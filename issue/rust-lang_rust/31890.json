{"url": "https://api.github.com/repos/rust-lang/rust/issues/31890", "repository_url": "https://api.github.com/repos/rust-lang/rust", "labels_url": "https://api.github.com/repos/rust-lang/rust/issues/31890/labels{/name}", "comments_url": "https://api.github.com/repos/rust-lang/rust/issues/31890/comments", "events_url": "https://api.github.com/repos/rust-lang/rust/issues/31890/events", "html_url": "https://github.com/rust-lang/rust/issues/31890", "id": 136470653, "node_id": "MDU6SXNzdWUxMzY0NzA2NTM=", "number": 31890, "title": "slice.iter_mut is not zero cost (vs IndexMut) when initializing a fresh vector", "user": {"login": "pnkfelix", "id": 173127, "node_id": "MDQ6VXNlcjE3MzEyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/173127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pnkfelix", "html_url": "https://github.com/pnkfelix", "followers_url": "https://api.github.com/users/pnkfelix/followers", "following_url": "https://api.github.com/users/pnkfelix/following{/other_user}", "gists_url": "https://api.github.com/users/pnkfelix/gists{/gist_id}", "starred_url": "https://api.github.com/users/pnkfelix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pnkfelix/subscriptions", "organizations_url": "https://api.github.com/users/pnkfelix/orgs", "repos_url": "https://api.github.com/users/pnkfelix/repos", "events_url": "https://api.github.com/users/pnkfelix/events{/privacy}", "received_events_url": "https://api.github.com/users/pnkfelix/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 113376, "node_id": "MDU6TGFiZWwxMTMzNzY=", "url": "https://api.github.com/repos/rust-lang/rust/labels/I-slow", "name": "I-slow", "color": "e10c02", "default": false, "description": "Problems and improvements with respect to performance of generated code."}, {"id": 211668062, "node_id": "MDU6TGFiZWwyMTE2NjgwNjI=", "url": "https://api.github.com/repos/rust-lang/rust/labels/T-libs-api", "name": "T-libs-api", "color": "bfd4f2", "default": false, "description": "Relevant to the library API team, which will review and decide on the PR/issue."}, {"id": 650731663, "node_id": "MDU6TGFiZWw2NTA3MzE2NjM=", "url": "https://api.github.com/repos/rust-lang/rust/labels/C-bug", "name": "C-bug", "color": "f5f1fd", "default": false, "description": "Category: This is a bug."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 17, "created_at": "2016-02-25T18:26:30Z", "updated_at": "2018-05-28T20:12:30Z", "closed_at": "2018-05-28T20:12:30Z", "author_association": "MEMBER", "active_lock_reason": null, "body": "While working on some demonstration code involving a matrix multiply, I discovered that the claim that Rust's iterator abstractions boil away to something competitive with hand-written assembly does not hold for a `for`-loop over `slice.iter_mut`.\n\nThat is, I would like to be able to give the following blanket advice:\n\n> You should prefer\n> \n> ``` rust\n> for elem in vec.iter_mut() { *elem = ...; }\n> ```\n> \n> over\n> \n> ``` rust\n> for i in 0..n { vec[i] = ...; }\n> ```\n> \n> as the first form will always be at least as fast as the second, and is sometimes faster\n\nBut here is a concrete example where that is not good advice:\n\n``` rust\npub fn applicative_add_vec_vec_index(a: &Vec<i32>, b: &Vec<i32>) -> Vec<i32> {\n    let n = a.len();\n    let mut c = vec![0; n];\n    for i in 0..n {         // \u21d0 COMPARING THIS...\n        c[i] = a[i] + b[i];\n    }\n    return c;\n}\n\npub fn applicative_add_vec_vec_itermut(a: &Vec<i32>, b: &Vec<i32>) -> Vec<i32> {\n    let n = a.len();\n    let mut i = 0;\n    let mut c = vec![0; n];\n    for c_i in c.iter_mut() { // \u21d0 ... TO THIS.\n        *c_i = a[i] + b[i];\n        i += 1;\n    }\n    return c;\n}\n```\n\nI made a benchmark to investigate the performance of the above two code snippets; each of the b_0/b_1/b_2/.../b_9 cases below are respectively adding vectors of length 1,000; 2,000; 4,000; ...; 512,000.\n\n```\ntest _b_0::bench_applicative_add_index                   ... bench:         708 ns/iter (+/- 33)\ntest _b_0::bench_applicative_add_itermut                 ... bench:       1,065 ns/iter (+/- 66)\n\ntest _b_1::bench_applicative_add_index                   ... bench:       1,418 ns/iter (+/- 545)\ntest _b_1::bench_applicative_add_itermut                 ... bench:       2,126 ns/iter (+/- 793)\n\ntest _b_2::bench_applicative_add_index                   ... bench:       3,038 ns/iter (+/- 715)\ntest _b_2::bench_applicative_add_itermut                 ... bench:       4,223 ns/iter (+/- 705)\n\ntest _b_3::bench_applicative_add_index                   ... bench:       5,883 ns/iter (+/- 2,503)\ntest _b_3::bench_applicative_add_itermut                 ... bench:       8,480 ns/iter (+/- 4,205)\n\ntest _b_4::bench_applicative_add_index                   ... bench:      12,255 ns/iter (+/- 949)\ntest _b_4::bench_applicative_add_itermut                 ... bench:      17,348 ns/iter (+/- 8,314)\n\ntest _b_5::bench_applicative_add_index                   ... bench:      39,095 ns/iter (+/- 10,043)\ntest _b_5::bench_applicative_add_itermut                 ... bench:      48,762 ns/iter (+/- 15,931)\n\ntest _b_6::bench_applicative_add_index                   ... bench:      76,462 ns/iter (+/- 26,995)\ntest _b_6::bench_applicative_add_itermut                 ... bench:      94,892 ns/iter (+/- 34,273)\n\ntest _b_7::bench_applicative_add_index                   ... bench:     150,292 ns/iter (+/- 61,944)\ntest _b_7::bench_applicative_add_itermut                 ... bench:     186,523 ns/iter (+/- 81,613)\n\ntest _b_8::bench_applicative_add_index                   ... bench:     312,718 ns/iter (+/- 64,088)\ntest _b_8::bench_applicative_add_itermut                 ... bench:     399,138 ns/iter (+/- 68,355)\n\ntest _b_9::bench_applicative_add_index                   ... bench:     654,565 ns/iter (+/- 112,684)\ntest _b_9::bench_applicative_add_itermut                 ... bench:     852,169 ns/iter (+/- 131,565)\n\n```\n\nThe index-based version is _consistently_ beating the `iter_mut`, with the latter exhibiting slowdown in the range of 1.2 to 1.3x. \n- That is the primary thing I am interested in trying to address in filing this ticket: Can we get code generation above to work for the functions above so that there is no significant performance hit for using `iter_mut` ? \n- (Ideally it would be faster than using indexing, but I would be satisfied if it was just roughly the same running times for both.)\n- I did bisection over the nightlies with multirust, and determined that the above two code snippets _used_ to have the same performance profile. Between nightly-2015-06-17 0250ff9a5 and nightly-2015-06-18 20d23d8e5  , the index based version got much faster, while the iter_mut version also got slower, yielding an observed performance difference similar to that documented above.\n\n---\n\nI eventually realized that the destination `Vector` being allocated within the benchmark iteration was certainly adding overhead to the benchmark that I wasn't necessarily interested in measuring.\n\nThis led me to make variations on the above benchmark with an imperative signature (`fn (&Vec<i32>, &Vec<i32>, &mut Vec<i32>)`): one that allocates the vector outside the benchmark `iter(|| ...)` call, and another that reallocates within the closure passed to `iter`, but still retains that imperative signature for the function being benchmarked.\n\nThis allows us to isolate how different operations compare; i.e. we can directly observe how a for loop with indexing works versus iter_mut when LLVM _does not know_ how large the actual given vector is that is being mutably traversed.\n\nHere then is the full benchmark code:\n\n``` rust\n#![feature(test)]\nextern crate test;\n\npub fn imperative_add_vec_vec_index(a: &Vec<i32>, b: &Vec<i32>, c: &mut Vec<i32>) {\n    let n = a.len();\n    for i in 0..n {         // \u21d0 COMPARING THIS...\n        c[i] = a[i] + b[i];\n    }\n}\n\npub fn imperative_add_vec_vec_itermut(a: &Vec<i32>, b: &Vec<i32>, c: &mut Vec<i32>) {\n    let mut i = 0;\n    for c_i in c.iter_mut() { // \u21d0 ... TO THIS.\n        *c_i = a[i] + b[i];\n        i += 1;\n    }\n}\n\npub fn applicative_add_vec_vec_index(a: &Vec<i32>, b: &Vec<i32>) -> Vec<i32> {\n    let n = a.len();\n    let mut c = vec![0; n];\n    for i in 0..n {         // \u21d0 COMPARING THIS...\n        c[i] = a[i] + b[i];\n    }\n    return c;\n}\n\npub fn applicative_add_vec_vec_itermut(a: &Vec<i32>, b: &Vec<i32>) -> Vec<i32> {\n    let n = a.len();\n    let mut i = 0;\n    let mut c = vec![0; n];\n    for c_i in c.iter_mut() { // \u21d0 ... TO THIS.\n        *c_i = a[i] + b[i];\n        i += 1;\n    }\n    return c;\n}\n\n#[test]\nfn test_add_tens_tens_index() {\n    let mut c = vec![0, 0, 0];\n    imperative_add_vec_vec_index(&vec![10,20,30],\n                                 &vec![10,20,30],\n                                 &mut c);\n    assert_eq!(c, vec![20, 40, 60]);\n    c = applicative_add_vec_vec_index(&vec![10,20,30],\n                                      &vec![10,20,30]);\n    assert_eq!(c, vec![20, 40, 60]);\n}\n\n#[test]\nfn test_add_tens_tens_itermut() {\n    let mut c = vec![0, 0, 0];\n    imperative_add_vec_vec_itermut(&vec![10,20,30],\n                                   &vec![10,20,30],\n                                   &mut c);\n    assert_eq!(c, vec![20, 40, 60]);\n    c = applicative_add_vec_vec_index(&vec![10,20,30],\n                                      &vec![10,20,30]);\n    assert_eq!(c, vec![20, 40, 60]);\n}\n\nmacro_rules! add_benches {\n    ($prefix: ident, $size: expr) => {\n        pub mod $prefix {\n            #[bench]\n            fn bench_imperative_add_index(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                let c = &mut vec![0; $size];\n                b.iter(|| super::imperative_add_vec_vec_index(u, v, c));\n                assert_eq!(c, &mut vec![20; $size]);\n            }\n\n            #[bench]\n            fn bench_imperative_add_itermut(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                let c = &mut vec![0; $size];\n                b.iter(|| super::imperative_add_vec_vec_itermut(u, v, c));\n                assert_eq!(c, &mut vec![20; $size]);\n            }\n\n            #[bench]\n            fn bench_imperative_reallocating_add_index(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                b.iter(|| {\n                    let c = &mut vec![0; $size];\n                    super::imperative_add_vec_vec_index(u, v, c);\n                    assert_eq!(c, &mut vec![20; $size]);\n                });\n            }\n\n            #[bench]\n            fn bench_imperative_reallocating_add_itermut(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                b.iter(|| {\n                    let c = &mut vec![0; $size];\n                    super::imperative_add_vec_vec_itermut(u, v, c);\n                    assert_eq!(c, &mut vec![20; $size]);\n                });\n            }\n\n            #[bench]\n            fn bench_applicative_add_index(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                let mut c = vec![0; $size];\n                b.iter(|| c = super::applicative_add_vec_vec_index(u, v));\n                assert_eq!(c, vec![20; $size]);\n            }\n\n            #[bench]\n            fn bench_applicative_add_itermut(b: &mut ::test::Bencher) {\n                let u = &vec![10; $size];\n                let v = &vec![10; $size];\n                let mut c = vec![0; $size];\n                b.iter(|| c = super::applicative_add_vec_vec_itermut(u, v));\n                assert_eq!(c, vec![20; $size]);\n            }\n\n            #[bench]\n            fn linebreak_applicative_imperative_reallocating(_: &mut ::test::Bencher) { }\n        }\n    }\n}\n\nadd_benches!(_b_0,    1_000);\nadd_benches!(_b_1,    2_000);\nadd_benches!(_b_2,    4_000);\nadd_benches!(_b_3,    8_000);\nadd_benches!(_b_4,   16_000);\nadd_benches!(_b_5,   32_000);\nadd_benches!(_b_6,   64_000);\nadd_benches!(_b_7,  128_000);\nadd_benches!(_b_8,  256_000);\nadd_benches!(_b_9,  512_000);\n```\n\nAnd here are results of running the above benchmark on my laptop. (The \"linebreak\" entries are, as the name indicates, just to break up the different data sets in the right hand side.)\n\n```\n% multirust show-default && cargo test test && cargo bench\nmultirust: default toolchain: nightly\nmultirust: default location: /Users/fklock/.multirust/toolchains/nightly\n\nrustc 1.8.0-nightly (0ef8d4260 2016-02-24)\ncargo 0.9.0-nightly (e721289 2016-02-25)\n\n     Running target/debug/iter_mut_bench-1f3abd6a849082b3\n\nrunning 2 tests\ntest test_add_tens_tens_index ... ok\ntest test_add_tens_tens_itermut ... ok\n\ntest result: ok. 2 passed; 0 failed; 0 ignored; 0 measured\n\n   Doc-tests iter_mut_bench\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured\n\n     Running target/release/iter_mut_bench-1f3abd6a849082b3\n\nrunning 72 tests\ntest test_add_tens_tens_index ... ignored\ntest test_add_tens_tens_itermut ... ignored\ntest _b_0::bench_applicative_add_index                   ... bench:         760 ns/iter (+/- 102)\ntest _b_0::bench_applicative_add_itermut                 ... bench:       1,079 ns/iter (+/- 172)\ntest _b_0::bench_imperative_add_index                    ... bench:         766 ns/iter (+/- 142)\ntest _b_0::bench_imperative_add_itermut                  ... bench:         649 ns/iter (+/- 141)\ntest _b_0::bench_imperative_reallocating_add_index       ... bench:       1,377 ns/iter (+/- 342)\ntest _b_0::bench_imperative_reallocating_add_itermut     ... bench:       1,031 ns/iter (+/- 254)\ntest _b_0::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_1::bench_applicative_add_index                   ... bench:       1,735 ns/iter (+/- 1,079)\ntest _b_1::bench_applicative_add_itermut                 ... bench:       3,082 ns/iter (+/- 5,055)\ntest _b_1::bench_imperative_add_index                    ... bench:       1,530 ns/iter (+/- 433)\ntest _b_1::bench_imperative_add_itermut                  ... bench:       1,277 ns/iter (+/- 368)\ntest _b_1::bench_imperative_reallocating_add_index       ... bench:       2,870 ns/iter (+/- 1,037)\ntest _b_1::bench_imperative_reallocating_add_itermut     ... bench:       2,126 ns/iter (+/- 2,189)\ntest _b_1::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_2::bench_applicative_add_index                   ... bench:       3,375 ns/iter (+/- 1,176)\ntest _b_2::bench_applicative_add_itermut                 ... bench:       5,092 ns/iter (+/- 7,258)\ntest _b_2::bench_imperative_add_index                    ... bench:       3,163 ns/iter (+/- 2,309)\ntest _b_2::bench_imperative_add_itermut                  ... bench:       2,740 ns/iter (+/- 3,348)\ntest _b_2::bench_imperative_reallocating_add_index       ... bench:       5,820 ns/iter (+/- 4,686)\ntest _b_2::bench_imperative_reallocating_add_itermut     ... bench:       4,496 ns/iter (+/- 1,314)\ntest _b_2::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_3::bench_applicative_add_index                   ... bench:       7,107 ns/iter (+/- 4,992)\ntest _b_3::bench_applicative_add_itermut                 ... bench:      10,039 ns/iter (+/- 5,720)\ntest _b_3::bench_imperative_add_index                    ... bench:       6,395 ns/iter (+/- 4,394)\ntest _b_3::bench_imperative_add_itermut                  ... bench:       5,488 ns/iter (+/- 7,558)\ntest _b_3::bench_imperative_reallocating_add_index       ... bench:      11,609 ns/iter (+/- 10,878)\ntest _b_3::bench_imperative_reallocating_add_itermut     ... bench:       9,217 ns/iter (+/- 5,291)\ntest _b_3::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_4::bench_applicative_add_index                   ... bench:      13,699 ns/iter (+/- 16,487)\ntest _b_4::bench_applicative_add_itermut                 ... bench:      19,223 ns/iter (+/- 2,807)\ntest _b_4::bench_imperative_add_index                    ... bench:      11,990 ns/iter (+/- 1,706)\ntest _b_4::bench_imperative_add_itermut                  ... bench:      10,324 ns/iter (+/- 2,901)\ntest _b_4::bench_imperative_reallocating_add_index       ... bench:      37,090 ns/iter (+/- 13,541)\ntest _b_4::bench_imperative_reallocating_add_itermut     ... bench:      32,028 ns/iter (+/- 9,136)\ntest _b_4::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_5::bench_applicative_add_index                   ... bench:      45,018 ns/iter (+/- 20,031)\ntest _b_5::bench_applicative_add_itermut                 ... bench:      55,431 ns/iter (+/- 57,384)\ntest _b_5::bench_imperative_add_index                    ... bench:      27,231 ns/iter (+/- 15,549)\ntest _b_5::bench_imperative_add_itermut                  ... bench:      21,901 ns/iter (+/- 31,860)\ntest _b_5::bench_imperative_reallocating_add_index       ... bench:      75,070 ns/iter (+/- 14,594)\ntest _b_5::bench_imperative_reallocating_add_itermut     ... bench:      66,472 ns/iter (+/- 19,059)\ntest _b_5::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_6::bench_applicative_add_index                   ... bench:      83,719 ns/iter (+/- 13,320)\ntest _b_6::bench_applicative_add_itermut                 ... bench:     110,591 ns/iter (+/- 23,880)\ntest _b_6::bench_imperative_add_index                    ... bench:      52,350 ns/iter (+/- 11,850)\ntest _b_6::bench_imperative_add_itermut                  ... bench:      45,233 ns/iter (+/- 13,832)\ntest _b_6::bench_imperative_reallocating_add_index       ... bench:     139,599 ns/iter (+/- 36,488)\ntest _b_6::bench_imperative_reallocating_add_itermut     ... bench:     115,499 ns/iter (+/- 41,773)\ntest _b_6::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_7::bench_applicative_add_index                   ... bench:     152,048 ns/iter (+/- 23,623)\ntest _b_7::bench_applicative_add_itermut                 ... bench:     195,796 ns/iter (+/- 24,616)\ntest _b_7::bench_imperative_add_index                    ... bench:      93,273 ns/iter (+/- 17,124)\ntest _b_7::bench_imperative_add_itermut                  ... bench:      82,290 ns/iter (+/- 14,308)\ntest _b_7::bench_imperative_reallocating_add_index       ... bench:     260,315 ns/iter (+/- 42,152)\ntest _b_7::bench_imperative_reallocating_add_itermut     ... bench:     222,595 ns/iter (+/- 28,584)\ntest _b_7::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_8::bench_applicative_add_index                   ... bench:     320,524 ns/iter (+/- 46,424)\ntest _b_8::bench_applicative_add_itermut                 ... bench:     419,922 ns/iter (+/- 45,263)\ntest _b_8::bench_imperative_add_index                    ... bench:     191,193 ns/iter (+/- 32,244)\ntest _b_8::bench_imperative_add_itermut                  ... bench:     161,733 ns/iter (+/- 29,028)\ntest _b_8::bench_imperative_reallocating_add_index       ... bench:     574,651 ns/iter (+/- 96,008)\ntest _b_8::bench_imperative_reallocating_add_itermut     ... bench:     513,109 ns/iter (+/- 63,440)\ntest _b_8::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\ntest _b_9::bench_applicative_add_index                   ... bench:     673,698 ns/iter (+/- 114,850)\ntest _b_9::bench_applicative_add_itermut                 ... bench:     842,234 ns/iter (+/- 130,654)\ntest _b_9::bench_imperative_add_index                    ... bench:     381,448 ns/iter (+/- 76,419)\ntest _b_9::bench_imperative_add_itermut                  ... bench:     339,002 ns/iter (+/- 63,421)\ntest _b_9::bench_imperative_reallocating_add_index       ... bench:   1,705,358 ns/iter (+/- 231,283)\ntest _b_9::bench_imperative_reallocating_add_itermut     ... bench:   1,533,730 ns/iter (+/- 253,143)\ntest _b_9::linebreak_applicative_imperative_reallocating ... bench:           0 ns/iter (+/- 0)\n\ntest result: ok. 0 passed; 0 failed; 2 ignored; 70 measured\n```\n\nThe main conclusions I draw from these data sets are:\n- If you avoid reallocation (which means you don't use applicative style), then `iter_mut` _will_ perform better than indexing for initializing a destination vector. (This is based on the lines labelled \"imperative\" and comparing the \"index\" versus \"itermut\" pairs.)\n- If you reallocate on each iteration and use \"iter_mut\", then for some bizarre reason on _small_ vectors (\"b_0\", \"b_1\", \"b_2\", \"b_3\") doing the reallocation outside of the initialization itself (\"imperative_reallocating_add_itermut\") will perform better than applicative style (\"applicative_add_itermut\").  At some threshold (\"b_4\" and above) the applicative itermut is faster than the reallocating itermut.\n- There is a _huge_ performance difference between \"imperative_reallocating_add_index\" and \"applicative_add_index.\" My current hypothesis is that LLVM is doing some amazing work to optimize all of the index based accesses when the vector is allocated within the same function (and thus LLVM can see how large the backing store for the vector is.)\n", "closed_by": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/rust-lang/rust/issues/31890/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/rust-lang/rust/issues/31890/timeline", "performed_via_github_app": null, "state_reason": "completed"}