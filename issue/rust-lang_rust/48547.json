{"url": "https://api.github.com/repos/rust-lang/rust/issues/48547", "repository_url": "https://api.github.com/repos/rust-lang/rust", "labels_url": "https://api.github.com/repos/rust-lang/rust/issues/48547/labels{/name}", "comments_url": "https://api.github.com/repos/rust-lang/rust/issues/48547/comments", "events_url": "https://api.github.com/repos/rust-lang/rust/issues/48547/events", "html_url": "https://github.com/rust-lang/rust/issues/48547", "id": 300273296, "node_id": "MDU6SXNzdWUzMDAyNzMyOTY=", "number": 48547, "title": "Compiler Performance Tracking Issue", "user": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 37977651, "node_id": "MDU6TGFiZWwzNzk3NzY1MQ==", "url": "https://api.github.com/repos/rust-lang/rust/labels/metabug", "name": "metabug", "color": "5319e7", "default": false, "description": "Issues about issues themselves (\"bugs about bugs\")"}, {"id": 64037154, "node_id": "MDU6TGFiZWw2NDAzNzE1NA==", "url": "https://api.github.com/repos/rust-lang/rust/labels/I-compiletime", "name": "I-compiletime", "color": "e11d21", "default": false, "description": "Problems and improvements with respect to compile times."}, {"id": 211668100, "node_id": "MDU6TGFiZWwyMTE2NjgxMDA=", "url": "https://api.github.com/repos/rust-lang/rust/labels/T-compiler", "name": "T-compiler", "color": "bfd4f2", "default": false, "description": "Relevant to the compiler team, which will review and decide on the PR/issue."}, {"id": 650846969, "node_id": "MDU6TGFiZWw2NTA4NDY5Njk=", "url": "https://api.github.com/repos/rust-lang/rust/labels/C-tracking-issue", "name": "C-tracking-issue", "color": "f5f1fd", "default": false, "description": "Category: A tracking issue for an RFC or an unstable feature."}, {"id": 849077850, "node_id": "MDU6TGFiZWw4NDkwNzc4NTA=", "url": "https://api.github.com/repos/rust-lang/rust/labels/WG-compiler-performance", "name": "WG-compiler-performance", "color": "c2e0c6", "default": false, "description": "Working group: Compiler Performance"}, {"id": 3537211959, "node_id": "LA_kwDOAAsO6M7S1ZI3", "url": "https://api.github.com/repos/rust-lang/rust/labels/S-tracking-impl-incomplete", "name": "S-tracking-impl-incomplete", "color": "4682b4", "default": false, "description": ""}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-02-26T15:06:48Z", "updated_at": "2023-03-02T11:32:20Z", "closed_at": null, "author_association": "MEMBER", "active_lock_reason": null, "body": "This issue is the landing page for all things compilation speed related. We define the most important usage scenarios, as seen by the @rust-lang/compiler team and the @rust-lang/wg-compiler-performance working group. Benchmarks based on these scenarios are then used as a metric for how well the compiler is doing, compile-time-wise. We then establish a model of the compilation process and use it to estimate the effect of optimization categories on the various usage scenarios. Finally, we list concrete optimization ideas and initiatives, relate them to categories and usage scenarios, and link to their various specific GH issues.\r\n\r\n\r\n\r\n# Usage Scenarios\r\nWe track compiler performance in a number of use cases in order to gauge how compile times in the most important and common scenarios develop. We continuously measure how the compiler performs on [perf.rust-lang.org](perf.rust-lang.org). #48750 defines which concrete benchmarks go into measuring each usage scenario. In the following, \"project\" means a medium to large codebase consisting of dozens of crates, most of which come from [crates.io](https://crates.io).\r\n\r\n - **FROM-SCRATCH** - Compiling a project from scratch (*P-high*)\r\nThis scenario occurs when a project is compiled for the first time, during CI builds, and when compiling after running `cargo clean`, `make clean` or something similar. The targeted runtime performance for builds like this is usually \"fast enough\", that is, the compiled program should execute with performance that does not hinder testing but it is not expected to have absolute peak performance as you would expect from a release build.\r\n\r\n - **SMALL-CHANGE** - Re-Compiling a project after a small change (*P-high*)\r\nThis scenario is the most common during the regular edit-compile-debug cycle. Low compile times are the top-most priority in this scenario. The compiled runtime performance, again, should be good enough not to be an obstacle.\r\n\r\n - **RLS** - Continuously re-compiling a project for the Rust Language Server (*P-high*)\r\nThis scenario covers how the Rust compiler is used by the [RLS](https://github.com/rust-lang-nursery/rls). Again, low compile times are the top-most priority here. The only difference to the previous scenario is that no executable program needs to be generated at all. The output here is diagnostics and the RLS specific `save-analysis` data.\r\n\r\n - **DIST** - Compiling a project for maximum runtime performance (*P-medium*)\r\nThis scenario covers the case of generating release artifacts meant for being distributed and for reflecting runtime performance as perceived by end users. Here, compile times are of secondary importance -- they should be low if possible (especially for running benchmarks) but if there is a trade-off between compile time and runtime performance then runtime performance wins.\r\n\r\nSometimes we also see people \"measuring\" Rust's compile times by compiling a \"Hello World\" program and comparing how long that takes in other languages. While we do have such a benchmark in our suite, we don't consider it one of the important usage scenarios.\r\n\r\n\r\n# A Model of the Compilation Process\r\nThe compiler does lots of different things while it is compiling a program. Making any one of those things faster might improve the compile time in one of the scenarios above or it might not. This section will establish a few categories of tasks that the compiler executes and then will map each category to the scenarios that it impacts.\r\n\r\n## Compilation Phases / Task Categories\r\nThe compiler works in four large phases these days:\r\n\r\n1. **Pre-Query Analysis** (pre-query) -- This roughly includes parsing, macro expansion, name resolution, and lowering to HIR. The tasks in this phase still follow the bulk processing paradigm and the results it produces cannot be cached for incremental compilation. This phase is executed on a single thread.\r\n\r\n2. **Query-based Analysis** (query) -- This includes type checking and inference, lowering to MIR, borrow checking, MIR optimization, and translation to LLVM IR. The various sub-tasks in this phase are implemented as so-called *queries*, which are computations that form a DAG and the results of which can be tracked and cached for incremental compilation. Queries are also only executed if their result is requested, so in theory this system would allow for partially compiling code. This phase too is executed on a single thread.\r\n\r\n3. **LLVM-based optimization and code generation** (llvm) -- Once the compiler has generated the LLVM IR representation of a given crate, it lets LLVM optimize and then translate it to a number of object files. For optimized builds this usually takes up 65-80% of the overall compilation time. This phase can be run on multiple threads in parallel, depending on compiler settings. Incremental compilation allows to skip LLVM work but is less effective than for queries because caching is more coarse-grained.\r\n\r\n4. **Linking** (link) -- Finally, after LLVM has translated the program into object files, the output is linked into the final binary. This is done by an external linker which `rustc` takes care of invoking.\r\n\r\nNote that this describes the compilation process for a single crate. However, in the scenarios given above, we always deal with a whole graph of crates. Cargo will coordinate the build process for a graph of crates, only compiling crates the code of which has changed. For the overall compile time of a whole project, it is important to note that Cargo will compile multiple crates in parallel, but can only start compiling a crate once all its dependencies have been compiled. The crates in a project form a directed acyclic graph.\r\n\r\n## Using Task Categories To Estimate Optimization Impact On Scenarios\r\nFrom the description above we can infer which optimizations will affect which scenarios:\r\n\r\n* Making a (pre-query) task faster will affect all scenarios as these are unconditionally executed in every compilation session.\r\n* Making a (query) task faster will also affect all scenarios as these are also executed in every session.\r\n* Making (llvm) execute faster will have most effect on FROM-SCRATCH and DIST, and some effect on SMALL-CHANGE. It will have no effect on RLS.\r\n* Making (link) faster helps with FROM-SCRATCH, DIST, and SMALL-CHANGE, since we always have to link the whole program in these cases. In the SMALL-CHANGE scenario, linking will be a bigger portion of overall compile time than in the other two. For RLS we don't do any linking.\r\n* Turning a (pre-query) task into a (query) task will improve SMALL-CHANGE and RLS because we profit from incremental compilation in these scenarios. If done properly, it should not make a difference for for the other scenarios.\r\n* Reducing the amount of work we generate for (llvm) will have the same effects as making (llvm) execute more quickly.\r\n* Reducing the time between the start of compiling a crate and the point where dependents of that crate can start compiling can bring superlinear compile-time speedups because it reduces contention in Cargo's parallel compilation flow.\r\n* Reducing the overhead for incremental compilation helps with SMALL-CHANGE and RLS and possibly FROM-SCRATCH.\r\n* Improving incr. comp. caching efficiency for LLVM artifacts helps with SMALL-CHANGE and possibly FROM-SCRATCH, but not DIST, which does not use incremental compilation, and RLS, which does not produce LLVM artifacts.\r\n* Improving generation of save-analysis data will help the RLS case, while this kind of data is not produced during any of the other scenarios.\r\n\r\n\r\n# Concrete Performance Improvement Initiatives\r\n\r\nThere are various concrete initiatives of various sizes that strive to improve the compiler's performance. Some of them are far along, some of them are just ideas that need to be validated before pursuing them further.\r\n\r\n## Incremental compilation\r\n\r\nWork on supporting incremental re-compilation of programs has been ongoing for quite a while now and it is available on stable Rust. However, there are still many opportunities for improving it.\r\n\r\n - Status: \"version 1.0\" available on stable.\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/47660.\r\n - Affected usage scenarios: **SMALL-CHANGE**, **RLS**\r\n\r\n## Query parallelization\r\n\r\nCurrently to compiler can evaluate queries (which comprise a large part of the non-LLVM compilation phases) in a single-threaded fashion. However, since queries have a clear evaluation model which structures computations into a directed acyclic graph, it seems feasible to implement parallel evaluation for queries at the framework level. @Zoxc even has done a proof-of-concept implementation. This would potentially help with usage scenarios since all of them have to execute the query-part of compilation.\r\n\r\n - Status: Preliminary work in progress, experimental\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/48685\r\n - Affect usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **RLS**, **DIST**\r\n\r\n## MIR-only RLIBs\r\n\r\n\"MIR-only RLIBs\" is what we call the idea of not generating any LLVM IR or machine code for RLIBs. Instead, all of this would be deferred to when executables, dynamic libraries, or static C libraries are generated. This potentially reduces the overall workload for compiling a whole crate graph and has some non-performance related benefits too. However, it might be detrimental in some other usage scenarios, especially if incremental compilation is not enabled.\r\n\r\n - Status: Blocked on query parallelization\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/38913\r\n - Affected usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **DIST**\r\n\r\n## ThinLTO\r\n\r\nThinLTO is an LLVM mode that allows to perform whole program optimization in a mostly parallel fashion. It is currently supported by the Rust compiler and even enabled by default in some cases. It tries to reduce compile times by distributing the LLVM workload to more CPU cores. At the same time the overall workload increases, so it can also have detrimental effects.\r\n\r\n - Status: available on stable, default for optimized builds\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/45320\r\n - Affected usage scenarios: **FROM-SCRATCH**, **DIST**\r\n\r\n## Sharing generic code between crates\r\n\r\nCurrently, the compiler will duplicate the machine code for generic functions within each crate that uses a specific monomorphization of a given function. If there is a lot of overlap this potentially means lots of redundant work. It should be investigated how much work and compile time could be saved by re-using monomorphizations across crate boundaries.\r\n\r\n - Status: Experimental implementation in #48779\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/47317\r\n - Affected usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **DIST**\r\n\r\n## Sharing closures among generic instances\r\n\r\nWe duplicate code for closures within generic functions even if they do not depend on the generic parameters of the enclosing function. This leads to redundant work. We should try to be smarter about it.\r\n\r\n - Status: Unknown\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/46477\r\n - Affected usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **DIST**\r\n\r\n## Perform inlining at the MIR-level\r\n\r\nPerforming at least some amount of inlining at the MIR-level would potentially reduce the pressure on LLVM. It would also reduce the overall amount of work to be done because inlining would only have to be done once for all monomorphizations of a function while LLVM has to redo the work for each instance. There is an experimental implementation of MIR-inlining but it is not production-ready yet.\r\n\r\n - Status: Experimental implementation exists on nightly, not stable or optimized yet\r\n - Current progress is tracked in #43542 (kind of)\r\n - Affected usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **DIST**\r\n\r\n## Provide tools and instructions for profiling the compiler\r\n\r\nProfiling is an indispensable part of performance optimization. We should make it as easy as possible to profile the compiler and get an idea what it is spending its time on. That includes guides on how to use external profiling tools and improving the compiler internal profiling facilities.\r\n\r\n - Status: Idea\r\n - Current progress is tracked in (nowhere yet)\r\n - Affect usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **RLS**, **DIST**\r\n\r\n## Build released compiler binaries as optimized as possible\r\n\r\nThere is still headroom for turning on more optimizations for building the `rustc` release artifacts. Right now this is blocked by a mix of CI restrictions and possibly outdated restrictions for when build Rust dylibs.\r\n\r\n - Status: In progress\r\n - Current progress is tracked in https://github.com/rust-lang/rust/issues/49180\r\n - Affect usage scenarios: **FROM-SCRATCH**, **SMALL-CHANGE**, **RLS**, **DIST**\r\n\r\n\r\nFeel free to leave comments below if there's anything you think is pertinent to this topic!\r\n", "closed_by": null, "reactions": {"url": "https://api.github.com/repos/rust-lang/rust/issues/48547/reactions", "total_count": 89, "+1": 21, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 68, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/rust-lang/rust/issues/48547/timeline", "performed_via_github_app": null, "state_reason": null}