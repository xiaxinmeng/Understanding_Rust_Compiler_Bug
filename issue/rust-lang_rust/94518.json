{"url": "https://api.github.com/repos/rust-lang/rust/issues/94518", "repository_url": "https://api.github.com/repos/rust-lang/rust", "labels_url": "https://api.github.com/repos/rust-lang/rust/issues/94518/labels{/name}", "comments_url": "https://api.github.com/repos/rust-lang/rust/issues/94518/comments", "events_url": "https://api.github.com/repos/rust-lang/rust/issues/94518/events", "html_url": "https://github.com/rust-lang/rust/issues/94518", "id": 1156987130, "node_id": "I_kwDOAAsO6M5E9jj6", "number": 94518, "title": "Concurrency bugs in mpsc's stream and shared mode", "user": {"login": "grelative", "id": 100744172, "node_id": "U_kgDOBgE77A", "avatar_url": "https://avatars.githubusercontent.com/u/100744172?v=4", "gravatar_id": "", "url": "https://api.github.com/users/grelative", "html_url": "https://github.com/grelative", "followers_url": "https://api.github.com/users/grelative/followers", "following_url": "https://api.github.com/users/grelative/following{/other_user}", "gists_url": "https://api.github.com/users/grelative/gists{/gist_id}", "starred_url": "https://api.github.com/users/grelative/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/grelative/subscriptions", "organizations_url": "https://api.github.com/users/grelative/orgs", "repos_url": "https://api.github.com/users/grelative/repos", "events_url": "https://api.github.com/users/grelative/events{/privacy}", "received_events_url": "https://api.github.com/users/grelative/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 9695584, "node_id": "MDU6TGFiZWw5Njk1NTg0", "url": "https://api.github.com/repos/rust-lang/rust/labels/A-concurrency", "name": "A-concurrency", "color": "f7e101", "default": false, "description": "Area: Concurrency related issues."}, {"id": 650731663, "node_id": "MDU6TGFiZWw2NTA3MzE2NjM=", "url": "https://api.github.com/repos/rust-lang/rust/labels/C-bug", "name": "C-bug", "color": "f5f1fd", "default": false, "description": "Category: This is a bug."}, {"id": 2011781731, "node_id": "MDU6TGFiZWwyMDExNzgxNzMx", "url": "https://api.github.com/repos/rust-lang/rust/labels/T-libs", "name": "T-libs", "color": "bfd4f2", "default": false, "description": "Relevant to the library team, which will review and decide on the PR/issue."}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2022-03-02T10:21:16Z", "updated_at": "2023-01-20T23:34:44Z", "closed_at": "2023-01-20T23:34:44Z", "author_association": "NONE", "active_lock_reason": null, "body": "# Case 1\r\nIf a reader wait on` recv_timeout()`  wakeups because of timeout, that reader will first call `abort_selection()` to clear the signal_token, then do another `try_recv()`, and return whatever` try_recv()` got.  Howerver if a `send()` operation happen after the reader wakeup and finish before the `try_recv()` got to execute, the `try_recv()` will return the data from that `send()` operation, and the next call to `recv()` will panic.\r\n\r\n```rust\r\nuse std::{sync::mpsc, thread, time};\r\n\r\nfn main() {\r\n    let (tx, rx) = mpsc::channel();\r\n    let tx = tx.clone();\r\n\r\n    let _ = thread::spawn(move||{\r\n        thread::sleep(time::Duration::from_millis(200));\r\n        tx.send(1).unwrap();\r\n        println!(\"send finished\");\r\n    });\r\n\r\n    println!(\"recv 1: {:?}\", rx.recv_timeout(time::Duration::from_millis(100)));\r\n    println!(\"recv 2: {:?}\", rx.recv());\r\n}\r\n```\r\nTo reproduce the problem, we have to arrange the `send()` happens exactly after the ` recv_timeout()` wakeups, and finishes before the `recv_timeout()` returns.  That can be done with a debugger's help.\r\n```\r\n(gdb) set non-stop on\r\n(gdb) set env RUST_BACKTRACE 1\r\n(gdb) break std::sync::mpsc::shared::Packet<T>::abort_selection\r\nBreakpoint 1 at 0xb622: file /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs, line 450.\r\n(gdb) run\r\nStarting program: \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff7d82700 (LWP 20921)]\r\n\r\nThread 1 \"channel\" hit Breakpoint 1, std::sync::mpsc::shared::Packet<T>::abort_selection (self=0x5555555c4a40,\r\n    _was_upgrade=false) at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:450\r\n450                 let _guard = self.select_lock.lock().unwrap();\r\nsend finished\r\n[Thread 0x7ffff7d82700 (LWP 20921) exited]\r\n\r\n(gdb) continue\r\nContinuing.\r\nrecv 1: Ok(1)\r\nthread 'main' panicked at 'internal error: entered unreachable code', /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/mod.rs:1175:43\r\nstack backtrace:\r\n   0: rust_begin_unwind\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/panicking.rs:498:5\r\n   1: core::panicking::panic_fmt\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/panicking.rs:107:14\r\n   2: core::panicking::panic\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/panicking.rs:48:5\r\n   3: std::sync::mpsc::Receiver<T>::recv\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/mod.rs:1175:43\r\n   4: channel::main\r\n             at ./src/bin/channel.rs:14:30\r\n   5: core::ops::function::FnOnce::call_once\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/ops/function.rs:227:5\r\nnote: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\r\n[Inferior 1 (process 20879) exited with code 0145]\r\n```\r\n\r\nThe `recv()` panics because in the [`decrement() `](https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L261), it founds that cnt(2) is greater than steals(1), which means the queue is not empty, and a next `try_recv()` is guaranteed to return som data. Howerver the queue is actually empty, this inconsistency cause code goes into an impossible path, and panics.  \r\n\r\nThe relation between cnt and steals seems like this:  if a sender send one element successfully, it must increase the cnt; if a reader receive an element successfully, it either increase the steals or decrease the cnt, if receive failed, it should not modify or undo the modification to steals and cnt.  Thus we are guaranteed when cnt <= steals, it means the queue is definitely empty, and if cnt > steals, the queue is definitely non-empty. \r\n\r\nEvery `recv`https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L218-L245  will call `try_recv()` twice:\r\nIf the first `try_recv` success, it will increase the steals; and if not, it will `decrease`https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L261 the cnt, then wait for the wakeup, after the wakeup it will call `try_recv` again. Normally when reader is waked up, that mean some elment has been sent, so the next `try_recv()` will return an element successfully; but when reader is waked up because of timeout, the next `try_recv()` will fail to get an element, thus it has to https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L462 increase the cnt back in `abort_selection`. \r\nThe  bug hides in here, in fact, if a` send `happend after the wakeup and finish before the next `try_recv`, the next try_recv will succeed!  But in that case, neither the steal is increased nor the cnt is decreased, the consistency is breaked. The next `recv` will discover this inconsistency, and panics.\r\n## fix\r\nThis problem can be fixed by adding a return after `abort_selection` https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L231. Since this reader is waked up because of timeout, it does not make sense to do another `try_recv`, we can return an Err(Timeout) directly.\r\n\r\n# case 2\r\n```\r\nuse std::{sync::mpsc, thread, time};\r\n\r\nfn main() {\r\n    let (tx, rx) = mpsc::channel::<i32>();\r\n\r\n    let thread = thread::spawn(move ||{\r\n        let _ = tx.clone();\r\n        thread::sleep(time::Duration::from_secs(2));\r\n    });\r\n\r\n    println!(\"recv 1: {:?}\", rx.recv_timeout(time::Duration::from_secs(1)));\r\n    thread.join().unwrap();\r\n}\r\n```\r\nThis problem also need to reproduce under a debugger.\r\n\r\n```\r\n(gdb) set non-stop on\r\n(gdb) set environment RUST_BACKTRACE 1\r\n(gdb) break std::sync::mpsc::shared::Packet<T>::abort_selection\r\ntd::sync::mpsc::shared::Packet<T>::take_to_wakeBreakpoint 1 at 0x16332: file /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs, line 450.\r\n(gdb) break std::sync::mpsc::shared::Packet<T>::take_to_wake\r\nBreakpoint 2 at 0x1622e: file /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs, line 417.\r\n(gdb) run\r\nStarting program: \r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff7d82700 (LWP 23113)]\r\n\r\nThread 1 \"channel2\" hit Breakpoint 1, std::sync::mpsc::shared::Packet<T>::abort_selection (self=0x7ffff0000bf0,\r\n    _was_upgrade=false) at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:450\r\n450                 let _guard = self.select_lock.lock().unwrap();\r\n(gdb)\r\nThread 2 \"channel2\" hit Breakpoint 2, std::sync::mpsc::shared::Packet<T>::take_to_wake (self=0x7ffff0000bf0)\r\n    at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:417\r\n417             let ptr = self.to_wake.load(Ordering::SeqCst);\r\n\r\n(gdb) continue\r\nContinuing.\r\nthread 'main' panicked at 'assertion failed: `(left == right)`\r\n  left: `93824992685056`,\r\n right: `0`', /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:465:13\r\nstack backtrace:\r\n   0: rust_begin_unwind\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/panicking.rs:498:5\r\n   1: core::panicking::panic_fmt\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/panicking.rs:107:14\r\n   2: core::panicking::assert_failed_inner\r\n   3: core::panicking::assert_failed\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/panicking.rs:145:5\r\n   4: std::sync::mpsc::shared::Packet<T>::abort_selection\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:465:13\r\n   5: std::sync::mpsc::shared::Packet<T>::recv\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/shared.rs:231:21\r\n   6: std::sync::mpsc::Receiver<T>::recv_deadline\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/mod.rs:1357:48\r\n   7: std::sync::mpsc::Receiver<T>::recv_timeout\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/std/src/sync/mpsc/mod.rs:1276:35\r\n   8: channel2::main\r\n             at ./src/bin/channel2.rs:11:30\r\n   9: core::ops::function::FnOnce::call_once\r\n             at /rustc/db9d1b20bba1968c1ec1fc49616d4742c1725b4b/library/core/src/ops/function.rs:227:5\r\nnote: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\r\n[Thread 0x7ffff7d82700 (LWP 23113) exited]\r\n[Inferior 1 (process 23071) exited with code 0145]\r\n```\r\nThis assert https://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L462-L467 in `abort_selection` caused the panic.  It assumes that if the reader sees DISCONNECTED(which means all senders are dropped), the signal token (`to_wake`) must has been cleared by the destructor. Which is not true, for in `drop_chan`(destructor of sender side), the `to_wake` was cleared after cnt was set to DISCONNECTED,\r\nhttps://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L375-L383\r\nif the reader's load of cnt and to_wake come after L375, but finish before L377, the reader's assertion won't hold.\r\n## fix\r\nThe fix would be simply remove this assertion. Since once the cnt switch to DISCONNECTED(means all sender are dropped), the recv operation  afterwards will not wait for sender anymore, reader doesn't need to worry about the sender wakeup a mismatched signal token like when reader discoverd that cnt >=0. \r\nhttps://github.com/rust-lang/rust/blob/293b8f2c11cbec03f0d4daae6b82ed7541ebbf4e/library/std/src/sync/mpsc/shared.rs#L470-L475\r\n\r\n# note\r\nFor the mpsc's stream mode's code is basically the same as shared mode, the stream mode suffers from these problems too.\r\n\r\nrust version: `rustc 1.58.1 (db9d1b20b 2022-01-20)`", "closed_by": {"login": "tmiasko", "id": 51362316, "node_id": "MDQ6VXNlcjUxMzYyMzE2", "avatar_url": "https://avatars.githubusercontent.com/u/51362316?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmiasko", "html_url": "https://github.com/tmiasko", "followers_url": "https://api.github.com/users/tmiasko/followers", "following_url": "https://api.github.com/users/tmiasko/following{/other_user}", "gists_url": "https://api.github.com/users/tmiasko/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmiasko/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmiasko/subscriptions", "organizations_url": "https://api.github.com/users/tmiasko/orgs", "repos_url": "https://api.github.com/users/tmiasko/repos", "events_url": "https://api.github.com/users/tmiasko/events{/privacy}", "received_events_url": "https://api.github.com/users/tmiasko/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/rust-lang/rust/issues/94518/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/rust-lang/rust/issues/94518/timeline", "performed_via_github_app": null, "state_reason": "completed"}