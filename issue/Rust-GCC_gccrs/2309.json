{"url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309", "repository_url": "https://api.github.com/repos/Rust-GCC/gccrs", "labels_url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309/labels{/name}", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309/comments", "events_url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309/events", "html_url": "https://github.com/Rust-GCC/gccrs/issues/2309", "id": 1762550895, "node_id": "I_kwDOANBUbM5pDmRv", "number": 2309, "title": "Refactoring lexer to treat all characters as UTF-8", "user": {"login": "tamaroning", "id": 20992019, "node_id": "MDQ6VXNlcjIwOTkyMDE5", "avatar_url": "https://avatars.githubusercontent.com/u/20992019?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tamaroning", "html_url": "https://github.com/tamaroning", "followers_url": "https://api.github.com/users/tamaroning/followers", "following_url": "https://api.github.com/users/tamaroning/following{/other_user}", "gists_url": "https://api.github.com/users/tamaroning/gists{/gist_id}", "starred_url": "https://api.github.com/users/tamaroning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tamaroning/subscriptions", "organizations_url": "https://api.github.com/users/tamaroning/orgs", "repos_url": "https://api.github.com/users/tamaroning/repos", "events_url": "https://api.github.com/users/tamaroning/events{/privacy}", "received_events_url": "https://api.github.com/users/tamaroning/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2023-06-19T01:11:58Z", "updated_at": "2023-06-19T04:15:15Z", "closed_at": null, "author_association": "CONTRIBUTOR", "active_lock_reason": null, "body": "Related to https://github.com/Rust-GCC/gccrs/issues/2287\r\n\r\nThe lexer currently handles ASCII and non-ASCII characters differently, though Rust accepts UTF-8 source.\r\nThe main problem in our lexer is mix use of `skip_codepoint_input()` (1~4 byte skip) and `skip_input(int n)` (one byte skip) (also, `peek_codepont_input()` and `peek_input(int n)`) , which makes difficult to support Unicode such as identifiers, and whitespaces in our lexer simply.\r\n\r\nTo deal with this problem, we need\r\n- [ ] to modify `peek_input(int n)` and `skip_input(int n)` to return and skip a UTF-8 character,\r\n  - https://github.com/Rust-GCC/gccrs/pull/2307\r\n- [ ] to replace all use of `peek_codepoint_input()` and `skip_codepoint_input()` with `peek_input` and `skip_input` respectively,\r\n- [ ] and to check if the input source is valid as UTF-8\r\n", "closed_by": null, "reactions": {"url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/Rust-GCC/gccrs/issues/2309/timeline", "performed_via_github_app": null, "state_reason": null}