{"sha": "e228f0c16ea8c34794a6285bf57aab627c26b147", "node_id": "MDY6Q29tbWl0NzI0NzEyOmUyMjhmMGMxNmVhOGMzNDc5NGE2Mjg1YmY1N2FhYjYyN2MyNmIxNDc=", "commit": {"author": {"name": "antoyo", "email": "antoyo@users.noreply.github.com", "date": "2021-08-15T12:28:46Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-08-15T12:28:46Z"}, "message": "Cleanup (#67)", "tree": {"sha": "c6f8c6a5a180e29c5baf334a794064b83ae194e0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c6f8c6a5a180e29c5baf334a794064b83ae194e0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e228f0c16ea8c34794a6285bf57aab627c26b147", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhGQh+CRBK7hj4Ov3rIwAAHTkIALNHtKjq4vWw0LoVLcISMzVe\nDrmW40/iG2DjIEBA60zNaN8BmU300ii0KBRye8IAQp42YC4xNjpPGfpD+osCW8eo\nUUw5wbt+Rvcx4OPZLXrMFrNKY6ParrCNPXcV9nHjZ0wEzIQI9f8wwydYDkja0rnB\njrmwPgiwjrwn0r/defTooN5kk/XYnFYtOXPZ4wbN5kNci2ipfdWlDj+zN03OKPfM\nlnpZHrRNDxivAGPvBnKCm9o2S3JzXY4fK8fLCinNdmjpu8QCaAtI8LijnINxfh6I\nwUAjub77qLf7wseBj2o+mPPtWLilKnLozaeYNpI0AgyE4zBh/PlhszllveRUyjE=\n=xxkz\n-----END PGP SIGNATURE-----\n", "payload": "tree c6f8c6a5a180e29c5baf334a794064b83ae194e0\nparent 0c89065b934397b62838fe3e4ef6f6352fc52daf\nauthor antoyo <antoyo@users.noreply.github.com> 1629030526 -0400\ncommitter GitHub <noreply@github.com> 1629030526 -0400\n\nCleanup (#67)\n\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e228f0c16ea8c34794a6285bf57aab627c26b147", "html_url": "https://github.com/rust-lang/rust/commit/e228f0c16ea8c34794a6285bf57aab627c26b147", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e228f0c16ea8c34794a6285bf57aab627c26b147/comments", "author": {"login": "antoyo", "id": 584972, "node_id": "MDQ6VXNlcjU4NDk3Mg==", "avatar_url": "https://avatars.githubusercontent.com/u/584972?v=4", "gravatar_id": "", "url": "https://api.github.com/users/antoyo", "html_url": "https://github.com/antoyo", "followers_url": "https://api.github.com/users/antoyo/followers", "following_url": "https://api.github.com/users/antoyo/following{/other_user}", "gists_url": "https://api.github.com/users/antoyo/gists{/gist_id}", "starred_url": "https://api.github.com/users/antoyo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/antoyo/subscriptions", "organizations_url": "https://api.github.com/users/antoyo/orgs", "repos_url": "https://api.github.com/users/antoyo/repos", "events_url": "https://api.github.com/users/antoyo/events{/privacy}", "received_events_url": "https://api.github.com/users/antoyo/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0c89065b934397b62838fe3e4ef6f6352fc52daf", "url": "https://api.github.com/repos/rust-lang/rust/commits/0c89065b934397b62838fe3e4ef6f6352fc52daf", "html_url": "https://github.com/rust-lang/rust/commit/0c89065b934397b62838fe3e4ef6f6352fc52daf"}], "stats": {"total": 3318, "additions": 265, "deletions": 3053}, "files": [{"sha": "071e7ed1f85df465dabe68bf1ee3e0216d2f424d", "filename": "build_sysroot/prepare_sysroot_src.sh", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/build_sysroot%2Fprepare_sysroot_src.sh", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/build_sysroot%2Fprepare_sysroot_src.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/build_sysroot%2Fprepare_sysroot_src.sh?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -21,7 +21,7 @@ echo \"[GIT] add\"\n git add .\n echo \"[GIT] commit\"\n \n-# This is needed on virgin system where nothing is configured.\n+# This is needed on systems where nothing is configured.\n # git really needs something here, or it will fail.\n # Even using --author is not enough.\n git config user.email || git config user.email \"none@example.com\""}, {"sha": "bd2d915f589a0828fb13e5b777117e62f335b737", "filename": "config.sh", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/config.sh", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/config.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/config.sh?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -31,9 +31,8 @@ if [[ \"$HOST_TRIPLE\" != \"$TARGET_TRIPLE\" ]]; then\n fi\n \n export RUSTFLAGS=$linker' -Cpanic=abort -Cdebuginfo=2 -Zpanic-abort-tests -Zcodegen-backend='$(pwd)'/target/'$CHANNEL'/librustc_codegen_gcc.'$dylib_ext' --sysroot '$(pwd)'/build_sysroot/sysroot'\n-#export RUSTFLAGS=$linker' -Cpanic=abort -Cdebuginfo=2 -Zpanic-abort-tests -Zcodegen-backend='$(pwd)'/target/'$CHANNEL'/librustc_codegen_gcc.'$dylib_ext' --sysroot '$(pwd)'/build_sysroot/sysroot -Clto=fat -Cembed-bitcode=yes'\n \n-# FIXME remove once the atomic shim is gone\n+# FIXME(antoyo): remove once the atomic shim is gone\n if [[ `uname` == 'Darwin' ]]; then\n    export RUSTFLAGS=\"$RUSTFLAGS -Clink-arg=-undefined -Clink-arg=dynamic_lookup\"\n fi\n@@ -43,6 +42,3 @@ export RUSTC_LOG=warn # display metadata load errors\n \n export LD_LIBRARY_PATH=\"$(pwd)/target/out:$(pwd)/build_sysroot/sysroot/lib/rustlib/$TARGET_TRIPLE/lib:$GCC_PATH\"\n export DYLD_LIBRARY_PATH=$LD_LIBRARY_PATH\n-\n-export CG_CLIF_DISPLAY_CG_TIME=1\n-export CG_CLIF_INCR_CACHE_DISABLED=1"}, {"sha": "69d591565acfa563820ee8c822098e4742603385", "filename": "example/mini_core_hello_world.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/example%2Fmini_core_hello_world.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/example%2Fmini_core_hello_world.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/example%2Fmini_core_hello_world.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -253,7 +253,7 @@ fn main() {\n         }\n     }\n \n-    // TODO: not sure about this assert. ABC is not defined, so should it be really 0?\n+    // TODO(antoyo): to make this work, support weak linkage.\n     //unsafe { assert_eq!(ABC as usize, 0); }\n \n     &mut (|| Some(0 as *const ())) as &mut dyn FnMut() -> Option<*const ()>;"}, {"sha": "eba0eb82896004c7168823ec909530aa7967aee4", "filename": "example/std_example.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/example%2Fstd_example.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/example%2Fstd_example.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/example%2Fstd_example.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -16,7 +16,6 @@ fn main() {\n     let stderr = ::std::io::stderr();\n     let mut stderr = stderr.lock();\n \n-    // FIXME: this thread panics.\n     std::thread::spawn(move || {\n         println!(\"Hello from another thread!\");\n     });\n@@ -56,7 +55,7 @@ fn main() {\n     assert_eq!(-32768i16, (-32768i16).saturating_add(-32768));\n     assert_eq!(32767i16, 32767i16.saturating_add(1));\n \n-    /*assert_eq!(0b0000000000000000000000000010000010000000000000000000000000000000_0000000000100000000000000000000000001000000000000100000000000000u128.leading_zeros(), 26);\n+    assert_eq!(0b0000000000000000000000000010000010000000000000000000000000000000_0000000000100000000000000000000000001000000000000100000000000000u128.leading_zeros(), 26);\n     assert_eq!(0b0000000000000000000000000010000000000000000000000000000000000000_0000000000000000000000000000000000001000000000000000000010000000u128.trailing_zeros(), 7);\n \n     let _d = 0i128.checked_div(2i128);\n@@ -85,7 +84,7 @@ fn main() {\n     assert_eq!(houndred_i128 as f32, 100.0);\n     assert_eq!(houndred_i128 as f64, 100.0);\n     assert_eq!(houndred_f32 as i128, 100);\n-    assert_eq!(houndred_f64 as i128, 100);*/\n+    assert_eq!(houndred_f64 as i128, 100);\n \n     let _a = 1u32 << 2u8;\n "}, {"sha": "b3696e3cf885ef29a8cbca7e84ae3ff953fd980c", "filename": "gcc_path", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/gcc_path", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/gcc_path", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/gcc_path?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -0,0 +1 @@\n+/home/bouanto/Ordinateur/Programmation/Projets/gcc-build/build/gcc"}, {"sha": "ce428c589a478f1f6059d3a4845c21b5e407db82", "filename": "src/abi.rs", "status": "modified", "additions": 2, "deletions": 128, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fabi.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -11,8 +11,7 @@ use crate::type_of::LayoutGccExt;\n \n impl<'a, 'gcc, 'tcx> AbiBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n     fn apply_attrs_callsite(&mut self, _fn_abi: &FnAbi<'tcx, Ty<'tcx>>, _callsite: Self::Value) {\n-        // TODO\n-        //fn_abi.apply_attrs_callsite(self, callsite)\n+        // TODO(antoyo)\n     }\n \n     fn get_param(&self, index: usize) -> Self::Value {\n@@ -87,12 +86,9 @@ impl GccType for Reg {\n }\n \n pub trait FnAbiGccExt<'gcc, 'tcx> {\n-    // TODO: return a function pointer type instead?\n+    // TODO(antoyo): return a function pointer type instead?\n     fn gcc_type(&self, cx: &CodegenCx<'gcc, 'tcx>) -> (Type<'gcc>, Vec<Type<'gcc>>, bool);\n     fn ptr_to_gcc_type(&self, cx: &CodegenCx<'gcc, 'tcx>) -> Type<'gcc>;\n-    /*fn llvm_cconv(&self) -> llvm::CallConv;\n-    fn apply_attrs_llfn(&self, cx: &CodegenCx<'ll, 'tcx>, llfn: &'ll Value);\n-    fn apply_attrs_callsite(&self, bx: &mut Builder<'a, 'll, 'tcx>, callsite: &'ll Value);*/\n }\n \n impl<'gcc, 'tcx> FnAbiGccExt<'gcc, 'tcx> for FnAbi<'tcx, Ty<'tcx>> {\n@@ -145,12 +141,7 @@ impl<'gcc, 'tcx> FnAbiGccExt<'gcc, 'tcx> for FnAbi<'tcx, Ty<'tcx>> {\n                     continue;\n                 }\n                 PassMode::Indirect { extra_attrs: Some(_), .. } => {\n-                    /*let ptr_ty = cx.tcx.mk_mut_ptr(arg.layout.ty);\n-                    let ptr_layout = cx.layout_of(ptr_ty);\n-                    argument_tys.push(ptr_layout.scalar_pair_element_gcc_type(cx, 0, true));\n-                    argument_tys.push(ptr_layout.scalar_pair_element_gcc_type(cx, 1, true));*/\n                     unimplemented!();\n-                    //continue;\n                 }\n                 PassMode::Cast(cast) => cast.gcc_type(cx),\n                 PassMode::Indirect { extra_attrs: None, .. } => cx.type_ptr_to(arg.memory_ty(cx)),\n@@ -166,121 +157,4 @@ impl<'gcc, 'tcx> FnAbiGccExt<'gcc, 'tcx> for FnAbi<'tcx, Ty<'tcx>> {\n         let pointer_type = cx.context.new_function_pointer_type(None, return_type, &params, variadic);\n         pointer_type\n     }\n-\n-    /*fn llvm_cconv(&self) -> llvm::CallConv {\n-        match self.conv {\n-            Conv::C | Conv::Rust => llvm::CCallConv,\n-            Conv::AmdGpuKernel => llvm::AmdGpuKernel,\n-            Conv::ArmAapcs => llvm::ArmAapcsCallConv,\n-            Conv::Msp430Intr => llvm::Msp430Intr,\n-            Conv::PtxKernel => llvm::PtxKernel,\n-            Conv::X86Fastcall => llvm::X86FastcallCallConv,\n-            Conv::X86Intr => llvm::X86_Intr,\n-            Conv::X86Stdcall => llvm::X86StdcallCallConv,\n-            Conv::X86ThisCall => llvm::X86_ThisCall,\n-            Conv::X86VectorCall => llvm::X86_VectorCall,\n-            Conv::X86_64SysV => llvm::X86_64_SysV,\n-            Conv::X86_64Win64 => llvm::X86_64_Win64,\n-        }\n-    }\n-\n-    fn apply_attrs_llfn(&self, cx: &CodegenCx<'ll, 'tcx>, llfn: &'ll Value) {\n-        // FIXME(eddyb) can this also be applied to callsites?\n-        if self.ret.layout.abi.is_uninhabited() {\n-            llvm::Attribute::NoReturn.apply_llfn(llvm::AttributePlace::Function, llfn);\n-        }\n-\n-        // FIXME(eddyb, wesleywiser): apply this to callsites as well?\n-        if !self.can_unwind {\n-            llvm::Attribute::NoUnwind.apply_llfn(llvm::AttributePlace::Function, llfn);\n-        }\n-\n-        let mut i = 0;\n-        let mut apply = |attrs: &ArgAttributes, ty: Option<&Type>| {\n-            attrs.apply_llfn(llvm::AttributePlace::Argument(i), llfn, ty);\n-            i += 1;\n-        };\n-        match self.ret.mode {\n-            PassMode::Direct(ref attrs) => {\n-                attrs.apply_llfn(llvm::AttributePlace::ReturnValue, llfn, None);\n-            }\n-            PassMode::Indirect(ref attrs, _) => apply(attrs, Some(self.ret.layout.gcc_type(cx))),\n-            _ => {}\n-        }\n-        for arg in &self.args {\n-            if arg.pad.is_some() {\n-                apply(&ArgAttributes::new(), None);\n-            }\n-            match arg.mode {\n-                PassMode::Ignore => {}\n-                PassMode::Direct(ref attrs) | PassMode::Indirect(ref attrs, None) => {\n-                    apply(attrs, Some(arg.layout.gcc_type(cx)))\n-                }\n-                PassMode::Indirect(ref attrs, Some(ref extra_attrs)) => {\n-                    apply(attrs, None);\n-                    apply(extra_attrs, None);\n-                }\n-                PassMode::Pair(ref a, ref b) => {\n-                    apply(a, None);\n-                    apply(b, None);\n-                }\n-                PassMode::Cast(_) => apply(&ArgAttributes::new(), None),\n-            }\n-        }\n-    }\n-\n-    fn apply_attrs_callsite(&self, bx: &mut Builder<'a, 'll, 'tcx>, callsite: &'ll Value) {\n-        // FIXME(wesleywiser, eddyb): We should apply `nounwind` and `noreturn` as appropriate to this callsite.\n-\n-        let mut i = 0;\n-        let mut apply = |attrs: &ArgAttributes, ty: Option<&Type>| {\n-            attrs.apply_callsite(llvm::AttributePlace::Argument(i), callsite, ty);\n-            i += 1;\n-        };\n-        match self.ret.mode {\n-            PassMode::Direct(ref attrs) => {\n-                attrs.apply_callsite(llvm::AttributePlace::ReturnValue, callsite, None);\n-            }\n-            PassMode::Indirect(ref attrs, _) => apply(attrs, Some(self.ret.layout.gcc_type(bx))),\n-            _ => {}\n-        }\n-        if let abi::Abi::Scalar(ref scalar) = self.ret.layout.abi {\n-            // If the value is a boolean, the range is 0..2 and that ultimately\n-            // become 0..0 when the type becomes i1, which would be rejected\n-            // by the LLVM verifier.\n-            if let Int(..) = scalar.value {\n-                if !scalar.is_bool() {\n-                    let range = scalar.valid_range_exclusive(bx);\n-                    if range.start != range.end {\n-                        bx.range_metadata(callsite, range);\n-                    }\n-                }\n-            }\n-        }\n-        for arg in &self.args {\n-            if arg.pad.is_some() {\n-                apply(&ArgAttributes::new(), None);\n-            }\n-            match arg.mode {\n-                PassMode::Ignore => {}\n-                PassMode::Direct(ref attrs) | PassMode::Indirect(ref attrs, None) => {\n-                    apply(attrs, Some(arg.layout.gcc_type(bx)))\n-                }\n-                PassMode::Indirect(ref attrs, Some(ref extra_attrs)) => {\n-                    apply(attrs, None);\n-                    apply(extra_attrs, None);\n-                }\n-                PassMode::Pair(ref a, ref b) => {\n-                    apply(a, None);\n-                    apply(b, None);\n-                }\n-                PassMode::Cast(_) => apply(&ArgAttributes::new(), None),\n-            }\n-        }\n-\n-        let cconv = self.llvm_cconv();\n-        if cconv != llvm::CCallConv {\n-            llvm::SetInstructionCallConv(callsite, cconv);\n-        }\n-    }*/\n }"}, {"sha": "4e622efcaa0baefbac06673e155d12f5483c7113", "filename": "src/allocator.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fallocator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fallocator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fallocator.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -1,4 +1,3 @@\n-//use crate::attributes;\n use gccjit::{FunctionType, ToRValue};\n use rustc_ast::expand::allocator::{AllocatorKind, AllocatorTy, ALLOCATOR_METHODS};\n use rustc_middle::bug;\n@@ -50,19 +49,18 @@ pub(crate) unsafe fn codegen(tcx: TyCtxt<'_>, mods: &mut GccContext, kind: Alloc\n         let func = context.new_function(None, FunctionType::Exported, output.unwrap_or(void), &args, name, false);\n \n         if tcx.sess.target.options.default_hidden_visibility {\n-            //llvm::LLVMRustSetVisibility(func, llvm::Visibility::Hidden);\n+            // TODO(antoyo): set visibility.\n         }\n         if tcx.sess.must_emit_unwind_tables() {\n-            // TODO\n-            //attributes::emit_uwtable(func, true);\n+            // TODO(antoyo): emit unwind tables.\n         }\n \n         let callee = kind.fn_name(method.name);\n         let args: Vec<_> = types.iter().enumerate()\n             .map(|(index, typ)| context.new_parameter(None, *typ, &format!(\"param{}\", index)))\n             .collect();\n         let callee = context.new_function(None, FunctionType::Extern, output.unwrap_or(void), &args, callee, false);\n-        //llvm::LLVMRustSetVisibility(callee, llvm::Visibility::Hidden);\n+        // TODO(antoyo): set visibility.\n \n         let block = func.new_block(\"entry\");\n "}, {"sha": "e4d57c39de48af670fd153f6394e7041dc9d22b0", "filename": "src/asm.rs", "status": "modified", "additions": 12, "deletions": 188, "changes": 200, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fasm.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -15,106 +15,8 @@ use crate::type_of::LayoutGccExt;\n \n impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n     fn codegen_llvm_inline_asm(&mut self, _ia: &LlvmInlineAsmInner, _outputs: Vec<PlaceRef<'tcx, RValue<'gcc>>>, mut _inputs: Vec<RValue<'gcc>>, _span: Span) -> bool {\n-        // TODO\n+        // TODO(antoyo)\n         return true;\n-\n-        /*let mut ext_constraints = vec![];\n-        let mut output_types = vec![];\n-\n-        // Prepare the output operands\n-        let mut indirect_outputs = vec![];\n-        for (i, (out, &place)) in ia.outputs.iter().zip(&outputs).enumerate() {\n-            if out.is_rw {\n-                let operand = self.load_operand(place);\n-                if let OperandValue::Immediate(_) = operand.val {\n-                    inputs.push(operand.immediate());\n-                }\n-                ext_constraints.push(i.to_string());\n-            }\n-            if out.is_indirect {\n-                let operand = self.load_operand(place);\n-                if let OperandValue::Immediate(_) = operand.val {\n-                    indirect_outputs.push(operand.immediate());\n-                }\n-            } else {\n-                output_types.push(place.layout.gcc_type(self.cx()));\n-            }\n-        }\n-        if !indirect_outputs.is_empty() {\n-            indirect_outputs.extend_from_slice(&inputs);\n-            inputs = indirect_outputs;\n-        }\n-\n-        let clobbers = ia.clobbers.iter().map(|s| format!(\"~{{{}}}\", &s));\n-\n-        // Default per-arch clobbers\n-        // Basically what clang does\n-        let arch_clobbers = match &self.sess().target.target.arch[..] {\n-            \"x86\" | \"x86_64\" => vec![\"~{dirflag}\", \"~{fpsr}\", \"~{flags}\"],\n-            \"mips\" | \"mips64\" => vec![\"~{$1}\"],\n-            _ => Vec::new(),\n-        };\n-\n-        let all_constraints = ia\n-            .outputs\n-            .iter()\n-            .map(|out| out.constraint.to_string())\n-            .chain(ia.inputs.iter().map(|s| s.to_string()))\n-            .chain(ext_constraints)\n-            .chain(clobbers)\n-            .chain(arch_clobbers.iter().map(|s| (*s).to_string()))\n-            .collect::<Vec<String>>()\n-            .join(\",\");\n-\n-        debug!(\"Asm Constraints: {}\", &all_constraints);\n-\n-        // Depending on how many outputs we have, the return type is different\n-        let num_outputs = output_types.len();\n-        let output_type = match num_outputs {\n-            0 => self.type_void(),\n-            1 => output_types[0],\n-            _ => self.type_struct(&output_types, false),\n-        };\n-\n-        let asm = ia.asm.as_str();\n-        let r = inline_asm_call(\n-            self,\n-            &asm,\n-            &all_constraints,\n-            &inputs,\n-            output_type,\n-            ia.volatile,\n-            ia.alignstack,\n-            ia.dialect,\n-        );\n-        if r.is_none() {\n-            return false;\n-        }\n-        let r = r.unwrap();\n-\n-        // Again, based on how many outputs we have\n-        let outputs = ia.outputs.iter().zip(&outputs).filter(|&(ref o, _)| !o.is_indirect);\n-        for (i, (_, &place)) in outputs.enumerate() {\n-            let v = if num_outputs == 1 { r } else { self.extract_value(r, i as u64) };\n-            OperandValue::Immediate(v).store(self, place);\n-        }\n-\n-        // Store mark in a metadata node so we can map LLVM errors\n-        // back to source locations.  See #17552.\n-        unsafe {\n-            let key = \"srcloc\";\n-            let kind = llvm::LLVMGetMDKindIDInContext(\n-                self.llcx,\n-                key.as_ptr() as *const c_char,\n-                key.len() as c_uint,\n-            );\n-\n-            let val: &'ll Value = self.const_i32(span.ctxt().outer_expn().as_u32() as i32);\n-\n-            llvm::LLVMSetMetadata(r, kind, llvm::LLVMMDNodeInContext(self.llcx, &val, 1));\n-        }\n-\n-        true*/\n     }\n \n     fn codegen_inline_asm(&mut self, template: &[InlineAsmTemplatePiece], operands: &[InlineAsmOperandRef<'tcx, Self>], options: InlineAsmOptions, _span: &[Span]) {\n@@ -127,7 +29,7 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n             };\n \n         // Collect the types of output operands\n-        // FIXME: we do this here instead of later because of a bug in libgccjit where creating the\n+        // FIXME(antoyo): we do this here instead of later because of a bug in libgccjit where creating the\n         // variable after the extended asm expression causes a segfault:\n         // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=100380\n         let mut output_vars = FxHashMap::default();\n@@ -160,11 +62,6 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                         match out_place {\n                             Some(place) => place.layout.gcc_type(self.cx, false),\n                             None => {\n-                                // If the output is discarded, we don't really care what\n-                                // type is used. We're just using this to tell GCC to\n-                                // reserve the register.\n-                                //dummy_output_type(self.cx, reg.reg_class())\n-\n                                 // NOTE: if no output value, we should not create one.\n                                 continue;\n                             },\n@@ -251,9 +148,9 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                 template_str\n             }\n             else {\n-                // FIXME: this might break the \"m\" memory constraint:\n+                // FIXME(antoyo): this might break the \"m\" memory constraint:\n                 // https://stackoverflow.com/a/9347957/389119\n-                // TODO: only set on x86 platforms.\n+                // TODO(antoyo): only set on x86 platforms.\n                 format!(\".att_syntax noprefix\\n\\t{}\\n\\t.intel_syntax noprefix\", template_str)\n             };\n         let extended_asm = block.add_extended_asm(None, &template_str);\n@@ -274,7 +171,6 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                             },\n                         };\n                     output_types.push(ty);\n-                    //op_idx.insert(idx, constraints.len());\n                     let prefix = if late { \"=\" } else { \"=&\" };\n                     let constraint = format!(\"{}{}\", prefix, reg_to_gcc(reg));\n \n@@ -295,14 +191,13 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                             None => dummy_output_type(self.cx, reg.reg_class())\n                         };\n                     output_types.push(ty);\n-                    //op_idx.insert(idx, constraints.len());\n-                    // TODO: prefix of \"+\" for reading and writing?\n+                    // TODO(antoyo): prefix of \"+\" for reading and writing?\n                     let prefix = if late { \"=\" } else { \"=&\" };\n                     let constraint = format!(\"{}{}\", prefix, reg_to_gcc(reg));\n \n                     if out_place.is_some() {\n                         let var = output_vars[&idx];\n-                        // TODO: also specify an output operand when out_place is none: that would\n+                        // TODO(antoyo): also specify an output operand when out_place is none: that would\n                         // be the clobber but clobbers do not support general constraint like reg;\n                         // they only support named registers.\n                         // Not sure how we can do this. And the LLVM backend does not seem to add a\n@@ -321,63 +216,6 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n             }\n         }\n \n-        /*if !options.contains(InlineAsmOptions::PRESERVES_FLAGS) {\n-            match asm_arch {\n-                InlineAsmArch::AArch64 | InlineAsmArch::Arm => {\n-                    constraints.push(\"~{cc}\".to_string());\n-                }\n-                InlineAsmArch::X86 | InlineAsmArch::X86_64 => {\n-                    constraints.extend_from_slice(&[\n-                        \"~{dirflag}\".to_string(),\n-                        \"~{fpsr}\".to_string(),\n-                        \"~{flags}\".to_string(),\n-                    ]);\n-                }\n-                InlineAsmArch::RiscV32 | InlineAsmArch::RiscV64 => {}\n-            }\n-        }\n-        if !options.contains(InlineAsmOptions::NOMEM) {\n-            // This is actually ignored by LLVM, but it's probably best to keep\n-            // it just in case. LLVM instead uses the ReadOnly/ReadNone\n-            // attributes on the call instruction to optimize.\n-            constraints.push(\"~{memory}\".to_string());\n-        }\n-        let volatile = !options.contains(InlineAsmOptions::PURE);\n-        let alignstack = !options.contains(InlineAsmOptions::NOSTACK);\n-        let output_type = match &output_types[..] {\n-            [] => self.type_void(),\n-            [ty] => ty,\n-            tys => self.type_struct(&tys, false),\n-        };*/\n-\n-        /*let result = inline_asm_call(\n-            self,\n-            &template_str,\n-            &constraints.join(\",\"),\n-            &inputs,\n-            output_type,\n-            volatile,\n-            alignstack,\n-            dialect,\n-            span,\n-        )\n-        .unwrap_or_else(|| span_bug!(span, \"LLVM asm constraint validation failed\"));\n-\n-        if options.contains(InlineAsmOptions::PURE) {\n-            if options.contains(InlineAsmOptions::NOMEM) {\n-                llvm::Attribute::ReadNone.apply_callsite(llvm::AttributePlace::Function, result);\n-            } else if options.contains(InlineAsmOptions::READONLY) {\n-                llvm::Attribute::ReadOnly.apply_callsite(llvm::AttributePlace::Function, result);\n-            }\n-        } else {\n-            if options.contains(InlineAsmOptions::NOMEM) {\n-                llvm::Attribute::InaccessibleMemOnly\n-                    .apply_callsite(llvm::AttributePlace::Function, result);\n-            } else {\n-                // LLVM doesn't have an attribute to represent ReadOnly + SideEffect\n-            }\n-        }*/\n-\n         // Write results to outputs\n         for (idx, op) in operands.iter().enumerate() {\n             if let InlineAsmOperandRef::Out { place: Some(place), .. }\n@@ -390,12 +228,12 @@ impl<'a, 'gcc, 'tcx> AsmBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n }\n \n /// Converts a register class to a GCC constraint code.\n-// TODO: return &'static str instead?\n+// TODO(antoyo): return &'static str instead?\n fn reg_to_gcc(reg: InlineAsmRegOrRegClass) -> String {\n     match reg {\n         // For vector registers LLVM wants the register name to match the type size.\n         InlineAsmRegOrRegClass::Reg(reg) => {\n-            // TODO: add support for vector register.\n+            // TODO(antoyo): add support for vector register.\n             let constraint =\n                 match reg.name() {\n                     \"ax\" => \"a\",\n@@ -404,11 +242,11 @@ fn reg_to_gcc(reg: InlineAsmRegOrRegClass) -> String {\n                     \"dx\" => \"d\",\n                     \"si\" => \"S\",\n                     \"di\" => \"D\",\n-                    // TODO: for registers like r11, we have to create a register variable: https://stackoverflow.com/a/31774784/389119\n-                    // TODO: in this case though, it's a clobber, so it should work as r11.\n+                    // TODO(antoyo): for registers like r11, we have to create a register variable: https://stackoverflow.com/a/31774784/389119\n+                    // TODO(antoyo): in this case though, it's a clobber, so it should work as r11.\n                     // Recent nightly supports clobber() syntax, so update to it. It does not seem\n                     // like it's implemented yet.\n-                    name => name, // FIXME: probably wrong.\n+                    name => name, // FIXME(antoyo): probably wrong.\n                 };\n             constraint.to_string()\n         },\n@@ -570,7 +408,6 @@ fn modifier_to_gcc(arch: InlineAsmArch, reg: InlineAsmRegClass, modifier: Option\n         InlineAsmRegClass::AArch64(AArch64InlineAsmRegClass::vreg)\n         | InlineAsmRegClass::AArch64(AArch64InlineAsmRegClass::vreg_low16) => {\n             unimplemented!()\n-            //if modifier == Some('v') { None } else { modifier }\n         }\n         InlineAsmRegClass::Arm(ArmInlineAsmRegClass::reg)\n         | InlineAsmRegClass::Arm(ArmInlineAsmRegClass::reg_thumb) => unimplemented!(),\n@@ -583,11 +420,6 @@ fn modifier_to_gcc(arch: InlineAsmArch, reg: InlineAsmRegClass, modifier: Option\n         | InlineAsmRegClass::Arm(ArmInlineAsmRegClass::qreg_low8)\n         | InlineAsmRegClass::Arm(ArmInlineAsmRegClass::qreg_low4) => {\n             unimplemented!()\n-            /*if modifier.is_none() {\n-                Some('q')\n-            } else {\n-                modifier\n-            }*/\n         }\n         InlineAsmRegClass::Bpf(_) => unimplemented!(),\n         InlineAsmRegClass::Hexagon(_) => unimplemented!(),\n@@ -612,15 +444,7 @@ fn modifier_to_gcc(arch: InlineAsmArch, reg: InlineAsmRegClass, modifier: Option\n         InlineAsmRegClass::X86(X86InlineAsmRegClass::reg_byte) => unimplemented!(),\n         InlineAsmRegClass::X86(X86InlineAsmRegClass::xmm_reg)\n         | InlineAsmRegClass::X86(X86InlineAsmRegClass::ymm_reg)\n-        | InlineAsmRegClass::X86(X86InlineAsmRegClass::zmm_reg) => unimplemented!() /*match (reg, modifier) {\n-            (X86InlineAsmRegClass::xmm_reg, None) => Some('x'),\n-            (X86InlineAsmRegClass::ymm_reg, None) => Some('t'),\n-            (X86InlineAsmRegClass::zmm_reg, None) => Some('g'),\n-            (_, Some('x')) => Some('x'),\n-            (_, Some('y')) => Some('t'),\n-            (_, Some('z')) => Some('g'),\n-            _ => unreachable!(),\n-        }*/,\n+        | InlineAsmRegClass::X86(X86InlineAsmRegClass::zmm_reg) => unimplemented!(),\n         InlineAsmRegClass::X86(X86InlineAsmRegClass::x87_reg) => unimplemented!(),\n         InlineAsmRegClass::X86(X86InlineAsmRegClass::kreg) => unimplemented!(),\n         InlineAsmRegClass::Wasm(WasmInlineAsmRegClass::local) => unimplemented!(),"}, {"sha": "c3e3847823d918a59ddaced2a4da539c5210959b", "filename": "src/back/write.rs", "status": "modified", "additions": 16, "deletions": 172, "changes": 188, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fback%2Fwrite.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -15,132 +15,18 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<GccCodegenBackend>, _diag_han\n     {\n         let context = &module.module_llvm.context;\n \n-        //let llcx = &*module.module_llvm.llcx;\n-        //let tm = &*module.module_llvm.tm;\n         let module_name = module.name.clone();\n         let module_name = Some(&module_name[..]);\n-        //let handlers = DiagnosticHandlers::new(cgcx, diag_handler, llcx);\n-\n-        /*if cgcx.msvc_imps_needed {\n-            create_msvc_imps(cgcx, llcx, llmod);\n-        }*/\n-\n-        // A codegen-specific pass manager is used to generate object\n-        // files for an GCC module.\n-        //\n-        // Apparently each of these pass managers is a one-shot kind of\n-        // thing, so we create a new one for each type of output. The\n-        // pass manager passed to the closure should be ensured to not\n-        // escape the closure itself, and the manager should only be\n-        // used once.\n-        /*unsafe fn with_codegen<'ll, F, R>(tm: &'ll llvm::TargetMachine, llmod: &'ll llvm::Module, no_builtins: bool, f: F) -> R\n-        where F: FnOnce(&'ll mut PassManager<'ll>) -> R,\n-        {\n-            let cpm = llvm::LLVMCreatePassManager();\n-            llvm::LLVMAddAnalysisPasses(tm, cpm);\n-            llvm::LLVMRustAddLibraryInfo(cpm, llmod, no_builtins);\n-            f(cpm)\n-        }*/\n-\n-        // Two things to note:\n-        // - If object files are just LLVM bitcode we write bitcode, copy it to\n-        //   the .o file, and delete the bitcode if it wasn't otherwise\n-        //   requested.\n-        // - If we don't have the integrated assembler then we need to emit\n-        //   asm from LLVM and use `gcc` to create the object file.\n \n         let _bc_out = cgcx.output_filenames.temp_path(OutputType::Bitcode, module_name);\n         let obj_out = cgcx.output_filenames.temp_path(OutputType::Object, module_name);\n \n         if config.bitcode_needed() {\n-            // TODO\n-            /*let _timer = cgcx\n-                .prof\n-                .generic_activity_with_arg(\"LLVM_module_codegen_make_bitcode\", &module.name[..]);\n-            let thin = ThinBuffer::new(llmod);\n-            let data = thin.data();\n-\n-            if config.emit_bc || config.emit_obj == EmitObj::Bitcode {\n-                let _timer = cgcx.prof.generic_activity_with_arg(\n-                    \"LLVM_module_codegen_emit_bitcode\",\n-                    &module.name[..],\n-                );\n-                if let Err(e) = fs::write(&bc_out, data) {\n-                    let msg = format!(\"failed to write bytecode to {}: {}\", bc_out.display(), e);\n-                    diag_handler.err(&msg);\n-                }\n-            }\n-\n-            if config.emit_obj == EmitObj::ObjectCode(BitcodeSection::Full) {\n-                let _timer = cgcx.prof.generic_activity_with_arg(\n-                    \"LLVM_module_codegen_embed_bitcode\",\n-                    &module.name[..],\n-                );\n-                embed_bitcode(cgcx, llcx, llmod, Some(data));\n-            }\n-\n-            if config.emit_bc_compressed {\n-                let _timer = cgcx.prof.generic_activity_with_arg(\n-                    \"LLVM_module_codegen_emit_compressed_bitcode\",\n-                    &module.name[..],\n-                );\n-                let dst = bc_out.with_extension(RLIB_BYTECODE_EXTENSION);\n-                let data = bytecode::encode(&module.name, data);\n-                if let Err(e) = fs::write(&dst, data) {\n-                    let msg = format!(\"failed to write bytecode to {}: {}\", dst.display(), e);\n-                    diag_handler.err(&msg);\n-                }\n-            }*/\n-        } /*else if config.emit_obj == EmitObj::ObjectCode(BitcodeSection::Marker) {\n-            unimplemented!();\n-            //embed_bitcode(cgcx, llcx, llmod, None);\n-        }*/\n+            // TODO(antoyo)\n+        }\n \n         if config.emit_ir {\n             unimplemented!();\n-            /*let _timer = cgcx\n-                .prof\n-                .generic_activity_with_arg(\"LLVM_module_codegen_emit_ir\", &module.name[..]);\n-            let out = cgcx.output_filenames.temp_path(OutputType::LlvmAssembly, module_name);\n-            let out_c = path_to_c_string(&out);\n-\n-            extern \"C\" fn demangle_callback(\n-                input_ptr: *const c_char,\n-                input_len: size_t,\n-                output_ptr: *mut c_char,\n-                output_len: size_t,\n-            ) -> size_t {\n-                let input =\n-                    unsafe { slice::from_raw_parts(input_ptr as *const u8, input_len as usize) };\n-\n-                let input = match str::from_utf8(input) {\n-                    Ok(s) => s,\n-                    Err(_) => return 0,\n-                };\n-\n-                let output = unsafe {\n-                    slice::from_raw_parts_mut(output_ptr as *mut u8, output_len as usize)\n-                };\n-                let mut cursor = io::Cursor::new(output);\n-\n-                let demangled = match rustc_demangle::try_demangle(input) {\n-                    Ok(d) => d,\n-                    Err(_) => return 0,\n-                };\n-\n-                if write!(cursor, \"{:#}\", demangled).is_err() {\n-                    // Possible only if provided buffer is not big enough\n-                    return 0;\n-                }\n-\n-                cursor.position() as size_t\n-            }\n-\n-            let result = llvm::LLVMRustPrintModule(llmod, out_c.as_ptr(), demangle_callback);\n-            result.into_result().map_err(|()| {\n-                let msg = format!(\"failed to write LLVM IR to {}\", out.display());\n-                llvm_err(diag_handler, &msg)\n-            })?;*/\n         }\n \n         if config.emit_asm {\n@@ -149,58 +35,34 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<GccCodegenBackend>, _diag_han\n                 .generic_activity_with_arg(\"LLVM_module_codegen_emit_asm\", &module.name[..]);\n             let path = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n             context.compile_to_file(OutputKind::Assembler, path.to_str().expect(\"path to str\"));\n-\n-            /*with_codegen(tm, llmod, config.no_builtins, |cpm| {\n-                write_output_file(diag_handler, tm, cpm, llmod, &path, llvm::FileType::AssemblyFile)\n-            })?;*/\n         }\n \n         match config.emit_obj {\n             EmitObj::ObjectCode(_) => {\n                 let _timer = cgcx\n                     .prof\n                     .generic_activity_with_arg(\"LLVM_module_codegen_emit_obj\", &module.name[..]);\n-                //with_codegen(tm, llmod, config.no_builtins, |cpm| {\n-                    //println!(\"1: {}\", module.name);\n-                    match &*module.name {\n-                        \"std_example.7rcbfp3g-cgu.15\" => {\n-                            println!(\"Dumping reproducer {}\", module.name);\n-                            let _ = fs::create_dir(\"/tmp/reproducers\");\n-                            // FIXME: segfault in dump_reproducer_to_file() might be caused by\n-                            // transmuting an rvalue to an lvalue.\n-                            // Segfault is actually in gcc::jit::reproducer::get_identifier_as_lvalue\n-                            context.dump_reproducer_to_file(&format!(\"/tmp/reproducers/{}.c\", module.name));\n-                            println!(\"Dumped reproducer {}\", module.name);\n-                        },\n-                        _ => (),\n-                    }\n-                    /*let _ = fs::create_dir(\"/tmp/dumps\");\n-                    context.dump_to_file(&format!(\"/tmp/dumps/{}.c\", module.name), true);\n-                    println!(\"Dumped {}\", module.name);*/\n-                    //println!(\"Compile module {}\", module.name);\n-                    context.compile_to_file(OutputKind::ObjectFile, obj_out.to_str().expect(\"path to str\"));\n-                //})?;\n+                match &*module.name {\n+                    \"std_example.7rcbfp3g-cgu.15\" => {\n+                        println!(\"Dumping reproducer {}\", module.name);\n+                        let _ = fs::create_dir(\"/tmp/reproducers\");\n+                        // FIXME(antoyo): segfault in dump_reproducer_to_file() might be caused by\n+                        // transmuting an rvalue to an lvalue.\n+                        // Segfault is actually in gcc::jit::reproducer::get_identifier_as_lvalue\n+                        context.dump_reproducer_to_file(&format!(\"/tmp/reproducers/{}.c\", module.name));\n+                        println!(\"Dumped reproducer {}\", module.name);\n+                    },\n+                    _ => (),\n+                }\n+                context.compile_to_file(OutputKind::ObjectFile, obj_out.to_str().expect(\"path to str\"));\n             }\n \n             EmitObj::Bitcode => {\n-                //unimplemented!();\n-                /*debug!(\"copying bitcode {:?} to obj {:?}\", bc_out, obj_out);\n-                if let Err(e) = link_or_copy(&bc_out, &obj_out) {\n-                    diag_handler.err(&format!(\"failed to copy bitcode to object file: {}\", e));\n-                }\n-\n-                if !config.emit_bc {\n-                    debug!(\"removing_bitcode {:?}\", bc_out);\n-                    if let Err(e) = fs::remove_file(&bc_out) {\n-                        diag_handler.err(&format!(\"failed to remove bitcode: {}\", e));\n-                    }\n-                }*/\n+                // TODO(antoyo)\n             }\n \n             EmitObj::None => {}\n         }\n-\n-        //drop(handlers);\n     }\n \n     Ok(module.into_compiled_module(\n@@ -213,22 +75,4 @@ pub(crate) unsafe fn codegen(cgcx: &CodegenContext<GccCodegenBackend>, _diag_han\n \n pub(crate) fn link(_cgcx: &CodegenContext<GccCodegenBackend>, _diag_handler: &Handler, mut _modules: Vec<ModuleCodegen<GccContext>>) -> Result<ModuleCodegen<GccContext>, FatalError> {\n     unimplemented!();\n-    /*use super::lto::{Linker, ModuleBuffer};\n-    // Sort the modules by name to ensure to ensure deterministic behavior.\n-    modules.sort_by(|a, b| a.name.cmp(&b.name));\n-    let (first, elements) =\n-        modules.split_first().expect(\"Bug! modules must contain at least one module.\");\n-\n-    let mut linker = Linker::new(first.module_llvm.llmod());\n-    for module in elements {\n-        let _timer =\n-            cgcx.prof.generic_activity_with_arg(\"LLVM_link_module\", format!(\"{:?}\", module.name));\n-        let buffer = ModuleBuffer::new(module.module_llvm.llmod());\n-        linker.add(&buffer.data()).map_err(|()| {\n-            let msg = format!(\"failed to serialize module {:?}\", module.name);\n-            llvm_err(&diag_handler, &msg)\n-        })?;\n-    }\n-    drop(linker);\n-    Ok(modules.remove(0))*/\n }"}, {"sha": "2963a3d49a20ef740c2f9197cf555845bbc06f9e", "filename": "src/base.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbase.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -35,7 +35,7 @@ pub fn global_linkage_to_gcc(linkage: Linkage) -> GlobalKind {\n         Linkage::Appending => unimplemented!(),\n         Linkage::Internal => GlobalKind::Internal,\n         Linkage::Private => GlobalKind::Internal,\n-        Linkage::ExternalWeak => GlobalKind::Imported, // TODO: should be weak linkage.\n+        Linkage::ExternalWeak => GlobalKind::Imported, // TODO(antoyo): should be weak linkage.\n         Linkage::Common => unimplemented!(),\n     }\n }\n@@ -46,7 +46,7 @@ pub fn linkage_to_gcc(linkage: Linkage) -> FunctionType {\n         Linkage::AvailableExternally => FunctionType::Extern,\n         Linkage::LinkOnceAny => unimplemented!(),\n         Linkage::LinkOnceODR => unimplemented!(),\n-        Linkage::WeakAny => FunctionType::Exported, // FIXME: should be similar to linkonce.\n+        Linkage::WeakAny => FunctionType::Exported, // FIXME(antoyo): should be similar to linkonce.\n         Linkage::WeakODR => unimplemented!(),\n         Linkage::Appending => unimplemented!(),\n         Linkage::Internal => FunctionType::Internal,\n@@ -74,19 +74,25 @@ pub fn compile_codegen_unit<'tcx>(tcx: TyCtxt<'tcx>, cgu_name: Symbol) -> (Modul\n         // Instantiate monomorphizations without filling out definitions yet...\n         //let llvm_module = ModuleLlvm::new(tcx, &cgu_name.as_str());\n         let context = Context::default();\n-        // TODO: only set on x86 platforms.\n+        // TODO(antoyo): only set on x86 platforms.\n         context.add_command_line_option(\"-masm=intel\");\n         for arg in &tcx.sess.opts.cg.llvm_args {\n             context.add_command_line_option(arg);\n         }\n         context.add_command_line_option(\"-fno-semantic-interposition\");\n-        //context.set_dump_code_on_compile(true);\n+        if env::var(\"CG_GCCJIT_DUMP_CODE\").as_deref() == Ok(\"1\") {\n+            context.set_dump_code_on_compile(true);\n+        }\n         if env::var(\"CG_GCCJIT_DUMP_GIMPLE\").as_deref() == Ok(\"1\") {\n             context.set_dump_initial_gimple(true);\n         }\n         context.set_debug_info(true);\n-        //context.set_dump_everything(true);\n-        //context.set_keep_intermediates(true);\n+        if env::var(\"CG_GCCJIT_DUMP_EVERYTHING\").as_deref() == Ok(\"1\") {\n+            context.set_dump_everything(true);\n+        }\n+        if env::var(\"CG_GCCJIT_KEEP_INTERMEDIATES\").as_deref() == Ok(\"1\") {\n+            context.set_keep_intermediates(true);\n+        }\n \n         {\n             let cx = CodegenCx::new(&context, cgu, tcx);\n@@ -100,7 +106,6 @@ pub fn compile_codegen_unit<'tcx>(tcx: TyCtxt<'tcx>, cgu_name: Symbol) -> (Modul\n                 block.end_with_void_return(None);\n             });\n \n-            //println!(\"module_codegen: {:?} {:?}\", cgu_name, &cx.context as *const _);\n             let mono_items = cgu.items_in_deterministic_order(tcx);\n             for &(mono_item, (linkage, visibility)) in &mono_items {\n                 mono_item.predefine::<Builder<'_, '_, '_>>(&cx, linkage, visibility);"}, {"sha": "0f7db911552a17cd5fd529ee7389222f832bbdd7", "filename": "src/builder.rs", "status": "modified", "additions": 79, "deletions": 392, "changes": 471, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbuilder.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -48,10 +48,10 @@ use crate::common::{SignType, TypeReflection, type_is_pointer};\n use crate::context::CodegenCx;\n use crate::type_of::LayoutGccExt;\n \n-// TODO\n+// TODO(antoyo)\n type Funclet = ();\n \n-// TODO: remove this variable.\n+// TODO(antoyo): remove this variable.\n static mut RETURN_VALUE_COUNT: usize = 0;\n \n enum ExtremumOperation {\n@@ -99,7 +99,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n \n         let load_ordering =\n             match order {\n-                // TODO: does this make sense?\n+                // TODO(antoyo): does this make sense?\n                 AtomicOrdering::AcquireRelease | AtomicOrdering::Release => AtomicOrdering::Acquire,\n                 _ => order.clone(),\n             };\n@@ -162,26 +162,6 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn check_call<'b>(&mut self, _typ: &str, func: Function<'gcc>, args: &'b [RValue<'gcc>]) -> Cow<'b, [RValue<'gcc>]> {\n-        //let mut fn_ty = self.cx.val_ty(func);\n-        // Strip off pointers\n-        /*while self.cx.type_kind(fn_ty) == TypeKind::Pointer {\n-            fn_ty = self.cx.element_type(fn_ty);\n-        }*/\n-\n-        /*assert!(\n-            self.cx.type_kind(fn_ty) == TypeKind::Function,\n-            \"builder::{} not passed a function, but {:?}\",\n-            typ,\n-            fn_ty\n-        );\n-\n-        let param_tys = self.cx.func_params_types(fn_ty);\n-\n-        let all_args_match = param_tys\n-            .iter()\n-            .zip(args.iter().map(|&v| self.val_ty(v)))\n-            .all(|(expected_ty, actual_ty)| *expected_ty == actual_ty);*/\n-\n         let mut all_args_match = true;\n         let mut param_types = vec![];\n         let param_count = func.get_param_count();\n@@ -205,16 +185,6 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n             .map(|(_i, (expected_ty, &actual_val))| {\n                 let actual_ty = actual_val.get_type();\n                 if expected_ty != actual_ty {\n-                    /*debug!(\n-                        \"type mismatch in function call of {:?}. \\\n-                            Expected {:?} for param {}, got {:?}; injecting bitcast\",\n-                        func, expected_ty, i, actual_ty\n-                    );*/\n-                    /*println!(\n-                        \"type mismatch in function call of {:?}. \\\n-                            Expected {:?} for param {}, got {:?}; injecting bitcast\",\n-                        func, expected_ty, i, actual_ty\n-                    );*/\n                     self.bitcast(actual_val, expected_ty)\n                 }\n                 else {\n@@ -227,26 +197,6 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn check_ptr_call<'b>(&mut self, _typ: &str, func_ptr: RValue<'gcc>, args: &'b [RValue<'gcc>]) -> Cow<'b, [RValue<'gcc>]> {\n-        //let mut fn_ty = self.cx.val_ty(func);\n-        // Strip off pointers\n-        /*while self.cx.type_kind(fn_ty) == TypeKind::Pointer {\n-            fn_ty = self.cx.element_type(fn_ty);\n-        }*/\n-\n-        /*assert!(\n-            self.cx.type_kind(fn_ty) == TypeKind::Function,\n-            \"builder::{} not passed a function, but {:?}\",\n-            typ,\n-            fn_ty\n-        );\n-\n-        let param_tys = self.cx.func_params_types(fn_ty);\n-\n-        let all_args_match = param_tys\n-            .iter()\n-            .zip(args.iter().map(|&v| self.val_ty(v)))\n-            .all(|(expected_ty, actual_ty)| *expected_ty == actual_ty);*/\n-\n         let mut all_args_match = true;\n         let mut param_types = vec![];\n         let gcc_func = func_ptr.get_type().is_function_ptr_type().expect(\"function ptr\");\n@@ -269,16 +219,6 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n             .map(|(_i, (expected_ty, &actual_val))| {\n                 let actual_ty = actual_val.get_type();\n                 if expected_ty != actual_ty {\n-                    /*debug!(\n-                        \"type mismatch in function call of {:?}. \\\n-                            Expected {:?} for param {}, got {:?}; injecting bitcast\",\n-                        func, expected_ty, i, actual_ty\n-                    );*/\n-                    /*println!(\n-                        \"type mismatch in function call of {:?}. \\\n-                            Expected {:?} for param {}, got {:?}; injecting bitcast\",\n-                        func, expected_ty, i, actual_ty\n-                    );*/\n                     self.bitcast(actual_val, expected_ty)\n                 }\n                 else {\n@@ -291,27 +231,14 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn check_store(&mut self, val: RValue<'gcc>, ptr: RValue<'gcc>) -> RValue<'gcc> {\n-        let dest_ptr_ty = self.cx.val_ty(ptr).make_pointer(); // TODO: make sure make_pointer() is okay here.\n+        let dest_ptr_ty = self.cx.val_ty(ptr).make_pointer(); // TODO(antoyo): make sure make_pointer() is okay here.\n         let stored_ty = self.cx.val_ty(val);\n         let stored_ptr_ty = self.cx.type_ptr_to(stored_ty);\n \n-        //assert_eq!(self.cx.type_kind(dest_ptr_ty), TypeKind::Pointer);\n-\n         if dest_ptr_ty == stored_ptr_ty {\n             ptr\n         }\n         else {\n-            /*debug!(\n-                \"type mismatch in store. \\\n-                    Expected {:?}, got {:?}; inserting bitcast\",\n-                dest_ptr_ty, stored_ptr_ty\n-            );*/\n-            /*println!(\n-                \"type mismatch in store. \\\n-                    Expected {:?}, got {:?}; inserting bitcast\",\n-                dest_ptr_ty, stored_ptr_ty\n-            );*/\n-            //ptr\n             self.bitcast(ptr, stored_ptr_ty)\n         }\n     }\n@@ -321,13 +248,9 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn function_call(&mut self, func: RValue<'gcc>, args: &[RValue<'gcc>], _funclet: Option<&Funclet>) -> RValue<'gcc> {\n-        //debug!(\"call {:?} with args ({:?})\", func, args);\n-\n-        // TODO: remove when the API supports a different type for functions.\n+        // TODO(antoyo): remove when the API supports a different type for functions.\n         let func: Function<'gcc> = self.cx.rvalue_as_function(func);\n         let args = self.check_call(\"call\", func, args);\n-        //let bundle = funclet.map(|funclet| funclet.bundle());\n-        //let bundle = bundle.as_ref().map(|b| &*b.raw);\n \n         // gccjit requires to use the result of functions, even when it's not used.\n         // That's why we assign the result to a local or call add_eval().\n@@ -349,11 +272,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn function_ptr_call(&mut self, func_ptr: RValue<'gcc>, args: &[RValue<'gcc>], _funclet: Option<&Funclet>) -> RValue<'gcc> {\n-        //debug!(\"func ptr call {:?} with args ({:?})\", func, args);\n-\n         let args = self.check_ptr_call(\"call\", func_ptr, args);\n-        //let bundle = funclet.map(|funclet| funclet.bundle());\n-        //let bundle = bundle.as_ref().map(|b| &*b.raw);\n \n         // gccjit requires to use the result of functions, even when it's not used.\n         // That's why we assign the result to a local or call add_eval().\n@@ -363,7 +282,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n         let void_type = self.context.new_type::<()>();\n         let current_func = current_block.get_function();\n \n-        // FIXME: As a temporary workaround for unsupported LLVM intrinsics.\n+        // FIXME(antoyo): As a temporary workaround for unsupported LLVM intrinsics.\n         if gcc_func.get_param_count() == 0 && format!(\"{:?}\", func_ptr) == \"__builtin_ia32_pmovmskb128\" {\n             return_type = self.int_type;\n         }\n@@ -376,7 +295,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n         }\n         else {\n             if gcc_func.get_param_count() == 0 {\n-                // FIXME: As a temporary workaround for unsupported LLVM intrinsics.\n+                // FIXME(antoyo): As a temporary workaround for unsupported LLVM intrinsics.\n                 current_block.add_eval(None, self.cx.context.new_call_through_ptr(None, func_ptr, &[]));\n             }\n             else {\n@@ -390,17 +309,12 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     pub fn overflow_call(&mut self, func: Function<'gcc>, args: &[RValue<'gcc>], _funclet: Option<&Funclet>) -> RValue<'gcc> {\n-        //debug!(\"overflow_call {:?} with args ({:?})\", func, args);\n-\n-        //let bundle = funclet.map(|funclet| funclet.bundle());\n-        //let bundle = bundle.as_ref().map(|b| &*b.raw);\n-\n         // gccjit requires to use the result of functions, even when it's not used.\n         // That's why we assign the result to a local.\n         let return_type = self.context.new_type::<bool>();\n         let current_block = self.current_block.borrow().expect(\"block\");\n         let current_func = current_block.get_function();\n-        // TODO: return the new_call() directly? Since the overflow function has no side-effects.\n+        // TODO(antoyo): return the new_call() directly? Since the overflow function has no side-effects.\n         unsafe { RETURN_VALUE_COUNT += 1 };\n         let result = current_func.new_local(None, return_type, &format!(\"returnValue{}\", unsafe { RETURN_VALUE_COUNT }));\n         current_block.add_assignment(None, result, self.cx.context.new_call(None, func, &args));\n@@ -520,25 +434,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         self.llbb().end_with_conditional(None, condition, then, catch);\n         self.context.new_rvalue_from_int(self.int_type, 0)\n \n-        // TODO\n-        /*debug!(\"invoke {:?} with args ({:?})\", func, args);\n-\n-        let args = self.check_call(\"invoke\", func, args);\n-        let bundle = funclet.map(|funclet| funclet.bundle());\n-        let bundle = bundle.as_ref().map(|b| &*b.raw);\n-\n-        unsafe {\n-            llvm::LLVMRustBuildInvoke(\n-                self.llbuilder,\n-                func,\n-                args.as_ptr(),\n-                args.len() as c_uint,\n-                then,\n-                catch,\n-                bundle,\n-                UNNAMED,\n-            )\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn unreachable(&mut self) {\n@@ -558,7 +454,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn add(&mut self, a: RValue<'gcc>, mut b: RValue<'gcc>) -> RValue<'gcc> {\n-        // FIXME: this should not be required.\n+        // FIXME(antoyo): this should not be required.\n         if format!(\"{:?}\", a.get_type()) != format!(\"{:?}\", b.get_type()) {\n             b = self.context.new_cast(None, b, a.get_type());\n         }\n@@ -589,24 +485,24 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn udiv(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: convert the arguments to unsigned?\n+        // TODO(antoyo): convert the arguments to unsigned?\n         a / b\n     }\n \n     fn exactudiv(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: convert the arguments to unsigned?\n-        // TODO: poison if not exact.\n+        // TODO(antoyo): convert the arguments to unsigned?\n+        // TODO(antoyo): poison if not exact.\n         a / b\n     }\n \n     fn sdiv(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: convert the arguments to signed?\n+        // TODO(antoyo): convert the arguments to signed?\n         a / b\n     }\n \n     fn exactsdiv(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: posion if not exact.\n-        // FIXME: rustc_codegen_ssa::mir::intrinsic uses different types for a and b but they\n+        // TODO(antoyo): posion if not exact.\n+        // FIXME(antoyo): rustc_codegen_ssa::mir::intrinsic uses different types for a and b but they\n         // should be the same.\n         let typ = a.get_type().to_signed(self);\n         let a = self.context.new_cast(None, a, typ);\n@@ -629,7 +525,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     fn frem(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n         if a.get_type() == self.cx.float_type {\n             let fmodf = self.context.get_builtin_function(\"fmodf\");\n-            // FIXME: this seems to produce the wrong result.\n+            // FIXME(antoyo): this seems to produce the wrong result.\n             return self.context.new_call(None, fmodf, &[a, b]);\n         }\n         assert_eq!(a.get_type(), self.cx.double_type);\n@@ -639,18 +535,15 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn shl(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // FIXME: remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n+        // FIXME(antoyo): remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n         let a_type = a.get_type();\n         let b_type = b.get_type();\n         if a_type.is_unsigned(self) && b_type.is_signed(self) {\n-            //println!(\"shl: {:?} -> {:?}\", a, b_type);\n             let a = self.context.new_cast(None, a, b_type);\n             let result = a << b;\n-            //println!(\"shl: {:?} -> {:?}\", result, a_type);\n             self.context.new_cast(None, result, a_type)\n         }\n         else if a_type.is_signed(self) && b_type.is_unsigned(self) {\n-            //println!(\"shl: {:?} -> {:?}\", b, a_type);\n             let b = self.context.new_cast(None, b, a_type);\n             a << b\n         }\n@@ -660,19 +553,16 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn lshr(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // FIXME: remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n-        // TODO: cast to unsigned to do a logical shift if that does not work.\n+        // FIXME(antoyo): remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n+        // TODO(antoyo): cast to unsigned to do a logical shift if that does not work.\n         let a_type = a.get_type();\n         let b_type = b.get_type();\n         if a_type.is_unsigned(self) && b_type.is_signed(self) {\n-            //println!(\"lshl: {:?} -> {:?}\", a, b_type);\n             let a = self.context.new_cast(None, a, b_type);\n             let result = a >> b;\n-            //println!(\"lshl: {:?} -> {:?}\", result, a_type);\n             self.context.new_cast(None, result, a_type)\n         }\n         else if a_type.is_signed(self) && b_type.is_unsigned(self) {\n-            //println!(\"lshl: {:?} -> {:?}\", b, a_type);\n             let b = self.context.new_cast(None, b, a_type);\n             a >> b\n         }\n@@ -682,19 +572,16 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn ashr(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: check whether behavior is an arithmetic shift for >> .\n-        // FIXME: remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n+        // TODO(antoyo): check whether behavior is an arithmetic shift for >> .\n+        // FIXME(antoyo): remove the casts when libgccjit can shift an unsigned number by an unsigned number.\n         let a_type = a.get_type();\n         let b_type = b.get_type();\n         if a_type.is_unsigned(self) && b_type.is_signed(self) {\n-            //println!(\"ashl: {:?} -> {:?}\", a, b_type);\n             let a = self.context.new_cast(None, a, b_type);\n             let result = a >> b;\n-            //println!(\"ashl: {:?} -> {:?}\", result, a_type);\n             self.context.new_cast(None, result, a_type)\n         }\n         else if a_type.is_signed(self) && b_type.is_unsigned(self) {\n-            //println!(\"ashl: {:?} -> {:?}\", b, a_type);\n             let b = self.context.new_cast(None, b, a_type);\n             a >> b\n         }\n@@ -704,7 +591,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn and(&mut self, a: RValue<'gcc>, mut b: RValue<'gcc>) -> RValue<'gcc> {\n-        // FIXME: hack by putting the result in a variable to workaround this bug:\n+        // FIXME(antoyo): hack by putting the result in a variable to workaround this bug:\n         // https://gcc.gnu.org/bugzilla//show_bug.cgi?id=95498\n         if a.get_type() != b.get_type() {\n             b = self.context.new_cast(None, b, a.get_type());\n@@ -715,7 +602,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn or(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // FIXME: hack by putting the result in a variable to workaround this bug:\n+        // FIXME(antoyo): hack by putting the result in a variable to workaround this bug:\n         // https://gcc.gnu.org/bugzilla//show_bug.cgi?id=95498\n         let res = self.current_func().new_local(None, b.get_type(), \"orResult\");\n         self.llbb().add_assignment(None, res, a | b);\n@@ -727,7 +614,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn neg(&mut self, a: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: use new_unary_op()?\n+        // TODO(antoyo): use new_unary_op()?\n         self.cx.context.new_rvalue_from_long(a.get_type(), 0) - a\n     }\n \n@@ -759,7 +646,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn unchecked_usub(&mut self, a: RValue<'gcc>, b: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: should generate poison value?\n+        // TODO(antoyo): should generate poison value?\n         a - b\n     }\n \n@@ -773,47 +660,22 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n     fn fadd_fast(&mut self, _lhs: RValue<'gcc>, _rhs: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let instr = llvm::LLVMBuildFAdd(self.llbuilder, lhs, rhs, UNNAMED);\n-            llvm::LLVMRustSetHasUnsafeAlgebra(instr);\n-            instr\n-        }*/\n     }\n \n     fn fsub_fast(&mut self, _lhs: RValue<'gcc>, _rhs: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let instr = llvm::LLVMBuildFSub(self.llbuilder, lhs, rhs, UNNAMED);\n-            llvm::LLVMRustSetHasUnsafeAlgebra(instr);\n-            instr\n-        }*/\n     }\n \n     fn fmul_fast(&mut self, _lhs: RValue<'gcc>, _rhs: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let instr = llvm::LLVMBuildFMul(self.llbuilder, lhs, rhs, UNNAMED);\n-            llvm::LLVMRustSetHasUnsafeAlgebra(instr);\n-            instr\n-        }*/\n     }\n \n     fn fdiv_fast(&mut self, _lhs: RValue<'gcc>, _rhs: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let instr = llvm::LLVMBuildFDiv(self.llbuilder, lhs, rhs, UNNAMED);\n-            llvm::LLVMRustSetHasUnsafeAlgebra(instr);\n-            instr\n-        }*/\n     }\n \n     fn frem_fast(&mut self, _lhs: RValue<'gcc>, _rhs: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let instr = llvm::LLVMBuildFRem(self.llbuilder, lhs, rhs, UNNAMED);\n-            llvm::LLVMRustSetHasUnsafeAlgebra(instr);\n-            instr\n-        }*/\n     }\n \n     fn checked_binop(&mut self, oop: OverflowOp, typ: Ty<'_>, lhs: Self::Value, rhs: Self::Value) -> (Self::Value, Self::Value) {\n@@ -827,7 +689,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n                 _ => panic!(\"tried to get overflow intrinsic for op applied to non-int type\"),\n             };\n \n-        // TODO: remove duplication with intrinsic?\n+        // TODO(antoyo): remove duplication with intrinsic?\n         let name =\n             match oop {\n                 OverflowOp::Add =>\n@@ -882,15 +744,15 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n         let intrinsic = self.context.get_builtin_function(&name);\n         let res = self.current_func()\n-            // TODO: is it correct to use rhs type instead of the parameter typ?\n+            // TODO(antoyo): is it correct to use rhs type instead of the parameter typ?\n             .new_local(None, rhs.get_type(), \"binopResult\")\n             .get_address(None);\n         let overflow = self.overflow_call(intrinsic, &[lhs, rhs, res], None);\n         (res.dereference(None).to_rvalue(), overflow)\n     }\n \n     fn alloca(&mut self, ty: Type<'gcc>, align: Align) -> RValue<'gcc> {\n-        // FIXME: this check that we don't call get_aligned() a second time on a time.\n+        // FIXME(antoyo): this check that we don't call get_aligned() a second time on a type.\n         // Ideally, we shouldn't need to do this check.\n         let aligned_type =\n             if ty == self.cx.u128_type || ty == self.cx.i128_type {\n@@ -899,37 +761,27 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n             else {\n                 ty.get_aligned(align.bytes())\n             };\n-        // TODO: It might be better to return a LValue, but fixing the rustc API is non-trivial.\n+        // TODO(antoyo): It might be better to return a LValue, but fixing the rustc API is non-trivial.\n         self.stack_var_count.set(self.stack_var_count.get() + 1);\n         self.current_func().new_local(None, aligned_type, &format!(\"stack_var_{}\", self.stack_var_count.get())).get_address(None)\n     }\n \n     fn dynamic_alloca(&mut self, _ty: Type<'gcc>, _align: Align) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let alloca = llvm::LLVMBuildAlloca(self.llbuilder, ty, UNNAMED);\n-            llvm::LLVMSetAlignment(alloca, align.bytes() as c_uint);\n-            alloca\n-        }*/\n     }\n \n     fn array_alloca(&mut self, _ty: Type<'gcc>, _len: RValue<'gcc>, _align: Align) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let alloca = llvm::LLVMBuildArrayAlloca(self.llbuilder, ty, len, UNNAMED);\n-            llvm::LLVMSetAlignment(alloca, align.bytes() as c_uint);\n-            alloca\n-        }*/\n     }\n \n     fn load(&mut self, _ty: Type<'gcc>, ptr: RValue<'gcc>, _align: Align) -> RValue<'gcc> {\n-        // TODO: use ty.\n+        // TODO(antoyo): use ty.\n         let block = self.llbb();\n         let function = block.get_function();\n         // NOTE: instead of returning the dereference here, we have to assign it to a variable in\n         // the current basic block. Otherwise, it could be used in another basic block, causing a\n         // dereference after a drop, for instance.\n-        // TODO: handle align.\n+        // TODO(antoyo): handle align.\n         let deref = ptr.dereference(None).to_rvalue();\n         let value_type = deref.get_type();\n         unsafe { RETURN_VALUE_COUNT += 1 };\n@@ -939,16 +791,14 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn volatile_load(&mut self, _ty: Type<'gcc>, ptr: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: use ty.\n-        //println!(\"5: volatile load: {:?} to {:?}\", ptr, ptr.get_type().make_volatile());\n+        // TODO(antoyo): use ty.\n         let ptr = self.context.new_cast(None, ptr, ptr.get_type().make_volatile());\n-        //println!(\"6\");\n         ptr.dereference(None).to_rvalue()\n     }\n \n     fn atomic_load(&mut self, _ty: Type<'gcc>, ptr: RValue<'gcc>, order: AtomicOrdering, size: Size) -> RValue<'gcc> {\n-        // TODO: use ty.\n-        // TODO: handle alignment.\n+        // TODO(antoyo): use ty.\n+        // TODO(antoyo): handle alignment.\n         let atomic_load = self.context.get_builtin_function(&format!(\"__atomic_load_{}\", size.bytes()));\n         let ordering = self.context.new_rvalue_from_int(self.i32_type, order.to_gcc());\n \n@@ -958,8 +808,6 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn load_operand(&mut self, place: PlaceRef<'tcx, RValue<'gcc>>) -> OperandRef<'tcx, RValue<'gcc>> {\n-        //debug!(\"PlaceRef::load: {:?}\", place);\n-\n         assert_eq!(place.llextra.is_some(), place.layout.is_unsized());\n \n         if place.layout.is_zst() {\n@@ -987,22 +835,11 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n                 OperandValue::Ref(place.llval, Some(llextra), place.align)\n             }\n             else if place.layout.is_gcc_immediate() {\n-                let const_llval = None;\n-                /*unsafe {\n-                    if let Some(global) = llvm::LLVMIsAGlobalVariable(place.llval) {\n-                        if llvm::LLVMIsGlobalConstant(global) == llvm::True {\n-                            const_llval = llvm::LLVMGetInitializer(global);\n-                        }\n-                    }\n-                }*/\n-                let llval = const_llval.unwrap_or_else(|| {\n-                    let load = self.load(place.llval.get_type(), place.llval, place.align);\n-                    if let abi::Abi::Scalar(ref scalar) = place.layout.abi {\n-                        scalar_load_metadata(self, load, scalar);\n-                    }\n-                    load\n-                });\n-                OperandValue::Immediate(self.to_immediate(llval, place.layout))\n+                let load = self.load(place.llval.get_type(), place.llval, place.align);\n+                if let abi::Abi::Scalar(ref scalar) = place.layout.abi {\n+                    scalar_load_metadata(self, load, scalar);\n+                }\n+                OperandValue::Immediate(self.to_immediate(load, place.layout))\n             }\n             else if let abi::Abi::ScalarPair(ref a, ref b) = place.layout.abi {\n                 let b_offset = a.value.size(self).align_to(b.value.align(self).abi);\n@@ -1058,76 +895,33 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn range_metadata(&mut self, _load: RValue<'gcc>, _range: Range<u128>) {\n-        // TODO\n-        /*if self.sess().target.target.arch == \"amdgpu\" {\n-            // amdgpu/LLVM does something weird and thinks a i64 value is\n-            // split into a v2i32, halving the bitwidth LLVM expects,\n-            // tripping an assertion. So, for now, just disable this\n-            // optimization.\n-            return;\n-        }\n-\n-        unsafe {\n-            let llty = self.cx.val_ty(load);\n-            let v = [\n-                self.cx.const_uint_big(llty, range.start),\n-                self.cx.const_uint_big(llty, range.end),\n-            ];\n-\n-            llvm::LLVMSetMetadata(\n-                load,\n-                llvm::MD_range as c_uint,\n-                llvm::LLVMMDNodeInContext(self.cx.llcx, v.as_ptr(), v.len() as c_uint),\n-            );\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn nonnull_metadata(&mut self, _load: RValue<'gcc>) {\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMSetMetadata(\n-                load,\n-                llvm::MD_nonnull as c_uint,\n-                llvm::LLVMMDNodeInContext(self.cx.llcx, ptr::null(), 0),\n-            );\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn store(&mut self, val: RValue<'gcc>, ptr: RValue<'gcc>, align: Align) -> RValue<'gcc> {\n         self.store_with_flags(val, ptr, align, MemFlags::empty())\n     }\n \n     fn store_with_flags(&mut self, val: RValue<'gcc>, ptr: RValue<'gcc>, _align: Align, _flags: MemFlags) -> RValue<'gcc> {\n-        //debug!(\"Store {:?} -> {:?} ({:?})\", val, ptr, flags);\n         let ptr = self.check_store(val, ptr);\n         self.llbb().add_assignment(None, ptr.dereference(None), val);\n-        /*let align =\n-            if flags.contains(MemFlags::UNALIGNED) { 1 } else { align.bytes() as c_uint };\n-        llvm::LLVMSetAlignment(store, align);\n-        if flags.contains(MemFlags::VOLATILE) {\n-            llvm::LLVMSetVolatile(store, llvm::True);\n-        }\n-        if flags.contains(MemFlags::NONTEMPORAL) {\n-            // According to LLVM [1] building a nontemporal store must\n-            // *always* point to a metadata value of the integer 1.\n-            //\n-            // [1]: http://llvm.org/docs/LangRef.html#store-instruction\n-            let one = self.cx.const_i32(1);\n-            let node = llvm::LLVMMDNodeInContext(self.cx.llcx, &one, 1);\n-            llvm::LLVMSetMetadata(store, llvm::MD_nontemporal as c_uint, node);\n-        }*/\n-        // NOTE: dummy value here since it's never used. FIXME: API should not return a value here?\n+        // TODO(antoyo): handle align and flags.\n+        // NOTE: dummy value here since it's never used. FIXME(antoyo): API should not return a value here?\n         self.cx.context.new_rvalue_zero(self.type_i32())\n     }\n \n     fn atomic_store(&mut self, value: RValue<'gcc>, ptr: RValue<'gcc>, order: AtomicOrdering, size: Size) {\n-        // TODO: handle alignment.\n+        // TODO(antoyo): handle alignment.\n         let atomic_store = self.context.get_builtin_function(&format!(\"__atomic_store_{}\", size.bytes()));\n         let ordering = self.context.new_rvalue_from_int(self.i32_type, order.to_gcc());\n         let volatile_const_void_ptr_type = self.context.new_type::<*mut ()>().make_const().make_volatile();\n         let ptr = self.context.new_cast(None, ptr, volatile_const_void_ptr_type);\n \n-        // FIXME: fix libgccjit to allow comparing an integer type with an aligned integer type because\n+        // FIXME(antoyo): fix libgccjit to allow comparing an integer type with an aligned integer type because\n         // the following cast is required to avoid this error:\n         // gcc_jit_context_new_call: mismatching types for argument 2 of function \"__atomic_store_4\": assignment to param arg1 (type: int) from loadedValue3577 (type: unsigned int  __attribute__((aligned(4))))\n         let int_type = atomic_store.get_param(1).to_rvalue().get_type();\n@@ -1145,22 +939,22 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn inbounds_gep(&mut self, _typ: Type<'gcc>, ptr: RValue<'gcc>, indices: &[RValue<'gcc>]) -> RValue<'gcc> {\n-        // FIXME: would be safer if doing the same thing (loop) as gep.\n-        // TODO: specify inbounds somehow.\n+        // FIXME(antoyo): would be safer if doing the same thing (loop) as gep.\n+        // TODO(antoyo): specify inbounds somehow.\n         match indices.len() {\n             1 => {\n                 self.context.new_array_access(None, ptr, indices[0]).get_address(None)\n             },\n             2 => {\n-                let array = ptr.dereference(None); // TODO: assert that first index is 0?\n+                let array = ptr.dereference(None); // TODO(antoyo): assert that first index is 0?\n                 self.context.new_array_access(None, array, indices[1]).get_address(None)\n             },\n             _ => unimplemented!(),\n         }\n     }\n \n     fn struct_gep(&mut self, value_type: Type<'gcc>, ptr: RValue<'gcc>, idx: u64) -> RValue<'gcc> {\n-        // FIXME: it would be better if the API only called this on struct, not on arrays.\n+        // FIXME(antoyo): it would be better if the API only called this on struct, not on arrays.\n         assert_eq!(idx as usize as u64, idx);\n         let value = ptr.dereference(None).to_rvalue();\n \n@@ -1186,53 +980,37 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n     /* Casts */\n     fn trunc(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        // TODO: check that it indeed truncate the value.\n-        //println!(\"trunc: {:?} -> {:?}\", value, dest_ty);\n+        // TODO(antoyo): check that it indeed truncate the value.\n         self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn sext(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        // TODO: check that it indeed sign extend the value.\n-        //println!(\"Sext {:?} to {:?}\", value, dest_ty);\n-        //if let Some(vector_type) = value.get_type().is_vector() {\n+        // TODO(antoyo): check that it indeed sign extend the value.\n         if dest_ty.is_vector().is_some() {\n-            // TODO: nothing to do as it is only for LLVM?\n+            // TODO(antoyo): nothing to do as it is only for LLVM?\n             return value;\n-            /*let dest_type = self.context.new_vector_type(dest_ty, vector_type.get_num_units() as u64);\n-            println!(\"Casting {:?} to {:?}\", value, dest_type);\n-            return self.context.new_cast(None, value, dest_type);*/\n         }\n         self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn fptoui(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        //println!(\"7: fptoui: {:?} to {:?}\", value, dest_ty);\n-        let ret = self.context.new_cast(None, value, dest_ty);\n-        //println!(\"8\");\n-        ret\n-        //unsafe { llvm::LLVMBuildFPToUI(self.llbuilder, val, dest_ty, UNNAMED) }\n+        self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn fptosi(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n         self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn uitofp(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        //println!(\"1: uitofp: {:?} -> {:?}\", value, dest_ty);\n-        let ret = self.context.new_cast(None, value, dest_ty);\n-        //println!(\"2\");\n-        ret\n+        self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn sitofp(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        //println!(\"3: sitofp: {:?} -> {:?}\", value, dest_ty);\n-        let ret = self.context.new_cast(None, value, dest_ty);\n-        //println!(\"4\");\n-        ret\n+        self.context.new_cast(None, value, dest_ty)\n     }\n \n     fn fptrunc(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        // TODO: make sure it trancates.\n+        // TODO(antoyo): make sure it truncates.\n         self.context.new_cast(None, value, dest_ty)\n     }\n \n@@ -1254,12 +1032,10 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n     fn intcast(&mut self, value: RValue<'gcc>, dest_typ: Type<'gcc>, _is_signed: bool) -> RValue<'gcc> {\n         // NOTE: is_signed is for value, not dest_typ.\n-        //println!(\"intcast: {:?} ({:?}) -> {:?}\", value, value.get_type(), dest_typ);\n         self.cx.context.new_cast(None, value, dest_typ)\n     }\n \n     fn pointercast(&mut self, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        //println!(\"pointercast: {:?} ({:?}) -> {:?}\", value, value.get_type(), dest_ty);\n         let val_type = value.get_type();\n         match (type_is_pointer(val_type), type_is_pointer(dest_ty)) {\n             (false, true) => {\n@@ -1269,7 +1045,6 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n             },\n             (false, false) => {\n                 // When they are not pointers, we want a transmute (or reinterpret_cast).\n-                //self.cx.context.new_cast(None, value, dest_ty)\n                 self.bitcast(value, dest_ty)\n             },\n             (true, true) => self.cx.context.new_cast(None, value, dest_ty),\n@@ -1307,7 +1082,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         let src = self.pointercast(src, self.type_ptr_to(self.type_void()));\n         let memcpy = self.context.get_builtin_function(\"memcpy\");\n         let block = self.block.expect(\"block\");\n-        // TODO: handle aligns and is_volatile.\n+        // TODO(antoyo): handle aligns and is_volatile.\n         block.add_eval(None, self.context.new_call(None, memcpy, &[dst, src, size]));\n     }\n \n@@ -1326,7 +1101,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n         let memmove = self.context.get_builtin_function(\"memmove\");\n         let block = self.block.expect(\"block\");\n-        // TODO: handle is_volatile.\n+        // TODO(antoyo): handle is_volatile.\n         block.add_eval(None, self.context.new_call(None, memmove, &[dst, src, size]));\n     }\n \n@@ -1335,8 +1110,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         let ptr = self.pointercast(ptr, self.type_i8p());\n         let memset = self.context.get_builtin_function(\"memset\");\n         let block = self.block.expect(\"block\");\n-        // TODO: handle aligns and is_volatile.\n-        //println!(\"memset: {:?} -> {:?}\", fill_byte, self.i32_type);\n+        // TODO(antoyo): handle align and is_volatile.\n         let fill_byte = self.context.new_cast(None, fill_byte, self.i32_type);\n         let size = self.intcast(size, self.type_size_t(), false);\n         block.add_eval(None, self.context.new_call(None, memset, &[ptr, fill_byte, size]));\n@@ -1370,27 +1144,18 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     #[allow(dead_code)]\n     fn va_arg(&mut self, _list: RValue<'gcc>, _ty: Type<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        //unsafe { llvm::LLVMBuildVAArg(self.llbuilder, list, ty, UNNAMED) }\n     }\n \n     fn extract_element(&mut self, _vec: RValue<'gcc>, _idx: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        //unsafe { llvm::LLVMBuildExtractElement(self.llbuilder, vec, idx, UNNAMED) }\n     }\n \n     fn vector_splat(&mut self, _num_elts: usize, _elt: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*unsafe {\n-            let elt_ty = self.cx.val_ty(elt);\n-            let undef = llvm::LLVMGetUndef(self.type_vector(elt_ty, num_elts as u64));\n-            let vec = self.insert_element(undef, elt, self.cx.const_i32(0));\n-            let vec_i32_ty = self.type_vector(self.type_i32(), num_elts as u64);\n-            self.shuffle_vector(vec, undef, self.const_null(vec_i32_ty))\n-        }*/\n     }\n \n     fn extract_value(&mut self, aggregate_value: RValue<'gcc>, idx: u64) -> RValue<'gcc> {\n-        // FIXME: it would be better if the API only called this on struct, not on arrays.\n+        // FIXME(antoyo): it would be better if the API only called this on struct, not on arrays.\n         assert_eq!(idx as usize as u64, idx);\n         let value_type = aggregate_value.get_type();\n \n@@ -1418,12 +1183,10 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         else {\n             panic!(\"Unexpected type {:?}\", value_type);\n         }\n-        /*assert_eq!(idx as c_uint as u64, idx);\n-        unsafe { llvm::LLVMBuildExtractValue(self.llbuilder, agg_val, idx as c_uint, UNNAMED) }*/\n     }\n \n     fn insert_value(&mut self, aggregate_value: RValue<'gcc>, value: RValue<'gcc>, idx: u64) -> RValue<'gcc> {\n-        // FIXME: it would be better if the API only called this on struct, not on arrays.\n+        // FIXME(antoyo): it would be better if the API only called this on struct, not on arrays.\n         assert_eq!(idx as usize as u64, idx);\n         let value_type = aggregate_value.get_type();\n \n@@ -1459,88 +1222,41 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         let struct_type = self.context.new_struct_type(None, \"landing_pad\", &[field1, field2]);\n         self.current_func().new_local(None, struct_type.as_type(), \"landing_pad\")\n             .to_rvalue()\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMBuildLandingPad(self.llbuilder, ty, pers_fn, num_clauses as c_uint, UNNAMED)\n-        }*/\n+        // TODO(antoyo): Properly implement unwinding.\n+        // the above is just to make the compilation work as it seems\n+        // rustc_codegen_ssa now calls the unwinding builder methods even on panic=abort.\n     }\n \n     fn set_cleanup(&mut self, _landing_pad: RValue<'gcc>) {\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMSetCleanup(landing_pad, llvm::True);\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn resume(&mut self, _exn: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        //unsafe { llvm::LLVMBuildResume(self.llbuilder, exn) }\n     }\n \n     fn cleanup_pad(&mut self, _parent: Option<RValue<'gcc>>, _args: &[RValue<'gcc>]) -> Funclet {\n         unimplemented!();\n-        /*let name = const_cstr!(\"cleanuppad\");\n-        let ret = unsafe {\n-            llvm::LLVMRustBuildCleanupPad(\n-                self.llbuilder,\n-                parent,\n-                args.len() as c_uint,\n-                args.as_ptr(),\n-                name.as_ptr(),\n-            )\n-        };\n-        Funclet::new(ret.expect(\"LLVM does not have support for cleanuppad\"))*/\n     }\n \n     fn cleanup_ret(&mut self, _funclet: &Funclet, _unwind: Option<Block<'gcc>>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*let ret =\n-            unsafe { llvm::LLVMRustBuildCleanupRet(self.llbuilder, funclet.cleanuppad(), unwind) };\n-        ret.expect(\"LLVM does not have support for cleanupret\")*/\n     }\n \n     fn catch_pad(&mut self, _parent: RValue<'gcc>, _args: &[RValue<'gcc>]) -> Funclet {\n         unimplemented!();\n-        /*let name = const_cstr!(\"catchpad\");\n-        let ret = unsafe {\n-            llvm::LLVMRustBuildCatchPad(\n-                self.llbuilder,\n-                parent,\n-                args.len() as c_uint,\n-                args.as_ptr(),\n-                name.as_ptr(),\n-            )\n-        };\n-        Funclet::new(ret.expect(\"LLVM does not have support for catchpad\"))*/\n     }\n \n     fn catch_switch(&mut self, _parent: Option<RValue<'gcc>>, _unwind: Option<Block<'gcc>>, _num_handlers: usize) -> RValue<'gcc> {\n         unimplemented!();\n-        /*let name = const_cstr!(\"catchswitch\");\n-        let ret = unsafe {\n-            llvm::LLVMRustBuildCatchSwitch(\n-                self.llbuilder,\n-                parent,\n-                unwind,\n-                num_handlers as c_uint,\n-                name.as_ptr(),\n-            )\n-        };\n-        ret.expect(\"LLVM does not have support for catchswitch\")*/\n     }\n \n     fn add_handler(&mut self, _catch_switch: RValue<'gcc>, _handler: Block<'gcc>) {\n         unimplemented!();\n-        /*unsafe {\n-            llvm::LLVMRustAddHandler(catch_switch, handler);\n-        }*/\n     }\n \n     fn set_personality_fn(&mut self, _personality: RValue<'gcc>) {\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMSetPersonalityFn(self.llfn(), personality);\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     // Atomic Operations\n@@ -1551,7 +1267,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n         let pair_type = self.cx.type_struct(&[src.get_type(), self.bool_type], false);\n         let result = self.current_func().new_local(None, pair_type, \"atomic_cmpxchg_result\");\n-        let align = Align::from_bits(64).expect(\"align\"); // TODO: use good align.\n+        let align = Align::from_bits(64).expect(\"align\"); // TODO(antoyo): use good align.\n \n         let value_type = result.to_rvalue().get_type();\n         if let Some(struct_type) = value_type.is_struct() {\n@@ -1560,7 +1276,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n             // expected so that we store expected after the call.\n             self.store(expected.to_rvalue(), result.access_field(None, struct_type.get_field(0)).get_address(None), align);\n         }\n-        // TODO: handle when value is not a struct.\n+        // TODO(antoyo): handle when value is not a struct.\n \n         result.to_rvalue()\n     }\n@@ -1589,7 +1305,7 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n         let void_ptr_type = self.context.new_type::<*mut ()>();\n         let volatile_void_ptr_type = void_ptr_type.make_volatile();\n         let dst = self.context.new_cast(None, dst, volatile_void_ptr_type);\n-        // NOTE: not sure why, but we have the wrong type here.\n+        // FIXME(antoyo): not sure why, but we have the wrong type here.\n         let new_src_type = atomic_function.get_param(1).to_rvalue().get_type();\n         let src = self.context.new_cast(None, src, new_src_type);\n         let res = self.context.new_call(None, atomic_function, &[dst, src, order]);\n@@ -1610,28 +1326,19 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     fn set_invariant_load(&mut self, load: RValue<'gcc>) {\n         // NOTE: Hack to consider vtable function pointer as non-global-variable function pointer.\n         self.normal_function_addresses.borrow_mut().insert(load);\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMSetMetadata(\n-                load,\n-                llvm::MD_invariant_load as c_uint,\n-                llvm::LLVMMDNodeInContext(self.cx.llcx, ptr::null(), 0),\n-            );\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn lifetime_start(&mut self, _ptr: RValue<'gcc>, _size: Size) {\n-        // TODO\n-        //self.call_lifetime_intrinsic(\"llvm.lifetime.start.p0i8\", ptr, size);\n+        // TODO(antoyo)\n     }\n \n     fn lifetime_end(&mut self, _ptr: RValue<'gcc>, _size: Size) {\n-        // TODO\n-        //self.call_lifetime_intrinsic(\"llvm.lifetime.end.p0i8\", ptr, size);\n+        // TODO(antoyo)\n     }\n \n     fn call(&mut self, _typ: Type<'gcc>, func: RValue<'gcc>, args: &[RValue<'gcc>], funclet: Option<&Funclet>) -> RValue<'gcc> {\n-        // FIXME: remove when having a proper API.\n+        // FIXME(antoyo): remove when having a proper API.\n         let gcc_func = unsafe { std::mem::transmute(func) };\n         if self.functions.borrow().values().find(|value| **value == gcc_func).is_some() {\n             self.function_call(func, args, funclet)\n@@ -1643,13 +1350,12 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn zext(&mut self, value: RValue<'gcc>, dest_typ: Type<'gcc>) -> RValue<'gcc> {\n-        // FIXME: this does not zero-extend.\n+        // FIXME(antoyo): this does not zero-extend.\n         if value.get_type().is_bool() && dest_typ.is_i8(&self.cx) {\n-            // FIXME: hack because base::from_immediate converts i1 to i8.\n+            // FIXME(antoyo): hack because base::from_immediate converts i1 to i8.\n             // Fix the code in codegen_ssa::base::from_immediate.\n             return value;\n         }\n-        //println!(\"zext: {:?} -> {:?}\", value, dest_typ);\n         self.context.new_cast(None, value, dest_typ)\n     }\n \n@@ -1659,7 +1365,6 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n     fn do_not_inline(&mut self, _llret: RValue<'gcc>) {\n         unimplemented!();\n-        //llvm::Attribute::NoInline.apply_callsite(llvm::AttributePlace::Function, llret);\n     }\n \n     fn set_span(&mut self, _span: Span) {}\n@@ -1690,24 +1395,6 @@ impl<'a, 'gcc, 'tcx> BuilderMethods<'a, 'tcx> for Builder<'a, 'gcc, 'tcx> {\n \n     fn instrprof_increment(&mut self, _fn_name: RValue<'gcc>, _hash: RValue<'gcc>, _num_counters: RValue<'gcc>, _index: RValue<'gcc>) {\n         unimplemented!();\n-        /*debug!(\n-            \"instrprof_increment() with args ({:?}, {:?}, {:?}, {:?})\",\n-            fn_name, hash, num_counters, index\n-        );\n-\n-        let llfn = unsafe { llvm::LLVMRustGetInstrProfIncrementIntrinsic(self.cx().llmod) };\n-        let args = &[fn_name, hash, num_counters, index];\n-        let args = self.check_call(\"call\", llfn, args);\n-\n-        unsafe {\n-            let _ = llvm::LLVMRustBuildCall(\n-                self.llbuilder,\n-                llfn,\n-                args.as_ptr() as *const &llvm::Value,\n-                args.len() as c_uint,\n-                None,\n-            );\n-        }*/\n     }\n }\n \n@@ -1766,7 +1453,7 @@ impl ToGccComp for IntPredicate {\n \n impl ToGccComp for RealPredicate {\n     fn to_gcc_comparison(&self) -> ComparisonOp {\n-        // TODO: check that ordered vs non-ordered is respected.\n+        // TODO(antoyo): check that ordered vs non-ordered is respected.\n         match *self {\n             RealPredicate::RealPredicateFalse => unreachable!(),\n             RealPredicate::RealOEQ => ComparisonOp::Equals,\n@@ -1809,9 +1496,9 @@ impl ToGccOrdering for AtomicOrdering {\n \n         let ordering =\n             match self {\n-                AtomicOrdering::NotAtomic => __ATOMIC_RELAXED, // TODO: check if that's the same.\n+                AtomicOrdering::NotAtomic => __ATOMIC_RELAXED, // TODO(antoyo): check if that's the same.\n                 AtomicOrdering::Unordered => __ATOMIC_RELAXED,\n-                AtomicOrdering::Monotonic => __ATOMIC_RELAXED, // TODO: check if that's the same.\n+                AtomicOrdering::Monotonic => __ATOMIC_RELAXED, // TODO(antoyo): check if that's the same.\n                 AtomicOrdering::Acquire => __ATOMIC_ACQUIRE,\n                 AtomicOrdering::Release => __ATOMIC_RELEASE,\n                 AtomicOrdering::AcquireRelease => __ATOMIC_ACQ_REL,"}, {"sha": "4ea084ef729d31e7f8139efac8ad8450b72396c6", "filename": "src/callee.rs", "status": "modified", "additions": 2, "deletions": 22, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcallee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcallee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcallee.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -17,8 +17,6 @@ use crate::context::CodegenCx;\n pub fn get_fn<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, instance: Instance<'tcx>) -> RValue<'gcc> {\n     let tcx = cx.tcx();\n \n-    //debug!(\"get_fn(instance={:?})\", instance);\n-\n     assert!(!instance.substs.needs_infer());\n     assert!(!instance.substs.has_escaping_bound_vars());\n     assert!(!instance.substs.has_param_types_or_consts());\n@@ -28,11 +26,9 @@ pub fn get_fn<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, instance: Instance<'tcx>)\n     }\n \n     let sym = tcx.symbol_name(instance).name;\n-    //debug!(\"get_fn({:?}: {:?}) => {}\", instance, instance.monomorphic_ty(cx.tcx()), sym);\n \n     let fn_abi = FnAbi::of_instance(cx, instance, &[]);\n \n-    // TODO\n     let func =\n         if let Some(func) = cx.get_declared_value(&sym) {\n             // Create a fn pointer with the new signature.\n@@ -62,34 +58,18 @@ pub fn get_fn<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, instance: Instance<'tcx>)\n             // reference. It also occurs when testing libcore and in some\n             // other weird situations. Annoying.\n             if cx.val_ty(func) != ptrty {\n-                //debug!(\"get_fn: casting {:?} to {:?}\", func, ptrty);\n-                // TODO\n-                //cx.const_ptrcast(func, ptrty)\n+                // TODO(antoyo): cast the pointer.\n                 func\n             }\n             else {\n-                //debug!(\"get_fn: not casting pointer!\");\n                 func\n             }\n         }\n         else {\n             cx.linkage.set(FunctionType::Extern);\n             let func = cx.declare_fn(&sym, &fn_abi);\n-            //cx.linkage.set(FunctionType::Internal);\n-            //debug!(\"get_fn: not casting pointer!\");\n-\n-            // TODO\n-            //attributes::from_fn_attrs(cx, func, instance);\n-\n-            //let instance_def_id = instance.def_id();\n-\n-            // TODO\n-            /*if cx.use_dll_storage_attrs && tcx.is_dllimport_foreign_item(instance_def_id) {\n-              unsafe {\n-              llvm::LLVMSetDLLStorageClass(func, llvm::DLLStorageClass::DllImport);\n-              }\n-              }*/\n \n+            // TODO(antoyo): set linkage and attributes.\n             func\n         };\n "}, {"sha": "752ba99af9ce3630b4d4deb9c63fdc396fabbed3", "filename": "src/common.rs", "status": "modified", "additions": 11, "deletions": 24, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcommon.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -27,7 +27,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     fn const_cstr(&self, symbol: Symbol, _null_terminated: bool) -> RValue<'gcc> {\n-        // TODO: handle null_terminated.\n+        // TODO(antoyo): handle null_terminated.\n         if let Some(&value) = self.const_cstr_cache.borrow().get(&symbol) {\n             return value.to_rvalue();\n         }\n@@ -39,7 +39,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     fn global_string(&self, string: &str) -> RValue<'gcc> {\n-        // TODO: handle non-null-terminated strings.\n+        // TODO(antoyo): handle non-null-terminated strings.\n         let string = self.context.new_string_literal(&*string);\n         let sym = self.generate_local_symbol_name(\"str\");\n         // NOTE: TLS is always off for a string litteral.\n@@ -48,7 +48,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n             .unwrap_or_else(|| bug!(\"symbol `{}` is already defined\", sym));\n         self.global_init_block.add_assignment(None, global.dereference(None), string);\n         global.to_rvalue()\n-        //llvm::LLVMRustSetLinkage(global, llvm::Linkage::InternalLinkage);\n+        // TODO(antoyo): set linkage.\n     }\n \n     pub fn inttoptr(&self, block: Block<'gcc>, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n@@ -62,7 +62,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     pub fn ptrtoint(&self, block: Block<'gcc>, value: RValue<'gcc>, dest_ty: Type<'gcc>) -> RValue<'gcc> {\n-        // TODO: when libgccjit allow casting from pointer to int, remove this.\n+        // TODO(antoyo): when libgccjit allow casting from pointer to int, remove this.\n         let func = block.get_function();\n         let local = func.new_local(None, value.get_type(), \"ptrLocal\");\n         block.add_assignment(None, local, value);\n@@ -71,10 +71,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n         let ptr = self.context.new_cast(None, ptr_address, dest_ty.make_pointer());\n         ptr.dereference(None).to_rvalue()\n     }\n-\n-    /*pub fn const_vector(&self, elements: &[RValue<'gcc>]) -> RValue<'gcc> {\n-        self.context.new_rvalue_from_vector(None, elements[0].get_type(), elements)\n-    }*/\n }\n \n pub fn bytes_in_context<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, bytes: &[u8]) -> RValue<'gcc> {\n@@ -125,13 +121,13 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     fn const_uint_big(&self, typ: Type<'gcc>, num: u128) -> RValue<'gcc> {\n         let num64: Result<i64, _> = num.try_into();\n         if let Ok(num) = num64 {\n-            // FIXME: workaround for a bug where libgccjit is expecting a constant.\n+            // FIXME(antoyo): workaround for a bug where libgccjit is expecting a constant.\n             // The operations >> 64 and | low are making the normal case a non-constant.\n             return self.context.new_rvalue_from_long(typ, num as i64);\n         }\n \n         if num >> 64 != 0 {\n-            // FIXME: use a new function new_rvalue_from_unsigned_long()?\n+            // FIXME(antoyo): use a new function new_rvalue_from_unsigned_long()?\n             let low = self.context.new_rvalue_from_long(self.u64_type, num as u64 as i64);\n             let high = self.context.new_rvalue_from_long(typ, (num >> 64) as u64 as i64);\n \n@@ -175,12 +171,10 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n \n     fn const_u8(&self, _i: u8) -> RValue<'gcc> {\n         unimplemented!();\n-        //self.const_uint(self.type_i8(), i as u64)\n     }\n \n     fn const_real(&self, _t: Type<'gcc>, _val: f64) -> RValue<'gcc> {\n         unimplemented!();\n-        //unsafe { llvm::LLVMConstReal(t, val) }\n     }\n \n     fn const_str(&self, s: Symbol) -> (RValue<'gcc>, RValue<'gcc>) {\n@@ -195,7 +189,7 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n         let fields: Vec<_> = values.iter()\n             .map(|value| value.get_type())\n             .collect();\n-        // TODO: cache the type? It's anonymous, so probably not.\n+        // TODO(antoyo): cache the type? It's anonymous, so probably not.\n         let name = fields.iter().map(|typ| format!(\"{:?}\", typ)).collect::<Vec<_>>().join(\"_\");\n         let typ = self.type_struct(&fields, packed);\n         let structure = self.global_init_func.new_local(None, typ, &name);\n@@ -209,19 +203,13 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     }\n \n     fn const_to_opt_uint(&self, _v: RValue<'gcc>) -> Option<u64> {\n-        // TODO\n+        // TODO(antoyo)\n         None\n-        //try_as_const_integral(v).map(|v| unsafe { llvm::LLVMConstIntGetZExtValue(v) })\n     }\n \n     fn const_to_opt_u128(&self, _v: RValue<'gcc>, _sign_ext: bool) -> Option<u128> {\n-        // TODO\n+        // TODO(antoyo)\n         None\n-        /*try_as_const_integral(v).and_then(|v| unsafe {\n-            let (mut lo, mut hi) = (0u64, 0u64);\n-            let success = llvm::LLVMRustConstInt128Get(v, sign_ext, &mut hi, &mut lo);\n-            success.then_some(hi_lo_to_u128(lo, hi))\n-        })*/\n     }\n \n     fn scalar_to_backend(&self, cv: Scalar, layout: &abi::Scalar, ty: Type<'gcc>) -> RValue<'gcc> {\n@@ -234,7 +222,7 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n             Scalar::Int(int) => {\n                 let data = int.assert_bits(layout.value.size(self));\n \n-                // FIXME: there's some issues with using the u128 code that follows, so hard-code\n+                // FIXME(antoyo): there's some issues with using the u128 code that follows, so hard-code\n                 // the paths for floating-point values.\n                 if ty == self.float_type {\n                     return self.context.new_rvalue_from_double(ty, f32::from_bits(data as u32) as f64);\n@@ -262,8 +250,7 @@ impl<'gcc, 'tcx> ConstMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n                                     _ => self.static_addr_of(init, alloc.align, None),\n                                 };\n                             if !self.sess().fewer_names() {\n-                                // TODO\n-                                //llvm::set_value_name(value, format!(\"{:?}\", ptr.alloc_id).as_bytes());\n+                                // TODO(antoyo): set value name.\n                             }\n                             value\n                         },"}, {"sha": "9b7959503ab1b9543317da8567bdfe3fe0a8d9fc", "filename": "src/consts.rs", "status": "modified", "additions": 20, "deletions": 117, "changes": 137, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fconsts.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fconsts.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fconsts.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -32,22 +32,11 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n     fn static_addr_of(&self, cv: RValue<'gcc>, align: Align, kind: Option<&str>) -> RValue<'gcc> {\n         if let Some(global_value) = self.const_globals.borrow().get(&cv) {\n-            // TODO\n-            /*unsafe {\n-                // Upgrade the alignment in cases where the same constant is used with different\n-                // alignment requirements\n-                let llalign = align.bytes() as u32;\n-                if llalign > llvm::LLVMGetAlignment(gv) {\n-                    llvm::LLVMSetAlignment(gv, llalign);\n-                }\n-            }*/\n+            // TODO(antoyo): upgrade alignment.\n             return *global_value;\n         }\n         let global_value = self.static_addr_of_mut(cv, align, kind);\n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMSetGlobalConstant(global_value, True);\n-        }*/\n+        // TODO(antoyo): set global constant.\n         self.const_globals.borrow_mut().insert(cv, global_value);\n         global_value\n     }\n@@ -73,9 +62,7 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n         let val_llty = self.val_ty(value);\n         let value =\n             if val_llty == self.type_i1() {\n-                //val_llty = self.type_i8();\n                 unimplemented!();\n-                //llvm::LLVMConstZExt(value, val_llty)\n             }\n             else {\n                 value\n@@ -92,41 +79,32 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n             else {\n                 // If we created the global with the wrong type,\n                 // correct the type.\n-                /*let name = llvm::get_value_name(global).to_vec();\n-                llvm::set_value_name(global, b\"\");\n-\n-                let linkage = llvm::LLVMRustGetLinkage(global);\n-                let visibility = llvm::LLVMRustGetVisibility(global);*/\n+                // TODO(antoyo): set value name, linkage and visibility.\n \n                 let new_global = self.get_or_insert_global(&name, val_llty, is_tls, attrs.link_section);\n \n-                /*llvm::LLVMRustSetLinkage(new_global, linkage);\n-                  llvm::LLVMRustSetVisibility(new_global, visibility);*/\n-\n                 // To avoid breaking any invariants, we leave around the old\n                 // global for the moment; we'll replace all references to it\n                 // with the new global later. (See base::codegen_backend.)\n                 //self.statics_to_rauw.borrow_mut().push((global, new_global));\n                 new_global\n             };\n-        // TODO\n-        //set_global_alignment(&self, global, self.align_of(ty));\n-        //llvm::LLVMSetInitializer(global, value);\n+        // TODO(antoyo): set alignment and initializer.\n         let value = self.rvalue_as_lvalue(value);\n         let value = value.get_address(None);\n         let dest_typ = global.get_type();\n         let value = self.context.new_cast(None, value, dest_typ);\n \n         // NOTE: do not init the variables related to argc/argv because it seems we cannot\n         // overwrite those variables.\n-        // FIXME: correctly support global variable initialization.\n+        // FIXME(antoyo): correctly support global variable initialization.\n         let skip_init = [\n             ARGV_INIT_ARRAY,\n             ARGC,\n             ARGV,\n         ];\n         if !skip_init.iter().any(|symbol_name| name.starts_with(symbol_name)) {\n-            // TODO: switch to set_initializer when libgccjit supports that.\n+            // TODO(antoyo): switch to set_initializer when libgccjit supports that.\n             let memcpy = self.context.get_builtin_function(\"memcpy\");\n             let dst = self.context.new_cast(None, global, self.type_i8p());\n             let src = self.context.new_cast(None, value, self.type_ptr_to(self.type_void()));\n@@ -138,13 +116,10 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n         // mutability are placed into read-only memory.\n         if !is_mutable {\n             if self.type_is_freeze(ty) {\n-                // TODO\n-                //llvm::LLVMSetGlobalConstant(global, llvm::True);\n+                // TODO(antoyo): set global constant.\n             }\n         }\n \n-        //debuginfo::create_global_var_metadata(&self, def_id, global);\n-\n         if attrs.flags.contains(CodegenFnAttrFlags::THREAD_LOCAL) {\n             // Do not allow LLVM to change the alignment of a TLS on macOS.\n             //\n@@ -184,19 +159,7 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n                 // happens to be zero. Instead, we should only check the value of defined bytes\n                 // and set all undefined bytes to zero if this allocation is headed for the\n                 // BSS.\n-                /*let all_bytes_are_zero = alloc.relocations().is_empty()\n-                    && alloc\n-                        .inspect_with_uninit_and_ptr_outside_interpreter(0..alloc.len())\n-                        .iter()\n-                        .all(|&byte| byte == 0);\n-\n-                let sect_name = if all_bytes_are_zero {\n-                    CStr::from_bytes_with_nul_unchecked(b\"__DATA,__thread_bss\\0\")\n-                } else {\n-                    CStr::from_bytes_with_nul_unchecked(b\"__DATA,__thread_data\\0\")\n-                };*/\n                 unimplemented!();\n-                //llvm::LLVMSetSection(global, sect_name.as_ptr());\n             }\n         }\n \n@@ -205,34 +168,9 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n         if self.tcx.sess.opts.target_triple.triple().starts_with(\"wasm32\") {\n             if let Some(_section) = attrs.link_section {\n                 unimplemented!();\n-                /*let section = llvm::LLVMMDStringInContext(\n-                    self.llcx,\n-                    section.as_str().as_ptr().cast(),\n-                    section.as_str().len() as c_uint,\n-                );\n-                assert!(alloc.relocations().is_empty());\n-\n-                // The `inspect` method is okay here because we checked relocations, and\n-                // because we are doing this access to inspect the final interpreter state (not\n-                // as part of the interpreter execution).\n-                let bytes =\n-                    alloc.inspect_with_uninit_and_ptr_outside_interpreter(0..alloc.len());\n-                let alloc = llvm::LLVMMDStringInContext(\n-                    self.llcx,\n-                    bytes.as_ptr().cast(),\n-                    bytes.len() as c_uint,\n-                );\n-                let data = [section, alloc];\n-                let meta = llvm::LLVMMDNodeInContext(self.llcx, data.as_ptr(), 2);\n-                llvm::LLVMAddNamedMetadataOperand(\n-                    self.llmod,\n-                    \"wasm.custom_sections\\0\".as_ptr().cast(),\n-                    meta,\n-                );*/\n             }\n         } else {\n-            // TODO\n-            //base::set_link_section(global, &attrs);\n+            // TODO(antoyo): set link section.\n         }\n \n         if attrs.flags.contains(CodegenFnAttrFlags::USED) {\n@@ -242,9 +180,7 @@ impl<'gcc, 'tcx> StaticMethods for CodegenCx<'gcc, 'tcx> {\n \n     /// Add a global value to a list to be stored in the `llvm.used` variable, an array of i8*.\n     fn add_used_global(&self, _global: RValue<'gcc>) {\n-        // TODO\n-        //let cast = self.context.new_cast(None, global, self.type_i8p());\n-        //self.used_statics.borrow_mut().push(cast);\n+        // TODO(antoyo)\n     }\n }\n \n@@ -254,13 +190,13 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n             match kind {\n                 Some(kind) if !self.tcx.sess.fewer_names() => {\n                     let name = self.generate_local_symbol_name(kind);\n-                    // TODO: check if it's okay that TLS is off here.\n-                    // TODO: check if it's okay that link_section is None here.\n-                    // TODO: set alignment here as well.\n+                    // TODO(antoyo): check if it's okay that TLS is off here.\n+                    // TODO(antoyo): check if it's okay that link_section is None here.\n+                    // TODO(antoyo): set alignment here as well.\n                     let gv = self.define_global(&name[..], self.val_ty(cv), false, None).unwrap_or_else(|| {\n                         bug!(\"symbol `{}` is already defined\", name);\n                     });\n-                    //llvm::LLVMRustSetLinkage(gv, llvm::Linkage::PrivateLinkage);\n+                    // TODO(antoyo): set linkage.\n                     (name, gv)\n                 }\n                 _ => {\n@@ -271,33 +207,20 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                     (name, global)\n                 },\n             };\n-        // FIXME: I think the name coming from generate_local_symbol_name() above cannot be used\n+        // FIXME(antoyo): I think the name coming from generate_local_symbol_name() above cannot be used\n         // globally.\n         // NOTE: global seems to only be global in a module. So save the name instead of the value\n         // to import it later.\n         self.global_names.borrow_mut().insert(cv, name);\n         self.global_init_block.add_assignment(None, gv.dereference(None), cv);\n-        //llvm::SetUnnamedAddress(gv, llvm::UnnamedAddr::Global);\n+        // TODO(antoyo): set unnamed address.\n         gv\n     }\n \n     pub fn get_static(&self, def_id: DefId) -> RValue<'gcc> {\n         let instance = Instance::mono(self.tcx, def_id);\n         let fn_attrs = self.tcx.codegen_fn_attrs(def_id);\n         if let Some(&global) = self.instances.borrow().get(&instance) {\n-            /*let attrs = self.tcx.codegen_fn_attrs(def_id);\n-            let name = &*self.tcx.symbol_name(instance).name;\n-            let name =\n-                if let Some(linkage) = attrs.linkage {\n-                    // This is to match what happens in check_and_apply_linkage.\n-                    Cow::from(format!(\"_rust_extern_with_linkage_{}\", name))\n-                }\n-                else {\n-                    Cow::from(name)\n-                };\n-            let global = self.context.new_global(None, GlobalKind::Imported, global.get_type(), &name)\n-                .get_address(None);\n-            self.global_names.borrow_mut().insert(global, name.to_string());*/\n             return global;\n         }\n \n@@ -313,8 +236,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n         let ty = instance.ty(self.tcx, ty::ParamEnv::reveal_all());\n         let sym = self.tcx.symbol_name(instance).name;\n \n-        //debug!(\"get_static: sym={} instance={:?}\", sym, instance);\n-\n         let global =\n             if let Some(def_id) = def_id.as_local() {\n                 let id = self.tcx.hir().local_def_id_to_hir_id(def_id);\n@@ -332,9 +253,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                         let global = self.declare_global(&sym, llty, is_tls, fn_attrs.link_section);\n \n                         if !self.tcx.is_reachable_non_generic(def_id) {\n-                            /*unsafe {\n-                              llvm::LLVMRustSetVisibility(global, llvm::Visibility::Hidden);\n-                              }*/\n+                            // TODO(antoyo): set visibility.\n                         }\n \n                         global\n@@ -352,8 +271,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                     item => bug!(\"get_static: expected static, found {:?}\", item),\n                 };\n \n-                //debug!(\"get_static: sym={} attrs={:?}\", sym, attrs);\n-\n                 global\n             }\n             else {\n@@ -364,11 +281,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                 let span = self.tcx.def_span(def_id);\n                 let global = check_and_apply_linkage(&self, &attrs, ty, sym, span);\n \n-                let needs_dll_storage_attr = false; /*self.use_dll_storage_attrs && !self.tcx.is_foreign_item(def_id) &&\n-                // ThinLTO can't handle this workaround in all cases, so we don't\n-                // emit the attrs. Instead we make them unnecessary by disallowing\n-                // dynamic linking when linker plugin based LTO is enabled.\n-                !self.tcx.sess.opts.cg.linker_plugin_lto.enabled();*/\n+                let needs_dll_storage_attr = false; // TODO(antoyo)\n \n                 // If this assertion triggers, there's something wrong with commandline\n                 // argument validation.\n@@ -391,20 +304,12 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                     // is_codegened_item query.\n                     if !self.tcx.is_codegened_item(def_id) {\n                         unimplemented!();\n-                        /*unsafe {\n-                            llvm::LLVMSetDLLStorageClass(global, llvm::DLLStorageClass::DllImport);\n-                        }*/\n                     }\n                 }\n                 global\n             };\n \n-        /*if self.use_dll_storage_attrs && self.tcx.is_dllimport_foreign_item(def_id) {\n-            // For foreign (native) libs we know the exact storage type to use.\n-            unsafe {\n-                llvm::LLVMSetDLLStorageClass(global, llvm::DLLStorageClass::DllImport);\n-            }\n-        }*/\n+        // TODO(antoyo): set dll storage class.\n \n         self.instances.borrow_mut().insert(instance, global);\n         global\n@@ -474,8 +379,6 @@ fn check_and_apply_linkage<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, attrs: &Codeg\n     let is_tls = attrs.flags.contains(CodegenFnAttrFlags::THREAD_LOCAL);\n     let llty = cx.layout_of(ty).gcc_type(cx, true);\n     if let Some(linkage) = attrs.linkage {\n-        //debug!(\"get_static: sym={} linkage={:?}\", sym, linkage);\n-\n         // If this is a static with a linkage specified, then we need to handle\n         // it a little specially. The typesystem prevents things like &T and\n         // extern \"C\" fn() from being non-null, so we can't just declare a\n@@ -506,10 +409,10 @@ fn check_and_apply_linkage<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, attrs: &Codeg\n             cx.define_global(&real_name, llty, is_tls, attrs.link_section).unwrap_or_else(|| {\n                 cx.sess().span_fatal(span, &format!(\"symbol `{}` is already defined\", &sym))\n             });\n-        //llvm::LLVMRustSetLinkage(global2, llvm::Linkage::InternalLinkage);\n+        // TODO(antoyo): set linkage.\n         let lvalue = global2.dereference(None);\n         cx.global_init_block.add_assignment(None, lvalue, global1);\n-        //llvm::LLVMSetInitializer(global2, global1);\n+        // TODO(antoyo): use global_set_initializer() when it will work.\n         global2\n     }\n     else {"}, {"sha": "7ab1ca0d771c1be318398c6315eecdbe897ad183", "filename": "src/context.rs", "status": "modified", "additions": 17, "deletions": 39, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcontext.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -41,7 +41,7 @@ pub struct CodegenCx<'gcc, 'tcx> {\n     pub codegen_unit: &'tcx CodegenUnit<'tcx>,\n     pub context: &'gcc Context<'gcc>,\n \n-    // TODO: First set it to a dummy block to avoid using Option?\n+    // TODO(antoyo): First set it to a dummy block to avoid using Option?\n     pub current_block: RefCell<Option<Block<'gcc>>>,\n     pub current_func: RefCell<Option<Function<'gcc>>>,\n     pub normal_function_addresses: RefCell<FxHashSet<RValue<'gcc>>>,\n@@ -104,7 +104,7 @@ pub struct CodegenCx<'gcc, 'tcx> {\n \n     /// Cache of globals.\n     pub globals: RefCell<FxHashMap<String, RValue<'gcc>>>,\n-    // TODO: remove global_names.\n+    // TODO(antoyo): remove global_names.\n     pub global_names: RefCell<FxHashMap<RValue<'gcc>, String>>,\n \n     /// A counter that is used for generating local symbol names\n@@ -119,36 +119,34 @@ pub struct CodegenCx<'gcc, 'tcx> {\n     /// `const_undef()` returns struct as pointer so that they can later be assigned a value.\n     /// As such, this set remembers which of these pointers were returned by this function so that\n     /// they can be derefered later.\n-    /// FIXME: fix the rustc API to avoid having this hack.\n+    /// FIXME(antoyo): fix the rustc API to avoid having this hack.\n     pub structs_as_pointer: RefCell<FxHashSet<RValue<'gcc>>>,\n \n     /// Store the pointer of different types for safety.\n     /// When casting the values back to their original types, check that they are indeed that type\n     /// with these sets.\n-    /// FIXME: remove when the API supports more types.\n+    /// FIXME(antoyo): remove when the API supports more types.\n     #[cfg(debug_assertions)]\n     lvalues: RefCell<FxHashSet<LValue<'gcc>>>,\n }\n \n impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     pub fn new(context: &'gcc Context<'gcc>, codegen_unit: &'tcx CodegenUnit<'tcx>, tcx: TyCtxt<'tcx>) -> Self {\n         let check_overflow = tcx.sess.overflow_checks();\n-        // TODO: fix this mess. libgccjit seems to return random type when using new_int_type().\n-        //let isize_type = context.new_int_type((tcx.data_layout.pointer_size.bits() / 8) as i32, true);\n+        // TODO(antoyo): fix this mess. libgccjit seems to return random type when using new_int_type().\n         let isize_type = context.new_c_type(CType::LongLong);\n-        //let usize_type = context.new_int_type((tcx.data_layout.pointer_size.bits() / 8) as i32, false);\n         let usize_type = context.new_c_type(CType::ULongLong);\n         let bool_type = context.new_type::<bool>();\n         let i8_type = context.new_type::<i8>();\n         let i16_type = context.new_type::<i16>();\n         let i32_type = context.new_type::<i32>();\n         let i64_type = context.new_c_type(CType::LongLong);\n-        let i128_type = context.new_c_type(CType::Int128t).get_aligned(8); // TODO: should this be hard-coded?\n+        let i128_type = context.new_c_type(CType::Int128t).get_aligned(8); // TODO(antoyo): should the alignment be hard-coded?\n         let u8_type = context.new_type::<u8>();\n         let u16_type = context.new_type::<u16>();\n         let u32_type = context.new_type::<u32>();\n         let u64_type = context.new_c_type(CType::ULongLong);\n-        let u128_type = context.new_c_type(CType::UInt128t).get_aligned(8); // TODO: should this be hard-coded?\n+        let u128_type = context.new_c_type(CType::UInt128t).get_aligned(8); // TODO(antoyo): should the alignment be hard-coded?\n \n         let tls_model = to_gcc_tls_mode(tcx.sess.tls_model());\n \n@@ -261,7 +259,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n \n     pub fn rvalue_as_lvalue(&self, value: RValue<'gcc>) -> LValue<'gcc> {\n         let lvalue: LValue<'gcc> = unsafe { std::mem::transmute(value) };\n-        //debug_assert!(self.lvalues.borrow().contains(&lvalue), \"{:?} is not an lvalue\", value);\n         lvalue\n     }\n \n@@ -276,11 +273,11 @@ impl<'gcc, 'tcx> BackendTypes for CodegenCx<'gcc, 'tcx> {\n \n     type BasicBlock = Block<'gcc>;\n     type Type = Type<'gcc>;\n-    type Funclet = (); // TODO\n+    type Funclet = (); // TODO(antoyo)\n \n-    type DIScope = (); // TODO\n-    type DILocation = (); // TODO\n-    type DIVariable = (); // TODO\n+    type DIScope = (); // TODO(antoyo)\n+    type DILocation = (); // TODO(antoyo)\n+    type DIVariable = (); // TODO(antoyo)\n }\n \n impl<'gcc, 'tcx> MiscMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n@@ -295,17 +292,12 @@ impl<'gcc, 'tcx> MiscMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     }\n \n     fn get_fn_addr(&self, instance: Instance<'tcx>) -> RValue<'gcc> {\n-        //let symbol = self.tcx.symbol_name(instance).name;\n-\n         let func = get_fn(self, instance);\n         let func = self.rvalue_as_function(func);\n         let ptr = func.get_address(None);\n \n-        // TODO: don't do this twice: i.e. in declare_fn and here.\n-        //let fn_abi = FnAbi::of_instance(self, instance, &[]);\n-        //let (return_type, params, _) = fn_abi.gcc_type(self);\n-        // FIXME: the rustc API seems to call get_fn_addr() when not needed (e.g. for FFI).\n-        //let pointer_type = ptr.get_type();\n+        // TODO(antoyo): don't do this twice: i.e. in declare_fn and here.\n+        // FIXME(antoyo): the rustc API seems to call get_fn_addr() when not needed (e.g. for FFI).\n \n         self.normal_function_addresses.borrow_mut().insert(ptr);\n \n@@ -354,12 +346,12 @@ impl<'gcc, 'tcx> MiscMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n                     \"rust_eh_personality\"\n                 };\n                 //let func = self.declare_func(name, self.type_i32(), &[], true);\n-                // FIXME: this hack should not be needed. That will probably be removed when\n+                // FIXME(antoyo): this hack should not be needed. That will probably be removed when\n                 // unwinding support is added.\n                 self.context.new_rvalue_from_int(self.int_type, 0)\n             }\n         };\n-        //attributes::apply_target_cpu_attr(self, llfn);\n+        // TODO(antoyo): apply target cpu attributes.\n         self.eh_personality.set(Some(llfn));\n         llfn\n     }\n@@ -378,32 +370,18 @@ impl<'gcc, 'tcx> MiscMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n \n     fn used_statics(&self) -> &RefCell<Vec<RValue<'gcc>>> {\n         unimplemented!();\n-        //&self.used_statics\n     }\n \n     fn set_frame_pointer_type(&self, _llfn: RValue<'gcc>) {\n-        // TODO\n-        //attributes::set_frame_pointer_type(self, llfn)\n+        // TODO(antoyo)\n     }\n \n     fn apply_target_cpu_attr(&self, _llfn: RValue<'gcc>) {\n-        // TODO\n-        //attributes::apply_target_cpu_attr(self, llfn)\n+        // TODO(antoyo)\n     }\n \n     fn create_used_variable(&self) {\n         unimplemented!();\n-        /*let name = const_cstr!(\"llvm.used\");\n-        let section = const_cstr!(\"llvm.metadata\");\n-        let array =\n-            self.const_array(&self.type_ptr_to(self.type_i8()), &*self.used_statics.borrow());\n-\n-        unsafe {\n-            let g = llvm::LLVMAddGlobal(self.llmod, self.val_ty(array), name.as_ptr());\n-            llvm::LLVMSetInitializer(g, array);\n-            llvm::LLVMRustSetLinkage(g, llvm::Linkage::AppendingLinkage);\n-            llvm::LLVMSetSection(g, section.as_ptr());\n-        }*/\n     }\n \n     fn declare_c_main(&self, fn_type: Self::Type) -> Option<Self::Function> {"}, {"sha": "872fc2472e223d68f6deccd853e37e653cd60dc4", "filename": "src/coverageinfo.rs", "status": "modified", "additions": 4, "deletions": 75, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcoverageinfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fcoverageinfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcoverageinfo.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -20,99 +20,31 @@ impl<'a, 'gcc, 'tcx> CoverageInfoBuilderMethods<'tcx> for Builder<'a, 'gcc, 'tcx\n         _function_source_hash: u64,\n     ) -> bool {\n         unimplemented!();\n-        /*if let Some(coverage_context) = self.coverage_context() {\n-            debug!(\n-                \"ensuring function source hash is set for instance={:?}; function_source_hash={}\",\n-                instance, function_source_hash,\n-            );\n-            let mut coverage_map = coverage_context.function_coverage_map.borrow_mut();\n-            coverage_map\n-                .entry(instance)\n-                .or_insert_with(|| FunctionCoverage::new(self.tcx, instance))\n-                .set_function_source_hash(function_source_hash);\n-            true\n-        } else {\n-            false\n-        }*/\n     }\n \n     fn add_coverage_counter(&mut self, _instance: Instance<'tcx>, _id: CounterValueReference, _region: CodeRegion) -> bool {\n-        /*if let Some(coverage_context) = self.coverage_context() {\n-            debug!(\n-                \"adding counter to coverage_regions: instance={:?}, function_source_hash={}, id={:?}, \\\n-                at {:?}\",\n-                instance, function_source_hash, id, region,\n-            );\n-            let mut coverage_regions = coverage_context.function_coverage_map.borrow_mut();\n-            coverage_regions\n-                .entry(instance)\n-                .or_insert_with(|| FunctionCoverage::new(self.tcx, instance))\n-                .add_counter(function_source_hash, id, region);\n-            true\n-        } else {\n-            false\n-        }*/\n-        // TODO\n+        // TODO(antoyo)\n         false\n     }\n \n     fn add_coverage_counter_expression(&mut self, _instance: Instance<'tcx>, _id: InjectedExpressionId, _lhs: ExpressionOperandId, _op: Op, _rhs: ExpressionOperandId, _region: Option<CodeRegion>) -> bool {\n-        /*if let Some(coverage_context) = self.coverage_context() {\n-            debug!(\n-                \"adding counter expression to coverage_regions: instance={:?}, id={:?}, {:?} {:?} {:?}, \\\n-                at {:?}\",\n-                instance, id, lhs, op, rhs, region,\n-            );\n-            let mut coverage_regions = coverage_context.function_coverage_map.borrow_mut();\n-            coverage_regions\n-                .entry(instance)\n-                .or_insert_with(|| FunctionCoverage::new(self.tcx, instance))\n-                .add_counter_expression(id, lhs, op, rhs, region);\n-            true\n-        } else {\n-            false\n-        }*/\n-        // TODO\n+        // TODO(antoyo)\n         false\n     }\n \n     fn add_coverage_unreachable(&mut self, _instance: Instance<'tcx>, _region: CodeRegion) -> bool {\n-        /*if let Some(coverage_context) = self.coverage_context() {\n-            debug!(\n-                \"adding unreachable code to coverage_regions: instance={:?}, at {:?}\",\n-                instance, region,\n-            );\n-            let mut coverage_regions = coverage_context.function_coverage_map.borrow_mut();\n-            coverage_regions\n-                .entry(instance)\n-                .or_insert_with(|| FunctionCoverage::new(self.tcx, instance))\n-                .add_unreachable_region(region);\n-            true\n-        } else {\n-            false\n-        }*/\n-        // TODO\n+        // TODO(antoyo)\n         false\n     }\n }\n \n impl<'gcc, 'tcx> CoverageInfoMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     fn coverageinfo_finalize(&self) {\n-        // TODO\n-        //mapgen::finalize(self)\n+        // TODO(antoyo)\n     }\n \n     fn get_pgo_func_name_var(&self, _instance: Instance<'tcx>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*if let Some(coverage_context) = self.coverage_context() {\n-            debug!(\"getting pgo_func_name_var for instance={:?}\", instance);\n-            let mut pgo_func_name_var_map = coverage_context.pgo_func_name_var_map.borrow_mut();\n-            pgo_func_name_var_map\n-                .entry(instance)\n-                .or_insert_with(|| create_pgo_func_name_var(self, instance))\n-        } else {\n-            bug!(\"Could not get the `coverage_context`\");\n-        }*/\n     }\n \n     /// Functions with MIR-based coverage are normally codegenned _only_ if\n@@ -133,8 +65,5 @@ impl<'gcc, 'tcx> CoverageInfoMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     /// added as `unreachable_region`s.\n     fn define_unused_fn(&self, _def_id: DefId) {\n         unimplemented!();\n-        /*let instance = declare_unused_fn(self, &def_id);\n-        codegen_unused_fn_and_counter(self, instance);\n-        add_unused_function_coverage(self, instance, def_id);*/\n     }\n }"}, {"sha": "8661532a3595e6e2d4a659a3bd763fffbe3c2c75", "filename": "src/debuginfo.rs", "status": "modified", "additions": 6, "deletions": 330, "changes": 336, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdebuginfo.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -17,66 +17,18 @@ impl<'a, 'gcc, 'tcx> DebugInfoBuilderMethods for Builder<'a, 'gcc, 'tcx> {\n     // names (choose between `dbg`, `debug`, `debuginfo`, `debug_info` etc.).\n     fn dbg_var_addr(&mut self, _dbg_var: Self::DIVariable, _scope_metadata: Self::DIScope, _variable_alloca: Self::Value, _direct_offset: Size, _indirect_offsets: &[Size]) {\n         unimplemented!();\n-        /*let cx = self.cx();\n-\n-        // Convert the direct and indirect offsets to address ops.\n-        // FIXME(eddyb) use `const`s instead of getting the values via FFI,\n-        // the values should match the ones in the DWARF standard anyway.\n-        let op_deref = || unsafe { llvm::LLVMRustDIBuilderCreateOpDeref() };\n-        let op_plus_uconst = || unsafe { llvm::LLVMRustDIBuilderCreateOpPlusUconst() };\n-        let mut addr_ops = SmallVec::<[_; 8]>::new();\n-\n-        if direct_offset.bytes() > 0 {\n-            addr_ops.push(op_plus_uconst());\n-            addr_ops.push(direct_offset.bytes() as i64);\n-        }\n-        for &offset in indirect_offsets {\n-            addr_ops.push(op_deref());\n-            if offset.bytes() > 0 {\n-                addr_ops.push(op_plus_uconst());\n-                addr_ops.push(offset.bytes() as i64);\n-            }\n-        }\n-\n-        // FIXME(eddyb) maybe this information could be extracted from `dbg_var`,\n-        // to avoid having to pass it down in both places?\n-        // NB: `var` doesn't seem to know about the column, so that's a limitation.\n-        let dbg_loc = cx.create_debug_loc(scope_metadata, span);\n-        unsafe {\n-            // FIXME(eddyb) replace `llvm.dbg.declare` with `llvm.dbg.addr`.\n-            llvm::LLVMRustDIBuilderInsertDeclareAtEnd(\n-                DIB(cx),\n-                variable_alloca,\n-                dbg_var,\n-                addr_ops.as_ptr(),\n-                addr_ops.len() as c_uint,\n-                dbg_loc,\n-                self.llbb(),\n-            );\n-        }*/\n     }\n \n-    /*fn set_source_location(&mut self, scope: Self::DIScope, span: Span) {\n-        unimplemented!();\n-        /*debug!(\"set_source_location: {}\", self.sess().source_map().span_to_string(span));\n-\n-        let dbg_loc = self.cx().create_debug_loc(scope, span);\n-\n-        unsafe {\n-            llvm::LLVMSetCurrentDebugLocation(self.llbuilder, dbg_loc);\n-        }*/\n-    }*/\n-\n     fn insert_reference_to_gdb_debug_scripts_section_global(&mut self) {\n-        // TODO: replace with gcc_jit_context_new_global_with_initializer() if it's added:\n+        // TODO(antoyo): replace with gcc_jit_context_new_global_with_initializer() if it's added:\n         // https://gcc.gnu.org/pipermail/jit/2020q3/001225.html\n         //\n         // Call the function to initialize global values here.\n         // We assume this is only called for the main function.\n         use std::iter;\n \n         for crate_num in self.cx.tcx.crates(()).iter().copied().chain(iter::once(LOCAL_CRATE)) {\n-            // FIXME: better way to find if a crate is of proc-macro type?\n+            // FIXME(antoyo): better way to find if a crate is of proc-macro type?\n             if crate_num == LOCAL_CRATE || self.cx.tcx.dep_kind(crate_num) != CrateDepKind::MacrosOnly {\n                 // NOTE: proc-macro crates are not included in the executable, so don't call their\n                 // initialization routine.\n@@ -87,50 +39,25 @@ impl<'a, 'gcc, 'tcx> DebugInfoBuilderMethods for Builder<'a, 'gcc, 'tcx> {\n             }\n         }\n \n-        // TODO\n-        //gdb::insert_reference_to_gdb_debug_scripts_section_global(self)\n+        // TODO(antoyo): insert reference to gdb debug scripts section global.\n     }\n \n     fn set_var_name(&mut self, _value: RValue<'gcc>, _name: &str) {\n         unimplemented!();\n-        // Avoid wasting time if LLVM value names aren't even enabled.\n-        /*if self.sess().fewer_names() {\n-            return;\n-        }\n-\n-        // Only function parameters and instructions are local to a function,\n-        // don't change the name of anything else (e.g. globals).\n-        let param_or_inst = unsafe {\n-            llvm::LLVMIsAArgument(value).is_some() || llvm::LLVMIsAInstruction(value).is_some()\n-        };\n-        if !param_or_inst {\n-            return;\n-        }\n-\n-        // Avoid replacing the name if it already exists.\n-        // While we could combine the names somehow, it'd\n-        // get noisy quick, and the usefulness is dubious.\n-        if llvm::get_value_name(value).is_empty() {\n-            llvm::set_value_name(value, name.as_bytes());\n-        }*/\n     }\n \n     fn set_dbg_loc(&mut self, _dbg_loc: Self::DILocation) {\n         unimplemented!();\n-        /*unsafe {\n-            let dbg_loc_as_llval = llvm::LLVMRustMetadataAsValue(self.cx().llcx, dbg_loc);\n-            llvm::LLVMSetCurrentDebugLocation(self.llbuilder, dbg_loc_as_llval);\n-        }*/\n     }\n }\n \n impl<'gcc, 'tcx> DebugInfoMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     fn create_vtable_metadata(&self, _ty: Ty<'tcx>, _vtable: Self::Value) {\n-        //metadata::create_vtable_metadata(self, ty, vtable)\n+        // TODO(antoyo)\n     }\n \n     fn create_function_debug_context(&self, _instance: Instance<'tcx>, _fn_abi: &FnAbi<'tcx, Ty<'tcx>>, _llfn: RValue<'gcc>, _mir: &mir::Body<'tcx>) -> Option<FunctionDebugContext<Self::DIScope, Self::DILocation>> {\n-        // TODO\n+        // TODO(antoyo)\n         None\n     }\n \n@@ -139,7 +66,7 @@ impl<'gcc, 'tcx> DebugInfoMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n     }\n \n     fn debuginfo_finalize(&self) {\n-        //unimplemented!();\n+        // TODO(antoyo)\n     }\n \n     fn create_dbg_var(&self, _variable_name: Symbol, _variable_type: Ty<'tcx>, _scope_metadata: Self::DIScope, _variable_kind: VariableKind, _span: Span) -> Self::DIVariable {\n@@ -148,260 +75,9 @@ impl<'gcc, 'tcx> DebugInfoMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n \n     fn dbg_scope_fn(&self, _instance: Instance<'tcx>, _fn_abi: &FnAbi<'tcx, Ty<'tcx>>, _maybe_definition_llfn: Option<RValue<'gcc>>) -> Self::DIScope {\n         unimplemented!();\n-        /*let def_id = instance.def_id();\n-        let containing_scope = get_containing_scope(self, instance);\n-        let span = self.tcx.def_span(def_id);\n-        let loc = self.lookup_debug_loc(span.lo());\n-        let file_metadata = file_metadata(self, &loc.file);\n-\n-        let function_type_metadata = unsafe {\n-            let fn_signature = get_function_signature(self, fn_abi);\n-            llvm::LLVMRustDIBuilderCreateSubroutineType(DIB(self), fn_signature)\n-        };\n-\n-        // Find the enclosing function, in case this is a closure.\n-        let def_key = self.tcx().def_key(def_id);\n-        let mut name = def_key.disambiguated_data.data.to_string();\n-\n-        let enclosing_fn_def_id = self.tcx().closure_base_def_id(def_id);\n-\n-        // Get_template_parameters() will append a `<...>` clause to the function\n-        // name if necessary.\n-        let generics = self.tcx().generics_of(enclosing_fn_def_id);\n-        let substs = instance.substs.truncate_to(self.tcx(), generics);\n-        let template_parameters = get_template_parameters(self, &generics, substs, &mut name);\n-\n-        let linkage_name = &mangled_name_of_instance(self, instance).name;\n-        // Omit the linkage_name if it is the same as subprogram name.\n-        let linkage_name = if &name == linkage_name { \"\" } else { linkage_name };\n-\n-        // FIXME(eddyb) does this need to be separate from `loc.line` for some reason?\n-        let scope_line = loc.line;\n-\n-        let mut flags = DIFlags::FlagPrototyped;\n-\n-        if fn_abi.ret.layout.abi.is_uninhabited() {\n-            flags |= DIFlags::FlagNoReturn;\n-        }\n-\n-        let mut spflags = DISPFlags::SPFlagDefinition;\n-        if is_node_local_to_unit(self, def_id) {\n-            spflags |= DISPFlags::SPFlagLocalToUnit;\n-        }\n-        if self.sess().opts.optimize != config::OptLevel::No {\n-            spflags |= DISPFlags::SPFlagOptimized;\n-        }\n-        if let Some((id, _)) = self.tcx.entry_fn(LOCAL_CRATE) {\n-            if id.to_def_id() == def_id {\n-                spflags |= DISPFlags::SPFlagMainSubprogram;\n-            }\n-        }\n-\n-        unsafe {\n-            return llvm::LLVMRustDIBuilderCreateFunction(\n-                DIB(self),\n-                containing_scope,\n-                name.as_ptr().cast(),\n-                name.len(),\n-                linkage_name.as_ptr().cast(),\n-                linkage_name.len(),\n-                file_metadata,\n-                loc.line.unwrap_or(UNKNOWN_LINE_NUMBER),\n-                function_type_metadata,\n-                scope_line.unwrap_or(UNKNOWN_LINE_NUMBER),\n-                flags,\n-                spflags,\n-                maybe_definition_llfn,\n-                template_parameters,\n-                None,\n-            );\n-        }\n-\n-        fn get_function_signature<'ll, 'tcx>(\n-            cx: &CodegenCx<'ll, 'tcx>,\n-            fn_abi: &FnAbi<'tcx, Ty<'tcx>>,\n-        ) -> &'ll DIArray {\n-            if cx.sess().opts.debuginfo == DebugInfo::Limited {\n-                return create_DIArray(DIB(cx), &[]);\n-            }\n-\n-            let mut signature = Vec::with_capacity(fn_abi.args.len() + 1);\n-\n-            // Return type -- llvm::DIBuilder wants this at index 0\n-            signature.push(if fn_abi.ret.is_ignore() {\n-                None\n-            } else {\n-                Some(type_metadata(cx, fn_abi.ret.layout.ty, rustc_span::DUMMY_SP))\n-            });\n-\n-            // Arguments types\n-            if cx.sess().target.options.is_like_msvc {\n-                // FIXME(#42800):\n-                // There is a bug in MSDIA that leads to a crash when it encounters\n-                // a fixed-size array of `u8` or something zero-sized in a\n-                // function-type (see #40477).\n-                // As a workaround, we replace those fixed-size arrays with a\n-                // pointer-type. So a function `fn foo(a: u8, b: [u8; 4])` would\n-                // appear as `fn foo(a: u8, b: *const u8)` in debuginfo,\n-                // and a function `fn bar(x: [(); 7])` as `fn bar(x: *const ())`.\n-                // This transformed type is wrong, but these function types are\n-                // already inaccurate due to ABI adjustments (see #42800).\n-                signature.extend(fn_abi.args.iter().map(|arg| {\n-                    let t = arg.layout.ty;\n-                    let t = match t.kind() {\n-                        ty::Array(ct, _)\n-                            if (*ct == cx.tcx.types.u8) || cx.layout_of(ct).is_zst() =>\n-                        {\n-                            cx.tcx.mk_imm_ptr(ct)\n-                        }\n-                        _ => t,\n-                    };\n-                    Some(type_metadata(cx, t, rustc_span::DUMMY_SP))\n-                }));\n-            } else {\n-                signature.extend(\n-                    fn_abi\n-                        .args\n-                        .iter()\n-                        .map(|arg| Some(type_metadata(cx, arg.layout.ty, rustc_span::DUMMY_SP))),\n-                );\n-            }\n-\n-            create_DIArray(DIB(cx), &signature[..])\n-        }\n-\n-        fn get_template_parameters<'ll, 'tcx>(\n-            cx: &CodegenCx<'ll, 'tcx>,\n-            generics: &ty::Generics,\n-            substs: SubstsRef<'tcx>,\n-            name_to_append_suffix_to: &mut String,\n-        ) -> &'ll DIArray {\n-            if substs.types().next().is_none() {\n-                return create_DIArray(DIB(cx), &[]);\n-            }\n-\n-            name_to_append_suffix_to.push('<');\n-            for (i, actual_type) in substs.types().enumerate() {\n-                if i != 0 {\n-                    name_to_append_suffix_to.push(',');\n-                }\n-\n-                let actual_type =\n-                    cx.tcx.normalize_erasing_regions(ParamEnv::reveal_all(), actual_type);\n-                // Add actual type name to <...> clause of function name\n-                let actual_type_name = compute_debuginfo_type_name(cx.tcx(), actual_type, true);\n-                name_to_append_suffix_to.push_str(&actual_type_name[..]);\n-            }\n-            name_to_append_suffix_to.push('>');\n-\n-            // Again, only create type information if full debuginfo is enabled\n-            let template_params: Vec<_> = if cx.sess().opts.debuginfo == DebugInfo::Full {\n-                let names = get_parameter_names(cx, generics);\n-                substs\n-                    .iter()\n-                    .zip(names)\n-                    .filter_map(|(kind, name)| {\n-                        if let GenericArgKind::Type(ty) = kind.unpack() {\n-                            let actual_type =\n-                                cx.tcx.normalize_erasing_regions(ParamEnv::reveal_all(), ty);\n-                            let actual_type_metadata =\n-                                type_metadata(cx, actual_type, rustc_span::DUMMY_SP);\n-                            let name = name.as_str();\n-                            Some(unsafe {\n-                                Some(llvm::LLVMRustDIBuilderCreateTemplateTypeParameter(\n-                                    DIB(cx),\n-                                    None,\n-                                    name.as_ptr().cast(),\n-                                    name.len(),\n-                                    actual_type_metadata,\n-                                ))\n-                            })\n-                        } else {\n-                            None\n-                        }\n-                    })\n-                    .collect()\n-            } else {\n-                vec![]\n-            };\n-\n-            create_DIArray(DIB(cx), &template_params[..])\n-        }\n-\n-        fn get_parameter_names(cx: &CodegenCx<'_, '_>, generics: &ty::Generics) -> Vec<Symbol> {\n-            let mut names = generics\n-                .parent\n-                .map_or(vec![], |def_id| get_parameter_names(cx, cx.tcx.generics_of(def_id)));\n-            names.extend(generics.params.iter().map(|param| param.name));\n-            names\n-        }\n-\n-        fn get_containing_scope<'ll, 'tcx>(\n-            cx: &CodegenCx<'ll, 'tcx>,\n-            instance: Instance<'tcx>,\n-        ) -> &'ll DIScope {\n-            // First, let's see if this is a method within an inherent impl. Because\n-            // if yes, we want to make the result subroutine DIE a child of the\n-            // subroutine's self-type.\n-            let self_type = cx.tcx.impl_of_method(instance.def_id()).and_then(|impl_def_id| {\n-                // If the method does *not* belong to a trait, proceed\n-                if cx.tcx.trait_id_of_impl(impl_def_id).is_none() {\n-                    let impl_self_ty = cx.tcx.subst_and_normalize_erasing_regions(\n-                        instance.substs,\n-                        ty::ParamEnv::reveal_all(),\n-                        &cx.tcx.type_of(impl_def_id),\n-                    );\n-\n-                    // Only \"class\" methods are generally understood by LLVM,\n-                    // so avoid methods on other types (e.g., `<*mut T>::null`).\n-                    match impl_self_ty.kind() {\n-                        ty::Adt(def, ..) if !def.is_box() => {\n-                            // Again, only create type information if full debuginfo is enabled\n-                            if cx.sess().opts.debuginfo == DebugInfo::Full\n-                                && !impl_self_ty.needs_subst()\n-                            {\n-                                Some(type_metadata(cx, impl_self_ty, rustc_span::DUMMY_SP))\n-                            } else {\n-                                Some(namespace::item_namespace(cx, def.did))\n-                            }\n-                        }\n-                        _ => None,\n-                    }\n-                } else {\n-                    // For trait method impls we still use the \"parallel namespace\"\n-                    // strategy\n-                    None\n-                }\n-            });\n-\n-            self_type.unwrap_or_else(|| {\n-                namespace::item_namespace(\n-                    cx,\n-                    DefId {\n-                        krate: instance.def_id().krate,\n-                        index: cx\n-                            .tcx\n-                            .def_key(instance.def_id())\n-                            .parent\n-                            .expect(\"get_containing_scope: missing parent?\"),\n-                    },\n-                )\n-            })\n-        }*/\n     }\n \n     fn dbg_loc(&self, _scope: Self::DIScope, _inlined_at: Option<Self::DILocation>, _span: Span) -> Self::DILocation {\n         unimplemented!();\n-        /*let DebugLoc { line, col, .. } = self.lookup_debug_loc(span.lo());\n-\n-        unsafe {\n-            llvm::LLVMRustDIBuilderCreateDebugLocation(\n-                utils::debug_context(self).llcontext,\n-                line.unwrap_or(UNKNOWN_LINE_NUMBER),\n-                col.unwrap_or(UNKNOWN_COLUMN_NUMBER),\n-                scope,\n-                inlined_at,\n-            )\n-        }*/\n     }\n }"}, {"sha": "c1382bf2f4a71210dcdeb1cb1e25ccafc415cfca", "filename": "src/declare.rs", "status": "modified", "additions": 14, "deletions": 41, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fdeclare.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fdeclare.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdeclare.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -35,7 +35,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     pub fn declare_global_with_linkage(&self, name: &str, ty: Type<'gcc>, linkage: GlobalKind) -> RValue<'gcc> {\n-        //debug!(\"declare_global_with_linkage(name={:?})\", name);\n         let global = self.context.new_global(None, linkage, ty, name)\n             .get_address(None);\n         self.globals.borrow_mut().insert(name.to_string(), global);\n@@ -48,13 +47,12 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     pub fn declare_func(&self, name: &str, return_type: Type<'gcc>, params: &[Type<'gcc>], variadic: bool) -> RValue<'gcc> {\n         self.linkage.set(FunctionType::Exported);\n         let func = declare_raw_fn(self, name, () /*llvm::CCallConv*/, return_type, params, variadic);\n-        // FIXME: this is a wrong cast. That requires changing the compiler API.\n+        // FIXME(antoyo): this is a wrong cast. That requires changing the compiler API.\n         unsafe { std::mem::transmute(func) }\n     }\n \n     pub fn declare_global(&self, name: &str, ty: Type<'gcc>, is_tls: bool, link_section: Option<Symbol>) -> RValue<'gcc> {\n-        //debug!(\"declare_global(name={:?})\", name);\n-        // FIXME: correctly support global variable initialization.\n+        // FIXME(antoyo): correctly support global variable initialization.\n         if name.starts_with(ARGV_INIT_ARRAY) {\n             // NOTE: hack to avoid having to update the names in mangled_std_symbols: we save the\n             // name of the variable now to actually declare it later.\n@@ -82,7 +80,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     pub fn declare_cfn(&self, name: &str, _fn_type: Type<'gcc>) -> RValue<'gcc> {\n-        // TODO: use the fn_type parameter.\n+        // TODO(antoyo): use the fn_type parameter.\n         let const_string = self.context.new_type::<u8>().make_pointer().make_pointer();\n         let return_type = self.type_i32();\n         let variadic = false;\n@@ -91,7 +89,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n         // NOTE: it is needed to set the current_func here as well, because get_fn() is not called\n         // for the main function.\n         *self.current_func.borrow_mut() = Some(func);\n-        // FIXME: this is a wrong cast. That requires changing the compiler API.\n+        // FIXME(antoyo): this is a wrong cast. That requires changing the compiler API.\n         unsafe { std::mem::transmute(func) }\n     }\n \n@@ -128,11 +126,9 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n             self.global_names.borrow_mut().insert(global, global_name.to_string());\n             self.argv_initialized.set(true);\n         }\n-        //debug!(\"declare_rust_fn(name={:?}, fn_abi={:?})\", name, fn_abi);\n         let (return_type, params, variadic) = fn_abi.gcc_type(self);\n         let func = declare_raw_fn(self, name, () /*fn_abi.llvm_cconv()*/, return_type, &params, variadic);\n-        //fn_abi.apply_attrs_llfn(self, func);\n-        // FIXME: this is a wrong cast. That requires changing the compiler API.\n+        // FIXME(antoyo): this is a wrong cast. That requires changing the compiler API.\n         unsafe { std::mem::transmute(func) }\n     }\n \n@@ -146,31 +142,16 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     pub fn get_declared_value(&self, name: &str) -> Option<RValue<'gcc>> {\n-        //debug!(\"get_declared_value(name={:?})\", name);\n-        // TODO: use a different field than globals, because this seems to return a function?\n+        // TODO(antoyo): use a different field than globals, because this seems to return a function?\n         self.globals.borrow().get(name).cloned()\n     }\n-\n-    /*fn get_defined_value(&self, name: &str) -> Option<RValue<'gcc>> {\n-        // TODO: gcc does not allow global initialization.\n-        None\n-        /*self.get_declared_value(name).and_then(|val| {\n-            let declaration = unsafe { llvm::LLVMIsDeclaration(val) != 0 };\n-            if !declaration { Some(val) } else { None }\n-        })*/\n-    }*/\n }\n \n /// Declare a function.\n ///\n /// If there\u2019s a value with the same name already declared, the function will\n /// update the declaration and return existing Value instead.\n fn declare_raw_fn<'gcc>(cx: &CodegenCx<'gcc, '_>, name: &str, _callconv: () /*llvm::CallConv*/, return_type: Type<'gcc>, param_types: &[Type<'gcc>], variadic: bool) -> Function<'gcc> {\n-    //debug!(\"declare_raw_fn(name={:?}, ty={:?})\", name, ty);\n-    /*let llfn = unsafe {\n-        llvm::LLVMRustGetOrInsertFunction(cx.llmod, name.as_ptr().cast(), name.len(), ty)\n-    };*/\n-\n     if name.starts_with(\"llvm.\") {\n         return llvm::intrinsic(name, cx);\n     }\n@@ -180,32 +161,24 @@ fn declare_raw_fn<'gcc>(cx: &CodegenCx<'gcc, '_>, name: &str, _callconv: () /*ll\n         }\n         else {\n             let params: Vec<_> = param_types.into_iter().enumerate()\n-                .map(|(index, param)| cx.context.new_parameter(None, *param, &format!(\"param{}\", index))) // TODO: set name.\n+                .map(|(index, param)| cx.context.new_parameter(None, *param, &format!(\"param{}\", index))) // TODO(antoyo): set name.\n                 .collect();\n             let func = cx.context.new_function(None, cx.linkage.get(), return_type, &params, mangle_name(name), variadic);\n             cx.functions.borrow_mut().insert(name.to_string(), func);\n             func\n         };\n \n-    //llvm::SetFunctionCallConv(llfn, callconv); // TODO\n-    // Function addresses in Rust are never significant, allowing functions to\n-    // be merged.\n-    //llvm::SetUnnamedAddress(llfn, llvm::UnnamedAddr::Global); // TODO\n-\n-    /*if cx.tcx.sess.opts.cg.no_redzone.unwrap_or(cx.tcx.sess.target.target.options.disable_redzone) {\n-        llvm::Attribute::NoRedZone.apply_llfn(Function, llfn);\n-    }*/\n-\n-    //attributes::default_optimisation_attrs(cx.tcx.sess, llfn);\n-    //attributes::non_lazy_bind(cx.sess(), llfn);\n+    // TODO(antoyo): set function calling convention.\n+    // TODO(antoyo): set unnamed address.\n+    // TODO(antoyo): set no red zone function attribute.\n+    // TODO(antoyo): set attributes for optimisation.\n+    // TODO(antoyo): set attributes for non lazy bind.\n \n-    // FIXME: invalid cast.\n-    // TODO: is this line useful?\n-    //cx.globals.borrow_mut().insert(name.to_string(), unsafe { std::mem::transmute(func) });\n+    // FIXME(antoyo): invalid cast.\n     func\n }\n \n-// FIXME: this is a hack because libgccjit currently only supports alpha, num and _.\n+// FIXME(antoyo): this is a hack because libgccjit currently only supports alpha, num and _.\n // Unsupported characters: `$` and `.`.\n pub fn mangle_name(name: &str) -> String {\n     name.replace(|char: char| {"}, {"sha": "b074febc521ebe03263fadb044fed62c48759900", "filename": "src/intrinsic/llvm.rs", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fllvm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fllvm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsic%2Fllvm.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -11,16 +11,12 @@ pub fn intrinsic<'gcc, 'tcx>(name: &str, cx: &CodegenCx<'gcc, 'tcx>) -> Function\n                 cx.functions.borrow_mut().insert(gcc_name.to_string(), func);\n                 return func;\n             },\n-            // TODO: this doc specifies the equivalent GCC builtins: http://huonw.github.io/llvmint/llvmint/x86/index.html\n+            // NOTE: this doc specifies the equivalent GCC builtins: http://huonw.github.io/llvmint/llvmint/x86/index.html\n             \"llvm.x86.sse2.cmp.pd\" => \"__builtin_ia32_cmppd\",\n             \"llvm.x86.sse2.movmsk.pd\" => \"__builtin_ia32_movmskpd\",\n             \"llvm.x86.sse2.pmovmskb.128\" => \"__builtin_ia32_pmovmskb128\",\n             _ => unimplemented!(\"unsupported LLVM intrinsic {}\", name)\n         };\n \n-    println!(\"Get target builtin\");\n     unimplemented!();\n-    /*let func = cx.context.get_target_builtin_function(gcc_name);\n-    cx.functions.borrow_mut().insert(gcc_name.to_string(), func);\n-    func*/\n }"}, {"sha": "a79be7cfc74c8ca850b7ecf4ecb9a14784020a5b", "filename": "src/intrinsic/mod.rs", "status": "modified", "additions": 15, "deletions": 280, "changes": 295, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsic%2Fmod.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -96,7 +96,7 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n         let llval =\n             match name {\n                 _ if simple.is_some() => {\n-                    // FIXME: remove this cast when the API supports function.\n+                    // FIXME(antoyo): remove this cast when the API supports function.\n                     let func = unsafe { std::mem::transmute(simple.expect(\"simple\")) };\n                     self.call(self.type_void(), func, &args.iter().map(|arg| arg.immediate()).collect::<Vec<_>>(), None)\n                 },\n@@ -118,40 +118,12 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                 }\n                 sym::breakpoint => {\n                     unimplemented!();\n-                    /*let llfn = self.get_intrinsic(&(\"llvm.debugtrap\"));\n-                    self.call(llfn, &[], None)*/\n                 }\n                 sym::va_copy => {\n                     unimplemented!();\n-                    /*let intrinsic = self.cx().get_intrinsic(&(\"llvm.va_copy\"));\n-                    self.call(intrinsic, &[args[0].immediate(), args[1].immediate()], None)*/\n                 }\n                 sym::va_arg => {\n                     unimplemented!();\n-                    /*match fn_abi.ret.layout.abi {\n-                        abi::Abi::Scalar(ref scalar) => {\n-                            match scalar.value {\n-                                Primitive::Int(..) => {\n-                                    if self.cx().size_of(ret_ty).bytes() < 4 {\n-                                        // `va_arg` should not be called on a integer type\n-                                        // less than 4 bytes in length. If it is, promote\n-                                        // the integer to a `i32` and truncate the result\n-                                        // back to the smaller type.\n-                                        let promoted_result = emit_va_arg(self, args[0], tcx.types.i32);\n-                                        self.trunc(promoted_result, llret_ty)\n-                                    } else {\n-                                        emit_va_arg(self, args[0], ret_ty)\n-                                    }\n-                                }\n-                                Primitive::F64 | Primitive::Pointer => {\n-                                    emit_va_arg(self, args[0], ret_ty)\n-                                }\n-                                // `va_arg` should never be used with the return type f32.\n-                                Primitive::F32 => bug!(\"the va_arg intrinsic does not work with `f32`\"),\n-                            }\n-                        }\n-                        _ => bug!(\"the va_arg intrinsic does not work with non-scalar types\"),\n-                    }*/\n                 }\n \n                 sym::volatile_load | sym::unaligned_volatile_load => {\n@@ -161,15 +133,7 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                         ptr = self.pointercast(ptr, self.type_ptr_to(ty.gcc_type(self)));\n                     }\n                     let load = self.volatile_load(ptr.get_type(), ptr);\n-                    // TODO\n-                    /*let align = if name == sym::unaligned_volatile_load {\n-                        1\n-                    } else {\n-                        self.align_of(tp_ty).bytes() as u32\n-                    };\n-                    unsafe {\n-                      llvm::LLVMSetAlignment(load, align);\n-                      }*/\n+                    // TODO(antoyo): set alignment.\n                     self.to_immediate(load, self.layout_of(tp_ty))\n                 }\n                 sym::volatile_store => {\n@@ -187,24 +151,6 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                     | sym::prefetch_read_instruction\n                     | sym::prefetch_write_instruction => {\n                         unimplemented!();\n-                        /*let expect = self.get_intrinsic(&(\"llvm.prefetch\"));\n-                        let (rw, cache_type) = match name {\n-                            sym::prefetch_read_data => (0, 1),\n-                            sym::prefetch_write_data => (1, 1),\n-                            sym::prefetch_read_instruction => (0, 0),\n-                            sym::prefetch_write_instruction => (1, 0),\n-                            _ => bug!(),\n-                        };\n-                        self.call(\n-                            expect,\n-                            &[\n-                            args[0].immediate(),\n-                            self.const_i32(rw),\n-                            args[1].immediate(),\n-                            self.const_i32(cache_type),\n-                            ],\n-                            None,\n-                        )*/\n                     }\n                 sym::ctlz\n                     | sym::ctlz_nonzero\n@@ -257,10 +203,6 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                                     self.block = Some(after_block);\n \n                                     result.to_rvalue()\n-\n-                                    /*let y = self.const_bool(false);\n-                                    let llfn = self.get_intrinsic(&format!(\"llvm.{}.i{}\", name, width));\n-                                    self.call(llfn, &[args[0].immediate(), y], None)*/\n                                 }\n                                 sym::ctlz_nonzero => {\n                                     self.count_leading_zeroes(width, args[0].immediate())\n@@ -274,11 +216,11 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                                         args[0].immediate() // byte swap a u8/i8 is just a no-op\n                                     }\n                                     else {\n-                                        // TODO: check if it's faster to use string literals and a\n+                                        // TODO(antoyo): check if it's faster to use string literals and a\n                                         // match instead of format!.\n                                         let bswap = self.cx.context.get_builtin_function(&format!(\"__builtin_bswap{}\", width));\n                                         let mut arg = args[0].immediate();\n-                                        // FIXME: this cast should not be necessary. Remove\n+                                        // FIXME(antoyo): this cast should not be necessary. Remove\n                                         // when having proper sized integer types.\n                                         let param_type = bswap.get_param(0).to_rvalue().get_type();\n                                         if param_type != arg.get_type() {\n@@ -289,7 +231,7 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                                 },\n                                 sym::bitreverse => self.bit_reverse(width, args[0].immediate()),\n                                 sym::rotate_left | sym::rotate_right => {\n-                                    // TODO: implement using algorithm from:\n+                                    // TODO(antoyo): implement using algorithm from:\n                                     // https://blog.regehr.org/archives/1063\n                                     // for other platforms.\n                                     let is_left = name == sym::rotate_left;\n@@ -346,7 +288,7 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n                         self.const_bool(true)\n                     }\n                     /*else if use_integer_compare {\n-                        let integer_ty = self.type_ix(layout.size.bits()); // FIXME: LLVM creates an integer of 96 bits for [i32; 3], but gcc doesn't support this, so it creates an integer of 128 bits.\n+                        let integer_ty = self.type_ix(layout.size.bits()); // FIXME(antoyo): LLVM creates an integer of 96 bits for [i32; 3], but gcc doesn't support this, so it creates an integer of 128 bits.\n                         let ptr_ty = self.type_ptr_to(integer_ty);\n                         let a_ptr = self.bitcast(a, ptr_ty);\n                         let a_val = self.load(integer_ty, a_ptr, layout.align.abi);\n@@ -396,38 +338,27 @@ impl<'a, 'gcc, 'tcx> IntrinsicCallMethods<'tcx> for Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn assume(&mut self, value: Self::Value) {\n-        // TODO: switch to asumme when it exists.\n+        // TODO(antoyo): switch to asumme when it exists.\n         // Or use something like this:\n         // #define __assume(cond) do { if (!(cond)) __builtin_unreachable(); } while (0)\n         self.expect(value, true);\n     }\n \n     fn expect(&mut self, cond: Self::Value, _expected: bool) -> Self::Value {\n-        // TODO\n-        /*let expect = self.context.get_builtin_function(\"__builtin_expect\");\n-        let expect: RValue<'gcc> = unsafe { std::mem::transmute(expect) };\n-        self.call(expect, &[cond, self.const_bool(expected)], None)*/\n+        // TODO(antoyo)\n         cond\n     }\n \n     fn sideeffect(&mut self) {\n-        // TODO\n-        /*if self.tcx().sess.opts.debugging_opts.insert_sideeffect {\n-            let fnname = self.get_intrinsic(&(\"llvm.sideeffect\"));\n-            self.call(fnname, &[], None);\n-        }*/\n+        // TODO(antoyo)\n     }\n \n     fn va_start(&mut self, _va_list: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*let intrinsic = self.cx().get_intrinsic(\"llvm.va_start\");\n-        self.call(intrinsic, &[va_list], None)*/\n     }\n \n     fn va_end(&mut self, _va_list: RValue<'gcc>) -> RValue<'gcc> {\n         unimplemented!();\n-        /*let intrinsic = self.cx().get_intrinsic(\"llvm.va_end\");\n-        self.call(intrinsic, &[va_list], None)*/\n     }\n }\n \n@@ -634,7 +565,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n                 step4\n             },\n             32 => {\n-                // TODO: Refactor with other implementations.\n+                // TODO(antoyo): Refactor with other implementations.\n                 // First step.\n                 let left = self.and(value, context.new_rvalue_from_long(typ, 0x55555555));\n                 let left = self.shl(left, context.new_rvalue_from_long(typ, 1));\n@@ -681,7 +612,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n                 // Second step.\n                 let left = self.and(step1, context.new_rvalue_from_long(typ, 0x0001FFFF0001FFFF));\n                 let left = self.shl(left, context.new_rvalue_from_long(typ, 15));\n-                let right = self.and(step1, context.new_rvalue_from_long(typ, 0xFFFE0000FFFE0000u64 as i64)); // TODO: transmute the number instead?\n+                let right = self.and(step1, context.new_rvalue_from_long(typ, 0xFFFE0000FFFE0000u64 as i64)); // TODO(antoyo): transmute the number instead?\n                 let right = self.lshr(right, context.new_rvalue_from_long(typ, 17));\n                 let step2 = self.or(left, right);\n \n@@ -715,7 +646,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n                 step5\n             },\n             128 => {\n-                // TODO: find a more efficient implementation?\n+                // TODO(antoyo): find a more efficient implementation?\n                 let sixty_four = self.context.new_rvalue_from_long(typ, 64);\n                 let high = self.context.new_cast(None, value >> sixty_four, self.u64_type);\n                 let low = self.context.new_cast(None, value, self.u64_type);\n@@ -735,7 +666,7 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn count_leading_zeroes(&self, width: u64, arg: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: use width?\n+        // TODO(antoyo): use width?\n         let arg_type = arg.get_type();\n         let count_leading_zeroes =\n             if arg_type.is_uint(&self.cx) {\n@@ -873,11 +804,11 @@ impl<'a, 'gcc, 'tcx> Builder<'a, 'gcc, 'tcx> {\n     }\n \n     fn pop_count(&self, value: RValue<'gcc>) -> RValue<'gcc> {\n-        // TODO: use the optimized version with fewer operations.\n+        // TODO(antoyo): use the optimized version with fewer operations.\n         let value_type = value.get_type();\n \n         if value_type.is_u128(&self.cx) {\n-            // TODO: implement in the normal algorithm below to have a more efficient\n+            // TODO(antoyo): implement in the normal algorithm below to have a more efficient\n             // implementation (that does not require a call to __popcountdi2).\n             let popcount = self.context.get_builtin_function(\"__builtin_popcountll\");\n             let sixty_four = self.context.new_rvalue_from_long(value_type, 64);\n@@ -1083,204 +1014,8 @@ fn try_intrinsic<'gcc, 'tcx>(bx: &mut Builder<'_, 'gcc, 'tcx>, try_func: RValue<\n     }\n     else if wants_msvc_seh(bx.sess()) {\n         unimplemented!();\n-        //codegen_msvc_try(bx, try_func, data, catch_func, dest);\n     }\n     else {\n         unimplemented!();\n-        //codegen_gnu_try(bx, try_func, data, catch_func, dest);\n     }\n }\n-\n-// MSVC's definition of the `rust_try` function.\n-//\n-// This implementation uses the new exception handling instructions in LLVM\n-// which have support in LLVM for SEH on MSVC targets. Although these\n-// instructions are meant to work for all targets, as of the time of this\n-// writing, however, LLVM does not recommend the usage of these new instructions\n-// as the old ones are still more optimized.\n-/*fn codegen_msvc_try<'a, 'gcc, 'tcx>(_bx: &mut Builder<'a, 'gcc, 'tcx>, _try_func: RValue<'gcc>, _data: RValue<'gcc>, _catch_func: RValue<'gcc>, _dest: RValue<'gcc>) {\n-    unimplemented!();\n-    /*let llfn = get_rust_try_fn(bx, &mut |mut bx| {\n-        bx.set_personality_fn(bx.eh_personality());\n-        bx.sideeffect();\n-\n-        let mut normal = bx.build_sibling_block(\"normal\");\n-        let mut catchswitch = bx.build_sibling_block(\"catchswitch\");\n-        let mut catchpad = bx.build_sibling_block(\"catchpad\");\n-        let mut caught = bx.build_sibling_block(\"caught\");\n-\n-        let try_func = llvm::get_param(bx.llfn(), 0);\n-        let data = llvm::get_param(bx.llfn(), 1);\n-        let catch_func = llvm::get_param(bx.llfn(), 2);\n-\n-        // We're generating an IR snippet that looks like:\n-        //\n-        //   declare i32 @rust_try(%try_func, %data, %catch_func) {\n-        //      %slot = alloca u8*\n-        //      invoke %try_func(%data) to label %normal unwind label %catchswitch\n-        //\n-        //   normal:\n-        //      ret i32 0\n-        //\n-        //   catchswitch:\n-        //      %cs = catchswitch within none [%catchpad] unwind to caller\n-        //\n-        //   catchpad:\n-        //      %tok = catchpad within %cs [%type_descriptor, 0, %slot]\n-        //      %ptr = load %slot\n-        //      call %catch_func(%data, %ptr)\n-        //      catchret from %tok to label %caught\n-        //\n-        //   caught:\n-        //      ret i32 1\n-        //   }\n-        //\n-        // This structure follows the basic usage of throw/try/catch in LLVM.\n-        // For example, compile this C++ snippet to see what LLVM generates:\n-        //\n-        //      #include <stdint.h>\n-        //\n-        //      struct rust_panic {\n-        //          rust_panic(const rust_panic&);\n-        //          ~rust_panic();\n-        //\n-        //          uint64_t x[2];\n-        //      };\n-        //\n-        //      int __rust_try(\n-        //          void (*try_func)(void*),\n-        //          void *data,\n-        //          void (*catch_func)(void*, void*) noexcept\n-        //      ) {\n-        //          try {\n-        //              try_func(data);\n-        //              return 0;\n-        //          } catch(rust_panic& a) {\n-        //              catch_func(data, &a);\n-        //              return 1;\n-        //          }\n-        //      }\n-        //\n-        // More information can be found in libstd's seh.rs implementation.\n-        let ptr_align = bx.tcx().data_layout.pointer_align.abi;\n-        let slot = bx.alloca(bx.type_i8p(), ptr_align);\n-        bx.invoke(try_func, &[data], normal.llbb(), catchswitch.llbb(), None);\n-\n-        normal.ret(bx.const_i32(0));\n-\n-        let cs = catchswitch.catch_switch(None, None, 1);\n-        catchswitch.add_handler(cs, catchpad.llbb());\n-\n-        // We can't use the TypeDescriptor defined in libpanic_unwind because it\n-        // might be in another DLL and the SEH encoding only supports specifying\n-        // a TypeDescriptor from the current module.\n-        //\n-        // However this isn't an issue since the MSVC runtime uses string\n-        // comparison on the type name to match TypeDescriptors rather than\n-        // pointer equality.\n-        //\n-        // So instead we generate a new TypeDescriptor in each module that uses\n-        // `try` and let the linker merge duplicate definitions in the same\n-        // module.\n-        //\n-        // When modifying, make sure that the type_name string exactly matches\n-        // the one used in src/libpanic_unwind/seh.rs.\n-        let type_info_vtable = bx.declare_global(\"??_7type_info@@6B@\", bx.type_i8p());\n-        let type_name = bx.const_bytes(b\"rust_panic\\0\");\n-        let type_info =\n-            bx.const_struct(&[type_info_vtable, bx.const_null(bx.type_i8p()), type_name], false);\n-        let tydesc = bx.declare_global(\"__rust_panic_type_info\", bx.val_ty(type_info));\n-        unsafe {\n-            llvm::LLVMRustSetLinkage(tydesc, llvm::Linkage::LinkOnceODRLinkage);\n-            llvm::SetUniqueComdat(bx.llmod, tydesc);\n-            llvm::LLVMSetInitializer(tydesc, type_info);\n-        }\n-\n-        // The flag value of 8 indicates that we are catching the exception by\n-        // reference instead of by value. We can't use catch by value because\n-        // that requires copying the exception object, which we don't support\n-        // since our exception object effectively contains a Box.\n-        //\n-        // Source: MicrosoftCXXABI::getAddrOfCXXCatchHandlerType in clang\n-        let flags = bx.const_i32(8);\n-        let funclet = catchpad.catch_pad(cs, &[tydesc, flags, slot]);\n-        let ptr = catchpad.load(slot, ptr_align);\n-        catchpad.call(catch_func, &[data, ptr], Some(&funclet));\n-\n-        catchpad.catch_ret(&funclet, caught.llbb());\n-\n-        caught.ret(bx.const_i32(1));\n-    });\n-\n-    // Note that no invoke is used here because by definition this function\n-    // can't panic (that's what it's catching).\n-    let ret = bx.call(llfn, &[try_func, data, catch_func], None);\n-    let i32_align = bx.tcx().data_layout.i32_align.abi;\n-    bx.store(ret, dest, i32_align);*/\n-}*/\n-\n-// Definition of the standard `try` function for Rust using the GNU-like model\n-// of exceptions (e.g., the normal semantics of LLVM's `landingpad` and `invoke`\n-// instructions).\n-//\n-// This codegen is a little surprising because we always call a shim\n-// function instead of inlining the call to `invoke` manually here. This is done\n-// because in LLVM we're only allowed to have one personality per function\n-// definition. The call to the `try` intrinsic is being inlined into the\n-// function calling it, and that function may already have other personality\n-// functions in play. By calling a shim we're guaranteed that our shim will have\n-// the right personality function.\n-/*fn codegen_gnu_try<'a, 'gcc, 'tcx>(_bx: &mut Builder<'a, 'gcc, 'tcx>, _try_func: RValue<'gcc>, _data: RValue<'gcc>, _catch_func: RValue<'gcc>, _dest: RValue<'gcc>) {\n-    unimplemented!();\n-    /*let llfn = get_rust_try_fn(bx, &mut |mut bx| {\n-        // Codegens the shims described above:\n-        //\n-        //   bx:\n-        //      invoke %try_func(%data) normal %normal unwind %catch\n-        //\n-        //   normal:\n-        //      ret 0\n-        //\n-        //   catch:\n-        //      (%ptr, _) = landingpad\n-        //      call %catch_func(%data, %ptr)\n-        //      ret 1\n-\n-        bx.sideeffect();\n-\n-        let mut then = bx.build_sibling_block(\"then\");\n-        let mut catch = bx.build_sibling_block(\"catch\");\n-\n-        let try_func = llvm::get_param(bx.llfn(), 0);\n-        let data = llvm::get_param(bx.llfn(), 1);\n-        let catch_func = llvm::get_param(bx.llfn(), 2);\n-        bx.invoke(try_func, &[data], then.llbb(), catch.llbb(), None);\n-        then.ret(bx.const_i32(0));\n-\n-        // Type indicator for the exception being thrown.\n-        //\n-        // The first value in this tuple is a pointer to the exception object\n-        // being thrown.  The second value is a \"selector\" indicating which of\n-        // the landing pad clauses the exception's type had been matched to.\n-        // rust_try ignores the selector.\n-        let lpad_ty = bx.type_struct(&[bx.type_i8p(), bx.type_i32()], false);\n-        let vals = catch.landing_pad(lpad_ty, bx.eh_personality(), 1);\n-        let tydesc = match bx.tcx().lang_items().eh_catch_typeinfo() {\n-            Some(tydesc) => {\n-                let tydesc = bx.get_static(tydesc);\n-                bx.bitcast(tydesc, bx.type_i8p())\n-            }\n-            None => bx.const_null(bx.type_i8p()),\n-        };\n-        catch.add_clause(vals, tydesc);\n-        let ptr = catch.extract_value(vals, 0);\n-        catch.call(catch_func, &[data, ptr], None);\n-        catch.ret(bx.const_i32(1));\n-    });\n-\n-    // Note that no invoke is used here because by definition this function\n-    // can't panic (that's what it's catching).\n-    let ret = bx.call(llfn, &[try_func, data, catch_func], None);\n-    let i32_align = bx.tcx().data_layout.i32_align.abi;\n-    bx.store(ret, dest, i32_align);*/\n-}*/"}, {"sha": "26a42217e4c56b192abe335b8e53d0ad286e4870", "filename": "src/intrinsic/simd.rs", "status": "modified", "additions": 1, "deletions": 835, "changes": 836, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fsimd.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fintrinsic%2Fsimd.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fintrinsic%2Fsimd.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -12,8 +12,6 @@ use rustc_span::{Span, Symbol, sym};\n use crate::builder::Builder;\n \n pub fn generic_simd_intrinsic<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, name: Symbol, callee_ty: Ty<'tcx>, args: &[OperandRef<'tcx, RValue<'gcc>>], ret_ty: Ty<'tcx>, llret_ty: Type<'gcc>, span: Span) -> Result<RValue<'gcc>, ()> {\n-    //println!(\"Generic simd: {}\", name);\n-\n     // macros for error handling:\n     macro_rules! emit_error {\n         ($msg: tt) => {\n@@ -56,33 +54,6 @@ pub fn generic_simd_intrinsic<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>,\n     let arg_tys = sig.inputs();\n     let name_str = &*name.as_str();\n \n-    /*if name == sym::simd_select_bitmask {\n-        let in_ty = arg_tys[0];\n-        let m_len = match in_ty.kind() {\n-            // Note that this `.unwrap()` crashes for isize/usize, that's sort\n-            // of intentional as there's not currently a use case for that.\n-            ty::Int(i) => i.bit_width().unwrap(),\n-            ty::Uint(i) => i.bit_width().unwrap(),\n-            _ => return_error!(\"`{}` is not an integral type\", in_ty),\n-        };\n-        require_simd!(arg_tys[1], \"argument\");\n-        let (v_len, _) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        require!(\n-            // Allow masks for vectors with fewer than 8 elements to be\n-            // represented with a u8 or i8.\n-            m_len == v_len || (m_len == 8 && v_len < 8),\n-            \"mismatched lengths: mask length `{}` != other vector length `{}`\",\n-            m_len,\n-            v_len\n-        );\n-        let i1 = bx.type_i1();\n-        let im = bx.type_ix(v_len);\n-        let i1xn = bx.type_vector(i1, v_len);\n-        let m_im = bx.trunc(args[0].immediate(), im);\n-        let m_i1s = bx.bitcast(m_im, i1xn);\n-        return Ok(bx.select(m_i1s, args[1].immediate(), args[2].immediate()));\n-    }*/\n-\n     // every intrinsic below takes a SIMD vector as its first argument\n     require_simd!(arg_tys[0], \"input\");\n     let in_ty = arg_tys[0];\n@@ -153,761 +124,15 @@ pub fn generic_simd_intrinsic<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>,\n             out_ty\n         );\n \n-        //let total_len = u128::from(in_len) * 2;\n-\n         let vector = args[2].immediate();\n \n-        // TODO:\n-        /*let indices: Option<Vec<_>> = (0..n)\n-            .map(|i| {\n-                let arg_idx = i;\n-                let val = bx.const_get_vector_element(vector, i as u64);\n-                match bx.const_to_opt_u128(val, true) {\n-                    None => {\n-                        emit_error!(\"shuffle index #{} is not a constant\", arg_idx);\n-                        None\n-                    }\n-                    Some(idx) if idx >= total_len => {\n-                        emit_error!(\n-                            \"shuffle index #{} is out of bounds (limit {})\",\n-                            arg_idx,\n-                            total_len\n-                        );\n-                        None\n-                    }\n-                    Some(idx) => Some(bx.const_i32(idx as i32)),\n-                }\n-            })\n-            .collect();\n-        let indices = match indices {\n-            Some(i) => i,\n-            None => return Ok(bx.const_null(llret_ty)),\n-        };*/\n-\n         return Ok(bx.shuffle_vector(\n             args[0].immediate(),\n             args[1].immediate(),\n             vector,\n         ));\n     }\n \n-    /*if name == sym::simd_insert {\n-        require!(\n-            in_elem == arg_tys[2],\n-            \"expected inserted type `{}` (element of input `{}`), found `{}`\",\n-            in_elem,\n-            in_ty,\n-            arg_tys[2]\n-        );\n-        return Ok(bx.insert_element(\n-            args[0].immediate(),\n-            args[2].immediate(),\n-            args[1].immediate(),\n-        ));\n-    }\n-    if name == sym::simd_extract {\n-        require!(\n-            ret_ty == in_elem,\n-            \"expected return type `{}` (element of input `{}`), found `{}`\",\n-            in_elem,\n-            in_ty,\n-            ret_ty\n-        );\n-        return Ok(bx.extract_element(args[0].immediate(), args[1].immediate()));\n-    }\n-\n-    if name == sym::simd_select {\n-        let m_elem_ty = in_elem;\n-        let m_len = in_len;\n-        require_simd!(arg_tys[1], \"argument\");\n-        let (v_len, _) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        require!(\n-            m_len == v_len,\n-            \"mismatched lengths: mask length `{}` != other vector length `{}`\",\n-            m_len,\n-            v_len\n-        );\n-        match m_elem_ty.kind() {\n-            ty::Int(_) => {}\n-            _ => return_error!(\"mask element type is `{}`, expected `i_`\", m_elem_ty),\n-        }\n-        // truncate the mask to a vector of i1s\n-        let i1 = bx.type_i1();\n-        let i1xn = bx.type_vector(i1, m_len as u64);\n-        let m_i1s = bx.trunc(args[0].immediate(), i1xn);\n-        return Ok(bx.select(m_i1s, args[1].immediate(), args[2].immediate()));\n-    }\n-\n-    if name == sym::simd_bitmask {\n-        // The `fn simd_bitmask(vector) -> unsigned integer` intrinsic takes a\n-        // vector mask and returns an unsigned integer containing the most\n-        // significant bit (MSB) of each lane.\n-\n-        // If the vector has less than 8 lanes, an u8 is returned with zeroed\n-        // trailing bits.\n-        let expected_int_bits = in_len.max(8);\n-        match ret_ty.kind() {\n-            ty::Uint(i) if i.bit_width() == Some(expected_int_bits) => (),\n-            _ => return_error!(\"bitmask `{}`, expected `u{}`\", ret_ty, expected_int_bits),\n-        }\n-\n-        // Integer vector <i{in_bitwidth} x in_len>:\n-        let (i_xn, in_elem_bitwidth) = match in_elem.kind() {\n-            ty::Int(i) => (\n-                args[0].immediate(),\n-                i.bit_width().unwrap_or_else(|| bx.data_layout().pointer_size.bits()),\n-            ),\n-            ty::Uint(i) => (\n-                args[0].immediate(),\n-                i.bit_width().unwrap_or_else(|| bx.data_layout().pointer_size.bits()),\n-            ),\n-            _ => return_error!(\n-                \"vector argument `{}`'s element type `{}`, expected integer element type\",\n-                in_ty,\n-                in_elem\n-            ),\n-        };\n-\n-        // Shift the MSB to the right by \"in_elem_bitwidth - 1\" into the first bit position.\n-        let shift_indices =\n-            vec![\n-                bx.cx.const_int(bx.type_ix(in_elem_bitwidth), (in_elem_bitwidth - 1) as _);\n-                in_len as _\n-            ];\n-        let i_xn_msb = bx.lshr(i_xn, bx.const_vector(shift_indices.as_slice()));\n-        // Truncate vector to an <i1 x N>\n-        let i1xn = bx.trunc(i_xn_msb, bx.type_vector(bx.type_i1(), in_len));\n-        // Bitcast <i1 x N> to iN:\n-        let i_ = bx.bitcast(i1xn, bx.type_ix(in_len));\n-        // Zero-extend iN to the bitmask type:\n-        return Ok(bx.zext(i_, bx.type_ix(expected_int_bits)));\n-    }\n-\n-    fn simd_simple_float_intrinsic<'a, 'gcc, 'tcx>(\n-        name: Symbol,\n-        in_elem: &::rustc_middle::ty::TyS<'_>,\n-        in_ty: &::rustc_middle::ty::TyS<'_>,\n-        in_len: u64,\n-        bx: &mut Builder<'a, 'gcc, 'tcx>,\n-        span: Span,\n-        args: &[OperandRef<'tcx, RValue<'gcc>>],\n-    ) -> Result<RValue<'gcc>, ()> {\n-        macro_rules! emit_error {\n-            ($msg: tt) => {\n-                emit_error!($msg, )\n-            };\n-            ($msg: tt, $($fmt: tt)*) => {\n-                span_invalid_monomorphization_error(\n-                    bx.sess(), span,\n-                    &format!(concat!(\"invalid monomorphization of `{}` intrinsic: \", $msg),\n-                             name, $($fmt)*));\n-            }\n-        }\n-        macro_rules! return_error {\n-            ($($fmt: tt)*) => {\n-                {\n-                    emit_error!($($fmt)*);\n-                    return Err(());\n-                }\n-            }\n-        }\n-\n-        let (elem_ty_str, elem_ty) = if let ty::Float(f) = in_elem.kind() {\n-            let elem_ty = bx.cx.type_float_from_ty(*f);\n-            match f.bit_width() {\n-                32 => (\"f32\", elem_ty),\n-                64 => (\"f64\", elem_ty),\n-                _ => {\n-                    return_error!(\n-                        \"unsupported element type `{}` of floating-point vector `{}`\",\n-                        f.name_str(),\n-                        in_ty\n-                    );\n-                }\n-            }\n-        } else {\n-            return_error!(\"`{}` is not a floating-point type\", in_ty);\n-        };\n-\n-        let vec_ty = bx.type_vector(elem_ty, in_len);\n-\n-        let (intr_name, fn_ty) = match name {\n-            sym::simd_ceil => (\"ceil\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fabs => (\"fabs\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fcos => (\"cos\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fexp2 => (\"exp2\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fexp => (\"exp\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_flog10 => (\"log10\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_flog2 => (\"log2\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_flog => (\"log\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_floor => (\"floor\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fma => (\"fma\", bx.type_func(&[vec_ty, vec_ty, vec_ty], vec_ty)),\n-            sym::simd_fpowi => (\"powi\", bx.type_func(&[vec_ty, bx.type_i32()], vec_ty)),\n-            sym::simd_fpow => (\"pow\", bx.type_func(&[vec_ty, vec_ty], vec_ty)),\n-            sym::simd_fsin => (\"sin\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_fsqrt => (\"sqrt\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_round => (\"round\", bx.type_func(&[vec_ty], vec_ty)),\n-            sym::simd_trunc => (\"trunc\", bx.type_func(&[vec_ty], vec_ty)),\n-            _ => return_error!(\"unrecognized intrinsic `{}`\", name),\n-        };\n-        let llvm_name = &format!(\"llvm.{0}.v{1}{2}\", intr_name, in_len, elem_ty_str);\n-        let f = bx.declare_cfn(&llvm_name, fn_ty);\n-        let c = bx.call(f, &args.iter().map(|arg| arg.immediate()).collect::<Vec<_>>(), None);\n-        Ok(c)\n-    }\n-\n-    if std::matches!(\n-        name,\n-        sym::simd_ceil\n-            | sym::simd_fabs\n-            | sym::simd_fcos\n-            | sym::simd_fexp2\n-            | sym::simd_fexp\n-            | sym::simd_flog10\n-            | sym::simd_flog2\n-            | sym::simd_flog\n-            | sym::simd_floor\n-            | sym::simd_fma\n-            | sym::simd_fpow\n-            | sym::simd_fpowi\n-            | sym::simd_fsin\n-            | sym::simd_fsqrt\n-            | sym::simd_round\n-            | sym::simd_trunc\n-    ) {\n-        return simd_simple_float_intrinsic(name, in_elem, in_ty, in_len, bx, span, args);\n-    }\n-\n-    // FIXME: use:\n-    //  https://github.com/llvm-mirror/llvm/blob/master/include/llvm/IR/Function.h#L182\n-    //  https://github.com/llvm-mirror/llvm/blob/master/include/llvm/IR/Intrinsics.h#L81\n-    fn llvm_vector_str(elem_ty: Ty<'_>, vec_len: u64, no_pointers: usize) -> String {\n-        let p0s: String = \"p0\".repeat(no_pointers);\n-        match *elem_ty.kind() {\n-            ty::Int(v) => format!(\"v{}{}i{}\", vec_len, p0s, v.bit_width().unwrap()),\n-            ty::Uint(v) => format!(\"v{}{}i{}\", vec_len, p0s, v.bit_width().unwrap()),\n-            ty::Float(v) => format!(\"v{}{}f{}\", vec_len, p0s, v.bit_width()),\n-            _ => unreachable!(),\n-        }\n-    }\n-\n-    fn gcc_vector_ty<'gcc>(\n-        cx: &CodegenCx<'gcc, '_>,\n-        elem_ty: Ty<'_>,\n-        vec_len: u64,\n-        mut no_pointers: usize,\n-    ) -> Type<'gcc> {\n-        // FIXME: use cx.layout_of(ty).llvm_type() ?\n-        let mut elem_ty = match *elem_ty.kind() {\n-            ty::Int(v) => cx.type_int_from_ty(v),\n-            ty::Uint(v) => cx.type_uint_from_ty(v),\n-            ty::Float(v) => cx.type_float_from_ty(v),\n-            _ => unreachable!(),\n-        };\n-        while no_pointers > 0 {\n-            elem_ty = cx.type_ptr_to(elem_ty);\n-            no_pointers -= 1;\n-        }\n-        cx.type_vector(elem_ty, vec_len)\n-    }\n-\n-    if name == sym::simd_gather {\n-        // simd_gather(values: <N x T>, pointers: <N x *_ T>,\n-        //             mask: <N x i{M}>) -> <N x T>\n-        // * N: number of elements in the input vectors\n-        // * T: type of the element to load\n-        // * M: any integer width is supported, will be truncated to i1\n-\n-        // All types must be simd vector types\n-        require_simd!(in_ty, \"first\");\n-        require_simd!(arg_tys[1], \"second\");\n-        require_simd!(arg_tys[2], \"third\");\n-        require_simd!(ret_ty, \"return\");\n-\n-        // Of the same length:\n-        let (out_len, _) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        let (out_len2, _) = arg_tys[2].simd_size_and_type(bx.tcx());\n-        require!(\n-            in_len == out_len,\n-            \"expected {} argument with length {} (same as input type `{}`), \\\n-             found `{}` with length {}\",\n-            \"second\",\n-            in_len,\n-            in_ty,\n-            arg_tys[1],\n-            out_len\n-        );\n-        require!(\n-            in_len == out_len2,\n-            \"expected {} argument with length {} (same as input type `{}`), \\\n-             found `{}` with length {}\",\n-            \"third\",\n-            in_len,\n-            in_ty,\n-            arg_tys[2],\n-            out_len2\n-        );\n-\n-        // The return type must match the first argument type\n-        require!(ret_ty == in_ty, \"expected return type `{}`, found `{}`\", in_ty, ret_ty);\n-\n-        // This counts how many pointers\n-        fn ptr_count(t: Ty<'_>) -> usize {\n-            match t.kind() {\n-                ty::RawPtr(p) => 1 + ptr_count(p.ty),\n-                _ => 0,\n-            }\n-        }\n-\n-        // Non-ptr type\n-        fn non_ptr(t: Ty<'_>) -> Ty<'_> {\n-            match t.kind() {\n-                ty::RawPtr(p) => non_ptr(p.ty),\n-                _ => t,\n-            }\n-        }\n-\n-        // The second argument must be a simd vector with an element type that's a pointer\n-        // to the element type of the first argument\n-        let (_, element_ty0) = arg_tys[0].simd_size_and_type(bx.tcx());\n-        let (_, element_ty1) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        let (pointer_count, underlying_ty) = match element_ty1.kind() {\n-            ty::RawPtr(p) if p.ty == in_elem => (ptr_count(element_ty1), non_ptr(element_ty1)),\n-            _ => {\n-                require!(\n-                    false,\n-                    \"expected element type `{}` of second argument `{}` \\\n-                        to be a pointer to the element type `{}` of the first \\\n-                        argument `{}`, found `{}` != `*_ {}`\",\n-                    element_ty1,\n-                    arg_tys[1],\n-                    in_elem,\n-                    in_ty,\n-                    element_ty1,\n-                    in_elem\n-                );\n-                unreachable!();\n-            }\n-        };\n-        assert!(pointer_count > 0);\n-        assert_eq!(pointer_count - 1, ptr_count(element_ty0));\n-        assert_eq!(underlying_ty, non_ptr(element_ty0));\n-\n-        // The element type of the third argument must be a signed integer type of any width:\n-        let (_, element_ty2) = arg_tys[2].simd_size_and_type(bx.tcx());\n-        match element_ty2.kind() {\n-            ty::Int(_) => (),\n-            _ => {\n-                require!(\n-                    false,\n-                    \"expected element type `{}` of third argument `{}` \\\n-                                 to be a signed integer type\",\n-                    element_ty2,\n-                    arg_tys[2]\n-                );\n-            }\n-        }\n-\n-        // Alignment of T, must be a constant integer value:\n-        let alignment_ty = bx.type_i32();\n-        let alignment = bx.const_i32(bx.align_of(in_elem).bytes() as i32);\n-\n-        // Truncate the mask vector to a vector of i1s:\n-        let (mask, mask_ty) = {\n-            let i1 = bx.type_i1();\n-            let i1xn = bx.type_vector(i1, in_len);\n-            (bx.trunc(args[2].immediate(), i1xn), i1xn)\n-        };\n-\n-        // Type of the vector of pointers:\n-        let llvm_pointer_vec_ty = gcc_vector_ty(bx, underlying_ty, in_len, pointer_count);\n-        let llvm_pointer_vec_str = llvm_vector_str(underlying_ty, in_len, pointer_count);\n-\n-        // Type of the vector of elements:\n-        let llvm_elem_vec_ty = gcc_vector_ty(bx, underlying_ty, in_len, pointer_count - 1);\n-        let llvm_elem_vec_str = llvm_vector_str(underlying_ty, in_len, pointer_count - 1);\n-\n-        let llvm_intrinsic =\n-            format!(\"llvm.masked.gather.{}.{}\", llvm_elem_vec_str, llvm_pointer_vec_str);\n-        let f = bx.declare_cfn(\n-            &llvm_intrinsic,\n-            bx.type_func(\n-                &[llvm_pointer_vec_ty, alignment_ty, mask_ty, llvm_elem_vec_ty],\n-                llvm_elem_vec_ty,\n-            ),\n-        );\n-        let v = bx.call(f, &[args[1].immediate(), alignment, mask, args[0].immediate()], None);\n-        return Ok(v);\n-    }\n-\n-    if name == sym::simd_scatter {\n-        // simd_scatter(values: <N x T>, pointers: <N x *mut T>,\n-        //             mask: <N x i{M}>) -> ()\n-        // * N: number of elements in the input vectors\n-        // * T: type of the element to load\n-        // * M: any integer width is supported, will be truncated to i1\n-\n-        // All types must be simd vector types\n-        require_simd!(in_ty, \"first\");\n-        require_simd!(arg_tys[1], \"second\");\n-        require_simd!(arg_tys[2], \"third\");\n-\n-        // Of the same length:\n-        let (element_len1, _) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        let (element_len2, _) = arg_tys[2].simd_size_and_type(bx.tcx());\n-        require!(\n-            in_len == element_len1,\n-            \"expected {} argument with length {} (same as input type `{}`), \\\n-            found `{}` with length {}\",\n-            \"second\",\n-            in_len,\n-            in_ty,\n-            arg_tys[1],\n-            element_len1\n-        );\n-        require!(\n-            in_len == element_len2,\n-            \"expected {} argument with length {} (same as input type `{}`), \\\n-            found `{}` with length {}\",\n-            \"third\",\n-            in_len,\n-            in_ty,\n-            arg_tys[2],\n-            element_len2\n-        );\n-\n-        // This counts how many pointers\n-        fn ptr_count(t: Ty<'_>) -> usize {\n-            match t.kind() {\n-                ty::RawPtr(p) => 1 + ptr_count(p.ty),\n-                _ => 0,\n-            }\n-        }\n-\n-        // Non-ptr type\n-        fn non_ptr(t: Ty<'_>) -> Ty<'_> {\n-            match t.kind() {\n-                ty::RawPtr(p) => non_ptr(p.ty),\n-                _ => t,\n-            }\n-        }\n-\n-        // The second argument must be a simd vector with an element type that's a pointer\n-        // to the element type of the first argument\n-        let (_, element_ty0) = arg_tys[0].simd_size_and_type(bx.tcx());\n-        let (_, element_ty1) = arg_tys[1].simd_size_and_type(bx.tcx());\n-        let (_, element_ty2) = arg_tys[2].simd_size_and_type(bx.tcx());\n-        let (pointer_count, underlying_ty) = match element_ty1.kind() {\n-            ty::RawPtr(p) if p.ty == in_elem && p.mutbl == hir::Mutability::Mut => {\n-                (ptr_count(element_ty1), non_ptr(element_ty1))\n-            }\n-            _ => {\n-                require!(\n-                    false,\n-                    \"expected element type `{}` of second argument `{}` \\\n-                        to be a pointer to the element type `{}` of the first \\\n-                        argument `{}`, found `{}` != `*mut {}`\",\n-                    element_ty1,\n-                    arg_tys[1],\n-                    in_elem,\n-                    in_ty,\n-                    element_ty1,\n-                    in_elem\n-                );\n-                unreachable!();\n-            }\n-        };\n-        assert!(pointer_count > 0);\n-        assert_eq!(pointer_count - 1, ptr_count(element_ty0));\n-        assert_eq!(underlying_ty, non_ptr(element_ty0));\n-\n-        // The element type of the third argument must be a signed integer type of any width:\n-        match element_ty2.kind() {\n-            ty::Int(_) => (),\n-            _ => {\n-                require!(\n-                    false,\n-                    \"expected element type `{}` of third argument `{}` \\\n-                         be a signed integer type\",\n-                    element_ty2,\n-                    arg_tys[2]\n-                );\n-            }\n-        }\n-\n-        // Alignment of T, must be a constant integer value:\n-        let alignment_ty = bx.type_i32();\n-        let alignment = bx.const_i32(bx.align_of(in_elem).bytes() as i32);\n-\n-        // Truncate the mask vector to a vector of i1s:\n-        let (mask, mask_ty) = {\n-            let i1 = bx.type_i1();\n-            let i1xn = bx.type_vector(i1, in_len);\n-            (bx.trunc(args[2].immediate(), i1xn), i1xn)\n-        };\n-\n-        let ret_t = bx.type_void();\n-\n-        // Type of the vector of pointers:\n-        let llvm_pointer_vec_ty = gcc_vector_ty(bx, underlying_ty, in_len, pointer_count);\n-        let llvm_pointer_vec_str = llvm_vector_str(underlying_ty, in_len, pointer_count);\n-\n-        // Type of the vector of elements:\n-        let llvm_elem_vec_ty = gcc_vector_ty(bx, underlying_ty, in_len, pointer_count - 1);\n-        let llvm_elem_vec_str = llvm_vector_str(underlying_ty, in_len, pointer_count - 1);\n-\n-        let llvm_intrinsic =\n-            format!(\"llvm.masked.scatter.{}.{}\", llvm_elem_vec_str, llvm_pointer_vec_str);\n-        let f = bx.declare_cfn(\n-            &llvm_intrinsic,\n-            bx.type_func(&[llvm_elem_vec_ty, llvm_pointer_vec_ty, alignment_ty, mask_ty], ret_t),\n-        );\n-        let v = bx.call(f, &[args[0].immediate(), args[1].immediate(), alignment, mask], None);\n-        return Ok(v);\n-    }\n-\n-    macro_rules! arith_red {\n-        ($name:ident : $integer_reduce:ident, $float_reduce:ident, $ordered:expr, $op:ident,\n-         $identity:expr) => {\n-            if name == sym::$name {\n-                require!(\n-                    ret_ty == in_elem,\n-                    \"expected return type `{}` (element of input `{}`), found `{}`\",\n-                    in_elem,\n-                    in_ty,\n-                    ret_ty\n-                );\n-                return match in_elem.kind() {\n-                    ty::Int(_) | ty::Uint(_) => {\n-                        let r = bx.$integer_reduce(args[0].immediate());\n-                        if $ordered {\n-                            // if overflow occurs, the result is the\n-                            // mathematical result modulo 2^n:\n-                            Ok(bx.$op(args[1].immediate(), r))\n-                        } else {\n-                            Ok(bx.$integer_reduce(args[0].immediate()))\n-                        }\n-                    }\n-                    ty::Float(f) => {\n-                        let acc = if $ordered {\n-                            // ordered arithmetic reductions take an accumulator\n-                            args[1].immediate()\n-                        } else {\n-                            // unordered arithmetic reductions use the identity accumulator\n-                            match f.bit_width() {\n-                                32 => bx.const_real(bx.type_f32(), $identity),\n-                                64 => bx.const_real(bx.type_f64(), $identity),\n-                                v => return_error!(\n-                                    r#\"\n-unsupported {} from `{}` with element `{}` of size `{}` to `{}`\"#,\n-                                    sym::$name,\n-                                    in_ty,\n-                                    in_elem,\n-                                    v,\n-                                    ret_ty\n-                                ),\n-                            }\n-                        };\n-                        Ok(bx.$float_reduce(acc, args[0].immediate()))\n-                    }\n-                    _ => return_error!(\n-                        \"unsupported {} from `{}` with element `{}` to `{}`\",\n-                        sym::$name,\n-                        in_ty,\n-                        in_elem,\n-                        ret_ty\n-                    ),\n-                };\n-            }\n-        };\n-    }\n-\n-    arith_red!(simd_reduce_add_ordered: vector_reduce_add, vector_reduce_fadd, true, add, 0.0);\n-    arith_red!(simd_reduce_mul_ordered: vector_reduce_mul, vector_reduce_fmul, true, mul, 1.0);\n-    arith_red!(\n-        simd_reduce_add_unordered: vector_reduce_add,\n-        vector_reduce_fadd_fast,\n-        false,\n-        add,\n-        0.0\n-    );\n-    arith_red!(\n-        simd_reduce_mul_unordered: vector_reduce_mul,\n-        vector_reduce_fmul_fast,\n-        false,\n-        mul,\n-        1.0\n-    );\n-\n-    macro_rules! minmax_red {\n-        ($name:ident: $int_red:ident, $float_red:ident) => {\n-            if name == sym::$name {\n-                require!(\n-                    ret_ty == in_elem,\n-                    \"expected return type `{}` (element of input `{}`), found `{}`\",\n-                    in_elem,\n-                    in_ty,\n-                    ret_ty\n-                );\n-                return match in_elem.kind() {\n-                    ty::Int(_i) => Ok(bx.$int_red(args[0].immediate(), true)),\n-                    ty::Uint(_u) => Ok(bx.$int_red(args[0].immediate(), false)),\n-                    ty::Float(_f) => Ok(bx.$float_red(args[0].immediate())),\n-                    _ => return_error!(\n-                        \"unsupported {} from `{}` with element `{}` to `{}`\",\n-                        sym::$name,\n-                        in_ty,\n-                        in_elem,\n-                        ret_ty\n-                    ),\n-                };\n-            }\n-        };\n-    }\n-\n-    minmax_red!(simd_reduce_min: vector_reduce_min, vector_reduce_fmin);\n-    minmax_red!(simd_reduce_max: vector_reduce_max, vector_reduce_fmax);\n-\n-    minmax_red!(simd_reduce_min_nanless: vector_reduce_min, vector_reduce_fmin_fast);\n-    minmax_red!(simd_reduce_max_nanless: vector_reduce_max, vector_reduce_fmax_fast);\n-\n-    macro_rules! bitwise_red {\n-        ($name:ident : $red:ident, $boolean:expr) => {\n-            if name == sym::$name {\n-                let input = if !$boolean {\n-                    require!(\n-                        ret_ty == in_elem,\n-                        \"expected return type `{}` (element of input `{}`), found `{}`\",\n-                        in_elem,\n-                        in_ty,\n-                        ret_ty\n-                    );\n-                    args[0].immediate()\n-                } else {\n-                    match in_elem.kind() {\n-                        ty::Int(_) | ty::Uint(_) => {}\n-                        _ => return_error!(\n-                            \"unsupported {} from `{}` with element `{}` to `{}`\",\n-                            sym::$name,\n-                            in_ty,\n-                            in_elem,\n-                            ret_ty\n-                        ),\n-                    }\n-\n-                    // boolean reductions operate on vectors of i1s:\n-                    let i1 = bx.type_i1();\n-                    let i1xn = bx.type_vector(i1, in_len as u64);\n-                    bx.trunc(args[0].immediate(), i1xn)\n-                };\n-                return match in_elem.kind() {\n-                    ty::Int(_) | ty::Uint(_) => {\n-                        let r = bx.$red(input);\n-                        Ok(if !$boolean { r } else { bx.zext(r, bx.type_bool()) })\n-                    }\n-                    _ => return_error!(\n-                        \"unsupported {} from `{}` with element `{}` to `{}`\",\n-                        sym::$name,\n-                        in_ty,\n-                        in_elem,\n-                        ret_ty\n-                    ),\n-                };\n-            }\n-        };\n-    }\n-\n-    bitwise_red!(simd_reduce_and: vector_reduce_and, false);\n-    bitwise_red!(simd_reduce_or: vector_reduce_or, false);\n-    bitwise_red!(simd_reduce_xor: vector_reduce_xor, false);\n-    bitwise_red!(simd_reduce_all: vector_reduce_and, true);\n-    bitwise_red!(simd_reduce_any: vector_reduce_or, true);\n-\n-    if name == sym::simd_cast {\n-        require_simd!(ret_ty, \"return\");\n-        let (out_len, out_elem) = ret_ty.simd_size_and_type(bx.tcx());\n-        require!(\n-            in_len == out_len,\n-            \"expected return type with length {} (same as input type `{}`), \\\n-                  found `{}` with length {}\",\n-            in_len,\n-            in_ty,\n-            ret_ty,\n-            out_len\n-        );\n-        // casting cares about nominal type, not just structural type\n-        if in_elem == out_elem {\n-            return Ok(args[0].immediate());\n-        }\n-\n-        enum Style {\n-            Float,\n-            Int(/* is signed? */ bool),\n-            Unsupported,\n-        }\n-\n-        let (in_style, in_width) = match in_elem.kind() {\n-            // vectors of pointer-sized integers should've been\n-            // disallowed before here, so this unwrap is safe.\n-            ty::Int(i) => (Style::Int(true), i.bit_width().unwrap()),\n-            ty::Uint(u) => (Style::Int(false), u.bit_width().unwrap()),\n-            ty::Float(f) => (Style::Float, f.bit_width()),\n-            _ => (Style::Unsupported, 0),\n-        };\n-        let (out_style, out_width) = match out_elem.kind() {\n-            ty::Int(i) => (Style::Int(true), i.bit_width().unwrap()),\n-            ty::Uint(u) => (Style::Int(false), u.bit_width().unwrap()),\n-            ty::Float(f) => (Style::Float, f.bit_width()),\n-            _ => (Style::Unsupported, 0),\n-        };\n-\n-        match (in_style, out_style) {\n-            (Style::Int(in_is_signed), Style::Int(_)) => {\n-                return Ok(match in_width.cmp(&out_width) {\n-                    Ordering::Greater => bx.trunc(args[0].immediate(), llret_ty),\n-                    Ordering::Equal => args[0].immediate(),\n-                    Ordering::Less => {\n-                        if in_is_signed {\n-                            bx.sext(args[0].immediate(), llret_ty)\n-                        } else {\n-                            bx.zext(args[0].immediate(), llret_ty)\n-                        }\n-                    }\n-                });\n-            }\n-            (Style::Int(in_is_signed), Style::Float) => {\n-                return Ok(if in_is_signed {\n-                    bx.sitofp(args[0].immediate(), llret_ty)\n-                } else {\n-                    bx.uitofp(args[0].immediate(), llret_ty)\n-                });\n-            }\n-            (Style::Float, Style::Int(out_is_signed)) => {\n-                return Ok(if out_is_signed {\n-                    bx.fptosi(args[0].immediate(), llret_ty)\n-                } else {\n-                    bx.fptoui(args[0].immediate(), llret_ty)\n-                });\n-            }\n-            (Style::Float, Style::Float) => {\n-                return Ok(match in_width.cmp(&out_width) {\n-                    Ordering::Greater => bx.fptrunc(args[0].immediate(), llret_ty),\n-                    Ordering::Equal => args[0].immediate(),\n-                    Ordering::Less => bx.fpext(args[0].immediate(), llret_ty),\n-                });\n-            }\n-            _ => { /* Unsupported. Fallthrough. */ }\n-        }\n-        require!(\n-            false,\n-            \"unsupported cast from `{}` with element `{}` to `{}` with element `{}`\",\n-            in_ty,\n-            in_elem,\n-            ret_ty,\n-            out_elem\n-        );\n-    }*/\n-\n     macro_rules! arith_binary {\n         ($($name: ident: $($($p: ident),* => $call: ident),*;)*) => {\n             $(if name == sym::$name {\n@@ -934,68 +159,9 @@ unsupported {} from `{}` with element `{}` of size `{}` to `{}`\"#,\n         simd_shl: Uint, Int => shl;\n         simd_shr: Uint => lshr, Int => ashr;\n         simd_and: Uint, Int => and;\n-        simd_or: Uint, Int => or; // FIXME: calling or might not work on vectors.\n+        simd_or: Uint, Int => or; // FIXME(antoyo): calling `or` might not work on vectors.\n         simd_xor: Uint, Int => xor;\n-        /*simd_fmax: Float => maxnum;\n-        simd_fmin: Float => minnum;*/\n     }\n \n-    /*macro_rules! arith_unary {\n-        ($($name: ident: $($($p: ident),* => $call: ident),*;)*) => {\n-            $(if name == sym::$name {\n-                match in_elem.kind() {\n-                    $($(ty::$p(_))|* => {\n-                        return Ok(bx.$call(args[0].immediate()))\n-                    })*\n-                    _ => {},\n-                }\n-                require!(false,\n-                         \"unsupported operation on `{}` with element `{}`\",\n-                         in_ty,\n-                         in_elem)\n-            })*\n-        }\n-    }\n-\n-    arith_unary! {\n-        simd_neg: Int => neg, Float => fneg;\n-    }\n-\n-    if name == sym::simd_saturating_add || name == sym::simd_saturating_sub {\n-        let lhs = args[0].immediate();\n-        let rhs = args[1].immediate();\n-        let is_add = name == sym::simd_saturating_add;\n-        let ptr_bits = bx.tcx().data_layout.pointer_size.bits() as _;\n-        let (signed, elem_width, elem_ty) = match *in_elem.kind() {\n-            ty::Int(i) => (true, i.bit_width().unwrap_or(ptr_bits), bx.cx.type_int_from_ty(i)),\n-            ty::Uint(i) => (false, i.bit_width().unwrap_or(ptr_bits), bx.cx.type_uint_from_ty(i)),\n-            _ => {\n-                return_error!(\n-                    \"expected element type `{}` of vector type `{}` \\\n-                     to be a signed or unsigned integer type\",\n-                    arg_tys[0].simd_size_and_type(bx.tcx()).1,\n-                    arg_tys[0]\n-                );\n-            }\n-        };\n-        let llvm_intrinsic = &format!(\n-            \"llvm.{}{}.sat.v{}i{}\",\n-            if signed { 's' } else { 'u' },\n-            if is_add { \"add\" } else { \"sub\" },\n-            in_len,\n-            elem_width\n-        );\n-        let vec_ty = bx.cx.type_vector(elem_ty, in_len as u64);\n-\n-        let f = bx.declare_cfn(\n-            &llvm_intrinsic,\n-            bx.type_func(&[vec_ty, vec_ty], vec_ty),\n-        );\n-        let v = bx.call(f, &[lhs, rhs], None);\n-        return Ok(v);\n-    }*/\n-\n     unimplemented!(\"simd {}\", name);\n-\n-    //span_bug!(span, \"unknown SIMD intrinsic\");\n }"}, {"sha": "6febccff1ffacd6270f1cd61f6099eac1d1b52f9", "filename": "src/lib.rs", "status": "modified", "additions": 10, "deletions": 39, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -1,10 +1,8 @@\n /*\n- * TODO: support #[inline] attributes.\n- * TODO: support LTO.\n+ * TODO(antoyo): support #[inline] attributes.\n+ * TODO(antoyo): support LTO.\n  *\n- * TODO: remove the local gccjit LD_LIBRARY_PATH in config.sh.\n- * TODO: remove the object dependency.\n- * TODO: remove the patches.\n+ * TODO(antoyo): remove the patches.\n  */\n \n #![feature(rustc_private, decl_macro, associated_type_bounds, never_type, trusted_len)]\n@@ -13,13 +11,10 @@\n #![warn(rust_2018_idioms)]\n #![warn(unused_lifetimes)]\n \n-/*extern crate flate2;\n-extern crate libc;*/\n extern crate rustc_ast;\n extern crate rustc_codegen_ssa;\n extern crate rustc_data_structures;\n extern crate rustc_errors;\n-//extern crate rustc_fs_util;\n extern crate rustc_hir;\n extern crate rustc_metadata;\n extern crate rustc_middle;\n@@ -53,7 +48,6 @@ mod mangled_std_symbols;\n mod mono_item;\n mod type_;\n mod type_of;\n-mod va_arg;\n \n use std::any::Any;\n use std::sync::Arc;\n@@ -119,7 +113,7 @@ impl CodegenBackend for GccCodegenBackend {\n     fn link(&self, sess: &Session, mut codegen_results: CodegenResults, outputs: &OutputFilenames) -> Result<(), ErrorReported> {\n         use rustc_codegen_ssa::back::link::link_binary;\n         if let Some(symbols) = codegen_results.crate_info.exported_symbols.get_mut(&CrateType::Dylib) {\n-            // TODO: remove when global initializer work without calling a function at runtime.\n+            // TODO:(antoyo): remove when global initializer work without calling a function at runtime.\n             // HACK: since this codegen add some symbols (e.g. __gccGlobalCrateInit) and the UI\n             // tests load libstd.so as a dynamic library, and rustc use a version-script to specify\n             // the symbols visibility, we add * to export all symbols.\n@@ -159,7 +153,7 @@ impl ExtraBackendMethods for GccCodegenBackend {\n     }\n \n     fn target_machine_factory(&self, _sess: &Session, _opt_level: OptLevel) -> TargetMachineFactoryFn<Self> {\n-        // TODO: set opt level.\n+        // TODO(antoyo): set opt level.\n         Arc::new(|_| {\n             Ok(())\n         })\n@@ -171,8 +165,7 @@ impl ExtraBackendMethods for GccCodegenBackend {\n \n     fn tune_cpu<'b>(&self, _sess: &'b Session) -> Option<&'b str> {\n         None\n-        // TODO\n-        //llvm_util::tune_cpu(sess)\n+        // TODO(antoyo)\n     }\n }\n \n@@ -197,7 +190,7 @@ pub struct GccContext {\n }\n \n unsafe impl Send for GccContext {}\n-// FIXME: that shouldn't be Sync. Parallel compilation is currently disabled with \"-Zno-parallel-llvm\". Try to disable it here.\n+// FIXME(antoyo): that shouldn't be Sync. Parallel compilation is currently disabled with \"-Zno-parallel-llvm\". Try to disable it here.\n unsafe impl Sync for GccContext {}\n \n impl WriteBackendMethods for GccCodegenBackend {\n@@ -209,16 +202,13 @@ impl WriteBackendMethods for GccCodegenBackend {\n     type ThinBuffer = ThinBuffer;\n \n     fn run_fat_lto(_cgcx: &CodegenContext<Self>, mut modules: Vec<FatLTOInput<Self>>, _cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>) -> Result<LtoModuleCodegen<Self>, FatalError> {\n-        // TODO: implement LTO by sending -flto to libgccjit and adding the appropriate gcc linker plugins.\n+        // TODO(antoyo): implement LTO by sending -flto to libgccjit and adding the appropriate gcc linker plugins.\n         // NOTE: implemented elsewhere.\n         let module =\n             match modules.remove(0) {\n                 FatLTOInput::InMemory(module) => module,\n                 FatLTOInput::Serialized { .. } => {\n                     unimplemented!();\n-                    /*info!(\"pushing serialized module {:?}\", name);\n-                    let buffer = SerializedModule::Local(buffer);\n-                    serialized_modules.push((buffer, CString::new(name).unwrap()));*/\n                 }\n             };\n         Ok(LtoModuleCodegen::Fat { module: Some(module), _serialized_bitcode: vec![] })\n@@ -233,9 +223,6 @@ impl WriteBackendMethods for GccCodegenBackend {\n     }\n \n     unsafe fn optimize(_cgcx: &CodegenContext<Self>, _diag_handler: &Handler, module: &ModuleCodegen<Self::Module>, config: &ModuleConfig) -> Result<(), FatalError> {\n-        //if cgcx.lto == Lto::Fat {\n-            //module.module_llvm.context.add_driver_option(\"-flto\");\n-        //}\n         module.module_llvm.context.set_optimization_level(to_gcc_opt_level(config.opt_level));\n         Ok(())\n     }\n@@ -257,7 +244,7 @@ impl WriteBackendMethods for GccCodegenBackend {\n     }\n \n     fn run_lto_pass_manager(_cgcx: &CodegenContext<Self>, _module: &ModuleCodegen<Self::Module>, _config: &ModuleConfig, _thin: bool) -> Result<(), FatalError> {\n-        // TODO\n+        // TODO(antoyo)\n         Ok(())\n     }\n \n@@ -266,10 +253,6 @@ impl WriteBackendMethods for GccCodegenBackend {\n     }\n }\n \n-/*fn target_triple(sess: &Session) -> target_lexicon::Triple {\n-    sess.target.llvm_target.parse().unwrap()\n-}*/\n-\n /// This is the entrypoint for a hot plugged rustc_codegen_gccjit\n #[no_mangle]\n pub fn __rustc_codegen_backend() -> Box<dyn CodegenBackend> {\n@@ -306,11 +289,6 @@ fn handle_native(name: &str) -> &str {\n     }\n \n     unimplemented!();\n-    /*unsafe {\n-        let mut len = 0;\n-        let ptr = llvm::LLVMRustGetHostCPUName(&mut len);\n-        str::from_utf8(slice::from_raw_parts(ptr as *const u8, len)).unwrap()\n-    }*/\n }\n \n pub fn target_cpu(sess: &Session) -> &str {\n@@ -327,14 +305,7 @@ pub fn target_features(sess: &Session) -> Vec<Symbol> {\n             },\n         )\n         .filter(|_feature| {\n-            /*if feature.starts_with(\"sse\") {\n-                return true;\n-            }*/\n-            // TODO: implement a way to get enabled feature in libgccjit.\n-            //println!(\"Feature: {}\", feature);\n-            /*let llvm_feature = to_llvm_feature(sess, feature);\n-            let cstr = CString::new(llvm_feature).unwrap();\n-            unsafe { llvm::LLVMRustHasFeature(target_machine, cstr.as_ptr()) }*/\n+            // TODO(antoyo): implement a way to get enabled feature in libgccjit.\n             false\n         })\n         .map(|feature| Symbol::intern(feature))"}, {"sha": "f9ec933dd3abc24e46075c8a8ff29e016d3530e0", "filename": "src/mono_item.rs", "status": "modified", "additions": 4, "deletions": 18, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fmono_item.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Fmono_item.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fmono_item.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -26,12 +26,7 @@ impl<'gcc, 'tcx> PreDefineMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n             )\n         });\n \n-        // TODO\n-        /*unsafe {\n-            llvm::LLVMRustSetLinkage(global, base::linkage_to_llvm(linkage));\n-            llvm::LLVMRustSetVisibility(global, base::visibility_to_llvm(visibility));\n-        }*/\n-\n+        // TODO(antoyo): set linkage and visibility.\n         self.instances.borrow_mut().insert(instance, global);\n     }\n \n@@ -43,17 +38,8 @@ impl<'gcc, 'tcx> PreDefineMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n         let _decl = self.declare_fn(symbol_name, &fn_abi);\n         //let attrs = self.tcx.codegen_fn_attrs(instance.def_id());\n \n-        // TODO: call set_link_section() to allow initializing argc/argv.\n-        //base::set_link_section(decl, &attrs);\n-        /*if linkage == Linkage::LinkOnceODR || linkage == Linkage::WeakODR {\n-            llvm::SetUniqueComdat(self.llmod, decl);\n-        }*/\n-\n-        //debug!(\"predefine_fn: instance = {:?}\", instance);\n-\n-        // TODO: use inline attribute from there in linkage.set() above:\n-        //attributes::from_fn_attrs(self, decl, instance);\n-\n-        //self.instances.borrow_mut().insert(instance, decl);\n+        // TODO(antoyo): call set_link_section() to allow initializing argc/argv.\n+        // TODO(antoyo): set unique comdat.\n+        // TODO(antoyo): use inline attribute from there in linkage.set() above.\n     }\n }"}, {"sha": "3545e1b628105870b333bd2030dbf30ad79c4ed5", "filename": "src/type_.rs", "status": "modified", "additions": 10, "deletions": 88, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Ftype_.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Ftype_.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftype_.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -14,6 +14,9 @@ use crate::type_of::LayoutGccExt;\n impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     pub fn type_ix(&self, num_bits: u64) -> Type<'gcc> {\n         // gcc only supports 1, 2, 4 or 8-byte integers.\n+        // FIXME(antoyo): this is misleading to use the next power of two as rustc_codegen_ssa\n+        // sometimes use 96-bit numbers and the following code will give an integer of a different\n+        // size.\n         let bytes = (num_bits / 8).next_power_of_two() as i32;\n         match bytes {\n             1 => self.i8_type,\n@@ -23,17 +26,8 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n             16 => self.i128_type,\n             _ => panic!(\"unexpected num_bits: {}\", num_bits),\n         }\n-        /*\n-        let bytes = (num_bits / 8).next_power_of_two() as i32;\n-        println!(\"num_bits: {}, bytes: {}\", num_bits, bytes);\n-        self.context.new_int_type(bytes, true) // TODO: check if it is indeed a signed integer.\n-        */\n     }\n \n-    /*pub fn type_bool(&self) -> Type<'gcc> {\n-        self.bool_type\n-    }*/\n-\n     pub fn type_void(&self) -> Type<'gcc> {\n         self.context.new_type::<()>()\n     }\n@@ -67,39 +61,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n         let ity = Integer::approximate_align(self, align);\n         self.type_from_integer(ity)\n     }\n-\n-    /*pub fn type_int_from_ty(&self, t: ty::IntTy) -> Type<'gcc> {\n-        match t {\n-            ty::IntTy::Isize => self.type_isize(),\n-            ty::IntTy::I8 => self.type_i8(),\n-            ty::IntTy::I16 => self.type_i16(),\n-            ty::IntTy::I32 => self.type_i32(),\n-            ty::IntTy::I64 => self.type_i64(),\n-            ty::IntTy::I128 => self.type_i128(),\n-        }\n-    }\n-\n-    pub fn type_uint_from_ty(&self, t: ty::UintTy) -> Type<'gcc> {\n-        match t {\n-            ty::UintTy::Usize => self.type_isize(),\n-            ty::UintTy::U8 => self.type_i8(),\n-            ty::UintTy::U16 => self.type_i16(),\n-            ty::UintTy::U32 => self.type_i32(),\n-            ty::UintTy::U64 => self.type_i64(),\n-            ty::UintTy::U128 => self.type_i128(),\n-        }\n-    }\n-\n-    pub fn type_float_from_ty(&self, t: ty::FloatTy) -> Type<'gcc> {\n-        match t {\n-            ty::FloatTy::F32 => self.type_f32(),\n-            ty::FloatTy::F64 => self.type_f64(),\n-        }\n-    }\n-\n-    pub fn type_vector(&self, ty: Type<'gcc>, len: u64) -> Type<'gcc> {\n-        self.context.new_vector_type(ty, len)\n-    }*/\n }\n \n impl<'gcc, 'tcx> BaseTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n@@ -151,9 +112,7 @@ impl<'gcc, 'tcx> BaseTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n         let fields: Vec<_> = fields.iter().enumerate()\n             .map(|(index, field)| self.context.new_field(None, *field, &format!(\"field{}_TODO\", index)))\n             .collect();\n-        // TODO: use packed.\n-        //let name = types.iter().map(|typ| format!(\"{:?}\", typ)).collect::<Vec<_>>().join(\"_\");\n-        //let typ = self.context.new_struct_type(None, format!(\"struct{}\", name), &fields).as_type();\n+        // TODO(antoyo): use packed.\n         let typ = self.context.new_struct_type(None, \"struct\", &fields).as_type();\n         self.struct_types.borrow_mut().insert(types, typ);\n         typ\n@@ -167,21 +126,17 @@ impl<'gcc, 'tcx> BaseTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n             TypeKind::Vector\n         }\n         else {\n-            // TODO\n+            // TODO(antoyo): support other types.\n             TypeKind::Void\n         }\n     }\n \n     fn type_ptr_to(&self, ty: Type<'gcc>) -> Type<'gcc> {\n-        // TODO\n-        /*assert_ne!(self.type_kind(ty), TypeKind::Function,\n-            \"don't call ptr_to on function types, use ptr_to_gcc_type on FnAbi instead\"\n-        );*/\n         ty.make_pointer()\n     }\n \n     fn type_ptr_to_ext(&self, ty: Type<'gcc>, _address_space: AddressSpace) -> Type<'gcc> {\n-        // TODO: use address_space\n+        // TODO(antoyo): use address_space\n         ty.make_pointer()\n     }\n \n@@ -202,7 +157,6 @@ impl<'gcc, 'tcx> BaseTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n \n     fn vector_length(&self, _ty: Type<'gcc>) -> usize {\n         unimplemented!();\n-        //unsafe { llvm::LLVMGetVectorSize(ty) as usize }\n     }\n \n     fn float_width(&self, typ: Type<'gcc>) -> usize {\n@@ -217,14 +171,7 @@ impl<'gcc, 'tcx> BaseTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n         else {\n             panic!(\"Cannot get width of float type {:?}\", typ);\n         }\n-        // TODO: support other sizes.\n-        /*match self.type_kind(ty) {\n-            TypeKind::Float => 32,\n-            TypeKind::Double => 64,\n-            TypeKind::X86_FP80 => 80,\n-            TypeKind::FP128 | TypeKind::PPC_FP128 => 128,\n-            _ => bug!(\"llvm_float_width called on a non-float type\"),\n-        }*/\n+        // TODO(antoyo): support other sizes.\n     }\n \n     fn int_width(&self, typ: Type<'gcc>) -> u64 {\n@@ -263,21 +210,13 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n     }\n \n     pub fn set_struct_body(&self, typ: Struct<'gcc>, fields: &[Type<'gcc>], _packed: bool) {\n-        // TODO: use packed.\n+        // TODO(antoyo): use packed.\n         let fields: Vec<_> = fields.iter().enumerate()\n             .map(|(index, field)| self.context.new_field(None, *field, &format!(\"field_{}\", index)))\n             .collect();\n         typ.set_fields(None, &fields);\n     }\n \n-    /*fn type_struct(&self, fields: &[Type<'gcc>], packed: bool) -> Type<'gcc> {\n-        // TODO: use packed.\n-        let fields: Vec<_> = fields.iter().enumerate()\n-            .map(|(index, field)| self.context.new_field(None, *field, &format!(\"field_{}\", index)))\n-            .collect();\n-        return self.context.new_struct_type(None, \"unnamedStruct\", &fields).as_type();\n-    }*/\n-\n     pub fn type_named_struct(&self, name: &str) -> Struct<'gcc> {\n         self.context.new_opaque_struct_type(None, name)\n     }\n@@ -288,7 +227,7 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n                 // NOTE: since gccjit only supports i32 for the array size and libcore's tests uses a\n                 // size of usize::MAX in test_binary_search, we workaround this by setting the size to\n                 // zero for ZSTs.\n-                // FIXME: fix gccjit API.\n+                // FIXME(antoyo): fix gccjit API.\n                 len = 0;\n             }\n         }\n@@ -305,7 +244,6 @@ impl<'gcc, 'tcx> CodegenCx<'gcc, 'tcx> {\n }\n \n pub fn struct_fields<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, layout: TyAndLayout<'tcx>) -> (Vec<Type<'gcc>>, bool) {\n-    //debug!(\"struct_fields: {:#?}\", layout);\n     let field_count = layout.fields.count();\n \n     let mut packed = false;\n@@ -319,23 +257,13 @@ pub fn struct_fields<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, layout: TyAndLayout\n             layout.align.abi.min(field.align.abi).restrict_for_offset(target_offset);\n         packed |= effective_field_align < field.align.abi;\n \n-        /*debug!(\n-            \"struct_fields: {}: {:?} offset: {:?} target_offset: {:?} \\\n-                effective_field_align: {}\",\n-            i,\n-            field,\n-            offset,\n-            target_offset,\n-            effective_field_align.bytes()\n-        );*/\n         assert!(target_offset >= offset);\n         let padding = target_offset - offset;\n         let padding_align = prev_effective_align.min(effective_field_align);\n         assert_eq!(offset.align_to(padding_align) + padding, target_offset);\n         result.push(cx.type_padding_filler(padding, padding_align));\n-        //debug!(\"    padding before: {:?}\", padding);\n \n-        result.push(field.gcc_type(cx, !field.ty.is_any_ptr())); // FIXME: might need to check if the type is inside another, like Box<Type>.\n+        result.push(field.gcc_type(cx, !field.ty.is_any_ptr())); // FIXME(antoyo): might need to check if the type is inside another, like Box<Type>.\n         offset = target_offset + field.size;\n         prev_effective_align = effective_field_align;\n     }\n@@ -346,14 +274,8 @@ pub fn struct_fields<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, layout: TyAndLayout\n         let padding = layout.size - offset;\n         let padding_align = prev_effective_align;\n         assert_eq!(offset.align_to(padding_align) + padding, layout.size);\n-        /*debug!(\n-            \"struct_fields: pad_bytes: {:?} offset: {:?} stride: {:?}\",\n-            padding, offset, layout.size\n-        );*/\n         result.push(cx.type_padding_filler(padding, padding_align));\n         assert_eq!(result.len(), 1 + field_count * 2);\n-    } else {\n-        //debug!(\"struct_fields: offset: {:?} stride: {:?}\", offset, layout.size);\n     }\n \n     (result, packed)"}, {"sha": "9302f57b642af1fc0cd3cf70936b0b847476deb8", "filename": "src/type_of.rs", "status": "modified", "additions": 8, "deletions": 21, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Ftype_of.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/src%2Ftype_of.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftype_of.rs?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -71,7 +71,7 @@ pub fn uncached_gcc_type<'gcc, 'tcx>(cx: &CodegenCx<'gcc, 'tcx>, layout: TyAndLa\n             // If `Some` is returned then a named struct is created in LLVM. Name collisions are\n             // avoided by LLVM (with increasing suffixes). If rustc doesn't generate names then that\n             // can improve perf.\n-            // FIXME: I don't think that's true for libgccjit.\n+            // FIXME(antoyo): I don't think that's true for libgccjit.\n             Some(String::new())\n         }\n         _ => None,\n@@ -144,6 +144,7 @@ impl<'tcx> LayoutGccExt<'tcx> for TyAndLayout<'tcx> {\n     /// with the inner-most trailing unsized field using the \"minimal unit\"\n     /// of that field's type - this is useful for taking the address of\n     /// that field and ensuring the struct has the right alignment.\n+    //TODO(antoyo): do we still need the set_fields parameter?\n     fn gcc_type<'gcc>(&self, cx: &CodegenCx<'gcc, 'tcx>, set_fields: bool) -> Type<'gcc> {\n         if let Abi::Scalar(ref scalar) = self.abi {\n             // Use a different cache for scalars because pointers to DSTs\n@@ -184,8 +185,6 @@ impl<'tcx> LayoutGccExt<'tcx> for TyAndLayout<'tcx> {\n             return ty;\n         }\n \n-        //debug!(\"gcc_type({:#?})\", self);\n-\n         assert!(!self.ty.has_escaping_bound_vars(), \"{:?} has escaping bound vars\", self.ty);\n \n         // Make sure lifetimes are erased, to avoid generating distinct LLVM\n@@ -204,22 +203,12 @@ impl<'tcx> LayoutGccExt<'tcx> for TyAndLayout<'tcx> {\n             else {\n                 uncached_gcc_type(cx, *self, &mut defer)\n             };\n-        //debug!(\"--> mapped {:#?} to ty={:?}\", self, ty);\n \n         cx.types.borrow_mut().insert((self.ty, variant_index), ty);\n \n         if let Some((ty, layout)) = defer {\n-            //TODO: do we still need this conditions and the set_fields parameter?\n-            //if set_fields {\n-                let (fields, packed) = struct_fields(cx, layout);\n-                cx.set_struct_body(ty, &fields, packed);\n-            /*}\n-            else {\n-                // Since we might be trying to generate a type containing another type which is not\n-                // completely generated yet, we don't set the fields right now, but we save the\n-                // type to set the fields later.\n-                cx.types_with_fields_to_set.borrow_mut().insert(ty.as_type(), (ty, layout));\n-            }*/\n+            let (fields, packed) = struct_fields(cx, layout);\n+            cx.set_struct_body(ty, &fields, packed);\n         }\n \n         ty\n@@ -255,7 +244,7 @@ impl<'tcx> LayoutGccExt<'tcx> for TyAndLayout<'tcx> {\n     }\n \n     fn scalar_pair_element_gcc_type<'gcc>(&self, cx: &CodegenCx<'gcc, 'tcx>, index: usize, immediate: bool) -> Type<'gcc> {\n-        // TODO: remove llvm hack:\n+        // TODO(antoyo): remove llvm hack:\n         // HACK(eddyb) special-case fat pointers until LLVM removes\n         // pointee types, to avoid bitcasting every `OperandRef::deref`.\n         match self.ty.kind() {\n@@ -281,8 +270,8 @@ impl<'tcx> LayoutGccExt<'tcx> for TyAndLayout<'tcx> {\n         // immediate, just like `bool` is typically `i8` in memory and only `i1`\n         // when immediate.  We need to load/store `bool` as `i8` to avoid\n         // crippling LLVM optimizations or triggering other LLVM bugs with `i1`.\n-        // TODO: this bugs certainly don't happen in this case since the bool type is used instead of i1.\n-        if /*immediate &&*/ scalar.is_bool() {\n+        // TODO(antoyo): this bugs certainly don't happen in this case since the bool type is used instead of i1.\n+        if scalar.is_bool() {\n             return cx.type_i1();\n         }\n \n@@ -361,12 +350,10 @@ impl<'gcc, 'tcx> LayoutTypeMethods<'tcx> for CodegenCx<'gcc, 'tcx> {\n \n     fn reg_backend_type(&self, _ty: &Reg) -> Type<'gcc> {\n         unimplemented!();\n-        //ty.gcc_type(self)\n     }\n \n     fn fn_decl_backend_type(&self, _fn_abi: &FnAbi<'tcx, Ty<'tcx>>) -> Type<'gcc> {\n-        // FIXME: return correct type.\n+        // FIXME(antoyo): return correct type.\n         self.type_void()\n-        //fn_abi.gcc_type(self)\n     }\n }"}, {"sha": "404a169d39ac9574f29acd212c9c92823609a791", "filename": "src/va_arg.rs", "status": "removed", "additions": 0, "deletions": 179, "changes": 179, "blob_url": "https://github.com/rust-lang/rust/blob/0c89065b934397b62838fe3e4ef6f6352fc52daf/src%2Fva_arg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c89065b934397b62838fe3e4ef6f6352fc52daf/src%2Fva_arg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fva_arg.rs?ref=0c89065b934397b62838fe3e4ef6f6352fc52daf", "patch": "@@ -1,179 +0,0 @@\n-/*use gccjit::{RValue, ToRValue, Type};\n-use rustc_codegen_ssa::mir::operand::OperandRef;\n-use rustc_codegen_ssa::{\n-    common::IntPredicate,\n-    traits::{BaseTypeMethods, BuilderMethods, ConstMethods, DerivedTypeMethods},\n-};\n-use rustc_middle::ty::layout::HasTyCtxt;\n-use rustc_middle::ty::Ty;\n-use rustc_target::abi::{Align, Endian, HasDataLayout, LayoutOf, Size};\n-\n-use crate::builder::Builder;\n-use crate::type_of::LayoutGccExt;\n-\n-fn round_pointer_up_to_alignment<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, addr: RValue<'gcc>, align: Align, ptr_ty: Type<'gcc>) -> RValue<'gcc> {\n-    let mut ptr_as_int = bx.ptrtoint(addr, bx.cx().type_isize());\n-    ptr_as_int = bx.add(ptr_as_int, bx.cx().const_i32(align.bytes() as i32 - 1));\n-    ptr_as_int = bx.and(ptr_as_int, bx.cx().const_i32(-(align.bytes() as i32)));\n-    bx.inttoptr(ptr_as_int, ptr_ty)\n-}\n-\n-fn emit_direct_ptr_va_arg<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, list: OperandRef<'tcx, RValue<'gcc>>, llty: Type<'gcc>, size: Size, align: Align, slot_size: Align, allow_higher_align: bool) -> (RValue<'gcc>, Align) {\n-    let va_list_ptr_ty = bx.cx().type_ptr_to(bx.cx.type_i8p());\n-    let va_list_addr =\n-        if list.layout.gcc_type(bx.cx, true) != va_list_ptr_ty {\n-            bx.bitcast(list.immediate(), va_list_ptr_ty)\n-        }\n-        else {\n-            list.immediate()\n-        };\n-\n-    let ptr = bx.load(va_list_addr, bx.tcx().data_layout.pointer_align.abi);\n-\n-    let (addr, addr_align) = if allow_higher_align && align > slot_size {\n-        (round_pointer_up_to_alignment(bx, ptr, align, bx.cx().type_i8p()), align)\n-    } else {\n-        (ptr, slot_size)\n-    };\n-\n-    let aligned_size = size.align_to(slot_size).bytes() as i32;\n-    let full_direct_size = bx.cx().const_i32(aligned_size);\n-    let next = bx.inbounds_gep(addr, &[full_direct_size]);\n-    bx.store(next, va_list_addr, bx.tcx().data_layout.pointer_align.abi);\n-\n-    if size.bytes() < slot_size.bytes() && bx.tcx().sess.target.endian == Endian::Big {\n-        let adjusted_size = bx.cx().const_i32((slot_size.bytes() - size.bytes()) as i32);\n-        let adjusted = bx.inbounds_gep(addr, &[adjusted_size]);\n-        (bx.bitcast(adjusted, bx.cx().type_ptr_to(llty)), addr_align)\n-    } else {\n-        (bx.bitcast(addr, bx.cx().type_ptr_to(llty)), addr_align)\n-    }\n-}\n-\n-fn emit_ptr_va_arg<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, list: OperandRef<'tcx, RValue<'gcc>>, target_ty: Ty<'tcx>, indirect: bool, slot_size: Align, allow_higher_align: bool) -> RValue<'gcc> {\n-    let layout = bx.cx.layout_of(target_ty);\n-    let (llty, size, align) =\n-        if indirect {\n-            (\n-                bx.cx.layout_of(bx.cx.tcx.mk_imm_ptr(target_ty)).gcc_type(bx.cx, true),\n-                bx.cx.data_layout().pointer_size,\n-                bx.cx.data_layout().pointer_align,\n-            )\n-        }\n-        else {\n-            (layout.gcc_type(bx.cx, true), layout.size, layout.align)\n-        };\n-    let (addr, addr_align) = emit_direct_ptr_va_arg(bx, list, llty, size, align.abi, slot_size, allow_higher_align);\n-    if indirect {\n-        let tmp_ret = bx.load(addr, addr_align);\n-        bx.load(tmp_ret, align.abi)\n-    }\n-    else {\n-        bx.load(addr, addr_align)\n-    }\n-}\n-\n-fn emit_aapcs_va_arg<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, list: OperandRef<'tcx, RValue<'gcc>>, target_ty: Ty<'tcx>) -> RValue<'gcc> {\n-    // Implementation of the AAPCS64 calling convention for va_args see\n-    // https://github.com/ARM-software/abi-aa/blob/master/aapcs64/aapcs64.rst\n-    let va_list_addr = list.immediate();\n-    let layout = bx.cx.layout_of(target_ty);\n-    let gcc_type = layout.immediate_gcc_type(bx);\n-\n-    let function = bx.llbb().get_function();\n-    let variable = function.new_local(None, gcc_type, \"va_arg\");\n-\n-    let mut maybe_reg = bx.build_sibling_block(\"va_arg.maybe_reg\");\n-    let mut in_reg = bx.build_sibling_block(\"va_arg.in_reg\");\n-    let mut on_stack = bx.build_sibling_block(\"va_arg.on_stack\");\n-    let end = bx.build_sibling_block(\"va_arg.end\");\n-    let zero = bx.const_i32(0);\n-    let offset_align = Align::from_bytes(4).unwrap();\n-    assert!(bx.tcx().sess.target.endian == Endian::Little);\n-\n-    let gr_type = target_ty.is_any_ptr() || target_ty.is_integral();\n-    let (reg_off, reg_top_index, slot_size) = if gr_type {\n-        let gr_offs = bx.struct_gep(va_list_addr, 7);\n-        let nreg = (layout.size.bytes() + 7) / 8;\n-        (gr_offs, 3, nreg * 8)\n-    } else {\n-        let vr_off = bx.struct_gep(va_list_addr, 9);\n-        let nreg = (layout.size.bytes() + 15) / 16;\n-        (vr_off, 5, nreg * 16)\n-    };\n-\n-    // if the offset >= 0 then the value will be on the stack\n-    let mut reg_off_v = bx.load(reg_off, offset_align);\n-    let use_stack = bx.icmp(IntPredicate::IntSGE, reg_off_v, zero);\n-    bx.cond_br(use_stack, on_stack.llbb(), maybe_reg.llbb());\n-\n-    // The value at this point might be in a register, but there is a chance that\n-    // it could be on the stack so we have to update the offset and then check\n-    // the offset again.\n-\n-    if gr_type && layout.align.abi.bytes() > 8 {\n-        reg_off_v = maybe_reg.add(reg_off_v, bx.const_i32(15));\n-        reg_off_v = maybe_reg.and(reg_off_v, bx.const_i32(-16));\n-    }\n-    let new_reg_off_v = maybe_reg.add(reg_off_v, bx.const_i32(slot_size as i32));\n-\n-    maybe_reg.store(new_reg_off_v, reg_off, offset_align);\n-\n-    // Check to see if we have overflowed the registers as a result of this.\n-    // If we have then we need to use the stack for this value\n-    let use_stack = maybe_reg.icmp(IntPredicate::IntSGT, new_reg_off_v, zero);\n-    maybe_reg.cond_br(use_stack, on_stack.llbb(), in_reg.llbb());\n-\n-    let top = in_reg.struct_gep(va_list_addr, reg_top_index);\n-    let top = in_reg.load(top, bx.tcx().data_layout.pointer_align.abi);\n-\n-    // reg_value = *(@top + reg_off_v);\n-    let top = in_reg.gep(top, &[reg_off_v]);\n-    let top = in_reg.bitcast(top, bx.cx.type_ptr_to(layout.gcc_type(bx, true)));\n-    let reg_value = in_reg.load(top, layout.align.abi);\n-    in_reg.assign(variable, reg_value);\n-    in_reg.br(end.llbb());\n-\n-    // On Stack block\n-    let stack_value =\n-        emit_ptr_va_arg(&mut on_stack, list, target_ty, false, Align::from_bytes(8).unwrap(), true);\n-    on_stack.assign(variable, stack_value);\n-    on_stack.br(end.llbb());\n-\n-    *bx = end;\n-    variable.to_rvalue()\n-}\n-\n-pub(super) fn emit_va_arg<'a, 'gcc, 'tcx>(bx: &mut Builder<'a, 'gcc, 'tcx>, addr: OperandRef<'tcx, RValue<'gcc>>, target_ty: Ty<'tcx>) -> RValue<'gcc> {\n-    // Determine the va_arg implementation to use. The LLVM va_arg instruction\n-    // is lacking in some instances, so we should only use it as a fallback.\n-    let target = &bx.cx.tcx.sess.target;\n-    let arch = &bx.cx.tcx.sess.target.arch;\n-    match &**arch {\n-        // Windows x86\n-        \"x86\" if target.options.is_like_windows => {\n-            emit_ptr_va_arg(bx, addr, target_ty, false, Align::from_bytes(4).unwrap(), false)\n-        }\n-        // Generic x86\n-        \"x86\" => emit_ptr_va_arg(bx, addr, target_ty, false, Align::from_bytes(4).unwrap(), true),\n-        // Windows AArch64\n-        \"aarch64\" if target.options.is_like_windows => {\n-            emit_ptr_va_arg(bx, addr, target_ty, false, Align::from_bytes(8).unwrap(), false)\n-        }\n-        // macOS / iOS AArch64\n-        \"aarch64\" if target.options.is_like_osx => {\n-            emit_ptr_va_arg(bx, addr, target_ty, false, Align::from_bytes(8).unwrap(), true)\n-        }\n-        \"aarch64\" => emit_aapcs_va_arg(bx, addr, target_ty),\n-        // Windows x86_64\n-        \"x86_64\" if target.options.is_like_windows => {\n-            let target_ty_size = bx.cx.size_of(target_ty).bytes();\n-            let indirect: bool = target_ty_size > 8 || !target_ty_size.is_power_of_two();\n-            emit_ptr_va_arg(bx, addr, target_ty, indirect, Align::from_bytes(8).unwrap(), false)\n-        }\n-        // For all other architecture/OS combinations fall back to using\n-        // the LLVM va_arg instruction.\n-        // https://llvm.org/docs/LangRef.html#va-arg-instruction\n-        _ => bx.va_arg(addr.immediate(), bx.cx.layout_of(target_ty).gcc_type(bx.cx, true)),\n-    }\n-}*/"}, {"sha": "06faa98d9b1f045987686d96f3d1d7e2b38931cb", "filename": "test.sh", "status": "modified", "additions": 12, "deletions": 38, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/e228f0c16ea8c34794a6285bf57aab627c26b147/test.sh", "raw_url": "https://github.com/rust-lang/rust/raw/e228f0c16ea8c34794a6285bf57aab627c26b147/test.sh", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/test.sh?ref=e228f0c16ea8c34794a6285bf57aab627c26b147", "patch": "@@ -1,8 +1,7 @@\n #!/bin/bash\n \n-# TODO: rewrite to cargo-make (or just) or something like that to only rebuild the sysroot when needed?\n+# TODO(antoyo): rewrite to cargo-make (or just) or something like that to only rebuild the sysroot when needed?\n \n-#set -x\n set -e\n \n export GCC_PATH=$(cat gcc_path)\n@@ -30,17 +29,9 @@ $RUSTC example/mini_core.rs --crate-name mini_core --crate-type lib,dylib --targ\n echo \"[BUILD] example\"\n $RUSTC example/example.rs --crate-type lib --target $TARGET_TRIPLE\n \n-#if [[ \"$HOST_TRIPLE\" = \"$TARGET_TRIPLE\" ]]; then\n-    #echo \"[JIT] mini_core_hello_world\"\n-    #CG_CLIF_JIT=1 CG_CLIF_JIT_ARGS=\"abc bcd\" $RUSTC --crate-type bin -Cprefer-dynamic example/mini_core_hello_world.rs --cfg jit --target $HOST_TRIPLE\n-#else\n-    #echo \"[JIT] mini_core_hello_world (skipped)\"\n-#fi\n-\n echo \"[AOT] mini_core_hello_world\"\n $RUSTC example/mini_core_hello_world.rs --crate-name mini_core_hello_world --crate-type bin -g --target $TARGET_TRIPLE\n $RUN_WRAPPER ./target/out/mini_core_hello_world abc bcd\n-# (echo \"break set -n main\"; echo \"run\"; sleep 1; echo \"si -c 10\"; sleep 1; echo \"frame variable\") | lldb -- ./target/out/mini_core_hello_world abc bcd\n \n echo \"[BUILD] sysroot\"\n time ./build_sysroot/build_sysroot.sh\n@@ -52,20 +43,12 @@ $RUN_WRAPPER ./target/out/arbitrary_self_types_pointers_and_wrappers\n echo \"[AOT] alloc_system\"\n $RUSTC example/alloc_system.rs --crate-type lib --target \"$TARGET_TRIPLE\"\n \n-# FIXME: this requires linking an additional lib for __popcountdi2\n-#echo \"[AOT] alloc_example\"\n-#$RUSTC example/alloc_example.rs --crate-type bin --target $TARGET_TRIPLE\n-#$RUN_WRAPPER ./target/out/alloc_example\n-\n-#if [[ \"$HOST_TRIPLE\" = \"$TARGET_TRIPLE\" ]]; then\n-    #echo \"[JIT] std_example\"\n-    #CG_CLIF_JIT=1 $RUSTC --crate-type bin -Cprefer-dynamic example/std_example.rs --target $HOST_TRIPLE\n-#else\n-    #echo \"[JIT] std_example (skipped)\"\n-#fi\n+echo \"[AOT] alloc_example\"\n+$RUSTC example/alloc_example.rs --crate-type bin --target $TARGET_TRIPLE\n+$RUN_WRAPPER ./target/out/alloc_example\n \n echo \"[AOT] dst_field_align\"\n-# FIXME Re-add -Zmir-opt-level=2 once rust-lang/rust#67529 is fixed.\n+# FIXME(antoyo): Re-add -Zmir-opt-level=2 once rust-lang/rust#67529 is fixed.\n $RUSTC example/dst-field-align.rs --crate-name dst_field_align --crate-type bin --target $TARGET_TRIPLE\n $RUN_WRAPPER ./target/out/dst_field_align || (echo $?; false)\n \n@@ -81,14 +64,14 @@ echo \"[AOT] track-caller-attribute\"\n $RUSTC example/track-caller-attribute.rs --crate-type bin -Cpanic=abort --target $TARGET_TRIPLE\n $RUN_WRAPPER ./target/out/track-caller-attribute\n \n-# FIXME: this requires linking an additional lib for __popcountdi2\n-#echo \"[BUILD] mod_bench\"\n-#$RUSTC example/mod_bench.rs --crate-type bin --target $TARGET_TRIPLE\n+echo \"[BUILD] mod_bench\"\n+$RUSTC example/mod_bench.rs --crate-type bin --target $TARGET_TRIPLE\n \n-# FIXME linker gives multiple definitions error on Linux\n+# FIXME(antoyo): linker gives multiple definitions error on Linux\n #echo \"[BUILD] sysroot in release mode\"\n #./build_sysroot/build_sysroot.sh --release\n \n+# TODO(antoyo): uncomment when it works.\n #pushd simple-raytracer\n #if [[ \"$HOST_TRIPLE\" = \"$TARGET_TRIPLE\" ]]; then\n     #echo \"[BENCH COMPILE] ebobby/simple-raytracer\"\n@@ -113,6 +96,7 @@ rm -r ./target || true\n ../../../../../cargo.sh test\n popd\n \n+# TODO(antoyo): uncomment when it works.\n #pushd regex\n #echo \"[TEST] rust-lang/regex example shootout-regex-dna\"\n #../cargo.sh clean\n@@ -152,9 +136,6 @@ git fetch\n git checkout $(rustc -V | cut -d' ' -f3 | tr -d '(')\n export RUSTFLAGS=\n \n-#git apply ../rust_lang.patch\n-\n-\n rm config.toml || true\n \n cat > config.toml <<EOF\n@@ -182,16 +163,9 @@ for test in $(rg --files-with-matches \"catch_unwind|should_panic|thread|lto\" src\n done\n git checkout src/test/ui/type-alias-impl-trait/auxiliary/cross_crate_ice.rs\n git checkout src/test/ui/type-alias-impl-trait/auxiliary/cross_crate_ice2.rs\n-rm src/test/ui/llvm-asm/llvm-asm-in-out-operand.rs || true # TODO: Enable back this test if I ever implement the llvm_asm! macro.\n-#rm src/test/ui/consts/const-size_of-cycle.rs || true # Error file path difference\n-#rm src/test/ui/impl-trait/impl-generic-mismatch.rs || true # ^\n-#rm src/test/ui/type_length_limit.rs || true\n-#rm src/test/ui/issues/issue-50993.rs || true # Target `thumbv7em-none-eabihf` is not supported\n-#rm src/test/ui/macros/same-sequence-span.rs || true # Proc macro .rustc section not found?\n-#rm src/test/ui/suggestions/issue-61963.rs || true # ^\n+rm src/test/ui/llvm-asm/llvm-asm-in-out-operand.rs || true # TODO(antoyo): Enable back this test if I ever implement the llvm_asm! macro.\n \n RUSTC_ARGS=\"-Zpanic-abort-tests -Zcodegen-backend=\"$(pwd)\"/../target/\"$CHANNEL\"/librustc_codegen_gcc.\"$dylib_ext\" --sysroot \"$(pwd)\"/../build_sysroot/sysroot -Cpanic=abort\"\n \n echo \"[TEST] rustc test suite\"\n-# TODO: remove excluded tests when they stop stalling.\n-COMPILETEST_FORCE_STAGE0=1 ./x.py test --run always --stage 0 src/test/ui/ --rustc-args \"$RUSTC_ARGS\" --exclude src/test/ui/numbers-arithmetic/saturating-float-casts.rs --exclude src/test/ui/issues/issue-50811.rs\n+COMPILETEST_FORCE_STAGE0=1 ./x.py test --run always --stage 0 src/test/ui/ --rustc-args \"$RUSTC_ARGS\""}]}