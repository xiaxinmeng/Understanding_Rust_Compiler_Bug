{"sha": "82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "node_id": "MDY6Q29tbWl0NzI0NzEyOjgyMjEzYTNiN2Y3Y2VlMmI3MGQ2Y2QzZTQxMTY0ZmE0NGMxODliZWM=", "commit": {"author": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2020-01-04T11:40:10Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-01-04T11:40:10Z"}, "message": "Merge pull request #853 from bjorn3/opt_stack2reg\n\nAdd stack2reg optimization pass", "tree": {"sha": "24e00742f6e5a90a98277c65befacf3b08c92b4d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/24e00742f6e5a90a98277c65befacf3b08c92b4d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJeEHmaCRBK7hj4Ov3rIwAAdHIIAJcQ8WlVpEIMAGiNT4OkT9KO\nHavpri4Ef+QQQmmX7qKNupV2xGcbKy8jZv3OudDOPDw3cjFH/6BPWd6NV+kKQN9r\n2YazueTiSYvhp4DGnUK1XEhX9j9vwnHYIVlfPxIV8UgdThtIeQgiwLc0xOVVEiN+\nGjgrnqzwXtdMyDkYokCZuINf5P2+jzPA+K7bXi7sVeTeakN9jAsmAPUUsGD9cYPo\nZ/Ea+fGy/U91N9/hRCEcSuByN+Qdrsq0gGvVgyEsPdhLFddOoZXqb2Mwj5/6m8SU\nai8MDusQ1Zm6hEmZyG5IUNJSeI0oTS7heGj3RZcFKBA8uuHJB9KjzYPuxJXx07A=\n=vBgu\n-----END PGP SIGNATURE-----\n", "payload": "tree 24e00742f6e5a90a98277c65befacf3b08c92b4d\nparent e9a8d8bf67ca0aab07f7796126f56ad8ee8fc5b2\nparent 87d6953719c5b9c3e7fe4c5a97d2e845dcb52d57\nauthor bjorn3 <bjorn3@users.noreply.github.com> 1578138010 +0100\ncommitter GitHub <noreply@github.com> 1578138010 +0100\n\nMerge pull request #853 from bjorn3/opt_stack2reg\n\nAdd stack2reg optimization pass"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "html_url": "https://github.com/rust-lang/rust/commit/82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/comments", "author": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e9a8d8bf67ca0aab07f7796126f56ad8ee8fc5b2", "url": "https://api.github.com/repos/rust-lang/rust/commits/e9a8d8bf67ca0aab07f7796126f56ad8ee8fc5b2", "html_url": "https://github.com/rust-lang/rust/commit/e9a8d8bf67ca0aab07f7796126f56ad8ee8fc5b2"}, {"sha": "87d6953719c5b9c3e7fe4c5a97d2e845dcb52d57", "url": "https://api.github.com/repos/rust-lang/rust/commits/87d6953719c5b9c3e7fe4c5a97d2e845dcb52d57", "html_url": "https://github.com/rust-lang/rust/commit/87d6953719c5b9c3e7fe4c5a97d2e845dcb52d57"}], "stats": {"total": 447, "additions": 444, "deletions": 3}, "files": [{"sha": "81ca47fe64580a7881dd42e5e95597daebaa7259", "filename": "src/base.rs", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbase.rs?ref=82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "patch": "@@ -66,7 +66,7 @@ pub fn trans_fn<'clif, 'tcx, B: Backend + 'static>(\n \n     // Recover all necessary data from fx, before accessing func will prevent future access to it.\n     let instance = fx.instance;\n-    let clif_comments = fx.clif_comments;\n+    let mut clif_comments = fx.clif_comments;\n     let source_info_set = fx.source_info_set;\n     let local_map = fx.local_map;\n \n@@ -76,9 +76,13 @@ pub fn trans_fn<'clif, 'tcx, B: Backend + 'static>(\n     // Verify function\n     verify_func(tcx, &clif_comments, &func);\n \n-    // Define function\n     let context = &mut cx.caches.context;\n     context.func = func;\n+\n+    // Perform rust specific optimizations\n+    crate::optimize::optimize_function(cx.tcx, instance, context, &mut clif_comments);\n+\n+    // Define function\n     cx.module.define_function(func_id, context).unwrap();\n \n     // Write optimized function to file for debugging\n@@ -108,7 +112,7 @@ pub fn trans_fn<'clif, 'tcx, B: Backend + 'static>(\n     context.clear();\n }\n \n-fn verify_func(tcx: TyCtxt, writer: &crate::pretty_clif::CommentWriter, func: &Function) {\n+pub fn verify_func(tcx: TyCtxt, writer: &crate::pretty_clif::CommentWriter, func: &Function) {\n     let flags = settings::Flags::new(settings::builder());\n     match ::cranelift_codegen::verify_function(&func, &flags) {\n         Ok(_) => {}"}, {"sha": "cbe07643a40df1f366f40bb380350158df8dcb97", "filename": "src/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "patch": "@@ -12,6 +12,7 @@ extern crate rustc_fs_util;\n extern crate rustc_incremental;\n extern crate rustc_index;\n extern crate rustc_mir;\n+extern crate rustc_session;\n extern crate rustc_target;\n extern crate syntax;\n \n@@ -47,6 +48,7 @@ mod linkage;\n mod main_shim;\n mod metadata;\n mod num;\n+mod optimize;\n mod pointer;\n mod pretty_clif;\n mod target_features_whitelist;"}, {"sha": "59e4d2dd47d1ef64e633ce18446585bf33175e2d", "filename": "src/optimize/mod.rs", "status": "added", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Foptimize%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Foptimize%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Foptimize%2Fmod.rs?ref=82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "patch": "@@ -0,0 +1,18 @@\n+use crate::prelude::*;\n+\n+mod stack2reg;\n+\n+pub fn optimize_function<'tcx>(\n+    tcx: TyCtxt<'tcx>,\n+    instance: Instance<'tcx>,\n+    ctx: &mut Context,\n+    clif_comments: &mut crate::pretty_clif::CommentWriter,\n+) {\n+    if tcx.sess.opts.optimize == rustc_session::config::OptLevel::No {\n+        return; // FIXME classify optimizations over opt levels\n+    }\n+    self::stack2reg::optimize_function(ctx, clif_comments, instance);\n+    #[cfg(debug_assertions)]\n+    crate::pretty_clif::write_clif_file(tcx, \"stack2reg\", instance, &ctx.func, &*clif_comments, None);\n+    crate::base::verify_func(tcx, &*clif_comments, &ctx.func);\n+}"}, {"sha": "4762b40db8dd9aec5321a0cf8d1e146883ef5e4e", "filename": "src/optimize/stack2reg.rs", "status": "added", "additions": 417, "deletions": 0, "changes": 417, "blob_url": "https://github.com/rust-lang/rust/blob/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Foptimize%2Fstack2reg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/82213a3b7f7cee2b70d6cd3e41164fa44c189bec/src%2Foptimize%2Fstack2reg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Foptimize%2Fstack2reg.rs?ref=82213a3b7f7cee2b70d6cd3e41164fa44c189bec", "patch": "@@ -0,0 +1,417 @@\n+//! This optimization replaces stack accesses with SSA variables and removes dead stores when possible.\n+//!\n+//! # Undefined behaviour\n+//!\n+//! This optimization is based on the assumption that stack slots which don't have their address\n+//! leaked through `stack_addr` are only accessed using `stack_load` and `stack_store` in the\n+//! function which has the stack slots. This optimization also assumes that stack slot accesses\n+//! are never out of bounds. If these assumptions are not correct, then this optimization may remove\n+//! `stack_store` instruction incorrectly, or incorrectly use a previously stored value as the value\n+//! being loaded by a `stack_load`.\n+\n+use std::collections::{BTreeMap, HashSet};\n+use std::ops::Not;\n+\n+use cranelift_codegen::cursor::{Cursor, FuncCursor};\n+use cranelift_codegen::entity::EntitySet;\n+use cranelift_codegen::ir::{InstructionData, Opcode, ValueDef};\n+use cranelift_codegen::ir::immediates::Offset32;\n+\n+use crate::prelude::*;\n+\n+/// Workaround for `StackSlot` not implementing `Ord`.\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+struct OrdStackSlot(StackSlot);\n+\n+impl PartialOrd for OrdStackSlot {\n+    fn partial_cmp(&self, rhs: &Self) -> Option<std::cmp::Ordering> {\n+        self.0.as_u32().partial_cmp(&rhs.0.as_u32())\n+    }\n+}\n+\n+impl Ord for OrdStackSlot {\n+    fn cmp(&self, rhs: &Self) -> std::cmp::Ordering {\n+        self.0.as_u32().cmp(&rhs.0.as_u32())\n+    }\n+}\n+\n+#[derive(Debug, Default)]\n+struct StackSlotUsage {\n+    stack_addr: HashSet<Inst>,\n+    stack_load: HashSet<Inst>,\n+    stack_store: HashSet<Inst>,\n+}\n+\n+impl StackSlotUsage {\n+    fn potential_stores_for_load(&self, ctx: &Context, load: Inst) -> Vec<Inst> {\n+        self.stack_store.iter().cloned().filter(|&store| {\n+            match spatial_overlap(&ctx.func, store, load) {\n+                SpatialOverlap::No => false, // Can never be the source of the loaded value.\n+                SpatialOverlap::Partial | SpatialOverlap::Full => true,\n+            }\n+        }).filter(|&store| {\n+            match temporal_order(ctx, store, load) {\n+                TemporalOrder::NeverBefore => false, // Can never be the source of the loaded value.\n+                TemporalOrder::MaybeBefore | TemporalOrder::DefinitivelyBefore => true,\n+            }\n+        }).collect::<Vec<Inst>>()\n+    }\n+\n+    fn potential_loads_of_store(&self, ctx: &Context, store: Inst) -> Vec<Inst> {\n+        self.stack_load.iter().cloned().filter(|&load| {\n+            match spatial_overlap(&ctx.func, store, load) {\n+                SpatialOverlap::No => false, // Can never be the source of the loaded value.\n+                SpatialOverlap::Partial | SpatialOverlap::Full => true,\n+            }\n+        }).filter(|&load| {\n+            match temporal_order(ctx, store, load) {\n+                TemporalOrder::NeverBefore => false, // Can never be the source of the loaded value.\n+                TemporalOrder::MaybeBefore | TemporalOrder::DefinitivelyBefore => true,\n+            }\n+        }).collect::<Vec<Inst>>()\n+    }\n+\n+    fn remove_unused_stack_addr(&mut self, func: &mut Function, inst: Inst) {\n+        func.dfg.detach_results(inst);\n+        func.dfg.replace(inst).nop();\n+        self.stack_addr.remove(&inst);\n+    }\n+\n+    fn remove_unused_load(&mut self, func: &mut Function, load: Inst) {\n+        func.dfg.detach_results(load);\n+        func.dfg.replace(load).nop();\n+        self.stack_load.remove(&load);\n+    }\n+\n+    fn remove_dead_store(&mut self, func: &mut Function, store: Inst) {\n+        func.dfg.replace(store).nop();\n+        self.stack_store.remove(&store);\n+    }\n+\n+    fn change_load_to_alias(&mut self, func: &mut Function, load: Inst, value: Value) {\n+        let loaded_value = func.dfg.inst_results(load)[0];\n+        let loaded_type = func.dfg.value_type(loaded_value);\n+\n+        if func.dfg.value_type(value) == loaded_type {\n+            func.dfg.detach_results(load);\n+            func.dfg.replace(load).nop();\n+            func.dfg.change_to_alias(loaded_value, value);\n+        } else {\n+            func.dfg.replace(load).bitcast(loaded_type, value);\n+        }\n+\n+        self.stack_load.remove(&load);\n+    }\n+}\n+\n+struct OptimizeContext<'a> {\n+    ctx: &'a mut Context,\n+    stack_slot_usage_map: BTreeMap<OrdStackSlot, StackSlotUsage>,\n+}\n+\n+impl<'a> OptimizeContext<'a> {\n+    fn for_context(ctx: &'a mut Context) -> Self {\n+        ctx.flowgraph(); // Compute cfg and domtree.\n+\n+        // Record all stack_addr, stack_load and stack_store instructions.\n+        let mut stack_slot_usage_map = BTreeMap::<OrdStackSlot, StackSlotUsage>::new();\n+\n+        let mut cursor = FuncCursor::new(&mut ctx.func);\n+        while let Some(_ebb) = cursor.next_ebb() {\n+            while let Some(inst) = cursor.next_inst() {\n+                match cursor.func.dfg[inst] {\n+                    InstructionData::StackLoad {\n+                        opcode: Opcode::StackAddr,\n+                        stack_slot,\n+                        offset: _,\n+                    } => {\n+                        stack_slot_usage_map.entry(OrdStackSlot(stack_slot)).or_insert_with(StackSlotUsage::default).stack_addr.insert(inst);\n+                    }\n+                    InstructionData::StackLoad {\n+                        opcode: Opcode::StackLoad,\n+                        stack_slot,\n+                        offset: _,\n+                    } => {\n+                        stack_slot_usage_map.entry(OrdStackSlot(stack_slot)).or_insert_with(StackSlotUsage::default).stack_load.insert(inst);\n+                    }\n+                    InstructionData::StackStore {\n+                        opcode: Opcode::StackStore,\n+                        arg: _,\n+                        stack_slot,\n+                        offset: _,\n+                    } => {\n+                        stack_slot_usage_map.entry(OrdStackSlot(stack_slot)).or_insert_with(StackSlotUsage::default).stack_store.insert(inst);\n+                    }\n+                    _ => {}\n+                }\n+            }\n+        }\n+\n+        OptimizeContext {\n+            ctx,\n+            stack_slot_usage_map,\n+        }\n+    }\n+}\n+\n+pub(super) fn optimize_function<T: std::fmt::Debug>(\n+    ctx: &mut Context,\n+    clif_comments: &mut crate::pretty_clif::CommentWriter,\n+    name: T,\n+) {\n+    combine_stack_addr_with_load_store(&mut ctx.func);\n+\n+    let mut opt_ctx = OptimizeContext::for_context(ctx);\n+\n+    // FIXME Repeat following instructions until fixpoint.\n+\n+    remove_unused_stack_addr_and_stack_load(&mut opt_ctx);\n+\n+    #[cfg(debug_assertions)] {\n+        println!(\"stack slot usage: {:?}\", opt_ctx.stack_slot_usage_map);\n+    }\n+\n+    for (stack_slot, users) in opt_ctx.stack_slot_usage_map.iter_mut() {\n+        if users.stack_addr.is_empty().not() {\n+            // Stack addr leaked; there may be unknown loads and stores.\n+            // FIXME use stacked borrows to optimize\n+            continue;\n+        }\n+\n+        for load in users.stack_load.clone().into_iter() {\n+            let potential_stores = users.potential_stores_for_load(&opt_ctx.ctx, load);\n+\n+            #[cfg(debug_assertions)]\n+            for &store in &potential_stores {\n+                println!(\n+                    \"Potential store -> load forwarding {} -> {} ({:?}, {:?})\",\n+                    opt_ctx.ctx.func.dfg.display_inst(store, None),\n+                    opt_ctx.ctx.func.dfg.display_inst(load, None),\n+                    spatial_overlap(&opt_ctx.ctx.func, store, load),\n+                    temporal_order(&opt_ctx.ctx, store, load),\n+                );\n+            }\n+\n+            match *potential_stores {\n+                [] => {\n+                    #[cfg(debug_assertions)] {\n+                        println!(\"[{:?}] [BUG?] Reading uninitialized memory\", name);\n+                    }\n+                }\n+                [store] if spatial_overlap(&opt_ctx.ctx.func, store, load) == SpatialOverlap::Full && temporal_order(&opt_ctx.ctx, store, load) == TemporalOrder::DefinitivelyBefore => {\n+                    // Only one store could have been the origin of the value.\n+                    let stored_value = opt_ctx.ctx.func.dfg.inst_args(store)[0];\n+\n+                    #[cfg(debug_assertions)] {\n+                        println!(\"Store to load forward {} -> {}\", store, load);\n+                    }\n+\n+                    users.change_load_to_alias(&mut opt_ctx.ctx.func, load, stored_value);\n+                }\n+                _ => {} // FIXME implement this\n+            }\n+        }\n+\n+        for store in users.stack_store.clone().into_iter() {\n+            let potential_loads = users.potential_loads_of_store(&opt_ctx.ctx, store);\n+\n+            #[cfg(debug_assertions)]\n+            for &load in &potential_loads {\n+                println!(\n+                    \"Potential load from store {} <- {} ({:?}, {:?})\",\n+                    opt_ctx.ctx.func.dfg.display_inst(load, None),\n+                    opt_ctx.ctx.func.dfg.display_inst(store, None),\n+                    spatial_overlap(&opt_ctx.ctx.func, store, load),\n+                    temporal_order(&opt_ctx.ctx, store, load),\n+                );\n+            }\n+\n+            if potential_loads.is_empty() {\n+                // Never loaded; can safely remove all stores and the stack slot.\n+                // FIXME also remove stores when there is always a next store before a load.\n+\n+                #[cfg(debug_assertions)] {\n+                    println!(\"[{:?}] Remove dead stack store {} of {}\", name, opt_ctx.ctx.func.dfg.display_inst(store, None), stack_slot.0);\n+                }\n+                users.remove_dead_store(&mut opt_ctx.ctx.func, store);\n+            }\n+        }\n+\n+        if users.stack_store.is_empty() && users.stack_load.is_empty() {\n+            // FIXME make stack_slot zero sized.\n+        }\n+    }\n+\n+    #[cfg(debug_assertions)] {\n+        println!();\n+    }\n+}\n+\n+fn combine_stack_addr_with_load_store(func: &mut Function) {\n+    // Turn load and store into stack_load and stack_store when possible.\n+    let mut cursor = FuncCursor::new(func);\n+    while let Some(_ebb) = cursor.next_ebb() {\n+        while let Some(inst) = cursor.next_inst() {\n+            match cursor.func.dfg[inst] {\n+                InstructionData::Load { opcode: Opcode::Load, arg: addr, flags: _, offset } => {\n+                    if cursor.func.dfg.ctrl_typevar(inst) == types::I128 || cursor.func.dfg.ctrl_typevar(inst).is_vector() {\n+                        continue; // WORKAROUD: stack_load.i128 not yet implemented\n+                    }\n+                    if let Some((stack_slot, stack_addr_offset)) = try_get_stack_slot_and_offset_for_addr(cursor.func, addr) {\n+                        if let Some(combined_offset) = offset.try_add_i64(stack_addr_offset.into()) {\n+                            let ty = cursor.func.dfg.ctrl_typevar(inst);\n+                            cursor.func.dfg.replace(inst).stack_load(ty, stack_slot, combined_offset);\n+                        }\n+                    }\n+                }\n+                InstructionData::Store { opcode: Opcode::Store, args: [value, addr], flags: _, offset } => {\n+                    if cursor.func.dfg.ctrl_typevar(inst) == types::I128 || cursor.func.dfg.ctrl_typevar(inst).is_vector() {\n+                        continue; // WORKAROUND: stack_store.i128 not yet implemented\n+                    }\n+                    if let Some((stack_slot, stack_addr_offset)) = try_get_stack_slot_and_offset_for_addr(cursor.func, addr) {\n+                        if let Some(combined_offset) = offset.try_add_i64(stack_addr_offset.into()) {\n+                            cursor.func.dfg.replace(inst).stack_store(value, stack_slot, combined_offset);\n+                        }\n+                    }\n+                }\n+                _ => {}\n+            }\n+        }\n+    }\n+}\n+\n+fn remove_unused_stack_addr_and_stack_load(opt_ctx: &mut OptimizeContext) {\n+    // FIXME incrementally rebuild on each call?\n+    let mut stack_addr_load_insts_users = HashMap::<Inst, HashSet<Inst>>::new();\n+\n+    let mut cursor = FuncCursor::new(&mut opt_ctx.ctx.func);\n+    while let Some(_ebb) = cursor.next_ebb() {\n+        while let Some(inst) = cursor.next_inst() {\n+            for &arg in cursor.func.dfg.inst_args(inst) {\n+                if let ValueDef::Result(arg_origin, 0) = cursor.func.dfg.value_def(arg) {\n+                    match cursor.func.dfg[arg_origin].opcode() {\n+                        Opcode::StackAddr | Opcode::StackLoad => {\n+                            stack_addr_load_insts_users.entry(arg_origin).or_insert_with(HashSet::new).insert(inst);\n+                        }\n+                        _ => {}\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    #[cfg(debug_assertions)]\n+    for inst in stack_addr_load_insts_users.keys() {\n+        let mut is_recorded_stack_addr_or_stack_load = false;\n+        for stack_slot_users in opt_ctx.stack_slot_usage_map.values() {\n+            is_recorded_stack_addr_or_stack_load |= stack_slot_users.stack_addr.contains(inst) || stack_slot_users.stack_load.contains(inst);\n+        }\n+        assert!(is_recorded_stack_addr_or_stack_load);\n+    }\n+\n+    // Replace all unused stack_addr and stack_load instructions with nop.\n+    for stack_slot_users in opt_ctx.stack_slot_usage_map.values_mut() {\n+        // FIXME remove clone\n+        for &inst in stack_slot_users.stack_addr.clone().iter() {\n+            if stack_addr_load_insts_users.get(&inst).map(|users| users.is_empty()).unwrap_or(true) {\n+                stack_slot_users.remove_unused_stack_addr(&mut opt_ctx.ctx.func, inst);\n+            }\n+        }\n+\n+        for &inst in stack_slot_users.stack_load.clone().iter() {\n+            if stack_addr_load_insts_users.get(&inst).map(|users| users.is_empty()).unwrap_or(true) {\n+                stack_slot_users.remove_unused_load(&mut opt_ctx.ctx.func, inst);\n+            }\n+        }\n+    }\n+}\n+\n+fn try_get_stack_slot_and_offset_for_addr(func: &Function, addr: Value) -> Option<(StackSlot, Offset32)> {\n+    if let ValueDef::Result(addr_inst, 0) = func.dfg.value_def(addr) {\n+        if let InstructionData::StackLoad {\n+            opcode: Opcode::StackAddr,\n+            stack_slot,\n+            offset,\n+        } = func.dfg[addr_inst] {\n+            return Some((stack_slot, offset));\n+        }\n+    }\n+    None\n+}\n+\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+enum SpatialOverlap {\n+    No,\n+    Partial,\n+    Full,\n+}\n+\n+fn spatial_overlap(func: &Function, src: Inst, dest: Inst) -> SpatialOverlap {\n+    fn inst_info(func: &Function, inst: Inst) -> (StackSlot, Offset32, u32) {\n+        match func.dfg[inst] {\n+            InstructionData::StackLoad {\n+                opcode: Opcode::StackAddr,\n+                stack_slot,\n+                offset,\n+            }\n+            | InstructionData::StackLoad {\n+                opcode: Opcode::StackLoad,\n+                stack_slot,\n+                offset,\n+            }\n+            | InstructionData::StackStore {\n+                opcode: Opcode::StackStore,\n+                stack_slot,\n+                offset,\n+                arg: _,\n+            } => (stack_slot, offset, func.dfg.ctrl_typevar(inst).bytes()),\n+            _ => unreachable!(\"{:?}\", func.dfg[inst]),\n+        }\n+    }\n+\n+    debug_assert_ne!(src, dest);\n+\n+    let (src_ss, src_offset, src_size) = inst_info(func, src);\n+    let (dest_ss, dest_offset, dest_size) = inst_info(func, dest);\n+\n+    if src_ss != dest_ss {\n+        return SpatialOverlap::No;\n+    }\n+\n+    if src_offset == dest_offset && src_size == dest_size {\n+        return SpatialOverlap::Full;\n+    }\n+\n+    let src_end: i64 = src_offset.try_add_i64(i64::from(src_size)).unwrap().into();\n+    let dest_end: i64 = dest_offset.try_add_i64(i64::from(dest_size)).unwrap().into();\n+    if src_end <= dest_offset.into() || dest_end <= src_offset.into() {\n+        return SpatialOverlap::No;\n+    }\n+\n+    SpatialOverlap::Partial\n+}\n+\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+enum TemporalOrder {\n+    /// `src` will never be executed before `dest`.\n+    NeverBefore,\n+\n+    /// `src` may be executed before `dest`.\n+    MaybeBefore,\n+\n+    /// `src` will always be executed before `dest`.\n+    /// There may still be other instructions in between.\n+    DefinitivelyBefore,\n+}\n+\n+fn temporal_order(ctx: &Context, src: Inst, dest: Inst) -> TemporalOrder {\n+    debug_assert_ne!(src, dest);\n+\n+    if ctx.domtree.dominates(src, dest, &ctx.func.layout) {\n+        TemporalOrder::DefinitivelyBefore\n+    } else if ctx.domtree.dominates(src, dest, &ctx.func.layout) {\n+        TemporalOrder::NeverBefore\n+    } else {\n+        TemporalOrder::MaybeBefore\n+    }\n+}"}]}