{"sha": "a49c6b8a57d954fab4555e6a8796af0f25fdf5d2", "node_id": "C_kwDOAAsO6NoAKGE0OWM2YjhhNTdkOTU0ZmFiNDU1NWU2YTg3OTZhZjBmMjVmZGY1ZDI", "commit": {"author": {"name": "bjorn3", "email": "bjorn3@users.noreply.github.com", "date": "2021-11-22T17:50:12Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-11-22T17:50:12Z"}, "message": "Merge pull request #1206 from nbdd0121/master\n\nImprove inline asm support", "tree": {"sha": "ce70df753451733fead8fd2253481f19bd40d9bc", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ce70df753451733fead8fd2253481f19bd40d9bc"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhm9hUCRBK7hj4Ov3rIwAAac4IAA0yblRLSTXbr8TEuPDBUEJq\n6H48968iKZ1+bKoAXLWNOeNiiFYBo8wY7SUuswYtmRy85vYT7ntUgXVJAqENMclQ\nPwGFby4fnkGMmkgt5h41UplD1y0uOddNKJhMjuBMNTTpnCq6UaoLxSxfP/xKbxuH\nh2/D9umhEJOODi+mVskK07V9oqeIMYJk6LDwitNVW+FgNecQsRij3fhLIu2K0MGS\nJHGPq1BEhF0tjZML1s0lCq70nzMa9ITdctTkqlypPMXsnnCrAPSjjpKDYClZRdNw\n3SodSWSJYoQ2PjXgdLJI6HOUKYwO46w8QH82tJmC0b+AEF2MerrTsZh5axuBTp8=\n=evvI\n-----END PGP SIGNATURE-----\n", "payload": "tree ce70df753451733fead8fd2253481f19bd40d9bc\nparent fd87c6dab95dc1b24f136f9b28b236999e8dd2cf\nparent 5f0c6e5539c66c251f562542cc6c1c01bcbdc75c\nauthor bjorn3 <bjorn3@users.noreply.github.com> 1637603412 +0100\ncommitter GitHub <noreply@github.com> 1637603412 +0100\n\nMerge pull request #1206 from nbdd0121/master\n\nImprove inline asm support"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2", "html_url": "https://github.com/rust-lang/rust/commit/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2/comments", "author": {"login": "bjorn3", "id": 17426603, "node_id": "MDQ6VXNlcjE3NDI2NjAz", "avatar_url": "https://avatars.githubusercontent.com/u/17426603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bjorn3", "html_url": "https://github.com/bjorn3", "followers_url": "https://api.github.com/users/bjorn3/followers", "following_url": "https://api.github.com/users/bjorn3/following{/other_user}", "gists_url": "https://api.github.com/users/bjorn3/gists{/gist_id}", "starred_url": "https://api.github.com/users/bjorn3/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bjorn3/subscriptions", "organizations_url": "https://api.github.com/users/bjorn3/orgs", "repos_url": "https://api.github.com/users/bjorn3/repos", "events_url": "https://api.github.com/users/bjorn3/events{/privacy}", "received_events_url": "https://api.github.com/users/bjorn3/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fd87c6dab95dc1b24f136f9b28b236999e8dd2cf", "url": "https://api.github.com/repos/rust-lang/rust/commits/fd87c6dab95dc1b24f136f9b28b236999e8dd2cf", "html_url": "https://github.com/rust-lang/rust/commit/fd87c6dab95dc1b24f136f9b28b236999e8dd2cf"}, {"sha": "5f0c6e5539c66c251f562542cc6c1c01bcbdc75c", "url": "https://api.github.com/repos/rust-lang/rust/commits/5f0c6e5539c66c251f562542cc6c1c01bcbdc75c", "html_url": "https://github.com/rust-lang/rust/commit/5f0c6e5539c66c251f562542cc6c1c01bcbdc75c"}], "stats": {"total": 623, "additions": 476, "deletions": 147}, "files": [{"sha": "706d9cdc166e6c283b5a95f05f3e9d5f130792f3", "filename": "src/inline_asm.rs", "status": "modified", "additions": 476, "deletions": 147, "changes": 623, "blob_url": "https://github.com/rust-lang/rust/blob/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2/src%2Finline_asm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a49c6b8a57d954fab4555e6a8796af0f25fdf5d2/src%2Finline_asm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Finline_asm.rs?ref=a49c6b8a57d954fab4555e6a8796af0f25fdf5d2", "patch": "@@ -6,6 +6,7 @@ use std::fmt::Write;\n \n use rustc_ast::ast::{InlineAsmOptions, InlineAsmTemplatePiece};\n use rustc_middle::mir::InlineAsmOperand;\n+use rustc_span::Symbol;\n use rustc_target::asm::*;\n \n pub(crate) fn codegen_inline_asm<'tcx>(\n@@ -41,8 +42,10 @@ pub(crate) fn codegen_inline_asm<'tcx>(\n         assert_eq!(operands.len(), 4);\n         let (leaf, eax_place) = match operands[1] {\n             InlineAsmOperand::InOut { reg, late: true, ref in_value, out_place } => {\n-                let reg = expect_reg(reg);\n-                assert_eq!(reg, InlineAsmReg::X86(X86InlineAsmReg::ax));\n+                assert_eq!(\n+                    reg,\n+                    InlineAsmRegOrRegClass::Reg(InlineAsmReg::X86(X86InlineAsmReg::ax))\n+                );\n                 (\n                     crate::base::codegen_operand(fx, in_value).load_scalar(fx),\n                     crate::base::codegen_place(fx, out_place.unwrap()),\n@@ -64,8 +67,10 @@ pub(crate) fn codegen_inline_asm<'tcx>(\n         };\n         let (sub_leaf, ecx_place) = match operands[2] {\n             InlineAsmOperand::InOut { reg, late: true, ref in_value, out_place } => {\n-                let reg = expect_reg(reg);\n-                assert_eq!(reg, InlineAsmReg::X86(X86InlineAsmReg::cx));\n+                assert_eq!(\n+                    reg,\n+                    InlineAsmRegOrRegClass::Reg(InlineAsmReg::X86(X86InlineAsmReg::cx))\n+                );\n                 (\n                     crate::base::codegen_operand(fx, in_value).load_scalar(fx),\n                     crate::base::codegen_place(fx, out_place.unwrap()),\n@@ -75,8 +80,10 @@ pub(crate) fn codegen_inline_asm<'tcx>(\n         };\n         let edx_place = match operands[3] {\n             InlineAsmOperand::Out { reg, late: true, place } => {\n-                let reg = expect_reg(reg);\n-                assert_eq!(reg, InlineAsmReg::X86(X86InlineAsmReg::dx));\n+                assert_eq!(\n+                    reg,\n+                    InlineAsmRegOrRegClass::Reg(InlineAsmReg::X86(X86InlineAsmReg::dx))\n+                );\n                 crate::base::codegen_place(fx, place.unwrap())\n             }\n             _ => unreachable!(),\n@@ -96,60 +103,55 @@ pub(crate) fn codegen_inline_asm<'tcx>(\n         crate::trap::trap_unimplemented(fx, \"Alloca is not supported\");\n     }\n \n-    let mut slot_size = Size::from_bytes(0);\n-    let mut clobbered_regs = Vec::new();\n     let mut inputs = Vec::new();\n     let mut outputs = Vec::new();\n \n-    let mut new_slot = |reg_class: InlineAsmRegClass| {\n-        let reg_size = reg_class\n-            .supported_types(InlineAsmArch::X86_64)\n-            .iter()\n-            .map(|(ty, _)| ty.size())\n-            .max()\n-            .unwrap();\n-        let align = rustc_target::abi::Align::from_bytes(reg_size.bytes()).unwrap();\n-        slot_size = slot_size.align_to(align);\n-        let offset = slot_size;\n-        slot_size += reg_size;\n-        offset\n+    let mut asm_gen = InlineAssemblyGenerator {\n+        tcx: fx.tcx,\n+        arch: fx.tcx.sess.asm_arch.unwrap(),\n+        template,\n+        operands,\n+        options,\n+        registers: Vec::new(),\n+        stack_slots_clobber: Vec::new(),\n+        stack_slots_input: Vec::new(),\n+        stack_slots_output: Vec::new(),\n+        stack_slot_size: Size::from_bytes(0),\n     };\n+    asm_gen.allocate_registers();\n+    asm_gen.allocate_stack_slots();\n+\n+    let inline_asm_index = fx.inline_asm_index;\n+    fx.inline_asm_index += 1;\n+    let asm_name = format!(\"{}__inline_asm_{}\", fx.symbol_name, inline_asm_index);\n \n-    // FIXME overlap input and output slots to save stack space\n-    for operand in operands {\n+    let generated_asm = asm_gen.generate_asm_wrapper(&asm_name);\n+    fx.cx.global_asm.push_str(&generated_asm);\n+\n+    for (i, operand) in operands.iter().enumerate() {\n         match *operand {\n-            InlineAsmOperand::In { reg, ref value } => {\n-                let reg = expect_reg(reg);\n-                clobbered_regs.push((reg, new_slot(reg.reg_class())));\n+            InlineAsmOperand::In { reg: _, ref value } => {\n                 inputs.push((\n-                    reg,\n-                    new_slot(reg.reg_class()),\n+                    asm_gen.stack_slots_input[i].unwrap(),\n                     crate::base::codegen_operand(fx, value).load_scalar(fx),\n                 ));\n             }\n-            InlineAsmOperand::Out { reg, late: _, place } => {\n-                let reg = expect_reg(reg);\n-                clobbered_regs.push((reg, new_slot(reg.reg_class())));\n+            InlineAsmOperand::Out { reg: _, late: _, place } => {\n                 if let Some(place) = place {\n                     outputs.push((\n-                        reg,\n-                        new_slot(reg.reg_class()),\n+                        asm_gen.stack_slots_output[i].unwrap(),\n                         crate::base::codegen_place(fx, place),\n                     ));\n                 }\n             }\n-            InlineAsmOperand::InOut { reg, late: _, ref in_value, out_place } => {\n-                let reg = expect_reg(reg);\n-                clobbered_regs.push((reg, new_slot(reg.reg_class())));\n+            InlineAsmOperand::InOut { reg: _, late: _, ref in_value, out_place } => {\n                 inputs.push((\n-                    reg,\n-                    new_slot(reg.reg_class()),\n+                    asm_gen.stack_slots_input[i].unwrap(),\n                     crate::base::codegen_operand(fx, in_value).load_scalar(fx),\n                 ));\n                 if let Some(out_place) = out_place {\n                     outputs.push((\n-                        reg,\n-                        new_slot(reg.reg_class()),\n+                        asm_gen.stack_slots_output[i].unwrap(),\n                         crate::base::codegen_place(fx, out_place),\n                     ));\n                 }\n@@ -160,106 +162,467 @@ pub(crate) fn codegen_inline_asm<'tcx>(\n         }\n     }\n \n-    let inline_asm_index = fx.inline_asm_index;\n-    fx.inline_asm_index += 1;\n-    let asm_name = format!(\"{}__inline_asm_{}\", fx.symbol_name, inline_asm_index);\n-\n-    let generated_asm = generate_asm_wrapper(\n-        &asm_name,\n-        InlineAsmArch::X86_64,\n-        options,\n-        template,\n-        clobbered_regs,\n-        &inputs,\n-        &outputs,\n-    );\n-    fx.cx.global_asm.push_str(&generated_asm);\n-\n-    call_inline_asm(fx, &asm_name, slot_size, inputs, outputs);\n+    call_inline_asm(fx, &asm_name, asm_gen.stack_slot_size, inputs, outputs);\n }\n \n-fn generate_asm_wrapper(\n-    asm_name: &str,\n+struct InlineAssemblyGenerator<'a, 'tcx> {\n+    tcx: TyCtxt<'tcx>,\n     arch: InlineAsmArch,\n+    template: &'a [InlineAsmTemplatePiece],\n+    operands: &'a [InlineAsmOperand<'tcx>],\n     options: InlineAsmOptions,\n-    template: &[InlineAsmTemplatePiece],\n-    clobbered_regs: Vec<(InlineAsmReg, Size)>,\n-    inputs: &[(InlineAsmReg, Size, Value)],\n-    outputs: &[(InlineAsmReg, Size, CPlace<'_>)],\n-) -> String {\n-    let mut generated_asm = String::new();\n-    writeln!(generated_asm, \".globl {}\", asm_name).unwrap();\n-    writeln!(generated_asm, \".type {},@function\", asm_name).unwrap();\n-    writeln!(generated_asm, \".section .text.{},\\\"ax\\\",@progbits\", asm_name).unwrap();\n-    writeln!(generated_asm, \"{}:\", asm_name).unwrap();\n-\n-    generated_asm.push_str(\".intel_syntax noprefix\\n\");\n-    generated_asm.push_str(\"    push rbp\\n\");\n-    generated_asm.push_str(\"    mov rbp,rdi\\n\");\n-\n-    // Save clobbered registers\n-    if !options.contains(InlineAsmOptions::NORETURN) {\n-        // FIXME skip registers saved by the calling convention\n-        for &(reg, offset) in &clobbered_regs {\n-            save_register(&mut generated_asm, arch, reg, offset);\n+    registers: Vec<Option<InlineAsmReg>>,\n+    stack_slots_clobber: Vec<Option<Size>>,\n+    stack_slots_input: Vec<Option<Size>>,\n+    stack_slots_output: Vec<Option<Size>>,\n+    stack_slot_size: Size,\n+}\n+\n+impl<'tcx> InlineAssemblyGenerator<'_, 'tcx> {\n+    fn allocate_registers(&mut self) {\n+        let sess = self.tcx.sess;\n+        let map = allocatable_registers(\n+            self.arch,\n+            |feature| sess.target_features.contains(&Symbol::intern(feature)),\n+            &sess.target,\n+        );\n+        let mut allocated = FxHashMap::<_, (bool, bool)>::default();\n+        let mut regs = vec![None; self.operands.len()];\n+\n+        // Add explicit registers to the allocated set.\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::In { reg: InlineAsmRegOrRegClass::Reg(reg), .. } => {\n+                    regs[i] = Some(reg);\n+                    allocated.entry(reg).or_default().0 = true;\n+                }\n+                InlineAsmOperand::Out {\n+                    reg: InlineAsmRegOrRegClass::Reg(reg), late: true, ..\n+                } => {\n+                    regs[i] = Some(reg);\n+                    allocated.entry(reg).or_default().1 = true;\n+                }\n+                InlineAsmOperand::Out { reg: InlineAsmRegOrRegClass::Reg(reg), .. }\n+                | InlineAsmOperand::InOut { reg: InlineAsmRegOrRegClass::Reg(reg), .. } => {\n+                    regs[i] = Some(reg);\n+                    allocated.insert(reg, (true, true));\n+                }\n+                _ => (),\n+            }\n         }\n-    }\n \n-    // Write input registers\n-    for &(reg, offset, _value) in inputs {\n-        restore_register(&mut generated_asm, arch, reg, offset);\n-    }\n+        // Allocate out/inout/inlateout registers first because they are more constrained.\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::Out {\n+                    reg: InlineAsmRegOrRegClass::RegClass(class),\n+                    late: false,\n+                    ..\n+                }\n+                | InlineAsmOperand::InOut {\n+                    reg: InlineAsmRegOrRegClass::RegClass(class), ..\n+                } => {\n+                    let mut alloc_reg = None;\n+                    for &reg in &map[&class] {\n+                        let mut used = false;\n+                        reg.overlapping_regs(|r| {\n+                            if allocated.contains_key(&r) {\n+                                used = true;\n+                            }\n+                        });\n+\n+                        if !used {\n+                            alloc_reg = Some(reg);\n+                            break;\n+                        }\n+                    }\n+\n+                    let reg = alloc_reg.expect(\"cannot allocate registers\");\n+                    regs[i] = Some(reg);\n+                    allocated.insert(reg, (true, true));\n+                }\n+                _ => (),\n+            }\n+        }\n+\n+        // Allocate in/lateout.\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::In { reg: InlineAsmRegOrRegClass::RegClass(class), .. } => {\n+                    let mut alloc_reg = None;\n+                    for &reg in &map[&class] {\n+                        let mut used = false;\n+                        reg.overlapping_regs(|r| {\n+                            if allocated.get(&r).copied().unwrap_or_default().0 {\n+                                used = true;\n+                            }\n+                        });\n+\n+                        if !used {\n+                            alloc_reg = Some(reg);\n+                            break;\n+                        }\n+                    }\n+\n+                    let reg = alloc_reg.expect(\"cannot allocate registers\");\n+                    regs[i] = Some(reg);\n+                    allocated.entry(reg).or_default().0 = true;\n+                }\n+                InlineAsmOperand::Out {\n+                    reg: InlineAsmRegOrRegClass::RegClass(class),\n+                    late: true,\n+                    ..\n+                } => {\n+                    let mut alloc_reg = None;\n+                    for &reg in &map[&class] {\n+                        let mut used = false;\n+                        reg.overlapping_regs(|r| {\n+                            if allocated.get(&r).copied().unwrap_or_default().1 {\n+                                used = true;\n+                            }\n+                        });\n+\n+                        if !used {\n+                            alloc_reg = Some(reg);\n+                            break;\n+                        }\n+                    }\n+\n+                    let reg = alloc_reg.expect(\"cannot allocate registers\");\n+                    regs[i] = Some(reg);\n+                    allocated.entry(reg).or_default().1 = true;\n+                }\n+                _ => (),\n+            }\n+        }\n \n-    if options.contains(InlineAsmOptions::ATT_SYNTAX) {\n-        generated_asm.push_str(\".att_syntax\\n\");\n+        self.registers = regs;\n     }\n \n-    // The actual inline asm\n-    for piece in template {\n-        match piece {\n-            InlineAsmTemplatePiece::String(s) => {\n-                generated_asm.push_str(s);\n+    fn allocate_stack_slots(&mut self) {\n+        let mut slot_size = Size::from_bytes(0);\n+        let mut slots_clobber = vec![None; self.operands.len()];\n+        let mut slots_input = vec![None; self.operands.len()];\n+        let mut slots_output = vec![None; self.operands.len()];\n+\n+        let new_slot_fn = |slot_size: &mut Size, reg_class: InlineAsmRegClass| {\n+            let reg_size =\n+                reg_class.supported_types(self.arch).iter().map(|(ty, _)| ty.size()).max().unwrap();\n+            let align = rustc_target::abi::Align::from_bytes(reg_size.bytes()).unwrap();\n+            let offset = slot_size.align_to(align);\n+            *slot_size = offset + reg_size;\n+            offset\n+        };\n+        let mut new_slot = |x| new_slot_fn(&mut slot_size, x);\n+\n+        // Allocate stack slots for saving clobbered registers\n+        let abi_clobber =\n+            InlineAsmClobberAbi::parse(self.arch, &self.tcx.sess.target, Symbol::intern(\"C\"))\n+                .unwrap()\n+                .clobbered_regs();\n+        for (i, reg) in self.registers.iter().enumerate().filter_map(|(i, r)| r.map(|r| (i, r))) {\n+            let mut need_save = true;\n+            // If the register overlaps with a register clobbered by function call, then\n+            // we don't need to save it.\n+            for r in abi_clobber {\n+                r.overlapping_regs(|r| {\n+                    if r == reg {\n+                        need_save = false;\n+                    }\n+                });\n+\n+                if !need_save {\n+                    break;\n+                }\n+            }\n+\n+            if need_save {\n+                slots_clobber[i] = Some(new_slot(reg.reg_class()));\n+            }\n+        }\n+\n+        // Allocate stack slots for inout\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::InOut { reg, out_place: Some(_), .. } => {\n+                    let slot = new_slot(reg.reg_class());\n+                    slots_input[i] = Some(slot);\n+                    slots_output[i] = Some(slot);\n+                }\n+                _ => (),\n+            }\n+        }\n+\n+        let slot_size_before_input = slot_size;\n+        let mut new_slot = |x| new_slot_fn(&mut slot_size, x);\n+\n+        // Allocate stack slots for input\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::In { reg, .. }\n+                | InlineAsmOperand::InOut { reg, out_place: None, .. } => {\n+                    slots_input[i] = Some(new_slot(reg.reg_class()));\n+                }\n+                _ => (),\n+            }\n+        }\n+\n+        // Reset slot size to before input so that input and output operands can overlap\n+        // and save some memory.\n+        let slot_size_after_input = slot_size;\n+        slot_size = slot_size_before_input;\n+        let mut new_slot = |x| new_slot_fn(&mut slot_size, x);\n+\n+        // Allocate stack slots for output\n+        for (i, operand) in self.operands.iter().enumerate() {\n+            match *operand {\n+                InlineAsmOperand::Out { reg, place: Some(_), .. } => {\n+                    slots_output[i] = Some(new_slot(reg.reg_class()));\n+                }\n+                _ => (),\n             }\n-            InlineAsmTemplatePiece::Placeholder { operand_idx: _, modifier: _, span: _ } => todo!(),\n         }\n+\n+        slot_size = slot_size.max(slot_size_after_input);\n+\n+        self.stack_slots_clobber = slots_clobber;\n+        self.stack_slots_input = slots_input;\n+        self.stack_slots_output = slots_output;\n+        self.stack_slot_size = slot_size;\n     }\n-    generated_asm.push('\\n');\n \n-    if options.contains(InlineAsmOptions::ATT_SYNTAX) {\n-        generated_asm.push_str(\".intel_syntax noprefix\\n\");\n+    fn generate_asm_wrapper(&self, asm_name: &str) -> String {\n+        let mut generated_asm = String::new();\n+        writeln!(generated_asm, \".globl {}\", asm_name).unwrap();\n+        writeln!(generated_asm, \".type {},@function\", asm_name).unwrap();\n+        writeln!(generated_asm, \".section .text.{},\\\"ax\\\",@progbits\", asm_name).unwrap();\n+        writeln!(generated_asm, \"{}:\", asm_name).unwrap();\n+\n+        let is_x86 = matches!(self.arch, InlineAsmArch::X86 | InlineAsmArch::X86_64);\n+\n+        if is_x86 {\n+            generated_asm.push_str(\".intel_syntax noprefix\\n\");\n+        }\n+        Self::prologue(&mut generated_asm, self.arch);\n+\n+        // Save clobbered registers\n+        if !self.options.contains(InlineAsmOptions::NORETURN) {\n+            for (reg, slot) in self\n+                .registers\n+                .iter()\n+                .zip(self.stack_slots_clobber.iter().copied())\n+                .filter_map(|(r, s)| r.zip(s))\n+            {\n+                Self::save_register(&mut generated_asm, self.arch, reg, slot);\n+            }\n+        }\n+\n+        // Write input registers\n+        for (reg, slot) in self\n+            .registers\n+            .iter()\n+            .zip(self.stack_slots_input.iter().copied())\n+            .filter_map(|(r, s)| r.zip(s))\n+        {\n+            Self::restore_register(&mut generated_asm, self.arch, reg, slot);\n+        }\n+\n+        if is_x86 && self.options.contains(InlineAsmOptions::ATT_SYNTAX) {\n+            generated_asm.push_str(\".att_syntax\\n\");\n+        }\n+\n+        // The actual inline asm\n+        for piece in self.template {\n+            match piece {\n+                InlineAsmTemplatePiece::String(s) => {\n+                    generated_asm.push_str(s);\n+                }\n+                InlineAsmTemplatePiece::Placeholder { operand_idx, modifier, span: _ } => {\n+                    if self.options.contains(InlineAsmOptions::ATT_SYNTAX) {\n+                        generated_asm.push('%');\n+                    }\n+                    self.registers[*operand_idx]\n+                        .unwrap()\n+                        .emit(&mut generated_asm, self.arch, *modifier)\n+                        .unwrap();\n+                }\n+            }\n+        }\n+        generated_asm.push('\\n');\n+\n+        if is_x86 && self.options.contains(InlineAsmOptions::ATT_SYNTAX) {\n+            generated_asm.push_str(\".intel_syntax noprefix\\n\");\n+        }\n+\n+        if !self.options.contains(InlineAsmOptions::NORETURN) {\n+            // Read output registers\n+            for (reg, slot) in self\n+                .registers\n+                .iter()\n+                .zip(self.stack_slots_output.iter().copied())\n+                .filter_map(|(r, s)| r.zip(s))\n+            {\n+                Self::save_register(&mut generated_asm, self.arch, reg, slot);\n+            }\n+\n+            // Restore clobbered registers\n+            for (reg, slot) in self\n+                .registers\n+                .iter()\n+                .zip(self.stack_slots_clobber.iter().copied())\n+                .filter_map(|(r, s)| r.zip(s))\n+            {\n+                Self::restore_register(&mut generated_asm, self.arch, reg, slot);\n+            }\n+\n+            Self::epilogue(&mut generated_asm, self.arch);\n+        } else {\n+            Self::epilogue_noreturn(&mut generated_asm, self.arch);\n+        }\n+\n+        if is_x86 {\n+            generated_asm.push_str(\".att_syntax\\n\");\n+        }\n+        writeln!(generated_asm, \".size {name}, .-{name}\", name = asm_name).unwrap();\n+        generated_asm.push_str(\".text\\n\");\n+        generated_asm.push_str(\"\\n\\n\");\n+\n+        generated_asm\n     }\n \n-    if !options.contains(InlineAsmOptions::NORETURN) {\n-        // Read output registers\n-        for &(reg, offset, _place) in outputs {\n-            save_register(&mut generated_asm, arch, reg, offset);\n+    fn prologue(generated_asm: &mut String, arch: InlineAsmArch) {\n+        match arch {\n+            InlineAsmArch::X86 => {\n+                generated_asm.push_str(\"    push ebp\\n\");\n+                generated_asm.push_str(\"    mov ebp,[esp+8]\\n\");\n+            }\n+            InlineAsmArch::X86_64 => {\n+                generated_asm.push_str(\"    push rbp\\n\");\n+                generated_asm.push_str(\"    mov rbp,rdi\\n\");\n+            }\n+            InlineAsmArch::RiscV32 => {\n+                generated_asm.push_str(\"    addi sp, sp, -8\\n\");\n+                generated_asm.push_str(\"    sw ra, 4(sp)\\n\");\n+                generated_asm.push_str(\"    sw s0, 0(sp)\\n\");\n+                generated_asm.push_str(\"    mv s0, a0\\n\");\n+            }\n+            InlineAsmArch::RiscV64 => {\n+                generated_asm.push_str(\"    addi sp, sp, -16\\n\");\n+                generated_asm.push_str(\"    sd ra, 8(sp)\\n\");\n+                generated_asm.push_str(\"    sd s0, 0(sp)\\n\");\n+                generated_asm.push_str(\"    mv s0, a0\\n\");\n+            }\n+            _ => unimplemented!(\"prologue for {:?}\", arch),\n         }\n+    }\n \n-        // Restore clobbered registers\n-        for &(reg, offset) in clobbered_regs.iter().rev() {\n-            restore_register(&mut generated_asm, arch, reg, offset);\n+    fn epilogue(generated_asm: &mut String, arch: InlineAsmArch) {\n+        match arch {\n+            InlineAsmArch::X86 => {\n+                generated_asm.push_str(\"    pop ebp\\n\");\n+                generated_asm.push_str(\"    ret\\n\");\n+            }\n+            InlineAsmArch::X86_64 => {\n+                generated_asm.push_str(\"    pop rbp\\n\");\n+                generated_asm.push_str(\"    ret\\n\");\n+            }\n+            InlineAsmArch::RiscV32 => {\n+                generated_asm.push_str(\"    lw s0, 0(sp)\\n\");\n+                generated_asm.push_str(\"    lw ra, 4(sp)\\n\");\n+                generated_asm.push_str(\"    addi sp, sp, 8\\n\");\n+                generated_asm.push_str(\"    ret\\n\");\n+            }\n+            InlineAsmArch::RiscV64 => {\n+                generated_asm.push_str(\"    ld s0, 0(sp)\\n\");\n+                generated_asm.push_str(\"    ld ra, 8(sp)\\n\");\n+                generated_asm.push_str(\"    addi sp, sp, 16\\n\");\n+                generated_asm.push_str(\"    ret\\n\");\n+            }\n+            _ => unimplemented!(\"epilogue for {:?}\", arch),\n         }\n+    }\n \n-        generated_asm.push_str(\"    pop rbp\\n\");\n-        generated_asm.push_str(\"    ret\\n\");\n-    } else {\n-        generated_asm.push_str(\"    ud2\\n\");\n+    fn epilogue_noreturn(generated_asm: &mut String, arch: InlineAsmArch) {\n+        match arch {\n+            InlineAsmArch::X86 | InlineAsmArch::X86_64 => {\n+                generated_asm.push_str(\"    ud2\\n\");\n+            }\n+            InlineAsmArch::RiscV32 | InlineAsmArch::RiscV64 => {\n+                generated_asm.push_str(\"    ebreak\\n\");\n+            }\n+            _ => unimplemented!(\"epilogue_noreturn for {:?}\", arch),\n+        }\n     }\n \n-    generated_asm.push_str(\".att_syntax\\n\");\n-    writeln!(generated_asm, \".size {name}, .-{name}\", name = asm_name).unwrap();\n-    generated_asm.push_str(\".text\\n\");\n-    generated_asm.push_str(\"\\n\\n\");\n+    fn save_register(\n+        generated_asm: &mut String,\n+        arch: InlineAsmArch,\n+        reg: InlineAsmReg,\n+        offset: Size,\n+    ) {\n+        match arch {\n+            InlineAsmArch::X86 => {\n+                write!(generated_asm, \"    mov [ebp+0x{:x}], \", offset.bytes()).unwrap();\n+                reg.emit(generated_asm, InlineAsmArch::X86, None).unwrap();\n+                generated_asm.push('\\n');\n+            }\n+            InlineAsmArch::X86_64 => {\n+                write!(generated_asm, \"    mov [rbp+0x{:x}], \", offset.bytes()).unwrap();\n+                reg.emit(generated_asm, InlineAsmArch::X86_64, None).unwrap();\n+                generated_asm.push('\\n');\n+            }\n+            InlineAsmArch::RiscV32 => {\n+                generated_asm.push_str(\"    sw \");\n+                reg.emit(generated_asm, InlineAsmArch::RiscV32, None).unwrap();\n+                writeln!(generated_asm, \", 0x{:x}(s0)\", offset.bytes()).unwrap();\n+            }\n+            InlineAsmArch::RiscV64 => {\n+                generated_asm.push_str(\"    sd \");\n+                reg.emit(generated_asm, InlineAsmArch::RiscV64, None).unwrap();\n+                writeln!(generated_asm, \", 0x{:x}(s0)\", offset.bytes()).unwrap();\n+            }\n+            _ => unimplemented!(\"save_register for {:?}\", arch),\n+        }\n+    }\n \n-    generated_asm\n+    fn restore_register(\n+        generated_asm: &mut String,\n+        arch: InlineAsmArch,\n+        reg: InlineAsmReg,\n+        offset: Size,\n+    ) {\n+        match arch {\n+            InlineAsmArch::X86 => {\n+                generated_asm.push_str(\"    mov \");\n+                reg.emit(generated_asm, InlineAsmArch::X86, None).unwrap();\n+                writeln!(generated_asm, \", [ebp+0x{:x}]\", offset.bytes()).unwrap();\n+            }\n+            InlineAsmArch::X86_64 => {\n+                generated_asm.push_str(\"    mov \");\n+                reg.emit(generated_asm, InlineAsmArch::X86_64, None).unwrap();\n+                writeln!(generated_asm, \", [rbp+0x{:x}]\", offset.bytes()).unwrap();\n+            }\n+            InlineAsmArch::RiscV32 => {\n+                generated_asm.push_str(\"    lw \");\n+                reg.emit(generated_asm, InlineAsmArch::RiscV32, None).unwrap();\n+                writeln!(generated_asm, \", 0x{:x}(s0)\", offset.bytes()).unwrap();\n+            }\n+            InlineAsmArch::RiscV64 => {\n+                generated_asm.push_str(\"    ld \");\n+                reg.emit(generated_asm, InlineAsmArch::RiscV64, None).unwrap();\n+                writeln!(generated_asm, \", 0x{:x}(s0)\", offset.bytes()).unwrap();\n+            }\n+            _ => unimplemented!(\"restore_register for {:?}\", arch),\n+        }\n+    }\n }\n \n fn call_inline_asm<'tcx>(\n     fx: &mut FunctionCx<'_, '_, 'tcx>,\n     asm_name: &str,\n     slot_size: Size,\n-    inputs: Vec<(InlineAsmReg, Size, Value)>,\n-    outputs: Vec<(InlineAsmReg, Size, CPlace<'tcx>)>,\n+    inputs: Vec<(Size, Value)>,\n+    outputs: Vec<(Size, CPlace<'tcx>)>,\n ) {\n     let stack_slot = fx.bcx.func.create_stack_slot(StackSlotData {\n         kind: StackSlotKind::ExplicitSlot,\n@@ -286,50 +649,16 @@ fn call_inline_asm<'tcx>(\n         fx.add_comment(inline_asm_func, asm_name);\n     }\n \n-    for (_reg, offset, value) in inputs {\n+    for (offset, value) in inputs {\n         fx.bcx.ins().stack_store(value, stack_slot, i32::try_from(offset.bytes()).unwrap());\n     }\n \n     let stack_slot_addr = fx.bcx.ins().stack_addr(fx.pointer_type, stack_slot, 0);\n     fx.bcx.ins().call(inline_asm_func, &[stack_slot_addr]);\n \n-    for (_reg, offset, place) in outputs {\n+    for (offset, place) in outputs {\n         let ty = fx.clif_type(place.layout().ty).unwrap();\n         let value = fx.bcx.ins().stack_load(ty, stack_slot, i32::try_from(offset.bytes()).unwrap());\n         place.write_cvalue(fx, CValue::by_val(value, place.layout()));\n     }\n }\n-\n-fn expect_reg(reg_or_class: InlineAsmRegOrRegClass) -> InlineAsmReg {\n-    match reg_or_class {\n-        InlineAsmRegOrRegClass::Reg(reg) => reg,\n-        InlineAsmRegOrRegClass::RegClass(class) => unimplemented!(\"{:?}\", class),\n-    }\n-}\n-\n-fn save_register(generated_asm: &mut String, arch: InlineAsmArch, reg: InlineAsmReg, offset: Size) {\n-    match arch {\n-        InlineAsmArch::X86_64 => {\n-            write!(generated_asm, \"    mov [rbp+0x{:x}], \", offset.bytes()).unwrap();\n-            reg.emit(generated_asm, InlineAsmArch::X86_64, None).unwrap();\n-            generated_asm.push('\\n');\n-        }\n-        _ => unimplemented!(\"save_register for {:?}\", arch),\n-    }\n-}\n-\n-fn restore_register(\n-    generated_asm: &mut String,\n-    arch: InlineAsmArch,\n-    reg: InlineAsmReg,\n-    offset: Size,\n-) {\n-    match arch {\n-        InlineAsmArch::X86_64 => {\n-            generated_asm.push_str(\"    mov \");\n-            reg.emit(generated_asm, InlineAsmArch::X86_64, None).unwrap();\n-            writeln!(generated_asm, \", [rbp+0x{:x}]\", offset.bytes()).unwrap();\n-        }\n-        _ => unimplemented!(\"restore_register for {:?}\", arch),\n-    }\n-}"}]}