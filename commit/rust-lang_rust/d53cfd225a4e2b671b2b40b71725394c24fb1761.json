{"sha": "d53cfd225a4e2b671b2b40b71725394c24fb1761", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ1M2NmZDIyNWE0ZTJiNjcxYjJiNDBiNzE3MjUzOTRjMjRmYjE3NjE=", "commit": {"author": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-09-18T21:51:40Z"}, "committer": {"name": "Brian Anderson", "email": "banderson@mozilla.com", "date": "2012-09-18T22:23:57Z"}, "message": "core: Move Exclusive and SharedMutableState to the private mod", "tree": {"sha": "dd99d901bd30cb08d82d2d4d8c01d92e8f13b4aa", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dd99d901bd30cb08d82d2d4d8c01d92e8f13b4aa"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d53cfd225a4e2b671b2b40b71725394c24fb1761", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d53cfd225a4e2b671b2b40b71725394c24fb1761", "html_url": "https://github.com/rust-lang/rust/commit/d53cfd225a4e2b671b2b40b71725394c24fb1761", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d53cfd225a4e2b671b2b40b71725394c24fb1761/comments", "author": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brson", "id": 147214, "node_id": "MDQ6VXNlcjE0NzIxNA==", "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brson", "html_url": "https://github.com/brson", "followers_url": "https://api.github.com/users/brson/followers", "following_url": "https://api.github.com/users/brson/following{/other_user}", "gists_url": "https://api.github.com/users/brson/gists{/gist_id}", "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brson/subscriptions", "organizations_url": "https://api.github.com/users/brson/orgs", "repos_url": "https://api.github.com/users/brson/repos", "events_url": "https://api.github.com/users/brson/events{/privacy}", "received_events_url": "https://api.github.com/users/brson/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2ac64d91ac9df242c780d162863c8c0abce448b1", "url": "https://api.github.com/repos/rust-lang/rust/commits/2ac64d91ac9df242c780d162863c8c0abce448b1", "html_url": "https://github.com/rust-lang/rust/commit/2ac64d91ac9df242c780d162863c8c0abce448b1"}], "stats": {"total": 853, "additions": 426, "deletions": 427}, "files": [{"sha": "e416bfced8ff431876811a31f20f7c39a4f2bacd", "filename": "src/libcore/pipes.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fpipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fpipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fpipes.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -1107,7 +1107,7 @@ impl<T: Send> PortSet<T> : Recv<T> {\n }\n \n /// A channel that can be shared between many senders.\n-type SharedChan<T: Send> = unsafe::Exclusive<Chan<T>>;\n+type SharedChan<T: Send> = private::Exclusive<Chan<T>>;\n \n impl<T: Send> SharedChan<T>: Channel<T> {\n     fn send(+x: T) {\n@@ -1131,7 +1131,7 @@ impl<T: Send> SharedChan<T>: Channel<T> {\n \n /// Converts a `chan` into a `shared_chan`.\n fn SharedChan<T:Send>(+c: Chan<T>) -> SharedChan<T> {\n-    unsafe::exclusive(move c)\n+    private::exclusive(move c)\n }\n \n /// Receive a message from one of two endpoints."}, {"sha": "06b380abac3ad02ee3b79bce09c33420ac645a02", "filename": "src/libcore/private.rs", "status": "modified", "additions": 412, "deletions": 7, "changes": 419, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fprivate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fprivate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fprivate.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -6,20 +6,41 @@\n \n export chan_from_global_ptr, weaken_task;\n \n+export SharedMutableState, shared_mutable_state, clone_shared_mutable_state;\n+export get_shared_mutable_state, get_shared_immutable_state;\n+export unwrap_shared_mutable_state;\n+export Exclusive, exclusive, unwrap_exclusive;\n+\n use compare_and_swap = rustrt::rust_compare_and_swap_ptr;\n use task::TaskBuilder;\n-\n-#[allow(non_camel_case_types)] // runtime type\n-type rust_port_id = uint;\n+use task::atomically;\n \n extern mod rustrt {\n-    fn rust_compare_and_swap_ptr(address: *libc::uintptr_t,\n-                                 oldval: libc::uintptr_t,\n-                                 newval: libc::uintptr_t) -> bool;\n     fn rust_task_weaken(ch: rust_port_id);\n     fn rust_task_unweaken(ch: rust_port_id);\n+\n+    #[rust_stack]\n+    fn rust_atomic_increment(p: &mut libc::intptr_t)\n+        -> libc::intptr_t;\n+\n+    #[rust_stack]\n+    fn rust_atomic_decrement(p: &mut libc::intptr_t)\n+        -> libc::intptr_t;\n+\n+    #[rust_stack]\n+    fn rust_compare_and_swap_ptr(address: &mut libc::uintptr_t,\n+                                 oldval: libc::uintptr_t,\n+                                 newval: libc::uintptr_t) -> bool;\n+\n+    fn rust_create_little_lock() -> rust_little_lock;\n+    fn rust_destroy_little_lock(lock: rust_little_lock);\n+    fn rust_lock_little_lock(lock: rust_little_lock);\n+    fn rust_unlock_little_lock(lock: rust_little_lock);\n }\n \n+#[allow(non_camel_case_types)] // runtime type\n+type rust_port_id = uint;\n+\n type GlobalPtr = *libc::uintptr_t;\n \n /**\n@@ -68,7 +89,8 @@ unsafe fn chan_from_global_ptr<T: Send>(\n         // Install the channel\n         log(debug,~\"BEFORE COMPARE AND SWAP\");\n         let swapped = compare_and_swap(\n-            global, 0u, unsafe::reinterpret_cast(&ch));\n+            unsafe::reinterpret_cast(&global),\n+            0u, unsafe::reinterpret_cast(&ch));\n         log(debug,fmt!(\"AFTER .. swapped? %?\", swapped));\n \n         if swapped {\n@@ -262,3 +284,386 @@ fn test_weaken_task_fail() {\n     };\n     assert result::is_err(res);\n }\n+\n+/****************************************************************************\n+ * Shared state & exclusive ARC\n+ ****************************************************************************/\n+\n+// An unwrapper uses this protocol to communicate with the \"other\" task that\n+// drops the last refcount on an arc. Unfortunately this can't be a proper\n+// pipe protocol because the unwrapper has to access both stages at once.\n+type UnwrapProto = ~mut Option<(pipes::ChanOne<()>, pipes::PortOne<bool>)>;\n+\n+struct ArcData<T> {\n+    mut count:     libc::intptr_t,\n+    mut unwrapper: libc::uintptr_t, // either a UnwrapProto or 0\n+    // FIXME(#3224) should be able to make this non-option to save memory, and\n+    // in unwrap() use \"let ~ArcData { data: result, _ } = thing\" to unwrap it\n+    mut data:      Option<T>,\n+}\n+\n+struct ArcDestruct<T> {\n+    mut data: *libc::c_void,\n+    drop unsafe {\n+        if self.data.is_null() {\n+            return; // Happens when destructing an unwrapper's handle.\n+        }\n+        do task::unkillable {\n+            let data: ~ArcData<T> = unsafe::reinterpret_cast(&self.data);\n+            let new_count = rustrt::rust_atomic_decrement(&mut data.count);\n+            assert new_count >= 0;\n+            if new_count == 0 {\n+                // Were we really last, or should we hand off to an unwrapper?\n+                // It's safe to not xchg because the unwrapper will set the\n+                // unwrap lock *before* dropping his/her reference. In effect,\n+                // being here means we're the only *awake* task with the data.\n+                if data.unwrapper != 0 {\n+                    let p: UnwrapProto =\n+                        unsafe::reinterpret_cast(&data.unwrapper);\n+                    let (message, response) = option::swap_unwrap(p);\n+                    // Send 'ready' and wait for a response.\n+                    pipes::send_one(move message, ());\n+                    // Unkillable wait. Message guaranteed to come.\n+                    if pipes::recv_one(move response) {\n+                        // Other task got the data.\n+                        unsafe::forget(move data);\n+                    } else {\n+                        // Other task was killed. drop glue takes over.\n+                    }\n+                } else {\n+                    // drop glue takes over.\n+                }\n+            } else {\n+                unsafe::forget(move data);\n+            }\n+        }\n+    }\n+}\n+\n+fn ArcDestruct<T>(data: *libc::c_void) -> ArcDestruct<T> {\n+    ArcDestruct {\n+        data: data\n+    }\n+}\n+\n+unsafe fn unwrap_shared_mutable_state<T: Send>(+rc: SharedMutableState<T>)\n+        -> T {\n+    struct DeathThroes<T> {\n+        mut ptr:      Option<~ArcData<T>>,\n+        mut response: Option<pipes::ChanOne<bool>>,\n+        drop unsafe {\n+            let response = option::swap_unwrap(&mut self.response);\n+            // In case we get killed early, we need to tell the person who\n+            // tried to wake us whether they should hand-off the data to us.\n+            if task::failing() {\n+                pipes::send_one(move response, false);\n+                // Either this swap_unwrap or the one below (at \"Got here\")\n+                // ought to run.\n+                unsafe::forget(option::swap_unwrap(&mut self.ptr));\n+            } else {\n+                assert self.ptr.is_none();\n+                pipes::send_one(move response, true);\n+            }\n+        }\n+    }\n+\n+    do task::unkillable {\n+        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&rc.data);\n+        let (c1,p1) = pipes::oneshot(); // ()\n+        let (c2,p2) = pipes::oneshot(); // bool\n+        let server: UnwrapProto = ~mut Some((move c1,move p2));\n+        let serverp: libc::uintptr_t = unsafe::transmute(move server);\n+        // Try to put our server end in the unwrapper slot.\n+        if rustrt::rust_compare_and_swap_ptr(&mut ptr.unwrapper, 0, serverp) {\n+            // Got in. Step 0: Tell destructor not to run. We are now it.\n+            rc.data = ptr::null();\n+            // Step 1 - drop our own reference.\n+            let new_count = rustrt::rust_atomic_decrement(&mut ptr.count);\n+            assert new_count >= 0;\n+            if new_count == 0 {\n+                // We were the last owner. Can unwrap immediately.\n+                // Also we have to free the server endpoints.\n+                let _server: UnwrapProto = unsafe::transmute(move serverp);\n+                option::swap_unwrap(&mut ptr.data)\n+                // drop glue takes over.\n+            } else {\n+                // The *next* person who sees the refcount hit 0 will wake us.\n+                let end_result =\n+                    DeathThroes { ptr: Some(move ptr),\n+                                  response: Some(move c2) };\n+                let mut p1 = Some(move p1); // argh\n+                do task::rekillable {\n+                    pipes::recv_one(option::swap_unwrap(&mut p1));\n+                }\n+                // Got here. Back in the 'unkillable' without getting killed.\n+                // Recover ownership of ptr, then take the data out.\n+                let ptr = option::swap_unwrap(&mut end_result.ptr);\n+                option::swap_unwrap(&mut ptr.data)\n+                // drop glue takes over.\n+            }\n+        } else {\n+            // Somebody else was trying to unwrap. Avoid guaranteed deadlock.\n+            unsafe::forget(move ptr);\n+            // Also we have to free the (rejected) server endpoints.\n+            let _server: UnwrapProto = unsafe::transmute(move serverp);\n+            fail ~\"Another task is already unwrapping this ARC!\";\n+        }\n+    }\n+}\n+\n+/**\n+ * COMPLETELY UNSAFE. Used as a primitive for the safe versions in std::arc.\n+ *\n+ * Data races between tasks can result in crashes and, with sufficient\n+ * cleverness, arbitrary type coercion.\n+ */\n+type SharedMutableState<T: Send> = ArcDestruct<T>;\n+\n+unsafe fn shared_mutable_state<T: Send>(+data: T) -> SharedMutableState<T> {\n+    let data = ~ArcData { count: 1, unwrapper: 0, data: Some(move data) };\n+    unsafe {\n+        let ptr = unsafe::transmute(move data);\n+        ArcDestruct(ptr)\n+    }\n+}\n+\n+#[inline(always)]\n+unsafe fn get_shared_mutable_state<T: Send>(rc: &a/SharedMutableState<T>)\n+        -> &a/mut T {\n+    unsafe {\n+        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n+        assert ptr.count > 0;\n+        // Cast us back into the correct region\n+        let r = unsafe::transmute_region(option::get_ref(&ptr.data));\n+        unsafe::forget(move ptr);\n+        return unsafe::transmute_mut(r);\n+    }\n+}\n+#[inline(always)]\n+unsafe fn get_shared_immutable_state<T: Send>(rc: &a/SharedMutableState<T>)\n+        -> &a/T {\n+    unsafe {\n+        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n+        assert ptr.count > 0;\n+        // Cast us back into the correct region\n+        let r = unsafe::transmute_region(option::get_ref(&ptr.data));\n+        unsafe::forget(move ptr);\n+        return r;\n+    }\n+}\n+\n+unsafe fn clone_shared_mutable_state<T: Send>(rc: &SharedMutableState<T>)\n+        -> SharedMutableState<T> {\n+    unsafe {\n+        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n+        let new_count = rustrt::rust_atomic_increment(&mut ptr.count);\n+        assert new_count >= 2;\n+        unsafe::forget(move ptr);\n+    }\n+    ArcDestruct((*rc).data)\n+}\n+\n+/****************************************************************************/\n+\n+#[allow(non_camel_case_types)] // runtime type\n+type rust_little_lock = *libc::c_void;\n+\n+struct LittleLock {\n+    l: rust_little_lock,\n+    drop { rustrt::rust_destroy_little_lock(self.l); }\n+}\n+\n+fn LittleLock() -> LittleLock {\n+    LittleLock {\n+        l: rustrt::rust_create_little_lock()\n+    }\n+}\n+\n+impl LittleLock {\n+    #[inline(always)]\n+    unsafe fn lock<T>(f: fn() -> T) -> T {\n+        struct Unlock {\n+            l: rust_little_lock,\n+            drop { rustrt::rust_unlock_little_lock(self.l); }\n+        }\n+\n+        fn Unlock(l: rust_little_lock) -> Unlock {\n+            Unlock {\n+                l: l\n+            }\n+        }\n+\n+        do atomically {\n+            rustrt::rust_lock_little_lock(self.l);\n+            let _r = Unlock(self.l);\n+            f()\n+        }\n+    }\n+}\n+\n+struct ExData<T: Send> { lock: LittleLock, mut failed: bool, mut data: T, }\n+/**\n+ * An arc over mutable data that is protected by a lock. For library use only.\n+ */\n+struct Exclusive<T: Send> { x: SharedMutableState<ExData<T>> }\n+\n+fn exclusive<T:Send >(+user_data: T) -> Exclusive<T> {\n+    let data = ExData {\n+        lock: LittleLock(), mut failed: false, mut data: user_data\n+    };\n+    Exclusive { x: unsafe { shared_mutable_state(move data) } }\n+}\n+\n+impl<T: Send> Exclusive<T> {\n+    // Duplicate an exclusive ARC, as std::arc::clone.\n+    fn clone() -> Exclusive<T> {\n+        Exclusive { x: unsafe { clone_shared_mutable_state(&self.x) } }\n+    }\n+\n+    // Exactly like std::arc::mutex_arc,access(), but with the little_lock\n+    // instead of a proper mutex. Same reason for being unsafe.\n+    //\n+    // Currently, scheduling operations (i.e., yielding, receiving on a pipe,\n+    // accessing the provided condition variable) are prohibited while inside\n+    // the exclusive. Supporting that is a work in progress.\n+    #[inline(always)]\n+    unsafe fn with<U>(f: fn(x: &mut T) -> U) -> U {\n+        let rec = unsafe { get_shared_mutable_state(&self.x) };\n+        do rec.lock.lock {\n+            if rec.failed {\n+                fail ~\"Poisoned exclusive - another task failed inside!\";\n+            }\n+            rec.failed = true;\n+            let result = f(&mut rec.data);\n+            rec.failed = false;\n+            move result\n+        }\n+    }\n+\n+    #[inline(always)]\n+    unsafe fn with_imm<U>(f: fn(x: &T) -> U) -> U {\n+        do self.with |x| {\n+            f(unsafe::transmute_immut(x))\n+        }\n+    }\n+}\n+\n+// FIXME(#2585) make this a by-move method on the exclusive\n+fn unwrap_exclusive<T: Send>(+arc: Exclusive<T>) -> T {\n+    let Exclusive { x: x } <- arc;\n+    let inner = unsafe { unwrap_shared_mutable_state(move x) };\n+    let ExData { data: data, _ } <- inner;\n+    move data\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+\n+    #[test]\n+    fn exclusive_arc() {\n+        let mut futures = ~[];\n+\n+        let num_tasks = 10u;\n+        let count = 10u;\n+\n+        let total = exclusive(~mut 0u);\n+\n+        for uint::range(0u, num_tasks) |_i| {\n+            let total = total.clone();\n+            vec::push(futures, future::spawn(|| {\n+                for uint::range(0u, count) |_i| {\n+                    do total.with |count| {\n+                        **count += 1u;\n+                    }\n+                }\n+            }));\n+        };\n+\n+        for futures.each |f| { f.get() }\n+\n+        do total.with |total| {\n+            assert **total == num_tasks * count\n+        };\n+    }\n+\n+    #[test] #[should_fail] #[ignore(cfg(windows))]\n+    fn exclusive_poison() {\n+        // Tests that if one task fails inside of an exclusive, subsequent\n+        // accesses will also fail.\n+        let x = exclusive(1);\n+        let x2 = x.clone();\n+        do task::try {\n+            do x2.with |one| {\n+                assert *one == 2;\n+            }\n+        };\n+        do x.with |one| {\n+            assert *one == 1;\n+        }\n+    }\n+\n+    #[test]\n+    fn exclusive_unwrap_basic() {\n+        let x = exclusive(~~\"hello\");\n+        assert unwrap_exclusive(x) == ~~\"hello\";\n+    }\n+\n+    #[test]\n+    fn exclusive_unwrap_contended() {\n+        let x = exclusive(~~\"hello\");\n+        let x2 = ~mut Some(x.clone());\n+        do task::spawn {\n+            let x2 = option::swap_unwrap(x2);\n+            do x2.with |_hello| { }\n+            task::yield();\n+        }\n+        assert unwrap_exclusive(x) == ~~\"hello\";\n+\n+        // Now try the same thing, but with the child task blocking.\n+        let x = exclusive(~~\"hello\");\n+        let x2 = ~mut Some(x.clone());\n+        let mut res = None;\n+        do task::task().future_result(|+r| res = Some(r)).spawn {\n+            let x2 = option::swap_unwrap(x2);\n+            assert unwrap_exclusive(x2) == ~~\"hello\";\n+        }\n+        // Have to get rid of our reference before blocking.\n+        { let _x = move x; } // FIXME(#3161) util::ignore doesn't work here\n+        let res = option::swap_unwrap(&mut res);\n+        future::get(&res);\n+    }\n+\n+    #[test] #[should_fail] #[ignore(cfg(windows))]\n+    fn exclusive_unwrap_conflict() {\n+        let x = exclusive(~~\"hello\");\n+        let x2 = ~mut Some(x.clone());\n+        let mut res = None;\n+        do task::task().future_result(|+r| res = Some(r)).spawn {\n+            let x2 = option::swap_unwrap(x2);\n+            assert unwrap_exclusive(x2) == ~~\"hello\";\n+        }\n+        assert unwrap_exclusive(x) == ~~\"hello\";\n+        let res = option::swap_unwrap(&mut res);\n+        future::get(&res);\n+    }\n+\n+    #[test] #[ignore(cfg(windows))]\n+    fn exclusive_unwrap_deadlock() {\n+        // This is not guaranteed to get to the deadlock before being killed,\n+        // but it will show up sometimes, and if the deadlock were not there,\n+        // the test would nondeterministically fail.\n+        let result = do task::try {\n+            // a task that has two references to the same exclusive will\n+            // deadlock when it unwraps. nothing to be done about that.\n+            let x = exclusive(~~\"hello\");\n+            let x2 = x.clone();\n+            do task::spawn {\n+                for 10.times { task::yield(); } // try to let the unwrapper go\n+                fail; // punt it awake from its deadlock\n+            }\n+            let _z = unwrap_exclusive(x);\n+            do x2.with |_hello| { }\n+        };\n+        assert result.is_err();\n+    }\n+}"}, {"sha": "0ee5a89cb63e85e6a94b4c973c007082f31e6ef7", "filename": "src/libcore/task.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ftask.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -900,7 +900,7 @@ type TaskGroupData = {\n     // tasks in this group.\n     mut descendants: TaskSet,\n };\n-type TaskGroupArc = unsafe::Exclusive<Option<TaskGroupData>>;\n+type TaskGroupArc = private::Exclusive<Option<TaskGroupData>>;\n \n type TaskGroupInner = &mut Option<TaskGroupData>;\n \n@@ -929,7 +929,7 @@ type AncestorNode = {\n     // Recursive rest of the list.\n     mut ancestors:    AncestorList,\n };\n-enum AncestorList = Option<unsafe::Exclusive<AncestorNode>>;\n+enum AncestorList = Option<private::Exclusive<AncestorNode>>;\n \n // Accessors for taskgroup arcs and ancestor arcs that wrap the unsafety.\n #[inline(always)]\n@@ -938,7 +938,7 @@ fn access_group<U>(x: &TaskGroupArc, blk: fn(TaskGroupInner) -> U) -> U {\n }\n \n #[inline(always)]\n-fn access_ancestors<U>(x: &unsafe::Exclusive<AncestorNode>,\n+fn access_ancestors<U>(x: &private::Exclusive<AncestorNode>,\n                        blk: fn(x: &mut AncestorNode) -> U) -> U {\n     unsafe { x.with(blk) }\n }\n@@ -1222,7 +1222,7 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n             let mut members = new_taskset();\n             taskset_insert(&mut members, spawner);\n             let tasks =\n-                unsafe::exclusive(Some({ mut members:     move members,\n+                private::exclusive(Some({ mut members:     move members,\n                                          mut descendants: new_taskset() }));\n             // Main task/group has no ancestors, no notifier, etc.\n             let group =\n@@ -1244,7 +1244,7 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n         (move g, move a, spawner_group.is_main)\n     } else {\n         // Child is in a separate group from spawner.\n-        let g = unsafe::exclusive(Some({ mut members:     new_taskset(),\n+        let g = private::exclusive(Some({ mut members:     new_taskset(),\n                                          mut descendants: new_taskset() }));\n         let a = if supervised {\n             // Child's ancestors start with the spawner.\n@@ -1259,7 +1259,7 @@ fn gen_child_taskgroup(linked: bool, supervised: bool)\n                 };\n             assert new_generation < uint::max_value;\n             // Build a new node in the ancestor list.\n-            AncestorList(Some(unsafe::exclusive(\n+            AncestorList(Some(private::exclusive(\n                 { generation:       new_generation,\n                   mut parent_group: Some(spawner_group.tasks.clone()),\n                   mut ancestors:    move old_ancestors })))"}, {"sha": "601eeff696996b853a6852fa789af0cd7a143b2d", "filename": "src/libcore/unsafe.rs", "status": "modified", "additions": 0, "deletions": 406, "changes": 406, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Funsafe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Funsafe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funsafe.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -4,14 +4,8 @@ export reinterpret_cast, forget, bump_box_refcount, transmute;\n export transmute_mut, transmute_immut, transmute_region, transmute_mut_region;\n export transmute_mut_unsafe, transmute_immut_unsafe;\n \n-export SharedMutableState, shared_mutable_state, clone_shared_mutable_state;\n-export get_shared_mutable_state, get_shared_immutable_state;\n-export unwrap_shared_mutable_state;\n-export Exclusive, exclusive, unwrap_exclusive;\n export copy_lifetime;\n \n-use task::atomically;\n-\n #[abi = \"rust-intrinsic\"]\n extern mod rusti {\n     fn forget<T>(-x: T);\n@@ -96,298 +90,6 @@ unsafe fn copy_lifetime_to_unsafe<S,T>(_ptr: &a/S, +ptr: *T) -> &a/T {\n }\n \n \n-/****************************************************************************\n- * Shared state & exclusive ARC\n- ****************************************************************************/\n-\n-// An unwrapper uses this protocol to communicate with the \"other\" task that\n-// drops the last refcount on an arc. Unfortunately this can't be a proper\n-// pipe protocol because the unwrapper has to access both stages at once.\n-type UnwrapProto = ~mut Option<(pipes::ChanOne<()>, pipes::PortOne<bool>)>;\n-\n-struct ArcData<T> {\n-    mut count:     libc::intptr_t,\n-    mut unwrapper: libc::uintptr_t, // either a UnwrapProto or 0\n-    // FIXME(#3224) should be able to make this non-option to save memory, and\n-    // in unwrap() use \"let ~ArcData { data: result, _ } = thing\" to unwrap it\n-    mut data:      Option<T>,\n-}\n-\n-struct ArcDestruct<T> {\n-    mut data: *libc::c_void,\n-    drop unsafe {\n-        if self.data.is_null() {\n-            return; // Happens when destructing an unwrapper's handle.\n-        }\n-        do task::unkillable {\n-            let data: ~ArcData<T> = unsafe::reinterpret_cast(&self.data);\n-            let new_count = rustrt::rust_atomic_decrement(&mut data.count);\n-            assert new_count >= 0;\n-            if new_count == 0 {\n-                // Were we really last, or should we hand off to an unwrapper?\n-                // It's safe to not xchg because the unwrapper will set the\n-                // unwrap lock *before* dropping his/her reference. In effect,\n-                // being here means we're the only *awake* task with the data.\n-                if data.unwrapper != 0 {\n-                    let p: UnwrapProto =\n-                        unsafe::reinterpret_cast(&data.unwrapper);\n-                    let (message, response) = option::swap_unwrap(p);\n-                    // Send 'ready' and wait for a response.\n-                    pipes::send_one(move message, ());\n-                    // Unkillable wait. Message guaranteed to come.\n-                    if pipes::recv_one(move response) {\n-                        // Other task got the data.\n-                        unsafe::forget(move data);\n-                    } else {\n-                        // Other task was killed. drop glue takes over.\n-                    }\n-                } else {\n-                    // drop glue takes over.\n-                }\n-            } else {\n-                unsafe::forget(move data);\n-            }\n-        }\n-    }\n-}\n-\n-fn ArcDestruct<T>(data: *libc::c_void) -> ArcDestruct<T> {\n-    ArcDestruct {\n-        data: data\n-    }\n-}\n-\n-unsafe fn unwrap_shared_mutable_state<T: Send>(+rc: SharedMutableState<T>)\n-        -> T {\n-    struct DeathThroes<T> {\n-        mut ptr:      Option<~ArcData<T>>,\n-        mut response: Option<pipes::ChanOne<bool>>,\n-        drop unsafe {\n-            let response = option::swap_unwrap(&mut self.response);\n-            // In case we get killed early, we need to tell the person who\n-            // tried to wake us whether they should hand-off the data to us.\n-            if task::failing() {\n-                pipes::send_one(move response, false);\n-                // Either this swap_unwrap or the one below (at \"Got here\")\n-                // ought to run.\n-                unsafe::forget(option::swap_unwrap(&mut self.ptr));\n-            } else {\n-                assert self.ptr.is_none();\n-                pipes::send_one(move response, true);\n-            }\n-        }\n-    }\n-\n-    do task::unkillable {\n-        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&rc.data);\n-        let (c1,p1) = pipes::oneshot(); // ()\n-        let (c2,p2) = pipes::oneshot(); // bool\n-        let server: UnwrapProto = ~mut Some((move c1,move p2));\n-        let serverp: libc::uintptr_t = unsafe::transmute(move server);\n-        // Try to put our server end in the unwrapper slot.\n-        if rustrt::rust_compare_and_swap_ptr(&mut ptr.unwrapper, 0, serverp) {\n-            // Got in. Step 0: Tell destructor not to run. We are now it.\n-            rc.data = ptr::null();\n-            // Step 1 - drop our own reference.\n-            let new_count = rustrt::rust_atomic_decrement(&mut ptr.count);\n-            assert new_count >= 0;\n-            if new_count == 0 {\n-                // We were the last owner. Can unwrap immediately.\n-                // Also we have to free the server endpoints.\n-                let _server: UnwrapProto = unsafe::transmute(move serverp);\n-                option::swap_unwrap(&mut ptr.data)\n-                // drop glue takes over.\n-            } else {\n-                // The *next* person who sees the refcount hit 0 will wake us.\n-                let end_result =\n-                    DeathThroes { ptr: Some(move ptr),\n-                                  response: Some(move c2) };\n-                let mut p1 = Some(move p1); // argh\n-                do task::rekillable {\n-                    pipes::recv_one(option::swap_unwrap(&mut p1));\n-                }\n-                // Got here. Back in the 'unkillable' without getting killed.\n-                // Recover ownership of ptr, then take the data out.\n-                let ptr = option::swap_unwrap(&mut end_result.ptr);\n-                option::swap_unwrap(&mut ptr.data)\n-                // drop glue takes over.\n-            }\n-        } else {\n-            // Somebody else was trying to unwrap. Avoid guaranteed deadlock.\n-            unsafe::forget(move ptr);\n-            // Also we have to free the (rejected) server endpoints.\n-            let _server: UnwrapProto = unsafe::transmute(move serverp);\n-            fail ~\"Another task is already unwrapping this ARC!\";\n-        }\n-    }\n-}\n-\n-/**\n- * COMPLETELY UNSAFE. Used as a primitive for the safe versions in std::arc.\n- *\n- * Data races between tasks can result in crashes and, with sufficient\n- * cleverness, arbitrary type coercion.\n- */\n-type SharedMutableState<T: Send> = ArcDestruct<T>;\n-\n-unsafe fn shared_mutable_state<T: Send>(+data: T) -> SharedMutableState<T> {\n-    let data = ~ArcData { count: 1, unwrapper: 0, data: Some(move data) };\n-    unsafe {\n-        let ptr = unsafe::transmute(move data);\n-        ArcDestruct(ptr)\n-    }\n-}\n-\n-#[inline(always)]\n-unsafe fn get_shared_mutable_state<T: Send>(rc: &a/SharedMutableState<T>)\n-        -> &a/mut T {\n-    unsafe {\n-        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n-        assert ptr.count > 0;\n-        // Cast us back into the correct region\n-        let r = unsafe::transmute_region(option::get_ref(&ptr.data));\n-        unsafe::forget(move ptr);\n-        return unsafe::transmute_mut(r);\n-    }\n-}\n-#[inline(always)]\n-unsafe fn get_shared_immutable_state<T: Send>(rc: &a/SharedMutableState<T>)\n-        -> &a/T {\n-    unsafe {\n-        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n-        assert ptr.count > 0;\n-        // Cast us back into the correct region\n-        let r = unsafe::transmute_region(option::get_ref(&ptr.data));\n-        unsafe::forget(move ptr);\n-        return r;\n-    }\n-}\n-\n-unsafe fn clone_shared_mutable_state<T: Send>(rc: &SharedMutableState<T>)\n-        -> SharedMutableState<T> {\n-    unsafe {\n-        let ptr: ~ArcData<T> = unsafe::reinterpret_cast(&(*rc).data);\n-        let new_count = rustrt::rust_atomic_increment(&mut ptr.count);\n-        assert new_count >= 2;\n-        unsafe::forget(move ptr);\n-    }\n-    ArcDestruct((*rc).data)\n-}\n-\n-/****************************************************************************/\n-\n-#[allow(non_camel_case_types)] // runtime type\n-type rust_little_lock = *libc::c_void;\n-\n-#[abi = \"cdecl\"]\n-extern mod rustrt {\n-    #[rust_stack]\n-    fn rust_atomic_increment(p: &mut libc::intptr_t)\n-        -> libc::intptr_t;\n-\n-    #[rust_stack]\n-    fn rust_atomic_decrement(p: &mut libc::intptr_t)\n-        -> libc::intptr_t;\n-\n-    #[rust_stack]\n-    fn rust_compare_and_swap_ptr(address: &mut libc::uintptr_t,\n-                                 oldval: libc::uintptr_t,\n-                                 newval: libc::uintptr_t) -> bool;\n-\n-    fn rust_create_little_lock() -> rust_little_lock;\n-    fn rust_destroy_little_lock(lock: rust_little_lock);\n-    fn rust_lock_little_lock(lock: rust_little_lock);\n-    fn rust_unlock_little_lock(lock: rust_little_lock);\n-}\n-\n-struct LittleLock {\n-    l: rust_little_lock,\n-    drop { rustrt::rust_destroy_little_lock(self.l); }\n-}\n-\n-fn LittleLock() -> LittleLock {\n-    LittleLock {\n-        l: rustrt::rust_create_little_lock()\n-    }\n-}\n-\n-impl LittleLock {\n-    #[inline(always)]\n-    unsafe fn lock<T>(f: fn() -> T) -> T {\n-        struct Unlock {\n-            l: rust_little_lock,\n-            drop { rustrt::rust_unlock_little_lock(self.l); }\n-        }\n-\n-        fn Unlock(l: rust_little_lock) -> Unlock {\n-            Unlock {\n-                l: l\n-            }\n-        }\n-\n-        do atomically {\n-            rustrt::rust_lock_little_lock(self.l);\n-            let _r = Unlock(self.l);\n-            f()\n-        }\n-    }\n-}\n-\n-struct ExData<T: Send> { lock: LittleLock, mut failed: bool, mut data: T, }\n-/**\n- * An arc over mutable data that is protected by a lock. For library use only.\n- */\n-struct Exclusive<T: Send> { x: SharedMutableState<ExData<T>> }\n-\n-fn exclusive<T:Send >(+user_data: T) -> Exclusive<T> {\n-    let data = ExData {\n-        lock: LittleLock(), mut failed: false, mut data: user_data\n-    };\n-    Exclusive { x: unsafe { shared_mutable_state(move data) } }\n-}\n-\n-impl<T: Send> Exclusive<T> {\n-    // Duplicate an exclusive ARC, as std::arc::clone.\n-    fn clone() -> Exclusive<T> {\n-        Exclusive { x: unsafe { clone_shared_mutable_state(&self.x) } }\n-    }\n-\n-    // Exactly like std::arc::mutex_arc,access(), but with the little_lock\n-    // instead of a proper mutex. Same reason for being unsafe.\n-    //\n-    // Currently, scheduling operations (i.e., yielding, receiving on a pipe,\n-    // accessing the provided condition variable) are prohibited while inside\n-    // the exclusive. Supporting that is a work in progress.\n-    #[inline(always)]\n-    unsafe fn with<U>(f: fn(x: &mut T) -> U) -> U {\n-        let rec = unsafe { get_shared_mutable_state(&self.x) };\n-        do rec.lock.lock {\n-            if rec.failed {\n-                fail ~\"Poisoned exclusive - another task failed inside!\";\n-            }\n-            rec.failed = true;\n-            let result = f(&mut rec.data);\n-            rec.failed = false;\n-            move result\n-        }\n-    }\n-\n-    #[inline(always)]\n-    unsafe fn with_imm<U>(f: fn(x: &T) -> U) -> U {\n-        do self.with |x| {\n-            f(unsafe::transmute_immut(x))\n-        }\n-    }\n-}\n-\n-// FIXME(#2585) make this a by-move method on the exclusive\n-fn unwrap_exclusive<T: Send>(+arc: Exclusive<T>) -> T {\n-    let Exclusive { x: x } <- arc;\n-    let inner = unsafe { unwrap_shared_mutable_state(move x) };\n-    let ExData { data: data, _ } <- inner;\n-    move data\n-}\n-\n /****************************************************************************\n  * Tests\n  ****************************************************************************/\n@@ -431,112 +133,4 @@ mod tests {\n             assert ~[76u8, 0u8] == transmute(~\"L\");\n         }\n     }\n-\n-    #[test]\n-    fn exclusive_arc() {\n-        let mut futures = ~[];\n-\n-        let num_tasks = 10u;\n-        let count = 10u;\n-\n-        let total = exclusive(~mut 0u);\n-\n-        for uint::range(0u, num_tasks) |_i| {\n-            let total = total.clone();\n-            vec::push(futures, future::spawn(|| {\n-                for uint::range(0u, count) |_i| {\n-                    do total.with |count| {\n-                        **count += 1u;\n-                    }\n-                }\n-            }));\n-        };\n-\n-        for futures.each |f| { f.get() }\n-\n-        do total.with |total| {\n-            assert **total == num_tasks * count\n-        };\n-    }\n-\n-    #[test] #[should_fail] #[ignore(cfg(windows))]\n-    fn exclusive_poison() {\n-        // Tests that if one task fails inside of an exclusive, subsequent\n-        // accesses will also fail.\n-        let x = exclusive(1);\n-        let x2 = x.clone();\n-        do task::try {\n-            do x2.with |one| {\n-                assert *one == 2;\n-            }\n-        };\n-        do x.with |one| {\n-            assert *one == 1;\n-        }\n-    }\n-\n-    #[test]\n-    fn exclusive_unwrap_basic() {\n-        let x = exclusive(~~\"hello\");\n-        assert unwrap_exclusive(x) == ~~\"hello\";\n-    }\n-\n-    #[test]\n-    fn exclusive_unwrap_contended() {\n-        let x = exclusive(~~\"hello\");\n-        let x2 = ~mut Some(x.clone());\n-        do task::spawn {\n-            let x2 = option::swap_unwrap(x2);\n-            do x2.with |_hello| { }\n-            task::yield();\n-        }\n-        assert unwrap_exclusive(x) == ~~\"hello\";\n-\n-        // Now try the same thing, but with the child task blocking.\n-        let x = exclusive(~~\"hello\");\n-        let x2 = ~mut Some(x.clone());\n-        let mut res = None;\n-        do task::task().future_result(|+r| res = Some(r)).spawn {\n-            let x2 = option::swap_unwrap(x2);\n-            assert unwrap_exclusive(x2) == ~~\"hello\";\n-        }\n-        // Have to get rid of our reference before blocking.\n-        { let _x = move x; } // FIXME(#3161) util::ignore doesn't work here\n-        let res = option::swap_unwrap(&mut res);\n-        future::get(&res);\n-    }\n-\n-    #[test] #[should_fail] #[ignore(cfg(windows))]\n-    fn exclusive_unwrap_conflict() {\n-        let x = exclusive(~~\"hello\");\n-        let x2 = ~mut Some(x.clone());\n-        let mut res = None;\n-        do task::task().future_result(|+r| res = Some(r)).spawn {\n-            let x2 = option::swap_unwrap(x2);\n-            assert unwrap_exclusive(x2) == ~~\"hello\";\n-        }\n-        assert unwrap_exclusive(x) == ~~\"hello\";\n-        let res = option::swap_unwrap(&mut res);\n-        future::get(&res);\n-    }\n-\n-    #[test] #[ignore(cfg(windows))]\n-    fn exclusive_unwrap_deadlock() {\n-        // This is not guaranteed to get to the deadlock before being killed,\n-        // but it will show up sometimes, and if the deadlock were not there,\n-        // the test would nondeterministically fail.\n-        let result = do task::try {\n-            // a task that has two references to the same exclusive will\n-            // deadlock when it unwraps. nothing to be done about that.\n-            let x = exclusive(~~\"hello\");\n-            let x2 = x.clone();\n-            do task::spawn {\n-                for 10.times { task::yield(); } // try to let the unwrapper go\n-                fail; // punt it awake from its deadlock\n-            }\n-            let _z = unwrap_exclusive(x);\n-            do x2.with |_hello| { }\n-        };\n-        assert result.is_err();\n-    }\n }"}, {"sha": "843ae07c4bcce048586c7eee6a61d05a506fa76c", "filename": "src/libcore/vec.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibcore%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fvec.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -2239,8 +2239,8 @@ mod tests {\n     #[test]\n     fn test_swap_remove_noncopyable() {\n         // Tests that we don't accidentally run destructors twice.\n-        let mut v = ~[::unsafe::exclusive(()), ::unsafe::exclusive(()),\n-                      ::unsafe::exclusive(())];\n+        let mut v = ~[::private::exclusive(()), ::private::exclusive(()),\n+                      ::private::exclusive(())];\n         let mut _e = swap_remove(v, 0);\n         assert (len(v) == 2);\n         _e = swap_remove(v, 1);"}, {"sha": "79c407e1b990199e4a3a65ab25627da5ca2e1175", "filename": "src/libstd/arc.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibstd%2Farc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibstd%2Farc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Farc.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -6,7 +6,7 @@\n  * between tasks.\n  */\n \n-use unsafe::{SharedMutableState, shared_mutable_state,\n+use private::{SharedMutableState, shared_mutable_state,\n                 clone_shared_mutable_state, unwrap_shared_mutable_state,\n                 get_shared_mutable_state, get_shared_immutable_state};\n use sync::{Mutex,  mutex_with_condvars,"}, {"sha": "68e9f24a863c3e5e2344b3e3cbb5e5fc4eec34fe", "filename": "src/libstd/sync.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibstd%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Flibstd%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -11,7 +11,7 @@\n export Condvar, Semaphore, Mutex, mutex_with_condvars;\n export RWlock, rwlock_with_condvars, RWlockReadMode, RWlockWriteMode;\n \n-use unsafe::{Exclusive, exclusive};\n+use private::{Exclusive, exclusive};\n \n /****************************************************************************\n  * Internals"}, {"sha": "29cfe9423fff76a74b80a676ccb4a7cdc5a0a874", "filename": "src/test/compile-fail/noncopyable-match-pattern.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Ftest%2Fcompile-fail%2Fnoncopyable-match-pattern.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Ftest%2Fcompile-fail%2Fnoncopyable-match-pattern.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fnoncopyable-match-pattern.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -1,5 +1,5 @@\n fn main() {\n-    let x = Some(unsafe::exclusive(false));\n+    let x = Some(private::exclusive(false));\n     match x {\n         Some(copy z) => { //~ ERROR copying a noncopyable value\n             do z.with |b| { assert !*b; }"}, {"sha": "0140998355a6ee24c71a331991bbc4a80f2a0c66", "filename": "src/test/run-pass/alt-ref-binding-in-guard-3256.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Ftest%2Frun-pass%2Falt-ref-binding-in-guard-3256.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d53cfd225a4e2b671b2b40b71725394c24fb1761/src%2Ftest%2Frun-pass%2Falt-ref-binding-in-guard-3256.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Falt-ref-binding-in-guard-3256.rs?ref=d53cfd225a4e2b671b2b40b71725394c24fb1761", "patch": "@@ -1,5 +1,5 @@\n fn main() {\n-    let x = Some(unsafe::exclusive(true));\n+    let x = Some(private::exclusive(true));\n     match move x {\n         Some(ref z) if z.with(|b| *b) => {\n             do z.with |b| { assert *b; }"}]}