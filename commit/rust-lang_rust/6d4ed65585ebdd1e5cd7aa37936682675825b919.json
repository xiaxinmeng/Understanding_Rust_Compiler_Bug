{"sha": "6d4ed65585ebdd1e5cd7aa37936682675825b919", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZkNGVkNjU1ODVlYmRkMWU1Y2Q3YWEzNzkzNjY4MjY3NTgyNWI5MTk=", "commit": {"author": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-25T04:03:57Z"}, "committer": {"name": "Mark Mansi", "email": "markm@cs.wisc.edu", "date": "2018-01-26T20:47:24Z"}, "message": "Added lots of comments + minor reorganization", "tree": {"sha": "c0fec2a597db0eec79e727713e7b6eddccfc5b43", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c0fec2a597db0eec79e727713e7b6eddccfc5b43"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6d4ed65585ebdd1e5cd7aa37936682675825b919", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6d4ed65585ebdd1e5cd7aa37936682675825b919", "html_url": "https://github.com/rust-lang/rust/commit/6d4ed65585ebdd1e5cd7aa37936682675825b919", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6d4ed65585ebdd1e5cd7aa37936682675825b919/comments", "author": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mark-i-m", "id": 8827840, "node_id": "MDQ6VXNlcjg4Mjc4NDA=", "avatar_url": "https://avatars.githubusercontent.com/u/8827840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mark-i-m", "html_url": "https://github.com/mark-i-m", "followers_url": "https://api.github.com/users/mark-i-m/followers", "following_url": "https://api.github.com/users/mark-i-m/following{/other_user}", "gists_url": "https://api.github.com/users/mark-i-m/gists{/gist_id}", "starred_url": "https://api.github.com/users/mark-i-m/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mark-i-m/subscriptions", "organizations_url": "https://api.github.com/users/mark-i-m/orgs", "repos_url": "https://api.github.com/users/mark-i-m/repos", "events_url": "https://api.github.com/users/mark-i-m/events{/privacy}", "received_events_url": "https://api.github.com/users/mark-i-m/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0d7f193dd358cdc13506cac2e0b84fc473b628be", "url": "https://api.github.com/repos/rust-lang/rust/commits/0d7f193dd358cdc13506cac2e0b84fc473b628be", "html_url": "https://github.com/rust-lang/rust/commit/0d7f193dd358cdc13506cac2e0b84fc473b628be"}], "stats": {"total": 128, "additions": 94, "deletions": 34}, "files": [{"sha": "28d4f5f832f55c76a3278c47a6637447e49dd501", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 94, "deletions": 34, "changes": 128, "blob_url": "https://github.com/rust-lang/rust/blob/6d4ed65585ebdd1e5cd7aa37936682675825b919/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d4ed65585ebdd1e5cd7aa37936682675825b919/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=6d4ed65585ebdd1e5cd7aa37936682675825b919", "patch": "@@ -102,23 +102,26 @@ use std::rc::Rc;\n use std::collections::HashMap;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n \n-// To avoid costly uniqueness checks, we require that `MatchSeq` always has\n-// a nonempty body.\n+// To avoid costly uniqueness checks, we require that `MatchSeq` always has a nonempty body.\n \n+/// Either a sequence of token trees or a single one. This is used as the representation of the\n+/// sequence of tokens that make up a matcher.\n #[derive(Clone)]\n enum TokenTreeOrTokenTreeVec {\n     Tt(TokenTree),\n     TtSeq(Vec<TokenTree>),\n }\n \n impl TokenTreeOrTokenTreeVec {\n+    /// Returns the number of constituent token trees of `self`.\n     fn len(&self) -> usize {\n         match *self {\n             TtSeq(ref v) => v.len(),\n             Tt(ref tt) => tt.len(),\n         }\n     }\n \n+    /// The the `index`-th token tree of `self`.\n     fn get_tt(&self, index: usize) -> TokenTree {\n         match *self {\n             TtSeq(ref v) => v[index].clone(),\n@@ -127,36 +130,90 @@ impl TokenTreeOrTokenTreeVec {\n     }\n }\n \n-/// an unzipping of `TokenTree`s\n+/// An unzipping of `TokenTree`s... see the `stack` field of `MatcherPos`.\n+///\n+/// This is used by `inner_parse_loop` to keep track of delimited submatchers that we have\n+/// descended into.\n #[derive(Clone)]\n struct MatcherTtFrame {\n+    /// The \"parent\" matcher that we are descending into.\n     elts: TokenTreeOrTokenTreeVec,\n+    /// The position of the \"dot\" in `elts` at the time we descended.\n     idx: usize,\n }\n \n+/// Represents a single \"position\" (aka \"matcher position\", aka \"item\"), as described in the module\n+/// documentation.\n #[derive(Clone)]\n struct MatcherPos {\n-    stack: Vec<MatcherTtFrame>,\n+    /// The token or sequence of tokens that make up the matcher\n     top_elts: TokenTreeOrTokenTreeVec,\n-    sep: Option<Token>,\n+    /// The position of the \"dot\" in this matcher\n     idx: usize,\n-    up: Option<Box<MatcherPos>>,\n+    /// The beginning position in the source that the beginning of this matcher corresponds to. In\n+    /// other words, the token in the source at `sp_lo` is matched against the first token of the\n+    /// matcher.\n+    sp_lo: BytePos,\n+\n+    /// For each named metavar in the matcher, we keep track of token trees matched against the\n+    /// metavar by the black box parser. In particular, there may be more than one match per\n+    /// metavar if we are in a repetition (each repetition matches each of the variables).\n+    /// Moreover, matchers and repetitions can be nested; the `matches` field is shared (hence the\n+    /// `Rc`) among all \"nested\" matchers. `match_lo`, `match_cur`, and `match_hi` keep track of\n+    /// the current position of the `self` matcher position in the shared `matches` list.\n     matches: Vec<Rc<Vec<NamedMatch>>>,\n+    /// The position in `matches` corresponding to the first metavar in this matcher's sequence of\n+    /// token trees. In other words, the first metavar in the first token of `top_elts` corresponds\n+    /// to `matches[match_lo]`.\n     match_lo: usize,\n+    /// The position in `matches` corresponding to the metavar we are currently trying to match\n+    /// against the source token stream. `match_lo <= match_cur <= match_hi`.\n     match_cur: usize,\n+    /// Similar to `match_lo` except `match_hi` is the position in `matches` of the _last_ metavar\n+    /// in this matcher.\n     match_hi: usize,\n-    sp_lo: BytePos,\n+\n+    // Specifically used if we are matching a repetition. If we aren't both should be `None`.\n+    /// The separator if we are in a repetition\n+    sep: Option<Token>,\n+    /// The \"parent\" matcher position if we are in a repetition. That is, the matcher position just\n+    /// before we enter the sequence.\n+    up: Option<Box<MatcherPos>>,\n+\n+    // Specifically used to \"unzip\" token trees. By \"unzip\", we mean to unwrap the delimiters from\n+    // a delimited token tree (e.g. something wrapped in `(` `)`) or to get the contents of a doc\n+    // comment...\n+    /// When matching against matchers with nested delimited submatchers (e.g. `pat ( pat ( .. )\n+    /// pat ) pat`), we need to keep track of the matchers we are descending into. This stack does\n+    /// that where the bottom of the stack is the outermost matcher.\n+    // Also, throughout the comments, this \"descent\" is often referred to as \"unzipping\"...\n+    stack: Vec<MatcherTtFrame>,\n }\n \n impl MatcherPos {\n+    /// Add `m` as a named match for the `idx`-th metavar.\n     fn push_match(&mut self, idx: usize, m: NamedMatch) {\n         let matches = Rc::make_mut(&mut self.matches[idx]);\n         matches.push(m);\n     }\n }\n \n+/// Represents the possible results of an attempted parse.\n+pub enum ParseResult<T> {\n+    /// Parsed successfully.\n+    Success(T),\n+    /// Arm failed to match. If the second parameter is `token::Eof`, it indicates an unexpected\n+    /// end of macro invocation. Otherwise, it indicates that no rules expected the given token.\n+    Failure(syntax_pos::Span, Token),\n+    /// Fatal error (malformed macro?). Abort compilation.\n+    Error(syntax_pos::Span, String),\n+}\n+\n+/// A `ParseResult` where the `Success` variant contains a mapping of `Ident`s to `NamedMatch`es.\n+/// This represents the mapping of metavars to the token trees they bind to.\n pub type NamedParseResult = ParseResult<HashMap<Ident, Rc<NamedMatch>>>;\n \n+/// Count how many metavars are named in the given matcher `ms`.\n pub fn count_names(ms: &[TokenTree]) -> usize {\n     ms.iter().fold(0, |count, elt| {\n         count + match *elt {\n@@ -169,20 +226,38 @@ pub fn count_names(ms: &[TokenTree]) -> usize {\n     })\n }\n \n+/// Initialize `len` empty shared `Vec`s to be used to store matches of metavars.\n+fn create_matches(len: usize) -> Vec<Rc<Vec<NamedMatch>>> {\n+    (0..len).into_iter().map(|_| Rc::new(Vec::new())).collect()\n+}\n+\n+/// Generate the top-level matcher position in which the \"dot\" is before the first token of the\n+/// matcher `ms` and we are going to start matching at position `lo` in the source.\n fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n     let match_idx_hi = count_names(&ms[..]);\n     let matches = create_matches(match_idx_hi);\n     Box::new(MatcherPos {\n-        stack: vec![],\n-        top_elts: TtSeq(ms),\n-        sep: None,\n+        // Start with the top level matcher given to us\n+        top_elts: TtSeq(ms), // \"elts\" is an abbr. for \"elements\"\n+        // The \"dot\" is before the first token of the matcher\n         idx: 0,\n-        up: None,\n+        // We start matching with byte `lo` in the source code\n+        sp_lo: lo,\n+\n+        // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in `top_elts`.\n+        // `match_lo` for `top_elts` is 0 and `match_hi` is `matches.len()`. `match_cur` is 0 since\n+        // we haven't actually matched anything yet.\n         matches,\n         match_lo: 0,\n         match_cur: 0,\n         match_hi: match_idx_hi,\n-        sp_lo: lo,\n+\n+        // Haven't descended into any delimiters, so empty stack\n+        stack: vec![],\n+\n+        // Haven't descended into any sequences, so both of these are `None`\n+        sep: None,\n+        up: None,\n     })\n }\n \n@@ -202,7 +277,6 @@ fn initial_matcher_pos(ms: Vec<TokenTree>, lo: BytePos) -> Box<MatcherPos> {\n /// token tree. The depth of the `NamedMatch` structure will therefore depend\n /// only on the nesting depth of `ast::TTSeq`s in the originating\n /// token tree it was derived from.\n-\n #[derive(Debug, Clone)]\n pub enum NamedMatch {\n     MatchedSeq(Rc<Vec<NamedMatch>>, syntax_pos::Span),\n@@ -260,16 +334,6 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n     Success(ret_val)\n }\n \n-pub enum ParseResult<T> {\n-    Success(T),\n-    /// Arm failed to match. If the second parameter is `token::Eof`, it\n-    /// indicates an unexpected end of macro invocation. Otherwise, it\n-    /// indicates that no rules expected the given token.\n-    Failure(syntax_pos::Span, Token),\n-    /// Fatal error (malformed macro?). Abort compilation.\n-    Error(syntax_pos::Span, String),\n-}\n-\n pub fn parse_failure_msg(tok: Token) -> String {\n     match tok {\n         token::Eof => \"unexpected end of macro invocation\".to_string(),\n@@ -291,10 +355,6 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     }\n }\n \n-fn create_matches(len: usize) -> Vec<Rc<Vec<NamedMatch>>> {\n-    (0..len).into_iter().map(|_| Rc::new(Vec::new())).collect()\n-}\n-\n fn inner_parse_loop(\n     sess: &ParseSess,\n     cur_items: &mut SmallVector<Box<MatcherPos>>,\n@@ -429,14 +489,14 @@ fn inner_parse_loop(\n     Success(())\n }\n \n-/// Parse the given set of token trees (`ms`), possibly consuming additional token trees from the\n-/// tokenstream (`tts`).\n+/// Use the given sequence of token trees (`ms`) as a matcher. Match the given token stream `tts`\n+/// against it and return the match.\n ///\n /// # Parameters\n ///\n /// - `sess`: The session into which errors are emitted\n-/// - `tts`: The tokenstream from which additional token trees may be consumed if needed\n-/// - `ms`: The token trees we want to parse as macros\n+/// - `tts`: The tokenstream we are matching against the pattern `ms`\n+/// - `ms`: A sequence of token trees representing a pattern against which we are matching\n /// - `directory`: Information about the file locations (needed for the black-box parser)\n /// - `recurse_into_modules`: Whether or not to recurse into modules (needed for the black-box\n ///   parser)\n@@ -451,10 +511,10 @@ pub fn parse(\n     let mut parser = Parser::new(sess, tts, directory, recurse_into_modules, true);\n \n     // A queue of possible matcher positions. We initialize it with the matcher position in which\n-    // the \"dot\" is before the first token of the first token tree. `inner_parse_loop` then\n+    // the \"dot\" is before the first token of the first token tree in `ms`. `inner_parse_loop` then\n     // processes all of these possible matcher positions and produces posible next positions into\n-    // `next_items`. After some post-processing, the contents of `next_items` replenish\n-    // `cur_items` and we start over again.\n+    // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n+    // and we start over again.\n     let mut cur_items = SmallVector::one(initial_matcher_pos(ms.to_owned(), parser.span.lo()));\n     let mut next_items = Vec::new();\n "}]}