{"sha": "59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU5ZWY1MWMxMmEyN2FiMTc2MDZlYjdhMWMxZGE1OGU5ZWMwYzA5YWQ=", "commit": {"author": {"name": "Mark-Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-12-11T15:59:20Z"}, "committer": {"name": "Mark Simulacrum", "email": "mark.simulacrum@gmail.com", "date": "2016-12-21T03:01:40Z"}, "message": "Replace build.rs with calling functions on builder directly", "tree": {"sha": "b95815c21319d6c5cd17dde8e295ef1aa802f918", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b95815c21319d6c5cd17dde8e295ef1aa802f918"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "html_url": "https://github.com/rust-lang/rust/commit/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3f17ab9618d147a3f16d49a10fff44c5e8da4e60", "url": "https://api.github.com/repos/rust-lang/rust/commits/3f17ab9618d147a3f16d49a10fff44c5e8da4e60", "html_url": "https://github.com/rust-lang/rust/commit/3f17ab9618d147a3f16d49a10fff44c5e8da4e60"}], "stats": {"total": 1540, "additions": 373, "deletions": 1167}, "files": [{"sha": "a0bea5d38b2a749d6edd5e76d9abeb6af1e88c09", "filename": "src/librustc_trans/abi.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fabi.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -10,7 +10,6 @@\n \n use llvm::{self, ValueRef, Integer, Pointer, Float, Double, Struct, Array, Vector, AttributePlace};\n use base;\n-use build::AllocaFcx;\n use common::{type_is_fat_ptr, BlockAndBuilder, C_uint};\n use context::CrateContext;\n use cabi_x86;\n@@ -278,7 +277,7 @@ impl ArgType {\n                 //   bitcasting to the struct type yields invalid cast errors.\n \n                 // We instead thus allocate some scratch space...\n-                let llscratch = AllocaFcx(bcx.fcx(), ty, \"abi_cast\");\n+                let llscratch = bcx.fcx().alloca(ty, \"abi_cast\");\n                 base::Lifetime::Start.call(bcx, llscratch);\n \n                 // ...where we first store the value..."}, {"sha": "ef44a5fd60ebcb3552a80bd239925e70ffa7325a", "filename": "src/librustc_trans/adt.rs", "status": "modified", "additions": 14, "deletions": 15, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fadt.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -48,7 +48,6 @@ use std;\n use llvm::{ValueRef, True, IntEQ, IntNE};\n use rustc::ty::layout;\n use rustc::ty::{self, Ty, AdtKind};\n-use build::*;\n use common::*;\n use debuginfo::DebugLoc;\n use glue;\n@@ -348,7 +347,7 @@ pub fn trans_get_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n             load_discr(bcx, discr, scrutinee, min, max, range_assert)\n         }\n         layout::General { discr, .. } => {\n-            let ptr = StructGEP(bcx, scrutinee, 0);\n+            let ptr = bcx.struct_gep(scrutinee, 0);\n             load_discr(bcx, discr, ptr, 0, def.variants.len() as u64 - 1,\n                        range_assert)\n         }\n@@ -358,7 +357,7 @@ pub fn trans_get_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n             let llptrty = type_of::sizing_type_of(bcx.ccx(),\n                 monomorphize::field_ty(bcx.ccx().tcx(), substs,\n                 &def.variants[nndiscr as usize].fields[0]));\n-            ICmp(bcx, cmp, Load(bcx, scrutinee), C_null(llptrty), DebugLoc::None)\n+            bcx.icmp(cmp, bcx.load(scrutinee), C_null(llptrty))\n         }\n         layout::StructWrappedNullablePointer { nndiscr, ref discrfield, .. } => {\n             struct_wrapped_nullable_bitdiscr(bcx, nndiscr, discrfield, scrutinee)\n@@ -367,7 +366,7 @@ pub fn trans_get_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n     };\n     match cast_to {\n         None => val,\n-        Some(llty) => if is_discr_signed(&l) { SExt(bcx, val, llty) } else { ZExt(bcx, val, llty) }\n+        Some(llty) => if is_discr_signed(&l) { bcx.sext(val, llty) } else { bcx.zext(val, llty) }\n     }\n }\n \n@@ -377,11 +376,11 @@ fn struct_wrapped_nullable_bitdiscr(\n     discrfield: &layout::FieldPath,\n     scrutinee: ValueRef\n ) -> ValueRef {\n-    let llptrptr = GEPi(bcx, scrutinee,\n+    let llptrptr = bcx.gepi(scrutinee,\n         &discrfield.iter().map(|f| *f as usize).collect::<Vec<_>>()[..]);\n-    let llptr = Load(bcx, llptrptr);\n+    let llptr = bcx.load(llptrptr);\n     let cmp = if nndiscr == 0 { IntEQ } else { IntNE };\n-    ICmp(bcx, cmp, llptr, C_null(val_ty(llptr)), DebugLoc::None)\n+    bcx.icmp(cmp, llptr, C_null(val_ty(llptr)))\n }\n \n /// Helper for cases where the discriminant is simply loaded.\n@@ -401,11 +400,11 @@ fn load_discr(bcx: &BlockAndBuilder, ity: layout::Integer, ptr: ValueRef, min: u\n         // rejected by the LLVM verifier (it would mean either an\n         // empty set, which is impossible, or the entire range of the\n         // type, which is pointless).\n-        Load(bcx, ptr)\n+        bcx.load(ptr)\n     } else {\n         // llvm::ConstantRange can deal with ranges that wrap around,\n         // so an overflow on (max + 1) is fine.\n-        LoadRangeAssert(bcx, ptr, min, max.wrapping_add(1), /* signed: */ True)\n+        bcx.load_range_assert(ptr, min, max.wrapping_add(1), /* signed: */ True)\n     }\n }\n \n@@ -440,12 +439,12 @@ pub fn trans_set_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n     match *l {\n         layout::CEnum{ discr, min, max, .. } => {\n             assert_discr_in_range(Disr(min), Disr(max), to);\n-            Store(bcx, C_integral(Type::from_integer(bcx.ccx(), discr), to.0, true),\n+            bcx.store(C_integral(Type::from_integer(bcx.ccx(), discr), to.0, true),\n                   val);\n         }\n         layout::General{ discr, .. } => {\n-            Store(bcx, C_integral(Type::from_integer(bcx.ccx(), discr), to.0, true),\n-                  StructGEP(bcx, val, 0));\n+            bcx.store(C_integral(Type::from_integer(bcx.ccx(), discr), to.0, true),\n+                  bcx.struct_gep(val, 0));\n         }\n         layout::Univariant { .. }\n         | layout::UntaggedUnion { .. }\n@@ -456,7 +455,7 @@ pub fn trans_set_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n             let nnty = compute_fields(bcx.ccx(), t, nndiscr as usize, false)[0];\n             if to.0 != nndiscr {\n                 let llptrty = type_of::sizing_type_of(bcx.ccx(), nnty);\n-                Store(bcx, C_null(llptrty), val);\n+                bcx.store(C_null(llptrty), val);\n             }\n         }\n         layout::StructWrappedNullablePointer { nndiscr, ref discrfield, ref nonnull, .. } => {\n@@ -472,9 +471,9 @@ pub fn trans_set_discr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, t: Ty<'tcx\n                     base::call_memset(bcx, llptr, fill_byte, size, align, false);\n                 } else {\n                     let path = discrfield.iter().map(|&i| i as usize).collect::<Vec<_>>();\n-                    let llptrptr = GEPi(bcx, val, &path[..]);\n+                    let llptrptr = bcx.gepi(val, &path[..]);\n                     let llptrty = val_ty(llptrptr).element_type();\n-                    Store(bcx, C_null(llptrty), llptrptr);\n+                    bcx.store(C_null(llptrty), llptrptr);\n                 }\n             }\n         }"}, {"sha": "4c4f8cf67d2d7a787c8c5e6bc9cc390b40968c55", "filename": "src/librustc_trans/asm.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fasm.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -12,7 +12,6 @@\n \n use llvm::{self, ValueRef};\n use base;\n-use build::*;\n use common::*;\n use type_of;\n use type_::Type;\n@@ -90,20 +89,21 @@ pub fn trans_inline_asm<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n \n     let asm = CString::new(ia.asm.as_str().as_bytes()).unwrap();\n     let constraint_cstr = CString::new(all_constraints).unwrap();\n-    let r = InlineAsmCall(bcx,\n-                          asm.as_ptr(),\n-                          constraint_cstr.as_ptr(),\n-                          &inputs,\n-                          output_type,\n-                          ia.volatile,\n-                          ia.alignstack,\n-                          dialect);\n+    let r = bcx.inline_asm_call(\n+        asm.as_ptr(),\n+        constraint_cstr.as_ptr(),\n+        &inputs,\n+        output_type,\n+        ia.volatile,\n+        ia.alignstack,\n+        dialect\n+    );\n \n     // Again, based on how many outputs we have\n     let outputs = ia.outputs.iter().zip(&outputs).filter(|&(ref o, _)| !o.is_indirect);\n     for (i, (_, &(val, _))) in outputs.enumerate() {\n-        let v = if num_outputs == 1 { r } else { ExtractValue(bcx, r, i) };\n-        Store(bcx, v, val);\n+        let v = if num_outputs == 1 { r } else { bcx.extract_value(r, i) };\n+        bcx.store(v, val);\n     }\n \n     // Store expn_id in a metadata node so we can map LLVM errors"}, {"sha": "1e4c10c4fc766fe784ef53bc7b3e5b1858dba773", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 62, "deletions": 59, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -51,7 +51,6 @@ use session::{self, DataTypeKind, Session};\n use abi::{self, Abi, FnType};\n use adt;\n use attributes;\n-use build::*;\n use builder::{Builder, noname};\n use callee::{Callee};\n use common::{BlockAndBuilder, C_bool, C_bytes_in_context, C_i32, C_uint};\n@@ -174,11 +173,11 @@ impl<'a, 'tcx> Drop for StatRecorder<'a, 'tcx> {\n }\n \n pub fn get_meta(bcx: &BlockAndBuilder, fat_ptr: ValueRef) -> ValueRef {\n-    StructGEP(bcx, fat_ptr, abi::FAT_PTR_EXTRA)\n+    bcx.struct_gep(fat_ptr, abi::FAT_PTR_EXTRA)\n }\n \n pub fn get_dataptr(bcx: &BlockAndBuilder, fat_ptr: ValueRef) -> ValueRef {\n-    StructGEP(bcx, fat_ptr, abi::FAT_PTR_ADDR)\n+    bcx.struct_gep(fat_ptr, abi::FAT_PTR_ADDR)\n }\n \n pub fn get_meta_builder(b: &Builder, fat_ptr: ValueRef) -> ValueRef {\n@@ -207,15 +206,14 @@ pub fn malloc_raw_dyn<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                   llty_ptr: Type,\n                                   info_ty: Ty<'tcx>,\n                                   size: ValueRef,\n-                                  align: ValueRef,\n-                                  debug_loc: DebugLoc)\n+                                  align: ValueRef)\n                                   -> ValueRef {\n     let _icx = push_ctxt(\"malloc_raw_exchange\");\n \n     // Allocate space:\n     let def_id = require_alloc_fn(bcx, info_ty, ExchangeMallocFnLangItem);\n     let r = Callee::def(bcx.ccx(), def_id, bcx.tcx().intern_substs(&[])).reify(bcx.ccx());\n-    PointerCast(bcx, Call(bcx, r, &[size, align], debug_loc), llty_ptr)\n+    bcx.pointercast(bcx.call(r, &[size, align], bcx.lpad().and_then(|b| b.bundle())), llty_ptr)\n }\n \n \n@@ -258,13 +256,12 @@ pub fn compare_simd_types<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                       rhs: ValueRef,\n                                       t: Ty<'tcx>,\n                                       ret_ty: Type,\n-                                      op: hir::BinOp_,\n-                                      debug_loc: DebugLoc)\n+                                      op: hir::BinOp_)\n                                       -> ValueRef {\n     let signed = match t.sty {\n         ty::TyFloat(_) => {\n             let cmp = bin_op_to_fcmp_predicate(op);\n-            return SExt(bcx, FCmp(bcx, cmp, lhs, rhs, debug_loc), ret_ty);\n+            return bcx.sext(bcx.fcmp(cmp, lhs, rhs), ret_ty);\n         },\n         ty::TyUint(_) => false,\n         ty::TyInt(_) => true,\n@@ -276,7 +273,7 @@ pub fn compare_simd_types<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     // to get the correctly sized type. This will compile to a single instruction\n     // once the IR is converted to assembly if the SIMD instruction is supported\n     // by the target architecture.\n-    SExt(bcx, ICmp(bcx, cmp, lhs, rhs, debug_loc), ret_ty)\n+    bcx.sext(bcx.icmp(cmp, lhs, rhs), ret_ty)\n }\n \n /// Retrieve the information we are losing (making dynamic) in an unsizing\n@@ -326,8 +323,7 @@ pub fn unsize_thin_ptr<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n          &ty::TyRawPtr(ty::TypeAndMut { ty: b, .. })) => {\n             assert!(common::type_is_sized(bcx.tcx(), a));\n             let ptr_ty = type_of::in_memory_type_of(bcx.ccx(), b).ptr_to();\n-            (PointerCast(bcx, src, ptr_ty),\n-             unsized_info(bcx.ccx(), a, b, None))\n+            (bcx.pointercast(src, ptr_ty), unsized_info(bcx.ccx(), a, b, None))\n         }\n         _ => bug!(\"unsize_thin_ptr: called on bad types\"),\n     }\n@@ -352,7 +348,7 @@ pub fn coerce_unsized_into<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                 // the types match up.\n                 let (base, info) = load_fat_ptr(bcx, src, src_ty);\n                 let llcast_ty = type_of::fat_ptr_base_ty(bcx.ccx(), dst_ty);\n-                let base = PointerCast(bcx, base, llcast_ty);\n+                let base = bcx.pointercast(base, llcast_ty);\n                 (base, info)\n             } else {\n                 let base = load_ty(bcx, src, src_ty);\n@@ -414,8 +410,10 @@ pub fn custom_coerce_unsize_info<'scx, 'tcx>(scx: &SharedCrateContext<'scx, 'tcx\n     }\n }\n \n-pub fn cast_shift_expr_rhs(cx: &BlockAndBuilder, op: hir::BinOp_, lhs: ValueRef, rhs: ValueRef) -> ValueRef {\n-    cast_shift_rhs(op, lhs, rhs, |a, b| Trunc(cx, a, b), |a, b| ZExt(cx, a, b))\n+pub fn cast_shift_expr_rhs(\n+    cx: &BlockAndBuilder, op: hir::BinOp_, lhs: ValueRef, rhs: ValueRef\n+) -> ValueRef {\n+    cast_shift_rhs(op, lhs, rhs, |a, b| cx.trunc(a, b), |a, b| cx.zext(a, b))\n }\n \n pub fn cast_shift_const_rhs(op: hir::BinOp_, lhs: ValueRef, rhs: ValueRef) -> ValueRef {\n@@ -463,8 +461,7 @@ fn cast_shift_rhs<F, G>(op: hir::BinOp_,\n \n pub fn invoke<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                           llfn: ValueRef,\n-                          llargs: &[ValueRef],\n-                          debug_loc: DebugLoc)\n+                          llargs: &[ValueRef])\n                           -> (ValueRef, BlockAndBuilder<'blk, 'tcx>) {\n     let _icx = push_ctxt(\"invoke_\");\n     if need_invoke(&bcx) {\n@@ -475,20 +472,21 @@ pub fn invoke<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n         let normal_bcx = bcx.fcx().new_block(\"normal-return\");\n         let landing_pad = bcx.fcx().get_landing_pad();\n \n-        let llresult = Invoke(&bcx,\n-                              llfn,\n-                              &llargs[..],\n-                              normal_bcx.llbb,\n-                              landing_pad,\n-                              debug_loc);\n+        let llresult = bcx.invoke(\n+            llfn,\n+            &llargs[..],\n+            normal_bcx.llbb,\n+            landing_pad,\n+            bcx.lpad().and_then(|b| b.bundle())\n+        );\n         return (llresult, normal_bcx.build());\n     } else {\n         debug!(\"calling {:?} at {:?}\", Value(llfn), bcx.llbb());\n         for &llarg in llargs {\n             debug!(\"arg: {:?}\", Value(llarg));\n         }\n \n-        let llresult = Call(&bcx, llfn, &llargs[..], debug_loc);\n+        let llresult = bcx.call(llfn, &llargs[..], bcx.lpad().and_then(|b| b.bundle()));\n         return (llresult, bcx);\n     }\n }\n@@ -518,7 +516,9 @@ pub fn call_assume<'a, 'tcx>(b: &Builder<'a, 'tcx>, val: ValueRef) {\n /// Helper for loading values from memory. Does the necessary conversion if the in-memory type\n /// differs from the type used for SSA values. Also handles various special cases where the type\n /// gives us better information about what we are loading.\n-pub fn load_ty<'blk, 'tcx>(cx: &BlockAndBuilder<'blk, 'tcx>, ptr: ValueRef, t: Ty<'tcx>) -> ValueRef {\n+pub fn load_ty<'blk, 'tcx>(\n+    cx: &BlockAndBuilder<'blk, 'tcx>, ptr: ValueRef, t: Ty<'tcx>\n+) -> ValueRef {\n     load_ty_builder(cx, ptr, t)\n }\n \n@@ -557,15 +557,17 @@ pub fn load_ty_builder<'a, 'tcx>(b: &Builder<'a, 'tcx>, ptr: ValueRef, t: Ty<'tc\n \n /// Helper for storing values in memory. Does the necessary conversion if the in-memory type\n /// differs from the type used for SSA values.\n-pub fn store_ty<'blk, 'tcx>(cx: &BlockAndBuilder<'blk, 'tcx>, v: ValueRef, dst: ValueRef, t: Ty<'tcx>) {\n+pub fn store_ty<'blk, 'tcx>(\n+    cx: &BlockAndBuilder<'blk, 'tcx>, v: ValueRef, dst: ValueRef, t: Ty<'tcx>\n+) {\n     debug!(\"store_ty: {:?} : {:?} <- {:?}\", Value(dst), t, Value(v));\n \n     if common::type_is_fat_ptr(cx.tcx(), t) {\n-        let lladdr = ExtractValue(cx, v, abi::FAT_PTR_ADDR);\n-        let llextra = ExtractValue(cx, v, abi::FAT_PTR_EXTRA);\n+        let lladdr = cx.extract_value(v, abi::FAT_PTR_ADDR);\n+        let llextra = cx.extract_value(v, abi::FAT_PTR_EXTRA);\n         store_fat_ptr(cx, lladdr, llextra, dst, t);\n     } else {\n-        Store(cx, from_immediate(cx, v), dst);\n+        cx.store(from_immediate(cx, v), dst);\n     }\n }\n \n@@ -575,8 +577,8 @@ pub fn store_fat_ptr<'blk, 'tcx>(cx: &BlockAndBuilder<'blk, 'tcx>,\n                                  dst: ValueRef,\n                                  _ty: Ty<'tcx>) {\n     // FIXME: emit metadata\n-    Store(cx, data, get_dataptr(cx, dst));\n-    Store(cx, extra, get_meta(cx, dst));\n+    cx.store(data, get_dataptr(cx, dst));\n+    cx.store(extra, get_meta(cx, dst));\n }\n \n pub fn load_fat_ptr<'blk, 'tcx>(cx: &BlockAndBuilder<'blk, 'tcx>,\n@@ -609,15 +611,15 @@ pub fn load_fat_ptr_builder<'a, 'tcx>(\n \n pub fn from_immediate(bcx: &BlockAndBuilder, val: ValueRef) -> ValueRef {\n     if val_ty(val) == Type::i1(bcx.ccx()) {\n-        ZExt(bcx, val, Type::i8(bcx.ccx()))\n+        bcx.zext(val, Type::i8(bcx.ccx()))\n     } else {\n         val\n     }\n }\n \n pub fn to_immediate(bcx: &BlockAndBuilder, val: ValueRef, ty: Ty) -> ValueRef {\n     if ty.is_bool() {\n-        Trunc(bcx, val, Type::i1(bcx.ccx()))\n+        bcx.trunc(val, Type::i1(bcx.ccx()))\n     } else {\n         val\n     }\n@@ -637,9 +639,9 @@ pub fn with_cond<'blk, 'tcx, F>(\n     let fcx = bcx.fcx();\n     let next_cx = fcx.new_block(\"next\").build();\n     let cond_cx = fcx.new_block(\"cond\").build();\n-    CondBr(&bcx, val, cond_cx.llbb(), next_cx.llbb(), DebugLoc::None);\n+    bcx.cond_br(val, cond_cx.llbb(), next_cx.llbb());\n     let after_cx = f(cond_cx);\n-    Br(&after_cx, next_cx.llbb(), DebugLoc::None);\n+    after_cx.br(next_cx.llbb());\n     next_cx\n }\n \n@@ -702,8 +704,9 @@ pub fn trans_unwind_resume(bcx: &BlockAndBuilder, lpval: ValueRef) {\n     if !bcx.sess().target.target.options.custom_unwind_resume {\n         bcx.resume(lpval);\n     } else {\n-        let exc_ptr = ExtractValue(bcx, lpval, 0);\n-        Call(bcx, bcx.fcx().eh_unwind_resume().reify(bcx.ccx()), &[exc_ptr], DebugLoc::None);\n+        let exc_ptr = bcx.extract_value(lpval, 0);\n+        bcx.call(bcx.fcx().eh_unwind_resume().reify(bcx.ccx()), &[exc_ptr],\n+            bcx.lpad().and_then(|b| b.bundle()));\n     }\n }\n \n@@ -725,7 +728,9 @@ pub fn call_memcpy<'bcx, 'tcx>(b: &Builder<'bcx, 'tcx>,\n     b.call(memcpy, &[dst_ptr, src_ptr, size, align, volatile], None);\n }\n \n-pub fn memcpy_ty<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>, dst: ValueRef, src: ValueRef, t: Ty<'tcx>) {\n+pub fn memcpy_ty<'blk, 'tcx>(\n+    bcx: &BlockAndBuilder<'blk, 'tcx>, dst: ValueRef, src: ValueRef, t: Ty<'tcx>\n+) {\n     let _icx = push_ctxt(\"memcpy_ty\");\n     let ccx = bcx.ccx();\n \n@@ -792,7 +797,7 @@ pub fn alloc_ty<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n pub fn alloca(cx: &BlockAndBuilder, ty: Type, name: &str) -> ValueRef {\n     let _icx = push_ctxt(\"alloca\");\n     DebugLoc::None.apply(cx.fcx());\n-    Alloca(cx, ty, name)\n+    cx.fcx().alloca(ty, name)\n }\n \n impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n@@ -863,7 +868,7 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n         // Use a dummy instruction as the insertion point for all allocas.\n         // This is later removed in FunctionContext::cleanup.\n         self.alloca_insert_pt.set(Some(unsafe {\n-            Load(&entry_bcx, C_null(Type::i8p(self.ccx)));\n+            entry_bcx.load(C_null(Type::i8p(self.ccx)));\n             llvm::LLVMGetFirstInstruction(entry_bcx.llbb())\n         }));\n \n@@ -881,7 +886,7 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n             let slot = if self.fn_ty.ret.is_indirect() {\n                 get_param(self.llfn, 0)\n             } else {\n-                AllocaFcx(self, llty, \"sret_slot\")\n+                self.alloca(llty, \"sret_slot\")\n             };\n \n             self.llretslotptr.set(Some(slot));\n@@ -892,21 +897,19 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n \n     /// Ties up the llstaticallocas -> llloadenv -> lltop edges,\n     /// and builds the return block.\n-    pub fn finish(&'blk self, ret_cx: &BlockAndBuilder<'blk, 'tcx>,\n-                  ret_debug_loc: DebugLoc) {\n+    pub fn finish(&'blk self, ret_cx: &BlockAndBuilder<'blk, 'tcx>) {\n         let _icx = push_ctxt(\"FunctionContext::finish\");\n \n-        self.build_return_block(ret_cx, ret_debug_loc);\n+        self.build_return_block(ret_cx);\n \n         DebugLoc::None.apply(self);\n         self.cleanup();\n     }\n \n     // Builds the return block for a function.\n-    pub fn build_return_block(&self, ret_cx: &BlockAndBuilder<'blk, 'tcx>,\n-                              ret_debug_location: DebugLoc) {\n+    pub fn build_return_block(&self, ret_cx: &BlockAndBuilder<'blk, 'tcx>) {\n         if self.llretslotptr.get().is_none() || self.fn_ty.ret.is_indirect() {\n-            return RetVoid(ret_cx, ret_debug_location);\n+            return ret_cx.ret_void();\n         }\n \n         let retslot = self.llretslotptr.get().unwrap();\n@@ -925,13 +928,13 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                 }\n \n                 if self.fn_ty.ret.is_indirect() {\n-                    Store(ret_cx, retval, get_param(self.llfn, 0));\n-                    RetVoid(ret_cx, ret_debug_location)\n+                    ret_cx.store(retval, get_param(self.llfn, 0));\n+                    ret_cx.ret_void()\n                 } else {\n                     if llty == Type::i1(self.ccx) {\n-                        retval = Trunc(ret_cx, retval, llty);\n+                        retval = ret_cx.trunc(retval, llty);\n                     }\n-                    Ret(ret_cx, retval, ret_debug_location)\n+                    ret_cx.ret(retval)\n                 }\n             }\n             (_, cast_ty) if self.fn_ty.ret.is_indirect() => {\n@@ -941,24 +944,24 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                 let llalign = llalign_of_min(self.ccx, self.fn_ty.ret.ty);\n                 call_memcpy(&ret_cx, get_param(self.llfn, 0),\n                             retslot, llsz, llalign as u32);\n-                RetVoid(ret_cx, ret_debug_location)\n+                ret_cx.ret_void()\n             }\n             (_, Some(cast_ty)) => {\n-                let load = Load(ret_cx, PointerCast(ret_cx, retslot, cast_ty.ptr_to()));\n+                let load = ret_cx.load(ret_cx.pointercast(retslot, cast_ty.ptr_to()));\n                 let llalign = llalign_of_min(self.ccx, self.fn_ty.ret.ty);\n                 unsafe {\n                     llvm::LLVMSetAlignment(load, llalign);\n                 }\n-                Ret(ret_cx, load, ret_debug_location)\n+                ret_cx.ret(load)\n             }\n             (_, None) => {\n                 let retval = if llty == Type::i1(self.ccx) {\n-                    let val = LoadRangeAssert(ret_cx, retslot, 0, 2, llvm::False);\n-                    Trunc(ret_cx, val, llty)\n+                    let val = ret_cx.load_range_assert(retslot, 0, 2, llvm::False);\n+                    ret_cx.trunc(val, llty)\n                 } else {\n-                    Load(ret_cx, retslot)\n+                    ret_cx.load(retslot)\n                 };\n-                Ret(ret_cx, retval, ret_debug_location)\n+                ret_cx.ret(retval)\n             }\n         }\n     }\n@@ -1056,7 +1059,7 @@ pub fn trans_ctor_shim<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n         adt::trans_set_discr(&bcx, sig.output(), dest, disr);\n     }\n \n-    fcx.finish(&bcx, DebugLoc::None);\n+    fcx.finish(&bcx);\n }\n \n pub fn llvm_linkage_by_name(name: &str) -> Option<Linkage> {"}, {"sha": "16f362da29fceb0faffc2c723740fa6252c1c6ff", "filename": "src/librustc_trans/build.rs", "status": "removed", "additions": 0, "deletions": 734, "changes": 734, "blob_url": "https://github.com/rust-lang/rust/blob/3f17ab9618d147a3f16d49a10fff44c5e8da4e60/src%2Flibrustc_trans%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3f17ab9618d147a3f16d49a10fff44c5e8da4e60/src%2Flibrustc_trans%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbuild.rs?ref=3f17ab9618d147a3f16d49a10fff44c5e8da4e60", "patch": "@@ -1,734 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-#![allow(dead_code)] // FFI wrappers\n-#![allow(non_snake_case)]\n-\n-use llvm;\n-use llvm::{AtomicRmwBinOp, AtomicOrdering, SynchronizationScope, AsmDialect};\n-use llvm::{Opcode, IntPredicate, RealPredicate};\n-use llvm::{ValueRef, BasicBlockRef};\n-use common::*;\n-use syntax_pos::Span;\n-\n-use type_::Type;\n-use value::Value;\n-use debuginfo::DebugLoc;\n-\n-use libc::{c_uint, c_char};\n-\n-pub fn RetVoid(cx: &BlockAndBuilder, debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.ret_void();\n-}\n-\n-pub fn Ret(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.ret(v);\n-}\n-\n-pub fn AggregateRet(cx: &BlockAndBuilder,\n-    ret_vals: &[ValueRef],\n-    debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.aggregate_ret(ret_vals);\n-}\n-\n-pub fn Br(cx: &BlockAndBuilder, dest: BasicBlockRef, debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.br(dest);\n-}\n-\n-pub fn CondBr(cx: &BlockAndBuilder,\n-    if_: ValueRef,\n-    then: BasicBlockRef,\n-    else_: BasicBlockRef,\n-    debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.cond_br(if_, then, else_);\n-}\n-\n-pub fn Switch(cx: &BlockAndBuilder, v: ValueRef, else_: BasicBlockRef, num_cases: usize)\n-    -> ValueRef {\n-        cx.switch(v, else_, num_cases)\n-    }\n-\n-pub fn AddCase(s: ValueRef, on_val: ValueRef, dest: BasicBlockRef) {\n-    unsafe {\n-        if llvm::LLVMIsUndef(s) == llvm::True { return; }\n-        llvm::LLVMAddCase(s, on_val, dest);\n-    }\n-}\n-\n-pub fn IndirectBr(cx: &BlockAndBuilder,\n-    addr: ValueRef,\n-    num_dests: usize,\n-    debug_loc: DebugLoc) {\n-    debug_loc.apply(cx.fcx());\n-    cx.indirect_br(addr, num_dests);\n-}\n-\n-pub fn Invoke(cx: &BlockAndBuilder,\n-    fn_: ValueRef,\n-    args: &[ValueRef],\n-    then: BasicBlockRef,\n-    catch: BasicBlockRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-    debug!(\"Invoke({:?} with arguments ({}))\",\n-    Value(fn_),\n-    args.iter().map(|a| {\n-        format!(\"{:?}\", Value(*a))\n-    }).collect::<Vec<String>>().join(\", \"));\n-    debug_loc.apply(cx.fcx());\n-    let bundle = cx.lpad().and_then(|b| b.bundle());\n-    cx.invoke(fn_, args, then, catch, bundle)\n-}\n-\n-/* Arithmetic */\n-pub fn Add(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.add(lhs, rhs)\n-    }\n-\n-pub fn NSWAdd(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nswadd(lhs, rhs)\n-    }\n-\n-pub fn NUWAdd(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nuwadd(lhs, rhs)\n-    }\n-\n-pub fn FAdd(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fadd(lhs, rhs)\n-    }\n-\n-pub fn FAddFast(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fadd_fast(lhs, rhs)\n-    }\n-\n-pub fn Sub(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.sub(lhs, rhs)\n-    }\n-\n-pub fn NSWSub(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nswsub(lhs, rhs)\n-    }\n-\n-pub fn NUWSub(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nuwsub(lhs, rhs)\n-    }\n-\n-pub fn FSub(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fsub(lhs, rhs)\n-    }\n-\n-pub fn FSubFast(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fsub_fast(lhs, rhs)\n-    }\n-\n-pub fn Mul(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.mul(lhs, rhs)\n-    }\n-\n-pub fn NSWMul(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nswmul(lhs, rhs)\n-    }\n-\n-pub fn NUWMul(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.nuwmul(lhs, rhs)\n-    }\n-\n-pub fn FMul(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fmul(lhs, rhs)\n-    }\n-\n-pub fn FMulFast(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fmul_fast(lhs, rhs)\n-    }\n-\n-pub fn UDiv(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.udiv(lhs, rhs)\n-    }\n-\n-pub fn SDiv(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.sdiv(lhs, rhs)\n-    }\n-\n-pub fn ExactSDiv(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.exactsdiv(lhs, rhs)\n-    }\n-\n-pub fn FDiv(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fdiv(lhs, rhs)\n-    }\n-\n-pub fn FDivFast(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fdiv_fast(lhs, rhs)\n-    }\n-\n-pub fn URem(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.urem(lhs, rhs)\n-    }\n-\n-pub fn SRem(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.srem(lhs, rhs)\n-    }\n-\n-pub fn FRem(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.frem(lhs, rhs)\n-    }\n-\n-pub fn FRemFast(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.frem_fast(lhs, rhs)\n-    }\n-\n-pub fn Shl(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.shl(lhs, rhs)\n-    }\n-\n-pub fn LShr(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.lshr(lhs, rhs)\n-    }\n-\n-pub fn AShr(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.ashr(lhs, rhs)\n-    }\n-\n-pub fn And(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.and(lhs, rhs)\n-    }\n-\n-pub fn Or(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.or(lhs, rhs)\n-    }\n-\n-pub fn Xor(cx: &BlockAndBuilder,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.xor(lhs, rhs)\n-    }\n-\n-pub fn BinOp(cx: &BlockAndBuilder,\n-    op: Opcode,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.binop(op, lhs, rhs)\n-    }\n-\n-pub fn Neg(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) -> ValueRef {\n-    debug_loc.apply(cx.fcx());\n-    cx.neg(v)\n-}\n-\n-pub fn NSWNeg(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) -> ValueRef {\n-    debug_loc.apply(cx.fcx());\n-    cx.nswneg(v)\n-}\n-\n-pub fn NUWNeg(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) -> ValueRef {\n-    debug_loc.apply(cx.fcx());\n-    cx.nuwneg(v)\n-}\n-pub fn FNeg(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) -> ValueRef {\n-    debug_loc.apply(cx.fcx());\n-    cx.fneg(v)\n-}\n-\n-pub fn Not(cx: &BlockAndBuilder, v: ValueRef, debug_loc: DebugLoc) -> ValueRef {\n-    debug_loc.apply(cx.fcx());\n-    cx.not(v)\n-}\n-\n-pub fn Alloca(cx: &BlockAndBuilder, ty: Type, name: &str) -> ValueRef {\n-    AllocaFcx(cx.fcx(), ty, name)\n-}\n-\n-pub fn AllocaFcx(fcx: &FunctionContext, ty: Type, name: &str) -> ValueRef {\n-    let b = fcx.ccx.builder();\n-    b.position_before(fcx.alloca_insert_pt.get().unwrap());\n-    DebugLoc::None.apply(fcx);\n-    b.alloca(ty, name)\n-}\n-\n-pub fn Free(cx: &BlockAndBuilder, pointer_val: ValueRef) {\n-    cx.free(pointer_val)\n-}\n-\n-pub fn Load(cx: &BlockAndBuilder, pointer_val: ValueRef) -> ValueRef {\n-    cx.load(pointer_val)\n-}\n-\n-pub fn VolatileLoad(cx: &BlockAndBuilder, pointer_val: ValueRef) -> ValueRef {\n-    cx.volatile_load(pointer_val)\n-}\n-\n-pub fn AtomicLoad(cx: &BlockAndBuilder, pointer_val: ValueRef, order: AtomicOrdering) -> ValueRef {\n-    cx.atomic_load(pointer_val, order)\n-}\n-\n-\n-pub fn LoadRangeAssert(cx: &BlockAndBuilder, pointer_val: ValueRef, lo: u64,\n-    hi: u64, signed: llvm::Bool) -> ValueRef {\n-    cx.load_range_assert(pointer_val, lo, hi, signed)\n-}\n-\n-pub fn LoadNonNull(cx: &BlockAndBuilder, ptr: ValueRef) -> ValueRef {\n-    cx.load_nonnull(ptr)\n-}\n-\n-pub fn Store(cx: &BlockAndBuilder, val: ValueRef, ptr: ValueRef) -> ValueRef {\n-    cx.store(val, ptr)\n-}\n-\n-pub fn VolatileStore(cx: &BlockAndBuilder, val: ValueRef, ptr: ValueRef) -> ValueRef {\n-    cx.volatile_store(val, ptr)\n-}\n-\n-pub fn AtomicStore(cx: &BlockAndBuilder, val: ValueRef, ptr: ValueRef, order: AtomicOrdering) {\n-    cx.atomic_store(val, ptr, order)\n-}\n-\n-pub fn GEP(cx: &BlockAndBuilder, pointer: ValueRef, indices: &[ValueRef]) -> ValueRef {\n-    cx.gep(pointer, indices)\n-}\n-\n-// Simple wrapper around GEP that takes an array of ints and wraps them\n-// in C_i32()\n-#[inline]\n-pub fn GEPi(cx: &BlockAndBuilder, base: ValueRef, ixs: &[usize]) -> ValueRef {\n-    cx.gepi(base, ixs)\n-}\n-\n-pub fn InBoundsGEP(cx: &BlockAndBuilder, pointer: ValueRef, indices: &[ValueRef]) -> ValueRef {\n-    cx.inbounds_gep(pointer, indices)\n-}\n-\n-pub fn StructGEP(cx: &BlockAndBuilder, pointer: ValueRef, idx: usize) -> ValueRef {\n-    cx.struct_gep(pointer, idx)\n-}\n-\n-pub fn GlobalString(cx: &BlockAndBuilder, _str: *const c_char) -> ValueRef {\n-    cx.global_string(_str)\n-}\n-\n-pub fn GlobalStringPtr(cx: &BlockAndBuilder, _str: *const c_char) -> ValueRef {\n-    cx.global_string_ptr(_str)\n-}\n-\n-/* Casts */\n-pub fn Trunc(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.trunc(val, dest_ty)\n-}\n-\n-pub fn ZExt(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.zext(val, dest_ty)\n-}\n-\n-pub fn SExt(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.sext(val, dest_ty)\n-}\n-\n-pub fn FPToUI(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.fptoui(val, dest_ty)\n-}\n-\n-pub fn FPToSI(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.fptosi(val, dest_ty)\n-}\n-\n-pub fn UIToFP(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.uitofp(val, dest_ty)\n-}\n-\n-pub fn SIToFP(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.sitofp(val, dest_ty)\n-}\n-\n-pub fn FPTrunc(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.fptrunc(val, dest_ty)\n-}\n-\n-pub fn FPExt(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.fpext(val, dest_ty)\n-}\n-\n-pub fn PtrToInt(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.ptrtoint(val, dest_ty)\n-}\n-\n-pub fn IntToPtr(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.inttoptr(val, dest_ty)\n-}\n-\n-pub fn BitCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.bitcast(val, dest_ty)\n-}\n-\n-pub fn ZExtOrBitCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.zext_or_bitcast(val, dest_ty)\n-}\n-\n-pub fn SExtOrBitCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.sext_or_bitcast(val, dest_ty)\n-}\n-\n-pub fn TruncOrBitCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.trunc_or_bitcast(val, dest_ty)\n-}\n-\n-pub fn Cast(cx: &BlockAndBuilder, op: Opcode, val: ValueRef, dest_ty: Type,\n-    _: *const u8)\n-    -> ValueRef {\n-        cx.cast(op, val, dest_ty)\n-    }\n-\n-pub fn PointerCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.pointercast(val, dest_ty)\n-}\n-\n-pub fn IntCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.intcast(val, dest_ty)\n-}\n-\n-pub fn FPCast(cx: &BlockAndBuilder, val: ValueRef, dest_ty: Type) -> ValueRef {\n-    cx.fpcast(val, dest_ty)\n-}\n-\n-\n-/* Comparisons */\n-pub fn ICmp(cx: &BlockAndBuilder,\n-    op: IntPredicate,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.icmp(op, lhs, rhs)\n-    }\n-\n-pub fn FCmp(cx: &BlockAndBuilder,\n-    op: RealPredicate,\n-    lhs: ValueRef,\n-    rhs: ValueRef,\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        cx.fcmp(op, lhs, rhs)\n-    }\n-\n-/* Miscellaneous instructions */\n-pub fn EmptyPhi(cx: &BlockAndBuilder, ty: Type) -> ValueRef {\n-    cx.empty_phi(ty)\n-}\n-\n-pub fn Phi(cx: &BlockAndBuilder, ty: Type, vals: &[ValueRef], bbs: &[BasicBlockRef]) -> ValueRef {\n-    cx.phi(ty, vals, bbs)\n-}\n-\n-pub fn AddIncomingToPhi(phi: ValueRef, val: ValueRef, bb: BasicBlockRef) {\n-    unsafe {\n-        if llvm::LLVMIsUndef(phi) == llvm::True { return; }\n-        llvm::LLVMAddIncoming(phi, &val, &bb, 1 as c_uint);\n-    }\n-}\n-\n-pub fn add_span_comment(cx: &BlockAndBuilder, sp: Span, text: &str) {\n-    cx.add_span_comment(sp, text)\n-}\n-\n-pub fn add_comment(cx: &BlockAndBuilder, text: &str) {\n-    cx.add_comment(text)\n-}\n-\n-pub fn InlineAsmCall(cx: &BlockAndBuilder, asm: *const c_char, cons: *const c_char,\n-    inputs: &[ValueRef], output: Type,\n-    volatile: bool, alignstack: bool,\n-    dia: AsmDialect) -> ValueRef {\n-    cx.inline_asm_call(asm, cons, inputs, output, volatile, alignstack, dia)\n-}\n-\n-pub fn Call(cx: &BlockAndBuilder,\n-    fn_: ValueRef,\n-    args: &[ValueRef],\n-    debug_loc: DebugLoc)\n-    -> ValueRef {\n-        debug_loc.apply(cx.fcx());\n-        let bundle = cx.lpad().and_then(|b| b.bundle());\n-        cx.call(fn_, args, bundle)\n-    }\n-\n-pub fn AtomicFence(cx: &BlockAndBuilder, order: AtomicOrdering, scope: SynchronizationScope) {\n-    cx.atomic_fence(order, scope)\n-}\n-\n-pub fn Select(cx: &BlockAndBuilder, if_: ValueRef, then: ValueRef, else_: ValueRef) -> ValueRef {\n-    cx.select(if_, then, else_)\n-}\n-\n-pub fn VAArg(cx: &BlockAndBuilder, list: ValueRef, ty: Type) -> ValueRef {\n-    cx.va_arg(list, ty)\n-}\n-\n-pub fn ExtractElement(cx: &BlockAndBuilder, vec_val: ValueRef, index: ValueRef) -> ValueRef {\n-    cx.extract_element(vec_val, index)\n-}\n-\n-pub fn InsertElement(cx: &BlockAndBuilder, vec_val: ValueRef, elt_val: ValueRef,\n-    index: ValueRef) -> ValueRef {\n-    cx.insert_element(vec_val, elt_val, index)\n-}\n-\n-pub fn ShuffleVector(cx: &BlockAndBuilder, v1: ValueRef, v2: ValueRef,\n-    mask: ValueRef) -> ValueRef {\n-    cx.shuffle_vector(v1, v2, mask)\n-}\n-\n-pub fn VectorSplat(cx: &BlockAndBuilder, num_elts: usize, elt_val: ValueRef) -> ValueRef {\n-    cx.vector_splat(num_elts, elt_val)\n-}\n-\n-pub fn ExtractValue(cx: &BlockAndBuilder, agg_val: ValueRef, index: usize) -> ValueRef {\n-    cx.extract_value(agg_val, index)\n-}\n-\n-pub fn InsertValue(cx: &BlockAndBuilder, agg_val: ValueRef, elt_val: ValueRef, index: usize) -> ValueRef {\n-    cx.insert_value(agg_val, elt_val, index)\n-}\n-\n-pub fn IsNull(cx: &BlockAndBuilder, val: ValueRef) -> ValueRef {\n-    cx.is_null(val)\n-}\n-\n-pub fn IsNotNull(cx: &BlockAndBuilder, val: ValueRef) -> ValueRef {\n-    cx.is_not_null(val)\n-}\n-\n-pub fn PtrDiff(cx: &BlockAndBuilder, lhs: ValueRef, rhs: ValueRef) -> ValueRef {\n-    cx.ptrdiff(lhs, rhs)\n-}\n-\n-pub fn Trap(cx: &BlockAndBuilder) {\n-    cx.trap();\n-}\n-\n-pub fn LandingPad(cx: &BlockAndBuilder, ty: Type, pers_fn: ValueRef,\n-    num_clauses: usize) -> ValueRef {\n-    cx.landing_pad(ty, pers_fn, num_clauses, cx.fcx().llfn)\n-}\n-\n-pub fn AddClause(cx: &BlockAndBuilder, landing_pad: ValueRef, clause: ValueRef) {\n-    cx.add_clause(landing_pad, clause)\n-}\n-\n-pub fn SetCleanup(cx: &BlockAndBuilder, landing_pad: ValueRef) {\n-    cx.set_cleanup(landing_pad)\n-}\n-\n-pub fn SetPersonalityFn(cx: &BlockAndBuilder, f: ValueRef) {\n-    cx.set_personality_fn(f)\n-}\n-\n-// Atomic Operations\n-pub fn AtomicCmpXchg(cx: &BlockAndBuilder, dst: ValueRef,\n-    cmp: ValueRef, src: ValueRef,\n-    order: AtomicOrdering,\n-    failure_order: AtomicOrdering,\n-    weak: llvm::Bool) -> ValueRef {\n-    cx.atomic_cmpxchg(dst, cmp, src, order, failure_order, weak)\n-}\n-pub fn AtomicRMW(cx: &BlockAndBuilder, op: AtomicRmwBinOp,\n-    dst: ValueRef, src: ValueRef,\n-    order: AtomicOrdering) -> ValueRef {\n-    cx.atomic_rmw(op, dst, src, order)\n-}\n-\n-pub fn CleanupPad(cx: &BlockAndBuilder,\n-    parent: Option<ValueRef>,\n-    args: &[ValueRef]) -> ValueRef {\n-    cx.cleanup_pad(parent, args)\n-}\n-\n-pub fn CleanupRet(cx: &BlockAndBuilder,\n-    cleanup: ValueRef,\n-    unwind: Option<BasicBlockRef>) -> ValueRef {\n-    cx.cleanup_ret(cleanup, unwind)\n-}\n-\n-pub fn CatchPad(cx: &BlockAndBuilder,\n-    parent: ValueRef,\n-    args: &[ValueRef]) -> ValueRef {\n-    cx.catch_pad(parent, args)\n-}\n-\n-pub fn CatchRet(cx: &BlockAndBuilder, pad: ValueRef, unwind: BasicBlockRef) -> ValueRef {\n-    cx.catch_ret(pad, unwind)\n-}\n-\n-pub fn CatchSwitch(cx: &BlockAndBuilder,\n-    parent: Option<ValueRef>,\n-    unwind: Option<BasicBlockRef>,\n-    num_handlers: usize) -> ValueRef {\n-    cx.catch_switch(parent, unwind, num_handlers)\n-}\n-\n-pub fn AddHandler(cx: &BlockAndBuilder, catch_switch: ValueRef, handler: BasicBlockRef) {\n-    cx.add_handler(catch_switch, handler)\n-}"}, {"sha": "1f937ba6e8af55956a19ed3d4c6b6bd1628e578e", "filename": "src/librustc_trans/builder.rs", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbuilder.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -1103,6 +1103,20 @@ impl<'a, 'tcx> Builder<'a, 'tcx> {\n         }\n     }\n \n+    pub fn add_case(s: ValueRef, on_val: ValueRef, dest: BasicBlockRef) {\n+        unsafe {\n+            if llvm::LLVMIsUndef(s) == llvm::True { return; }\n+            llvm::LLVMAddCase(s, on_val, dest)\n+        }\n+    }\n+\n+    pub fn add_incoming_to_phi(phi: ValueRef, val: ValueRef, bb: BasicBlockRef) {\n+        unsafe {\n+            if llvm::LLVMIsUndef(phi) == llvm::True { return; }\n+            llvm::LLVMAddIncoming(phi, &val, &bb, 1 as c_uint);\n+        }\n+    }\n+\n     /// Returns the ptr value that should be used for storing `val`.\n     fn check_store<'b>(&self,\n                        val: ValueRef,"}, {"sha": "6dd2c46ecec7303f2122151fc0a99f6de97e7a32", "filename": "src/librustc_trans/callee.rs", "status": "modified", "additions": 9, "deletions": 13, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcallee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcallee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcallee.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -25,12 +25,10 @@ use abi::{Abi, FnType};\n use attributes;\n use base;\n use base::*;\n-use build::*;\n use common::{\n     self, Block, BlockAndBuilder, CrateContext, FunctionContext, SharedCrateContext\n };\n use consts;\n-use debuginfo::DebugLoc;\n use declare;\n use value::Value;\n use meth;\n@@ -210,11 +208,10 @@ impl<'tcx> Callee<'tcx> {\n     /// into memory somewhere. Nonetheless we return the actual return value of the\n     /// function.\n     pub fn call<'a, 'blk>(self, bcx: BlockAndBuilder<'blk, 'tcx>,\n-                          debug_loc: DebugLoc,\n                           args: &[ValueRef],\n                           dest: Option<ValueRef>)\n                           -> (BlockAndBuilder<'blk, 'tcx>, ValueRef) {\n-        trans_call_inner(bcx, debug_loc, self, args, dest)\n+        trans_call_inner(bcx, self, args, dest)\n     }\n \n     /// Turn the callee into a function pointer.\n@@ -414,11 +411,11 @@ fn trans_fn_once_adapter_shim<'a, 'tcx>(\n     let self_scope = fcx.push_custom_cleanup_scope();\n     fcx.schedule_drop_mem(self_scope, llenv, closure_ty);\n \n-    let bcx = callee.call(bcx, DebugLoc::None, &llargs[self_idx..], dest).0;\n+    let bcx = callee.call(bcx, &llargs[self_idx..], dest).0;\n \n     let bcx = fcx.pop_and_trans_custom_cleanup_scope(bcx, self_scope);\n \n-    fcx.finish(&bcx, DebugLoc::None);\n+    fcx.finish(&bcx);\n \n     ccx.instances().borrow_mut().insert(method_instance, lloncefn);\n \n@@ -531,7 +528,7 @@ fn trans_fn_pointer_shim<'a, 'tcx>(\n     let llfnpointer = llfnpointer.unwrap_or_else(|| {\n         // the first argument (`self`) will be ptr to the fn pointer\n         if is_by_ref {\n-            Load(&bcx, llargs[self_idx])\n+            bcx.load(llargs[self_idx])\n         } else {\n             llargs[self_idx]\n         }\n@@ -543,8 +540,8 @@ fn trans_fn_pointer_shim<'a, 'tcx>(\n         data: Fn(llfnpointer),\n         ty: bare_fn_ty\n     };\n-    let bcx = callee.call(bcx, DebugLoc::None, &llargs[(self_idx + 1)..], dest).0;\n-    fcx.finish(&bcx, DebugLoc::None);\n+    let bcx = callee.call(bcx, &llargs[(self_idx + 1)..], dest).0;\n+    fcx.finish(&bcx);\n \n     ccx.fn_pointer_shims().borrow_mut().insert(bare_fn_ty_maybe_ref, llfn);\n \n@@ -654,7 +651,6 @@ fn get_fn<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n // Translating calls\n \n fn trans_call_inner<'a, 'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n-                                    debug_loc: DebugLoc,\n                                     callee: Callee<'tcx>,\n                                     args: &[ValueRef],\n                                     opt_llretslot: Option<ValueRef>)\n@@ -689,7 +685,7 @@ fn trans_call_inner<'a, 'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n     if fn_ty.ret.is_indirect() {\n         let mut llretslot = opt_llretslot.unwrap();\n         if let Some(ty) = fn_ty.ret.cast {\n-            llretslot = PointerCast(&bcx, llretslot, ty.ptr_to());\n+            llretslot = bcx.pointercast(llretslot, ty.ptr_to());\n         }\n         llargs.push(llretslot);\n     }\n@@ -700,7 +696,7 @@ fn trans_call_inner<'a, 'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n \n             let fn_ptr = meth::get_virtual_method(&bcx, args[1], idx);\n             let llty = fn_ty.llvm_type(&bcx.ccx()).ptr_to();\n-            callee = Fn(PointerCast(&bcx, fn_ptr, llty));\n+            callee = Fn(bcx.pointercast(fn_ptr, llty));\n             llargs.extend_from_slice(&args[2..]);\n         }\n         _ => llargs.extend_from_slice(args)\n@@ -711,7 +707,7 @@ fn trans_call_inner<'a, 'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n         _ => bug!(\"expected fn pointer callee, found {:?}\", callee)\n     };\n \n-    let (llret, bcx) = base::invoke(bcx, llfn, &llargs, debug_loc);\n+    let (llret, bcx) = base::invoke(bcx, llfn, &llargs);\n     fn_ty.apply_attrs_callsite(llret);\n \n     // If the function we just called does not use an outpointer,"}, {"sha": "651687286aecaad52f98c17c860ffb4efb2b7b38", "filename": "src/librustc_trans/cleanup.rs", "status": "modified", "additions": 16, "deletions": 20, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcleanup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcleanup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcleanup.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -118,7 +118,6 @@ pub use self::EarlyExitLabel::*;\n \n use llvm::{BasicBlockRef, ValueRef};\n use base;\n-use build;\n use common;\n use common::{BlockAndBuilder, FunctionContext, LandingPad};\n use debuginfo::{DebugLoc};\n@@ -344,7 +343,7 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n \n         let mut bcx = bcx;\n         for cleanup in scope.cleanups.iter().rev() {\n-            bcx = cleanup.trans(bcx, scope.debug_loc);\n+            bcx = cleanup.trans(bcx);\n         }\n         bcx\n     }\n@@ -422,13 +421,13 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                             UnwindKind::LandingPad => {\n                                 let addr = self.landingpad_alloca.get()\n                                                .unwrap();\n-                                let lp = build::Load(&bcx, addr);\n+                                let lp = bcx.load(addr);\n                                 base::call_lifetime_end(&bcx, addr);\n                                 base::trans_unwind_resume(&bcx, lp);\n                             }\n                             UnwindKind::CleanupPad(_) => {\n-                                let pad = build::CleanupPad(&bcx, None, &[]);\n-                                build::CleanupRet(&bcx, pad, None);\n+                                let pad = bcx.cleanup_pad(None, &[]);\n+                                bcx.cleanup_ret(pad, None);\n                             }\n                         }\n                         prev_llbb = bcx.llbb();\n@@ -488,7 +487,7 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                 let mut bcx_out = bcx_in;\n                 let len = scope.cleanups.len();\n                 for cleanup in scope.cleanups.iter().rev().take(len - skip) {\n-                    bcx_out = cleanup.trans(bcx_out, scope.debug_loc);\n+                    bcx_out = cleanup.trans(bcx_out);\n                 }\n                 skip = 0;\n                 exit_label.branch(&bcx_out, prev_llbb);\n@@ -540,8 +539,8 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n             // creation of the landingpad instruction). We then create a\n             // cleanuppad instruction which has no filters to run cleanup on all\n             // exceptions.\n-            build::SetPersonalityFn(&pad_bcx, llpersonality);\n-            let llretval = build::CleanupPad(&pad_bcx, None, &[]);\n+            pad_bcx.set_personality_fn(llpersonality);\n+            let llretval = pad_bcx.cleanup_pad(None, &[]);\n             UnwindKind::CleanupPad(llretval)\n         } else {\n             // The landing pad return type (the type being propagated). Not sure\n@@ -552,10 +551,10 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                                         false);\n \n             // The only landing pad clause will be 'cleanup'\n-            let llretval = build::LandingPad(&pad_bcx, llretty, llpersonality, 1);\n+            let llretval = pad_bcx.landing_pad(llretty, llpersonality, 1, pad_bcx.fcx().llfn);\n \n             // The landing pad block is a cleanup\n-            build::SetCleanup(&pad_bcx, llretval);\n+            pad_bcx.set_cleanup(llretval);\n \n             let addr = match self.landingpad_alloca.get() {\n                 Some(addr) => addr,\n@@ -567,7 +566,7 @@ impl<'blk, 'tcx> FunctionContext<'blk, 'tcx> {\n                     addr\n                 }\n             };\n-            build::Store(&pad_bcx, llretval, addr);\n+            pad_bcx.store(llretval, addr);\n             UnwindKind::LandingPad\n         };\n \n@@ -629,9 +628,9 @@ impl EarlyExitLabel {\n     /// the `cleanupret` instruction instead of the `br` instruction.\n     fn branch(&self, from_bcx: &BlockAndBuilder, to_llbb: BasicBlockRef) {\n         if let UnwindExit(UnwindKind::CleanupPad(pad)) = *self {\n-            build::CleanupRet(from_bcx, pad, Some(to_llbb));\n+            from_bcx.cleanup_ret(pad, Some(to_llbb));\n         } else {\n-            build::Br(from_bcx, to_llbb, DebugLoc::None);\n+            from_bcx.br(to_llbb);\n         }\n     }\n \n@@ -649,7 +648,7 @@ impl EarlyExitLabel {\n     fn start(&self, bcx: &BlockAndBuilder) -> EarlyExitLabel {\n         match *self {\n             UnwindExit(UnwindKind::CleanupPad(..)) => {\n-                let pad = build::CleanupPad(bcx, None, &[]);\n+                let pad = bcx.cleanup_pad(None, &[]);\n                 bcx.set_lpad_ref(Some(bcx.fcx().lpad_arena.alloc(LandingPad::msvc(pad))));\n                 UnwindExit(UnwindKind::CleanupPad(pad))\n             }\n@@ -683,20 +682,17 @@ pub struct DropValue<'tcx> {\n }\n \n impl<'tcx> DropValue<'tcx> {\n-    fn trans<'blk>(&self,\n-                   bcx: BlockAndBuilder<'blk, 'tcx>,\n-                   debug_loc: DebugLoc)\n-                   -> BlockAndBuilder<'blk, 'tcx> {\n+    fn trans<'blk>(&self, bcx: BlockAndBuilder<'blk, 'tcx>) -> BlockAndBuilder<'blk, 'tcx> {\n         let skip_dtor = self.skip_dtor;\n         let _icx = if skip_dtor {\n             base::push_ctxt(\"<DropValue as Cleanup>::trans skip_dtor=true\")\n         } else {\n             base::push_ctxt(\"<DropValue as Cleanup>::trans skip_dtor=false\")\n         };\n         if self.is_immediate {\n-            glue::drop_ty_immediate(bcx, self.val, self.ty, debug_loc, self.skip_dtor)\n+            glue::drop_ty_immediate(bcx, self.val, self.ty, self.skip_dtor)\n         } else {\n-            glue::drop_ty_core(bcx, self.val, self.ty, debug_loc, self.skip_dtor)\n+            glue::drop_ty_core(bcx, self.val, self.ty, self.skip_dtor)\n         }\n     }\n }"}, {"sha": "32f437fea522021c5842ca3e8fa1e82cfc19d85d", "filename": "src/librustc_trans/common.rs", "status": "modified", "additions": 17, "deletions": 15, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcommon.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -26,12 +26,11 @@ use middle::lang_items::LangItem;\n use rustc::ty::subst::Substs;\n use abi::{Abi, FnType};\n use base;\n-use build;\n use builder::Builder;\n use callee::Callee;\n use cleanup;\n use consts;\n-use debuginfo::{self, DebugLoc};\n+use debuginfo;\n use declare;\n use machine;\n use monomorphize;\n@@ -434,6 +433,12 @@ impl<'a, 'tcx> FunctionContext<'a, 'tcx> {\n         unwresume.set(Some(llfn));\n         Callee::ptr(llfn, ty)\n     }\n+\n+    pub fn alloca(&self, ty: Type, name: &str) -> ValueRef {\n+        let b = self.ccx.builder();\n+        b.position_before(self.alloca_insert_pt.get().unwrap());\n+        b.alloca(ty, name)\n+    }\n }\n \n // Basic block context.  We create a block context for each basic block\n@@ -998,35 +1003,32 @@ pub fn langcall(tcx: TyCtxt,\n \n pub fn build_unchecked_lshift<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                           lhs: ValueRef,\n-                                          rhs: ValueRef,\n-                                          binop_debug_loc: DebugLoc) -> ValueRef {\n+                                          rhs: ValueRef) -> ValueRef {\n     let rhs = base::cast_shift_expr_rhs(bcx, hir::BinOp_::BiShl, lhs, rhs);\n     // #1877, #10183: Ensure that input is always valid\n-    let rhs = shift_mask_rhs(bcx, rhs, binop_debug_loc);\n-    build::Shl(bcx, lhs, rhs, binop_debug_loc)\n+    let rhs = shift_mask_rhs(bcx, rhs);\n+    bcx.shl(lhs, rhs)\n }\n \n pub fn build_unchecked_rshift<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                           lhs_t: Ty<'tcx>,\n                                           lhs: ValueRef,\n-                                          rhs: ValueRef,\n-                                          binop_debug_loc: DebugLoc) -> ValueRef {\n+                                          rhs: ValueRef) -> ValueRef {\n     let rhs = base::cast_shift_expr_rhs(bcx, hir::BinOp_::BiShr, lhs, rhs);\n     // #1877, #10183: Ensure that input is always valid\n-    let rhs = shift_mask_rhs(bcx, rhs, binop_debug_loc);\n+    let rhs = shift_mask_rhs(bcx, rhs);\n     let is_signed = lhs_t.is_signed();\n     if is_signed {\n-        build::AShr(bcx, lhs, rhs, binop_debug_loc)\n+        bcx.ashr(lhs, rhs)\n     } else {\n-        build::LShr(bcx, lhs, rhs, binop_debug_loc)\n+        bcx.lshr(lhs, rhs)\n     }\n }\n \n fn shift_mask_rhs<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n-                              rhs: ValueRef,\n-                              debug_loc: DebugLoc) -> ValueRef {\n+                              rhs: ValueRef) -> ValueRef {\n     let rhs_llty = val_ty(rhs);\n-    build::And(bcx, rhs, shift_mask_val(bcx, rhs_llty, rhs_llty, false), debug_loc)\n+    bcx.and(rhs, shift_mask_val(bcx, rhs_llty, rhs_llty, false))\n }\n \n pub fn shift_mask_val<'blk, 'tcx>(\n@@ -1048,7 +1050,7 @@ pub fn shift_mask_val<'blk, 'tcx>(\n         },\n         TypeKind::Vector => {\n             let mask = shift_mask_val(bcx, llty.element_type(), mask_llty.element_type(), invert);\n-            build::VectorSplat(bcx, mask_llty.vector_length(), mask)\n+            bcx.vector_splat(mask_llty.vector_length(), mask)\n         },\n         _ => bug!(\"shift_mask_val: expected Integer or Vector, found {:?}\", kind),\n     }"}, {"sha": "10c38af8a7396ea81b6afc453382cdcd2b2db381", "filename": "src/librustc_trans/glue.rs", "status": "modified", "additions": 45, "deletions": 59, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fglue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fglue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fglue.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -22,10 +22,9 @@ use rustc::traits;\n use rustc::ty::{self, AdtKind, Ty, TyCtxt, TypeFoldable};\n use adt;\n use base::*;\n-use build::*;\n use callee::{Callee};\n+use builder::Builder;\n use common::*;\n-use debuginfo::DebugLoc;\n use machine::*;\n use monomorphize;\n use trans_item::TransItem;\n@@ -41,35 +40,28 @@ use syntax_pos::DUMMY_SP;\n pub fn trans_exchange_free_dyn<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                                            v: ValueRef,\n                                            size: ValueRef,\n-                                           align: ValueRef,\n-                                           debug_loc: DebugLoc)\n+                                           align: ValueRef)\n                                            -> BlockAndBuilder<'blk, 'tcx> {\n     let _icx = push_ctxt(\"trans_exchange_free\");\n \n     let def_id = langcall(bcx.tcx(), None, \"\", ExchangeFreeFnLangItem);\n-    let args = [PointerCast(&bcx, v, Type::i8p(bcx.ccx())), size, align];\n+    let args = [bcx.pointercast(v, Type::i8p(bcx.ccx())), size, align];\n     Callee::def(bcx.ccx(), def_id, bcx.tcx().intern_substs(&[]))\n-        .call(bcx, debug_loc, &args, None).0\n+        .call(bcx, &args, None).0\n }\n \n pub fn trans_exchange_free<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n                                        v: ValueRef,\n                                        size: u64,\n-                                       align: u32,\n-                                       debug_loc: DebugLoc)\n+                                       align: u32)\n                                        -> BlockAndBuilder<'blk, 'tcx> {\n     let ccx = cx.ccx();\n-    trans_exchange_free_dyn(cx,\n-                            v,\n-                            C_uint(ccx, size),\n-                            C_uint(ccx, align),\n-                            debug_loc)\n+    trans_exchange_free_dyn(cx, v, C_uint(ccx, size), C_uint(ccx, align))\n }\n \n pub fn trans_exchange_free_ty<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                                           ptr: ValueRef,\n-                                          content_ty: Ty<'tcx>,\n-                                          debug_loc: DebugLoc)\n+                                          content_ty: Ty<'tcx>)\n                                           -> BlockAndBuilder<'blk, 'tcx> {\n     assert!(type_is_sized(bcx.ccx().tcx(), content_ty));\n     let sizing_type = sizing_type_of(bcx.ccx(), content_ty);\n@@ -78,7 +70,7 @@ pub fn trans_exchange_free_ty<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n     // `Box<ZeroSizeType>` does not allocate.\n     if content_size != 0 {\n         let content_align = align_of(bcx.ccx(), content_ty);\n-        trans_exchange_free(bcx, ptr, content_size, content_align, debug_loc)\n+        trans_exchange_free(bcx, ptr, content_size, content_align)\n     } else {\n         bcx\n     }\n@@ -132,15 +124,13 @@ pub fn get_drop_glue_type<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n pub fn drop_ty<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                            v: ValueRef,\n-                           t: Ty<'tcx>,\n-                           debug_loc: DebugLoc) -> BlockAndBuilder<'blk, 'tcx> {\n-    drop_ty_core(bcx, v, t, debug_loc, false)\n+                           t: Ty<'tcx>) -> BlockAndBuilder<'blk, 'tcx> {\n+    drop_ty_core(bcx, v, t, false)\n }\n \n pub fn drop_ty_core<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                                 v: ValueRef,\n                                 t: Ty<'tcx>,\n-                                debug_loc: DebugLoc,\n                                 skip_dtor: bool)\n                                 -> BlockAndBuilder<'blk, 'tcx> {\n     // NB: v is an *alias* of type t here, not a direct value.\n@@ -156,28 +146,27 @@ pub fn drop_ty_core<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n         let glue = get_drop_glue_core(ccx, g);\n         let glue_type = get_drop_glue_type(ccx.tcx(), t);\n         let ptr = if glue_type != t {\n-            PointerCast(&bcx, v, type_of(ccx, glue_type).ptr_to())\n+            bcx.pointercast(v, type_of(ccx, glue_type).ptr_to())\n         } else {\n             v\n         };\n \n         // No drop-hint ==> call standard drop glue\n-        Call(&bcx, glue, &[ptr], debug_loc);\n+        bcx.call(glue, &[ptr], bcx.lpad().and_then(|b| b.bundle()));\n     }\n     bcx\n }\n \n pub fn drop_ty_immediate<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n                                      v: ValueRef,\n                                      t: Ty<'tcx>,\n-                                     debug_loc: DebugLoc,\n                                      skip_dtor: bool)\n                                      -> BlockAndBuilder<'blk, 'tcx> {\n     let _icx = push_ctxt(\"drop_ty_immediate\");\n     let vp = alloc_ty(&bcx, t, \"\");\n     call_lifetime_start(&bcx, vp);\n     store_ty(&bcx, v, vp, t);\n-    let bcx = drop_ty_core(bcx, vp, t, debug_loc, skip_dtor);\n+    let bcx = drop_ty_core(bcx, vp, t, skip_dtor);\n     call_lifetime_end(&bcx, vp);\n     bcx\n }\n@@ -249,7 +238,7 @@ pub fn implement_drop_glue<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n     // type, so we don't need to explicitly cast the function parameter.\n \n     let bcx = make_drop_glue(bcx, get_param(llfn, 0), g);\n-    fcx.finish(&bcx, DebugLoc::None);\n+    fcx.finish(&bcx);\n }\n \n fn trans_custom_dtor<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n@@ -285,8 +274,8 @@ fn trans_custom_dtor<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n     } else {\n         // FIXME(#36457) -- we should pass unsized values to drop glue as two arguments\n         unsized_args = [\n-            Load(&bcx, get_dataptr(&bcx, v0)),\n-            Load(&bcx, get_meta(&bcx, v0))\n+            bcx.load(get_dataptr(&bcx, v0)),\n+            bcx.load(get_meta(&bcx, v0))\n         ];\n         &unsized_args\n     };\n@@ -301,7 +290,7 @@ fn trans_custom_dtor<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n     };\n     let dtor_did = def.destructor().unwrap();\n     bcx = Callee::def(bcx.ccx(), dtor_did, vtbl.substs)\n-        .call(bcx, DebugLoc::None, args, None).0;\n+        .call(bcx, args, None).0;\n \n     bcx.fcx().pop_and_trans_custom_cleanup_scope(bcx, contents_scope)\n }\n@@ -436,29 +425,27 @@ fn make_drop_glue<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n             assert!(!skip_dtor);\n             if !type_is_sized(bcx.tcx(), content_ty) {\n                 let llval = get_dataptr(&bcx, v0);\n-                let llbox = Load(&bcx, llval);\n-                let bcx = drop_ty(bcx, v0, content_ty, DebugLoc::None);\n+                let llbox = bcx.load(llval);\n+                let bcx = drop_ty(bcx, v0, content_ty);\n                 // FIXME(#36457) -- we should pass unsized values to drop glue as two arguments\n                 let info = get_meta(&bcx, v0);\n-                let info = Load(&bcx, info);\n+                let info = bcx.load(info);\n                 let (llsize, llalign) = size_and_align_of_dst(&bcx, content_ty, info);\n \n                 // `Box<ZeroSizeType>` does not allocate.\n-                let needs_free = ICmp(\n-                    &bcx,\n+                let needs_free = bcx.icmp(\n                     llvm::IntNE,\n                     llsize,\n                     C_uint(bcx.ccx(), 0u64),\n-                    DebugLoc::None\n                 );\n                 with_cond(bcx, needs_free, |bcx| {\n-                    trans_exchange_free_dyn(bcx, llbox, llsize, llalign, DebugLoc::None)\n+                    trans_exchange_free_dyn(bcx, llbox, llsize, llalign)\n                 })\n             } else {\n                 let llval = v0;\n-                let llbox = Load(&bcx, llval);\n-                let bcx = drop_ty(bcx, llbox, content_ty, DebugLoc::None);\n-                trans_exchange_free_ty(bcx, llbox, content_ty, DebugLoc::None)\n+                let llbox = bcx.load(llval);\n+                let bcx = drop_ty(bcx, llbox, content_ty);\n+                trans_exchange_free_ty(bcx, llbox, content_ty)\n             }\n         }\n         ty::TyDynamic(..) => {\n@@ -468,12 +455,11 @@ fn make_drop_glue<'blk, 'tcx>(bcx: BlockAndBuilder<'blk, 'tcx>,\n             // FIXME(#36457) -- we should pass unsized values to drop glue as two arguments\n             assert!(!skip_dtor);\n             let data_ptr = get_dataptr(&bcx, v0);\n-            let vtable_ptr = Load(&bcx, get_meta(&bcx, v0));\n-            let dtor = Load(&bcx, vtable_ptr);\n-            Call(&bcx,\n-                 dtor,\n-                 &[PointerCast(&bcx, Load(&bcx, data_ptr), Type::i8p(bcx.ccx()))],\n-                 DebugLoc::None);\n+            let vtable_ptr = bcx.load(get_meta(&bcx, v0));\n+            let dtor = bcx.load(vtable_ptr);\n+            bcx.call(dtor,\n+                &[bcx.pointercast(bcx.load(data_ptr), Type::i8p(bcx.ccx()))],\n+                bcx.lpad().and_then(|b| b.bundle()));\n             bcx\n         }\n         ty::TyAdt(def, ..) if def.dtor_kind().is_present() && !skip_dtor => {\n@@ -512,7 +498,7 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n         for (i, field) in variant.fields.iter().enumerate() {\n             let arg = monomorphize::field_ty(tcx, substs, field);\n             let field_ptr = adt::trans_field_ptr(&cx, t, av, Disr::from(variant.disr_val), i);\n-            cx = drop_ty(cx, field_ptr, arg, DebugLoc::None);\n+            cx = drop_ty(cx, field_ptr, arg);\n         }\n         return cx;\n     }\n@@ -521,8 +507,8 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n         adt::MaybeSizedValue::sized(av)\n     } else {\n         // FIXME(#36457) -- we should pass unsized values as two arguments\n-        let data = Load(&cx, get_dataptr(&cx, av));\n-        let info = Load(&cx, get_meta(&cx, av));\n+        let data = cx.load(get_dataptr(&cx, av));\n+        let info = cx.load(get_meta(&cx, av));\n         adt::MaybeSizedValue::unsized_(data, info)\n     };\n \n@@ -531,25 +517,25 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n         ty::TyClosure(def_id, substs) => {\n             for (i, upvar_ty) in substs.upvar_tys(def_id, cx.tcx()).enumerate() {\n                 let llupvar = adt::trans_field_ptr(&cx, t, value, Disr(0), i);\n-                cx = drop_ty(cx, llupvar, upvar_ty, DebugLoc::None);\n+                cx = drop_ty(cx, llupvar, upvar_ty);\n             }\n         }\n         ty::TyArray(_, n) => {\n             let base = get_dataptr(&cx, value.value);\n             let len = C_uint(cx.ccx(), n);\n             let unit_ty = t.sequence_element_type(cx.tcx());\n             cx = tvec::slice_for_each(cx, base, unit_ty, len,\n-                |bb, vv| drop_ty(bb, vv, unit_ty, DebugLoc::None));\n+                |bb, vv| drop_ty(bb, vv, unit_ty));\n         }\n         ty::TySlice(_) | ty::TyStr => {\n             let unit_ty = t.sequence_element_type(cx.tcx());\n             cx = tvec::slice_for_each(cx, value.value, unit_ty, value.meta,\n-                |bb, vv| drop_ty(bb, vv, unit_ty, DebugLoc::None));\n+                |bb, vv| drop_ty(bb, vv, unit_ty));\n         }\n         ty::TyTuple(ref args) => {\n             for (i, arg) in args.iter().enumerate() {\n                 let llfld_a = adt::trans_field_ptr(&cx, t, value, Disr(0), i);\n-                cx = drop_ty(cx, llfld_a, *arg, DebugLoc::None);\n+                cx = drop_ty(cx, llfld_a, *arg);\n             }\n         }\n         ty::TyAdt(adt, substs) => match adt.adt_kind() {\n@@ -563,11 +549,11 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n                     } else {\n                         // FIXME(#36457) -- we should pass unsized values as two arguments\n                         let scratch = alloc_ty(&cx, field_ty, \"__fat_ptr_iter\");\n-                        Store(&cx, llfld_a, get_dataptr(&cx, scratch));\n-                        Store(&cx, value.meta, get_meta(&cx, scratch));\n+                        cx.store(llfld_a, get_dataptr(&cx, scratch));\n+                        cx.store(value.meta, get_meta(&cx, scratch));\n                         scratch\n                     };\n-                    cx = drop_ty(cx, val, field_ty, DebugLoc::None);\n+                    cx = drop_ty(cx, val, field_ty);\n                 }\n             }\n             AdtKind::Union => {\n@@ -591,7 +577,7 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n                     }\n                     (adt::BranchKind::Switch, Some(lldiscrim_a)) => {\n                         let tcx = cx.tcx();\n-                        cx = drop_ty(cx, lldiscrim_a, tcx.types.isize, DebugLoc::None);\n+                        cx = drop_ty(cx, lldiscrim_a, tcx.types.isize);\n \n                         // Create a fall-through basic block for the \"else\" case of\n                         // the switch instruction we're about to generate. Note that\n@@ -607,18 +593,18 @@ fn drop_structural_ty<'blk, 'tcx>(cx: BlockAndBuilder<'blk, 'tcx>,\n                         // call this for an already-valid enum in which case the `ret\n                         // void` will never be hit.\n                         let ret_void_cx = fcx.new_block(\"enum-iter-ret-void\").build();\n-                        RetVoid(&ret_void_cx, DebugLoc::None);\n-                        let llswitch = Switch(&cx, lldiscrim_a, ret_void_cx.llbb(), n_variants);\n+                        ret_void_cx.ret_void();\n+                        let llswitch = cx.switch(lldiscrim_a, ret_void_cx.llbb(), n_variants);\n                         let next_cx = fcx.new_block(\"enum-iter-next\").build();\n \n                         for variant in &adt.variants {\n                             let variant_cx_name = format!(\"enum-iter-variant-{}\",\n                                 &variant.disr_val.to_string());\n                             let variant_cx = fcx.new_block(&variant_cx_name).build();\n                             let case_val = adt::trans_case(&cx, t, Disr::from(variant.disr_val));\n-                            AddCase(llswitch, case_val, variant_cx.llbb());\n+                            Builder::add_case(llswitch, case_val, variant_cx.llbb());\n                             let variant_cx = iter_variant(variant_cx, t, value, variant, substs);\n-                            Br(&variant_cx, next_cx.llbb(), DebugLoc::None);\n+                            variant_cx.br(next_cx.llbb());\n                         }\n                         cx = next_cx;\n                     }"}, {"sha": "90f8c64a2cf8b1fccef56337637940e0b35b0373", "filename": "src/librustc_trans/intrinsic.rs", "status": "modified", "additions": 145, "deletions": 166, "changes": 311, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fintrinsic.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -18,7 +18,6 @@ use llvm::{ValueRef};\n use abi::{Abi, FnType};\n use adt;\n use base::*;\n-use build::*;\n use common::*;\n use debuginfo::DebugLoc;\n use declare;\n@@ -120,7 +119,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     // These are the only intrinsic functions that diverge.\n     if name == \"abort\" {\n         let llfn = ccx.get_intrinsic(&(\"llvm.trap\"));\n-        Call(bcx, llfn, &[], call_debug_location);\n+        bcx.call(llfn, &[], bcx.lpad().and_then(|b| b.bundle()));\n         return;\n     } else if name == \"unreachable\" {\n         // FIXME: do nothing?\n@@ -132,23 +131,23 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     let simple = get_simple_intrinsic(ccx, name);\n     let llval = match (simple, name) {\n         (Some(llfn), _) => {\n-            Call(bcx, llfn, &llargs, call_debug_location)\n+            bcx.call(llfn, &llargs, bcx.lpad().and_then(|b| b.bundle()))\n         }\n         (_, \"likely\") => {\n             let expect = ccx.get_intrinsic(&(\"llvm.expect.i1\"));\n-            Call(bcx, expect, &[llargs[0], C_bool(ccx, true)], call_debug_location)\n+            bcx.call(expect, &[llargs[0], C_bool(ccx, true)], bcx.lpad().and_then(|b| b.bundle()))\n         }\n         (_, \"unlikely\") => {\n             let expect = ccx.get_intrinsic(&(\"llvm.expect.i1\"));\n-            Call(bcx, expect, &[llargs[0], C_bool(ccx, false)], call_debug_location)\n+            bcx.call(expect, &[llargs[0], C_bool(ccx, false)], bcx.lpad().and_then(|b| b.bundle()))\n         }\n         (_, \"try\") => {\n-            try_intrinsic(bcx, llargs[0], llargs[1], llargs[2], llresult, call_debug_location);\n+            try_intrinsic(bcx, llargs[0], llargs[1], llargs[2], llresult);\n             C_nil(ccx)\n         }\n         (_, \"breakpoint\") => {\n             let llfn = ccx.get_intrinsic(&(\"llvm.debugtrap\"));\n-            Call(bcx, llfn, &[], call_debug_location)\n+            bcx.call(llfn, &[], bcx.lpad().and_then(|b| b.bundle()))\n         }\n         (_, \"size_of\") => {\n             let tp_ty = substs.type_at(0);\n@@ -213,12 +212,12 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n         (_, \"offset\") => {\n             let ptr = llargs[0];\n             let offset = llargs[1];\n-            InBoundsGEP(bcx, ptr, &[offset])\n+            bcx.inbounds_gep(ptr, &[offset])\n         }\n         (_, \"arith_offset\") => {\n             let ptr = llargs[0];\n             let offset = llargs[1];\n-            GEP(bcx, ptr, &[offset])\n+            bcx.gep(ptr, &[offset])\n         }\n \n         (_, \"copy_nonoverlapping\") => {\n@@ -228,8 +227,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                            substs.type_at(0),\n                            llargs[1],\n                            llargs[0],\n-                           llargs[2],\n-                           call_debug_location)\n+                           llargs[2])\n         }\n         (_, \"copy\") => {\n             copy_intrinsic(bcx,\n@@ -238,17 +236,15 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                            substs.type_at(0),\n                            llargs[1],\n                            llargs[0],\n-                           llargs[2],\n-                           call_debug_location)\n+                           llargs[2])\n         }\n         (_, \"write_bytes\") => {\n             memset_intrinsic(bcx,\n                              false,\n                              substs.type_at(0),\n                              llargs[0],\n                              llargs[1],\n-                             llargs[2],\n-                             call_debug_location)\n+                             llargs[2])\n         }\n \n         (_, \"volatile_copy_nonoverlapping_memory\") => {\n@@ -258,8 +254,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                            substs.type_at(0),\n                            llargs[0],\n                            llargs[1],\n-                           llargs[2],\n-                           call_debug_location)\n+                           llargs[2])\n         }\n         (_, \"volatile_copy_memory\") => {\n             copy_intrinsic(bcx,\n@@ -268,25 +263,23 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                            substs.type_at(0),\n                            llargs[0],\n                            llargs[1],\n-                           llargs[2],\n-                           call_debug_location)\n+                           llargs[2])\n         }\n         (_, \"volatile_set_memory\") => {\n             memset_intrinsic(bcx,\n                              true,\n                              substs.type_at(0),\n                              llargs[0],\n                              llargs[1],\n-                             llargs[2],\n-                             call_debug_location)\n+                             llargs[2])\n         }\n         (_, \"volatile_load\") => {\n             let tp_ty = substs.type_at(0);\n             let mut ptr = llargs[0];\n             if let Some(ty) = fn_ty.ret.cast {\n-                ptr = PointerCast(bcx, ptr, ty.ptr_to());\n+                ptr = bcx.pointercast(ptr, ty.ptr_to());\n             }\n-            let load = VolatileLoad(bcx, ptr);\n+            let load = bcx.volatile_load(ptr);\n             unsafe {\n                 llvm::LLVMSetAlignment(load, type_of::align_of(ccx, tp_ty));\n             }\n@@ -295,16 +288,16 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n         (_, \"volatile_store\") => {\n             let tp_ty = substs.type_at(0);\n             if type_is_fat_ptr(bcx.tcx(), tp_ty) {\n-                VolatileStore(bcx, llargs[1], get_dataptr(bcx, llargs[0]));\n-                VolatileStore(bcx, llargs[2], get_meta(bcx, llargs[0]));\n+                bcx.volatile_store(llargs[1], get_dataptr(bcx, llargs[0]));\n+                bcx.volatile_store(llargs[2], get_meta(bcx, llargs[0]));\n             } else {\n                 let val = if fn_ty.args[1].is_indirect() {\n-                    Load(bcx, llargs[1])\n+                    bcx.load(llargs[1])\n                 } else {\n                     from_immediate(bcx, llargs[1])\n                 };\n-                let ptr = PointerCast(bcx, llargs[0], val_ty(val).ptr_to());\n-                let store = VolatileStore(bcx, val, ptr);\n+                let ptr = bcx.pointercast(llargs[0], val_ty(val).ptr_to());\n+                let store = bcx.volatile_store(val, ptr);\n                 unsafe {\n                     llvm::LLVMSetAlignment(store, type_of::align_of(ccx, tp_ty));\n                 }\n@@ -321,40 +314,39 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                 Some((width, signed)) =>\n                     match name {\n                         \"ctlz\" => count_zeros_intrinsic(bcx, &format!(\"llvm.ctlz.i{}\", width),\n-                                                        llargs[0], call_debug_location),\n+                                                        llargs[0]),\n                         \"cttz\" => count_zeros_intrinsic(bcx, &format!(\"llvm.cttz.i{}\", width),\n-                                                        llargs[0], call_debug_location),\n-                        \"ctpop\" => Call(bcx, ccx.get_intrinsic(&format!(\"llvm.ctpop.i{}\", width)),\n-                                        &llargs, call_debug_location),\n+                                                        llargs[0]),\n+                        \"ctpop\" => bcx.call(ccx.get_intrinsic(&format!(\"llvm.ctpop.i{}\", width)),\n+                                        &llargs, bcx.lpad().and_then(|b| b.bundle())),\n                         \"bswap\" => {\n                             if width == 8 {\n                                 llargs[0] // byte swap a u8/i8 is just a no-op\n                             } else {\n-                                Call(bcx, ccx.get_intrinsic(&format!(\"llvm.bswap.i{}\", width)),\n-                                        &llargs, call_debug_location)\n+                                bcx.call(ccx.get_intrinsic(&format!(\"llvm.bswap.i{}\", width)),\n+                                        &llargs, bcx.lpad().and_then(|b| b.bundle()))\n                             }\n                         }\n                         \"add_with_overflow\" | \"sub_with_overflow\" | \"mul_with_overflow\" => {\n                             let intrinsic = format!(\"llvm.{}{}.with.overflow.i{}\",\n                                                     if signed { 's' } else { 'u' },\n                                                     &name[..3], width);\n-                            with_overflow_intrinsic(bcx, &intrinsic, llargs[0], llargs[1], llresult,\n-                                                    call_debug_location)\n+                            with_overflow_intrinsic(bcx, &intrinsic, llargs[0], llargs[1], llresult)\n                         },\n-                        \"overflowing_add\" => Add(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"overflowing_sub\" => Sub(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"overflowing_mul\" => Mul(bcx, llargs[0], llargs[1], call_debug_location),\n+                        \"overflowing_add\" => bcx.add(llargs[0], llargs[1]),\n+                        \"overflowing_sub\" => bcx.sub(llargs[0], llargs[1]),\n+                        \"overflowing_mul\" => bcx.mul(llargs[0], llargs[1]),\n                         \"unchecked_div\" =>\n                             if signed {\n-                                SDiv(bcx, llargs[0], llargs[1], call_debug_location)\n+                                bcx.sdiv(llargs[0], llargs[1])\n                             } else {\n-                                UDiv(bcx, llargs[0], llargs[1], call_debug_location)\n+                                bcx.udiv(llargs[0], llargs[1])\n                             },\n                         \"unchecked_rem\" =>\n                             if signed {\n-                                SRem(bcx, llargs[0], llargs[1], call_debug_location)\n+                                bcx.srem(llargs[0], llargs[1])\n                             } else {\n-                                URem(bcx, llargs[0], llargs[1], call_debug_location)\n+                                bcx.urem(llargs[0], llargs[1])\n                             },\n                         _ => bug!(),\n                     },\n@@ -374,11 +366,11 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n             match float_type_width(sty) {\n                 Some(_width) =>\n                     match name {\n-                        \"fadd_fast\" => FAddFast(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"fsub_fast\" => FSubFast(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"fmul_fast\" => FMulFast(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"fdiv_fast\" => FDivFast(bcx, llargs[0], llargs[1], call_debug_location),\n-                        \"frem_fast\" => FRemFast(bcx, llargs[0], llargs[1], call_debug_location),\n+                        \"fadd_fast\" => bcx.fadd_fast(llargs[0], llargs[1]),\n+                        \"fsub_fast\" => bcx.fsub_fast(llargs[0], llargs[1]),\n+                        \"fmul_fast\" => bcx.fmul_fast(llargs[0], llargs[1]),\n+                        \"fdiv_fast\" => bcx.fdiv_fast(llargs[0], llargs[1]),\n+                        \"frem_fast\" => bcx.frem_fast(llargs[0], llargs[1]),\n                         _ => bug!(),\n                     },\n                 None => {\n@@ -407,7 +399,6 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                    callee_ty,\n                                    &llargs,\n                                    ret_ty, llret_ty,\n-                                   call_debug_location,\n                                    span)\n         }\n         // This requires that atomic intrinsics follow a specific naming pattern:\n@@ -447,12 +438,12 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                     let sty = &substs.type_at(0).sty;\n                     if int_type_width_signed(sty, ccx).is_some() {\n                         let weak = if split[1] == \"cxchgweak\" { llvm::True } else { llvm::False };\n-                        let val = AtomicCmpXchg(bcx, llargs[0], llargs[1], llargs[2],\n-                                                order, failorder, weak);\n-                        let result = ExtractValue(bcx, val, 0);\n-                        let success = ZExt(bcx, ExtractValue(bcx, val, 1), Type::bool(bcx.ccx()));\n-                        Store(bcx, result, StructGEP(bcx, llresult, 0));\n-                        Store(bcx, success, StructGEP(bcx, llresult, 1));\n+                        let val = bcx.atomic_cmpxchg(llargs[0], llargs[1], llargs[2], order,\n+                            failorder, weak);\n+                        let result = bcx.extract_value(val, 0);\n+                        let success = bcx.zext(bcx.extract_value(val, 1), Type::bool(bcx.ccx()));\n+                        bcx.store(result, bcx.struct_gep(llresult, 0));\n+                        bcx.store(success, bcx.struct_gep(llresult, 1));\n                     } else {\n                         span_invalid_monomorphization_error(\n                             tcx.sess, span,\n@@ -465,7 +456,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                 \"load\" => {\n                     let sty = &substs.type_at(0).sty;\n                     if int_type_width_signed(sty, ccx).is_some() {\n-                        AtomicLoad(bcx, llargs[0], order)\n+                        bcx.atomic_load(llargs[0], order)\n                     } else {\n                         span_invalid_monomorphization_error(\n                             tcx.sess, span,\n@@ -478,7 +469,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                 \"store\" => {\n                     let sty = &substs.type_at(0).sty;\n                     if int_type_width_signed(sty, ccx).is_some() {\n-                        AtomicStore(bcx, llargs[1], llargs[0], order);\n+                        bcx.atomic_store(llargs[1], llargs[0], order);\n                     } else {\n                         span_invalid_monomorphization_error(\n                             tcx.sess, span,\n@@ -489,12 +480,12 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                 }\n \n                 \"fence\" => {\n-                    AtomicFence(bcx, order, llvm::SynchronizationScope::CrossThread);\n+                    bcx.atomic_fence(order, llvm::SynchronizationScope::CrossThread);\n                     C_nil(ccx)\n                 }\n \n                 \"singlethreadfence\" => {\n-                    AtomicFence(bcx, order, llvm::SynchronizationScope::SingleThread);\n+                    bcx.atomic_fence(order, llvm::SynchronizationScope::SingleThread);\n                     C_nil(ccx)\n                 }\n \n@@ -517,7 +508,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n \n                     let sty = &substs.type_at(0).sty;\n                     if int_type_width_signed(sty, ccx).is_some() {\n-                        AtomicRMW(bcx, atom_op, llargs[0], llargs[1], order)\n+                        bcx.atomic_rmw(atom_op, llargs[0], llargs[1], order)\n                     } else {\n                         span_invalid_monomorphization_error(\n                             tcx.sess, span,\n@@ -609,25 +600,24 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                         let arg = adt::MaybeSizedValue::sized(llarg);\n                         (0..contents.len())\n                             .map(|i| {\n-                                Load(bcx, adt::trans_field_ptr(bcx, arg_type, arg, Disr(0), i))\n+                                bcx.load(adt::trans_field_ptr(bcx, arg_type, arg, Disr(0), i))\n                             })\n                             .collect()\n                     }\n                     intrinsics::Type::Pointer(_, Some(ref llvm_elem), _) => {\n                         let llvm_elem = one(ty_to_type(bcx.ccx(), llvm_elem, &mut false));\n-                        vec![PointerCast(bcx, llarg,\n+                        vec![bcx.pointercast(llarg,\n                                          llvm_elem.ptr_to())]\n                     }\n                     intrinsics::Type::Vector(_, Some(ref llvm_elem), length) => {\n                         let llvm_elem = one(ty_to_type(bcx.ccx(), llvm_elem, &mut false));\n-                        vec![BitCast(bcx, llarg,\n-                                     Type::vector(&llvm_elem, length as u64))]\n+                        vec![bcx.bitcast(llarg, Type::vector(&llvm_elem, length as u64))]\n                     }\n                     intrinsics::Type::Integer(_, width, llvm_width) if width != llvm_width => {\n                         // the LLVM intrinsic uses a smaller integer\n                         // size than the C intrinsic's signature, so\n                         // we have to trim it down here.\n-                        vec![Trunc(bcx, llarg, Type::ix(bcx.ccx(), llvm_width as u64))]\n+                        vec![bcx.trunc(llarg, Type::ix(bcx.ccx(), llvm_width as u64))]\n                     }\n                     _ => vec![llarg],\n                 }\n@@ -664,7 +654,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                     let f = declare::declare_cfn(ccx,\n                                                  name,\n                                                  Type::func(&inputs, &outputs));\n-                    Call(bcx, f, &llargs, call_debug_location)\n+                    bcx.call(f, &llargs, bcx.lpad().and_then(|b| b.bundle()))\n                 }\n             };\n \n@@ -674,8 +664,8 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                     assert!(!flatten);\n \n                     for i in 0..elems.len() {\n-                        let val = ExtractValue(bcx, val, i);\n-                        Store(bcx, val, StructGEP(bcx, llresult, i));\n+                        let val = bcx.extract_value(val, i);\n+                        bcx.store(val, bcx.struct_gep(llresult, i));\n                     }\n                     C_nil(ccx)\n                 }\n@@ -687,8 +677,8 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     if val_ty(llval) != Type::void(ccx) &&\n        machine::llsize_of_alloc(ccx, val_ty(llval)) != 0 {\n         if let Some(ty) = fn_ty.ret.cast {\n-            let ptr = PointerCast(bcx, llresult, ty.ptr_to());\n-            let store = Store(bcx, llval, ptr);\n+            let ptr = bcx.pointercast(llresult, ty.ptr_to());\n+            let store = bcx.store(llval, ptr);\n             unsafe {\n                 llvm::LLVMSetAlignment(store, type_of::align_of(ccx, ret_ty));\n             }\n@@ -704,8 +694,7 @@ fn copy_intrinsic<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                               tp_ty: Ty<'tcx>,\n                               dst: ValueRef,\n                               src: ValueRef,\n-                              count: ValueRef,\n-                              call_debug_location: DebugLoc)\n+                              count: ValueRef)\n                               -> ValueRef {\n     let ccx = bcx.ccx();\n     let lltp_ty = type_of::type_of(ccx, tp_ty);\n@@ -721,27 +710,25 @@ fn copy_intrinsic<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n \n     let name = format!(\"llvm.{}.p0i8.p0i8.i{}\", operation, int_size);\n \n-    let dst_ptr = PointerCast(bcx, dst, Type::i8p(ccx));\n-    let src_ptr = PointerCast(bcx, src, Type::i8p(ccx));\n+    let dst_ptr = bcx.pointercast(dst, Type::i8p(ccx));\n+    let src_ptr = bcx.pointercast(src, Type::i8p(ccx));\n     let llfn = ccx.get_intrinsic(&name);\n \n-    Call(bcx,\n-         llfn,\n-         &[dst_ptr,\n-           src_ptr,\n-           Mul(bcx, size, count, DebugLoc::None),\n-           align,\n-           C_bool(ccx, volatile)],\n-         call_debug_location)\n+    bcx.call(llfn,\n+        &[dst_ptr,\n+        src_ptr,\n+        bcx.mul(size, count),\n+        align,\n+        C_bool(ccx, volatile)],\n+        bcx.lpad().and_then(|b| b.bundle()))\n }\n \n fn memset_intrinsic<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                 volatile: bool,\n                                 tp_ty: Ty<'tcx>,\n                                 dst: ValueRef,\n                                 val: ValueRef,\n-                                count: ValueRef,\n-                                call_debug_location: DebugLoc)\n+                                count: ValueRef)\n                                 -> ValueRef {\n     let ccx = bcx.ccx();\n     let lltp_ty = type_of::type_of(ccx, tp_ty);\n@@ -751,44 +738,42 @@ fn memset_intrinsic<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n \n     let name = format!(\"llvm.memset.p0i8.i{}\", int_size);\n \n-    let dst_ptr = PointerCast(bcx, dst, Type::i8p(ccx));\n+    let dst_ptr = bcx.pointercast(dst, Type::i8p(ccx));\n     let llfn = ccx.get_intrinsic(&name);\n \n-    Call(bcx,\n-         llfn,\n-         &[dst_ptr,\n-           val,\n-           Mul(bcx, size, count, DebugLoc::None),\n-           align,\n-           C_bool(ccx, volatile)],\n-         call_debug_location)\n+    bcx.call(\n+        llfn,\n+        &[dst_ptr,\n+        val,\n+        bcx.mul(size, count),\n+        align,\n+        C_bool(ccx, volatile)],\n+        bcx.lpad().and_then(|b| b.bundle()))\n }\n \n fn count_zeros_intrinsic(bcx: &BlockAndBuilder,\n                          name: &str,\n-                         val: ValueRef,\n-                         call_debug_location: DebugLoc)\n+                         val: ValueRef)\n                          -> ValueRef {\n     let y = C_bool(bcx.ccx(), false);\n     let llfn = bcx.ccx().get_intrinsic(&name);\n-    Call(bcx, llfn, &[val, y], call_debug_location)\n+    bcx.call(llfn, &[val, y], bcx.lpad().and_then(|b| b.bundle()))\n }\n \n fn with_overflow_intrinsic<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                                        name: &str,\n                                        a: ValueRef,\n                                        b: ValueRef,\n-                                       out: ValueRef,\n-                                       call_debug_location: DebugLoc)\n+                                       out: ValueRef)\n                                        -> ValueRef {\n     let llfn = bcx.ccx().get_intrinsic(&name);\n \n     // Convert `i1` to a `bool`, and write it to the out parameter\n-    let val = Call(bcx, llfn, &[a, b], call_debug_location);\n-    let result = ExtractValue(bcx, val, 0);\n-    let overflow = ZExt(bcx, ExtractValue(bcx, val, 1), Type::bool(bcx.ccx()));\n-    Store(bcx, result, StructGEP(bcx, out, 0));\n-    Store(bcx, overflow, StructGEP(bcx, out, 1));\n+    let val = bcx.call(llfn, &[a, b], bcx.lpad().and_then(|b| b.bundle()));\n+    let result = bcx.extract_value(val, 0);\n+    let overflow = bcx.zext(bcx.extract_value(val, 1), Type::bool(bcx.ccx()));\n+    bcx.store(result, bcx.struct_gep(out, 0));\n+    bcx.store(overflow, bcx.struct_gep(out, 1));\n \n     C_nil(bcx.ccx())\n }\n@@ -799,15 +784,14 @@ fn try_intrinsic<'blk, 'tcx>(\n     data: ValueRef,\n     local_ptr: ValueRef,\n     dest: ValueRef,\n-    dloc: DebugLoc\n ) {\n     if bcx.sess().no_landing_pads() {\n-        Call(bcx, func, &[data], dloc);\n-        Store(bcx, C_null(Type::i8p(&bcx.ccx())), dest);\n+        bcx.call(func, &[data], bcx.lpad().and_then(|b| b.bundle()));\n+        bcx.store(C_null(Type::i8p(&bcx.ccx())), dest);\n     } else if wants_msvc_seh(bcx.sess()) {\n-        trans_msvc_try(bcx, func, data, local_ptr, dest, dloc);\n+        trans_msvc_try(bcx, func, data, local_ptr, dest);\n     } else {\n-        trans_gnu_try(bcx, func, data, local_ptr, dest, dloc);\n+        trans_gnu_try(bcx, func, data, local_ptr, dest);\n     }\n }\n \n@@ -822,13 +806,11 @@ fn trans_msvc_try<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                               func: ValueRef,\n                               data: ValueRef,\n                               local_ptr: ValueRef,\n-                              dest: ValueRef,\n-                              dloc: DebugLoc) {\n+                              dest: ValueRef) {\n     let llfn = get_rust_try_fn(bcx.fcx(), &mut |bcx| {\n         let ccx = bcx.ccx();\n-        let dloc = DebugLoc::None;\n \n-        SetPersonalityFn(&bcx, bcx.fcx().eh_personality());\n+        bcx.set_personality_fn(bcx.fcx().eh_personality());\n \n         let normal = bcx.fcx().new_block(\"normal\").build();\n         let catchswitch = bcx.fcx().new_block(\"catchswitch\").build();\n@@ -879,36 +861,37 @@ fn trans_msvc_try<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n         //\n         // More information can be found in libstd's seh.rs implementation.\n         let i64p = Type::i64(ccx).ptr_to();\n-        let slot = Alloca(&bcx, i64p, \"slot\");\n-        Invoke(&bcx, func, &[data], normal.llbb(), catchswitch.llbb(), dloc);\n+        let slot = bcx.fcx().alloca(i64p, \"slot\");\n+        bcx.invoke(func, &[data], normal.llbb(), catchswitch.llbb(),\n+            bcx.lpad().and_then(|b| b.bundle()));\n \n-        Ret(&normal, C_i32(ccx, 0), dloc);\n+        normal.ret(C_i32(ccx, 0));\n \n-        let cs = CatchSwitch(&catchswitch, None, None, 1);\n-        AddHandler(&catchswitch, cs, catchpad.llbb());\n+        let cs = catchswitch.catch_switch(None, None, 1);\n+        catchswitch.add_handler(cs, catchpad.llbb());\n \n         let tcx = ccx.tcx();\n         let tydesc = match tcx.lang_items.msvc_try_filter() {\n             Some(did) => ::consts::get_static(ccx, did),\n             None => bug!(\"msvc_try_filter not defined\"),\n         };\n-        let tok = CatchPad(&catchpad, cs, &[tydesc, C_i32(ccx, 0), slot]);\n-        let addr = Load(&catchpad, slot);\n-        let arg1 = Load(&catchpad, addr);\n+        let tok = catchpad.catch_pad(cs, &[tydesc, C_i32(ccx, 0), slot]);\n+        let addr = catchpad.load(slot);\n+        let arg1 = catchpad.load(addr);\n         let val1 = C_i32(ccx, 1);\n-        let arg2 = Load(&catchpad, InBoundsGEP(&catchpad, addr, &[val1]));\n-        let local_ptr = BitCast(&catchpad, local_ptr, i64p);\n-        Store(&catchpad, arg1, local_ptr);\n-        Store(&catchpad, arg2, InBoundsGEP(&catchpad, local_ptr, &[val1]));\n-        CatchRet(&catchpad, tok, caught.llbb());\n+        let arg2 = catchpad.load(catchpad.inbounds_gep(addr, &[val1]));\n+        let local_ptr = catchpad.bitcast(local_ptr, i64p);\n+        catchpad.store(arg1, local_ptr);\n+        catchpad.store(arg2, catchpad.inbounds_gep(local_ptr, &[val1]));\n+        catchpad.catch_ret(tok, caught.llbb());\n \n-        Ret(&caught, C_i32(ccx, 1), dloc);\n+        caught.ret(C_i32(ccx, 1));\n     });\n \n     // Note that no invoke is used here because by definition this function\n     // can't panic (that's what it's catching).\n-    let ret = Call(bcx, llfn, &[func, data, local_ptr], dloc);\n-    Store(bcx, ret, dest);\n+    let ret = bcx.call(llfn, &[func, data, local_ptr], bcx.lpad().and_then(|b| b.bundle()));\n+    bcx.store(ret, dest);\n }\n \n // Definition of the standard \"try\" function for Rust using the GNU-like model\n@@ -926,11 +909,9 @@ fn trans_gnu_try<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n                              func: ValueRef,\n                              data: ValueRef,\n                              local_ptr: ValueRef,\n-                             dest: ValueRef,\n-                             dloc: DebugLoc) {\n+                             dest: ValueRef) {\n     let llfn = get_rust_try_fn(bcx.fcx(), &mut |bcx| {\n         let ccx = bcx.ccx();\n-        let dloc = DebugLoc::None;\n \n         // Translates the shims described above:\n         //\n@@ -955,8 +936,8 @@ fn trans_gnu_try<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n         let func = llvm::get_param(bcx.fcx().llfn, 0);\n         let data = llvm::get_param(bcx.fcx().llfn, 1);\n         let local_ptr = llvm::get_param(bcx.fcx().llfn, 2);\n-        Invoke(&bcx, func, &[data], then.llbb(), catch.llbb(), dloc);\n-        Ret(&then, C_i32(ccx, 0), dloc);\n+        bcx.invoke(func, &[data], then.llbb(), catch.llbb(), bcx.lpad().and_then(|b| b.bundle()));\n+        then.ret(C_i32(ccx, 0));\n \n         // Type indicator for the exception being thrown.\n         //\n@@ -966,17 +947,17 @@ fn trans_gnu_try<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n         // rust_try ignores the selector.\n         let lpad_ty = Type::struct_(ccx, &[Type::i8p(ccx), Type::i32(ccx)],\n                                     false);\n-        let vals = LandingPad(&catch, lpad_ty, bcx.fcx().eh_personality(), 1);\n-        AddClause(&catch, vals, C_null(Type::i8p(ccx)));\n-        let ptr = ExtractValue(&catch, vals, 0);\n-        Store(&catch, ptr, BitCast(&catch, local_ptr, Type::i8p(ccx).ptr_to()));\n-        Ret(&catch, C_i32(ccx, 1), dloc);\n+        let vals = catch.landing_pad(lpad_ty, bcx.fcx().eh_personality(), 1, catch.fcx().llfn);\n+        catch.add_clause(vals, C_null(Type::i8p(ccx)));\n+        let ptr = catch.extract_value(vals, 0);\n+        catch.store(ptr, catch.bitcast(local_ptr, Type::i8p(ccx).ptr_to()));\n+        catch.ret(C_i32(ccx, 1));\n     });\n \n     // Note that no invoke is used here because by definition this function\n     // can't panic (that's what it's catching).\n-    let ret = Call(bcx, llfn, &[func, data, local_ptr], dloc);\n-    Store(bcx, ret, dest);\n+    let ret = bcx.call(llfn, &[func, data, local_ptr], bcx.lpad().and_then(|b| b.bundle()));\n+    bcx.store(ret, dest);\n }\n \n // Helper function to give a Block to a closure to translate a shim function.\n@@ -1042,7 +1023,6 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n     llargs: &[ValueRef],\n     ret_ty: Ty<'tcx>,\n     llret_ty: Type,\n-    call_debug_location: DebugLoc,\n     span: Span\n ) -> ValueRef {\n     // macros for error handling:\n@@ -1113,8 +1093,7 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n                                   llargs[1],\n                                   in_elem,\n                                   llret_ty,\n-                                  cmp_op,\n-                                  call_debug_location)\n+                                  cmp_op)\n     }\n \n     if name.starts_with(\"simd_shuffle\") {\n@@ -1163,20 +1142,20 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n             None => return C_null(llret_ty)\n         };\n \n-        return ShuffleVector(bcx, llargs[0], llargs[1], C_vector(&indices))\n+        return bcx.shuffle_vector(llargs[0], llargs[1], C_vector(&indices))\n     }\n \n     if name == \"simd_insert\" {\n         require!(in_elem == arg_tys[2],\n                  \"expected inserted type `{}` (element of input `{}`), found `{}`\",\n                  in_elem, in_ty, arg_tys[2]);\n-        return InsertElement(bcx, llargs[0], llargs[2], llargs[1])\n+        return bcx.insert_element(llargs[0], llargs[2], llargs[1])\n     }\n     if name == \"simd_extract\" {\n         require!(ret_ty == in_elem,\n                  \"expected return type `{}` (element of input `{}`), found `{}`\",\n                  in_elem, in_ty, ret_ty);\n-        return ExtractElement(bcx, llargs[0], llargs[1])\n+        return bcx.extract_element(llargs[0], llargs[1])\n     }\n \n     if name == \"simd_cast\" {\n@@ -1212,34 +1191,34 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n         match (in_style, out_style) {\n             (Style::Int(in_is_signed), Style::Int(_)) => {\n                 return match in_width.cmp(&out_width) {\n-                    Ordering::Greater => Trunc(bcx, llargs[0], llret_ty),\n+                    Ordering::Greater => bcx.trunc(llargs[0], llret_ty),\n                     Ordering::Equal => llargs[0],\n                     Ordering::Less => if in_is_signed {\n-                        SExt(bcx, llargs[0], llret_ty)\n+                        bcx.sext(llargs[0], llret_ty)\n                     } else {\n-                        ZExt(bcx, llargs[0], llret_ty)\n+                        bcx.zext(llargs[0], llret_ty)\n                     }\n                 }\n             }\n             (Style::Int(in_is_signed), Style::Float) => {\n                 return if in_is_signed {\n-                    SIToFP(bcx, llargs[0], llret_ty)\n+                    bcx.sitofp(llargs[0], llret_ty)\n                 } else {\n-                    UIToFP(bcx, llargs[0], llret_ty)\n+                    bcx.uitofp(llargs[0], llret_ty)\n                 }\n             }\n             (Style::Float, Style::Int(out_is_signed)) => {\n                 return if out_is_signed {\n-                    FPToSI(bcx, llargs[0], llret_ty)\n+                    bcx.fptosi(llargs[0], llret_ty)\n                 } else {\n-                    FPToUI(bcx, llargs[0], llret_ty)\n+                    bcx.fptoui(llargs[0], llret_ty)\n                 }\n             }\n             (Style::Float, Style::Float) => {\n                 return match in_width.cmp(&out_width) {\n-                    Ordering::Greater => FPTrunc(bcx, llargs[0], llret_ty),\n+                    Ordering::Greater => bcx.fptrunc(llargs[0], llret_ty),\n                     Ordering::Equal => llargs[0],\n-                    Ordering::Less => FPExt(bcx, llargs[0], llret_ty)\n+                    Ordering::Less => bcx.fpext(llargs[0], llret_ty)\n                 }\n             }\n             _ => {/* Unsupported. Fallthrough. */}\n@@ -1250,13 +1229,13 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n                  ret_ty, out_elem);\n     }\n     macro_rules! arith {\n-        ($($name: ident: $($($p: ident),* => $call: expr),*;)*) => {\n+        ($($name: ident: $($($p: ident),* => $call: ident),*;)*) => {\n             $(\n                 if name == stringify!($name) {\n                     match in_elem.sty {\n                         $(\n                             $(ty::$p(_))|* => {\n-                                return $call(bcx, llargs[0], llargs[1], call_debug_location)\n+                                return bcx.$call(llargs[0], llargs[1])\n                             }\n                             )*\n                         _ => {},\n@@ -1269,15 +1248,15 @@ fn generic_simd_intrinsic<'blk, 'tcx, 'a>(\n         }\n     }\n     arith! {\n-        simd_add: TyUint, TyInt => Add, TyFloat => FAdd;\n-        simd_sub: TyUint, TyInt => Sub, TyFloat => FSub;\n-        simd_mul: TyUint, TyInt => Mul, TyFloat => FMul;\n-        simd_div: TyFloat => FDiv;\n-        simd_shl: TyUint, TyInt => Shl;\n-        simd_shr: TyUint => LShr, TyInt => AShr;\n-        simd_and: TyUint, TyInt => And;\n-        simd_or: TyUint, TyInt => Or;\n-        simd_xor: TyUint, TyInt => Xor;\n+        simd_add: TyUint, TyInt => add, TyFloat => fadd;\n+        simd_sub: TyUint, TyInt => sub, TyFloat => fsub;\n+        simd_mul: TyUint, TyInt => mul, TyFloat => fmul;\n+        simd_div: TyFloat => fdiv;\n+        simd_shl: TyUint, TyInt => shl;\n+        simd_shr: TyUint => lshr, TyInt => ashr;\n+        simd_and: TyUint, TyInt => and;\n+        simd_or: TyUint, TyInt => or;\n+        simd_xor: TyUint, TyInt => xor;\n     }\n     span_bug!(span, \"unknown SIMD intrinsic\");\n }"}, {"sha": "572d96eaef29d908e39c3ebb7338d5406274514c", "filename": "src/librustc_trans/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Flib.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -96,7 +96,6 @@ mod assert_module_sources;\n mod attributes;\n mod base;\n mod basic_block;\n-mod build;\n mod builder;\n mod cabi_aarch64;\n mod cabi_arm;"}, {"sha": "75746584becbb2a123db7ccc9fbecf4cd5004648", "filename": "src/librustc_trans/meth.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmeth.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmeth.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmeth.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -14,11 +14,9 @@ use llvm::{ValueRef, get_params};\n use rustc::traits;\n use abi::FnType;\n use base::*;\n-use build::*;\n use callee::Callee;\n use common::*;\n use consts;\n-use debuginfo::DebugLoc;\n use declare;\n use glue;\n use machine;\n@@ -40,7 +38,7 @@ pub fn get_virtual_method<'blk, 'tcx>(bcx: &BlockAndBuilder<'blk, 'tcx>,\n     debug!(\"get_virtual_method(vtable_index={}, llvtable={:?})\",\n            vtable_index, Value(llvtable));\n \n-    Load(bcx, GEPi(bcx, llvtable, &[vtable_index + VTABLE_OFFSET]))\n+    bcx.load(bcx.gepi(llvtable, &[vtable_index + VTABLE_OFFSET]))\n }\n \n /// Generate a shim function that allows an object type like `SomeTrait` to\n@@ -93,10 +91,9 @@ pub fn trans_object_shim<'a, 'tcx>(ccx: &'a CrateContext<'a, 'tcx>,\n \n     let dest = fcx.llretslotptr.get();\n     let llargs = get_params(fcx.llfn);\n-    bcx = callee.call(bcx, DebugLoc::None,\n-                      &llargs[fcx.fn_ty.ret.is_indirect() as usize..], dest).0;\n+    bcx = callee.call(bcx, &llargs[fcx.fn_ty.ret.is_indirect() as usize..], dest).0;\n \n-    fcx.finish(&bcx, DebugLoc::None);\n+    fcx.finish(&bcx);\n \n     llfn\n }"}, {"sha": "caeb25241e5c83ac9fc16ca8831176ce884a0c36", "filename": "src/librustc_trans/mir/block.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fblock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fblock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmir%2Fblock.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -16,10 +16,10 @@ use rustc::mir;\n use abi::{Abi, FnType, ArgType};\n use adt;\n use base;\n-use build;\n use callee::{Callee, CalleeData, Fn, Intrinsic, NamedTupleConstructor, Virtual};\n use common::{self, Block, BlockAndBuilder, LandingPad};\n use common::{C_bool, C_str_slice, C_struct, C_u32, C_undef};\n+use builder::Builder;\n use consts;\n use debuginfo::DebugLoc;\n use Disr;\n@@ -167,7 +167,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                     if default_bb != Some(target) {\n                         let llbb = llblock(self, target);\n                         let llval = adt::trans_case(&bcx, ty, Disr::from(adt_variant.disr_val));\n-                        build::AddCase(switch, llval, llbb)\n+                        Builder::add_case(switch, llval, llbb)\n                     }\n                 }\n             }\n@@ -180,7 +180,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                 for (value, target) in values.iter().zip(targets) {\n                     let val = Const::from_constval(bcx.ccx(), value.clone(), switch_ty);\n                     let llbb = llblock(self, *target);\n-                    build::AddCase(switch, val.llval, llbb)\n+                    Builder::add_case(switch, val.llval, llbb)\n                 }\n             }\n \n@@ -204,7 +204,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                     };\n                     let llslot = match op.val {\n                         Immediate(_) | Pair(..) => {\n-                            let llscratch = build::AllocaFcx(bcx.fcx(), ret.original_ty, \"ret\");\n+                            let llscratch = bcx.fcx().alloca(ret.original_ty, \"ret\");\n                             self.store_operand(&bcx, llscratch, op);\n                             llscratch\n                         }\n@@ -257,8 +257,8 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                     // I want to avoid touching all of trans.\n                     let scratch = base::alloc_ty(&bcx, ty, \"drop\");\n                     base::call_lifetime_start(&bcx, scratch);\n-                    build::Store(&bcx, lvalue.llval, base::get_dataptr(&bcx, scratch));\n-                    build::Store(&bcx, lvalue.llextra, base::get_meta(&bcx, scratch));\n+                    bcx.store(lvalue.llval, base::get_dataptr(&bcx, scratch));\n+                    bcx.store(lvalue.llextra, base::get_meta(&bcx, scratch));\n                     scratch\n                 };\n                 if let Some(unwind) = unwind {\n@@ -479,8 +479,8 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                         // I want to avoid touching all of trans.\n                         let scratch = base::alloc_ty(&bcx, ty, \"drop\");\n                         base::call_lifetime_start(&bcx, scratch);\n-                        build::Store(&bcx, llval, base::get_dataptr(&bcx, scratch));\n-                        build::Store(&bcx, llextra, base::get_meta(&bcx, scratch));\n+                        bcx.store(llval, base::get_dataptr(&bcx, scratch));\n+                        bcx.store(llextra, base::get_meta(&bcx, scratch));\n                         scratch\n                     };\n                     if let Some(unwind) = *cleanup {\n@@ -702,7 +702,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n         let (mut llval, by_ref) = match op.val {\n             Immediate(_) | Pair(..) => {\n                 if arg.is_indirect() || arg.cast.is_some() {\n-                    let llscratch = build::AllocaFcx(bcx.fcx(), arg.original_ty, \"arg\");\n+                    let llscratch = bcx.fcx().alloca(arg.original_ty, \"arg\");\n                     self.store_operand(bcx, llscratch, op);\n                     (llscratch, true)\n                 } else {"}, {"sha": "d767a2cb1d07cffc33b9b47a6b3ab51f99d1128e", "filename": "src/librustc_trans/mir/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmir%2Fmod.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -478,10 +478,9 @@ fn arg_local_refs<'bcx, 'tcx>(bcx: &BlockAndBuilder<'bcx, 'tcx>,\n             // environment into its components so it ends up out of bounds.\n             let env_ptr = if !env_ref {\n                 use base::*;\n-                use build::*;\n                 use common::*;\n                 let alloc = alloca(bcx, val_ty(llval), \"__debuginfo_env_ptr\");\n-                Store(bcx, llval, alloc);\n+                bcx.store(llval, alloc);\n                 alloc\n             } else {\n                 llval"}, {"sha": "053eabb6fbf27f4e0c3b3f5b09bebc7530088cb1", "filename": "src/librustc_trans/mir/operand.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmir%2Foperand.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -264,11 +264,10 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n             OperandValue::Ref(r) => base::memcpy_ty(bcx, lldest, r, operand.ty),\n             OperandValue::Immediate(s) => base::store_ty(bcx, s, lldest, operand.ty),\n             OperandValue::Pair(a, b) => {\n-                use build::*;\n                 let a = base::from_immediate(bcx, a);\n                 let b = base::from_immediate(bcx, b);\n-                Store(bcx, a, StructGEP(bcx, lldest, 0));\n-                Store(bcx, b, StructGEP(bcx, lldest, 1));\n+                bcx.store(a, bcx.struct_gep(lldest, 0));\n+                bcx.store(b, bcx.struct_gep(lldest, 1));\n             }\n         }\n     }"}, {"sha": "d9a0895de5bb93755dda7f921d3f7b7e55ea43ad", "filename": "src/librustc_trans/mir/rvalue.rs", "status": "modified", "additions": 7, "deletions": 32, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Frvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Frvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmir%2Frvalue.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -19,7 +19,6 @@ use base;\n use callee::Callee;\n use common::{self, val_ty, C_bool, C_null, C_uint, BlockAndBuilder};\n use common::{C_integral};\n-use debuginfo::DebugLoc;\n use adt;\n use machine;\n use type_::Type;\n@@ -37,8 +36,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n     pub fn trans_rvalue(&mut self,\n                         bcx: BlockAndBuilder<'bcx, 'tcx>,\n                         dest: LvalueRef<'tcx>,\n-                        rvalue: &mir::Rvalue<'tcx>,\n-                        debug_loc: DebugLoc)\n+                        rvalue: &mir::Rvalue<'tcx>)\n                         -> BlockAndBuilder<'bcx, 'tcx>\n     {\n         debug!(\"trans_rvalue(dest.llval={:?}, rvalue={:?})\",\n@@ -59,7 +57,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                 if common::type_is_fat_ptr(bcx.tcx(), cast_ty) {\n                     // into-coerce of a thin pointer to a fat pointer - just\n                     // use the operand path.\n-                    let (bcx, temp) = self.trans_rvalue_operand(bcx, rvalue, debug_loc);\n+                    let (bcx, temp) = self.trans_rvalue_operand(bcx, rvalue);\n                     self.store_operand(&bcx, dest.llval, temp);\n                     return bcx;\n                 }\n@@ -171,7 +169,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n \n             _ => {\n                 assert!(rvalue_creates_operand(&self.mir, &bcx, rvalue));\n-                let (bcx, temp) = self.trans_rvalue_operand(bcx, rvalue, debug_loc);\n+                let (bcx, temp) = self.trans_rvalue_operand(bcx, rvalue);\n                 self.store_operand(&bcx, dest.llval, temp);\n                 bcx\n             }\n@@ -180,8 +178,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n \n     pub fn trans_rvalue_operand(&mut self,\n                                 bcx: BlockAndBuilder<'bcx, 'tcx>,\n-                                rvalue: &mir::Rvalue<'tcx>,\n-                                debug_loc: DebugLoc)\n+                                rvalue: &mir::Rvalue<'tcx>)\n                                 -> (BlockAndBuilder<'bcx, 'tcx>, OperandRef<'tcx>)\n     {\n         assert!(rvalue_creates_operand(&self.mir, &bcx, rvalue),\n@@ -455,14 +452,7 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                 let llalign = C_uint(bcx.ccx(), align);\n                 let llty_ptr = llty.ptr_to();\n                 let box_ty = bcx.tcx().mk_box(content_ty);\n-                let val = base::malloc_raw_dyn(\n-                    &bcx,\n-                    llty_ptr,\n-                    box_ty,\n-                    llsize,\n-                    llalign,\n-                    debug_loc\n-                );\n+                let val = base::malloc_raw_dyn(&bcx, llty_ptr, box_ty, llsize, llalign);\n                 let operand = OperandRef {\n                     val: OperandValue::Immediate(val),\n                     ty: box_ty,\n@@ -526,23 +516,8 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n             mir::BinOp::BitOr => bcx.or(lhs, rhs),\n             mir::BinOp::BitAnd => bcx.and(lhs, rhs),\n             mir::BinOp::BitXor => bcx.xor(lhs, rhs),\n-            mir::BinOp::Shl => {\n-                common::build_unchecked_lshift(\n-                    &bcx,\n-                    lhs,\n-                    rhs,\n-                    DebugLoc::None\n-                )\n-            }\n-            mir::BinOp::Shr => {\n-                common::build_unchecked_rshift(\n-                    bcx,\n-                    input_ty,\n-                    lhs,\n-                    rhs,\n-                    DebugLoc::None\n-                )\n-            }\n+            mir::BinOp::Shl => common::build_unchecked_lshift(bcx, lhs, rhs),\n+            mir::BinOp::Shr => common::build_unchecked_rshift(bcx, input_ty, lhs, rhs),\n             mir::BinOp::Ne | mir::BinOp::Lt | mir::BinOp::Gt |\n             mir::BinOp::Eq | mir::BinOp::Le | mir::BinOp::Ge => if is_nil {\n                 C_bool(bcx.ccx(), match op {"}, {"sha": "47537c830dc3b30788a5e6fc1d57e6fdc1e28b5d", "filename": "src/librustc_trans/mir/statement.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fstatement.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Fmir%2Fstatement.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmir%2Fstatement.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -33,11 +33,10 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                 if let mir::Lvalue::Local(index) = *lvalue {\n                     match self.locals[index] {\n                         LocalRef::Lvalue(tr_dest) => {\n-                            self.trans_rvalue(bcx, tr_dest, rvalue, debug_loc)\n+                            self.trans_rvalue(bcx, tr_dest, rvalue)\n                         }\n                         LocalRef::Operand(None) => {\n-                            let (bcx, operand) = self.trans_rvalue_operand(bcx, rvalue,\n-                                                                           debug_loc);\n+                            let (bcx, operand) = self.trans_rvalue_operand(bcx, rvalue);\n                             self.locals[index] = LocalRef::Operand(Some(operand));\n                             bcx\n                         }\n@@ -51,13 +50,13 @@ impl<'bcx, 'tcx> MirContext<'bcx, 'tcx> {\n                             } else {\n                                 // If the type is zero-sized, it's already been set here,\n                                 // but we still need to make sure we translate the operand\n-                                self.trans_rvalue_operand(bcx, rvalue, debug_loc).0\n+                                self.trans_rvalue_operand(bcx, rvalue).0\n                             }\n                         }\n                     }\n                 } else {\n                     let tr_dest = self.trans_lvalue(&bcx, lvalue);\n-                    self.trans_rvalue(bcx, tr_dest, rvalue, debug_loc)\n+                    self.trans_rvalue(bcx, tr_dest, rvalue)\n                 }\n             }\n             mir::StatementKind::SetDiscriminant{ref lvalue, variant_index} => {"}, {"sha": "8e0069a2a43f8d95b8bb84ca4a111b40cfeacaf3", "filename": "src/librustc_trans/tvec.rs", "status": "modified", "additions": 13, "deletions": 15, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Ftvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad/src%2Flibrustc_trans%2Ftvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftvec.rs?ref=59ef51c12a27ab17606eb7a1c1da58e9ec0c09ad", "patch": "@@ -13,9 +13,8 @@\n use llvm;\n use llvm::ValueRef;\n use base::*;\n-use build::*;\n use common::*;\n-use debuginfo::DebugLoc;\n+use builder::Builder;\n use rustc::ty::Ty;\n \n pub fn slice_for_each<'blk, 'tcx, F>(bcx: BlockAndBuilder<'blk, 'tcx>,\n@@ -31,39 +30,38 @@ pub fn slice_for_each<'blk, 'tcx, F>(bcx: BlockAndBuilder<'blk, 'tcx>,\n \n     // Special-case vectors with elements of size 0  so they don't go out of bounds (#9890)\n     let zst = type_is_zero_size(bcx.ccx(), unit_ty);\n-    let add = |bcx, a, b| if zst {\n-        Add(bcx, a, b, DebugLoc::None)\n+    let add = |bcx: &BlockAndBuilder, a, b| if zst {\n+        bcx.add(a, b)\n     } else {\n-        InBoundsGEP(bcx, a, &[b])\n+        bcx.inbounds_gep(a, &[b])\n     };\n \n     let body_bcx = fcx.new_block(\"slice_loop_body\").build();\n     let next_bcx = fcx.new_block(\"slice_loop_next\").build();\n     let header_bcx = fcx.new_block(\"slice_loop_header\").build();\n \n     let start = if zst {\n-        C_uint(bcx.ccx(), 0 as usize)\n+        C_uint(bcx.ccx(), 0usize)\n     } else {\n         data_ptr\n     };\n     let end = add(&bcx, start, len);\n \n-    Br(&bcx, header_bcx.llbb(), DebugLoc::None);\n-    let current = Phi(&header_bcx, val_ty(start), &[start], &[bcx.llbb()]);\n+    bcx.br(header_bcx.llbb());\n+    let current = header_bcx.phi(val_ty(start), &[start], &[bcx.llbb()]);\n \n-    let keep_going =\n-        ICmp(&header_bcx, llvm::IntNE, current, end, DebugLoc::None);\n-    CondBr(&header_bcx, keep_going, body_bcx.llbb(), next_bcx.llbb(), DebugLoc::None);\n+    let keep_going = header_bcx.icmp(llvm::IntNE, current, end);\n+    header_bcx.cond_br(keep_going, body_bcx.llbb(), next_bcx.llbb());\n \n     let body_bcx = f(body_bcx, if zst { data_ptr } else { current });\n     // FIXME(simulacrum): The code below is identical to the closure (add) above, but using the\n     // closure doesn't compile due to body_bcx still being borrowed when dropped.\n     let next = if zst {\n-        Add(&body_bcx, current, C_uint(bcx.ccx(), 1usize), DebugLoc::None)\n+        body_bcx.add(current, C_uint(bcx.ccx(), 1usize))\n     } else {\n-        InBoundsGEP(&body_bcx, current, &[C_uint(bcx.ccx(), 1usize)])\n+        body_bcx.inbounds_gep(current, &[C_uint(bcx.ccx(), 1usize)])\n     };\n-    AddIncomingToPhi(current, next, body_bcx.llbb());\n-    Br(&body_bcx, header_bcx.llbb(), DebugLoc::None);\n+    Builder::add_incoming_to_phi(current, next, body_bcx.llbb());\n+    body_bcx.br(header_bcx.llbb());\n     next_bcx\n }"}]}