{"sha": "f535940bd55f8d659a5a26370665c5567c6ba55e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY1MzU5NDBiZDU1ZjhkNjU5YTVhMjYzNzA2NjVjNTU2N2M2YmE1NWU=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-01-13T23:42:59Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-01-13T23:43:12Z"}, "message": "Import task and memory-model docs.", "tree": {"sha": "31ee5a53c92efe3afa65f45dc7cd64586a02d99e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/31ee5a53c92efe3afa65f45dc7cd64586a02d99e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f535940bd55f8d659a5a26370665c5567c6ba55e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f535940bd55f8d659a5a26370665c5567c6ba55e", "html_url": "https://github.com/rust-lang/rust/commit/f535940bd55f8d659a5a26370665c5567c6ba55e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f535940bd55f8d659a5a26370665c5567c6ba55e/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "91b0a512904936212cb104e5d1ae3ea86686664a", "url": "https://api.github.com/repos/rust-lang/rust/commits/91b0a512904936212cb104e5d1ae3ea86686664a", "html_url": "https://github.com/rust-lang/rust/commit/91b0a512904936212cb104e5d1ae3ea86686664a"}], "stats": {"total": 222, "additions": 213, "deletions": 9}, "files": [{"sha": "534ba9c6c5b8edc0657e03af323178f8748c7c28", "filename": "doc/rust.md", "status": "modified", "additions": 213, "deletions": 9, "changes": 222, "blob_url": "https://github.com/rust-lang/rust/blob/f535940bd55f8d659a5a26370665c5567c6ba55e/doc%2Frust.md", "raw_url": "https://github.com/rust-lang/rust/raw/f535940bd55f8d659a5a26370665c5567c6ba55e/doc%2Frust.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/doc%2Frust.md?ref=f535940bd55f8d659a5a26370665c5567c6ba55e", "patch": "@@ -736,13 +736,24 @@ macro-generated and user-written code can cause unintentional capture.\n \n Future versions of Rust will address these issues.\n \n-# Memory and concurrency model\n+\n+# Memory and concurrency models\n+\n+Rust has a memory model centered around concurrently-executing _tasks_. Thus\n+its memory model and its concurrency model are best discussed simultaneously,\n+as parts of each only make sense when considered from the perspective of the\n+other.\n+\n+When reading about the memory model, keep in mind that it is partitioned in\n+order to support tasks; and when reading about tasks, keep in mind that their\n+isolation and communication mechanisms are only possible due to the ownership\n+and lifetime semantics of the memory model.\n \n ## Memory model\n \n-A Rust task's memory consists of a static set of *items*, a set of tasks\n-each with its own *stack*, and a *heap*. Immutable portions of the\n-heap may be shared between tasks, mutable portions may not.\n+A Rust [task](#tasks)'s memory consists of a static set of *items*, a set of\n+tasks each with its own *stack*, and a *heap*. Immutable portions of the heap\n+may be shared between tasks, mutable portions may not.\n \n Allocations in the stack consist of *slots*, and allocations in the heap\n consist of *boxes*.\n@@ -774,10 +785,12 @@ shared or unique boxes, and/or references. Sharing memory between tasks can\n only be accomplished using *unsafe* constructs, such as raw pointer\n operations or calling C code.\n \n-When a task sends a value of *unique* kind over a channel, it loses\n-ownership of the value sent and can no longer refer to it. This is statically\n-guaranteed by the combined use of \"move semantics\" and unique kinds, within\n-the communication system.\n+When a task sends a value satisfying the `send` interface over a channel, it\n+loses ownership of the value sent and can no longer refer to it. This is\n+statically guaranteed by the combined use of \"move semantics\" and the\n+compiler-checked _meaning_ of the `send` interface: it is only instantiated\n+for (transitively) unique kinds of data constructor and pointers, never shared\n+pointers.\n \n When a stack frame is exited, its local allocations are all released, and its\n references to boxes (both shared and owned) are dropped.\n@@ -831,7 +844,6 @@ fn incr(&i: int) {\n }\n ~~~~~~~~\n \n-\n ### Memory boxes\n \n A _box_ is a reference to a heap allocation holding another value. There\n@@ -899,6 +911,198 @@ fn main() {\n }\n ~~~~~~~~\n \n+## Tasks\n+\n+An executing Rust program consists of a tree of tasks. A Rust _task_\n+consists of an entry function, a stack, a set of outgoing communication\n+channels and incoming communication ports, and ownership of some portion of\n+the heap of a single operating-system process.\n+\n+Multiple Rust tasks may coexist in a single operating-system process. The\n+runtime scheduler maps tasks to a certain number of operating-system threads;\n+by default a number of threads is used based on the number of concurrent\n+physical CPUs detected at startup, but this can be changed dynamically at\n+runtime. When the number of tasks exceeds the number of threads -- which is\n+quite possible -- the tasks are multiplexed onto the threads ^[This is an M:N\n+scheduler, which is known to give suboptimal results for CPU-bound concurrency\n+problems. In such cases, running with the same number of threads as tasks can\n+give better results. The M:N scheduling in Rust exists to support very large\n+numbers of tasks in contexts where threads are too resource-intensive to use\n+in a similar volume. The cost of threads varies substantially per operating\n+system, and is sometimes quite low, so this flexibility is not always worth\n+exploiting.]\n+\n+\n+### Communication between tasks\n+\n+With the exception of *unsafe* blocks, Rust tasks are isolated from\n+interfering with one another's memory directly. Instead of manipulating shared\n+storage, Rust tasks communicate with one another using a typed, asynchronous,\n+simplex message-passing system.\n+\n+A _port_ is a communication endpoint that can *receive* messages. Ports\n+receive messages from channels.\n+\n+A _channel_ is a communication endpoint that can *send* messages. Channels\n+send messages to ports.\n+\n+Each port is implicitly boxed and mutable; as such a port has a unique\n+per-task identity and cannot be replicated or transmitted. If a port value is\n+copied, both copies refer to the *same* port. New ports can be\n+constructed dynamically and stored in data structures.\n+\n+Each channel is bound to a port when the channel is constructed, so the\n+destination port for a channel must exist before the channel itself. A channel\n+cannot be rebound to a different port from the one it was constructed with.\n+\n+Channels are weak: a channel does not keep the port it is bound to\n+alive. Ports are owned by their allocating task and cannot be sent over\n+channels; if a task dies its ports die with it, and all channels bound to\n+those ports no longer function. Messages sent to a channel connected to a dead\n+port will be dropped.\n+\n+Channels are immutable types with meaning known to the runtime; channels can\n+be sent over channels.\n+\n+Many channels can be bound to the same port, but each channel is bound to a\n+single port. In other words, channels and ports exist in an N:1 relationship,\n+N channels to 1 port. ^[It may help to remember nautical terminology\n+when differentiating channels from ports.  Many different waterways --\n+channels -- may lead to the same port.}\n+\n+Each port and channel can carry only one type of message. The message type is\n+encoded as a parameter of the channel or port type. The message type of a\n+channel is equal to the message type of the port it is bound to. The types of\n+messages must satisfy the `send` built-in interface.\n+\n+Messages are generally sent asynchronously, with optional rate-limiting on the\n+transmit side. A channel contains a message queue and asynchronously sending a\n+message merely inserts it into the sending channel's queue; message receipt is\n+the responsibility of the receiving task.\n+\n+Messages are sent on channels and received on ports using standard library\n+functions.\n+\n+\n+### Task lifecycle\n+\n+The _lifecycle_ of a task consists of a finite set of states and events\n+that cause transitions between the states. The lifecycle states of a task are:\n+\n+* running\n+* blocked\n+* failing\n+* dead\n+\n+A task begins its lifecycle -- once it has been spawned -- in the *running*\n+state. In this state it executes the statements of its entry function, and any\n+functions called by the entry function.\n+\n+A task may transition from the *running* state to the *blocked* state any time\n+it makes a blocking recieve call on a port, or attempts a rate-limited\n+blocking send on a channel. When the communication expression can be completed\n+-- when a message arrives at a sender, or a queue drains sufficiently to\n+complete a rate-limited send -- then the blocked task will unblock and\n+transition back to *running*.\n+\n+A task may transition to the *failing* state at any time, due being\n+killed by some external event or internally, from the evaluation of a\n+`fail` expression. Once *failing*, a task unwinds its stack and\n+transitions to the *dead* state. Unwinding the stack of a task is done by\n+the task itself, on its own control stack. If a value with a destructor is\n+freed during unwinding, the code for the destructor is run, also on the task's\n+control stack. Running the destructor code causes a temporary transition to a\n+*running* state, and allows the destructor code to cause any subsequent\n+state transitions.  The original task of unwinding and failing thereby may\n+suspend temporarily, and may involve (recursive) unwinding of the stack of a\n+failed destructor. Nonetheless, the outermost unwinding activity will continue\n+until the stack is unwound and the task transitions to the *dead*\n+state. There is no way to \"recover\" from task failure.  Once a task has\n+temporarily suspended its unwinding in the *failing* state, failure\n+occurring from within this destructor results in *hard* failure.  The\n+unwinding procedure of hard failure frees resources but does not execute\n+destructors.  The original (soft) failure is still resumed at the point where\n+it was temporarily suspended.\n+\n+A task in the *dead* state cannot transition to other states; it exists\n+only to have its termination status inspected by other tasks, and/or to await\n+reclamation when the last reference to it drops.\n+\n+\n+### Task scheduling\n+\n+The currently scheduled task is given a finite *time slice* in which to\n+execute, after which it is *descheduled* at a loop-edge or similar\n+preemption point, and another task within is scheduled, pseudo-randomly.\n+\n+An executing task can yield control at any time, by making a library call to\n+`std::task::yield`, which deschedules it immediately. Entering any other\n+non-executing state (blocked, dead) similarly deschedules the task.\n+\n+\n+### Spawning tasks\n+\n+A call to `std::task::spawn`, passing a 0-argument function as its single\n+argument, causes the runtime to construct a new task executing the passed\n+function. The passed function is referred to as the _entry function_ for\n+the spawned task, and any captured environment is carries is moved from the\n+spawning task to the spawned task before the spawned task begins execution.\n+\n+The result of a `spawn` call is a `std::task::task` value.\n+\n+An example of a `spawn` call:\n+\n+~~~~\n+import std::task::*;\n+import std::comm::*;\n+\n+fn helper(c: chan<u8>) {\n+    // do some work.\n+    let result = ...;\n+    send(c, result);\n+}\n+\n+let p: port<u8>;\n+\n+spawn(bind helper(chan(p)));\n+// let task run, do other things.\n+// ...\n+let result = recv(p);\n+~~~~\n+\n+\n+### Sending values into channels\n+\n+Sending a value into a channel is done by a library call to `std::comm::send`,\n+which takes a channel and a value to send, and moves the value into the\n+channel's outgoing buffer.\n+\n+An example of a send:\n+\n+~~~~\n+import std::comm::*;\n+let c: chan<str> = ...;\n+send(c, \"hello, world\");\n+~~~~\n+\n+\n+### Receiving values from ports\n+\n+Receiving a value is done by a call to the `recv` method, on a value of type\n+`std::comm::port`. This call causes the receiving task to enter the *blocked\n+reading* state until a task is sending a value to the port, at which point the\n+runtime pseudo-randomly selects a sending task and moves a value from the head\n+of one of the task queues to the call's return value, and un-blocks the\n+receiving task. See [communication system](#communication-system).\n+\n+An example of a *receive*:\n+\n+~~~~~~~~\n+import std::comm::*;\n+let p: port<str> = ...;\n+let s: str = recv(p);\n+~~~~~~~~\n+\n \n # Runtime services, linkage and debugging\n "}]}