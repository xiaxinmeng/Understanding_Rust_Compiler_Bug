{"sha": "981135ae8e6e5465d1283c59476b4e3183bc0ebe", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk4MTEzNWFlOGU2ZTU0NjVkMTI4M2M1OTQ3NmI0ZTMxODNiYzBlYmU=", "commit": {"author": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2021-05-01T22:11:51Z"}, "committer": {"name": "Mark Rousskov", "email": "mark.simulacrum@gmail.com", "date": "2021-05-02T16:25:48Z"}, "message": "Streamline try_start code\n\nThis shifts some branches around and avoids interleaving parallel and\nnon-parallel versions of the function too much.", "tree": {"sha": "1adb7b8433733da94831c655b183c1ff5810676f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1adb7b8433733da94831c655b183c1ff5810676f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/981135ae8e6e5465d1283c59476b4e3183bc0ebe", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/981135ae8e6e5465d1283c59476b4e3183bc0ebe", "html_url": "https://github.com/rust-lang/rust/commit/981135ae8e6e5465d1283c59476b4e3183bc0ebe", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/981135ae8e6e5465d1283c59476b4e3183bc0ebe/comments", "author": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Mark-Simulacrum", "id": 5047365, "node_id": "MDQ6VXNlcjUwNDczNjU=", "avatar_url": "https://avatars.githubusercontent.com/u/5047365?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mark-Simulacrum", "html_url": "https://github.com/Mark-Simulacrum", "followers_url": "https://api.github.com/users/Mark-Simulacrum/followers", "following_url": "https://api.github.com/users/Mark-Simulacrum/following{/other_user}", "gists_url": "https://api.github.com/users/Mark-Simulacrum/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mark-Simulacrum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mark-Simulacrum/subscriptions", "organizations_url": "https://api.github.com/users/Mark-Simulacrum/orgs", "repos_url": "https://api.github.com/users/Mark-Simulacrum/repos", "events_url": "https://api.github.com/users/Mark-Simulacrum/events{/privacy}", "received_events_url": "https://api.github.com/users/Mark-Simulacrum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1c2c6b670023efda0fea8e1837f9542d3ed12f5d", "url": "https://api.github.com/repos/rust-lang/rust/commits/1c2c6b670023efda0fea8e1837f9542d3ed12f5d", "html_url": "https://github.com/rust-lang/rust/commit/1c2c6b670023efda0fea8e1837f9542d3ed12f5d"}], "stats": {"total": 212, "additions": 111, "deletions": 101}, "files": [{"sha": "011c2ceebb7148797d92260cc89576b8c5ccd0b5", "filename": "compiler/rustc_query_system/src/query/caches.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fcaches.rs?ref=981135ae8e6e5465d1283c59476b4e3183bc0ebe", "patch": "@@ -14,7 +14,7 @@ pub trait CacheSelector<K, V> {\n     type Cache;\n }\n \n-pub trait QueryStorage: Default {\n+pub trait QueryStorage {\n     type Value: Debug;\n     type Stored: Clone;\n \n@@ -23,7 +23,7 @@ pub trait QueryStorage: Default {\n     fn store_nocache(&self, value: Self::Value) -> Self::Stored;\n }\n \n-pub trait QueryCache: QueryStorage {\n+pub trait QueryCache: QueryStorage + Sized {\n     type Key: Hash + Eq + Clone + Debug;\n     type Sharded: Default;\n "}, {"sha": "f2a6b6df4b9de3f75208a6eb5dadc5fa39a77363", "filename": "compiler/rustc_query_system/src/query/config.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fconfig.rs?ref=981135ae8e6e5465d1283c59476b4e3183bc0ebe", "patch": "@@ -52,10 +52,6 @@ impl<CTX: QueryContext, K, V> QueryVtable<CTX, K, V> {\n         (self.hash_result)(hcx, value)\n     }\n \n-    pub(crate) fn handle_cycle_error(&self, tcx: CTX, diag: DiagnosticBuilder<'_>) -> V {\n-        (self.handle_cycle_error)(tcx, diag)\n-    }\n-\n     pub(crate) fn cache_on_disk(&self, tcx: CTX, key: &K, value: Option<&V>) -> bool {\n         (self.cache_on_disk)(tcx, key, value)\n     }"}, {"sha": "a967670280ff2ec8990ad27481d0bef354a164ec", "filename": "compiler/rustc_query_system/src/query/job.rs", "status": "modified", "additions": 3, "deletions": 18, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fjob.rs?ref=981135ae8e6e5465d1283c59476b4e3183bc0ebe", "patch": "@@ -9,7 +9,6 @@ use rustc_span::Span;\n \n use std::convert::TryFrom;\n use std::hash::Hash;\n-use std::marker::PhantomData;\n use std::num::NonZeroU32;\n \n #[cfg(parallel_compiler)]\n@@ -100,8 +99,6 @@ pub struct QueryJob<D> {\n     /// The latch that is used to wait on this job.\n     #[cfg(parallel_compiler)]\n     latch: Option<QueryLatch<D>>,\n-\n-    dummy: PhantomData<QueryLatch<D>>,\n }\n \n impl<D> QueryJob<D>\n@@ -116,23 +113,17 @@ where\n             parent,\n             #[cfg(parallel_compiler)]\n             latch: None,\n-            dummy: PhantomData,\n         }\n     }\n \n     #[cfg(parallel_compiler)]\n-    pub(super) fn latch(&mut self, _id: QueryJobId<D>) -> QueryLatch<D> {\n+    pub(super) fn latch(&mut self) -> QueryLatch<D> {\n         if self.latch.is_none() {\n             self.latch = Some(QueryLatch::new());\n         }\n         self.latch.as_ref().unwrap().clone()\n     }\n \n-    #[cfg(not(parallel_compiler))]\n-    pub(super) fn latch(&mut self, id: QueryJobId<D>) -> QueryLatch<D> {\n-        QueryLatch { id }\n-    }\n-\n     /// Signals to waiters that the query is complete.\n     ///\n     /// This does nothing for single threaded rustc,\n@@ -148,13 +139,7 @@ where\n }\n \n #[cfg(not(parallel_compiler))]\n-#[derive(Clone)]\n-pub(super) struct QueryLatch<D> {\n-    id: QueryJobId<D>,\n-}\n-\n-#[cfg(not(parallel_compiler))]\n-impl<D> QueryLatch<D>\n+impl<D> QueryJobId<D>\n where\n     D: Copy + Clone + Eq + Hash,\n {\n@@ -172,7 +157,7 @@ where\n             let info = query_map.get(&job).unwrap();\n             cycle.push(info.info.clone());\n \n-            if job == self.id {\n+            if job == *self {\n                 cycle.reverse();\n \n                 // This is the end of the cycle"}, {"sha": "53e6267ac009992da5710c23b8bdf8eeebf46058", "filename": "compiler/rustc_query_system/src/query/plumbing.rs", "status": "modified", "additions": 106, "deletions": 77, "changes": 183, "blob_url": "https://github.com/rust-lang/rust/blob/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/981135ae8e6e5465d1283c59476b4e3183bc0ebe/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_query_system%2Fsrc%2Fquery%2Fplumbing.rs?ref=981135ae8e6e5465d1283c59476b4e3183bc0ebe", "patch": "@@ -11,13 +11,13 @@ use crate::query::job::{\n };\n use crate::query::{QueryContext, QueryMap, QueryStackFrame};\n \n-#[cfg(not(parallel_compiler))]\n-use rustc_data_structures::cold_path;\n use rustc_data_structures::fingerprint::Fingerprint;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n use rustc_data_structures::sharded::{get_shard_index_by_hash, Sharded};\n use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n+#[cfg(not(parallel_compiler))]\n+use rustc_errors::DiagnosticBuilder;\n use rustc_errors::{Diagnostic, FatalError};\n use rustc_span::Span;\n use std::collections::hash_map::Entry;\n@@ -36,7 +36,7 @@ pub struct QueryCacheStore<C: QueryCache> {\n     pub cache_hits: AtomicUsize,\n }\n \n-impl<C: QueryCache> Default for QueryCacheStore<C> {\n+impl<C: QueryCache + Default> Default for QueryCacheStore<C> {\n     fn default() -> Self {\n         Self {\n             cache: C::default(),\n@@ -161,6 +161,31 @@ where\n     id: QueryJobId<D>,\n }\n \n+#[cold]\n+#[inline(never)]\n+#[cfg(not(parallel_compiler))]\n+fn mk_cycle<CTX, V, R>(\n+    tcx: CTX,\n+    root: QueryJobId<CTX::DepKind>,\n+    span: Span,\n+    handle_cycle_error: fn(CTX, DiagnosticBuilder<'_>) -> V,\n+    cache: &dyn crate::query::QueryStorage<Value = V, Stored = R>,\n+) -> R\n+where\n+    CTX: QueryContext,\n+    V: std::fmt::Debug,\n+    R: Clone,\n+{\n+    let error: CycleError = root.find_cycle_in_stack(\n+        tcx.try_collect_active_jobs().unwrap(),\n+        &tcx.current_query_job(),\n+        span,\n+    );\n+    let error = report_cycle(tcx.dep_context().sess(), error);\n+    let value = handle_cycle_error(tcx, error);\n+    cache.store_nocache(value)\n+}\n+\n impl<'tcx, D, C> JobOwner<'tcx, D, C>\n where\n     D: Copy + Clone + Eq + Hash,\n@@ -180,7 +205,7 @@ where\n         state: &'b QueryState<CTX::DepKind, C::Key>,\n         cache: &'b QueryCacheStore<C>,\n         span: Span,\n-        key: &C::Key,\n+        key: C::Key,\n         lookup: QueryLookup,\n         query: &QueryVtable<CTX, C::Key, C::Value>,\n     ) -> TryGetJob<'b, CTX::DepKind, C>\n@@ -191,94 +216,86 @@ where\n         let mut state_lock = state.shards.get_shard_by_index(shard).lock();\n         let lock = &mut *state_lock;\n \n-        let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n-            Entry::Occupied(mut entry) => {\n-                match entry.get_mut() {\n-                    QueryResult::Started(job) => {\n-                        // For parallel queries, we'll block and wait until the query running\n-                        // in another thread has completed. Record how long we wait in the\n-                        // self-profiler.\n-                        let _query_blocked_prof_timer = if cfg!(parallel_compiler) {\n-                            Some(tcx.dep_context().profiler().query_blocked())\n-                        } else {\n-                            None\n-                        };\n-\n-                        // Create the id of the job we're waiting for\n-                        let id = QueryJobId::new(job.id, shard, query.dep_kind);\n-\n-                        (job.latch(id), _query_blocked_prof_timer)\n-                    }\n-                    QueryResult::Poisoned => FatalError.raise(),\n-                }\n-            }\n+        match lock.active.entry(key) {\n             Entry::Vacant(entry) => {\n-                // No job entry for this query. Return a new one to be started later.\n-\n                 // Generate an id unique within this shard.\n                 let id = lock.jobs.checked_add(1).unwrap();\n                 lock.jobs = id;\n                 let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n \n-                let global_id = QueryJobId::new(id, shard, query.dep_kind);\n-\n                 let job = tcx.current_query_job();\n                 let job = QueryJob::new(id, span, job);\n \n+                let key = entry.key().clone();\n                 entry.insert(QueryResult::Started(job));\n \n-                let owner = JobOwner { state, cache, id: global_id, key: (*key).clone() };\n+                let global_id = QueryJobId::new(id, shard, query.dep_kind);\n+                let owner = JobOwner { state, cache, id: global_id, key };\n                 return TryGetJob::NotYetStarted(owner);\n             }\n-        };\n-        mem::drop(state_lock);\n-\n-        // If we are single-threaded we know that we have cycle error,\n-        // so we just return the error.\n-        #[cfg(not(parallel_compiler))]\n-        return TryGetJob::Cycle(cold_path(|| {\n-            let error: CycleError = latch.find_cycle_in_stack(\n-                tcx.try_collect_active_jobs().unwrap(),\n-                &tcx.current_query_job(),\n-                span,\n-            );\n-            let error = report_cycle(tcx.dep_context().sess(), error);\n-            let value = query.handle_cycle_error(tcx, error);\n-            cache.cache.store_nocache(value)\n-        }));\n-\n-        // With parallel queries we might just have to wait on some other\n-        // thread.\n-        #[cfg(parallel_compiler)]\n-        {\n-            let result = latch.wait_on(tcx.current_query_job(), span);\n-\n-            if let Err(cycle) = result {\n-                let cycle = report_cycle(tcx.dep_context().sess(), cycle);\n-                let value = query.handle_cycle_error(tcx, cycle);\n-                let value = cache.cache.store_nocache(value);\n-                return TryGetJob::Cycle(value);\n-            }\n+            Entry::Occupied(mut entry) => {\n+                match entry.get_mut() {\n+                    #[cfg(not(parallel_compiler))]\n+                    QueryResult::Started(job) => {\n+                        let id = QueryJobId::new(job.id, shard, query.dep_kind);\n \n-            let cached = cache\n-                .cache\n-                .lookup(cache, &key, |value, index| {\n-                    if unlikely!(tcx.dep_context().profiler().enabled()) {\n-                        tcx.dep_context().profiler().query_cache_hit(index.into());\n+                        drop(state_lock);\n+\n+                        // If we are single-threaded we know that we have cycle error,\n+                        // so we just return the error.\n+                        return TryGetJob::Cycle(mk_cycle(\n+                            tcx,\n+                            id,\n+                            span,\n+                            query.handle_cycle_error,\n+                            &cache.cache,\n+                        ));\n                     }\n-                    #[cfg(debug_assertions)]\n-                    {\n-                        cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+                    #[cfg(parallel_compiler)]\n+                    QueryResult::Started(job) => {\n+                        // For parallel queries, we'll block and wait until the query running\n+                        // in another thread has completed. Record how long we wait in the\n+                        // self-profiler.\n+                        let query_blocked_prof_timer = tcx.dep_context().profiler().query_blocked();\n+\n+                        // Get the latch out\n+                        let latch = job.latch();\n+                        let key = entry.key().clone();\n+\n+                        drop(state_lock);\n+\n+                        // With parallel queries we might just have to wait on some other\n+                        // thread.\n+                        let result = latch.wait_on(tcx.current_query_job(), span);\n+\n+                        if let Err(cycle) = result {\n+                            let cycle = report_cycle(tcx.dep_context().sess(), cycle);\n+                            let value = (query.handle_cycle_error)(tcx, cycle);\n+                            let value = cache.cache.store_nocache(value);\n+                            return TryGetJob::Cycle(value);\n+                        }\n+\n+                        let cached = cache\n+                            .cache\n+                            .lookup(cache, &key, |value, index| {\n+                                if unlikely!(tcx.dep_context().profiler().enabled()) {\n+                                    tcx.dep_context().profiler().query_cache_hit(index.into());\n+                                }\n+                                #[cfg(debug_assertions)]\n+                                {\n+                                    cache.cache_hits.fetch_add(1, Ordering::Relaxed);\n+                                }\n+                                (value.clone(), index)\n+                            })\n+                            .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n+\n+                        query_blocked_prof_timer.finish_with_query_invocation_id(cached.1.into());\n+\n+                        return TryGetJob::JobCompleted(cached);\n                     }\n-                    (value.clone(), index)\n-                })\n-                .unwrap_or_else(|_| panic!(\"value must be in cache after waiting\"));\n-\n-            if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n-                prof_timer.finish_with_query_invocation_id(cached.1.into());\n+                    QueryResult::Poisoned => FatalError.raise(),\n+                }\n             }\n-\n-            return TryGetJob::JobCompleted(cached);\n         }\n     }\n \n@@ -421,7 +438,13 @@ where\n     CTX: QueryContext,\n {\n     let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n-        tcx, state, cache, span, &key, lookup, query,\n+        tcx,\n+        state,\n+        cache,\n+        span,\n+        key.clone(),\n+        lookup,\n+        query,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,\n         TryGetJob::Cycle(result) => return result,\n@@ -744,7 +767,13 @@ fn force_query_impl<CTX, C>(\n     };\n \n     let job = match JobOwner::<'_, CTX::DepKind, C>::try_start(\n-        tcx, state, cache, span, &key, lookup, query,\n+        tcx,\n+        state,\n+        cache,\n+        span,\n+        key.clone(),\n+        lookup,\n+        query,\n     ) {\n         TryGetJob::NotYetStarted(job) => job,\n         TryGetJob::Cycle(_) => return,"}]}