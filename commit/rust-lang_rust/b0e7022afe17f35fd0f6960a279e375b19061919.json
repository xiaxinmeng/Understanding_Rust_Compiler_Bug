{"sha": "b0e7022afe17f35fd0f6960a279e375b19061919", "node_id": "MDY6Q29tbWl0NzI0NzEyOmIwZTcwMjJhZmUxN2YzNWZkMGY2OTYwYTI3OWUzNzViMTkwNjE5MTk=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-05-02T06:32:42Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-05-02T06:32:42Z"}, "message": "Merge #1224\n\n1224: Remove unused multchar puncts code and add space between puncts r=matklad a=edwin0cheng\n\nAfter #1213 , parser only need single char punct, this PR do the following things: \r\n\r\n* Remove code which handles multi char puncts\r\n* Remove code which handle traversal backward in `SubtreeSource` , because we cached the result in #1195\r\n* Add space between two consecutive puncts while `tt` to `SyntaxNode` conversion . \r\n\r\nNote that the spaces should only be added if both puncts are not delimiters. \n\nCo-authored-by: Edwin Cheng <edwin0cheng@gmail.com>", "tree": {"sha": "487b133512986fb6eb6eac4068e0045e75cfd2ac", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/487b133512986fb6eb6eac4068e0045e75cfd2ac"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b0e7022afe17f35fd0f6960a279e375b19061919", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b0e7022afe17f35fd0f6960a279e375b19061919", "html_url": "https://github.com/rust-lang/rust/commit/b0e7022afe17f35fd0f6960a279e375b19061919", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b0e7022afe17f35fd0f6960a279e375b19061919/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "12629d5e4f2d949eedb707dedad4d75eff09e683", "url": "https://api.github.com/repos/rust-lang/rust/commits/12629d5e4f2d949eedb707dedad4d75eff09e683", "html_url": "https://github.com/rust-lang/rust/commit/12629d5e4f2d949eedb707dedad4d75eff09e683"}, {"sha": "779676f782565cfc936db79db48e2e7b62adf3a3", "url": "https://api.github.com/repos/rust-lang/rust/commits/779676f782565cfc936db79db48e2e7b62adf3a3", "html_url": "https://github.com/rust-lang/rust/commit/779676f782565cfc936db79db48e2e7b62adf3a3"}], "stats": {"total": 333, "additions": 120, "deletions": 213}, "files": [{"sha": "8176296e6f14fc210600176279df6dece6342bdc", "filename": "crates/ra_mbe/src/subtree_source.rs", "status": "modified", "additions": 41, "deletions": 182, "changes": 223, "blob_url": "https://github.com/rust-lang/rust/blob/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsubtree_source.rs?ref=b0e7022afe17f35fd0f6960a279e375b19061919", "patch": "@@ -45,28 +45,13 @@ impl<'a> TokenSeq<'a> {\n             }\n         }\n     }\n-\n-    fn len(&self) -> usize {\n-        match self {\n-            TokenSeq::Subtree(subtree) => subtree.token_trees.len() + 2,\n-            TokenSeq::Seq(tokens) => tokens.len(),\n-        }\n-    }\n-\n-    fn child_slice(&self, pos: usize) -> &[tt::TokenTree] {\n-        match self {\n-            TokenSeq::Subtree(subtree) => &subtree.token_trees[pos - 1..],\n-            TokenSeq::Seq(tokens) => &tokens[pos..],\n-        }\n-    }\n }\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n struct TtToken {\n     pub kind: SyntaxKind,\n     pub is_joint_to_next: bool,\n     pub text: SmolStr,\n-    pub n_tokens: usize,\n }\n \n #[derive(Debug, Clone, Eq, PartialEq)]\n@@ -80,19 +65,12 @@ struct SubTreeWalker<'a> {\n     pos: usize,\n     stack: Vec<(TokenSeq<'a>, usize)>,\n     cursor: WalkCursor,\n-    last_steps: Vec<usize>,\n     ts: TokenSeq<'a>,\n }\n \n impl<'a> SubTreeWalker<'a> {\n     fn new(ts: TokenSeq<'a>) -> SubTreeWalker {\n-        let mut res = SubTreeWalker {\n-            pos: 0,\n-            stack: vec![],\n-            cursor: WalkCursor::Eof,\n-            last_steps: vec![],\n-            ts,\n-        };\n+        let mut res = SubTreeWalker { pos: 0, stack: vec![], cursor: WalkCursor::Eof, ts };\n \n         res.reset();\n         res\n@@ -105,7 +83,6 @@ impl<'a> SubTreeWalker<'a> {\n     fn reset(&mut self) {\n         self.pos = 0;\n         self.stack = vec![];\n-        self.last_steps = vec![];\n \n         self.cursor = match self.ts.get(0) {\n             DelimToken::Token(token) => match token {\n@@ -114,10 +91,7 @@ impl<'a> SubTreeWalker<'a> {\n                     self.stack.push((ts, 0));\n                     WalkCursor::Token(0, convert_delim(subtree.delimiter, false))\n                 }\n-                tt::TokenTree::Leaf(leaf) => {\n-                    let next_tokens = self.ts.child_slice(0);\n-                    WalkCursor::Token(0, convert_leaf(&next_tokens, leaf))\n-                }\n+                tt::TokenTree::Leaf(leaf) => WalkCursor::Token(0, convert_leaf(leaf)),\n             },\n             DelimToken::Delim(delim, is_end) => {\n                 assert!(!is_end);\n@@ -138,71 +112,39 @@ impl<'a> SubTreeWalker<'a> {\n         self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts)\n     }\n \n-    /// Move cursor backward by 1 step\n-    fn backward(&mut self) {\n-        if self.last_steps.is_empty() {\n-            return;\n-        }\n-\n-        self.pos -= 1;\n-        let last_step = self.last_steps.pop().unwrap();\n-\n-        self.cursor = match self.cursor {\n-            WalkCursor::Token(idx, _) => self.walk_token(idx, last_step, true),\n-            WalkCursor::Eof => {\n-                let len = self.top().len();\n-                self.walk_token(len, last_step, true)\n-            }\n-        }\n-    }\n-\n     /// Move cursor forward by 1 step        \n     fn forward(&mut self) {\n         if self.is_eof() {\n             return;\n         }\n         self.pos += 1;\n \n-        let step = self.current().map(|x| x.n_tokens).unwrap_or(1);\n-        self.last_steps.push(step);\n-\n         if let WalkCursor::Token(u, _) = self.cursor {\n-            self.cursor = self.walk_token(u, step, false)\n+            self.cursor = self.walk_token(u)\n         }\n     }\n \n     /// Traversal child token\n-    fn walk_token(&mut self, pos: usize, offset: usize, backward: bool) -> WalkCursor {\n+    fn walk_token(&mut self, pos: usize) -> WalkCursor {\n         let top = self.stack.last().map(|(t, _)| t).unwrap_or(&self.ts);\n-\n-        if backward && pos < offset {\n-            let (_, last_idx) = self.stack.pop().unwrap();\n-            return self.walk_token(last_idx, offset, backward);\n-        }\n-\n-        let pos = if backward { pos - offset } else { pos + offset };\n+        let pos = pos + 1;\n \n         match top.get(pos) {\n             DelimToken::Token(token) => match token {\n                 tt::TokenTree::Subtree(subtree) => {\n                     let ts = TokenSeq::from(subtree);\n-                    let new_idx = if backward { ts.len() - 1 } else { 0 };\n                     self.stack.push((ts, pos));\n-                    WalkCursor::Token(new_idx, convert_delim(subtree.delimiter, backward))\n-                }\n-                tt::TokenTree::Leaf(leaf) => {\n-                    let next_tokens = top.child_slice(pos);\n-                    WalkCursor::Token(pos, convert_leaf(&next_tokens, leaf))\n+                    WalkCursor::Token(0, convert_delim(subtree.delimiter, false))\n                 }\n+                tt::TokenTree::Leaf(leaf) => WalkCursor::Token(pos, convert_leaf(leaf)),\n             },\n             DelimToken::Delim(delim, is_end) => {\n                 WalkCursor::Token(pos, convert_delim(*delim, is_end))\n             }\n             DelimToken::End => {\n                 // it is the top level\n                 if let Some((_, last_idx)) = self.stack.pop() {\n-                    assert!(!backward);\n-                    self.walk_token(last_idx, offset, backward)\n+                    self.walk_token(last_idx)\n                 } else {\n                     WalkCursor::Eof\n                 }\n@@ -237,25 +179,21 @@ impl<'a> WalkerOwner<'a> {\n         }\n \n         while pos >= cached.len() {\n-            let len = cached.len();\n-            cached.push({\n-                self.set_pos(len);\n-                let walker = self.walker.borrow();\n-                walker.current().cloned()\n-            });\n+            self.set_pos(cached.len());\n+            let walker = self.walker.borrow();\n+            cached.push(walker.current().cloned());\n         }\n \n         return cached[pos].clone();\n     }\n \n     fn set_pos(&self, pos: usize) {\n         let mut walker = self.walker.borrow_mut();\n+        assert!(walker.pos <= pos);\n+\n         while pos > walker.pos && !walker.is_eof() {\n             walker.forward();\n         }\n-        while pos < walker.pos {\n-            walker.backward();\n-        }\n     }\n \n     fn collect_token_trees(&mut self, n: usize) -> Vec<&tt::TokenTree> {\n@@ -264,15 +202,16 @@ impl<'a> WalkerOwner<'a> {\n         walker.reset();\n \n         while walker.pos < n {\n-            if let WalkCursor::Token(u, tt) = &walker.cursor {\n+            if let WalkCursor::Token(u, _) = &walker.cursor {\n                 // We only collect the topmost child\n                 if walker.stack.len() == 0 {\n-                    for i in 0..tt.n_tokens {\n-                        if let DelimToken::Token(token) = walker.ts.get(u + i) {\n-                            res.push(token);\n-                        }\n+                    if let DelimToken::Token(token) = walker.ts.get(*u) {\n+                        res.push(token);\n                     }\n-                } else if walker.stack.len() == 1 {\n+                }\n+                // Check whether the second level is a subtree\n+                // if so, collect its parent which is topmost child\n+                else if walker.stack.len() == 1 {\n                     if let DelimToken::Delim(_, is_end) = walker.top().get(*u) {\n                         if !is_end {\n                             let (_, last_idx) = &walker.stack[0];\n@@ -343,78 +282,6 @@ impl<'a> TokenSource for SubtreeTokenSource<'a> {\n     }\n }\n \n-pub(crate) struct TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    iter: itertools::MultiPeek<I>,\n-}\n-\n-// helper function\n-fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n-    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n-        return Some(pp);\n-    }\n-    None\n-}\n-\n-impl<'a, I> TokenPeek<'a, I>\n-where\n-    I: Iterator<Item = &'a tt::TokenTree>,\n-{\n-    pub fn new(iter: I) -> Self {\n-        TokenPeek { iter: itertools::multipeek(iter) }\n-    }\n-\n-    pub fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n-        if p.spacing != tt::Spacing::Joint {\n-            return None;\n-        }\n-\n-        self.iter.reset_peek();\n-        let p1 = to_punct(self.iter.peek()?)?;\n-        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n-    }\n-\n-    pub fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n-        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n-            if !last_joint {\n-                None\n-            } else {\n-                let p2 = to_punct(*self.iter.peek()?)?;\n-                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n-            }\n-        })\n-    }\n-}\n-\n-// FIXME: Remove this function\n-fn convert_multi_char_punct<'b, I>(\n-    p: &tt::Punct,\n-    iter: &mut TokenPeek<'b, I>,\n-) -> Option<(SyntaxKind, bool, &'static str, usize)>\n-where\n-    I: Iterator<Item = &'b tt::TokenTree>,\n-{\n-    if let Some((m, is_joint_to_next)) = iter.current_punct3(p) {\n-        if let Some((kind, text)) = match m {\n-            _ => None,\n-        } {\n-            return Some((kind, is_joint_to_next, text, 3));\n-        }\n-    }\n-\n-    if let Some((m, is_joint_to_next)) = iter.current_punct2(p) {\n-        if let Some((kind, text)) = match m {\n-            _ => None,\n-        } {\n-            return Some((kind, is_joint_to_next, text, 2));\n-        }\n-    }\n-\n-    None\n-}\n-\n fn convert_delim(d: tt::Delimiter, closing: bool) -> TtToken {\n     let (kinds, texts) = match d {\n         tt::Delimiter::Parenthesis => ([L_PAREN, R_PAREN], \"()\"),\n@@ -426,7 +293,7 @@ fn convert_delim(d: tt::Delimiter, closing: bool) -> TtToken {\n     let idx = closing as usize;\n     let kind = kinds[idx];\n     let text = if texts.len() > 0 { &texts[idx..texts.len() - (1 - idx)] } else { \"\" };\n-    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: SmolStr::new(text) }\n }\n \n fn convert_literal(l: &tt::Literal) -> TtToken {\n@@ -437,7 +304,7 @@ fn convert_literal(l: &tt::Literal) -> TtToken {\n             _ => panic!(\"Fail to convert given literal {:#?}\", &l),\n         });\n \n-    TtToken { kind, is_joint_to_next: false, text: l.text.clone(), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: l.text.clone() }\n }\n \n fn convert_ident(ident: &tt::Ident) -> TtToken {\n@@ -447,39 +314,31 @@ fn convert_ident(ident: &tt::Ident) -> TtToken {\n         SyntaxKind::from_keyword(ident.text.as_str()).unwrap_or(IDENT)\n     };\n \n-    TtToken { kind, is_joint_to_next: false, text: ident.text.clone(), n_tokens: 1 }\n+    TtToken { kind, is_joint_to_next: false, text: ident.text.clone() }\n }\n \n-fn convert_punct(p: &tt::Punct, next_tokens: &[tt::TokenTree]) -> TtToken {\n-    let mut iter = next_tokens.iter();\n-    iter.next();\n-    let mut peek = TokenPeek::new(iter);\n-\n-    if let Some((kind, is_joint_to_next, text, size)) = convert_multi_char_punct(p, &mut peek) {\n-        TtToken { kind, is_joint_to_next, text: text.into(), n_tokens: size }\n-    } else {\n-        let kind = match p.char {\n-            // lexer may produce combpund tokens for these ones\n-            '.' => DOT,\n-            ':' => COLON,\n-            '=' => EQ,\n-            '!' => EXCL,\n-            '-' => MINUS,\n-            c => SyntaxKind::from_char(c).unwrap(),\n-        };\n-        let text = {\n-            let mut buf = [0u8; 4];\n-            let s: &str = p.char.encode_utf8(&mut buf);\n-            SmolStr::new(s)\n-        };\n-        TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text, n_tokens: 1 }\n-    }\n+fn convert_punct(p: &tt::Punct) -> TtToken {\n+    let kind = match p.char {\n+        // lexer may produce combpund tokens for these ones\n+        '.' => DOT,\n+        ':' => COLON,\n+        '=' => EQ,\n+        '!' => EXCL,\n+        '-' => MINUS,\n+        c => SyntaxKind::from_char(c).unwrap(),\n+    };\n+    let text = {\n+        let mut buf = [0u8; 4];\n+        let s: &str = p.char.encode_utf8(&mut buf);\n+        SmolStr::new(s)\n+    };\n+    TtToken { kind, is_joint_to_next: p.spacing == tt::Spacing::Joint, text }\n }\n \n-fn convert_leaf(tokens: &[tt::TokenTree], leaf: &tt::Leaf) -> TtToken {\n+fn convert_leaf(leaf: &tt::Leaf) -> TtToken {\n     match leaf {\n         tt::Leaf::Literal(l) => convert_literal(l),\n         tt::Leaf::Ident(ident) => convert_ident(ident),\n-        tt::Leaf::Punct(punct) => convert_punct(punct, tokens),\n+        tt::Leaf::Punct(punct) => convert_punct(punct),\n     }\n }"}, {"sha": "3521b382adfe14f4450f531fb0850e1307228209", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 34, "deletions": 30, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=b0e7022afe17f35fd0f6960a279e375b19061919", "patch": "@@ -148,30 +148,21 @@ fn convert_tt(\n         match child {\n             SyntaxElement::Token(token) => {\n                 if token.kind().is_punct() {\n-                    let mut prev = None;\n-                    for char in token.text().chars() {\n-                        if let Some(char) = prev {\n-                            token_trees.push(\n-                                tt::Leaf::from(tt::Punct { char, spacing: tt::Spacing::Joint })\n-                                    .into(),\n-                            );\n-                        }\n-                        prev = Some(char)\n-                    }\n-                    if let Some(char) = prev {\n-                        let spacing = match child_iter.peek() {\n-                            Some(SyntaxElement::Token(token)) => {\n-                                if token.kind().is_punct() {\n-                                    tt::Spacing::Joint\n-                                } else {\n-                                    tt::Spacing::Alone\n-                                }\n+                    assert!(token.text().len() == 1, \"Input ast::token punct must be single char.\");\n+                    let char = token.text().chars().next().unwrap();\n+\n+                    let spacing = match child_iter.peek() {\n+                        Some(SyntaxElement::Token(token)) => {\n+                            if token.kind().is_punct() {\n+                                tt::Spacing::Joint\n+                            } else {\n+                                tt::Spacing::Alone\n                             }\n-                            _ => tt::Spacing::Alone,\n-                        };\n+                        }\n+                        _ => tt::Spacing::Alone,\n+                    };\n \n-                        token_trees.push(tt::Leaf::from(tt::Punct { char, spacing }).into());\n-                    }\n+                    token_trees.push(tt::Leaf::from(tt::Punct { char, spacing }).into());\n                 } else {\n                     let child: tt::TokenTree = if token.kind() == SyntaxKind::TRUE_KW\n                         || token.kind() == SyntaxKind::FALSE_KW\n@@ -224,6 +215,15 @@ impl<'a, Q: Querier> TtTreeSink<'a, Q> {\n     }\n }\n \n+fn is_delimiter(kind: SyntaxKind) -> bool {\n+    use SyntaxKind::*;\n+\n+    match kind {\n+        L_PAREN | L_BRACK | L_CURLY | R_PAREN | R_BRACK | R_CURLY => true,\n+        _ => false,\n+    }\n+}\n+\n impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n     fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         if kind == L_DOLLAR || kind == R_DOLLAR {\n@@ -240,14 +240,18 @@ impl<'a, Q: Querier> TreeSink for TtTreeSink<'a, Q> {\n         self.buf.clear();\n         self.inner.token(kind, text);\n \n-        // // Add a white space to token\n-        // let (last_kind, _, last_joint_to_next ) = self.src_querier.token(self.token_pos-n_tokens as usize);\n-        // if !last_joint_to_next && last_kind.is_punct() {\n-        //     let (cur_kind, _, _ ) = self.src_querier.token(self.token_pos);\n-        //     if cur_kind.is_punct() {\n-        //         self.inner.token(WHITESPACE, \" \".into());\n-        //     }\n-        // }\n+        // Add a white space between tokens, only if both are not delimiters\n+        if !is_delimiter(kind) {\n+            let (last_kind, _, last_joint_to_next) = self.src_querier.token(self.token_pos - 1);\n+            if !last_joint_to_next && last_kind.is_punct() {\n+                let (cur_kind, _, _) = self.src_querier.token(self.token_pos);\n+                if !is_delimiter(cur_kind) {\n+                    if cur_kind.is_punct() {\n+                        self.inner.token(WHITESPACE, \" \".into());\n+                    }\n+                }\n+            }\n+        }\n     }\n \n     fn start_node(&mut self, kind: SyntaxKind) {"}, {"sha": "8f15d215b6be54bff60a61aa96e988f495b8730b", "filename": "crates/ra_mbe/src/tt_cursor.rs", "status": "modified", "additions": 45, "deletions": 1, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b0e7022afe17f35fd0f6960a279e375b19061919/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Ftt_cursor.rs?ref=b0e7022afe17f35fd0f6960a279e375b19061919", "patch": "@@ -1,6 +1,5 @@\n use crate::ParseError;\n use crate::subtree_parser::Parser;\n-use crate::subtree_source::TokenPeek;\n use smallvec::{SmallVec, smallvec};\n \n #[derive(Debug, Clone)]\n@@ -262,3 +261,48 @@ impl<'a> TtCursor<'a> {\n         self.pos = memento.pos;\n     }\n }\n+\n+pub(crate) struct TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    iter: itertools::MultiPeek<I>,\n+}\n+\n+// helper function\n+fn to_punct(tt: &tt::TokenTree) -> Option<&tt::Punct> {\n+    if let tt::TokenTree::Leaf(tt::Leaf::Punct(pp)) = tt {\n+        return Some(pp);\n+    }\n+    None\n+}\n+\n+impl<'a, I> TokenPeek<'a, I>\n+where\n+    I: Iterator<Item = &'a tt::TokenTree>,\n+{\n+    pub fn new(iter: I) -> Self {\n+        TokenPeek { iter: itertools::multipeek(iter) }\n+    }\n+\n+    pub fn current_punct2(&mut self, p: &tt::Punct) -> Option<((char, char), bool)> {\n+        if p.spacing != tt::Spacing::Joint {\n+            return None;\n+        }\n+\n+        self.iter.reset_peek();\n+        let p1 = to_punct(self.iter.peek()?)?;\n+        Some(((p.char, p1.char), p1.spacing == tt::Spacing::Joint))\n+    }\n+\n+    pub fn current_punct3(&mut self, p: &tt::Punct) -> Option<((char, char, char), bool)> {\n+        self.current_punct2(p).and_then(|((p0, p1), last_joint)| {\n+            if !last_joint {\n+                None\n+            } else {\n+                let p2 = to_punct(*self.iter.peek()?)?;\n+                Some(((p0, p1, p2.char), p2.spacing == tt::Spacing::Joint))\n+            }\n+        })\n+    }\n+}"}]}