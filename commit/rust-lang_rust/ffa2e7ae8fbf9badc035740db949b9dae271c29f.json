{"sha": "ffa2e7ae8fbf9badc035740db949b9dae271c29f", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZmYTJlN2FlOGZiZjliYWRjMDM1NzQwZGI5NDliOWRhZTI3MWMyOWY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-10-24T19:23:32Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-10-24T19:23:32Z"}, "message": "Auto merge of #77255 - Aaron1011:feature/collect-attr-tokens, r=petrochenkov\n\nUnconditionally capture tokens for attributes.\n\nThis allows us to avoid synthesizing tokens in `prepend_attr`, since we\nhave the original tokens available.\n\nWe still need to synthesize tokens when expanding `cfg_attr`,\nbut this is an unavoidable consequence of the syntax of `cfg_attr` -\nthe user does not supply the `#` and `[]` tokens that a `cfg_attr`\nexpands to.\n\nThis is based on PR https://github.com/rust-lang/rust/pull/77250 - this PR exposes a bug in the current `collect_tokens` implementation, which is fixed by the rewrite.", "tree": {"sha": "828c3a5e26b4b35d40aa7cd43ecabcf972892c89", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/828c3a5e26b4b35d40aa7cd43ecabcf972892c89"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ffa2e7ae8fbf9badc035740db949b9dae271c29f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ffa2e7ae8fbf9badc035740db949b9dae271c29f", "html_url": "https://github.com/rust-lang/rust/commit/ffa2e7ae8fbf9badc035740db949b9dae271c29f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ffa2e7ae8fbf9badc035740db949b9dae271c29f/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "89fdb30892dbe330730ad1a1c1fe45b9046c2973", "url": "https://api.github.com/repos/rust-lang/rust/commits/89fdb30892dbe330730ad1a1c1fe45b9046c2973", "html_url": "https://github.com/rust-lang/rust/commit/89fdb30892dbe330730ad1a1c1fe45b9046c2973"}, {"sha": "5c7d8d049c88fe58fb4cf67f47e69ad5e6995e28", "url": "https://api.github.com/repos/rust-lang/rust/commits/5c7d8d049c88fe58fb4cf67f47e69ad5e6995e28", "html_url": "https://github.com/rust-lang/rust/commit/5c7d8d049c88fe58fb4cf67f47e69ad5e6995e28"}], "stats": {"total": 389, "additions": 251, "deletions": 138}, "files": [{"sha": "7224b482ed780fc1348c5f031879bbe577038d96", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -2423,6 +2423,7 @@ pub struct Attribute {\n     /// or the construct this attribute is contained within (inner).\n     pub style: AttrStyle,\n     pub span: Span,\n+    pub tokens: Option<LazyTokenStream>,\n }\n \n #[derive(Clone, Encodable, Decodable, Debug)]"}, {"sha": "34b03382c52318fdc9536d3ca472260bd8cf5b5a", "filename": "compiler/rustc_ast/src/attr/mod.rs", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -325,7 +325,7 @@ pub fn mk_attr(style: AttrStyle, path: Path, args: MacArgs, span: Span) -> Attri\n }\n \n pub fn mk_attr_from_item(style: AttrStyle, item: AttrItem, span: Span) -> Attribute {\n-    Attribute { kind: AttrKind::Normal(item), id: mk_attr_id(), style, span }\n+    Attribute { kind: AttrKind::Normal(item), id: mk_attr_id(), style, span, tokens: None }\n }\n \n /// Returns an inner attribute with the given value and span.\n@@ -344,7 +344,13 @@ pub fn mk_doc_comment(\n     data: Symbol,\n     span: Span,\n ) -> Attribute {\n-    Attribute { kind: AttrKind::DocComment(comment_kind, data), id: mk_attr_id(), style, span }\n+    Attribute {\n+        kind: AttrKind::DocComment(comment_kind, data),\n+        id: mk_attr_id(),\n+        style,\n+        span,\n+        tokens: None,\n+    }\n }\n \n pub fn list_contains_name(items: &[NestedMetaItem], name: Symbol) -> bool {"}, {"sha": "166d36ce4243305aa5f414c7843e9395e7ffc2d7", "filename": "compiler/rustc_ast/src/mut_visit.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -577,7 +577,7 @@ pub fn noop_visit_local<T: MutVisitor>(local: &mut P<Local>, vis: &mut T) {\n }\n \n pub fn noop_visit_attribute<T: MutVisitor>(attr: &mut Attribute, vis: &mut T) {\n-    let Attribute { kind, id: _, style: _, span } = attr;\n+    let Attribute { kind, id: _, style: _, span, tokens: _ } = attr;\n     match kind {\n         AttrKind::Normal(AttrItem { path, args, tokens: _ }) => {\n             vis.visit_path(path);"}, {"sha": "a6ac056b93b5e265c124be759705b9db2e2594ce", "filename": "compiler/rustc_ast_lowering/src/expr.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast_lowering%2Fsrc%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast_lowering%2Fsrc%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_lowering%2Fsrc%2Fexpr.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -210,9 +210,9 @@ impl<'hir> LoweringContext<'_, 'hir> {\n                         ex.span = e.span;\n                     }\n                     // Merge attributes into the inner expression.\n-                    let mut attrs = e.attrs.clone();\n+                    let mut attrs: Vec<_> = e.attrs.iter().map(|a| self.lower_attr(a)).collect();\n                     attrs.extend::<Vec<_>>(ex.attrs.into());\n-                    ex.attrs = attrs;\n+                    ex.attrs = attrs.into();\n                     return ex;\n                 }\n \n@@ -1471,13 +1471,15 @@ impl<'hir> LoweringContext<'_, 'hir> {\n             hir::MatchSource::ForLoopDesugar,\n         ));\n \n+        let attrs: Vec<_> = e.attrs.iter().map(|a| self.lower_attr(a)).collect();\n+\n         // This is effectively `{ let _result = ...; _result }`.\n         // The construct was introduced in #21984 and is necessary to make sure that\n         // temporaries in the `head` expression are dropped and do not leak to the\n         // surrounding scope of the `match` since the `match` is not a terminating scope.\n         //\n         // Also, add the attributes to the outer returned expr node.\n-        self.expr_drop_temps_mut(desugared_span, match_expr, e.attrs.clone())\n+        self.expr_drop_temps_mut(desugared_span, match_expr, attrs.into())\n     }\n \n     /// Desugar `ExprKind::Try` from: `<expr>?` into:"}, {"sha": "361bccd7a252c3715abb6f8288c0394b37f8dca9", "filename": "compiler/rustc_ast_lowering/src/lib.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -972,7 +972,8 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n             AttrKind::DocComment(comment_kind, data) => AttrKind::DocComment(comment_kind, data),\n         };\n \n-        Attribute { kind, id: attr.id, style: attr.style, span: attr.span }\n+        // Tokens aren't needed after macro expansion and parsing\n+        Attribute { kind, id: attr.id, style: attr.style, span: attr.span, tokens: None }\n     }\n \n     fn lower_mac_args(&mut self, args: &MacArgs) -> MacArgs {\n@@ -1713,7 +1714,7 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n                 pat: self.lower_pat(&l.pat),\n                 init,\n                 span: l.span,\n-                attrs: l.attrs.clone(),\n+                attrs: l.attrs.iter().map(|a| self.lower_attr(a)).collect::<Vec<_>>().into(),\n                 source: hir::LocalSource::Normal,\n             },\n             ids,"}, {"sha": "747e48ece704cbb11b06ec19635968fb3625f312", "filename": "compiler/rustc_builtin_macros/src/cmdline_attrs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_builtin_macros%2Fsrc%2Fcmdline_attrs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_builtin_macros%2Fsrc%2Fcmdline_attrs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fcmdline_attrs.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -15,7 +15,7 @@ pub fn inject(mut krate: ast::Crate, parse_sess: &ParseSess, attrs: &[String]) -\n         );\n \n         let start_span = parser.token.span;\n-        let AttrItem { path, args, tokens: _ } = match parser.parse_attr_item() {\n+        let AttrItem { path, args, tokens: _ } = match parser.parse_attr_item(false) {\n             Ok(ai) => ai,\n             Err(mut err) => {\n                 err.emit();"}, {"sha": "3551b92967c4716520c7beaf0f3819e0b21df8d2", "filename": "compiler/rustc_expand/src/config.rs", "status": "modified", "additions": 34, "deletions": 1, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -3,10 +3,13 @@\n use rustc_ast::attr::HasAttrs;\n use rustc_ast::mut_visit::*;\n use rustc_ast::ptr::P;\n+use rustc_ast::token::{DelimToken, Token, TokenKind};\n+use rustc_ast::tokenstream::{DelimSpan, LazyTokenStreamInner, Spacing, TokenStream, TokenTree};\n use rustc_ast::{self as ast, AttrItem, Attribute, MetaItem};\n use rustc_attr as attr;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::map_in_place::MapInPlace;\n+use rustc_data_structures::sync::Lrc;\n use rustc_errors::{error_code, struct_span_err, Applicability, Handler};\n use rustc_feature::{Feature, Features, State as FeatureState};\n use rustc_feature::{\n@@ -289,7 +292,37 @@ impl<'a> StripUnconfigured<'a> {\n         expanded_attrs\n             .into_iter()\n             .flat_map(|(item, span)| {\n-                let attr = attr::mk_attr_from_item(attr.style, item, span);\n+                let orig_tokens =\n+                    attr.tokens.as_ref().unwrap_or_else(|| panic!(\"Missing tokens for {:?}\", attr));\n+\n+                // We are taking an attribute of the form `#[cfg_attr(pred, attr)]`\n+                // and producing an attribute of the form `#[attr]`. We\n+                // have captured tokens for `attr` itself, but we need to\n+                // synthesize tokens for the wrapper `#` and `[]`, which\n+                // we do below.\n+\n+                // Use the `#` in `#[cfg_attr(pred, attr)]` as the `#` token\n+                // for `attr` when we expand it to `#[attr]`\n+                let pound_token = orig_tokens.into_token_stream().trees().next().unwrap();\n+                if !matches!(pound_token, TokenTree::Token(Token { kind: TokenKind::Pound, .. })) {\n+                    panic!(\"Bad tokens for attribute {:?}\", attr);\n+                }\n+                // We don't really have a good span to use for the syntheized `[]`\n+                // in `#[attr]`, so just use the span of the `#` token.\n+                let bracket_group = TokenTree::Delimited(\n+                    DelimSpan::from_single(pound_token.span()),\n+                    DelimToken::Bracket,\n+                    item.tokens\n+                        .clone()\n+                        .unwrap_or_else(|| panic!(\"Missing tokens for {:?}\", item))\n+                        .into_token_stream(),\n+                );\n+\n+                let mut attr = attr::mk_attr_from_item(attr.style, item, span);\n+                attr.tokens = Some(Lrc::new(LazyTokenStreamInner::Ready(TokenStream::new(vec![\n+                    (pound_token, Spacing::Alone),\n+                    (bracket_group, Spacing::Alone),\n+                ]))));\n                 self.process_cfg_attr(attr)\n             })\n             .collect()"}, {"sha": "ce198b3a41c9e4730e2b3bab408546fd9405467e", "filename": "compiler/rustc_expand/src/expand.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -1785,6 +1785,7 @@ impl<'a, 'b> MutVisitor for InvocationCollector<'a, 'b> {\n                 span: at.span,\n                 id: at.id,\n                 style: at.style,\n+                tokens: None,\n             };\n         } else {\n             noop_visit_attribute(at, self)"}, {"sha": "bbb47a6e8071e70e15714151c9437b9b1cb889cd", "filename": "compiler/rustc_interface/src/passes.rs", "status": "modified", "additions": 70, "deletions": 2, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_interface%2Fsrc%2Fpasses.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -2,8 +2,9 @@ use crate::interface::{Compiler, Result};\n use crate::proc_macro_decls;\n use crate::util;\n \n-use rustc_ast::mut_visit::MutVisitor;\n-use rustc_ast::{self as ast, visit};\n+use rustc_ast::mut_visit::{self, MutVisitor};\n+use rustc_ast::ptr::P;\n+use rustc_ast::{self as ast, token, visit};\n use rustc_codegen_ssa::back::link::emit_metadata;\n use rustc_codegen_ssa::traits::CodegenBackend;\n use rustc_data_structures::sync::{par_iter, Lrc, OnceCell, ParallelIterator, WorkerLocal};\n@@ -36,6 +37,7 @@ use rustc_span::symbol::Symbol;\n use rustc_span::{FileName, RealFileName};\n use rustc_trait_selection::traits;\n use rustc_typeck as typeck;\n+use smallvec::SmallVec;\n use tracing::{info, warn};\n \n use rustc_serialize::json;\n@@ -50,6 +52,64 @@ use std::path::PathBuf;\n use std::rc::Rc;\n use std::{env, fs, iter, mem};\n \n+/// Remove alls `LazyTokenStreams` from an AST struct\n+/// Normally, this is done during AST lowering. However,\n+/// printing the AST JSON requires us to serialize\n+/// the entire AST, and we don't want to serialize\n+/// a `LazyTokenStream`.\n+struct TokenStripper;\n+impl mut_visit::MutVisitor for TokenStripper {\n+    fn flat_map_item(&mut self, mut i: P<ast::Item>) -> SmallVec<[P<ast::Item>; 1]> {\n+        i.tokens = None;\n+        mut_visit::noop_flat_map_item(i, self)\n+    }\n+    fn visit_block(&mut self, b: &mut P<ast::Block>) {\n+        b.tokens = None;\n+        mut_visit::noop_visit_block(b, self);\n+    }\n+    fn flat_map_stmt(&mut self, mut stmt: ast::Stmt) -> SmallVec<[ast::Stmt; 1]> {\n+        stmt.tokens = None;\n+        mut_visit::noop_flat_map_stmt(stmt, self)\n+    }\n+    fn visit_pat(&mut self, p: &mut P<ast::Pat>) {\n+        p.tokens = None;\n+        mut_visit::noop_visit_pat(p, self);\n+    }\n+    fn visit_ty(&mut self, ty: &mut P<ast::Ty>) {\n+        ty.tokens = None;\n+        mut_visit::noop_visit_ty(ty, self);\n+    }\n+    fn visit_attribute(&mut self, attr: &mut ast::Attribute) {\n+        attr.tokens = None;\n+        if let ast::AttrKind::Normal(ast::AttrItem { tokens, .. }) = &mut attr.kind {\n+            *tokens = None;\n+        }\n+        mut_visit::noop_visit_attribute(attr, self);\n+    }\n+\n+    fn visit_interpolated(&mut self, nt: &mut token::Nonterminal) {\n+        if let token::Nonterminal::NtMeta(meta) = nt {\n+            meta.tokens = None;\n+        }\n+        // Handles all of the other cases\n+        mut_visit::noop_visit_interpolated(nt, self);\n+    }\n+\n+    fn visit_path(&mut self, p: &mut ast::Path) {\n+        p.tokens = None;\n+        mut_visit::noop_visit_path(p, self);\n+    }\n+    fn visit_vis(&mut self, vis: &mut ast::Visibility) {\n+        vis.tokens = None;\n+        mut_visit::noop_visit_vis(vis, self);\n+    }\n+    fn visit_expr(&mut self, e: &mut P<ast::Expr>) {\n+        e.tokens = None;\n+        mut_visit::noop_visit_expr(e, self);\n+    }\n+    fn visit_mac(&mut self, _mac: &mut ast::MacCall) {}\n+}\n+\n pub fn parse<'a>(sess: &'a Session, input: &Input) -> PResult<'a, ast::Crate> {\n     let krate = sess.time(\"parse_crate\", || match input {\n         Input::File(file) => parse_crate_from_file(file, &sess.parse_sess),\n@@ -59,6 +119,10 @@ pub fn parse<'a>(sess: &'a Session, input: &Input) -> PResult<'a, ast::Crate> {\n     })?;\n \n     if sess.opts.debugging_opts.ast_json_noexpand {\n+        // Set any `token` fields to `None` before\n+        // we display the AST.\n+        let mut krate = krate.clone();\n+        TokenStripper.visit_crate(&mut krate);\n         println!(\"{}\", json::as_json(&krate));\n     }\n \n@@ -379,6 +443,10 @@ fn configure_and_expand_inner<'a>(\n     }\n \n     if sess.opts.debugging_opts.ast_json {\n+        // Set any `token` fields to `None` before\n+        // we display the AST.\n+        let mut krate = krate.clone();\n+        TokenStripper.visit_crate(&mut krate);\n         println!(\"{}\", json::as_json(&krate));\n     }\n "}, {"sha": "cab2ca2919f9fab321d316da4be97036acd27ed9", "filename": "compiler/rustc_middle/src/ich/impls_syntax.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_middle%2Fsrc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_middle%2Fsrc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fich%2Fimpls_syntax.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -40,11 +40,12 @@ impl<'ctx> rustc_ast::HashStableContext for StableHashingContext<'ctx> {\n         debug_assert!(!attr.ident().map_or(false, |ident| self.is_ignored_attr(ident.name)));\n         debug_assert!(!attr.is_doc_comment());\n \n-        let ast::Attribute { kind, id: _, style, span } = attr;\n+        let ast::Attribute { kind, id: _, style, span, tokens } = attr;\n         if let ast::AttrKind::Normal(item) = kind {\n             item.hash_stable(self, hasher);\n             style.hash_stable(self, hasher);\n             span.hash_stable(self, hasher);\n+            tokens.as_ref().expect_none(\"Tokens should have been removed during lowering!\");\n         } else {\n             unreachable!();\n         }"}, {"sha": "ba416be6b38d3e8589cc0698229f54135bba5004", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 8, "deletions": 47, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -252,9 +252,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     let convert_tokens = |tokens: Option<LazyTokenStream>| tokens.map(|t| t.into_token_stream());\n \n     let tokens = match *nt {\n-        Nonterminal::NtItem(ref item) => {\n-            prepend_attrs(sess, &item.attrs, item.tokens.as_ref(), span)\n-        }\n+        Nonterminal::NtItem(ref item) => prepend_attrs(&item.attrs, item.tokens.as_ref()),\n         Nonterminal::NtBlock(ref block) => convert_tokens(block.tokens.clone()),\n         Nonterminal::NtStmt(ref stmt) => {\n             // FIXME: We currently only collect tokens for `:stmt`\n@@ -279,7 +277,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n             if expr.tokens.is_none() {\n                 debug!(\"missing tokens for expr {:?}\", expr);\n             }\n-            prepend_attrs(sess, &expr.attrs, expr.tokens.as_ref(), span)\n+            prepend_attrs(&expr.attrs, expr.tokens.as_ref())\n         }\n     };\n \n@@ -603,10 +601,8 @@ fn token_probably_equal_for_proc_macro(first: &Token, other: &Token) -> bool {\n }\n \n fn prepend_attrs(\n-    sess: &ParseSess,\n     attrs: &[ast::Attribute],\n     tokens: Option<&tokenstream::LazyTokenStream>,\n-    span: rustc_span::Span,\n ) -> Option<tokenstream::TokenStream> {\n     let tokens = tokens?.clone().into_token_stream();\n     if attrs.is_empty() {\n@@ -619,47 +615,12 @@ fn prepend_attrs(\n             ast::AttrStyle::Outer,\n             \"inner attributes should prevent cached tokens from existing\"\n         );\n-\n-        let source = pprust::attribute_to_string(attr);\n-        let macro_filename = FileName::macro_expansion_source_code(&source);\n-\n-        let item = match attr.kind {\n-            ast::AttrKind::Normal(ref item) => item,\n-            ast::AttrKind::DocComment(..) => {\n-                let stream = parse_stream_from_source_str(macro_filename, source, sess, Some(span));\n-                builder.push(stream);\n-                continue;\n-            }\n-        };\n-\n-        // synthesize # [ $path $tokens ] manually here\n-        let mut brackets = tokenstream::TokenStreamBuilder::new();\n-\n-        // For simple paths, push the identifier directly\n-        if item.path.segments.len() == 1 && item.path.segments[0].args.is_none() {\n-            let ident = item.path.segments[0].ident;\n-            let token = token::Ident(ident.name, ident.as_str().starts_with(\"r#\"));\n-            brackets.push(tokenstream::TokenTree::token(token, ident.span));\n-\n-        // ... and for more complicated paths, fall back to a reparse hack that\n-        // should eventually be removed.\n-        } else {\n-            let stream = parse_stream_from_source_str(macro_filename, source, sess, Some(span));\n-            brackets.push(stream);\n-        }\n-\n-        brackets.push(item.args.outer_tokens());\n-\n-        // The span we list here for `#` and for `[ ... ]` are both wrong in\n-        // that it encompasses more than each token, but it hopefully is \"good\n-        // enough\" for now at least.\n-        builder.push(tokenstream::TokenTree::token(token::Pound, attr.span));\n-        let delim_span = tokenstream::DelimSpan::from_single(attr.span);\n-        builder.push(tokenstream::TokenTree::Delimited(\n-            delim_span,\n-            token::DelimToken::Bracket,\n-            brackets.build(),\n-        ));\n+        builder.push(\n+            attr.tokens\n+                .clone()\n+                .unwrap_or_else(|| panic!(\"Attribute {:?} is missing tokens!\", attr))\n+                .into_token_stream(),\n+        );\n     }\n     builder.push(tokens.clone());\n     Some(builder.build())"}, {"sha": "053b7e0b75fe4cf731f4d6c59c80bc92f6c03f89", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 84, "deletions": 51, "changes": 135, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -30,41 +30,53 @@ impl<'a> Parser<'a> {\n         let mut just_parsed_doc_comment = false;\n         loop {\n             debug!(\"parse_outer_attributes: self.token={:?}\", self.token);\n-            if self.check(&token::Pound) {\n-                let inner_error_reason = if just_parsed_doc_comment {\n-                    \"an inner attribute is not permitted following an outer doc comment\"\n-                } else if !attrs.is_empty() {\n-                    \"an inner attribute is not permitted following an outer attribute\"\n-                } else {\n-                    DEFAULT_UNEXPECTED_INNER_ATTR_ERR_MSG\n-                };\n-                let inner_parse_policy = InnerAttrPolicy::Forbidden {\n-                    reason: inner_error_reason,\n-                    saw_doc_comment: just_parsed_doc_comment,\n-                    prev_attr_sp: attrs.last().map(|a| a.span),\n-                };\n-                let attr = self.parse_attribute_with_inner_parse_policy(inner_parse_policy)?;\n-                attrs.push(attr);\n-                just_parsed_doc_comment = false;\n+            let (attr, tokens) = if self.check(&token::Pound) {\n+                self.collect_tokens(|this| {\n+                    let inner_error_reason = if just_parsed_doc_comment {\n+                        \"an inner attribute is not permitted following an outer doc comment\"\n+                    } else if !attrs.is_empty() {\n+                        \"an inner attribute is not permitted following an outer attribute\"\n+                    } else {\n+                        DEFAULT_UNEXPECTED_INNER_ATTR_ERR_MSG\n+                    };\n+                    let inner_parse_policy = InnerAttrPolicy::Forbidden {\n+                        reason: inner_error_reason,\n+                        saw_doc_comment: just_parsed_doc_comment,\n+                        prev_attr_sp: attrs.last().map(|a| a.span),\n+                    };\n+                    let attr = this.parse_attribute_with_inner_parse_policy(inner_parse_policy)?;\n+                    just_parsed_doc_comment = false;\n+                    Ok(Some(attr))\n+                })?\n             } else if let token::DocComment(comment_kind, attr_style, data) = self.token.kind {\n-                let attr = attr::mk_doc_comment(comment_kind, attr_style, data, self.token.span);\n-                if attr.style != ast::AttrStyle::Outer {\n-                    self.sess\n-                        .span_diagnostic\n-                        .struct_span_err_with_code(\n-                            self.token.span,\n-                            \"expected outer doc comment\",\n-                            error_code!(E0753),\n-                        )\n-                        .note(\n-                            \"inner doc comments like this (starting with \\\n-                             `//!` or `/*!`) can only appear before items\",\n-                        )\n-                        .emit();\n-                }\n+                self.collect_tokens(|this| {\n+                    let attr =\n+                        attr::mk_doc_comment(comment_kind, attr_style, data, this.token.span);\n+                    if attr.style != ast::AttrStyle::Outer {\n+                        this.sess\n+                            .span_diagnostic\n+                            .struct_span_err_with_code(\n+                                this.token.span,\n+                                \"expected outer doc comment\",\n+                                error_code!(E0753),\n+                            )\n+                            .note(\n+                                \"inner doc comments like this (starting with \\\n+                                 `//!` or `/*!`) can only appear before items\",\n+                            )\n+                            .emit();\n+                    }\n+                    this.bump();\n+                    just_parsed_doc_comment = true;\n+                    Ok(Some(attr))\n+                })?\n+            } else {\n+                (None, None)\n+            };\n+\n+            if let Some(mut attr) = attr {\n+                attr.tokens = tokens;\n                 attrs.push(attr);\n-                self.bump();\n-                just_parsed_doc_comment = true;\n             } else {\n                 break;\n             }\n@@ -99,7 +111,7 @@ impl<'a> Parser<'a> {\n                 if self.eat(&token::Not) { ast::AttrStyle::Inner } else { ast::AttrStyle::Outer };\n \n             self.expect(&token::OpenDelim(token::Bracket))?;\n-            let item = self.parse_attr_item()?;\n+            let item = self.parse_attr_item(false)?;\n             self.expect(&token::CloseDelim(token::Bracket))?;\n             let attr_sp = lo.to(self.prev_token.span);\n \n@@ -148,7 +160,7 @@ impl<'a> Parser<'a> {\n     ///     PATH\n     ///     PATH `=` UNSUFFIXED_LIT\n     /// The delimiters or `=` are still put into the resulting token stream.\n-    pub fn parse_attr_item(&mut self) -> PResult<'a, ast::AttrItem> {\n+    pub fn parse_attr_item(&mut self, capture_tokens: bool) -> PResult<'a, ast::AttrItem> {\n         let item = match self.token.kind {\n             token::Interpolated(ref nt) => match **nt {\n                 Nonterminal::NtMeta(ref item) => Some(item.clone().into_inner()),\n@@ -160,9 +172,18 @@ impl<'a> Parser<'a> {\n             self.bump();\n             item\n         } else {\n-            let path = self.parse_path(PathStyle::Mod)?;\n-            let args = self.parse_attr_args()?;\n-            ast::AttrItem { path, args, tokens: None }\n+            let do_parse = |this: &mut Self| {\n+                let path = this.parse_path(PathStyle::Mod)?;\n+                let args = this.parse_attr_args()?;\n+                Ok(ast::AttrItem { path, args, tokens: None })\n+            };\n+            if capture_tokens {\n+                let (mut item, tokens) = self.collect_tokens(do_parse)?;\n+                item.tokens = tokens;\n+                item\n+            } else {\n+                do_parse(self)?\n+            }\n         })\n     }\n \n@@ -175,19 +196,31 @@ impl<'a> Parser<'a> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n             // Only try to parse if it is an inner attribute (has `!`).\n-            if self.check(&token::Pound) && self.look_ahead(1, |t| t == &token::Not) {\n-                let attr = self.parse_attribute(true)?;\n-                assert_eq!(attr.style, ast::AttrStyle::Inner);\n-                attrs.push(attr);\n-            } else if let token::DocComment(comment_kind, attr_style, data) = self.token.kind {\n-                // We need to get the position of this token before we bump.\n-                let attr = attr::mk_doc_comment(comment_kind, attr_style, data, self.token.span);\n-                if attr.style == ast::AttrStyle::Inner {\n-                    attrs.push(attr);\n-                    self.bump();\n+            let (attr, tokens) =\n+                if self.check(&token::Pound) && self.look_ahead(1, |t| t == &token::Not) {\n+                    self.collect_tokens(|this| {\n+                        let attr = this.parse_attribute(true)?;\n+                        assert_eq!(attr.style, ast::AttrStyle::Inner);\n+                        Ok(Some(attr))\n+                    })?\n+                } else if let token::DocComment(comment_kind, attr_style, data) = self.token.kind {\n+                    self.collect_tokens(|this| {\n+                        // We need to get the position of this token before we bump.\n+                        let attr =\n+                            attr::mk_doc_comment(comment_kind, attr_style, data, this.token.span);\n+                        if attr.style == ast::AttrStyle::Inner {\n+                            this.bump();\n+                            Ok(Some(attr))\n+                        } else {\n+                            Ok(None)\n+                        }\n+                    })?\n                 } else {\n-                    break;\n-                }\n+                    (None, None)\n+                };\n+            if let Some(mut attr) = attr {\n+                attr.tokens = tokens;\n+                attrs.push(attr);\n             } else {\n                 break;\n             }\n@@ -220,7 +253,7 @@ impl<'a> Parser<'a> {\n         let mut expanded_attrs = Vec::with_capacity(1);\n         while self.token.kind != token::Eof {\n             let lo = self.token.span;\n-            let item = self.parse_attr_item()?;\n+            let item = self.parse_attr_item(true)?;\n             expanded_attrs.push((item, lo.to(self.prev_token.span)));\n             if !self.eat(&token::Comma) {\n                 break;"}, {"sha": "c44e00f861de6c17ad5953663924abeaac75eddc", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -1116,7 +1116,7 @@ impl<'a> Parser<'a> {\n     ) -> PResult<'a, P<Expr>> {\n         if needs_tokens {\n             let (mut expr, tokens) = self.collect_tokens(f)?;\n-            expr.tokens = Some(tokens);\n+            expr.tokens = tokens;\n             Ok(expr)\n         } else {\n             f(self)"}, {"sha": "e57a2e42b5dded7270008fc427083d428f6ce01f", "filename": "compiler/rustc_parse/src/parser/item.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -151,7 +151,7 @@ impl<'a> Parser<'a> {\n         if let Some(tokens) = tokens {\n             if let Some(item) = &mut item {\n                 if !item.attrs.iter().any(|attr| attr.style == AttrStyle::Inner) {\n-                    item.tokens = Some(tokens);\n+                    item.tokens = tokens;\n                 }\n             }\n         }"}, {"sha": "175dd3fa53a6eb727c317dbb5f7190761ab25e38", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -1178,8 +1178,9 @@ impl<'a> Parser<'a> {\n \n     /// Records all tokens consumed by the provided callback,\n     /// including the current token. These tokens are collected\n-    /// into a `TokenStream`, and returned along with the result\n-    /// of the callback.\n+    /// into a `LazyTokenStream`, and returned along with the result\n+    /// of the callback. The returned `LazyTokenStream` will be `None`\n+    /// if not tokens were captured.\n     ///\n     /// Note: If your callback consumes an opening delimiter\n     /// (including the case where you call `collect_tokens`\n@@ -1195,7 +1196,7 @@ impl<'a> Parser<'a> {\n     pub fn collect_tokens<R>(\n         &mut self,\n         f: impl FnOnce(&mut Self) -> PResult<'a, R>,\n-    ) -> PResult<'a, (R, LazyTokenStream)> {\n+    ) -> PResult<'a, (R, Option<LazyTokenStream>)> {\n         let start_token = (self.token.clone(), self.token_spacing);\n         let mut cursor_snapshot = self.token_cursor.clone();\n \n@@ -1205,6 +1206,11 @@ impl<'a> Parser<'a> {\n         let num_calls = new_calls - cursor_snapshot.num_next_calls;\n         let desugar_doc_comments = self.desugar_doc_comments;\n \n+        // We didn't capture any tokens\n+        if num_calls == 0 {\n+            return Ok((ret, None));\n+        }\n+\n         // Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n         // and `num_calls`, we can reconstruct the `TokenStream` seen\n         // by the callback. This allows us to avoid producing a `TokenStream`\n@@ -1233,7 +1239,7 @@ impl<'a> Parser<'a> {\n         };\n         let stream = LazyTokenStream::new(LazyTokenStreamInner::Lazy(Box::new(lazy_cb)));\n \n-        Ok((ret, stream))\n+        Ok((ret, Some(stream)))\n     }\n \n     /// `::{` or `::*`"}, {"sha": "98fb1c829251072dc012f11f271a62ce9eaf7906", "filename": "compiler/rustc_parse/src/parser/nonterminal.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -103,7 +103,7 @@ impl<'a> Parser<'a> {\n                     // If we captured tokens during parsing (due to outer attributes),\n                     // use those.\n                     if item.tokens.is_none() {\n-                        item.tokens = Some(tokens);\n+                        item.tokens = tokens;\n                     }\n                     token::NtItem(item)\n                 }\n@@ -115,7 +115,7 @@ impl<'a> Parser<'a> {\n                 let (mut block, tokens) = self.collect_tokens(|this| this.parse_block())?;\n                 // We have have eaten an NtBlock, which could already have tokens\n                 if block.tokens.is_none() {\n-                    block.tokens = Some(tokens);\n+                    block.tokens = tokens;\n                 }\n                 token::NtBlock(block)\n             }\n@@ -124,7 +124,7 @@ impl<'a> Parser<'a> {\n                 match stmt {\n                     Some(mut s) => {\n                         if s.tokens.is_none() {\n-                            s.tokens = Some(tokens);\n+                            s.tokens = tokens;\n                         }\n                         token::NtStmt(s)\n                     }\n@@ -137,7 +137,7 @@ impl<'a> Parser<'a> {\n                 let (mut pat, tokens) = self.collect_tokens(|this| this.parse_pat(None))?;\n                 // We have have eaten an NtPat, which could already have tokens\n                 if pat.tokens.is_none() {\n-                    pat.tokens = Some(tokens);\n+                    pat.tokens = tokens;\n                 }\n                 token::NtPat(pat)\n             }\n@@ -146,7 +146,7 @@ impl<'a> Parser<'a> {\n                 // If we captured tokens during parsing (due to outer attributes),\n                 // use those.\n                 if expr.tokens.is_none() {\n-                    expr.tokens = Some(tokens);\n+                    expr.tokens = tokens;\n                 }\n                 token::NtExpr(expr)\n             }\n@@ -155,15 +155,15 @@ impl<'a> Parser<'a> {\n                     self.collect_tokens(|this| this.parse_literal_maybe_minus())?;\n                 // We have have eaten a nonterminal, which  could already have tokens\n                 if lit.tokens.is_none() {\n-                    lit.tokens = Some(tokens);\n+                    lit.tokens = tokens;\n                 }\n                 token::NtLiteral(lit)\n             }\n             NonterminalKind::Ty => {\n                 let (mut ty, tokens) = self.collect_tokens(|this| this.parse_ty())?;\n                 // We have an eaten an NtTy, which could already have tokens\n                 if ty.tokens.is_none() {\n-                    ty.tokens = Some(tokens);\n+                    ty.tokens = tokens;\n                 }\n                 token::NtTy(ty)\n             }\n@@ -183,15 +183,15 @@ impl<'a> Parser<'a> {\n                     self.collect_tokens(|this| this.parse_path(PathStyle::Type))?;\n                 // We have have eaten an NtPath, which could already have tokens\n                 if path.tokens.is_none() {\n-                    path.tokens = Some(tokens);\n+                    path.tokens = tokens;\n                 }\n                 token::NtPath(path)\n             }\n             NonterminalKind::Meta => {\n-                let (mut attr, tokens) = self.collect_tokens(|this| this.parse_attr_item())?;\n+                let (mut attr, tokens) = self.collect_tokens(|this| this.parse_attr_item(false))?;\n                 // We may have eaten a nonterminal, which could already have tokens\n                 if attr.tokens.is_none() {\n-                    attr.tokens = Some(tokens);\n+                    attr.tokens = tokens;\n                 }\n                 token::NtMeta(P(attr))\n             }\n@@ -201,7 +201,7 @@ impl<'a> Parser<'a> {\n                     self.collect_tokens(|this| this.parse_visibility(FollowedByType::Yes))?;\n                 // We may have etan an `NtVis`, which could already have tokens\n                 if vis.tokens.is_none() {\n-                    vis.tokens = Some(tokens);\n+                    vis.tokens = tokens;\n                 }\n                 token::NtVis(vis)\n             }"}, {"sha": "259206ba90718c9af11b30f13266e6fb379c4aa6", "filename": "src/test/ui/ast-json/ast-json-noexpand-output.stdout", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fast-json%2Fast-json-noexpand-output.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fast-json%2Fast-json-noexpand-output.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fast-json%2Fast-json-noexpand-output.stdout?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -1 +1 @@\n-{\"module\":{\"inner\":{\"lo\":0,\"hi\":0},\"unsafety\":\"No\",\"items\":[{\"attrs\":[],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"core\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null}],\"inline\":true},\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"crate_type\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":{\"variant\":\"Eq\",\"fields\":[{\"lo\":0,\"hi\":0},{\"0\":[[{\"variant\":\"Token\",\"fields\":[{\"kind\":{\"variant\":\"Literal\",\"fields\":[{\"kind\":\"Str\",\"symbol\":\"lib\",\"suffix\":null}]},\"span\":{\"lo\":0,\"hi\":0}}]},\"Alone\"]]}]},\"tokens\":null}]},\"id\":null,\"style\":\"Inner\",\"span\":{\"lo\":0,\"hi\":0}}],\"span\":{\"lo\":0,\"hi\":0},\"proc_macros\":[]}\n+{\"module\":{\"inner\":{\"lo\":0,\"hi\":0},\"unsafety\":\"No\",\"items\":[{\"attrs\":[],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"core\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null}],\"inline\":true},\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"crate_type\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":{\"variant\":\"Eq\",\"fields\":[{\"lo\":0,\"hi\":0},{\"0\":[[{\"variant\":\"Token\",\"fields\":[{\"kind\":{\"variant\":\"Literal\",\"fields\":[{\"kind\":\"Str\",\"symbol\":\"lib\",\"suffix\":null}]},\"span\":{\"lo\":0,\"hi\":0}}]},\"Alone\"]]}]},\"tokens\":null}]},\"id\":null,\"style\":\"Inner\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null}],\"span\":{\"lo\":0,\"hi\":0},\"proc_macros\":[]}"}, {"sha": "76e32044add18715055daadc60f010f5f52e4f33", "filename": "src/test/ui/ast-json/ast-json-output.stdout", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fast-json%2Fast-json-output.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fast-json%2Fast-json-output.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fast-json%2Fast-json-output.stdout?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -1 +1 @@\n-{\"module\":{\"inner\":{\"lo\":0,\"hi\":0},\"unsafety\":\"No\",\"items\":[{\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"prelude_import\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":\"Empty\",\"tokens\":null}]},\"id\":null,\"style\":\"Outer\",\"span\":{\"lo\":0,\"hi\":0}}],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"Use\",\"fields\":[{\"prefix\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"{{root}}\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"std\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"prelude\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"v1\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"kind\":\"Glob\",\"span\":{\"lo\":0,\"hi\":0}}]},\"tokens\":null},{\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"macro_use\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":\"Empty\",\"tokens\":null}]},\"id\":null,\"style\":\"Outer\",\"span\":{\"lo\":0,\"hi\":0}}],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"std\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null},{\"attrs\":[],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"core\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null}],\"inline\":true},\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"crate_type\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":{\"variant\":\"Eq\",\"fields\":[{\"lo\":0,\"hi\":0},{\"0\":[[{\"variant\":\"Token\",\"fields\":[{\"kind\":{\"variant\":\"Literal\",\"fields\":[{\"kind\":\"Str\",\"symbol\":\"lib\",\"suffix\":null}]},\"span\":{\"lo\":0,\"hi\":0}}]},\"Alone\"]]}]},\"tokens\":null}]},\"id\":null,\"style\":\"Inner\",\"span\":{\"lo\":0,\"hi\":0}}],\"span\":{\"lo\":0,\"hi\":0},\"proc_macros\":[]}\n+{\"module\":{\"inner\":{\"lo\":0,\"hi\":0},\"unsafety\":\"No\",\"items\":[{\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"prelude_import\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":\"Empty\",\"tokens\":null}]},\"id\":null,\"style\":\"Outer\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null}],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"Use\",\"fields\":[{\"prefix\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"{{root}}\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"std\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"prelude\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null},{\"ident\":{\"name\":\"v1\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"kind\":\"Glob\",\"span\":{\"lo\":0,\"hi\":0}}]},\"tokens\":null},{\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"macro_use\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":\"Empty\",\"tokens\":null}]},\"id\":null,\"style\":\"Outer\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null}],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"std\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null},{\"attrs\":[],\"id\":0,\"span\":{\"lo\":0,\"hi\":0},\"vis\":{\"kind\":\"Inherited\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null},\"ident\":{\"name\":\"core\",\"span\":{\"lo\":0,\"hi\":0}},\"kind\":{\"variant\":\"ExternCrate\",\"fields\":[null]},\"tokens\":null}],\"inline\":true},\"attrs\":[{\"kind\":{\"variant\":\"Normal\",\"fields\":[{\"path\":{\"span\":{\"lo\":0,\"hi\":0},\"segments\":[{\"ident\":{\"name\":\"crate_type\",\"span\":{\"lo\":0,\"hi\":0}},\"id\":0,\"args\":null}],\"tokens\":null},\"args\":{\"variant\":\"Eq\",\"fields\":[{\"lo\":0,\"hi\":0},{\"0\":[[{\"variant\":\"Token\",\"fields\":[{\"kind\":{\"variant\":\"Literal\",\"fields\":[{\"kind\":\"Str\",\"symbol\":\"lib\",\"suffix\":null}]},\"span\":{\"lo\":0,\"hi\":0}}]},\"Alone\"]]}]},\"tokens\":null}]},\"id\":null,\"style\":\"Inner\",\"span\":{\"lo\":0,\"hi\":0},\"tokens\":null}],\"span\":{\"lo\":0,\"hi\":0},\"proc_macros\":[]}"}, {"sha": "4c0810217bf33ea7491a27b9de77847df8b3997e", "filename": "src/test/ui/proc-macro/issue-75930-derive-cfg.stdout", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ffa2e7ae8fbf9badc035740db949b9dae271c29f/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout?ref=ffa2e7ae8fbf9badc035740db949b9dae271c29f", "patch": "@@ -26,7 +26,7 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:17:24: 17:40 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:17:1: 17:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n@@ -46,12 +46,12 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 span: $DIR/issue-75930-derive-cfg.rs:17:29: 17:40 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:17:24: 17:40 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:17:1: 17:2 (#0),\n     },\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:19:1: 19:17 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:19:1: 19:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n@@ -71,12 +71,12 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 span: $DIR/issue-75930-derive-cfg.rs:19:9: 19:16 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:19:1: 19:17 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:19:2: 19:17 (#0),\n     },\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:20:1: 20:19 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:20:1: 20:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n@@ -96,12 +96,12 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 span: $DIR/issue-75930-derive-cfg.rs:20:15: 20:18 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:20:1: 20:19 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:20:2: 20:19 (#0),\n     },\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:16:1: 16:19 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:16:1: 16:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n@@ -121,7 +121,7 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 span: $DIR/issue-75930-derive-cfg.rs:16:15: 16:18 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:16:1: 16:19 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:16:2: 16:19 (#0),\n     },\n     Ident {\n         ident: \"struct\","}]}