{"sha": "fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0", "node_id": "C_kwDOAAsO6NoAKGZiNGRiYTBhMTdiNmViMjQxYjRmZDM3MzJiOTc2YWIzOGZlMmNkYzA", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-26T02:12:58Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-09-26T03:50:13Z"}, "message": "Inline and remove `cook_lexer_token`.\n\nThis is a small performance win, alas.", "tree": {"sha": "2a1e13940867fa8260df9c73719e3c72fe81e4ed", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2a1e13940867fa8260df9c73719e3c72fe81e4ed"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0", "html_url": "https://github.com/rust-lang/rust/commit/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "da84f0f4c31914c14dd03628395e9c53f28b88b9", "url": "https://api.github.com/repos/rust-lang/rust/commits/da84f0f4c31914c14dd03628395e9c53f28b88b9", "html_url": "https://github.com/rust-lang/rust/commit/da84f0f4c31914c14dd03628395e9c53f28b88b9"}], "stats": {"total": 345, "additions": 174, "deletions": 171}, "files": [{"sha": "151e80e2b3e9da0da75091812d87049c5414f43e", "filename": "compiler/rustc_parse/src/lexer/mod.rs", "status": "modified", "additions": 174, "deletions": 171, "changes": 345, "blob_url": "https://github.com/rust-lang/rust/blob/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flexer%2Fmod.rs?ref=fb4dba0a17b6eb241b4fd3732b976ab38fe2cdc0", "patch": "@@ -86,13 +86,182 @@ impl<'a> StringReader<'a> {\n \n             debug!(\"next_token: {:?}({:?})\", token.kind, self.str_from(start));\n \n-            match self.cook_lexer_token(token.kind, start) {\n-                Some(kind) => {\n+            // Now \"cook\" the token, converting the simple `rustc_lexer::TokenKind` enum into a\n+            // rich `rustc_ast::TokenKind`. This turns strings into interned symbols and runs\n+            // additional validation.\n+            let kind = match token.kind {\n+                rustc_lexer::TokenKind::LineComment { doc_style } => {\n+                    // Skip non-doc comments\n+                    let Some(doc_style) = doc_style else {\n+                        self.lint_unicode_text_flow(start);\n+                        preceded_by_whitespace = true;\n+                        continue;\n+                    };\n+\n+                    // Opening delimiter of the length 3 is not included into the symbol.\n+                    let content_start = start + BytePos(3);\n+                    let content = self.str_from(content_start);\n+                    self.cook_doc_comment(content_start, content, CommentKind::Line, doc_style)\n+                }\n+                rustc_lexer::TokenKind::BlockComment { doc_style, terminated } => {\n+                    if !terminated {\n+                        self.report_unterminated_block_comment(start, doc_style);\n+                    }\n+\n+                    // Skip non-doc comments\n+                    let Some(doc_style) = doc_style else {\n+                        self.lint_unicode_text_flow(start);\n+                        preceded_by_whitespace = true;\n+                        continue;\n+                    };\n+\n+                    // Opening delimiter of the length 3 and closing delimiter of the length 2\n+                    // are not included into the symbol.\n+                    let content_start = start + BytePos(3);\n+                    let content_end = self.pos - BytePos(if terminated { 2 } else { 0 });\n+                    let content = self.str_from_to(content_start, content_end);\n+                    self.cook_doc_comment(content_start, content, CommentKind::Block, doc_style)\n+                }\n+                rustc_lexer::TokenKind::Whitespace => {\n+                    preceded_by_whitespace = true;\n+                    continue;\n+                }\n+                rustc_lexer::TokenKind::Ident => {\n+                    let sym = nfc_normalize(self.str_from(start));\n                     let span = self.mk_sp(start, self.pos);\n-                    return (Token::new(kind, span), preceded_by_whitespace);\n+                    self.sess.symbol_gallery.insert(sym, span);\n+                    token::Ident(sym, false)\n                 }\n-                None => preceded_by_whitespace = true,\n-            }\n+                rustc_lexer::TokenKind::RawIdent => {\n+                    let sym = nfc_normalize(self.str_from(start + BytePos(2)));\n+                    let span = self.mk_sp(start, self.pos);\n+                    self.sess.symbol_gallery.insert(sym, span);\n+                    if !sym.can_be_raw() {\n+                        self.err_span(span, &format!(\"`{}` cannot be a raw identifier\", sym));\n+                    }\n+                    self.sess.raw_identifier_spans.borrow_mut().push(span);\n+                    token::Ident(sym, true)\n+                }\n+                rustc_lexer::TokenKind::UnknownPrefix => {\n+                    self.report_unknown_prefix(start);\n+                    let sym = nfc_normalize(self.str_from(start));\n+                    let span = self.mk_sp(start, self.pos);\n+                    self.sess.symbol_gallery.insert(sym, span);\n+                    token::Ident(sym, false)\n+                }\n+                rustc_lexer::TokenKind::InvalidIdent\n+                    // Do not recover an identifier with emoji if the codepoint is a confusable\n+                    // with a recoverable substitution token, like `\u2796`.\n+                    if !UNICODE_ARRAY\n+                        .iter()\n+                        .any(|&(c, _, _)| {\n+                            let sym = self.str_from(start);\n+                            sym.chars().count() == 1 && c == sym.chars().next().unwrap()\n+                        }) =>\n+                {\n+                    let sym = nfc_normalize(self.str_from(start));\n+                    let span = self.mk_sp(start, self.pos);\n+                    self.sess.bad_unicode_identifiers.borrow_mut().entry(sym).or_default()\n+                        .push(span);\n+                    token::Ident(sym, false)\n+                }\n+                rustc_lexer::TokenKind::Literal { kind, suffix_start } => {\n+                    let suffix_start = start + BytePos(suffix_start);\n+                    let (kind, symbol) = self.cook_lexer_literal(start, suffix_start, kind);\n+                    let suffix = if suffix_start < self.pos {\n+                        let string = self.str_from(suffix_start);\n+                        if string == \"_\" {\n+                            self.sess\n+                                .span_diagnostic\n+                                .struct_span_warn(\n+                                    self.mk_sp(suffix_start, self.pos),\n+                                    \"underscore literal suffix is not allowed\",\n+                                )\n+                                .warn(\n+                                    \"this was previously accepted by the compiler but is \\\n+                                       being phased out; it will become a hard error in \\\n+                                       a future release!\",\n+                                )\n+                                .note(\n+                                    \"see issue #42326 \\\n+                                     <https://github.com/rust-lang/rust/issues/42326> \\\n+                                     for more information\",\n+                                )\n+                                .emit();\n+                            None\n+                        } else {\n+                            Some(Symbol::intern(string))\n+                        }\n+                    } else {\n+                        None\n+                    };\n+                    token::Literal(token::Lit { kind, symbol, suffix })\n+                }\n+                rustc_lexer::TokenKind::Lifetime { starts_with_number } => {\n+                    // Include the leading `'` in the real identifier, for macro\n+                    // expansion purposes. See #12512 for the gory details of why\n+                    // this is necessary.\n+                    let lifetime_name = self.str_from(start);\n+                    if starts_with_number {\n+                        self.err_span_(start, self.pos, \"lifetimes cannot start with a number\");\n+                    }\n+                    let ident = Symbol::intern(lifetime_name);\n+                    token::Lifetime(ident)\n+                }\n+                rustc_lexer::TokenKind::Semi => token::Semi,\n+                rustc_lexer::TokenKind::Comma => token::Comma,\n+                rustc_lexer::TokenKind::Dot => token::Dot,\n+                rustc_lexer::TokenKind::OpenParen => token::OpenDelim(Delimiter::Parenthesis),\n+                rustc_lexer::TokenKind::CloseParen => token::CloseDelim(Delimiter::Parenthesis),\n+                rustc_lexer::TokenKind::OpenBrace => token::OpenDelim(Delimiter::Brace),\n+                rustc_lexer::TokenKind::CloseBrace => token::CloseDelim(Delimiter::Brace),\n+                rustc_lexer::TokenKind::OpenBracket => token::OpenDelim(Delimiter::Bracket),\n+                rustc_lexer::TokenKind::CloseBracket => token::CloseDelim(Delimiter::Bracket),\n+                rustc_lexer::TokenKind::At => token::At,\n+                rustc_lexer::TokenKind::Pound => token::Pound,\n+                rustc_lexer::TokenKind::Tilde => token::Tilde,\n+                rustc_lexer::TokenKind::Question => token::Question,\n+                rustc_lexer::TokenKind::Colon => token::Colon,\n+                rustc_lexer::TokenKind::Dollar => token::Dollar,\n+                rustc_lexer::TokenKind::Eq => token::Eq,\n+                rustc_lexer::TokenKind::Bang => token::Not,\n+                rustc_lexer::TokenKind::Lt => token::Lt,\n+                rustc_lexer::TokenKind::Gt => token::Gt,\n+                rustc_lexer::TokenKind::Minus => token::BinOp(token::Minus),\n+                rustc_lexer::TokenKind::And => token::BinOp(token::And),\n+                rustc_lexer::TokenKind::Or => token::BinOp(token::Or),\n+                rustc_lexer::TokenKind::Plus => token::BinOp(token::Plus),\n+                rustc_lexer::TokenKind::Star => token::BinOp(token::Star),\n+                rustc_lexer::TokenKind::Slash => token::BinOp(token::Slash),\n+                rustc_lexer::TokenKind::Caret => token::BinOp(token::Caret),\n+                rustc_lexer::TokenKind::Percent => token::BinOp(token::Percent),\n+\n+                rustc_lexer::TokenKind::Unknown | rustc_lexer::TokenKind::InvalidIdent => {\n+                    let c = self.str_from(start).chars().next().unwrap();\n+                    let mut err =\n+                        self.struct_err_span_char(start, self.pos, \"unknown start of token\", c);\n+                    // FIXME: the lexer could be used to turn the ASCII version of unicode\n+                    // homoglyphs, instead of keeping a table in `check_for_substitution`into the\n+                    // token. Ideally, this should be inside `rustc_lexer`. However, we should\n+                    // first remove compound tokens like `<<` from `rustc_lexer`, and then add\n+                    // fancier error recovery to it, as there will be less overall work to do this\n+                    // way.\n+                    let token = unicode_chars::check_for_substitution(self, start, c, &mut err);\n+                    if c == '\\x00' {\n+                        err.help(\"source files must contain UTF-8 encoded text, unexpected null bytes might occur when a different encoding is used\");\n+                    }\n+                    err.emit();\n+                    if let Some(token) = token {\n+                        token\n+                    } else {\n+                        preceded_by_whitespace = true;\n+                        continue;\n+                    }\n+                }\n+                rustc_lexer::TokenKind::Eof => token::Eof,\n+            };\n+            let span = self.mk_sp(start, self.pos);\n+            return (Token::new(kind, span), preceded_by_whitespace);\n         }\n     }\n \n@@ -158,172 +327,6 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    /// Turns simple `rustc_lexer::TokenKind` enum into a rich\n-    /// `rustc_ast::TokenKind`. This turns strings into interned\n-    /// symbols and runs additional validation.\n-    fn cook_lexer_token(&self, token: rustc_lexer::TokenKind, start: BytePos) -> Option<TokenKind> {\n-        Some(match token {\n-            rustc_lexer::TokenKind::LineComment { doc_style } => {\n-                // Skip non-doc comments\n-                let Some(doc_style) = doc_style else {\n-                    self.lint_unicode_text_flow(start);\n-                    return None;\n-                };\n-\n-                // Opening delimiter of the length 3 is not included into the symbol.\n-                let content_start = start + BytePos(3);\n-                let content = self.str_from(content_start);\n-                self.cook_doc_comment(content_start, content, CommentKind::Line, doc_style)\n-            }\n-            rustc_lexer::TokenKind::BlockComment { doc_style, terminated } => {\n-                if !terminated {\n-                    self.report_unterminated_block_comment(start, doc_style);\n-                }\n-\n-                // Skip non-doc comments\n-                let Some(doc_style) = doc_style else {\n-                    self.lint_unicode_text_flow(start);\n-                    return None;\n-                };\n-\n-                // Opening delimiter of the length 3 and closing delimiter of the length 2\n-                // are not included into the symbol.\n-                let content_start = start + BytePos(3);\n-                let content_end = self.pos - BytePos(if terminated { 2 } else { 0 });\n-                let content = self.str_from_to(content_start, content_end);\n-                self.cook_doc_comment(content_start, content, CommentKind::Block, doc_style)\n-            }\n-            rustc_lexer::TokenKind::Whitespace => return None,\n-            rustc_lexer::TokenKind::Ident => {\n-                let sym = nfc_normalize(self.str_from(start));\n-                let span = self.mk_sp(start, self.pos);\n-                self.sess.symbol_gallery.insert(sym, span);\n-                token::Ident(sym, false)\n-            }\n-            rustc_lexer::TokenKind::RawIdent => {\n-                let sym = nfc_normalize(self.str_from(start + BytePos(2)));\n-                let span = self.mk_sp(start, self.pos);\n-                self.sess.symbol_gallery.insert(sym, span);\n-                if !sym.can_be_raw() {\n-                    self.err_span(span, &format!(\"`{}` cannot be a raw identifier\", sym));\n-                }\n-                self.sess.raw_identifier_spans.borrow_mut().push(span);\n-                token::Ident(sym, true)\n-            }\n-            rustc_lexer::TokenKind::UnknownPrefix => {\n-                self.report_unknown_prefix(start);\n-                let sym = nfc_normalize(self.str_from(start));\n-                let span = self.mk_sp(start, self.pos);\n-                self.sess.symbol_gallery.insert(sym, span);\n-                token::Ident(sym, false)\n-            }\n-            rustc_lexer::TokenKind::InvalidIdent\n-                // Do not recover an identifier with emoji if the codepoint is a confusable\n-                // with a recoverable substitution token, like `\u2796`.\n-                if !UNICODE_ARRAY\n-                    .iter()\n-                    .any(|&(c, _, _)| {\n-                        let sym = self.str_from(start);\n-                        sym.chars().count() == 1 && c == sym.chars().next().unwrap()\n-                    })\n-                     =>\n-            {\n-                let sym = nfc_normalize(self.str_from(start));\n-                let span = self.mk_sp(start, self.pos);\n-                self.sess.bad_unicode_identifiers.borrow_mut().entry(sym).or_default().push(span);\n-                token::Ident(sym, false)\n-            }\n-            rustc_lexer::TokenKind::Literal { kind, suffix_start } => {\n-                let suffix_start = start + BytePos(suffix_start);\n-                let (kind, symbol) = self.cook_lexer_literal(start, suffix_start, kind);\n-                let suffix = if suffix_start < self.pos {\n-                    let string = self.str_from(suffix_start);\n-                    if string == \"_\" {\n-                        self.sess\n-                            .span_diagnostic\n-                            .struct_span_warn(\n-                                self.mk_sp(suffix_start, self.pos),\n-                                \"underscore literal suffix is not allowed\",\n-                            )\n-                            .warn(\n-                                \"this was previously accepted by the compiler but is \\\n-                                   being phased out; it will become a hard error in \\\n-                                   a future release!\",\n-                            )\n-                            .note(\n-                                \"see issue #42326 \\\n-                                 <https://github.com/rust-lang/rust/issues/42326> \\\n-                                 for more information\",\n-                            )\n-                            .emit();\n-                        None\n-                    } else {\n-                        Some(Symbol::intern(string))\n-                    }\n-                } else {\n-                    None\n-                };\n-                token::Literal(token::Lit { kind, symbol, suffix })\n-            }\n-            rustc_lexer::TokenKind::Lifetime { starts_with_number } => {\n-                // Include the leading `'` in the real identifier, for macro\n-                // expansion purposes. See #12512 for the gory details of why\n-                // this is necessary.\n-                let lifetime_name = self.str_from(start);\n-                if starts_with_number {\n-                    self.err_span_(start, self.pos, \"lifetimes cannot start with a number\");\n-                }\n-                let ident = Symbol::intern(lifetime_name);\n-                token::Lifetime(ident)\n-            }\n-            rustc_lexer::TokenKind::Semi => token::Semi,\n-            rustc_lexer::TokenKind::Comma => token::Comma,\n-            rustc_lexer::TokenKind::Dot => token::Dot,\n-            rustc_lexer::TokenKind::OpenParen => token::OpenDelim(Delimiter::Parenthesis),\n-            rustc_lexer::TokenKind::CloseParen => token::CloseDelim(Delimiter::Parenthesis),\n-            rustc_lexer::TokenKind::OpenBrace => token::OpenDelim(Delimiter::Brace),\n-            rustc_lexer::TokenKind::CloseBrace => token::CloseDelim(Delimiter::Brace),\n-            rustc_lexer::TokenKind::OpenBracket => token::OpenDelim(Delimiter::Bracket),\n-            rustc_lexer::TokenKind::CloseBracket => token::CloseDelim(Delimiter::Bracket),\n-            rustc_lexer::TokenKind::At => token::At,\n-            rustc_lexer::TokenKind::Pound => token::Pound,\n-            rustc_lexer::TokenKind::Tilde => token::Tilde,\n-            rustc_lexer::TokenKind::Question => token::Question,\n-            rustc_lexer::TokenKind::Colon => token::Colon,\n-            rustc_lexer::TokenKind::Dollar => token::Dollar,\n-            rustc_lexer::TokenKind::Eq => token::Eq,\n-            rustc_lexer::TokenKind::Bang => token::Not,\n-            rustc_lexer::TokenKind::Lt => token::Lt,\n-            rustc_lexer::TokenKind::Gt => token::Gt,\n-            rustc_lexer::TokenKind::Minus => token::BinOp(token::Minus),\n-            rustc_lexer::TokenKind::And => token::BinOp(token::And),\n-            rustc_lexer::TokenKind::Or => token::BinOp(token::Or),\n-            rustc_lexer::TokenKind::Plus => token::BinOp(token::Plus),\n-            rustc_lexer::TokenKind::Star => token::BinOp(token::Star),\n-            rustc_lexer::TokenKind::Slash => token::BinOp(token::Slash),\n-            rustc_lexer::TokenKind::Caret => token::BinOp(token::Caret),\n-            rustc_lexer::TokenKind::Percent => token::BinOp(token::Percent),\n-\n-            rustc_lexer::TokenKind::Unknown | rustc_lexer::TokenKind::InvalidIdent => {\n-                let c = self.str_from(start).chars().next().unwrap();\n-                let mut err =\n-                    self.struct_err_span_char(start, self.pos, \"unknown start of token\", c);\n-                // FIXME: the lexer could be used to turn the ASCII version of unicode homoglyphs,\n-                // instead of keeping a table in `check_for_substitution`into the token. Ideally,\n-                // this should be inside `rustc_lexer`. However, we should first remove compound\n-                // tokens like `<<` from `rustc_lexer`, and then add fancier error recovery to it,\n-                // as there will be less overall work to do this way.\n-                let token = unicode_chars::check_for_substitution(self, start, c, &mut err);\n-                if c == '\\x00' {\n-                    err.help(\"source files must contain UTF-8 encoded text, unexpected null bytes might occur when a different encoding is used\");\n-                }\n-                err.emit();\n-                token?\n-            }\n-            rustc_lexer::TokenKind::Eof => token::Eof,\n-        })\n-    }\n-\n     fn cook_doc_comment(\n         &self,\n         content_start: BytePos,"}]}