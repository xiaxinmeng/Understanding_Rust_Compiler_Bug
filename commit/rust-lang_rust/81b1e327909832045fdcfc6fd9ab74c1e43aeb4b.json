{"sha": "81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "node_id": "C_kwDOAAsO6NoAKDgxYjFlMzI3OTA5ODMyMDQ1ZmRjZmM2ZmQ5YWI3NGMxZTQzYWViNGI", "commit": {"author": {"name": "David Tolnay", "email": "dtolnay@gmail.com", "date": "2022-01-14T22:28:20Z"}, "committer": {"name": "David Tolnay", "email": "dtolnay@gmail.com", "date": "2022-01-18T19:14:30Z"}, "message": "Move render_macro_matcher to own module", "tree": {"sha": "c8213a94cea7a70046838be08a47fc3fc42df3ae", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c8213a94cea7a70046838be08a47fc3fc42df3ae"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCgAdFiEERijF2Cz/ZdaBZKeK+boUO5X/bYIFAmHnEZkACgkQ+boUO5X/\nbYIJiA/+KDjy3fnuGl5tfsE87bqZ+yOs0zTdTgIS9Uug51cAAvwuCbW7RN0x+I6i\nXIlXiVciXzgcFebWeiuhyQEkeNfEUffuJ17bBQFdbUVoGjPS1khhd8dE0wMT2AK2\nQh5IHyKe23t7fJOiLFczTae50fs6kfj3hvramXcJp+0n3LjXDlDJyh+H7d8k6ChI\nWNWMsLlD1ViqksQAC23J6D0gqKYJQ/49LHV6WaZs46cPoIshL7fBzq4mTFoIp7H9\n6UfVxLdksyqv9GoNFsTUBBKbSrkYYFn6GlsNg1KAoxgMYl67sWHRMpxyZ55jMUYJ\nt+MveVkbG1hn0dz55ACvXkDr0HsMzJw/Nfp6Z+EjHd9uKQWPsRpnToXc61hjooWw\nwyjoZQCVUJNrnS0egY0gL60RqqCocz9c2gSN/1AwTucs+WAijJCo1iqAi1TrN0rL\n6F2xfB7b8ngITZe4E+PjbZWCQJ1ltoO/dttC39+snQUWs2fyYPEF0OlyybyoHxLd\ntOV0q3XcbGxj8r0gamP1ZTlmPvChTm+yb2Sjd6YqeTs/wlVoWd063ysDi7hGfiNA\n0TvdJ05AckKvVDCyuMAkOAwohoFVM3KLAosJqZLy0XQsTzOxa+wbmkm0lxkgQ+se\noJSuk4ai7bfZLtM6Y50HRGCfikkP3W806GEao9sFdpmH422E8ZY=\n=/uGy\n-----END PGP SIGNATURE-----", "payload": "tree c8213a94cea7a70046838be08a47fc3fc42df3ae\nparent 090461475102cda8c42a7b4c65e25d0d38b27db8\nauthor David Tolnay <dtolnay@gmail.com> 1642199300 -0800\ncommitter David Tolnay <dtolnay@gmail.com> 1642533270 -0800\n\nMove render_macro_matcher to own module\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "html_url": "https://github.com/rust-lang/rust/commit/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/comments", "author": {"login": "dtolnay", "id": 1940490, "node_id": "MDQ6VXNlcjE5NDA0OTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1940490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtolnay", "html_url": "https://github.com/dtolnay", "followers_url": "https://api.github.com/users/dtolnay/followers", "following_url": "https://api.github.com/users/dtolnay/following{/other_user}", "gists_url": "https://api.github.com/users/dtolnay/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtolnay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtolnay/subscriptions", "organizations_url": "https://api.github.com/users/dtolnay/orgs", "repos_url": "https://api.github.com/users/dtolnay/repos", "events_url": "https://api.github.com/users/dtolnay/events{/privacy}", "received_events_url": "https://api.github.com/users/dtolnay/received_events", "type": "User", "site_admin": false}, "committer": {"login": "dtolnay", "id": 1940490, "node_id": "MDQ6VXNlcjE5NDA0OTA=", "avatar_url": "https://avatars.githubusercontent.com/u/1940490?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dtolnay", "html_url": "https://github.com/dtolnay", "followers_url": "https://api.github.com/users/dtolnay/followers", "following_url": "https://api.github.com/users/dtolnay/following{/other_user}", "gists_url": "https://api.github.com/users/dtolnay/gists{/gist_id}", "starred_url": "https://api.github.com/users/dtolnay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dtolnay/subscriptions", "organizations_url": "https://api.github.com/users/dtolnay/orgs", "repos_url": "https://api.github.com/users/dtolnay/repos", "events_url": "https://api.github.com/users/dtolnay/events{/privacy}", "received_events_url": "https://api.github.com/users/dtolnay/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "090461475102cda8c42a7b4c65e25d0d38b27db8", "url": "https://api.github.com/repos/rust-lang/rust/commits/090461475102cda8c42a7b4c65e25d0d38b27db8", "html_url": "https://github.com/rust-lang/rust/commit/090461475102cda8c42a7b4c65e25d0d38b27db8"}], "stats": {"total": 383, "additions": 194, "deletions": 189}, "files": [{"sha": "dfa83ba995947210ee7573af2c860770857bcaea", "filename": "src/librustdoc/clean/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fmod.rs?ref=81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "patch": "@@ -5,6 +5,7 @@ mod auto_trait;\n mod blanket_impl;\n crate mod cfg;\n crate mod inline;\n+mod render_macro_matchers;\n mod simplify;\n crate mod types;\n crate mod utils;"}, {"sha": "14990c2e9e6e9a8a94fa44800204242620e2811c", "filename": "src/librustdoc/clean/render_macro_matchers.rs", "status": "added", "additions": 191, "deletions": 0, "changes": 191, "blob_url": "https://github.com/rust-lang/rust/blob/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Frender_macro_matchers.rs?ref=81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "patch": "@@ -0,0 +1,191 @@\n+use rustc_ast::token::{self, BinOpToken, DelimToken};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree};\n+use rustc_ast_pretty::pprust::state::State as Printer;\n+use rustc_ast_pretty::pprust::PrintState;\n+use rustc_middle::ty::TyCtxt;\n+use rustc_session::parse::ParseSess;\n+use rustc_span::source_map::FilePathMapping;\n+use rustc_span::symbol::Symbol;\n+\n+/// Render a macro matcher in a format suitable for displaying to the user\n+/// as part of an item declaration.\n+pub(super) fn render_macro_matcher(tcx: TyCtxt<'_>, matcher: &TokenTree) -> String {\n+    if let Some(snippet) = snippet_equal_to_token(tcx, matcher) {\n+        // If the original source code is known, we display the matcher exactly\n+        // as present in the source code.\n+        return snippet;\n+    }\n+\n+    // If the matcher is macro-generated or some other reason the source code\n+    // snippet is not available, we attempt to nicely render the token tree.\n+    let mut printer = Printer::new();\n+\n+    // If the inner ibox fits on one line, we get:\n+    //\n+    //     macro_rules! macroname {\n+    //         (the matcher) => {...};\n+    //     }\n+    //\n+    // If the inner ibox gets wrapped, the cbox will break and get indented:\n+    //\n+    //     macro_rules! macroname {\n+    //         (\n+    //             the matcher ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+    //             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!\n+    //         ) => {...};\n+    //     }\n+    printer.cbox(8);\n+    printer.word(\"(\");\n+    printer.zerobreak();\n+    printer.ibox(0);\n+    match matcher {\n+        TokenTree::Delimited(_span, _delim, tts) => print_tts(&mut printer, tts),\n+        // Matcher which is not a Delimited is unexpected and should've failed\n+        // to compile, but we render whatever it is wrapped in parens.\n+        TokenTree::Token(_) => print_tt(&mut printer, matcher),\n+    }\n+    printer.end();\n+    printer.break_offset_if_not_bol(0, -4);\n+    printer.word(\")\");\n+    printer.end();\n+    printer.s.eof()\n+}\n+\n+/// Find the source snippet for this token's Span, reparse it, and return the\n+/// snippet if the reparsed TokenTree matches the argument TokenTree.\n+fn snippet_equal_to_token(tcx: TyCtxt<'_>, matcher: &TokenTree) -> Option<String> {\n+    // Find what rustc thinks is the source snippet.\n+    // This may not actually be anything meaningful if this matcher was itself\n+    // generated by a macro.\n+    let source_map = tcx.sess.source_map();\n+    let span = matcher.span();\n+    let snippet = source_map.span_to_snippet(span).ok()?;\n+\n+    // Create a Parser.\n+    let sess = ParseSess::new(FilePathMapping::empty());\n+    let file_name = source_map.span_to_filename(span);\n+    let mut parser =\n+        match rustc_parse::maybe_new_parser_from_source_str(&sess, file_name, snippet.clone()) {\n+            Ok(parser) => parser,\n+            Err(diagnostics) => {\n+                for mut diagnostic in diagnostics {\n+                    diagnostic.cancel();\n+                }\n+                return None;\n+            }\n+        };\n+\n+    // Reparse a single token tree.\n+    let mut reparsed_trees = match parser.parse_all_token_trees() {\n+        Ok(reparsed_trees) => reparsed_trees,\n+        Err(mut diagnostic) => {\n+            diagnostic.cancel();\n+            return None;\n+        }\n+    };\n+    if reparsed_trees.len() != 1 {\n+        return None;\n+    }\n+    let reparsed_tree = reparsed_trees.pop().unwrap();\n+\n+    // Compare against the original tree.\n+    if reparsed_tree.eq_unspanned(matcher) { Some(snippet) } else { None }\n+}\n+\n+fn print_tt(printer: &mut Printer<'_>, tt: &TokenTree) {\n+    match tt {\n+        TokenTree::Token(token) => {\n+            let token_str = printer.token_to_string(token);\n+            printer.word(token_str);\n+            if let token::DocComment(..) = token.kind {\n+                printer.hardbreak()\n+            }\n+        }\n+        TokenTree::Delimited(_span, delim, tts) => {\n+            let open_delim = printer.token_kind_to_string(&token::OpenDelim(*delim));\n+            printer.word(open_delim);\n+            if !tts.is_empty() {\n+                if *delim == DelimToken::Brace {\n+                    printer.space();\n+                }\n+                print_tts(printer, tts);\n+                if *delim == DelimToken::Brace {\n+                    printer.space();\n+                }\n+            }\n+            let close_delim = printer.token_kind_to_string(&token::CloseDelim(*delim));\n+            printer.word(close_delim);\n+        }\n+    }\n+}\n+\n+fn print_tts(printer: &mut Printer<'_>, tts: &TokenStream) {\n+    #[derive(Copy, Clone, PartialEq)]\n+    enum State {\n+        Start,\n+        Dollar,\n+        DollarIdent,\n+        DollarIdentColon,\n+        DollarParen,\n+        DollarParenSep,\n+        Pound,\n+        PoundBang,\n+        Ident,\n+        Other,\n+    }\n+\n+    use State::*;\n+\n+    let mut state = Start;\n+    for tt in tts.trees() {\n+        let (needs_space, next_state) = match &tt {\n+            TokenTree::Token(tt) => match (state, &tt.kind) {\n+                (Dollar, token::Ident(..)) => (false, DollarIdent),\n+                (DollarIdent, token::Colon) => (false, DollarIdentColon),\n+                (DollarIdentColon, token::Ident(..)) => (false, Other),\n+                (\n+                    DollarParen,\n+                    token::BinOp(BinOpToken::Plus | BinOpToken::Star) | token::Question,\n+                ) => (false, Other),\n+                (DollarParen, _) => (false, DollarParenSep),\n+                (DollarParenSep, token::BinOp(BinOpToken::Plus | BinOpToken::Star)) => {\n+                    (false, Other)\n+                }\n+                (Pound, token::Not) => (false, PoundBang),\n+                (_, token::Ident(symbol, /* is_raw */ false))\n+                    if !usually_needs_space_between_keyword_and_open_delim(*symbol) =>\n+                {\n+                    (true, Ident)\n+                }\n+                (_, token::Comma | token::Semi) => (false, Other),\n+                (_, token::Dollar) => (true, Dollar),\n+                (_, token::Pound) => (true, Pound),\n+                (_, _) => (true, Other),\n+            },\n+            TokenTree::Delimited(_, delim, _) => match (state, delim) {\n+                (Dollar, DelimToken::Paren) => (false, DollarParen),\n+                (Pound | PoundBang, DelimToken::Bracket) => (false, Other),\n+                (Ident, DelimToken::Paren | DelimToken::Bracket) => (false, Other),\n+                (_, _) => (true, Other),\n+            },\n+        };\n+        if state != Start && needs_space {\n+            printer.space();\n+        }\n+        print_tt(printer, &tt);\n+        state = next_state;\n+    }\n+}\n+\n+// This rough subset of keywords is listed here to distinguish tokens resembling\n+// `f(0)` (no space between ident and paren) from tokens resembling `if let (0,\n+// 0) = x` (space between ident and paren).\n+fn usually_needs_space_between_keyword_and_open_delim(symbol: Symbol) -> bool {\n+    match symbol.as_str() {\n+        \"as\" | \"box\" | \"break\" | \"const\" | \"continue\" | \"crate\" | \"else\" | \"enum\" | \"extern\"\n+        | \"for\" | \"if\" | \"impl\" | \"in\" | \"let\" | \"loop\" | \"macro\" | \"match\" | \"mod\" | \"move\"\n+        | \"mut\" | \"ref\" | \"return\" | \"static\" | \"struct\" | \"trait\" | \"type\" | \"unsafe\" | \"use\"\n+        | \"where\" | \"while\" | \"yield\" => true,\n+        _ => false,\n+    }\n+}"}, {"sha": "dabf1e878c9fb38d3f5aaaf04f128a2cd7cd7c30", "filename": "src/librustdoc/clean/utils.rs", "status": "modified", "additions": 2, "deletions": 189, "changes": 191, "blob_url": "https://github.com/rust-lang/rust/blob/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Futils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/81b1e327909832045fdcfc6fd9ab74c1e43aeb4b/src%2Flibrustdoc%2Fclean%2Futils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Futils.rs?ref=81b1e327909832045fdcfc6fd9ab74c1e43aeb4b", "patch": "@@ -1,5 +1,6 @@\n use crate::clean::auto_trait::AutoTraitFinder;\n use crate::clean::blanket_impl::BlanketImplFinder;\n+use crate::clean::render_macro_matchers::render_macro_matcher;\n use crate::clean::{\n     inline, Clean, Crate, ExternalCrate, Generic, GenericArg, GenericArgs, ImportSource, Item,\n     ItemKind, Lifetime, Path, PathSegment, Primitive, PrimitiveType, Type, TypeBinding, Visibility,\n@@ -9,19 +10,14 @@ use crate::formats::item_type::ItemType;\n use crate::visit_lib::LibEmbargoVisitor;\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, BinOpToken, DelimToken};\n-use rustc_ast::tokenstream::{TokenStream, TokenTree};\n-use rustc_ast_pretty::pprust::state::State as Printer;\n-use rustc_ast_pretty::pprust::PrintState;\n+use rustc_ast::tokenstream::TokenTree;\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_hir as hir;\n use rustc_hir::def::{DefKind, Res};\n use rustc_hir::def_id::{DefId, LOCAL_CRATE};\n use rustc_middle::mir::interpret::ConstValue;\n use rustc_middle::ty::subst::{GenericArgKind, SubstsRef};\n use rustc_middle::ty::{self, DefIdTree, TyCtxt};\n-use rustc_session::parse::ParseSess;\n-use rustc_span::source_map::FilePathMapping;\n use rustc_span::symbol::{kw, sym, Symbol};\n use std::fmt::Write as _;\n use std::mem;\n@@ -503,189 +499,6 @@ pub(super) fn render_macro_arms<'a>(\n     out\n }\n \n-/// Render a macro matcher in a format suitable for displaying to the user\n-/// as part of an item declaration.\n-pub(super) fn render_macro_matcher(tcx: TyCtxt<'_>, matcher: &TokenTree) -> String {\n-    if let Some(snippet) = snippet_equal_to_token(tcx, matcher) {\n-        // If the original source code is known, we display the matcher exactly\n-        // as present in the source code.\n-        return snippet;\n-    }\n-\n-    // If the matcher is macro-generated or some other reason the source code\n-    // snippet is not available, we attempt to nicely render the token tree.\n-    let mut printer = Printer::new();\n-\n-    // If the inner ibox fits on one line, we get:\n-    //\n-    //     macro_rules! macroname {\n-    //         (the matcher) => {...};\n-    //     }\n-    //\n-    // If the inner ibox gets wrapped, the cbox will break and get indented:\n-    //\n-    //     macro_rules! macroname {\n-    //         (\n-    //             the matcher ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-    //             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~!\n-    //         ) => {...};\n-    //     }\n-    printer.cbox(8);\n-    printer.word(\"(\");\n-    printer.zerobreak();\n-    printer.ibox(0);\n-    match matcher {\n-        TokenTree::Delimited(_span, _delim, tts) => print_tts(&mut printer, tts),\n-        // Matcher which is not a Delimited is unexpected and should've failed\n-        // to compile, but we render whatever it is wrapped in parens.\n-        TokenTree::Token(_) => print_tt(&mut printer, matcher),\n-    }\n-    printer.end();\n-    printer.break_offset_if_not_bol(0, -4);\n-    printer.word(\")\");\n-    printer.end();\n-    printer.s.eof()\n-}\n-\n-/// Find the source snippet for this token's Span, reparse it, and return the\n-/// snippet if the reparsed TokenTree matches the argument TokenTree.\n-fn snippet_equal_to_token(tcx: TyCtxt<'_>, matcher: &TokenTree) -> Option<String> {\n-    // Find what rustc thinks is the source snippet.\n-    // This may not actually be anything meaningful if this matcher was itself\n-    // generated by a macro.\n-    let source_map = tcx.sess.source_map();\n-    let span = matcher.span();\n-    let snippet = source_map.span_to_snippet(span).ok()?;\n-\n-    // Create a Parser.\n-    let sess = ParseSess::new(FilePathMapping::empty());\n-    let file_name = source_map.span_to_filename(span);\n-    let mut parser =\n-        match rustc_parse::maybe_new_parser_from_source_str(&sess, file_name, snippet.clone()) {\n-            Ok(parser) => parser,\n-            Err(diagnostics) => {\n-                for mut diagnostic in diagnostics {\n-                    diagnostic.cancel();\n-                }\n-                return None;\n-            }\n-        };\n-\n-    // Reparse a single token tree.\n-    let mut reparsed_trees = match parser.parse_all_token_trees() {\n-        Ok(reparsed_trees) => reparsed_trees,\n-        Err(mut diagnostic) => {\n-            diagnostic.cancel();\n-            return None;\n-        }\n-    };\n-    if reparsed_trees.len() != 1 {\n-        return None;\n-    }\n-    let reparsed_tree = reparsed_trees.pop().unwrap();\n-\n-    // Compare against the original tree.\n-    if reparsed_tree.eq_unspanned(matcher) { Some(snippet) } else { None }\n-}\n-\n-fn print_tt(printer: &mut Printer<'_>, tt: &TokenTree) {\n-    match tt {\n-        TokenTree::Token(token) => {\n-            let token_str = printer.token_to_string(token);\n-            printer.word(token_str);\n-            if let token::DocComment(..) = token.kind {\n-                printer.hardbreak()\n-            }\n-        }\n-        TokenTree::Delimited(_span, delim, tts) => {\n-            let open_delim = printer.token_kind_to_string(&token::OpenDelim(*delim));\n-            printer.word(open_delim);\n-            if !tts.is_empty() {\n-                if *delim == DelimToken::Brace {\n-                    printer.space();\n-                }\n-                print_tts(printer, tts);\n-                if *delim == DelimToken::Brace {\n-                    printer.space();\n-                }\n-            }\n-            let close_delim = printer.token_kind_to_string(&token::CloseDelim(*delim));\n-            printer.word(close_delim);\n-        }\n-    }\n-}\n-\n-fn print_tts(printer: &mut Printer<'_>, tts: &TokenStream) {\n-    #[derive(Copy, Clone, PartialEq)]\n-    enum State {\n-        Start,\n-        Dollar,\n-        DollarIdent,\n-        DollarIdentColon,\n-        DollarParen,\n-        DollarParenSep,\n-        Pound,\n-        PoundBang,\n-        Ident,\n-        Other,\n-    }\n-\n-    use State::*;\n-\n-    let mut state = Start;\n-    for tt in tts.trees() {\n-        let (needs_space, next_state) = match &tt {\n-            TokenTree::Token(tt) => match (state, &tt.kind) {\n-                (Dollar, token::Ident(..)) => (false, DollarIdent),\n-                (DollarIdent, token::Colon) => (false, DollarIdentColon),\n-                (DollarIdentColon, token::Ident(..)) => (false, Other),\n-                (\n-                    DollarParen,\n-                    token::BinOp(BinOpToken::Plus | BinOpToken::Star) | token::Question,\n-                ) => (false, Other),\n-                (DollarParen, _) => (false, DollarParenSep),\n-                (DollarParenSep, token::BinOp(BinOpToken::Plus | BinOpToken::Star)) => {\n-                    (false, Other)\n-                }\n-                (Pound, token::Not) => (false, PoundBang),\n-                (_, token::Ident(symbol, /* is_raw */ false))\n-                    if !usually_needs_space_between_keyword_and_open_delim(*symbol) =>\n-                {\n-                    (true, Ident)\n-                }\n-                (_, token::Comma | token::Semi) => (false, Other),\n-                (_, token::Dollar) => (true, Dollar),\n-                (_, token::Pound) => (true, Pound),\n-                (_, _) => (true, Other),\n-            },\n-            TokenTree::Delimited(_, delim, _) => match (state, delim) {\n-                (Dollar, DelimToken::Paren) => (false, DollarParen),\n-                (Pound | PoundBang, DelimToken::Bracket) => (false, Other),\n-                (Ident, DelimToken::Paren | DelimToken::Bracket) => (false, Other),\n-                (_, _) => (true, Other),\n-            },\n-        };\n-        if state != Start && needs_space {\n-            printer.space();\n-        }\n-        print_tt(printer, &tt);\n-        state = next_state;\n-    }\n-}\n-\n-// This rough subset of keywords is listed here to distinguish tokens resembling\n-// `f(0)` (no space between ident and paren) from tokens resembling `if let (0,\n-// 0) = x` (space between ident and paren).\n-fn usually_needs_space_between_keyword_and_open_delim(symbol: Symbol) -> bool {\n-    match symbol.as_str() {\n-        \"as\" | \"box\" | \"break\" | \"const\" | \"continue\" | \"crate\" | \"else\" | \"enum\" | \"extern\"\n-        | \"for\" | \"if\" | \"impl\" | \"in\" | \"let\" | \"loop\" | \"macro\" | \"match\" | \"mod\" | \"move\"\n-        | \"mut\" | \"ref\" | \"return\" | \"static\" | \"struct\" | \"trait\" | \"type\" | \"unsafe\" | \"use\"\n-        | \"where\" | \"while\" | \"yield\" => true,\n-        _ => false,\n-    }\n-}\n-\n pub(super) fn display_macro_source(\n     cx: &mut DocContext<'_>,\n     name: Symbol,"}]}