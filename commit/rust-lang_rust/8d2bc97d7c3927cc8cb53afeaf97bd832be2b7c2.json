{"sha": "8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "node_id": "MDY6Q29tbWl0NzI0NzEyOjhkMmJjOTdkN2MzOTI3Y2M4Y2I1M2FmZWFmOTdiZDgzMmJlMmI3YzI=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2018-11-30T07:00:02Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2018-11-30T07:00:02Z"}, "message": "Merge pull request #553 from solson/rustup\n\nStacked Borrow: Barriers", "tree": {"sha": "134cf40e2db95cd96786710467f4520d91ca8270", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/134cf40e2db95cd96786710467f4520d91ca8270"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJcAN/yCRBK7hj4Ov3rIwAAdHIIAE88FV3Isf090D5t2WgH7NiN\nrwpAXzDVSiSDUoPsoKv1QY/4kqcoT1T5b1BDLhItfoS+gDZvBIp0B+LJugfjyZ/Y\nuCDWwtwJuauFSr6lIXMtFuj6FPUb8Cj2ZmI2j8uXBETHC+BHq4VrxU3pQDz5TPxq\nSvulPkUduwbfCiZtLCp1aUV5o2rIxzpt0vCxaoXLYDsFmbktdCJJyLOM7XsWusZ2\nahcYCktFvxiuK74XlLgOezJWsFuuHh274/XrbB5w3+vAw82iYRXdn16nne77YXxd\nXHl/ijbmRv8tU91/t54WTEl01bY0bTc+V0EY6zly1j7yLqJUBxdn7A2gLxNb1Q8=\n=4dq2\n-----END PGP SIGNATURE-----\n", "payload": "tree 134cf40e2db95cd96786710467f4520d91ca8270\nparent 559ad2db4a543d69d2b1438cdbcc0e8c3b18484c\nparent 3999db1159f06672c25ba661b3a5e4de26f5b58e\nauthor Ralf Jung <post@ralfj.de> 1543561202 +0100\ncommitter GitHub <noreply@github.com> 1543561202 +0100\n\nMerge pull request #553 from solson/rustup\n\nStacked Borrow: Barriers"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "html_url": "https://github.com/rust-lang/rust/commit/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "559ad2db4a543d69d2b1438cdbcc0e8c3b18484c", "url": "https://api.github.com/repos/rust-lang/rust/commits/559ad2db4a543d69d2b1438cdbcc0e8c3b18484c", "html_url": "https://github.com/rust-lang/rust/commit/559ad2db4a543d69d2b1438cdbcc0e8c3b18484c"}, {"sha": "3999db1159f06672c25ba661b3a5e4de26f5b58e", "url": "https://api.github.com/repos/rust-lang/rust/commits/3999db1159f06672c25ba661b3a5e4de26f5b58e", "html_url": "https://github.com/rust-lang/rust/commit/3999db1159f06672c25ba661b3a5e4de26f5b58e"}], "stats": {"total": 605, "additions": 368, "deletions": 237}, "files": [{"sha": "6fd720c5c785d550daf0ca6aceda40fa0822321d", "filename": "rust-version", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/rust-version", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/rust-version", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/rust-version?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1 +1 @@\n-nightly-2018-11-26\n+nightly-2018-11-30"}, {"sha": "9739a7a95b6dc8f17cde256124a85ba7d6a09cb3", "filename": "src/lib.rs", "status": "modified", "additions": 33, "deletions": 9, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flib.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -289,7 +289,7 @@ impl<'tcx> Evaluator<'tcx> {\n             env_vars: HashMap::default(),\n             tls: TlsData::default(),\n             validate,\n-            stacked_borrows: stacked_borrows::State::new(),\n+            stacked_borrows: stacked_borrows::State::default(),\n         }\n     }\n }\n@@ -301,6 +301,8 @@ type MiriEvalContext<'a, 'mir, 'tcx> = EvalContext<'a, 'mir, 'tcx, Evaluator<'tc\n impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n     type MemoryKinds = MiriMemoryKind;\n \n+    type FrameExtra = stacked_borrows::CallId;\n+    type MemoryExtra = stacked_borrows::MemoryState;\n     type AllocExtra = stacked_borrows::Stacks;\n     type PointerTag = Borrow;\n \n@@ -317,7 +319,6 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n         // We walk up the stack a few frames to also cover their callees.\n         const WHITELIST: &[(&str, &str)] = &[\n             // Uses mem::uninitialized\n-            (\"std::ptr::read\", \"\"),\n             (\"std::sys::windows::mutex::Mutex::\", \"\"),\n         ];\n         for frame in ecx.stack().iter()\n@@ -405,8 +406,9 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n     }\n \n     fn find_foreign_static(\n-        tcx: TyCtxtAt<'a, 'tcx, 'tcx>,\n         def_id: DefId,\n+        tcx: TyCtxtAt<'a, 'tcx, 'tcx>,\n+        memory_extra: &Self::MemoryExtra,\n     ) -> EvalResult<'tcx, Cow<'tcx, Allocation<Borrow, Self::AllocExtra>>> {\n         let attrs = tcx.get_attrs(def_id);\n         let link_name = match attr::first_attr_value_str_by_name(&attrs, \"link_name\") {\n@@ -417,8 +419,10 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n         let alloc = match &link_name[..] {\n             \"__cxa_thread_atexit_impl\" => {\n                 // This should be all-zero, pointer-sized\n-                let data = vec![0; tcx.data_layout.pointer_size.bytes() as usize];\n-                Allocation::from_bytes(&data[..], tcx.data_layout.pointer_align.abi)\n+                let size = tcx.data_layout.pointer_size;\n+                let data = vec![0; size.bytes() as usize];\n+                let extra = AllocationExtra::memory_allocated(size, memory_extra);\n+                Allocation::from_bytes(&data[..], tcx.data_layout.pointer_align.abi, extra)\n             }\n             _ => return err!(Unimplemented(\n                     format!(\"can't access foreign static: {}\", link_name),\n@@ -434,9 +438,14 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n         Ok(())\n     }\n \n-    fn adjust_static_allocation(\n-        alloc: &'_ Allocation\n-    ) -> Cow<'_, Allocation<Borrow, Self::AllocExtra>> {\n+    fn adjust_static_allocation<'b>(\n+        alloc: &'b Allocation,\n+        memory_extra: &Self::MemoryExtra,\n+    ) -> Cow<'b, Allocation<Borrow, Self::AllocExtra>> {\n+        let extra = AllocationExtra::memory_allocated(\n+            Size::from_bytes(alloc.bytes.len() as u64),\n+            memory_extra,\n+        );\n         let alloc: Allocation<Borrow, Self::AllocExtra> = Allocation {\n             bytes: alloc.bytes.clone(),\n             relocations: Relocations::from_presorted(\n@@ -447,7 +456,7 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n             undef_mask: alloc.undef_mask.clone(),\n             align: alloc.align,\n             mutability: alloc.mutability,\n-            extra: Self::AllocExtra::default(),\n+            extra,\n         };\n         Cow::Owned(alloc)\n     }\n@@ -529,4 +538,19 @@ impl<'a, 'mir, 'tcx> Machine<'a, 'mir, 'tcx> for Evaluator<'tcx> {\n             ecx.retag(fn_entry, place)\n         }\n     }\n+\n+    #[inline(always)]\n+    fn stack_push(\n+        ecx: &mut EvalContext<'a, 'mir, 'tcx, Self>,\n+    ) -> EvalResult<'tcx, stacked_borrows::CallId> {\n+        Ok(ecx.memory().extra.borrow_mut().new_call())\n+    }\n+\n+    #[inline(always)]\n+    fn stack_pop(\n+        ecx: &mut EvalContext<'a, 'mir, 'tcx, Self>,\n+        extra: stacked_borrows::CallId,\n+    ) -> EvalResult<'tcx> {\n+        Ok(ecx.memory().extra.borrow_mut().end_call(extra))\n+    }\n }"}, {"sha": "762b17b1ae3389a8a9fac9e06bb70e271e4fee20", "filename": "src/range_map.rs", "status": "modified", "additions": 29, "deletions": 79, "changes": 108, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Frange_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Frange_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frange_map.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -16,13 +16,6 @@ pub struct RangeMap<T> {\n     map: BTreeMap<Range, T>,\n }\n \n-impl<T> Default for RangeMap<T> {\n-    #[inline(always)]\n-    fn default() -> Self {\n-        RangeMap::new()\n-    }\n-}\n-\n // The derived `Ord` impl sorts first by the first field, then, if the fields are the same,\n // by the second field.\n // This is exactly what we need for our purposes, since a range query on a BTReeSet/BTreeMap will give us all\n@@ -73,9 +66,15 @@ impl Range {\n }\n \n impl<T> RangeMap<T> {\n+    /// Create a new RangeMap for the given size, and with the given initial value used for\n+    /// the entire range.\n     #[inline(always)]\n-    pub fn new() -> RangeMap<T> {\n-        RangeMap { map: BTreeMap::new() }\n+    pub fn new(size: Size, init: T) -> RangeMap<T> {\n+        let mut map = RangeMap { map: BTreeMap::new() };\n+        if size.bytes() > 0 {\n+            map.map.insert(Range { start: 0, end: size.bytes() }, init);\n+        }\n+        map\n     }\n \n     fn iter_with_range<'a>(\n@@ -95,6 +94,9 @@ impl<T> RangeMap<T> {\n         )\n     }\n \n+    /// Provide read-only iteration over everything in the given range.  This does\n+    /// *not* split items if they overlap with the edges.  Do not use this to mutate\n+    /// through interior mutability.\n     pub fn iter<'a>(&'a self, offset: Size, len: Size) -> impl Iterator<Item = &'a T> + 'a {\n         self.iter_with_range(offset.bytes(), len.bytes()).map(|(_, data)| data)\n     }\n@@ -140,8 +142,7 @@ impl<T> RangeMap<T> {\n     /// Provide mutable iteration over everything in the given range.  As a side-effect,\n     /// this will split entries in the map that are only partially hit by the given range,\n     /// to make sure that when they are mutated, the effect is constrained to the given range.\n-    /// If there are gaps, leave them be.\n-    pub fn iter_mut_with_gaps<'a>(\n+    pub fn iter_mut<'a>(\n         &'a mut self,\n         offset: Size,\n         len: Size,\n@@ -174,93 +175,34 @@ impl<T> RangeMap<T> {\n             },\n         )\n     }\n-\n-    /// Provide a mutable iterator over everything in the given range, with the same side-effects as\n-    /// iter_mut_with_gaps.  Furthermore, if there are gaps between ranges, fill them with the given default\n-    /// before yielding them in the iterator.\n-    /// This is also how you insert.\n-    pub fn iter_mut<'a>(&'a mut self, offset: Size, len: Size) -> impl Iterator<Item = &'a mut T> + 'a\n-    where\n-        T: Clone + Default,\n-    {\n-        if len.bytes() > 0 {\n-            let offset = offset.bytes();\n-            let len = len.bytes();\n-\n-            // Do a first iteration to collect the gaps\n-            let mut gaps = Vec::new();\n-            let mut last_end = offset;\n-            for (range, _) in self.iter_with_range(offset, len) {\n-                if last_end < range.start {\n-                    gaps.push(Range {\n-                        start: last_end,\n-                        end: range.start,\n-                    });\n-                }\n-                last_end = range.end;\n-            }\n-            if last_end < offset + len {\n-                gaps.push(Range {\n-                    start: last_end,\n-                    end: offset + len,\n-                });\n-            }\n-\n-            // Add default for all gaps\n-            for gap in gaps {\n-                let old = self.map.insert(gap, Default::default());\n-                assert!(old.is_none());\n-            }\n-        }\n-\n-        // Now provide mutable iteration\n-        self.iter_mut_with_gaps(offset, len)\n-    }\n-\n-    pub fn retain<F>(&mut self, mut f: F)\n-    where\n-        F: FnMut(&T) -> bool,\n-    {\n-        let mut remove = Vec::new();\n-        for (range, data) in &self.map {\n-            if !f(data) {\n-                remove.push(*range);\n-            }\n-        }\n-\n-        for range in remove {\n-            self.map.remove(&range);\n-        }\n-    }\n }\n \n #[cfg(test)]\n mod tests {\n     use super::*;\n \n     /// Query the map at every offset in the range and collect the results.\n-    fn to_vec<T: Copy>(map: &RangeMap<T>, offset: u64, len: u64, default: Option<T>) -> Vec<T> {\n+    fn to_vec<T: Copy>(map: &RangeMap<T>, offset: u64, len: u64) -> Vec<T> {\n         (offset..offset + len)\n             .into_iter()\n             .map(|i| map\n                 .iter(Size::from_bytes(i), Size::from_bytes(1))\n                 .next()\n                 .map(|&t| t)\n-                .or(default)\n                 .unwrap()\n             )\n             .collect()\n     }\n \n     #[test]\n     fn basic_insert() {\n-        let mut map = RangeMap::<i32>::new();\n+        let mut map = RangeMap::<i32>::new(Size::from_bytes(20), -1);\n         // Insert\n         for x in map.iter_mut(Size::from_bytes(10), Size::from_bytes(1)) {\n             *x = 42;\n         }\n         // Check\n-        assert_eq!(to_vec(&map, 10, 1, None), vec![42]);\n+        assert_eq!(to_vec(&map, 10, 1), vec![42]);\n \n         // Insert with size 0\n         for x in map.iter_mut(Size::from_bytes(10), Size::from_bytes(0)) {\n@@ -269,34 +211,42 @@ mod tests {\n         for x in map.iter_mut(Size::from_bytes(11), Size::from_bytes(0)) {\n             *x = 19;\n         }\n-        assert_eq!(to_vec(&map, 10, 2, Some(-1)), vec![42, -1]);\n+        assert_eq!(to_vec(&map, 10, 2), vec![42, -1]);\n     }\n \n     #[test]\n     fn gaps() {\n-        let mut map = RangeMap::<i32>::new();\n+        let mut map = RangeMap::<i32>::new(Size::from_bytes(20), -1);\n         for x in map.iter_mut(Size::from_bytes(11), Size::from_bytes(1)) {\n             *x = 42;\n         }\n         for x in map.iter_mut(Size::from_bytes(15), Size::from_bytes(1)) {\n             *x = 43;\n         }\n         assert_eq!(\n-            to_vec(&map, 10, 10, Some(-1)),\n+            to_vec(&map, 10, 10),\n             vec![-1, 42, -1, -1, -1, 43, -1, -1, -1, -1]\n         );\n \n-        // Now request a range that needs three gaps filled\n         for x in map.iter_mut(Size::from_bytes(10), Size::from_bytes(10)) {\n             if *x < 42 {\n                 *x = 23;\n             }\n         }\n \n         assert_eq!(\n-            to_vec(&map, 10, 10, None),\n+            to_vec(&map, 10, 10),\n             vec![23, 42, 23, 23, 23, 43, 23, 23, 23, 23]\n         );\n-        assert_eq!(to_vec(&map, 13, 5, None), vec![23, 23, 43, 23, 23]);\n+        assert_eq!(to_vec(&map, 13, 5), vec![23, 23, 43, 23, 23]);\n+\n+        // Now request a range that goes beyond the initial size\n+        for x in map.iter_mut(Size::from_bytes(15), Size::from_bytes(10)) {\n+            *x = 19;\n+        }\n+        assert_eq!(map.iter(Size::from_bytes(19), Size::from_bytes(1))\n+            .map(|&t| t).collect::<Vec<_>>(), vec![19]);\n+        assert_eq!(map.iter(Size::from_bytes(20), Size::from_bytes(1))\n+            .map(|&t| t).collect::<Vec<_>>(), vec![]);\n     }\n }"}, {"sha": "31f80fe2f6c68fb75f8785e4c3440d281ec9fb2f", "filename": "src/stacked_borrows.rs", "status": "modified", "additions": 210, "deletions": 96, "changes": 306, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Fstacked_borrows.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/src%2Fstacked_borrows.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstacked_borrows.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,4 +1,6 @@\n use std::cell::RefCell;\n+use std::collections::HashSet;\n+use std::rc::Rc;\n \n use rustc::ty::{self, layout::Size};\n use rustc::hir::{Mutability, MutMutable, MutImmutable};\n@@ -10,6 +12,7 @@ use crate::{\n };\n \n pub type Timestamp = u64;\n+pub type CallId = u64;\n \n /// Information about which kind of borrow was used to create the reference this is tagged\n /// with.\n@@ -59,18 +62,7 @@ pub enum BorStackItem {\n     /// when there is no `UnsafeCell`.\n     Shr,\n     /// A barrier, tracking the function it belongs to by its index on the call stack\n-    #[allow(dead_code)] // for future use\n-    FnBarrier(usize)\n-}\n-\n-impl BorStackItem {\n-    #[inline(always)]\n-    pub fn is_fn_barrier(self) -> bool {\n-        match self {\n-            BorStackItem::FnBarrier(_) => true,\n-            _ => false,\n-        }\n-    }\n+    FnBarrier(CallId)\n }\n \n /// Extra per-location state\n@@ -80,15 +72,6 @@ pub struct Stack {\n     frozen_since: Option<Timestamp>, // virtual frozen \"item\" on top of the stack\n }\n \n-impl Default for Stack {\n-    fn default() -> Self {\n-        Stack {\n-            borrows: vec![BorStackItem::Shr],\n-            frozen_since: None,\n-        }\n-    }\n-}\n-\n impl Stack {\n     #[inline(always)]\n     pub fn is_frozen(&self) -> bool {\n@@ -107,17 +90,62 @@ pub enum RefKind {\n     Raw,\n }\n \n+/// What kind of access is being performed?\n+#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq)]\n+pub enum AccessKind {\n+    Read,\n+    Write,\n+    Dealloc,\n+}\n+\n+/// Extra global state in the memory, available to the memory access hooks\n+#[derive(Debug)]\n+pub struct BarrierTracking {\n+    next_id: CallId,\n+    active_calls: HashSet<CallId>,\n+}\n+pub type MemoryState = Rc<RefCell<BarrierTracking>>;\n+\n+impl Default for BarrierTracking {\n+    fn default() -> Self {\n+        BarrierTracking {\n+            next_id: 0,\n+            active_calls: HashSet::default(),\n+        }\n+    }\n+}\n+\n+impl BarrierTracking {\n+    pub fn new_call(&mut self) -> CallId {\n+        let id = self.next_id;\n+        trace!(\"new_call: Assigning ID {}\", id);\n+        self.active_calls.insert(id);\n+        self.next_id += 1;\n+        id\n+    }\n+\n+    pub fn end_call(&mut self, id: CallId) {\n+        assert!(self.active_calls.remove(&id));\n+    }\n+\n+    fn is_active(&self, id: CallId) -> bool {\n+        self.active_calls.contains(&id)\n+    }\n+}\n+\n /// Extra global machine state\n #[derive(Clone, Debug)]\n pub struct State {\n     clock: Timestamp\n }\n \n-impl State {\n-    pub fn new() -> State {\n+impl Default for State {\n+    fn default() -> Self {\n         State { clock: 0 }\n     }\n+}\n \n+impl State {\n     fn increment_clock(&mut self) -> Timestamp {\n         let val = self.clock;\n         self.clock = val + 1;\n@@ -126,10 +154,11 @@ impl State {\n }\n \n /// Extra per-allocation state\n-#[derive(Clone, Debug, Default)]\n+#[derive(Clone, Debug)]\n pub struct Stacks {\n     // Even reading memory can have effects on the stack, so we need a `RefCell` here.\n     stacks: RefCell<RangeMap<Stack>>,\n+    barrier_tracking: MemoryState,\n }\n \n /// Core per-location operations: deref, access, create.\n@@ -150,7 +179,11 @@ impl<'tcx> Stack {\n     /// going to read or write.\n     /// Returns the index of the item we matched, `None` if it was the frozen one.\n     /// `kind` indicates which kind of reference is being dereferenced.\n-    fn deref(&self, bor: Borrow, kind: RefKind) -> Result<Option<usize>, String> {\n+    fn deref(\n+        &self,\n+        bor: Borrow,\n+        kind: RefKind,\n+    ) -> Result<Option<usize>, String> {\n         // Exclude unique ref with frozen tag.\n         if let (RefKind::Unique, Borrow::Shr(Some(_))) = (kind, bor) {\n             return Err(format!(\"Encountered mutable reference with frozen tag ({:?})\", bor));\n@@ -172,7 +205,6 @@ impl<'tcx> Stack {\n         // If we got here, we have to look for our item in the stack.\n         for (idx, &itm) in self.borrows.iter().enumerate().rev() {\n             match (itm, bor) {\n-                (BorStackItem::FnBarrier(_), _) => break,\n                 (BorStackItem::Uniq(itm_t), Borrow::Uniq(bor_t)) if itm_t == bor_t => {\n                     // Found matching unique item.  This satisfies U3.\n                     return Ok(Some(idx))\n@@ -181,25 +213,29 @@ impl<'tcx> Stack {\n                     // Found matching shared/raw item.\n                     return Ok(Some(idx))\n                 }\n-                // Go on looking.\n+                // Go on looking.  We ignore barriers!  When an `&mut` and an `&` alias,\n+                // dereferencing the `&` is still possible (to reborrow), but doing\n+                // an access is not.\n                 _ => {}\n             }\n         }\n         // If we got here, we did not find our item.  We have to error to satisfy U3.\n-        Err(format!(\n-            \"Borrow being dereferenced ({:?}) does not exist on the stack, or is guarded by a barrier\",\n-            bor\n-        ))\n+        Err(format!(\"Borrow being dereferenced ({:?}) does not exist on the stack\", bor))\n     }\n \n     /// Perform an actual memory access using `bor`.  We do not know any types here\n     /// or whether things should be frozen, but we *do* know if this is reading\n     /// or writing.\n-    fn access(&mut self, bor: Borrow, is_write: bool) -> EvalResult<'tcx> {\n+    fn access(\n+        &mut self,\n+        bor: Borrow,\n+        kind: AccessKind,\n+        barrier_tracking: &BarrierTracking,\n+    ) -> EvalResult<'tcx> {\n         // Check if we can match the frozen \"item\".\n         // Not possible on writes!\n         if self.is_frozen() {\n-            if !is_write {\n+            if kind == AccessKind::Read {\n                 // When we are frozen, we just accept all reads.  No harm in this.\n                 // The deref already checked that `Uniq` items are in the stack, and that\n                 // the location is frozen if it should be.\n@@ -212,32 +248,52 @@ impl<'tcx> Stack {\n         // Pop the stack until we have something matching.\n         while let Some(&itm) = self.borrows.last() {\n             match (itm, bor) {\n-                (BorStackItem::FnBarrier(_), _) => break,\n+                (BorStackItem::FnBarrier(call), _) if barrier_tracking.is_active(call) => {\n+                    return err!(MachineError(format!(\n+                        \"Stopping looking for borrow being accessed ({:?}) because of barrier ({})\",\n+                        bor, call\n+                    )))\n+                }\n                 (BorStackItem::Uniq(itm_t), Borrow::Uniq(bor_t)) if itm_t == bor_t => {\n-                    // Found matching unique item.\n-                    return Ok(())\n+                    // Found matching unique item.  Continue after the match.\n                 }\n-                (BorStackItem::Shr, _) if !is_write => {\n+                (BorStackItem::Shr, _) if kind == AccessKind::Read => {\n                     // When reading, everything can use a shared item!\n                     // We do not want to do this when writing: Writing to an `&mut`\n                     // should reaffirm its exclusivity (i.e., make sure it is\n-                    // on top of the stack).\n-                    return Ok(())\n+                    // on top of the stack).  Continue after the match.\n                 }\n                 (BorStackItem::Shr, Borrow::Shr(_)) => {\n-                    // Found matching shared item.\n-                    return Ok(())\n+                    // Found matching shared item.  Continue after the match.\n                 }\n                 _ => {\n-                    // Pop this.  This ensures U2.\n+                    // Pop this, go on.  This ensures U2.\n                     let itm = self.borrows.pop().unwrap();\n                     trace!(\"access: Popping {:?}\", itm);\n+                    continue\n                 }\n             }\n+            // If we got here, we found a matching item.  Congratulations!\n+            // However, we are not done yet: If this access is deallocating, we must make sure\n+            // there are no active barriers remaining on the stack.\n+            if kind == AccessKind::Dealloc {\n+                for &itm in self.borrows.iter().rev() {\n+                    match itm {\n+                        BorStackItem::FnBarrier(call) if barrier_tracking.is_active(call) => {\n+                            return err!(MachineError(format!(\n+                                \"Deallocating with active barrier ({})\", call\n+                            )))\n+                        }\n+                        _ => {},\n+                    }\n+                }\n+            }\n+            // NOW we are done.\n+            return Ok(())\n         }\n         // If we got here, we did not find our item.\n         err!(MachineError(format!(\n-            \"Borrow being accessed ({:?}) does not exist on the stack, or is guarded by a barrier\",\n+            \"Borrow being accessed ({:?}) does not exist on the stack\",\n             bor\n         )))\n     }\n@@ -247,18 +303,21 @@ impl<'tcx> Stack {\n     /// is met: We cannot push `Uniq` onto frozen stacks.\n     /// `kind` indicates which kind of reference is being created.\n     fn create(&mut self, bor: Borrow, kind: RefKind) {\n-        // First, push the item.  We do this even if we will later freeze, because we\n-        // will allow mutation of shared data at the expense of unfreezing.\n         if self.frozen_since.is_some() {\n-            // A frozen location, this should be impossible!\n-            bug!(\"We should never try pushing to a frozen stack\");\n+            // A frozen location?  Possible if we create a barrier, then push again.\n+            assert!(bor.is_shared(), \"We should never try creating a unique borrow for a frozen stack\");\n+            trace!(\"create: Not doing anything on frozen location\");\n+            return;\n         }\n-        // First, push.\n+        // First, push.  We do this even if we will later freeze, because we\n+        // will allow mutation of shared data at the expense of unfreezing.\n         let itm = match bor {\n             Borrow::Uniq(t) => BorStackItem::Uniq(t),\n             Borrow::Shr(_) => BorStackItem::Shr,\n         };\n         if *self.borrows.last().unwrap() == itm {\n+            // This is just an optimization, no functional change: Avoid stacking\n+            // multiple `Shr` on top of each other.\n             assert!(bor.is_shared());\n             trace!(\"create: Sharing a shared location is a NOP\");\n         } else {\n@@ -276,6 +335,21 @@ impl<'tcx> Stack {\n             self.frozen_since = Some(bor_t);\n         }\n     }\n+\n+    /// Add a barrier\n+    fn barrier(&mut self, call: CallId) {\n+        let itm = BorStackItem::FnBarrier(call);\n+        if *self.borrows.last().unwrap() == itm {\n+            // This is just an optimization, no functional change: Avoid stacking\n+            // multiple identical barriers on top of each other.\n+            // This can happen when a function receives several shared references\n+            // that overlap.\n+            trace!(\"barrier: Avoiding redundant extra barrier\");\n+        } else {\n+            trace!(\"barrier: Pushing barrier for call {}\", call);\n+            self.borrows.push(itm);\n+        }\n+    }\n }\n \n /// Higher-level per-location operations: deref, access, reborrow.\n@@ -289,9 +363,8 @@ impl<'tcx> Stacks {\n     ) -> EvalResult<'tcx> {\n         trace!(\"deref for tag {:?} as {:?}: {:?}, size {}\",\n             ptr.tag, kind, ptr, size.bytes());\n-        let mut stacks = self.stacks.borrow_mut();\n-        // We need `iter_mut` because `iter` would skip gaps!\n-        for stack in stacks.iter_mut(ptr.offset, size) {\n+        let stacks = self.stacks.borrow();\n+        for stack in stacks.iter(ptr.offset, size) {\n             stack.deref(ptr.tag, kind).map_err(EvalErrorKind::MachineError)?;\n         }\n         Ok(())\n@@ -302,17 +375,16 @@ impl<'tcx> Stacks {\n         &self,\n         ptr: Pointer<Borrow>,\n         size: Size,\n-        is_write: bool,\n+        kind: AccessKind,\n     ) -> EvalResult<'tcx> {\n-        trace!(\"{} access of tag {:?}: {:?}, size {}\",\n-            if is_write { \"read\" } else { \"write\" },\n-            ptr.tag, ptr, size.bytes());\n+        trace!(\"{:?} access of tag {:?}: {:?}, size {}\", kind, ptr.tag, ptr, size.bytes());\n         // Even reads can have a side-effect, by invalidating other references.\n         // This is fundamentally necessary since `&mut` asserts that there\n         // are no accesses through other references, not even reads.\n+        let barrier_tracking = self.barrier_tracking.borrow();\n         let mut stacks = self.stacks.borrow_mut();\n         for stack in stacks.iter_mut(ptr.offset, size) {\n-            stack.access(ptr.tag, is_write)?;\n+            stack.access(ptr.tag, kind, &*barrier_tracking)?;\n         }\n         Ok(())\n     }\n@@ -323,12 +395,27 @@ impl<'tcx> Stacks {\n         &self,\n         ptr: Pointer<Borrow>,\n         size: Size,\n+        mut barrier: Option<CallId>,\n         new_bor: Borrow,\n         new_kind: RefKind,\n     ) -> EvalResult<'tcx> {\n         assert_eq!(new_bor.is_unique(), new_kind == RefKind::Unique);\n         trace!(\"reborrow for tag {:?} to {:?} as {:?}: {:?}, size {}\",\n             ptr.tag, new_bor, new_kind, ptr, size.bytes());\n+        if new_kind == RefKind::Raw {\n+            // No barrier for raw, including `&UnsafeCell`.  They can rightfully\n+            // alias with `&mut`.\n+            // FIXME: This means that the `dereferencable` attribute on non-frozen shared\n+            // references is incorrect!  They are dereferencable when the function is\n+            // called, but might become non-dereferencable during the course of execution.\n+            // Also see [1], [2].\n+            //\n+            // [1]: <https://internals.rust-lang.org/t/\n+            //       is-it-possible-to-be-memory-safe-with-deallocated-self/8457/8>,\n+            // [2]: <https://lists.llvm.org/pipermail/llvm-dev/2018-July/124555.html>\n+            barrier = None;\n+        }\n+        let barrier_tracking = self.barrier_tracking.borrow();\n         let mut stacks = self.stacks.borrow_mut();\n         for stack in stacks.iter_mut(ptr.offset, size) {\n             // Access source `ptr`, create new ref.\n@@ -337,36 +424,57 @@ impl<'tcx> Stacks {\n             // the stack than the one we come from, just use that.\n             // IOW, we check if `new_bor` *already* is \"derived from\" `ptr.tag`.\n             // This also checks frozenness, if required.\n-            let bor_redundant = match (ptr_idx, stack.deref(new_bor, new_kind)) {\n-                // If the new borrow works with the frozen item, or else if it lives\n-                // above the old one in the stack, our job here is done.\n-                (_, Ok(None)) => true,\n-                (Some(ptr_idx), Ok(Some(new_idx))) if new_idx >= ptr_idx => true,\n-                // Otherwise we need to create a new borrow.\n-                _ => false,\n-            };\n+            let bor_redundant = barrier.is_none() &&\n+                match (ptr_idx, stack.deref(new_bor, new_kind)) {\n+                    // If the new borrow works with the frozen item, or else if it lives\n+                    // above the old one in the stack, our job here is done.\n+                    (_, Ok(None)) => true,\n+                    (Some(ptr_idx), Ok(Some(new_idx))) if new_idx >= ptr_idx => true,\n+                    // Otherwise we need to create a new borrow.\n+                    _ => false,\n+                };\n             if bor_redundant {\n                 assert!(new_bor.is_shared(), \"A unique reborrow can never be redundant\");\n                 trace!(\"reborrow is redundant\");\n                 continue;\n             }\n             // We need to do some actual work.\n-            stack.access(ptr.tag, new_kind == RefKind::Unique)?;\n+            let access_kind = if new_kind == RefKind::Unique {\n+                AccessKind::Write\n+            } else {\n+                AccessKind::Read\n+            };\n+            stack.access(ptr.tag, access_kind, &*barrier_tracking)?;\n+            if let Some(call) = barrier {\n+                stack.barrier(call);\n+            }\n             stack.create(new_bor, new_kind);\n         }\n         Ok(())\n     }\n }\n \n /// Hooks and glue\n-impl AllocationExtra<Borrow> for Stacks {\n+impl AllocationExtra<Borrow, MemoryState> for Stacks {\n+    #[inline(always)]\n+    fn memory_allocated<'tcx>(size: Size, extra: &MemoryState) -> Self {\n+        let stack = Stack {\n+            borrows: vec![BorStackItem::Shr],\n+            frozen_since: None,\n+        };\n+        Stacks {\n+            stacks: RefCell::new(RangeMap::new(size, stack)),\n+            barrier_tracking: Rc::clone(extra),\n+        }\n+    }\n+\n     #[inline(always)]\n     fn memory_read<'tcx>(\n         alloc: &Allocation<Borrow, Stacks>,\n         ptr: Pointer<Borrow>,\n         size: Size,\n     ) -> EvalResult<'tcx> {\n-        alloc.extra.access(ptr, size, /*is_write*/false)\n+        alloc.extra.access(ptr, size, AccessKind::Read)\n     }\n \n     #[inline(always)]\n@@ -375,7 +483,7 @@ impl AllocationExtra<Borrow> for Stacks {\n         ptr: Pointer<Borrow>,\n         size: Size,\n     ) -> EvalResult<'tcx> {\n-        alloc.extra.access(ptr, size, /*is_write*/true)\n+        alloc.extra.access(ptr, size, AccessKind::Write)\n     }\n \n     #[inline(always)]\n@@ -384,20 +492,17 @@ impl AllocationExtra<Borrow> for Stacks {\n         ptr: Pointer<Borrow>,\n         size: Size,\n     ) -> EvalResult<'tcx> {\n-        // This is like mutating\n-        alloc.extra.access(ptr, size, /*is_write*/true)\n-        // FIXME: Error out of there are any barriers?\n+        alloc.extra.access(ptr, size, AccessKind::Dealloc)\n     }\n }\n \n impl<'tcx> Stacks {\n     /// Pushes the first item to the stacks.\n-    pub fn first_item(\n+    pub(crate) fn first_item(\n         &mut self,\n         itm: BorStackItem,\n         size: Size\n     ) {\n-        assert!(!itm.is_fn_barrier());\n         for stack in self.stacks.get_mut().iter_mut(Size::ZERO, size) {\n             assert!(stack.borrows.len() == 1);\n             assert_eq!(stack.borrows.pop().unwrap(), BorStackItem::Shr);\n@@ -427,6 +532,7 @@ pub trait EvalContextExt<'tcx> {\n         &mut self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n+        fn_barrier: bool,\n         new_bor: Borrow\n     ) -> EvalResult<'tcx, Pointer<Borrow>>;\n \n@@ -435,6 +541,7 @@ pub trait EvalContextExt<'tcx> {\n         &mut self,\n         ptr: ImmTy<'tcx, Borrow>,\n         mutbl: Mutability,\n+        fn_barrier: bool,\n     ) -> EvalResult<'tcx, Immediate<Borrow>>;\n \n     fn retag(\n@@ -527,18 +634,20 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n     ) -> EvalResult<'tcx> {\n-        self.reborrow(place, size, Borrow::default())?;\n+        self.reborrow(place, size, /*fn_barrier*/ false, Borrow::default())?;\n         Ok(())\n     }\n \n     fn reborrow(\n         &mut self,\n         place: MPlaceTy<'tcx, Borrow>,\n         size: Size,\n+        fn_barrier: bool,\n         new_bor: Borrow\n     ) -> EvalResult<'tcx, Pointer<Borrow>> {\n         let ptr = place.ptr.to_ptr()?;\n         let new_ptr = Pointer::new_with_tag(ptr.alloc_id, ptr.offset, new_bor);\n+        let barrier = if fn_barrier { Some(self.frame().extra) } else { None };\n         trace!(\"reborrow: Creating new reference for {:?} (pointee {}): {:?}\",\n             ptr, place.layout.ty, new_bor);\n \n@@ -550,12 +659,12 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n             // Reference that cares about freezing. We need a frozen-sensitive reborrow.\n             self.visit_freeze_sensitive(place, size, |cur_ptr, size, frozen| {\n                 let kind = if frozen { RefKind::Frozen } else { RefKind::Raw };\n-                alloc.extra.reborrow(cur_ptr, size, new_bor, kind)\n+                alloc.extra.reborrow(cur_ptr, size, barrier, new_bor, kind)\n             })?;\n         } else {\n             // Just treat this as one big chunk.\n             let kind = if new_bor.is_unique() { RefKind::Unique } else { RefKind::Raw };\n-            alloc.extra.reborrow(ptr, size, new_bor, kind)?;\n+            alloc.extra.reborrow(ptr, size, barrier, new_bor, kind)?;\n         }\n         Ok(new_ptr)\n     }\n@@ -564,6 +673,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         &mut self,\n         val: ImmTy<'tcx, Borrow>,\n         mutbl: Mutability,\n+        fn_barrier: bool,\n     ) -> EvalResult<'tcx, Immediate<Borrow>> {\n         // We want a place for where the ptr *points to*, so we get one.\n         let place = self.ref_to_mplace(val)?;\n@@ -583,7 +693,7 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n         };\n \n         // Reborrow.\n-        let new_ptr = self.reborrow(place, size, new_bor)?;\n+        let new_ptr = self.reborrow(place, size, fn_barrier, new_bor)?;\n \n         // Return new ptr\n         let new_place = MemPlace { ptr: Scalar::Ptr(new_ptr), ..*place };\n@@ -592,35 +702,42 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n \n     fn retag(\n         &mut self,\n-        _fn_entry: bool,\n+        fn_entry: bool,\n         place: PlaceTy<'tcx, Borrow>\n     ) -> EvalResult<'tcx> {\n-        // TODO: Honor `fn_entry`.\n+        // Determine mutability and whether to add a barrier.\n+        // Cannot use `builtin_deref` because that reports *immutable* for `Box`,\n+        // making it useless.\n+        fn qualify(ty: ty::Ty<'_>, fn_entry: bool) -> Option<(Mutability, bool)> {\n+            match ty.sty {\n+                // References are simple\n+                ty::Ref(_, _, mutbl) => Some((mutbl, fn_entry)),\n+                // Boxes do not get a barrier: Barriers reflect that references outlive the call\n+                // they were passed in to; that's just not the case for boxes.\n+                ty::Adt(..) if ty.is_box() => Some((MutMutable, false)),\n+                _ => None,\n+            }\n+        }\n \n         // We need a visitor to visit all references.  However, that requires\n         // a `MemPlace`, so we have a fast path for reference types that\n         // avoids allocating.\n-        // Cannot use `builtin_deref` because that reports *immutable* for `Box`,\n-        // making it useless.\n-        if let Some(mutbl) = match place.layout.ty.sty {\n-            ty::Ref(_, _, mutbl) => Some(mutbl),\n-            ty::Adt(..) if place.layout.ty.is_box() => Some(MutMutable),\n-            _ => None, // handled with the general case below\n-        } {\n+        if let Some((mutbl, barrier)) = qualify(place.layout.ty, fn_entry) {\n             // fast path\n             let val = self.read_immediate(self.place_to_op(place)?)?;\n-            let val = self.retag_reference(val, mutbl)?;\n+            let val = self.retag_reference(val, mutbl, barrier)?;\n             self.write_immediate(val, place)?;\n             return Ok(());\n         }\n         let place = self.force_allocation(place)?;\n \n-        let mut visitor = RetagVisitor { ecx: self };\n+        let mut visitor = RetagVisitor { ecx: self, fn_entry };\n         visitor.visit_value(place)?;\n \n         // The actual visitor\n         struct RetagVisitor<'ecx, 'a, 'mir, 'tcx> {\n             ecx: &'ecx mut MiriEvalContext<'a, 'mir, 'tcx>,\n+            fn_entry: bool,\n         }\n         impl<'ecx, 'a, 'mir, 'tcx>\n             MutValueVisitor<'a, 'mir, 'tcx, Evaluator<'tcx>>\n@@ -639,14 +756,11 @@ impl<'a, 'mir, 'tcx> EvalContextExt<'tcx> for MiriEvalContext<'a, 'mir, 'tcx> {\n             {\n                 // Cannot use `builtin_deref` because that reports *immutable* for `Box`,\n                 // making it useless.\n-                let mutbl = match place.layout.ty.sty {\n-                    ty::Ref(_, _, mutbl) => mutbl,\n-                    ty::Adt(..) if place.layout.ty.is_box() => MutMutable,\n-                    _ => return Ok(()), // nothing to do\n-                };\n-                let val = self.ecx.read_immediate(place.into())?;\n-                let val = self.ecx.retag_reference(val, mutbl)?;\n-                self.ecx.write_immediate(val, place.into())?;\n+                if let Some((mutbl, barrier)) = qualify(place.layout.ty, self.fn_entry) {\n+                    let val = self.ecx.read_immediate(place.into())?;\n+                    let val = self.ecx.retag_reference(val, mutbl, barrier)?;\n+                    self.ecx.write_immediate(val, place.into())?;\n+                }\n                 Ok(())\n             }\n         }"}, {"sha": "b82901985b781743b94b655e664c629cc781d734", "filename": "tests/compile-fail-fullmir/stacked_borrows/aliasing_mut1.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut1.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,12 +1,17 @@\n-// ignore-test validation_op is disabled\n-\n #![allow(unused_variables)]\n \n-mod safe {\n-    pub fn safe(x: &mut i32, y: &mut i32) {} //~ ERROR: in conflict with lock WriteLock\n-}\n+use std::mem;\n+\n+pub fn safe(x: &mut i32, y: &mut i32) {} //~ ERROR barrier\n \n fn main() {\n-    let x = &mut 0 as *mut _;\n-    unsafe { safe::safe(&mut *x, &mut *x) };\n+    let mut x = 0;\n+    let xraw: *mut i32 = unsafe { mem::transmute(&mut x) };\n+    // We need to apply some tricky to be able to call `safe` with two mutable references\n+    // with the same tag: We transmute both the fn ptr (to take raw ptrs) and the argument\n+    // (to be raw, but still have the unique tag).\n+    let safe_raw: fn(x: *mut i32, y: *mut i32) = unsafe {\n+        mem::transmute::<fn(&mut i32, &mut i32), _>(safe)\n+    };\n+    safe_raw(xraw, xraw);\n }"}, {"sha": "69caddfa8c389055e65ebfede9bb8edfd4b09674", "filename": "tests/compile-fail-fullmir/stacked_borrows/aliasing_mut2.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut2.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,12 +1,17 @@\n-// ignore-test validation_op is disabled\n-\n #![allow(unused_variables)]\n \n-mod safe {\n-    pub fn safe(x: &i32, y: &mut i32) {} //~ ERROR: in conflict with lock ReadLock\n-}\n+use std::mem;\n+\n+pub fn safe(x: &i32, y: &mut i32) {} //~ ERROR barrier\n \n fn main() {\n-    let x = &mut 0 as *mut _;\n-    unsafe { safe::safe(&*x, &mut *x) };\n+    let mut x = 0;\n+    let xref = &mut x;\n+    let xraw: *mut i32 = unsafe { mem::transmute_copy(&xref) };\n+    let xshr = &*xref;\n+    // transmute fn ptr around so that we can avoid retagging\n+    let safe_raw: fn(x: *const i32, y: *mut i32) = unsafe {\n+        mem::transmute::<fn(&i32, &mut i32), _>(safe)\n+    };\n+    safe_raw(xshr, xraw);\n }"}, {"sha": "d37f9e63f60d90a16bf719ba127edf65899990f3", "filename": "tests/compile-fail-fullmir/stacked_borrows/aliasing_mut3.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut3.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut3.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut3.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,12 +1,17 @@\n-// ignore-test validation_op is disabled\n-\n #![allow(unused_variables)]\n \n-mod safe {\n-    pub fn safe(x: &mut i32, y: &i32) {} //~ ERROR: in conflict with lock WriteLock\n-}\n+use std::mem;\n+\n+pub fn safe(x: &mut i32, y: &i32) {} //~ ERROR does not exist on the stack\n \n fn main() {\n-    let x = &mut 0 as *mut _;\n-    unsafe { safe::safe(&mut *x, &*x) };\n+    let mut x = 0;\n+    let xref = &mut x;\n+    let xraw: *mut i32 = unsafe { mem::transmute_copy(&xref) };\n+    let xshr = &*xref;\n+    // transmute fn ptr around so that we can avoid retagging\n+    let safe_raw: fn(x: *mut i32, y: *const i32) = unsafe {\n+        mem::transmute::<fn(&mut i32, &i32), _>(safe)\n+    };\n+    safe_raw(xraw, xshr);\n }"}, {"sha": "bf65d6e230358c28b2ca48266b1e8174645c16c1", "filename": "tests/compile-fail-fullmir/stacked_borrows/aliasing_mut4.rs", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut4.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut4.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Faliasing_mut4.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,15 +1,19 @@\n-// ignore-test validation_op is disabled\n-\n #![allow(unused_variables)]\n \n-mod safe {\n-    use std::cell::Cell;\n+use std::mem;\n+use std::cell::Cell;\n \n-    // Make sure &mut UnsafeCell also has a lock to it\n-    pub fn safe(x: &mut Cell<i32>, y: &i32) {} //~ ERROR: in conflict with lock WriteLock\n-}\n+// Make sure &mut UnsafeCell also is exclusive\n+pub fn safe(x: &i32, y: &mut Cell<i32>) {} //~ ERROR barrier\n \n fn main() {\n-    let x = &mut 0 as *mut _;\n-    unsafe { safe::safe(&mut *(x as *mut _), &*x) };\n+    let mut x = 0;\n+    let xref = &mut x;\n+    let xraw: *mut i32 = unsafe { mem::transmute_copy(&xref) };\n+    let xshr = &*xref;\n+    // transmute fn ptr around so that we can avoid retagging\n+    let safe_raw: fn(x: *const i32, y: *mut Cell<i32>) = unsafe {\n+        mem::transmute::<fn(&i32, &mut Cell<i32>), _>(safe)\n+    };\n+    safe_raw(xshr, xraw as *mut _);\n }"}, {"sha": "eb988a5899593f5371a6562a014b26ae9fa6047c", "filename": "tests/compile-fail-fullmir/stacked_borrows/deallocate_against_barrier.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fdeallocate_against_barrier.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fdeallocate_against_barrier.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fdeallocate_against_barrier.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -0,0 +1,13 @@\n+// error-pattern: Deallocating with active barrier\n+\n+fn inner(x: &mut i32, f: fn(&mut i32)) {\n+    // `f` may mutate, but it may not deallocate!\n+    f(x)\n+}\n+\n+fn main() {\n+    inner(Box::leak(Box::new(0)), |x| {\n+        let raw = x as *mut _;\n+        drop(unsafe { Box::from_raw(raw) });\n+    });\n+}"}, {"sha": "d0a23cb44489ae8ec4511c5f709cdc49371dd791", "filename": "tests/compile-fail-fullmir/stacked_borrows/illegal_write1.rs", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fillegal_write1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fillegal_write1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fillegal_write1.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -1,12 +1,9 @@\n-fn evil(x: &u32) {\n-    // mutating shared ref without `UnsafeCell`\n-    let x : *mut u32 = x as *const _ as *mut _;\n-    unsafe { *x = 42; }\n-}\n-\n fn main() {\n     let target = Box::new(42); // has an implicit raw\n-    let ref_ = &*target;\n-    evil(ref_); // invalidates shared ref, activates raw\n-    let _x = *ref_; //~ ERROR is not frozen\n+    let xref = &*target;\n+    {\n+        let x : *mut u32 = xref as *const _ as *mut _;\n+        unsafe { *x = 42; } // invalidates shared ref, activates raw\n+    }\n+    let _x = *xref; //~ ERROR is not frozen\n }"}, {"sha": "fc0dbb9e13133e8d299af04ae672d24e26ec2e96", "filename": "tests/compile-fail-fullmir/stacked_borrows/invalidate_against_barrier1.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier1.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -0,0 +1,13 @@\n+fn inner(x: *mut i32, _y: &mut i32) {\n+    // If `x` and `y` alias, retagging is fine with this... but we really\n+    // shouldn't be allowed to use `x` at all because `y` was assumed to be\n+    // unique for the duration of this call.\n+    let _val = unsafe { *x }; //~ ERROR barrier\n+}\n+\n+fn main() {\n+    let mut x = 0;\n+    let xraw = &mut x as *mut _;\n+    let xref = unsafe { &mut *xraw };\n+    inner(xraw, xref);\n+}"}, {"sha": "a080c0958e4006dd382d9b47fdaab155ccb49ff0", "filename": "tests/compile-fail-fullmir/stacked_borrows/invalidate_against_barrier2.rs", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Finvalidate_against_barrier2.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -0,0 +1,13 @@\n+fn inner(x: *mut i32, _y: &i32) {\n+    // If `x` and `y` alias, retagging is fine with this... but we really\n+    // shouldn't be allowed to write to `x` at all because `y` was assumed to be\n+    // immutable for the duration of this call.\n+    unsafe { *x = 0 }; //~ ERROR barrier\n+}\n+\n+fn main() {\n+    let mut x = 0;\n+    let xraw = &mut x as *mut _;\n+    let xref = unsafe { &*xraw };\n+    inner(xraw, xref);\n+}"}, {"sha": "3fe6b6567423c80f9fd706c11f4469660c67254f", "filename": "tests/compile-fail-fullmir/stacked_borrows/mut_exclusive_violation1.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fmut_exclusive_violation1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fmut_exclusive_violation1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail-fullmir%2Fstacked_borrows%2Fmut_exclusive_violation1.rs?ref=8d2bc97d7c3927cc8cb53afeaf97bd832be2b7c2", "patch": "@@ -21,7 +21,7 @@ fn unknown_code_1(x: &i32) { unsafe {\n } }\n \n fn unknown_code_2() { unsafe {\n-    *LEAK = 7; //~ ERROR does not exist on the stack\n+    *LEAK = 7; //~ ERROR barrier\n } }\n \n fn main() {"}, {"sha": "f86fef9454e82891f1b8e15a3450788b18b1a3fa", "filename": "tests/compile-fail/validity/undef.rs", "status": "removed", "additions": 0, "deletions": 12, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/559ad2db4a543d69d2b1438cdbcc0e8c3b18484c/tests%2Fcompile-fail%2Fvalidity%2Fundef.rs", "raw_url": "https://github.com/rust-lang/rust/raw/559ad2db4a543d69d2b1438cdbcc0e8c3b18484c/tests%2Fcompile-fail%2Fvalidity%2Fundef.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fcompile-fail%2Fvalidity%2Fundef.rs?ref=559ad2db4a543d69d2b1438cdbcc0e8c3b18484c", "patch": "@@ -1,12 +0,0 @@\n-#![allow(unused_variables)]\n-// error-pattern: encountered undefined address in pointer\n-\n-use std::mem;\n-\n-fn make_raw() -> *const f32 {\n-    unsafe { mem::uninitialized() }\n-}\n-\n-fn main() {\n-    let _x = make_raw();\n-}"}]}