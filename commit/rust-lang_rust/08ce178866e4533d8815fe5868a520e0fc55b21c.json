{"sha": "08ce178866e4533d8815fe5868a520e0fc55b21c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA4Y2UxNzg4NjZlNDUzM2Q4ODE1ZmU1ODY4YTUyMGUwZmM1NWIyMWM=", "commit": {"author": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-12-05T18:06:39Z"}, "committer": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-12-05T18:06:39Z"}, "message": "rollup merge of #19274: alexcrichton/rewrite-sync\n\nThis commit is a reimplementation of `std::sync` to be based on the\nsystem-provided primitives wherever possible. The previous implementation was\nfundamentally built on top of channels, and as part of the runtime reform it has\nbecome clear that this is not the level of abstraction that the standard level\nshould be providing. This rewrite aims to provide as thin of a shim as possible\non top of the system primitives in order to make them safe.\n\nThe overall interface of the `std::sync` module has in general not changed, but\nthere are a few important distinctions, highlighted below:\n\n* The condition variable type, `Condvar`, has been separated out of a `Mutex`.\n  A condition variable is now an entirely separate type. This separation\n  benefits users who only use one mutex, and provides a clearer distinction of\n  who's responsible for managing condition variables (the application).\n\n* All of `Condvar`, `Mutex`, and `RWLock` are now directly built on top of\n  system primitives rather than using a custom implementation. The `Once`,\n  `Barrier`, and `Semaphore` types are still built upon these abstractions of\n  the system primitives.\n\n* The `Condvar`, `Mutex`, and `RWLock` types all have a new static type and\n  constant initializer corresponding to them. These are provided primarily for C\n  FFI interoperation, but are often useful to otherwise simply have a global\n  lock. The types, however, will leak memory unless `destroy()` is called on\n  them, which is clearly documented.\n\n* The fundamental architecture of this design is to provide two separate layers.\n  The first layer is that exposed by `sys_common` which is a cross-platform\n  bare-metal abstraction of the system synchronization primitives. No attempt is\n  made at making this layer safe, and it is quite unsafe to use! It is currently\n  not exported as part of the API of the standard library, but the stabilization\n  of the `sys` module will ensure that these will be exposed in time. The\n  purpose of this layer is to provide the core cross-platform abstractions if\n  necessary to implementors.\n\n  The second layer is the layer provided by `std::sync` which is intended to be\n  the thinnest possible layer on top of `sys_common` which is entirely safe to\n  use. There are a few concerns which need to be addressed when making these\n  system primitives safe:\n\n    * Once used, the OS primitives can never be **moved**. This means that they\n      essentially need to have a stable address. The static primitives use\n      `&'static self` to enforce this, and the non-static primitives all use a\n      `Box` to provide this guarantee.\n\n    * Poisoning is leveraged to ensure that invalid data is not accessible from\n      other tasks after one has panicked.\n\n  In addition to these overall blanket safety limitations, each primitive has a\n  few restrictions of its own:\n\n    * Mutexes and rwlocks can only be unlocked from the same thread that they\n      were locked by. This is achieved through RAII lock guards which cannot be\n      sent across threads.\n\n    * Mutexes and rwlocks can only be unlocked if they were previously locked.\n      This is achieved by not exposing an unlocking method.\n\n    * A condition variable can only be waited on with a locked mutex. This is\n      achieved by requiring a `MutexGuard` in the `wait()` method.\n\n    * A condition variable cannot be used concurrently with more than one mutex.\n      This is guaranteed by dynamically binding a condition variable to\n      precisely one mutex for its entire lifecycle. This restriction may be able\n      to be relaxed in the future (a mutex is unbound when no threads are\n      waiting on the condvar), but for now it is sufficient to guarantee safety.\n\n* Condvars support timeouts for their blocking operations. The\n  implementation for these operations is provided by the system.\n\nDue to the modification of the `Condvar` API, removal of the `std::sync::mutex`\nAPI, and reimplementation, this is a breaking change. Most code should be fairly\neasy to port using the examples in the documentation of these primitives.\n\n[breaking-change]\n\nCloses #17094\nCloses #18003", "tree": {"sha": "3aeedd65ff8df034c51c630c3e53c074e295f793", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3aeedd65ff8df034c51c630c3e53c074e295f793"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/08ce178866e4533d8815fe5868a520e0fc55b21c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/08ce178866e4533d8815fe5868a520e0fc55b21c", "html_url": "https://github.com/rust-lang/rust/commit/08ce178866e4533d8815fe5868a520e0fc55b21c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/08ce178866e4533d8815fe5868a520e0fc55b21c/comments", "author": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "committer": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4573da6f4ffb276c31773679fd19581fc15ded8f", "url": "https://api.github.com/repos/rust-lang/rust/commits/4573da6f4ffb276c31773679fd19581fc15ded8f", "html_url": "https://github.com/rust-lang/rust/commit/4573da6f4ffb276c31773679fd19581fc15ded8f"}, {"sha": "c3adbd34c4e637d20a184eb03f09b30c69de8b6e", "url": "https://api.github.com/repos/rust-lang/rust/commits/c3adbd34c4e637d20a184eb03f09b30c69de8b6e", "html_url": "https://github.com/rust-lang/rust/commit/c3adbd34c4e637d20a184eb03f09b30c69de8b6e"}], "stats": {"total": 5801, "additions": 2572, "deletions": 3229}, "files": [{"sha": "7669df36b041d9282aea7e22d7b0f771d7332e86", "filename": "src/etc/licenseck.py", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Fetc%2Flicenseck.py", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Fetc%2Flicenseck.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Flicenseck.py?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -38,9 +38,8 @@\n     \"rt/isaac/randport.cpp\", # public domain\n     \"rt/isaac/rand.h\", # public domain\n     \"rt/isaac/standard.h\", # public domain\n-    \"libstd/sync/mpsc_queue.rs\", # BSD\n-    \"libstd/sync/spsc_queue.rs\", # BSD\n-    \"libstd/sync/mpmc_bounded_queue.rs\", # BSD\n+    \"libstd/comm/mpsc_queue.rs\", # BSD\n+    \"libstd/comm/spsc_queue.rs\", # BSD\n     \"test/bench/shootout-binarytrees.rs\", # BSD\n     \"test/bench/shootout-chameneos-redux.rs\", # BSD\n     \"test/bench/shootout-fannkuch-redux.rs\", # BSD"}, {"sha": "d291ed7256743b224a8e4a4806ce5fb3a6871973", "filename": "src/libstd/comm/mod.rs", "status": "modified", "additions": 12, "deletions": 8, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fmod.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -354,6 +354,8 @@ mod select;\n mod shared;\n mod stream;\n mod sync;\n+mod mpsc_queue;\n+mod spsc_queue;\n \n /// The receiving-half of Rust's channel type. This half can only be owned by\n /// one task\n@@ -628,24 +630,26 @@ impl<T: Send> Sender<T> {\n #[unstable]\n impl<T: Send> Clone for Sender<T> {\n     fn clone(&self) -> Sender<T> {\n-        let (packet, sleeper) = match *unsafe { self.inner() } {\n+        let (packet, sleeper, guard) = match *unsafe { self.inner() } {\n             Oneshot(ref p) => {\n                 let a = Arc::new(UnsafeCell::new(shared::Packet::new()));\n                 unsafe {\n-                    (*a.get()).postinit_lock();\n+                    let guard = (*a.get()).postinit_lock();\n                     match (*p.get()).upgrade(Receiver::new(Shared(a.clone()))) {\n-                        oneshot::UpSuccess | oneshot::UpDisconnected => (a, None),\n-                        oneshot::UpWoke(task) => (a, Some(task))\n+                        oneshot::UpSuccess |\n+                        oneshot::UpDisconnected => (a, None, guard),\n+                        oneshot::UpWoke(task) => (a, Some(task), guard)\n                     }\n                 }\n             }\n             Stream(ref p) => {\n                 let a = Arc::new(UnsafeCell::new(shared::Packet::new()));\n                 unsafe {\n-                    (*a.get()).postinit_lock();\n+                    let guard = (*a.get()).postinit_lock();\n                     match (*p.get()).upgrade(Receiver::new(Shared(a.clone()))) {\n-                        stream::UpSuccess | stream::UpDisconnected => (a, None),\n-                        stream::UpWoke(task) => (a, Some(task)),\n+                        stream::UpSuccess |\n+                        stream::UpDisconnected => (a, None, guard),\n+                        stream::UpWoke(task) => (a, Some(task), guard),\n                     }\n                 }\n             }\n@@ -657,7 +661,7 @@ impl<T: Send> Clone for Sender<T> {\n         };\n \n         unsafe {\n-            (*packet.get()).inherit_blocker(sleeper);\n+            (*packet.get()).inherit_blocker(sleeper, guard);\n \n             let tmp = Sender::new(Shared(packet.clone()));\n             mem::swap(self.inner_mut(), tmp.inner_mut());"}, {"sha": "d4249abc3dda1188715d076f48b409a5c4cff36a", "filename": "src/libstd/comm/mpsc_queue.rs", "status": "renamed", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fmpsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fmpsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fmpsc_queue.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -132,15 +132,6 @@ impl<T: Send> Queue<T> {\n             if self.head.load(Acquire) == tail {Empty} else {Inconsistent}\n         }\n     }\n-\n-    /// Attempts to pop data from this queue, but doesn't attempt too hard. This\n-    /// will canonicalize inconsistent states to a `None` value.\n-    pub fn casual_pop(&self) -> Option<T> {\n-        match self.pop() {\n-            Data(t) => Some(t),\n-            Empty | Inconsistent => None,\n-        }\n-    }\n }\n \n #[unsafe_destructor]", "previous_filename": "src/libstd/sync/mpsc_queue.rs"}, {"sha": "13b5e10fcd3dcd02cbf2ffb3a95a82cc005fb984", "filename": "src/libstd/comm/shared.rs", "status": "modified", "additions": 11, "deletions": 10, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fshared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fshared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fshared.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -26,12 +26,11 @@ use alloc::boxed::Box;\n use core::cmp;\n use core::int;\n use rustrt::local::Local;\n-use rustrt::mutex::NativeMutex;\n use rustrt::task::{Task, BlockedTask};\n use rustrt::thread::Thread;\n \n-use sync::atomic;\n-use sync::mpsc_queue as mpsc;\n+use sync::{atomic, Mutex, MutexGuard};\n+use comm::mpsc_queue as mpsc;\n \n const DISCONNECTED: int = int::MIN;\n const FUDGE: int = 1024;\n@@ -56,7 +55,7 @@ pub struct Packet<T> {\n \n     // this lock protects various portions of this implementation during\n     // select()\n-    select_lock: NativeMutex,\n+    select_lock: Mutex<()>,\n }\n \n pub enum Failure {\n@@ -76,7 +75,7 @@ impl<T: Send> Packet<T> {\n             channels: atomic::AtomicInt::new(2),\n             port_dropped: atomic::AtomicBool::new(false),\n             sender_drain: atomic::AtomicInt::new(0),\n-            select_lock: unsafe { NativeMutex::new() },\n+            select_lock: Mutex::new(()),\n         };\n         return p;\n     }\n@@ -86,16 +85,18 @@ impl<T: Send> Packet<T> {\n     // In other case mutex data will be duplicated while cloning\n     // and that could cause problems on platforms where it is\n     // represented by opaque data structure\n-    pub fn postinit_lock(&mut self) {\n-        unsafe { self.select_lock.lock_noguard() }\n+    pub fn postinit_lock(&self) -> MutexGuard<()> {\n+        self.select_lock.lock()\n     }\n \n     // This function is used at the creation of a shared packet to inherit a\n     // previously blocked task. This is done to prevent spurious wakeups of\n     // tasks in select().\n     //\n     // This can only be called at channel-creation time\n-    pub fn inherit_blocker(&mut self, task: Option<BlockedTask>) {\n+    pub fn inherit_blocker(&mut self,\n+                           task: Option<BlockedTask>,\n+                           guard: MutexGuard<()>) {\n         match task {\n             Some(task) => {\n                 assert_eq!(self.cnt.load(atomic::SeqCst), 0);\n@@ -135,7 +136,7 @@ impl<T: Send> Packet<T> {\n         // interfere with this method. After we unlock this lock, we're\n         // signifying that we're done modifying self.cnt and self.to_wake and\n         // the port is ready for the world to continue using it.\n-        unsafe { self.select_lock.unlock_noguard() }\n+        drop(guard);\n     }\n \n     pub fn send(&mut self, t: T) -> Result<(), T> {\n@@ -441,7 +442,7 @@ impl<T: Send> Packet<T> {\n         // done with. Without this bounce, we can race with inherit_blocker\n         // about looking at and dealing with to_wake. Once we have acquired the\n         // lock, we are guaranteed that inherit_blocker is done.\n-        unsafe {\n+        {\n             let _guard = self.select_lock.lock();\n         }\n "}, {"sha": "a6b4ab71bacc1be1acabe6fc15192f63c15146cd", "filename": "src/libstd/comm/spsc_queue.rs", "status": "renamed", "additions": 56, "deletions": 104, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fspsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fspsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fspsc_queue.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -40,7 +40,6 @@ use core::prelude::*;\n use alloc::boxed::Box;\n use core::mem;\n use core::cell::UnsafeCell;\n-use alloc::arc::Arc;\n \n use sync::atomic::{AtomicPtr, Relaxed, AtomicUint, Acquire, Release};\n \n@@ -74,39 +73,6 @@ pub struct Queue<T> {\n     cache_subtractions: AtomicUint,\n }\n \n-/// A safe abstraction for the consumer in a single-producer single-consumer\n-/// queue.\n-pub struct Consumer<T> {\n-    inner: Arc<Queue<T>>\n-}\n-\n-impl<T: Send> Consumer<T> {\n-    /// Attempts to pop the value from the head of the queue, returning `None`\n-    /// if the queue is empty.\n-    pub fn pop(&mut self) -> Option<T> {\n-        self.inner.pop()\n-    }\n-\n-    /// Attempts to peek at the head of the queue, returning `None` if the queue\n-    /// is empty.\n-    pub fn peek<'a>(&'a mut self) -> Option<&'a mut T> {\n-        self.inner.peek()\n-    }\n-}\n-\n-/// A safe abstraction for the producer in a single-producer single-consumer\n-/// queue.\n-pub struct Producer<T> {\n-    inner: Arc<Queue<T>>\n-}\n-\n-impl<T: Send> Producer<T> {\n-    /// Pushes a new value onto the queue.\n-    pub fn push(&mut self, t: T) {\n-        self.inner.push(t)\n-    }\n-}\n-\n impl<T: Send> Node<T> {\n     fn new() -> *mut Node<T> {\n         unsafe {\n@@ -118,30 +84,6 @@ impl<T: Send> Node<T> {\n     }\n }\n \n-/// Creates a new queue with a consumer-producer pair.\n-///\n-/// The producer returned is connected to the consumer to push all data to\n-/// the consumer.\n-///\n-/// # Arguments\n-///\n-///   * `bound` - This queue implementation is implemented with a linked\n-///               list, and this means that a push is always a malloc. In\n-///               order to amortize this cost, an internal cache of nodes is\n-///               maintained to prevent a malloc from always being\n-///               necessary. This bound is the limit on the size of the\n-///               cache (if desired). If the value is 0, then the cache has\n-///               no bound. Otherwise, the cache will never grow larger than\n-///               `bound` (although the queue itself could be much larger.\n-pub fn queue<T: Send>(bound: uint) -> (Consumer<T>, Producer<T>) {\n-    let q = unsafe { Queue::new(bound) };\n-    let arc = Arc::new(q);\n-    let consumer = Consumer { inner: arc.clone() };\n-    let producer = Producer { inner: arc };\n-\n-    (consumer, producer)\n-}\n-\n impl<T: Send> Queue<T> {\n     /// Creates a new queue.\n     ///\n@@ -296,78 +238,88 @@ impl<T: Send> Drop for Queue<T> {\n mod test {\n     use prelude::*;\n \n-    use super::{queue};\n+    use sync::Arc;\n+    use super::Queue;\n \n     #[test]\n     fn smoke() {\n-        let (mut consumer, mut producer) = queue(0);\n-        producer.push(1i);\n-        producer.push(2);\n-        assert_eq!(consumer.pop(), Some(1i));\n-        assert_eq!(consumer.pop(), Some(2));\n-        assert_eq!(consumer.pop(), None);\n-        producer.push(3);\n-        producer.push(4);\n-        assert_eq!(consumer.pop(), Some(3));\n-        assert_eq!(consumer.pop(), Some(4));\n-        assert_eq!(consumer.pop(), None);\n+        unsafe {\n+            let queue = Queue::new(0);\n+            queue.push(1i);\n+            queue.push(2);\n+            assert_eq!(queue.pop(), Some(1i));\n+            assert_eq!(queue.pop(), Some(2));\n+            assert_eq!(queue.pop(), None);\n+            queue.push(3);\n+            queue.push(4);\n+            assert_eq!(queue.pop(), Some(3));\n+            assert_eq!(queue.pop(), Some(4));\n+            assert_eq!(queue.pop(), None);\n+        }\n     }\n \n     #[test]\n     fn peek() {\n-        let (mut consumer, mut producer) = queue(0);\n-        producer.push(vec![1i]);\n+        unsafe {\n+            let queue = Queue::new(0);\n+            queue.push(vec![1i]);\n+\n+            // Ensure the borrowchecker works\n+            match queue.peek() {\n+                Some(vec) => match vec.as_slice() {\n+                    // Note that `pop` is not allowed here due to borrow\n+                    [1] => {}\n+                    _ => return\n+                },\n+                None => unreachable!()\n+            }\n \n-        // Ensure the borrowchecker works\n-        match consumer.peek() {\n-            Some(vec) => match vec.as_slice() {\n-                // Note that `pop` is not allowed here due to borrow\n-                [1] => {}\n-                _ => return\n-            },\n-            None => unreachable!()\n+            queue.pop();\n         }\n-\n-        consumer.pop();\n     }\n \n     #[test]\n     fn drop_full() {\n-        let (_, mut producer) = queue(0);\n-        producer.push(box 1i);\n-        producer.push(box 2i);\n+        unsafe {\n+            let q = Queue::new(0);\n+            q.push(box 1i);\n+            q.push(box 2i);\n+        }\n     }\n \n     #[test]\n     fn smoke_bound() {\n-        let (mut consumer, mut producer) = queue(1);\n-        producer.push(1i);\n-        producer.push(2);\n-        assert_eq!(consumer.pop(), Some(1));\n-        assert_eq!(consumer.pop(), Some(2));\n-        assert_eq!(consumer.pop(), None);\n-        producer.push(3);\n-        producer.push(4);\n-        assert_eq!(consumer.pop(), Some(3));\n-        assert_eq!(consumer.pop(), Some(4));\n-        assert_eq!(consumer.pop(), None);\n+        unsafe {\n+            let q = Queue::new(0);\n+            q.push(1i);\n+            q.push(2);\n+            assert_eq!(q.pop(), Some(1));\n+            assert_eq!(q.pop(), Some(2));\n+            assert_eq!(q.pop(), None);\n+            q.push(3);\n+            q.push(4);\n+            assert_eq!(q.pop(), Some(3));\n+            assert_eq!(q.pop(), Some(4));\n+            assert_eq!(q.pop(), None);\n+        }\n     }\n \n     #[test]\n     fn stress() {\n-        stress_bound(0);\n-        stress_bound(1);\n+        unsafe {\n+            stress_bound(0);\n+            stress_bound(1);\n+        }\n \n-        fn stress_bound(bound: uint) {\n-            let (consumer, mut producer) = queue(bound);\n+        unsafe fn stress_bound(bound: uint) {\n+            let q = Arc::new(Queue::new(bound));\n \n             let (tx, rx) = channel();\n+            let q2 = q.clone();\n             spawn(proc() {\n-                // Move the consumer to a local mutable slot\n-                let mut consumer = consumer;\n                 for _ in range(0u, 100000) {\n                     loop {\n-                        match consumer.pop() {\n+                        match q2.pop() {\n                             Some(1i) => break,\n                             Some(_) => panic!(),\n                             None => {}\n@@ -377,7 +329,7 @@ mod test {\n                 tx.send(());\n             });\n             for _ in range(0i, 100000) {\n-                producer.push(1);\n+                q.push(1);\n             }\n             rx.recv();\n         }", "previous_filename": "src/libstd/sync/spsc_queue.rs"}, {"sha": "06ab4f4427aa664a1e5c8b1edfc7c4bc903bcabf", "filename": "src/libstd/comm/stream.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fcomm%2Fstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fstream.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -32,7 +32,7 @@ use rustrt::task::{Task, BlockedTask};\n use rustrt::thread::Thread;\n \n use sync::atomic;\n-use sync::spsc_queue as spsc;\n+use comm::spsc_queue as spsc;\n use comm::Receiver;\n \n const DISCONNECTED: int = int::MIN;"}, {"sha": "160365dac361223453acc70d19c9b4790edece75", "filename": "src/libstd/dynamic_lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fdynamic_lib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fdynamic_lib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fdynamic_lib.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -225,8 +225,8 @@ pub mod dl {\n     }\n \n     pub fn check_for_errors_in<T>(f: || -> T) -> Result<T, String> {\n-        use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n-        static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n+        use sync::{StaticMutex, MUTEX_INIT};\n+        static LOCK: StaticMutex = MUTEX_INIT;\n         unsafe {\n             // dlerror isn't thread safe, so we need to lock around this entire\n             // sequence"}, {"sha": "d4274d7e4017e2a1b8dd9a461957f57099dc339a", "filename": "src/libstd/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Flib.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -106,7 +106,7 @@\n #![allow(unknown_features)]\n #![feature(macro_rules, globs, linkage)]\n #![feature(default_type_params, phase, lang_items, unsafe_destructor)]\n-#![feature(import_shadowing, slicing_syntax)]\n+#![feature(import_shadowing, slicing_syntax, tuple_indexing)]\n \n // Don't link to std. We are std.\n #![no_std]"}, {"sha": "a8adfec34ed683c48ed07f56e5244e4d14d4bd10", "filename": "src/libstd/os.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fos.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -209,14 +209,12 @@ Accessing environment variables is not generally threadsafe.\n Serialize access through a global lock.\n */\n fn with_env_lock<T>(f: || -> T) -> T {\n-    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use sync::{StaticMutex, MUTEX_INIT};\n \n-    static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n+    static LOCK: StaticMutex = MUTEX_INIT;\n \n-    unsafe {\n-        let _guard = LOCK.lock();\n-        f()\n-    }\n+    let _guard = LOCK.lock();\n+    f()\n }\n \n /// Returns a vector of (variable, value) pairs, for all the environment"}, {"sha": "159fc3080e836aba0adfbcb74a53d15e6c5a8233", "filename": "src/libstd/rt/backtrace.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Frt%2Fbacktrace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Frt%2Fbacktrace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fbacktrace.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -238,7 +238,7 @@ mod imp {\n     use mem;\n     use option::{Some, None, Option};\n     use result::{Ok, Err};\n-    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use sync::{StaticMutex, MUTEX_INIT};\n \n     /// As always - iOS on arm uses SjLj exceptions and\n     /// _Unwind_Backtrace is even not available there. Still,\n@@ -264,8 +264,8 @@ mod imp {\n         // while it doesn't requires lock for work as everything is\n         // local, it still displays much nicer backtraces when a\n         // couple of tasks panic simultaneously\n-        static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n-        let _g = unsafe { LOCK.lock() };\n+        static LOCK: StaticMutex = MUTEX_INIT;\n+        let _g = LOCK.lock();\n \n         try!(writeln!(w, \"stack backtrace:\"));\n         // 100 lines should be enough\n@@ -297,8 +297,8 @@ mod imp {\n         // is semi-reasonable in terms of printing anyway, and we know that all\n         // I/O done here is blocking I/O, not green I/O, so we don't have to\n         // worry about this being a native vs green mutex.\n-        static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n-        let _g = unsafe { LOCK.lock() };\n+        static LOCK: StaticMutex = MUTEX_INIT;\n+        let _g = LOCK.lock();\n \n         try!(writeln!(w, \"stack backtrace:\"));\n \n@@ -667,7 +667,7 @@ mod imp {\n     use option::{Some, None};\n     use path::Path;\n     use result::{Ok, Err};\n-    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use sync::{StaticMutex, MUTEX_INIT};\n     use slice::SlicePrelude;\n     use str::StrPrelude;\n     use dynamic_lib::DynamicLibrary;\n@@ -928,8 +928,8 @@ mod imp {\n     pub fn write(w: &mut Writer) -> IoResult<()> {\n         // According to windows documentation, all dbghelp functions are\n         // single-threaded.\n-        static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n-        let _g = unsafe { LOCK.lock() };\n+        static LOCK: StaticMutex = MUTEX_INIT;\n+        let _g = LOCK.lock();\n \n         // Open up dbghelp.dll, we don't link to it explicitly because it can't\n         // always be found. Additionally, it's nice having fewer dependencies."}, {"sha": "5e6dc6ec650836ebe204a9d90d591ca5b631587c", "filename": "src/libstd/sync/barrier.rs", "status": "added", "additions": 116, "deletions": 0, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fbarrier.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fbarrier.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fbarrier.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,116 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use sync::{Mutex, Condvar};\n+\n+/// A barrier enables multiple tasks to synchronize the beginning\n+/// of some computation.\n+///\n+/// ```rust\n+/// use std::sync::{Arc, Barrier};\n+///\n+/// let barrier = Arc::new(Barrier::new(10));\n+/// for _ in range(0u, 10) {\n+///     let c = barrier.clone();\n+///     // The same messages will be printed together.\n+///     // You will NOT see any interleaving.\n+///     spawn(proc() {\n+///         println!(\"before wait\");\n+///         c.wait();\n+///         println!(\"after wait\");\n+///     });\n+/// }\n+/// ```\n+pub struct Barrier {\n+    lock: Mutex<BarrierState>,\n+    cvar: Condvar,\n+    num_threads: uint,\n+}\n+\n+// The inner state of a double barrier\n+struct BarrierState {\n+    count: uint,\n+    generation_id: uint,\n+}\n+\n+impl Barrier {\n+    /// Create a new barrier that can block a given number of threads.\n+    ///\n+    /// A barrier will block `n`-1 threads which call `wait` and then wake up\n+    /// all threads at once when the `n`th thread calls `wait`.\n+    pub fn new(n: uint) -> Barrier {\n+        Barrier {\n+            lock: Mutex::new(BarrierState {\n+                count: 0,\n+                generation_id: 0,\n+            }),\n+            cvar: Condvar::new(),\n+            num_threads: n,\n+        }\n+    }\n+\n+    /// Block the current thread until all threads has rendezvoused here.\n+    ///\n+    /// Barriers are re-usable after all threads have rendezvoused once, and can\n+    /// be used continuously.\n+    pub fn wait(&self) {\n+        let mut lock = self.lock.lock();\n+        let local_gen = lock.generation_id;\n+        lock.count += 1;\n+        if lock.count < self.num_threads {\n+            // We need a while loop to guard against spurious wakeups.\n+            // http://en.wikipedia.org/wiki/Spurious_wakeup\n+            while local_gen == lock.generation_id &&\n+                  lock.count < self.num_threads {\n+                self.cvar.wait(&lock);\n+            }\n+        } else {\n+            lock.count = 0;\n+            lock.generation_id += 1;\n+            self.cvar.notify_all();\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use prelude::*;\n+\n+    use sync::{Arc, Barrier};\n+    use comm::Empty;\n+\n+    #[test]\n+    fn test_barrier() {\n+        let barrier = Arc::new(Barrier::new(10));\n+        let (tx, rx) = channel();\n+\n+        for _ in range(0u, 9) {\n+            let c = barrier.clone();\n+            let tx = tx.clone();\n+            spawn(proc() {\n+                c.wait();\n+                tx.send(true);\n+            });\n+        }\n+\n+        // At this point, all spawned tasks should be blocked,\n+        // so we shouldn't get anything from the port\n+        assert!(match rx.try_recv() {\n+            Err(Empty) => true,\n+            _ => false,\n+        });\n+\n+        barrier.wait();\n+        // Now, the barrier is cleared and we should get data.\n+        for _ in range(0u, 9) {\n+            rx.recv();\n+        }\n+    }\n+}"}, {"sha": "0fdd57b27922c50d5e9068eb8a20bc413e1f45cb", "filename": "src/libstd/sync/condvar.rs", "status": "added", "additions": 365, "deletions": 0, "changes": 365, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fcondvar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fcondvar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fcondvar.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,365 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use prelude::*;\n+\n+use sync::atomic::{mod, AtomicUint};\n+use sync::{mutex, StaticMutexGuard};\n+use sys_common::condvar as sys;\n+use sys_common::mutex as sys_mutex;\n+use time::Duration;\n+\n+/// A Condition Variable\n+///\n+/// Condition variables represent the ability to block a thread such that it\n+/// consumes no CPU time while waiting for an event to occur. Condition\n+/// variables are typically associated with a boolean predicate (a condition)\n+/// and a mutex. The predicate is always verified inside of the mutex before\n+/// determining that thread must block.\n+///\n+/// Functions in this module will block the current **thread** of execution and\n+/// are bindings to system-provided condition variables where possible. Note\n+/// that this module places one additional restriction over the system condition\n+/// variables: each condvar can be used with precisely one mutex at runtime. Any\n+/// attempt to use multiple mutexes on the same condition variable will result\n+/// in a runtime panic. If this is not desired, then the unsafe primitives in\n+/// `sys` do not have this restriction but may result in undefined behavior.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::sync::{Arc, Mutex, Condvar};\n+///\n+/// let pair = Arc::new((Mutex::new(false), Condvar::new()));\n+/// let pair2 = pair.clone();\n+///\n+/// // Inside of our lock, spawn a new thread, and then wait for it to start\n+/// spawn(proc() {\n+///     let &(ref lock, ref cvar) = &*pair2;\n+///     let mut started = lock.lock();\n+///     *started = true;\n+///     cvar.notify_one();\n+/// });\n+///\n+/// // wait for the thread to start up\n+/// let &(ref lock, ref cvar) = &*pair;\n+/// let started = lock.lock();\n+/// while !*started {\n+///     cvar.wait(&started);\n+/// }\n+/// ```\n+pub struct Condvar { inner: Box<StaticCondvar> }\n+\n+/// Statically allocated condition variables.\n+///\n+/// This structure is identical to `Condvar` except that it is suitable for use\n+/// in static initializers for other structures.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::sync::{StaticCondvar, CONDVAR_INIT};\n+///\n+/// static CVAR: StaticCondvar = CONDVAR_INIT;\n+/// ```\n+pub struct StaticCondvar {\n+    inner: sys::Condvar,\n+    mutex: AtomicUint,\n+}\n+\n+/// Constant initializer for a statically allocated condition variable.\n+pub const CONDVAR_INIT: StaticCondvar = StaticCondvar {\n+    inner: sys::CONDVAR_INIT,\n+    mutex: atomic::INIT_ATOMIC_UINT,\n+};\n+\n+/// A trait for vaules which can be passed to the waiting methods of condition\n+/// variables. This is implemented by the mutex guards in this module.\n+///\n+/// Note that this trait should likely not be implemented manually unless you\n+/// really know what you're doing.\n+pub trait AsMutexGuard {\n+    #[allow(missing_docs)]\n+    unsafe fn as_mutex_guard(&self) -> &StaticMutexGuard;\n+}\n+\n+impl Condvar {\n+    /// Creates a new condition variable which is ready to be waited on and\n+    /// notified.\n+    pub fn new() -> Condvar {\n+        Condvar {\n+            inner: box StaticCondvar {\n+                inner: unsafe { sys::Condvar::new() },\n+                mutex: AtomicUint::new(0),\n+            }\n+        }\n+    }\n+\n+    /// Block the current thread until this condition variable receives a\n+    /// notification.\n+    ///\n+    /// This function will atomically unlock the mutex specified (represented by\n+    /// `guard`) and block the current thread. This means that any calls to\n+    /// `notify_*()` which happen logically after the mutex is unlocked are\n+    /// candidates to wake this thread up. When this function call returns, the\n+    /// lock specified will have been re-acquired.\n+    ///\n+    /// Note that this function is susceptible to spurious wakeups. Condition\n+    /// variables normally have a boolean predicate associated with them, and\n+    /// the predicate must always be checked each time this function returns to\n+    /// protect against spurious wakeups.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function will `panic!()` if it is used with more than one mutex\n+    /// over time. Each condition variable is dynamically bound to exactly one\n+    /// mutex to ensure defined behavior across platforms. If this functionality\n+    /// is not desired, then unsafe primitives in `sys` are provided.\n+    pub fn wait<T: AsMutexGuard>(&self, mutex_guard: &T) {\n+        unsafe {\n+            let me: &'static Condvar = &*(self as *const _);\n+            me.inner.wait(mutex_guard)\n+        }\n+    }\n+\n+    /// Wait on this condition variable for a notification, timing out after a\n+    /// specified duration.\n+    ///\n+    /// The semantics of this function are equivalent to `wait()` except that\n+    /// the thread will be blocked for roughly no longer than `dur`. This method\n+    /// should not be used for precise timing due to anomalies such as\n+    /// preemption or platform differences that may not cause the maximum amount\n+    /// of time waited to be precisely `dur`.\n+    ///\n+    /// If the wait timed out, then `false` will be returned. Otherwise if a\n+    /// notification was received then `true` will be returned.\n+    ///\n+    /// Like `wait`, the lock specified will be re-acquired when this function\n+    /// returns, regardless of whether the timeout elapsed or not.\n+    // Note that this method is *not* public, and this is quite intentional\n+    // because we're not quite sure about the semantics of relative vs absolute\n+    // durations or how the timing guarantees play into what the system APIs\n+    // provide. There are also additional concerns about the unix-specific\n+    // implementation which may need to be addressed.\n+    #[allow(dead_code)]\n+    fn wait_timeout<T: AsMutexGuard>(&self, mutex_guard: &T,\n+                                     dur: Duration) -> bool {\n+        unsafe {\n+            let me: &'static Condvar = &*(self as *const _);\n+            me.inner.wait_timeout(mutex_guard, dur)\n+        }\n+    }\n+\n+    /// Wake up one blocked thread on this condvar.\n+    ///\n+    /// If there is a blocked thread on this condition variable, then it will\n+    /// be woken up from its call to `wait` or `wait_timeout`. Calls to\n+    /// `notify_one` are not buffered in any way.\n+    ///\n+    /// To wake up all threads, see `notify_one()`.\n+    pub fn notify_one(&self) { unsafe { self.inner.inner.notify_one() } }\n+\n+    /// Wake up all blocked threads on this condvar.\n+    ///\n+    /// This method will ensure that any current waiters on the condition\n+    /// variable are awoken. Calls to `notify_all()` are not buffered in any\n+    /// way.\n+    ///\n+    /// To wake up only one thread, see `notify_one()`.\n+    pub fn notify_all(&self) { unsafe { self.inner.inner.notify_all() } }\n+}\n+\n+impl Drop for Condvar {\n+    fn drop(&mut self) {\n+        unsafe { self.inner.inner.destroy() }\n+    }\n+}\n+\n+impl StaticCondvar {\n+    /// Block the current thread until this condition variable receives a\n+    /// notification.\n+    ///\n+    /// See `Condvar::wait`.\n+    pub fn wait<T: AsMutexGuard>(&'static self, mutex_guard: &T) {\n+        unsafe {\n+            let lock = mutex_guard.as_mutex_guard();\n+            let sys = mutex::guard_lock(lock);\n+            self.verify(sys);\n+            self.inner.wait(sys);\n+            (*mutex::guard_poison(lock)).check(\"mutex\");\n+        }\n+    }\n+\n+    /// Wait on this condition variable for a notification, timing out after a\n+    /// specified duration.\n+    ///\n+    /// See `Condvar::wait_timeout`.\n+    #[allow(dead_code)] // may want to stabilize this later, see wait_timeout above\n+    fn wait_timeout<T: AsMutexGuard>(&'static self, mutex_guard: &T,\n+                                     dur: Duration) -> bool {\n+        unsafe {\n+            let lock = mutex_guard.as_mutex_guard();\n+            let sys = mutex::guard_lock(lock);\n+            self.verify(sys);\n+            let ret = self.inner.wait_timeout(sys, dur);\n+            (*mutex::guard_poison(lock)).check(\"mutex\");\n+            return ret;\n+        }\n+    }\n+\n+    /// Wake up one blocked thread on this condvar.\n+    ///\n+    /// See `Condvar::notify_one`.\n+    pub fn notify_one(&'static self) { unsafe { self.inner.notify_one() } }\n+\n+    /// Wake up all blocked threads on this condvar.\n+    ///\n+    /// See `Condvar::notify_all`.\n+    pub fn notify_all(&'static self) { unsafe { self.inner.notify_all() } }\n+\n+    /// Deallocate all resources associated with this static condvar.\n+    ///\n+    /// This method is unsafe to call as there is no guarantee that there are no\n+    /// active users of the condvar, and this also doesn't prevent any future\n+    /// users of the condvar. This method is required to be called to not leak\n+    /// memory on all platforms.\n+    pub unsafe fn destroy(&'static self) {\n+        self.inner.destroy()\n+    }\n+\n+    fn verify(&self, mutex: &sys_mutex::Mutex) {\n+        let addr = mutex as *const _ as uint;\n+        match self.mutex.compare_and_swap(0, addr, atomic::SeqCst) {\n+            // If we got out 0, then we have successfully bound the mutex to\n+            // this cvar.\n+            0 => {}\n+\n+            // If we get out a value that's the same as `addr`, then someone\n+            // already beat us to the punch.\n+            n if n == addr => {}\n+\n+            // Anything else and we're using more than one mutex on this cvar,\n+            // which is currently disallowed.\n+            _ => panic!(\"attempted to use a condition variable with two \\\n+                         mutexes\"),\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use prelude::*;\n+\n+    use time::Duration;\n+    use super::{StaticCondvar, CONDVAR_INIT};\n+    use sync::{StaticMutex, MUTEX_INIT, Condvar, Mutex, Arc};\n+\n+    #[test]\n+    fn smoke() {\n+        let c = Condvar::new();\n+        c.notify_one();\n+        c.notify_all();\n+    }\n+\n+    #[test]\n+    fn static_smoke() {\n+        static C: StaticCondvar = CONDVAR_INIT;\n+        C.notify_one();\n+        C.notify_all();\n+        unsafe { C.destroy(); }\n+    }\n+\n+    #[test]\n+    fn notify_one() {\n+        static C: StaticCondvar = CONDVAR_INIT;\n+        static M: StaticMutex = MUTEX_INIT;\n+\n+        let g = M.lock();\n+        spawn(proc() {\n+            let _g = M.lock();\n+            C.notify_one();\n+        });\n+        C.wait(&g);\n+        drop(g);\n+        unsafe { C.destroy(); M.destroy(); }\n+    }\n+\n+    #[test]\n+    fn notify_all() {\n+        const N: uint = 10;\n+\n+        let data = Arc::new((Mutex::new(0), Condvar::new()));\n+        let (tx, rx) = channel();\n+        for _ in range(0, N) {\n+            let data = data.clone();\n+            let tx = tx.clone();\n+            spawn(proc() {\n+                let &(ref lock, ref cond) = &*data;\n+                let mut cnt = lock.lock();\n+                *cnt += 1;\n+                if *cnt == N {\n+                    tx.send(());\n+                }\n+                while *cnt != 0 {\n+                    cond.wait(&cnt);\n+                }\n+                tx.send(());\n+            });\n+        }\n+        drop(tx);\n+\n+        let &(ref lock, ref cond) = &*data;\n+        rx.recv();\n+        let mut cnt = lock.lock();\n+        *cnt = 0;\n+        cond.notify_all();\n+        drop(cnt);\n+\n+        for _ in range(0, N) {\n+            rx.recv();\n+        }\n+    }\n+\n+    #[test]\n+    fn wait_timeout() {\n+        static C: StaticCondvar = CONDVAR_INIT;\n+        static M: StaticMutex = MUTEX_INIT;\n+\n+        let g = M.lock();\n+        assert!(!C.wait_timeout(&g, Duration::nanoseconds(1000)));\n+        spawn(proc() {\n+            let _g = M.lock();\n+            C.notify_one();\n+        });\n+        assert!(C.wait_timeout(&g, Duration::days(1)));\n+        drop(g);\n+        unsafe { C.destroy(); M.destroy(); }\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn two_mutexes() {\n+        static M1: StaticMutex = MUTEX_INIT;\n+        static M2: StaticMutex = MUTEX_INIT;\n+        static C: StaticCondvar = CONDVAR_INIT;\n+\n+        let g = M1.lock();\n+        spawn(proc() {\n+            let _g = M1.lock();\n+            C.notify_one();\n+        });\n+        C.wait(&g);\n+        drop(g);\n+\n+        C.wait(&M2.lock());\n+\n+    }\n+}\n+"}, {"sha": "33f6f77eb62a3115f9db537bb5d4e1a98bf1fdfe", "filename": "src/libstd/sync/deque.rs", "status": "removed", "additions": 0, "deletions": 663, "changes": 663, "blob_url": "https://github.com/rust-lang/rust/blob/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fdeque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fdeque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fdeque.rs?ref=4573da6f4ffb276c31773679fd19581fc15ded8f", "patch": "@@ -1,663 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! A (mostly) lock-free concurrent work-stealing deque\n-//!\n-//! This module contains an implementation of the Chase-Lev work stealing deque\n-//! described in \"Dynamic Circular Work-Stealing Deque\". The implementation is\n-//! heavily based on the pseudocode found in the paper.\n-//!\n-//! This implementation does not want to have the restriction of a garbage\n-//! collector for reclamation of buffers, and instead it uses a shared pool of\n-//! buffers. This shared pool is required for correctness in this\n-//! implementation.\n-//!\n-//! The only lock-synchronized portions of this deque are the buffer allocation\n-//! and deallocation portions. Otherwise all operations are lock-free.\n-//!\n-//! # Example\n-//!\n-//!     use std::sync::deque::BufferPool;\n-//!\n-//!     let mut pool = BufferPool::new();\n-//!     let (mut worker, mut stealer) = pool.deque();\n-//!\n-//!     // Only the worker may push/pop\n-//!     worker.push(1i);\n-//!     worker.pop();\n-//!\n-//!     // Stealers take data from the other end of the deque\n-//!     worker.push(1i);\n-//!     stealer.steal();\n-//!\n-//!     // Stealers can be cloned to have many stealers stealing in parallel\n-//!     worker.push(1i);\n-//!     let mut stealer2 = stealer.clone();\n-//!     stealer2.steal();\n-\n-#![experimental]\n-\n-// NB: the \"buffer pool\" strategy is not done for speed, but rather for\n-//     correctness. For more info, see the comment on `swap_buffer`\n-\n-// FIXME: all atomic operations in this module use a SeqCst ordering. That is\n-//      probably overkill\n-\n-pub use self::Stolen::*;\n-\n-use core::prelude::*;\n-\n-use alloc::arc::Arc;\n-use alloc::heap::{allocate, deallocate};\n-use alloc::boxed::Box;\n-use vec::Vec;\n-use core::kinds::marker;\n-use core::mem::{forget, min_align_of, size_of, transmute};\n-use core::ptr;\n-use rustrt::exclusive::Exclusive;\n-\n-use sync::atomic::{AtomicInt, AtomicPtr, SeqCst};\n-\n-// Once the queue is less than 1/K full, then it will be downsized. Note that\n-// the deque requires that this number be less than 2.\n-static K: int = 4;\n-\n-// Minimum number of bits that a buffer size should be. No buffer will resize to\n-// under this value, and all deques will initially contain a buffer of this\n-// size.\n-//\n-// The size in question is 1 << MIN_BITS\n-static MIN_BITS: uint = 7;\n-\n-struct Deque<T> {\n-    bottom: AtomicInt,\n-    top: AtomicInt,\n-    array: AtomicPtr<Buffer<T>>,\n-    pool: BufferPool<T>,\n-}\n-\n-/// Worker half of the work-stealing deque. This worker has exclusive access to\n-/// one side of the deque, and uses `push` and `pop` method to manipulate it.\n-///\n-/// There may only be one worker per deque.\n-pub struct Worker<T> {\n-    deque: Arc<Deque<T>>,\n-    _noshare: marker::NoSync,\n-}\n-\n-/// The stealing half of the work-stealing deque. Stealers have access to the\n-/// opposite end of the deque from the worker, and they only have access to the\n-/// `steal` method.\n-pub struct Stealer<T> {\n-    deque: Arc<Deque<T>>,\n-    _noshare: marker::NoSync,\n-}\n-\n-/// When stealing some data, this is an enumeration of the possible outcomes.\n-#[deriving(PartialEq, Show)]\n-pub enum Stolen<T> {\n-    /// The deque was empty at the time of stealing\n-    Empty,\n-    /// The stealer lost the race for stealing data, and a retry may return more\n-    /// data.\n-    Abort,\n-    /// The stealer has successfully stolen some data.\n-    Data(T),\n-}\n-\n-/// The allocation pool for buffers used by work-stealing deques. Right now this\n-/// structure is used for reclamation of memory after it is no longer in use by\n-/// deques.\n-///\n-/// This data structure is protected by a mutex, but it is rarely used. Deques\n-/// will only use this structure when allocating a new buffer or deallocating a\n-/// previous one.\n-pub struct BufferPool<T> {\n-    pool: Arc<Exclusive<Vec<Box<Buffer<T>>>>>,\n-}\n-\n-/// An internal buffer used by the chase-lev deque. This structure is actually\n-/// implemented as a circular buffer, and is used as the intermediate storage of\n-/// the data in the deque.\n-///\n-/// This type is implemented with *T instead of Vec<T> for two reasons:\n-///\n-///   1. There is nothing safe about using this buffer. This easily allows the\n-///      same value to be read twice in to rust, and there is nothing to\n-///      prevent this. The usage by the deque must ensure that one of the\n-///      values is forgotten. Furthermore, we only ever want to manually run\n-///      destructors for values in this buffer (on drop) because the bounds\n-///      are defined by the deque it's owned by.\n-///\n-///   2. We can certainly avoid bounds checks using *T instead of Vec<T>, although\n-///      LLVM is probably pretty good at doing this already.\n-struct Buffer<T> {\n-    storage: *const T,\n-    log_size: uint,\n-}\n-\n-impl<T: Send> BufferPool<T> {\n-    /// Allocates a new buffer pool which in turn can be used to allocate new\n-    /// deques.\n-    pub fn new() -> BufferPool<T> {\n-        BufferPool { pool: Arc::new(Exclusive::new(Vec::new())) }\n-    }\n-\n-    /// Allocates a new work-stealing deque which will send/receiving memory to\n-    /// and from this buffer pool.\n-    pub fn deque(&self) -> (Worker<T>, Stealer<T>) {\n-        let a = Arc::new(Deque::new(self.clone()));\n-        let b = a.clone();\n-        (Worker { deque: a, _noshare: marker::NoSync },\n-         Stealer { deque: b, _noshare: marker::NoSync })\n-    }\n-\n-    fn alloc(&mut self, bits: uint) -> Box<Buffer<T>> {\n-        unsafe {\n-            let mut pool = self.pool.lock();\n-            match pool.iter().position(|x| x.size() >= (1 << bits)) {\n-                Some(i) => pool.remove(i).unwrap(),\n-                None => box Buffer::new(bits)\n-            }\n-        }\n-    }\n-\n-    fn free(&self, buf: Box<Buffer<T>>) {\n-        unsafe {\n-            let mut pool = self.pool.lock();\n-            match pool.iter().position(|v| v.size() > buf.size()) {\n-                Some(i) => pool.insert(i, buf),\n-                None => pool.push(buf),\n-            }\n-        }\n-    }\n-}\n-\n-impl<T: Send> Clone for BufferPool<T> {\n-    fn clone(&self) -> BufferPool<T> { BufferPool { pool: self.pool.clone() } }\n-}\n-\n-impl<T: Send> Worker<T> {\n-    /// Pushes data onto the front of this work queue.\n-    pub fn push(&self, t: T) {\n-        unsafe { self.deque.push(t) }\n-    }\n-    /// Pops data off the front of the work queue, returning `None` on an empty\n-    /// queue.\n-    pub fn pop(&self) -> Option<T> {\n-        unsafe { self.deque.pop() }\n-    }\n-\n-    /// Gets access to the buffer pool that this worker is attached to. This can\n-    /// be used to create more deques which share the same buffer pool as this\n-    /// deque.\n-    pub fn pool<'a>(&'a self) -> &'a BufferPool<T> {\n-        &self.deque.pool\n-    }\n-}\n-\n-impl<T: Send> Stealer<T> {\n-    /// Steals work off the end of the queue (opposite of the worker's end)\n-    pub fn steal(&self) -> Stolen<T> {\n-        unsafe { self.deque.steal() }\n-    }\n-\n-    /// Gets access to the buffer pool that this stealer is attached to. This\n-    /// can be used to create more deques which share the same buffer pool as\n-    /// this deque.\n-    pub fn pool<'a>(&'a self) -> &'a BufferPool<T> {\n-        &self.deque.pool\n-    }\n-}\n-\n-impl<T: Send> Clone for Stealer<T> {\n-    fn clone(&self) -> Stealer<T> {\n-        Stealer { deque: self.deque.clone(), _noshare: marker::NoSync }\n-    }\n-}\n-\n-// Almost all of this code can be found directly in the paper so I'm not\n-// personally going to heavily comment what's going on here.\n-\n-impl<T: Send> Deque<T> {\n-    fn new(mut pool: BufferPool<T>) -> Deque<T> {\n-        let buf = pool.alloc(MIN_BITS);\n-        Deque {\n-            bottom: AtomicInt::new(0),\n-            top: AtomicInt::new(0),\n-            array: AtomicPtr::new(unsafe { transmute(buf) }),\n-            pool: pool,\n-        }\n-    }\n-\n-    unsafe fn push(&self, data: T) {\n-        let mut b = self.bottom.load(SeqCst);\n-        let t = self.top.load(SeqCst);\n-        let mut a = self.array.load(SeqCst);\n-        let size = b - t;\n-        if size >= (*a).size() - 1 {\n-            // You won't find this code in the chase-lev deque paper. This is\n-            // alluded to in a small footnote, however. We always free a buffer\n-            // when growing in order to prevent leaks.\n-            a = self.swap_buffer(b, a, (*a).resize(b, t, 1));\n-            b = self.bottom.load(SeqCst);\n-        }\n-        (*a).put(b, data);\n-        self.bottom.store(b + 1, SeqCst);\n-    }\n-\n-    unsafe fn pop(&self) -> Option<T> {\n-        let b = self.bottom.load(SeqCst);\n-        let a = self.array.load(SeqCst);\n-        let b = b - 1;\n-        self.bottom.store(b, SeqCst);\n-        let t = self.top.load(SeqCst);\n-        let size = b - t;\n-        if size < 0 {\n-            self.bottom.store(t, SeqCst);\n-            return None;\n-        }\n-        let data = (*a).get(b);\n-        if size > 0 {\n-            self.maybe_shrink(b, t);\n-            return Some(data);\n-        }\n-        if self.top.compare_and_swap(t, t + 1, SeqCst) == t {\n-            self.bottom.store(t + 1, SeqCst);\n-            return Some(data);\n-        } else {\n-            self.bottom.store(t + 1, SeqCst);\n-            forget(data); // someone else stole this value\n-            return None;\n-        }\n-    }\n-\n-    unsafe fn steal(&self) -> Stolen<T> {\n-        let t = self.top.load(SeqCst);\n-        let old = self.array.load(SeqCst);\n-        let b = self.bottom.load(SeqCst);\n-        let a = self.array.load(SeqCst);\n-        let size = b - t;\n-        if size <= 0 { return Empty }\n-        if size % (*a).size() == 0 {\n-            if a == old && t == self.top.load(SeqCst) {\n-                return Empty\n-            }\n-            return Abort\n-        }\n-        let data = (*a).get(t);\n-        if self.top.compare_and_swap(t, t + 1, SeqCst) == t {\n-            Data(data)\n-        } else {\n-            forget(data); // someone else stole this value\n-            Abort\n-        }\n-    }\n-\n-    unsafe fn maybe_shrink(&self, b: int, t: int) {\n-        let a = self.array.load(SeqCst);\n-        if b - t < (*a).size() / K && b - t > (1 << MIN_BITS) {\n-            self.swap_buffer(b, a, (*a).resize(b, t, -1));\n-        }\n-    }\n-\n-    // Helper routine not mentioned in the paper which is used in growing and\n-    // shrinking buffers to swap in a new buffer into place. As a bit of a\n-    // recap, the whole point that we need a buffer pool rather than just\n-    // calling malloc/free directly is that stealers can continue using buffers\n-    // after this method has called 'free' on it. The continued usage is simply\n-    // a read followed by a forget, but we must make sure that the memory can\n-    // continue to be read after we flag this buffer for reclamation.\n-    unsafe fn swap_buffer(&self, b: int, old: *mut Buffer<T>,\n-                          buf: Buffer<T>) -> *mut Buffer<T> {\n-        let newbuf: *mut Buffer<T> = transmute(box buf);\n-        self.array.store(newbuf, SeqCst);\n-        let ss = (*newbuf).size();\n-        self.bottom.store(b + ss, SeqCst);\n-        let t = self.top.load(SeqCst);\n-        if self.top.compare_and_swap(t, t + ss, SeqCst) != t {\n-            self.bottom.store(b, SeqCst);\n-        }\n-        self.pool.free(transmute(old));\n-        return newbuf;\n-    }\n-}\n-\n-\n-#[unsafe_destructor]\n-impl<T: Send> Drop for Deque<T> {\n-    fn drop(&mut self) {\n-        let t = self.top.load(SeqCst);\n-        let b = self.bottom.load(SeqCst);\n-        let a = self.array.load(SeqCst);\n-        // Free whatever is leftover in the dequeue, and then move the buffer\n-        // back into the pool.\n-        for i in range(t, b) {\n-            let _: T = unsafe { (*a).get(i) };\n-        }\n-        self.pool.free(unsafe { transmute(a) });\n-    }\n-}\n-\n-#[inline]\n-fn buffer_alloc_size<T>(log_size: uint) -> uint {\n-    (1 << log_size) * size_of::<T>()\n-}\n-\n-impl<T: Send> Buffer<T> {\n-    unsafe fn new(log_size: uint) -> Buffer<T> {\n-        let size = buffer_alloc_size::<T>(log_size);\n-        let buffer = allocate(size, min_align_of::<T>());\n-        if buffer.is_null() { ::alloc::oom() }\n-        Buffer {\n-            storage: buffer as *const T,\n-            log_size: log_size,\n-        }\n-    }\n-\n-    fn size(&self) -> int { 1 << self.log_size }\n-\n-    // Apparently LLVM cannot optimize (foo % (1 << bar)) into this implicitly\n-    fn mask(&self) -> int { (1 << self.log_size) - 1 }\n-\n-    unsafe fn elem(&self, i: int) -> *const T {\n-        self.storage.offset(i & self.mask())\n-    }\n-\n-    // This does not protect against loading duplicate values of the same cell,\n-    // nor does this clear out the contents contained within. Hence, this is a\n-    // very unsafe method which the caller needs to treat specially in case a\n-    // race is lost.\n-    unsafe fn get(&self, i: int) -> T {\n-        ptr::read(self.elem(i))\n-    }\n-\n-    // Unsafe because this unsafely overwrites possibly uninitialized or\n-    // initialized data.\n-    unsafe fn put(&self, i: int, t: T) {\n-        ptr::write(self.elem(i) as *mut T, t);\n-    }\n-\n-    // Again, unsafe because this has incredibly dubious ownership violations.\n-    // It is assumed that this buffer is immediately dropped.\n-    unsafe fn resize(&self, b: int, t: int, delta: int) -> Buffer<T> {\n-        // NB: not entirely obvious, but thanks to 2's complement,\n-        // casting delta to uint and then adding gives the desired\n-        // effect.\n-        let buf = Buffer::new(self.log_size + delta as uint);\n-        for i in range(t, b) {\n-            buf.put(i, self.get(i));\n-        }\n-        return buf;\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<T: Send> Drop for Buffer<T> {\n-    fn drop(&mut self) {\n-        // It is assumed that all buffers are empty on drop.\n-        let size = buffer_alloc_size::<T>(self.log_size);\n-        unsafe { deallocate(self.storage as *mut u8, size, min_align_of::<T>()) }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use prelude::*;\n-    use super::{Data, BufferPool, Abort, Empty, Worker, Stealer};\n-\n-    use mem;\n-    use rustrt::thread::Thread;\n-    use rand;\n-    use rand::Rng;\n-    use sync::atomic::{AtomicBool, INIT_ATOMIC_BOOL, SeqCst,\n-                       AtomicUint, INIT_ATOMIC_UINT};\n-    use vec;\n-\n-    #[test]\n-    fn smoke() {\n-        let pool = BufferPool::new();\n-        let (w, s) = pool.deque();\n-        assert_eq!(w.pop(), None);\n-        assert_eq!(s.steal(), Empty);\n-        w.push(1i);\n-        assert_eq!(w.pop(), Some(1));\n-        w.push(1);\n-        assert_eq!(s.steal(), Data(1));\n-        w.push(1);\n-        assert_eq!(s.clone().steal(), Data(1));\n-    }\n-\n-    #[test]\n-    fn stealpush() {\n-        static AMT: int = 100000;\n-        let pool = BufferPool::<int>::new();\n-        let (w, s) = pool.deque();\n-        let t = Thread::start(proc() {\n-            let mut left = AMT;\n-            while left > 0 {\n-                match s.steal() {\n-                    Data(i) => {\n-                        assert_eq!(i, 1);\n-                        left -= 1;\n-                    }\n-                    Abort | Empty => {}\n-                }\n-            }\n-        });\n-\n-        for _ in range(0, AMT) {\n-            w.push(1);\n-        }\n-\n-        t.join();\n-    }\n-\n-    #[test]\n-    fn stealpush_large() {\n-        static AMT: int = 100000;\n-        let pool = BufferPool::<(int, int)>::new();\n-        let (w, s) = pool.deque();\n-        let t = Thread::start(proc() {\n-            let mut left = AMT;\n-            while left > 0 {\n-                match s.steal() {\n-                    Data((1, 10)) => { left -= 1; }\n-                    Data(..) => panic!(),\n-                    Abort | Empty => {}\n-                }\n-            }\n-        });\n-\n-        for _ in range(0, AMT) {\n-            w.push((1, 10));\n-        }\n-\n-        t.join();\n-    }\n-\n-    fn stampede(w: Worker<Box<int>>, s: Stealer<Box<int>>,\n-                nthreads: int, amt: uint) {\n-        for _ in range(0, amt) {\n-            w.push(box 20);\n-        }\n-        let mut remaining = AtomicUint::new(amt);\n-        let unsafe_remaining: *mut AtomicUint = &mut remaining;\n-\n-        let threads = range(0, nthreads).map(|_| {\n-            let s = s.clone();\n-            Thread::start(proc() {\n-                unsafe {\n-                    while (*unsafe_remaining).load(SeqCst) > 0 {\n-                        match s.steal() {\n-                            Data(box 20) => {\n-                                (*unsafe_remaining).fetch_sub(1, SeqCst);\n-                            }\n-                            Data(..) => panic!(),\n-                            Abort | Empty => {}\n-                        }\n-                    }\n-                }\n-            })\n-        }).collect::<Vec<Thread<()>>>();\n-\n-        while remaining.load(SeqCst) > 0 {\n-            match w.pop() {\n-                Some(box 20) => { remaining.fetch_sub(1, SeqCst); }\n-                Some(..) => panic!(),\n-                None => {}\n-            }\n-        }\n-\n-        for thread in threads.into_iter() {\n-            thread.join();\n-        }\n-    }\n-\n-    #[test]\n-    fn run_stampede() {\n-        let pool = BufferPool::<Box<int>>::new();\n-        let (w, s) = pool.deque();\n-        stampede(w, s, 8, 10000);\n-    }\n-\n-    #[test]\n-    fn many_stampede() {\n-        static AMT: uint = 4;\n-        let pool = BufferPool::<Box<int>>::new();\n-        let threads = range(0, AMT).map(|_| {\n-            let (w, s) = pool.deque();\n-            Thread::start(proc() {\n-                stampede(w, s, 4, 10000);\n-            })\n-        }).collect::<Vec<Thread<()>>>();\n-\n-        for thread in threads.into_iter() {\n-            thread.join();\n-        }\n-    }\n-\n-    #[test]\n-    fn stress() {\n-        static AMT: int = 100000;\n-        static NTHREADS: int = 8;\n-        static DONE: AtomicBool = INIT_ATOMIC_BOOL;\n-        static HITS: AtomicUint = INIT_ATOMIC_UINT;\n-        let pool = BufferPool::<int>::new();\n-        let (w, s) = pool.deque();\n-\n-        let threads = range(0, NTHREADS).map(|_| {\n-            let s = s.clone();\n-            Thread::start(proc() {\n-                loop {\n-                    match s.steal() {\n-                        Data(2) => { HITS.fetch_add(1, SeqCst); }\n-                        Data(..) => panic!(),\n-                        _ if DONE.load(SeqCst) => break,\n-                        _ => {}\n-                    }\n-                }\n-            })\n-        }).collect::<Vec<Thread<()>>>();\n-\n-        let mut rng = rand::task_rng();\n-        let mut expected = 0;\n-        while expected < AMT {\n-            if rng.gen_range(0i, 3) == 2 {\n-                match w.pop() {\n-                    None => {}\n-                    Some(2) => { HITS.fetch_add(1, SeqCst); },\n-                    Some(_) => panic!(),\n-                }\n-            } else {\n-                expected += 1;\n-                w.push(2);\n-            }\n-        }\n-\n-        while HITS.load(SeqCst) < AMT as uint {\n-            match w.pop() {\n-                None => {}\n-                Some(2) => { HITS.fetch_add(1, SeqCst); },\n-                Some(_) => panic!(),\n-            }\n-        }\n-        DONE.store(true, SeqCst);\n-\n-        for thread in threads.into_iter() {\n-            thread.join();\n-        }\n-\n-        assert_eq!(HITS.load(SeqCst), expected as uint);\n-    }\n-\n-    #[test]\n-    #[cfg_attr(windows, ignore)] // apparently windows scheduling is weird?\n-    fn no_starvation() {\n-        static AMT: int = 10000;\n-        static NTHREADS: int = 4;\n-        static DONE: AtomicBool = INIT_ATOMIC_BOOL;\n-        let pool = BufferPool::<(int, uint)>::new();\n-        let (w, s) = pool.deque();\n-\n-        let (threads, hits) = vec::unzip(range(0, NTHREADS).map(|_| {\n-            let s = s.clone();\n-            let unique_box = box AtomicUint::new(0);\n-            let thread_box = unsafe {\n-                *mem::transmute::<&Box<AtomicUint>,\n-                                  *const *mut AtomicUint>(&unique_box)\n-            };\n-            (Thread::start(proc() {\n-                unsafe {\n-                    loop {\n-                        match s.steal() {\n-                            Data((1, 2)) => {\n-                                (*thread_box).fetch_add(1, SeqCst);\n-                            }\n-                            Data(..) => panic!(),\n-                            _ if DONE.load(SeqCst) => break,\n-                            _ => {}\n-                        }\n-                    }\n-                }\n-            }), unique_box)\n-        }));\n-\n-        let mut rng = rand::task_rng();\n-        let mut myhit = false;\n-        'outer: loop {\n-            for _ in range(0, rng.gen_range(0, AMT)) {\n-                if !myhit && rng.gen_range(0i, 3) == 2 {\n-                    match w.pop() {\n-                        None => {}\n-                        Some((1, 2)) => myhit = true,\n-                        Some(_) => panic!(),\n-                    }\n-                } else {\n-                    w.push((1, 2));\n-                }\n-            }\n-\n-            for slot in hits.iter() {\n-                let amt = slot.load(SeqCst);\n-                if amt == 0 { continue 'outer; }\n-            }\n-            if myhit {\n-                break\n-            }\n-        }\n-\n-        DONE.store(true, SeqCst);\n-\n-        for thread in threads.into_iter() {\n-            thread.join();\n-        }\n-    }\n-}"}, {"sha": "79e0d487cadb9b3996ba8c739a1c671015ed384f", "filename": "src/libstd/sync/future.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Ffuture.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Ffuture.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Ffuture.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -148,7 +148,7 @@ mod test {\n     use prelude::*;\n     use sync::Future;\n     use task;\n-    use comm::{channel, Sender};\n+    use comm::channel;\n \n     #[test]\n     fn test_from_value() {"}, {"sha": "77f5b01351908c2aa33b123881607c627209654c", "filename": "src/libstd/sync/lock.rs", "status": "removed", "additions": 0, "deletions": 805, "changes": 805, "blob_url": "https://github.com/rust-lang/rust/blob/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Flock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Flock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Flock.rs?ref=4573da6f4ffb276c31773679fd19581fc15ded8f", "patch": "@@ -1,805 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Wrappers for safe, shared, mutable memory between tasks\n-//!\n-//! The wrappers in this module build on the primitives from `sync::raw` to\n-//! provide safe interfaces around using the primitive locks. These primitives\n-//! implement a technique called \"poisoning\" where when a task panicked with a\n-//! held lock, all future attempts to use the lock will panic.\n-//!\n-//! For example, if two tasks are contending on a mutex and one of them panics\n-//! after grabbing the lock, the second task will immediately panic because the\n-//! lock is now poisoned.\n-\n-use core::prelude::*;\n-\n-use self::Inner::*;\n-\n-use core::cell::UnsafeCell;\n-use rustrt::local::Local;\n-use rustrt::task::Task;\n-\n-use super::raw;\n-\n-// Poisoning helpers\n-\n-struct PoisonOnFail<'a> {\n-    flag: &'a mut bool,\n-    failed: bool,\n-}\n-\n-fn failing() -> bool {\n-    Local::borrow(None::<Task>).unwinder.unwinding()\n-}\n-\n-impl<'a> PoisonOnFail<'a> {\n-    fn check(flag: bool, name: &str) {\n-        if flag {\n-            panic!(\"Poisoned {} - another task failed inside!\", name);\n-        }\n-    }\n-\n-    fn new<'a>(flag: &'a mut bool, name: &str) -> PoisonOnFail<'a> {\n-        PoisonOnFail::check(*flag, name);\n-        PoisonOnFail {\n-            flag: flag,\n-            failed: failing()\n-        }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<'a> Drop for PoisonOnFail<'a> {\n-    fn drop(&mut self) {\n-        if !self.failed && failing() {\n-            *self.flag = true;\n-        }\n-    }\n-}\n-\n-// Condvar\n-\n-enum Inner<'a> {\n-    InnerMutex(raw::MutexGuard<'a>),\n-    InnerRWLock(raw::RWLockWriteGuard<'a>),\n-}\n-\n-impl<'b> Inner<'b> {\n-    fn cond<'a>(&'a self) -> &'a raw::Condvar<'b> {\n-        match *self {\n-            InnerMutex(ref m) => &m.cond,\n-            InnerRWLock(ref m) => &m.cond,\n-        }\n-    }\n-}\n-\n-/// A condition variable, a mechanism for unlock-and-descheduling and\n-/// signaling, for use with the lock types.\n-pub struct Condvar<'a> {\n-    name: &'static str,\n-    // n.b. Inner must be after PoisonOnFail because we must set the poison flag\n-    //      *inside* the mutex, and struct fields are destroyed top-to-bottom\n-    //      (destroy the lock guard last).\n-    poison: PoisonOnFail<'a>,\n-    inner: Inner<'a>,\n-}\n-\n-impl<'a> Condvar<'a> {\n-    /// Atomically exit the associated lock and block until a signal is sent.\n-    ///\n-    /// wait() is equivalent to wait_on(0).\n-    ///\n-    /// # Panics\n-    ///\n-    /// A task which is killed while waiting on a condition variable will wake\n-    /// up, panic, and unlock the associated lock as it unwinds.\n-    #[inline]\n-    pub fn wait(&self) { self.wait_on(0) }\n-\n-    /// Atomically exit the associated lock and block on a specified condvar\n-    /// until a signal is sent on that same condvar.\n-    ///\n-    /// The associated lock must have been initialised with an appropriate\n-    /// number of condvars. The condvar_id must be between 0 and num_condvars-1\n-    /// or else this call will fail.\n-    #[inline]\n-    pub fn wait_on(&self, condvar_id: uint) {\n-        assert!(!*self.poison.flag);\n-        self.inner.cond().wait_on(condvar_id);\n-        // This is why we need to wrap sync::condvar.\n-        PoisonOnFail::check(*self.poison.flag, self.name);\n-    }\n-\n-    /// Wake up a blocked task. Returns false if there was no blocked task.\n-    #[inline]\n-    pub fn signal(&self) -> bool { self.signal_on(0) }\n-\n-    /// Wake up a blocked task on a specified condvar (as\n-    /// sync::cond.signal_on). Returns false if there was no blocked task.\n-    #[inline]\n-    pub fn signal_on(&self, condvar_id: uint) -> bool {\n-        assert!(!*self.poison.flag);\n-        self.inner.cond().signal_on(condvar_id)\n-    }\n-\n-    /// Wake up all blocked tasks. Returns the number of tasks woken.\n-    #[inline]\n-    pub fn broadcast(&self) -> uint { self.broadcast_on(0) }\n-\n-    /// Wake up all blocked tasks on a specified condvar (as\n-    /// sync::cond.broadcast_on). Returns the number of tasks woken.\n-    #[inline]\n-    pub fn broadcast_on(&self, condvar_id: uint) -> uint {\n-        assert!(!*self.poison.flag);\n-        self.inner.cond().broadcast_on(condvar_id)\n-    }\n-}\n-\n-/// A wrapper type which provides synchronized access to the underlying data, of\n-/// type `T`. A mutex always provides exclusive access, and concurrent requests\n-/// will block while the mutex is already locked.\n-///\n-/// # Example\n-///\n-/// ```\n-/// use std::sync::{Mutex, Arc};\n-///\n-/// let mutex = Arc::new(Mutex::new(1i));\n-/// let mutex2 = mutex.clone();\n-///\n-/// spawn(proc() {\n-///     let mut val = mutex2.lock();\n-///     *val += 1;\n-///     val.cond.signal();\n-/// });\n-///\n-/// let value = mutex.lock();\n-/// while *value != 2 {\n-///     value.cond.wait();\n-/// }\n-/// ```\n-pub struct Mutex<T> {\n-    lock: raw::Mutex,\n-    failed: UnsafeCell<bool>,\n-    data: UnsafeCell<T>,\n-}\n-\n-/// An guard which is created by locking a mutex. Through this guard the\n-/// underlying data can be accessed.\n-pub struct MutexGuard<'a, T:'a> {\n-    // FIXME #12808: strange name to try to avoid interfering with\n-    // field accesses of the contained type via Deref\n-    _data: &'a mut T,\n-    /// Inner condition variable connected to the locked mutex that this guard\n-    /// was created from. This can be used for atomic-unlock-and-deschedule.\n-    pub cond: Condvar<'a>,\n-}\n-\n-impl<T: Send> Mutex<T> {\n-    /// Creates a new mutex to protect the user-supplied data.\n-    pub fn new(user_data: T) -> Mutex<T> {\n-        Mutex::new_with_condvars(user_data, 1)\n-    }\n-\n-    /// Create a new mutex, with a specified number of associated condvars.\n-    ///\n-    /// This will allow calling wait_on/signal_on/broadcast_on with condvar IDs\n-    /// between 0 and num_condvars-1. (If num_condvars is 0, lock_cond will be\n-    /// allowed but any operations on the condvar will fail.)\n-    pub fn new_with_condvars(user_data: T, num_condvars: uint) -> Mutex<T> {\n-        Mutex {\n-            lock: raw::Mutex::new_with_condvars(num_condvars),\n-            failed: UnsafeCell::new(false),\n-            data: UnsafeCell::new(user_data),\n-        }\n-    }\n-\n-    /// Access the underlying mutable data with mutual exclusion from other\n-    /// tasks. The returned value is an RAII guard which will unlock the mutex\n-    /// when dropped. All concurrent tasks attempting to lock the mutex will\n-    /// block while the returned value is still alive.\n-    ///\n-    /// # Panics\n-    ///\n-    /// Panicking while inside the Mutex will unlock the Mutex while unwinding, so\n-    /// that other tasks won't block forever. It will also poison the Mutex:\n-    /// any tasks that subsequently try to access it (including those already\n-    /// blocked on the mutex) will also panic immediately.\n-    #[inline]\n-    pub fn lock<'a>(&'a self) -> MutexGuard<'a, T> {\n-        let guard = self.lock.lock();\n-\n-        // These two accesses are safe because we're guaranteed at this point\n-        // that we have exclusive access to this mutex. We are indeed able to\n-        // promote ourselves from &Mutex to `&mut T`\n-        let poison = unsafe { &mut *self.failed.get() };\n-        let data = unsafe { &mut *self.data.get() };\n-\n-        MutexGuard {\n-            _data: data,\n-            cond: Condvar {\n-                name: \"Mutex\",\n-                poison: PoisonOnFail::new(poison, \"Mutex\"),\n-                inner: InnerMutex(guard),\n-            },\n-        }\n-    }\n-}\n-\n-impl<'a, T: Send> Deref<T> for MutexGuard<'a, T> {\n-    fn deref<'a>(&'a self) -> &'a T { &*self._data }\n-}\n-impl<'a, T: Send> DerefMut<T> for MutexGuard<'a, T> {\n-    fn deref_mut<'a>(&'a mut self) -> &'a mut T { &mut *self._data }\n-}\n-\n-/// A dual-mode reader-writer lock. The data can be accessed mutably or\n-/// immutably, and immutably-accessing tasks may run concurrently.\n-///\n-/// # Example\n-///\n-/// ```\n-/// use std::sync::{RWLock, Arc};\n-///\n-/// let lock1 = Arc::new(RWLock::new(1i));\n-/// let lock2 = lock1.clone();\n-///\n-/// spawn(proc() {\n-///     let mut val = lock2.write();\n-///     *val = 3;\n-///     let val = val.downgrade();\n-///     println!(\"{}\", *val);\n-/// });\n-///\n-/// let val = lock1.read();\n-/// println!(\"{}\", *val);\n-/// ```\n-pub struct RWLock<T> {\n-    lock: raw::RWLock,\n-    failed: UnsafeCell<bool>,\n-    data: UnsafeCell<T>,\n-}\n-\n-/// A guard which is created by locking an rwlock in write mode. Through this\n-/// guard the underlying data can be accessed.\n-pub struct RWLockWriteGuard<'a, T:'a> {\n-    // FIXME #12808: strange name to try to avoid interfering with\n-    // field accesses of the contained type via Deref\n-    _data: &'a mut T,\n-    /// Inner condition variable that can be used to sleep on the write mode of\n-    /// this rwlock.\n-    pub cond: Condvar<'a>,\n-}\n-\n-/// A guard which is created by locking an rwlock in read mode. Through this\n-/// guard the underlying data can be accessed.\n-pub struct RWLockReadGuard<'a, T:'a> {\n-    // FIXME #12808: strange names to try to avoid interfering with\n-    // field accesses of the contained type via Deref\n-    _data: &'a T,\n-    _guard: raw::RWLockReadGuard<'a>,\n-}\n-\n-impl<T: Send + Sync> RWLock<T> {\n-    /// Create a reader/writer lock with the supplied data.\n-    pub fn new(user_data: T) -> RWLock<T> {\n-        RWLock::new_with_condvars(user_data, 1)\n-    }\n-\n-    /// Create a reader/writer lock with the supplied data and a specified number\n-    /// of condvars (as sync::RWLock::new_with_condvars).\n-    pub fn new_with_condvars(user_data: T, num_condvars: uint) -> RWLock<T> {\n-        RWLock {\n-            lock: raw::RWLock::new_with_condvars(num_condvars),\n-            failed: UnsafeCell::new(false),\n-            data: UnsafeCell::new(user_data),\n-        }\n-    }\n-\n-    /// Access the underlying data mutably. Locks the rwlock in write mode;\n-    /// other readers and writers will block.\n-    ///\n-    /// # Panics\n-    ///\n-    /// Panicking while inside the lock will unlock the lock while unwinding, so\n-    /// that other tasks won't block forever. As Mutex.lock, it will also poison\n-    /// the lock, so subsequent readers and writers will both also panic.\n-    #[inline]\n-    pub fn write<'a>(&'a self) -> RWLockWriteGuard<'a, T> {\n-        let guard = self.lock.write();\n-\n-        // These two accesses are safe because we're guaranteed at this point\n-        // that we have exclusive access to this rwlock. We are indeed able to\n-        // promote ourselves from &RWLock to `&mut T`\n-        let poison = unsafe { &mut *self.failed.get() };\n-        let data = unsafe { &mut *self.data.get() };\n-\n-        RWLockWriteGuard {\n-            _data: data,\n-            cond: Condvar {\n-                name: \"RWLock\",\n-                poison: PoisonOnFail::new(poison, \"RWLock\"),\n-                inner: InnerRWLock(guard),\n-            },\n-        }\n-    }\n-\n-    /// Access the underlying data immutably. May run concurrently with other\n-    /// reading tasks.\n-    ///\n-    /// # Panics\n-    ///\n-    /// Panicking will unlock the lock while unwinding. However, unlike all other\n-    /// access modes, this will not poison the lock.\n-    pub fn read<'a>(&'a self) -> RWLockReadGuard<'a, T> {\n-        let guard = self.lock.read();\n-        PoisonOnFail::check(unsafe { *self.failed.get() }, \"RWLock\");\n-        RWLockReadGuard {\n-            _guard: guard,\n-            _data: unsafe { &*self.data.get() },\n-        }\n-    }\n-}\n-\n-impl<'a, T: Send + Sync> RWLockWriteGuard<'a, T> {\n-    /// Consumes this write lock token, returning a new read lock token.\n-    ///\n-    /// This will allow pending readers to come into the lock.\n-    pub fn downgrade(self) -> RWLockReadGuard<'a, T> {\n-        let RWLockWriteGuard { _data, cond } = self;\n-        // convert the data to read-only explicitly\n-        let data = &*_data;\n-        let guard = match cond.inner {\n-            InnerMutex(..) => unreachable!(),\n-            InnerRWLock(guard) => guard.downgrade()\n-        };\n-        RWLockReadGuard { _guard: guard, _data: data }\n-    }\n-}\n-\n-impl<'a, T: Send + Sync> Deref<T> for RWLockReadGuard<'a, T> {\n-    fn deref<'a>(&'a self) -> &'a T { self._data }\n-}\n-impl<'a, T: Send + Sync> Deref<T> for RWLockWriteGuard<'a, T> {\n-    fn deref<'a>(&'a self) -> &'a T { &*self._data }\n-}\n-impl<'a, T: Send + Sync> DerefMut<T> for RWLockWriteGuard<'a, T> {\n-    fn deref_mut<'a>(&'a mut self) -> &'a mut T { &mut *self._data }\n-}\n-\n-/// A barrier enables multiple tasks to synchronize the beginning\n-/// of some computation.\n-///\n-/// ```rust\n-/// use std::sync::{Arc, Barrier};\n-///\n-/// let barrier = Arc::new(Barrier::new(10));\n-/// for _ in range(0u, 10) {\n-///     let c = barrier.clone();\n-///     // The same messages will be printed together.\n-///     // You will NOT see any interleaving.\n-///     spawn(proc() {\n-///         println!(\"before wait\");\n-///         c.wait();\n-///         println!(\"after wait\");\n-///     });\n-/// }\n-/// ```\n-pub struct Barrier {\n-    lock: Mutex<BarrierState>,\n-    num_tasks: uint,\n-}\n-\n-// The inner state of a double barrier\n-struct BarrierState {\n-    count: uint,\n-    generation_id: uint,\n-}\n-\n-impl Barrier {\n-    /// Create a new barrier that can block a given number of tasks.\n-    pub fn new(num_tasks: uint) -> Barrier {\n-        Barrier {\n-            lock: Mutex::new(BarrierState {\n-                count: 0,\n-                generation_id: 0,\n-            }),\n-            num_tasks: num_tasks,\n-        }\n-    }\n-\n-    /// Block the current task until a certain number of tasks is waiting.\n-    pub fn wait(&self) {\n-        let mut lock = self.lock.lock();\n-        let local_gen = lock.generation_id;\n-        lock.count += 1;\n-        if lock.count < self.num_tasks {\n-            // We need a while loop to guard against spurious wakeups.\n-            // http://en.wikipedia.org/wiki/Spurious_wakeup\n-            while local_gen == lock.generation_id &&\n-                  lock.count < self.num_tasks {\n-                lock.cond.wait();\n-            }\n-        } else {\n-            lock.count = 0;\n-            lock.generation_id += 1;\n-            lock.cond.broadcast();\n-        }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use prelude::*;\n-    use comm::Empty;\n-    use task;\n-    use task::try_future;\n-    use sync::Arc;\n-\n-    use super::{Mutex, Barrier, RWLock};\n-\n-    #[test]\n-    fn test_mutex_arc_condvar() {\n-        let arc = Arc::new(Mutex::new(false));\n-        let arc2 = arc.clone();\n-        let (tx, rx) = channel();\n-        task::spawn(proc() {\n-            // wait until parent gets in\n-            rx.recv();\n-            let mut lock = arc2.lock();\n-            *lock = true;\n-            lock.cond.signal();\n-        });\n-\n-        let lock = arc.lock();\n-        tx.send(());\n-        assert!(!*lock);\n-        while !*lock {\n-            lock.cond.wait();\n-        }\n-    }\n-\n-    #[test] #[should_fail]\n-    fn test_arc_condvar_poison() {\n-        let arc = Arc::new(Mutex::new(1i));\n-        let arc2 = arc.clone();\n-        let (tx, rx) = channel();\n-\n-        spawn(proc() {\n-            rx.recv();\n-            let lock = arc2.lock();\n-            lock.cond.signal();\n-            // Parent should fail when it wakes up.\n-            panic!();\n-        });\n-\n-        let lock = arc.lock();\n-        tx.send(());\n-        while *lock == 1 {\n-            lock.cond.wait();\n-        }\n-    }\n-\n-    #[test] #[should_fail]\n-    fn test_mutex_arc_poison() {\n-        let arc = Arc::new(Mutex::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.lock();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.lock();\n-        assert_eq!(*lock, 1);\n-    }\n-\n-    #[test]\n-    fn test_mutex_arc_nested() {\n-        // Tests nested mutexes and access\n-        // to underlying data.\n-        let arc = Arc::new(Mutex::new(1i));\n-        let arc2 = Arc::new(Mutex::new(arc));\n-        task::spawn(proc() {\n-            let lock = arc2.lock();\n-            let lock2 = lock.deref().lock();\n-            assert_eq!(*lock2, 1);\n-        });\n-    }\n-\n-    #[test]\n-    fn test_mutex_arc_access_in_unwind() {\n-        let arc = Arc::new(Mutex::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try::<()>(proc() {\n-            struct Unwinder {\n-                i: Arc<Mutex<int>>,\n-            }\n-            impl Drop for Unwinder {\n-                fn drop(&mut self) {\n-                    let mut lock = self.i.lock();\n-                    *lock += 1;\n-                }\n-            }\n-            let _u = Unwinder { i: arc2 };\n-            panic!();\n-        });\n-        let lock = arc.lock();\n-        assert_eq!(*lock, 2);\n-    }\n-\n-    #[test] #[should_fail]\n-    fn test_rw_arc_poison_wr() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.write();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.read();\n-        assert_eq!(*lock, 1);\n-    }\n-    #[test] #[should_fail]\n-    fn test_rw_arc_poison_ww() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.write();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.write();\n-        assert_eq!(*lock, 1);\n-    }\n-    #[test]\n-    fn test_rw_arc_no_poison_rr() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.read();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.read();\n-        assert_eq!(*lock, 1);\n-    }\n-    #[test]\n-    fn test_rw_arc_no_poison_rw() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.read();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.write();\n-        assert_eq!(*lock, 1);\n-    }\n-    #[test]\n-    fn test_rw_arc_no_poison_dr() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try(proc() {\n-            let lock = arc2.write().downgrade();\n-            assert_eq!(*lock, 2);\n-        });\n-        let lock = arc.write();\n-        assert_eq!(*lock, 1);\n-    }\n-\n-    #[test]\n-    fn test_rw_arc() {\n-        let arc = Arc::new(RWLock::new(0i));\n-        let arc2 = arc.clone();\n-        let (tx, rx) = channel();\n-\n-        task::spawn(proc() {\n-            let mut lock = arc2.write();\n-            for _ in range(0u, 10) {\n-                let tmp = *lock;\n-                *lock = -1;\n-                task::deschedule();\n-                *lock = tmp + 1;\n-            }\n-            tx.send(());\n-        });\n-\n-        // Readers try to catch the writer in the act\n-        let mut children = Vec::new();\n-        for _ in range(0u, 5) {\n-            let arc3 = arc.clone();\n-            children.push(try_future(proc() {\n-                let lock = arc3.read();\n-                assert!(*lock >= 0);\n-            }));\n-        }\n-\n-        // Wait for children to pass their asserts\n-        for r in children.iter_mut() {\n-            assert!(r.get_ref().is_ok());\n-        }\n-\n-        // Wait for writer to finish\n-        rx.recv();\n-        let lock = arc.read();\n-        assert_eq!(*lock, 10);\n-    }\n-\n-    #[test]\n-    fn test_rw_arc_access_in_unwind() {\n-        let arc = Arc::new(RWLock::new(1i));\n-        let arc2 = arc.clone();\n-        let _ = task::try::<()>(proc() {\n-            struct Unwinder {\n-                i: Arc<RWLock<int>>,\n-            }\n-            impl Drop for Unwinder {\n-                fn drop(&mut self) {\n-                    let mut lock = self.i.write();\n-                    *lock += 1;\n-                }\n-            }\n-            let _u = Unwinder { i: arc2 };\n-            panic!();\n-        });\n-        let lock = arc.read();\n-        assert_eq!(*lock, 2);\n-    }\n-\n-    #[test]\n-    fn test_rw_downgrade() {\n-        // (1) A downgrader gets in write mode and does cond.wait.\n-        // (2) A writer gets in write mode, sets state to 42, and does signal.\n-        // (3) Downgrader wakes, sets state to 31337.\n-        // (4) tells writer and all other readers to contend as it downgrades.\n-        // (5) Writer attempts to set state back to 42, while downgraded task\n-        //     and all reader tasks assert that it's 31337.\n-        let arc = Arc::new(RWLock::new(0i));\n-\n-        // Reader tasks\n-        let mut reader_convos = Vec::new();\n-        for _ in range(0u, 10) {\n-            let ((tx1, rx1), (tx2, rx2)) = (channel(), channel());\n-            reader_convos.push((tx1, rx2));\n-            let arcn = arc.clone();\n-            task::spawn(proc() {\n-                rx1.recv(); // wait for downgrader to give go-ahead\n-                let lock = arcn.read();\n-                assert_eq!(*lock, 31337);\n-                tx2.send(());\n-            });\n-        }\n-\n-        // Writer task\n-        let arc2 = arc.clone();\n-        let ((tx1, rx1), (tx2, rx2)) = (channel(), channel());\n-        task::spawn(proc() {\n-            rx1.recv();\n-            {\n-                let mut lock = arc2.write();\n-                assert_eq!(*lock, 0);\n-                *lock = 42;\n-                lock.cond.signal();\n-            }\n-            rx1.recv();\n-            {\n-                let mut lock = arc2.write();\n-                // This shouldn't happen until after the downgrade read\n-                // section, and all other readers, finish.\n-                assert_eq!(*lock, 31337);\n-                *lock = 42;\n-            }\n-            tx2.send(());\n-        });\n-\n-        // Downgrader (us)\n-        let mut lock = arc.write();\n-        tx1.send(()); // send to another writer who will wake us up\n-        while *lock == 0 {\n-            lock.cond.wait();\n-        }\n-        assert_eq!(*lock, 42);\n-        *lock = 31337;\n-        // send to other readers\n-        for &(ref mut rc, _) in reader_convos.iter_mut() {\n-            rc.send(())\n-        }\n-        let lock = lock.downgrade();\n-        // complete handshake with other readers\n-        for &(_, ref mut rp) in reader_convos.iter_mut() {\n-            rp.recv()\n-        }\n-        tx1.send(()); // tell writer to try again\n-        assert_eq!(*lock, 31337);\n-        drop(lock);\n-\n-        rx2.recv(); // complete handshake with writer\n-    }\n-\n-    #[cfg(test)]\n-    fn test_rw_write_cond_downgrade_read_race_helper() {\n-        // Tests that when a downgrader hands off the \"reader cloud\" lock\n-        // because of a contending reader, a writer can't race to get it\n-        // instead, which would result in readers_and_writers. This tests\n-        // the raw module rather than this one, but it's here because an\n-        // rwarc gives us extra shared state to help check for the race.\n-        let x = Arc::new(RWLock::new(true));\n-        let (tx, rx) = channel();\n-\n-        // writer task\n-        let xw = x.clone();\n-        task::spawn(proc() {\n-            let mut lock = xw.write();\n-            tx.send(()); // tell downgrader it's ok to go\n-            lock.cond.wait();\n-            // The core of the test is here: the condvar reacquire path\n-            // must involve order_lock, so that it cannot race with a reader\n-            // trying to receive the \"reader cloud lock hand-off\".\n-            *lock = false;\n-        });\n-\n-        rx.recv(); // wait for writer to get in\n-\n-        let lock = x.write();\n-        assert!(*lock);\n-        // make writer contend in the cond-reacquire path\n-        lock.cond.signal();\n-        // make a reader task to trigger the \"reader cloud lock\" handoff\n-        let xr = x.clone();\n-        let (tx, rx) = channel();\n-        task::spawn(proc() {\n-            tx.send(());\n-            drop(xr.read());\n-        });\n-        rx.recv(); // wait for reader task to exist\n-\n-        let lock = lock.downgrade();\n-        // if writer mistakenly got in, make sure it mutates state\n-        // before we assert on it\n-        for _ in range(0u, 5) { task::deschedule(); }\n-        // make sure writer didn't get in.\n-        assert!(*lock);\n-    }\n-    #[test]\n-    fn test_rw_write_cond_downgrade_read_race() {\n-        // Ideally the above test case would have deschedule statements in it\n-        // that helped to expose the race nearly 100% of the time... but adding\n-        // deschedules in the intuitively-right locations made it even less\n-        // likely, and I wasn't sure why :( . This is a mediocre \"next best\"\n-        // option.\n-        for _ in range(0u, 8) {\n-            test_rw_write_cond_downgrade_read_race_helper();\n-        }\n-    }\n-\n-    #[test]\n-    fn test_barrier() {\n-        let barrier = Arc::new(Barrier::new(10));\n-        let (tx, rx) = channel();\n-\n-        for _ in range(0u, 9) {\n-            let c = barrier.clone();\n-            let tx = tx.clone();\n-            spawn(proc() {\n-                c.wait();\n-                tx.send(true);\n-            });\n-        }\n-\n-        // At this point, all spawned tasks should be blocked,\n-        // so we shouldn't get anything from the port\n-        assert!(match rx.try_recv() {\n-            Err(Empty) => true,\n-            _ => false,\n-        });\n-\n-        barrier.wait();\n-        // Now, the barrier is cleared and we should get data.\n-        for _ in range(0u, 9) {\n-            rx.recv();\n-        }\n-    }\n-}"}, {"sha": "7605a6a96a005d150713a774ff97d2fda90abeff", "filename": "src/libstd/sync/mod.rs", "status": "modified", "additions": 15, "deletions": 29, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmod.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -17,41 +17,27 @@\n \n #![experimental]\n \n-pub use self::one::{Once, ONCE_INIT};\n-\n pub use alloc::arc::{Arc, Weak};\n-pub use self::lock::{Mutex, MutexGuard, Condvar, Barrier,\n-                     RWLock, RWLockReadGuard, RWLockWriteGuard};\n \n-// The mutex/rwlock in this module are not meant for reexport\n-pub use self::raw::{Semaphore, SemaphoreGuard};\n+pub use self::mutex::{Mutex, MutexGuard, StaticMutex, StaticMutexGuard, MUTEX_INIT};\n+pub use self::rwlock::{RWLock, StaticRWLock, RWLOCK_INIT};\n+pub use self::rwlock::{RWLockReadGuard, RWLockWriteGuard};\n+pub use self::rwlock::{StaticRWLockReadGuard, StaticRWLockWriteGuard};\n+pub use self::condvar::{Condvar, StaticCondvar, CONDVAR_INIT, AsMutexGuard};\n+pub use self::once::{Once, ONCE_INIT};\n+pub use self::semaphore::{Semaphore, SemaphoreGuard};\n+pub use self::barrier::Barrier;\n \n pub use self::future::Future;\n pub use self::task_pool::TaskPool;\n \n-// Core building blocks for all primitives in this crate\n-\n-#[stable]\n pub mod atomic;\n-\n-// Concurrent data structures\n-\n-pub mod spsc_queue;\n-pub mod mpsc_queue;\n-pub mod mpmc_bounded_queue;\n-pub mod deque;\n-\n-// Low-level concurrency primitives\n-\n-mod raw;\n-mod mutex;\n-mod one;\n-\n-// Higher level primitives based on those above\n-\n-mod lock;\n-\n-// Task management\n-\n+mod barrier;\n+mod condvar;\n mod future;\n+mod mutex;\n+mod once;\n+mod poison;\n+mod rwlock;\n+mod semaphore;\n mod task_pool;"}, {"sha": "dca2d4098c6a6152e4b73f2ef0d4b2b820ed739b", "filename": "src/libstd/sync/mpmc_bounded_queue.rs", "status": "removed", "additions": 0, "deletions": 219, "changes": 219, "blob_url": "https://github.com/rust-lang/rust/blob/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs?ref=4573da6f4ffb276c31773679fd19581fc15ded8f", "patch": "@@ -1,219 +0,0 @@\n-/* Copyright (c) 2010-2011 Dmitry Vyukov. All rights reserved.\n- * Redistribution and use in source and binary forms, with or without\n- * modification, are permitted provided that the following conditions are met:\n- *\n- *    1. Redistributions of source code must retain the above copyright notice,\n- *       this list of conditions and the following disclaimer.\n- *\n- *    2. Redistributions in binary form must reproduce the above copyright\n- *       notice, this list of conditions and the following disclaimer in the\n- *       documentation and/or other materials provided with the distribution.\n- *\n- * THIS SOFTWARE IS PROVIDED BY DMITRY VYUKOV \"AS IS\" AND ANY EXPRESS OR IMPLIED\n- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n- * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT\n- * SHALL DMITRY VYUKOV OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n- * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n- * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n- * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\n- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n- * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n- *\n- * The views and conclusions contained in the software and documentation are\n- * those of the authors and should not be interpreted as representing official\n- * policies, either expressed or implied, of Dmitry Vyukov.\n- */\n-\n-#![experimental]\n-#![allow(missing_docs, dead_code)]\n-\n-// http://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue\n-\n-use core::prelude::*;\n-\n-use alloc::arc::Arc;\n-use vec::Vec;\n-use core::num::UnsignedInt;\n-use core::cell::UnsafeCell;\n-\n-use sync::atomic::{AtomicUint,Relaxed,Release,Acquire};\n-\n-struct Node<T> {\n-    sequence: AtomicUint,\n-    value: Option<T>,\n-}\n-\n-struct State<T> {\n-    pad0: [u8, ..64],\n-    buffer: Vec<UnsafeCell<Node<T>>>,\n-    mask: uint,\n-    pad1: [u8, ..64],\n-    enqueue_pos: AtomicUint,\n-    pad2: [u8, ..64],\n-    dequeue_pos: AtomicUint,\n-    pad3: [u8, ..64],\n-}\n-\n-pub struct Queue<T> {\n-    state: Arc<State<T>>,\n-}\n-\n-impl<T: Send> State<T> {\n-    fn with_capacity(capacity: uint) -> State<T> {\n-        let capacity = if capacity < 2 || (capacity & (capacity - 1)) != 0 {\n-            if capacity < 2 {\n-                2u\n-            } else {\n-                // use next power of 2 as capacity\n-                capacity.next_power_of_two()\n-            }\n-        } else {\n-            capacity\n-        };\n-        let buffer = Vec::from_fn(capacity, |i| {\n-            UnsafeCell::new(Node { sequence:AtomicUint::new(i), value: None })\n-        });\n-        State{\n-            pad0: [0, ..64],\n-            buffer: buffer,\n-            mask: capacity-1,\n-            pad1: [0, ..64],\n-            enqueue_pos: AtomicUint::new(0),\n-            pad2: [0, ..64],\n-            dequeue_pos: AtomicUint::new(0),\n-            pad3: [0, ..64],\n-        }\n-    }\n-\n-    fn push(&self, value: T) -> bool {\n-        let mask = self.mask;\n-        let mut pos = self.enqueue_pos.load(Relaxed);\n-        loop {\n-            let node = &self.buffer[pos & mask];\n-            let seq = unsafe { (*node.get()).sequence.load(Acquire) };\n-            let diff: int = seq as int - pos as int;\n-\n-            if diff == 0 {\n-                let enqueue_pos = self.enqueue_pos.compare_and_swap(pos, pos+1, Relaxed);\n-                if enqueue_pos == pos {\n-                    unsafe {\n-                        (*node.get()).value = Some(value);\n-                        (*node.get()).sequence.store(pos+1, Release);\n-                    }\n-                    break\n-                } else {\n-                    pos = enqueue_pos;\n-                }\n-            } else if diff < 0 {\n-                return false\n-            } else {\n-                pos = self.enqueue_pos.load(Relaxed);\n-            }\n-        }\n-        true\n-    }\n-\n-    fn pop(&self) -> Option<T> {\n-        let mask = self.mask;\n-        let mut pos = self.dequeue_pos.load(Relaxed);\n-        loop {\n-            let node = &self.buffer[pos & mask];\n-            let seq = unsafe { (*node.get()).sequence.load(Acquire) };\n-            let diff: int = seq as int - (pos + 1) as int;\n-            if diff == 0 {\n-                let dequeue_pos = self.dequeue_pos.compare_and_swap(pos, pos+1, Relaxed);\n-                if dequeue_pos == pos {\n-                    unsafe {\n-                        let value = (*node.get()).value.take();\n-                        (*node.get()).sequence.store(pos + mask + 1, Release);\n-                        return value\n-                    }\n-                } else {\n-                    pos = dequeue_pos;\n-                }\n-            } else if diff < 0 {\n-                return None\n-            } else {\n-                pos = self.dequeue_pos.load(Relaxed);\n-            }\n-        }\n-    }\n-}\n-\n-impl<T: Send> Queue<T> {\n-    pub fn with_capacity(capacity: uint) -> Queue<T> {\n-        Queue{\n-            state: Arc::new(State::with_capacity(capacity))\n-        }\n-    }\n-\n-    pub fn push(&self, value: T) -> bool {\n-        self.state.push(value)\n-    }\n-\n-    pub fn pop(&self) -> Option<T> {\n-        self.state.pop()\n-    }\n-}\n-\n-impl<T: Send> Clone for Queue<T> {\n-    fn clone(&self) -> Queue<T> {\n-        Queue { state: self.state.clone() }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use prelude::*;\n-    use super::Queue;\n-\n-    #[test]\n-    fn test() {\n-        let nthreads = 8u;\n-        let nmsgs = 1000u;\n-        let q = Queue::with_capacity(nthreads*nmsgs);\n-        assert_eq!(None, q.pop());\n-        let (tx, rx) = channel();\n-\n-        for _ in range(0, nthreads) {\n-            let q = q.clone();\n-            let tx = tx.clone();\n-            spawn(proc() {\n-                let q = q;\n-                for i in range(0, nmsgs) {\n-                    assert!(q.push(i));\n-                }\n-                tx.send(());\n-            });\n-        }\n-\n-        let mut completion_rxs = vec![];\n-        for _ in range(0, nthreads) {\n-            let (tx, rx) = channel();\n-            completion_rxs.push(rx);\n-            let q = q.clone();\n-            spawn(proc() {\n-                let q = q;\n-                let mut i = 0u;\n-                loop {\n-                    match q.pop() {\n-                        None => {},\n-                        Some(_) => {\n-                            i += 1;\n-                            if i == nmsgs { break }\n-                        }\n-                    }\n-                }\n-                tx.send(i);\n-            });\n-        }\n-\n-        for rx in completion_rxs.iter_mut() {\n-            assert_eq!(nmsgs, rx.recv());\n-        }\n-        for _ in range(0, nthreads) {\n-            rx.recv();\n-        }\n-    }\n-}"}, {"sha": "4e07d54c57e7d6b79b20be42006e4492180b05d1", "filename": "src/libstd/sync/mutex.rs", "status": "modified", "additions": 289, "deletions": 75, "changes": 364, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmutex.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -8,43 +8,68 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! A simple native mutex implementation. Warning: this API is likely\n-//! to change soon.\n+use prelude::*;\n \n-#![allow(dead_code)]\n-\n-use core::prelude::*;\n-use alloc::boxed::Box;\n-use rustrt::mutex;\n-\n-pub const LOCKED: uint = 1 << 0;\n-pub const BLOCKED: uint = 1 << 1;\n+use cell::UnsafeCell;\n+use kinds::marker;\n+use sync::{poison, AsMutexGuard};\n+use sys_common::mutex as sys;\n \n /// A mutual exclusion primitive useful for protecting shared data\n ///\n-/// This mutex will properly block tasks waiting for the lock to become\n-/// available. The mutex can also be statically initialized or created via a\n-/// `new` constructor.\n+/// This mutex will block threads waiting for the lock to become available. The\n+/// mutex can also be statically initialized or created via a `new`\n+/// constructor. Each mutex has a type parameter which represents the data that\n+/// it is protecting. The data can only be accessed through the RAII guards\n+/// returned from `lock` and `try_lock`, which guarantees that the data is only\n+/// ever accessed when the mutex is locked.\n+///\n+/// # Poisoning\n+///\n+/// In order to prevent access to otherwise invalid data, each mutex will\n+/// propagate any panics which occur while the lock is held. Once a thread has\n+/// panicked while holding the lock, then all other threads will immediately\n+/// panic as well once they hold the lock.\n ///\n /// # Example\n ///\n-/// ```rust,ignore\n-/// use std::sync::mutex::Mutex;\n+/// ```rust\n+/// use std::sync::{Arc, Mutex};\n+/// const N: uint = 10;\n ///\n-/// let m = Mutex::new();\n-/// let guard = m.lock();\n-/// // do some work\n-/// drop(guard); // unlock the lock\n+/// // Spawn a few threads to increment a shared variable (non-atomically), and\n+/// // let the main thread know once all increments are done.\n+/// //\n+/// // Here we're using an Arc to share memory among tasks, and the data inside\n+/// // the Arc is protected with a mutex.\n+/// let data = Arc::new(Mutex::new(0));\n+///\n+/// let (tx, rx) = channel();\n+/// for _ in range(0u, 10) {\n+///     let (data, tx) = (data.clone(), tx.clone());\n+///     spawn(proc() {\n+///         // The shared static can only be accessed once the lock is held.\n+///         // Our non-atomic increment is safe because we're the only thread\n+///         // which can access the shared state when the lock is held.\n+///         let mut data = data.lock();\n+///         *data += 1;\n+///         if *data == N {\n+///             tx.send(());\n+///         }\n+///         // the lock is unlocked here when `data` goes out of scope.\n+///     });\n+/// }\n+///\n+/// rx.recv();\n /// ```\n-pub struct Mutex {\n+pub struct Mutex<T> {\n     // Note that this static mutex is in a *box*, not inlined into the struct\n-    // itself. This is done for memory safety reasons with the usage of a\n-    // StaticNativeMutex inside the static mutex above. Once a native mutex has\n-    // been used once, its address can never change (it can't be moved). This\n-    // mutex type can be safely moved at any time, so to ensure that the native\n-    // mutex is used correctly we box the inner lock to give it a constant\n-    // address.\n-    lock: Box<StaticMutex>,\n+    // itself. Once a native mutex has been used once, its address can never\n+    // change (it can't be moved). This mutex type can be safely moved at any\n+    // time, so to ensure that the native mutex is used correctly we box the\n+    // inner lock to give it a constant address.\n+    inner: Box<StaticMutex>,\n+    data: UnsafeCell<T>,\n }\n \n /// The static mutex type is provided to allow for static allocation of mutexes.\n@@ -57,8 +82,8 @@ pub struct Mutex {\n ///\n /// # Example\n ///\n-/// ```rust,ignore\n-/// use std::sync::mutex::{StaticMutex, MUTEX_INIT};\n+/// ```rust\n+/// use std::sync::{StaticMutex, MUTEX_INIT};\n ///\n /// static LOCK: StaticMutex = MUTEX_INIT;\n ///\n@@ -69,35 +94,113 @@ pub struct Mutex {\n /// // lock is unlocked here.\n /// ```\n pub struct StaticMutex {\n-    lock: mutex::StaticNativeMutex,\n+    lock: sys::Mutex,\n+    poison: UnsafeCell<poison::Flag>,\n }\n \n /// An RAII implementation of a \"scoped lock\" of a mutex. When this structure is\n /// dropped (falls out of scope), the lock will be unlocked.\n+///\n+/// The data protected by the mutex can be access through this guard via its\n+/// Deref and DerefMut implementations\n #[must_use]\n-pub struct Guard<'a> {\n-    guard: mutex::LockGuard<'a>,\n+pub struct MutexGuard<'a, T: 'a> {\n+    // funny underscores due to how Deref/DerefMut currently work (they\n+    // disregard field privacy).\n+    __lock: &'a Mutex<T>,\n+    __guard: StaticMutexGuard,\n }\n \n-fn lift_guard(guard: mutex::LockGuard) -> Guard {\n-    Guard { guard: guard }\n+/// An RAII implementation of a \"scoped lock\" of a static mutex. When this\n+/// structure is dropped (falls out of scope), the lock will be unlocked.\n+#[must_use]\n+pub struct StaticMutexGuard {\n+    lock: &'static sys::Mutex,\n+    marker: marker::NoSend,\n+    poison: poison::Guard<'static>,\n }\n \n /// Static initialization of a mutex. This constant can be used to initialize\n /// other mutex constants.\n pub const MUTEX_INIT: StaticMutex = StaticMutex {\n-    lock: mutex::NATIVE_MUTEX_INIT\n+    lock: sys::MUTEX_INIT,\n+    poison: UnsafeCell { value: poison::Flag { failed: false } },\n };\n \n-impl StaticMutex {\n-    /// Attempts to grab this lock, see `Mutex::try_lock`\n-    pub fn try_lock<'a>(&'a self) -> Option<Guard<'a>> {\n-        unsafe { self.lock.trylock().map(lift_guard) }\n+impl<T: Send> Mutex<T> {\n+    /// Creates a new mutex in an unlocked state ready for use.\n+    pub fn new(t: T) -> Mutex<T> {\n+        Mutex {\n+            inner: box MUTEX_INIT,\n+            data: UnsafeCell::new(t),\n+        }\n+    }\n+\n+    /// Acquires a mutex, blocking the current task until it is able to do so.\n+    ///\n+    /// This function will block the local task until it is available to acquire\n+    /// the mutex. Upon returning, the task is the only task with the mutex\n+    /// held. An RAII guard is returned to allow scoped unlock of the lock. When\n+    /// the guard goes out of scope, the mutex will be unlocked.\n+    ///\n+    /// # Panics\n+    ///\n+    /// If another user of this mutex panicked while holding the mutex, then\n+    /// this call will immediately panic once the mutex is acquired.\n+    pub fn lock(&self) -> MutexGuard<T> {\n+        unsafe {\n+            let lock: &'static StaticMutex = &*(&*self.inner as *const _);\n+            MutexGuard::new(self, lock.lock())\n+        }\n+    }\n+\n+    /// Attempts to acquire this lock.\n+    ///\n+    /// If the lock could not be acquired at this time, then `None` is returned.\n+    /// Otherwise, an RAII guard is returned. The lock will be unlocked when the\n+    /// guard is dropped.\n+    ///\n+    /// This function does not block.\n+    ///\n+    /// # Panics\n+    ///\n+    /// If another user of this mutex panicked while holding the mutex, then\n+    /// this call will immediately panic if the mutex would otherwise be\n+    /// acquired.\n+    pub fn try_lock(&self) -> Option<MutexGuard<T>> {\n+        unsafe {\n+            let lock: &'static StaticMutex = &*(&*self.inner as *const _);\n+            lock.try_lock().map(|guard| {\n+                MutexGuard::new(self, guard)\n+            })\n+        }\n     }\n+}\n \n+#[unsafe_destructor]\n+impl<T: Send> Drop for Mutex<T> {\n+    fn drop(&mut self) {\n+        // This is actually safe b/c we know that there is no further usage of\n+        // this mutex (it's up to the user to arrange for a mutex to get\n+        // dropped, that's not our job)\n+        unsafe { self.inner.lock.destroy() }\n+    }\n+}\n+\n+impl StaticMutex {\n     /// Acquires this lock, see `Mutex::lock`\n-    pub fn lock<'a>(&'a self) -> Guard<'a> {\n-        lift_guard(unsafe { self.lock.lock() })\n+    pub fn lock(&'static self) -> StaticMutexGuard {\n+        unsafe { self.lock.lock() }\n+        StaticMutexGuard::new(self)\n+    }\n+\n+    /// Attempts to grab this lock, see `Mutex::try_lock`\n+    pub fn try_lock(&'static self) -> Option<StaticMutexGuard> {\n+        if unsafe { self.lock.try_lock() } {\n+            Some(StaticMutexGuard::new(self))\n+        } else {\n+            None\n+        }\n     }\n \n     /// Deallocates resources associated with this static mutex.\n@@ -110,58 +213,73 @@ impl StaticMutex {\n     /// *all* platforms. It may be the case that some platforms do not leak\n     /// memory if this method is not called, but this is not guaranteed to be\n     /// true on all platforms.\n-    pub unsafe fn destroy(&self) {\n+    pub unsafe fn destroy(&'static self) {\n         self.lock.destroy()\n     }\n }\n \n-impl Mutex {\n-    /// Creates a new mutex in an unlocked state ready for use.\n-    pub fn new() -> Mutex {\n-        Mutex {\n-            lock: box StaticMutex {\n-                lock: unsafe { mutex::StaticNativeMutex::new() },\n-            }\n-        }\n+impl<'mutex, T> MutexGuard<'mutex, T> {\n+    fn new(lock: &Mutex<T>, guard: StaticMutexGuard) -> MutexGuard<T> {\n+        MutexGuard { __lock: lock, __guard: guard }\n     }\n+}\n \n-    /// Attempts to acquire this lock.\n-    ///\n-    /// If the lock could not be acquired at this time, then `None` is returned.\n-    /// Otherwise, an RAII guard is returned. The lock will be unlocked when the\n-    /// guard is dropped.\n-    ///\n-    /// This function does not block.\n-    pub fn try_lock<'a>(&'a self) -> Option<Guard<'a>> {\n-        self.lock.try_lock()\n+impl<'mutex, T> AsMutexGuard for MutexGuard<'mutex, T> {\n+    unsafe fn as_mutex_guard(&self) -> &StaticMutexGuard { &self.__guard }\n+}\n+\n+impl<'mutex, T> Deref<T> for MutexGuard<'mutex, T> {\n+    fn deref<'a>(&'a self) -> &'a T { unsafe { &*self.__lock.data.get() } }\n+}\n+impl<'mutex, T> DerefMut<T> for MutexGuard<'mutex, T> {\n+    fn deref_mut<'a>(&'a mut self) -> &'a mut T {\n+        unsafe { &mut *self.__lock.data.get() }\n     }\n+}\n \n-    /// Acquires a mutex, blocking the current task until it is able to do so.\n-    ///\n-    /// This function will block the local task until it is available to acquire\n-    /// the mutex. Upon returning, the task is the only task with the mutex\n-    /// held. An RAII guard is returned to allow scoped unlock of the lock. When\n-    /// the guard goes out of scope, the mutex will be unlocked.\n-    pub fn lock<'a>(&'a self) -> Guard<'a> { self.lock.lock() }\n+impl StaticMutexGuard {\n+    fn new(lock: &'static StaticMutex) -> StaticMutexGuard {\n+        unsafe {\n+            let guard = StaticMutexGuard {\n+                lock: &lock.lock,\n+                marker: marker::NoSend,\n+                poison: (*lock.poison.get()).borrow(),\n+            };\n+            guard.poison.check(\"mutex\");\n+            return guard;\n+        }\n+    }\n+}\n+\n+pub fn guard_lock(guard: &StaticMutexGuard) -> &sys::Mutex { guard.lock }\n+pub fn guard_poison(guard: &StaticMutexGuard) -> &poison::Guard {\n+    &guard.poison\n+}\n+\n+impl AsMutexGuard for StaticMutexGuard {\n+    unsafe fn as_mutex_guard(&self) -> &StaticMutexGuard { self }\n }\n \n-impl Drop for Mutex {\n+#[unsafe_destructor]\n+impl Drop for StaticMutexGuard {\n     fn drop(&mut self) {\n-        // This is actually safe b/c we know that there is no further usage of\n-        // this mutex (it's up to the user to arrange for a mutex to get\n-        // dropped, that's not our job)\n-        unsafe { self.lock.destroy() }\n+        unsafe {\n+            self.poison.done();\n+            self.lock.unlock();\n+        }\n     }\n }\n \n #[cfg(test)]\n mod test {\n     use prelude::*;\n-    use super::{Mutex, StaticMutex, MUTEX_INIT};\n+\n+    use task;\n+    use sync::{Arc, Mutex, StaticMutex, MUTEX_INIT, Condvar};\n \n     #[test]\n     fn smoke() {\n-        let m = Mutex::new();\n+        let m = Mutex::new(());\n         drop(m.lock());\n         drop(m.lock());\n     }\n@@ -211,8 +329,104 @@ mod test {\n     }\n \n     #[test]\n-    fn trylock() {\n-        let m = Mutex::new();\n+    fn try_lock() {\n+        let m = Mutex::new(());\n         assert!(m.try_lock().is_some());\n     }\n+\n+    #[test]\n+    fn test_mutex_arc_condvar() {\n+        let arc = Arc::new((Mutex::new(false), Condvar::new()));\n+        let arc2 = arc.clone();\n+        let (tx, rx) = channel();\n+        spawn(proc() {\n+            // wait until parent gets in\n+            rx.recv();\n+            let &(ref lock, ref cvar) = &*arc2;\n+            let mut lock = lock.lock();\n+            *lock = true;\n+            cvar.notify_one();\n+        });\n+\n+        let &(ref lock, ref cvar) = &*arc;\n+        let lock = lock.lock();\n+        tx.send(());\n+        assert!(!*lock);\n+        while !*lock {\n+            cvar.wait(&lock);\n+        }\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_arc_condvar_poison() {\n+        let arc = Arc::new((Mutex::new(1i), Condvar::new()));\n+        let arc2 = arc.clone();\n+        let (tx, rx) = channel();\n+\n+        spawn(proc() {\n+            rx.recv();\n+            let &(ref lock, ref cvar) = &*arc2;\n+            let _g = lock.lock();\n+            cvar.notify_one();\n+            // Parent should fail when it wakes up.\n+            panic!();\n+        });\n+\n+        let &(ref lock, ref cvar) = &*arc;\n+        let lock = lock.lock();\n+        tx.send(());\n+        while *lock == 1 {\n+            cvar.wait(&lock);\n+        }\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_mutex_arc_poison() {\n+        let arc = Arc::new(Mutex::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try(proc() {\n+            let lock = arc2.lock();\n+            assert_eq!(*lock, 2);\n+        });\n+        let lock = arc.lock();\n+        assert_eq!(*lock, 1);\n+    }\n+\n+    #[test]\n+    fn test_mutex_arc_nested() {\n+        // Tests nested mutexes and access\n+        // to underlying data.\n+        let arc = Arc::new(Mutex::new(1i));\n+        let arc2 = Arc::new(Mutex::new(arc));\n+        let (tx, rx) = channel();\n+        spawn(proc() {\n+            let lock = arc2.lock();\n+            let lock2 = lock.deref().lock();\n+            assert_eq!(*lock2, 1);\n+            tx.send(());\n+        });\n+        rx.recv();\n+    }\n+\n+    #[test]\n+    fn test_mutex_arc_access_in_unwind() {\n+        let arc = Arc::new(Mutex::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try::<()>(proc() {\n+            struct Unwinder {\n+                i: Arc<Mutex<int>>,\n+            }\n+            impl Drop for Unwinder {\n+                fn drop(&mut self) {\n+                    *self.i.lock() += 1;\n+                }\n+            }\n+            let _u = Unwinder { i: arc2 };\n+            panic!();\n+        });\n+        let lock = arc.lock();\n+        assert_eq!(*lock, 2);\n+    }\n }"}, {"sha": "a75088120f869f73e0db460b0d1f04dd98224aee", "filename": "src/libstd/sync/once.rs", "status": "renamed", "additions": 8, "deletions": 9, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fonce.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fonce.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fonce.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -13,12 +13,10 @@\n //! This primitive is meant to be used to run one-time initialization. An\n //! example use case would be for initializing an FFI library.\n \n-use core::prelude::*;\n-\n-use core::int;\n-use core::atomic;\n-\n-use super::mutex::{StaticMutex, MUTEX_INIT};\n+use int;\n+use mem::drop;\n+use sync::atomic;\n+use sync::{StaticMutex, MUTEX_INIT};\n \n /// A synchronization primitive which can be used to run a one-time global\n /// initialization. Useful for one-time initialization for FFI or related\n@@ -27,8 +25,8 @@ use super::mutex::{StaticMutex, MUTEX_INIT};\n ///\n /// # Example\n ///\n-/// ```rust,ignore\n-/// use std::sync::one::{Once, ONCE_INIT};\n+/// ```rust\n+/// use std::sync::{Once, ONCE_INIT};\n ///\n /// static START: Once = ONCE_INIT;\n ///\n@@ -59,7 +57,7 @@ impl Once {\n     ///\n     /// When this function returns, it is guaranteed that some initialization\n     /// has run and completed (it may not be the closure specified).\n-    pub fn doit(&self, f: ||) {\n+    pub fn doit(&'static self, f: ||) {\n         // Optimize common path: load is much cheaper than fetch_add.\n         if self.cnt.load(atomic::SeqCst) < 0 {\n             return\n@@ -121,6 +119,7 @@ impl Once {\n #[cfg(test)]\n mod test {\n     use prelude::*;\n+\n     use task;\n     use super::{ONCE_INIT, Once};\n ", "previous_filename": "src/libstd/sync/one.rs"}, {"sha": "eb46fd771477e6df7349f00258478993e077dee4", "filename": "src/libstd/sync/poison.rs", "status": "added", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fpoison.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fpoison.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fpoison.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,48 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use option::None;\n+use rustrt::task::Task;\n+use rustrt::local::Local;\n+\n+pub struct Flag { pub failed: bool }\n+\n+impl Flag {\n+    pub fn borrow(&mut self) -> Guard {\n+        Guard { flag: &mut self.failed, failing: failing() }\n+    }\n+}\n+\n+pub struct Guard<'a> {\n+    flag: &'a mut bool,\n+    failing: bool,\n+}\n+\n+impl<'a> Guard<'a> {\n+    pub fn check(&self, name: &str) {\n+        if *self.flag {\n+            panic!(\"poisoned {} - another task failed inside\", name);\n+        }\n+    }\n+\n+    pub fn done(&mut self) {\n+        if !self.failing && failing() {\n+            *self.flag = true;\n+        }\n+    }\n+}\n+\n+fn failing() -> bool {\n+    if Local::exists(None::<Task>) {\n+        Local::borrow(None::<Task>).unwinder.unwinding()\n+    } else {\n+        false\n+    }\n+}"}, {"sha": "47580a115131bb2e467b3ca2df280992da04b978", "filename": "src/libstd/sync/raw.rs", "status": "removed", "additions": 0, "deletions": 1132, "changes": 1132, "blob_url": "https://github.com/rust-lang/rust/blob/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fraw.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Flibstd%2Fsync%2Fraw.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fraw.rs?ref=4573da6f4ffb276c31773679fd19581fc15ded8f", "patch": "@@ -1,1132 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Raw concurrency primitives you know and love.\n-//!\n-//! These primitives are not recommended for general use, but are provided for\n-//! flavorful use-cases. It is recommended to use the types at the top of the\n-//! `sync` crate which wrap values directly and provide safer abstractions for\n-//! containing data.\n-\n-// A side-effect of merging libsync into libstd; will go away once\n-// libsync rewrite lands\n-#![allow(dead_code)]\n-\n-use core::prelude::*;\n-use self::ReacquireOrderLock::*;\n-\n-use core::atomic;\n-use core::finally::Finally;\n-use core::kinds::marker;\n-use core::mem;\n-use core::cell::UnsafeCell;\n-use vec::Vec;\n-\n-use super::mutex;\n-use comm::{Receiver, Sender, channel};\n-\n-// Each waiting task receives on one of these.\n-type WaitEnd = Receiver<()>;\n-type SignalEnd = Sender<()>;\n-// A doubly-ended queue of waiting tasks.\n-struct WaitQueue {\n-    head: Receiver<SignalEnd>,\n-    tail: Sender<SignalEnd>,\n-}\n-\n-impl WaitQueue {\n-    fn new() -> WaitQueue {\n-        let (block_tail, block_head) = channel();\n-        WaitQueue { head: block_head, tail: block_tail }\n-    }\n-\n-    // Signals one live task from the queue.\n-    fn signal(&self) -> bool {\n-        match self.head.try_recv() {\n-            Ok(ch) => {\n-                // Send a wakeup signal. If the waiter was killed, its port will\n-                // have closed. Keep trying until we get a live task.\n-                if ch.send_opt(()).is_ok() {\n-                    true\n-                } else {\n-                    self.signal()\n-                }\n-            }\n-            _ => false\n-        }\n-    }\n-\n-    fn broadcast(&self) -> uint {\n-        let mut count = 0;\n-        loop {\n-            match self.head.try_recv() {\n-                Ok(ch) => {\n-                    if ch.send_opt(()).is_ok() {\n-                        count += 1;\n-                    }\n-                }\n-                _ => break\n-            }\n-        }\n-        count\n-    }\n-\n-    fn wait_end(&self) -> WaitEnd {\n-        let (signal_end, wait_end) = channel();\n-        self.tail.send(signal_end);\n-        wait_end\n-    }\n-}\n-\n-// The building-block used to make semaphores, mutexes, and rwlocks.\n-struct Sem<Q> {\n-    lock: mutex::Mutex,\n-    // n.b, we need Sem to be `Sync`, but the WaitQueue type is not send/share\n-    //      (for good reason). We have an internal invariant on this semaphore,\n-    //      however, that the queue is never accessed outside of a locked\n-    //      context.\n-    inner: UnsafeCell<SemInner<Q>>\n-}\n-\n-struct SemInner<Q> {\n-    count: int,\n-    waiters: WaitQueue,\n-    // Can be either unit or another waitqueue. Some sems shouldn't come with\n-    // a condition variable attached, others should.\n-    blocked: Q,\n-}\n-\n-#[must_use]\n-struct SemGuard<'a, Q:'a> {\n-    sem: &'a Sem<Q>,\n-}\n-\n-impl<Q: Send> Sem<Q> {\n-    fn new(count: int, q: Q) -> Sem<Q> {\n-        assert!(count >= 0,\n-                \"semaphores cannot be initialized with negative values\");\n-        Sem {\n-            lock: mutex::Mutex::new(),\n-            inner: UnsafeCell::new(SemInner {\n-                waiters: WaitQueue::new(),\n-                count: count,\n-                blocked: q,\n-            })\n-        }\n-    }\n-\n-    unsafe fn with(&self, f: |&mut SemInner<Q>|) {\n-        let _g = self.lock.lock();\n-        // This &mut is safe because, due to the lock, we are the only one who can touch the data\n-        f(&mut *self.inner.get())\n-    }\n-\n-    pub fn acquire(&self) {\n-        unsafe {\n-            let mut waiter_nobe = None;\n-            self.with(|state| {\n-                state.count -= 1;\n-                if state.count < 0 {\n-                    // Create waiter nobe, enqueue ourself, and tell\n-                    // outer scope we need to block.\n-                    waiter_nobe = Some(state.waiters.wait_end());\n-                }\n-            });\n-            // Uncomment if you wish to test for sem races. Not\n-            // valgrind-friendly.\n-            /* for _ in range(0u, 1000) { task::deschedule(); } */\n-            // Need to wait outside the exclusive.\n-            if waiter_nobe.is_some() {\n-                let _ = waiter_nobe.unwrap().recv();\n-            }\n-        }\n-    }\n-\n-    pub fn release(&self) {\n-        unsafe {\n-            self.with(|state| {\n-                state.count += 1;\n-                if state.count <= 0 {\n-                    state.waiters.signal();\n-                }\n-            })\n-        }\n-    }\n-\n-    pub fn access<'a>(&'a self) -> SemGuard<'a, Q> {\n-        self.acquire();\n-        SemGuard { sem: self }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<'a, Q: Send> Drop for SemGuard<'a, Q> {\n-    fn drop(&mut self) {\n-        self.sem.release();\n-    }\n-}\n-\n-impl Sem<Vec<WaitQueue>> {\n-    fn new_and_signal(count: int, num_condvars: uint) -> Sem<Vec<WaitQueue>> {\n-        let mut queues = Vec::new();\n-        for _ in range(0, num_condvars) { queues.push(WaitQueue::new()); }\n-        Sem::new(count, queues)\n-    }\n-\n-    // The only other places that condvars get built are rwlock.write_cond()\n-    // and rwlock_write_mode.\n-    pub fn access_cond<'a>(&'a self) -> SemCondGuard<'a> {\n-        SemCondGuard {\n-            guard: self.access(),\n-            cvar: Condvar { sem: self, order: Nothing, nocopy: marker::NoCopy },\n-        }\n-    }\n-}\n-\n-// FIXME(#3598): Want to use an Option down below, but we need a custom enum\n-// that's not polymorphic to get around the fact that lifetimes are invariant\n-// inside of type parameters.\n-enum ReacquireOrderLock<'a> {\n-    Nothing, // c.c\n-    Just(&'a Semaphore),\n-}\n-\n-/// A mechanism for atomic-unlock-and-deschedule blocking and signalling.\n-pub struct Condvar<'a> {\n-    // The 'Sem' object associated with this condvar. This is the one that's\n-    // atomically-unlocked-and-descheduled upon and reacquired during wakeup.\n-    sem: &'a Sem<Vec<WaitQueue> >,\n-    // This is (can be) an extra semaphore which is held around the reacquire\n-    // operation on the first one. This is only used in cvars associated with\n-    // rwlocks, and is needed to ensure that, when a downgrader is trying to\n-    // hand off the access lock (which would be the first field, here), a 2nd\n-    // writer waking up from a cvar wait can't race with a reader to steal it,\n-    // See the comment in write_cond for more detail.\n-    order: ReacquireOrderLock<'a>,\n-    // Make sure condvars are non-copyable.\n-    nocopy: marker::NoCopy,\n-}\n-\n-impl<'a> Condvar<'a> {\n-    /// Atomically drop the associated lock, and block until a signal is sent.\n-    ///\n-    /// # Panics\n-    ///\n-    /// A task which is killed while waiting on a condition variable will wake\n-    /// up, panic, and unlock the associated lock as it unwinds.\n-    pub fn wait(&self) { self.wait_on(0) }\n-\n-    /// As wait(), but can specify which of multiple condition variables to\n-    /// wait on. Only a signal_on() or broadcast_on() with the same condvar_id\n-    /// will wake this thread.\n-    ///\n-    /// The associated lock must have been initialised with an appropriate\n-    /// number of condvars. The condvar_id must be between 0 and num_condvars-1\n-    /// or else this call will panic.\n-    ///\n-    /// wait() is equivalent to wait_on(0).\n-    pub fn wait_on(&self, condvar_id: uint) {\n-        let mut wait_end = None;\n-        let mut out_of_bounds = None;\n-        // Release lock, 'atomically' enqueuing ourselves in so doing.\n-        unsafe {\n-            self.sem.with(|state| {\n-                if condvar_id < state.blocked.len() {\n-                    // Drop the lock.\n-                    state.count += 1;\n-                    if state.count <= 0 {\n-                        state.waiters.signal();\n-                    }\n-                    // Create waiter nobe, and enqueue ourself to\n-                    // be woken up by a signaller.\n-                    wait_end = Some(state.blocked[condvar_id].wait_end());\n-                } else {\n-                    out_of_bounds = Some(state.blocked.len());\n-                }\n-            })\n-        }\n-\n-        // If deschedule checks start getting inserted anywhere, we can be\n-        // killed before or after enqueueing.\n-        check_cvar_bounds(out_of_bounds, condvar_id, \"cond.wait_on()\", || {\n-            // Unconditionally \"block\". (Might not actually block if a\n-            // signaller already sent -- I mean 'unconditionally' in contrast\n-            // with acquire().)\n-            (|| {\n-                let _ = wait_end.take().unwrap().recv();\n-            }).finally(|| {\n-                // Reacquire the condvar.\n-                match self.order {\n-                    Just(lock) => {\n-                        let _g = lock.access();\n-                        self.sem.acquire();\n-                    }\n-                    Nothing => self.sem.acquire(),\n-                }\n-            })\n-        })\n-    }\n-\n-    /// Wake up a blocked task. Returns false if there was no blocked task.\n-    pub fn signal(&self) -> bool { self.signal_on(0) }\n-\n-    /// As signal, but with a specified condvar_id. See wait_on.\n-    pub fn signal_on(&self, condvar_id: uint) -> bool {\n-        unsafe {\n-            let mut out_of_bounds = None;\n-            let mut result = false;\n-            self.sem.with(|state| {\n-                if condvar_id < state.blocked.len() {\n-                    result = state.blocked[condvar_id].signal();\n-                } else {\n-                    out_of_bounds = Some(state.blocked.len());\n-                }\n-            });\n-            check_cvar_bounds(out_of_bounds,\n-                              condvar_id,\n-                              \"cond.signal_on()\",\n-                              || result)\n-        }\n-    }\n-\n-    /// Wake up all blocked tasks. Returns the number of tasks woken.\n-    pub fn broadcast(&self) -> uint { self.broadcast_on(0) }\n-\n-    /// As broadcast, but with a specified condvar_id. See wait_on.\n-    pub fn broadcast_on(&self, condvar_id: uint) -> uint {\n-        let mut out_of_bounds = None;\n-        let mut queue = None;\n-        unsafe {\n-            self.sem.with(|state| {\n-                if condvar_id < state.blocked.len() {\n-                    // To avoid :broadcast_heavy, we make a new waitqueue,\n-                    // swap it out with the old one, and broadcast on the\n-                    // old one outside of the little-lock.\n-                    queue = Some(mem::replace(&mut state.blocked[condvar_id],\n-                                              WaitQueue::new()));\n-                } else {\n-                    out_of_bounds = Some(state.blocked.len());\n-                }\n-            });\n-            check_cvar_bounds(out_of_bounds,\n-                              condvar_id,\n-                              \"cond.signal_on()\",\n-                              || {\n-                queue.take().unwrap().broadcast()\n-            })\n-        }\n-    }\n-}\n-\n-// Checks whether a condvar ID was out of bounds, and panics if so, or does\n-// something else next on success.\n-#[inline]\n-fn check_cvar_bounds<U>(\n-                     out_of_bounds: Option<uint>,\n-                     id: uint,\n-                     act: &str,\n-                     blk: || -> U)\n-                     -> U {\n-    match out_of_bounds {\n-        Some(0) =>\n-            panic!(\"{} with illegal ID {} - this lock has no condvars!\", act, id),\n-        Some(length) =>\n-            panic!(\"{} with illegal ID {} - ID must be less than {}\", act, id, length),\n-        None => blk()\n-    }\n-}\n-\n-#[must_use]\n-struct SemCondGuard<'a> {\n-    guard: SemGuard<'a, Vec<WaitQueue>>,\n-    cvar: Condvar<'a>,\n-}\n-\n-/// A counting, blocking, bounded-waiting semaphore.\n-pub struct Semaphore {\n-    sem: Sem<()>,\n-}\n-\n-/// An RAII guard used to represent an acquired resource to a semaphore. When\n-/// dropped, this value will release the resource back to the semaphore.\n-#[must_use]\n-pub struct SemaphoreGuard<'a> {\n-    _guard: SemGuard<'a, ()>,\n-}\n-\n-impl Semaphore {\n-    /// Create a new semaphore with the specified count.\n-    ///\n-    /// # Panics\n-    ///\n-    /// This function will panic if `count` is negative.\n-    pub fn new(count: int) -> Semaphore {\n-        Semaphore { sem: Sem::new(count, ()) }\n-    }\n-\n-    /// Acquire a resource represented by the semaphore. Blocks if necessary\n-    /// until resource(s) become available.\n-    pub fn acquire(&self) { self.sem.acquire() }\n-\n-    /// Release a held resource represented by the semaphore. Wakes a blocked\n-    /// contending task, if any exist. Won't block the caller.\n-    pub fn release(&self) { self.sem.release() }\n-\n-    /// Acquire a resource of this semaphore, returning an RAII guard which will\n-    /// release the resource when dropped.\n-    pub fn access<'a>(&'a self) -> SemaphoreGuard<'a> {\n-        SemaphoreGuard { _guard: self.sem.access() }\n-    }\n-}\n-\n-/// A blocking, bounded-waiting, mutual exclusion lock with an associated\n-/// FIFO condition variable.\n-///\n-/// # Panics\n-///\n-/// A task which panicks while holding a mutex will unlock the mutex as it\n-/// unwinds.\n-pub struct Mutex {\n-    sem: Sem<Vec<WaitQueue>>,\n-}\n-\n-/// An RAII structure which is used to gain access to a mutex's condition\n-/// variable. Additionally, when a value of this type is dropped, the\n-/// corresponding mutex is also unlocked.\n-#[must_use]\n-pub struct MutexGuard<'a> {\n-    _guard: SemGuard<'a, Vec<WaitQueue>>,\n-    /// Inner condition variable which is connected to the outer mutex, and can\n-    /// be used for atomic-unlock-and-deschedule.\n-    pub cond: Condvar<'a>,\n-}\n-\n-impl Mutex {\n-    /// Create a new mutex, with one associated condvar.\n-    pub fn new() -> Mutex { Mutex::new_with_condvars(1) }\n-\n-    /// Create a new mutex, with a specified number of associated condvars. This\n-    /// will allow calling wait_on/signal_on/broadcast_on with condvar IDs\n-    /// between 0 and num_condvars-1. (If num_condvars is 0, lock_cond will be\n-    /// allowed but any operations on the condvar will panic.)\n-    pub fn new_with_condvars(num_condvars: uint) -> Mutex {\n-        Mutex { sem: Sem::new_and_signal(1, num_condvars) }\n-    }\n-\n-    /// Acquires ownership of this mutex, returning an RAII guard which will\n-    /// unlock the mutex when dropped. The associated condition variable can\n-    /// also be accessed through the returned guard.\n-    pub fn lock<'a>(&'a self) -> MutexGuard<'a> {\n-        let SemCondGuard { guard, cvar } = self.sem.access_cond();\n-        MutexGuard { _guard: guard, cond: cvar }\n-    }\n-}\n-\n-// NB: Wikipedia - Readers-writers_problem#The_third_readers-writers_problem\n-\n-/// A blocking, no-starvation, reader-writer lock with an associated condvar.\n-///\n-/// # Panics\n-///\n-/// A task which panics while holding an rwlock will unlock the rwlock as it\n-/// unwinds.\n-pub struct RWLock {\n-    order_lock:  Semaphore,\n-    access_lock: Sem<Vec<WaitQueue>>,\n-\n-    // The only way the count flag is ever accessed is with xadd. Since it is\n-    // a read-modify-write operation, multiple xadds on different cores will\n-    // always be consistent with respect to each other, so a monotonic/relaxed\n-    // consistency ordering suffices (i.e., no extra barriers are needed).\n-    //\n-    // FIXME(#6598): The atomics module has no relaxed ordering flag, so I use\n-    // acquire/release orderings superfluously. Change these someday.\n-    read_count: atomic::AtomicUint,\n-}\n-\n-/// An RAII helper which is created by acquiring a read lock on an RWLock. When\n-/// dropped, this will unlock the RWLock.\n-#[must_use]\n-pub struct RWLockReadGuard<'a> {\n-    lock: &'a RWLock,\n-}\n-\n-/// An RAII helper which is created by acquiring a write lock on an RWLock. When\n-/// dropped, this will unlock the RWLock.\n-///\n-/// A value of this type can also be consumed to downgrade to a read-only lock.\n-#[must_use]\n-pub struct RWLockWriteGuard<'a> {\n-    lock: &'a RWLock,\n-    /// Inner condition variable that is connected to the write-mode of the\n-    /// outer rwlock.\n-    pub cond: Condvar<'a>,\n-}\n-\n-impl RWLock {\n-    /// Create a new rwlock, with one associated condvar.\n-    pub fn new() -> RWLock { RWLock::new_with_condvars(1) }\n-\n-    /// Create a new rwlock, with a specified number of associated condvars.\n-    /// Similar to mutex_with_condvars.\n-    pub fn new_with_condvars(num_condvars: uint) -> RWLock {\n-        RWLock {\n-            order_lock: Semaphore::new(1),\n-            access_lock: Sem::new_and_signal(1, num_condvars),\n-            read_count: atomic::AtomicUint::new(0),\n-        }\n-    }\n-\n-    /// Acquires a read-lock, returning an RAII guard that will unlock the lock\n-    /// when dropped. Calls to 'read' from other tasks may run concurrently with\n-    /// this one.\n-    pub fn read<'a>(&'a self) -> RWLockReadGuard<'a> {\n-        let _guard = self.order_lock.access();\n-        let old_count = self.read_count.fetch_add(1, atomic::Acquire);\n-        if old_count == 0 {\n-            self.access_lock.acquire();\n-        }\n-        RWLockReadGuard { lock: self }\n-    }\n-\n-    /// Acquire a write-lock, returning an RAII guard that will unlock the lock\n-    /// when dropped. No calls to 'read' or 'write' from other tasks will run\n-    /// concurrently with this one.\n-    ///\n-    /// You can also downgrade a write to a read by calling the `downgrade`\n-    /// method on the returned guard. Additionally, the guard will contain a\n-    /// `Condvar` attached to this lock.\n-    ///\n-    /// # Example\n-    ///\n-    /// ```{rust,ignore}\n-    /// use std::sync::raw::RWLock;\n-    ///\n-    /// let lock = RWLock::new();\n-    /// let write = lock.write();\n-    /// // ... exclusive access ...\n-    /// let read = write.downgrade();\n-    /// // ... shared access ...\n-    /// drop(read);\n-    /// ```\n-    pub fn write<'a>(&'a self) -> RWLockWriteGuard<'a> {\n-        let _g = self.order_lock.access();\n-        self.access_lock.acquire();\n-\n-        // It's important to thread our order lock into the condvar, so that\n-        // when a cond.wait() wakes up, it uses it while reacquiring the\n-        // access lock. If we permitted a waking-up writer to \"cut in line\",\n-        // there could arise a subtle race when a downgrader attempts to hand\n-        // off the reader cloud lock to a waiting reader. This race is tested\n-        // in arc.rs (test_rw_write_cond_downgrade_read_race) and looks like:\n-        // T1 (writer)              T2 (downgrader)             T3 (reader)\n-        // [in cond.wait()]\n-        //                          [locks for writing]\n-        //                          [holds access_lock]\n-        // [is signalled, perhaps by\n-        //  downgrader or a 4th thread]\n-        // tries to lock access(!)\n-        //                                                      lock order_lock\n-        //                                                      xadd read_count[0->1]\n-        //                                                      tries to lock access\n-        //                          [downgrade]\n-        //                          xadd read_count[1->2]\n-        //                          unlock access\n-        // Since T1 contended on the access lock before T3 did, it will steal\n-        // the lock handoff. Adding order_lock in the condvar reacquire path\n-        // solves this because T1 will hold order_lock while waiting on access,\n-        // which will cause T3 to have to wait until T1 finishes its write,\n-        // which can't happen until T2 finishes the downgrade-read entirely.\n-        // The astute reader will also note that making waking writers use the\n-        // order_lock is better for not starving readers.\n-        RWLockWriteGuard {\n-            lock: self,\n-            cond: Condvar {\n-                sem: &self.access_lock,\n-                order: Just(&self.order_lock),\n-                nocopy: marker::NoCopy,\n-            }\n-        }\n-    }\n-}\n-\n-impl<'a> RWLockWriteGuard<'a> {\n-    /// Consumes this write lock and converts it into a read lock.\n-    pub fn downgrade(self) -> RWLockReadGuard<'a> {\n-        let lock = self.lock;\n-        // Don't run the destructor of the write guard, we're in charge of\n-        // things from now on\n-        unsafe { mem::forget(self) }\n-\n-        let old_count = lock.read_count.fetch_add(1, atomic::Release);\n-        // If another reader was already blocking, we need to hand-off\n-        // the \"reader cloud\" access lock to them.\n-        if old_count != 0 {\n-            // Guaranteed not to let another writer in, because\n-            // another reader was holding the order_lock. Hence they\n-            // must be the one to get the access_lock (because all\n-            // access_locks are acquired with order_lock held). See\n-            // the comment in write_cond for more justification.\n-            lock.access_lock.release();\n-        }\n-        RWLockReadGuard { lock: lock }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<'a> Drop for RWLockWriteGuard<'a> {\n-    fn drop(&mut self) {\n-        self.lock.access_lock.release();\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<'a> Drop for RWLockReadGuard<'a> {\n-    fn drop(&mut self) {\n-        let old_count = self.lock.read_count.fetch_sub(1, atomic::Release);\n-        assert!(old_count > 0);\n-        if old_count == 1 {\n-            // Note: this release used to be outside of a locked access\n-            // to exclusive-protected state. If this code is ever\n-            // converted back to such (instead of using atomic ops),\n-            // this access MUST NOT go inside the exclusive access.\n-            self.lock.access_lock.release();\n-        }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    pub use self::RWLockMode::*;\n-\n-    use sync::Arc;\n-    use prelude::*;\n-    use super::{Semaphore, Mutex, RWLock, Condvar};\n-\n-    use mem;\n-    use result;\n-    use task;\n-\n-    #[test]\n-    fn test_sem_acquire_release() {\n-        let s = Semaphore::new(1);\n-        s.acquire();\n-        s.release();\n-        s.acquire();\n-    }\n-\n-    #[test]\n-    fn test_sem_basic() {\n-        let s = Semaphore::new(1);\n-        let _g = s.access();\n-    }\n-\n-    #[test]\n-    #[should_fail]\n-    fn test_sem_basic2() {\n-        Semaphore::new(-1);\n-    }\n-\n-    #[test]\n-    fn test_sem_as_mutex() {\n-        let s = Arc::new(Semaphore::new(1));\n-        let s2 = s.clone();\n-        task::spawn(proc() {\n-            let _g = s2.access();\n-            for _ in range(0u, 5) { task::deschedule(); }\n-        });\n-        let _g = s.access();\n-        for _ in range(0u, 5) { task::deschedule(); }\n-    }\n-\n-    #[test]\n-    fn test_sem_as_cvar() {\n-        /* Child waits and parent signals */\n-        let (tx, rx) = channel();\n-        let s = Arc::new(Semaphore::new(0));\n-        let s2 = s.clone();\n-        task::spawn(proc() {\n-            s2.acquire();\n-            tx.send(());\n-        });\n-        for _ in range(0u, 5) { task::deschedule(); }\n-        s.release();\n-        let _ = rx.recv();\n-\n-        /* Parent waits and child signals */\n-        let (tx, rx) = channel();\n-        let s = Arc::new(Semaphore::new(0));\n-        let s2 = s.clone();\n-        task::spawn(proc() {\n-            for _ in range(0u, 5) { task::deschedule(); }\n-            s2.release();\n-            let _ = rx.recv();\n-        });\n-        s.acquire();\n-        tx.send(());\n-    }\n-\n-    #[test]\n-    fn test_sem_multi_resource() {\n-        // Parent and child both get in the critical section at the same\n-        // time, and shake hands.\n-        let s = Arc::new(Semaphore::new(2));\n-        let s2 = s.clone();\n-        let (tx1, rx1) = channel();\n-        let (tx2, rx2) = channel();\n-        task::spawn(proc() {\n-            let _g = s2.access();\n-            let _ = rx2.recv();\n-            tx1.send(());\n-        });\n-        let _g = s.access();\n-        tx2.send(());\n-        let _ = rx1.recv();\n-    }\n-\n-    #[test]\n-    fn test_sem_runtime_friendly_blocking() {\n-        // Force the runtime to schedule two threads on the same sched_loop.\n-        // When one blocks, it should schedule the other one.\n-        let s = Arc::new(Semaphore::new(1));\n-        let s2 = s.clone();\n-        let (tx, rx) = channel();\n-        {\n-            let _g = s.access();\n-            task::spawn(proc() {\n-                tx.send(());\n-                drop(s2.access());\n-                tx.send(());\n-            });\n-            rx.recv(); // wait for child to come alive\n-            for _ in range(0u, 5) { task::deschedule(); } // let the child contend\n-        }\n-        rx.recv(); // wait for child to be done\n-    }\n-\n-    #[test]\n-    fn test_mutex_lock() {\n-        // Unsafely achieve shared state, and do the textbook\n-        // \"load tmp = move ptr; inc tmp; store ptr <- tmp\" dance.\n-        let (tx, rx) = channel();\n-        let m = Arc::new(Mutex::new());\n-        let m2 = m.clone();\n-        let mut sharedstate = box 0;\n-        {\n-            let ptr: *mut int = &mut *sharedstate;\n-            task::spawn(proc() {\n-                access_shared(ptr, &m2, 10);\n-                tx.send(());\n-            });\n-        }\n-        {\n-            access_shared(&mut *sharedstate, &m, 10);\n-            let _ = rx.recv();\n-\n-            assert_eq!(*sharedstate, 20);\n-        }\n-\n-        fn access_shared(sharedstate: *mut int, m: &Arc<Mutex>, n: uint) {\n-            for _ in range(0u, n) {\n-                let _g = m.lock();\n-                let oldval = unsafe { *sharedstate };\n-                task::deschedule();\n-                unsafe { *sharedstate = oldval + 1; }\n-            }\n-        }\n-    }\n-\n-    #[test]\n-    fn test_mutex_cond_wait() {\n-        let m = Arc::new(Mutex::new());\n-\n-        // Child wakes up parent\n-        {\n-            let lock = m.lock();\n-            let m2 = m.clone();\n-            task::spawn(proc() {\n-                let lock = m2.lock();\n-                let woken = lock.cond.signal();\n-                assert!(woken);\n-            });\n-            lock.cond.wait();\n-        }\n-        // Parent wakes up child\n-        let (tx, rx) = channel();\n-        let m3 = m.clone();\n-        task::spawn(proc() {\n-            let lock = m3.lock();\n-            tx.send(());\n-            lock.cond.wait();\n-            tx.send(());\n-        });\n-        rx.recv(); // Wait until child gets in the mutex\n-        {\n-            let lock = m.lock();\n-            let woken = lock.cond.signal();\n-            assert!(woken);\n-        }\n-        rx.recv(); // Wait until child wakes up\n-    }\n-\n-    fn test_mutex_cond_broadcast_helper(num_waiters: uint) {\n-        let m = Arc::new(Mutex::new());\n-        let mut rxs = Vec::new();\n-\n-        for _ in range(0u, num_waiters) {\n-            let mi = m.clone();\n-            let (tx, rx) = channel();\n-            rxs.push(rx);\n-            task::spawn(proc() {\n-                let lock = mi.lock();\n-                tx.send(());\n-                lock.cond.wait();\n-                tx.send(());\n-            });\n-        }\n-\n-        // wait until all children get in the mutex\n-        for rx in rxs.iter_mut() { rx.recv(); }\n-        {\n-            let lock = m.lock();\n-            let num_woken = lock.cond.broadcast();\n-            assert_eq!(num_woken, num_waiters);\n-        }\n-        // wait until all children wake up\n-        for rx in rxs.iter_mut() { rx.recv(); }\n-    }\n-\n-    #[test]\n-    fn test_mutex_cond_broadcast() {\n-        test_mutex_cond_broadcast_helper(12);\n-    }\n-\n-    #[test]\n-    fn test_mutex_cond_broadcast_none() {\n-        test_mutex_cond_broadcast_helper(0);\n-    }\n-\n-    #[test]\n-    fn test_mutex_cond_no_waiter() {\n-        let m = Arc::new(Mutex::new());\n-        let m2 = m.clone();\n-        let _ = task::try(proc() {\n-            drop(m.lock());\n-        });\n-        let lock = m2.lock();\n-        assert!(!lock.cond.signal());\n-    }\n-\n-    #[test]\n-    fn test_mutex_killed_simple() {\n-        use any::Any;\n-\n-        // Mutex must get automatically unlocked if panicked/killed within.\n-        let m = Arc::new(Mutex::new());\n-        let m2 = m.clone();\n-\n-        let result: result::Result<(), Box<Any + Send>> = task::try(proc() {\n-            let _lock = m2.lock();\n-            panic!();\n-        });\n-        assert!(result.is_err());\n-        // child task must have finished by the time try returns\n-        drop(m.lock());\n-    }\n-\n-    #[test]\n-    fn test_mutex_cond_signal_on_0() {\n-        // Tests that signal_on(0) is equivalent to signal().\n-        let m = Arc::new(Mutex::new());\n-        let lock = m.lock();\n-        let m2 = m.clone();\n-        task::spawn(proc() {\n-            let lock = m2.lock();\n-            lock.cond.signal_on(0);\n-        });\n-        lock.cond.wait();\n-    }\n-\n-    #[test]\n-    fn test_mutex_no_condvars() {\n-        let result = task::try(proc() {\n-            let m = Mutex::new_with_condvars(0);\n-            m.lock().cond.wait();\n-        });\n-        assert!(result.is_err());\n-        let result = task::try(proc() {\n-            let m = Mutex::new_with_condvars(0);\n-            m.lock().cond.signal();\n-        });\n-        assert!(result.is_err());\n-        let result = task::try(proc() {\n-            let m = Mutex::new_with_condvars(0);\n-            m.lock().cond.broadcast();\n-        });\n-        assert!(result.is_err());\n-    }\n-\n-    #[cfg(test)]\n-    pub enum RWLockMode { Read, Write, Downgrade, DowngradeRead }\n-\n-    #[cfg(test)]\n-    fn lock_rwlock_in_mode(x: &Arc<RWLock>, mode: RWLockMode, blk: ||) {\n-        match mode {\n-            Read => { let _g = x.read(); blk() }\n-            Write => { let _g = x.write(); blk() }\n-            Downgrade => { let _g = x.write(); blk() }\n-            DowngradeRead => { let _g = x.write().downgrade(); blk() }\n-        }\n-    }\n-\n-    #[cfg(test)]\n-    fn test_rwlock_exclusion(x: Arc<RWLock>,\n-                             mode1: RWLockMode,\n-                             mode2: RWLockMode) {\n-        // Test mutual exclusion between readers and writers. Just like the\n-        // mutex mutual exclusion test, a ways above.\n-        let (tx, rx) = channel();\n-        let x2 = x.clone();\n-        let mut sharedstate = box 0;\n-        {\n-            let ptr: *const int = &*sharedstate;\n-            task::spawn(proc() {\n-                let sharedstate: &mut int =\n-                    unsafe { mem::transmute(ptr) };\n-                access_shared(sharedstate, &x2, mode1, 10);\n-                tx.send(());\n-            });\n-        }\n-        {\n-            access_shared(&mut *sharedstate, &x, mode2, 10);\n-            let _ = rx.recv();\n-\n-            assert_eq!(*sharedstate, 20);\n-        }\n-\n-        fn access_shared(sharedstate: &mut int, x: &Arc<RWLock>,\n-                         mode: RWLockMode, n: uint) {\n-            for _ in range(0u, n) {\n-                lock_rwlock_in_mode(x, mode, || {\n-                    let oldval = *sharedstate;\n-                    task::deschedule();\n-                    *sharedstate = oldval + 1;\n-                })\n-            }\n-        }\n-    }\n-\n-    #[test]\n-    fn test_rwlock_readers_wont_modify_the_data() {\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Read, Write);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Write, Read);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Read, Downgrade);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Downgrade, Read);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Write, DowngradeRead);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), DowngradeRead, Write);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_writers_and_writers() {\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Write, Write);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Write, Downgrade);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Downgrade, Write);\n-        test_rwlock_exclusion(Arc::new(RWLock::new()), Downgrade, Downgrade);\n-    }\n-\n-    #[cfg(test)]\n-    fn test_rwlock_handshake(x: Arc<RWLock>,\n-                             mode1: RWLockMode,\n-                             mode2: RWLockMode,\n-                             make_mode2_go_first: bool) {\n-        // Much like sem_multi_resource.\n-        let x2 = x.clone();\n-        let (tx1, rx1) = channel();\n-        let (tx2, rx2) = channel();\n-        task::spawn(proc() {\n-            if !make_mode2_go_first {\n-                rx2.recv(); // parent sends to us once it locks, or ...\n-            }\n-            lock_rwlock_in_mode(&x2, mode2, || {\n-                if make_mode2_go_first {\n-                    tx1.send(()); // ... we send to it once we lock\n-                }\n-                rx2.recv();\n-                tx1.send(());\n-            })\n-        });\n-        if make_mode2_go_first {\n-            rx1.recv(); // child sends to us once it locks, or ...\n-        }\n-        lock_rwlock_in_mode(&x, mode1, || {\n-            if !make_mode2_go_first {\n-                tx2.send(()); // ... we send to it once we lock\n-            }\n-            tx2.send(());\n-            rx1.recv();\n-        })\n-    }\n-\n-    #[test]\n-    fn test_rwlock_readers_and_readers() {\n-        test_rwlock_handshake(Arc::new(RWLock::new()), Read, Read, false);\n-        // The downgrader needs to get in before the reader gets in, otherwise\n-        // they cannot end up reading at the same time.\n-        test_rwlock_handshake(Arc::new(RWLock::new()), DowngradeRead, Read, false);\n-        test_rwlock_handshake(Arc::new(RWLock::new()), Read, DowngradeRead, true);\n-        // Two downgrade_reads can never both end up reading at the same time.\n-    }\n-\n-    #[test]\n-    fn test_rwlock_downgrade_unlock() {\n-        // Tests that downgrade can unlock the lock in both modes\n-        let x = Arc::new(RWLock::new());\n-        lock_rwlock_in_mode(&x, Downgrade, || { });\n-        test_rwlock_handshake(x, Read, Read, false);\n-        let y = Arc::new(RWLock::new());\n-        lock_rwlock_in_mode(&y, DowngradeRead, || { });\n-        test_rwlock_exclusion(y, Write, Write);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_read_recursive() {\n-        let x = RWLock::new();\n-        let _g1 = x.read();\n-        let _g2 = x.read();\n-    }\n-\n-    #[test]\n-    fn test_rwlock_cond_wait() {\n-        // As test_mutex_cond_wait above.\n-        let x = Arc::new(RWLock::new());\n-\n-        // Child wakes up parent\n-        {\n-            let lock = x.write();\n-            let x2 = x.clone();\n-            task::spawn(proc() {\n-                let lock = x2.write();\n-                assert!(lock.cond.signal());\n-            });\n-            lock.cond.wait();\n-        }\n-        // Parent wakes up child\n-        let (tx, rx) = channel();\n-        let x3 = x.clone();\n-        task::spawn(proc() {\n-            let lock = x3.write();\n-            tx.send(());\n-            lock.cond.wait();\n-            tx.send(());\n-        });\n-        rx.recv(); // Wait until child gets in the rwlock\n-        drop(x.read()); // Must be able to get in as a reader\n-        {\n-            let x = x.write();\n-            assert!(x.cond.signal());\n-        }\n-        rx.recv(); // Wait until child wakes up\n-        drop(x.read()); // Just for good measure\n-    }\n-\n-    #[cfg(test)]\n-    fn test_rwlock_cond_broadcast_helper(num_waiters: uint) {\n-        // Much like the mutex broadcast test. Downgrade-enabled.\n-        fn lock_cond(x: &Arc<RWLock>, blk: |c: &Condvar|) {\n-            let lock = x.write();\n-            blk(&lock.cond);\n-        }\n-\n-        let x = Arc::new(RWLock::new());\n-        let mut rxs = Vec::new();\n-\n-        for _ in range(0u, num_waiters) {\n-            let xi = x.clone();\n-            let (tx, rx) = channel();\n-            rxs.push(rx);\n-            task::spawn(proc() {\n-                lock_cond(&xi, |cond| {\n-                    tx.send(());\n-                    cond.wait();\n-                    tx.send(());\n-                })\n-            });\n-        }\n-\n-        // wait until all children get in the mutex\n-        for rx in rxs.iter_mut() { let _ = rx.recv(); }\n-        lock_cond(&x, |cond| {\n-            let num_woken = cond.broadcast();\n-            assert_eq!(num_woken, num_waiters);\n-        });\n-        // wait until all children wake up\n-        for rx in rxs.iter_mut() { let _ = rx.recv(); }\n-    }\n-\n-    #[test]\n-    fn test_rwlock_cond_broadcast() {\n-        test_rwlock_cond_broadcast_helper(0);\n-        test_rwlock_cond_broadcast_helper(12);\n-    }\n-\n-    #[cfg(test)]\n-    fn rwlock_kill_helper(mode1: RWLockMode, mode2: RWLockMode) {\n-        use any::Any;\n-\n-        // Mutex must get automatically unlocked if panicked/killed within.\n-        let x = Arc::new(RWLock::new());\n-        let x2 = x.clone();\n-\n-        let result: result::Result<(), Box<Any + Send>> = task::try(proc() {\n-            lock_rwlock_in_mode(&x2, mode1, || {\n-                panic!();\n-            })\n-        });\n-        assert!(result.is_err());\n-        // child task must have finished by the time try returns\n-        lock_rwlock_in_mode(&x, mode2, || { })\n-    }\n-\n-    #[test]\n-    fn test_rwlock_reader_killed_writer() {\n-        rwlock_kill_helper(Read, Write);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_writer_killed_reader() {\n-        rwlock_kill_helper(Write, Read);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_reader_killed_reader() {\n-        rwlock_kill_helper(Read, Read);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_writer_killed_writer() {\n-        rwlock_kill_helper(Write, Write);\n-    }\n-\n-    #[test]\n-    fn test_rwlock_kill_downgrader() {\n-        rwlock_kill_helper(Downgrade, Read);\n-        rwlock_kill_helper(Read, Downgrade);\n-        rwlock_kill_helper(Downgrade, Write);\n-        rwlock_kill_helper(Write, Downgrade);\n-        rwlock_kill_helper(DowngradeRead, Read);\n-        rwlock_kill_helper(Read, DowngradeRead);\n-        rwlock_kill_helper(DowngradeRead, Write);\n-        rwlock_kill_helper(Write, DowngradeRead);\n-        rwlock_kill_helper(DowngradeRead, Downgrade);\n-        rwlock_kill_helper(DowngradeRead, Downgrade);\n-        rwlock_kill_helper(Downgrade, DowngradeRead);\n-        rwlock_kill_helper(Downgrade, DowngradeRead);\n-    }\n-}"}, {"sha": "a4f8b1df6af527a188db0e848c9886fca164e4ec", "filename": "src/libstd/sync/rwlock.rs", "status": "added", "additions": 514, "deletions": 0, "changes": 514, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Frwlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Frwlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Frwlock.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,514 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use prelude::*;\n+\n+use kinds::marker;\n+use cell::UnsafeCell;\n+use sys_common::rwlock as sys;\n+use sync::poison;\n+\n+/// A reader-writer lock\n+///\n+/// This type of lock allows a number of readers or at most one writer at any\n+/// point in time. The write portion of this lock typically allows modification\n+/// of the underlying data (exclusive access) and the read portion of this lock\n+/// typically allows for read-only access (shared access).\n+///\n+/// The type parameter `T` represents the data that this lock protects. It is\n+/// required that `T` satisfies `Send` to be shared across tasks and `Sync` to\n+/// allow concurrent access through readers. The RAII guards returned from the\n+/// locking methods implement `Deref` (and `DerefMut` for the `write` methods)\n+/// to allow access to the contained of the lock.\n+///\n+/// RWLocks, like Mutexes, will become poisoned on panics. Note, however, that\n+/// an RWLock may only be poisoned if a panic occurs while it is locked\n+/// exclusively (write mode). If a panic occurs in any reader, then the lock\n+/// will not be poisoned.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::sync::RWLock;\n+///\n+/// let lock = RWLock::new(5i);\n+///\n+/// // many reader locks can be held at once\n+/// {\n+///     let r1 = lock.read();\n+///     let r2 = lock.read();\n+///     assert_eq!(*r1, 5);\n+///     assert_eq!(*r2, 5);\n+/// } // read locks are dropped at this point\n+///\n+/// // only one write lock may be held, however\n+/// {\n+///     let mut w = lock.write();\n+///     *w += 1;\n+///     assert_eq!(*w, 6);\n+/// } // write lock is dropped here\n+/// ```\n+pub struct RWLock<T> {\n+    inner: Box<StaticRWLock>,\n+    data: UnsafeCell<T>,\n+}\n+\n+/// Structure representing a staticaly allocated RWLock.\n+///\n+/// This structure is intended to be used inside of a `static` and will provide\n+/// automatic global access as well as lazy initialization. The internal\n+/// resources of this RWLock, however, must be manually deallocated.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::sync::{StaticRWLock, RWLOCK_INIT};\n+///\n+/// static LOCK: StaticRWLock = RWLOCK_INIT;\n+///\n+/// {\n+///     let _g = LOCK.read();\n+///     // ... shared read access\n+/// }\n+/// {\n+///     let _g = LOCK.write();\n+///     // ... exclusive write access\n+/// }\n+/// unsafe { LOCK.destroy() } // free all resources\n+/// ```\n+pub struct StaticRWLock {\n+    inner: sys::RWLock,\n+    poison: UnsafeCell<poison::Flag>,\n+}\n+\n+/// Constant initialization for a statically-initialized rwlock.\n+pub const RWLOCK_INIT: StaticRWLock = StaticRWLock {\n+    inner: sys::RWLOCK_INIT,\n+    poison: UnsafeCell { value: poison::Flag { failed: false } },\n+};\n+\n+/// RAII structure used to release the shared read access of a lock when\n+/// dropped.\n+#[must_use]\n+pub struct RWLockReadGuard<'a, T: 'a> {\n+    __lock: &'a RWLock<T>,\n+    __guard: StaticRWLockReadGuard,\n+}\n+\n+/// RAII structure used to release the exclusive write access of a lock when\n+/// dropped.\n+#[must_use]\n+pub struct RWLockWriteGuard<'a, T: 'a> {\n+    __lock: &'a RWLock<T>,\n+    __guard: StaticRWLockWriteGuard,\n+}\n+\n+/// RAII structure used to release the shared read access of a lock when\n+/// dropped.\n+#[must_use]\n+pub struct StaticRWLockReadGuard {\n+    lock: &'static sys::RWLock,\n+    marker: marker::NoSend,\n+}\n+\n+/// RAII structure used to release the exclusive write access of a lock when\n+/// dropped.\n+#[must_use]\n+pub struct StaticRWLockWriteGuard {\n+    lock: &'static sys::RWLock,\n+    marker: marker::NoSend,\n+    poison: poison::Guard<'static>,\n+}\n+\n+impl<T: Send + Sync> RWLock<T> {\n+    /// Creates a new instance of an RWLock which is unlocked and read to go.\n+    pub fn new(t: T) -> RWLock<T> {\n+        RWLock { inner: box RWLOCK_INIT, data: UnsafeCell::new(t) }\n+    }\n+\n+    /// Locks this rwlock with shared read access, blocking the current thread\n+    /// until it can be acquired.\n+    ///\n+    /// The calling thread will be blocked until there are no more writers which\n+    /// hold the lock. There may be other readers currently inside the lock when\n+    /// this method returns. This method does not provide any guarantees with\n+    /// respect to the ordering of whether contentious readers or writers will\n+    /// acquire the lock first.\n+    ///\n+    /// Returns an RAII guard which will release this thread's shared access\n+    /// once it is dropped.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function will panic if the RWLock is poisoned. An RWLock is\n+    /// poisoned whenever a writer panics while holding an exclusive lock. The\n+    /// panic will occur immediately after the lock has been acquired.\n+    #[inline]\n+    pub fn read(&self) -> RWLockReadGuard<T> {\n+        unsafe {\n+            let lock: &'static StaticRWLock = &*(&*self.inner as *const _);\n+            RWLockReadGuard::new(self, lock.read())\n+        }\n+    }\n+\n+    /// Attempt to acquire this lock with shared read access.\n+    ///\n+    /// This function will never block and will return immediately if `read`\n+    /// would otherwise succeed. Returns `Some` of an RAII guard which will\n+    /// release the shared access of this thread when dropped, or `None` if the\n+    /// access could not be granted. This method does not provide any\n+    /// guarantees with respect to the ordering of whether contentious readers\n+    /// or writers will acquire the lock first.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function will panic if the RWLock is poisoned. An RWLock is\n+    /// poisoned whenever a writer panics while holding an exclusive lock. A\n+    /// panic will only occur if the lock is acquired.\n+    #[inline]\n+    pub fn try_read(&self) -> Option<RWLockReadGuard<T>> {\n+        unsafe {\n+            let lock: &'static StaticRWLock = &*(&*self.inner as *const _);\n+            lock.try_read().map(|guard| {\n+                RWLockReadGuard::new(self, guard)\n+            })\n+        }\n+    }\n+\n+    /// Lock this rwlock with exclusive write access, blocking the current\n+    /// thread until it can be acquired.\n+    ///\n+    /// This function will not return while other writers or other readers\n+    /// currently have access to the lock.\n+    ///\n+    /// Returns an RAII guard which will drop the write access of this rwlock\n+    /// when dropped.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function will panic if the RWLock is poisoned. An RWLock is\n+    /// poisoned whenever a writer panics while holding an exclusive lock. The\n+    /// panic will occur when the lock is acquired.\n+    #[inline]\n+    pub fn write(&self) -> RWLockWriteGuard<T> {\n+        unsafe {\n+            let lock: &'static StaticRWLock = &*(&*self.inner as *const _);\n+            RWLockWriteGuard::new(self, lock.write())\n+        }\n+    }\n+\n+    /// Attempt to lock this rwlock with exclusive write access.\n+    ///\n+    /// This function does not ever block, and it will return `None` if a call\n+    /// to `write` would otherwise block. If successful, an RAII guard is\n+    /// returned.\n+    ///\n+    /// # Panics\n+    ///\n+    /// This function will panic if the RWLock is poisoned. An RWLock is\n+    /// poisoned whenever a writer panics while holding an exclusive lock. A\n+    /// panic will only occur if the lock is acquired.\n+    #[inline]\n+    pub fn try_write(&self) -> Option<RWLockWriteGuard<T>> {\n+        unsafe {\n+            let lock: &'static StaticRWLock = &*(&*self.inner as *const _);\n+            lock.try_write().map(|guard| {\n+                RWLockWriteGuard::new(self, guard)\n+            })\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<T> Drop for RWLock<T> {\n+    fn drop(&mut self) {\n+        unsafe { self.inner.inner.destroy() }\n+    }\n+}\n+\n+impl StaticRWLock {\n+    /// Locks this rwlock with shared read access, blocking the current thread\n+    /// until it can be acquired.\n+    ///\n+    /// See `RWLock::read`.\n+    #[inline]\n+    pub fn read(&'static self) -> StaticRWLockReadGuard {\n+        unsafe { self.inner.read() }\n+        StaticRWLockReadGuard::new(self)\n+    }\n+\n+    /// Attempt to acquire this lock with shared read access.\n+    ///\n+    /// See `RWLock::try_read`.\n+    #[inline]\n+    pub fn try_read(&'static self) -> Option<StaticRWLockReadGuard> {\n+        if unsafe { self.inner.try_read() } {\n+            Some(StaticRWLockReadGuard::new(self))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    /// Lock this rwlock with exclusive write access, blocking the current\n+    /// thread until it can be acquired.\n+    ///\n+    /// See `RWLock::write`.\n+    #[inline]\n+    pub fn write(&'static self) -> StaticRWLockWriteGuard {\n+        unsafe { self.inner.write() }\n+        StaticRWLockWriteGuard::new(self)\n+    }\n+\n+    /// Attempt to lock this rwlock with exclusive write access.\n+    ///\n+    /// See `RWLock::try_write`.\n+    #[inline]\n+    pub fn try_write(&'static self) -> Option<StaticRWLockWriteGuard> {\n+        if unsafe { self.inner.try_write() } {\n+            Some(StaticRWLockWriteGuard::new(self))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    /// Deallocate all resources associated with this static lock.\n+    ///\n+    /// This method is unsafe to call as there is no guarantee that there are no\n+    /// active users of the lock, and this also doesn't prevent any future users\n+    /// of this lock. This method is required to be called to not leak memory on\n+    /// all platforms.\n+    pub unsafe fn destroy(&'static self) {\n+        self.inner.destroy()\n+    }\n+}\n+\n+impl<'rwlock, T> RWLockReadGuard<'rwlock, T> {\n+    fn new(lock: &RWLock<T>, guard: StaticRWLockReadGuard)\n+           -> RWLockReadGuard<T> {\n+        RWLockReadGuard { __lock: lock, __guard: guard }\n+    }\n+}\n+impl<'rwlock, T> RWLockWriteGuard<'rwlock, T> {\n+    fn new(lock: &RWLock<T>, guard: StaticRWLockWriteGuard)\n+           -> RWLockWriteGuard<T> {\n+        RWLockWriteGuard { __lock: lock, __guard: guard }\n+    }\n+}\n+\n+impl<'rwlock, T> Deref<T> for RWLockReadGuard<'rwlock, T> {\n+    fn deref(&self) -> &T { unsafe { &*self.__lock.data.get() } }\n+}\n+impl<'rwlock, T> Deref<T> for RWLockWriteGuard<'rwlock, T> {\n+    fn deref(&self) -> &T { unsafe { &*self.__lock.data.get() } }\n+}\n+impl<'rwlock, T> DerefMut<T> for RWLockWriteGuard<'rwlock, T> {\n+    fn deref_mut(&mut self) -> &mut T { unsafe { &mut *self.__lock.data.get() } }\n+}\n+\n+impl StaticRWLockReadGuard {\n+    fn new(lock: &'static StaticRWLock) -> StaticRWLockReadGuard {\n+        let guard = StaticRWLockReadGuard {\n+            lock: &lock.inner,\n+            marker: marker::NoSend,\n+        };\n+        unsafe { (*lock.poison.get()).borrow().check(\"rwlock\"); }\n+        return guard;\n+    }\n+}\n+impl StaticRWLockWriteGuard {\n+    fn new(lock: &'static StaticRWLock) -> StaticRWLockWriteGuard {\n+        unsafe {\n+            let guard = StaticRWLockWriteGuard {\n+                lock: &lock.inner,\n+                marker: marker::NoSend,\n+                poison: (*lock.poison.get()).borrow(),\n+            };\n+            guard.poison.check(\"rwlock\");\n+            return guard;\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl Drop for StaticRWLockReadGuard {\n+    fn drop(&mut self) {\n+        unsafe { self.lock.read_unlock(); }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl Drop for StaticRWLockWriteGuard {\n+    fn drop(&mut self) {\n+        self.poison.done();\n+        unsafe { self.lock.write_unlock(); }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use prelude::*;\n+\n+    use rand::{mod, Rng};\n+    use task;\n+    use sync::{Arc, RWLock, StaticRWLock, RWLOCK_INIT};\n+\n+    #[test]\n+    fn smoke() {\n+        let l = RWLock::new(());\n+        drop(l.read());\n+        drop(l.write());\n+        drop((l.read(), l.read()));\n+        drop(l.write());\n+    }\n+\n+    #[test]\n+    fn static_smoke() {\n+        static R: StaticRWLock = RWLOCK_INIT;\n+        drop(R.read());\n+        drop(R.write());\n+        drop((R.read(), R.read()));\n+        drop(R.write());\n+        unsafe { R.destroy(); }\n+    }\n+\n+    #[test]\n+    fn frob() {\n+        static R: StaticRWLock = RWLOCK_INIT;\n+        static N: uint = 10;\n+        static M: uint = 1000;\n+\n+        let (tx, rx) = channel::<()>();\n+        for _ in range(0, N) {\n+            let tx = tx.clone();\n+            spawn(proc() {\n+                let mut rng = rand::task_rng();\n+                for _ in range(0, M) {\n+                    if rng.gen_weighted_bool(N) {\n+                        drop(R.write());\n+                    } else {\n+                        drop(R.read());\n+                    }\n+                }\n+                drop(tx);\n+            });\n+        }\n+        drop(tx);\n+        let _ = rx.recv_opt();\n+        unsafe { R.destroy(); }\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_rw_arc_poison_wr() {\n+        let arc = Arc::new(RWLock::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try(proc() {\n+            let lock = arc2.write();\n+            assert_eq!(*lock, 2);\n+        });\n+        let lock = arc.read();\n+        assert_eq!(*lock, 1);\n+    }\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_rw_arc_poison_ww() {\n+        let arc = Arc::new(RWLock::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try(proc() {\n+            let lock = arc2.write();\n+            assert_eq!(*lock, 2);\n+        });\n+        let lock = arc.write();\n+        assert_eq!(*lock, 1);\n+    }\n+\n+    #[test]\n+    fn test_rw_arc_no_poison_rr() {\n+        let arc = Arc::new(RWLock::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try(proc() {\n+            let lock = arc2.read();\n+            assert_eq!(*lock, 2);\n+        });\n+        let lock = arc.read();\n+        assert_eq!(*lock, 1);\n+    }\n+    #[test]\n+    fn test_rw_arc_no_poison_rw() {\n+        let arc = Arc::new(RWLock::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try(proc() {\n+            let lock = arc2.read();\n+            assert_eq!(*lock, 2);\n+        });\n+        let lock = arc.write();\n+        assert_eq!(*lock, 1);\n+    }\n+\n+    #[test]\n+    fn test_rw_arc() {\n+        let arc = Arc::new(RWLock::new(0i));\n+        let arc2 = arc.clone();\n+        let (tx, rx) = channel();\n+\n+        task::spawn(proc() {\n+            let mut lock = arc2.write();\n+            for _ in range(0u, 10) {\n+                let tmp = *lock;\n+                *lock = -1;\n+                task::deschedule();\n+                *lock = tmp + 1;\n+            }\n+            tx.send(());\n+        });\n+\n+        // Readers try to catch the writer in the act\n+        let mut children = Vec::new();\n+        for _ in range(0u, 5) {\n+            let arc3 = arc.clone();\n+            children.push(task::try_future(proc() {\n+                let lock = arc3.read();\n+                assert!(*lock >= 0);\n+            }));\n+        }\n+\n+        // Wait for children to pass their asserts\n+        for r in children.iter_mut() {\n+            assert!(r.get_ref().is_ok());\n+        }\n+\n+        // Wait for writer to finish\n+        rx.recv();\n+        let lock = arc.read();\n+        assert_eq!(*lock, 10);\n+    }\n+\n+    #[test]\n+    fn test_rw_arc_access_in_unwind() {\n+        let arc = Arc::new(RWLock::new(1i));\n+        let arc2 = arc.clone();\n+        let _ = task::try::<()>(proc() {\n+            struct Unwinder {\n+                i: Arc<RWLock<int>>,\n+            }\n+            impl Drop for Unwinder {\n+                fn drop(&mut self) {\n+                    let mut lock = self.i.write();\n+                    *lock += 1;\n+                }\n+            }\n+            let _u = Unwinder { i: arc2 };\n+            panic!();\n+        });\n+        let lock = arc.read();\n+        assert_eq!(*lock, 2);\n+    }\n+}"}, {"sha": "03fb84c38d470889ee04909afb8e758f38c3869b", "filename": "src/libstd/sync/semaphore.rs", "status": "added", "additions": 195, "deletions": 0, "changes": 195, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fsemaphore.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsync%2Fsemaphore.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fsemaphore.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,195 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use ops::Drop;\n+use sync::{Mutex, Condvar};\n+\n+/// A counting, blocking, semaphore.\n+///\n+/// Semaphores are a form of atomic counter where access is only granted if the\n+/// counter is a positive value. Each acquisition will block the calling thread\n+/// until the counter is positive, and each release will increment the counter\n+/// and unblock any threads if necessary.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::sync::Semaphore;\n+///\n+/// // Create a semaphore that represents 5 resources\n+/// let sem = Semaphore::new(5);\n+///\n+/// // Acquire one of the resources\n+/// sem.acquire();\n+///\n+/// // Acquire one of the resources for a limited period of time\n+/// {\n+///     let _guard = sem.access();\n+///     // ...\n+/// } // resources is released here\n+///\n+/// // Release our initially acquired resource\n+/// sem.release();\n+/// ```\n+pub struct Semaphore {\n+    lock: Mutex<int>,\n+    cvar: Condvar,\n+}\n+\n+/// An RAII guard which will release a resource acquired from a semaphore when\n+/// dropped.\n+pub struct SemaphoreGuard<'a> {\n+    sem: &'a Semaphore,\n+}\n+\n+impl Semaphore {\n+    /// Creates a new semaphore with the initial count specified.\n+    ///\n+    /// The count specified can be thought of as a number of resources, and a\n+    /// call to `acquire` or `access` will block until at least one resource is\n+    /// available. It is valid to initialize a semaphore with a negative count.\n+    pub fn new(count: int) -> Semaphore {\n+        Semaphore {\n+            lock: Mutex::new(count),\n+            cvar: Condvar::new(),\n+        }\n+    }\n+\n+    /// Acquires a resource of this semaphore, blocking the current thread until\n+    /// it can do so.\n+    ///\n+    /// This method will block until the internal count of the semaphore is at\n+    /// least 1.\n+    pub fn acquire(&self) {\n+        let mut count = self.lock.lock();\n+        while *count <= 0 {\n+            self.cvar.wait(&count);\n+        }\n+        *count -= 1;\n+    }\n+\n+    /// Release a resource from this semaphore.\n+    ///\n+    /// This will increment the number of resources in this semaphore by 1 and\n+    /// will notify any pending waiters in `acquire` or `access` if necessary.\n+    pub fn release(&self) {\n+        *self.lock.lock() += 1;\n+        self.cvar.notify_one();\n+    }\n+\n+    /// Acquires a resource of this semaphore, returning an RAII guard to\n+    /// release the semaphore when dropped.\n+    ///\n+    /// This function is semantically equivalent to an `acquire` followed by a\n+    /// `release` when the guard returned is dropped.\n+    pub fn access(&self) -> SemaphoreGuard {\n+        self.acquire();\n+        SemaphoreGuard { sem: self }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<'a> Drop for SemaphoreGuard<'a> {\n+    fn drop(&mut self) {\n+        self.sem.release();\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use prelude::*;\n+\n+    use sync::Arc;\n+    use super::Semaphore;\n+\n+    #[test]\n+    fn test_sem_acquire_release() {\n+        let s = Semaphore::new(1);\n+        s.acquire();\n+        s.release();\n+        s.acquire();\n+    }\n+\n+    #[test]\n+    fn test_sem_basic() {\n+        let s = Semaphore::new(1);\n+        let _g = s.access();\n+    }\n+\n+    #[test]\n+    fn test_sem_as_mutex() {\n+        let s = Arc::new(Semaphore::new(1));\n+        let s2 = s.clone();\n+        spawn(proc() {\n+            let _g = s2.access();\n+        });\n+        let _g = s.access();\n+    }\n+\n+    #[test]\n+    fn test_sem_as_cvar() {\n+        /* Child waits and parent signals */\n+        let (tx, rx) = channel();\n+        let s = Arc::new(Semaphore::new(0));\n+        let s2 = s.clone();\n+        spawn(proc() {\n+            s2.acquire();\n+            tx.send(());\n+        });\n+        s.release();\n+        let _ = rx.recv();\n+\n+        /* Parent waits and child signals */\n+        let (tx, rx) = channel();\n+        let s = Arc::new(Semaphore::new(0));\n+        let s2 = s.clone();\n+        spawn(proc() {\n+            s2.release();\n+            let _ = rx.recv();\n+        });\n+        s.acquire();\n+        tx.send(());\n+    }\n+\n+    #[test]\n+    fn test_sem_multi_resource() {\n+        // Parent and child both get in the critical section at the same\n+        // time, and shake hands.\n+        let s = Arc::new(Semaphore::new(2));\n+        let s2 = s.clone();\n+        let (tx1, rx1) = channel();\n+        let (tx2, rx2) = channel();\n+        spawn(proc() {\n+            let _g = s2.access();\n+            let _ = rx2.recv();\n+            tx1.send(());\n+        });\n+        let _g = s.access();\n+        tx2.send(());\n+        let _ = rx1.recv();\n+    }\n+\n+    #[test]\n+    fn test_sem_runtime_friendly_blocking() {\n+        let s = Arc::new(Semaphore::new(1));\n+        let s2 = s.clone();\n+        let (tx, rx) = channel();\n+        {\n+            let _g = s.access();\n+            spawn(proc() {\n+                tx.send(());\n+                drop(s2.access());\n+                tx.send(());\n+            });\n+            rx.recv(); // wait for child to come alive\n+        }\n+        rx.recv(); // wait for child to be done\n+    }\n+}"}, {"sha": "e09d970402966451d3a83f0330b79765072ccd10", "filename": "src/libstd/sys/common/condvar.rs", "status": "added", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fcondvar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fcondvar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fcondvar.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,67 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use time::Duration;\n+use sys_common::mutex::{mod, Mutex};\n+use sys::condvar as imp;\n+\n+/// An OS-based condition variable.\n+///\n+/// This structure is the lowest layer possible on top of the OS-provided\n+/// condition variables. It is consequently entirely unsafe to use. It is\n+/// recommended to use the safer types at the top level of this crate instead of\n+/// this type.\n+pub struct Condvar(imp::Condvar);\n+\n+/// Static initializer for condition variables.\n+pub const CONDVAR_INIT: Condvar = Condvar(imp::CONDVAR_INIT);\n+\n+impl Condvar {\n+    /// Creates a new condition variable for use.\n+    ///\n+    /// Behavior is undefined if the condition variable is moved after it is\n+    /// first used with any of the functions below.\n+    #[inline]\n+    pub unsafe fn new() -> Condvar { Condvar(imp::Condvar::new()) }\n+\n+    /// Signal one waiter on this condition variable to wake up.\n+    #[inline]\n+    pub unsafe fn notify_one(&self) { self.0.notify_one() }\n+\n+    /// Awaken all current waiters on this condition variable.\n+    #[inline]\n+    pub unsafe fn notify_all(&self) { self.0.notify_all() }\n+\n+    /// Wait for a signal on the specified mutex.\n+    ///\n+    /// Behavior is undefined if the mutex is not locked by the current thread.\n+    /// Behavior is also undefined if more than one mutex is used concurrently\n+    /// on this condition variable.\n+    #[inline]\n+    pub unsafe fn wait(&self, mutex: &Mutex) { self.0.wait(mutex::raw(mutex)) }\n+\n+    /// Wait for a signal on the specified mutex with a timeout duration\n+    /// specified by `dur` (a relative time into the future).\n+    ///\n+    /// Behavior is undefined if the mutex is not locked by the current thread.\n+    /// Behavior is also undefined if more than one mutex is used concurrently\n+    /// on this condition variable.\n+    #[inline]\n+    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n+        self.0.wait_timeout(mutex::raw(mutex), dur)\n+    }\n+\n+    /// Deallocate all resources associated with this condition variable.\n+    ///\n+    /// Behavior is undefined if there are current or will be future users of\n+    /// this condition variable.\n+    #[inline]\n+    pub unsafe fn destroy(&self) { self.0.destroy() }\n+}"}, {"sha": "c0018c5d970421086eb86d70ad6ef17bf7f6254c", "filename": "src/libstd/sys/common/helper_thread.rs", "status": "modified", "additions": 15, "deletions": 6, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -20,13 +20,14 @@\n //! can be created in the future and there must be no active timers at that\n //! time.\n \n+use prelude::*;\n+\n+use cell::UnsafeCell;\n use mem;\n use rustrt::bookkeeping;\n-use rustrt::mutex::StaticNativeMutex;\n use rustrt;\n-use cell::UnsafeCell;\n+use sync::{StaticMutex, StaticCondvar};\n use sys::helper_signal;\n-use prelude::*;\n \n use task;\n \n@@ -39,7 +40,8 @@ use task;\n /// is for static initialization.\n pub struct Helper<M> {\n     /// Internal lock which protects the remaining fields\n-    pub lock: StaticNativeMutex,\n+    pub lock: StaticMutex,\n+    pub cond: StaticCondvar,\n \n     // You'll notice that the remaining fields are UnsafeCell<T>, and this is\n     // because all helper thread operations are done through &self, but we need\n@@ -53,6 +55,9 @@ pub struct Helper<M> {\n \n     /// Flag if this helper thread has booted and been initialized yet.\n     pub initialized: UnsafeCell<bool>,\n+\n+    /// Flag if this helper thread has shut down\n+    pub shutdown: UnsafeCell<bool>,\n }\n \n impl<M: Send> Helper<M> {\n@@ -80,7 +85,9 @@ impl<M: Send> Helper<M> {\n                 task::spawn(proc() {\n                     bookkeeping::decrement();\n                     helper(receive, rx, t);\n-                    self.lock.lock().signal()\n+                    let _g = self.lock.lock();\n+                    *self.shutdown.get() = true;\n+                    self.cond.notify_one()\n                 });\n \n                 rustrt::at_exit(proc() { self.shutdown() });\n@@ -119,7 +126,9 @@ impl<M: Send> Helper<M> {\n             helper_signal::signal(*self.signal.get() as helper_signal::signal);\n \n             // Wait for the child to exit\n-            guard.wait();\n+            while !*self.shutdown.get() {\n+                self.cond.wait(&guard);\n+            }\n             drop(guard);\n \n             // Clean up after ourselves"}, {"sha": "f8861c20464dd50599854aaff6d30eb9578eef3c", "filename": "src/libstd/sys/common/mod.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fmod.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -19,8 +19,11 @@ use num::Int;\n use path::BytesContainer;\n use collections;\n \n-pub mod net;\n+pub mod condvar;\n pub mod helper_thread;\n+pub mod mutex;\n+pub mod net;\n+pub mod rwlock;\n pub mod thread_local;\n \n // common error constructors"}, {"sha": "117d33db32896a7b57c8b6a6fd0de03af8a43deb", "filename": "src/libstd/sys/common/mutex.rs", "status": "added", "additions": 64, "deletions": 0, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fmutex.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,64 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+pub use sys::mutex::raw;\n+\n+use sys::mutex as imp;\n+\n+/// An OS-based mutual exclusion lock.\n+///\n+/// This is the thinnest cross-platform wrapper around OS mutexes. All usage of\n+/// this mutex is unsafe and it is recommended to instead use the safe wrapper\n+/// at the top level of the crate instead of this type.\n+pub struct Mutex(imp::Mutex);\n+\n+/// Constant initializer for statically allocated mutexes.\n+pub const MUTEX_INIT: Mutex = Mutex(imp::MUTEX_INIT);\n+\n+impl Mutex {\n+    /// Creates a newly initialized mutex.\n+    ///\n+    /// Behavior is undefined if the mutex is moved after the first method is\n+    /// called on the mutex.\n+    #[inline]\n+    pub unsafe fn new() -> Mutex { Mutex(imp::Mutex::new()) }\n+\n+    /// Lock the mutex blocking the current thread until it is available.\n+    ///\n+    /// Behavior is undefined if the mutex has been moved between this and any\n+    /// previous function call.\n+    #[inline]\n+    pub unsafe fn lock(&self) { self.0.lock() }\n+\n+    /// Attempt to lock the mutex without blocking, returning whether it was\n+    /// successfully acquired or not.\n+    ///\n+    /// Behavior is undefined if the mutex has been moved between this and any\n+    /// previous function call.\n+    #[inline]\n+    pub unsafe fn try_lock(&self) -> bool { self.0.try_lock() }\n+\n+    /// Unlock the mutex.\n+    ///\n+    /// Behavior is undefined if the current thread does not actually hold the\n+    /// mutex.\n+    #[inline]\n+    pub unsafe fn unlock(&self) { self.0.unlock() }\n+\n+    /// Deallocate all resources associated with this mutex.\n+    ///\n+    /// Behavior is undefined if there are current or will be future users of\n+    /// this mutex.\n+    #[inline]\n+    pub unsafe fn destroy(&self) { self.0.destroy() }\n+}\n+\n+// not meant to be exported to the outside world, just the containing module\n+pub fn raw(mutex: &Mutex) -> &imp::Mutex { &mutex.0 }"}, {"sha": "ddc6dd021c30f7b178b2e7623e70639a6dc5b3c3", "filename": "src/libstd/sys/common/net.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -16,13 +16,13 @@ use libc::{mod, c_char, c_int};\n use mem;\n use num::Int;\n use ptr::{mod, null, null_mut};\n-use rustrt::mutex;\n use io::net::ip::{SocketAddr, IpAddr, Ipv4Addr, Ipv6Addr};\n use io::net::addrinfo;\n use io::{IoResult, IoError};\n use sys::{mod, retry, c, sock_t, last_error, last_net_error, last_gai_error, close_sock,\n           wrlen, msglen_t, os, wouldblock, set_nonblocking, timer, ms_to_timeval,\n           decode_error_detailed};\n+use sync::{Mutex, MutexGuard};\n use sys_common::{mod, keep_going, short_write, timeout};\n use prelude::*;\n use cmp;\n@@ -557,12 +557,12 @@ struct Inner {\n \n     // Unused on Linux, where this lock is not necessary.\n     #[allow(dead_code)]\n-    lock: mutex::NativeMutex\n+    lock: Mutex<()>,\n }\n \n impl Inner {\n     fn new(fd: sock_t) -> Inner {\n-        Inner { fd: fd, lock: unsafe { mutex::NativeMutex::new() } }\n+        Inner { fd: fd, lock: Mutex::new(()) }\n     }\n }\n \n@@ -572,7 +572,7 @@ impl Drop for Inner {\n \n pub struct Guard<'a> {\n     pub fd: sock_t,\n-    pub guard: mutex::LockGuard<'a>,\n+    pub guard: MutexGuard<'a, ()>,\n }\n \n #[unsafe_destructor]\n@@ -666,7 +666,7 @@ impl TcpStream {\n     fn lock_nonblocking<'a>(&'a self) -> Guard<'a> {\n         let ret = Guard {\n             fd: self.fd(),\n-            guard: unsafe { self.inner.lock.lock() },\n+            guard: self.inner.lock.lock(),\n         };\n         assert!(set_nonblocking(self.fd(), true).is_ok());\n         ret\n@@ -805,7 +805,7 @@ impl UdpSocket {\n     fn lock_nonblocking<'a>(&'a self) -> Guard<'a> {\n         let ret = Guard {\n             fd: self.fd(),\n-            guard: unsafe { self.inner.lock.lock() },\n+            guard: self.inner.lock.lock(),\n         };\n         assert!(set_nonblocking(self.fd(), true).is_ok());\n         ret"}, {"sha": "df016b9e293b7fb44e20aecd4ccdca1acd94429f", "filename": "src/libstd/sys/common/rwlock.rs", "status": "added", "additions": 86, "deletions": 0, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Frwlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fcommon%2Frwlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Frwlock.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,86 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use sys::rwlock as imp;\n+\n+/// An OS-based reader-writer lock.\n+///\n+/// This structure is entirely unsafe and serves as the lowest layer of a\n+/// cross-platform binding of system rwlocks. It is recommended to use the\n+/// safer types at the top level of this crate instead of this type.\n+pub struct RWLock(imp::RWLock);\n+\n+/// Constant initializer for static RWLocks.\n+pub const RWLOCK_INIT: RWLock = RWLock(imp::RWLOCK_INIT);\n+\n+impl RWLock {\n+    /// Creates a new instance of an RWLock.\n+    ///\n+    /// Usage of an RWLock is undefined if it is moved after its first use (any\n+    /// function calls below).\n+    #[inline]\n+    pub unsafe fn new() -> RWLock { RWLock(imp::RWLock::new()) }\n+\n+    /// Acquire shared access to the underlying lock, blocking the current\n+    /// thread to do so.\n+    ///\n+    /// Behavior is undefined if the rwlock has been moved between this and any\n+    /// previous methodo call.\n+    #[inline]\n+    pub unsafe fn read(&self) { self.0.read() }\n+\n+    /// Attempt to acquire shared access to this lock, returning whether it\n+    /// succeeded or not.\n+    ///\n+    /// This function does not block the current thread.\n+    ///\n+    /// Behavior is undefined if the rwlock has been moved between this and any\n+    /// previous methodo call.\n+    #[inline]\n+    pub unsafe fn try_read(&self) -> bool { self.0.try_read() }\n+\n+    /// Acquire write access to the underlying lock, blocking the current thread\n+    /// to do so.\n+    ///\n+    /// Behavior is undefined if the rwlock has been moved between this and any\n+    /// previous methodo call.\n+    #[inline]\n+    pub unsafe fn write(&self) { self.0.write() }\n+\n+    /// Attempt to acquire exclusive access to this lock, returning whether it\n+    /// succeeded or not.\n+    ///\n+    /// This function does not block the current thread.\n+    ///\n+    /// Behavior is undefined if the rwlock has been moved between this and any\n+    /// previous methodo call.\n+    #[inline]\n+    pub unsafe fn try_write(&self) -> bool { self.0.try_write() }\n+\n+    /// Unlock previously acquired shared access to this lock.\n+    ///\n+    /// Behavior is undefined if the current thread does not have shared access.\n+    #[inline]\n+    pub unsafe fn read_unlock(&self) { self.0.read_unlock() }\n+\n+    /// Unlock previously acquired exclusive access to this lock.\n+    ///\n+    /// Behavior is undefined if the current thread does not currently have\n+    /// exclusive access.\n+    #[inline]\n+    pub unsafe fn write_unlock(&self) { self.0.write_unlock() }\n+\n+    /// Destroy OS-related resources with this RWLock.\n+    ///\n+    /// Behavior is undefined if there are any currently active users of this\n+    /// lock.\n+    #[inline]\n+    pub unsafe fn destroy(&self) { self.0.destroy() }\n+}"}, {"sha": "f64718539ef0c92812b4504c9dcf08ae2e727388", "filename": "src/libstd/sys/unix/condvar.rs", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fcondvar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fcondvar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fcondvar.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,83 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cell::UnsafeCell;\n+use libc;\n+use sys::mutex::{mod, Mutex};\n+use sys::sync as ffi;\n+use time::Duration;\n+\n+pub struct Condvar { inner: UnsafeCell<ffi::pthread_cond_t> }\n+\n+pub const CONDVAR_INIT: Condvar = Condvar {\n+    inner: UnsafeCell { value: ffi::PTHREAD_COND_INITIALIZER },\n+};\n+\n+impl Condvar {\n+    #[inline]\n+    pub unsafe fn new() -> Condvar {\n+        // Might be moved and address is changing it is better to avoid\n+        // initialization of potentially opaque OS data before it landed\n+        Condvar { inner: UnsafeCell::new(ffi::PTHREAD_COND_INITIALIZER) }\n+    }\n+\n+    #[inline]\n+    pub unsafe fn notify_one(&self) {\n+        let r = ffi::pthread_cond_signal(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+\n+    #[inline]\n+    pub unsafe fn notify_all(&self) {\n+        let r = ffi::pthread_cond_broadcast(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+\n+    #[inline]\n+    pub unsafe fn wait(&self, mutex: &Mutex) {\n+        let r = ffi::pthread_cond_wait(self.inner.get(), mutex::raw(mutex));\n+        debug_assert_eq!(r, 0);\n+    }\n+\n+    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n+        assert!(dur >= Duration::nanoseconds(0));\n+\n+        // First, figure out what time it currently is\n+        let mut tv = libc::timeval { tv_sec: 0, tv_usec: 0 };\n+        let r = ffi::gettimeofday(&mut tv, 0 as *mut _);\n+        debug_assert_eq!(r, 0);\n+\n+        // Offset that time with the specified duration\n+        let abs = Duration::seconds(tv.tv_sec as i64) +\n+                  Duration::microseconds(tv.tv_usec as i64) +\n+                  dur;\n+        let ns = abs.num_nanoseconds().unwrap() as u64;\n+        let timeout = libc::timespec {\n+            tv_sec: (ns / 1000000000) as libc::time_t,\n+            tv_nsec: (ns % 1000000000) as libc::c_long,\n+        };\n+\n+        // And wait!\n+        let r = ffi::pthread_cond_timedwait(self.inner.get(), mutex::raw(mutex),\n+                                            &timeout);\n+        if r != 0 {\n+            debug_assert_eq!(r as int, libc::ETIMEDOUT as int);\n+            false\n+        } else {\n+            true\n+        }\n+    }\n+\n+    #[inline]\n+    pub unsafe fn destroy(&self) {\n+        let r = ffi::pthread_cond_destroy(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+}"}, {"sha": "4effedbe3abd83635f0107bc2988572d74b25ee4", "filename": "src/libstd/sys/unix/mod.rs", "status": "modified", "additions": 8, "deletions": 2, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fmod.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -25,23 +25,29 @@ use sys_common::mkerr_libc;\n \n macro_rules! helper_init( (static $name:ident: Helper<$m:ty>) => (\n     static $name: Helper<$m> = Helper {\n-        lock: ::rustrt::mutex::NATIVE_MUTEX_INIT,\n+        lock: ::sync::MUTEX_INIT,\n+        cond: ::sync::CONDVAR_INIT,\n         chan: ::cell::UnsafeCell { value: 0 as *mut Sender<$m> },\n         signal: ::cell::UnsafeCell { value: 0 },\n         initialized: ::cell::UnsafeCell { value: false },\n+        shutdown: ::cell::UnsafeCell { value: false },\n     };\n ) )\n \n pub mod c;\n pub mod ext;\n+pub mod condvar;\n pub mod fs;\n pub mod helper_signal;\n+pub mod mutex;\n pub mod os;\n pub mod pipe;\n pub mod process;\n+pub mod rwlock;\n+pub mod sync;\n pub mod tcp;\n-pub mod timer;\n pub mod thread_local;\n+pub mod timer;\n pub mod tty;\n pub mod udp;\n "}, {"sha": "2f01c53cb2cf51114323f171a6f7f4af69df009f", "filename": "src/libstd/sys/unix/mutex.rs", "status": "added", "additions": 52, "deletions": 0, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fmutex.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,52 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cell::UnsafeCell;\n+use sys::sync as ffi;\n+use sys_common::mutex;\n+\n+pub struct Mutex { inner: UnsafeCell<ffi::pthread_mutex_t> }\n+\n+#[inline]\n+pub unsafe fn raw(m: &Mutex) -> *mut ffi::pthread_mutex_t {\n+    m.inner.get()\n+}\n+\n+pub const MUTEX_INIT: Mutex = Mutex {\n+    inner: UnsafeCell { value: ffi::PTHREAD_MUTEX_INITIALIZER },\n+};\n+\n+impl Mutex {\n+    #[inline]\n+    pub unsafe fn new() -> Mutex {\n+        // Might be moved and address is changing it is better to avoid\n+        // initialization of potentially opaque OS data before it landed\n+        MUTEX_INIT\n+    }\n+    #[inline]\n+    pub unsafe fn lock(&self) {\n+        let r = ffi::pthread_mutex_lock(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+    #[inline]\n+    pub unsafe fn unlock(&self) {\n+        let r = ffi::pthread_mutex_unlock(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+    #[inline]\n+    pub unsafe fn try_lock(&self) -> bool {\n+        ffi::pthread_mutex_trylock(self.inner.get()) == 0\n+    }\n+    #[inline]\n+    pub unsafe fn destroy(&self) {\n+        let r = ffi::pthread_mutex_destroy(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+}"}, {"sha": "08e6f7059d8c678c4d843f2faa1a3af3366b6ea0", "filename": "src/libstd/sys/unix/pipe.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -12,8 +12,7 @@ use alloc::arc::Arc;\n use libc;\n use c_str::CString;\n use mem;\n-use rustrt::mutex;\n-use sync::atomic;\n+use sync::{atomic, Mutex};\n use io::{mod, IoResult, IoError};\n use prelude::*;\n \n@@ -60,12 +59,12 @@ struct Inner {\n \n     // Unused on Linux, where this lock is not necessary.\n     #[allow(dead_code)]\n-    lock: mutex::NativeMutex\n+    lock: Mutex<()>,\n }\n \n impl Inner {\n     fn new(fd: fd_t) -> Inner {\n-        Inner { fd: fd, lock: unsafe { mutex::NativeMutex::new() } }\n+        Inner { fd: fd, lock: Mutex::new(()) }\n     }\n }\n "}, {"sha": "0d63ff14ff26b892a3e0f346598dd60f2cd81b61", "filename": "src/libstd/sys/unix/rwlock.rs", "status": "added", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Frwlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Frwlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Frwlock.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,57 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cell::UnsafeCell;\n+use sys::sync as ffi;\n+\n+pub struct RWLock { inner: UnsafeCell<ffi::pthread_rwlock_t> }\n+\n+pub const RWLOCK_INIT: RWLock = RWLock {\n+    inner: UnsafeCell { value: ffi::PTHREAD_RWLOCK_INITIALIZER },\n+};\n+\n+impl RWLock {\n+    #[inline]\n+    pub unsafe fn new() -> RWLock {\n+        // Might be moved and address is changing it is better to avoid\n+        // initialization of potentially opaque OS data before it landed\n+        RWLOCK_INIT\n+    }\n+    #[inline]\n+    pub unsafe fn read(&self) {\n+        let r = ffi::pthread_rwlock_rdlock(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+    #[inline]\n+    pub unsafe fn try_read(&self) -> bool {\n+        ffi::pthread_rwlock_tryrdlock(self.inner.get()) == 0\n+    }\n+    #[inline]\n+    pub unsafe fn write(&self) {\n+        let r = ffi::pthread_rwlock_wrlock(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+    #[inline]\n+    pub unsafe fn try_write(&self) -> bool {\n+        ffi::pthread_rwlock_trywrlock(self.inner.get()) == 0\n+    }\n+    #[inline]\n+    pub unsafe fn read_unlock(&self) {\n+        let r = ffi::pthread_rwlock_unlock(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+    #[inline]\n+    pub unsafe fn write_unlock(&self) { self.read_unlock() }\n+    #[inline]\n+    pub unsafe fn destroy(&self) {\n+        let r = ffi::pthread_rwlock_destroy(self.inner.get());\n+        debug_assert_eq!(r, 0);\n+    }\n+}"}, {"sha": "007826b4b9d58b3f6f40515e1c3b9a26f6387440", "filename": "src/libstd/sys/unix/sync.rs", "status": "added", "additions": 208, "deletions": 0, "changes": 208, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Funix%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fsync.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,208 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![allow(bad_style)]\n+\n+use libc;\n+\n+pub use self::os::{PTHREAD_MUTEX_INITIALIZER, pthread_mutex_t};\n+pub use self::os::{PTHREAD_COND_INITIALIZER, pthread_cond_t};\n+pub use self::os::{PTHREAD_RWLOCK_INITIALIZER, pthread_rwlock_t};\n+\n+extern {\n+    // mutexes\n+    pub fn pthread_mutex_destroy(lock: *mut pthread_mutex_t) -> libc::c_int;\n+    pub fn pthread_mutex_lock(lock: *mut pthread_mutex_t) -> libc::c_int;\n+    pub fn pthread_mutex_trylock(lock: *mut pthread_mutex_t) -> libc::c_int;\n+    pub fn pthread_mutex_unlock(lock: *mut pthread_mutex_t) -> libc::c_int;\n+\n+    // cvars\n+    pub fn pthread_cond_wait(cond: *mut pthread_cond_t,\n+                             lock: *mut pthread_mutex_t) -> libc::c_int;\n+    pub fn pthread_cond_timedwait(cond: *mut pthread_cond_t,\n+                              lock: *mut pthread_mutex_t,\n+                              abstime: *const libc::timespec) -> libc::c_int;\n+    pub fn pthread_cond_signal(cond: *mut pthread_cond_t) -> libc::c_int;\n+    pub fn pthread_cond_broadcast(cond: *mut pthread_cond_t) -> libc::c_int;\n+    pub fn pthread_cond_destroy(cond: *mut pthread_cond_t) -> libc::c_int;\n+    pub fn gettimeofday(tp: *mut libc::timeval,\n+                        tz: *mut libc::c_void) -> libc::c_int;\n+\n+    // rwlocks\n+    pub fn pthread_rwlock_destroy(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+    pub fn pthread_rwlock_rdlock(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+    pub fn pthread_rwlock_tryrdlock(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+    pub fn pthread_rwlock_wrlock(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+    pub fn pthread_rwlock_trywrlock(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+    pub fn pthread_rwlock_unlock(lock: *mut pthread_rwlock_t) -> libc::c_int;\n+}\n+\n+#[cfg(any(target_os = \"freebsd\", target_os = \"dragonfly\"))]\n+mod os {\n+    use libc;\n+\n+    pub type pthread_mutex_t = *mut libc::c_void;\n+    pub type pthread_cond_t = *mut libc::c_void;\n+    pub type pthread_rwlock_t = *mut libc::c_void;\n+\n+    pub const PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = 0 as *mut _;\n+    pub const PTHREAD_COND_INITIALIZER: pthread_cond_t = 0 as *mut _;\n+    pub const PTHREAD_RWLOCK_INITIALIZER: pthread_rwlock_t = 0 as *mut _;\n+}\n+\n+#[cfg(any(target_os = \"macos\", target_os = \"ios\"))]\n+mod os {\n+    use libc;\n+\n+    #[cfg(target_arch = \"x86_64\")]\n+    const __PTHREAD_MUTEX_SIZE__: uint = 56;\n+    #[cfg(any(target_arch = \"x86\",\n+              target_arch = \"arm\"))]\n+    const __PTHREAD_MUTEX_SIZE__: uint = 40;\n+\n+    #[cfg(target_arch = \"x86_64\")]\n+    const __PTHREAD_COND_SIZE__: uint = 40;\n+    #[cfg(any(target_arch = \"x86\",\n+              target_arch = \"arm\"))]\n+    const __PTHREAD_COND_SIZE__: uint = 24;\n+\n+    #[cfg(target_arch = \"x86_64\")]\n+    const __PTHREAD_RWLOCK_SIZE__: uint = 192;\n+    #[cfg(any(target_arch = \"x86\",\n+              target_arch = \"arm\"))]\n+    const __PTHREAD_RWLOCK_SIZE__: uint = 124;\n+\n+    const _PTHREAD_MUTEX_SIG_INIT: libc::c_long = 0x32AAABA7;\n+    const _PTHREAD_COND_SIG_INIT: libc::c_long = 0x3CB0B1BB;\n+    const _PTHREAD_RWLOCK_SIG_INIT: libc::c_long = 0x2DA8B3B4;\n+\n+    #[repr(C)]\n+    pub struct pthread_mutex_t {\n+        __sig: libc::c_long,\n+        __opaque: [u8, ..__PTHREAD_MUTEX_SIZE__],\n+    }\n+    #[repr(C)]\n+    pub struct pthread_cond_t {\n+        __sig: libc::c_long,\n+        __opaque: [u8, ..__PTHREAD_COND_SIZE__],\n+    }\n+    #[repr(C)]\n+    pub struct pthread_rwlock_t {\n+        __sig: libc::c_long,\n+        __opaque: [u8, ..__PTHREAD_RWLOCK_SIZE__],\n+    }\n+\n+    pub const PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+        __sig: _PTHREAD_MUTEX_SIG_INIT,\n+        __opaque: [0, ..__PTHREAD_MUTEX_SIZE__],\n+    };\n+    pub const PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+        __sig: _PTHREAD_COND_SIG_INIT,\n+        __opaque: [0, ..__PTHREAD_COND_SIZE__],\n+    };\n+    pub const PTHREAD_RWLOCK_INITIALIZER: pthread_rwlock_t = pthread_rwlock_t {\n+        __sig: _PTHREAD_RWLOCK_SIG_INIT,\n+        __opaque: [0, ..__PTHREAD_RWLOCK_SIZE__],\n+    };\n+}\n+\n+#[cfg(target_os = \"linux\")]\n+mod os {\n+    use libc;\n+\n+    // minus 8 because we have an 'align' field\n+    #[cfg(target_arch = \"x86_64\")]\n+    const __SIZEOF_PTHREAD_MUTEX_T: uint = 40 - 8;\n+    #[cfg(any(target_arch = \"x86\",\n+              target_arch = \"arm\",\n+              target_arch = \"mips\",\n+              target_arch = \"mipsel\"))]\n+    const __SIZEOF_PTHREAD_MUTEX_T: uint = 24 - 8;\n+\n+    #[cfg(any(target_arch = \"x86_64\",\n+              target_arch = \"x86\",\n+              target_arch = \"arm\",\n+              target_arch = \"mips\",\n+              target_arch = \"mipsel\"))]\n+    const __SIZEOF_PTHREAD_COND_T: uint = 48 - 8;\n+\n+    #[cfg(target_arch = \"x86_64\")]\n+    const __SIZEOF_PTHREAD_RWLOCK_T: uint = 56 - 8;\n+\n+    #[cfg(any(target_arch = \"x86\",\n+              target_arch = \"arm\",\n+              target_arch = \"mips\",\n+              target_arch = \"mipsel\"))]\n+    const __SIZEOF_PTHREAD_RWLOCK_T: uint = 32 - 8;\n+\n+    #[repr(C)]\n+    pub struct pthread_mutex_t {\n+        __align: libc::c_longlong,\n+        size: [u8, ..__SIZEOF_PTHREAD_MUTEX_T],\n+    }\n+    #[repr(C)]\n+    pub struct pthread_cond_t {\n+        __align: libc::c_longlong,\n+        size: [u8, ..__SIZEOF_PTHREAD_COND_T],\n+    }\n+    #[repr(C)]\n+    pub struct pthread_rwlock_t {\n+        __align: libc::c_longlong,\n+        size: [u8, ..__SIZEOF_PTHREAD_RWLOCK_T],\n+    }\n+\n+    pub const PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+        __align: 0,\n+        size: [0, ..__SIZEOF_PTHREAD_MUTEX_T],\n+    };\n+    pub const PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+        __align: 0,\n+        size: [0, ..__SIZEOF_PTHREAD_COND_T],\n+    };\n+    pub const PTHREAD_RWLOCK_INITIALIZER: pthread_rwlock_t = pthread_rwlock_t {\n+        __align: 0,\n+        size: [0, ..__SIZEOF_PTHREAD_RWLOCK_T],\n+    };\n+}\n+#[cfg(target_os = \"android\")]\n+mod os {\n+    use libc;\n+\n+    #[repr(C)]\n+    pub struct pthread_mutex_t { value: libc::c_int }\n+    #[repr(C)]\n+    pub struct pthread_cond_t { value: libc::c_int }\n+    #[repr(C)]\n+    pub struct pthread_rwlock_t {\n+        lock: pthread_mutex_t,\n+        cond: pthread_cond_t,\n+        numLocks: libc::c_int,\n+        writerThreadId: libc::c_int,\n+        pendingReaders: libc::c_int,\n+        pendingWriters: libc::c_int,\n+        reserved: [*mut libc::c_void, ..4],\n+    }\n+\n+    pub const PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = pthread_mutex_t {\n+        value: 0,\n+    };\n+    pub const PTHREAD_COND_INITIALIZER: pthread_cond_t = pthread_cond_t {\n+        value: 0,\n+    };\n+    pub const PTHREAD_RWLOCK_INITIALIZER: pthread_rwlock_t = pthread_rwlock_t {\n+        lock: PTHREAD_MUTEX_INITIALIZER,\n+        cond: PTHREAD_COND_INITIALIZER,\n+        numLocks: 0,\n+        writerThreadId: 0,\n+        pendingReaders: 0,\n+        pendingWriters: 0,\n+        reserved: [0 as *mut _, ..4],\n+    };\n+}"}, {"sha": "3cabf3a63194cceee3f107bf0e2c76150568ea8e", "filename": "src/libstd/sys/windows/condvar.rs", "status": "added", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fcondvar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fcondvar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fcondvar.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,63 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cell::UnsafeCell;\n+use libc::{mod, DWORD};\n+use libc;\n+use os;\n+use sys::mutex::{mod, Mutex};\n+use sys::sync as ffi;\n+use time::Duration;\n+\n+pub struct Condvar { inner: UnsafeCell<ffi::CONDITION_VARIABLE> }\n+\n+pub const CONDVAR_INIT: Condvar = Condvar {\n+    inner: UnsafeCell { value: ffi::CONDITION_VARIABLE_INIT }\n+};\n+\n+impl Condvar {\n+    #[inline]\n+    pub unsafe fn new() -> Condvar { CONDVAR_INIT }\n+\n+    #[inline]\n+    pub unsafe fn wait(&self, mutex: &Mutex) {\n+        let r = ffi::SleepConditionVariableCS(self.inner.get(),\n+                                              mutex::raw(mutex),\n+                                              libc::INFINITE);\n+        debug_assert!(r != 0);\n+    }\n+\n+    pub unsafe fn wait_timeout(&self, mutex: &Mutex, dur: Duration) -> bool {\n+        let r = ffi::SleepConditionVariableCS(self.inner.get(),\n+                                              mutex::raw(mutex),\n+                                              dur.num_milliseconds() as DWORD);\n+        if r == 0 {\n+            const ERROR_TIMEOUT: DWORD = 0x5B4;\n+            debug_assert_eq!(os::errno() as uint, ERROR_TIMEOUT as uint);\n+            false\n+        } else {\n+            true\n+        }\n+    }\n+\n+    #[inline]\n+    pub unsafe fn notify_one(&self) {\n+        ffi::WakeConditionVariable(self.inner.get())\n+    }\n+\n+    #[inline]\n+    pub unsafe fn notify_all(&self) {\n+        ffi::WakeAllConditionVariable(self.inner.get())\n+    }\n+\n+    pub unsafe fn destroy(&self) {\n+        // ...\n+    }\n+}"}, {"sha": "9fce308cb9468cad60def633aa6a3825ff412858", "filename": "src/libstd/sys/windows/mod.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -26,20 +26,26 @@ use sync::{Once, ONCE_INIT};\n \n macro_rules! helper_init( (static $name:ident: Helper<$m:ty>) => (\n     static $name: Helper<$m> = Helper {\n-        lock: ::rustrt::mutex::NATIVE_MUTEX_INIT,\n+        lock: ::sync::MUTEX_INIT,\n+        cond: ::sync::CONDVAR_INIT,\n         chan: ::cell::UnsafeCell { value: 0 as *mut Sender<$m> },\n         signal: ::cell::UnsafeCell { value: 0 },\n         initialized: ::cell::UnsafeCell { value: false },\n+        shutdown: ::cell::UnsafeCell { value: false },\n     };\n ) )\n \n pub mod c;\n pub mod ext;\n+pub mod condvar;\n pub mod fs;\n pub mod helper_signal;\n+pub mod mutex;\n pub mod os;\n pub mod pipe;\n pub mod process;\n+pub mod rwlock;\n+pub mod sync;\n pub mod tcp;\n pub mod thread_local;\n pub mod timer;"}, {"sha": "ddd89070ed53d56ecff1c531f998a4d0022310d5", "filename": "src/libstd/sys/windows/mutex.rs", "status": "added", "additions": 78, "deletions": 0, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fmutex.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,78 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use prelude::*;\n+\n+use sync::atomic;\n+use alloc::{mod, heap};\n+\n+use libc::DWORD;\n+use sys::sync as ffi;\n+\n+const SPIN_COUNT: DWORD = 4000;\n+\n+pub struct Mutex { inner: atomic::AtomicUint }\n+\n+pub const MUTEX_INIT: Mutex = Mutex { inner: atomic::INIT_ATOMIC_UINT };\n+\n+#[inline]\n+pub unsafe fn raw(m: &Mutex) -> ffi::LPCRITICAL_SECTION {\n+    m.get()\n+}\n+\n+impl Mutex {\n+    #[inline]\n+    pub unsafe fn new() -> Mutex {\n+        Mutex { inner: atomic::AtomicUint::new(init_lock() as uint) }\n+    }\n+    #[inline]\n+    pub unsafe fn lock(&self) {\n+        ffi::EnterCriticalSection(self.get())\n+    }\n+    #[inline]\n+    pub unsafe fn try_lock(&self) -> bool {\n+        ffi::TryEnterCriticalSection(self.get()) != 0\n+    }\n+    #[inline]\n+    pub unsafe fn unlock(&self) {\n+        ffi::LeaveCriticalSection(self.get())\n+    }\n+    pub unsafe fn destroy(&self) {\n+        let lock = self.inner.swap(0, atomic::SeqCst);\n+        if lock != 0 { free_lock(lock as ffi::LPCRITICAL_SECTION) }\n+    }\n+\n+    unsafe fn get(&self) -> ffi::LPCRITICAL_SECTION {\n+        match self.inner.load(atomic::SeqCst) {\n+            0 => {}\n+            n => return n as ffi::LPCRITICAL_SECTION\n+        }\n+        let lock = init_lock();\n+        match self.inner.compare_and_swap(0, lock as uint, atomic::SeqCst) {\n+            0 => return lock as ffi::LPCRITICAL_SECTION,\n+            _ => {}\n+        }\n+        free_lock(lock);\n+        return self.inner.load(atomic::SeqCst) as ffi::LPCRITICAL_SECTION;\n+    }\n+}\n+\n+unsafe fn init_lock() -> ffi::LPCRITICAL_SECTION {\n+    let block = heap::allocate(ffi::CRITICAL_SECTION_SIZE, 8)\n+                        as ffi::LPCRITICAL_SECTION;\n+    if block.is_null() { alloc::oom() }\n+    ffi::InitializeCriticalSectionAndSpinCount(block, SPIN_COUNT);\n+    return block;\n+}\n+\n+unsafe fn free_lock(h: ffi::LPCRITICAL_SECTION) {\n+    ffi::DeleteCriticalSection(h);\n+    heap::deallocate(h as *mut _, ffi::CRITICAL_SECTION_SIZE, 8);\n+}"}, {"sha": "bf658d0efd0290bd15345070f4e2f3cbbbd924b8", "filename": "src/libstd/sys/windows/pipe.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -89,8 +89,7 @@ use libc;\n use c_str::CString;\n use mem;\n use ptr;\n-use sync::atomic;\n-use rustrt::mutex;\n+use sync::{atomic, Mutex};\n use io::{mod, IoError, IoResult};\n use prelude::*;\n \n@@ -126,7 +125,7 @@ impl Drop for Event {\n \n struct Inner {\n     handle: libc::HANDLE,\n-    lock: mutex::NativeMutex,\n+    lock: Mutex<()>,\n     read_closed: atomic::AtomicBool,\n     write_closed: atomic::AtomicBool,\n }\n@@ -135,7 +134,7 @@ impl Inner {\n     fn new(handle: libc::HANDLE) -> Inner {\n         Inner {\n             handle: handle,\n-            lock: unsafe { mutex::NativeMutex::new() },\n+            lock: Mutex::new(()),\n             read_closed: atomic::AtomicBool::new(false),\n             write_closed: atomic::AtomicBool::new(false),\n         }"}, {"sha": "88ce85c39f625f67694fa326be1cd9c487b922b8", "filename": "src/libstd/sys/windows/rwlock.rs", "status": "added", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Frwlock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Frwlock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Frwlock.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,53 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use cell::UnsafeCell;\n+use sys::sync as ffi;\n+\n+pub struct RWLock { inner: UnsafeCell<ffi::SRWLOCK> }\n+\n+pub const RWLOCK_INIT: RWLock = RWLock {\n+    inner: UnsafeCell { value: ffi::SRWLOCK_INIT }\n+};\n+\n+impl RWLock {\n+    #[inline]\n+    pub unsafe fn new() -> RWLock { RWLOCK_INIT }\n+\n+    #[inline]\n+    pub unsafe fn read(&self) {\n+        ffi::AcquireSRWLockShared(self.inner.get())\n+    }\n+    #[inline]\n+    pub unsafe fn try_read(&self) -> bool {\n+        ffi::TryAcquireSRWLockShared(self.inner.get()) != 0\n+    }\n+    #[inline]\n+    pub unsafe fn write(&self) {\n+        ffi::AcquireSRWLockExclusive(self.inner.get())\n+    }\n+    #[inline]\n+    pub unsafe fn try_write(&self) -> bool {\n+        ffi::TryAcquireSRWLockExclusive(self.inner.get()) != 0\n+    }\n+    #[inline]\n+    pub unsafe fn read_unlock(&self) {\n+        ffi::ReleaseSRWLockShared(self.inner.get())\n+    }\n+    #[inline]\n+    pub unsafe fn write_unlock(&self) {\n+        ffi::ReleaseSRWLockExclusive(self.inner.get())\n+    }\n+\n+    #[inline]\n+    pub unsafe fn destroy(&self) {\n+        // ...\n+    }\n+}"}, {"sha": "cbca47912b511642ab309ddd1ca451ce7c7496bb", "filename": "src/libstd/sys/windows/sync.rs", "status": "added", "additions": 58, "deletions": 0, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Flibstd%2Fsys%2Fwindows%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fsync.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -0,0 +1,58 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use libc::{BOOL, DWORD, c_void, LPVOID};\n+use libc::types::os::arch::extra::BOOLEAN;\n+\n+pub type LPCRITICAL_SECTION = *mut c_void;\n+pub type LPCONDITION_VARIABLE = *mut CONDITION_VARIABLE;\n+pub type LPSRWLOCK = *mut SRWLOCK;\n+\n+#[cfg(target_arch = \"x86\")]\n+pub const CRITICAL_SECTION_SIZE: uint = 24;\n+#[cfg(target_arch = \"x86_64\")]\n+pub const CRITICAL_SECTION_SIZE: uint = 40;\n+\n+#[repr(C)]\n+pub struct CONDITION_VARIABLE { pub ptr: LPVOID }\n+#[repr(C)]\n+pub struct SRWLOCK { pub ptr: LPVOID }\n+\n+pub const CONDITION_VARIABLE_INIT: CONDITION_VARIABLE = CONDITION_VARIABLE {\n+    ptr: 0 as *mut _,\n+};\n+pub const SRWLOCK_INIT: SRWLOCK = SRWLOCK { ptr: 0 as *mut _ };\n+\n+extern \"system\" {\n+    // critical sections\n+    pub fn InitializeCriticalSectionAndSpinCount(\n+                    lpCriticalSection: LPCRITICAL_SECTION,\n+                    dwSpinCount: DWORD) -> BOOL;\n+    pub fn DeleteCriticalSection(lpCriticalSection: LPCRITICAL_SECTION);\n+    pub fn EnterCriticalSection(lpCriticalSection: LPCRITICAL_SECTION);\n+    pub fn LeaveCriticalSection(lpCriticalSection: LPCRITICAL_SECTION);\n+    pub fn TryEnterCriticalSection(lpCriticalSection: LPCRITICAL_SECTION) -> BOOL;\n+\n+    // condition variables\n+    pub fn SleepConditionVariableCS(ConditionVariable: LPCONDITION_VARIABLE,\n+                                    CriticalSection: LPCRITICAL_SECTION,\n+                                    dwMilliseconds: DWORD) -> BOOL;\n+    pub fn WakeConditionVariable(ConditionVariable: LPCONDITION_VARIABLE);\n+    pub fn WakeAllConditionVariable(ConditionVariable: LPCONDITION_VARIABLE);\n+\n+    // slim rwlocks\n+    pub fn AcquireSRWLockExclusive(SRWLock: LPSRWLOCK);\n+    pub fn AcquireSRWLockShared(SRWLock: LPSRWLOCK);\n+    pub fn ReleaseSRWLockExclusive(SRWLock: LPSRWLOCK);\n+    pub fn ReleaseSRWLockShared(SRWLock: LPSRWLOCK);\n+    pub fn TryAcquireSRWLockExclusive(SRWLock: LPSRWLOCK) -> BOOLEAN;\n+    pub fn TryAcquireSRWLockShared(SRWLock: LPSRWLOCK) -> BOOLEAN;\n+}\n+"}, {"sha": "863c3c879a7c108009e14604233c2dddfd962168", "filename": "src/test/bench/msgsend-ring-mutex-arcs.rs", "status": "modified", "additions": 9, "deletions": 7, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/08ce178866e4533d8815fe5868a520e0fc55b21c/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-ring-mutex-arcs.rs?ref=08ce178866e4533d8815fe5868a520e0fc55b21c", "patch": "@@ -19,28 +19,30 @@\n // ignore-lexer-test FIXME #15679\n \n use std::os;\n-use std::sync::{Arc, Future, Mutex};\n+use std::sync::{Arc, Future, Mutex, Condvar};\n use std::time::Duration;\n use std::uint;\n \n // A poor man's pipe.\n-type pipe = Arc<Mutex<Vec<uint>>>;\n+type pipe = Arc<(Mutex<Vec<uint>>, Condvar)>;\n \n fn send(p: &pipe, msg: uint) {\n-    let mut arr = p.lock();\n+    let &(ref lock, ref cond) = &**p;\n+    let mut arr = lock.lock();\n     arr.push(msg);\n-    arr.cond.signal();\n+    cond.notify_one();\n }\n fn recv(p: &pipe) -> uint {\n-    let mut arr = p.lock();\n+    let &(ref lock, ref cond) = &**p;\n+    let mut arr = lock.lock();\n     while arr.is_empty() {\n-        arr.cond.wait();\n+        cond.wait(&arr);\n     }\n     arr.pop().unwrap()\n }\n \n fn init() -> (pipe,pipe) {\n-    let m = Arc::new(Mutex::new(Vec::new()));\n+    let m = Arc::new((Mutex::new(Vec::new()), Condvar::new()));\n     ((&m).clone(), m)\n }\n "}, {"sha": "03066d40512f3cec8b91fb6af081ec0f870cd039", "filename": "src/test/bench/msgsend-ring-rw-arcs.rs", "status": "removed", "additions": 0, "deletions": 113, "changes": 113, "blob_url": "https://github.com/rust-lang/rust/blob/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4573da6f4ffb276c31773679fd19581fc15ded8f/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-ring-rw-arcs.rs?ref=4573da6f4ffb276c31773679fd19581fc15ded8f", "patch": "@@ -1,113 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// This test creates a bunch of tasks that simultaneously send to each\n-// other in a ring. The messages should all be basically\n-// independent.\n-// This is like msgsend-ring-pipes but adapted to use Arcs.\n-\n-// This also serves as a pipes test, because Arcs are implemented with pipes.\n-\n-// no-pretty-expanded FIXME #15189\n-// ignore-lexer-test FIXME #15679\n-\n-use std::os;\n-use std::sync::{RWLock, Arc, Future};\n-use std::time::Duration;\n-use std::uint;\n-\n-// A poor man's pipe.\n-type pipe = Arc<RWLock<Vec<uint>>>;\n-\n-fn send(p: &pipe, msg: uint) {\n-    let mut arr = p.write();\n-    arr.push(msg);\n-    arr.cond.signal();\n-}\n-fn recv(p: &pipe) -> uint {\n-    let mut arr = p.write();\n-    while arr.is_empty() {\n-        arr.cond.wait();\n-    }\n-    arr.pop().unwrap()\n-}\n-\n-fn init() -> (pipe,pipe) {\n-    let x = Arc::new(RWLock::new(Vec::new()));\n-    ((&x).clone(), x)\n-}\n-\n-\n-fn thread_ring(i: uint, count: uint, num_chan: pipe, num_port: pipe) {\n-    let mut num_chan = Some(num_chan);\n-    let mut num_port = Some(num_port);\n-    // Send/Receive lots of messages.\n-    for j in range(0u, count) {\n-        //println!(\"task %?, iter %?\", i, j);\n-        let num_chan2 = num_chan.take().unwrap();\n-        let num_port2 = num_port.take().unwrap();\n-        send(&num_chan2, i * j);\n-        num_chan = Some(num_chan2);\n-        let _n = recv(&num_port2);\n-        //log(error, _n);\n-        num_port = Some(num_port2);\n-    };\n-}\n-\n-fn main() {\n-    let args = os::args();\n-    let args = if os::getenv(\"RUST_BENCH\").is_some() {\n-        vec!(\"\".to_string(), \"100\".to_string(), \"10000\".to_string())\n-    } else if args.len() <= 1u {\n-        vec!(\"\".to_string(), \"10\".to_string(), \"100\".to_string())\n-    } else {\n-        args.clone().into_iter().collect()\n-    };\n-\n-    let num_tasks = from_str::<uint>(args[1].as_slice()).unwrap();\n-    let msg_per_task = from_str::<uint>(args[2].as_slice()).unwrap();\n-\n-    let (mut num_chan, num_port) = init();\n-\n-    let mut p = Some((num_chan, num_port));\n-    let dur = Duration::span(|| {\n-        let (mut num_chan, num_port) = p.take().unwrap();\n-\n-        // create the ring\n-        let mut futures = Vec::new();\n-\n-        for i in range(1u, num_tasks) {\n-            //println!(\"spawning %?\", i);\n-            let (new_chan, num_port) = init();\n-            let num_chan_2 = num_chan.clone();\n-            let new_future = Future::spawn(proc() {\n-                thread_ring(i, msg_per_task, num_chan_2, num_port)\n-            });\n-            futures.push(new_future);\n-            num_chan = new_chan;\n-        };\n-\n-        // do our iteration\n-        thread_ring(0, msg_per_task, num_chan, num_port);\n-\n-        // synchronize\n-        for f in futures.iter_mut() {\n-            let _ = f.get();\n-        }\n-    });\n-\n-    // all done, report stats.\n-    let num_msgs = num_tasks * msg_per_task;\n-    let rate = (num_msgs as f64) / (dur.num_milliseconds() as f64);\n-\n-    println!(\"Sent {} messages in {} ms\", num_msgs, dur.num_milliseconds());\n-    println!(\"  {} messages / second\", rate / 1000.0);\n-    println!(\"  {} \u03bcs / message\", 1000000. / rate / 1000.0);\n-}"}]}