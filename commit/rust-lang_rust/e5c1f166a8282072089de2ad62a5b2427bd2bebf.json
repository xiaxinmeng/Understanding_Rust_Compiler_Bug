{"sha": "e5c1f166a8282072089de2ad62a5b2427bd2bebf", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU1YzFmMTY2YTgyODIwNzIwODlkZTJhZDYyYTViMjQyN2JkMmJlYmY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-01-24T05:12:15Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-01-24T05:12:15Z"}, "message": "Auto merge of #21458 - alexcrichton:remove-some-code, r=brson\n\nThe base64 support can be trivially removed (there are no in-tree users) and the regex support is a whopping 4k lines of code to maintain for a few non-critical uses in-tree. This commit migrates all current users in-tree away from regexes to custom matching code.\r\n\r\nThe most critical application affected by this migration is that the testing framework no longer considers filter arguments as regexes, but rather just a substring matching. It is expected that more featureful testing frameworks can evolve outside of the in-tree libtest version over time which can properly depend on libregex from crates.io.\r\n\r\n[breaking-change]", "tree": {"sha": "f34f763e8ee24bba284b7902496d370667e2a1f5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f34f763e8ee24bba284b7902496d370667e2a1f5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e5c1f166a8282072089de2ad62a5b2427bd2bebf", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e5c1f166a8282072089de2ad62a5b2427bd2bebf", "html_url": "https://github.com/rust-lang/rust/commit/e5c1f166a8282072089de2ad62a5b2427bd2bebf", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e5c1f166a8282072089de2ad62a5b2427bd2bebf/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "url": "https://api.github.com/repos/rust-lang/rust/commits/4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "html_url": "https://github.com/rust-lang/rust/commit/4be79d6acde9eed3a9b5281a46f385bcb4ce736c"}, {"sha": "6c29708bf906fa9075bb96b76fd7f6cc81eda43c", "url": "https://api.github.com/repos/rust-lang/rust/commits/6c29708bf906fa9075bb96b76fd7f6cc81eda43c", "html_url": "https://github.com/rust-lang/rust/commit/6c29708bf906fa9075bb96b76fd7f6cc81eda43c"}], "stats": {"total": 5062, "additions": 187, "deletions": 4875}, "files": [{"sha": "be1965b7edadddd6358ab898816e33828121d57e", "filename": "mk/crates.mk", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/mk%2Fcrates.mk", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/mk%2Fcrates.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fcrates.mk?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -51,7 +51,7 @@\n \n TARGET_CRATES := libc std flate arena term \\\n                  serialize getopts collections test rand \\\n-                 log regex graphviz core rbml alloc \\\n+                 log graphviz core rbml alloc \\\n                  unicode rustc_bitflags\n RUSTC_CRATES := rustc rustc_typeck rustc_borrowck rustc_resolve rustc_driver \\\n                 rustc_trans rustc_back rustc_llvm rustc_privacy\n@@ -95,16 +95,15 @@ DEPS_term := std log\n DEPS_getopts := std\n DEPS_collections := core alloc unicode\n DEPS_num := std\n-DEPS_test := std getopts serialize rbml term regex native:rust_test_helpers\n+DEPS_test := std getopts serialize rbml term native:rust_test_helpers\n DEPS_rand := core\n-DEPS_log := std regex\n-DEPS_regex := std\n+DEPS_log := std\n DEPS_fmt_macros = std\n \n TOOL_DEPS_compiletest := test getopts\n TOOL_DEPS_rustdoc := rustdoc\n TOOL_DEPS_rustc := rustc_driver\n-TOOL_DEPS_rustbook := std regex rustdoc\n+TOOL_DEPS_rustbook := std rustdoc\n TOOL_SOURCE_compiletest := $(S)src/compiletest/compiletest.rs\n TOOL_SOURCE_rustdoc := $(S)src/driver/driver.rs\n TOOL_SOURCE_rustc := $(S)src/driver/driver.rs\n@@ -130,9 +129,8 @@ DOC_CRATES := $(filter-out rustc, \\\n               $(filter-out rustc_driver, \\\n               $(filter-out rustc_privacy, \\\n               $(filter-out log, \\\n-              $(filter-out regex, \\\n               $(filter-out getopts, \\\n-              $(filter-out syntax, $(CRATES))))))))))))\n+              $(filter-out syntax, $(CRATES)))))))))))\n COMPILER_DOC_CRATES := rustc rustc_trans rustc_borrowck rustc_resolve \\\n                        rustc_typeck rustc_driver syntax rustc_privacy\n "}, {"sha": "1f4f444634dc254ad98fec426fdbdf8028a83a19", "filename": "src/compiletest/common.rs", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcompiletest%2Fcommon.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -11,7 +11,6 @@ pub use self::Mode::*;\n \n use std::fmt;\n use std::str::FromStr;\n-use regex::Regex;\n \n #[derive(Clone, PartialEq, Debug)]\n pub enum Mode {\n@@ -101,10 +100,7 @@ pub struct Config {\n     pub run_ignored: bool,\n \n     // Only run tests that match this filter\n-    pub filter: Option<Regex>,\n-\n-    // Precompiled regex for finding expected errors in cfail\n-    pub cfail_regex: Regex,\n+    pub filter: Option<String>,\n \n     // Write out a parseable log of tests that were run\n     pub logfile: Option<Path>,"}, {"sha": "4659af4416bd96232231b887f34b9e82a0e95bea", "filename": "src/compiletest/compiletest.rs", "status": "modified", "additions": 35, "deletions": 31, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fcompiletest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fcompiletest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcompiletest%2Fcompiletest.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -22,7 +22,6 @@ extern crate getopts;\n \n #[macro_use]\n extern crate log;\n-extern crate regex;\n \n use std::os;\n use std::io;\n@@ -33,7 +32,6 @@ use getopts::{optopt, optflag, reqopt};\n use common::Config;\n use common::{Pretty, DebugInfoGdb, DebugInfoLldb, Codegen};\n use util::logv;\n-use regex::Regex;\n \n pub mod procsrv;\n pub mod util;\n@@ -116,14 +114,7 @@ pub fn parse_config(args: Vec<String> ) -> Config {\n     }\n \n     let filter = if !matches.free.is_empty() {\n-        let s = matches.free[0].as_slice();\n-        match regex::Regex::new(s) {\n-            Ok(re) => Some(re),\n-            Err(e) => {\n-                println!(\"failed to parse filter /{}/: {:?}\", s, e);\n-                panic!()\n-            }\n-        }\n+        Some(matches.free[0].clone())\n     } else {\n         None\n     };\n@@ -145,7 +136,6 @@ pub fn parse_config(args: Vec<String> ) -> Config {\n                                        .as_slice()).expect(\"invalid mode\"),\n         run_ignored: matches.opt_present(\"ignored\"),\n         filter: filter,\n-        cfail_regex: Regex::new(errors::EXPECTED_PATTERN).unwrap(),\n         logfile: matches.opt_str(\"logfile\").map(|s| Path::new(s)),\n         runtool: matches.opt_str(\"runtool\"),\n         host_rustcflags: matches.opt_str(\"host-rustcflags\"),\n@@ -374,18 +364,24 @@ fn extract_gdb_version(full_version_line: Option<String>) -> Option<String> {\n           if full_version_line.as_slice().trim().len() > 0 => {\n             let full_version_line = full_version_line.as_slice().trim();\n \n-            let re = Regex::new(r\"(^|[^0-9])([0-9]\\.[0-9])([^0-9]|$)\").unwrap();\n-\n-            match re.captures(full_version_line) {\n-                Some(captures) => {\n-                    Some(captures.at(2).unwrap_or(\"\").to_string())\n+            // used to be a regex \"(^|[^0-9])([0-9]\\.[0-9])([^0-9]|$)\"\n+            for (pos, c) in full_version_line.char_indices() {\n+                if !c.is_digit(10) { continue }\n+                if pos + 2 >= full_version_line.len() { continue }\n+                if full_version_line.char_at(pos + 1) != '.' { continue }\n+                if !full_version_line.char_at(pos + 2).is_digit(10) { continue }\n+                if pos > 0 && full_version_line.char_at_reverse(pos).is_digit(10) {\n+                    continue\n                 }\n-                None => {\n-                    println!(\"Could not extract GDB version from line '{}'\",\n-                             full_version_line);\n-                    None\n+                if pos + 3 < full_version_line.len() &&\n+                   full_version_line.char_at(pos + 3).is_digit(10) {\n+                    continue\n                 }\n+                return Some(full_version_line[pos..pos+3].to_string());\n             }\n+            println!(\"Could not extract GDB version from line '{}'\",\n+                     full_version_line);\n+            None\n         },\n         _ => None\n     }\n@@ -408,18 +404,26 @@ fn extract_lldb_version(full_version_line: Option<String>) -> Option<String> {\n           if full_version_line.as_slice().trim().len() > 0 => {\n             let full_version_line = full_version_line.as_slice().trim();\n \n-            let re = Regex::new(r\"[Ll][Ll][Dd][Bb]-([0-9]+)\").unwrap();\n-\n-            match re.captures(full_version_line) {\n-                Some(captures) => {\n-                    Some(captures.at(1).unwrap_or(\"\").to_string())\n-                }\n-                None => {\n-                    println!(\"Could not extract LLDB version from line '{}'\",\n-                             full_version_line);\n-                    None\n-                }\n+            for (pos, l) in full_version_line.char_indices() {\n+                if l != 'l' && l != 'L' { continue }\n+                if pos + 5 >= full_version_line.len() { continue }\n+                let l = full_version_line.char_at(pos + 1);\n+                if l != 'l' && l != 'L' { continue }\n+                let d = full_version_line.char_at(pos + 2);\n+                if d != 'd' && d != 'D' { continue }\n+                let b = full_version_line.char_at(pos + 3);\n+                if b != 'b' && b != 'B' { continue }\n+                let dash = full_version_line.char_at(pos + 4);\n+                if dash != '-' { continue }\n+\n+                let vers = full_version_line[pos + 5..].chars().take_while(|c| {\n+                    c.is_digit(10)\n+                }).collect::<String>();\n+                if vers.len() > 0 { return Some(vers) }\n             }\n+            println!(\"Could not extract LLDB version from line '{}'\",\n+                     full_version_line);\n+            None\n         },\n         _ => None\n     }"}, {"sha": "fc815d66a4d4205eaa8e90f591ab8b40ce29f468", "filename": "src/compiletest/errors.rs", "status": "modified", "additions": 38, "deletions": 35, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Ferrors.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Ferrors.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcompiletest%2Ferrors.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -9,32 +9,26 @@\n // except according to those terms.\n use self::WhichLine::*;\n \n-use std::ascii::AsciiExt;\n use std::io::{BufferedReader, File};\n-use regex::Regex;\n \n pub struct ExpectedError {\n     pub line: uint,\n     pub kind: String,\n     pub msg: String,\n }\n \n+#[derive(PartialEq, Show)]\n+enum WhichLine { ThisLine, FollowPrevious(uint), AdjustBackward(uint) }\n+\n /// Looks for either \"//~| KIND MESSAGE\" or \"//~^^... KIND MESSAGE\"\n /// The former is a \"follow\" that inherits its target from the preceding line;\n /// the latter is an \"adjusts\" that goes that many lines up.\n ///\n /// Goal is to enable tests both like: //~^^^ ERROR go up three\n /// and also //~^ ERROR message one for the preceding line, and\n ///          //~| ERROR message two for that same line.\n-\n-pub static EXPECTED_PATTERN : &'static str =\n-    r\"//~(?P<follow>\\|)?(?P<adjusts>\\^*)\\s*(?P<kind>\\S*)\\s*(?P<msg>.*)\";\n-\n-#[derive(PartialEq, Show)]\n-enum WhichLine { ThisLine, FollowPrevious(uint), AdjustBackward(uint) }\n-\n // Load any test directives embedded in the file\n-pub fn load_errors(re: &Regex, testfile: &Path) -> Vec<ExpectedError> {\n+pub fn load_errors(testfile: &Path) -> Vec<ExpectedError> {\n     let mut rdr = BufferedReader::new(File::open(testfile).unwrap());\n \n     // `last_nonfollow_error` tracks the most recently seen\n@@ -50,7 +44,7 @@ pub fn load_errors(re: &Regex, testfile: &Path) -> Vec<ExpectedError> {\n     rdr.lines().enumerate().filter_map(|(line_no, ln)| {\n         parse_expected(last_nonfollow_error,\n                        line_no + 1,\n-                       ln.unwrap().as_slice(), re)\n+                       ln.unwrap().as_slice())\n             .map(|(which, error)| {\n                 match which {\n                     FollowPrevious(_) => {}\n@@ -63,30 +57,39 @@ pub fn load_errors(re: &Regex, testfile: &Path) -> Vec<ExpectedError> {\n \n fn parse_expected(last_nonfollow_error: Option<uint>,\n                   line_num: uint,\n-                  line: &str,\n-                  re: &Regex) -> Option<(WhichLine, ExpectedError)> {\n-    re.captures(line).and_then(|caps| {\n-        let adjusts = caps.name(\"adjusts\").unwrap_or(\"\").len();\n-        let kind = caps.name(\"kind\").unwrap_or(\"\").to_ascii_lowercase();\n-        let msg = caps.name(\"msg\").unwrap_or(\"\").trim().to_string();\n-        let follow = caps.name(\"follow\").unwrap_or(\"\").len() > 0;\n+                  line: &str) -> Option<(WhichLine, ExpectedError)> {\n+    let start = match line.find_str(\"//~\") { Some(i) => i, None => return None };\n+    let (follow, adjusts) = if line.char_at(start + 3) == '|' {\n+        (true, 0)\n+    } else {\n+        (false, line[start + 3..].chars().take_while(|c| *c == '^').count())\n+    };\n+    let kind_start = start + 3 + adjusts + (follow as usize);\n+    let letters = line[kind_start..].chars();\n+    let kind = letters.skip_while(|c| c.is_whitespace())\n+                      .take_while(|c| !c.is_whitespace())\n+                      .map(|c| c.to_lowercase())\n+                      .collect::<String>();\n+    let letters = line[kind_start..].chars();\n+    let msg = letters.skip_while(|c| c.is_whitespace())\n+                     .skip_while(|c| !c.is_whitespace())\n+                     .collect::<String>().trim().to_string();\n \n-        let (which, line) = if follow {\n-            assert!(adjusts == 0, \"use either //~| or //~^, not both.\");\n-            let line = last_nonfollow_error.unwrap_or_else(|| {\n-                panic!(\"encountered //~| without preceding //~^ line.\")\n-            });\n-            (FollowPrevious(line), line)\n-        } else {\n-            let which =\n-                if adjusts > 0 { AdjustBackward(adjusts) } else { ThisLine };\n-            let line = line_num - adjusts;\n-            (which, line)\n-        };\n+    let (which, line) = if follow {\n+        assert!(adjusts == 0, \"use either //~| or //~^, not both.\");\n+        let line = last_nonfollow_error.unwrap_or_else(|| {\n+            panic!(\"encountered //~| without preceding //~^ line.\")\n+        });\n+        (FollowPrevious(line), line)\n+    } else {\n+        let which =\n+            if adjusts > 0 { AdjustBackward(adjusts) } else { ThisLine };\n+        let line = line_num - adjusts;\n+        (which, line)\n+    };\n \n-        debug!(\"line={} which={:?} kind={:?} msg={:?}\", line_num, which, kind, msg);\n-        Some((which, ExpectedError { line: line,\n-                                     kind: kind,\n-                                     msg: msg, }))\n-    })\n+    debug!(\"line={} which={:?} kind={:?} msg={:?}\", line_num, which, kind, msg);\n+    Some((which, ExpectedError { line: line,\n+                                 kind: kind,\n+                                 msg: msg, }))\n }"}, {"sha": "e5a973e7501ae6ad155757ac5ea9dd6740258f94", "filename": "src/compiletest/runtest.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fruntest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fcompiletest%2Fruntest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcompiletest%2Fruntest.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -99,7 +99,7 @@ fn run_cfail_test(config: &Config, props: &TestProps, testfile: &Path) {\n     }\n \n     let output_to_check = get_output(props, &proc_res);\n-    let expected_errors = errors::load_errors(&config.cfail_regex, testfile);\n+    let expected_errors = errors::load_errors(testfile);\n     if !expected_errors.is_empty() {\n         if !props.error_patterns.is_empty() {\n             fatal(\"both error pattern and expected errors specified\");"}, {"sha": "1288110df330a236306977793225a0dcb259e3e3", "filename": "src/grammar/verify.rs", "status": "modified", "additions": 13, "deletions": 12, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fgrammar%2Fverify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fgrammar%2Fverify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fgrammar%2Fverify.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -13,14 +13,11 @@\n extern crate syntax;\n extern crate rustc;\n \n-extern crate regex;\n-\n #[macro_use]\n extern crate log;\n \n use std::collections::HashMap;\n use std::io::File;\n-use regex::Regex;\n \n use syntax::parse;\n use syntax::parse::lexer;\n@@ -167,15 +164,19 @@ fn count(lit: &str) -> usize {\n }\n \n fn parse_antlr_token(s: &str, tokens: &HashMap<String, token::Token>) -> TokenAndSpan {\n-    let re = Regex::new(\n-      r\"\\[@(?P<seq>\\d+),(?P<start>\\d+):(?P<end>\\d+)='(?P<content>.+?)',<(?P<toknum>-?\\d+)>,\\d+:\\d+]\"\n-    ).unwrap();\n-\n-    let m = re.captures(s).expect(format!(\"The regex didn't match {}\", s).as_slice());\n-    let start = m.name(\"start\").unwrap_or(\"\");\n-    let end = m.name(\"end\").unwrap_or(\"\");\n-    let toknum = m.name(\"toknum\").unwrap_or(\"\");\n-    let content = m.name(\"content\").unwrap_or(\"\");\n+    // old regex:\n+    // \\[@(?P<seq>\\d+),(?P<start>\\d+):(?P<end>\\d+)='(?P<content>.+?)',<(?P<toknum>-?\\d+)>,\\d+:\\d+]\n+    let start = s.find_str(\"[@\").unwrap();\n+    let comma = start + s[start..].find_str(\",\").unwrap();\n+    let colon = comma + s[comma..].find_str(\":\").unwrap();\n+    let content_start = colon + s[colon..].find_str(\"='\").unwrap();\n+    let content_end = content_start + s[content_start..].find_str(\"',<\").unwrap();\n+    let toknum_end = content_end + s[content_end..].find_str(\">,\").unwrap();\n+\n+    let start = &s[comma + 1 .. colon];\n+    let end = &s[colon + 1 .. content_start];\n+    let content = &s[content_start + 2 .. content_end];\n+    let toknum = &s[content_end + 3 .. toknum_end];\n \n     let proto_tok = tokens.get(toknum).expect(format!(\"didn't find token {:?} in the map\",\n                                                               toknum).as_slice());"}, {"sha": "5efa799f56279628f123fb617ed3ad375abc35fd", "filename": "src/liblog/directive.rs", "status": "modified", "additions": 2, "deletions": 13, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fliblog%2Fdirective.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fliblog%2Fdirective.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliblog%2Fdirective.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -8,7 +8,6 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use regex::Regex;\n use std::ascii::AsciiExt;\n use std::cmp;\n \n@@ -34,7 +33,7 @@ fn parse_log_level(level: &str) -> Option<u32> {\n ///\n /// Valid log levels are 0-255, with the most likely ones being 1-4 (defined in\n /// std::).  Also supports string log levels of error, warn, info, and debug\n-pub fn parse_logging_spec(spec: &str) -> (Vec<LogDirective>, Option<Regex>) {\n+pub fn parse_logging_spec(spec: &str) -> (Vec<LogDirective>, Option<String>) {\n     let mut dirs = Vec::new();\n \n     let mut parts = spec.split('/');\n@@ -80,17 +79,7 @@ pub fn parse_logging_spec(spec: &str) -> (Vec<LogDirective>, Option<Regex>) {\n         });\n     }});\n \n-    let filter = filter.map_or(None, |filter| {\n-        match Regex::new(filter) {\n-            Ok(re) => Some(re),\n-            Err(e) => {\n-                println!(\"warning: invalid regex filter - {:?}\", e);\n-                None\n-            }\n-        }\n-    });\n-\n-    return (dirs, filter);\n+    (dirs, filter.map(|s| s.to_string()))\n }\n \n #[cfg(test)]"}, {"sha": "e7c5bc35f761af22eb1052e0ddc69b4610450d05", "filename": "src/liblog/lib.rs", "status": "modified", "additions": 10, "deletions": 14, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fliblog%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Fliblog%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliblog%2Flib.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -123,11 +123,11 @@\n //!\n //! # Filtering results\n //!\n-//! A RUST_LOG directive may include a regex filter. The syntax is to append `/`\n-//! followed by a regex. Each message is checked against the regex, and is only\n-//! logged if it matches. Note that the matching is done after formatting the log\n-//! string but before adding any logging meta-data. There is a single filter for all\n-//! modules.\n+//! A RUST_LOG directive may include a string filter. The syntax is to append\n+//! `/` followed by a string. Each message is checked against the string and is\n+//! only logged if it contains the string. Note that the matching is done after\n+//! formatting the log string but before adding any logging meta-data. There is\n+//! a single filter for all modules.\n //!\n //! Some examples:\n //!\n@@ -172,8 +172,6 @@\n #![allow(unstable)]\n #![deny(missing_docs)]\n \n-extern crate regex;\n-\n use std::cell::RefCell;\n use std::fmt;\n use std::io::LineBufferedWriter;\n@@ -185,8 +183,6 @@ use std::rt;\n use std::slice;\n use std::sync::{Once, ONCE_INIT};\n \n-use regex::Regex;\n-\n use directive::LOG_LEVEL_NAMES;\n \n #[macro_use]\n@@ -209,8 +205,8 @@ static mut LOG_LEVEL: u32 = MAX_LOG_LEVEL;\n static mut DIRECTIVES: *const Vec<directive::LogDirective> =\n     0 as *const Vec<directive::LogDirective>;\n \n-/// Optional regex filter.\n-static mut FILTER: *const Regex = 0 as *const _;\n+/// Optional filter.\n+static mut FILTER: *const String = 0 as *const _;\n \n /// Debug log level\n pub const DEBUG: u32 = 4;\n@@ -288,7 +284,7 @@ pub fn log(level: u32, loc: &'static LogLocation, args: fmt::Arguments) {\n     // Test the literal string from args against the current filter, if there\n     // is one.\n     match unsafe { FILTER.as_ref() } {\n-        Some(filter) if !filter.is_match(&args.to_string()[]) => return,\n+        Some(filter) if !args.to_string().contains(&filter[]) => return,\n         _ => {}\n     }\n \n@@ -435,8 +431,8 @@ fn init() {\n             DIRECTIVES = ptr::null();\n \n             if !FILTER.is_null() {\n-                let _filter: Box<Regex> = mem::transmute(FILTER);\n-                FILTER = ptr::null();\n+                let _filter: Box<String> = mem::transmute(FILTER);\n+                FILTER = 0 as *const _;\n             }\n         });\n     }"}, {"sha": "d29a7a425c1164d1825549f49a99305377d89a95", "filename": "src/libregex/compile.rs", "status": "removed", "additions": 0, "deletions": 275, "changes": 275, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fcompile.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fcompile.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fcompile.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,275 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// Enable this to squash warnings due to exporting pieces of the representation\n-// for use with the regex! macro. See lib.rs for explanation.\n-\n-pub use self::Inst::*;\n-\n-use std::cmp;\n-use std::iter::repeat;\n-use parse;\n-use parse::{\n-    Flags, FLAG_EMPTY,\n-    Nothing, Literal, Dot, AstClass, Begin, End, WordBoundary, Capture, Cat, Alt,\n-    Rep,\n-    ZeroOne, ZeroMore, OneMore,\n-};\n-\n-type InstIdx = uint;\n-\n-#[derive(Show, Clone)]\n-pub enum Inst {\n-    // When a Match instruction is executed, the current thread is successful.\n-    Match,\n-\n-    // The OneChar instruction matches a literal character.\n-    // The flags indicate whether to do a case insensitive match.\n-    OneChar(char, Flags),\n-\n-    // The CharClass instruction tries to match one input character against\n-    // the range of characters given.\n-    // The flags indicate whether to do a case insensitive match and whether\n-    // the character class is negated or not.\n-    CharClass(Vec<(char, char)>, Flags),\n-\n-    // Matches any character except new lines.\n-    // The flags indicate whether to include the '\\n' character.\n-    Any(Flags),\n-\n-    // Matches the beginning of the string, consumes no characters.\n-    // The flags indicate whether it matches if the preceding character\n-    // is a new line.\n-    EmptyBegin(Flags),\n-\n-    // Matches the end of the string, consumes no characters.\n-    // The flags indicate whether it matches if the proceeding character\n-    // is a new line.\n-    EmptyEnd(Flags),\n-\n-    // Matches a word boundary (\\w on one side and \\W \\A or \\z on the other),\n-    // and consumes no character.\n-    // The flags indicate whether this matches a word boundary or something\n-    // that isn't a word boundary.\n-    EmptyWordBoundary(Flags),\n-\n-    // Saves the current position in the input string to the Nth save slot.\n-    Save(uint),\n-\n-    // Jumps to the instruction at the index given.\n-    Jump(InstIdx),\n-\n-    // Jumps to the instruction at the first index given. If that leads to\n-    // a panic state, then the instruction at the second index given is\n-    // tried.\n-    Split(InstIdx, InstIdx),\n-}\n-\n-/// Program represents a compiled regular expression. Once an expression is\n-/// compiled, its representation is immutable and will never change.\n-///\n-/// All of the data in a compiled expression is wrapped in \"MaybeStatic\" or\n-/// \"MaybeOwned\" types so that a `Program` can be represented as static data.\n-/// (This makes it convenient and efficient for use with the `regex!` macro.)\n-#[derive(Clone)]\n-pub struct Program {\n-    /// A sequence of instructions.\n-    pub insts: Vec<Inst>,\n-    /// If the regular expression requires a literal prefix in order to have a\n-    /// match, that prefix is stored here. (It's used in the VM to implement\n-    /// an optimization.)\n-    pub prefix: String,\n-}\n-\n-impl Program {\n-    /// Compiles a Regex given its AST.\n-    pub fn new(ast: parse::Ast) -> (Program, Vec<Option<String>>) {\n-        let mut c = Compiler {\n-            insts: Vec::with_capacity(100),\n-            names: Vec::with_capacity(10),\n-        };\n-\n-        c.insts.push(Save(0));\n-        c.compile(ast);\n-        c.insts.push(Save(1));\n-        c.insts.push(Match);\n-\n-        // Try to discover a literal string prefix.\n-        // This is a bit hacky since we have to skip over the initial\n-        // 'Save' instruction.\n-        let mut pre = String::with_capacity(5);\n-        for inst in c.insts[1..].iter() {\n-            match *inst {\n-                OneChar(c, FLAG_EMPTY) => pre.push(c),\n-                _ => break\n-            }\n-        }\n-\n-        let Compiler { insts, names } = c;\n-        let prog = Program {\n-            insts: insts,\n-            prefix: pre,\n-        };\n-        (prog, names)\n-    }\n-\n-    /// Returns the total number of capture groups in the regular expression.\n-    /// This includes the zeroth capture.\n-    pub fn num_captures(&self) -> uint {\n-        let mut n = 0;\n-        for inst in self.insts.iter() {\n-            match *inst {\n-                Save(c) => n = cmp::max(n, c+1),\n-                _ => {}\n-            }\n-        }\n-        // There's exactly 2 Save slots for every capture.\n-        n / 2\n-    }\n-}\n-\n-struct Compiler<'r> {\n-    insts: Vec<Inst>,\n-    names: Vec<Option<String>>,\n-}\n-\n-// The compiler implemented here is extremely simple. Most of the complexity\n-// in this crate is in the parser or the VM.\n-// The only tricky thing here is patching jump/split instructions to point to\n-// the right instruction.\n-impl<'r> Compiler<'r> {\n-    fn compile(&mut self, ast: parse::Ast) {\n-        match ast {\n-            Nothing => {},\n-            Literal(c, flags) => self.push(OneChar(c, flags)),\n-            Dot(nl) => self.push(Any(nl)),\n-            AstClass(ranges, flags) =>\n-                self.push(CharClass(ranges, flags)),\n-            Begin(flags) => self.push(EmptyBegin(flags)),\n-            End(flags) => self.push(EmptyEnd(flags)),\n-            WordBoundary(flags) => self.push(EmptyWordBoundary(flags)),\n-            Capture(cap, name, x) => {\n-                let len = self.names.len();\n-                if cap >= len {\n-                    self.names.extend(repeat(None).take(10 + cap - len))\n-                }\n-                self.names[cap] = name;\n-\n-                self.push(Save(2 * cap));\n-                self.compile(*x);\n-                self.push(Save(2 * cap + 1));\n-            }\n-            Cat(xs) => {\n-                for x in xs.into_iter() {\n-                    self.compile(x)\n-                }\n-            }\n-            Alt(x, y) => {\n-                let split = self.empty_split(); // push: split 0, 0\n-                let j1 = self.insts.len();\n-                self.compile(*x);                // push: insts for x\n-                let jmp = self.empty_jump();    // push: jmp 0\n-                let j2 = self.insts.len();\n-                self.compile(*y);                // push: insts for y\n-                let j3 = self.insts.len();\n-\n-                self.set_split(split, j1, j2);  // split 0, 0 -> split j1, j2\n-                self.set_jump(jmp, j3);         // jmp 0      -> jmp j3\n-            }\n-            Rep(x, ZeroOne, g) => {\n-                let split = self.empty_split();\n-                let j1 = self.insts.len();\n-                self.compile(*x);\n-                let j2 = self.insts.len();\n-\n-                if g.is_greedy() {\n-                    self.set_split(split, j1, j2);\n-                } else {\n-                    self.set_split(split, j2, j1);\n-                }\n-            }\n-            Rep(x, ZeroMore, g) => {\n-                let j1 = self.insts.len();\n-                let split = self.empty_split();\n-                let j2 = self.insts.len();\n-                self.compile(*x);\n-                let jmp = self.empty_jump();\n-                let j3 = self.insts.len();\n-\n-                self.set_jump(jmp, j1);\n-                if g.is_greedy() {\n-                    self.set_split(split, j2, j3);\n-                } else {\n-                    self.set_split(split, j3, j2);\n-                }\n-            }\n-            Rep(x, OneMore, g) => {\n-                let j1 = self.insts.len();\n-                self.compile(*x);\n-                let split = self.empty_split();\n-                let j2 = self.insts.len();\n-\n-                if g.is_greedy() {\n-                    self.set_split(split, j1, j2);\n-                } else {\n-                    self.set_split(split, j2, j1);\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Appends the given instruction to the program.\n-    #[inline]\n-    fn push(&mut self, x: Inst) {\n-        self.insts.push(x)\n-    }\n-\n-    /// Appends an *empty* `Split` instruction to the program and returns\n-    /// the index of that instruction. (The index can then be used to \"patch\"\n-    /// the actual locations of the split in later.)\n-    #[inline]\n-    fn empty_split(&mut self) -> InstIdx {\n-        self.insts.push(Split(0, 0));\n-        self.insts.len() - 1\n-    }\n-\n-    /// Sets the left and right locations of a `Split` instruction at index\n-    /// `i` to `pc1` and `pc2`, respectively.\n-    /// If the instruction at index `i` isn't a `Split` instruction, then\n-    /// `panic!` is called.\n-    #[inline]\n-    fn set_split(&mut self, i: InstIdx, pc1: InstIdx, pc2: InstIdx) {\n-        let split = &mut self.insts[i];\n-        match *split {\n-            Split(_, _) => *split = Split(pc1, pc2),\n-            _ => panic!(\"BUG: Invalid split index.\"),\n-        }\n-    }\n-\n-    /// Appends an *empty* `Jump` instruction to the program and returns the\n-    /// index of that instruction.\n-    #[inline]\n-    fn empty_jump(&mut self) -> InstIdx {\n-        self.insts.push(Jump(0));\n-        self.insts.len() - 1\n-    }\n-\n-    /// Sets the location of a `Jump` instruction at index `i` to `pc`.\n-    /// If the instruction at index `i` isn't a `Jump` instruction, then\n-    /// `panic!` is called.\n-    #[inline]\n-    fn set_jump(&mut self, i: InstIdx, pc: InstIdx) {\n-        let jmp = &mut self.insts[i];\n-        match *jmp {\n-            Jump(_) => *jmp = Jump(pc),\n-            _ => panic!(\"BUG: Invalid jump index.\"),\n-        }\n-    }\n-}"}, {"sha": "002b74cf1efa4afda248cf8b7d2581e0a645e5c9", "filename": "src/libregex/lib.rs", "status": "removed", "additions": 0, "deletions": 93, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Flib.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,93 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-//\n-// ignore-lexer-test FIXME #15679\n-\n-//! Regular expressions implemented in Rust\n-//!\n-//! For official documentation, see the rust-lang/regex crate\n-#![crate_name = \"regex\"]\n-#![crate_type = \"rlib\"]\n-#![crate_type = \"dylib\"]\n-#![unstable = \"use the crates.io `regex` library instead\"]\n-#![staged_api]\n-#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n-       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n-       html_root_url = \"http://doc.rust-lang.org/nightly/\",\n-       html_playground_url = \"http://play.rust-lang.org/\")]\n-\n-#![allow(unknown_features)]\n-#![allow(unstable)]\n-#![feature(slicing_syntax)]\n-#![feature(box_syntax)]\n-#![allow(unknown_features)] #![feature(int_uint)]\n-#![deny(missing_docs)]\n-\n-#[cfg(test)]\n-extern crate \"test\" as stdtest;\n-#[cfg(test)]\n-extern crate rand;\n-\n-// During tests, this links with the `regex` crate so that the `regex!` macro\n-// can be tested.\n-#[cfg(test)]\n-extern crate regex;\n-\n-// Unicode tables for character classes are defined in libunicode\n-extern crate unicode;\n-\n-pub use parse::Error;\n-pub use re::{Regex, Captures, SubCaptures, SubCapturesPos};\n-pub use re::{FindCaptures, FindMatches};\n-pub use re::{Replacer, NoExpand, RegexSplits, RegexSplitsN};\n-pub use re::{quote, is_match};\n-\n-mod compile;\n-mod parse;\n-mod re;\n-mod vm;\n-\n-#[cfg(test)]\n-mod test;\n-\n-/// The `native` module exists to support the `regex!` macro. Do not use.\n-#[doc(hidden)]\n-pub mod native {\n-    // Exporting this stuff is bad form, but it's necessary for two reasons.\n-    // Firstly, the `regex!` syntax extension is in a different crate and\n-    // requires access to the representation of a regex (particularly the\n-    // instruction set) in order to compile to native Rust. This could be\n-    // mitigated if `regex!` was defined in the same crate, but this has\n-    // undesirable consequences (such as requiring a dependency on\n-    // `libsyntax`).\n-    //\n-    // Secondly, the code generated by `regex!` must *also* be able\n-    // to access various functions in this crate to reduce code duplication\n-    // and to provide a value with precisely the same `Regex` type in this\n-    // crate. This, AFAIK, is impossible to mitigate.\n-    //\n-    // On the bright side, `rustdoc` lets us hide this from the public API\n-    // documentation.\n-    pub use compile::{\n-        Program,\n-        OneChar, CharClass, Any, Save, Jump, Split,\n-        Match, EmptyBegin, EmptyEnd, EmptyWordBoundary,\n-    };\n-    pub use parse::{\n-        FLAG_EMPTY, FLAG_NOCASE, FLAG_MULTI, FLAG_DOTNL,\n-        FLAG_SWAP_GREED, FLAG_NEGATED,\n-    };\n-    pub use re::{Dynamic, ExDynamic, Native, ExNative};\n-    pub use vm::{\n-        MatchKind, Exists, Location, Submatches,\n-        StepState, StepMatchEarlyReturn, StepMatch, StepContinue,\n-        CharReader, find_prefix,\n-    };\n-}"}, {"sha": "c2186a0ec241ce30b2184e05227c96e5dda92a63", "filename": "src/libregex/parse.rs", "status": "removed", "additions": 0, "deletions": 1087, "changes": 1087, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fparse.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,1087 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-pub use self::Ast::*;\n-pub use self::Repeater::*;\n-pub use self::Greed::*;\n-use self::BuildAst::*;\n-\n-use std::char;\n-use std::cmp;\n-use std::fmt;\n-use std::iter;\n-use std::num;\n-\n-/// Static data containing Unicode ranges for general categories and scripts.\n-use unicode::regex::{UNICODE_CLASSES, PERLD, PERLS, PERLW};\n-\n-/// The maximum number of repetitions allowed with the `{n,m}` syntax.\n-static MAX_REPEAT: uint = 1000;\n-\n-/// Error corresponds to something that can go wrong while parsing\n-/// a regular expression.\n-///\n-/// (Once an expression is compiled, it is not possible to produce an error\n-/// via searching, splitting or replacing.)\n-#[derive(Show)]\n-pub struct Error {\n-    /// The *approximate* character index of where the error occurred.\n-    pub pos: uint,\n-    /// A message describing the error.\n-    pub msg: String,\n-}\n-\n-impl fmt::Display for Error {\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        write!(f, \"Regex syntax error near position {}: {:?}\",\n-               self.pos, self.msg)\n-    }\n-}\n-\n-/// Represents the abstract syntax of a regular expression.\n-/// It is showable so that error messages resulting from a bug can provide\n-/// useful information.\n-/// It is cloneable so that expressions can be repeated for the counted\n-/// repetition feature. (No other copying is done.)\n-///\n-/// Note that this representation prevents one from reproducing the regex as\n-/// it was typed. (But it could be used to reproduce an equivalent regex.)\n-#[derive(Show, Clone)]\n-pub enum Ast {\n-    Nothing,\n-    Literal(char, Flags),\n-    Dot(Flags),\n-    AstClass(Vec<(char, char)>, Flags),\n-    Begin(Flags),\n-    End(Flags),\n-    WordBoundary(Flags),\n-    Capture(uint, Option<String>, Box<Ast>),\n-    // Represent concatenation as a flat vector to avoid blowing the\n-    // stack in the compiler.\n-    Cat(Vec<Ast>),\n-    Alt(Box<Ast>, Box<Ast>),\n-    Rep(Box<Ast>, Repeater, Greed),\n-}\n-\n-#[derive(Show, PartialEq, Clone)]\n-pub enum Repeater {\n-    ZeroOne,\n-    ZeroMore,\n-    OneMore,\n-}\n-\n-#[derive(Copy, Show, Clone)]\n-pub enum Greed {\n-    Greedy,\n-    Ungreedy,\n-}\n-\n-impl Greed {\n-    pub fn is_greedy(&self) -> bool {\n-        match *self {\n-            Greedy => true,\n-            _ => false,\n-        }\n-    }\n-\n-    fn swap(self, swapped: bool) -> Greed {\n-        if !swapped { return self }\n-        match self {\n-            Greedy => Ungreedy,\n-            Ungreedy => Greedy,\n-        }\n-    }\n-}\n-\n-/// BuildAst is a regrettable type that represents intermediate state for\n-/// constructing an abstract syntax tree. Its central purpose is to facilitate\n-/// parsing groups and alternations while also maintaining a stack of flag\n-/// state.\n-#[derive(Show)]\n-enum BuildAst {\n-    Expr(Ast),\n-    Paren(Flags, uint, String), // '('\n-    Bar, // '|'\n-}\n-\n-impl BuildAst {\n-    fn paren(&self) -> bool {\n-        match *self {\n-            Paren(_, _, _) => true,\n-            _ => false,\n-        }\n-    }\n-\n-    fn flags(&self) -> Flags {\n-        match *self {\n-            Paren(flags, _, _) => flags,\n-            _ => panic!(\"Cannot get flags from {:?}\", self),\n-        }\n-    }\n-\n-    fn capture(&self) -> Option<uint> {\n-        match *self {\n-            Paren(_, 0, _) => None,\n-            Paren(_, c, _) => Some(c),\n-            _ => panic!(\"Cannot get capture group from {:?}\", self),\n-        }\n-    }\n-\n-    fn capture_name(&self) -> Option<String> {\n-        match *self {\n-            Paren(_, 0, _) => None,\n-            Paren(_, _, ref name) => {\n-                if name.len() == 0 {\n-                    None\n-                } else {\n-                    Some(name.clone())\n-                }\n-            }\n-            _ => panic!(\"Cannot get capture name from {:?}\", self),\n-        }\n-    }\n-\n-    fn bar(&self) -> bool {\n-        match *self {\n-            Bar => true,\n-            _ => false,\n-        }\n-    }\n-\n-    fn unwrap(self) -> Result<Ast, Error> {\n-        match self {\n-            Expr(x) => Ok(x),\n-            _ => panic!(\"Tried to unwrap non-AST item: {:?}\", self),\n-        }\n-    }\n-}\n-\n-/// Flags represents all options that can be twiddled by a user in an\n-/// expression.\n-pub type Flags = u8;\n-\n-pub const FLAG_EMPTY:      u8 = 0;\n-pub const FLAG_NOCASE:     u8 = 1 << 0; // i\n-pub const FLAG_MULTI:      u8 = 1 << 1; // m\n-pub const FLAG_DOTNL:      u8 = 1 << 2; // s\n-pub const FLAG_SWAP_GREED: u8 = 1 << 3; // U\n-pub const FLAG_NEGATED:    u8 = 1 << 4; // char class or not word boundary\n-\n-struct Parser<'a> {\n-    // The input, parsed only as a sequence of UTF8 code points.\n-    chars: Vec<char>,\n-    // The index of the current character in the input.\n-    chari: uint,\n-    // The intermediate state representing the AST.\n-    stack: Vec<BuildAst>,\n-    // The current set of flags.\n-    flags: Flags,\n-    // The total number of capture groups.\n-    // Incremented each time an opening left paren is seen (assuming it is\n-    // opening a capture group).\n-    caps: uint,\n-    // A set of all capture group names used only to detect duplicates.\n-    names: Vec<String>,\n-}\n-\n-pub fn parse(s: &str) -> Result<Ast, Error> {\n-    Parser {\n-        chars: s.chars().collect(),\n-        chari: 0,\n-        stack: vec!(),\n-        flags: FLAG_EMPTY,\n-        caps: 0,\n-        names: vec!(),\n-    }.parse()\n-}\n-\n-impl<'a> Parser<'a> {\n-    fn parse(&mut self) -> Result<Ast, Error> {\n-        if self.chars.len() == 0 {\n-            return Ok(Nothing);\n-        }\n-        loop {\n-            let c = self.cur();\n-            match c {\n-                '?' | '*' | '+' => try!(self.push_repeater(c)),\n-                '\\\\' => {\n-                    let ast = try!(self.parse_escape());\n-                    self.push(ast)\n-                }\n-                '{' => try!(self.parse_counted()),\n-                '[' => match self.try_parse_ascii() {\n-                    None => try!(self.parse_class()),\n-                    Some(class) => self.push(class),\n-                },\n-                '(' => {\n-                    if self.peek_is(1, '?') {\n-                        try!(self.expect('?'));\n-                        try!(self.parse_group_opts())\n-                    } else {\n-                        self.caps += 1;\n-                        self.stack.push(Paren(self.flags,\n-                                              self.caps,\n-                                              \"\".to_string()))\n-                    }\n-                }\n-                ')' => {\n-                    let catfrom = try!(\n-                        self.pos_last(false, |x| x.paren() || x.bar()));\n-                    try!(self.concat(catfrom));\n-\n-                    let altfrom = try!(self.pos_last(false, |x| x.paren()));\n-                    // Before we smush the alternates together and pop off the\n-                    // left paren, let's grab the old flags and see if we\n-                    // need a capture.\n-                    let (cap, cap_name, oldflags) = {\n-                        let paren = &self.stack[altfrom-1];\n-                        (paren.capture(), paren.capture_name(), paren.flags())\n-                    };\n-                    try!(self.alternate(altfrom));\n-                    self.flags = oldflags;\n-\n-                    // If this was a capture, pop what we just pushed in\n-                    // alternate and make it a capture.\n-                    if cap.is_some() {\n-                        let ast = try!(self.pop_ast());\n-                        self.push(Capture(cap.unwrap(), cap_name, box ast));\n-                    }\n-                }\n-                '|' => {\n-                    let catfrom = try!(\n-                        self.pos_last(true, |x| x.paren() || x.bar()));\n-                    try!(self.concat(catfrom));\n-\n-                    self.stack.push(Bar);\n-                }\n-                _ => try!(self.push_literal(c)),\n-            }\n-            if !self.next_char() {\n-                break\n-            }\n-        }\n-\n-        // Try to improve error handling. At this point, there should be\n-        // no remaining open parens.\n-        if self.stack.iter().any(|x| x.paren()) {\n-            return self.err(\"Unclosed parenthesis.\")\n-        }\n-        let catfrom = try!(self.pos_last(true, |x| x.bar()));\n-        try!(self.concat(catfrom));\n-        try!(self.alternate(0));\n-\n-        assert!(self.stack.len() == 1);\n-        self.pop_ast()\n-    }\n-\n-    fn noteof(&mut self, expected: &str) -> Result<(), Error> {\n-        match self.next_char() {\n-            true => Ok(()),\n-            false => {\n-                self.err(&format!(\"Expected {:?} but got EOF.\",\n-                                  expected)[])\n-            }\n-        }\n-    }\n-\n-    fn expect(&mut self, expected: char) -> Result<(), Error> {\n-        match self.next_char() {\n-            true if self.cur() == expected => Ok(()),\n-            true => self.err(&format!(\"Expected '{:?}' but got '{:?}'.\",\n-                                      expected, self.cur())[]),\n-            false => {\n-                self.err(&format!(\"Expected '{:?}' but got EOF.\",\n-                                  expected)[])\n-            }\n-        }\n-    }\n-\n-    fn next_char(&mut self) -> bool {\n-        self.chari += 1;\n-        self.chari < self.chars.len()\n-    }\n-\n-    fn pop_ast(&mut self) -> Result<Ast, Error> {\n-        match self.stack.pop().unwrap().unwrap() {\n-            Err(e) => Err(e),\n-            Ok(ast) => Ok(ast),\n-        }\n-    }\n-\n-    fn push(&mut self, ast: Ast) {\n-        self.stack.push(Expr(ast))\n-    }\n-\n-    fn push_repeater(&mut self, c: char) -> Result<(), Error> {\n-        match self.stack.last() {\n-            Some(&Expr(..)) => (),\n-            // self.stack is empty, or the top item is not an Expr\n-            _ => return self.err(\"A repeat operator must be preceded by a valid expression.\"),\n-        }\n-        let rep: Repeater = match c {\n-            '?' => ZeroOne, '*' => ZeroMore, '+' => OneMore,\n-            _ => panic!(\"Not a valid repeater operator.\"),\n-        };\n-\n-        match self.peek(1) {\n-            Some('*') | Some('+') =>\n-                return self.err(\n-                    \"Double repeat operators are not supported.\"),\n-            _ => {},\n-        }\n-        let ast = try!(self.pop_ast());\n-        match ast {\n-            Begin(_) | End(_) | WordBoundary(_) =>\n-                return self.err(\n-                    \"Repeat arguments cannot be empty width assertions.\"),\n-            _ => {}\n-        }\n-        let greed = try!(self.get_next_greedy());\n-        self.push(Rep(box ast, rep, greed));\n-        Ok(())\n-    }\n-\n-    fn push_literal(&mut self, c: char) -> Result<(), Error> {\n-        let flags = self.flags;\n-        match c {\n-            '.' => {\n-                self.push(Dot(flags))\n-            }\n-            '^' => {\n-                self.push(Begin(flags))\n-            }\n-            '$' => {\n-                self.push(End(flags))\n-            }\n-            _ => {\n-                self.push(Literal(c, flags))\n-            }\n-        }\n-        Ok(())\n-    }\n-\n-    // Parses all forms of character classes.\n-    // Assumes that '[' is the current character.\n-    fn parse_class(&mut self) -> Result<(), Error> {\n-        let negated =\n-            if self.peek_is(1, '^') {\n-                try!(self.expect('^'));\n-                FLAG_NEGATED\n-            } else {\n-                FLAG_EMPTY\n-            };\n-        let mut ranges: Vec<(char, char)> = vec!();\n-        let mut alts: Vec<Ast> = vec!();\n-\n-        while self.peek_is(1, '-') {\n-            try!(self.expect('-'));\n-            ranges.push(('-', '-'))\n-        }\n-        loop {\n-            try!(self.noteof(\"a closing ']' or a non-empty character class)\"));\n-            let mut c = self.cur();\n-            match c {\n-                '[' =>\n-                    match self.try_parse_ascii() {\n-                        Some(AstClass(asciis, flags)) => {\n-                            alts.push(AstClass(asciis, flags ^ negated));\n-                            continue\n-                        }\n-                        Some(ast) =>\n-                            panic!(\"Expected Class AST but got '{:?}'\", ast),\n-                        // Just drop down and try to add as a regular character.\n-                        None => {},\n-                    },\n-                '\\\\' => {\n-                    match try!(self.parse_escape()) {\n-                        AstClass(asciis, flags) => {\n-                            alts.push(AstClass(asciis, flags ^ negated));\n-                            continue\n-                        }\n-                        Literal(c2, _) => c = c2, // process below\n-                        Begin(_) | End(_) | WordBoundary(_) =>\n-                            return self.err(\n-                                \"\\\\A, \\\\z, \\\\b and \\\\B are not valid escape \\\n-                                 sequences inside a character class.\"),\n-                        ast => panic!(\"Unexpected AST item '{:?}'\", ast),\n-                    }\n-                }\n-                ']' if ranges.len() > 0 || alts.len() > 0 => {\n-                    if ranges.len() > 0 {\n-                        let flags = negated | (self.flags & FLAG_NOCASE);\n-                        let mut ast = AstClass(combine_ranges(ranges), flags);\n-                        for alt in alts.into_iter() {\n-                            ast = Alt(box alt, box ast)\n-                        }\n-                        self.push(ast);\n-                    } else if alts.len() > 0 {\n-                        let mut ast = alts.pop().unwrap();\n-                        for alt in alts.into_iter() {\n-                            ast = Alt(box alt, box ast)\n-                        }\n-                        self.push(ast);\n-                    }\n-                    return Ok(())\n-                }\n-                _ => {}\n-            }\n-\n-            if self.peek_is(1, '-') && !self.peek_is(2, ']') {\n-                try!(self.expect('-'));\n-                // The regex can't end here.\n-                try!(self.noteof(\"not a ']'\"));\n-                // End the range with a single character or character escape.\n-                let mut c2 = self.cur();\n-                if c2 == '\\\\' {\n-                    match try!(self.parse_escape()) {\n-                        Literal(c3, _) => c2 = c3, // allow literal escapes below\n-                        ast =>\n-                            return self.err(&format!(\"Expected a literal, but got {:?}.\",\n-                                                     ast)[]),\n-                    }\n-                }\n-                if c2 < c {\n-                    return self.err(&format!(\"Invalid character class \\\n-                                              range '{}-{}'\",\n-                                             c,\n-                                             c2)[])\n-                }\n-                ranges.push((c, self.cur()))\n-            } else {\n-                ranges.push((c, c))\n-            }\n-        }\n-    }\n-\n-    // Tries to parse an ASCII character class of the form [:name:].\n-    // If successful, returns an AST character class corresponding to name\n-    // and moves the parser to the final ']' character.\n-    // If unsuccessful, no state is changed and None is returned.\n-    // Assumes that '[' is the current character.\n-    fn try_parse_ascii(&mut self) -> Option<Ast> {\n-        if !self.peek_is(1, ':') {\n-            return None\n-        }\n-        let closer =\n-            match self.pos(']') {\n-                Some(i) => i,\n-                None => return None,\n-            };\n-        if self.chars[closer-1] != ':' {\n-            return None\n-        }\n-        if closer - self.chari <= 3 {\n-            return None\n-        }\n-        let mut name_start = self.chari + 2;\n-        let negated =\n-            if self.peek_is(2, '^') {\n-                name_start += 1;\n-                FLAG_NEGATED\n-            } else {\n-                FLAG_EMPTY\n-            };\n-        let name = self.slice(name_start, closer - 1);\n-        match find_class(ASCII_CLASSES, &name[]) {\n-            None => None,\n-            Some(ranges) => {\n-                self.chari = closer;\n-                let flags = negated | (self.flags & FLAG_NOCASE);\n-                Some(AstClass(combine_ranges(ranges), flags))\n-            }\n-        }\n-    }\n-\n-    // Parses counted repetition. Supports:\n-    // {n}, {n,}, {n,m}, {n}?, {n,}? and {n,m}?\n-    // Assumes that '{' is the current character.\n-    // Returns either an error or moves the parser to the final '}' character.\n-    // (Or the '?' character if not greedy.)\n-    fn parse_counted(&mut self) -> Result<(), Error> {\n-        // Scan until the closing '}' and grab the stuff in {}.\n-        let start = self.chari;\n-        let closer =\n-            match self.pos('}') {\n-                Some(i) => i,\n-                None => {\n-                    return self.err(&format!(\"No closing brace for counted \\\n-                                              repetition starting at position \\\n-                                              {:?}.\",\n-                                             start)[])\n-                }\n-            };\n-        self.chari = closer;\n-        let greed = try!(self.get_next_greedy());\n-        let inner = self.chars[start+1..closer].iter().cloned()\n-                                               .collect::<String>();\n-\n-        // Parse the min and max values from the regex.\n-        let (mut min, mut max): (uint, Option<uint>);\n-        if !inner.contains(\",\") {\n-            min = try!(self.parse_uint(&inner[]));\n-            max = Some(min);\n-        } else {\n-            let pieces: Vec<&str> = inner.splitn(1, ',').collect();\n-            let (smin, smax) = (pieces[0], pieces[1]);\n-            if smin.len() == 0 {\n-                return self.err(\"Max repetitions cannot be specified \\\n-                                    without min repetitions.\")\n-            }\n-            min = try!(self.parse_uint(smin));\n-            max =\n-                if smax.len() == 0 {\n-                    None\n-                } else {\n-                    Some(try!(self.parse_uint(smax)))\n-                };\n-        }\n-\n-        // Do some bounds checking and make sure max >= min.\n-        if min > MAX_REPEAT {\n-            return self.err(&format!(\n-                \"{} exceeds maximum allowed repetitions ({})\",\n-                min, MAX_REPEAT)[]);\n-        }\n-        if max.is_some() {\n-            let m = max.unwrap();\n-            if m > MAX_REPEAT {\n-                return self.err(&format!(\n-                    \"{} exceeds maximum allowed repetitions ({})\",\n-                    m, MAX_REPEAT)[]);\n-            }\n-            if m < min {\n-                return self.err(&format!(\n-                    \"Max repetitions ({}) cannot be smaller than min \\\n-                     repetitions ({}).\", m, min)[]);\n-            }\n-        }\n-\n-        // Now manipulate the AST be repeating elements.\n-        if max.is_none() {\n-            // Require N copies of what's on the stack and then repeat it.\n-            let ast = try!(self.pop_ast());\n-            for _ in iter::range(0, min) {\n-                self.push(ast.clone())\n-            }\n-            self.push(Rep(box ast, ZeroMore, greed));\n-        } else {\n-            // Require N copies of what's on the stack and then repeat it\n-            // up to M times optionally.\n-            let ast = try!(self.pop_ast());\n-            for _ in iter::range(0, min) {\n-                self.push(ast.clone())\n-            }\n-            if max.is_some() {\n-                for _ in iter::range(min, max.unwrap()) {\n-                    self.push(Rep(box ast.clone(), ZeroOne, greed))\n-                }\n-            }\n-            // It's possible that we popped something off the stack but\n-            // never put anything back on it. To keep things simple, add\n-            // a no-op expression.\n-            if min == 0 && (max.is_none() || max == Some(0)) {\n-                self.push(Nothing)\n-            }\n-        }\n-        Ok(())\n-    }\n-\n-    // Parses all escape sequences.\n-    // Assumes that '\\' is the current character.\n-    fn parse_escape(&mut self) -> Result<Ast, Error> {\n-        try!(self.noteof(\"an escape sequence following a '\\\\'\"));\n-\n-        let c = self.cur();\n-        if is_punct(c) {\n-            return Ok(Literal(c, FLAG_EMPTY))\n-        }\n-        match c {\n-            'a' => Ok(Literal('\\x07', FLAG_EMPTY)),\n-            'f' => Ok(Literal('\\x0C', FLAG_EMPTY)),\n-            't' => Ok(Literal('\\t', FLAG_EMPTY)),\n-            'n' => Ok(Literal('\\n', FLAG_EMPTY)),\n-            'r' => Ok(Literal('\\r', FLAG_EMPTY)),\n-            'v' => Ok(Literal('\\x0B', FLAG_EMPTY)),\n-            'A' => Ok(Begin(FLAG_EMPTY)),\n-            'z' => Ok(End(FLAG_EMPTY)),\n-            'b' => Ok(WordBoundary(FLAG_EMPTY)),\n-            'B' => Ok(WordBoundary(FLAG_NEGATED)),\n-            '0'|'1'|'2'|'3'|'4'|'5'|'6'|'7' => Ok(try!(self.parse_octal())),\n-            'x' => Ok(try!(self.parse_hex())),\n-            'p' | 'P' => Ok(try!(self.parse_unicode_name())),\n-            'd' | 'D' | 's' | 'S' | 'w' | 'W' => {\n-                let ranges = perl_unicode_class(c);\n-                let mut flags = self.flags & FLAG_NOCASE;\n-                if c.is_uppercase() { flags |= FLAG_NEGATED }\n-                Ok(AstClass(ranges, flags))\n-            }\n-            _ => {\n-                self.err(&format!(\"Invalid escape sequence '\\\\\\\\{}'\", c)[])\n-            }\n-        }\n-    }\n-\n-    // Parses a Unicode character class name, either of the form \\pF where\n-    // F is a one letter Unicode class name or of the form \\p{name} where\n-    // name is the Unicode class name.\n-    // Assumes that \\p or \\P has been read (and 'p' or 'P' is the current\n-    // character).\n-    fn parse_unicode_name(&mut self) -> Result<Ast, Error> {\n-        let negated = if self.cur() == 'P' { FLAG_NEGATED } else { FLAG_EMPTY };\n-        let mut name: String;\n-        if self.peek_is(1, '{') {\n-            try!(self.expect('{'));\n-            let closer =\n-                match self.pos('}') {\n-                    Some(i) => i,\n-                    None => return self.err(&format!(\n-                        \"Missing '}}' for unclosed '{{' at position {}\",\n-                        self.chari)[]),\n-                };\n-            if closer - self.chari + 1 == 0 {\n-                return self.err(\"No Unicode class name found.\")\n-            }\n-            name = self.slice(self.chari + 1, closer);\n-            self.chari = closer;\n-        } else {\n-            if self.chari + 1 >= self.chars.len() {\n-                return self.err(\"No single letter Unicode class name found.\")\n-            }\n-            name = self.slice(self.chari + 1, self.chari + 2);\n-            self.chari += 1;\n-        }\n-        match find_class(UNICODE_CLASSES, &name[]) {\n-            None => {\n-                return self.err(&format!(\"Could not find Unicode class '{}'\",\n-                                        name)[])\n-            }\n-            Some(ranges) => {\n-                Ok(AstClass(ranges, negated | (self.flags & FLAG_NOCASE)))\n-            }\n-        }\n-    }\n-\n-    // Parses an octal number, up to 3 digits.\n-    // Assumes that \\n has been read, where n is the first digit.\n-    fn parse_octal(&mut self) -> Result<Ast, Error> {\n-        let start = self.chari;\n-        let mut end = start + 1;\n-        let (d2, d3) = (self.peek(1), self.peek(2));\n-        if d2 >= Some('0') && d2 <= Some('7') {\n-            try!(self.noteof(\"expected octal character in [0-7]\"));\n-            end += 1;\n-            if d3 >= Some('0') && d3 <= Some('7') {\n-                try!(self.noteof(\"expected octal character in [0-7]\"));\n-                end += 1;\n-            }\n-        }\n-        let s = self.slice(start, end);\n-        match num::from_str_radix::<u32>(&s[], 8) {\n-            Some(n) => Ok(Literal(try!(self.char_from_u32(n)), FLAG_EMPTY)),\n-            None => {\n-                self.err(&format!(\"Could not parse '{:?}' as octal number.\",\n-                                 s)[])\n-            }\n-        }\n-    }\n-\n-    // Parse a hex number. Either exactly two digits or anything in {}.\n-    // Assumes that \\x has been read.\n-    fn parse_hex(&mut self) -> Result<Ast, Error> {\n-        if !self.peek_is(1, '{') {\n-            try!(self.expect('{'));\n-            return self.parse_hex_two()\n-        }\n-        let start = self.chari + 2;\n-        let closer =\n-            match self.pos('}') {\n-                None => {\n-                    return self.err(&format!(\"Missing '}}' for unclosed \\\n-                                             '{{' at position {}\",\n-                                            start)[])\n-                }\n-                Some(i) => i,\n-            };\n-        self.chari = closer;\n-        self.parse_hex_digits(&self.slice(start, closer)[])\n-    }\n-\n-    // Parses a two-digit hex number.\n-    // Assumes that \\xn has been read, where n is the first digit and is the\n-    // current character.\n-    // After return, parser will point at the second digit.\n-    fn parse_hex_two(&mut self) -> Result<Ast, Error> {\n-        let (start, end) = (self.chari, self.chari + 2);\n-        let bad = self.slice(start - 2, self.chars.len());\n-        try!(self.noteof(format!(\"Invalid hex escape sequence '{}'\",\n-                                 bad).as_slice()));\n-        self.parse_hex_digits(self.slice(start, end).as_slice())\n-    }\n-\n-    // Parses `s` as a hexadecimal number.\n-    fn parse_hex_digits(&self, s: &str) -> Result<Ast, Error> {\n-        match num::from_str_radix::<u32>(s, 16) {\n-            Some(n) => Ok(Literal(try!(self.char_from_u32(n)), FLAG_EMPTY)),\n-            None => {\n-                self.err(&format!(\"Could not parse '{}' as hex number.\", s)[])\n-            }\n-        }\n-    }\n-\n-    // Parses a named capture.\n-    // Assumes that '(?P<' has been consumed and that the current character\n-    // is '<'.\n-    // When done, parser will be at the closing '>' character.\n-    fn parse_named_capture(&mut self) -> Result<(), Error> {\n-        try!(self.noteof(\"a capture name\"));\n-        let closer =\n-            match self.pos('>') {\n-                Some(i) => i,\n-                None => return self.err(\"Capture name must end with '>'.\"),\n-            };\n-        if closer - self.chari == 0 {\n-            return self.err(\"Capture names must have at least 1 character.\")\n-        }\n-        let name = self.slice(self.chari, closer);\n-        if !name.chars().all(is_valid_cap) {\n-            return self.err(\n-                \"Capture names can only have underscores, letters and digits.\")\n-        }\n-        if self.names.contains(&name) {\n-            return self.err(&format!(\"Duplicate capture group name '{}'.\",\n-                                    name)[])\n-        }\n-        self.names.push(name.clone());\n-        self.chari = closer;\n-        self.caps += 1;\n-        self.stack.push(Paren(self.flags, self.caps, name));\n-        Ok(())\n-    }\n-\n-    // Parses non-capture groups and options.\n-    // Assumes that '(?' has already been consumed and '?' is the current\n-    // character.\n-    fn parse_group_opts(&mut self) -> Result<(), Error> {\n-        if self.peek_is(1, 'P') && self.peek_is(2, '<') {\n-            try!(self.expect('P'));\n-            try!(self.expect('<'));\n-            return self.parse_named_capture()\n-        }\n-        let start = self.chari;\n-        let mut flags = self.flags;\n-        let mut sign = 1i;\n-        let mut saw_flag = false;\n-        loop {\n-            try!(self.noteof(\n-                    \"expected non-empty set of flags or closing ')'\"));\n-            match self.cur() {\n-                'i' => { flags = flags | FLAG_NOCASE;     saw_flag = true},\n-                'm' => { flags = flags | FLAG_MULTI;      saw_flag = true},\n-                's' => { flags = flags | FLAG_DOTNL;      saw_flag = true},\n-                'U' => { flags = flags | FLAG_SWAP_GREED; saw_flag = true},\n-                '-' => {\n-                    if sign < 0 {\n-                        return self.err(&format!(\n-                            \"Cannot negate flags twice in '{}'.\",\n-                            self.slice(start, self.chari + 1))[])\n-                    }\n-                    sign = -1;\n-                    saw_flag = false;\n-                    flags = flags ^ flags;\n-                }\n-                ':' | ')' => {\n-                    if sign < 0 {\n-                        if !saw_flag {\n-                            return self.err(&format!(\n-                                \"A valid flag does not follow negation in '{}'\",\n-                                self.slice(start, self.chari + 1))[])\n-                        }\n-                        flags = flags ^ flags;\n-                    }\n-                    if self.cur() == ':' {\n-                        // Save the old flags with the opening paren.\n-                        self.stack.push(Paren(self.flags, 0, \"\".to_string()));\n-                    }\n-                    self.flags = flags;\n-                    return Ok(())\n-                }\n-                _ => return self.err(&format!(\n-                    \"Unrecognized flag '{}'.\", self.cur())[]),\n-            }\n-        }\n-    }\n-\n-    // Peeks at the next character and returns whether it's ungreedy or not.\n-    // If it is, then the next character is consumed.\n-    fn get_next_greedy(&mut self) -> Result<Greed, Error> {\n-        Ok(if self.peek_is(1, '?') {\n-            try!(self.expect('?'));\n-            Ungreedy\n-        } else {\n-            Greedy\n-        }.swap(self.flags & FLAG_SWAP_GREED > 0))\n-    }\n-\n-    // Searches the stack (starting at the top) until it finds an expression\n-    // for which `pred` returns true. The index of that expression in the\n-    // stack is returned.\n-    // If there's no match, then one of two things happens depending on the\n-    // values of `allow_start`. When it's true, then `0` will be returned.\n-    // Otherwise, an error will be returned.\n-    // Generally, `allow_start` is only true when you're *not* expecting an\n-    // opening parenthesis.\n-    fn pos_last<P>(&self, allow_start: bool, pred: P) -> Result<uint, Error> where\n-        P: FnMut(&BuildAst) -> bool,\n-   {\n-        let from = match self.stack.iter().rev().position(pred) {\n-            Some(i) => i,\n-            None => {\n-                if allow_start {\n-                    self.stack.len()\n-                } else {\n-                    return self.err(\"No matching opening parenthesis.\")\n-                }\n-            }\n-        };\n-        // Adjust index since 'from' is for the reversed stack.\n-        // Also, don't include the '(' or '|'.\n-        Ok(self.stack.len() - from)\n-    }\n-\n-    // concat starts at `from` in the parser's stack and concatenates all\n-    // expressions up to the top of the stack. The resulting concatenation is\n-    // then pushed on to the stack.\n-    // Usually `from` corresponds to the position of an opening parenthesis,\n-    // a '|' (alternation) or the start of the entire expression.\n-    fn concat(&mut self, from: uint) -> Result<(), Error> {\n-        let ast = try!(self.build_from(from, concat_flatten));\n-        self.push(ast);\n-        Ok(())\n-    }\n-\n-    // concat starts at `from` in the parser's stack and alternates all\n-    // expressions up to the top of the stack. The resulting alternation is\n-    // then pushed on to the stack.\n-    // Usually `from` corresponds to the position of an opening parenthesis\n-    // or the start of the entire expression.\n-    // This will also drop any opening parens or alternation bars found in\n-    // the intermediate AST.\n-    fn alternate(&mut self, mut from: uint) -> Result<(), Error> {\n-        // Unlike in the concatenation case, we want 'build_from' to continue\n-        // all the way to the opening left paren (so it will be popped off and\n-        // thrown away). But be careful with overflow---we can't count on the\n-        // open paren to be there.\n-        if from > 0 { from = from - 1}\n-        let ast = try!(self.build_from(from, |l,r| Alt(box l, box r)));\n-        self.push(ast);\n-        Ok(())\n-    }\n-\n-    // build_from combines all AST elements starting at 'from' in the\n-    // parser's stack using 'mk' to combine them. If any such element is not an\n-    // AST then it is popped off the stack and ignored.\n-    fn build_from<F>(&mut self, from: uint, mut mk: F) -> Result<Ast, Error> where\n-        F: FnMut(Ast, Ast) -> Ast,\n-    {\n-        if from >= self.stack.len() {\n-            return self.err(\"Empty group or alternate not allowed.\")\n-        }\n-\n-        let mut combined = try!(self.pop_ast());\n-        let mut i = self.stack.len();\n-        while i > from {\n-            i = i - 1;\n-            match self.stack.pop().unwrap() {\n-                Expr(x) => combined = mk(x, combined),\n-                _ => {},\n-            }\n-        }\n-        Ok(combined)\n-    }\n-\n-    fn parse_uint(&self, s: &str) -> Result<uint, Error> {\n-        match s.parse::<uint>() {\n-            Some(i) => Ok(i),\n-            None => {\n-                self.err(&format!(\"Expected an unsigned integer but got '{}'.\",\n-                                 s)[])\n-            }\n-        }\n-    }\n-\n-    fn char_from_u32(&self, n: u32) -> Result<char, Error> {\n-        match char::from_u32(n) {\n-            Some(c) => Ok(c),\n-            None => {\n-                self.err(&format!(\"Could not decode '{}' to unicode \\\n-                                  character.\", n)[])\n-            }\n-        }\n-    }\n-\n-    fn pos(&self, c: char) -> Option<uint> {\n-        self.chars.iter()\n-            .skip(self.chari).position(|&c2| c2 == c).map(|i| self.chari + i)\n-    }\n-\n-    fn err<T>(&self, msg: &str) -> Result<T, Error> {\n-        Err(Error {\n-            pos: self.chari,\n-            msg: msg.to_string(),\n-        })\n-    }\n-\n-    fn peek(&self, offset: uint) -> Option<char> {\n-        if self.chari + offset >= self.chars.len() {\n-            return None\n-        }\n-        Some(self.chars[self.chari + offset])\n-    }\n-\n-    fn peek_is(&self, offset: uint, is: char) -> bool {\n-        self.peek(offset) == Some(is)\n-    }\n-\n-    fn cur(&self) -> char {\n-        self.chars[self.chari]\n-    }\n-\n-    fn slice(&self, start: uint, end: uint) -> String {\n-        self.chars[start..end].iter().cloned().collect()\n-    }\n-}\n-\n-// Given an unordered collection of character ranges, combine_ranges returns\n-// an ordered sequence of character ranges where no two ranges overlap. They\n-// are ordered from least to greatest (using start position).\n-fn combine_ranges(unordered: Vec<(char, char)>) -> Vec<(char, char)> {\n-    // Returns true iff the two character classes overlap or share a boundary.\n-    // e.g., ('a', 'g') and ('h', 'm') would return true.\n-    fn should_merge((a, b): (char, char), (x, y): (char, char)) -> bool {\n-        cmp::max(a, x) as u32 <= cmp::min(b, y) as u32 + 1\n-    }\n-\n-    // This is currently O(n^2), but I think with sufficient cleverness,\n-    // it can be reduced to O(n) **if necessary**.\n-    let mut ordered: Vec<(char, char)> = Vec::with_capacity(unordered.len());\n-    for (us, ue) in unordered.into_iter() {\n-        let (mut us, mut ue) = (us, ue);\n-        assert!(us <= ue);\n-        let mut which: Option<uint> = None;\n-        for (i, &(os, oe)) in ordered.iter().enumerate() {\n-            if should_merge((us, ue), (os, oe)) {\n-                us = cmp::min(us, os);\n-                ue = cmp::max(ue, oe);\n-                which = Some(i);\n-                break\n-            }\n-        }\n-        match which {\n-            None => ordered.push((us, ue)),\n-            Some(i) => ordered[i] = (us, ue),\n-        }\n-    }\n-    ordered.sort();\n-    ordered\n-}\n-\n-// Constructs a Unicode friendly Perl character class from \\d, \\s or \\w\n-// (or any of their negated forms). Note that this does not handle negation.\n-fn perl_unicode_class(which: char) -> Vec<(char, char)> {\n-    match which.to_lowercase() {\n-        'd' => PERLD.to_vec(),\n-        's' => PERLS.to_vec(),\n-        'w' => PERLW.to_vec(),\n-        _ => unreachable!(),\n-    }\n-}\n-\n-// Returns a concatenation of two expressions. This also guarantees that a\n-// `Cat` expression will never be a direct child of another `Cat` expression.\n-fn concat_flatten(x: Ast, y: Ast) -> Ast {\n-    match (x, y) {\n-        (Cat(mut xs), Cat(ys)) => { xs.extend(ys.into_iter()); Cat(xs) }\n-        (Cat(mut xs), ast) => { xs.push(ast); Cat(xs) }\n-        (ast, Cat(mut xs)) => { xs.insert(0, ast); Cat(xs) }\n-        (ast1, ast2) => Cat(vec!(ast1, ast2)),\n-    }\n-}\n-\n-pub fn is_punct(c: char) -> bool {\n-    match c {\n-        '\\\\' | '.' | '+' | '*' | '?' | '(' | ')' | '|' |\n-        '[' | ']' | '{' | '}' | '^' | '$' => true,\n-        _ => false,\n-    }\n-}\n-\n-fn is_valid_cap(c: char) -> bool {\n-    c == '_' || (c >= '0' && c <= '9')\n-    || (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')\n-}\n-\n-fn find_class(classes: NamedClasses, name: &str) -> Option<Vec<(char, char)>> {\n-    match classes.binary_search_by(|&(s, _)| s.cmp(name)) {\n-        Ok(i) => Some(classes[i].1.to_vec()),\n-        Err(_) => None,\n-    }\n-}\n-\n-type Class = &'static [(char, char)];\n-type NamedClasses = &'static [(&'static str, &'static Class)];\n-\n-static ASCII_CLASSES: NamedClasses = &[\n-    // Classes must be in alphabetical order so that bsearch works.\n-    // [:alnum:]      alphanumeric (== [0-9A-Za-z])\n-    // [:alpha:]      alphabetic (== [A-Za-z])\n-    // [:ascii:]      ASCII (== [\\x00-\\x7F])\n-    // [:blank:]      blank (== [\\t ])\n-    // [:cntrl:]      control (== [\\x00-\\x1F\\x7F])\n-    // [:digit:]      digits (== [0-9])\n-    // [:graph:]      graphical (== [!-~])\n-    // [:lower:]      lower case (== [a-z])\n-    // [:print:]      printable (== [ -~] == [ [:graph:]])\n-    // [:punct:]      punctuation (== [!-/:-@[-`{-~])\n-    // [:space:]      whitespace (== [\\t\\n\\v\\f\\r ])\n-    // [:upper:]      upper case (== [A-Z])\n-    // [:word:]       word characters (== [0-9A-Za-z_])\n-    // [:xdigit:]     hex digit (== [0-9A-Fa-f])\n-    // Taken from: http://golang.org/pkg/regex/syntax/\n-    (\"alnum\", &ALNUM),\n-    (\"alpha\", &ALPHA),\n-    (\"ascii\", &ASCII),\n-    (\"blank\", &BLANK),\n-    (\"cntrl\", &CNTRL),\n-    (\"digit\", &DIGIT),\n-    (\"graph\", &GRAPH),\n-    (\"lower\", &LOWER),\n-    (\"print\", &PRINT),\n-    (\"punct\", &PUNCT),\n-    (\"space\", &SPACE),\n-    (\"upper\", &UPPER),\n-    (\"word\", &WORD),\n-    (\"xdigit\", &XDIGIT),\n-];\n-\n-static ALNUM: Class = &[('0', '9'), ('A', 'Z'), ('a', 'z')];\n-static ALPHA: Class = &[('A', 'Z'), ('a', 'z')];\n-static ASCII: Class = &[('\\x00', '\\x7F')];\n-static BLANK: Class = &[(' ', ' '), ('\\t', '\\t')];\n-static CNTRL: Class = &[('\\x00', '\\x1F'), ('\\x7F', '\\x7F')];\n-static DIGIT: Class = &[('0', '9')];\n-static GRAPH: Class = &[('!', '~')];\n-static LOWER: Class = &[('a', 'z')];\n-static PRINT: Class = &[(' ', '~')];\n-static PUNCT: Class = &[('!', '/'), (':', '@'), ('[', '`'), ('{', '~')];\n-static SPACE: Class = &[('\\t', '\\t'), ('\\n', '\\n'), ('\\x0B', '\\x0B'),\n-                        ('\\x0C', '\\x0C'), ('\\r', '\\r'), (' ', ' ')];\n-static UPPER: Class = &[('A', 'Z')];\n-static WORD: Class = &[('0', '9'), ('A', 'Z'), ('a', 'z'), ('_', '_')];\n-static XDIGIT: Class = &[('0', '9'), ('A', 'F'), ('a', 'f')];"}, {"sha": "1b68ad500caa57820d936bfcd33831bb60faef03", "filename": "src/libregex/re.rs", "status": "removed", "additions": 0, "deletions": 684, "changes": 684, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fre.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fre.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fre.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,684 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-pub use self::NamesIter::*;\n-pub use self::Regex::*;\n-\n-use std::borrow::IntoCow;\n-use std::collections::HashMap;\n-use std::fmt;\n-use std::string::CowString;\n-\n-use compile::Program;\n-use parse;\n-use vm;\n-use vm::{CaptureLocs, MatchKind, Exists, Location, Submatches};\n-\n-/// Escapes all regular expression meta characters in `text`.\n-///\n-/// The string returned may be safely used as a literal in a regular\n-/// expression.\n-pub fn quote(text: &str) -> String {\n-    let mut quoted = String::with_capacity(text.len());\n-    for c in text.chars() {\n-        if parse::is_punct(c) {\n-            quoted.push('\\\\')\n-        }\n-        quoted.push(c);\n-    }\n-    quoted\n-}\n-\n-/// Tests if the given regular expression matches somewhere in the text given.\n-///\n-/// If there was a problem compiling the regular expression, an error is\n-/// returned.\n-///\n-/// To find submatches, split or replace text, you'll need to compile an\n-/// expression first.\n-///\n-/// Note that you should prefer the `regex!` macro when possible. For example,\n-/// `regex!(\"...\").is_match(\"...\")`.\n-pub fn is_match(regex: &str, text: &str) -> Result<bool, parse::Error> {\n-    Regex::new(regex).map(|r| r.is_match(text))\n-}\n-\n-/// A compiled regular expression\n-#[derive(Clone)]\n-pub enum Regex {\n-    // The representation of `Regex` is exported to support the `regex!`\n-    // syntax extension. Do not rely on it.\n-    //\n-    // See the comments for the `program` module in `lib.rs` for a more\n-    // detailed explanation for what `regex!` requires.\n-    #[doc(hidden)]\n-    Dynamic(ExDynamic),\n-    #[doc(hidden)]\n-    Native(ExNative),\n-}\n-\n-#[derive(Clone)]\n-#[doc(hidden)]\n-pub struct ExDynamic {\n-    original: String,\n-    names: Vec<Option<String>>,\n-    #[doc(hidden)]\n-    pub prog: Program\n-}\n-\n-#[doc(hidden)]\n-#[derive(Copy)]\n-pub struct ExNative {\n-    #[doc(hidden)]\n-    pub original: &'static str,\n-    #[doc(hidden)]\n-    pub names: &'static &'static [Option<&'static str>],\n-    #[doc(hidden)]\n-    pub prog: fn(MatchKind, &str, uint, uint) -> Vec<Option<uint>>\n-}\n-\n-impl Clone for ExNative {\n-    fn clone(&self) -> ExNative {\n-        *self\n-    }\n-}\n-\n-impl fmt::Display for Regex {\n-    /// Shows the original regular expression.\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        fmt::Display::fmt(self.as_str(), f)\n-    }\n-}\n-\n-impl Regex {\n-    /// Compiles a dynamic regular expression. Once compiled, it can be\n-    /// used repeatedly to search, split or replace text in a string.\n-    ///\n-    /// When possible, you should prefer the `regex!` macro since it is\n-    /// safer and always faster.\n-    ///\n-    /// If an invalid expression is given, then an error is returned.\n-    pub fn new(re: &str) -> Result<Regex, parse::Error> {\n-        let ast = try!(parse::parse(re));\n-        let (prog, names) = Program::new(ast);\n-        Ok(Dynamic(ExDynamic {\n-            original: re.to_string(),\n-            names: names,\n-            prog: prog,\n-        }))\n-    }\n-\n-    /// Returns true if and only if the regex matches the string given.\n-    pub fn is_match(&self, text: &str) -> bool {\n-        has_match(&exec(self, Exists, text))\n-    }\n-\n-    /// Returns the start and end byte range of the leftmost-first match in\n-    /// `text`. If no match exists, then `None` is returned.\n-    pub fn find(&self, text: &str) -> Option<(uint, uint)> {\n-        let caps = exec(self, Location, text);\n-        if has_match(&caps) {\n-            Some((caps[0].unwrap(), caps[1].unwrap()))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    /// Returns an iterator for each successive non-overlapping match in\n-    /// `text`, returning the start and end byte indices with respect to\n-    /// `text`.\n-    pub fn find_iter<'r, 't>(&'r self, text: &'t str) -> FindMatches<'r, 't> {\n-        FindMatches {\n-            re: self,\n-            search: text,\n-            last_end: 0,\n-            last_match: None,\n-        }\n-    }\n-\n-    /// Returns the capture groups corresponding to the leftmost-first\n-    /// match in `text`. Capture group `0` always corresponds to the entire\n-    /// match. If no match is found, then `None` is returned.\n-    ///\n-    /// You should only use `captures` if you need access to submatches.\n-    /// Otherwise, `find` is faster for discovering the location of the overall\n-    /// match.\n-    pub fn captures<'t>(&self, text: &'t str) -> Option<Captures<'t>> {\n-        let caps = exec(self, Submatches, text);\n-        Captures::new(self, text, caps)\n-    }\n-\n-    /// Returns an iterator over all the non-overlapping capture groups matched\n-    /// in `text`. This is operationally the same as `find_iter` (except it\n-    /// yields information about submatches).\n-    pub fn captures_iter<'r, 't>(&'r self, text: &'t str)\n-                                -> FindCaptures<'r, 't> {\n-        FindCaptures {\n-            re: self,\n-            search: text,\n-            last_match: None,\n-            last_end: 0,\n-        }\n-    }\n-\n-    /// Returns an iterator of substrings of `text` delimited by a match\n-    /// of the regular expression.\n-    /// Namely, each element of the iterator corresponds to text that *isn't*\n-    /// matched by the regular expression.\n-    ///\n-    /// This method will *not* copy the text given.\n-    pub fn split<'r, 't>(&'r self, text: &'t str) -> RegexSplits<'r, 't> {\n-        RegexSplits {\n-            finder: self.find_iter(text),\n-            last: 0,\n-        }\n-    }\n-\n-    /// Returns an iterator of at most `limit` substrings of `text` delimited\n-    /// by a match of the regular expression. (A `limit` of `0` will return no\n-    /// substrings.)\n-    /// Namely, each element of the iterator corresponds to text that *isn't*\n-    /// matched by the regular expression.\n-    /// The remainder of the string that is not split will be the last element\n-    /// in the iterator.\n-    ///\n-    /// This method will *not* copy the text given.\n-    pub fn splitn<'r, 't>(&'r self, text: &'t str, limit: uint)\n-                         -> RegexSplitsN<'r, 't> {\n-        RegexSplitsN {\n-            splits: self.split(text),\n-            cur: 0,\n-            limit: limit,\n-        }\n-    }\n-\n-    /// Replaces the leftmost-first match with the replacement provided.\n-    /// The replacement can be a regular string (where `$N` and `$name` are\n-    /// expanded to match capture groups) or a function that takes the matches'\n-    /// `Captures` and returns the replaced string.\n-    ///\n-    /// If no match is found, then a copy of the string is returned unchanged.\n-    pub fn replace<R: Replacer>(&self, text: &str, rep: R) -> String {\n-        self.replacen(text, 1, rep)\n-    }\n-\n-    /// Replaces all non-overlapping matches in `text` with the\n-    /// replacement provided. This is the same as calling `replacen` with\n-    /// `limit` set to `0`.\n-    ///\n-    /// See the documentation for `replace` for details on how to access\n-    /// submatches in the replacement string.\n-    pub fn replace_all<R: Replacer>(&self, text: &str, rep: R) -> String {\n-        self.replacen(text, 0, rep)\n-    }\n-\n-    /// Replaces at most `limit` non-overlapping matches in `text` with the\n-    /// replacement provided. If `limit` is 0, then all non-overlapping matches\n-    /// are replaced.\n-    ///\n-    /// See the documentation for `replace` for details on how to access\n-    /// submatches in the replacement string.\n-    pub fn replacen<R: Replacer>\n-                   (&self, text: &str, limit: uint, mut rep: R) -> String {\n-        let mut new = String::with_capacity(text.len());\n-        let mut last_match = 0u;\n-\n-        for (i, cap) in self.captures_iter(text).enumerate() {\n-            // It'd be nicer to use the 'take' iterator instead, but it seemed\n-            // awkward given that '0' => no limit.\n-            if limit > 0 && i >= limit {\n-                break\n-            }\n-\n-            let (s, e) = cap.pos(0).unwrap(); // captures only reports matches\n-            new.push_str(&text[last_match..s]);\n-            new.push_str(&rep.reg_replace(&cap)[]);\n-            last_match = e;\n-        }\n-        new.push_str(&text[last_match..text.len()]);\n-        return new;\n-    }\n-\n-    /// Returns the original string of this regex.\n-    pub fn as_str<'a>(&'a self) -> &'a str {\n-        match *self {\n-            Dynamic(ExDynamic { ref original, .. }) => &original[],\n-            Native(ExNative { ref original, .. }) => &original[],\n-        }\n-    }\n-\n-    #[doc(hidden)]\n-    #[unstable]\n-    pub fn names_iter<'a>(&'a self) -> NamesIter<'a> {\n-        match *self {\n-            Native(ref n) => NamesIterNative(n.names.iter()),\n-            Dynamic(ref d) => NamesIterDynamic(d.names.iter())\n-        }\n-    }\n-\n-    fn names_len(&self) -> uint {\n-        match *self {\n-            Native(ref n) => n.names.len(),\n-            Dynamic(ref d) => d.names.len()\n-        }\n-    }\n-\n-}\n-\n-#[derive(Clone)]\n-pub enum NamesIter<'a> {\n-    NamesIterNative(::std::slice::Iter<'a, Option<&'static str>>),\n-    NamesIterDynamic(::std::slice::Iter<'a, Option<String>>)\n-}\n-\n-impl<'a> Iterator for NamesIter<'a> {\n-    type Item = Option<String>;\n-\n-    fn next(&mut self) -> Option<Option<String>> {\n-        match *self {\n-            NamesIterNative(ref mut i) => i.next().map(|x| x.map(|s| s.to_string())),\n-            NamesIterDynamic(ref mut i) => i.next().map(|x| x.as_ref().map(|s| s.to_string())),\n-        }\n-    }\n-}\n-\n-/// NoExpand indicates literal string replacement.\n-///\n-/// It can be used with `replace` and `replace_all` to do a literal\n-/// string replacement without expanding `$name` to their corresponding\n-/// capture groups.\n-///\n-/// `'r` is the lifetime of the literal text.\n-pub struct NoExpand<'t>(pub &'t str);\n-\n-/// Replacer describes types that can be used to replace matches in a string.\n-pub trait Replacer {\n-    /// Returns a possibly owned string that is used to replace the match\n-    /// corresponding to the `caps` capture group.\n-    ///\n-    /// The `'a` lifetime refers to the lifetime of a borrowed string when\n-    /// a new owned string isn't needed (e.g., for `NoExpand`).\n-    fn reg_replace<'a>(&'a mut self, caps: &Captures) -> CowString<'a>;\n-}\n-\n-impl<'t> Replacer for NoExpand<'t> {\n-    fn reg_replace<'a>(&'a mut self, _: &Captures) -> CowString<'a> {\n-        let NoExpand(s) = *self;\n-        s.into_cow()\n-    }\n-}\n-\n-impl<'t> Replacer for &'t str {\n-    fn reg_replace<'a>(&'a mut self, caps: &Captures) -> CowString<'a> {\n-        caps.expand(*self).into_cow()\n-    }\n-}\n-\n-impl<F> Replacer for F where F: FnMut(&Captures) -> String {\n-    fn reg_replace<'a>(&'a mut self, caps: &Captures) -> CowString<'a> {\n-        (*self)(caps).into_cow()\n-    }\n-}\n-\n-/// Yields all substrings delimited by a regular expression match.\n-///\n-/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n-/// of the string being split.\n-#[derive(Clone)]\n-pub struct RegexSplits<'r, 't> {\n-    finder: FindMatches<'r, 't>,\n-    last: uint,\n-}\n-\n-impl<'r, 't> Iterator for RegexSplits<'r, 't> {\n-    type Item = &'t str;\n-\n-    fn next(&mut self) -> Option<&'t str> {\n-        let text = self.finder.search;\n-        match self.finder.next() {\n-            None => {\n-                if self.last >= text.len() {\n-                    None\n-                } else {\n-                    let s = &text[self.last..text.len()];\n-                    self.last = text.len();\n-                    Some(s)\n-                }\n-            }\n-            Some((s, e)) => {\n-                let matched = &text[self.last..s];\n-                self.last = e;\n-                Some(matched)\n-            }\n-        }\n-    }\n-}\n-\n-/// Yields at most `N` substrings delimited by a regular expression match.\n-///\n-/// The last substring will be whatever remains after splitting.\n-///\n-/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n-/// of the string being split.\n-#[derive(Clone)]\n-pub struct RegexSplitsN<'r, 't> {\n-    splits: RegexSplits<'r, 't>,\n-    cur: uint,\n-    limit: uint,\n-}\n-\n-impl<'r, 't> Iterator for RegexSplitsN<'r, 't> {\n-    type Item = &'t str;\n-\n-    fn next(&mut self) -> Option<&'t str> {\n-        let text = self.splits.finder.search;\n-        if self.cur >= self.limit {\n-            None\n-        } else {\n-            self.cur += 1;\n-            if self.cur >= self.limit {\n-                Some(&text[self.splits.last..text.len()])\n-            } else {\n-                self.splits.next()\n-            }\n-        }\n-    }\n-}\n-\n-/// Captures represents a group of captured strings for a single match.\n-///\n-/// The 0th capture always corresponds to the entire match. Each subsequent\n-/// index corresponds to the next capture group in the regex.\n-/// If a capture group is named, then the matched string is *also* available\n-/// via the `name` method. (Note that the 0th capture is always unnamed and so\n-/// must be accessed with the `at` method.)\n-///\n-/// Positions returned from a capture group are always byte indices.\n-///\n-/// `'t` is the lifetime of the matched text.\n-pub struct Captures<'t> {\n-    text: &'t str,\n-    locs: CaptureLocs,\n-    named: Option<HashMap<String, uint>>,\n-}\n-\n-impl<'t> Captures<'t> {\n-    #[allow(unstable)]\n-    fn new(re: &Regex, search: &'t str, locs: CaptureLocs)\n-          -> Option<Captures<'t>> {\n-        if !has_match(&locs) {\n-            return None\n-        }\n-\n-        let named =\n-            if re.names_len() == 0 {\n-                None\n-            } else {\n-                let mut named = HashMap::new();\n-                for (i, name) in re.names_iter().enumerate() {\n-                    match name {\n-                        None => {},\n-                        Some(name) => {\n-                            named.insert(name, i);\n-                        }\n-                    }\n-                }\n-                Some(named)\n-            };\n-        Some(Captures {\n-            text: search,\n-            locs: locs,\n-            named: named,\n-        })\n-    }\n-\n-    /// Returns the start and end positions of the Nth capture group.\n-    /// Returns `None` if `i` is not a valid capture group or if the capture\n-    /// group did not match anything.\n-    /// The positions returned are *always* byte indices with respect to the\n-    /// original string matched.\n-    pub fn pos(&self, i: uint) -> Option<(uint, uint)> {\n-        let (s, e) = (i * 2, i * 2 + 1);\n-        if e >= self.locs.len() || self.locs[s].is_none() {\n-            // VM guarantees that each pair of locations are both Some or None.\n-            return None\n-        }\n-        Some((self.locs[s].unwrap(), self.locs[e].unwrap()))\n-    }\n-\n-    /// Returns the matched string for the capture group `i`.  If `i` isn't\n-    /// a valid capture group or didn't match anything, then `None` is\n-    /// returned.\n-    pub fn at(&self, i: uint) -> Option<&'t str> {\n-        match self.pos(i) {\n-            None => None,\n-            Some((s, e)) => Some(&self.text[s.. e])\n-        }\n-    }\n-\n-    /// Returns the matched string for the capture group named `name`.  If\n-    /// `name` isn't a valid capture group or didn't match anything, then\n-    /// `None` is returned.\n-    pub fn name(&self, name: &str) -> Option<&'t str> {\n-        match self.named {\n-            None => None,\n-            Some(ref h) => {\n-                match h.get(name) {\n-                    None => None,\n-                    Some(i) => self.at(*i),\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Creates an iterator of all the capture groups in order of appearance\n-    /// in the regular expression.\n-    pub fn iter(&'t self) -> SubCaptures<'t> {\n-        SubCaptures { idx: 0, caps: self, }\n-    }\n-\n-    /// Creates an iterator of all the capture group positions in order of\n-    /// appearance in the regular expression. Positions are byte indices\n-    /// in terms of the original string matched.\n-    pub fn iter_pos(&'t self) -> SubCapturesPos<'t> {\n-        SubCapturesPos { idx: 0, caps: self, }\n-    }\n-\n-    /// Expands all instances of `$name` in `text` to the corresponding capture\n-    /// group `name`.\n-    ///\n-    /// `name` may be an integer corresponding to the index of the\n-    /// capture group (counted by order of opening parenthesis where `0` is the\n-    /// entire match) or it can be a name (consisting of letters, digits or\n-    /// underscores) corresponding to a named capture group.\n-    ///\n-    /// If `name` isn't a valid capture group (whether the name doesn't exist or\n-    /// isn't a valid index), then it is replaced with the empty string.\n-    ///\n-    /// To write a literal `$` use `$$`.\n-    pub fn expand(&self, text: &str) -> String {\n-        // How evil can you get?\n-        // FIXME: Don't use regexes for this. It's completely unnecessary.\n-        let re = Regex::new(r\"(^|[^$]|\\b)\\$(\\w+)\").unwrap();\n-        let text = re.replace_all(text, |&mut: refs: &Captures| -> String {\n-            let pre = refs.at(1).unwrap_or(\"\");\n-            let name = refs.at(2).unwrap_or(\"\");\n-            format!(\"{}{}\", pre,\n-                    match name.parse::<uint>() {\n-                None => self.name(name).unwrap_or(\"\").to_string(),\n-                Some(i) => self.at(i).unwrap_or(\"\").to_string(),\n-            })\n-        });\n-        let re = Regex::new(r\"\\$\\$\").unwrap();\n-        re.replace_all(&text[], NoExpand(\"$\"))\n-    }\n-\n-    /// Returns the number of captured groups.\n-    #[inline]\n-    pub fn len(&self) -> uint { self.locs.len() / 2 }\n-\n-    /// Returns if there are no captured groups.\n-    #[inline]\n-    pub fn is_empty(&self) -> bool { self.len() == 0 }\n-}\n-\n-/// An iterator over capture groups for a particular match of a regular\n-/// expression.\n-///\n-/// `'t` is the lifetime of the matched text.\n-#[derive(Clone)]\n-pub struct SubCaptures<'t> {\n-    idx: uint,\n-    caps: &'t Captures<'t>,\n-}\n-\n-impl<'t> Iterator for SubCaptures<'t> {\n-    type Item = &'t str;\n-\n-    fn next(&mut self) -> Option<&'t str> {\n-        if self.idx < self.caps.len() {\n-            self.idx += 1;\n-            Some(self.caps.at(self.idx - 1).unwrap_or(\"\"))\n-        } else {\n-            None\n-        }\n-    }\n-}\n-\n-/// An iterator over capture group positions for a particular match of a\n-/// regular expression.\n-///\n-/// Positions are byte indices in terms of the original string matched.\n-///\n-/// `'t` is the lifetime of the matched text.\n-#[derive(Clone)]\n-pub struct SubCapturesPos<'t> {\n-    idx: uint,\n-    caps: &'t Captures<'t>,\n-}\n-\n-impl<'t> Iterator for SubCapturesPos<'t> {\n-    type Item = Option<(uint, uint)>;\n-\n-    fn next(&mut self) -> Option<Option<(uint, uint)>> {\n-        if self.idx < self.caps.len() {\n-            self.idx += 1;\n-            Some(self.caps.pos(self.idx - 1))\n-        } else {\n-            None\n-        }\n-    }\n-}\n-\n-/// An iterator that yields all non-overlapping capture groups matching a\n-/// particular regular expression.\n-///\n-/// The iterator stops when no more matches can be found.\n-///\n-/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n-/// of the matched string.\n-#[derive(Clone)]\n-pub struct FindCaptures<'r, 't> {\n-    re: &'r Regex,\n-    search: &'t str,\n-    last_match: Option<uint>,\n-    last_end: uint,\n-}\n-\n-impl<'r, 't> Iterator for FindCaptures<'r, 't> {\n-    type Item = Captures<'t>;\n-\n-    fn next(&mut self) -> Option<Captures<'t>> {\n-        if self.last_end > self.search.len() {\n-            return None\n-        }\n-\n-        let caps = exec_slice(self.re, Submatches, self.search,\n-                              self.last_end, self.search.len());\n-        let (s, e) =\n-            if !has_match(&caps) {\n-                return None\n-            } else {\n-                (caps[0].unwrap(), caps[1].unwrap())\n-            };\n-\n-        // Don't accept empty matches immediately following a match.\n-        // i.e., no infinite loops please.\n-        if e == s && Some(self.last_end) == self.last_match {\n-            self.last_end += 1;\n-            return self.next()\n-        }\n-        self.last_end = e;\n-        self.last_match = Some(self.last_end);\n-        Captures::new(self.re, self.search, caps)\n-    }\n-}\n-\n-/// An iterator over all non-overlapping matches for a particular string.\n-///\n-/// The iterator yields a tuple of integers corresponding to the start and end\n-/// of the match. The indices are byte offsets. The iterator stops when no more\n-/// matches can be found.\n-///\n-/// `'r` is the lifetime of the compiled expression and `'t` is the lifetime\n-/// of the matched string.\n-#[derive(Clone)]\n-pub struct FindMatches<'r, 't> {\n-    re: &'r Regex,\n-    search: &'t str,\n-    last_match: Option<uint>,\n-    last_end: uint,\n-}\n-\n-impl<'r, 't> Iterator for FindMatches<'r, 't> {\n-    type Item = (uint, uint);\n-\n-    fn next(&mut self) -> Option<(uint, uint)> {\n-        if self.last_end > self.search.len() {\n-            return None\n-        }\n-\n-        let caps = exec_slice(self.re, Location, self.search,\n-                              self.last_end, self.search.len());\n-        let (s, e) =\n-            if !has_match(&caps) {\n-                return None\n-            } else {\n-                (caps[0].unwrap(), caps[1].unwrap())\n-            };\n-\n-        // Don't accept empty matches immediately following a match.\n-        // i.e., no infinite loops please.\n-        if e == s && Some(self.last_end) == self.last_match {\n-            self.last_end += 1;\n-            return self.next()\n-        }\n-        self.last_end = e;\n-        self.last_match = Some(self.last_end);\n-        Some((s, e))\n-    }\n-}\n-\n-fn exec(re: &Regex, which: MatchKind, input: &str) -> CaptureLocs {\n-    exec_slice(re, which, input, 0, input.len())\n-}\n-\n-fn exec_slice(re: &Regex, which: MatchKind,\n-              input: &str, s: uint, e: uint) -> CaptureLocs {\n-    match *re {\n-        Dynamic(ExDynamic { ref prog, .. }) => vm::run(which, prog, input, s, e),\n-        Native(ExNative { ref prog, .. }) => (*prog)(which, input, s, e),\n-    }\n-}\n-\n-#[inline]\n-fn has_match(caps: &CaptureLocs) -> bool {\n-    caps.len() >= 2 && caps[0].is_some() && caps[1].is_some()\n-}"}, {"sha": "17521ff7ea54bb9ebcdaf01e6298451bdb21e68e", "filename": "src/libregex/test/bench.rs", "status": "removed", "additions": 0, "deletions": 183, "changes": 183, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fbench.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fbench.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fbench.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,183 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-#![allow(non_snake_case)]\n-\n-use std::rand::{Rng, thread_rng};\n-use stdtest::Bencher;\n-use std::iter::repeat;\n-\n-use regex::{Regex, NoExpand};\n-\n-fn bench_assert_match(b: &mut Bencher, re: Regex, text: &str) {\n-    b.iter(|| if !re.is_match(text) { panic!(\"no match\") });\n-}\n-\n-#[bench]\n-fn no_exponential(b: &mut Bencher) {\n-    let n = 100;\n-    let re = Regex::new(format!(\"{}{}\",\n-                                repeat(\"a?\").take(n).collect::<String>(),\n-                                repeat(\"a\").take(n).collect::<String>()).as_slice()).unwrap();\n-    let text = repeat(\"a\").take(n).collect::<String>();\n-    bench_assert_match(b, re, text.as_slice());\n-}\n-\n-#[bench]\n-fn literal(b: &mut Bencher) {\n-    let re = regex!(\"y\");\n-    let text = format!(\"{}y\", repeat(\"x\").take(50).collect::<String>());\n-    bench_assert_match(b, re, text.as_slice());\n-}\n-\n-#[bench]\n-fn not_literal(b: &mut Bencher) {\n-    let re = regex!(\".y\");\n-    let text = format!(\"{}y\", repeat(\"x\").take(50).collect::<String>());\n-    bench_assert_match(b, re, text.as_slice());\n-}\n-\n-#[bench]\n-fn match_class(b: &mut Bencher) {\n-    let re = regex!(\"[abcdw]\");\n-    let text = format!(\"{}w\", repeat(\"xxxx\").take(20).collect::<String>());\n-    bench_assert_match(b, re, text.as_slice());\n-}\n-\n-#[bench]\n-fn match_class_in_range(b: &mut Bencher) {\n-    // 'b' is between 'a' and 'c', so the class range checking doesn't help.\n-    let re = regex!(\"[ac]\");\n-    let text = format!(\"{}c\", repeat(\"bbbb\").take(20).collect::<String>());\n-    bench_assert_match(b, re, text.as_slice());\n-}\n-\n-#[bench]\n-fn replace_all(b: &mut Bencher) {\n-    let re = regex!(\"[cjrw]\");\n-    let text = \"abcdefghijklmnopqrstuvwxyz\";\n-    // FIXME: This isn't using the $name expand stuff.\n-    // It's possible RE2/Go is using it, but currently, the expand in this\n-    // crate is actually compiling a regex, so it's incredibly slow.\n-    b.iter(|| re.replace_all(text, NoExpand(\"\")));\n-}\n-\n-#[bench]\n-fn anchored_literal_short_non_match(b: &mut Bencher) {\n-    let re = regex!(\"^zbc(d|e)\");\n-    let text = \"abcdefghijklmnopqrstuvwxyz\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn anchored_literal_long_non_match(b: &mut Bencher) {\n-    let re = regex!(\"^zbc(d|e)\");\n-    let text = repeat(\"abcdefghijklmnopqrstuvwxyz\").take(15).collect::<String>();\n-    b.iter(|| re.is_match(text.as_slice()));\n-}\n-\n-#[bench]\n-fn anchored_literal_short_match(b: &mut Bencher) {\n-    let re = regex!(\"^.bc(d|e)\");\n-    let text = \"abcdefghijklmnopqrstuvwxyz\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn anchored_literal_long_match(b: &mut Bencher) {\n-    let re = regex!(\"^.bc(d|e)\");\n-    let text = repeat(\"abcdefghijklmnopqrstuvwxyz\").take(15).collect::<String>();\n-    b.iter(|| re.is_match(text.as_slice()));\n-}\n-\n-#[bench]\n-fn one_pass_short_a(b: &mut Bencher) {\n-    let re = regex!(\"^.bc(d|e)*$\");\n-    let text = \"abcddddddeeeededd\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn one_pass_short_a_not(b: &mut Bencher) {\n-    let re = regex!(\".bc(d|e)*$\");\n-    let text = \"abcddddddeeeededd\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn one_pass_short_b(b: &mut Bencher) {\n-    let re = regex!(\"^.bc(?:d|e)*$\");\n-    let text = \"abcddddddeeeededd\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn one_pass_short_b_not(b: &mut Bencher) {\n-    let re = regex!(\".bc(?:d|e)*$\");\n-    let text = \"abcddddddeeeededd\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn one_pass_long_prefix(b: &mut Bencher) {\n-    let re = regex!(\"^abcdefghijklmnopqrstuvwxyz.*$\");\n-    let text = \"abcdefghijklmnopqrstuvwxyz\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-#[bench]\n-fn one_pass_long_prefix_not(b: &mut Bencher) {\n-    let re = regex!(\"^.bcdefghijklmnopqrstuvwxyz.*$\");\n-    let text = \"abcdefghijklmnopqrstuvwxyz\";\n-    b.iter(|| re.is_match(text));\n-}\n-\n-macro_rules! throughput {\n-    ($name:ident, $regex:expr, $size:expr) => (\n-        #[bench]\n-        fn $name(b: &mut Bencher) {\n-            let text = gen_text($size);\n-            b.bytes = $size;\n-            b.iter(|| if $regex.is_match(text.as_slice()) { panic!(\"match\") });\n-        }\n-    );\n-}\n-\n-fn easy0() -> Regex { regex!(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n-fn easy1() -> Regex { regex!(\"A[AB]B[BC]C[CD]D[DE]E[EF]F[FG]G[GH]H[HI]I[IJ]J$\") }\n-fn medium() -> Regex { regex!(\"[XYZ]ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n-fn hard() -> Regex { regex!(\"[ -~]*ABCDEFGHIJKLMNOPQRSTUVWXYZ$\") }\n-\n-fn gen_text(n: uint) -> String {\n-    let mut rng = thread_rng();\n-    let mut bytes = rng.gen_ascii_chars().map(|n| n as u8).take(n)\n-                       .collect::<Vec<u8>>();\n-    for (i, b) in bytes.iter_mut().enumerate() {\n-        if i % 20 == 0 {\n-            *b = b'\\n'\n-        }\n-    }\n-    String::from_utf8(bytes).unwrap()\n-}\n-\n-throughput!{easy0_32, easy0(), 32}\n-throughput!{easy0_1K, easy0(), 1<<10}\n-throughput!{easy0_32K, easy0(), 32<<10}\n-\n-throughput!{easy1_32, easy1(), 32}\n-throughput!{easy1_1K, easy1(), 1<<10}\n-throughput!{easy1_32K, easy1(), 32<<10}\n-\n-throughput!{medium_32, medium(), 32}\n-throughput!{medium_1K, medium(), 1<<10}\n-throughput!{medium_32K,medium(), 32<<10}\n-\n-throughput!{hard_32, hard(), 32}\n-throughput!{hard_1K, hard(), 1<<10}\n-throughput!{hard_32K,hard(), 32<<10}"}, {"sha": "7508f4c50a2c313ff373fee34e22901c9565e005", "filename": "src/libregex/test/matches.rs", "status": "removed", "additions": 0, "deletions": 373, "changes": 373, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fmatches.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fmatches.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fmatches.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,373 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// ignore-tidy-linelength\n-\n-// DO NOT EDIT. Automatically generated by 'src/etc/regex-match-tests'\n-// on 2014-04-23 01:33:36.539280.\n-\n-// Tests from basic.dat\n-mat!{match_basic_3, r\"abracadabra$\", r\"abracadabracadabra\", Some((7, 18))}\n-mat!{match_basic_4, r\"a...b\", r\"abababbb\", Some((2, 7))}\n-mat!{match_basic_5, r\"XXXXXX\", r\"..XXXXXX\", Some((2, 8))}\n-mat!{match_basic_6, r\"\\)\", r\"()\", Some((1, 2))}\n-mat!{match_basic_7, r\"a]\", r\"a]a\", Some((0, 2))}\n-mat!{match_basic_9, r\"\\}\", r\"}\", Some((0, 1))}\n-mat!{match_basic_10, r\"\\]\", r\"]\", Some((0, 1))}\n-mat!{match_basic_12, r\"]\", r\"]\", Some((0, 1))}\n-mat!{match_basic_15, r\"^a\", r\"ax\", Some((0, 1))}\n-mat!{match_basic_16, r\"\\^a\", r\"a^a\", Some((1, 3))}\n-mat!{match_basic_17, r\"a\\^\", r\"a^\", Some((0, 2))}\n-mat!{match_basic_18, r\"a$\", r\"aa\", Some((1, 2))}\n-mat!{match_basic_19, r\"a\\$\", r\"a$\", Some((0, 2))}\n-mat!{match_basic_20, r\"^$\", r\"\", Some((0, 0))}\n-mat!{match_basic_21, r\"$^\", r\"\", Some((0, 0))}\n-mat!{match_basic_22, r\"a($)\", r\"aa\", Some((1, 2)), Some((2, 2))}\n-mat!{match_basic_23, r\"a*(^a)\", r\"aa\", Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_24, r\"(..)*(...)*\", r\"a\", Some((0, 0))}\n-mat!{match_basic_25, r\"(..)*(...)*\", r\"abcd\", Some((0, 4)), Some((2, 4))}\n-mat!{match_basic_26, r\"(ab|a)(bc|c)\", r\"abc\", Some((0, 3)), Some((0, 2)), Some((2, 3))}\n-mat!{match_basic_27, r\"(ab)c|abc\", r\"abc\", Some((0, 3)), Some((0, 2))}\n-mat!{match_basic_28, r\"a{0}b\", r\"ab\", Some((1, 2))}\n-mat!{match_basic_29, r\"(a*)(b?)(b+)b{3}\", r\"aaabbbbbbb\", Some((0, 10)), Some((0, 3)), Some((3, 4)), Some((4, 7))}\n-mat!{match_basic_30, r\"(a*)(b{0,1})(b{1,})b{3}\", r\"aaabbbbbbb\", Some((0, 10)), Some((0, 3)), Some((3, 4)), Some((4, 7))}\n-mat!{match_basic_32, r\"((a|a)|a)\", r\"a\", Some((0, 1)), Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_33, r\"(a*)(a|aa)\", r\"aaaa\", Some((0, 4)), Some((0, 3)), Some((3, 4))}\n-mat!{match_basic_34, r\"a*(a.|aa)\", r\"aaaa\", Some((0, 4)), Some((2, 4))}\n-mat!{match_basic_35, r\"a(b)|c(d)|a(e)f\", r\"aef\", Some((0, 3)), None, None, Some((1, 2))}\n-mat!{match_basic_36, r\"(a|b)?.*\", r\"b\", Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_37, r\"(a|b)c|a(b|c)\", r\"ac\", Some((0, 2)), Some((0, 1))}\n-mat!{match_basic_38, r\"(a|b)c|a(b|c)\", r\"ab\", Some((0, 2)), None, Some((1, 2))}\n-mat!{match_basic_39, r\"(a|b)*c|(a|ab)*c\", r\"abc\", Some((0, 3)), Some((1, 2))}\n-mat!{match_basic_40, r\"(a|b)*c|(a|ab)*c\", r\"xc\", Some((1, 2))}\n-mat!{match_basic_41, r\"(.a|.b).*|.*(.a|.b)\", r\"xa\", Some((0, 2)), Some((0, 2))}\n-mat!{match_basic_42, r\"a?(ab|ba)ab\", r\"abab\", Some((0, 4)), Some((0, 2))}\n-mat!{match_basic_43, r\"a?(ac{0}b|ba)ab\", r\"abab\", Some((0, 4)), Some((0, 2))}\n-mat!{match_basic_44, r\"ab|abab\", r\"abbabab\", Some((0, 2))}\n-mat!{match_basic_45, r\"aba|bab|bba\", r\"baaabbbaba\", Some((5, 8))}\n-mat!{match_basic_46, r\"aba|bab\", r\"baaabbbaba\", Some((6, 9))}\n-mat!{match_basic_47, r\"(aa|aaa)*|(a|aaaaa)\", r\"aa\", Some((0, 2)), Some((0, 2))}\n-mat!{match_basic_48, r\"(a.|.a.)*|(a|.a...)\", r\"aa\", Some((0, 2)), Some((0, 2))}\n-mat!{match_basic_49, r\"ab|a\", r\"xabc\", Some((1, 3))}\n-mat!{match_basic_50, r\"ab|a\", r\"xxabc\", Some((2, 4))}\n-mat!{match_basic_51, r\"(?i)(Ab|cD)*\", r\"aBcD\", Some((0, 4)), Some((2, 4))}\n-mat!{match_basic_52, r\"[^-]\", r\"--a\", Some((2, 3))}\n-mat!{match_basic_53, r\"[a-]*\", r\"--a\", Some((0, 3))}\n-mat!{match_basic_54, r\"[a-m-]*\", r\"--amoma--\", Some((0, 4))}\n-mat!{match_basic_55, r\":::1:::0:|:::1:1:0:\", r\":::0:::1:::1:::0:\", Some((8, 17))}\n-mat!{match_basic_56, r\":::1:::0:|:::1:1:1:\", r\":::0:::1:::1:::0:\", Some((8, 17))}\n-mat!{match_basic_57, r\"[[:upper:]]\", r\"A\", Some((0, 1))}\n-mat!{match_basic_58, r\"[[:lower:]]+\", r\"`az{\", Some((1, 3))}\n-mat!{match_basic_59, r\"[[:upper:]]+\", r\"@AZ[\", Some((1, 3))}\n-mat!{match_basic_65, r\"\n-\", r\"\n-\", Some((0, 1))}\n-mat!{match_basic_66, r\"\n-\", r\"\n-\", Some((0, 1))}\n-mat!{match_basic_67, r\"[^a]\", r\"\n-\", Some((0, 1))}\n-mat!{match_basic_68, r\"\n-a\", r\"\n-a\", Some((0, 2))}\n-mat!{match_basic_69, r\"(a)(b)(c)\", r\"abc\", Some((0, 3)), Some((0, 1)), Some((1, 2)), Some((2, 3))}\n-mat!{match_basic_70, r\"xxx\", r\"xxx\", Some((0, 3))}\n-mat!{match_basic_71, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"feb 6,\", Some((0, 6))}\n-mat!{match_basic_72, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"2/7\", Some((0, 3))}\n-mat!{match_basic_73, r\"(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\", r\"feb 1,Feb 6\", Some((5, 11))}\n-mat!{match_basic_74, r\"((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))\", r\"x\", Some((0, 1)), Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_75, r\"((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))*\", r\"xx\", Some((0, 2)), Some((1, 2)), Some((1, 2))}\n-mat!{match_basic_76, r\"a?(ab|ba)*\", r\"ababababababababababababababababababababababababababababababababababababababababa\", Some((0, 81)), Some((79, 81))}\n-mat!{match_basic_77, r\"abaa|abbaa|abbbaa|abbbbaa\", r\"ababbabbbabbbabbbbabbbbaa\", Some((18, 25))}\n-mat!{match_basic_78, r\"abaa|abbaa|abbbaa|abbbbaa\", r\"ababbabbbabbbabbbbabaa\", Some((18, 22))}\n-mat!{match_basic_79, r\"aaac|aabc|abac|abbc|baac|babc|bbac|bbbc\", r\"baaabbbabac\", Some((7, 11))}\n-mat!{match_basic_80, r\".*\", r\"\u0001\u007f\", Some((0, 2))}\n-mat!{match_basic_81, r\"aaaa|bbbb|cccc|ddddd|eeeeee|fffffff|gggg|hhhh|iiiii|jjjjj|kkkkk|llll\", r\"XaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\", Some((53, 57))}\n-mat!{match_basic_83, r\"a*a*a*a*a*b\", r\"aaaaaaaaab\", Some((0, 10))}\n-mat!{match_basic_84, r\"^\", r\"\", Some((0, 0))}\n-mat!{match_basic_85, r\"$\", r\"\", Some((0, 0))}\n-mat!{match_basic_86, r\"^$\", r\"\", Some((0, 0))}\n-mat!{match_basic_87, r\"^a$\", r\"a\", Some((0, 1))}\n-mat!{match_basic_88, r\"abc\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_89, r\"abc\", r\"xabcy\", Some((1, 4))}\n-mat!{match_basic_90, r\"abc\", r\"ababc\", Some((2, 5))}\n-mat!{match_basic_91, r\"ab*c\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_92, r\"ab*bc\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_93, r\"ab*bc\", r\"abbc\", Some((0, 4))}\n-mat!{match_basic_94, r\"ab*bc\", r\"abbbbc\", Some((0, 6))}\n-mat!{match_basic_95, r\"ab+bc\", r\"abbc\", Some((0, 4))}\n-mat!{match_basic_96, r\"ab+bc\", r\"abbbbc\", Some((0, 6))}\n-mat!{match_basic_97, r\"ab?bc\", r\"abbc\", Some((0, 4))}\n-mat!{match_basic_98, r\"ab?bc\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_99, r\"ab?c\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_100, r\"^abc$\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_101, r\"^abc\", r\"abcc\", Some((0, 3))}\n-mat!{match_basic_102, r\"abc$\", r\"aabc\", Some((1, 4))}\n-mat!{match_basic_103, r\"^\", r\"abc\", Some((0, 0))}\n-mat!{match_basic_104, r\"$\", r\"abc\", Some((3, 3))}\n-mat!{match_basic_105, r\"a.c\", r\"abc\", Some((0, 3))}\n-mat!{match_basic_106, r\"a.c\", r\"axc\", Some((0, 3))}\n-mat!{match_basic_107, r\"a.*c\", r\"axyzc\", Some((0, 5))}\n-mat!{match_basic_108, r\"a[bc]d\", r\"abd\", Some((0, 3))}\n-mat!{match_basic_109, r\"a[b-d]e\", r\"ace\", Some((0, 3))}\n-mat!{match_basic_110, r\"a[b-d]\", r\"aac\", Some((1, 3))}\n-mat!{match_basic_111, r\"a[-b]\", r\"a-\", Some((0, 2))}\n-mat!{match_basic_112, r\"a[b-]\", r\"a-\", Some((0, 2))}\n-mat!{match_basic_113, r\"a]\", r\"a]\", Some((0, 2))}\n-mat!{match_basic_114, r\"a[]]b\", r\"a]b\", Some((0, 3))}\n-mat!{match_basic_115, r\"a[^bc]d\", r\"aed\", Some((0, 3))}\n-mat!{match_basic_116, r\"a[^-b]c\", r\"adc\", Some((0, 3))}\n-mat!{match_basic_117, r\"a[^]b]c\", r\"adc\", Some((0, 3))}\n-mat!{match_basic_118, r\"ab|cd\", r\"abc\", Some((0, 2))}\n-mat!{match_basic_119, r\"ab|cd\", r\"abcd\", Some((0, 2))}\n-mat!{match_basic_120, r\"a\\(b\", r\"a(b\", Some((0, 3))}\n-mat!{match_basic_121, r\"a\\(*b\", r\"ab\", Some((0, 2))}\n-mat!{match_basic_122, r\"a\\(*b\", r\"a((b\", Some((0, 4))}\n-mat!{match_basic_123, r\"((a))\", r\"abc\", Some((0, 1)), Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_124, r\"(a)b(c)\", r\"abc\", Some((0, 3)), Some((0, 1)), Some((2, 3))}\n-mat!{match_basic_125, r\"a+b+c\", r\"aabbabc\", Some((4, 7))}\n-mat!{match_basic_126, r\"a*\", r\"aaa\", Some((0, 3))}\n-mat!{match_basic_128, r\"(a*)*\", r\"-\", Some((0, 0)), None}\n-mat!{match_basic_129, r\"(a*)+\", r\"-\", Some((0, 0)), Some((0, 0))}\n-mat!{match_basic_131, r\"(a*|b)*\", r\"-\", Some((0, 0)), None}\n-mat!{match_basic_132, r\"(a+|b)*\", r\"ab\", Some((0, 2)), Some((1, 2))}\n-mat!{match_basic_133, r\"(a+|b)+\", r\"ab\", Some((0, 2)), Some((1, 2))}\n-mat!{match_basic_134, r\"(a+|b)?\", r\"ab\", Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_135, r\"[^ab]*\", r\"cde\", Some((0, 3))}\n-mat!{match_basic_137, r\"(^)*\", r\"-\", Some((0, 0)), None}\n-mat!{match_basic_138, r\"a*\", r\"\", Some((0, 0))}\n-mat!{match_basic_139, r\"([abc])*d\", r\"abbbcd\", Some((0, 6)), Some((4, 5))}\n-mat!{match_basic_140, r\"([abc])*bcd\", r\"abcd\", Some((0, 4)), Some((0, 1))}\n-mat!{match_basic_141, r\"a|b|c|d|e\", r\"e\", Some((0, 1))}\n-mat!{match_basic_142, r\"(a|b|c|d|e)f\", r\"ef\", Some((0, 2)), Some((0, 1))}\n-mat!{match_basic_144, r\"((a*|b))*\", r\"-\", Some((0, 0)), None, None}\n-mat!{match_basic_145, r\"abcd*efg\", r\"abcdefg\", Some((0, 7))}\n-mat!{match_basic_146, r\"ab*\", r\"xabyabbbz\", Some((1, 3))}\n-mat!{match_basic_147, r\"ab*\", r\"xayabbbz\", Some((1, 2))}\n-mat!{match_basic_148, r\"(ab|cd)e\", r\"abcde\", Some((2, 5)), Some((2, 4))}\n-mat!{match_basic_149, r\"[abhgefdc]ij\", r\"hij\", Some((0, 3))}\n-mat!{match_basic_150, r\"(a|b)c*d\", r\"abcd\", Some((1, 4)), Some((1, 2))}\n-mat!{match_basic_151, r\"(ab|ab*)bc\", r\"abc\", Some((0, 3)), Some((0, 1))}\n-mat!{match_basic_152, r\"a([bc]*)c*\", r\"abc\", Some((0, 3)), Some((1, 3))}\n-mat!{match_basic_153, r\"a([bc]*)(c*d)\", r\"abcd\", Some((0, 4)), Some((1, 3)), Some((3, 4))}\n-mat!{match_basic_154, r\"a([bc]+)(c*d)\", r\"abcd\", Some((0, 4)), Some((1, 3)), Some((3, 4))}\n-mat!{match_basic_155, r\"a([bc]*)(c+d)\", r\"abcd\", Some((0, 4)), Some((1, 2)), Some((2, 4))}\n-mat!{match_basic_156, r\"a[bcd]*dcdcde\", r\"adcdcde\", Some((0, 7))}\n-mat!{match_basic_157, r\"(ab|a)b*c\", r\"abc\", Some((0, 3)), Some((0, 2))}\n-mat!{match_basic_158, r\"((a)(b)c)(d)\", r\"abcd\", Some((0, 4)), Some((0, 3)), Some((0, 1)), Some((1, 2)), Some((3, 4))}\n-mat!{match_basic_159, r\"[A-Za-z_][A-Za-z0-9_]*\", r\"alpha\", Some((0, 5))}\n-mat!{match_basic_160, r\"^a(bc+|b[eh])g|.h$\", r\"abh\", Some((1, 3))}\n-mat!{match_basic_161, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"effgz\", Some((0, 5)), Some((0, 5))}\n-mat!{match_basic_162, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"ij\", Some((0, 2)), Some((0, 2)), Some((1, 2))}\n-mat!{match_basic_163, r\"(bc+d$|ef*g.|h?i(j|k))\", r\"reffgz\", Some((1, 6)), Some((1, 6))}\n-mat!{match_basic_164, r\"(((((((((a)))))))))\", r\"a\", Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1)), Some((0, 1))}\n-mat!{match_basic_165, r\"multiple words\", r\"multiple words yeah\", Some((0, 14))}\n-mat!{match_basic_166, r\"(.*)c(.*)\", r\"abcde\", Some((0, 5)), Some((0, 2)), Some((3, 5))}\n-mat!{match_basic_167, r\"abcd\", r\"abcd\", Some((0, 4))}\n-mat!{match_basic_168, r\"a(bc)d\", r\"abcd\", Some((0, 4)), Some((1, 3))}\n-mat!{match_basic_169, r\"a[\u0001-\u0003]?c\", r\"a\u0002c\", Some((0, 3))}\n-mat!{match_basic_170, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Qaddafi\", Some((0, 15)), None, Some((10, 12))}\n-mat!{match_basic_171, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mo'ammar Gadhafi\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_172, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Kaddafi\", Some((0, 15)), None, Some((10, 12))}\n-mat!{match_basic_173, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Qadhafi\", Some((0, 15)), None, Some((10, 12))}\n-mat!{match_basic_174, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Gadafi\", Some((0, 14)), None, Some((10, 11))}\n-mat!{match_basic_175, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mu'ammar Qadafi\", Some((0, 15)), None, Some((11, 12))}\n-mat!{match_basic_176, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moamar Gaddafi\", Some((0, 14)), None, Some((9, 11))}\n-mat!{match_basic_177, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Mu'ammar Qadhdhafi\", Some((0, 18)), None, Some((13, 15))}\n-mat!{match_basic_178, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Khaddafi\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_179, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghaddafy\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_180, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghadafi\", Some((0, 15)), None, Some((11, 12))}\n-mat!{match_basic_181, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Ghaddafi\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_182, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muamar Kaddafi\", Some((0, 14)), None, Some((9, 11))}\n-mat!{match_basic_183, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Quathafi\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_184, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Muammar Gheddafi\", Some((0, 16)), None, Some((11, 13))}\n-mat!{match_basic_185, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moammar Khadafy\", Some((0, 15)), None, Some((11, 12))}\n-mat!{match_basic_186, r\"M[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\", r\"Moammar Qudhafi\", Some((0, 15)), None, Some((10, 12))}\n-mat!{match_basic_187, r\"a+(b|c)*d+\", r\"aabcdd\", Some((0, 6)), Some((3, 4))}\n-mat!{match_basic_188, r\"^.+$\", r\"vivi\", Some((0, 4))}\n-mat!{match_basic_189, r\"^(.+)$\", r\"vivi\", Some((0, 4)), Some((0, 4))}\n-mat!{match_basic_190, r\"^([^!.]+).att.com!(.+)$\", r\"gryphon.att.com!eby\", Some((0, 19)), Some((0, 7)), Some((16, 19))}\n-mat!{match_basic_191, r\"^([^!]+!)?([^!]+)$\", r\"bas\", Some((0, 3)), None, Some((0, 3))}\n-mat!{match_basic_192, r\"^([^!]+!)?([^!]+)$\", r\"bar!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_193, r\"^([^!]+!)?([^!]+)$\", r\"foo!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_194, r\"^.+!([^!]+!)([^!]+)$\", r\"foo!bar!bas\", Some((0, 11)), Some((4, 8)), Some((8, 11))}\n-mat!{match_basic_195, r\"((foo)|(bar))!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)), None, Some((0, 3))}\n-mat!{match_basic_196, r\"((foo)|(bar))!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)), None, Some((4, 7))}\n-mat!{match_basic_197, r\"((foo)|(bar))!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3))}\n-mat!{match_basic_198, r\"((foo)|bar)!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3))}\n-mat!{match_basic_199, r\"((foo)|bar)!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7))}\n-mat!{match_basic_200, r\"((foo)|bar)!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3))}\n-mat!{match_basic_201, r\"(foo|(bar))!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3)), Some((0, 3))}\n-mat!{match_basic_202, r\"(foo|(bar))!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7)), Some((4, 7))}\n-mat!{match_basic_203, r\"(foo|(bar))!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3))}\n-mat!{match_basic_204, r\"(foo|bar)!bas\", r\"bar!bas\", Some((0, 7)), Some((0, 3))}\n-mat!{match_basic_205, r\"(foo|bar)!bas\", r\"foo!bar!bas\", Some((4, 11)), Some((4, 7))}\n-mat!{match_basic_206, r\"(foo|bar)!bas\", r\"foo!bas\", Some((0, 7)), Some((0, 3))}\n-mat!{match_basic_207, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bar!bas\", Some((0, 11)), Some((0, 11)), None, None, Some((4, 8)), Some((8, 11))}\n-mat!{match_basic_208, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"bas\", Some((0, 3)), None, Some((0, 3))}\n-mat!{match_basic_209, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"bar!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_210, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"foo!bar!bas\", Some((0, 11)), None, None, Some((4, 8)), Some((8, 11))}\n-mat!{match_basic_211, r\"^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\", r\"foo!bas\", Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_212, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"bas\", Some((0, 3)), Some((0, 3)), None, Some((0, 3))}\n-mat!{match_basic_213, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"bar!bas\", Some((0, 7)), Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_214, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bar!bas\", Some((0, 11)), Some((0, 11)), None, None, Some((4, 8)), Some((8, 11))}\n-mat!{match_basic_215, r\"^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\", r\"foo!bas\", Some((0, 7)), Some((0, 7)), Some((0, 4)), Some((4, 7))}\n-mat!{match_basic_216, r\".*(/XXX).*\", r\"/XXX\", Some((0, 4)), Some((0, 4))}\n-mat!{match_basic_217, r\".*(\\\\XXX).*\", r\"\\XXX\", Some((0, 4)), Some((0, 4))}\n-mat!{match_basic_218, r\"\\\\XXX\", r\"\\XXX\", Some((0, 4))}\n-mat!{match_basic_219, r\".*(/000).*\", r\"/000\", Some((0, 4)), Some((0, 4))}\n-mat!{match_basic_220, r\".*(\\\\000).*\", r\"\\000\", Some((0, 4)), Some((0, 4))}\n-mat!{match_basic_221, r\"\\\\000\", r\"\\000\", Some((0, 4))}\n-\n-// Tests from nullsubexpr.dat\n-mat!{match_nullsubexpr_3, r\"(a*)*\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_5, r\"(a*)*\", r\"x\", Some((0, 0)), None}\n-mat!{match_nullsubexpr_6, r\"(a*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_7, r\"(a*)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_8, r\"(a*)+\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_9, r\"(a*)+\", r\"x\", Some((0, 0)), Some((0, 0))}\n-mat!{match_nullsubexpr_10, r\"(a*)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_11, r\"(a*)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_12, r\"(a+)*\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_13, r\"(a+)*\", r\"x\", Some((0, 0))}\n-mat!{match_nullsubexpr_14, r\"(a+)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_15, r\"(a+)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_16, r\"(a+)+\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_17, r\"(a+)+\", r\"x\", None}\n-mat!{match_nullsubexpr_18, r\"(a+)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_19, r\"(a+)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_21, r\"([a]*)*\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_23, r\"([a]*)*\", r\"x\", Some((0, 0)), None}\n-mat!{match_nullsubexpr_24, r\"([a]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_25, r\"([a]*)*\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_26, r\"([a]*)+\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_27, r\"([a]*)+\", r\"x\", Some((0, 0)), Some((0, 0))}\n-mat!{match_nullsubexpr_28, r\"([a]*)+\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_29, r\"([a]*)+\", r\"aaaaaax\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_30, r\"([^b]*)*\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_32, r\"([^b]*)*\", r\"b\", Some((0, 0)), None}\n-mat!{match_nullsubexpr_33, r\"([^b]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_34, r\"([^b]*)*\", r\"aaaaaab\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_35, r\"([ab]*)*\", r\"a\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_36, r\"([ab]*)*\", r\"aaaaaa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_37, r\"([ab]*)*\", r\"ababab\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_38, r\"([ab]*)*\", r\"bababa\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_39, r\"([ab]*)*\", r\"b\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_40, r\"([ab]*)*\", r\"bbbbbb\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_41, r\"([ab]*)*\", r\"aaaabcde\", Some((0, 5)), Some((0, 5))}\n-mat!{match_nullsubexpr_42, r\"([^a]*)*\", r\"b\", Some((0, 1)), Some((0, 1))}\n-mat!{match_nullsubexpr_43, r\"([^a]*)*\", r\"bbbbbb\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_45, r\"([^a]*)*\", r\"aaaaaa\", Some((0, 0)), None}\n-mat!{match_nullsubexpr_46, r\"([^ab]*)*\", r\"ccccxx\", Some((0, 6)), Some((0, 6))}\n-mat!{match_nullsubexpr_48, r\"([^ab]*)*\", r\"ababab\", Some((0, 0)), None}\n-mat!{match_nullsubexpr_50, r\"((z)+|a)*\", r\"zabcde\", Some((0, 2)), Some((1, 2))}\n-mat!{match_nullsubexpr_69, r\"(a*)*(x)\", r\"x\", Some((0, 1)), None, Some((0, 1))}\n-mat!{match_nullsubexpr_70, r\"(a*)*(x)\", r\"ax\", Some((0, 2)), Some((0, 1)), Some((1, 2))}\n-mat!{match_nullsubexpr_71, r\"(a*)*(x)\", r\"axa\", Some((0, 2)), Some((0, 1)), Some((1, 2))}\n-mat!{match_nullsubexpr_73, r\"(a*)+(x)\", r\"x\", Some((0, 1)), Some((0, 0)), Some((0, 1))}\n-mat!{match_nullsubexpr_74, r\"(a*)+(x)\", r\"ax\", Some((0, 2)), Some((0, 1)), Some((1, 2))}\n-mat!{match_nullsubexpr_75, r\"(a*)+(x)\", r\"axa\", Some((0, 2)), Some((0, 1)), Some((1, 2))}\n-mat!{match_nullsubexpr_77, r\"(a*){2}(x)\", r\"x\", Some((0, 1)), Some((0, 0)), Some((0, 1))}\n-mat!{match_nullsubexpr_78, r\"(a*){2}(x)\", r\"ax\", Some((0, 2)), Some((1, 1)), Some((1, 2))}\n-mat!{match_nullsubexpr_79, r\"(a*){2}(x)\", r\"axa\", Some((0, 2)), Some((1, 1)), Some((1, 2))}\n-\n-// Tests from repetition.dat\n-mat!{match_repetition_10, r\"((..)|(.))\", r\"\", None}\n-mat!{match_repetition_11, r\"((..)|(.))((..)|(.))\", r\"\", None}\n-mat!{match_repetition_12, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"\", None}\n-mat!{match_repetition_14, r\"((..)|(.)){1}\", r\"\", None}\n-mat!{match_repetition_15, r\"((..)|(.)){2}\", r\"\", None}\n-mat!{match_repetition_16, r\"((..)|(.)){3}\", r\"\", None}\n-mat!{match_repetition_18, r\"((..)|(.))*\", r\"\", Some((0, 0))}\n-mat!{match_repetition_20, r\"((..)|(.))\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1))}\n-mat!{match_repetition_21, r\"((..)|(.))((..)|(.))\", r\"a\", None}\n-mat!{match_repetition_22, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"a\", None}\n-mat!{match_repetition_24, r\"((..)|(.)){1}\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1))}\n-mat!{match_repetition_25, r\"((..)|(.)){2}\", r\"a\", None}\n-mat!{match_repetition_26, r\"((..)|(.)){3}\", r\"a\", None}\n-mat!{match_repetition_28, r\"((..)|(.))*\", r\"a\", Some((0, 1)), Some((0, 1)), None, Some((0, 1))}\n-mat!{match_repetition_30, r\"((..)|(.))\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_31, r\"((..)|(.))((..)|(.))\", r\"aa\", Some((0, 2)), Some((0, 1)), None, Some((0, 1)), Some((1, 2)), None, Some((1, 2))}\n-mat!{match_repetition_32, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aa\", None}\n-mat!{match_repetition_34, r\"((..)|(.)){1}\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_35, r\"((..)|(.)){2}\", r\"aa\", Some((0, 2)), Some((1, 2)), None, Some((1, 2))}\n-mat!{match_repetition_36, r\"((..)|(.)){3}\", r\"aa\", None}\n-mat!{match_repetition_38, r\"((..)|(.))*\", r\"aa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_40, r\"((..)|(.))\", r\"aaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_41, r\"((..)|(.))((..)|(.))\", r\"aaa\", Some((0, 3)), Some((0, 2)), Some((0, 2)), None, Some((2, 3)), None, Some((2, 3))}\n-mat!{match_repetition_42, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaa\", Some((0, 3)), Some((0, 1)), None, Some((0, 1)), Some((1, 2)), None, Some((1, 2)), Some((2, 3)), None, Some((2, 3))}\n-mat!{match_repetition_44, r\"((..)|(.)){1}\", r\"aaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_46, r\"((..)|(.)){2}\", r\"aaa\", Some((0, 3)), Some((2, 3)), Some((0, 2)), Some((2, 3))}\n-mat!{match_repetition_47, r\"((..)|(.)){3}\", r\"aaa\", Some((0, 3)), Some((2, 3)), None, Some((2, 3))}\n-mat!{match_repetition_50, r\"((..)|(.))*\", r\"aaa\", Some((0, 3)), Some((2, 3)), Some((0, 2)), Some((2, 3))}\n-mat!{match_repetition_52, r\"((..)|(.))\", r\"aaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_53, r\"((..)|(.))((..)|(.))\", r\"aaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_54, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 3)), None, Some((2, 3)), Some((3, 4)), None, Some((3, 4))}\n-mat!{match_repetition_56, r\"((..)|(.)){1}\", r\"aaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_57, r\"((..)|(.)){2}\", r\"aaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_59, r\"((..)|(.)){3}\", r\"aaaa\", Some((0, 4)), Some((3, 4)), Some((0, 2)), Some((3, 4))}\n-mat!{match_repetition_61, r\"((..)|(.))*\", r\"aaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_63, r\"((..)|(.))\", r\"aaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_64, r\"((..)|(.))((..)|(.))\", r\"aaaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_65, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaaa\", Some((0, 5)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None, Some((4, 5)), None, Some((4, 5))}\n-mat!{match_repetition_67, r\"((..)|(.)){1}\", r\"aaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_68, r\"((..)|(.)){2}\", r\"aaaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_70, r\"((..)|(.)){3}\", r\"aaaaa\", Some((0, 5)), Some((4, 5)), Some((2, 4)), Some((4, 5))}\n-mat!{match_repetition_73, r\"((..)|(.))*\", r\"aaaaa\", Some((0, 5)), Some((4, 5)), Some((2, 4)), Some((4, 5))}\n-mat!{match_repetition_75, r\"((..)|(.))\", r\"aaaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_76, r\"((..)|(.))((..)|(.))\", r\"aaaaaa\", Some((0, 4)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_77, r\"((..)|(.))((..)|(.))((..)|(.))\", r\"aaaaaa\", Some((0, 6)), Some((0, 2)), Some((0, 2)), None, Some((2, 4)), Some((2, 4)), None, Some((4, 6)), Some((4, 6)), None}\n-mat!{match_repetition_79, r\"((..)|(.)){1}\", r\"aaaaaa\", Some((0, 2)), Some((0, 2)), Some((0, 2)), None}\n-mat!{match_repetition_80, r\"((..)|(.)){2}\", r\"aaaaaa\", Some((0, 4)), Some((2, 4)), Some((2, 4)), None}\n-mat!{match_repetition_81, r\"((..)|(.)){3}\", r\"aaaaaa\", Some((0, 6)), Some((4, 6)), Some((4, 6)), None}\n-mat!{match_repetition_83, r\"((..)|(.))*\", r\"aaaaaa\", Some((0, 6)), Some((4, 6)), Some((4, 6)), None}\n-mat!{match_repetition_90, r\"X(.?){0,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_91, r\"X(.?){1,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_92, r\"X(.?){2,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_93, r\"X(.?){3,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_94, r\"X(.?){4,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_95, r\"X(.?){5,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_96, r\"X(.?){6,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_97, r\"X(.?){7,}Y\", r\"X1234567Y\", Some((0, 9)), Some((7, 8))}\n-mat!{match_repetition_98, r\"X(.?){8,}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_100, r\"X(.?){0,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_102, r\"X(.?){1,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_104, r\"X(.?){2,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_106, r\"X(.?){3,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_108, r\"X(.?){4,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_110, r\"X(.?){5,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_112, r\"X(.?){6,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_114, r\"X(.?){7,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_115, r\"X(.?){8,8}Y\", r\"X1234567Y\", Some((0, 9)), Some((8, 8))}\n-mat!{match_repetition_126, r\"(a|ab|c|bcd){0,}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_127, r\"(a|ab|c|bcd){1,}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_128, r\"(a|ab|c|bcd){2,}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6))}\n-mat!{match_repetition_129, r\"(a|ab|c|bcd){3,}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6))}\n-mat!{match_repetition_130, r\"(a|ab|c|bcd){4,}(d*)\", r\"ababcd\", None}\n-mat!{match_repetition_131, r\"(a|ab|c|bcd){0,10}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_132, r\"(a|ab|c|bcd){1,10}(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_133, r\"(a|ab|c|bcd){2,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6))}\n-mat!{match_repetition_134, r\"(a|ab|c|bcd){3,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((3, 6)), Some((6, 6))}\n-mat!{match_repetition_135, r\"(a|ab|c|bcd){4,10}(d*)\", r\"ababcd\", None}\n-mat!{match_repetition_136, r\"(a|ab|c|bcd)*(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_137, r\"(a|ab|c|bcd)+(d*)\", r\"ababcd\", Some((0, 1)), Some((0, 1)), Some((1, 1))}\n-mat!{match_repetition_143, r\"(ab|a|c|bcd){0,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_145, r\"(ab|a|c|bcd){1,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_147, r\"(ab|a|c|bcd){2,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_149, r\"(ab|a|c|bcd){3,}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_150, r\"(ab|a|c|bcd){4,}(d*)\", r\"ababcd\", None}\n-mat!{match_repetition_152, r\"(ab|a|c|bcd){0,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_154, r\"(ab|a|c|bcd){1,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_156, r\"(ab|a|c|bcd){2,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_158, r\"(ab|a|c|bcd){3,10}(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_159, r\"(ab|a|c|bcd){4,10}(d*)\", r\"ababcd\", None}\n-mat!{match_repetition_161, r\"(ab|a|c|bcd)*(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-mat!{match_repetition_163, r\"(ab|a|c|bcd)+(d*)\", r\"ababcd\", Some((0, 6)), Some((4, 5)), Some((5, 6))}\n-"}, {"sha": "e11094b1174713a1b2bdbdc0480d4c94421dbd83", "filename": "src/libregex/test/mod.rs", "status": "removed", "additions": 0, "deletions": 24, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fmod.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,24 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-macro_rules! regex {\n-    ($re:expr) => (\n-        match ::regex::Regex::new($re) {\n-            Ok(re) => re,\n-            Err(err) => panic!(\"{:?}\", err),\n-        }\n-    );\n-}\n-\n-#[path = \"bench.rs\"]\n-mod dynamic_bench;\n-#[path = \"tests.rs\"]\n-mod dynamic_tests;\n-"}, {"sha": "62e14731c207bb3e99685bfd51d143a287f59494", "filename": "src/libregex/test/native_static.rs", "status": "removed", "additions": 0, "deletions": 26, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fnative_static.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Fnative_static.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Fnative_static.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,26 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use regex::Regex;\n-static RE: Regex = regex!(r\"\\d+\");\n-\n-#[test]\n-fn static_splitn() {\n-    let text = \"cauchy123plato456tyler789binx\";\n-    let subs: Vec<&str> = RE.splitn(text, 2).collect();\n-    assert_eq!(subs, vec!(\"cauchy\", \"plato456tyler789binx\"));\n-}\n-\n-#[test]\n-fn static_split() {\n-    let text = \"cauchy123plato456tyler789binx\";\n-    let subs: Vec<&str> = RE.split(text).collect();\n-    assert_eq!(subs, vec!(\"cauchy\", \"plato\", \"tyler\", \"binx\"));\n-}"}, {"sha": "b69420ac05bd1336e5b187950f8037bd0c2815e6", "filename": "src/libregex/test/tests.rs", "status": "removed", "additions": 0, "deletions": 245, "changes": 245, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftest%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftest%2Ftests.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,245 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// ignore-tidy-linelength\n-// ignore-lexer-test FIXME #15679\n-\n-use regex::{Regex, NoExpand};\n-\n-#[test]\n-fn splitn() {\n-    let re = regex!(r\"\\d+\");\n-    let text = \"cauchy123plato456tyler789binx\";\n-    let subs: Vec<&str> = re.splitn(text, 2).collect();\n-    assert_eq!(subs, vec!(\"cauchy\", \"plato456tyler789binx\"));\n-}\n-\n-#[test]\n-fn split() {\n-    let re = regex!(r\"\\d+\");\n-    let text = \"cauchy123plato456tyler789binx\";\n-    let subs: Vec<&str> = re.split(text).collect();\n-    assert_eq!(subs, vec!(\"cauchy\", \"plato\", \"tyler\", \"binx\"));\n-}\n-\n-#[test]\n-fn empty_regex_empty_match() {\n-    let re = regex!(\"\");\n-    let ms = re.find_iter(\"\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 0)]);\n-}\n-\n-#[test]\n-fn empty_regex_nonempty_match() {\n-    let re = regex!(\"\");\n-    let ms = re.find_iter(\"abc\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 0), (1, 1), (2, 2), (3, 3)]);\n-}\n-\n-#[test]\n-fn quoted_bracket_set() {\n-    let re = regex!(r\"([\\x{5b}\\x{5d}])\");\n-    let ms = re.find_iter(\"[]\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 1), (1, 2)]);\n-    let re = regex!(r\"([\\[\\]])\");\n-    let ms = re.find_iter(\"[]\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 1), (1, 2)]);\n-}\n-\n-#[test]\n-fn first_range_starts_with_left_bracket() {\n-    let re = regex!(r\"([[-z])\");\n-    let ms = re.find_iter(\"[]\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 1), (1, 2)]);\n-}\n-\n-#[test]\n-fn range_ends_with_escape() {\n-    let re = regex!(r\"([\\[-\\x{5d}])\");\n-    let ms = re.find_iter(\"[]\").collect::<Vec<(uint, uint)>>();\n-    assert_eq!(ms, vec![(0, 1), (1, 2)]);\n-}\n-\n-macro_rules! replace {\n-    ($name:ident, $which:ident, $re:expr,\n-     $search:expr, $replace:expr, $result:expr) => (\n-        #[test]\n-        fn $name() {\n-            let re = regex!($re);\n-            assert_eq!(re.$which($search, $replace), String::from_str($result));\n-        }\n-    );\n-}\n-\n-replace!{rep_first, replace, r\"\\d\", \"age: 26\", \"Z\", \"age: Z6\"}\n-replace!{rep_plus, replace, r\"\\d+\", \"age: 26\", \"Z\", \"age: Z\"}\n-replace!{rep_all, replace_all, r\"\\d\", \"age: 26\", \"Z\", \"age: ZZ\"}\n-replace!{rep_groups, replace, r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", \"$2 $1\", \"w2 w1\"}\n-replace!{rep_double_dollar, replace,\n-         r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", \"$2 $$1\", \"w2 $1\"}\n-replace!{rep_no_expand, replace,\n-         r\"(\\S+)\\s+(\\S+)\", \"w1 w2\", NoExpand(\"$2 $1\"), \"$2 $1\"}\n-replace!{rep_named, replace_all,\n-         r\"(?P<first>\\S+)\\s+(?P<last>\\S+)(?P<space>\\s*)\",\n-         \"w1 w2 w3 w4\", \"$last $first$space\", \"w2 w1 w4 w3\"}\n-replace!{rep_trim, replace_all, \"^[ \\t]+|[ \\t]+$\", \" \\t  trim me\\t   \\t\",\n-         \"\", \"trim me\"}\n-\n-macro_rules! noparse {\n-    ($name:ident, $re:expr) => (\n-        #[test]\n-        fn $name() {\n-            let re = $re;\n-            match Regex::new(re) {\n-                Err(_) => {},\n-                Ok(_) => panic!(\"Regex '{}' should cause a parse error.\", re),\n-            }\n-        }\n-    );\n-}\n-\n-noparse!{fail_double_repeat, \"a**\"}\n-noparse!{fail_no_repeat_arg, \"*\"}\n-noparse!{fail_no_repeat_arg_begin, \"^*\"}\n-noparse!{fail_incomplete_escape, \"\\\\\"}\n-noparse!{fail_class_incomplete, \"[A-\"}\n-noparse!{fail_class_not_closed, \"[A\"}\n-noparse!{fail_class_no_begin, r\"[\\A]\"}\n-noparse!{fail_class_no_end, r\"[\\z]\"}\n-noparse!{fail_class_no_boundary, r\"[\\b]\"}\n-noparse!{fail_open_paren, \"(\"}\n-noparse!{fail_close_paren, \")\"}\n-noparse!{fail_invalid_range, \"[a-Z]\"}\n-noparse!{fail_empty_capture_name, \"(?P<>a)\"}\n-noparse!{fail_empty_capture_exp, \"(?P<name>)\"}\n-noparse!{fail_bad_capture_name, \"(?P<na-me>)\"}\n-noparse!{fail_bad_flag, \"(?a)a\"}\n-noparse!{fail_empty_alt_before, \"|a\"}\n-noparse!{fail_empty_alt_after, \"a|\"}\n-noparse!{fail_counted_big_exact, \"a{1001}\"}\n-noparse!{fail_counted_big_min, \"a{1001,}\"}\n-noparse!{fail_counted_no_close, \"a{1001\"}\n-noparse!{fail_unfinished_cap, \"(?\"}\n-noparse!{fail_unfinished_escape, \"\\\\\"}\n-noparse!{fail_octal_digit, r\"\\8\"}\n-noparse!{fail_hex_digit, r\"\\xG0\"}\n-noparse!{fail_hex_short, r\"\\xF\"}\n-noparse!{fail_hex_long_digits, r\"\\x{fffg}\"}\n-noparse!{fail_flag_bad, \"(?a)\"}\n-noparse!{fail_flag_empty, \"(?)\"}\n-noparse!{fail_double_neg, \"(?-i-i)\"}\n-noparse!{fail_neg_empty, \"(?i-)\"}\n-noparse!{fail_empty_group, \"()\"}\n-noparse!{fail_dupe_named, \"(?P<a>.)(?P<a>.)\"}\n-noparse!{fail_range_end_no_class, \"[a-[:lower:]]\"}\n-noparse!{fail_range_end_no_begin, r\"[a-\\A]\"}\n-noparse!{fail_range_end_no_end, r\"[a-\\z]\"}\n-noparse!{fail_range_end_no_boundary, r\"[a-\\b]\"}\n-noparse!{fail_repeat_no_expr, r\"-|+\"}\n-\n-macro_rules! mat {\n-    ($name:ident, $re:expr, $text:expr, $($loc:tt)+) => (\n-        #[test]\n-        fn $name() {\n-            let text = $text;\n-            let expected: Vec<Option<(uint, uint)>> = vec!($($loc)+);\n-            let r = regex!($re);\n-            let got = match r.captures(text) {\n-                Some(c) => c.iter_pos().collect::<Vec<Option<(uint, uint)>>>(),\n-                None => vec!(None),\n-            };\n-            // The test set sometimes leave out capture groups, so truncate\n-            // actual capture groups to match test set.\n-            let mut sgot = got.as_slice();\n-            if sgot.len() > expected.len() {\n-                sgot = &sgot[..expected.len()]\n-            }\n-            if expected != sgot {\n-                panic!(\"For RE '{}' against '{}', expected '{:?}' but got '{:?}'\",\n-                      $re, text, expected, sgot);\n-            }\n-        }\n-    );\n-}\n-\n-// Some crazy expressions from regular-expressions.info.\n-mat!{match_ranges,\n-     r\"\\b(?:[0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\b\",\n-     \"num: 255\", Some((5, 8))}\n-mat!{match_ranges_not,\n-     r\"\\b(?:[0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\\b\",\n-     \"num: 256\", None}\n-mat!{match_float1, r\"[-+]?[0-9]*\\.?[0-9]+\", \"0.1\", Some((0, 3))}\n-mat!{match_float2, r\"[-+]?[0-9]*\\.?[0-9]+\", \"0.1.2\", Some((0, 3))}\n-mat!{match_float3, r\"[-+]?[0-9]*\\.?[0-9]+\", \"a1.2\", Some((1, 4))}\n-mat!{match_float4, r\"^[-+]?[0-9]*\\.?[0-9]+$\", \"1.a\", None}\n-mat!{match_email, r\"(?i)\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b\",\n-     \"mine is jam.slam@gmail.com \", Some((8, 26))}\n-mat!{match_email_not, r\"(?i)\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\\b\",\n-     \"mine is jam.slam@gmail \", None}\n-mat!{match_email_big, r\"[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*@(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\",\n-     \"mine is jam.slam@gmail.com \", Some((8, 26))}\n-mat!{match_date1,\n-     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n-     \"1900-01-01\", Some((0, 10))}\n-mat!{match_date2,\n-     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n-     \"1900-00-01\", None}\n-mat!{match_date3,\n-     r\"^(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])$\",\n-     \"1900-13-01\", None}\n-\n-// Exercise the flags.\n-mat!{match_flag_case, \"(?i)abc\", \"ABC\", Some((0, 3))}\n-mat!{match_flag_weird_case, \"(?i)a(?-i)bc\", \"Abc\", Some((0, 3))}\n-mat!{match_flag_weird_case_not, \"(?i)a(?-i)bc\", \"ABC\", None}\n-mat!{match_flag_case_dotnl, \"(?is)a.\", \"A\\n\", Some((0, 2))}\n-mat!{match_flag_case_dotnl_toggle, \"(?is)a.(?-is)a.\", \"A\\nab\", Some((0, 4))}\n-mat!{match_flag_case_dotnl_toggle_not, \"(?is)a.(?-is)a.\", \"A\\na\\n\", None}\n-mat!{match_flag_case_dotnl_toggle_ok, \"(?is)a.(?-is:a.)?\", \"A\\na\\n\", Some((0, 2))}\n-mat!{match_flag_multi, \"(?m)(?:^\\\\d+$\\n?)+\", \"123\\n456\\n789\", Some((0, 11))}\n-mat!{match_flag_ungreedy, \"(?U)a+\", \"aa\", Some((0, 1))}\n-mat!{match_flag_ungreedy_greedy, \"(?U)a+?\", \"aa\", Some((0, 2))}\n-mat!{match_flag_ungreedy_noop, \"(?U)(?-U)a+\", \"aa\", Some((0, 2))}\n-\n-// Some Unicode tests.\n-// A couple of these are commented out because something in the guts of macro expansion is creating\n-// invalid byte strings.\n-//mat!{uni_literal, r\"\u2160\", \"\u2160\", Some((0, 3))}\n-mat!{uni_one, r\"\\pN\", \"\u2160\", Some((0, 3))}\n-mat!{uni_mixed, r\"\\pN+\", \"\u21601\u21612\", Some((0, 8))}\n-mat!{uni_not, r\"\\PN+\", \"ab\u2160\", Some((0, 2))}\n-mat!{uni_not_class, r\"[\\PN]+\", \"ab\u2160\", Some((0, 2))}\n-mat!{uni_not_class_neg, r\"[^\\PN]+\", \"ab\u2160\", Some((2, 5))}\n-mat!{uni_case, r\"(?i)\u0394\", \"\u03b4\", Some((0, 2))}\n-//mat!{uni_case_not, r\"\u0394\", \"\u03b4\", None}\n-mat!{uni_case_upper, r\"\\p{Lu}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 8))}\n-mat!{uni_case_upper_nocase_flag, r\"(?i)\\p{Lu}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 10))}\n-mat!{uni_case_upper_nocase, r\"\\p{L}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((0, 10))}\n-mat!{uni_case_lower, r\"\\p{Ll}+\", \"\u039b\u0398\u0393\u0394\u03b1\", Some((8, 10))}\n-\n-// Test the Unicode friendliness of Perl character classes.\n-mat!{uni_perl_w, r\"\\w+\", \"d\u03b4d\", Some((0, 4))}\n-mat!{uni_perl_w_not, r\"\\w+\", \"\u2961\", None}\n-mat!{uni_perl_w_neg, r\"\\W+\", \"\u2961\", Some((0, 3))}\n-mat!{uni_perl_d, r\"\\d+\", \"1\u0968\u09699\", Some((0, 8))}\n-mat!{uni_perl_d_not, r\"\\d+\", \"\u2161\", None}\n-mat!{uni_perl_d_neg, r\"\\D+\", \"\u2161\", Some((0, 3))}\n-mat!{uni_perl_s, r\"\\s+\", \"\u1680\", Some((0, 3))}\n-mat!{uni_perl_s_not, r\"\\s+\", \"\u2603\", None}\n-mat!{uni_perl_s_neg, r\"\\S+\", \"\u2603\", Some((0, 3))}\n-\n-// And do the same for word boundaries.\n-mat!{uni_boundary_none, r\"\\d\\b\", \"6\u03b4\", None}\n-mat!{uni_boundary_ogham, r\"\\d\\b\", \"6\u1680\", Some((0, 1))}\n-\n-// A whole mess of tests from Glenn Fowler's regex test suite.\n-// Generated by the 'src/etc/regex-match-tests' program.\n-mod matches;"}, {"sha": "f47dbf4c449bcc067f3d535cce4b43b4cc52e21d", "filename": "src/libregex/testdata/LICENSE", "status": "removed", "additions": 0, "deletions": 19, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2FLICENSE", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2FLICENSE", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2FLICENSE?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,19 +0,0 @@\n-The following license covers testregex.c and all associated test data.\n-\n-Permission is hereby granted, free of charge, to any person obtaining a\n-copy of THIS SOFTWARE FILE (the \"Software\"), to deal in the Software\n-without restriction, including without limitation the rights to use,\n-copy, modify, merge, publish, distribute, and/or sell copies of the\n-Software, and to permit persons to whom the Software is furnished to do\n-so, subject to the following disclaimer:\n-\n-THIS SOFTWARE IS PROVIDED BY AT&T ``AS IS'' AND ANY EXPRESS OR IMPLIED\n-WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n-MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n-IN NO EVENT SHALL AT&T BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."}, {"sha": "33b0ba17ed7f6aed2808a98f8fc00dcaa3dc488e", "filename": "src/libregex/testdata/README", "status": "removed", "additions": 0, "deletions": 17, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2FREADME", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2FREADME", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2FREADME?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,17 +0,0 @@\n-Test data was taken from the Go distribution, which was in turn taken from the \n-testregex test suite:\n-\n-  http://www2.research.att.com/~astopen/testregex/testregex.html\n-\n-The LICENSE in this directory corresponds to the LICENSE that the data was\n-released under.\n-\n-The tests themselves were modified for RE2/Go. A couple were modified further \n-by me (Andrew Gallant) (only in repetition.dat) so that RE2/Go would pass them. \n-(Yes, it seems like RE2/Go includes failing test cases.) This may or may not \n-have been a bad idea, but I think being consistent with an established Regex \n-library is worth something.\n-\n-Note that these files are read by 'src/etc/regexp-match-tests' and turned into \n-Rust tests found in 'src/libregexp/tests/matches.rs'.\n-"}, {"sha": "e55efaeec062428fa08511d579dd6b9d897ff83c", "filename": "src/libregex/testdata/basic.dat", "status": "removed", "additions": 0, "deletions": 221, "changes": 221, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Fbasic.dat", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Fbasic.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Fbasic.dat?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,221 +0,0 @@\n-NOTE\tall standard compliant implementations should pass these : 2002-05-31\n-\n-BE\tabracadabra$\tabracadabracadabra\t(7,18)\n-BE\ta...b\t\tabababbb\t\t(2,7)\n-BE\tXXXXXX\t\t..XXXXXX\t\t(2,8)\n-E\t\\)\t\t()\t(1,2)\n-BE\ta]\t\ta]a\t(0,2)\n-B\t}\t\t}\t(0,1)\n-E\t\\}\t\t}\t(0,1)\n-BE\t\\]\t\t]\t(0,1)\n-B\t]\t\t]\t(0,1)\n-E\t]\t\t]\t(0,1)\n-B\t{\t\t{\t(0,1)\n-B\t}\t\t}\t(0,1)\n-BE\t^a\t\tax\t(0,1)\n-BE\t\\^a\t\ta^a\t(1,3)\n-BE\ta\\^\t\ta^\t(0,2)\n-BE\ta$\t\taa\t(1,2)\n-BE\ta\\$\t\ta$\t(0,2)\n-BE\t^$\t\tNULL\t(0,0)\n-E\t$^\t\tNULL\t(0,0)\n-E\ta($)\t\taa\t(1,2)(2,2)\n-E\ta*(^a)\t\taa\t(0,1)(0,1)\n-E\t(..)*(...)*\t\ta\t(0,0)\n-E\t(..)*(...)*\t\tabcd\t(0,4)(2,4)\n-E\t(ab|a)(bc|c)\t\tabc\t(0,3)(0,2)(2,3)\n-E\t(ab)c|abc\t\tabc\t(0,3)(0,2)\n-E\ta{0}b\t\tab\t\t\t(1,2)\n-E\t(a*)(b?)(b+)b{3}\taaabbbbbbb\t(0,10)(0,3)(3,4)(4,7)\n-E\t(a*)(b{0,1})(b{1,})b{3}\taaabbbbbbb\t(0,10)(0,3)(3,4)(4,7)\n-E\ta{9876543210}\tNULL\tBADBR\n-E\t((a|a)|a)\t\t\ta\t(0,1)(0,1)(0,1)\n-E\t(a*)(a|aa)\t\t\taaaa\t(0,4)(0,3)(3,4)\n-E\ta*(a.|aa)\t\t\taaaa\t(0,4)(2,4)\n-E\ta(b)|c(d)|a(e)f\t\t\taef\t(0,3)(?,?)(?,?)(1,2)\n-E\t(a|b)?.*\t\t\tb\t(0,1)(0,1)\n-E\t(a|b)c|a(b|c)\t\t\tac\t(0,2)(0,1)\n-E\t(a|b)c|a(b|c)\t\t\tab\t(0,2)(?,?)(1,2)\n-E\t(a|b)*c|(a|ab)*c\t\tabc\t(0,3)(1,2)\n-E\t(a|b)*c|(a|ab)*c\t\txc\t(1,2)\n-E\t(.a|.b).*|.*(.a|.b)\t\txa\t(0,2)(0,2)\n-E\ta?(ab|ba)ab\t\t\tabab\t(0,4)(0,2)\n-E\ta?(ac{0}b|ba)ab\t\t\tabab\t(0,4)(0,2)\n-E\tab|abab\t\t\t\tabbabab\t(0,2)\n-E\taba|bab|bba\t\t\tbaaabbbaba\t(5,8)\n-E\taba|bab\t\t\t\tbaaabbbaba\t(6,9)\n-E\t(aa|aaa)*|(a|aaaaa)\t\taa\t(0,2)(0,2)\n-E\t(a.|.a.)*|(a|.a...)\t\taa\t(0,2)(0,2)\n-E\tab|a\t\t\t\txabc\t(1,3)\n-E\tab|a\t\t\t\txxabc\t(2,4)\n-Ei\t(Ab|cD)*\t\t\taBcD\t(0,4)(2,4)\n-BE\t[^-]\t\t\t--a\t\t(2,3)\n-BE\t[a-]*\t\t\t--a\t\t(0,3)\n-BE\t[a-m-]*\t\t\t--amoma--\t(0,4)\n-E\t:::1:::0:|:::1:1:0:\t:::0:::1:::1:::0:\t(8,17)\n-E\t:::1:::0:|:::1:1:1:\t:::0:::1:::1:::0:\t(8,17)\n-{E\t[[:upper:]]\t\tA\t\t(0,1)\t[[<element>]] not supported\n-E\t[[:lower:]]+\t\t`az{\t\t(1,3)\n-E\t[[:upper:]]+\t\t@AZ[\t\t(1,3)\n-# No collation in Go\n-#BE\t[[-]]\t\t\t[[-]]\t\t(2,4)\n-#BE\t[[.NIL.]]\tNULL\tECOLLATE\n-#BE\t[[=aleph=]]\tNULL\tECOLLATE\n-}\n-BE$\t\\n\t\t\\n\t(0,1)\n-BEn$\t\\n\t\t\\n\t(0,1)\n-BE$\t[^a]\t\t\\n\t(0,1)\n-BE$\t\\na\t\t\\na\t(0,2)\n-E\t(a)(b)(c)\tabc\t(0,3)(0,1)(1,2)(2,3)\n-BE\txxx\t\txxx\t(0,3)\n-E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\tfeb 6,\t(0,6)\n-E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\t2/7\t(0,3)\n-E1\t(^|[ (,;])((([Ff]eb[^ ]* *|0*2/|\\* */?)0*[6-7]))([^0-9]|$)\tfeb 1,Feb 6\t(5,11)\n-E3\t((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))\tx\t(0,1)(0,1)(0,1)\n-E3\t((((((((((((((((((((((((((((((x))))))))))))))))))))))))))))))*\txx\t(0,2)(1,2)(1,2)\n-E\ta?(ab|ba)*\tababababababababababababababababababababababababababababababababababababababababa\t(0,81)(79,81)\n-E\tabaa|abbaa|abbbaa|abbbbaa\tababbabbbabbbabbbbabbbbaa\t(18,25)\n-E\tabaa|abbaa|abbbaa|abbbbaa\tababbabbbabbbabbbbabaa\t(18,22)\n-E\taaac|aabc|abac|abbc|baac|babc|bbac|bbbc\tbaaabbbabac\t(7,11)\n-BE$\t.*\t\t\t\\x01\\x7f\t(0,2)\n-E\taaaa|bbbb|cccc|ddddd|eeeeee|fffffff|gggg|hhhh|iiiii|jjjjj|kkkkk|llll\t\tXaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\t(53,57)\n-L\taaaa\\nbbbb\\ncccc\\nddddd\\neeeeee\\nfffffff\\ngggg\\nhhhh\\niiiii\\njjjjj\\nkkkkk\\nllll\t\tXaaaXbbbXcccXdddXeeeXfffXgggXhhhXiiiXjjjXkkkXlllXcbaXaaaa\tNOMATCH\n-E\ta*a*a*a*a*b\t\taaaaaaaaab\t(0,10)\n-BE\t^\t\t\tNULL\t\t(0,0)\n-BE\t$\t\t\tNULL\t\t(0,0)\n-BE\t^$\t\t\tNULL\t\t(0,0)\n-BE\t^a$\t\t\ta\t\t(0,1)\n-BE\tabc\t\t\tabc\t\t(0,3)\n-BE\tabc\t\t\txabcy\t\t(1,4)\n-BE\tabc\t\t\tababc\t\t(2,5)\n-BE\tab*c\t\t\tabc\t\t(0,3)\n-BE\tab*bc\t\t\tabc\t\t(0,3)\n-BE\tab*bc\t\t\tabbc\t\t(0,4)\n-BE\tab*bc\t\t\tabbbbc\t\t(0,6)\n-E\tab+bc\t\t\tabbc\t\t(0,4)\n-E\tab+bc\t\t\tabbbbc\t\t(0,6)\n-E\tab?bc\t\t\tabbc\t\t(0,4)\n-E\tab?bc\t\t\tabc\t\t(0,3)\n-E\tab?c\t\t\tabc\t\t(0,3)\n-BE\t^abc$\t\t\tabc\t\t(0,3)\n-BE\t^abc\t\t\tabcc\t\t(0,3)\n-BE\tabc$\t\t\taabc\t\t(1,4)\n-BE\t^\t\t\tabc\t\t(0,0)\n-BE\t$\t\t\tabc\t\t(3,3)\n-BE\ta.c\t\t\tabc\t\t(0,3)\n-BE\ta.c\t\t\taxc\t\t(0,3)\n-BE\ta.*c\t\t\taxyzc\t\t(0,5)\n-BE\ta[bc]d\t\t\tabd\t\t(0,3)\n-BE\ta[b-d]e\t\t\tace\t\t(0,3)\n-BE\ta[b-d]\t\t\taac\t\t(1,3)\n-BE\ta[-b]\t\t\ta-\t\t(0,2)\n-BE\ta[b-]\t\t\ta-\t\t(0,2)\n-BE\ta]\t\t\ta]\t\t(0,2)\n-BE\ta[]]b\t\t\ta]b\t\t(0,3)\n-BE\ta[^bc]d\t\t\taed\t\t(0,3)\n-BE\ta[^-b]c\t\t\tadc\t\t(0,3)\n-BE\ta[^]b]c\t\t\tadc\t\t(0,3)\n-E\tab|cd\t\t\tabc\t\t(0,2)\n-E\tab|cd\t\t\tabcd\t\t(0,2)\n-E\ta\\(b\t\t\ta(b\t\t(0,3)\n-E\ta\\(*b\t\t\tab\t\t(0,2)\n-E\ta\\(*b\t\t\ta((b\t\t(0,4)\n-E\t((a))\t\t\tabc\t\t(0,1)(0,1)(0,1)\n-E\t(a)b(c)\t\t\tabc\t\t(0,3)(0,1)(2,3)\n-E\ta+b+c\t\t\taabbabc\t\t(4,7)\n-E\ta*\t\t\taaa\t\t(0,3)\n-#E\t(a*)*\t\t\t-\t\t(0,0)(0,0)\n-E\t(a*)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n-E\t(a*)+\t\t\t-\t\t(0,0)(0,0)\n-#E\t(a*|b)*\t\t\t-\t\t(0,0)(0,0)\n-E\t(a*|b)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n-E\t(a+|b)*\t\t\tab\t\t(0,2)(1,2)\n-E\t(a+|b)+\t\t\tab\t\t(0,2)(1,2)\n-E\t(a+|b)?\t\t\tab\t\t(0,1)(0,1)\n-BE\t[^ab]*\t\t\tcde\t\t(0,3)\n-#E\t(^)*\t\t\t-\t\t(0,0)(0,0)\n-E\t(^)*\t\t\t-\t\t(0,0)(?,?)\tRE2/Go\n-BE\ta*\t\t\tNULL\t\t(0,0)\n-E\t([abc])*d\t\tabbbcd\t\t(0,6)(4,5)\n-E\t([abc])*bcd\t\tabcd\t\t(0,4)(0,1)\n-E\ta|b|c|d|e\t\te\t\t(0,1)\n-E\t(a|b|c|d|e)f\t\tef\t\t(0,2)(0,1)\n-#E\t((a*|b))*\t\t-\t\t(0,0)(0,0)(0,0)\n-E\t((a*|b))*\t\t-\t\t(0,0)(?,?)(?,?)\tRE2/Go\n-BE\tabcd*efg\t\tabcdefg\t\t(0,7)\n-BE\tab*\t\t\txabyabbbz\t(1,3)\n-BE\tab*\t\t\txayabbbz\t(1,2)\n-E\t(ab|cd)e\t\tabcde\t\t(2,5)(2,4)\n-BE\t[abhgefdc]ij\t\thij\t\t(0,3)\n-E\t(a|b)c*d\t\tabcd\t\t(1,4)(1,2)\n-E\t(ab|ab*)bc\t\tabc\t\t(0,3)(0,1)\n-E\ta([bc]*)c*\t\tabc\t\t(0,3)(1,3)\n-E\ta([bc]*)(c*d)\t\tabcd\t\t(0,4)(1,3)(3,4)\n-E\ta([bc]+)(c*d)\t\tabcd\t\t(0,4)(1,3)(3,4)\n-E\ta([bc]*)(c+d)\t\tabcd\t\t(0,4)(1,2)(2,4)\n-E\ta[bcd]*dcdcde\t\tadcdcde\t\t(0,7)\n-E\t(ab|a)b*c\t\tabc\t\t(0,3)(0,2)\n-E\t((a)(b)c)(d)\t\tabcd\t\t(0,4)(0,3)(0,1)(1,2)(3,4)\n-BE\t[A-Za-z_][A-Za-z0-9_]*\talpha\t\t(0,5)\n-E\t^a(bc+|b[eh])g|.h$\tabh\t\t(1,3)\n-E\t(bc+d$|ef*g.|h?i(j|k))\teffgz\t\t(0,5)(0,5)\n-E\t(bc+d$|ef*g.|h?i(j|k))\tij\t\t(0,2)(0,2)(1,2)\n-E\t(bc+d$|ef*g.|h?i(j|k))\treffgz\t\t(1,6)(1,6)\n-E\t(((((((((a)))))))))\ta\t\t(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)(0,1)\n-BE\tmultiple words\t\tmultiple words yeah\t(0,14)\n-E\t(.*)c(.*)\t\tabcde\t\t(0,5)(0,2)(3,5)\n-BE\tabcd\t\t\tabcd\t\t(0,4)\n-E\ta(bc)d\t\t\tabcd\t\t(0,4)(1,3)\n-E\ta[\u0001-\u0003]?c\t\ta\u0002c\t\t(0,3)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Qaddafi\t(0,15)(?,?)(10,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMo'ammar Gadhafi\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Kaddafi\t(0,15)(?,?)(10,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Qadhafi\t(0,15)(?,?)(10,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Gadafi\t(0,14)(?,?)(10,11)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMu'ammar Qadafi\t(0,15)(?,?)(11,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoamar Gaddafi\t(0,14)(?,?)(9,11)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMu'ammar Qadhdhafi\t(0,18)(?,?)(13,15)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Khaddafi\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghaddafy\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghadafi\t(0,15)(?,?)(11,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Ghaddafi\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuamar Kaddafi\t(0,14)(?,?)(9,11)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Quathafi\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMuammar Gheddafi\t(0,16)(?,?)(11,13)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoammar Khadafy\t(0,15)(?,?)(11,12)\n-E\tM[ou]'?am+[ae]r .*([AEae]l[- ])?[GKQ]h?[aeu]+([dtz][dhz]?)+af[iy]\tMoammar Qudhafi\t(0,15)(?,?)(10,12)\n-E\ta+(b|c)*d+\t\taabcdd\t\t\t(0,6)(3,4)\n-E\t^.+$\t\t\tvivi\t\t\t(0,4)\n-E\t^(.+)$\t\t\tvivi\t\t\t(0,4)(0,4)\n-E\t^([^!.]+).att.com!(.+)$\tgryphon.att.com!eby\t(0,19)(0,7)(16,19)\n-E\t^([^!]+!)?([^!]+)$\tbas\t\t\t(0,3)(?,?)(0,3)\n-E\t^([^!]+!)?([^!]+)$\tbar!bas\t\t\t(0,7)(0,4)(4,7)\n-E\t^([^!]+!)?([^!]+)$\tfoo!bas\t\t\t(0,7)(0,4)(4,7)\n-E\t^.+!([^!]+!)([^!]+)$\tfoo!bar!bas\t\t(0,11)(4,8)(8,11)\n-E\t((foo)|(bar))!bas\tbar!bas\t\t\t(0,7)(0,3)(?,?)(0,3)\n-E\t((foo)|(bar))!bas\tfoo!bar!bas\t\t(4,11)(4,7)(?,?)(4,7)\n-E\t((foo)|(bar))!bas\tfoo!bas\t\t\t(0,7)(0,3)(0,3)\n-E\t((foo)|bar)!bas\t\tbar!bas\t\t\t(0,7)(0,3)\n-E\t((foo)|bar)!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)\n-E\t((foo)|bar)!bas\t\tfoo!bas\t\t\t(0,7)(0,3)(0,3)\n-E\t(foo|(bar))!bas\t\tbar!bas\t\t\t(0,7)(0,3)(0,3)\n-E\t(foo|(bar))!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)(4,7)\n-E\t(foo|(bar))!bas\t\tfoo!bas\t\t\t(0,7)(0,3)\n-E\t(foo|bar)!bas\t\tbar!bas\t\t\t(0,7)(0,3)\n-E\t(foo|bar)!bas\t\tfoo!bar!bas\t\t(4,11)(4,7)\n-E\t(foo|bar)!bas\t\tfoo!bas\t\t\t(0,7)(0,3)\n-E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bar!bas\t(0,11)(0,11)(?,?)(?,?)(4,8)(8,11)\n-E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tbas\t\t(0,3)(?,?)(0,3)\n-E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tbar!bas\t\t(0,7)(0,4)(4,7)\n-E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tfoo!bar!bas\t(0,11)(?,?)(?,?)(4,8)(8,11)\n-E\t^([^!]+!)?([^!]+)$|^.+!([^!]+!)([^!]+)$\tfoo!bas\t\t(0,7)(0,4)(4,7)\n-E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tbas\t\t(0,3)(0,3)(?,?)(0,3)\n-E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tbar!bas\t\t(0,7)(0,7)(0,4)(4,7)\n-E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bar!bas\t(0,11)(0,11)(?,?)(?,?)(4,8)(8,11)\n-E\t^(([^!]+!)?([^!]+)|.+!([^!]+!)([^!]+))$\tfoo!bas\t\t(0,7)(0,7)(0,4)(4,7)\n-E\t.*(/XXX).*\t\t\t/XXX\t\t\t(0,4)(0,4)\n-E\t.*(\\\\XXX).*\t\t\t\\XXX\t\t\t(0,4)(0,4)\n-E\t\\\\XXX\t\t\t\t\\XXX\t\t\t(0,4)\n-E\t.*(/000).*\t\t\t/000\t\t\t(0,4)(0,4)\n-E\t.*(\\\\000).*\t\t\t\\000\t\t\t(0,4)(0,4)\n-E\t\\\\000\t\t\t\t\\000\t\t\t(0,4)"}, {"sha": "2e18fbb917070347df82ed24978b62884652a037", "filename": "src/libregex/testdata/nullsubexpr.dat", "status": "removed", "additions": 0, "deletions": 79, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Fnullsubexpr.dat?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,79 +0,0 @@\n-NOTE\tnull subexpression matches : 2002-06-06\n-\n-E\t(a*)*\t\ta\t\t(0,1)(0,1)\n-#E\tSAME\t\tx\t\t(0,0)(0,0)\n-E\tSAME\t\tx\t\t(0,0)(?,?)\tRE2/Go\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-E\t(a*)+\t\ta\t\t(0,1)(0,1)\n-E\tSAME\t\tx\t\t(0,0)(0,0)\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-E\t(a+)*\t\ta\t\t(0,1)(0,1)\n-E\tSAME\t\tx\t\t(0,0)\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-E\t(a+)+\t\ta\t\t(0,1)(0,1)\n-E\tSAME\t\tx\t\tNOMATCH\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-\n-E\t([a]*)*\t\ta\t\t(0,1)(0,1)\n-#E\tSAME\t\tx\t\t(0,0)(0,0)\n-E\tSAME\t\tx\t\t(0,0)(?,?)\tRE2/Go\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-E\t([a]*)+\t\ta\t\t(0,1)(0,1)\n-E\tSAME\t\tx\t\t(0,0)(0,0)\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaax\t\t(0,6)(0,6)\n-E\t([^b]*)*\ta\t\t(0,1)(0,1)\n-#E\tSAME\t\tb\t\t(0,0)(0,0)\n-E\tSAME\t\tb\t\t(0,0)(?,?)\tRE2/Go\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\taaaaaab\t\t(0,6)(0,6)\n-E\t([ab]*)*\ta\t\t(0,1)(0,1)\n-E\tSAME\t\taaaaaa\t\t(0,6)(0,6)\n-E\tSAME\t\tababab\t\t(0,6)(0,6)\n-E\tSAME\t\tbababa\t\t(0,6)(0,6)\n-E\tSAME\t\tb\t\t(0,1)(0,1)\n-E\tSAME\t\tbbbbbb\t\t(0,6)(0,6)\n-E\tSAME\t\taaaabcde\t(0,5)(0,5)\n-E\t([^a]*)*\tb\t\t(0,1)(0,1)\n-E\tSAME\t\tbbbbbb\t\t(0,6)(0,6)\n-#E\tSAME\t\taaaaaa\t\t(0,0)(0,0)\n-E\tSAME\t\taaaaaa\t\t(0,0)(?,?)\tRE2/Go\n-E\t([^ab]*)*\tccccxx\t\t(0,6)(0,6)\n-#E\tSAME\t\tababab\t\t(0,0)(0,0)\n-E\tSAME\t\tababab\t\t(0,0)(?,?)\tRE2/Go\n-\n-E\t((z)+|a)*\tzabcde\t\t(0,2)(1,2)\n-\n-#{E\ta+?\t\taaaaaa\t\t(0,1)\tno *? +? mimimal match ops\n-#E\t(a)\t\taaa\t\t(0,1)(0,1)\n-#E\t(a*?)\t\taaa\t\t(0,0)(0,0)\n-#E\t(a)*?\t\taaa\t\t(0,0)\n-#E\t(a*?)*?\t\taaa\t\t(0,0)\n-#}\n-\n-B\t\\(a*\\)*\\(x\\)\t\tx\t(0,1)(0,0)(0,1)\n-B\t\\(a*\\)*\\(x\\)\t\tax\t(0,2)(0,1)(1,2)\n-B\t\\(a*\\)*\\(x\\)\t\taxa\t(0,2)(0,1)(1,2)\n-B\t\\(a*\\)*\\(x\\)\\(\\1\\)\tx\t(0,1)(0,0)(0,1)(1,1)\n-B\t\\(a*\\)*\\(x\\)\\(\\1\\)\tax\t(0,2)(1,1)(1,2)(2,2)\n-B\t\\(a*\\)*\\(x\\)\\(\\1\\)\taxa\t(0,3)(0,1)(1,2)(2,3)\n-B\t\\(a*\\)*\\(x\\)\\(\\1\\)\\(x\\)\taxax\t(0,4)(0,1)(1,2)(2,3)(3,4)\n-B\t\\(a*\\)*\\(x\\)\\(\\1\\)\\(x\\)\taxxa\t(0,3)(1,1)(1,2)(2,2)(2,3)\n-\n-#E\t(a*)*(x)\t\tx\t(0,1)(0,0)(0,1)\n-E\t(a*)*(x)\t\tx\t(0,1)(?,?)(0,1)\tRE2/Go\n-E\t(a*)*(x)\t\tax\t(0,2)(0,1)(1,2)\n-E\t(a*)*(x)\t\taxa\t(0,2)(0,1)(1,2)\n-\n-E\t(a*)+(x)\t\tx\t(0,1)(0,0)(0,1)\n-E\t(a*)+(x)\t\tax\t(0,2)(0,1)(1,2)\n-E\t(a*)+(x)\t\taxa\t(0,2)(0,1)(1,2)\n-\n-E\t(a*){2}(x)\t\tx\t(0,1)(0,0)(0,1)\n-E\t(a*){2}(x)\t\tax\t(0,2)(1,1)(1,2)\n-E\t(a*){2}(x)\t\taxa\t(0,2)(1,1)(1,2)"}, {"sha": "3bb21211800058cef9beaad6cfdc54aa867926ad", "filename": "src/libregex/testdata/repetition.dat", "status": "removed", "additions": 0, "deletions": 163, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Frepetition.dat", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Ftestdata%2Frepetition.dat", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Ftestdata%2Frepetition.dat?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,163 +0,0 @@\n-NOTE\timplicit vs. explicit repetitions : 2009-02-02\n-\n-# Glenn Fowler <gsf@research.att.com>\n-# conforming matches (column 4) must match one of the following BREs\n-#\tNOMATCH\n-#\t(0,.)\\((\\(.\\),\\(.\\))(?,?)(\\2,\\3)\\)*\n-#\t(0,.)\\((\\(.\\),\\(.\\))(\\2,\\3)(?,?)\\)*\n-# i.e., each 3-tuple has two identical elements and one (?,?)\n-\n-E\t((..)|(.))\t\t\t\tNULL\t\tNOMATCH\n-E\t((..)|(.))((..)|(.))\t\t\tNULL\t\tNOMATCH\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\tNULL\t\tNOMATCH\n-\n-E\t((..)|(.)){1}\t\t\t\tNULL\t\tNOMATCH\n-E\t((..)|(.)){2}\t\t\t\tNULL\t\tNOMATCH\n-E\t((..)|(.)){3}\t\t\t\tNULL\t\tNOMATCH\n-\n-E\t((..)|(.))*\t\t\t\tNULL\t\t(0,0)\n-\n-E\t((..)|(.))\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n-E\t((..)|(.))((..)|(.))\t\t\ta\t\tNOMATCH\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\ta\t\tNOMATCH\n-\n-E\t((..)|(.)){1}\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n-E\t((..)|(.)){2}\t\t\t\ta\t\tNOMATCH\n-E\t((..)|(.)){3}\t\t\t\ta\t\tNOMATCH\n-\n-E\t((..)|(.))*\t\t\t\ta\t\t(0,1)(0,1)(?,?)(0,1)\n-\n-E\t((..)|(.))\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.))((..)|(.))\t\t\taa\t\t(0,2)(0,1)(?,?)(0,1)(1,2)(?,?)(1,2)\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\taa\t\tNOMATCH\n-\n-E\t((..)|(.)){1}\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.)){2}\t\t\t\taa\t\t(0,2)(1,2)(?,?)(1,2)\n-E\t((..)|(.)){3}\t\t\t\taa\t\tNOMATCH\n-\n-E\t((..)|(.))*\t\t\t\taa\t\t(0,2)(0,2)(0,2)(?,?)\n-\n-E\t((..)|(.))\t\t\t\taaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.))((..)|(.))\t\t\taaa\t\t(0,3)(0,2)(0,2)(?,?)(2,3)(?,?)(2,3)\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\taaa\t\t(0,3)(0,1)(?,?)(0,1)(1,2)(?,?)(1,2)(2,3)(?,?)(2,3)\n-\n-E\t((..)|(.)){1}\t\t\t\taaa\t\t(0,2)(0,2)(0,2)(?,?)\n-#E\t((..)|(.)){2}\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n-E\t((..)|(.)){2}\t\t\t\taaa\t\t(0,3)(2,3)(0,2)(2,3)\tRE2/Go\n-E\t((..)|(.)){3}\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n-\n-#E\t((..)|(.))*\t\t\t\taaa\t\t(0,3)(2,3)(?,?)(2,3)\n-E\t((..)|(.))*\t\t\t\taaa\t\t(0,3)(2,3)(0,2)(2,3)\tRE2/Go\n-\n-E\t((..)|(.))\t\t\t\taaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.))((..)|(.))\t\t\taaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,3)(?,?)(2,3)(3,4)(?,?)(3,4)\n-\n-E\t((..)|(.)){1}\t\t\t\taaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.)){2}\t\t\t\taaaa\t\t(0,4)(2,4)(2,4)(?,?)\n-#E\t((..)|(.)){3}\t\t\t\taaaa\t\t(0,4)(3,4)(?,?)(3,4)\n-E\t((..)|(.)){3}\t\t\t\taaaa\t\t(0,4)(3,4)(0,2)(3,4)\tRE2/Go\n-\n-E\t((..)|(.))*\t\t\t\taaaa\t\t(0,4)(2,4)(2,4)(?,?)\n-\n-E\t((..)|(.))\t\t\t\taaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.))((..)|(.))\t\t\taaaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaaa\t\t(0,5)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)(4,5)(?,?)(4,5)\n-\n-E\t((..)|(.)){1}\t\t\t\taaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.)){2}\t\t\t\taaaaa\t\t(0,4)(2,4)(2,4)(?,?)\n-#E\t((..)|(.)){3}\t\t\t\taaaaa\t\t(0,5)(4,5)(?,?)(4,5)\n-E\t((..)|(.)){3}\t\t\t\taaaaa\t\t(0,5)(4,5)(2,4)(4,5)\tRE2/Go\n-\n-#E\t((..)|(.))*\t\t\t\taaaaa\t\t(0,5)(4,5)(?,?)(4,5)\n-E\t((..)|(.))*\t\t\t\taaaaa\t\t(0,5)(4,5)(2,4)(4,5)\tRE2/Go\n-\n-E\t((..)|(.))\t\t\t\taaaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.))((..)|(.))\t\t\taaaaaa\t\t(0,4)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)\n-E\t((..)|(.))((..)|(.))((..)|(.))\t\taaaaaa\t\t(0,6)(0,2)(0,2)(?,?)(2,4)(2,4)(?,?)(4,6)(4,6)(?,?)\n-\n-E\t((..)|(.)){1}\t\t\t\taaaaaa\t\t(0,2)(0,2)(0,2)(?,?)\n-E\t((..)|(.)){2}\t\t\t\taaaaaa\t\t(0,4)(2,4)(2,4)(?,?)\n-E\t((..)|(.)){3}\t\t\t\taaaaaa\t\t(0,6)(4,6)(4,6)(?,?)\n-\n-E\t((..)|(.))*\t\t\t\taaaaaa\t\t(0,6)(4,6)(4,6)(?,?)\n-\n-NOTE\tadditional repetition tests graciously provided by Chris Kuklewicz www.haskell.org 2009-02-02\n-\n-# These test a bug in OS X / FreeBSD / NetBSD, and libtree. \n-# Linux/GLIBC gets the {8,} and {8,8} wrong.\n-\n-:HA#100:E\tX(.?){0,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#101:E\tX(.?){1,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#102:E\tX(.?){2,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#103:E\tX(.?){3,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#104:E\tX(.?){4,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#105:E\tX(.?){5,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#106:E\tX(.?){6,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#107:E\tX(.?){7,}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#108:E\tX(.?){8,}Y\tX1234567Y\t(0,9)(8,8)\n-#:HA#110:E\tX(.?){0,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#110:E\tX(.?){0,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#111:E\tX(.?){1,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#111:E\tX(.?){1,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#112:E\tX(.?){2,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#112:E\tX(.?){2,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#113:E\tX(.?){3,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#113:E\tX(.?){3,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#114:E\tX(.?){4,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#114:E\tX(.?){4,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#115:E\tX(.?){5,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#115:E\tX(.?){5,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#116:E\tX(.?){6,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#116:E\tX(.?){6,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-#:HA#117:E\tX(.?){7,8}Y\tX1234567Y\t(0,9)(7,8)\n-:HA#117:E\tX(.?){7,8}Y\tX1234567Y\t(0,9)(8,8)\tRE2/Go\n-:HA#118:E\tX(.?){8,8}Y\tX1234567Y\t(0,9)(8,8)\n-\n-# These test a fixed bug in my regex-tdfa that did not keep the expanded\n-# form properly grouped, so right association did the wrong thing with\n-# these ambiguous patterns (crafted just to test my code when I became\n-# suspicious of my implementation).  The first subexpression should use\n-# \"ab\" then \"a\" then \"bcd\".\n-\n-# OS X / FreeBSD / NetBSD badly fail many of these, with impossible\n-# results like (0,6)(4,5)(6,6).\n-\n-:HA#260:E\t(a|ab|c|bcd){0,}(d*)\tababcd\t(0,1)(0,1)(1,1)\n-:HA#261:E\t(a|ab|c|bcd){1,}(d*)\tababcd\t(0,1)(0,1)(1,1)\n-:HA#262:E\t(a|ab|c|bcd){2,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#263:E\t(a|ab|c|bcd){3,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#264:E\t(a|ab|c|bcd){4,}(d*)\tababcd\tNOMATCH\n-:HA#265:E\t(a|ab|c|bcd){0,10}(d*)\tababcd\t(0,1)(0,1)(1,1)\n-:HA#266:E\t(a|ab|c|bcd){1,10}(d*)\tababcd\t(0,1)(0,1)(1,1)\n-:HA#267:E\t(a|ab|c|bcd){2,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#268:E\t(a|ab|c|bcd){3,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#269:E\t(a|ab|c|bcd){4,10}(d*)\tababcd\tNOMATCH\n-:HA#270:E\t(a|ab|c|bcd)*(d*)\tababcd\t(0,1)(0,1)(1,1)\n-:HA#271:E\t(a|ab|c|bcd)+(d*)\tababcd\t(0,1)(0,1)(1,1)\n-\n-# The above worked on Linux/GLIBC but the following often fail.\n-# They also trip up OS X / FreeBSD / NetBSD:\n-\n-#:HA#280:E\t(ab|a|c|bcd){0,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#280:E\t(ab|a|c|bcd){0,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#281:E\t(ab|a|c|bcd){1,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#281:E\t(ab|a|c|bcd){1,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#282:E\t(ab|a|c|bcd){2,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#282:E\t(ab|a|c|bcd){2,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#283:E\t(ab|a|c|bcd){3,}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#283:E\t(ab|a|c|bcd){3,}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-:HA#284:E\t(ab|a|c|bcd){4,}(d*)\tababcd\tNOMATCH\n-#:HA#285:E\t(ab|a|c|bcd){0,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#285:E\t(ab|a|c|bcd){0,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#286:E\t(ab|a|c|bcd){1,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#286:E\t(ab|a|c|bcd){1,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#287:E\t(ab|a|c|bcd){2,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#287:E\t(ab|a|c|bcd){2,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#288:E\t(ab|a|c|bcd){3,10}(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#288:E\t(ab|a|c|bcd){3,10}(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-:HA#289:E\t(ab|a|c|bcd){4,10}(d*)\tababcd\tNOMATCH\n-#:HA#290:E\t(ab|a|c|bcd)*(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#290:E\t(ab|a|c|bcd)*(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go\n-#:HA#291:E\t(ab|a|c|bcd)+(d*)\tababcd\t(0,6)(3,6)(6,6)\n-:HA#291:E\t(ab|a|c|bcd)+(d*)\tababcd\t(0,6)(4,5)(5,6)\tRE2/Go"}, {"sha": "9605536a052c04d3135888e754e0c18269b128d5", "filename": "src/libregex/vm.rs", "status": "removed", "additions": 0, "deletions": 582, "changes": 582, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fvm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibregex%2Fvm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fvm.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,582 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// FIXME: Currently, the VM simulates an NFA. It would be nice to have another\n-// VM that simulates a DFA.\n-//\n-// According to Russ Cox[1], a DFA performs better than an NFA, principally\n-// because it reuses states previously computed by the machine *and* doesn't\n-// keep track of capture groups. The drawback of a DFA (aside from its\n-// complexity) is that it can't accurately return the locations of submatches.\n-// The NFA *can* do that. (This is my understanding anyway.)\n-//\n-// Cox suggests that a DFA ought to be used to answer \"does this match\" and\n-// \"where does it match\" questions. (In the latter, the starting position of\n-// the match is computed by executing the regex backwards.) Cox also suggests\n-// that a DFA should be run when asking \"where are the submatches\", which can\n-// 1) quickly answer \"no\" is there's no match and 2) discover the substring\n-// that matches, which means running the NFA on smaller input.\n-//\n-// Currently, the NFA simulation implemented below does some dirty tricks to\n-// avoid tracking capture groups when they aren't needed (which only works\n-// for 'is_match', not 'find'). This is a half-measure, but does provide some\n-// perf improvement.\n-//\n-// AFAIK, the DFA/NFA approach is implemented in RE2/C++ but *not* in RE2/Go.\n-//\n-// [1] - http://swtch.com/~rsc/regex/regex3.html\n-\n-pub use self::MatchKind::*;\n-pub use self::StepState::*;\n-\n-use std::cmp;\n-use std::cmp::Ordering::{self, Less, Equal, Greater};\n-use std::mem;\n-use std::iter::repeat;\n-use std::slice::SliceExt;\n-use compile::{\n-    Program,\n-    Match, OneChar, CharClass, Any, EmptyBegin, EmptyEnd, EmptyWordBoundary,\n-    Save, Jump, Split,\n-};\n-use parse::{FLAG_NOCASE, FLAG_MULTI, FLAG_DOTNL, FLAG_NEGATED};\n-use unicode::regex::PERLW;\n-\n-pub type CaptureLocs = Vec<Option<uint>>;\n-\n-/// Indicates the type of match to be performed by the VM.\n-#[derive(Copy)]\n-pub enum MatchKind {\n-    /// Only checks if a match exists or not. Does not return location.\n-    Exists,\n-    /// Returns the start and end indices of the entire match in the input\n-    /// given.\n-    Location,\n-    /// Returns the start and end indices of each submatch in the input given.\n-    Submatches,\n-}\n-\n-/// Runs an NFA simulation on the compiled expression given on the search text\n-/// `input`. The search begins at byte index `start` and ends at byte index\n-/// `end`. (The range is specified here so that zero-width assertions will work\n-/// correctly when searching for successive non-overlapping matches.)\n-///\n-/// The `which` parameter indicates what kind of capture information the caller\n-/// wants. There are three choices: match existence only, the location of the\n-/// entire match or the locations of the entire match in addition to the\n-/// locations of each submatch.\n-pub fn run<'r, 't>(which: MatchKind, prog: &'r Program, input: &'t str,\n-                   start: uint, end: uint) -> CaptureLocs {\n-    Nfa {\n-        which: which,\n-        prog: prog,\n-        input: input,\n-        start: start,\n-        end: end,\n-        ic: 0,\n-        chars: CharReader::new(input),\n-    }.run()\n-}\n-\n-struct Nfa<'r, 't> {\n-    which: MatchKind,\n-    prog: &'r Program,\n-    input: &'t str,\n-    start: uint,\n-    end: uint,\n-    ic: uint,\n-    chars: CharReader<'t>,\n-}\n-\n-/// Indicates the next action to take after a single non-empty instruction\n-/// is processed.\n-#[derive(Copy)]\n-pub enum StepState {\n-    /// This is returned if and only if a Match instruction is reached and\n-    /// we only care about the existence of a match. It instructs the VM to\n-    /// quit early.\n-    StepMatchEarlyReturn,\n-    /// Indicates that a match was found. Thus, the rest of the states in the\n-    /// *current* queue should be dropped (i.e., leftmost-first semantics).\n-    /// States in the \"next\" queue can still be processed.\n-    StepMatch,\n-    /// No match was found. Continue with the next state in the queue.\n-    StepContinue,\n-}\n-\n-impl<'r, 't> Nfa<'r, 't> {\n-    fn run(&mut self) -> CaptureLocs {\n-        let ncaps = match self.which {\n-            Exists => 0,\n-            Location => 1,\n-            Submatches => self.prog.num_captures(),\n-        };\n-        let mut matched = false;\n-        let ninsts = self.prog.insts.len();\n-        let mut clist = &mut Threads::new(self.which, ninsts, ncaps);\n-        let mut nlist = &mut Threads::new(self.which, ninsts, ncaps);\n-\n-        let mut groups: Vec<_> = repeat(None).take(ncaps * 2).collect();\n-\n-        // Determine if the expression starts with a '^' so we can avoid\n-        // simulating .*?\n-        // Make sure multi-line mode isn't enabled for it, otherwise we can't\n-        // drop the initial .*?\n-        let prefix_anchor =\n-            match self.prog.insts[1] {\n-                EmptyBegin(flags) if flags & FLAG_MULTI == 0 => true,\n-                _ => false,\n-            };\n-\n-        self.ic = self.start;\n-        let mut next_ic = self.chars.set(self.start);\n-        while self.ic <= self.end {\n-            if clist.size == 0 {\n-                // We have a match and we're done exploring alternatives.\n-                // Time to quit.\n-                if matched {\n-                    break\n-                }\n-\n-                // If there are no threads to try, then we'll have to start\n-                // over at the beginning of the regex.\n-                // BUT, if there's a literal prefix for the program, try to\n-                // jump ahead quickly. If it can't be found, then we can bail\n-                // out early.\n-                if self.prog.prefix.len() > 0 && clist.size == 0 {\n-                    let needle = self.prog.prefix.as_bytes();\n-                    let haystack = &self.input.as_bytes()[self.ic..];\n-                    match find_prefix(needle, haystack) {\n-                        None => break,\n-                        Some(i) => {\n-                            self.ic += i;\n-                            next_ic = self.chars.set(self.ic);\n-                        }\n-                    }\n-                }\n-            }\n-\n-            // This simulates a preceding '.*?' for every regex by adding\n-            // a state starting at the current position in the input for the\n-            // beginning of the program only if we don't already have a match.\n-            if clist.size == 0 || (!prefix_anchor && !matched) {\n-                self.add(clist, 0, groups.as_mut_slice())\n-            }\n-\n-            // Now we try to read the next character.\n-            // As a result, the 'step' method will look at the previous\n-            // character.\n-            self.ic = next_ic;\n-            next_ic = self.chars.advance();\n-\n-            for i in range(0, clist.size) {\n-                let pc = clist.pc(i);\n-                let step_state = self.step(groups.as_mut_slice(), nlist,\n-                                           clist.groups(i), pc);\n-                match step_state {\n-                    StepMatchEarlyReturn => return vec![Some(0), Some(0)],\n-                    StepMatch => { matched = true; break },\n-                    StepContinue => {},\n-                }\n-            }\n-            mem::swap(&mut clist, &mut nlist);\n-            nlist.empty();\n-        }\n-        match self.which {\n-            Exists if matched     => vec![Some(0), Some(0)],\n-            Exists                => vec![None, None],\n-            Location | Submatches => groups,\n-        }\n-    }\n-\n-    fn step(&self, groups: &mut [Option<uint>], nlist: &mut Threads,\n-            caps: &mut [Option<uint>], pc: uint)\n-           -> StepState {\n-        match self.prog.insts[pc] {\n-            Match => {\n-                match self.which {\n-                    Exists => {\n-                        return StepMatchEarlyReturn\n-                    }\n-                    Location => {\n-                        groups[0] = caps[0];\n-                        groups[1] = caps[1];\n-                        return StepMatch\n-                    }\n-                    Submatches => {\n-                        for (slot, val) in groups.iter_mut().zip(caps.iter()) {\n-                            *slot = *val;\n-                        }\n-                        return StepMatch\n-                    }\n-                }\n-            }\n-            OneChar(c, flags) => {\n-                if self.char_eq(flags & FLAG_NOCASE > 0, self.chars.prev, c) {\n-                    self.add(nlist, pc+1, caps);\n-                }\n-            }\n-            CharClass(ref ranges, flags) => {\n-                if self.chars.prev.is_some() {\n-                    let c = self.chars.prev.unwrap();\n-                    let negate = flags & FLAG_NEGATED > 0;\n-                    let casei = flags & FLAG_NOCASE > 0;\n-                    let found = ranges.as_slice();\n-                    let found = found.binary_search_by(|&rc| class_cmp(casei, c, rc)).is_ok();\n-                    if found ^ negate {\n-                        self.add(nlist, pc+1, caps);\n-                    }\n-                }\n-            }\n-            Any(flags) => {\n-                if flags & FLAG_DOTNL > 0\n-                   || !self.char_eq(false, self.chars.prev, '\\n') {\n-                    self.add(nlist, pc+1, caps)\n-                }\n-            }\n-            EmptyBegin(_) | EmptyEnd(_) | EmptyWordBoundary(_)\n-            | Save(_) | Jump(_) | Split(_, _) => {},\n-        }\n-        StepContinue\n-    }\n-\n-    fn add(&self, nlist: &mut Threads, pc: uint, groups: &mut [Option<uint>]) {\n-        if nlist.contains(pc) {\n-            return\n-        }\n-        // We have to add states to the threads list even if their empty.\n-        // TL;DR - It prevents cycles.\n-        // If we didn't care about cycles, we'd *only* add threads that\n-        // correspond to non-jumping instructions (OneChar, Any, Match, etc.).\n-        // But, it's possible for valid regexs (like '(a*)*') to result in\n-        // a cycle in the instruction list. e.g., We'll keep chasing the Split\n-        // instructions forever.\n-        // So we add these instructions to our thread queue, but in the main\n-        // VM loop, we look for them but simply ignore them.\n-        // Adding them to the queue prevents them from being revisited so we\n-        // can avoid cycles (and the inevitable stack overflow).\n-        //\n-        // We make a minor optimization by indicating that the state is \"empty\"\n-        // so that its capture groups are not filled in.\n-        match self.prog.insts[pc] {\n-            EmptyBegin(flags) => {\n-                let multi = flags & FLAG_MULTI > 0;\n-                nlist.add(pc, groups, true);\n-                if self.chars.is_begin()\n-                   || (multi && self.char_is(self.chars.prev, '\\n')) {\n-                    self.add(nlist, pc + 1, groups)\n-                }\n-            }\n-            EmptyEnd(flags) => {\n-                let multi = flags & FLAG_MULTI > 0;\n-                nlist.add(pc, groups, true);\n-                if self.chars.is_end()\n-                   || (multi && self.char_is(self.chars.cur, '\\n')) {\n-                    self.add(nlist, pc + 1, groups)\n-                }\n-            }\n-            EmptyWordBoundary(flags) => {\n-                nlist.add(pc, groups, true);\n-                if self.chars.is_word_boundary() == !(flags & FLAG_NEGATED > 0) {\n-                    self.add(nlist, pc + 1, groups)\n-                }\n-            }\n-            Save(slot) => {\n-                nlist.add(pc, groups, true);\n-                match self.which {\n-                    Location if slot <= 1 => {\n-                        let old = groups[slot];\n-                        groups[slot] = Some(self.ic);\n-                        self.add(nlist, pc + 1, groups);\n-                        groups[slot] = old;\n-                    }\n-                    Submatches => {\n-                        let old = groups[slot];\n-                        groups[slot] = Some(self.ic);\n-                        self.add(nlist, pc + 1, groups);\n-                        groups[slot] = old;\n-                    }\n-                    Exists | Location => self.add(nlist, pc + 1, groups),\n-                }\n-            }\n-            Jump(to) => {\n-                nlist.add(pc, groups, true);\n-                self.add(nlist, to, groups)\n-            }\n-            Split(x, y) => {\n-                nlist.add(pc, groups, true);\n-                self.add(nlist, x, groups);\n-                self.add(nlist, y, groups);\n-            }\n-            Match | OneChar(_, _) | CharClass(_, _) | Any(_) => {\n-                nlist.add(pc, groups, false);\n-            }\n-        }\n-    }\n-\n-    // FIXME: For case insensitive comparisons, it uses the uppercase\n-    // character and tests for equality. IIUC, this does not generalize to\n-    // all of Unicode. I believe we need to check the entire fold for each\n-    // character. This will be easy to add if and when it gets added to Rust's\n-    // standard library.\n-    #[inline]\n-    fn char_eq(&self, casei: bool, textc: Option<char>, regc: char) -> bool {\n-        match textc {\n-            None => false,\n-            Some(textc) => {\n-                regc == textc\n-                    || (casei && regc.to_uppercase() == textc.to_uppercase())\n-            }\n-        }\n-    }\n-\n-    #[inline]\n-    fn char_is(&self, textc: Option<char>, regc: char) -> bool {\n-        textc == Some(regc)\n-    }\n-}\n-\n-/// CharReader is responsible for maintaining a \"previous\" and a \"current\"\n-/// character. This one-character lookahead is necessary for assertions that\n-/// look one character before or after the current position.\n-pub struct CharReader<'t> {\n-    /// The previous character read. It is None only when processing the first\n-    /// character of the input.\n-    pub prev: Option<char>,\n-    /// The current character.\n-    pub cur: Option<char>,\n-    input: &'t str,\n-    next: uint,\n-}\n-\n-impl<'t> CharReader<'t> {\n-    /// Returns a new CharReader that advances through the input given.\n-    /// Note that a CharReader has no knowledge of the range in which to search\n-    /// the input.\n-    pub fn new(input: &'t str) -> CharReader<'t> {\n-        CharReader {\n-            prev: None,\n-            cur: None,\n-            input: input,\n-            next: 0,\n-       }\n-    }\n-\n-    /// Sets the previous and current character given any arbitrary byte\n-    /// index (at a Unicode codepoint boundary).\n-    #[inline]\n-    pub fn set(&mut self, ic: uint) -> uint {\n-        self.prev = None;\n-        self.cur = None;\n-        self.next = 0;\n-\n-        if self.input.len() == 0 {\n-            return 1\n-        }\n-        if ic > 0 {\n-            let i = cmp::min(ic, self.input.len());\n-            let prev = self.input.char_range_at_reverse(i);\n-            self.prev = Some(prev.ch);\n-        }\n-        if ic < self.input.len() {\n-            let cur = self.input.char_range_at(ic);\n-            self.cur = Some(cur.ch);\n-            self.next = cur.next;\n-            self.next\n-        } else {\n-            self.input.len() + 1\n-        }\n-    }\n-\n-    /// Does the same as `set`, except it always advances to the next\n-    /// character in the input (and therefore does half as many UTF8 decodings).\n-    #[inline]\n-    pub fn advance(&mut self) -> uint {\n-        self.prev = self.cur;\n-        if self.next < self.input.len() {\n-            let cur = self.input.char_range_at(self.next);\n-            self.cur = Some(cur.ch);\n-            self.next = cur.next;\n-        } else {\n-            self.cur = None;\n-            self.next = self.input.len() + 1;\n-        }\n-        self.next\n-    }\n-\n-    /// Returns true if and only if this is the beginning of the input\n-    /// (ignoring the range of the input to search).\n-    #[inline]\n-    pub fn is_begin(&self) -> bool { self.prev.is_none() }\n-\n-    /// Returns true if and only if this is the end of the input\n-    /// (ignoring the range of the input to search).\n-    #[inline]\n-    pub fn is_end(&self) -> bool { self.cur.is_none() }\n-\n-    /// Returns true if and only if the current position is a word boundary.\n-    /// (Ignoring the range of the input to search.)\n-    pub fn is_word_boundary(&self) -> bool {\n-        if self.is_begin() {\n-            return is_word(self.cur)\n-        }\n-        if self.is_end() {\n-            return is_word(self.prev)\n-        }\n-        (is_word(self.cur) && !is_word(self.prev))\n-        || (is_word(self.prev) && !is_word(self.cur))\n-    }\n-}\n-\n-struct Thread {\n-    pc: uint,\n-    groups: Vec<Option<uint>>,\n-}\n-\n-struct Threads {\n-    which: MatchKind,\n-    queue: Vec<Thread>,\n-    sparse: Vec<uint>,\n-    size: uint,\n-}\n-\n-impl Threads {\n-    // This is using a wicked neat trick to provide constant time lookup\n-    // for threads in the queue using a sparse set. A queue of threads is\n-    // allocated once with maximal size when the VM initializes and is reused\n-    // throughout execution. That is, there should be zero allocation during\n-    // the execution of a VM.\n-    //\n-    // See http://research.swtch.com/sparse for the deets.\n-    fn new(which: MatchKind, num_insts: uint, ncaps: uint) -> Threads {\n-        Threads {\n-            which: which,\n-            queue: range(0, num_insts).map(|_| {\n-                Thread { pc: 0, groups: repeat(None).take(ncaps * 2).collect() }\n-            }).collect(),\n-            sparse: repeat(0u).take(num_insts).collect(),\n-            size: 0,\n-        }\n-    }\n-\n-    fn add(&mut self, pc: uint, groups: &[Option<uint>], empty: bool) {\n-        let t = &mut self.queue[self.size];\n-        t.pc = pc;\n-        match (empty, self.which) {\n-            (_, Exists) | (true, _) => {},\n-            (false, Location) => {\n-                t.groups[0] = groups[0];\n-                t.groups[1] = groups[1];\n-            }\n-            (false, Submatches) => {\n-                for (slot, val) in t.groups.iter_mut().zip(groups.iter()) {\n-                    *slot = *val;\n-                }\n-            }\n-        }\n-        self.sparse[pc] = self.size;\n-        self.size += 1;\n-    }\n-\n-    #[inline]\n-    fn contains(&self, pc: uint) -> bool {\n-        let s = self.sparse[pc];\n-        s < self.size && self.queue[s].pc == pc\n-    }\n-\n-    #[inline]\n-    fn empty(&mut self) {\n-        self.size = 0;\n-    }\n-\n-    #[inline]\n-    fn pc(&self, i: uint) -> uint {\n-        self.queue[i].pc\n-    }\n-\n-    #[inline]\n-    fn groups<'r>(&'r mut self, i: uint) -> &'r mut [Option<uint>] {\n-        let q = &mut self.queue[i];\n-        q.groups.as_mut_slice()\n-    }\n-}\n-\n-/// Returns true if the character is a word character, according to the\n-/// (Unicode friendly) Perl character class '\\w'.\n-/// Note that this is only use for testing word boundaries. The actual '\\w'\n-/// is encoded as a CharClass instruction.\n-pub fn is_word(c: Option<char>) -> bool {\n-    let c = match c {\n-        None => return false,\n-        Some(c) => c,\n-    };\n-    // Try the common ASCII case before invoking binary search.\n-    match c {\n-        '_' | '0' ... '9' | 'a' ... 'z' | 'A' ... 'Z' => true,\n-        _ => PERLW.binary_search_by(|&(start, end)| {\n-            if c >= start && c <= end {\n-                Equal\n-            } else if start > c {\n-                Greater\n-            } else {\n-                Less\n-            }\n-        }).is_ok()\n-    }\n-}\n-\n-/// Given a character and a single character class range, return an ordering\n-/// indicating whether the character is less than the start of the range,\n-/// in the range (inclusive) or greater than the end of the range.\n-///\n-/// If `casei` is `true`, then this ordering is computed case insensitively.\n-///\n-/// This function is meant to be used with a binary search.\n-#[inline]\n-fn class_cmp(casei: bool, mut textc: char,\n-             (mut start, mut end): (char, char)) -> Ordering {\n-    if casei {\n-        // FIXME: This is pretty ridiculous. All of this case conversion\n-        // can be moved outside this function:\n-        // 1) textc should be uppercased outside the bsearch.\n-        // 2) the character class itself should be uppercased either in the\n-        //    parser or the compiler.\n-        // FIXME: This is too simplistic for correct Unicode support.\n-        //        See also: char_eq\n-        textc = textc.to_uppercase();\n-        start = start.to_uppercase();\n-        end = end.to_uppercase();\n-    }\n-    if textc >= start && textc <= end {\n-        Equal\n-    } else if start > textc {\n-        Greater\n-    } else {\n-        Less\n-    }\n-}\n-\n-/// Returns the starting location of `needle` in `haystack`.\n-/// If `needle` is not in `haystack`, then `None` is returned.\n-///\n-/// Note that this is using a naive substring algorithm.\n-#[inline]\n-pub fn find_prefix(needle: &[u8], haystack: &[u8]) -> Option<uint> {\n-    let (hlen, nlen) = (haystack.len(), needle.len());\n-    if nlen > hlen || nlen == 0 {\n-        return None\n-    }\n-    for (offset, window) in haystack.windows(nlen).enumerate() {\n-        if window == needle {\n-            return Some(offset)\n-        }\n-    }\n-    None\n-}"}, {"sha": "b961200f33501afa94f347022d3ff9b35cea0bd9", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -37,7 +37,6 @@ extern crate fmt_macros;\n extern crate getopts;\n extern crate graphviz;\n extern crate libc;\n-extern crate regex;\n extern crate rustc_llvm;\n extern crate rustc_back;\n extern crate serialize;"}, {"sha": "f90a60c9754a06e8b9d276274293cb883550f06c", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 30, "deletions": 28, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -15,8 +15,6 @@ use metadata::filesearch;\n use session::search_paths::PathKind;\n use util::nodemap::NodeMap;\n \n-use regex::Regex;\n-\n use syntax::ast::NodeId;\n use syntax::codemap::Span;\n use syntax::diagnostic::{self, Emitter};\n@@ -253,50 +251,54 @@ fn split_msg_into_multilines(msg: &str) -> Option<String> {\n         !msg.contains(\"structure constructor specifies a structure of type\") {\n             return None\n     }\n-\n-    let first  = Regex::new(r\"[( ]expected\").unwrap();\n-    let second = Regex::new(r\" found\").unwrap();\n-    let third  = Regex::new(\n-        r\"\\((values differ|lifetime|cyclic type of infinite size)\").unwrap();\n+    let first = msg.match_indices(\"expected\").filter(|s| {\n+        s.0 > 0 && (msg.char_at_reverse(s.0) == ' ' ||\n+                    msg.char_at_reverse(s.0) == '(')\n+    }).map(|(a, b)| (a - 1, b));\n+    let second = msg.match_indices(\"found\").filter(|s| {\n+        msg.char_at_reverse(s.0) == ' '\n+    }).map(|(a, b)| (a - 1, b));\n \n     let mut new_msg = String::new();\n     let mut head = 0u;\n \n     // Insert `\\n` before expected and found.\n-    for (pos1, pos2) in first.find_iter(msg).zip(\n-        second.find_iter(msg)) {\n+    for (pos1, pos2) in first.zip(second) {\n         new_msg = new_msg +\n-            // A `(` may be preceded by a space and it should be trimmed\n-            msg[head..pos1.0].trim_right() + // prefix\n-            \"\\n\" +                           // insert before first\n-            &msg[pos1.0..pos1.1] +           // insert what first matched\n-            &msg[pos1.1..pos2.0] +           // between matches\n-            \"\\n   \" +                        // insert before second\n-            //           123\n-            // `expected` is 3 char longer than `found`. To align the types, `found` gets\n-            // 3 spaces prepended.\n-            &msg[pos2.0..pos2.1];            // insert what second matched\n+        // A `(` may be preceded by a space and it should be trimmed\n+                  msg[head..pos1.0].trim_right() + // prefix\n+                  \"\\n\" +                           // insert before first\n+                  &msg[pos1.0..pos1.1] +           // insert what first matched\n+                  &msg[pos1.1..pos2.0] +           // between matches\n+                  \"\\n   \" +                        // insert before second\n+        //           123\n+        // `expected` is 3 char longer than `found`. To align the types,\n+        // `found` gets 3 spaces prepended.\n+                  &msg[pos2.0..pos2.1];            // insert what second matched\n \n         head = pos2.1;\n     }\n \n     let mut tail = &msg[head..];\n+    let third = tail.find_str(\"(values differ\")\n+                   .or(tail.find_str(\"(lifetime\"))\n+                   .or(tail.find_str(\"(cyclic type of infinite size\"));\n     // Insert `\\n` before any remaining messages which match.\n-    for pos in third.find_iter(tail).take(1) {\n-        // The end of the message may just be wrapped in `()` without `expected`/`found`.\n-        // Push this also to a new line and add the final tail after.\n+    if let Some(pos) = third {\n+        // The end of the message may just be wrapped in `()` without\n+        // `expected`/`found`.  Push this also to a new line and add the\n+        // final tail after.\n         new_msg = new_msg +\n-            // `(` is usually preceded by a space and should be trimmed.\n-            tail[..pos.0].trim_right() + // prefix\n-            \"\\n\" +                       // insert before paren\n-            &tail[pos.0..];              // append the tail\n+        // `(` is usually preceded by a space and should be trimmed.\n+                  tail[..pos].trim_right() + // prefix\n+                  \"\\n\" +                     // insert before paren\n+                  &tail[pos..];              // append the tail\n \n         tail = \"\";\n     }\n \n     new_msg.push_str(tail);\n-\n-    return Some(new_msg)\n+    return Some(new_msg);\n }\n \n pub fn build_session(sopts: config::Options,"}, {"sha": "c97d67ba1b9b4229bbe1cf642c8c1efcc1c83aab", "filename": "src/libserialize/base64.rs", "status": "removed", "additions": 0, "deletions": 424, "changes": 424, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibserialize%2Fbase64.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Flibserialize%2Fbase64.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fbase64.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,424 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-//\n-// ignore-lexer-test FIXME #15679\n-\n-//! Base64 binary-to-text encoding\n-\n-pub use self::FromBase64Error::*;\n-pub use self::CharacterSet::*;\n-\n-use std::fmt;\n-use std::error;\n-\n-/// Available encoding character sets\n-#[derive(Copy)]\n-pub enum CharacterSet {\n-    /// The standard character set (uses `+` and `/`)\n-    Standard,\n-    /// The URL safe character set (uses `-` and `_`)\n-    UrlSafe\n-}\n-\n-/// Available newline types\n-#[derive(Copy)]\n-pub enum Newline {\n-    /// A linefeed (i.e. Unix-style newline)\n-    LF,\n-    /// A carriage return and a linefeed (i.e. Windows-style newline)\n-    CRLF\n-}\n-\n-/// Contains configuration parameters for `to_base64`.\n-#[derive(Copy)]\n-pub struct Config {\n-    /// Character set to use\n-    pub char_set: CharacterSet,\n-    /// Newline to use\n-    pub newline: Newline,\n-    /// True to pad output with `=` characters\n-    pub pad: bool,\n-    /// `Some(len)` to wrap lines at `len`, `None` to disable line wrapping\n-    pub line_length: Option<uint>\n-}\n-\n-/// Configuration for RFC 4648 standard base64 encoding\n-pub static STANDARD: Config =\n-    Config {char_set: Standard, newline: Newline::CRLF, pad: true, line_length: None};\n-\n-/// Configuration for RFC 4648 base64url encoding\n-pub static URL_SAFE: Config =\n-    Config {char_set: UrlSafe, newline: Newline::CRLF, pad: false, line_length: None};\n-\n-/// Configuration for RFC 2045 MIME base64 encoding\n-pub static MIME: Config =\n-    Config {char_set: Standard, newline: Newline::CRLF, pad: true, line_length: Some(76)};\n-\n-static STANDARD_CHARS: &'static[u8] = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\\\n-                                        abcdefghijklmnopqrstuvwxyz\\\n-                                        0123456789+/\";\n-\n-static URLSAFE_CHARS: &'static[u8] = b\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\\\n-                                       abcdefghijklmnopqrstuvwxyz\\\n-                                       0123456789-_\";\n-\n-/// A trait for converting a value to base64 encoding.\n-pub trait ToBase64 {\n-    /// Converts the value of `self` to a base64 value following the specified\n-    /// format configuration, returning the owned string.\n-    fn to_base64(&self, config: Config) -> String;\n-}\n-\n-impl ToBase64 for [u8] {\n-    /// Turn a vector of `u8` bytes into a base64 string.\n-    ///\n-    /// # Example\n-    ///\n-    /// ```rust\n-    /// extern crate serialize;\n-    /// use serialize::base64::{ToBase64, STANDARD};\n-    ///\n-    /// fn main () {\n-    ///     let str = [52,32].to_base64(STANDARD);\n-    ///     println!(\"base 64 output: {}\", str);\n-    /// }\n-    /// ```\n-    fn to_base64(&self, config: Config) -> String {\n-        let bytes = match config.char_set {\n-            Standard => STANDARD_CHARS,\n-            UrlSafe => URLSAFE_CHARS\n-        };\n-\n-        // In general, this Vec only needs (4/3) * self.len() memory, but\n-        // addition is faster than multiplication and division.\n-        let mut v = Vec::with_capacity(self.len() + self.len());\n-        let mut i = 0;\n-        let mut cur_length = 0;\n-        let len = self.len();\n-        let mod_len = len % 3;\n-        let cond_len = len - mod_len;\n-        let newline = match config.newline {\n-            Newline::LF => b\"\\n\",\n-            Newline::CRLF => b\"\\r\\n\"\n-        };\n-        while i < cond_len {\n-            let (first, second, third) = (self[i], self[i + 1], self[i + 2]);\n-            if let Some(line_length) = config.line_length {\n-                if cur_length >= line_length {\n-                    v.push_all(newline);\n-                    cur_length = 0;\n-                }\n-            }\n-\n-            let n = (first  as u32) << 16 |\n-                    (second as u32) << 8 |\n-                    (third  as u32);\n-\n-            // This 24-bit number gets separated into four 6-bit numbers.\n-            v.push(bytes[((n >> 18) & 63) as uint]);\n-            v.push(bytes[((n >> 12) & 63) as uint]);\n-            v.push(bytes[((n >> 6 ) & 63) as uint]);\n-            v.push(bytes[(n & 63) as uint]);\n-\n-            cur_length += 4;\n-            i += 3;\n-        }\n-\n-        if mod_len != 0 {\n-            if let Some(line_length) = config.line_length {\n-                if cur_length >= line_length {\n-                    v.push_all(newline);\n-                }\n-            }\n-        }\n-\n-        // Heh, would be cool if we knew this was exhaustive\n-        // (the dream of bounded integer types)\n-        match mod_len {\n-            0 => (),\n-            1 => {\n-                let n = (self[i] as u32) << 16;\n-                v.push(bytes[((n >> 18) & 63) as uint]);\n-                v.push(bytes[((n >> 12) & 63) as uint]);\n-                if config.pad {\n-                    v.push(b'=');\n-                    v.push(b'=');\n-                }\n-            }\n-            2 => {\n-                let n = (self[i] as u32) << 16 |\n-                    (self[i + 1u] as u32) << 8;\n-                v.push(bytes[((n >> 18) & 63) as uint]);\n-                v.push(bytes[((n >> 12) & 63) as uint]);\n-                v.push(bytes[((n >> 6 ) & 63) as uint]);\n-                if config.pad {\n-                    v.push(b'=');\n-                }\n-            }\n-            _ => panic!(\"Algebra is broken, please alert the math police\")\n-        }\n-\n-        unsafe { String::from_utf8_unchecked(v) }\n-    }\n-}\n-\n-/// A trait for converting from base64 encoded values.\n-pub trait FromBase64 {\n-    /// Converts the value of `self`, interpreted as base64 encoded data, into\n-    /// an owned vector of bytes, returning the vector.\n-    fn from_base64(&self) -> Result<Vec<u8>, FromBase64Error>;\n-}\n-\n-/// Errors that can occur when decoding a base64 encoded string\n-#[derive(Copy, Show)]\n-pub enum FromBase64Error {\n-    /// The input contained a character not part of the base64 format\n-    InvalidBase64Byte(u8, uint),\n-    /// The input had an invalid length\n-    InvalidBase64Length,\n-}\n-\n-impl fmt::Display for FromBase64Error {\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        match *self {\n-            InvalidBase64Byte(ch, idx) =>\n-                write!(f, \"Invalid character '{}' at position {}\", ch, idx),\n-            InvalidBase64Length => write!(f, \"Invalid length\"),\n-        }\n-    }\n-}\n-\n-impl error::Error for FromBase64Error {\n-    fn description(&self) -> &str {\n-        match *self {\n-            InvalidBase64Byte(_, _) => \"invalid character\",\n-            InvalidBase64Length => \"invalid length\",\n-        }\n-    }\n-}\n-\n-impl FromBase64 for str {\n-    /// Convert any base64 encoded string (literal, `@`, `&`, or `~`)\n-    /// to the byte values it encodes.\n-    ///\n-    /// You can use the `String::from_utf8` function to turn a `Vec<u8>` into a\n-    /// string with characters corresponding to those values.\n-    ///\n-    /// # Example\n-    ///\n-    /// This converts a string literal to base64 and back.\n-    ///\n-    /// ```rust\n-    /// extern crate serialize;\n-    /// use serialize::base64::{ToBase64, FromBase64, STANDARD};\n-    ///\n-    /// fn main () {\n-    ///     let hello_str = b\"Hello, World\".to_base64(STANDARD);\n-    ///     println!(\"base64 output: {}\", hello_str);\n-    ///     let res = hello_str.as_slice().from_base64();\n-    ///     if res.is_ok() {\n-    ///       let opt_bytes = String::from_utf8(res.unwrap());\n-    ///       if opt_bytes.is_ok() {\n-    ///         println!(\"decoded from base64: {}\", opt_bytes.unwrap());\n-    ///       }\n-    ///     }\n-    /// }\n-    /// ```\n-    #[inline]\n-    fn from_base64(&self) -> Result<Vec<u8>, FromBase64Error> {\n-        self.as_bytes().from_base64()\n-    }\n-}\n-\n-impl FromBase64 for [u8] {\n-    fn from_base64(&self) -> Result<Vec<u8>, FromBase64Error> {\n-        let mut r = Vec::with_capacity(self.len());\n-        let mut buf: u32 = 0;\n-        let mut modulus = 0i;\n-\n-        let mut it = self.iter().enumerate();\n-        for (idx, &byte) in it {\n-            let val = byte as u32;\n-\n-            match byte {\n-                b'A'...b'Z' => buf |= val - 0x41,\n-                b'a'...b'z' => buf |= val - 0x47,\n-                b'0'...b'9' => buf |= val + 0x04,\n-                b'+' | b'-' => buf |= 0x3E,\n-                b'/' | b'_' => buf |= 0x3F,\n-                b'\\r' | b'\\n' => continue,\n-                b'=' => break,\n-                _ => return Err(InvalidBase64Byte(self[idx], idx)),\n-            }\n-\n-            buf <<= 6;\n-            modulus += 1;\n-            if modulus == 4 {\n-                modulus = 0;\n-                r.push((buf >> 22) as u8);\n-                r.push((buf >> 14) as u8);\n-                r.push((buf >> 6 ) as u8);\n-            }\n-        }\n-\n-        for (idx, &byte) in it {\n-            match byte {\n-                b'=' | b'\\r' | b'\\n' => continue,\n-                _ => return Err(InvalidBase64Byte(self[idx], idx)),\n-            }\n-        }\n-\n-        match modulus {\n-            2 => {\n-                r.push((buf >> 10) as u8);\n-            }\n-            3 => {\n-                r.push((buf >> 16) as u8);\n-                r.push((buf >> 8 ) as u8);\n-            }\n-            0 => (),\n-            _ => return Err(InvalidBase64Length),\n-        }\n-\n-        Ok(r)\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    extern crate test;\n-    use self::test::Bencher;\n-    use base64::{Config, Newline, FromBase64, ToBase64, STANDARD, URL_SAFE};\n-\n-    #[test]\n-    fn test_to_base64_basic() {\n-        assert_eq!(\"\".as_bytes().to_base64(STANDARD), \"\");\n-        assert_eq!(\"f\".as_bytes().to_base64(STANDARD), \"Zg==\");\n-        assert_eq!(\"fo\".as_bytes().to_base64(STANDARD), \"Zm8=\");\n-        assert_eq!(\"foo\".as_bytes().to_base64(STANDARD), \"Zm9v\");\n-        assert_eq!(\"foob\".as_bytes().to_base64(STANDARD), \"Zm9vYg==\");\n-        assert_eq!(\"fooba\".as_bytes().to_base64(STANDARD), \"Zm9vYmE=\");\n-        assert_eq!(\"foobar\".as_bytes().to_base64(STANDARD), \"Zm9vYmFy\");\n-    }\n-\n-    #[test]\n-    fn test_to_base64_crlf_line_break() {\n-        assert!(![0u8; 1000].to_base64(Config {line_length: None, ..STANDARD})\n-                              .contains(\"\\r\\n\"));\n-        assert_eq!(b\"foobar\".to_base64(Config {line_length: Some(4),\n-                                               ..STANDARD}),\n-                   \"Zm9v\\r\\nYmFy\");\n-    }\n-\n-    #[test]\n-    fn test_to_base64_lf_line_break() {\n-        assert!(![0u8; 1000].to_base64(Config {line_length: None,\n-                                                 newline: Newline::LF,\n-                                                 ..STANDARD})\n-                              .as_slice()\n-                              .contains(\"\\n\"));\n-        assert_eq!(b\"foobar\".to_base64(Config {line_length: Some(4),\n-                                               newline: Newline::LF,\n-                                               ..STANDARD}),\n-                   \"Zm9v\\nYmFy\");\n-    }\n-\n-    #[test]\n-    fn test_to_base64_padding() {\n-        assert_eq!(\"f\".as_bytes().to_base64(Config {pad: false, ..STANDARD}), \"Zg\");\n-        assert_eq!(\"fo\".as_bytes().to_base64(Config {pad: false, ..STANDARD}), \"Zm8\");\n-    }\n-\n-    #[test]\n-    fn test_to_base64_url_safe() {\n-        assert_eq!([251, 255].to_base64(URL_SAFE), \"-_8\");\n-        assert_eq!([251, 255].to_base64(STANDARD), \"+/8=\");\n-    }\n-\n-    #[test]\n-    fn test_from_base64_basic() {\n-        assert_eq!(\"\".from_base64().unwrap(), b\"\");\n-        assert_eq!(\"Zg==\".from_base64().unwrap(), b\"f\");\n-        assert_eq!(\"Zm8=\".from_base64().unwrap(), b\"fo\");\n-        assert_eq!(\"Zm9v\".from_base64().unwrap(), b\"foo\");\n-        assert_eq!(\"Zm9vYg==\".from_base64().unwrap(), b\"foob\");\n-        assert_eq!(\"Zm9vYmE=\".from_base64().unwrap(), b\"fooba\");\n-        assert_eq!(\"Zm9vYmFy\".from_base64().unwrap(), b\"foobar\");\n-    }\n-\n-    #[test]\n-    fn test_from_base64_bytes() {\n-        assert_eq!(b\"Zm9vYmFy\".from_base64().unwrap(), b\"foobar\");\n-    }\n-\n-    #[test]\n-    fn test_from_base64_newlines() {\n-        assert_eq!(\"Zm9v\\r\\nYmFy\".from_base64().unwrap(),\n-                   b\"foobar\");\n-        assert_eq!(\"Zm9vYg==\\r\\n\".from_base64().unwrap(),\n-                   b\"foob\");\n-        assert_eq!(\"Zm9v\\nYmFy\".from_base64().unwrap(),\n-                   b\"foobar\");\n-        assert_eq!(\"Zm9vYg==\\n\".from_base64().unwrap(),\n-                   b\"foob\");\n-    }\n-\n-    #[test]\n-    fn test_from_base64_urlsafe() {\n-        assert_eq!(\"-_8\".from_base64().unwrap(), \"+/8=\".from_base64().unwrap());\n-    }\n-\n-    #[test]\n-    fn test_from_base64_invalid_char() {\n-        assert!(\"Zm$=\".from_base64().is_err());\n-        assert!(\"Zg==$\".from_base64().is_err());\n-    }\n-\n-    #[test]\n-    fn test_from_base64_invalid_padding() {\n-        assert!(\"Z===\".from_base64().is_err());\n-    }\n-\n-    #[test]\n-    fn test_base64_random() {\n-        use std::rand::{thread_rng, random, Rng};\n-\n-        for _ in range(0u, 1000) {\n-            let times = thread_rng().gen_range(1u, 100);\n-            let v = thread_rng().gen_iter::<u8>().take(times).collect::<Vec<_>>();\n-            assert_eq!(v.to_base64(STANDARD)\n-                        .from_base64()\n-                        .unwrap(),\n-                       v);\n-        }\n-    }\n-\n-    #[bench]\n-    pub fn bench_to_base64(b: &mut Bencher) {\n-        let s = \"\u30a4\u30ed\u30cf\u30cb\u30db\u30d8\u30c8 \u30c1\u30ea\u30cc\u30eb\u30f2 \u30ef\u30ab\u30e8\u30bf\u30ec\u30bd \u30c4\u30cd\u30ca\u30e9\u30e0 \\\n-                 \u30a6\u30f0\u30ce\u30aa\u30af\u30e4\u30de \u30b1\u30d5\u30b3\u30a8\u30c6 \u30a2\u30b5\u30ad\u30e6\u30e1\u30df\u30b7 \u30f1\u30d2\u30e2\u30bb\u30b9\u30f3\";\n-        b.iter(|| {\n-            s.as_bytes().to_base64(STANDARD);\n-        });\n-        b.bytes = s.len() as u64;\n-    }\n-\n-    #[bench]\n-    pub fn bench_from_base64(b: &mut Bencher) {\n-        let s = \"\u30a4\u30ed\u30cf\u30cb\u30db\u30d8\u30c8 \u30c1\u30ea\u30cc\u30eb\u30f2 \u30ef\u30ab\u30e8\u30bf\u30ec\u30bd \u30c4\u30cd\u30ca\u30e9\u30e0 \\\n-                 \u30a6\u30f0\u30ce\u30aa\u30af\u30e4\u30de \u30b1\u30d5\u30b3\u30a8\u30c6 \u30a2\u30b5\u30ad\u30e6\u30e1\u30df\u30b7 \u30f1\u30d2\u30e2\u30bb\u30b9\u30f3\";\n-        let sb = s.as_bytes().to_base64(STANDARD);\n-        b.iter(|| {\n-            sb.from_base64().unwrap();\n-        });\n-        b.bytes = sb.len() as u64;\n-    }\n-\n-}"}, {"sha": "45dc297330be684708453679e632347b2cb2a1df", "filename": "src/libserialize/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibserialize%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibserialize%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Flib.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -43,7 +43,6 @@ pub use self::serialize::{Decoder, Encoder, Decodable, Encodable,\n mod serialize;\n mod collection_impls;\n \n-pub mod base64;\n pub mod hex;\n pub mod json;\n "}, {"sha": "793483754eebf05fd5726be4d693a3b298a8b0f6", "filename": "src/libtest/lib.rs", "status": "modified", "additions": 6, "deletions": 52, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibtest%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Flibtest%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibtest%2Flib.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -38,7 +38,6 @@\n #![allow(unstable)]\n \n extern crate getopts;\n-extern crate regex;\n extern crate serialize;\n extern crate \"serialize\" as rustc_serialize;\n extern crate term;\n@@ -53,7 +52,6 @@ use self::OutputLocation::*;\n \n use stats::Stats;\n use getopts::{OptGroup, optflag, optopt};\n-use regex::Regex;\n use serialize::Encodable;\n use term::Terminal;\n use term::color::{Color, RED, YELLOW, GREEN, CYAN};\n@@ -279,7 +277,7 @@ pub enum ColorConfig {\n }\n \n pub struct TestOpts {\n-    pub filter: Option<Regex>,\n+    pub filter: Option<String>,\n     pub run_ignored: bool,\n     pub run_tests: bool,\n     pub run_benchmarks: bool,\n@@ -365,11 +363,7 @@ pub fn parse_opts(args: &[String]) -> Option<OptRes> {\n     if matches.opt_present(\"h\") { usage(args[0].as_slice()); return None; }\n \n     let filter = if matches.free.len() > 0 {\n-        let s = matches.free[0].as_slice();\n-        match Regex::new(s) {\n-            Ok(re) => Some(re),\n-            Err(e) => return Some(Err(format!(\"could not parse /{}/: {:?}\", s, e)))\n-        }\n+        Some(matches.free[0].clone())\n     } else {\n         None\n     };\n@@ -833,9 +827,10 @@ pub fn filter_tests(opts: &TestOpts, tests: Vec<TestDescAndFn>) -> Vec<TestDescA\n     // Remove tests that don't match the test filter\n     filtered = match opts.filter {\n         None => filtered,\n-        Some(ref re) => {\n-            filtered.into_iter()\n-                .filter(|test| re.is_match(test.desc.name.as_slice())).collect()\n+        Some(ref filter) => {\n+            filtered.into_iter().filter(|test| {\n+                test.desc.name.as_slice().contains(&filter[])\n+            }).collect()\n         }\n     };\n \n@@ -1230,16 +1225,6 @@ mod tests {\n         assert!(res == TrFailed);\n     }\n \n-    #[test]\n-    fn first_free_arg_should_be_a_filter() {\n-        let args = vec!(\"progname\".to_string(), \"some_regex_filter\".to_string());\n-        let opts = match parse_opts(args.as_slice()) {\n-            Some(Ok(o)) => o,\n-            _ => panic!(\"Malformed arg in first_free_arg_should_be_a_filter\")\n-        };\n-        assert!(opts.filter.expect(\"should've found filter\").is_match(\"some_regex_filter\"))\n-    }\n-\n     #[test]\n     fn parse_ignored_flag() {\n         let args = vec!(\"progname\".to_string(),\n@@ -1336,37 +1321,6 @@ mod tests {\n         }\n     }\n \n-    #[test]\n-    pub fn filter_tests_regex() {\n-        let mut opts = TestOpts::new();\n-        opts.filter = Some(::regex::Regex::new(\"a.*b.+c\").unwrap());\n-\n-        let mut names = [\"yes::abXc\", \"yes::aXXXbXXXXc\",\n-                         \"no::XYZ\", \"no::abc\"];\n-        names.sort();\n-\n-        fn test_fn() {}\n-        let tests = names.iter().map(|name| {\n-            TestDescAndFn {\n-                desc: TestDesc {\n-                    name: DynTestName(name.to_string()),\n-                    ignore: false,\n-                    should_fail: ShouldFail::No,\n-                },\n-                testfn: DynTestFn(Thunk::new(test_fn))\n-            }\n-        }).collect();\n-        let filtered = filter_tests(&opts, tests);\n-\n-        let expected: Vec<&str> =\n-            names.iter().map(|&s| s).filter(|name| name.starts_with(\"yes\")).collect();\n-\n-        assert_eq!(filtered.len(), expected.len());\n-        for (test, expected_name) in filtered.iter().zip(expected.iter()) {\n-            assert_eq!(test.desc.name.as_slice(), *expected_name);\n-        }\n-    }\n-\n     #[test]\n     pub fn test_metricmap_compare() {\n         let mut m1 = MetricMap::new();"}, {"sha": "3047e93137f9fa70a71dac915c975a9aaf949642", "filename": "src/rustbook/book.rs", "status": "modified", "additions": 44, "deletions": 41, "changes": 85, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fbook.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fbook.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustbook%2Fbook.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -13,7 +13,6 @@\n use std::io::BufferedReader;\n use std::iter;\n use std::iter::AdditiveIterator;\n-use regex::Regex;\n \n pub struct BookItem {\n     pub title: String,\n@@ -94,8 +93,6 @@ pub fn parse_summary<R: Reader>(input: R, src: &Path) -> Result<Book, Vec<String\n         }\n     }\n \n-    let regex = r\"(?P<indent>[\\t ]*)\\*[:space:]*\\[(?P<title>.*)\\]\\((?P<path>.*)\\)\";\n-    let item_re = Regex::new(regex).unwrap();\n     let mut top_items = vec!();\n     let mut stack = vec!();\n     let mut errors = vec!();\n@@ -117,45 +114,51 @@ pub fn parse_summary<R: Reader>(input: R, src: &Path) -> Result<Book, Vec<String\n             }\n         };\n \n-        item_re.captures(&line[]).map(|cap| {\n-            let given_path = cap.name(\"path\");\n-            let title = cap.name(\"title\").unwrap().to_string();\n-\n-            let path_from_root = match src.join(given_path.unwrap()).path_relative_from(src) {\n-                Some(p) => p,\n-                None => {\n-                    errors.push(format!(\"paths in SUMMARY.md must be relative, \\\n-                                         but path '{}' for section '{}' is not.\",\n-                                         given_path.unwrap(), title));\n-                    Path::new(\"\")\n-                }\n-            };\n-            let path_to_root = Path::new(iter::repeat(\"../\")\n-                                             .take(path_from_root.components().count() - 1)\n-                                             .collect::<String>());\n-            let item = BookItem {\n-                title: title,\n-                path: path_from_root,\n-                path_to_root: path_to_root,\n-                children: vec!(),\n-            };\n-            let level = cap.name(\"indent\").unwrap().chars().map(|c| {\n-                match c {\n-                    ' ' => 1us,\n-                    '\\t' => 4,\n-                    _ => unreachable!()\n-                }\n-            }).sum() / 4 + 1;\n-\n-            if level > stack.len() + 1 {\n-                errors.push(format!(\"section '{}' is indented too deeply; \\\n-                                     found {}, expected {} or less\",\n-                                    item.title, level, stack.len() + 1));\n-            } else if level <= stack.len() {\n-                collapse(&mut stack, &mut top_items, level);\n+        let star_idx = match line.find_str(\"*\") { Some(i) => i, None => continue };\n+\n+        let start_bracket = star_idx + line[star_idx..].find_str(\"[\").unwrap();\n+        let end_bracket = start_bracket + line[start_bracket..].find_str(\"](\").unwrap();\n+        let start_paren = end_bracket + 1;\n+        let end_paren = start_paren + line[start_paren..].find_str(\")\").unwrap();\n+\n+        let given_path = &line[start_paren + 1 .. end_paren];\n+        let title = line[start_bracket + 1..end_bracket].to_string();\n+        let indent = &line[..star_idx];\n+\n+        let path_from_root = match src.join(given_path).path_relative_from(src) {\n+            Some(p) => p,\n+            None => {\n+                errors.push(format!(\"paths in SUMMARY.md must be relative, \\\n+                                     but path '{}' for section '{}' is not.\",\n+                                     given_path, title));\n+                Path::new(\"\")\n             }\n-            stack.push(item)\n-        });\n+        };\n+        let path_to_root = Path::new(iter::repeat(\"../\")\n+                                         .take(path_from_root.components().count() - 1)\n+                                         .collect::<String>());\n+        let item = BookItem {\n+            title: title,\n+            path: path_from_root,\n+            path_to_root: path_to_root,\n+            children: vec!(),\n+        };\n+        let level = indent.chars().map(|c| {\n+            match c {\n+                ' ' => 1us,\n+                '\\t' => 4,\n+                _ => unreachable!()\n+            }\n+        }).sum() / 4 + 1;\n+\n+        if level > stack.len() + 1 {\n+            errors.push(format!(\"section '{}' is indented too deeply; \\\n+                                 found {}, expected {} or less\",\n+                                item.title, level, stack.len() + 1));\n+        } else if level <= stack.len() {\n+            collapse(&mut stack, &mut top_items, level);\n+        }\n+        stack.push(item)\n     }\n \n     if errors.is_empty() {"}, {"sha": "93601c0f61bf40c4fa71de65ead89d44764e7a4f", "filename": "src/rustbook/build.rs", "status": "modified", "additions": 1, "deletions": 6, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustbook%2Fbuild.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -22,8 +22,6 @@ use book::{Book, BookItem};\n use css;\n use javascript;\n \n-use regex::Regex;\n-\n use rustdoc;\n \n struct Build;\n@@ -81,9 +79,6 @@ fn render(book: &Book, tgt: &Path) -> CliResult<()> {\n \n         let out_path = tgt.join(item.path.dirname());\n \n-        let regex = r\"\\[(?P<title>[^]]*)\\]\\((?P<url_stem>[^)]*)\\.(?P<ext>md|markdown)\\)\";\n-        let md_urls = Regex::new(regex).unwrap();\n-\n         let src;\n         if os::args().len() < 3 {\n             src = os::getcwd().unwrap().clone();\n@@ -94,7 +89,7 @@ fn render(book: &Book, tgt: &Path) -> CliResult<()> {\n         let markdown_data = try!(File::open(&src.join(&item.path)).read_to_string());\n         let preprocessed_path = tmp.path().join(item.path.filename().unwrap());\n         {\n-            let urls = md_urls.replace_all(&markdown_data[], \"[$title]($url_stem.html)\");\n+            let urls = markdown_data.replace(\".md)\", \".html)\");\n             try!(File::create(&preprocessed_path)\n                       .write_str(&urls[]));\n         }"}, {"sha": "cbd29004097e8b4c09ad00c799e510a5e1d0e8e1", "filename": "src/rustbook/main.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Frustbook%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Frustbook%2Fmain.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -11,8 +11,6 @@\n #![feature(slicing_syntax, box_syntax)]\n #![allow(unstable)]\n \n-extern crate regex;\n-\n extern crate rustdoc;\n \n use std::os;"}, {"sha": "074c05923129933845e45c144534c6d0819cd86e", "filename": "src/test/bench/shootout-regex-dna.rs", "status": "removed", "additions": 0, "deletions": 126, "changes": 126, "blob_url": "https://github.com/rust-lang/rust/blob/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4be79d6acde9eed3a9b5281a46f385bcb4ce736c/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-regex-dna.rs?ref=4be79d6acde9eed3a9b5281a46f385bcb4ce736c", "patch": "@@ -1,126 +0,0 @@\n-// The Computer Language Benchmarks Game\n-// http://benchmarksgame.alioth.debian.org/\n-//\n-// contributed by the Rust Project Developers\n-\n-// Copyright (c) 2014 The Rust Project Developers\n-//\n-// All rights reserved.\n-//\n-// Redistribution and use in source and binary forms, with or without\n-// modification, are permitted provided that the following conditions\n-// are met:\n-//\n-// - Redistributions of source code must retain the above copyright\n-//   notice, this list of conditions and the following disclaimer.\n-//\n-// - Redistributions in binary form must reproduce the above copyright\n-//   notice, this list of conditions and the following disclaimer in\n-//   the documentation and/or other materials provided with the\n-//   distribution.\n-//\n-// - Neither the name of \"The Computer Language Benchmarks Game\" nor\n-//   the name of \"The Computer Language Shootout Benchmarks\" nor the\n-//   names of its contributors may be used to endorse or promote\n-//   products derived from this software without specific prior\n-//   written permission.\n-//\n-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n-// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n-// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n-// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n-// COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n-// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n-// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n-// HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n-// STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n-// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED\n-// OF THE POSSIBILITY OF SUCH DAMAGE.\n-\n-// ignore-stage1\n-// ignore-cross-compile #12102\n-\n-#![feature(box_syntax)]\n-\n-extern crate regex;\n-\n-use std::io;\n-use regex::{NoExpand, Regex};\n-use std::sync::{Arc, Future};\n-\n-macro_rules! regex {\n-    ($e:expr) => (Regex::new($e).unwrap())\n-}\n-\n-fn count_matches(seq: &str, variant: &Regex) -> int {\n-    let mut n = 0;\n-    for _ in variant.find_iter(seq) {\n-        n += 1;\n-    }\n-    n\n-}\n-\n-fn main() {\n-    let mut rdr = if std::os::getenv(\"RUST_BENCH\").is_some() {\n-        let fd = io::File::open(&Path::new(\"shootout-k-nucleotide.data\"));\n-        box io::BufferedReader::new(fd) as Box<io::Reader>\n-    } else {\n-        box io::stdin() as Box<io::Reader>\n-    };\n-    let mut seq = rdr.read_to_string().unwrap();\n-    let ilen = seq.len();\n-\n-    seq = regex!(\">[^\\n]*\\n|\\n\").replace_all(seq.as_slice(), NoExpand(\"\"));\n-    let seq_arc = Arc::new(seq.clone()); // copy before it moves\n-    let clen = seq.len();\n-\n-    let mut seqlen = Future::spawn(move|| {\n-        let substs = vec![\n-            (regex!(\"B\"), \"(c|g|t)\"),\n-            (regex!(\"D\"), \"(a|g|t)\"),\n-            (regex!(\"H\"), \"(a|c|t)\"),\n-            (regex!(\"K\"), \"(g|t)\"),\n-            (regex!(\"M\"), \"(a|c)\"),\n-            (regex!(\"N\"), \"(a|c|g|t)\"),\n-            (regex!(\"R\"), \"(a|g)\"),\n-            (regex!(\"S\"), \"(c|g)\"),\n-            (regex!(\"V\"), \"(a|c|g)\"),\n-            (regex!(\"W\"), \"(a|t)\"),\n-            (regex!(\"Y\"), \"(c|t)\"),\n-        ];\n-        let mut seq = seq;\n-        for (re, replacement) in substs.into_iter() {\n-            seq = re.replace_all(seq.as_slice(), NoExpand(replacement));\n-        }\n-        seq.len()\n-    });\n-\n-    let variants = vec![\n-        regex!(\"agggtaaa|tttaccct\"),\n-        regex!(\"[cgt]gggtaaa|tttaccc[acg]\"),\n-        regex!(\"a[act]ggtaaa|tttacc[agt]t\"),\n-        regex!(\"ag[act]gtaaa|tttac[agt]ct\"),\n-        regex!(\"agg[act]taaa|ttta[agt]cct\"),\n-        regex!(\"aggg[acg]aaa|ttt[cgt]ccct\"),\n-        regex!(\"agggt[cgt]aa|tt[acg]accct\"),\n-        regex!(\"agggta[cgt]a|t[acg]taccct\"),\n-        regex!(\"agggtaa[cgt]|[acg]ttaccct\"),\n-    ];\n-    let (mut variant_strs, mut counts) = (vec!(), vec!());\n-    for variant in variants.into_iter() {\n-        let seq_arc_copy = seq_arc.clone();\n-        variant_strs.push(variant.to_string());\n-        counts.push(Future::spawn(move|| {\n-            count_matches(seq_arc_copy.as_slice(), &variant)\n-        }));\n-    }\n-\n-    for (i, variant) in variant_strs.iter().enumerate() {\n-        println!(\"{} {}\", variant, counts[i].get());\n-    }\n-    println!(\"\");\n-    println!(\"{}\", ilen);\n-    println!(\"{}\", clen);\n-    println!(\"{}\", seqlen.get());\n-}"}, {"sha": "f7fa204d4539cb47fa950e1913ff0d9255fa3f5c", "filename": "src/test/run-pass/rust-log-filter.rs", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Ftest%2Frun-pass%2Frust-log-filter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e5c1f166a8282072089de2ad62a5b2427bd2bebf/src%2Ftest%2Frun-pass%2Frust-log-filter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Frust-log-filter.rs?ref=e5c1f166a8282072089de2ad62a5b2427bd2bebf", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-// exec-env:RUST_LOG=rust-log-filter/f.o\n+// exec-env:RUST_LOG=rust-log-filter/foo\n \n #![allow(unknown_features)]\n #![feature(box_syntax)]\n@@ -42,18 +42,14 @@ pub fn main() {\n     let _t = Thread::spawn(move|| {\n         log::set_logger(logger);\n \n-        // our regex is \"f.o\"\n-        // ensure it is a regex, and isn't anchored\n         info!(\"foo\");\n         info!(\"bar\");\n         info!(\"foo bar\");\n         info!(\"bar foo\");\n-        info!(\"f1o\");\n     });\n \n     assert_eq!(rx.recv().unwrap().as_slice(), \"foo\");\n     assert_eq!(rx.recv().unwrap().as_slice(), \"foo bar\");\n     assert_eq!(rx.recv().unwrap().as_slice(), \"bar foo\");\n-    assert_eq!(rx.recv().unwrap().as_slice(), \"f1o\");\n     assert!(rx.recv().is_err());\n }"}]}