{"sha": "ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFlMDY1OWM5N2QzM2ViNGQ5Yzg0ZTBlYzZhNjZiODFhOWUzNWVmMWM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-06-09T23:32:01Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-06-09T23:32:01Z"}, "message": "Auto merge of #51265 - Mark-Simulacrum:cleanup-syntax-parse, r=petrochenkov\n\ncrate-ify and delete unused code from syntax::parse\n\nThis is intended primarily to ensure the compiler catches dead code for us in\nmore cases.", "tree": {"sha": "626bb824770e0118ec38951a3cba7757cf853a75", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/626bb824770e0118ec38951a3cba7757cf853a75"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "html_url": "https://github.com/rust-lang/rust/commit/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2a0062974a5225847fc43d5522c4dc3718173fe5", "url": "https://api.github.com/repos/rust-lang/rust/commits/2a0062974a5225847fc43d5522c4dc3718173fe5", "html_url": "https://github.com/rust-lang/rust/commit/2a0062974a5225847fc43d5522c4dc3718173fe5"}, {"sha": "60058e5dbe1ef466010cc34aa31e84ccf1ebb330", "url": "https://api.github.com/repos/rust-lang/rust/commits/60058e5dbe1ef466010cc34aa31e84ccf1ebb330", "html_url": "https://github.com/rust-lang/rust/commit/60058e5dbe1ef466010cc34aa31e84ccf1ebb330"}], "stats": {"total": 556, "additions": 191, "deletions": 365}, "files": [{"sha": "2ee14bd61c28532c3750c52f7b124562cbf340b8", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -25,6 +25,7 @@\n #![feature(const_atomic_usize_new)]\n #![feature(rustc_attrs)]\n #![feature(str_escape)]\n+#![feature(crate_visibility_modifier)]\n \n #![recursion_limit=\"256\"]\n "}, {"sha": "9919d910fbccaa89484bfcf131ab98a103f36d8e", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -11,8 +11,7 @@\n use attr;\n use ast;\n use codemap::respan;\n-use parse::common::SeqSep;\n-use parse::PResult;\n+use parse::{SeqSep, PResult};\n use parse::token::{self, Nonterminal};\n use parse::parser::{Parser, TokenType, PathStyle};\n use tokenstream::TokenStream;\n@@ -28,7 +27,7 @@ const DEFAULT_UNEXPECTED_INNER_ATTR_ERR_MSG: &'static str = \"an inner attribute\n \n impl<'a> Parser<'a> {\n     /// Parse attributes that appear before an item\n-    pub fn parse_outer_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n+    crate fn parse_outer_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = Vec::new();\n         let mut just_parsed_doc_comment = false;\n         loop {\n@@ -139,7 +138,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn parse_path_and_tokens(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n+    crate fn parse_path_and_tokens(&mut self) -> PResult<'a, (ast::Path, TokenStream)> {\n         let meta = match self.token {\n             token::Interpolated(ref nt) => match nt.0 {\n                 Nonterminal::NtMeta(ref meta) => Some(meta.clone()),\n@@ -160,7 +159,7 @@ impl<'a> Parser<'a> {\n     /// terminated by a semicolon.\n \n     /// matches inner_attrs*\n-    pub fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n+    crate fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n             match self.token {\n@@ -231,7 +230,7 @@ impl<'a> Parser<'a> {\n         Ok(ast::MetaItem { ident, node, span })\n     }\n \n-    pub fn parse_meta_item_kind(&mut self) -> PResult<'a, ast::MetaItemKind> {\n+    crate fn parse_meta_item_kind(&mut self) -> PResult<'a, ast::MetaItemKind> {\n         Ok(if self.eat(&token::Eq) {\n             ast::MetaItemKind::NameValue(self.parse_unsuffixed_lit()?)\n         } else if self.eat(&token::OpenDelim(token::Paren)) {"}, {"sha": "fe931f7cf6a645f4025baea781dc4e5a89ac2460", "filename": "src/libsyntax/parse/common.rs", "status": "removed", "additions": 0, "deletions": 36, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/2a0062974a5225847fc43d5522c4dc3718173fe5/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2a0062974a5225847fc43d5522c4dc3718173fe5/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=2a0062974a5225847fc43d5522c4dc3718173fe5", "patch": "@@ -1,36 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Common routines shared by parser mods\n-\n-use parse::token;\n-\n-/// `SeqSep` : a sequence separator (token)\n-/// and whether a trailing separator is allowed.\n-pub struct SeqSep {\n-    pub sep: Option<token::Token>,\n-    pub trailing_sep_allowed: bool,\n-}\n-\n-impl SeqSep {\n-    pub fn trailing_allowed(t: token::Token) -> SeqSep {\n-        SeqSep {\n-            sep: Some(t),\n-            trailing_sep_allowed: true,\n-        }\n-    }\n-\n-    pub fn none() -> SeqSep {\n-        SeqSep {\n-            sep: None,\n-            trailing_sep_allowed: false,\n-        }\n-    }\n-}"}, {"sha": "7da0d816d0f7aeb39afeb67c587d999604ea521b", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -40,7 +40,7 @@ pub struct Comment {\n     pub pos: BytePos,\n }\n \n-pub fn is_doc_comment(s: &str) -> bool {\n+fn is_doc_comment(s: &str) -> bool {\n     (s.starts_with(\"///\") && super::is_doc_comment(s)) || s.starts_with(\"//!\") ||\n     (s.starts_with(\"/**\") && is_block_doc_comment(s)) || s.starts_with(\"/*!\")\n }"}, {"sha": "8363c1f39aa37e5f3bfcdd903f6d4be096c7a0ad", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 19, "deletions": 21, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -51,16 +51,16 @@ pub struct StringReader<'a> {\n     pub ch: Option<char>,\n     pub filemap: Lrc<syntax_pos::FileMap>,\n     /// Stop reading src at this index.\n-    pub end_src_index: usize,\n+    end_src_index: usize,\n     /// Whether to record new-lines and multibyte chars in filemap.\n     /// This is only necessary the first time a filemap is lexed.\n     /// If part of a filemap is being re-lexed, this should be set to false.\n-    pub save_new_lines_and_multibyte: bool,\n+    save_new_lines_and_multibyte: bool,\n     // cached:\n     peek_tok: token::Token,\n     peek_span: Span,\n     peek_span_src_raw: Span,\n-    pub fatal_errs: Vec<DiagnosticBuilder<'a>>,\n+    fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n     src: Lrc<String>,\n@@ -70,7 +70,7 @@ pub struct StringReader<'a> {\n     /// The raw source span which *does not* take `override_span` into account\n     span_src_raw: Span,\n     open_braces: Vec<(token::DelimToken, Span)>,\n-    pub override_span: Option<Span>,\n+    crate override_span: Option<Span>,\n }\n \n impl<'a> StringReader<'a> {\n@@ -163,11 +163,9 @@ impl<'a> StringReader<'a> {\n             sp: self.peek_span,\n         }\n     }\n-}\n \n-impl<'a> StringReader<'a> {\n     /// For comments.rs, which hackily pokes into next_pos and ch\n-    pub fn new_raw(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>,\n+    fn new_raw(sess: &'a ParseSess, filemap: Lrc<syntax_pos::FileMap>,\n                    override_span: Option<Span>) -> Self {\n         let mut sr = StringReader::new_raw_internal(sess, filemap, override_span);\n         sr.bump();\n@@ -240,17 +238,17 @@ impl<'a> StringReader<'a> {\n         sr\n     }\n \n-    pub fn ch_is(&self, c: char) -> bool {\n+    fn ch_is(&self, c: char) -> bool {\n         self.ch == Some(c)\n     }\n \n     /// Report a fatal lexical error with a given span.\n-    pub fn fatal_span(&self, sp: Span, m: &str) -> FatalError {\n+    fn fatal_span(&self, sp: Span, m: &str) -> FatalError {\n         self.sess.span_diagnostic.span_fatal(sp, m)\n     }\n \n     /// Report a lexical error with a given span.\n-    pub fn err_span(&self, sp: Span, m: &str) {\n+    fn err_span(&self, sp: Span, m: &str) {\n         self.sess.span_diagnostic.span_err(sp, m)\n     }\n \n@@ -375,7 +373,7 @@ impl<'a> StringReader<'a> {\n     /// Calls `f` with a string slice of the source text spanning from `start`\n     /// up to but excluding `self.pos`, meaning the slice does not include\n     /// the character `self.ch`.\n-    pub fn with_str_from<T, F>(&self, start: BytePos, f: F) -> T\n+    fn with_str_from<T, F>(&self, start: BytePos, f: F) -> T\n         where F: FnOnce(&str) -> T\n     {\n         self.with_str_from_to(start, self.pos, f)\n@@ -384,13 +382,13 @@ impl<'a> StringReader<'a> {\n     /// Create a Name from a given offset to the current offset, each\n     /// adjusted 1 towards each other (assumes that on either side there is a\n     /// single-byte delimiter).\n-    pub fn name_from(&self, start: BytePos) -> ast::Name {\n+    fn name_from(&self, start: BytePos) -> ast::Name {\n         debug!(\"taking an ident from {:?} to {:?}\", start, self.pos);\n         self.with_str_from(start, Symbol::intern)\n     }\n \n     /// As name_from, with an explicit endpoint.\n-    pub fn name_from_to(&self, start: BytePos, end: BytePos) -> ast::Name {\n+    fn name_from_to(&self, start: BytePos, end: BytePos) -> ast::Name {\n         debug!(\"taking an ident from {:?} to {:?}\", start, end);\n         self.with_str_from_to(start, end, Symbol::intern)\n     }\n@@ -454,7 +452,7 @@ impl<'a> StringReader<'a> {\n \n     /// Advance the StringReader by one character. If a newline is\n     /// discovered, add it to the FileMap's list of line start offsets.\n-    pub fn bump(&mut self) {\n+    crate fn bump(&mut self) {\n         let next_src_index = self.src_index(self.next_pos);\n         if next_src_index < self.end_src_index {\n             let next_ch = char_at(&self.src, next_src_index);\n@@ -481,7 +479,7 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    pub fn nextch(&self) -> Option<char> {\n+    fn nextch(&self) -> Option<char> {\n         let next_src_index = self.src_index(self.next_pos);\n         if next_src_index < self.end_src_index {\n             Some(char_at(&self.src, next_src_index))\n@@ -490,11 +488,11 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    pub fn nextch_is(&self, c: char) -> bool {\n+    fn nextch_is(&self, c: char) -> bool {\n         self.nextch() == Some(c)\n     }\n \n-    pub fn nextnextch(&self) -> Option<char> {\n+    fn nextnextch(&self) -> Option<char> {\n         let next_src_index = self.src_index(self.next_pos);\n         if next_src_index < self.end_src_index {\n             let next_next_src_index =\n@@ -506,7 +504,7 @@ impl<'a> StringReader<'a> {\n         None\n     }\n \n-    pub fn nextnextch_is(&self, c: char) -> bool {\n+    fn nextnextch_is(&self, c: char) -> bool {\n         self.nextnextch() == Some(c)\n     }\n \n@@ -1732,7 +1730,7 @@ impl<'a> StringReader<'a> {\n \n // This tests the character for the unicode property 'PATTERN_WHITE_SPACE' which\n // is guaranteed to be forward compatible. http://unicode.org/reports/tr31/#R3\n-pub fn is_pattern_whitespace(c: Option<char>) -> bool {\n+crate fn is_pattern_whitespace(c: Option<char>) -> bool {\n     c.map_or(false, Pattern_White_Space)\n }\n \n@@ -1747,14 +1745,14 @@ fn is_dec_digit(c: Option<char>) -> bool {\n     in_range(c, '0', '9')\n }\n \n-pub fn is_doc_comment(s: &str) -> bool {\n+fn is_doc_comment(s: &str) -> bool {\n     let res = (s.starts_with(\"///\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'/') ||\n               s.starts_with(\"//!\");\n     debug!(\"is {:?} a doc comment? {}\", s, res);\n     res\n }\n \n-pub fn is_block_doc_comment(s: &str) -> bool {\n+fn is_block_doc_comment(s: &str) -> bool {\n     // Prevent `/**/` from being parsed as a doc comment\n     let res = ((s.starts_with(\"/**\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'*') ||\n                s.starts_with(\"/*!\")) && s.len() >= 5;"}, {"sha": "36c220fa0d943d34f3aa4973c6618008ca4261a8", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -15,7 +15,7 @@ use tokenstream::{Delimited, TokenStream, TokenTree};\n \n impl<'a> StringReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n-    pub fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n+    crate fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n         let mut tts = Vec::new();\n         while self.token != token::Eof {\n             tts.push(self.parse_token_tree()?);"}, {"sha": "a32b515672ecaba229bc572b095fb18801ee66fa", "filename": "src/libsyntax/parse/lexer/unicode_chars.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -333,7 +333,7 @@ const ASCII_ARRAY: &'static [(char, &'static str)] = &[\n     ('=', \"Equals Sign\"),\n     ('>', \"Greater-Than Sign\"), ];\n \n-pub fn check_for_substitution<'a>(reader: &StringReader<'a>,\n+crate fn check_for_substitution<'a>(reader: &StringReader<'a>,\n                                   ch: char,\n                                   err: &mut DiagnosticBuilder<'a>) -> bool {\n     UNICODE_ARRAY"}, {"sha": "0050434d42e3f41060be582896f1dd26be0139a1", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 37, "deletions": 20, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -38,7 +38,6 @@ pub mod lexer;\n pub mod token;\n pub mod attr;\n \n-pub mod common;\n pub mod classify;\n \n /// Info about a parsing session.\n@@ -51,7 +50,7 @@ pub struct ParseSess {\n     /// raw identifiers\n     pub raw_identifier_spans: Lock<Vec<Span>>,\n     /// The registered diagnostics codes\n-    pub registered_diagnostics: Lock<ErrorMap>,\n+    crate registered_diagnostics: Lock<ErrorMap>,\n     // Spans where a `mod foo;` statement was included in a non-mod.rs file.\n     // These are used to issue errors if the non_modrs_mods feature is not enabled.\n     pub non_modrs_mods: Lock<Vec<(ast::Ident, Span)>>,\n@@ -131,7 +130,7 @@ pub fn parse_crate_attrs_from_source_str(name: FileName, source: String, sess: &\n     new_parser_from_source_str(sess, name, source).parse_inner_attributes()\n }\n \n-pub fn parse_expr_from_source_str(name: FileName, source: String, sess: &ParseSess)\n+crate fn parse_expr_from_source_str(name: FileName, source: String, sess: &ParseSess)\n                                       -> PResult<P<ast::Expr>> {\n     new_parser_from_source_str(sess, name, source).parse_expr()\n }\n@@ -140,17 +139,12 @@ pub fn parse_expr_from_source_str(name: FileName, source: String, sess: &ParseSe\n ///\n /// Returns `Ok(Some(item))` when successful, `Ok(None)` when no item was found, and `Err`\n /// when a syntax error occurred.\n-pub fn parse_item_from_source_str(name: FileName, source: String, sess: &ParseSess)\n+crate fn parse_item_from_source_str(name: FileName, source: String, sess: &ParseSess)\n                                       -> PResult<Option<P<ast::Item>>> {\n     new_parser_from_source_str(sess, name, source).parse_item()\n }\n \n-pub fn parse_meta_from_source_str(name: FileName, source: String, sess: &ParseSess)\n-                                      -> PResult<ast::MetaItem> {\n-    new_parser_from_source_str(sess, name, source).parse_meta_item()\n-}\n-\n-pub fn parse_stmt_from_source_str(name: FileName, source: String, sess: &ParseSess)\n+crate fn parse_stmt_from_source_str(name: FileName, source: String, sess: &ParseSess)\n                                       -> PResult<Option<ast::Stmt>> {\n     new_parser_from_source_str(sess, name, source).parse_stmt()\n }\n@@ -178,7 +172,7 @@ pub fn new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path) -> Parser<'a>\n /// Given a session, a crate config, a path, and a span, add\n /// the file at the given path to the codemap, and return a parser.\n /// On an error, use the given span as the source of the problem.\n-pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n+crate fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n                                     path: &Path,\n                                     directory_ownership: DirectoryOwnership,\n                                     module_name: Option<String>,\n@@ -190,7 +184,7 @@ pub fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n }\n \n /// Given a filemap and config, return a parser\n-pub fn filemap_to_parser(sess: & ParseSess, filemap: Lrc<FileMap>) -> Parser {\n+fn filemap_to_parser(sess: & ParseSess, filemap: Lrc<FileMap>) -> Parser {\n     let end_pos = filemap.end_pos;\n     let mut parser = stream_to_parser(sess, filemap_to_stream(sess, filemap, None));\n \n@@ -243,7 +237,7 @@ pub fn stream_to_parser(sess: &ParseSess, stream: TokenStream) -> Parser {\n /// Rather than just accepting/rejecting a given literal, unescapes it as\n /// well. Can take any slice prefixed by a character escape. Returns the\n /// character and the number of characters consumed.\n-pub fn char_lit(lit: &str, diag: Option<(Span, &Handler)>) -> (char, isize) {\n+fn char_lit(lit: &str, diag: Option<(Span, &Handler)>) -> (char, isize) {\n     use std::char;\n \n     // Handle non-escaped chars first.\n@@ -300,7 +294,7 @@ pub fn char_lit(lit: &str, diag: Option<(Span, &Handler)>) -> (char, isize) {\n \n /// Parse a string representing a string literal into its final form. Does\n /// unescaping.\n-pub fn str_lit(lit: &str, diag: Option<(Span, &Handler)>) -> String {\n+fn str_lit(lit: &str, diag: Option<(Span, &Handler)>) -> String {\n     debug!(\"str_lit: given {}\", lit.escape_default());\n     let mut res = String::with_capacity(lit.len());\n \n@@ -369,7 +363,7 @@ pub fn str_lit(lit: &str, diag: Option<(Span, &Handler)>) -> String {\n \n /// Parse a string representing a raw string literal into its final form. The\n /// only operation this does is convert embedded CRLF into a single LF.\n-pub fn raw_str_lit(lit: &str) -> String {\n+fn raw_str_lit(lit: &str) -> String {\n     debug!(\"raw_str_lit: given {}\", lit.escape_default());\n     let mut res = String::with_capacity(lit.len());\n \n@@ -406,7 +400,7 @@ macro_rules! err {\n     }\n }\n \n-pub fn lit_token(lit: token::Lit, suf: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+crate fn lit_token(lit: token::Lit, suf: Option<Symbol>, diag: Option<(Span, &Handler)>)\n                  -> (bool /* suffix illegal? */, Option<ast::LitKind>) {\n     use ast::LitKind;\n \n@@ -476,7 +470,7 @@ fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span,\n         }\n     })\n }\n-pub fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n                  -> Option<ast::LitKind> {\n     debug!(\"float_lit: {:?}, {:?}\", s, suffix);\n     // FIXME #2252: bounds checking float literals is deferred until trans\n@@ -485,7 +479,7 @@ pub fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>\n }\n \n /// Parse a string representing a byte literal into its final form. Similar to `char_lit`\n-pub fn byte_lit(lit: &str) -> (u8, usize) {\n+fn byte_lit(lit: &str) -> (u8, usize) {\n     let err = |i| format!(\"lexer accepted invalid byte literal {} step {}\", lit, i);\n \n     if lit.len() == 1 {\n@@ -516,7 +510,7 @@ pub fn byte_lit(lit: &str) -> (u8, usize) {\n     }\n }\n \n-pub fn byte_str_lit(lit: &str) -> Lrc<Vec<u8>> {\n+fn byte_str_lit(lit: &str) -> Lrc<Vec<u8>> {\n     let mut res = Vec::with_capacity(lit.len());\n \n     let error = |i| format!(\"lexer should have rejected {} at {}\", lit, i);\n@@ -575,7 +569,7 @@ pub fn byte_str_lit(lit: &str) -> Lrc<Vec<u8>> {\n     Lrc::new(res)\n }\n \n-pub fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n+fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n                    -> Option<ast::LitKind> {\n     // s can only be ascii, byte indexing is fine\n \n@@ -1136,3 +1130,26 @@ mod tests {\n         });\n     }\n }\n+\n+/// `SeqSep` : a sequence separator (token)\n+/// and whether a trailing separator is allowed.\n+pub struct SeqSep {\n+    pub sep: Option<token::Token>,\n+    pub trailing_sep_allowed: bool,\n+}\n+\n+impl SeqSep {\n+    pub fn trailing_allowed(t: token::Token) -> SeqSep {\n+        SeqSep {\n+            sep: Some(t),\n+            trailing_sep_allowed: true,\n+        }\n+    }\n+\n+    pub fn none() -> SeqSep {\n+        SeqSep {\n+            sep: None,\n+            trailing_sep_allowed: false,\n+        }\n+    }\n+}"}, {"sha": "ab2371626c374d55ece5b773ea9c4b9e5f3e4773", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 105, "deletions": 234, "changes": 339, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -23,7 +23,7 @@ use ast::{Field, FnDecl};\n use ast::{ForeignItem, ForeignItemKind, FunctionRetTy};\n use ast::GenericParam;\n use ast::{Ident, ImplItem, IsAuto, Item, ItemKind};\n-use ast::{Label, Lifetime, LifetimeDef, Lit, LitKind, UintTy};\n+use ast::{Label, Lifetime, LifetimeDef, Lit, LitKind};\n use ast::Local;\n use ast::MacStmtStyle;\n use ast::{Mac, Mac_, MacDelimiter};\n@@ -44,8 +44,7 @@ use {ast, attr};\n use codemap::{self, CodeMap, Spanned, respan};\n use syntax_pos::{self, Span, MultiSpan, BytePos, FileName, DUMMY_SP};\n use errors::{self, Applicability, DiagnosticBuilder};\n-use parse::{self, classify, token};\n-use parse::common::SeqSep;\n+use parse::{self, SeqSep, classify, token};\n use parse::lexer::TokenAndSpan;\n use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use parse::{new_sub_parser_from_file, ParseSess, Directory, DirectoryOwnership};\n@@ -64,7 +63,7 @@ use std::path::{self, Path, PathBuf};\n use std::slice;\n \n bitflags! {\n-    pub struct Restrictions: u8 {\n+    struct Restrictions: u8 {\n         const STMT_EXPR         = 1 << 0;\n         const NO_STRUCT_LITERAL = 1 << 1;\n     }\n@@ -96,13 +95,13 @@ pub enum PathStyle {\n }\n \n #[derive(Clone, Copy, Debug, PartialEq)]\n-pub enum SemiColonMode {\n+enum SemiColonMode {\n     Break,\n     Ignore,\n }\n \n #[derive(Clone, Copy, Debug, PartialEq)]\n-pub enum BlockMode {\n+enum BlockMode {\n     Break,\n     Ignore,\n }\n@@ -223,22 +222,22 @@ pub struct Parser<'a> {\n     /// the span of the current token:\n     pub span: Span,\n     /// the span of the previous token:\n-    pub meta_var_span: Option<Span>,\n+    meta_var_span: Option<Span>,\n     pub prev_span: Span,\n     /// the previous token kind\n     prev_token_kind: PrevTokenKind,\n-    pub restrictions: Restrictions,\n+    restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files\n-    pub directory: Directory<'a>,\n+    crate directory: Directory<'a>,\n     /// Whether to parse sub-modules in other files.\n     pub recurse_into_file_modules: bool,\n     /// Name of the root module this parser originated from. If `None`, then the\n     /// name is not known. This does not change while the parser is descending\n     /// into modules, and sub-parsers have new values for this name.\n     pub root_module_name: Option<String>,\n-    pub expected_tokens: Vec<TokenType>,\n+    crate expected_tokens: Vec<TokenType>,\n     token_cursor: TokenCursor,\n-    pub desugar_doc_comments: bool,\n+    desugar_doc_comments: bool,\n     /// Whether we should configure out of line modules as we parse.\n     pub cfg_mods: bool,\n }\n@@ -377,7 +376,7 @@ impl TokenCursor {\n }\n \n #[derive(PartialEq, Eq, Clone)]\n-pub enum TokenType {\n+crate enum TokenType {\n     Token(token::Token),\n     Keyword(keywords::Keyword),\n     Operator,\n@@ -390,7 +389,7 @@ pub enum TokenType {\n impl TokenType {\n     fn to_string(&self) -> String {\n         match *self {\n-            TokenType::Token(ref t) => format!(\"`{}`\", Parser::token_to_string(t)),\n+            TokenType::Token(ref t) => format!(\"`{}`\", pprust::token_to_string(t)),\n             TokenType::Keyword(kw) => format!(\"`{}`\", kw.name()),\n             TokenType::Operator => \"an operator\".to_string(),\n             TokenType::Lifetime => \"lifetime\".to_string(),\n@@ -413,8 +412,8 @@ fn can_continue_type_after_non_fn_ident(t: &token::Token) -> bool {\n \n /// Information about the path to a module.\n pub struct ModulePath {\n-    pub name: String,\n-    pub path_exists: bool,\n+    name: String,\n+    path_exists: bool,\n     pub result: Result<ModulePathSuccess, Error>,\n }\n \n@@ -424,11 +423,6 @@ pub struct ModulePathSuccess {\n     warn: bool,\n }\n \n-pub struct ModulePathError {\n-    pub err_msg: String,\n-    pub help_msg: String,\n-}\n-\n pub enum Error {\n     FileNotFoundForModule {\n         mod_name: String,\n@@ -446,7 +440,7 @@ pub enum Error {\n }\n \n impl Error {\n-    pub fn span_err<S: Into<MultiSpan>>(self,\n+    fn span_err<S: Into<MultiSpan>>(self,\n                                         sp: S,\n                                         handler: &errors::Handler) -> DiagnosticBuilder {\n         match self {\n@@ -489,7 +483,7 @@ impl Error {\n }\n \n #[derive(Debug)]\n-pub enum LhsExpr {\n+enum LhsExpr {\n     NotYetParsed,\n     AttributesParsed(ThinVec<Attribute>),\n     AlreadyParsed(P<Expr>),\n@@ -596,17 +590,12 @@ impl<'a> Parser<'a> {\n         next\n     }\n \n-    /// Convert a token to a string using self's reader\n-    pub fn token_to_string(token: &token::Token) -> String {\n-        pprust::token_to_string(token)\n-    }\n-\n     /// Convert the current token to a string using self's reader\n     pub fn this_token_to_string(&self) -> String {\n-        Parser::token_to_string(&self.token)\n+        pprust::token_to_string(&self.token)\n     }\n \n-    pub fn token_descr(&self) -> Option<&'static str> {\n+    fn token_descr(&self) -> Option<&'static str> {\n         Some(match &self.token {\n             t if t.is_special_ident() => \"reserved identifier\",\n             t if t.is_used_keyword() => \"keyword\",\n@@ -615,20 +604,20 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn this_token_descr(&self) -> String {\n+    fn this_token_descr(&self) -> String {\n         if let Some(prefix) = self.token_descr() {\n             format!(\"{} `{}`\", prefix, self.this_token_to_string())\n         } else {\n             format!(\"`{}`\", self.this_token_to_string())\n         }\n     }\n \n-    pub fn unexpected_last<T>(&self, t: &token::Token) -> PResult<'a, T> {\n-        let token_str = Parser::token_to_string(t);\n+    fn unexpected_last<T>(&self, t: &token::Token) -> PResult<'a, T> {\n+        let token_str = pprust::token_to_string(t);\n         Err(self.span_fatal(self.prev_span, &format!(\"unexpected token: `{}`\", token_str)))\n     }\n \n-    pub fn unexpected<T>(&mut self) -> PResult<'a, T> {\n+    crate fn unexpected<T>(&mut self) -> PResult<'a, T> {\n         match self.expect_one_of(&[], &[]) {\n             Err(e) => Err(e),\n             Ok(_) => unreachable!(),\n@@ -643,7 +632,7 @@ impl<'a> Parser<'a> {\n                 self.bump();\n                 Ok(())\n             } else {\n-                let token_str = Parser::token_to_string(t);\n+                let token_str = pprust::token_to_string(t);\n                 let this_token_str = self.this_token_to_string();\n                 let mut err = self.fatal(&format!(\"expected `{}`, found `{}`\",\n                                                   token_str,\n@@ -659,7 +648,7 @@ impl<'a> Parser<'a> {\n     /// Expect next token to be edible or inedible token.  If edible,\n     /// then consume it; if inedible, then return without consuming\n     /// anything.  Signal a fatal error if next token is unexpected.\n-    pub fn expect_one_of(&mut self,\n+    fn expect_one_of(&mut self,\n                          edible: &[token::Token],\n                          inedible: &[token::Token]) -> PResult<'a,  ()>{\n         fn tokens_to_string(tokens: &[TokenType]) -> String {\n@@ -771,7 +760,7 @@ impl<'a> Parser<'a> {\n         err\n     }\n \n-    pub fn parse_ident(&mut self) -> PResult<'a, ast::Ident> {\n+    fn parse_ident(&mut self) -> PResult<'a, ast::Ident> {\n         self.parse_ident_common(true)\n     }\n \n@@ -804,7 +793,7 @@ impl<'a> Parser<'a> {\n     ///\n     /// This method will automatically add `tok` to `expected_tokens` if `tok` is not\n     /// encountered.\n-    pub fn check(&mut self, tok: &token::Token) -> bool {\n+    fn check(&mut self, tok: &token::Token) -> bool {\n         let is_present = self.token == *tok;\n         if !is_present { self.expected_tokens.push(TokenType::Token(tok.clone())); }\n         is_present\n@@ -818,7 +807,7 @@ impl<'a> Parser<'a> {\n         is_present\n     }\n \n-    pub fn check_keyword(&mut self, kw: keywords::Keyword) -> bool {\n+    fn check_keyword(&mut self, kw: keywords::Keyword) -> bool {\n         self.expected_tokens.push(TokenType::Keyword(kw));\n         self.token.is_keyword(kw)\n     }\n@@ -834,7 +823,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn eat_keyword_noexpect(&mut self, kw: keywords::Keyword) -> bool {\n+    fn eat_keyword_noexpect(&mut self, kw: keywords::Keyword) -> bool {\n         if self.token.is_keyword(kw) {\n             self.bump();\n             true\n@@ -846,7 +835,7 @@ impl<'a> Parser<'a> {\n     /// If the given word is not a keyword, signal an error.\n     /// If the next token is not the given word, signal an error.\n     /// Otherwise, eat it.\n-    pub fn expect_keyword(&mut self, kw: keywords::Keyword) -> PResult<'a, ()> {\n+    fn expect_keyword(&mut self, kw: keywords::Keyword) -> PResult<'a, ()> {\n         if !self.eat_keyword(kw) {\n             self.unexpected()\n         } else {\n@@ -949,7 +938,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn expect_no_suffix(&self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n+    fn expect_no_suffix(&self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n         match suffix {\n             None => {/* everything ok */}\n             Some(suf) => {\n@@ -994,7 +983,7 @@ impl<'a> Parser<'a> {\n     /// Expect and consume a GT. if a >> is seen, replace it\n     /// with a single > and continue. If a GT is not seen,\n     /// signal an error.\n-    pub fn expect_gt(&mut self) -> PResult<'a, ()> {\n+    fn expect_gt(&mut self) -> PResult<'a, ()> {\n         self.expected_tokens.push(TokenType::Token(token::Gt));\n         match self.token {\n             token::Gt => {\n@@ -1017,83 +1006,9 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn parse_seq_to_before_gt_or_return<T, F>(&mut self,\n-                                                  sep: Option<token::Token>,\n-                                                  mut f: F)\n-                                                  -> PResult<'a, (Vec<T>, bool)>\n-        where F: FnMut(&mut Parser<'a>) -> PResult<'a, Option<T>>,\n-    {\n-        let mut v = Vec::new();\n-        // This loop works by alternating back and forth between parsing types\n-        // and commas.  For example, given a string `A, B,>`, the parser would\n-        // first parse `A`, then a comma, then `B`, then a comma. After that it\n-        // would encounter a `>` and stop. This lets the parser handle trailing\n-        // commas in generic parameters, because it can stop either after\n-        // parsing a type or after parsing a comma.\n-        for i in 0.. {\n-            if self.check(&token::Gt)\n-                || self.token == token::BinOp(token::Shr)\n-                || self.token == token::Ge\n-                || self.token == token::BinOpEq(token::Shr) {\n-                break;\n-            }\n-\n-            if i % 2 == 0 {\n-                match f(self)? {\n-                    Some(result) => v.push(result),\n-                    None => return Ok((v, true))\n-                }\n-            } else {\n-                if let Some(t) = sep.as_ref() {\n-                    self.expect(t)?;\n-                }\n-\n-            }\n-        }\n-        return Ok((v, false));\n-    }\n-\n-    /// Parse a sequence bracketed by '<' and '>', stopping\n-    /// before the '>'.\n-    pub fn parse_seq_to_before_gt<T, F>(&mut self,\n-                                        sep: Option<token::Token>,\n-                                        mut f: F)\n-                                        -> PResult<'a, Vec<T>> where\n-        F: FnMut(&mut Parser<'a>) -> PResult<'a, T>,\n-    {\n-        let (result, returned) = self.parse_seq_to_before_gt_or_return(sep,\n-                                                                       |p| Ok(Some(f(p)?)))?;\n-        assert!(!returned);\n-        return Ok(result);\n-    }\n-\n-    pub fn parse_seq_to_gt<T, F>(&mut self,\n-                                 sep: Option<token::Token>,\n-                                 f: F)\n-                                 -> PResult<'a, Vec<T>> where\n-        F: FnMut(&mut Parser<'a>) -> PResult<'a, T>,\n-    {\n-        let v = self.parse_seq_to_before_gt(sep, f)?;\n-        self.expect_gt()?;\n-        return Ok(v);\n-    }\n-\n-    pub fn parse_seq_to_gt_or_return<T, F>(&mut self,\n-                                           sep: Option<token::Token>,\n-                                           f: F)\n-                                           -> PResult<'a, (Vec<T>, bool)> where\n-        F: FnMut(&mut Parser<'a>) -> PResult<'a, Option<T>>,\n-    {\n-        let (v, returned) = self.parse_seq_to_before_gt_or_return(sep, f)?;\n-        if !returned {\n-            self.expect_gt()?;\n-        }\n-        return Ok((v, returned));\n-    }\n-\n     /// Eat and discard tokens until one of `kets` is encountered. Respects token trees,\n     /// passes through any errors encountered. Used for error recovery.\n-    pub fn eat_to_tokens(&mut self, kets: &[&token::Token]) {\n+    fn eat_to_tokens(&mut self, kets: &[&token::Token]) {\n         let handler = self.diagnostic();\n \n         if let Err(ref mut err) = self.parse_seq_to_before_tokens(kets,\n@@ -1107,7 +1022,7 @@ impl<'a> Parser<'a> {\n     /// Parse a sequence, including the closing delimiter. The function\n     /// f must consume tokens until reaching the next separator or\n     /// closing bracket.\n-    pub fn parse_seq_to_end<T, F>(&mut self,\n+    crate fn parse_seq_to_end<T, F>(&mut self,\n                                   ket: &token::Token,\n                                   sep: SeqSep,\n                                   f: F)\n@@ -1122,7 +1037,7 @@ impl<'a> Parser<'a> {\n     /// Parse a sequence, not including the closing delimiter. The function\n     /// f must consume tokens until reaching the next separator or\n     /// closing bracket.\n-    pub fn parse_seq_to_before_end<T, F>(&mut self,\n+    fn parse_seq_to_before_end<T, F>(&mut self,\n                                          ket: &token::Token,\n                                          sep: SeqSep,\n                                          f: F)\n@@ -1197,7 +1112,7 @@ impl<'a> Parser<'a> {\n     /// Parse a sequence, including the closing delimiter. The function\n     /// f must consume tokens until reaching the next separator or\n     /// closing bracket.\n-    pub fn parse_unspanned_seq<T, F>(&mut self,\n+    fn parse_unspanned_seq<T, F>(&mut self,\n                                      bra: &token::Token,\n                                      ket: &token::Token,\n                                      sep: SeqSep,\n@@ -1213,24 +1128,6 @@ impl<'a> Parser<'a> {\n         Ok(result)\n     }\n \n-    // NB: Do not use this function unless you actually plan to place the\n-    // spanned list in the AST.\n-    pub fn parse_seq<T, F>(&mut self,\n-                           bra: &token::Token,\n-                           ket: &token::Token,\n-                           sep: SeqSep,\n-                           f: F)\n-                           -> PResult<'a, Spanned<Vec<T>>> where\n-        F: FnMut(&mut Parser<'a>) -> PResult<'a, T>,\n-    {\n-        let lo = self.span;\n-        self.expect(bra)?;\n-        let result = self.parse_seq_to_before_end(ket, sep, f)?;\n-        let hi = self.span;\n-        self.bump();\n-        Ok(respan(lo.to(hi), result))\n-    }\n-\n     /// Advance the parser by one token\n     pub fn bump(&mut self) {\n         if self.prev_token_kind == PrevTokenKind::Eof {\n@@ -1261,7 +1158,7 @@ impl<'a> Parser<'a> {\n \n     /// Advance the parser using provided token as a next one. Use this when\n     /// consuming a part of a token. For example a single `<` from `<<`.\n-    pub fn bump_with(&mut self, next: token::Token, span: Span) {\n+    fn bump_with(&mut self, next: token::Token, span: Span) {\n         self.prev_span = self.span.with_hi(span.lo());\n         // It would be incorrect to record the kind of the current token, but\n         // fortunately for tokens currently using `bump_with`, the\n@@ -1301,65 +1198,54 @@ impl<'a> Parser<'a> {\n     pub fn fatal(&self, m: &str) -> DiagnosticBuilder<'a> {\n         self.sess.span_diagnostic.struct_span_fatal(self.span, m)\n     }\n-    pub fn span_fatal<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n+    fn span_fatal<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n         self.sess.span_diagnostic.struct_span_fatal(sp, m)\n     }\n-    pub fn span_fatal_err<S: Into<MultiSpan>>(&self, sp: S, err: Error) -> DiagnosticBuilder<'a> {\n+    fn span_fatal_err<S: Into<MultiSpan>>(&self, sp: S, err: Error) -> DiagnosticBuilder<'a> {\n         err.span_err(sp, self.diagnostic())\n     }\n-    pub fn span_fatal_help<S: Into<MultiSpan>>(&self,\n+    fn span_fatal_help<S: Into<MultiSpan>>(&self,\n                                             sp: S,\n                                             m: &str,\n                                             help: &str) -> DiagnosticBuilder<'a> {\n         let mut err = self.sess.span_diagnostic.struct_span_fatal(sp, m);\n         err.help(help);\n         err\n     }\n-    pub fn bug(&self, m: &str) -> ! {\n+    fn bug(&self, m: &str) -> ! {\n         self.sess.span_diagnostic.span_bug(self.span, m)\n     }\n-    pub fn warn(&self, m: &str) {\n-        self.sess.span_diagnostic.span_warn(self.span, m)\n-    }\n-    pub fn span_warn<S: Into<MultiSpan>>(&self, sp: S, m: &str) {\n-        self.sess.span_diagnostic.span_warn(sp, m)\n-    }\n-    pub fn span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) {\n+    fn span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) {\n         self.sess.span_diagnostic.span_err(sp, m)\n     }\n-    pub fn struct_span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n+    fn struct_span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n         self.sess.span_diagnostic.struct_span_err(sp, m)\n     }\n-    pub fn span_err_help<S: Into<MultiSpan>>(&self, sp: S, m: &str, h: &str) {\n-        let mut err = self.sess.span_diagnostic.mut_span_err(sp, m);\n-        err.help(h);\n-        err.emit();\n-    }\n-    pub fn span_bug<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> ! {\n+    crate fn span_bug<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> ! {\n         self.sess.span_diagnostic.span_bug(sp, m)\n     }\n-    pub fn abort_if_errors(&self) {\n+    crate fn abort_if_errors(&self) {\n         self.sess.span_diagnostic.abort_if_errors();\n     }\n \n     fn cancel(&self, err: &mut DiagnosticBuilder) {\n         self.sess.span_diagnostic.cancel(err)\n     }\n \n-    pub fn diagnostic(&self) -> &'a errors::Handler {\n+    crate fn diagnostic(&self) -> &'a errors::Handler {\n         &self.sess.span_diagnostic\n     }\n \n     /// Is the current token one of the keywords that signals a bare function\n     /// type?\n-    pub fn token_is_bare_fn_keyword(&mut self) -> bool {\n+    fn token_is_bare_fn_keyword(&mut self) -> bool {\n         self.check_keyword(keywords::Fn) ||\n             self.check_keyword(keywords::Unsafe) ||\n             self.check_keyword(keywords::Extern) && self.is_extern_non_path()\n     }\n \n     /// parse a TyKind::BareFn type:\n-    pub fn parse_ty_bare_fn(&mut self, generic_params: Vec<GenericParam>)\n+    fn parse_ty_bare_fn(&mut self, generic_params: Vec<GenericParam>)\n                             -> PResult<'a, TyKind> {\n         /*\n \n@@ -1786,7 +1672,7 @@ impl<'a> Parser<'a> {\n         return Ok(TyKind::Rptr(opt_lifetime, MutTy { ty: ty, mutbl: mutbl }));\n     }\n \n-    pub fn parse_ptr(&mut self) -> PResult<'a, MutTy> {\n+    fn parse_ptr(&mut self) -> PResult<'a, MutTy> {\n         let mutbl = if self.eat_keyword(keywords::Mut) {\n             Mutability::Mutable\n         } else if self.eat_keyword(keywords::Const) {\n@@ -1819,7 +1705,7 @@ impl<'a> Parser<'a> {\n \n     /// This version of parse arg doesn't necessarily require\n     /// identifier names.\n-    pub fn parse_arg_general(&mut self, require_name: bool) -> PResult<'a, Arg> {\n+    fn parse_arg_general(&mut self, require_name: bool) -> PResult<'a, Arg> {\n         maybe_whole!(self, NtArg, |x| x);\n \n         let (pat, ty) = if require_name || self.is_named_argument() {\n@@ -1849,12 +1735,12 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a single function argument\n-    pub fn parse_arg(&mut self) -> PResult<'a, Arg> {\n+    crate fn parse_arg(&mut self) -> PResult<'a, Arg> {\n         self.parse_arg_general(true)\n     }\n \n     /// Parse an argument in a lambda header e.g. |arg, arg|\n-    pub fn parse_fn_block_arg(&mut self) -> PResult<'a, Arg> {\n+    fn parse_fn_block_arg(&mut self) -> PResult<'a, Arg> {\n         let pat = self.parse_pat()?;\n         let t = if self.eat(&token::Colon) {\n             self.parse_ty()?\n@@ -1872,7 +1758,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn maybe_parse_fixed_length_of_vec(&mut self) -> PResult<'a, Option<P<ast::Expr>>> {\n+    fn maybe_parse_fixed_length_of_vec(&mut self) -> PResult<'a, Option<P<ast::Expr>>> {\n         if self.eat(&token::Semi) {\n             Ok(Some(self.parse_expr()?))\n         } else {\n@@ -1881,7 +1767,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Matches token_lit = LIT_INTEGER | ...\n-    pub fn parse_lit_token(&mut self) -> PResult<'a, LitKind> {\n+    fn parse_lit_token(&mut self) -> PResult<'a, LitKind> {\n         let out = match self.token {\n             token::Interpolated(ref nt) => match nt.0 {\n                 token::NtExpr(ref v) | token::NtLiteral(ref v) => match v.node {\n@@ -1909,7 +1795,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Matches lit = true | false | token_lit\n-    pub fn parse_lit(&mut self) -> PResult<'a, Lit> {\n+    crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n         let lo = self.span;\n         let lit = if self.eat_keyword(keywords::True) {\n             LitKind::Bool(true)\n@@ -1923,7 +1809,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// matches '-' lit | lit (cf. ast_validation::AstValidator::check_expr_within_pat)\n-    pub fn parse_literal_maybe_minus(&mut self) -> PResult<'a, P<Expr>> {\n+    crate fn parse_literal_maybe_minus(&mut self) -> PResult<'a, P<Expr>> {\n         maybe_whole_expr!(self);\n \n         let minus_lo = self.span;\n@@ -1942,7 +1828,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn parse_path_segment_ident(&mut self) -> PResult<'a, ast::Ident> {\n+    fn parse_path_segment_ident(&mut self) -> PResult<'a, ast::Ident> {\n         match self.token {\n             token::Ident(ident, _) if self.token.is_path_segment_keyword() => {\n                 let span = self.span;\n@@ -2000,11 +1886,11 @@ impl<'a> Parser<'a> {\n     /// `a::b::C::<D>` (with disambiguator)\n     /// `Fn(Args)` (without disambiguator)\n     /// `Fn::(Args)` (with disambiguator)\n-    pub fn parse_path(&mut self, style: PathStyle) -> PResult<'a, ast::Path> {\n+    crate fn parse_path(&mut self, style: PathStyle) -> PResult<'a, ast::Path> {\n         self.parse_path_common(style, true)\n     }\n \n-    pub fn parse_path_common(&mut self, style: PathStyle, enable_warning: bool)\n+    crate fn parse_path_common(&mut self, style: PathStyle, enable_warning: bool)\n                              -> PResult<'a, ast::Path> {\n         maybe_whole!(self, NtPath, |path| {\n             if style == PathStyle::Mod &&\n@@ -2114,13 +2000,13 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn check_lifetime(&mut self) -> bool {\n+    crate fn check_lifetime(&mut self) -> bool {\n         self.expected_tokens.push(TokenType::Lifetime);\n         self.token.is_lifetime()\n     }\n \n     /// Parse single lifetime 'a or panic.\n-    pub fn expect_lifetime(&mut self) -> Lifetime {\n+    crate fn expect_lifetime(&mut self) -> Lifetime {\n         if let Some(ident) = self.token.lifetime() {\n             let span = self.span;\n             self.bump();\n@@ -2149,7 +2035,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n+    fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n         if let token::Literal(token::Integer(name), None) = self.token {\n             self.bump();\n             Ok(Ident::new(name, self.prev_span))\n@@ -2159,7 +2045,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse ident (COLON expr)?\n-    pub fn parse_field(&mut self) -> PResult<'a, Field> {\n+    fn parse_field(&mut self) -> PResult<'a, Field> {\n         let attrs = self.parse_outer_attributes()?;\n         let lo = self.span;\n \n@@ -2185,27 +2071,27 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn mk_expr(&mut self, span: Span, node: ExprKind, attrs: ThinVec<Attribute>) -> P<Expr> {\n+    fn mk_expr(&mut self, span: Span, node: ExprKind, attrs: ThinVec<Attribute>) -> P<Expr> {\n         P(Expr { node, span, attrs, id: ast::DUMMY_NODE_ID })\n     }\n \n-    pub fn mk_unary(&mut self, unop: ast::UnOp, expr: P<Expr>) -> ast::ExprKind {\n+    fn mk_unary(&mut self, unop: ast::UnOp, expr: P<Expr>) -> ast::ExprKind {\n         ExprKind::Unary(unop, expr)\n     }\n \n-    pub fn mk_binary(&mut self, binop: ast::BinOp, lhs: P<Expr>, rhs: P<Expr>) -> ast::ExprKind {\n+    fn mk_binary(&mut self, binop: ast::BinOp, lhs: P<Expr>, rhs: P<Expr>) -> ast::ExprKind {\n         ExprKind::Binary(binop, lhs, rhs)\n     }\n \n-    pub fn mk_call(&mut self, f: P<Expr>, args: Vec<P<Expr>>) -> ast::ExprKind {\n+    fn mk_call(&mut self, f: P<Expr>, args: Vec<P<Expr>>) -> ast::ExprKind {\n         ExprKind::Call(f, args)\n     }\n \n-    pub fn mk_index(&mut self, expr: P<Expr>, idx: P<Expr>) -> ast::ExprKind {\n+    fn mk_index(&mut self, expr: P<Expr>, idx: P<Expr>) -> ast::ExprKind {\n         ExprKind::Index(expr, idx)\n     }\n \n-    pub fn mk_range(&mut self,\n+    fn mk_range(&mut self,\n                     start: Option<P<Expr>>,\n                     end: Option<P<Expr>>,\n                     limits: RangeLimits)\n@@ -2217,12 +2103,12 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn mk_assign_op(&mut self, binop: ast::BinOp,\n+    fn mk_assign_op(&mut self, binop: ast::BinOp,\n                         lhs: P<Expr>, rhs: P<Expr>) -> ast::ExprKind {\n         ExprKind::AssignOp(binop, lhs, rhs)\n     }\n \n-    pub fn mk_mac_expr(&mut self, span: Span, m: Mac_, attrs: ThinVec<Attribute>) -> P<Expr> {\n+    fn mk_mac_expr(&mut self, span: Span, m: Mac_, attrs: ThinVec<Attribute>) -> P<Expr> {\n         P(Expr {\n             id: ast::DUMMY_NODE_ID,\n             node: ExprKind::Mac(codemap::Spanned {node: m, span: span}),\n@@ -2231,21 +2117,6 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn mk_lit_u32(&mut self, i: u32, attrs: ThinVec<Attribute>) -> P<Expr> {\n-        let span = &self.span;\n-        let lv_lit = P(codemap::Spanned {\n-            node: LitKind::Int(i as u128, ast::LitIntType::Unsigned(UintTy::U32)),\n-            span: *span\n-        });\n-\n-        P(Expr {\n-            id: ast::DUMMY_NODE_ID,\n-            node: ExprKind::Lit(lv_lit),\n-            span: *span,\n-            attrs,\n-        })\n-    }\n-\n     fn expect_delimited_token_tree(&mut self) -> PResult<'a, (MacDelimiter, ThinTokenStream)> {\n         let delim = match self.token {\n             token::OpenDelim(delim) => delim,\n@@ -2598,7 +2469,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a block or unsafe block\n-    pub fn parse_block_expr(&mut self, opt_label: Option<Label>,\n+    fn parse_block_expr(&mut self, opt_label: Option<Label>,\n                             lo: Span, blk_mode: BlockCheckMode,\n                             outer_attrs: ThinVec<Attribute>)\n                             -> PResult<'a, P<Expr>> {\n@@ -2612,7 +2483,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// parse a.b or a(13) or a[4] or just a\n-    pub fn parse_dot_or_call_expr(&mut self,\n+    fn parse_dot_or_call_expr(&mut self,\n                                   already_parsed_attrs: Option<ThinVec<Attribute>>)\n                                   -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(already_parsed_attrs)?;\n@@ -2622,7 +2493,7 @@ impl<'a> Parser<'a> {\n         self.parse_dot_or_call_expr_with(b, span, attrs)\n     }\n \n-    pub fn parse_dot_or_call_expr_with(&mut self,\n+    fn parse_dot_or_call_expr_with(&mut self,\n                                        e0: P<Expr>,\n                                        lo: Span,\n                                        mut attrs: ThinVec<Attribute>)\n@@ -2776,7 +2647,7 @@ impl<'a> Parser<'a> {\n         return Ok(e);\n     }\n \n-    pub fn process_potential_macro_variable(&mut self) {\n+    crate fn process_potential_macro_variable(&mut self) {\n         let (token, span) = match self.token {\n             token::Dollar if self.span.ctxt() != syntax_pos::hygiene::SyntaxContext::empty() &&\n                              self.look_ahead(1, |t| t.is_ident()) => {\n@@ -2807,7 +2678,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// parse a single token tree from the input.\n-    pub fn parse_token_tree(&mut self) -> TokenTree {\n+    crate fn parse_token_tree(&mut self) -> TokenTree {\n         match self.token {\n             token::OpenDelim(..) => {\n                 let frame = mem::replace(&mut self.token_cursor.frame,\n@@ -2850,7 +2721,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a prefix-unary-operator expr\n-    pub fn parse_prefix_expr(&mut self,\n+    fn parse_prefix_expr(&mut self,\n                              already_parsed_attrs: Option<ThinVec<Attribute>>)\n                              -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(already_parsed_attrs)?;\n@@ -2969,14 +2840,14 @@ impl<'a> Parser<'a> {\n     ///\n     /// This parses an expression accounting for associativity and precedence of the operators in\n     /// the expression.\n-    pub fn parse_assoc_expr(&mut self,\n+    fn parse_assoc_expr(&mut self,\n                             already_parsed_attrs: Option<ThinVec<Attribute>>)\n                             -> PResult<'a, P<Expr>> {\n         self.parse_assoc_expr_with(0, already_parsed_attrs.into())\n     }\n \n     /// Parse an associative expression with operators of at least `min_prec` precedence\n-    pub fn parse_assoc_expr_with(&mut self,\n+    fn parse_assoc_expr_with(&mut self,\n                                  min_prec: usize,\n                                  lhs: LhsExpr)\n                                  -> PResult<'a, P<Expr>> {\n@@ -3305,7 +3176,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse an 'if' or 'if let' expression ('if' token already eaten)\n-    pub fn parse_if_expr(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n+    fn parse_if_expr(&mut self, attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         if self.check_keyword(keywords::Let) {\n             return self.parse_if_let_expr(attrs);\n         }\n@@ -3341,7 +3212,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse an 'if let' expression ('if' token already eaten)\n-    pub fn parse_if_let_expr(&mut self, attrs: ThinVec<Attribute>)\n+    fn parse_if_let_expr(&mut self, attrs: ThinVec<Attribute>)\n                              -> PResult<'a, P<Expr>> {\n         let lo = self.prev_span;\n         self.expect_keyword(keywords::Let)?;\n@@ -3359,7 +3230,7 @@ impl<'a> Parser<'a> {\n     }\n \n     // `move |args| expr`\n-    pub fn parse_lambda_expr(&mut self,\n+    fn parse_lambda_expr(&mut self,\n                              attrs: ThinVec<Attribute>)\n                              -> PResult<'a, P<Expr>>\n     {\n@@ -3396,7 +3267,7 @@ impl<'a> Parser<'a> {\n     }\n \n     // `else` token already eaten\n-    pub fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n+    fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n         if self.eat_keyword(keywords::If) {\n             return self.parse_if_expr(ThinVec::new());\n         } else {\n@@ -3406,7 +3277,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a 'for' .. 'in' expression ('for' token already eaten)\n-    pub fn parse_for_expr(&mut self, opt_label: Option<Label>,\n+    fn parse_for_expr(&mut self, opt_label: Option<Label>,\n                           span_lo: Span,\n                           mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         // Parse: `for <src_pat> in <src_expr> <src_loop_block>`\n@@ -3432,7 +3303,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a 'while' or 'while let' expression ('while' token already eaten)\n-    pub fn parse_while_expr(&mut self, opt_label: Option<Label>,\n+    fn parse_while_expr(&mut self, opt_label: Option<Label>,\n                             span_lo: Span,\n                             mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         if self.token.is_keyword(keywords::Let) {\n@@ -3446,7 +3317,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a 'while let' expression ('while' token already eaten)\n-    pub fn parse_while_let_expr(&mut self, opt_label: Option<Label>,\n+    fn parse_while_let_expr(&mut self, opt_label: Option<Label>,\n                                 span_lo: Span,\n                                 mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         self.expect_keyword(keywords::Let)?;\n@@ -3460,7 +3331,7 @@ impl<'a> Parser<'a> {\n     }\n \n     // parse `loop {...}`, `loop` token already eaten\n-    pub fn parse_loop_expr(&mut self, opt_label: Option<Label>,\n+    fn parse_loop_expr(&mut self, opt_label: Option<Label>,\n                            span_lo: Span,\n                            mut attrs: ThinVec<Attribute>) -> PResult<'a, P<Expr>> {\n         let (iattrs, body) = self.parse_inner_attrs_and_block()?;\n@@ -3470,7 +3341,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a `do catch {...}` expression (`do catch` token already eaten)\n-    pub fn parse_catch_expr(&mut self, span_lo: Span, mut attrs: ThinVec<Attribute>)\n+    fn parse_catch_expr(&mut self, span_lo: Span, mut attrs: ThinVec<Attribute>)\n         -> PResult<'a, P<Expr>>\n     {\n         let (iattrs, body) = self.parse_inner_attrs_and_block()?;\n@@ -3518,7 +3389,7 @@ impl<'a> Parser<'a> {\n         return Ok(self.mk_expr(lo.to(hi), ExprKind::Match(discriminant, arms), attrs));\n     }\n \n-    pub fn parse_arm(&mut self) -> PResult<'a, Arm> {\n+    crate fn parse_arm(&mut self) -> PResult<'a, Arm> {\n         maybe_whole!(self, NtArm, |x| x);\n \n         let attrs = self.parse_outer_attributes()?;\n@@ -3597,7 +3468,7 @@ impl<'a> Parser<'a> {\n     /// Evaluate the closure with restrictions in place.\n     ///\n     /// After the closure is evaluated, restrictions are reset.\n-    pub fn with_res<F, T>(&mut self, r: Restrictions, f: F) -> T\n+    fn with_res<F, T>(&mut self, r: Restrictions, f: F) -> T\n         where F: FnOnce(&mut Self) -> T\n     {\n         let old = self.restrictions;\n@@ -3609,7 +3480,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse an expression, subject to the given restrictions\n-    pub fn parse_expr_res(&mut self, r: Restrictions,\n+    fn parse_expr_res(&mut self, r: Restrictions,\n                           already_parsed_attrs: Option<ThinVec<Attribute>>)\n                           -> PResult<'a, P<Expr>> {\n         self.with_res(r, |this| this.parse_assoc_expr(already_parsed_attrs))\n@@ -3953,7 +3824,7 @@ impl<'a> Parser<'a> {\n     /// A wrapper around `parse_pat` with some special error handling for the\n     /// \"top-level\" patterns in a match arm, `for` loop, `let`, &c. (in contast\n     /// to subpatterns within such).\n-    pub fn parse_top_level_pat(&mut self) -> PResult<'a, P<Pat>> {\n+    fn parse_top_level_pat(&mut self) -> PResult<'a, P<Pat>> {\n         let pat = self.parse_pat()?;\n         if self.token == token::Comma {\n             // An unexpected comma after a top-level pattern is a clue that the\n@@ -4701,7 +4572,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a block. No inner attrs are allowed.\n-    pub fn parse_block(&mut self) -> PResult<'a, P<Block>> {\n+    crate fn parse_block(&mut self) -> PResult<'a, P<Block>> {\n         maybe_whole!(self, NtBlock, |x| x);\n \n         let lo = self.span;\n@@ -4802,7 +4673,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a statement, including the trailing semicolon.\n-    pub fn parse_full_stmt(&mut self, macro_legacy_warnings: bool) -> PResult<'a, Option<Stmt>> {\n+    crate fn parse_full_stmt(&mut self, macro_legacy_warnings: bool) -> PResult<'a, Option<Stmt>> {\n         // skip looking for a trailing semicolon when we have an interpolated statement\n         maybe_whole!(self, NtStmt, |x| Some(x));\n \n@@ -4991,7 +4862,7 @@ impl<'a> Parser<'a> {\n \n     /// Parses (possibly empty) list of lifetime and type parameters, possibly including\n     /// trailing comma and erroneous trailing attributes.\n-    pub fn parse_generic_params(&mut self) -> PResult<'a, Vec<ast::GenericParam>> {\n+    crate fn parse_generic_params(&mut self) -> PResult<'a, Vec<ast::GenericParam>> {\n         let mut params = Vec::new();\n         let mut seen_ty_param = false;\n         loop {\n@@ -5041,7 +4912,7 @@ impl<'a> Parser<'a> {\n     /// matches generics = ( ) | ( < > ) | ( < typaramseq ( , )? > ) | ( < lifetimes ( , )? > )\n     ///                  | ( < lifetimes , typaramseq ( , )? > )\n     /// where   typaramseq = ( typaram ) | ( typaram , typaramseq )\n-    pub fn parse_generics(&mut self) -> PResult<'a, ast::Generics> {\n+    fn parse_generics(&mut self) -> PResult<'a, ast::Generics> {\n         maybe_whole!(self, NtGenerics, |x| x);\n \n         let span_lo = self.span;\n@@ -5115,7 +4986,7 @@ impl<'a> Parser<'a> {\n     /// ```ignore (only-for-syntax-highlight)\n     /// where T : Trait<U, V> + 'b, 'a : 'b\n     /// ```\n-    pub fn parse_where_clause(&mut self) -> PResult<'a, WhereClause> {\n+    fn parse_where_clause(&mut self) -> PResult<'a, WhereClause> {\n         maybe_whole!(self, NtWhereClause, |x| x);\n \n         let mut where_clause = WhereClause {\n@@ -5266,7 +5137,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse the argument list and result type of a function declaration\n-    pub fn parse_fn_decl(&mut self, allow_variadic: bool) -> PResult<'a, P<FnDecl>> {\n+    fn parse_fn_decl(&mut self, allow_variadic: bool) -> PResult<'a, P<FnDecl>> {\n \n         let (args, variadic) = self.parse_fn_args(true, allow_variadic)?;\n         let ret_ty = self.parse_ret_ty(true)?;\n@@ -5478,7 +5349,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// true if we are looking at `const ID`, false for things like `const fn` etc\n-    pub fn is_const_item(&mut self) -> bool {\n+    fn is_const_item(&mut self) -> bool {\n         self.token.is_keyword(keywords::Const) &&\n             !self.look_ahead(1, |t| t.is_keyword(keywords::Fn)) &&\n             !self.look_ahead(1, |t| t.is_keyword(keywords::Unsafe))\n@@ -5492,7 +5363,7 @@ impl<'a> Parser<'a> {\n     /// - `const unsafe fn`\n     /// - `extern fn`\n     /// - etc\n-    pub fn parse_fn_front_matter(&mut self) -> PResult<'a, (Spanned<Constness>, Unsafety, Abi)> {\n+    fn parse_fn_front_matter(&mut self) -> PResult<'a, (Spanned<Constness>, Unsafety, Abi)> {\n         let is_const_fn = self.eat_keyword(keywords::Const);\n         let const_span = self.prev_span;\n         let unsafety = self.parse_unsafety();\n@@ -5511,7 +5382,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse an impl item.\n-    pub fn parse_impl_item(&mut self, at_end: &mut bool) -> PResult<'a, ImplItem> {\n+    crate fn parse_impl_item(&mut self, at_end: &mut bool) -> PResult<'a, ImplItem> {\n         maybe_whole!(self, NtImplItem, |x| x);\n         let attrs = self.parse_outer_attributes()?;\n         let (mut item, tokens) = self.collect_tokens(|this| {\n@@ -5931,7 +5802,7 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn parse_record_struct_body(&mut self) -> PResult<'a, Vec<StructField>> {\n+    fn parse_record_struct_body(&mut self) -> PResult<'a, Vec<StructField>> {\n         let mut fields = Vec::new();\n         if self.eat(&token::OpenDelim(token::Brace)) {\n             while self.token != token::CloseDelim(token::Brace) {\n@@ -5958,7 +5829,7 @@ impl<'a> Parser<'a> {\n         Ok(fields)\n     }\n \n-    pub fn parse_tuple_struct_body(&mut self) -> PResult<'a, Vec<StructField>> {\n+    fn parse_tuple_struct_body(&mut self) -> PResult<'a, Vec<StructField>> {\n         // This is the case where we find `struct Foo<T>(T) where T: Copy;`\n         // Unit like structs are handled in parse_item_struct function\n         let fields = self.parse_unspanned_seq(\n@@ -5984,7 +5855,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a structure field declaration\n-    pub fn parse_single_struct_field(&mut self,\n+    fn parse_single_struct_field(&mut self,\n                                      lo: Span,\n                                      vis: Visibility,\n                                      attrs: Vec<Attribute> )\n@@ -7026,7 +6897,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parse a foreign item.\n-    pub fn parse_foreign_item(&mut self) -> PResult<'a, Option<ForeignItem>> {\n+    crate fn parse_foreign_item(&mut self) -> PResult<'a, Option<ForeignItem>> {\n         maybe_whole!(self, NtForeignItem, |ni| Some(ni));\n \n         let attrs = self.parse_outer_attributes()?;\n@@ -7328,7 +7199,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    pub fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n+    fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n         let ret = match self.token {\n             token::Literal(token::Str_(s), suf) => (s, ast::StrStyle::Cooked, suf),\n             token::Literal(token::StrRaw(s, n), suf) => (s, ast::StrStyle::Raw(n), suf),"}, {"sha": "7ea047d332b21454e90ec02ff323cabac24be67a", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 21, "deletions": 45, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=ae0659c97d33eb4d9c84e0ec6a66b81a9e35ef1c", "patch": "@@ -80,7 +80,7 @@ pub enum Lit {\n }\n \n impl Lit {\n-    pub fn short_name(&self) -> &'static str {\n+    crate fn short_name(&self) -> &'static str {\n         match *self {\n             Byte(_) => \"byte\",\n             Char(_) => \"char\",\n@@ -217,23 +217,15 @@ impl Token {\n         Ident(ident, ident.is_raw_guess())\n     }\n \n-    /// Returns `true` if the token starts with '>'.\n-    pub fn is_like_gt(&self) -> bool {\n-        match *self {\n-            BinOp(Shr) | BinOpEq(Shr) | Gt | Ge => true,\n-            _ => false,\n-        }\n-    }\n-\n-    pub fn is_like_plus(&self) -> bool {\n+    crate fn is_like_plus(&self) -> bool {\n         match *self {\n             BinOp(Plus) | BinOpEq(Plus) => true,\n             _ => false,\n         }\n     }\n \n     /// Returns `true` if the token can appear at the start of an expression.\n-    pub fn can_begin_expr(&self) -> bool {\n+    crate fn can_begin_expr(&self) -> bool {\n         match *self {\n             Ident(ident, is_raw)              =>\n                 ident_can_begin_expr(ident, is_raw), // value name or keyword\n@@ -265,7 +257,7 @@ impl Token {\n     }\n \n     /// Returns `true` if the token can appear at the start of a type.\n-    pub fn can_begin_type(&self) -> bool {\n+    crate fn can_begin_type(&self) -> bool {\n         match *self {\n             Ident(ident, is_raw)        =>\n                 ident_can_begin_type(ident, is_raw), // type name or keyword\n@@ -288,13 +280,13 @@ impl Token {\n     }\n \n     /// Returns `true` if the token can appear at the start of a generic bound.\n-    pub fn can_begin_bound(&self) -> bool {\n+    crate fn can_begin_bound(&self) -> bool {\n         self.is_path_start() || self.is_lifetime() || self.is_keyword(keywords::For) ||\n         self == &Question || self == &OpenDelim(Paren)\n     }\n \n     /// Returns `true` if the token is any literal\n-    pub fn is_lit(&self) -> bool {\n+    crate fn is_lit(&self) -> bool {\n         match *self {\n             Literal(..) => true,\n             _           => false,\n@@ -303,7 +295,7 @@ impl Token {\n \n     /// Returns `true` if the token is any literal, a minus (which can follow a literal,\n     /// for example a '-42', or one of the boolean idents).\n-    pub fn can_begin_literal_or_bool(&self) -> bool {\n+    crate fn can_begin_literal_or_bool(&self) -> bool {\n         match *self {\n             Literal(..)  => true,\n             BinOp(Minus) => true,\n@@ -340,37 +332,21 @@ impl Token {\n         self.ident().is_some()\n     }\n     /// Returns `true` if the token is a lifetime.\n-    pub fn is_lifetime(&self) -> bool {\n+    crate fn is_lifetime(&self) -> bool {\n         self.lifetime().is_some()\n     }\n \n     /// Returns `true` if the token is a identifier whose name is the given\n     /// string slice.\n-    pub fn is_ident_named(&self, name: &str) -> bool {\n+    crate fn is_ident_named(&self, name: &str) -> bool {\n         match self.ident() {\n             Some((ident, _)) => ident.as_str() == name,\n             None => false\n         }\n     }\n \n-    /// Returns `true` if the token is a documentation comment.\n-    pub fn is_doc_comment(&self) -> bool {\n-        match *self {\n-            DocComment(..)   => true,\n-            _                => false,\n-        }\n-    }\n-\n-    /// Returns `true` if the token is interpolated.\n-    pub fn is_interpolated(&self) -> bool {\n-        match *self {\n-            Interpolated(..) => true,\n-            _                => false,\n-        }\n-    }\n-\n     /// Returns `true` if the token is an interpolated path.\n-    pub fn is_path(&self) -> bool {\n+    fn is_path(&self) -> bool {\n         if let Interpolated(ref nt) = *self {\n             if let NtPath(..) = nt.0 {\n                 return true;\n@@ -380,16 +356,16 @@ impl Token {\n     }\n \n     /// Returns `true` if the token is either the `mut` or `const` keyword.\n-    pub fn is_mutability(&self) -> bool {\n+    crate fn is_mutability(&self) -> bool {\n         self.is_keyword(keywords::Mut) ||\n         self.is_keyword(keywords::Const)\n     }\n \n-    pub fn is_qpath_start(&self) -> bool {\n+    crate fn is_qpath_start(&self) -> bool {\n         self == &Lt || self == &BinOp(Shl)\n     }\n \n-    pub fn is_path_start(&self) -> bool {\n+    crate fn is_path_start(&self) -> bool {\n         self == &ModSep || self.is_qpath_start() || self.is_path() ||\n         self.is_path_segment_keyword() || self.is_ident() && !self.is_reserved_ident()\n     }\n@@ -416,15 +392,15 @@ impl Token {\n     }\n \n     /// Returns `true` if the token is a keyword used in the language.\n-    pub fn is_used_keyword(&self) -> bool {\n+    crate fn is_used_keyword(&self) -> bool {\n         match self.ident() {\n             Some((id, false)) => id.is_used_keyword(),\n             _ => false,\n         }\n     }\n \n     /// Returns `true` if the token is a keyword reserved for possible future use.\n-    pub fn is_unused_keyword(&self) -> bool {\n+    crate fn is_unused_keyword(&self) -> bool {\n         match self.ident() {\n             Some((id, false)) => id.is_unused_keyword(),\n             _ => false,\n@@ -439,7 +415,7 @@ impl Token {\n         }\n     }\n \n-    pub fn glue(self, joint: Token) -> Option<Token> {\n+    crate fn glue(self, joint: Token) -> Option<Token> {\n         Some(match self {\n             Eq => match joint {\n                 Eq => EqEq,\n@@ -507,7 +483,7 @@ impl Token {\n \n     /// Returns tokens that are likely to be typed accidentally instead of the current token.\n     /// Enables better error recovery when the wrong token is found.\n-    pub fn similar_tokens(&self) -> Option<Vec<Token>> {\n+    crate fn similar_tokens(&self) -> Option<Vec<Token>> {\n         match *self {\n             Comma => Some(vec![Dot, Lt]),\n             Semi => Some(vec![Colon]),\n@@ -603,7 +579,7 @@ impl Token {\n \n     // See comments in `interpolated_to_tokenstream` for why we care about\n     // *probably* equal here rather than actual equality\n-    pub fn probably_equal_for_proc_macro(&self, other: &Token) -> bool {\n+    crate fn probably_equal_for_proc_macro(&self, other: &Token) -> bool {\n         if mem::discriminant(self) != mem::discriminant(other) {\n             return false\n         }\n@@ -732,7 +708,7 @@ impl fmt::Debug for Nonterminal {\n     }\n }\n \n-pub fn is_op(tok: &Token) -> bool {\n+crate fn is_op(tok: &Token) -> bool {\n     match *tok {\n         OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) |\n         Ident(..) | Lifetime(..) | Interpolated(..) |\n@@ -758,11 +734,11 @@ impl fmt::Debug for LazyTokenStream {\n }\n \n impl LazyTokenStream {\n-    pub fn new() -> Self {\n+    fn new() -> Self {\n         LazyTokenStream(Lock::new(None))\n     }\n \n-    pub fn force<F: FnOnce() -> TokenStream>(&self, f: F) -> TokenStream {\n+    fn force<F: FnOnce() -> TokenStream>(&self, f: F) -> TokenStream {\n         let mut opt_stream = self.0.lock();\n         if opt_stream.is_none() {\n             *opt_stream = Some(f());"}]}