{"sha": "5f52a516dedeab16ede8c26807c4ff79b3d308d3", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVmNTJhNTE2ZGVkZWFiMTZlZGU4YzI2ODA3YzRmZjc5YjNkMzA4ZDM=", "commit": {"author": {"name": "Zac Pullar-Strecker", "email": "zacmps@gmail.com", "date": "2020-06-12T03:02:48Z"}, "committer": {"name": "Zac Pullar-Strecker", "email": "zacmps@gmail.com", "date": "2020-06-30T08:02:47Z"}, "message": "Working intra-doc-links", "tree": {"sha": "a3a061ee2b2c5ceadae741d2c695fcebb25f16e9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a3a061ee2b2c5ceadae741d2c695fcebb25f16e9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5f52a516dedeab16ede8c26807c4ff79b3d308d3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5f52a516dedeab16ede8c26807c4ff79b3d308d3", "html_url": "https://github.com/rust-lang/rust/commit/5f52a516dedeab16ede8c26807c4ff79b3d308d3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5f52a516dedeab16ede8c26807c4ff79b3d308d3/comments", "author": {"login": "zacps", "id": 9827696, "node_id": "MDQ6VXNlcjk4Mjc2OTY=", "avatar_url": "https://avatars.githubusercontent.com/u/9827696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zacps", "html_url": "https://github.com/zacps", "followers_url": "https://api.github.com/users/zacps/followers", "following_url": "https://api.github.com/users/zacps/following{/other_user}", "gists_url": "https://api.github.com/users/zacps/gists{/gist_id}", "starred_url": "https://api.github.com/users/zacps/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zacps/subscriptions", "organizations_url": "https://api.github.com/users/zacps/orgs", "repos_url": "https://api.github.com/users/zacps/repos", "events_url": "https://api.github.com/users/zacps/events{/privacy}", "received_events_url": "https://api.github.com/users/zacps/received_events", "type": "User", "site_admin": false}, "committer": {"login": "zacps", "id": 9827696, "node_id": "MDQ6VXNlcjk4Mjc2OTY=", "avatar_url": "https://avatars.githubusercontent.com/u/9827696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zacps", "html_url": "https://github.com/zacps", "followers_url": "https://api.github.com/users/zacps/followers", "following_url": "https://api.github.com/users/zacps/following{/other_user}", "gists_url": "https://api.github.com/users/zacps/gists{/gist_id}", "starred_url": "https://api.github.com/users/zacps/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zacps/subscriptions", "organizations_url": "https://api.github.com/users/zacps/orgs", "repos_url": "https://api.github.com/users/zacps/repos", "events_url": "https://api.github.com/users/zacps/events{/privacy}", "received_events_url": "https://api.github.com/users/zacps/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8f56e7c3b1220ed0b065e97a9061e59284ac1df1", "url": "https://api.github.com/repos/rust-lang/rust/commits/8f56e7c3b1220ed0b065e97a9061e59284ac1df1", "html_url": "https://github.com/rust-lang/rust/commit/8f56e7c3b1220ed0b065e97a9061e59284ac1df1"}], "stats": {"total": 127, "additions": 119, "deletions": 8}, "files": [{"sha": "be97c16ff2b63b72899567d9d15966780088d0cd", "filename": "Cargo.lock", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5f52a516dedeab16ede8c26807c4ff79b3d308d3/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/5f52a516dedeab16ede8c26807c4ff79b3d308d3/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=5f52a516dedeab16ede8c26807c4ff79b3d308d3", "patch": "@@ -1270,6 +1270,7 @@ dependencies = [\n  \"insta\",\n  \"itertools\",\n  \"log\",\n+ \"maplit\",\n  \"ra_assists\",\n  \"ra_cfg\",\n  \"ra_db\",\n@@ -1278,6 +1279,7 @@ dependencies = [\n  \"ra_hir_def\",\n  \"ra_hir_expand\",\n  \"ra_ide_db\",\n+ \"ra_parser\",\n  \"ra_prof\",\n  \"ra_project_model\",\n  \"ra_ssr\","}, {"sha": "1bc095c5b89963532b9938504f54619aa80d23b9", "filename": "crates/ra_ide/Cargo.toml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_ide%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_ide%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2FCargo.toml?ref=5f52a516dedeab16ede8c26807c4ff79b3d308d3", "patch": "@@ -19,6 +19,7 @@ rustc-hash = \"1.1.0\"\n rand = { version = \"0.7.3\", features = [\"small_rng\"] }\n comrak = \"0.7.0\"\n url = \"*\"\n+maplit = \"*\"\n \n stdx = { path = \"../stdx\" }\n \n@@ -36,6 +37,7 @@ ra_project_model = { path = \"../ra_project_model\" }\n ra_hir_def = { path = \"../ra_hir_def\" }\n ra_tt = { path = \"../ra_tt\" }\n ra_hir_expand = { path = \"../ra_hir_expand\" }\n+ra_parser = { path = \"../ra_parser\" }\n \n # ra_ide should depend only on the top-level `hir` package. if you need\n # something from some `hir_xxx` subpackage, reexport the API via `hir`."}, {"sha": "f4b10deacead12c07597484aef18aac8f9a8b637", "filename": "crates/ra_ide/src/hover.rs", "status": "modified", "additions": 113, "deletions": 6, "changes": 119, "blob_url": "https://github.com/rust-lang/rust/blob/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_ide%2Fsrc%2Fhover.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_ide%2Fsrc%2Fhover.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fhover.rs?ref=5f52a516dedeab16ede8c26807c4ff79b3d308d3", "patch": "@@ -4,19 +4,21 @@ use std::sync::Arc;\n \n use hir::{\n     Adt, AsAssocItem, AssocItemContainer, FieldSource, HasSource, HirDisplay, ModuleDef,\n-    ModuleSource, Semantics, Documentation, AttrDef, Crate\n+    ModuleSource, Semantics, Documentation, AttrDef, Crate, GenericDef, ModPath, Hygiene\n };\n use itertools::Itertools;\n use ra_db::SourceDatabase;\n use ra_ide_db::{\n     defs::{classify_name, classify_name_ref, Definition},\n     RootDatabase,\n };\n-use ra_syntax::{ast, match_ast, AstNode, SyntaxKind::*, SyntaxToken, TokenAtOffset};\n+use ra_syntax::{ast, match_ast, AstNode, SyntaxKind::*, SyntaxToken, SyntaxNode, TokenAtOffset, ast::Path};\n use ra_project_model::ProjectWorkspace;\n-use ra_hir_def::{item_scope::ItemInNs, db::DefDatabase};\n+use ra_hir_def::{item_scope::ItemInNs, db::DefDatabase, GenericDefId, ModuleId, resolver::HasResolver};\n use ra_tt::{Literal, Ident, Punct, TokenTree, Leaf};\n use ra_hir_expand::name::AsName;\n+use ra_parser::FragmentKind;\n+use maplit::{hashset, hashmap};\n \n use comrak::{parse_document,format_commonmark, ComrakOptions, Arena};\n use comrak::nodes::NodeValue;\n@@ -412,8 +414,9 @@ fn rewrite_links(db: &RootDatabase, markdown: &str, definition: &Definition, wor\n                     // module-based links (AKA intra-doc links): `super::super::module::MyStruct`\n                     Err(_) => {\n                         let link_str = String::from_utf8(link.url.clone()).unwrap();\n+                        let link_text = String::from_utf8(link.title.clone()).unwrap();\n                         let resolved = try_resolve_path(db, &mut doc_target_dirs.clone(), definition, &link_str, UrlMode::Url)\n-                            .or_else(|| try_resolve_intra(db, &mut doc_target_dirs.clone(), definition, &link_str));\n+                            .or_else(|| try_resolve_intra(db, &mut doc_target_dirs.clone(), definition, &link_text, &link_str));\n \n                         if let Some(resolved) = resolved {\n                             link.url = resolved.as_bytes().to_vec();\n@@ -430,11 +433,113 @@ fn rewrite_links(db: &RootDatabase, markdown: &str, definition: &Definition, wor\n     Some(String::from_utf8(out).unwrap())\n }\n \n+#[derive(PartialEq, Eq, Hash, Copy, Clone, Debug)]\n+enum Namespace {\n+    Types,\n+    Values,\n+    Macros\n+}\n+\n+impl Namespace {\n+    /// Extract the specified namespace from an intra-doc-link if one exists.\n+    fn from_intra_spec(s: &str) -> Option<Self> {\n+        let ns_map = hashmap!{\n+            Self::Types => (hashset!{\"type\", \"struct\", \"enum\", \"mod\", \"trait\", \"union\", \"module\"}, hashset!{}),\n+            Self::Values => (hashset!{\"value\", \"function\", \"fn\", \"method\", \"const\", \"static\", \"mod\", \"module\"}, hashset!{\"()\"}),\n+            Self::Macros => (hashset!{\"macro\"}, hashset!{\"!\"})\n+        };\n+\n+        ns_map\n+            .iter()\n+            .filter(|(ns, (prefixes, suffixes))| {\n+                prefixes.iter().map(|prefix| s.starts_with(prefix) && s.chars().nth(prefix.len()+1).map(|c| c == '@' || c == ' ').unwrap_or(false)).any(|cond| cond) ||\n+                suffixes.iter().map(|suffix| s.starts_with(suffix) && s.chars().nth(suffix.len()+1).map(|c| c == '@' || c == ' ').unwrap_or(false)).any(|cond| cond)\n+            })\n+            .map(|(ns, (_, _))| *ns)\n+            .next()\n+    }\n+}\n+\n /// Try to resolve path to local documentation via intra-doc-links (i.e. `super::gateway::Shard`).\n ///\n /// See [RFC1946](https://github.com/rust-lang/rfcs/blob/master/text/1946-intra-rustdoc-links.md).\n-fn try_resolve_intra(db: &RootDatabase, doc_target_dirs: impl Iterator<Item = PathBuf>, definition: &Definition, link: &str) -> Option<String> {\n-    None\n+fn try_resolve_intra(db: &RootDatabase, doc_target_dirs: impl Iterator<Item = PathBuf>, definition: &Definition, link_text: &str, link_target: &str) -> Option<String> {\n+    eprintln!(\"try_resolve_intra\");\n+\n+    // Set link_target for implied shortlinks\n+    let link_target = if link_target.is_empty() {\n+        link_text.trim_matches('`')\n+    } else {\n+        link_target\n+    };\n+\n+    // Parse link as a module path\n+    // This expects a full document, which a single path isn't, but we can just ignore the errors.\n+    let parsed = SyntaxNode::new_root(ra_syntax::parse_text(link_target).0);\n+    let path = parsed.descendants().filter_map(Path::cast).next()?;\n+    let modpath = ModPath::from_src(path, &Hygiene::new_unhygienic()).unwrap();\n+\n+    // Resolve it relative to symbol's location (according to the RFC this should consider small scopes\n+    let resolver = {\n+        use ra_hir_def::*;\n+        use hir::*;\n+\n+        // TODO: This should be replaced by implementing HasResolver/TryHasResolver on ModuleDef and Definition.\n+        match definition {\n+            Definition::ModuleDef(def) => match def {\n+                ModuleDef::Module(m) => Into::<ModuleId>::into(m.clone()).resolver(db),\n+                ModuleDef::Function(f) => Into::<FunctionId>::into(f.clone()).resolver(db),\n+                ModuleDef::Adt(adt) => Into::<AdtId>::into(adt.clone()).resolver(db),\n+                ModuleDef::EnumVariant(ev) => Into::<GenericDefId>::into(Into::<GenericDef>::into(ev.clone())).resolver(db),\n+                ModuleDef::Const(c) => Into::<GenericDefId>::into(Into::<GenericDef>::into(c.clone())).resolver(db),\n+                ModuleDef::Static(s) => Into::<StaticId>::into(s.clone()).resolver(db),\n+                ModuleDef::Trait(t) => Into::<TraitId>::into(t.clone()).resolver(db),\n+                ModuleDef::TypeAlias(t) => Into::<ModuleId>::into(t.module(db)).resolver(db),\n+                // TODO: This should be a resolver relative to `std`\n+                ModuleDef::BuiltinType(t) => Into::<ModuleId>::into(definition.module(db)?).resolver(db)\n+            },\n+            Definition::Field(field) => Into::<VariantId>::into(Into::<VariantDef>::into(field.parent_def(db))).resolver(db),\n+            Definition::Macro(m) => Into::<ModuleId>::into(m.module(db)?).resolver(db),\n+            Definition::SelfType(imp) => Into::<ImplId>::into(imp.clone()).resolver(db),\n+            // it's possible, read probable, that other arms of this are also unreachable\n+            Definition::Local(local) => unreachable!(),\n+            Definition::TypeParam(tp) => Into::<ModuleId>::into(tp.module(db)).resolver(db)\n+        }\n+    };\n+\n+    // Namespace disambiguation\n+    let namespace = Namespace::from_intra_spec(link_target);\n+\n+    let resolved = resolver.resolve_module_path_in_items(db, &modpath);\n+    let (defid, namespace) = match namespace {\n+        // TODO: .or(resolved.macros)\n+        None => resolved.types.map(|t| (t.0, Namespace::Types)).or(resolved.values.map(|t| (t.0, Namespace::Values)))?,\n+        Some(ns @ Namespace::Types) => (resolved.types?.0, ns),\n+        Some(ns @ Namespace::Values) => (resolved.values?.0, ns),\n+        // TODO:\n+        Some(Namespace::Macros) => None?\n+    };\n+\n+    // Get the filepath of the final symbol\n+    let def: ModuleDef = defid.into();\n+    let module = def.module(db)?;\n+    let krate = module.krate();\n+    let ns = match namespace {\n+        Namespace::Types => ItemInNs::Types(defid),\n+        Namespace::Values => ItemInNs::Values(defid),\n+        // TODO:\n+        Namespace::Macros => None?\n+    };\n+    let import_map = db.import_map(krate.into());\n+    let path = import_map.path_of(ns)?;\n+\n+    Some(\n+        get_doc_url(db, &krate)?\n+            .join(&format!(\"{}/\", krate.display_name(db)?)).ok()?\n+            .join(&path.segments.iter().map(|name| format!(\"{}\", name)).join(\"/\")).ok()?\n+            .join(&get_symbol_filename(db, definition)?).ok()?\n+            .into_string()\n+    )\n }\n \n enum UrlMode {\n@@ -444,6 +549,7 @@ enum UrlMode {\n \n /// Try to resolve path to local documentation via path-based links (i.e. `../gateway/struct.Shard.html`).\n fn try_resolve_path(db: &RootDatabase, doc_target_dirs: impl Iterator<Item = PathBuf>, definition: &Definition, link: &str, mode: UrlMode) -> Option<String> {\n+    eprintln!(\"try_resolve_path\");\n     let ns = if let Definition::ModuleDef(moddef) = definition {\n         ItemInNs::Types(moddef.clone().into())\n     } else {\n@@ -481,6 +587,7 @@ fn try_resolve_path(db: &RootDatabase, doc_target_dirs: impl Iterator<Item = Pat\n }\n \n /// Try to get the root URL of the documentation of a crate.\n+// TODO: Special case standard, core, alloc libraries\n fn get_doc_url(db: &RootDatabase, krate: &Crate) -> Option<Url> {\n     // Look for #![doc(html_root_url = \"...\")]\n     let attrs = db.attrs(AttrDef::from(krate.root_module(db)?).into());"}, {"sha": "7a2c44cd28d861fe986d9b9e38884fb6efecce8c", "filename": "crates/ra_syntax/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_syntax%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_syntax%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Flib.rs?ref=5f52a516dedeab16ede8c26807c4ff79b3d308d3", "patch": "@@ -47,7 +47,7 @@ use crate::syntax_node::GreenNode;\n pub use crate::{\n     algo::InsertPosition,\n     ast::{AstNode, AstToken},\n-    parsing::{lex_single_syntax_kind, lex_single_valid_syntax_kind, tokenize, Token},\n+    parsing::{lex_single_syntax_kind, lex_single_valid_syntax_kind, tokenize, Token, parse_text},\n     ptr::{AstPtr, SyntaxNodePtr},\n     syntax_error::SyntaxError,\n     syntax_node::{"}, {"sha": "4ec0b8d59c46e39510d4db602deed4cf861ca19d", "filename": "crates/ra_syntax/src/parsing.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5f52a516dedeab16ede8c26807c4ff79b3d308d3/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing.rs?ref=5f52a516dedeab16ede8c26807c4ff79b3d308d3", "patch": "@@ -15,7 +15,7 @@ pub use lexer::*;\n pub(crate) use self::reparsing::incremental_reparse;\n use ra_parser::SyntaxKind;\n \n-pub(crate) fn parse_text(text: &str) -> (GreenNode, Vec<SyntaxError>) {\n+pub fn parse_text(text: &str) -> (GreenNode, Vec<SyntaxError>) {\n     let (tokens, lexer_errors) = tokenize(&text);\n \n     let mut token_source = TextTokenSource::new(text, &tokens);"}]}