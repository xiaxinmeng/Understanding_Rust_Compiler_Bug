{"sha": "eb3ac29a101f9388966175bb51e340a98b849b59", "node_id": "MDY6Q29tbWl0NzI0NzEyOmViM2FjMjlhMTAxZjkzODg5NjYxNzViYjUxZTM0MGE5OGI4NDliNTk=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-11-02T03:03:55Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2016-11-03T23:48:24Z"}, "message": "Reduce the size of `Token` and make it cheaper to clone by refactoring\n`Token::Interpolated(Nonterminal)` -> `Token::Interpolated(Rc<Nonterminal>)`.", "tree": {"sha": "f77cf112fbbd52dcbd25d018850c6c0886606cf0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f77cf112fbbd52dcbd25d018850c6c0886606cf0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/eb3ac29a101f9388966175bb51e340a98b849b59", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/eb3ac29a101f9388966175bb51e340a98b849b59", "html_url": "https://github.com/rust-lang/rust/commit/eb3ac29a101f9388966175bb51e340a98b849b59", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/eb3ac29a101f9388966175bb51e340a98b849b59/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5f280a5c608c6cb92fa75829599d5759ed6305a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/5f280a5c608c6cb92fa75829599d5759ed6305a5", "html_url": "https://github.com/rust-lang/rust/commit/5f280a5c608c6cb92fa75829599d5759ed6305a5"}], "stats": {"total": 385, "additions": 159, "deletions": 226}, "files": [{"sha": "969cfa292ce8068315fea22fd6d587851647264f", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 32, "deletions": 22, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -80,67 +80,71 @@ pub mod rt {\n \n     impl ToTokens for ast::Path {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP,\n-                                  token::Interpolated(token::NtPath(Box::new(self.clone()))))]\n+            let nt = token::NtPath(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Ty {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtTy(P(self.clone()))))]\n+            let nt = token::NtTy(P(self.clone()));\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Block {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtBlock(P(self.clone()))))]\n+            let nt = token::NtBlock(P(self.clone()));\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Generics {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtGenerics(self.clone())))]\n+            let nt = token::NtGenerics(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::WhereClause {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP,\n-                                  token::Interpolated(token::NtWhereClause(self.clone())))]\n+            let nt = token::NtWhereClause(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for P<ast::Item> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtItem(self.clone())))]\n+            let nt = token::NtItem(self.clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::ImplItem {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span,\n-                                  token::Interpolated(token::NtImplItem(P(self.clone()))))]\n+            let nt = token::NtImplItem(self.clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for P<ast::ImplItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtImplItem(self.clone())))]\n+            let nt = token::NtImplItem((**self).clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::TraitItem {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span,\n-                                  token::Interpolated(token::NtTraitItem(P(self.clone()))))]\n+            let nt = token::NtTraitItem(self.clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Stmt {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            let mut tts = vec![\n-                TokenTree::Token(self.span, token::Interpolated(token::NtStmt(P(self.clone()))))\n-            ];\n+            let nt = token::NtStmt(self.clone());\n+            let mut tts = vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))];\n \n             // Some statements require a trailing semicolon.\n             if classify::stmt_ends_with_semi(&self.node) {\n@@ -153,31 +157,36 @@ pub mod rt {\n \n     impl ToTokens for P<ast::Expr> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtExpr(self.clone())))]\n+            let nt = token::NtExpr(self.clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for P<ast::Pat> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(self.span, token::Interpolated(token::NtPat(self.clone())))]\n+            let nt = token::NtPat(self.clone());\n+            vec![TokenTree::Token(self.span, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Arm {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtArm(self.clone())))]\n+            let nt = token::NtArm(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for ast::Arg {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtArg(self.clone())))]\n+            let nt = token::NtArg(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n     impl ToTokens for P<ast::Block> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtBlock(self.clone())))]\n+            let nt = token::NtBlock(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n \n@@ -204,7 +213,8 @@ pub mod rt {\n \n     impl ToTokens for P<ast::MetaItem> {\n         fn to_tokens(&self, _cx: &ExtCtxt) -> Vec<TokenTree> {\n-            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(token::NtMeta(self.clone())))]\n+            let nt = token::NtMeta(self.clone());\n+            vec![TokenTree::Token(DUMMY_SP, token::Interpolated(Rc::new(nt)))]\n         }\n     }\n "}, {"sha": "6680119d2eaa20f37c6dc32c1b1c9eff26cbcb85", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -89,7 +89,6 @@ use parse::token::{DocComment, MatchNt, SubstNt};\n use parse::token::{Token, Nonterminal};\n use parse::token;\n use print::pprust;\n-use ptr::P;\n use tokenstream::{self, TokenTree};\n use util::small_vector::SmallVector;\n \n@@ -198,7 +197,7 @@ pub fn initial_matcher_pos(ms: Vec<TokenTree>, sep: Option<Token>, lo: BytePos)\n \n pub enum NamedMatch {\n     MatchedSeq(Vec<Rc<NamedMatch>>, syntax_pos::Span),\n-    MatchedNonterminal(Nonterminal)\n+    MatchedNonterminal(Rc<Nonterminal>)\n }\n \n pub fn nameize(p_s: &ParseSess, ms: &[TokenTree], res: &[Rc<NamedMatch>])\n@@ -482,7 +481,7 @@ pub fn parse(sess: &ParseSess, mut rdr: TtReader, ms: &[TokenTree]) -> NamedPars\n                     if let TokenTree::Token(span, MatchNt(_, ident)) = ei.top_elts.get_tt(ei.idx) {\n                         let match_cur = ei.match_cur;\n                         (&mut ei.matches[match_cur]).push(Rc::new(MatchedNonterminal(\n-                            parse_nt(&mut rust_parser, span, &ident.name.as_str()))));\n+                            Rc::new(parse_nt(&mut rust_parser, span, &ident.name.as_str())))));\n                         ei.idx += 1;\n                         ei.match_cur += 1;\n                     } else {\n@@ -503,7 +502,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         \"tt\" => {\n             p.quote_depth += 1; //but in theory, non-quoted tts might be useful\n             let res: ::parse::PResult<'a, _> = p.parse_token_tree();\n-            let res = token::NtTT(P(panictry!(res)));\n+            let res = token::NtTT(panictry!(res));\n             p.quote_depth -= 1;\n             return res;\n         }\n@@ -521,7 +520,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         },\n         \"block\" => token::NtBlock(panictry!(p.parse_block())),\n         \"stmt\" => match panictry!(p.parse_stmt()) {\n-            Some(s) => token::NtStmt(P(s)),\n+            Some(s) => token::NtStmt(s),\n             None => {\n                 p.fatal(\"expected a statement\").emit();\n                 panic!(FatalError);\n@@ -534,7 +533,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n         \"ident\" => match p.token {\n             token::Ident(sn) => {\n                 p.bump();\n-                token::NtIdent(Box::new(Spanned::<Ident>{node: sn, span: p.span}))\n+                token::NtIdent(Spanned::<Ident>{node: sn, span: p.span})\n             }\n             _ => {\n                 let token_str = pprust::token_to_string(&p.token);\n@@ -544,7 +543,7 @@ pub fn parse_nt<'a>(p: &mut Parser<'a>, sp: Span, name: &str) -> Nonterminal {\n             }\n         },\n         \"path\" => {\n-            token::NtPath(Box::new(panictry!(p.parse_path(PathStyle::Type))))\n+            token::NtPath(panictry!(p.parse_path(PathStyle::Type)))\n         },\n         \"meta\" => token::NtMeta(panictry!(p.parse_meta_item())),\n         // this is not supposed to happen, since it has been checked"}, {"sha": "552d4de961740f4c59b749b30ba9fde36719d75e", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 14, "deletions": 8, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -236,22 +236,28 @@ pub fn compile(sess: &ParseSess, def: &ast::MacroDef) -> SyntaxExtension {\n     // Extract the arguments:\n     let lhses = match **argument_map.get(&lhs_nm).unwrap() {\n         MatchedSeq(ref s, _) => {\n-            s.iter().map(|m| match **m {\n-                MatchedNonterminal(NtTT(ref tt)) => {\n-                    valid &= check_lhs_nt_follows(sess, tt);\n-                    (**tt).clone()\n+            s.iter().map(|m| {\n+                if let MatchedNonterminal(ref nt) = **m {\n+                    if let NtTT(ref tt) = **nt {\n+                        valid &= check_lhs_nt_follows(sess, tt);\n+                        return (*tt).clone();\n+                    }\n                 }\n-                _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n+                sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n             }).collect::<Vec<TokenTree>>()\n         }\n         _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n     };\n \n     let rhses = match **argument_map.get(&rhs_nm).unwrap() {\n         MatchedSeq(ref s, _) => {\n-            s.iter().map(|m| match **m {\n-                MatchedNonterminal(NtTT(ref tt)) => (**tt).clone(),\n-                _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\")\n+            s.iter().map(|m| {\n+                if let MatchedNonterminal(ref nt) = **m {\n+                    if let NtTT(ref tt) = **nt {\n+                        return (*tt).clone();\n+                    }\n+                }\n+                sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n             }).collect()\n         }\n         _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\")"}, {"sha": "641d69900f730158e1a75de0d57da69b62b65dcb", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 11, "deletions": 13, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -277,39 +277,37 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                         return ret_val;\n                         // this can't be 0 length, just like TokenTree::Delimited\n                     }\n-                    Some(cur_matched) => {\n-                        match *cur_matched {\n+                    Some(cur_matched) => if let MatchedNonterminal(ref nt) = *cur_matched {\n+                        match **nt {\n                             // sidestep the interpolation tricks for ident because\n                             // (a) idents can be in lots of places, so it'd be a pain\n                             // (b) we actually can, since it's a token.\n-                            MatchedNonterminal(NtIdent(ref sn)) => {\n+                            NtIdent(ref sn) => {\n                                 r.stack.last_mut().unwrap().idx += 1;\n                                 r.cur_span = sn.span;\n                                 r.cur_tok = token::Ident(sn.node);\n                                 return ret_val;\n                             }\n-                            MatchedNonterminal(NtTT(ref tt)) => {\n+                            NtTT(_) => {\n                                 r.stack.push(TtFrame {\n-                                    forest: TokenTree::Token(sp, Interpolated(NtTT(tt.clone()))),\n+                                    forest: TokenTree::Token(sp, Interpolated(nt.clone())),\n                                     idx: 0,\n                                     dotdotdoted: false,\n                                     sep: None,\n                                 });\n                             }\n-                            MatchedNonterminal(ref other_whole_nt) => {\n+                            _ => {\n                                 r.stack.last_mut().unwrap().idx += 1;\n                                 // FIXME(pcwalton): Bad copy.\n                                 r.cur_span = sp;\n-                                r.cur_tok = Interpolated((*other_whole_nt).clone());\n+                                r.cur_tok = Interpolated(nt.clone());\n                                 return ret_val;\n                             }\n-                            MatchedSeq(..) => {\n-                                panic!(r.sp_diag.span_fatal(\n-                                    sp, /* blame the macro writer */\n-                                    &format!(\"variable '{}' is still repeating at this depth\",\n-                                            ident)));\n-                            }\n                         }\n+                    } else {\n+                        panic!(r.sp_diag.span_fatal(\n+                            sp, /* blame the macro writer */\n+                            &format!(\"variable '{}' is still repeating at this depth\", ident)));\n                     }\n                 }\n             }"}, {"sha": "71aa0437609d12d48ef44dda47b3e32c693c4d8e", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 18, "deletions": 13, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -576,7 +576,13 @@ pub fn noop_fold_token<T: Folder>(t: token::Token, fld: &mut T) -> token::Token\n     match t {\n         token::Ident(id) => token::Ident(fld.fold_ident(id)),\n         token::Lifetime(id) => token::Lifetime(fld.fold_ident(id)),\n-        token::Interpolated(nt) => token::Interpolated(fld.fold_interpolated(nt)),\n+        token::Interpolated(nt) => {\n+            let nt = match Rc::try_unwrap(nt) {\n+                Ok(nt) => nt,\n+                Err(nt) => (*nt).clone(),\n+            };\n+            token::Interpolated(Rc::new(fld.fold_interpolated(nt)))\n+        }\n         token::SubstNt(ident) => token::SubstNt(fld.fold_ident(ident)),\n         token::MatchNt(name, kind) => token::MatchNt(fld.fold_ident(name), fld.fold_ident(kind)),\n         _ => t\n@@ -614,26 +620,25 @@ pub fn noop_fold_interpolated<T: Folder>(nt: token::Nonterminal, fld: &mut T)\n                           .expect_one(\"expected fold to produce exactly one item\")),\n         token::NtBlock(block) => token::NtBlock(fld.fold_block(block)),\n         token::NtStmt(stmt) =>\n-            token::NtStmt(stmt.map(|stmt| fld.fold_stmt(stmt)\n+            token::NtStmt(fld.fold_stmt(stmt)\n                           // this is probably okay, because the only folds likely\n                           // to peek inside interpolated nodes will be renamings/markings,\n                           // which map single items to single items\n-                          .expect_one(\"expected fold to produce exactly one statement\"))),\n+                          .expect_one(\"expected fold to produce exactly one statement\")),\n         token::NtPat(pat) => token::NtPat(fld.fold_pat(pat)),\n         token::NtExpr(expr) => token::NtExpr(fld.fold_expr(expr)),\n         token::NtTy(ty) => token::NtTy(fld.fold_ty(ty)),\n-        token::NtIdent(id) =>\n-            token::NtIdent(Box::new(Spanned::<Ident>{node: fld.fold_ident(id.node), ..*id})),\n+        token::NtIdent(id) => token::NtIdent(Spanned::<Ident>{node: fld.fold_ident(id.node), ..id}),\n         token::NtMeta(meta_item) => token::NtMeta(fld.fold_meta_item(meta_item)),\n-        token::NtPath(path) => token::NtPath(Box::new(fld.fold_path(*path))),\n-        token::NtTT(tt) => token::NtTT(P(fld.fold_tt(&tt))),\n+        token::NtPath(path) => token::NtPath(fld.fold_path(path)),\n+        token::NtTT(tt) => token::NtTT(fld.fold_tt(&tt)),\n         token::NtArm(arm) => token::NtArm(fld.fold_arm(arm)),\n-        token::NtImplItem(arm) =>\n-            token::NtImplItem(arm.map(|arm| fld.fold_impl_item(arm)\n-                              .expect_one(\"expected fold to produce exactly one item\"))),\n-        token::NtTraitItem(arm) =>\n-            token::NtTraitItem(arm.map(|arm| fld.fold_trait_item(arm)\n-                               .expect_one(\"expected fold to produce exactly one item\"))),\n+        token::NtImplItem(item) =>\n+            token::NtImplItem(fld.fold_impl_item(item)\n+                              .expect_one(\"expected fold to produce exactly one item\")),\n+        token::NtTraitItem(item) =>\n+            token::NtTraitItem(fld.fold_trait_item(item)\n+                               .expect_one(\"expected fold to produce exactly one item\")),\n         token::NtGenerics(generics) => token::NtGenerics(fld.fold_generics(generics)),\n         token::NtWhereClause(where_clause) =>\n             token::NtWhereClause(fld.fold_where_clause(where_clause)),"}, {"sha": "983c882eafca31298542d0a2a53ee7d44eca1dd8", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -215,7 +215,10 @@ impl<'a> Parser<'a> {\n     /// meta_item_inner : (meta_item | UNSUFFIXED_LIT) (',' meta_item_inner)? ;\n     pub fn parse_meta_item(&mut self) -> PResult<'a, P<ast::MetaItem>> {\n         let nt_meta = match self.token {\n-            token::Interpolated(token::NtMeta(ref e)) => Some(e.clone()),\n+            token::Interpolated(ref nt) => match **nt {\n+                token::NtMeta(ref e) => Some(e.clone()),\n+                _ => None,\n+            },\n             _ => None,\n         };\n "}, {"sha": "f77525ff549d92aa6d50ce19b66648e209f35612", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 44, "deletions": 143, "changes": 187, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -107,125 +107,41 @@ pub enum SemiColonMode {\n /// be. The important thing is to make sure that lookahead doesn't balk at\n /// `token::Interpolated` tokens.\n macro_rules! maybe_whole_expr {\n-    ($p:expr) => (\n-        {\n-            let found = match $p.token {\n-                token::Interpolated(token::NtExpr(ref e)) => {\n-                    Some((*e).clone())\n+    ($p:expr) => {\n+        if let token::Interpolated(nt) = $p.token.clone() {\n+            match *nt {\n+                token::NtExpr(ref e) => {\n+                    $p.bump();\n+                    return Ok((*e).clone());\n                 }\n-                token::Interpolated(token::NtPath(_)) => {\n-                    // FIXME: The following avoids an issue with lexical borrowck scopes,\n-                    // but the clone is unfortunate.\n-                    let pt = match $p.token {\n-                        token::Interpolated(token::NtPath(ref pt)) => (**pt).clone(),\n-                        _ => unreachable!()\n-                    };\n+                token::NtPath(ref path) => {\n+                    $p.bump();\n                     let span = $p.span;\n-                    Some($p.mk_expr(span.lo, span.hi, ExprKind::Path(None, pt), ThinVec::new()))\n+                    let kind = ExprKind::Path(None, (*path).clone());\n+                    return Ok($p.mk_expr(span.lo, span.hi, kind, ThinVec::new()));\n                 }\n-                token::Interpolated(token::NtBlock(_)) => {\n-                    // FIXME: The following avoids an issue with lexical borrowck scopes,\n-                    // but the clone is unfortunate.\n-                    let b = match $p.token {\n-                        token::Interpolated(token::NtBlock(ref b)) => (*b).clone(),\n-                        _ => unreachable!()\n-                    };\n+                token::NtBlock(ref block) => {\n+                    $p.bump();\n                     let span = $p.span;\n-                    Some($p.mk_expr(span.lo, span.hi, ExprKind::Block(b), ThinVec::new()))\n+                    let kind = ExprKind::Block((*block).clone());\n+                    return Ok($p.mk_expr(span.lo, span.hi, kind, ThinVec::new()));\n                 }\n-                _ => None\n+                _ => {},\n             };\n-            match found {\n-                Some(e) => {\n-                    $p.bump();\n-                    return Ok(e);\n-                }\n-                None => ()\n-            }\n         }\n-    )\n+    }\n }\n \n /// As maybe_whole_expr, but for things other than expressions\n macro_rules! maybe_whole {\n-    ($p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok(x.clone());\n-            }\n-        }\n-    );\n-    (no_clone $p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok(x);\n-            }\n-        }\n-    );\n-    (no_clone_from_p $p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok(x.unwrap());\n-            }\n-        }\n-    );\n-    (deref $p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok((*x).clone());\n-            }\n-        }\n-    );\n-    (Some deref $p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok(Some((*x).clone()));\n-            }\n-        }\n-    );\n-    (pair_empty $p:expr, $constructor:ident) => (\n-        {\n-            let found = match ($p).token {\n-                token::Interpolated(token::$constructor(_)) => {\n-                    Some(($p).bump_and_get())\n-                }\n-                _ => None\n-            };\n-            if let Some(token::Interpolated(token::$constructor(x))) = found {\n-                return Ok((Vec::new(), x));\n+    ($p:expr, $constructor:ident, |$x:ident| $e:expr) => {\n+        if let token::Interpolated(nt) = $p.token.clone() {\n+            if let token::$constructor($x) = (*nt).clone() {\n+                $p.bump();\n+                return Ok($e);\n             }\n         }\n-    )\n+    };\n }\n \n fn maybe_append(mut lhs: Vec<Attribute>, rhs: Option<Vec<Attribute>>)\n@@ -516,9 +432,6 @@ impl<'a> Parser<'a> {\n                 self.bump();\n                 Ok(i)\n             }\n-            token::Interpolated(token::NtIdent(..)) => {\n-                self.bug(\"ident interpolation not converted to real token\");\n-            }\n             _ => {\n                 Err(if self.prev_token_kind == PrevTokenKind::DocComment {\n                     self.span_fatal_help(self.prev_span,\n@@ -1162,7 +1075,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse the items in a trait declaration\n     pub fn parse_trait_item(&mut self) -> PResult<'a, TraitItem> {\n-        maybe_whole!(no_clone_from_p self, NtTraitItem);\n+        maybe_whole!(self, NtTraitItem, |x| x);\n         let mut attrs = self.parse_outer_attributes()?;\n         let lo = self.span.lo;\n \n@@ -1331,7 +1244,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse a type.\n     pub fn parse_ty(&mut self) -> PResult<'a, P<Ty>> {\n-        maybe_whole!(no_clone self, NtTy);\n+        maybe_whole!(self, NtTy, |x| x);\n \n         let lo = self.span.lo;\n \n@@ -1476,7 +1389,7 @@ impl<'a> Parser<'a> {\n     /// This version of parse arg doesn't necessarily require\n     /// identifier names.\n     pub fn parse_arg_general(&mut self, require_name: bool) -> PResult<'a, Arg> {\n-        maybe_whole!(no_clone self, NtArg);\n+        maybe_whole!(self, NtArg, |x| x);\n \n         let pat = if require_name || self.is_named_argument() {\n             debug!(\"parse_arg_general parse_pat (require_name:{})\",\n@@ -1542,12 +1455,13 @@ impl<'a> Parser<'a> {\n     /// Matches token_lit = LIT_INTEGER | ...\n     pub fn parse_lit_token(&mut self) -> PResult<'a, LitKind> {\n         let out = match self.token {\n-            token::Interpolated(token::NtExpr(ref v)) => {\n-                match v.node {\n+            token::Interpolated(ref nt) => match **nt {\n+                token::NtExpr(ref v) => match v.node {\n                     ExprKind::Lit(ref lit) => { lit.node.clone() }\n                     _ => { return self.unexpected_last(&self.token); }\n-                }\n-            }\n+                },\n+                _ => { return self.unexpected_last(&self.token); }\n+            },\n             token::Literal(lit, suf) => {\n                 let (suffix_illegal, out) = match lit {\n                     token::Byte(i) => (true, LitKind::Byte(parse::byte_lit(&i.as_str()).0)),\n@@ -1703,14 +1617,7 @@ impl<'a> Parser<'a> {\n     /// bounds are permitted and whether `::` must precede type parameter\n     /// groups.\n     pub fn parse_path(&mut self, mode: PathStyle) -> PResult<'a, ast::Path> {\n-        // Check for a whole path...\n-        let found = match self.token {\n-            token::Interpolated(token::NtPath(_)) => Some(self.bump_and_get()),\n-            _ => None,\n-        };\n-        if let Some(token::Interpolated(token::NtPath(path))) = found {\n-            return Ok(*path);\n-        }\n+        maybe_whole!(self, NtPath, |x| x);\n \n         let lo = self.span.lo;\n         let is_global = self.eat(&token::ModSep);\n@@ -2746,7 +2653,7 @@ impl<'a> Parser<'a> {\n         // and token::SubstNt's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n-        maybe_whole!(deref self, NtTT);\n+        maybe_whole!(self, NtTT, |x| x);\n \n         match self.token {\n             token::Eof => {\n@@ -3327,7 +3234,7 @@ impl<'a> Parser<'a> {\n     }\n \n     pub fn parse_arm(&mut self) -> PResult<'a, Arm> {\n-        maybe_whole!(no_clone self, NtArm);\n+        maybe_whole!(self, NtArm, |x| x);\n \n         let attrs = self.parse_outer_attributes()?;\n         let pats = self.parse_pats()?;\n@@ -3583,7 +3490,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse a pattern.\n     pub fn parse_pat(&mut self) -> PResult<'a, P<Pat>> {\n-        maybe_whole!(self, NtPat);\n+        maybe_whole!(self, NtPat, |x| x);\n \n         let lo = self.span.lo;\n         let pat;\n@@ -3888,7 +3795,7 @@ impl<'a> Parser<'a> {\n     fn parse_stmt_without_recovery(&mut self,\n                                    macro_legacy_warnings: bool)\n                                    -> PResult<'a, Option<Stmt>> {\n-        maybe_whole!(Some deref self, NtStmt);\n+        maybe_whole!(self, NtStmt, |x| Some(x));\n \n         let attrs = self.parse_outer_attributes()?;\n         let lo = self.span.lo;\n@@ -4077,7 +3984,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse a block. No inner attrs are allowed.\n     pub fn parse_block(&mut self) -> PResult<'a, P<Block>> {\n-        maybe_whole!(no_clone self, NtBlock);\n+        maybe_whole!(self, NtBlock, |x| x);\n \n         let lo = self.span.lo;\n \n@@ -4115,7 +4022,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse a block. Inner attrs are allowed.\n     fn parse_inner_attrs_and_block(&mut self) -> PResult<'a, (Vec<Attribute>, P<Block>)> {\n-        maybe_whole!(pair_empty self, NtBlock);\n+        maybe_whole!(self, NtBlock, |x| (Vec::new(), x));\n \n         let lo = self.span.lo;\n         self.expect(&token::OpenDelim(token::Brace))?;\n@@ -4290,7 +4197,7 @@ impl<'a> Parser<'a> {\n     ///                  | ( < lifetimes , typaramseq ( , )? > )\n     /// where   typaramseq = ( typaram ) | ( typaram , typaramseq )\n     pub fn parse_generics(&mut self) -> PResult<'a, ast::Generics> {\n-        maybe_whole!(self, NtGenerics);\n+        maybe_whole!(self, NtGenerics, |x| x);\n         let span_lo = self.span.lo;\n \n         if self.eat(&token::Lt) {\n@@ -4431,7 +4338,7 @@ impl<'a> Parser<'a> {\n     /// where T : Trait<U, V> + 'b, 'a : 'b\n     /// ```\n     pub fn parse_where_clause(&mut self) -> PResult<'a, ast::WhereClause> {\n-        maybe_whole!(self, NtWhereClause);\n+        maybe_whole!(self, NtWhereClause, |x| x);\n \n         let mut where_clause = WhereClause {\n             id: ast::DUMMY_NODE_ID,\n@@ -4839,7 +4746,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse an impl item.\n     pub fn parse_impl_item(&mut self) -> PResult<'a, ImplItem> {\n-        maybe_whole!(no_clone_from_p self, NtImplItem);\n+        maybe_whole!(self, NtImplItem, |x| x);\n \n         let mut attrs = self.parse_outer_attributes()?;\n         let lo = self.span.lo;\n@@ -5707,19 +5614,13 @@ impl<'a> Parser<'a> {\n     /// extern crate.\n     fn parse_item_(&mut self, attrs: Vec<Attribute>,\n                    macros_allowed: bool, attributes_allowed: bool) -> PResult<'a, Option<P<Item>>> {\n-        let nt_item = match self.token {\n-            token::Interpolated(token::NtItem(ref item)) => {\n-                Some((**item).clone())\n-            }\n-            _ => None\n-        };\n-        if let Some(mut item) = nt_item {\n-            self.bump();\n+        maybe_whole!(self, NtItem, |item| {\n+            let mut item = item.unwrap();\n             let mut attrs = attrs;\n             mem::swap(&mut item.attrs, &mut attrs);\n             item.attrs.extend(attrs);\n-            return Ok(Some(P(item)));\n-        }\n+            Some(P(item))\n+        });\n \n         let lo = self.span.lo;\n "}, {"sha": "0198ee073d23982c3534787ab2c950fa2a44076e", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 20, "deletions": 15, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -123,7 +123,7 @@ pub enum Token {\n     Lifetime(ast::Ident),\n \n     /* For interpolation */\n-    Interpolated(Nonterminal),\n+    Interpolated(Rc<Nonterminal>),\n     // Can be expanded into several tokens.\n     /// Doc comment\n     DocComment(ast::Name),\n@@ -172,12 +172,15 @@ impl Token {\n             DotDot | DotDotDot          => true, // range notation\n             Lt | BinOp(Shl)             => true, // associated path\n             ModSep                      => true,\n-            Interpolated(NtExpr(..))    => true,\n-            Interpolated(NtIdent(..))   => true,\n-            Interpolated(NtBlock(..))   => true,\n-            Interpolated(NtPath(..))    => true,\n             Pound                       => true, // for expression attributes\n-            _                           => false,\n+            Interpolated(ref nt) => match **nt {\n+                NtExpr(..) => true,\n+                NtIdent(..) => true,\n+                NtBlock(..) => true,\n+                NtPath(..) => true,\n+                _ => false,\n+            },\n+            _ => false,\n         }\n     }\n \n@@ -215,10 +218,12 @@ impl Token {\n \n     /// Returns `true` if the token is an interpolated path.\n     pub fn is_path(&self) -> bool {\n-        match *self {\n-            Interpolated(NtPath(..))    => true,\n-            _                           => false,\n+        if let Interpolated(ref nt) = *self {\n+            if let NtPath(..) = **nt {\n+                return true;\n+            }\n         }\n+        false\n     }\n \n     /// Returns `true` if the token is a lifetime.\n@@ -290,19 +295,19 @@ impl Token {\n pub enum Nonterminal {\n     NtItem(P<ast::Item>),\n     NtBlock(P<ast::Block>),\n-    NtStmt(P<ast::Stmt>),\n+    NtStmt(ast::Stmt),\n     NtPat(P<ast::Pat>),\n     NtExpr(P<ast::Expr>),\n     NtTy(P<ast::Ty>),\n-    NtIdent(Box<ast::SpannedIdent>),\n+    NtIdent(ast::SpannedIdent),\n     /// Stuff inside brackets for attributes\n     NtMeta(P<ast::MetaItem>),\n-    NtPath(Box<ast::Path>),\n-    NtTT(P<tokenstream::TokenTree>), // needs P'ed to break a circularity\n+    NtPath(ast::Path),\n+    NtTT(tokenstream::TokenTree),\n     // These are not exposed to macros, but are used by quasiquote.\n     NtArm(ast::Arm),\n-    NtImplItem(P<ast::ImplItem>),\n-    NtTraitItem(P<ast::TraitItem>),\n+    NtImplItem(ast::ImplItem),\n+    NtTraitItem(ast::TraitItem),\n     NtGenerics(ast::Generics),\n     NtWhereClause(ast::WhereClause),\n     NtArg(ast::Arg),"}, {"sha": "7352792a8a25253ec950d07722089a53c2b4232b", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -285,7 +285,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::Comment              => \"/* */\".to_string(),\n         token::Shebang(s)           => format!(\"/* shebang: {}*/\", s),\n \n-        token::Interpolated(ref nt) => match *nt {\n+        token::Interpolated(ref nt) => match **nt {\n             token::NtExpr(ref e)        => expr_to_string(&e),\n             token::NtMeta(ref e)        => meta_item_to_string(&e),\n             token::NtTy(ref e)          => ty_to_string(&e),"}, {"sha": "a0dd7b4c5212c318b77ff0d8b0f7817099a4f606", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 9, "deletions": 3, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eb3ac29a101f9388966175bb51e340a98b849b59/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=eb3ac29a101f9388966175bb51e340a98b849b59", "patch": "@@ -134,8 +134,10 @@ impl TokenTree {\n                     AttrStyle::Inner => 3,\n                 }\n             }\n+            TokenTree::Token(_, token::Interpolated(ref nt)) => {\n+                if let Nonterminal::NtTT(..) = **nt { 1 } else { 0 }\n+            },\n             TokenTree::Token(_, token::MatchNt(..)) => 3,\n-            TokenTree::Token(_, token::Interpolated(Nonterminal::NtTT(..))) => 1,\n             TokenTree::Delimited(_, ref delimed) => delimed.tts.len() + 2,\n             TokenTree::Sequence(_, ref seq) => seq.tts.len(),\n             TokenTree::Token(..) => 0,\n@@ -193,8 +195,12 @@ impl TokenTree {\n                          TokenTree::Token(sp, token::Ident(kind))];\n                 v[index].clone()\n             }\n-            (&TokenTree::Token(_, token::Interpolated(Nonterminal::NtTT(ref tt))), _) => {\n-                tt.clone().unwrap()\n+            (&TokenTree::Token(_, token::Interpolated(ref nt)), _) => {\n+                if let Nonterminal::NtTT(ref tt) = **nt {\n+                    tt.clone()\n+                } else {\n+                    panic!(\"Cannot expand a token tree\");\n+                }\n             }\n             (&TokenTree::Sequence(_, ref seq), _) => seq.tts[index].clone(),\n             _ => panic!(\"Cannot expand a token tree\"),"}]}