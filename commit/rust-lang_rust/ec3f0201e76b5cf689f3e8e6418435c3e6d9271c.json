{"sha": "ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVjM2YwMjAxZTc2YjVjZjY4OWYzZThlNjQxODQzNWMzZTZkOTI3MWM=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-22T12:35:32Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-25T22:53:29Z"}, "message": "Rename TokenTree variants for clarity\n\nThis should be clearer, and fits in better with the `TTNonterminal` variant.\n\nRenames:\n\n- `TTTok` -> `TTToken`\n- `TTDelim` -> `TTDelimited`\n- `TTSeq` -> `TTSequence`", "tree": {"sha": "a86e67e155e7f801fe9a76e95a8f970c251cc966", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a86e67e155e7f801fe9a76e95a8f970c251cc966"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "html_url": "https://github.com/rust-lang/rust/commit/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "971d776aa5a678672eb3d37f2f507664aacd2440", "url": "https://api.github.com/repos/rust-lang/rust/commits/971d776aa5a678672eb3d37f2f507664aacd2440", "html_url": "https://github.com/rust-lang/rust/commit/971d776aa5a678672eb3d37f2f507664aacd2440"}], "stats": {"total": 193, "additions": 98, "deletions": 95}, "files": [{"sha": "9bf1d29569ca4ab41c948379ff2d129b4327fb2b", "filename": "src/doc/guide-plugin.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Fdoc%2Fguide-plugin.md", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Fdoc%2Fguide-plugin.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide-plugin.md?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -56,7 +56,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTTok};\n+use syntax::ast::{TokenTree, TTToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -71,7 +71,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTTok(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TTToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}, {"sha": "36373638099d2a1d509ac2e864770063c032b541", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 15, "deletions": 12, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -24,6 +24,9 @@ use std::fmt::Show;\n use std::rc::Rc;\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n+#[cfg(stage0)]\n+pub use self::TTToken as TTTok;\n+\n // FIXME #6993: in librustc, uses of \"ident\" should be replaced\n // by just \"Name\".\n \n@@ -600,9 +603,9 @@ pub struct Delimiter {\n }\n \n impl Delimiter {\n-    /// Convert the delimiter to a `TTTok`\n+    /// Convert the delimiter to a `TTToken`\n     pub fn to_tt(&self) -> TokenTree {\n-        TTTok(self.span, self.token.clone())\n+        TTToken(self.span, self.token.clone())\n     }\n }\n \n@@ -614,28 +617,28 @@ impl Delimiter {\n /// If the syntax extension is an MBE macro, it will attempt to match its\n /// LHS \"matchers\" against the provided token tree, and if it finds a\n /// match, will transcribe the RHS token tree, splicing in any captured\n-/// macro_parser::matched_nonterminals into the TTNonterminals it finds.\n+/// `macro_parser::matched_nonterminals` into the `TTNonterminal`s it finds.\n ///\n-/// The RHS of an MBE macro is the only place a TTNonterminal or TTSeq\n+/// The RHS of an MBE macro is the only place a `TTNonterminal` or `TTSequence`\n /// makes any real sense. You could write them elsewhere but nothing\n /// else knows what to do with them, so you'll probably get a syntax\n /// error.\n #[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n pub enum TokenTree {\n     /// A single token\n-    TTTok(Span, ::parse::token::Token),\n+    TTToken(Span, ::parse::token::Token),\n     /// A delimited sequence of token trees\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTDelim(Span, Delimiter, Rc<Vec<TokenTree>>, Delimiter),\n+    TTDelimited(Span, Delimiter, Rc<Vec<TokenTree>>, Delimiter),\n \n     // These only make sense for right-hand-sides of MBE macros:\n \n-    /// A kleene-style repetition sequence with a span, a TTForest,\n+    /// A kleene-style repetition sequence with a span, a `TTForest`,\n     /// an optional separator, and a boolean where true indicates\n     /// zero or more (..), and false indicates one or more (+).\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTSeq(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, bool),\n+    TTSequence(Span, Rc<Vec<TokenTree>>, Option<::parse::token::Token>, bool),\n \n     /// A syntactic variable that will be filled in by macro expansion.\n     TTNonterminal(Span, Ident)\n@@ -645,10 +648,10 @@ impl TokenTree {\n     /// Returns the `Span` corresponding to this token tree.\n     pub fn get_span(&self) -> Span {\n         match *self {\n-            TTTok(span, _)         => span,\n-            TTDelim(span, _, _, _) => span,\n-            TTSeq(span, _, _, _)   => span,\n-            TTNonterminal(span, _) => span,\n+            TTToken(span, _)           => span,\n+            TTDelimited(span, _, _, _) => span,\n+            TTSequence(span, _, _, _)  => span,\n+            TTNonterminal(span, _)     => span,\n         }\n     }\n }"}, {"sha": "8ea08c58d065c1dde085a779af6da1e3a9d8b3d3", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -50,7 +50,7 @@ pub fn expand_diagnostic_used<'cx>(ecx: &'cx mut ExtCtxt,\n                                    token_tree: &[TokenTree])\n                                    -> Box<MacResult+'cx> {\n     let code = match token_tree {\n-        [ast::TTTok(_, token::IDENT(code, _))] => code,\n+        [ast::TTToken(_, token::IDENT(code, _))] => code,\n         _ => unreachable!()\n     };\n     with_registered_diagnostics(|diagnostics| {\n@@ -82,12 +82,12 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt,\n                                        token_tree: &[TokenTree])\n                                        -> Box<MacResult+'cx> {\n     let (code, description) = match token_tree {\n-        [ast::TTTok(_, token::IDENT(ref code, _))] => {\n+        [ast::TTToken(_, token::IDENT(ref code, _))] => {\n             (code, None)\n         },\n-        [ast::TTTok(_, token::IDENT(ref code, _)),\n-         ast::TTTok(_, token::COMMA),\n-         ast::TTTok(_, token::LIT_STR_RAW(description, _))] => {\n+        [ast::TTToken(_, token::IDENT(ref code, _)),\n+         ast::TTToken(_, token::COMMA),\n+         ast::TTToken(_, token::LIT_STR_RAW(description, _))] => {\n             (code, Some(description))\n         }\n         _ => unreachable!()\n@@ -110,7 +110,7 @@ pub fn expand_build_diagnostic_array<'cx>(ecx: &'cx mut ExtCtxt,\n                                           token_tree: &[TokenTree])\n                                           -> Box<MacResult+'cx> {\n     let name = match token_tree {\n-        [ast::TTTok(_, token::IDENT(ref name, _))] => name,\n+        [ast::TTToken(_, token::IDENT(ref name, _))] => name,\n         _ => unreachable!()\n     };\n "}, {"sha": "b5cc2d95890bb77f071d1d64d58973535ffa36ee", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -684,8 +684,8 @@ pub fn get_single_str_from_tts(cx: &ExtCtxt,\n         cx.span_err(sp, format!(\"{} takes 1 argument.\", name).as_slice());\n     } else {\n         match tts[0] {\n-            ast::TTTok(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n-            ast::TTTok(_, token::LIT_STR_RAW(ident, _)) => {\n+            ast::TTToken(_, token::LIT_STR(ident)) => return Some(parse::str_lit(ident.as_str())),\n+            ast::TTToken(_, token::LIT_STR_RAW(ident, _)) => {\n                 return Some(parse::raw_str_lit(ident.as_str()))\n             }\n             _ => {"}, {"sha": "e6befdd2aac9224190eedf6c4557ee1646f8f693", "filename": "src/libsyntax/ext/concat_idents.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fconcat_idents.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fconcat_idents.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -23,15 +23,15 @@ pub fn expand_syntax_ext<'cx>(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree]\n     for (i, e) in tts.iter().enumerate() {\n         if i & 1 == 1 {\n             match *e {\n-                ast::TTTok(_, token::COMMA) => (),\n+                ast::TTToken(_, token::COMMA) => (),\n                 _ => {\n                     cx.span_err(sp, \"concat_idents! expecting comma.\");\n                     return DummyResult::expr(sp);\n                 }\n             }\n         } else {\n             match *e {\n-                ast::TTTok(_, token::IDENT(ident,_)) => {\n+                ast::TTToken(_, token::IDENT(ident,_)) => {\n                     res_str.push_str(token::get_ident(ident).get())\n                 }\n                 _ => {"}, {"sha": "93bd66d6eeba6da690dad96de0e9519fa22c9d9a", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -639,10 +639,10 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n \n fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n-        ast::TTTok(sp, ref tok) => {\n+        ast::TTToken(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n             let e_tok = cx.expr_call(sp,\n-                                     mk_ast_path(cx, sp, \"TTTok\"),\n+                                     mk_ast_path(cx, sp, \"TTToken\"),\n                                      vec!(e_sp, mk_token(cx, sp, tok)));\n             let e_push =\n                 cx.expr_method_call(sp,\n@@ -651,14 +651,14 @@ fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                                     vec!(e_tok));\n             vec!(cx.stmt_expr(e_push))\n         },\n-        ast::TTDelim(sp, ref open, ref tts, ref close) => {\n+        ast::TTDelimited(sp, ref open, ref tts, ref close) => {\n             let mut stmts = vec![];\n             stmts.extend(mk_tt(cx, sp, &open.to_tt()).into_iter());\n             stmts.extend(tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()));\n             stmts.extend(mk_tt(cx, sp, &close.to_tt()).into_iter());\n             stmts\n         },\n-        ast::TTSeq(..) => fail!(\"TTSeq in quote!\"),\n+        ast::TTSequence(..) => fail!(\"TTSequence in quote!\"),\n         ast::TTNonterminal(sp, ident) => {\n             // tt.extend($ident.to_tokens(ext_cx).into_iter())\n "}, {"sha": "4c3846731f43209f15409a25c179c8602169cdc1", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -20,10 +20,10 @@ pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            tt: &[ast::TokenTree])\n                            -> Box<base::MacResult+'static> {\n     match tt {\n-        [ast::TTTok(_, ref tok)] if is_keyword(keywords::True, tok) => {\n+        [ast::TTToken(_, ref tok)] if is_keyword(keywords::True, tok) => {\n             cx.set_trace_macros(true);\n         }\n-        [ast::TTTok(_, ref tok)] if is_keyword(keywords::False, tok) => {\n+        [ast::TTToken(_, ref tok)] if is_keyword(keywords::False, tok) => {\n             cx.set_trace_macros(false);\n         }\n         _ => cx.span_err(sp, \"trace_macros! accepts only `true` or `false`\"),"}, {"sha": "4a3828a8043fb6301d36f9ad06c738906ca08e83", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TTDelim};\n+use ast::{Ident, Matcher_, Matcher, MatchTok, MatchNonterminal, MatchSeq, TTDelimited};\n use ast;\n use codemap::{Span, Spanned, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, MacroDef};\n@@ -172,7 +172,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n                             // ignore delimiters\n-                            TTDelim(_, _, ref tts, _) => (**tts).clone(),\n+                            TTDelimited(_, _, ref tts, _) => (**tts).clone(),\n                             _ => cx.span_fatal(sp, \"macro rhs must be delimited\"),\n                         }\n                     },"}, {"sha": "e705c4d8b33c770438ef2ba69e8ac127af5ec37d", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -9,7 +9,7 @@\n // except according to those terms.\n \n use ast;\n-use ast::{TokenTree, TTDelim, TTTok, TTSeq, TTNonterminal, Ident};\n+use ast::{TokenTree, TTDelimited, TTToken, TTSequence, TTNonterminal, Ident};\n use codemap::{Span, DUMMY_SP};\n use diagnostic::SpanHandler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n@@ -45,7 +45,7 @@ pub struct TtReader<'a> {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TTSeq`s and `TTNonterminal`s, `interp` can (and\n+/// `src` contains no `TTSequence`s and `TTNonterminal`s, `interp` can (and\n /// should) be none.\n pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n                          interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n@@ -130,12 +130,12 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n         // The opening and closing delimiters are both tokens, so they are\n         // treated as `LisUnconstrained`.\n-        TTDelim(_, _, ref tts, _) | TTSeq(_, ref tts, _, _) => {\n+        TTDelimited(_, _, ref tts, _) | TTSequence(_, ref tts, _, _) => {\n             tts.iter().fold(LisUnconstrained, |size, tt| {\n                 size + lockstep_iter_size(tt, r)\n             })\n         },\n-        TTTok(..) => LisUnconstrained,\n+        TTToken(..) => LisUnconstrained,\n         TTNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n             MatchedNonterminal(_) => LisUnconstrained,\n             MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name)\n@@ -194,15 +194,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             }\n         }\n     }\n-    loop { /* because it's easiest, this handles `TTDelim` not starting\n-              with a `TTTok`, even though it won't happen */\n+    loop { /* because it's easiest, this handles `TTDelimited` not starting\n+              with a `TTToken`, even though it won't happen */\n         let t = {\n             let frame = r.stack.last().unwrap();\n             // FIXME(pcwalton): Bad copy.\n             (*frame.forest)[frame.idx].clone()\n         };\n         match t {\n-            TTDelim(_, open, delimed_tts, close) => {\n+            TTDelimited(_, open, delimed_tts, close) => {\n                 let mut tts = vec![];\n                 tts.push(open.to_tt());\n                 tts.extend(delimed_tts.iter().map(|x| (*x).clone()));\n@@ -216,15 +216,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 });\n                 // if this could be 0-length, we'd need to potentially recur here\n             }\n-            TTTok(sp, tok) => {\n+            TTToken(sp, tok) => {\n                 r.cur_span = sp;\n                 r.cur_tok = tok;\n                 r.stack.last_mut().unwrap().idx += 1;\n                 return ret_val;\n             }\n-            TTSeq(sp, tts, sep, zerok) => {\n+            TTSequence(sp, tts, sep, zerok) => {\n                 // FIXME(pcwalton): Bad copy.\n-                match lockstep_iter_size(&TTSeq(sp, tts.clone(), sep.clone(), zerok), r) {\n+                match lockstep_iter_size(&TTSequence(sp, tts.clone(), sep.clone(), zerok), r) {\n                     LisUnconstrained => {\n                         r.sp_diag.span_fatal(\n                             sp.clone(), /* blame macro writer */"}, {"sha": "9cffce74a095a0f13412cd5bf3c5b6ba9db5b121", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -569,24 +569,24 @@ pub fn noop_fold_arg<T: Folder>(Arg {id, pat, ty}: Arg, fld: &mut T) -> Arg {\n \n pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n     match *tt {\n-        TTTok(span, ref tok) =>\n-            TTTok(span, fld.fold_token(tok.clone())),\n-        TTDelim(span, ref open, ref tts, ref close) =>\n-            TTDelim(span,\n-                    Delimiter {\n-                        span: open.span,\n-                        token: fld.fold_token(open.token.clone())\n-                    },\n-                    Rc::new(fld.fold_tts(tts.as_slice())),\n-                    Delimiter {\n-                        span: close.span,\n-                        token: fld.fold_token(close.token.clone())\n-                    }),\n-        TTSeq(span, ref pattern, ref sep, is_optional) =>\n-            TTSeq(span,\n-                  Rc::new(fld.fold_tts(pattern.as_slice())),\n-                  sep.clone().map(|tok| fld.fold_token(tok)),\n-                  is_optional),\n+        TTToken(span, ref tok) =>\n+            TTToken(span, fld.fold_token(tok.clone())),\n+        TTDelimited(span, ref open, ref tts, ref close) =>\n+            TTDelimited(span,\n+                        Delimiter {\n+                            span: open.span,\n+                            token: fld.fold_token(open.token.clone())\n+                        },\n+                        Rc::new(fld.fold_tts(tts.as_slice())),\n+                        Delimiter {\n+                            span: close.span,\n+                            token: fld.fold_token(close.token.clone())\n+                        }),\n+        TTSequence(span, ref pattern, ref sep, is_optional) =>\n+            TTSequence(span,\n+                       Rc::new(fld.fold_tts(pattern.as_slice())),\n+                       sep.clone().map(|tok| fld.fold_token(tok)),\n+                       is_optional),\n         TTNonterminal(sp,ref ident) =>\n             TTNonterminal(sp,fld.fold_ident(*ident))\n     }"}, {"sha": "a2e4028232100653cf1288dfdec72fcd664becd3", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -793,29 +793,29 @@ mod test {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n-            [ast::TTTok(_, _),\n-             ast::TTTok(_, token::NOT),\n-             ast::TTTok(_, _),\n-             ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+            [ast::TTToken(_, _),\n+             ast::TTToken(_, token::NOT),\n+             ast::TTToken(_, _),\n+             ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n                           ref delim_elts,\n-                          ast::TTTok(_, token::RPAREN))] => {\n+                          ast::TTToken(_, token::RPAREN))] => {\n                 let delim_elts: &[ast::TokenTree] = delim_elts.as_slice();\n                 match delim_elts {\n-                    [ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+                    [ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n                                   ref first_set,\n-                                  ast::TTTok(_, token::RPAREN)),\n-                     ast::TTTok(_, token::FAT_ARROW),\n-                     ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+                                  ast::TTToken(_, token::RPAREN)),\n+                     ast::TTToken(_, token::FAT_ARROW),\n+                     ast::TTDelimited(_, ast::TTToken(_, token::LPAREN),\n                                   ref second_set,\n-                                  ast::TTTok(_, token::RPAREN))] => {\n+                                  ast::TTToken(_, token::RPAREN))] => {\n                         let first_set: &[ast::TokenTree] =\n                             first_set.as_slice();\n                         match first_set {\n-                            [ast::TTTok(_, token::DOLLAR), ast::TTTok(_, _)] => {\n+                            [ast::TTToken(_, token::DOLLAR), ast::TTToken(_, _)] => {\n                                 let second_set: &[ast::TokenTree] =\n                                     second_set.as_slice();\n                                 match second_set {\n-                                    [ast::TTTok(_, token::DOLLAR), ast::TTTok(_, _)] => {\n+                                    [ast::TTToken(_, token::DOLLAR), ast::TTToken(_, _)] => {\n                                         assert_eq!(\"correct\",\"correct\")\n                                     }\n                                     _ => assert_eq!(\"wrong 4\",\"correct\")\n@@ -845,7 +845,7 @@ mod test {\n         assert_eq!(json::encode(&tts),\n         \"[\\\n     {\\\n-        \\\"variant\\\":\\\"TTTok\\\",\\\n+        \\\"variant\\\":\\\"TTToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -858,7 +858,7 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTTok\\\",\\\n+        \\\"variant\\\":\\\"TTToken\\\",\\\n         \\\"fields\\\":[\\\n             null,\\\n             {\\\n@@ -871,18 +871,18 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelim\\\",\\\n+        \\\"variant\\\":\\\"TTDelimited\\\",\\\n         \\\"fields\\\":[\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"LPAREN\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -895,14 +895,14 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"COLON\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -915,7 +915,7 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"RPAREN\\\"\\\n@@ -925,18 +925,18 @@ mod test {\n         ]\\\n     },\\\n     {\\\n-        \\\"variant\\\":\\\"TTDelim\\\",\\\n+        \\\"variant\\\":\\\"TTDelimited\\\",\\\n         \\\"fields\\\":[\\\n             [\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"LBRACE\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         {\\\n@@ -949,14 +949,14 @@ mod test {\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"SEMI\\\"\\\n                     ]\\\n                 },\\\n                 {\\\n-                    \\\"variant\\\":\\\"TTTok\\\",\\\n+                    \\\"variant\\\":\\\"TTToken\\\",\\\n                     \\\"fields\\\":[\\\n                         null,\\\n                         \\\"RBRACE\\\"\\"}, {"sha": "1ed7baa13b42dfc564eb9c4f39bd54565e68205a", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -48,7 +48,7 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TTDelim, TTSeq, TTTok};\n+use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TTDelimited, TTSequence, TTToken};\n use ast::{TTNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n@@ -2526,7 +2526,7 @@ impl<'a> Parser<'a> {\n     /// parse a single token tree from the input.\n     pub fn parse_token_tree(&mut self) -> TokenTree {\n         // FIXME #6994: currently, this is too eager. It\n-        // parses token trees but also identifies TTSeq's\n+        // parses token trees but also identifies TTSequence's\n         // and TTNonterminal's; it's too early to know yet\n         // whether something will be a nonterminal or a seq\n         // yet.\n@@ -2568,13 +2568,13 @@ impl<'a> Parser<'a> {\n                     let seq = match seq {\n                         Spanned { node, .. } => node,\n                     };\n-                    TTSeq(mk_sp(sp.lo, p.span.hi), Rc::new(seq), s, z)\n+                    TTSequence(mk_sp(sp.lo, p.span.hi), Rc::new(seq), s, z)\n                 } else {\n                     TTNonterminal(sp, p.parse_ident())\n                 }\n               }\n               _ => {\n-                  TTTok(p.span, p.bump_and_get())\n+                  TTToken(p.span, p.bump_and_get())\n               }\n             }\n         }\n@@ -2615,7 +2615,7 @@ impl<'a> Parser<'a> {\n                 // Expand to cover the entire delimited token tree\n                 let span = Span { hi: self.span.hi, ..pre_span };\n \n-                TTDelim(span, open, Rc::new(tts), close)\n+                TTDelimited(span, open, Rc::new(tts), close)\n             }\n             _ => parse_non_delim_tt_tok(self)\n         }"}, {"sha": "9a102d229718f674021798b4a8323297c01418b0", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -1020,14 +1020,14 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n-            ast::TTDelim(_, ref open, ref tts, ref close) => {\n+            ast::TTDelimited(_, ref open, ref tts, ref close) => {\n                 try!(word(&mut self.s, parse::token::to_string(&open.token).as_slice()));\n                 try!(space(&mut self.s));\n                 try!(self.print_tts(tts.as_slice()));\n                 try!(space(&mut self.s));\n                 word(&mut self.s, parse::token::to_string(&close.token).as_slice())\n             },\n-            ast::TTTok(_, ref tk) => {\n+            ast::TTToken(_, ref tk) => {\n                 try!(word(&mut self.s, parse::token::to_string(tk).as_slice()));\n                 match *tk {\n                     parse::token::DOC_COMMENT(..) => {\n@@ -1036,7 +1036,7 @@ impl<'a> State<'a> {\n                     _ => Ok(())\n                 }\n             }\n-            ast::TTSeq(_, ref tts, ref sep, zerok) => {\n+            ast::TTSequence(_, ref tts, ref sep, zerok) => {\n                 try!(word(&mut self.s, \"$(\"));\n                 for tt_elt in (*tts).iter() {\n                     try!(self.print_tt(tt_elt));"}, {"sha": "0d5abb8fb5dd9bd1cd414ca7822c734ef755f3c5", "filename": "src/test/auxiliary/roman_numerals.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ec3f0201e76b5cf689f3e8e6418435c3e6d9271c/src%2Ftest%2Fauxiliary%2Froman_numerals.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Froman_numerals.rs?ref=ec3f0201e76b5cf689f3e8e6418435c3e6d9271c", "patch": "@@ -18,7 +18,7 @@ extern crate rustc;\n \n use syntax::codemap::Span;\n use syntax::parse::token::{IDENT, get_ident};\n-use syntax::ast::{TokenTree, TTTok};\n+use syntax::ast::{TokenTree, TTToken};\n use syntax::ext::base::{ExtCtxt, MacResult, DummyResult, MacExpr};\n use syntax::ext::build::AstBuilder;  // trait for expr_uint\n use rustc::plugin::Registry;\n@@ -39,7 +39,7 @@ fn expand_rn(cx: &mut ExtCtxt, sp: Span, args: &[TokenTree])\n         (\"I\",    1)];\n \n     let text = match args {\n-        [TTTok(_, IDENT(s, _))] => get_ident(s).to_string(),\n+        [TTToken(_, IDENT(s, _))] => get_ident(s).to_string(),\n         _ => {\n             cx.span_err(sp, \"argument should be a single identifier\");\n             return DummyResult::any(sp);"}]}