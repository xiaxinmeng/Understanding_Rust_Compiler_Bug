{"sha": "ff36986fa490917bcacfb4e5010e304d5e82f3bb", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZmMzY5ODZmYTQ5MDkxN2JjYWNmYjRlNTAxMGUzMDRkNWU4MmYzYmI=", "commit": {"author": {"name": "Erick Tryzelaar", "email": "erick.tryzelaar@gmail.com", "date": "2013-02-25T01:24:28Z"}, "committer": {"name": "Erick Tryzelaar", "email": "erick.tryzelaar@gmail.com", "date": "2013-02-26T09:51:41Z"}, "message": "libsyntax: change token fns to take &Token", "tree": {"sha": "be4693995dd53f90fb1c720628669167e1e54052", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/be4693995dd53f90fb1c720628669167e1e54052"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ff36986fa490917bcacfb4e5010e304d5e82f3bb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ff36986fa490917bcacfb4e5010e304d5e82f3bb", "html_url": "https://github.com/rust-lang/rust/commit/ff36986fa490917bcacfb4e5010e304d5e82f3bb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ff36986fa490917bcacfb4e5010e304d5e82f3bb/comments", "author": {"login": "erickt", "id": 84711, "node_id": "MDQ6VXNlcjg0NzEx", "avatar_url": "https://avatars.githubusercontent.com/u/84711?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erickt", "html_url": "https://github.com/erickt", "followers_url": "https://api.github.com/users/erickt/followers", "following_url": "https://api.github.com/users/erickt/following{/other_user}", "gists_url": "https://api.github.com/users/erickt/gists{/gist_id}", "starred_url": "https://api.github.com/users/erickt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erickt/subscriptions", "organizations_url": "https://api.github.com/users/erickt/orgs", "repos_url": "https://api.github.com/users/erickt/repos", "events_url": "https://api.github.com/users/erickt/events{/privacy}", "received_events_url": "https://api.github.com/users/erickt/received_events", "type": "User", "site_admin": false}, "committer": {"login": "erickt", "id": 84711, "node_id": "MDQ6VXNlcjg0NzEx", "avatar_url": "https://avatars.githubusercontent.com/u/84711?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erickt", "html_url": "https://github.com/erickt", "followers_url": "https://api.github.com/users/erickt/followers", "following_url": "https://api.github.com/users/erickt/following{/other_user}", "gists_url": "https://api.github.com/users/erickt/gists{/gist_id}", "starred_url": "https://api.github.com/users/erickt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erickt/subscriptions", "organizations_url": "https://api.github.com/users/erickt/orgs", "repos_url": "https://api.github.com/users/erickt/repos", "events_url": "https://api.github.com/users/erickt/events{/privacy}", "received_events_url": "https://api.github.com/users/erickt/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d346b51997a4a5d9f2e85aa41fc3113338b8a83b", "url": "https://api.github.com/repos/rust-lang/rust/commits/d346b51997a4a5d9f2e85aa41fc3113338b8a83b", "html_url": "https://github.com/rust-lang/rust/commit/d346b51997a4a5d9f2e85aa41fc3113338b8a83b"}], "stats": {"total": 78, "additions": 39, "deletions": 39}, "files": [{"sha": "4960563db8875bb88f0a8e9323084f27856ef350", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=ff36986fa490917bcacfb4e5010e304d5e82f3bb", "patch": "@@ -354,7 +354,7 @@ pub fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n         rdr.next_token();\n         //discard, and look ahead; we're working with internal state\n         let TokenAndSpan {tok: tok, sp: sp} = rdr.peek();\n-        if token::is_lit(tok) {\n+        if token::is_lit(&tok) {\n             let s = get_str_from(rdr, bstart);\n             literals.push(lit {lit: s, pos: sp.lo});\n             log(debug, ~\"tok lit: \" + s);"}, {"sha": "a522612794740ef30afc53a58c7fa27325460408", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=ff36986fa490917bcacfb4e5010e304d5e82f3bb", "patch": "@@ -656,7 +656,7 @@ pub impl Parser {\n         } else if self.token_is_closure_keyword(&copy *self.token) {\n             self.parse_ty_closure(None, None)\n         } else if *self.token == token::MOD_SEP\n-            || is_ident_or_path(*self.token) {\n+            || is_ident_or_path(&*self.token) {\n             let path = self.parse_path_with_tps(colons_before_params);\n             ty_path(path, self.get_id())\n         } else {\n@@ -760,10 +760,10 @@ pub impl Parser {\n             }\n         } else { 0 };\n         if offset == 0 {\n-            is_plain_ident(*self.token)\n+            is_plain_ident(&*self.token)\n                 && self.look_ahead(1) == token::COLON\n         } else {\n-            is_plain_ident(self.look_ahead(offset))\n+            is_plain_ident(&self.look_ahead(offset))\n                 && self.look_ahead(offset + 1) == token::COLON\n         }\n     }\n@@ -1141,7 +1141,7 @@ pub impl Parser {\n                 return self.mk_expr(blk.span.lo, blk.span.hi,\n                                      expr_block(blk));\n             }\n-        } else if token::is_bar(*self.token) {\n+        } else if token::is_bar(&*self.token) {\n             return self.parse_lambda_expr();\n         } else if self.eat_keyword(&~\"if\") {\n             return self.parse_if_expr();\n@@ -1215,13 +1215,13 @@ pub impl Parser {\n             ex = expr_assert(e);\n             hi = e.span.hi;\n         } else if self.eat_keyword(&~\"return\") {\n-            if can_begin_expr(*self.token) {\n+            if can_begin_expr(&*self.token) {\n                 let e = self.parse_expr();\n                 hi = e.span.hi;\n                 ex = expr_ret(Some(e));\n             } else { ex = expr_ret(None); }\n         } else if self.eat_keyword(&~\"break\") {\n-            if is_ident(*self.token) {\n+            if is_ident(&*self.token) {\n                 ex = expr_break(Some(self.parse_ident()));\n             } else {\n                 ex = expr_break(None);\n@@ -1232,7 +1232,7 @@ pub impl Parser {\n             ex = expr_copy(e);\n             hi = e.span.hi;\n         } else if *self.token == token::MOD_SEP ||\n-                is_ident(*self.token) && !self.is_keyword(&~\"true\") &&\n+                is_ident(&*self.token) && !self.is_keyword(&~\"true\") &&\n                 !self.is_keyword(&~\"false\") {\n             let pth = self.parse_path_with_tps(true);\n \n@@ -1914,11 +1914,11 @@ pub impl Parser {\n         // loop headers look like 'loop {' or 'loop unsafe {'\n         let is_loop_header =\n             *self.token == token::LBRACE\n-            || (is_ident(*self.token)\n+            || (is_ident(&*self.token)\n                 && self.look_ahead(1) == token::LBRACE);\n         // labeled loop headers look like 'loop foo: {'\n         let is_labeled_loop_header =\n-            is_ident(*self.token)\n+            is_ident(&*self.token)\n             && !self.is_any_keyword(&copy *self.token)\n             && self.look_ahead(1) == token::COLON;\n \n@@ -1939,7 +1939,7 @@ pub impl Parser {\n         } else {\n             // This is a 'continue' expression\n             let lo = self.span.lo;\n-            let ex = if is_ident(*self.token) {\n+            let ex = if is_ident(&*self.token) {\n                 expr_again(Some(self.parse_ident()))\n             } else {\n                 expr_again(None)\n@@ -1954,7 +1954,7 @@ pub impl Parser {\n         let lookahead = self.look_ahead(1);\n         *self.token == token::LBRACE &&\n             (self.token_is_keyword(&~\"mut\", &lookahead) ||\n-             (is_plain_ident(lookahead) &&\n+             (is_plain_ident(&lookahead) &&\n               self.look_ahead(2) == token::COLON))\n     }\n \n@@ -2260,7 +2260,7 @@ pub impl Parser {\n             pat = ast::pat_vec(elements, tail);\n           }\n           copy tok => {\n-            if !is_ident_or_path(tok)\n+            if !is_ident_or_path(&tok)\n                 || self.is_keyword(&~\"true\")\n                 || self.is_keyword(&~\"false\")\n             {\n@@ -2290,7 +2290,7 @@ pub impl Parser {\n                         cannot_be_enum_or_struct = true\n                 }\n \n-                if is_plain_ident(*self.token) && cannot_be_enum_or_struct {\n+                if is_plain_ident(&*self.token) && cannot_be_enum_or_struct {\n                     let name = self.parse_value_path();\n                     let sub;\n                     if self.eat(&token::AT) {\n@@ -2359,7 +2359,7 @@ pub impl Parser {\n \n     fn parse_pat_ident(refutable: bool,\n                        binding_mode: ast::binding_mode) -> ast::pat_ {\n-        if !is_plain_ident(*self.token) {\n+        if !is_plain_ident(&*self.token) {\n             self.span_fatal(\n                 *self.last_span,\n                 ~\"expected identifier, found path\");\n@@ -2425,7 +2425,7 @@ pub impl Parser {\n         if self.eat_keyword(&~\"mut\") {\n             is_mutbl = struct_mutable;\n         }\n-        if !is_plain_ident(*self.token) {\n+        if !is_plain_ident(&*self.token) {\n             self.fatal(~\"expected ident\");\n         }\n         let name = self.parse_ident();\n@@ -2454,7 +2454,7 @@ pub impl Parser {\n             self.expect_keyword(&~\"let\");\n             let decl = self.parse_let();\n             return @spanned(lo, decl.span.hi, stmt_decl(decl, self.get_id()));\n-        } else if is_ident(*self.token)\n+        } else if is_ident(&*self.token)\n             && !self.is_any_keyword(&copy *self.token)\n             && self.look_ahead(1) == token::NOT {\n \n@@ -2716,7 +2716,7 @@ pub impl Parser {\n                                       ~\"`&static` is the only permissible \\\n                                         region bound here\");\n                     }\n-                } else if is_ident(*self.token) {\n+                } else if is_ident(&*self.token) {\n                     let maybe_bound = match *self.token {\n                       token::IDENT(copy sid, _) => {\n                         match *self.id_to_str(sid) {\n@@ -2757,7 +2757,7 @@ pub impl Parser {\n                     loop;\n                 }\n \n-                if is_ident_or_path(*self.token) {\n+                if is_ident_or_path(&*self.token) {\n                     self.obsolete(*self.span,\n                                   ObsoleteTraitBoundSeparator);\n                 }\n@@ -3987,7 +3987,7 @@ pub impl Parser {\n             });\n         } else if macros_allowed && !self.is_any_keyword(&copy *self.token)\n                 && self.look_ahead(1) == token::NOT\n-                && (is_plain_ident(self.look_ahead(2))\n+                && (is_plain_ident(&self.look_ahead(2))\n                     || self.look_ahead(2) == token::LPAREN\n                     || self.look_ahead(2) == token::LBRACE) {\n             // MACRO INVOCATION ITEM\n@@ -4002,7 +4002,7 @@ pub impl Parser {\n             // a 'special' identifier (like what `macro_rules!` uses)\n             // is optional. We should eventually unify invoc syntax\n             // and remove this.\n-            let id = if is_plain_ident(*self.token) {\n+            let id = if is_plain_ident(&*self.token) {\n                 self.parse_ident()\n             } else {\n                 token::special_idents::invalid // no special identifier"}, {"sha": "bb1f8f1d1d9a2fe9565f612e1d3a4159df711c2c", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ff36986fa490917bcacfb4e5010e304d5e82f3bb/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=ff36986fa490917bcacfb4e5010e304d5e82f3bb", "patch": "@@ -225,8 +225,8 @@ pub fn to_str(in: @ident_interner, t: &Token) -> ~str {\n     }\n }\n \n-pub pure fn can_begin_expr(t: Token) -> bool {\n-    match t {\n+pub pure fn can_begin_expr(t: &Token) -> bool {\n+    match *t {\n       LPAREN => true,\n       LBRACE => true,\n       LBRACKET => true,\n@@ -259,20 +259,20 @@ pub pure fn can_begin_expr(t: Token) -> bool {\n /// what's the opposite delimiter?\n pub fn flip_delimiter(t: &token::Token) -> token::Token {\n     match *t {\n-      token::LPAREN => token::RPAREN,\n-      token::LBRACE => token::RBRACE,\n-      token::LBRACKET => token::RBRACKET,\n-      token::RPAREN => token::LPAREN,\n-      token::RBRACE => token::LBRACE,\n-      token::RBRACKET => token::LBRACKET,\n+      LPAREN => RPAREN,\n+      LBRACE => RBRACE,\n+      LBRACKET => RBRACKET,\n+      RPAREN => LPAREN,\n+      RBRACE => LBRACE,\n+      RBRACKET => LBRACKET,\n       _ => fail!()\n     }\n }\n \n \n \n-pub fn is_lit(t: Token) -> bool {\n-    match t {\n+pub fn is_lit(t: &Token) -> bool {\n+    match *t {\n       LIT_INT(_, _) => true,\n       LIT_UINT(_, _) => true,\n       LIT_INT_UNSUFFIXED(_) => true,\n@@ -283,23 +283,23 @@ pub fn is_lit(t: Token) -> bool {\n     }\n }\n \n-pub pure fn is_ident(t: Token) -> bool {\n-    match t { IDENT(_, _) => true, _ => false }\n+pub pure fn is_ident(t: &Token) -> bool {\n+    match *t { IDENT(_, _) => true, _ => false }\n }\n \n-pub pure fn is_ident_or_path(t: Token) -> bool {\n-    match t {\n+pub pure fn is_ident_or_path(t: &Token) -> bool {\n+    match *t {\n       IDENT(_, _) | INTERPOLATED(nt_path(*)) => true,\n       _ => false\n     }\n }\n \n-pub pure fn is_plain_ident(t: Token) -> bool {\n-    match t { IDENT(_, false) => true, _ => false }\n+pub pure fn is_plain_ident(t: &Token) -> bool {\n+    match *t { IDENT(_, false) => true, _ => false }\n }\n \n-pub pure fn is_bar(t: Token) -> bool {\n-    match t { BINOP(OR) | OROR => true, _ => false }\n+pub pure fn is_bar(t: &Token) -> bool {\n+    match *t { BINOP(OR) | OROR => true, _ => false }\n }\n \n "}]}