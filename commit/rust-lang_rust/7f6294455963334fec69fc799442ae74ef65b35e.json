{"sha": "7f6294455963334fec69fc799442ae74ef65b35e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdmNjI5NDQ1NTk2MzMzNGZlYzY5ZmM3OTk0NDJhZTc0ZWY2NWIzNWU=", "commit": {"author": {"name": "Marijn Haverbeke", "email": "marijnh@gmail.com", "date": "2012-01-13T08:56:53Z"}, "committer": {"name": "Marijn Haverbeke", "email": "marijnh@gmail.com", "date": "2012-01-13T10:50:53Z"}, "message": "Convert the objects used in the lexer and parser to records + impls", "tree": {"sha": "8c5b7ab38389dc6e4afcbfe4943bc432c6192846", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8c5b7ab38389dc6e4afcbfe4943bc432c6192846"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7f6294455963334fec69fc799442ae74ef65b35e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7f6294455963334fec69fc799442ae74ef65b35e", "html_url": "https://github.com/rust-lang/rust/commit/7f6294455963334fec69fc799442ae74ef65b35e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7f6294455963334fec69fc799442ae74ef65b35e/comments", "author": {"login": "marijnh", "id": 144427, "node_id": "MDQ6VXNlcjE0NDQyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/144427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marijnh", "html_url": "https://github.com/marijnh", "followers_url": "https://api.github.com/users/marijnh/followers", "following_url": "https://api.github.com/users/marijnh/following{/other_user}", "gists_url": "https://api.github.com/users/marijnh/gists{/gist_id}", "starred_url": "https://api.github.com/users/marijnh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marijnh/subscriptions", "organizations_url": "https://api.github.com/users/marijnh/orgs", "repos_url": "https://api.github.com/users/marijnh/repos", "events_url": "https://api.github.com/users/marijnh/events{/privacy}", "received_events_url": "https://api.github.com/users/marijnh/received_events", "type": "User", "site_admin": false}, "committer": {"login": "marijnh", "id": 144427, "node_id": "MDQ6VXNlcjE0NDQyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/144427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marijnh", "html_url": "https://github.com/marijnh", "followers_url": "https://api.github.com/users/marijnh/followers", "following_url": "https://api.github.com/users/marijnh/following{/other_user}", "gists_url": "https://api.github.com/users/marijnh/gists{/gist_id}", "starred_url": "https://api.github.com/users/marijnh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marijnh/subscriptions", "organizations_url": "https://api.github.com/users/marijnh/orgs", "repos_url": "https://api.github.com/users/marijnh/repos", "events_url": "https://api.github.com/users/marijnh/events{/privacy}", "received_events_url": "https://api.github.com/users/marijnh/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0616cba62be78082f10f6673d45ba4d94da423dc", "url": "https://api.github.com/repos/rust-lang/rust/commits/0616cba62be78082f10f6673d45ba4d94da423dc", "html_url": "https://github.com/rust-lang/rust/commit/0616cba62be78082f10f6673d45ba4d94da423dc"}], "stats": {"total": 919, "additions": 435, "deletions": 484}, "files": [{"sha": "4e3f2711a2f6a4dfa9929ce7590d63c3e561fb2a", "filename": "src/comp/syntax/parse/eval.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Feval.rs?ref=7f6294455963334fec69fc799442ae74ef65b35e", "patch": "@@ -80,8 +80,8 @@ fn parse_companion_mod(cx: ctx, prefix: str, suffix: option::t<str>)\n         let inner_attrs = parse_inner_attrs_and_next(p0);\n         let first_item_outer_attrs = inner_attrs.next;\n         let m0 = parse_mod_items(p0, token::EOF, first_item_outer_attrs);\n-        cx.chpos = p0.get_chpos();\n-        cx.byte_pos = p0.get_byte_pos();\n+        cx.chpos = p0.reader.chpos;\n+        cx.byte_pos = p0.reader.pos;\n         ret (m0.view_items, m0.items, inner_attrs.inner);\n     } else {\n         ret ([], [], []);\n@@ -119,8 +119,8 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: str,\n             syntax::parse::parser::mk_item(p0, cdir.span.lo, cdir.span.hi, id,\n                                            ast::item_mod(m0), mod_attrs);\n         // Thread defids, chpos and byte_pos through the parsers\n-        cx.chpos = p0.get_chpos();\n-        cx.byte_pos = p0.get_byte_pos();\n+        cx.chpos = p0.reader.chpos;\n+        cx.byte_pos = p0.reader.pos;\n         items += [i];\n       }\n       ast::cdir_dir_mod(id, cdirs, attrs) {"}, {"sha": "b0b1cd76d87a5075df4d5340fe448e36973339fb", "filename": "src/comp/syntax/parse/lexer.rs", "status": "modified", "additions": 115, "deletions": 133, "changes": 248, "blob_url": "https://github.com/rust-lang/rust/blob/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Flexer.rs?ref=7f6294455963334fec69fc799442ae74ef65b35e", "patch": "@@ -7,81 +7,63 @@ import util::interner;\n import util::interner::intern;\n import codemap;\n \n-type reader =\n-    obj {\n-        fn is_eof() -> bool;\n-        fn curr() -> char;\n-        fn next() -> char;\n-        fn init();\n-        fn bump();\n-        fn get_str_from(uint) -> str;\n-        fn get_interner() -> @interner::interner<str>;\n-        fn get_chpos() -> uint;\n-        fn get_byte_pos() -> uint;\n-        fn get_col() -> uint;\n-        fn get_filemap() -> codemap::filemap;\n-        fn err(str);\n-    };\n+type reader = @{\n+    cm: codemap::codemap,\n+    src: str,\n+    len: uint,\n+    mutable col: uint,\n+    mutable pos: uint,\n+    mutable curr: char,\n+    mutable chpos: uint,\n+    mutable strs: [str],\n+    filemap: codemap::filemap,\n+    interner: @interner::interner<str>\n+};\n+\n+impl reader for reader {\n+    fn is_eof() -> bool { self.curr == -1 as char }\n+    fn get_str_from(start: uint) -> str {\n+        // I'm pretty skeptical about this subtraction. What if there's a\n+        // multi-byte character before the mark?\n+        ret str::slice(self.src, start - 1u, self.pos - 1u);\n+    }\n+    fn next() -> char {\n+        if self.pos < self.len {\n+            ret str::char_at(self.src, self.pos);\n+        } else { ret -1 as char; }\n+    }\n+    fn bump() {\n+        if self.pos < self.len {\n+            self.col += 1u;\n+            self.chpos += 1u;\n+            if self.curr == '\\n' {\n+                codemap::next_line(self.filemap, self.chpos, self.pos +\n+                                   self.filemap.start_pos.byte);\n+                self.col = 0u;\n+            }\n+            let next = str::char_range_at(self.src, self.pos);\n+            self.pos = next.next;\n+            self.curr = next.ch;\n+        } else { self.curr = -1 as char; }\n+    }\n+    fn err(m: str) {\n+        codemap::emit_error(some(ast_util::mk_sp(self.chpos, self.chpos)),\n+                            m, self.cm);\n+    }\n+}\n \n fn new_reader(cm: codemap::codemap, src: str, filemap: codemap::filemap,\n               itr: @interner::interner<str>) -> reader {\n-    obj reader(cm: codemap::codemap,\n-               src: str,\n-               len: uint,\n-               mutable col: uint,\n-               mutable pos: uint,\n-               mutable ch: char,\n-               mutable chpos: uint,\n-               mutable strs: [str],\n-               fm: codemap::filemap,\n-               itr: @interner::interner<str>) {\n-        fn is_eof() -> bool { ret ch == -1 as char; }\n-        fn get_str_from(start: uint) -> str {\n-            // I'm pretty skeptical about this subtraction. What if there's a\n-            // multi-byte character before the mark?\n-            ret str::slice(src, start - 1u, pos - 1u);\n-        }\n-        fn get_chpos() -> uint { ret chpos; }\n-        fn get_byte_pos() -> uint { ret pos; }\n-        fn curr() -> char { ret ch; }\n-        fn next() -> char {\n-            if pos < len {\n-                ret str::char_at(src, pos);\n-            } else { ret -1 as char; }\n-        }\n-        fn init() {\n-            if pos < len {\n-                let next = str::char_range_at(src, pos);\n-                pos = next.next;\n-                ch = next.ch;\n-            }\n-        }\n-        fn bump() {\n-            if pos < len {\n-                col += 1u;\n-                chpos += 1u;\n-                if ch == '\\n' {\n-                    codemap::next_line(fm, chpos, pos + fm.start_pos.byte);\n-                    col = 0u;\n-                }\n-                let next = str::char_range_at(src, pos);\n-                pos = next.next;\n-                ch = next.ch;\n-            } else { ch = -1 as char; }\n-        }\n-        fn get_interner() -> @interner::interner<str> { ret itr; }\n-        fn get_col() -> uint { ret col; }\n-        fn get_filemap() -> codemap::filemap { ret fm; }\n-        fn err(m: str) {\n-            codemap::emit_error(some(ast_util::mk_sp(chpos, chpos)), m, cm);\n-        }\n+    let r = @{cm: cm, src: src, len: str::byte_len(src),\n+              mutable col: 0u, mutable pos: 0u, mutable curr: -1 as char,\n+              mutable chpos: filemap.start_pos.ch, mutable strs: [],\n+              filemap: filemap, interner: itr};\n+    if r.pos < r.len {\n+        let next = str::char_range_at(r.src, r.pos);\n+        r.pos = next.next;\n+        r.curr = next.ch;\n     }\n-    let strs: [str] = [];\n-    let rd =\n-        reader(cm, src, str::byte_len(src), 0u, 0u, -1 as char,\n-               filemap.start_pos.ch, strs, filemap, itr);\n-    rd.init();\n-    ret rd;\n+    ret r;\n }\n \n fn dec_digit_val(c: char) -> int { ret (c as int) - ('0' as int); }\n@@ -119,15 +101,15 @@ fn is_hex_digit(c: char) -> bool {\n fn is_bin_digit(c: char) -> bool { ret c == '0' || c == '1'; }\n \n fn consume_whitespace_and_comments(rdr: reader) {\n-    while is_whitespace(rdr.curr()) { rdr.bump(); }\n+    while is_whitespace(rdr.curr) { rdr.bump(); }\n     be consume_any_line_comment(rdr);\n }\n \n fn consume_any_line_comment(rdr: reader) {\n-    if rdr.curr() == '/' {\n+    if rdr.curr == '/' {\n         alt rdr.next() {\n           '/' {\n-            while rdr.curr() != '\\n' && !rdr.is_eof() { rdr.bump(); }\n+            while rdr.curr != '\\n' && !rdr.is_eof() { rdr.bump(); }\n             // Restart whitespace munch.\n \n             be consume_whitespace_and_comments(rdr);\n@@ -142,12 +124,12 @@ fn consume_block_comment(rdr: reader) {\n     let level: int = 1;\n     while level > 0 {\n         if rdr.is_eof() { rdr.err(\"unterminated block comment\"); fail; }\n-        if rdr.curr() == '/' && rdr.next() == '*' {\n+        if rdr.curr == '/' && rdr.next() == '*' {\n             rdr.bump();\n             rdr.bump();\n             level += 1;\n         } else {\n-            if rdr.curr() == '*' && rdr.next() == '/' {\n+            if rdr.curr == '*' && rdr.next() == '/' {\n                 rdr.bump();\n                 rdr.bump();\n                 level -= 1;\n@@ -160,12 +142,12 @@ fn consume_block_comment(rdr: reader) {\n }\n \n fn scan_exponent(rdr: reader) -> option::t<str> {\n-    let c = rdr.curr();\n+    let c = rdr.curr;\n     let rslt = \"\";\n     if c == 'e' || c == 'E' {\n         str::push_byte(rslt, c as u8);\n         rdr.bump();\n-        c = rdr.curr();\n+        c = rdr.curr;\n         if c == '-' || c == '+' {\n             str::push_byte(rslt, c as u8);\n             rdr.bump();\n@@ -180,7 +162,7 @@ fn scan_exponent(rdr: reader) -> option::t<str> {\n fn scan_digits(rdr: reader, radix: uint) -> str {\n     let rslt = \"\";\n     while true {\n-        let c = rdr.curr();\n+        let c = rdr.curr;\n         if c == '_' { rdr.bump(); cont; }\n         alt char::maybe_digit(c) {\n           some(d) if (d as uint) < radix {\n@@ -205,13 +187,13 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n         base = 2u;\n     }\n     num_str = scan_digits(rdr, base);\n-    c = rdr.curr();\n+    c = rdr.curr;\n     n = rdr.next();\n     if c == 'u' || c == 'i' {\n         let signed = c == 'i', tp = signed ? either::left(ast::ty_i)\n                                            : either::right(ast::ty_u);\n         rdr.bump();\n-        c = rdr.curr();\n+        c = rdr.curr;\n         if c == '8' {\n             rdr.bump();\n             tp = signed ? either::left(ast::ty_i8)\n@@ -241,7 +223,7 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n         }\n     }\n     let is_float = false;\n-    if rdr.curr() == '.' && !(is_alpha(rdr.next()) || rdr.next() == '_') {\n+    if rdr.curr == '.' && !(is_alpha(rdr.next()) || rdr.next() == '_') {\n         is_float = true;\n         rdr.bump();\n         let dec_part = scan_digits(rdr, 10u);\n@@ -254,19 +236,19 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n       }\n       none. {}\n     }\n-    if rdr.curr() == 'f' {\n+    if rdr.curr == 'f' {\n         rdr.bump();\n-        c = rdr.curr();\n+        c = rdr.curr;\n         n = rdr.next();\n         if c == '3' && n == '2' {\n             rdr.bump();\n             rdr.bump();\n-            ret token::LIT_FLOAT(intern(*rdr.get_interner(), num_str),\n+            ret token::LIT_FLOAT(intern(*rdr.interner, num_str),\n                                  ast::ty_f32);\n         } else if c == '6' && n == '4' {\n             rdr.bump();\n             rdr.bump();\n-            ret token::LIT_FLOAT(intern(*rdr.get_interner(), num_str),\n+            ret token::LIT_FLOAT(intern(*rdr.interner, num_str),\n                                  ast::ty_f64);\n             /* FIXME: if this is out of range for either a 32-bit or\n             64-bit float, it won't be noticed till the back-end */\n@@ -275,7 +257,7 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n         }\n     }\n     if is_float {\n-        ret token::LIT_FLOAT(interner::intern(*rdr.get_interner(), num_str),\n+        ret token::LIT_FLOAT(interner::intern(*rdr.interner, num_str),\n                              ast::ty_f);\n     } else {\n         let parsed = u64::from_str(num_str, base as u64);\n@@ -286,7 +268,7 @@ fn scan_number(c: char, rdr: reader) -> token::token {\n fn scan_numeric_escape(rdr: reader, n_hex_digits: uint) -> char {\n     let accum_int = 0, i = n_hex_digits;\n     while i != 0u {\n-        let n = rdr.curr();\n+        let n = rdr.curr;\n         rdr.bump();\n         if !is_hex_digit(n) {\n             rdr.err(#fmt[\"illegal numeric character escape: %d\", n as int]);\n@@ -301,34 +283,34 @@ fn scan_numeric_escape(rdr: reader, n_hex_digits: uint) -> char {\n \n fn next_token(rdr: reader) -> {tok: token::token, chpos: uint, bpos: uint} {\n     consume_whitespace_and_comments(rdr);\n-    let start_chpos = rdr.get_chpos();\n-    let start_bpos = rdr.get_byte_pos();\n+    let start_chpos = rdr.chpos;\n+    let start_bpos = rdr.pos;\n     let tok = if rdr.is_eof() { token::EOF } else { next_token_inner(rdr) };\n     ret {tok: tok, chpos: start_chpos, bpos: start_bpos};\n }\n \n fn next_token_inner(rdr: reader) -> token::token {\n     let accum_str = \"\";\n-    let c = rdr.curr();\n+    let c = rdr.curr;\n     if char::is_XID_start(c) || c == '_' {\n         while char::is_XID_continue(c) {\n             str::push_char(accum_str, c);\n             rdr.bump();\n-            c = rdr.curr();\n+            c = rdr.curr;\n         }\n         if str::eq(accum_str, \"_\") { ret token::UNDERSCORE; }\n         let is_mod_name = c == ':' && rdr.next() == ':';\n \n         // FIXME: perform NFKC normalization here.\n-        ret token::IDENT(interner::intern::<str>(*rdr.get_interner(),\n+        ret token::IDENT(interner::intern::<str>(*rdr.interner,\n                                                  accum_str), is_mod_name);\n     }\n     if is_dec_digit(c) {\n         ret scan_number(c, rdr);\n     }\n     fn binop(rdr: reader, op: token::binop) -> token::token {\n         rdr.bump();\n-        if rdr.curr() == '=' {\n+        if rdr.curr == '=' {\n             rdr.bump();\n             ret token::BINOPEQ(op);\n         } else { ret token::BINOP(op); }\n@@ -348,7 +330,7 @@ fn next_token_inner(rdr: reader) -> token::token {\n       ',' { rdr.bump(); ret token::COMMA; }\n       '.' {\n         rdr.bump();\n-        if rdr.curr() == '.' && rdr.next() == '.' {\n+        if rdr.curr == '.' && rdr.next() == '.' {\n             rdr.bump();\n             rdr.bump();\n             ret token::ELLIPSIS;\n@@ -364,14 +346,14 @@ fn next_token_inner(rdr: reader) -> token::token {\n       '@' { rdr.bump(); ret token::AT; }\n       '#' {\n         rdr.bump();\n-        if rdr.curr() == '<' { rdr.bump(); ret token::POUND_LT; }\n-        if rdr.curr() == '{' { rdr.bump(); ret token::POUND_LBRACE; }\n+        if rdr.curr == '<' { rdr.bump(); ret token::POUND_LT; }\n+        if rdr.curr == '{' { rdr.bump(); ret token::POUND_LBRACE; }\n         ret token::POUND;\n       }\n       '~' { rdr.bump(); ret token::TILDE; }\n       ':' {\n         rdr.bump();\n-        if rdr.curr() == ':' {\n+        if rdr.curr == ':' {\n             rdr.bump();\n             ret token::MOD_SEP;\n         } else { ret token::COLON; }\n@@ -384,26 +366,26 @@ fn next_token_inner(rdr: reader) -> token::token {\n       // Multi-byte tokens.\n       '=' {\n         rdr.bump();\n-        if rdr.curr() == '=' {\n+        if rdr.curr == '=' {\n             rdr.bump();\n             ret token::EQEQ;\n         } else { ret token::EQ; }\n       }\n       '!' {\n         rdr.bump();\n-        if rdr.curr() == '=' {\n+        if rdr.curr == '=' {\n             rdr.bump();\n             ret token::NE;\n         } else { ret token::NOT; }\n       }\n       '<' {\n         rdr.bump();\n-        alt rdr.curr() {\n+        alt rdr.curr {\n           '=' { rdr.bump(); ret token::LE; }\n           '<' { ret binop(rdr, token::LSL); }\n           '-' {\n             rdr.bump();\n-            alt rdr.curr() {\n+            alt rdr.curr {\n               '>' { rdr.bump(); ret token::DARROW; }\n               _ { ret token::LARROW; }\n             }\n@@ -413,7 +395,7 @@ fn next_token_inner(rdr: reader) -> token::token {\n       }\n       '>' {\n         rdr.bump();\n-        alt rdr.curr() {\n+        alt rdr.curr {\n           '=' { rdr.bump(); ret token::GE; }\n           '>' {\n             if rdr.next() == '>' {\n@@ -426,10 +408,10 @@ fn next_token_inner(rdr: reader) -> token::token {\n       }\n       '\\'' {\n         rdr.bump();\n-        let c2 = rdr.curr();\n+        let c2 = rdr.curr;\n         rdr.bump();\n         if c2 == '\\\\' {\n-            let escaped = rdr.curr();\n+            let escaped = rdr.curr;\n             rdr.bump();\n             alt escaped {\n               'n' { c2 = '\\n'; }\n@@ -446,28 +428,28 @@ fn next_token_inner(rdr: reader) -> token::token {\n               }\n             }\n         }\n-        if rdr.curr() != '\\'' {\n+        if rdr.curr != '\\'' {\n             rdr.err(\"unterminated character constant\");\n             fail;\n         }\n         rdr.bump(); // advance curr past token\n         ret token::LIT_INT(c2 as i64, ast::ty_char);\n       }\n       '\"' {\n-        let n = rdr.get_chpos();\n+        let n = rdr.chpos;\n         rdr.bump();\n-        while rdr.curr() != '\"' {\n+        while rdr.curr != '\"' {\n             if rdr.is_eof() {\n                 rdr.err(#fmt[\"unterminated double quote string: %s\",\n                              rdr.get_str_from(n)]);\n                 fail;\n             }\n \n-            let ch = rdr.curr();\n+            let ch = rdr.curr;\n             rdr.bump();\n             alt ch {\n               '\\\\' {\n-                let escaped = rdr.curr();\n+                let escaped = rdr.curr;\n                 rdr.bump();\n                 alt escaped {\n                   'n' { str::push_byte(accum_str, '\\n' as u8); }\n@@ -495,7 +477,7 @@ fn next_token_inner(rdr: reader) -> token::token {\n             }\n         }\n         rdr.bump();\n-        ret token::LIT_STR(interner::intern::<str>(*rdr.get_interner(),\n+        ret token::LIT_STR(interner::intern::<str>(*rdr.interner,\n                                                    accum_str));\n       }\n       '-' {\n@@ -538,11 +520,11 @@ type cmnt = {style: cmnt_style, lines: [str], pos: uint};\n \n fn read_to_eol(rdr: reader) -> str {\n     let val = \"\";\n-    while rdr.curr() != '\\n' && !rdr.is_eof() {\n-        str::push_char(val, rdr.curr());\n+    while rdr.curr != '\\n' && !rdr.is_eof() {\n+        str::push_char(val, rdr.curr);\n         rdr.bump();\n     }\n-    if rdr.curr() == '\\n' { rdr.bump(); }\n+    if rdr.curr == '\\n' { rdr.bump(); }\n     ret val;\n }\n \n@@ -553,24 +535,24 @@ fn read_one_line_comment(rdr: reader) -> str {\n }\n \n fn consume_whitespace(rdr: reader) {\n-    while is_whitespace(rdr.curr()) && !rdr.is_eof() { rdr.bump(); }\n+    while is_whitespace(rdr.curr) && !rdr.is_eof() { rdr.bump(); }\n }\n \n fn consume_non_eol_whitespace(rdr: reader) {\n-    while is_whitespace(rdr.curr()) && rdr.curr() != '\\n' && !rdr.is_eof() {\n+    while is_whitespace(rdr.curr) && rdr.curr != '\\n' && !rdr.is_eof() {\n         rdr.bump();\n     }\n }\n \n fn push_blank_line_comment(rdr: reader, &comments: [cmnt]) {\n     #debug(\">>> blank-line comment\");\n     let v: [str] = [];\n-    comments += [{style: blank_line, lines: v, pos: rdr.get_chpos()}];\n+    comments += [{style: blank_line, lines: v, pos: rdr.chpos}];\n }\n \n fn consume_whitespace_counting_blank_lines(rdr: reader, &comments: [cmnt]) {\n-    while is_whitespace(rdr.curr()) && !rdr.is_eof() {\n-        if rdr.get_col() == 0u && rdr.curr() == '\\n' {\n+    while is_whitespace(rdr.curr) && !rdr.is_eof() {\n+        if rdr.col == 0u && rdr.curr == '\\n' {\n             push_blank_line_comment(rdr, comments);\n         }\n         rdr.bump();\n@@ -579,9 +561,9 @@ fn consume_whitespace_counting_blank_lines(rdr: reader, &comments: [cmnt]) {\n \n fn read_line_comments(rdr: reader, code_to_the_left: bool) -> cmnt {\n     #debug(\">>> line comments\");\n-    let p = rdr.get_chpos();\n+    let p = rdr.chpos;\n     let lines: [str] = [];\n-    while rdr.curr() == '/' && rdr.next() == '/' {\n+    while rdr.curr == '/' && rdr.next() == '/' {\n         let line = read_one_line_comment(rdr);\n         log(debug, line);\n         lines += [line];\n@@ -612,29 +594,29 @@ fn trim_whitespace_prefix_and_push_line(&lines: [str], s: str, col: uint) {\n \n fn read_block_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n     #debug(\">>> block comment\");\n-    let p = rdr.get_chpos();\n+    let p = rdr.chpos;\n     let lines: [str] = [];\n-    let col: uint = rdr.get_col();\n+    let col: uint = rdr.col;\n     rdr.bump();\n     rdr.bump();\n     let curr_line = \"/*\";\n     let level: int = 1;\n     while level > 0 {\n         #debug(\"=== block comment level %d\", level);\n         if rdr.is_eof() { rdr.err(\"unterminated block comment\"); fail; }\n-        if rdr.curr() == '\\n' {\n+        if rdr.curr == '\\n' {\n             trim_whitespace_prefix_and_push_line(lines, curr_line, col);\n             curr_line = \"\";\n             rdr.bump();\n         } else {\n-            str::push_char(curr_line, rdr.curr());\n-            if rdr.curr() == '/' && rdr.next() == '*' {\n+            str::push_char(curr_line, rdr.curr);\n+            if rdr.curr == '/' && rdr.next() == '*' {\n                 rdr.bump();\n                 rdr.bump();\n                 curr_line += \"*\";\n                 level += 1;\n             } else {\n-                if rdr.curr() == '*' && rdr.next() == '/' {\n+                if rdr.curr == '*' && rdr.next() == '/' {\n                     rdr.bump();\n                     rdr.bump();\n                     curr_line += \"/\";\n@@ -648,23 +630,23 @@ fn read_block_comment(rdr: reader, code_to_the_left: bool) -> cmnt {\n     }\n     let style = if code_to_the_left { trailing } else { isolated };\n     consume_non_eol_whitespace(rdr);\n-    if !rdr.is_eof() && rdr.curr() != '\\n' && vec::len(lines) == 1u {\n+    if !rdr.is_eof() && rdr.curr != '\\n' && vec::len(lines) == 1u {\n         style = mixed;\n     }\n     #debug(\"<<< block comment\");\n     ret {style: style, lines: lines, pos: p};\n }\n \n fn peeking_at_comment(rdr: reader) -> bool {\n-    ret rdr.curr() == '/' && rdr.next() == '/' ||\n-            rdr.curr() == '/' && rdr.next() == '*';\n+    ret rdr.curr == '/' && rdr.next() == '/' ||\n+            rdr.curr == '/' && rdr.next() == '*';\n }\n \n fn consume_comment(rdr: reader, code_to_the_left: bool, &comments: [cmnt]) {\n     #debug(\">>> consume comment\");\n-    if rdr.curr() == '/' && rdr.next() == '/' {\n+    if rdr.curr == '/' && rdr.next() == '/' {\n         comments += [read_line_comments(rdr, code_to_the_left)];\n-    } else if rdr.curr() == '/' && rdr.next() == '*' {\n+    } else if rdr.curr == '/' && rdr.next() == '*' {\n         comments += [read_block_comment(rdr, code_to_the_left)];\n     } else { fail; }\n     #debug(\"<<< consume comment\");\n@@ -696,7 +678,7 @@ fn gather_comments_and_literals(cm: codemap::codemap, path: str,\n         while true {\n             let code_to_the_left = !first_read;\n             consume_non_eol_whitespace(rdr);\n-            if rdr.curr() == '\\n' {\n+            if rdr.curr == '\\n' {\n                 code_to_the_left = false;\n                 consume_whitespace_counting_blank_lines(rdr, comments);\n             }"}, {"sha": "314add8289ce73d9ec62f63e0c9f047c1877cb2e", "filename": "src/comp/syntax/parse/parser.rs", "status": "modified", "additions": 311, "deletions": 343, "changes": 654, "blob_url": "https://github.com/rust-lang/rust/blob/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Fparser.rs?ref=7f6294455963334fec69fc799442ae74ef65b35e", "patch": "@@ -9,6 +9,7 @@ import codemap::span;\n import util::interner;\n import ast::{node_id, spanned};\n import front::attr;\n+import lexer::reader;\n \n tag restriction {\n     UNRESTRICTED;\n@@ -27,34 +28,60 @@ fn next_node_id(sess: parse_sess) -> node_id {\n     ret rv;\n }\n \n-type parser =\n-    obj {\n-        fn peek() -> token::token;\n-        fn bump();\n-        fn swap(token::token, uint, uint);\n-        fn look_ahead(uint) -> token::token;\n-        fn fatal(str) -> ! ;\n-        fn span_fatal(span, str) -> ! ;\n-        fn warn(str);\n-        fn restrict(restriction);\n-        fn get_restriction() -> restriction;\n-        fn get_file_type() -> file_type;\n-        fn get_cfg() -> ast::crate_cfg;\n-        fn get_span() -> span;\n-        fn get_lo_pos() -> uint;\n-        fn get_hi_pos() -> uint;\n-        fn get_last_lo_pos() -> uint;\n-        fn get_last_hi_pos() -> uint;\n-        fn get_prec_table() -> @[op_spec];\n-        fn get_str(token::str_num) -> str;\n-        fn get_reader() -> lexer::reader;\n-        fn get_filemap() -> codemap::filemap;\n-        fn get_bad_expr_words() -> hashmap<str, ()>;\n-        fn get_chpos() -> uint;\n-        fn get_byte_pos() -> uint;\n-        fn get_id() -> node_id;\n-        fn get_sess() -> parse_sess;\n-    };\n+type parser = @{\n+    sess: parse_sess,\n+    cfg: ast::crate_cfg,\n+    file_type: file_type,\n+    mutable token: token::token,\n+    mutable span: span,\n+    mutable last_span: span,\n+    mutable buffer: [{tok: token::token, span: span}],\n+    mutable restriction: restriction,\n+    reader: reader,\n+    precs: @[op_spec],\n+    bad_expr_words: hashmap<str, ()>\n+};\n+\n+impl parser for parser {\n+    fn bump() {\n+        self.last_span = self.span;\n+        if vec::len(self.buffer) == 0u {\n+            let next = lexer::next_token(self.reader);\n+            self.token = next.tok;\n+            self.span = ast_util::mk_sp(next.chpos, self.reader.chpos);\n+        } else {\n+            let next = vec::pop(self.buffer);\n+            self.token = next.tok;\n+            self.span = next.span;\n+        }\n+    }\n+    fn swap(next: token::token, lo: uint, hi: uint) {\n+        self.token = next;\n+        self.span = ast_util::mk_sp(lo, hi);\n+    }\n+    fn look_ahead(distance: uint) -> token::token {\n+        while vec::len(self.buffer) < distance {\n+            let next = lexer::next_token(self.reader);\n+            let sp = ast_util::mk_sp(next.chpos, self.reader.chpos);\n+            self.buffer = [{tok: next.tok, span: sp}] + self.buffer;\n+        }\n+        ret self.buffer[distance - 1u].tok;\n+    }\n+    fn fatal(m: str) -> ! {\n+        self.span_fatal(self.span, m);\n+    }\n+    fn span_fatal(sp: span, m: str) -> ! {\n+        codemap::emit_error(some(sp), m, self.sess.cm);\n+        fail;\n+    }\n+    fn warn(m: str) {\n+        codemap::emit_warning(some(self.span), m, self.sess.cm);\n+    }\n+    fn get_str(i: token::str_num) -> str {\n+        interner::get(*self.reader.interner, i)\n+    }\n+    fn get_id() -> node_id { next_node_id(self.sess) }\n+}\n \n fn new_parser_from_file(sess: parse_sess, cfg: ast::crate_cfg, path: str,\n                         chpos: uint, byte_pos: uint, ftype: file_type) ->\n@@ -86,79 +113,21 @@ fn new_parser_from_source_str(sess: parse_sess, cfg: ast::crate_cfg,\n     ret new_parser(sess, cfg, rdr, ftype);\n }\n \n-fn new_parser(sess: parse_sess, cfg: ast::crate_cfg, rdr: lexer::reader,\n+fn new_parser(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader,\n               ftype: file_type) -> parser {\n-    obj stdio_parser(sess: parse_sess,\n-                     cfg: ast::crate_cfg,\n-                     ftype: file_type,\n-                     mutable tok: token::token,\n-                     mutable tok_span: span,\n-                     mutable last_tok_span: span,\n-                     mutable buffer: [{tok: token::token, span: span}],\n-                     mutable restr: restriction,\n-                     rdr: lexer::reader,\n-                     precs: @[op_spec],\n-                     bad_words: hashmap<str, ()>) {\n-        fn peek() -> token::token { ret tok; }\n-        fn bump() {\n-            last_tok_span = tok_span;\n-            if vec::len(buffer) == 0u {\n-                let next = lexer::next_token(rdr);\n-                tok = next.tok;\n-                tok_span = ast_util::mk_sp(next.chpos, rdr.get_chpos());\n-            } else {\n-                let next = vec::pop(buffer);\n-                tok = next.tok;\n-                tok_span = next.span;\n-            }\n-        }\n-        fn swap(next: token::token, lo: uint, hi: uint) {\n-            tok = next;\n-            tok_span = ast_util::mk_sp(lo, hi);\n-        }\n-        fn look_ahead(distance: uint) -> token::token {\n-            while vec::len(buffer) < distance {\n-                let next = lexer::next_token(rdr);\n-                let sp = ast_util::mk_sp(next.chpos, rdr.get_chpos());\n-                buffer = [{tok: next.tok, span: sp}] + buffer;\n-            }\n-            ret buffer[distance - 1u].tok;\n-        }\n-        fn fatal(m: str) -> ! {\n-            self.span_fatal(self.get_span(), m);\n-        }\n-        fn span_fatal(sp: span, m: str) -> ! {\n-            codemap::emit_error(some(sp), m, sess.cm);\n-            fail;\n-        }\n-        fn warn(m: str) {\n-            codemap::emit_warning(some(self.get_span()), m, sess.cm);\n-        }\n-        fn restrict(r: restriction) { restr = r; }\n-        fn get_restriction() -> restriction { ret restr; }\n-        fn get_span() -> span { ret tok_span; }\n-        fn get_lo_pos() -> uint { ret tok_span.lo; }\n-        fn get_hi_pos() -> uint { ret tok_span.hi; }\n-        fn get_last_lo_pos() -> uint { ret last_tok_span.lo; }\n-        fn get_last_hi_pos() -> uint { ret last_tok_span.hi; }\n-        fn get_file_type() -> file_type { ret ftype; }\n-        fn get_cfg() -> ast::crate_cfg { ret cfg; }\n-        fn get_prec_table() -> @[op_spec] { ret precs; }\n-        fn get_str(i: token::str_num) -> str {\n-            ret interner::get(*rdr.get_interner(), i);\n-        }\n-        fn get_reader() -> lexer::reader { ret rdr; }\n-        fn get_filemap() -> codemap::filemap { ret rdr.get_filemap(); }\n-        fn get_bad_expr_words() -> hashmap<str, ()> { ret bad_words; }\n-        fn get_chpos() -> uint { ret rdr.get_chpos(); }\n-        fn get_byte_pos() -> uint { ret rdr.get_byte_pos(); }\n-        fn get_id() -> node_id { ret next_node_id(sess); }\n-        fn get_sess() -> parse_sess { ret sess; }\n-    }\n     let tok0 = lexer::next_token(rdr);\n-    let span0 = ast_util::mk_sp(tok0.chpos, rdr.get_chpos());\n-    ret stdio_parser(sess, cfg, ftype, tok0.tok, span0, span0, [],\n-                     UNRESTRICTED, rdr, prec_table(), bad_expr_word_table());\n+    let span0 = ast_util::mk_sp(tok0.chpos, rdr.chpos);\n+    @{sess: sess,\n+      cfg: cfg,\n+      file_type: ftype,\n+      mutable token: tok0.tok,\n+      mutable span: span0,\n+      mutable last_span: span0,\n+      mutable buffer: [],\n+      mutable restriction: UNRESTRICTED,\n+      reader: rdr,\n+      precs: prec_table(),\n+      bad_expr_words: bad_expr_word_table()}\n }\n \n // These are the words that shouldn't be allowed as value identifiers,\n@@ -178,35 +147,35 @@ fn bad_expr_word_table() -> hashmap<str, ()> {\n }\n \n fn unexpected(p: parser, t: token::token) -> ! {\n-    let s: str = \"unexpected token: '\" + token::to_str(p.get_reader(), t) +\n+    let s: str = \"unexpected token: '\" + token::to_str(p.reader, t) +\n         \"'\";\n     p.fatal(s);\n }\n \n fn expect(p: parser, t: token::token) {\n-    if p.peek() == t {\n+    if p.token == t {\n         p.bump();\n     } else {\n         let s: str = \"expecting '\";\n-        s += token::to_str(p.get_reader(), t);\n+        s += token::to_str(p.reader, t);\n         s += \"' but found '\";\n-        s += token::to_str(p.get_reader(), p.peek());\n+        s += token::to_str(p.reader, p.token);\n         p.fatal(s + \"'\");\n     }\n }\n \n fn expect_gt(p: parser) {\n-    if p.peek() == token::GT {\n+    if p.token == token::GT {\n         p.bump();\n-    } else if p.peek() == token::BINOP(token::LSR) {\n-        p.swap(token::GT, p.get_lo_pos() + 1u, p.get_hi_pos());\n-    } else if p.peek() == token::BINOP(token::ASR) {\n-        p.swap(token::BINOP(token::LSR), p.get_lo_pos() + 1u, p.get_hi_pos());\n+    } else if p.token == token::BINOP(token::LSR) {\n+        p.swap(token::GT, p.span.lo + 1u, p.span.hi);\n+    } else if p.token == token::BINOP(token::ASR) {\n+        p.swap(token::BINOP(token::LSR), p.span.lo + 1u, p.span.hi);\n     } else {\n         let s: str = \"expecting \";\n-        s += token::to_str(p.get_reader(), token::GT);\n+        s += token::to_str(p.reader, token::GT);\n         s += \", found \";\n-        s += token::to_str(p.get_reader(), p.peek());\n+        s += token::to_str(p.reader, p.token);\n         p.fatal(s);\n     }\n }\n@@ -216,7 +185,7 @@ fn spanned<T: copy>(lo: uint, hi: uint, node: T) -> spanned<T> {\n }\n \n fn parse_ident(p: parser) -> ast::ident {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(i, _) { p.bump(); ret p.get_str(i); }\n       _ { p.fatal(\"expecting ident\"); }\n     }\n@@ -228,18 +197,18 @@ fn parse_value_ident(p: parser) -> ast::ident {\n }\n \n fn eat(p: parser, tok: token::token) -> bool {\n-    ret if p.peek() == tok { p.bump(); true } else { false };\n+    ret if p.token == tok { p.bump(); true } else { false };\n }\n \n fn is_word(p: parser, word: str) -> bool {\n-    ret alt p.peek() {\n+    ret alt p.token {\n           token::IDENT(sid, false) { str::eq(word, p.get_str(sid)) }\n           _ { false }\n         };\n }\n \n fn eat_word(p: parser, word: str) -> bool {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(sid, false) {\n         if str::eq(word, p.get_str(sid)) {\n             p.bump();\n@@ -253,15 +222,15 @@ fn eat_word(p: parser, word: str) -> bool {\n fn expect_word(p: parser, word: str) {\n     if !eat_word(p, word) {\n         p.fatal(\"expecting \" + word + \", found \" +\n-                    token::to_str(p.get_reader(), p.peek()));\n+                    token::to_str(p.reader, p.token));\n     }\n }\n \n fn check_bad_word(p: parser) {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(sid, false) {\n         let w = p.get_str(sid);\n-        if p.get_bad_expr_words().contains_key(w) {\n+        if p.bad_expr_words.contains_key(w) {\n             p.fatal(\"found \" + w + \" in expression position\");\n         }\n       }\n@@ -293,11 +262,11 @@ fn parse_ty_fn(proto: ast::proto, p: parser) -> ast::ty_ {\n \n fn parse_ty_methods(p: parser, allow_tps: bool) -> [ast::ty_method] {\n     parse_seq(token::LBRACE, token::RBRACE, seq_sep_none(), {|p|\n-        let flo = p.get_lo_pos();\n+        let flo = p.span.lo;\n         expect_word(p, \"fn\");\n         let ident = parse_value_ident(p);\n         let tps = allow_tps ? parse_ty_params(p) : [];\n-        let f = parse_ty_fn(ast::proto_bare, p), fhi = p.get_last_hi_pos();\n+        let f = parse_ty_fn(ast::proto_bare, p), fhi = p.last_span.hi;\n         expect(p, token::SEMI);\n         alt f {\n           ast::ty_fn(_, d) {\n@@ -315,7 +284,7 @@ fn parse_mt(p: parser) -> ast::mt {\n }\n \n fn parse_ty_field(p: parser) -> ast::ty_field {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let mut = parse_mutability(p);\n     let id = parse_ident(p);\n     expect(p, token::COLON);\n@@ -332,10 +301,10 @@ fn ident_index(p: parser, args: [ast::arg], i: ast::ident) -> uint {\n }\n \n fn parse_type_constr_arg(p: parser) -> @ast::ty_constr_arg {\n-    let sp = p.get_span();\n+    let sp = p.span;\n     let carg = ast::carg_base;\n     expect(p, token::BINOP(token::STAR));\n-    if p.peek() == token::DOT {\n+    if p.token == token::DOT {\n         // \"*...\" notation for record fields\n         p.bump();\n         let pth = parse_path(p);\n@@ -346,9 +315,9 @@ fn parse_type_constr_arg(p: parser) -> @ast::ty_constr_arg {\n }\n \n fn parse_constr_arg(args: [ast::arg], p: parser) -> @ast::constr_arg {\n-    let sp = p.get_span();\n+    let sp = p.span;\n     let carg = ast::carg_base;\n-    if p.peek() == token::BINOP(token::STAR) {\n+    if p.token == token::BINOP(token::STAR) {\n         p.bump();\n     } else {\n         let i: ast::ident = parse_value_ident(p);\n@@ -358,7 +327,7 @@ fn parse_constr_arg(args: [ast::arg], p: parser) -> @ast::constr_arg {\n }\n \n fn parse_ty_constr(fn_args: [ast::arg], p: parser) -> @ast::constr {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let path = parse_path(p);\n     let args: {node: [@ast::constr_arg], span: span} =\n         parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n@@ -368,12 +337,12 @@ fn parse_ty_constr(fn_args: [ast::arg], p: parser) -> @ast::constr {\n }\n \n fn parse_constr_in_type(p: parser) -> @ast::ty_constr {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let path = parse_path(p);\n     let args: [@ast::ty_constr_arg] =\n         parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n                   parse_type_constr_arg, p).node;\n-    let hi = p.get_lo_pos();\n+    let hi = p.span.lo;\n     let tc: ast::ty_constr_ = {path: path, args: args, id: p.get_id()};\n     ret @spanned(lo, hi, tc);\n }\n@@ -386,7 +355,7 @@ fn parse_constrs<T: copy>(pser: block(parser) -> @ast::constr_general<T>,\n     while true {\n         let constr = pser(p);\n         constrs += [constr];\n-        if p.peek() == token::COMMA { p.bump(); } else { break; }\n+        if p.token == token::COMMA { p.bump(); } else { break; }\n     }\n     constrs\n }\n@@ -397,21 +366,21 @@ fn parse_type_constraints(p: parser) -> [@ast::ty_constr] {\n \n fn parse_ty_postfix(orig_t: ast::ty_, p: parser, colons_before_params: bool,\n                     lo: uint) -> @ast::ty {\n-    if colons_before_params && p.peek() == token::MOD_SEP {\n+    if colons_before_params && p.token == token::MOD_SEP {\n         p.bump();\n         expect(p, token::LT);\n-    } else if !colons_before_params && p.peek() == token::LT {\n+    } else if !colons_before_params && p.token == token::LT {\n         p.bump();\n-    } else { ret @spanned(lo, p.get_last_hi_pos(), orig_t); }\n+    } else { ret @spanned(lo, p.last_span.hi, orig_t); }\n \n     // If we're here, we have explicit type parameter instantiation.\n     let seq = parse_seq_to_gt(some(token::COMMA), {|p| parse_ty(p, false)},\n                               p);\n \n     alt orig_t {\n       ast::ty_path(pth, ann) {\n-        ret @spanned(lo, p.get_last_hi_pos(),\n-                     ast::ty_path(@spanned(lo, p.get_last_hi_pos(),\n+        ret @spanned(lo, p.last_span.hi,\n+                     ast::ty_path(@spanned(lo, p.last_span.hi,\n                                            {global: pth.node.global,\n                                             idents: pth.node.idents,\n                                             types: seq}), ann));\n@@ -422,18 +391,18 @@ fn parse_ty_postfix(orig_t: ast::ty_, p: parser, colons_before_params: bool,\n \n fn parse_ret_ty(p: parser) -> (ast::ret_style, @ast::ty) {\n     ret if eat(p, token::RARROW) {\n-        let lo = p.get_lo_pos();\n+        let lo = p.span.lo;\n         if eat(p, token::NOT) {\n-            (ast::noreturn, @spanned(lo, p.get_last_hi_pos(), ast::ty_bot))\n+            (ast::noreturn, @spanned(lo, p.last_span.hi, ast::ty_bot))\n         } else { (ast::return_val, parse_ty(p, false)) }\n     } else {\n-        let pos = p.get_lo_pos();\n+        let pos = p.span.lo;\n         (ast::return_val, @spanned(pos, pos, ast::ty_nil))\n     }\n }\n \n fn parse_ty(p: parser, colons_before_params: bool) -> @ast::ty {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let t: ast::ty_;\n     // FIXME: do something with this\n \n@@ -469,14 +438,14 @@ fn parse_ty(p: parser, colons_before_params: bool) -> @ast::ty {\n         t = ast::ty_float(ast::ty_f32);\n     } else if eat_word(p, \"f64\") {\n         t = ast::ty_float(ast::ty_f64);\n-    } else if p.peek() == token::LPAREN {\n+    } else if p.token == token::LPAREN {\n         p.bump();\n-        if p.peek() == token::RPAREN {\n+        if p.token == token::RPAREN {\n             p.bump();\n             t = ast::ty_nil;\n         } else {\n             let ts = [parse_ty(p, false)];\n-            while p.peek() == token::COMMA {\n+            while p.token == token::COMMA {\n                 p.bump();\n                 ts += [parse_ty(p, false)];\n             }\n@@ -485,28 +454,28 @@ fn parse_ty(p: parser, colons_before_params: bool) -> @ast::ty {\n             } else { t = ast::ty_tup(ts); }\n             expect(p, token::RPAREN);\n         }\n-    } else if p.peek() == token::AT {\n+    } else if p.token == token::AT {\n         p.bump();\n         t = ast::ty_box(parse_mt(p));\n-    } else if p.peek() == token::TILDE {\n+    } else if p.token == token::TILDE {\n         p.bump();\n         t = ast::ty_uniq(parse_mt(p));\n-    } else if p.peek() == token::BINOP(token::STAR) {\n+    } else if p.token == token::BINOP(token::STAR) {\n         p.bump();\n         t = ast::ty_ptr(parse_mt(p));\n-    } else if p.peek() == token::LBRACE {\n+    } else if p.token == token::LBRACE {\n         let elems =\n             parse_seq(token::LBRACE, token::RBRACE, seq_sep_opt(token::COMMA),\n                       parse_ty_field, p);\n         if vec::len(elems.node) == 0u { unexpected(p, token::RBRACE); }\n         let hi = elems.span.hi;\n         t = ast::ty_rec(elems.node);\n-        if p.peek() == token::COLON {\n+        if p.token == token::COLON {\n             p.bump();\n             t = ast::ty_constr(@spanned(lo, hi, t),\n                                parse_type_constraints(p));\n         }\n-    } else if p.peek() == token::LBRACKET {\n+    } else if p.token == token::LBRACKET {\n         expect(p, token::LBRACKET);\n         t = ast::ty_vec(parse_mt(p));\n         expect(p, token::RBRACKET);\n@@ -523,7 +492,7 @@ fn parse_ty(p: parser, colons_before_params: bool) -> @ast::ty {\n         t = parse_ty_fn(ast::proto_uniq, p);\n     } else if eat_word(p, \"obj\") {\n         t = ast::ty_obj(parse_ty_methods(p, false));\n-    } else if p.peek() == token::MOD_SEP || is_ident(p.peek()) {\n+    } else if p.token == token::MOD_SEP || is_ident(p.token) {\n         let path = parse_path(p);\n         t = ast::ty_path(path, p.get_id());\n     } else { p.fatal(\"expecting type\"); }\n@@ -553,7 +522,7 @@ fn parse_fn_block_arg(p: parser) -> ast::arg {\n     let m = parse_arg_mode(p);\n     let i = parse_value_ident(p);\n     let t = eat(p, token::COLON) ? parse_ty(p, false) :\n-        @spanned(p.get_lo_pos(), p.get_hi_pos(), ast::ty_infer);\n+        @spanned(p.span.lo, p.span.hi, ast::ty_infer);\n     ret {mode: m, ty: t, ident: i, id: p.get_id()};\n }\n \n@@ -562,8 +531,8 @@ fn parse_seq_to_before_gt<T: copy>(sep: option::t<token::token>,\n                                   p: parser) -> [T] {\n     let first = true;\n     let v = [];\n-    while p.peek() != token::GT && p.peek() != token::BINOP(token::LSR) &&\n-              p.peek() != token::BINOP(token::ASR) {\n+    while p.token != token::GT && p.token != token::BINOP(token::LSR) &&\n+              p.token != token::BINOP(token::ASR) {\n         alt sep {\n           some(t) { if first { first = false; } else { expect(p, t); } }\n           _ { }\n@@ -585,10 +554,10 @@ fn parse_seq_to_gt<T: copy>(sep: option::t<token::token>,\n fn parse_seq_lt_gt<T: copy>(sep: option::t<token::token>,\n                            f: block(parser) -> T,\n                            p: parser) -> spanned<[T]> {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     expect(p, token::LT);\n     let result = parse_seq_to_before_gt::<T>(sep, f, p);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect_gt(p);\n     ret spanned(lo, hi, result);\n }\n@@ -620,12 +589,12 @@ fn parse_seq_to_before_end<T: copy>(ket: token::token,\n                                    f: block(parser) -> T, p: parser) -> [T] {\n     let first: bool = true;\n     let v: [T] = [];\n-    while p.peek() != ket {\n+    while p.token != ket {\n         alt sep.sep {\n           some(t) { if first { first = false; } else { expect(p, t); } }\n           _ { }\n         }\n-        if sep.trailing_opt && p.peek() == ket { break; }\n+        if sep.trailing_opt && p.token == ket { break; }\n         v += [f(p)];\n     }\n     ret v;\n@@ -635,10 +604,10 @@ fn parse_seq_to_before_end<T: copy>(ket: token::token,\n fn parse_seq<T: copy>(bra: token::token, ket: token::token,\n                      sep: seq_sep, f: block(parser) -> T,\n                      p: parser) -> spanned<[T]> {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     expect(p, bra);\n     let result = parse_seq_to_before_end::<T>(ket, sep, f, p);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     p.bump();\n     ret spanned(lo, hi, result);\n }\n@@ -655,13 +624,13 @@ fn lit_from_token(p: parser, tok: token::token) -> ast::lit_ {\n }\n \n fn parse_lit(p: parser) -> ast::lit {\n-    let sp = p.get_span();\n+    let sp = p.span;\n     let lit = if eat_word(p, \"true\") {\n         ast::lit_bool(true)\n     } else if eat_word(p, \"false\") {\n         ast::lit_bool(false)\n     } else {\n-        let tok = p.peek();\n+        let tok = p.token;\n         p.bump();\n         lit_from_token(p, tok)\n     };\n@@ -674,23 +643,23 @@ fn is_ident(t: token::token) -> bool {\n }\n \n fn is_plain_ident(p: parser) -> bool {\n-    ret alt p.peek() { token::IDENT(_, false) { true } _ { false } };\n+    ret alt p.token { token::IDENT(_, false) { true } _ { false } };\n }\n \n fn parse_path(p: parser) -> @ast::path {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let global = eat(p, token::MOD_SEP), ids = [parse_ident(p)];\n     while p.look_ahead(1u) != token::LT && eat(p, token::MOD_SEP) {\n         ids += [parse_ident(p)];\n     }\n-    ret @spanned(lo, p.get_last_hi_pos(),\n+    ret @spanned(lo, p.last_span.hi,\n                  {global: global, idents: ids, types: []});\n }\n \n fn parse_path_and_ty_param_substs(p: parser, colons: bool) -> @ast::path {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let path = parse_path(p);\n-    if colons ? eat(p, token::MOD_SEP) : p.peek() == token::LT {\n+    if colons ? eat(p, token::MOD_SEP) : p.token == token::LT {\n         let seq = parse_seq_lt_gt(some(token::COMMA),\n                                   {|p| parse_ty(p, false)}, p);\n         @spanned(lo, seq.span.hi, {types: seq.node with path.node})\n@@ -708,7 +677,7 @@ fn parse_mutability(p: parser) -> ast::mutability {\n }\n \n fn parse_field(p: parser, sep: token::token) -> ast::field {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let m = parse_mutability(p);\n     let i = parse_ident(p);\n     expect(p, sep);\n@@ -731,8 +700,7 @@ fn is_bar(t: token::token) -> bool {\n }\n \n fn mk_lit_u32(p: parser, i: u32) -> @ast::expr {\n-    let span = p.get_span();\n-\n+    let span = p.span;\n     let lv_lit = @{node: ast::lit_uint(i as u64, ast::ty_u32),\n                    span: span};\n \n@@ -762,21 +730,21 @@ fn to_expr(e: pexpr) -> @ast::expr {\n }\n \n fn parse_bottom_expr(p: parser) -> pexpr {\n-    let lo = p.get_lo_pos();\n-    let hi = p.get_hi_pos();\n+    let lo = p.span.lo;\n+    let hi = p.span.hi;\n \n     let ex: ast::expr_;\n-    if p.peek() == token::LPAREN {\n+    if p.token == token::LPAREN {\n         p.bump();\n-        if p.peek() == token::RPAREN {\n-            hi = p.get_hi_pos();\n+        if p.token == token::RPAREN {\n+            hi = p.span.hi;\n             p.bump();\n             let lit = @spanned(lo, hi, ast::lit_nil);\n             ret mk_pexpr(p, lo, hi, ast::expr_lit(lit));\n         }\n         let es = [parse_expr(p)];\n-        while p.peek() == token::COMMA { p.bump(); es += [parse_expr(p)]; }\n-        hi = p.get_hi_pos();\n+        while p.token == token::COMMA { p.bump(); es += [parse_expr(p)]; }\n+        hi = p.span.hi;\n         expect(p, token::RPAREN);\n \n         // Note: we retain the expr_tup() even for simple\n@@ -785,25 +753,25 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         // can tell whether the expression was parenthesized or not,\n         // which affects expr_is_complete().\n         ret mk_pexpr(p, lo, hi, ast::expr_tup(es));\n-    } else if p.peek() == token::LBRACE {\n+    } else if p.token == token::LBRACE {\n         p.bump();\n         if is_word(p, \"mutable\") ||\n                is_plain_ident(p) && p.look_ahead(1u) == token::COLON {\n             let fields = [parse_field(p, token::COLON)];\n             let base = none;\n-            while p.peek() != token::RBRACE {\n+            while p.token != token::RBRACE {\n                 if eat_word(p, \"with\") { base = some(parse_expr(p)); break; }\n                 expect(p, token::COMMA);\n-                if p.peek() == token::RBRACE {\n+                if p.token == token::RBRACE {\n                     // record ends by an optional trailing comma\n                     break;\n                 }\n                 fields += [parse_field(p, token::COLON)];\n             }\n-            hi = p.get_hi_pos();\n+            hi = p.span.hi;\n             expect(p, token::RBRACE);\n             ex = ast::expr_rec(fields, base);\n-        } else if is_bar(p.peek()) {\n+        } else if is_bar(p.token) {\n             ret pexpr(parse_fn_block_expr(p));\n         } else {\n             let blk = parse_block_tail(p, lo, ast::default_blk);\n@@ -834,35 +802,35 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         ret pexpr(parse_block_expr(p, lo, ast::unchecked_blk));\n     } else if eat_word(p, \"unsafe\") {\n         ret pexpr(parse_block_expr(p, lo, ast::unsafe_blk));\n-    } else if p.peek() == token::LBRACKET {\n+    } else if p.token == token::LBRACKET {\n         p.bump();\n         let mut = parse_mutability(p);\n         let es =\n             parse_seq_to_end(token::RBRACKET, seq_sep(token::COMMA),\n                              parse_expr, p);\n         ex = ast::expr_vec(es, mut);\n-    } else if p.peek() == token::POUND_LT {\n+    } else if p.token == token::POUND_LT {\n         p.bump();\n         let ty = parse_ty(p, false);\n         expect(p, token::GT);\n \n         /* hack: early return to take advantage of specialized function */\n-        ret pexpr(mk_mac_expr(p, lo, p.get_hi_pos(),\n+        ret pexpr(mk_mac_expr(p, lo, p.span.hi,\n                               ast::mac_embed_type(ty)));\n-    } else if p.peek() == token::POUND_LBRACE {\n+    } else if p.token == token::POUND_LBRACE {\n         p.bump();\n         let blk = ast::mac_embed_block(\n             parse_block_tail(p, lo, ast::default_blk));\n-        ret pexpr(mk_mac_expr(p, lo, p.get_hi_pos(), blk));\n-    } else if p.peek() == token::ELLIPSIS {\n+        ret pexpr(mk_mac_expr(p, lo, p.span.hi, blk));\n+    } else if p.token == token::ELLIPSIS {\n         p.bump();\n-        ret pexpr(mk_mac_expr(p, lo, p.get_hi_pos(), ast::mac_ellipsis));\n+        ret pexpr(mk_mac_expr(p, lo, p.span.hi, ast::mac_ellipsis));\n     } else if eat_word(p, \"obj\") {\n         // Anonymous object\n \n         // Only make people type () if they're actually adding new fields\n         let fields: option::t<[ast::anon_obj_field]> = none;\n-        if p.peek() == token::LPAREN {\n+        if p.token == token::LPAREN {\n             p.bump();\n             fields =\n                 some(parse_seq_to_end(token::RPAREN, seq_sep(token::COMMA),\n@@ -871,12 +839,12 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         let meths: [@ast::method] = [];\n         let inner_obj: option::t<@ast::expr> = none;\n         expect(p, token::LBRACE);\n-        while p.peek() != token::RBRACE {\n+        while p.token != token::RBRACE {\n             if eat_word(p, \"with\") {\n                 inner_obj = some(parse_expr(p));\n             } else { meths += [parse_method(p, false)]; }\n         }\n-        hi = p.get_hi_pos();\n+        hi = p.span.hi;\n         expect(p, token::RBRACE);\n         // fields and methods may be *additional* or *overriding* fields\n         // and methods if there's a inner_obj, or they may be the *only*\n@@ -889,7 +857,7 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n     } else if eat_word(p, \"bind\") {\n         let e = parse_expr_res(p, RESTRICT_NO_CALL_EXPRS);\n         fn parse_expr_opt(p: parser) -> option::t<@ast::expr> {\n-            alt p.peek() {\n+            alt p.token {\n               token::UNDERSCORE. { p.bump(); ret none; }\n               _ { ret some(parse_expr(p)); }\n             }\n@@ -899,12 +867,12 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n                       parse_expr_opt, p);\n         hi = es.span.hi;\n         ex = ast::expr_bind(e, es.node);\n-    } else if p.peek() == token::POUND {\n+    } else if p.token == token::POUND {\n         let ex_ext = parse_syntax_ext(p);\n         hi = ex_ext.span.hi;\n         ex = ex_ext.node;\n     } else if eat_word(p, \"fail\") {\n-        if can_begin_expr(p.peek()) {\n+        if can_begin_expr(p.token) {\n             let e = parse_expr(p);\n             hi = e.span.hi;\n             ex = ast::expr_fail(some(e));\n@@ -915,7 +883,7 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         expect(p, token::COMMA);\n         let e = parse_expr(p);\n         ex = ast::expr_log(2, lvl, e);\n-        hi = p.get_hi_pos();\n+        hi = p.span.hi;\n         expect(p, token::RPAREN);\n     } else if eat_word(p, \"assert\") {\n         let e = parse_expr(p);\n@@ -938,17 +906,17 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         hi = e.span.hi;\n         ex = ast::expr_check(ast::claimed_expr, e);\n     } else if eat_word(p, \"ret\") {\n-        if can_begin_expr(p.peek()) {\n+        if can_begin_expr(p.token) {\n             let e = parse_expr(p);\n             hi = e.span.hi;\n             ex = ast::expr_ret(some(e));\n         } else { ex = ast::expr_ret(none); }\n     } else if eat_word(p, \"break\") {\n         ex = ast::expr_break;\n-        hi = p.get_hi_pos();\n+        hi = p.span.hi;\n     } else if eat_word(p, \"cont\") {\n         ex = ast::expr_cont;\n-        hi = p.get_hi_pos();\n+        hi = p.span.hi;\n     } else if eat_word(p, \"be\") {\n         let e = parse_expr(p);\n \n@@ -961,8 +929,8 @@ fn parse_bottom_expr(p: parser) -> pexpr {\n         let e = parse_expr(p);\n         ex = ast::expr_copy(e);\n         hi = e.span.hi;\n-    } else if p.peek() == token::MOD_SEP ||\n-                  is_ident(p.peek()) && !is_word(p, \"true\") &&\n+    } else if p.token == token::MOD_SEP ||\n+                  is_ident(p.token) && !is_word(p, \"true\") &&\n                       !is_word(p, \"false\") {\n         check_bad_word(p);\n         let pth = parse_path_and_ty_param_substs(p, true);\n@@ -985,21 +953,21 @@ fn parse_block_expr(p: parser,\n }\n \n fn parse_syntax_ext(p: parser) -> @ast::expr {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     expect(p, token::POUND);\n     ret parse_syntax_ext_naked(p, lo);\n }\n \n fn parse_syntax_ext_naked(p: parser, lo: uint) -> @ast::expr {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(_, _) {}\n       _ { p.fatal(\"expected a syntax expander name\"); }\n     }\n     let pth = parse_path(p);\n     //temporary for a backwards-compatible cycle:\n     let sep = seq_sep(token::COMMA);\n     let es =\n-        if p.peek() == token::LPAREN {\n+        if p.token == token::LPAREN {\n             parse_seq(token::LPAREN, token::RPAREN, sep, parse_expr, p)\n         } else {\n             parse_seq(token::LBRACKET, token::RBRACKET, sep, parse_expr, p)\n@@ -1015,15 +983,15 @@ fn parse_dot_or_call_expr(p: parser) -> pexpr {\n }\n \n fn permits_call(p: parser) -> bool {\n-    ret p.get_restriction() != RESTRICT_NO_CALL_EXPRS;\n+    ret p.restriction != RESTRICT_NO_CALL_EXPRS;\n }\n \n fn parse_dot_or_call_expr_with(p: parser, e0: pexpr) -> pexpr {\n     let e = e0;\n     let lo = e.span.lo;\n     let hi = e.span.hi;\n     while !expr_is_complete(p, e) {\n-        alt p.peek() {\n+        alt p.token {\n           // expr(...)\n           token::LPAREN. if permits_call(p) {\n             let es = parse_seq(token::LPAREN, token::RPAREN,\n@@ -1043,7 +1011,7 @@ fn parse_dot_or_call_expr_with(p: parser, e0: pexpr) -> pexpr {\n                             with *to_expr(e)});\n               }\n               _ {\n-                e = mk_pexpr(p, lo, p.get_last_hi_pos(),\n+                e = mk_pexpr(p, lo, p.last_span.hi,\n                             ast::expr_call(to_expr(e), [blk], true));\n               }\n             }\n@@ -1061,9 +1029,9 @@ fn parse_dot_or_call_expr_with(p: parser, e0: pexpr) -> pexpr {\n           // expr.f\n           token::DOT. {\n             p.bump();\n-            alt p.peek() {\n+            alt p.token {\n               token::IDENT(i, _) {\n-                hi = p.get_hi_pos();\n+                hi = p.span.hi;\n                 p.bump();\n                 let tys = if eat(p, token::MOD_SEP) {\n                     expect(p, token::LT);\n@@ -1086,11 +1054,11 @@ fn parse_dot_or_call_expr_with(p: parser, e0: pexpr) -> pexpr {\n }\n \n fn parse_prefix_expr(p: parser) -> pexpr {\n-    let lo = p.get_lo_pos();\n-    let hi = p.get_hi_pos();\n+    let lo = p.span.lo;\n+    let hi = p.span.hi;\n \n     let ex;\n-    alt p.peek() {\n+    alt p.token {\n       token::NOT. {\n         p.bump();\n         let e = to_expr(parse_prefix_expr(p));\n@@ -1135,7 +1103,7 @@ fn parse_prefix_expr(p: parser) -> pexpr {\n \n fn parse_ternary(p: parser) -> @ast::expr {\n     let cond_expr = parse_binops(p);\n-    if p.peek() == token::QUES {\n+    if p.token == token::QUES {\n         p.bump();\n         let then_expr = parse_expr(p);\n         expect(p, token::COLON);\n@@ -1185,10 +1153,10 @@ fn parse_more_binops(p: parser, plhs: pexpr, min_prec: int) ->\n    @ast::expr {\n     let lhs = to_expr(plhs);\n     if expr_is_complete(p, plhs) { ret lhs; }\n-    let peeked = p.peek();\n+    let peeked = p.token;\n     if peeked == token::BINOP(token::OR) &&\n-       p.get_restriction() == RESTRICT_NO_BAR_OP { ret lhs; }\n-    for cur: op_spec in *p.get_prec_table() {\n+       p.restriction == RESTRICT_NO_BAR_OP { ret lhs; }\n+    for cur: op_spec in *p.precs {\n         if cur.prec > min_prec && cur.tok == peeked {\n             p.bump();\n             let expr = parse_prefix_expr(p);\n@@ -1208,9 +1176,9 @@ fn parse_more_binops(p: parser, plhs: pexpr, min_prec: int) ->\n }\n \n fn parse_assign_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let lhs = parse_ternary(p);\n-    alt p.peek() {\n+    alt p.token {\n       token::EQ. {\n         p.bump();\n         let rhs = parse_expr(p);\n@@ -1256,7 +1224,7 @@ fn parse_if_expr_1(p: parser) ->\n     els: option::t<@ast::expr>,\n     lo: uint,\n     hi: uint} {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let cond = parse_expr(p);\n     let thn = parse_block(p);\n     let els: option::t<@ast::expr> = none;\n@@ -1287,7 +1255,7 @@ fn parse_if_expr(p: parser) -> @ast::expr {\n fn parse_capture_clause(p: parser) -> @ast::capture_clause {\n     fn expect_opt_trailing_semi(p: parser) {\n         if !eat(p, token::SEMI) {\n-            if p.peek() != token::RBRACKET {\n+            if p.token != token::RBRACKET {\n                 p.fatal(\"expecting ; or ]\");\n             }\n         }\n@@ -1296,10 +1264,10 @@ fn parse_capture_clause(p: parser) -> @ast::capture_clause {\n     fn eat_ident_list(p: parser) -> [@ast::capture_item] {\n         let res = [];\n         while true {\n-            alt p.peek() {\n+            alt p.token {\n               token::IDENT(_, _) {\n                 let id = p.get_id();\n-                let sp = ast_util::mk_sp(p.get_lo_pos(), p.get_hi_pos());\n+                let sp = ast_util::mk_sp(p.span.lo, p.span.hi);\n                 let ident = parse_ident(p);\n                 res += [@{id:id, name:ident, span:sp}];\n                 if !eat(p, token::COMMA) {\n@@ -1335,7 +1303,7 @@ fn parse_capture_clause(p: parser) -> @ast::capture_clause {\n }\n \n fn parse_fn_expr(p: parser, proto: ast::proto) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let capture_clause = parse_capture_clause(p);\n     let decl = parse_fn_decl(p, ast::impure_fn);\n     let body = parse_block(p);\n@@ -1344,7 +1312,7 @@ fn parse_fn_expr(p: parser, proto: ast::proto) -> @ast::expr {\n }\n \n fn parse_fn_block_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let decl = parse_fn_block_decl(p);\n     let body = parse_block_tail(p, lo, ast::default_blk);\n     ret mk_expr(p, lo, body.span.hi, ast::expr_fn_block(decl, body));\n@@ -1360,7 +1328,7 @@ fn parse_else_expr(p: parser) -> @ast::expr {\n }\n \n fn parse_for_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let decl = parse_local(p, false);\n     expect_word(p, \"in\");\n     let seq = parse_expr(p);\n@@ -1370,15 +1338,15 @@ fn parse_for_expr(p: parser) -> @ast::expr {\n }\n \n fn parse_while_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let cond = parse_expr(p);\n     let body = parse_block_no_value(p);\n     let hi = body.span.hi;\n     ret mk_expr(p, lo, hi, ast::expr_while(cond, body));\n }\n \n fn parse_do_while_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let body = parse_block_no_value(p);\n     expect_word(p, \"while\");\n     let cond = parse_expr(p);\n@@ -1387,18 +1355,18 @@ fn parse_do_while_expr(p: parser) -> @ast::expr {\n }\n \n fn parse_alt_expr(p: parser) -> @ast::expr {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let discriminant = parse_expr(p);\n     expect(p, token::LBRACE);\n     let arms: [ast::arm] = [];\n-    while p.peek() != token::RBRACE {\n+    while p.token != token::RBRACE {\n         let pats = parse_pats(p);\n         let guard = none;\n         if eat_word(p, \"if\") { guard = some(parse_expr(p)); }\n         let blk = parse_block(p);\n         arms += [{pats: pats, guard: guard, body: blk}];\n     }\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     p.bump();\n     ret mk_expr(p, lo, hi, ast::expr_alt(discriminant, arms));\n }\n@@ -1408,15 +1376,15 @@ fn parse_expr(p: parser) -> @ast::expr {\n }\n \n fn parse_expr_res(p: parser, r: restriction) -> @ast::expr {\n-    let old = p.get_restriction();\n-    p.restrict(r);\n+    let old = p.restriction;\n+    p.restriction = r;\n     let e = parse_assign_expr(p);\n-    p.restrict(old);\n+    p.restriction = old;\n     ret e;\n }\n \n fn parse_initializer(p: parser) -> option::t<ast::initializer> {\n-    alt p.peek() {\n+    alt p.token {\n       token::EQ. {\n         p.bump();\n         ret some({op: ast::init_assign, expr: parse_expr(p)});\n@@ -1442,16 +1410,16 @@ fn parse_pats(p: parser) -> [@ast::pat] {\n     let pats = [];\n     while true {\n         pats += [parse_pat(p)];\n-        if p.peek() == token::BINOP(token::OR) { p.bump(); } else { break; }\n+        if p.token == token::BINOP(token::OR) { p.bump(); } else { break; }\n     }\n     ret pats;\n }\n \n fn parse_pat(p: parser) -> @ast::pat {\n-    let lo = p.get_lo_pos();\n-    let hi = p.get_hi_pos();\n+    let lo = p.span.lo;\n+    let hi = p.span.hi;\n     let pat;\n-    alt p.peek() {\n+    alt p.token {\n       token::UNDERSCORE. { p.bump(); pat = ast::pat_wild; }\n       token::AT. {\n         p.bump();\n@@ -1470,26 +1438,26 @@ fn parse_pat(p: parser) -> @ast::pat {\n         let fields = [];\n         let etc = false;\n         let first = true;\n-        while p.peek() != token::RBRACE {\n+        while p.token != token::RBRACE {\n             if first { first = false; } else { expect(p, token::COMMA); }\n \n-            if p.peek() == token::UNDERSCORE {\n+            if p.token == token::UNDERSCORE {\n                 p.bump();\n-                if p.peek() != token::RBRACE {\n+                if p.token != token::RBRACE {\n                     p.fatal(\"expecting }, found \" +\n-                                token::to_str(p.get_reader(), p.peek()));\n+                                token::to_str(p.reader, p.token));\n                 }\n                 etc = true;\n                 break;\n             }\n \n             let fieldname = parse_ident(p);\n             let subpat;\n-            if p.peek() == token::COLON {\n+            if p.token == token::COLON {\n                 p.bump();\n                 subpat = parse_pat(p);\n             } else {\n-                if p.get_bad_expr_words().contains_key(fieldname) {\n+                if p.bad_expr_words.contains_key(fieldname) {\n                     p.fatal(\"found \" + fieldname + \" in binding position\");\n                 }\n                 subpat = @{id: p.get_id(),\n@@ -1498,26 +1466,26 @@ fn parse_pat(p: parser) -> @ast::pat {\n             }\n             fields += [{ident: fieldname, pat: subpat}];\n         }\n-        hi = p.get_hi_pos();\n+        hi = p.span.hi;\n         p.bump();\n         pat = ast::pat_rec(fields, etc);\n       }\n       token::LPAREN. {\n         p.bump();\n-        if p.peek() == token::RPAREN {\n-            hi = p.get_hi_pos();\n+        if p.token == token::RPAREN {\n+            hi = p.span.hi;\n             p.bump();\n             let lit = @{node: ast::lit_nil, span: ast_util::mk_sp(lo, hi)};\n             let expr = mk_expr(p, lo, hi, ast::expr_lit(lit));\n             pat = ast::pat_lit(expr);\n         } else {\n             let fields = [parse_pat(p)];\n-            while p.peek() == token::COMMA {\n+            while p.token == token::COMMA {\n                 p.bump();\n                 fields += [parse_pat(p)];\n             }\n             if vec::len(fields) == 1u { expect(p, token::COMMA); }\n-            hi = p.get_hi_pos();\n+            hi = p.span.hi;\n             expect(p, token::RPAREN);\n             pat = ast::pat_tup(fields);\n         }\n@@ -1540,15 +1508,15 @@ fn parse_pat(p: parser) -> @ast::pat {\n                         }\n                         _ { true }\n                       } {\n-            hi = p.get_hi_pos();\n+            hi = p.span.hi;\n             let name = parse_value_ident(p);\n             let sub = eat(p, token::AT) ? some(parse_pat(p)) : none;\n             pat = ast::pat_bind(name, sub);\n         } else {\n             let tag_path = parse_path_and_ty_param_substs(p, true);\n             hi = tag_path.span.hi;\n             let args: [@ast::pat];\n-            alt p.peek() {\n+            alt p.token {\n               token::LPAREN. {\n                 let a =\n                     parse_seq(token::LPAREN, token::RPAREN,\n@@ -1567,29 +1535,29 @@ fn parse_pat(p: parser) -> @ast::pat {\n }\n \n fn parse_local(p: parser, allow_init: bool) -> @ast::local {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let pat = parse_pat(p);\n     let ty = @spanned(lo, lo, ast::ty_infer);\n     if eat(p, token::COLON) { ty = parse_ty(p, false); }\n     let init = if allow_init { parse_initializer(p) } else { none };\n-    ret @spanned(lo, p.get_last_hi_pos(),\n+    ret @spanned(lo, p.last_span.hi,\n                  {ty: ty, pat: pat, init: init, id: p.get_id()});\n }\n \n fn parse_let(p: parser) -> @ast::decl {\n     fn parse_let_style(p: parser) -> ast::let_style {\n         eat(p, token::BINOP(token::AND)) ? ast::let_ref : ast::let_copy\n     }\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let locals = [(parse_let_style(p), parse_local(p, true))];\n     while eat(p, token::COMMA) {\n         locals += [(parse_let_style(p), parse_local(p, true))];\n     }\n-    ret @spanned(lo, p.get_last_hi_pos(), ast::decl_local(locals));\n+    ret @spanned(lo, p.last_span.hi, ast::decl_local(locals));\n }\n \n fn parse_stmt(p: parser) -> @ast::stmt {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     if eat_word(p, \"let\") {\n         let decl = parse_let(p);\n         ret @spanned(lo, decl.span.hi, ast::stmt_decl(decl, p.get_id()));\n@@ -1624,10 +1592,10 @@ fn parse_stmt(p: parser) -> @ast::stmt {\n }\n \n fn expr_is_complete(p: parser, e: pexpr) -> bool {\n-    log(debug, (\"expr_is_complete\", p.get_restriction(),\n+    log(debug, (\"expr_is_complete\", p.restriction,\n                 print::pprust::expr_to_str(*e),\n                 expr_requires_semi_to_be_stmt(*e)));\n-    ret p.get_restriction() == RESTRICT_STMT_EXPR &&\n+    ret p.restriction == RESTRICT_STMT_EXPR &&\n         !expr_requires_semi_to_be_stmt(*e);\n }\n \n@@ -1662,7 +1630,7 @@ fn stmt_ends_with_semi(stmt: ast::stmt) -> bool {\n }\n \n fn parse_block(p: parser) -> ast::blk {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     if eat_word(p, \"unchecked\") {\n         expect(p, token::LBRACE);\n         be parse_block_tail(p, lo, ast::unchecked_blk);\n@@ -1689,16 +1657,16 @@ fn parse_block_no_value(p: parser) -> ast::blk {\n fn parse_block_tail(p: parser, lo: uint, s: ast::blk_check_mode) -> ast::blk {\n     let view_items = [], stmts = [], expr = none;\n     while is_word(p, \"import\") { view_items += [parse_view_item(p)]; }\n-    while p.peek() != token::RBRACE {\n-        alt p.peek() {\n+    while p.token != token::RBRACE {\n+        alt p.token {\n           token::SEMI. {\n             p.bump(); // empty\n           }\n           _ {\n             let stmt = parse_stmt(p);\n             alt stmt.node {\n               ast::stmt_expr(e, stmt_id) { // Expression without semicolon:\n-                alt p.peek() {\n+                alt p.token {\n                   token::SEMI. {\n                     p.bump();\n                     stmts += [@{node: ast::stmt_semi(e, stmt_id) with *stmt}];\n@@ -1709,7 +1677,7 @@ fn parse_block_tail(p: parser, lo: uint, s: ast::blk_check_mode) -> ast::blk {\n                   t {\n                     if stmt_ends_with_semi(*stmt) {\n                         p.fatal(\"expected ';' or '}' after expression but \\\n-                                 found '\" + token::to_str(p.get_reader(), t) +\n+                                 found '\" + token::to_str(p.reader, t) +\n                                 \"'\");\n                     }\n                     stmts += [stmt];\n@@ -1728,7 +1696,7 @@ fn parse_block_tail(p: parser, lo: uint, s: ast::blk_check_mode) -> ast::blk {\n           }\n         }\n     }\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     p.bump();\n     let bloc = {view_items: view_items, stmts: stmts, expr: expr,\n                 id: p.get_id(), rules: s};\n@@ -1739,7 +1707,7 @@ fn parse_ty_param(p: parser) -> ast::ty_param {\n     let bounds = [];\n     let ident = parse_ident(p);\n     if eat(p, token::COLON) {\n-        while p.peek() != token::COMMA && p.peek() != token::GT {\n+        while p.token != token::COMMA && p.token != token::GT {\n             if eat_word(p, \"send\") { bounds += [ast::bound_send]; }\n             else if eat_word(p, \"copy\") { bounds += [ast::bound_copy]; }\n             else { bounds += [ast::bound_iface(parse_ty(p, false))]; }\n@@ -1763,7 +1731,7 @@ fn parse_fn_decl(p: parser, purity: ast::purity)\n     // mentioned in a constraint to an arg index.\n     // Seems weird to do this in the parser, but I'm not sure how else to.\n     let constrs = [];\n-    if p.peek() == token::COLON {\n+    if p.token == token::COLON {\n         p.bump();\n         constrs = parse_constrs({|x| parse_ty_constr(inputs.node, x) }, p);\n     }\n@@ -1780,7 +1748,7 @@ fn parse_fn_block_decl(p: parser) -> ast::fn_decl {\n         parse_seq(token::BINOP(token::OR), token::BINOP(token::OR),\n                   seq_sep(token::COMMA), parse_fn_block_arg, p).node;\n     let output = eat(p, token::RARROW) ? parse_ty(p, false) :\n-        @spanned(p.get_lo_pos(), p.get_hi_pos(), ast::ty_infer);\n+        @spanned(p.span.lo, p.span.hi, ast::ty_infer);\n     ret {inputs: inputs,\n          output: output,\n          purity: ast::impure_fn,\n@@ -1805,7 +1773,7 @@ fn mk_item(p: parser, lo: uint, hi: uint, ident: ast::ident, node: ast::item_,\n \n fn parse_item_fn(p: parser, purity: ast::purity,\n                  attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let t = parse_fn_header(p);\n     let decl = parse_fn_decl(p, purity);\n     let body = parse_block(p);\n@@ -1832,7 +1800,7 @@ fn parse_anon_obj_field(p: parser) -> ast::anon_obj_field {\n }\n \n fn parse_method(p: parser, allow_tps: bool) -> @ast::method {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     expect_word(p, \"fn\");\n     let ident = parse_value_ident(p);\n     let tps = allow_tps ? parse_ty_params(p) : [];\n@@ -1843,26 +1811,26 @@ fn parse_method(p: parser, allow_tps: bool) -> @ast::method {\n }\n \n fn parse_item_obj(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let ident = parse_value_ident(p);\n     let ty_params = parse_ty_params(p);\n     let fields: ast::spanned<[ast::obj_field]> =\n         parse_seq(token::LPAREN, token::RPAREN, seq_sep(token::COMMA),\n                   parse_obj_field, p);\n     let meths: [@ast::method] = [];\n     expect(p, token::LBRACE);\n-    while p.peek() != token::RBRACE { meths += [parse_method(p, false)]; }\n-    let hi = p.get_hi_pos();\n+    while p.token != token::RBRACE { meths += [parse_method(p, false)]; }\n+    let hi = p.span.hi;\n     expect(p, token::RBRACE);\n     let ob: ast::_obj = {fields: fields.node, methods: meths};\n     ret mk_item(p, lo, hi, ident, ast::item_obj(ob, ty_params, p.get_id()),\n                 attrs);\n }\n \n fn parse_item_iface(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos(), ident = parse_ident(p),\n+    let lo = p.last_span.lo, ident = parse_ident(p),\n         tps = parse_ty_params(p), meths = parse_ty_methods(p, true);\n-    ret mk_item(p, lo, p.get_last_hi_pos(), ident,\n+    ret mk_item(p, lo, p.last_span.hi, ident,\n                 ast::item_iface(tps, meths), attrs);\n }\n \n@@ -1871,12 +1839,12 @@ fn parse_item_iface(p: parser, attrs: [ast::attribute]) -> @ast::item {\n //    impl name<T> of to_str for [T] { ... }\n //    impl name<T> for [T] { ... }\n fn parse_item_impl(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     fn wrap_path(p: parser, pt: @ast::path) -> @ast::ty {\n         @{node: ast::ty_path(pt, p.get_id()), span: pt.span}\n     }\n     let (ident, tps) = if !is_word(p, \"of\") {\n-        if p.peek() == token::LT { (none, parse_ty_params(p)) }\n+        if p.token == token::LT { (none, parse_ty_params(p)) }\n         else { (some(parse_ident(p)), parse_ty_params(p)) }\n     } else { (none, []) };\n     let ifce = if eat_word(p, \"of\") {\n@@ -1894,12 +1862,12 @@ fn parse_item_impl(p: parser, attrs: [ast::attribute]) -> @ast::item {\n     let ty = parse_ty(p, false), meths = [];\n     expect(p, token::LBRACE);\n     while !eat(p, token::RBRACE) { meths += [parse_method(p, true)]; }\n-    ret mk_item(p, lo, p.get_last_hi_pos(), ident,\n+    ret mk_item(p, lo, p.last_span.hi, ident,\n                 ast::item_impl(tps, ifce, ty, meths), attrs);\n }\n \n fn parse_item_res(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let ident = parse_value_ident(p);\n     let ty_params = parse_ty_params(p);\n     expect(p, token::LPAREN);\n@@ -1928,48 +1896,48 @@ fn parse_mod_items(p: parser, term: token::token,\n         if vec::len(first_item_attrs) == 0u { parse_view(p) } else { [] };\n     let items: [@ast::item] = [];\n     let initial_attrs = first_item_attrs;\n-    while p.peek() != term {\n+    while p.token != term {\n         let attrs = initial_attrs + parse_outer_attributes(p);\n         initial_attrs = [];\n         alt parse_item(p, attrs) {\n           some(i) { items += [i]; }\n           _ {\n             p.fatal(\"expected item but found '\" +\n-                    token::to_str(p.get_reader(), p.peek()) + \"'\");\n+                    token::to_str(p.reader, p.token) + \"'\");\n           }\n         }\n     }\n     ret {view_items: view_items, items: items};\n }\n \n fn parse_item_const(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let id = parse_value_ident(p);\n     expect(p, token::COLON);\n     let ty = parse_ty(p, false);\n     expect(p, token::EQ);\n     let e = parse_expr(p);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::SEMI);\n     ret mk_item(p, lo, hi, id, ast::item_const(ty, e), attrs);\n }\n \n fn parse_item_mod(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let id = parse_ident(p);\n     expect(p, token::LBRACE);\n     let inner_attrs = parse_inner_attrs_and_next(p);\n     let first_item_outer_attrs = inner_attrs.next;\n     let m = parse_mod_items(p, token::RBRACE, first_item_outer_attrs);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::RBRACE);\n     ret mk_item(p, lo, hi, id, ast::item_mod(m), attrs + inner_attrs.inner);\n }\n \n fn parse_item_native_type(p: parser, attrs: [ast::attribute]) ->\n    @ast::native_item {\n     let t = parse_type_decl(p);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::SEMI);\n     ret @{ident: t.ident,\n           attrs: attrs,\n@@ -1980,10 +1948,10 @@ fn parse_item_native_type(p: parser, attrs: [ast::attribute]) ->\n \n fn parse_item_native_fn(p: parser, attrs: [ast::attribute],\n                         purity: ast::purity) -> @ast::native_item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let t = parse_fn_header(p);\n     let decl = parse_fn_decl(p, purity);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::SEMI);\n     ret @{ident: t.ident,\n           attrs: attrs,\n@@ -2004,7 +1972,7 @@ fn parse_native_item(p: parser, attrs: [ast::attribute]) ->\n     } else if eat_word(p, \"unsafe\") {\n         expect_word(p, \"fn\");\n         ret parse_item_native_fn(p, attrs, ast::unsafe_fn);\n-    } else { unexpected(p, p.peek()); }\n+    } else { unexpected(p, p.token); }\n }\n \n fn parse_native_mod_items(p: parser, first_item_attrs: [ast::attribute]) ->\n@@ -2016,7 +1984,7 @@ fn parse_native_mod_items(p: parser, first_item_attrs: [ast::attribute]) ->\n         } else { [] };\n     let items: [@ast::native_item] = [];\n     let initial_attrs = first_item_attrs;\n-    while p.peek() != token::RBRACE {\n+    while p.token != token::RBRACE {\n         let attrs = initial_attrs + parse_outer_attributes(p);\n         initial_attrs = [];\n         items += [parse_native_item(p, attrs)];\n@@ -2026,21 +1994,21 @@ fn parse_native_mod_items(p: parser, first_item_attrs: [ast::attribute]) ->\n }\n \n fn parse_item_native_mod(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     expect_word(p, \"mod\");\n     let id = parse_ident(p);\n     expect(p, token::LBRACE);\n     let more_attrs = parse_inner_attrs_and_next(p);\n     let inner_attrs = more_attrs.inner;\n     let first_item_outer_attrs = more_attrs.next;\n     let m = parse_native_mod_items(p, first_item_outer_attrs);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::RBRACE);\n     ret mk_item(p, lo, hi, id, ast::item_native_mod(m), attrs + inner_attrs);\n }\n \n fn parse_type_decl(p: parser) -> {lo: uint, ident: ast::ident} {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let id = parse_ident(p);\n     ret {lo: lo, ident: id};\n }\n@@ -2050,19 +2018,19 @@ fn parse_item_type(p: parser, attrs: [ast::attribute]) -> @ast::item {\n     let tps = parse_ty_params(p);\n     expect(p, token::EQ);\n     let ty = parse_ty(p, false);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::SEMI);\n     ret mk_item(p, t.lo, hi, t.ident, ast::item_ty(ty, tps), attrs);\n }\n \n fn parse_item_tag(p: parser, attrs: [ast::attribute]) -> @ast::item {\n-    let lo = p.get_last_lo_pos();\n+    let lo = p.last_span.lo;\n     let id = parse_ident(p);\n     let ty_params = parse_ty_params(p);\n     let variants: [ast::variant] = [];\n     // Newtype syntax\n-    if p.peek() == token::EQ {\n-        if p.get_bad_expr_words().contains_key(id) {\n+    if p.token == token::EQ {\n+        if p.bad_expr_words.contains_key(id) {\n             p.fatal(\"found \" + id + \" in tag constructor position\");\n         }\n         p.bump();\n@@ -2082,17 +2050,17 @@ fn parse_item_tag(p: parser, attrs: [ast::attribute]) -> @ast::item {\n     let all_nullary = true;\n     let have_disr = false;\n     let disr_val = 0;\n-    while p.peek() != token::RBRACE {\n-        let tok = p.peek();\n+    while p.token != token::RBRACE {\n+        let tok = p.token;\n         alt tok {\n           token::IDENT(name, _) {\n             check_bad_word(p);\n-            let vlo = p.get_lo_pos();\n+            let vlo = p.span.lo;\n             p.bump();\n             let args: [ast::variant_arg] = [];\n-            let vhi = p.get_hi_pos();\n+            let vhi = p.span.hi;\n             let disr_expr = none;\n-            alt p.peek() {\n+            alt p.token {\n               token::LPAREN. {\n                 all_nullary = false;\n                 let arg_tys = parse_seq(token::LPAREN, token::RPAREN,\n@@ -2142,11 +2110,11 @@ fn parse_item_tag(p: parser, attrs: [ast::attribute]) -> @ast::item {\n           token::RBRACE. {/* empty */ }\n           _ {\n             p.fatal(\"expected name of variant or '}' but found '\" +\n-                        token::to_str(p.get_reader(), tok) + \"'\");\n+                        token::to_str(p.reader, tok) + \"'\");\n           }\n         }\n     }\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     if (have_disr && !all_nullary) {\n         p.fatal(\"discriminator values can only be used with a c-like enum\");\n     }\n@@ -2155,10 +2123,10 @@ fn parse_item_tag(p: parser, attrs: [ast::attribute]) -> @ast::item {\n }\n \n fn parse_fn_ty_proto(p: parser) -> ast::proto {\n-    if p.peek() == token::AT {\n+    if p.token == token::AT {\n         p.bump();\n         ast::proto_box\n-    } else if p.peek() == token::TILDE {\n+    } else if p.token == token::TILDE {\n         p.bump();\n         ast::proto_uniq\n     } else {\n@@ -2218,13 +2186,13 @@ fn parse_item(p: parser, attrs: [ast::attribute]) -> option::t<@ast::item> {\n type attr_or_ext = option::t<either::t<[ast::attribute], @ast::expr>>;\n \n fn parse_outer_attrs_or_ext(p: parser) -> attr_or_ext {\n-    if p.peek() == token::POUND {\n-        let lo = p.get_lo_pos();\n+    if p.token == token::POUND {\n+        let lo = p.span.lo;\n         p.bump();\n-        if p.peek() == token::LBRACKET {\n+        if p.token == token::LBRACKET {\n             let first_attr = parse_attribute_naked(p, ast::attr_outer, lo);\n             ret some(left([first_attr] + parse_outer_attributes(p)));\n-        } else if !(p.peek() == token::LT || p.peek() == token::LBRACKET) {\n+        } else if !(p.token == token::LT || p.token == token::LBRACKET) {\n             ret some(right(parse_syntax_ext_naked(p, lo)));\n         } else { ret none; }\n     } else { ret none; }\n@@ -2233,14 +2201,14 @@ fn parse_outer_attrs_or_ext(p: parser) -> attr_or_ext {\n // Parse attributes that appear before an item\n fn parse_outer_attributes(p: parser) -> [ast::attribute] {\n     let attrs: [ast::attribute] = [];\n-    while p.peek() == token::POUND {\n+    while p.token == token::POUND {\n         attrs += [parse_attribute(p, ast::attr_outer)];\n     }\n     ret attrs;\n }\n \n fn parse_attribute(p: parser, style: ast::attr_style) -> ast::attribute {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     expect(p, token::POUND);\n     ret parse_attribute_naked(p, style, lo);\n }\n@@ -2250,7 +2218,7 @@ fn parse_attribute_naked(p: parser, style: ast::attr_style, lo: uint) ->\n     expect(p, token::LBRACKET);\n     let meta_item = parse_meta_item(p);\n     expect(p, token::RBRACKET);\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     ret spanned(lo, hi, {style: style, value: *meta_item});\n }\n \n@@ -2264,9 +2232,9 @@ fn parse_inner_attrs_and_next(p: parser) ->\n    {inner: [ast::attribute], next: [ast::attribute]} {\n     let inner_attrs: [ast::attribute] = [];\n     let next_outer_attrs: [ast::attribute] = [];\n-    while p.peek() == token::POUND {\n+    while p.token == token::POUND {\n         let attr = parse_attribute(p, ast::attr_inner);\n-        if p.peek() == token::SEMI {\n+        if p.token == token::SEMI {\n             p.bump();\n             inner_attrs += [attr];\n         } else {\n@@ -2282,22 +2250,22 @@ fn parse_inner_attrs_and_next(p: parser) ->\n }\n \n fn parse_meta_item(p: parser) -> @ast::meta_item {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let ident = parse_ident(p);\n-    alt p.peek() {\n+    alt p.token {\n       token::EQ. {\n         p.bump();\n         let lit = parse_lit(p);\n-        let hi = p.get_hi_pos();\n+        let hi = p.span.hi;\n         ret @spanned(lo, hi, ast::meta_name_value(ident, lit));\n       }\n       token::LPAREN. {\n         let inner_items = parse_meta_seq(p);\n-        let hi = p.get_hi_pos();\n+        let hi = p.span.hi;\n         ret @spanned(lo, hi, ast::meta_list(ident, inner_items));\n       }\n       _ {\n-        let hi = p.get_hi_pos();\n+        let hi = p.span.hi;\n         ret @spanned(lo, hi, ast::meta_word(ident));\n       }\n     }\n@@ -2309,7 +2277,7 @@ fn parse_meta_seq(p: parser) -> [@ast::meta_item] {\n }\n \n fn parse_optional_meta(p: parser) -> [@ast::meta_item] {\n-    alt p.peek() { token::LPAREN. { ret parse_meta_seq(p); } _ { ret []; } }\n+    alt p.token { token::LPAREN. { ret parse_meta_seq(p); } _ { ret []; } }\n }\n \n fn parse_use(p: parser) -> ast::view_item_ {\n@@ -2325,7 +2293,7 @@ fn parse_rest_import_name(p: parser, first: ast::ident,\n     let glob: bool = false;\n     let from_idents = option::none::<[ast::import_ident]>;\n     while true {\n-        alt p.peek() {\n+        alt p.token {\n           token::SEMI. { break; }\n           token::MOD_SEP. {\n             if glob { p.fatal(\"cannot path into a glob\"); }\n@@ -2336,7 +2304,7 @@ fn parse_rest_import_name(p: parser, first: ast::ident,\n           }\n           _ { p.fatal(\"expecting '::' or ';'\"); }\n         }\n-        alt p.peek() {\n+        alt p.token {\n           token::IDENT(_, _) { identifiers += [parse_ident(p)]; }\n \n \n@@ -2355,9 +2323,9 @@ fn parse_rest_import_name(p: parser, first: ast::ident,\n \n           token::LBRACE. {\n             fn parse_import_ident(p: parser) -> ast::import_ident {\n-                let lo = p.get_lo_pos();\n+                let lo = p.span.lo;\n                 let ident = parse_ident(p);\n-                let hi = p.get_hi_pos();\n+                let hi = p.span.hi;\n                 ret spanned(lo, hi, {name: ident, id: p.get_id()});\n             }\n             let from_idents_ =\n@@ -2404,7 +2372,7 @@ fn parse_rest_import_name(p: parser, first: ast::ident,\n \n fn parse_full_import_name(p: parser, def_ident: ast::ident) ->\n    ast::view_item_ {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(i, _) {\n         p.bump();\n         ret parse_rest_import_name(p, p.get_str(i), some(def_ident));\n@@ -2414,10 +2382,10 @@ fn parse_full_import_name(p: parser, def_ident: ast::ident) ->\n }\n \n fn parse_import(p: parser) -> ast::view_item_ {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(i, _) {\n         p.bump();\n-        alt p.peek() {\n+        alt p.token {\n           token::EQ. {\n             p.bump();\n             ret parse_full_import_name(p, p.get_str(i));\n@@ -2437,20 +2405,20 @@ fn parse_export(p: parser) -> ast::view_item_ {\n }\n \n fn parse_view_item(p: parser) -> @ast::view_item {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let the_item =\n         if eat_word(p, \"use\") {\n             parse_use(p)\n         } else if eat_word(p, \"import\") {\n             parse_import(p)\n         } else if eat_word(p, \"export\") { parse_export(p) } else { fail };\n-    let hi = p.get_lo_pos();\n+    let hi = p.span.lo;\n     expect(p, token::SEMI);\n     ret @spanned(lo, hi, the_item);\n }\n \n fn is_view_item(p: parser) -> bool {\n-    alt p.peek() {\n+    alt p.token {\n       token::IDENT(sid, false) {\n         let st = p.get_str(sid);\n         ret str::eq(st, \"use\") || str::eq(st, \"import\") ||\n@@ -2493,19 +2461,19 @@ fn parse_crate_from_source_str(name: str, source: str, cfg: ast::crate_cfg,\n \n // Parses a source module as a crate\n fn parse_crate_mod(p: parser, _cfg: ast::crate_cfg) -> @ast::crate {\n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     let crate_attrs = parse_inner_attrs_and_next(p);\n     let first_item_outer_attrs = crate_attrs.next;\n     let m = parse_mod_items(p, token::EOF, first_item_outer_attrs);\n-    ret @spanned(lo, p.get_lo_pos(),\n+    ret @spanned(lo, p.span.lo,\n                  {directives: [],\n                   module: m,\n                   attrs: crate_attrs.inner,\n-                  config: p.get_cfg()});\n+                  config: p.cfg});\n }\n \n fn parse_str(p: parser) -> str {\n-    alt p.peek() {\n+    alt p.token {\n       token::LIT_STR(s) { p.bump(); p.get_str(s) }\n       _ {\n         p.fatal(\"expected string literal\")\n@@ -2526,14 +2494,14 @@ fn parse_crate_directive(p: parser, first_outer_attr: [ast::attribute]) ->\n     // In a crate file outer attributes are only going to apply to mods\n     let expect_mod = vec::len(outer_attrs) > 0u;\n \n-    let lo = p.get_lo_pos();\n+    let lo = p.span.lo;\n     if expect_mod || is_word(p, \"mod\") {\n         expect_word(p, \"mod\");\n         let id = parse_ident(p);\n-        alt p.peek() {\n+        alt p.token {\n           // mod x = \"foo.rs\";\n           token::SEMI. {\n-            let hi = p.get_hi_pos();\n+            let hi = p.span.hi;\n             p.bump();\n             ret spanned(lo, hi, ast::cdir_src_mod(id, outer_attrs));\n           }\n@@ -2545,7 +2513,7 @@ fn parse_crate_directive(p: parser, first_outer_attr: [ast::attribute]) ->\n             let next_outer_attr = inner_attrs.next;\n             let cdirs =\n                 parse_crate_directives(p, token::RBRACE, next_outer_attr);\n-            let hi = p.get_hi_pos();\n+            let hi = p.span.hi;\n             expect(p, token::RBRACE);\n             ret spanned(lo, hi,\n                         ast::cdir_dir_mod(id, cdirs, mod_attrs));\n@@ -2565,13 +2533,13 @@ fn parse_crate_directives(p: parser, term: token::token,\n     // This is pretty ugly. If we have an outer attribute then we can't accept\n     // seeing the terminator next, so if we do see it then fail the same way\n     // parse_crate_directive would\n-    if vec::len(first_outer_attr) > 0u && p.peek() == term {\n+    if vec::len(first_outer_attr) > 0u && p.token == term {\n         expect_word(p, \"mod\");\n     }\n \n     let cdirs: [@ast::crate_directive] = [];\n     let first_outer_attr = first_outer_attr;\n-    while p.peek() != term {\n+    while p.token != term {\n         let cdir = @parse_crate_directive(p, first_outer_attr);\n         cdirs += [cdir];\n         first_outer_attr = [];\n@@ -2582,28 +2550,28 @@ fn parse_crate_directives(p: parser, term: token::token,\n fn parse_crate_from_crate_file(input: str, cfg: ast::crate_cfg,\n                                sess: parse_sess) -> @ast::crate {\n     let p = new_parser_from_file(sess, cfg, input, 0u, 0u, CRATE_FILE);\n-    let lo = p.get_lo_pos();\n-    let prefix = std::fs::dirname(p.get_filemap().name);\n+    let lo = p.span.lo;\n+    let prefix = std::fs::dirname(p.reader.filemap.name);\n     let leading_attrs = parse_inner_attrs_and_next(p);\n     let crate_attrs = leading_attrs.inner;\n     let first_cdir_attr = leading_attrs.next;\n     let cdirs = parse_crate_directives(p, token::EOF, first_cdir_attr);\n     let cx =\n         @{p: p,\n           sess: sess,\n-          mutable chpos: p.get_chpos(),\n-          mutable byte_pos: p.get_byte_pos(),\n-          cfg: p.get_cfg()};\n+          mutable chpos: p.reader.chpos,\n+          mutable byte_pos: p.reader.pos,\n+          cfg: p.cfg};\n     let (companionmod, _) = fs::splitext(fs::basename(input));\n     let (m, attrs) = eval::eval_crate_directives_to_mod(\n         cx, cdirs, prefix, option::some(companionmod));\n-    let hi = p.get_hi_pos();\n+    let hi = p.span.hi;\n     expect(p, token::EOF);\n     ret @spanned(lo, hi,\n                  {directives: cdirs,\n                   module: m,\n                   attrs: crate_attrs + attrs,\n-                  config: p.get_cfg()});\n+                  config: p.cfg});\n }\n \n fn parse_crate_from_file(input: str, cfg: ast::crate_cfg, sess: parse_sess) ->"}, {"sha": "d04396ad9b4773f0424548550b96b30cbaa8afbe", "filename": "src/comp/syntax/parse/token.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f6294455963334fec69fc799442ae74ef65b35e/src%2Fcomp%2Fsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fsyntax%2Fparse%2Ftoken.rs?ref=7f6294455963334fec69fc799442ae74ef65b35e", "patch": "@@ -1,6 +1,7 @@\n \n import util::interner;\n import core::{int, uint, str};\n+import lexer::reader;\n \n type str_num = uint;\n \n@@ -87,7 +88,7 @@ fn binop_to_str(o: binop) -> str {\n     }\n }\n \n-fn to_str(r: lexer::reader, t: token) -> str {\n+fn to_str(r: reader, t: token) -> str {\n     alt t {\n       EQ. { ret \"=\"; }\n       LT. { ret \"<\"; }\n@@ -142,17 +143,17 @@ fn to_str(r: lexer::reader, t: token) -> str {\n         ret uint::to_str(u as uint, 10u) + ast_util::uint_ty_to_str(t);\n       }\n       LIT_FLOAT(s, t) {\n-        ret interner::get::<str>(*r.get_interner(), s) +\n+        ret interner::get::<str>(*r.interner, s) +\n             ast_util::float_ty_to_str(t);\n       }\n       LIT_STR(s) { // FIXME: escape.\n-        ret \"\\\"\" + interner::get::<str>(*r.get_interner(), s) + \"\\\"\";\n+        ret \"\\\"\" + interner::get::<str>(*r.interner, s) + \"\\\"\";\n       }\n       LIT_BOOL(b) { if b { ret \"true\"; } else { ret \"false\"; } }\n \n       /* Name components */\n       IDENT(s, _) {\n-        ret interner::get::<str>(*r.get_interner(), s);\n+        ret interner::get::<str>(*r.interner, s);\n       }\n       IDX(i) { ret \"_\" + int::to_str(i, 10u); }\n       UNDERSCORE. { ret \"_\"; }"}]}