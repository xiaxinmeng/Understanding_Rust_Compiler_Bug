{"sha": "d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ3NjBhYWY3MDc3ZDBiNGIxZTA5M2EzZjM1M2M0Yjg0YzJjNmQzOTQ=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-07-22T15:48:29Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2018-07-22T15:57:31Z"}, "message": "rustc: Implement tokenization of nested items\n\nEver plagued by #43081 the compiler can return surprising spans in situations\nrelated to procedural macros. This is exhibited by #47983 where whenever a\nprocedural macro is invoked in a nested item context it would fail to have\ncorrect span information.\n\nWhile #43230 provided a \"hack\" to cache the token stream used for each item in\nthe compiler it's not a full-blown solution. This commit continues to extend\nthis \"hack\" a bit more to work for nested items.\n\nPreviously in the parser the `parse_item` method would collect the tokens for an\nitem into a cache on the item itself. It turned out, however, that nested items\nwere parsed through the `parse_item_` method, so they didn't receive similar\ntreatment. To remedy this situation the hook for collecting tokens was moved\ninto `parse_item_` instead of `parse_item`.\n\nAfterwards the token collection scheme was updated to support nested collection\nof tokens. This is implemented by tracking `TokenStream` tokens instead of\n`TokenTree` to allow for collecting items into streams at intermediate layers\nand having them interleaved in the upper layers.\n\nAll in all, this...\n\nCloses #47983", "tree": {"sha": "241ae58d8905bf95c66ebcb08535c046ab07bbaa", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/241ae58d8905bf95c66ebcb08535c046ab07bbaa"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "html_url": "https://github.com/rust-lang/rust/commit/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a57d5d7b25d471c902608223793d9b3bb8c4643c", "url": "https://api.github.com/repos/rust-lang/rust/commits/a57d5d7b25d471c902608223793d9b3bb8c4643c", "html_url": "https://github.com/rust-lang/rust/commit/a57d5d7b25d471c902608223793d9b3bb8c4643c"}], "stats": {"total": 199, "additions": 156, "deletions": 43}, "files": [{"sha": "54376797dea990a1cdc6be11a38c5fecb43981be", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 76, "deletions": 43, "changes": 119, "blob_url": "https://github.com/rust-lang/rust/blob/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "patch": "@@ -288,8 +288,8 @@ struct TokenCursorFrame {\n /// on the parser.\n #[derive(Clone)]\n enum LastToken {\n-    Collecting(Vec<TokenTree>),\n-    Was(Option<TokenTree>),\n+    Collecting(Vec<TokenStream>),\n+    Was(Option<TokenStream>),\n }\n \n impl TokenCursorFrame {\n@@ -326,8 +326,8 @@ impl TokenCursor {\n             };\n \n             match self.frame.last_token {\n-                LastToken::Collecting(ref mut v) => v.push(tree.clone()),\n-                LastToken::Was(ref mut t) => *t = Some(tree.clone()),\n+                LastToken::Collecting(ref mut v) => v.push(tree.clone().into()),\n+                LastToken::Was(ref mut t) => *t = Some(tree.clone().into()),\n             }\n \n             match tree {\n@@ -6723,11 +6723,49 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n+    fn parse_item_(\n+        &mut self,\n+        attrs: Vec<Attribute>,\n+        macros_allowed: bool,\n+        attributes_allowed: bool,\n+    ) -> PResult<'a, Option<P<Item>>> {\n+        let (ret, tokens) = self.collect_tokens(|this| {\n+            this.parse_item_implementation(attrs, macros_allowed, attributes_allowed)\n+        })?;\n+\n+        // Once we've parsed an item and recorded the tokens we got while\n+        // parsing we may want to store `tokens` into the item we're about to\n+        // return. Note, though, that we specifically didn't capture tokens\n+        // related to outer attributes. The `tokens` field here may later be\n+        // used with procedural macros to convert this item back into a token\n+        // stream, but during expansion we may be removing attributes as we go\n+        // along.\n+        //\n+        // If we've got inner attributes then the `tokens` we've got above holds\n+        // these inner attributes. If an inner attribute is expanded we won't\n+        // actually remove it from the token stream, so we'll just keep yielding\n+        // it (bad!). To work around this case for now we just avoid recording\n+        // `tokens` if we detect any inner attributes. This should help keep\n+        // expansion correct, but we should fix this bug one day!\n+        Ok(ret.map(|item| {\n+            item.map(|mut i| {\n+                if !i.attrs.iter().any(|attr| attr.style == AttrStyle::Inner) {\n+                    i.tokens = Some(tokens);\n+                }\n+                i\n+            })\n+        }))\n+    }\n+\n     /// Parse one of the items allowed by the flags.\n     /// NB: this function no longer parses the items inside an\n     /// extern crate.\n-    fn parse_item_(&mut self, attrs: Vec<Attribute>,\n-                   macros_allowed: bool, attributes_allowed: bool) -> PResult<'a, Option<P<Item>>> {\n+    fn parse_item_implementation(\n+        &mut self,\n+        attrs: Vec<Attribute>,\n+        macros_allowed: bool,\n+        attributes_allowed: bool,\n+    ) -> PResult<'a, Option<P<Item>>> {\n         maybe_whole!(self, NtItem, |item| {\n             let mut item = item.into_inner();\n             let mut attrs = attrs;\n@@ -7260,12 +7298,15 @@ impl<'a> Parser<'a> {\n     {\n         // Record all tokens we parse when parsing this item.\n         let mut tokens = Vec::new();\n-        match self.token_cursor.frame.last_token {\n-            LastToken::Collecting(_) => {\n-                panic!(\"cannot collect tokens recursively yet\")\n+        let prev_collecting = match self.token_cursor.frame.last_token {\n+            LastToken::Collecting(ref mut list) => {\n+                Some(mem::replace(list, Vec::new()))\n             }\n-            LastToken::Was(ref mut last) => tokens.extend(last.take()),\n-        }\n+            LastToken::Was(ref mut last) => {\n+                tokens.extend(last.take());\n+                None\n+            }\n+        };\n         self.token_cursor.frame.last_token = LastToken::Collecting(tokens);\n         let prev = self.token_cursor.stack.len();\n         let ret = f(self);\n@@ -7274,52 +7315,44 @@ impl<'a> Parser<'a> {\n         } else {\n             &mut self.token_cursor.stack[prev].last_token\n         };\n-        let mut tokens = match *last_token {\n+\n+        // Pull our the toekns that we've collected from the call to `f` above\n+        let mut collected_tokens = match *last_token {\n             LastToken::Collecting(ref mut v) => mem::replace(v, Vec::new()),\n             LastToken::Was(_) => panic!(\"our vector went away?\"),\n         };\n \n         // If we're not at EOF our current token wasn't actually consumed by\n         // `f`, but it'll still be in our list that we pulled out. In that case\n         // put it back.\n-        if self.token == token::Eof {\n-            *last_token = LastToken::Was(None);\n+        let extra_token = if self.token != token::Eof {\n+            collected_tokens.pop()\n         } else {\n-            *last_token = LastToken::Was(tokens.pop());\n+            None\n+        };\n+\n+        // If we were previously collecting tokens, then this was a recursive\n+        // call. In that case we need to record all the tokens we collected in\n+        // our parent list as well. To do that we push a clone of our stream\n+        // onto the previous list.\n+        let stream = collected_tokens.into_iter().collect::<TokenStream>();\n+        match prev_collecting {\n+            Some(mut list) => {\n+                list.push(stream.clone());\n+                list.extend(extra_token);\n+                *last_token = LastToken::Collecting(list);\n+            }\n+            None => {\n+                *last_token = LastToken::Was(extra_token);\n+            }\n         }\n \n-        Ok((ret?, tokens.into_iter().collect()))\n+        Ok((ret?, stream))\n     }\n \n     pub fn parse_item(&mut self) -> PResult<'a, Option<P<Item>>> {\n         let attrs = self.parse_outer_attributes()?;\n-\n-        let (ret, tokens) = self.collect_tokens(|this| {\n-            this.parse_item_(attrs, true, false)\n-        })?;\n-\n-        // Once we've parsed an item and recorded the tokens we got while\n-        // parsing we may want to store `tokens` into the item we're about to\n-        // return. Note, though, that we specifically didn't capture tokens\n-        // related to outer attributes. The `tokens` field here may later be\n-        // used with procedural macros to convert this item back into a token\n-        // stream, but during expansion we may be removing attributes as we go\n-        // along.\n-        //\n-        // If we've got inner attributes then the `tokens` we've got above holds\n-        // these inner attributes. If an inner attribute is expanded we won't\n-        // actually remove it from the token stream, so we'll just keep yielding\n-        // it (bad!). To work around this case for now we just avoid recording\n-        // `tokens` if we detect any inner attributes. This should help keep\n-        // expansion correct, but we should fix this bug one day!\n-        Ok(ret.map(|item| {\n-            item.map(|mut i| {\n-                if !i.attrs.iter().any(|attr| attr.style == AttrStyle::Inner) {\n-                    i.tokens = Some(tokens);\n-                }\n-                i\n-            })\n-        }))\n+        self.parse_item_(attrs, true, false)\n     }\n \n     /// `::{` or `::*`"}, {"sha": "1a4236b280b45b6ddf1da0309217d06834ee31ab", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "patch": "@@ -340,6 +340,7 @@ impl TokenStream {\n     }\n }\n \n+#[derive(Clone)]\n pub struct TokenStreamBuilder(Vec<TokenStream>);\n \n impl TokenStreamBuilder {"}, {"sha": "6b893150b45e4ea194c502cdb35f7bda579709ee", "filename": "src/test/ui-fulldeps/proc-macro/auxiliary/nested-item-spans.rs", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fnested-item-spans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fnested-item-spans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fauxiliary%2Fnested-item-spans.rs?ref=d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "patch": "@@ -0,0 +1,22 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// no-prefer-dynamic\n+\n+#![crate_type = \"proc-macro\"]\n+\n+extern crate proc_macro;\n+\n+use proc_macro::*;\n+\n+#[proc_macro_attribute]\n+pub fn foo(_: TokenStream, item: TokenStream) -> TokenStream {\n+    item.into_iter().collect()\n+}"}, {"sha": "bacab345351ca12e63e2c5fe007aa689e4399874", "filename": "src/test/ui-fulldeps/proc-macro/nested-item-spans.rs", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.rs?ref=d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "patch": "@@ -0,0 +1,36 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// aux-build:nested-item-spans.rs\n+\n+#![feature(use_extern_macros)]\n+\n+extern crate nested_item_spans;\n+\n+use nested_item_spans::foo;\n+\n+#[foo]\n+fn another() {\n+    fn bar() {\n+        let x: u32 = \"x\"; //~ ERROR: mismatched types\n+    }\n+\n+    bar();\n+}\n+\n+fn main() {\n+    #[foo]\n+    fn bar() {\n+        let x: u32 = \"x\"; //~ ERROR: mismatched types\n+    }\n+\n+    bar();\n+    another();\n+}"}, {"sha": "c02cc2520f8d62d9f99ef46393a523c5535aabf4", "filename": "src/test/ui-fulldeps/proc-macro/nested-item-spans.stderr", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/d760aaf7077d0b4b1e093a3f353c4b84c2c6d394/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui-fulldeps%2Fproc-macro%2Fnested-item-spans.stderr?ref=d760aaf7077d0b4b1e093a3f353c4b84c2c6d394", "patch": "@@ -0,0 +1,21 @@\n+error[E0308]: mismatched types\n+  --> $DIR/nested-item-spans.rs:22:22\n+   |\n+LL |         let x: u32 = \"x\"; //~ ERROR: mismatched types\n+   |                      ^^^ expected u32, found reference\n+   |\n+   = note: expected type `u32`\n+              found type `&'static str`\n+\n+error[E0308]: mismatched types\n+  --> $DIR/nested-item-spans.rs:31:22\n+   |\n+LL |         let x: u32 = \"x\"; //~ ERROR: mismatched types\n+   |                      ^^^ expected u32, found reference\n+   |\n+   = note: expected type `u32`\n+              found type `&'static str`\n+\n+error: aborting due to 2 previous errors\n+\n+For more information about this error, try `rustc --explain E0308`."}]}