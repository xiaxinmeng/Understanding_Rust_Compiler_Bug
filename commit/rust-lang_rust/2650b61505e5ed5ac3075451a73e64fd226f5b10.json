{"sha": "2650b61505e5ed5ac3075451a73e64fd226f5b10", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI2NTBiNjE1MDVlNWVkNWFjMzA3NTQ1MWE3M2U2NGZkMjI2ZjViMTA=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-02-11T06:48:45Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2014-02-12T17:46:31Z"}, "message": "Don't hit epoll unless a scheduler absolutely must\n\nCurrently, a scheduler will hit epoll() or kqueue() at the end of *every task*.\nThe reason is that the scheduler will context switch back to the scheduler task,\nterminate the previous task, and then return from run_sched_once. In doing so,\nthe scheduler will poll for any active I/O.\n\nThis shows up painfully in benchmarks that have no I/O at all. For example, this\nbenchmark:\n\n    for _ in range(0, 1000000) {\n        spawn(proc() {});\n    }\n\nIn this benchmark, the scheduler is currently wasting a good chunk of its time\nhitting epoll() when there's always active work to be done (run with\nRUST_THREADS=1).\n\nThis patch uses the previous two commits to alter the scheduler's behavior to\nonly return from run_sched_once if no work could be found when trying really\nreally hard. If there is active I/O, this commit will perform the same as\nbefore, falling back to epoll() to check for I/O completion (to not starve I/O\ntasks).\n\nIn the benchmark above, I got the following numbers:\n\n    12.554s on today's master\n    3.861s  with #12172 applied\n    2.261s  with both this and #12172 applied\n\ncc #8341", "tree": {"sha": "07ee98fa426de7952d7454c924490fda5595ba29", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/07ee98fa426de7952d7454c924490fda5595ba29"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2650b61505e5ed5ac3075451a73e64fd226f5b10", "comment_count": 9, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2650b61505e5ed5ac3075451a73e64fd226f5b10", "html_url": "https://github.com/rust-lang/rust/commit/2650b61505e5ed5ac3075451a73e64fd226f5b10", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2650b61505e5ed5ac3075451a73e64fd226f5b10/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4256d24a16600715aa46007450e6b3d076740711", "url": "https://api.github.com/repos/rust-lang/rust/commits/4256d24a16600715aa46007450e6b3d076740711", "html_url": "https://github.com/rust-lang/rust/commit/4256d24a16600715aa46007450e6b3d076740711"}], "stats": {"total": 69, "additions": 50, "deletions": 19}, "files": [{"sha": "bf42bcfd387b83d9c791b2ae352e6c9363b68bf0", "filename": "src/libgreen/sched.rs", "status": "modified", "additions": 50, "deletions": 19, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/2650b61505e5ed5ac3075451a73e64fd226f5b10/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2650b61505e5ed5ac3075451a73e64fd226f5b10/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=2650b61505e5ed5ac3075451a73e64fd226f5b10", "patch": "@@ -252,12 +252,23 @@ impl Scheduler {\n \n     // * Execution Functions - Core Loop Logic\n \n-    // The model for this function is that you continue through it\n-    // until you either use the scheduler while performing a schedule\n-    // action, in which case you give it away and return early, or\n-    // you reach the end and sleep. In the case that a scheduler\n-    // action is performed the loop is evented such that this function\n-    // is called again.\n+    // This function is run from the idle callback on the uv loop, indicating\n+    // that there are no I/O events pending. When this function returns, we will\n+    // fall back to epoll() in the uv event loop, waiting for more things to\n+    // happen. We may come right back off epoll() if the idle callback is still\n+    // active, in which case we're truly just polling to see if I/O events are\n+    // complete.\n+    //\n+    // The model for this function is to execute as much work as possible while\n+    // still fairly considering I/O tasks. Falling back to epoll() frequently is\n+    // often quite expensive, so we attempt to avoid it as much as possible. If\n+    // we have any active I/O on the event loop, then we're forced to fall back\n+    // to epoll() in order to provide fairness, but as long as we're doing work\n+    // and there's no active I/O, we can continue to do work.\n+    //\n+    // If we try really hard to do some work, but no work is available to be\n+    // done, then we fall back to epoll() to block this thread waiting for more\n+    // work (instead of busy waiting).\n     fn run_sched_once(mut ~self, stask: ~GreenTask) {\n         // Make sure that we're not lying in that the `stask` argument is indeed\n         // the scheduler task for this scheduler.\n@@ -269,23 +280,43 @@ impl Scheduler {\n \n         // First we check for scheduler messages, these are higher\n         // priority than regular tasks.\n-        let (sched, stask, did_work) =\n+        let (mut sched, mut stask, mut did_work) =\n             self.interpret_message_queue(stask, DontTryTooHard);\n-        if did_work {\n-            return stask.put_with_sched(sched);\n-        }\n \n-        // This helper will use a randomized work-stealing algorithm\n-        // to find work.\n-        let (sched, stask, did_work) = sched.do_work(stask);\n-        if did_work {\n-            return stask.put_with_sched(sched);\n+        // After processing a message, we consider doing some more work on the\n+        // event loop. The \"keep going\" condition changes after the first\n+        // iteration becase we don't want to spin here infinitely.\n+        //\n+        // Once we start doing work we can keep doing work so long as the\n+        // iteration does something. Note that we don't want to starve the\n+        // message queue here, so each iteration when we're done working we\n+        // check the message queue regardless of whether we did work or not.\n+        let mut keep_going = !did_work || !sched.event_loop.has_active_io();\n+        while keep_going {\n+            let (a, b, c) = match sched.do_work(stask) {\n+                (sched, task, false) => {\n+                    sched.interpret_message_queue(task, GiveItYourBest)\n+                }\n+                (sched, task, true) => {\n+                    let (sched, task, _) =\n+                        sched.interpret_message_queue(task, GiveItYourBest);\n+                    (sched, task, true)\n+                }\n+            };\n+            sched = a;\n+            stask = b;\n+            did_work = c;\n+\n+            // We only keep going if we managed to do something productive and\n+            // also don't have any active I/O. If we didn't do anything, we\n+            // should consider going to sleep, and if we have active I/O we need\n+            // to poll for completion.\n+            keep_going = did_work && !sched.event_loop.has_active_io();\n         }\n \n-        // Now, before sleeping we need to find out if there really\n-        // were any messages. Give it your best!\n-        let (mut sched, stask, did_work) =\n-            sched.interpret_message_queue(stask, GiveItYourBest);\n+        // If we ever did some work, then we shouldn't put our scheduler\n+        // entirely to sleep just yet. Leave the idle callback active and fall\n+        // back to epoll() to see what's going on.\n         if did_work {\n             return stask.put_with_sched(sched);\n         }"}]}