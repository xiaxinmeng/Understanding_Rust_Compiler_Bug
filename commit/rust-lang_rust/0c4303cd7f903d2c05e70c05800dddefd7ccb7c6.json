{"sha": "0c4303cd7f903d2c05e70c05800dddefd7ccb7c6", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjNDMwM2NkN2Y5MDNkMmMwNWU3MGMwNTgwMGRkZGVmZDdjY2I3YzY=", "commit": {"author": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-09T20:37:38Z"}, "committer": {"name": "Vytautas Astrauskas", "email": "astrauv@amazon.com", "date": "2020-04-27T21:23:32Z"}, "message": "Small refactoring in pthread sync: extract common functionallity to separate functions.", "tree": {"sha": "5368c31314a036d59cbab7cf08a5b3abf7a1756c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5368c31314a036d59cbab7cf08a5b3abf7a1756c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6", "html_url": "https://github.com/rust-lang/rust/commit/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6/comments", "author": null, "committer": null, "parents": [{"sha": "d907fb50215c2f79e4fd312447a67439620bb2ab", "url": "https://api.github.com/repos/rust-lang/rust/commits/d907fb50215c2f79e4fd312447a67439620bb2ab", "html_url": "https://github.com/rust-lang/rust/commit/d907fb50215c2f79e4fd312447a67439620bb2ab"}], "stats": {"total": 235, "additions": 58, "deletions": 177}, "files": [{"sha": "76f97aab239167f076c5646675888a69c80b7676", "filename": "src/shims/sync.rs", "status": "modified", "additions": 58, "deletions": 177, "changes": 235, "blob_url": "https://github.com/rust-lang/rust/blob/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6/src%2Fshims%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c4303cd7f903d2c05e70c05800dddefd7ccb7c6/src%2Fshims%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fsync.rs?ref=0c4303cd7f903d2c05e70c05800dddefd7ccb7c6", "patch": "@@ -1,4 +1,4 @@\n-use rustc_middle::ty::{TyKind, TypeAndMut};\n+use rustc_middle::ty::{layout::TyAndLayout, TyKind, TypeAndMut};\n use rustc_target::abi::{LayoutOf, Size};\n \n use crate::stacked_borrows::Tag;\n@@ -19,35 +19,56 @@ fn assert_ptr_target_min_size<'mir, 'tcx: 'mir>(\n     Ok(())\n }\n \n+fn get_at_offset<'mir, 'tcx: 'mir>(\n+    ecx: &MiriEvalContext<'mir, 'tcx>,\n+    op: OpTy<'tcx, Tag>,\n+    offset: u64,\n+    layout: TyAndLayout<'tcx>,\n+    min_size: u64,\n+) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n+    // Ensure that the following read at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, op, min_size)?;\n+    let op_place = ecx.deref_operand(op)?;\n+    let value_place = op_place.offset(Size::from_bytes(offset), MemPlaceMeta::None, layout, ecx)?;\n+    ecx.read_scalar(value_place.into())\n+}\n+\n+fn set_at_offset<'mir, 'tcx: 'mir>(\n+    ecx: &mut MiriEvalContext<'mir, 'tcx>,\n+    op: OpTy<'tcx, Tag>,\n+    offset: u64,\n+    value: impl Into<ScalarMaybeUndef<Tag>>,\n+    layout: TyAndLayout<'tcx>,\n+    min_size: u64,\n+) -> InterpResult<'tcx, ()> {\n+    // Ensure that the following write at an offset to the attr pointer is within bounds\n+    assert_ptr_target_min_size(ecx, op, min_size)?;\n+    let op_place = ecx.deref_operand(op)?;\n+    let value_place = op_place.offset(Size::from_bytes(offset), MemPlaceMeta::None, layout, ecx)?;\n+    ecx.write_scalar(value.into(), value_place.into())\n+}\n+\n // pthread_mutexattr_t is either 4 or 8 bytes, depending on the platform.\n \n // Our chosen memory layout for emulation (does not have to match the platform layout!):\n // store an i32 in the first four bytes equal to the corresponding libc mutex kind constant\n // (e.g. PTHREAD_MUTEX_NORMAL).\n \n+const PTHREAD_MUTEXATTR_T_MIN_SIZE: u64 = 4;\n+\n fn mutexattr_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     attr_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let kind_place =\n-        attr_place.offset(Size::ZERO, MemPlaceMeta::None, ecx.machine.layouts.i32, ecx)?;\n-    ecx.read_scalar(kind_place.into())\n+    get_at_offset(ecx, attr_op, 0, ecx.machine.layouts.i32, PTHREAD_MUTEXATTR_T_MIN_SIZE)\n }\n \n fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     attr_op: OpTy<'tcx, Tag>,\n     kind: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the attr pointer is within bounds\n-    assert_ptr_target_min_size(ecx, attr_op, 4)?;\n-    let attr_place = ecx.deref_operand(attr_op)?;\n-    let kind_place =\n-        attr_place.offset(Size::ZERO, MemPlaceMeta::None, ecx.machine.layouts.i32, ecx)?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n+    set_at_offset(ecx, attr_op, 0, kind, ecx.machine.layouts.i32, PTHREAD_MUTEXATTR_T_MIN_SIZE)\n }\n \n // pthread_mutex_t is between 24 and 48 bytes, depending on the platform.\n@@ -61,138 +82,68 @@ fn mutexattr_set_kind<'mir, 'tcx: 'mir>(\n // (the kind has to be at its offset for compatibility with static initializer macros)\n // bytes 20-23: when count > 0, id of the blockset in which the blocked threads are waiting.\n \n+const PTHREAD_MUTEX_T_MIN_SIZE: u64 = 24;\n+\n fn mutex_get_locked_count<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let locked_count_place = mutex_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(locked_count_place.into())\n+    get_at_offset(ecx, mutex_op, 4, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_locked_count<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n     locked_count: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let locked_count_place = mutex_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(locked_count.into(), locked_count_place.into())\n+    set_at_offset(ecx, mutex_op, 4, locked_count, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_get_owner<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let mutex_id_place = mutex_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(mutex_id_place.into())\n+    get_at_offset(ecx, mutex_op, 8, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_owner<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n-    mutex_id: impl Into<ScalarMaybeUndef<Tag>>,\n+    owner: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let mutex_id_place = mutex_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(mutex_id.into(), mutex_id_place.into())\n+    set_at_offset(ecx, mutex_op, 8, owner, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_get_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place = mutex_place.offset(\n-        Size::from_bytes(kind_offset),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.i32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(kind_place.into())\n+    let offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    get_at_offset(ecx, mutex_op, offset, ecx.machine.layouts.i32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_kind<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n     kind: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let kind_offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n-    let kind_place = mutex_place.offset(\n-        Size::from_bytes(kind_offset),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.i32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(kind.into(), kind_place.into())\n+    let offset = if ecx.pointer_size().bytes() == 8 { 16 } else { 12 };\n+    set_at_offset(ecx, mutex_op, offset, kind, ecx.machine.layouts.i32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_get_blockset<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let mutex_id_place = mutex_place.offset(\n-        Size::from_bytes(20),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(mutex_id_place.into())\n+    get_at_offset(ecx, mutex_op, 20, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_set_blockset<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     mutex_op: OpTy<'tcx, Tag>,\n-    mutex_id: impl Into<ScalarMaybeUndef<Tag>>,\n+    blockset: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the mutex pointer is within bounds\n-    assert_ptr_target_min_size(ecx, mutex_op, 24)?;\n-    let mutex_place = ecx.deref_operand(mutex_op)?;\n-    let mutex_id_place = mutex_place.offset(\n-        Size::from_bytes(20),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(mutex_id.into(), mutex_id_place.into())\n+    set_at_offset(ecx, mutex_op, 20, blockset, ecx.machine.layouts.u32, PTHREAD_MUTEX_T_MIN_SIZE)\n }\n \n fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n@@ -223,103 +174,51 @@ fn mutex_get_or_create_blockset<'mir, 'tcx: 'mir>(\n // bytes 16-20: when writer count > 0, id of the blockset in which the blocked\n // readers are waiting.\n \n+const PTHREAD_RWLOCK_T_MIN_SIZE: u64 = 20;\n+\n fn rwlock_get_readers<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let readers_place = rwlock_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(readers_place.into())\n+    get_at_offset(ecx, rwlock_op, 4, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_readers<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     readers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let readers_place = rwlock_place.offset(\n-        Size::from_bytes(4),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(readers.into(), readers_place.into())\n+    set_at_offset(ecx, rwlock_op, 4, readers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_get_writers<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let writers_place = rwlock_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(writers_place.into())\n+    get_at_offset(ecx, rwlock_op, 8, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_writers<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     writers: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let writers_place = rwlock_place.offset(\n-        Size::from_bytes(8),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(writers.into(), writers_place.into())\n+    set_at_offset(ecx, rwlock_op, 8, writers, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_get_writer_blockset<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let blockset_place = rwlock_place.offset(\n-        Size::from_bytes(12),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(blockset_place.into())\n+    get_at_offset(ecx, rwlock_op, 12, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_writer_blockset<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     blockset: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let blockset_place = rwlock_place.offset(\n-        Size::from_bytes(12),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(blockset.into(), blockset_place.into())\n+    set_at_offset(ecx, rwlock_op, 12, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_get_or_create_writer_blockset<'mir, 'tcx: 'mir>(\n@@ -342,33 +241,15 @@ fn rwlock_get_reader_blockset<'mir, 'tcx: 'mir>(\n     ecx: &MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n ) -> InterpResult<'tcx, ScalarMaybeUndef<Tag>> {\n-    // Ensure that the following read at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let blockset_place = rwlock_place.offset(\n-        Size::from_bytes(16),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.read_scalar(blockset_place.into())\n+    get_at_offset(ecx, rwlock_op, 16, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_set_reader_blockset<'mir, 'tcx: 'mir>(\n     ecx: &mut MiriEvalContext<'mir, 'tcx>,\n     rwlock_op: OpTy<'tcx, Tag>,\n     blockset: impl Into<ScalarMaybeUndef<Tag>>,\n ) -> InterpResult<'tcx, ()> {\n-    // Ensure that the following write at an offset to the rwlock pointer is within bounds\n-    assert_ptr_target_min_size(ecx, rwlock_op, 20)?;\n-    let rwlock_place = ecx.deref_operand(rwlock_op)?;\n-    let blockset_place = rwlock_place.offset(\n-        Size::from_bytes(16),\n-        MemPlaceMeta::None,\n-        ecx.machine.layouts.u32,\n-        ecx,\n-    )?;\n-    ecx.write_scalar(blockset.into(), blockset_place.into())\n+    set_at_offset(ecx, rwlock_op, 16, blockset, ecx.machine.layouts.u32, PTHREAD_RWLOCK_T_MIN_SIZE)\n }\n \n fn rwlock_get_or_create_reader_blockset<'mir, 'tcx: 'mir>("}]}