{"sha": "cbd05957103926fa10d41474fde773167fe64dfb", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNiZDA1OTU3MTAzOTI2ZmExMGQ0MTQ3NGZkZTc3MzE2N2ZlNjRkZmI=", "commit": {"author": {"name": "Donato Sciarra", "email": "sciarp@gmail.com", "date": "2018-08-18T10:13:56Z"}, "committer": {"name": "Donato Sciarra", "email": "sciarp@gmail.com", "date": "2018-08-19T21:00:59Z"}, "message": "mv filemap source_file", "tree": {"sha": "8ff2321dca0305ba524398cf1d415afc51efeeab", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8ff2321dca0305ba524398cf1d415afc51efeeab"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cbd05957103926fa10d41474fde773167fe64dfb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cbd05957103926fa10d41474fde773167fe64dfb", "html_url": "https://github.com/rust-lang/rust/commit/cbd05957103926fa10d41474fde773167fe64dfb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cbd05957103926fa10d41474fde773167fe64dfb/comments", "author": {"login": "dsciarra", "id": 2036702, "node_id": "MDQ6VXNlcjIwMzY3MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/2036702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dsciarra", "html_url": "https://github.com/dsciarra", "followers_url": "https://api.github.com/users/dsciarra/followers", "following_url": "https://api.github.com/users/dsciarra/following{/other_user}", "gists_url": "https://api.github.com/users/dsciarra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dsciarra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dsciarra/subscriptions", "organizations_url": "https://api.github.com/users/dsciarra/orgs", "repos_url": "https://api.github.com/users/dsciarra/repos", "events_url": "https://api.github.com/users/dsciarra/events{/privacy}", "received_events_url": "https://api.github.com/users/dsciarra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "dsciarra", "id": 2036702, "node_id": "MDQ6VXNlcjIwMzY3MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/2036702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dsciarra", "html_url": "https://github.com/dsciarra", "followers_url": "https://api.github.com/users/dsciarra/followers", "following_url": "https://api.github.com/users/dsciarra/following{/other_user}", "gists_url": "https://api.github.com/users/dsciarra/gists{/gist_id}", "starred_url": "https://api.github.com/users/dsciarra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dsciarra/subscriptions", "organizations_url": "https://api.github.com/users/dsciarra/orgs", "repos_url": "https://api.github.com/users/dsciarra/repos", "events_url": "https://api.github.com/users/dsciarra/events{/privacy}", "received_events_url": "https://api.github.com/users/dsciarra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d6dcbcd4e11a1b787a9db1fa43a49907e8bccecf", "url": "https://api.github.com/repos/rust-lang/rust/commits/d6dcbcd4e11a1b787a9db1fa43a49907e8bccecf", "html_url": "https://github.com/rust-lang/rust/commit/d6dcbcd4e11a1b787a9db1fa43a49907e8bccecf"}], "stats": {"total": 418, "additions": 209, "deletions": 209}, "files": [{"sha": "08ae78f775bdf9085f23ab7c48c017f985b7edfd", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -440,9 +440,9 @@ impl SourceFile {\n     /// [`is_real`]: #method.is_real\n     #[unstable(feature = \"proc_macro_span\", issue = \"38356\")]\n     pub fn path(&self) -> PathBuf {\n-        match self.filemap.name {\n+        match self.source_file.name {\n             FileName::Real(ref path) => path.clone(),\n-            _ => PathBuf::from(self.filemap.name.to_string())\n+            _ => PathBuf::from(self.source_file.name.to_string())\n         }\n     }\n \n@@ -453,7 +453,7 @@ impl SourceFile {\n         // This is a hack until intercrate spans are implemented and we can have real source files\n         // for spans generated in external macros.\n         // https://github.com/rust-lang/rust/pull/43604#issuecomment-333334368\n-        self.filemap.is_real_file()\n+        self.source_file.is_real_file()\n     }\n }\n \n@@ -471,7 +471,7 @@ impl fmt::Debug for SourceFile {\n #[unstable(feature = \"proc_macro_span\", issue = \"38356\")]\n impl PartialEq for SourceFile {\n     fn eq(&self, other: &Self) -> bool {\n-        Lrc::ptr_eq(&self.filemap, &other.filemap)\n+        Lrc::ptr_eq(&self.source_file, &other.source_file)\n     }\n }\n "}, {"sha": "7a304603ada6af4bfbd056ad3fa581f64d749670", "filename": "src/librustc/hir/map/collector.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fcollector.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -158,8 +158,8 @@ impl<'a, 'hir> NodeCollector<'a, 'hir> {\n         let mut source_file_names: Vec<_> = codemap\n             .files()\n             .iter()\n-            .filter(|filemap| CrateNum::from_u32(filemap.crate_of_origin) == LOCAL_CRATE)\n-            .map(|filemap| filemap.name_hash)\n+            .filter(|source_file| CrateNum::from_u32(source_file.crate_of_origin) == LOCAL_CRATE)\n+            .map(|source_file| source_file.name_hash)\n             .collect();\n \n         source_file_names.sort_unstable();"}, {"sha": "adfb9b6181a9cb038c0b13978c380fffd90eb0e9", "filename": "src/librustc/ich/caching_codemap_view.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fich%2Fcaching_codemap_view.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fich%2Fcaching_codemap_view.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fcaching_codemap_view.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -79,7 +79,7 @@ impl<'cm> CachingCodemapView<'cm> {\n         if pos < cache_entry.file.start_pos || pos >= cache_entry.file.end_pos {\n             let file_valid;\n             if self.codemap.files().len() > 0 {\n-                let file_index = self.codemap.lookup_filemap_idx(pos);\n+                let file_index = self.codemap.lookup_source_file_idx(pos);\n                 let file = self.codemap.files()[file_index].clone();\n \n                 if pos >= file.start_pos && pos < file.end_pos {"}, {"sha": "65b84ce4a82251b9864c19eca07aeab1b822dd46", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -458,13 +458,13 @@ impl<'a> HashStable<StableHashingContext<'a>> for SourceFile {\n \n         src_hash.hash_stable(hcx, hasher);\n \n-        // We only hash the relative position within this filemap\n+        // We only hash the relative position within this source_file\n         lines.len().hash_stable(hcx, hasher);\n         for &line in lines.iter() {\n             stable_byte_pos(line, start_pos).hash_stable(hcx, hasher);\n         }\n \n-        // We only hash the relative position within this filemap\n+        // We only hash the relative position within this source_file\n         multibyte_chars.len().hash_stable(hcx, hasher);\n         for &char_pos in multibyte_chars.iter() {\n             stable_multibyte_char(char_pos, start_pos).hash_stable(hcx, hasher);\n@@ -478,29 +478,29 @@ impl<'a> HashStable<StableHashingContext<'a>> for SourceFile {\n }\n \n fn stable_byte_pos(pos: ::syntax_pos::BytePos,\n-                   filemap_start: ::syntax_pos::BytePos)\n+                   source_file_start: ::syntax_pos::BytePos)\n                    -> u32 {\n-    pos.0 - filemap_start.0\n+    pos.0 - source_file_start.0\n }\n \n fn stable_multibyte_char(mbc: ::syntax_pos::MultiByteChar,\n-                         filemap_start: ::syntax_pos::BytePos)\n+                         source_file_start: ::syntax_pos::BytePos)\n                          -> (u32, u32) {\n     let ::syntax_pos::MultiByteChar {\n         pos,\n         bytes,\n     } = mbc;\n \n-    (pos.0 - filemap_start.0, bytes as u32)\n+    (pos.0 - source_file_start.0, bytes as u32)\n }\n \n fn stable_non_narrow_char(swc: ::syntax_pos::NonNarrowChar,\n-                          filemap_start: ::syntax_pos::BytePos)\n+                          source_file_start: ::syntax_pos::BytePos)\n                           -> (u32, u32) {\n     let pos = swc.pos();\n     let width = swc.width();\n \n-    (pos.0 - filemap_start.0, width as u32)\n+    (pos.0 - source_file_start.0, width as u32)\n }\n \n "}, {"sha": "0dcdf44d6e67ee4523b50c9100c2d98b958a1c4d", "filename": "src/librustc/ty/query/on_disk_cache.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fon_disk_cache.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -494,7 +494,7 @@ impl<'a, 'tcx, 'x> CacheDecoder<'a, 'tcx, 'x> {\n \n         file_index_to_file.borrow_mut().entry(index).or_insert_with(|| {\n             let stable_id = file_index_to_stable_id[&index];\n-            codemap.filemap_by_stable_id(stable_id)\n+            codemap.source_file_by_stable_id(stable_id)\n                    .expect(\"Failed to lookup SourceFile in new context.\")\n         }).clone()\n     }\n@@ -777,8 +777,8 @@ struct CacheEncoder<'enc, 'a, 'tcx, E>\n impl<'enc, 'a, 'tcx, E> CacheEncoder<'enc, 'a, 'tcx, E>\n     where E: 'enc + ty_codec::TyEncoder\n {\n-    fn filemap_index(&mut self, filemap: Lrc<SourceFile>) -> SourceFileIndex {\n-        self.file_to_file_index[&(&*filemap as *const SourceFile)]\n+    fn source_file_index(&mut self, source_file: Lrc<SourceFile>) -> SourceFileIndex {\n+        self.file_to_file_index[&(&*source_file as *const SourceFile)]\n     }\n \n     /// Encode something with additional information that allows to do some\n@@ -850,10 +850,10 @@ impl<'enc, 'a, 'tcx, E> SpecializedEncoder<Span> for CacheEncoder<'enc, 'a, 'tcx\n \n         let len = span_data.hi - span_data.lo;\n \n-        let filemap_index = self.filemap_index(file_lo);\n+        let source_file_index = self.source_file_index(file_lo);\n \n         TAG_VALID_SPAN.encode(self)?;\n-        filemap_index.encode(self)?;\n+        source_file_index.encode(self)?;\n         line_lo.encode(self)?;\n         col_lo.encode(self)?;\n         len.encode(self)?;"}, {"sha": "4d4198d34bc2779fc585c1b2d7b0f0c24697d090", "filename": "src/librustc_driver/pretty.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_driver%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_driver%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fpretty.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -916,7 +916,7 @@ pub fn fold_crate(sess: &Session, krate: ast::Crate, ppm: PpMode) -> ast::Crate\n fn get_source(input: &Input, sess: &Session) -> (Vec<u8>, FileName) {\n     let src_name = driver::source_name(input);\n     let src = sess.codemap()\n-        .get_filemap(&src_name)\n+        .get_source_file(&src_name)\n         .unwrap()\n         .src\n         .as_ref()"}, {"sha": "b4034a6a529bd65313240732ae5f1e93124103f5", "filename": "src/librustc_errors/emitter.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_errors%2Femitter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_errors%2Femitter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Femitter.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -1021,7 +1021,7 @@ impl EmitterWriter {\n         // Print out the annotate source lines that correspond with the error\n         for annotated_file in annotated_files {\n             // we can't annotate anything if the source is unavailable.\n-            if !cm.ensure_filemap_source_present(annotated_file.file.clone()) {\n+            if !cm.ensure_source_file_source_present(annotated_file.file.clone()) {\n                 continue;\n             }\n "}, {"sha": "ae88a365cbe48f19338227e41d55c084fc795883", "filename": "src/librustc_errors/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_errors%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_errors%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_errors%2Flib.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -120,7 +120,7 @@ pub trait SourceMapper {\n     fn span_to_filename(&self, sp: Span) -> FileName;\n     fn merge_spans(&self, sp_lhs: Span, sp_rhs: Span) -> Option<Span>;\n     fn call_span_if_macro(&self, sp: Span) -> Span;\n-    fn ensure_filemap_source_present(&self, file_map: Lrc<SourceFile>) -> bool;\n+    fn ensure_source_file_source_present(&self, file_map: Lrc<SourceFile>) -> bool;\n     fn doctest_offset_line(&self, line: usize) -> usize;\n }\n "}, {"sha": "5c020b70e30364a7dc96f431f4f9a1852061b425", "filename": "src/librustc_metadata/cstore.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fcstore.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fcstore.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -42,14 +42,14 @@ pub use rustc_data_structures::sync::MetadataRef;\n pub struct MetadataBlob(pub MetadataRef);\n \n /// Holds information about a syntax_pos::SourceFile imported from another crate.\n-/// See `imported_filemaps()` for more information.\n+/// See `imported_source_files()` for more information.\n pub struct ImportedSourceFile {\n     /// This SourceFile's byte-offset within the codemap of its original crate\n     pub original_start_pos: syntax_pos::BytePos,\n     /// The end of this SourceFile within the codemap of its original crate\n     pub original_end_pos: syntax_pos::BytePos,\n     /// The imported SourceFile's representation within the local codemap\n-    pub translated_filemap: Lrc<syntax_pos::SourceFile>,\n+    pub translated_source_file: Lrc<syntax_pos::SourceFile>,\n }\n \n pub struct CrateMetadata {"}, {"sha": "54431e669a807346f5bc3e6ef5e35ecba24fefe5", "filename": "src/librustc_metadata/cstore_impl.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore_impl.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -40,7 +40,7 @@ use syntax::ast;\n use syntax::attr;\n use syntax::codemap;\n use syntax::edition::Edition;\n-use syntax::parse::filemap_to_stream;\n+use syntax::parse::source_file_to_stream;\n use syntax::symbol::Symbol;\n use syntax_pos::{Span, NO_EXPANSION, FileName};\n use rustc_data_structures::indexed_set::IdxSetBuf;\n@@ -463,9 +463,9 @@ impl cstore::CStore {\n         let (name, def) = data.get_macro(id.index);\n         let source_name = FileName::Macros(name.to_string());\n \n-        let filemap = sess.parse_sess.codemap().new_filemap(source_name, def.body);\n-        let local_span = Span::new(filemap.start_pos, filemap.end_pos, NO_EXPANSION);\n-        let body = filemap_to_stream(&sess.parse_sess, filemap, None);\n+        let source_file = sess.parse_sess.codemap().new_source_file(source_name, def.body);\n+        let local_span = Span::new(source_file.start_pos, source_file.end_pos, NO_EXPANSION);\n+        let body = source_file_to_stream(&sess.parse_sess, source_file, None);\n \n         // Mark the attrs as used\n         let attrs = data.get_item_attrs(id.index, sess);"}, {"sha": "1efe6e50a2497223cfcbc1b16610c3040a604b61", "filename": "src/librustc_metadata/decoder.rs", "status": "modified", "additions": 32, "deletions": 32, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fdecoder.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -50,8 +50,8 @@ pub struct DecodeContext<'a, 'tcx: 'a> {\n     sess: Option<&'a Session>,\n     tcx: Option<TyCtxt<'a, 'tcx, 'tcx>>,\n \n-    // Cache the last used filemap for translating spans as an optimization.\n-    last_filemap_index: usize,\n+    // Cache the last used source_file for translating spans as an optimization.\n+    last_source_file_index: usize,\n \n     lazy_state: LazyState,\n \n@@ -73,7 +73,7 @@ pub trait Metadata<'a, 'tcx>: Copy {\n             cdata: self.cdata(),\n             sess: self.sess().or(tcx.map(|tcx| tcx.sess)),\n             tcx,\n-            last_filemap_index: 0,\n+            last_source_file_index: 0,\n             lazy_state: LazyState::NoNode,\n             alloc_decoding_session: self.cdata().map(|cdata| {\n                 cdata.alloc_decoding_state.new_decoding_session()\n@@ -314,43 +314,43 @@ impl<'a, 'tcx> SpecializedDecoder<Span> for DecodeContext<'a, 'tcx> {\n             bug!(\"Cannot decode Span without Session.\")\n         };\n \n-        let imported_filemaps = self.cdata().imported_filemaps(&sess.codemap());\n-        let filemap = {\n+        let imported_source_files = self.cdata().imported_source_files(&sess.codemap());\n+        let source_file = {\n             // Optimize for the case that most spans within a translated item\n-            // originate from the same filemap.\n-            let last_filemap = &imported_filemaps[self.last_filemap_index];\n+            // originate from the same source_file.\n+            let last_source_file = &imported_source_files[self.last_source_file_index];\n \n-            if lo >= last_filemap.original_start_pos &&\n-               lo <= last_filemap.original_end_pos {\n-                last_filemap\n+            if lo >= last_source_file.original_start_pos &&\n+               lo <= last_source_file.original_end_pos {\n+                last_source_file\n             } else {\n                 let mut a = 0;\n-                let mut b = imported_filemaps.len();\n+                let mut b = imported_source_files.len();\n \n                 while b - a > 1 {\n                     let m = (a + b) / 2;\n-                    if imported_filemaps[m].original_start_pos > lo {\n+                    if imported_source_files[m].original_start_pos > lo {\n                         b = m;\n                     } else {\n                         a = m;\n                     }\n                 }\n \n-                self.last_filemap_index = a;\n-                &imported_filemaps[a]\n+                self.last_source_file_index = a;\n+                &imported_source_files[a]\n             }\n         };\n \n         // Make sure our binary search above is correct.\n-        debug_assert!(lo >= filemap.original_start_pos &&\n-                      lo <= filemap.original_end_pos);\n+        debug_assert!(lo >= source_file.original_start_pos &&\n+                      lo <= source_file.original_end_pos);\n \n         // Make sure we correctly filtered out invalid spans during encoding\n-        debug_assert!(hi >= filemap.original_start_pos &&\n-                      hi <= filemap.original_end_pos);\n+        debug_assert!(hi >= source_file.original_start_pos &&\n+                      hi <= source_file.original_end_pos);\n \n-        let lo = (lo + filemap.translated_filemap.start_pos) - filemap.original_start_pos;\n-        let hi = (hi + filemap.translated_filemap.start_pos) - filemap.original_start_pos;\n+        let lo = (lo + source_file.translated_source_file.start_pos) - source_file.original_start_pos;\n+        let hi = (hi + source_file.translated_source_file.start_pos) - source_file.original_start_pos;\n \n         Ok(Span::new(lo, hi, NO_EXPANSION))\n     }\n@@ -1116,13 +1116,13 @@ impl<'a, 'tcx> CrateMetadata {\n     /// file they represent, just information about length, line breaks, and\n     /// multibyte characters. This information is enough to generate valid debuginfo\n     /// for items inlined from other crates.\n-    pub fn imported_filemaps(&'a self,\n+    pub fn imported_source_files(&'a self,\n                              local_codemap: &codemap::SourceMap)\n                              -> ReadGuard<'a, Vec<cstore::ImportedSourceFile>> {\n         {\n-            let filemaps = self.codemap_import_info.borrow();\n-            if !filemaps.is_empty() {\n-                return filemaps;\n+            let source_files = self.codemap_import_info.borrow();\n+            if !source_files.is_empty() {\n+                return source_files;\n             }\n         }\n \n@@ -1136,7 +1136,7 @@ impl<'a, 'tcx> CrateMetadata {\n \n         let external_codemap = self.root.codemap.decode(self);\n \n-        let imported_filemaps = external_codemap.map(|filemap_to_import| {\n+        let imported_source_files = external_codemap.map(|source_file_to_import| {\n             // We can't reuse an existing SourceFile, so allocate a new one\n             // containing the information we need.\n             let syntax_pos::SourceFile { name,\n@@ -1148,13 +1148,13 @@ impl<'a, 'tcx> CrateMetadata {\n                                       mut multibyte_chars,\n                                       mut non_narrow_chars,\n                                       name_hash,\n-                                      .. } = filemap_to_import;\n+                                      .. } = source_file_to_import;\n \n             let source_length = (end_pos - start_pos).to_usize();\n \n             // Translate line-start positions and multibyte character\n             // position into frame of reference local to file.\n-            // `SourceMap::new_imported_filemap()` will then translate those\n+            // `SourceMap::new_imported_source_file()` will then translate those\n             // coordinates to their new global frame of reference when the\n             // offset of the SourceFile is known.\n             for pos in &mut lines {\n@@ -1167,7 +1167,7 @@ impl<'a, 'tcx> CrateMetadata {\n                 *swc = *swc - start_pos;\n             }\n \n-            let local_version = local_codemap.new_imported_filemap(name,\n+            let local_version = local_codemap.new_imported_source_file(name,\n                                                                    name_was_remapped,\n                                                                    self.cnum.as_u32(),\n                                                                    src_hash,\n@@ -1176,20 +1176,20 @@ impl<'a, 'tcx> CrateMetadata {\n                                                                    lines,\n                                                                    multibyte_chars,\n                                                                    non_narrow_chars);\n-            debug!(\"CrateMetaData::imported_filemaps alloc \\\n-                    filemap {:?} original (start_pos {:?} end_pos {:?}) \\\n+            debug!(\"CrateMetaData::imported_source_files alloc \\\n+                    source_file {:?} original (start_pos {:?} end_pos {:?}) \\\n                     translated (start_pos {:?} end_pos {:?})\",\n                    local_version.name, start_pos, end_pos,\n                    local_version.start_pos, local_version.end_pos);\n \n             cstore::ImportedSourceFile {\n                 original_start_pos: start_pos,\n                 original_end_pos: end_pos,\n-                translated_filemap: local_version,\n+                translated_source_file: local_version,\n             }\n         }).collect();\n \n-        *codemap_import_info = imported_filemaps;\n+        *codemap_import_info = imported_source_files;\n         drop(codemap_import_info);\n \n         // This shouldn't borrow twice, but there is no way to downgrade RefMut to Ref."}, {"sha": "2111cb363b21c526b50499fa5ce708b4fb49e440", "filename": "src/librustc_metadata/encoder.rs", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_metadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fencoder.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -62,7 +62,7 @@ pub struct EncodeContext<'a, 'tcx: 'a> {\n     interpret_allocs_inverse: Vec<interpret::AllocId>,\n \n     // This is used to speed up Span encoding.\n-    filemap_cache: Lrc<SourceFile>,\n+    source_file_cache: Lrc<SourceFile>,\n }\n \n macro_rules! encoder_methods {\n@@ -157,13 +157,13 @@ impl<'a, 'tcx> SpecializedEncoder<Span> for EncodeContext<'a, 'tcx> {\n         // The Span infrastructure should make sure that this invariant holds:\n         debug_assert!(span.lo <= span.hi);\n \n-        if !self.filemap_cache.contains(span.lo) {\n+        if !self.source_file_cache.contains(span.lo) {\n             let codemap = self.tcx.sess.codemap();\n-            let filemap_index = codemap.lookup_filemap_idx(span.lo);\n-            self.filemap_cache = codemap.files()[filemap_index].clone();\n+            let source_file_index = codemap.lookup_source_file_idx(span.lo);\n+            self.source_file_cache = codemap.files()[source_file_index].clone();\n         }\n \n-        if !self.filemap_cache.contains(span.hi) {\n+        if !self.source_file_cache.contains(span.hi) {\n             // Unfortunately, macro expansion still sometimes generates Spans\n             // that malformed in this way.\n             return TAG_INVALID_SPAN.encode(self)\n@@ -339,34 +339,34 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n \n     fn encode_codemap(&mut self) -> LazySeq<syntax_pos::SourceFile> {\n         let codemap = self.tcx.sess.codemap();\n-        let all_filemaps = codemap.files();\n+        let all_source_files = codemap.files();\n \n         let (working_dir, working_dir_was_remapped) = self.tcx.sess.working_dir.clone();\n \n-        let adapted = all_filemaps.iter()\n-            .filter(|filemap| {\n-                // No need to re-export imported filemaps, as any downstream\n+        let adapted = all_source_files.iter()\n+            .filter(|source_file| {\n+                // No need to re-export imported source_files, as any downstream\n                 // crate will import them from their original source.\n-                !filemap.is_imported()\n+                !source_file.is_imported()\n             })\n-            .map(|filemap| {\n+            .map(|source_file| {\n                 // When exporting SourceFiles, we expand all paths to absolute\n                 // paths because any relative paths are potentially relative to\n                 // a wrong directory.\n                 // However, if a path has been modified via\n                 // `--remap-path-prefix` we assume the user has already set\n                 // things up the way they want and don't touch the path values\n                 // anymore.\n-                match filemap.name {\n+                match source_file.name {\n                     FileName::Real(ref name) => {\n-                        if filemap.name_was_remapped ||\n+                        if source_file.name_was_remapped ||\n                         (name.is_relative() && working_dir_was_remapped) {\n                             // This path of this SourceFile has been modified by\n                             // path-remapping, so we use it verbatim (and avoid cloning\n                             // the whole map in the process).\n-                            filemap.clone()\n+                            source_file.clone()\n                         } else {\n-                            let mut adapted = (**filemap).clone();\n+                            let mut adapted = (**source_file).clone();\n                             adapted.name = Path::new(&working_dir).join(name).into();\n                             adapted.name_hash = {\n                                 let mut hasher: StableHasher<u128> = StableHasher::new();\n@@ -377,7 +377,7 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n                         }\n                     },\n                     // expanded code, not from a file\n-                    _ => filemap.clone(),\n+                    _ => source_file.clone(),\n                 }\n             })\n             .collect::<Vec<_>>();\n@@ -1842,7 +1842,7 @@ pub fn encode_metadata<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             lazy_state: LazyState::NoNode,\n             type_shorthands: Default::default(),\n             predicate_shorthands: Default::default(),\n-            filemap_cache: tcx.sess.codemap().files()[0].clone(),\n+            source_file_cache: tcx.sess.codemap().files()[0].clone(),\n             interpret_allocs: Default::default(),\n             interpret_allocs_inverse: Default::default(),\n         };"}, {"sha": "f764042926a161d228063984e2c83d9e3ab4cc69", "filename": "src/librustc_save_analysis/span_utils.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustc_save_analysis%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_save_analysis%2Fspan_utils.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -276,7 +276,7 @@ impl<'a> SpanUtils<'a> {\n             None => return true,\n         };\n \n-        //If the span comes from a fake filemap, filter it.\n+        //If the span comes from a fake source_file, filter it.\n         if !self.sess\n             .codemap()\n             .lookup_char_pos(parent.lo())"}, {"sha": "a3ad50b707942808b15e5c6d369323da783e6c8c", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -33,7 +33,7 @@ pub fn render_with_highlighting(src: &str, class: Option<&str>,\n                                 tooltip: Option<(&str, &str)>) -> String {\n     debug!(\"highlighting: ================\\n{}\\n==============\", src);\n     let sess = parse::ParseSess::new(FilePathMapping::empty());\n-    let fm = sess.codemap().new_filemap(FileName::Custom(\"stdin\".to_string()), src.to_string());\n+    let fm = sess.codemap().new_source_file(FileName::Custom(\"stdin\".to_string()), src.to_string());\n \n     let mut out = Vec::new();\n     if let Some((tooltip, class)) = tooltip {"}, {"sha": "34cd026f7a06f2198882195f5fff9cd8d5a985ac", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 44, "deletions": 44, "changes": 88, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -109,12 +109,12 @@ impl FileLoader for RealFileLoader {\n pub struct StableFilemapId(u128);\n \n impl StableFilemapId {\n-    pub fn new(filemap: &SourceFile) -> StableFilemapId {\n+    pub fn new(source_file: &SourceFile) -> StableFilemapId {\n         let mut hasher = StableHasher::new();\n \n-        filemap.name.hash(&mut hasher);\n-        filemap.name_was_remapped.hash(&mut hasher);\n-        filemap.unmapped_path.hash(&mut hasher);\n+        source_file.name.hash(&mut hasher);\n+        source_file.name_was_remapped.hash(&mut hasher);\n+        source_file.unmapped_path.hash(&mut hasher);\n \n         StableFilemapId(hasher.finish())\n     }\n@@ -126,7 +126,7 @@ impl StableFilemapId {\n \n pub(super) struct SourceMapFiles {\n     pub(super) file_maps: Vec<Lrc<SourceFile>>,\n-    stable_id_to_filemap: FxHashMap<StableFilemapId, Lrc<SourceFile>>\n+    stable_id_to_source_file: FxHashMap<StableFilemapId, Lrc<SourceFile>>\n }\n \n pub struct SourceMap {\n@@ -145,7 +145,7 @@ impl SourceMap {\n         SourceMap {\n             files: Lock::new(SourceMapFiles {\n                 file_maps: Vec::new(),\n-                stable_id_to_filemap: FxHashMap(),\n+                stable_id_to_source_file: FxHashMap(),\n             }),\n             file_loader: Box::new(RealFileLoader),\n             path_mapping,\n@@ -168,7 +168,7 @@ impl SourceMap {\n         SourceMap {\n             files: Lock::new(SourceMapFiles {\n                 file_maps: Vec::new(),\n-                stable_id_to_filemap: FxHashMap(),\n+                stable_id_to_source_file: FxHashMap(),\n             }),\n             file_loader: file_loader,\n             path_mapping,\n@@ -191,15 +191,15 @@ impl SourceMap {\n         } else {\n             path.to_owned().into()\n         };\n-        Ok(self.new_filemap(filename, src))\n+        Ok(self.new_source_file(filename, src))\n     }\n \n     pub fn files(&self) -> LockGuard<Vec<Lrc<SourceFile>>> {\n         LockGuard::map(self.files.borrow(), |files| &mut files.file_maps)\n     }\n \n-    pub fn filemap_by_stable_id(&self, stable_id: StableFilemapId) -> Option<Lrc<SourceFile>> {\n-        self.files.borrow().stable_id_to_filemap.get(&stable_id).map(|fm| fm.clone())\n+    pub fn source_file_by_stable_id(&self, stable_id: StableFilemapId) -> Option<Lrc<SourceFile>> {\n+        self.files.borrow().stable_id_to_source_file.get(&stable_id).map(|fm| fm.clone())\n     }\n \n     fn next_start_pos(&self) -> usize {\n@@ -211,9 +211,9 @@ impl SourceMap {\n         }\n     }\n \n-    /// Creates a new filemap.\n+    /// Creates a new source_file.\n     /// This does not ensure that only one SourceFile exists per file name.\n-    pub fn new_filemap(&self, filename: FileName, src: String) -> Lrc<SourceFile> {\n+    pub fn new_source_file(&self, filename: FileName, src: String) -> Lrc<SourceFile> {\n         let start_pos = self.next_start_pos();\n \n         // The path is used to determine the directory for loading submodules and\n@@ -230,7 +230,7 @@ impl SourceMap {\n             },\n             other => (other, false),\n         };\n-        let filemap = Lrc::new(SourceFile::new(\n+        let source_file = Lrc::new(SourceFile::new(\n             filename,\n             was_remapped,\n             unmapped_path,\n@@ -240,17 +240,17 @@ impl SourceMap {\n \n         let mut files = self.files.borrow_mut();\n \n-        files.file_maps.push(filemap.clone());\n-        files.stable_id_to_filemap.insert(StableFilemapId::new(&filemap), filemap.clone());\n+        files.file_maps.push(source_file.clone());\n+        files.stable_id_to_source_file.insert(StableFilemapId::new(&source_file), source_file.clone());\n \n-        filemap\n+        source_file\n     }\n \n     /// Allocates a new SourceFile representing a source file from an external\n-    /// crate. The source code of such an \"imported filemap\" is not available,\n+    /// crate. The source code of such an \"imported source_file\" is not available,\n     /// but we still know enough to generate accurate debuginfo location\n     /// information for things inlined from other crates.\n-    pub fn new_imported_filemap(&self,\n+    pub fn new_imported_source_file(&self,\n                                 filename: FileName,\n                                 name_was_remapped: bool,\n                                 crate_of_origin: u32,\n@@ -278,7 +278,7 @@ impl SourceMap {\n             *swc = *swc + start_pos;\n         }\n \n-        let filemap = Lrc::new(SourceFile {\n+        let source_file = Lrc::new(SourceFile {\n             name: filename,\n             name_was_remapped,\n             unmapped_path: None,\n@@ -296,10 +296,10 @@ impl SourceMap {\n \n         let mut files = self.files.borrow_mut();\n \n-        files.file_maps.push(filemap.clone());\n-        files.stable_id_to_filemap.insert(StableFilemapId::new(&filemap), filemap.clone());\n+        files.file_maps.push(source_file.clone());\n+        files.stable_id_to_source_file.insert(StableFilemapId::new(&source_file), source_file.clone());\n \n-        filemap\n+        source_file\n     }\n \n     pub fn mk_substr_filename(&self, sp: Span) -> String {\n@@ -385,9 +385,9 @@ impl SourceMap {\n         }\n     }\n \n-    // If the relevant filemap is empty, we don't return a line number.\n+    // If the relevant source_file is empty, we don't return a line number.\n     pub fn lookup_line(&self, pos: BytePos) -> Result<SourceFileAndLine, Lrc<SourceFile>> {\n-        let idx = self.lookup_filemap_idx(pos);\n+        let idx = self.lookup_source_file_idx(pos);\n \n         let f = (*self.files.borrow().file_maps)[idx].clone();\n \n@@ -541,7 +541,7 @@ impl SourceMap {\n                       local_end.fm.start_pos)\n             }));\n         } else {\n-            self.ensure_filemap_source_present(local_begin.fm.clone());\n+            self.ensure_source_file_source_present(local_begin.fm.clone());\n \n             let start_index = local_begin.pos.to_usize();\n             let end_index = local_end.pos.to_usize();\n@@ -798,7 +798,7 @@ impl SourceMap {\n         }\n     }\n \n-    pub fn get_filemap(&self, filename: &FileName) -> Option<Lrc<SourceFile>> {\n+    pub fn get_source_file(&self, filename: &FileName) -> Option<Lrc<SourceFile>> {\n         for fm in self.files.borrow().file_maps.iter() {\n             if *filename == fm.name {\n                 return Some(fm.clone());\n@@ -809,15 +809,15 @@ impl SourceMap {\n \n     /// For a global BytePos compute the local offset within the containing SourceFile\n     pub fn lookup_byte_offset(&self, bpos: BytePos) -> SourceFileAndBytePos {\n-        let idx = self.lookup_filemap_idx(bpos);\n+        let idx = self.lookup_source_file_idx(bpos);\n         let fm = (*self.files.borrow().file_maps)[idx].clone();\n         let offset = bpos - fm.start_pos;\n         SourceFileAndBytePos {fm: fm, pos: offset}\n     }\n \n-    /// Converts an absolute BytePos to a CharPos relative to the filemap.\n+    /// Converts an absolute BytePos to a CharPos relative to the source_file.\n     pub fn bytepos_to_file_charpos(&self, bpos: BytePos) -> CharPos {\n-        let idx = self.lookup_filemap_idx(bpos);\n+        let idx = self.lookup_source_file_idx(bpos);\n         let map = &(*self.files.borrow().file_maps)[idx];\n \n         // The number of extra bytes due to multibyte chars in the SourceFile\n@@ -841,13 +841,13 @@ impl SourceMap {\n         CharPos(bpos.to_usize() - map.start_pos.to_usize() - total_extra_bytes as usize)\n     }\n \n-    // Return the index of the filemap (in self.files) which contains pos.\n-    pub fn lookup_filemap_idx(&self, pos: BytePos) -> usize {\n+    // Return the index of the source_file (in self.files) which contains pos.\n+    pub fn lookup_source_file_idx(&self, pos: BytePos) -> usize {\n         let files = self.files.borrow();\n         let files = &files.file_maps;\n         let count = files.len();\n \n-        // Binary search for the filemap.\n+        // Binary search for the source_file.\n         let mut a = 0;\n         let mut b = count;\n         while b - a > 1 {\n@@ -966,7 +966,7 @@ impl SourceMapper for SourceMap {\n         }\n         sp\n     }\n-    fn ensure_filemap_source_present(&self, file_map: Lrc<SourceFile>) -> bool {\n+    fn ensure_source_file_source_present(&self, file_map: Lrc<SourceFile>) -> bool {\n         file_map.add_external_src(\n             || match file_map.name {\n                 FileName::Real(ref name) => self.file_loader.read_file(name).ok(),\n@@ -1025,11 +1025,11 @@ mod tests {\n \n     fn init_code_map() -> SourceMap {\n         let cm = SourceMap::new(FilePathMapping::empty());\n-        cm.new_filemap(PathBuf::from(\"blork.rs\").into(),\n+        cm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                        \"first line.\\nsecond line\".to_string());\n-        cm.new_filemap(PathBuf::from(\"empty.rs\").into(),\n+        cm.new_source_file(PathBuf::from(\"empty.rs\").into(),\n                        \"\".to_string());\n-        cm.new_filemap(PathBuf::from(\"blork2.rs\").into(),\n+        cm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                        \"first line.\\nsecond line\".to_string());\n         cm\n     }\n@@ -1066,7 +1066,7 @@ mod tests {\n \n     #[test]\n     fn t5() {\n-        // Test zero-length filemaps.\n+        // Test zero-length source_files.\n         let cm = init_code_map();\n \n         let loc1 = cm.lookup_char_pos(BytePos(22));\n@@ -1083,9 +1083,9 @@ mod tests {\n     fn init_code_map_mbc() -> SourceMap {\n         let cm = SourceMap::new(FilePathMapping::empty());\n         // \u20ac is a three byte utf8 char.\n-        cm.new_filemap(PathBuf::from(\"blork.rs\").into(),\n+        cm.new_source_file(PathBuf::from(\"blork.rs\").into(),\n                        \"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_string());\n-        cm.new_filemap(PathBuf::from(\"blork2.rs\").into(),\n+        cm.new_source_file(PathBuf::from(\"blork2.rs\").into(),\n                        \"first line\u20ac\u20ac.\\n\u20ac second line\".to_string());\n         cm\n     }\n@@ -1110,7 +1110,7 @@ mod tests {\n \n     #[test]\n     fn t7() {\n-        // Test span_to_lines for a span ending at the end of filemap\n+        // Test span_to_lines for a span ending at the end of source_file\n         let cm = init_code_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n         let file_lines = cm.span_to_lines(span).unwrap();\n@@ -1138,7 +1138,7 @@ mod tests {\n         let cm = SourceMap::new(FilePathMapping::empty());\n         let inputtext = \"aaaaa\\nbbbbBB\\nCCC\\nDDDDDddddd\\neee\\n\";\n         let selection = \"     \\n    ~~\\n~~~\\n~~~~~     \\n   \\n\";\n-        cm.new_filemap(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n+        cm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_string());\n         let span = span_from_selection(inputtext, selection);\n \n         // check that we are extracting the text we thought we were extracting\n@@ -1156,7 +1156,7 @@ mod tests {\n \n     #[test]\n     fn t8() {\n-        // Test span_to_snippet for a span ending at the end of filemap\n+        // Test span_to_snippet for a span ending at the end of source_file\n         let cm = init_code_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n         let snippet = cm.span_to_snippet(span);\n@@ -1166,7 +1166,7 @@ mod tests {\n \n     #[test]\n     fn t9() {\n-        // Test span_to_str for a span ending at the end of filemap\n+        // Test span_to_str for a span ending at the end of source_file\n         let cm = init_code_map();\n         let span = Span::new(BytePos(12), BytePos(23), NO_EXPANSION);\n         let sstr =  cm.span_to_string(span);\n@@ -1181,7 +1181,7 @@ mod tests {\n         let inputtext  = \"bbbb BB\\ncc CCC\\n\";\n         let selection1 = \"     ~~\\n      \\n\";\n         let selection2 = \"       \\n   ~~~\\n\";\n-        cm.new_filemap(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_owned());\n+        cm.new_source_file(Path::new(\"blork.rs\").to_owned().into(), inputtext.to_owned());\n         let span1 = span_from_selection(inputtext, selection1);\n         let span2 = span_from_selection(inputtext, selection2);\n "}, {"sha": "6b41dfafd07e128037fd39cef0f6d6117efb1c99", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -1563,7 +1563,7 @@ impl<'a, 'b> Folder for InvocationCollector<'a, 'b> {\n \n                             // Add this input file to the code map to make it available as\n                             // dependency information\n-                            self.cx.codemap().new_filemap(filename.into(), src);\n+                            self.cx.codemap().new_source_file(filename.into(), src);\n \n                             let include_info = vec![\n                                 dummy_spanned(ast::NestedMetaItemKind::MetaItem("}, {"sha": "fdf9c33b6f4b1421970bdffa2ba2361844fe2059", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -63,7 +63,7 @@ pub fn expand_column_gated(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::Token\n }\n \n /// file!(): expands to the current filename */\n-/// The filemap (`loc.file`) contains a bunch more information we could spit\n+/// The source_file (`loc.file`) contains a bunch more information we could spit\n /// out if we wanted.\n pub fn expand_file(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenTree])\n                    -> Box<dyn base::MacResult+'static> {\n@@ -154,7 +154,7 @@ pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::TokenT\n \n             // Add this input file to the code map to make it available as\n             // dependency information\n-            cx.codemap().new_filemap(file.into(), src);\n+            cx.codemap().new_source_file(file.into(), src);\n \n             base::MacEager::expr(cx.expr_str(sp, interned_src))\n         }\n@@ -184,7 +184,7 @@ pub fn expand_include_bytes(cx: &mut ExtCtxt, sp: Span, tts: &[tokenstream::Toke\n         Ok(..) => {\n             // Add this input file to the code map to make it available as\n             // dependency information, but don't enter it's contents\n-            cx.codemap().new_filemap(file.into(), \"\".to_string());\n+            cx.codemap().new_source_file(file.into(), \"\".to_string());\n \n             base::MacEager::expr(cx.expr_lit(sp, ast::LitKind::ByteStr(Lrc::new(bytes))))\n         }"}, {"sha": "1ac51a68b62b4fbc0958e37f7e9244fec3ced3b8", "filename": "src/libsyntax/json.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fjson.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fjson.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fjson.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -340,7 +340,7 @@ impl DiagnosticSpan {\n }\n \n impl DiagnosticSpanLine {\n-    fn line_from_filemap(fm: &syntax_pos::SourceFile,\n+    fn line_from_source_file(fm: &syntax_pos::SourceFile,\n                          index: usize,\n                          h_start: usize,\n                          h_end: usize)\n@@ -362,7 +362,7 @@ impl DiagnosticSpanLine {\n                  lines.lines\n                       .iter()\n                       .map(|line| {\n-                          DiagnosticSpanLine::line_from_filemap(fm,\n+                          DiagnosticSpanLine::line_from_source_file(fm,\n                                                                 line.line_index,\n                                                                 line.start_col.0 + 1,\n                                                                 line.end_col.0 + 1)"}, {"sha": "f4d4635b61e63daf86837e3899766a4b0fb1a19a", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -247,11 +247,11 @@ fn read_block_comment(rdr: &mut StringReader,\n     let mut lines: Vec<String> = Vec::new();\n \n     // Count the number of chars since the start of the line by rescanning.\n-    let mut src_index = rdr.src_index(rdr.filemap.line_begin_pos(rdr.pos));\n+    let mut src_index = rdr.src_index(rdr.source_file.line_begin_pos(rdr.pos));\n     let end_src_index = rdr.src_index(rdr.pos);\n     assert!(src_index <= end_src_index,\n         \"src_index={}, end_src_index={}, line_begin_pos={}\",\n-        src_index, end_src_index, rdr.filemap.line_begin_pos(rdr.pos).to_u32());\n+        src_index, end_src_index, rdr.source_file.line_begin_pos(rdr.pos).to_u32());\n     let mut n = 0;\n \n     while src_index < end_src_index {\n@@ -372,8 +372,8 @@ pub fn gather_comments_and_literals(sess: &ParseSess, path: FileName, srdr: &mut\n     let mut src = String::new();\n     srdr.read_to_string(&mut src).unwrap();\n     let cm = SourceMap::new(sess.codemap().path_mapping().clone());\n-    let filemap = cm.new_filemap(path, src);\n-    let mut rdr = lexer::StringReader::new_raw(sess, filemap, None);\n+    let source_file = cm.new_source_file(path, src);\n+    let mut rdr = lexer::StringReader::new_raw(sess, source_file, None);\n \n     let mut comments: Vec<Comment> = Vec::new();\n     let mut literals: Vec<Literal> = Vec::new();"}, {"sha": "acec975d32a44f6bf83adf5f70f1a7df0e0f44d9", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -49,7 +49,7 @@ pub struct StringReader<'a> {\n     pub pos: BytePos,\n     /// The current character (which has been read from self.pos)\n     pub ch: Option<char>,\n-    pub filemap: Lrc<syntax_pos::SourceFile>,\n+    pub source_file: Lrc<syntax_pos::SourceFile>,\n     /// Stop reading src at this index.\n     pub end_src_index: usize,\n     // cached:\n@@ -58,7 +58,7 @@ pub struct StringReader<'a> {\n     peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     // cache a direct reference to the source text, so that we don't have to\n-    // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n+    // retrieve it via `self.source_file.src.as_ref().unwrap()` all the time.\n     src: Lrc<String>,\n     /// Stack of open delimiters and their spans. Used for error message.\n     token: token::Token,\n@@ -180,31 +180,31 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// For comments.rs, which hackily pokes into next_pos and ch\n-    fn new_raw(sess: &'a ParseSess, filemap: Lrc<syntax_pos::SourceFile>, override_span: Option<Span>)\n+    fn new_raw(sess: &'a ParseSess, source_file: Lrc<syntax_pos::SourceFile>, override_span: Option<Span>)\n         -> Self\n     {\n-        let mut sr = StringReader::new_raw_internal(sess, filemap, override_span);\n+        let mut sr = StringReader::new_raw_internal(sess, source_file, override_span);\n         sr.bump();\n \n         sr\n     }\n \n-    fn new_raw_internal(sess: &'a ParseSess, filemap: Lrc<syntax_pos::SourceFile>,\n+    fn new_raw_internal(sess: &'a ParseSess, source_file: Lrc<syntax_pos::SourceFile>,\n         override_span: Option<Span>) -> Self\n     {\n-        if filemap.src.is_none() {\n-            sess.span_diagnostic.bug(&format!(\"Cannot lex filemap without source: {}\",\n-                                              filemap.name));\n+        if source_file.src.is_none() {\n+            sess.span_diagnostic.bug(&format!(\"Cannot lex source_file without source: {}\",\n+                                              source_file.name));\n         }\n \n-        let src = (*filemap.src.as_ref().unwrap()).clone();\n+        let src = (*source_file.src.as_ref().unwrap()).clone();\n \n         StringReader {\n             sess,\n-            next_pos: filemap.start_pos,\n-            pos: filemap.start_pos,\n+            next_pos: source_file.start_pos,\n+            pos: source_file.start_pos,\n             ch: Some('\\n'),\n-            filemap,\n+            source_file,\n             end_src_index: src.len(),\n             // dummy values; not read\n             peek_tok: token::Eof,\n@@ -221,10 +221,10 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    pub fn new(sess: &'a ParseSess, filemap: Lrc<syntax_pos::SourceFile>, override_span: Option<Span>)\n+    pub fn new(sess: &'a ParseSess, source_file: Lrc<syntax_pos::SourceFile>, override_span: Option<Span>)\n         -> Self\n     {\n-        let mut sr = StringReader::new_raw(sess, filemap, override_span);\n+        let mut sr = StringReader::new_raw(sess, source_file, override_span);\n         if sr.advance_token().is_err() {\n             sr.emit_fatal_errors();\n             FatalError.raise();\n@@ -364,8 +364,8 @@ impl<'a> StringReader<'a> {\n                 if self.is_eof() {\n                     self.peek_tok = token::Eof;\n                     let (real, raw) = self.mk_sp_and_raw(\n-                        self.filemap.end_pos,\n-                        self.filemap.end_pos,\n+                        self.source_file.end_pos,\n+                        self.source_file.end_pos,\n                     );\n                     self.peek_span = real;\n                     self.peek_span_src_raw = raw;\n@@ -384,7 +384,7 @@ impl<'a> StringReader<'a> {\n \n     #[inline]\n     fn src_index(&self, pos: BytePos) -> usize {\n-        (pos - self.filemap.start_pos).to_usize()\n+        (pos - self.source_file.start_pos).to_usize()\n     }\n \n     /// Calls `f` with a string slice of the source text spanning from `start`\n@@ -623,7 +623,7 @@ impl<'a> StringReader<'a> {\n                 // I guess this is the only way to figure out if\n                 // we're at the beginning of the file...\n                 let cmap = SourceMap::new(FilePathMapping::empty());\n-                cmap.files.borrow_mut().file_maps.push(self.filemap.clone());\n+                cmap.files.borrow_mut().file_maps.push(self.source_file.clone());\n                 let loc = cmap.lookup_char_pos_adj(self.pos);\n                 debug!(\"Skipping a shebang\");\n                 if loc.line == 1 && loc.col == CharPos(0) {\n@@ -1861,7 +1861,7 @@ mod tests {\n                  sess: &'a ParseSess,\n                  teststr: String)\n                  -> StringReader<'a> {\n-        let fm = cm.new_filemap(PathBuf::from(\"zebra.rs\").into(), teststr);\n+        let fm = cm.new_source_file(PathBuf::from(\"zebra.rs\").into(), teststr);\n         StringReader::new(sess, fm, None)\n     }\n "}, {"sha": "07a9f44fe4aa4a358e47ffcf842f313dd72cb355", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -171,21 +171,21 @@ crate fn parse_stmt_from_source_str(name: FileName, source: String, sess: &Parse\n pub fn parse_stream_from_source_str(name: FileName, source: String, sess: &ParseSess,\n                                     override_span: Option<Span>)\n                                     -> TokenStream {\n-    filemap_to_stream(sess, sess.codemap().new_filemap(name, source), override_span)\n+    source_file_to_stream(sess, sess.codemap().new_source_file(name, source), override_span)\n }\n \n // Create a new parser from a source string\n pub fn new_parser_from_source_str(sess: &ParseSess, name: FileName, source: String)\n                                       -> Parser {\n-    let mut parser = filemap_to_parser(sess, sess.codemap().new_filemap(name, source));\n+    let mut parser = source_file_to_parser(sess, sess.codemap().new_source_file(name, source));\n     parser.recurse_into_file_modules = false;\n     parser\n }\n \n /// Create a new parser, handling errors as appropriate\n /// if the file doesn't exist\n pub fn new_parser_from_file<'a>(sess: &'a ParseSess, path: &Path) -> Parser<'a> {\n-    filemap_to_parser(sess, file_to_filemap(sess, path, None))\n+    source_file_to_parser(sess, file_to_source_file(sess, path, None))\n }\n \n /// Given a session, a crate config, a path, and a span, add\n@@ -196,16 +196,16 @@ crate fn new_sub_parser_from_file<'a>(sess: &'a ParseSess,\n                                     directory_ownership: DirectoryOwnership,\n                                     module_name: Option<String>,\n                                     sp: Span) -> Parser<'a> {\n-    let mut p = filemap_to_parser(sess, file_to_filemap(sess, path, Some(sp)));\n+    let mut p = source_file_to_parser(sess, file_to_source_file(sess, path, Some(sp)));\n     p.directory.ownership = directory_ownership;\n     p.root_module_name = module_name;\n     p\n }\n \n-/// Given a filemap and config, return a parser\n-fn filemap_to_parser(sess: & ParseSess, filemap: Lrc<SourceFile>) -> Parser {\n-    let end_pos = filemap.end_pos;\n-    let mut parser = stream_to_parser(sess, filemap_to_stream(sess, filemap, None));\n+/// Given a source_file and config, return a parser\n+fn source_file_to_parser(sess: & ParseSess, source_file: Lrc<SourceFile>) -> Parser {\n+    let end_pos = source_file.end_pos;\n+    let mut parser = stream_to_parser(sess, source_file_to_stream(sess, source_file, None));\n \n     if parser.token == token::Eof && parser.span.is_dummy() {\n         parser.span = Span::new(end_pos, end_pos, parser.span.ctxt());\n@@ -224,11 +224,11 @@ pub fn new_parser_from_tts(sess: &ParseSess, tts: Vec<TokenTree>) -> Parser {\n // base abstractions\n \n /// Given a session and a path and an optional span (for error reporting),\n-/// add the path to the session's codemap and return the new filemap.\n-fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n+/// add the path to the session's codemap and return the new source_file.\n+fn file_to_source_file(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n                    -> Lrc<SourceFile> {\n     match sess.codemap().load_file(path) {\n-        Ok(filemap) => filemap,\n+        Ok(source_file) => source_file,\n         Err(e) => {\n             let msg = format!(\"couldn't read {:?}: {}\", path.display(), e);\n             match spanopt {\n@@ -239,10 +239,10 @@ fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n     }\n }\n \n-/// Given a filemap, produce a sequence of token-trees\n-pub fn filemap_to_stream(sess: &ParseSess, filemap: Lrc<SourceFile>, override_span: Option<Span>)\n+/// Given a source_file, produce a sequence of token-trees\n+pub fn source_file_to_stream(sess: &ParseSess, source_file: Lrc<SourceFile>, override_span: Option<Span>)\n                          -> TokenStream {\n-    let mut srdr = lexer::StringReader::new(sess, filemap, override_span);\n+    let mut srdr = lexer::StringReader::new(sess, source_file, override_span);\n     srdr.real_token();\n     panictry!(srdr.parse_all_token_trees())\n }"}, {"sha": "00dd79ffb00df2f3b9a914c8bf0e7815ec7572cc", "filename": "src/libsyntax/test_snippet.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Ftest_snippet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Ftest_snippet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest_snippet.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -51,7 +51,7 @@ fn test_harness(file_text: &str, span_labels: Vec<SpanLabel>, expected_output: &\n         let output = Arc::new(Mutex::new(Vec::new()));\n \n         let code_map = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n-        code_map.new_filemap(Path::new(\"test.rs\").to_owned().into(), file_text.to_owned());\n+        code_map.new_source_file(Path::new(\"test.rs\").to_owned().into(), file_text.to_owned());\n \n         let primary_span = make_span(&file_text, &span_labels[0].start, &span_labels[0].end);\n         let mut msp = MultiSpan::from_span(primary_span);"}, {"sha": "35dae1a4e6742c7cb75bf1a554b712faae08df7b", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -10,7 +10,7 @@\n \n use ast::{self, Ident};\n use codemap::FilePathMapping;\n-use parse::{ParseSess, PResult, filemap_to_stream};\n+use parse::{ParseSess, PResult, source_file_to_stream};\n use parse::{lexer, new_parser_from_source_str};\n use parse::parser::Parser;\n use ptr::P;\n@@ -21,8 +21,8 @@ use std::path::PathBuf;\n /// Map a string to tts, using a made-up filename:\n pub fn string_to_stream(source_str: String) -> TokenStream {\n     let ps = ParseSess::new(FilePathMapping::empty());\n-    filemap_to_stream(&ps, ps.codemap()\n-                             .new_filemap(PathBuf::from(\"bogofile\").into(), source_str), None)\n+    source_file_to_stream(&ps, ps.codemap()\n+                             .new_source_file(PathBuf::from(\"bogofile\").into(), source_str), None)\n }\n \n /// Map string to parser (via tts)"}, {"sha": "e468aaac7a30686d46d640d0581e07d03a10083a", "filename": "src/libsyntax_pos/analyze_source_file.rs", "status": "renamed", "additions": 35, "deletions": 35, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax_pos%2Fanalyze_source_file.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax_pos%2Fanalyze_source_file.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fanalyze_source_file.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -16,27 +16,27 @@ use super::*;\n ///\n /// This function will use an SSE2 enhanced implementation if hardware support\n /// is detected at runtime.\n-pub fn analyze_filemap(\n+pub fn analyze_source_file(\n     src: &str,\n-    filemap_start_pos: BytePos)\n+    source_file_start_pos: BytePos)\n     -> (Vec<BytePos>, Vec<MultiByteChar>, Vec<NonNarrowChar>)\n {\n-    let mut lines = vec![filemap_start_pos];\n+    let mut lines = vec![source_file_start_pos];\n     let mut multi_byte_chars = vec![];\n     let mut non_narrow_chars = vec![];\n \n     // Calls the right implementation, depending on hardware support available.\n-    analyze_filemap_dispatch(src,\n-                             filemap_start_pos,\n+    analyze_source_file_dispatch(src,\n+                             source_file_start_pos,\n                              &mut lines,\n                              &mut multi_byte_chars,\n                              &mut non_narrow_chars);\n \n     // The code above optimistically registers a new line *after* each \\n\n-    // it encounters. If that point is already outside the filemap, remove\n+    // it encounters. If that point is already outside the source_file, remove\n     // it again.\n     if let Some(&last_line_start) = lines.last() {\n-        let file_map_end = filemap_start_pos + BytePos::from_usize(src.len());\n+        let file_map_end = source_file_start_pos + BytePos::from_usize(src.len());\n         assert!(file_map_end >= last_line_start);\n         if last_line_start == file_map_end {\n             lines.pop();\n@@ -49,23 +49,23 @@ pub fn analyze_filemap(\n cfg_if! {\n     if #[cfg(all(any(target_arch = \"x86\", target_arch = \"x86_64\"),\n                  not(stage0)))] {\n-        fn analyze_filemap_dispatch(src: &str,\n-                                    filemap_start_pos: BytePos,\n+        fn analyze_source_file_dispatch(src: &str,\n+                                    source_file_start_pos: BytePos,\n                                     lines: &mut Vec<BytePos>,\n                                     multi_byte_chars: &mut Vec<MultiByteChar>,\n                                     non_narrow_chars: &mut Vec<NonNarrowChar>) {\n             if is_x86_feature_detected!(\"sse2\") {\n                 unsafe {\n-                    analyze_filemap_sse2(src,\n-                                         filemap_start_pos,\n+                    analyze_source_file_sse2(src,\n+                                         source_file_start_pos,\n                                          lines,\n                                          multi_byte_chars,\n                                          non_narrow_chars);\n                 }\n             } else {\n-                analyze_filemap_generic(src,\n+                analyze_source_file_generic(src,\n                                         src.len(),\n-                                        filemap_start_pos,\n+                                        source_file_start_pos,\n                                         lines,\n                                         multi_byte_chars,\n                                         non_narrow_chars);\n@@ -78,7 +78,7 @@ cfg_if! {\n         /// function falls back to the generic implementation. Otherwise it uses\n         /// SSE2 intrinsics to quickly find all newlines.\n         #[target_feature(enable = \"sse2\")]\n-        unsafe fn analyze_filemap_sse2(src: &str,\n+        unsafe fn analyze_source_file_sse2(src: &str,\n                                        output_offset: BytePos,\n                                        lines: &mut Vec<BytePos>,\n                                        multi_byte_chars: &mut Vec<MultiByteChar>,\n@@ -169,7 +169,7 @@ cfg_if! {\n                 // The slow path.\n                 // There are control chars in here, fallback to generic decoding.\n                 let scan_start = chunk_index * CHUNK_SIZE + intra_chunk_offset;\n-                intra_chunk_offset = analyze_filemap_generic(\n+                intra_chunk_offset = analyze_source_file_generic(\n                     &src[scan_start .. ],\n                     CHUNK_SIZE - intra_chunk_offset,\n                     BytePos::from_usize(scan_start) + output_offset,\n@@ -182,7 +182,7 @@ cfg_if! {\n             // There might still be a tail left to analyze\n             let tail_start = chunk_count * CHUNK_SIZE + intra_chunk_offset;\n             if tail_start < src.len() {\n-                analyze_filemap_generic(&src[tail_start as usize ..],\n+                analyze_source_file_generic(&src[tail_start as usize ..],\n                                         src.len() - tail_start,\n                                         output_offset + BytePos::from_usize(tail_start),\n                                         lines,\n@@ -193,14 +193,14 @@ cfg_if! {\n     } else {\n \n         // The target (or compiler version) does not support SSE2 ...\n-        fn analyze_filemap_dispatch(src: &str,\n-                                    filemap_start_pos: BytePos,\n+        fn analyze_source_file_dispatch(src: &str,\n+                                    source_file_start_pos: BytePos,\n                                     lines: &mut Vec<BytePos>,\n                                     multi_byte_chars: &mut Vec<MultiByteChar>,\n                                     non_narrow_chars: &mut Vec<NonNarrowChar>) {\n-            analyze_filemap_generic(src,\n+            analyze_source_file_generic(src,\n                                     src.len(),\n-                                    filemap_start_pos,\n+                                    source_file_start_pos,\n                                     lines,\n                                     multi_byte_chars,\n                                     non_narrow_chars);\n@@ -211,7 +211,7 @@ cfg_if! {\n // `scan_len` determines the number of bytes in `src` to scan. Note that the\n // function can read past `scan_len` if a multi-byte character start within the\n // range but extends past it. The overflow is returned by the function.\n-fn analyze_filemap_generic(src: &str,\n+fn analyze_source_file_generic(src: &str,\n                            scan_len: usize,\n                            output_offset: BytePos,\n                            lines: &mut Vec<BytePos>,\n@@ -288,7 +288,7 @@ fn analyze_filemap_generic(src: &str,\n macro_rules! test {\n     (case: $test_name:ident,\n      text: $text:expr,\n-     filemap_start_pos: $filemap_start_pos:expr,\n+     source_file_start_pos: $source_file_start_pos:expr,\n      lines: $lines:expr,\n      multi_byte_chars: $multi_byte_chars:expr,\n      non_narrow_chars: $non_narrow_chars:expr,) => (\n@@ -297,7 +297,7 @@ macro_rules! test {\n     fn $test_name() {\n \n         let (lines, multi_byte_chars, non_narrow_chars) =\n-            analyze_filemap($text, BytePos($filemap_start_pos));\n+            analyze_source_file($text, BytePos($source_file_start_pos));\n \n         let expected_lines: Vec<BytePos> = $lines\n             .into_iter()\n@@ -330,7 +330,7 @@ macro_rules! test {\n test!(\n     case: empty_text,\n     text: \"\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![],\n@@ -339,7 +339,7 @@ test!(\n test!(\n     case: newlines_short,\n     text: \"a\\nc\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0, 2],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![],\n@@ -348,7 +348,7 @@ test!(\n test!(\n     case: newlines_long,\n     text: \"012345678\\nabcdef012345678\\na\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0, 10, 26],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![],\n@@ -357,7 +357,7 @@ test!(\n test!(\n     case: newline_and_multi_byte_char_in_same_chunk,\n     text: \"01234\u03b2789\\nbcdef0123456789abcdef\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0, 11],\n     multi_byte_chars: vec![(5, 2)],\n     non_narrow_chars: vec![],\n@@ -366,7 +366,7 @@ test!(\n test!(\n     case: newline_and_control_char_in_same_chunk,\n     text: \"01234\\u{07}6789\\nbcdef0123456789abcdef\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0, 11],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![(5, 0)],\n@@ -375,7 +375,7 @@ test!(\n test!(\n     case: multi_byte_char_short,\n     text: \"a\u03b2c\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![(1, 2)],\n     non_narrow_chars: vec![],\n@@ -384,7 +384,7 @@ test!(\n test!(\n     case: multi_byte_char_long,\n     text: \"0123456789abc\u0394f012345\u03b2\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![(13, 2), (22, 2)],\n     non_narrow_chars: vec![],\n@@ -393,7 +393,7 @@ test!(\n test!(\n     case: multi_byte_char_across_chunk_boundary,\n     text: \"0123456789abcde\u0394123456789abcdef01234\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![(15, 2)],\n     non_narrow_chars: vec![],\n@@ -402,7 +402,7 @@ test!(\n test!(\n     case: multi_byte_char_across_chunk_boundary_tail,\n     text: \"0123456789abcde\u0394....\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![(15, 2)],\n     non_narrow_chars: vec![],\n@@ -411,7 +411,7 @@ test!(\n test!(\n     case: non_narrow_short,\n     text: \"0\\t2\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![(1, 4)],\n@@ -420,7 +420,7 @@ test!(\n test!(\n     case: non_narrow_long,\n     text: \"01\\t3456789abcdef01234567\\u{07}9\",\n-    filemap_start_pos: 0,\n+    source_file_start_pos: 0,\n     lines: vec![0],\n     multi_byte_chars: vec![],\n     non_narrow_chars: vec![(2, 4), (24, 0)],\n@@ -429,7 +429,7 @@ test!(\n test!(\n     case: output_offset_all,\n     text: \"01\\t345\\n789abc\u0394f01234567\\u{07}9\\nbc\u0394f\",\n-    filemap_start_pos: 1000,\n+    source_file_start_pos: 1000,\n     lines: vec![0 + 1000, 7 + 1000, 27 + 1000],\n     multi_byte_chars: vec![(13 + 1000, 2), (29 + 1000, 2)],\n     non_narrow_chars: vec![(2 + 1000, 4), (24 + 1000, 0)],", "previous_filename": "src/libsyntax_pos/analyze_filemap.rs"}, {"sha": "f9c91dc8a97c866dd47fdcf5bdf102fb4bbe3d1b", "filename": "src/libsyntax_pos/lib.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax_pos%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cbd05957103926fa10d41474fde773167fe64dfb/src%2Flibsyntax_pos%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Flib.rs?ref=cbd05957103926fa10d41474fde773167fe64dfb", "patch": "@@ -63,7 +63,7 @@ pub use span_encoding::{Span, DUMMY_SP};\n \n pub mod symbol;\n \n-mod analyze_filemap;\n+mod analyze_source_file;\n \n pub struct Globals {\n     symbol_interner: Lock<symbol::Interner>,\n@@ -974,7 +974,7 @@ impl SourceFile {\n         let end_pos = start_pos.to_usize() + src.len();\n \n         let (lines, multibyte_chars, non_narrow_chars) =\n-            analyze_filemap::analyze_filemap(&src[..], start_pos);\n+            analyze_source_file::analyze_source_file(&src[..], start_pos);\n \n         SourceFile {\n             name,\n@@ -1082,7 +1082,7 @@ impl SourceFile {\n \n     /// Find the line containing the given position. The return value is the\n     /// index into the `lines` array of this SourceFile, not the 1-based line\n-    /// number. If the filemap is empty or the position is located before the\n+    /// number. If the source_file is empty or the position is located before the\n     /// first line, None is returned.\n     pub fn lookup_line(&self, pos: BytePos) -> Option<usize> {\n         if self.lines.len() == 0 {"}]}