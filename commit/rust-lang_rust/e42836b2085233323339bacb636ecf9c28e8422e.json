{"sha": "e42836b2085233323339bacb636ecf9c28e8422e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU0MjgzNmIyMDg1MjMzMzIzMzM5YmFjYjYzNmVjZjljMjhlODQyMmU=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-03-17T23:41:09Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-06-26T02:06:26Z"}, "message": "Implement `quote!` and other `proc_macro` API.", "tree": {"sha": "c43855deb6274dce6bbafb7efb75bd9ac8b95f97", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c43855deb6274dce6bbafb7efb75bd9ac8b95f97"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e42836b2085233323339bacb636ecf9c28e8422e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e42836b2085233323339bacb636ecf9c28e8422e", "html_url": "https://github.com/rust-lang/rust/commit/e42836b2085233323339bacb636ecf9c28e8422e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e42836b2085233323339bacb636ecf9c28e8422e/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7d41674b175cdb3452e042ef6f37141bc3788f8b", "url": "https://api.github.com/repos/rust-lang/rust/commits/7d41674b175cdb3452e042ef6f37141bc3788f8b", "html_url": "https://github.com/rust-lang/rust/commit/7d41674b175cdb3452e042ef6f37141bc3788f8b"}], "stats": {"total": 1662, "additions": 1085, "deletions": 577}, "files": [{"sha": "e8f0ed6ed2c189b97c52038a7e20c3455b70e116", "filename": "src/Cargo.lock", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -882,14 +882,6 @@ name = \"proc_macro\"\n version = \"0.0.0\"\n dependencies = [\n  \"syntax 0.0.0\",\n-]\n-\n-[[package]]\n-name = \"proc_macro_plugin\"\n-version = \"0.0.0\"\n-dependencies = [\n- \"rustc_plugin 0.0.0\",\n- \"syntax 0.0.0\",\n  \"syntax_pos 0.0.0\",\n ]\n \n@@ -1210,7 +1202,6 @@ dependencies = [\n  \"env_logger 0.4.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"graphviz 0.0.0\",\n  \"log 0.3.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"proc_macro_plugin 0.0.0\",\n  \"rustc 0.0.0\",\n  \"rustc_back 0.0.0\",\n  \"rustc_borrowck 0.0.0\","}, {"sha": "19e7f663c7ac33228c76f4c17a92c8a1b0f47222", "filename": "src/doc/unstable-book/src/library-features/proc-macro.md", "status": "added", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Fdoc%2Funstable-book%2Fsrc%2Flibrary-features%2Fproc-macro.md", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Fdoc%2Funstable-book%2Fsrc%2Flibrary-features%2Fproc-macro.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Funstable-book%2Fsrc%2Flibrary-features%2Fproc-macro.md?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -0,0 +1,7 @@\n+# `proc_macro`\n+\n+The tracking issue for this feature is: [#38356]\n+\n+[#38356]: https://github.com/rust-lang/rust/issues/38356\n+\n+------------------------"}, {"sha": "1b5141773a96719549892f3b2edba0fedbe7f298", "filename": "src/libproc_macro/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2FCargo.toml?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -9,3 +9,4 @@ crate-type = [\"dylib\"]\n \n [dependencies]\n syntax = { path = \"../libsyntax\" }\n+syntax_pos = { path = \"../libsyntax_pos\" }"}, {"sha": "f1abd3339ed53b96d3903706627b3e0b19dc8ff5", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 450, "deletions": 24, "changes": 474, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -37,18 +37,24 @@\n        test(no_crate_inject, attr(deny(warnings))),\n        test(attr(allow(dead_code, deprecated, unused_variables, unused_mut))))]\n \n+#![feature(i128_type)]\n #![feature(rustc_private)]\n #![feature(staged_api)]\n #![feature(lang_items)]\n \n extern crate syntax;\n+extern crate syntax_pos;\n \n-use std::fmt;\n+use std::{fmt, iter, ops};\n use std::str::FromStr;\n \n+use syntax::ast;\n use syntax::errors::DiagnosticBuilder;\n-use syntax::parse;\n+use syntax::parse::{self, token};\n+use syntax::symbol;\n use syntax::tokenstream;\n+use syntax_pos::DUMMY_SP;\n+use syntax_pos::SyntaxContext;\n \n /// The main type provided by this crate, representing an abstract stream of\n /// tokens.\n@@ -60,6 +66,7 @@ use syntax::tokenstream;\n /// The API of this type is intentionally bare-bones, but it'll be expanded over\n /// time!\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n+#[derive(Clone)]\n pub struct TokenStream(tokenstream::TokenStream);\n \n /// Error returned from `TokenStream::from_str`.\n@@ -69,6 +76,443 @@ pub struct LexError {\n     _inner: (),\n }\n \n+#[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n+impl FromStr for TokenStream {\n+    type Err = LexError;\n+\n+    fn from_str(src: &str) -> Result<TokenStream, LexError> {\n+        __internal::with_sess(|(sess, mark)| {\n+            let src = src.to_string();\n+            let name = \"<proc-macro source code>\".to_string();\n+            let call_site = mark.expn_info().unwrap().call_site;\n+            let stream = parse::parse_stream_from_source_str(name, src, sess, Some(call_site));\n+            Ok(__internal::token_stream_wrap(stream))\n+        })\n+    }\n+}\n+\n+#[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n+impl fmt::Display for TokenStream {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        self.0.fmt(f)\n+    }\n+}\n+\n+/// `quote!(..)` accepts arbitrary tokens and expands into a `TokenStream` describing the input.\n+/// For example, `quote!(a + b)` will produce a expression, that, when evaluated, constructs\n+/// constructs the `TokenStream` `[Word(\"a\"), Op('+', Alone), Word(\"b\")]`.\n+///\n+/// Unquoting is done with `$`, and works by taking the single next ident as the unquoted term.\n+/// To quote `$` itself, use `$$`.\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+#[macro_export]\n+macro_rules! quote { () => {} }\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<TokenTree> for TokenStream {\n+    fn from(tree: TokenTree) -> TokenStream {\n+        TokenStream(tree.to_raw())\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<TokenKind> for TokenStream {\n+    fn from(kind: TokenKind) -> TokenStream {\n+        TokenTree::from(kind).into()\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl<T: Into<TokenStream>> iter::FromIterator<T> for TokenStream {\n+    fn from_iter<I: IntoIterator<Item = T>>(streams: I) -> Self {\n+        let mut builder = tokenstream::TokenStream::builder();\n+        for stream in streams {\n+            builder.push(stream.into().0);\n+        }\n+        TokenStream(builder.build())\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl IntoIterator for TokenStream {\n+    type Item = TokenTree;\n+    type IntoIter = TokenIter;\n+\n+    fn into_iter(self) -> TokenIter {\n+        TokenIter { cursor: self.0.trees(), next: None }\n+    }\n+}\n+\n+impl TokenStream {\n+    /// Returns an empty `TokenStream`.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn empty() -> TokenStream {\n+        TokenStream(tokenstream::TokenStream::empty())\n+    }\n+\n+    /// Checks if this `TokenStream` is empty.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+}\n+\n+/// A region of source code, along with macro expansion information.\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+#[derive(Copy, Clone)]\n+pub struct Span(syntax_pos::Span);\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl Default for Span {\n+    fn default() -> Span {\n+        ::__internal::with_sess(|(_, mark)| Span(syntax_pos::Span {\n+            ctxt: SyntaxContext::empty().apply_mark(mark),\n+            ..mark.expn_info().unwrap().call_site\n+        }))\n+    }\n+}\n+\n+impl Span {\n+    /// The span of the invocation of the current procedural macro.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn call_site() -> Span {\n+        ::__internal::with_sess(|(_, mark)| Span(mark.expn_info().unwrap().call_site))\n+    }\n+}\n+\n+/// A single token or a delimited sequence of token trees (e.g. `[1, (), ..]`).\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+#[derive(Clone)]\n+pub struct TokenTree {\n+    /// The `TokenTree`'s span\n+    pub span: Span,\n+    /// Description of the `TokenTree`\n+    pub kind: TokenKind,\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl From<TokenKind> for TokenTree {\n+    fn from(kind: TokenKind) -> TokenTree {\n+        TokenTree { span: Span::default(), kind: kind }\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl fmt::Display for TokenTree {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        TokenStream::from(self.clone()).fmt(f)\n+    }\n+}\n+\n+/// Description of a `TokenTree`\n+#[derive(Clone)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub enum TokenKind {\n+    /// A delimited tokenstream.\n+    Sequence(Delimiter, TokenStream),\n+    /// A unicode identifier.\n+    Word(Symbol),\n+    /// A punctuation character (`+`, `,`, `$`, etc.).\n+    Op(char, OpKind),\n+    /// A literal character (`'a'`), string (`\"hello\"`), or number (`2.3`).\n+    Literal(Literal),\n+}\n+\n+/// Describes how a sequence of token trees is delimited.\n+#[derive(Copy, Clone)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub enum Delimiter {\n+    /// `( ... )`\n+    Parenthesis,\n+    /// `[ ... ]`\n+    Brace,\n+    /// `{ ... }`\n+    Bracket,\n+    /// An implicit delimiter, e.g. `$var`, where $var is  `...`.\n+    None,\n+}\n+\n+/// An interned string.\n+#[derive(Copy, Clone)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub struct Symbol(symbol::Symbol);\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl<'a> From<&'a str> for Symbol {\n+    fn from(string: &'a str) -> Symbol {\n+        Symbol(symbol::Symbol::intern(string))\n+    }\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl ops::Deref for Symbol {\n+    type Target = str;\n+\n+    fn deref(&self) -> &str {\n+        unsafe { &*(self.0.as_str().deref() as *const str) }\n+    }\n+}\n+\n+/// Whether an `Op` is either followed immediately by another `Op` or followed by whitespace.\n+#[derive(Copy, Clone)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub enum OpKind {\n+    /// e.g. `+` is `Alone` in `+ =`.\n+    Alone,\n+    /// e.g. `+` is `Joint` in `+=`.\n+    Joint,\n+}\n+\n+/// A literal character (`'a'`), string (`\"hello\"`), or number (`2.3`).\n+#[derive(Clone)]\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub struct Literal(token::Token);\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl fmt::Display for Literal {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        TokenTree { kind: TokenKind::Literal(self.clone()), span: Span(DUMMY_SP) }.fmt(f)\n+    }\n+}\n+\n+macro_rules! int_literals {\n+    ($($int_kind:ident),*) => {$(\n+        /// Integer literal.\n+        #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+        pub fn $int_kind(n: $int_kind) -> Literal {\n+            Literal::integer(n as i128, stringify!($int_kind))\n+        }\n+    )*}\n+}\n+\n+impl Literal {\n+    int_literals!(u8, i8, u16, i16, u32, i32, u64, i64);\n+    fn integer(n: i128, kind: &'static str) -> Literal {\n+        Literal(token::Literal(token::Lit::Integer(symbol::Symbol::intern(&n.to_string())),\n+                               Some(symbol::Symbol::intern(kind))))\n+    }\n+\n+    /// Floating point literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn f32(n: f32) -> Literal {\n+        Literal(token::Literal(token::Lit::Float(symbol::Symbol::intern(&n.to_string())),\n+                               Some(symbol::Symbol::intern(\"f32\"))))\n+    }\n+\n+    /// Floating point literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn f64(n: f32) -> Literal {\n+        Literal(token::Literal(token::Lit::Float(symbol::Symbol::intern(&n.to_string())),\n+                               Some(symbol::Symbol::intern(\"f64\"))))\n+    }\n+\n+    /// String literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn string(string: &str) -> Literal {\n+        let mut escaped = String::new();\n+        for ch in string.chars() {\n+            escaped.extend(ch.escape_unicode());\n+        }\n+        Literal(token::Literal(token::Lit::Str_(symbol::Symbol::intern(&escaped)), None))\n+    }\n+\n+    /// Character literal.\n+    #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+    pub fn character(ch: char) -> Literal {\n+        let mut escaped = String::new();\n+        escaped.extend(ch.escape_unicode());\n+        Literal(token::Literal(token::Lit::Char(symbol::Symbol::intern(&escaped)), None))\n+    }\n+}\n+\n+/// An iterator over `TokenTree`s.\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+pub struct TokenIter {\n+    cursor: tokenstream::Cursor,\n+    next: Option<tokenstream::TokenStream>,\n+}\n+\n+#[unstable(feature = \"proc_macro\", issue = \"38356\")]\n+impl Iterator for TokenIter {\n+    type Item = TokenTree;\n+\n+    fn next(&mut self) -> Option<TokenTree> {\n+        self.next.take().or_else(|| self.cursor.next_as_stream())\n+            .map(|next| TokenTree::from_raw(next, &mut self.next))\n+    }\n+}\n+\n+impl Delimiter {\n+    fn from_raw(delim: token::DelimToken) -> Delimiter {\n+        match delim {\n+            token::Paren => Delimiter::Parenthesis,\n+            token::Brace => Delimiter::Brace,\n+            token::Bracket => Delimiter::Bracket,\n+            token::NoDelim => Delimiter::None,\n+        }\n+    }\n+\n+    fn to_raw(self) -> token::DelimToken {\n+        match self {\n+            Delimiter::Parenthesis => token::Paren,\n+            Delimiter::Brace => token::Brace,\n+            Delimiter::Bracket => token::Bracket,\n+            Delimiter::None => token::NoDelim,\n+        }\n+    }\n+}\n+\n+impl TokenTree {\n+    fn from_raw(stream: tokenstream::TokenStream, next: &mut Option<tokenstream::TokenStream>)\n+                -> TokenTree {\n+        use syntax::parse::token::*;\n+\n+        let (tree, is_joint) = stream.as_tree();\n+        let (mut span, token) = match tree {\n+            tokenstream::TokenTree::Token(span, token) => (span, token),\n+            tokenstream::TokenTree::Delimited(span, delimed) => {\n+                let delimiter = Delimiter::from_raw(delimed.delim);\n+                return TokenTree {\n+                    span: Span(span),\n+                    kind: TokenKind::Sequence(delimiter, TokenStream(delimed.tts.into())),\n+                };\n+            }\n+        };\n+\n+        let op_kind = if is_joint { OpKind::Joint } else { OpKind::Alone };\n+        macro_rules! op {\n+            ($op:expr) => { TokenKind::Op($op, op_kind) }\n+        }\n+\n+        macro_rules! joint {\n+            ($first:expr, $rest:expr) => { joint($first, $rest, is_joint, &mut span, next) }\n+        }\n+\n+        fn joint(first: char, rest: Token, is_joint: bool, span: &mut syntax_pos::Span,\n+                 next: &mut Option<tokenstream::TokenStream>)\n+                 -> TokenKind {\n+            let (first_span, rest_span) = (*span, *span);\n+            *span = first_span;\n+            let tree = tokenstream::TokenTree::Token(rest_span, rest);\n+            *next = Some(if is_joint { tree.joint() } else { tree.into() });\n+            TokenKind::Op(first, OpKind::Joint)\n+        }\n+\n+        let kind = match token {\n+            Eq => op!('='),\n+            Lt => op!('<'),\n+            Le => joint!('<', Eq),\n+            EqEq => joint!('=', Eq),\n+            Ne => joint!('!', Eq),\n+            Ge => joint!('>', Eq),\n+            Gt => op!('>'),\n+            AndAnd => joint!('&', BinOp(And)),\n+            OrOr => joint!('|', BinOp(Or)),\n+            Not => op!('!'),\n+            Tilde => op!('~'),\n+            BinOp(Plus) => op!('+'),\n+            BinOp(Minus) => op!('-'),\n+            BinOp(Star) => op!('*'),\n+            BinOp(Slash) => op!('/'),\n+            BinOp(Percent) => op!('%'),\n+            BinOp(Caret) => op!('^'),\n+            BinOp(And) => op!('&'),\n+            BinOp(Or) => op!('|'),\n+            BinOp(Shl) => joint!('<', Lt),\n+            BinOp(Shr) => joint!('>', Gt),\n+            BinOpEq(Plus) => joint!('+', Eq),\n+            BinOpEq(Minus) => joint!('-', Eq),\n+            BinOpEq(Star) => joint!('*', Eq),\n+            BinOpEq(Slash) => joint!('/', Eq),\n+            BinOpEq(Percent) => joint!('%', Eq),\n+            BinOpEq(Caret) => joint!('^', Eq),\n+            BinOpEq(And) => joint!('&', Eq),\n+            BinOpEq(Or) => joint!('|', Eq),\n+            BinOpEq(Shl) => joint!('<', Le),\n+            BinOpEq(Shr) => joint!('>', Ge),\n+            At => op!('@'),\n+            Dot => op!('.'),\n+            DotDot => joint!('.', Dot),\n+            DotDotDot => joint!('.', DotDot),\n+            Comma => op!(','),\n+            Semi => op!(';'),\n+            Colon => op!(':'),\n+            ModSep => joint!(':', Colon),\n+            RArrow => joint!('-', Gt),\n+            LArrow => joint!('<', BinOp(Minus)),\n+            FatArrow => joint!('=', Gt),\n+            Pound => op!('#'),\n+            Dollar => op!('$'),\n+            Question => op!('?'),\n+            Underscore => op!('_'),\n+\n+            Ident(ident) | Lifetime(ident) => TokenKind::Word(Symbol(ident.name)),\n+            Literal(..) | DocComment(..) => TokenKind::Literal(self::Literal(token)),\n+\n+            Interpolated(..) => unimplemented!(),\n+\n+            OpenDelim(..) | CloseDelim(..) => unreachable!(),\n+            Whitespace | Comment | Shebang(..) | Eof => unreachable!(),\n+        };\n+\n+        TokenTree { span: Span(span), kind: kind }\n+    }\n+\n+    fn to_raw(self) -> tokenstream::TokenStream {\n+        use syntax::parse::token::*;\n+        use syntax::tokenstream::{TokenTree, Delimited};\n+\n+        let (op, kind) = match self.kind {\n+            TokenKind::Op(op, kind) => (op, kind),\n+            TokenKind::Sequence(delimiter, tokens) => {\n+                return TokenTree::Delimited(self.span.0, Delimited {\n+                    delim: delimiter.to_raw(),\n+                    tts: tokens.0.into(),\n+                }).into();\n+            },\n+            TokenKind::Word(symbol) => {\n+                let ident = ast::Ident { name: symbol.0, ctxt: self.span.0.ctxt };\n+                let token =\n+                    if symbol.0.as_str().starts_with(\"'\") { Lifetime(ident) } else { Ident(ident) };\n+                return TokenTree::Token(self.span.0, token).into();\n+            }\n+            TokenKind::Literal(token) => return TokenTree::Token(self.span.0, token.0).into(),\n+        };\n+\n+        let token = match op {\n+            '=' => Eq,\n+            '<' => Lt,\n+            '>' => Gt,\n+            '!' => Not,\n+            '~' => Tilde,\n+            '+' => BinOp(Plus),\n+            '-' => BinOp(Minus),\n+            '*' => BinOp(Star),\n+            '/' => BinOp(Slash),\n+            '%' => BinOp(Percent),\n+            '^' => BinOp(Caret),\n+            '&' => BinOp(And),\n+            '|' => BinOp(Or),\n+            '@' => At,\n+            '.' => Dot,\n+            ',' => Comma,\n+            ';' => Semi,\n+            ':' => Colon,\n+            '#' => Pound,\n+            '$' => Dollar,\n+            '?' => Question,\n+            '_' => Underscore,\n+            _ => panic!(\"unsupported character {}\", op),\n+        };\n+\n+        let tree = TokenTree::Token(self.span.0, token);\n+        match kind {\n+            OpKind::Alone => tree.into(),\n+            OpKind::Joint => tree.joint(),\n+        }\n+    }\n+}\n+\n /// Permanently unstable internal implementation details of this crate. This\n /// should not be used.\n ///\n@@ -80,7 +524,11 @@ pub struct LexError {\n /// all of the contents.\n #[unstable(feature = \"proc_macro_internals\", issue = \"27812\")]\n #[doc(hidden)]\n+#[path = \"\"]\n pub mod __internal {\n+    mod quote;\n+    pub use self::quote::{Quoter, __rt};\n+\n     use std::cell::Cell;\n     use std::rc::Rc;\n \n@@ -172,25 +620,3 @@ fn parse_to_lex_err(mut err: DiagnosticBuilder) -> LexError {\n     err.cancel();\n     LexError { _inner: () }\n }\n-\n-#[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n-impl FromStr for TokenStream {\n-    type Err = LexError;\n-\n-    fn from_str(src: &str) -> Result<TokenStream, LexError> {\n-        __internal::with_sess(|(sess, mark)| {\n-            let src = src.to_string();\n-            let name = \"<proc-macro source code>\".to_string();\n-            let call_site = mark.expn_info().unwrap().call_site;\n-            let stream = parse::parse_stream_from_source_str(name, src, sess, Some(call_site));\n-            Ok(__internal::token_stream_wrap(stream))\n-        })\n-    }\n-}\n-\n-#[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n-impl fmt::Display for TokenStream {\n-    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        self.0.fmt(f)\n-    }\n-}"}, {"sha": "a3ea3925fcd4818f510ed979d129e918cdf6e83d", "filename": "src/libproc_macro/quote.rs", "status": "added", "additions": 259, "deletions": 0, "changes": 259, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibproc_macro%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fquote.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -0,0 +1,259 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! # Quasiquoter\n+//! This file contains the implementation internals of the quasiquoter provided by `qquote!`.\n+\n+use syntax::ast::Ident;\n+use syntax::ext::base::{ExtCtxt, ProcMacro};\n+use syntax::parse::token::{self, Token, Lit};\n+use syntax::symbol::Symbol;\n+use syntax::tokenstream::{Delimited, TokenTree, TokenStream};\n+use syntax_pos::{DUMMY_SP, Span};\n+use syntax_pos::hygiene::SyntaxContext;\n+\n+pub struct Quoter;\n+\n+pub mod __rt {\n+    pub use syntax::ast::Ident;\n+    pub use syntax::parse::token;\n+    pub use syntax::symbol::Symbol;\n+    pub use syntax::tokenstream::{TokenStream, TokenTree, Delimited};\n+    pub use super::{ctxt, span};\n+\n+    pub fn unquote<T: Into<::TokenStream> + Clone>(tokens: &T) -> TokenStream {\n+        T::into(tokens.clone()).0\n+    }\n+}\n+\n+pub fn ctxt() -> SyntaxContext {\n+    ::__internal::with_sess(|(_, mark)| SyntaxContext::empty().apply_mark(mark))\n+}\n+\n+pub fn span() -> Span {\n+    ::Span::default().0\n+}\n+\n+trait Quote {\n+    fn quote(&self) -> TokenStream;\n+}\n+\n+macro_rules! quote_tok {\n+    (,) => { Token::Comma };\n+    (.) => { Token::Dot };\n+    (:) => { Token::Colon };\n+    (::) => { Token::ModSep };\n+    (!) => { Token::Not };\n+    (<) => { Token::Lt };\n+    (>) => { Token::Gt };\n+    (_) => { Token::Underscore };\n+    (0) => { Token::Literal(token::Lit::Integer(Symbol::intern(\"0\")), None) };\n+    (&) => { Token::BinOp(token::And) };\n+    ($i:ident) => { Token::Ident(Ident { name: Symbol::intern(stringify!($i)), ctxt: ctxt() }) };\n+}\n+\n+macro_rules! quote_tree {\n+    ((unquote $($t:tt)*)) => { TokenStream::from($($t)*) };\n+    ((quote $($t:tt)*)) => { ($($t)*).quote() };\n+    (($($t:tt)*)) => { delimit(token::Paren, quote!($($t)*)) };\n+    ([$($t:tt)*]) => { delimit(token::Bracket, quote!($($t)*)) };\n+    ({$($t:tt)*}) => { delimit(token::Brace, quote!($($t)*)) };\n+    (rt) => { quote!(::__internal::__rt) };\n+    ($t:tt) => { TokenStream::from(TokenTree::Token(span(), quote_tok!($t))) };\n+}\n+\n+fn delimit(delim: token::DelimToken, stream: TokenStream) -> TokenStream {\n+    TokenTree::Delimited(span(), Delimited { delim: delim, tts: stream.into() }).into()\n+}\n+\n+macro_rules! quote {\n+    () => { TokenStream::empty() };\n+    ($($t:tt)*) => { [ $( quote_tree!($t), )* ].iter().cloned().collect::<TokenStream>() };\n+}\n+\n+impl ProcMacro for Quoter {\n+    fn expand<'cx>(&self, cx: &'cx mut ExtCtxt, _: Span, stream: TokenStream) -> TokenStream {\n+        let mut info = cx.current_expansion.mark.expn_info().unwrap();\n+        info.callee.allow_internal_unstable = true;\n+        cx.current_expansion.mark.set_expn_info(info);\n+        ::__internal::set_sess(cx, || quote!(::TokenStream((quote stream))))\n+    }\n+}\n+\n+impl<T: Quote> Quote for Option<T> {\n+    fn quote(&self) -> TokenStream {\n+        match *self {\n+            Some(ref t) => quote!(Some((quote t))),\n+            None => quote!(None),\n+        }\n+    }\n+}\n+\n+impl Quote for TokenStream {\n+    fn quote(&self) -> TokenStream {\n+        let mut builder = TokenStream::builder();\n+        builder.push(quote!(rt::TokenStream::builder()));\n+\n+        let mut trees = self.trees();\n+        loop {\n+            let (mut tree, mut is_joint) = match trees.next_as_stream() {\n+                Some(next) => next.as_tree(),\n+                None => return builder.add(quote!(.build())).build(),\n+            };\n+            if let TokenTree::Token(_, Token::Dollar) = tree {\n+                let (next_tree, next_is_joint) = match trees.next_as_stream() {\n+                    Some(next) => next.as_tree(),\n+                    None => panic!(\"unexpected trailing `$` in `quote!`\"),\n+                };\n+                match next_tree {\n+                    TokenTree::Token(_, Token::Ident(..)) => {\n+                        builder.push(quote!(.add(rt::unquote(&(unquote next_tree)))));\n+                        continue\n+                    }\n+                    TokenTree::Token(_, Token::Dollar) => {\n+                        tree = next_tree;\n+                        is_joint = next_is_joint;\n+                    }\n+                    _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n+                }\n+            }\n+\n+            builder.push(match is_joint {\n+                true => quote!(.add((quote tree).joint())),\n+                false => quote!(.add(rt::TokenStream::from((quote tree)))),\n+            });\n+        }\n+    }\n+}\n+\n+impl Quote for TokenTree {\n+    fn quote(&self) -> TokenStream {\n+        match *self {\n+            TokenTree::Token(span, ref token) => quote! {\n+                rt::TokenTree::Token((quote span), (quote token))\n+            },\n+            TokenTree::Delimited(span, ref delimited) => quote! {\n+                rt::TokenTree::Delimited((quote span), (quote delimited))\n+            },\n+        }\n+    }\n+}\n+\n+impl Quote for Delimited {\n+    fn quote(&self) -> TokenStream {\n+        quote!(rt::Delimited { delim: (quote self.delim), tts: (quote self.stream()).into() })\n+    }\n+}\n+\n+impl<'a> Quote for &'a str {\n+    fn quote(&self) -> TokenStream {\n+        TokenTree::Token(span(), Token::Literal(token::Lit::Str_(Symbol::intern(self)), None))\n+            .into()\n+    }\n+}\n+\n+impl Quote for usize {\n+    fn quote(&self) -> TokenStream {\n+        let integer_symbol = Symbol::intern(&self.to_string());\n+        TokenTree::Token(DUMMY_SP, Token::Literal(token::Lit::Integer(integer_symbol), None))\n+            .into()\n+    }\n+}\n+\n+impl Quote for Ident {\n+    fn quote(&self) -> TokenStream {\n+        quote!(rt::Ident { name: (quote self.name), ctxt: rt::ctxt() })\n+    }\n+}\n+\n+impl Quote for Symbol {\n+    fn quote(&self) -> TokenStream {\n+        quote!(rt::Symbol::intern((quote &*self.as_str())))\n+    }\n+}\n+\n+impl Quote for Span {\n+    fn quote(&self) -> TokenStream {\n+        quote!(rt::span())\n+    }\n+}\n+\n+impl Quote for Token {\n+    fn quote(&self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident),*; $($t:tt)*) => {\n+                match *self {\n+                    $( Token::$i => quote!(rt::token::$i), )*\n+                    $( $t )*\n+                }\n+            }\n+        }\n+\n+        gen_match! {\n+            Eq, Lt, Le, EqEq, Ne, Ge, Gt, AndAnd, OrOr, Not, Tilde, At, Dot, DotDot, DotDotDot,\n+            Comma, Semi, Colon, ModSep, RArrow, LArrow, FatArrow, Pound, Dollar, Question,\n+            Underscore;\n+\n+            Token::OpenDelim(delim) => quote!(rt::token::OpenDelim((quote delim))),\n+            Token::CloseDelim(delim) => quote!(rt::token::CloseDelim((quote delim))),\n+            Token::BinOp(tok) => quote!(rt::token::BinOp((quote tok))),\n+            Token::BinOpEq(tok) => quote!(rt::token::BinOpEq((quote tok))),\n+            Token::Ident(ident) => quote!(rt::token::Ident((quote ident))),\n+            Token::Lifetime(ident) => quote!(rt::token::Lifetime((quote ident))),\n+            Token::Literal(lit, sfx) => quote!(rt::token::Literal((quote lit), (quote sfx))),\n+            _ => panic!(\"Unhandled case!\"),\n+        }\n+    }\n+}\n+\n+impl Quote for token::BinOpToken {\n+    fn quote(&self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident),*) => {\n+                match *self {\n+                    $( token::BinOpToken::$i => quote!(rt::token::BinOpToken::$i), )*\n+                }\n+            }\n+        }\n+\n+        gen_match!(Plus, Minus, Star, Slash, Percent, Caret, And, Or, Shl, Shr)\n+    }\n+}\n+\n+impl Quote for Lit {\n+    fn quote(&self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident),*; $($raw:ident),*) => {\n+                match *self {\n+                    $( Lit::$i(lit) => quote!(rt::token::Lit::$i((quote lit))), )*\n+                    $( Lit::$raw(lit, n) => {\n+                        quote!(::syntax::parse::token::Lit::$raw((quote lit), (quote n)))\n+                    })*\n+                }\n+            }\n+        }\n+\n+        gen_match!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw)\n+    }\n+}\n+\n+impl Quote for token::DelimToken {\n+    fn quote(&self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident),*) => {\n+                match *self {\n+                    $(token::DelimToken::$i => { quote!(rt::token::DelimToken::$i) })*\n+                }\n+            }\n+        }\n+\n+        gen_match!(Paren, Bracket, Brace, NoDelim)\n+    }\n+}"}, {"sha": "146a66cdf01cb484586677b7c68cbdc89e2dd233", "filename": "src/libproc_macro_plugin/Cargo.toml", "status": "removed", "additions": 0, "deletions": 13, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro_plugin%2FCargo.toml?ref=7d41674b175cdb3452e042ef6f37141bc3788f8b", "patch": "@@ -1,13 +0,0 @@\n-[package]\n-authors = [\"The Rust Project Developers\"]\n-name = \"proc_macro_plugin\"\n-version = \"0.0.0\"\n-\n-[lib]\n-path = \"lib.rs\"\n-crate-type = [\"dylib\"]\n-\n-[dependencies]\n-rustc_plugin = { path = \"../librustc_plugin\" }\n-syntax = { path = \"../libsyntax\" }\n-syntax_pos = { path = \"../libsyntax_pos\" }"}, {"sha": "d1bc0966eb567188dbc15d2e6c39f6a82eedf64f", "filename": "src/libproc_macro_plugin/lib.rs", "status": "removed", "additions": 0, "deletions": 103, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro_plugin%2Flib.rs?ref=7d41674b175cdb3452e042ef6f37141bc3788f8b", "patch": "@@ -1,103 +0,0 @@\n-// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Proc_Macro\n-//!\n-//! A library for procedural macro writers.\n-//!\n-//! ## Usage\n-//! This crate provides the `quote!` macro for syntax creation.\n-//!\n-//! The `quote!` macro uses the crate `syntax`, so users must declare `extern crate syntax;`\n-//! at the crate root. This is a temporary solution until we have better hygiene.\n-//!\n-//! ## Quasiquotation\n-//!\n-//! The quasiquoter creates output that, when run, constructs the tokenstream specified as\n-//! input. For example, `quote!(5 + 5)` will produce a program, that, when run, will\n-//! construct the TokenStream `5 | + | 5`.\n-//!\n-//! ### Unquoting\n-//!\n-//! Unquoting is done with `$`, and works by taking the single next ident as the unquoted term.\n-//! To quote `$` itself, use `$$`.\n-//!\n-//! A simple example is:\n-//!\n-//!```\n-//!fn double(tmp: TokenStream) -> TokenStream {\n-//!    quote!($tmp * 2)\n-//!}\n-//!```\n-//!\n-//! ### Large example: Scheme's `cond`\n-//!\n-//! Below is an example implementation of Scheme's `cond`.\n-//!\n-//! ```\n-//! fn cond(input: TokenStream) -> TokenStream {\n-//!     let mut conds = Vec::new();\n-//!     let mut input = input.trees().peekable();\n-//!     while let Some(tree) = input.next() {\n-//!         let mut cond = match tree {\n-//!             TokenTree::Delimited(_, ref delimited) => delimited.stream(),\n-//!             _ => panic!(\"Invalid input\"),\n-//!         };\n-//!         let mut trees = cond.trees();\n-//!         let test = trees.next();\n-//!         let rhs = trees.collect::<TokenStream>();\n-//!         if rhs.is_empty() {\n-//!             panic!(\"Invalid macro usage in cond: {}\", cond);\n-//!         }\n-//!         let is_else = match test {\n-//!             Some(TokenTree::Token(_, Token::Ident(ident))) if ident.name == \"else\" => true,\n-//!             _ => false,\n-//!         };\n-//!         conds.push(if is_else || input.peek().is_none() {\n-//!             quote!({ $rhs })\n-//!         } else {\n-//!             let test = test.unwrap();\n-//!             quote!(if $test { $rhs } else)\n-//!         });\n-//!     }\n-//!\n-//!     conds.into_iter().collect()\n-//! }\n-//! ```\n-#![crate_name = \"proc_macro_plugin\"]\n-#![feature(plugin_registrar)]\n-#![crate_type = \"dylib\"]\n-#![crate_type = \"rlib\"]\n-#![doc(html_logo_url = \"https://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n-       html_favicon_url = \"https://doc.rust-lang.org/favicon.ico\",\n-       html_root_url = \"https://doc.rust-lang.org/nightly/\")]\n-#![deny(warnings)]\n-\n-#![feature(rustc_diagnostic_macros)]\n-\n-extern crate rustc_plugin;\n-extern crate syntax;\n-extern crate syntax_pos;\n-\n-mod quote;\n-use quote::quote;\n-\n-use rustc_plugin::Registry;\n-use syntax::ext::base::SyntaxExtension;\n-use syntax::symbol::Symbol;\n-\n-// ____________________________________________________________________________________________\n-// Main macro definition\n-\n-#[plugin_registrar]\n-pub fn plugin_registrar(reg: &mut Registry) {\n-    reg.register_syntax_extension(Symbol::intern(\"quote\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(quote)));\n-}"}, {"sha": "09675564291a248b4ded93dddccee6aa6371a73f", "filename": "src/libproc_macro_plugin/quote.rs", "status": "removed", "additions": 0, "deletions": 230, "changes": 230, "blob_url": "https://github.com/rust-lang/rust/blob/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Flibproc_macro_plugin%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro_plugin%2Fquote.rs?ref=7d41674b175cdb3452e042ef6f37141bc3788f8b", "patch": "@@ -1,230 +0,0 @@\n-// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! # Quasiquoter\n-//! This file contains the implementation internals of the quasiquoter provided by `qquote!`.\n-\n-use syntax::ast::Ident;\n-use syntax::parse::token::{self, Token, Lit};\n-use syntax::symbol::Symbol;\n-use syntax::tokenstream::{self, Delimited, TokenTree, TokenStream};\n-use syntax_pos::DUMMY_SP;\n-\n-use std::iter;\n-\n-pub fn quote<'cx>(stream: TokenStream) -> TokenStream {\n-    stream.quote()\n-}\n-\n-trait Quote {\n-    fn quote(&self) -> TokenStream;\n-}\n-\n-macro_rules! quote_tok {\n-    (,) => { Token::Comma };\n-    (.) => { Token::Dot };\n-    (:) => { Token::Colon };\n-    (::) => { Token::ModSep };\n-    (!) => { Token::Not };\n-    (<) => { Token::Lt };\n-    (>) => { Token::Gt };\n-    (_) => { Token::Underscore };\n-    ($i:ident) => { Token::Ident(Ident::from_str(stringify!($i))) };\n-}\n-\n-macro_rules! quote_tree {\n-    ((unquote $($t:tt)*)) => { $($t)* };\n-    ((quote $($t:tt)*)) => { ($($t)*).quote() };\n-    (($($t:tt)*)) => { delimit(token::Paren, quote!($($t)*)) };\n-    ([$($t:tt)*]) => { delimit(token::Bracket, quote!($($t)*)) };\n-    ({$($t:tt)*}) => { delimit(token::Brace, quote!($($t)*)) };\n-    ($t:tt) => { TokenStream::from(TokenTree::Token(DUMMY_SP, quote_tok!($t))) };\n-}\n-\n-fn delimit(delim: token::DelimToken, stream: TokenStream) -> TokenStream {\n-    TokenTree::Delimited(DUMMY_SP, Delimited { delim: delim, tts: stream.into() }).into()\n-}\n-\n-macro_rules! quote {\n-    () => { TokenStream::empty() };\n-    ($($t:tt)*) => { [ $( quote_tree!($t), )* ].iter().cloned().collect::<TokenStream>() };\n-}\n-\n-impl<T: Quote> Quote for Option<T> {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            Some(ref t) => quote!(::std::option::Option::Some((quote t))),\n-            None => quote!(::std::option::Option::None),\n-        }\n-    }\n-}\n-\n-impl Quote for TokenStream {\n-    fn quote(&self) -> TokenStream {\n-        if self.is_empty() {\n-            return quote!(::syntax::tokenstream::TokenStream::empty());\n-        }\n-\n-        struct Quoter(iter::Peekable<tokenstream::Cursor>);\n-\n-        impl Iterator for Quoter {\n-            type Item = TokenStream;\n-\n-            fn next(&mut self) -> Option<TokenStream> {\n-                let quoted_tree = if let Some(&TokenTree::Token(_, Token::Dollar)) = self.0.peek() {\n-                    self.0.next();\n-                    match self.0.next() {\n-                        Some(tree @ TokenTree::Token(_, Token::Ident(..))) => Some(tree.into()),\n-                        Some(tree @ TokenTree::Token(_, Token::Dollar)) => Some(tree.quote()),\n-                        // FIXME(jseyfried): improve these diagnostics\n-                        Some(..) => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n-                        None => panic!(\"unexpected trailing `$` in `quote!`\"),\n-                    }\n-                } else {\n-                    self.0.next().as_ref().map(Quote::quote)\n-                };\n-\n-                quoted_tree.map(|quoted_tree| {\n-                    quote!(::syntax::tokenstream::TokenStream::from((unquote quoted_tree)),)\n-                })\n-            }\n-        }\n-\n-        let quoted = Quoter(self.trees().peekable()).collect::<TokenStream>();\n-        quote!([(unquote quoted)].iter().cloned().collect::<::syntax::tokenstream::TokenStream>())\n-    }\n-}\n-\n-impl Quote for TokenTree {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            TokenTree::Token(_, ref token) => quote! {\n-                ::syntax::tokenstream::TokenTree::Token(::syntax::ext::quote::rt::DUMMY_SP,\n-                                                        (quote token))\n-            },\n-            TokenTree::Delimited(_, ref delimited) => quote! {\n-                ::syntax::tokenstream::TokenTree::Delimited(::syntax::ext::quote::rt::DUMMY_SP,\n-                                                            (quote delimited))\n-            },\n-        }\n-    }\n-}\n-\n-impl Quote for Delimited {\n-    fn quote(&self) -> TokenStream {\n-        quote!(::syntax::tokenstream::Delimited {\n-            delim: (quote self.delim),\n-            tts: (quote self.stream()).into(),\n-        })\n-    }\n-}\n-\n-impl<'a> Quote for &'a str {\n-    fn quote(&self) -> TokenStream {\n-        TokenTree::Token(DUMMY_SP, Token::Literal(token::Lit::Str_(Symbol::intern(self)), None))\n-            .into()\n-    }\n-}\n-\n-impl Quote for usize {\n-    fn quote(&self) -> TokenStream {\n-        let integer_symbol = Symbol::intern(&self.to_string());\n-        TokenTree::Token(DUMMY_SP, Token::Literal(token::Lit::Integer(integer_symbol), None))\n-            .into()\n-    }\n-}\n-\n-impl Quote for Ident {\n-    fn quote(&self) -> TokenStream {\n-        // FIXME(jseyfried) quote hygiene\n-        quote!(::syntax::ast::Ident::from_str((quote &*self.name.as_str())))\n-    }\n-}\n-\n-impl Quote for Symbol {\n-    fn quote(&self) -> TokenStream {\n-        quote!(::syntax::symbol::Symbol::intern((quote &*self.as_str())))\n-    }\n-}\n-\n-impl Quote for Token {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*; $($t:tt)*) => {\n-                match *self {\n-                    $( Token::$i => quote!(::syntax::parse::token::$i), )*\n-                    $( $t )*\n-                }\n-            }\n-        }\n-\n-        gen_match! {\n-            Eq, Lt, Le, EqEq, Ne, Ge, Gt, AndAnd, OrOr, Not, Tilde, At, Dot, DotDot, DotDotDot,\n-            Comma, Semi, Colon, ModSep, RArrow, LArrow, FatArrow, Pound, Dollar, Question,\n-            Underscore;\n-\n-            Token::OpenDelim(delim) => quote!(::syntax::parse::token::OpenDelim((quote delim))),\n-            Token::CloseDelim(delim) => quote!(::syntax::parse::token::CloseDelim((quote delim))),\n-            Token::BinOp(tok) => quote!(::syntax::parse::token::BinOp((quote tok))),\n-            Token::BinOpEq(tok) => quote!(::syntax::parse::token::BinOpEq((quote tok))),\n-            Token::Ident(ident) => quote!(::syntax::parse::token::Ident((quote ident))),\n-            Token::Lifetime(ident) => quote!(::syntax::parse::token::Lifetime((quote ident))),\n-            Token::Literal(lit, sfx) => quote! {\n-                ::syntax::parse::token::Literal((quote lit), (quote sfx))\n-            },\n-            _ => panic!(\"Unhandled case!\"),\n-        }\n-    }\n-}\n-\n-impl Quote for token::BinOpToken {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*) => {\n-                match *self {\n-                    $( token::BinOpToken::$i => quote!(::syntax::parse::token::BinOpToken::$i), )*\n-                }\n-            }\n-        }\n-\n-        gen_match!(Plus, Minus, Star, Slash, Percent, Caret, And, Or, Shl, Shr)\n-    }\n-}\n-\n-impl Quote for Lit {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*; $($raw:ident),*) => {\n-                match *self {\n-                    $( Lit::$i(lit) => quote!(::syntax::parse::token::Lit::$i((quote lit))), )*\n-                    $( Lit::$raw(lit, n) => {\n-                        quote!(::syntax::parse::token::Lit::$raw((quote lit), (quote n)))\n-                    })*\n-                }\n-            }\n-        }\n-\n-        gen_match!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw)\n-    }\n-}\n-\n-impl Quote for token::DelimToken {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*) => {\n-                match *self {\n-                    $(token::DelimToken::$i => { quote!(::syntax::parse::token::DelimToken::$i) })*\n-                }\n-            }\n-        }\n-\n-        gen_match!(Paren, Bracket, Brace, NoDelim)\n-    }\n-}"}, {"sha": "5322d24e38934cddaaab784fc6915cd955f866fa", "filename": "src/librustc/hir/map/definitions.rs", "status": "modified", "additions": 15, "deletions": 12, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fmap%2Fdefinitions.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -55,12 +55,19 @@ impl Clone for DefPathTable {\n }\n \n impl DefPathTable {\n+    pub fn new() -> Self {\n+        DefPathTable {\n+            index_to_key: [vec![], vec![]],\n+            key_to_index: FxHashMap(),\n+            def_path_hashes: [vec![], vec![]],\n+        }\n+    }\n \n-    fn allocate(&mut self,\n-                key: DefKey,\n-                def_path_hash: DefPathHash,\n-                address_space: DefIndexAddressSpace)\n-                -> DefIndex {\n+    pub fn allocate(&mut self,\n+                    key: DefKey,\n+                    def_path_hash: DefPathHash,\n+                    address_space: DefIndexAddressSpace)\n+                    -> DefIndex {\n         let index = {\n             let index_to_key = &mut self.index_to_key[address_space.index()];\n             let index = DefIndex::new(index_to_key.len() + address_space.start());\n@@ -241,7 +248,7 @@ pub struct DefKey {\n }\n \n impl DefKey {\n-    fn compute_stable_hash(&self, parent_hash: DefPathHash) -> DefPathHash {\n+    pub fn compute_stable_hash(&self, parent_hash: DefPathHash) -> DefPathHash {\n         let mut hasher = StableHasher::new();\n \n         // We hash a 0u8 here to disambiguate between regular DefPath hashes,\n@@ -284,7 +291,7 @@ impl DefKey {\n         DefPathHash(hasher.finish())\n     }\n \n-    fn root_parent_stable_hash(crate_name: &str, crate_disambiguator: &str) -> DefPathHash {\n+    pub fn root_parent_stable_hash(crate_name: &str, crate_disambiguator: &str) -> DefPathHash {\n         let mut hasher = StableHasher::new();\n         // Disambiguate this from a regular DefPath hash,\n         // see compute_stable_hash() above.\n@@ -446,11 +453,7 @@ impl Definitions {\n     /// Create new empty definition map.\n     pub fn new() -> Definitions {\n         Definitions {\n-            table: DefPathTable {\n-                index_to_key: [vec![], vec![]],\n-                key_to_index: FxHashMap(),\n-                def_path_hashes: [vec![], vec![]],\n-            },\n+            table: DefPathTable::new(),\n             node_to_def_index: NodeMap(),\n             def_index_to_node: [vec![], vec![]],\n             node_to_hir_id: IndexVec::new(),"}, {"sha": "e6dc5da969a88a2c23449806b746b4ea51a8e163", "filename": "src/librustc/middle/stability.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc%2Fmiddle%2Fstability.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc%2Fmiddle%2Fstability.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fstability.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -728,6 +728,7 @@ pub fn check_unused_or_stable_features<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n     let ref declared_lib_features = sess.features.borrow().declared_lib_features;\n     let mut remaining_lib_features: FxHashMap<Symbol, Span>\n         = declared_lib_features.clone().into_iter().collect();\n+    remaining_lib_features.remove(&Symbol::intern(\"proc_macro\"));\n \n     fn format_stable_since_msg(version: &str) -> String {\n         format!(\"this feature has been stable since {}. Attribute no longer needed\", version)"}, {"sha": "0b950787e3b91123a87ed6b7d653648adf870ed7", "filename": "src/librustc_driver/Cargo.toml", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_driver%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_driver%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2FCargo.toml?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -13,7 +13,6 @@ arena = { path = \"../libarena\" }\n graphviz = { path = \"../libgraphviz\" }\n log = { version = \"0.3\", features = [\"release_max_level_info\"] }\n env_logger = { version = \"0.4\", default-features = false }\n-proc_macro_plugin = { path = \"../libproc_macro_plugin\" }\n rustc = { path = \"../librustc\" }\n rustc_back = { path = \"../librustc_back\" }\n rustc_borrowck = { path = \"../librustc_borrowck\" }"}, {"sha": "57a09ed15032f4aace3fe9429cbbb2bb42136cd1", "filename": "src/librustc_metadata/creader.rs", "status": "modified", "additions": 41, "deletions": 7, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fcreader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fcreader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcreader.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -26,15 +26,16 @@ use rustc::middle::cstore::{CrateStore, validate_crate_name, ExternCrate};\n use rustc::util::common::record_time;\n use rustc::util::nodemap::FxHashSet;\n use rustc::middle::cstore::NativeLibrary;\n-use rustc::hir::map::Definitions;\n+use rustc::hir::map::{Definitions, DefKey, DefPathData, DisambiguatedDefPathData, ITEM_LIKE_SPACE};\n+use rustc::hir::map::definitions::DefPathTable;\n \n use std::cell::{RefCell, Cell};\n use std::ops::Deref;\n use std::path::PathBuf;\n use std::rc::Rc;\n use std::{cmp, fs};\n \n-use syntax::ast;\n+use syntax::ast::{self, Ident};\n use syntax::abi::Abi;\n use syntax::attr;\n use syntax::ext::base::SyntaxExtension;\n@@ -307,9 +308,16 @@ impl<'a> CrateLoader<'a> {\n \n         let cnum_map = self.resolve_crate_deps(root, &crate_root, &metadata, cnum, span, dep_kind);\n \n-        let def_path_table = record_time(&self.sess.perf_stats.decode_def_path_tables_time, || {\n-            crate_root.def_path_table.decode(&metadata)\n+        let proc_macros = crate_root.macro_derive_registrar.map(|_| {\n+            self.load_derive_macros(&crate_root, dylib.clone().map(|p| p.0), span)\n         });\n+        let def_path_table = if let Some(ref proc_macros) = proc_macros {\n+            proc_macro_def_path_table(proc_macros)\n+        } else {\n+            record_time(&self.sess.perf_stats.decode_def_path_tables_time, || {\n+                crate_root.def_path_table.decode(&metadata)\n+            })\n+        };\n \n         let exported_symbols = crate_root.exported_symbols\n                                          .map(|x| x.decode(&metadata).collect());\n@@ -328,9 +336,7 @@ impl<'a> CrateLoader<'a> {\n             def_path_table: Rc::new(def_path_table),\n             exported_symbols: exported_symbols,\n             trait_impls: trait_impls,\n-            proc_macros: crate_root.macro_derive_registrar.map(|_| {\n-                self.load_derive_macros(&crate_root, dylib.clone().map(|p| p.0), span)\n-            }),\n+            proc_macros: proc_macros,\n             root: crate_root,\n             blob: metadata,\n             cnum_map: RefCell::new(cnum_map),\n@@ -1213,3 +1219,31 @@ impl<'a> middle::cstore::CrateLoader for CrateLoader<'a> {\n         }\n     }\n }\n+\n+fn proc_macro_def_path_table(proc_macros: &[(ast::Name, Rc<SyntaxExtension>)]) -> DefPathTable {\n+    let mut table = DefPathTable::new();\n+    let root = DefKey {\n+        parent: None,\n+        disambiguated_data: DisambiguatedDefPathData {\n+            data: DefPathData::CrateRoot,\n+            disambiguator: 0,\n+        },\n+    };\n+\n+    let initial_hash = DefKey::root_parent_stable_hash(\"\", \"\");\n+    let root_hash = root.compute_stable_hash(initial_hash);\n+    let root_id = table.allocate(root, root_hash, ITEM_LIKE_SPACE);\n+    let root_path_hash = table.def_path_hash(root_id);\n+    for proc_macro in proc_macros {\n+        let key = DefKey {\n+            parent: Some(CRATE_DEF_INDEX),\n+            disambiguated_data: DisambiguatedDefPathData {\n+                data: DefPathData::MacroDef(Ident::with_empty_ctxt(proc_macro.0)),\n+                disambiguator: 0,\n+            },\n+        };\n+        let def_path_hash = key.compute_stable_hash(root_path_hash);\n+        table.allocate(key, def_path_hash, ITEM_LIKE_SPACE);\n+    }\n+    table\n+}"}, {"sha": "ff5febadeb70fc378ba76b88135f0c5e3ea917e8", "filename": "src/librustc_metadata/cstore_impl.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fcstore_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fcstore_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fcstore_impl.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -33,6 +33,7 @@ use std::rc::Rc;\n \n use syntax::ast;\n use syntax::attr;\n+use syntax::ext::base::SyntaxExtension;\n use syntax::parse::filemap_to_stream;\n use syntax::symbol::Symbol;\n use syntax_pos::{Span, NO_EXPANSION};\n@@ -365,6 +366,10 @@ impl CrateStore for cstore::CStore {\n         let data = self.get_crate_data(id.krate);\n         if let Some(ref proc_macros) = data.proc_macros {\n             return LoadedMacro::ProcMacro(proc_macros[id.index.as_usize() - 1].1.clone());\n+        } else if data.name == \"proc_macro\" &&\n+                  self.get_crate_data(id.krate).item_name(id.index) == \"quote\" {\n+            let ext = SyntaxExtension::ProcMacro(Box::new(::proc_macro::__internal::Quoter));\n+            return LoadedMacro::ProcMacro(Rc::new(ext));\n         }\n \n         let (name, def) = data.get_macro(id.index);"}, {"sha": "b974541ef255af3984dd692aad837046b1332bb3", "filename": "src/librustc_metadata/decoder.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fdecoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fdecoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fdecoder.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -472,7 +472,7 @@ impl<'a, 'tcx> CrateMetadata {\n         }\n     }\n \n-    fn item_name(&self, item_index: DefIndex) -> ast::Name {\n+    pub fn item_name(&self, item_index: DefIndex) -> ast::Name {\n         self.def_key(item_index)\n             .disambiguated_data\n             .data"}, {"sha": "63a24c7db18ffcede6b1dbf3bd75a49cfabdc859", "filename": "src/librustc_metadata/encoder.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibrustc_metadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_metadata%2Fencoder.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -1095,18 +1095,19 @@ impl<'a, 'b: 'a, 'tcx: 'b> IsolatedEncoder<'a, 'b, 'tcx> {\n     /// Serialize the text of exported macros\n     fn encode_info_for_macro_def(&mut self, macro_def: &hir::MacroDef) -> Entry<'tcx> {\n         use syntax::print::pprust;\n+        let def_id = self.tcx.hir.local_def_id(macro_def.id);\n         Entry {\n             kind: EntryKind::MacroDef(self.lazy(&MacroDef {\n                 body: pprust::tts_to_string(&macro_def.body.trees().collect::<Vec<_>>()),\n                 legacy: macro_def.legacy,\n             })),\n             visibility: self.lazy(&ty::Visibility::Public),\n             span: self.lazy(&macro_def.span),\n-\n             attributes: self.encode_attributes(&macro_def.attrs),\n+            stability: self.encode_stability(def_id),\n+            deprecation: self.encode_deprecation(def_id),\n+\n             children: LazySeq::empty(),\n-            stability: None,\n-            deprecation: None,\n             ty: None,\n             inherent_impls: LazySeq::empty(),\n             variances: LazySeq::empty(),"}, {"sha": "325a5cdf8fc0279a7e0008bb0267ba7f189ee1da", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -100,7 +100,7 @@ impl Path {\n         let name = self.segments[0].identifier.name;\n         if !self.is_global() && name != \"$crate\" &&\n            name != keywords::SelfValue.name() && name != keywords::Super.name() {\n-            self.segments.insert(0, PathSegment::crate_root());\n+            self.segments.insert(0, PathSegment::crate_root(self.span));\n         }\n         self\n     }\n@@ -134,10 +134,10 @@ impl PathSegment {\n     pub fn from_ident(ident: Ident, span: Span) -> Self {\n         PathSegment { identifier: ident, span: span, parameters: None }\n     }\n-    pub fn crate_root() -> Self {\n+    pub fn crate_root(span: Span) -> Self {\n         PathSegment {\n-            identifier: keywords::CrateRoot.ident(),\n-            span: DUMMY_SP,\n+            identifier: Ident { ctxt: span.ctxt, ..keywords::CrateRoot.ident() },\n+            span: span,\n             parameters: None,\n         }\n     }"}, {"sha": "7a5c9456c5315e5dd6ca247dbf878eb0eb7a122e", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -578,7 +578,10 @@ impl SyntaxExtension {\n \n     pub fn is_modern(&self) -> bool {\n         match *self {\n-            SyntaxExtension::DeclMacro(..) => true,\n+            SyntaxExtension::DeclMacro(..) |\n+            SyntaxExtension::ProcMacro(..) |\n+            SyntaxExtension::AttrProcMacro(..) |\n+            SyntaxExtension::ProcMacroDerive(..) => true,\n             _ => false,\n         }\n     }"}, {"sha": "5168943d108cb5daf08d7b0b0149b67d3f5db804", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -320,7 +320,7 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         let last_identifier = idents.pop().unwrap();\n         let mut segments: Vec<ast::PathSegment> = Vec::new();\n         if global {\n-            segments.push(ast::PathSegment::crate_root());\n+            segments.push(ast::PathSegment::crate_root(sp));\n         }\n \n         segments.extend(idents.into_iter().map(|i| ast::PathSegment::from_ident(i, sp)));"}, {"sha": "3f3c94536a6e739650797d7e6522bfd8e204f2e0", "filename": "src/libsyntax/feature_gate.rs", "status": "modified", "additions": 17, "deletions": 11, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ffeature_gate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ffeature_gate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffeature_gate.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -38,23 +38,29 @@ use symbol::Symbol;\n use std::ascii::AsciiExt;\n use std::env;\n \n-macro_rules! setter {\n+macro_rules! set {\n+    (proc_macro) => {{\n+        fn f(features: &mut Features, span: Span) {\n+            features.declared_lib_features.push((Symbol::intern(\"proc_macro\"), span));\n+            features.proc_macro = true;\n+        }\n+        f as fn(&mut Features, Span)\n+    }};\n     ($field: ident) => {{\n-        fn f(features: &mut Features) -> &mut bool {\n-            &mut features.$field\n+        fn f(features: &mut Features, _: Span) {\n+            features.$field = true;\n         }\n-        f as fn(&mut Features) -> &mut bool\n+        f as fn(&mut Features, Span)\n     }}\n }\n \n macro_rules! declare_features {\n     ($((active, $feature: ident, $ver: expr, $issue: expr),)+) => {\n         /// Represents active features that are currently being implemented or\n         /// currently being considered for addition/removal.\n-        const ACTIVE_FEATURES: &'static [(&'static str, &'static str,\n-                                          Option<u32>, fn(&mut Features) -> &mut bool)] = &[\n-            $((stringify!($feature), $ver, $issue, setter!($feature))),+\n-        ];\n+        const ACTIVE_FEATURES:\n+                &'static [(&'static str, &'static str, Option<u32>, fn(&mut Features, Span))] =\n+            &[$((stringify!($feature), $ver, $issue, set!($feature))),+];\n \n         /// A set of features to be used by later passes.\n         pub struct Features {\n@@ -1464,9 +1470,9 @@ pub fn get_features(span_handler: &Handler, krate_attrs: &[ast::Attribute]) -> F\n                         continue\n                     };\n \n-                    if let Some(&(_, _, _, setter)) = ACTIVE_FEATURES.iter()\n+                    if let Some(&(_, _, _, set)) = ACTIVE_FEATURES.iter()\n                         .find(|& &(n, _, _, _)| name == n) {\n-                        *(setter(&mut features)) = true;\n+                        set(&mut features, mi.span);\n                         feature_checker.collect(&features, mi.span);\n                     }\n                     else if let Some(&(_, _, _)) = REMOVED_FEATURES.iter()\n@@ -1500,7 +1506,7 @@ struct MutexFeatureChecker {\n \n impl MutexFeatureChecker {\n     // If this method turns out to be a hotspot due to branching,\n-    // the branching can be eliminated by modifying `setter!()` to set these spans\n+    // the branching can be eliminated by modifying `set!()` to set these spans\n     // only for the features that need to be checked for mutual exclusion.\n     fn collect(&mut self, features: &Features, span: Span) {\n         if features.proc_macro {"}, {"sha": "ca4814397d8aca098a9c7738fac0a9526b875be7", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -573,7 +573,7 @@ pub fn noop_fold_tt<T: Folder>(tt: TokenTree, fld: &mut T) -> TokenTree {\n }\n \n pub fn noop_fold_tts<T: Folder>(tts: TokenStream, fld: &mut T) -> TokenStream {\n-    tts.trees().map(|tt| fld.fold_tt(tt)).collect()\n+    tts.map(|tt| fld.fold_tt(tt))\n }\n \n // apply ident folder if it's an ident, apply other folds to interpolated nodes"}, {"sha": "63a396c14db858607ea1a17ba61564b894bff080", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -19,7 +19,9 @@ impl<'a> StringReader<'a> {\n     pub fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n         let mut tts = Vec::new();\n         while self.token != token::Eof {\n-            tts.push(self.parse_token_tree()?.into());\n+            let tree = self.parse_token_tree()?;\n+            let is_joint = tree.span().hi == self.span.lo && token::is_op(&self.token);\n+            tts.push(if is_joint { tree.joint() } else { tree.into() });\n         }\n         Ok(TokenStream::concat(tts))\n     }\n@@ -31,13 +33,15 @@ impl<'a> StringReader<'a> {\n             if let token::CloseDelim(..) = self.token {\n                 return TokenStream::concat(tts);\n             }\n-            match self.parse_token_tree() {\n-                Ok(tt) => tts.push(tt.into()),\n+            let tree = match self.parse_token_tree() {\n+                Ok(tree) => tree,\n                 Err(mut e) => {\n                     e.emit();\n                     return TokenStream::concat(tts);\n                 }\n-            }\n+            };\n+            let is_joint = tree.span().hi == self.span.lo && token::is_op(&self.token);\n+            tts.push(if is_joint { tree.joint() } else { tree.into() });\n         }\n     }\n "}, {"sha": "a30dcef6f44e18c6489175d75f4fb540c0e632fe", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -1777,7 +1777,7 @@ impl<'a> Parser<'a> {\n         };\n \n         if is_global {\n-            segments.insert(0, PathSegment::crate_root());\n+            segments.insert(0, PathSegment::crate_root(lo));\n         }\n \n         // Assemble the result.\n@@ -6187,7 +6187,7 @@ impl<'a> Parser<'a> {\n             // `{foo, bar}`, `::{foo, bar}`, `*`, or `::*`.\n             self.eat(&token::ModSep);\n             let prefix = ast::Path {\n-                segments: vec![PathSegment::crate_root()],\n+                segments: vec![PathSegment::crate_root(lo)],\n                 span: lo.to(self.span),\n             };\n             let view_path_kind = if self.eat(&token::BinOp(token::Star)) {"}, {"sha": "e568af66e8aa825e0e7e87bfb2187eb003c619b8", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -349,6 +349,60 @@ impl Token {\n             _ => false,\n         }\n     }\n+\n+    pub fn glue(self, joint: Token) -> Option<Token> {\n+        Some(match self {\n+            Eq => match joint {\n+                Eq => EqEq,\n+                Gt => FatArrow,\n+                _ => return None,\n+            },\n+            Lt => match joint {\n+                Eq => Le,\n+                Lt => BinOp(Shl),\n+                Le => BinOpEq(Shl),\n+                BinOp(Minus) => LArrow,\n+                _ => return None,\n+            },\n+            Gt => match joint {\n+                Eq => Ge,\n+                Gt => BinOp(Shr),\n+                Ge => BinOpEq(Shr),\n+                _ => return None,\n+            },\n+            Not => match joint {\n+                Eq => Ne,\n+                _ => return None,\n+            },\n+            BinOp(op) => match joint {\n+                Eq => BinOpEq(op),\n+                BinOp(And) if op == And => AndAnd,\n+                BinOp(Or) if op == Or => OrOr,\n+                Gt if op == Minus => RArrow,\n+                _ => return None,\n+            },\n+            Dot => match joint {\n+                Dot => DotDot,\n+                DotDot => DotDotDot,\n+                _ => return None,\n+            },\n+            DotDot => match joint {\n+                Dot => DotDotDot,\n+                _ => return None,\n+            },\n+            Colon => match joint {\n+                Colon => ModSep,\n+                _ => return None,\n+            },\n+\n+            Le | EqEq | Ne | Ge | AndAnd | OrOr | Tilde | BinOpEq(..) | At | DotDotDot | Comma |\n+            Semi | ModSep | RArrow | LArrow | FatArrow | Pound | Dollar | Question |\n+            OpenDelim(..) | CloseDelim(..) | Underscore => return None,\n+\n+            Literal(..) | Ident(..) | Lifetime(..) | Interpolated(..) | DocComment(..) |\n+            Whitespace | Comment | Shebang(..) | Eof => return None,\n+        })\n+    }\n }\n \n #[derive(Clone, RustcEncodable, RustcDecodable, PartialEq, Eq, Hash)]\n@@ -398,3 +452,12 @@ impl fmt::Debug for Nonterminal {\n         }\n     }\n }\n+\n+pub fn is_op(tok: &Token) -> bool {\n+    match *tok {\n+        OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) |\n+        Ident(..) | Underscore | Lifetime(..) | Interpolated(..) |\n+        Whitespace | Comment | Shebang(..) | Eof => false,\n+        _ => true,\n+    }\n+}"}, {"sha": "2637972cc63628f9cbf108b1c06f0f368c1f4756", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 136, "deletions": 16, "changes": 152, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -138,6 +138,10 @@ impl TokenTree {\n             _ => false,\n         }\n     }\n+\n+    pub fn joint(self) -> TokenStream {\n+        TokenStream { kind: TokenStreamKind::JointTree(self) }\n+    }\n }\n \n /// # Token Streams\n@@ -155,6 +159,7 @@ pub struct TokenStream {\n enum TokenStreamKind {\n     Empty,\n     Tree(TokenTree),\n+    JointTree(TokenTree),\n     Stream(RcSlice<TokenStream>),\n }\n \n@@ -196,6 +201,10 @@ impl TokenStream {\n         }\n     }\n \n+    pub fn builder() -> TokenStreamBuilder {\n+        TokenStreamBuilder(Vec::new())\n+    }\n+\n     pub fn concat(mut streams: Vec<TokenStream>) -> TokenStream {\n         match streams.len() {\n             0 => TokenStream::empty(),\n@@ -225,6 +234,99 @@ impl TokenStream {\n         }\n         true\n     }\n+\n+    pub fn as_tree(self) -> (TokenTree, bool /* joint? */) {\n+        match self.kind {\n+            TokenStreamKind::Tree(tree) => (tree, false),\n+            TokenStreamKind::JointTree(tree) => (tree, true),\n+            _ => unreachable!(),\n+        }\n+    }\n+\n+    pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n+        let mut trees = self.into_trees();\n+        let mut result = Vec::new();\n+        while let Some(stream) = trees.next_as_stream() {\n+            result.push(match stream.kind {\n+                TokenStreamKind::Tree(tree) => f(tree).into(),\n+                TokenStreamKind::JointTree(tree) => f(tree).joint(),\n+                _ => unreachable!()\n+            });\n+        }\n+        TokenStream::concat(result)\n+    }\n+\n+    fn first_tree(&self) -> Option<TokenTree> {\n+        match self.kind {\n+            TokenStreamKind::Empty => None,\n+            TokenStreamKind::Tree(ref tree) |\n+            TokenStreamKind::JointTree(ref tree) => Some(tree.clone()),\n+            TokenStreamKind::Stream(ref stream) => stream.first().unwrap().first_tree(),\n+        }\n+    }\n+\n+    fn last_tree_if_joint(&self) -> Option<TokenTree> {\n+        match self.kind {\n+            TokenStreamKind::Empty | TokenStreamKind::Tree(..) => None,\n+            TokenStreamKind::JointTree(ref tree) => Some(tree.clone()),\n+            TokenStreamKind::Stream(ref stream) => stream.last().unwrap().last_tree_if_joint(),\n+        }\n+    }\n+}\n+\n+pub struct TokenStreamBuilder(Vec<TokenStream>);\n+\n+impl TokenStreamBuilder {\n+    pub fn push<T: Into<TokenStream>>(&mut self, stream: T) {\n+        let stream = stream.into();\n+        let last_tree_if_joint = self.0.last().and_then(TokenStream::last_tree_if_joint);\n+        if let Some(TokenTree::Token(last_span, last_tok)) = last_tree_if_joint {\n+            if let Some(TokenTree::Token(span, tok)) = stream.first_tree() {\n+                if let Some(glued_tok) = last_tok.glue(tok) {\n+                    let last_stream = self.0.pop().unwrap();\n+                    self.push_all_but_last_tree(&last_stream);\n+                    let glued_span = last_span.to(span);\n+                    self.0.push(TokenTree::Token(glued_span, glued_tok).into());\n+                    self.push_all_but_first_tree(&stream);\n+                    return\n+                }\n+            }\n+        }\n+        self.0.push(stream);\n+    }\n+\n+    pub fn add<T: Into<TokenStream>>(mut self, stream: T) -> Self {\n+        self.push(stream);\n+        self\n+    }\n+\n+    pub fn build(self) -> TokenStream {\n+        TokenStream::concat(self.0)\n+    }\n+\n+    fn push_all_but_last_tree(&mut self, stream: &TokenStream) {\n+        if let TokenStreamKind::Stream(ref streams) = stream.kind {\n+            let len = streams.len();\n+            match len {\n+                1 => {}\n+                2 => self.0.push(streams[0].clone().into()),\n+                _ => self.0.push(TokenStream::concat_rc_slice(streams.sub_slice(0 .. len - 1))),\n+            }\n+            self.push_all_but_last_tree(&streams[len - 1])\n+        }\n+    }\n+\n+    fn push_all_but_first_tree(&mut self, stream: &TokenStream) {\n+        if let TokenStreamKind::Stream(ref streams) = stream.kind {\n+            let len = streams.len();\n+            match len {\n+                1 => {}\n+                2 => self.0.push(streams[1].clone().into()),\n+                _ => self.0.push(TokenStream::concat_rc_slice(streams.sub_slice(1 .. len))),\n+            }\n+            self.push_all_but_first_tree(&streams[0])\n+        }\n+    }\n }\n \n #[derive(Clone)]\n@@ -234,6 +336,7 @@ pub struct Cursor(CursorKind);\n enum CursorKind {\n     Empty,\n     Tree(TokenTree, bool /* consumed? */),\n+    JointTree(TokenTree, bool /* consumed? */),\n     Stream(StreamCursor),\n }\n \n@@ -245,12 +348,13 @@ struct StreamCursor {\n }\n \n impl StreamCursor {\n-    fn next(&mut self) -> Option<TokenTree> {\n+    fn next_as_stream(&mut self) -> Option<TokenStream> {\n         loop {\n             if self.index < self.stream.len() {\n                 self.index += 1;\n-                match self.stream[self.index - 1].kind.clone() {\n-                    TokenStreamKind::Tree(tree) => return Some(tree),\n+                let next = self.stream[self.index - 1].clone();\n+                match next.kind {\n+                    TokenStreamKind::Tree(..) | TokenStreamKind::JointTree(..) => return Some(next),\n                     TokenStreamKind::Stream(stream) => {\n                         self.stack.push((mem::replace(&mut self.stream, stream),\n                                          mem::replace(&mut self.index, 0)));\n@@ -271,14 +375,10 @@ impl Iterator for Cursor {\n     type Item = TokenTree;\n \n     fn next(&mut self) -> Option<TokenTree> {\n-        let (tree, consumed) = match self.0 {\n-            CursorKind::Tree(ref tree, ref mut consumed @ false) => (tree, consumed),\n-            CursorKind::Stream(ref mut cursor) => return cursor.next(),\n-            _ => return None,\n-        };\n-\n-        *consumed = true;\n-        Some(tree.clone())\n+        self.next_as_stream().map(|stream| match stream.kind {\n+            TokenStreamKind::Tree(tree) | TokenStreamKind::JointTree(tree) => tree,\n+            _ => unreachable!()\n+        })\n     }\n }\n \n@@ -287,16 +387,32 @@ impl Cursor {\n         Cursor(match stream.kind {\n             TokenStreamKind::Empty => CursorKind::Empty,\n             TokenStreamKind::Tree(tree) => CursorKind::Tree(tree, false),\n+            TokenStreamKind::JointTree(tree) => CursorKind::JointTree(tree, false),\n             TokenStreamKind::Stream(stream) => {\n                 CursorKind::Stream(StreamCursor { stream: stream, index: 0, stack: Vec::new() })\n             }\n         })\n     }\n \n+    pub fn next_as_stream(&mut self) -> Option<TokenStream> {\n+        let (stream, consumed) = match self.0 {\n+            CursorKind::Tree(ref tree, ref mut consumed @ false) =>\n+                (tree.clone().into(), consumed),\n+            CursorKind::JointTree(ref tree, ref mut consumed @ false) =>\n+                (tree.clone().joint(), consumed),\n+            CursorKind::Stream(ref mut cursor) => return cursor.next_as_stream(),\n+            _ => return None,\n+        };\n+\n+        *consumed = true;\n+        Some(stream)\n+    }\n+\n     pub fn original_stream(self) -> TokenStream {\n         match self.0 {\n             CursorKind::Empty => TokenStream::empty(),\n             CursorKind::Tree(tree, _) => tree.into(),\n+            CursorKind::JointTree(tree, _) => tree.joint(),\n             CursorKind::Stream(cursor) => TokenStream::concat_rc_slice({\n                 cursor.stack.get(0).cloned().map(|(stream, _)| stream).unwrap_or(cursor.stream)\n             }),\n@@ -307,22 +423,25 @@ impl Cursor {\n         fn look_ahead(streams: &[TokenStream], mut n: usize) -> Result<TokenTree, usize> {\n             for stream in streams {\n                 n = match stream.kind {\n-                    TokenStreamKind::Tree(ref tree) if n == 0 => return Ok(tree.clone()),\n-                    TokenStreamKind::Tree(..) => n - 1,\n+                    TokenStreamKind::Tree(ref tree) | TokenStreamKind::JointTree(ref tree)\n+                        if n == 0 => return Ok(tree.clone()),\n+                    TokenStreamKind::Tree(..) | TokenStreamKind::JointTree(..) => n - 1,\n                     TokenStreamKind::Stream(ref stream) => match look_ahead(stream, n) {\n                         Ok(tree) => return Ok(tree),\n                         Err(n) => n,\n                     },\n                     _ => n,\n                 };\n             }\n-\n             Err(n)\n         }\n \n         match self.0 {\n-            CursorKind::Empty | CursorKind::Tree(_, true) => Err(n),\n-            CursorKind::Tree(ref tree, false) => look_ahead(&[tree.clone().into()], n),\n+            CursorKind::Empty |\n+            CursorKind::Tree(_, true) |\n+            CursorKind::JointTree(_, true) => Err(n),\n+            CursorKind::Tree(ref tree, false) |\n+            CursorKind::JointTree(ref tree, false) => look_ahead(&[tree.clone().into()], n),\n             CursorKind::Stream(ref cursor) => {\n                 look_ahead(&cursor.stream[cursor.index ..], n).or_else(|mut n| {\n                     for &(ref stream, index) in cursor.stack.iter().rev() {\n@@ -350,6 +469,7 @@ impl From<TokenStream> for ThinTokenStream {\n         ThinTokenStream(match stream.kind {\n             TokenStreamKind::Empty => None,\n             TokenStreamKind::Tree(tree) => Some(RcSlice::new(vec![tree.into()])),\n+            TokenStreamKind::JointTree(tree) => Some(RcSlice::new(vec![tree.joint()])),\n             TokenStreamKind::Stream(stream) => Some(stream),\n         })\n     }"}, {"sha": "d6939d71129e4e276b7c94f3a915f44d293db569", "filename": "src/libsyntax/util/rc_slice.rs", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Futil%2Frc_slice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Flibsyntax%2Futil%2Frc_slice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Frc_slice.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -9,7 +9,7 @@\n // except according to those terms.\n \n use std::fmt;\n-use std::ops::Deref;\n+use std::ops::{Deref, Range};\n use std::rc::Rc;\n \n use rustc_data_structures::stable_hasher::{StableHasher, StableHasherResult,\n@@ -30,6 +30,14 @@ impl<T> RcSlice<T> {\n             data: Rc::new(vec.into_boxed_slice()),\n         }\n     }\n+\n+    pub fn sub_slice(&self, range: Range<usize>) -> Self {\n+        RcSlice {\n+            data: self.data.clone(),\n+            offset: self.offset + range.start as u32,\n+            len: (range.end - range.start) as u32,\n+        }\n+    }\n }\n \n impl<T> Deref for RcSlice<T> {"}, {"sha": "9406eda5231d50dabd6a9d32be05f3b6d00073de", "filename": "src/test/run-pass-fulldeps/auxiliary/cond_plugin.rs", "status": "modified", "additions": 15, "deletions": 28, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fcond_plugin.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -8,50 +8,37 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-#![allow(unused_parens)]\n-#![feature(plugin)]\n-#![feature(plugin_registrar)]\n-#![feature(rustc_private)]\n-#![plugin(proc_macro_plugin)]\n+// no-prefer-dynamic\n \n-extern crate rustc_plugin;\n-extern crate syntax;\n+#![crate_type = \"proc-macro\"]\n+#![feature(proc_macro, proc_macro_lib)]\n \n-use rustc_plugin::Registry;\n+extern crate proc_macro;\n \n-use syntax::ext::base::SyntaxExtension;\n-use syntax::parse::token::Token;\n-use syntax::symbol::Symbol;\n-use syntax::tokenstream::{TokenTree, TokenStream};\n+use proc_macro::{TokenStream, TokenKind, quote};\n \n-#[plugin_registrar]\n-pub fn plugin_registrar(reg: &mut Registry) {\n-    reg.register_syntax_extension(Symbol::intern(\"cond\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(cond)));\n-}\n-\n-fn cond(input: TokenStream) -> TokenStream {\n+#[proc_macro]\n+pub fn cond(input: TokenStream) -> TokenStream {\n     let mut conds = Vec::new();\n-    let mut input = input.trees().peekable();\n+    let mut input = input.into_iter().peekable();\n     while let Some(tree) = input.next() {\n-        let mut cond = match tree {\n-            TokenTree::Delimited(_, ref delimited) => delimited.stream(),\n+        let cond = match tree.kind {\n+            TokenKind::Sequence(_, cond) => cond,\n             _ => panic!(\"Invalid input\"),\n         };\n-        let mut trees = cond.trees();\n-        let test = trees.next();\n-        let rhs = trees.collect::<TokenStream>();\n+        let mut cond_trees = cond.clone().into_iter();\n+        let test = cond_trees.next().expect(\"Unexpected empty condition in `cond!`\");\n+        let rhs = cond_trees.collect::<TokenStream>();\n         if rhs.is_empty() {\n             panic!(\"Invalid macro usage in cond: {}\", cond);\n         }\n-        let is_else = match test {\n-            Some(TokenTree::Token(_, Token::Ident(ident))) if ident.name == \"else\" => true,\n+        let is_else = match test.kind {\n+            TokenKind::Word(word) => *word == *\"else\",\n             _ => false,\n         };\n         conds.push(if is_else || input.peek().is_none() {\n             quote!({ $rhs })\n         } else {\n-            let test = test.unwrap();\n             quote!(if $test { $rhs } else)\n         });\n     }"}, {"sha": "cf6584e961a67a5997525be85d3488dc6dfbe628", "filename": "src/test/run-pass-fulldeps/auxiliary/hello_macro.rs", "status": "modified", "additions": 7, "deletions": 16, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fhello_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fhello_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fhello_macro.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -8,29 +8,20 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-#![feature(plugin)]\n-#![feature(plugin_registrar)]\n-#![feature(rustc_private)]\n-#![plugin(proc_macro_plugin)]\n+// no-prefer-dynamic\n \n-extern crate rustc_plugin;\n-extern crate syntax;\n+#![crate_type = \"proc-macro\"]\n+#![feature(proc_macro, proc_macro_lib)]\n \n-use rustc_plugin::Registry;\n-use syntax::ext::base::SyntaxExtension;\n-use syntax::symbol::Symbol;\n-use syntax::tokenstream::TokenStream;\n+extern crate proc_macro;\n \n-#[plugin_registrar]\n-pub fn plugin_registrar(reg: &mut Registry) {\n-    reg.register_syntax_extension(Symbol::intern(\"hello\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(hello)));\n-}\n+use proc_macro::{TokenStream, quote};\n \n // This macro is not very interesting, but it does contain delimited tokens with\n // no content - `()` and `{}` - which has caused problems in the past.\n // Also, it tests that we can escape `$` via `$$`.\n-fn hello(_: TokenStream) -> TokenStream {\n+#[proc_macro]\n+pub fn hello(_: TokenStream) -> TokenStream {\n     quote!({\n         fn hello() {}\n         macro_rules! m { ($$($$t:tt)*) => { $$($$t)* } }"}, {"sha": "1b47043884844b49409b550d4356e09efed08785", "filename": "src/test/run-pass-fulldeps/auxiliary/proc_macro_def.rs", "status": "modified", "additions": 20, "deletions": 30, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fauxiliary%2Fproc_macro_def.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -8,47 +8,37 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-#![feature(plugin, plugin_registrar, rustc_private)]\n-#![plugin(proc_macro_plugin)]\n-\n-extern crate rustc_plugin;\n-extern crate syntax;\n-\n-use rustc_plugin::Registry;\n-use syntax::ext::base::SyntaxExtension;\n-use syntax::tokenstream::TokenStream;\n-use syntax::symbol::Symbol;\n-\n-#[plugin_registrar]\n-pub fn plugin_registrar(reg: &mut Registry) {\n-    reg.register_syntax_extension(Symbol::intern(\"attr_tru\"),\n-                                  SyntaxExtension::AttrProcMacro(Box::new(attr_tru)));\n-    reg.register_syntax_extension(Symbol::intern(\"attr_identity\"),\n-                                  SyntaxExtension::AttrProcMacro(Box::new(attr_identity)));\n-    reg.register_syntax_extension(Symbol::intern(\"tru\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(tru)));\n-    reg.register_syntax_extension(Symbol::intern(\"ret_tru\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(ret_tru)));\n-    reg.register_syntax_extension(Symbol::intern(\"identity\"),\n-                                  SyntaxExtension::ProcMacro(Box::new(identity)));\n-}\n+// no-prefer-dynamic\n+\n+#![crate_type = \"proc-macro\"]\n+#![feature(proc_macro, proc_macro_lib)]\n+\n+extern crate proc_macro;\n+\n+use proc_macro::{TokenStream, quote};\n \n-fn attr_tru(_attr: TokenStream, _item: TokenStream) -> TokenStream {\n-    quote!(fn f1() -> bool { true })\n+#[proc_macro_attribute]\n+pub fn attr_tru(_attr: TokenStream, item: TokenStream) -> TokenStream {\n+    let name = item.into_iter().skip(1).next().unwrap();\n+    quote!(fn $name() -> bool { true })\n }\n \n-fn attr_identity(_attr: TokenStream, item: TokenStream) -> TokenStream {\n+#[proc_macro_attribute]\n+pub fn attr_identity(_attr: TokenStream, item: TokenStream) -> TokenStream {\n     quote!($item)\n }\n \n-fn tru(_ts: TokenStream) -> TokenStream {\n+#[proc_macro]\n+pub fn tru(_ts: TokenStream) -> TokenStream {\n     quote!(true)\n }\n \n-fn ret_tru(_ts: TokenStream) -> TokenStream {\n+#[proc_macro]\n+pub fn ret_tru(_ts: TokenStream) -> TokenStream {\n     quote!(return true;)\n }\n \n-fn identity(ts: TokenStream) -> TokenStream {\n+#[proc_macro]\n+pub fn identity(ts: TokenStream) -> TokenStream {\n     quote!($ts)\n }"}, {"sha": "e7d0a83017be004c4128d318ea1978515e18ed22", "filename": "src/test/run-pass-fulldeps/macro-quote-1.rs", "status": "removed", "additions": 0, "deletions": 40, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7d41674b175cdb3452e042ef6f37141bc3788f8b/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-1.rs?ref=7d41674b175cdb3452e042ef6f37141bc3788f8b", "patch": "@@ -1,40 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// ignore-stage1\n-\n-#![feature(plugin)]\n-#![feature(rustc_private)]\n-#![plugin(proc_macro_plugin)]\n-\n-extern crate syntax;\n-extern crate syntax_pos;\n-\n-use syntax::ast::{Ident, Name};\n-use syntax::parse::token::{self, Token, Lit};\n-use syntax::tokenstream::TokenTree;\n-\n-fn main() {\n-    let true_tok = token::Ident(Ident::from_str(\"true\"));\n-    assert!(quote!(true).eq_unspanned(&true_tok.into()));\n-\n-    // issue #35829, extended check to proc_macro.\n-    let triple_dot_tok = Token::DotDotDot;\n-    assert!(quote!(...).eq_unspanned(&triple_dot_tok.into()));\n-\n-    let byte_str_tok = Token::Literal(Lit::ByteStr(Name::intern(\"one\")), None);\n-    assert!(quote!(b\"one\").eq_unspanned(&byte_str_tok.into()));\n-\n-    let byte_str_raw_tok = Token::Literal(Lit::ByteStrRaw(Name::intern(\"#\\\"two\\\"#\"), 3), None);\n-    assert!(quote!(br###\"#\"two\"#\"###).eq_unspanned(&byte_str_raw_tok.into()));\n-\n-    let str_raw_tok = Token::Literal(Lit::StrRaw(Name::intern(\"#\\\"three\\\"#\"), 2), None);\n-    assert!(quote!(r##\"#\"three\"#\"##).eq_unspanned(&str_raw_tok.into()));\n-}"}, {"sha": "cff743bdae6cd485c756a145d2f5ad903a93b9da", "filename": "src/test/run-pass-fulldeps/macro-quote-cond.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-cond.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -11,9 +11,11 @@\n // aux-build:cond_plugin.rs\n // ignore-stage1\n \n-#![feature(plugin)]\n-#![feature(rustc_private)]\n-#![plugin(cond_plugin)]\n+#![feature(proc_macro)]\n+\n+extern crate cond_plugin;\n+\n+use cond_plugin::cond;\n \n fn fact(n : i64) -> i64 {\n     if n == 0 {"}, {"sha": "eb77895e2d7ad6da63429583b983ee4321f19173", "filename": "src/test/run-pass-fulldeps/macro-quote-test.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-test.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-test.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fmacro-quote-test.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -13,10 +13,10 @@\n // aux-build:hello_macro.rs\n // ignore-stage1\n \n-#![feature(plugin)]\n-#![feature(rustc_private)]\n-#![plugin(hello_macro)]\n+#![feature(proc_macro)]\n+\n+extern crate hello_macro;\n \n fn main() {\n-    hello!();\n+    hello_macro::hello!();\n }"}, {"sha": "cdda723585b7a850bb23de640358c26919ffb8b1", "filename": "src/test/run-pass-fulldeps/proc_macro.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fproc_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftest%2Frun-pass-fulldeps%2Fproc_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fproc_macro.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -12,10 +12,11 @@\n // ignore-stage1\n // ignore-cross-compile\n \n-#![feature(plugin, custom_attribute)]\n-#![feature(type_macros)]\n+#![feature(proc_macro)]\n \n-#![plugin(proc_macro_def)]\n+extern crate proc_macro_def;\n+\n+use proc_macro_def::{attr_tru, attr_identity, identity, ret_tru, tru};\n \n #[attr_tru]\n fn f1() -> bool {"}, {"sha": "f40fea60f40a89bbf6b297da58cb89bad8178583", "filename": "src/tools/tidy/src/cargo.rs", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Fcargo.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -91,14 +91,6 @@ fn verify(tomlfile: &Path, libfile: &Path, bad: &mut bool) {\n             continue\n         }\n \n-        // We want the compiler to depend on the proc_macro_plugin crate so\n-        // that it is built and included in the end, but we don't want to\n-        // actually use it in the compiler.\n-        if toml.contains(\"name = \\\"rustc_driver\\\"\") &&\n-           krate == \"proc_macro_plugin\" {\n-            continue\n-        }\n-\n         if !librs.contains(&format!(\"extern crate {}\", krate)) {\n             tidy_error!(bad, \"{} doesn't have `extern crate {}`, but Cargo.toml \\\n                               depends on it\", libfile.display(), krate);"}, {"sha": "d98c6932c51e18bb84674987e65186bfa2b90e60", "filename": "src/tools/tidy/src/features.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftools%2Ftidy%2Fsrc%2Ffeatures.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e42836b2085233323339bacb636ecf9c28e8422e/src%2Ftools%2Ftidy%2Fsrc%2Ffeatures.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Ffeatures.rs?ref=e42836b2085233323339bacb636ecf9c28e8422e", "patch": "@@ -245,7 +245,7 @@ fn get_and_check_lib_features(base_src_path: &Path,\n                     let mut err = |msg: &str| {\n                         tidy_error!(bad, \"{}:{}: {}\", file.display(), line, msg);\n                     };\n-                    if lang_features.contains_key(name) {\n+                    if lang_features.contains_key(name) && feature_name != \"proc_macro\" {\n                         err(\"duplicating a lang feature\");\n                     }\n                     if let Some(ref s) = lib_features.get(name) {"}]}