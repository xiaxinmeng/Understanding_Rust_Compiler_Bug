{"sha": "0a1c50955b35892643a4bcfce08e72d9297b5bca", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBhMWM1MDk1NWIzNTg5MjY0M2E0YmNmY2UwOGU3MmQ5Mjk3YjViY2E=", "commit": {"author": {"name": "Denis Merigoux", "email": "denis.merigoux@gmail.com", "date": "2018-09-11T09:46:03Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2018-11-16T12:12:49Z"}, "message": "Traitified IntrinsicCallMethods", "tree": {"sha": "1f2b84cf18d5e6314ff4a31d9b5a1aa78f7cc6bb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1f2b84cf18d5e6314ff4a31d9b5a1aa78f7cc6bb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0a1c50955b35892643a4bcfce08e72d9297b5bca", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0a1c50955b35892643a4bcfce08e72d9297b5bca", "html_url": "https://github.com/rust-lang/rust/commit/0a1c50955b35892643a4bcfce08e72d9297b5bca", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0a1c50955b35892643a4bcfce08e72d9297b5bca/comments", "author": {"login": "denismerigoux", "id": 1766128, "node_id": "MDQ6VXNlcjE3NjYxMjg=", "avatar_url": "https://avatars.githubusercontent.com/u/1766128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/denismerigoux", "html_url": "https://github.com/denismerigoux", "followers_url": "https://api.github.com/users/denismerigoux/followers", "following_url": "https://api.github.com/users/denismerigoux/following{/other_user}", "gists_url": "https://api.github.com/users/denismerigoux/gists{/gist_id}", "starred_url": "https://api.github.com/users/denismerigoux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/denismerigoux/subscriptions", "organizations_url": "https://api.github.com/users/denismerigoux/orgs", "repos_url": "https://api.github.com/users/denismerigoux/repos", "events_url": "https://api.github.com/users/denismerigoux/events{/privacy}", "received_events_url": "https://api.github.com/users/denismerigoux/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a5aeb8edd662ec1bec482894f08e2dda5eb677b8", "url": "https://api.github.com/repos/rust-lang/rust/commits/a5aeb8edd662ec1bec482894f08e2dda5eb677b8", "html_url": "https://github.com/rust-lang/rust/commit/a5aeb8edd662ec1bec482894f08e2dda5eb677b8"}], "stats": {"total": 1272, "additions": 648, "deletions": 624}, "files": [{"sha": "7428e3f16417d7a41520551421217047ce88ab64", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -73,9 +73,7 @@ use rustc_data_structures::small_c_str::SmallCStr;\n use rustc_data_structures::sync::Lrc;\n use rustc_data_structures::indexed_vec::Idx;\n \n-use interfaces::{\n-    BuilderMethods, ConstMethods, BaseTypeMethods, DerivedTypeMethods, DerivedIntrinsicMethods,\n-};\n+use interfaces::*;\n \n use std::any::Any;\n use std::cmp;"}, {"sha": "cee046c86c747a8e0cb12ecbaeb34cfc4b616bd2", "filename": "src/librustc_codegen_llvm/builder.rs", "status": "modified", "additions": 3, "deletions": 11, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbuilder.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -19,10 +19,7 @@ use rustc::ty::TyCtxt;\n use rustc::ty::layout::{Align, Size};\n use rustc::session::{config, Session};\n use rustc_data_structures::small_c_str::SmallCStr;\n-use interfaces::{\n-    Backend,\n-    BuilderMethods, ConstMethods, BaseTypeMethods, DerivedTypeMethods, DerivedIntrinsicMethods,\n-};\n+use interfaces::*;\n use syntax;\n \n use std::borrow::Cow;\n@@ -59,16 +56,11 @@ bitflags! {\n     }\n }\n \n-impl Backend for Builder<'a, 'll, 'tcx>  {\n-    type Value = &'ll Value;\n-    type BasicBlock = &'ll BasicBlock;\n-    type Type = &'ll Type;\n-    type Context = &'ll llvm::Context;\n+impl HasCodegen for Builder<'a, 'll, 'tcx> {\n+    type CodegenCx = CodegenCx<'ll, 'tcx>;\n }\n \n impl BuilderMethods<'a, 'tcx> for Builder<'a, 'll, 'tcx> {\n-    type CodegenCx = CodegenCx<'ll, 'tcx>;\n-\n     fn new_block<'b>(\n         cx: &'a CodegenCx<'ll, 'tcx>,\n         llfn: &'ll Value,"}, {"sha": "896fb9e6e431ac15c752bc248002fe301c642c61", "filename": "src/librustc_codegen_llvm/context.rs", "status": "modified", "additions": 2, "deletions": 7, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fcontext.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -23,8 +23,7 @@ use value::Value;\n use monomorphize::partitioning::CodegenUnit;\n use type_::Type;\n use type_of::PointeeInfo;\n-use interfaces::{BaseTypeMethods, DerivedTypeMethods,\n-    IntrinsicMethods, BaseIntrinsicMethods, DerivedIntrinsicMethods};\n+use interfaces::{BaseTypeMethods, DerivedTypeMethods, IntrinsicDeclarationMethods};\n \n use rustc_data_structures::base_n;\n use rustc_data_structures::small_c_str::SmallCStr;\n@@ -323,9 +322,7 @@ impl<'b, 'tcx> CodegenCx<'b, 'tcx> {\n     }\n }\n \n-impl BaseIntrinsicMethods for CodegenCx<'_, '_> {}\n-\n-impl DerivedIntrinsicMethods for CodegenCx<'b, 'tcx> {\n+impl IntrinsicDeclarationMethods for CodegenCx<'b, 'tcx> {\n     fn get_intrinsic(&self, key: &str) -> &'b Value {\n         if let Some(v) = self.intrinsics.borrow().get(key).cloned() {\n             return v;\n@@ -647,8 +644,6 @@ impl DerivedIntrinsicMethods for CodegenCx<'b, 'tcx> {\n     }\n }\n \n-impl IntrinsicMethods for CodegenCx<'a, 'tcx> {}\n-\n impl<'b, 'tcx> CodegenCx<'b, 'tcx> {\n     /// Generate a new symbol name with the given prefix. This symbol name must\n     /// only be used for definitions with `internal` or `private` linkage."}, {"sha": "c7a753cea87eef8cafdbc8e4247d9f7892867951", "filename": "src/librustc_codegen_llvm/interfaces/builder.rs", "status": "modified", "additions": 12, "deletions": 4, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fbuilder.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -17,21 +17,29 @@ use builder::MemFlags;\n use super::backend::Backend;\n use super::type_::TypeMethods;\n use super::consts::ConstMethods;\n-use super::intrinsic::IntrinsicMethods;\n+use super::intrinsic::IntrinsicDeclarationMethods;\n \n use std::borrow::Cow;\n use std::ops::Range;\n use syntax::ast::AsmDialect;\n \n-\n-pub trait BuilderMethods<'a, 'tcx: 'a>: Backend {\n-    type CodegenCx: 'a + TypeMethods + ConstMethods + IntrinsicMethods + Backend<\n+pub trait HasCodegen: Backend {\n+    type CodegenCx: TypeMethods + ConstMethods + IntrinsicDeclarationMethods + Backend<\n         Value = Self::Value,\n         BasicBlock = Self::BasicBlock,\n         Type = Self::Type,\n         Context = Self::Context,\n     >;\n+}\n+\n+impl<T: HasCodegen> Backend for T {\n+    type Value = <T::CodegenCx as Backend>::Value;\n+    type BasicBlock = <T::CodegenCx as Backend>::BasicBlock;\n+    type Type = <T::CodegenCx as Backend>::Type;\n+    type Context = <T::CodegenCx as Backend>::Context;\n+}\n \n+pub trait BuilderMethods<'a, 'tcx: 'a>: HasCodegen {\n     fn new_block<'b>(\n         cx: &'a Self::CodegenCx,\n         llfn: Self::Value,"}, {"sha": "39b95344c7101c232d1170fe2c47f65c545290fa", "filename": "src/librustc_codegen_llvm/interfaces/intrinsic.rs", "status": "modified", "additions": 15, "deletions": 5, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fintrinsic.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -9,17 +9,27 @@\n // except according to those terms.\n \n use super::backend::Backend;\n+use super::builder::HasCodegen;\n+use mir::operand::OperandRef;\n+use rustc::ty::Ty;\n+use abi::FnType;\n+use syntax_pos::Span;\n \n-pub trait BaseIntrinsicMethods: Backend {\n-\n+pub trait IntrinsicCallMethods<'a, 'tcx: 'a>: HasCodegen {\n+    fn codegen_intrinsic_call(\n+        &self,\n+        callee_ty: Ty<'tcx>,\n+        fn_ty: &FnType<'tcx, Ty<'tcx>>,\n+        args: &[OperandRef<'tcx, Self::Value>],\n+        llresult: Self::Value,\n+        span: Span,\n+    );\n }\n \n-pub trait DerivedIntrinsicMethods: Backend {\n+pub trait IntrinsicDeclarationMethods: Backend {\n     fn get_intrinsic(&self, key: &str) -> Self::Value;\n     fn declare_intrinsic(\n         &self,\n         key: &str\n     ) -> Option<Self::Value>;\n }\n-\n-pub trait IntrinsicMethods: BaseIntrinsicMethods + DerivedIntrinsicMethods {}"}, {"sha": "9f963f63383bfb801870345529781e2183c4a1cb", "filename": "src/librustc_codegen_llvm/interfaces/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Finterfaces%2Fmod.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -15,9 +15,9 @@ mod type_;\n mod intrinsic;\n mod statics;\n \n-pub use self::builder::BuilderMethods;\n+pub use self::builder::{BuilderMethods, HasCodegen};\n pub use self::backend::Backend;\n pub use self::consts::ConstMethods;\n pub use self::type_::{TypeMethods, BaseTypeMethods, DerivedTypeMethods};\n-pub use self::intrinsic::{IntrinsicMethods, BaseIntrinsicMethods, DerivedIntrinsicMethods};\n+pub use self::intrinsic::{IntrinsicCallMethods, IntrinsicDeclarationMethods};\n pub use self::statics::StaticMethods;"}, {"sha": "4c7401eac0707fcea2abff19fdb26f5349a8e59b", "filename": "src/librustc_codegen_llvm/intrinsic.rs", "status": "modified", "additions": 607, "deletions": 578, "changes": 1185, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fintrinsic.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -32,10 +32,7 @@ use syntax::symbol::Symbol;\n use builder::{Builder, MemFlags};\n use value::Value;\n \n-use interfaces::{\n-    BuilderMethods, ConstMethods, BaseTypeMethods, DerivedTypeMethods, DerivedIntrinsicMethods,\n-    StaticMethods,\n-};\n+use interfaces::*;\n \n use rustc::session::Session;\n use syntax_pos::Span;\n@@ -90,635 +87,667 @@ fn get_simple_intrinsic(cx: &CodegenCx<'ll, '_>, name: &str) -> Option<&'ll Valu\n     Some(cx.get_intrinsic(&llvm_name))\n }\n \n-/// Remember to add all intrinsics here, in librustc_typeck/check/mod.rs,\n-/// and in libcore/intrinsics.rs; if you need access to any llvm intrinsics,\n-/// add them to librustc_codegen_llvm/context.rs\n-pub fn codegen_intrinsic_call(\n-    bx: &Builder<'a, 'll, 'tcx>,\n-    callee_ty: Ty<'tcx>,\n-    fn_ty: &FnType<'tcx, Ty<'tcx>>,\n-    args: &[OperandRef<'tcx, &'ll Value>],\n-    llresult: &'ll Value,\n-    span: Span,\n-) {\n-    let cx = bx.cx();\n-    let tcx = cx.tcx;\n+impl IntrinsicCallMethods<'a, 'tcx> for Builder<'a, 'll, 'tcx> {\n+    /// Remember to add all intrinsics here, in librustc_typeck/check/mod.rs,\n+    /// and in libcore/intrinsics.rs; if you need access to any llvm intrinsics,\n+    /// add them to librustc_codegen_llvm/context.rs\n+    fn codegen_intrinsic_call(\n+        &self,\n+        callee_ty: Ty<'tcx>,\n+        fn_ty: &FnType<'tcx, Ty<'tcx>>,\n+        args: &[OperandRef<'tcx, &'ll Value>],\n+        llresult: &'ll Value,\n+        span: Span,\n+    ) {\n+        let cx = self.cx();\n+        let tcx = cx.tcx;\n \n-    let (def_id, substs) = match callee_ty.sty {\n-        ty::FnDef(def_id, substs) => (def_id, substs),\n-        _ => bug!(\"expected fn item type, found {}\", callee_ty)\n-    };\n+        let (def_id, substs) = match callee_ty.sty {\n+            ty::FnDef(def_id, substs) => (def_id, substs),\n+            _ => bug!(\"expected fn item type, found {}\", callee_ty)\n+        };\n \n-    let sig = callee_ty.fn_sig(tcx);\n-    let sig = tcx.normalize_erasing_late_bound_regions(ty::ParamEnv::reveal_all(), &sig);\n-    let arg_tys = sig.inputs();\n-    let ret_ty = sig.output();\n-    let name = &*tcx.item_name(def_id).as_str();\n-\n-    let llret_ty = cx.layout_of(ret_ty).llvm_type(cx);\n-    let result = PlaceRef::new_sized(llresult, fn_ty.ret.layout, fn_ty.ret.layout.align);\n-\n-    let simple = get_simple_intrinsic(cx, name);\n-    let llval = match name {\n-        _ if simple.is_some() => {\n-            bx.call(simple.unwrap(),\n-                    &args.iter().map(|arg| arg.immediate()).collect::<Vec<_>>(),\n-                    None)\n-        }\n-        \"unreachable\" => {\n-            return;\n-        },\n-        \"likely\" => {\n-            let expect = cx.get_intrinsic(&(\"llvm.expect.i1\"));\n-            bx.call(expect, &[args[0].immediate(), bx.cx().const_bool(true)], None)\n-        }\n-        \"unlikely\" => {\n-            let expect = cx.get_intrinsic(&(\"llvm.expect.i1\"));\n-            bx.call(expect, &[args[0].immediate(), bx.cx().const_bool(false)], None)\n-        }\n-        \"try\" => {\n-            try_intrinsic(bx, cx,\n-                          args[0].immediate(),\n-                          args[1].immediate(),\n-                          args[2].immediate(),\n-                          llresult);\n-            return;\n-        }\n-        \"breakpoint\" => {\n-            let llfn = cx.get_intrinsic(&(\"llvm.debugtrap\"));\n-            bx.call(llfn, &[], None)\n-        }\n-        \"size_of\" => {\n-            let tp_ty = substs.type_at(0);\n-            cx.const_usize(cx.size_of(tp_ty).bytes())\n-        }\n-        \"size_of_val\" => {\n-            let tp_ty = substs.type_at(0);\n-            if let OperandValue::Pair(_, meta) = args[0].val {\n-                let (llsize, _) =\n-                    glue::size_and_align_of_dst(bx, tp_ty, Some(meta));\n-                llsize\n-            } else {\n+        let sig = callee_ty.fn_sig(tcx);\n+        let sig = tcx.normalize_erasing_late_bound_regions(ty::ParamEnv::reveal_all(), &sig);\n+        let arg_tys = sig.inputs();\n+        let ret_ty = sig.output();\n+        let name = &*tcx.item_name(def_id).as_str();\n+\n+        let llret_ty = cx.layout_of(ret_ty).llvm_type(cx);\n+        let result = PlaceRef::new_sized(llresult, fn_ty.ret.layout, fn_ty.ret.layout.align);\n+\n+        let simple = get_simple_intrinsic(cx, name);\n+        let llval = match name {\n+            _ if simple.is_some() => {\n+                self.call(simple.unwrap(),\n+                        &args.iter().map(|arg| arg.immediate()).collect::<Vec<_>>(),\n+                        None)\n+            }\n+            \"unreachable\" => {\n+                return;\n+            },\n+            \"likely\" => {\n+                let expect = cx.get_intrinsic(&(\"llvm.expect.i1\"));\n+                self.call(expect, &[args[0].immediate(), cx.const_bool(true)], None)\n+            }\n+            \"unlikely\" => {\n+                let expect = cx.get_intrinsic(&(\"llvm.expect.i1\"));\n+                self.call(expect, &[args[0].immediate(), cx.const_bool(false)], None)\n+            }\n+            \"try\" => {\n+                try_intrinsic(self, cx,\n+                              args[0].immediate(),\n+                              args[1].immediate(),\n+                              args[2].immediate(),\n+                              llresult);\n+                return;\n+            }\n+            \"breakpoint\" => {\n+                let llfn = cx.get_intrinsic(&(\"llvm.debugtrap\"));\n+                self.call(llfn, &[], None)\n+            }\n+            \"size_of\" => {\n+                let tp_ty = substs.type_at(0);\n                 cx.const_usize(cx.size_of(tp_ty).bytes())\n             }\n-        }\n-        \"min_align_of\" => {\n-            let tp_ty = substs.type_at(0);\n-            cx.const_usize(cx.align_of(tp_ty).abi())\n-        }\n-        \"min_align_of_val\" => {\n-            let tp_ty = substs.type_at(0);\n-            if let OperandValue::Pair(_, meta) = args[0].val {\n-                let (_, llalign) =\n-                    glue::size_and_align_of_dst(bx, tp_ty, Some(meta));\n-                llalign\n-            } else {\n+            \"size_of_val\" => {\n+                let tp_ty = substs.type_at(0);\n+                if let OperandValue::Pair(_, meta) = args[0].val {\n+                    let (llsize, _) =\n+                        glue::size_and_align_of_dst(&self, tp_ty, Some(meta));\n+                    llsize\n+                } else {\n+                    cx.const_usize(cx.size_of(tp_ty).bytes())\n+                }\n+            }\n+            \"min_align_of\" => {\n+                let tp_ty = substs.type_at(0);\n                 cx.const_usize(cx.align_of(tp_ty).abi())\n             }\n-        }\n-        \"pref_align_of\" => {\n-            let tp_ty = substs.type_at(0);\n-            cx.const_usize(cx.align_of(tp_ty).pref())\n-        }\n-        \"type_name\" => {\n-            let tp_ty = substs.type_at(0);\n-            let ty_name = Symbol::intern(&tp_ty.to_string()).as_str();\n-            cx.const_str_slice(ty_name)\n-        }\n-        \"type_id\" => {\n-            cx.const_u64(cx.tcx.type_id_hash(substs.type_at(0)))\n-        }\n-        \"init\" => {\n-            let ty = substs.type_at(0);\n-            if !cx.layout_of(ty).is_zst() {\n-                // Just zero out the stack slot.\n-                // If we store a zero constant, LLVM will drown in vreg allocation for large data\n-                // structures, and the generated code will be awful. (A telltale sign of this is\n-                // large quantities of `mov [byte ptr foo],0` in the generated code.)\n-                memset_intrinsic(\n-                    bx,\n-                    false,\n-                    ty,\n-                    llresult,\n-                    cx.const_u8(0),\n-                    cx.const_usize(1)\n-                );\n+            \"min_align_of_val\" => {\n+                let tp_ty = substs.type_at(0);\n+                if let OperandValue::Pair(_, meta) = args[0].val {\n+                    let (_, llalign) =\n+                        glue::size_and_align_of_dst(&self, tp_ty, Some(meta));\n+                    llalign\n+                } else {\n+                    cx.const_usize(cx.align_of(tp_ty).abi())\n+                }\n             }\n-            return;\n-        }\n-        // Effectively no-ops\n-        \"uninit\" | \"forget\" => {\n-            return;\n-        }\n-        \"needs_drop\" => {\n-            let tp_ty = substs.type_at(0);\n+            \"pref_align_of\" => {\n+                let tp_ty = substs.type_at(0);\n+                cx.const_usize(cx.align_of(tp_ty).pref())\n+            }\n+            \"type_name\" => {\n+                let tp_ty = substs.type_at(0);\n+                let ty_name = Symbol::intern(&tp_ty.to_string()).as_str();\n+                cx.const_str_slice(ty_name)\n+            }\n+            \"type_id\" => {\n+                cx.const_u64(cx.tcx.type_id_hash(substs.type_at(0)))\n+            }\n+            \"init\" => {\n+                let ty = substs.type_at(0);\n+                if !cx.layout_of(ty).is_zst() {\n+                    // Just zero out the stack slot.\n+                    // If we store a zero constant, LLVM will drown in vreg allocation for large\n+                    // data structures, and the generated code will be awful. (A telltale sign of\n+                    // this is large quantities of `mov [byte ptr foo],0` in the generated code.)\n+                    memset_intrinsic(\n+                        &self,\n+                        false,\n+                        ty,\n+                        llresult,\n+                        cx.const_u8(0),\n+                        cx.const_usize(1)\n+                    );\n+                }\n+                return;\n+            }\n+            // Effectively no-ops\n+            \"uninit\" | \"forget\" => {\n+                return;\n+            }\n+            \"needs_drop\" => {\n+                let tp_ty = substs.type_at(0);\n \n-            cx.const_bool(bx.cx().type_needs_drop(tp_ty))\n-        }\n-        \"offset\" => {\n-            let ptr = args[0].immediate();\n-            let offset = args[1].immediate();\n-            bx.inbounds_gep(ptr, &[offset])\n-        }\n-        \"arith_offset\" => {\n-            let ptr = args[0].immediate();\n-            let offset = args[1].immediate();\n-            bx.gep(ptr, &[offset])\n-        }\n+                cx.const_bool(cx.type_needs_drop(tp_ty))\n+            }\n+            \"offset\" => {\n+                let ptr = args[0].immediate();\n+                let offset = args[1].immediate();\n+                self.inbounds_gep(ptr, &[offset])\n+            }\n+            \"arith_offset\" => {\n+                let ptr = args[0].immediate();\n+                let offset = args[1].immediate();\n+                self.gep(ptr, &[offset])\n+            }\n \n-        \"copy_nonoverlapping\" => {\n-            copy_intrinsic(bx, false, false, substs.type_at(0),\n-                           args[1].immediate(), args[0].immediate(), args[2].immediate());\n-            return;\n-        }\n-        \"copy\" => {\n-            copy_intrinsic(bx, true, false, substs.type_at(0),\n-                           args[1].immediate(), args[0].immediate(), args[2].immediate());\n-            return;\n-        }\n-        \"write_bytes\" => {\n-            memset_intrinsic(bx, false, substs.type_at(0),\n-                             args[0].immediate(), args[1].immediate(), args[2].immediate());\n-            return;\n-        }\n+            \"copy_nonoverlapping\" => {\n+                copy_intrinsic(&self, false, false, substs.type_at(0),\n+                               args[1].immediate(), args[0].immediate(), args[2].immediate());\n+                return;\n+            }\n+            \"copy\" => {\n+                copy_intrinsic(&self, true, false, substs.type_at(0),\n+                               args[1].immediate(), args[0].immediate(), args[2].immediate());\n+                return;\n+            }\n+            \"write_bytes\" => {\n+                memset_intrinsic(&self, false, substs.type_at(0),\n+                                 args[0].immediate(), args[1].immediate(), args[2].immediate());\n+                return;\n+            }\n \n-        \"volatile_copy_nonoverlapping_memory\" => {\n-            copy_intrinsic(bx, false, true, substs.type_at(0),\n-                           args[0].immediate(), args[1].immediate(), args[2].immediate());\n-            return;\n-        }\n-        \"volatile_copy_memory\" => {\n-            copy_intrinsic(bx, true, true, substs.type_at(0),\n-                           args[0].immediate(), args[1].immediate(), args[2].immediate());\n-            return;\n-        }\n-        \"volatile_set_memory\" => {\n-            memset_intrinsic(bx, true, substs.type_at(0),\n-                             args[0].immediate(), args[1].immediate(), args[2].immediate());\n-            return;\n-        }\n-        \"volatile_load\" | \"unaligned_volatile_load\" => {\n-            let tp_ty = substs.type_at(0);\n-            let mut ptr = args[0].immediate();\n-            if let PassMode::Cast(ty) = fn_ty.ret.mode {\n-                ptr = bx.pointercast(ptr, bx.cx().type_ptr_to(ty.llvm_type(cx)));\n+            \"volatile_copy_nonoverlapping_memory\" => {\n+                copy_intrinsic(&self, false, true, substs.type_at(0),\n+                               args[0].immediate(), args[1].immediate(), args[2].immediate());\n+                return;\n             }\n-            let load = bx.volatile_load(ptr);\n-            let align = if name == \"unaligned_volatile_load\" {\n-                1\n-            } else {\n-                cx.align_of(tp_ty).abi() as u32\n-            };\n-            unsafe {\n-                llvm::LLVMSetAlignment(load, align);\n+            \"volatile_copy_memory\" => {\n+                copy_intrinsic(&self, true, true, substs.type_at(0),\n+                               args[0].immediate(), args[1].immediate(), args[2].immediate());\n+                return;\n             }\n-            to_immediate(bx, load, cx.layout_of(tp_ty))\n-        },\n-        \"volatile_store\" => {\n-            let dst = args[0].deref(bx.cx());\n-            args[1].val.volatile_store(bx, dst);\n-            return;\n-        },\n-        \"unaligned_volatile_store\" => {\n-            let dst = args[0].deref(bx.cx());\n-            args[1].val.unaligned_volatile_store(bx, dst);\n-            return;\n-        },\n-        \"prefetch_read_data\" | \"prefetch_write_data\" |\n-        \"prefetch_read_instruction\" | \"prefetch_write_instruction\" => {\n-            let expect = cx.get_intrinsic(&(\"llvm.prefetch\"));\n-            let (rw, cache_type) = match name {\n-                \"prefetch_read_data\" => (0, 1),\n-                \"prefetch_write_data\" => (1, 1),\n-                \"prefetch_read_instruction\" => (0, 0),\n-                \"prefetch_write_instruction\" => (1, 0),\n-                _ => bug!()\n-            };\n-            bx.call(expect, &[\n-                args[0].immediate(),\n-                cx.const_i32(rw),\n-                args[1].immediate(),\n-                cx.const_i32(cache_type)\n-            ], None)\n-        },\n-        \"ctlz\" | \"ctlz_nonzero\" | \"cttz\" | \"cttz_nonzero\" | \"ctpop\" | \"bswap\" |\n-        \"bitreverse\" | \"add_with_overflow\" | \"sub_with_overflow\" |\n-        \"mul_with_overflow\" | \"overflowing_add\" | \"overflowing_sub\" | \"overflowing_mul\" |\n-        \"unchecked_div\" | \"unchecked_rem\" | \"unchecked_shl\" | \"unchecked_shr\" | \"exact_div\" |\n-        \"rotate_left\" | \"rotate_right\" => {\n-            let ty = arg_tys[0];\n-            match int_type_width_signed(ty, cx) {\n-                Some((width, signed)) =>\n-                    match name {\n-                        \"ctlz\" | \"cttz\" => {\n-                            let y = cx.const_bool(false);\n-                            let llfn = cx.get_intrinsic(&format!(\"llvm.{}.i{}\", name, width));\n-                            bx.call(llfn, &[args[0].immediate(), y], None)\n-                        }\n-                        \"ctlz_nonzero\" | \"cttz_nonzero\" => {\n-                            let y = cx.const_bool(true);\n-                            let llvm_name = &format!(\"llvm.{}.i{}\", &name[..4], width);\n-                            let llfn = cx.get_intrinsic(llvm_name);\n-                            bx.call(llfn, &[args[0].immediate(), y], None)\n-                        }\n-                        \"ctpop\" => bx.call(cx.get_intrinsic(&format!(\"llvm.ctpop.i{}\", width)),\n-                                        &[args[0].immediate()], None),\n-                        \"bswap\" => {\n-                            if width == 8 {\n-                                args[0].immediate() // byte swap a u8/i8 is just a no-op\n-                            } else {\n-                                bx.call(cx.get_intrinsic(&format!(\"llvm.bswap.i{}\", width)),\n-                                        &[args[0].immediate()], None)\n+            \"volatile_set_memory\" => {\n+                memset_intrinsic(&self, true, substs.type_at(0),\n+                                 args[0].immediate(), args[1].immediate(), args[2].immediate());\n+                return;\n+            }\n+            \"volatile_load\" | \"unaligned_volatile_load\" => {\n+                let tp_ty = substs.type_at(0);\n+                let mut ptr = args[0].immediate();\n+                if let PassMode::Cast(ty) = fn_ty.ret.mode {\n+                    ptr = self.pointercast(ptr, cx.type_ptr_to(ty.llvm_type(cx)));\n+                }\n+                let load = self.volatile_load(ptr);\n+                let align = if name == \"unaligned_volatile_load\" {\n+                    1\n+                } else {\n+                    cx.align_of(tp_ty).abi() as u32\n+                };\n+                unsafe {\n+                    llvm::LLVMSetAlignment(load, align);\n+                }\n+                to_immediate(self, load, cx.layout_of(tp_ty))\n+            },\n+            \"volatile_store\" => {\n+                let dst = args[0].deref(cx);\n+                args[1].val.volatile_store(&self, dst);\n+                return;\n+            },\n+            \"unaligned_volatile_store\" => {\n+                let dst = args[0].deref(cx);\n+                args[1].val.unaligned_volatile_store(&self, dst);\n+                return;\n+            },\n+            \"prefetch_read_data\" | \"prefetch_write_data\" |\n+            \"prefetch_read_instruction\" | \"prefetch_write_instruction\" => {\n+                let expect = cx.get_intrinsic(&(\"llvm.prefetch\"));\n+                let (rw, cache_type) = match name {\n+                    \"prefetch_read_data\" => (0, 1),\n+                    \"prefetch_write_data\" => (1, 1),\n+                    \"prefetch_read_instruction\" => (0, 0),\n+                    \"prefetch_write_instruction\" => (1, 0),\n+                    _ => bug!()\n+                };\n+                self.call(expect, &[\n+                    args[0].immediate(),\n+                    cx.const_i32(rw),\n+                    args[1].immediate(),\n+                    cx.const_i32(cache_type)\n+                ], None)\n+            },\n+            \"ctlz\" | \"ctlz_nonzero\" | \"cttz\" | \"cttz_nonzero\" | \"ctpop\" | \"bswap\" |\n+            \"bitreverse\" | \"add_with_overflow\" | \"sub_with_overflow\" |\n+            \"mul_with_overflow\" | \"overflowing_add\" | \"overflowing_sub\" | \"overflowing_mul\" |\n+            \"unchecked_div\" | \"unchecked_rem\" | \"unchecked_shl\" | \"unchecked_shr\" | \"exact_div\" |\n+            \"rotate_left\" | \"rotate_right\" => {\n+                let ty = arg_tys[0];\n+                match int_type_width_signed(ty, cx) {\n+                    Some((width, signed)) =>\n+                        match name {\n+                            \"ctlz\" | \"cttz\" => {\n+                                let y = cx.const_bool(false);\n+                                let llfn = cx.get_intrinsic(&format!(\"llvm.{}.i{}\", name, width));\n+                                self.call(llfn, &[args[0].immediate(), y], None)\n                             }\n-                        }\n-                        \"bitreverse\" => {\n-                            bx.call(cx.get_intrinsic(&format!(\"llvm.bitreverse.i{}\", width)),\n-                                &[args[0].immediate()], None)\n-                        }\n-                        \"add_with_overflow\" | \"sub_with_overflow\" | \"mul_with_overflow\" => {\n-                            let intrinsic = format!(\"llvm.{}{}.with.overflow.i{}\",\n-                                                    if signed { 's' } else { 'u' },\n-                                                    &name[..3], width);\n-                            let llfn = bx.cx().get_intrinsic(&intrinsic);\n-\n-                            // Convert `i1` to a `bool`, and write it to the out parameter\n-                            let pair = bx.call(llfn, &[\n-                                args[0].immediate(),\n-                                args[1].immediate()\n-                            ], None);\n-                            let val = bx.extract_value(pair, 0);\n-                            let overflow = bx.zext(bx.extract_value(pair, 1), cx.type_bool());\n-\n-                            let dest = result.project_field(bx, 0);\n-                            bx.store(val, dest.llval, dest.align);\n-                            let dest = result.project_field(bx, 1);\n-                            bx.store(overflow, dest.llval, dest.align);\n-\n-                            return;\n-                        },\n-                        \"overflowing_add\" => bx.add(args[0].immediate(), args[1].immediate()),\n-                        \"overflowing_sub\" => bx.sub(args[0].immediate(), args[1].immediate()),\n-                        \"overflowing_mul\" => bx.mul(args[0].immediate(), args[1].immediate()),\n-                        \"exact_div\" =>\n-                            if signed {\n-                                bx.exactsdiv(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                bx.exactudiv(args[0].immediate(), args[1].immediate())\n-                            },\n-                        \"unchecked_div\" =>\n-                            if signed {\n-                                bx.sdiv(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                bx.udiv(args[0].immediate(), args[1].immediate())\n-                            },\n-                        \"unchecked_rem\" =>\n-                            if signed {\n-                                bx.srem(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                bx.urem(args[0].immediate(), args[1].immediate())\n-                            },\n-                        \"unchecked_shl\" => bx.shl(args[0].immediate(), args[1].immediate()),\n-                        \"unchecked_shr\" =>\n-                            if signed {\n-                                bx.ashr(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                bx.lshr(args[0].immediate(), args[1].immediate())\n-                            },\n-                        \"rotate_left\" | \"rotate_right\" => {\n-                            let is_left = name == \"rotate_left\";\n-                            let val = args[0].immediate();\n-                            let raw_shift = args[1].immediate();\n-                            if llvm_util::get_major_version() >= 7 {\n-                                // rotate = funnel shift with first two args the same\n-                                let llvm_name = &format!(\"llvm.fsh{}.i{}\",\n-                                                         if is_left { 'l' } else { 'r' }, width);\n+                            \"ctlz_nonzero\" | \"cttz_nonzero\" => {\n+                                let y = cx.const_bool(true);\n+                                let llvm_name = &format!(\"llvm.{}.i{}\", &name[..4], width);\n                                 let llfn = cx.get_intrinsic(llvm_name);\n-                                bx.call(llfn, &[val, val, raw_shift], None)\n-                            } else {\n-                                // rotate_left: (X << (S % BW)) | (X >> ((BW - S) % BW))\n-                                // rotate_right: (X << ((BW - S) % BW)) | (X >> (S % BW))\n-                                let width = cx.const_uint(cx.type_ix(width), width);\n-                                let shift = bx.urem(raw_shift, width);\n-                                let inv_shift = bx.urem(bx.sub(width, raw_shift), width);\n-                                let shift1 = bx.shl(val, if is_left { shift } else { inv_shift });\n-                                let shift2 = bx.lshr(val, if !is_left { shift } else { inv_shift });\n-                                bx.or(shift1, shift2)\n+                                self.call(llfn, &[args[0].immediate(), y], None)\n                             }\n+                            \"ctpop\" => self.call(\n+                                cx.get_intrinsic(&format!(\"llvm.ctpop.i{}\", width)),\n+                                &[args[0].immediate()],\n+                                None\n+                            ),\n+                            \"bswap\" => {\n+                                if width == 8 {\n+                                    args[0].immediate() // byte swap a u8/i8 is just a no-op\n+                                } else {\n+                                    self.call(cx.get_intrinsic(&format!(\"llvm.bswap.i{}\", width)),\n+                                            &[args[0].immediate()], None)\n+                                }\n+                            }\n+                            \"bitreverse\" => {\n+                                self.call(cx.get_intrinsic(&format!(\"llvm.bitreverse.i{}\", width)),\n+                                    &[args[0].immediate()], None)\n+                            }\n+                            \"add_with_overflow\" | \"sub_with_overflow\" | \"mul_with_overflow\" => {\n+                                let intrinsic = format!(\"llvm.{}{}.with.overflow.i{}\",\n+                                                        if signed { 's' } else { 'u' },\n+                                                        &name[..3], width);\n+                                let llfn = cx.get_intrinsic(&intrinsic);\n+\n+                                // Convert `i1` to a `bool`, and write it to the out parameter\n+                                let pair = self.call(llfn, &[\n+                                    args[0].immediate(),\n+                                    args[1].immediate()\n+                                ], None);\n+                                let val = self.extract_value(pair, 0);\n+                                let overflow = self.zext(\n+                                    self.extract_value(pair, 1),\n+                                    cx.type_bool()\n+                                );\n+\n+                                let dest = result.project_field(&self, 0);\n+                                self.store(val, dest.llval, dest.align);\n+                                let dest = result.project_field(&self, 1);\n+                                self.store(overflow, dest.llval, dest.align);\n+\n+                                return;\n+                            },\n+                            \"overflowing_add\" => self.add(args[0].immediate(), args[1].immediate()),\n+                            \"overflowing_sub\" => self.sub(args[0].immediate(), args[1].immediate()),\n+                            \"overflowing_mul\" => self.mul(args[0].immediate(), args[1].immediate()),\n+                            \"exact_div\" =>\n+                                if signed {\n+                                    self.exactsdiv(args[0].immediate(), args[1].immediate())\n+                                } else {\n+                                    self.exactudiv(args[0].immediate(), args[1].immediate())\n+                                },\n+                            \"unchecked_div\" =>\n+                                if signed {\n+                                    self.sdiv(args[0].immediate(), args[1].immediate())\n+                                } else {\n+                                    self.udiv(args[0].immediate(), args[1].immediate())\n+                                },\n+                            \"unchecked_rem\" =>\n+                                if signed {\n+                                    self.srem(args[0].immediate(), args[1].immediate())\n+                                } else {\n+                                    self.urem(args[0].immediate(), args[1].immediate())\n+                                },\n+                            \"unchecked_shl\" => self.shl(args[0].immediate(), args[1].immediate()),\n+                            \"unchecked_shr\" =>\n+                                if signed {\n+                                    self.ashr(args[0].immediate(), args[1].immediate())\n+                                } else {\n+                                    self.lshr(args[0].immediate(), args[1].immediate())\n+                                },\n+                            \"rotate_left\" | \"rotate_right\" => {\n+                                let is_left = name == \"rotate_left\";\n+                                let val = args[0].immediate();\n+                                let raw_shift = args[1].immediate();\n+                                if llvm_util::get_major_version() >= 7 {\n+                                    // rotate = funnel shift with first two args the same\n+                                    let llvm_name = &format!(\"llvm.fsh{}.i{}\",\n+                                                            if is_left { 'l' } else { 'r' }, width);\n+                                    let llfn = cx.get_intrinsic(llvm_name);\n+                                    self.call(llfn, &[val, val, raw_shift], None)\n+                                } else {\n+                                    // rotate_left: (X << (S % BW)) | (X >> ((BW - S) % BW))\n+                                    // rotate_right: (X << ((BW - S) % BW)) | (X >> (S % BW))\n+                                    let width = cx.const_uint(cx.type_ix(width), width);\n+                                    let shift = self.urem(raw_shift, width);\n+                                    let inv_shift = self.urem(self.sub(width, raw_shift), width);\n+                                    let shift1 = self.shl(\n+                                        val,\n+                                        if is_left { shift } else { inv_shift },\n+                                    );\n+                                    let shift2 = self.lshr(\n+                                        val,\n+                                        if !is_left { shift } else { inv_shift },\n+                                    );\n+                                    self.or(shift1, shift2)\n+                                }\n+                            },\n+                            _ => bug!(),\n                         },\n-                        _ => bug!(),\n-                    },\n-                None => {\n-                    span_invalid_monomorphization_error(\n-                        tcx.sess, span,\n-                        &format!(\"invalid monomorphization of `{}` intrinsic: \\\n-                                  expected basic integer type, found `{}`\", name, ty));\n-                    return;\n+                    None => {\n+                        span_invalid_monomorphization_error(\n+                            tcx.sess, span,\n+                            &format!(\"invalid monomorphization of `{}` intrinsic: \\\n+                                      expected basic integer type, found `{}`\", name, ty));\n+                        return;\n+                    }\n                 }\n-            }\n-        },\n-        \"fadd_fast\" | \"fsub_fast\" | \"fmul_fast\" | \"fdiv_fast\" | \"frem_fast\" => {\n-            let sty = &arg_tys[0].sty;\n-            match float_type_width(sty) {\n-                Some(_width) =>\n-                    match name {\n-                        \"fadd_fast\" => bx.fadd_fast(args[0].immediate(), args[1].immediate()),\n-                        \"fsub_fast\" => bx.fsub_fast(args[0].immediate(), args[1].immediate()),\n-                        \"fmul_fast\" => bx.fmul_fast(args[0].immediate(), args[1].immediate()),\n-                        \"fdiv_fast\" => bx.fdiv_fast(args[0].immediate(), args[1].immediate()),\n-                        \"frem_fast\" => bx.frem_fast(args[0].immediate(), args[1].immediate()),\n-                        _ => bug!(),\n-                    },\n-                None => {\n-                    span_invalid_monomorphization_error(\n-                        tcx.sess, span,\n-                        &format!(\"invalid monomorphization of `{}` intrinsic: \\\n-                                  expected basic float type, found `{}`\", name, sty));\n-                    return;\n+\n+            },\n+            \"fadd_fast\" | \"fsub_fast\" | \"fmul_fast\" | \"fdiv_fast\" | \"frem_fast\" => {\n+                let sty = &arg_tys[0].sty;\n+                match float_type_width(sty) {\n+                    Some(_width) =>\n+                        match name {\n+                            \"fadd_fast\" => self.fadd_fast(args[0].immediate(), args[1].immediate()),\n+                            \"fsub_fast\" => self.fsub_fast(args[0].immediate(), args[1].immediate()),\n+                            \"fmul_fast\" => self.fmul_fast(args[0].immediate(), args[1].immediate()),\n+                            \"fdiv_fast\" => self.fdiv_fast(args[0].immediate(), args[1].immediate()),\n+                            \"frem_fast\" => self.frem_fast(args[0].immediate(), args[1].immediate()),\n+                            _ => bug!(),\n+                        },\n+                    None => {\n+                        span_invalid_monomorphization_error(\n+                            tcx.sess, span,\n+                            &format!(\"invalid monomorphization of `{}` intrinsic: \\\n+                                      expected basic float type, found `{}`\", name, sty));\n+                        return;\n+                    }\n                 }\n-            }\n \n-        },\n+            },\n \n-        \"discriminant_value\" => {\n-            args[0].deref(bx.cx()).codegen_get_discr(bx, ret_ty)\n-        }\n+            \"discriminant_value\" => {\n+                args[0].deref(cx).codegen_get_discr(&self, ret_ty)\n+            }\n \n-        name if name.starts_with(\"simd_\") => {\n-            match generic_simd_intrinsic(bx, name,\n-                                         callee_ty,\n-                                         args,\n-                                         ret_ty, llret_ty,\n-                                         span) {\n-                Ok(llval) => llval,\n-                Err(()) => return\n+            name if name.starts_with(\"simd_\") => {\n+                match generic_simd_intrinsic(&self, name,\n+                                             callee_ty,\n+                                             args,\n+                                             ret_ty, llret_ty,\n+                                             span) {\n+                    Ok(llval) => llval,\n+                    Err(()) => return\n+                }\n             }\n-        }\n-        // This requires that atomic intrinsics follow a specific naming pattern:\n-        // \"atomic_<operation>[_<ordering>]\", and no ordering means SeqCst\n-        name if name.starts_with(\"atomic_\") => {\n-            use self::AtomicOrdering::*;\n-\n-            let split: Vec<&str> = name.split('_').collect();\n-\n-            let is_cxchg = split[1] == \"cxchg\" || split[1] == \"cxchgweak\";\n-            let (order, failorder) = match split.len() {\n-                2 => (SequentiallyConsistent, SequentiallyConsistent),\n-                3 => match split[2] {\n-                    \"unordered\" => (Unordered, Unordered),\n-                    \"relaxed\" => (Monotonic, Monotonic),\n-                    \"acq\"     => (Acquire, Acquire),\n-                    \"rel\"     => (Release, Monotonic),\n-                    \"acqrel\"  => (AcquireRelease, Acquire),\n-                    \"failrelaxed\" if is_cxchg =>\n-                        (SequentiallyConsistent, Monotonic),\n-                    \"failacq\" if is_cxchg =>\n-                        (SequentiallyConsistent, Acquire),\n-                    _ => cx.sess().fatal(\"unknown ordering in atomic intrinsic\")\n-                },\n-                4 => match (split[2], split[3]) {\n-                    (\"acq\", \"failrelaxed\") if is_cxchg =>\n-                        (Acquire, Monotonic),\n-                    (\"acqrel\", \"failrelaxed\") if is_cxchg =>\n-                        (AcquireRelease, Monotonic),\n-                    _ => cx.sess().fatal(\"unknown ordering in atomic intrinsic\")\n-                },\n-                _ => cx.sess().fatal(\"Atomic intrinsic not in correct format\"),\n-            };\n+            // This requires that atomic intrinsics follow a specific naming pattern:\n+            // \"atomic_<operation>[_<ordering>]\", and no ordering means SeqCst\n+            name if name.starts_with(\"atomic_\") => {\n+                use self::AtomicOrdering::*;\n+\n+                let split: Vec<&str> = name.split('_').collect();\n+\n+                let is_cxchg = split[1] == \"cxchg\" || split[1] == \"cxchgweak\";\n+                let (order, failorder) = match split.len() {\n+                    2 => (SequentiallyConsistent, SequentiallyConsistent),\n+                    3 => match split[2] {\n+                        \"unordered\" => (Unordered, Unordered),\n+                        \"relaxed\" => (Monotonic, Monotonic),\n+                        \"acq\"     => (Acquire, Acquire),\n+                        \"rel\"     => (Release, Monotonic),\n+                        \"acqrel\"  => (AcquireRelease, Acquire),\n+                        \"failrelaxed\" if is_cxchg =>\n+                            (SequentiallyConsistent, Monotonic),\n+                        \"failacq\" if is_cxchg =>\n+                            (SequentiallyConsistent, Acquire),\n+                        _ => cx.sess().fatal(\"unknown ordering in atomic intrinsic\")\n+                    },\n+                    4 => match (split[2], split[3]) {\n+                        (\"acq\", \"failrelaxed\") if is_cxchg =>\n+                            (Acquire, Monotonic),\n+                        (\"acqrel\", \"failrelaxed\") if is_cxchg =>\n+                            (AcquireRelease, Monotonic),\n+                        _ => cx.sess().fatal(\"unknown ordering in atomic intrinsic\")\n+                    },\n+                    _ => cx.sess().fatal(\"Atomic intrinsic not in correct format\"),\n+                };\n \n-            let invalid_monomorphization = |ty| {\n-                span_invalid_monomorphization_error(tcx.sess, span,\n-                    &format!(\"invalid monomorphization of `{}` intrinsic: \\\n-                              expected basic integer type, found `{}`\", name, ty));\n-            };\n+                let invalid_monomorphization = |ty| {\n+                    span_invalid_monomorphization_error(tcx.sess, span,\n+                        &format!(\"invalid monomorphization of `{}` intrinsic: \\\n+                                  expected basic integer type, found `{}`\", name, ty));\n+                };\n \n-            match split[1] {\n-                \"cxchg\" | \"cxchgweak\" => {\n-                    let ty = substs.type_at(0);\n-                    if int_type_width_signed(ty, cx).is_some() {\n-                        let weak = split[1] == \"cxchgweak\";\n-                        let pair = bx.atomic_cmpxchg(\n-                            args[0].immediate(),\n-                            args[1].immediate(),\n-                            args[2].immediate(),\n-                            order,\n-                            failorder,\n-                            weak);\n-                        let val = bx.extract_value(pair, 0);\n-                        let success = bx.zext(bx.extract_value(pair, 1), bx.cx().type_bool());\n-\n-                        let dest = result.project_field(bx, 0);\n-                        bx.store(val, dest.llval, dest.align);\n-                        let dest = result.project_field(bx, 1);\n-                        bx.store(success, dest.llval, dest.align);\n-                        return;\n-                    } else {\n-                        return invalid_monomorphization(ty);\n+                match split[1] {\n+                    \"cxchg\" | \"cxchgweak\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, cx).is_some() {\n+                            let weak = split[1] == \"cxchgweak\";\n+                            let pair = self.atomic_cmpxchg(\n+                                args[0].immediate(),\n+                                args[1].immediate(),\n+                                args[2].immediate(),\n+                                order,\n+                                failorder,\n+                                weak);\n+                            let val = self.extract_value(pair, 0);\n+                            let success = self.zext(\n+                                self.extract_value(pair, 1),\n+                                cx.type_bool()\n+                            );\n+\n+                            let dest = result.project_field(&self, 0);\n+                            self.store(val, dest.llval, dest.align);\n+                            let dest = result.project_field(&self, 1);\n+                            self.store(success, dest.llval, dest.align);\n+                            return;\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n                     }\n-                }\n \n-                \"load\" => {\n-                    let ty = substs.type_at(0);\n-                    if int_type_width_signed(ty, cx).is_some() {\n-                        let size = cx.size_of(ty);\n-                        bx.atomic_load(args[0].immediate(), order, size)\n-                    } else {\n-                        return invalid_monomorphization(ty);\n+                    \"load\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, cx).is_some() {\n+                            let size = cx.size_of(ty);\n+                            self.atomic_load(args[0].immediate(), order, size)\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n+                    }\n+\n+                    \"store\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, cx).is_some() {\n+                            let size = cx.size_of(ty);\n+                            self.atomic_store(\n+                                args[1].immediate(),\n+                                args[0].immediate(),\n+                                order,\n+                                size\n+                            );\n+                            return;\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n                     }\n-                }\n \n-                \"store\" => {\n-                    let ty = substs.type_at(0);\n-                    if int_type_width_signed(ty, cx).is_some() {\n-                        let size = cx.size_of(ty);\n-                        bx.atomic_store(args[1].immediate(), args[0].immediate(), order, size);\n+                    \"fence\" => {\n+                        self.atomic_fence(order, SynchronizationScope::CrossThread);\n                         return;\n-                    } else {\n-                        return invalid_monomorphization(ty);\n                     }\n-                }\n \n-                \"fence\" => {\n-                    bx.atomic_fence(order, SynchronizationScope::CrossThread);\n-                    return;\n-                }\n+                    \"singlethreadfence\" => {\n+                        self.atomic_fence(order, SynchronizationScope::SingleThread);\n+                        return;\n+                    }\n \n-                \"singlethreadfence\" => {\n-                    bx.atomic_fence(order, SynchronizationScope::SingleThread);\n-                    return;\n-                }\n+                    // These are all AtomicRMW ops\n+                    op => {\n+                        let atom_op = match op {\n+                            \"xchg\"  => AtomicRmwBinOp::AtomicXchg,\n+                            \"xadd\"  => AtomicRmwBinOp::AtomicAdd,\n+                            \"xsub\"  => AtomicRmwBinOp::AtomicSub,\n+                            \"and\"   => AtomicRmwBinOp::AtomicAnd,\n+                            \"nand\"  => AtomicRmwBinOp::AtomicNand,\n+                            \"or\"    => AtomicRmwBinOp::AtomicOr,\n+                            \"xor\"   => AtomicRmwBinOp::AtomicXor,\n+                            \"max\"   => AtomicRmwBinOp::AtomicMax,\n+                            \"min\"   => AtomicRmwBinOp::AtomicMin,\n+                            \"umax\"  => AtomicRmwBinOp::AtomicUMax,\n+                            \"umin\"  => AtomicRmwBinOp::AtomicUMin,\n+                            _ => cx.sess().fatal(\"unknown atomic operation\")\n+                        };\n \n-                // These are all AtomicRMW ops\n-                op => {\n-                    let atom_op = match op {\n-                        \"xchg\"  => AtomicRmwBinOp::AtomicXchg,\n-                        \"xadd\"  => AtomicRmwBinOp::AtomicAdd,\n-                        \"xsub\"  => AtomicRmwBinOp::AtomicSub,\n-                        \"and\"   => AtomicRmwBinOp::AtomicAnd,\n-                        \"nand\"  => AtomicRmwBinOp::AtomicNand,\n-                        \"or\"    => AtomicRmwBinOp::AtomicOr,\n-                        \"xor\"   => AtomicRmwBinOp::AtomicXor,\n-                        \"max\"   => AtomicRmwBinOp::AtomicMax,\n-                        \"min\"   => AtomicRmwBinOp::AtomicMin,\n-                        \"umax\"  => AtomicRmwBinOp::AtomicUMax,\n-                        \"umin\"  => AtomicRmwBinOp::AtomicUMin,\n-                        _ => cx.sess().fatal(\"unknown atomic operation\")\n-                    };\n-\n-                    let ty = substs.type_at(0);\n-                    if int_type_width_signed(ty, cx).is_some() {\n-                        bx.atomic_rmw(atom_op, args[0].immediate(), args[1].immediate(), order)\n-                    } else {\n-                        return invalid_monomorphization(ty);\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, cx).is_some() {\n+                            self.atomic_rmw(\n+                                atom_op,\n+                                args[0].immediate(),\n+                                args[1].immediate(),\n+                                order\n+                            )\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n                     }\n                 }\n             }\n-        }\n-\n-        \"nontemporal_store\" => {\n-            let dst = args[0].deref(bx.cx());\n-            args[1].val.nontemporal_store(bx, dst);\n-            return;\n-        }\n \n-        _ => {\n-            let intr = Intrinsic::find(&name).unwrap_or_else(||\n-                bug!(\"unknown intrinsic '{}'\", name));\n-\n-            fn one<T>(x: Vec<T>) -> T {\n-                assert_eq!(x.len(), 1);\n-                x.into_iter().next().unwrap()\n+            \"nontemporal_store\" => {\n+                let dst = args[0].deref(cx);\n+                args[1].val.nontemporal_store(&self, dst);\n+                return;\n             }\n-            fn ty_to_type(cx: &CodegenCx<'ll, '_>, t: &intrinsics::Type) -> Vec<&'ll Type> {\n-                use intrinsics::Type::*;\n-                match *t {\n-                    Void => vec![cx.type_void()],\n-                    Integer(_signed, _width, llvm_width) => {\n-                        vec![cx.type_ix( llvm_width as u64)]\n-                    }\n-                    Float(x) => {\n-                        match x {\n-                            32 => vec![cx.type_f32()],\n-                            64 => vec![cx.type_f64()],\n-                            _ => bug!()\n+\n+            _ => {\n+                let intr = match Intrinsic::find(&name) {\n+                    Some(intr) => intr,\n+                    None => bug!(\"unknown intrinsic '{}'\", name),\n+                };\n+                fn one<T>(x: Vec<T>) -> T {\n+                    assert_eq!(x.len(), 1);\n+                    x.into_iter().next().unwrap()\n+                }\n+                fn ty_to_type<'ll>(\n+                    cx: &CodegenCx<'ll, '_>,\n+                     t: &intrinsics::Type\n+                 ) -> Vec<&'ll Type> {\n+                    use intrinsics::Type::*;\n+                    match *t {\n+                        Void => vec![cx.type_void()],\n+                        Integer(_signed, _width, llvm_width) => {\n+                            vec![cx.type_ix( llvm_width as u64)]\n+                        }\n+                        Float(x) => {\n+                            match x {\n+                                32 => vec![cx.type_f32()],\n+                                64 => vec![cx.type_f64()],\n+                                _ => bug!()\n+                            }\n+                        }\n+                        Pointer(ref t, ref llvm_elem, _const) => {\n+                            let t = llvm_elem.as_ref().unwrap_or(t);\n+                            let elem = one(ty_to_type(cx, t));\n+                            vec![cx.type_ptr_to(elem)]\n+                        }\n+                        Vector(ref t, ref llvm_elem, length) => {\n+                            let t = llvm_elem.as_ref().unwrap_or(t);\n+                            let elem = one(ty_to_type(cx, t));\n+                            vec![cx.type_vector(elem, length as u64)]\n+                        }\n+                        Aggregate(false, ref contents) => {\n+                            let elems = contents.iter()\n+                                                .map(|t| one(ty_to_type(cx, t)))\n+                                                .collect::<Vec<_>>();\n+                            vec![cx.type_struct( &elems, false)]\n+                        }\n+                        Aggregate(true, ref contents) => {\n+                            contents.iter()\n+                                    .flat_map(|t| ty_to_type(cx, t))\n+                                    .collect()\n                         }\n-                    }\n-                    Pointer(ref t, ref llvm_elem, _const) => {\n-                        let t = llvm_elem.as_ref().unwrap_or(t);\n-                        let elem = one(ty_to_type(cx, t));\n-                        vec![cx.type_ptr_to(elem)]\n-                    }\n-                    Vector(ref t, ref llvm_elem, length) => {\n-                        let t = llvm_elem.as_ref().unwrap_or(t);\n-                        let elem = one(ty_to_type(cx, t));\n-                        vec![cx.type_vector(elem, length as u64)]\n-                    }\n-                    Aggregate(false, ref contents) => {\n-                        let elems = contents.iter()\n-                                            .map(|t| one(ty_to_type(cx, t)))\n-                                            .collect::<Vec<_>>();\n-                        vec![cx.type_struct( &elems, false)]\n-                    }\n-                    Aggregate(true, ref contents) => {\n-                        contents.iter()\n-                                .flat_map(|t| ty_to_type(cx, t))\n-                                .collect()\n                     }\n                 }\n-            }\n \n-            // This allows an argument list like `foo, (bar, baz),\n-            // qux` to be converted into `foo, bar, baz, qux`, integer\n-            // arguments to be truncated as needed and pointers to be\n-            // cast.\n-            fn modify_as_needed(\n-                bx: &Builder<'a, 'll, 'tcx>,\n-                t: &intrinsics::Type,\n-                arg: &OperandRef<'tcx, &'ll Value>,\n-            ) -> Vec<&'ll Value> {\n-                match *t {\n-                    intrinsics::Type::Aggregate(true, ref contents) => {\n-                        // We found a tuple that needs squishing! So\n-                        // run over the tuple and load each field.\n-                        //\n-                        // This assumes the type is \"simple\", i.e. no\n-                        // destructors, and the contents are SIMD\n-                        // etc.\n-                        assert!(!bx.cx().type_needs_drop(arg.layout.ty));\n-                        let (ptr, align) = match arg.val {\n-                            OperandValue::Ref(ptr, None, align) => (ptr, align),\n-                            _ => bug!()\n-                        };\n-                        let arg = PlaceRef::new_sized(ptr, arg.layout, align);\n-                        (0..contents.len()).map(|i| {\n-                            arg.project_field(bx, i).load(bx).immediate()\n-                        }).collect()\n-                    }\n-                    intrinsics::Type::Pointer(_, Some(ref llvm_elem), _) => {\n-                        let llvm_elem = one(ty_to_type(bx.cx(), llvm_elem));\n-                        vec![bx.pointercast(arg.immediate(), bx.cx().type_ptr_to(llvm_elem))]\n-                    }\n-                    intrinsics::Type::Vector(_, Some(ref llvm_elem), length) => {\n-                        let llvm_elem = one(ty_to_type(bx.cx(), llvm_elem));\n-                        vec![\n-                            bx.bitcast(arg.immediate(),\n-                            bx.cx().type_vector(llvm_elem, length as u64))\n-                        ]\n-                    }\n-                    intrinsics::Type::Integer(_, width, llvm_width) if width != llvm_width => {\n-                        // the LLVM intrinsic uses a smaller integer\n-                        // size than the C intrinsic's signature, so\n-                        // we have to trim it down here.\n-                        vec![bx.trunc(arg.immediate(), bx.cx().type_ix(llvm_width as u64))]\n+                // This allows an argument list like `foo, (bar, baz),\n+                // qux` to be converted into `foo, bar, baz, qux`, integer\n+                // arguments to be truncated as needed and pointers to be\n+                // cast.\n+                fn modify_as_needed<'ll, 'tcx>(\n+                    bx: &Builder<'_, 'll, 'tcx>,\n+                    t: &intrinsics::Type,\n+                    arg: &OperandRef<'tcx, &'ll Value>,\n+                ) -> Vec<&'ll Value> {\n+                    match *t {\n+                        intrinsics::Type::Aggregate(true, ref contents) => {\n+                            // We found a tuple that needs squishing! So\n+                            // run over the tuple and load each field.\n+                            //\n+                            // This assumes the type is \"simple\", i.e. no\n+                            // destructors, and the contents are SIMD\n+                            // etc.\n+                            assert!(!bx.cx().type_needs_drop(arg.layout.ty));\n+                            let (ptr, align) = match arg.val {\n+                                OperandValue::Ref(ptr, None, align) => (ptr, align),\n+                                _ => bug!()\n+                            };\n+                            let arg = PlaceRef::new_sized(ptr, arg.layout, align);\n+                            (0..contents.len()).map(|i| {\n+                                arg.project_field(bx, i).load(bx).immediate()\n+                            }).collect()\n+                        }\n+                        intrinsics::Type::Pointer(_, Some(ref llvm_elem), _) => {\n+                            let llvm_elem = one(ty_to_type(bx.cx(), llvm_elem));\n+                            vec![bx.pointercast(arg.immediate(), bx.cx().type_ptr_to(llvm_elem))]\n+                        }\n+                        intrinsics::Type::Vector(_, Some(ref llvm_elem), length) => {\n+                            let llvm_elem = one(ty_to_type(bx.cx(), llvm_elem));\n+                            vec![\n+                                bx.bitcast(arg.immediate(),\n+                                bx.cx().type_vector(llvm_elem, length as u64))\n+                            ]\n+                        }\n+                        intrinsics::Type::Integer(_, width, llvm_width) if width != llvm_width => {\n+                            // the LLVM intrinsic uses a smaller integer\n+                            // size than the C intrinsic's signature, so\n+                            // we have to trim it down here.\n+                            vec![bx.trunc(arg.immediate(), bx.cx().type_ix(llvm_width as u64))]\n+                        }\n+                        _ => vec![arg.immediate()],\n                     }\n-                    _ => vec![arg.immediate()],\n                 }\n-            }\n \n \n-            let inputs = intr.inputs.iter()\n-                                    .flat_map(|t| ty_to_type(cx, t))\n-                                    .collect::<Vec<_>>();\n+                let inputs = intr.inputs.iter()\n+                                        .flat_map(|t| ty_to_type(cx, t))\n+                                        .collect::<Vec<_>>();\n \n-            let outputs = one(ty_to_type(cx, &intr.output));\n+                let outputs = one(ty_to_type(cx, &intr.output));\n \n-            let llargs: Vec<_> = intr.inputs.iter().zip(args).flat_map(|(t, arg)| {\n-                modify_as_needed(bx, t, arg)\n-            }).collect();\n-            assert_eq!(inputs.len(), llargs.len());\n+                let llargs: Vec<_> = intr.inputs.iter().zip(args).flat_map(|(t, arg)| {\n+                    modify_as_needed(&self, t, arg)\n+                }).collect();\n+                assert_eq!(inputs.len(), llargs.len());\n \n-            let val = match intr.definition {\n-                intrinsics::IntrinsicDef::Named(name) => {\n-                    let f = declare::declare_cfn(cx,\n-                                                 name,\n-                                                 cx.type_func(&inputs, outputs));\n-                    bx.call(f, &llargs, None)\n-                }\n-            };\n+                let val = match intr.definition {\n+                    intrinsics::IntrinsicDef::Named(name) => {\n+                        let f = declare::declare_cfn(cx,\n+                                                     name,\n+                                                     cx.type_func(&inputs, outputs));\n+                        self.call(f, &llargs, None)\n+                    }\n+                };\n \n-            match *intr.output {\n-                intrinsics::Type::Aggregate(flatten, ref elems) => {\n-                    // the output is a tuple so we need to munge it properly\n-                    assert!(!flatten);\n+                match *intr.output {\n+                    intrinsics::Type::Aggregate(flatten, ref elems) => {\n+                        // the output is a tuple so we need to munge it properly\n+                        assert!(!flatten);\n \n-                    for i in 0..elems.len() {\n-                        let dest = result.project_field(bx, i);\n-                        let val = bx.extract_value(val, i as u64);\n-                        bx.store(val, dest.llval, dest.align);\n+                        for i in 0..elems.len() {\n+                            let dest = result.project_field(&self, i);\n+                            let val = self.extract_value(val, i as u64);\n+                            self.store(val, dest.llval, dest.align);\n+                        }\n+                        return;\n                     }\n-                    return;\n+                    _ => val,\n                 }\n-                _ => val,\n             }\n-        }\n-    };\n+        };\n \n-    if !fn_ty.ret.is_ignore() {\n-        if let PassMode::Cast(ty) = fn_ty.ret.mode {\n-            let ptr = bx.pointercast(result.llval, cx.type_ptr_to(ty.llvm_type(cx)));\n-            bx.store(llval, ptr, result.align);\n-        } else {\n-            OperandRef::from_immediate_or_packed_pair(bx, llval, result.layout)\n-                .val.store(bx, result);\n+        if !fn_ty.ret.is_ignore() {\n+            if let PassMode::Cast(ty) = fn_ty.ret.mode {\n+                let ptr = self.pointercast(result.llval, cx.type_ptr_to(ty.llvm_type(cx)));\n+                self.store(llval, ptr, result.align);\n+            } else {\n+                OperandRef::from_immediate_or_packed_pair(&self, llval, result.layout)\n+                    .val.store(&self, result);\n+            }\n         }\n     }\n }"}, {"sha": "7c7ad740e797c0b206356edda0d26e18cfd44814", "filename": "src/librustc_codegen_llvm/mir/block.rs", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Fblock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Fblock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fmir%2Fblock.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -25,10 +25,7 @@ use type_of::LayoutLlvmExt;\n use type_::Type;\n use value::Value;\n \n-use interfaces::{\n-    BuilderMethods, ConstMethods, BaseTypeMethods, DerivedTypeMethods, DerivedIntrinsicMethods,\n-    StaticMethods,\n-};\n+use interfaces::*;\n \n use syntax::symbol::Symbol;\n use syntax_pos::Pos;\n@@ -560,8 +557,6 @@ impl FunctionCx<'a, 'll, 'tcx, &'ll Value> {\n                 };\n \n                 if intrinsic.is_some() && intrinsic != Some(\"drop_in_place\") {\n-                    use intrinsic::codegen_intrinsic_call;\n-\n                     let dest = match ret_dest {\n                         _ if fn_ty.ret.is_indirect() => llargs[0],\n                         ReturnDest::Nothing => {\n@@ -628,8 +623,8 @@ impl FunctionCx<'a, 'll, 'tcx, &'ll Value> {\n \n \n                     let callee_ty = instance.as_ref().unwrap().ty(bx.cx().tcx);\n-                    codegen_intrinsic_call(&bx, callee_ty, &fn_ty, &args, dest,\n-                                           terminator.source_info.span);\n+                    &bx.codegen_intrinsic_call(callee_ty, &fn_ty, &args, dest,\n+                                               terminator.source_info.span);\n \n                     if let ReturnDest::IndirectOperand(dst, _) = ret_dest {\n                         self.store_return(&bx, ret_dest, &fn_ty.ret, dst.llval);"}, {"sha": "91f1b085affa8c1e9838a3e88ca2eb8b79724f68", "filename": "src/librustc_codegen_llvm/mir/operand.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Foperand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Foperand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fmir%2Foperand.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -20,7 +20,7 @@ use value::Value;\n use type_of::LayoutLlvmExt;\n use glue;\n \n-use interfaces::{BuilderMethods, ConstMethods, BaseTypeMethods, DerivedIntrinsicMethods};\n+use interfaces::{BuilderMethods, ConstMethods, BaseTypeMethods, IntrinsicDeclarationMethods};\n \n use std::fmt;\n "}, {"sha": "b6142d50bb76c3cb3563ed52f4bf8ac4268ba845", "filename": "src/librustc_codegen_llvm/mir/place.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Fplace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Fplace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fmir%2Fplace.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -21,10 +21,7 @@ use value::Value;\n use glue;\n use mir::constant::const_alloc_to_llvm;\n \n-use interfaces::{\n-    BuilderMethods, ConstMethods, BaseTypeMethods, DerivedTypeMethods, DerivedIntrinsicMethods,\n-    StaticMethods,\n-};\n+use interfaces::*;\n \n use super::{FunctionCx, LocalRef};\n use super::operand::{OperandRef, OperandValue};"}, {"sha": "c7e8e467f50799867e8d32e830c817f22bfadcc1", "filename": "src/librustc_codegen_llvm/mir/rvalue.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Frvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0a1c50955b35892643a4bcfce08e72d9297b5bca/src%2Flibrustc_codegen_llvm%2Fmir%2Frvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fmir%2Frvalue.rs?ref=0a1c50955b35892643a4bcfce08e72d9297b5bca", "patch": "@@ -25,7 +25,7 @@ use type_::Type;\n use type_of::LayoutLlvmExt;\n use value::Value;\n \n-use interfaces::{BuilderMethods, ConstMethods, BaseTypeMethods, DerivedIntrinsicMethods};\n+use interfaces::{BuilderMethods, ConstMethods, BaseTypeMethods, IntrinsicDeclarationMethods};\n \n use super::{FunctionCx, LocalRef};\n use super::operand::{OperandRef, OperandValue};"}]}