{"sha": "3e9bed92da499d7905232d47d54300134fca13b5", "node_id": "MDY6Q29tbWl0NzI0NzEyOjNlOWJlZDkyZGE0OTlkNzkwNTIzMmQ0N2Q1NDMwMDEzNGZjYTEzYjU=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2016-08-11T23:02:39Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2016-08-29T18:27:40Z"}, "message": "Implement copy-on-write scheme for managing the incremental compilation cache.", "tree": {"sha": "dcde0e00ac9b9c709a0e74799805a13382a0d4ba", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dcde0e00ac9b9c709a0e74799805a13382a0d4ba"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3e9bed92da499d7905232d47d54300134fca13b5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3e9bed92da499d7905232d47d54300134fca13b5", "html_url": "https://github.com/rust-lang/rust/commit/3e9bed92da499d7905232d47d54300134fca13b5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3e9bed92da499d7905232d47d54300134fca13b5/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "206e7b6fc704c53b2a7174e8bec7b5f575d9bc93", "url": "https://api.github.com/repos/rust-lang/rust/commits/206e7b6fc704c53b2a7174e8bec7b5f575d9bc93", "html_url": "https://github.com/rust-lang/rust/commit/206e7b6fc704c53b2a7174e8bec7b5f575d9bc93"}], "stats": {"total": 1312, "additions": 1162, "deletions": 150}, "files": [{"sha": "ae1f9d3028c2c08075934fc18654d212bb7decaa", "filename": "src/librustc/hir/svh.rs", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Fhir%2Fsvh.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Fhir%2Fsvh.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fsvh.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -17,6 +17,7 @@\n \n use std::fmt;\n use std::hash::{Hash, Hasher};\n+use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n #[derive(Copy, Clone, PartialEq, Eq, Debug)]\n pub struct Svh {\n@@ -51,3 +52,17 @@ impl fmt::Display for Svh {\n         f.pad(&self.to_string())\n     }\n }\n+\n+impl Encodable for Svh {\n+    fn encode<S: Encoder>(&self, s: &mut S) -> Result<(), S::Error> {\n+        s.emit_u64(self.as_u64().to_le())\n+    }\n+}\n+\n+impl Decodable for Svh {\n+    fn decode<D: Decoder>(d: &mut D) -> Result<Svh, D::Error> {\n+        d.read_u64()\n+         .map(u64::from_le)\n+         .map(Svh::new)\n+    }\n+}"}, {"sha": "02ee4571ab5d9a714c0d62092feb59ca0970553a", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 92, "deletions": 1, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -33,10 +33,11 @@ use syntax::feature_gate::AttributeType;\n use syntax_pos::{Span, MultiSpan};\n \n use rustc_back::target::Target;\n+use rustc_data_structures::flock;\n use llvm;\n \n use std::path::{Path, PathBuf};\n-use std::cell::{Cell, RefCell};\n+use std::cell::{self, Cell, RefCell};\n use std::collections::{HashMap, HashSet};\n use std::env;\n use std::ffi::CString;\n@@ -101,6 +102,8 @@ pub struct Session {\n     /// macro name and defintion span in the source crate.\n     pub imported_macro_spans: RefCell<HashMap<Span, (String, Span)>>,\n \n+    incr_comp_session: RefCell<IncrCompSession>,\n+\n     next_node_id: Cell<ast::NodeId>,\n }\n \n@@ -331,6 +334,70 @@ impl Session {\n             &self.opts.search_paths,\n             kind)\n     }\n+\n+    pub fn init_incr_comp_session(&self,\n+                                  session_dir: PathBuf,\n+                                  lock_file: flock::Lock) {\n+        let mut incr_comp_session = self.incr_comp_session.borrow_mut();\n+\n+        if let IncrCompSession::NotInitialized = *incr_comp_session { } else {\n+            bug!(\"Trying to initialize IncrCompSession `{:?}`\", *incr_comp_session)\n+        }\n+\n+        *incr_comp_session = IncrCompSession::Active {\n+            session_directory: session_dir,\n+            lock_file: lock_file,\n+        };\n+    }\n+\n+    pub fn finalize_incr_comp_session(&self, new_directory_path: PathBuf) {\n+        let mut incr_comp_session = self.incr_comp_session.borrow_mut();\n+\n+        if let IncrCompSession::Active { .. } = *incr_comp_session { } else {\n+            bug!(\"Trying to finalize IncrCompSession `{:?}`\", *incr_comp_session)\n+        }\n+\n+        // Note: This will also drop the lock file, thus unlocking the directory\n+        *incr_comp_session = IncrCompSession::Finalized {\n+            session_directory: new_directory_path,\n+        };\n+    }\n+\n+    pub fn mark_incr_comp_session_as_invalid(&self) {\n+        let mut incr_comp_session = self.incr_comp_session.borrow_mut();\n+\n+        if let IncrCompSession::Active { .. } = *incr_comp_session { } else {\n+            bug!(\"Trying to invalidate IncrCompSession `{:?}`\", *incr_comp_session)\n+        }\n+\n+        // Note: This will also drop the lock file, thus unlocking the directory\n+        *incr_comp_session = IncrCompSession::InvalidBecauseOfErrors;\n+    }\n+\n+    pub fn incr_comp_session_dir(&self) -> cell::Ref<PathBuf> {\n+        let incr_comp_session = self.incr_comp_session.borrow();\n+        cell::Ref::map(incr_comp_session, |incr_comp_session| {\n+            match *incr_comp_session {\n+                IncrCompSession::NotInitialized |\n+                IncrCompSession::InvalidBecauseOfErrors => {\n+                    bug!(\"Trying to get session directory from IncrCompSession `{:?}`\",\n+                        *incr_comp_session)\n+                }\n+                IncrCompSession::Active { ref session_directory, .. } |\n+                IncrCompSession::Finalized { ref session_directory } => {\n+                    session_directory\n+                }\n+            }\n+        })\n+    }\n+\n+    pub fn incr_comp_session_dir_opt(&self) -> Option<cell::Ref<PathBuf>> {\n+        if self.opts.incremental.is_some() {\n+            Some(self.incr_comp_session_dir())\n+        } else {\n+            None\n+        }\n+    }\n }\n \n pub fn build_session(sopts: config::Options,\n@@ -446,13 +513,37 @@ pub fn build_session_(sopts: config::Options,\n         injected_panic_runtime: Cell::new(None),\n         available_macros: RefCell::new(HashSet::new()),\n         imported_macro_spans: RefCell::new(HashMap::new()),\n+        incr_comp_session: RefCell::new(IncrCompSession::NotInitialized),\n     };\n \n     init_llvm(&sess);\n \n     sess\n }\n \n+/// Holds data on the current incremental compilation session, if there is one.\n+#[derive(Debug)]\n+pub enum IncrCompSession {\n+    // This is the state the session will be in until the incr. comp. dir is\n+    // needed.\n+    NotInitialized,\n+    // This is the state during which the session directory is private and can\n+    // be modified.\n+    Active {\n+        session_directory: PathBuf,\n+        lock_file: flock::Lock,\n+    },\n+    // This is the state after the session directory has been finalized. In this\n+    // state, the contents of the directory must not be modified any more.\n+    Finalized {\n+        session_directory: PathBuf,\n+    },\n+    // This is an error state that is reached when some compilation error has\n+    // occurred. It indicates that the contents of the session directory must\n+    // not be used, since they might be invalid.\n+    InvalidBecauseOfErrors,\n+}\n+\n fn init_llvm(sess: &Session) {\n     unsafe {\n         // Before we touch LLVM, make sure that multithreading is enabled."}, {"sha": "d7800ccaa5dd393e598cdba8d106598c47ed3af6", "filename": "src/librustc/util/fs.rs", "status": "modified", "additions": 38, "deletions": 3, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Futil%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc%2Futil%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Ffs.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -56,14 +56,49 @@ pub fn fix_windows_verbatim_for_gcc(p: &Path) -> PathBuf {\n     }\n }\n \n+pub enum LinkOrCopy {\n+    Link,\n+    Copy\n+}\n+\n /// Copy `p` into `q`, preferring to use hard-linking if possible. If\n /// `q` already exists, it is removed first.\n-pub fn link_or_copy<P: AsRef<Path>, Q: AsRef<Path>>(p: P, q: Q) -> io::Result<()> {\n+/// The result indicates which of the two operations has been performed.\n+pub fn link_or_copy<P: AsRef<Path>, Q: AsRef<Path>>(p: P, q: Q) -> io::Result<LinkOrCopy> {\n     let p = p.as_ref();\n     let q = q.as_ref();\n     if q.exists() {\n         try!(fs::remove_file(&q));\n     }\n-    fs::hard_link(p, q)\n-        .or_else(|_| fs::copy(p, q).map(|_| ()))\n+\n+    match fs::hard_link(p, q) {\n+        Ok(()) => Ok(LinkOrCopy::Link),\n+        Err(_) => {\n+            match fs::copy(p, q) {\n+                Ok(_) => Ok(LinkOrCopy::Copy),\n+                Err(e) => Err(e)\n+            }\n+        }\n+    }\n+}\n+\n+// Like std::fs::create_dir_all, except handles concurrent calls among multiple\n+// threads or processes.\n+pub fn create_dir_racy(path: &Path) -> io::Result<()> {\n+    match fs::create_dir(path) {\n+        Ok(()) => return Ok(()),\n+        Err(ref e) if e.kind() == io::ErrorKind::AlreadyExists => return Ok(()),\n+        Err(ref e) if e.kind() == io::ErrorKind::NotFound => {}\n+        Err(e) => return Err(e),\n+    }\n+    match path.parent() {\n+        Some(p) => try!(create_dir_racy(p)),\n+        None => return Err(io::Error::new(io::ErrorKind::Other,\n+                                          \"failed to create whole tree\")),\n+    }\n+    match fs::create_dir(path) {\n+        Ok(()) => Ok(()),\n+        Err(ref e) if e.kind() == io::ErrorKind::AlreadyExists => Ok(()),\n+        Err(e) => Err(e),\n+    }\n }"}, {"sha": "22f8d76399519fe822346dd746a6bc9b6c28256b", "filename": "src/librustc_data_structures/flock.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_data_structures%2Fflock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_data_structures%2Fflock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fflock.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -136,6 +136,7 @@ mod imp {\n         pub const F_SETLKW: libc::c_int = 7;\n     }\n \n+    #[derive(Debug)]\n     pub struct Lock {\n         fd: libc::c_int,\n     }\n@@ -251,6 +252,7 @@ mod imp {\n                       lpOverlapped: LPOVERLAPPED) -> BOOL;\n     }\n \n+    #[derive(Debug)]\n     pub struct Lock {\n         _file: File,\n     }"}, {"sha": "33d68523a0f940e103b0426f4539eabe98984985", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 12, "deletions": 8, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -88,7 +88,7 @@ pub fn compile_input(sess: &Session,\n     // We need nested scopes here, because the intermediate results can keep\n     // large chunks of memory alive and we want to free them as soon as\n     // possible to keep the peak memory usage low\n-    let (outputs, trans, crate_name) = {\n+    let (outputs, trans) = {\n         let krate = match phase_1_parse_input(sess, cfg, input) {\n             Ok(krate) => krate,\n             Err(mut parse_error) => {\n@@ -213,11 +213,11 @@ pub fn compile_input(sess: &Session,\n             // Discard interned strings as they are no longer required.\n             token::clear_ident_interner();\n \n-            Ok((outputs, trans, crate_name.clone()))\n+            Ok((outputs, trans))\n         })??\n     };\n \n-    let phase5_result = phase_5_run_llvm_passes(sess, &crate_name, &trans, &outputs);\n+    let phase5_result = phase_5_run_llvm_passes(sess, &trans, &outputs);\n \n     controller_entry_point!(after_llvm,\n                             sess,\n@@ -229,6 +229,10 @@ pub fn compile_input(sess: &Session,\n \n     phase_6_link_output(sess, &trans, &outputs);\n \n+    // Now that we won't touch anything in the incremental compilation directory\n+    // any more, we can finalize it (which involves renaming it)\n+    rustc_incremental::finalize_session_directory(sess, trans.link.crate_hash);\n+\n     controller_entry_point!(compilation_done,\n                             sess,\n                             CompileState::state_when_compilation_done(input, sess, outdir, output),\n@@ -1026,19 +1030,19 @@ pub fn phase_4_translate_to_llvm<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     time(time_passes,\n          \"assert dep graph\",\n-         move || rustc_incremental::assert_dep_graph(tcx));\n+         || rustc_incremental::assert_dep_graph(tcx));\n \n     time(time_passes,\n          \"serialize dep graph\",\n-         move || rustc_incremental::save_dep_graph(tcx, &incremental_hashes_map));\n-\n+         || rustc_incremental::save_dep_graph(tcx,\n+                                              &incremental_hashes_map,\n+                                              translation.link.crate_hash));\n     translation\n }\n \n /// Run LLVM itself, producing a bitcode file, assembly file or object file\n /// as a side effect.\n pub fn phase_5_run_llvm_passes(sess: &Session,\n-                               crate_name: &str,\n                                trans: &trans::CrateTranslation,\n                                outputs: &OutputFilenames) -> CompileResult {\n     if sess.opts.cg.no_integrated_as {\n@@ -1061,7 +1065,7 @@ pub fn phase_5_run_llvm_passes(sess: &Session,\n \n     time(sess.time_passes(),\n          \"serialize work products\",\n-         move || rustc_incremental::save_work_products(sess, crate_name));\n+         move || rustc_incremental::save_work_products(sess));\n \n     if sess.err_count() > 0 {\n         Err(sess.err_count())"}, {"sha": "511ba8ec19cc7fe3e9ceea29a359757271df2317", "filename": "src/librustc_incremental/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Flib.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -22,6 +22,7 @@\n #![feature(question_mark)]\n #![feature(rustc_private)]\n #![feature(staged_api)]\n+#![feature(rand)]\n \n extern crate graphviz;\n extern crate rbml;\n@@ -45,3 +46,4 @@ pub use persist::save_dep_graph;\n pub use persist::save_trans_partition;\n pub use persist::save_work_products;\n pub use persist::in_incr_comp_dir;\n+pub use persist::finalize_session_directory;"}, {"sha": "c2990c66020b54dd99d286161ef5d35174274e6b", "filename": "src/librustc_incremental/persist/fs.rs", "status": "added", "additions": 895, "deletions": 0, "changes": 895, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Ffs.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -0,0 +1,895 @@\n+// Copyright 2016 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+\n+//! This module manages how the incremental compilation cache is represented in\n+//! the file system.\n+//!\n+//! Incremental compilation caches are managed according to a copy-on-write\n+//! strategy: Once a complete, consistent cache version is finalized, it is\n+//! never modified. Instead, when a subsequent compilation session is started,\n+//! the compiler will allocate a new version of the cache that starts out as\n+//! a copy of the previous version. Then only this new copy is modified and it\n+//! will not be visible to other processes until it is finalized. This ensures\n+//! that multiple compiler processes can be executed concurrently for the same\n+//! crate without interfering with each other or blocking each other.\n+//!\n+//! More concretely this is implemented via the following protocol:\n+//!\n+//! 1. For a newly started compilation session, the compiler allocates a\n+//!    new `session` directory within the incremental compilation directory.\n+//!    This session directory will have a unique name that ends with the suffix\n+//!    \"-working\" and that contains a creation timestamp.\n+//! 2. Next, the compiler looks for the newest finalized session directory,\n+//!    that is, a session directory from a previous compilation session that\n+//!    has been marked as valid and consistent. A session directory is\n+//!    considered finalized if the \"-working\" suffix in the directory name has\n+//!    been replaced by the SVH of the crate.\n+//! 3. Once the compiler has found a valid, finalized session directory, it will\n+//!    hard-link/copy its contents into the new \"-working\" directory. If all\n+//!    goes well, it will have its own, private copy of the source directory and\n+//!    subsequently not have to worry about synchronizing with other compiler\n+//!    processes.\n+//! 4. Now the compiler can do its normal compilation process, which involves\n+//!    reading and updating its private session directory.\n+//! 5. When compilation finishes without errors, the private session directory\n+//!    will be in a state where it can be used as input for other compilation\n+//!    sessions. That is, it will contain a dependency graph and cache artifacts\n+//!    that are consistent with the state of the source code it was compiled\n+//!    from, with no need to change them ever again. At this point, the compiler\n+//!    finalizes and \"publishes\" its private session directory by renaming it\n+//!    from \"sess-{timestamp}-{random}-working\" to \"sess-{timestamp}-{SVH}\".\n+//! 6. At this point the \"old\" session directory that we copied our data from\n+//!    at the beginning of the session has become obsolete because we have just\n+//!    published a more current version. Thus the compiler will delete it.\n+//!\n+//! ## Garbage Collection\n+//!\n+//! Naively following the above protocol might lead to old session directories\n+//! piling up if a compiler instance crashes for some reason before its able to\n+//! remove its private session directory. In order to avoid wasting disk space,\n+//! the compiler also does some garbage collection each time it is started in\n+//! incremental compilation mode. Specifically, it will scan the incremental\n+//! compilation directory for private session directories that are not in use\n+//! any more and will delete those. It will also delete any finalized session\n+//! directories for a given crate except for the most recent one.\n+//!\n+//! ## Synchronization\n+//!\n+//! There is some synchronization needed in order for the compiler to be able to\n+//! determine whether a given private session directory is not in used any more.\n+//! This is done by creating a lock file within each session directory and\n+//! locking it while the directory is still being used. Since file locks have\n+//! operating system support, we can rely on the lock being released if the\n+//! compiler process dies for some unexpected reason. Thus, when garbage\n+//! collecting private session directories, the collecting process can determine\n+//! whether the directory is still in use by trying to acquire a lock on the\n+//! file. If locking the file fails, the original process must still be alive.\n+//! If locking the file succeeds, we know that the owning process is not alive\n+//! any more and we can safely delete the directory.\n+//! There is still a small time window between the original process creating the\n+//! lock file and actually locking it. In order to minimize the chance that\n+//! another process tries to acquire the lock in just that instance, only\n+//! session directories that are older than a few seconds are considered for\n+//! garbage collection.\n+//!\n+//! Another case that has to be considered is what happens if one process\n+//! deletes a finalized session directory that another process is currently\n+//! trying to copy from. This case is also handled via the lock file. Before\n+//! a process starts copying a finalized session directory, it will acquire a\n+//! shared lock on the directory's lock file. Any garbage collecting process,\n+//! on the other hand, will acquire an exclusive lock on the lock file.\n+//! Thus, if a directory is being collected, any reader process will fail\n+//! acquiring the shared lock and will leave the directory alone. Conversely,\n+//! if a collecting process can't acquire the exclusive lock because the\n+//! directory is currently being read from, it will leave collecting that\n+//! directory to another process at a later point in time.\n+//! The exact same scheme is also used when reading the metadata hashes file\n+//! from an extern crate. When a crate is compiled, the hash values of its\n+//! metadata are stored in a file in its session directory. When the\n+//! compilation session of another crate imports the first crate's metadata,\n+//! it also has to read in the accompanying metadata hashes. It thus will access\n+//! the finalized session directory of all crates it links to and while doing\n+//! so, it will also place a read lock on that the respective session directory\n+//! so that it won't be deleted while the metadata hashes are loaded.\n+//!\n+//! ## Preconditions\n+//!\n+//! This system relies on two features being available in the file system in\n+//! order to work really well: file locking and hard linking.\n+//! If hard linking is not available (like on FAT) the data in the cache\n+//! actually has to be copied at the beginning of each session.\n+//! If file locking does not work reliably (like on NFS), some of the\n+//! synchronization will go haywire.\n+//! In both cases we recommend to locate the incremental compilation directory\n+//! on a file system that supports these things.\n+//! It might be a good idea though to try and detect whether we are on an\n+//! unsupported file system and emit a warning in that case. This is not yet\n+//! implemented.\n+\n+use rustc::hir::svh::Svh;\n+use rustc::middle::cstore::LOCAL_CRATE;\n+use rustc::session::Session;\n+use rustc::ty::TyCtxt;\n+use rustc::util::fs as fs_util;\n+use rustc_data_structures::flock;\n+use rustc_data_structures::fnv::{FnvHashSet, FnvHashMap};\n+\n+use std::ffi::OsString;\n+use std::fs as std_fs;\n+use std::io;\n+use std::mem;\n+use std::path::{Path, PathBuf};\n+use std::time::{UNIX_EPOCH, SystemTime, Duration};\n+use std::__rand::{thread_rng, Rng};\n+use syntax::ast;\n+\n+const LOCK_FILE_NAME: &'static str = \".lock_file\";\n+const DEP_GRAPH_FILENAME: &'static str = \"dep-graph.bin\";\n+const WORK_PRODUCTS_FILENAME: &'static str = \"work-products.bin\";\n+const METADATA_HASHES_FILENAME: &'static str = \"metadata.bin\";\n+\n+pub fn dep_graph_path(sess: &Session) -> PathBuf {\n+    in_incr_comp_dir_sess(sess, DEP_GRAPH_FILENAME)\n+}\n+\n+pub fn work_products_path(sess: &Session) -> PathBuf {\n+    in_incr_comp_dir_sess(sess, WORK_PRODUCTS_FILENAME)\n+}\n+\n+pub fn metadata_hash_export_path(sess: &Session) -> PathBuf {\n+    in_incr_comp_dir_sess(sess, METADATA_HASHES_FILENAME)\n+}\n+\n+pub fn metadata_hash_import_path(import_session_dir: &Path) -> PathBuf {\n+    import_session_dir.join(METADATA_HASHES_FILENAME)\n+}\n+\n+pub fn lock_file_path(session_dir: &Path) -> PathBuf {\n+    session_dir.join(LOCK_FILE_NAME)\n+}\n+\n+pub fn in_incr_comp_dir_sess(sess: &Session, file_name: &str) -> PathBuf {\n+    in_incr_comp_dir(&sess.incr_comp_session_dir(), file_name)\n+}\n+\n+pub fn in_incr_comp_dir(incr_comp_session_dir: &Path, file_name: &str) -> PathBuf {\n+    incr_comp_session_dir.join(file_name)\n+}\n+\n+/// Allocates the private session directory. The boolean in the Ok() result\n+/// indicates whether we should try loading a dep graph from the successfully\n+/// initialized directory, or not.\n+/// The post-condition of this fn is that we have a valid incremental\n+/// compilation session directory, if the result is `Ok`. A valid session\n+/// directory is one that contains a locked lock file. It may or may not contain\n+/// a dep-graph and work products from a previous session.\n+/// If the call fails, the fn may leave behind an invalid session directory.\n+/// The garbage collection will take care of it.\n+pub fn prepare_session_directory(tcx: TyCtxt) -> Result<bool, ()> {\n+    debug!(\"prepare_session_directory\");\n+\n+    // {incr-comp-dir}/{crate-name-and-disambiguator}\n+    let crate_dir = crate_path_tcx(tcx, LOCAL_CRATE);\n+    debug!(\"crate-dir: {}\", crate_dir.display());\n+\n+    let mut source_directories_already_tried = FnvHashSet();\n+\n+    loop {\n+        // Allocate a session directory of the form:\n+        //\n+        // {incr-comp-dir}/{crate-name-and-disambiguator}/sess-{timestamp}-{random}-working\n+        //\n+        // If this fails, return an error, don't retry\n+        let session_dir = try!(alloc_session_dir(tcx.sess, &crate_dir));\n+        debug!(\"session-dir: {}\", session_dir.display());\n+\n+        // Lock the newly created session directory. If this fails, return an\n+        // error without retrying\n+        let directory_lock = try!(lock_directory(tcx.sess, &session_dir));\n+\n+        let print_file_copy_stats = tcx.sess.opts.debugging_opts.incremental_info;\n+\n+        // Find a suitable source directory to copy from. Ignore those that we\n+        // have already tried before.\n+        let source_directory = find_source_directory(&crate_dir,\n+                                                     &source_directories_already_tried);\n+\n+        let source_directory = if let Some(dir) = source_directory {\n+            dir\n+        } else {\n+            // There's nowhere to copy from, we're done\n+            debug!(\"no source directory found. Continuing with empty session \\\n+                    directory.\");\n+\n+            tcx.sess.init_incr_comp_session(session_dir, directory_lock);\n+            return Ok(false)\n+        };\n+\n+        debug!(\"attempting to copy data from source: {}\",\n+               source_directory.display());\n+\n+        // Try copying over all files from the source directory\n+        if copy_files(&session_dir, &source_directory, print_file_copy_stats).is_ok() {\n+            debug!(\"successfully copied data from: {}\",\n+                   source_directory.display());\n+\n+            tcx.sess.init_incr_comp_session(session_dir, directory_lock);\n+            return Ok(true)\n+        } else {\n+             debug!(\"copying failed - trying next directory\");\n+\n+            // Something went wrong while trying to copy/link files from the\n+            // source directory. Try again with a different one.\n+            source_directories_already_tried.insert(source_directory);\n+\n+            // Try to remove the session directory we just allocated. We don't\n+            // know if there's any garbage in it from the failed copy action.\n+            if let Err(err) = std_fs::remove_dir_all(&session_dir) {\n+                debug!(\"Failed to delete partly initialized session dir `{}`: {}\",\n+                       session_dir.display(),\n+                       err);\n+            }\n+            mem::drop(directory_lock);\n+        }\n+    }\n+}\n+\n+/// This function finalizes and thus 'publishes' the session directory by\n+/// renaming it to `sess-{timestamp}-{svh}` and releasing the file lock.\n+/// If there have been compilation errors, however, this function will just\n+/// delete the presumably invalid session directory.\n+pub fn finalize_session_directory(sess: &Session, svh: Svh) {\n+    if sess.opts.incremental.is_none() {\n+        return;\n+    }\n+\n+    let incr_comp_session_dir: PathBuf = sess.incr_comp_session_dir().clone();\n+\n+    if sess.has_errors() {\n+        // If there have been any errors during compilation, we don't want to\n+        // publish this session directory. Rather, we'll just delete it.\n+\n+        debug!(\"finalize_session_directory() - invalidating session directory: {}\",\n+                incr_comp_session_dir.display());\n+\n+        if let Err(err) = std_fs::remove_dir_all(&*incr_comp_session_dir) {\n+            sess.warn(&format!(\"Error deleting incremental compilation \\\n+                               session directory `{}`: {}\",\n+                               incr_comp_session_dir.display(),\n+                               err));\n+        }\n+        sess.mark_incr_comp_session_as_invalid();\n+    }\n+\n+    debug!(\"finalize_session_directory() - session directory: {}\",\n+            incr_comp_session_dir.display());\n+\n+    let old_sub_dir_name = incr_comp_session_dir.file_name()\n+                                                .unwrap()\n+                                                .to_string_lossy();\n+    assert_no_characters_lost(&old_sub_dir_name);\n+\n+    // Keep the 'sess-{timestamp}' prefix, but replace the\n+    // '-{random-number}-working' part with the SVH of the crate\n+    let dash_indices: Vec<_> = old_sub_dir_name.match_indices(\"-\")\n+                                               .map(|(idx, _)| idx)\n+                                               .collect();\n+    if dash_indices.len() != 3 {\n+        bug!(\"Encountered incremental compilation session directory with \\\n+              malformed name: {}\",\n+             incr_comp_session_dir.display())\n+    }\n+\n+    // State: \"sess-{timestamp}-\"\n+    let mut new_sub_dir_name = String::from(&old_sub_dir_name[.. dash_indices[1] + 1]);\n+\n+    // Append the svh\n+    new_sub_dir_name.push_str(&svh.to_string());\n+\n+    // Create the full path\n+    let new_path = incr_comp_session_dir.parent().unwrap().join(new_sub_dir_name);\n+    debug!(\"finalize_session_directory() - new path: {}\", new_path.display());\n+\n+    match std_fs::rename(&*incr_comp_session_dir, &new_path) {\n+        Ok(_) => {\n+            debug!(\"finalize_session_directory() - directory renamed successfully\");\n+\n+            // This unlocks the directory\n+            sess.finalize_incr_comp_session(new_path);\n+        }\n+        Err(e) => {\n+            // Warn about the error. However, no need to abort compilation now.\n+            sess.warn(&format!(\"Error finalizing incremental compilation \\\n+                               session directory `{}`: {}\",\n+                               incr_comp_session_dir.display(),\n+                               e));\n+\n+            debug!(\"finalize_session_directory() - error, marking as invalid\");\n+            // Drop the file lock, so we can garage collect\n+            sess.mark_incr_comp_session_as_invalid();\n+        }\n+    }\n+\n+    let _ = garbage_collect_session_directories(sess);\n+}\n+\n+fn copy_files(target_dir: &Path,\n+              source_dir: &Path,\n+              print_stats_on_success: bool)\n+              -> Result<(), ()> {\n+    // We acquire a shared lock on the lock file of the directory, so that\n+    // nobody deletes it out from under us while we are reading from it.\n+    let lock_file_path = source_dir.join(LOCK_FILE_NAME);\n+    let _lock = if let Ok(lock) = flock::Lock::new(&lock_file_path,\n+                                                   false,   // don't wait,\n+                                                   false,   // don't create\n+                                                   false) { // not exclusive\n+        lock\n+    } else {\n+        // Could not acquire the lock, don't try to copy from here\n+        return Err(())\n+    };\n+\n+    let source_dir_iterator = match source_dir.read_dir() {\n+        Ok(it) => it,\n+        Err(_) => return Err(())\n+    };\n+\n+    let mut files_linked = 0;\n+    let mut files_copied = 0;\n+\n+    for entry in source_dir_iterator {\n+        match entry {\n+            Ok(entry) => {\n+                let file_name = entry.file_name();\n+\n+                if file_name.to_string_lossy() == LOCK_FILE_NAME {\n+                    continue;\n+                }\n+\n+                let target_file_path = target_dir.join(file_name);\n+                let source_path = entry.path();\n+\n+                debug!(\"copying into session dir: {}\", source_path.display());\n+                match fs_util::link_or_copy(source_path, target_file_path) {\n+                    Ok(fs_util::LinkOrCopy::Link) => {\n+                        files_linked += 1\n+                    }\n+                    Ok(fs_util::LinkOrCopy::Copy) => {\n+                        files_copied += 1\n+                    }\n+                    Err(_) => return Err(())\n+                }\n+            }\n+            Err(_) => {\n+                return Err(())\n+            }\n+        }\n+    }\n+\n+    if print_stats_on_success {\n+        println!(\"incr. comp. session directory: {} files hard-linked\", files_linked);\n+        println!(\"incr. comp. session directory: {} files copied\", files_copied);\n+    }\n+\n+    Ok(())\n+}\n+\n+/// Create a directory with a path of the form:\n+/// {crate_dir}/sess-{timestamp}-{random-number}-working\n+fn alloc_session_dir(sess: &Session,\n+                     crate_dir: &Path)\n+                     -> Result<PathBuf, ()> {\n+    let timestamp = timestamp_to_string(SystemTime::now());\n+    debug!(\"alloc_session_dir: timestamp = {}\", timestamp);\n+    let random_number = thread_rng().next_u32();\n+    debug!(\"alloc_session_dir: random_number = {}\", random_number);\n+\n+    let directory_name = format!(\"sess-{}-{:x}-working\", timestamp, random_number);\n+    debug!(\"alloc_session_dir: directory_name = {}\", directory_name);\n+    let directory_path = crate_dir.join(directory_name);\n+    debug!(\"alloc_session_dir: directory_path = {}\", directory_path.display());\n+\n+    match fs_util::create_dir_racy(&directory_path) {\n+        Ok(()) => {\n+            debug!(\"alloc_session_dir: directory created successfully\");\n+            Ok(directory_path)\n+        }\n+        Err(err) => {\n+            sess.err(&format!(\"incremental compilation: could not create \\\n+                               session directory `{}`: {}\",\n+                              directory_path.display(),\n+                              err));\n+            Err(())\n+        }\n+    }\n+}\n+\n+/// Allocate a the lock-file and lock it.\n+fn lock_directory(sess: &Session,\n+                  session_dir: &Path)\n+                  -> Result<flock::Lock, ()> {\n+    let lock_file_path = session_dir.join(LOCK_FILE_NAME);\n+    debug!(\"lock_directory() - lock_file: {}\", lock_file_path.display());\n+\n+    match flock::Lock::new(&lock_file_path,\n+                           false, // don't wait\n+                           true,  // create the lock file\n+                           true) { // the lock should be exclusive\n+        Ok(lock) => Ok(lock),\n+        Err(err) => {\n+            sess.err(&format!(\"incremental compilation: could not create \\\n+                               session directory lock file: {}\", err));\n+            Err(())\n+        }\n+    }\n+}\n+\n+/// Find the most recent published session directory that is not in the\n+/// ignore-list.\n+fn find_source_directory(crate_dir: &Path,\n+                         source_directories_already_tried: &FnvHashSet<PathBuf>)\n+                         -> Option<PathBuf> {\n+    let iter = crate_dir.read_dir()\n+                        .unwrap() // FIXME\n+                        .filter_map(|e| e.ok().map(|e| e.path()));\n+\n+    find_source_directory_in_iter(iter, source_directories_already_tried)\n+}\n+\n+fn find_source_directory_in_iter<I>(iter: I,\n+                                    source_directories_already_tried: &FnvHashSet<PathBuf>)\n+                                    -> Option<PathBuf>\n+    where I: Iterator<Item=PathBuf>\n+{\n+    let mut best_candidate = (UNIX_EPOCH, None);\n+\n+    for session_dir in iter {\n+        if source_directories_already_tried.contains(&session_dir) ||\n+           !is_finalized(&session_dir.to_string_lossy()) {\n+            continue\n+        }\n+\n+        let timestamp = {\n+            let directory_name = session_dir.file_name().unwrap().to_string_lossy();\n+            assert_no_characters_lost(&directory_name);\n+\n+            extract_timestamp_from_session_dir(&directory_name)\n+                .unwrap_or_else(|_| {\n+                    bug!(\"unexpected incr-comp session dir: {}\", session_dir.display())\n+                })\n+        };\n+\n+        if timestamp > best_candidate.0 {\n+            best_candidate = (timestamp, Some(session_dir));\n+        }\n+    }\n+\n+    best_candidate.1\n+}\n+\n+fn is_finalized(directory_name: &str) -> bool {\n+    !directory_name.ends_with(\"-working\")\n+}\n+\n+fn is_session_directory(directory_name: &str) -> bool {\n+    directory_name.starts_with(\"sess-\")\n+}\n+\n+fn extract_timestamp_from_session_dir(directory_name: &str)\n+                                      -> Result<SystemTime, ()> {\n+    if !is_session_directory(directory_name) {\n+        return Err(())\n+    }\n+\n+    let dash_indices: Vec<_> = directory_name.match_indices(\"-\")\n+                                             .map(|(idx, _)| idx)\n+                                             .collect();\n+    if dash_indices.len() < 2 {\n+        return Err(())\n+    }\n+\n+    string_to_timestamp(&directory_name[dash_indices[0]+1 .. dash_indices[1]])\n+}\n+\n+fn timestamp_to_string(timestamp: SystemTime) -> String {\n+    let duration = timestamp.duration_since(UNIX_EPOCH).unwrap();\n+    let nanos = duration.as_secs() * 1_000_000_000 +\n+                (duration.subsec_nanos() as u64);\n+    format!(\"{:x}\", nanos)\n+}\n+\n+fn string_to_timestamp(s: &str) -> Result<SystemTime, ()> {\n+    let nanos_since_unix_epoch = u64::from_str_radix(s, 16);\n+\n+    if nanos_since_unix_epoch.is_err() {\n+        return Err(())\n+    }\n+\n+    let nanos_since_unix_epoch = nanos_since_unix_epoch.unwrap();\n+\n+    let duration = Duration::new(nanos_since_unix_epoch / 1_000_000_000,\n+                                 (nanos_since_unix_epoch % 1_000_000_000) as u32);\n+    Ok(UNIX_EPOCH + duration)\n+}\n+\n+fn crate_path_tcx(tcx: TyCtxt, cnum: ast::CrateNum) -> PathBuf {\n+    crate_path(tcx.sess, &tcx.crate_name(cnum), &tcx.crate_disambiguator(cnum))\n+}\n+\n+/// Finds the session directory containing the correct metadata hashes file for\n+/// the given crate. In order to do that it has to compute the crate directory\n+/// of the given crate, and in there, look for the session directory with the\n+/// correct SVH in it.\n+/// Note that we have to match on the exact SVH here, not just the\n+/// crate's (name, disambiguator) pair. The metadata hashes are only valid for\n+/// the exact version of the binary we are reading from now (i.e. the hashes\n+/// are part of the dependency graph of a specific compilation session).\n+pub fn find_metadata_hashes_for(tcx: TyCtxt, cnum: ast::CrateNum) -> Option<PathBuf> {\n+    let crate_directory = crate_path_tcx(tcx, cnum);\n+\n+    if !crate_directory.exists() {\n+        return None\n+    }\n+\n+    let dir_entries = match crate_directory.read_dir() {\n+        Ok(dir_entries) => dir_entries,\n+        Err(e) => {\n+            tcx.sess\n+               .err(&format!(\"incremental compilation: Could not read crate directory `{}`: {}\",\n+                             crate_directory.display(), e));\n+            return None\n+        }\n+    };\n+\n+    let target_svh = tcx.sess.cstore.crate_hash(cnum).to_string();\n+\n+    let sub_dir = find_metadata_hashes_iter(&target_svh, dir_entries.filter_map(|e| {\n+        e.ok().map(|e| e.file_name().to_string_lossy().into_owned())\n+    }));\n+\n+    sub_dir.map(|sub_dir_name| crate_directory.join(&sub_dir_name))\n+}\n+\n+fn find_metadata_hashes_iter<'a, I>(target_svh: &str, iter: I) -> Option<OsString>\n+    where I: Iterator<Item=String>\n+{\n+    for sub_dir_name in iter {\n+        if !is_session_directory(&sub_dir_name) || !is_finalized(&sub_dir_name) {\n+            // This is not a usable session directory\n+            continue\n+        }\n+\n+        let is_match = if let Some(last_dash_pos) = sub_dir_name.rfind(\"-\") {\n+            let candidate_svh = &sub_dir_name[last_dash_pos + 1 .. ];\n+            target_svh == candidate_svh\n+        } else {\n+            // some kind of invalid directory name\n+            continue\n+        };\n+\n+        if is_match {\n+            return Some(OsString::from(sub_dir_name))\n+        }\n+    }\n+\n+    None\n+}\n+\n+fn crate_path(sess: &Session,\n+              crate_name: &str,\n+              crate_disambiguator: &str)\n+              -> PathBuf {\n+    use std::hash::{SipHasher, Hasher, Hash};\n+\n+    let incr_dir = sess.opts.incremental.as_ref().unwrap().clone();\n+\n+    // The full crate disambiguator is really long. A hash of it should be\n+    // sufficient.\n+    let mut hasher = SipHasher::new();\n+    crate_disambiguator.hash(&mut hasher);\n+\n+    let crate_name = format!(\"{}-{:x}\", crate_name, hasher.finish());\n+    incr_dir.join(crate_name)\n+}\n+\n+fn assert_no_characters_lost(s: &str) {\n+    if s.contains('\\u{FFFD}') {\n+        bug!(\"Could not losslessly convert '{}'.\", s)\n+    }\n+}\n+\n+pub fn garbage_collect_session_directories(sess: &Session) -> io::Result<()> {\n+    debug!(\"garbage_collect_session_directories() - begin\");\n+\n+    let session_directory = sess.incr_comp_session_dir();\n+    debug!(\"garbage_collect_session_directories() - session directory: {}\",\n+        session_directory.display());\n+\n+    let crate_directory = session_directory.parent().unwrap();\n+    debug!(\"garbage_collect_session_directories() - crate directory: {}\",\n+        crate_directory.display());\n+\n+    let mut deletion_candidates = vec![];\n+    let mut definitely_delete = vec![];\n+\n+    for dir_entry in try!(crate_directory.read_dir()) {\n+        let dir_entry = match dir_entry {\n+            Ok(dir_entry) => dir_entry,\n+            _ => {\n+                // Ignore any errors\n+                continue\n+            }\n+        };\n+\n+        let directory_name = dir_entry.file_name();\n+        let directory_name = directory_name.to_string_lossy();\n+\n+        if !is_session_directory(&directory_name) {\n+            // This is something we don't know, leave it alone...\n+            continue\n+        }\n+        assert_no_characters_lost(&directory_name);\n+\n+        if let Ok(file_type) = dir_entry.file_type() {\n+            if !file_type.is_dir() {\n+                // This is not a directory, skip it\n+                continue\n+            }\n+        } else {\n+            // Some error occurred while trying to determine the file type,\n+            // skip it\n+            continue\n+        }\n+\n+        debug!(\"garbage_collect_session_directories() - inspecting: {}\",\n+                directory_name);\n+\n+        match extract_timestamp_from_session_dir(&directory_name) {\n+            Ok(timestamp) => {\n+                let lock_file_path = crate_directory.join(&*directory_name)\n+                                                    .join(LOCK_FILE_NAME);\n+\n+                if !is_finalized(&directory_name) {\n+                    let ten_seconds = Duration::from_secs(10);\n+\n+                    // When cleaning out \"-working\" session directories, i.e.\n+                    // session directories that might still be in use by another\n+                    // compiler instance, we only look a directories that are\n+                    // at least ten seconds old. This is supposed to reduce the\n+                    // chance of deleting a directory in the time window where\n+                    // the process has allocated the directory but has not yet\n+                    // acquired the file-lock on it.\n+                    if timestamp < SystemTime::now() - ten_seconds {\n+                        debug!(\"garbage_collect_session_directories() - \\\n+                                attempting to collect\");\n+\n+                        // Try to acquire the directory lock. If we can't, it\n+                        // means that the owning process is still alive and we\n+                        // leave this directory alone.\n+                        match flock::Lock::new(&lock_file_path,\n+                                               false,  // don't wait\n+                                               false,  // don't create the lock-file\n+                                               true) { // get an exclusive lock\n+                            Ok(lock) => {\n+                                debug!(\"garbage_collect_session_directories() - \\\n+                                        successfully acquired lock\");\n+\n+                                // Note that we are holding on to the lock\n+                                definitely_delete.push((dir_entry.path(),\n+                                                        Some(lock)));\n+                            }\n+                            Err(_) => {\n+                                debug!(\"garbage_collect_session_directories() - \\\n+                                not collecting, still in use\");\n+                            }\n+                        }\n+                    } else {\n+                        debug!(\"garbage_collect_session_directories() - \\\n+                                private session directory too new\");\n+                    }\n+                } else {\n+                    match flock::Lock::new(&lock_file_path,\n+                                           false,  // don't wait\n+                                           false,  // don't create the lock-file\n+                                           true) { // get an exclusive lock\n+                        Ok(lock) => {\n+                            debug!(\"garbage_collect_session_directories() - \\\n+                                    successfully acquired lock\");\n+                            debug!(\"garbage_collect_session_directories() - adding \\\n+                                    deletion candidate: {}\", directory_name);\n+\n+                            // Note that we are holding on to the lock\n+                            deletion_candidates.push((timestamp,\n+                                                      dir_entry.path(),\n+                                                      Some(lock)));\n+                        }\n+                        Err(_) => {\n+                            debug!(\"garbage_collect_session_directories() - \\\n+                            not collecting, still in use\");\n+                        }\n+                    }\n+                }\n+            }\n+            Err(_) => {\n+                // Malformed timestamp in directory, delete it\n+                definitely_delete.push((dir_entry.path(), None));\n+\n+                debug!(\"garbage_collect_session_directories() - encountered \\\n+                        malformed session directory: {}\", directory_name);\n+            }\n+        }\n+    }\n+\n+    // Delete all but the most recent of the candidates\n+    for (path, lock) in all_except_most_recent(deletion_candidates) {\n+        debug!(\"garbage_collect_session_directories() - deleting `{}`\",\n+                path.display());\n+\n+        if let Err(err) = std_fs::remove_dir_all(&path) {\n+            sess.warn(&format!(\"Failed to garbage collect finalized incremental \\\n+                                compilation session directory `{}`: {}\",\n+                               path.display(),\n+                               err));\n+        }\n+\n+        // Let's make it explicit that the file lock is released at this point,\n+        // or rather, that we held on to it until here\n+        mem::drop(lock);\n+    }\n+\n+    for (path, lock) in definitely_delete {\n+        debug!(\"garbage_collect_session_directories() - deleting `{}`\",\n+                path.display());\n+\n+        if let Err(err) = std_fs::remove_dir_all(&path) {\n+            sess.warn(&format!(\"Failed to garbage collect incremental \\\n+                                compilation session directory `{}`: {}\",\n+                               path.display(),\n+                               err));\n+        }\n+\n+        // Let's make it explicit that the file lock is released at this point,\n+        // or rather, that we held on to it until here\n+        mem::drop(lock);\n+    }\n+\n+    Ok(())\n+}\n+\n+fn all_except_most_recent(deletion_candidates: Vec<(SystemTime, PathBuf, Option<flock::Lock>)>)\n+                          -> FnvHashMap<PathBuf, Option<flock::Lock>> {\n+    let most_recent = deletion_candidates.iter()\n+                                         .map(|&(timestamp, _, _)| timestamp)\n+                                         .max();\n+\n+    if let Some(most_recent) = most_recent {\n+        deletion_candidates.into_iter()\n+                           .filter(|&(timestamp, _, _)| timestamp != most_recent)\n+                           .map(|(_, path, lock)| (path, lock))\n+                           .collect()\n+    } else {\n+        FnvHashMap()\n+    }\n+}\n+\n+#[test]\n+fn test_all_except_most_recent() {\n+    assert_eq!(all_except_most_recent(\n+        vec![\n+            (UNIX_EPOCH + Duration::new(4, 0), PathBuf::from(\"4\"), None),\n+            (UNIX_EPOCH + Duration::new(1, 0), PathBuf::from(\"1\"), None),\n+            (UNIX_EPOCH + Duration::new(5, 0), PathBuf::from(\"5\"), None),\n+            (UNIX_EPOCH + Duration::new(3, 0), PathBuf::from(\"3\"), None),\n+            (UNIX_EPOCH + Duration::new(2, 0), PathBuf::from(\"2\"), None),\n+        ]).keys().cloned().collect::<FnvHashSet<PathBuf>>(),\n+        vec![\n+            PathBuf::from(\"1\"),\n+            PathBuf::from(\"2\"),\n+            PathBuf::from(\"3\"),\n+            PathBuf::from(\"4\"),\n+        ].into_iter().collect::<FnvHashSet<PathBuf>>()\n+    );\n+\n+    assert_eq!(all_except_most_recent(\n+        vec![\n+        ]).keys().cloned().collect::<FnvHashSet<PathBuf>>(),\n+        FnvHashSet()\n+    );\n+}\n+\n+#[test]\n+fn test_timestamp_serialization() {\n+    for i in 0 .. 1_000u64 {\n+        let time = UNIX_EPOCH + Duration::new(i * 3_434_578, (i as u32) * 239_676);\n+        let s = timestamp_to_string(time);\n+        assert_eq!(time, string_to_timestamp(&s).unwrap());\n+    }\n+}\n+\n+#[test]\n+fn test_find_source_directory_in_iter() {\n+    let already_visited = FnvHashSet();\n+\n+    // Find newest\n+    assert_eq!(find_source_directory_in_iter(\n+        vec![PathBuf::from(\"./sess-3234-0000\"),\n+             PathBuf::from(\"./sess-2234-0000\"),\n+             PathBuf::from(\"./sess-1234-0000\")].into_iter(), &already_visited),\n+        Some(PathBuf::from(\"./sess-3234-0000\")));\n+\n+    // Filter out \"-working\"\n+    assert_eq!(find_source_directory_in_iter(\n+        vec![PathBuf::from(\"./sess-3234-0000-working\"),\n+             PathBuf::from(\"./sess-2234-0000\"),\n+             PathBuf::from(\"./sess-1234-0000\")].into_iter(), &already_visited),\n+        Some(PathBuf::from(\"./sess-2234-0000\")));\n+\n+    // Handle empty\n+    assert_eq!(find_source_directory_in_iter(vec![].into_iter(), &already_visited),\n+               None);\n+\n+    // Handle only working\n+    assert_eq!(find_source_directory_in_iter(\n+        vec![PathBuf::from(\"./sess-3234-0000-working\"),\n+             PathBuf::from(\"./sess-2234-0000-working\"),\n+             PathBuf::from(\"./sess-1234-0000-working\")].into_iter(), &already_visited),\n+        None);\n+}\n+\n+#[test]\n+fn test_find_metadata_hashes_iter()\n+{\n+    assert_eq!(find_metadata_hashes_iter(\"testsvh2\",\n+        vec![\n+            String::from(\"sess-timestamp1-testsvh1\"),\n+            String::from(\"sess-timestamp2-testsvh2\"),\n+            String::from(\"sess-timestamp3-testsvh3\"),\n+        ].into_iter()),\n+        Some(OsString::from(\"sess-timestamp2-testsvh2\"))\n+    );\n+\n+    assert_eq!(find_metadata_hashes_iter(\"testsvh2\",\n+        vec![\n+            String::from(\"sess-timestamp1-testsvh1\"),\n+            String::from(\"sess-timestamp2-testsvh2\"),\n+            String::from(\"invalid-name\"),\n+        ].into_iter()),\n+        Some(OsString::from(\"sess-timestamp2-testsvh2\"))\n+    );\n+\n+    assert_eq!(find_metadata_hashes_iter(\"testsvh2\",\n+        vec![\n+            String::from(\"sess-timestamp1-testsvh1\"),\n+            String::from(\"sess-timestamp2-testsvh2-working\"),\n+            String::from(\"sess-timestamp3-testsvh3\"),\n+        ].into_iter()),\n+        None\n+    );\n+\n+    assert_eq!(find_metadata_hashes_iter(\"testsvh1\",\n+        vec![\n+            String::from(\"sess-timestamp1-random1-working\"),\n+            String::from(\"sess-timestamp2-random2-working\"),\n+            String::from(\"sess-timestamp3-random3-working\"),\n+        ].into_iter()),\n+        None\n+    );\n+\n+    assert_eq!(find_metadata_hashes_iter(\"testsvh2\",\n+        vec![\n+            String::from(\"timestamp1-testsvh2\"),\n+            String::from(\"timestamp2-testsvh2\"),\n+            String::from(\"timestamp3-testsvh2\"),\n+        ].into_iter()),\n+        None\n+    );\n+}"}, {"sha": "95bee669d3256151cafdc3ba174f21ec4391e591", "filename": "src/librustc_incremental/persist/hash.rs", "status": "modified", "additions": 45, "deletions": 9, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fhash.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -15,14 +15,15 @@ use rustc::hir::def_id::DefId;\n use rustc::hir::svh::Svh;\n use rustc::ty::TyCtxt;\n use rustc_data_structures::fnv::FnvHashMap;\n+use rustc_data_structures::flock;\n use rustc_serialize::Decodable;\n use std::io::{ErrorKind, Read};\n use std::fs::File;\n use syntax::ast;\n \n use IncrementalHashesMap;\n use super::data::*;\n-use super::util::*;\n+use super::fs::*;\n \n pub struct HashContext<'a, 'tcx: 'a> {\n     pub tcx: TyCtxt<'a, 'tcx, 'tcx>,\n@@ -128,19 +129,43 @@ impl<'a, 'tcx> HashContext<'a, 'tcx> {\n         debug!(\"load_data: svh={}\", svh);\n         assert!(old.is_none(), \"loaded data for crate {:?} twice\", cnum);\n \n-        if let Some(path) = metadata_hash_path(self.tcx, cnum) {\n-            debug!(\"load_data: path={:?}\", path);\n+        if let Some(session_dir) = find_metadata_hashes_for(self.tcx, cnum) {\n+            debug!(\"load_data: session_dir={:?}\", session_dir);\n+\n+            // Lock the directory we'll be reading  the hashes from.\n+            let lock_file_path = lock_file_path(&session_dir);\n+            let _lock = match flock::Lock::new(&lock_file_path,\n+                                               false,   // don't wait\n+                                               false,   // don't create the lock-file\n+                                               false) { // shared lock\n+                Ok(lock) => lock,\n+                Err(err) => {\n+                    debug!(\"Could not acquire lock on `{}` while trying to \\\n+                            load metadata hashes: {}\",\n+                            lock_file_path.display(),\n+                            err);\n+\n+                    // Could not acquire the lock. The directory is probably in\n+                    // in the process of being deleted. It's OK to just exit\n+                    // here. It's the same scenario as if the file had not\n+                    // existed in the first place.\n+                    return\n+                }\n+            };\n+\n+            let hashes_file_path = metadata_hash_import_path(&session_dir);\n+\n             let mut data = vec![];\n             match\n-                File::open(&path)\n-                .and_then(|mut file| file.read_to_end(&mut data))\n+                File::open(&hashes_file_path)\n+                     .and_then(|mut file| file.read_to_end(&mut data))\n             {\n                 Ok(_) => {\n-                    match self.load_from_data(cnum, &data) {\n+                    match self.load_from_data(cnum, &data, svh) {\n                         Ok(()) => { }\n                         Err(err) => {\n                             bug!(\"decoding error in dep-graph from `{}`: {}\",\n-                                 path.display(), err);\n+                                 &hashes_file_path.display(), err);\n                         }\n                     }\n                 }\n@@ -152,7 +177,7 @@ impl<'a, 'tcx> HashContext<'a, 'tcx> {\n                         _ => {\n                             self.tcx.sess.err(\n                                 &format!(\"could not load dep information from `{}`: {}\",\n-                                         path.display(), err));\n+                                         hashes_file_path.display(), err));\n                             return;\n                         }\n                     }\n@@ -161,11 +186,22 @@ impl<'a, 'tcx> HashContext<'a, 'tcx> {\n         }\n     }\n \n-    fn load_from_data(&mut self, cnum: ast::CrateNum, data: &[u8]) -> Result<(), Error> {\n+    fn load_from_data(&mut self,\n+                      cnum: ast::CrateNum,\n+                      data: &[u8],\n+                      expected_svh: Svh) -> Result<(), Error> {\n         debug!(\"load_from_data(cnum={})\", cnum);\n \n         // Load up the hashes for the def-ids from this crate.\n         let mut decoder = Decoder::new(data, 0);\n+        let svh_in_hashes_file = try!(Svh::decode(&mut decoder));\n+\n+        if svh_in_hashes_file != expected_svh {\n+            // We should not be able to get here. If we do, then\n+            // `fs::find_metadata_hashes_for()` has messed up.\n+            bug!(\"mismatch between SVH in crate and SVH in incr. comp. hashes\")\n+        }\n+\n         let serialized_hashes = try!(SerializedMetadataHashes::decode(&mut decoder));\n         for serialized_hash in serialized_hashes.hashes {\n             // the hashes are stored with just a def-index, which is"}, {"sha": "cc4966eadae9131f1366e7c9641a2ef6b882ceb4", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 24, "deletions": 5, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -27,7 +27,7 @@ use super::data::*;\n use super::directory::*;\n use super::dirty_clean;\n use super::hash::*;\n-use super::util::*;\n+use super::fs::*;\n \n pub type DirtyNodes = FnvHashSet<DepNode<DefPathIndex>>;\n \n@@ -45,19 +45,38 @@ pub fn load_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         return;\n     }\n \n+    match prepare_session_directory(tcx) {\n+        Ok(true) => {\n+            // We successfully allocated a session directory and there is\n+            // something in it to load, so continue\n+        }\n+        Ok(false) => {\n+            // We successfully allocated a session directory, but there is no\n+            // dep-graph data in it to load (because this is the first\n+            // compilation session with this incr. comp. dir.)\n+            return\n+        }\n+        Err(()) => {\n+            // Something went wrong while trying to allocate the session\n+            // directory. Don't try to use it any further.\n+            let _ = garbage_collect_session_directories(tcx.sess);\n+            return\n+        }\n+    }\n+\n     let _ignore = tcx.dep_graph.in_ignore();\n     load_dep_graph_if_exists(tcx, incremental_hashes_map);\n }\n \n fn load_dep_graph_if_exists<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                       incremental_hashes_map: &IncrementalHashesMap) {\n-    let dep_graph_path = dep_graph_path(tcx).unwrap();\n+    let dep_graph_path = dep_graph_path(tcx.sess);\n     let dep_graph_data = match load_data(tcx.sess, &dep_graph_path) {\n         Some(p) => p,\n         None => return // no file\n     };\n \n-    let work_products_path = tcx_work_products_path(tcx).unwrap();\n+    let work_products_path = work_products_path(tcx.sess);\n     let work_products_data = match load_data(tcx.sess, &work_products_path) {\n         Some(p) => p,\n         None => return // no file\n@@ -258,7 +277,7 @@ fn reconcile_work_products<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                    .saved_files\n                    .iter()\n                    .all(|&(_, ref file_name)| {\n-                       let path = in_incr_comp_dir(tcx.sess, &file_name).unwrap();\n+                       let path = in_incr_comp_dir_sess(tcx.sess, &file_name);\n                        path.exists()\n                    });\n             if all_files_exist {\n@@ -276,7 +295,7 @@ fn delete_dirty_work_product(tcx: TyCtxt,\n                              swp: SerializedWorkProduct) {\n     debug!(\"delete_dirty_work_product({:?})\", swp);\n     for &(_, ref file_name) in &swp.work_product.saved_files {\n-        let path = in_incr_comp_dir(tcx.sess, file_name).unwrap();\n+        let path = in_incr_comp_dir_sess(tcx.sess, file_name);\n         match fs::remove_file(&path) {\n             Ok(()) => { }\n             Err(err) => {"}, {"sha": "ba0f71971bb45e9afce432e341843b41d164816c", "filename": "src/librustc_incremental/persist/mod.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fmod.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -15,15 +15,16 @@\n mod data;\n mod directory;\n mod dirty_clean;\n+mod fs;\n mod hash;\n mod load;\n mod preds;\n mod save;\n-mod util;\n mod work_product;\n \n+pub use self::fs::finalize_session_directory;\n+pub use self::fs::in_incr_comp_dir;\n pub use self::load::load_dep_graph;\n pub use self::save::save_dep_graph;\n pub use self::save::save_work_products;\n pub use self::work_product::save_trans_partition;\n-pub use self::util::in_incr_comp_dir;"}, {"sha": "d31252be5e857295bce2ea16ffb321148e009c66", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 19, "deletions": 16, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -11,7 +11,7 @@\n use rbml::opaque::Encoder;\n use rustc::dep_graph::DepNode;\n use rustc::hir::def_id::DefId;\n-use rustc::middle::cstore::LOCAL_CRATE;\n+use rustc::hir::svh::Svh;\n use rustc::session::Session;\n use rustc::ty::TyCtxt;\n use rustc_data_structures::fnv::FnvHashMap;\n@@ -26,10 +26,11 @@ use super::data::*;\n use super::directory::*;\n use super::hash::*;\n use super::preds::*;\n-use super::util::*;\n+use super::fs::*;\n \n pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                incremental_hashes_map: &IncrementalHashesMap) {\n+                                incremental_hashes_map: &IncrementalHashesMap,\n+                                svh: Svh) {\n     debug!(\"save_dep_graph()\");\n     let _ignore = tcx.dep_graph.in_ignore();\n     let sess = tcx.sess;\n@@ -41,31 +42,31 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let query = tcx.dep_graph.query();\n     let preds = Predecessors::new(&query, &mut hcx);\n     save_in(sess,\n-            dep_graph_path(tcx),\n+            dep_graph_path(sess),\n             |e| encode_dep_graph(&preds, &mut builder, e));\n     save_in(sess,\n-            metadata_hash_path(tcx, LOCAL_CRATE),\n-            |e| encode_metadata_hashes(tcx, &preds, &mut builder, e));\n+            metadata_hash_export_path(sess),\n+            |e| encode_metadata_hashes(tcx, svh, &preds, &mut builder, e));\n }\n \n-pub fn save_work_products(sess: &Session, local_crate_name: &str) {\n+pub fn save_work_products(sess: &Session) {\n+    if sess.opts.incremental.is_none() {\n+        return;\n+    }\n+\n     debug!(\"save_work_products()\");\n     let _ignore = sess.dep_graph.in_ignore();\n-    let path = sess_work_products_path(sess, local_crate_name);\n+    let path = work_products_path(sess);\n     save_in(sess, path, |e| encode_work_products(sess, e));\n }\n \n-fn save_in<F>(sess: &Session, opt_path_buf: Option<PathBuf>, encode: F)\n+fn save_in<F>(sess: &Session, path_buf: PathBuf, encode: F)\n     where F: FnOnce(&mut Encoder) -> io::Result<()>\n {\n-    let path_buf = match opt_path_buf {\n-        Some(p) => p,\n-        None => return,\n-    };\n-\n-    // FIXME(#32754) lock file?\n-\n     // delete the old dep-graph, if any\n+    // Note: It's important that we actually delete the old file and not just\n+    // truncate and overwrite it, since it might be a shared hard-link, the\n+    // underlying data of which we don't want to modify\n     if path_buf.exists() {\n         match fs::remove_file(&path_buf) {\n             Ok(()) => {}\n@@ -155,6 +156,7 @@ pub fn encode_dep_graph(preds: &Predecessors,\n }\n \n pub fn encode_metadata_hashes(tcx: TyCtxt,\n+                              svh: Svh,\n                               preds: &Predecessors,\n                               builder: &mut DefIdDirectoryBuilder,\n                               encoder: &mut Encoder)\n@@ -220,6 +222,7 @@ pub fn encode_metadata_hashes(tcx: TyCtxt,\n     }\n \n     // Encode everything.\n+    try!(svh.encode(encoder));\n     try!(serialized_hashes.encode(encoder));\n \n     Ok(())"}, {"sha": "f1e81fdb266b9b201271281c02851e8248b16083", "filename": "src/librustc_incremental/persist/util.rs", "status": "removed", "additions": 0, "deletions": 95, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/206e7b6fc704c53b2a7174e8bec7b5f575d9bc93/src%2Flibrustc_incremental%2Fpersist%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/206e7b6fc704c53b2a7174e8bec7b5f575d9bc93/src%2Flibrustc_incremental%2Fpersist%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Futil.rs?ref=206e7b6fc704c53b2a7174e8bec7b5f575d9bc93", "patch": "@@ -1,95 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use rustc::middle::cstore::LOCAL_CRATE;\n-use rustc::session::Session;\n-use rustc::ty::TyCtxt;\n-\n-use std::fs;\n-use std::io;\n-use std::path::{Path, PathBuf};\n-use syntax::ast;\n-\n-pub fn dep_graph_path(tcx: TyCtxt) -> Option<PathBuf> {\n-    tcx_path(tcx, LOCAL_CRATE, \"local\")\n-}\n-\n-pub fn metadata_hash_path(tcx: TyCtxt, cnum: ast::CrateNum) -> Option<PathBuf> {\n-    tcx_path(tcx, cnum, \"metadata\")\n-}\n-\n-pub fn tcx_work_products_path(tcx: TyCtxt) -> Option<PathBuf> {\n-    let crate_name = tcx.crate_name(LOCAL_CRATE);\n-    sess_work_products_path(tcx.sess, &crate_name)\n-}\n-\n-pub fn sess_work_products_path(sess: &Session,\n-                               local_crate_name: &str)\n-                               -> Option<PathBuf> {\n-    let crate_disambiguator = sess.local_crate_disambiguator();\n-    path(sess, local_crate_name, &crate_disambiguator, \"work-products\")\n-}\n-\n-pub fn in_incr_comp_dir(sess: &Session, file_name: &str) -> Option<PathBuf> {\n-    sess.opts.incremental.as_ref().map(|incr_dir| incr_dir.join(file_name))\n-}\n-\n-fn tcx_path(tcx: TyCtxt,\n-            cnum: ast::CrateNum,\n-            middle: &str)\n-            -> Option<PathBuf> {\n-    path(tcx.sess, &tcx.crate_name(cnum), &tcx.crate_disambiguator(cnum), middle)\n-}\n-\n-fn path(sess: &Session,\n-        crate_name: &str,\n-        crate_disambiguator: &str,\n-        middle: &str)\n-        -> Option<PathBuf> {\n-    // For now, just save/load dep-graph from\n-    // directory/dep_graph.rbml\n-    sess.opts.incremental.as_ref().and_then(|incr_dir| {\n-        match create_dir_racy(&incr_dir) {\n-            Ok(()) => {}\n-            Err(err) => {\n-                sess.err(\n-                    &format!(\"could not create the directory `{}`: {}\",\n-                             incr_dir.display(), err));\n-                return None;\n-            }\n-        }\n-\n-        let file_name = format!(\"{}-{}.{}.bin\", crate_name, crate_disambiguator, middle);\n-\n-        Some(incr_dir.join(file_name))\n-    })\n-}\n-\n-// Like std::fs::create_dir_all, except handles concurrent calls among multiple\n-// threads or processes.\n-fn create_dir_racy(path: &Path) -> io::Result<()> {\n-    match fs::create_dir(path) {\n-        Ok(()) => return Ok(()),\n-        Err(ref e) if e.kind() == io::ErrorKind::AlreadyExists => return Ok(()),\n-        Err(ref e) if e.kind() == io::ErrorKind::NotFound => {}\n-        Err(e) => return Err(e),\n-    }\n-    match path.parent() {\n-        Some(p) => try!(create_dir_racy(p)),\n-        None => return Err(io::Error::new(io::ErrorKind::Other,\n-                                          \"failed to create whole tree\")),\n-    }\n-    match fs::create_dir(path) {\n-        Ok(()) => Ok(()),\n-        Err(ref e) if e.kind() == io::ErrorKind::AlreadyExists => Ok(()),\n-        Err(e) => Err(e),\n-    }\n-}\n-"}, {"sha": "a9ebd27ce9928fc22eec587d5420de8cf38745b1", "filename": "src/librustc_incremental/persist/work_product.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -10,7 +10,7 @@\n \n //! This module contains files for saving intermediate work-products.\n \n-use persist::util::*;\n+use persist::fs::*;\n use rustc::dep_graph::{WorkProduct, WorkProductId};\n use rustc::session::Session;\n use rustc::session::config::OutputType;\n@@ -35,7 +35,7 @@ pub fn save_trans_partition(sess: &Session,\n         files.iter()\n              .map(|&(kind, ref path)| {\n                  let file_name = format!(\"cgu-{}.{}\", cgu_name, kind.extension());\n-                 let path_in_incr_dir = in_incr_comp_dir(sess, &file_name).unwrap();\n+                 let path_in_incr_dir = in_incr_comp_dir_sess(sess, &file_name);\n                  match link_or_copy(path, &path_in_incr_dir) {\n                      Ok(_) => Some((kind, file_name)),\n                      Err(err) => {"}, {"sha": "081b4431bd7b80dfe6b9df5e7de7627705df30ea", "filename": "src/librustc_trans/back/write.rs", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3e9bed92da499d7905232d47d54300134fca13b5/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fwrite.rs?ref=3e9bed92da499d7905232d47d54300134fca13b5", "patch": "@@ -10,7 +10,7 @@\n \n use back::lto;\n use back::link::{get_linker, remove};\n-use rustc_incremental::save_trans_partition;\n+use rustc_incremental::{save_trans_partition, in_incr_comp_dir};\n use session::config::{OutputFilenames, OutputTypes, Passes, SomePasses, AllPasses};\n use session::Session;\n use session::config::{self, OutputType};\n@@ -328,8 +328,9 @@ struct CodegenContext<'a> {\n     remark: Passes,\n     // Worker thread number\n     worker: usize,\n-    // Directory where incremental data is stored (if any)\n-    incremental: Option<PathBuf>,\n+    // The incremental compilation session directory, or None if we are not\n+    // compiling incrementally\n+    incr_comp_session_dir: Option<PathBuf>\n }\n \n impl<'a> CodegenContext<'a> {\n@@ -340,7 +341,7 @@ impl<'a> CodegenContext<'a> {\n             plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n             remark: sess.opts.cg.remark.clone(),\n             worker: 0,\n-            incremental: sess.opts.incremental.clone(),\n+            incr_comp_session_dir: sess.incr_comp_session_dir_opt().map(|r| r.clone())\n         }\n     }\n }\n@@ -962,17 +963,20 @@ fn execute_work_item(cgcx: &CodegenContext,\n                                      work_item.output_names);\n             }\n             ModuleSource::Preexisting(wp) => {\n-                let incremental = cgcx.incremental.as_ref().unwrap();\n+                let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                                .as_ref()\n+                                                .unwrap();\n                 let name = &work_item.mtrans.name;\n                 for (kind, saved_file) in wp.saved_files {\n                     let obj_out = work_item.output_names.temp_path(kind, Some(name));\n-                    let source_file = incremental.join(&saved_file);\n+                    let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n+                                                       &saved_file);\n                     debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n                            work_item.mtrans.name,\n                            source_file,\n                            obj_out.display());\n                     match link_or_copy(&source_file, &obj_out) {\n-                        Ok(()) => { }\n+                        Ok(_) => { }\n                         Err(err) => {\n                             cgcx.handler.err(&format!(\"unable to copy {} to {}: {}\",\n                                                       source_file.display(),\n@@ -1018,7 +1022,7 @@ fn run_work_multithreaded(sess: &Session,\n         let mut tx = Some(tx);\n         futures.push(rx);\n \n-        let incremental = sess.opts.incremental.clone();\n+        let incr_comp_session_dir = sess.incr_comp_session_dir_opt().map(|r| r.clone());\n \n         thread::Builder::new().name(format!(\"codegen-{}\", i)).spawn(move || {\n             let diag_handler = Handler::with_emitter(true, false, box diag_emitter);\n@@ -1031,7 +1035,7 @@ fn run_work_multithreaded(sess: &Session,\n                 plugin_passes: plugin_passes,\n                 remark: remark,\n                 worker: i,\n-                incremental: incremental,\n+                incr_comp_session_dir: incr_comp_session_dir\n             };\n \n             loop {"}]}