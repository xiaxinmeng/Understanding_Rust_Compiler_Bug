{"sha": "a580421afbd6ee93aaab0ad01dee3df8343a88dc", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE1ODA0MjFhZmJkNmVlOTNhYWFiMGFkMDFkZWUzZGY4MzQzYTg4ZGM=", "commit": {"author": {"name": "Pawe\u0142 Romanowski", "email": "pawroman@gmail.com", "date": "2019-04-18T14:16:34Z"}, "committer": {"name": "Pawe\u0142 Romanowski", "email": "pawroman@gmail.com", "date": "2019-04-18T14:16:34Z"}, "message": "More cleanups for unicode.py", "tree": {"sha": "73e6c44eed2e918dccea88eeb453539a8b911856", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/73e6c44eed2e918dccea88eeb453539a8b911856"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a580421afbd6ee93aaab0ad01dee3df8343a88dc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a580421afbd6ee93aaab0ad01dee3df8343a88dc", "html_url": "https://github.com/rust-lang/rust/commit/a580421afbd6ee93aaab0ad01dee3df8343a88dc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a580421afbd6ee93aaab0ad01dee3df8343a88dc/comments", "author": {"login": "pawroman", "id": 914977, "node_id": "MDQ6VXNlcjkxNDk3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/914977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawroman", "html_url": "https://github.com/pawroman", "followers_url": "https://api.github.com/users/pawroman/followers", "following_url": "https://api.github.com/users/pawroman/following{/other_user}", "gists_url": "https://api.github.com/users/pawroman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawroman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawroman/subscriptions", "organizations_url": "https://api.github.com/users/pawroman/orgs", "repos_url": "https://api.github.com/users/pawroman/repos", "events_url": "https://api.github.com/users/pawroman/events{/privacy}", "received_events_url": "https://api.github.com/users/pawroman/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pawroman", "id": 914977, "node_id": "MDQ6VXNlcjkxNDk3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/914977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pawroman", "html_url": "https://github.com/pawroman", "followers_url": "https://api.github.com/users/pawroman/followers", "following_url": "https://api.github.com/users/pawroman/following{/other_user}", "gists_url": "https://api.github.com/users/pawroman/gists{/gist_id}", "starred_url": "https://api.github.com/users/pawroman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pawroman/subscriptions", "organizations_url": "https://api.github.com/users/pawroman/orgs", "repos_url": "https://api.github.com/users/pawroman/repos", "events_url": "https://api.github.com/users/pawroman/events{/privacy}", "received_events_url": "https://api.github.com/users/pawroman/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "89feb6d5fd38aa9b493d6fc3ca5b546c373aac31", "url": "https://api.github.com/repos/rust-lang/rust/commits/89feb6d5fd38aa9b493d6fc3ca5b546c373aac31", "html_url": "https://github.com/rust-lang/rust/commit/89feb6d5fd38aa9b493d6fc3ca5b546c373aac31"}], "stats": {"total": 48, "additions": 23, "deletions": 25}, "files": [{"sha": "447f4274c18da44dcdc6e8bd708d5ba87f60b36b", "filename": "src/libcore/unicode/unicode.py", "status": "modified", "additions": 23, "deletions": 25, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/a580421afbd6ee93aaab0ad01dee3df8343a88dc/src%2Flibcore%2Funicode%2Funicode.py", "raw_url": "https://github.com/rust-lang/rust/raw/a580421afbd6ee93aaab0ad01dee3df8343a88dc/src%2Flibcore%2Funicode%2Funicode.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Funicode%2Funicode.py?ref=a580421afbd6ee93aaab0ad01dee3df8343a88dc", "patch": "@@ -28,14 +28,14 @@\n # we don't use enum.Enum because of Python 2.7 compatibility\n class UnicodeFiles(object):\n     # ReadMe does not contain any unicode data, we\n-    # use it to extract versions.\n+    # only use it to extract versions.\n     README = \"ReadMe.txt\"\n \n     DERIVED_CORE_PROPERTIES = \"DerivedCoreProperties.txt\"\n     DERIVED_NORMALIZATION_PROPS = \"DerivedNormalizationProps.txt\"\n-    SPECIAL_CASING = \"SpecialCasing.txt\"\n-    SCRIPTS = \"Scripts.txt\"\n     PROPS = \"PropList.txt\"\n+    SCRIPTS = \"Scripts.txt\"\n+    SPECIAL_CASING = \"SpecialCasing.txt\"\n     UNICODE_DATA = \"UnicodeData.txt\"\n \n \n@@ -66,15 +66,15 @@ class UnicodeFiles(object):\n # Mapping taken from Table 12 from:\n # http://www.unicode.org/reports/tr44/#General_Category_Values\n EXPANDED_CATEGORIES = {\n-    'Lu': ['LC', 'L'], 'Ll': ['LC', 'L'], 'Lt': ['LC', 'L'],\n-    'Lm': ['L'], 'Lo': ['L'],\n-    'Mn': ['M'], 'Mc': ['M'], 'Me': ['M'],\n-    'Nd': ['N'], 'Nl': ['N'], 'No': ['N'],\n-    'Pc': ['P'], 'Pd': ['P'], 'Ps': ['P'], 'Pe': ['P'],\n-    'Pi': ['P'], 'Pf': ['P'], 'Po': ['P'],\n-    'Sm': ['S'], 'Sc': ['S'], 'Sk': ['S'], 'So': ['S'],\n-    'Zs': ['Z'], 'Zl': ['Z'], 'Zp': ['Z'],\n-    'Cc': ['C'], 'Cf': ['C'], 'Cs': ['C'], 'Co': ['C'], 'Cn': ['C'],\n+    \"Lu\": [\"LC\", \"L\"], \"Ll\": [\"LC\", \"L\"], \"Lt\": [\"LC\", \"L\"],\n+    \"Lm\": [\"L\"], \"Lo\": [\"L\"],\n+    \"Mn\": [\"M\"], \"Mc\": [\"M\"], \"Me\": [\"M\"],\n+    \"Nd\": [\"N\"], \"Nl\": [\"N\"], \"No\": [\"N\"],\n+    \"Pc\": [\"P\"], \"Pd\": [\"P\"], \"Ps\": [\"P\"], \"Pe\": [\"P\"],\n+    \"Pi\": [\"P\"], \"Pf\": [\"P\"], \"Po\": [\"P\"],\n+    \"Sm\": [\"S\"], \"Sc\": [\"S\"], \"Sk\": [\"S\"], \"So\": [\"S\"],\n+    \"Zs\": [\"Z\"], \"Zl\": [\"Z\"], \"Zp\": [\"Z\"],\n+    \"Cc\": [\"C\"], \"Cf\": [\"C\"], \"Cs\": [\"C\"], \"Co\": [\"C\"], \"Cn\": [\"C\"],\n }\n \n # these are the surrogate codepoints, which are not valid rust characters\n@@ -115,7 +115,7 @@ def fetch_files(version=None):\n     readme_content = subprocess.check_output((\"curl\", readme_url))\n \n     unicode_version = parse_unicode_version(\n-        str(readme_content, \"utf8\")\n+        readme_content.decode(\"utf8\")\n     )\n \n     download_dir = os.path.join(FETCH_DIR, unicode_version.as_str)\n@@ -415,7 +415,7 @@ def compute_trie(rawdata, chunksize):\n     child_data = []\n     for i in range(len(rawdata) // chunksize):\n         data = rawdata[i * chunksize: (i + 1) * chunksize]\n-        child = '|'.join(map(str, data))\n+        child = \"|\".join(map(str, data))\n         if child not in childmap:\n             childmap[child] = len(childmap)\n             child_data.extend(data)\n@@ -444,34 +444,34 @@ def emit_bool_trie(f, name, t_data, is_pub=True):\n         pub_string = \"pub \"\n     f.write(\"    %sconst %s: &super::BoolTrie = &super::BoolTrie {\\n\" % (pub_string, name))\n     f.write(\"        r1: [\\n\")\n-    data = ','.join('0x%016x' % chunk for chunk in chunks[0:0x800 // chunk_size])\n+    data = \",\".join(\"0x%016x\" % chunk for chunk in chunks[0:0x800 // chunk_size])\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n \n     # 0x800..0x10000 trie\n     (r2, r3) = compute_trie(chunks[0x800 // chunk_size : 0x10000 // chunk_size], 64 // chunk_size)\n     f.write(\"        r2: [\\n\")\n-    data = ','.join(str(node) for node in r2)\n+    data = \",\".join(str(node) for node in r2)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n     f.write(\"        r3: &[\\n\")\n-    data = ','.join('0x%016x' % chunk for chunk in r3)\n+    data = \",\".join(\"0x%016x\" % chunk for chunk in r3)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n \n     # 0x10000..0x110000 trie\n     (mid, r6) = compute_trie(chunks[0x10000 // chunk_size : 0x110000 // chunk_size], 64 // chunk_size)\n     (r4, r5) = compute_trie(mid, 64)\n     f.write(\"        r4: [\\n\")\n-    data = ','.join(str(node) for node in r4)\n+    data = \",\".join(str(node) for node in r4)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n     f.write(\"        r5: &[\\n\")\n-    data = ','.join(str(node) for node in r5)\n+    data = \",\".join(str(node) for node in r5)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n     f.write(\"        r6: &[\\n\")\n-    data = ','.join('0x%016x' % chunk for chunk in r6)\n+    data = \",\".join(\"0x%016x\" % chunk for chunk in r6)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n \n@@ -497,12 +497,12 @@ def emit_small_bool_trie(f, name, t_data, is_pub=True):\n     (r1, r2) = compute_trie(chunks, 1)\n \n     f.write(\"        r1: &[\\n\")\n-    data = ','.join(str(node) for node in r1)\n+    data = \",\".join(str(node) for node in r1)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n \n     f.write(\"        r2: &[\\n\")\n-    data = ','.join('0x%016x' % node for node in r2)\n+    data = \",\".join(\"0x%016x\" % node for node in r2)\n     format_table_content(f, data, 12)\n     f.write(\"\\n        ],\\n\")\n \n@@ -599,11 +599,9 @@ def main():\n     print(\"Using Unicode version: {}\".format(unicode_version.as_str))\n \n     tables_rs_path = os.path.join(THIS_DIR, \"tables.rs\")\n-    if os.path.exists(tables_rs_path):\n-        os.remove(tables_rs_path)\n \n+    # will overwrite the file if it exists\n     with open(tables_rs_path, \"w\") as rf:\n-        # write the file's preamble\n         rf.write(PREAMBLE)\n \n         unicode_version_notice = textwrap.dedent(\"\"\""}]}