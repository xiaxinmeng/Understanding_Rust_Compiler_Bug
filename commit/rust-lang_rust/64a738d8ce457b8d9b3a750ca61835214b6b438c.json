{"sha": "64a738d8ce457b8d9b3a750ca61835214b6b438c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY0YTczOGQ4Y2U0NTdiOGQ5YjNhNzUwY2E2MTgzNTIxNGI2YjQzOGM=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-08-20T15:13:01Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-08-31T13:22:52Z"}, "message": "Support local ThinLTO with incremental compilation.", "tree": {"sha": "9c4dd1fe97e19a1cbc21ecdea38c6cdebdabf992", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/9c4dd1fe97e19a1cbc21ecdea38c6cdebdabf992"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/64a738d8ce457b8d9b3a750ca61835214b6b438c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/64a738d8ce457b8d9b3a750ca61835214b6b438c", "html_url": "https://github.com/rust-lang/rust/commit/64a738d8ce457b8d9b3a750ca61835214b6b438c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/64a738d8ce457b8d9b3a750ca61835214b6b438c/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "72c1993b8e9ec095bab299b4cc298be7eb9bf1ee", "url": "https://api.github.com/repos/rust-lang/rust/commits/72c1993b8e9ec095bab299b4cc298be7eb9bf1ee", "html_url": "https://github.com/rust-lang/rust/commit/72c1993b8e9ec095bab299b4cc298be7eb9bf1ee"}], "stats": {"total": 900, "additions": 634, "deletions": 266}, "files": [{"sha": "1c883eeed966cad529a2f8a0aefeb421f130e65e", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -878,11 +878,12 @@ pub struct WorkProduct {\n     pub saved_files: Vec<(WorkProductFileKind, String)>,\n }\n \n-#[derive(Clone, Copy, Debug, RustcEncodable, RustcDecodable)]\n+#[derive(Clone, Copy, Debug, RustcEncodable, RustcDecodable, PartialEq)]\n pub enum WorkProductFileKind {\n     Object,\n     Bytecode,\n     BytecodeCompressed,\n+    PreThinLtoBytecode,\n }\n \n pub(super) struct CurrentDepGraph {"}, {"sha": "ee3fabc58d53f6edc6e6b150a1b652727991587b", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -68,7 +68,7 @@ pub enum OptLevel {\n     SizeMin,    // -Oz\n }\n \n-#[derive(Clone, Copy, PartialEq, Hash)]\n+#[derive(Clone, Copy, PartialEq, Hash, Debug)]\n pub enum Lto {\n     /// Don't do any LTO whatsoever\n     No,"}, {"sha": "778c388c7dec71181c88bdb7da7b009c6f8a1c46", "filename": "src/librustc/session/mod.rs", "status": "modified", "additions": 12, "deletions": 7, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fsession%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc%2Fsession%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fmod.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -580,11 +580,6 @@ impl Session {\n             return config::Lto::No;\n         }\n \n-        // Right now ThinLTO isn't compatible with incremental compilation.\n-        if self.opts.incremental.is_some() {\n-            return config::Lto::No;\n-        }\n-\n         // Now we're in \"defaults\" territory. By default we enable ThinLTO for\n         // optimized compiles (anything greater than O0).\n         match self.opts.optimize {\n@@ -1177,8 +1172,18 @@ pub fn build_session_(\n // commandline argument, you can do so here.\n fn validate_commandline_args_with_session_available(sess: &Session) {\n \n-    if sess.lto() != Lto::No && sess.opts.incremental.is_some() {\n-        sess.err(\"can't perform LTO when compiling incrementally\");\n+    if sess.opts.incremental.is_some() {\n+        match sess.lto() {\n+            Lto::Yes |\n+            Lto::Thin |\n+            Lto::Fat => {\n+                sess.err(\"can't perform LTO when compiling incrementally\");\n+            }\n+            Lto::ThinLocal |\n+            Lto::No => {\n+                // This is fine\n+            }\n+        }\n     }\n \n     // Since we don't know if code in an rlib will be linked to statically or"}, {"sha": "b711502b14b7fb1af4222d0859fbf82a03e75d06", "filename": "src/librustc_codegen_llvm/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2FCargo.toml?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -14,6 +14,7 @@ cc = \"1.0.1\"\n num_cpus = \"1.0\"\n rustc-demangle = \"0.1.4\"\n rustc_llvm = { path = \"../librustc_llvm\" }\n+memmap = \"0.6\"\n \n [features]\n # This is used to convince Cargo to separately cache builds of `rustc_codegen_llvm`"}, {"sha": "9813134992760391112350fbc51c71e67788e2bc", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 88, "deletions": 20, "changes": 108, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -16,13 +16,14 @@ use errors::{FatalError, Handler};\n use llvm::archive_ro::ArchiveRO;\n use llvm::{True, False};\n use llvm;\n+use memmap;\n use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::exported_symbols::SymbolExportLevel;\n use rustc::session::config::{self, Lto};\n use rustc::util::common::time_ext;\n-use rustc_data_structures::fx::FxHashMap;\n+use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use time_graph::Timeline;\n-use {ModuleCodegen, ModuleLlvm, ModuleKind, ModuleSource};\n+use {ModuleCodegen, ModuleLlvm, ModuleKind};\n \n use libc;\n \n@@ -82,8 +83,8 @@ impl LtoModuleCodegen {\n                 let module = module.take().unwrap();\n                 {\n                     let config = cgcx.config(module.kind);\n-                    let llmod = module.llvm().unwrap().llmod();\n-                    let tm = &*module.llvm().unwrap().tm;\n+                    let llmod = module.module_llvm.llmod();\n+                    let tm = &*module.module_llvm.tm;\n                     run_pass_manager(cgcx, tm, llmod, config, false);\n                     timeline.record(\"fat-done\");\n                 }\n@@ -106,6 +107,7 @@ impl LtoModuleCodegen {\n \n pub(crate) fn run(cgcx: &CodegenContext,\n                   modules: Vec<ModuleCodegen>,\n+                  import_only_modules: Vec<(SerializedModule, CString)>,\n                   timeline: &mut Timeline)\n     -> Result<Vec<LtoModuleCodegen>, FatalError>\n {\n@@ -194,19 +196,33 @@ pub(crate) fn run(cgcx: &CodegenContext,\n         }\n     }\n \n-    let arr = symbol_white_list.iter().map(|c| c.as_ptr()).collect::<Vec<_>>();\n+    let symbol_white_list = symbol_white_list.iter()\n+                                             .map(|c| c.as_ptr())\n+                                             .collect::<Vec<_>>();\n     match cgcx.lto {\n         Lto::Yes | // `-C lto` == fat LTO by default\n         Lto::Fat => {\n-            fat_lto(cgcx, &diag_handler, modules, upstream_modules, &arr, timeline)\n+            assert!(import_only_modules.is_empty());\n+            fat_lto(cgcx,\n+                    &diag_handler,\n+                    modules,\n+                    upstream_modules,\n+                    &symbol_white_list,\n+                    timeline)\n         }\n         Lto::Thin |\n         Lto::ThinLocal => {\n             if cgcx.opts.debugging_opts.cross_lang_lto.enabled() {\n                 unreachable!(\"We should never reach this case if the LTO step \\\n                               is deferred to the linker\");\n             }\n-            thin_lto(cgcx, &diag_handler, modules, upstream_modules, &arr, timeline)\n+            thin_lto(cgcx,\n+                     &diag_handler,\n+                     modules,\n+                     upstream_modules,\n+                     import_only_modules,\n+                     &symbol_white_list,\n+                     timeline)\n         }\n         Lto::No => unreachable!(),\n     }\n@@ -236,7 +252,7 @@ fn fat_lto(cgcx: &CodegenContext,\n         .filter(|&(_, module)| module.kind == ModuleKind::Regular)\n         .map(|(i, module)| {\n             let cost = unsafe {\n-                llvm::LLVMRustModuleCost(module.llvm().unwrap().llmod())\n+                llvm::LLVMRustModuleCost(module.module_llvm.llmod())\n             };\n             (cost, i)\n         })\n@@ -246,7 +262,7 @@ fn fat_lto(cgcx: &CodegenContext,\n     let mut serialized_bitcode = Vec::new();\n     {\n         let (llcx, llmod) = {\n-            let llvm = module.llvm().expect(\"can't lto pre-codegened modules\");\n+            let llvm = &module.module_llvm;\n             (&llvm.llcx, llvm.llmod())\n         };\n         info!(\"using {:?} as a base module\", module.name);\n@@ -262,8 +278,7 @@ fn fat_lto(cgcx: &CodegenContext,\n         // way we know of to do that is to serialize them to a string and them parse\n         // them later. Not great but hey, that's why it's \"fat\" LTO, right?\n         for module in modules {\n-            let llvm = module.llvm().expect(\"can't lto pre-codegened modules\");\n-            let buffer = ModuleBuffer::new(llvm.llmod());\n+            let buffer = ModuleBuffer::new(module.module_llvm.llmod());\n             let llmod_id = CString::new(&module.name[..]).unwrap();\n             serialized_modules.push((SerializedModule::Local(buffer), llmod_id));\n         }\n@@ -373,6 +388,7 @@ fn thin_lto(cgcx: &CodegenContext,\n             diag_handler: &Handler,\n             modules: Vec<ModuleCodegen>,\n             serialized_modules: Vec<(SerializedModule, CString)>,\n+            import_only_modules: Vec<(SerializedModule, CString)>,\n             symbol_white_list: &[*const libc::c_char],\n             timeline: &mut Timeline)\n     -> Result<Vec<LtoModuleCodegen>, FatalError>\n@@ -393,9 +409,8 @@ fn thin_lto(cgcx: &CodegenContext,\n         //        analysis!\n         for (i, module) in modules.iter().enumerate() {\n             info!(\"local module: {} - {}\", i, module.name);\n-            let llvm = module.llvm().expect(\"can't lto precodegened module\");\n             let name = CString::new(module.name.clone()).unwrap();\n-            let buffer = ThinBuffer::new(llvm.llmod());\n+            let buffer = ThinBuffer::new(module.module_llvm.llmod());\n             thin_modules.push(llvm::ThinLTOModule {\n                 identifier: name.as_ptr(),\n                 data: buffer.data().as_ptr(),\n@@ -434,6 +449,22 @@ fn thin_lto(cgcx: &CodegenContext,\n             module_names.push(name);\n         }\n \n+        // All the modules collected up to this point we actually want to\n+        // optimize. The `import_only_modules` below need to be in the list of\n+        // available modules but we don't need to run optimizations for them\n+        // since we already have their optimized version cached.\n+        let modules_to_optimize = module_names.len();\n+        for (module, name) in import_only_modules {\n+            info!(\"foreign module {:?}\", name);\n+            thin_modules.push(llvm::ThinLTOModule {\n+                identifier: name.as_ptr(),\n+                data: module.data().as_ptr(),\n+                len: module.data().len(),\n+            });\n+            serialized.push(module);\n+            module_names.push(name);\n+        }\n+\n         // Delegate to the C++ bindings to create some data here. Once this is a\n         // tried-and-true interface we may wish to try to upstream some of this\n         // to LLVM itself, right now we reimplement a lot of what they do\n@@ -450,7 +481,21 @@ fn thin_lto(cgcx: &CodegenContext,\n         // Save the ThinLTO import information for incremental compilation.\n         if let Some(ref incr_comp_session_dir) = cgcx.incr_comp_session_dir {\n             let path = incr_comp_session_dir.join(THIN_LTO_IMPORTS_INCR_COMP_FILE_NAME);\n-            let imports = ThinLTOImports::from_thin_lto_data(data);\n+\n+            // The import information from the current compilation session. It\n+            // does not contain info about modules that have been loaded from\n+            // the cache instead of having been recompiled...\n+            let current_imports = ThinLTOImports::from_thin_lto_data(data);\n+\n+            // ... so we load this additional information from the previous\n+            // cache file if necessary.\n+            let imports = if path.exists() {\n+                let prev_imports = ThinLTOImports::load_from_file(&path).unwrap();\n+                prev_imports.update(current_imports, &module_names)\n+            } else {\n+                current_imports\n+            };\n+\n             if let Err(err) = imports.save_to_file(&path) {\n                 let msg = format!(\"Error while writing ThinLTO import data: {}\",\n                                   err);\n@@ -472,7 +517,7 @@ fn thin_lto(cgcx: &CodegenContext,\n             serialized_modules: serialized,\n             module_names,\n         });\n-        Ok((0..shared.module_names.len()).map(|i| {\n+        Ok((0..modules_to_optimize).map(|i| {\n             LtoModuleCodegen::Thin(ThinModule {\n                 shared: shared.clone(),\n                 idx: i,\n@@ -546,13 +591,15 @@ fn run_pass_manager(cgcx: &CodegenContext,\n pub enum SerializedModule {\n     Local(ModuleBuffer),\n     FromRlib(Vec<u8>),\n+    FromUncompressedFile(memmap::Mmap, File),\n }\n \n impl SerializedModule {\n     fn data(&self) -> &[u8] {\n         match *self {\n             SerializedModule::Local(ref m) => m.data(),\n             SerializedModule::FromRlib(ref m) => m,\n+            SerializedModule::FromUncompressedFile(ref m, _) => m,\n         }\n     }\n }\n@@ -682,16 +729,16 @@ impl ThinModule {\n             write::llvm_err(&diag_handler, msg)\n         })? as *const _;\n         let module = ModuleCodegen {\n-            source: ModuleSource::Codegened(ModuleLlvm {\n+            module_llvm: ModuleLlvm {\n                 llmod_raw,\n                 llcx,\n                 tm,\n-            }),\n+            },\n             name: self.name().to_string(),\n             kind: ModuleKind::Regular,\n         };\n         {\n-            let llmod = module.llvm().unwrap().llmod();\n+            let llmod = module.module_llvm.llmod();\n             cgcx.save_temp_bitcode(&module, \"thin-lto-input\");\n \n             // Before we do much else find the \"main\" `DICompileUnit` that we'll be\n@@ -787,7 +834,7 @@ impl ThinModule {\n             // little differently.\n             info!(\"running thin lto passes over {}\", module.name);\n             let config = cgcx.config(module.kind);\n-            run_pass_manager(cgcx, module.llvm().unwrap().tm, llmod, config, true);\n+            run_pass_manager(cgcx, module.module_llvm.tm, llmod, config, true);\n             cgcx.save_temp_bitcode(&module, \"thin-lto-after-pm\");\n             timeline.record(\"thin-done\");\n         }\n@@ -809,6 +856,26 @@ impl ThinLTOImports {\n         }\n     }\n \n+    pub fn modules_imported_by(&self, llvm_module_name: &str) -> &[String] {\n+        self.imports.get(llvm_module_name).map(|v| &v[..]).unwrap_or(&[])\n+    }\n+\n+    pub fn update(mut self, new: ThinLTOImports, module_names: &[CString]) -> ThinLTOImports {\n+        let module_names: FxHashSet<_> = module_names.iter().map(|name| {\n+            name.clone().into_string().unwrap()\n+        }).collect();\n+\n+        // Remove all modules that don't exist anymore.\n+        self.imports.retain(|k, _| module_names.contains(k));\n+\n+        // Overwrite old values\n+        for (importing_module, imported_modules) in new.imports {\n+            self.imports.insert(importing_module, imported_modules);\n+        }\n+\n+        self\n+    }\n+\n     /// Load the ThinLTO import map from ThinLTOData.\n     unsafe fn from_thin_lto_data(data: *const llvm::ThinLTOData) -> ThinLTOImports {\n         fn module_name_to_str(c_str: &CStr) -> &str {\n@@ -832,6 +899,7 @@ impl ThinLTOImports {\n             if !map.imports.contains_key(importing_module_name) {\n                 map.imports.insert(importing_module_name.to_owned(), vec![]);\n             }\n+\n             map.imports\n                .get_mut(importing_module_name)\n                .unwrap()\n@@ -888,4 +956,4 @@ impl ThinLTOImports {\n             imports\n         })\n     }\n-}\n\\ No newline at end of file\n+}"}, {"sha": "e1d69db83b99d0b947c9cbf9af92188147b25b0c", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 385, "deletions": 156, "changes": 541, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -10,14 +10,16 @@\n \n use attributes;\n use back::bytecode::{self, RLIB_BYTECODE_EXTENSION};\n-use back::lto::{self, ModuleBuffer, ThinBuffer};\n+use back::lto::{self, ModuleBuffer, ThinBuffer, SerializedModule};\n use back::link::{self, get_linker, remove};\n use back::command::Command;\n use back::linker::LinkerInfo;\n use back::symbol_export::ExportedSymbols;\n use base;\n use consts;\n-use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir, in_incr_comp_dir};\n+use memmap;\n+use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir,\n+                        in_incr_comp_dir, in_incr_comp_dir_sess};\n use rustc::dep_graph::{WorkProduct, WorkProductId, WorkProductFileKind};\n use rustc::middle::cstore::EncodedMetadata;\n use rustc::session::config::{self, OutputFilenames, OutputType, Passes, Sanitizer, Lto};\n@@ -26,7 +28,8 @@ use rustc::util::nodemap::FxHashMap;\n use time_graph::{self, TimeGraph, Timeline};\n use llvm::{self, DiagnosticInfo, PassManager, SMDiagnostic};\n use llvm_util;\n-use {CodegenResults, ModuleSource, ModuleCodegen, CompiledModule, ModuleKind};\n+use {CodegenResults, ModuleCodegen, CompiledModule, ModuleKind, ModuleLlvm,\n+     CachedModuleCodegen};\n use CrateInfo;\n use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n use rustc::ty::TyCtxt;\n@@ -84,6 +87,8 @@ pub const TLS_MODEL_ARGS : [(&'static str, llvm::ThreadLocalMode); 4] = [\n     (\"local-exec\", llvm::ThreadLocalMode::LocalExec),\n ];\n \n+const PRE_THIN_LTO_BC_EXT: &str = \"pre-thin-lto.bc\";\n+\n pub fn llvm_err(handler: &errors::Handler, msg: String) -> FatalError {\n     match llvm::last_error() {\n         Some(err) => handler.fatal(&format!(\"{}: {}\", msg, err)),\n@@ -224,6 +229,7 @@ pub struct ModuleConfig {\n \n     // Flags indicating which outputs to produce.\n     emit_no_opt_bc: bool,\n+    emit_pre_thin_lto_bc: bool,\n     emit_bc: bool,\n     emit_bc_compressed: bool,\n     emit_lto_bc: bool,\n@@ -260,6 +266,7 @@ impl ModuleConfig {\n             pgo_use: String::new(),\n \n             emit_no_opt_bc: false,\n+            emit_pre_thin_lto_bc: false,\n             emit_bc: false,\n             emit_bc_compressed: false,\n             emit_lto_bc: false,\n@@ -392,7 +399,7 @@ impl CodegenContext {\n             let cgu = Some(&module.name[..]);\n             let path = self.output_filenames.temp_path_ext(&ext, cgu);\n             let cstr = path2cstr(&path);\n-            let llmod = module.llvm().unwrap().llmod();\n+            let llmod = module.module_llvm.llmod();\n             llvm::LLVMWriteBitcodeToFile(llmod, cstr.as_ptr());\n         }\n     }\n@@ -495,13 +502,9 @@ unsafe fn optimize(cgcx: &CodegenContext,\n                    timeline: &mut Timeline)\n     -> Result<(), FatalError>\n {\n-    let (llmod, llcx, tm) = match module.source {\n-        ModuleSource::Codegened(ref llvm) => (llvm.llmod(), &*llvm.llcx, &*llvm.tm),\n-        ModuleSource::Preexisting(_) => {\n-            bug!(\"optimize_and_codegen: called with ModuleSource::Preexisting\")\n-        }\n-    };\n-\n+    let llmod = module.module_llvm.llmod();\n+    let llcx = &*module.module_llvm.llcx;\n+    let tm = &*module.module_llvm.tm;\n     let _handlers = DiagnosticHandlers::new(cgcx, diag_handler, llcx);\n \n     let module_name = module.name.clone();\n@@ -622,20 +625,28 @@ unsafe fn optimize(cgcx: &CodegenContext,\n         // Deallocate managers that we're now done with\n         llvm::LLVMDisposePassManager(fpm);\n         llvm::LLVMDisposePassManager(mpm);\n+\n+        if config.emit_pre_thin_lto_bc {\n+            let out = cgcx.output_filenames.temp_path_ext(PRE_THIN_LTO_BC_EXT,\n+                                                          module_name);\n+            let out = path2cstr(&out);\n+            llvm::LLVMWriteBitcodeToFile(llmod, out.as_ptr());\n+        }\n     }\n     Ok(())\n }\n \n fn generate_lto_work(cgcx: &CodegenContext,\n-                     modules: Vec<ModuleCodegen>)\n+                     modules: Vec<ModuleCodegen>,\n+                     import_only_modules: Vec<(SerializedModule, CString)>)\n     -> Vec<(WorkItem, u64)>\n {\n     let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n         tg.start(CODEGEN_WORKER_TIMELINE,\n                  CODEGEN_WORK_PACKAGE_KIND,\n                  \"generate lto\")\n     }).unwrap_or(Timeline::noop());\n-    let lto_modules = lto::run(cgcx, modules, &mut timeline)\n+    let lto_modules = lto::run(cgcx, modules, import_only_modules, &mut timeline)\n         .unwrap_or_else(|e| e.raise());\n \n     lto_modules.into_iter().map(|module| {\n@@ -653,12 +664,9 @@ unsafe fn codegen(cgcx: &CodegenContext,\n {\n     timeline.record(\"codegen\");\n     {\n-        let (llmod, llcx, tm) = match module.source {\n-            ModuleSource::Codegened(ref llvm) => (llvm.llmod(), &*llvm.llcx, &*llvm.tm),\n-            ModuleSource::Preexisting(_) => {\n-                bug!(\"codegen: called with ModuleSource::Preexisting\")\n-            }\n-        };\n+        let llmod = module.module_llvm.llmod();\n+        let llcx = &*module.module_llvm.llcx;\n+        let tm = &*module.module_llvm.tm;\n         let module_name = module.name.clone();\n         let module_name = Some(&module_name[..]);\n         let handlers = DiagnosticHandlers::new(cgcx, diag_handler, llcx);\n@@ -912,6 +920,20 @@ fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n     sess.opts.output_types.contains_key(&OutputType::Exe)\n }\n \n+fn need_pre_thin_lto_bitcode_for_incr_comp(sess: &Session) -> bool {\n+    if sess.opts.incremental.is_none() {\n+        return false\n+    }\n+\n+    match sess.lto() {\n+        Lto::Yes |\n+        Lto::Fat |\n+        Lto::No => false,\n+        Lto::Thin |\n+        Lto::ThinLocal => true,\n+    }\n+}\n+\n pub fn start_async_codegen(tcx: TyCtxt,\n                                time_graph: Option<TimeGraph>,\n                                metadata: EncodedMetadata,\n@@ -970,6 +992,7 @@ pub fn start_async_codegen(tcx: TyCtxt,\n     // Save all versions of the bytecode if we're saving our temporaries.\n     if sess.opts.cg.save_temps {\n         modules_config.emit_no_opt_bc = true;\n+        modules_config.emit_pre_thin_lto_bc = true;\n         modules_config.emit_bc = true;\n         modules_config.emit_lto_bc = true;\n         metadata_config.emit_bc = true;\n@@ -984,6 +1007,9 @@ pub fn start_async_codegen(tcx: TyCtxt,\n         allocator_config.emit_bc_compressed = true;\n     }\n \n+    modules_config.emit_pre_thin_lto_bc =\n+        need_pre_thin_lto_bitcode_for_incr_comp(sess);\n+\n     modules_config.no_integrated_as = tcx.sess.opts.cg.no_integrated_as ||\n         tcx.sess.target.target.options.no_integrated_as;\n \n@@ -1056,15 +1082,16 @@ pub fn start_async_codegen(tcx: TyCtxt,\n \n fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n     sess: &Session,\n-    compiled_modules: &CompiledModules\n+    compiled_modules: &CompiledModules,\n+    output_filenames: &OutputFilenames,\n ) -> FxHashMap<WorkProductId, WorkProduct> {\n     let mut work_products = FxHashMap::default();\n \n     if sess.opts.incremental.is_none() {\n         return work_products;\n     }\n \n-    for module in compiled_modules.modules.iter() {\n+    for module in compiled_modules.modules.iter().filter(|m| m.kind == ModuleKind::Regular) {\n         let mut files = vec![];\n \n         if let Some(ref path) = module.object {\n@@ -1077,6 +1104,13 @@ fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n             files.push((WorkProductFileKind::BytecodeCompressed, path.clone()));\n         }\n \n+        let pre_thin_lto_bytecode_path =\n+            output_filenames.temp_path_ext(PRE_THIN_LTO_BC_EXT, Some(&module.name));\n+\n+        if pre_thin_lto_bytecode_path.exists() {\n+            files.push((WorkProductFileKind::PreThinLtoBytecode, pre_thin_lto_bytecode_path));\n+        }\n+\n         if let Some((id, product)) =\n                 copy_cgu_workproducts_to_incr_comp_cache_dir(sess, &module.name, &files) {\n             work_products.insert(id, product);\n@@ -1236,28 +1270,43 @@ fn produce_final_output_artifacts(sess: &Session,\n     // These are used in linking steps and will be cleaned up afterward.\n }\n \n-pub(crate) fn dump_incremental_data(codegen_results: &CodegenResults) {\n-    println!(\"[incremental] Re-using {} out of {} modules\",\n-              codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n-              codegen_results.modules.len());\n+pub(crate) fn dump_incremental_data(_codegen_results: &CodegenResults) {\n+    // FIXME(mw): This does not work at the moment because the situation has\n+    //            become more complicated due to incremental LTO. Now a CGU\n+    //            can have more than two caching states.\n+    // println!(\"[incremental] Re-using {} out of {} modules\",\n+    //           codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n+    //           codegen_results.modules.len());\n }\n \n enum WorkItem {\n+    /// Optimize a newly codegened, totally unoptimized module.\n     Optimize(ModuleCodegen),\n+    /// Copy the post-LTO artifacts from the incremental cache to the output\n+    /// directory.\n+    CopyPostLtoArtifacts(CachedModuleCodegen),\n+    /// Load the pre-LTO version of a module from the incremental cache, so it\n+    /// can be run through LTO again.\n+    LoadPreLtoModule(CachedModuleCodegen),\n+    /// Perform (Thin)LTO on the given module.\n     LTO(lto::LtoModuleCodegen),\n }\n \n impl WorkItem {\n-    fn kind(&self) -> ModuleKind {\n+    fn module_kind(&self) -> ModuleKind {\n         match *self {\n             WorkItem::Optimize(ref m) => m.kind,\n+            WorkItem::CopyPostLtoArtifacts(_) |\n+            WorkItem::LoadPreLtoModule(_) |\n             WorkItem::LTO(_) => ModuleKind::Regular,\n         }\n     }\n \n     fn name(&self) -> String {\n         match *self {\n             WorkItem::Optimize(ref m) => format!(\"optimize: {}\", m.name),\n+            WorkItem::LoadPreLtoModule(ref m) => format!(\"load pre-lto module: {}\", m.name),\n+            WorkItem::CopyPostLtoArtifacts(ref m) => format!(\"copy post LTO artifacts: {}\", m.name),\n             WorkItem::LTO(ref m) => format!(\"lto: {}\", m.name()),\n         }\n     }\n@@ -1273,141 +1322,254 @@ fn execute_work_item(cgcx: &CodegenContext,\n                      timeline: &mut Timeline)\n     -> Result<WorkItemResult, FatalError>\n {\n+    match work_item {\n+        work_item @ WorkItem::Optimize(_) => {\n+            execute_optimize_work_item(cgcx, work_item, timeline)\n+        }\n+        work_item @ WorkItem::LoadPreLtoModule(_) => {\n+            execute_load_pre_lto_mod_work_item(cgcx, work_item, timeline)\n+        }\n+        work_item @ WorkItem::CopyPostLtoArtifacts(_) => {\n+            execute_copy_from_cache_work_item(cgcx, work_item, timeline)\n+        }\n+        work_item @ WorkItem::LTO(_) => {\n+            execute_lto_work_item(cgcx, work_item, timeline)\n+        }\n+    }\n+}\n+\n+fn execute_optimize_work_item(cgcx: &CodegenContext,\n+                              work_item: WorkItem,\n+                              timeline: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let config = cgcx.config(work_item.module_kind());\n+\n+    let module = if let WorkItem::Optimize(module) = work_item {\n+        module\n+    } else {\n+        bug!(\"execute_optimize_work_item() called with non-WorkItem::Optimize\");\n+    };\n+\n     let diag_handler = cgcx.create_diag_handler();\n-    let config = cgcx.config(work_item.kind());\n-    let module = match work_item {\n-        WorkItem::Optimize(module) => module,\n-        WorkItem::LTO(mut lto) => {\n-            unsafe {\n-                let module = lto.optimize(cgcx, timeline)?;\n-                let module = codegen(cgcx, &diag_handler, module, config, timeline)?;\n-                return Ok(WorkItemResult::Compiled(module))\n-            }\n+\n+    unsafe {\n+        optimize(cgcx, &diag_handler, &module, config, timeline)?;\n+    }\n+\n+    let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n+\n+    // After we've done the initial round of optimizations we need to\n+    // decide whether to synchronously codegen this module or ship it\n+    // back to the coordinator thread for further LTO processing (which\n+    // has to wait for all the initial modules to be optimized).\n+    //\n+    // Here we dispatch based on the `cgcx.lto` and kind of module we're\n+    // codegenning...\n+    let needs_lto = match cgcx.lto {\n+        Lto::No => false,\n+\n+        // If the linker does LTO, we don't have to do it. Note that we\n+        // keep doing full LTO, if it is requested, as not to break the\n+        // assumption that the output will be a single module.\n+        Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n+\n+        // Here we've got a full crate graph LTO requested. We ignore\n+        // this, however, if the crate type is only an rlib as there's\n+        // no full crate graph to process, that'll happen later.\n+        //\n+        // This use case currently comes up primarily for targets that\n+        // require LTO so the request for LTO is always unconditionally\n+        // passed down to the backend, but we don't actually want to do\n+        // anything about it yet until we've got a final product.\n+        Lto::Yes | Lto::Fat | Lto::Thin => {\n+            cgcx.crate_types.len() != 1 ||\n+                cgcx.crate_types[0] != config::CrateType::Rlib\n+        }\n+\n+        // When we're automatically doing ThinLTO for multi-codegen-unit\n+        // builds we don't actually want to LTO the allocator modules if\n+        // it shows up. This is due to various linker shenanigans that\n+        // we'll encounter later.\n+        //\n+        // Additionally here's where we also factor in the current LLVM\n+        // version. If it doesn't support ThinLTO we skip this.\n+        Lto::ThinLocal => {\n+            module.kind != ModuleKind::Allocator &&\n+                unsafe { llvm::LLVMRustThinLTOAvailable() }\n         }\n     };\n-    let module_name = module.name.clone();\n \n-    let pre_existing = match module.source {\n-        ModuleSource::Codegened(_) => None,\n-        ModuleSource::Preexisting(ref wp) => Some(wp.clone()),\n+    // Metadata modules never participate in LTO regardless of the lto\n+    // settings.\n+    let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n+\n+    if needs_lto {\n+        Ok(WorkItemResult::NeedsLTO(module))\n+    } else {\n+        let module = unsafe {\n+            codegen(cgcx, &diag_handler, module, config, timeline)?\n+        };\n+        Ok(WorkItemResult::Compiled(module))\n+    }\n+}\n+\n+fn execute_copy_from_cache_work_item(cgcx: &CodegenContext,\n+                                     work_item: WorkItem,\n+                                     _: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let config = cgcx.config(work_item.module_kind());\n+\n+    let module = if let WorkItem::CopyPostLtoArtifacts(module) = work_item {\n+        module\n+    } else {\n+        bug!(\"execute_copy_from_cache_work_item() called with wrong WorkItem kind.\")\n     };\n \n-    if let Some(wp) = pre_existing {\n-        let incr_comp_session_dir = cgcx.incr_comp_session_dir\n-                                        .as_ref()\n-                                        .unwrap();\n-        let name = &module.name;\n-        let mut object = None;\n-        let mut bytecode = None;\n-        let mut bytecode_compressed = None;\n-        for (kind, saved_file) in wp.saved_files {\n-            let obj_out = match kind {\n-                WorkProductFileKind::Object => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Object, Some(name));\n-                    object = Some(path.clone());\n-                    path\n-                }\n-                WorkProductFileKind::Bytecode => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Bitcode, Some(name));\n-                    bytecode = Some(path.clone());\n-                    path\n-                }\n-                WorkProductFileKind::BytecodeCompressed => {\n-                    let path = cgcx.output_filenames.temp_path(OutputType::Bitcode, Some(name))\n-                        .with_extension(RLIB_BYTECODE_EXTENSION);\n-                    bytecode_compressed = Some(path.clone());\n-                    path\n-                }\n-            };\n-            let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n-                                               &saved_file);\n-            debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n-                   module.name,\n-                   source_file,\n-                   obj_out.display());\n-            match link_or_copy(&source_file, &obj_out) {\n-                Ok(_) => { }\n-                Err(err) => {\n-                    diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n-                                              source_file.display(),\n-                                              obj_out.display(),\n-                                              err));\n-                }\n+    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                    .as_ref()\n+                                    .unwrap();\n+    let mut object = None;\n+    let mut bytecode = None;\n+    let mut bytecode_compressed = None;\n+    for (kind, saved_file) in &module.source.saved_files {\n+        let obj_out = match kind {\n+            WorkProductFileKind::Object => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Object,\n+                                                           Some(&module.name));\n+                object = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::Bytecode => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name));\n+                bytecode = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::BytecodeCompressed => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name))\n+                    .with_extension(RLIB_BYTECODE_EXTENSION);\n+                bytecode_compressed = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::PreThinLtoBytecode => {\n+                continue;\n+            }\n+        };\n+        let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n+                                           &saved_file);\n+        debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n+               module.name,\n+               source_file,\n+               obj_out.display());\n+        match link_or_copy(&source_file, &obj_out) {\n+            Ok(_) => { }\n+            Err(err) => {\n+                let diag_handler = cgcx.create_diag_handler();\n+                diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n+                                          source_file.display(),\n+                                          obj_out.display(),\n+                                          err));\n             }\n         }\n-        assert_eq!(object.is_some(), config.emit_obj);\n-        assert_eq!(bytecode.is_some(), config.emit_bc);\n-        assert_eq!(bytecode_compressed.is_some(), config.emit_bc_compressed);\n-\n-        Ok(WorkItemResult::Compiled(CompiledModule {\n-            name: module_name,\n-            kind: ModuleKind::Regular,\n-            pre_existing: true,\n-            object,\n-            bytecode,\n-            bytecode_compressed,\n-        }))\n-    } else {\n-        debug!(\"llvm-optimizing {:?}\", module_name);\n+    }\n+\n+    assert_eq!(object.is_some(), config.emit_obj);\n+    assert_eq!(bytecode.is_some(), config.emit_bc);\n+    assert_eq!(bytecode_compressed.is_some(), config.emit_bc_compressed);\n+\n+    Ok(WorkItemResult::Compiled(CompiledModule {\n+        name: module.name,\n+        kind: ModuleKind::Regular,\n+        object,\n+        bytecode,\n+        bytecode_compressed,\n+    }))\n+}\n+\n+fn execute_lto_work_item(cgcx: &CodegenContext,\n+                         work_item: WorkItem,\n+                         timeline: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let config = cgcx.config(work_item.module_kind());\n+\n+    if let WorkItem::LTO(mut lto) = work_item {\n+        let diag_handler = cgcx.create_diag_handler();\n \n         unsafe {\n-            optimize(cgcx, &diag_handler, &module, config, timeline)?;\n-\n-            let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n-\n-            // After we've done the initial round of optimizations we need to\n-            // decide whether to synchronously codegen this module or ship it\n-            // back to the coordinator thread for further LTO processing (which\n-            // has to wait for all the initial modules to be optimized).\n-            //\n-            // Here we dispatch based on the `cgcx.lto` and kind of module we're\n-            // codegenning...\n-            let needs_lto = match cgcx.lto {\n-                Lto::No => false,\n-\n-                // If the linker does LTO, we don't have to do it. Note that we\n-                // keep doing full LTO, if it is requested, as not to break the\n-                // assumption that the output will be a single module.\n-                Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n-\n-                // Here we've got a full crate graph LTO requested. We ignore\n-                // this, however, if the crate type is only an rlib as there's\n-                // no full crate graph to process, that'll happen later.\n-                //\n-                // This use case currently comes up primarily for targets that\n-                // require LTO so the request for LTO is always unconditionally\n-                // passed down to the backend, but we don't actually want to do\n-                // anything about it yet until we've got a final product.\n-                Lto::Yes | Lto::Fat | Lto::Thin => {\n-                    cgcx.crate_types.len() != 1 ||\n-                        cgcx.crate_types[0] != config::CrateType::Rlib\n-                }\n+            let module = lto.optimize(cgcx, timeline)?;\n+            let module = codegen(cgcx, &diag_handler, module, config, timeline)?;\n+            Ok(WorkItemResult::Compiled(module))\n+        }\n+    } else {\n+        bug!(\"execute_lto_work_item() called with wrong WorkItem kind.\")\n+    }\n+}\n \n-                // When we're automatically doing ThinLTO for multi-codegen-unit\n-                // builds we don't actually want to LTO the allocator modules if\n-                // it shows up. This is due to various linker shenanigans that\n-                // we'll encounter later.\n-                //\n-                // Additionally here's where we also factor in the current LLVM\n-                // version. If it doesn't support ThinLTO we skip this.\n-                Lto::ThinLocal => {\n-                    module.kind != ModuleKind::Allocator &&\n-                        llvm::LLVMRustThinLTOAvailable()\n-                }\n-            };\n+fn execute_load_pre_lto_mod_work_item(cgcx: &CodegenContext,\n+                                      work_item: WorkItem,\n+                                      _: &mut Timeline)\n+    -> Result<WorkItemResult, FatalError>\n+{\n+    let module = if let WorkItem::LoadPreLtoModule(module) = work_item {\n+        module\n+    } else {\n+        bug!(\"execute_load_pre_lto_mod_work_item() called with wrong WorkItem kind.\")\n+    };\n \n-            // Metadata modules never participate in LTO regardless of the lto\n-            // settings.\n-            let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n+    let work_product = module.source.clone();\n+    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                    .as_ref()\n+                                    .unwrap();\n \n-            if needs_lto {\n-                Ok(WorkItemResult::NeedsLTO(module))\n-            } else {\n-                let module = codegen(cgcx, &diag_handler, module, config, timeline)?;\n-                Ok(WorkItemResult::Compiled(module))\n+    let filename = pre_lto_bitcode_filename(&work_product);\n+    let bc_path = in_incr_comp_dir(&incr_comp_session_dir, &filename);\n+\n+    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n+        panic!(\"failed to open bitcode file `{}`: {}\",\n+                           bc_path.display(),\n+                           e);\n+    });\n+\n+    let module_llvm = unsafe {\n+        let data = ::memmap::Mmap::map(&file).unwrap_or_else(|e| {\n+            panic!(\"failed to create mmap for bitcode file `{}`: {}\",\n+                               bc_path.display(),\n+                               e);\n+        });\n+\n+        let llcx = llvm::LLVMRustContextCreate(cgcx.fewer_names);\n+        let mod_name_c = SmallCStr::new(&module.name);\n+        let llmod_raw = match llvm::LLVMRustParseBitcodeForThinLTO(\n+            llcx,\n+            data.as_ptr(),\n+            data.len(),\n+            mod_name_c.as_ptr(),\n+        ) {\n+            Some(m) => m as *const _,\n+            None => {\n+                panic!(\"failed to parse bitcode for thin LTO module `{}`\",\n+                        module.name);\n             }\n+        };\n+\n+        let tm = (cgcx.tm_factory)().unwrap();\n+\n+        ModuleLlvm {\n+            llmod_raw,\n+            llcx,\n+            tm,\n         }\n-    }\n+    };\n+\n+    Ok(WorkItemResult::NeedsLTO(ModuleCodegen {\n+        name: module.name.to_string(),\n+        module_llvm,\n+        kind: ModuleKind::Regular,\n+    }))\n }\n \n enum Message {\n@@ -1424,6 +1586,10 @@ enum Message {\n         llvm_work_item: WorkItem,\n         cost: u64,\n     },\n+    AddImportOnlyModule {\n+        module_data: SerializedModule,\n+        module_name: CString,\n+    },\n     CodegenComplete,\n     CodegenItem,\n }\n@@ -1703,6 +1869,7 @@ fn start_executing_work(tcx: TyCtxt,\n         let mut compiled_metadata_module = None;\n         let mut compiled_allocator_module = None;\n         let mut needs_lto = Vec::new();\n+        let mut lto_import_only_modules = Vec::new();\n         let mut started_lto = false;\n \n         // This flag tracks whether all items have gone through codegens\n@@ -1749,7 +1916,7 @@ fn start_executing_work(tcx: TyCtxt,\n                             worker: get_worker_id(&mut free_worker_ids),\n                             .. cgcx.clone()\n                         };\n-                        maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                        maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                                &mut llvm_start_time);\n                         main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                         spawn_work(cgcx, item);\n@@ -1768,7 +1935,9 @@ fn start_executing_work(tcx: TyCtxt,\n                     assert!(needs_lto.len() > 0);\n                     started_lto = true;\n                     let modules = mem::replace(&mut needs_lto, Vec::new());\n-                    for (work, cost) in generate_lto_work(&cgcx, modules) {\n+                    let import_only_modules =\n+                        mem::replace(&mut lto_import_only_modules, Vec::new());\n+                    for (work, cost) in generate_lto_work(&cgcx, modules, import_only_modules) {\n                         let insertion_index = work_items\n                             .binary_search_by_key(&cost, |&(_, cost)| cost)\n                             .unwrap_or_else(|e| e);\n@@ -1789,7 +1958,7 @@ fn start_executing_work(tcx: TyCtxt,\n                                 worker: get_worker_id(&mut free_worker_ids),\n                                 .. cgcx.clone()\n                             };\n-                            maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                            maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                                    &mut llvm_start_time);\n                             main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                             spawn_work(cgcx, item);\n@@ -1820,7 +1989,7 @@ fn start_executing_work(tcx: TyCtxt,\n             while work_items.len() > 0 && running < tokens.len() {\n                 let (item, _) = work_items.pop().unwrap();\n \n-                maybe_start_llvm_timer(cgcx.config(item.kind()),\n+                maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n                                        &mut llvm_start_time);\n \n                 let cgcx = CodegenContext {\n@@ -1932,10 +2101,14 @@ fn start_executing_work(tcx: TyCtxt,\n                     } else {\n                         running -= 1;\n                     }\n-\n                     free_worker_ids.push(worker_id);\n                     needs_lto.push(result);\n                 }\n+                Message::AddImportOnlyModule { module_data, module_name } => {\n+                    assert!(!started_lto);\n+                    assert!(!codegen_done);\n+                    lto_import_only_modules.push((module_data, module_name));\n+                }\n                 Message::Done { result: Err(()), worker_id: _ } => {\n                     shared_emitter.fatal(\"aborting due to worker thread failure\");\n                     // Exit the coordinator thread\n@@ -2308,9 +2481,10 @@ impl OngoingCodegen {\n             time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n         }\n \n-        let work_products = copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n-                                                                             &compiled_modules);\n-\n+        let work_products =\n+            copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n+                                                             &compiled_modules,\n+                                                             &self.output_filenames);\n         produce_final_output_artifacts(sess,\n                                        &compiled_modules,\n                                        &self.output_filenames);\n@@ -2371,15 +2545,70 @@ impl OngoingCodegen {\n }\n \n pub(crate) fn submit_codegened_module_to_llvm(tcx: TyCtxt,\n-                                               module: ModuleCodegen,\n-                                               cost: u64) {\n+                                              module: ModuleCodegen,\n+                                              cost: u64) {\n     let llvm_work_item = WorkItem::Optimize(module);\n     drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n         llvm_work_item,\n         cost,\n     })));\n }\n \n+pub(crate) fn submit_post_lto_module_to_llvm(tcx: TyCtxt,\n+                                             module: CachedModuleCodegen) {\n+    let llvm_work_item = WorkItem::CopyPostLtoArtifacts(module);\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n+        llvm_work_item,\n+        cost: 0,\n+    })));\n+}\n+\n+pub(crate) fn submit_pre_lto_module_to_llvm(tcx: TyCtxt,\n+                                            module: CachedModuleCodegen) {\n+    let llvm_work_item = WorkItem::LoadPreLtoModule(module);\n+\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n+        llvm_work_item,\n+        // We don't know the size of the module, but just loading will have smaller\n+        // cost than optimizing.\n+        cost: 10,\n+    })));\n+}\n+\n+pub(crate) fn submit_import_only_module_to_llvm(tcx: TyCtxt,\n+                                                module: CachedModuleCodegen) {\n+    let filename = pre_lto_bitcode_filename(&module.source);\n+    let bc_path = in_incr_comp_dir_sess(tcx.sess, &filename);\n+    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n+        panic!(\"failed to open bitcode file `{}`: {}\", bc_path.display(), e)\n+    });\n+\n+    let mmap = unsafe {\n+        memmap::Mmap::map(&file).unwrap_or_else(|e| {\n+            panic!(\"failed to mmap bitcode file `{}`: {}\", bc_path.display(), e)\n+        })\n+    };\n+\n+    // Schedule the module to be loaded\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::AddImportOnlyModule {\n+        module_data: SerializedModule::FromUncompressedFile(mmap, file),\n+        module_name: CString::new(module.name.clone()).unwrap(),\n+    })));\n+\n+    // Note: We also schedule for the cached files to be copied to the output\n+    // directory\n+    submit_post_lto_module_to_llvm(tcx, module);\n+}\n+\n+fn pre_lto_bitcode_filename(wp: &WorkProduct) -> String {\n+    wp.saved_files\n+      .iter()\n+      .find(|&&(kind, _)| kind == WorkProductFileKind::PreThinLtoBytecode)\n+      .map(|&(_, ref filename)| filename.clone())\n+      .unwrap_or_else(|| panic!(\"Couldn't find pre-thin-lto bytecode for `{}`\",\n+                                wp.cgu_name))\n+}\n+\n fn msvc_imps_needed(tcx: TyCtxt) -> bool {\n     // This should never be true (because it's not supported). If it is true,\n     // something is wrong with commandline arg validation."}, {"sha": "10e415190b4a5c71f5ebede05584c68c6619e83b", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 122, "deletions": 52, "changes": 174, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -24,9 +24,9 @@\n //!     int) and rec(x=int, y=int, z=int) will have the same llvm::Type.\n \n use super::ModuleLlvm;\n-use super::ModuleSource;\n use super::ModuleCodegen;\n use super::ModuleKind;\n+use super::CachedModuleCodegen;\n \n use abi;\n use back::lto;\n@@ -41,7 +41,6 @@ use rustc::middle::cstore::{EncodedMetadata};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::ty::layout::{self, Align, TyLayout, LayoutOf};\n use rustc::ty::query::Providers;\n-use rustc::dep_graph::{DepNode, DepConstructor};\n use rustc::middle::cstore::{self, LinkagePreference};\n use rustc::middle::exported_symbols;\n use rustc::util::common::{time, print_time_passes_entry};\n@@ -699,6 +698,79 @@ pub fn iter_globals(llmod: &'ll llvm::Module) -> ValueIter<'ll> {\n     }\n }\n \n+#[derive(Debug, PartialEq)]\n+enum CguReUsable {\n+    No,\n+    PreThinLto,\n+    PostThinLto,\n+    PostThinLtoButImportedFrom,\n+}\n+\n+fn determine_cgu_reuse<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                 codegen_units: &[Arc<CodegenUnit<'tcx>>])\n+                                 -> FxHashMap<InternedString, CguReUsable> {\n+    if !tcx.dep_graph.is_fully_enabled() {\n+        return codegen_units.iter()\n+                            .map(|cgu| (cgu.name().clone(), CguReUsable::No))\n+                            .collect();\n+    }\n+\n+    let thin_lto_imports = load_thin_lto_imports(tcx.sess);\n+\n+    let mut reusable_cgus = FxHashMap();\n+    let mut green_cgus = FxHashMap();\n+    let mut need_for_importing = FxHashSet();\n+\n+    for cgu in codegen_units {\n+        let work_product_id = &cgu.work_product_id();\n+        if tcx.dep_graph.previous_work_product(work_product_id).is_none() {\n+            // We don't have anything cached for this CGU. This can happen\n+            // if the CGU did not exist in the previous session.\n+            reusable_cgus.insert(cgu.name().clone(), CguReUsable::No);\n+            continue\n+        };\n+        // Try to mark the CGU as green\n+        let dep_node = cgu.codegen_dep_node(tcx);\n+        assert!(!tcx.dep_graph.dep_node_exists(&dep_node),\n+            \"CompileCodegenUnit dep-node for CGU `{}` already exists before marking.\",\n+            cgu.name());\n+\n+        if tcx.dep_graph.try_mark_green(tcx, &dep_node).is_some() {\n+            // We can re-use either the pre- or the post-thinlto state\n+            green_cgus.insert(cgu.name().to_string(), cgu);\n+        } else {\n+            // We definitely cannot re-use this CGU\n+            reusable_cgus.insert(cgu.name().clone(), CguReUsable::No);\n+\n+            let imported_cgus = thin_lto_imports.modules_imported_by(&cgu.name().as_str());\n+            need_for_importing.extend(imported_cgus.iter().cloned());\n+        }\n+    }\n+\n+    // Now we know all CGUs that have not changed themselves. Next we need to\n+    // check if anything they imported via ThinLTO has changed.\n+    for (cgu_name, cgu) in &green_cgus {\n+        let imported_cgus = thin_lto_imports.modules_imported_by(cgu_name);\n+        let all_imports_green = imported_cgus.iter().all(|imported_cgu| {\n+            green_cgus.contains_key(&imported_cgu[..])\n+        });\n+        if all_imports_green {\n+            reusable_cgus.insert(cgu.name().clone(), CguReUsable::PostThinLto);\n+        } else {\n+            reusable_cgus.insert(cgu.name().clone(), CguReUsable::PreThinLto);\n+            need_for_importing.extend(imported_cgus.iter().cloned());\n+        }\n+    }\n+\n+    for (name, state) in reusable_cgus.iter_mut() {\n+        if *state == CguReUsable::PostThinLto && need_for_importing.contains(&name.as_str()[..]) {\n+            *state = CguReUsable::PostThinLtoButImportedFrom;\n+        }\n+    }\n+\n+    reusable_cgus\n+}\n+\n pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                              rx: mpsc::Receiver<Box<dyn Any + Send>>)\n                              -> OngoingCodegen {\n@@ -735,7 +807,7 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     let metadata_module = ModuleCodegen {\n         name: metadata_cgu_name,\n-        source: ModuleSource::Codegened(metadata_llvm_module),\n+        module_llvm: metadata_llvm_module,\n         kind: ModuleKind::Metadata,\n     };\n \n@@ -824,7 +896,7 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n         Some(ModuleCodegen {\n             name: llmod_id,\n-            source: ModuleSource::Codegened(modules),\n+            module_llvm: modules,\n             kind: ModuleKind::Allocator,\n         })\n     } else {\n@@ -848,52 +920,53 @@ pub fn codegen_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     let mut total_codegen_time = Duration::new(0, 0);\n     let mut all_stats = Stats::default();\n \n+    let cgu_reuse = determine_cgu_reuse(tcx, &codegen_units);\n+\n     for cgu in codegen_units.into_iter() {\n         ongoing_codegen.wait_for_signal_to_codegen_item();\n         ongoing_codegen.check_for_errors(tcx.sess);\n \n-        // First, if incremental compilation is enabled, we try to re-use the\n-        // codegen unit from the cache.\n-        if tcx.dep_graph.is_fully_enabled() {\n-            let cgu_id = cgu.work_product_id();\n-\n-            // Check whether there is a previous work-product we can\n-            // re-use.  Not only must the file exist, and the inputs not\n-            // be dirty, but the hash of the symbols we will generate must\n-            // be the same.\n-            if let Some(buf) = tcx.dep_graph.previous_work_product(&cgu_id) {\n-                let dep_node = &DepNode::new(tcx,\n-                    DepConstructor::CompileCodegenUnit(cgu.name().clone()));\n-\n-                // We try to mark the DepNode::CompileCodegenUnit green. If we\n-                // succeed it means that none of the dependencies has changed\n-                // and we can safely re-use.\n-                if let Some(dep_node_index) = tcx.dep_graph.try_mark_green(tcx, dep_node) {\n-                    let module = ModuleCodegen {\n-                        name: cgu.name().to_string(),\n-                        source: ModuleSource::Preexisting(buf),\n-                        kind: ModuleKind::Regular,\n-                    };\n-                    tcx.dep_graph.mark_loaded_from_cache(dep_node_index, true);\n-                    write::submit_codegened_module_to_llvm(tcx, module, 0);\n-                    // Continue to next cgu, this one is done.\n-                    continue\n-                }\n-            } else {\n-                // This can happen if files were  deleted from the cache\n-                // directory for some reason. We just re-compile then.\n+        let loaded_from_cache = match cgu_reuse[cgu.name()] {\n+            CguReUsable::No => {\n+                let _timing_guard = time_graph.as_ref().map(|time_graph| {\n+                    time_graph.start(write::CODEGEN_WORKER_TIMELINE,\n+                                     write::CODEGEN_WORK_PACKAGE_KIND,\n+                                     &format!(\"codegen {}\", cgu.name()))\n+                });\n+                let start_time = Instant::now();\n+                let stats = compile_codegen_unit(tcx, *cgu.name());\n+                all_stats.extend(stats);\n+                total_codegen_time += start_time.elapsed();\n+                false\n             }\n-        }\n+            CguReUsable::PreThinLto => {\n+                write::submit_pre_lto_module_to_llvm(tcx, CachedModuleCodegen {\n+                    name: cgu.name().to_string(),\n+                    source: cgu.work_product(tcx),\n+                });\n+                true\n+            }\n+            CguReUsable::PostThinLtoButImportedFrom => {\n+                write::submit_import_only_module_to_llvm(tcx, CachedModuleCodegen {\n+                    name: cgu.name().to_string(),\n+                    source: cgu.work_product(tcx),\n+                });\n+                true\n+            }\n+            CguReUsable::PostThinLto => {\n+                write::submit_post_lto_module_to_llvm(tcx, CachedModuleCodegen {\n+                    name: cgu.name().to_string(),\n+                    source: cgu.work_product(tcx),\n+                });\n+                true\n+            }\n+        };\n \n-        let _timing_guard = time_graph.as_ref().map(|time_graph| {\n-            time_graph.start(write::CODEGEN_WORKER_TIMELINE,\n-                             write::CODEGEN_WORK_PACKAGE_KIND,\n-                             &format!(\"codegen {}\", cgu.name()))\n-        });\n-        let start_time = Instant::now();\n-        all_stats.extend(compile_codegen_unit(tcx, *cgu.name()));\n-        total_codegen_time += start_time.elapsed();\n-        ongoing_codegen.check_for_errors(tcx.sess);\n+        if tcx.dep_graph.is_fully_enabled() {\n+            let dep_node = cgu.codegen_dep_node(tcx);\n+            let dep_node_index = tcx.dep_graph.dep_node_index_of(&dep_node);\n+            tcx.dep_graph.mark_loaded_from_cache(dep_node_index, loaded_from_cache);\n+        }\n     }\n \n     ongoing_codegen.codegen_finished(tcx);\n@@ -1176,12 +1249,6 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     write::submit_codegened_module_to_llvm(tcx,\n                                            module,\n                                            cost);\n-\n-    if tcx.dep_graph.is_fully_enabled() {\n-        let dep_node_index = tcx.dep_graph.dep_node_index_of(&dep_node);\n-        tcx.dep_graph.mark_loaded_from_cache(dep_node_index, false);\n-    }\n-\n     return stats;\n \n     fn module_codegen<'a, 'tcx>(\n@@ -1246,7 +1313,7 @@ fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n         (stats, ModuleCodegen {\n             name: cgu_name.to_string(),\n-            source: ModuleSource::Codegened(llvm_module),\n+            module_llvm: llvm_module,\n             kind: ModuleKind::Regular,\n         })\n     }\n@@ -1324,8 +1391,11 @@ pub fn visibility_to_llvm(linkage: Visibility) -> llvm::Visibility {\n     }\n }\n \n-#[allow(unused)]\n fn load_thin_lto_imports(sess: &Session) -> lto::ThinLTOImports {\n+    if sess.opts.incremental.is_none() {\n+        return lto::ThinLTOImports::new();\n+    }\n+\n     let path = rustc_incremental::in_incr_comp_dir_sess(\n         sess,\n         lto::THIN_LTO_IMPORTS_INCR_COMP_FILE_NAME"}, {"sha": "dcdd8c1f6e9f99a5c2848af27fba61feaaaa8789", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 12, "deletions": 28, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -66,13 +66,13 @@ extern crate rustc_errors as errors;\n extern crate serialize;\n extern crate cc; // Used to locate MSVC\n extern crate tempfile;\n+extern crate memmap;\n \n use back::bytecode::RLIB_BYTECODE_EXTENSION;\n \n pub use llvm_util::target_features;\n-\n use std::any::Any;\n-use std::path::PathBuf;\n+use std::path::{PathBuf};\n use std::sync::mpsc;\n use rustc_data_structures::sync::Lrc;\n \n@@ -273,10 +273,15 @@ struct ModuleCodegen {\n     /// as the crate name and disambiguator.\n     /// We currently generate these names via CodegenUnit::build_cgu_name().\n     name: String,\n-    source: ModuleSource,\n+    module_llvm: ModuleLlvm,\n     kind: ModuleKind,\n }\n \n+struct CachedModuleCodegen {\n+    name: String,\n+    source: WorkProduct,\n+}\n+\n #[derive(Copy, Clone, Debug, PartialEq)]\n enum ModuleKind {\n     Regular,\n@@ -285,22 +290,11 @@ enum ModuleKind {\n }\n \n impl ModuleCodegen {\n-    fn llvm(&self) -> Option<&ModuleLlvm> {\n-        match self.source {\n-            ModuleSource::Codegened(ref llvm) => Some(llvm),\n-            ModuleSource::Preexisting(_) => None,\n-        }\n-    }\n-\n     fn into_compiled_module(self,\n-                                emit_obj: bool,\n-                                emit_bc: bool,\n-                                emit_bc_compressed: bool,\n-                                outputs: &OutputFilenames) -> CompiledModule {\n-        let pre_existing = match self.source {\n-            ModuleSource::Preexisting(_) => true,\n-            ModuleSource::Codegened(_) => false,\n-        };\n+                            emit_obj: bool,\n+                            emit_bc: bool,\n+                            emit_bc_compressed: bool,\n+                            outputs: &OutputFilenames) -> CompiledModule {\n         let object = if emit_obj {\n             Some(outputs.temp_path(OutputType::Object, Some(&self.name)))\n         } else {\n@@ -321,7 +315,6 @@ impl ModuleCodegen {\n         CompiledModule {\n             name: self.name.clone(),\n             kind: self.kind,\n-            pre_existing,\n             object,\n             bytecode,\n             bytecode_compressed,\n@@ -333,20 +326,11 @@ impl ModuleCodegen {\n struct CompiledModule {\n     name: String,\n     kind: ModuleKind,\n-    pre_existing: bool,\n     object: Option<PathBuf>,\n     bytecode: Option<PathBuf>,\n     bytecode_compressed: Option<PathBuf>,\n }\n \n-enum ModuleSource {\n-    /// Copy the `.o` files or whatever from the incr. comp. directory.\n-    Preexisting(WorkProduct),\n-\n-    /// Rebuild from this LLVM module.\n-    Codegened(ModuleLlvm),\n-}\n-\n struct ModuleLlvm {\n     llcx: &'static mut llvm::Context,\n     llmod_raw: *const llvm::Module,"}, {"sha": "c285934d75bb9a85788b7a9211d849caea9c5e90", "filename": "src/librustc_incremental/persist/work_product.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fwork_product.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -36,6 +36,7 @@ pub fn copy_cgu_workproducts_to_incr_comp_cache_dir(\n                      WorkProductFileKind::Object => \"o\",\n                      WorkProductFileKind::Bytecode => \"bc\",\n                      WorkProductFileKind::BytecodeCompressed => \"bc.z\",\n+                     WorkProductFileKind::PreThinLtoBytecode => \"pre-thinlto.bc\",\n                  };\n                  let file_name = format!(\"{}.{}\", cgu_name, extension);\n                  let path_in_incr_dir = in_incr_comp_dir_sess(sess, &file_name);"}, {"sha": "fd094ffc1cf4f7fd02d09f4bff3cde03224a44ab", "filename": "src/librustc_mir/monomorphize/partitioning.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs", "raw_url": "https://github.com/rust-lang/rust/raw/64a738d8ce457b8d9b3a750ca61835214b6b438c/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Fmonomorphize%2Fpartitioning.rs?ref=64a738d8ce457b8d9b3a750ca61835214b6b438c", "patch": "@@ -103,7 +103,7 @@\n //! inlining, even when they are not marked #[inline].\n \n use monomorphize::collector::InliningMap;\n-use rustc::dep_graph::{WorkProductId, DepNode, DepConstructor};\n+use rustc::dep_graph::{WorkProductId, WorkProduct, DepNode, DepConstructor};\n use rustc::hir::CodegenFnAttrFlags;\n use rustc::hir::def_id::{DefId, LOCAL_CRATE, CRATE_DEF_INDEX};\n use rustc::hir::map::DefPathData;\n@@ -150,6 +150,15 @@ pub trait CodegenUnitExt<'tcx> {\n         WorkProductId::from_cgu_name(&self.name().as_str())\n     }\n \n+    fn work_product(&self, tcx: TyCtxt) -> WorkProduct {\n+        let work_product_id = self.work_product_id();\n+        tcx.dep_graph\n+           .previous_work_product(&work_product_id)\n+           .unwrap_or_else(|| {\n+                panic!(\"Could not find work-product for CGU `{}`\", self.name())\n+            })\n+    }\n+\n     fn items_in_deterministic_order<'a>(&self,\n                                         tcx: TyCtxt<'a, 'tcx, 'tcx>)\n                                         -> Vec<(MonoItem<'tcx>,"}]}