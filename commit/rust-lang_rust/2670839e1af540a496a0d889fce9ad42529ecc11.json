{"sha": "2670839e1af540a496a0d889fce9ad42529ecc11", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI2NzA4MzllMWFmNTQwYTQ5NmEwZDg4OWZjZTlhZDQyNTI5ZWNjMTE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-03-02T14:52:32Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-03-02T14:52:32Z"}, "message": "Auto merge of #1721 - henryboisdequin:add-atomic-min-and-max, r=oli-obk\n\nAdd atomic min and max\n\nCloses #1718\nPrevious attempt: #1653\n\nTODO:\n\n- [x] Merge `atomic_op` and `atomic_min_max` functions\n- [x] Fix CI\n\n**Note:** this PR also removes arbitrary trailing whitespace and generally formats the affected files", "tree": {"sha": "ea8dbef530c9623df17bb3f3376f45b0a8b5614e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ea8dbef530c9623df17bb3f3376f45b0a8b5614e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2670839e1af540a496a0d889fce9ad42529ecc11", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2670839e1af540a496a0d889fce9ad42529ecc11", "html_url": "https://github.com/rust-lang/rust/commit/2670839e1af540a496a0d889fce9ad42529ecc11", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2670839e1af540a496a0d889fce9ad42529ecc11/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "904e66a7a6e4f2af9333b06521e47b8bf55fbae4", "url": "https://api.github.com/repos/rust-lang/rust/commits/904e66a7a6e4f2af9333b06521e47b8bf55fbae4", "html_url": "https://github.com/rust-lang/rust/commit/904e66a7a6e4f2af9333b06521e47b8bf55fbae4"}, {"sha": "f8440d6c998b6f30fa04d6ed6f1e4f19242283af", "url": "https://api.github.com/repos/rust-lang/rust/commits/f8440d6c998b6f30fa04d6ed6f1e4f19242283af", "html_url": "https://github.com/rust-lang/rust/commit/f8440d6c998b6f30fa04d6ed6f1e4f19242283af"}], "stats": {"total": 599, "additions": 470, "deletions": 129}, "files": [{"sha": "e8071845c7d76240046ef8c3be17023474c772ad", "filename": "src/data_race.rs", "status": "modified", "additions": 57, "deletions": 23, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/2670839e1af540a496a0d889fce9ad42529ecc11/src%2Fdata_race.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2670839e1af540a496a0d889fce9ad42529ecc11/src%2Fdata_race.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdata_race.rs?ref=2670839e1af540a496a0d889fce9ad42529ecc11", "patch": "@@ -74,9 +74,9 @@ use rustc_middle::{mir, ty::layout::TyAndLayout};\n use rustc_target::abi::Size;\n \n use crate::{\n-    ImmTy, Immediate, InterpResult, MPlaceTy, MemPlaceMeta, MiriEvalContext, MiriEvalContextExt,\n-    OpTy, Pointer, RangeMap, Scalar, ScalarMaybeUninit, Tag, ThreadId, VClock, VTimestamp,\n-    VectorIdx, MemoryKind, MiriMemoryKind\n+    ImmTy, Immediate, InterpResult, MPlaceTy, MemPlaceMeta, MemoryKind, MiriEvalContext,\n+    MiriEvalContextExt, MiriMemoryKind, OpTy, Pointer, RangeMap, Scalar, ScalarMaybeUninit, Tag,\n+    ThreadId, VClock, VTimestamp, VectorIdx,\n };\n \n pub type AllocExtra = VClockAlloc;\n@@ -263,7 +263,7 @@ impl MemoryCellClocks {\n             atomic_ops: None,\n         }\n     }\n-    \n+\n     /// Load the internal atomic memory cells if they exist.\n     #[inline]\n     fn atomic(&self) -> Option<&AtomicMemoryCellClocks> {\n@@ -323,7 +323,7 @@ impl MemoryCellClocks {\n     /// store relaxed semantics.\n     fn store_relaxed(&mut self, clocks: &ThreadClockSet, index: VectorIdx) -> Result<(), DataRace> {\n         self.atomic_write_detect(clocks, index)?;\n-        \n+\n         // The handling of release sequences was changed in C++20 and so\n         // the code here is different to the paper since now all relaxed\n         // stores block release sequences. The exception for same-thread\n@@ -542,6 +542,34 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         Ok(old)\n     }\n \n+    /// Perform an conditional atomic exchange with a memory place and a new\n+    /// scalar value, the old value is returned.\n+    fn atomic_min_max_scalar(\n+        &mut self,\n+        place: &MPlaceTy<'tcx, Tag>,\n+        rhs: ImmTy<'tcx, Tag>,\n+        min: bool,\n+        atomic: AtomicRwOp,\n+    ) -> InterpResult<'tcx, ImmTy<'tcx, Tag>> {\n+        let this = self.eval_context_mut();\n+\n+        let old = this.allow_data_races_mut(|this| this.read_immediate(&place.into()))?;\n+        let lt = this.overflowing_binary_op(mir::BinOp::Lt, &old, &rhs)?.0.to_bool()?;\n+\n+        let new_val = if min {\n+            if lt { &old } else { &rhs }\n+        } else {\n+            if lt { &rhs } else { &old }\n+        };\n+\n+        this.allow_data_races_mut(|this| this.write_immediate_to_mplace(**new_val, place))?;\n+\n+        this.validate_atomic_rmw(&place, atomic)?;\n+\n+        // Return the old value.\n+        Ok(old)\n+    }\n+\n     /// Perform an atomic compare and exchange at a given memory location.\n     /// On success an atomic RMW operation is performed and on failure\n     /// only an atomic read occurs. If `can_fail_spuriously` is true,\n@@ -678,7 +706,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n                     // Either Release | AcqRel | SeqCst\n                     clocks.apply_release_fence();\n                 }\n-                \n+\n                 // Increment timestamp in case of release semantics.\n                 Ok(atomic != AtomicFenceOp::Acquire)\n             })\n@@ -687,15 +715,12 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n         }\n     }\n \n-    fn reset_vector_clocks(\n-        &mut self,\n-        ptr: Pointer<Tag>,\n-        size: Size\n-    ) -> InterpResult<'tcx> {\n+    fn reset_vector_clocks(&mut self, ptr: Pointer<Tag>, size: Size) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         if let Some(data_race) = &mut this.memory.extra.data_race {\n             if data_race.multi_threaded.get() {\n-                let alloc_meta = this.memory.get_raw_mut(ptr.alloc_id)?.extra.data_race.as_mut().unwrap();\n+                let alloc_meta =\n+                    this.memory.get_raw_mut(ptr.alloc_id)?.extra.data_race.as_mut().unwrap();\n                 alloc_meta.reset_clocks(ptr.offset, size);\n             }\n         }\n@@ -715,28 +740,37 @@ pub struct VClockAlloc {\n \n impl VClockAlloc {\n     /// Create a new data-race detector for newly allocated memory.\n-    pub fn new_allocation(global: &MemoryExtra, len: Size, kind: MemoryKind<MiriMemoryKind>) -> VClockAlloc {\n+    pub fn new_allocation(\n+        global: &MemoryExtra,\n+        len: Size,\n+        kind: MemoryKind<MiriMemoryKind>,\n+    ) -> VClockAlloc {\n         let (alloc_timestamp, alloc_index) = match kind {\n             // User allocated and stack memory should track allocation.\n             MemoryKind::Machine(\n-                MiriMemoryKind::Rust | MiriMemoryKind::C | MiriMemoryKind::WinHeap\n-            ) | MemoryKind::Stack => {\n+                MiriMemoryKind::Rust | MiriMemoryKind::C | MiriMemoryKind::WinHeap,\n+            )\n+            | MemoryKind::Stack => {\n                 let (alloc_index, clocks) = global.current_thread_state();\n                 let alloc_timestamp = clocks.clock[alloc_index];\n                 (alloc_timestamp, alloc_index)\n             }\n             // Other global memory should trace races but be allocated at the 0 timestamp.\n             MemoryKind::Machine(\n-                MiriMemoryKind::Global | MiriMemoryKind::Machine | MiriMemoryKind::Env |\n-                MiriMemoryKind::ExternStatic | MiriMemoryKind::Tls\n-            ) | MemoryKind::CallerLocation | MemoryKind::Vtable => {\n-                (0, VectorIdx::MAX_INDEX)\n-            }\n+                MiriMemoryKind::Global\n+                | MiriMemoryKind::Machine\n+                | MiriMemoryKind::Env\n+                | MiriMemoryKind::ExternStatic\n+                | MiriMemoryKind::Tls,\n+            )\n+            | MemoryKind::CallerLocation\n+            | MemoryKind::Vtable => (0, VectorIdx::MAX_INDEX),\n         };\n         VClockAlloc {\n             global: Rc::clone(global),\n             alloc_ranges: RefCell::new(RangeMap::new(\n-                len, MemoryCellClocks::new(alloc_timestamp, alloc_index)\n+                len,\n+                MemoryCellClocks::new(alloc_timestamp, alloc_index),\n             )),\n         }\n     }\n@@ -1015,7 +1049,8 @@ trait EvalContextPrivExt<'mir, 'tcx: 'mir>: MiriEvalContextExt<'mir, 'tcx> {\n                                 true,\n                                 place_ptr,\n                                 size,\n-                            ).map(|_| true);\n+                            )\n+                            .map(|_| true);\n                         }\n                     }\n \n@@ -1267,7 +1302,6 @@ impl GlobalState {\n             .as_ref()\n             .expect(\"Joined with thread but thread has not terminated\");\n \n-\n         // The join thread happens-before the current thread\n         // so update the current vector clock.\n         // Is not a release operation so the clock is not incremented."}, {"sha": "66ba42c5a017b581edeeb6b9e0f3824ad843992d", "filename": "src/shims/intrinsics.rs", "status": "modified", "additions": 399, "deletions": 106, "changes": 505, "blob_url": "https://github.com/rust-lang/rust/blob/2670839e1af540a496a0d889fce9ad42529ecc11/src%2Fshims%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2670839e1af540a496a0d889fce9ad42529ecc11/src%2Fshims%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fshims%2Fintrinsics.rs?ref=2670839e1af540a496a0d889fce9ad42529ecc11", "patch": "@@ -2,14 +2,20 @@ use std::iter;\n \n use log::trace;\n \n-use rustc_middle::{mir, mir::BinOp, ty, ty::FloatTy};\n-use rustc_middle::ty::layout::IntegerExt;\n use rustc_apfloat::{Float, Round};\n+use rustc_middle::ty::layout::IntegerExt;\n+use rustc_middle::{mir, mir::BinOp, ty, ty::FloatTy};\n use rustc_target::abi::{Align, Integer, LayoutOf};\n \n use crate::*;\n use helpers::check_arg_count;\n \n+pub enum AtomicOp {\n+    MirOp(mir::BinOp, bool),\n+    Max,\n+    Min,\n+}\n+\n impl<'mir, 'tcx: 'mir> EvalContextExt<'mir, 'tcx> for crate::MiriEvalContext<'mir, 'tcx> {}\n pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx> {\n     fn call_intrinsic(\n@@ -67,8 +73,9 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 let val_byte = this.read_scalar(val_byte)?.to_u8()?;\n                 let ptr = this.read_scalar(ptr)?.check_init()?;\n                 let count = this.read_scalar(count)?.to_machine_usize(this)?;\n-                let byte_count = ty_layout.size.checked_mul(count, this)\n-                    .ok_or_else(|| err_ub_format!(\"overflow computing total size of `write_bytes`\"))?;\n+                let byte_count = ty_layout.size.checked_mul(count, this).ok_or_else(|| {\n+                    err_ub_format!(\"overflow computing total size of `write_bytes`\")\n+                })?;\n                 this.memory\n                     .write_bytes(ptr, iter::repeat(val_byte).take(byte_count.bytes() as usize))?;\n             }\n@@ -258,13 +265,14 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                 let val = this.read_immediate(val)?;\n \n                 let res = match val.layout.ty.kind() {\n-                    ty::Float(FloatTy::F32) => {\n-                        this.float_to_int_unchecked(val.to_scalar()?.to_f32()?, dest.layout.ty)?\n-                    }\n-                    ty::Float(FloatTy::F64) => {\n-                        this.float_to_int_unchecked(val.to_scalar()?.to_f64()?, dest.layout.ty)?\n-                    }\n-                    _ => bug!(\"`float_to_int_unchecked` called with non-float input type {:?}\", val.layout.ty),\n+                    ty::Float(FloatTy::F32) =>\n+                        this.float_to_int_unchecked(val.to_scalar()?.to_f32()?, dest.layout.ty)?,\n+                    ty::Float(FloatTy::F64) =>\n+                        this.float_to_int_unchecked(val.to_scalar()?.to_f64()?, dest.layout.ty)?,\n+                    _ => bug!(\n+                        \"`float_to_int_unchecked` called with non-float input type {:?}\",\n+                        val.layout.ty\n+                    ),\n                 };\n \n                 this.write_scalar(res, dest)?;\n@@ -286,7 +294,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n \n             \"atomic_singlethreadfence_acq\" => this.compiler_fence(args, AtomicFenceOp::Acquire)?,\n             \"atomic_singlethreadfence_rel\" => this.compiler_fence(args, AtomicFenceOp::Release)?,\n-            \"atomic_singlethreadfence_acqrel\" => this.compiler_fence(args, AtomicFenceOp::AcqRel)?,\n+            \"atomic_singlethreadfence_acqrel\" =>\n+                this.compiler_fence(args, AtomicFenceOp::AcqRel)?,\n             \"atomic_singlethreadfence\" => this.compiler_fence(args, AtomicFenceOp::SeqCst)?,\n \n             \"atomic_xchg\" => this.atomic_exchange(args, dest, AtomicRwOp::SeqCst)?,\n@@ -295,110 +304,345 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n             \"atomic_xchg_acqrel\" => this.atomic_exchange(args, dest, AtomicRwOp::AcqRel)?,\n             \"atomic_xchg_relaxed\" => this.atomic_exchange(args, dest, AtomicRwOp::Relaxed)?,\n \n-            \"atomic_cxchg\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::SeqCst\n-            )?,\n+            \"atomic_cxchg\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOp::SeqCst, AtomicReadOp::SeqCst)?,\n             \"atomic_cxchg_acq\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::Acquire, AtomicReadOp::Acquire\n+                args,\n+                dest,\n+                AtomicRwOp::Acquire,\n+                AtomicReadOp::Acquire,\n             )?,\n             \"atomic_cxchg_rel\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::Release, AtomicReadOp::Relaxed\n-            )?,\n-            \"atomic_cxchg_acqrel\" => this.atomic_compare_exchange\n-            (args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Acquire\n+                args,\n+                dest,\n+                AtomicRwOp::Release,\n+                AtomicReadOp::Relaxed,\n             )?,\n+            \"atomic_cxchg_acqrel\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Acquire)?,\n             \"atomic_cxchg_relaxed\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::Relaxed, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::Relaxed,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchg_acq_failrelaxed\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::Acquire, AtomicReadOp::Relaxed\n-            )?,\n-            \"atomic_cxchg_acqrel_failrelaxed\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Relaxed\n-            )?,\n-            \"atomic_cxchg_failrelaxed\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Relaxed\n-            )?,\n-            \"atomic_cxchg_failacq\" => this.atomic_compare_exchange(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Acquire\n+                args,\n+                dest,\n+                AtomicRwOp::Acquire,\n+                AtomicReadOp::Relaxed,\n             )?,\n+            \"atomic_cxchg_acqrel_failrelaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Relaxed)?,\n+            \"atomic_cxchg_failrelaxed\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Relaxed)?,\n+            \"atomic_cxchg_failacq\" =>\n+                this.atomic_compare_exchange(args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Acquire)?,\n \n             \"atomic_cxchgweak\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::SeqCst\n+                args,\n+                dest,\n+                AtomicRwOp::SeqCst,\n+                AtomicReadOp::SeqCst,\n             )?,\n             \"atomic_cxchgweak_acq\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::Acquire, AtomicReadOp::Acquire\n+                args,\n+                dest,\n+                AtomicRwOp::Acquire,\n+                AtomicReadOp::Acquire,\n             )?,\n             \"atomic_cxchgweak_rel\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::Release, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::Release,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchgweak_acqrel\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Acquire\n+                args,\n+                dest,\n+                AtomicRwOp::AcqRel,\n+                AtomicReadOp::Acquire,\n             )?,\n             \"atomic_cxchgweak_relaxed\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::Relaxed, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::Relaxed,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchgweak_acq_failrelaxed\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::Acquire, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::Acquire,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchgweak_acqrel_failrelaxed\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::AcqRel, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::AcqRel,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchgweak_failrelaxed\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Relaxed\n+                args,\n+                dest,\n+                AtomicRwOp::SeqCst,\n+                AtomicReadOp::Relaxed,\n             )?,\n             \"atomic_cxchgweak_failacq\" => this.atomic_compare_exchange_weak(\n-                args, dest, AtomicRwOp::SeqCst, AtomicReadOp::Acquire\n-            )?,\n-\n-            \"atomic_or\" => this.atomic_op(args, dest, BinOp::BitOr, false, AtomicRwOp::SeqCst)?,\n-            \"atomic_or_acq\" => this.atomic_op(args, dest, BinOp::BitOr, false, AtomicRwOp::Acquire)?,\n-            \"atomic_or_rel\" => this.atomic_op(args, dest, BinOp::BitOr, false, AtomicRwOp::Release)?,\n-            \"atomic_or_acqrel\" => this.atomic_op(args, dest, BinOp::BitOr, false, AtomicRwOp::AcqRel)?,\n-            \"atomic_or_relaxed\" => this.atomic_op(args, dest, BinOp::BitOr, false, AtomicRwOp::Relaxed)?,\n-            \"atomic_xor\" => this.atomic_op(args, dest, BinOp::BitXor, false, AtomicRwOp::SeqCst)?,\n-            \"atomic_xor_acq\" => this.atomic_op(args, dest, BinOp::BitXor, false, AtomicRwOp::Acquire)?,\n-            \"atomic_xor_rel\" => this.atomic_op(args, dest, BinOp::BitXor, false, AtomicRwOp::Release)?,\n-            \"atomic_xor_acqrel\" => this.atomic_op(args, dest, BinOp::BitXor, false, AtomicRwOp::AcqRel)?,\n-            \"atomic_xor_relaxed\" => this.atomic_op(args, dest, BinOp::BitXor, false, AtomicRwOp::Relaxed)?,\n-            \"atomic_and\" => this.atomic_op(args, dest, BinOp::BitAnd, false, AtomicRwOp::SeqCst)?,\n-            \"atomic_and_acq\" => this.atomic_op(args, dest, BinOp::BitAnd, false, AtomicRwOp::Acquire)?,\n-            \"atomic_and_rel\" => this.atomic_op(args, dest, BinOp::BitAnd, false, AtomicRwOp::Release)?,\n-            \"atomic_and_acqrel\" => this.atomic_op(args, dest, BinOp::BitAnd, false, AtomicRwOp::AcqRel)?,\n-            \"atomic_and_relaxed\" => this.atomic_op(args, dest, BinOp::BitAnd, false, AtomicRwOp::Relaxed)?,\n-            \"atomic_nand\" => this.atomic_op(args, dest, BinOp::BitAnd, true, AtomicRwOp::SeqCst)?,\n-            \"atomic_nand_acq\" => this.atomic_op(args, dest, BinOp::BitAnd, true, AtomicRwOp::Acquire)?,\n-            \"atomic_nand_rel\" => this.atomic_op(args, dest, BinOp::BitAnd, true, AtomicRwOp::Release)?,\n-            \"atomic_nand_acqrel\" => this.atomic_op(args, dest, BinOp::BitAnd, true, AtomicRwOp::AcqRel)?,\n-            \"atomic_nand_relaxed\" => this.atomic_op(args, dest, BinOp::BitAnd, true, AtomicRwOp::Relaxed)?,\n-            \"atomic_xadd\" => this.atomic_op(args, dest, BinOp::Add, false, AtomicRwOp::SeqCst)?,\n-            \"atomic_xadd_acq\" => this.atomic_op(args, dest, BinOp::Add, false, AtomicRwOp::Acquire)?,\n-            \"atomic_xadd_rel\" => this.atomic_op(args, dest, BinOp::Add, false, AtomicRwOp::Release)?,\n-            \"atomic_xadd_acqrel\" => this.atomic_op(args, dest, BinOp::Add, false, AtomicRwOp::AcqRel)?,\n-            \"atomic_xadd_relaxed\" => this.atomic_op(args, dest, BinOp::Add, false, AtomicRwOp::Relaxed)?,\n-            \"atomic_xsub\" => this.atomic_op(args, dest, BinOp::Sub, false, AtomicRwOp::SeqCst)?,\n-            \"atomic_xsub_acq\" => this.atomic_op(args, dest, BinOp::Sub, false, AtomicRwOp::Acquire)?,\n-            \"atomic_xsub_rel\" => this.atomic_op(args, dest, BinOp::Sub, false, AtomicRwOp::Release)?,\n-            \"atomic_xsub_acqrel\" => this.atomic_op(args, dest, BinOp::Sub, false, AtomicRwOp::AcqRel)?,\n-            \"atomic_xsub_relaxed\" => this.atomic_op(args, dest, BinOp::Sub, false, AtomicRwOp::Relaxed)?,\n+                args,\n+                dest,\n+                AtomicRwOp::SeqCst,\n+                AtomicReadOp::Acquire,\n+            )?,\n \n+            \"atomic_or\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitOr, false),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_or_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitOr, false),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_or_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitOr, false),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_or_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitOr, false),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_or_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitOr, false),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_xor\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitXor, false),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_xor_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitXor, false),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_xor_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitXor, false),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_xor_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitXor, false),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_xor_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitXor, false),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_and\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, false),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_and_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, false),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_and_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, false),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_and_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, false),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_and_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, false),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_nand\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, true),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_nand_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, true),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_nand_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, true),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_nand_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, true),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_nand_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::BitAnd, true),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_xadd\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Add, false),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_xadd_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Add, false),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_xadd_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Add, false),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_xadd_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Add, false),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_xadd_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Add, false),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_xsub\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Sub, false),\n+                AtomicRwOp::SeqCst,\n+            )?,\n+            \"atomic_xsub_acq\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Sub, false),\n+                AtomicRwOp::Acquire,\n+            )?,\n+            \"atomic_xsub_rel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Sub, false),\n+                AtomicRwOp::Release,\n+            )?,\n+            \"atomic_xsub_acqrel\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Sub, false),\n+                AtomicRwOp::AcqRel,\n+            )?,\n+            \"atomic_xsub_relaxed\" => this.atomic_op_min_max(\n+                args,\n+                dest,\n+                AtomicOp::MirOp(BinOp::Sub, false),\n+                AtomicRwOp::Relaxed,\n+            )?,\n+            \"atomic_min\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::SeqCst)?,\n+            \"atomic_min_acq\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Acquire)?,\n+            \"atomic_min_rel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Release)?,\n+            \"atomic_min_acqrel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::AcqRel)?,\n+            \"atomic_min_relaxed\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Relaxed)?,\n+            \"atomic_max\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::SeqCst)?,\n+            \"atomic_max_acq\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Acquire)?,\n+            \"atomic_max_rel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Release)?,\n+            \"atomic_max_acqrel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::AcqRel)?,\n+            \"atomic_max_relaxed\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Relaxed)?,\n+            \"atomic_umin\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::SeqCst)?,\n+            \"atomic_umin_acq\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Acquire)?,\n+            \"atomic_umin_rel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Release)?,\n+            \"atomic_umin_acqrel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::AcqRel)?,\n+            \"atomic_umin_relaxed\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Min, AtomicRwOp::Relaxed)?,\n+            \"atomic_umax\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::SeqCst)?,\n+            \"atomic_umax_acq\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Acquire)?,\n+            \"atomic_umax_rel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Release)?,\n+            \"atomic_umax_acqrel\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::AcqRel)?,\n+            \"atomic_umax_relaxed\" =>\n+                this.atomic_op_min_max(args, dest, AtomicOp::Max, AtomicRwOp::Relaxed)?,\n \n             // Query type information\n-            \"assert_zero_valid\" |\n-            \"assert_uninit_valid\" => {\n+            \"assert_zero_valid\" | \"assert_uninit_valid\" => {\n                 let &[] = check_arg_count(args)?;\n                 let ty = instance.substs.type_at(0);\n                 let layout = this.layout_of(ty)?;\n                 // Abort here because the caller might not be panic safe.\n                 if layout.abi.is_uninhabited() {\n                     // Use this message even for the other intrinsics, as that's what codegen does\n-                    throw_machine_stop!(TerminationInfo::Abort(format!(\"aborted execution: attempted to instantiate uninhabited type `{}`\", ty)))\n+                    throw_machine_stop!(TerminationInfo::Abort(format!(\n+                        \"aborted execution: attempted to instantiate uninhabited type `{}`\",\n+                        ty\n+                    )))\n                 }\n-                if intrinsic_name == \"assert_zero_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ true).unwrap() {\n-                    throw_machine_stop!(TerminationInfo::Abort(format!(\"aborted execution: attempted to zero-initialize type `{}`, which is invalid\", ty)))\n+                if intrinsic_name == \"assert_zero_valid\"\n+                    && !layout.might_permit_raw_init(this, /*zero:*/ true).unwrap()\n+                {\n+                    throw_machine_stop!(TerminationInfo::Abort(format!(\n+                        \"aborted execution: attempted to zero-initialize type `{}`, which is invalid\",\n+                        ty\n+                    )))\n                 }\n-                if intrinsic_name == \"assert_uninit_valid\" && !layout.might_permit_raw_init(this, /*zero:*/ false).unwrap() {\n-                    throw_machine_stop!(TerminationInfo::Abort(format!(\"aborted execution: attempted to leave type `{}` uninitialized, which is invalid\", ty)))\n+                if intrinsic_name == \"assert_uninit_valid\"\n+                    && !layout.might_permit_raw_init(this, /*zero:*/ false).unwrap()\n+                {\n+                    throw_machine_stop!(TerminationInfo::Abort(format!(\n+                        \"aborted execution: attempted to leave type `{}` uninitialized, which is invalid\",\n+                        ty\n+                    )))\n                 }\n             }\n \n@@ -419,12 +663,13 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n     }\n \n     fn atomic_load(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>,\n-        atomic: AtomicReadOp\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic: AtomicReadOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n-\n         let &[ref place] = check_arg_count(args)?;\n         let place = this.deref_operand(place)?;\n \n@@ -440,7 +685,11 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(())\n     }\n \n-    fn atomic_store(&mut self, args: &[OpTy<'tcx, Tag>], atomic: AtomicWriteOp) -> InterpResult<'tcx> {\n+    fn atomic_store(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicWriteOp,\n+    ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n         let &[ref place, ref val] = check_arg_count(args)?;\n@@ -458,28 +707,40 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         Ok(())\n     }\n \n-    fn compiler_fence(&mut self, args: &[OpTy<'tcx, Tag>], atomic: AtomicFenceOp) -> InterpResult<'tcx> {\n+    fn compiler_fence(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicFenceOp,\n+    ) -> InterpResult<'tcx> {\n         let &[] = check_arg_count(args)?;\n         let _ = atomic;\n         //FIXME: compiler fences are currently ignored\n         Ok(())\n     }\n \n-    fn atomic_fence(&mut self, args: &[OpTy<'tcx, Tag>], atomic: AtomicFenceOp) -> InterpResult<'tcx> {\n+    fn atomic_fence(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        atomic: AtomicFenceOp,\n+    ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n         let &[] = check_arg_count(args)?;\n         this.validate_atomic_fence(atomic)?;\n         Ok(())\n     }\n \n-    fn atomic_op(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>,\n-        op: mir::BinOp, neg: bool, atomic: AtomicRwOp\n+    fn atomic_op_min_max(\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic_op: AtomicOp,\n+        atomic: AtomicRwOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n         let &[ref place, ref rhs] = check_arg_count(args)?;\n         let place = this.deref_operand(place)?;\n+\n         if !place.layout.ty.is_integral() {\n             bug!(\"Atomic arithmetic operations only work on integer types\");\n         }\n@@ -490,14 +751,31 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         // be 8-aligned).\n         let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n         this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n-        \n-        let old = this.atomic_op_immediate(&place, &rhs, op, neg, atomic)?;\n-        this.write_immediate(*old, dest)?; // old value is returned\n-        Ok(())\n+\n+        match atomic_op {\n+            AtomicOp::Min => {\n+                let old = this.atomic_min_max_scalar(&place, rhs, true, atomic)?;\n+                this.write_immediate(*old, &dest)?; // old value is returned\n+                Ok(())\n+            }\n+            AtomicOp::Max => {\n+                let old = this.atomic_min_max_scalar(&place, rhs, false, atomic)?;\n+                this.write_immediate(*old, &dest)?; // old value is returned\n+                Ok(())\n+            }\n+            AtomicOp::MirOp(op, neg) => {\n+                let old = this.atomic_op_immediate(&place, &rhs, op, neg, atomic)?;\n+                this.write_immediate(*old, dest)?; // old value is returned\n+                Ok(())\n+            }\n+        }\n     }\n-    \n+\n     fn atomic_exchange(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>, atomic: AtomicRwOp\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        atomic: AtomicRwOp,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n@@ -517,8 +795,12 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n     }\n \n     fn atomic_compare_exchange_impl(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOp, fail: AtomicReadOp, can_fail_spuriously: bool\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOp,\n+        fail: AtomicReadOp,\n+        can_fail_spuriously: bool,\n     ) -> InterpResult<'tcx> {\n         let this = self.eval_context_mut();\n \n@@ -527,16 +809,19 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         let expect_old = this.read_immediate(expect_old)?; // read as immediate for the sake of `binary_op()`\n         let new = this.read_scalar(new)?;\n \n-\n         // Check alignment requirements. Atomics must always be aligned to their size,\n         // even if the type they wrap would be less aligned (e.g. AtomicU64 on 32bit must\n         // be 8-aligned).\n         let align = Align::from_bytes(place.layout.size.bytes()).unwrap();\n         this.memory.check_ptr_access(place.ptr, place.layout.size, align)?;\n \n-        \n         let old = this.atomic_compare_exchange_scalar(\n-            &place, &expect_old, new, success, fail, can_fail_spuriously\n+            &place,\n+            &expect_old,\n+            new,\n+            success,\n+            fail,\n+            can_fail_spuriously,\n         )?;\n \n         // Return old value.\n@@ -545,15 +830,21 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n     }\n \n     fn atomic_compare_exchange(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOp, fail: AtomicReadOp\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOp,\n+        fail: AtomicReadOp,\n     ) -> InterpResult<'tcx> {\n         self.atomic_compare_exchange_impl(args, dest, success, fail, false)\n     }\n \n     fn atomic_compare_exchange_weak(\n-        &mut self, args: &[OpTy<'tcx, Tag>], dest: &PlaceTy<'tcx, Tag>,\n-        success: AtomicRwOp, fail: AtomicReadOp\n+        &mut self,\n+        args: &[OpTy<'tcx, Tag>],\n+        dest: &PlaceTy<'tcx, Tag>,\n+        success: AtomicRwOp,\n+        fail: AtomicReadOp,\n     ) -> InterpResult<'tcx> {\n         self.atomic_compare_exchange_impl(args, dest, success, fail, true)\n     }\n@@ -564,7 +855,7 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n         dest_ty: ty::Ty<'tcx>,\n     ) -> InterpResult<'tcx, Scalar<Tag>>\n     where\n-        F: Float + Into<Scalar<Tag>>\n+        F: Float + Into<Scalar<Tag>>,\n     {\n         let this = self.eval_context_ref();\n \n@@ -585,7 +876,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                     // `f` was not representable in this integer type.\n                     throw_ub_format!(\n                         \"`float_to_int_unchecked` intrinsic called on {} which cannot be represented in target type `{:?}`\",\n-                        f, dest_ty,\n+                        f,\n+                        dest_ty,\n                     );\n                 }\n             }\n@@ -600,7 +892,8 @@ pub trait EvalContextExt<'mir, 'tcx: 'mir>: crate::MiriEvalContextExt<'mir, 'tcx\n                     // `f` was not representable in this integer type.\n                     throw_ub_format!(\n                         \"`float_to_int_unchecked` intrinsic called on {} which cannot be represented in target type `{:?}`\",\n-                        f, dest_ty,\n+                        f,\n+                        dest_ty,\n                     );\n                 }\n             }"}, {"sha": "9a9e852ecf50f9114386e7bcedb36b1c78ed47ec", "filename": "tests/run-pass/atomic.rs", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/2670839e1af540a496a0d889fce9ad42529ecc11/tests%2Frun-pass%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2670839e1af540a496a0d889fce9ad42529ecc11/tests%2Frun-pass%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fatomic.rs?ref=2670839e1af540a496a0d889fce9ad42529ecc11", "patch": "@@ -74,6 +74,20 @@ fn atomic_u64() {\n     assert_eq!(ATOMIC.compare_exchange(0, 0x100, AcqRel, Acquire), Err(1));\n     compare_exchange_weak_loop!(ATOMIC, 1, 0x100, AcqRel, Acquire);\n     assert_eq!(ATOMIC.load(Relaxed), 0x100);\n+\n+    assert_eq!(ATOMIC.fetch_max(0x10, SeqCst), 0x100);\n+    assert_eq!(ATOMIC.fetch_max(0x100, SeqCst), 0x100);\n+    assert_eq!(ATOMIC.fetch_max(0x1000, SeqCst), 0x100);\n+    assert_eq!(ATOMIC.fetch_max(0x1000, SeqCst), 0x1000);\n+    assert_eq!(ATOMIC.fetch_max(0x2000, SeqCst), 0x1000);\n+    assert_eq!(ATOMIC.fetch_max(0x2000, SeqCst), 0x2000);\n+\n+    assert_eq!(ATOMIC.fetch_min(0x2000, SeqCst), 0x2000);\n+    assert_eq!(ATOMIC.fetch_min(0x2000, SeqCst), 0x2000);\n+    assert_eq!(ATOMIC.fetch_min(0x1000, SeqCst), 0x2000);\n+    assert_eq!(ATOMIC.fetch_min(0x1000, SeqCst), 0x1000);\n+    assert_eq!(ATOMIC.fetch_min(0x100, SeqCst), 0x1000);\n+    assert_eq!(ATOMIC.fetch_min(0x10, SeqCst), 0x100);\n }\n \n fn atomic_fences() {"}]}