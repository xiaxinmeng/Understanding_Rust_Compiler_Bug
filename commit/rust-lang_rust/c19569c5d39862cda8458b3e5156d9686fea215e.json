{"sha": "c19569c5d39862cda8458b3e5156d9686fea215e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMxOTU2OWM1ZDM5ODYyY2RhODQ1OGIzZTUxNTZkOTY4NmZlYTIxNWU=", "commit": {"author": {"name": "Seiichi Uchida", "email": "seuchida@gmail.com", "date": "2018-08-05T01:50:24Z"}, "committer": {"name": "Seiichi Uchida", "email": "seuchida@gmail.com", "date": "2018-08-05T01:50:24Z"}, "message": "Add a test for #2896", "tree": {"sha": "64cd7a25f7cab5637daebb2ff4181ee1313802c3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/64cd7a25f7cab5637daebb2ff4181ee1313802c3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c19569c5d39862cda8458b3e5156d9686fea215e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c19569c5d39862cda8458b3e5156d9686fea215e", "html_url": "https://github.com/rust-lang/rust/commit/c19569c5d39862cda8458b3e5156d9686fea215e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c19569c5d39862cda8458b3e5156d9686fea215e/comments", "author": {"login": "topecongiro", "id": 21980157, "node_id": "MDQ6VXNlcjIxOTgwMTU3", "avatar_url": "https://avatars.githubusercontent.com/u/21980157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/topecongiro", "html_url": "https://github.com/topecongiro", "followers_url": "https://api.github.com/users/topecongiro/followers", "following_url": "https://api.github.com/users/topecongiro/following{/other_user}", "gists_url": "https://api.github.com/users/topecongiro/gists{/gist_id}", "starred_url": "https://api.github.com/users/topecongiro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/topecongiro/subscriptions", "organizations_url": "https://api.github.com/users/topecongiro/orgs", "repos_url": "https://api.github.com/users/topecongiro/repos", "events_url": "https://api.github.com/users/topecongiro/events{/privacy}", "received_events_url": "https://api.github.com/users/topecongiro/received_events", "type": "User", "site_admin": false}, "committer": {"login": "topecongiro", "id": 21980157, "node_id": "MDQ6VXNlcjIxOTgwMTU3", "avatar_url": "https://avatars.githubusercontent.com/u/21980157?v=4", "gravatar_id": "", "url": "https://api.github.com/users/topecongiro", "html_url": "https://github.com/topecongiro", "followers_url": "https://api.github.com/users/topecongiro/followers", "following_url": "https://api.github.com/users/topecongiro/following{/other_user}", "gists_url": "https://api.github.com/users/topecongiro/gists{/gist_id}", "starred_url": "https://api.github.com/users/topecongiro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/topecongiro/subscriptions", "organizations_url": "https://api.github.com/users/topecongiro/orgs", "repos_url": "https://api.github.com/users/topecongiro/repos", "events_url": "https://api.github.com/users/topecongiro/events{/privacy}", "received_events_url": "https://api.github.com/users/topecongiro/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "da17b689595ddc863b02eb1ba6831c87cefc1e21", "url": "https://api.github.com/repos/rust-lang/rust/commits/da17b689595ddc863b02eb1ba6831c87cefc1e21", "html_url": "https://github.com/rust-lang/rust/commit/da17b689595ddc863b02eb1ba6831c87cefc1e21"}], "stats": {"total": 324, "additions": 324, "deletions": 0}, "files": [{"sha": "f648e64b1e3731da06bb12ca5abcc3cdeaa2909e", "filename": "tests/source/issue-2896.rs", "status": "added", "additions": 161, "deletions": 0, "changes": 161, "blob_url": "https://github.com/rust-lang/rust/blob/c19569c5d39862cda8458b3e5156d9686fea215e/tests%2Fsource%2Fissue-2896.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c19569c5d39862cda8458b3e5156d9686fea215e/tests%2Fsource%2Fissue-2896.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fsource%2Fissue-2896.rs?ref=c19569c5d39862cda8458b3e5156d9686fea215e", "patch": "@@ -0,0 +1,161 @@\n+extern crate rand;\n+extern crate timely;\n+extern crate differential_dataflow;\n+\n+use rand::{Rng, SeedableRng, StdRng};\n+\n+use timely::dataflow::operators::*;\n+\n+use differential_dataflow::AsCollection;\n+use differential_dataflow::operators::*;\n+use differential_dataflow::input::InputSession;\n+\n+// mod loglikelihoodratio;\n+\n+fn main() {\n+\n+  // define a new timely dataflow computation. \n+  timely::execute_from_args(std::env::args().skip(6), move |worker| {\n+\n+    // capture parameters of the experiment.\n+    let users: usize = std::env::args().nth(1).unwrap().parse().unwrap();\n+    let items: usize = std::env::args().nth(2).unwrap().parse().unwrap();\n+    let scale: usize = std::env::args().nth(3).unwrap().parse().unwrap();\n+    let batch: usize = std::env::args().nth(4).unwrap().parse().unwrap();\n+    let noisy: bool = std::env::args().nth(5).unwrap() == \"noisy\";\n+\n+    let index = worker.index();\n+    let peers = worker.peers();\n+\n+    let (input, probe) = worker.dataflow(|scope| {\n+\n+      // input of (user, item) collection.\n+      let (input, occurrences) = scope.new_input();\n+      let occurrences = occurrences.as_collection();\n+\n+      //TODO adjust code to only work with upper triangular half of cooccurrence matrix\n+\n+      /* Compute the cooccurrence matrix C = A'A from the binary interaction matrix A. */\n+      let cooccurrences = \n+      occurrences\n+        .join_map(&occurrences, |_user, &item_a, &item_b| (item_a, item_b))\n+        .filter(|&(item_a, item_b)| item_a != item_b)\n+        .count();\n+\n+      /* compute the rowsums of C indicating how often we encounter individual items. */\n+      let row_sums = \n+      occurrences\n+        .map(|(_user, item)| item)\n+        .count();\n+\n+      // row_sums.inspect(|record| println!(\"[row_sums] {:?}\", record));\n+\n+      /* Join the cooccurrence pairs with the corresponding row sums. */\n+      let mut cooccurrences_with_row_sums = cooccurrences\n+        .map(|((item_a, item_b), num_cooccurrences)| (item_a, (item_b, num_cooccurrences)))\n+        .join_map(&row_sums, |&item_a, &(item_b, num_cooccurrences), &row_sum_a| {\n+          assert!(row_sum_a > 0);\n+          (item_b, (item_a, num_cooccurrences, row_sum_a))\n+        })\n+        .join_map(&row_sums, |&item_b, &(item_a, num_cooccurrences, row_sum_a), &row_sum_b| {\n+          assert!(row_sum_a > 0);\n+          assert!(row_sum_b > 0);\n+          (item_a, (item_b, num_cooccurrences, row_sum_a, row_sum_b))\n+        });\n+\n+      // cooccurrences_with_row_sums\n+      //     .inspect(|record| println!(\"[cooccurrences_with_row_sums] {:?}\", record));\n+\n+      // //TODO compute top-k \"similar items\" per item\n+      // /* Compute LLR scores for each item pair. */\n+      // let llr_scores = cooccurrences_with_row_sums.map(\n+      //   |(item_a, (item_b, num_cooccurrences, row_sum_a, row_sum_b))| {\n+\n+      //     println!(\n+      //       \"[llr_scores] item_a={} item_b={}, num_cooccurrences={} row_sum_a={} row_sum_b={}\",\n+      //       item_a, item_b, num_cooccurrences, row_sum_a, row_sum_b);\n+\n+      //     let k11: isize = num_cooccurrences;\n+      //     let k12: isize = row_sum_a as isize - k11;\n+      //     let k21: isize = row_sum_b as isize - k11;\n+      //     let k22: isize = 10000 - k12 - k21 + k11;\n+\n+      //     let llr_score = loglikelihoodratio::log_likelihood_ratio(k11, k12, k21, k22);\n+\n+      //     ((item_a, item_b), llr_score)\n+      //   });\n+\n+      if noisy {\n+        cooccurrences_with_row_sums = \n+        cooccurrences_with_row_sums\n+          .inspect(|x| println!(\"change: {:?}\", x));\n+      }\n+\n+      let probe = \n+      cooccurrences_with_row_sums\n+          .probe();\n+/*\n+      // produce the (item, item) collection\n+      let cooccurrences = occurrences\n+        .join_map(&occurrences, |_user, &item_a, &item_b| (item_a, item_b));\n+      // count the occurrences of each item.\n+      let counts = cooccurrences\n+        .map(|(item_a,_)| item_a)\n+        .count();\n+      // produce ((item1, item2), count1, count2, count12) tuples\n+      let cooccurrences_with_counts = cooccurrences\n+        .join_map(&counts, |&item_a, &item_b, &count_item_a| (item_b, (item_a, count_item_a)))\n+        .join_map(&counts, |&item_b, &(item_a, count_item_a), &count_item_b| {\n+          ((item_a, item_b), count_item_a, count_item_b)\n+        });\n+      let probe = cooccurrences_with_counts\n+        .inspect(|x| println!(\"change: {:?}\", x))\n+        .probe();\n+*/\n+      (input, probe)\n+    });\n+\n+    let seed: &[_] = &[1, 2, 3, index];\n+    let mut rng1: StdRng = SeedableRng::from_seed(seed);  // rng for edge additions\n+    let mut rng2: StdRng = SeedableRng::from_seed(seed);  // rng for edge deletions\n+\n+    let mut input = InputSession::from(input);\n+\n+    for count in 0 .. scale {\n+      if count % peers == index {\n+        let user = rng1.gen_range(0, users);\n+        let item = rng1.gen_range(0, items);\n+        // println!(\"[INITIAL INPUT] ({}, {})\", user, item);\n+        input.insert((user, item));\n+      }\n+    }\n+\n+    // load the initial data up!\n+    while probe.less_than(input.time()) { worker.step(); }\n+\n+    for round in 1 .. {\n+\n+      for element in (round * batch) .. ((round + 1) * batch) {\n+        if element % peers == index {\n+          // advance the input timestamp.\n+          input.advance_to(round * batch);\n+          // insert a new item.\n+          let user = rng1.gen_range(0, users);\n+          let item = rng1.gen_range(0, items);\n+          if noisy { println!(\"[INPUT: insert] ({}, {})\", user, item); }\n+          input.insert((user, item));\n+          // remove an old item.\n+          let user = rng2.gen_range(0, users);\n+          let item = rng2.gen_range(0, items);\n+          if noisy { println!(\"[INPUT: remove] ({}, {})\", user, item); }\n+          input.remove((user, item));\n+        }\n+      }\n+\n+      input.advance_to(round * batch);\n+      input.flush();\n+\n+      while probe.less_than(input.time()) { worker.step(); }\n+    }\n+  }).unwrap();\n+}"}, {"sha": "c750d96aa67c2d54f167df080c6f90e362c7e34e", "filename": "tests/target/issue-2896.rs", "status": "added", "additions": 163, "deletions": 0, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/c19569c5d39862cda8458b3e5156d9686fea215e/tests%2Ftarget%2Fissue-2896.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c19569c5d39862cda8458b3e5156d9686fea215e/tests%2Ftarget%2Fissue-2896.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Ftarget%2Fissue-2896.rs?ref=c19569c5d39862cda8458b3e5156d9686fea215e", "patch": "@@ -0,0 +1,163 @@\n+extern crate differential_dataflow;\n+extern crate rand;\n+extern crate timely;\n+\n+use rand::{Rng, SeedableRng, StdRng};\n+\n+use timely::dataflow::operators::*;\n+\n+use differential_dataflow::input::InputSession;\n+use differential_dataflow::operators::*;\n+use differential_dataflow::AsCollection;\n+\n+// mod loglikelihoodratio;\n+\n+fn main() {\n+    // define a new timely dataflow computation.\n+    timely::execute_from_args(std::env::args().skip(6), move |worker| {\n+        // capture parameters of the experiment.\n+        let users: usize = std::env::args().nth(1).unwrap().parse().unwrap();\n+        let items: usize = std::env::args().nth(2).unwrap().parse().unwrap();\n+        let scale: usize = std::env::args().nth(3).unwrap().parse().unwrap();\n+        let batch: usize = std::env::args().nth(4).unwrap().parse().unwrap();\n+        let noisy: bool = std::env::args().nth(5).unwrap() == \"noisy\";\n+\n+        let index = worker.index();\n+        let peers = worker.peers();\n+\n+        let (input, probe) = worker.dataflow(|scope| {\n+            // input of (user, item) collection.\n+            let (input, occurrences) = scope.new_input();\n+            let occurrences = occurrences.as_collection();\n+\n+            //TODO adjust code to only work with upper triangular half of cooccurrence matrix\n+\n+            /* Compute the cooccurrence matrix C = A'A from the binary interaction matrix A. */\n+            let cooccurrences = occurrences\n+                .join_map(&occurrences, |_user, &item_a, &item_b| (item_a, item_b))\n+                .filter(|&(item_a, item_b)| item_a != item_b)\n+                .count();\n+\n+            /* compute the rowsums of C indicating how often we encounter individual items. */\n+            let row_sums = occurrences.map(|(_user, item)| item).count();\n+\n+            // row_sums.inspect(|record| println!(\"[row_sums] {:?}\", record));\n+\n+            /* Join the cooccurrence pairs with the corresponding row sums. */\n+            let mut cooccurrences_with_row_sums = cooccurrences\n+                .map(|((item_a, item_b), num_cooccurrences)| (item_a, (item_b, num_cooccurrences)))\n+                .join_map(\n+                    &row_sums,\n+                    |&item_a, &(item_b, num_cooccurrences), &row_sum_a| {\n+                        assert!(row_sum_a > 0);\n+                        (item_b, (item_a, num_cooccurrences, row_sum_a))\n+                    },\n+                ).join_map(\n+                    &row_sums,\n+                    |&item_b, &(item_a, num_cooccurrences, row_sum_a), &row_sum_b| {\n+                        assert!(row_sum_a > 0);\n+                        assert!(row_sum_b > 0);\n+                        (item_a, (item_b, num_cooccurrences, row_sum_a, row_sum_b))\n+                    },\n+                );\n+\n+            // cooccurrences_with_row_sums\n+            //     .inspect(|record| println!(\"[cooccurrences_with_row_sums] {:?}\", record));\n+\n+            // //TODO compute top-k \"similar items\" per item\n+            // /* Compute LLR scores for each item pair. */\n+            // let llr_scores = cooccurrences_with_row_sums.map(\n+            //   |(item_a, (item_b, num_cooccurrences, row_sum_a, row_sum_b))| {\n+\n+            //     println!(\n+            //       \"[llr_scores] item_a={} item_b={}, num_cooccurrences={} row_sum_a={} row_sum_b={}\",\n+            //       item_a, item_b, num_cooccurrences, row_sum_a, row_sum_b);\n+\n+            //     let k11: isize = num_cooccurrences;\n+            //     let k12: isize = row_sum_a as isize - k11;\n+            //     let k21: isize = row_sum_b as isize - k11;\n+            //     let k22: isize = 10000 - k12 - k21 + k11;\n+\n+            //     let llr_score = loglikelihoodratio::log_likelihood_ratio(k11, k12, k21, k22);\n+\n+            //     ((item_a, item_b), llr_score)\n+            //   });\n+\n+            if noisy {\n+                cooccurrences_with_row_sums =\n+                    cooccurrences_with_row_sums.inspect(|x| println!(\"change: {:?}\", x));\n+            }\n+\n+            let probe = cooccurrences_with_row_sums.probe();\n+            /*\n+      // produce the (item, item) collection\n+      let cooccurrences = occurrences\n+        .join_map(&occurrences, |_user, &item_a, &item_b| (item_a, item_b));\n+      // count the occurrences of each item.\n+      let counts = cooccurrences\n+        .map(|(item_a,_)| item_a)\n+        .count();\n+      // produce ((item1, item2), count1, count2, count12) tuples\n+      let cooccurrences_with_counts = cooccurrences\n+        .join_map(&counts, |&item_a, &item_b, &count_item_a| (item_b, (item_a, count_item_a)))\n+        .join_map(&counts, |&item_b, &(item_a, count_item_a), &count_item_b| {\n+          ((item_a, item_b), count_item_a, count_item_b)\n+        });\n+      let probe = cooccurrences_with_counts\n+        .inspect(|x| println!(\"change: {:?}\", x))\n+        .probe();\n+*/\n+            (input, probe)\n+        });\n+\n+        let seed: &[_] = &[1, 2, 3, index];\n+        let mut rng1: StdRng = SeedableRng::from_seed(seed); // rng for edge additions\n+        let mut rng2: StdRng = SeedableRng::from_seed(seed); // rng for edge deletions\n+\n+        let mut input = InputSession::from(input);\n+\n+        for count in 0..scale {\n+            if count % peers == index {\n+                let user = rng1.gen_range(0, users);\n+                let item = rng1.gen_range(0, items);\n+                // println!(\"[INITIAL INPUT] ({}, {})\", user, item);\n+                input.insert((user, item));\n+            }\n+        }\n+\n+        // load the initial data up!\n+        while probe.less_than(input.time()) {\n+            worker.step();\n+        }\n+\n+        for round in 1.. {\n+            for element in (round * batch)..((round + 1) * batch) {\n+                if element % peers == index {\n+                    // advance the input timestamp.\n+                    input.advance_to(round * batch);\n+                    // insert a new item.\n+                    let user = rng1.gen_range(0, users);\n+                    let item = rng1.gen_range(0, items);\n+                    if noisy {\n+                        println!(\"[INPUT: insert] ({}, {})\", user, item);\n+                    }\n+                    input.insert((user, item));\n+                    // remove an old item.\n+                    let user = rng2.gen_range(0, users);\n+                    let item = rng2.gen_range(0, items);\n+                    if noisy {\n+                        println!(\"[INPUT: remove] ({}, {})\", user, item);\n+                    }\n+                    input.remove((user, item));\n+                }\n+            }\n+\n+            input.advance_to(round * batch);\n+            input.flush();\n+\n+            while probe.less_than(input.time()) {\n+                worker.step();\n+            }\n+        }\n+    }).unwrap();\n+}"}]}