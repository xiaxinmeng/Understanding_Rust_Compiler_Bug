{"sha": "7365bee5066aae03e52a67c3fac6a8129140d90f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjczNjViZWU1MDY2YWFlMDNlNTJhNjdjM2ZhYzZhODEyOTE0MGQ5MGY=", "commit": {"author": {"name": "Inokentiy Babushkin", "email": "twk@twki.de", "date": "2018-03-09T21:49:37Z"}, "committer": {"name": "Inokentiy Babushkin", "email": "twk@twki.de", "date": "2018-04-26T19:54:22Z"}, "message": "Begun refactoring auto trait discovery for use outside rustc.", "tree": {"sha": "750f7dc68df680b5238dbdf8b1b4827d4300ae50", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/750f7dc68df680b5238dbdf8b1b4827d4300ae50"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7365bee5066aae03e52a67c3fac6a8129140d90f", "comment_count": 0, "verification": {"verified": false, "reason": "unverified_email", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEEXezFNCHL3+3lgSPSfvyOxSJN6OwFAlriLm4ACgkQfvyOxSJN\n6OwHOQ/8CTr/XerB3OEgzvFqecitTebSAqC3eP8Wj80WDbIqkqRFCKGAGLjODeyd\nbPVTVtyJARdhCWfebzNL+23vyFxQqsBm9BSiK/Qx33XyO2ZtcfCvFP6d8nnexIte\nmKERggtj4B6YZRigLSeQbhvKH50EULCzz8bY2wpavr5JtPL9czaMmoHK48kBHYm8\n/BjJcbtCyuSukRdtajucjSk2tYkawg9eeJdFBbUkcY17ePEYFU3fS9fezQJGz5bn\nvVAK3B/yq8zVChZSA4CwAjY3WPEnDYiD3eJI21lZduIbG/UkgfQsdh78D3KUP1wh\nEAHbfkusmPc49NAQ2aogfmTbJs2pzPUE26G4gQetFC5TKLZpBiV1dJmDyh9sYMqH\n8XKtDmHhsBCFgXjZp0PI7Mq8bmWkzChpJgeb0NoS23/Xe9y/qKXfWXARdQXwGP/H\nmmmZ2W76ePKc7zaXR3UhexcmF/rC+zfu200aXSMqx1iJ5rLUD0V/v38Dc2UeGXZ0\nXnfsLAIkq6K5TVKbxDp65zCXclKw9uCtexxy17ryIEUAia4RjM2hiTpCdYsKnfbD\nHNA7z3PxqaWW1ERltE1ca4aWAU3x/TI+h4G46xpTBIa5D8OJ00WoN6b3Yb7deGUq\nFB/t/WAtSYxRTgBWyZ1XEgS5BedZyf45DUQjKzlfZCrSr+LslTU=\n=RaA+\n-----END PGP SIGNATURE-----", "payload": "tree 750f7dc68df680b5238dbdf8b1b4827d4300ae50\nparent 949010d23e9f7037a8e6f323588873b3d2438fb1\nauthor Inokentiy Babushkin <twk@twki.de> 1520632177 +0100\ncommitter Inokentiy Babushkin <twk@twki.de> 1524772462 +0200\n\nBegun refactoring auto trait discovery for use outside rustc.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7365bee5066aae03e52a67c3fac6a8129140d90f", "html_url": "https://github.com/rust-lang/rust/commit/7365bee5066aae03e52a67c3fac6a8129140d90f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7365bee5066aae03e52a67c3fac6a8129140d90f/comments", "author": {"login": "ibabushkin", "id": 10811417, "node_id": "MDQ6VXNlcjEwODExNDE3", "avatar_url": "https://avatars.githubusercontent.com/u/10811417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibabushkin", "html_url": "https://github.com/ibabushkin", "followers_url": "https://api.github.com/users/ibabushkin/followers", "following_url": "https://api.github.com/users/ibabushkin/following{/other_user}", "gists_url": "https://api.github.com/users/ibabushkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibabushkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibabushkin/subscriptions", "organizations_url": "https://api.github.com/users/ibabushkin/orgs", "repos_url": "https://api.github.com/users/ibabushkin/repos", "events_url": "https://api.github.com/users/ibabushkin/events{/privacy}", "received_events_url": "https://api.github.com/users/ibabushkin/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ibabushkin", "id": 10811417, "node_id": "MDQ6VXNlcjEwODExNDE3", "avatar_url": "https://avatars.githubusercontent.com/u/10811417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ibabushkin", "html_url": "https://github.com/ibabushkin", "followers_url": "https://api.github.com/users/ibabushkin/followers", "following_url": "https://api.github.com/users/ibabushkin/following{/other_user}", "gists_url": "https://api.github.com/users/ibabushkin/gists{/gist_id}", "starred_url": "https://api.github.com/users/ibabushkin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ibabushkin/subscriptions", "organizations_url": "https://api.github.com/users/ibabushkin/orgs", "repos_url": "https://api.github.com/users/ibabushkin/repos", "events_url": "https://api.github.com/users/ibabushkin/events{/privacy}", "received_events_url": "https://api.github.com/users/ibabushkin/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "949010d23e9f7037a8e6f323588873b3d2438fb1", "url": "https://api.github.com/repos/rust-lang/rust/commits/949010d23e9f7037a8e6f323588873b3d2438fb1", "html_url": "https://github.com/rust-lang/rust/commit/949010d23e9f7037a8e6f323588873b3d2438fb1"}], "stats": {"total": 806, "additions": 806, "deletions": 0}, "files": [{"sha": "7cdec4b84f6ad1576a160ed2d5e309c99252fef7", "filename": "src/librustc/traits/auto_trait.rs", "status": "added", "additions": 804, "deletions": 0, "changes": 804, "blob_url": "https://github.com/rust-lang/rust/blob/7365bee5066aae03e52a67c3fac6a8129140d90f/src%2Flibrustc%2Ftraits%2Fauto_trait.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7365bee5066aae03e52a67c3fac6a8129140d90f/src%2Flibrustc%2Ftraits%2Fauto_trait.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Fauto_trait.rs?ref=7365bee5066aae03e52a67c3fac6a8129140d90f", "patch": "@@ -0,0 +1,804 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use super::*;\n+\n+use std::collections::VecDeque;\n+use std::collections::hash_map::Entry;\n+\n+use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n+\n+use hir::WherePredicate;\n+\n+use infer::{InferCtxt, RegionObligation};\n+use infer::region_constraints::{Constraint, RegionConstraintData};\n+\n+use ty::{Region, RegionVid};\n+use ty::fold::TypeFolder;\n+\n+// TODO(twk): this is obviously not nice to duplicate like that\n+#[derive(Eq, PartialEq, Hash, Copy, Clone, Debug)]\n+enum RegionTarget<'tcx> {\n+    Region(Region<'tcx>),\n+    RegionVid(RegionVid)\n+}\n+\n+#[derive(Default, Debug, Clone)]\n+struct RegionDeps<'tcx> {\n+    larger: FxHashSet<RegionTarget<'tcx>>,\n+    smaller: FxHashSet<RegionTarget<'tcx>>\n+}\n+\n+enum AutoTraitResult {\n+    ExplicitImpl,\n+    PositiveImpl, /*(ty::Generics), TODO(twk)*/\n+    NegativeImpl,\n+}\n+\n+impl AutoTraitResult {\n+    fn is_auto(&self) -> bool {\n+        match *self {\n+            AutoTraitResult::PositiveImpl | AutoTraitResult::NegativeImpl => true,\n+            _ => false,\n+        }\n+    }\n+}\n+\n+pub struct AutoTraitFinder<'a, 'tcx: 'a> {\n+    pub tcx: &'a TyCtxt<'a, 'tcx, 'tcx>,\n+}\n+\n+impl<'a, 'tcx> AutoTraitFinder<'a, 'tcx> {\n+    fn find_auto_trait_generics(\n+        &self,\n+        did: DefId,\n+        trait_did: DefId,\n+        generics: &ty::Generics,\n+    ) -> AutoTraitResult {\n+        let tcx = self.tcx;\n+        let ty = self.tcx.type_of(did);\n+\n+        let orig_params = tcx.param_env(did);\n+\n+        let trait_ref = ty::TraitRef {\n+            def_id: trait_did,\n+            substs: tcx.mk_substs_trait(ty, &[]),\n+        };\n+\n+        let trait_pred = ty::Binder(trait_ref);\n+\n+        let bail_out = tcx.infer_ctxt().enter(|infcx| {\n+            let mut selcx = SelectionContext::with_negative(&infcx, true);\n+            let result = selcx.select(&Obligation::new(\n+                ObligationCause::dummy(),\n+                orig_params,\n+                trait_pred.to_poly_trait_predicate(),\n+            ));\n+            match result {\n+                Ok(Some(Vtable::VtableImpl(_))) => {\n+                    debug!(\n+                        \"find_auto_trait_generics(did={:?}, trait_did={:?}, generics={:?}): \\\n+                         manual impl found, bailing out\",\n+                        did, trait_did, generics\n+                    );\n+                    return true;\n+                }\n+                _ => return false,\n+            };\n+        });\n+\n+        // If an explicit impl exists, it always takes priority over an auto impl\n+        if bail_out {\n+            return AutoTraitResult::ExplicitImpl;\n+        }\n+\n+        return tcx.infer_ctxt().enter(|mut infcx| {\n+            let mut fresh_preds = FxHashSet();\n+\n+            // Due to the way projections are handled by SelectionContext, we need to run\n+            // evaluate_predicates twice: once on the original param env, and once on the result of\n+            // the first evaluate_predicates call.\n+            //\n+            // The problem is this: most of rustc, including SelectionContext and traits::project,\n+            // are designed to work with a concrete usage of a type (e.g. Vec<u8>\n+            // fn<T>() { Vec<T> }. This information will generally never change - given\n+            // the 'T' in fn<T>() { ... }, we'll never know anything else about 'T'.\n+            // If we're unable to prove that 'T' implements a particular trait, we're done -\n+            // there's nothing left to do but error out.\n+            //\n+            // However, synthesizing an auto trait impl works differently. Here, we start out with\n+            // a set of initial conditions - the ParamEnv of the struct/enum/union we're dealing\n+            // with - and progressively discover the conditions we need to fulfill for it to\n+            // implement a certain auto trait. This ends up breaking two assumptions made by trait\n+            // selection and projection:\n+            //\n+            // * We can always cache the result of a particular trait selection for the lifetime of\n+            // an InfCtxt\n+            // * Given a projection bound such as '<T as SomeTrait>::SomeItem = K', if 'T:\n+            // SomeTrait' doesn't hold, then we don't need to care about the 'SomeItem = K'\n+            //\n+            // We fix the first assumption by manually clearing out all of the InferCtxt's caches\n+            // in between calls to SelectionContext.select. This allows us to keep all of the\n+            // intermediate types we create bound to the 'tcx lifetime, rather than needing to lift\n+            // them between calls.\n+            //\n+            // We fix the second assumption by reprocessing the result of our first call to\n+            // evaluate_predicates. Using the example of '<T as SomeTrait>::SomeItem = K', our first\n+            // pass will pick up 'T: SomeTrait', but not 'SomeItem = K'. On our second pass,\n+            // traits::project will see that 'T: SomeTrait' is in our ParamEnv, allowing\n+            // SelectionContext to return it back to us.\n+\n+            let (new_env, user_env) = match self.evaluate_predicates(\n+                &mut infcx,\n+                did,\n+                trait_did,\n+                ty,\n+                orig_params.clone(),\n+                orig_params,\n+                &mut fresh_preds,\n+                false,\n+            ) {\n+                Some(e) => e,\n+                None => return AutoTraitResult::NegativeImpl,\n+            };\n+\n+            let (full_env, _full_user_env) = self.evaluate_predicates(\n+                &mut infcx,\n+                did,\n+                trait_did,\n+                ty,\n+                new_env.clone(),\n+                user_env,\n+                &mut fresh_preds,\n+                true,\n+            ).unwrap_or_else(|| {\n+                panic!(\n+                    \"Failed to fully process: {:?} {:?} {:?}\",\n+                    ty, trait_did, orig_params\n+                )\n+            });\n+\n+            debug!(\n+                \"find_auto_trait_generics(did={:?}, trait_did={:?}, generics={:?}): fulfilling \\\n+                 with {:?}\",\n+                did, trait_did, generics, full_env\n+            );\n+            infcx.clear_caches();\n+\n+            // At this point, we already have all of the bounds we need. FulfillmentContext is used\n+            // to store all of the necessary region/lifetime bounds in the InferContext, as well as\n+            // an additional sanity check.\n+            let mut fulfill = FulfillmentContext::new();\n+            fulfill.register_bound(\n+                &infcx,\n+                full_env,\n+                ty,\n+                trait_did,\n+                ObligationCause::misc(DUMMY_SP, ast::DUMMY_NODE_ID),\n+            );\n+            fulfill.select_all_or_error(&infcx).unwrap_or_else(|e| {\n+                panic!(\n+                    \"Unable to fulfill trait {:?} for '{:?}': {:?}\",\n+                    trait_did, ty, e\n+                )\n+            });\n+\n+            let names_map: FxHashMap<String, String> = generics\n+                .regions\n+                .iter()\n+                .map(|l| (l.name.as_str().to_string(), l.name.to_string()))\n+                // TODO(twk): Lifetime branding\n+                .collect();\n+\n+            let body_ids: FxHashSet<_> = infcx\n+                .region_obligations\n+                .borrow()\n+                .iter()\n+                .map(|&(id, _)| id)\n+                .collect();\n+\n+            for id in body_ids {\n+                infcx.process_registered_region_obligations(&[], None, full_env.clone(), id);\n+            }\n+\n+            let region_data = infcx\n+                .borrow_region_constraints()\n+                .region_constraint_data()\n+                .clone();\n+\n+            let lifetime_predicates = self.handle_lifetimes(&region_data, &names_map);\n+            let vid_to_region = self.map_vid_to_region(&region_data);\n+\n+            debug!(\n+                \"find_auto_trait_generics(did={:?}, trait_did={:?}, generics={:?}): computed \\\n+                 lifetime information '{:?}' '{:?}'\",\n+                did, trait_did, generics, lifetime_predicates, vid_to_region\n+            );\n+\n+            /* let new_generics = self.param_env_to_generics(\n+                infcx.tcx,\n+                did,\n+                full_user_env,\n+                generics.clone(),\n+                lifetime_predicates,\n+                vid_to_region,\n+            ); */\n+\n+            debug!(\n+                \"find_auto_trait_generics(did={:?}, trait_did={:?}, generics={:?}): finished with \\\n+                 <generics placeholder here>\",\n+                did, trait_did, generics /* , new_generics */\n+            );\n+            return AutoTraitResult::PositiveImpl;\n+        });\n+    }\n+\n+    // The core logic responsible for computing the bounds for our synthesized impl.\n+    //\n+    // To calculate the bounds, we call SelectionContext.select in a loop. Like FulfillmentContext,\n+    // we recursively select the nested obligations of predicates we encounter. However, whenver we\n+    // encounter an UnimplementedError involving a type parameter, we add it to our ParamEnv. Since\n+    // our goal is to determine when a particular type implements an auto trait, Unimplemented\n+    // errors tell us what conditions need to be met.\n+    //\n+    // This method ends up working somewhat similary to FulfillmentContext, but with a few key\n+    // differences. FulfillmentContext works under the assumption that it's dealing with concrete\n+    // user code. According, it considers all possible ways that a Predicate could be met - which\n+    // isn't always what we want for a synthesized impl. For example, given the predicate 'T:\n+    // Iterator', FulfillmentContext can end up reporting an Unimplemented error for T:\n+    // IntoIterator - since there's an implementation of Iteratpr where T: IntoIterator,\n+    // FulfillmentContext will drive SelectionContext to consider that impl before giving up. If we\n+    // were to rely on FulfillmentContext's decision, we might end up synthesizing an impl like\n+    // this:\n+    // 'impl<T> Send for Foo<T> where T: IntoIterator'\n+    //\n+    // While it might be technically true that Foo implements Send where T: IntoIterator,\n+    // the bound is overly restrictive - it's really only necessary that T: Iterator.\n+    //\n+    // For this reason, evaluate_predicates handles predicates with type variables specially. When\n+    // we encounter an Unimplemented error for a bound such as 'T: Iterator', we immediately add it\n+    // to our ParamEnv, and add it to our stack for recursive evaluation. When we later select it,\n+    // we'll pick up any nested bounds, without ever inferring that 'T: IntoIterator' needs to\n+    // hold.\n+    //\n+    // One additonal consideration is supertrait bounds. Normally, a ParamEnv is only ever\n+    // consutrcted once for a given type. As part of the construction process, the ParamEnv will\n+    // have any supertrait bounds normalized - e.g. if we have a type 'struct Foo<T: Copy>', the\n+    // ParamEnv will contain 'T: Copy' and 'T: Clone', since 'Copy: Clone'. When we construct our\n+    // own ParamEnv, we need to do this outselves, through traits::elaborate_predicates, or else\n+    // SelectionContext will choke on the missing predicates. However, this should never show up in\n+    // the final synthesized generics: we don't want our generated docs page to contain something\n+    // like 'T: Copy + Clone', as that's redundant. Therefore, we keep track of a separate\n+    // 'user_env', which only holds the predicates that will actually be displayed to the user.\n+    fn evaluate_predicates<'b, 'gcx, 'c>(\n+        &self,\n+        infcx: &mut InferCtxt<'b, 'tcx, 'c>,\n+        ty_did: DefId,\n+        trait_did: DefId,\n+        ty: ty::Ty<'c>,\n+        param_env: ty::ParamEnv<'c>,\n+        user_env: ty::ParamEnv<'c>,\n+        fresh_preds: &mut FxHashSet<ty::Predicate<'c>>,\n+        only_projections: bool,\n+    ) -> Option<(ty::ParamEnv<'c>, ty::ParamEnv<'c>)> {\n+        let tcx = infcx.tcx;\n+\n+        let mut select = SelectionContext::new(&infcx);\n+\n+        let mut already_visited = FxHashSet();\n+        let mut predicates = VecDeque::new();\n+        predicates.push_back(ty::Binder(ty::TraitPredicate {\n+            trait_ref: ty::TraitRef {\n+                def_id: trait_did,\n+                substs: infcx.tcx.mk_substs_trait(ty, &[]),\n+            },\n+        }));\n+\n+        let mut computed_preds: FxHashSet<_> = param_env.caller_bounds.iter().cloned().collect();\n+        let mut user_computed_preds: FxHashSet<_> =\n+            user_env.caller_bounds.iter().cloned().collect();\n+\n+        let mut new_env = param_env.clone();\n+        let dummy_cause = ObligationCause::misc(DUMMY_SP, ast::DUMMY_NODE_ID);\n+\n+        while let Some(pred) = predicates.pop_front() {\n+            infcx.clear_caches();\n+\n+            if !already_visited.insert(pred.clone()) {\n+                continue;\n+            }\n+\n+            let result = select.select(&Obligation::new(dummy_cause.clone(), new_env, pred));\n+\n+            match &result {\n+                &Ok(Some(ref vtable)) => {\n+                    let obligations = vtable.clone().nested_obligations().into_iter();\n+\n+                    if !self.evaluate_nested_obligations(\n+                        ty,\n+                        obligations,\n+                        &mut user_computed_preds,\n+                        fresh_preds,\n+                        &mut predicates,\n+                        &mut select,\n+                        only_projections,\n+                    ) {\n+                        return None;\n+                    }\n+                }\n+                &Ok(None) => {}\n+                &Err(SelectionError::Unimplemented) => {\n+                    if self.is_of_param(pred.skip_binder().trait_ref.substs) {\n+                        already_visited.remove(&pred);\n+                        user_computed_preds.insert(ty::Predicate::Trait(pred.clone()));\n+                        predicates.push_back(pred);\n+                    } else {\n+                        debug!(\n+                            \"evaluate_nested_obligations: Unimplemented found, bailing: {:?} {:?} \\\n+                             {:?}\",\n+                            ty,\n+                            pred,\n+                            pred.skip_binder().trait_ref.substs\n+                        );\n+                        return None;\n+                    }\n+                }\n+                _ => panic!(\"Unexpected error for '{:?}': {:?}\", ty, result),\n+            };\n+\n+            computed_preds.extend(user_computed_preds.iter().cloned());\n+            let normalized_preds =\n+                elaborate_predicates(tcx, computed_preds.clone().into_iter().collect());\n+            new_env = ty::ParamEnv::new(\n+                tcx.mk_predicates(normalized_preds),\n+                param_env.reveal,\n+                ty::UniverseIndex::ROOT,\n+            );\n+        }\n+\n+        let final_user_env = ty::ParamEnv::new(\n+            tcx.mk_predicates(user_computed_preds.into_iter()),\n+            user_env.reveal,\n+            ty::UniverseIndex::ROOT,\n+        );\n+        debug!(\n+            \"evaluate_nested_obligations(ty_did={:?}, trait_did={:?}): succeeded with '{:?}' \\\n+             '{:?}'\",\n+            ty_did, trait_did, new_env, final_user_env\n+        );\n+\n+        return Some((new_env, final_user_env));\n+    }\n+\n+    // This method calculates two things: Lifetime constraints of the form 'a: 'b,\n+    // and region constraints of the form ReVar: 'a\n+    //\n+    // This is essentially a simplified version of lexical_region_resolve. However,\n+    // handle_lifetimes determines what *needs be* true in order for an impl to hold.\n+    // lexical_region_resolve, along with much of the rest of the compiler, is concerned\n+    // with determining if a given set up constraints/predicates *are* met, given some\n+    // starting conditions (e.g. user-provided code). For this reason, it's easier\n+    // to perform the calculations we need on our own, rather than trying to make\n+    // existing inference/solver code do what we want.\n+    fn handle_lifetimes<'cx>(\n+        &self,\n+        regions: &RegionConstraintData<'cx>,\n+        names_map: &FxHashMap<String, String>, // TODO(twk): lifetime branding\n+    ) -> Vec<WherePredicate> {\n+        // Our goal is to 'flatten' the list of constraints by eliminating\n+        // all intermediate RegionVids. At the end, all constraints should\n+        // be between Regions (aka region variables). This gives us the information\n+        // we need to create the Generics.\n+        let mut finished = FxHashMap();\n+\n+        let mut vid_map: FxHashMap<RegionTarget, RegionDeps> = FxHashMap();\n+\n+        // Flattening is done in two parts. First, we insert all of the constraints\n+        // into a map. Each RegionTarget (either a RegionVid or a Region) maps\n+        // to its smaller and larger regions. Note that 'larger' regions correspond\n+        // to sub-regions in Rust code (e.g. in 'a: 'b, 'a is the larger region).\n+        for constraint in regions.constraints.keys() {\n+            match constraint {\n+                &Constraint::VarSubVar(r1, r2) => {\n+                    {\n+                        let deps1 = vid_map\n+                            .entry(RegionTarget::RegionVid(r1))\n+                            .or_insert_with(|| Default::default());\n+                        deps1.larger.insert(RegionTarget::RegionVid(r2));\n+                    }\n+\n+                    let deps2 = vid_map\n+                        .entry(RegionTarget::RegionVid(r2))\n+                        .or_insert_with(|| Default::default());\n+                    deps2.smaller.insert(RegionTarget::RegionVid(r1));\n+                }\n+                &Constraint::RegSubVar(region, vid) => {\n+                    let deps = vid_map\n+                        .entry(RegionTarget::RegionVid(vid))\n+                        .or_insert_with(|| Default::default());\n+                    deps.smaller.insert(RegionTarget::Region(region));\n+                }\n+                &Constraint::VarSubReg(vid, region) => {\n+                    let deps = vid_map\n+                        .entry(RegionTarget::RegionVid(vid))\n+                        .or_insert_with(|| Default::default());\n+                    deps.larger.insert(RegionTarget::Region(region));\n+                }\n+                &Constraint::RegSubReg(r1, r2) => {\n+                    // The constraint is already in the form that we want, so we're done with it\n+                    // Desired order is 'larger, smaller', so flip then\n+                    if self.region_name(r1) != self.region_name(r2) {\n+                        finished\n+                            .entry(self.region_name(r2).unwrap())\n+                            .or_insert_with(|| Vec::new())\n+                            .push(r1);\n+                    }\n+                }\n+            }\n+        }\n+\n+        // Here, we 'flatten' the map one element at a time.\n+        // All of the element's sub and super regions are connected\n+        // to each other. For example, if we have a graph that looks like this:\n+        //\n+        // (A, B) - C - (D, E)\n+        // Where (A, B) are subregions, and (D,E) are super-regions\n+        //\n+        // then after deleting 'C', the graph will look like this:\n+        //  ... - A - (D, E ...)\n+        //  ... - B - (D, E, ...)\n+        //  (A, B, ...) - D - ...\n+        //  (A, B, ...) - E - ...\n+        //\n+        //  where '...' signifies the existing sub and super regions of an entry\n+        //  When two adjacent ty::Regions are encountered, we've computed a final\n+        //  constraint, and add it to our list. Since we make sure to never re-add\n+        //  deleted items, this process will always finish.\n+        while !vid_map.is_empty() {\n+            let target = vid_map.keys().next().expect(\"Keys somehow empty\").clone();\n+            let deps = vid_map.remove(&target).expect(\"Entry somehow missing\");\n+\n+            for smaller in deps.smaller.iter() {\n+                for larger in deps.larger.iter() {\n+                    match (smaller, larger) {\n+                        (&RegionTarget::Region(r1), &RegionTarget::Region(r2)) => {\n+                            if self.region_name(r1) != self.region_name(r2) {\n+                                finished\n+                                    .entry(self.region_name(r2).unwrap())\n+                                    .or_insert_with(|| Vec::new())\n+                                    .push(r1) // Larger, smaller\n+                            }\n+                        }\n+                        (&RegionTarget::RegionVid(_), &RegionTarget::Region(_)) => {\n+                            if let Entry::Occupied(v) = vid_map.entry(*smaller) {\n+                                let smaller_deps = v.into_mut();\n+                                smaller_deps.larger.insert(*larger);\n+                                smaller_deps.larger.remove(&target);\n+                            }\n+                        }\n+                        (&RegionTarget::Region(_), &RegionTarget::RegionVid(_)) => {\n+                            if let Entry::Occupied(v) = vid_map.entry(*larger) {\n+                                let deps = v.into_mut();\n+                                deps.smaller.insert(*smaller);\n+                                deps.smaller.remove(&target);\n+                            }\n+                        }\n+                        (&RegionTarget::RegionVid(_), &RegionTarget::RegionVid(_)) => {\n+                            if let Entry::Occupied(v) = vid_map.entry(*smaller) {\n+                                let smaller_deps = v.into_mut();\n+                                smaller_deps.larger.insert(*larger);\n+                                smaller_deps.larger.remove(&target);\n+                            }\n+\n+                            if let Entry::Occupied(v) = vid_map.entry(*larger) {\n+                                let larger_deps = v.into_mut();\n+                                larger_deps.smaller.insert(*smaller);\n+                                larger_deps.smaller.remove(&target);\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        let lifetime_predicates = names_map\n+            .iter()\n+            .flat_map(|(name, _lifetime)| {\n+                let empty = Vec::new();\n+                let bounds: FxHashSet<String> = finished // TODO(twk): lifetime branding\n+                    .get(name)\n+                    .unwrap_or(&empty)\n+                    .iter()\n+                    .map(|region| self.get_lifetime(region, names_map))\n+                    .collect();\n+\n+                if bounds.is_empty() {\n+                    return None;\n+                }\n+                /* Some(WherePredicate::RegionPredicate {\n+                    lifetime: lifetime.clone(),\n+                    bounds: bounds.into_iter().collect(),\n+                }) */\n+                None // TODO(twk): use the correct WherePredicate and rebuild the code above\n+            })\n+            .collect();\n+\n+        lifetime_predicates\n+    }\n+\n+    fn region_name(&self, region: Region) -> Option<String> {\n+        match region {\n+            &ty::ReEarlyBound(r) => Some(r.name.as_str().to_string()),\n+            _ => None,\n+        }\n+    }\n+\n+    // TODO(twk): lifetime branding\n+    fn get_lifetime(&self, region: Region, names_map: &FxHashMap<String, String>) -> String {\n+        self.region_name(region)\n+            .map(|name| {\n+                names_map.get(&name).unwrap_or_else(|| {\n+                    panic!(\"Missing lifetime with name {:?} for {:?}\", name, region)\n+                })\n+            })\n+            // TODO(twk): .unwrap_or(&Lifetime::statik())\n+            .unwrap_or(&\"'static\".to_string())\n+            .clone()\n+    }\n+\n+    // This is very similar to handle_lifetimes. However, instead of matching ty::Region's\n+    // to each other, we match ty::RegionVid's to ty::Region's\n+    fn map_vid_to_region<'cx>(\n+        &self,\n+        regions: &RegionConstraintData<'cx>,\n+    ) -> FxHashMap<ty::RegionVid, ty::Region<'cx>> {\n+        let mut vid_map: FxHashMap<RegionTarget<'cx>, RegionDeps<'cx>> = FxHashMap();\n+        let mut finished_map = FxHashMap();\n+\n+        for constraint in regions.constraints.keys() {\n+            match constraint {\n+                &Constraint::VarSubVar(r1, r2) => {\n+                    {\n+                        let deps1 = vid_map\n+                            .entry(RegionTarget::RegionVid(r1))\n+                            .or_insert_with(|| Default::default());\n+                        deps1.larger.insert(RegionTarget::RegionVid(r2));\n+                    }\n+\n+                    let deps2 = vid_map\n+                        .entry(RegionTarget::RegionVid(r2))\n+                        .or_insert_with(|| Default::default());\n+                    deps2.smaller.insert(RegionTarget::RegionVid(r1));\n+                }\n+                &Constraint::RegSubVar(region, vid) => {\n+                    {\n+                        let deps1 = vid_map\n+                            .entry(RegionTarget::Region(region))\n+                            .or_insert_with(|| Default::default());\n+                        deps1.larger.insert(RegionTarget::RegionVid(vid));\n+                    }\n+\n+                    let deps2 = vid_map\n+                        .entry(RegionTarget::RegionVid(vid))\n+                        .or_insert_with(|| Default::default());\n+                    deps2.smaller.insert(RegionTarget::Region(region));\n+                }\n+                &Constraint::VarSubReg(vid, region) => {\n+                    finished_map.insert(vid, region);\n+                }\n+                &Constraint::RegSubReg(r1, r2) => {\n+                    {\n+                        let deps1 = vid_map\n+                            .entry(RegionTarget::Region(r1))\n+                            .or_insert_with(|| Default::default());\n+                        deps1.larger.insert(RegionTarget::Region(r2));\n+                    }\n+\n+                    let deps2 = vid_map\n+                        .entry(RegionTarget::Region(r2))\n+                        .or_insert_with(|| Default::default());\n+                    deps2.smaller.insert(RegionTarget::Region(r1));\n+                }\n+            }\n+        }\n+\n+        while !vid_map.is_empty() {\n+            let target = vid_map.keys().next().expect(\"Keys somehow empty\").clone();\n+            let deps = vid_map.remove(&target).expect(\"Entry somehow missing\");\n+\n+            for smaller in deps.smaller.iter() {\n+                for larger in deps.larger.iter() {\n+                    match (smaller, larger) {\n+                        (&RegionTarget::Region(_), &RegionTarget::Region(_)) => {\n+                            if let Entry::Occupied(v) = vid_map.entry(*smaller) {\n+                                let smaller_deps = v.into_mut();\n+                                smaller_deps.larger.insert(*larger);\n+                                smaller_deps.larger.remove(&target);\n+                            }\n+\n+                            if let Entry::Occupied(v) = vid_map.entry(*larger) {\n+                                let larger_deps = v.into_mut();\n+                                larger_deps.smaller.insert(*smaller);\n+                                larger_deps.smaller.remove(&target);\n+                            }\n+                        }\n+                        (&RegionTarget::RegionVid(v1), &RegionTarget::Region(r1)) => {\n+                            finished_map.insert(v1, r1);\n+                        }\n+                        (&RegionTarget::Region(_), &RegionTarget::RegionVid(_)) => {\n+                            // Do nothing - we don't care about regions that are smaller than vids\n+                        }\n+                        (&RegionTarget::RegionVid(_), &RegionTarget::RegionVid(_)) => {\n+                            if let Entry::Occupied(v) = vid_map.entry(*smaller) {\n+                                let smaller_deps = v.into_mut();\n+                                smaller_deps.larger.insert(*larger);\n+                                smaller_deps.larger.remove(&target);\n+                            }\n+\n+                            if let Entry::Occupied(v) = vid_map.entry(*larger) {\n+                                let larger_deps = v.into_mut();\n+                                larger_deps.smaller.insert(*smaller);\n+                                larger_deps.smaller.remove(&target);\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        finished_map\n+    }\n+\n+    fn is_of_param(&self, substs: &Substs) -> bool {\n+        if substs.is_noop() {\n+            return false;\n+        }\n+\n+        return match substs.type_at(0).sty {\n+            ty::TyParam(_) => true,\n+            ty::TyProjection(p) => self.is_of_param(p.substs),\n+            _ => false,\n+        };\n+    }\n+\n+    fn evaluate_nested_obligations<'b, 'c, 'd, 'cx,\n+                                    T: Iterator<Item = Obligation<'cx, ty::Predicate<'cx>>>>(\n+        &self,\n+        ty: ty::Ty,\n+        nested: T,\n+        computed_preds: &'b mut FxHashSet<ty::Predicate<'cx>>,\n+        fresh_preds: &'b mut FxHashSet<ty::Predicate<'cx>>,\n+        predicates: &'b mut VecDeque<ty::PolyTraitPredicate<'cx>>,\n+        select: &mut SelectionContext<'c, 'd, 'cx>,\n+        only_projections: bool,\n+    ) -> bool {\n+        let dummy_cause = ObligationCause::misc(DUMMY_SP, ast::DUMMY_NODE_ID);\n+\n+        for (obligation, predicate) in nested\n+            .filter(|o| o.recursion_depth == 1)\n+            .map(|o| (o.clone(), o.predicate.clone()))\n+        {\n+            let is_new_pred =\n+                fresh_preds.insert(self.clean_pred(select.infcx(), predicate.clone()));\n+\n+            match &predicate {\n+                &ty::Predicate::Trait(ref p) => {\n+                    let substs = &p.skip_binder().trait_ref.substs;\n+\n+                    if self.is_of_param(substs) && !only_projections && is_new_pred {\n+                        computed_preds.insert(predicate);\n+                    }\n+                    predicates.push_back(p.clone());\n+                }\n+                &ty::Predicate::Projection(p) => {\n+                    // If the projection isn't all type vars, then\n+                    // we don't want to add it as a bound\n+                    if self.is_of_param(p.skip_binder().projection_ty.substs) && is_new_pred {\n+                        computed_preds.insert(predicate);\n+                    } else {\n+                        match poly_project_and_unify_type(\n+                            select,\n+                            &obligation.with(p.clone()),\n+                        ) {\n+                            Err(e) => {\n+                                debug!(\n+                                    \"evaluate_nested_obligations: Unable to unify predicate \\\n+                                     '{:?}' '{:?}', bailing out\",\n+                                    ty, e\n+                                );\n+                                return false;\n+                            }\n+                            Ok(Some(v)) => {\n+                                if !self.evaluate_nested_obligations(\n+                                    ty,\n+                                    v.clone().iter().cloned(),\n+                                    computed_preds,\n+                                    fresh_preds,\n+                                    predicates,\n+                                    select,\n+                                    only_projections,\n+                                ) {\n+                                    return false;\n+                                }\n+                            }\n+                            Ok(None) => {\n+                                panic!(\"Unexpected result when selecting {:?} {:?}\", ty, obligation)\n+                            }\n+                        }\n+                    }\n+                }\n+                &ty::Predicate::RegionOutlives(ref binder) => {\n+                    if let Err(_) = select\n+                        .infcx()\n+                        .region_outlives_predicate(&dummy_cause, binder)\n+                    {\n+                        return false;\n+                    }\n+                }\n+                &ty::Predicate::TypeOutlives(ref binder) => {\n+                    match (\n+                        binder.no_late_bound_regions(),\n+                        binder.map_bound_ref(|pred| pred.0).no_late_bound_regions(),\n+                    ) {\n+                        (None, Some(t_a)) => {\n+                            select.infcx().register_region_obligation(\n+                                ast::DUMMY_NODE_ID,\n+                                RegionObligation {\n+                                    sup_type: t_a,\n+                                    sub_region: select.infcx().tcx.types.re_static,\n+                                    cause: dummy_cause.clone(),\n+                                },\n+                            );\n+                        }\n+                        (Some(ty::OutlivesPredicate(t_a, r_b)), _) => {\n+                            select.infcx().register_region_obligation(\n+                                ast::DUMMY_NODE_ID,\n+                                RegionObligation {\n+                                    sup_type: t_a,\n+                                    sub_region: r_b,\n+                                    cause: dummy_cause.clone(),\n+                                },\n+                            );\n+                        }\n+                        _ => {}\n+                    };\n+                }\n+                _ => panic!(\"Unexpected predicate {:?} {:?}\", ty, predicate),\n+            };\n+        }\n+        return true;\n+    }\n+\n+    fn clean_pred<'c, 'd, 'cx>(\n+        &self,\n+        infcx: &InferCtxt<'c, 'd, 'cx>,\n+        p: ty::Predicate<'cx>,\n+    ) -> ty::Predicate<'cx> {\n+        infcx.freshen(p)\n+    }\n+}\n+\n+// Replaces all ReVars in a type with ty::Region's, using the provided map\n+struct RegionReplacer<'a, 'gcx: 'a + 'tcx, 'tcx: 'a> {\n+    vid_to_region: &'a FxHashMap<ty::RegionVid, ty::Region<'tcx>>,\n+    tcx: TyCtxt<'a, 'gcx, 'tcx>,\n+}\n+\n+impl<'a, 'gcx, 'tcx> TypeFolder<'gcx, 'tcx> for RegionReplacer<'a, 'gcx, 'tcx> {\n+    fn tcx<'b>(&'b self) -> TyCtxt<'b, 'gcx, 'tcx> {\n+        self.tcx\n+    }\n+\n+    fn fold_region(&mut self, r: ty::Region<'tcx>) -> ty::Region<'tcx> {\n+        (match r {\n+            &ty::ReVar(vid) => self.vid_to_region.get(&vid).cloned(),\n+            _ => None,\n+        }).unwrap_or_else(|| r.super_fold_with(self))\n+    }\n+}"}, {"sha": "b6b0b91fc535c78e505b0ad0e78e8348eee95fa9", "filename": "src/librustc/traits/mod.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7365bee5066aae03e52a67c3fac6a8129140d90f/src%2Flibrustc%2Ftraits%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7365bee5066aae03e52a67c3fac6a8129140d90f/src%2Flibrustc%2Ftraits%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ftraits%2Fmod.rs?ref=7365bee5066aae03e52a67c3fac6a8129140d90f", "patch": "@@ -52,6 +52,8 @@ pub use self::util::supertrait_def_ids;\n pub use self::util::SupertraitDefIds;\n pub use self::util::transitive_bounds;\n \n+#[allow(dead_code)]\n+pub mod auto_trait;\n mod coherence;\n pub mod error_reporting;\n mod engine;"}]}