{"sha": "2812015d40c94ddb94bb57ed1a9811ff24414c44", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI4MTIwMTVkNDBjOTRkZGI5NGJiNTdlZDFhOTgxMWZmMjQ0MTRjNDQ=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2018-08-24T15:14:21Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2018-08-24T15:14:21Z"}, "message": "README", "tree": {"sha": "d134a3af875036f3921c5b620685510f6dbe0bf6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d134a3af875036f3921c5b620685510f6dbe0bf6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2812015d40c94ddb94bb57ed1a9811ff24414c44", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2812015d40c94ddb94bb57ed1a9811ff24414c44", "html_url": "https://github.com/rust-lang/rust/commit/2812015d40c94ddb94bb57ed1a9811ff24414c44", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2812015d40c94ddb94bb57ed1a9811ff24414c44/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6cade3f6d8ad7bb5a11b1910689b25f709c12502", "url": "https://api.github.com/repos/rust-lang/rust/commits/6cade3f6d8ad7bb5a11b1910689b25f709c12502", "html_url": "https://github.com/rust-lang/rust/commit/6cade3f6d8ad7bb5a11b1910689b25f709c12502"}], "stats": {"total": 774, "additions": 102, "deletions": 672}, "files": [{"sha": "6fcd7eb078d024f5501bb3501ee98e974d564ee1", "filename": "README.md", "status": "modified", "additions": 102, "deletions": 5, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/2812015d40c94ddb94bb57ed1a9811ff24414c44/README.md", "raw_url": "https://github.com/rust-lang/rust/raw/2812015d40c94ddb94bb57ed1a9811ff24414c44/README.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/README.md?ref=2812015d40c94ddb94bb57ed1a9811ff24414c44", "patch": "@@ -5,13 +5,110 @@\n [![Build status](https://ci.appveyor.com/api/projects/status/j56x1hbje8rdg6xk/branch/master?svg=true)](https://ci.appveyor.com/project/matklad/libsyntax2/branch/master)\n \n \n+libsyntax2.0 is an **experimental** parser of the Rust language,\n+intended for the use in IDEs.\n+[RFC](https://github.com/rust-lang/rfcs/pull/2256).\n \n-libsyntax2.0 is an **experimental** implementation of the corresponding [RFC](https://github.com/rust-lang/rfcs/pull/2256).\n \n-See [`docs`](./docs) folder to learn how libsyntax2 works, and check\n-[`CONTRIBUTING.md`](./CONTRIBUTING.md) if you want to contribute!\n-**WARNING** everything is in a bit of a flux recently, the docs are obsolete,\n-see the recent work on red/green trees.\n+## Quick Start\n+\n+```\n+$ cargo test\n+$ cargo parse < crates/libsyntax2/src/lib.rs\n+```\n+\n+\n+## Trying It Out\n+\n+This installs experimental VS Code plugin\n+\n+```\n+$ cargo install-code\n+```\n+\n+It's better to remove existing Rust plugins to avoid interference.\n+Warning: plugin is not intended for general use, has a lot of rough\n+edges and missing features (notably, no code completion). That said,\n+while originally libsyntax2 was developed in IntelliJ, @matklad now\n+uses this plugin (and thus, libsytax2) to develop libsyntax2, and it\n+doesn't hurt too much :-)\n+\n+\n+### Features:\n+\n+* syntax highlighting (LSP does not have API for it, so impl is hacky\n+  and sometimes fall-backs to the horrible built-in highlighting)\n+  \n+* commands (`ctrl+shift+p` or keybindings)\n+  - **Show Rust Syntax Tree** (use it to verify that plugin works)\n+  - **Rust Extend Selection** (works with multiple cursors)\n+  - **Rust Matching Brace** (knows the difference between `<` and `<`)\n+  - **Rust Parent Module**\n+  - **Rust Join Lines** (deals with trailing commas)\n+  \n+* **Go to symbol in file**\n+\n+* **Go to symbol in workspace** (no support for Cargo deps yet)\n+\n+* code actions:\n+  - Flip `,` in comma separated lists\n+  - Add `#[derive]` to struct/enum\n+  - Add `impl` block to struct/enum\n+  - Run tests at caret\n+  \n+* **Go to definition** (\"correct\" for `mod foo;` decls, index-based for functions).\n+\n+\n+## Code Walk-Through\n+\n+### `crates/libsyntax2`\n+\n+- `yellow`, red/green syntax tree, heavily inspired [by this](https://github.com/apple/swift/tree/ab68f0d4cbf99cdfa672f8ffe18e433fddc8b371/lib/Syntax)\n+- `grammar`, the actual parser\n+- `parser_api/parser_impl` bridges the tree-agnostic parser from `grammar` with `yellow` trees\n+- `grammar.ron` RON description of the grammar, which is used to\n+  generate `syntax_kinds` and `ast` modules.\n+- `algo`: generic tree algorithms, including `walk` for O(1) stack\n+  space tree traversal (this is cool) and `visit` for type-driven\n+  visiting the nodes (this is double plus cool, if you understand how\n+  `Visitor` works, you understand libsyntax2).\n+  \n+\n+### `crates/libeditor`\n+\n+Most of IDE features leave here, unlike `libanalysis`, `libeditor` is\n+single-file and is basically a bunch of pure functions.\n+\n+\n+### `crates/libanalysis`\n+\n+A stateful library for analyzing many Rust files as they change.\n+`WorldState` is a mutable entity (clojure's atom) which holds current\n+state, incorporates changes and handles out `World`s --- immutable\n+consistent snapshots of `WorldState`, which actually power analysis. \n+\n+\n+### `crates/server`\n+\n+An LSP implementation which uses `libanalysis` for managing state and\n+`libeditor` for actually doing useful stuff.\n+\n+\n+### `crates/cli`\n+\n+A CLI interface to libsyntax\n+\n+### `crate/tools`\n+\n+Code-gen tasks, used to develop libsyntax2:\n+\n+- `cargo gen-kinds` -- generate `ast` and `syntax_kinds`\n+- `cargo gen-tests` -- collect inline tests from grammar\n+- `cargo install-code` -- build and install VS Code extension and server\n+\n+### `code`\n+\n+VS Code plugin\n \n \n ## License"}, {"sha": "6b4434396aaa4a976b30e0f14d1708ca2233e589", "filename": "docs/ARCHITECTURE.md", "status": "removed", "additions": 0, "deletions": 93, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FARCHITECTURE.md", "raw_url": "https://github.com/rust-lang/rust/raw/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FARCHITECTURE.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2FARCHITECTURE.md?ref=6cade3f6d8ad7bb5a11b1910689b25f709c12502", "patch": "@@ -1,93 +0,0 @@\n-# Design and open questions about libsyntax\n-\n-\n-The high-level description of the architecture is in RFC.md. You might\n-also want to dig through https://github.com/matklad/fall/ which\n-contains some pretty interesting stuff build using similar ideas\n-(warning: it is completely undocumented, poorly written and in general\n-not the thing which I recommend to study (yes, this is\n-self-contradictory)).\n-\n-## Tree\n-\n-The centerpiece of this whole endeavor is the syntax tree, in the\n-`tree` module. Open questions:\n-\n-- how to best represent errors, to take advantage of the fact that\n-  they are rare, but to enable fully-persistent style structure\n-  sharing between tree nodes?\n-  \n-- should we make red/green split from Roslyn more pronounced?\n-\n-- one can layout nodes in a single array in such a way that children\n-  of the node form a continuous slice. Seems nifty, but do we need it?\n-  \n-- should we use SoA or AoS for NodeData?\n-\n-- should we split leaf nodes and internal nodes into separate arrays?\n-  Can we use it to save some bits here and there? (leaves don't need\n-  first_child field, for example).\n-\n-\n-## Parser\n-\n-The syntax tree is produced using a three-staged process. \n-\n-First, a raw text is split into tokens with a lexer (the `lexer` module).\n-Lexer has a peculiar signature: it is an `Fn(&str) -> Token`, where token \n-is a pair of `SyntaxKind` (you should have read the `tree` module and RFC\n-by this time! :)) and a len. That is, lexer chomps only the first\n-token of the input. This forces the lexer to be stateless, and makes\n-it possible to implement incremental relexing easily.\n-\n-Then, the bulk of work, the parser turns a stream of tokens into\n-stream of events (the `parser` module; of particular interest are \n-the `parser/event` and `parser/parser` modules, which contain parsing \n-API, and the `parser/grammar` module, which contains actual parsing code\n-for various Rust syntactic constructs). Not that parser **does not** \n-construct a tree right away. This is done for several reasons:\n-\n-* to decouple the actual tree data structure from the parser: you can\n-  build any data structure you want from the stream of events\n-  \n-* to make parsing fast: you can produce a list of events without\n-  allocations\n-  \n-* to make it easy to tweak tree structure. Consider this code:\n-\n-  ```\n-  #[cfg(test)]\n-  pub fn foo() {}\n-  ```\n-  \n-  Here, the attribute and the `pub` keyword must be the children of\n-  the `fn` node. However, when parsing them, we don't yet know if\n-  there would be a function ahead: it very well might be a `struct`\n-  there. If we use events, we generally don't care about this *in\n-  parser* and just spit them in order.\n-  \n-* (Is this true?)  to make incremental reparsing easier: you can reuse\n-  the same rope data structure for all of the original string, the\n-  tokens and the events.\n-  \n-\n-The parser also does not know about whitespace tokens: it's the job of\n-the next layer to assign whitespace and comments to nodes. However,\n-parser can remap contextual tokens, like `>>` or `union`, so it has\n-access to the text.\n-\n-And at last, the TreeBuilder converts a flat stream of events into a\n-tree structure. It also *should* be responsible for attaching comments\n-and rebalancing the tree, but it does not do this yet :) \n-\n-## Validator\n-\n-Parser and lexer accept a lot of *invalid* code intentionally. The\n-idea is to post-process the tree and to proper error reporting,\n-literal conversion and quick-fix suggestions. There is no\n-design/implementation for this yet.\n-\n-\n-## AST\n-\n-Nothing yet, see `AstNode` in `fall`."}, {"sha": "2bd9f18f1d84a732258bffd71ab58533836720e4", "filename": "docs/RFC.md", "status": "removed", "additions": 0, "deletions": 494, "changes": 494, "blob_url": "https://github.com/rust-lang/rust/blob/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FRFC.md", "raw_url": "https://github.com/rust-lang/rust/raw/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FRFC.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2FRFC.md?ref=6cade3f6d8ad7bb5a11b1910689b25f709c12502", "patch": "@@ -1,494 +0,0 @@\n-- Feature Name: libsyntax2.0\n-- Start Date: 2017-12-30\n-- RFC PR: (leave this empty)\n-- Rust Issue: (leave this empty)\n-\n-\n->I think the lack of reusability comes in object-oriented languages,\n->not functional languages. Because the problem with object-oriented\n->languages is they\u2019ve got all this implicit environment that they\n->carry around with them. You wanted a banana but what you got was a\n->gorilla holding the banana and the entire jungle.\n->\n->If you have referentially transparent code, if you have pure\n->functions \u2014 all the data comes in its input arguments and everything\n->goes out and leave no state behind \u2014 it\u2019s incredibly reusable.\n->\n-> **Joe Armstrong**\n-\n-# Summary\n-[summary]: #summary\n-\n-The long-term plan is to rewrite libsyntax parser and syntax tree data\n-structure to create a software component independent of the rest of\n-rustc compiler and suitable for the needs of IDEs and code\n-editors. This RFCs is the first step of this plan, whose goal is to\n-find out if this is possible at least in theory. If it is possible,\n-the next steps would be a prototype implementation as a crates.io\n-crate and a separate RFC for integrating the prototype with rustc,\n-other tools, and eventual libsyntax removal.\n-\n-Note that this RFC does not propose to stabilize any API for working\n-with rust syntax: the semver version of the hypothetical library would\n-be `0.1.0`. It is intended to be used by tools, which are currently\n-closely related to the compiler: `rustc`, `rustfmt`, `clippy`, `rls`\n-and hypothetical `rustfix`. While it would be possible to create\n-third-party tools on top of the new libsyntax, the burden of adopting\n-to breaking changes would be on authors of such tools.\n-\n-\n-# Motivation\n-[motivation]: #motivation\n-\n-There are two main drawbacks with the current version of libsyntax:\n-\n-* It is tightly integrated with the compiler and hard to use\n-  independently\n-\n-* The AST representation is not well-suited for use inside IDEs\n-\n-\n-## IDE support\n-\n-There are several differences in how IDEs and compilers typically\n-treat source code.\n-\n-In the compiler, it is convenient to transform the source\n-code into Abstract Syntax Tree form, which is independent of the\n-surface syntax. For example, it's convenient to discard comments,\n-whitespaces and desugar some syntactic constructs in terms of the\n-simpler ones.\n-\n-In contrast, IDEs work much closer to the source code, so it is\n-crucial to preserve full information about the original text. For\n-example, IDE may adjust indentation after typing a `}` which closes a\n-block, and to do this correctly, IDE must be aware of syntax (that is,\n-that `}` indeed closes some block, and is not a syntax error) and of\n-all whitespaces and comments. So, IDE suitable AST should explicitly\n-account for syntactic elements, not considered important by the\n-compiler.\n-\n-Another difference is that IDEs typically work with incomplete and\n-syntactically invalid code. This boils down to two parser properties.\n-First, the parser must produce syntax tree even if some required input\n-is missing. For example, for input `fn foo` the function node should\n-be present in the parse, despite the fact that there is no parameters\n-or body. Second, the parser must be able to skip over parts of input\n-it can't recognize and aggressively recover from errors. That is, the\n-syntax tree data structure should be able to handle both missing and\n-extra nodes.\n-\n-IDEs also need the ability to incrementally reparse and relex source\n-code after the user types. A smart IDE would use syntax tree structure\n-to handle editing commands (for example, to add/remove trailing commas\n-after join/split lines actions), so parsing time can be very\n-noticeable.\n-\n-\n-Currently rustc uses the classical AST approach, and preserves some of\n-the source code information in the form of spans in the AST. It is not\n-clear if this structure can full fill all IDE requirements.\n-\n-\n-## Reusability\n-\n-In theory, the parser can be a pure function, which takes a `&str` as\n-an input, and produces a `ParseTree` as an output.\n-\n-This is great for reusability: for example, you can compile this\n-function to WASM and use it for fast client-side validation of syntax\n-on the rust playground, or you can develop tools like `rustfmt` on\n-stable Rust outside of rustc repository, or you can embed the parser\n-into your favorite IDE or code editor.\n-\n-This is also great for correctness: with such simple interface, it's\n-possible to write property-based tests to thoroughly compare two\n-different implementations of the parser. It's also straightforward to\n-create a comprehensive test suite, because all the inputs and outputs\n-are trivially serializable to human-readable text.\n-\n-Another benefit is performance: with this signature, you can cache a\n-parse tree for each file, with trivial strategy for cache invalidation\n-(invalidate an entry when the underling file changes). On top of such\n-a cache it is possible to build a smart code indexer which maintains\n-the set of symbols in the project, watches files for changes and\n-automatically reindexes only changed files.\n-\n-Unfortunately, the current libsyntax is far from this ideal. For\n-example, even the lexer makes use of the `FileMap` which is\n-essentially a global state of the compiler which represents all know\n-files. As a data point, it turned out to be easier to move `rustfmt`\n-into the main `rustc` repository than to move libsyntax outside!\n-\n-\n-# Guide-level explanation\n-[guide-level-explanation]: #guide-level-explanation\n-\n-Not applicable.\n-\n-\n-# Reference-level explanation\n-[reference-level-explanation]: #reference-level-explanation\n-\n-It is not clear if a single parser can accommodate the needs of the\n-compiler and the IDE, but there is hope that it is possible. The RFC\n-proposes to develop libsynax2.0 as an experimental crates.io crate. If\n-the experiment turns out to be a success, the second RFC will propose\n-to integrate it with all existing tools and `rustc`.\n-\n-Next, a syntax tree data structure is proposed for libsyntax2.0. It\n-seems to have the following important properties:\n-\n-* It is lossless and faithfully represents the original source code,\n-  including explicit nodes for comments and whitespace.\n-\n-* It is flexible and allows to encode arbitrary node structure,\n-  even for invalid syntax.\n-\n-* It is minimal: it stores small amount of data and has no\n-  dependencies. For instance, it does not need compiler's string\n-  interner or literal data representation.\n-\n-* While the tree itself is minimal, it is extensible in a sense that\n-  it possible to associate arbitrary data with certain nodes in a\n-  type-safe way.\n-\n-\n-It is not clear if this representation is the best one. It is heavily\n-inspired by [PSI] data structure which used in [IntelliJ] based IDEs\n-and in the [Kotlin] compiler.\n-\n-[PSI]: http://www.jetbrains.org/intellij/sdk/docs/reference_guide/custom_language_support/implementing_parser_and_psi.html\n-[IntelliJ]: https://github.com/JetBrains/intellij-community/\n-[Kotlin]: https://kotlinlang.org/\n-\n-\n-## Untyped Tree\n-\n-The main idea is to store the minimal amount of information in the\n-tree itself, and instead lean heavily on the source code for the\n-actual data about identifier names, constant values etc.\n-\n-All nodes in the tree are of the same type and store a constant for\n-the syntactic category of the element and a range in the source code.\n-\n-Here is a minimal implementation of this data structure with some Rust\n-syntactic categories\n-\n-\n-```rust\n-#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\n-pub struct NodeKind(u16);\n-\n-pub struct File {\n-\ttext: String,\n-\tnodes: Vec<NodeData>,\n-}\n-\n-struct NodeData {\n-\tkind: NodeKind,\n-\trange: (u32, u32),\n-\tparent: Option<u32>,\n-\tfirst_child: Option<u32>,\n-\tnext_sibling: Option<u32>,\n-}\n-\n-#[derive(Clone, Copy)]\n-pub struct Node<'f> {\n-\tfile: &'f File,\n-\tidx: u32,\n-}\n-\n-pub struct Children<'f> {\n-\tnext: Option<Node<'f>>,\n-}\n-\n-impl File {\n-\tpub fn root<'f>(&'f self) -> Node<'f> {\n-\t\tassert!(!self.nodes.is_empty());\n-\t\tNode { file: self, idx: 0 }\n-\t}\n-}\n-\n-impl<'f> Node<'f> {\n-\tpub fn kind(&self) -> NodeKind {\n-\t\tself.data().kind\n-\t}\n-\n-\tpub fn text(&self) -> &'f str {\n-\t\tlet (start, end) = self.data().range;\n-\t\t&self.file.text[start as usize..end as usize]\n-\t}\n-\n-\tpub fn parent(&self) -> Option<Node<'f>> {\n-\t\tself.as_node(self.data().parent)\n-\t}\n-\n-\tpub fn children(&self) -> Children<'f> {\n-\t\tChildren { next: self.as_node(self.data().first_child) }\n-\t}\n-\n-\tfn data(&self) -> &'f NodeData {\n-\t\t&self.file.nodes[self.idx as usize]\n-\t}\n-\n-\tfn as_node(&self, idx: Option<u32>) -> Option<Node<'f>> {\n-\t\tidx.map(|idx| Node { file: self.file, idx })\n-\t}\n-}\n-\n-impl<'f> Iterator for Children<'f> {\n-\ttype Item = Node<'f>;\n-\n-\tfn next(&mut self) -> Option<Node<'f>> {\n-\t\tlet next = self.next;\n-\t\tself.next = next.and_then(|node| node.as_node(node.data().next_sibling));\n-\t\tnext\n-\t}\n-}\n-\n-pub const ERROR: NodeKind = NodeKind(0);\n-pub const WHITESPACE: NodeKind = NodeKind(1);\n-pub const STRUCT_KW: NodeKind = NodeKind(2);\n-pub const IDENT: NodeKind = NodeKind(3);\n-pub const L_CURLY: NodeKind = NodeKind(4);\n-pub const R_CURLY: NodeKind = NodeKind(5);\n-pub const COLON: NodeKind = NodeKind(6);\n-pub const COMMA: NodeKind = NodeKind(7);\n-pub const AMP: NodeKind = NodeKind(8);\n-pub const LINE_COMMENT: NodeKind = NodeKind(9);\n-pub const FILE: NodeKind = NodeKind(10);\n-pub const STRUCT_DEF: NodeKind = NodeKind(11);\n-pub const FIELD_DEF: NodeKind = NodeKind(12);\n-pub const TYPE_REF: NodeKind = NodeKind(13);\n-```\n-\n-Here is a rust snippet and the corresponding parse tree:\n-\n-```rust\n-struct Foo {\n-\tfield1: u32,\n-\t&\n-\t// non-doc comment\n-\tfield2:\n-}\n-```\n-\n-\n-```\n-FILE\n-  STRUCT_DEF\n-    STRUCT_KW\n-    WHITESPACE\n-    IDENT\n-    WHITESPACE\n-    L_CURLY\n-    WHITESPACE\n-    FIELD_DEF\n-      IDENT\n-      COLON\n-      WHITESPACE\n-      TYPE_REF\n-        IDENT\n-    COMMA\n-    WHITESPACE\n-    ERROR\n-      AMP\n-    WHITESPACE\n-    FIELD_DEF\n-      LINE_COMMENT\n-      WHITESPACE\n-      IDENT\n-      COLON\n-      ERROR\n-    WHITESPACE\n-    R_CURLY\n-```\n-\n-Note several features of the tree:\n-\n-* All whitespace and comments are explicitly accounted for.\n-\n-* The node for `STRUCT_DEF` contains the error element for `&`, but\n-  still represents the following field correctly.\n-\n-* The second field of the struct is incomplete: `FIELD_DEF` node for\n-  it contains an `ERROR` element, but nevertheless has the correct\n-  `NodeKind`.\n-\n-* The non-documenting comment is correctly attached to the following\n-  field.\n-\n-\n-## Typed Tree\n-\n-It's hard to work with this raw parse tree, because it is untyped:\n-node containing a struct definition has the same API as the node for\n-the struct field. But it's possible to add a strongly typed layer on\n-top of this raw tree, and get a zero-cost AST. Here is an example\n-which adds type-safe wrappers for structs and fields:\n-\n-```rust\n-// generic infrastructure\n-\n-pub trait AstNode<'f>: Copy + 'f {\n-\tfn new(node: Node<'f>) -> Option<Self>;\n-\tfn node(&self) -> Node<'f>;\n-}\n-\n-pub fn child_of_kind<'f>(node: Node<'f>, kind: NodeKind) -> Option<Node<'f>> {\n-\tnode.children().find(|child| child.kind() == kind)\n-}\n-\n-pub fn ast_children<'f, A: AstNode<'f>>(node: Node<'f>) -> Box<Iterator<Item=A> + 'f> {\n-\tBox::new(node.children().filter_map(A::new))\n-}\n-\n-// AST elements, specific to Rust\n-\n-#[derive(Clone, Copy)]\n-pub struct StructDef<'f>(Node<'f>);\n-\n-#[derive(Clone, Copy)]\n-pub struct FieldDef<'f>(Node<'f>);\n-\n-#[derive(Clone, Copy)]\n-pub struct TypeRef<'f>(Node<'f>);\n-\n-pub trait NameOwner<'f>: AstNode<'f> {\n-\tfn name_ident(&self) -> Node<'f> {\n-\t\tchild_of_kind(self.node(), IDENT).unwrap()\n-\t}\n-\n-\tfn name(&self) -> &'f str { self.name_ident().text() }\n-}\n-\n-\n-impl<'f> AstNode<'f> for StructDef<'f> {\n-\tfn new(node: Node<'f>) -> Option<Self> {\n-\t\tif node.kind() == STRUCT_DEF { Some(StructDef(node)) } else { None }\n-\t}\n-\tfn node(&self) -> Node<'f> { self.0 }\n-}\n-\n-impl<'f> NameOwner<'f> for StructDef<'f> {}\n-\n-impl<'f> StructDef<'f> {\n-\tpub fn fields(&self) -> Box<Iterator<Item=FieldDef<'f>> + 'f> {\n-\t\tast_children(self.node())\n-\t}\n-}\n-\n-\n-impl<'f> AstNode<'f> for FieldDef<'f> {\n-\tfn new(node: Node<'f>) -> Option<Self> {\n-\t\tif node.kind() == FIELD_DEF { Some(FieldDef(node)) } else { None }\n-\t}\n-\tfn node(&self) -> Node<'f> { self.0 }\n-}\n-\n-impl<'f> FieldDef<'f> {\n-\tpub fn type_ref(&self) -> Option<TypeRef<'f>> {\n-\t\tast_children(self.node()).next()\n-\t}\n-}\n-\n-impl<'f> NameOwner<'f> for FieldDef<'f> {}\n-\n-\n-impl<'f> AstNode<'f> for TypeRef<'f> {\n-\tfn new(node: Node<'f>) -> Option<Self> {\n-\t\tif node.kind() == TYPE_REF { Some(TypeRef(node)) } else { None }\n-\t}\n-\tfn node(&self) -> Node<'f> { self.0 }\n-}\n-```\n-\n-Note that although AST wrappers provide a type-safe access to the\n-tree, they are still represented as indexes, so clients of the syntax\n-tree can easily associated additional data with AST nodes by storing\n-it in a side-table.\n-\n-\n-## Missing Source Code\n-\n-The crucial feature of this syntax tree is that it is just a view into\n-the original source code. And this poses a problem for the Rust\n-language, because not all compiled Rust code is represented in the\n-form of source code! Specifically, Rust has a powerful macro system,\n-which effectively allows to create and parse additional source code at\n-compile time. It is not entirely clear that the proposed parsing\n-framework is able to handle this use case, and it's the main purpose\n-of this RFC to figure it out. The current idea for handling macros is\n-to make each macro expansion produce a triple of (expansion text,\n-syntax tree, hygiene information), where hygiene information is a side\n-table, which colors different ranges of the expansion text according\n-to the original syntactic context.\n-\n-\n-## Implementation plan\n-\n-This RFC proposes huge changes to the internals of the compiler, so\n-it's important to proceed carefully and incrementally. The following\n-plan is suggested:\n-\n-* RFC discussion about the theoretical feasibility of the proposal,\n-  and the best representation representation for the syntax tree.\n-\n-* Implementation of the proposal as a completely separate crates.io\n-  crate, by refactoring existing libsyntax source code to produce a\n-  new tree.\n-\n-* A prototype implementation of the macro expansion on top of the new\n-  sytnax tree.\n-\n-* Additional round of discussion/RFC about merging with the mainline\n-  compiler.\n-\n-\n-# Drawbacks\n-[drawbacks]: #drawbacks\n-\n-- No harm will be done as long as the new libsyntax exists as an\n-  experiemt on crates.io. However, actually using it in the compiler\n-  and other tools would require massive refactorings.\n-\n-- It's difficult to know upfront if the proposed syntax tree would\n-  actually work well in both the compiler and IDE. It may be possible\n-  that some drawbacks will be discovered during implementation.\n-\n-\n-# Rationale and alternatives\n-[alternatives]: #alternatives\n-\n-- Incrementally add more information about source code to the current\n-  AST.\n-\n-- Move the current libsyntax to crates.io as is. In the past, there\n-  were several failed attempts to do that.\n-\n-- Explore alternative representations for the parse tree.\n-\n-- Use parser generator instead of hand written parser. Using the\n-  parser from libsyntax directly would be easier, and hand-written\n-  LL-style parsers usually have much better error recovery than\n-  generated LR-style ones.\n-\n-# Unresolved questions\n-[unresolved]: #unresolved-questions\n-\n-- Is it at all possible to represent Rust parser as a pure function of\n-  the source code? It seems like the answer is yes, because the\n-  language and especially macros were cleverly designed with this\n-  use-case in mind.\n-\n-\n-- Is it possible to implement macro expansion using the proposed\n-  framework? This is the main question of this RFC. The proposed\n-  solution of synthesizing source code on the fly seems workable: it's\n-  not that different from the current implementation, which\n-  synthesizes token trees.\n-\n-\n-- How to actually phase out current libsyntax, if libsyntax2.0 turns\n-  out to be a success?"}, {"sha": "a9d32d1d410ada49c26307c95ef23999229ee2ca", "filename": "docs/TESTS.md", "status": "removed", "additions": 0, "deletions": 44, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FTESTS.md", "raw_url": "https://github.com/rust-lang/rust/raw/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FTESTS.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2FTESTS.md?ref=6cade3f6d8ad7bb5a11b1910689b25f709c12502", "patch": "@@ -1,44 +0,0 @@\n-# libsyntax2.0 testing infrastructure\n-\n-Libsyntax2.0 tests are in the `tests/data` directory. Each test is a\n-pair of files, an `.rs` file with Rust code and a `.txt` file with a\n-human-readable representation of syntax tree.\n-\n-The test suite is intended to be independent from a particular parser:\n-that's why it is just a list of files.\n-\n-The test suite is intended to be progressive: that is, if you want to\n-write a Rust parser, you can TDD it by working through the test in\n-order. That's why each test file begins with the number. Generally,\n-tests should be added in order of the appearance of corresponding\n-functionality in libsytnax2.0. If a bug in parser is uncovered, a\n-**new** test should be created instead of modifying an existing one:\n-it is preferable to have a gazillion of small isolated test files,\n-rather than a single file which covers all edge cases. It's okay for\n-files to have the same name except for the leading number. In general,\n-test suite should be append-only: old tests should not be modified,\n-new tests should be created instead.\n-\n-Note that only `ok` tests are normative: `err` tests test error\n-recovery and it is totally ok for a parser to not implement any error\n-recovery at all. However, for libsyntax2.0 we do care about error\n-recovery, and we do care about precise and useful error messages.\n-\n-There are also so-called \"inline tests\". They appear as the comments\n-with a `test` header in the source code, like this:\n-\n-```rust\n-// test fn_basic\n-// fn foo() {}\n-fn function(p: &mut Parser) {\n-    // ...\n-}\n-```\n-\n-You can run `cargo collect-tests` command to collect all inline tests\n-into `tests/data/inline` directory. The main advantage of inline tests\n-is that they help to illustrate what the relevant code is doing.\n-\n-\n-Contribution opportunity: design and implement testing infrastructure\n-for validators."}, {"sha": "f8754c06fe42cb42d5487fbbb6108803ddb28209", "filename": "docs/TOOLS.md", "status": "removed", "additions": 0, "deletions": 36, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FTOOLS.md", "raw_url": "https://github.com/rust-lang/rust/raw/6cade3f6d8ad7bb5a11b1910689b25f709c12502/docs%2FTOOLS.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2FTOOLS.md?ref=6cade3f6d8ad7bb5a11b1910689b25f709c12502", "patch": "@@ -1,36 +0,0 @@\n-# Tools used to implement libsyntax\n-\n-libsyntax uses several tools to help with development. \n-\n-Each tool is a binary in the [tools/](../tools) package. \n-You can run them via `cargo run` command. \n-\n-```\n-cargo run --package tools --bin tool\n-```\n-\n-There are also aliases in [./cargo/config](../.cargo/config), \n-so the following also works:\n-\n-```\n-cargo tool\n-```\n-\n-\n-## Tool: `gen`\n-\n-This tool reads a \"grammar\" from [grammar.ron](../grammar.ron) and\n-generates the `syntax_kinds.rs` file. You should run this tool if you \n-add new keywords or syntax elements.\n-\n-\n-## Tool: `parse`\n-\n-This tool reads rust source code from the standard input, parses it,\n-and prints the result to stdout.\n-\n-\n-## Tool: `collect-tests`\n-\n-This tools collect inline tests from comments in libsyntax2 source code\n-and places them into `tests/data/inline` directory."}]}