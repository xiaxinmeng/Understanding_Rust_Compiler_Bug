{"sha": "aa6725407ae0a2cb88458e147e76adf8bcae0961", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFhNjcyNTQwN2FlMGEyY2I4ODQ1OGUxNDdlNzZhZGY4YmNhZTA5NjE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-08T16:06:42Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-05-08T16:06:42Z"}, "message": "auto merge of #14032 : pcwalton/rust/detildestr, r=alexcrichton\n\nr? @brson", "tree": {"sha": "c09983e00886791c40b9304d99dd8d05e2d613c2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c09983e00886791c40b9304d99dd8d05e2d613c2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/aa6725407ae0a2cb88458e147e76adf8bcae0961", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/aa6725407ae0a2cb88458e147e76adf8bcae0961", "html_url": "https://github.com/rust-lang/rust/commit/aa6725407ae0a2cb88458e147e76adf8bcae0961", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/aa6725407ae0a2cb88458e147e76adf8bcae0961/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e45485181338137136ea2816d78ed108440f7d50", "url": "https://api.github.com/repos/rust-lang/rust/commits/e45485181338137136ea2816d78ed108440f7d50", "html_url": "https://github.com/rust-lang/rust/commit/e45485181338137136ea2816d78ed108440f7d50"}, {"sha": "7f8f3dcf179d7b771f8e9c588ab081ab5eb9c394", "url": "https://api.github.com/repos/rust-lang/rust/commits/7f8f3dcf179d7b771f8e9c588ab081ab5eb9c394", "html_url": "https://github.com/rust-lang/rust/commit/7f8f3dcf179d7b771f8e9c588ab081ab5eb9c394"}], "stats": {"total": 1402, "additions": 773, "deletions": 629}, "files": [{"sha": "9fa3553cbfc9d8f382735219da4f0759aa6089d9", "filename": "src/librustc/back/link.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fback%2Flink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fback%2Flink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fback%2Flink.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -536,7 +536,7 @@ pub fn crate_id_hash(crate_id: &CrateId) -> ~str {\n     // the crate id in the hash because lookups are only done by (name/vers),\n     // not by path.\n     let mut s = Sha256::new();\n-    s.input_str(crate_id.short_name_with_version());\n+    s.input_str(crate_id.short_name_with_version().as_slice());\n     truncated_hash_result(&mut s).slice_to(8).to_owned()\n }\n \n@@ -566,7 +566,7 @@ fn symbol_hash(tcx: &ty::ctxt,\n     // to be independent of one another in the crate.\n \n     symbol_hasher.reset();\n-    symbol_hasher.input_str(link_meta.crateid.name);\n+    symbol_hasher.input_str(link_meta.crateid.name.as_slice());\n     symbol_hasher.input_str(\"-\");\n     symbol_hasher.input_str(link_meta.crate_hash.as_str());\n     symbol_hasher.input_str(\"-\");"}, {"sha": "701117edb478330e9abdacbe5215b2de1d0fc5f2", "filename": "src/librustc/driver/driver.rs", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdriver%2Fdriver.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -143,8 +143,8 @@ pub fn build_configuration(sess: &Session) -> ast::CrateConfig {\n fn parse_cfgspecs(cfgspecs: Vec<~str> )\n                   -> ast::CrateConfig {\n     cfgspecs.move_iter().map(|s| {\n-        parse::parse_meta_from_source_str(\"cfgspec\".to_str(),\n-                                          s,\n+        parse::parse_meta_from_source_str(\"cfgspec\".to_strbuf(),\n+                                          s.to_strbuf(),\n                                           Vec::new(),\n                                           &parse::new_parse_sess())\n     }).collect::<ast::CrateConfig>()\n@@ -175,8 +175,8 @@ pub fn phase_1_parse_input(sess: &Session, cfg: ast::CrateConfig, input: &Input)\n                 parse::parse_crate_from_file(&(*file), cfg.clone(), &sess.parse_sess)\n             }\n             StrInput(ref src) => {\n-                parse::parse_crate_from_source_str(anon_src(),\n-                                                   (*src).clone(),\n+                parse::parse_crate_from_source_str(anon_src().to_strbuf(),\n+                                                   src.to_strbuf(),\n                                                    cfg.clone(),\n                                                    &sess.parse_sess)\n             }\n@@ -528,7 +528,7 @@ fn write_out_deps(sess: &Session,\n         // write Makefile-compatible dependency rules\n         let files: Vec<~str> = sess.codemap().files.borrow()\n                                    .iter().filter(|fmap| fmap.is_real_file())\n-                                   .map(|fmap| fmap.name.clone())\n+                                   .map(|fmap| fmap.name.to_owned())\n                                    .collect();\n         let mut file = try!(io::File::create(&deps_filename));\n         for path in out_filenames.iter() {\n@@ -604,20 +604,20 @@ impl pprust::PpAnn for IdentifiedAnnotation {\n         match node {\n             pprust::NodeItem(item) => {\n                 try!(pp::space(&mut s.s));\n-                s.synth_comment(item.id.to_str())\n+                s.synth_comment(item.id.to_str().to_strbuf())\n             }\n             pprust::NodeBlock(blk) => {\n                 try!(pp::space(&mut s.s));\n-                s.synth_comment(\"block \".to_owned() + blk.id.to_str())\n+                s.synth_comment((format!(\"block {}\", blk.id)).to_strbuf())\n             }\n             pprust::NodeExpr(expr) => {\n                 try!(pp::space(&mut s.s));\n-                try!(s.synth_comment(expr.id.to_str()));\n+                try!(s.synth_comment(expr.id.to_str().to_strbuf()));\n                 s.pclose()\n             }\n             pprust::NodePat(pat) => {\n                 try!(pp::space(&mut s.s));\n-                s.synth_comment(\"pat \".to_owned() + pat.id.to_str())\n+                s.synth_comment((format!(\"pat {}\", pat.id)).to_strbuf())\n             }\n         }\n     }\n@@ -692,7 +692,7 @@ pub fn pretty_print_input(sess: Session,\n             pprust::print_crate(sess.codemap(),\n                                 sess.diagnostic(),\n                                 &krate,\n-                                src_name,\n+                                src_name.to_strbuf(),\n                                 &mut rdr,\n                                 out,\n                                 &IdentifiedAnnotation,\n@@ -707,7 +707,7 @@ pub fn pretty_print_input(sess: Session,\n             pprust::print_crate(annotation.analysis.ty_cx.sess.codemap(),\n                                 annotation.analysis.ty_cx.sess.diagnostic(),\n                                 &krate,\n-                                src_name,\n+                                src_name.to_strbuf(),\n                                 &mut rdr,\n                                 out,\n                                 &annotation,\n@@ -717,7 +717,7 @@ pub fn pretty_print_input(sess: Session,\n             pprust::print_crate(sess.codemap(),\n                                 sess.diagnostic(),\n                                 &krate,\n-                                src_name,\n+                                src_name.to_strbuf(),\n                                 &mut rdr,\n                                 out,\n                                 &pprust::NoAnn,"}, {"sha": "859647b1beb47c7d8bcf827351450cdc52489d6b", "filename": "src/librustc/driver/session.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fdriver%2Fsession.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fdriver%2Fsession.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdriver%2Fsession.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -471,7 +471,8 @@ cgoptions!(\n )\n \n // Seems out of place, but it uses session, so I'm putting it here\n-pub fn expect<T:Clone>(sess: &Session, opt: Option<T>, msg: || -> ~str) -> T {\n+pub fn expect<T:Clone>(sess: &Session, opt: Option<T>, msg: || -> StrBuf)\n+              -> T {\n     diagnostic::expect(sess.diagnostic(), opt, msg)\n }\n "}, {"sha": "732443f1d4211b9da3db14bee5869cbd2c487df9", "filename": "src/librustc/front/test.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Ffront%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Ffront%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Ffront%2Ftest.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -168,7 +168,7 @@ fn generate_test_harness(sess: &Session, krate: ast::Crate)\n     cx.ext_cx.bt_push(ExpnInfo {\n         call_site: DUMMY_SP,\n         callee: NameAndSpan {\n-            name: \"test\".to_owned(),\n+            name: \"test\".to_strbuf(),\n             format: MacroAttribute,\n             span: None\n         }\n@@ -398,7 +398,7 @@ fn mk_tests(cx: &TestCtxt) -> @ast::Item {\n \n fn is_test_crate(krate: &ast::Crate) -> bool {\n     match attr::find_crateid(krate.attrs.as_slice()) {\n-        Some(ref s) if \"test\" == s.name => true,\n+        Some(ref s) if \"test\" == s.name.as_slice() => true,\n         _ => false\n     }\n }\n@@ -427,7 +427,7 @@ fn mk_test_desc_and_fn_rec(cx: &TestCtxt, test: &Test) -> @ast::Expr {\n \n     let name_lit: ast::Lit =\n         nospan(ast::LitStr(token::intern_and_get_ident(\n-                    ast_util::path_name_i(path.as_slice())),\n+                    ast_util::path_name_i(path.as_slice()).as_slice()),\n                     ast::CookedStr));\n \n     let name_expr = @ast::Expr {"}, {"sha": "ab755b39f1a399ffcb5aaa03314df92c667ea9ab", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -352,10 +352,11 @@ fn parse_crate_attrs(sess: &session::Session, input: &d::Input) ->\n                                                &sess.parse_sess)\n         }\n         d::StrInput(ref src) => {\n-            parse::parse_crate_attrs_from_source_str(d::anon_src(),\n-                                                     (*src).clone(),\n-                                                     Vec::new(),\n-                                                     &sess.parse_sess)\n+            parse::parse_crate_attrs_from_source_str(\n+                d::anon_src().to_strbuf(),\n+                src.to_strbuf(),\n+                Vec::new(),\n+                &sess.parse_sess)\n         }\n     };\n     result.move_iter().collect()"}, {"sha": "a5675f52671feb011c036fcf6298118c5888478f", "filename": "src/librustc/metadata/creader.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fcreader.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fcreader.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fcreader.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -428,11 +428,11 @@ impl<'a> CrateLoader for Loader<'a> {\n         };\n         let macros = decoder::get_exported_macros(library.metadata.as_slice());\n         let registrar = decoder::get_macro_registrar_fn(library.metadata.as_slice()).map(|id| {\n-            decoder::get_symbol(library.metadata.as_slice(), id)\n+            decoder::get_symbol(library.metadata.as_slice(), id).to_strbuf()\n         });\n         let mc = MacroCrate {\n             lib: library.dylib.clone(),\n-            macros: macros.move_iter().collect(),\n+            macros: macros.move_iter().map(|x| x.to_strbuf()).collect(),\n             registrar_symbol: registrar,\n         };\n         if should_link {"}, {"sha": "5906312b51523ea371ab0ff59784a4a421c8f757", "filename": "src/librustc/metadata/csearch.rs", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fcsearch.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fcsearch.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fcsearch.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -207,12 +207,17 @@ pub fn get_field_type(tcx: &ty::ctxt, class_id: ast::DefId,\n     let all_items = reader::get_doc(reader::Doc(cdata.data()), tag_items);\n     let class_doc = expect(tcx.sess.diagnostic(),\n                            decoder::maybe_find_item(class_id.node, all_items),\n-                           || format!(\"get_field_type: class ID {:?} not found\",\n-                                   class_id) );\n+                           || {\n+        (format!(\"get_field_type: class ID {:?} not found\",\n+                 class_id)).to_strbuf()\n+    });\n     let the_field = expect(tcx.sess.diagnostic(),\n         decoder::maybe_find_item(def.node, class_doc),\n-        || format!(\"get_field_type: in class {:?}, field ID {:?} not found\",\n-                 class_id, def) );\n+        || {\n+            (format!(\"get_field_type: in class {:?}, field ID {:?} not found\",\n+                    class_id,\n+                    def)).to_strbuf()\n+        });\n     let ty = decoder::item_type(def, the_field, tcx, &*cdata);\n     ty::ty_param_bounds_and_ty {\n         generics: ty::Generics {type_param_defs: Rc::new(Vec::new()),"}, {"sha": "5faae72791d7e784bd20c5027d90839d5258b987", "filename": "src/librustc/metadata/encoder.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fencoder.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -1563,7 +1563,7 @@ impl<'a, 'b, 'c> Visitor<()> for MacroDefVisitor<'a, 'b, 'c> {\n                 let def = self.ecx.tcx.sess.codemap().span_to_snippet(item.span)\n                     .expect(\"Unable to find source for macro\");\n                 self.ebml_w.start_tag(tag_macro_def);\n-                self.ebml_w.wr_str(def);\n+                self.ebml_w.wr_str(def.as_slice());\n                 self.ebml_w.end_tag();\n             }\n             _ => {}"}, {"sha": "48c6d2a53d756b181c1891854d4581fc43c11bbe", "filename": "src/librustc/middle/dataflow.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fdataflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fdataflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fdataflow.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -112,8 +112,8 @@ impl<'a, O:DataFlowOperator> pprust::PpAnn for DataFlowContext<'a, O> {\n                 \"\".to_owned()\n             };\n \n-            try!(ps.synth_comment(format!(\"id {}: {}{}{}\", id, entry_str,\n-                                          gens_str, kills_str)));\n+            try!(ps.synth_comment((format!(\"id {}: {}{}{}\", id, entry_str,\n+                                          gens_str, kills_str)).to_strbuf()));\n             try!(pp::space(&mut ps.s));\n         }\n         Ok(())"}, {"sha": "e63711f0a575a2b10e4806106ec3f5e81f6b1921", "filename": "src/librustc/middle/kind.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fkind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fkind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fkind.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -569,7 +569,7 @@ fn check_sized(tcx: &ty::ctxt, ty: ty::t, name: ~str, sp: Span) {\n fn check_pat(cx: &mut Context, pat: &Pat) {\n     let var_name = match pat.node {\n         PatWild => Some(\"_\".to_owned()),\n-        PatIdent(_, ref path, _) => Some(path_to_str(path)),\n+        PatIdent(_, ref path, _) => Some(path_to_str(path).to_owned()),\n         _ => None\n     };\n "}, {"sha": "a08028f374283839a963382e19f5ef730620f9d5", "filename": "src/librustc/middle/privacy.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fprivacy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fprivacy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fprivacy.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -357,7 +357,7 @@ enum FieldName {\n impl<'a> PrivacyVisitor<'a> {\n     // used when debugging\n     fn nodestr(&self, id: ast::NodeId) -> ~str {\n-        self.tcx.map.node_to_str(id)\n+        self.tcx.map.node_to_str(id).to_owned()\n     }\n \n     // Determines whether the given definition is public from the point of view"}, {"sha": "064593f2b41790b4ffd9efcb6361d1c82d0b544a", "filename": "src/librustc/middle/resolve.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fresolve.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fresolve.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fresolve.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -3167,12 +3167,12 @@ impl<'a> Resolver<'a> {\n                          .codemap()\n                          .span_to_snippet(imports.get(index).span)\n                          .unwrap();\n-            if sn.contains(\"::\") {\n+            if sn.as_slice().contains(\"::\") {\n                 self.resolve_error(imports.get(index).span,\n                                    \"unresolved import\");\n             } else {\n                 let err = format!(\"unresolved import (maybe you meant `{}::*`?)\",\n-                               sn.slice(0, sn.len()));\n+                                  sn.as_slice().slice(0, sn.len()));\n                 self.resolve_error(imports.get(index).span, err);\n             }\n         }"}, {"sha": "3bef0eae0acbce0c98ece7977e85d00546e74ed2", "filename": "src/librustc/middle/trans/base.rs", "status": "modified", "additions": 9, "deletions": 4, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fbase.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -1145,7 +1145,11 @@ pub fn new_fn_ctxt<'a>(ccx: &'a CrateContext,\n     for p in param_substs.iter() { p.validate(); }\n \n     debug!(\"new_fn_ctxt(path={}, id={}, param_substs={})\",\n-           if id == -1 { \"\".to_owned() } else { ccx.tcx.map.path_to_str(id) },\n+           if id == -1 {\n+               \"\".to_owned()\n+           } else {\n+               ccx.tcx.map.path_to_str(id).to_owned()\n+           },\n            id, param_substs.map(|s| s.repr(ccx.tcx())));\n \n     let substd_output_type = match param_substs {\n@@ -1458,7 +1462,7 @@ pub fn trans_fn(ccx: &CrateContext,\n                 param_substs: Option<&param_substs>,\n                 id: ast::NodeId,\n                 attrs: &[ast::Attribute]) {\n-    let _s = StatRecorder::new(ccx, ccx.tcx.map.path_to_str(id));\n+    let _s = StatRecorder::new(ccx, ccx.tcx.map.path_to_str(id).to_owned());\n     debug!(\"trans_fn(param_substs={})\", param_substs.map(|s| s.repr(ccx.tcx())));\n     let _icx = push_ctxt(\"trans_fn\");\n     let output_type = ty::ty_fn_ret(ty::node_id_to_type(ccx.tcx(), id));\n@@ -2161,9 +2165,10 @@ pub fn trans_crate(krate: ast::Crate,\n     // crashes if the module identifer is same as other symbols\n     // such as a function name in the module.\n     // 1. http://llvm.org/bugs/show_bug.cgi?id=11479\n-    let llmod_id = link_meta.crateid.name + \".rs\";\n+    let mut llmod_id = link_meta.crateid.name.clone();\n+    llmod_id.push_str(\".rs\");\n \n-    let ccx = CrateContext::new(llmod_id, tcx, exp_map2,\n+    let ccx = CrateContext::new(llmod_id.as_slice(), tcx, exp_map2,\n                                 Sha256::new(), link_meta, reachable);\n     {\n         let _icx = push_ctxt(\"text\");"}, {"sha": "e1763ab3ff16481c7d0d73721fa89ff8d9045747", "filename": "src/librustc/middle/trans/callee.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcallee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcallee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcallee.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -364,7 +364,7 @@ pub fn trans_fn_ref_with_vtables(\n         let map_node = session::expect(\n             ccx.sess(),\n             tcx.map.find(def_id.node),\n-            || format!(\"local item should be in ast map\"));\n+            || \"local item should be in ast map\".to_strbuf());\n \n         match map_node {\n             ast_map::NodeForeignItem(_) => {"}, {"sha": "24abf1fd3f1bb8d3d2fef46c98c8d1d55b94cfe3", "filename": "src/librustc/middle/trans/common.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcommon.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -426,7 +426,7 @@ impl<'a> Block<'a> {\n     }\n \n     pub fn node_id_to_str(&self, id: ast::NodeId) -> ~str {\n-        self.tcx().map.node_to_str(id)\n+        self.tcx().map.node_to_str(id).to_owned()\n     }\n \n     pub fn expr_to_str(&self, e: &ast::Expr) -> ~str {\n@@ -839,7 +839,10 @@ pub fn filename_and_line_num_from_span(bcx: &Block, span: Span)\n                                        -> (ValueRef, ValueRef) {\n     let loc = bcx.sess().codemap().lookup_char_pos(span.lo);\n     let filename_cstr = C_cstr(bcx.ccx(),\n-                               token::intern_and_get_ident(loc.file.name), true);\n+                               token::intern_and_get_ident(loc.file\n+                                                              .name\n+                                                              .as_slice()),\n+                               true);\n     let filename = build::PointerCast(bcx, filename_cstr, Type::i8p(bcx.ccx()));\n     let line = C_int(bcx.ccx(), loc.line as int);\n     (filename, line)"}, {"sha": "a165549dacabb34dd64e8cdd6637a8169287d8cb", "filename": "src/librustc/middle/trans/controlflow.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fcontrolflow.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -345,7 +345,11 @@ pub fn trans_fail<'a>(\n     let v_fail_str = C_cstr(ccx, fail_str, true);\n     let _icx = push_ctxt(\"trans_fail_value\");\n     let loc = bcx.sess().codemap().lookup_char_pos(sp.lo);\n-    let v_filename = C_cstr(ccx, token::intern_and_get_ident(loc.file.name), true);\n+    let v_filename = C_cstr(ccx,\n+                            token::intern_and_get_ident(loc.file\n+                                                           .name\n+                                                           .as_slice()),\n+                            true);\n     let v_line = loc.line as int;\n     let v_str = PointerCast(bcx, v_fail_str, Type::i8p(ccx));\n     let v_filename = PointerCast(bcx, v_filename, Type::i8p(ccx));"}, {"sha": "fe92105118936d0f061da3d33340a5394e8f34f8", "filename": "src/librustc/middle/trans/debuginfo.rs", "status": "modified", "additions": 21, "deletions": 15, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fdebuginfo.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -330,7 +330,7 @@ pub fn create_global_var_metadata(cx: &CrateContext,\n     };\n \n     let filename = span_start(cx, span).file.name.clone();\n-    let file_metadata = file_metadata(cx, filename);\n+    let file_metadata = file_metadata(cx, filename.as_slice());\n \n     let is_local_to_unit = is_node_local_to_unit(cx, node_id);\n     let loc = span_start(cx, span);\n@@ -700,7 +700,7 @@ pub fn create_function_debug_context(cx: &CrateContext,\n     }\n \n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     let function_type_metadata = unsafe {\n         let fn_signature = get_function_signature(cx, fn_ast_id, fn_decl, param_substs, span);\n@@ -1011,7 +1011,7 @@ fn compile_unit_metadata(cx: &CrateContext) {\n     });\n \n     fn fallback_path(cx: &CrateContext) -> CString {\n-        cx.link_meta.crateid.name.to_c_str()\n+        cx.link_meta.crateid.name.as_slice().to_c_str()\n     }\n }\n \n@@ -1025,7 +1025,7 @@ fn declare_local(bcx: &Block,\n     let cx: &CrateContext = bcx.ccx();\n \n     let filename = span_start(cx, span).file.name.clone();\n-    let file_metadata = file_metadata(cx, filename);\n+    let file_metadata = file_metadata(cx, filename.as_slice());\n \n     let name = token::get_ident(variable_ident);\n     let loc = span_start(cx, span);\n@@ -1277,7 +1277,7 @@ fn prepare_struct_metadata(cx: &CrateContext,\n     let (containing_scope, definition_span) = get_namespace_and_span_for_item(cx, def_id);\n \n     let file_name = span_start(cx, definition_span).file.name.clone();\n-    let file_metadata = file_metadata(cx, file_name);\n+    let file_metadata = file_metadata(cx, file_name.as_slice());\n \n     let struct_metadata_stub = create_struct_stub(cx,\n                                                   struct_llvm_type,\n@@ -1371,7 +1371,7 @@ fn prepare_tuple_metadata(cx: &CrateContext,\n     let tuple_llvm_type = type_of::type_of(cx, tuple_type);\n \n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     UnfinishedMetadata {\n         cache_id: cache_id_for_type(tuple_type),\n@@ -1533,7 +1533,7 @@ fn prepare_enum_metadata(cx: &CrateContext,\n \n     let (containing_scope, definition_span) = get_namespace_and_span_for_item(cx, enum_def_id);\n     let loc = span_start(cx, definition_span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     // For empty enums there is an early exit. Just describe it as an empty struct with the\n     // appropriate type name\n@@ -1903,7 +1903,7 @@ fn boxed_type_metadata(cx: &CrateContext,\n     ];\n \n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     return composite_type_metadata(\n         cx,\n@@ -2004,7 +2004,7 @@ fn vec_metadata(cx: &CrateContext,\n     assert!(member_descriptions.len() == member_llvm_types.len());\n \n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     composite_type_metadata(\n         cx,\n@@ -2055,7 +2055,7 @@ fn vec_slice_metadata(cx: &CrateContext,\n     assert!(member_descriptions.len() == member_llvm_types.len());\n \n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     return composite_type_metadata(\n         cx,\n@@ -2081,7 +2081,7 @@ fn subroutine_type_metadata(cx: &CrateContext,\n                             span: Span)\n                          -> DICompositeType {\n     let loc = span_start(cx, span);\n-    let file_metadata = file_metadata(cx, loc.file.name);\n+    let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n \n     let mut signature_metadata: Vec<DIType> =\n         Vec::with_capacity(signature.inputs.len() + 1);\n@@ -2126,7 +2126,7 @@ fn trait_metadata(cx: &CrateContext,\n     let (containing_scope, definition_span) = get_namespace_and_span_for_item(cx, def_id);\n \n     let file_name = span_start(cx, definition_span).file.name.clone();\n-    let file_metadata = file_metadata(cx, file_name);\n+    let file_metadata = file_metadata(cx, file_name.as_slice());\n \n     let trait_llvm_type = type_of::type_of(cx, trait_type);\n \n@@ -2420,7 +2420,7 @@ fn populate_scope_map(cx: &CrateContext,\n                                    &mut HashMap<ast::NodeId, DIScope>|) {\n         // Create a new lexical scope and push it onto the stack\n         let loc = cx.sess().codemap().lookup_char_pos(scope_span.lo);\n-        let file_metadata = file_metadata(cx, loc.file.name);\n+        let file_metadata = file_metadata(cx, loc.file.name.as_slice());\n         let parent_scope = scope_stack.last().unwrap().scope_metadata;\n \n         let scope_metadata = unsafe {\n@@ -2538,7 +2538,10 @@ fn populate_scope_map(cx: &CrateContext,\n                     if need_new_scope {\n                         // Create a new lexical scope and push it onto the stack\n                         let loc = cx.sess().codemap().lookup_char_pos(pat.span.lo);\n-                        let file_metadata = file_metadata(cx, loc.file.name);\n+                        let file_metadata = file_metadata(cx,\n+                                                          loc.file\n+                                                             .name\n+                                                             .as_slice());\n                         let parent_scope = scope_stack.last().unwrap().scope_metadata;\n \n                         let scope_metadata = unsafe {\n@@ -2860,7 +2863,10 @@ fn namespace_for_item(cx: &CrateContext, def_id: ast::DefId) -> Rc<NamespaceTree\n     ty::with_path(cx.tcx(), def_id, |path| {\n         // prepend crate name if not already present\n         let krate = if def_id.krate == ast::LOCAL_CRATE {\n-            let crate_namespace_ident = token::str_to_ident(cx.link_meta.crateid.name);\n+            let crate_namespace_ident = token::str_to_ident(cx.link_meta\n+                                                              .crateid\n+                                                              .name\n+                                                              .as_slice());\n             Some(ast_map::PathMod(crate_namespace_ident.name))\n         } else {\n             None"}, {"sha": "b8f50fcb1e58c245e61592e918567f8818e08fbd", "filename": "src/librustc/middle/trans/monomorphize.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fmonomorphize.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Ftrans%2Fmonomorphize.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans%2Fmonomorphize.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -109,9 +109,11 @@ pub fn monomorphic_fn(ccx: &CrateContext,\n     let map_node = session::expect(\n         ccx.sess(),\n         ccx.tcx.map.find(fn_id.node),\n-        || format!(\"while monomorphizing {:?}, couldn't find it in the \\\n-                    item map (may have attempted to monomorphize an item \\\n-                    defined in a different crate?)\", fn_id));\n+        || {\n+            (format!(\"while monomorphizing {:?}, couldn't find it in the \\\n+                      item map (may have attempted to monomorphize an item \\\n+                      defined in a different crate?)\", fn_id)).to_strbuf()\n+        });\n \n     match map_node {\n         ast_map::NodeForeignItem(_) => {"}, {"sha": "7067ce888368bccca1da038c7ad7746c7a98f125", "filename": "src/librustc/middle/ty.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Fmiddle%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fty.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -3709,7 +3709,7 @@ pub fn substd_enum_variants(cx: &ctxt,\n }\n \n pub fn item_path_str(cx: &ctxt, id: ast::DefId) -> ~str {\n-    with_path(cx, id, |path| ast_map::path_to_str(path))\n+    with_path(cx, id, |path| ast_map::path_to_str(path)).to_owned()\n }\n \n pub enum DtorKind {"}, {"sha": "1808c0209b754c1e39e62b503753380643b45b7c", "filename": "src/librustc/util/ppaux.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Futil%2Fppaux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustc%2Futil%2Fppaux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fppaux.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -341,9 +341,9 @@ pub fn ty_to_str(cx: &ctxt, typ: t) -> ~str {\n       ty_bot => \"!\".to_owned(),\n       ty_bool => \"bool\".to_owned(),\n       ty_char => \"char\".to_owned(),\n-      ty_int(t) => ast_util::int_ty_to_str(t, None),\n-      ty_uint(t) => ast_util::uint_ty_to_str(t, None),\n-      ty_float(t) => ast_util::float_ty_to_str(t),\n+      ty_int(t) => ast_util::int_ty_to_str(t, None).to_owned(),\n+      ty_uint(t) => ast_util::uint_ty_to_str(t, None).to_owned(),\n+      ty_float(t) => ast_util::float_ty_to_str(t).to_owned(),\n       ty_box(typ) => \"@\".to_owned() + ty_to_str(cx, typ),\n       ty_uniq(typ) => \"~\".to_owned() + ty_to_str(cx, typ),\n       ty_ptr(ref tm) => \"*\".to_owned() + mt_to_str(cx, tm),\n@@ -870,7 +870,7 @@ impl Repr for ty::BuiltinBounds {\n \n impl Repr for Span {\n     fn repr(&self, tcx: &ctxt) -> ~str {\n-        tcx.sess.codemap().span_to_str(*self)\n+        tcx.sess.codemap().span_to_str(*self).to_owned()\n     }\n }\n "}, {"sha": "14a27a607823c1d5b4cb9c0951a1863cce4614b5", "filename": "src/librustdoc/clean.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustdoc%2Fclean.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustdoc%2Fclean.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -92,7 +92,7 @@ impl<'a> Clean<Crate> for visit_ast::RustdocVisitor<'a> {\n         let id = link::find_crate_id(self.attrs.as_slice(),\n                                      t_outputs.out_filestem);\n         Crate {\n-            name: id.name,\n+            name: id.name.to_owned(),\n             module: Some(self.module.clean()),\n             externs: externs,\n         }\n@@ -1239,7 +1239,7 @@ impl ToSource for syntax::codemap::Span {\n         let ctxt = super::ctxtkey.get().unwrap();\n         let cm = ctxt.sess().codemap().clone();\n         let sn = match cm.span_to_snippet(*self) {\n-            Some(x) => x,\n+            Some(x) => x.to_owned(),\n             None    => \"\".to_owned()\n         };\n         debug!(\"got snippet {}\", sn);"}, {"sha": "bddf857534424716f0cea6e98e895e9bde6333fe", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -27,7 +27,9 @@ use t = syntax::parse::token;\n /// Highlights some source code, returning the HTML output.\n pub fn highlight(src: &str, class: Option<&str>) -> ~str {\n     let sess = parse::new_parse_sess();\n-    let fm = parse::string_to_filemap(&sess, src.to_owned(), \"<stdin>\".to_owned());\n+    let fm = parse::string_to_filemap(&sess,\n+                                      src.to_strbuf(),\n+                                      \"<stdin>\".to_strbuf());\n \n     let mut out = io::MemWriter::new();\n     doit(&sess,\n@@ -70,11 +72,11 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader, class: Option<&\n                 hi: test,\n                 expn_info: None,\n             }).unwrap();\n-            if snip.contains(\"/\") {\n+            if snip.as_slice().contains(\"/\") {\n                 try!(write!(out, \"<span class='comment'>{}</span>\",\n-                              Escape(snip)));\n+                              Escape(snip.as_slice())));\n             } else {\n-                try!(write!(out, \"{}\", Escape(snip)));\n+                try!(write!(out, \"{}\", Escape(snip.as_slice())));\n             }\n         }\n         last = next.sp.hi;\n@@ -171,10 +173,10 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader, class: Option<&\n         // stringifying this token\n         let snip = sess.span_diagnostic.cm.span_to_snippet(next.sp).unwrap();\n         if klass == \"\" {\n-            try!(write!(out, \"{}\", Escape(snip)));\n+            try!(write!(out, \"{}\", Escape(snip.as_slice())));\n         } else {\n             try!(write!(out, \"<span class='{}'>{}</span>\", klass,\n-                          Escape(snip)));\n+                          Escape(snip.as_slice())));\n         }\n     }\n "}, {"sha": "333f876e479b168a839df0f575d243b0f0a3f758", "filename": "src/libsyntax/ast_map.rs", "status": "modified", "additions": 29, "deletions": 22, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fast_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fast_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_map.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -79,7 +79,7 @@ impl<'a, T: Copy> Iterator<T> for Values<'a, T> {\n /// The type of the iterator used by with_path.\n pub type PathElems<'a, 'b> = iter::Chain<Values<'a, PathElem>, LinkedPath<'b>>;\n \n-pub fn path_to_str<PI: Iterator<PathElem>>(mut path: PI) -> ~str {\n+pub fn path_to_str<PI: Iterator<PathElem>>(mut path: PI) -> StrBuf {\n     let itr = token::get_ident_interner();\n \n     path.fold(StrBuf::new(), |mut s, e| {\n@@ -89,7 +89,7 @@ pub fn path_to_str<PI: Iterator<PathElem>>(mut path: PI) -> ~str {\n         }\n         s.push_str(e.as_slice());\n         s\n-    }).into_owned()\n+    }).to_strbuf()\n }\n \n #[deriving(Clone)]\n@@ -322,11 +322,11 @@ impl Map {\n         self.with_path_next(id, None, f)\n     }\n \n-    pub fn path_to_str(&self, id: NodeId) -> ~str {\n+    pub fn path_to_str(&self, id: NodeId) -> StrBuf {\n         self.with_path(id, |path| path_to_str(path))\n     }\n \n-    fn path_to_str_with_ident(&self, id: NodeId, i: Ident) -> ~str {\n+    fn path_to_str_with_ident(&self, id: NodeId, i: Ident) -> StrBuf {\n         self.with_path(id, |path| {\n             path_to_str(path.chain(Some(PathName(i.name)).move_iter()))\n         })\n@@ -405,7 +405,7 @@ impl Map {\n         }\n     }\n \n-    pub fn node_to_str(&self, id: NodeId) -> ~str {\n+    pub fn node_to_str(&self, id: NodeId) -> StrBuf {\n         node_id_to_str(self, id)\n     }\n }\n@@ -650,7 +650,7 @@ pub fn map_decoded_item<F: FoldOps>(map: &Map,\n     ii\n }\n \n-fn node_id_to_str(map: &Map, id: NodeId) -> ~str {\n+fn node_id_to_str(map: &Map, id: NodeId) -> StrBuf {\n     match map.find(id) {\n         Some(NodeItem(item)) => {\n             let path_str = map.path_to_str_with_ident(id, item.ident);\n@@ -666,51 +666,58 @@ fn node_id_to_str(map: &Map, id: NodeId) -> ~str {\n                 ItemImpl(..) => \"impl\",\n                 ItemMac(..) => \"macro\"\n             };\n-            format!(\"{} {} (id={})\", item_str, path_str, id)\n+            (format!(\"{} {} (id={})\", item_str, path_str, id)).to_strbuf()\n         }\n         Some(NodeForeignItem(item)) => {\n             let path_str = map.path_to_str_with_ident(id, item.ident);\n-            format!(\"foreign item {} (id={})\", path_str, id)\n+            (format!(\"foreign item {} (id={})\", path_str, id)).to_strbuf()\n         }\n         Some(NodeMethod(m)) => {\n-            format!(\"method {} in {} (id={})\",\n+            (format!(\"method {} in {} (id={})\",\n                     token::get_ident(m.ident),\n-                    map.path_to_str(id), id)\n+                    map.path_to_str(id), id)).to_strbuf()\n         }\n         Some(NodeTraitMethod(ref tm)) => {\n             let m = ast_util::trait_method_to_ty_method(&**tm);\n-            format!(\"method {} in {} (id={})\",\n+            (format!(\"method {} in {} (id={})\",\n                     token::get_ident(m.ident),\n-                    map.path_to_str(id), id)\n+                    map.path_to_str(id), id)).to_strbuf()\n         }\n         Some(NodeVariant(ref variant)) => {\n-            format!(\"variant {} in {} (id={})\",\n+            (format!(\"variant {} in {} (id={})\",\n                     token::get_ident(variant.node.name),\n-                    map.path_to_str(id), id)\n+                    map.path_to_str(id), id)).to_strbuf()\n         }\n         Some(NodeExpr(expr)) => {\n-            format!(\"expr {} (id={})\", pprust::expr_to_str(expr), id)\n+            (format!(\"expr {} (id={})\",\n+                    pprust::expr_to_str(expr), id)).to_strbuf()\n         }\n         Some(NodeStmt(stmt)) => {\n-            format!(\"stmt {} (id={})\", pprust::stmt_to_str(stmt), id)\n+            (format!(\"stmt {} (id={})\",\n+                    pprust::stmt_to_str(stmt), id)).to_strbuf()\n         }\n         Some(NodeArg(pat)) => {\n-            format!(\"arg {} (id={})\", pprust::pat_to_str(pat), id)\n+            (format!(\"arg {} (id={})\",\n+                    pprust::pat_to_str(pat), id)).to_strbuf()\n         }\n         Some(NodeLocal(pat)) => {\n-            format!(\"local {} (id={})\", pprust::pat_to_str(pat), id)\n+            (format!(\"local {} (id={})\",\n+                    pprust::pat_to_str(pat), id)).to_strbuf()\n         }\n         Some(NodeBlock(block)) => {\n-            format!(\"block {} (id={})\", pprust::block_to_str(block), id)\n+            (format!(\"block {} (id={})\",\n+                    pprust::block_to_str(block), id)).to_strbuf()\n         }\n         Some(NodeStructCtor(_)) => {\n-            format!(\"struct_ctor {} (id={})\", map.path_to_str(id), id)\n+            (format!(\"struct_ctor {} (id={})\",\n+                    map.path_to_str(id), id)).to_strbuf()\n         }\n         Some(NodeLifetime(ref l)) => {\n-            format!(\"lifetime {} (id={})\", pprust::lifetime_to_str(*l), id)\n+            (format!(\"lifetime {} (id={})\",\n+                    pprust::lifetime_to_str(*l), id)).to_strbuf()\n         }\n         None => {\n-            format!(\"unknown node (id={})\", id)\n+            (format!(\"unknown node (id={})\", id)).to_strbuf()\n         }\n     }\n }"}, {"sha": "550b6603d5d55e82ed7d738544363fd4960988ec", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 17, "deletions": 13, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -24,11 +24,11 @@ use std::cmp;\n use std::strbuf::StrBuf;\n use std::u32;\n \n-pub fn path_name_i(idents: &[Ident]) -> ~str {\n+pub fn path_name_i(idents: &[Ident]) -> StrBuf {\n     // FIXME: Bad copies (#2543 -- same for everything else that says \"bad\")\n     idents.iter().map(|i| {\n-        token::get_ident(*i).get().to_str()\n-    }).collect::<Vec<~str>>().connect(\"::\")\n+        token::get_ident(*i).get().to_strbuf()\n+    }).collect::<Vec<StrBuf>>().connect(\"::\").to_strbuf()\n }\n \n // totally scary function: ignores all but the last element, should have\n@@ -134,7 +134,7 @@ pub fn is_path(e: @Expr) -> bool {\n \n // Get a string representation of a signed int type, with its value.\n // We want to avoid \"45int\" and \"-3int\" in favor of \"45\" and \"-3\"\n-pub fn int_ty_to_str(t: IntTy, val: Option<i64>) -> ~str {\n+pub fn int_ty_to_str(t: IntTy, val: Option<i64>) -> StrBuf {\n     let s = match t {\n         TyI if val.is_some() => \"\",\n         TyI => \"int\",\n@@ -145,8 +145,8 @@ pub fn int_ty_to_str(t: IntTy, val: Option<i64>) -> ~str {\n     };\n \n     match val {\n-        Some(n) => format!(\"{}{}\", n, s),\n-        None => s.to_owned()\n+        Some(n) => format!(\"{}{}\", n, s).to_strbuf(),\n+        None => s.to_strbuf()\n     }\n }\n \n@@ -161,7 +161,7 @@ pub fn int_ty_max(t: IntTy) -> u64 {\n \n // Get a string representation of an unsigned int type, with its value.\n // We want to avoid \"42uint\" in favor of \"42u\"\n-pub fn uint_ty_to_str(t: UintTy, val: Option<u64>) -> ~str {\n+pub fn uint_ty_to_str(t: UintTy, val: Option<u64>) -> StrBuf {\n     let s = match t {\n         TyU if val.is_some() => \"u\",\n         TyU => \"uint\",\n@@ -172,8 +172,8 @@ pub fn uint_ty_to_str(t: UintTy, val: Option<u64>) -> ~str {\n     };\n \n     match val {\n-        Some(n) => format!(\"{}{}\", n, s),\n-        None => s.to_owned()\n+        Some(n) => format!(\"{}{}\", n, s).to_strbuf(),\n+        None => s.to_strbuf()\n     }\n }\n \n@@ -186,8 +186,12 @@ pub fn uint_ty_max(t: UintTy) -> u64 {\n     }\n }\n \n-pub fn float_ty_to_str(t: FloatTy) -> ~str {\n-    match t { TyF32 => \"f32\".to_owned(), TyF64 => \"f64\".to_owned(), TyF128 => \"f128\".to_owned() }\n+pub fn float_ty_to_str(t: FloatTy) -> StrBuf {\n+    match t {\n+        TyF32 => \"f32\".to_strbuf(),\n+        TyF64 => \"f64\".to_strbuf(),\n+        TyF128 => \"f128\".to_strbuf(),\n+    }\n }\n \n pub fn is_call_expr(e: @Expr) -> bool {\n@@ -252,11 +256,11 @@ pub fn unguarded_pat(a: &Arm) -> Option<Vec<@Pat> > {\n /// listed as `__extensions__::method_name::hash`, with no indication\n /// of the type).\n pub fn impl_pretty_name(trait_ref: &Option<TraitRef>, ty: &Ty) -> Ident {\n-    let mut pretty = StrBuf::from_owned_str(pprust::ty_to_str(ty));\n+    let mut pretty = pprust::ty_to_str(ty);\n     match *trait_ref {\n         Some(ref trait_ref) => {\n             pretty.push_char('.');\n-            pretty.push_str(pprust::path_to_str(&trait_ref.path));\n+            pretty.push_str(pprust::path_to_str(&trait_ref.path).as_slice());\n         }\n         None => {}\n     }"}, {"sha": "cf5163af7170fd66f5113f8a98f1313bd4b08007", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -125,7 +125,7 @@ impl AttributeMethods for Attribute {\n             let meta = mk_name_value_item_str(\n                 InternedString::new(\"doc\"),\n                 token::intern_and_get_ident(strip_doc_comment_decoration(\n-                        comment.get())));\n+                        comment.get()).as_slice()));\n             mk_attr(meta)\n         } else {\n             *self"}, {"sha": "07cf0a61a73e1da380c04a1d4a9006babd85a3dd", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 56, "deletions": 39, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -189,7 +189,7 @@ pub enum MacroFormat {\n pub struct NameAndSpan {\n     /// The name of the macro that was invoked to create the thing\n     /// with this Span.\n-    pub name: ~str,\n+    pub name: StrBuf,\n     /// The format with which the macro was invoked.\n     pub format: MacroFormat,\n     /// The span of the macro definition itself. The macro may not\n@@ -220,7 +220,7 @@ pub struct ExpnInfo {\n     pub callee: NameAndSpan\n }\n \n-pub type FileName = ~str;\n+pub type FileName = StrBuf;\n \n pub struct FileLines {\n     pub file: Rc<FileMap>,\n@@ -242,7 +242,7 @@ pub struct FileMap {\n     /// e.g. `<anon>`\n     pub name: FileName,\n     /// The complete source code\n-    pub src: ~str,\n+    pub src: StrBuf,\n     /// The start position of this source in the CodeMap\n     pub start_pos: BytePos,\n     /// Locations of lines beginnings in the source code\n@@ -270,14 +270,14 @@ impl FileMap {\n     }\n \n     // get a line from the list of pre-computed line-beginnings\n-    pub fn get_line(&self, line: int) -> ~str {\n+    pub fn get_line(&self, line: int) -> StrBuf {\n         let mut lines = self.lines.borrow_mut();\n         let begin: BytePos = *lines.get(line as uint) - self.start_pos;\n         let begin = begin.to_uint();\n-        let slice = self.src.slice_from(begin);\n+        let slice = self.src.as_slice().slice_from(begin);\n         match slice.find('\\n') {\n-            Some(e) => slice.slice_to(e).to_owned(),\n-            None => slice.to_owned()\n+            Some(e) => slice.slice_to(e).to_strbuf(),\n+            None => slice.to_strbuf()\n         }\n     }\n \n@@ -291,7 +291,8 @@ impl FileMap {\n     }\n \n     pub fn is_real_file(&self) -> bool {\n-        !(self.name.starts_with(\"<\") && self.name.ends_with(\">\"))\n+        !(self.name.as_slice().starts_with(\"<\") &&\n+          self.name.as_slice().ends_with(\">\"))\n     }\n }\n \n@@ -306,7 +307,7 @@ impl CodeMap {\n         }\n     }\n \n-    pub fn new_filemap(&self, filename: FileName, src: ~str) -> Rc<FileMap> {\n+    pub fn new_filemap(&self, filename: FileName, src: StrBuf) -> Rc<FileMap> {\n         let mut files = self.files.borrow_mut();\n         let start_pos = match files.last() {\n             None => 0,\n@@ -316,10 +317,10 @@ impl CodeMap {\n         // Remove utf-8 BOM if any.\n         // FIXME #12884: no efficient/safe way to remove from the start of a string\n         // and reuse the allocation.\n-        let mut src = if src.starts_with(\"\\ufeff\") {\n+        let mut src = if src.as_slice().starts_with(\"\\ufeff\") {\n             StrBuf::from_str(src.as_slice().slice_from(3))\n         } else {\n-            StrBuf::from_owned_str(src)\n+            StrBuf::from_str(src.as_slice())\n         };\n \n         // Append '\\n' in case it's not already there.\n@@ -332,7 +333,7 @@ impl CodeMap {\n \n         let filemap = Rc::new(FileMap {\n             name: filename,\n-            src: src.into_owned(),\n+            src: src.to_strbuf(),\n             start_pos: Pos::from_uint(start_pos),\n             lines: RefCell::new(Vec::new()),\n             multibyte_chars: RefCell::new(Vec::new()),\n@@ -343,9 +344,12 @@ impl CodeMap {\n         filemap\n     }\n \n-    pub fn mk_substr_filename(&self, sp: Span) -> ~str {\n+    pub fn mk_substr_filename(&self, sp: Span) -> StrBuf {\n         let pos = self.lookup_char_pos(sp.lo);\n-        format!(\"<{}:{}:{}>\", pos.file.name, pos.line, pos.col.to_uint() + 1)\n+        (format!(\"<{}:{}:{}>\",\n+                 pos.file.name,\n+                 pos.line,\n+                 pos.col.to_uint() + 1)).to_strbuf()\n     }\n \n     /// Lookup source information about a BytePos\n@@ -356,26 +360,30 @@ impl CodeMap {\n     pub fn lookup_char_pos_adj(&self, pos: BytePos) -> LocWithOpt {\n         let loc = self.lookup_char_pos(pos);\n         LocWithOpt {\n-            filename: loc.file.name.to_str(),\n+            filename: loc.file.name.to_strbuf(),\n             line: loc.line,\n             col: loc.col,\n             file: Some(loc.file)\n         }\n     }\n \n-    pub fn span_to_str(&self, sp: Span) -> ~str {\n+    pub fn span_to_str(&self, sp: Span) -> StrBuf {\n         if self.files.borrow().len() == 0 && sp == DUMMY_SP {\n-            return \"no-location\".to_owned();\n+            return \"no-location\".to_strbuf();\n         }\n \n         let lo = self.lookup_char_pos_adj(sp.lo);\n         let hi = self.lookup_char_pos_adj(sp.hi);\n-        return format!(\"{}:{}:{}: {}:{}\", lo.filename,\n-                       lo.line, lo.col.to_uint() + 1, hi.line, hi.col.to_uint() + 1)\n+        return (format!(\"{}:{}:{}: {}:{}\",\n+                        lo.filename,\n+                        lo.line,\n+                        lo.col.to_uint() + 1,\n+                        hi.line,\n+                        hi.col.to_uint() + 1)).to_strbuf()\n     }\n \n     pub fn span_to_filename(&self, sp: Span) -> FileName {\n-        self.lookup_char_pos(sp.lo).file.name.to_str()\n+        self.lookup_char_pos(sp.lo).file.name.to_strbuf()\n     }\n \n     pub fn span_to_lines(&self, sp: Span) -> FileLines {\n@@ -388,7 +396,7 @@ impl CodeMap {\n         FileLines {file: lo.file, lines: lines}\n     }\n \n-    pub fn span_to_snippet(&self, sp: Span) -> Option<~str> {\n+    pub fn span_to_snippet(&self, sp: Span) -> Option<StrBuf> {\n         let begin = self.lookup_byte_offset(sp.lo);\n         let end = self.lookup_byte_offset(sp.hi);\n \n@@ -399,13 +407,14 @@ impl CodeMap {\n         if begin.fm.start_pos != end.fm.start_pos {\n             None\n         } else {\n-            Some(begin.fm.src.slice( begin.pos.to_uint(), end.pos.to_uint()).to_owned())\n+            Some(begin.fm.src.as_slice().slice(begin.pos.to_uint(),\n+                                               end.pos.to_uint()).to_strbuf())\n         }\n     }\n \n     pub fn get_filemap(&self, filename: &str) -> Rc<FileMap> {\n         for fm in self.files.borrow().iter() {\n-            if filename == fm.name {\n+            if filename == fm.name.as_slice() {\n                 return fm.clone();\n             }\n         }\n@@ -526,19 +535,21 @@ mod test {\n     #[test]\n     fn t1 () {\n         let cm = CodeMap::new();\n-        let fm = cm.new_filemap(\"blork.rs\".to_owned(),\"first line.\\nsecond line\".to_owned());\n+        let fm = cm.new_filemap(\"blork.rs\".to_strbuf(),\n+                                \"first line.\\nsecond line\".to_strbuf());\n         fm.next_line(BytePos(0));\n-        assert_eq!(&fm.get_line(0),&\"first line.\".to_owned());\n+        assert_eq!(&fm.get_line(0),&\"first line.\".to_strbuf());\n         // TESTING BROKEN BEHAVIOR:\n         fm.next_line(BytePos(10));\n-        assert_eq!(&fm.get_line(1),&\".\".to_owned());\n+        assert_eq!(&fm.get_line(1), &\".\".to_strbuf());\n     }\n \n     #[test]\n     #[should_fail]\n     fn t2 () {\n         let cm = CodeMap::new();\n-        let fm = cm.new_filemap(\"blork.rs\".to_owned(),\"first line.\\nsecond line\".to_owned());\n+        let fm = cm.new_filemap(\"blork.rs\".to_strbuf(),\n+                                \"first line.\\nsecond line\".to_strbuf());\n         // TESTING *REALLY* BROKEN BEHAVIOR:\n         fm.next_line(BytePos(0));\n         fm.next_line(BytePos(10));\n@@ -547,9 +558,12 @@ mod test {\n \n     fn init_code_map() -> CodeMap {\n         let cm = CodeMap::new();\n-        let fm1 = cm.new_filemap(\"blork.rs\".to_owned(),\"first line.\\nsecond line\".to_owned());\n-        let fm2 = cm.new_filemap(\"empty.rs\".to_owned(),\"\".to_owned());\n-        let fm3 = cm.new_filemap(\"blork2.rs\".to_owned(),\"first line.\\nsecond line\".to_owned());\n+        let fm1 = cm.new_filemap(\"blork.rs\".to_strbuf(),\n+                                 \"first line.\\nsecond line\".to_strbuf());\n+        let fm2 = cm.new_filemap(\"empty.rs\".to_strbuf(),\n+                                 \"\".to_strbuf());\n+        let fm3 = cm.new_filemap(\"blork2.rs\".to_strbuf(),\n+                                 \"first line.\\nsecond line\".to_strbuf());\n \n         fm1.next_line(BytePos(0));\n         fm1.next_line(BytePos(12));\n@@ -566,11 +580,11 @@ mod test {\n         let cm = init_code_map();\n \n         let fmabp1 = cm.lookup_byte_offset(BytePos(22));\n-        assert_eq!(fmabp1.fm.name, \"blork.rs\".to_owned());\n+        assert_eq!(fmabp1.fm.name, \"blork.rs\".to_strbuf());\n         assert_eq!(fmabp1.pos, BytePos(22));\n \n         let fmabp2 = cm.lookup_byte_offset(BytePos(24));\n-        assert_eq!(fmabp2.fm.name, \"blork2.rs\".to_owned());\n+        assert_eq!(fmabp2.fm.name, \"blork2.rs\".to_strbuf());\n         assert_eq!(fmabp2.pos, BytePos(0));\n     }\n \n@@ -592,21 +606,24 @@ mod test {\n         let cm = init_code_map();\n \n         let loc1 = cm.lookup_char_pos(BytePos(22));\n-        assert_eq!(loc1.file.name, \"blork.rs\".to_owned());\n+        assert_eq!(loc1.file.name, \"blork.rs\".to_strbuf());\n         assert_eq!(loc1.line, 2);\n         assert_eq!(loc1.col, CharPos(10));\n \n         let loc2 = cm.lookup_char_pos(BytePos(24));\n-        assert_eq!(loc2.file.name, \"blork2.rs\".to_owned());\n+        assert_eq!(loc2.file.name, \"blork2.rs\".to_strbuf());\n         assert_eq!(loc2.line, 1);\n         assert_eq!(loc2.col, CharPos(0));\n     }\n \n     fn init_code_map_mbc() -> CodeMap {\n         let cm = CodeMap::new();\n         // \u20ac is a three byte utf8 char.\n-        let fm1 = cm.new_filemap(\"blork.rs\".to_owned(),\"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_owned());\n-        let fm2 = cm.new_filemap(\"blork2.rs\".to_owned(),\"first line\u20ac\u20ac.\\n\u20ac second line\".to_owned());\n+        let fm1 =\n+            cm.new_filemap(\"blork.rs\".to_strbuf(),\n+                           \"fir\u20acst \u20ac\u20ac\u20ac\u20ac line.\\nsecond line\".to_strbuf());\n+        let fm2 = cm.new_filemap(\"blork2.rs\".to_strbuf(),\n+                                 \"first line\u20ac\u20ac.\\n\u20ac second line\".to_strbuf());\n \n         fm1.next_line(BytePos(0));\n         fm1.next_line(BytePos(22));\n@@ -650,7 +667,7 @@ mod test {\n         let span = Span {lo: BytePos(12), hi: BytePos(23), expn_info: None};\n         let file_lines = cm.span_to_lines(span);\n \n-        assert_eq!(file_lines.file.name, \"blork.rs\".to_owned());\n+        assert_eq!(file_lines.file.name, \"blork.rs\".to_strbuf());\n         assert_eq!(file_lines.lines.len(), 1);\n         assert_eq!(*file_lines.lines.get(0), 1u);\n     }\n@@ -662,7 +679,7 @@ mod test {\n         let span = Span {lo: BytePos(12), hi: BytePos(23), expn_info: None};\n         let snippet = cm.span_to_snippet(span);\n \n-        assert_eq!(snippet, Some(\"second line\".to_owned()));\n+        assert_eq!(snippet, Some(\"second line\".to_strbuf()));\n     }\n \n     #[test]\n@@ -672,6 +689,6 @@ mod test {\n         let span = Span {lo: BytePos(12), hi: BytePos(23), expn_info: None};\n         let sstr =  cm.span_to_str(span);\n \n-        assert_eq!(sstr, \"blork.rs:2:1: 2:12\".to_owned());\n+        assert_eq!(sstr, \"blork.rs:2:1: 2:12\".to_strbuf());\n     }\n }"}, {"sha": "84ef7941b2ed7546d65a671b5bd7306e3c04fec2", "filename": "src/libsyntax/crateid.rs", "status": "modified", "additions": 35, "deletions": 34, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fcrateid.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fcrateid.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcrateid.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -24,11 +24,11 @@ use std::from_str::FromStr;\n pub struct CrateId {\n     /// A path which represents the codes origin. By convention this is the\n     /// URL, without `http://` or `https://` prefix, to the crate's repository\n-    pub path: ~str,\n+    pub path: StrBuf,\n     /// The name of the crate.\n-    pub name: ~str,\n+    pub name: StrBuf,\n     /// The version of the crate.\n-    pub version: Option<~str>,\n+    pub version: Option<StrBuf>,\n }\n \n impl fmt::Show for CrateId {\n@@ -38,7 +38,8 @@ impl fmt::Show for CrateId {\n             None => \"0.0\",\n             Some(ref version) => version.as_slice(),\n         };\n-        if self.path == self.name || self.path.ends_with(format!(\"/{}\", self.name)) {\n+        if self.path == self.name ||\n+                self.path.as_slice().ends_with(format!(\"/{}\", self.name)) {\n             write!(f.buf, \"\\\\#{}\", version)\n         } else {\n             write!(f.buf, \"\\\\#{}:{}\", self.name, version)\n@@ -60,7 +61,7 @@ impl FromStr for CrateId {\n         let inferred_name = *path_pieces.get(0);\n \n         let (name, version) = if pieces.len() == 1 {\n-            (inferred_name.to_owned(), None)\n+            (inferred_name.to_strbuf(), None)\n         } else {\n             let hash_pieces: Vec<&str> = pieces.get(1)\n                                                .splitn(':', 1)\n@@ -72,16 +73,16 @@ impl FromStr for CrateId {\n             };\n \n             let name = if !hash_name.is_empty() {\n-                hash_name.to_owned()\n+                hash_name.to_strbuf()\n             } else {\n-                inferred_name.to_owned()\n+                inferred_name.to_strbuf()\n             };\n \n             let version = if !hash_version.is_empty() {\n                 if hash_version == \"0.0\" {\n                     None\n                 } else {\n-                    Some(hash_version.to_owned())\n+                    Some(hash_version.to_strbuf())\n                 }\n             } else {\n                 None\n@@ -91,7 +92,7 @@ impl FromStr for CrateId {\n         };\n \n         Some(CrateId {\n-            path: path.clone(),\n+            path: path.to_strbuf(),\n             name: name,\n             version: version,\n         })\n@@ -106,8 +107,8 @@ impl CrateId {\n         }\n     }\n \n-    pub fn short_name_with_version(&self) -> ~str {\n-        format!(\"{}-{}\", self.name, self.version_or_default())\n+    pub fn short_name_with_version(&self) -> StrBuf {\n+        (format!(\"{}-{}\", self.name, self.version_or_default())).to_strbuf()\n     }\n \n     pub fn matches(&self, other: &CrateId) -> bool {\n@@ -123,17 +124,17 @@ impl CrateId {\n #[test]\n fn bare_name() {\n     let crateid: CrateId = from_str(\"foo\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"foo\".to_owned());\n+    assert_eq!(crateid.name, \"foo\".to_strbuf());\n     assert_eq!(crateid.version, None);\n-    assert_eq!(crateid.path, \"foo\".to_owned());\n+    assert_eq!(crateid.path, \"foo\".to_strbuf());\n }\n \n #[test]\n fn bare_name_single_char() {\n     let crateid: CrateId = from_str(\"f\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"f\".to_owned());\n+    assert_eq!(crateid.name, \"f\".to_strbuf());\n     assert_eq!(crateid.version, None);\n-    assert_eq!(crateid.path, \"f\".to_owned());\n+    assert_eq!(crateid.path, \"f\".to_strbuf());\n }\n \n #[test]\n@@ -145,17 +146,17 @@ fn empty_crateid() {\n #[test]\n fn simple_path() {\n     let crateid: CrateId = from_str(\"example.com/foo/bar\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"bar\".to_owned());\n+    assert_eq!(crateid.name, \"bar\".to_strbuf());\n     assert_eq!(crateid.version, None);\n-    assert_eq!(crateid.path, \"example.com/foo/bar\".to_owned());\n+    assert_eq!(crateid.path, \"example.com/foo/bar\".to_strbuf());\n }\n \n #[test]\n fn simple_version() {\n     let crateid: CrateId = from_str(\"foo#1.0\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"foo\".to_owned());\n-    assert_eq!(crateid.version, Some(\"1.0\".to_owned()));\n-    assert_eq!(crateid.path, \"foo\".to_owned());\n+    assert_eq!(crateid.name, \"foo\".to_strbuf());\n+    assert_eq!(crateid.version, Some(\"1.0\".to_strbuf()));\n+    assert_eq!(crateid.path, \"foo\".to_strbuf());\n }\n \n #[test]\n@@ -173,39 +174,39 @@ fn path_ends_with_slash() {\n #[test]\n fn path_and_version() {\n     let crateid: CrateId = from_str(\"example.com/foo/bar#1.0\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"bar\".to_owned());\n-    assert_eq!(crateid.version, Some(\"1.0\".to_owned()));\n-    assert_eq!(crateid.path, \"example.com/foo/bar\".to_owned());\n+    assert_eq!(crateid.name, \"bar\".to_strbuf());\n+    assert_eq!(crateid.version, Some(\"1.0\".to_strbuf()));\n+    assert_eq!(crateid.path, \"example.com/foo/bar\".to_strbuf());\n }\n \n #[test]\n fn single_chars() {\n     let crateid: CrateId = from_str(\"a/b#1\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"b\".to_owned());\n-    assert_eq!(crateid.version, Some(\"1\".to_owned()));\n-    assert_eq!(crateid.path, \"a/b\".to_owned());\n+    assert_eq!(crateid.name, \"b\".to_strbuf());\n+    assert_eq!(crateid.version, Some(\"1\".to_strbuf()));\n+    assert_eq!(crateid.path, \"a/b\".to_strbuf());\n }\n \n #[test]\n fn missing_version() {\n     let crateid: CrateId = from_str(\"foo#\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"foo\".to_owned());\n+    assert_eq!(crateid.name, \"foo\".to_strbuf());\n     assert_eq!(crateid.version, None);\n-    assert_eq!(crateid.path, \"foo\".to_owned());\n+    assert_eq!(crateid.path, \"foo\".to_strbuf());\n }\n \n #[test]\n fn path_and_name() {\n     let crateid: CrateId = from_str(\"foo/rust-bar#bar:1.0\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"bar\".to_owned());\n-    assert_eq!(crateid.version, Some(\"1.0\".to_owned()));\n-    assert_eq!(crateid.path, \"foo/rust-bar\".to_owned());\n+    assert_eq!(crateid.name, \"bar\".to_strbuf());\n+    assert_eq!(crateid.version, Some(\"1.0\".to_strbuf()));\n+    assert_eq!(crateid.path, \"foo/rust-bar\".to_strbuf());\n }\n \n #[test]\n fn empty_name() {\n     let crateid: CrateId = from_str(\"foo/bar#:1.0\").expect(\"valid crateid\");\n-    assert_eq!(crateid.name, \"bar\".to_owned());\n-    assert_eq!(crateid.version, Some(\"1.0\".to_owned()));\n-    assert_eq!(crateid.path, \"foo/bar\".to_owned());\n+    assert_eq!(crateid.name, \"bar\".to_strbuf());\n+    assert_eq!(crateid.version, Some(\"1.0\".to_strbuf()));\n+    assert_eq!(crateid.path, \"foo/bar\".to_strbuf());\n }"}, {"sha": "73027013090e72202197501c31d43db5dd7bc6b8", "filename": "src/libsyntax/diagnostic.rs", "status": "modified", "additions": 12, "deletions": 8, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fdiagnostic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fdiagnostic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostic.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -320,12 +320,12 @@ fn emit(dst: &mut EmitterWriter, cm: &codemap::CodeMap, rsp: RenderSpan,\n         // the span)\n         let span_end = Span { lo: sp.hi, hi: sp.hi, expn_info: sp.expn_info};\n         let ses = cm.span_to_str(span_end);\n-        try!(print_diagnostic(dst, ses, lvl, msg));\n+        try!(print_diagnostic(dst, ses.as_slice(), lvl, msg));\n         if rsp.is_full_span() {\n             try!(custom_highlight_lines(dst, cm, sp, lvl, lines));\n         }\n     } else {\n-        try!(print_diagnostic(dst, ss, lvl, msg));\n+        try!(print_diagnostic(dst, ss.as_slice(), lvl, msg));\n         if rsp.is_full_span() {\n             try!(highlight_lines(dst, cm, sp, lvl, lines));\n         }\n@@ -378,7 +378,7 @@ fn highlight_lines(err: &mut EmitterWriter,\n         }\n         let orig = fm.get_line(*lines.lines.get(0) as int);\n         for pos in range(0u, left-skip) {\n-            let cur_char = orig[pos] as char;\n+            let cur_char = orig.as_slice()[pos] as char;\n             // Whenever a tab occurs on the previous line, we insert one on\n             // the error-point-squiggly-line as well (instead of a space).\n             // That way the squiggly line will usually appear in the correct\n@@ -452,24 +452,28 @@ fn print_macro_backtrace(w: &mut EmitterWriter,\n                          sp: Span)\n                          -> io::IoResult<()> {\n     for ei in sp.expn_info.iter() {\n-        let ss = ei.callee.span.as_ref().map_or(\"\".to_owned(), |span| cm.span_to_str(*span));\n+        let ss = ei.callee\n+                   .span\n+                   .as_ref()\n+                   .map_or(\"\".to_strbuf(), |span| cm.span_to_str(*span));\n         let (pre, post) = match ei.callee.format {\n             codemap::MacroAttribute => (\"#[\", \"]\"),\n             codemap::MacroBang => (\"\", \"!\")\n         };\n-        try!(print_diagnostic(w, ss, Note,\n+        try!(print_diagnostic(w, ss.as_slice(), Note,\n                               format!(\"in expansion of {}{}{}\", pre,\n                                       ei.callee.name, post)));\n         let ss = cm.span_to_str(ei.call_site);\n-        try!(print_diagnostic(w, ss, Note, \"expansion site\"));\n+        try!(print_diagnostic(w, ss.as_slice(), Note, \"expansion site\"));\n         try!(print_macro_backtrace(w, cm, ei.call_site));\n     }\n     Ok(())\n }\n \n-pub fn expect<T:Clone>(diag: &SpanHandler, opt: Option<T>, msg: || -> ~str) -> T {\n+pub fn expect<T:Clone>(diag: &SpanHandler, opt: Option<T>, msg: || -> StrBuf)\n+              -> T {\n     match opt {\n        Some(ref t) => (*t).clone(),\n-       None => diag.handler().bug(msg()),\n+       None => diag.handler().bug(msg().as_slice()),\n     }\n }"}, {"sha": "f4330960acacb3e20d113b47916195231d865681", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -30,7 +30,7 @@ use collections::HashMap;\n // ast::MacInvocTT.\n \n pub struct MacroDef {\n-    pub name: ~str,\n+    pub name: StrBuf,\n     pub ext: SyntaxExtension\n }\n \n@@ -361,8 +361,8 @@ pub fn syntax_expander_table() -> SyntaxEnv {\n \n pub struct MacroCrate {\n     pub lib: Option<Path>,\n-    pub macros: Vec<~str>,\n-    pub registrar_symbol: Option<~str>,\n+    pub macros: Vec<StrBuf>,\n+    pub registrar_symbol: Option<StrBuf>,\n }\n \n pub trait CrateLoader {\n@@ -425,7 +425,7 @@ impl<'a> ExtCtxt<'a> {\n     pub fn mod_pop(&mut self) { self.mod_path.pop().unwrap(); }\n     pub fn mod_path(&self) -> Vec<ast::Ident> {\n         let mut v = Vec::new();\n-        v.push(token::str_to_ident(self.ecfg.crate_id.name));\n+        v.push(token::str_to_ident(self.ecfg.crate_id.name.as_slice()));\n         v.extend(self.mod_path.iter().map(|a| *a));\n         return v;\n     }\n@@ -540,14 +540,14 @@ pub fn get_single_str_from_tts(cx: &ExtCtxt,\n                                sp: Span,\n                                tts: &[ast::TokenTree],\n                                name: &str)\n-                               -> Option<~str> {\n+                               -> Option<StrBuf> {\n     if tts.len() != 1 {\n         cx.span_err(sp, format!(\"{} takes 1 argument.\", name));\n     } else {\n         match tts[0] {\n             ast::TTTok(_, token::LIT_STR(ident))\n             | ast::TTTok(_, token::LIT_STR_RAW(ident, _)) => {\n-                return Some(token::get_ident(ident).get().to_str())\n+                return Some(token::get_ident(ident).get().to_strbuf())\n             }\n             _ => cx.span_err(sp, format!(\"{} requires a string.\", name)),\n         }"}, {"sha": "3c7415ae0e9b9fe0a81bf116ed173ba26aae260b", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -639,7 +639,9 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n             vec!(\n                 self.expr_str(span, msg),\n                 self.expr_str(span,\n-                              token::intern_and_get_ident(loc.file.name)),\n+                              token::intern_and_get_ident(loc.file\n+                                                             .name\n+                                                             .as_slice())),\n                 self.expr_uint(span, loc.line)))\n     }\n "}, {"sha": "9c967cfb4eeaabb47d1cdf24387706c67af2ff41", "filename": "src/libsyntax/ext/deriving/generic.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -987,7 +987,7 @@ impl<'a> TraitDef<'a> {\n         to_set.expn_info = Some(@codemap::ExpnInfo {\n             call_site: to_set,\n             callee: codemap::NameAndSpan {\n-                name: format!(\"deriving({})\", trait_name),\n+                name: format!(\"deriving({})\", trait_name).to_strbuf(),\n                 format: codemap::MacroAttribute,\n                 span: Some(self.span)\n             }"}, {"sha": "8dbfbc53cecf73b4bbdfd86598b74207dd798adc", "filename": "src/libsyntax/ext/env.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fenv.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -30,7 +30,7 @@ pub fn expand_option_env(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n         Some(v) => v\n     };\n \n-    let e = match os::getenv(var) {\n+    let e = match os::getenv(var.as_slice()) {\n       None => {\n           cx.expr_path(cx.path_all(sp,\n                                    true,"}, {"sha": "0f3b96c2132b6ce65b85081f119d4d435ede885f", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 28, "deletions": 24, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -71,7 +71,7 @@ pub fn expand_expr(e: @ast::Expr, fld: &mut MacroExpander) -> @ast::Expr {\n                             fld.cx.bt_push(ExpnInfo {\n                                 call_site: e.span,\n                                 callee: NameAndSpan {\n-                                    name: extnamestr.get().to_str(),\n+                                    name: extnamestr.get().to_strbuf(),\n                                     format: MacroBang,\n                                     span: exp_span,\n                                 },\n@@ -270,7 +270,7 @@ pub fn expand_item(it: @ast::Item, fld: &mut MacroExpander)\n                 fld.cx.bt_push(ExpnInfo {\n                     call_site: attr.span,\n                     callee: NameAndSpan {\n-                        name: mname.get().to_str(),\n+                        name: mname.get().to_strbuf(),\n                         format: MacroAttribute,\n                         span: None\n                     }\n@@ -334,7 +334,7 @@ fn expand_item_modifiers(mut it: @ast::Item, fld: &mut MacroExpander)\n                 fld.cx.bt_push(ExpnInfo {\n                     call_site: attr.span,\n                     callee: NameAndSpan {\n-                        name: mname.get().to_str(),\n+                        name: mname.get().to_strbuf(),\n                         format: MacroAttribute,\n                         span: None,\n                     }\n@@ -393,7 +393,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n             fld.cx.bt_push(ExpnInfo {\n                 call_site: it.span,\n                 callee: NameAndSpan {\n-                    name: extnamestr.get().to_str(),\n+                    name: extnamestr.get().to_strbuf(),\n                     format: MacroBang,\n                     span: span\n                 }\n@@ -412,7 +412,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n             fld.cx.bt_push(ExpnInfo {\n                 call_site: it.span,\n                 callee: NameAndSpan {\n-                    name: extnamestr.get().to_str(),\n+                    name: extnamestr.get().to_strbuf(),\n                     format: MacroBang,\n                     span: span\n                 }\n@@ -433,7 +433,7 @@ pub fn expand_item_mac(it: @ast::Item, fld: &mut MacroExpander)\n         Some(MacroDef { name, ext }) => {\n             // yikes... no idea how to apply the mark to this. I'm afraid\n             // we're going to have to wait-and-see on this one.\n-            fld.extsbox.insert(intern(name), ext);\n+            fld.extsbox.insert(intern(name.as_slice()), ext);\n             if attr::contains_name(it.attrs.as_slice(), \"macro_export\") {\n                 SmallVector::one(it)\n             } else {\n@@ -493,6 +493,7 @@ fn load_extern_macros(krate: &ast::ViewItem, fld: &mut MacroExpander) {\n         _ => unreachable!()\n     };\n     let name = format!(\"<{} macros>\", token::get_ident(crate_name));\n+    let name = name.to_strbuf();\n \n     for source in macros.iter() {\n         let item = parse::parse_item_from_source_str(name.clone(),\n@@ -524,11 +525,12 @@ fn load_extern_macros(krate: &ast::ViewItem, fld: &mut MacroExpander) {\n     };\n \n     unsafe {\n-        let registrar: MacroCrateRegistrationFun = match lib.symbol(registrar) {\n-            Ok(registrar) => registrar,\n-            // again fatal if we can't register macros\n-            Err(err) => fld.cx.span_fatal(krate.span, err)\n-        };\n+        let registrar: MacroCrateRegistrationFun =\n+            match lib.symbol(registrar.as_slice()) {\n+                Ok(registrar) => registrar,\n+                // again fatal if we can't register macros\n+                Err(err) => fld.cx.span_fatal(krate.span, err)\n+            };\n         registrar(|name, extension| {\n             let extension = match extension {\n                 NormalTT(ext, _) => NormalTT(ext, Some(krate.span)),\n@@ -576,7 +578,7 @@ pub fn expand_stmt(s: &Stmt, fld: &mut MacroExpander) -> SmallVector<@Stmt> {\n             fld.cx.bt_push(ExpnInfo {\n                 call_site: s.span,\n                 callee: NameAndSpan {\n-                    name: extnamestr.get().to_str(),\n+                    name: extnamestr.get().to_strbuf(),\n                     format: MacroBang,\n                     span: exp_span,\n                 }\n@@ -1020,10 +1022,10 @@ mod test {\n     #[should_fail]\n     #[test] fn macros_cant_escape_fns_test () {\n         let src = \"fn bogus() {macro_rules! z (() => (3+4))}\\\n-                   fn inty() -> int { z!() }\".to_owned();\n+                   fn inty() -> int { z!() }\".to_strbuf();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n-            \"<test>\".to_owned(),\n+            \"<test>\".to_strbuf(),\n             src,\n             Vec::new(), &sess);\n         // should fail:\n@@ -1040,10 +1042,10 @@ mod test {\n     #[should_fail]\n     #[test] fn macros_cant_escape_mods_test () {\n         let src = \"mod foo {macro_rules! z (() => (3+4))}\\\n-                   fn inty() -> int { z!() }\".to_owned();\n+                   fn inty() -> int { z!() }\".to_strbuf();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n-            \"<test>\".to_owned(),\n+            \"<test>\".to_strbuf(),\n             src,\n             Vec::new(), &sess);\n         // should fail:\n@@ -1059,10 +1061,10 @@ mod test {\n     // macro_escape modules shouldn't cause macros to leave scope\n     #[test] fn macros_can_escape_flattened_mods_test () {\n         let src = \"#[macro_escape] mod foo {macro_rules! z (() => (3+4))}\\\n-                   fn inty() -> int { z!() }\".to_owned();\n+                   fn inty() -> int { z!() }\".to_strbuf();\n         let sess = parse::new_parse_sess();\n         let crate_ast = parse::parse_crate_from_source_str(\n-            \"<test>\".to_owned(),\n+            \"<test>\".to_strbuf(),\n             src,\n             Vec::new(), &sess);\n         // should fail:\n@@ -1100,7 +1102,7 @@ mod test {\n         }\n     }\n \n-    fn expand_crate_str(crate_str: ~str) -> ast::Crate {\n+    fn expand_crate_str(crate_str: StrBuf) -> ast::Crate {\n         let ps = parse::new_parse_sess();\n         let crate_ast = string_to_parser(&ps, crate_str).parse_crate_mod();\n         // the cfg argument actually does matter, here...\n@@ -1118,13 +1120,14 @@ mod test {\n         // println!(\"expanded: {:?}\\n\",expanded_ast);\n         //mtwt_resolve_crate(expanded_ast)\n     //}\n-    //fn expand_and_resolve_and_pretty_print (crate_str: @str) -> ~str {\n+    //fn expand_and_resolve_and_pretty_print (crate_str: @str) -> StrBuf {\n         //let resolved_ast = expand_and_resolve(crate_str);\n         //pprust::to_str(&resolved_ast,fake_print_crate,get_ident_interner())\n     //}\n \n     #[test] fn macro_tokens_should_match(){\n-        expand_crate_str(\"macro_rules! m((a)=>(13)) fn main(){m!(a);}\".to_owned());\n+        expand_crate_str(\n+            \"macro_rules! m((a)=>(13)) fn main(){m!(a);}\".to_strbuf());\n     }\n \n     // renaming tests expand a crate and then check that the bindings match\n@@ -1182,7 +1185,7 @@ mod test {\n         let (teststr, bound_connections, bound_ident_check) = match *t {\n             (ref str,ref conns, bic) => (str.to_owned(), conns.clone(), bic)\n         };\n-        let cr = expand_crate_str(teststr.to_owned());\n+        let cr = expand_crate_str(teststr.to_strbuf());\n         // find the bindings:\n         let mut name_finder = new_name_finder(Vec::new());\n         visit::walk_crate(&mut name_finder,&cr,());\n@@ -1257,7 +1260,7 @@ mod test {\n         let crate_str = \"macro_rules! fmt_wrap(($b:expr)=>($b.to_str()))\n macro_rules! foo_module (() => (mod generated { fn a() { let xx = 147; fmt_wrap!(xx);}}))\n foo_module!()\n-\".to_owned();\n+\".to_strbuf();\n         let cr = expand_crate_str(crate_str);\n         // find the xx binding\n         let mut name_finder = new_name_finder(Vec::new());\n@@ -1303,7 +1306,8 @@ foo_module!()\n \n     #[test]\n     fn pat_idents(){\n-        let pat = string_to_pat(\"(a,Foo{x:c @ (b,9),y:Bar(4,d)})\".to_owned());\n+        let pat = string_to_pat(\n+            \"(a,Foo{x:c @ (b,9),y:Bar(4,d)})\".to_strbuf());\n         let mut pat_idents = new_name_finder(Vec::new());\n         pat_idents.visit_pat(pat, ());\n         assert_eq!(pat_idents.ident_accumulator,"}, {"sha": "79f49b908d1373f993f8e2c626e4aecf8c4b95f5", "filename": "src/libsyntax/ext/format.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fformat.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -23,14 +23,14 @@ use collections::{HashMap, HashSet};\n \n #[deriving(Eq)]\n enum ArgumentType {\n-    Known(~str),\n+    Known(StrBuf),\n     Unsigned,\n     String,\n }\n \n enum Position {\n     Exact(uint),\n-    Named(~str),\n+    Named(StrBuf),\n }\n \n struct Context<'a, 'b> {\n@@ -45,13 +45,13 @@ struct Context<'a, 'b> {\n     // Note that we keep a side-array of the ordering of the named arguments\n     // found to be sure that we can translate them in the same order that they\n     // were declared in.\n-    names: HashMap<~str, @ast::Expr>,\n-    name_types: HashMap<~str, ArgumentType>,\n-    name_ordering: Vec<~str>,\n+    names: HashMap<StrBuf, @ast::Expr>,\n+    name_types: HashMap<StrBuf, ArgumentType>,\n+    name_ordering: Vec<StrBuf>,\n \n     // Collection of the compiled `rt::Piece` structures\n     pieces: Vec<@ast::Expr> ,\n-    name_positions: HashMap<~str, uint>,\n+    name_positions: HashMap<StrBuf, uint>,\n     method_statics: Vec<@ast::Item> ,\n \n     // Updated as arguments are consumed or methods are entered\n@@ -68,10 +68,10 @@ struct Context<'a, 'b> {\n ///     Some((fmtstr, unnamed arguments, ordering of named arguments,\n ///           named arguments))\n fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n-    -> (@ast::Expr, Option<(@ast::Expr, Vec<@ast::Expr>, Vec<~str>,\n-                            HashMap<~str, @ast::Expr>)>) {\n+    -> (@ast::Expr, Option<(@ast::Expr, Vec<@ast::Expr>, Vec<StrBuf>,\n+                            HashMap<StrBuf, @ast::Expr>)>) {\n     let mut args = Vec::new();\n-    let mut names = HashMap::<~str, @ast::Expr>::new();\n+    let mut names = HashMap::<StrBuf, @ast::Expr>::new();\n     let mut order = Vec::new();\n \n     let mut p = rsparse::new_parser_from_tts(ecx.parse_sess(),\n@@ -131,8 +131,8 @@ fn parse_args(ecx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                     continue\n                 }\n             }\n-            order.push(name.to_str());\n-            names.insert(name.to_str(), e);\n+            order.push(name.to_strbuf());\n+            names.insert(name.to_strbuf(), e);\n         } else {\n             args.push(p.parse_expr());\n         }\n@@ -171,13 +171,13 @@ impl<'a, 'b> Context<'a, 'b> {\n                         Exact(i)\n                     }\n                     parse::ArgumentIs(i) => Exact(i),\n-                    parse::ArgumentNamed(s) => Named(s.to_str()),\n+                    parse::ArgumentNamed(s) => Named(s.to_strbuf()),\n                 };\n \n                 // and finally the method being applied\n                 match arg.method {\n                     None => {\n-                        let ty = Known(arg.format.ty.to_str());\n+                        let ty = Known(arg.format.ty.to_strbuf());\n                         self.verify_arg_type(pos, ty);\n                     }\n                     Some(ref method) => { self.verify_method(pos, *method); }\n@@ -199,7 +199,7 @@ impl<'a, 'b> Context<'a, 'b> {\n                 self.verify_arg_type(Exact(i), Unsigned);\n             }\n             parse::CountIsName(s) => {\n-                self.verify_arg_type(Named(s.to_str()), Unsigned);\n+                self.verify_arg_type(Named(s.to_strbuf()), Unsigned);\n             }\n             parse::CountIsNextParam => {\n                 if self.check_positional_ok() {\n@@ -822,8 +822,8 @@ pub fn expand_args(ecx: &mut ExtCtxt, sp: Span,\n pub fn expand_preparsed_format_args(ecx: &mut ExtCtxt, sp: Span,\n                                     extra: @ast::Expr,\n                                     efmt: @ast::Expr, args: Vec<@ast::Expr>,\n-                                    name_ordering: Vec<~str>,\n-                                    names: HashMap<~str, @ast::Expr>) -> @ast::Expr {\n+                                    name_ordering: Vec<StrBuf>,\n+                                    names: HashMap<StrBuf, @ast::Expr>) -> @ast::Expr {\n     let arg_types = Vec::from_fn(args.len(), |_| None);\n     let mut cx = Context {\n         ecx: ecx,"}, {"sha": "b3eec136c7d696e87ceca81f992e772408fd339e", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 55, "deletions": 47, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -55,7 +55,7 @@ pub mod rt {\n \n     trait ToSource : ToTokens {\n         // Takes a thing and generates a string containing rust code for it.\n-        pub fn to_source() -> ~str;\n+        pub fn to_source() -> StrBuf;\n \n         // If you can make source, you can definitely make tokens.\n         pub fn to_tokens(cx: &ExtCtxt) -> ~[TokenTree] {\n@@ -67,151 +67,159 @@ pub mod rt {\n \n     pub trait ToSource {\n         // Takes a thing and generates a string containing rust code for it.\n-        fn to_source(&self) -> ~str;\n+        fn to_source(&self) -> StrBuf;\n     }\n \n     impl ToSource for ast::Ident {\n-        fn to_source(&self) -> ~str {\n-            get_ident(*self).get().to_str()\n+        fn to_source(&self) -> StrBuf {\n+            get_ident(*self).get().to_strbuf()\n         }\n     }\n \n     impl ToSource for @ast::Item {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             pprust::item_to_str(*self)\n         }\n     }\n \n     impl<'a> ToSource for &'a [@ast::Item] {\n-        fn to_source(&self) -> ~str {\n-            self.iter().map(|i| i.to_source()).collect::<Vec<~str>>().connect(\"\\n\\n\")\n+        fn to_source(&self) -> StrBuf {\n+            self.iter()\n+                .map(|i| i.to_source())\n+                .collect::<Vec<StrBuf>>()\n+                .connect(\"\\n\\n\")\n+                .to_strbuf()\n         }\n     }\n \n     impl ToSource for ast::Ty {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             pprust::ty_to_str(self)\n         }\n     }\n \n     impl<'a> ToSource for &'a [ast::Ty] {\n-        fn to_source(&self) -> ~str {\n-            self.iter().map(|i| i.to_source()).collect::<Vec<~str>>().connect(\", \")\n+        fn to_source(&self) -> StrBuf {\n+            self.iter()\n+                .map(|i| i.to_source())\n+                .collect::<Vec<StrBuf>>()\n+                .connect(\", \")\n+                .to_strbuf()\n         }\n     }\n \n     impl ToSource for Generics {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             pprust::generics_to_str(self)\n         }\n     }\n \n     impl ToSource for @ast::Expr {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             pprust::expr_to_str(*self)\n         }\n     }\n \n     impl ToSource for ast::Block {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             pprust::block_to_str(self)\n         }\n     }\n \n     impl<'a> ToSource for &'a str {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitStr(\n                     token::intern_and_get_ident(*self), ast::CookedStr));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for () {\n-        fn to_source(&self) -> ~str {\n-            \"()\".to_owned()\n+        fn to_source(&self) -> StrBuf {\n+            \"()\".to_strbuf()\n         }\n     }\n \n     impl ToSource for bool {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitBool(*self));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for char {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitChar(*self));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for int {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitInt(*self as i64, ast::TyI));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for i8 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitInt(*self as i64, ast::TyI8));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for i16 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitInt(*self as i64, ast::TyI16));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n \n     impl ToSource for i32 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitInt(*self as i64, ast::TyI32));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for i64 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitInt(*self as i64, ast::TyI64));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for uint {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitUint(*self as u64, ast::TyU));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for u8 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitUint(*self as u64, ast::TyU8));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for u16 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitUint(*self as u64, ast::TyU16));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for u32 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitUint(*self as u64, ast::TyU32));\n             pprust::lit_to_str(&lit)\n         }\n     }\n \n     impl ToSource for u64 {\n-        fn to_source(&self) -> ~str {\n+        fn to_source(&self) -> StrBuf {\n             let lit = dummy_spanned(ast::LitUint(*self as u64, ast::TyU64));\n             pprust::lit_to_str(&lit)\n         }\n@@ -263,17 +271,17 @@ pub mod rt {\n     impl_to_tokens!(u64)\n \n     pub trait ExtParseUtils {\n-        fn parse_item(&self, s: ~str) -> @ast::Item;\n-        fn parse_expr(&self, s: ~str) -> @ast::Expr;\n-        fn parse_stmt(&self, s: ~str) -> @ast::Stmt;\n-        fn parse_tts(&self, s: ~str) -> Vec<ast::TokenTree> ;\n+        fn parse_item(&self, s: StrBuf) -> @ast::Item;\n+        fn parse_expr(&self, s: StrBuf) -> @ast::Expr;\n+        fn parse_stmt(&self, s: StrBuf) -> @ast::Stmt;\n+        fn parse_tts(&self, s: StrBuf) -> Vec<ast::TokenTree> ;\n     }\n \n     impl<'a> ExtParseUtils for ExtCtxt<'a> {\n \n-        fn parse_item(&self, s: ~str) -> @ast::Item {\n+        fn parse_item(&self, s: StrBuf) -> @ast::Item {\n             let res = parse::parse_item_from_source_str(\n-                \"<quote expansion>\".to_str(),\n+                \"<quote expansion>\".to_strbuf(),\n                 s,\n                 self.cfg(),\n                 self.parse_sess());\n@@ -286,23 +294,23 @@ pub mod rt {\n             }\n         }\n \n-        fn parse_stmt(&self, s: ~str) -> @ast::Stmt {\n-            parse::parse_stmt_from_source_str(\"<quote expansion>\".to_str(),\n+        fn parse_stmt(&self, s: StrBuf) -> @ast::Stmt {\n+            parse::parse_stmt_from_source_str(\"<quote expansion>\".to_strbuf(),\n                                               s,\n                                               self.cfg(),\n                                               Vec::new(),\n                                               self.parse_sess())\n         }\n \n-        fn parse_expr(&self, s: ~str) -> @ast::Expr {\n-            parse::parse_expr_from_source_str(\"<quote expansion>\".to_str(),\n+        fn parse_expr(&self, s: StrBuf) -> @ast::Expr {\n+            parse::parse_expr_from_source_str(\"<quote expansion>\".to_strbuf(),\n                                               s,\n                                               self.cfg(),\n                                               self.parse_sess())\n         }\n \n-        fn parse_tts(&self, s: ~str) -> Vec<ast::TokenTree> {\n-            parse::parse_tts_from_source_str(\"<quote expansion>\".to_str(),\n+        fn parse_tts(&self, s: StrBuf) -> Vec<ast::TokenTree> {\n+            parse::parse_tts_from_source_str(\"<quote expansion>\".to_strbuf(),\n                                              s,\n                                              self.cfg(),\n                                              self.parse_sess())\n@@ -367,8 +375,8 @@ pub fn expand_quote_stmt(cx: &mut ExtCtxt,\n     base::MacExpr::new(expanded)\n }\n \n-fn ids_ext(strs: Vec<~str> ) -> Vec<ast::Ident> {\n-    strs.iter().map(|str| str_to_ident(*str)).collect()\n+fn ids_ext(strs: Vec<StrBuf> ) -> Vec<ast::Ident> {\n+    strs.iter().map(|str| str_to_ident((*str).as_slice())).collect()\n }\n \n fn id_ext(str: &str) -> ast::Ident {\n@@ -678,11 +686,11 @@ fn expand_wrapper(cx: &ExtCtxt,\n                   sp: Span,\n                   cx_expr: @ast::Expr,\n                   expr: @ast::Expr) -> @ast::Expr {\n-    let uses = vec!( cx.view_use_glob(sp, ast::Inherited,\n-                                   ids_ext(vec!(\"syntax\".to_owned(),\n-                                             \"ext\".to_owned(),\n-                                             \"quote\".to_owned(),\n-                                             \"rt\".to_owned()))) );\n+    let uses = vec![ cx.view_use_glob(sp, ast::Inherited,\n+                                   ids_ext(vec![\"syntax\".to_strbuf(),\n+                                                \"ext\".to_strbuf(),\n+                                                \"quote\".to_strbuf(),\n+                                                \"rt\".to_strbuf()])) ];\n \n     let stmt_let_ext_cx = cx.stmt_let(sp, false, id_ext(\"ext_cx\"), cx_expr);\n "}, {"sha": "6e7e72bd2e843145d8a9992893591e5a28e905b6", "filename": "src/libsyntax/ext/source_util.rs", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fsource_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Fsource_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fsource_util.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -57,23 +57,24 @@ pub fn expand_file(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n \n     let topmost = topmost_expn_info(cx.backtrace().unwrap());\n     let loc = cx.codemap().lookup_char_pos(topmost.call_site.lo);\n-    let filename = token::intern_and_get_ident(loc.file.name);\n+    let filename = token::intern_and_get_ident(loc.file.name.as_slice());\n     base::MacExpr::new(cx.expr_str(topmost.call_site, filename))\n }\n \n pub fn expand_stringify(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                         -> Box<base::MacResult> {\n     let s = pprust::tts_to_str(tts);\n-    base::MacExpr::new(cx.expr_str(sp, token::intern_and_get_ident(s)))\n+    base::MacExpr::new(cx.expr_str(sp,\n+                                   token::intern_and_get_ident(s.as_slice())))\n }\n \n pub fn expand_mod(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n                   -> Box<base::MacResult> {\n     base::check_zero_tts(cx, sp, tts, \"module_path!\");\n     let string = cx.mod_path()\n                    .iter()\n-                   .map(|x| token::get_ident(*x).get().to_str())\n-                   .collect::<Vec<~str>>()\n+                   .map(|x| token::get_ident(*x).get().to_strbuf())\n+                   .collect::<Vec<StrBuf>>()\n                    .connect(\"::\");\n     base::MacExpr::new(cx.expr_str(sp, token::intern_and_get_ident(string)))\n }\n@@ -117,9 +118,9 @@ pub fn expand_include_str(cx: &mut ExtCtxt, sp: Span, tts: &[ast::TokenTree])\n         Some(src) => {\n             // Add this input file to the code map to make it available as\n             // dependency information\n-            let filename = file.display().to_str();\n+            let filename = file.display().to_str().to_strbuf();\n             let interned = token::intern_and_get_ident(src);\n-            cx.codemap().new_filemap(filename, src.to_owned());\n+            cx.codemap().new_filemap(filename, src.to_strbuf());\n \n             base::MacExpr::new(cx.expr_str(sp, interned))\n         }\n@@ -161,7 +162,7 @@ fn topmost_expn_info(expn_info: @codemap::ExpnInfo) -> @codemap::ExpnInfo {\n                             ..\n                         } => {\n                             // Don't recurse into file using \"include!\"\n-                            if \"include\" == *name  {\n+                            if \"include\" == name.as_slice() {\n                                 expn_info\n                             } else {\n                                 topmost_expn_info(next_expn_info)"}, {"sha": "89e8d48425f6cc6ebfbd88c0120acff487c3b2de", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 17, "deletions": 12, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -201,8 +201,8 @@ pub fn nameize(p_s: &ParseSess, ms: &[Matcher], res: &[Rc<NamedMatch>])\n \n pub enum ParseResult {\n     Success(HashMap<Ident, Rc<NamedMatch>>),\n-    Failure(codemap::Span, ~str),\n-    Error(codemap::Span, ~str)\n+    Failure(codemap::Span, StrBuf),\n+    Error(codemap::Span, StrBuf)\n }\n \n pub fn parse_or_else(sess: &ParseSess,\n@@ -212,8 +212,12 @@ pub fn parse_or_else(sess: &ParseSess,\n                      -> HashMap<Ident, Rc<NamedMatch>> {\n     match parse(sess, cfg, rdr, ms.as_slice()) {\n         Success(m) => m,\n-        Failure(sp, str) => sess.span_diagnostic.span_fatal(sp, str),\n-        Error(sp, str) => sess.span_diagnostic.span_fatal(sp, str)\n+        Failure(sp, str) => {\n+            sess.span_diagnostic.span_fatal(sp, str.as_slice())\n+        }\n+        Error(sp, str) => {\n+            sess.span_diagnostic.span_fatal(sp, str.as_slice())\n+        }\n     }\n }\n \n@@ -366,29 +370,29 @@ pub fn parse(sess: &ParseSess,\n                 }\n                 return Success(nameize(sess, ms, v.as_slice()));\n             } else if eof_eis.len() > 1u {\n-                return Error(sp, \"ambiguity: multiple successful parses\".to_owned());\n+                return Error(sp, \"ambiguity: multiple successful parses\".to_strbuf());\n             } else {\n-                return Failure(sp, \"unexpected end of macro invocation\".to_owned());\n+                return Failure(sp, \"unexpected end of macro invocation\".to_strbuf());\n             }\n         } else {\n             if (bb_eis.len() > 0u && next_eis.len() > 0u)\n                 || bb_eis.len() > 1u {\n                 let nts = bb_eis.iter().map(|ei| {\n                     match ei.elts.get(ei.idx).node {\n                       MatchNonterminal(bind, name, _) => {\n-                        format!(\"{} ('{}')\",\n+                        (format!(\"{} ('{}')\",\n                                 token::get_ident(name),\n-                                token::get_ident(bind))\n+                                token::get_ident(bind))).to_strbuf()\n                       }\n                       _ => fail!()\n-                    } }).collect::<Vec<~str>>().connect(\" or \");\n+                    } }).collect::<Vec<StrBuf>>().connect(\" or \");\n                 return Error(sp, format!(\n                     \"local ambiguity: multiple parsing options: \\\n                      built-in NTs {} or {} other options.\",\n-                    nts, next_eis.len()));\n+                    nts, next_eis.len()).to_strbuf());\n             } else if bb_eis.len() == 0u && next_eis.len() == 0u {\n                 return Failure(sp, format!(\"no rules expected the token `{}`\",\n-                            token::to_str(&tok)));\n+                            token::to_str(&tok)).to_strbuf());\n             } else if next_eis.len() > 0u {\n                 /* Now process the next token */\n                 while next_eis.len() > 0u {\n@@ -436,7 +440,8 @@ pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n         token::IDENT(sn,b) => { p.bump(); token::NtIdent(box sn,b) }\n         _ => {\n             let token_str = token::to_str(&p.token);\n-            p.fatal(\"expected ident, found \".to_owned() + token_str)\n+            p.fatal((format!(\"expected ident, found {}\",\n+                             token_str.as_slice())).as_slice())\n         }\n       },\n       \"path\" => {"}, {"sha": "7ff690582d6800f0030c9b048a20b755736152e8", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -132,7 +132,7 @@ fn generic_extension(cx: &ExtCtxt,\n \n     // Which arm's failure should we report? (the one furthest along)\n     let mut best_fail_spot = DUMMY_SP;\n-    let mut best_fail_msg = \"internal error: ran no matchers\".to_owned();\n+    let mut best_fail_msg = \"internal error: ran no matchers\".to_strbuf();\n \n     for (i, lhs) in lhses.iter().enumerate() { // try each arm's matchers\n         match **lhs {\n@@ -177,13 +177,13 @@ fn generic_extension(cx: &ExtCtxt,\n                 best_fail_spot = sp;\n                 best_fail_msg = (*msg).clone();\n               },\n-              Error(sp, ref msg) => cx.span_fatal(sp, (*msg))\n+              Error(sp, ref msg) => cx.span_fatal(sp, msg.as_slice())\n             }\n           }\n           _ => cx.bug(\"non-matcher found in parsed lhses\")\n         }\n     }\n-    cx.span_fatal(best_fail_spot, best_fail_msg);\n+    cx.span_fatal(best_fail_spot, best_fail_msg.as_slice());\n }\n \n // this procedure performs the expansion of the\n@@ -247,7 +247,7 @@ pub fn add_new_extension(cx: &mut ExtCtxt,\n \n     box MacroRulesDefiner {\n         def: RefCell::new(Some(MacroDef {\n-            name: token::get_ident(name).to_str(),\n+            name: token::get_ident(name).to_str().to_strbuf(),\n             ext: NormalTT(exp, Some(sp))\n         }))\n     } as Box<MacResult>"}, {"sha": "1f264e73d4aa3eb3934b2dcb54d2131c52bbb837", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -100,7 +100,7 @@ fn lookup_cur_matched(r: &TtReader, name: Ident) -> Rc<NamedMatch> {\n enum LockstepIterSize {\n     LisUnconstrained,\n     LisConstraint(uint, Ident),\n-    LisContradiction(~str),\n+    LisContradiction(StrBuf),\n }\n \n fn lis_merge(lhs: LockstepIterSize, rhs: LockstepIterSize) -> LockstepIterSize {\n@@ -116,7 +116,7 @@ fn lis_merge(lhs: LockstepIterSize, rhs: LockstepIterSize) -> LockstepIterSize {\n                 let r_n = token::get_ident(r_id);\n                 LisContradiction(format!(\"inconsistent lockstep iteration: \\\n                                           '{}' has {} items, but '{}' has {}\",\n-                                          l_n, l_len, r_n, r_len))\n+                                          l_n, l_len, r_n, r_len).to_strbuf())\n             }\n         }\n     }\n@@ -223,7 +223,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                         }\n                         LisContradiction(ref msg) => {\n                             // FIXME #2887 blame macro invoker instead\n-                            r.sp_diag.span_fatal(sp.clone(), *msg);\n+                            r.sp_diag.span_fatal(sp.clone(), msg.as_slice());\n                         }\n                     LisConstraint(len, _) => {\n                         if len == 0 {"}, {"sha": "10df264676e335f6919a423c48989b7da6d38578", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 13, "deletions": 11, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -949,7 +949,7 @@ mod test {\n                 let pred_val = $pred;\n                 let a_val = $a;\n                 let b_val = $b;\n-                if !(pred_val(a_val,b_val)) {\n+                if !(pred_val(a_val.as_slice(),b_val.as_slice())) {\n                     fail!(\"expected args satisfying {}, got {:?} and {:?}\",\n                           $predname, a_val, b_val);\n                 }\n@@ -961,24 +961,26 @@ mod test {\n     #[test] fn ident_transformation () {\n         let mut zz_fold = ToZzIdentFolder;\n         let ast = string_to_crate(\n-            \"#[a] mod b {fn c (d : e, f : g) {h!(i,j,k);l;m}}\".to_owned());\n+            \"#[a] mod b {fn c (d : e, f : g) {h!(i,j,k);l;m}}\".to_strbuf());\n         let folded_crate = zz_fold.fold_crate(ast);\n-        assert_pred!(matches_codepattern,\n-                     \"matches_codepattern\",\n-                     pprust::to_str(|s| fake_print_crate(s, &folded_crate)),\n-                     \"#[a]mod zz{fn zz(zz:zz,zz:zz){zz!(zz,zz,zz);zz;zz}}\".to_owned());\n+        assert_pred!(\n+            matches_codepattern,\n+            \"matches_codepattern\",\n+            pprust::to_str(|s| fake_print_crate(s, &folded_crate)),\n+            \"#[a]mod zz{fn zz(zz:zz,zz:zz){zz!(zz,zz,zz);zz;zz}}\".to_strbuf());\n     }\n \n     // even inside macro defs....\n     #[test] fn ident_transformation_in_defs () {\n         let mut zz_fold = ToZzIdentFolder;\n         let ast = string_to_crate(\n             \"macro_rules! a {(b $c:expr $(d $e:token)f+ => \\\n-             (g $(d $d $e)+))} \".to_owned());\n+             (g $(d $d $e)+))} \".to_strbuf());\n         let folded_crate = zz_fold.fold_crate(ast);\n-        assert_pred!(matches_codepattern,\n-                     \"matches_codepattern\",\n-                     pprust::to_str(|s| fake_print_crate(s, &folded_crate)),\n-                     \"zz!zz((zz$zz:zz$(zz $zz:zz)zz+=>(zz$(zz$zz$zz)+)))\".to_owned());\n+        assert_pred!(\n+            matches_codepattern,\n+            \"matches_codepattern\",\n+            pprust::to_str(|s| fake_print_crate(s, &folded_crate)),\n+            \"zz!zz((zz$zz:zz$(zz $zz:zz)zz+=>(zz$(zz$zz$zz)+)))\".to_strbuf());\n     }\n }"}, {"sha": "5fc214109c256555cbe92647cb5d0427e6e082f9", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 58, "deletions": 46, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -33,7 +33,7 @@ pub enum CommentStyle {\n #[deriving(Clone)]\n pub struct Comment {\n     pub style: CommentStyle,\n-    pub lines: Vec<~str>,\n+    pub lines: Vec<StrBuf>,\n     pub pos: BytePos,\n }\n \n@@ -53,35 +53,40 @@ pub fn doc_comment_style(comment: &str) -> ast::AttrStyle {\n     }\n }\n \n-pub fn strip_doc_comment_decoration(comment: &str) -> ~str {\n+pub fn strip_doc_comment_decoration(comment: &str) -> StrBuf {\n     /// remove whitespace-only lines from the start/end of lines\n-    fn vertical_trim(lines: Vec<~str> ) -> Vec<~str> {\n+    fn vertical_trim(lines: Vec<StrBuf> ) -> Vec<StrBuf> {\n         let mut i = 0u;\n         let mut j = lines.len();\n         // first line of all-stars should be omitted\n-        if lines.len() > 0 && lines.get(0).chars().all(|c| c == '*') {\n+        if lines.len() > 0 &&\n+                lines.get(0).as_slice().chars().all(|c| c == '*') {\n             i += 1;\n         }\n-        while i < j && lines.get(i).trim().is_empty() {\n+        while i < j && lines.get(i).as_slice().trim().is_empty() {\n             i += 1;\n         }\n         // like the first, a last line of all stars should be omitted\n-        if j > i && lines.get(j - 1).chars().skip(1).all(|c| c == '*') {\n+        if j > i && lines.get(j - 1)\n+                         .as_slice()\n+                         .chars()\n+                         .skip(1)\n+                         .all(|c| c == '*') {\n             j -= 1;\n         }\n-        while j > i && lines.get(j - 1).trim().is_empty() {\n+        while j > i && lines.get(j - 1).as_slice().trim().is_empty() {\n             j -= 1;\n         }\n         return lines.slice(i, j).iter().map(|x| (*x).clone()).collect();\n     }\n \n     /// remove a \"[ \\t]*\\*\" block from each line, if possible\n-    fn horizontal_trim(lines: Vec<~str> ) -> Vec<~str> {\n+    fn horizontal_trim(lines: Vec<StrBuf> ) -> Vec<StrBuf> {\n         let mut i = uint::MAX;\n         let mut can_trim = true;\n         let mut first = true;\n         for line in lines.iter() {\n-            for (j, c) in line.chars().enumerate() {\n+            for (j, c) in line.as_slice().chars().enumerate() {\n                 if j > i || !\"* \\t\".contains_char(c) {\n                     can_trim = false;\n                     break;\n@@ -105,7 +110,9 @@ pub fn strip_doc_comment_decoration(comment: &str) -> ~str {\n         }\n \n         if can_trim {\n-            lines.iter().map(|line| line.slice(i + 1, line.len()).to_owned()).collect()\n+            lines.iter().map(|line| {\n+                line.as_slice().slice(i + 1, line.len()).to_strbuf()\n+            }).collect()\n         } else {\n             lines\n         }\n@@ -115,39 +122,41 @@ pub fn strip_doc_comment_decoration(comment: &str) -> ~str {\n     static ONLINERS: &'static [&'static str] = &[\"///!\", \"///\", \"//!\", \"//\"];\n     for prefix in ONLINERS.iter() {\n         if comment.starts_with(*prefix) {\n-            return comment.slice_from(prefix.len()).to_owned();\n+            return comment.slice_from(prefix.len()).to_strbuf();\n         }\n     }\n \n     if comment.starts_with(\"/*\") {\n         let lines = comment.slice(3u, comment.len() - 2u)\n             .lines_any()\n-            .map(|s| s.to_owned())\n-            .collect::<Vec<~str> >();\n+            .map(|s| s.to_strbuf())\n+            .collect::<Vec<StrBuf> >();\n \n         let lines = vertical_trim(lines);\n         let lines = horizontal_trim(lines);\n \n-        return lines.connect(\"\\n\");\n+        return lines.connect(\"\\n\").to_strbuf();\n     }\n \n     fail!(\"not a doc-comment: {}\", comment);\n }\n \n-fn read_to_eol(rdr: &mut StringReader) -> ~str {\n+fn read_to_eol(rdr: &mut StringReader) -> StrBuf {\n     let mut val = StrBuf::new();\n     while !rdr.curr_is('\\n') && !is_eof(rdr) {\n         val.push_char(rdr.curr.unwrap());\n         bump(rdr);\n     }\n     if rdr.curr_is('\\n') { bump(rdr); }\n-    return val.into_owned();\n+    return val\n }\n \n-fn read_one_line_comment(rdr: &mut StringReader) -> ~str {\n+fn read_one_line_comment(rdr: &mut StringReader) -> StrBuf {\n     let val = read_to_eol(rdr);\n-    assert!((val[0] == '/' as u8 && val[1] == '/' as u8) ||\n-                 (val[0] == '#' as u8 && val[1] == '!' as u8));\n+    assert!((val.as_slice()[0] == '/' as u8 &&\n+                val.as_slice()[1] == '/' as u8) ||\n+                (val.as_slice()[0] == '#' as u8 &&\n+                 val.as_slice()[1] == '!' as u8));\n     return val;\n }\n \n@@ -193,11 +202,12 @@ fn read_line_comments(rdr: &mut StringReader, code_to_the_left: bool,\n                       comments: &mut Vec<Comment>) {\n     debug!(\">>> line comments\");\n     let p = rdr.last_pos;\n-    let mut lines: Vec<~str> = Vec::new();\n+    let mut lines: Vec<StrBuf> = Vec::new();\n     while rdr.curr_is('/') && nextch_is(rdr, '/') {\n         let line = read_one_line_comment(rdr);\n         debug!(\"{}\", line);\n-        if is_doc_comment(line) { // doc-comments are not put in comments\n+        // Doc comments are not put in comments.\n+        if is_doc_comment(line.as_slice()) {\n             break;\n         }\n         lines.push(line);\n@@ -231,14 +241,16 @@ fn all_whitespace(s: &str, col: CharPos) -> Option<uint> {\n     return Some(cursor);\n }\n \n-fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<~str> ,\n-                                        s: ~str, col: CharPos) {\n+fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<StrBuf> ,\n+                                        s: StrBuf, col: CharPos) {\n     let len = s.len();\n-    let s1 = match all_whitespace(s, col) {\n+    let s1 = match all_whitespace(s.as_slice(), col) {\n         Some(col) => {\n             if col < len {\n-                s.slice(col, len).to_owned()\n-            } else {  \"\".to_owned() }\n+                s.as_slice().slice(col, len).to_strbuf()\n+            } else {\n+                \"\".to_strbuf()\n+            }\n         }\n         None => s,\n     };\n@@ -251,7 +263,7 @@ fn read_block_comment(rdr: &mut StringReader,\n                       comments: &mut Vec<Comment> ) {\n     debug!(\">>> block comment\");\n     let p = rdr.last_pos;\n-    let mut lines: Vec<~str> = Vec::new();\n+    let mut lines: Vec<StrBuf> = Vec::new();\n     let col = rdr.col;\n     bump(rdr);\n     bump(rdr);\n@@ -273,17 +285,17 @@ fn read_block_comment(rdr: &mut StringReader,\n             return\n         }\n         assert!(!curr_line.as_slice().contains_char('\\n'));\n-        lines.push(curr_line.into_owned());\n+        lines.push(curr_line);\n     } else {\n         let mut level: int = 1;\n         while level > 0 {\n             debug!(\"=== block comment level {}\", level);\n             if is_eof(rdr) {\n-                rdr.fatal(\"unterminated block comment\".to_owned());\n+                rdr.fatal(\"unterminated block comment\".to_strbuf());\n             }\n             if rdr.curr_is('\\n') {\n                 trim_whitespace_prefix_and_push_line(&mut lines,\n-                                                     curr_line.into_owned(),\n+                                                     curr_line,\n                                                      col);\n                 curr_line = StrBuf::new();\n                 bump(rdr);\n@@ -306,7 +318,7 @@ fn read_block_comment(rdr: &mut StringReader,\n         }\n         if curr_line.len() != 0 {\n             trim_whitespace_prefix_and_push_line(&mut lines,\n-                                                 curr_line.into_owned(),\n+                                                 curr_line,\n                                                  col);\n         }\n     }\n@@ -344,19 +356,19 @@ fn consume_comment(rdr: &mut StringReader,\n \n #[deriving(Clone)]\n pub struct Literal {\n-    pub lit: ~str,\n+    pub lit: StrBuf,\n     pub pos: BytePos,\n }\n \n // it appears this function is called only from pprust... that's\n // probably not a good thing.\n pub fn gather_comments_and_literals(span_diagnostic:\n                                         &diagnostic::SpanHandler,\n-                                    path: ~str,\n+                                    path: StrBuf,\n                                     srdr: &mut io::Reader)\n                                  -> (Vec<Comment>, Vec<Literal>) {\n     let src = srdr.read_to_end().unwrap();\n-    let src = str::from_utf8(src.as_slice()).unwrap().to_owned();\n+    let src = str::from_utf8(src.as_slice()).unwrap().to_strbuf();\n     let cm = CodeMap::new();\n     let filemap = cm.new_filemap(path, src);\n     let mut rdr = lexer::new_low_level_string_reader(span_diagnostic, filemap);\n@@ -387,7 +399,7 @@ pub fn gather_comments_and_literals(span_diagnostic:\n         if token::is_lit(&tok) {\n             with_str_from(&rdr, bstart, |s| {\n                 debug!(\"tok lit: {}\", s);\n-                literals.push(Literal {lit: s.to_owned(), pos: sp.lo});\n+                literals.push(Literal {lit: s.to_strbuf(), pos: sp.lo});\n             })\n         } else {\n             debug!(\"tok: {}\", token::to_str(&tok));\n@@ -405,41 +417,41 @@ mod test {\n     #[test] fn test_block_doc_comment_1() {\n         let comment = \"/**\\n * Test \\n **  Test\\n *   Test\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n-        assert_eq!(stripped, \" Test \\n*  Test\\n   Test\".to_owned());\n+        assert_eq!(stripped, \" Test \\n*  Test\\n   Test\".to_strbuf());\n     }\n \n     #[test] fn test_block_doc_comment_2() {\n         let comment = \"/**\\n * Test\\n *  Test\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n-        assert_eq!(stripped, \" Test\\n  Test\".to_owned());\n+        assert_eq!(stripped, \" Test\\n  Test\".to_strbuf());\n     }\n \n     #[test] fn test_block_doc_comment_3() {\n         let comment = \"/**\\n let a: *int;\\n *a = 5;\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n-        assert_eq!(stripped, \" let a: *int;\\n *a = 5;\".to_owned());\n+        assert_eq!(stripped, \" let a: *int;\\n *a = 5;\".to_strbuf());\n     }\n \n     #[test] fn test_block_doc_comment_4() {\n         let comment = \"/*******************\\n test\\n *********************/\";\n         let stripped = strip_doc_comment_decoration(comment);\n-        assert_eq!(stripped, \" test\".to_owned());\n+        assert_eq!(stripped, \" test\".to_strbuf());\n     }\n \n     #[test] fn test_line_doc_comment() {\n         let stripped = strip_doc_comment_decoration(\"/// test\");\n-        assert_eq!(stripped, \" test\".to_owned());\n+        assert_eq!(stripped, \" test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"///! test\");\n-        assert_eq!(stripped, \" test\".to_owned());\n+        assert_eq!(stripped, \" test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"// test\");\n-        assert_eq!(stripped, \" test\".to_owned());\n+        assert_eq!(stripped, \" test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"// test\");\n-        assert_eq!(stripped, \" test\".to_owned());\n+        assert_eq!(stripped, \" test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"///test\");\n-        assert_eq!(stripped, \"test\".to_owned());\n+        assert_eq!(stripped, \"test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"///!test\");\n-        assert_eq!(stripped, \"test\".to_owned());\n+        assert_eq!(stripped, \"test\".to_strbuf());\n         let stripped = strip_doc_comment_decoration(\"//test\");\n-        assert_eq!(stripped, \"test\".to_owned());\n+        assert_eq!(stripped, \"test\".to_strbuf());\n     }\n }"}, {"sha": "c78d2aaf3a7e891567519b443054d9c1b6fa0619", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 90, "deletions": 69, "changes": 159, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -28,7 +28,7 @@ pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n pub trait Reader {\n     fn is_eof(&self) -> bool;\n     fn next_token(&mut self) -> TokenAndSpan;\n-    fn fatal(&self, ~str) -> !;\n+    fn fatal(&self, StrBuf) -> !;\n     fn span_diag<'a>(&'a self) -> &'a SpanHandler;\n     fn peek(&self) -> TokenAndSpan;\n }\n@@ -101,8 +101,8 @@ impl<'a> Reader for StringReader<'a> {\n         string_advance_token(self);\n         ret_val\n     }\n-    fn fatal(&self, m: ~str) -> ! {\n-        self.span_diagnostic.span_fatal(self.peek_span, m)\n+    fn fatal(&self, m: StrBuf) -> ! {\n+        self.span_diagnostic.span_fatal(self.peek_span, m.as_slice())\n     }\n     fn span_diag<'a>(&'a self) -> &'a SpanHandler { self.span_diagnostic }\n     fn peek(&self) -> TokenAndSpan {\n@@ -123,8 +123,8 @@ impl<'a> Reader for TtReader<'a> {\n         debug!(\"TtReader: r={:?}\", r);\n         r\n     }\n-    fn fatal(&self, m: ~str) -> ! {\n-        self.sp_diag.span_fatal(self.cur_span, m);\n+    fn fatal(&self, m: StrBuf) -> ! {\n+        self.sp_diag.span_fatal(self.cur_span, m.as_slice());\n     }\n     fn span_diag<'a>(&'a self) -> &'a SpanHandler { self.sp_diag }\n     fn peek(&self) -> TokenAndSpan {\n@@ -139,7 +139,7 @@ impl<'a> Reader for TtReader<'a> {\n fn fatal_span(rdr: &mut StringReader,\n               from_pos: BytePos,\n               to_pos: BytePos,\n-              m: ~str)\n+              m: StrBuf)\n            -> ! {\n     rdr.peek_span = codemap::mk_sp(from_pos, to_pos);\n     rdr.fatal(m);\n@@ -150,28 +150,28 @@ fn fatal_span(rdr: &mut StringReader,\n fn fatal_span_char(rdr: &mut StringReader,\n                    from_pos: BytePos,\n                    to_pos: BytePos,\n-                   m: ~str,\n+                   m: StrBuf,\n                    c: char)\n                 -> ! {\n-    let mut m = StrBuf::from_owned_str(m);\n+    let mut m = m;\n     m.push_str(\": \");\n     char::escape_default(c, |c| m.push_char(c));\n-    fatal_span(rdr, from_pos, to_pos, m.into_owned());\n+    fatal_span(rdr, from_pos, to_pos, m.into_strbuf());\n }\n \n // report a lexical error spanning [`from_pos`, `to_pos`), appending the\n // offending string to the error message\n fn fatal_span_verbose(rdr: &mut StringReader,\n                       from_pos: BytePos,\n                       to_pos: BytePos,\n-                      m: ~str)\n+                      m: StrBuf)\n                    -> ! {\n-    let mut m = StrBuf::from_owned_str(m);\n+    let mut m = m;\n     m.push_str(\": \");\n     let from = byte_offset(rdr, from_pos).to_uint();\n     let to = byte_offset(rdr, to_pos).to_uint();\n-    m.push_str(rdr.filemap.src.slice(from, to));\n-    fatal_span(rdr, from_pos, to_pos, m.into_owned());\n+    m.push_str(rdr.filemap.src.as_slice().slice(from, to));\n+    fatal_span(rdr, from_pos, to_pos, m);\n }\n \n // EFFECT: advance peek_tok and peek_span to refer to the next token.\n@@ -218,7 +218,7 @@ fn with_str_from_to<T>(\n                     end: BytePos,\n                     f: |s: &str| -> T)\n                     -> T {\n-    f(rdr.filemap.src.slice(\n+    f(rdr.filemap.src.as_slice().slice(\n             byte_offset(rdr, start).to_uint(),\n             byte_offset(rdr, end).to_uint()))\n }\n@@ -231,7 +231,10 @@ pub fn bump(rdr: &mut StringReader) {\n     if current_byte_offset < rdr.filemap.src.len() {\n         assert!(rdr.curr.is_some());\n         let last_char = rdr.curr.unwrap();\n-        let next = rdr.filemap.src.char_range_at(current_byte_offset);\n+        let next = rdr.filemap\n+                      .src\n+                      .as_slice()\n+                      .char_range_at(current_byte_offset);\n         let byte_offset_diff = next.next - current_byte_offset;\n         rdr.pos = rdr.pos + Pos::from_uint(byte_offset_diff);\n         rdr.curr = Some(next.ch);\n@@ -256,7 +259,7 @@ pub fn is_eof(rdr: &StringReader) -> bool {\n pub fn nextch(rdr: &StringReader) -> Option<char> {\n     let offset = byte_offset(rdr, rdr.pos).to_uint();\n     if offset < rdr.filemap.src.len() {\n-        Some(rdr.filemap.src.char_at(offset))\n+        Some(rdr.filemap.src.as_slice().char_at(offset))\n     } else {\n         None\n     }\n@@ -400,9 +403,9 @@ fn consume_block_comment(rdr: &mut StringReader) -> Option<TokenAndSpan> {\n     while level > 0 {\n         if is_eof(rdr) {\n             let msg = if is_doc_comment {\n-                \"unterminated block doc-comment\".to_owned()\n+                \"unterminated block doc-comment\".to_strbuf()\n             } else {\n-                \"unterminated block comment\".to_owned()\n+                \"unterminated block comment\".to_strbuf()\n             };\n             fatal_span(rdr, start_bpos, rdr.last_pos, msg);\n         } else if rdr.curr_is('/') && nextch_is(rdr, '*') {\n@@ -438,7 +441,7 @@ fn consume_block_comment(rdr: &mut StringReader) -> Option<TokenAndSpan> {\n     if res.is_some() { res } else { consume_whitespace_and_comments(rdr) }\n }\n \n-fn scan_exponent(rdr: &mut StringReader, start_bpos: BytePos) -> Option<~str> {\n+fn scan_exponent(rdr: &mut StringReader, start_bpos: BytePos) -> Option<StrBuf> {\n     // \\x00 hits the `return None` case immediately, so this is fine.\n     let mut c = rdr.curr.unwrap_or('\\x00');\n     let mut rslt = StrBuf::new();\n@@ -452,16 +455,18 @@ fn scan_exponent(rdr: &mut StringReader, start_bpos: BytePos) -> Option<~str> {\n         }\n         let exponent = scan_digits(rdr, 10u);\n         if exponent.len() > 0u {\n-            rslt.push_str(exponent);\n-            return Some(rslt.into_owned());\n+            rslt.push_str(exponent.as_slice());\n+            return Some(rslt);\n         } else {\n             fatal_span(rdr, start_bpos, rdr.last_pos,\n-                       \"scan_exponent: bad fp literal\".to_owned());\n+                       \"scan_exponent: bad fp literal\".to_strbuf());\n         }\n-    } else { return None::<~str>; }\n+    } else {\n+        return None::<StrBuf>;\n+    }\n }\n \n-fn scan_digits(rdr: &mut StringReader, radix: uint) -> ~str {\n+fn scan_digits(rdr: &mut StringReader, radix: uint) -> StrBuf {\n     let mut rslt = StrBuf::new();\n     loop {\n         let c = rdr.curr;\n@@ -471,20 +476,22 @@ fn scan_digits(rdr: &mut StringReader, radix: uint) -> ~str {\n             rslt.push_char(c.unwrap());\n             bump(rdr);\n           }\n-          _ => return rslt.into_owned()\n+          _ => return rslt\n         }\n     };\n }\n \n fn check_float_base(rdr: &mut StringReader, start_bpos: BytePos, last_bpos: BytePos,\n                     base: uint) {\n     match base {\n-      16u => fatal_span(rdr, start_bpos, last_bpos,\n-                      \"hexadecimal float literal is not supported\".to_owned()),\n+      16u => {\n+          fatal_span(rdr, start_bpos, last_bpos,\n+                     \"hexadecimal float literal is not supported\".to_strbuf())\n+      }\n       8u => fatal_span(rdr, start_bpos, last_bpos,\n-                     \"octal float literal is not supported\".to_owned()),\n+                     \"octal float literal is not supported\".to_strbuf()),\n       2u => fatal_span(rdr, start_bpos, last_bpos,\n-                     \"binary float literal is not supported\".to_owned()),\n+                     \"binary float literal is not supported\".to_strbuf()),\n       _ => ()\n     }\n }\n@@ -508,7 +515,7 @@ fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n         bump(rdr);\n         base = 2u;\n     }\n-    num_str = StrBuf::from_owned_str(scan_digits(rdr, base));\n+    num_str = scan_digits(rdr, base);\n     c = rdr.curr.unwrap_or('\\x00');\n     nextch(rdr);\n     if c == 'u' || c == 'i' {\n@@ -544,13 +551,13 @@ fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n         }\n         if num_str.len() == 0u {\n             fatal_span(rdr, start_bpos, rdr.last_pos,\n-                       \"no valid digits found for number\".to_owned());\n+                       \"no valid digits found for number\".to_strbuf());\n         }\n         let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n                                                  base as uint) {\n             Some(p) => p,\n             None => fatal_span(rdr, start_bpos, rdr.last_pos,\n-                               \"int literal is too large\".to_owned())\n+                               \"int literal is too large\".to_strbuf())\n         };\n \n         match tp {\n@@ -564,12 +571,12 @@ fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n         bump(rdr);\n         let dec_part = scan_digits(rdr, 10u);\n         num_str.push_char('.');\n-        num_str.push_str(dec_part);\n+        num_str.push_str(dec_part.as_slice());\n     }\n     match scan_exponent(rdr, start_bpos) {\n       Some(ref s) => {\n         is_float = true;\n-        num_str.push_str(*s);\n+        num_str.push_str(s.as_slice());\n       }\n       None => ()\n     }\n@@ -601,7 +608,7 @@ fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n             return token::LIT_FLOAT(str_to_ident(num_str.as_slice()), ast::TyF128);\n         }\n         fatal_span(rdr, start_bpos, rdr.last_pos,\n-                   \"expected `f32`, `f64` or `f128` suffix\".to_owned());\n+                   \"expected `f32`, `f64` or `f128` suffix\".to_strbuf());\n     }\n     if is_float {\n         check_float_base(rdr, start_bpos, rdr.last_pos, base);\n@@ -610,13 +617,13 @@ fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n     } else {\n         if num_str.len() == 0u {\n             fatal_span(rdr, start_bpos, rdr.last_pos,\n-                       \"no valid digits found for number\".to_owned());\n+                       \"no valid digits found for number\".to_strbuf());\n         }\n         let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n                                                  base as uint) {\n             Some(p) => p,\n             None => fatal_span(rdr, start_bpos, rdr.last_pos,\n-                               \"int literal is too large\".to_owned())\n+                               \"int literal is too large\".to_strbuf())\n         };\n \n         debug!(\"lexing {} as an unsuffixed integer literal\",\n@@ -632,9 +639,12 @@ fn scan_numeric_escape(rdr: &mut StringReader, n_hex_digits: uint) -> char {\n     while i != 0u && !is_eof(rdr) {\n         let n = rdr.curr;\n         if !is_hex_digit(n) {\n-            fatal_span_char(rdr, rdr.last_pos, rdr.pos,\n-                            \"illegal character in numeric character escape\".to_owned(),\n-                            n.unwrap());\n+            fatal_span_char(\n+                rdr,\n+                rdr.last_pos,\n+                rdr.pos,\n+                \"illegal character in numeric character escape\".to_strbuf(),\n+                n.unwrap());\n         }\n         bump(rdr);\n         accum_int *= 16;\n@@ -643,13 +653,13 @@ fn scan_numeric_escape(rdr: &mut StringReader, n_hex_digits: uint) -> char {\n     }\n     if i != 0 && is_eof(rdr) {\n         fatal_span(rdr, start_bpos, rdr.last_pos,\n-                   \"unterminated numeric character escape\".to_owned());\n+                   \"unterminated numeric character escape\".to_strbuf());\n     }\n \n     match char::from_u32(accum_int as u32) {\n         Some(x) => x,\n         None => fatal_span(rdr, start_bpos, rdr.last_pos,\n-                           \"illegal numeric character escape\".to_owned())\n+                           \"illegal numeric character escape\".to_strbuf())\n     }\n }\n \n@@ -819,11 +829,11 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n             if token::is_keyword(token::keywords::Self, tok) {\n                 fatal_span(rdr, start, rdr.last_pos,\n                            \"invalid lifetime name: 'self \\\n-                            is no longer a special lifetime\".to_owned());\n+                            is no longer a special lifetime\".to_strbuf());\n             } else if token::is_any_keyword(tok) &&\n                 !token::is_keyword(token::keywords::Static, tok) {\n                 fatal_span(rdr, start, rdr.last_pos,\n-                           \"invalid lifetime name\".to_owned());\n+                           \"invalid lifetime name\".to_strbuf());\n             } else {\n                 return token::LIFETIME(ident);\n             }\n@@ -851,16 +861,24 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n                             'u' => scan_numeric_escape(rdr, 4u),\n                             'U' => scan_numeric_escape(rdr, 8u),\n                             c2 => {\n-                                fatal_span_char(rdr, escaped_pos, rdr.last_pos,\n-                                                \"unknown character escape\".to_owned(), c2)\n+                                fatal_span_char(rdr,\n+                                                escaped_pos,\n+                                                rdr.last_pos,\n+                                                \"unknown character \\\n+                                                 escape\".to_strbuf(),\n+                                                c2)\n                             }\n                         }\n                     }\n                 }\n             }\n             '\\t' | '\\n' | '\\r' | '\\'' => {\n-                fatal_span_char(rdr, start, rdr.last_pos,\n-                                \"character constant must be escaped\".to_owned(), c2);\n+                fatal_span_char(\n+                    rdr,\n+                    start,\n+                    rdr.last_pos,\n+                    \"character constant must be escaped\".to_strbuf(),\n+                    c2);\n             }\n             _ => {}\n         }\n@@ -871,7 +889,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n                                // ascii single quote.\n                                start - BytePos(1),\n                                rdr.last_pos,\n-                               \"unterminated character constant\".to_owned());\n+                               \"unterminated character constant\".to_strbuf());\n         }\n         bump(rdr); // advance curr past token\n         return token::LIT_CHAR(c2);\n@@ -883,7 +901,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n         while !rdr.curr_is('\"') {\n             if is_eof(rdr) {\n                 fatal_span(rdr, start_bpos, rdr.last_pos,\n-                           \"unterminated double quote string\".to_owned());\n+                           \"unterminated double quote string\".to_strbuf());\n             }\n \n             let ch = rdr.curr.unwrap();\n@@ -892,7 +910,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n               '\\\\' => {\n                 if is_eof(rdr) {\n                     fatal_span(rdr, start_bpos, rdr.last_pos,\n-                           \"unterminated double quote string\".to_owned());\n+                           \"unterminated double quote string\".to_strbuf());\n                 }\n \n                 let escaped = rdr.curr.unwrap();\n@@ -918,7 +936,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n                   }\n                   c2 => {\n                     fatal_span_char(rdr, escaped_pos, rdr.last_pos,\n-                                    \"unknown string escape\".to_owned(), c2);\n+                                    \"unknown string escape\".to_strbuf(), c2);\n                   }\n                 }\n               }\n@@ -939,11 +957,11 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n \n         if is_eof(rdr) {\n             fatal_span(rdr, start_bpos, rdr.last_pos,\n-                       \"unterminated raw string\".to_owned());\n+                       \"unterminated raw string\".to_strbuf());\n         } else if !rdr.curr_is('\"') {\n             fatal_span_char(rdr, start_bpos, rdr.last_pos,\n                             \"only `#` is allowed in raw string delimitation; \\\n-                             found illegal character\".to_owned(),\n+                             found illegal character\".to_strbuf(),\n                             rdr.curr.unwrap());\n         }\n         bump(rdr);\n@@ -952,7 +970,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n         'outer: loop {\n             if is_eof(rdr) {\n                 fatal_span(rdr, start_bpos, rdr.last_pos,\n-                           \"unterminated raw string\".to_owned());\n+                           \"unterminated raw string\".to_strbuf());\n             }\n             if rdr.curr_is('\"') {\n                 content_end_bpos = rdr.last_pos;\n@@ -1000,7 +1018,7 @@ fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n       '%' => { return binop(rdr, token::PERCENT); }\n       c => {\n           fatal_span_char(rdr, rdr.last_pos, rdr.pos,\n-                          \"unknown start of token\".to_owned(), c);\n+                          \"unknown start of token\".to_strbuf(), c);\n       }\n     }\n }\n@@ -1027,16 +1045,16 @@ mod test {\n \n     // open a string reader for the given string\n     fn setup<'a>(span_handler: &'a diagnostic::SpanHandler,\n-                 teststr: ~str) -> StringReader<'a> {\n-        let fm = span_handler.cm.new_filemap(\"zebra.rs\".to_owned(), teststr);\n+                 teststr: StrBuf) -> StringReader<'a> {\n+        let fm = span_handler.cm.new_filemap(\"zebra.rs\".to_strbuf(), teststr);\n         new_string_reader(span_handler, fm)\n     }\n \n     #[test] fn t1 () {\n         let span_handler = mk_sh();\n         let mut string_reader = setup(&span_handler,\n             \"/* my source file */ \\\n-             fn main() { println!(\\\"zebra\\\"); }\\n\".to_owned());\n+             fn main() { println!(\\\"zebra\\\"); }\\n\".to_strbuf());\n         let id = str_to_ident(\"fn\");\n         let tok1 = string_reader.next_token();\n         let tok2 = TokenAndSpan{\n@@ -1069,54 +1087,56 @@ mod test {\n     }\n \n     #[test] fn doublecolonparsing () {\n-        check_tokenization(setup(&mk_sh(), \"a b\".to_owned()),\n+        check_tokenization(setup(&mk_sh(), \"a b\".to_strbuf()),\n                            vec!(mk_ident(\"a\",false),\n                              mk_ident(\"b\",false)));\n     }\n \n     #[test] fn dcparsing_2 () {\n-        check_tokenization(setup(&mk_sh(), \"a::b\".to_owned()),\n+        check_tokenization(setup(&mk_sh(), \"a::b\".to_strbuf()),\n                            vec!(mk_ident(\"a\",true),\n                              token::MOD_SEP,\n                              mk_ident(\"b\",false)));\n     }\n \n     #[test] fn dcparsing_3 () {\n-        check_tokenization(setup(&mk_sh(), \"a ::b\".to_owned()),\n+        check_tokenization(setup(&mk_sh(), \"a ::b\".to_strbuf()),\n                            vec!(mk_ident(\"a\",false),\n                              token::MOD_SEP,\n                              mk_ident(\"b\",false)));\n     }\n \n     #[test] fn dcparsing_4 () {\n-        check_tokenization(setup(&mk_sh(), \"a:: b\".to_owned()),\n+        check_tokenization(setup(&mk_sh(), \"a:: b\".to_strbuf()),\n                            vec!(mk_ident(\"a\",true),\n                              token::MOD_SEP,\n                              mk_ident(\"b\",false)));\n     }\n \n     #[test] fn character_a() {\n-        assert_eq!(setup(&mk_sh(), \"'a'\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(), \"'a'\".to_strbuf()).next_token().tok,\n                    token::LIT_CHAR('a'));\n     }\n \n     #[test] fn character_space() {\n-        assert_eq!(setup(&mk_sh(), \"' '\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(), \"' '\".to_strbuf()).next_token().tok,\n                    token::LIT_CHAR(' '));\n     }\n \n     #[test] fn character_escaped() {\n-        assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_strbuf()).next_token().tok,\n                    token::LIT_CHAR('\\n'));\n     }\n \n     #[test] fn lifetime_name() {\n-        assert_eq!(setup(&mk_sh(), \"'abc\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(), \"'abc\".to_strbuf()).next_token().tok,\n                    token::LIFETIME(token::str_to_ident(\"abc\")));\n     }\n \n     #[test] fn raw_string() {\n-        assert_eq!(setup(&mk_sh(), \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(),\n+                         \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_strbuf()).next_token()\n+                                                                 .tok,\n                    token::LIT_STR_RAW(token::str_to_ident(\"\\\"#a\\\\b\\x00c\\\"\"), 3));\n     }\n \n@@ -1127,7 +1147,8 @@ mod test {\n     }\n \n     #[test] fn nested_block_comments() {\n-        assert_eq!(setup(&mk_sh(), \"/* /* */ */'a'\".to_owned()).next_token().tok,\n+        assert_eq!(setup(&mk_sh(),\n+                         \"/* /* */ */'a'\".to_strbuf()).next_token().tok,\n                    token::LIT_CHAR('a'));\n     }\n "}, {"sha": "28f235a3da0398fff283040cb16964ec108d0908", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 35, "deletions": 35, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -77,8 +77,8 @@ pub fn parse_crate_attrs_from_file(\n     inner\n }\n \n-pub fn parse_crate_from_source_str(name: ~str,\n-                                   source: ~str,\n+pub fn parse_crate_from_source_str(name: StrBuf,\n+                                   source: StrBuf,\n                                    cfg: ast::CrateConfig,\n                                    sess: &ParseSess)\n                                    -> ast::Crate {\n@@ -89,8 +89,8 @@ pub fn parse_crate_from_source_str(name: ~str,\n     maybe_aborted(p.parse_crate_mod(),p)\n }\n \n-pub fn parse_crate_attrs_from_source_str(name: ~str,\n-                                         source: ~str,\n+pub fn parse_crate_attrs_from_source_str(name: StrBuf,\n+                                         source: StrBuf,\n                                          cfg: ast::CrateConfig,\n                                          sess: &ParseSess)\n                                          -> Vec<ast::Attribute> {\n@@ -102,17 +102,17 @@ pub fn parse_crate_attrs_from_source_str(name: ~str,\n     inner\n }\n \n-pub fn parse_expr_from_source_str(name: ~str,\n-                                  source: ~str,\n+pub fn parse_expr_from_source_str(name: StrBuf,\n+                                  source: StrBuf,\n                                   cfg: ast::CrateConfig,\n                                   sess: &ParseSess)\n                                   -> @ast::Expr {\n     let mut p = new_parser_from_source_str(sess, cfg, name, source);\n     maybe_aborted(p.parse_expr(), p)\n }\n \n-pub fn parse_item_from_source_str(name: ~str,\n-                                  source: ~str,\n+pub fn parse_item_from_source_str(name: StrBuf,\n+                                  source: StrBuf,\n                                   cfg: ast::CrateConfig,\n                                   sess: &ParseSess)\n                                   -> Option<@ast::Item> {\n@@ -121,17 +121,17 @@ pub fn parse_item_from_source_str(name: ~str,\n     maybe_aborted(p.parse_item(attrs),p)\n }\n \n-pub fn parse_meta_from_source_str(name: ~str,\n-                                  source: ~str,\n+pub fn parse_meta_from_source_str(name: StrBuf,\n+                                  source: StrBuf,\n                                   cfg: ast::CrateConfig,\n                                   sess: &ParseSess)\n                                   -> @ast::MetaItem {\n     let mut p = new_parser_from_source_str(sess, cfg, name, source);\n     maybe_aborted(p.parse_meta_item(),p)\n }\n \n-pub fn parse_stmt_from_source_str(name: ~str,\n-                                  source: ~str,\n+pub fn parse_stmt_from_source_str(name: StrBuf,\n+                                  source: StrBuf,\n                                   cfg: ast::CrateConfig,\n                                   attrs: Vec<ast::Attribute> ,\n                                   sess: &ParseSess)\n@@ -145,8 +145,8 @@ pub fn parse_stmt_from_source_str(name: ~str,\n     maybe_aborted(p.parse_stmt(attrs),p)\n }\n \n-pub fn parse_tts_from_source_str(name: ~str,\n-                                 source: ~str,\n+pub fn parse_tts_from_source_str(name: StrBuf,\n+                                 source: StrBuf,\n                                  cfg: ast::CrateConfig,\n                                  sess: &ParseSess)\n                                  -> Vec<ast::TokenTree> {\n@@ -164,8 +164,8 @@ pub fn parse_tts_from_source_str(name: ~str,\n // Create a new parser from a source string\n pub fn new_parser_from_source_str<'a>(sess: &'a ParseSess,\n                                       cfg: ast::CrateConfig,\n-                                      name: ~str,\n-                                      source: ~str)\n+                                      name: StrBuf,\n+                                      source: StrBuf)\n                                       -> Parser<'a> {\n     filemap_to_parser(sess, string_to_filemap(sess, source, name), cfg)\n }\n@@ -225,8 +225,8 @@ pub fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n     };\n     match str::from_utf8(bytes.as_slice()) {\n         Some(s) => {\n-            return string_to_filemap(sess, s.to_owned(),\n-                                     path.as_str().unwrap().to_str())\n+            return string_to_filemap(sess, s.to_strbuf(),\n+                                     path.as_str().unwrap().to_strbuf())\n         }\n         None => err(format!(\"{} is not UTF-8 encoded\", path.display())),\n     }\n@@ -235,7 +235,7 @@ pub fn file_to_filemap(sess: &ParseSess, path: &Path, spanopt: Option<Span>)\n \n // given a session and a string, add the string to\n // the session's codemap and return the new filemap\n-pub fn string_to_filemap(sess: &ParseSess, source: ~str, path: ~str)\n+pub fn string_to_filemap(sess: &ParseSess, source: StrBuf, path: StrBuf)\n                          -> Rc<FileMap> {\n     sess.span_diagnostic.cm.new_filemap(path, source)\n }\n@@ -284,11 +284,11 @@ mod test {\n     use util::parser_testing::{string_to_expr, string_to_item};\n     use util::parser_testing::string_to_stmt;\n \n-    fn to_json_str<'a, E: Encodable<json::Encoder<'a>, io::IoError>>(val: &E) -> ~str {\n+    fn to_json_str<'a, E: Encodable<json::Encoder<'a>, io::IoError>>(val: &E) -> StrBuf {\n         let mut writer = MemWriter::new();\n         let mut encoder = json::Encoder::new(&mut writer as &mut io::Writer);\n         let _ = val.encode(&mut encoder);\n-        str::from_utf8(writer.unwrap().as_slice()).unwrap().to_owned()\n+        str::from_utf8(writer.unwrap().as_slice()).unwrap().to_strbuf()\n     }\n \n     // produce a codemap::span\n@@ -297,7 +297,7 @@ mod test {\n     }\n \n     #[test] fn path_exprs_1() {\n-        assert!(string_to_expr(\"a\".to_owned()) ==\n+        assert!(string_to_expr(\"a\".to_strbuf()) ==\n                    @ast::Expr{\n                     id: ast::DUMMY_NODE_ID,\n                     node: ast::ExprPath(ast::Path {\n@@ -316,7 +316,7 @@ mod test {\n     }\n \n     #[test] fn path_exprs_2 () {\n-        assert!(string_to_expr(\"::a::b\".to_owned()) ==\n+        assert!(string_to_expr(\"::a::b\".to_strbuf()) ==\n                    @ast::Expr {\n                     id: ast::DUMMY_NODE_ID,\n                     node: ast::ExprPath(ast::Path {\n@@ -341,12 +341,12 @@ mod test {\n \n     #[should_fail]\n     #[test] fn bad_path_expr_1() {\n-        string_to_expr(\"::abc::def::return\".to_owned());\n+        string_to_expr(\"::abc::def::return\".to_strbuf());\n     }\n \n     // check the token-tree-ization of macros\n     #[test] fn string_to_tts_macro () {\n-        let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_owned());\n+        let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_strbuf());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n             [ast::TTTok(_,_),\n@@ -399,7 +399,7 @@ mod test {\n     }\n \n     #[test] fn string_to_tts_1 () {\n-        let tts = string_to_tts(\"fn a (b : int) { b; }\".to_owned());\n+        let tts = string_to_tts(\"fn a (b : int) { b; }\".to_strbuf());\n         assert_eq!(to_json_str(&tts),\n         \"[\\\n     {\\\n@@ -523,12 +523,12 @@ mod test {\n             ]\\\n         ]\\\n     }\\\n-]\".to_owned()\n+]\".to_strbuf()\n         );\n     }\n \n     #[test] fn ret_expr() {\n-        assert!(string_to_expr(\"return d\".to_owned()) ==\n+        assert!(string_to_expr(\"return d\".to_strbuf()) ==\n                    @ast::Expr{\n                     id: ast::DUMMY_NODE_ID,\n                     node:ast::ExprRet(Some(@ast::Expr{\n@@ -551,7 +551,7 @@ mod test {\n     }\n \n     #[test] fn parse_stmt_1 () {\n-        assert!(string_to_stmt(\"b;\".to_owned()) ==\n+        assert!(string_to_stmt(\"b;\".to_strbuf()) ==\n                    @Spanned{\n                        node: ast::StmtExpr(@ast::Expr {\n                            id: ast::DUMMY_NODE_ID,\n@@ -578,7 +578,7 @@ mod test {\n \n     #[test] fn parse_ident_pat () {\n         let sess = new_parse_sess();\n-        let mut parser = string_to_parser(&sess, \"b\".to_owned());\n+        let mut parser = string_to_parser(&sess, \"b\".to_strbuf());\n         assert!(parser.parse_pat() ==\n                    @ast::Pat{id: ast::DUMMY_NODE_ID,\n                              node: ast::PatIdent(\n@@ -602,7 +602,7 @@ mod test {\n     // check the contents of the tt manually:\n     #[test] fn parse_fundecl () {\n         // this test depends on the intern order of \"fn\" and \"int\"\n-        assert!(string_to_item(\"fn a (b : int) { b; }\".to_owned()) ==\n+        assert!(string_to_item(\"fn a (b : int) { b; }\".to_strbuf()) ==\n                   Some(\n                       @ast::Item{ident:str_to_ident(\"a\"),\n                             attrs:Vec::new(),\n@@ -694,13 +694,13 @@ mod test {\n \n     #[test] fn parse_exprs () {\n         // just make sure that they parse....\n-        string_to_expr(\"3 + 4\".to_owned());\n-        string_to_expr(\"a::z.froob(b,@(987+3))\".to_owned());\n+        string_to_expr(\"3 + 4\".to_strbuf());\n+        string_to_expr(\"a::z.froob(b,@(987+3))\".to_strbuf());\n     }\n \n     #[test] fn attrs_fix_bug () {\n         string_to_item(\"pub fn mk_file_writer(path: &Path, flags: &[FileFlag])\n-                   -> Result<@Writer, ~str> {\n+                   -> Result<@Writer, StrBuf> {\n     #[cfg(windows)]\n     fn wb() -> c_int {\n       (O_WRONLY | libc::consts::os::extra::O_BINARY) as c_int\n@@ -710,7 +710,7 @@ mod test {\n     fn wb() -> c_int { O_WRONLY as c_int }\n \n     let mut fflags: c_int = wb();\n-}\".to_owned());\n+}\".to_strbuf());\n     }\n \n }"}, {"sha": "b6aa47128e630991140f31745c58a02654de3766", "filename": "src/libsyntax/parse/obsolete.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fobsolete.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -123,7 +123,7 @@ impl<'a> ParserObsoleteMethods for Parser<'a> {\n             ),\n             ObsoleteManagedString => (\n                 \"managed string\",\n-                \"use `Rc<~str>` instead of a managed string\"\n+                \"use `Rc<StrBuf>` instead of a managed string\"\n             ),\n             ObsoleteManagedVec => (\n                 \"managed vector\","}, {"sha": "8f3b77dd58c2d0b0a86be2092a70649806ac3b27", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 13, "deletions": 7, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -345,12 +345,12 @@ fn is_plain_ident_or_underscore(t: &token::Token) -> bool {\n \n impl<'a> Parser<'a> {\n     // convert a token to a string using self's reader\n-    pub fn token_to_str(token: &token::Token) -> ~str {\n+    pub fn token_to_str(token: &token::Token) -> StrBuf {\n         token::to_str(token)\n     }\n \n     // convert the current token to a string using self's reader\n-    pub fn this_token_to_str(&mut self) -> ~str {\n+    pub fn this_token_to_str(&mut self) -> StrBuf {\n         Parser::token_to_str(&self.token)\n     }\n \n@@ -385,11 +385,17 @@ impl<'a> Parser<'a> {\n     pub fn expect_one_of(&mut self,\n                          edible: &[token::Token],\n                          inedible: &[token::Token]) {\n-        fn tokens_to_str(tokens: &[token::Token]) -> ~str {\n+        fn tokens_to_str(tokens: &[token::Token]) -> StrBuf {\n             let mut i = tokens.iter();\n             // This might be a sign we need a connect method on Iterator.\n-            let b = i.next().map_or(\"\".to_owned(), |t| Parser::token_to_str(t));\n-            i.fold(b, |b,a| b + \"`, `\" + Parser::token_to_str(a))\n+            let b = i.next()\n+                     .map_or(\"\".to_strbuf(), |t| Parser::token_to_str(t));\n+            i.fold(b, |b,a| {\n+                let mut b = b;\n+                b.push_str(\"`, `\");\n+                b.push_str(Parser::token_to_str(a).as_slice());\n+                b\n+            })\n         }\n         if edible.contains(&self.token) {\n             self.bump();\n@@ -3898,15 +3904,15 @@ impl<'a> Parser<'a> {\n         (ident, ItemImpl(generics, opt_trait, ty, meths), Some(inner_attrs))\n     }\n \n-    // parse a::B<~str,int>\n+    // parse a::B<StrBuf,int>\n     fn parse_trait_ref(&mut self) -> TraitRef {\n         ast::TraitRef {\n             path: self.parse_path(LifetimeAndTypesWithoutColons).path,\n             ref_id: ast::DUMMY_NODE_ID,\n         }\n     }\n \n-    // parse B + C<~str,int> + D\n+    // parse B + C<StrBuf,int> + D\n     fn parse_trait_ref_list(&mut self, ket: &token::Token) -> Vec<TraitRef> {\n         self.parse_seq_to_before_end(\n             ket,"}, {"sha": "8fb2fe61b833d8fb669fcfa1f6429e2d2bb18800", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 76, "deletions": 71, "changes": 147, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -137,58 +137,62 @@ impl fmt::Show for Nonterminal {\n     }\n }\n \n-pub fn binop_to_str(o: BinOp) -> ~str {\n+pub fn binop_to_str(o: BinOp) -> StrBuf {\n     match o {\n-      PLUS => \"+\".to_owned(),\n-      MINUS => \"-\".to_owned(),\n-      STAR => \"*\".to_owned(),\n-      SLASH => \"/\".to_owned(),\n-      PERCENT => \"%\".to_owned(),\n-      CARET => \"^\".to_owned(),\n-      AND => \"&\".to_owned(),\n-      OR => \"|\".to_owned(),\n-      SHL => \"<<\".to_owned(),\n-      SHR => \">>\".to_owned()\n+      PLUS => \"+\".to_strbuf(),\n+      MINUS => \"-\".to_strbuf(),\n+      STAR => \"*\".to_strbuf(),\n+      SLASH => \"/\".to_strbuf(),\n+      PERCENT => \"%\".to_strbuf(),\n+      CARET => \"^\".to_strbuf(),\n+      AND => \"&\".to_strbuf(),\n+      OR => \"|\".to_strbuf(),\n+      SHL => \"<<\".to_strbuf(),\n+      SHR => \">>\".to_strbuf()\n     }\n }\n \n-pub fn to_str(t: &Token) -> ~str {\n+pub fn to_str(t: &Token) -> StrBuf {\n     match *t {\n-      EQ => \"=\".to_owned(),\n-      LT => \"<\".to_owned(),\n-      LE => \"<=\".to_owned(),\n-      EQEQ => \"==\".to_owned(),\n-      NE => \"!=\".to_owned(),\n-      GE => \">=\".to_owned(),\n-      GT => \">\".to_owned(),\n-      NOT => \"!\".to_owned(),\n-      TILDE => \"~\".to_owned(),\n-      OROR => \"||\".to_owned(),\n-      ANDAND => \"&&\".to_owned(),\n+      EQ => \"=\".to_strbuf(),\n+      LT => \"<\".to_strbuf(),\n+      LE => \"<=\".to_strbuf(),\n+      EQEQ => \"==\".to_strbuf(),\n+      NE => \"!=\".to_strbuf(),\n+      GE => \">=\".to_strbuf(),\n+      GT => \">\".to_strbuf(),\n+      NOT => \"!\".to_strbuf(),\n+      TILDE => \"~\".to_strbuf(),\n+      OROR => \"||\".to_strbuf(),\n+      ANDAND => \"&&\".to_strbuf(),\n       BINOP(op) => binop_to_str(op),\n-      BINOPEQ(op) => binop_to_str(op) + \"=\",\n+      BINOPEQ(op) => {\n+          let mut s = binop_to_str(op);\n+          s.push_str(\"=\");\n+          s\n+      }\n \n       /* Structural symbols */\n-      AT => \"@\".to_owned(),\n-      DOT => \".\".to_owned(),\n-      DOTDOT => \"..\".to_owned(),\n-      DOTDOTDOT => \"...\".to_owned(),\n-      COMMA => \",\".to_owned(),\n-      SEMI => \";\".to_owned(),\n-      COLON => \":\".to_owned(),\n-      MOD_SEP => \"::\".to_owned(),\n-      RARROW => \"->\".to_owned(),\n-      LARROW => \"<-\".to_owned(),\n-      DARROW => \"<->\".to_owned(),\n-      FAT_ARROW => \"=>\".to_owned(),\n-      LPAREN => \"(\".to_owned(),\n-      RPAREN => \")\".to_owned(),\n-      LBRACKET => \"[\".to_owned(),\n-      RBRACKET => \"]\".to_owned(),\n-      LBRACE => \"{\".to_owned(),\n-      RBRACE => \"}\".to_owned(),\n-      POUND => \"#\".to_owned(),\n-      DOLLAR => \"$\".to_owned(),\n+      AT => \"@\".to_strbuf(),\n+      DOT => \".\".to_strbuf(),\n+      DOTDOT => \"..\".to_strbuf(),\n+      DOTDOTDOT => \"...\".to_strbuf(),\n+      COMMA => \",\".to_strbuf(),\n+      SEMI => \";\".to_strbuf(),\n+      COLON => \":\".to_strbuf(),\n+      MOD_SEP => \"::\".to_strbuf(),\n+      RARROW => \"->\".to_strbuf(),\n+      LARROW => \"<-\".to_strbuf(),\n+      DARROW => \"<->\".to_strbuf(),\n+      FAT_ARROW => \"=>\".to_strbuf(),\n+      LPAREN => \"(\".to_strbuf(),\n+      RPAREN => \")\".to_strbuf(),\n+      LBRACKET => \"[\".to_strbuf(),\n+      RBRACKET => \"]\".to_strbuf(),\n+      LBRACE => \"{\".to_strbuf(),\n+      RBRACE => \"}\".to_strbuf(),\n+      POUND => \"#\".to_strbuf(),\n+      DOLLAR => \"$\".to_strbuf(),\n \n       /* Literals */\n       LIT_CHAR(c) => {\n@@ -197,63 +201,64 @@ pub fn to_str(t: &Token) -> ~str {\n               res.push_char(c);\n           });\n           res.push_char('\\'');\n-          res.into_owned()\n+          res\n       }\n       LIT_INT(i, t) => ast_util::int_ty_to_str(t, Some(i)),\n       LIT_UINT(u, t) => ast_util::uint_ty_to_str(t, Some(u)),\n-      LIT_INT_UNSUFFIXED(i) => { i.to_str() }\n+      LIT_INT_UNSUFFIXED(i) => { i.to_str().to_strbuf() }\n       LIT_FLOAT(s, t) => {\n         let mut body = StrBuf::from_str(get_ident(s).get());\n         if body.as_slice().ends_with(\".\") {\n             body.push_char('0');  // `10.f` is not a float literal\n         }\n-        body.push_str(ast_util::float_ty_to_str(t));\n-        body.into_owned()\n+        body.push_str(ast_util::float_ty_to_str(t).as_slice());\n+        body\n       }\n       LIT_FLOAT_UNSUFFIXED(s) => {\n         let mut body = StrBuf::from_str(get_ident(s).get());\n         if body.as_slice().ends_with(\".\") {\n             body.push_char('0');  // `10.f` is not a float literal\n         }\n-        body.into_owned()\n+        body\n       }\n       LIT_STR(s) => {\n-          format!(\"\\\"{}\\\"\", get_ident(s).get().escape_default())\n+          (format!(\"\\\"{}\\\"\", get_ident(s).get().escape_default())).to_strbuf()\n       }\n       LIT_STR_RAW(s, n) => {\n-          format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                  delim=\"#\".repeat(n), string=get_ident(s))\n+          (format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                  delim=\"#\".repeat(n), string=get_ident(s))).to_strbuf()\n       }\n \n       /* Name components */\n-      IDENT(s, _) => get_ident(s).get().to_str(),\n+      IDENT(s, _) => get_ident(s).get().to_strbuf(),\n       LIFETIME(s) => {\n-          format!(\"'{}\", get_ident(s))\n+          (format!(\"'{}\", get_ident(s))).to_strbuf()\n       }\n-      UNDERSCORE => \"_\".to_owned(),\n+      UNDERSCORE => \"_\".to_strbuf(),\n \n       /* Other */\n-      DOC_COMMENT(s) => get_ident(s).get().to_str(),\n-      EOF => \"<eof>\".to_owned(),\n+      DOC_COMMENT(s) => get_ident(s).get().to_strbuf(),\n+      EOF => \"<eof>\".to_strbuf(),\n       INTERPOLATED(ref nt) => {\n         match nt {\n             &NtExpr(e) => ::print::pprust::expr_to_str(e),\n             &NtMeta(e) => ::print::pprust::meta_item_to_str(e),\n             _ => {\n-                \"an interpolated \".to_owned() +\n-                    match *nt {\n-                        NtItem(..) => \"item\".to_owned(),\n-                        NtBlock(..) => \"block\".to_owned(),\n-                        NtStmt(..) => \"statement\".to_owned(),\n-                        NtPat(..) => \"pattern\".to_owned(),\n-                        NtMeta(..) => fail!(\"should have been handled\"),\n-                        NtExpr(..) => fail!(\"should have been handled above\"),\n-                        NtTy(..) => \"type\".to_owned(),\n-                        NtIdent(..) => \"identifier\".to_owned(),\n-                        NtPath(..) => \"path\".to_owned(),\n-                        NtTT(..) => \"tt\".to_owned(),\n-                        NtMatchers(..) => \"matcher sequence\".to_owned()\n-                    }\n+                let mut s = \"an interpolated \".to_strbuf();\n+                match *nt {\n+                    NtItem(..) => s.push_str(\"item\"),\n+                    NtBlock(..) => s.push_str(\"block\"),\n+                    NtStmt(..) => s.push_str(\"statement\"),\n+                    NtPat(..) => s.push_str(\"pattern\"),\n+                    NtMeta(..) => fail!(\"should have been handled\"),\n+                    NtExpr(..) => fail!(\"should have been handled above\"),\n+                    NtTy(..) => s.push_str(\"type\"),\n+                    NtIdent(..) => s.push_str(\"identifier\"),\n+                    NtPath(..) => s.push_str(\"path\"),\n+                    NtTT(..) => s.push_str(\"tt\"),\n+                    NtMatchers(..) => s.push_str(\"matcher sequence\")\n+                };\n+                s\n             }\n         }\n       }"}, {"sha": "f08cf264f8bfb0390df7f06a808be338e36ac1d0", "filename": "src/libsyntax/print/pp.rs", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fprint%2Fpp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fprint%2Fpp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpp.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -84,7 +84,7 @@ pub struct BeginToken {\n \n #[deriving(Clone)]\n pub enum Token {\n-    String(~str, int),\n+    String(StrBuf, int),\n     Break(BreakToken),\n     Begin(BeginToken),\n     End,\n@@ -109,13 +109,13 @@ impl Token {\n     }\n }\n \n-pub fn tok_str(t: Token) -> ~str {\n+pub fn tok_str(t: Token) -> StrBuf {\n     match t {\n-        String(s, len) => return format!(\"STR({},{})\", s, len),\n-        Break(_) => return \"BREAK\".to_owned(),\n-        Begin(_) => return \"BEGIN\".to_owned(),\n-        End => return \"END\".to_owned(),\n-        Eof => return \"EOF\".to_owned()\n+        String(s, len) => return format!(\"STR({},{})\", s, len).to_strbuf(),\n+        Break(_) => return \"BREAK\".to_strbuf(),\n+        Begin(_) => return \"BEGIN\".to_strbuf(),\n+        End => return \"END\".to_strbuf(),\n+        Eof => return \"EOF\".to_strbuf()\n     }\n }\n \n@@ -124,7 +124,7 @@ pub fn buf_str(toks: Vec<Token>,\n                left: uint,\n                right: uint,\n                lim: uint)\n-               -> ~str {\n+               -> StrBuf {\n     let n = toks.len();\n     assert_eq!(n, szs.len());\n     let mut i = left;\n@@ -140,7 +140,7 @@ pub fn buf_str(toks: Vec<Token>,\n         i %= n;\n     }\n     s.push_char(']');\n-    return s.into_owned();\n+    return s.into_strbuf();\n }\n \n pub enum PrintStackBreak {\n@@ -585,7 +585,7 @@ impl Printer {\n             assert_eq!(l, len);\n             // assert!(l <= space);\n             self.space -= len;\n-            self.print_str(s)\n+            self.print_str(s.as_slice())\n           }\n           Eof => {\n             // Eof should never get here.\n@@ -625,15 +625,15 @@ pub fn end(p: &mut Printer) -> io::IoResult<()> { p.pretty_print(End) }\n pub fn eof(p: &mut Printer) -> io::IoResult<()> { p.pretty_print(Eof) }\n \n pub fn word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n-    p.pretty_print(String(/* bad */ wrd.to_str(), wrd.len() as int))\n+    p.pretty_print(String(/* bad */ wrd.to_strbuf(), wrd.len() as int))\n }\n \n pub fn huge_word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n-    p.pretty_print(String(/* bad */ wrd.to_str(), SIZE_INFINITY))\n+    p.pretty_print(String(/* bad */ wrd.to_strbuf(), SIZE_INFINITY))\n }\n \n pub fn zero_word(p: &mut Printer, wrd: &str) -> io::IoResult<()> {\n-    p.pretty_print(String(/* bad */ wrd.to_str(), 0))\n+    p.pretty_print(String(/* bad */ wrd.to_strbuf(), 0))\n }\n \n pub fn spaces(p: &mut Printer, n: uint) -> io::IoResult<()> {"}, {"sha": "510ec2a370fb50aa8ad44ef9d2c33333ec39c8a0", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 62, "deletions": 50, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -97,7 +97,7 @@ pub static default_columns: uint = 78u;\n pub fn print_crate<'a>(cm: &'a CodeMap,\n                        span_diagnostic: &diagnostic::SpanHandler,\n                        krate: &ast::Crate,\n-                       filename: ~str,\n+                       filename: StrBuf,\n                        input: &mut io::Reader,\n                        out: Box<io::Writer>,\n                        ann: &'a PpAnn,\n@@ -132,7 +132,7 @@ pub fn print_crate<'a>(cm: &'a CodeMap,\n     eof(&mut s.s)\n }\n \n-pub fn to_str(f: |&mut State| -> IoResult<()>) -> ~str {\n+pub fn to_str(f: |&mut State| -> IoResult<()>) -> StrBuf {\n     let mut s = rust_printer(box MemWriter::new());\n     f(&mut s).unwrap();\n     eof(&mut s.s).unwrap();\n@@ -143,65 +143,65 @@ pub fn to_str(f: |&mut State| -> IoResult<()>) -> ~str {\n         let (_, wr): (uint, Box<MemWriter>) = cast::transmute_copy(&s.s.out);\n         let result = str::from_utf8_owned(wr.get_ref().to_owned()).unwrap();\n         cast::forget(wr);\n-        result\n+        result.to_strbuf()\n     }\n }\n \n-pub fn ty_to_str(ty: &ast::Ty) -> ~str {\n+pub fn ty_to_str(ty: &ast::Ty) -> StrBuf {\n     to_str(|s| s.print_type(ty))\n }\n \n-pub fn pat_to_str(pat: &ast::Pat) -> ~str {\n+pub fn pat_to_str(pat: &ast::Pat) -> StrBuf {\n     to_str(|s| s.print_pat(pat))\n }\n \n-pub fn expr_to_str(e: &ast::Expr) -> ~str {\n+pub fn expr_to_str(e: &ast::Expr) -> StrBuf {\n     to_str(|s| s.print_expr(e))\n }\n \n-pub fn lifetime_to_str(e: &ast::Lifetime) -> ~str {\n+pub fn lifetime_to_str(e: &ast::Lifetime) -> StrBuf {\n     to_str(|s| s.print_lifetime(e))\n }\n \n-pub fn tt_to_str(tt: &ast::TokenTree) -> ~str {\n+pub fn tt_to_str(tt: &ast::TokenTree) -> StrBuf {\n     to_str(|s| s.print_tt(tt))\n }\n \n-pub fn tts_to_str(tts: &[ast::TokenTree]) -> ~str {\n+pub fn tts_to_str(tts: &[ast::TokenTree]) -> StrBuf {\n     to_str(|s| s.print_tts(&tts))\n }\n \n-pub fn stmt_to_str(stmt: &ast::Stmt) -> ~str {\n+pub fn stmt_to_str(stmt: &ast::Stmt) -> StrBuf {\n     to_str(|s| s.print_stmt(stmt))\n }\n \n-pub fn item_to_str(i: &ast::Item) -> ~str {\n+pub fn item_to_str(i: &ast::Item) -> StrBuf {\n     to_str(|s| s.print_item(i))\n }\n \n-pub fn generics_to_str(generics: &ast::Generics) -> ~str {\n+pub fn generics_to_str(generics: &ast::Generics) -> StrBuf {\n     to_str(|s| s.print_generics(generics))\n }\n \n-pub fn ty_method_to_str(p: &ast::TypeMethod) -> ~str {\n+pub fn ty_method_to_str(p: &ast::TypeMethod) -> StrBuf {\n     to_str(|s| s.print_ty_method(p))\n }\n \n-pub fn method_to_str(p: &ast::Method) -> ~str {\n+pub fn method_to_str(p: &ast::Method) -> StrBuf {\n     to_str(|s| s.print_method(p))\n }\n \n-pub fn fn_block_to_str(p: &ast::FnDecl) -> ~str {\n+pub fn fn_block_to_str(p: &ast::FnDecl) -> StrBuf {\n     to_str(|s| s.print_fn_block_args(p))\n }\n \n-pub fn path_to_str(p: &ast::Path) -> ~str {\n+pub fn path_to_str(p: &ast::Path) -> StrBuf {\n     to_str(|s| s.print_path(p, false))\n }\n \n pub fn fun_to_str(decl: &ast::FnDecl, fn_style: ast::FnStyle, name: ast::Ident,\n                   opt_explicit_self: Option<ast::ExplicitSelf_>,\n-                  generics: &ast::Generics) -> ~str {\n+                  generics: &ast::Generics) -> StrBuf {\n     to_str(|s| {\n         try!(s.print_fn(decl, Some(fn_style), abi::Rust,\n                         name, generics, opt_explicit_self, ast::Inherited));\n@@ -210,7 +210,7 @@ pub fn fun_to_str(decl: &ast::FnDecl, fn_style: ast::FnStyle, name: ast::Ident,\n     })\n }\n \n-pub fn block_to_str(blk: &ast::Block) -> ~str {\n+pub fn block_to_str(blk: &ast::Block) -> StrBuf {\n     to_str(|s| {\n         // containing cbox, will be closed by print-block at }\n         try!(s.cbox(indent_unit));\n@@ -220,30 +220,30 @@ pub fn block_to_str(blk: &ast::Block) -> ~str {\n     })\n }\n \n-pub fn meta_item_to_str(mi: &ast::MetaItem) -> ~str {\n+pub fn meta_item_to_str(mi: &ast::MetaItem) -> StrBuf {\n     to_str(|s| s.print_meta_item(mi))\n }\n \n-pub fn attribute_to_str(attr: &ast::Attribute) -> ~str {\n+pub fn attribute_to_str(attr: &ast::Attribute) -> StrBuf {\n     to_str(|s| s.print_attribute(attr))\n }\n \n-pub fn lit_to_str(l: &ast::Lit) -> ~str {\n+pub fn lit_to_str(l: &ast::Lit) -> StrBuf {\n     to_str(|s| s.print_literal(l))\n }\n \n-pub fn explicit_self_to_str(explicit_self: ast::ExplicitSelf_) -> ~str {\n+pub fn explicit_self_to_str(explicit_self: ast::ExplicitSelf_) -> StrBuf {\n     to_str(|s| s.print_explicit_self(explicit_self, ast::MutImmutable).map(|_| {}))\n }\n \n-pub fn variant_to_str(var: &ast::Variant) -> ~str {\n+pub fn variant_to_str(var: &ast::Variant) -> StrBuf {\n     to_str(|s| s.print_variant(var))\n }\n \n-pub fn visibility_qualified(vis: ast::Visibility, s: &str) -> ~str {\n+pub fn visibility_qualified(vis: ast::Visibility, s: &str) -> StrBuf {\n     match vis {\n-        ast::Public => format!(\"pub {}\", s),\n-        ast::Inherited => s.to_owned()\n+        ast::Public => format!(\"pub {}\", s).to_strbuf(),\n+        ast::Inherited => s.to_strbuf()\n     }\n }\n \n@@ -366,10 +366,10 @@ impl<'a> State<'a> {\n \n     // Synthesizes a comment that was not textually present in the original source\n     // file.\n-    pub fn synth_comment(&mut self, text: ~str) -> IoResult<()> {\n+    pub fn synth_comment(&mut self, text: StrBuf) -> IoResult<()> {\n         try!(word(&mut self.s, \"/*\"));\n         try!(space(&mut self.s));\n-        try!(word(&mut self.s, text));\n+        try!(word(&mut self.s, text.as_slice()));\n         try!(space(&mut self.s));\n         word(&mut self.s, \"*/\")\n     }\n@@ -552,7 +552,8 @@ impl<'a> State<'a> {\n                 self.end() // end the outer fn box\n             }\n             ast::ForeignItemStatic(t, m) => {\n-                try!(self.head(visibility_qualified(item.vis, \"static\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"static\").as_slice()));\n                 if m {\n                     try!(self.word_space(\"mut\"));\n                 }\n@@ -573,7 +574,8 @@ impl<'a> State<'a> {\n         try!(self.ann.pre(self, NodeItem(item)));\n         match item.node {\n             ast::ItemStatic(ty, m, expr) => {\n-                try!(self.head(visibility_qualified(item.vis, \"static\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"static\").as_slice()));\n                 if m == ast::MutMutable {\n                     try!(self.word_space(\"mut\"));\n                 }\n@@ -602,7 +604,8 @@ impl<'a> State<'a> {\n                 try!(self.print_block_with_attrs(body, item.attrs.as_slice()));\n             }\n             ast::ItemMod(ref _mod) => {\n-                try!(self.head(visibility_qualified(item.vis, \"mod\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"mod\").as_slice()));\n                 try!(self.print_ident(item.ident));\n                 try!(self.nbsp());\n                 try!(self.bopen());\n@@ -619,7 +622,8 @@ impl<'a> State<'a> {\n             ast::ItemTy(ty, ref params) => {\n                 try!(self.ibox(indent_unit));\n                 try!(self.ibox(0u));\n-                try!(self.word_nbsp(visibility_qualified(item.vis, \"type\")));\n+                try!(self.word_nbsp(visibility_qualified(item.vis,\n+                                                         \"type\").as_slice()));\n                 try!(self.print_ident(item.ident));\n                 try!(self.print_generics(params));\n                 try!(self.end()); // end the inner ibox\n@@ -643,12 +647,14 @@ impl<'a> State<'a> {\n                 if struct_def.is_virtual {\n                     try!(self.word_space(\"virtual\"));\n                 }\n-                try!(self.head(visibility_qualified(item.vis, \"struct\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"struct\").as_slice()));\n                 try!(self.print_struct(struct_def, generics, item.ident, item.span));\n             }\n \n             ast::ItemImpl(ref generics, ref opt_trait, ty, ref methods) => {\n-                try!(self.head(visibility_qualified(item.vis, \"impl\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"impl\").as_slice()));\n                 if generics.is_parameterized() {\n                     try!(self.print_generics(generics));\n                     try!(space(&mut self.s));\n@@ -674,7 +680,8 @@ impl<'a> State<'a> {\n                 try!(self.bclose(item.span));\n             }\n             ast::ItemTrait(ref generics, ref sized, ref traits, ref methods) => {\n-                try!(self.head(visibility_qualified(item.vis, \"trait\")));\n+                try!(self.head(visibility_qualified(item.vis,\n+                                                    \"trait\").as_slice()));\n                 try!(self.print_ident(item.ident));\n                 try!(self.print_generics(generics));\n                 if *sized == ast::DynSize {\n@@ -723,7 +730,7 @@ impl<'a> State<'a> {\n                           generics: &ast::Generics, ident: ast::Ident,\n                           span: codemap::Span,\n                           visibility: ast::Visibility) -> IoResult<()> {\n-        try!(self.head(visibility_qualified(visibility, \"enum\")));\n+        try!(self.head(visibility_qualified(visibility, \"enum\").as_slice()));\n         try!(self.print_ident(ident));\n         try!(self.print_generics(generics));\n         try!(space(&mut self.s));\n@@ -825,7 +832,7 @@ impl<'a> State<'a> {\n         match *tt {\n             ast::TTDelim(ref tts) => self.print_tts(&(tts.as_slice())),\n             ast::TTTok(_, ref tk) => {\n-                word(&mut self.s, parse::token::to_str(tk))\n+                word(&mut self.s, parse::token::to_str(tk).as_slice())\n             }\n             ast::TTSeq(_, ref tts, ref sep, zerok) => {\n                 try!(word(&mut self.s, \"$(\"));\n@@ -835,7 +842,8 @@ impl<'a> State<'a> {\n                 try!(word(&mut self.s, \")\"));\n                 match *sep {\n                     Some(ref tk) => {\n-                        try!(word(&mut self.s, parse::token::to_str(tk)));\n+                        try!(word(&mut self.s,\n+                                  parse::token::to_str(tk).as_slice()));\n                     }\n                     None => ()\n                 }\n@@ -2189,7 +2197,7 @@ impl<'a> State<'a> {\n         try!(self.maybe_print_comment(lit.span.lo));\n         match self.next_lit(lit.span.lo) {\n             Some(ref ltrl) => {\n-                return word(&mut self.s, (*ltrl).lit);\n+                return word(&mut self.s, (*ltrl).lit.as_slice());\n             }\n             _ => ()\n         }\n@@ -2202,16 +2210,19 @@ impl<'a> State<'a> {\n                 word(&mut self.s, res.into_owned())\n             }\n             ast::LitInt(i, t) => {\n-                word(&mut self.s, ast_util::int_ty_to_str(t, Some(i)))\n+                word(&mut self.s,\n+                     ast_util::int_ty_to_str(t, Some(i)).as_slice())\n             }\n             ast::LitUint(u, t) => {\n-                word(&mut self.s, ast_util::uint_ty_to_str(t, Some(u)))\n+                word(&mut self.s,\n+                     ast_util::uint_ty_to_str(t, Some(u)).as_slice())\n             }\n             ast::LitIntUnsuffixed(i) => {\n                 word(&mut self.s, format!(\"{}\", i))\n             }\n             ast::LitFloat(ref f, t) => {\n-                word(&mut self.s, f.get() + ast_util::float_ty_to_str(t))\n+                word(&mut self.s,\n+                     f.get() + ast_util::float_ty_to_str(t).as_slice())\n             }\n             ast::LitFloatUnsuffixed(ref f) => word(&mut self.s, f.get()),\n             ast::LitNil => word(&mut self.s, \"()\"),\n@@ -2266,7 +2277,7 @@ impl<'a> State<'a> {\n             comments::Mixed => {\n                 assert_eq!(cmnt.lines.len(), 1u);\n                 try!(zerobreak(&mut self.s));\n-                try!(word(&mut self.s, *cmnt.lines.get(0)));\n+                try!(word(&mut self.s, cmnt.lines.get(0).as_slice()));\n                 zerobreak(&mut self.s)\n             }\n             comments::Isolated => {\n@@ -2275,7 +2286,7 @@ impl<'a> State<'a> {\n                     // Don't print empty lines because they will end up as trailing\n                     // whitespace\n                     if !line.is_empty() {\n-                        try!(word(&mut self.s, *line));\n+                        try!(word(&mut self.s, line.as_slice()));\n                     }\n                     try!(hardbreak(&mut self.s));\n                 }\n@@ -2284,13 +2295,13 @@ impl<'a> State<'a> {\n             comments::Trailing => {\n                 try!(word(&mut self.s, \" \"));\n                 if cmnt.lines.len() == 1u {\n-                    try!(word(&mut self.s, *cmnt.lines.get(0)));\n+                    try!(word(&mut self.s, cmnt.lines.get(0).as_slice()));\n                     hardbreak(&mut self.s)\n                 } else {\n                     try!(self.ibox(0u));\n                     for line in cmnt.lines.iter() {\n                         if !line.is_empty() {\n-                            try!(word(&mut self.s, *line));\n+                            try!(word(&mut self.s, line.as_slice()));\n                         }\n                         try!(hardbreak(&mut self.s));\n                     }\n@@ -2300,7 +2311,7 @@ impl<'a> State<'a> {\n             comments::BlankLine => {\n                 // We need to do at least one, possibly two hardbreaks.\n                 let is_semi = match self.s.last_token() {\n-                    pp::String(s, _) => \";\" == s,\n+                    pp::String(s, _) => \";\" == s.as_slice(),\n                     _ => false\n                 };\n                 if is_semi || self.is_begin() || self.is_end() {\n@@ -2371,8 +2382,9 @@ impl<'a> State<'a> {\n                                 opt_fn_style: Option<ast::FnStyle>,\n                                 abi: abi::Abi,\n                                 vis: ast::Visibility) -> IoResult<()> {\n-        try!(word(&mut self.s, visibility_qualified(vis, \"\")));\n+        try!(word(&mut self.s, visibility_qualified(vis, \"\").as_slice()));\n         try!(self.print_opt_fn_style(opt_fn_style));\n+\n         if abi != abi::Rust {\n             try!(self.word_nbsp(\"extern\"));\n             try!(self.word_nbsp(abi.to_str()));\n@@ -2420,7 +2432,7 @@ mod test {\n         let generics = ast_util::empty_generics();\n         assert_eq!(&fun_to_str(&decl, ast::NormalFn, abba_ident,\n                                None, &generics),\n-                   &\"fn abba()\".to_owned());\n+                   &\"fn abba()\".to_strbuf());\n     }\n \n     #[test]\n@@ -2438,6 +2450,6 @@ mod test {\n         });\n \n         let varstr = variant_to_str(&var);\n-        assert_eq!(&varstr,&\"pub principal_skinner\".to_owned());\n+        assert_eq!(&varstr,&\"pub principal_skinner\".to_strbuf());\n     }\n }"}, {"sha": "7f85684572286fd05433cb563263065f9cd742ea", "filename": "src/libsyntax/util/interner.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Futil%2Finterner.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Futil%2Finterner.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Finterner.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -92,7 +92,7 @@ impl<T: TotalEq + Hash + Clone + 'static> Interner<T> {\n \n #[deriving(Clone, Eq, Hash, Ord)]\n pub struct RcStr {\n-    string: Rc<~str>,\n+    string: Rc<StrBuf>,\n }\n \n impl TotalEq for RcStr {}\n@@ -106,7 +106,7 @@ impl TotalOrd for RcStr {\n impl Str for RcStr {\n     #[inline]\n     fn as_slice<'a>(&'a self) -> &'a str {\n-        let s: &'a str = *self.string;\n+        let s: &'a str = self.string.as_slice();\n         s\n     }\n }\n@@ -121,7 +121,7 @@ impl fmt::Show for RcStr {\n impl RcStr {\n     pub fn new(string: &str) -> RcStr {\n         RcStr {\n-            string: Rc::new(string.to_owned()),\n+            string: Rc::new(string.to_strbuf()),\n         }\n     }\n }"}, {"sha": "359a8537b2b57d43818d06fce0cf8ccee0c3b4e8", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 14, "deletions": 10, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aa6725407ae0a2cb88458e147e76adf8bcae0961/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=aa6725407ae0a2cb88458e147e76adf8bcae0961", "patch": "@@ -16,17 +16,21 @@ use parse::parser::Parser;\n use parse::token;\n \n // map a string to tts, using a made-up filename:\n-pub fn string_to_tts(source_str: ~str) -> Vec<ast::TokenTree> {\n+pub fn string_to_tts(source_str: StrBuf) -> Vec<ast::TokenTree> {\n     let ps = new_parse_sess();\n-    filemap_to_tts(&ps, string_to_filemap(&ps, source_str,\"bogofile\".to_owned()))\n+    filemap_to_tts(&ps,\n+                   string_to_filemap(&ps, source_str, \"bogofile\".to_strbuf()))\n }\n \n // map string to parser (via tts)\n-pub fn string_to_parser<'a>(ps: &'a ParseSess, source_str: ~str) -> Parser<'a> {\n-    new_parser_from_source_str(ps, Vec::new(), \"bogofile\".to_owned(), source_str)\n+pub fn string_to_parser<'a>(ps: &'a ParseSess, source_str: StrBuf) -> Parser<'a> {\n+    new_parser_from_source_str(ps,\n+                               Vec::new(),\n+                               \"bogofile\".to_strbuf(),\n+                               source_str)\n }\n \n-fn with_error_checking_parse<T>(s: ~str, f: |&mut Parser| -> T) -> T {\n+fn with_error_checking_parse<T>(s: StrBuf, f: |&mut Parser| -> T) -> T {\n     let ps = new_parse_sess();\n     let mut p = string_to_parser(&ps, s);\n     let x = f(&mut p);\n@@ -35,36 +39,36 @@ fn with_error_checking_parse<T>(s: ~str, f: |&mut Parser| -> T) -> T {\n }\n \n // parse a string, return a crate.\n-pub fn string_to_crate (source_str : ~str) -> ast::Crate {\n+pub fn string_to_crate (source_str : StrBuf) -> ast::Crate {\n     with_error_checking_parse(source_str, |p| {\n         p.parse_crate_mod()\n     })\n }\n \n // parse a string, return an expr\n-pub fn string_to_expr (source_str : ~str) -> @ast::Expr {\n+pub fn string_to_expr (source_str : StrBuf) -> @ast::Expr {\n     with_error_checking_parse(source_str, |p| {\n         p.parse_expr()\n     })\n }\n \n // parse a string, return an item\n-pub fn string_to_item (source_str : ~str) -> Option<@ast::Item> {\n+pub fn string_to_item (source_str : StrBuf) -> Option<@ast::Item> {\n     with_error_checking_parse(source_str, |p| {\n         p.parse_item(Vec::new())\n     })\n }\n \n // parse a string, return a stmt\n-pub fn string_to_stmt(source_str : ~str) -> @ast::Stmt {\n+pub fn string_to_stmt(source_str : StrBuf) -> @ast::Stmt {\n     with_error_checking_parse(source_str, |p| {\n         p.parse_stmt(Vec::new())\n     })\n }\n \n // parse a string, return a pat. Uses \"irrefutable\"... which doesn't\n // (currently) affect parsing.\n-pub fn string_to_pat(source_str: ~str) -> @ast::Pat {\n+pub fn string_to_pat(source_str: StrBuf) -> @ast::Pat {\n     string_to_parser(&new_parse_sess(), source_str).parse_pat()\n }\n "}]}