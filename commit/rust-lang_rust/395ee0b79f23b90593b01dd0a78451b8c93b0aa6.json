{"sha": "395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM5NWVlMGI3OWYyM2I5MDU5M2IwMWRkMGE3ODQ1MWI4YzkzYjBhYTY=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-05-06T08:53:40Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-20T18:12:34Z"}, "message": "Introduce rustc_lexer\n\nThe idea here is to make a reusable library out of the existing\nrust-lexer, by separating out pure lexing and rustc-specific concerns,\nlike spans, error reporting an interning.\n\nSo, rustc_lexer operates directly on `&str`, produces simple tokens\nwhich are a pair of type-tag and a bit of original text, and does not\nreport errors, instead storing them as flags on the token.", "tree": {"sha": "46544580dab78a9ce0e2ad59231c65709955ba2d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/46544580dab78a9ce0e2ad59231c65709955ba2d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "html_url": "https://github.com/rust-lang/rust/commit/395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "95b1fe560d2bd8472f250fb8cfd2168520a58405", "url": "https://api.github.com/repos/rust-lang/rust/commits/95b1fe560d2bd8472f250fb8cfd2168520a58405", "html_url": "https://github.com/rust-lang/rust/commit/95b1fe560d2bd8472f250fb8cfd2168520a58405"}], "stats": {"total": 2594, "additions": 1335, "deletions": 1259}, "files": [{"sha": "bdc746c0bb0e0d82a4d3ce13db4baeb701951e30", "filename": "Cargo.lock", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -2972,6 +2972,13 @@ dependencies = [\n  \"tempfile 3.0.5 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n+[[package]]\n+name = \"rustc_lexer\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"unicode-xid 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n+]\n+\n [[package]]\n name = \"rustc_lint\"\n version = \"0.0.0\"\n@@ -3622,6 +3629,7 @@ dependencies = [\n  \"log 0.4.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc_data_structures 0.0.0\",\n  \"rustc_errors 0.0.0\",\n+ \"rustc_lexer 0.1.0\",\n  \"rustc_macros 0.1.0\",\n  \"rustc_target 0.0.0\",\n  \"scoped-tls 1.0.0 (registry+https://github.com/rust-lang/crates.io-index)\","}, {"sha": "9c0230e83221f05e5123ef0d066c4ce5ecaf487c", "filename": "src/librustc_lexer/Cargo.toml", "status": "added", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2FCargo.toml?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -0,0 +1,9 @@\n+[package]\n+authors = [\"The Rust Project Developers\"]\n+name = \"rustc_lexer\"\n+version = \"0.1.0\"\n+edition = \"2018\"\n+\n+# Note that this crate purposefully does not depend on other rustc crates\n+[dependencies]\n+unicode-xid = { version = \"0.1.0\", optional = true }"}, {"sha": "5831159c344d7850708172ad2eadf0196263f9e2", "filename": "src/librustc_lexer/src/cursor.rs", "status": "added", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Fcursor.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -0,0 +1,57 @@\n+use std::str::Chars;\n+\n+pub(crate) struct Cursor<'a> {\n+    initial_len: usize,\n+    chars: Chars<'a>,\n+    #[cfg(debug_assertions)]\n+    prev: char,\n+}\n+\n+pub(crate) const EOF_CHAR: char = '\\0';\n+\n+impl<'a> Cursor<'a> {\n+    pub(crate) fn new(input: &'a str) -> Cursor<'a> {\n+        Cursor {\n+            initial_len: input.len(),\n+            chars: input.chars(),\n+            #[cfg(debug_assertions)]\n+            prev: EOF_CHAR,\n+        }\n+    }\n+    /// For debug assertions only\n+    pub(crate) fn prev(&self) -> char {\n+        #[cfg(debug_assertions)]\n+        {\n+            self.prev\n+        }\n+\n+        #[cfg(not(debug_assertions))]\n+        {\n+            '\\0'\n+        }\n+    }\n+    pub(crate) fn nth_char(&self, n: usize) -> char {\n+        self.chars().nth(n).unwrap_or(EOF_CHAR)\n+    }\n+    pub(crate) fn is_eof(&self) -> bool {\n+        self.chars.as_str().is_empty()\n+    }\n+    pub(crate) fn len_consumed(&self) -> usize {\n+        self.initial_len - self.chars.as_str().len()\n+    }\n+    /// Returns an iterator over the remaining characters.\n+    fn chars(&self) -> Chars<'a> {\n+        self.chars.clone()\n+    }\n+    /// Moves to the next character.\n+    pub(crate) fn bump(&mut self) -> Option<char> {\n+        let c = self.chars.next()?;\n+\n+        #[cfg(debug_assertions)]\n+        {\n+            self.prev = c;\n+        }\n+\n+        Some(c)\n+    }\n+}"}, {"sha": "a21190ec33244a27e31f3ceb31bbdaa26bb75c26", "filename": "src/librustc_lexer/src/lib.rs", "status": "added", "additions": 710, "deletions": 0, "changes": 710, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Flib.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -0,0 +1,710 @@\n+// We want to be able to build this crate with a stable compiler, so feature\n+// flags should optional.\n+#![cfg_attr(not(feature = \"unicode-xid\"), feature(rustc_private))]\n+#![cfg_attr(not(feature = \"unicode-xid\"), feature(unicode_internals))]\n+\n+mod cursor;\n+\n+use crate::cursor::{Cursor, EOF_CHAR};\n+\n+pub struct Token {\n+    pub kind: TokenKind,\n+    pub len: usize,\n+}\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n+pub enum TokenKind {\n+    LineComment,\n+    BlockComment { terminated: bool },\n+    Whitespace,\n+    Ident,\n+    RawIdent,\n+    Literal { kind: LiteralKind, suffix_start: usize },\n+    Lifetime { starts_with_number: bool },\n+    Semi,\n+    Comma,\n+    DotDotDot,\n+    DotDotEq,\n+    DotDot,\n+    Dot,\n+    OpenParen,\n+    CloseParen,\n+    OpenBrace,\n+    CloseBrace,\n+    OpenBracket,\n+    CloseBracket,\n+    At,\n+    Pound,\n+    Tilde,\n+    Question,\n+    ColonColon,\n+    Colon,\n+    Dollar,\n+    EqEq,\n+    Eq,\n+    FatArrow,\n+    Ne,\n+    Not,\n+    Le,\n+    LArrow,\n+    Lt,\n+    ShlEq,\n+    Shl,\n+    Ge,\n+    Gt,\n+    ShrEq,\n+    Shr,\n+    RArrow,\n+    Minus,\n+    MinusEq,\n+    And,\n+    AndAnd,\n+    AndEq,\n+    Or,\n+    OrOr,\n+    OrEq,\n+    PlusEq,\n+    Plus,\n+    StarEq,\n+    Star,\n+    SlashEq,\n+    Slash,\n+    CaretEq,\n+    Caret,\n+    PercentEq,\n+    Percent,\n+    Unknown,\n+}\n+use self::TokenKind::*;\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n+pub enum LiteralKind {\n+    Int { base: Base, empty_int: bool },\n+    Float { base: Base, empty_exponent: bool },\n+    Char { terminated: bool },\n+    Byte { terminated: bool },\n+    Str { terminated: bool },\n+    ByteStr { terminated: bool },\n+    RawStr { n_hashes: usize, started: bool, terminated: bool },\n+    RawByteStr { n_hashes: usize, started: bool, terminated: bool },\n+}\n+use self::LiteralKind::*;\n+\n+#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n+pub enum Base {\n+    Binary,\n+    Octal,\n+    Hexadecimal,\n+    Decimal,\n+}\n+\n+impl Token {\n+    fn new(kind: TokenKind, len: usize) -> Token {\n+        Token { kind, len }\n+    }\n+}\n+\n+pub fn strip_shebang(input: &str) -> Option<usize> {\n+    debug_assert!(!input.is_empty());\n+    if !input.starts_with(\"#!\") || input.starts_with(\"#![\") {\n+        return None;\n+    }\n+    Some(input.find('\\n').unwrap_or(input.len()))\n+}\n+\n+pub fn first_token(input: &str) -> Token {\n+    debug_assert!(!input.is_empty());\n+    Cursor::new(input).advance_token()\n+}\n+\n+pub fn tokenize(mut input: &str) -> impl Iterator<Item = Token> + '_ {\n+    std::iter::from_fn(move || {\n+        if input.is_empty() {\n+            return None;\n+        }\n+        let token = first_token(input);\n+        input = &input[token.len..];\n+        Some(token)\n+    })\n+}\n+\n+impl Cursor<'_> {\n+    fn advance_token(&mut self) -> Token {\n+        let first_char = self.bump().unwrap();\n+        let token_kind = match first_char {\n+            '/' => match self.nth_char(0) {\n+                '/' => self.line_comment(),\n+                '*' => self.block_comment(),\n+                _ => {\n+                    if self.eat_assign() {\n+                        SlashEq\n+                    } else {\n+                        Slash\n+                    }\n+                }\n+            },\n+            c if character_properties::is_whitespace(c) => self.whitespace(),\n+            'r' => match (self.nth_char(0), self.nth_char(1)) {\n+                ('#', c1) if character_properties::is_id_start(c1) => self.raw_ident(),\n+                ('#', _) | ('\"', _) => {\n+                    let (n_hashes, started, terminated) = self.raw_double_quoted_string();\n+                    let suffix_start = self.len_consumed();\n+                    if terminated {\n+                        self.eat_literal_suffix();\n+                    }\n+                    let kind = RawStr { n_hashes, started, terminated };\n+                    Literal { kind, suffix_start }\n+                }\n+                _ => self.ident(),\n+            },\n+            'b' => match (self.nth_char(0), self.nth_char(1)) {\n+                ('\\'', _) => {\n+                    self.bump();\n+                    let terminated = self.single_quoted_string();\n+                    let suffix_start = self.len_consumed();\n+                    if terminated {\n+                        self.eat_literal_suffix();\n+                    }\n+                    let kind = Byte { terminated };\n+                    Literal { kind, suffix_start }\n+                }\n+                ('\"', _) => {\n+                    self.bump();\n+                    let terminated = self.double_quoted_string();\n+                    let suffix_start = self.len_consumed();\n+                    if terminated {\n+                        self.eat_literal_suffix();\n+                    }\n+                    let kind = ByteStr { terminated };\n+                    Literal { kind, suffix_start }\n+                }\n+                ('r', '\"') | ('r', '#') => {\n+                    self.bump();\n+                    let (n_hashes, started, terminated) = self.raw_double_quoted_string();\n+                    let suffix_start = self.len_consumed();\n+                    if terminated {\n+                        self.eat_literal_suffix();\n+                    }\n+                    let kind = RawByteStr { n_hashes, started, terminated };\n+                    Literal { kind, suffix_start }\n+                }\n+                _ => self.ident(),\n+            },\n+            c if character_properties::is_id_start(c) => self.ident(),\n+            c @ '0'..='9' => {\n+                let literal_kind = self.number(c);\n+                let suffix_start = self.len_consumed();\n+                self.eat_literal_suffix();\n+                TokenKind::Literal { kind: literal_kind, suffix_start }\n+            }\n+            ';' => Semi,\n+            ',' => Comma,\n+            '.' => {\n+                if self.nth_char(0) == '.' {\n+                    self.bump();\n+                    if self.nth_char(0) == '.' {\n+                        self.bump();\n+                        DotDotDot\n+                    } else if self.nth_char(0) == '=' {\n+                        self.bump();\n+                        DotDotEq\n+                    } else {\n+                        DotDot\n+                    }\n+                } else {\n+                    Dot\n+                }\n+            }\n+            '(' => OpenParen,\n+            ')' => CloseParen,\n+            '{' => OpenBrace,\n+            '}' => CloseBrace,\n+            '[' => OpenBracket,\n+            ']' => CloseBracket,\n+            '@' => At,\n+            '#' => Pound,\n+            '~' => Tilde,\n+            '?' => Question,\n+            ':' => {\n+                if self.nth_char(0) == ':' {\n+                    self.bump();\n+                    ColonColon\n+                } else {\n+                    Colon\n+                }\n+            }\n+            '$' => Dollar,\n+            '=' => {\n+                if self.nth_char(0) == '=' {\n+                    self.bump();\n+                    EqEq\n+                } else if self.nth_char(0) == '>' {\n+                    self.bump();\n+                    FatArrow\n+                } else {\n+                    Eq\n+                }\n+            }\n+            '!' => {\n+                if self.nth_char(0) == '=' {\n+                    self.bump();\n+                    Ne\n+                } else {\n+                    Not\n+                }\n+            }\n+            '<' => match self.nth_char(0) {\n+                '=' => {\n+                    self.bump();\n+                    Le\n+                }\n+                '<' => {\n+                    self.bump();\n+                    if self.eat_assign() { ShlEq } else { Shl }\n+                }\n+                '-' => {\n+                    self.bump();\n+                    LArrow\n+                }\n+                _ => Lt,\n+            },\n+            '>' => match self.nth_char(0) {\n+                '=' => {\n+                    self.bump();\n+                    Ge\n+                }\n+                '>' => {\n+                    self.bump();\n+                    if self.eat_assign() { ShrEq } else { Shr }\n+                }\n+                _ => Gt,\n+            },\n+            '-' => {\n+                if self.nth_char(0) == '>' {\n+                    self.bump();\n+                    RArrow\n+                } else {\n+                    if self.eat_assign() { MinusEq } else { Minus }\n+                }\n+            }\n+            '&' => {\n+                if self.nth_char(0) == '&' {\n+                    self.bump();\n+                    AndAnd\n+                } else {\n+                    if self.eat_assign() { AndEq } else { And }\n+                }\n+            }\n+            '|' => {\n+                if self.nth_char(0) == '|' {\n+                    self.bump();\n+                    OrOr\n+                } else {\n+                    if self.eat_assign() { OrEq } else { Or }\n+                }\n+            }\n+            '+' => {\n+                if self.eat_assign() {\n+                    PlusEq\n+                } else {\n+                    Plus\n+                }\n+            }\n+            '*' => {\n+                if self.eat_assign() {\n+                    StarEq\n+                } else {\n+                    Star\n+                }\n+            }\n+            '^' => {\n+                if self.eat_assign() {\n+                    CaretEq\n+                } else {\n+                    Caret\n+                }\n+            }\n+            '%' => {\n+                if self.eat_assign() {\n+                    PercentEq\n+                } else {\n+                    Percent\n+                }\n+            }\n+            '\\'' => self.lifetime_or_char(),\n+            '\"' => {\n+                let terminated = self.double_quoted_string();\n+                let suffix_start = self.len_consumed();\n+                if terminated {\n+                    self.eat_literal_suffix();\n+                }\n+                let kind = Str { terminated };\n+                Literal { kind, suffix_start }\n+            }\n+            _ => Unknown,\n+        };\n+        Token::new(token_kind, self.len_consumed())\n+    }\n+\n+    fn line_comment(&mut self) -> TokenKind {\n+        debug_assert!(self.prev() == '/' && self.nth_char(0) == '/');\n+        self.bump();\n+        loop {\n+            match self.nth_char(0) {\n+                '\\n' => break,\n+                '\\r' if self.nth_char(1) == '\\n' => break,\n+                EOF_CHAR if self.is_eof() => break,\n+                _ => {\n+                    self.bump();\n+                }\n+            }\n+        }\n+        LineComment\n+    }\n+\n+    fn block_comment(&mut self) -> TokenKind {\n+        debug_assert!(self.prev() == '/' && self.nth_char(0) == '*');\n+        self.bump();\n+        let mut depth = 1usize;\n+        while let Some(c) = self.bump() {\n+            match c {\n+                '/' if self.nth_char(0) == '*' => {\n+                    self.bump();\n+                    depth += 1;\n+                }\n+                '*' if self.nth_char(0) == '/' => {\n+                    self.bump();\n+                    depth -= 1;\n+                    if depth == 0 {\n+                        break;\n+                    }\n+                }\n+                _ => (),\n+            }\n+        }\n+\n+        BlockComment { terminated: depth == 0 }\n+    }\n+\n+    fn whitespace(&mut self) -> TokenKind {\n+        debug_assert!(character_properties::is_whitespace(self.prev()));\n+        while character_properties::is_whitespace(self.nth_char(0)) {\n+            self.bump();\n+        }\n+        Whitespace\n+    }\n+\n+    fn raw_ident(&mut self) -> TokenKind {\n+        debug_assert!(\n+            self.prev() == 'r'\n+                && self.nth_char(0) == '#'\n+                && character_properties::is_id_start(self.nth_char(1))\n+        );\n+        self.bump();\n+        self.bump();\n+        while character_properties::is_id_continue(self.nth_char(0)) {\n+            self.bump();\n+        }\n+        RawIdent\n+    }\n+\n+    fn ident(&mut self) -> TokenKind {\n+        debug_assert!(character_properties::is_id_start(self.prev()));\n+        while character_properties::is_id_continue(self.nth_char(0)) {\n+            self.bump();\n+        }\n+        Ident\n+    }\n+\n+    fn number(&mut self, first_digit: char) -> LiteralKind {\n+        debug_assert!('0' <= self.prev() && self.prev() <= '9');\n+        let mut base = Base::Decimal;\n+        if first_digit == '0' {\n+            let has_digits = match self.nth_char(0) {\n+                'b' => {\n+                    base = Base::Binary;\n+                    self.bump();\n+                    self.eat_decimal_digits()\n+                }\n+                'o' => {\n+                    base = Base::Octal;\n+                    self.bump();\n+                    self.eat_decimal_digits()\n+                }\n+                'x' => {\n+                    base = Base::Hexadecimal;\n+                    self.bump();\n+                    self.eat_hexadecimal_digits()\n+                }\n+                '0'..='9' | '_' | '.' | 'e' | 'E' => {\n+                    self.eat_decimal_digits();\n+                    true\n+                }\n+                // just a 0\n+                _ => return Int { base, empty_int: false },\n+            };\n+            if !has_digits {\n+                return Int { base, empty_int: true };\n+            }\n+        } else {\n+            self.eat_decimal_digits();\n+        };\n+\n+        match self.nth_char(0) {\n+            // Don't be greedy if this is actually an\n+            // integer literal followed by field/method access or a range pattern\n+            // (`0..2` and `12.foo()`)\n+            '.' if self.nth_char(1) != '.'\n+                && !character_properties::is_id_start(self.nth_char(1)) =>\n+            {\n+                // might have stuff after the ., and if it does, it needs to start\n+                // with a number\n+                self.bump();\n+                let mut empty_exponent = false;\n+                if self.nth_char(0).is_digit(10) {\n+                    self.eat_decimal_digits();\n+                    match self.nth_char(0) {\n+                        'e' | 'E' => {\n+                            self.bump();\n+                            empty_exponent = self.float_exponent().is_err()\n+                        }\n+                        _ => (),\n+                    }\n+                }\n+                Float { base, empty_exponent }\n+            }\n+            'e' | 'E' => {\n+                self.bump();\n+                let empty_exponent = self.float_exponent().is_err();\n+                Float { base, empty_exponent }\n+            }\n+            _ => Int { base, empty_int: false },\n+        }\n+    }\n+\n+    fn lifetime_or_char(&mut self) -> TokenKind {\n+        debug_assert!(self.prev() == '\\'');\n+        let mut starts_with_number = false;\n+        if (character_properties::is_id_start(self.nth_char(0))\n+            || self.nth_char(0).is_digit(10) && {\n+                starts_with_number = true;\n+                true\n+            })\n+            && self.nth_char(1) != '\\''\n+        {\n+            self.bump();\n+            while character_properties::is_id_continue(self.nth_char(0)) {\n+                self.bump();\n+            }\n+\n+            return if self.nth_char(0) == '\\'' {\n+                self.bump();\n+                let kind = Char { terminated: true };\n+                Literal { kind, suffix_start: self.len_consumed() }\n+            } else {\n+                Lifetime { starts_with_number }\n+            };\n+        }\n+        let terminated = self.single_quoted_string();\n+        let suffix_start = self.len_consumed();\n+        if terminated {\n+            self.eat_literal_suffix();\n+        }\n+        let kind = Char { terminated };\n+        return Literal { kind, suffix_start };\n+    }\n+\n+    fn single_quoted_string(&mut self) -> bool {\n+        debug_assert!(self.prev() == '\\'');\n+        // parse `'''` as a single char literal\n+        if self.nth_char(0) == '\\'' && self.nth_char(1) == '\\'' {\n+            self.bump();\n+        }\n+        let mut first = true;\n+        loop {\n+            match self.nth_char(0) {\n+                '/' if !first => break,\n+                '\\n' if self.nth_char(1) != '\\'' => break,\n+                '\\r' if self.nth_char(1) == '\\n' => break,\n+                EOF_CHAR if self.is_eof() => break,\n+                '\\'' => {\n+                    self.bump();\n+                    return true;\n+                }\n+                '\\\\' => {\n+                    self.bump();\n+                    self.bump();\n+                }\n+                _ => {\n+                    self.bump();\n+                }\n+            }\n+            first = false;\n+        }\n+        false\n+    }\n+\n+    fn double_quoted_string(&mut self) -> bool {\n+        debug_assert!(self.prev() == '\"');\n+        loop {\n+            match self.nth_char(0) {\n+                '\"' => {\n+                    self.bump();\n+                    return true;\n+                }\n+                EOF_CHAR if self.is_eof() => return false,\n+                '\\\\' if self.nth_char(1) == '\\\\' || self.nth_char(1) == '\"' => {\n+                    self.bump();\n+                }\n+                _ => (),\n+            }\n+            self.bump();\n+        }\n+    }\n+\n+    fn raw_double_quoted_string(&mut self) -> (usize, bool, bool) {\n+        debug_assert!(self.prev() == 'r');\n+        let n_hashes = {\n+            let mut acc: usize = 0;\n+            loop {\n+                match self.bump() {\n+                    Some('#') => acc += 1,\n+                    Some('\"') => break acc,\n+                    None | Some(_) => return (acc, false, false),\n+                }\n+            }\n+        };\n+\n+        loop {\n+            match self.bump() {\n+                Some('\"') => {\n+                    let mut acc = n_hashes;\n+                    while self.nth_char(0) == '#' && acc > 0 {\n+                        self.bump();\n+                        acc -= 1;\n+                    }\n+                    if acc == 0 {\n+                        return (n_hashes, true, true);\n+                    }\n+                }\n+                Some(_) => (),\n+                None => return (n_hashes, true, false),\n+            }\n+        }\n+    }\n+\n+    fn eat_decimal_digits(&mut self) -> bool {\n+        let mut has_digits = false;\n+        loop {\n+            match self.nth_char(0) {\n+                '_' => {\n+                    self.bump();\n+                }\n+                '0'..='9' => {\n+                    has_digits = true;\n+                    self.bump();\n+                }\n+                _ => break,\n+            }\n+        }\n+        has_digits\n+    }\n+\n+    fn eat_hexadecimal_digits(&mut self) -> bool {\n+        let mut has_digits = false;\n+        loop {\n+            match self.nth_char(0) {\n+                '_' => {\n+                    self.bump();\n+                }\n+                '0'..='9' | 'a'..='f' | 'A'..='F' => {\n+                    has_digits = true;\n+                    self.bump();\n+                }\n+                _ => break,\n+            }\n+        }\n+        has_digits\n+    }\n+\n+    fn float_exponent(&mut self) -> Result<(), ()> {\n+        debug_assert!(self.prev() == 'e' || self.prev() == 'E');\n+        if self.nth_char(0) == '-' || self.nth_char(0) == '+' {\n+            self.bump();\n+        }\n+        if self.eat_decimal_digits() { Ok(()) } else { Err(()) }\n+    }\n+\n+    fn eat_literal_suffix(&mut self) {\n+        if !character_properties::is_id_start(self.nth_char(0)) {\n+            return;\n+        }\n+        self.bump();\n+\n+        while character_properties::is_id_continue(self.nth_char(0)) {\n+            self.bump();\n+        }\n+    }\n+\n+    fn eat_assign(&mut self) -> bool {\n+        if self.nth_char(0) == '=' {\n+            self.bump();\n+            true\n+        } else {\n+            false\n+        }\n+    }\n+}\n+\n+pub mod character_properties {\n+    // this is Pattern_White_Space\n+    #[cfg(feature = \"unicode-xid\")]\n+    pub fn is_whitespace(c: char) -> bool {\n+        match c {\n+            '\\u{0009}' | '\\u{000A}' | '\\u{000B}' | '\\u{000C}' | '\\u{000D}' | '\\u{0020}'\n+            | '\\u{0085}' | '\\u{200E}' | '\\u{200F}' | '\\u{2028}' | '\\u{2029}' => true,\n+            _ => false,\n+        }\n+    }\n+\n+    #[cfg(not(feature = \"unicode-xid\"))]\n+    pub fn is_whitespace(c: char) -> bool {\n+        core::unicode::property::Pattern_White_Space(c)\n+    }\n+\n+    // this is XID_Start OR '_' (which formally is not a XID_Start)\n+    #[cfg(feature = \"unicode-xid\")]\n+    pub fn is_id_start(c: char) -> bool {\n+        ('a' <= c && c <= 'z')\n+            || ('A' <= c && c <= 'Z')\n+            || c == '_'\n+            || (c > '\\x7f' && unicode_xid::UnicodeXID::is_xid_start(c))\n+    }\n+\n+    #[cfg(not(feature = \"unicode-xid\"))]\n+    pub fn is_id_start(c: char) -> bool {\n+        ('a' <= c && c <= 'z')\n+            || ('A' <= c && c <= 'Z')\n+            || c == '_'\n+            || (c > '\\x7f' && c.is_xid_start())\n+    }\n+\n+    // this is XID_Continue\n+    #[cfg(feature = \"unicode-xid\")]\n+    pub fn is_id_continue(c: char) -> bool {\n+        ('a' <= c && c <= 'z')\n+            || ('A' <= c && c <= 'Z')\n+            || ('0' <= c && c <= '9')\n+            || c == '_'\n+            || (c > '\\x7f' && unicode_xid::UnicodeXID::is_xid_continue(c))\n+    }\n+\n+    #[cfg(not(feature = \"unicode-xid\"))]\n+    pub fn is_id_continue(c: char) -> bool {\n+        ('a' <= c && c <= 'z')\n+            || ('A' <= c && c <= 'Z')\n+            || ('0' <= c && c <= '9')\n+            || c == '_'\n+            || (c > '\\x7f' && c.is_xid_continue())\n+    }\n+}"}, {"sha": "15c685b3b7b504fa241fec1ebcec0637d702d166", "filename": "src/libsyntax/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2FCargo.toml?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -18,6 +18,7 @@ lazy_static = \"1.0.0\"\n syntax_pos = { path = \"../libsyntax_pos\" }\n errors = { path = \"../librustc_errors\", package = \"rustc_errors\" }\n rustc_data_structures = { path = \"../librustc_data_structures\" }\n+rustc_lexer = { path = \"../librustc_lexer\" }\n rustc_macros = { path = \"../librustc_macros\" }\n rustc_target = { path = \"../librustc_target\" }\n smallvec = { version = \"0.6.7\", features = [\"union\", \"may_dangle\"] }"}, {"sha": "d8f22072d7d366946222062d8b1cee0b50e3f24c", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 81, "deletions": 209, "changes": 290, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -2,11 +2,10 @@ pub use CommentStyle::*;\n \n use crate::ast;\n use crate::source_map::SourceMap;\n-use crate::parse::lexer::{is_block_doc_comment, is_pattern_whitespace};\n-use crate::parse::lexer::{self, ParseSess, StringReader};\n+use crate::parse::lexer::is_block_doc_comment;\n+use crate::parse::lexer::ParseSess;\n \n use syntax_pos::{BytePos, CharPos, Pos, FileName};\n-use log::debug;\n \n use std::usize;\n \n@@ -135,66 +134,6 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     panic!(\"not a doc-comment: {}\", comment);\n }\n \n-fn push_blank_line_comment(rdr: &StringReader<'_>, comments: &mut Vec<Comment>) {\n-    debug!(\">>> blank-line comment\");\n-    comments.push(Comment {\n-        style: BlankLine,\n-        lines: Vec::new(),\n-        pos: rdr.pos,\n-    });\n-}\n-\n-fn consume_whitespace_counting_blank_lines(\n-    rdr: &mut StringReader<'_>,\n-    comments: &mut Vec<Comment>\n-) {\n-    while is_pattern_whitespace(rdr.ch) && !rdr.is_eof() {\n-        if rdr.ch_is('\\n') {\n-            push_blank_line_comment(rdr, &mut *comments);\n-        }\n-        rdr.bump();\n-    }\n-}\n-\n-fn read_shebang_comment(rdr: &mut StringReader<'_>,\n-                        code_to_the_left: bool,\n-                        comments: &mut Vec<Comment>) {\n-    debug!(\">>> shebang comment\");\n-    let p = rdr.pos;\n-    debug!(\"<<< shebang comment\");\n-    comments.push(Comment {\n-        style: if code_to_the_left { Trailing } else { Isolated },\n-        lines: vec![rdr.read_one_line_comment()],\n-        pos: p,\n-    });\n-}\n-\n-fn read_line_comments(rdr: &mut StringReader<'_>,\n-                      code_to_the_left: bool,\n-                      comments: &mut Vec<Comment>) {\n-    debug!(\">>> line comments\");\n-    let p = rdr.pos;\n-    let mut lines: Vec<String> = Vec::new();\n-    while rdr.ch_is('/') && rdr.nextch_is('/') {\n-        let line = rdr.read_one_line_comment();\n-        debug!(\"{}\", line);\n-        // Doc comments are not put in comments.\n-        if is_doc_comment(&line[..]) {\n-            break;\n-        }\n-        lines.push(line);\n-        rdr.consume_non_eol_whitespace();\n-    }\n-    debug!(\"<<< line comments\");\n-    if !lines.is_empty() {\n-        comments.push(Comment {\n-            style: if code_to_the_left { Trailing } else { Isolated },\n-            lines,\n-            pos: p,\n-        });\n-    }\n-}\n-\n /// Returns `None` if the first `col` chars of `s` contain a non-whitespace char.\n /// Otherwise returns `Some(k)` where `k` is first char offset after that leading\n /// whitespace. Note that `k` may be outside bounds of `s`.\n@@ -209,170 +148,103 @@ fn all_whitespace(s: &str, col: CharPos) -> Option<usize> {\n     Some(idx)\n }\n \n-fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<String>, s: String, col: CharPos) {\n+fn trim_whitespace_prefix(s: &str, col: CharPos) -> &str {\n     let len = s.len();\n-    let s1 = match all_whitespace(&s[..], col) {\n-        Some(col) => {\n-            if col < len {\n-                s[col..len].to_string()\n-            } else {\n-                String::new()\n-            }\n-        }\n+    match all_whitespace(&s, col) {\n+        Some(col) => if col < len { &s[col..] } else { \"\" },\n         None => s,\n-    };\n-    debug!(\"pushing line: {}\", s1);\n-    lines.push(s1);\n-}\n-\n-fn read_block_comment(rdr: &mut StringReader<'_>,\n-                      code_to_the_left: bool,\n-                      comments: &mut Vec<Comment>) {\n-    debug!(\">>> block comment\");\n-    let p = rdr.pos;\n-    let mut lines: Vec<String> = Vec::new();\n-\n-    // Count the number of chars since the start of the line by rescanning.\n-    let src_index = rdr.src_index(rdr.source_file.line_begin_pos(rdr.pos));\n-    let end_src_index = rdr.src_index(rdr.pos);\n-    assert!(src_index <= end_src_index,\n-        \"src_index={}, end_src_index={}, line_begin_pos={}\",\n-        src_index, end_src_index, rdr.source_file.line_begin_pos(rdr.pos).to_u32());\n-\n-    let col = CharPos(rdr.src[src_index..end_src_index].chars().count());\n-\n-    rdr.bump();\n-    rdr.bump();\n-\n-    let mut curr_line = String::from(\"/*\");\n-\n-    // doc-comments are not really comments, they are attributes\n-    if (rdr.ch_is('*') && !rdr.nextch_is('*')) || rdr.ch_is('!') {\n-        while !(rdr.ch_is('*') && rdr.nextch_is('/')) && !rdr.is_eof() {\n-            curr_line.push(rdr.ch.unwrap());\n-            rdr.bump();\n-        }\n-        if !rdr.is_eof() {\n-            curr_line.push_str(\"*/\");\n-            rdr.bump();\n-            rdr.bump();\n-        }\n-        if is_block_doc_comment(&curr_line[..]) {\n-            return;\n-        }\n-        assert!(!curr_line.contains('\\n'));\n-        lines.push(curr_line);\n-    } else {\n-        let mut level: isize = 1;\n-        while level > 0 {\n-            debug!(\"=== block comment level {}\", level);\n-            if rdr.is_eof() {\n-                rdr.fatal_span_(rdr.pos, rdr.pos, \"unterminated block comment\").raise();\n-            }\n-            if rdr.ch_is('\\n') {\n-                trim_whitespace_prefix_and_push_line(&mut lines, curr_line, col);\n-                curr_line = String::new();\n-                rdr.bump();\n-            } else {\n-                curr_line.push(rdr.ch.unwrap());\n-                if rdr.ch_is('/') && rdr.nextch_is('*') {\n-                    rdr.bump();\n-                    rdr.bump();\n-                    curr_line.push('*');\n-                    level += 1;\n-                } else {\n-                    if rdr.ch_is('*') && rdr.nextch_is('/') {\n-                        rdr.bump();\n-                        rdr.bump();\n-                        curr_line.push('/');\n-                        level -= 1;\n-                    } else {\n-                        rdr.bump();\n-                    }\n-                }\n-            }\n-        }\n-        if !curr_line.is_empty() {\n-            trim_whitespace_prefix_and_push_line(&mut lines, curr_line, col);\n-        }\n-    }\n-\n-    let mut style = if code_to_the_left {\n-        Trailing\n-    } else {\n-        Isolated\n-    };\n-    rdr.consume_non_eol_whitespace();\n-    if !rdr.is_eof() && !rdr.ch_is('\\n') && lines.len() == 1 {\n-        style = Mixed;\n     }\n-    debug!(\"<<< block comment\");\n-    comments.push(Comment {\n-        style,\n-        lines,\n-        pos: p,\n-    });\n }\n \n-\n-fn consume_comment(rdr: &mut StringReader<'_>,\n-                   comments: &mut Vec<Comment>,\n-                   code_to_the_left: &mut bool,\n-                   anything_to_the_left: &mut bool) {\n-    debug!(\">>> consume comment\");\n-    if rdr.ch_is('/') && rdr.nextch_is('/') {\n-        read_line_comments(rdr, *code_to_the_left, comments);\n-        *code_to_the_left = false;\n-        *anything_to_the_left = false;\n-    } else if rdr.ch_is('/') && rdr.nextch_is('*') {\n-        read_block_comment(rdr, *code_to_the_left, comments);\n-        *anything_to_the_left = true;\n-    } else if rdr.ch_is('#') && rdr.nextch_is('!') {\n-        read_shebang_comment(rdr, *code_to_the_left, comments);\n-        *code_to_the_left = false;\n-        *anything_to_the_left = false;\n-    } else {\n-        panic!();\n+fn split_block_comment_into_lines(\n+    text: &str,\n+    col: CharPos,\n+) -> Vec<String> {\n+    let mut res: Vec<String> = vec![];\n+    let mut lines = text.lines();\n+    // just push the first line\n+    res.extend(lines.next().map(|it| it.to_string()));\n+    // for other lines, strip common whitespace prefix\n+    for line in lines {\n+        res.push(trim_whitespace_prefix(line, col).to_string())\n     }\n-    debug!(\"<<< consume comment\");\n+    res\n }\n \n // it appears this function is called only from pprust... that's\n // probably not a good thing.\n-pub fn gather_comments(sess: &ParseSess, path: FileName, src: String) -> Vec<Comment>\n-{\n+pub fn gather_comments(sess: &ParseSess, path: FileName, src: String) -> Vec<Comment> {\n     let cm = SourceMap::new(sess.source_map().path_mapping().clone());\n     let source_file = cm.new_source_file(path, src);\n-    let mut rdr = lexer::StringReader::new(sess, source_file, None);\n+    let text = (*source_file.src.as_ref().unwrap()).clone();\n \n+    let text: &str = text.as_str();\n+    let start_bpos = source_file.start_pos;\n+    let mut pos = 0;\n     let mut comments: Vec<Comment> = Vec::new();\n-    let mut code_to_the_left = false; // Only code\n-    let mut anything_to_the_left = false; // Code or comments\n-\n-    while !rdr.is_eof() {\n-        loop {\n-            // Eat all the whitespace and count blank lines.\n-            rdr.consume_non_eol_whitespace();\n-            if rdr.ch_is('\\n') {\n-                if anything_to_the_left {\n-                    rdr.bump(); // The line is not blank, do not count.\n+    let mut code_to_the_left = false;\n+\n+    if let Some(shebang_len) = rustc_lexer::strip_shebang(text) {\n+        comments.push(Comment {\n+            style: Isolated,\n+            lines: vec![text[..shebang_len].to_string()],\n+            pos: start_bpos,\n+        });\n+        pos += shebang_len;\n+    }\n+\n+    for token in rustc_lexer::tokenize(&text[pos..]) {\n+        let token_text = &text[pos..pos + token.len];\n+        match token.kind {\n+            rustc_lexer::TokenKind::Whitespace => {\n+                if let Some(mut idx) = token_text.find('\\n') {\n+                    code_to_the_left = false;\n+                    while let Some(next_newline) = &token_text[idx + 1..].find('\\n') {\n+                        idx = idx + 1 + next_newline;\n+                        comments.push(Comment {\n+                            style: BlankLine,\n+                            lines: vec![],\n+                            pos: start_bpos + BytePos((pos + idx) as u32),\n+                        });\n+                    }\n+                }\n+            }\n+            rustc_lexer::TokenKind::BlockComment { terminated: _ } => {\n+                if !is_block_doc_comment(token_text) {\n+                    let code_to_the_right = match text[pos + token.len..].chars().next() {\n+                        Some('\\r') | Some('\\n') => false,\n+                        _ => true,\n+                    };\n+                    let style = match (code_to_the_left, code_to_the_right) {\n+                        (true, true) | (false, true) => Mixed,\n+                        (false, false) => Isolated,\n+                        (true, false) => Trailing,\n+                    };\n+\n+                    // Count the number of chars since the start of the line by rescanning.\n+                    let pos_in_file = start_bpos + BytePos(pos as u32);\n+                    let line_begin_in_file = source_file.line_begin_pos(pos_in_file);\n+                    let line_begin_pos = (line_begin_in_file - start_bpos).to_usize();\n+                    let col = CharPos(text[line_begin_pos..pos].chars().count());\n+\n+                    let lines = split_block_comment_into_lines(token_text, col);\n+                    comments.push(Comment { style, lines, pos: pos_in_file })\n                 }\n-                consume_whitespace_counting_blank_lines(&mut rdr, &mut comments);\n-                code_to_the_left = false;\n-                anything_to_the_left = false;\n             }\n-            // Eat one comment group\n-            if rdr.peeking_at_comment() {\n-                consume_comment(&mut rdr, &mut comments,\n-                                &mut code_to_the_left, &mut anything_to_the_left);\n-            } else {\n-                break\n+            rustc_lexer::TokenKind::LineComment => {\n+                if !is_doc_comment(token_text) {\n+                    comments.push(Comment {\n+                        style: if code_to_the_left { Trailing } else { Isolated },\n+                        lines: vec![token_text.to_string()],\n+                        pos: start_bpos + BytePos(pos as u32),\n+                    })\n+                }\n+            }\n+            _ => {\n+                code_to_the_left = true;\n             }\n         }\n-\n-        rdr.next_token();\n-        code_to_the_left = true;\n-        anything_to_the_left = true;\n+        pos += token.len;\n     }\n \n     comments"}, {"sha": "317c49c7d35430721fd6dc1089928d5edefd454e", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 433, "deletions": 1014, "changes": 1447, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -6,11 +6,12 @@ use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_c\n \n use errors::{FatalError, Diagnostic, DiagnosticBuilder};\n use syntax_pos::{BytePos, Pos, Span, NO_EXPANSION};\n-use core::unicode::property::Pattern_White_Space;\n+use rustc_lexer::Base;\n \n use std::borrow::Cow;\n use std::char;\n use std::iter;\n+use std::convert::TryInto;\n use rustc_data_structures::sync::Lrc;\n use log::debug;\n \n@@ -29,12 +30,9 @@ pub struct UnmatchedBrace {\n \n pub struct StringReader<'a> {\n     crate sess: &'a ParseSess,\n-    /// The absolute offset within the source_map of the next character to read\n-    crate next_pos: BytePos,\n     /// The absolute offset within the source_map of the current character\n     crate pos: BytePos,\n     /// The current character (which has been read from self.pos)\n-    crate ch: Option<char>,\n     crate source_file: Lrc<syntax_pos::SourceFile>,\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n@@ -49,9 +47,22 @@ impl<'a> StringReader<'a> {\n     pub fn new(sess: &'a ParseSess,\n                source_file: Lrc<syntax_pos::SourceFile>,\n                override_span: Option<Span>) -> Self {\n-        let mut sr = StringReader::new_internal(sess, source_file, override_span);\n-        sr.bump();\n-        sr\n+        if source_file.src.is_none() {\n+            sess.span_diagnostic.bug(&format!(\"Cannot lex source_file without source: {}\",\n+                                              source_file.name));\n+        }\n+\n+        let src = (*source_file.src.as_ref().unwrap()).clone();\n+\n+        StringReader {\n+            sess,\n+            pos: source_file.start_pos,\n+            source_file,\n+            end_src_index: src.len(),\n+            src,\n+            fatal_errs: Vec::new(),\n+            override_span,\n+        }\n     }\n \n     pub fn retokenize(sess: &'a ParseSess, mut span: Span) -> Self {\n@@ -63,39 +74,14 @@ impl<'a> StringReader<'a> {\n             span = span.shrink_to_lo();\n         }\n \n-        let mut sr = StringReader::new_internal(sess, begin.sf, None);\n+        let mut sr = StringReader::new(sess, begin.sf, None);\n \n         // Seek the lexer to the right byte range.\n-        sr.next_pos = span.lo();\n         sr.end_src_index = sr.src_index(span.hi());\n \n-        sr.bump();\n-\n         sr\n     }\n \n-    fn new_internal(sess: &'a ParseSess, source_file: Lrc<syntax_pos::SourceFile>,\n-        override_span: Option<Span>) -> Self\n-    {\n-        if source_file.src.is_none() {\n-            sess.span_diagnostic.bug(&format!(\"Cannot lex source_file without source: {}\",\n-                                              source_file.name));\n-        }\n-\n-        let src = (*source_file.src.as_ref().unwrap()).clone();\n-\n-        StringReader {\n-            sess,\n-            next_pos: source_file.start_pos,\n-            pos: source_file.start_pos,\n-            ch: Some('\\n'),\n-            source_file,\n-            end_src_index: src.len(),\n-            src,\n-            fatal_errs: Vec::new(),\n-            override_span,\n-        }\n-    }\n \n     fn mk_sp(&self, lo: BytePos, hi: BytePos) -> Span {\n         self.override_span.unwrap_or_else(|| Span::new(lo, hi, NO_EXPANSION))\n@@ -117,19 +103,47 @@ impl<'a> StringReader<'a> {\n     /// retrieved using `buffer_fatal_errors`.\n     pub fn try_next_token(&mut self) -> Result<Token, ()> {\n         assert!(self.fatal_errs.is_empty());\n-        match self.scan_whitespace_or_comment() {\n-            Some(comment) => Ok(comment),\n-            None => {\n-                let (kind, start_pos, end_pos) = if self.is_eof() {\n-                    (token::Eof, self.source_file.end_pos, self.source_file.end_pos)\n-                } else {\n-                    let start_pos = self.pos;\n-                    (self.next_token_inner()?, start_pos, self.pos)\n-                };\n-                let span = self.mk_sp(start_pos, end_pos);\n-                Ok(Token::new(kind, span))\n+\n+        let start_src_index = self.src_index(self.pos);\n+        let text: &str = &self.src[start_src_index..self.end_src_index];\n+\n+        if text.is_empty() {\n+            let span = self.mk_sp(self.source_file.end_pos, self.source_file.end_pos);\n+            return Ok(Token::new(token::Eof, span));\n+        }\n+\n+        {\n+            let is_beginning_of_file = self.pos == self.source_file.start_pos;\n+            if is_beginning_of_file {\n+                if let Some(shebang_len) = rustc_lexer::strip_shebang(text) {\n+                    let start = self.pos;\n+                    self.pos = self.pos + BytePos::from_usize(shebang_len);\n+\n+                    let sym = self.symbol_from(start + BytePos::from_usize(\"#!\".len()));\n+                    let kind = token::Shebang(sym);\n+\n+                    let span = self.mk_sp(start, self.pos);\n+                    return Ok(Token::new(kind, span));\n+                }\n             }\n         }\n+\n+        let token = rustc_lexer::first_token(text);\n+\n+        let start = self.pos;\n+        self.pos = self.pos + BytePos::from_usize(token.len);\n+\n+        debug!(\"try_next_token: {:?}({:?})\", token.kind, self.str_from(start));\n+\n+        // This could use `?`, but that makes code significantly (10-20%) slower.\n+        // https://github.com/rust-lang/rust/issues/37939\n+        let kind = match self.cook_lexer_token(token.kind, start) {\n+            Ok(it) => it,\n+            Err(err) => return Err(self.fatal_errs.push(err)),\n+        };\n+\n+        let span = self.mk_sp(start, self.pos);\n+        Ok(Token::new(kind, span))\n     }\n \n     /// Returns the next token, including trivia like whitespace or comments.\n@@ -140,25 +154,7 @@ impl<'a> StringReader<'a> {\n         self.unwrap_or_abort(res)\n     }\n \n-    #[inline]\n-    fn is_eof(&self) -> bool {\n-        self.ch.is_none()\n-    }\n-\n-    fn fail_unterminated_raw_string(&self, pos: BytePos, hash_count: u16) -> ! {\n-        let mut err = self.struct_span_fatal(pos, pos, \"unterminated raw string\");\n-        err.span_label(self.mk_sp(pos, pos), \"unterminated raw string\");\n-\n-        if hash_count > 0 {\n-            err.note(&format!(\"this raw string should be terminated with `\\\"{}`\",\n-                              \"#\".repeat(hash_count as usize)));\n-        }\n-\n-        err.emit();\n-        FatalError.raise();\n-    }\n-\n-    crate fn emit_fatal_errors(&mut self) {\n+    fn emit_fatal_errors(&mut self) {\n         for err in &mut self.fatal_errs {\n             err.emit();\n         }\n@@ -176,11 +172,6 @@ impl<'a> StringReader<'a> {\n         buffer\n     }\n \n-    #[inline]\n-    fn ch_is(&self, c: char) -> bool {\n-        self.ch == Some(c)\n-    }\n-\n     /// Report a fatal lexical error with a given span.\n     fn fatal_span(&self, sp: Span, m: &str) -> FatalError {\n         self.sess.span_diagnostic.span_fatal(sp, m)\n@@ -202,16 +193,6 @@ impl<'a> StringReader<'a> {\n         self.err_span(self.mk_sp(from_pos, to_pos), m)\n     }\n \n-    /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n-    /// escaped character to the error message\n-    fn fatal_span_char(&self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) -> FatalError {\n-        let mut m = m.to_string();\n-        m.push_str(\": \");\n-        push_escaped_char(&mut m, c);\n-\n-        self.fatal_span_(from_pos, to_pos, &m[..])\n-    }\n-\n     fn struct_span_fatal(&self, from_pos: BytePos, to_pos: BytePos, m: &str)\n         -> DiagnosticBuilder<'a>\n     {\n@@ -228,6 +209,318 @@ impl<'a> StringReader<'a> {\n         self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), &m[..])\n     }\n \n+    /// Turns simple `rustc_lexer::TokenKind` enum into a rich\n+    /// `libsyntax::TokenKind`. This turns strings into interned\n+    /// symbols and runs additional validation.\n+    fn cook_lexer_token(\n+        &self,\n+        token: rustc_lexer::TokenKind,\n+        start: BytePos,\n+    ) -> Result<TokenKind, DiagnosticBuilder<'a>> {\n+        let kind = match token {\n+            rustc_lexer::TokenKind::LineComment => {\n+                let string = self.str_from(start);\n+                // comments with only more \"/\"s are not doc comments\n+                let tok = if is_doc_comment(string) {\n+                    let mut idx = 0;\n+                    loop {\n+                        idx = match string[idx..].find('\\r') {\n+                            None => break,\n+                            Some(it) => it + 1\n+                        };\n+                        if string[idx..].chars().next() != Some('\\n') {\n+                            self.err_span_(start + BytePos(idx as u32 - 1),\n+                                            start + BytePos(idx as u32),\n+                                            \"bare CR not allowed in doc-comment\");\n+                        }\n+                    }\n+                    token::DocComment(Symbol::intern(string))\n+                } else {\n+                    token::Comment\n+                };\n+\n+                tok\n+            }\n+            rustc_lexer::TokenKind::BlockComment { terminated } => {\n+                let string = self.str_from(start);\n+                // block comments starting with \"/**\" or \"/*!\" are doc-comments\n+                // but comments with only \"*\"s between two \"/\"s are not\n+                let is_doc_comment = is_block_doc_comment(string);\n+\n+                if !terminated {\n+                    let msg = if is_doc_comment {\n+                        \"unterminated block doc-comment\"\n+                    } else {\n+                        \"unterminated block comment\"\n+                    };\n+                    let last_bpos = self.pos;\n+                    self.fatal_span_(start, last_bpos, msg).raise();\n+                }\n+\n+                let tok = if is_doc_comment {\n+                    let has_cr = string.contains('\\r');\n+                    let string = if has_cr {\n+                        self.translate_crlf(start,\n+                                            string,\n+                                            \"bare CR not allowed in block doc-comment\")\n+                    } else {\n+                        string.into()\n+                    };\n+                    token::DocComment(Symbol::intern(&string[..]))\n+                } else {\n+                    token::Comment\n+                };\n+\n+                tok\n+            }\n+            rustc_lexer::TokenKind::Whitespace => token::Whitespace,\n+            rustc_lexer::TokenKind::Ident | rustc_lexer::TokenKind::RawIdent => {\n+                let is_raw_ident = token == rustc_lexer::TokenKind::RawIdent;\n+                let mut ident_start = start;\n+                if is_raw_ident {\n+                    ident_start = ident_start + BytePos(2);\n+                }\n+                // FIXME: perform NFKC normalization here. (Issue #2253)\n+                let sym = self.symbol_from(ident_start);\n+                if is_raw_ident {\n+                    let span = self.mk_sp(start, self.pos);\n+                    if !sym.can_be_raw() {\n+                        self.err_span(span, &format!(\"`{}` cannot be a raw identifier\", sym));\n+                    }\n+                    self.sess.raw_identifier_spans.borrow_mut().push(span);\n+                }\n+                token::Ident(sym, is_raw_ident)\n+            }\n+            rustc_lexer::TokenKind::Literal { kind, suffix_start } => {\n+                let suffix_start = start + BytePos(suffix_start as u32);\n+                let (kind, symbol) = self.cook_lexer_literal(start, suffix_start, kind);\n+                let suffix = if suffix_start < self.pos {\n+                    let string = self.str_from(suffix_start);\n+                    if string == \"_\" {\n+                        self.sess.span_diagnostic\n+                            .struct_span_warn(self.mk_sp(suffix_start, self.pos),\n+                                              \"underscore literal suffix is not allowed\")\n+                            .warn(\"this was previously accepted by the compiler but is \\\n+                                   being phased out; it will become a hard error in \\\n+                                   a future release!\")\n+                            .note(\"for more information, see issue #42326 \\\n+                                   <https://github.com/rust-lang/rust/issues/42326>\")\n+                            .emit();\n+                        None\n+                    } else {\n+                        Some(Symbol::intern(string))\n+                    }\n+                } else {\n+                    None\n+                };\n+                token::Literal(token::Lit { kind, symbol, suffix })\n+            }\n+            rustc_lexer::TokenKind::Lifetime { starts_with_number } => {\n+                // Include the leading `'` in the real identifier, for macro\n+                // expansion purposes. See #12512 for the gory details of why\n+                // this is necessary.\n+                let lifetime_name = self.str_from(start);\n+                if starts_with_number {\n+                    self.err_span_(\n+                        start,\n+                        self.pos,\n+                        \"lifetimes cannot start with a number\",\n+                    );\n+                }\n+                let ident = Symbol::intern(lifetime_name);\n+                token::Lifetime(ident)\n+            }\n+            rustc_lexer::TokenKind::Semi => token::Semi,\n+            rustc_lexer::TokenKind::Comma => token::Comma,\n+            rustc_lexer::TokenKind::DotDotDot => token::DotDotDot,\n+            rustc_lexer::TokenKind::DotDotEq => token::DotDotEq,\n+            rustc_lexer::TokenKind::DotDot => token::DotDot,\n+            rustc_lexer::TokenKind::Dot => token::Dot,\n+            rustc_lexer::TokenKind::OpenParen => token::OpenDelim(token::Paren),\n+            rustc_lexer::TokenKind::CloseParen => token::CloseDelim(token::Paren),\n+            rustc_lexer::TokenKind::OpenBrace => token::OpenDelim(token::Brace),\n+            rustc_lexer::TokenKind::CloseBrace => token::CloseDelim(token::Brace),\n+            rustc_lexer::TokenKind::OpenBracket => token::OpenDelim(token::Bracket),\n+            rustc_lexer::TokenKind::CloseBracket => token::CloseDelim(token::Bracket),\n+            rustc_lexer::TokenKind::At => token::At,\n+            rustc_lexer::TokenKind::Pound => token::Pound,\n+            rustc_lexer::TokenKind::Tilde => token::Tilde,\n+            rustc_lexer::TokenKind::Question => token::Question,\n+            rustc_lexer::TokenKind::ColonColon => token::ModSep,\n+            rustc_lexer::TokenKind::Colon => token::Colon,\n+            rustc_lexer::TokenKind::Dollar => token::Dollar,\n+            rustc_lexer::TokenKind::EqEq => token::EqEq,\n+            rustc_lexer::TokenKind::Eq => token::Eq,\n+            rustc_lexer::TokenKind::FatArrow => token::FatArrow,\n+            rustc_lexer::TokenKind::Ne => token::Ne,\n+            rustc_lexer::TokenKind::Not => token::Not,\n+            rustc_lexer::TokenKind::Le => token::Le,\n+            rustc_lexer::TokenKind::LArrow => token::LArrow,\n+            rustc_lexer::TokenKind::Lt => token::Lt,\n+            rustc_lexer::TokenKind::ShlEq => token::BinOpEq(token::Shl),\n+            rustc_lexer::TokenKind::Shl => token::BinOp(token::Shl),\n+            rustc_lexer::TokenKind::Ge => token::Ge,\n+            rustc_lexer::TokenKind::Gt => token::Gt,\n+            rustc_lexer::TokenKind::ShrEq => token::BinOpEq(token::Shr),\n+            rustc_lexer::TokenKind::Shr => token::BinOp(token::Shr),\n+            rustc_lexer::TokenKind::RArrow => token::RArrow,\n+            rustc_lexer::TokenKind::Minus => token::BinOp(token::Minus),\n+            rustc_lexer::TokenKind::MinusEq => token::BinOpEq(token::Minus),\n+            rustc_lexer::TokenKind::And => token::BinOp(token::And),\n+            rustc_lexer::TokenKind::AndEq => token::BinOpEq(token::And),\n+            rustc_lexer::TokenKind::AndAnd => token::AndAnd,\n+            rustc_lexer::TokenKind::Or => token::BinOp(token::Or),\n+            rustc_lexer::TokenKind::OrEq => token::BinOpEq(token::Or),\n+            rustc_lexer::TokenKind::OrOr => token::OrOr,\n+            rustc_lexer::TokenKind::Plus => token::BinOp(token::Plus),\n+            rustc_lexer::TokenKind::PlusEq => token::BinOpEq(token::Plus),\n+            rustc_lexer::TokenKind::Star => token::BinOp(token::Star),\n+            rustc_lexer::TokenKind::StarEq => token::BinOpEq(token::Star),\n+            rustc_lexer::TokenKind::Slash => token::BinOp(token::Slash),\n+            rustc_lexer::TokenKind::SlashEq => token::BinOpEq(token::Slash),\n+            rustc_lexer::TokenKind::Caret => token::BinOp(token::Caret),\n+            rustc_lexer::TokenKind::CaretEq => token::BinOpEq(token::Caret),\n+            rustc_lexer::TokenKind::Percent => token::BinOp(token::Percent),\n+            rustc_lexer::TokenKind::PercentEq => token::BinOpEq(token::Percent),\n+\n+            rustc_lexer::TokenKind::Unknown => {\n+                let c = self.str_from(start).chars().next().unwrap();\n+                let mut err = self.struct_fatal_span_char(start,\n+                                                          self.pos,\n+                                                          \"unknown start of token\",\n+                                                          c);\n+                unicode_chars::check_for_substitution(self, start, c, &mut err);\n+                return Err(err)\n+            }\n+        };\n+        Ok(kind)\n+    }\n+\n+    fn cook_lexer_literal(\n+        &self,\n+        start: BytePos,\n+        suffix_start: BytePos,\n+        kind: rustc_lexer::LiteralKind\n+    ) -> (token::LitKind, Symbol) {\n+        match kind {\n+            rustc_lexer::LiteralKind::Char { terminated } => {\n+                if !terminated {\n+                    self.fatal_span_(start, suffix_start,\n+                                     \"unterminated character literal\".into())\n+                        .raise()\n+                }\n+                let content_start = start + BytePos(1);\n+                let content_end = suffix_start - BytePos(1);\n+                self.validate_char_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::Char, id)\n+            },\n+            rustc_lexer::LiteralKind::Byte { terminated } => {\n+                if !terminated {\n+                    self.fatal_span_(start + BytePos(1), suffix_start,\n+                                     \"unterminated byte constant\".into())\n+                        .raise()\n+                }\n+                let content_start = start + BytePos(2);\n+                let content_end = suffix_start - BytePos(1);\n+                self.validate_byte_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::Byte, id)\n+            },\n+            rustc_lexer::LiteralKind::Str { terminated } => {\n+                if !terminated {\n+                    self.fatal_span_(start, suffix_start,\n+                                     \"unterminated double quote string\".into())\n+                        .raise()\n+                }\n+                let content_start = start + BytePos(1);\n+                let content_end = suffix_start - BytePos(1);\n+                self.validate_str_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::Str, id)\n+            }\n+            rustc_lexer::LiteralKind::ByteStr { terminated } => {\n+                if !terminated {\n+                    self.fatal_span_(start + BytePos(1), suffix_start,\n+                                     \"unterminated double quote byte string\".into())\n+                        .raise()\n+                }\n+                let content_start = start + BytePos(2);\n+                let content_end = suffix_start - BytePos(1);\n+                self.validate_byte_str_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::ByteStr, id)\n+            }\n+            rustc_lexer::LiteralKind::RawStr { n_hashes, started, terminated } => {\n+                if !started {\n+                    self.report_non_started_raw_string(start);\n+                }\n+                if !terminated {\n+                    self.report_unterminated_raw_string(start, n_hashes)\n+                }\n+                let n_hashes: u16 = self.restrict_n_hashes(start, n_hashes);\n+                let n = u32::from(n_hashes);\n+                let content_start = start + BytePos(2 + n);\n+                let content_end = suffix_start - BytePos(1 + n);\n+                self.validate_raw_str_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::StrRaw(n_hashes), id)\n+            }\n+            rustc_lexer::LiteralKind::RawByteStr { n_hashes, started, terminated } => {\n+                if !started {\n+                    self.report_non_started_raw_string(start);\n+                }\n+                if !terminated {\n+                    self.report_unterminated_raw_string(start, n_hashes)\n+                }\n+                let n_hashes: u16 = self.restrict_n_hashes(start, n_hashes);\n+                let n = u32::from(n_hashes);\n+                let content_start = start + BytePos(3 + n);\n+                let content_end = suffix_start - BytePos(1 + n);\n+                self.validate_raw_byte_str_escape(content_start, content_end);\n+                let id = self.symbol_from_to(content_start, content_end);\n+                (token::ByteStrRaw(n_hashes), id)\n+            }\n+            rustc_lexer::LiteralKind::Int { base, empty_int } => {\n+                if empty_int {\n+                    self.err_span_(start, suffix_start, \"no valid digits found for number\");\n+                    (token::Integer, sym::integer(0))\n+                } else {\n+                    self.validate_int_literal(base, start, suffix_start);\n+                    (token::Integer, self.symbol_from_to(start, suffix_start))\n+                }\n+            },\n+            rustc_lexer::LiteralKind::Float { base, empty_exponent } => {\n+                if empty_exponent {\n+                    let mut err = self.struct_span_fatal(\n+                        start, self.pos,\n+                        \"expected at least one digit in exponent\"\n+                    );\n+                    err.emit();\n+                }\n+\n+                match base {\n+                    Base::Hexadecimal => {\n+                        self.err_span_(start, suffix_start,\n+                                       \"hexadecimal float literal is not supported\")\n+                    }\n+                    Base::Octal => {\n+                        self.err_span_(start, suffix_start,\n+                                       \"octal float literal is not supported\")\n+                    }\n+                    Base::Binary => {\n+                        self.err_span_(start, suffix_start,\n+                                       \"binary float literal is not supported\")\n+                    }\n+                    _ => ()\n+                }\n+\n+                let id = self.symbol_from_to(start, suffix_start);\n+                (token::Float, id)\n+            },\n+        }\n+    }\n+\n     #[inline]\n     fn src_index(&self, pos: BytePos) -> usize {\n         (pos - self.source_file.start_pos).to_usize()\n@@ -304,938 +597,87 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    /// Advance the StringReader by one character.\n-    crate fn bump(&mut self) {\n-        let next_src_index = self.src_index(self.next_pos);\n-        if next_src_index < self.end_src_index {\n-            let next_ch = char_at(&self.src, next_src_index);\n-            let next_ch_len = next_ch.len_utf8();\n-\n-            self.ch = Some(next_ch);\n-            self.pos = self.next_pos;\n-            self.next_pos = self.next_pos + Pos::from_usize(next_ch_len);\n-        } else {\n-            self.ch = None;\n-            self.pos = self.next_pos;\n-        }\n-    }\n-\n-    fn nextch(&self) -> Option<char> {\n-        let next_src_index = self.src_index(self.next_pos);\n-        if next_src_index < self.end_src_index {\n-            Some(char_at(&self.src, next_src_index))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    #[inline]\n-    fn nextch_is(&self, c: char) -> bool {\n-        self.nextch() == Some(c)\n-    }\n-\n-    fn nextnextch(&self) -> Option<char> {\n-        let next_src_index = self.src_index(self.next_pos);\n-        if next_src_index < self.end_src_index {\n-            let next_next_src_index =\n-                next_src_index + char_at(&self.src, next_src_index).len_utf8();\n-            if next_next_src_index < self.end_src_index {\n-                return Some(char_at(&self.src, next_next_src_index));\n-            }\n-        }\n-        None\n-    }\n-\n-    #[inline]\n-    fn nextnextch_is(&self, c: char) -> bool {\n-        self.nextnextch() == Some(c)\n-    }\n-\n-    /// Eats <XID_start><XID_continue>*, if possible.\n-    fn scan_optional_raw_name(&mut self) -> Option<Symbol> {\n-        if !ident_start(self.ch) {\n-            return None;\n-        }\n-\n-        let start = self.pos;\n-        self.bump();\n-\n-        while ident_continue(self.ch) {\n-            self.bump();\n-        }\n-\n-        match self.str_from(start) {\n-            \"_\" => {\n-                self.sess.span_diagnostic\n-                    .struct_span_warn(self.mk_sp(start, self.pos),\n-                                      \"underscore literal suffix is not allowed\")\n-                    .warn(\"this was previously accepted by the compiler but is \\\n-                          being phased out; it will become a hard error in \\\n-                          a future release!\")\n-                    .note(\"for more information, see issue #42326 \\\n-                          <https://github.com/rust-lang/rust/issues/42326>\")\n-                    .emit();\n-                None\n-            }\n-            name => Some(Symbol::intern(name))\n-        }\n-    }\n-\n-    /// PRECONDITION: self.ch is not whitespace\n-    /// Eats any kind of comment.\n-    fn scan_comment(&mut self) -> Option<Token> {\n-        if let Some(c) = self.ch {\n-            if c.is_whitespace() {\n-                let msg = \"called consume_any_line_comment, but there was whitespace\";\n-                self.sess.span_diagnostic.span_err(self.mk_sp(self.pos, self.pos), msg);\n-            }\n-        }\n-\n-        if self.ch_is('/') {\n-            match self.nextch() {\n-                Some('/') => {\n-                    self.bump();\n-                    self.bump();\n-\n-                    // line comments starting with \"///\" or \"//!\" are doc-comments\n-                    let doc_comment = (self.ch_is('/') && !self.nextch_is('/')) || self.ch_is('!');\n-                    let start_bpos = self.pos - BytePos(2);\n-\n-                    while !self.is_eof() {\n-                        match self.ch.unwrap() {\n-                            '\\n' => break,\n-                            '\\r' => {\n-                                if self.nextch_is('\\n') {\n-                                    // CRLF\n-                                    break;\n-                                } else if doc_comment {\n-                                    self.err_span_(self.pos,\n-                                                   self.next_pos,\n-                                                   \"bare CR not allowed in doc-comment\");\n-                                }\n-                            }\n-                            _ => (),\n-                        }\n-                        self.bump();\n-                    }\n-\n-                    let kind = if doc_comment {\n-                        token::DocComment(self.symbol_from(start_bpos))\n-                    } else {\n-                        token::Comment\n-                    };\n-                    Some(Token::new(kind, self.mk_sp(start_bpos, self.pos)))\n-                }\n-                Some('*') => {\n-                    self.bump();\n-                    self.bump();\n-                    self.scan_block_comment()\n-                }\n-                _ => None,\n-            }\n-        } else if self.ch_is('#') {\n-            if self.nextch_is('!') {\n-\n-                // Parse an inner attribute.\n-                if self.nextnextch_is('[') {\n-                    return None;\n-                }\n-\n-                let is_beginning_of_file = self.pos == self.source_file.start_pos;\n-                if is_beginning_of_file {\n-                    debug!(\"skipping a shebang\");\n-                    let start = self.pos;\n-                    while !self.ch_is('\\n') && !self.is_eof() {\n-                        self.bump();\n-                    }\n-                    return Some(Token::new(\n-                        token::Shebang(self.symbol_from(start)),\n-                        self.mk_sp(start, self.pos),\n-                    ));\n-                }\n-            }\n-            None\n-        } else {\n-            None\n-        }\n-    }\n-\n-    /// If there is whitespace, shebang, or a comment, scan it. Otherwise,\n-    /// return `None`.\n-    fn scan_whitespace_or_comment(&mut self) -> Option<Token> {\n-        match self.ch.unwrap_or('\\0') {\n-            // # to handle shebang at start of file -- this is the entry point\n-            // for skipping over all \"junk\"\n-            '/' | '#' => {\n-                let c = self.scan_comment();\n-                debug!(\"scanning a comment {:?}\", c);\n-                c\n-            },\n-            c if is_pattern_whitespace(Some(c)) => {\n-                let start_bpos = self.pos;\n-                while is_pattern_whitespace(self.ch) {\n-                    self.bump();\n-                }\n-                let c = Some(Token::new(token::Whitespace, self.mk_sp(start_bpos, self.pos)));\n-                debug!(\"scanning whitespace: {:?}\", c);\n-                c\n-            }\n-            _ => None,\n-        }\n-    }\n-\n-    /// Might return a sugared-doc-attr\n-    fn scan_block_comment(&mut self) -> Option<Token> {\n-        // block comments starting with \"/**\" or \"/*!\" are doc-comments\n-        let is_doc_comment = self.ch_is('*') || self.ch_is('!');\n-        let start_bpos = self.pos - BytePos(2);\n-\n-        let mut level: isize = 1;\n-        let mut has_cr = false;\n-        while level > 0 {\n-            if self.is_eof() {\n-                let msg = if is_doc_comment {\n-                    \"unterminated block doc-comment\"\n-                } else {\n-                    \"unterminated block comment\"\n-                };\n-                let last_bpos = self.pos;\n-                self.fatal_span_(start_bpos, last_bpos, msg).raise();\n-            }\n-            let n = self.ch.unwrap();\n-            match n {\n-                '/' if self.nextch_is('*') => {\n-                    level += 1;\n-                    self.bump();\n-                }\n-                '*' if self.nextch_is('/') => {\n-                    level -= 1;\n-                    self.bump();\n-                }\n-                '\\r' => {\n-                    has_cr = true;\n-                }\n-                _ => (),\n-            }\n-            self.bump();\n-        }\n-\n-        let string = self.str_from(start_bpos);\n-        // but comments with only \"*\"s between two \"/\"s are not\n-        let kind = if is_block_doc_comment(string) {\n-            let string = if has_cr {\n-                self.translate_crlf(start_bpos,\n-                                    string,\n-                                    \"bare CR not allowed in block doc-comment\")\n-            } else {\n-                string.into()\n-            };\n-            token::DocComment(Symbol::intern(&string[..]))\n-        } else {\n-            token::Comment\n-        };\n-\n-        Some(Token::new(kind, self.mk_sp(start_bpos, self.pos)))\n-    }\n-\n-    /// Scan through any digits (base `scan_radix`) or underscores,\n-    /// and return how many digits there were.\n-    ///\n-    /// `real_radix` represents the true radix of the number we're\n-    /// interested in, and errors will be emitted for any digits\n-    /// between `real_radix` and `scan_radix`.\n-    fn scan_digits(&mut self, real_radix: u32, scan_radix: u32) -> usize {\n-        assert!(real_radix <= scan_radix);\n-        let mut len = 0;\n-\n-        loop {\n-            let c = self.ch;\n-            if c == Some('_') {\n-                debug!(\"skipping a _\");\n-                self.bump();\n-                continue;\n-            }\n-            match c.and_then(|cc| cc.to_digit(scan_radix)) {\n-                Some(_) => {\n-                    debug!(\"{:?} in scan_digits\", c);\n-                    // check that the hypothetical digit is actually\n-                    // in range for the true radix\n-                    if c.unwrap().to_digit(real_radix).is_none() {\n-                        self.err_span_(self.pos,\n-                                       self.next_pos,\n-                                       &format!(\"invalid digit for a base {} literal\", real_radix));\n-                    }\n-                    len += 1;\n-                    self.bump();\n-                }\n-                _ => return len,\n-            }\n-        }\n-    }\n-\n-    /// Lex a LIT_INTEGER or a LIT_FLOAT\n-    fn scan_number(&mut self, c: char) -> (token::LitKind, Symbol) {\n-        let mut base = 10;\n-        let start_bpos = self.pos;\n-        self.bump();\n-\n-        let num_digits = if c == '0' {\n-            match self.ch.unwrap_or('\\0') {\n-                'b' => {\n-                    self.bump();\n-                    base = 2;\n-                    self.scan_digits(2, 10)\n-                }\n-                'o' => {\n-                    self.bump();\n-                    base = 8;\n-                    self.scan_digits(8, 10)\n-                }\n-                'x' => {\n-                    self.bump();\n-                    base = 16;\n-                    self.scan_digits(16, 16)\n-                }\n-                '0'..='9' | '_' | '.' | 'e' | 'E' => {\n-                    self.scan_digits(10, 10) + 1\n-                }\n-                _ => {\n-                    // just a 0\n-                    return (token::Integer, sym::integer(0));\n-                }\n-            }\n-        } else if c.is_digit(10) {\n-            self.scan_digits(10, 10) + 1\n-        } else {\n-            0\n-        };\n-\n-        if num_digits == 0 {\n-            self.err_span_(start_bpos, self.pos, \"no valid digits found for number\");\n-\n-            return (token::Integer, sym::integer(0));\n-        }\n-\n-        // might be a float, but don't be greedy if this is actually an\n-        // integer literal followed by field/method access or a range pattern\n-        // (`0..2` and `12.foo()`)\n-        if self.ch_is('.') && !self.nextch_is('.') &&\n-           !ident_start(self.nextch()) {\n-            // might have stuff after the ., and if it does, it needs to start\n-            // with a number\n-            self.bump();\n-            if self.ch.unwrap_or('\\0').is_digit(10) {\n-                self.scan_digits(10, 10);\n-                self.scan_float_exponent();\n-            }\n-            let pos = self.pos;\n-            self.check_float_base(start_bpos, pos, base);\n-\n-            (token::Float, self.symbol_from(start_bpos))\n-        } else {\n-            // it might be a float if it has an exponent\n-            if self.ch_is('e') || self.ch_is('E') {\n-                self.scan_float_exponent();\n-                let pos = self.pos;\n-                self.check_float_base(start_bpos, pos, base);\n-                return (token::Float, self.symbol_from(start_bpos));\n-            }\n-            // but we certainly have an integer!\n-            (token::Integer, self.symbol_from(start_bpos))\n-        }\n-    }\n-\n-    /// Scan over a float exponent.\n-    fn scan_float_exponent(&mut self) {\n-        if self.ch_is('e') || self.ch_is('E') {\n-            self.bump();\n-\n-            if self.ch_is('-') || self.ch_is('+') {\n-                self.bump();\n-            }\n-\n-            if self.scan_digits(10, 10) == 0 {\n-                let mut err = self.struct_span_fatal(\n-                    self.pos, self.next_pos,\n-                    \"expected at least one digit in exponent\"\n-                );\n-                if let Some(ch) = self.ch {\n-                    // check for e.g., Unicode minus '\u2212' (Issue #49746)\n-                    if unicode_chars::check_for_substitution(self, ch, &mut err) {\n-                        self.bump();\n-                        self.scan_digits(10, 10);\n-                    }\n-                }\n-                err.emit();\n-            }\n-        }\n-    }\n-\n-    /// Checks that a base is valid for a floating literal, emitting a nice\n-    /// error if it isn't.\n-    fn check_float_base(&mut self, start_bpos: BytePos, last_bpos: BytePos, base: usize) {\n-        match base {\n-            16 => {\n-                self.err_span_(start_bpos,\n-                               last_bpos,\n-                               \"hexadecimal float literal is not supported\")\n-            }\n-            8 => {\n-                self.err_span_(start_bpos,\n-                               last_bpos,\n-                               \"octal float literal is not supported\")\n-            }\n-            2 => {\n-                self.err_span_(start_bpos,\n-                               last_bpos,\n-                               \"binary float literal is not supported\")\n-            }\n-            _ => (),\n-        }\n-    }\n-\n-    fn binop(&mut self, op: token::BinOpToken) -> TokenKind {\n-        self.bump();\n-        if self.ch_is('=') {\n-            self.bump();\n-            token::BinOpEq(op)\n-        } else {\n-            token::BinOp(op)\n-        }\n-    }\n-\n-    /// Returns the next token from the string, advances the input past that\n-    /// token, and updates the interner\n-    fn next_token_inner(&mut self) -> Result<TokenKind, ()> {\n-        let c = self.ch;\n-\n-        if ident_start(c) {\n-            let (is_ident_start, is_raw_ident) =\n-                match (c.unwrap(), self.nextch(), self.nextnextch()) {\n-                    // r# followed by an identifier starter is a raw identifier.\n-                    // This is an exception to the r# case below.\n-                    ('r', Some('#'), x) if ident_start(x) => (true, true),\n-                    // r as in r\" or r#\" is part of a raw string literal.\n-                    // b as in b' is part of a byte literal.\n-                    // They are not identifiers, and are handled further down.\n-                    ('r', Some('\"'), _) |\n-                    ('r', Some('#'), _) |\n-                    ('b', Some('\"'), _) |\n-                    ('b', Some('\\''), _) |\n-                    ('b', Some('r'), Some('\"')) |\n-                    ('b', Some('r'), Some('#')) => (false, false),\n-                    _ => (true, false),\n-                };\n-\n-            if is_ident_start {\n-                let raw_start = self.pos;\n-                if is_raw_ident {\n-                    // Consume the 'r#' characters.\n-                    self.bump();\n-                    self.bump();\n-                }\n-\n-                let start = self.pos;\n-                self.bump();\n-\n-                while ident_continue(self.ch) {\n-                    self.bump();\n-                }\n-\n-                // FIXME: perform NFKC normalization here. (Issue #2253)\n-                let name = self.symbol_from(start);\n-                if is_raw_ident {\n-                    let span = self.mk_sp(raw_start, self.pos);\n-                    if !name.can_be_raw() {\n-                        self.err_span(span, &format!(\"`{}` cannot be a raw identifier\", name));\n-                    }\n-                    self.sess.raw_identifier_spans.borrow_mut().push(span);\n-                }\n-\n-                return Ok(token::Ident(name, is_raw_ident));\n-            }\n-        }\n-\n-        if is_dec_digit(c) {\n-            let (kind, symbol) = self.scan_number(c.unwrap());\n-            let suffix = self.scan_optional_raw_name();\n-            debug!(\"next_token_inner: scanned number {:?}, {:?}, {:?}\", kind, symbol, suffix);\n-            return Ok(TokenKind::lit(kind, symbol, suffix));\n-        }\n-\n-        match c.expect(\"next_token_inner called at EOF\") {\n-            // One-byte tokens.\n-            ';' => {\n-                self.bump();\n-                Ok(token::Semi)\n-            }\n-            ',' => {\n-                self.bump();\n-                Ok(token::Comma)\n-            }\n-            '.' => {\n-                self.bump();\n-                if self.ch_is('.') {\n-                    self.bump();\n-                    if self.ch_is('.') {\n-                        self.bump();\n-                        Ok(token::DotDotDot)\n-                    } else if self.ch_is('=') {\n-                        self.bump();\n-                        Ok(token::DotDotEq)\n-                    } else {\n-                        Ok(token::DotDot)\n-                    }\n-                } else {\n-                    Ok(token::Dot)\n-                }\n-            }\n-            '(' => {\n-                self.bump();\n-                Ok(token::OpenDelim(token::Paren))\n-            }\n-            ')' => {\n-                self.bump();\n-                Ok(token::CloseDelim(token::Paren))\n-            }\n-            '{' => {\n-                self.bump();\n-                Ok(token::OpenDelim(token::Brace))\n-            }\n-            '}' => {\n-                self.bump();\n-                Ok(token::CloseDelim(token::Brace))\n-            }\n-            '[' => {\n-                self.bump();\n-                Ok(token::OpenDelim(token::Bracket))\n-            }\n-            ']' => {\n-                self.bump();\n-                Ok(token::CloseDelim(token::Bracket))\n-            }\n-            '@' => {\n-                self.bump();\n-                Ok(token::At)\n-            }\n-            '#' => {\n-                self.bump();\n-                Ok(token::Pound)\n-            }\n-            '~' => {\n-                self.bump();\n-                Ok(token::Tilde)\n-            }\n-            '?' => {\n-                self.bump();\n-                Ok(token::Question)\n-            }\n-            ':' => {\n-                self.bump();\n-                if self.ch_is(':') {\n-                    self.bump();\n-                    Ok(token::ModSep)\n-                } else {\n-                    Ok(token::Colon)\n-                }\n-            }\n-\n-            '$' => {\n-                self.bump();\n-                Ok(token::Dollar)\n-            }\n-\n-            // Multi-byte tokens.\n-            '=' => {\n-                self.bump();\n-                if self.ch_is('=') {\n-                    self.bump();\n-                    Ok(token::EqEq)\n-                } else if self.ch_is('>') {\n-                    self.bump();\n-                    Ok(token::FatArrow)\n-                } else {\n-                    Ok(token::Eq)\n-                }\n-            }\n-            '!' => {\n-                self.bump();\n-                if self.ch_is('=') {\n-                    self.bump();\n-                    Ok(token::Ne)\n-                } else {\n-                    Ok(token::Not)\n-                }\n-            }\n-            '<' => {\n-                self.bump();\n-                match self.ch.unwrap_or('\\x00') {\n-                    '=' => {\n-                        self.bump();\n-                        Ok(token::Le)\n-                    }\n-                    '<' => {\n-                        Ok(self.binop(token::Shl))\n-                    }\n-                    '-' => {\n-                        self.bump();\n-                        Ok(token::LArrow)\n-                    }\n-                    _ => {\n-                        Ok(token::Lt)\n-                    }\n-                }\n-            }\n-            '>' => {\n-                self.bump();\n-                match self.ch.unwrap_or('\\x00') {\n-                    '=' => {\n-                        self.bump();\n-                        Ok(token::Ge)\n-                    }\n-                    '>' => {\n-                        Ok(self.binop(token::Shr))\n-                    }\n-                    _ => {\n-                        Ok(token::Gt)\n-                    }\n-                }\n-            }\n-            '\\'' => {\n-                // Either a character constant 'a' OR a lifetime name 'abc\n-                let start_with_quote = self.pos;\n-                self.bump();\n-                let start = self.pos;\n-\n-                // If the character is an ident start not followed by another single\n-                // quote, then this is a lifetime name:\n-                let starts_with_number = self.ch.unwrap_or('\\x00').is_numeric();\n-                if (ident_start(self.ch) || starts_with_number) && !self.nextch_is('\\'') {\n-                    self.bump();\n-                    while ident_continue(self.ch) {\n-                        self.bump();\n-                    }\n-                    // lifetimes shouldn't end with a single quote\n-                    // if we find one, then this is an invalid character literal\n-                    if self.ch_is('\\'') {\n-                        let symbol = self.symbol_from(start);\n-                        self.bump();\n-                        self.validate_char_escape(start_with_quote);\n-                        return Ok(TokenKind::lit(token::Char, symbol, None));\n-                    }\n-\n-                    if starts_with_number {\n-                        // this is a recovered lifetime written `'1`, error but accept it\n-                        self.err_span_(\n-                            start_with_quote,\n-                            self.pos,\n-                            \"lifetimes cannot start with a number\",\n-                        );\n-                    }\n-\n-                    // Include the leading `'` in the real identifier, for macro\n-                    // expansion purposes. See #12512 for the gory details of why\n-                    // this is necessary.\n-                    return Ok(token::Lifetime(self.symbol_from(start_with_quote)));\n-                }\n-                let msg = \"unterminated character literal\";\n-                let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n-                self.validate_char_escape(start_with_quote);\n-                let suffix = self.scan_optional_raw_name();\n-                Ok(TokenKind::lit(token::Char, symbol, suffix))\n-            }\n-            'b' => {\n-                self.bump();\n-                let (kind, symbol) = match self.ch {\n-                    Some('\\'') => {\n-                        let start_with_quote = self.pos;\n-                        self.bump();\n-                        let msg = \"unterminated byte constant\";\n-                        let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n-                        self.validate_byte_escape(start_with_quote);\n-                        (token::Byte, symbol)\n-                    },\n-                    Some('\"') => {\n-                        let start_with_quote = self.pos;\n-                        let msg = \"unterminated double quote byte string\";\n-                        let symbol = self.scan_double_quoted_string(msg);\n-                        self.validate_byte_str_escape(start_with_quote);\n-                        (token::ByteStr, symbol)\n-                    },\n-                    Some('r') => {\n-                        let (start, end, hash_count) = self.scan_raw_string();\n-                        let symbol = self.symbol_from_to(start, end);\n-                        self.validate_raw_byte_str_escape(start, end);\n-\n-                        (token::ByteStrRaw(hash_count), symbol)\n-                    }\n-                    _ => unreachable!(),  // Should have been a token::Ident above.\n-                };\n-                let suffix = self.scan_optional_raw_name();\n-\n-                Ok(TokenKind::lit(kind, symbol, suffix))\n-            }\n-            '\"' => {\n-                let start_with_quote = self.pos;\n-                let msg = \"unterminated double quote string\";\n-                let symbol = self.scan_double_quoted_string(msg);\n-                self.validate_str_escape(start_with_quote);\n-                let suffix = self.scan_optional_raw_name();\n-                Ok(TokenKind::lit(token::Str, symbol, suffix))\n-            }\n-            'r' => {\n-                let (start, end, hash_count) = self.scan_raw_string();\n-                let symbol = self.symbol_from_to(start, end);\n-                self.validate_raw_str_escape(start, end);\n-                let suffix = self.scan_optional_raw_name();\n-\n-                Ok(TokenKind::lit(token::StrRaw(hash_count), symbol, suffix))\n-            }\n-            '-' => {\n-                if self.nextch_is('>') {\n-                    self.bump();\n-                    self.bump();\n-                    Ok(token::RArrow)\n-                } else {\n-                    Ok(self.binop(token::Minus))\n-                }\n-            }\n-            '&' => {\n-                if self.nextch_is('&') {\n-                    self.bump();\n-                    self.bump();\n-                    Ok(token::AndAnd)\n-                } else {\n-                    Ok(self.binop(token::And))\n-                }\n-            }\n-            '|' => {\n-                match self.nextch() {\n-                    Some('|') => {\n-                        self.bump();\n-                        self.bump();\n-                        Ok(token::OrOr)\n-                    }\n-                    _ => {\n-                        Ok(self.binop(token::Or))\n-                    }\n-                }\n-            }\n-            '+' => {\n-                Ok(self.binop(token::Plus))\n-            }\n-            '*' => {\n-                Ok(self.binop(token::Star))\n-            }\n-            '/' => {\n-                Ok(self.binop(token::Slash))\n-            }\n-            '^' => {\n-                Ok(self.binop(token::Caret))\n-            }\n-            '%' => {\n-                Ok(self.binop(token::Percent))\n-            }\n-            c => {\n-                let last_bpos = self.pos;\n-                let bpos = self.next_pos;\n-                let mut err = self.struct_fatal_span_char(last_bpos,\n-                                                          bpos,\n-                                                          \"unknown start of token\",\n-                                                          c);\n-                unicode_chars::check_for_substitution(self, c, &mut err);\n-                self.fatal_errs.push(err);\n-\n-                Err(())\n-            }\n-        }\n-    }\n-\n-    fn read_to_eol(&mut self) -> String {\n-        let mut val = String::new();\n-        while !self.ch_is('\\n') && !self.is_eof() {\n-            val.push(self.ch.unwrap());\n-            self.bump();\n-        }\n-\n-        if self.ch_is('\\n') {\n-            self.bump();\n-        }\n-\n-        val\n-    }\n-\n-    fn read_one_line_comment(&mut self) -> String {\n-        let val = self.read_to_eol();\n-        assert!((val.as_bytes()[0] == b'/' && val.as_bytes()[1] == b'/') ||\n-                (val.as_bytes()[0] == b'#' && val.as_bytes()[1] == b'!'));\n-        val\n+    fn report_non_started_raw_string(&self, start: BytePos) -> ! {\n+        let bad_char = self.str_from(start).chars().last().unwrap();\n+        self\n+            .struct_fatal_span_char(\n+                start,\n+                self.pos,\n+                \"found invalid character; only `#` is allowed \\\n+                 in raw string delimitation\",\n+                bad_char,\n+            )\n+            .emit();\n+        FatalError.raise()\n     }\n \n-    fn consume_non_eol_whitespace(&mut self) {\n-        while is_pattern_whitespace(self.ch) && !self.ch_is('\\n') && !self.is_eof() {\n-            self.bump();\n-        }\n-    }\n+    fn report_unterminated_raw_string(&self, start: BytePos, n_hashes: usize) -> ! {\n+        let mut err = self.struct_span_fatal(\n+            start, start,\n+            \"unterminated raw string\",\n+        );\n+        err.span_label(\n+            self.mk_sp(start, start),\n+            \"unterminated raw string\",\n+        );\n \n-    fn peeking_at_comment(&self) -> bool {\n-        (self.ch_is('/') && self.nextch_is('/')) || (self.ch_is('/') && self.nextch_is('*')) ||\n-        // consider shebangs comments, but not inner attributes\n-        (self.ch_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n-    }\n-\n-    fn scan_single_quoted_string(&mut self,\n-                                 start_with_quote: BytePos,\n-                                 unterminated_msg: &str) -> Symbol {\n-        // assumes that first `'` is consumed\n-        let start = self.pos;\n-        // lex `'''` as a single char, for recovery\n-        if self.ch_is('\\'') && self.nextch_is('\\'') {\n-            self.bump();\n-        } else {\n-            let mut first = true;\n-            loop {\n-                if self.ch_is('\\'') {\n-                    break;\n-                }\n-                if self.ch_is('\\\\') && (self.nextch_is('\\'') || self.nextch_is('\\\\')) {\n-                    self.bump();\n-                    self.bump();\n-                } else {\n-                    // Only attempt to infer single line string literals. If we encounter\n-                    // a slash, bail out in order to avoid nonsensical suggestion when\n-                    // involving comments.\n-                    if self.is_eof()\n-                        || (self.ch_is('/') && !first)\n-                        || (self.ch_is('\\n') && !self.nextch_is('\\'')) {\n-\n-                        self.fatal_span_(start_with_quote, self.pos, unterminated_msg.into())\n-                            .raise()\n-                    }\n-                    self.bump();\n-                }\n-                first = false;\n-            }\n+        if n_hashes > 0 {\n+            err.note(&format!(\"this raw string should be terminated with `\\\"{}`\",\n+                                \"#\".repeat(n_hashes as usize)));\n         }\n \n-        let id = self.symbol_from(start);\n-        self.bump();\n-        id\n-    }\n-\n-    fn scan_double_quoted_string(&mut self, unterminated_msg: &str) -> Symbol {\n-        debug_assert!(self.ch_is('\\\"'));\n-        let start_with_quote = self.pos;\n-        self.bump();\n-        let start = self.pos;\n-        while !self.ch_is('\"') {\n-            if self.is_eof() {\n-                let pos = self.pos;\n-                self.fatal_span_(start_with_quote, pos, unterminated_msg).raise();\n-            }\n-            if self.ch_is('\\\\') && (self.nextch_is('\\\\') || self.nextch_is('\"')) {\n-                self.bump();\n-            }\n-            self.bump();\n-        }\n-        let id = self.symbol_from(start);\n-        self.bump();\n-        id\n+        err.emit();\n+        FatalError.raise()\n     }\n \n-    /// Scans a raw (byte) string, returning byte position range for `\"<literal>\"`\n-    /// (including quotes) along with `#` character count in `(b)r##...\"<literal>\"##...`;\n-    fn scan_raw_string(&mut self) -> (BytePos, BytePos, u16) {\n-        let start_bpos = self.pos;\n-        self.bump();\n-        let mut hash_count: u16 = 0;\n-        while self.ch_is('#') {\n-            if hash_count == 65535 {\n-                let bpos = self.next_pos;\n-                self.fatal_span_(start_bpos,\n-                                 bpos,\n+    fn restrict_n_hashes(&self, start: BytePos, n_hashes: usize) -> u16 {\n+        match n_hashes.try_into() {\n+            Ok(n_hashes) => n_hashes,\n+            Err(_) => {\n+                self.fatal_span_(start,\n+                                 self.pos,\n                                  \"too many `#` symbols: raw strings may be \\\n-                                 delimited by up to 65535 `#` symbols\").raise();\n-            }\n-            self.bump();\n-            hash_count += 1;\n-        }\n-\n-        if self.is_eof() {\n-            self.fail_unterminated_raw_string(start_bpos, hash_count);\n-        } else if !self.ch_is('\"') {\n-            let last_bpos = self.pos;\n-            let curr_char = self.ch.unwrap();\n-            self.fatal_span_char(start_bpos,\n-                                 last_bpos,\n-                                 \"found invalid character; only `#` is allowed \\\n-                                 in raw string delimitation\",\n-                                 curr_char).raise();\n-        }\n-        self.bump();\n-        let content_start_bpos = self.pos;\n-        let mut content_end_bpos;\n-        'outer: loop {\n-            match self.ch {\n-                None => {\n-                    self.fail_unterminated_raw_string(start_bpos, hash_count);\n-                }\n-                Some('\"') => {\n-                    content_end_bpos = self.pos;\n-                    for _ in 0..hash_count {\n-                        self.bump();\n-                        if !self.ch_is('#') {\n-                            continue 'outer;\n-                        }\n-                    }\n-                    break;\n-                }\n-                _ => (),\n+                                  delimited by up to 65535 `#` symbols\").raise();\n             }\n-            self.bump();\n         }\n-\n-        self.bump();\n-\n-        (content_start_bpos, content_end_bpos, hash_count)\n     }\n \n-    fn validate_char_escape(&self, start_with_quote: BytePos) {\n-        let lit = self.str_from_to(start_with_quote + BytePos(1), self.pos - BytePos(1));\n+    fn validate_char_escape(&self, content_start: BytePos, content_end: BytePos) {\n+        let lit = self.str_from_to(content_start, content_end);\n         if let Err((off, err)) = unescape::unescape_char(lit) {\n             emit_unescape_error(\n                 &self.sess.span_diagnostic,\n                 lit,\n-                self.mk_sp(start_with_quote, self.pos),\n+                self.mk_sp(content_start - BytePos(1), content_end + BytePos(1)),\n                 unescape::Mode::Char,\n                 0..off,\n                 err,\n             )\n         }\n     }\n \n-    fn validate_byte_escape(&self, start_with_quote: BytePos) {\n-        let lit = self.str_from_to(start_with_quote + BytePos(1), self.pos - BytePos(1));\n+    fn validate_byte_escape(&self, content_start: BytePos, content_end: BytePos) {\n+        let lit = self.str_from_to(content_start, content_end);\n         if let Err((off, err)) = unescape::unescape_byte(lit) {\n             emit_unescape_error(\n                 &self.sess.span_diagnostic,\n                 lit,\n-                self.mk_sp(start_with_quote, self.pos),\n+                self.mk_sp(content_start - BytePos(1), content_end + BytePos(1)),\n                 unescape::Mode::Byte,\n                 0..off,\n                 err,\n             )\n         }\n     }\n \n-    fn validate_str_escape(&self, start_with_quote: BytePos) {\n-        let lit = self.str_from_to(start_with_quote + BytePos(1), self.pos - BytePos(1));\n+    fn validate_str_escape(&self, content_start: BytePos, content_end: BytePos) {\n+        let lit = self.str_from_to(content_start, content_end);\n         unescape::unescape_str(lit, &mut |range, c| {\n             if let Err(err) = c {\n                 emit_unescape_error(\n                     &self.sess.span_diagnostic,\n                     lit,\n-                    self.mk_sp(start_with_quote, self.pos),\n+                    self.mk_sp(content_start - BytePos(1), content_end + BytePos(1)),\n                     unescape::Mode::Str,\n                     range,\n                     err,\n@@ -1276,38 +718,40 @@ impl<'a> StringReader<'a> {\n         })\n     }\n \n-    fn validate_byte_str_escape(&self, start_with_quote: BytePos) {\n-        let lit = self.str_from_to(start_with_quote + BytePos(1), self.pos - BytePos(1));\n+    fn validate_byte_str_escape(&self, content_start: BytePos, content_end: BytePos) {\n+        let lit = self.str_from_to(content_start, content_end);\n         unescape::unescape_byte_str(lit, &mut |range, c| {\n             if let Err(err) = c {\n                 emit_unescape_error(\n                     &self.sess.span_diagnostic,\n                     lit,\n-                    self.mk_sp(start_with_quote, self.pos),\n+                    self.mk_sp(content_start - BytePos(1), content_end + BytePos(1)),\n                     unescape::Mode::ByteStr,\n                     range,\n                     err,\n                 )\n             }\n         })\n     }\n-}\n \n-// This tests the character for the unicode property 'PATTERN_WHITE_SPACE' which\n-// is guaranteed to be forward compatible. http://unicode.org/reports/tr31/#R3\n-#[inline]\n-crate fn is_pattern_whitespace(c: Option<char>) -> bool {\n-    c.map_or(false, Pattern_White_Space)\n-}\n-\n-#[inline]\n-fn in_range(c: Option<char>, lo: char, hi: char) -> bool {\n-    c.map_or(false, |c| lo <= c && c <= hi)\n-}\n+    fn validate_int_literal(&self, base: Base, content_start: BytePos, content_end: BytePos) {\n+        let base = match base {\n+            Base::Binary => 2,\n+            Base::Octal => 8,\n+            _ => return,\n+        };\n+        let s = self.str_from_to(content_start + BytePos(2), content_end);\n+        for (idx, c) in s.char_indices() {\n+            let idx = idx as u32;\n+            if c != '_' && c.to_digit(base).is_none() {\n+                let lo = content_start + BytePos(2 + idx);\n+                let hi = content_start + BytePos(2 + idx + c.len_utf8() as u32);\n+                self.err_span_(lo, hi,\n+                               &format!(\"invalid digit for a base {} literal\", base));\n \n-#[inline]\n-fn is_dec_digit(c: Option<char>) -> bool {\n-    in_range(c, '0', '9')\n+            }\n+        }\n+    }\n }\n \n fn is_doc_comment(s: &str) -> bool {\n@@ -1325,31 +769,6 @@ fn is_block_doc_comment(s: &str) -> bool {\n     res\n }\n \n-/// Determine whether `c` is a valid start for an ident.\n-fn ident_start(c: Option<char>) -> bool {\n-    let c = match c {\n-        Some(c) => c,\n-        None => return false,\n-    };\n-\n-    (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || c == '_' || (c > '\\x7f' && c.is_xid_start())\n-}\n-\n-fn ident_continue(c: Option<char>) -> bool {\n-    let c = match c {\n-        Some(c) => c,\n-        None => return false,\n-    };\n-\n-    (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || c == '_' ||\n-    (c > '\\x7f' && c.is_xid_continue())\n-}\n-\n-#[inline]\n-fn char_at(s: &str, byte: usize) -> char {\n-    s[byte..].chars().next().unwrap()\n-}\n-\n #[cfg(test)]\n mod tests {\n     use super::*;"}, {"sha": "e51657c0f132abf83e3380760256707346628b86", "filename": "src/libsyntax/parse/lexer/unicode_chars.rs", "status": "modified", "additions": 17, "deletions": 24, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Funicode_chars.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -3,7 +3,7 @@\n \n use super::StringReader;\n use errors::{Applicability, DiagnosticBuilder};\n-use syntax_pos::{Pos, Span, NO_EXPANSION};\n+use syntax_pos::{BytePos, Pos, Span, NO_EXPANSION};\n \n #[rustfmt::skip] // for line breaks\n const UNICODE_ARRAY: &[(char, &str, char)] = &[\n@@ -327,6 +327,7 @@ const ASCII_ARRAY: &[(char, &str)] = &[\n \n crate fn check_for_substitution<'a>(\n     reader: &StringReader<'a>,\n+    pos: BytePos,\n     ch: char,\n     err: &mut DiagnosticBuilder<'a>,\n ) -> bool {\n@@ -335,28 +336,28 @@ crate fn check_for_substitution<'a>(\n         None => return false,\n     };\n \n-    let span = Span::new(reader.pos, reader.next_pos, NO_EXPANSION);\n+    let span = Span::new(pos, pos + Pos::from_usize(ch.len_utf8()), NO_EXPANSION);\n \n     let ascii_name = match ASCII_ARRAY.iter().find(|&&(c, _)| c == ascii_char) {\n         Some((_ascii_char, ascii_name)) => ascii_name,\n         None => {\n             let msg = format!(\"substitution character not found for '{}'\", ch);\n             reader.sess.span_diagnostic.span_bug_no_panic(span, &msg);\n-            return false\n-        },\n+            return false;\n+        }\n     };\n \n     // special help suggestion for \"directed\" double quotes\n-    if let Some(s) = reader.peek_delimited('\u201c', '\u201d') {\n+    if let Some(s) = peek_delimited(&reader.src[reader.src_index(pos)..], '\u201c', '\u201d') {\n         let msg = format!(\n             \"Unicode characters '\u201c' (Left Double Quotation Mark) and \\\n              '\u201d' (Right Double Quotation Mark) look like '{}' ({}), but are not\",\n             ascii_char, ascii_name\n         );\n         err.span_suggestion(\n             Span::new(\n-                reader.pos,\n-                reader.next_pos + Pos::from_usize(s.len()) + Pos::from_usize('\u201d'.len_utf8()),\n+                pos,\n+                pos + Pos::from_usize('\u201c'.len_utf8() + s.len() + '\u201d'.len_utf8()),\n                 NO_EXPANSION,\n             ),\n             &msg,\n@@ -368,26 +369,18 @@ crate fn check_for_substitution<'a>(\n             \"Unicode character '{}' ({}) looks like '{}' ({}), but it is not\",\n             ch, u_name, ascii_char, ascii_name\n         );\n-        err.span_suggestion(\n-            span,\n-            &msg,\n-            ascii_char.to_string(),\n-            Applicability::MaybeIncorrect,\n-        );\n+        err.span_suggestion(span, &msg, ascii_char.to_string(), Applicability::MaybeIncorrect);\n     }\n     true\n }\n \n-impl StringReader<'_> {\n-    /// Immutably extract string if found at current position with given delimiters\n-    fn peek_delimited(&self, from_ch: char, to_ch: char) -> Option<&str> {\n-        let tail = &self.src[self.src_index(self.pos)..];\n-        let mut chars = tail.chars();\n-        let first_char = chars.next()?;\n-        if first_char != from_ch {\n-            return None;\n-        }\n-        let last_char_idx = chars.as_str().find(to_ch)?;\n-        Some(&chars.as_str()[..last_char_idx])\n+/// Extract string if found at current position with given delimiters\n+fn peek_delimited(text: &str, from_ch: char, to_ch: char) -> Option<&str> {\n+    let mut chars = text.chars();\n+    let first_char = chars.next()?;\n+    if first_char != from_ch {\n+        return None;\n     }\n+    let last_char_idx = chars.as_str().find(to_ch)?;\n+    Some(&chars.as_str()[..last_char_idx])\n }"}, {"sha": "627422df1db1c9cc8c9edc4818638f9770a1df87", "filename": "src/libsyntax/util/parser_testing.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Flibsyntax%2Futil%2Fparser_testing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Futil%2Fparser_testing.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -1,7 +1,7 @@\n use crate::ast::{self, Ident};\n use crate::source_map::FilePathMapping;\n use crate::parse::{ParseSess, PResult, source_file_to_stream};\n-use crate::parse::{lexer, new_parser_from_source_str};\n+use crate::parse::new_parser_from_source_str;\n use crate::parse::parser::Parser;\n use crate::ptr::P;\n use crate::tokenstream::TokenStream;\n@@ -113,14 +113,14 @@ pub fn matches_codepattern(a : &str, b : &str) -> bool {\n }\n \n /// Advances the given peekable `Iterator` until it reaches a non-whitespace character\n-fn scan_for_non_ws_or_end<I: Iterator<Item= char>>(iter: &mut Peekable<I>) {\n-    while lexer::is_pattern_whitespace(iter.peek().cloned()) {\n+fn scan_for_non_ws_or_end<I: Iterator<Item = char>>(iter: &mut Peekable<I>) {\n+    while iter.peek().copied().map(|c| is_pattern_whitespace(c)) == Some(true) {\n         iter.next();\n     }\n }\n \n pub fn is_pattern_whitespace(c: char) -> bool {\n-    lexer::is_pattern_whitespace(Some(c))\n+    rustc_lexer::character_properties::is_whitespace(c)\n }\n \n #[cfg(test)]"}, {"sha": "5c2c3b8ec61d5316f1841fc6352390f911ac537b", "filename": "src/test/ui/did_you_mean/issue-49746-unicode-confusable-in-float-literal-expt.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.rs?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -1,4 +1,5 @@\n const UNIVERSAL_GRAVITATIONAL_CONSTANT: f64 = 6.674e\u221211; // m\u00b3\u22c5kg\u207b\u00b9\u22c5s\u207b\u00b2\n //~^ ERROR expected at least one digit in exponent\n+//~| ERROR unknown start of token: \\u{2212}\n \n fn main() {}"}, {"sha": "07653c791db1cfb0d0e884995dd6a7221d97ef8d", "filename": "src/test/ui/did_you_mean/issue-49746-unicode-confusable-in-float-literal-expt.stderr", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fdid_you_mean%2Fissue-49746-unicode-confusable-in-float-literal-expt.stderr?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -1,4 +1,10 @@\n error: expected at least one digit in exponent\n+  --> $DIR/issue-49746-unicode-confusable-in-float-literal-expt.rs:1:47\n+   |\n+LL | const UNIVERSAL_GRAVITATIONAL_CONSTANT: f64 = 6.674e\u221211; // m\u00b3\u22c5kg\u207b\u00b9\u22c5s\u207b\u00b2\n+   |                                               ^^^^^^\n+\n+error: unknown start of token: \\u{2212}\n   --> $DIR/issue-49746-unicode-confusable-in-float-literal-expt.rs:1:53\n    |\n LL | const UNIVERSAL_GRAVITATIONAL_CONSTANT: f64 = 6.674e\u221211; // m\u00b3\u22c5kg\u207b\u00b9\u22c5s\u207b\u00b2\n@@ -8,5 +14,5 @@ help: Unicode character '\u2212' (Minus Sign) looks like '-' (Minus/Hyphen), but it\n LL | const UNIVERSAL_GRAVITATIONAL_CONSTANT: f64 = 6.674e-11; // m\u00b3\u22c5kg\u207b\u00b9\u22c5s\u207b\u00b2\n    |                                                     ^\n \n-error: aborting due to previous error\n+error: aborting due to 2 previous errors\n "}, {"sha": "151480dd012a3025c7d7ec7a88710304bf92ece9", "filename": "src/test/ui/parser/lex-bad-numeric-literals.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-bad-numeric-literals.stderr?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -53,10 +53,10 @@ LL |     0o;\n    |     ^^\n \n error: expected at least one digit in exponent\n-  --> $DIR/lex-bad-numeric-literals.rs:12:8\n+  --> $DIR/lex-bad-numeric-literals.rs:12:5\n    |\n LL |     1e+;\n-   |        ^\n+   |     ^^^\n \n error: hexadecimal float literal is not supported\n   --> $DIR/lex-bad-numeric-literals.rs:13:5"}, {"sha": "65fa89f2a81ac178290ecc8fc460eb9629b0f9b1", "filename": "src/test/ui/parser/raw-byte-string-eof.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-eof.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-eof.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-eof.stderr?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -1,8 +1,8 @@\n error: unterminated raw string\n-  --> $DIR/raw-byte-string-eof.rs:2:6\n+  --> $DIR/raw-byte-string-eof.rs:2:5\n    |\n LL |     br##\"a\"#;\n-   |      ^ unterminated raw string\n+   |     ^ unterminated raw string\n    |\n    = note: this raw string should be terminated with `\"##`\n "}, {"sha": "4076fe334e6533e3ddf1a697d9db181ef1e48512", "filename": "src/test/ui/parser/raw-byte-string-literals.stderr", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-literals.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-literals.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fraw-byte-string-literals.stderr?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -11,10 +11,10 @@ LL |     br\"\u00e9\";\n    |        ^\n \n error: found invalid character; only `#` is allowed in raw string delimitation: ~\n-  --> $DIR/raw-byte-string-literals.rs:6:6\n+  --> $DIR/raw-byte-string-literals.rs:6:5\n    |\n LL |     br##~\"a\"~##;\n-   |      ^^^\n+   |     ^^^^^\n \n error: aborting due to 3 previous errors\n "}, {"sha": "8a04f99a126dadb7534b8f9faa8affc217ead99a", "filename": "src/test/ui/parser/raw-str-delim.stderr", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-str-delim.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/395ee0b79f23b90593b01dd0a78451b8c93b0aa6/src%2Ftest%2Fui%2Fparser%2Fraw-str-delim.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Fraw-str-delim.stderr?ref=395ee0b79f23b90593b01dd0a78451b8c93b0aa6", "patch": "@@ -2,7 +2,7 @@ error: found invalid character; only `#` is allowed in raw string delimitation:\n   --> $DIR/raw-str-delim.rs:2:5\n    |\n LL |     r#~\"#\"~#\n-   |     ^^\n+   |     ^^^\n \n error: aborting due to previous error\n "}]}