{"sha": "fad27df3e7aafbd83341df34d397fe4015f69679", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZhZDI3ZGYzZTdhYWZiZDgzMzQxZGYzNGQzOTdmZTQwMTVmNjk2Nzk=", "commit": {"author": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2019-06-23T01:37:23Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2019-06-25T10:59:49Z"}, "message": "rustc: correctly transform memory_index mappings for generators.", "tree": {"sha": "568d893e2edea22ff4e721e49aaee78bf4db7b18", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/568d893e2edea22ff4e721e49aaee78bf4db7b18"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fad27df3e7aafbd83341df34d397fe4015f69679", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fad27df3e7aafbd83341df34d397fe4015f69679", "html_url": "https://github.com/rust-lang/rust/commit/fad27df3e7aafbd83341df34d397fe4015f69679", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fad27df3e7aafbd83341df34d397fe4015f69679/comments", "author": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dbec74ffa7982de8e066a93969ce70a891d7908b", "url": "https://api.github.com/repos/rust-lang/rust/commits/dbec74ffa7982de8e066a93969ce70a891d7908b", "html_url": "https://github.com/rust-lang/rust/commit/dbec74ffa7982de8e066a93969ce70a891d7908b"}], "stats": {"total": 145, "additions": 107, "deletions": 38}, "files": [{"sha": "4af26e19b370c08e8ec33c3a236cbfc3fe86b6ef", "filename": "src/librustc/ty/layout.rs", "status": "modified", "additions": 78, "deletions": 37, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Flibrustc%2Fty%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Flibrustc%2Fty%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Flayout.rs?ref=fad27df3e7aafbd83341df34d397fe4015f69679", "patch": "@@ -226,6 +226,19 @@ enum StructKind {\n     Prefixed(Size, Align),\n }\n \n+// Invert a bijective mapping, i.e. `invert(map)[y] = x` if `map[x] = y`.\n+// This is used to go between `memory_index` (source field order to memory order)\n+// and `inverse_memory_index` (memory order to source field order).\n+// See also `FieldPlacement::Arbitrary::memory_index` for more details.\n+// FIXME(eddyb) build a better abstraction for permutations, if possible.\n+fn invert_mapping(map: &[u32]) -> Vec<u32> {\n+    let mut inverse = vec![0; map.len()];\n+    for i in 0..map.len() {\n+        inverse[map[i] as usize] = i as u32;\n+    }\n+    inverse\n+}\n+\n impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n     fn scalar_pair(&self, a: Scalar, b: Scalar) -> LayoutDetails {\n         let dl = self.data_layout();\n@@ -303,7 +316,9 @@ impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n         // That is, if field 5 has offset 0, the first element of inverse_memory_index is 5.\n         // We now write field offsets to the corresponding offset slot;\n         // field 5 with offset 0 puts 0 in offsets[5].\n-        // At the bottom of this function, we use inverse_memory_index to produce memory_index.\n+        // At the bottom of this function, we invert `inverse_memory_index` to\n+        // produce `memory_index` (see `invert_mapping`).\n+\n \n         let mut offset = Size::ZERO;\n \n@@ -360,13 +375,9 @@ impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n         // Field 5 would be the first element, so memory_index is i:\n         // Note: if we didn't optimize, it's already right.\n \n-        let mut memory_index;\n+        let memory_index;\n         if optimize {\n-            memory_index = vec![0; inverse_memory_index.len()];\n-\n-            for i in 0..inverse_memory_index.len() {\n-                memory_index[inverse_memory_index[i] as usize]  = i as u32;\n-            }\n+            memory_index = invert_mapping(&inverse_memory_index);\n         } else {\n             memory_index = inverse_memory_index;\n         }\n@@ -1311,18 +1322,7 @@ impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n     ) -> Result<&'tcx LayoutDetails, LayoutError<'tcx>> {\n         use SavedLocalEligibility::*;\n         let tcx = self.tcx;\n-        let recompute_memory_index = |offsets: &[Size]| -> Vec<u32> {\n-            debug!(\"recompute_memory_index({:?})\", offsets);\n-            let mut inverse_index = (0..offsets.len() as u32).collect::<Vec<_>>();\n-            inverse_index.sort_unstable_by_key(|i| offsets[*i as usize]);\n \n-            let mut index = vec![0; offsets.len()];\n-            for i in 0..index.len() {\n-                index[inverse_index[i] as usize] = i as u32;\n-            }\n-            debug!(\"recompute_memory_index() => {:?}\", index);\n-            index\n-        };\n         let subst_field = |ty: Ty<'tcx>| { ty.subst(tcx, substs.substs) };\n \n         let info = tcx.generator_layout(def_id);\n@@ -1349,14 +1349,34 @@ impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n         // get included in each variant that requested them in\n         // GeneratorLayout.\n         debug!(\"prefix = {:#?}\", prefix);\n-        let (outer_fields, promoted_offsets) = match prefix.fields {\n-            FieldPlacement::Arbitrary { mut offsets, .. } => {\n-                let offsets_b = offsets.split_off(discr_index + 1);\n+        let (outer_fields, promoted_offsets, promoted_memory_index) = match prefix.fields {\n+            FieldPlacement::Arbitrary { mut offsets, memory_index } => {\n+                let mut inverse_memory_index = invert_mapping(&memory_index);\n+\n+                // \"a\" (`0..b_start`) and \"b\" (`b_start..`) correspond to\n+                // \"outer\" and \"promoted\" fields respectively.\n+                let b_start = (discr_index + 1) as u32;\n+                let offsets_b = offsets.split_off(b_start as usize);\n                 let offsets_a = offsets;\n \n-                let memory_index = recompute_memory_index(&offsets_a);\n-                let outer_fields = FieldPlacement::Arbitrary { offsets: offsets_a, memory_index };\n-                (outer_fields, offsets_b)\n+                // Disentangle the \"a\" and \"b\" components of `inverse_memory_index`\n+                // by preserving the order but keeping only one disjoint \"half\" each.\n+                // FIXME(eddyb) build a better abstraction for permutations, if possible.\n+                let inverse_memory_index_b: Vec<_> =\n+                    inverse_memory_index.iter().filter_map(|&i| i.checked_sub(b_start)).collect();\n+                inverse_memory_index.retain(|&i| i < b_start);\n+                let inverse_memory_index_a = inverse_memory_index;\n+\n+                // Since `inverse_memory_index_{a,b}` each only refer to their\n+                // respective fields, they can be safely inverted\n+                let memory_index_a = invert_mapping(&inverse_memory_index_a);\n+                let memory_index_b = invert_mapping(&inverse_memory_index_b);\n+\n+                let outer_fields = FieldPlacement::Arbitrary {\n+                    offsets: offsets_a,\n+                    memory_index: memory_index_a,\n+                };\n+                (outer_fields, offsets_b, memory_index_b)\n             }\n             _ => bug!(),\n         };\n@@ -1386,30 +1406,51 @@ impl<'tcx> LayoutCx<'tcx, TyCtxt<'tcx>> {\n                 StructKind::Prefixed(prefix_size, prefix_align.abi))?;\n             variant.variants = Variants::Single { index };\n \n-            let offsets = match variant.fields {\n-                FieldPlacement::Arbitrary { offsets, .. } => offsets,\n+            let (offsets, memory_index) = match variant.fields {\n+                FieldPlacement::Arbitrary { offsets, memory_index } => {\n+                    (offsets, memory_index)\n+                }\n                 _ => bug!(),\n             };\n \n             // Now, stitch the promoted and variant-only fields back together in\n             // the order they are mentioned by our GeneratorLayout.\n-            let mut next_variant_field = 0;\n-            let mut combined_offsets = Vec::new();\n-            for local in variant_fields.iter() {\n-                match assignments[*local] {\n+            // Because we only use some subset (that can differ between variants)\n+            // of the promoted fields, we can't just pick those elements of the\n+            // `promoted_memory_index` (as we'd end up with gaps).\n+            // So instead, we build an \"inverse memory_index\", as if all of the\n+            // promoted fields were being used, but leave the elements not in the\n+            // subset as `INVALID_FIELD_IDX`, which we can filter out later to\n+            // obtain a valid (bijective) mapping.\n+            const INVALID_FIELD_IDX: u32 = !0;\n+            let mut combined_inverse_memory_index =\n+                vec![INVALID_FIELD_IDX; promoted_memory_index.len() + memory_index.len()];\n+            let mut offsets_and_memory_index = offsets.into_iter().zip(memory_index);\n+            let combined_offsets = variant_fields.iter().enumerate().map(|(i, local)| {\n+                let (offset, memory_index) = match assignments[*local] {\n                     Unassigned => bug!(),\n                     Assigned(_) => {\n-                        combined_offsets.push(offsets[next_variant_field]);\n-                        next_variant_field += 1;\n+                        let (offset, memory_index) = offsets_and_memory_index.next().unwrap();\n+                        (offset, promoted_memory_index.len() as u32 + memory_index)\n                     }\n                     Ineligible(field_idx) => {\n                         let field_idx = field_idx.unwrap() as usize;\n-                        combined_offsets.push(promoted_offsets[field_idx]);\n+                        (promoted_offsets[field_idx], promoted_memory_index[field_idx])\n                     }\n-                }\n-            }\n-            let memory_index = recompute_memory_index(&combined_offsets);\n-            variant.fields = FieldPlacement::Arbitrary { offsets: combined_offsets, memory_index };\n+                };\n+                combined_inverse_memory_index[memory_index as usize] = i as u32;\n+                offset\n+            }).collect();\n+\n+            // Remove the unused slots and invert the mapping to obtain the\n+            // combined `memory_index` (also see previous comment).\n+            combined_inverse_memory_index.retain(|&i| i != INVALID_FIELD_IDX);\n+            let combined_memory_index = invert_mapping(&combined_inverse_memory_index);\n+\n+            variant.fields = FieldPlacement::Arbitrary {\n+                offsets: combined_offsets,\n+                memory_index: combined_memory_index,\n+            };\n \n             size = size.max(variant.size);\n             align = align.max(variant.align);"}, {"sha": "55cb179144309987c4c84c3e0e7bb06f6752d3a0", "filename": "src/librustc_target/abi/mod.rs", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Flibrustc_target%2Fabi%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Flibrustc_target%2Fabi%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_target%2Fabi%2Fmod.rs?ref=fad27df3e7aafbd83341df34d397fe4015f69679", "patch": "@@ -699,7 +699,16 @@ pub enum FieldPlacement {\n         offsets: Vec<Size>,\n \n         /// Maps source order field indices to memory order indices,\n-        /// depending how fields were permuted.\n+        /// depending on how the fields were reordered (if at all).\n+        /// This is a permutation, with both the source order and the\n+        /// memory order using the same (0..n) index ranges.\n+        ///\n+        /// Note that during computation of `memory_index`, sometimes\n+        /// it is easier to operate on the inverse mapping (that is,\n+        /// from memory order to source order), and that is usually\n+        /// named `inverse_memory_index`.\n+        ///\n+        // FIXME(eddyb) build a better abstraction for permutations, if possible.\n         // FIXME(camlorn) also consider small vector  optimization here.\n         memory_index: Vec<u32>\n     }"}, {"sha": "bccdf0113ff69c948d9d8ac97309cf247b7ac31c", "filename": "src/test/ui/async-await/issue-61793.rs", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Ftest%2Fui%2Fasync-await%2Fissue-61793.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fad27df3e7aafbd83341df34d397fe4015f69679/src%2Ftest%2Fui%2Fasync-await%2Fissue-61793.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fasync-await%2Fissue-61793.rs?ref=fad27df3e7aafbd83341df34d397fe4015f69679", "patch": "@@ -0,0 +1,19 @@\n+// This testcase used to ICE in codegen due to inconsistent field reordering\n+// in the generator state, claiming a ZST field was after a non-ZST field,\n+// while those two fields were at the same offset (which is impossible).\n+// That is, memory ordering of `(X, ())`, but offsets of `((), X)`.\n+\n+// compile-pass\n+// edition:2018\n+\n+#![feature(async_await)]\n+#![allow(unused)]\n+\n+async fn foo<F>(_: &(), _: F) {}\n+\n+fn main() {\n+    foo(&(), || {});\n+    async {\n+        foo(&(), || {}).await;\n+    };\n+}"}]}