{"sha": "860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg2MGU2YmRkMmZmZmJjOThlNjc4NTFlYWFlYzg3ZmI0MzBiZGQxNmI=", "commit": {"author": {"name": "Dylan DPC", "email": "dylan.dpc@gmail.com", "date": "2020-06-09T23:06:23Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-06-09T23:06:23Z"}, "message": "Rollup merge of #72417 - nnethercote:rm-RawVec-reserve_in_place, r=Amanieu\n\nRemove `RawVec::reserve_in_place`.\n\nAnd some related clean-ups.\n\nr? @oli-obk", "tree": {"sha": "30df97157d6e0ab7f35e896d8a68a58821356f40", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/30df97157d6e0ab7f35e896d8a68a58821356f40"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe4BXwCRBK7hj4Ov3rIwAAdHIIAF9uJuAeJ482nb193IraWr0G\nRMrYfY9V6pZCvCwCLvdP9DQtifsizmXZ1++GbKZG4Hl78LC6s6A6ZTxWy5BtmvH4\nfS7DgqsQzRepup20+Z3gvH5HtkM1psu+4bnA5lUuqyBl22aeD2PyGIwBvbR6CDiX\nZPYqbiu/qQ+FGM5x+skwVbbIoLlZaEyBOHEpa4XQa++2XWxgXZ2PtO9sSsUudbcd\nGabRBGaOBQH9MoLeIQ1ExhzDvnDBiWZll9rqYkIsZ70gXU9UZMiN5eq4Ajt0QYXC\nDCNHBZKPTtvjZYck1YV7JUe+pWNYDKT6oQvFCZMhUYDM3n+/Wt1FDO6roEHCOiY=\n=6pYE\n-----END PGP SIGNATURE-----\n", "payload": "tree 30df97157d6e0ab7f35e896d8a68a58821356f40\nparent feb3536eba10c2e4585d066629598f03d5ddc7c6\nparent c9cbe7e7eb37ec06a9c76a6b9ca4d342ff5a1128\nauthor Dylan DPC <dylan.dpc@gmail.com> 1591743983 +0200\ncommitter GitHub <noreply@github.com> 1591743983 +0200\n\nRollup merge of #72417 - nnethercote:rm-RawVec-reserve_in_place, r=Amanieu\n\nRemove `RawVec::reserve_in_place`.\n\nAnd some related clean-ups.\n\nr? @oli-obk\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "html_url": "https://github.com/rust-lang/rust/commit/860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "feb3536eba10c2e4585d066629598f03d5ddc7c6", "url": "https://api.github.com/repos/rust-lang/rust/commits/feb3536eba10c2e4585d066629598f03d5ddc7c6", "html_url": "https://github.com/rust-lang/rust/commit/feb3536eba10c2e4585d066629598f03d5ddc7c6"}, {"sha": "c9cbe7e7eb37ec06a9c76a6b9ca4d342ff5a1128", "url": "https://api.github.com/repos/rust-lang/rust/commits/c9cbe7e7eb37ec06a9c76a6b9ca4d342ff5a1128", "html_url": "https://github.com/rust-lang/rust/commit/c9cbe7e7eb37ec06a9c76a6b9ca4d342ff5a1128"}], "stats": {"total": 216, "additions": 79, "deletions": 137}, "files": [{"sha": "805dbfe277584f58c2c699931dc5bff56174af08", "filename": "src/liballoc/raw_vec.rs", "status": "modified", "additions": 36, "deletions": 86, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Fliballoc%2Fraw_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Fliballoc%2Fraw_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec.rs?ref=860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "patch": "@@ -9,7 +9,7 @@ use core::ptr::{NonNull, Unique};\n use core::slice;\n \n use crate::alloc::{\n-    handle_alloc_error, AllocErr,\n+    handle_alloc_error,\n     AllocInit::{self, *},\n     AllocRef, Global, Layout,\n     ReallocPlacement::{self, *},\n@@ -235,13 +235,13 @@ impl<T, A: AllocRef> RawVec<T, A> {\n         }\n     }\n \n-    /// Ensures that the buffer contains at least enough space to hold\n-    /// `used_capacity + needed_extra_capacity` elements. If it doesn't already have\n-    /// enough capacity, will reallocate enough space plus comfortable slack\n-    /// space to get amortized `O(1)` behavior. Will limit this behavior\n-    /// if it would needlessly cause itself to panic.\n+    /// Ensures that the buffer contains at least enough space to hold `len +\n+    /// additional` elements. If it doesn't already have enough capacity, will\n+    /// reallocate enough space plus comfortable slack space to get amortized\n+    /// `O(1)` behavior. Will limit this behavior if it would needlessly cause\n+    /// itself to panic.\n     ///\n-    /// If `used_capacity` exceeds `self.capacity()`, this may fail to actually allocate\n+    /// If `len` exceeds `self.capacity()`, this may fail to actually allocate\n     /// the requested space. This is not really unsafe, but the unsafe\n     /// code *you* write that relies on the behavior of this function may break.\n     ///\n@@ -287,64 +287,32 @@ impl<T, A: AllocRef> RawVec<T, A> {\n     /// #   vector.push_all(&[1, 3, 5, 7, 9]);\n     /// # }\n     /// ```\n-    pub fn reserve(&mut self, used_capacity: usize, needed_extra_capacity: usize) {\n-        match self.try_reserve(used_capacity, needed_extra_capacity) {\n+    pub fn reserve(&mut self, len: usize, additional: usize) {\n+        match self.try_reserve(len, additional) {\n             Err(CapacityOverflow) => capacity_overflow(),\n             Err(AllocError { layout, .. }) => handle_alloc_error(layout),\n             Ok(()) => { /* yay */ }\n         }\n     }\n \n     /// The same as `reserve`, but returns on errors instead of panicking or aborting.\n-    pub fn try_reserve(\n-        &mut self,\n-        used_capacity: usize,\n-        needed_extra_capacity: usize,\n-    ) -> Result<(), TryReserveError> {\n-        if self.needs_to_grow(used_capacity, needed_extra_capacity) {\n-            self.grow_amortized(used_capacity, needed_extra_capacity, MayMove)\n+    pub fn try_reserve(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n+        if self.needs_to_grow(len, additional) {\n+            self.grow_amortized(len, additional)\n         } else {\n             Ok(())\n         }\n     }\n \n-    /// Attempts to ensure that the buffer contains at least enough space to hold\n-    /// `used_capacity + needed_extra_capacity` elements. If it doesn't already have\n-    /// enough capacity, will reallocate in place enough space plus comfortable slack\n-    /// space to get amortized `O(1)` behavior. Will limit this behaviour\n-    /// if it would needlessly cause itself to panic.\n+    /// Ensures that the buffer contains at least enough space to hold `len +\n+    /// additional` elements. If it doesn't already, will reallocate the\n+    /// minimum possible amount of memory necessary. Generally this will be\n+    /// exactly the amount of memory necessary, but in principle the allocator\n+    /// is free to give back more than we asked for.\n     ///\n-    /// If `used_capacity` exceeds `self.capacity()`, this may fail to actually allocate\n-    /// the requested space. This is not really unsafe, but the unsafe\n-    /// code *you* write that relies on the behavior of this function may break.\n-    ///\n-    /// Returns `true` if the reallocation attempt has succeeded.\n-    ///\n-    /// # Panics\n-    ///\n-    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n-    /// * Panics on 32-bit platforms if the requested capacity exceeds\n-    ///   `isize::MAX` bytes.\n-    pub fn reserve_in_place(&mut self, used_capacity: usize, needed_extra_capacity: usize) -> bool {\n-        // This is more readable than putting this in one line:\n-        // `!self.needs_to_grow(...) || self.grow(...).is_ok()`\n-        if self.needs_to_grow(used_capacity, needed_extra_capacity) {\n-            self.grow_amortized(used_capacity, needed_extra_capacity, InPlace).is_ok()\n-        } else {\n-            true\n-        }\n-    }\n-\n-    /// Ensures that the buffer contains at least enough space to hold\n-    /// `used_capacity + needed_extra_capacity` elements. If it doesn't already,\n-    /// will reallocate the minimum possible amount of memory necessary.\n-    /// Generally this will be exactly the amount of memory necessary,\n-    /// but in principle the allocator is free to give back more than what\n-    /// we asked for.\n-    ///\n-    /// If `used_capacity` exceeds `self.capacity()`, this may fail to actually allocate\n-    /// the requested space. This is not really unsafe, but the unsafe\n-    /// code *you* write that relies on the behavior of this function may break.\n+    /// If `len` exceeds `self.capacity()`, this may fail to actually allocate\n+    /// the requested space. This is not really unsafe, but the unsafe code\n+    /// *you* write that relies on the behavior of this function may break.\n     ///\n     /// # Panics\n     ///\n@@ -355,8 +323,8 @@ impl<T, A: AllocRef> RawVec<T, A> {\n     /// # Aborts\n     ///\n     /// Aborts on OOM.\n-    pub fn reserve_exact(&mut self, used_capacity: usize, needed_extra_capacity: usize) {\n-        match self.try_reserve_exact(used_capacity, needed_extra_capacity) {\n+    pub fn reserve_exact(&mut self, len: usize, additional: usize) {\n+        match self.try_reserve_exact(len, additional) {\n             Err(CapacityOverflow) => capacity_overflow(),\n             Err(AllocError { layout, .. }) => handle_alloc_error(layout),\n             Ok(()) => { /* yay */ }\n@@ -366,14 +334,10 @@ impl<T, A: AllocRef> RawVec<T, A> {\n     /// The same as `reserve_exact`, but returns on errors instead of panicking or aborting.\n     pub fn try_reserve_exact(\n         &mut self,\n-        used_capacity: usize,\n-        needed_extra_capacity: usize,\n+        len: usize,\n+        additional: usize,\n     ) -> Result<(), TryReserveError> {\n-        if self.needs_to_grow(used_capacity, needed_extra_capacity) {\n-            self.grow_exact(used_capacity, needed_extra_capacity)\n-        } else {\n-            Ok(())\n-        }\n+        if self.needs_to_grow(len, additional) { self.grow_exact(len, additional) } else { Ok(()) }\n     }\n \n     /// Shrinks the allocation down to the specified amount. If the given amount\n@@ -398,8 +362,8 @@ impl<T, A: AllocRef> RawVec<T, A> {\n impl<T, A: AllocRef> RawVec<T, A> {\n     /// Returns if the buffer needs to grow to fulfill the needed extra capacity.\n     /// Mainly used to make inlining reserve-calls possible without inlining `grow`.\n-    fn needs_to_grow(&self, used_capacity: usize, needed_extra_capacity: usize) -> bool {\n-        needed_extra_capacity > self.capacity().wrapping_sub(used_capacity)\n+    fn needs_to_grow(&self, len: usize, additional: usize) -> bool {\n+        additional > self.capacity().wrapping_sub(len)\n     }\n \n     fn capacity_from_bytes(excess: usize) -> usize {\n@@ -419,14 +383,9 @@ impl<T, A: AllocRef> RawVec<T, A> {\n     // so that all of the code that depends on `T` is within it, while as much\n     // of the code that doesn't depend on `T` as possible is in functions that\n     // are non-generic over `T`.\n-    fn grow_amortized(\n-        &mut self,\n-        used_capacity: usize,\n-        needed_extra_capacity: usize,\n-        placement: ReallocPlacement,\n-    ) -> Result<(), TryReserveError> {\n+    fn grow_amortized(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n         // This is ensured by the calling contexts.\n-        debug_assert!(needed_extra_capacity > 0);\n+        debug_assert!(additional > 0);\n \n         if mem::size_of::<T>() == 0 {\n             // Since we return a capacity of `usize::MAX` when `elem_size` is\n@@ -435,8 +394,7 @@ impl<T, A: AllocRef> RawVec<T, A> {\n         }\n \n         // Nothing we can really do about these checks, sadly.\n-        let required_cap =\n-            used_capacity.checked_add(needed_extra_capacity).ok_or(CapacityOverflow)?;\n+        let required_cap = len.checked_add(additional).ok_or(CapacityOverflow)?;\n \n         // This guarantees exponential growth. The doubling cannot overflow\n         // because `cap <= isize::MAX` and the type of `cap` is `usize`.\n@@ -461,30 +419,26 @@ impl<T, A: AllocRef> RawVec<T, A> {\n         let new_layout = Layout::array::<T>(cap);\n \n         // `finish_grow` is non-generic over `T`.\n-        let memory = finish_grow(new_layout, placement, self.current_memory(), &mut self.alloc)?;\n+        let memory = finish_grow(new_layout, self.current_memory(), &mut self.alloc)?;\n         self.set_memory(memory);\n         Ok(())\n     }\n \n     // The constraints on this method are much the same as those on\n     // `grow_amortized`, but this method is usually instantiated less often so\n     // it's less critical.\n-    fn grow_exact(\n-        &mut self,\n-        used_capacity: usize,\n-        needed_extra_capacity: usize,\n-    ) -> Result<(), TryReserveError> {\n+    fn grow_exact(&mut self, len: usize, additional: usize) -> Result<(), TryReserveError> {\n         if mem::size_of::<T>() == 0 {\n             // Since we return a capacity of `usize::MAX` when the type size is\n             // 0, getting to here necessarily means the `RawVec` is overfull.\n             return Err(CapacityOverflow);\n         }\n \n-        let cap = used_capacity.checked_add(needed_extra_capacity).ok_or(CapacityOverflow)?;\n+        let cap = len.checked_add(additional).ok_or(CapacityOverflow)?;\n         let new_layout = Layout::array::<T>(cap);\n \n         // `finish_grow` is non-generic over `T`.\n-        let memory = finish_grow(new_layout, MayMove, self.current_memory(), &mut self.alloc)?;\n+        let memory = finish_grow(new_layout, self.current_memory(), &mut self.alloc)?;\n         self.set_memory(memory);\n         Ok(())\n     }\n@@ -518,7 +472,6 @@ impl<T, A: AllocRef> RawVec<T, A> {\n // much smaller than the number of `T` types.)\n fn finish_grow<A>(\n     new_layout: Result<Layout, LayoutErr>,\n-    placement: ReallocPlacement,\n     current_memory: Option<(NonNull<u8>, Layout)>,\n     alloc: &mut A,\n ) -> Result<MemoryBlock, TryReserveError>\n@@ -532,12 +485,9 @@ where\n \n     let memory = if let Some((ptr, old_layout)) = current_memory {\n         debug_assert_eq!(old_layout.align(), new_layout.align());\n-        unsafe { alloc.grow(ptr, old_layout, new_layout.size(), placement, Uninitialized) }\n+        unsafe { alloc.grow(ptr, old_layout, new_layout.size(), MayMove, Uninitialized) }\n     } else {\n-        match placement {\n-            MayMove => alloc.alloc(new_layout, Uninitialized),\n-            InPlace => Err(AllocErr),\n-        }\n+        alloc.alloc(new_layout, Uninitialized)\n     }\n     .map_err(|_| AllocError { layout: new_layout, non_exhaustive: () })?;\n "}, {"sha": "2226737757bc5bf91c2d1ef205ce9b03ecdd86ce", "filename": "src/liballoc/vec.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Fliballoc%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Fliballoc%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fvec.rs?ref=860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "patch": "@@ -2977,12 +2977,12 @@ impl<T> Drain<'_, T> {\n     }\n \n     /// Makes room for inserting more elements before the tail.\n-    unsafe fn move_tail(&mut self, extra_capacity: usize) {\n+    unsafe fn move_tail(&mut self, additional: usize) {\n         let vec = self.vec.as_mut();\n-        let used_capacity = self.tail_start + self.tail_len;\n-        vec.buf.reserve(used_capacity, extra_capacity);\n+        let len = self.tail_start + self.tail_len;\n+        vec.buf.reserve(len, additional);\n \n-        let new_tail_start = self.tail_start + extra_capacity;\n+        let new_tail_start = self.tail_start + additional;\n         let src = vec.as_ptr().add(self.tail_start);\n         let dst = vec.as_mut_ptr().add(new_tail_start);\n         ptr::copy(src, dst, self.tail_len);"}, {"sha": "4da336f8e288da9eb243b11dec0330e825e274ef", "filename": "src/librustc_arena/lib.rs", "status": "modified", "additions": 39, "deletions": 47, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Flibrustc_arena%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/860e6bdd2fffbc98e67851eaaec87fb430bdd16b/src%2Flibrustc_arena%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_arena%2Flib.rs?ref=860e6bdd2fffbc98e67851eaaec87fb430bdd16b", "patch": "@@ -146,18 +146,18 @@ impl<T> TypedArena<T> {\n     }\n \n     #[inline]\n-    fn can_allocate(&self, len: usize) -> bool {\n-        let available_capacity_bytes = self.end.get() as usize - self.ptr.get() as usize;\n-        let at_least_bytes = len.checked_mul(mem::size_of::<T>()).unwrap();\n-        available_capacity_bytes >= at_least_bytes\n+    fn can_allocate(&self, additional: usize) -> bool {\n+        let available_bytes = self.end.get() as usize - self.ptr.get() as usize;\n+        let additional_bytes = additional.checked_mul(mem::size_of::<T>()).unwrap();\n+        available_bytes >= additional_bytes\n     }\n \n     /// Ensures there's enough space in the current chunk to fit `len` objects.\n     #[inline]\n-    fn ensure_capacity(&self, len: usize) {\n-        if !self.can_allocate(len) {\n-            self.grow(len);\n-            debug_assert!(self.can_allocate(len));\n+    fn ensure_capacity(&self, additional: usize) {\n+        if !self.can_allocate(additional) {\n+            self.grow(additional);\n+            debug_assert!(self.can_allocate(additional));\n         }\n     }\n \n@@ -214,36 +214,31 @@ impl<T> TypedArena<T> {\n     /// Grows the arena.\n     #[inline(never)]\n     #[cold]\n-    fn grow(&self, n: usize) {\n+    fn grow(&self, additional: usize) {\n         unsafe {\n-            // We need the element size in to convert chunk sizes (ranging from\n+            // We need the element size to convert chunk sizes (ranging from\n             // PAGE to HUGE_PAGE bytes) to element counts.\n             let elem_size = cmp::max(1, mem::size_of::<T>());\n             let mut chunks = self.chunks.borrow_mut();\n-            let (chunk, mut new_capacity);\n+            let mut new_cap;\n             if let Some(last_chunk) = chunks.last_mut() {\n                 let used_bytes = self.ptr.get() as usize - last_chunk.start() as usize;\n-                let currently_used_cap = used_bytes / mem::size_of::<T>();\n-                last_chunk.entries = currently_used_cap;\n-                if last_chunk.storage.reserve_in_place(currently_used_cap, n) {\n-                    self.end.set(last_chunk.end());\n-                    return;\n-                } else {\n-                    // If the previous chunk's capacity is less than HUGE_PAGE\n-                    // bytes, then this chunk will be least double the previous\n-                    // chunk's size.\n-                    new_capacity = last_chunk.storage.capacity();\n-                    if new_capacity < HUGE_PAGE / elem_size {\n-                        new_capacity = new_capacity.checked_mul(2).unwrap();\n-                    }\n+                last_chunk.entries = used_bytes / mem::size_of::<T>();\n+\n+                // If the previous chunk's capacity is less than HUGE_PAGE\n+                // bytes, then this chunk will be least double the previous\n+                // chunk's size.\n+                new_cap = last_chunk.storage.capacity();\n+                if new_cap < HUGE_PAGE / elem_size {\n+                    new_cap = new_cap.checked_mul(2).unwrap();\n                 }\n             } else {\n-                new_capacity = PAGE / elem_size;\n+                new_cap = PAGE / elem_size;\n             }\n-            // Also ensure that this chunk can fit `n`.\n-            new_capacity = cmp::max(n, new_capacity);\n+            // Also ensure that this chunk can fit `additional`.\n+            new_cap = cmp::max(additional, new_cap);\n \n-            chunk = TypedArenaChunk::<T>::new(new_capacity);\n+            let chunk = TypedArenaChunk::<T>::new(new_cap);\n             self.ptr.set(chunk.start());\n             self.end.set(chunk.end());\n             chunks.push(chunk);\n@@ -347,31 +342,28 @@ impl DroplessArena {\n \n     #[inline(never)]\n     #[cold]\n-    fn grow(&self, needed_bytes: usize) {\n+    fn grow(&self, additional: usize) {\n         unsafe {\n             let mut chunks = self.chunks.borrow_mut();\n-            let (chunk, mut new_capacity);\n+            let mut new_cap;\n             if let Some(last_chunk) = chunks.last_mut() {\n-                let used_bytes = self.ptr.get() as usize - last_chunk.start() as usize;\n-                if last_chunk.storage.reserve_in_place(used_bytes, needed_bytes) {\n-                    self.end.set(last_chunk.end());\n-                    return;\n-                } else {\n-                    // If the previous chunk's capacity is less than HUGE_PAGE\n-                    // bytes, then this chunk will be least double the previous\n-                    // chunk's size.\n-                    new_capacity = last_chunk.storage.capacity();\n-                    if new_capacity < HUGE_PAGE {\n-                        new_capacity = new_capacity.checked_mul(2).unwrap();\n-                    }\n+                // There is no need to update `last_chunk.entries` because that\n+                // field isn't used by `DroplessArena`.\n+\n+                // If the previous chunk's capacity is less than HUGE_PAGE\n+                // bytes, then this chunk will be least double the previous\n+                // chunk's size.\n+                new_cap = last_chunk.storage.capacity();\n+                if new_cap < HUGE_PAGE {\n+                    new_cap = new_cap.checked_mul(2).unwrap();\n                 }\n             } else {\n-                new_capacity = PAGE;\n+                new_cap = PAGE;\n             }\n-            // Also ensure that this chunk can fit `needed_bytes`.\n-            new_capacity = cmp::max(needed_bytes, new_capacity);\n+            // Also ensure that this chunk can fit `additional`.\n+            new_cap = cmp::max(additional, new_cap);\n \n-            chunk = TypedArenaChunk::<u8>::new(new_capacity);\n+            let chunk = TypedArenaChunk::<u8>::new(new_cap);\n             self.ptr.set(chunk.start());\n             self.end.set(chunk.end());\n             chunks.push(chunk);\n@@ -386,7 +378,7 @@ impl DroplessArena {\n             self.align(align);\n \n             let future_end = intrinsics::arith_offset(self.ptr.get(), bytes as isize);\n-            if (future_end as *mut u8) >= self.end.get() {\n+            if (future_end as *mut u8) > self.end.get() {\n                 self.grow(bytes);\n             }\n "}]}