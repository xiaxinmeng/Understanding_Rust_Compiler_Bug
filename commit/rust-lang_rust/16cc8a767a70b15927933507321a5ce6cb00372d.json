{"sha": "16cc8a767a70b15927933507321a5ce6cb00372d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE2Y2M4YTc2N2E3MGIxNTkyNzkzMzUwNzMyMWE1Y2U2Y2IwMDM3MmQ=", "commit": {"author": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-08-02T16:41:21Z"}, "committer": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-08-10T23:31:05Z"}, "message": "Implemented a smarter concatenation system that will hopefully produce more efficient tokenstream usages.", "tree": {"sha": "e3f66266fefd06292e06e0d65de96d7495a80e39", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e3f66266fefd06292e06e0d65de96d7495a80e39"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/16cc8a767a70b15927933507321a5ce6cb00372d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/16cc8a767a70b15927933507321a5ce6cb00372d", "html_url": "https://github.com/rust-lang/rust/commit/16cc8a767a70b15927933507321a5ce6cb00372d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/16cc8a767a70b15927933507321a5ce6cb00372d/comments", "author": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c", "url": "https://api.github.com/repos/rust-lang/rust/commits/32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c", "html_url": "https://github.com/rust-lang/rust/commit/32e462ef99e2f61b75e2b0ef37048d50ad8ccf6c"}], "stats": {"total": 112, "additions": 92, "deletions": 20}, "files": [{"sha": "0171f24101aecd6565fa29655481cf5f928a63bd", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 92, "deletions": 20, "changes": 112, "blob_url": "https://github.com/rust-lang/rust/blob/16cc8a767a70b15927933507321a5ce6cb00372d/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/16cc8a767a70b15927933507321a5ce6cb00372d/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=16cc8a767a70b15927933507321a5ce6cb00372d", "patch": "@@ -340,6 +340,11 @@ pub struct TokenStream {\n     ts: InternalTS,\n }\n \n+// This indicates the maximum size for a leaf in the concatenation algorithm.\n+// If two leafs will be collectively smaller than this, they will be merged.\n+// If a leaf is larger than this, it will be concatenated at the top.\n+const LEAF_SIZE : usize = 32;\n+\n // NB If Leaf access proves to be slow, inroducing a secondary Leaf without the bounds\n // for unsliced Leafs may lead to some performance improvemenet.\n #[derive(Clone, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable)]\n@@ -483,6 +488,37 @@ impl InternalTS {\n             }\n         }\n     }\n+\n+    fn to_vec(&self) -> Vec<&TokenTree> {\n+        let mut res = Vec::with_capacity(self.len());\n+        fn traverse_and_append<'a>(res: &mut Vec<&'a TokenTree>, ts: &'a InternalTS) {\n+            match *ts {\n+                InternalTS::Empty(..) => {},\n+                InternalTS::Leaf { ref tts, offset, len, .. } => {\n+                    let mut to_app = tts[offset..offset + len].iter().collect();\n+                    res.append(&mut to_app);\n+                }\n+                InternalTS::Node { ref left, ref right, .. } => {\n+                    traverse_and_append(res, left);\n+                    traverse_and_append(res, right);\n+                }\n+            }\n+        }\n+        traverse_and_append(&mut res, self);\n+        res\n+    }\n+\n+    fn to_tts(&self) -> Vec<TokenTree> {\n+        self.to_vec().into_iter().cloned().collect::<Vec<TokenTree>>()\n+    }\n+\n+    // Returns an internal node's children.\n+    fn children(&self) -> Option<(Rc<InternalTS>, Rc<InternalTS>)> {\n+        match *self {\n+            InternalTS::Node { ref left, ref right, .. } => Some((left.clone(), right.clone())),\n+            _ => None,\n+        }\n+    }\n }\n \n /// TokenStream operators include basic destructuring, boolean operations, `maybe_...`\n@@ -496,14 +532,17 @@ impl InternalTS {\n ///\n ///    `maybe_path_prefix(\"a::b::c(a,b,c).foo()\") -> (a::b::c, \"(a,b,c).foo()\")`\n impl TokenStream {\n+    // Construct an empty node with a dummy span.\n     pub fn mk_empty() -> TokenStream {\n         TokenStream { ts: InternalTS::Empty(DUMMY_SP) }\n     }\n \n+    // Construct an empty node with the provided span.\n     fn mk_spanned_empty(sp: Span) -> TokenStream {\n         TokenStream { ts: InternalTS::Empty(sp) }\n     }\n \n+    // Construct a leaf node with a 0 offset and length equivalent to the input.\n     fn mk_leaf(tts: Rc<Vec<TokenTree>>, sp: Span) -> TokenStream {\n         let len = tts.len();\n         TokenStream {\n@@ -516,6 +555,7 @@ impl TokenStream {\n         }\n     }\n \n+    // Construct a leaf node with the provided values.\n     fn mk_sub_leaf(tts: Rc<Vec<TokenTree>>, offset: usize, len: usize, sp: Span) -> TokenStream {\n         TokenStream {\n             ts: InternalTS::Leaf {\n@@ -527,6 +567,7 @@ impl TokenStream {\n         }\n     }\n \n+    // Construct an internal node with the provided values.\n     fn mk_int_node(left: Rc<InternalTS>,\n                    right: Rc<InternalTS>,\n                    len: usize,\n@@ -561,11 +602,56 @@ impl TokenStream {\n         }\n     }\n \n-    /// Concatenates two TokenStreams into a new TokenStream\n+    /// Concatenates two TokenStreams into a new TokenStream.\n     pub fn concat(left: TokenStream, right: TokenStream) -> TokenStream {\n-        let new_len = left.len() + right.len();\n-        let new_span = combine_spans(left.span(), right.span());\n-        TokenStream::mk_int_node(Rc::new(left.ts), Rc::new(right.ts), new_len, new_span)\n+        // This internal procedure performs 'aggressive compacting' during concatenation as\n+        // follows:\n+        // - If the nodes' combined total total length is less than 32, we copy both of\n+        //   them into a new vector and build a new leaf node.\n+        // - If one node is an internal node and the other is a 'small' leaf (length<32),\n+        //   we recur down the internal node on the appropriate side.\n+        // - Otherwise, we construct a new internal node that points to them as left and\n+        // right.\n+        fn concat_internal(left: Rc<InternalTS>, right: Rc<InternalTS>) -> TokenStream {\n+            let llen = left.len();\n+            let rlen = right.len();\n+            let len = llen + rlen;\n+            let span = combine_spans(left.span(), right.span());\n+            if len <= LEAF_SIZE {\n+                let mut new_vec = left.to_tts();\n+                let mut rvec = right.to_tts();\n+                new_vec.append(&mut rvec);\n+                return TokenStream::mk_leaf(Rc::new(new_vec), span);\n+            }\n+\n+            match (left.children(), right.children()) {\n+                (Some((lleft, lright)), None) => {\n+                    if rlen <= LEAF_SIZE  {\n+                        let new_right = concat_internal(lright, right);\n+                        TokenStream::mk_int_node(lleft, Rc::new(new_right.ts), len, span)\n+                    } else {\n+                       TokenStream::mk_int_node(left, right, len, span)\n+                    }\n+                }\n+                (None, Some((rleft, rright))) => {\n+                    if rlen <= LEAF_SIZE  {\n+                        let new_left = concat_internal(left, rleft);\n+                        TokenStream::mk_int_node(Rc::new(new_left.ts), rright, len, span)\n+                    } else {\n+                       TokenStream::mk_int_node(left, right, len, span)\n+                    }\n+                }\n+                (_, _) => TokenStream::mk_int_node(left, right, len, span),\n+            }\n+        }\n+\n+        if left.is_empty() {\n+            right\n+        } else if right.is_empty() {\n+            left\n+        } else {\n+            concat_internal(Rc::new(left.ts), Rc::new(right.ts))\n+        }\n     }\n \n     /// Indicate if the TokenStream is empty.\n@@ -580,27 +666,13 @@ impl TokenStream {\n \n     /// Convert a TokenStream into a vector of borrowed TokenTrees.\n     pub fn to_vec(&self) -> Vec<&TokenTree> {\n-        fn internal_to_vec(ts: &InternalTS) -> Vec<&TokenTree> {\n-            match *ts {\n-                InternalTS::Empty(..) => Vec::new(),\n-                InternalTS::Leaf { ref tts, offset, len, .. } => {\n-                    tts[offset..offset + len].iter().collect()\n-                }\n-                InternalTS::Node { ref left, ref right, .. } => {\n-                    let mut v1 = internal_to_vec(left);\n-                    let mut v2 = internal_to_vec(right);\n-                    v1.append(&mut v2);\n-                    v1\n-                }\n-            }\n-        }\n-        internal_to_vec(&self.ts)\n+        self.ts.to_vec()\n     }\n \n     /// Convert a TokenStream into a vector of TokenTrees (by cloning the TokenTrees).\n     /// (This operation is an O(n) deep copy of the underlying structure.)\n     pub fn to_tts(&self) -> Vec<TokenTree> {\n-        self.to_vec().into_iter().cloned().collect::<Vec<TokenTree>>()\n+        self.ts.to_tts()\n     }\n \n     /// Return the TokenStream's span."}]}