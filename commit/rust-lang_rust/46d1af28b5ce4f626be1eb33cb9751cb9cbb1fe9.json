{"sha": "46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ2ZDFhZjI4YjVjZTRmNjI2YmUxZWIzM2NiOTc1MWNiOWNiYjFmZTk=", "commit": {"author": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-05-21T23:57:31Z"}, "committer": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2014-06-04T19:10:46Z"}, "message": "syntax: methodify the lexer", "tree": {"sha": "6ad3023488d747633bef86cbdab5d30e79e4b032", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6ad3023488d747633bef86cbdab5d30e79e4b032"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "html_url": "https://github.com/rust-lang/rust/commit/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/comments", "author": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "committer": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652", "url": "https://api.github.com/repos/rust-lang/rust/commits/5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652", "html_url": "https://github.com/rust-lang/rust/commit/5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652"}], "stats": {"total": 2382, "additions": 1195, "deletions": 1187}, "files": [{"sha": "f544e1e0973f3d2ff610659ae457e757e0878ded", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -34,7 +34,7 @@ pub fn highlight(src: &str, class: Option<&str>) -> String {\n \n     let mut out = io::MemWriter::new();\n     doit(&sess,\n-         lexer::new_string_reader(&sess.span_diagnostic, fm),\n+         lexer::StringReader::new(&sess.span_diagnostic, fm),\n          class,\n          &mut out).unwrap();\n     str::from_utf8_lossy(out.unwrap().as_slice()).to_string()"}, {"sha": "a514ef65e729fdfcbde3a4729e43506b63388912", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -15,7 +15,7 @@ use ast::{AttrId, Attribute, Attribute_, MetaItem, MetaWord, MetaNameValue, Meta\n use codemap::{Span, Spanned, spanned, dummy_spanned};\n use codemap::BytePos;\n use diagnostic::SpanHandler;\n-use parse::comments::{doc_comment_style, strip_doc_comment_decoration};\n+use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use parse::token::InternedString;\n use parse::token;\n use crateid::CrateId;"}, {"sha": "f5386b43d5127deb164fb335ef8fa4f9903a97be", "filename": "src/libsyntax/parse/lexer.rs", "status": "removed", "additions": 0, "deletions": 1112, "changes": 1112, "blob_url": "https://github.com/rust-lang/rust/blob/5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=5343eb7e0cf576d690b6cfceb9c5ca6a4bfd8652", "patch": "@@ -1,1112 +0,0 @@\n-// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use ast;\n-use codemap::{BytePos, CharPos, CodeMap, Pos, Span};\n-use codemap;\n-use diagnostic::SpanHandler;\n-use ext::tt::transcribe::tt_next_token;\n-use parse::token;\n-use parse::token::{str_to_ident};\n-\n-use std::char;\n-use std::mem::replace;\n-use std::num::from_str_radix;\n-use std::rc::Rc;\n-use std::str;\n-\n-pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n-\n-pub trait Reader {\n-    fn is_eof(&self) -> bool;\n-    fn next_token(&mut self) -> TokenAndSpan;\n-    /// Report a fatal error with the current span.\n-    fn fatal(&self, &str) -> !;\n-    /// Report a non-fatal error with the current span.\n-    fn err(&self, &str);\n-    fn peek(&self) -> TokenAndSpan;\n-}\n-\n-#[deriving(Clone, PartialEq, Show)]\n-pub struct TokenAndSpan {\n-    pub tok: token::Token,\n-    pub sp: Span,\n-}\n-\n-pub struct StringReader<'a> {\n-    pub span_diagnostic: &'a SpanHandler,\n-    // The absolute offset within the codemap of the next character to read\n-    pub pos: BytePos,\n-    // The absolute offset within the codemap of the last character read(curr)\n-    pub last_pos: BytePos,\n-    // The column of the next character to read\n-    pub col: CharPos,\n-    // The last character to be read\n-    pub curr: Option<char>,\n-    pub filemap: Rc<codemap::FileMap>,\n-    /* cached: */\n-    pub peek_tok: token::Token,\n-    pub peek_span: Span,\n-}\n-\n-impl<'a> StringReader<'a> {\n-    pub fn curr_is(&self, c: char) -> bool {\n-        self.curr == Some(c)\n-    }\n-}\n-\n-pub fn new_string_reader<'a>(span_diagnostic: &'a SpanHandler,\n-                             filemap: Rc<codemap::FileMap>)\n-                             -> StringReader<'a> {\n-    let mut r = new_low_level_string_reader(span_diagnostic, filemap);\n-    string_advance_token(&mut r); /* fill in peek_* */\n-    r\n-}\n-\n-/* For comments.rs, which hackily pokes into 'pos' and 'curr' */\n-pub fn new_low_level_string_reader<'a>(span_diagnostic: &'a SpanHandler,\n-                                       filemap: Rc<codemap::FileMap>)\n-                                       -> StringReader<'a> {\n-    // Force the initial reader bump to start on a fresh line\n-    let initial_char = '\\n';\n-    let mut r = StringReader {\n-        span_diagnostic: span_diagnostic,\n-        pos: filemap.start_pos,\n-        last_pos: filemap.start_pos,\n-        col: CharPos(0),\n-        curr: Some(initial_char),\n-        filemap: filemap,\n-        /* dummy values; not read */\n-        peek_tok: token::EOF,\n-        peek_span: codemap::DUMMY_SP,\n-    };\n-    bump(&mut r);\n-    r\n-}\n-\n-impl<'a> Reader for StringReader<'a> {\n-    fn is_eof(&self) -> bool { is_eof(self) }\n-    // return the next token. EFFECT: advances the string_reader.\n-    fn next_token(&mut self) -> TokenAndSpan {\n-        let ret_val = TokenAndSpan {\n-            tok: replace(&mut self.peek_tok, token::UNDERSCORE),\n-            sp: self.peek_span,\n-        };\n-        string_advance_token(self);\n-        ret_val\n-    }\n-    fn fatal(&self, m: &str) -> ! {\n-        self.span_diagnostic.span_fatal(self.peek_span, m)\n-    }\n-    fn err(&self, m: &str) {\n-        self.span_diagnostic.span_err(self.peek_span, m)\n-    }\n-    fn peek(&self) -> TokenAndSpan {\n-        // FIXME(pcwalton): Bad copy!\n-        TokenAndSpan {\n-            tok: self.peek_tok.clone(),\n-            sp: self.peek_span,\n-        }\n-    }\n-}\n-\n-impl<'a> Reader for TtReader<'a> {\n-    fn is_eof(&self) -> bool {\n-        self.cur_tok == token::EOF\n-    }\n-    fn next_token(&mut self) -> TokenAndSpan {\n-        let r = tt_next_token(self);\n-        debug!(\"TtReader: r={:?}\", r);\n-        r\n-    }\n-    fn fatal(&self, m: &str) -> ! {\n-        self.sp_diag.span_fatal(self.cur_span, m);\n-    }\n-    fn err(&self, m: &str) {\n-        self.sp_diag.span_err(self.cur_span, m);\n-    }\n-    fn peek(&self) -> TokenAndSpan {\n-        TokenAndSpan {\n-            tok: self.cur_tok.clone(),\n-            sp: self.cur_span,\n-        }\n-    }\n-}\n-\n-// report a lexical error spanning [`from_pos`, `to_pos`)\n-fn fatal_span(rdr: &mut StringReader, from_pos: BytePos, to_pos: BytePos, m: &str) -> ! {\n-    rdr.peek_span = codemap::mk_sp(from_pos, to_pos);\n-    rdr.fatal(m);\n-}\n-\n-fn err_span(rdr: &mut StringReader, from_pos: BytePos, to_pos: BytePos, m: &str) {\n-    rdr.peek_span = codemap::mk_sp(from_pos, to_pos);\n-    rdr.err(m);\n-}\n-\n-// report a lexical error spanning [`from_pos`, `to_pos`), appending an\n-// escaped character to the error message\n-fn fatal_span_char(rdr: &mut StringReader,\n-                   from_pos: BytePos, to_pos: BytePos,\n-                   m: &str, c: char) -> ! {\n-    let mut m = m.to_string();\n-    m.push_str(\": \");\n-    char::escape_default(c, |c| m.push_char(c));\n-    fatal_span(rdr, from_pos, to_pos, m.as_slice());\n-}\n-\n-fn err_span_char(rdr: &mut StringReader, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) {\n-    let mut m = m.to_string();\n-    m.push_str(\": \");\n-    char::escape_default(c, |c| m.push_char(c));\n-    err_span(rdr, from_pos, to_pos, m.as_slice());\n-}\n-\n-// report a lexical error spanning [`from_pos`, `to_pos`), appending the\n-// offending string to the error message\n-fn fatal_span_verbose(rdr: &mut StringReader, from_pos: BytePos, to_pos: BytePos, m: &str) -> ! {\n-    let mut m = m.to_string();\n-    m.push_str(\": \");\n-    let from = byte_offset(rdr, from_pos).to_uint();\n-    let to = byte_offset(rdr, to_pos).to_uint();\n-    m.push_str(rdr.filemap.src.as_slice().slice(from, to));\n-    fatal_span(rdr, from_pos, to_pos, m.as_slice());\n-}\n-\n-// EFFECT: advance peek_tok and peek_span to refer to the next token.\n-// EFFECT: update the interner, maybe.\n-fn string_advance_token(r: &mut StringReader) {\n-    match consume_whitespace_and_comments(r) {\n-        Some(comment) => {\n-            r.peek_span = comment.sp;\n-            r.peek_tok = comment.tok;\n-        },\n-        None => {\n-            if is_eof(r) {\n-                r.peek_tok = token::EOF;\n-            } else {\n-                let start_bytepos = r.last_pos;\n-                r.peek_tok = next_token_inner(r);\n-                r.peek_span = codemap::mk_sp(start_bytepos,\n-                                             r.last_pos);\n-            };\n-        }\n-    }\n-}\n-\n-fn byte_offset(rdr: &StringReader, pos: BytePos) -> BytePos {\n-    (pos - rdr.filemap.start_pos)\n-}\n-\n-/// Calls `f` with a string slice of the source text spanning from `start`\n-/// up to but excluding `rdr.last_pos`, meaning the slice does not include\n-/// the character `rdr.curr`.\n-pub fn with_str_from<T>(\n-                     rdr: &StringReader,\n-                     start: BytePos,\n-                     f: |s: &str| -> T)\n-                     -> T {\n-    with_str_from_to(rdr, start, rdr.last_pos, f)\n-}\n-\n-/// Calls `f` with astring slice of the source text spanning from `start`\n-/// up to but excluding `end`.\n-fn with_str_from_to<T>(\n-                    rdr: &StringReader,\n-                    start: BytePos,\n-                    end: BytePos,\n-                    f: |s: &str| -> T)\n-                    -> T {\n-    f(rdr.filemap.src.as_slice().slice(\n-            byte_offset(rdr, start).to_uint(),\n-            byte_offset(rdr, end).to_uint()))\n-}\n-\n-// EFFECT: advance the StringReader by one character. If a newline is\n-// discovered, add it to the FileMap's list of line start offsets.\n-pub fn bump(rdr: &mut StringReader) {\n-    rdr.last_pos = rdr.pos;\n-    let current_byte_offset = byte_offset(rdr, rdr.pos).to_uint();\n-    if current_byte_offset < rdr.filemap.src.len() {\n-        assert!(rdr.curr.is_some());\n-        let last_char = rdr.curr.unwrap();\n-        let next = rdr.filemap\n-                      .src\n-                      .as_slice()\n-                      .char_range_at(current_byte_offset);\n-        let byte_offset_diff = next.next - current_byte_offset;\n-        rdr.pos = rdr.pos + Pos::from_uint(byte_offset_diff);\n-        rdr.curr = Some(next.ch);\n-        rdr.col = rdr.col + CharPos(1u);\n-        if last_char == '\\n' {\n-            rdr.filemap.next_line(rdr.last_pos);\n-            rdr.col = CharPos(0u);\n-        }\n-\n-        if byte_offset_diff > 1 {\n-            rdr.filemap.record_multibyte_char(rdr.last_pos, byte_offset_diff);\n-        }\n-    } else {\n-        rdr.curr = None;\n-    }\n-}\n-\n-pub fn is_eof(rdr: &StringReader) -> bool {\n-    rdr.curr.is_none()\n-}\n-\n-pub fn nextch(rdr: &StringReader) -> Option<char> {\n-    let offset = byte_offset(rdr, rdr.pos).to_uint();\n-    if offset < rdr.filemap.src.len() {\n-        Some(rdr.filemap.src.as_slice().char_at(offset))\n-    } else {\n-        None\n-    }\n-}\n-pub fn nextch_is(rdr: &StringReader, c: char) -> bool {\n-    nextch(rdr) == Some(c)\n-}\n-\n-pub fn nextnextch(rdr: &StringReader) -> Option<char> {\n-    let offset = byte_offset(rdr, rdr.pos).to_uint();\n-    let s = rdr.filemap.deref().src.as_slice();\n-    if offset >= s.len() { return None }\n-    let str::CharRange { next, .. } = s.char_range_at(offset);\n-    if next < s.len() {\n-        Some(s.char_at(next))\n-    } else {\n-        None\n-    }\n-}\n-pub fn nextnextch_is(rdr: &StringReader, c: char) -> bool {\n-    nextnextch(rdr) == Some(c)\n-}\n-\n-pub fn is_whitespace(c: Option<char>) -> bool {\n-    match c.unwrap_or('\\x00') { // None can be null for now... it's not whitespace\n-        ' ' | '\\n' | '\\t' | '\\r' => true,\n-        _ => false\n-    }\n-}\n-\n-// EFFECT: eats whitespace and comments.\n-// returns a Some(sugared-doc-attr) if one exists, None otherwise.\n-fn consume_whitespace_and_comments(rdr: &mut StringReader)\n-                                -> Option<TokenAndSpan> {\n-    while is_whitespace(rdr.curr) { bump(rdr); }\n-    return consume_any_line_comment(rdr);\n-}\n-\n-pub fn is_line_non_doc_comment(s: &str) -> bool {\n-    s.starts_with(\"////\")\n-}\n-\n-// PRECONDITION: rdr.curr is not whitespace\n-// EFFECT: eats any kind of comment.\n-// returns a Some(sugared-doc-attr) if one exists, None otherwise\n-fn consume_any_line_comment(rdr: &mut StringReader)\n-                         -> Option<TokenAndSpan> {\n-    if rdr.curr_is('/') {\n-        match nextch(rdr) {\n-            Some('/') => {\n-                bump(rdr);\n-                bump(rdr);\n-                // line comments starting with \"///\" or \"//!\" are doc-comments\n-                if rdr.curr_is('/') || rdr.curr_is('!') {\n-                    let start_bpos = rdr.pos - BytePos(3);\n-                    while !rdr.curr_is('\\n') && !is_eof(rdr) {\n-                        bump(rdr);\n-                    }\n-                    let ret = with_str_from(rdr, start_bpos, |string| {\n-                        // but comments with only more \"/\"s are not\n-                        if !is_line_non_doc_comment(string) {\n-                            Some(TokenAndSpan{\n-                                tok: token::DOC_COMMENT(str_to_ident(string)),\n-                                sp: codemap::mk_sp(start_bpos, rdr.pos)\n-                            })\n-                        } else {\n-                            None\n-                        }\n-                    });\n-\n-                    if ret.is_some() {\n-                        return ret;\n-                    }\n-                } else {\n-                    while !rdr.curr_is('\\n') && !is_eof(rdr) { bump(rdr); }\n-                }\n-                // Restart whitespace munch.\n-                consume_whitespace_and_comments(rdr)\n-            }\n-            Some('*') => { bump(rdr); bump(rdr); consume_block_comment(rdr) }\n-            _ => None\n-        }\n-    } else if rdr.curr_is('#') {\n-        if nextch_is(rdr, '!') {\n-\n-            // Parse an inner attribute.\n-            if nextnextch_is(rdr, '[') {\n-                return None;\n-            }\n-\n-            // I guess this is the only way to figure out if\n-            // we're at the beginning of the file...\n-            let cmap = CodeMap::new();\n-            cmap.files.borrow_mut().push(rdr.filemap.clone());\n-            let loc = cmap.lookup_char_pos_adj(rdr.last_pos);\n-            if loc.line == 1u && loc.col == CharPos(0u) {\n-                while !rdr.curr_is('\\n') && !is_eof(rdr) { bump(rdr); }\n-                return consume_whitespace_and_comments(rdr);\n-            }\n-        }\n-        None\n-    } else {\n-        None\n-    }\n-}\n-\n-pub fn is_block_non_doc_comment(s: &str) -> bool {\n-    s.starts_with(\"/***\")\n-}\n-\n-// might return a sugared-doc-attr\n-fn consume_block_comment(rdr: &mut StringReader) -> Option<TokenAndSpan> {\n-    // block comments starting with \"/**\" or \"/*!\" are doc-comments\n-    let is_doc_comment = rdr.curr_is('*') || rdr.curr_is('!');\n-    let start_bpos = rdr.pos - BytePos(if is_doc_comment {3} else {2});\n-\n-    let mut level: int = 1;\n-    while level > 0 {\n-        if is_eof(rdr) {\n-            let msg = if is_doc_comment {\n-                \"unterminated block doc-comment\"\n-            } else {\n-                \"unterminated block comment\"\n-            };\n-            fatal_span(rdr, start_bpos, rdr.last_pos, msg);\n-        } else if rdr.curr_is('/') && nextch_is(rdr, '*') {\n-            level += 1;\n-            bump(rdr);\n-            bump(rdr);\n-        } else if rdr.curr_is('*') && nextch_is(rdr, '/') {\n-            level -= 1;\n-            bump(rdr);\n-            bump(rdr);\n-        } else {\n-            bump(rdr);\n-        }\n-    }\n-\n-    let res = if is_doc_comment {\n-        with_str_from(rdr, start_bpos, |string| {\n-            // but comments with only \"*\"s between two \"/\"s are not\n-            if !is_block_non_doc_comment(string) {\n-                Some(TokenAndSpan{\n-                        tok: token::DOC_COMMENT(str_to_ident(string)),\n-                        sp: codemap::mk_sp(start_bpos, rdr.pos)\n-                    })\n-            } else {\n-                None\n-            }\n-        })\n-    } else {\n-        None\n-    };\n-\n-    // restart whitespace munch.\n-    if res.is_some() { res } else { consume_whitespace_and_comments(rdr) }\n-}\n-\n-fn scan_exponent(rdr: &mut StringReader, start_bpos: BytePos) -> Option<String> {\n-    // \\x00 hits the `return None` case immediately, so this is fine.\n-    let mut c = rdr.curr.unwrap_or('\\x00');\n-    let mut rslt = String::new();\n-    if c == 'e' || c == 'E' {\n-        rslt.push_char(c);\n-        bump(rdr);\n-        c = rdr.curr.unwrap_or('\\x00');\n-        if c == '-' || c == '+' {\n-            rslt.push_char(c);\n-            bump(rdr);\n-        }\n-        let exponent = scan_digits(rdr, 10u);\n-        if exponent.len() > 0u {\n-            rslt.push_str(exponent.as_slice());\n-        } else {\n-            err_span(rdr, start_bpos, rdr.last_pos, \"scan_exponent: bad fp literal\");\n-            rslt.push_str(\"1\"); // arbitrary placeholder exponent\n-        }\n-        Some(rslt)\n-    } else {\n-        None\n-    }\n-}\n-\n-fn scan_digits(rdr: &mut StringReader, radix: uint) -> String {\n-    let mut rslt = String::new();\n-    loop {\n-        let c = rdr.curr;\n-        if c == Some('_') { bump(rdr); continue; }\n-        match c.and_then(|cc| char::to_digit(cc, radix)) {\n-          Some(_) => {\n-            rslt.push_char(c.unwrap());\n-            bump(rdr);\n-          }\n-          _ => return rslt\n-        }\n-    };\n-}\n-\n-fn check_float_base(rdr: &mut StringReader, start_bpos: BytePos, last_bpos: BytePos,\n-                    base: uint) {\n-    match base {\n-      16u => err_span(rdr, start_bpos, last_bpos, \"hexadecimal float literal is not supported\"),\n-      8u => err_span(rdr, start_bpos, last_bpos, \"octal float literal is not supported\"),\n-      2u => err_span(rdr, start_bpos, last_bpos, \"binary float literal is not supported\"),\n-      _ => ()\n-    }\n-}\n-\n-fn scan_number(c: char, rdr: &mut StringReader) -> token::Token {\n-    let mut num_str;\n-    let mut base = 10u;\n-    let mut c = c;\n-    let mut n = nextch(rdr).unwrap_or('\\x00');\n-    let start_bpos = rdr.last_pos;\n-    if c == '0' && n == 'x' {\n-        bump(rdr);\n-        bump(rdr);\n-        base = 16u;\n-    } else if c == '0' && n == 'o' {\n-        bump(rdr);\n-        bump(rdr);\n-        base = 8u;\n-    } else if c == '0' && n == 'b' {\n-        bump(rdr);\n-        bump(rdr);\n-        base = 2u;\n-    }\n-    num_str = scan_digits(rdr, base);\n-    c = rdr.curr.unwrap_or('\\x00');\n-    if c == 'u' || c == 'i' {\n-        enum Result { Signed(ast::IntTy), Unsigned(ast::UintTy) }\n-        let signed = c == 'i';\n-        let mut tp = {\n-            if signed { Signed(ast::TyI) }\n-            else { Unsigned(ast::TyU) }\n-        };\n-        bump(rdr);\n-        c = rdr.curr.unwrap_or('\\x00');\n-        if c == '8' {\n-            bump(rdr);\n-            tp = if signed { Signed(ast::TyI8) }\n-                      else { Unsigned(ast::TyU8) };\n-        }\n-        n = nextch(rdr).unwrap_or('\\x00');\n-        if c == '1' && n == '6' {\n-            bump(rdr);\n-            bump(rdr);\n-            tp = if signed { Signed(ast::TyI16) }\n-                      else { Unsigned(ast::TyU16) };\n-        } else if c == '3' && n == '2' {\n-            bump(rdr);\n-            bump(rdr);\n-            tp = if signed { Signed(ast::TyI32) }\n-                      else { Unsigned(ast::TyU32) };\n-        } else if c == '6' && n == '4' {\n-            bump(rdr);\n-            bump(rdr);\n-            tp = if signed { Signed(ast::TyI64) }\n-                      else { Unsigned(ast::TyU64) };\n-        }\n-        if num_str.len() == 0u {\n-            err_span(rdr, start_bpos, rdr.last_pos, \"no valid digits found for number\");\n-            num_str = \"1\".to_string();\n-        }\n-        let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n-                                                 base as uint) {\n-            Some(p) => p,\n-            None => {\n-                err_span(rdr, start_bpos, rdr.last_pos, \"int literal is too large\");\n-                1\n-            }\n-        };\n-\n-        match tp {\n-          Signed(t) => return token::LIT_INT(parsed as i64, t),\n-          Unsigned(t) => return token::LIT_UINT(parsed, t)\n-        }\n-    }\n-    let mut is_float = false;\n-    if rdr.curr_is('.') && !(ident_start(nextch(rdr)) || nextch_is(rdr, '.')) {\n-        is_float = true;\n-        bump(rdr);\n-        let dec_part = scan_digits(rdr, 10u);\n-        num_str.push_char('.');\n-        num_str.push_str(dec_part.as_slice());\n-    }\n-    match scan_exponent(rdr, start_bpos) {\n-      Some(ref s) => {\n-        is_float = true;\n-        num_str.push_str(s.as_slice());\n-      }\n-      None => ()\n-    }\n-\n-    if rdr.curr_is('f') {\n-        bump(rdr);\n-        c = rdr.curr.unwrap_or('\\x00');\n-        n = nextch(rdr).unwrap_or('\\x00');\n-        if c == '3' && n == '2' {\n-            bump(rdr);\n-            bump(rdr);\n-            check_float_base(rdr, start_bpos, rdr.last_pos, base);\n-            return token::LIT_FLOAT(str_to_ident(num_str.as_slice()),\n-                                    ast::TyF32);\n-        } else if c == '6' && n == '4' {\n-            bump(rdr);\n-            bump(rdr);\n-            check_float_base(rdr, start_bpos, rdr.last_pos, base);\n-            return token::LIT_FLOAT(str_to_ident(num_str.as_slice()),\n-                                    ast::TyF64);\n-            /* FIXME (#2252): if this is out of range for either a\n-            32-bit or 64-bit float, it won't be noticed till the\n-            back-end.  */\n-        } else if c == '1' && n == '2' && nextnextch(rdr).unwrap_or('\\x00') == '8' {\n-            bump(rdr);\n-            bump(rdr);\n-            bump(rdr);\n-            check_float_base(rdr, start_bpos, rdr.last_pos, base);\n-            return token::LIT_FLOAT(str_to_ident(num_str.as_slice()), ast::TyF128);\n-        }\n-        err_span(rdr, start_bpos, rdr.last_pos, \"expected `f32`, `f64` or `f128` suffix\");\n-    }\n-    if is_float {\n-        check_float_base(rdr, start_bpos, rdr.last_pos, base);\n-        return token::LIT_FLOAT_UNSUFFIXED(str_to_ident(num_str.as_slice()));\n-    } else {\n-        if num_str.len() == 0u {\n-            err_span(rdr, start_bpos, rdr.last_pos, \"no valid digits found for number\");\n-            num_str = \"1\".to_string();\n-        }\n-        let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n-                                                 base as uint) {\n-            Some(p) => p,\n-            None => {\n-                err_span(rdr, start_bpos, rdr.last_pos, \"int literal is too large\");\n-                1\n-            }\n-        };\n-\n-        debug!(\"lexing {} as an unsuffixed integer literal\",\n-               num_str.as_slice());\n-        return token::LIT_INT_UNSUFFIXED(parsed as i64);\n-    }\n-}\n-\n-fn scan_numeric_escape(rdr: &mut StringReader, n_hex_digits: uint, delim: char) -> char {\n-    let mut accum_int = 0u32;\n-    let start_bpos = rdr.last_pos;\n-    for _ in range(0, n_hex_digits) {\n-        if is_eof(rdr) {\n-            fatal_span(rdr, start_bpos, rdr.last_pos, \"unterminated numeric character escape\");\n-        }\n-        if rdr.curr_is(delim) {\n-            err_span(rdr, start_bpos, rdr.last_pos, \"numeric character escape is too short\");\n-            break;\n-        }\n-        let c = rdr.curr.unwrap_or('\\x00');\n-        accum_int *= 16;\n-        accum_int += c.to_digit(16).unwrap_or_else(|| {\n-            err_span_char(rdr, rdr.last_pos, rdr.pos,\n-                          \"illegal character in numeric character escape\", c);\n-            0\n-        }) as u32;\n-        bump(rdr);\n-    }\n-\n-    match char::from_u32(accum_int) {\n-        Some(x) => x,\n-        None => {\n-            err_span(rdr, start_bpos, rdr.last_pos, \"illegal numeric character escape\");\n-            '?'\n-        }\n-    }\n-}\n-\n-fn ident_start(c: Option<char>) -> bool {\n-    let c = match c { Some(c) => c, None => return false };\n-\n-    (c >= 'a' && c <= 'z')\n-        || (c >= 'A' && c <= 'Z')\n-        || c == '_'\n-        || (c > '\\x7f' && char::is_XID_start(c))\n-}\n-\n-fn ident_continue(c: Option<char>) -> bool {\n-    let c = match c { Some(c) => c, None => return false };\n-\n-    (c >= 'a' && c <= 'z')\n-        || (c >= 'A' && c <= 'Z')\n-        || (c >= '0' && c <= '9')\n-        || c == '_'\n-        || (c > '\\x7f' && char::is_XID_continue(c))\n-}\n-\n-// return the next token from the string\n-// EFFECT: advances the input past that token\n-// EFFECT: updates the interner\n-fn next_token_inner(rdr: &mut StringReader) -> token::Token {\n-    let c = rdr.curr;\n-    if ident_start(c) && !nextch_is(rdr, '\"') && !nextch_is(rdr, '#') {\n-        // Note: r as in r\" or r#\" is part of a raw string literal,\n-        // not an identifier, and is handled further down.\n-\n-        let start = rdr.last_pos;\n-        while ident_continue(rdr.curr) {\n-            bump(rdr);\n-        }\n-\n-        return with_str_from(rdr, start, |string| {\n-            if string == \"_\" {\n-                token::UNDERSCORE\n-            } else {\n-                let is_mod_name = rdr.curr_is(':') && nextch_is(rdr, ':');\n-\n-                // FIXME: perform NFKC normalization here. (Issue #2253)\n-                token::IDENT(str_to_ident(string), is_mod_name)\n-            }\n-        })\n-    }\n-    if c.map_or(false, |c| c.is_digit_radix(10)) {\n-        return scan_number(c.unwrap(), rdr);\n-    }\n-    fn binop(rdr: &mut StringReader, op: token::BinOp) -> token::Token {\n-        bump(rdr);\n-        if rdr.curr_is('=') {\n-            bump(rdr);\n-            return token::BINOPEQ(op);\n-        } else { return token::BINOP(op); }\n-    }\n-    match c.expect(\"next_token_inner called at EOF\") {\n-\n-\n-\n-\n-\n-      // One-byte tokens.\n-      ';' => { bump(rdr); return token::SEMI; }\n-      ',' => { bump(rdr); return token::COMMA; }\n-      '.' => {\n-          bump(rdr);\n-          return if rdr.curr_is('.') {\n-              bump(rdr);\n-              if rdr.curr_is('.') {\n-                  bump(rdr);\n-                  token::DOTDOTDOT\n-              } else {\n-                  token::DOTDOT\n-              }\n-          } else {\n-              token::DOT\n-          };\n-      }\n-      '(' => { bump(rdr); return token::LPAREN; }\n-      ')' => { bump(rdr); return token::RPAREN; }\n-      '{' => { bump(rdr); return token::LBRACE; }\n-      '}' => { bump(rdr); return token::RBRACE; }\n-      '[' => { bump(rdr); return token::LBRACKET; }\n-      ']' => { bump(rdr); return token::RBRACKET; }\n-      '@' => { bump(rdr); return token::AT; }\n-      '#' => { bump(rdr); return token::POUND; }\n-      '~' => { bump(rdr); return token::TILDE; }\n-      ':' => {\n-        bump(rdr);\n-        if rdr.curr_is(':') {\n-            bump(rdr);\n-            return token::MOD_SEP;\n-        } else { return token::COLON; }\n-      }\n-\n-      '$' => { bump(rdr); return token::DOLLAR; }\n-\n-\n-\n-\n-\n-      // Multi-byte tokens.\n-      '=' => {\n-        bump(rdr);\n-        if rdr.curr_is('=') {\n-            bump(rdr);\n-            return token::EQEQ;\n-        } else if rdr.curr_is('>') {\n-            bump(rdr);\n-            return token::FAT_ARROW;\n-        } else {\n-            return token::EQ;\n-        }\n-      }\n-      '!' => {\n-        bump(rdr);\n-        if rdr.curr_is('=') {\n-            bump(rdr);\n-            return token::NE;\n-        } else { return token::NOT; }\n-      }\n-      '<' => {\n-        bump(rdr);\n-        match rdr.curr.unwrap_or('\\x00') {\n-          '=' => { bump(rdr); return token::LE; }\n-          '<' => { return binop(rdr, token::SHL); }\n-          '-' => {\n-            bump(rdr);\n-            return token::LARROW;\n-          }\n-          _ => { return token::LT; }\n-        }\n-      }\n-      '>' => {\n-        bump(rdr);\n-        match rdr.curr.unwrap_or('\\x00') {\n-          '=' => { bump(rdr); return token::GE; }\n-          '>' => { return binop(rdr, token::SHR); }\n-          _ => { return token::GT; }\n-        }\n-      }\n-      '\\'' => {\n-        // Either a character constant 'a' OR a lifetime name 'abc\n-        bump(rdr);\n-        let start = rdr.last_pos;\n-\n-        // the eof will be picked up by the final `'` check below\n-        let mut c2 = rdr.curr.unwrap_or('\\x00');\n-        bump(rdr);\n-\n-        // If the character is an ident start not followed by another single\n-        // quote, then this is a lifetime name:\n-        if ident_start(Some(c2)) && !rdr.curr_is('\\'') {\n-            while ident_continue(rdr.curr) {\n-                bump(rdr);\n-            }\n-            let ident = with_str_from(rdr, start, |lifetime_name| {\n-                str_to_ident(lifetime_name)\n-            });\n-            let tok = &token::IDENT(ident, false);\n-\n-            if token::is_keyword(token::keywords::Self, tok) {\n-                err_span(rdr, start, rdr.last_pos,\n-                         \"invalid lifetime name: 'self is no longer a special lifetime\");\n-            } else if token::is_any_keyword(tok) &&\n-                !token::is_keyword(token::keywords::Static, tok) {\n-                err_span(rdr, start, rdr.last_pos, \"invalid lifetime name\");\n-            }\n-            return token::LIFETIME(ident);\n-        }\n-\n-        // Otherwise it is a character constant:\n-        match c2 {\n-            '\\\\' => {\n-                // '\\X' for some X must be a character constant:\n-                let escaped = rdr.curr;\n-                let escaped_pos = rdr.last_pos;\n-                bump(rdr);\n-                match escaped {\n-                    None => {}\n-                    Some(e) => {\n-                        c2 = match e {\n-                            'n' => '\\n',\n-                            'r' => '\\r',\n-                            't' => '\\t',\n-                            '\\\\' => '\\\\',\n-                            '\\'' => '\\'',\n-                            '\"' => '\"',\n-                            '0' => '\\x00',\n-                            'x' => scan_numeric_escape(rdr, 2u, '\\''),\n-                            'u' => scan_numeric_escape(rdr, 4u, '\\''),\n-                            'U' => scan_numeric_escape(rdr, 8u, '\\''),\n-                            c2 => {\n-                                err_span_char(rdr, escaped_pos, rdr.last_pos,\n-                                              \"unknown character escape\", c2);\n-                                c2\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n-            '\\t' | '\\n' | '\\r' | '\\'' => {\n-                err_span_char(rdr, start, rdr.last_pos, \"character constant must be escaped\", c2);\n-            }\n-            _ => {}\n-        }\n-        if !rdr.curr_is('\\'') {\n-            fatal_span_verbose(rdr,\n-                               // Byte offsetting here is okay because the\n-                               // character before position `start` is an\n-                               // ascii single quote.\n-                               start - BytePos(1), rdr.last_pos,\n-                               \"unterminated character constant\");\n-        }\n-        bump(rdr); // advance curr past token\n-        return token::LIT_CHAR(c2);\n-      }\n-      '\"' => {\n-        let mut accum_str = String::new();\n-        let start_bpos = rdr.last_pos;\n-        bump(rdr);\n-        while !rdr.curr_is('\"') {\n-            if is_eof(rdr) {\n-                fatal_span(rdr, start_bpos, rdr.last_pos, \"unterminated double quote string\");\n-            }\n-\n-            let ch = rdr.curr.unwrap();\n-            bump(rdr);\n-            match ch {\n-              '\\\\' => {\n-                if is_eof(rdr) {\n-                    fatal_span(rdr, start_bpos, rdr.last_pos, \"unterminated double quote string\");\n-                }\n-\n-                let escaped = rdr.curr.unwrap();\n-                let escaped_pos = rdr.last_pos;\n-                bump(rdr);\n-                match escaped {\n-                  'n' => accum_str.push_char('\\n'),\n-                  'r' => accum_str.push_char('\\r'),\n-                  't' => accum_str.push_char('\\t'),\n-                  '\\\\' => accum_str.push_char('\\\\'),\n-                  '\\'' => accum_str.push_char('\\''),\n-                  '\"' => accum_str.push_char('\"'),\n-                  '\\n' => consume_whitespace(rdr),\n-                  '0' => accum_str.push_char('\\x00'),\n-                  'x' => {\n-                    accum_str.push_char(scan_numeric_escape(rdr, 2u, '\"'));\n-                  }\n-                  'u' => {\n-                    accum_str.push_char(scan_numeric_escape(rdr, 4u, '\"'));\n-                  }\n-                  'U' => {\n-                    accum_str.push_char(scan_numeric_escape(rdr, 8u, '\"'));\n-                  }\n-                  c2 => {\n-                    err_span_char(rdr, escaped_pos, rdr.last_pos, \"unknown string escape\", c2);\n-                  }\n-                }\n-              }\n-              _ => accum_str.push_char(ch)\n-            }\n-        }\n-        bump(rdr);\n-        return token::LIT_STR(str_to_ident(accum_str.as_slice()));\n-      }\n-      'r' => {\n-        let start_bpos = rdr.last_pos;\n-        bump(rdr);\n-        let mut hash_count = 0u;\n-        while rdr.curr_is('#') {\n-            bump(rdr);\n-            hash_count += 1;\n-        }\n-\n-        if is_eof(rdr) {\n-            fatal_span(rdr, start_bpos, rdr.last_pos, \"unterminated raw string\");\n-        } else if !rdr.curr_is('\"') {\n-            fatal_span_char(rdr, start_bpos, rdr.last_pos,\n-                            \"only `#` is allowed in raw string delimitation; \\\n-                             found illegal character\",\n-                            rdr.curr.unwrap());\n-        }\n-        bump(rdr);\n-        let content_start_bpos = rdr.last_pos;\n-        let mut content_end_bpos;\n-        'outer: loop {\n-            if is_eof(rdr) {\n-                fatal_span(rdr, start_bpos, rdr.last_pos, \"unterminated raw string\");\n-            }\n-            if rdr.curr_is('\"') {\n-                content_end_bpos = rdr.last_pos;\n-                for _ in range(0, hash_count) {\n-                    bump(rdr);\n-                    if !rdr.curr_is('#') {\n-                        continue 'outer;\n-                    }\n-                }\n-                break;\n-            }\n-            bump(rdr);\n-        }\n-        bump(rdr);\n-        let str_content = with_str_from_to(rdr,\n-                                           content_start_bpos,\n-                                           content_end_bpos,\n-                                           str_to_ident);\n-        return token::LIT_STR_RAW(str_content, hash_count);\n-      }\n-      '-' => {\n-        if nextch_is(rdr, '>') {\n-            bump(rdr);\n-            bump(rdr);\n-            return token::RARROW;\n-        } else { return binop(rdr, token::MINUS); }\n-      }\n-      '&' => {\n-        if nextch_is(rdr, '&') {\n-            bump(rdr);\n-            bump(rdr);\n-            return token::ANDAND;\n-        } else { return binop(rdr, token::AND); }\n-      }\n-      '|' => {\n-        match nextch(rdr) {\n-          Some('|') => { bump(rdr); bump(rdr); return token::OROR; }\n-          _ => { return binop(rdr, token::OR); }\n-        }\n-      }\n-      '+' => { return binop(rdr, token::PLUS); }\n-      '*' => { return binop(rdr, token::STAR); }\n-      '/' => { return binop(rdr, token::SLASH); }\n-      '^' => { return binop(rdr, token::CARET); }\n-      '%' => { return binop(rdr, token::PERCENT); }\n-      c => {\n-          fatal_span_char(rdr, rdr.last_pos, rdr.pos, \"unknown start of token\", c);\n-      }\n-    }\n-}\n-\n-fn consume_whitespace(rdr: &mut StringReader) {\n-    while is_whitespace(rdr.curr) && !is_eof(rdr) { bump(rdr); }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use super::*;\n-\n-    use codemap::{BytePos, CodeMap, Span};\n-    use diagnostic;\n-    use parse::token;\n-    use parse::token::{str_to_ident};\n-    use std::io::util;\n-\n-    fn mk_sh() -> diagnostic::SpanHandler {\n-        let emitter = diagnostic::EmitterWriter::new(box util::NullWriter);\n-        let handler = diagnostic::mk_handler(box emitter);\n-        diagnostic::mk_span_handler(handler, CodeMap::new())\n-    }\n-\n-    // open a string reader for the given string\n-    fn setup<'a>(span_handler: &'a diagnostic::SpanHandler,\n-                 teststr: String) -> StringReader<'a> {\n-        let fm = span_handler.cm.new_filemap(\"zebra.rs\".to_string(), teststr);\n-        new_string_reader(span_handler, fm)\n-    }\n-\n-    #[test] fn t1 () {\n-        let span_handler = mk_sh();\n-        let mut string_reader = setup(&span_handler,\n-            \"/* my source file */ \\\n-             fn main() { println!(\\\"zebra\\\"); }\\n\".to_string());\n-        let id = str_to_ident(\"fn\");\n-        let tok1 = string_reader.next_token();\n-        let tok2 = TokenAndSpan{\n-            tok:token::IDENT(id, false),\n-            sp:Span {lo:BytePos(21),hi:BytePos(23),expn_info: None}};\n-        assert_eq!(tok1,tok2);\n-        // the 'main' id is already read:\n-        assert_eq!(string_reader.last_pos.clone(), BytePos(28));\n-        // read another token:\n-        let tok3 = string_reader.next_token();\n-        let tok4 = TokenAndSpan{\n-            tok:token::IDENT(str_to_ident(\"main\"), false),\n-            sp:Span {lo:BytePos(24),hi:BytePos(28),expn_info: None}};\n-        assert_eq!(tok3,tok4);\n-        // the lparen is already read:\n-        assert_eq!(string_reader.last_pos.clone(), BytePos(29))\n-    }\n-\n-    // check that the given reader produces the desired stream\n-    // of tokens (stop checking after exhausting the expected vec)\n-    fn check_tokenization (mut string_reader: StringReader, expected: Vec<token::Token> ) {\n-        for expected_tok in expected.iter() {\n-            assert_eq!(&string_reader.next_token().tok, expected_tok);\n-        }\n-    }\n-\n-    // make the identifier by looking up the string in the interner\n-    fn mk_ident (id: &str, is_mod_name: bool) -> token::Token {\n-        token::IDENT (str_to_ident(id),is_mod_name)\n-    }\n-\n-    #[test] fn doublecolonparsing () {\n-        check_tokenization(setup(&mk_sh(), \"a b\".to_string()),\n-                           vec!(mk_ident(\"a\",false),\n-                             mk_ident(\"b\",false)));\n-    }\n-\n-    #[test] fn dcparsing_2 () {\n-        check_tokenization(setup(&mk_sh(), \"a::b\".to_string()),\n-                           vec!(mk_ident(\"a\",true),\n-                             token::MOD_SEP,\n-                             mk_ident(\"b\",false)));\n-    }\n-\n-    #[test] fn dcparsing_3 () {\n-        check_tokenization(setup(&mk_sh(), \"a ::b\".to_string()),\n-                           vec!(mk_ident(\"a\",false),\n-                             token::MOD_SEP,\n-                             mk_ident(\"b\",false)));\n-    }\n-\n-    #[test] fn dcparsing_4 () {\n-        check_tokenization(setup(&mk_sh(), \"a:: b\".to_string()),\n-                           vec!(mk_ident(\"a\",true),\n-                             token::MOD_SEP,\n-                             mk_ident(\"b\",false)));\n-    }\n-\n-    #[test] fn character_a() {\n-        assert_eq!(setup(&mk_sh(), \"'a'\".to_string()).next_token().tok,\n-                   token::LIT_CHAR('a'));\n-    }\n-\n-    #[test] fn character_space() {\n-        assert_eq!(setup(&mk_sh(), \"' '\".to_string()).next_token().tok,\n-                   token::LIT_CHAR(' '));\n-    }\n-\n-    #[test] fn character_escaped() {\n-        assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_string()).next_token().tok,\n-                   token::LIT_CHAR('\\n'));\n-    }\n-\n-    #[test] fn lifetime_name() {\n-        assert_eq!(setup(&mk_sh(), \"'abc\".to_string()).next_token().tok,\n-                   token::LIFETIME(token::str_to_ident(\"abc\")));\n-    }\n-\n-    #[test] fn raw_string() {\n-        assert_eq!(setup(&mk_sh(),\n-                         \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token()\n-                                                                 .tok,\n-                   token::LIT_STR_RAW(token::str_to_ident(\"\\\"#a\\\\b\\x00c\\\"\"), 3));\n-    }\n-\n-    #[test] fn line_doc_comments() {\n-        assert!(!is_line_non_doc_comment(\"///\"));\n-        assert!(!is_line_non_doc_comment(\"/// blah\"));\n-        assert!(is_line_non_doc_comment(\"////\"));\n-    }\n-\n-    #[test] fn nested_block_comments() {\n-        assert_eq!(setup(&mk_sh(),\n-                         \"/* /* */ */'a'\".to_string()).next_token().tok,\n-                   token::LIT_CHAR('a'));\n-    }\n-\n-}"}, {"sha": "a009955f91a7bdcb191ec5bda6deaba3cfd65091", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "renamed", "additions": 36, "deletions": 69, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -11,8 +11,8 @@\n use ast;\n use codemap::{BytePos, CharPos, CodeMap, Pos};\n use diagnostic;\n-use parse::lexer::{is_whitespace, with_str_from, Reader};\n-use parse::lexer::{StringReader, bump, is_eof, nextch_is, TokenAndSpan};\n+use parse::lexer::{is_whitespace, Reader};\n+use parse::lexer::{StringReader, TokenAndSpan};\n use parse::lexer::{is_line_non_doc_comment, is_block_non_doc_comment};\n use parse::lexer;\n use parse::token;\n@@ -141,31 +141,6 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     fail!(\"not a doc-comment: {}\", comment);\n }\n \n-fn read_to_eol(rdr: &mut StringReader) -> String {\n-    let mut val = String::new();\n-    while !rdr.curr_is('\\n') && !is_eof(rdr) {\n-        val.push_char(rdr.curr.unwrap());\n-        bump(rdr);\n-    }\n-    if rdr.curr_is('\\n') { bump(rdr); }\n-    return val\n-}\n-\n-fn read_one_line_comment(rdr: &mut StringReader) -> String {\n-    let val = read_to_eol(rdr);\n-    assert!((val.as_slice()[0] == '/' as u8 &&\n-                val.as_slice()[1] == '/' as u8) ||\n-                (val.as_slice()[0] == '#' as u8 &&\n-                 val.as_slice()[1] == '!' as u8));\n-    return val;\n-}\n-\n-fn consume_non_eol_whitespace(rdr: &mut StringReader) {\n-    while is_whitespace(rdr.curr) && !rdr.curr_is('\\n') && !is_eof(rdr) {\n-        bump(rdr);\n-    }\n-}\n-\n fn push_blank_line_comment(rdr: &StringReader, comments: &mut Vec<Comment>) {\n     debug!(\">>> blank-line comment\");\n     comments.push(Comment {\n@@ -177,11 +152,11 @@ fn push_blank_line_comment(rdr: &StringReader, comments: &mut Vec<Comment>) {\n \n fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader,\n                                            comments: &mut Vec<Comment>) {\n-    while is_whitespace(rdr.curr) && !is_eof(rdr) {\n+    while is_whitespace(rdr.curr) && !rdr.is_eof() {\n         if rdr.col == CharPos(0u) && rdr.curr_is('\\n') {\n             push_blank_line_comment(rdr, &mut *comments);\n         }\n-        bump(rdr);\n+        rdr.bump();\n     }\n }\n \n@@ -193,7 +168,7 @@ fn read_shebang_comment(rdr: &mut StringReader, code_to_the_left: bool,\n     debug!(\"<<< shebang comment\");\n     comments.push(Comment {\n         style: if code_to_the_left { Trailing } else { Isolated },\n-        lines: vec!(read_one_line_comment(rdr)),\n+        lines: vec!(rdr.read_one_line_comment()),\n         pos: p\n     });\n }\n@@ -203,15 +178,15 @@ fn read_line_comments(rdr: &mut StringReader, code_to_the_left: bool,\n     debug!(\">>> line comments\");\n     let p = rdr.last_pos;\n     let mut lines: Vec<String> = Vec::new();\n-    while rdr.curr_is('/') && nextch_is(rdr, '/') {\n-        let line = read_one_line_comment(rdr);\n+    while rdr.curr_is('/') && rdr.nextch_is('/') {\n+        let line = rdr.read_one_line_comment();\n         debug!(\"{}\", line);\n         // Doc comments are not put in comments.\n         if is_doc_comment(line.as_slice()) {\n             break;\n         }\n         lines.push(line);\n-        consume_non_eol_whitespace(rdr);\n+        rdr.consume_non_eol_whitespace();\n     }\n     debug!(\"<<< line comments\");\n     if !lines.is_empty() {\n@@ -265,21 +240,21 @@ fn read_block_comment(rdr: &mut StringReader,\n     let p = rdr.last_pos;\n     let mut lines: Vec<String> = Vec::new();\n     let col = rdr.col;\n-    bump(rdr);\n-    bump(rdr);\n+    rdr.bump();\n+    rdr.bump();\n \n     let mut curr_line = String::from_str(\"/*\");\n \n     // doc-comments are not really comments, they are attributes\n-    if (rdr.curr_is('*') && !nextch_is(rdr, '*')) || rdr.curr_is('!') {\n-        while !(rdr.curr_is('*') && nextch_is(rdr, '/')) && !is_eof(rdr) {\n+    if (rdr.curr_is('*') && !rdr.nextch_is('*')) || rdr.curr_is('!') {\n+        while !(rdr.curr_is('*') && rdr.nextch_is('/')) && !rdr.is_eof() {\n             curr_line.push_char(rdr.curr.unwrap());\n-            bump(rdr);\n+            rdr.bump();\n         }\n-        if !is_eof(rdr) {\n+        if !rdr.is_eof() {\n             curr_line.push_str(\"*/\");\n-            bump(rdr);\n-            bump(rdr);\n+            rdr.bump();\n+            rdr.bump();\n         }\n         if !is_block_non_doc_comment(curr_line.as_slice()) {\n             return\n@@ -290,29 +265,29 @@ fn read_block_comment(rdr: &mut StringReader,\n         let mut level: int = 1;\n         while level > 0 {\n             debug!(\"=== block comment level {}\", level);\n-            if is_eof(rdr) {\n+            if rdr.is_eof() {\n                 rdr.fatal(\"unterminated block comment\");\n             }\n             if rdr.curr_is('\\n') {\n                 trim_whitespace_prefix_and_push_line(&mut lines,\n                                                      curr_line,\n                                                      col);\n                 curr_line = String::new();\n-                bump(rdr);\n+                rdr.bump();\n             } else {\n                 curr_line.push_char(rdr.curr.unwrap());\n-                if rdr.curr_is('/') && nextch_is(rdr, '*') {\n-                    bump(rdr);\n-                    bump(rdr);\n+                if rdr.curr_is('/') && rdr.nextch_is('*') {\n+                    rdr.bump();\n+                    rdr.bump();\n                     curr_line.push_char('*');\n                     level += 1;\n                 } else {\n-                    if rdr.curr_is('*') && nextch_is(rdr, '/') {\n-                        bump(rdr);\n-                        bump(rdr);\n+                    if rdr.curr_is('*') && rdr.nextch_is('/') {\n+                        rdr.bump();\n+                        rdr.bump();\n                         curr_line.push_char('/');\n                         level -= 1;\n-                    } else { bump(rdr); }\n+                    } else { rdr.bump(); }\n                 }\n             }\n         }\n@@ -324,31 +299,24 @@ fn read_block_comment(rdr: &mut StringReader,\n     }\n \n     let mut style = if code_to_the_left { Trailing } else { Isolated };\n-    consume_non_eol_whitespace(rdr);\n-    if !is_eof(rdr) && !rdr.curr_is('\\n') && lines.len() == 1u {\n+    rdr.consume_non_eol_whitespace();\n+    if !rdr.is_eof() && !rdr.curr_is('\\n') && lines.len() == 1u {\n         style = Mixed;\n     }\n     debug!(\"<<< block comment\");\n     comments.push(Comment {style: style, lines: lines, pos: p});\n }\n \n-fn peeking_at_comment(rdr: &StringReader) -> bool {\n-    return (rdr.curr_is('/') && nextch_is(rdr, '/')) ||\n-         (rdr.curr_is('/') && nextch_is(rdr, '*')) ||\n-         // consider shebangs comments, but not inner attributes\n-         (rdr.curr_is('#') && nextch_is(rdr, '!') &&\n-          !lexer::nextnextch_is(rdr, '['));\n-}\n \n fn consume_comment(rdr: &mut StringReader,\n                    code_to_the_left: bool,\n                    comments: &mut Vec<Comment> ) {\n     debug!(\">>> consume comment\");\n-    if rdr.curr_is('/') && nextch_is(rdr, '/') {\n+    if rdr.curr_is('/') && rdr.nextch_is('/') {\n         read_line_comments(rdr, code_to_the_left, comments);\n-    } else if rdr.curr_is('/') && nextch_is(rdr, '*') {\n+    } else if rdr.curr_is('/') && rdr.nextch_is('*') {\n         read_block_comment(rdr, code_to_the_left, comments);\n-    } else if rdr.curr_is('#') && nextch_is(rdr, '!') {\n+    } else if rdr.curr_is('#') && rdr.nextch_is('!') {\n         read_shebang_comment(rdr, code_to_the_left, comments);\n     } else { fail!(); }\n     debug!(\"<<< consume comment\");\n@@ -362,29 +330,28 @@ pub struct Literal {\n \n // it appears this function is called only from pprust... that's\n // probably not a good thing.\n-pub fn gather_comments_and_literals(span_diagnostic:\n-                                        &diagnostic::SpanHandler,\n+pub fn gather_comments_and_literals(span_diagnostic: &diagnostic::SpanHandler,\n                                     path: String,\n                                     srdr: &mut io::Reader)\n                                  -> (Vec<Comment>, Vec<Literal>) {\n     let src = srdr.read_to_end().unwrap();\n     let src = str::from_utf8(src.as_slice()).unwrap().to_string();\n     let cm = CodeMap::new();\n     let filemap = cm.new_filemap(path, src);\n-    let mut rdr = lexer::new_low_level_string_reader(span_diagnostic, filemap);\n+    let mut rdr = lexer::StringReader::new_raw(span_diagnostic, filemap);\n \n     let mut comments: Vec<Comment> = Vec::new();\n     let mut literals: Vec<Literal> = Vec::new();\n     let mut first_read: bool = true;\n-    while !is_eof(&rdr) {\n+    while !rdr.is_eof() {\n         loop {\n             let mut code_to_the_left = !first_read;\n-            consume_non_eol_whitespace(&mut rdr);\n+            rdr.consume_non_eol_whitespace();\n             if rdr.curr_is('\\n') {\n                 code_to_the_left = false;\n                 consume_whitespace_counting_blank_lines(&mut rdr, &mut comments);\n             }\n-            while peeking_at_comment(&rdr) {\n+            while rdr.peeking_at_comment() {\n                 consume_comment(&mut rdr, code_to_the_left, &mut comments);\n                 consume_whitespace_counting_blank_lines(&mut rdr, &mut comments);\n             }\n@@ -397,7 +364,7 @@ pub fn gather_comments_and_literals(span_diagnostic:\n         //discard, and look ahead; we're working with internal state\n         let TokenAndSpan {tok: tok, sp: sp} = rdr.peek();\n         if token::is_lit(&tok) {\n-            with_str_from(&rdr, bstart, |s| {\n+            rdr.with_str_from(bstart, |s| {\n                 debug!(\"tok lit: {}\", s);\n                 literals.push(Literal {lit: s.to_string(), pos: sp.lo});\n             })", "previous_filename": "src/libsyntax/parse/comments.rs"}, {"sha": "bb23fe50bd9e2d32e18604960bf359d0b9ebffd8", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "added", "additions": 1153, "deletions": 0, "changes": 1153, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -0,0 +1,1153 @@\n+// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use ast;\n+use codemap::{BytePos, CharPos, CodeMap, Pos, Span};\n+use codemap;\n+use diagnostic::SpanHandler;\n+use ext::tt::transcribe::tt_next_token;\n+use parse::token;\n+use parse::token::{str_to_ident};\n+\n+use std::char;\n+use std::mem::replace;\n+use std::num::from_str_radix;\n+use std::rc::Rc;\n+use std::str;\n+\n+pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n+\n+pub mod comments;\n+\n+pub trait Reader {\n+    fn is_eof(&self) -> bool;\n+    fn next_token(&mut self) -> TokenAndSpan;\n+    /// Report a fatal error with the current span.\n+    fn fatal(&self, &str) -> !;\n+    /// Report a non-fatal error with the current span.\n+    fn err(&self, &str);\n+    fn peek(&self) -> TokenAndSpan;\n+}\n+\n+#[deriving(Clone, PartialEq, Eq, Show)]\n+pub struct TokenAndSpan {\n+    pub tok: token::Token,\n+    pub sp: Span,\n+}\n+\n+pub struct StringReader<'a> {\n+    pub span_diagnostic: &'a SpanHandler,\n+    // The absolute offset within the codemap of the next character to read\n+    pub pos: BytePos,\n+    // The absolute offset within the codemap of the last character read(curr)\n+    pub last_pos: BytePos,\n+    // The column of the next character to read\n+    pub col: CharPos,\n+    // The last character to be read\n+    pub curr: Option<char>,\n+    pub filemap: Rc<codemap::FileMap>,\n+    /* cached: */\n+    pub peek_tok: token::Token,\n+    pub peek_span: Span,\n+}\n+\n+impl<'a> Reader for StringReader<'a> {\n+    fn is_eof(&self) -> bool { self.curr.is_none() }\n+    // return the next token. EFFECT: advances the string_reader.\n+    fn next_token(&mut self) -> TokenAndSpan {\n+        let ret_val = TokenAndSpan {\n+            tok: replace(&mut self.peek_tok, token::UNDERSCORE),\n+            sp: self.peek_span,\n+        };\n+        self.advance_token();\n+        ret_val\n+    }\n+    fn fatal(&self, m: &str) -> ! {\n+        self.span_diagnostic.span_fatal(self.peek_span, m)\n+    }\n+    fn err(&self, m: &str) {\n+        self.span_diagnostic.span_err(self.peek_span, m)\n+    }\n+    fn peek(&self) -> TokenAndSpan {\n+        // FIXME(pcwalton): Bad copy!\n+        TokenAndSpan {\n+            tok: self.peek_tok.clone(),\n+            sp: self.peek_span,\n+        }\n+    }\n+}\n+\n+impl<'a> Reader for TtReader<'a> {\n+    fn is_eof(&self) -> bool {\n+        self.cur_tok == token::EOF\n+    }\n+    fn next_token(&mut self) -> TokenAndSpan {\n+        let r = tt_next_token(self);\n+        debug!(\"TtReader: r={:?}\", r);\n+        r\n+    }\n+    fn fatal(&self, m: &str) -> ! {\n+        self.sp_diag.span_fatal(self.cur_span, m);\n+    }\n+    fn err(&self, m: &str) {\n+        self.sp_diag.span_err(self.cur_span, m);\n+    }\n+    fn peek(&self) -> TokenAndSpan {\n+        TokenAndSpan {\n+            tok: self.cur_tok.clone(),\n+            sp: self.cur_span,\n+        }\n+    }\n+}\n+\n+impl<'a> StringReader<'a> {\n+    /// For comments.rs, which hackily pokes into pos and curr\n+    pub fn new_raw<'b>(span_diagnostic: &'b SpanHandler,\n+                   filemap: Rc<codemap::FileMap>) -> StringReader<'b> {\n+        let mut sr = StringReader {\n+            span_diagnostic: span_diagnostic,\n+            pos: filemap.start_pos,\n+            last_pos: filemap.start_pos,\n+            col: CharPos(0),\n+            curr: Some('\\n'),\n+            filemap: filemap,\n+            /* dummy values; not read */\n+            peek_tok: token::EOF,\n+            peek_span: codemap::DUMMY_SP,\n+        };\n+        sr.bump();\n+        sr\n+    }\n+\n+    pub fn new<'b>(span_diagnostic: &'b SpanHandler,\n+                   filemap: Rc<codemap::FileMap>) -> StringReader<'b> {\n+        let mut sr = StringReader::new_raw(span_diagnostic, filemap);\n+        sr.advance_token();\n+        sr\n+    }\n+\n+    pub fn curr_is(&self, c: char) -> bool {\n+        self.curr == Some(c)\n+    }\n+\n+    /// Report a lexical error spanning [`from_pos`, `to_pos`)\n+    fn fatal_span(&mut self, from_pos: BytePos, to_pos: BytePos, m: &str) -> ! {\n+        self.peek_span = codemap::mk_sp(from_pos, to_pos);\n+        self.fatal(m);\n+    }\n+\n+    fn err_span(&mut self, from_pos: BytePos, to_pos: BytePos, m: &str) {\n+        self.peek_span = codemap::mk_sp(from_pos, to_pos);\n+        self.err(m);\n+    }\n+\n+    /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n+    /// escaped character to the error message\n+    fn fatal_span_char(&mut self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) -> ! {\n+        let mut m = m.to_string();\n+        m.push_str(\": \");\n+        char::escape_default(c, |c| m.push_char(c));\n+        self.fatal_span(from_pos, to_pos, m.as_slice());\n+    }\n+\n+    /// Report a lexical error spanning [`from_pos`, `to_pos`), appending an\n+    /// escaped character to the error message\n+    fn err_span_char(&mut self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) {\n+        let mut m = m.to_string();\n+        m.push_str(\": \");\n+        char::escape_default(c, |c| m.push_char(c));\n+        self.err_span(from_pos, to_pos, m.as_slice());\n+    }\n+\n+    /// Report a lexical error spanning [`from_pos`, `to_pos`), appending the\n+    /// offending string to the error message\n+    fn fatal_span_verbose(&mut self, from_pos: BytePos, to_pos: BytePos, mut m: String) -> ! {\n+        m.push_str(\": \");\n+        let from = self.byte_offset(from_pos).to_uint();\n+        let to = self.byte_offset(to_pos).to_uint();\n+        m.push_str(self.filemap.src.as_slice().slice(from, to));\n+        self.fatal_span(from_pos, to_pos, m.as_slice());\n+    }\n+\n+    /// Advance peek_tok and peek_span to refer to the next token, and\n+    /// possibly update the interner.\n+    fn advance_token(&mut self) {\n+        match self.consume_whitespace_and_comments() {\n+            Some(comment) => {\n+                self.peek_span = comment.sp;\n+                self.peek_tok = comment.tok;\n+            },\n+            None => {\n+                if self.is_eof() {\n+                    self.peek_tok = token::EOF;\n+                } else {\n+                    let start_bytepos = self.last_pos;\n+                    self.peek_tok = self.next_token_inner();\n+                    self.peek_span = codemap::mk_sp(start_bytepos,\n+                                                    self.last_pos);\n+                };\n+            }\n+        }\n+    }\n+\n+    fn byte_offset(&self, pos: BytePos) -> BytePos {\n+        (pos - self.filemap.start_pos)\n+    }\n+\n+    /// Calls `f` with a string slice of the source text spanning from `start`\n+    /// up to but excluding `self.last_pos`, meaning the slice does not include\n+    /// the character `self.curr`.\n+    pub fn with_str_from<T>(&self, start: BytePos, f: |s: &str| -> T) -> T {\n+        self.with_str_from_to(start, self.last_pos, f)\n+    }\n+\n+    /// Calls `f` with a string slice of the source text spanning from `start`\n+    /// up to but excluding `end`.\n+    fn with_str_from_to<T>(&self, start: BytePos, end: BytePos, f: |s: &str| -> T) -> T {\n+        f(self.filemap.src.as_slice().slice(\n+                self.byte_offset(start).to_uint(),\n+                self.byte_offset(end).to_uint()))\n+    }\n+\n+    /// Advance the StringReader by one character. If a newline is\n+    /// discovered, add it to the FileMap's list of line start offsets.\n+    pub fn bump(&mut self) {\n+        self.last_pos = self.pos;\n+        let current_byte_offset = self.byte_offset(self.pos).to_uint();\n+        if current_byte_offset < self.filemap.src.len() {\n+            assert!(self.curr.is_some());\n+            let last_char = self.curr.unwrap();\n+            let next = self.filemap\n+                          .src\n+                          .as_slice()\n+                          .char_range_at(current_byte_offset);\n+            let byte_offset_diff = next.next - current_byte_offset;\n+            self.pos = self.pos + Pos::from_uint(byte_offset_diff);\n+            self.curr = Some(next.ch);\n+            self.col = self.col + CharPos(1u);\n+            if last_char == '\\n' {\n+                self.filemap.next_line(self.last_pos);\n+                self.col = CharPos(0u);\n+            }\n+\n+            if byte_offset_diff > 1 {\n+                self.filemap.record_multibyte_char(self.last_pos, byte_offset_diff);\n+            }\n+        } else {\n+            self.curr = None;\n+        }\n+    }\n+\n+    pub fn nextch(&self) -> Option<char> {\n+        let offset = self.byte_offset(self.pos).to_uint();\n+        if offset < self.filemap.src.len() {\n+            Some(self.filemap.src.as_slice().char_at(offset))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn nextch_is(&self, c: char) -> bool {\n+        self.nextch() == Some(c)\n+    }\n+\n+    pub fn nextnextch(&self) -> Option<char> {\n+        let offset = self.byte_offset(self.pos).to_uint();\n+        let s = self.filemap.deref().src.as_slice();\n+        if offset >= s.len() { return None }\n+        let str::CharRange { next, .. } = s.char_range_at(offset);\n+        if next < s.len() {\n+            Some(s.char_at(next))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn nextnextch_is(&self, c: char) -> bool {\n+        self.nextnextch() == Some(c)\n+    }\n+\n+    /// PRECONDITION: self.curr is not whitespace\n+    /// Eats any kind of comment.\n+    /// Returns a Some(sugared-doc-attr) if one exists, None otherwise\n+    fn consume_any_line_comment(&mut self) -> Option<TokenAndSpan> {\n+        match self.curr {\n+            Some(c) => {\n+                if c.is_whitespace() {\n+                    self.span_diagnostic.span_err(codemap::mk_sp(self.last_pos, self.last_pos),\n+                                    \"called consume_any_line_comment, but there was whitespace\");\n+                }\n+            },\n+            None => { }\n+        }\n+\n+        if self.curr_is('/') {\n+            match self.nextch() {\n+                Some('/') => {\n+                    self.bump();\n+                    self.bump();\n+                    // line comments starting with \"///\" or \"//!\" are doc-comments\n+                    if self.curr_is('/') || self.curr_is('!') {\n+                        let start_bpos = self.pos - BytePos(3);\n+                        while !self.curr_is('\\n') && !self.is_eof() {\n+                            self.bump();\n+                        }\n+                        let ret = self.with_str_from(start_bpos, |string| {\n+                            // but comments with only more \"/\"s are not\n+                            if !is_line_non_doc_comment(string) {\n+                                Some(TokenAndSpan{\n+                                    tok: token::DOC_COMMENT(str_to_ident(string)),\n+                                    sp: codemap::mk_sp(start_bpos, self.pos)\n+                                })\n+                            } else {\n+                                None\n+                            }\n+                        });\n+\n+                        if ret.is_some() {\n+                            return ret;\n+                        }\n+                    } else {\n+                        while !self.curr_is('\\n') && !self.is_eof() { self.bump(); }\n+                    }\n+                    // Restart whitespace munch.\n+                    self.consume_whitespace_and_comments()\n+                }\n+                Some('*') => { self.bump(); self.bump(); self.consume_block_comment() }\n+                _ => None\n+            }\n+        } else if self.curr_is('#') {\n+            if self.nextch_is('!') {\n+\n+                // Parse an inner attribute.\n+                if self.nextnextch_is('[') {\n+                    return None;\n+                }\n+\n+                // I guess this is the only way to figure out if\n+                // we're at the beginning of the file...\n+                let cmap = CodeMap::new();\n+                cmap.files.borrow_mut().push(self.filemap.clone());\n+                let loc = cmap.lookup_char_pos_adj(self.last_pos);\n+                if loc.line == 1u && loc.col == CharPos(0u) {\n+                    while !self.curr_is('\\n') && !self.is_eof() { self.bump(); }\n+                    return self.consume_whitespace_and_comments();\n+                }\n+            }\n+            None\n+        } else {\n+            None\n+        }\n+    }\n+\n+    /// EFFECT: eats whitespace and comments.\n+    /// Returns a Some(sugared-doc-attr) if one exists, None otherwise.\n+    fn consume_whitespace_and_comments(&mut self) -> Option<TokenAndSpan> {\n+        while is_whitespace(self.curr) { self.bump(); }\n+        return self.consume_any_line_comment();\n+    }\n+\n+    // might return a sugared-doc-attr\n+    fn consume_block_comment(&mut self) -> Option<TokenAndSpan> {\n+        // block comments starting with \"/**\" or \"/*!\" are doc-comments\n+        let is_doc_comment = self.curr_is('*') || self.curr_is('!');\n+        let start_bpos = self.pos - BytePos(if is_doc_comment {3} else {2});\n+\n+        let mut level: int = 1;\n+        while level > 0 {\n+            if self.is_eof() {\n+                let msg = if is_doc_comment {\n+                    \"unterminated block doc-comment\"\n+                } else {\n+                    \"unterminated block comment\"\n+                };\n+                self.fatal_span(start_bpos, self.last_pos, msg);\n+            } else if self.curr_is('/') && self.nextch_is('*') {\n+                level += 1;\n+                self.bump();\n+                self.bump();\n+            } else if self.curr_is('*') && self.nextch_is('/') {\n+                level -= 1;\n+                self.bump();\n+                self.bump();\n+            } else {\n+                self.bump();\n+            }\n+        }\n+\n+        let res = if is_doc_comment {\n+            self.with_str_from(start_bpos, |string| {\n+                // but comments with only \"*\"s between two \"/\"s are not\n+                if !is_block_non_doc_comment(string) {\n+                    Some(TokenAndSpan{\n+                            tok: token::DOC_COMMENT(str_to_ident(string)),\n+                            sp: codemap::mk_sp(start_bpos, self.pos)\n+                        })\n+                } else {\n+                    None\n+                }\n+            })\n+        } else {\n+            None\n+        };\n+\n+        // restart whitespace munch.\n+        if res.is_some() { res } else { self.consume_whitespace_and_comments() }\n+    }\n+\n+    fn scan_exponent(&mut self, start_bpos: BytePos) -> Option<String> {\n+        // \\x00 hits the `return None` case immediately, so this is fine.\n+        let mut c = self.curr.unwrap_or('\\x00');\n+        let mut rslt = String::new();\n+        if c == 'e' || c == 'E' {\n+            rslt.push_char(c);\n+            self.bump();\n+            c = self.curr.unwrap_or('\\x00');\n+            if c == '-' || c == '+' {\n+                rslt.push_char(c);\n+                self.bump();\n+            }\n+            let exponent = self.scan_digits(10u);\n+            if exponent.len() > 0u {\n+                rslt.push_str(exponent.as_slice());\n+                return Some(rslt);\n+            } else {\n+                self.err_span(start_bpos, self.last_pos, \"scan_exponent: bad fp literal\");\n+                rslt.push_str(\"1\"); // arbitrary placeholder exponent\n+                return Some(rslt);\n+            }\n+        } else {\n+            return None::<String>;\n+        }\n+    }\n+\n+    fn scan_digits(&mut self, radix: uint) -> String {\n+        let mut rslt = String::new();\n+        loop {\n+            let c = self.curr;\n+            if c == Some('_') { self.bump(); continue; }\n+            match c.and_then(|cc| char::to_digit(cc, radix)) {\n+              Some(_) => {\n+                rslt.push_char(c.unwrap());\n+                self.bump();\n+              }\n+              _ => return rslt\n+            }\n+        };\n+    }\n+\n+    fn check_float_base(&mut self, start_bpos: BytePos, last_bpos: BytePos, base: uint) {\n+        match base {\n+          16u => self.err_span(start_bpos, last_bpos, \"hexadecimal float literal is not supported\"),\n+          8u => self.err_span(start_bpos, last_bpos, \"octal float literal is not supported\"),\n+          2u => self.err_span(start_bpos, last_bpos, \"binary float literal is not supported\"),\n+          _ => ()\n+        }\n+    }\n+\n+    fn scan_number(&mut self, c: char) -> token::Token {\n+        let mut num_str;\n+        let mut base = 10u;\n+        let mut c = c;\n+        let mut n = self.nextch().unwrap_or('\\x00');\n+        let start_bpos = self.last_pos;\n+        if c == '0' && n == 'x' {\n+            self.bump();\n+            self.bump();\n+            base = 16u;\n+        } else if c == '0' && n == 'o' {\n+            self.bump();\n+            self.bump();\n+            base = 8u;\n+        } else if c == '0' && n == 'b' {\n+            self.bump();\n+            self.bump();\n+            base = 2u;\n+        }\n+        num_str = self.scan_digits(base);\n+        c = self.curr.unwrap_or('\\x00');\n+        self.nextch();\n+        if c == 'u' || c == 'i' {\n+            enum Result { Signed(ast::IntTy), Unsigned(ast::UintTy) }\n+            let signed = c == 'i';\n+            let mut tp = {\n+                if signed { Signed(ast::TyI) }\n+                else { Unsigned(ast::TyU) }\n+            };\n+            self.bump();\n+            c = self.curr.unwrap_or('\\x00');\n+            if c == '8' {\n+                self.bump();\n+                tp = if signed { Signed(ast::TyI8) }\n+                          else { Unsigned(ast::TyU8) };\n+            }\n+            n = self.nextch().unwrap_or('\\x00');\n+            if c == '1' && n == '6' {\n+                self.bump();\n+                self.bump();\n+                tp = if signed { Signed(ast::TyI16) }\n+                          else { Unsigned(ast::TyU16) };\n+            } else if c == '3' && n == '2' {\n+                self.bump();\n+                self.bump();\n+                tp = if signed { Signed(ast::TyI32) }\n+                          else { Unsigned(ast::TyU32) };\n+            } else if c == '6' && n == '4' {\n+                self.bump();\n+                self.bump();\n+                tp = if signed { Signed(ast::TyI64) }\n+                          else { Unsigned(ast::TyU64) };\n+            }\n+            if num_str.len() == 0u {\n+                self.err_span(start_bpos, self.last_pos, \"no valid digits found for number\");\n+                num_str = \"1\".to_string();\n+            }\n+            let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n+                                                     base as uint) {\n+                Some(p) => p,\n+                None => {\n+                    self.err_span(start_bpos, self.last_pos, \"int literal is too large\");\n+                    1\n+                }\n+            };\n+\n+            match tp {\n+              Signed(t) => return token::LIT_INT(parsed as i64, t),\n+              Unsigned(t) => return token::LIT_UINT(parsed, t)\n+            }\n+        }\n+        let mut is_float = false;\n+        if self.curr_is('.') && !(ident_start(self.nextch()) || self.nextch_is('.')) {\n+            is_float = true;\n+            self.bump();\n+            let dec_part = self.scan_digits(10u);\n+            num_str.push_char('.');\n+            num_str.push_str(dec_part.as_slice());\n+        }\n+        match self.scan_exponent(start_bpos) {\n+          Some(ref s) => {\n+            is_float = true;\n+            num_str.push_str(s.as_slice());\n+          }\n+          None => ()\n+        }\n+\n+        if self.curr_is('f') {\n+            self.bump();\n+            c = self.curr.unwrap_or('\\x00');\n+            n = self.nextch().unwrap_or('\\x00');\n+            if c == '3' && n == '2' {\n+                self.bump();\n+                self.bump();\n+                self.check_float_base(start_bpos, self.last_pos, base);\n+                return token::LIT_FLOAT(str_to_ident(num_str.as_slice()),\n+                                        ast::TyF32);\n+            } else if c == '6' && n == '4' {\n+                self.bump();\n+                self.bump();\n+                self.check_float_base(start_bpos, self.last_pos, base);\n+                return token::LIT_FLOAT(str_to_ident(num_str.as_slice()),\n+                                        ast::TyF64);\n+                /* FIXME (#2252): if this is out of range for either a\n+                32-bit or 64-bit float, it won't be noticed till the\n+                back-end.  */\n+            } else if c == '1' && n == '2' && self.nextnextch().unwrap_or('\\x00') == '8' {\n+                self.bump();\n+                self.bump();\n+                self.bump();\n+                self.check_float_base(start_bpos, self.last_pos, base);\n+                return token::LIT_FLOAT(str_to_ident(num_str.as_slice()), ast::TyF128);\n+            }\n+            self.err_span(start_bpos, self.last_pos, \"expected `f32`, `f64` or `f128` suffix\");\n+        }\n+        if is_float {\n+            self.check_float_base(start_bpos, self.last_pos, base);\n+            return token::LIT_FLOAT_UNSUFFIXED(str_to_ident(\n+                    num_str.as_slice()));\n+        } else {\n+            if num_str.len() == 0u {\n+                self.err_span(start_bpos, self.last_pos, \"no valid digits found for number\");\n+                num_str = \"1\".to_string();\n+            }\n+            let parsed = match from_str_radix::<u64>(num_str.as_slice(),\n+                                                     base as uint) {\n+                Some(p) => p,\n+                None => {\n+                    self.err_span(start_bpos, self.last_pos, \"int literal is too large\");\n+                    1\n+                }\n+            };\n+\n+            debug!(\"lexing {} as an unsuffixed integer literal\",\n+                   num_str.as_slice());\n+            return token::LIT_INT_UNSUFFIXED(parsed as i64);\n+        }\n+    }\n+\n+\n+    fn scan_numeric_escape(&mut self, n_hex_digits: uint, delim: char) -> char {\n+        let mut accum_int = 0u32;\n+        let start_bpos = self.last_pos;\n+        for _ in range(0, n_hex_digits) {\n+            if self.is_eof() {\n+                self.fatal_span(start_bpos, self.last_pos, \"unterminated numeric character escape\");\n+            }\n+            if self.curr_is(delim) {\n+                self.err_span(start_bpos, self.last_pos, \"numeric character escape is too short\");\n+                break;\n+            }\n+            let c = self.curr.unwrap_or('\\x00');\n+            accum_int *= 16;\n+            accum_int += c.to_digit(16).unwrap_or_else(|| {\n+                self.err_span_char(self.last_pos, self.pos,\n+                              \"illegal character in numeric character escape\", c);\n+                0\n+            }) as u32;\n+            self.bump();\n+        }\n+\n+        match char::from_u32(accum_int) {\n+            Some(x) => x,\n+            None => {\n+                self.err_span(start_bpos, self.last_pos, \"illegal numeric character escape\");\n+                '?'\n+            }\n+        }\n+    }\n+\n+    fn binop(&mut self, op: token::BinOp) -> token::Token {\n+        self.bump();\n+        if self.curr_is('=') {\n+            self.bump();\n+            return token::BINOPEQ(op);\n+        } else {\n+            return token::BINOP(op);\n+        }\n+    }\n+\n+    /// Return the next token from the string, advances the input past that\n+    /// token, and updates the interner\n+    fn next_token_inner(&mut self) -> token::Token {\n+        let c = self.curr;\n+        if ident_start(c) && !self.nextch_is('\"') && !self.nextch_is('#') {\n+            // Note: r as in r\" or r#\" is part of a raw string literal,\n+            // not an identifier, and is handled further down.\n+\n+            let start = self.last_pos;\n+            while ident_continue(self.curr) {\n+                self.bump();\n+            }\n+\n+            return self.with_str_from(start, |string| {\n+                if string == \"_\" {\n+                    token::UNDERSCORE\n+                } else {\n+                    let is_mod_name = self.curr_is(':') && self.nextch_is(':');\n+\n+                    // FIXME: perform NFKC normalization here. (Issue #2253)\n+                    token::IDENT(str_to_ident(string), is_mod_name)\n+                }\n+            })\n+        }\n+\n+        if is_dec_digit(c) {\n+            return self.scan_number(c.unwrap());\n+        }\n+\n+        match c.expect(\"next_token_inner called at EOF\") {\n+          // One-byte tokens.\n+          ';' => { self.bump(); return token::SEMI; }\n+          ',' => { self.bump(); return token::COMMA; }\n+          '.' => {\n+              self.bump();\n+              return if self.curr_is('.') {\n+                  self.bump();\n+                  if self.curr_is('.') {\n+                      self.bump();\n+                      token::DOTDOTDOT\n+                  } else {\n+                      token::DOTDOT\n+                  }\n+              } else {\n+                  token::DOT\n+              };\n+          }\n+          '(' => { self.bump(); return token::LPAREN; }\n+          ')' => { self.bump(); return token::RPAREN; }\n+          '{' => { self.bump(); return token::LBRACE; }\n+          '}' => { self.bump(); return token::RBRACE; }\n+          '[' => { self.bump(); return token::LBRACKET; }\n+          ']' => { self.bump(); return token::RBRACKET; }\n+          '@' => { self.bump(); return token::AT; }\n+          '#' => { self.bump(); return token::POUND; }\n+          '~' => { self.bump(); return token::TILDE; }\n+          ':' => {\n+            self.bump();\n+            if self.curr_is(':') {\n+                self.bump();\n+                return token::MOD_SEP;\n+            } else {\n+                return token::COLON;\n+            }\n+          }\n+\n+          '$' => { self.bump(); return token::DOLLAR; }\n+\n+          // Multi-byte tokens.\n+          '=' => {\n+            self.bump();\n+            if self.curr_is('=') {\n+                self.bump();\n+                return token::EQEQ;\n+            } else if self.curr_is('>') {\n+                self.bump();\n+                return token::FAT_ARROW;\n+            } else {\n+                return token::EQ;\n+            }\n+          }\n+          '!' => {\n+            self.bump();\n+            if self.curr_is('=') {\n+                self.bump();\n+                return token::NE;\n+            } else { return token::NOT; }\n+          }\n+          '<' => {\n+            self.bump();\n+            match self.curr.unwrap_or('\\x00') {\n+              '=' => { self.bump(); return token::LE; }\n+              '<' => { return self.binop(token::SHL); }\n+              '-' => {\n+                self.bump();\n+                match self.curr.unwrap_or('\\x00') {\n+                  _ => { return token::LARROW; }\n+                }\n+              }\n+              _ => { return token::LT; }\n+            }\n+          }\n+          '>' => {\n+            self.bump();\n+            match self.curr.unwrap_or('\\x00') {\n+              '=' => { self.bump(); return token::GE; }\n+              '>' => { return self.binop(token::SHR); }\n+              _ => { return token::GT; }\n+            }\n+          }\n+          '\\'' => {\n+            // Either a character constant 'a' OR a lifetime name 'abc\n+            self.bump();\n+            let start = self.last_pos;\n+\n+            // the eof will be picked up by the final `'` check below\n+            let mut c2 = self.curr.unwrap_or('\\x00');\n+            self.bump();\n+\n+            // If the character is an ident start not followed by another single\n+            // quote, then this is a lifetime name:\n+            if ident_start(Some(c2)) && !self.curr_is('\\'') {\n+                while ident_continue(self.curr) {\n+                    self.bump();\n+                }\n+                let ident = self.with_str_from(start, |lifetime_name| {\n+                    str_to_ident(lifetime_name)\n+                });\n+                let tok = &token::IDENT(ident, false);\n+\n+                if token::is_keyword(token::keywords::Self, tok) {\n+                    self.err_span(start, self.last_pos,\n+                               \"invalid lifetime name: 'self \\\n+                                is no longer a special lifetime\");\n+                } else if token::is_any_keyword(tok) &&\n+                    !token::is_keyword(token::keywords::Static, tok) {\n+                    self.err_span(start, self.last_pos,\n+                               \"invalid lifetime name\");\n+                }\n+                return token::LIFETIME(ident);\n+            }\n+\n+            // Otherwise it is a character constant:\n+            match c2 {\n+                '\\\\' => {\n+                    // '\\X' for some X must be a character constant:\n+                    let escaped = self.curr;\n+                    let escaped_pos = self.last_pos;\n+                    self.bump();\n+                    match escaped {\n+                        None => {}\n+                        Some(e) => {\n+                            c2 = match e {\n+                                'n' => '\\n',\n+                                'r' => '\\r',\n+                                't' => '\\t',\n+                                '\\\\' => '\\\\',\n+                                '\\'' => '\\'',\n+                                '\"' => '\"',\n+                                '0' => '\\x00',\n+                                'x' => self.scan_numeric_escape(2u, '\\''),\n+                                'u' => self.scan_numeric_escape(4u, '\\''),\n+                                'U' => self.scan_numeric_escape(8u, '\\''),\n+                                c2 => {\n+                                    self.err_span_char(escaped_pos, self.last_pos,\n+                                                         \"unknown character escape\", c2);\n+                                    c2\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+                '\\t' | '\\n' | '\\r' | '\\'' => {\n+                    self.err_span_char( start, self.last_pos,\n+                        \"character constant must be escaped\", c2);\n+                }\n+                _ => {}\n+            }\n+            if !self.curr_is('\\'') {\n+                self.fatal_span_verbose(\n+                                   // Byte offsetting here is okay because the\n+                                   // character before position `start` is an\n+                                   // ascii single quote.\n+                                   start - BytePos(1), self.last_pos,\n+                                   \"unterminated character constant\".to_string());\n+            }\n+            self.bump(); // advance curr past token\n+            return token::LIT_CHAR(c2);\n+          }\n+          '\"' => {\n+            let mut accum_str = String::new();\n+            let start_bpos = self.last_pos;\n+            self.bump();\n+            while !self.curr_is('\"') {\n+                if self.is_eof() {\n+                    self.fatal_span(start_bpos, self.last_pos, \"unterminated double quote string\");\n+                }\n+\n+                let ch = self.curr.unwrap();\n+                self.bump();\n+                match ch {\n+                  '\\\\' => {\n+                    if self.is_eof() {\n+                        self.fatal_span(start_bpos, self.last_pos,\n+                               \"unterminated double quote string\");\n+                    }\n+\n+                    let escaped = self.curr.unwrap();\n+                    let escaped_pos = self.last_pos;\n+                    self.bump();\n+                    match escaped {\n+                      'n' => accum_str.push_char('\\n'),\n+                      'r' => accum_str.push_char('\\r'),\n+                      't' => accum_str.push_char('\\t'),\n+                      '\\\\' => accum_str.push_char('\\\\'),\n+                      '\\'' => accum_str.push_char('\\''),\n+                      '\"' => accum_str.push_char('\"'),\n+                      '\\n' => self.consume_whitespace(),\n+                      '0' => accum_str.push_char('\\x00'),\n+                      'x' => {\n+                        accum_str.push_char(self.scan_numeric_escape(2u, '\"'));\n+                      }\n+                      'u' => {\n+                        accum_str.push_char(self.scan_numeric_escape(4u, '\"'));\n+                      }\n+                      'U' => {\n+                        accum_str.push_char(self.scan_numeric_escape(8u, '\"'));\n+                      }\n+                      c2 => {\n+                        self.err_span_char(escaped_pos, self.last_pos,\n+                                        \"unknown string escape\", c2);\n+                      }\n+                    }\n+                  }\n+                  _ => accum_str.push_char(ch)\n+                }\n+            }\n+            self.bump();\n+            return token::LIT_STR(str_to_ident(accum_str.as_slice()));\n+          }\n+          'r' => {\n+            let start_bpos = self.last_pos;\n+            self.bump();\n+            let mut hash_count = 0u;\n+            while self.curr_is('#') {\n+                self.bump();\n+                hash_count += 1;\n+            }\n+\n+            if self.is_eof() {\n+                self.fatal_span(start_bpos, self.last_pos, \"unterminated raw string\");\n+            } else if !self.curr_is('\"') {\n+                self.fatal_span_char(start_bpos, self.last_pos,\n+                                \"only `#` is allowed in raw string delimitation; \\\n+                                 found illegal character\",\n+                                self.curr.unwrap());\n+            }\n+            self.bump();\n+            let content_start_bpos = self.last_pos;\n+            let mut content_end_bpos;\n+            'outer: loop {\n+                if self.is_eof() {\n+                    self.fatal_span(start_bpos, self.last_pos, \"unterminated raw string\");\n+                }\n+                if self.curr_is('\"') {\n+                    content_end_bpos = self.last_pos;\n+                    for _ in range(0, hash_count) {\n+                        self.bump();\n+                        if !self.curr_is('#') {\n+                            continue 'outer;\n+                        }\n+                    }\n+                    break;\n+                }\n+                self.bump();\n+            }\n+            self.bump();\n+            let str_content = self.with_str_from_to(\n+                                               content_start_bpos,\n+                                               content_end_bpos,\n+                                               str_to_ident);\n+            return token::LIT_STR_RAW(str_content, hash_count);\n+          }\n+          '-' => {\n+            if self.nextch_is('>') {\n+                self.bump();\n+                self.bump();\n+                return token::RARROW;\n+            } else { return self.binop(token::MINUS); }\n+          }\n+          '&' => {\n+            if self.nextch_is('&') {\n+                self.bump();\n+                self.bump();\n+                return token::ANDAND;\n+            } else { return self.binop(token::AND); }\n+          }\n+          '|' => {\n+            match self.nextch() {\n+              Some('|') => { self.bump(); self.bump(); return token::OROR; }\n+              _ => { return self.binop(token::OR); }\n+            }\n+          }\n+          '+' => { return self.binop(token::PLUS); }\n+          '*' => { return self.binop(token::STAR); }\n+          '/' => { return self.binop(token::SLASH); }\n+          '^' => { return self.binop(token::CARET); }\n+          '%' => { return self.binop(token::PERCENT); }\n+          c => {\n+              self.fatal_span_char(self.last_pos, self.pos,\n+                              \"unknown start of token\", c);\n+          }\n+        }\n+    }\n+\n+    fn consume_whitespace(&mut self) {\n+        while is_whitespace(self.curr) && !self.is_eof() { self.bump(); }\n+    }\n+\n+    fn read_to_eol(&mut self) -> String {\n+        let mut val = String::new();\n+        while !self.curr_is('\\n') && !self.is_eof() {\n+            val.push_char(self.curr.unwrap());\n+            self.bump();\n+        }\n+        if self.curr_is('\\n') { self.bump(); }\n+        return val\n+    }\n+\n+    fn read_one_line_comment(&mut self) -> String {\n+        let val = self.read_to_eol();\n+        assert!((val.as_slice()[0] == '/' as u8 && val.as_slice()[1] == '/' as u8)\n+             || (val.as_slice()[0] == '#' as u8 && val.as_slice()[1] == '!' as u8));\n+        return val;\n+    }\n+\n+    fn consume_non_eol_whitespace(&mut self) {\n+        while is_whitespace(self.curr) && !self.curr_is('\\n') && !self.is_eof() {\n+            self.bump();\n+        }\n+    }\n+\n+    fn peeking_at_comment(&self) -> bool {\n+        (self.curr_is('/') && self.nextch_is('/'))\n+     || (self.curr_is('/') && self.nextch_is('*'))\n+     // consider shebangs comments, but not inner attributes\n+     || (self.curr_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n+    }\n+}\n+\n+pub fn is_whitespace(c: Option<char>) -> bool {\n+    match c.unwrap_or('\\x00') { // None can be null for now... it's not whitespace\n+        ' ' | '\\n' | '\\t' | '\\r' => true,\n+        _ => false\n+    }\n+}\n+\n+fn in_range(c: Option<char>, lo: char, hi: char) -> bool {\n+    match c {\n+        Some(c) => lo <= c && c <= hi,\n+        _ => false\n+    }\n+}\n+\n+fn is_dec_digit(c: Option<char>) -> bool { return in_range(c, '0', '9'); }\n+\n+pub fn is_line_non_doc_comment(s: &str) -> bool {\n+    s.starts_with(\"////\")\n+}\n+\n+pub fn is_block_non_doc_comment(s: &str) -> bool {\n+    s.starts_with(\"/***\")\n+}\n+\n+fn ident_start(c: Option<char>) -> bool {\n+    let c = match c { Some(c) => c, None => return false };\n+\n+    (c >= 'a' && c <= 'z')\n+        || (c >= 'A' && c <= 'Z')\n+        || c == '_'\n+        || (c > '\\x7f' && char::is_XID_start(c))\n+}\n+\n+fn ident_continue(c: Option<char>) -> bool {\n+    let c = match c { Some(c) => c, None => return false };\n+\n+    (c >= 'a' && c <= 'z')\n+        || (c >= 'A' && c <= 'Z')\n+        || (c >= '0' && c <= '9')\n+        || c == '_'\n+        || (c > '\\x7f' && char::is_XID_continue(c))\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+\n+    use codemap::{BytePos, CodeMap, Span};\n+    use diagnostic;\n+    use parse::token;\n+    use parse::token::{str_to_ident};\n+    use std::io::util;\n+\n+    fn mk_sh() -> diagnostic::SpanHandler {\n+        let emitter = diagnostic::EmitterWriter::new(box util::NullWriter);\n+        let handler = diagnostic::mk_handler(box emitter);\n+        diagnostic::mk_span_handler(handler, CodeMap::new())\n+    }\n+\n+    // open a string reader for the given string\n+    fn setup<'a>(span_handler: &'a diagnostic::SpanHandler,\n+                 teststr: String) -> StringReader<'a> {\n+        let fm = span_handler.cm.new_filemap(\"zebra.rs\".to_string(), teststr);\n+        StringReader::new(span_handler, fm)\n+    }\n+\n+    #[test] fn t1 () {\n+        let span_handler = mk_sh();\n+        let mut string_reader = setup(&span_handler,\n+            \"/* my source file */ \\\n+             fn main() { println!(\\\"zebra\\\"); }\\n\".to_string());\n+        let id = str_to_ident(\"fn\");\n+        let tok1 = string_reader.next_token();\n+        let tok2 = TokenAndSpan{\n+            tok:token::IDENT(id, false),\n+            sp:Span {lo:BytePos(21),hi:BytePos(23),expn_info: None}};\n+        assert_eq!(tok1,tok2);\n+        // the 'main' id is already read:\n+        assert_eq!(string_reader.last_pos.clone(), BytePos(28));\n+        // read another token:\n+        let tok3 = string_reader.next_token();\n+        let tok4 = TokenAndSpan{\n+            tok:token::IDENT(str_to_ident(\"main\"), false),\n+            sp:Span {lo:BytePos(24),hi:BytePos(28),expn_info: None}};\n+        assert_eq!(tok3,tok4);\n+        // the lparen is already read:\n+        assert_eq!(string_reader.last_pos.clone(), BytePos(29))\n+    }\n+\n+    // check that the given reader produces the desired stream\n+    // of tokens (stop checking after exhausting the expected vec)\n+    fn check_tokenization (mut string_reader: StringReader, expected: Vec<token::Token> ) {\n+        for expected_tok in expected.iter() {\n+            assert_eq!(&string_reader.next_token().tok, expected_tok);\n+        }\n+    }\n+\n+    // make the identifier by looking up the string in the interner\n+    fn mk_ident (id: &str, is_mod_name: bool) -> token::Token {\n+        token::IDENT (str_to_ident(id),is_mod_name)\n+    }\n+\n+    #[test] fn doublecolonparsing () {\n+        check_tokenization(setup(&mk_sh(), \"a b\".to_string()),\n+                           vec!(mk_ident(\"a\",false),\n+                             mk_ident(\"b\",false)));\n+    }\n+\n+    #[test] fn dcparsing_2 () {\n+        check_tokenization(setup(&mk_sh(), \"a::b\".to_string()),\n+                           vec!(mk_ident(\"a\",true),\n+                             token::MOD_SEP,\n+                             mk_ident(\"b\",false)));\n+    }\n+\n+    #[test] fn dcparsing_3 () {\n+        check_tokenization(setup(&mk_sh(), \"a ::b\".to_string()),\n+                           vec!(mk_ident(\"a\",false),\n+                             token::MOD_SEP,\n+                             mk_ident(\"b\",false)));\n+    }\n+\n+    #[test] fn dcparsing_4 () {\n+        check_tokenization(setup(&mk_sh(), \"a:: b\".to_string()),\n+                           vec!(mk_ident(\"a\",true),\n+                             token::MOD_SEP,\n+                             mk_ident(\"b\",false)));\n+    }\n+\n+    #[test] fn character_a() {\n+        assert_eq!(setup(&mk_sh(), \"'a'\".to_string()).next_token().tok,\n+                   token::LIT_CHAR('a'));\n+    }\n+\n+    #[test] fn character_space() {\n+        assert_eq!(setup(&mk_sh(), \"' '\".to_string()).next_token().tok,\n+                   token::LIT_CHAR(' '));\n+    }\n+\n+    #[test] fn character_escaped() {\n+        assert_eq!(setup(&mk_sh(), \"'\\\\n'\".to_string()).next_token().tok,\n+                   token::LIT_CHAR('\\n'));\n+    }\n+\n+    #[test] fn lifetime_name() {\n+        assert_eq!(setup(&mk_sh(), \"'abc\".to_string()).next_token().tok,\n+                   token::LIFETIME(token::str_to_ident(\"abc\")));\n+    }\n+\n+    #[test] fn raw_string() {\n+        assert_eq!(setup(&mk_sh(),\n+                         \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token()\n+                                                                 .tok,\n+                   token::LIT_STR_RAW(token::str_to_ident(\"\\\"#a\\\\b\\x00c\\\"\"), 3));\n+    }\n+\n+    #[test] fn line_doc_comments() {\n+        assert!(!is_line_non_doc_comment(\"///\"));\n+        assert!(!is_line_non_doc_comment(\"/// blah\"));\n+        assert!(is_line_non_doc_comment(\"////\"));\n+    }\n+\n+    #[test] fn nested_block_comments() {\n+        assert_eq!(setup(&mk_sh(),\n+                         \"/* /* */ */'a'\".to_string()).next_token().tok,\n+                   token::LIT_CHAR('a'));\n+    }\n+\n+}"}, {"sha": "2231b7a78e1c9f61bc7d6581d1dac5de180224da", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -25,7 +25,6 @@ use std::str;\n pub mod lexer;\n pub mod parser;\n pub mod token;\n-pub mod comments;\n pub mod attr;\n \n pub mod common;\n@@ -255,7 +254,7 @@ pub fn filemap_to_tts(sess: &ParseSess, filemap: Rc<FileMap>)\n     // it appears to me that the cfg doesn't matter here... indeed,\n     // parsing tt's probably shouldn't require a parser at all.\n     let cfg = Vec::new();\n-    let srdr = lexer::new_string_reader(&sess.span_diagnostic, filemap);\n+    let srdr = lexer::StringReader::new(&sess.span_diagnostic, filemap);\n     let mut p1 = Parser::new(sess, cfg, box srdr);\n     p1.parse_all_token_trees()\n }"}, {"sha": "42319eeb371d6f66751979de099826282797786e", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -166,7 +166,7 @@ pub fn to_str(t: &Token) -> String {\n       ANDAND => \"&&\".to_string(),\n       BINOP(op) => binop_to_str(op).to_string(),\n       BINOPEQ(op) => {\n-          let mut s = binop_to_str(op).to_strbuf();\n+          let mut s = binop_to_str(op).to_string();\n           s.push_str(\"=\");\n           s\n       }"}, {"sha": "440070e70a6bb24b3bf9ee745479ce8d15d4dbb5", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=46d1af28b5ce4f626be1eb33cb9751cb9cbb1fe9", "patch": "@@ -20,7 +20,8 @@ use codemap;\n use diagnostic;\n use parse::classify::expr_is_simple_block;\n use parse::token::IdentInterner;\n-use parse::{comments, token};\n+use parse::token;\n+use parse::lexer::comments;\n use parse;\n use print::pp::{break_offset, word, space, zerobreak, hardbreak};\n use print::pp::{Breaks, Consistent, Inconsistent, eof};"}]}