{"sha": "bd913270794798eacd162596fc63473d710f2b65", "node_id": "C_kwDOAAsO6NoAKGJkOTEzMjcwNzk0Nzk4ZWFjZDE2MjU5NmZjNjM0NzNkNzEwZjJiNjU", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-01-05T20:12:36Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-01-05T20:44:56Z"}, "message": "fix: Fix completions not considering ancestor items for attribute search", "tree": {"sha": "b1ec95d2ef2ea47a88ddeddd115ddcc097130c63", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b1ec95d2ef2ea47a88ddeddd115ddcc097130c63"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bd913270794798eacd162596fc63473d710f2b65", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bd913270794798eacd162596fc63473d710f2b65", "html_url": "https://github.com/rust-lang/rust/commit/bd913270794798eacd162596fc63473d710f2b65", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bd913270794798eacd162596fc63473d710f2b65/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "68bc12c3b80b0dce655c8602e683b1989640f00b", "url": "https://api.github.com/repos/rust-lang/rust/commits/68bc12c3b80b0dce655c8602e683b1989640f00b", "html_url": "https://github.com/rust-lang/rust/commit/68bc12c3b80b0dce655c8602e683b1989640f00b"}], "stats": {"total": 67, "additions": 40, "deletions": 27}, "files": [{"sha": "2374d689cbb5582077a2e4c9cdd192ed605ef26a", "filename": "crates/ide_completion/src/context.rs", "status": "modified", "additions": 40, "deletions": 27, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/bd913270794798eacd162596fc63473d710f2b65/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bd913270794798eacd162596fc63473d710f2b65/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcontext.rs?ref=bd913270794798eacd162596fc63473d710f2b65", "patch": "@@ -1,5 +1,7 @@\n //! See `CompletionContext` structure.\n \n+use std::iter;\n+\n use base_db::SourceDatabaseExt;\n use hir::{Local, Name, ScopeDef, Semantics, SemanticsScope, Type, TypeInfo};\n use ide_db::{\n@@ -431,12 +433,17 @@ impl<'a> CompletionContext<'a> {\n         mut fake_ident_token: SyntaxToken,\n     ) {\n         let _p = profile::span(\"CompletionContext::expand_and_fill\");\n-        loop {\n-            // Expand attributes\n-            if let (Some(actual_item), Some(item_with_fake_ident)) = (\n-                find_node_at_offset::<ast::Item>(&original_file, offset),\n-                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n-            ) {\n+        'expansion: loop {\n+            let parent_item =\n+                |item: &ast::Item| item.syntax().ancestors().skip(1).find_map(ast::Item::cast);\n+            let ancestor_items = iter::successors(\n+                Option::zip(\n+                    find_node_at_offset::<ast::Item>(&original_file, offset),\n+                    find_node_at_offset::<ast::Item>(&speculative_file, offset),\n+                ),\n+                |(a, b)| parent_item(a).zip(parent_item(b)),\n+            );\n+            for (actual_item, item_with_fake_ident) in ancestor_items {\n                 match (\n                     self.sema.expand_attr_macro(&actual_item),\n                     self.sema.speculative_expand_attr_macro(\n@@ -445,19 +452,22 @@ impl<'a> CompletionContext<'a> {\n                         fake_ident_token.clone(),\n                     ),\n                 ) {\n-                    (Some(actual_expansion), Some(speculative_expansion)) => {\n-                        let new_offset = speculative_expansion.1.text_range().start();\n+                    // maybe parent items have attributes\n+                    (None, None) => (),\n+                    // successful expansions\n+                    (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n+                        let new_offset = fake_mapped_token.text_range().start();\n                         if new_offset > actual_expansion.text_range().end() {\n-                            break;\n+                            break 'expansion;\n                         }\n                         original_file = actual_expansion;\n-                        speculative_file = speculative_expansion.0;\n-                        fake_ident_token = speculative_expansion.1;\n+                        speculative_file = fake_expansion;\n+                        fake_ident_token = fake_mapped_token;\n                         offset = new_offset;\n-                        continue;\n+                        continue 'expansion;\n                     }\n-                    (None, None) => (),\n-                    _ => break,\n+                    // exactly one expansion failed, inconsistent state so stop expanding completely\n+                    _ => break 'expansion,\n                 }\n             }\n \n@@ -477,28 +487,31 @@ impl<'a> CompletionContext<'a> {\n                     None => break,\n                 };\n \n-                if let (Some(actual_expansion), Some(speculative_expansion)) = (\n+                match (\n                     self.sema.expand(&actual_macro_call),\n                     self.sema.speculative_expand(\n                         &actual_macro_call,\n                         &speculative_args,\n-                        fake_ident_token,\n+                        fake_ident_token.clone(),\n                     ),\n                 ) {\n-                    let new_offset = speculative_expansion.1.text_range().start();\n-                    if new_offset > actual_expansion.text_range().end() {\n-                        break;\n+                    // successful expansions\n+                    (Some(actual_expansion), Some((fake_expansion, fake_mapped_token))) => {\n+                        let new_offset = fake_mapped_token.text_range().start();\n+                        if new_offset > actual_expansion.text_range().end() {\n+                            break;\n+                        }\n+                        original_file = actual_expansion;\n+                        speculative_file = fake_expansion;\n+                        fake_ident_token = fake_mapped_token;\n+                        offset = new_offset;\n+                        continue;\n                     }\n-                    original_file = actual_expansion;\n-                    speculative_file = speculative_expansion.0;\n-                    fake_ident_token = speculative_expansion.1;\n-                    offset = new_offset;\n-                } else {\n-                    break;\n+                    _ => break,\n                 }\n-            } else {\n-                break;\n             }\n+\n+            break;\n         }\n \n         self.fill(&original_file, speculative_file, offset);"}]}