{"sha": "466d3e702a0626305f32b3230b206f4f2b650bfc", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ2NmQzZTcwMmEwNjI2MzA1ZjMyYjMyMzBiMjA2ZjRmMmI2NTBiZmM=", "commit": {"author": {"name": "Dylan DPC", "email": "dylan.dpc@gmail.com", "date": "2020-06-02T16:29:57Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-06-02T16:29:57Z"}, "message": "Rollup merge of #72884 - Julian-Wollersberger:raw_str_error_cleanup, r=petrochenkov\n\nRawString error reporting cleanup\n\nI simplified how errors with raw string are represented in the lexer and reportet in the parser, by using one enum instead of two structs with impls. This makes 70 code lines obsolete.\n\nI also noticed some other things (2nd commit) and added a missing test for the `too many '#' symbols' error.\n\nMy original intent was to improve performance, but the only thing I found was to inline some functions in `cursor.rs`. It's effect is barely measurable, though.\n\nThere is one open question. Before, the compiler aborts when encountering the `too many '#' symbols` error. Now the lexer says in this case that there are 0 hashes, and then later the parser aborts on the error.\nI'm worrying that the parser may be changed to recover and continue, and then later stages will see the wrong numer of hashes and act strange. (eg. the `format!` macro expansion).\nIs that possibility important enough today to worry about it?", "tree": {"sha": "e06987596754c4b63d9714aad2b996167768cdf8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e06987596754c4b63d9714aad2b996167768cdf8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/466d3e702a0626305f32b3230b206f4f2b650bfc", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe1n6FCRBK7hj4Ov3rIwAAdHIIACKbjDbmaWiW3B6VUTUQeFd6\nYKcKMfYWYucdqmOYXa2lu/Ml40wCTed/6a3AXl6oJggWEzvX1DgtSthTCMkFM0tW\n1UzGJ0MQ9V+F7H0XVbOZSdx0qL3XGjNNEfxoSHVjBuzTlBcMprzeKXbxoYJQBCmx\nChwc8i1/IcQIuXUptk5g6fFrqNGWyNQyoIswM5QnHBKCUpBMMbs8FmymNeQ93m3j\noXAwa8il/iWEYXYgSrwKVFAZMsOCY9W3gAFvm0h+szZD+9NZmReEVlDxispCe5L1\nymxP0BL0dy6AzlmLBCC8sjt/NFxTbrzAD3x37X+G0LNy3TaHCvj196lwyu21S4w=\n=49y6\n-----END PGP SIGNATURE-----\n", "payload": "tree e06987596754c4b63d9714aad2b996167768cdf8\nparent eeaf497b2a6bc065874e3d3367b1f3023c5bb3d3\nparent 7be8077b3fe7565573001b602f8709467da903e7\nauthor Dylan DPC <dylan.dpc@gmail.com> 1591115397 +0200\ncommitter GitHub <noreply@github.com> 1591115397 +0200\n\nRollup merge of #72884 - Julian-Wollersberger:raw_str_error_cleanup, r=petrochenkov\n\nRawString error reporting cleanup\n\nI simplified how errors with raw string are represented in the lexer and reportet in the parser, by using one enum instead of two structs with impls. This makes 70 code lines obsolete.\n\nI also noticed some other things (2nd commit) and added a missing test for the `too many '#' symbols' error.\n\nMy original intent was to improve performance, but the only thing I found was to inline some functions in `cursor.rs`. It's effect is barely measurable, though.\n\nThere is one open question. Before, the compiler aborts when encountering the `too many '#' symbols` error. Now the lexer says in this case that there are 0 hashes, and then later the parser aborts on the error.\nI'm worrying that the parser may be changed to recover and continue, and then later stages will see the wrong numer of hashes and act strange. (eg. the `format!` macro expansion).\nIs that possibility important enough today to worry about it?\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/466d3e702a0626305f32b3230b206f4f2b650bfc", "html_url": "https://github.com/rust-lang/rust/commit/466d3e702a0626305f32b3230b206f4f2b650bfc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/466d3e702a0626305f32b3230b206f4f2b650bfc/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "eeaf497b2a6bc065874e3d3367b1f3023c5bb3d3", "url": "https://api.github.com/repos/rust-lang/rust/commits/eeaf497b2a6bc065874e3d3367b1f3023c5bb3d3", "html_url": "https://github.com/rust-lang/rust/commit/eeaf497b2a6bc065874e3d3367b1f3023c5bb3d3"}, {"sha": "7be8077b3fe7565573001b602f8709467da903e7", "url": "https://api.github.com/repos/rust-lang/rust/commits/7be8077b3fe7565573001b602f8709467da903e7", "html_url": "https://github.com/rust-lang/rust/commit/7be8077b3fe7565573001b602f8709467da903e7"}], "stats": {"total": 330, "additions": 90, "deletions": 240}, "files": [{"sha": "cf90c6d838635b12c85465930e371c5419668ba7", "filename": "src/librustc_lexer/src/lib.rs", "status": "modified", "additions": 45, "deletions": 105, "changes": 150, "blob_url": "https://github.com/rust-lang/rust/blob/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_lexer%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Flib.rs?ref=466d3e702a0626305f32b3230b206f4f2b650bfc", "patch": "@@ -29,7 +29,7 @@ mod tests;\n use self::LiteralKind::*;\n use self::TokenKind::*;\n use crate::cursor::{Cursor, EOF_CHAR};\n-use std::convert::TryInto;\n+use std::convert::TryFrom;\n \n /// Parsed token.\n /// It doesn't contain information about data that has been parsed,\n@@ -142,84 +142,24 @@ pub enum LiteralKind {\n     /// \"b\"abc\"\", \"b\"abc\"\n     ByteStr { terminated: bool },\n     /// \"r\"abc\"\", \"r#\"abc\"#\", \"r####\"ab\"###\"c\"####\", \"r#\"a\"\n-    RawStr(UnvalidatedRawStr),\n+    RawStr { n_hashes: u16, err: Option<RawStrError> },\n     /// \"br\"abc\"\", \"br#\"abc\"#\", \"br####\"ab\"###\"c\"####\", \"br#\"a\"\n-    RawByteStr(UnvalidatedRawStr),\n-}\n-\n-/// Represents something that looks like a raw string, but may have some\n-/// problems. Use `.validate()` to convert it into something\n-/// usable.\n-#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n-pub struct UnvalidatedRawStr {\n-    /// The prefix (`r###\"`) is valid\n-    valid_start: bool,\n-\n-    /// The postfix (`\"###`) is valid\n-    valid_end: bool,\n-\n-    /// The number of leading `#`\n-    n_start_hashes: usize,\n-    /// The number of trailing `#`. `n_end_hashes` <= `n_start_hashes`\n-    n_end_hashes: usize,\n-    /// The offset starting at `r` or `br` where the user may have intended to end the string.\n-    /// Currently, it is the longest sequence of pattern `\"#+\"`.\n-    possible_terminator_offset: Option<usize>,\n+    RawByteStr { n_hashes: u16, err: Option<RawStrError> },\n }\n \n /// Error produced validating a raw string. Represents cases like:\n-/// - `r##~\"abcde\"##`: `LexRawStrError::InvalidStarter`\n-/// - `r###\"abcde\"##`: `LexRawStrError::NoTerminator { expected: 3, found: 2, possible_terminator_offset: Some(11)`\n-/// - Too many `#`s (>65536): `TooManyDelimiters`\n+/// - `r##~\"abcde\"##`: `InvalidStarter`\n+/// - `r###\"abcde\"##`: `NoTerminator { expected: 3, found: 2, possible_terminator_offset: Some(11)`\n+/// - Too many `#`s (>65535): `TooManyDelimiters`\n #[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]\n-pub enum LexRawStrError {\n+pub enum RawStrError {\n     /// Non `#` characters exist between `r` and `\"` eg. `r#~\"..`\n-    InvalidStarter,\n+    InvalidStarter { bad_char: char },\n     /// The string was never terminated. `possible_terminator_offset` is the number of characters after `r` or `br` where they\n     /// may have intended to terminate it.\n     NoTerminator { expected: usize, found: usize, possible_terminator_offset: Option<usize> },\n-    /// More than 65536 `#`s exist.\n-    TooManyDelimiters,\n-}\n-\n-/// Raw String that contains a valid prefix (`#+\"`) and postfix (`\"#+`) where\n-/// there are a matching number of `#` characters in both. Note that this will\n-/// not consume extra trailing `#` characters: `r###\"abcde\"####` is lexed as a\n-/// `ValidatedRawString { n_hashes: 3 }` followed by a `#` token.\n-#[derive(Debug, Eq, PartialEq, Copy, Clone)]\n-pub struct ValidatedRawStr {\n-    n_hashes: u16,\n-}\n-\n-impl ValidatedRawStr {\n-    pub fn num_hashes(&self) -> u16 {\n-        self.n_hashes\n-    }\n-}\n-\n-impl UnvalidatedRawStr {\n-    pub fn validate(self) -> Result<ValidatedRawStr, LexRawStrError> {\n-        if !self.valid_start {\n-            return Err(LexRawStrError::InvalidStarter);\n-        }\n-\n-        // Only up to 65535 `#`s are allowed in raw strings\n-        let n_start_safe: u16 =\n-            self.n_start_hashes.try_into().map_err(|_| LexRawStrError::TooManyDelimiters)?;\n-\n-        if self.n_start_hashes > self.n_end_hashes || !self.valid_end {\n-            Err(LexRawStrError::NoTerminator {\n-                expected: self.n_start_hashes,\n-                found: self.n_end_hashes,\n-                possible_terminator_offset: self.possible_terminator_offset,\n-            })\n-        } else {\n-            // Since the lexer should never produce a literal with n_end > n_start, if n_start <= n_end,\n-            // they must be equal.\n-            debug_assert_eq!(self.n_start_hashes, self.n_end_hashes);\n-            Ok(ValidatedRawStr { n_hashes: n_start_safe })\n-        }\n-    }\n+    /// More than 65535 `#`s exist.\n+    TooManyDelimiters { found: usize },\n }\n \n /// Base of numeric literal encoding according to its prefix.\n@@ -354,12 +294,12 @@ impl Cursor<'_> {\n             'r' => match (self.first(), self.second()) {\n                 ('#', c1) if is_id_start(c1) => self.raw_ident(),\n                 ('#', _) | ('\"', _) => {\n-                    let raw_str_i = self.raw_double_quoted_string(1);\n+                    let (n_hashes, err) = self.raw_double_quoted_string(1);\n                     let suffix_start = self.len_consumed();\n-                    if raw_str_i.n_end_hashes == raw_str_i.n_start_hashes {\n+                    if err.is_none() {\n                         self.eat_literal_suffix();\n                     }\n-                    let kind = RawStr(raw_str_i);\n+                    let kind = RawStr { n_hashes, err };\n                     Literal { kind, suffix_start }\n                 }\n                 _ => self.ident(),\n@@ -389,14 +329,12 @@ impl Cursor<'_> {\n                 }\n                 ('r', '\"') | ('r', '#') => {\n                     self.bump();\n-                    let raw_str_i = self.raw_double_quoted_string(2);\n+                    let (n_hashes, err) = self.raw_double_quoted_string(2);\n                     let suffix_start = self.len_consumed();\n-                    let terminated = raw_str_i.n_start_hashes == raw_str_i.n_end_hashes;\n-                    if terminated {\n+                    if err.is_none() {\n                         self.eat_literal_suffix();\n                     }\n-\n-                    let kind = RawByteStr(raw_str_i);\n+                    let kind = RawByteStr { n_hashes, err };\n                     Literal { kind, suffix_start }\n                 }\n                 _ => self.ident(),\n@@ -692,27 +630,34 @@ impl Cursor<'_> {\n         false\n     }\n \n-    /// Eats the double-quoted string and returns an `UnvalidatedRawStr`.\n-    fn raw_double_quoted_string(&mut self, prefix_len: usize) -> UnvalidatedRawStr {\n+    /// Eats the double-quoted string and returns `n_hashes` and an error if encountered.\n+    fn raw_double_quoted_string(&mut self, prefix_len: usize) -> (u16, Option<RawStrError>) {\n+        // Wrap the actual function to handle the error with too many hashes.\n+        // This way, it eats the whole raw string.\n+        let (n_hashes, err) = self.raw_string_unvalidated(prefix_len);\n+        // Only up to 65535 `#`s are allowed in raw strings\n+        match u16::try_from(n_hashes) {\n+            Ok(num) => (num, err),\n+            // We lie about the number of hashes here :P\n+            Err(_) => (0, Some(RawStrError::TooManyDelimiters { found: n_hashes })),\n+        }\n+    }\n+\n+    fn raw_string_unvalidated(&mut self, prefix_len: usize) -> (usize, Option<RawStrError>) {\n         debug_assert!(self.prev() == 'r');\n-        let mut valid_start: bool = false;\n         let start_pos = self.len_consumed();\n-        let (mut possible_terminator_offset, mut max_hashes) = (None, 0);\n+        let mut possible_terminator_offset = None;\n+        let mut max_hashes = 0;\n \n         // Count opening '#' symbols.\n         let n_start_hashes = self.eat_while(|c| c == '#');\n \n         // Check that string is started.\n         match self.bump() {\n-            Some('\"') => valid_start = true,\n-            _ => {\n-                return UnvalidatedRawStr {\n-                    valid_start,\n-                    valid_end: false,\n-                    n_start_hashes,\n-                    n_end_hashes: 0,\n-                    possible_terminator_offset,\n-                };\n+            Some('\"') => (),\n+            c => {\n+                let c = c.unwrap_or(EOF_CHAR);\n+                return (n_start_hashes, Some(RawStrError::InvalidStarter { bad_char: c }));\n             }\n         }\n \n@@ -722,13 +667,14 @@ impl Cursor<'_> {\n             self.eat_while(|c| c != '\"');\n \n             if self.is_eof() {\n-                return UnvalidatedRawStr {\n-                    valid_start,\n-                    valid_end: false,\n+                return (\n                     n_start_hashes,\n-                    n_end_hashes: max_hashes,\n-                    possible_terminator_offset,\n-                };\n+                    Some(RawStrError::NoTerminator {\n+                        expected: n_start_hashes,\n+                        found: max_hashes,\n+                        possible_terminator_offset,\n+                    }),\n+                );\n             }\n \n             // Eat closing double quote.\n@@ -737,7 +683,7 @@ impl Cursor<'_> {\n             // Check that amount of closing '#' symbols\n             // is equal to the amount of opening ones.\n             // Note that this will not consume extra trailing `#` characters:\n-            // `r###\"abcde\"####` is lexed as a `LexedRawString { n_hashes: 3 }`\n+            // `r###\"abcde\"####` is lexed as a `RawStr { n_hashes: 3 }`\n             // followed by a `#` token.\n             let mut hashes_left = n_start_hashes;\n             let is_closing_hash = |c| {\n@@ -751,13 +697,7 @@ impl Cursor<'_> {\n             let n_end_hashes = self.eat_while(is_closing_hash);\n \n             if n_end_hashes == n_start_hashes {\n-                return UnvalidatedRawStr {\n-                    valid_start,\n-                    valid_end: true,\n-                    n_start_hashes,\n-                    n_end_hashes,\n-                    possible_terminator_offset: None,\n-                };\n+                return (n_start_hashes, None);\n             } else if n_end_hashes > max_hashes {\n                 // Keep track of possible terminators to give a hint about\n                 // where there might be a missing terminator"}, {"sha": "e6acc26ec2f343e6645755f6032eff88e8e385d3", "filename": "src/librustc_lexer/src/tests.rs", "status": "modified", "additions": 16, "deletions": 84, "changes": 100, "blob_url": "https://github.com/rust-lang/rust/blob/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_lexer%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_lexer%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lexer%2Fsrc%2Ftests.rs?ref=466d3e702a0626305f32b3230b206f4f2b650bfc", "patch": "@@ -2,92 +2,46 @@\n mod tests {\n     use crate::*;\n \n-    fn check_raw_str(\n-        s: &str,\n-        expected: UnvalidatedRawStr,\n-        validated: Result<ValidatedRawStr, LexRawStrError>,\n-    ) {\n+    fn check_raw_str(s: &str, expected_hashes: u16, expected_err: Option<RawStrError>) {\n         let s = &format!(\"r{}\", s);\n         let mut cursor = Cursor::new(s);\n         cursor.bump();\n-        let tok = cursor.raw_double_quoted_string(0);\n-        assert_eq!(tok, expected);\n-        assert_eq!(tok.validate(), validated);\n+        let (n_hashes, err) = cursor.raw_double_quoted_string(0);\n+        assert_eq!(n_hashes, expected_hashes);\n+        assert_eq!(err, expected_err);\n     }\n \n     #[test]\n     fn test_naked_raw_str() {\n-        check_raw_str(\n-            r#\"\"abc\"\"#,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 0,\n-                n_end_hashes: 0,\n-                valid_start: true,\n-                valid_end: true,\n-                possible_terminator_offset: None,\n-            },\n-            Ok(ValidatedRawStr { n_hashes: 0 }),\n-        );\n+        check_raw_str(r#\"\"abc\"\"#, 0, None);\n     }\n \n     #[test]\n     fn test_raw_no_start() {\n-        check_raw_str(\n-            r##\"\"abc\"#\"##,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 0,\n-                n_end_hashes: 0,\n-                valid_start: true,\n-                valid_end: true,\n-                possible_terminator_offset: None,\n-            },\n-            Ok(ValidatedRawStr { n_hashes: 0 }),\n-        );\n+        check_raw_str(r##\"\"abc\"#\"##, 0, None);\n     }\n \n     #[test]\n     fn test_too_many_terminators() {\n         // this error is handled in the parser later\n-        check_raw_str(\n-            r###\"#\"abc\"##\"###,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 1,\n-                n_end_hashes: 1,\n-                valid_end: true,\n-                valid_start: true,\n-                possible_terminator_offset: None,\n-            },\n-            Ok(ValidatedRawStr { n_hashes: 1 }),\n-        );\n+        check_raw_str(r###\"#\"abc\"##\"###, 1, None);\n     }\n \n     #[test]\n     fn test_unterminated() {\n         check_raw_str(\n             r#\"#\"abc\"#,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 1,\n-                n_end_hashes: 0,\n-                valid_end: false,\n-                valid_start: true,\n-                possible_terminator_offset: None,\n-            },\n-            Err(LexRawStrError::NoTerminator {\n+            1,\n+            Some(RawStrError::NoTerminator {\n                 expected: 1,\n                 found: 0,\n                 possible_terminator_offset: None,\n             }),\n         );\n         check_raw_str(\n             r###\"##\"abc\"#\"###,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 2,\n-                n_end_hashes: 1,\n-                valid_start: true,\n-                valid_end: false,\n-                possible_terminator_offset: Some(7),\n-            },\n-            Err(LexRawStrError::NoTerminator {\n+            2,\n+            Some(RawStrError::NoTerminator {\n                 expected: 2,\n                 found: 1,\n                 possible_terminator_offset: Some(7),\n@@ -96,14 +50,8 @@ mod tests {\n         // We're looking for \"# not just any #\n         check_raw_str(\n             r###\"##\"abc#\"###,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 2,\n-                n_end_hashes: 0,\n-                valid_start: true,\n-                valid_end: false,\n-                possible_terminator_offset: None,\n-            },\n-            Err(LexRawStrError::NoTerminator {\n+            2,\n+            Some(RawStrError::NoTerminator {\n                 expected: 2,\n                 found: 0,\n                 possible_terminator_offset: None,\n@@ -113,32 +61,16 @@ mod tests {\n \n     #[test]\n     fn test_invalid_start() {\n-        check_raw_str(\n-            r##\"#~\"abc\"#\"##,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 1,\n-                n_end_hashes: 0,\n-                valid_start: false,\n-                valid_end: false,\n-                possible_terminator_offset: None,\n-            },\n-            Err(LexRawStrError::InvalidStarter),\n-        );\n+        check_raw_str(r##\"#~\"abc\"#\"##, 1, Some(RawStrError::InvalidStarter { bad_char: '~' }));\n     }\n \n     #[test]\n     fn test_unterminated_no_pound() {\n         // https://github.com/rust-lang/rust/issues/70677\n         check_raw_str(\n             r#\"\"\"#,\n-            UnvalidatedRawStr {\n-                n_start_hashes: 0,\n-                n_end_hashes: 0,\n-                valid_start: true,\n-                valid_end: false,\n-                possible_terminator_offset: None,\n-            },\n-            Err(LexRawStrError::NoTerminator {\n+            0,\n+            Some(RawStrError::NoTerminator {\n                 expected: 0,\n                 found: 0,\n                 possible_terminator_offset: None,"}, {"sha": "7e59f06e44ae3ecd43fb3530238210233add403a", "filename": "src/librustc_parse/lexer/mod.rs", "status": "modified", "additions": 29, "deletions": 51, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_parse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/466d3e702a0626305f32b3230b206f4f2b650bfc/src%2Flibrustc_parse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Flexer%2Fmod.rs?ref=466d3e702a0626305f32b3230b206f4f2b650bfc", "patch": "@@ -3,7 +3,7 @@ use rustc_ast::util::comments;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{error_code, Applicability, DiagnosticBuilder, FatalError};\n use rustc_lexer::Base;\n-use rustc_lexer::{unescape, LexRawStrError, UnvalidatedRawStr, ValidatedRawStr};\n+use rustc_lexer::{unescape, RawStrError};\n use rustc_session::parse::ParseSess;\n use rustc_span::symbol::{sym, Symbol};\n use rustc_span::{BytePos, Pos, Span};\n@@ -49,13 +49,12 @@ impl<'a> StringReader<'a> {\n         // Make sure external source is loaded first, before accessing it.\n         // While this can't show up during normal parsing, `retokenize` may\n         // be called with a source file from an external crate.\n-        sess.source_map().ensure_source_file_source_present(source_file.clone());\n+        sess.source_map().ensure_source_file_source_present(Lrc::clone(&source_file));\n \n-        // FIXME(eddyb) use `Lrc<str>` or similar to avoid cloning the `String`.\n         let src = if let Some(src) = &source_file.src {\n-            src.clone()\n+            Lrc::clone(&src)\n         } else if let Some(src) = source_file.external_src.borrow().get_source() {\n-            src.clone()\n+            Lrc::clone(&src)\n         } else {\n             sess.span_diagnostic\n                 .bug(&format!(\"cannot lex `source_file` without source: {}\", source_file.name));\n@@ -125,10 +124,7 @@ impl<'a> StringReader<'a> {\n \n         debug!(\"try_next_token: {:?}({:?})\", token.kind, self.str_from(start));\n \n-        // This could use `?`, but that makes code significantly (10-20%) slower.\n-        // https://github.com/rust-lang/rust/issues/37939\n         let kind = self.cook_lexer_token(token.kind, start);\n-\n         let span = self.mk_sp(start, self.pos);\n         Token::new(kind, span)\n     }\n@@ -153,15 +149,6 @@ impl<'a> StringReader<'a> {\n         self.err_span(self.mk_sp(from_pos, to_pos), m)\n     }\n \n-    fn struct_span_fatal(\n-        &self,\n-        from_pos: BytePos,\n-        to_pos: BytePos,\n-        m: &str,\n-    ) -> DiagnosticBuilder<'a> {\n-        self.sess.span_diagnostic.struct_span_fatal(self.mk_sp(from_pos, to_pos), m)\n-    }\n-\n     fn struct_fatal_span_char(\n         &self,\n         from_pos: BytePos,\n@@ -359,15 +346,13 @@ impl<'a> StringReader<'a> {\n                 }\n                 (token::ByteStr, Mode::ByteStr, 2, 1) // b\" \"\n             }\n-            rustc_lexer::LiteralKind::RawStr(unvalidated_raw_str) => {\n-                let valid_raw_str = self.validate_and_report_errors(start, unvalidated_raw_str);\n-                let n_hashes = valid_raw_str.num_hashes();\n+            rustc_lexer::LiteralKind::RawStr { n_hashes, err } => {\n+                self.report_raw_str_error(start, err);\n                 let n = u32::from(n_hashes);\n                 (token::StrRaw(n_hashes), Mode::RawStr, 2 + n, 1 + n) // r##\" \"##\n             }\n-            rustc_lexer::LiteralKind::RawByteStr(unvalidated_raw_str) => {\n-                let validated_raw_str = self.validate_and_report_errors(start, unvalidated_raw_str);\n-                let n_hashes = validated_raw_str.num_hashes();\n+            rustc_lexer::LiteralKind::RawByteStr { n_hashes, err } => {\n+                self.report_raw_str_error(start, err);\n                 let n = u32::from(n_hashes);\n                 (token::ByteStrRaw(n_hashes), Mode::RawByteStr, 3 + n, 1 + n) // br##\" \"##\n             }\n@@ -382,12 +367,7 @@ impl<'a> StringReader<'a> {\n             }\n             rustc_lexer::LiteralKind::Float { base, empty_exponent } => {\n                 if empty_exponent {\n-                    let mut err = self.struct_span_fatal(\n-                        start,\n-                        self.pos,\n-                        \"expected at least one digit in exponent\",\n-                    );\n-                    err.emit();\n+                    self.err_span_(start, self.pos, \"expected at least one digit in exponent\");\n                 }\n \n                 match base {\n@@ -459,33 +439,25 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    fn validate_and_report_errors(\n-        &self,\n-        start: BytePos,\n-        unvalidated_raw_str: UnvalidatedRawStr,\n-    ) -> ValidatedRawStr {\n-        match unvalidated_raw_str.validate() {\n-            Err(LexRawStrError::InvalidStarter) => self.report_non_started_raw_string(start),\n-            Err(LexRawStrError::NoTerminator { expected, found, possible_terminator_offset }) => {\n-                self.report_unterminated_raw_string(\n-                    start,\n-                    expected,\n-                    possible_terminator_offset,\n-                    found,\n-                )\n+    fn report_raw_str_error(&self, start: BytePos, opt_err: Option<RawStrError>) {\n+        match opt_err {\n+            Some(RawStrError::InvalidStarter { bad_char }) => {\n+                self.report_non_started_raw_string(start, bad_char)\n+            }\n+            Some(RawStrError::NoTerminator { expected, found, possible_terminator_offset }) => self\n+                .report_unterminated_raw_string(start, expected, possible_terminator_offset, found),\n+            Some(RawStrError::TooManyDelimiters { found }) => {\n+                self.report_too_many_hashes(start, found)\n             }\n-            Err(LexRawStrError::TooManyDelimiters) => self.report_too_many_hashes(start),\n-            Ok(valid) => valid,\n+            None => (),\n         }\n     }\n \n-    fn report_non_started_raw_string(&self, start: BytePos) -> ! {\n-        let bad_char = self.str_from(start).chars().last().unwrap();\n+    fn report_non_started_raw_string(&self, start: BytePos, bad_char: char) -> ! {\n         self.struct_fatal_span_char(\n             start,\n             self.pos,\n-            \"found invalid character; only `#` is allowed \\\n-                 in raw string delimitation\",\n+            \"found invalid character; only `#` is allowed in raw string delimitation\",\n             bad_char,\n         )\n         .emit();\n@@ -530,11 +502,17 @@ impl<'a> StringReader<'a> {\n         FatalError.raise()\n     }\n \n-    fn report_too_many_hashes(&self, start: BytePos) -> ! {\n+    /// Note: It was decided to not add a test case, because it would be to big.\n+    /// https://github.com/rust-lang/rust/pull/50296#issuecomment-392135180\n+    fn report_too_many_hashes(&self, start: BytePos, found: usize) -> ! {\n         self.fatal_span_(\n             start,\n             self.pos,\n-            \"too many `#` symbols: raw strings may be delimited by up to 65535 `#` symbols\",\n+            &format!(\n+                \"too many `#` symbols: raw strings may be delimited \\\n+                by up to 65535 `#` symbols, but found {}\",\n+                found\n+            ),\n         )\n         .raise();\n     }"}]}