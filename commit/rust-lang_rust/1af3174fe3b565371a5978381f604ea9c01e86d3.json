{"sha": "1af3174fe3b565371a5978381f604ea9c01e86d3", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFhZjMxNzRmZTNiNTY1MzcxYTU5NzgzODFmNjA0ZWE5YzAxZTg2ZDM=", "commit": {"author": {"name": "Marijn Haverbeke", "email": "marijnh@gmail.com", "date": "2011-04-08T16:44:20Z"}, "committer": {"name": "Marijn Haverbeke", "email": "marijnh@gmail.com", "date": "2011-04-08T23:05:18Z"}, "message": "Move to single-uint file-position representation.\n\nThis makes passing them around cheaper. There is now a table (see\nfront/codemap.rs) that is needed to transform such an uint into an\nactual filename/line/col location.\n\nAlso cleans up the span building in the parser a bit.", "tree": {"sha": "1690b133b0690fdf6a2c005528355c2d00313129", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1690b133b0690fdf6a2c005528355c2d00313129"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1af3174fe3b565371a5978381f604ea9c01e86d3", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1af3174fe3b565371a5978381f604ea9c01e86d3", "html_url": "https://github.com/rust-lang/rust/commit/1af3174fe3b565371a5978381f604ea9c01e86d3", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1af3174fe3b565371a5978381f604ea9c01e86d3/comments", "author": {"login": "marijnh", "id": 144427, "node_id": "MDQ6VXNlcjE0NDQyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/144427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marijnh", "html_url": "https://github.com/marijnh", "followers_url": "https://api.github.com/users/marijnh/followers", "following_url": "https://api.github.com/users/marijnh/following{/other_user}", "gists_url": "https://api.github.com/users/marijnh/gists{/gist_id}", "starred_url": "https://api.github.com/users/marijnh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marijnh/subscriptions", "organizations_url": "https://api.github.com/users/marijnh/orgs", "repos_url": "https://api.github.com/users/marijnh/repos", "events_url": "https://api.github.com/users/marijnh/events{/privacy}", "received_events_url": "https://api.github.com/users/marijnh/received_events", "type": "User", "site_admin": false}, "committer": {"login": "marijnh", "id": 144427, "node_id": "MDQ6VXNlcjE0NDQyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/144427?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marijnh", "html_url": "https://github.com/marijnh", "followers_url": "https://api.github.com/users/marijnh/followers", "following_url": "https://api.github.com/users/marijnh/following{/other_user}", "gists_url": "https://api.github.com/users/marijnh/gists{/gist_id}", "starred_url": "https://api.github.com/users/marijnh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marijnh/subscriptions", "organizations_url": "https://api.github.com/users/marijnh/orgs", "repos_url": "https://api.github.com/users/marijnh/repos", "events_url": "https://api.github.com/users/marijnh/events{/privacy}", "received_events_url": "https://api.github.com/users/marijnh/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "094d31f5e40d086a3f1aeb4ff7ea93f59a755d4e", "url": "https://api.github.com/repos/rust-lang/rust/commits/094d31f5e40d086a3f1aeb4ff7ea93f59a755d4e", "html_url": "https://github.com/rust-lang/rust/commit/094d31f5e40d086a3f1aeb4ff7ea93f59a755d4e"}], "stats": {"total": 764, "additions": 413, "deletions": 351}, "files": [{"sha": "c2f633685a763712420f2b63ce6ca0c8ebf20dcc", "filename": "src/comp/driver/rustc.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fdriver%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fdriver%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fdriver%2Frustc.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -62,7 +62,7 @@ impure fn compile_input(session.session sess,\n                         bool parse_only,\n                         vec[str] library_search_paths) {\n     auto def = tup(0, 0);\n-    auto p = parser.new_parser(sess, env, def, input);\n+    auto p = parser.new_parser(sess, env, def, input, 0u);\n     auto crate = parse_input(sess, p, input);\n     if (parse_only) {ret;}\n     crate = creader.read_crates(sess, crate, library_search_paths);\n@@ -79,7 +79,7 @@ impure fn pretty_print_input(session.session sess,\n                              eval.env env,\n                              str input) {\n     auto def = tup(0, 0);\n-    auto p = front.parser.new_parser(sess, env, def, input);\n+    auto p = front.parser.new_parser(sess, env, def, input, 0u);\n     auto crate = front.parser.parse_crate_from_source_file(p);\n     pretty.pprust.print_file(crate.node.module, input, std.io.stdout());\n }\n@@ -125,7 +125,8 @@ impure fn main(vec[str] args) {\n \n     auto crate_cache = common.new_int_hash[session.crate_metadata]();\n     auto target_crate_num = 0;\n-    auto sess = session.session(target_crate_num, target_cfg, crate_cache);\n+    auto sess = session.session(target_crate_num, target_cfg, crate_cache,\n+                                front.codemap.new_codemap());\n \n     let option.t[str] input_file = none[str];\n     let option.t[str] output_file = none[str];"}, {"sha": "dab02fbd6272a5f6e53e5d6543eefd3af219ceab", "filename": "src/comp/driver/session.rs", "status": "modified", "additions": 26, "deletions": 10, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fdriver%2Fsession.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fdriver%2Fsession.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fdriver%2Fsession.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -1,4 +1,5 @@\n import front.ast;\n+import front.codemap;\n import util.common.span;\n import util.common.ty_mach;\n import std._uint;\n@@ -25,7 +26,8 @@ type cfg = rec(os os,\n type crate_metadata = vec[u8];\n \n obj session(ast.crate_num cnum, cfg targ,\n-            map.hashmap[int, crate_metadata] crates) {\n+            map.hashmap[int, crate_metadata] crates,\n+            codemap.codemap cm) {\n \n     fn get_targ_cfg() -> cfg {\n         ret targ;\n@@ -36,10 +38,12 @@ obj session(ast.crate_num cnum, cfg targ,\n     }\n \n     fn span_err(span sp, str msg) {\n+        auto lo = codemap.lookup_pos(cm, sp.lo);\n+        auto hi = codemap.lookup_pos(cm, sp.hi);\n         log #fmt(\"%s:%u:%u:%u:%u: error: %s\",\n-                 sp.filename,\n-                 sp.lo.line, sp.lo.col,\n-                 sp.hi.line, sp.hi.col,\n+                 lo.filename,\n+                 lo.line, lo.col,\n+                 hi.line, hi.col,\n                  msg);\n         fail;\n     }\n@@ -50,10 +54,12 @@ obj session(ast.crate_num cnum, cfg targ,\n     }\n \n     fn span_warn(span sp, str msg) {\n+        auto lo = codemap.lookup_pos(cm, sp.lo);\n+        auto hi = codemap.lookup_pos(cm, sp.hi);\n         log #fmt(\"%s:%u:%u:%u:%u: warning: %s\",\n-                 sp.filename,\n-                 sp.lo.line, sp.lo.col,\n-                 sp.hi.line, sp.hi.col,\n+                 lo.filename,\n+                 lo.line, lo.col,\n+                 hi.line, hi.col,\n                  msg);\n     }\n \n@@ -63,10 +69,12 @@ obj session(ast.crate_num cnum, cfg targ,\n     }\n \n     fn span_unimpl(span sp, str msg) {\n+        auto lo = codemap.lookup_pos(cm, sp.lo);\n+        auto hi = codemap.lookup_pos(cm, sp.hi);\n         log #fmt(\"%s:%u:%u:%u:%u: error: unimplemented %s\",\n-                 sp.filename,\n-                 sp.lo.line, sp.lo.col,\n-                 sp.hi.line, sp.hi.col,\n+                 lo.filename,\n+                 lo.line, lo.col,\n+                 hi.line, hi.col,\n                  msg);\n         fail;\n     }\n@@ -87,6 +95,14 @@ obj session(ast.crate_num cnum, cfg targ,\n     fn has_external_crate(int num) -> bool {\n         ret crates.contains_key(num);\n     }\n+\n+    fn get_codemap() -> codemap.codemap {\n+        ret cm;\n+    }\n+\n+    fn lookup_pos(uint pos) -> codemap.loc {\n+        ret codemap.lookup_pos(cm, pos);\n+    }\n }\n \n "}, {"sha": "20b4e2eec3218c5192801f46ab4261ee34da6f25", "filename": "src/comp/front/codemap.rs", "status": "added", "additions": 65, "deletions": 0, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fcodemap.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -0,0 +1,65 @@\n+import std._vec;\n+\n+/* A codemap is a thing that maps uints to file/line/column positions\n+ * in a crate. This to make it possible to represent the positions\n+ * with single-word things, rather than passing records all over the\n+ * compiler.\n+ */\n+\n+type filemap = @rec(str name,\n+                    uint start_pos,\n+                    mutable vec[uint] lines);\n+type codemap = @rec(mutable vec[filemap] files);\n+type loc = rec(str filename, uint line, uint col);\n+\n+fn new_codemap() -> codemap {\n+    let vec[filemap] files = vec();\n+    ret @rec(mutable files=files);\n+}\n+\n+fn new_filemap(str filename, uint start_pos) -> filemap {\n+    let vec[uint] lines = vec();\n+    ret @rec(name=filename,\n+             start_pos=start_pos,\n+             mutable lines=lines);\n+}\n+\n+fn next_line(filemap file, uint pos) {\n+    _vec.push[uint](file.lines, pos);\n+}\n+\n+fn lookup_pos(codemap map, uint pos) -> loc {\n+    for (filemap f in map.files) {\n+        if (f.start_pos < pos) {\n+            auto line_num = 1u;\n+            auto line_start = 0u;\n+            // FIXME this can be a binary search if we need to be faster\n+            for (uint line_start_ in f.lines) {\n+                // FIXME duplicate code due to lack of working break\n+                if (line_start_ > pos) {\n+                    ret rec(filename=f.name,\n+                            line=line_num,\n+                            col=pos-line_start);\n+                }\n+                line_start = line_start_;\n+                line_num += 1u;\n+            }\n+            ret rec(filename=f.name,\n+                    line=line_num,\n+                    col=pos-line_start);\n+        }\n+    }\n+    log #fmt(\"Failed to find a location for character %u\", pos);\n+    fail;\n+}\n+\n+//\n+// Local Variables:\n+// mode: rust\n+// fill-column: 78;\n+// indent-tabs-mode: nil\n+// c-basic-offset: 4\n+// buffer-file-coding-system: utf-8-unix\n+// compile-command: \"make -k -C $RBUILD 2>&1 | sed -e 's/\\\\/x\\\\//x:\\\\//g'\";\n+// End:\n+//"}, {"sha": "ca350c36530bf456925a8d0bb664a0823d89839c", "filename": "src/comp/front/eval.rs", "status": "modified", "additions": 61, "deletions": 61, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Feval.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -25,6 +25,9 @@ tag val {\n }\n \n type env = vec[tup(ident, val)];\n+type ctx = @rec(parser p,\n+                session.session sess,\n+                mutable uint chpos);\n \n fn mk_env() -> env {\n     let env e = vec();\n@@ -89,50 +92,50 @@ fn lookup(session.session sess, env e, span sp, ident i) -> val {\n     fail;\n }\n \n-fn eval_lit(session.session sess, env e, span sp, @ast.lit lit) -> val {\n+fn eval_lit(ctx cx, span sp, @ast.lit lit) -> val {\n     alt (lit.node) {\n         case (ast.lit_bool(?b)) { ret val_bool(b); }\n         case (ast.lit_int(?i)) { ret val_int(i); }\n         case (ast.lit_str(?s)) { ret val_str(s); }\n         case (_) {\n-            sess.span_err(sp, \"evaluating unsupported literal\");\n+            cx.sess.span_err(sp, \"evaluating unsupported literal\");\n         }\n     }\n     fail;\n }\n \n-fn eval_expr(session.session sess, env e, @ast.expr x) -> val {\n+fn eval_expr(ctx cx, env e, @ast.expr x) -> val {\n     alt (x.node) {\n         case (ast.expr_path(?pth, _, _)) {\n             if (_vec.len[ident](pth.node.idents) == 1u &&\n                 _vec.len[@ast.ty](pth.node.types) == 0u) {\n-                ret lookup(sess, e, x.span, pth.node.idents.(0));\n+                ret lookup(cx.sess, e, x.span, pth.node.idents.(0));\n             }\n-            sess.span_err(x.span, \"evaluating structured path-name\");\n+            cx.sess.span_err(x.span, \"evaluating structured path-name\");\n         }\n \n         case (ast.expr_lit(?lit, _)) {\n-            ret eval_lit(sess, e, x.span, lit);\n+            ret eval_lit(cx, x.span, lit);\n         }\n \n         case (ast.expr_unary(?op, ?a, _)) {\n-            auto av = eval_expr(sess, e, a);\n+            auto av = eval_expr(cx, e, a);\n             alt (op) {\n                 case (ast.not) {\n                     if (val_is_bool(av)) {\n                         ret val_bool(!val_as_bool(av));\n                     }\n-                    sess.span_err(x.span, \"bad types in '!' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '!' expression\");\n                 }\n                 case (_) {\n-                    sess.span_err(x.span, \"evaluating unsupported unop\");\n+                    cx.sess.span_err(x.span, \"evaluating unsupported unop\");\n                 }\n             }\n         }\n \n         case (ast.expr_binary(?op, ?a, ?b, _)) {\n-            auto av = eval_expr(sess, e, a);\n-            auto bv = eval_expr(sess, e, b);\n+            auto av = eval_expr(cx, e, a);\n+            auto bv = eval_expr(cx, e, b);\n             alt (op) {\n                 case (ast.add) {\n                     if (val_is_int(av) && val_is_int(bv)) {\n@@ -141,66 +144,66 @@ fn eval_expr(session.session sess, env e, @ast.expr x) -> val {\n                     if (val_is_str(av) && val_is_str(bv)) {\n                         ret val_str(val_as_str(av) + val_as_str(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '+' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '+' expression\");\n                 }\n \n                 case (ast.sub) {\n                     if (val_is_int(av) && val_is_int(bv)) {\n                         ret val_int(val_as_int(av) - val_as_int(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '-' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '-' expression\");\n                 }\n \n                 case (ast.mul) {\n                     if (val_is_int(av) && val_is_int(bv)) {\n                         ret val_int(val_as_int(av) * val_as_int(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '*' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '*' expression\");\n                 }\n \n                 case (ast.div) {\n                     if (val_is_int(av) && val_is_int(bv)) {\n                         ret val_int(val_as_int(av) / val_as_int(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '/' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '/' expression\");\n                 }\n \n                 case (ast.rem) {\n                     if (val_is_int(av) && val_is_int(bv)) {\n                         ret val_int(val_as_int(av) % val_as_int(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '%' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '%' expression\");\n                 }\n \n                 case (ast.and) {\n                     if (val_is_bool(av) && val_is_bool(bv)) {\n                         ret val_bool(val_as_bool(av) && val_as_bool(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '&&' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '&&' expression\");\n                 }\n \n                 case (ast.or) {\n                     if (val_is_bool(av) && val_is_bool(bv)) {\n                         ret val_bool(val_as_bool(av) || val_as_bool(bv));\n                     }\n-                    sess.span_err(x.span, \"bad types in '||' expression\");\n+                    cx.sess.span_err(x.span, \"bad types in '||' expression\");\n                 }\n \n                 case (ast.eq) {\n-                    ret val_bool(val_eq(sess, x.span, av, bv));\n+                    ret val_bool(val_eq(cx.sess, x.span, av, bv));\n                 }\n \n                 case (ast.ne) {\n-                    ret val_bool(! val_eq(sess, x.span, av, bv));\n+                    ret val_bool(! val_eq(cx.sess, x.span, av, bv));\n                 }\n \n                 case (_) {\n-                    sess.span_err(x.span, \"evaluating unsupported binop\");\n+                    cx.sess.span_err(x.span, \"evaluating unsupported binop\");\n                 }\n             }\n         }\n         case (_) {\n-            sess.span_err(x.span, \"evaluating unsupported expression\");\n+            cx.sess.span_err(x.span, \"evaluating unsupported expression\");\n         }\n     }\n     fail;\n@@ -221,7 +224,7 @@ fn val_eq(session.session sess, span sp, val av, val bv) -> bool {\n     fail;\n }\n \n-impure fn eval_crate_directives(parser p,\n+impure fn eval_crate_directives(ctx cx,\n                                 env e,\n                                 vec[@ast.crate_directive] cdirs,\n                                 str prefix,\n@@ -231,28 +234,27 @@ impure fn eval_crate_directives(parser p,\n                                         ast.mod_index_entry] index) {\n \n     for (@ast.crate_directive sub_cdir in cdirs) {\n-        eval_crate_directive(p, e, sub_cdir, prefix,\n+        eval_crate_directive(cx, e, sub_cdir, prefix,\n                              view_items, items, index);\n     }\n }\n \n \n-impure fn eval_crate_directives_to_mod(parser p,\n-                                       env e,\n+impure fn eval_crate_directives_to_mod(ctx cx, env e,\n                                        vec[@ast.crate_directive] cdirs,\n                                        str prefix) -> ast._mod {\n     let vec[@ast.view_item] view_items = vec();\n     let vec[@ast.item] items = vec();\n     auto index = new_str_hash[ast.mod_index_entry]();\n \n-    eval_crate_directives(p, e, cdirs, prefix,\n+    eval_crate_directives(cx, e, cdirs, prefix,\n                           view_items, items, index);\n \n     ret rec(view_items=view_items, items=items, index=index);\n }\n \n \n-impure fn eval_crate_directive_block(parser p,\n+impure fn eval_crate_directive_block(ctx cx,\n                                      env e,\n                                      &ast.block blk,\n                                      str prefix,\n@@ -264,45 +266,42 @@ impure fn eval_crate_directive_block(parser p,\n     for (@ast.stmt s in blk.node.stmts) {\n         alt (s.node) {\n             case (ast.stmt_crate_directive(?cdir)) {\n-                eval_crate_directive(p, e, cdir, prefix,\n+                eval_crate_directive(cx, e, cdir, prefix,\n                                      view_items, items, index);\n             }\n             case (_) {\n-                auto sess = p.get_session();\n-                sess.span_err(s.span,\n-                              \"unsupported stmt in crate-directive block\");\n+                cx.sess.span_err(s.span,\n+                                 \"unsupported stmt in crate-directive block\");\n             }\n         }\n     }\n }\n \n-impure fn eval_crate_directive_expr(parser p,\n+impure fn eval_crate_directive_expr(ctx cx,\n                                     env e,\n                                     @ast.expr x,\n                                     str prefix,\n                                     &mutable vec[@ast.view_item] view_items,\n                                     &mutable vec[@ast.item] items,\n                                     hashmap[ast.ident,\n                                             ast.mod_index_entry] index) {\n-    auto sess = p.get_session();\n-\n     alt (x.node) {\n \n         case (ast.expr_if(?cond, ?thn, ?elopt, _)) {\n-            auto cv = eval_expr(sess, e, cond);\n+            auto cv = eval_expr(cx, e, cond);\n             if (!val_is_bool(cv)) {\n-                sess.span_err(x.span, \"bad cond type in 'if'\");\n+                cx.sess.span_err(x.span, \"bad cond type in 'if'\");\n             }\n \n             if (val_as_bool(cv)) {\n-                ret eval_crate_directive_block(p, e, thn, prefix,\n+                ret eval_crate_directive_block(cx, e, thn, prefix,\n                                                view_items, items,\n                                                index);\n             }\n \n             alt (elopt) {\n                 case (some[@ast.expr](?els)) {\n-                    ret eval_crate_directive_expr(p, e, els, prefix,\n+                    ret eval_crate_directive_expr(cx, e, els, prefix,\n                                                   view_items, items,\n                                                   index);\n                 }\n@@ -313,45 +312,44 @@ impure fn eval_crate_directive_expr(parser p,\n         }\n \n         case (ast.expr_alt(?v, ?arms, _)) {\n-            auto vv = eval_expr(sess, e, v);\n+            auto vv = eval_expr(cx, e, v);\n             for (ast.arm arm in arms) {\n                 alt (arm.pat.node) {\n                     case (ast.pat_lit(?lit, _)) {\n-                        auto pv = eval_lit(sess, e,\n-                                           arm.pat.span, lit);\n-                        if (val_eq(sess, arm.pat.span, vv, pv)) {\n+                        auto pv = eval_lit(cx, arm.pat.span, lit);\n+                        if (val_eq(cx.sess, arm.pat.span, vv, pv)) {\n                             ret eval_crate_directive_block\n-                                (p, e, arm.block, prefix,\n+                                (cx, e, arm.block, prefix,\n                                  view_items, items, index);\n                         }\n                     }\n                     case (ast.pat_wild(_)) {\n                         ret eval_crate_directive_block\n-                            (p, e, arm.block, prefix,\n+                            (cx, e, arm.block, prefix,\n                              view_items, items, index);\n                     }\n                     case (_) {\n-                        sess.span_err(arm.pat.span,\n-                                      \"bad pattern type in 'alt'\");\n+                        cx.sess.span_err(arm.pat.span,\n+                                         \"bad pattern type in 'alt'\");\n                     }\n                 }\n             }\n-            sess.span_err(x.span, \"no cases matched in 'alt'\");\n+            cx.sess.span_err(x.span, \"no cases matched in 'alt'\");\n         }\n \n         case (ast.expr_block(?block, _)) {\n-            ret eval_crate_directive_block(p, e, block, prefix,\n+            ret eval_crate_directive_block(cx, e, block, prefix,\n                                            view_items, items,\n                                            index);\n         }\n \n         case (_) {\n-            sess.span_err(x.span, \"unsupported expr type\");\n+            cx.sess.span_err(x.span, \"unsupported expr type\");\n         }\n     }\n }\n \n-impure fn eval_crate_directive(parser p,\n+impure fn eval_crate_directive(ctx cx,\n                                env e,\n                                @ast.crate_directive cdir,\n                                str prefix,\n@@ -362,14 +360,14 @@ impure fn eval_crate_directive(parser p,\n     alt (cdir.node) {\n \n         case (ast.cdir_let(?id, ?x, ?cdirs)) {\n-            auto v = eval_expr(p.get_session(), e, x);\n+            auto v = eval_expr(cx, e, x);\n             auto e0 = vec(tup(id, v)) + e;\n-            eval_crate_directives(p, e0, cdirs, prefix,\n+            eval_crate_directives(cx, e0, cdirs, prefix,\n                                   view_items, items, index);\n         }\n \n         case (ast.cdir_expr(?x)) {\n-            eval_crate_directive_expr(p, e, x, prefix,\n+            eval_crate_directive_expr(cx, e, x, prefix,\n                                       view_items, items, index);\n         }\n \n@@ -385,13 +383,15 @@ impure fn eval_crate_directive(parser p,\n \n             auto full_path = prefix + std.fs.path_sep() + file_path;\n \n-            auto start_id = p.next_def_id();\n-            auto p0 = new_parser(p.get_session(), e, start_id, full_path);\n+            auto start_id = cx.p.next_def_id();\n+            auto p0 = new_parser(cx.sess, e, start_id, full_path, cx.chpos);\n             auto m0 = parse_mod_items(p0, token.EOF);\n             auto next_id = p0.next_def_id();\n-            p.set_def(next_id._1);\n+            // Thread defids and chpos through the parsers\n+            cx.p.set_def(next_id._1);\n+            cx.chpos = p0.get_chpos();\n             auto im = ast.item_mod(id, m0, next_id);\n-            auto i = @spanned(cdir.span, cdir.span, im);\n+            auto i = @spanned(cdir.span.lo, cdir.span.hi, im);\n             ast.index_item(index, i);\n             _vec.push[@ast.item](items, i);\n         }\n@@ -407,9 +407,9 @@ impure fn eval_crate_directive(parser p,\n             }\n \n             auto full_path = prefix + std.fs.path_sep() + path;\n-            auto m0 = eval_crate_directives_to_mod(p, e, cdirs, full_path);\n-            auto im = ast.item_mod(id, m0, p.next_def_id());\n-            auto i = @spanned(cdir.span, cdir.span, im);\n+            auto m0 = eval_crate_directives_to_mod(cx, e, cdirs, full_path);\n+            auto im = ast.item_mod(id, m0, cx.p.next_def_id());\n+            auto i = @spanned(cdir.span.lo, cdir.span.hi, im);\n             ast.index_item(index, i);\n             _vec.push[@ast.item](items, i);\n         }"}, {"sha": "5e4f86afb9eed1ad6d6fca2731c17ee504814993", "filename": "src/comp/front/extfmt.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fextfmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fextfmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fextfmt.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -318,9 +318,9 @@ fn parse_type(str s, uint i, uint lim) -> tup(ty, uint) {\n fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n \n     fn make_new_lit(common.span sp, ast.lit_ lit) -> @ast.expr {\n-        auto sp_lit = @parser.spanned[ast.lit_](sp, sp, lit);\n+        auto sp_lit = @rec(node=lit, span=sp);\n         auto expr = ast.expr_lit(sp_lit, ast.ann_none);\n-        ret @parser.spanned[ast.expr_](sp, sp, expr);\n+        ret @rec(node=expr, span=sp);\n     }\n \n     fn make_new_str(common.span sp, str s) -> @ast.expr {\n@@ -336,19 +336,19 @@ fn pieces_to_expr(vec[piece] pieces, vec[@ast.expr] args) -> @ast.expr {\n     fn make_add_expr(common.span sp,\n                      @ast.expr lhs, @ast.expr rhs) -> @ast.expr {\n         auto binexpr = ast.expr_binary(ast.add, lhs, rhs, ast.ann_none);\n-        ret @parser.spanned[ast.expr_](sp, sp, binexpr);\n+        ret @rec(node=binexpr, span=sp);\n     }\n \n     fn make_call(common.span sp, vec[ast.ident] fn_path,\n                  vec[@ast.expr] args) -> @ast.expr {\n         let vec[ast.ident] path_idents = fn_path;\n         let vec[@ast.ty] path_types = vec();\n         auto path = rec(idents = path_idents, types = path_types);\n-        auto sp_path = parser.spanned[ast.path_](sp, sp, path);\n+        auto sp_path = rec(node=path, span=sp);\n         auto pathexpr = ast.expr_path(sp_path, none[ast.def], ast.ann_none);\n-        auto sp_pathexpr = @parser.spanned[ast.expr_](sp, sp, pathexpr);\n+        auto sp_pathexpr = @rec(node=pathexpr, span=sp);\n         auto callexpr = ast.expr_call(sp_pathexpr, args, ast.ann_none);\n-        auto sp_callexpr = @parser.spanned[ast.expr_](sp, sp, callexpr);\n+        auto sp_callexpr = @rec(node=callexpr, span=sp);\n         ret sp_callexpr;\n     }\n "}, {"sha": "65091ff7b29b746ee5db004de56a7089f8c38ea2", "filename": "src/comp/front/lexer.rs", "status": "modified", "additions": 38, "deletions": 43, "changes": 81, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Flexer.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -17,42 +17,32 @@ state type reader = state obj {\n     impure fn init();\n     impure fn bump();\n     fn mark();\n-    fn get_filename() -> str;\n-    fn get_mark_pos() -> common.pos;\n-    fn get_curr_pos() -> common.pos;\n+    fn get_mark_chpos() -> uint;\n+    fn get_chpos() -> uint;\n     fn get_keywords() -> hashmap[str,token.token];\n     fn get_reserved() -> hashmap[str,()];\n+    fn get_filemap() -> codemap.filemap;\n };\n \n-impure fn new_reader(io.reader rdr, str filename) -> reader\n-{\n+impure fn new_reader(io.reader rdr, str filename, codemap.filemap filemap)\n+    -> reader {\n     state obj reader(str file,\n-                     str filename,\n                      uint len,\n                      mutable uint pos,\n                      mutable char ch,\n-                     mutable uint mark_line,\n-                     mutable uint mark_col,\n-                     mutable uint line,\n-                     mutable uint col,\n+                     mutable uint mark_chpos,\n+                     mutable uint chpos,\n                      hashmap[str,token.token] keywords,\n-                     hashmap[str,()] reserved) {\n+                     hashmap[str,()] reserved,\n+                     codemap.filemap fm) {\n \n         fn is_eof() -> bool {\n             ret ch == -1 as char;\n         }\n \n-        fn get_curr_pos() -> common.pos {\n-            ret rec(line=line, col=col);\n-        }\n-\n-        fn get_mark_pos() -> common.pos {\n-            ret rec(line=mark_line, col=mark_col);\n-        }\n-\n-        fn get_filename() -> str {\n-            ret filename;\n-        }\n+        fn mark() { mark_chpos = chpos; }\n+        fn get_mark_chpos() -> uint { ret mark_chpos; }\n+        fn get_chpos() -> uint { ret chpos; }\n \n         fn curr() -> char {\n             ret ch;\n@@ -73,11 +63,9 @@ impure fn new_reader(io.reader rdr, str filename) -> reader\n \n         impure fn bump() {\n             if (pos < len) {\n+                chpos += 1u;\n                 if (ch == '\\n') {\n-                    line += 1u;\n-                    col = 0u;\n-                } else {\n-                    col += 1u;\n+                    codemap.next_line(fm, chpos);\n                 }\n                 auto next = _str.char_range_at(file, pos);\n                 pos = next._1;\n@@ -87,20 +75,29 @@ impure fn new_reader(io.reader rdr, str filename) -> reader\n             }\n         }\n \n-        fn mark() {\n-            mark_line = line;\n-            mark_col = col;\n-        }\n-\n         fn get_keywords() -> hashmap[str,token.token] {\n             ret keywords;\n         }\n \n         fn get_reserved() -> hashmap[str,()] {\n             ret reserved;\n         }\n+\n+        fn get_filemap() -> codemap.filemap {\n+            ret fm;\n+        }\n     }\n+    auto file = _str.unsafe_from_bytes(rdr.read_whole_stream());\n+    auto rd = reader(file, _str.byte_len(file), 0u, -1 as char,\n+                     filemap.start_pos, filemap.start_pos,\n+                     keyword_table(),\n+                     reserved_word_table(),\n+                     filemap);\n+    rd.init();\n+    ret rd;\n+}\n \n+fn keyword_table() -> std.map.hashmap[str, token.token] {\n     auto keywords = new_str_hash[token.token]();\n \n     keywords.insert(\"mod\", token.MOD);\n@@ -205,24 +202,21 @@ impure fn new_reader(io.reader rdr, str filename) -> reader\n     keywords.insert(\"f32\", token.MACH(common.ty_f32));\n     keywords.insert(\"f64\", token.MACH(common.ty_f64));\n \n-    auto reserved = new_str_hash[()]();\n+    ret keywords;\n+}\n \n+fn reserved_word_table() -> std.map.hashmap[str, ()] {\n+    auto reserved = new_str_hash[()]();\n     reserved.insert(\"f16\", ());  // IEEE 754-2008 'binary16' interchange fmt\n     reserved.insert(\"f80\", ());  // IEEE 754-1985 'extended'\n     reserved.insert(\"f128\", ()); // IEEE 754-2008 'binary128'\n     reserved.insert(\"m32\", ());  // IEEE 754-2008 'decimal32'\n     reserved.insert(\"m64\", ());  // IEEE 754-2008 'decimal64'\n     reserved.insert(\"m128\", ()); // IEEE 754-2008 'decimal128'\n     reserved.insert(\"dec\", ());  // One of m32, m64, m128\n-\n-    auto file = _str.unsafe_from_bytes(rdr.read_whole_stream());\n-    auto rd = reader(file, filename, _str.byte_len(file), 0u, -1 as char,\n-                     1u, 0u, 1u, 0u, keywords, reserved);\n-    rd.init();\n-    ret rd;\n+    ret reserved;\n }\n \n-\n fn in_range(char c, char lo, char hi) -> bool {\n     ret lo <= c && c <= hi;\n }\n@@ -797,7 +791,8 @@ tag cmnt_ {\n     cmnt_line(str);\n     cmnt_block(vec[str]);\n }\n-type cmnt = rec(cmnt_ val, common.pos pos, bool space_after);\n+\n+type cmnt = rec(cmnt_ val, uint pos, bool space_after);\n \n impure fn consume_whitespace(reader rdr) -> uint {\n     auto lines = 0u;\n@@ -809,7 +804,7 @@ impure fn consume_whitespace(reader rdr) -> uint {\n }\n \n impure fn read_line_comment(reader rdr) -> cmnt {\n-    auto p = rdr.get_curr_pos();\n+    auto p = rdr.get_chpos();\n     rdr.bump(); rdr.bump();\n     while (rdr.curr() == ' ') {rdr.bump();}\n     auto val = \"\";\n@@ -823,7 +818,7 @@ impure fn read_line_comment(reader rdr) -> cmnt {\n }\n \n impure fn read_block_comment(reader rdr) -> cmnt {\n-    auto p = rdr.get_curr_pos();\n+    auto p = rdr.get_chpos();\n     rdr.bump(); rdr.bump();\n     while (rdr.curr() == ' ') {rdr.bump();}\n     let vec[str] lines = vec();\n@@ -857,7 +852,7 @@ impure fn read_block_comment(reader rdr) -> cmnt {\n \n impure fn gather_comments(str path) -> vec[cmnt] {\n     auto srdr = io.file_reader(path);\n-    auto rdr = new_reader(srdr, path);\n+    auto rdr = new_reader(srdr, path, codemap.new_filemap(path, 0u));\n     let vec[cmnt] comments = vec();\n     while (!rdr.is_eof()) {\n         while (true) {"}, {"sha": "617f18135b1a315baf43a21835802b3d7efa88cc", "filename": "src/comp/front/parser.rs", "status": "modified", "additions": 204, "deletions": 209, "changes": 413, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Ffront%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffront%2Fparser.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -34,21 +34,25 @@ state type parser =\n           fn get_env() -> eval.env;\n           fn get_session() -> session.session;\n           fn get_span() -> common.span;\n+          fn get_lo_pos() -> uint;\n+          fn get_hi_pos() -> uint;\n           fn next_def_id() -> ast.def_id;\n           fn set_def(ast.def_num);\n           fn get_prec_table() -> vec[op_spec];\n+          fn get_filemap() -> codemap.filemap;\n+          fn get_chpos() -> uint;\n     };\n \n impure fn new_parser(session.session sess,\n                      eval.env env,\n                      ast.def_id initial_def,\n-                     str path) -> parser {\n+                     str path, uint pos) -> parser {\n     state obj stdio_parser(session.session sess,\n                            eval.env env,\n                            file_type ftype,\n                            mutable token.token tok,\n-                           mutable common.pos lo,\n-                           mutable common.pos hi,\n+                           mutable uint lo,\n+                           mutable uint hi,\n                            mutable ast.def_num def,\n                            mutable restriction res,\n                            ast.crate_num crate,\n@@ -63,14 +67,12 @@ impure fn new_parser(session.session sess,\n                 // log rdr.get_filename()\n                 //   + \":\" + common.istr(lo.line as int);\n                 tok = lexer.next_token(rdr);\n-                lo = rdr.get_mark_pos();\n-                hi = rdr.get_curr_pos();\n+                lo = rdr.get_mark_chpos();\n+                hi = rdr.get_chpos();\n             }\n \n             impure fn err(str m) {\n-                auto span = rec(filename = rdr.get_filename(),\n-                                lo = lo, hi = hi);\n-                sess.span_err(span, m);\n+                sess.span_err(rec(lo=lo, hi=hi), m);\n             }\n \n             impure fn restrict(restriction r) {\n@@ -85,10 +87,9 @@ impure fn new_parser(session.session sess,\n                 ret sess;\n             }\n \n-            fn get_span() -> common.span {\n-                ret rec(filename = rdr.get_filename(),\n-                        lo = lo, hi = hi);\n-            }\n+            fn get_span() -> common.span { ret rec(lo=lo, hi=hi); }\n+            fn get_lo_pos() -> uint { ret lo; }\n+            fn get_hi_pos() -> uint { ret hi; }\n \n             fn next_def_id() -> ast.def_id {\n                 def += 1;\n@@ -110,16 +111,24 @@ impure fn new_parser(session.session sess,\n             fn get_prec_table() -> vec[op_spec] {\n                 ret precs;\n             }\n+\n+            fn get_filemap() -> codemap.filemap {\n+                ret rdr.get_filemap();\n+            }\n+\n+            fn get_chpos() -> uint {ret rdr.get_chpos();}\n         }\n     auto ftype = SOURCE_FILE;\n     if (_str.ends_with(path, \".rc\")) {\n         ftype = CRATE_FILE;\n     }\n     auto srdr = io.file_reader(path);\n-    auto rdr = lexer.new_reader(srdr, path);\n+    auto filemap = codemap.new_filemap(path, pos);\n+    _vec.push[codemap.filemap](sess.get_codemap().files, filemap);\n+    auto rdr = lexer.new_reader(srdr, path, filemap);\n     // Make sure npos points at first actual token.\n     lexer.consume_any_whitespace(rdr);\n-    auto npos = rdr.get_curr_pos();\n+    auto npos = rdr.get_chpos();\n     ret stdio_parser(sess, env, ftype, lexer.next_token(rdr),\n                      npos, npos, initial_def._1, UNRESTRICTED, initial_def._0,\n                      rdr, prec_table());\n@@ -143,10 +152,8 @@ impure fn expect(parser p, token.token t) {\n     }\n }\n \n-fn spanned[T](&span lo, &span hi, &T node) -> ast.spanned[T] {\n-    ret rec(node=node, span=rec(filename=lo.filename,\n-                                lo=lo.lo,\n-                                hi=hi.hi));\n+fn spanned[T](uint lo, uint hi, &T node) -> ast.spanned[T] {\n+    ret rec(node=node, span=rec(lo=lo, hi=hi));\n }\n \n impure fn parse_ident(parser p) -> ast.ident {\n@@ -185,8 +192,8 @@ impure fn parse_str_lit_or_env_ident(parser p) -> ast.ident {\n }\n \n \n-impure fn parse_ty_fn(ast.effect eff, ast.proto proto, parser p,\n-                      ast.span lo) -> ast.ty_ {\n+impure fn parse_ty_fn(ast.effect eff, ast.proto proto, parser p, uint lo)\n+    -> ast.ty_ {\n     impure fn parse_fn_input_ty(parser p) -> rec(ast.mode mode, @ast.ty ty) {\n         auto mode;\n         if (p.peek() == token.BINOP(token.AND)) {\n@@ -211,7 +218,7 @@ impure fn parse_ty_fn(ast.effect eff, ast.proto proto, parser p,\n         ret rec(mode=mode, ty=t);\n     }\n \n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n \n     auto f = parse_fn_input_ty; // FIXME: trans_const_lval bug\n     auto inputs = parse_seq[rec(ast.mode mode, @ast.ty ty)](token.LPAREN,\n@@ -226,7 +233,7 @@ impure fn parse_ty_fn(ast.effect eff, ast.proto proto, parser p,\n         p.bump();\n         output = parse_ty(p);\n     } else {\n-        output = @spanned(lo, inputs.span, ast.ty_nil);\n+        output = @spanned(lo, inputs.span.hi, ast.ty_nil);\n     }\n \n     ret ast.ty_fn(eff, proto, inputs.node, output);\n@@ -241,10 +248,10 @@ impure fn parse_proto(parser p) -> ast.proto {\n     fail;\n }\n \n-impure fn parse_ty_obj(parser p, &mutable ast.span hi) -> ast.ty_ {\n+impure fn parse_ty_obj(parser p, &mutable uint hi) -> ast.ty_ {\n     expect(p, token.OBJ);\n     impure fn parse_method_sig(parser p) -> ast.ty_method {\n-        auto flo = p.get_span();\n+        auto flo = p.get_lo_pos();\n \n         let ast.effect eff = parse_effect(p);\n         let ast.proto proto = parse_proto(p);\n@@ -265,7 +272,7 @@ impure fn parse_ty_obj(parser p, &mutable ast.span hi) -> ast.ty_ {\n                                  token.RBRACE,\n                                  none[token.token],\n                                  f, p);\n-    hi = meths.span;\n+    hi = meths.span.hi;\n     ret ast.ty_obj(meths.node);\n }\n \n@@ -282,30 +289,29 @@ impure fn parse_ty_field(parser p) -> ast.ty_field {\n }\n \n impure fn parse_constr_arg(parser p) -> @ast.constr_arg {\n-    auto lo = p.get_span();\n+    auto sp = p.get_span();\n     auto carg = ast.carg_base;\n     if (p.peek() == token.BINOP(token.STAR)) {\n         p.bump();\n     } else {\n         carg = ast.carg_ident(parse_ident(p));\n     }\n-    ret @spanned(lo, lo, carg);\n+    ret @rec(node=carg, span=sp);\n }\n \n impure fn parse_ty_constr(parser p) -> @ast.constr {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto path = parse_path(p, GREEDY);\n     auto pf = parse_constr_arg;\n     auto args = parse_seq[@ast.constr_arg](token.LPAREN,\n                                          token.RPAREN,\n                                          some(token.COMMA), pf, p);\n-    auto hi = args.span;\n-    ret @spanned(lo, hi, rec(path=path, args=args.node));\n+    ret @spanned(lo, args.span.hi, rec(path=path, args=args.node));\n }\n \n impure fn parse_constrs(parser p) -> common.spanned[vec[@ast.constr]] {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n+    auto hi = p.get_hi_pos();\n     let vec[@ast.constr] constrs = vec();\n     if (p.peek() == token.COLON) {\n         p.bump();\n@@ -314,7 +320,7 @@ impure fn parse_constrs(parser p) -> common.spanned[vec[@ast.constr]] {\n             alt (p.peek()) {\n                 case (token.IDENT(_)) {\n                     auto constr = parse_ty_constr(p);\n-                    hi = constr.span;\n+                    hi = constr.span.hi;\n                     _vec.push[@ast.constr](constrs, constr);\n                     if (p.peek() == token.COMMA) {\n                         p.bump();\n@@ -331,14 +337,14 @@ impure fn parse_constrs(parser p) -> common.spanned[vec[@ast.constr]] {\n impure fn parse_ty_constrs(@ast.ty t, parser p) -> @ast.ty {\n    if (p.peek() == token.COLON) {\n        auto constrs = parse_constrs(p);\n-       ret @spanned(t.span, constrs.span,\n+       ret @spanned(t.span.lo, constrs.span.hi,\n                     ast.ty_constr(t, constrs.node));\n    }\n    ret t;\n }\n \n impure fn parse_ty(parser p) -> @ast.ty {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto hi = lo;\n     let ast.ty_ t;\n \n@@ -360,13 +366,13 @@ impure fn parse_ty(parser p) -> @ast.ty {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.RPAREN) {\n-                    hi = p.get_span();\n+                    hi = p.get_hi_pos();\n                     p.bump();\n                     t = ast.ty_nil;\n                 }\n                 case (_) {\n                     t = parse_ty(p).node;\n-                    hi = p.get_span();\n+                    hi = p.get_hi_pos();\n                     expect(p, token.RPAREN);\n                 }\n             }\n@@ -375,15 +381,15 @@ impure fn parse_ty(parser p) -> @ast.ty {\n         case (token.AT) {\n             p.bump();\n             auto mt = parse_mt(p);\n-            hi = mt.ty.span;\n+            hi = mt.ty.span.hi;\n             t = ast.ty_box(mt);\n         }\n \n         case (token.VEC) {\n             p.bump();\n             expect(p, token.LBRACKET);\n             t = ast.ty_vec(parse_mt(p));\n-            hi = p.get_span();\n+            hi = p.get_hi_pos();\n             expect(p, token.RBRACKET);\n         }\n \n@@ -393,7 +399,7 @@ impure fn parse_ty(parser p) -> @ast.ty {\n             auto elems = parse_seq[ast.mt] (token.LPAREN,\n                                             token.RPAREN,\n                                             some(token.COMMA), f, p);\n-            hi = elems.span;\n+            hi = elems.span.hi;\n             t = ast.ty_tup(elems.node);\n         }\n \n@@ -405,28 +411,28 @@ impure fn parse_ty(parser p) -> @ast.ty {\n                                         token.RPAREN,\n                                         some(token.COMMA),\n                                         f, p);\n-            hi = elems.span;\n+            hi = elems.span.hi;\n             t = ast.ty_rec(elems.node);\n         }\n \n         case (token.FN) {\n-            auto flo = p.get_span();\n+            auto flo = p.get_lo_pos();\n             p.bump();\n             t = parse_ty_fn(eff, ast.proto_fn, p, flo);\n             alt (t) {\n                 case (ast.ty_fn(_, _, _, ?out)) {\n-                    hi = out.span;\n+                    hi = out.span.hi;\n                 }\n             }\n         }\n \n         case (token.ITER) {\n-            auto flo = p.get_span();\n+            auto flo = p.get_lo_pos();\n             p.bump();\n             t = parse_ty_fn(eff, ast.proto_iter, p, flo);\n             alt (t) {\n                 case (ast.ty_fn(_, _, _, ?out)) {\n-                    hi = out.span;\n+                    hi = out.span.hi;\n                 }\n             }\n         }\n@@ -439,22 +445,22 @@ impure fn parse_ty(parser p) -> @ast.ty {\n             p.bump();\n             expect(p, token.LBRACKET);\n             t = ast.ty_port(parse_ty(p));\n-            hi = p.get_span();\n+            hi = p.get_hi_pos();\n             expect(p, token.RBRACKET);\n         }\n \n         case (token.CHAN) {\n             p.bump();\n             expect(p, token.LBRACKET);\n             t = ast.ty_chan(parse_ty(p));\n-            hi = p.get_span();\n+            hi = p.get_hi_pos();\n             expect(p, token.RBRACKET);\n         }\n \n         case (token.IDENT(_)) {\n             auto path = parse_path(p, GREEDY);\n             t = ast.ty_path(path, none[ast.def]);\n-            hi = path.span;\n+            hi = path.span.hi;\n         }\n \n         case (token.MUTABLE) {\n@@ -463,7 +469,7 @@ impure fn parse_ty(parser p) -> @ast.ty {\n                 \"ignoring deprecated 'mutable' type constructor\");\n             auto typ = parse_ty(p);\n             t = typ.node;\n-            hi = typ.span;\n+            hi = typ.span.hi;\n         }\n \n         case (_) {\n@@ -495,6 +501,7 @@ impure fn parse_arg(parser p) -> ast.arg {\n impure fn parse_seq_to_end[T](token.token ket,\n                               option.t[token.token] sep,\n                               (impure fn(parser) -> T) f,\n+                              mutable uint hi,\n                               parser p) -> vec[T] {\n     let bool first = true;\n     let vec[T] v = vec();\n@@ -514,24 +521,25 @@ impure fn parse_seq_to_end[T](token.token ket,\n         let T t = f(p);\n         v += vec(t);\n     }\n+    hi = p.get_hi_pos();\n     expect(p, ket);\n     ret v;\n }\n \n impure fn parse_seq[T](token.token bra,\n-                      token.token ket,\n-                      option.t[token.token] sep,\n-                      (impure fn(parser) -> T) f,\n-                      parser p) -> util.common.spanned[vec[T]] {\n-    auto lo = p.get_span();\n+                       token.token ket,\n+                       option.t[token.token] sep,\n+                       (impure fn(parser) -> T) f,\n+                       parser p) -> util.common.spanned[vec[T]] {\n+    auto lo = p.get_lo_pos();\n+    auto hi = p.get_hi_pos();\n     expect(p, bra);\n-    auto result = parse_seq_to_end[T](ket, sep, f, p);\n-    auto hi = p.get_span();\n+    auto result = parse_seq_to_end[T](ket, sep, f, hi, p);\n     ret spanned(lo, hi, result);\n }\n \n impure fn parse_lit(parser p) -> ast.lit {\n-    auto lo = p.get_span();\n+    auto sp = p.get_span();\n     let ast.lit_ lit = ast.lit_nil;\n     alt (p.peek()) {\n         case (token.LIT_INT(?i)) {\n@@ -570,7 +578,7 @@ impure fn parse_lit(parser p) -> ast.lit {\n             unexpected(p, t);\n         }\n     }\n-    ret spanned(lo, lo, lit);\n+    ret rec(node=lit, span=sp);\n }\n \n fn is_ident(token.token t) -> bool {\n@@ -586,7 +594,7 @@ tag greed {\n     MINIMAL;\n }\n \n-impure fn parse_ty_args(parser p, span hi) ->\n+impure fn parse_ty_args(parser p, uint hi) ->\n     util.common.spanned[vec[@ast.ty]] {\n \n     if (p.peek() == token.LBRACKET) {\n@@ -597,20 +605,21 @@ impure fn parse_ty_args(parser p, span hi) ->\n                                pf, p);\n     }\n     let vec[@ast.ty] v = vec();\n+    auto pos = p.get_lo_pos();\n     ret spanned(hi, hi, v);\n }\n \n impure fn parse_path(parser p, greed g) -> ast.path {\n \n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto hi = lo;\n \n     let vec[ast.ident] ids = vec();\n     let bool more = true;\n     while (more) {\n         alt (p.peek()) {\n             case (token.IDENT(?i)) {\n-                hi = p.get_span();\n+                hi = p.get_hi_pos();\n                 ids += vec(i);\n                 p.bump();\n                 if (p.peek() == token.DOT) {\n@@ -631,7 +640,7 @@ impure fn parse_path(parser p, greed g) -> ast.path {\n     }\n \n     auto tys = parse_ty_args(p, hi);\n-    ret spanned(lo, tys.span, rec(idents=ids, types=tys.node));\n+    ret spanned(lo, tys.span.hi, rec(idents=ids, types=tys.node));\n }\n \n impure fn parse_mutability(parser p) -> ast.mutability {\n@@ -656,27 +665,27 @@ impure fn parse_field(parser p) -> ast.field {\n \n impure fn parse_bottom_expr(parser p) -> @ast.expr {\n \n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n+    auto hi = p.get_hi_pos();\n \n     // FIXME: can only remove this sort of thing when both typestate and\n     // alt-exhaustive-match checking are co-operating.\n-    auto lit = @spanned(lo, lo, ast.lit_nil);\n+    auto lit = @spanned(lo, hi, ast.lit_nil);\n     let ast.expr_ ex = ast.expr_lit(lit, ast.ann_none);\n \n     alt (p.peek()) {\n \n         case (token.IDENT(_)) {\n             auto pth = parse_path(p, MINIMAL);\n-            hi = pth.span;\n+            hi = pth.span.hi;\n             ex = ast.expr_path(pth, none[ast.def], ast.ann_none);\n         }\n \n         case (token.LPAREN) {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.RPAREN) {\n-                    hi = p.get_span();\n+                    hi = p.get_hi_pos();\n                     p.bump();\n                     auto lit = @spanned(lo, hi, ast.lit_nil);\n                     ret @spanned(lo, hi,\n@@ -685,7 +694,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                 case (_) { /* fall through */ }\n             }\n             auto e = parse_expr(p);\n-            hi = p.get_span();\n+            hi = p.get_hi_pos();\n             expect(p, token.RPAREN);\n             ret @spanned(lo, hi, e.node);\n         }\n@@ -703,7 +712,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                                    token.RPAREN,\n                                    some(token.COMMA),\n                                    pf, p);\n-            hi = es.span;\n+            hi = es.span.hi;\n             ex = ast.expr_tup(es.node, ast.ann_none);\n         }\n \n@@ -716,8 +725,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n \n             auto es = parse_seq_to_end[@ast.expr](token.RPAREN,\n                                                   some(token.COMMA),\n-                                                  pf, p);\n-            hi = p.get_span();\n+                                                  pf, hi, p);\n             ex = ast.expr_vec(es, mut, ast.ann_none);\n         }\n \n@@ -731,14 +739,14 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n             while (more) {\n                 alt (p.peek()) {\n                     case (token.RPAREN) {\n-                        hi = p.get_span();\n+                        hi = p.get_hi_pos();\n                         p.bump();\n                         more = false;\n                     }\n                     case (token.WITH) {\n                         p.bump();\n                         base = some[@ast.expr](parse_expr(p));\n-                        hi = p.get_span();\n+                        hi = p.get_hi_pos();\n                         expect(p, token.RPAREN);\n                         more = false;\n                     }\n@@ -776,7 +784,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                                                      token.RPAREN,\n                                                      some(token.COMMA),\n                                                      pf, p);\n-            hi = es.span;\n+            hi = es.span.hi;\n             ex = ast.expr_bind(e, es.node, ast.ann_none);\n         }\n \n@@ -788,7 +796,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                                            token.RPAREN,\n                                            some(token.COMMA),\n                                            pf, p);\n-            hi = es.span;\n+            hi = es.span.hi;\n             ex = expand_syntax_ext(p, es.span, pth, es.node,\n                                    none[@ast.expr]);\n         }\n@@ -801,7 +809,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n         case (token.LOG) {\n             p.bump();\n             auto e = parse_expr(p);\n-            auto hi = e.span;\n+            auto hi = e.span.hi;\n             ex = ast.expr_log(e, ast.ann_none);\n         }\n \n@@ -810,7 +818,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n             alt (p.peek()) {\n                 case (token.LPAREN) {\n                     auto e = parse_expr(p);\n-                    auto hi = e.span;\n+                    auto hi = e.span.hi;\n                     ex = ast.expr_check_expr(e, ast.ann_none);\n                 }\n                 case (_) {\n@@ -827,7 +835,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                 }\n                 case (_) {\n                     auto e = parse_expr(p);\n-                    hi = e.span;\n+                    hi = e.span.hi;\n                     ex = ast.expr_ret(some[@ast.expr](e), ast.ann_none);\n                 }\n             }\n@@ -851,7 +859,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                 }\n                 case (_) {\n                     auto e = parse_expr(p);\n-                    hi = e.span;\n+                    hi = e.span.hi;\n                     ex = ast.expr_put(some[@ast.expr](e), ast.ann_none);\n                 }\n             }\n@@ -862,7 +870,7 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n             auto e = parse_expr(p);\n             // FIXME: Is this the right place for this check?\n             if /*check*/ (ast.is_call_expr(e)) {\n-                    hi = e.span;\n+                    hi = e.span.hi;\n                     ex = ast.expr_be(e, ast.ann_none);\n             }\n             else {\n@@ -874,15 +882,15 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n             p.bump();\n             expect(p, token.LPAREN);\n             expect(p, token.RPAREN);\n-            hi = p.get_span();\n+            hi = p.get_hi_pos();\n             ex = ast.expr_port(ast.ann_none);\n         }\n \n         case (token.CHAN) {\n             p.bump();\n             expect(p, token.LPAREN);\n             auto e = parse_expr(p);\n-            hi = e.span;\n+            hi = e.span.hi;\n             expect(p, token.RPAREN);\n             ex = ast.expr_chan(e, ast.ann_none);\n         }\n@@ -899,13 +907,13 @@ impure fn parse_bottom_expr(parser p) -> @ast.expr {\n                                            token.RPAREN,\n                                            some(token.COMMA),\n                                            pf, p);\n-            hi = es.span;\n+            hi = es.span.hi;\n             ex = ast.expr_call(f, es.node, ast.ann_none);\n         }\n \n         case (_) {\n             auto lit = parse_lit(p);\n-            hi = lit.span;\n+            hi = lit.span.hi;\n             ex = ast.expr_lit(@lit, ast.ann_none);\n         }\n     }\n@@ -941,7 +949,7 @@ impure fn expand_syntax_ext(parser p, ast.span sp,\n     }\n }\n \n-impure fn extend_expr_by_ident(parser p, span lo, span hi,\n+impure fn extend_expr_by_ident(parser p, uint lo, uint hi,\n                                @ast.expr e, ast.ident i) -> @ast.expr {\n     auto e_ = e.node;\n     alt (e.node) {\n@@ -950,11 +958,11 @@ impure fn extend_expr_by_ident(parser p, span lo, span hi,\n                 auto idents_ = pth.node.idents;\n                 idents_ += vec(i);\n                 auto tys = parse_ty_args(p, hi);\n-                auto pth_ = spanned(pth.span, tys.span,\n+                auto pth_ = spanned(pth.span.lo, tys.span.hi,\n                                     rec(idents=idents_,\n                                         types=tys.node));\n                 e_ = ast.expr_path(pth_, def, ann);\n-                ret @spanned(pth_.span, pth_.span, e_);\n+                ret @spanned(pth_.span.lo, pth_.span.hi, e_);\n             } else {\n                 e_ = ast.expr_field(e, i, ann);\n             }\n@@ -967,16 +975,16 @@ impure fn extend_expr_by_ident(parser p, span lo, span hi,\n }\n \n impure fn parse_self_method(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n+    auto sp = p.get_span();\n     let ast.ident f_name = parse_ident(p);\n     auto hi = p.get_span();\n-    ret @spanned(lo, hi, ast.expr_self_method(f_name, ast.ann_none));\n+    ret @rec(node=ast.expr_self_method(f_name, ast.ann_none), span=sp);\n }\n \n impure fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto e = parse_bottom_expr(p);\n-    auto hi = e.span;\n+    auto hi = e.span.hi;\n     while (true) {\n         alt (p.peek()) {\n \n@@ -990,7 +998,7 @@ impure fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n                                                    token.RPAREN,\n                                                    some(token.COMMA),\n                                                    pf, p);\n-                    hi = es.span;\n+                    hi = es.span.hi;\n                     auto e_ = ast.expr_call(e, es.node, ast.ann_none);\n                     e = @spanned(lo, hi, e_);\n                 }\n@@ -1001,15 +1009,15 @@ impure fn parse_dot_or_call_expr(parser p) -> @ast.expr {\n                 alt (p.peek()) {\n \n                     case (token.IDENT(?i)) {\n-                        hi = p.get_span();\n+                        hi = p.get_hi_pos();\n                         p.bump();\n                         e = extend_expr_by_ident(p, lo, hi, e, i);\n                     }\n \n                     case (token.LPAREN) {\n                         p.bump();\n                         auto ix = parse_expr(p);\n-                        hi = ix.span;\n+                        hi = ix.span.hi;\n                         expect(p, token.RPAREN);\n                         auto e_ = ast.expr_index(e, ix, ast.ann_none);\n                         e = @spanned(lo, hi, e_);\n@@ -1036,8 +1044,8 @@ impure fn parse_prefix_expr(parser p) -> @ast.expr {\n             \"ignoring deprecated 'mutable' prefix operator\");\n     }\n \n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n+    auto hi = p.get_hi_pos();\n \n     // FIXME: can only remove this sort of thing when both typestate and\n     // alt-exhaustive-match checking are co-operating.\n@@ -1049,14 +1057,14 @@ impure fn parse_prefix_expr(parser p) -> @ast.expr {\n         case (token.NOT) {\n             p.bump();\n             auto e = parse_prefix_expr(p);\n-            hi = e.span;\n+            hi = e.span.hi;\n             ex = ast.expr_unary(ast.not, e, ast.ann_none);\n         }\n \n         case (token.TILDE) {\n             p.bump();\n             auto e = parse_prefix_expr(p);\n-            hi = e.span;\n+            hi = e.span.hi;\n             ex = ast.expr_unary(ast.bitnot, e, ast.ann_none);\n         }\n \n@@ -1065,14 +1073,14 @@ impure fn parse_prefix_expr(parser p) -> @ast.expr {\n                 case (token.MINUS) {\n                     p.bump();\n                     auto e = parse_prefix_expr(p);\n-                    hi = e.span;\n+                    hi = e.span.hi;\n                     ex = ast.expr_unary(ast.neg, e, ast.ann_none);\n                 }\n \n                 case (token.STAR) {\n                     p.bump();\n                     auto e = parse_prefix_expr(p);\n-                    hi = e.span;\n+                    hi = e.span.hi;\n                     ex = ast.expr_unary(ast.deref, e, ast.ann_none);\n                 }\n \n@@ -1086,7 +1094,7 @@ impure fn parse_prefix_expr(parser p) -> @ast.expr {\n             p.bump();\n             auto m = parse_mutability(p);\n             auto e = parse_prefix_expr(p);\n-            hi = e.span;\n+            hi = e.span.hi;\n             ex = ast.expr_unary(ast.box(m), e, ast.ann_none);\n         }\n \n@@ -1144,15 +1152,15 @@ impure fn parse_more_binops(parser p, @ast.expr lhs, int min_prec)\n                 case (token.AS) {\n                     auto rhs = parse_ty(p);\n                     auto _as = ast.expr_cast(lhs, rhs, ast.ann_none);\n-                    auto span = @spanned(lhs.span, rhs.span, _as);\n+                    auto span = @spanned(lhs.span.lo, rhs.span.hi, _as);\n                     ret parse_more_binops(p, span, min_prec);\n                 }\n                 case (_) {\n                     auto rhs = parse_more_binops(p, parse_prefix_expr(p),\n                                                  cur.prec);\n                     auto bin = ast.expr_binary(cur.op, lhs, rhs,\n                                                ast.ann_none);\n-                    auto span = @spanned(lhs.span, rhs.span, bin);\n+                    auto span = @spanned(lhs.span.lo, rhs.span.hi, bin);\n                     ret parse_more_binops(p, span, min_prec);\n                 }\n             }\n@@ -1162,13 +1170,13 @@ impure fn parse_more_binops(parser p, @ast.expr lhs, int min_prec)\n }\n \n impure fn parse_assign_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto lhs = parse_binops(p);\n     alt (p.peek()) {\n         case (token.EQ) {\n             p.bump();\n             auto rhs = parse_expr(p);\n-            ret @spanned(lo, rhs.span,\n+            ret @spanned(lo, rhs.span.hi,\n                          ast.expr_assign(lhs, rhs, ast.ann_none));\n         }\n         case (token.BINOPEQ(?op)) {\n@@ -1188,19 +1196,19 @@ impure fn parse_assign_expr(parser p) -> @ast.expr {\n                 case (token.LSR) { aop = ast.lsr; }\n                 case (token.ASR) { aop = ast.asr; }\n             }\n-            ret @spanned(lo, rhs.span,\n+            ret @spanned(lo, rhs.span.hi,\n                          ast.expr_assign_op(aop, lhs, rhs, ast.ann_none));\n         }\n         case (token.SEND) {\n             p.bump();\n             auto rhs = parse_expr(p);\n-            ret @spanned(lo, rhs.span,\n+            ret @spanned(lo, rhs.span.hi,\n                          ast.expr_send(lhs, rhs, ast.ann_none));\n         }\n         case (token.LARROW) {\n             p.bump();\n             auto rhs = parse_expr(p);\n-            ret @spanned(lo, rhs.span,\n+            ret @spanned(lo, rhs.span.hi,\n                          ast.expr_recv(lhs, rhs, ast.ann_none));\n         }\n         case (_) { /* fall through */ }\n@@ -1209,21 +1217,20 @@ impure fn parse_assign_expr(parser p) -> @ast.expr {\n }\n \n impure fn parse_if_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n \n     expect(p, token.IF);\n     expect(p, token.LPAREN);\n     auto cond = parse_expr(p);\n     expect(p, token.RPAREN);\n     auto thn = parse_block(p);\n     let option.t[@ast.expr] els = none[@ast.expr];\n-    hi = thn.span;\n+    auto hi = thn.span.hi;\n     alt (p.peek()) {\n         case (token.ELSE) {\n             auto elexpr = parse_else_expr(p);\n             els = some(elexpr);\n-            hi = elexpr.span;\n+            hi = elexpr.span.hi;\n         }\n         case (_) { /* fall through */ }\n     }\n@@ -1239,29 +1246,27 @@ impure fn parse_else_expr(parser p) -> @ast.expr {\n         }\n         case (_) {\n             auto blk = parse_block(p);\n-            ret @spanned(blk.span, blk.span,\n+            ret @spanned(blk.span.lo, blk.span.hi,\n                          ast.expr_block(blk, ast.ann_none));\n         }\n     }\n }\n \n impure fn parse_head_local(parser p) -> @ast.decl {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     let @ast.local local;\n     if (p.peek() == token.AUTO) {\n         local = parse_auto_local(p);\n     } else {\n         local = parse_typed_local(p);\n     }\n-    auto hi = p.get_span();\n-    ret @spanned(lo, hi, ast.decl_local(local));\n+    ret @spanned(lo, p.get_hi_pos(), ast.decl_local(local));\n }\n \n \n \n impure fn parse_for_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     auto is_each = false;\n \n     expect(p, token.FOR);\n@@ -1278,10 +1283,10 @@ impure fn parse_for_expr(parser p) -> @ast.expr {\n     auto seq = parse_expr(p);\n     expect(p, token.RPAREN);\n     auto body = parse_block(p);\n-    hi = body.span;\n+    auto hi = body.span.hi;\n     if (is_each) {\n         ret @spanned(lo, hi, ast.expr_for_each(decl, seq, body,\n-                                               ast.ann_none));\n+                                                ast.ann_none));\n     } else {\n         ret @spanned(lo, hi, ast.expr_for(decl, seq, body,\n                                           ast.ann_none));\n@@ -1290,34 +1295,32 @@ impure fn parse_for_expr(parser p) -> @ast.expr {\n \n \n impure fn parse_while_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n \n     expect(p, token.WHILE);\n     expect (p, token.LPAREN);\n     auto cond = parse_expr(p);\n     expect(p, token.RPAREN);\n     auto body = parse_block(p);\n-    hi = body.span;\n+    auto hi = body.span.hi;\n     ret @spanned(lo, hi, ast.expr_while(cond, body, ast.ann_none));\n }\n \n impure fn parse_do_while_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n \n     expect(p, token.DO);\n     auto body = parse_block(p);\n     expect(p, token.WHILE);\n     expect (p, token.LPAREN);\n     auto cond = parse_expr(p);\n     expect(p, token.RPAREN);\n-    hi = cond.span;\n+    auto hi = cond.span.hi;\n     ret @spanned(lo, hi, ast.expr_do_while(body, cond, ast.ann_none));\n }\n \n impure fn parse_alt_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.ALT);\n     expect(p, token.LPAREN);\n     auto discriminant = parse_expr(p);\n@@ -1347,7 +1350,7 @@ impure fn parse_alt_expr(parser p) -> @ast.expr {\n \n             case (token.ELSE) {\n                 p.bump();\n-                auto hi = p.get_span();\n+                auto hi = p.get_hi_pos();\n                 auto pat = @spanned(lo, hi, ast.pat_wild(ast.ann_none));\n                 auto index = index_arm(pat);\n                 auto block = parse_block(p);\n@@ -1360,15 +1363,15 @@ impure fn parse_alt_expr(parser p) -> @ast.expr {\n             }\n         }\n     }\n+    auto hi = p.get_hi_pos();\n     p.bump();\n \n     auto expr = ast.expr_alt(discriminant, arms, ast.ann_none);\n-    auto hi = p.get_span();\n     ret @spanned(lo, hi, expr);\n }\n \n impure fn parse_spawn_expr(parser p) -> @ast.expr {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.SPAWN);\n \n     // FIXME: Parse domain and name\n@@ -1379,7 +1382,7 @@ impure fn parse_spawn_expr(parser p) -> @ast.expr {\n                                    token.RPAREN,\n                                    some(token.COMMA),\n                                    pf, p);\n-    auto hi = es.span;\n+    auto hi = es.span.hi;\n     auto spawn_expr = ast.expr_spawn(ast.dom_implicit,\n                                      option.none[str],\n                                      fn_expr,\n@@ -1404,7 +1407,7 @@ impure fn parse_expr_inner(parser p) -> @ast.expr {\n     alt (p.peek()) {\n         case (token.LBRACE) {\n             auto blk = parse_block(p);\n-            ret @spanned(blk.span, blk.span,\n+            ret @spanned(blk.span.lo, blk.span.hi,\n                          ast.expr_block(blk, ast.ann_none));\n         }\n         case (token.IF) {\n@@ -1451,21 +1454,20 @@ impure fn parse_initializer(parser p) -> option.t[ast.initializer] {\n }\n \n impure fn parse_pat(parser p) -> @ast.pat {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n+    auto hi = p.get_hi_pos();\n     auto pat;\n \n     alt (p.peek()) {\n         case (token.UNDERSCORE) {\n-            hi = p.get_span();\n             p.bump();\n             pat = ast.pat_wild(ast.ann_none);\n         }\n         case (token.QUES) {\n             p.bump();\n             alt (p.peek()) {\n                 case (token.IDENT(?id)) {\n-                    hi = p.get_span();\n+                    hi = p.get_hi_pos();\n                     p.bump();\n                     pat = ast.pat_bind(id, p.next_def_id(), ast.ann_none);\n                 }\n@@ -1478,7 +1480,7 @@ impure fn parse_pat(parser p) -> @ast.pat {\n         }\n         case (token.IDENT(?id)) {\n             auto tag_path = parse_path(p, GREEDY);\n-            hi = tag_path.span;\n+            hi = tag_path.span.hi;\n \n             let vec[@ast.pat] args;\n             alt (p.peek()) {\n@@ -1487,7 +1489,7 @@ impure fn parse_pat(parser p) -> @ast.pat {\n                     auto a = parse_seq[@ast.pat](token.LPAREN, token.RPAREN,\n                                                  some(token.COMMA), f, p);\n                     args = a.node;\n-                    hi = a.span;\n+                    hi = a.span.hi;\n                 }\n                 case (_) { args = vec(); }\n             }\n@@ -1497,7 +1499,7 @@ impure fn parse_pat(parser p) -> @ast.pat {\n         }\n         case (_) {\n             auto lit = parse_lit(p);\n-            hi = lit.span;\n+            hi = lit.span.hi;\n             pat = ast.pat_lit(@lit, ast.ann_none);\n         }\n     }\n@@ -1527,19 +1529,17 @@ impure fn parse_auto_local(parser p) -> @ast.local {\n }\n \n impure fn parse_let(parser p) -> @ast.decl {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.LET);\n     auto local = parse_typed_local(p);\n-    auto hi = p.get_span();\n-    ret @spanned(lo, hi, ast.decl_local(local));\n+    ret @spanned(lo, p.get_hi_pos(), ast.decl_local(local));\n }\n \n impure fn parse_auto(parser p) -> @ast.decl {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.AUTO);\n     auto local = parse_auto_local(p);\n-    auto hi = p.get_span();\n-    ret @spanned(lo, hi, ast.decl_local(local));\n+    ret @spanned(lo, p.get_hi_pos(), ast.decl_local(local));\n }\n \n impure fn parse_stmt(parser p) -> @ast.stmt {\n@@ -1552,39 +1552,38 @@ impure fn parse_stmt(parser p) -> @ast.stmt {\n \n impure fn parse_crate_stmt(parser p) -> @ast.stmt {\n     auto cdir = parse_crate_directive(p);\n-    ret @spanned(cdir.span, cdir.span,\n+    ret @spanned(cdir.span.lo, cdir.span.hi,\n                  ast.stmt_crate_directive(@cdir));\n }\n \n impure fn parse_source_stmt(parser p) -> @ast.stmt {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     alt (p.peek()) {\n \n         case (token.LET) {\n             auto decl = parse_let(p);\n-            auto hi = p.get_span();\n-            ret @spanned(lo, hi, ast.stmt_decl(decl, none[@ts_ann]));\n+            ret @spanned(lo, decl.span.hi,\n+                         ast.stmt_decl(decl, none[@ts_ann]));\n         }\n \n         case (token.AUTO) {\n             auto decl = parse_auto(p);\n-            auto hi = p.get_span();\n-            ret @spanned(lo, hi, ast.stmt_decl(decl, none[@ts_ann]));\n+            ret @spanned(lo, decl.span.hi,\n+                         ast.stmt_decl(decl, none[@ts_ann]));\n         }\n \n         case (_) {\n             if (peeking_at_item(p)) {\n                 // Might be a local item decl.\n                 auto i = parse_item(p);\n-                auto hi = i.span;\n+                auto hi = i.span.hi;\n                 auto decl = @spanned(lo, hi, ast.decl_item(i));\n                 ret @spanned(lo, hi, ast.stmt_decl(decl, none[@ts_ann]));\n \n             } else {\n                 // Remainder are line-expr stmts.\n                 auto e = parse_expr(p);\n-                auto hi = p.get_span();\n-                ret @spanned(lo, hi, ast.stmt_expr(e, none[@ts_ann]));\n+                ret @spanned(lo, e.span.hi, ast.stmt_expr(e, none[@ts_ann]));\n             }\n         }\n     }\n@@ -1678,7 +1677,7 @@ fn stmt_ends_with_semi(@ast.stmt stmt) -> bool {\n }\n \n impure fn parse_block(parser p) -> ast.block {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n \n     let vec[@ast.stmt] stmts = vec();\n     let option.t[@ast.expr] expr = none[@ast.expr];\n@@ -1731,7 +1730,7 @@ impure fn parse_block(parser p) -> ast.block {\n         }\n     }\n \n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     p.bump();\n \n     auto bloc = index_block(stmts, expr);\n@@ -1774,7 +1773,7 @@ impure fn parse_fn_decl(parser p, ast.effect eff) -> ast.fn_decl {\n         p.bump();\n         output = parse_ty(p);\n     } else {\n-        output = @spanned(inputs.span, inputs.span, ast.ty_nil);\n+        output = @spanned(inputs.span.lo, inputs.span.hi, ast.ty_nil);\n     }\n     ret rec(effect=eff, inputs=inputs.node, output=output);\n }\n@@ -1795,13 +1794,13 @@ impure fn parse_fn_header(parser p)\n }\n \n impure fn parse_item_fn_or_iter(parser p, ast.effect eff) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto proto = parse_proto(p);\n     auto t = parse_fn_header(p);\n     auto f = parse_fn(p, eff, proto);\n     auto item = ast.item_fn(t._0, f, t._1,\n                             p.next_def_id(), ast.ann_none);\n-    ret @spanned(lo, f.body.span, item);\n+    ret @spanned(lo, f.body.span.hi, item);\n }\n \n \n@@ -1813,18 +1812,18 @@ impure fn parse_obj_field(parser p) -> ast.obj_field {\n }\n \n impure fn parse_method(parser p) -> @ast.method {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     auto eff = parse_effect(p);\n     auto proto = parse_proto(p);\n     auto ident = parse_ident(p);\n     auto f = parse_fn(p, eff, proto);\n     auto meth = rec(ident=ident, meth=f,\n                     id=p.next_def_id(), ann=ast.ann_none);\n-    ret @spanned(lo, f.body.span, meth);\n+    ret @spanned(lo, f.body.span.hi, meth);\n }\n \n impure fn parse_item_obj(parser p, ast.layer lyr) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.OBJ);\n     auto ident = parse_ident(p);\n     auto ty_params = parse_ty_params(p);\n@@ -1852,7 +1851,7 @@ impure fn parse_item_obj(parser p, ast.layer lyr) -> @ast.item {\n             }\n         }\n     }\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.RBRACE);\n \n     let ast._obj ob = rec(fields=fields.node,\n@@ -1880,40 +1879,40 @@ impure fn parse_mod_items(parser p, token.token term) -> ast._mod {\n }\n \n impure fn parse_item_const(parser p) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.CONST);\n     auto ty = parse_ty(p);\n     auto id = parse_ident(p);\n     expect(p, token.EQ);\n     auto e = parse_expr(p);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     auto item = ast.item_const(id, ty, e, p.next_def_id(), ast.ann_none);\n     ret @spanned(lo, hi, item);\n }\n \n impure fn parse_item_mod(parser p) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.MOD);\n     auto id = parse_ident(p);\n     expect(p, token.LBRACE);\n     auto m = parse_mod_items(p, token.RBRACE);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.RBRACE);\n     auto item = ast.item_mod(id, m, p.next_def_id());\n     ret @spanned(lo, hi, item);\n }\n \n impure fn parse_item_native_type(parser p) -> @ast.native_item {\n     auto t = parse_type_decl(p);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     auto item = ast.native_item_ty(t._1, p.next_def_id());\n     ret @spanned(t._0, hi, item);\n }\n \n impure fn parse_item_native_fn(parser p, ast.effect eff) -> @ast.native_item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.FN);\n     auto t = parse_fn_header(p);\n     auto decl = parse_fn_decl(p, eff);\n@@ -1922,7 +1921,7 @@ impure fn parse_item_native_fn(parser p, ast.effect eff) -> @ast.native_item {\n         p.bump();\n         link_name = some[str](parse_str_lit_or_env_ident(p));\n     }\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     auto item = ast.native_item_fn(t._0, link_name, decl,\n                                    t._1, p.next_def_id(),\n@@ -1984,7 +1983,7 @@ fn default_native_name(session.session sess, str id) -> str {\n }\n \n impure fn parse_item_native_mod(parser p) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.NATIVE);\n     auto abi = ast.native_abi_cdecl;\n     if (p.peek() != token.MOD) {\n@@ -2010,14 +2009,14 @@ impure fn parse_item_native_mod(parser p) -> @ast.item {\n     }\n     expect(p, token.LBRACE);\n     auto m = parse_native_mod_items(p, native_name, abi);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.RBRACE);\n     auto item = ast.item_native_mod(id, m, p.next_def_id());\n     ret @spanned(lo, hi, item);\n }\n \n-impure fn parse_type_decl(parser p) -> tup(span, ast.ident) {\n-    auto lo = p.get_span();\n+impure fn parse_type_decl(parser p) -> tup(uint, ast.ident) {\n+    auto lo = p.get_lo_pos();\n     expect(p, token.TYPE);\n     auto id = parse_ident(p);\n     ret tup(lo, id);\n@@ -2029,14 +2028,14 @@ impure fn parse_item_type(parser p) -> @ast.item {\n \n     expect(p, token.EQ);\n     auto ty = parse_ty(p);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     auto item = ast.item_ty(t._1, ty, tps, p.next_def_id(), ast.ann_none);\n     ret @spanned(t._0, hi, item);\n }\n \n impure fn parse_item_tag(parser p) -> @ast.item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.TAG);\n     auto id = parse_ident(p);\n     auto ty_params = parse_ty_params(p);\n@@ -2047,7 +2046,7 @@ impure fn parse_item_tag(parser p) -> @ast.item {\n         auto tok = p.peek();\n         alt (tok) {\n             case (token.IDENT(?name)) {\n-                auto vlo = p.get_span();\n+                auto vlo = p.get_lo_pos();\n                 p.bump();\n \n                 let vec[ast.variant_arg] args = vec();\n@@ -2065,7 +2064,7 @@ impure fn parse_item_tag(parser p) -> @ast.item {\n                     case (_) { /* empty */ }\n                 }\n \n-                auto vhi = p.get_span();\n+                auto vhi = p.get_hi_pos();\n                 expect(p, token.SEMI);\n \n                 auto id = p.next_def_id();\n@@ -2079,9 +2078,9 @@ impure fn parse_item_tag(parser p) -> @ast.item {\n             }\n         }\n     }\n+    auto hi = p.get_hi_pos();\n     p.bump();\n \n-    auto hi = p.get_span();\n     auto item = ast.item_tag(id, variants, ty_params, p.next_def_id(),\n                              ast.ann_none);\n     ret @spanned(lo, hi, item);\n@@ -2203,12 +2202,12 @@ impure fn parse_item(parser p) -> @ast.item {\n }\n \n impure fn parse_meta_item(parser p) -> @ast.meta_item {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     auto ident = parse_ident(p);\n     expect(p, token.EQ);\n     alt (p.peek()) {\n         case (token.LIT_STR(?s)) {\n+            auto hi = p.get_hi_pos();\n             p.bump();\n             ret @spanned(lo, hi, rec(name = ident, value = s));\n         }\n@@ -2226,8 +2225,6 @@ impure fn parse_meta(parser p) -> vec[@ast.meta_item] {\n }\n \n impure fn parse_optional_meta(parser p) -> vec[@ast.meta_item] {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n     alt (p.peek()) {\n         case (token.LPAREN) {\n             ret parse_meta(p);\n@@ -2240,11 +2237,11 @@ impure fn parse_optional_meta(parser p) -> vec[@ast.meta_item] {\n }\n \n impure fn parse_use(parser p) -> @ast.view_item {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     expect(p, token.USE);\n     auto ident = parse_ident(p);\n     auto metadata = parse_optional_meta(p);\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     auto use_decl = ast.view_item_use(ident, metadata, p.next_def_id(),\n                                       none[int]);\n@@ -2254,14 +2251,14 @@ impure fn parse_use(parser p) -> @ast.view_item {\n impure fn parse_rest_import_name(parser p, ast.ident first,\n                                  option.t[ast.ident] def_ident)\n         -> @ast.view_item {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     let vec[ast.ident] identifiers = vec(first);\n     while (p.peek() != token.SEMI) {\n         expect(p, token.DOT);\n         auto i = parse_ident(p);\n         identifiers += vec(i);\n     }\n+    auto hi = p.get_hi_pos();\n     p.bump();\n     auto defined_id;\n     alt (def_ident) {\n@@ -2316,10 +2313,10 @@ impure fn parse_import(parser p) -> @ast.view_item {\n }\n \n impure fn parse_export(parser p) -> @ast.view_item {\n-    auto lo = p.get_span();\n+    auto lo = p.get_lo_pos();\n     expect(p, token.EXPORT);\n     auto id = parse_ident(p);\n-    auto hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.SEMI);\n     ret @spanned(lo, hi, ast.view_item_export(id));\n }\n@@ -2373,12 +2370,11 @@ impure fn parse_native_view(parser p, ast.native_mod_index index)\n \n \n impure fn parse_crate_from_source_file(parser p) -> @ast.crate {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     auto m = parse_mod_items(p, token.EOF);\n     let vec[@ast.crate_directive] cdirs = vec();\n-    ret @spanned(lo, hi, rec(directives=cdirs,\n-                             module=m));\n+    ret @spanned(lo, p.get_lo_pos(), rec(directives=cdirs,\n+                                         module=m));\n }\n \n // Logic for parsing crate files (.rc)\n@@ -2389,23 +2385,22 @@ impure fn parse_crate_from_source_file(parser p) -> @ast.crate {\n \n impure fn parse_crate_directive(parser p) -> ast.crate_directive\n {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n+    auto lo = p.get_lo_pos();\n     alt (p.peek()) {\n         case (token.AUTH) {\n             p.bump();\n             auto n = parse_path(p, GREEDY);\n             expect(p, token.EQ);\n             auto e = parse_effect(p);\n-            hi = p.get_span();\n+            auto hi = p.get_hi_pos();\n             expect(p, token.SEMI);\n             ret spanned(lo, hi, ast.cdir_auth(n, e));\n         }\n \n         case (token.META) {\n             p.bump();\n             auto mis = parse_meta(p);\n-            hi = p.get_span();\n+            auto hi = p.get_hi_pos();\n             expect(p, token.SEMI);\n             ret spanned(lo, hi, ast.cdir_meta(mis));\n         }\n@@ -2429,7 +2424,7 @@ impure fn parse_crate_directive(parser p) -> ast.crate_directive\n                 // mod x = \"foo.rs\";\n \n                 case (token.SEMI) {\n-                    hi = p.get_span();\n+                    auto hi = p.get_hi_pos();\n                     p.bump();\n                     ret spanned(lo, hi, ast.cdir_src_mod(id, file_opt));\n                 }\n@@ -2439,7 +2434,7 @@ impure fn parse_crate_directive(parser p) -> ast.crate_directive\n                 case (token.LBRACE) {\n                     p.bump();\n                     auto cdirs = parse_crate_directives(p, token.RBRACE);\n-                    hi = p.get_span();\n+                    auto hi = p.get_hi_pos();\n                     expect(p, token.RBRACE);\n                     ret spanned(lo, hi,\n                                 ast.cdir_dir_mod(id, file_opt, cdirs));\n@@ -2460,29 +2455,29 @@ impure fn parse_crate_directive(parser p) -> ast.crate_directive\n             expect(p, token.RPAREN);\n             expect(p, token.LBRACE);\n             auto v = parse_crate_directives(p, token.RBRACE);\n-            hi = p.get_span();\n+            auto hi = p.get_hi_pos();\n             expect(p, token.RBRACE);\n             ret spanned(lo, hi, ast.cdir_let(id, x, v));\n         }\n \n         case (token.USE) {\n             auto vi = parse_view_item(p);\n-            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+            ret spanned(lo, vi.span.hi, ast.cdir_view_item(vi));\n         }\n \n         case (token.IMPORT) {\n             auto vi = parse_view_item(p);\n-            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+            ret spanned(lo, vi.span.hi, ast.cdir_view_item(vi));\n         }\n \n         case (token.EXPORT) {\n             auto vi = parse_view_item(p);\n-            ret spanned(lo, vi.span, ast.cdir_view_item(vi));\n+            ret spanned(lo, vi.span.hi, ast.cdir_view_item(vi));\n         }\n \n         case (_) {\n             auto x = parse_expr(p);\n-            ret spanned(lo, x.span, ast.cdir_expr(x));\n+            ret spanned(lo, x.span.hi, ast.cdir_expr(x));\n         }\n     }\n     fail;\n@@ -2503,13 +2498,13 @@ impure fn parse_crate_directives(parser p, token.token term)\n }\n \n impure fn parse_crate_from_crate_file(parser p) -> @ast.crate {\n-    auto lo = p.get_span();\n-    auto hi = lo;\n-    auto prefix = std.fs.dirname(lo.filename);\n+    auto lo = p.get_lo_pos();\n+    auto prefix = std.fs.dirname(p.get_filemap().name);\n     auto cdirs = parse_crate_directives(p, token.EOF);\n-    auto m = eval.eval_crate_directives_to_mod(p, p.get_env(),\n+    auto cx = @rec(p=p, sess=p.get_session(), mutable chpos=p.get_chpos());\n+    auto m = eval.eval_crate_directives_to_mod(cx, p.get_env(),\n                                                cdirs, prefix);\n-    hi = p.get_span();\n+    auto hi = p.get_hi_pos();\n     expect(p, token.EOF);\n     ret @spanned(lo, hi, rec(directives=cdirs,\n                              module=m));"}, {"sha": "3c03d0fc22b0b4684d8cd12f06880fb9c67cb59a", "filename": "src/comp/middle/trans.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fmiddle%2Ftrans.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -4939,8 +4939,9 @@ fn trans_check_expr(@block_ctxt cx, @ast.expr e) -> result {\n \n fn trans_fail(@block_ctxt cx, common.span sp, str fail_str) -> result {\n     auto V_fail_str = p2i(C_cstr(cx.fcx.ccx, fail_str));\n-    auto V_filename = p2i(C_cstr(cx.fcx.ccx, sp.filename));\n-    auto V_line = sp.lo.line as int;\n+    auto loc = cx.fcx.ccx.sess.lookup_pos(sp.lo);\n+    auto V_filename = p2i(C_cstr(cx.fcx.ccx, loc.filename));\n+    auto V_line = loc.line as int;\n     auto args = vec(V_fail_str, V_filename, C_int(V_line));\n \n     auto sub = trans_upcall(cx, \"upcall_fail\", args);"}, {"sha": "8c09393a3c6d270f069542a927604151c418cdb1", "filename": "src/comp/pretty/pprust.rs", "status": "modified", "additions": 4, "deletions": 15, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fpretty%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Fpretty%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Fpretty%2Fpprust.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -159,8 +159,7 @@ impure fn print_type(ps s, &@ast.ty ty) {\n             fn get_span(&ast.ty_field f) -> common.span {\n               // Try to reconstruct the span for this field\n               auto sp = f.mt.ty.span;\n-              auto hi = rec(line=sp.hi.line,\n-                            col=sp.hi.col + _str.char_len(f.ident) + 1u);\n+              auto hi = sp.hi + _str.char_len(f.ident) + 1u;\n               ret rec(hi=hi with sp);\n             }\n             auto f = print_field;\n@@ -329,14 +328,9 @@ impure fn print_item(ps s, @ast.item item) {\n }\n \n impure fn print_block(ps s, ast.block blk) {\n-    auto cur_line = 0u;\n     maybe_print_comment(s, blk.span.lo);\n     bopen(s);\n     for (@ast.stmt st in blk.node.stmts) {\n-        if (cur_line != 0u && st.span.lo.line > cur_line + 1u) {\n-            line(s.s);\n-        }\n-        cur_line = st.span.hi.line;\n         maybe_print_comment(s, st.span.lo);\n         alt (st.node) {\n           case (ast.stmt_decl(?decl,_)) {print_decl(s, decl);}\n@@ -347,9 +341,6 @@ impure fn print_block(ps s, ast.block blk) {\n     }\n     alt (blk.node.expr) {\n         case (option.some[@ast.expr](?expr)) {\n-            if (cur_line != 0u && expr.span.lo.line > cur_line + 1u) {\n-                line(s.s);\n-            }\n             print_expr(s, expr);\n             if (!maybe_print_line_comment(s, expr.span)) {line(s.s);}\n         }\n@@ -958,12 +949,11 @@ fn next_comment(ps s) -> option.t[lexer.cmnt] {\n     }\n }\n \n-impure fn maybe_print_comment(ps s, common.pos pos) {\n+impure fn maybe_print_comment(ps s, uint pos) {\n     while (true) {\n         alt (next_comment(s)) {\n             case (option.some[lexer.cmnt](?cmnt)) {\n-                if (cmnt.pos.line < pos.line ||\n-                    (cmnt.pos.line == pos.line && cmnt.pos.col < pos.col)) {\n+                if (cmnt.pos < pos) {\n                     print_comment(s, cmnt.val);\n                     if (cmnt.space_after) {line(s.s);}\n                     s.cur_cmnt += 1u;\n@@ -977,8 +967,7 @@ impure fn maybe_print_comment(ps s, common.pos pos) {\n impure fn maybe_print_line_comment(ps s, common.span span) -> bool {\n     alt (next_comment(s)) {\n         case (option.some[lexer.cmnt](?cmnt)) {\n-            if (span.hi.line == cmnt.pos.line &&\n-                span.hi.col + 4u >= cmnt.pos.col) {\n+            if (span.hi + 4u >= cmnt.pos) {\n                 wrd(s.s, \" \");\n                 print_comment(s, cmnt.val);\n                 s.cur_cmnt += 1u;"}, {"sha": "981577abc57a222f648f82ea352f7eb80934802f", "filename": "src/comp/rustc.rc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Frustc.rc", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Frustc.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Frustc.rc?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -7,6 +7,7 @@ mod front {\n     mod ast;\n     mod creader;\n     mod extfmt;\n+    mod codemap;\n     mod lexer;\n     mod parser;\n     mod token;"}, {"sha": "b33a7db278c2d737090ec78fee47b5522eee48a2", "filename": "src/comp/util/common.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Futil%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1af3174fe3b565371a5978381f604ea9c01e86d3/src%2Fcomp%2Futil%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Futil%2Fcommon.rs?ref=1af3174fe3b565371a5978381f604ea9c01e86d3", "patch": "@@ -5,8 +5,7 @@ import front.ast;\n \n \n type filename = str;\n-type pos = rec(uint line, uint col);\n-type span = rec(filename filename, pos lo, pos hi);\n+type span = rec(uint lo, uint hi);\n type spanned[T] = rec(T node, span span);\n \n tag ty_mach {"}]}