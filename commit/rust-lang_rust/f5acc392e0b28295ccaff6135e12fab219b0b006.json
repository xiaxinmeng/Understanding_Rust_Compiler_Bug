{"sha": "f5acc392e0b28295ccaff6135e12fab219b0b006", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY1YWNjMzkyZTBiMjgyOTVjY2FmZjYxMzVlMTJmYWIyMTliMGIwMDY=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2017-07-27T14:59:30Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2017-07-31T13:15:44Z"}, "message": "async-llvm(23): Let the main thread also do LLVM work in order to reduce memory pressure.", "tree": {"sha": "2280fb6c300cc4ea6b9197d8f2bee65bb2b328a1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2280fb6c300cc4ea6b9197d8f2bee65bb2b328a1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f5acc392e0b28295ccaff6135e12fab219b0b006", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f5acc392e0b28295ccaff6135e12fab219b0b006", "html_url": "https://github.com/rust-lang/rust/commit/f5acc392e0b28295ccaff6135e12fab219b0b006", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f5acc392e0b28295ccaff6135e12fab219b0b006/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "88192785233d0fed6cc8702e3067f02208e62a14", "url": "https://api.github.com/repos/rust-lang/rust/commits/88192785233d0fed6cc8702e3067f02208e62a14", "html_url": "https://github.com/rust-lang/rust/commit/88192785233d0fed6cc8702e3067f02208e62a14"}], "stats": {"total": 316, "additions": 218, "deletions": 98}, "files": [{"sha": "649b16f17a9298387c1e707f66acbffdce90f661", "filename": "src/librustc_trans/back/write.rs", "status": "modified", "additions": 142, "deletions": 35, "changes": 177, "blob_url": "https://github.com/rust-lang/rust/blob/f5acc392e0b28295ccaff6135e12fab219b0b006/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5acc392e0b28295ccaff6135e12fab219b0b006/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fwrite.rs?ref=f5acc392e0b28295ccaff6135e12fab219b0b006", "patch": "@@ -764,7 +764,7 @@ pub fn start_async_translation(sess: &Session,\n     });\n \n     let (shared_emitter, shared_emitter_main) = SharedEmitter::new();\n-    let (trans_worker_send, _trans_worker_receive) = channel();\n+    let (trans_worker_send, trans_worker_receive) = channel();\n     let (coordinator_send, coordinator_receive) = channel();\n \n     let coordinator_thread = start_executing_work(sess,\n@@ -792,6 +792,7 @@ pub fn start_async_translation(sess: &Session,\n         time_graph,\n         output_filenames: crate_output.clone(),\n         coordinator_send,\n+        trans_worker_receive,\n         shared_emitter_main,\n         future: coordinator_thread\n     }\n@@ -987,7 +988,7 @@ pub fn dump_incremental_data(trans: &CrateTranslation) {\n     eprintln!(\"incremental: re-using {} out of {} modules\", reuse, trans.modules.len());\n }\n \n-pub struct WorkItem {\n+struct WorkItem {\n     mtrans: ModuleTranslation,\n     config: ModuleConfig,\n     output_names: OutputFilenames\n@@ -1074,9 +1075,11 @@ enum Message {\n         result: Result<CompiledModule, ()>,\n         worker_id: usize,\n     },\n-    WorkItem(WorkItem),\n-    CheckErrorMessages,\n-    TranslationDone,\n+    TranslationDone {\n+        llvm_work_item: WorkItem,\n+        is_last: bool\n+    },\n+    TranslateItem,\n }\n \n struct Diagnostic {\n@@ -1085,6 +1088,13 @@ struct Diagnostic {\n     lvl: Level,\n }\n \n+#[derive(PartialEq, Clone, Copy, Debug)]\n+enum TransWorkerState {\n+    Idle,\n+    Translating,\n+    LLVMing,\n+}\n+\n fn start_executing_work(sess: &Session,\n                         shared_emitter: SharedEmitter,\n                         trans_worker_send: Sender<Message>,\n@@ -1189,7 +1199,6 @@ fn start_executing_work(sess: &Session,\n     // Before that work finishes, however, we may acquire a token. In that case\n     // we actually wastefully acquired the token, so we relinquish it back to\n     // the jobserver.\n-\n     thread::spawn(move || {\n         let mut worker_id_counter = 0;\n         let mut free_worker_ids = Vec::new();\n@@ -1211,13 +1220,74 @@ fn start_executing_work(sess: &Session,\n         let mut work_items = Vec::new();\n         let mut tokens = Vec::new();\n \n+        let mut trans_worker_state = TransWorkerState::Idle;\n         let mut running = 0;\n \n-        while !translation_done || work_items.len() > 0 || running > 0 {\n+        while !translation_done ||\n+              work_items.len() > 0 ||\n+              running > 0 ||\n+              trans_worker_state != TransWorkerState::Idle {\n+\n+            if !translation_done {\n+                if trans_worker_state == TransWorkerState::Idle {\n+                    // Translation is not done yet, so there are two things the\n+                    // translation worker could do:\n+                    //\n+                    // (1) Translate another CGU\n+                    // (2) Run an already translated CGU through LLVM\n+                    //\n+                    // Option (2) makes sense if there's already enough work for\n+                    // all the other workers. In that case it's better to run\n+                    // a CGU through LLVM, so its resources can be freed.\n+                    //\n+                    // However, it's not trivial to determines what \"enough work\n+                    // for all the other workers\" means because:\n+                    //\n+                    // (1) We don't know how long the currently working workers\n+                    //     will need to finish their work package, and\n+                    // (2) we don't know how many idle workers would be available\n+                    //     because that is dynamically decided by the jobserver.\n+                    //\n+                    // TODO: Come up with a useful heuristic.\n+                    if work_items.len() <= 4 {\n+                        trans_worker_send.send(Message::TranslateItem).unwrap();\n+                        trans_worker_state = TransWorkerState::Translating;\n+                    } else {\n+                        let item = work_items.pop().unwrap();\n+                        let cgcx = CodegenContext {\n+                            worker: TRANS_WORKER_ID,\n+                            .. cgcx.clone()\n+                        };\n+                        trans_worker_state = TransWorkerState::LLVMing;\n+                        spawn_work(cgcx, item);\n+                    }\n+                }\n+            } else {\n+                match trans_worker_state {\n+                    TransWorkerState::Idle => {\n+                        if let Some(item) = work_items.pop() {\n+                            let cgcx = CodegenContext {\n+                                worker: TRANS_WORKER_ID,\n+                                .. cgcx.clone()\n+                            };\n+\n+                            trans_worker_state = TransWorkerState::LLVMing;\n+                            spawn_work(cgcx, item);\n+                        }\n+                    }\n+                    TransWorkerState::Translating => {\n+                        bug!(\"trans worker should not be translating after \\\n+                              translation was already completed\")\n+                    }\n+                    TransWorkerState::LLVMing => {\n+                        // Already making good use of that token\n+                    }\n+                }\n+            }\n \n             // Spin up what work we can, only doing this while we've got available\n             // parallelism slots and work left to spawn.\n-            while work_items.len() > 0 && running < tokens.len() + 1 {\n+            while work_items.len() > 0 && running < tokens.len() {\n                 let item = work_items.pop().unwrap();\n                 let worker_id = get_worker_id(&mut free_worker_ids);\n \n@@ -1231,7 +1301,7 @@ fn start_executing_work(sess: &Session,\n             }\n \n             // Relinquish accidentally acquired extra tokens\n-            tokens.truncate(running.saturating_sub(1));\n+            tokens.truncate(running);\n \n             match coordinator_receive.recv().unwrap() {\n                 // Save the token locally and the next turn of the loop will use\n@@ -1242,15 +1312,25 @@ fn start_executing_work(sess: &Session,\n                         tokens.push(token);\n                     } else {\n                         shared_emitter.fatal(\"failed to acquire jobserver token\");\n-                        drop(trans_worker_send.send(Message::CheckErrorMessages));\n                         // Exit the coordinator thread\n                         panic!()\n                     }\n                 }\n \n-                Message::WorkItem(work_item) => {\n-                    work_items.push(work_item);\n-                    helper.request_token();\n+                Message::TranslationDone { llvm_work_item, is_last } => {\n+                    work_items.insert(0, llvm_work_item);\n+\n+                    if is_last {\n+                        // If this is the last, don't request a token because\n+                        // the trans worker thread will be free to handle this\n+                        // immediately.\n+                        translation_done = true;\n+                    } else {\n+                        helper.request_token();\n+                    }\n+\n+                    assert_eq!(trans_worker_state, TransWorkerState::Translating);\n+                    trans_worker_state = TransWorkerState::Idle;\n                 }\n \n                 // If a thread exits successfully then we drop a token associated\n@@ -1262,10 +1342,14 @@ fn start_executing_work(sess: &Session,\n                 // Note that if the thread failed that means it panicked, so we\n                 // abort immediately.\n                 Message::Done { result: Ok(compiled_module), worker_id } => {\n-                    drop(tokens.pop());\n-                    running -= 1;\n-                    free_worker_ids.push(worker_id);\n-                    drop(trans_worker_send.send(Message::CheckErrorMessages));\n+                    if worker_id == TRANS_WORKER_ID {\n+                        assert_eq!(trans_worker_state, TransWorkerState::LLVMing);\n+                        trans_worker_state = TransWorkerState::Idle;\n+                    } else {\n+                        drop(tokens.pop());\n+                        running -= 1;\n+                        free_worker_ids.push(worker_id);\n+                    }\n \n                     match compiled_module.kind {\n                         ModuleKind::Regular => {\n@@ -1283,15 +1367,11 @@ fn start_executing_work(sess: &Session,\n                 }\n                 Message::Done { result: Err(()), worker_id: _ } => {\n                     shared_emitter.fatal(\"aborting due to worker thread panic\");\n-                    drop(trans_worker_send.send(Message::CheckErrorMessages));\n                     // Exit the coordinator thread\n                     panic!()\n                 }\n-                Message::TranslationDone => {\n-                    translation_done = true;\n-                }\n-                msg @ Message::CheckErrorMessages => {\n-                    bug!(\"unexpected message: {:?}\", msg);\n+                Message::TranslateItem => {\n+                    bug!(\"the coordinator should not receive translation requests\")\n                 }\n             }\n         }\n@@ -1316,10 +1396,6 @@ fn spawn_work(cgcx: CodegenContext, work: WorkItem) {\n     let depth = time_depth();\n \n     thread::spawn(move || {\n-        let _timing_guard = cgcx.time_graph\n-                                .as_ref()\n-                                .map(|tg| tg.start(time_graph::TimelineId(cgcx.worker),\n-                                                   LLVM_WORK_PACKAGE_KIND));\n         set_time_depth(depth);\n \n         // Set up a destructor which will fire off a message that we're done as\n@@ -1362,7 +1438,13 @@ fn spawn_work(cgcx: CodegenContext, work: WorkItem) {\n         // we just ignore the result and then send off our message saying that\n         // we're done, which if `execute_work_item` failed is unlikely to be\n         // seen by the main thread, but hey we might as well try anyway.\n-        bomb.result = Some(execute_work_item(&cgcx, work).unwrap());\n+        bomb.result = {\n+            let _timing_guard = cgcx.time_graph\n+                                .as_ref()\n+                                .map(|tg| tg.start(time_graph::TimelineId(cgcx.worker),\n+                                                   LLVM_WORK_PACKAGE_KIND));\n+            Some(execute_work_item(&cgcx, work).unwrap())\n+        };\n     });\n }\n \n@@ -1578,6 +1660,7 @@ pub struct OngoingCrateTranslation {\n \n     time_graph: Option<TimeGraph>,\n     coordinator_send: Sender<Message>,\n+    trans_worker_receive: Receiver<Message>,\n     shared_emitter_main: SharedEmitterMain,\n     future: thread::JoinHandle<CompiledModules>,\n }\n@@ -1645,25 +1728,49 @@ impl OngoingCrateTranslation {\n \n     pub fn submit_translated_module_to_llvm(&self,\n                                             sess: &Session,\n-                                            mtrans: ModuleTranslation) {\n+                                            mtrans: ModuleTranslation,\n+                                            is_last: bool) {\n         let module_config = match mtrans.kind {\n             ModuleKind::Regular => self.regular_module_config.clone(sess),\n             ModuleKind::Metadata => self.metadata_module_config.clone(sess),\n             ModuleKind::Allocator => self.allocator_module_config.clone(sess),\n         };\n \n-        let work_item = build_work_item(mtrans,\n-                                        module_config,\n-                                        self.output_filenames.clone());\n+        let llvm_work_item = build_work_item(mtrans,\n+                                             module_config,\n+                                             self.output_filenames.clone());\n \n-        drop(self.coordinator_send.send(Message::WorkItem(work_item)));\n+        drop(self.coordinator_send.send(Message::TranslationDone {\n+            llvm_work_item,\n+            is_last\n+        }));\n     }\n \n-    pub fn signal_translation_done(&self) {\n-        drop(self.coordinator_send.send(Message::TranslationDone));\n+    pub fn submit_pre_translated_module_to_llvm(&self,\n+                                                sess: &Session,\n+                                                mtrans: ModuleTranslation,\n+                                                is_last: bool) {\n+        self.wait_for_signal_to_translate_item();\n+        self.check_for_errors(sess);\n+        self.submit_translated_module_to_llvm(sess, mtrans, is_last);\n     }\n \n     pub fn check_for_errors(&self, sess: &Session) {\n         self.shared_emitter_main.check(sess, false);\n     }\n+\n+    pub fn wait_for_signal_to_translate_item(&self) {\n+        match self.trans_worker_receive.recv() {\n+            Ok(Message::TranslateItem) => {\n+                // Nothing to do\n+            }\n+            Ok(message) => {\n+                panic!(\"unexpected message: {:?}\", message)\n+            }\n+            Err(_) => {\n+                // One of the LLVM threads must have panicked, fall through so\n+                // error handling can be reached.\n+            }\n+        }\n+    }\n }"}, {"sha": "2d1f43aff571becba6eacbd19429581d8d00af64", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 76, "deletions": 63, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/f5acc392e0b28295ccaff6135e12fab219b0b006/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f5acc392e0b28295ccaff6135e12fab219b0b006/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=f5acc392e0b28295ccaff6135e12fab219b0b006", "patch": "@@ -981,14 +981,15 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n             linker_info,\n             false);\n \n-        ongoing_translation.submit_translated_module_to_llvm(tcx.sess, metadata_module);\n-        ongoing_translation.signal_translation_done();\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, metadata_module, true);\n \n         assert_and_save_dep_graph(tcx,\n                                   incremental_hashes_map,\n                                   metadata_incr_hashes,\n                                   link_meta);\n \n+        ongoing_translation.check_for_errors(tcx.sess);\n+\n         return ongoing_translation;\n     }\n \n@@ -1032,35 +1033,87 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         linker_info,\n         no_integrated_as);\n \n-    ongoing_translation.submit_translated_module_to_llvm(tcx.sess, metadata_module);\n+    // Translate an allocator shim, if any\n+    //\n+    // If LTO is enabled and we've got some previous LLVM module we translated\n+    // above, then we can just translate directly into that LLVM module. If not,\n+    // however, we need to create a separate module and trans into that. Note\n+    // that the separate translation is critical for the standard library where\n+    // the rlib's object file doesn't have allocator functions but the dylib\n+    // links in an object file that has allocator functions. When we're\n+    // compiling a final LTO artifact, though, there's no need to worry about\n+    // this as we're not working with this dual \"rlib/dylib\" functionality.\n+    let allocator_module = if tcx.sess.lto() {\n+        None\n+    } else if let Some(kind) = tcx.sess.allocator_kind.get() {\n+        unsafe {\n+            let (llcx, llmod) =\n+                context::create_context_and_module(tcx.sess, \"allocator\");\n+            let modules = ModuleLlvm {\n+                llmod: llmod,\n+                llcx: llcx,\n+            };\n+            time(tcx.sess.time_passes(), \"write allocator module\", || {\n+                allocator::trans(tcx, &modules, kind)\n+            });\n+\n+            Some(ModuleTranslation {\n+                name: link::ALLOCATOR_MODULE_NAME.to_string(),\n+                symbol_name_hash: 0, // we always rebuild allocator shims\n+                source: ModuleSource::Translated(modules),\n+                kind: ModuleKind::Allocator,\n+            })\n+        }\n+    } else {\n+        None\n+    };\n+\n+    if let Some(allocator_module) = allocator_module {\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, allocator_module, false);\n+    }\n+\n+    let codegen_unit_count = codegen_units.len();\n+    ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess,\n+                                                             metadata_module,\n+                                                             codegen_unit_count == 0);\n \n     let translation_items = Arc::new(translation_items);\n \n     let mut all_stats = Stats::default();\n     let mut module_dispositions = tcx.sess.opts.incremental.as_ref().map(|_| Vec::new());\n \n-    for cgu in codegen_units.into_iter() {\n+    for (cgu_index, cgu) in codegen_units.into_iter().enumerate() {\n+        ongoing_translation.wait_for_signal_to_translate_item();\n         ongoing_translation.check_for_errors(tcx.sess);\n \n-        let _timing_guard = time_graph\n-            .as_ref()\n-            .map(|time_graph| time_graph.start(write::TRANS_WORKER_TIMELINE,\n-                                               write::TRANS_WORK_PACKAGE_KIND));\n-\n-        let dep_node = cgu.work_product_dep_node();\n-        let ((stats, module), _) =\n-            tcx.dep_graph.with_task(dep_node,\n-                                    AssertDepGraphSafe(&shared_ccx),\n-                                    AssertDepGraphSafe((cgu,\n-                                                        translation_items.clone(),\n-                                                        exported_symbols.clone())),\n-                                    module_translation);\n-        all_stats.extend(stats);\n-\n-        if let Some(ref mut module_dispositions) = module_dispositions {\n-            module_dispositions.push(module.disposition());\n-        }\n-        ongoing_translation.submit_translated_module_to_llvm(tcx.sess, module);\n+        let module = {\n+            let _timing_guard = time_graph\n+                .as_ref()\n+                .map(|time_graph| time_graph.start(write::TRANS_WORKER_TIMELINE,\n+                                                   write::TRANS_WORK_PACKAGE_KIND));\n+            let dep_node = cgu.work_product_dep_node();\n+            let ((stats, module), _) =\n+                tcx.dep_graph.with_task(dep_node,\n+                                        AssertDepGraphSafe(&shared_ccx),\n+                                        AssertDepGraphSafe((cgu,\n+                                                            translation_items.clone(),\n+                                                            exported_symbols.clone())),\n+                                        module_translation);\n+            all_stats.extend(stats);\n+\n+            if let Some(ref mut module_dispositions) = module_dispositions {\n+                module_dispositions.push(module.disposition());\n+            }\n+\n+            module\n+        };\n+\n+        let is_last_cgu = (cgu_index + 1) == codegen_unit_count;\n+\n+        ongoing_translation.submit_translated_module_to_llvm(tcx.sess,\n+                                                             module,\n+                                                             is_last_cgu);\n+        ongoing_translation.check_for_errors(tcx.sess);\n     }\n \n     if let Some(module_dispositions) = module_dispositions {\n@@ -1229,47 +1282,7 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         }\n     }\n \n-    // Translate an allocator shim, if any\n-    //\n-    // If LTO is enabled and we've got some previous LLVM module we translated\n-    // above, then we can just translate directly into that LLVM module. If not,\n-    // however, we need to create a separate module and trans into that. Note\n-    // that the separate translation is critical for the standard library where\n-    // the rlib's object file doesn't have allocator functions but the dylib\n-    // links in an object file that has allocator functions. When we're\n-    // compiling a final LTO artifact, though, there's no need to worry about\n-    // this as we're not working with this dual \"rlib/dylib\" functionality.\n-    let allocator_module = if tcx.sess.lto() {\n-        None\n-    } else if let Some(kind) = tcx.sess.allocator_kind.get() {\n-        unsafe {\n-            let (llcx, llmod) =\n-                context::create_context_and_module(tcx.sess, \"allocator\");\n-            let modules = ModuleLlvm {\n-                llmod: llmod,\n-                llcx: llcx,\n-            };\n-            time(tcx.sess.time_passes(), \"write allocator module\", || {\n-                allocator::trans(tcx, &modules, kind)\n-            });\n-\n-            Some(ModuleTranslation {\n-                name: link::ALLOCATOR_MODULE_NAME.to_string(),\n-                symbol_name_hash: 0, // we always rebuild allocator shims\n-                source: ModuleSource::Translated(modules),\n-                kind: ModuleKind::Allocator,\n-            })\n-        }\n-    } else {\n-        None\n-    };\n-\n-    if let Some(allocator_module) = allocator_module {\n-        ongoing_translation.submit_translated_module_to_llvm(tcx.sess, allocator_module);\n-    }\n-\n     ongoing_translation.check_for_errors(tcx.sess);\n-    ongoing_translation.signal_translation_done();\n \n     assert_and_save_dep_graph(tcx,\n                               incremental_hashes_map,"}]}