{"sha": "971d776aa5a678672eb3d37f2f507664aacd2440", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk3MWQ3NzZhYTVhNjc4NjcyZWIzZDM3ZjJmNTA3NjY0YWFjZDI0NDA=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-22T05:37:20Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-25T22:53:29Z"}, "message": "Add Span and separate open/close delims to TTDelim\n\nThis came up when working [on the gl-rs generator extension](https://github.com/bjz/gl-rs/blob/990383de801bd2e233159d5be07c9b5622827620/src/gl_generator/lib.rs#L135-L146).\n\nThe new definition of  `TTDelim` adds an associated `Span` that covers the whole token tree and enforces the invariant that a delimited sequence of token trees must have an opening and closing delimiter.\n\nA `get_span` method has also been added to `TokenTree` type to make it easier to implement better error messages for syntax extensions.", "tree": {"sha": "050e68a9c76a8bf969778396b42c44060671c241", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/050e68a9c76a8bf969778396b42c44060671c241"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/971d776aa5a678672eb3d37f2f507664aacd2440", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/971d776aa5a678672eb3d37f2f507664aacd2440", "html_url": "https://github.com/rust-lang/rust/commit/971d776aa5a678672eb3d37f2f507664aacd2440", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/971d776aa5a678672eb3d37f2f507664aacd2440/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "80e5fe1a56bb95e8e89d5f8f0ff5122583bb5336", "url": "https://api.github.com/repos/rust-lang/rust/commits/80e5fe1a56bb95e8e89d5f8f0ff5122583bb5336", "html_url": "https://github.com/rust-lang/rust/commit/80e5fe1a56bb95e8e89d5f8f0ff5122583bb5336"}], "stats": {"total": 223, "additions": 135, "deletions": 88}, "files": [{"sha": "be316ba9f4d89d17c1ac8e2148f345ff0fd6c73e", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 28, "deletions": 3, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -592,6 +592,20 @@ pub enum CaptureClause {\n     CaptureByRef,\n }\n \n+/// A token that delimits a sequence of token trees\n+#[deriving(Clone, PartialEq, Eq, Encodable, Decodable, Hash, Show)]\n+pub struct Delimiter {\n+    pub span: Span,\n+    pub token: ::parse::token::Token,\n+}\n+\n+impl Delimiter {\n+    /// Convert the delimiter to a `TTTok`\n+    pub fn to_tt(&self) -> TokenTree {\n+        TTTok(self.span, self.token.clone())\n+    }\n+}\n+\n /// When the main rust parser encounters a syntax-extension invocation, it\n /// parses the arguments to the invocation as a token-tree. This is a very\n /// loose structure, such that all sorts of different AST-fragments can\n@@ -611,10 +625,9 @@ pub enum CaptureClause {\n pub enum TokenTree {\n     /// A single token\n     TTTok(Span, ::parse::token::Token),\n-    /// A delimited sequence (the delimiters appear as the first\n-    /// and last elements of the vector)\n+    /// A delimited sequence of token trees\n     // FIXME(eddyb) #6308 Use Rc<[TokenTree]> after DST.\n-    TTDelim(Rc<Vec<TokenTree>>),\n+    TTDelim(Span, Delimiter, Rc<Vec<TokenTree>>, Delimiter),\n \n     // These only make sense for right-hand-sides of MBE macros:\n \n@@ -628,6 +641,18 @@ pub enum TokenTree {\n     TTNonterminal(Span, Ident)\n }\n \n+impl TokenTree {\n+    /// Returns the `Span` corresponding to this token tree.\n+    pub fn get_span(&self) -> Span {\n+        match *self {\n+            TTTok(span, _)         => span,\n+            TTDelim(span, _, _, _) => span,\n+            TTSeq(span, _, _, _)   => span,\n+            TTNonterminal(span, _) => span,\n+        }\n+    }\n+}\n+\n // Matchers are nodes defined-by and recognized-by the main rust parser and\n // language, but they're only ever found inside syntax-extension invocations;\n // indeed, the only thing that ever _activates_ the rules in the rust parser"}, {"sha": "30301e3b8cc92414a940ebc6fb374d958a267479", "filename": "src/libsyntax/ext/log_syntax.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Flog_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Flog_syntax.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -13,16 +13,14 @@ use codemap;\n use ext::base;\n use print;\n \n-use std::rc::Rc;\n-\n pub fn expand_syntax_ext<'cx>(cx: &'cx mut base::ExtCtxt,\n                               sp: codemap::Span,\n-                              tt: &[ast::TokenTree])\n+                              tts: &[ast::TokenTree])\n                               -> Box<base::MacResult+'cx> {\n \n     cx.print_backtrace();\n-    println!(\"{}\", print::pprust::tt_to_string(&ast::TTDelim(\n-                Rc::new(tt.iter().map(|x| (*x).clone()).collect()))));\n+\n+    println!(\"{}\", print::pprust::tts_to_string(tts));\n \n     // any so that `log_syntax` can be invoked as an expression and item.\n     base::DummyResult::any(sp)"}, {"sha": "783c08a44436e3b2603819174c651e990e58191f", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 10, "deletions": 7, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -637,7 +637,7 @@ fn mk_token(cx: &ExtCtxt, sp: Span, tok: &token::Token) -> P<ast::Expr> {\n }\n \n \n-fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n+fn mk_tt(cx: &ExtCtxt, _: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n     match *tt {\n         ast::TTTok(sp, ref tok) => {\n             let e_sp = cx.expr_ident(sp, id_ext(\"_sp\"));\n@@ -650,13 +650,16 @@ fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                                     id_ext(\"push\"),\n                                     vec!(e_tok));\n             vec!(cx.stmt_expr(e_push))\n-        }\n-\n-        ast::TTDelim(ref tts) => mk_tts(cx, sp, tts.as_slice()),\n+        },\n+        ast::TTDelim(sp, ref open, ref tts, ref close) => {\n+            let mut stmts = vec![];\n+            stmts.extend(mk_tt(cx, sp, &open.to_tt()).into_iter());\n+            stmts.extend(tts.iter().flat_map(|tt| mk_tt(cx, sp, tt).into_iter()));\n+            stmts.extend(mk_tt(cx, sp, &close.to_tt()).into_iter());\n+            stmts\n+        },\n         ast::TTSeq(..) => fail!(\"TTSeq in quote!\"),\n-\n         ast::TTNonterminal(sp, ident) => {\n-\n             // tt.extend($ident.to_tokens(ext_cx).into_iter())\n \n             let e_to_toks =\n@@ -674,7 +677,7 @@ fn mk_tt(cx: &ExtCtxt, sp: Span, tt: &ast::TokenTree) -> Vec<P<ast::Stmt>> {\n                                     vec!(e_to_toks));\n \n             vec!(cx.stmt_expr(e_push))\n-        }\n+        },\n     }\n }\n "}, {"sha": "fbfe10d004e06d1f5a3cc0db1e4a2a0ec2bc8ee9", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 5, "deletions": 15, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -147,13 +147,9 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                           rhses: &[Rc<NamedMatch>])\n                           -> Box<MacResult+'cx> {\n     if cx.trace_macros() {\n-        println!(\"{}! {} {} {}\",\n+        println!(\"{}! {{ {} }}\",\n                  token::get_ident(name),\n-                 \"{\",\n-                 print::pprust::tt_to_string(&TTDelim(Rc::new(arg.iter()\n-                                                              .map(|x| (*x).clone())\n-                                                              .collect()))),\n-                 \"}\");\n+                 print::pprust::tts_to_string(arg));\n     }\n \n     // Which arm's failure should we report? (the one furthest along)\n@@ -175,15 +171,9 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     // okay, what's your transcriber?\n                     MatchedNonterminal(NtTT(ref tt)) => {\n                         match **tt {\n-                            // cut off delimiters; don't parse 'em\n-                            TTDelim(ref tts) => {\n-                                (*tts).slice(1u,(*tts).len()-1u)\n-                                      .iter()\n-                                      .map(|x| (*x).clone())\n-                                      .collect()\n-                            }\n-                            _ => cx.span_fatal(\n-                                sp, \"macro rhs must be delimited\")\n+                            // ignore delimiters\n+                            TTDelim(_, _, ref tts, _) => (**tts).clone(),\n+                            _ => cx.span_fatal(sp, \"macro rhs must be delimited\"),\n                         }\n                     },\n                     _ => cx.span_bug(sp, \"bad thing in rhs\")"}, {"sha": "472b24be81b93db0cf61fea4bf3150a713e141c6", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 32, "deletions": 22, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -18,6 +18,7 @@ use parse::token;\n use parse::lexer::TokenAndSpan;\n \n use std::rc::Rc;\n+use std::ops::Add;\n use std::collections::HashMap;\n \n ///an unzipping of `TokenTree`s\n@@ -104,37 +105,41 @@ enum LockstepIterSize {\n     LisContradiction(String),\n }\n \n-fn lis_merge(lhs: LockstepIterSize, rhs: LockstepIterSize) -> LockstepIterSize {\n-    match lhs {\n-        LisUnconstrained => rhs.clone(),\n-        LisContradiction(_) => lhs.clone(),\n-        LisConstraint(l_len, l_id) => match rhs {\n-            LisUnconstrained => lhs.clone(),\n-            LisContradiction(_) => rhs.clone(),\n-            LisConstraint(r_len, _) if l_len == r_len => lhs.clone(),\n-            LisConstraint(r_len, r_id) => {\n-                let l_n = token::get_ident(l_id);\n-                let r_n = token::get_ident(r_id);\n-                LisContradiction(format!(\"inconsistent lockstep iteration: \\\n-                                          '{}' has {} items, but '{}' has {}\",\n-                                          l_n, l_len, r_n, r_len).to_string())\n-            }\n+impl Add<LockstepIterSize, LockstepIterSize> for LockstepIterSize {\n+    fn add(&self, other: &LockstepIterSize) -> LockstepIterSize {\n+        match *self {\n+            LisUnconstrained => other.clone(),\n+            LisContradiction(_) => self.clone(),\n+            LisConstraint(l_len, l_id) => match *other {\n+                LisUnconstrained => self.clone(),\n+                LisContradiction(_) => other.clone(),\n+                LisConstraint(r_len, _) if l_len == r_len => self.clone(),\n+                LisConstraint(r_len, r_id) => {\n+                    let l_n = token::get_ident(l_id);\n+                    let r_n = token::get_ident(r_id);\n+                    LisContradiction(format!(\"inconsistent lockstep iteration: \\\n+                                              '{}' has {} items, but '{}' has {}\",\n+                                              l_n, l_len, r_n, r_len).to_string())\n+                }\n+            },\n         }\n     }\n }\n \n fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n     match *t {\n-        TTDelim(ref tts) | TTSeq(_, ref tts, _, _) => {\n-            tts.iter().fold(LisUnconstrained, |lis, tt| {\n-                lis_merge(lis, lockstep_iter_size(tt, r))\n+        // The opening and closing delimiters are both tokens, so they are\n+        // treated as `LisUnconstrained`.\n+        TTDelim(_, _, ref tts, _) | TTSeq(_, ref tts, _, _) => {\n+            tts.iter().fold(LisUnconstrained, |size, tt| {\n+                size + lockstep_iter_size(tt, r)\n             })\n-        }\n+        },\n         TTTok(..) => LisUnconstrained,\n         TTNonterminal(_, name) => match *lookup_cur_matched(r, name) {\n             MatchedNonterminal(_) => LisUnconstrained,\n             MatchedSeq(ref ads, _) => LisConstraint(ads.len(), name)\n-        }\n+        },\n     }\n }\n \n@@ -197,9 +202,14 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             (*frame.forest)[frame.idx].clone()\n         };\n         match t {\n-            TTDelim(tts) => {\n+            TTDelim(_, open, delimed_tts, close) => {\n+                let mut tts = vec![];\n+                tts.push(open.to_tt());\n+                tts.extend(delimed_tts.iter().map(|x| (*x).clone()));\n+                tts.push(close.to_tt());\n+\n                 r.stack.push(TtFrame {\n-                    forest: tts,\n+                    forest: Rc::new(tts),\n                     idx: 0,\n                     dotdotdoted: false,\n                     sep: None"}, {"sha": "ddb2ab49f8b527eadaf3f587d7379bce00564401", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 11, "deletions": 1, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -571,7 +571,17 @@ pub fn noop_fold_tt<T: Folder>(tt: &TokenTree, fld: &mut T) -> TokenTree {\n     match *tt {\n         TTTok(span, ref tok) =>\n             TTTok(span, fld.fold_token(tok.clone())),\n-        TTDelim(ref tts) => TTDelim(Rc::new(fld.fold_tts(tts.as_slice()))),\n+        TTDelim(span, ref open, ref tts, ref close) =>\n+            TTDelim(span,\n+                    Delimiter {\n+                        span: open.span,\n+                        token: fld.fold_token(open.token.clone())\n+                    },\n+                    Rc::new(fld.fold_tts(tts.as_slice())),\n+                    Delimiter {\n+                        span: close.span,\n+                        token: fld.fold_token(close.token.clone())\n+                    }),\n         TTSeq(span, ref pattern, ref sep, is_optional) =>\n             TTSeq(span,\n                   Rc::new(fld.fold_tts(pattern.as_slice())),"}, {"sha": "1c99b608f7aa38df471fa00179e6733eba5de797", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 18, "deletions": 19, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -788,35 +788,34 @@ mod test {\n     }\n \n     // check the token-tree-ization of macros\n-    #[test] fn string_to_tts_macro () {\n+    #[test]\n+    fn string_to_tts_macro () {\n         let tts = string_to_tts(\"macro_rules! zip (($a)=>($a))\".to_string());\n         let tts: &[ast::TokenTree] = tts.as_slice();\n         match tts {\n-            [ast::TTTok(_,_),\n-             ast::TTTok(_,token::NOT),\n-             ast::TTTok(_,_),\n-             ast::TTDelim(ref delim_elts)] => {\n+            [ast::TTTok(_, _),\n+             ast::TTTok(_, token::NOT),\n+             ast::TTTok(_, _),\n+             ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+                          ref delim_elts,\n+                          ast::TTTok(_, token::RPAREN))] => {\n                 let delim_elts: &[ast::TokenTree] = delim_elts.as_slice();\n                 match delim_elts {\n-                    [ast::TTTok(_,token::LPAREN),\n-                     ast::TTDelim(ref first_set),\n-                     ast::TTTok(_,token::FAT_ARROW),\n-                     ast::TTDelim(ref second_set),\n-                     ast::TTTok(_,token::RPAREN)] => {\n+                    [ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+                                  ref first_set,\n+                                  ast::TTTok(_, token::RPAREN)),\n+                     ast::TTTok(_, token::FAT_ARROW),\n+                     ast::TTDelim(_, ast::TTTok(_, token::LPAREN),\n+                                  ref second_set,\n+                                  ast::TTTok(_, token::RPAREN))] => {\n                         let first_set: &[ast::TokenTree] =\n                             first_set.as_slice();\n                         match first_set {\n-                            [ast::TTTok(_,token::LPAREN),\n-                             ast::TTTok(_,token::DOLLAR),\n-                             ast::TTTok(_,_),\n-                             ast::TTTok(_,token::RPAREN)] => {\n+                            [ast::TTTok(_, token::DOLLAR), ast::TTTok(_, _)] => {\n                                 let second_set: &[ast::TokenTree] =\n                                     second_set.as_slice();\n                                 match second_set {\n-                                    [ast::TTTok(_,token::LPAREN),\n-                                     ast::TTTok(_,token::DOLLAR),\n-                                     ast::TTTok(_,_),\n-                                     ast::TTTok(_,token::RPAREN)] => {\n+                                    [ast::TTTok(_, token::DOLLAR), ast::TTTok(_, _)] => {\n                                         assert_eq!(\"correct\",\"correct\")\n                                     }\n                                     _ => assert_eq!(\"wrong 4\",\"correct\")\n@@ -837,7 +836,7 @@ mod test {\n             _ => {\n                 error!(\"failing value: {}\",tts);\n                 assert_eq!(\"wrong 1\",\"correct\");\n-            }\n+            },\n         }\n     }\n "}, {"sha": "005ed2e7ed3741392f62fb345b2b2e20d94b0135", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 21, "deletions": 15, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -48,7 +48,7 @@ use ast::{StmtExpr, StmtSemi, StmtMac, StructDef, StructField};\n use ast::{StructVariantKind, BiSub};\n use ast::StrStyle;\n use ast::{SelfExplicit, SelfRegion, SelfStatic, SelfValue};\n-use ast::{TokenTree, TraitItem, TraitRef, TTDelim, TTSeq, TTTok};\n+use ast::{Delimiter, TokenTree, TraitItem, TraitRef, TTDelim, TTSeq, TTTok};\n use ast::{TTNonterminal, TupleVariantKind, Ty, Ty_, TyBot};\n use ast::{TypeField, TyFixedLengthVec, TyClosure, TyProc, TyBareFn};\n use ast::{TyTypeof, TyInfer, TypeMethod};\n@@ -2574,16 +2574,11 @@ impl<'a> Parser<'a> {\n                 }\n               }\n               _ => {\n-                  parse_any_tt_tok(p)\n+                  TTTok(p.span, p.bump_and_get())\n               }\n             }\n         }\n \n-        // turn the next token into a TTTok:\n-        fn parse_any_tt_tok(p: &mut Parser) -> TokenTree {\n-            TTTok(p.span, p.bump_and_get())\n-        }\n-\n         match (&self.token, token::close_delimiter_for(&self.token)) {\n             (&token::EOF, _) => {\n                 let open_braces = self.open_braces.clone();\n@@ -2595,21 +2590,32 @@ impl<'a> Parser<'a> {\n                 self.fatal(\"this file contains an un-closed delimiter \");\n             }\n             (_, Some(close_delim)) => {\n+                // The span for beginning of the delimited section\n+                let pre_span = self.span;\n+\n                 // Parse the open delimiter.\n                 self.open_braces.push(self.span);\n-                let mut result = vec!(parse_any_tt_tok(self));\n+                let open = Delimiter {\n+                    span: self.span,\n+                    token: self.bump_and_get(),\n+                };\n \n-                let trees =\n-                    self.parse_seq_to_before_end(&close_delim,\n-                                                 seq_sep_none(),\n-                                                 |p| p.parse_token_tree());\n-                result.extend(trees.into_iter());\n+                // Parse the token trees within the delimeters\n+                let tts = self.parse_seq_to_before_end(\n+                    &close_delim, seq_sep_none(), |p| p.parse_token_tree()\n+                );\n \n                 // Parse the close delimiter.\n-                result.push(parse_any_tt_tok(self));\n+                let close = Delimiter {\n+                    span: self.span,\n+                    token: self.bump_and_get(),\n+                };\n                 self.open_braces.pop().unwrap();\n \n-                TTDelim(Rc::new(result))\n+                // Expand to cover the entire delimited token tree\n+                let span = Span { hi: self.span.hi, ..pre_span };\n+\n+                TTDelim(span, open, Rc::new(tts), close)\n             }\n             _ => parse_non_delim_tt_tok(self)\n         }"}, {"sha": "4f4b153d3a964286dac85fa39594fd8cf151ba16", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/971d776aa5a678672eb3d37f2f507664aacd2440/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=971d776aa5a678672eb3d37f2f507664aacd2440", "patch": "@@ -1020,7 +1020,13 @@ impl<'a> State<'a> {\n     /// expression arguments as expressions). It can be done! I think.\n     pub fn print_tt(&mut self, tt: &ast::TokenTree) -> IoResult<()> {\n         match *tt {\n-            ast::TTDelim(ref tts) => self.print_tts(tts.as_slice()),\n+            ast::TTDelim(_, ref open, ref tts, ref close) => {\n+                try!(word(&mut self.s, parse::token::to_string(&open.token).as_slice()));\n+                try!(space(&mut self.s));\n+                try!(self.print_tts(tts.as_slice()));\n+                try!(space(&mut self.s));\n+                word(&mut self.s, parse::token::to_string(&close.token).as_slice())\n+            },\n             ast::TTTok(_, ref tk) => {\n                 try!(word(&mut self.s, parse::token::to_string(tk).as_slice()));\n                 match *tk {"}]}