{"sha": "6680c9c5c797101fc5e0608cb2c3657517333148", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY2ODBjOWM1Yzc5NzEwMWZjNWUwNjA4Y2IyYzM2NTc1MTczMzMxNDg=", "commit": {"author": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2015-01-02T21:41:24Z"}, "committer": {"name": "Corey Richardson", "email": "corey@octayn.net", "date": "2015-01-06T17:03:12Z"}, "message": "syntax: implement 'macro input future proofing'\n\nSee RFC 550 (https://github.com/rust-lang/rfcs/pull/550) for the motivation\nand details.\n\nIf this breaks your code, add one of the listed tokens after the relevant\nnon-terminal in your matcher.\n\n[breaking-change]", "tree": {"sha": "dbbcc5b4cc5af30075ba5b172e403dfe0ced7ceb", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dbbcc5b4cc5af30075ba5b172e403dfe0ced7ceb"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6680c9c5c797101fc5e0608cb2c3657517333148", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6680c9c5c797101fc5e0608cb2c3657517333148", "html_url": "https://github.com/rust-lang/rust/commit/6680c9c5c797101fc5e0608cb2c3657517333148", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6680c9c5c797101fc5e0608cb2c3657517333148/comments", "author": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "committer": {"login": "emberian", "id": 704250, "node_id": "MDQ6VXNlcjcwNDI1MA==", "avatar_url": "https://avatars.githubusercontent.com/u/704250?v=4", "gravatar_id": "", "url": "https://api.github.com/users/emberian", "html_url": "https://github.com/emberian", "followers_url": "https://api.github.com/users/emberian/followers", "following_url": "https://api.github.com/users/emberian/following{/other_user}", "gists_url": "https://api.github.com/users/emberian/gists{/gist_id}", "starred_url": "https://api.github.com/users/emberian/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/emberian/subscriptions", "organizations_url": "https://api.github.com/users/emberian/orgs", "repos_url": "https://api.github.com/users/emberian/repos", "events_url": "https://api.github.com/users/emberian/events{/privacy}", "received_events_url": "https://api.github.com/users/emberian/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8efd9901b628d687d11a4d0ccc153553b38ada49", "url": "https://api.github.com/repos/rust-lang/rust/commits/8efd9901b628d687d11a4d0ccc153553b38ada49", "html_url": "https://github.com/rust-lang/rust/commit/8efd9901b628d687d11a4d0ccc153553b38ada49"}], "stats": {"total": 175, "additions": 167, "deletions": 8}, "files": [{"sha": "96a0f7de0fdc88a1ffa5abcafb9a456891573bcd", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 140, "deletions": 8, "changes": 148, "blob_url": "https://github.com/rust-lang/rust/blob/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=6680c9c5c797101fc5e0608cb2c3657517333148", "patch": "@@ -1,4 +1,4 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n // file at the top-level directory of this distribution and at\n // http://rust-lang.org/COPYRIGHT.\n //\n@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use ast::{Ident, TtDelimited, TtSequence, TtToken};\n+use ast::{TokenTree, TtDelimited, TtSequence, TtToken};\n use ast;\n use codemap::{Span, DUMMY_SP};\n use ext::base::{ExtCtxt, MacResult, SyntaxExtension};\n@@ -19,8 +19,8 @@ use ext::tt::macro_parser::{parse, parse_or_else};\n use parse::lexer::new_tt_reader;\n use parse::parser::Parser;\n use parse::attr::ParserAttr;\n-use parse::token::{special_idents, gensym_ident};\n-use parse::token::{MatchNt, NtTT};\n+use parse::token::{special_idents, gensym_ident, NtTT, Token};\n+use parse::token::Token::*;\n use parse::token;\n use print;\n use ptr::P;\n@@ -109,8 +109,8 @@ impl<'a> MacResult for ParserAnyMacro<'a> {\n }\n \n struct MacroRulesMacroExpander {\n-    name: Ident,\n-    imported_from: Option<Ident>,\n+    name: ast::Ident,\n+    imported_from: Option<ast::Ident>,\n     lhses: Vec<Rc<NamedMatch>>,\n     rhses: Vec<Rc<NamedMatch>>,\n }\n@@ -134,8 +134,8 @@ impl TTMacroExpander for MacroRulesMacroExpander {\n /// Given `lhses` and `rhses`, this is the new macro we create\n fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                           sp: Span,\n-                          name: Ident,\n-                          imported_from: Option<Ident>,\n+                          name: ast::Ident,\n+                          imported_from: Option<ast::Ident>,\n                           arg: &[ast::TokenTree],\n                           lhses: &[Rc<NamedMatch>],\n                           rhses: &[Rc<NamedMatch>])\n@@ -260,6 +260,10 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n         _ => cx.span_bug(def.span, \"wrong-structured lhs\")\n     };\n \n+    for lhs in lhses.iter() {\n+        check_lhs_nt_follows(cx, &**lhs, def.span);\n+    }\n+\n     let rhses = match *argument_map[rhs_nm] {\n         MatchedSeq(ref s, _) => /* FIXME (#2543) */ (*s).clone(),\n         _ => cx.span_bug(def.span, \"wrong-structured rhs\")\n@@ -274,3 +278,131 @@ pub fn compile<'cx>(cx: &'cx mut ExtCtxt,\n \n     NormalTT(exp, Some(def.span))\n }\n+\n+fn check_lhs_nt_follows(cx: &mut ExtCtxt, lhs: &NamedMatch, sp: Span) {\n+    // lhs is going to be like MatchedNonterminal(NtTT(TtDelimited(...))), where\n+    // the entire lhs is those tts.\n+    // if ever we get box/deref patterns, this could turn into an `if let\n+    // &MatchedNonterminal(NtTT(box TtDelimited(...))) = lhs`\n+    let matcher = match lhs {\n+        &MatchedNonterminal(NtTT(ref inner)) => match &**inner {\n+            &TtDelimited(_, ref tts) => tts.tts[],\n+            _ => cx.span_bug(sp, \"wrong-structured lhs for follow check\")\n+        },\n+        _ => cx.span_bug(sp, \"wrong-structured lhs for follow check\")\n+    };\n+\n+    check_matcher(cx, matcher, &Eof);\n+    // we don't abort on errors on rejection, the driver will do that for us\n+    // after parsing/expansion. we can report every error in every macro this way.\n+}\n+\n+fn check_matcher(cx: &mut ExtCtxt, matcher: &[TokenTree], follow: &Token) {\n+    use print::pprust::token_to_string;\n+\n+    // 1. If there are no tokens in M, accept\n+    if matcher.is_empty() {\n+        return;\n+    }\n+\n+    // 2. For each token T in M:\n+    let mut tokens = matcher.iter().peekable();\n+    while let Some(token) = tokens.next() {\n+        match *token {\n+            TtToken(sp, MatchNt(ref name, ref frag_spec, _, _)) => {\n+                // ii. If T is a simple NT, look ahead to the next token T' in\n+                // M.\n+                let next_token = match tokens.peek() {\n+                    // If T' closes a complex NT, replace T' with F\n+                    Some(&&TtToken(_, CloseDelim(_))) => follow,\n+                    Some(&&TtToken(_, ref tok)) => tok,\n+                    // T' is any NT (this catches complex NTs, the next\n+                    // iteration will die if it's a TtDelimited).\n+                    Some(_) => continue,\n+                    // else, we're at the end of the macro or sequence\n+                    None => follow\n+                };\n+\n+                // If T' is in the set FOLLOW(NT), continue. Else, reject.\n+                match *next_token {\n+                    Eof | MatchNt(..) => continue,\n+                    _ if is_in_follow(cx, next_token, frag_spec.as_str()) => continue,\n+                    ref tok => cx.span_err(sp, format!(\"`${0}:{1}` is followed by `{2}`, which \\\n+                                                        is not allowed for `{1}` fragments\",\n+                                                        name.as_str(), frag_spec.as_str(),\n+                                                        token_to_string(tok))[])\n+                }\n+            },\n+            TtSequence(_, ref seq) => {\n+                // iii. Else, T is a complex NT.\n+                match seq.separator {\n+                    // If T has the form $(...)U+ or $(...)U* for some token U,\n+                    // run the algorithm on the contents with F set to U. If it\n+                    // accepts, continue, else, reject.\n+                    Some(ref u) => check_matcher(cx, seq.tts[], u),\n+                    // If T has the form $(...)+ or $(...)*, run the algorithm\n+                    // on the contents with F set to EOF. If it accepts,\n+                    // continue, else, reject.\n+                    None => check_matcher(cx, seq.tts[], &Eof)\n+                }\n+            },\n+            TtToken(..) => {\n+                // i. If T is not an NT, continue.\n+                continue\n+            },\n+            TtDelimited(_, ref tts) => {\n+                // if we don't pass in that close delimiter, we'll incorrectly consider the matcher\n+                // `{ $foo:ty }` as having a follow that isn't `}`\n+                check_matcher(cx, tts.tts[], &tts.close_token())\n+            }\n+        }\n+    }\n+}\n+\n+fn is_in_follow(cx: &ExtCtxt, tok: &Token, frag: &str) -> bool {\n+    if let &CloseDelim(_) = tok {\n+        return true;\n+    }\n+\n+    match frag {\n+        \"item\" => {\n+            // since items *must* be followed by either a `;` or a `}`, we can\n+            // accept anything after them\n+            true\n+        },\n+        \"block\" => {\n+            // anything can follow block, the braces provide a easy boundary to\n+            // maintain\n+            true\n+        },\n+        \"stmt\" | \"expr\"  => {\n+            match *tok {\n+                Comma | Semi => true,\n+                _ => false\n+            }\n+        },\n+        \"pat\" => {\n+            match *tok {\n+                FatArrow | Comma | Eq => true,\n+                _ => false\n+            }\n+        },\n+        \"path\" | \"ty\" => {\n+            match *tok {\n+                Comma | RArrow | Colon | Eq | Gt => true,\n+                Ident(i, _) if i.as_str() == \"as\" => true,\n+                _ => false\n+            }\n+        },\n+        \"ident\" => {\n+            // being a single token, idents are harmless\n+            true\n+        },\n+        \"meta\" | \"tt\" => {\n+            // being either a single token or a delimited sequence, tt is\n+            // harmless\n+            true\n+        },\n+        _ => cx.bug(format!(\"unrecognized builtin nonterminal {}\", frag)[]),\n+    }\n+}"}, {"sha": "205589ba78ead7ae8f2614e8c94643b3415ddf86", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=6680c9c5c797101fc5e0608cb2c3657517333148", "patch": "@@ -392,6 +392,7 @@ impl fmt::Show for Nonterminal {\n     }\n }\n \n+\n // Get the first \"argument\"\n macro_rules! first {\n     ( $first:expr, $( $remainder:expr, )* ) => ( $first )"}, {"sha": "2804fc147962647e9737017a66e1482dc055931c", "filename": "src/test/compile-fail/macro-input-future-proofing.rs", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Ftest%2Fcompile-fail%2Fmacro-input-future-proofing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6680c9c5c797101fc5e0608cb2c3657517333148/src%2Ftest%2Fcompile-fail%2Fmacro-input-future-proofing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fmacro-input-future-proofing.rs?ref=6680c9c5c797101fc5e0608cb2c3657517333148", "patch": "@@ -0,0 +1,26 @@\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+macro_rules! errors_everywhere {\n+    ($ty:ty <) => () //~ ERROR `$ty:ty` is followed by `<`, which is not allowed for `ty` fragments\n+    ($ty:ty < foo ,) => () //~ ERROR `$ty:ty` is followed by `<`, which is not allowed for `ty`\n+    ($ty:ty , ) => ()\n+    ( ( $ty:ty ) ) => ()\n+    ( { $ty:ty } ) => ()\n+    ( [ $ty:ty ] ) => ()\n+    ($bl:block < ) => ()\n+    ($pa:pat >) => () //~ ERROR `$pa:pat` is followed by `>` which is not allowed for `pat`\n+    ($pa:pat , ) => ()\n+    ($pa:pat | ) => ()\n+    ($pa:pat $pb:pat $ty:ty ,) => ()\n+    ($($ty:ty)-+) => () //~ ERROR `$ty:ty` is followed by `-` which is not allowed for `ty`\n+}\n+\n+fn main() { }"}]}