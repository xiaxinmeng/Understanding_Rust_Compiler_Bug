{"sha": "f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "node_id": "MDY6Q29tbWl0NzI0NzEyOmYzNThjYTQ1YzhjZjhhNWVhODkyMmI1YzY2NDAzZDZhNGY0ZDUyYWQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-27T04:32:12Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-27T04:32:12Z"}, "message": "auto merge of #19342 : alexcrichton/rust/rollup, r=alexcrichton", "tree": {"sha": "755e6d6f67ea238da49c5a697375b20b2513bc66", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/755e6d6f67ea238da49c5a697375b20b2513bc66"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "html_url": "https://github.com/rust-lang/rust/commit/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fac5a07679cac21a580badc84b755b8df0f975cf", "url": "https://api.github.com/repos/rust-lang/rust/commits/fac5a07679cac21a580badc84b755b8df0f975cf", "html_url": "https://github.com/rust-lang/rust/commit/fac5a07679cac21a580badc84b755b8df0f975cf"}, {"sha": "5816d7f5305ce4401326568785d624e689064311", "url": "https://api.github.com/repos/rust-lang/rust/commits/5816d7f5305ce4401326568785d624e689064311", "html_url": "https://github.com/rust-lang/rust/commit/5816d7f5305ce4401326568785d624e689064311"}], "stats": {"total": 20280, "additions": 9720, "deletions": 10560}, "files": [{"sha": "613f62db9e49ad9b130c8f5ab49ab8b941abccd7", "filename": "configure", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/configure", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/configure", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/configure?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -624,7 +624,6 @@ probe CFG_LD               ld\n probe CFG_VALGRIND         valgrind\n probe CFG_PERF             perf\n probe CFG_ISCC             iscc\n-probe CFG_LLNEXTGEN        LLnextgen\n probe CFG_JAVAC            javac\n probe CFG_ANTLR4           antlr4\n probe CFG_GRUN             grun"}, {"sha": "898e4eb8c75cd4d08ef114a2e193c3eb7897e390", "filename": "mk/docs.mk", "status": "modified", "additions": 2, "deletions": 21, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Fdocs.mk", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Fdocs.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fdocs.mk?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -246,26 +246,6 @@ endef\n $(foreach lang,$(L10N_LANGS),$(eval $(call DEF_L10N_DOC,$(lang),guide)))\n \n \n-######################################################################\n-# LLnextgen (grammar analysis from refman)\n-######################################################################\n-\n-ifeq ($(CFG_LLNEXTGEN),)\n-  $(info cfg: no llnextgen found, omitting grammar-verification)\n-else\n-.PHONY: verify-grammar\n-\n-doc/rust.g: $(D)/rust.md $(S)src/etc/extract_grammar.py\n-\t@$(call E, extract_grammar: $@)\n-\t$(Q)$(CFG_PYTHON) $(S)src/etc/extract_grammar.py $< >$@\n-\n-verify-grammar: doc/rust.g\n-\t@$(call E, LLnextgen: $<)\n-\t$(Q)$(CFG_LLNEXTGEN) --generate-lexer-wrapper=no $< >$@\n-\t$(Q)rm -f doc/rust.c doc/rust.h\n-endif\n-\n-\n ######################################################################\n # Rustdoc (libstd/extra)\n ######################################################################\n@@ -299,7 +279,8 @@ $(2) += doc/$(1)/index.html\n doc/$(1)/index.html: CFG_COMPILER_HOST_TRIPLE = $(CFG_TARGET)\n doc/$(1)/index.html: $$(LIB_DOC_DEP_$(1)) doc/$(1)/\n \t@$$(call E, rustdoc: $$@)\n-\t$$(Q)$$(RUSTDOC) --cfg dox --cfg stage2 $$<\n+\t$$(Q)CFG_LLVM_LINKAGE_FILE=$$(LLVM_LINKAGE_PATH_$(CFG_BUILD)) \\\n+\t\t$$(RUSTDOC) --cfg dox --cfg stage2 $$<\n endef\n \n $(foreach crate,$(DOC_CRATES),$(eval $(call DEF_LIB_DOC,$(crate),DOC_TARGETS)))"}, {"sha": "ba2e073803935b89632a9e476a40a4293fd45cfb", "filename": "mk/llvm.mk", "status": "modified", "additions": 17, "deletions": 7, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Fllvm.mk", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Fllvm.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fllvm.mk?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -49,6 +49,12 @@ else\n LLVM_STDCPP_LOCATION_$(1) =\n endif\n \n+\n+# LLVM linkage:\n+LLVM_LINKAGE_PATH_$(1):=$$(abspath $$(RT_OUTPUT_DIR_$(1))/llvmdeps.rs)\n+$$(LLVM_LINKAGE_PATH_$(1)): $(S)src/etc/mklldeps.py $$(LLVM_CONFIG_$(1))\n+\t$(Q)$(CFG_PYTHON) \"$$<\" \"$$@\" \"$$(LLVM_COMPONENTS)\" \"$$(CFG_ENABLE_LLVM_STATIC_STDCPP)\" \\\n+\t\t$$(LLVM_CONFIG_$(1))\n endef\n \n $(foreach host,$(CFG_HOST), \\\n@@ -57,10 +63,14 @@ $(foreach host,$(CFG_HOST), \\\n $(foreach host,$(CFG_HOST), \\\n  $(eval LLVM_CONFIGS := $(LLVM_CONFIGS) $(LLVM_CONFIG_$(host))))\n \n-$(S)src/librustc_llvm/llvmdeps.rs: \\\n-\t\t    $(LLVM_CONFIGS) \\\n-\t\t    $(S)src/etc/mklldeps.py \\\n-\t\t    $(MKFILE_DEPS)\n-\t$(Q)$(CFG_PYTHON) $(S)src/etc/mklldeps.py \\\n-\t\t\"$@\" \"$(LLVM_COMPONENTS)\" \"$(CFG_ENABLE_LLVM_STATIC_STDCPP)\" \\\n-\t\t$(LLVM_CONFIGS)\n+# This can't be done in target.mk because it's included before this file.\n+define LLVM_LINKAGE_DEPS\n+$$(TLIB$(1)_T_$(2)_H_$(3))/stamp.rustc_llvm: $$(LLVM_LINKAGE_PATH_$(3))\n+endef\n+\n+$(foreach source,$(CFG_HOST), \\\n+ $(foreach target,$(CFG_TARGET), \\\n+  $(eval $(call LLVM_LINKAGE_DEPS,0,$(target),$(source))) \\\n+  $(eval $(call LLVM_LINKAGE_DEPS,1,$(target),$(source))) \\\n+  $(eval $(call LLVM_LINKAGE_DEPS,2,$(target),$(source))) \\\n+  $(eval $(call LLVM_LINKAGE_DEPS,3,$(target),$(source)))))"}, {"sha": "5b0de64574cd3338c4fd915c01fdb256c3b844be", "filename": "mk/target.mk", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Ftarget.mk", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Ftarget.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Ftarget.mk?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -79,7 +79,8 @@ $$(TLIB$(1)_T_$(2)_H_$(3))/stamp.$(4): \\\n \t    $$(dir $$@)$$(call CFG_LIB_GLOB_$(2),$(4)))\n \t$$(call REMOVE_ALL_OLD_GLOB_MATCHES, \\\n \t    $$(dir $$@)$$(call CFG_RLIB_GLOB,$(4)))\n-\t$$(STAGE$(1)_T_$(2)_H_$(3)) \\\n+\t$(Q)CFG_LLVM_LINKAGE_FILE=$$(LLVM_LINKAGE_PATH_$(2)) \\\n+\t    $$(subst @,,$$(STAGE$(1)_T_$(2)_H_$(3))) \\\n \t\t$$(RUST_LIB_FLAGS_ST$(1)) \\\n \t\t-L \"$$(RT_OUTPUT_DIR_$(2))\" \\\n \t\t-L \"$$(LLVM_LIBDIR_$(2))\" \\\n@@ -134,8 +135,6 @@ SNAPSHOT_RUSTC_POST_CLEANUP=$(HBIN0_H_$(CFG_BUILD))/rustc$(X_$(CFG_BUILD))\n \n define TARGET_HOST_RULES\n \n-$$(TLIB$(1)_T_$(2)_H_$(3))/stamp.rustc_llvm: $(S)src/librustc_llvm/llvmdeps.rs\n-\n $$(TBIN$(1)_T_$(2)_H_$(3))/:\n \tmkdir -p $$@\n "}, {"sha": "0ec0c81f2882e014e0637d7aeda93741a530bd3c", "filename": "mk/tests.mk", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Ftests.mk", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/mk%2Ftests.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Ftests.mk?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -412,7 +412,8 @@ $(3)/stage$(1)/test/$(4)test-$(2)$$(X_$(2)): \\\n \t\t$$(CRATEFILE_$(4)) \\\n \t\t$$(TESTDEP_$(1)_$(2)_$(3)_$(4))\n \t@$$(call E, rustc: $$@)\n-\t$$(STAGE$(1)_T_$(2)_H_$(3)) -o $$@ $$< --test \\\n+\t$(Q)CFG_LLVM_LINKAGE_FILE=$$(LLVM_LINKAGE_PATH_$(2)) \\\n+\t    $$(subst @,,$$(STAGE$(1)_T_$(2)_H_$(3))) -o $$@ $$< --test \\\n \t\t-L \"$$(RT_OUTPUT_DIR_$(2))\" \\\n \t\t-L \"$$(LLVM_LIBDIR_$(2))\" \\\n \t\t$$(RUSTFLAGS_$(4))\n@@ -890,7 +891,8 @@ endif\n ifeq ($(2),$$(CFG_BUILD))\n $$(call TEST_OK_FILE,$(1),$(2),$(3),doc-crate-$(4)): $$(CRATEDOCTESTDEP_$(1)_$(2)_$(3)_$(4))\n \t@$$(call E, run doc-crate-$(4) [$(2)])\n-\t$$(Q)$$(RUSTDOC_$(1)_T_$(2)_H_$(3)) --test --cfg dox \\\n+\t$$(Q)CFG_LLVM_LINKAGE_FILE=$$(LLVM_LINKAGE_PATH_$(2)) \\\n+\t    $$(RUSTDOC_$(1)_T_$(2)_H_$(3)) --test --cfg dox \\\n \t    \t$$(CRATEFILE_$(4)) --test-args \"$$(TESTARGS)\" && touch $$@\n else\n $$(call TEST_OK_FILE,$(1),$(2),$(3),doc-crate-$(4)):"}, {"sha": "918c087e66bf21070739acf8bc3a69a2497cc470", "filename": "src/doc/complement-bugreport.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fcomplement-bugreport.md", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fcomplement-bugreport.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fcomplement-bugreport.md?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -2,7 +2,7 @@\n \n # I think I found a bug in the compiler!\n \n-If you see this message: `error: internal compiler error: unexpected failure`,\n+If you see this message: `error: internal compiler error: unexpected panic`,\n then you have definitely found a bug in the compiler. It's also possible that\n your code is not well-typed, but if you saw this message, it's still a bug in\n error reporting."}, {"sha": "8b6d00168e942cab3450bedccb7c601669109e17", "filename": "src/doc/guide-pointers.md", "status": "modified", "additions": 26, "deletions": 5, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fguide-pointers.md", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fguide-pointers.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide-pointers.md?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -445,11 +445,32 @@ fn succ(x: &int) -> int { *x + 1 }\n to\n \n ```{rust}\n+use std::rc::Rc;\n+\n fn box_succ(x: Box<int>) -> int { *x + 1 }\n \n-fn rc_succ(x: std::rc::Rc<int>) -> int { *x + 1 }\n+fn rc_succ(x: Rc<int>) -> int { *x + 1 }\n+```\n+\n+Note that the caller of your function will have to modify their calls slightly:\n+\n+```{rust}\n+use std::rc::Rc;\n+\n+fn succ(x: &int) -> int { *x + 1 }\n+\n+let ref_x = &5i;\n+let box_x = box 5i;\n+let rc_x  = Rc::new(5i);\n+\n+succ(ref_x);\n+succ(&*box_x);\n+succ(&*rc_x);\n ```\n \n+The initial `*` dereferences the pointer, and then `&` takes a reference to\n+those contents.\n+\n # Boxes\n \n `Box<T>` is Rust's 'boxed pointer' type. Boxes provide the simplest form of\n@@ -572,7 +593,7 @@ fn add_one(x: &mut int) -> int {\n fn main() {\n     let x = box 5i;\n \n-    println!(\"{}\", add_one(&*x)); // error: cannot borrow immutable dereference \n+    println!(\"{}\", add_one(&*x)); // error: cannot borrow immutable dereference\n                                   // of `&`-pointer as mutable\n }\n ```\n@@ -700,9 +721,9 @@ This gives you flexibility without sacrificing performance.\n \n You may think that this gives us terrible performance: return a value and then\n immediately box it up ?! Isn't that the worst of both worlds? Rust is smarter\n-than that. There is no copy in this code. main allocates enough room for the\n-`box , passes a pointer to that memory into foo as x, and then foo writes the\n-value straight into that pointer. This writes the return value directly into\n+than that. There is no copy in this code. `main` allocates enough room for the\n+`box`, passes a pointer to that memory into `foo` as `x`, and then `foo` writes\n+the value straight into that pointer. This writes the return value directly into\n the allocated box.\n \n This is important enough that it bears repeating: pointers are not for"}, {"sha": "670af614b95a70e76a2f77e5c022f1cf0ec33b57", "filename": "src/doc/guide.md", "status": "modified", "additions": 46, "deletions": 11, "changes": 57, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fguide.md", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fdoc%2Fguide.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide.md?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -62,7 +62,7 @@ the easiest way to keep people updated while Rust is in its alpha state.\n \n Oh, we should also mention the officially supported platforms:\n \n-* Windows (7, 8, Server 2008 R2), x86 only\n+* Windows (7, 8, Server 2008 R2)\n * Linux (2.6.18 or later, various distributions), x86 and x86-64\n * OSX 10.7 (Lion) or greater, x86 and x86-64\n \n@@ -378,9 +378,15 @@ of your time with Rust.\n The first thing we'll learn about are 'variable bindings.' They look like this:\n \n ```{rust}\n-let x = 5i;\n+fn main() {\n+    let x = 5i;\n+}\n ```\n \n+Putting `fn main() {` in each example is a bit tedious, so we'll leave that out\n+in the future. If you're following along, make sure to edit your `main()`\n+function, rather than leaving it off. Otherwise, you'll get an error.\n+\n In many languages, this is called a 'variable.' But Rust's variable bindings\n have a few tricks up their sleeves. Rust has a very powerful feature called\n 'pattern matching' that we'll get into detail with later, but the left\n@@ -683,7 +689,7 @@ fn main() {\n ```\n \n This is the simplest possible function declaration. As we mentioned before,\n-`fn` says 'this is a function,' followed by the name, some parenthesis because\n+`fn` says 'this is a function,' followed by the name, some parentheses because\n this function takes no arguments, and then some curly braces to indicate the\n body. Here's a function named `foo`:\n \n@@ -884,7 +890,7 @@ Tuples are an ordered list of a fixed size. Like this:\n let x = (1i, \"hello\");\n ```\n \n-The parenthesis and commas form this two-length tuple. Here's the same code, but\n+The parentheses and commas form this two-length tuple. Here's the same code, but\n with the type annotated:\n \n ```rust\n@@ -908,9 +914,9 @@ let (x, y, z) = (1i, 2i, 3i);\n println!(\"x is {}\", x);\n ```\n \n-Remember before when I said the left hand side of a `let` statement was more\n+Remember before when I said the left-hand side of a `let` statement was more\n powerful than just assigning a binding? Here we are. We can put a pattern on\n-the left hand side of the `let`, and if it matches up to the right hand side,\n+the left-hand side of the `let`, and if it matches up to the right-hand side,\n we can assign multiple bindings at once. In this case, `let` 'destructures,'\n or 'breaks up,' the tuple, and assigns the bits to three bindings.\n \n@@ -1453,9 +1459,9 @@ focus. Any time you have a data structure of variable size, things can get\n tricky, and strings are a re-sizable data structure. That said, Rust's strings\n also work differently than in some other systems languages, such as C.\n \n-Let's dig into the details. A **string** is a sequence of unicode scalar values\n+Let's dig into the details. A **string** is a sequence of Unicode scalar values\n encoded as a stream of UTF-8 bytes. All strings are guaranteed to be\n-validly-encoded UTF-8 sequences. Additionally, strings are not null-terminated\n+validly encoded UTF-8 sequences. Additionally, strings are not null-terminated\n and can contain null bytes.\n \n Rust has two main types of strings: `&str` and `String`.\n@@ -3933,7 +3939,7 @@ match x {\n }\n ```\n \n-Here, the `val` inside the `match` has type `int`. In other words, the left hand\n+Here, the `val` inside the `match` has type `int`. In other words, the left-hand\n side of the pattern destructures the value. If we have `&5i`, then in `&val`, `val`\n would be `5i`.\n \n@@ -3991,6 +3997,35 @@ match origin {\n }\n ```\n \n+You can do this kind of match on any member, not just the first:\n+\n+```{rust}\n+# #![allow(non_shorthand_field_patterns)]\n+struct Point {\n+    x: int,\n+    y: int,\n+}\n+\n+let origin = Point { x: 0i, y: 0i };\n+\n+match origin {\n+    Point { y: y, .. } => println!(\"y is {}\", y),\n+}\n+```\n+\n+If you want to match against a slice or array, you can use `[]`:\n+\n+```{rust}\n+fn main() {\n+    let v = vec![\"match_this\", \"1\"];\n+\n+    match v.as_slice() {\n+        [\"match_this\", second] => println!(\"The second element is {}\", second),\n+        _ => {},\n+    }\n+}\n+```\n+\n Whew! That's a lot of different ways to match things, and they can all be\n mixed and matched, depending on what you're doing:\n \n@@ -4681,7 +4716,7 @@ let x: Option<int> = Some(5i);\n \n In the type declaration, we say `Option<int>`. Note how similar this looks to\n `Option<T>`. So, in this particular `Option`, `T` has the value of `int`. On\n-the right hand side of the binding, we do make a `Some(T)`, where `T` is `5i`.\n+the right-hand side of the binding, we do make a `Some(T)`, where `T` is `5i`.\n Since that's an `int`, the two sides match, and Rust is happy. If they didn't\n match, we'd get an error:\n \n@@ -5249,7 +5284,7 @@ immediately.\n \n ## Success and failure\n \n-Tasks don't always succeed, they can also panic. A task that wishes to panic \n+Tasks don't always succeed, they can also panic. A task that wishes to panic\n can call the `panic!` macro, passing a message:\n \n ```{rust}"}, {"sha": "834ba074c62102ecf51184434f4b96fedc5f3648", "filename": "src/etc/mklldeps.py", "status": "modified", "additions": 40, "deletions": 61, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fetc%2Fmklldeps.py", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fetc%2Fmklldeps.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fmklldeps.py?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -19,6 +19,7 @@\n components = sys.argv[2].split(' ')\n components = [i for i in components if i]  # ignore extra whitespaces\n enable_static = sys.argv[3]\n+llconfig = sys.argv[4]\n \n f.write(\"\"\"// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n // file at the top-level directory of this distribution and at\n@@ -44,69 +45,47 @@ def run(args):\n         sys.exit(1)\n     return out\n \n-for llconfig in sys.argv[4:]:\n-    f.write(\"\\n\")\n-\n-    out = run([llconfig, '--host-target'])\n-    arch, os = out.split('-', 1)\n-    arch = 'x86' if arch == 'i686' or arch == 'i386' else arch\n-    if 'darwin' in os:\n-        os = 'macos'\n-    elif 'linux' in os:\n-        os = 'linux'\n-    elif 'freebsd' in os:\n-        os = 'freebsd'\n-    elif 'dragonfly' in os:\n-        os = 'dragonfly'\n-    elif 'android' in os:\n-        os = 'android'\n-    elif 'win' in os or 'mingw' in os:\n-        os = 'windows'\n-    cfg = [\n-        \"target_arch = \\\"\" + arch + \"\\\"\",\n-        \"target_os = \\\"\" + os + \"\\\"\",\n-    ]\n-\n-    f.write(\"#[cfg(all(\" + ', '.join(cfg) + \"))]\\n\")\n-\n-    version = run([llconfig, '--version']).strip()\n-\n-    # LLVM libs\n-    if version < '3.5':\n-      args = [llconfig, '--libs']\n-    else:\n-      args = [llconfig, '--libs', '--system-libs']\n-    args.extend(components)\n-    out = run(args)\n-    for lib in out.strip().replace(\"\\n\", ' ').split(' '):\n-        lib = lib.strip()[2:] # chop of the leading '-l'\n-        f.write(\"#[link(name = \\\"\" + lib + \"\\\"\")\n-        # LLVM libraries are all static libraries\n-        if 'LLVM' in lib:\n-            f.write(\", kind = \\\"static\\\"\")\n-        f.write(\")]\\n\")\n-\n-    # llvm-config before 3.5 didn't have a system-libs flag\n-    if version < '3.5':\n-      if os == 'win32':\n+f.write(\"\\n\")\n+\n+version = run([llconfig, '--version']).strip()\n+\n+# LLVM libs\n+if version < '3.5':\n+    args = [llconfig, '--libs']\n+else:\n+    args = [llconfig, '--libs', '--system-libs']\n+\n+args.extend(components)\n+out = run(args)\n+for lib in out.strip().replace(\"\\n\", ' ').split(' '):\n+    lib = lib.strip()[2:] # chop of the leading '-l'\n+    f.write(\"#[link(name = \\\"\" + lib + \"\\\"\")\n+    # LLVM libraries are all static libraries\n+    if 'LLVM' in lib:\n+        f.write(\", kind = \\\"static\\\"\")\n+    f.write(\")]\\n\")\n+\n+# llvm-config before 3.5 didn't have a system-libs flag\n+if version < '3.5':\n+    if os == 'win32':\n         f.write(\"#[link(name = \\\"imagehlp\\\")]\")\n \n-    # LLVM ldflags\n-    out = run([llconfig, '--ldflags'])\n-    for lib in out.strip().split(' '):\n-        if lib[:2] == \"-l\":\n-            f.write(\"#[link(name = \\\"\" + lib[2:] + \"\\\")]\\n\")\n-\n-    # C++ runtime library\n-    out = run([llconfig, '--cxxflags'])\n-    if enable_static == '1':\n-      assert('stdlib=libc++' not in out)\n-      f.write(\"#[link(name = \\\"stdc++\\\", kind = \\\"static\\\")]\\n\")\n-    else:\n-      if 'stdlib=libc++' in out:\n+# LLVM ldflags\n+out = run([llconfig, '--ldflags'])\n+for lib in out.strip().split(' '):\n+    if lib[:2] == \"-l\":\n+        f.write(\"#[link(name = \\\"\" + lib[2:] + \"\\\")]\\n\")\n+\n+# C++ runtime library\n+out = run([llconfig, '--cxxflags'])\n+if enable_static == '1':\n+    assert('stdlib=libc++' not in out)\n+    f.write(\"#[link(name = \\\"stdc++\\\", kind = \\\"static\\\")]\\n\")\n+else:\n+    if 'stdlib=libc++' in out:\n         f.write(\"#[link(name = \\\"c++\\\")]\\n\")\n-      else:\n+    else:\n         f.write(\"#[link(name = \\\"stdc++\\\")]\\n\")\n \n-    # Attach everything to an extern block\n-    f.write(\"extern {}\\n\")\n+# Attach everything to an extern block\n+f.write(\"extern {}\\n\")"}, {"sha": "cbf45ee36a3d8e30c8c60776c2cc62ae7306f3e8", "filename": "src/libcollections/binary_heap.rs", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fbinary_heap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fbinary_heap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fbinary_heap.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -567,6 +567,13 @@ impl<'a, T> Iterator<&'a T> for Items<'a, T> {\n     fn size_hint(&self) -> (uint, Option<uint>) { self.iter.size_hint() }\n }\n \n+impl<'a, T> DoubleEndedIterator<&'a T> for Items<'a, T> {\n+    #[inline]\n+    fn next_back(&mut self) -> Option<(&'a T)> { self.iter.next_back() }\n+}\n+\n+impl<'a, T> ExactSizeIterator<&'a T> for Items<'a, T> {}\n+\n /// An iterator that moves out of a `BinaryHeap`.\n pub struct MoveItems<T> {\n     iter: vec::MoveItems<T>,\n@@ -625,6 +632,16 @@ mod tests {\n         }\n     }\n \n+    #[test]\n+    fn test_iterator_reverse() {\n+        let data = vec!(5i, 9, 3);\n+        let iterout = vec!(3i, 5, 9);\n+        let pq = BinaryHeap::from_vec(data);\n+\n+        let v: Vec<int> = pq.iter().rev().map(|&x| x).collect();\n+        assert_eq!(v, iterout);\n+    }\n+\n     #[test]\n     fn test_move_iter() {\n         let data = vec!(5i, 9, 3);"}, {"sha": "d21465c822f4745875a2155b1d7920278dbf1cdc", "filename": "src/libcollections/enum_set.rs", "status": "modified", "additions": 19, "deletions": 21, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fenum_set.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fenum_set.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fenum_set.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -42,27 +42,25 @@ impl<E:CLike+fmt::Show> fmt::Show for EnumSet<E> {\n     }\n }\n \n-/**\n-An interface for casting C-like enum to uint and back.\n-A typically implementation is as below.\n-\n-```{rust,ignore}\n-#[repr(uint)]\n-enum Foo {\n-    A, B, C\n-}\n-\n-impl CLike for Foo {\n-    fn to_uint(&self) -> uint {\n-        *self as uint\n-    }\n-\n-    fn from_uint(v: uint) -> Foo {\n-        unsafe { mem::transmute(v) }\n-    }\n-}\n-```\n-*/\n+/// An interface for casting C-like enum to uint and back.\n+/// A typically implementation is as below.\n+///\n+/// ```{rust,ignore}\n+/// #[repr(uint)]\n+/// enum Foo {\n+///     A, B, C\n+/// }\n+///\n+/// impl CLike for Foo {\n+///     fn to_uint(&self) -> uint {\n+///         *self as uint\n+///     }\n+///\n+///     fn from_uint(v: uint) -> Foo {\n+///         unsafe { mem::transmute(v) }\n+///     }\n+/// }\n+/// ```\n pub trait CLike {\n     /// Converts a C-like enum to a `uint`.\n     fn to_uint(&self) -> uint;"}, {"sha": "1dc2539c592e9d68564aaa26055ff39f4b750437", "filename": "src/libcollections/hash/mod.rs", "status": "modified", "additions": 50, "deletions": 52, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fhash%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fhash%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fhash%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,58 +8,56 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Generic hashing support.\n- *\n- * This module provides a generic way to compute the hash of a value. The\n- * simplest way to make a type hashable is to use `#[deriving(Hash)]`:\n- *\n- * # Example\n- *\n- * ```rust\n- * use std::hash;\n- * use std::hash::Hash;\n- *\n- * #[deriving(Hash)]\n- * struct Person {\n- *     id: uint,\n- *     name: String,\n- *     phone: u64,\n- * }\n- *\n- * let person1 = Person { id: 5, name: \"Janet\".to_string(), phone: 555_666_7777 };\n- * let person2 = Person { id: 5, name: \"Bob\".to_string(), phone: 555_666_7777 };\n- *\n- * assert!(hash::hash(&person1) != hash::hash(&person2));\n- * ```\n- *\n- * If you need more control over how a value is hashed, you need to implement\n- * the trait `Hash`:\n- *\n- * ```rust\n- * use std::hash;\n- * use std::hash::Hash;\n- * use std::hash::sip::SipState;\n- *\n- * struct Person {\n- *     id: uint,\n- *     name: String,\n- *     phone: u64,\n- * }\n- *\n- * impl Hash for Person {\n- *     fn hash(&self, state: &mut SipState) {\n- *         self.id.hash(state);\n- *         self.phone.hash(state);\n- *     }\n- * }\n- *\n- * let person1 = Person { id: 5, name: \"Janet\".to_string(), phone: 555_666_7777 };\n- * let person2 = Person { id: 5, name: \"Bob\".to_string(), phone: 555_666_7777 };\n- *\n- * assert!(hash::hash(&person1) == hash::hash(&person2));\n- * ```\n- */\n+//! Generic hashing support.\n+//!\n+//! This module provides a generic way to compute the hash of a value. The\n+//! simplest way to make a type hashable is to use `#[deriving(Hash)]`:\n+//!\n+//! # Example\n+//!\n+//! ```rust\n+//! use std::hash;\n+//! use std::hash::Hash;\n+//!\n+//! #[deriving(Hash)]\n+//! struct Person {\n+//!     id: uint,\n+//!     name: String,\n+//!     phone: u64,\n+//! }\n+//!\n+//! let person1 = Person { id: 5, name: \"Janet\".to_string(), phone: 555_666_7777 };\n+//! let person2 = Person { id: 5, name: \"Bob\".to_string(), phone: 555_666_7777 };\n+//!\n+//! assert!(hash::hash(&person1) != hash::hash(&person2));\n+//! ```\n+//!\n+//! If you need more control over how a value is hashed, you need to implement\n+//! the trait `Hash`:\n+//!\n+//! ```rust\n+//! use std::hash;\n+//! use std::hash::Hash;\n+//! use std::hash::sip::SipState;\n+//!\n+//! struct Person {\n+//!     id: uint,\n+//!     name: String,\n+//!     phone: u64,\n+//! }\n+//!\n+//! impl Hash for Person {\n+//!     fn hash(&self, state: &mut SipState) {\n+//!         self.id.hash(state);\n+//!         self.phone.hash(state);\n+//!     }\n+//! }\n+//!\n+//! let person1 = Person { id: 5, name: \"Janet\".to_string(), phone: 555_666_7777 };\n+//! let person2 = Person { id: 5, name: \"Bob\".to_string(), phone: 555_666_7777 };\n+//!\n+//! assert!(hash::hash(&person1) == hash::hash(&person2));\n+//! ```\n \n #![allow(unused_must_use)]\n "}, {"sha": "e11ba35367e2eb56770887eb8e3ea9cdb9f18af6", "filename": "src/libcollections/ring_buf.rs", "status": "modified", "additions": 102, "deletions": 8, "changes": 110, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fring_buf.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fring_buf.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fring_buf.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -34,8 +34,6 @@ static MINIMUM_CAPACITY: uint = 2u;\n \n // FIXME(conventions): implement shrink_to_fit. Awkward with the current design, but it should\n // be scrapped anyway. Defer to rewrite?\n-// FIXME(conventions): implement into_iter\n-\n \n /// `RingBuf` is a circular buffer that implements `Deque`.\n pub struct RingBuf<T> {\n@@ -394,6 +392,14 @@ impl<T> RingBuf<T> {\n         }\n     }\n \n+    /// Consumes the list into an iterator yielding elements by value.\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn into_iter(self) -> MoveItems<T> {\n+        MoveItems {\n+            inner: self,\n+        }\n+    }\n+\n     /// Returns the number of elements in the `RingBuf`.\n     ///\n     /// # Example\n@@ -736,11 +742,9 @@ impl<'a, T> Iterator<&'a mut T> for MutItems<'a, T> {\n         }\n         let tail = self.tail;\n         self.tail = wrap_index(self.tail + 1, self.cap);\n-        if mem::size_of::<T>() != 0 {\n-            unsafe { Some(&mut *self.ptr.offset(tail as int)) }\n-        } else {\n-            // use a non-zero pointer\n-            Some(unsafe { mem::transmute(1u) })\n+\n+        unsafe {\n+            Some(&mut *self.ptr.offset(tail as int))\n         }\n     }\n \n@@ -758,12 +762,43 @@ impl<'a, T> DoubleEndedIterator<&'a mut T> for MutItems<'a, T> {\n             return None;\n         }\n         self.head = wrap_index(self.head - 1, self.cap);\n-        unsafe { Some(&mut *self.ptr.offset(self.head as int)) }\n+\n+        unsafe {\n+            Some(&mut *self.ptr.offset(self.head as int))\n+        }\n     }\n }\n \n impl<'a, T> ExactSizeIterator<&'a mut T> for MutItems<'a, T> {}\n \n+// A by-value RingBuf iterator\n+pub struct MoveItems<T> {\n+    inner: RingBuf<T>,\n+}\n+\n+impl<T> Iterator<T> for MoveItems<T> {\n+    #[inline]\n+    fn next(&mut self) -> Option<T> {\n+        self.inner.pop_front()\n+    }\n+\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        let len = self.inner.len();\n+        (len, Some(len))\n+    }\n+}\n+\n+impl<T> DoubleEndedIterator<T> for MoveItems<T> {\n+    #[inline]\n+    fn next_back(&mut self) -> Option<T> {\n+        self.inner.pop_back()\n+    }\n+}\n+\n+\n+impl<T> ExactSizeIterator<T> for MoveItems<T> {}\n+\n impl<A: PartialEq> PartialEq for RingBuf<A> {\n     fn eq(&self, other: &RingBuf<A>) -> bool {\n         self.len() == other.len() &&\n@@ -1313,6 +1348,65 @@ mod tests {\n         }\n     }\n \n+    #[test]\n+    fn test_into_iter() {\n+\n+        // Empty iter\n+        {\n+            let d: RingBuf<int> = RingBuf::new();\n+            let mut iter = d.into_iter();\n+\n+            assert_eq!(iter.size_hint(), (0, Some(0)));\n+            assert_eq!(iter.next(), None);\n+            assert_eq!(iter.size_hint(), (0, Some(0)));\n+        }\n+\n+        // simple iter\n+        {\n+            let mut d = RingBuf::new();\n+            for i in range(0i, 5) {\n+                d.push_back(i);\n+            }\n+\n+            let b = vec![0,1,2,3,4];\n+            assert_eq!(d.into_iter().collect::<Vec<int>>(), b);\n+        }\n+\n+        // wrapped iter\n+        {\n+            let mut d = RingBuf::new();\n+            for i in range(0i, 5) {\n+                d.push_back(i);\n+            }\n+            for i in range(6, 9) {\n+                d.push_front(i);\n+            }\n+\n+            let b = vec![8,7,6,0,1,2,3,4];\n+            assert_eq!(d.into_iter().collect::<Vec<int>>(), b);\n+        }\n+\n+        // partially used\n+        {\n+            let mut d = RingBuf::new();\n+            for i in range(0i, 5) {\n+                d.push_back(i);\n+            }\n+            for i in range(6, 9) {\n+                d.push_front(i);\n+            }\n+\n+            let mut it = d.into_iter();\n+            assert_eq!(it.size_hint(), (8, Some(8)));\n+            assert_eq!(it.next(), Some(8));\n+            assert_eq!(it.size_hint(), (7, Some(7)));\n+            assert_eq!(it.next_back(), Some(4));\n+            assert_eq!(it.size_hint(), (6, Some(6)));\n+            assert_eq!(it.next(), Some(7));\n+            assert_eq!(it.size_hint(), (5, Some(5)));\n+        }\n+    }\n+\n     #[test]\n     fn test_from_iter() {\n         use std::iter;"}, {"sha": "6c13abdaf892f52fd2460fdcf57c94dd93b096d5", "filename": "src/libcollections/slice.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fslice.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -106,7 +106,7 @@ pub use core::slice::{OrdSlicePrelude, SlicePrelude, Items, MutItems};\n pub use core::slice::{ImmutableIntSlice, MutableIntSlice};\n pub use core::slice::{MutSplits, MutChunks, Splits};\n pub use core::slice::{bytes, mut_ref_slice, ref_slice, CloneSlicePrelude};\n-pub use core::slice::{Found, NotFound, from_raw_buf, from_raw_mut_buf};\n+pub use core::slice::{from_raw_buf, from_raw_mut_buf, BinarySearchResult};\n \n // Functional utilities\n "}, {"sha": "dd884b6ee41d88a5ab82a10c1335ef6c230ce92f", "filename": "src/libcollections/trie/set.rs", "status": "modified", "additions": 268, "deletions": 1, "changes": 269, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Ftrie%2Fset.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Ftrie%2Fset.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Ftrie%2Fset.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -9,7 +9,6 @@\n // except according to those terms.\n \n // FIXME(conventions): implement bounded iterators\n-// FIXME(conventions): implement union family of fns\n // FIXME(conventions): implement BitOr, BitAnd, BitXor, and Sub\n // FIXME(conventions): replace each_reverse by making iter DoubleEnded\n // FIXME(conventions): implement iter_mut and into_iter\n@@ -19,6 +18,7 @@ use core::prelude::*;\n use core::default::Default;\n use core::fmt;\n use core::fmt::Show;\n+use core::iter::Peekable;\n use std::hash::Hash;\n \n use trie_map::{TrieMap, Entries};\n@@ -172,6 +172,106 @@ impl TrieSet {\n         SetItems{iter: self.map.upper_bound(val)}\n     }\n \n+    /// Visits the values representing the difference, in ascending order.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::TrieSet;\n+    ///\n+    /// let a: TrieSet = [1, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: TrieSet = [3, 4, 5].iter().map(|&x| x).collect();\n+    ///\n+    /// // Can be seen as `a - b`.\n+    /// for x in a.difference(&b) {\n+    ///     println!(\"{}\", x); // Print 1 then 2\n+    /// }\n+    ///\n+    /// let diff1: TrieSet = a.difference(&b).collect();\n+    /// assert_eq!(diff1, [1, 2].iter().map(|&x| x).collect());\n+    ///\n+    /// // Note that difference is not symmetric,\n+    /// // and `b - a` means something else:\n+    /// let diff2: TrieSet = b.difference(&a).collect();\n+    /// assert_eq!(diff2, [4, 5].iter().map(|&x| x).collect());\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn difference<'a>(&'a self, other: &'a TrieSet) -> DifferenceItems<'a> {\n+        DifferenceItems{a: self.iter().peekable(), b: other.iter().peekable()}\n+    }\n+\n+    /// Visits the values representing the symmetric difference, in ascending order.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::TrieSet;\n+    ///\n+    /// let a: TrieSet = [1, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: TrieSet = [3, 4, 5].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 1, 2, 4, 5 in ascending order.\n+    /// for x in a.symmetric_difference(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff1: TrieSet = a.symmetric_difference(&b).collect();\n+    /// let diff2: TrieSet = b.symmetric_difference(&a).collect();\n+    ///\n+    /// assert_eq!(diff1, diff2);\n+    /// assert_eq!(diff1, [1, 2, 4, 5].iter().map(|&x| x).collect());\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle.\"]\n+    pub fn symmetric_difference<'a>(&'a self, other: &'a TrieSet) -> SymDifferenceItems<'a> {\n+        SymDifferenceItems{a: self.iter().peekable(), b: other.iter().peekable()}\n+    }\n+\n+    /// Visits the values representing the intersection, in ascending order.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::TrieSet;\n+    ///\n+    /// let a: TrieSet = [1, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: TrieSet = [2, 3, 4].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 2, 3 in ascending order.\n+    /// for x in a.intersection(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff: TrieSet = a.intersection(&b).collect();\n+    /// assert_eq!(diff, [2, 3].iter().map(|&x| x).collect());\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn intersection<'a>(&'a self, other: &'a TrieSet) -> IntersectionItems<'a> {\n+        IntersectionItems{a: self.iter().peekable(), b: other.iter().peekable()}\n+    }\n+\n+    /// Visits the values representing the union, in ascending order.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// use std::collections::TrieSet;\n+    ///\n+    /// let a: TrieSet = [1, 2, 3].iter().map(|&x| x).collect();\n+    /// let b: TrieSet = [3, 4, 5].iter().map(|&x| x).collect();\n+    ///\n+    /// // Print 1, 2, 3, 4, 5 in ascending order.\n+    /// for x in a.union(&b) {\n+    ///     println!(\"{}\", x);\n+    /// }\n+    ///\n+    /// let diff: TrieSet = a.union(&b).collect();\n+    /// assert_eq!(diff, [1, 2, 3, 4, 5].iter().map(|&x| x).collect());\n+    /// ```\n+    #[unstable = \"matches collection reform specification, waiting for dust to settle\"]\n+    pub fn union<'a>(&'a self, other: &'a TrieSet) -> UnionItems<'a> {\n+        UnionItems{a: self.iter().peekable(), b: other.iter().peekable()}\n+    }\n+\n     /// Return the number of elements in the set\n     ///\n     /// # Example\n@@ -368,6 +468,39 @@ pub struct SetItems<'a> {\n     iter: Entries<'a, ()>\n }\n \n+/// An iterator producing elements in the set difference (in-order).\n+pub struct DifferenceItems<'a> {\n+    a: Peekable<uint, SetItems<'a>>,\n+    b: Peekable<uint, SetItems<'a>>,\n+}\n+\n+/// An iterator producing elements in the set symmetric difference (in-order).\n+pub struct SymDifferenceItems<'a> {\n+    a: Peekable<uint, SetItems<'a>>,\n+    b: Peekable<uint, SetItems<'a>>,\n+}\n+\n+/// An iterator producing elements in the set intersection (in-order).\n+pub struct IntersectionItems<'a> {\n+    a: Peekable<uint, SetItems<'a>>,\n+    b: Peekable<uint, SetItems<'a>>,\n+}\n+\n+/// An iterator producing elements in the set union (in-order).\n+pub struct UnionItems<'a> {\n+    a: Peekable<uint, SetItems<'a>>,\n+    b: Peekable<uint, SetItems<'a>>,\n+}\n+\n+/// Compare `x` and `y`, but return `short` if x is None and `long` if y is None\n+fn cmp_opt(x: Option<&uint>, y: Option<&uint>, short: Ordering, long: Ordering) -> Ordering {\n+    match (x, y) {\n+        (None    , _       ) => short,\n+        (_       , None    ) => long,\n+        (Some(x1), Some(y1)) => x1.cmp(y1),\n+    }\n+}\n+\n impl<'a> Iterator<uint> for SetItems<'a> {\n     fn next(&mut self) -> Option<uint> {\n         self.iter.next().map(|(key, _)| key)\n@@ -378,6 +511,60 @@ impl<'a> Iterator<uint> for SetItems<'a> {\n     }\n }\n \n+impl<'a> Iterator<uint> for DifferenceItems<'a> {\n+    fn next(&mut self) -> Option<uint> {\n+        loop {\n+            match cmp_opt(self.a.peek(), self.b.peek(), Less, Less) {\n+                Less    => return self.a.next(),\n+                Equal   => { self.a.next(); self.b.next(); }\n+                Greater => { self.b.next(); }\n+            }\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator<uint> for SymDifferenceItems<'a> {\n+    fn next(&mut self) -> Option<uint> {\n+        loop {\n+            match cmp_opt(self.a.peek(), self.b.peek(), Greater, Less) {\n+                Less => return self.a.next(),\n+                Equal => { self.a.next(); self.b.next(); }\n+                Greater => return self.b.next(),\n+            }\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator<uint> for IntersectionItems<'a> {\n+    fn next(&mut self) -> Option<uint> {\n+        loop {\n+            let o_cmp = match (self.a.peek(), self.b.peek()) {\n+                (None    , _       ) => None,\n+                (_       , None    ) => None,\n+                (Some(a1), Some(b1)) => Some(a1.cmp(b1)),\n+            };\n+            match o_cmp {\n+                None          => return None,\n+                Some(Less)    => { self.a.next(); }\n+                Some(Equal)   => { self.b.next(); return self.a.next() }\n+                Some(Greater) => { self.b.next(); }\n+            }\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator<uint> for UnionItems<'a> {\n+    fn next(&mut self) -> Option<uint> {\n+        loop {\n+            match cmp_opt(self.a.peek(), self.b.peek(), Greater, Less) {\n+                Less    => return self.a.next(),\n+                Equal   => { self.b.next(); return self.a.next() }\n+                Greater => return self.b.next(),\n+            }\n+        }\n+    }\n+}\n+\n #[cfg(test)]\n mod test {\n     use std::prelude::*;\n@@ -471,4 +658,84 @@ mod test {\n         assert!(b > a && b >= a);\n         assert!(a < b && a <= b);\n     }\n+\n+    fn check(a: &[uint],\n+             b: &[uint],\n+             expected: &[uint],\n+             f: |&TrieSet, &TrieSet, f: |uint| -> bool| -> bool) {\n+        let mut set_a = TrieSet::new();\n+        let mut set_b = TrieSet::new();\n+\n+        for x in a.iter() { assert!(set_a.insert(*x)) }\n+        for y in b.iter() { assert!(set_b.insert(*y)) }\n+\n+        let mut i = 0;\n+        f(&set_a, &set_b, |x| {\n+            assert_eq!(x, expected[i]);\n+            i += 1;\n+            true\n+        });\n+        assert_eq!(i, expected.len());\n+    }\n+\n+    #[test]\n+    fn test_intersection() {\n+        fn check_intersection(a: &[uint], b: &[uint], expected: &[uint]) {\n+            check(a, b, expected, |x, y, f| x.intersection(y).all(f))\n+        }\n+\n+        check_intersection(&[], &[], &[]);\n+        check_intersection(&[1, 2, 3], &[], &[]);\n+        check_intersection(&[], &[1, 2, 3], &[]);\n+        check_intersection(&[2], &[1, 2, 3], &[2]);\n+        check_intersection(&[1, 2, 3], &[2], &[2]);\n+        check_intersection(&[11, 1, 3, 77, 103, 5],\n+                           &[2, 11, 77, 5, 3],\n+                           &[3, 5, 11, 77]);\n+    }\n+\n+    #[test]\n+    fn test_difference() {\n+        fn check_difference(a: &[uint], b: &[uint], expected: &[uint]) {\n+            check(a, b, expected, |x, y, f| x.difference(y).all(f))\n+        }\n+\n+        check_difference(&[], &[], &[]);\n+        check_difference(&[1, 12], &[], &[1, 12]);\n+        check_difference(&[], &[1, 2, 3, 9], &[]);\n+        check_difference(&[1, 3, 5, 9, 11],\n+                         &[3, 9],\n+                         &[1, 5, 11]);\n+        check_difference(&[11, 22, 33, 40, 42],\n+                         &[14, 23, 34, 38, 39, 50],\n+                         &[11, 22, 33, 40, 42]);\n+    }\n+\n+    #[test]\n+    fn test_symmetric_difference() {\n+        fn check_symmetric_difference(a: &[uint], b: &[uint], expected: &[uint]) {\n+            check(a, b, expected, |x, y, f| x.symmetric_difference(y).all(f))\n+        }\n+\n+        check_symmetric_difference(&[], &[], &[]);\n+        check_symmetric_difference(&[1, 2, 3], &[2], &[1, 3]);\n+        check_symmetric_difference(&[2], &[1, 2, 3], &[1, 3]);\n+        check_symmetric_difference(&[1, 3, 5, 9, 11],\n+                                   &[3, 9, 14, 22],\n+                                   &[1, 5, 11, 14, 22]);\n+    }\n+\n+    #[test]\n+    fn test_union() {\n+        fn check_union(a: &[uint], b: &[uint], expected: &[uint]) {\n+            check(a, b, expected, |x, y, f| x.union(y).all(f))\n+        }\n+\n+        check_union(&[], &[], &[]);\n+        check_union(&[1, 2, 3], &[2], &[1, 2, 3]);\n+        check_union(&[2], &[1, 2, 3], &[1, 2, 3]);\n+        check_union(&[1, 3, 5, 9, 11, 16, 19, 24],\n+                    &[1, 5, 9, 13, 19],\n+                    &[1, 3, 5, 9, 11, 13, 16, 19, 24]);\n+    }\n }"}, {"sha": "5edd3d0b780be11d831d036ef2dd47ed06e8e544", "filename": "src/libcollections/vec.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcollections%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fvec.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -187,6 +187,7 @@ impl<T> Vec<T> {\n             let size = capacity.checked_mul(mem::size_of::<T>())\n                                .expect(\"capacity overflow\");\n             let ptr = unsafe { allocate(size, mem::min_align_of::<T>()) };\n+            if ptr.is_null() { ::alloc::oom() }\n             Vec { ptr: ptr as *mut T, len: 0, cap: capacity }\n         }\n     }"}, {"sha": "9f928f57e9e400c856c27b81511c8141c8d81557", "filename": "src/libcore/clone.rs", "status": "modified", "additions": 10, "deletions": 12, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fclone.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fclone.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fclone.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,18 +8,16 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! The `Clone` trait for types that cannot be 'implicitly copied'\n-\n-In Rust, some simple types are \"implicitly copyable\" and when you\n-assign them or pass them as arguments, the receiver will get a copy,\n-leaving the original value in place. These types do not require\n-allocation to copy and do not have finalizers (i.e. they do not\n-contain owned boxes or implement `Drop`), so the compiler considers\n-them cheap and safe to copy. For other types copies must be made\n-explicitly, by convention implementing the `Clone` trait and calling\n-the `clone` method.\n-\n-*/\n+//! The `Clone` trait for types that cannot be 'implicitly copied'\n+//!\n+//! In Rust, some simple types are \"implicitly copyable\" and when you\n+//! assign them or pass them as arguments, the receiver will get a copy,\n+//! leaving the original value in place. These types do not require\n+//! allocation to copy and do not have finalizers (i.e. they do not\n+//! contain owned boxes or implement `Drop`), so the compiler considers\n+//! them cheap and safe to copy. For other types copies must be made\n+//! explicitly, by convention implementing the `Clone` trait and calling\n+//! the `clone` method.\n \n #![unstable]\n "}, {"sha": "d2b7591b3efa10a32050d348b682602816f63ad9", "filename": "src/libcore/finally.rs", "status": "modified", "additions": 49, "deletions": 53, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffinally.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffinally.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ffinally.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,27 +8,25 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-The Finally trait provides a method, `finally` on\n-stack closures that emulates Java-style try/finally blocks.\n-\n-Using the `finally` method is sometimes convenient, but the type rules\n-prohibit any shared, mutable state between the \"try\" case and the\n-\"finally\" case. For advanced cases, the `try_finally` function can\n-also be used. See that function for more details.\n-\n-# Example\n-\n-```\n-use std::finally::Finally;\n-\n-(|| {\n-    // ...\n-}).finally(|| {\n-    // this code is always run\n-})\n-```\n-*/\n+//! The Finally trait provides a method, `finally` on\n+//! stack closures that emulates Java-style try/finally blocks.\n+//!\n+//! Using the `finally` method is sometimes convenient, but the type rules\n+//! prohibit any shared, mutable state between the \"try\" case and the\n+//! \"finally\" case. For advanced cases, the `try_finally` function can\n+//! also be used. See that function for more details.\n+//!\n+//! # Example\n+//!\n+//! ```\n+//! use std::finally::Finally;\n+//!\n+//! (|| {\n+//!     // ...\n+//! }).finally(|| {\n+//!     // this code is always run\n+//! })\n+//! ```\n \n #![experimental]\n \n@@ -58,38 +56,36 @@ impl<T> Finally<T> for fn() -> T {\n     }\n }\n \n-/**\n- * The most general form of the `finally` functions. The function\n- * `try_fn` will be invoked first; whether or not it panics, the\n- * function `finally_fn` will be invoked next. The two parameters\n- * `mutate` and `drop` are used to thread state through the two\n- * closures. `mutate` is used for any shared, mutable state that both\n- * closures require access to; `drop` is used for any state that the\n- * `try_fn` requires ownership of.\n- *\n- * **WARNING:** While shared, mutable state between the try and finally\n- * function is often necessary, one must be very careful; the `try`\n- * function could have panicked at any point, so the values of the shared\n- * state may be inconsistent.\n- *\n- * # Example\n- *\n- * ```\n- * use std::finally::try_finally;\n- *\n- * struct State<'a> { buffer: &'a mut [u8], len: uint }\n- * # let mut buf = [];\n- * let mut state = State { buffer: &mut buf, len: 0 };\n- * try_finally(\n- *     &mut state, (),\n- *     |state, ()| {\n- *         // use state.buffer, state.len\n- *     },\n- *     |state| {\n- *         // use state.buffer, state.len to cleanup\n- *     })\n- * ```\n- */\n+/// The most general form of the `finally` functions. The function\n+/// `try_fn` will be invoked first; whether or not it panics, the\n+/// function `finally_fn` will be invoked next. The two parameters\n+/// `mutate` and `drop` are used to thread state through the two\n+/// closures. `mutate` is used for any shared, mutable state that both\n+/// closures require access to; `drop` is used for any state that the\n+/// `try_fn` requires ownership of.\n+///\n+/// **WARNING:** While shared, mutable state between the try and finally\n+/// function is often necessary, one must be very careful; the `try`\n+/// function could have panicked at any point, so the values of the shared\n+/// state may be inconsistent.\n+///\n+/// # Example\n+///\n+/// ```\n+/// use std::finally::try_finally;\n+///\n+/// struct State<'a> { buffer: &'a mut [u8], len: uint }\n+/// # let mut buf = [];\n+/// let mut state = State { buffer: &mut buf, len: 0 };\n+/// try_finally(\n+///     &mut state, (),\n+///     |state, ()| {\n+///         // use state.buffer, state.len\n+///     },\n+///     |state| {\n+///         // use state.buffer, state.len to cleanup\n+///     })\n+/// ```\n pub fn try_finally<T,U,R>(mutate: &mut T,\n                           drop: U,\n                           try_fn: |&mut T, U| -> R,"}, {"sha": "1e31df837794273f0ed9fd27b7ad7970671e27ec", "filename": "src/libcore/fmt/float.rs", "status": "modified", "additions": 30, "deletions": 30, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffmt%2Ffloat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffmt%2Ffloat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ffmt%2Ffloat.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -54,36 +54,36 @@ pub enum SignFormat {\n \n static DIGIT_E_RADIX: uint = ('e' as uint) - ('a' as uint) + 11u;\n \n-/**\n- * Converts a number to its string representation as a byte vector.\n- * This is meant to be a common base implementation for all numeric string\n- * conversion functions like `to_string()` or `to_str_radix()`.\n- *\n- * # Arguments\n- * - `num`           - The number to convert. Accepts any number that\n- *                     implements the numeric traits.\n- * - `radix`         - Base to use. Accepts only the values 2-36. If the exponential notation\n- *                     is used, then this base is only used for the significand. The exponent\n- *                     itself always printed using a base of 10.\n- * - `negative_zero` - Whether to treat the special value `-0` as\n- *                     `-0` or as `+0`.\n- * - `sign`          - How to emit the sign. See `SignFormat`.\n- * - `digits`        - The amount of digits to use for emitting the fractional\n- *                     part, if any. See `SignificantDigits`.\n- * - `exp_format`   - Whether or not to use the exponential (scientific) notation.\n- *                    See `ExponentFormat`.\n- * - `exp_capital`   - Whether or not to use a capital letter for the exponent sign, if\n- *                     exponential notation is desired.\n- * - `f`             - A closure to invoke with the bytes representing the\n- *                     float.\n- *\n- * # Panics\n- * - Panics if `radix` < 2 or `radix` > 36.\n- * - Panics if `radix` > 14 and `exp_format` is `ExpDec` due to conflict\n- *   between digit and exponent sign `'e'`.\n- * - Panics if `radix` > 25 and `exp_format` is `ExpBin` due to conflict\n- *   between digit and exponent sign `'p'`.\n- */\n+/// Converts a number to its string representation as a byte vector.\n+/// This is meant to be a common base implementation for all numeric string\n+/// conversion functions like `to_string()` or `to_str_radix()`.\n+///\n+/// # Arguments\n+///\n+/// - `num`           - The number to convert. Accepts any number that\n+///                     implements the numeric traits.\n+/// - `radix`         - Base to use. Accepts only the values 2-36. If the exponential notation\n+///                     is used, then this base is only used for the significand. The exponent\n+///                     itself always printed using a base of 10.\n+/// - `negative_zero` - Whether to treat the special value `-0` as\n+///                     `-0` or as `+0`.\n+/// - `sign`          - How to emit the sign. See `SignFormat`.\n+/// - `digits`        - The amount of digits to use for emitting the fractional\n+///                     part, if any. See `SignificantDigits`.\n+/// - `exp_format`   - Whether or not to use the exponential (scientific) notation.\n+///                    See `ExponentFormat`.\n+/// - `exp_capital`   - Whether or not to use a capital letter for the exponent sign, if\n+///                     exponential notation is desired.\n+/// - `f`             - A closure to invoke with the bytes representing the\n+///                     float.\n+///\n+/// # Panics\n+///\n+/// - Panics if `radix` < 2 or `radix` > 36.\n+/// - Panics if `radix` > 14 and `exp_format` is `ExpDec` due to conflict\n+///   between digit and exponent sign `'e'`.\n+/// - Panics if `radix` > 25 and `exp_format` is `ExpBin` due to conflict\n+///   between digit and exponent sign `'p'`.\n pub fn float_to_str_bytes_common<T: Float, U>(\n     num: T,\n     radix: uint,"}, {"sha": "1d6906c13a8fa028e036c63f9fc83ae9928caaf2", "filename": "src/libcore/fmt/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffmt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Ffmt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Ffmt%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -85,7 +85,7 @@ pub struct Formatter<'a> {\n     width: Option<uint>,\n     precision: Option<uint>,\n \n-    buf: &'a mut FormatWriter+'a,\n+    buf: &'a mut (FormatWriter+'a),\n     curarg: slice::Items<'a, Argument<'a>>,\n     args: &'a [Argument<'a>],\n }\n@@ -565,7 +565,7 @@ impl<'a, Sized? T: Show> Show for &'a T {\n impl<'a, Sized? T: Show> Show for &'a mut T {\n     fn fmt(&self, f: &mut Formatter) -> Result { (**self).fmt(f) }\n }\n-impl<'a> Show for &'a Show+'a {\n+impl<'a> Show for &'a (Show+'a) {\n     fn fmt(&self, f: &mut Formatter) -> Result { (*self).fmt(f) }\n }\n \n@@ -724,7 +724,7 @@ macro_rules! tuple (\n \n tuple! { T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, }\n \n-impl<'a> Show for &'a any::Any+'a {\n+impl<'a> Show for &'a (any::Any+'a) {\n     fn fmt(&self, f: &mut Formatter) -> Result { f.pad(\"&Any\") }\n }\n "}, {"sha": "78c74075d4867107131380631481c8d2ac0f0197", "filename": "src/libcore/intrinsics.rs", "status": "modified", "additions": 30, "deletions": 32, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fintrinsics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fintrinsics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fintrinsics.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,38 +8,36 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! rustc compiler intrinsics.\n-\n-The corresponding definitions are in librustc/middle/trans/foreign.rs.\n-\n-# Volatiles\n-\n-The volatile intrinsics provide operations intended to act on I/O\n-memory, which are guaranteed to not be reordered by the compiler\n-across other volatile intrinsics. See the LLVM documentation on\n-[[volatile]].\n-\n-[volatile]: http://llvm.org/docs/LangRef.html#volatile-memory-accesses\n-\n-# Atomics\n-\n-The atomic intrinsics provide common atomic operations on machine\n-words, with multiple possible memory orderings. They obey the same\n-semantics as C++11. See the LLVM documentation on [[atomics]].\n-\n-[atomics]: http://llvm.org/docs/Atomics.html\n-\n-A quick refresher on memory ordering:\n-\n-* Acquire - a barrier for acquiring a lock. Subsequent reads and writes\n-  take place after the barrier.\n-* Release - a barrier for releasing a lock. Preceding reads and writes\n-  take place before the barrier.\n-* Sequentially consistent - sequentially consistent operations are\n-  guaranteed to happen in order. This is the standard mode for working\n-  with atomic types and is equivalent to Java's `volatile`.\n-\n-*/\n+//! rustc compiler intrinsics.\n+//!\n+//! The corresponding definitions are in librustc/middle/trans/foreign.rs.\n+//!\n+//! # Volatiles\n+//!\n+//! The volatile intrinsics provide operations intended to act on I/O\n+//! memory, which are guaranteed to not be reordered by the compiler\n+//! across other volatile intrinsics. See the LLVM documentation on\n+//! [[volatile]].\n+//!\n+//! [volatile]: http://llvm.org/docs/LangRef.html#volatile-memory-accesses\n+//!\n+//! # Atomics\n+//!\n+//! The atomic intrinsics provide common atomic operations on machine\n+//! words, with multiple possible memory orderings. They obey the same\n+//! semantics as C++11. See the LLVM documentation on [[atomics]].\n+//!\n+//! [atomics]: http://llvm.org/docs/Atomics.html\n+//!\n+//! A quick refresher on memory ordering:\n+//!\n+//! * Acquire - a barrier for acquiring a lock. Subsequent reads and writes\n+//!   take place after the barrier.\n+//! * Release - a barrier for releasing a lock. Preceding reads and writes\n+//!   take place before the barrier.\n+//! * Sequentially consistent - sequentially consistent operations are\n+//!   guaranteed to happen in order. This is the standard mode for working\n+//!   with atomic types and is equivalent to Java's `volatile`.\n \n #![experimental]\n #![allow(missing_docs)]"}, {"sha": "2d488a4b15563196d0f2a5526d3171941e00f68c", "filename": "src/libcore/iter.rs", "status": "modified", "additions": 45, "deletions": 49, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fiter.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fiter.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fiter.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,55 +8,51 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Composable external iterators\n-\n-# The `Iterator` trait\n-\n-This module defines Rust's core iteration trait. The `Iterator` trait has one\n-unimplemented method, `next`. All other methods are derived through default\n-methods to perform operations such as `zip`, `chain`, `enumerate`, and `fold`.\n-\n-The goal of this module is to unify iteration across all containers in Rust.\n-An iterator can be considered as a state machine which is used to track which\n-element will be yielded next.\n-\n-There are various extensions also defined in this module to assist with various\n-types of iteration, such as the `DoubleEndedIterator` for iterating in reverse,\n-the `FromIterator` trait for creating a container from an iterator, and much\n-more.\n-\n-## Rust's `for` loop\n-\n-The special syntax used by rust's `for` loop is based around the `Iterator`\n-trait defined in this module. For loops can be viewed as a syntactical expansion\n-into a `loop`, for example, the `for` loop in this example is essentially\n-translated to the `loop` below.\n-\n-```rust\n-let values = vec![1i, 2, 3];\n-\n-// \"Syntactical sugar\" taking advantage of an iterator\n-for &x in values.iter() {\n-    println!(\"{}\", x);\n-}\n-\n-// Rough translation of the iteration without a `for` iterator.\n-let mut it = values.iter();\n-loop {\n-    match it.next() {\n-        Some(&x) => {\n-            println!(\"{}\", x);\n-        }\n-        None => { break }\n-    }\n-}\n-```\n-\n-This `for` loop syntax can be applied to any iterator over any type.\n-\n-*/\n+//! Composable external iterators\n+//!\n+//! # The `Iterator` trait\n+//!\n+//! This module defines Rust's core iteration trait. The `Iterator` trait has one\n+//! unimplemented method, `next`. All other methods are derived through default\n+//! methods to perform operations such as `zip`, `chain`, `enumerate`, and `fold`.\n+//!\n+//! The goal of this module is to unify iteration across all containers in Rust.\n+//! An iterator can be considered as a state machine which is used to track which\n+//! element will be yielded next.\n+//!\n+//! There are various extensions also defined in this module to assist with various\n+//! types of iteration, such as the `DoubleEndedIterator` for iterating in reverse,\n+//! the `FromIterator` trait for creating a container from an iterator, and much\n+//! more.\n+//!\n+//! ## Rust's `for` loop\n+//!\n+//! The special syntax used by rust's `for` loop is based around the `Iterator`\n+//! trait defined in this module. For loops can be viewed as a syntactical expansion\n+//! into a `loop`, for example, the `for` loop in this example is essentially\n+//! translated to the `loop` below.\n+//!\n+//! ```rust\n+//! let values = vec![1i, 2, 3];\n+//!\n+//! // \"Syntactical sugar\" taking advantage of an iterator\n+//! for &x in values.iter() {\n+//!     println!(\"{}\", x);\n+//! }\n+//!\n+//! // Rough translation of the iteration without a `for` iterator.\n+//! let mut it = values.iter();\n+//! loop {\n+//!     match it.next() {\n+//!         Some(&x) => {\n+//!             println!(\"{}\", x);\n+//!         }\n+//!         None => { break }\n+//!     }\n+//! }\n+//! ```\n+//!\n+//! This `for` loop syntax can be applied to any iterator over any type.\n \n pub use self::MinMaxResult::*;\n "}, {"sha": "0c2cb9d5910056cd385c6ab84d0de9f2493b96aa", "filename": "src/libcore/kinds.rs", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fkinds.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fkinds.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fkinds.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,17 +8,14 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-Primitive traits representing basic 'kinds' of types\n-\n-Rust types can be classified in various useful ways according to\n-intrinsic properties of the type. These classifications, often called\n-'kinds', are represented as traits.\n-\n-They cannot be implemented by user code, but are instead implemented\n-by the compiler automatically for the types to which they apply.\n-\n-*/\n+//! Primitive traits representing basic 'kinds' of types\n+//!\n+//! Rust types can be classified in various useful ways according to\n+//! intrinsic properties of the type. These classifications, often called\n+//! 'kinds', are represented as traits.\n+//!\n+//! They cannot be implemented by user code, but are instead implemented\n+//! by the compiler automatically for the types to which they apply.\n \n /// Types able to be transferred across task boundaries.\n #[lang=\"send\"]"}, {"sha": "d85481098e4ffaabfbe6d0145b5d59f5d9522e6e", "filename": "src/libcore/ops.rs", "status": "modified", "additions": 482, "deletions": 543, "changes": 1025, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fops.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fops.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fops.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,109 +8,99 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- *\n- * Overloadable operators\n- *\n- * Implementing these traits allows you to get an effect similar to\n- * overloading operators.\n- *\n- * The values for the right hand side of an operator are automatically\n- * borrowed, so `a + b` is sugar for `a.add(&b)`.\n- *\n- * All of these traits are imported by the prelude, so they are available in\n- * every Rust program.\n- *\n- * # Example\n- *\n- * This example creates a `Point` struct that implements `Add` and `Sub`, and then\n- * demonstrates adding and subtracting two `Point`s.\n- *\n- * ```rust\n- * #[deriving(Show)]\n- * struct Point {\n- *     x: int,\n- *     y: int\n- * }\n- *\n- * impl Add<Point, Point> for Point {\n- *     fn add(&self, other: &Point) -> Point {\n- *         Point {x: self.x + other.x, y: self.y + other.y}\n- *     }\n- * }\n- *\n- * impl Sub<Point, Point> for Point {\n- *     fn sub(&self, other: &Point) -> Point {\n- *         Point {x: self.x - other.x, y: self.y - other.y}\n- *     }\n- * }\n- * fn main() {\n- *     println!(\"{}\", Point {x: 1, y: 0} + Point {x: 2, y: 3});\n- *     println!(\"{}\", Point {x: 1, y: 0} - Point {x: 2, y: 3});\n- * }\n- * ```\n- *\n- * See the documentation for each trait for a minimum implementation that prints\n- * something to the screen.\n- *\n- */\n+//! Overloadable operators\n+//!\n+//! Implementing these traits allows you to get an effect similar to\n+//! overloading operators.\n+//!\n+//! The values for the right hand side of an operator are automatically\n+//! borrowed, so `a + b` is sugar for `a.add(&b)`.\n+//!\n+//! All of these traits are imported by the prelude, so they are available in\n+//! every Rust program.\n+//!\n+//! # Example\n+//!\n+//! This example creates a `Point` struct that implements `Add` and `Sub`, and then\n+//! demonstrates adding and subtracting two `Point`s.\n+//!\n+//! ```rust\n+//! #[deriving(Show)]\n+//! struct Point {\n+//!     x: int,\n+//!     y: int\n+//! }\n+//!\n+//! impl Add<Point, Point> for Point {\n+//!     fn add(&self, other: &Point) -> Point {\n+//!         Point {x: self.x + other.x, y: self.y + other.y}\n+//!     }\n+//! }\n+//!\n+//! impl Sub<Point, Point> for Point {\n+//!     fn sub(&self, other: &Point) -> Point {\n+//!         Point {x: self.x - other.x, y: self.y - other.y}\n+//!     }\n+//! }\n+//! fn main() {\n+//!     println!(\"{}\", Point {x: 1, y: 0} + Point {x: 2, y: 3});\n+//!     println!(\"{}\", Point {x: 1, y: 0} - Point {x: 2, y: 3});\n+//! }\n+//! ```\n+//!\n+//! See the documentation for each trait for a minimum implementation that prints\n+//! something to the screen.\n \n use kinds::Sized;\n \n-/**\n- *\n- * The `Drop` trait is used to run some code when a value goes out of scope. This\n- * is sometimes called a 'destructor'.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Drop`. The `drop` method is called when `_x` goes\n- * out of scope, and therefore `main` prints `Dropping!`.\n- *\n- * ```rust\n- * struct HasDrop;\n- *\n- * impl Drop for HasDrop {\n- *   fn drop(&mut self) {\n- *       println!(\"Dropping!\");\n- *   }\n- * }\n- *\n- * fn main() {\n- *   let _x = HasDrop;\n- * }\n- * ```\n- */\n+/// The `Drop` trait is used to run some code when a value goes out of scope. This\n+/// is sometimes called a 'destructor'.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Drop`. The `drop` method is called when `_x` goes\n+/// out of scope, and therefore `main` prints `Dropping!`.\n+///\n+/// ```rust\n+/// struct HasDrop;\n+///\n+/// impl Drop for HasDrop {\n+///   fn drop(&mut self) {\n+///       println!(\"Dropping!\");\n+///   }\n+/// }\n+///\n+/// fn main() {\n+///   let _x = HasDrop;\n+/// }\n+/// ```\n #[lang=\"drop\"]\n pub trait Drop {\n     /// The `drop` method, called when the value goes out of scope.\n     fn drop(&mut self);\n }\n \n-/**\n- *\n- * The `Add` trait is used to specify the functionality of `+`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Add`. When `Foo + Foo` happens, it ends up\n- * calling `add`, and therefore, `main` prints `Adding!`.\n- *\n- * ```rust\n- * struct Foo;\n- *\n- * impl Add<Foo, Foo> for Foo {\n- *     fn add(&self, _rhs: &Foo) -> Foo {\n- *       println!(\"Adding!\");\n- *       *self\n- *   }\n- * }\n- *\n- * fn main() {\n- *   Foo + Foo;\n- * }\n- * ```\n- */\n+/// The `Add` trait is used to specify the functionality of `+`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Add`. When `Foo + Foo` happens, it ends up\n+/// calling `add`, and therefore, `main` prints `Adding!`.\n+///\n+/// ```rust\n+/// struct Foo;\n+///\n+/// impl Add<Foo, Foo> for Foo {\n+///     fn add(&self, _rhs: &Foo) -> Foo {\n+///       println!(\"Adding!\");\n+///       *self\n+///   }\n+/// }\n+///\n+/// fn main() {\n+///   Foo + Foo;\n+/// }\n+/// ```\n #[lang=\"add\"]\n pub trait Add<Sized? RHS,Result> for Sized? {\n     /// The method for the `+` operator\n@@ -128,30 +118,27 @@ macro_rules! add_impl(\n \n add_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64 f32 f64)\n \n-/**\n- *\n- * The `Sub` trait is used to specify the functionality of `-`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Sub`. When `Foo - Foo` happens, it ends up\n- * calling `sub`, and therefore, `main` prints `Subtracting!`.\n- *\n- * ```rust\n- * struct Foo;\n- *\n- * impl Sub<Foo, Foo> for Foo {\n- *     fn sub(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Subtracting!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo - Foo;\n- * }\n- * ```\n- */\n+/// The `Sub` trait is used to specify the functionality of `-`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Sub`. When `Foo - Foo` happens, it ends up\n+/// calling `sub`, and therefore, `main` prints `Subtracting!`.\n+///\n+/// ```rust\n+/// struct Foo;\n+///\n+/// impl Sub<Foo, Foo> for Foo {\n+///     fn sub(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Subtracting!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo - Foo;\n+/// }\n+/// ```\n #[lang=\"sub\"]\n pub trait Sub<Sized? RHS, Result> for Sized? {\n     /// The method for the `-` operator\n@@ -169,30 +156,27 @@ macro_rules! sub_impl(\n \n sub_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64 f32 f64)\n \n-/**\n- *\n- * The `Mul` trait is used to specify the functionality of `*`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Mul`. When `Foo * Foo` happens, it ends up\n- * calling `mul`, and therefore, `main` prints `Multiplying!`.\n- *\n- * ```rust\n- * struct Foo;\n- *\n- * impl Mul<Foo, Foo> for Foo {\n- *     fn mul(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Multiplying!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo * Foo;\n- * }\n- * ```\n- */\n+/// The `Mul` trait is used to specify the functionality of `*`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Mul`. When `Foo * Foo` happens, it ends up\n+/// calling `mul`, and therefore, `main` prints `Multiplying!`.\n+///\n+/// ```rust\n+/// struct Foo;\n+///\n+/// impl Mul<Foo, Foo> for Foo {\n+///     fn mul(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Multiplying!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo * Foo;\n+/// }\n+/// ```\n #[lang=\"mul\"]\n pub trait Mul<Sized? RHS, Result>  for Sized? {\n     /// The method for the `*` operator\n@@ -210,30 +194,27 @@ macro_rules! mul_impl(\n \n mul_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64 f32 f64)\n \n-/**\n- *\n- * The `Div` trait is used to specify the functionality of `/`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Div`. When `Foo / Foo` happens, it ends up\n- * calling `div`, and therefore, `main` prints `Dividing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Div<Foo, Foo> for Foo {\n- *     fn div(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Dividing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo / Foo;\n- * }\n- * ```\n- */\n+/// The `Div` trait is used to specify the functionality of `/`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Div`. When `Foo / Foo` happens, it ends up\n+/// calling `div`, and therefore, `main` prints `Dividing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Div<Foo, Foo> for Foo {\n+///     fn div(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Dividing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo / Foo;\n+/// }\n+/// ```\n #[lang=\"div\"]\n pub trait Div<Sized? RHS, Result> for Sized? {\n     /// The method for the `/` operator\n@@ -251,30 +232,27 @@ macro_rules! div_impl(\n \n div_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64 f32 f64)\n \n-/**\n- *\n- * The `Rem` trait is used to specify the functionality of `%`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Rem`. When `Foo % Foo` happens, it ends up\n- * calling `rem`, and therefore, `main` prints `Remainder-ing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Rem<Foo, Foo> for Foo {\n- *     fn rem(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Remainder-ing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo % Foo;\n- * }\n- * ```\n- */\n+/// The `Rem` trait is used to specify the functionality of `%`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Rem`. When `Foo % Foo` happens, it ends up\n+/// calling `rem`, and therefore, `main` prints `Remainder-ing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Rem<Foo, Foo> for Foo {\n+///     fn rem(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Remainder-ing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo % Foo;\n+/// }\n+/// ```\n #[lang=\"rem\"]\n pub trait Rem<Sized? RHS, Result>  for Sized? {\n     /// The method for the `%` operator\n@@ -306,30 +284,27 @@ rem_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64)\n rem_float_impl!(f32, fmodf)\n rem_float_impl!(f64, fmod)\n \n-/**\n- *\n- * The `Neg` trait is used to specify the functionality of unary `-`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Neg`. When `-Foo` happens, it ends up calling\n- * `neg`, and therefore, `main` prints `Negating!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Neg<Foo> for Foo {\n- *     fn neg(&self) -> Foo {\n- *         println!(\"Negating!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     -Foo;\n- * }\n- * ```\n- */\n+/// The `Neg` trait is used to specify the functionality of unary `-`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Neg`. When `-Foo` happens, it ends up calling\n+/// `neg`, and therefore, `main` prints `Negating!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Neg<Foo> for Foo {\n+///     fn neg(&self) -> Foo {\n+///         println!(\"Negating!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     -Foo;\n+/// }\n+/// ```\n #[lang=\"neg\"]\n pub trait Neg<Result> for Sized? {\n     /// The method for the unary `-` operator\n@@ -363,30 +338,27 @@ neg_uint_impl!(u32, i32)\n neg_uint_impl!(u64, i64)\n \n \n-/**\n- *\n- * The `Not` trait is used to specify the functionality of unary `!`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Not`. When `!Foo` happens, it ends up calling\n- * `not`, and therefore, `main` prints `Not-ing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Not<Foo> for Foo {\n- *     fn not(&self) -> Foo {\n- *         println!(\"Not-ing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     !Foo;\n- * }\n- * ```\n- */\n+/// The `Not` trait is used to specify the functionality of unary `!`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Not`. When `!Foo` happens, it ends up calling\n+/// `not`, and therefore, `main` prints `Not-ing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Not<Foo> for Foo {\n+///     fn not(&self) -> Foo {\n+///         println!(\"Not-ing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     !Foo;\n+/// }\n+/// ```\n #[lang=\"not\"]\n pub trait Not<Result> for Sized? {\n     /// The method for the unary `!` operator\n@@ -405,30 +377,27 @@ macro_rules! not_impl(\n \n not_impl!(bool uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `BitAnd` trait is used to specify the functionality of `&`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `BitAnd`. When `Foo & Foo` happens, it ends up\n- * calling `bitand`, and therefore, `main` prints `Bitwise And-ing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl BitAnd<Foo, Foo> for Foo {\n- *     fn bitand(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Bitwise And-ing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo & Foo;\n- * }\n- * ```\n- */\n+/// The `BitAnd` trait is used to specify the functionality of `&`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `BitAnd`. When `Foo & Foo` happens, it ends up\n+/// calling `bitand`, and therefore, `main` prints `Bitwise And-ing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl BitAnd<Foo, Foo> for Foo {\n+///     fn bitand(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Bitwise And-ing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo & Foo;\n+/// }\n+/// ```\n #[lang=\"bitand\"]\n pub trait BitAnd<Sized? RHS, Result> for Sized? {\n     /// The method for the `&` operator\n@@ -446,30 +415,27 @@ macro_rules! bitand_impl(\n \n bitand_impl!(bool uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `BitOr` trait is used to specify the functionality of `|`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `BitOr`. When `Foo | Foo` happens, it ends up\n- * calling `bitor`, and therefore, `main` prints `Bitwise Or-ing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl BitOr<Foo, Foo> for Foo {\n- *     fn bitor(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Bitwise Or-ing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo | Foo;\n- * }\n- * ```\n- */\n+/// The `BitOr` trait is used to specify the functionality of `|`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `BitOr`. When `Foo | Foo` happens, it ends up\n+/// calling `bitor`, and therefore, `main` prints `Bitwise Or-ing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl BitOr<Foo, Foo> for Foo {\n+///     fn bitor(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Bitwise Or-ing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo | Foo;\n+/// }\n+/// ```\n #[lang=\"bitor\"]\n pub trait BitOr<Sized? RHS, Result> for Sized? {\n     /// The method for the `|` operator\n@@ -487,30 +453,27 @@ macro_rules! bitor_impl(\n \n bitor_impl!(bool uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `BitXor` trait is used to specify the functionality of `^`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `BitXor`. When `Foo ^ Foo` happens, it ends up\n- * calling `bitxor`, and therefore, `main` prints `Bitwise Xor-ing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl BitXor<Foo, Foo> for Foo {\n- *     fn bitxor(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Bitwise Xor-ing!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo ^ Foo;\n- * }\n- * ```\n- */\n+/// The `BitXor` trait is used to specify the functionality of `^`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `BitXor`. When `Foo ^ Foo` happens, it ends up\n+/// calling `bitxor`, and therefore, `main` prints `Bitwise Xor-ing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl BitXor<Foo, Foo> for Foo {\n+///     fn bitxor(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Bitwise Xor-ing!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo ^ Foo;\n+/// }\n+/// ```\n #[lang=\"bitxor\"]\n pub trait BitXor<Sized? RHS, Result> for Sized? {\n     /// The method for the `^` operator\n@@ -528,30 +491,27 @@ macro_rules! bitxor_impl(\n \n bitxor_impl!(bool uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `Shl` trait is used to specify the functionality of `<<`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Shl`. When `Foo << Foo` happens, it ends up\n- * calling `shl`, and therefore, `main` prints `Shifting left!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Shl<Foo, Foo> for Foo {\n- *     fn shl(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Shifting left!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo << Foo;\n- * }\n- * ```\n- */\n+/// The `Shl` trait is used to specify the functionality of `<<`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Shl`. When `Foo << Foo` happens, it ends up\n+/// calling `shl`, and therefore, `main` prints `Shifting left!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Shl<Foo, Foo> for Foo {\n+///     fn shl(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Shifting left!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo << Foo;\n+/// }\n+/// ```\n #[lang=\"shl\"]\n pub trait Shl<Sized? RHS, Result> for Sized? {\n     /// The method for the `<<` operator\n@@ -571,30 +531,27 @@ macro_rules! shl_impl(\n \n shl_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `Shr` trait is used to specify the functionality of `>>`.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Shr`. When `Foo >> Foo` happens, it ends up\n- * calling `shr`, and therefore, `main` prints `Shifting right!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Shr<Foo, Foo> for Foo {\n- *     fn shr(&self, _rhs: &Foo) -> Foo {\n- *         println!(\"Shifting right!\");\n- *         *self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo >> Foo;\n- * }\n- * ```\n- */\n+/// The `Shr` trait is used to specify the functionality of `>>`.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Shr`. When `Foo >> Foo` happens, it ends up\n+/// calling `shr`, and therefore, `main` prints `Shifting right!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Shr<Foo, Foo> for Foo {\n+///     fn shr(&self, _rhs: &Foo) -> Foo {\n+///         println!(\"Shifting right!\");\n+///         *self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo >> Foo;\n+/// }\n+/// ```\n #[lang=\"shr\"]\n pub trait Shr<Sized? RHS, Result> for Sized? {\n     /// The method for the `>>` operator\n@@ -612,105 +569,96 @@ macro_rules! shr_impl(\n \n shr_impl!(uint u8 u16 u32 u64 int i8 i16 i32 i64)\n \n-/**\n- *\n- * The `Index` trait is used to specify the functionality of indexing operations\n- * like `arr[idx]` when used in an immutable context.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Index`. When `Foo[Foo]` happens, it ends up\n- * calling `index`, and therefore, `main` prints `Indexing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl Index<Foo, Foo> for Foo {\n- *     fn index<'a>(&'a self, _index: &Foo) -> &'a Foo {\n- *         println!(\"Indexing!\");\n- *         self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo[Foo];\n- * }\n- * ```\n- */\n+/// The `Index` trait is used to specify the functionality of indexing operations\n+/// like `arr[idx]` when used in an immutable context.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Index`. When `Foo[Foo]` happens, it ends up\n+/// calling `index`, and therefore, `main` prints `Indexing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl Index<Foo, Foo> for Foo {\n+///     fn index<'a>(&'a self, _index: &Foo) -> &'a Foo {\n+///         println!(\"Indexing!\");\n+///         self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo[Foo];\n+/// }\n+/// ```\n #[lang=\"index\"]\n pub trait Index<Sized? Index, Sized? Result> for Sized? {\n     /// The method for the indexing (`Foo[Bar]`) operation\n     fn index<'a>(&'a self, index: &Index) -> &'a Result;\n }\n \n-/**\n- *\n- * The `IndexMut` trait is used to specify the functionality of indexing\n- * operations like `arr[idx]`, when used in a mutable context.\n- *\n- * # Example\n- *\n- * A trivial implementation of `IndexMut`. When `Foo[Foo]` happens, it ends up\n- * calling `index_mut`, and therefore, `main` prints `Indexing!`.\n- *\n- * ```\n- * struct Foo;\n- *\n- * impl IndexMut<Foo, Foo> for Foo {\n- *     fn index_mut<'a>(&'a mut self, _index: &Foo) -> &'a mut Foo {\n- *         println!(\"Indexing!\");\n- *         self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     &mut Foo[Foo];\n- * }\n- * ```\n- */\n+/// The `IndexMut` trait is used to specify the functionality of indexing\n+/// operations like `arr[idx]`, when used in a mutable context.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `IndexMut`. When `Foo[Foo]` happens, it ends up\n+/// calling `index_mut`, and therefore, `main` prints `Indexing!`.\n+///\n+/// ```\n+/// struct Foo;\n+///\n+/// impl IndexMut<Foo, Foo> for Foo {\n+///     fn index_mut<'a>(&'a mut self, _index: &Foo) -> &'a mut Foo {\n+///         println!(\"Indexing!\");\n+///         self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     &mut Foo[Foo];\n+/// }\n+/// ```\n #[lang=\"index_mut\"]\n pub trait IndexMut<Sized? Index, Sized? Result> for Sized? {\n     /// The method for the indexing (`Foo[Bar]`) operation\n     fn index_mut<'a>(&'a mut self, index: &Index) -> &'a mut Result;\n }\n \n-/**\n- *\n- * The `Slice` trait is used to specify the functionality of slicing operations\n- * like `arr[from..to]` when used in an immutable context.\n- *\n- * # Example\n- *\n- * A trivial implementation of `Slice`. When `Foo[..Foo]` happens, it ends up\n- * calling `slice_to`, and therefore, `main` prints `Slicing!`.\n- *\n- * ```ignore\n- * struct Foo;\n- *\n- * impl Slice<Foo, Foo> for Foo {\n- *     fn as_slice_<'a>(&'a self) -> &'a Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_from_or_fail<'a>(&'a self, _from: &Foo) -> &'a Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_to_or_fail<'a>(&'a self, _to: &Foo) -> &'a Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_or_fail<'a>(&'a self, _from: &Foo, _to: &Foo) -> &'a Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- * }\n- *\n- * fn main() {\n- *     Foo[..Foo];\n- * }\n- * ```\n- */\n+/// The `Slice` trait is used to specify the functionality of slicing operations\n+/// like `arr[from..to]` when used in an immutable context.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `Slice`. When `Foo[..Foo]` happens, it ends up\n+/// calling `slice_to`, and therefore, `main` prints `Slicing!`.\n+///\n+/// ```ignore\n+/// struct Foo;\n+///\n+/// impl Slice<Foo, Foo> for Foo {\n+///     fn as_slice_<'a>(&'a self) -> &'a Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_from_or_fail<'a>(&'a self, _from: &Foo) -> &'a Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_to_or_fail<'a>(&'a self, _to: &Foo) -> &'a Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_or_fail<'a>(&'a self, _from: &Foo, _to: &Foo) -> &'a Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     Foo[..Foo];\n+/// }\n+/// ```\n #[lang=\"slice\"]\n pub trait Slice<Sized? Idx, Sized? Result> for Sized? {\n     /// The method for the slicing operation foo[]\n@@ -723,43 +671,40 @@ pub trait Slice<Sized? Idx, Sized? Result> for Sized? {\n     fn slice_or_fail<'a>(&'a self, from: &Idx, to: &Idx) -> &'a Result;\n }\n \n-/**\n- *\n- * The `SliceMut` trait is used to specify the functionality of slicing\n- * operations like `arr[from..to]`, when used in a mutable context.\n- *\n- * # Example\n- *\n- * A trivial implementation of `SliceMut`. When `Foo[Foo..]` happens, it ends up\n- * calling `slice_from_mut`, and therefore, `main` prints `Slicing!`.\n- *\n- * ```ignore\n- * struct Foo;\n- *\n- * impl SliceMut<Foo, Foo> for Foo {\n- *     fn as_mut_slice_<'a>(&'a mut self) -> &'a mut Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_from_or_fail_mut<'a>(&'a mut self, _from: &Foo) -> &'a mut Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_to_or_fail_mut<'a>(&'a mut self, _to: &Foo) -> &'a mut Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- *     fn slice_or_fail_mut<'a>(&'a mut self, _from: &Foo, _to: &Foo) -> &'a mut Foo {\n- *         println!(\"Slicing!\");\n- *         self\n- *     }\n- * }\n- *\n- * pub fn main() {\n- *     Foo[mut Foo..];\n- * }\n- * ```\n- */\n+/// The `SliceMut` trait is used to specify the functionality of slicing\n+/// operations like `arr[from..to]`, when used in a mutable context.\n+///\n+/// # Example\n+///\n+/// A trivial implementation of `SliceMut`. When `Foo[Foo..]` happens, it ends up\n+/// calling `slice_from_mut`, and therefore, `main` prints `Slicing!`.\n+///\n+/// ```ignore\n+/// struct Foo;\n+///\n+/// impl SliceMut<Foo, Foo> for Foo {\n+///     fn as_mut_slice_<'a>(&'a mut self) -> &'a mut Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_from_or_fail_mut<'a>(&'a mut self, _from: &Foo) -> &'a mut Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_to_or_fail_mut<'a>(&'a mut self, _to: &Foo) -> &'a mut Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+///     fn slice_or_fail_mut<'a>(&'a mut self, _from: &Foo, _to: &Foo) -> &'a mut Foo {\n+///         println!(\"Slicing!\");\n+///         self\n+///     }\n+/// }\n+///\n+/// pub fn main() {\n+///     Foo[mut Foo..];\n+/// }\n+/// ```\n #[lang=\"slice_mut\"]\n pub trait SliceMut<Sized? Idx, Sized? Result> for Sized? {\n     /// The method for the slicing operation foo[]\n@@ -772,33 +717,30 @@ pub trait SliceMut<Sized? Idx, Sized? Result> for Sized? {\n     fn slice_or_fail_mut<'a>(&'a mut self, from: &Idx, to: &Idx) -> &'a mut Result;\n }\n \n-/**\n- *\n- * The `Deref` trait is used to specify the functionality of dereferencing\n- * operations like `*v`.\n- *\n- * # Example\n- *\n- * A struct with a single field which is accessible via dereferencing the\n- * struct.\n- *\n- * ```\n- * struct DerefExample<T> {\n- *     value: T\n- * }\n- *\n- * impl<T> Deref<T> for DerefExample<T> {\n- *     fn deref<'a>(&'a self) -> &'a T {\n- *         &self.value\n- *     }\n- * }\n- *\n- * fn main() {\n- *     let x = DerefExample { value: 'a' };\n- *     assert_eq!('a', *x);\n- * }\n- * ```\n- */\n+/// The `Deref` trait is used to specify the functionality of dereferencing\n+/// operations like `*v`.\n+///\n+/// # Example\n+///\n+/// A struct with a single field which is accessible via dereferencing the\n+/// struct.\n+///\n+/// ```\n+/// struct DerefExample<T> {\n+///     value: T\n+/// }\n+///\n+/// impl<T> Deref<T> for DerefExample<T> {\n+///     fn deref<'a>(&'a self) -> &'a T {\n+///         &self.value\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     let x = DerefExample { value: 'a' };\n+///     assert_eq!('a', *x);\n+/// }\n+/// ```\n #[lang=\"deref\"]\n pub trait Deref<Sized? Result> for Sized? {\n     /// The method called to dereference a value\n@@ -813,40 +755,37 @@ impl<'a, Sized? T> Deref<T> for &'a mut T {\n     fn deref(&self) -> &T { *self }\n }\n \n-/**\n- *\n- * The `DerefMut` trait is used to specify the functionality of dereferencing\n- * mutably like `*v = 1;`\n- *\n- * # Example\n- *\n- * A struct with a single field which is modifiable via dereferencing the\n- * struct.\n- *\n- * ```\n- * struct DerefMutExample<T> {\n- *     value: T\n- * }\n- *\n- * impl<T> Deref<T> for DerefMutExample<T> {\n- *     fn deref<'a>(&'a self) -> &'a T {\n- *         &self.value\n- *     }\n- * }\n- *\n- * impl<T> DerefMut<T> for DerefMutExample<T> {\n- *     fn deref_mut<'a>(&'a mut self) -> &'a mut T {\n- *         &mut self.value\n- *     }\n- * }\n- *\n- * fn main() {\n- *     let mut x = DerefMutExample { value: 'a' };\n- *     *x = 'b';\n- *     assert_eq!('b', *x);\n- * }\n- * ```\n- */\n+/// The `DerefMut` trait is used to specify the functionality of dereferencing\n+/// mutably like `*v = 1;`\n+///\n+/// # Example\n+///\n+/// A struct with a single field which is modifiable via dereferencing the\n+/// struct.\n+///\n+/// ```\n+/// struct DerefMutExample<T> {\n+///     value: T\n+/// }\n+///\n+/// impl<T> Deref<T> for DerefMutExample<T> {\n+///     fn deref<'a>(&'a self) -> &'a T {\n+///         &self.value\n+///     }\n+/// }\n+///\n+/// impl<T> DerefMut<T> for DerefMutExample<T> {\n+///     fn deref_mut<'a>(&'a mut self) -> &'a mut T {\n+///         &mut self.value\n+///     }\n+/// }\n+///\n+/// fn main() {\n+///     let mut x = DerefMutExample { value: 'a' };\n+///     *x = 'b';\n+///     assert_eq!('b', *x);\n+/// }\n+/// ```\n #[lang=\"deref_mut\"]\n pub trait DerefMut<Sized? Result>: Deref<Result> {\n     /// The method called to mutably dereference a value"}, {"sha": "950f04a5d97e384062c8a3a92ec5cfb3862adec7", "filename": "src/libcore/slice.rs", "status": "modified", "additions": 21, "deletions": 35, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcore%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcore%2Fslice.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -34,8 +34,6 @@\n // * The `raw` and `bytes` submodules.\n // * Boilerplate trait implementations.\n \n-pub use self::BinarySearchResult::*;\n-\n use mem::transmute;\n use clone::Clone;\n use cmp::{PartialEq, PartialOrd, Eq, Ord, Ordering, Less, Equal, Greater, Equiv};\n@@ -219,7 +217,7 @@ pub trait SlicePrelude<T> for Sized? {\n     /// found; the fourth could match any position in `[1,4]`.\n     ///\n     /// ```rust\n-    /// use std::slice::{Found, NotFound};\n+    /// use std::slice::BinarySearchResult::{Found, NotFound};\n     /// let s = [0i, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55];\n     /// let s = s.as_slice();\n     ///\n@@ -548,7 +546,7 @@ impl<T> SlicePrelude<T> for [T] {\n         while lim != 0 {\n             let ix = base + (lim >> 1);\n             match f(&self[ix]) {\n-                Equal => return Found(ix),\n+                Equal => return BinarySearchResult::Found(ix),\n                 Less => {\n                     base = ix + 1;\n                     lim -= 1;\n@@ -557,7 +555,7 @@ impl<T> SlicePrelude<T> for [T] {\n             }\n             lim >>= 1;\n         }\n-        return NotFound(base);\n+        return BinarySearchResult::NotFound(base);\n     }\n \n     #[inline]\n@@ -838,7 +836,7 @@ pub trait OrdSlicePrelude<T: Ord> for Sized? {\n     /// found; the fourth could match any position in `[1,4]`.\n     ///\n     /// ```rust\n-    /// use std::slice::{Found, NotFound};\n+    /// use std::slice::BinarySearchResult::{Found, NotFound};\n     /// let s = [0i, 1, 1, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55];\n     /// let s = s.as_slice();\n     ///\n@@ -1613,17 +1611,17 @@ impl BinarySearchResult {\n     /// Similar to `Result::ok`.\n     pub fn found(&self) -> Option<uint> {\n         match *self {\n-            Found(i) => Some(i),\n-            NotFound(_) => None\n+            BinarySearchResult::Found(i) => Some(i),\n+            BinarySearchResult::NotFound(_) => None\n         }\n     }\n \n     /// Convert a `Found` to `None`, `NotFound` to `Some`.\n     /// Similar to `Result::err`.\n     pub fn not_found(&self) -> Option<uint> {\n         match *self {\n-            Found(_) => None,\n-            NotFound(i) => Some(i)\n+            BinarySearchResult::Found(_) => None,\n+            BinarySearchResult::NotFound(i) => Some(i)\n         }\n     }\n }\n@@ -1634,19 +1632,15 @@ impl BinarySearchResult {\n // Free functions\n //\n \n-/**\n- * Converts a pointer to A into a slice of length 1 (without copying).\n- */\n+/// Converts a pointer to A into a slice of length 1 (without copying).\n #[unstable = \"waiting for DST\"]\n pub fn ref_slice<'a, A>(s: &'a A) -> &'a [A] {\n     unsafe {\n         transmute(RawSlice { data: s, len: 1 })\n     }\n }\n \n-/**\n- * Converts a pointer to A into a slice of length 1 (without copying).\n- */\n+/// Converts a pointer to A into a slice of length 1 (without copying).\n #[unstable = \"waiting for DST\"]\n pub fn mut_ref_slice<'a, A>(s: &'a mut A) -> &'a mut [A] {\n     unsafe {\n@@ -1710,10 +1704,8 @@ pub mod raw {\n     use raw::Slice;\n     use option::{None, Option, Some};\n \n-    /**\n-     * Form a slice from a pointer and length (as a number of units,\n-     * not bytes).\n-     */\n+    /// Form a slice from a pointer and length (as a number of units,\n+    /// not bytes).\n     #[inline]\n     #[deprecated = \"renamed to slice::from_raw_buf\"]\n     pub unsafe fn buf_as_slice<T,U>(p: *const T, len: uint, f: |v: &[T]| -> U)\n@@ -1724,10 +1716,8 @@ pub mod raw {\n         }))\n     }\n \n-    /**\n-     * Form a slice from a pointer and length (as a number of units,\n-     * not bytes).\n-     */\n+    /// Form a slice from a pointer and length (as a number of units,\n+    /// not bytes).\n     #[inline]\n     #[deprecated = \"renamed to slice::from_raw_mut_buf\"]\n     pub unsafe fn mut_buf_as_slice<T,\n@@ -1742,12 +1732,10 @@ pub mod raw {\n         }))\n     }\n \n-    /**\n-     * Returns a pointer to first element in slice and adjusts\n-     * slice so it no longer contains that element. Returns None\n-     * if the slice is empty. O(1).\n-     */\n-     #[inline]\n+    /// Returns a pointer to first element in slice and adjusts\n+    /// slice so it no longer contains that element. Returns None\n+    /// if the slice is empty. O(1).\n+    #[inline]\n     #[deprecated = \"inspect `Slice::{data, len}` manually (increment data by 1)\"]\n     pub unsafe fn shift_ptr<T>(slice: &mut Slice<T>) -> Option<*const T> {\n         if slice.len == 0 { return None; }\n@@ -1757,11 +1745,9 @@ pub mod raw {\n         Some(head)\n     }\n \n-    /**\n-     * Returns a pointer to last element in slice and adjusts\n-     * slice so it no longer contains that element. Returns None\n-     * if the slice is empty. O(1).\n-     */\n+    /// Returns a pointer to last element in slice and adjusts\n+    /// slice so it no longer contains that element. Returns None\n+    /// if the slice is empty. O(1).\n     #[inline]\n     #[deprecated = \"inspect `Slice::{data, len}` manually (decrement len by 1)\"]\n     pub unsafe fn pop_ptr<T>(slice: &mut Slice<T>) -> Option<*const T> {"}, {"sha": "987da903211170bac275d898a2da6b6d4223a878", "filename": "src/libcoretest/slice.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcoretest%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibcoretest%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcoretest%2Fslice.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use std::slice::{Found, NotFound};\n+use std::slice::BinarySearchResult::{Found, NotFound};\n \n #[test]\n fn binary_search_not_found() {"}, {"sha": "36a04392c36f3028619b000b719cc263ff720c31", "filename": "src/libflate/lib.rs", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibflate%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibflate%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibflate%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,15 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Simple [DEFLATE][def]-based compression. This is a wrapper around the\n-[`miniz`][mz] library, which is a one-file pure-C implementation of zlib.\n-\n-[def]: https://en.wikipedia.org/wiki/DEFLATE\n-[mz]: https://code.google.com/p/miniz/\n-\n-*/\n+//! Simple [DEFLATE][def]-based compression. This is a wrapper around the\n+//! [`miniz`][mz] library, which is a one-file pure-C implementation of zlib.\n+//!\n+//! [def]: https://en.wikipedia.org/wiki/DEFLATE\n+//! [mz]: https://code.google.com/p/miniz/\n \n #![crate_name = \"flate\"]\n #![experimental]"}, {"sha": "04eeeb62e1d359cb31fa193aaafd7840589ddcd5", "filename": "src/libgraphviz/lib.rs", "status": "modified", "additions": 252, "deletions": 254, "changes": 506, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibgraphviz%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibgraphviz%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgraphviz%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,260 +8,258 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! Generate files suitable for use with [Graphviz](http://www.graphviz.org/)\n-\n-The `render` function generates output (e.g. an `output.dot` file) for\n-use with [Graphviz](http://www.graphviz.org/) by walking a labelled\n-graph. (Graphviz can then automatically lay out the nodes and edges\n-of the graph, and also optionally render the graph as an image or\n-other [output formats](\n-http://www.graphviz.org/content/output-formats), such as SVG.)\n-\n-Rather than impose some particular graph data structure on clients,\n-this library exposes two traits that clients can implement on their\n-own structs before handing them over to the rendering function.\n-\n-Note: This library does not yet provide access to the full\n-expressiveness of the [DOT language](\n-http://www.graphviz.org/doc/info/lang.html). For example, there are\n-many [attributes](http://www.graphviz.org/content/attrs) related to\n-providing layout hints (e.g. left-to-right versus top-down, which\n-algorithm to use, etc). The current intention of this library is to\n-emit a human-readable .dot file with very regular structure suitable\n-for easy post-processing.\n-\n-# Examples\n-\n-The first example uses a very simple graph representation: a list of\n-pairs of ints, representing the edges (the node set is implicit).\n-Each node label is derived directly from the int representing the node,\n-while the edge labels are all empty strings.\n-\n-This example also illustrates how to use `CowVec` to return\n-an owned vector or a borrowed slice as appropriate: we construct the\n-node vector from scratch, but borrow the edge list (rather than\n-constructing a copy of all the edges from scratch).\n-\n-The output from this example renders five nodes, with the first four\n-forming a diamond-shaped acyclic graph and then pointing to the fifth\n-which is cyclic.\n-\n-```rust\n-use graphviz as dot;\n-\n-type Nd = int;\n-type Ed = (int,int);\n-struct Edges(Vec<Ed>);\n-\n-pub fn render_to<W:Writer>(output: &mut W) {\n-    let edges = Edges(vec!((0,1), (0,2), (1,3), (2,3), (3,4), (4,4)));\n-    dot::render(&edges, output).unwrap()\n-}\n-\n-impl<'a> dot::Labeller<'a, Nd, Ed> for Edges {\n-    fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example1\").unwrap() }\n-\n-    fn node_id(&'a self, n: &Nd) -> dot::Id<'a> {\n-        dot::Id::new(format!(\"N{}\", *n)).unwrap()\n-    }\n-}\n-\n-impl<'a> dot::GraphWalk<'a, Nd, Ed> for Edges {\n-    fn nodes(&self) -> dot::Nodes<'a,Nd> {\n-        // (assumes that |N| \\approxeq |E|)\n-        let &Edges(ref v) = self;\n-        let mut nodes = Vec::with_capacity(v.len());\n-        for &(s,t) in v.iter() {\n-            nodes.push(s); nodes.push(t);\n-        }\n-        nodes.sort();\n-        nodes.dedup();\n-        nodes.into_cow()\n-    }\n-\n-    fn edges(&'a self) -> dot::Edges<'a,Ed> {\n-        let &Edges(ref edges) = self;\n-        edges.as_slice().into_cow()\n-    }\n-\n-    fn source(&self, e: &Ed) -> Nd { let &(s,_) = e; s }\n-\n-    fn target(&self, e: &Ed) -> Nd { let &(_,t) = e; t }\n-}\n-\n-# pub fn main() { render_to(&mut Vec::new()) }\n-```\n-\n-```no_run\n-# pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n-pub fn main() {\n-    use std::io::File;\n-    let mut f = File::create(&Path::new(\"example1.dot\"));\n-    render_to(&mut f)\n-}\n-```\n-\n-Output from first example (in `example1.dot`):\n-\n-```ignore\n-digraph example1 {\n-    N0[label=\"N0\"];\n-    N1[label=\"N1\"];\n-    N2[label=\"N2\"];\n-    N3[label=\"N3\"];\n-    N4[label=\"N4\"];\n-    N0 -> N1[label=\"\"];\n-    N0 -> N2[label=\"\"];\n-    N1 -> N3[label=\"\"];\n-    N2 -> N3[label=\"\"];\n-    N3 -> N4[label=\"\"];\n-    N4 -> N4[label=\"\"];\n-}\n-```\n-\n-The second example illustrates using `node_label` and `edge_label` to\n-add labels to the nodes and edges in the rendered graph. The graph\n-here carries both `nodes` (the label text to use for rendering a\n-particular node), and `edges` (again a list of `(source,target)`\n-indices).\n-\n-This example also illustrates how to use a type (in this case the edge\n-type) that shares substructure with the graph: the edge type here is a\n-direct reference to the `(source,target)` pair stored in the graph's\n-internal vector (rather than passing around a copy of the pair\n-itself). Note that this implies that `fn edges(&'a self)` must\n-construct a fresh `Vec<&'a (uint,uint)>` from the `Vec<(uint,uint)>`\n-edges stored in `self`.\n-\n-Since both the set of nodes and the set of edges are always\n-constructed from scratch via iterators, we use the `collect()` method\n-from the `Iterator` trait to collect the nodes and edges into freshly\n-constructed growable `Vec` values (rather use the `into_cow`\n-from the `IntoCow` trait as was used in the first example\n-above).\n-\n-The output from this example renders four nodes that make up the\n-Hasse-diagram for the subsets of the set `{x, y}`. Each edge is\n-labelled with the &sube; character (specified using the HTML character\n-entity `&sube`).\n-\n-```rust\n-use graphviz as dot;\n-\n-type Nd = uint;\n-type Ed<'a> = &'a (uint, uint);\n-struct Graph { nodes: Vec<&'static str>, edges: Vec<(uint,uint)> }\n-\n-pub fn render_to<W:Writer>(output: &mut W) {\n-    let nodes = vec!(\"{x,y}\",\"{x}\",\"{y}\",\"{}\");\n-    let edges = vec!((0,1), (0,2), (1,3), (2,3));\n-    let graph = Graph { nodes: nodes, edges: edges };\n-\n-    dot::render(&graph, output).unwrap()\n-}\n-\n-impl<'a> dot::Labeller<'a, Nd, Ed<'a>> for Graph {\n-    fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example2\").unwrap() }\n-    fn node_id(&'a self, n: &Nd) -> dot::Id<'a> {\n-        dot::Id::new(format!(\"N{}\", n)).unwrap()\n-    }\n-    fn node_label<'a>(&'a self, n: &Nd) -> dot::LabelText<'a> {\n-        dot::LabelStr(self.nodes[*n].as_slice().into_cow())\n-    }\n-    fn edge_label<'a>(&'a self, _: &Ed) -> dot::LabelText<'a> {\n-        dot::LabelStr(\"&sube;\".into_cow())\n-    }\n-}\n-\n-impl<'a> dot::GraphWalk<'a, Nd, Ed<'a>> for Graph {\n-    fn nodes(&self) -> dot::Nodes<'a,Nd> { range(0,self.nodes.len()).collect() }\n-    fn edges(&'a self) -> dot::Edges<'a,Ed<'a>> { self.edges.iter().collect() }\n-    fn source(&self, e: &Ed) -> Nd { let & &(s,_) = e; s }\n-    fn target(&self, e: &Ed) -> Nd { let & &(_,t) = e; t }\n-}\n-\n-# pub fn main() { render_to(&mut Vec::new()) }\n-```\n-\n-```no_run\n-# pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n-pub fn main() {\n-    use std::io::File;\n-    let mut f = File::create(&Path::new(\"example2.dot\"));\n-    render_to(&mut f)\n-}\n-```\n-\n-The third example is similar to the second, except now each node and\n-edge now carries a reference to the string label for each node as well\n-as that node's index. (This is another illustration of how to share\n-structure with the graph itself, and why one might want to do so.)\n-\n-The output from this example is the same as the second example: the\n-Hasse-diagram for the subsets of the set `{x, y}`.\n-\n-```rust\n-use graphviz as dot;\n-\n-type Nd<'a> = (uint, &'a str);\n-type Ed<'a> = (Nd<'a>, Nd<'a>);\n-struct Graph { nodes: Vec<&'static str>, edges: Vec<(uint,uint)> }\n-\n-pub fn render_to<W:Writer>(output: &mut W) {\n-    let nodes = vec!(\"{x,y}\",\"{x}\",\"{y}\",\"{}\");\n-    let edges = vec!((0,1), (0,2), (1,3), (2,3));\n-    let graph = Graph { nodes: nodes, edges: edges };\n-\n-    dot::render(&graph, output).unwrap()\n-}\n-\n-impl<'a> dot::Labeller<'a, Nd<'a>, Ed<'a>> for Graph {\n-    fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example3\").unwrap() }\n-    fn node_id(&'a self, n: &Nd<'a>) -> dot::Id<'a> {\n-        dot::Id::new(format!(\"N{}\", n.val0())).unwrap()\n-    }\n-    fn node_label<'a>(&'a self, n: &Nd<'a>) -> dot::LabelText<'a> {\n-        let &(i, _) = n;\n-        dot::LabelStr(self.nodes[i].as_slice().into_cow())\n-    }\n-    fn edge_label<'a>(&'a self, _: &Ed<'a>) -> dot::LabelText<'a> {\n-        dot::LabelStr(\"&sube;\".into_cow())\n-    }\n-}\n-\n-impl<'a> dot::GraphWalk<'a, Nd<'a>, Ed<'a>> for Graph {\n-    fn nodes(&'a self) -> dot::Nodes<'a,Nd<'a>> {\n-        self.nodes.iter().map(|s|s.as_slice()).enumerate().collect()\n-    }\n-    fn edges(&'a self) -> dot::Edges<'a,Ed<'a>> {\n-        self.edges.iter()\n-            .map(|&(i,j)|((i, self.nodes[i].as_slice()),\n-                          (j, self.nodes[j].as_slice())))\n-            .collect()\n-    }\n-    fn source(&self, e: &Ed<'a>) -> Nd<'a> { let &(s,_) = e; s }\n-    fn target(&self, e: &Ed<'a>) -> Nd<'a> { let &(_,t) = e; t }\n-}\n-\n-# pub fn main() { render_to(&mut Vec::new()) }\n-```\n-\n-```no_run\n-# pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n-pub fn main() {\n-    use std::io::File;\n-    let mut f = File::create(&Path::new(\"example3.dot\"));\n-    render_to(&mut f)\n-}\n-```\n-\n-# References\n-\n-* [Graphviz](http://www.graphviz.org/)\n-\n-* [DOT language](http://www.graphviz.org/doc/info/lang.html)\n-\n-*/\n+//! Generate files suitable for use with [Graphviz](http://www.graphviz.org/)\n+//!\n+//! The `render` function generates output (e.g. an `output.dot` file) for\n+//! use with [Graphviz](http://www.graphviz.org/) by walking a labelled\n+//! graph. (Graphviz can then automatically lay out the nodes and edges\n+//! of the graph, and also optionally render the graph as an image or\n+//! other [output formats](\n+//! http://www.graphviz.org/content/output-formats), such as SVG.)\n+//!\n+//! Rather than impose some particular graph data structure on clients,\n+//! this library exposes two traits that clients can implement on their\n+//! own structs before handing them over to the rendering function.\n+//!\n+//! Note: This library does not yet provide access to the full\n+//! expressiveness of the [DOT language](\n+//! http://www.graphviz.org/doc/info/lang.html). For example, there are\n+//! many [attributes](http://www.graphviz.org/content/attrs) related to\n+//! providing layout hints (e.g. left-to-right versus top-down, which\n+//! algorithm to use, etc). The current intention of this library is to\n+//! emit a human-readable .dot file with very regular structure suitable\n+//! for easy post-processing.\n+//!\n+//! # Examples\n+//!\n+//! The first example uses a very simple graph representation: a list of\n+//! pairs of ints, representing the edges (the node set is implicit).\n+//! Each node label is derived directly from the int representing the node,\n+//! while the edge labels are all empty strings.\n+//!\n+//! This example also illustrates how to use `CowVec` to return\n+//! an owned vector or a borrowed slice as appropriate: we construct the\n+//! node vector from scratch, but borrow the edge list (rather than\n+//! constructing a copy of all the edges from scratch).\n+//!\n+//! The output from this example renders five nodes, with the first four\n+//! forming a diamond-shaped acyclic graph and then pointing to the fifth\n+//! which is cyclic.\n+//!\n+//! ```rust\n+//! use graphviz as dot;\n+//!\n+//! type Nd = int;\n+//! type Ed = (int,int);\n+//! struct Edges(Vec<Ed>);\n+//!\n+//! pub fn render_to<W:Writer>(output: &mut W) {\n+//!     let edges = Edges(vec!((0,1), (0,2), (1,3), (2,3), (3,4), (4,4)));\n+//!     dot::render(&edges, output).unwrap()\n+//! }\n+//!\n+//! impl<'a> dot::Labeller<'a, Nd, Ed> for Edges {\n+//!     fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example1\").unwrap() }\n+//!\n+//!     fn node_id(&'a self, n: &Nd) -> dot::Id<'a> {\n+//!         dot::Id::new(format!(\"N{}\", *n)).unwrap()\n+//!     }\n+//! }\n+//!\n+//! impl<'a> dot::GraphWalk<'a, Nd, Ed> for Edges {\n+//!     fn nodes(&self) -> dot::Nodes<'a,Nd> {\n+//!         // (assumes that |N| \\approxeq |E|)\n+//!         let &Edges(ref v) = self;\n+//!         let mut nodes = Vec::with_capacity(v.len());\n+//!         for &(s,t) in v.iter() {\n+//!             nodes.push(s); nodes.push(t);\n+//!         }\n+//!         nodes.sort();\n+//!         nodes.dedup();\n+//!         nodes.into_cow()\n+//!     }\n+//!\n+//!     fn edges(&'a self) -> dot::Edges<'a,Ed> {\n+//!         let &Edges(ref edges) = self;\n+//!         edges.as_slice().into_cow()\n+//!     }\n+//!\n+//!     fn source(&self, e: &Ed) -> Nd { let &(s,_) = e; s }\n+//!\n+//!     fn target(&self, e: &Ed) -> Nd { let &(_,t) = e; t }\n+//! }\n+//!\n+//! # pub fn main() { render_to(&mut Vec::new()) }\n+//! ```\n+//!\n+//! ```no_run\n+//! # pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n+//! pub fn main() {\n+//!     use std::io::File;\n+//!     let mut f = File::create(&Path::new(\"example1.dot\"));\n+//!     render_to(&mut f)\n+//! }\n+//! ```\n+//!\n+//! Output from first example (in `example1.dot`):\n+//!\n+//! ```ignore\n+//! digraph example1 {\n+//!     N0[label=\"N0\"];\n+//!     N1[label=\"N1\"];\n+//!     N2[label=\"N2\"];\n+//!     N3[label=\"N3\"];\n+//!     N4[label=\"N4\"];\n+//!     N0 -> N1[label=\"\"];\n+//!     N0 -> N2[label=\"\"];\n+//!     N1 -> N3[label=\"\"];\n+//!     N2 -> N3[label=\"\"];\n+//!     N3 -> N4[label=\"\"];\n+//!     N4 -> N4[label=\"\"];\n+//! }\n+//! ```\n+//!\n+//! The second example illustrates using `node_label` and `edge_label` to\n+//! add labels to the nodes and edges in the rendered graph. The graph\n+//! here carries both `nodes` (the label text to use for rendering a\n+//! particular node), and `edges` (again a list of `(source,target)`\n+//! indices).\n+//!\n+//! This example also illustrates how to use a type (in this case the edge\n+//! type) that shares substructure with the graph: the edge type here is a\n+//! direct reference to the `(source,target)` pair stored in the graph's\n+//! internal vector (rather than passing around a copy of the pair\n+//! itself). Note that this implies that `fn edges(&'a self)` must\n+//! construct a fresh `Vec<&'a (uint,uint)>` from the `Vec<(uint,uint)>`\n+//! edges stored in `self`.\n+//!\n+//! Since both the set of nodes and the set of edges are always\n+//! constructed from scratch via iterators, we use the `collect()` method\n+//! from the `Iterator` trait to collect the nodes and edges into freshly\n+//! constructed growable `Vec` values (rather use the `into_cow`\n+//! from the `IntoCow` trait as was used in the first example\n+//! above).\n+//!\n+//! The output from this example renders four nodes that make up the\n+//! Hasse-diagram for the subsets of the set `{x, y}`. Each edge is\n+//! labelled with the &sube; character (specified using the HTML character\n+//! entity `&sube`).\n+//!\n+//! ```rust\n+//! use graphviz as dot;\n+//!\n+//! type Nd = uint;\n+//! type Ed<'a> = &'a (uint, uint);\n+//! struct Graph { nodes: Vec<&'static str>, edges: Vec<(uint,uint)> }\n+//!\n+//! pub fn render_to<W:Writer>(output: &mut W) {\n+//!     let nodes = vec!(\"{x,y}\",\"{x}\",\"{y}\",\"{}\");\n+//!     let edges = vec!((0,1), (0,2), (1,3), (2,3));\n+//!     let graph = Graph { nodes: nodes, edges: edges };\n+//!\n+//!     dot::render(&graph, output).unwrap()\n+//! }\n+//!\n+//! impl<'a> dot::Labeller<'a, Nd, Ed<'a>> for Graph {\n+//!     fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example2\").unwrap() }\n+//!     fn node_id(&'a self, n: &Nd) -> dot::Id<'a> {\n+//!         dot::Id::new(format!(\"N{}\", n)).unwrap()\n+//!     }\n+//!     fn node_label<'a>(&'a self, n: &Nd) -> dot::LabelText<'a> {\n+//!         dot::LabelStr(self.nodes[*n].as_slice().into_cow())\n+//!     }\n+//!     fn edge_label<'a>(&'a self, _: &Ed) -> dot::LabelText<'a> {\n+//!         dot::LabelStr(\"&sube;\".into_cow())\n+//!     }\n+//! }\n+//!\n+//! impl<'a> dot::GraphWalk<'a, Nd, Ed<'a>> for Graph {\n+//!     fn nodes(&self) -> dot::Nodes<'a,Nd> { range(0,self.nodes.len()).collect() }\n+//!     fn edges(&'a self) -> dot::Edges<'a,Ed<'a>> { self.edges.iter().collect() }\n+//!     fn source(&self, e: &Ed) -> Nd { let & &(s,_) = e; s }\n+//!     fn target(&self, e: &Ed) -> Nd { let & &(_,t) = e; t }\n+//! }\n+//!\n+//! # pub fn main() { render_to(&mut Vec::new()) }\n+//! ```\n+//!\n+//! ```no_run\n+//! # pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n+//! pub fn main() {\n+//!     use std::io::File;\n+//!     let mut f = File::create(&Path::new(\"example2.dot\"));\n+//!     render_to(&mut f)\n+//! }\n+//! ```\n+//!\n+//! The third example is similar to the second, except now each node and\n+//! edge now carries a reference to the string label for each node as well\n+//! as that node's index. (This is another illustration of how to share\n+//! structure with the graph itself, and why one might want to do so.)\n+//!\n+//! The output from this example is the same as the second example: the\n+//! Hasse-diagram for the subsets of the set `{x, y}`.\n+//!\n+//! ```rust\n+//! use graphviz as dot;\n+//!\n+//! type Nd<'a> = (uint, &'a str);\n+//! type Ed<'a> = (Nd<'a>, Nd<'a>);\n+//! struct Graph { nodes: Vec<&'static str>, edges: Vec<(uint,uint)> }\n+//!\n+//! pub fn render_to<W:Writer>(output: &mut W) {\n+//!     let nodes = vec!(\"{x,y}\",\"{x}\",\"{y}\",\"{}\");\n+//!     let edges = vec!((0,1), (0,2), (1,3), (2,3));\n+//!     let graph = Graph { nodes: nodes, edges: edges };\n+//!\n+//!     dot::render(&graph, output).unwrap()\n+//! }\n+//!\n+//! impl<'a> dot::Labeller<'a, Nd<'a>, Ed<'a>> for Graph {\n+//!     fn graph_id(&'a self) -> dot::Id<'a> { dot::Id::new(\"example3\").unwrap() }\n+//!     fn node_id(&'a self, n: &Nd<'a>) -> dot::Id<'a> {\n+//!         dot::Id::new(format!(\"N{}\", n.val0())).unwrap()\n+//!     }\n+//!     fn node_label<'a>(&'a self, n: &Nd<'a>) -> dot::LabelText<'a> {\n+//!         let &(i, _) = n;\n+//!         dot::LabelStr(self.nodes[i].as_slice().into_cow())\n+//!     }\n+//!     fn edge_label<'a>(&'a self, _: &Ed<'a>) -> dot::LabelText<'a> {\n+//!         dot::LabelStr(\"&sube;\".into_cow())\n+//!     }\n+//! }\n+//!\n+//! impl<'a> dot::GraphWalk<'a, Nd<'a>, Ed<'a>> for Graph {\n+//!     fn nodes(&'a self) -> dot::Nodes<'a,Nd<'a>> {\n+//!         self.nodes.iter().map(|s|s.as_slice()).enumerate().collect()\n+//!     }\n+//!     fn edges(&'a self) -> dot::Edges<'a,Ed<'a>> {\n+//!         self.edges.iter()\n+//!             .map(|&(i,j)|((i, self.nodes[i].as_slice()),\n+//!                           (j, self.nodes[j].as_slice())))\n+//!             .collect()\n+//!     }\n+//!     fn source(&self, e: &Ed<'a>) -> Nd<'a> { let &(s,_) = e; s }\n+//!     fn target(&self, e: &Ed<'a>) -> Nd<'a> { let &(_,t) = e; t }\n+//! }\n+//!\n+//! # pub fn main() { render_to(&mut Vec::new()) }\n+//! ```\n+//!\n+//! ```no_run\n+//! # pub fn render_to<W:Writer>(output: &mut W) { unimplemented!() }\n+//! pub fn main() {\n+//!     use std::io::File;\n+//!     let mut f = File::create(&Path::new(\"example3.dot\"));\n+//!     render_to(&mut f)\n+//! }\n+//! ```\n+//!\n+//! # References\n+//!\n+//! * [Graphviz](http://www.graphviz.org/)\n+//!\n+//! * [DOT language](http://www.graphviz.org/doc/info/lang.html)\n \n #![crate_name = \"graphviz\"]\n #![experimental]"}, {"sha": "6ce85d1d80248342f27e8300c8c84ca408e08fbe", "filename": "src/liblibc/lib.rs", "status": "modified", "additions": 63, "deletions": 67, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fliblibc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Fliblibc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliblibc%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -19,59 +19,57 @@\n        html_root_url = \"http://doc.rust-lang.org/nightly/\",\n        html_playground_url = \"http://play.rust-lang.org/\")]\n \n-/*!\n-* Bindings for the C standard library and other platform libraries\n-*\n-* **NOTE:** These are *architecture and libc* specific. On Linux, these\n-* bindings are only correct for glibc.\n-*\n-* This module contains bindings to the C standard library, organized into\n-* modules by their defining standard.  Additionally, it contains some assorted\n-* platform-specific definitions.  For convenience, most functions and types\n-* are reexported, so `use libc::*` will import the available C bindings as\n-* appropriate for the target platform. The exact set of functions available\n-* are platform specific.\n-*\n-* *Note:* Because these definitions are platform-specific, some may not appear\n-* in the generated documentation.\n-*\n-* We consider the following specs reasonably normative with respect to\n-* interoperating with the C standard library (libc/msvcrt):\n-*\n-* * ISO 9899:1990 ('C95', 'ANSI C', 'Standard C'), NA1, 1995.\n-* * ISO 9899:1999 ('C99' or 'C9x').\n-* * ISO 9945:1988 / IEEE 1003.1-1988 ('POSIX.1').\n-* * ISO 9945:2001 / IEEE 1003.1-2001 ('POSIX:2001', 'SUSv3').\n-* * ISO 9945:2008 / IEEE 1003.1-2008 ('POSIX:2008', 'SUSv4').\n-*\n-* Note that any reference to the 1996 revision of POSIX, or any revs between\n-* 1990 (when '88 was approved at ISO) and 2001 (when the next actual\n-* revision-revision happened), are merely additions of other chapters (1b and\n-* 1c) outside the core interfaces.\n-*\n-* Despite having several names each, these are *reasonably* coherent\n-* point-in-time, list-of-definition sorts of specs. You can get each under a\n-* variety of names but will wind up with the same definition in each case.\n-*\n-* See standards(7) in linux-manpages for more details.\n-*\n-* Our interface to these libraries is complicated by the non-universality of\n-* conformance to any of them. About the only thing universally supported is\n-* the first (C95), beyond that definitions quickly become absent on various\n-* platforms.\n-*\n-* We therefore wind up dividing our module-space up (mostly for the sake of\n-* sanity while editing, filling-in-details and eliminating duplication) into\n-* definitions common-to-all (held in modules named c95, c99, posix88, posix01\n-* and posix08) and definitions that appear only on *some* platforms (named\n-* 'extra'). This would be things like significant OSX foundation kit, or Windows\n-* library kernel32.dll, or various fancy glibc, Linux or BSD extensions.\n-*\n-* In addition to the per-platform 'extra' modules, we define a module of\n-* 'common BSD' libc routines that never quite made it into POSIX but show up\n-* in multiple derived systems. This is the 4.4BSD r2 / 1995 release, the final\n-* one from Berkeley after the lawsuits died down and the CSRG dissolved.\n-*/\n+//! Bindings for the C standard library and other platform libraries\n+//!\n+//! **NOTE:** These are *architecture and libc* specific. On Linux, these\n+//! bindings are only correct for glibc.\n+//!\n+//! This module contains bindings to the C standard library, organized into\n+//! modules by their defining standard.  Additionally, it contains some assorted\n+//! platform-specific definitions.  For convenience, most functions and types\n+//! are reexported, so `use libc::*` will import the available C bindings as\n+//! appropriate for the target platform. The exact set of functions available\n+//! are platform specific.\n+//!\n+//! *Note:* Because these definitions are platform-specific, some may not appear\n+//! in the generated documentation.\n+//!\n+//! We consider the following specs reasonably normative with respect to\n+//! interoperating with the C standard library (libc/msvcrt):\n+//!\n+//! * ISO 9899:1990 ('C95', 'ANSI C', 'Standard C'), NA1, 1995.\n+//! * ISO 9899:1999 ('C99' or 'C9x').\n+//! * ISO 9945:1988 / IEEE 1003.1-1988 ('POSIX.1').\n+//! * ISO 9945:2001 / IEEE 1003.1-2001 ('POSIX:2001', 'SUSv3').\n+//! * ISO 9945:2008 / IEEE 1003.1-2008 ('POSIX:2008', 'SUSv4').\n+//!\n+//! Note that any reference to the 1996 revision of POSIX, or any revs between\n+//! 1990 (when '88 was approved at ISO) and 2001 (when the next actual\n+//! revision-revision happened), are merely additions of other chapters (1b and\n+//! 1c) outside the core interfaces.\n+//!\n+//! Despite having several names each, these are *reasonably* coherent\n+//! point-in-time, list-of-definition sorts of specs. You can get each under a\n+//! variety of names but will wind up with the same definition in each case.\n+//!\n+//! See standards(7) in linux-manpages for more details.\n+//!\n+//! Our interface to these libraries is complicated by the non-universality of\n+//! conformance to any of them. About the only thing universally supported is\n+//! the first (C95), beyond that definitions quickly become absent on various\n+//! platforms.\n+//!\n+//! We therefore wind up dividing our module-space up (mostly for the sake of\n+//! sanity while editing, filling-in-details and eliminating duplication) into\n+//! definitions common-to-all (held in modules named c95, c99, posix88, posix01\n+//! and posix08) and definitions that appear only on *some* platforms (named\n+//! 'extra'). This would be things like significant OSX foundation kit, or Windows\n+//! library kernel32.dll, or various fancy glibc, Linux or BSD extensions.\n+//!\n+//! In addition to the per-platform 'extra' modules, we define a module of\n+//! 'common BSD' libc routines that never quite made it into POSIX but show up\n+//! in multiple derived systems. This is the 4.4BSD r2 / 1995 release, the final\n+//! one from Berkeley after the lawsuits died down and the CSRG dissolved.\n \n #![allow(non_camel_case_types)]\n #![allow(non_snake_case)]\n@@ -329,20 +327,18 @@ pub mod types {\n     // Standard types that are opaque or common, so are not per-target.\n     pub mod common {\n         pub mod c95 {\n-            /**\n-            Type used to construct void pointers for use with C.\n-\n-            This type is only useful as a pointer target. Do not use it as a\n-            return type for FFI functions which have the `void` return type in\n-            C. Use the unit type `()` or omit the return type instead.\n-\n-            For LLVM to recognize the void pointer type and by extension\n-            functions like malloc(), we need to have it represented as i8* in\n-            LLVM bitcode. The enum used here ensures this and prevents misuse\n-            of the \"raw\" type by only having private variants.. We need two\n-            variants, because the compiler complains about the repr attribute\n-            otherwise.\n-            */\n+            /// Type used to construct void pointers for use with C.\n+            ///\n+            /// This type is only useful as a pointer target. Do not use it as a\n+            /// return type for FFI functions which have the `void` return type in\n+            /// C. Use the unit type `()` or omit the return type instead.\n+            ///\n+            /// For LLVM to recognize the void pointer type and by extension\n+            /// functions like malloc(), we need to have it represented as i8* in\n+            /// LLVM bitcode. The enum used here ensures this and prevents misuse\n+            /// of the \"raw\" type by only having private variants.. We need two\n+            /// variants, because the compiler complains about the repr attribute\n+            /// otherwise.\n             #[repr(u8)]\n             pub enum c_void {\n                 __variant1,"}, {"sha": "0fa989bf0b2b9b4e8713bc1cc2581e5fba7a31bd", "filename": "src/librand/distributions/mod.rs", "status": "modified", "additions": 8, "deletions": 11, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrand%2Fdistributions%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrand%2Fdistributions%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrand%2Fdistributions%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,17 +8,14 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-Sampling from random distributions.\n-\n-This is a generalization of `Rand` to allow parameters to control the\n-exact properties of the generated values, e.g. the mean and standard\n-deviation of a normal distribution. The `Sample` trait is the most\n-general, and allows for generating values that change some state\n-internally. The `IndependentSample` trait is for generating values\n-that do not need to record state.\n-\n-*/\n+//! Sampling from random distributions.\n+//!\n+//! This is a generalization of `Rand` to allow parameters to control the\n+//! exact properties of the generated values, e.g. the mean and standard\n+//! deviation of a normal distribution. The `Sample` trait is the most\n+//! general, and allows for generating values that change some state\n+//! internally. The `IndependentSample` trait is for generating values\n+//! that do not need to record state.\n \n #![experimental]\n "}, {"sha": "2bf3fa992cd669c847c27de3d838ae4e2c93d466", "filename": "src/libregex/parse.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibregex%2Fparse.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibregex%2Fparse.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibregex%2Fparse.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -18,7 +18,7 @@ use std::cmp;\n use std::fmt;\n use std::iter;\n use std::num;\n-use std::slice;\n+use std::slice::BinarySearchResult;\n \n /// Static data containing Unicode ranges for general categories and scripts.\n use unicode::regex::{UNICODE_CLASSES, PERLD, PERLS, PERLW};\n@@ -1027,8 +1027,8 @@ fn is_valid_cap(c: char) -> bool {\n \n fn find_class(classes: NamedClasses, name: &str) -> Option<Vec<(char, char)>> {\n     match classes.binary_search(|&(s, _)| s.cmp(name)) {\n-        slice::Found(i) => Some(classes[i].val1().to_vec()),\n-        slice::NotFound(_) => None,\n+        BinarySearchResult::Found(i) => Some(classes[i].val1().to_vec()),\n+        BinarySearchResult::NotFound(_) => None,\n     }\n }\n "}, {"sha": "81209763a0c5aed06a7bb37ea7d40b4b9debf40d", "filename": "src/librustc/diagnostics.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdiagnostics.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -146,5 +146,7 @@ register_diagnostics!(\n     E0167,\n     E0168,\n     E0169,\n-    E0170\n+    E0170,\n+    E0171,\n+    E0172\n )"}, {"sha": "c599a0f2daf7f194249e0780867a745b8a3d8486", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,15 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-The Rust compiler.\n-\n-# Note\n-\n-This API is completely unstable and subject to change.\n-\n-*/\n+//! The Rust compiler.\n+//!\n+//! # Note\n+//!\n+//! This API is completely unstable and subject to change.\n \n #![crate_name = \"rustc\"]\n #![experimental]"}, {"sha": "1dbd170a0d997f9242bf02bf7b8131b127fad100", "filename": "src/librustc/lint/builtin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flint%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flint%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fbuiltin.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -421,7 +421,7 @@ impl<'a, 'tcx> ImproperCTypesVisitor<'a, 'tcx> {\n impl<'a, 'tcx, 'v> Visitor<'v> for ImproperCTypesVisitor<'a, 'tcx> {\n     fn visit_ty(&mut self, ty: &ast::Ty) {\n         match ty.node {\n-            ast::TyPath(_, _, id) => self.check_def(ty.span, ty.id, id),\n+            ast::TyPath(_, id) => self.check_def(ty.span, ty.id, id),\n             _ => (),\n         }\n         visit::walk_ty(self, ty);"}, {"sha": "c7bed838eb91927991e59fb66f8e7239873043db", "filename": "src/librustc/lint/context.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flint%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Flint%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flint%2Fcontext.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -464,11 +464,9 @@ impl<'a, 'tcx> Context<'a, 'tcx> {\n         self.lookup_and_emit(lint, Some(span), msg);\n     }\n \n-    /**\n-     * Merge the lints specified by any lint attributes into the\n-     * current lint context, call the provided function, then reset the\n-     * lints in effect to their previous state.\n-     */\n+    /// Merge the lints specified by any lint attributes into the\n+    /// current lint context, call the provided function, then reset the\n+    /// lints in effect to their previous state.\n     fn with_lint_attrs(&mut self,\n                        attrs: &[ast::Attribute],\n                        f: |&mut Context|) {"}, {"sha": "d65fb9d2778becd2678bfb59126649cad032a9a0", "filename": "src/librustc/metadata/encoder.rs", "status": "modified", "additions": 1, "deletions": 12, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmetadata%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmetadata%2Fencoder.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -500,20 +500,10 @@ fn encode_reexported_static_methods(ecx: &EncodeContext,\n /// Iterates through \"auxiliary node IDs\", which are node IDs that describe\n /// top-level items that are sub-items of the given item. Specifically:\n ///\n-/// * For enums, iterates through the node IDs of the variants.\n-///\n /// * For newtype structs, iterates through the node ID of the constructor.\n fn each_auxiliary_node_id(item: &ast::Item, callback: |NodeId| -> bool) -> bool {\n     let mut continue_ = true;\n     match item.node {\n-        ast::ItemEnum(ref enum_def, _) => {\n-            for variant in enum_def.variants.iter() {\n-                continue_ = callback(variant.node.id);\n-                if !continue_ {\n-                    break\n-                }\n-            }\n-        }\n         ast::ItemStruct(ref struct_def, _) => {\n             // If this is a newtype struct, return the constructor.\n             match struct_def.ctor_id {\n@@ -1230,10 +1220,9 @@ fn encode_info_for_item(ecx: &EncodeContext,\n         encode_name(rbml_w, item.ident.name);\n         encode_attributes(rbml_w, item.attrs.as_slice());\n         match ty.node {\n-            ast::TyPath(ref path, ref bounds, _) if path.segments\n+            ast::TyPath(ref path, _) if path.segments\n                                                         .len() == 1 => {\n                 let ident = path.segments.last().unwrap().identifier;\n-                assert!(bounds.is_none());\n                 encode_impl_type_basename(rbml_w, ident);\n             }\n             _ => {}"}, {"sha": "523e997a8deec149995e228cf531ddc7719841b9", "filename": "src/librustc/middle/astencode.rs", "status": "modified", "additions": 51, "deletions": 69, "changes": 120, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fastencode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fastencode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fastencode.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -196,53 +196,38 @@ fn reserve_id_range(sess: &Session,\n }\n \n impl<'a, 'b, 'tcx> DecodeContext<'a, 'b, 'tcx> {\n+    /// Translates an internal id, meaning a node id that is known to refer to some part of the\n+    /// item currently being inlined, such as a local variable or argument.  All naked node-ids\n+    /// that appear in types have this property, since if something might refer to an external item\n+    /// we would use a def-id to allow for the possibility that the item resides in another crate.\n     pub fn tr_id(&self, id: ast::NodeId) -> ast::NodeId {\n-        /*!\n-         * Translates an internal id, meaning a node id that is known\n-         * to refer to some part of the item currently being inlined,\n-         * such as a local variable or argument.  All naked node-ids\n-         * that appear in types have this property, since if something\n-         * might refer to an external item we would use a def-id to\n-         * allow for the possibility that the item resides in another\n-         * crate.\n-         */\n-\n         // from_id_range should be non-empty\n         assert!(!self.from_id_range.empty());\n         (id - self.from_id_range.min + self.to_id_range.min)\n     }\n+\n+    /// Translates an EXTERNAL def-id, converting the crate number from the one used in the encoded\n+    /// data to the current crate numbers..  By external, I mean that it be translated to a\n+    /// reference to the item in its original crate, as opposed to being translated to a reference\n+    /// to the inlined version of the item.  This is typically, but not always, what you want,\n+    /// because most def-ids refer to external things like types or other fns that may or may not\n+    /// be inlined.  Note that even when the inlined function is referencing itself recursively, we\n+    /// would want `tr_def_id` for that reference--- conceptually the function calls the original,\n+    /// non-inlined version, and trans deals with linking that recursive call to the inlined copy.\n+    ///\n+    /// However, there are a *few* cases where def-ids are used but we know that the thing being\n+    /// referenced is in fact *internal* to the item being inlined.  In those cases, you should use\n+    /// `tr_intern_def_id()` below.\n     pub fn tr_def_id(&self, did: ast::DefId) -> ast::DefId {\n-        /*!\n-         * Translates an EXTERNAL def-id, converting the crate number\n-         * from the one used in the encoded data to the current crate\n-         * numbers..  By external, I mean that it be translated to a\n-         * reference to the item in its original crate, as opposed to\n-         * being translated to a reference to the inlined version of\n-         * the item.  This is typically, but not always, what you\n-         * want, because most def-ids refer to external things like\n-         * types or other fns that may or may not be inlined.  Note\n-         * that even when the inlined function is referencing itself\n-         * recursively, we would want `tr_def_id` for that\n-         * reference--- conceptually the function calls the original,\n-         * non-inlined version, and trans deals with linking that\n-         * recursive call to the inlined copy.\n-         *\n-         * However, there are a *few* cases where def-ids are used but\n-         * we know that the thing being referenced is in fact *internal*\n-         * to the item being inlined.  In those cases, you should use\n-         * `tr_intern_def_id()` below.\n-         */\n \n         decoder::translate_def_id(self.cdata, did)\n     }\n-    pub fn tr_intern_def_id(&self, did: ast::DefId) -> ast::DefId {\n-        /*!\n-         * Translates an INTERNAL def-id, meaning a def-id that is\n-         * known to refer to some part of the item currently being\n-         * inlined.  In that case, we want to convert the def-id to\n-         * refer to the current crate and to the new, inlined node-id.\n-         */\n \n+    /// Translates an INTERNAL def-id, meaning a def-id that is\n+    /// known to refer to some part of the item currently being\n+    /// inlined.  In that case, we want to convert the def-id to\n+    /// refer to the current crate and to the new, inlined node-id.\n+    pub fn tr_intern_def_id(&self, did: ast::DefId) -> ast::DefId {\n         assert_eq!(did.krate, ast::LOCAL_CRATE);\n         ast::DefId { krate: ast::LOCAL_CRATE, node: self.tr_id(did.node) }\n     }\n@@ -1780,43 +1765,40 @@ impl<'a, 'tcx> rbml_decoder_decoder_helpers<'tcx> for reader::Decoder<'a> {\n         }\n     }\n \n+    /// Converts a def-id that appears in a type.  The correct\n+    /// translation will depend on what kind of def-id this is.\n+    /// This is a subtle point: type definitions are not\n+    /// inlined into the current crate, so if the def-id names\n+    /// a nominal type or type alias, then it should be\n+    /// translated to refer to the source crate.\n+    ///\n+    /// However, *type parameters* are cloned along with the function\n+    /// they are attached to.  So we should translate those def-ids\n+    /// to refer to the new, cloned copy of the type parameter.\n+    /// We only see references to free type parameters in the body of\n+    /// an inlined function. In such cases, we need the def-id to\n+    /// be a local id so that the TypeContents code is able to lookup\n+    /// the relevant info in the ty_param_defs table.\n+    ///\n+    /// *Region parameters*, unfortunately, are another kettle of fish.\n+    /// In such cases, def_id's can appear in types to distinguish\n+    /// shadowed bound regions and so forth. It doesn't actually\n+    /// matter so much what we do to these, since regions are erased\n+    /// at trans time, but it's good to keep them consistent just in\n+    /// case. We translate them with `tr_def_id()` which will map\n+    /// the crate numbers back to the original source crate.\n+    ///\n+    /// Unboxed closures are cloned along with the function being\n+    /// inlined, and all side tables use interned node IDs, so we\n+    /// translate their def IDs accordingly.\n+    ///\n+    /// It'd be really nice to refactor the type repr to not include\n+    /// def-ids so that all these distinctions were unnecessary.\n     fn convert_def_id(&mut self,\n                       dcx: &DecodeContext,\n                       source: tydecode::DefIdSource,\n                       did: ast::DefId)\n                       -> ast::DefId {\n-        /*!\n-         * Converts a def-id that appears in a type.  The correct\n-         * translation will depend on what kind of def-id this is.\n-         * This is a subtle point: type definitions are not\n-         * inlined into the current crate, so if the def-id names\n-         * a nominal type or type alias, then it should be\n-         * translated to refer to the source crate.\n-         *\n-         * However, *type parameters* are cloned along with the function\n-         * they are attached to.  So we should translate those def-ids\n-         * to refer to the new, cloned copy of the type parameter.\n-         * We only see references to free type parameters in the body of\n-         * an inlined function. In such cases, we need the def-id to\n-         * be a local id so that the TypeContents code is able to lookup\n-         * the relevant info in the ty_param_defs table.\n-         *\n-         * *Region parameters*, unfortunately, are another kettle of fish.\n-         * In such cases, def_id's can appear in types to distinguish\n-         * shadowed bound regions and so forth. It doesn't actually\n-         * matter so much what we do to these, since regions are erased\n-         * at trans time, but it's good to keep them consistent just in\n-         * case. We translate them with `tr_def_id()` which will map\n-         * the crate numbers back to the original source crate.\n-         *\n-         * Unboxed closures are cloned along with the function being\n-         * inlined, and all side tables use interned node IDs, so we\n-         * translate their def IDs accordingly.\n-         *\n-         * It'd be really nice to refactor the type repr to not include\n-         * def-ids so that all these distinctions were unnecessary.\n-         */\n-\n         let r = match source {\n             NominalType | TypeWithId | RegionParameter => dcx.tr_def_id(did),\n             TypeParameter | UnboxedClosureSource => dcx.tr_intern_def_id(did)"}, {"sha": "9a27abbe8322dc107a3a90f4eb4c785d48509ce8", "filename": "src/librustc/middle/borrowck/check_loans.rs", "status": "modified", "additions": 19, "deletions": 23, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fcheck_loans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fcheck_loans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fcheck_loans.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -684,16 +684,13 @@ impl<'a, 'tcx> CheckLoanCtxt<'a, 'tcx> {\n         return ret;\n     }\n \n+    /// Reports an error if `expr` (which should be a path)\n+    /// is using a moved/uninitialized value\n     fn check_if_path_is_moved(&self,\n                               id: ast::NodeId,\n                               span: Span,\n                               use_kind: MovedValueUseKind,\n                               lp: &Rc<LoanPath<'tcx>>) {\n-        /*!\n-         * Reports an error if `expr` (which should be a path)\n-         * is using a moved/uninitialized value\n-         */\n-\n         debug!(\"check_if_path_is_moved(id={}, use_kind={}, lp={})\",\n                id, use_kind, lp.repr(self.bccx.tcx));\n         let base_lp = owned_ptr_base_path_rc(lp);\n@@ -708,30 +705,29 @@ impl<'a, 'tcx> CheckLoanCtxt<'a, 'tcx> {\n         });\n     }\n \n+    /// Reports an error if assigning to `lp` will use a\n+    /// moved/uninitialized value. Mainly this is concerned with\n+    /// detecting derefs of uninitialized pointers.\n+    ///\n+    /// For example:\n+    ///\n+    /// ```\n+    /// let a: int;\n+    /// a = 10; // ok, even though a is uninitialized\n+    ///\n+    /// struct Point { x: uint, y: uint }\n+    /// let p: Point;\n+    /// p.x = 22; // ok, even though `p` is uninitialized\n+    ///\n+    /// let p: ~Point;\n+    /// (*p).x = 22; // not ok, p is uninitialized, can't deref\n+    /// ```\n     fn check_if_assigned_path_is_moved(&self,\n                                        id: ast::NodeId,\n                                        span: Span,\n                                        use_kind: MovedValueUseKind,\n                                        lp: &Rc<LoanPath<'tcx>>)\n     {\n-        /*!\n-         * Reports an error if assigning to `lp` will use a\n-         * moved/uninitialized value. Mainly this is concerned with\n-         * detecting derefs of uninitialized pointers.\n-         *\n-         * For example:\n-         *\n-         *     let a: int;\n-         *     a = 10; // ok, even though a is uninitialized\n-         *\n-         *     struct Point { x: uint, y: uint }\n-         *     let p: Point;\n-         *     p.x = 22; // ok, even though `p` is uninitialized\n-         *\n-         *     let p: ~Point;\n-         *     (*p).x = 22; // not ok, p is uninitialized, can't deref\n-         */\n-\n         match lp.kind {\n             LpVar(_) | LpUpvar(_) => {\n                 // assigning to `x` does not require that `x` is initialized"}, {"sha": "c6db5340f0f511d9e6865516368908a347b68185", "filename": "src/librustc/middle/borrowck/doc.rs", "status": "modified", "additions": 1212, "deletions": 1216, "changes": 2428, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,1219 +8,1215 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# The Borrow Checker\n-\n-This pass has the job of enforcing memory safety. This is a subtle\n-topic. This docs aim to explain both the practice and the theory\n-behind the borrow checker. They start with a high-level overview of\n-how it works, and then proceed to dive into the theoretical\n-background. Finally, they go into detail on some of the more subtle\n-aspects.\n-\n-# Table of contents\n-\n-These docs are long. Search for the section you are interested in.\n-\n-- Overview\n-- Formal model\n-- Borrowing and loans\n-- Moves and initialization\n-- Drop flags and structural fragments\n-- Future work\n-\n-# Overview\n-\n-The borrow checker checks one function at a time. It operates in two\n-passes. The first pass, called `gather_loans`, walks over the function\n-and identifies all of the places where borrows (e.g., `&` expressions\n-and `ref` bindings) and moves (copies or captures of a linear value)\n-occur. It also tracks initialization sites. For each borrow and move,\n-it checks various basic safety conditions at this time (for example,\n-that the lifetime of the borrow doesn't exceed the lifetime of the\n-value being borrowed, or that there is no move out of an `&T`\n-referent).\n-\n-It then uses the dataflow module to propagate which of those borrows\n-may be in scope at each point in the procedure. A loan is considered\n-to come into scope at the expression that caused it and to go out of\n-scope when the lifetime of the resulting reference expires.\n-\n-Once the in-scope loans are known for each point in the program, the\n-borrow checker walks the IR again in a second pass called\n-`check_loans`. This pass examines each statement and makes sure that\n-it is safe with respect to the in-scope loans.\n-\n-# Formal model\n-\n-Throughout the docs we'll consider a simple subset of Rust in which\n-you can only borrow from lvalues, defined like so:\n-\n-```text\n-LV = x | LV.f | *LV\n-```\n-\n-Here `x` represents some variable, `LV.f` is a field reference,\n-and `*LV` is a pointer dereference. There is no auto-deref or other\n-niceties. This means that if you have a type like:\n-\n-```text\n-struct S { f: uint }\n-```\n-\n-and a variable `a: Box<S>`, then the rust expression `a.f` would correspond\n-to an `LV` of `(*a).f`.\n-\n-Here is the formal grammar for the types we'll consider:\n-\n-```text\n-TY = () | S<'LT...> | Box<TY> | & 'LT MQ TY\n-MQ = mut | imm | const\n-```\n-\n-Most of these types should be pretty self explanatory. Here `S` is a\n-struct name and we assume structs are declared like so:\n-\n-```text\n-SD = struct S<'LT...> { (f: TY)... }\n-```\n-\n-# Borrowing and loans\n-\n-## An intuitive explanation\n-\n-### Issuing loans\n-\n-Now, imagine we had a program like this:\n-\n-```text\n-struct Foo { f: uint, g: uint }\n-...\n-'a: {\n-  let mut x: Box<Foo> = ...;\n-  let y = &mut (*x).f;\n-  x = ...;\n-}\n-```\n-\n-This is of course dangerous because mutating `x` will free the old\n-value and hence invalidate `y`. The borrow checker aims to prevent\n-this sort of thing.\n-\n-#### Loans and restrictions\n-\n-The way the borrow checker works is that it analyzes each borrow\n-expression (in our simple model, that's stuff like `&LV`, though in\n-real life there are a few other cases to consider). For each borrow\n-expression, it computes a `Loan`, which is a data structure that\n-records (1) the value being borrowed, (2) the mutability and scope of\n-the borrow, and (3) a set of restrictions. In the code, `Loan` is a\n-struct defined in `middle::borrowck`. Formally, we define `LOAN` as\n-follows:\n-\n-```text\n-LOAN = (LV, LT, MQ, RESTRICTION*)\n-RESTRICTION = (LV, ACTION*)\n-ACTION = MUTATE | CLAIM | FREEZE\n-```\n-\n-Here the `LOAN` tuple defines the lvalue `LV` being borrowed; the\n-lifetime `LT` of that borrow; the mutability `MQ` of the borrow; and a\n-list of restrictions. The restrictions indicate actions which, if\n-taken, could invalidate the loan and lead to type safety violations.\n-\n-Each `RESTRICTION` is a pair of a restrictive lvalue `LV` (which will\n-either be the path that was borrowed or some prefix of the path that\n-was borrowed) and a set of restricted actions.  There are three kinds\n-of actions that may be restricted for the path `LV`:\n-\n-- `MUTATE` means that `LV` cannot be assigned to;\n-- `CLAIM` means that the `LV` cannot be borrowed mutably;\n-- `FREEZE` means that the `LV` cannot be borrowed immutably;\n-\n-Finally, it is never possible to move from an lvalue that appears in a\n-restriction. This implies that the \"empty restriction\" `(LV, [])`,\n-which contains an empty set of actions, still has a purpose---it\n-prevents moves from `LV`. I chose not to make `MOVE` a fourth kind of\n-action because that would imply that sometimes moves are permitted\n-from restrictived values, which is not the case.\n-\n-#### Example\n-\n-To give you a better feeling for what kind of restrictions derived\n-from a loan, let's look at the loan `L` that would be issued as a\n-result of the borrow `&mut (*x).f` in the example above:\n-\n-```text\n-L = ((*x).f, 'a, mut, RS) where\n-    RS = [((*x).f, [MUTATE, CLAIM, FREEZE]),\n-          (*x, [MUTATE, CLAIM, FREEZE]),\n-          (x, [MUTATE, CLAIM, FREEZE])]\n-```\n-\n-The loan states that the expression `(*x).f` has been loaned as\n-mutable for the lifetime `'a`. Because the loan is mutable, that means\n-that the value `(*x).f` may be mutated via the newly created reference\n-(and *only* via that pointer). This is reflected in the\n-restrictions `RS` that accompany the loan.\n-\n-The first restriction `((*x).f, [MUTATE, CLAIM, FREEZE])` states that\n-the lender may not mutate, freeze, nor alias `(*x).f`. Mutation is\n-illegal because `(*x).f` is only supposed to be mutated via the new\n-reference, not by mutating the original path `(*x).f`. Freezing is\n-illegal because the path now has an `&mut` alias; so even if we the\n-lender were to consider `(*x).f` to be immutable, it might be mutated\n-via this alias. They will be enforced for the lifetime `'a` of the\n-loan. After the loan expires, the restrictions no longer apply.\n-\n-The second restriction on `*x` is interesting because it does not\n-apply to the path that was lent (`(*x).f`) but rather to a prefix of\n-the borrowed path. This is due to the rules of inherited mutability:\n-if the user were to assign to (or freeze) `*x`, they would indirectly\n-overwrite (or freeze) `(*x).f`, and thus invalidate the reference\n-that was created. In general it holds that when a path is\n-lent, restrictions are issued for all the owning prefixes of that\n-path. In this case, the path `*x` owns the path `(*x).f` and,\n-because `x` is an owned pointer, the path `x` owns the path `*x`.\n-Therefore, borrowing `(*x).f` yields restrictions on both\n-`*x` and `x`.\n-\n-### Checking for illegal assignments, moves, and reborrows\n-\n-Once we have computed the loans introduced by each borrow, the borrow\n-checker uses a data flow propagation to compute the full set of loans\n-in scope at each expression and then uses that set to decide whether\n-that expression is legal.  Remember that the scope of loan is defined\n-by its lifetime LT.  We sometimes say that a loan which is in-scope at\n-a particular point is an \"outstanding loan\", and the set of\n-restrictions included in those loans as the \"outstanding\n-restrictions\".\n-\n-The kinds of expressions which in-scope loans can render illegal are:\n-- *assignments* (`lv = v`): illegal if there is an in-scope restriction\n-  against mutating `lv`;\n-- *moves*: illegal if there is any in-scope restriction on `lv` at all;\n-- *mutable borrows* (`&mut lv`): illegal there is an in-scope restriction\n-  against claiming `lv`;\n-- *immutable borrows* (`&lv`): illegal there is an in-scope restriction\n-  against freezing `lv`.\n-\n-## Formal rules\n-\n-Now that we hopefully have some kind of intuitive feeling for how the\n-borrow checker works, let's look a bit more closely now at the precise\n-conditions that it uses. For simplicity I will ignore const loans.\n-\n-I will present the rules in a modified form of standard inference\n-rules, which looks as follows:\n-\n-```text\n-PREDICATE(X, Y, Z)                  // Rule-Name\n-  Condition 1\n-  Condition 2\n-  Condition 3\n-```\n-\n-The initial line states the predicate that is to be satisfied.  The\n-indented lines indicate the conditions that must be met for the\n-predicate to be satisfied. The right-justified comment states the name\n-of this rule: there are comments in the borrowck source referencing\n-these names, so that you can cross reference to find the actual code\n-that corresponds to the formal rule.\n-\n-### Invariants\n-\n-I want to collect, at a high-level, the invariants the borrow checker\n-maintains. I will give them names and refer to them throughout the\n-text. Together these invariants are crucial for the overall soundness\n-of the system.\n-\n-**Mutability requires uniqueness.** To mutate a path\n-\n-**Unique mutability.** There is only one *usable* mutable path to any\n-given memory at any given time. This implies that when claiming memory\n-with an expression like `p = &mut x`, the compiler must guarantee that\n-the borrowed value `x` can no longer be mutated so long as `p` is\n-live. (This is done via restrictions, read on.)\n-\n-**.**\n-\n-\n-### The `gather_loans` pass\n-\n-We start with the `gather_loans` pass, which walks the AST looking for\n-borrows.  For each borrow, there are three bits of information: the\n-lvalue `LV` being borrowed and the mutability `MQ` and lifetime `LT`\n-of the resulting pointer. Given those, `gather_loans` applies four\n-validity tests:\n-\n-1. `MUTABILITY(LV, MQ)`: The mutability of the reference is\n-compatible with the mutability of `LV` (i.e., not borrowing immutable\n-data as mutable).\n-\n-2. `ALIASABLE(LV, MQ)`: The aliasability of the reference is\n-compatible with the aliasability of `LV`. The goal is to prevent\n-`&mut` borrows of aliasability data.\n-\n-3. `LIFETIME(LV, LT, MQ)`: The lifetime of the borrow does not exceed\n-the lifetime of the value being borrowed.\n-\n-4. `RESTRICTIONS(LV, LT, ACTIONS) = RS`: This pass checks and computes the\n-restrictions to maintain memory safety. These are the restrictions\n-that will go into the final loan. We'll discuss in more detail below.\n-\n-## Checking mutability\n-\n-Checking mutability is fairly straightforward. We just want to prevent\n-immutable data from being borrowed as mutable. Note that it is ok to\n-borrow mutable data as immutable, since that is simply a\n-freeze. Formally we define a predicate `MUTABLE(LV, MQ)` which, if\n-defined, means that \"borrowing `LV` with mutability `MQ` is ok. The\n-Rust code corresponding to this predicate is the function\n-`check_mutability` in `middle::borrowck::gather_loans`.\n-\n-### Checking mutability of variables\n-\n-*Code pointer:* Function `check_mutability()` in `gather_loans/mod.rs`,\n-but also the code in `mem_categorization`.\n-\n-Let's begin with the rules for variables, which state that if a\n-variable is declared as mutable, it may be borrowed any which way, but\n-otherwise the variable must be borrowed as immutable or const:\n-\n-```text\n-MUTABILITY(X, MQ)                   // M-Var-Mut\n-  DECL(X) = mut\n-\n-MUTABILITY(X, MQ)                   // M-Var-Imm\n-  DECL(X) = imm\n-  MQ = imm | const\n-```\n-\n-### Checking mutability of owned content\n-\n-Fields and owned pointers inherit their mutability from\n-their base expressions, so both of their rules basically\n-delegate the check to the base expression `LV`:\n-\n-```text\n-MUTABILITY(LV.f, MQ)                // M-Field\n-  MUTABILITY(LV, MQ)\n-\n-MUTABILITY(*LV, MQ)                 // M-Deref-Unique\n-  TYPE(LV) = Box<Ty>\n-  MUTABILITY(LV, MQ)\n-```\n-\n-### Checking mutability of immutable pointer types\n-\n-Immutable pointer types like `&T` can only\n-be borrowed if MQ is immutable or const:\n-\n-```text\n-MUTABILITY(*LV, MQ)                // M-Deref-Borrowed-Imm\n-  TYPE(LV) = &Ty\n-  MQ == imm | const\n-```\n-\n-### Checking mutability of mutable pointer types\n-\n-`&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n-\n-```text\n-MUTABILITY(*LV, MQ)                 // M-Deref-Borrowed-Mut\n-  TYPE(LV) = &mut Ty\n-```\n-\n-## Checking aliasability\n-\n-The goal of the aliasability check is to ensure that we never permit\n-`&mut` borrows of aliasable data. Formally we define a predicate\n-`ALIASABLE(LV, MQ)` which if defined means that\n-\"borrowing `LV` with mutability `MQ` is ok\". The\n-Rust code corresponding to this predicate is the function\n-`check_aliasability()` in `middle::borrowck::gather_loans`.\n-\n-### Checking aliasability of variables\n-\n-Local variables are never aliasable as they are accessible only within\n-the stack frame.\n-\n-```text\n-    ALIASABLE(X, MQ)                   // M-Var-Mut\n-```\n-\n-### Checking aliasable of owned content\n-\n-Owned content is aliasable if it is found in an aliasable location:\n-\n-```text\n-ALIASABLE(LV.f, MQ)                // M-Field\n-  ALIASABLE(LV, MQ)\n-\n-ALIASABLE(*LV, MQ)                 // M-Deref-Unique\n-  ALIASABLE(LV, MQ)\n-```\n-\n-### Checking mutability of immutable pointer types\n-\n-Immutable pointer types like `&T` are aliasable, and hence can only be\n-borrowed immutably:\n-\n-```text\n-ALIASABLE(*LV, imm)                // M-Deref-Borrowed-Imm\n-  TYPE(LV) = &Ty\n-```\n-\n-### Checking mutability of mutable pointer types\n-\n-`&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n-\n-```text\n-ALIASABLE(*LV, MQ)                 // M-Deref-Borrowed-Mut\n-  TYPE(LV) = &mut Ty\n-```\n-\n-## Checking lifetime\n-\n-These rules aim to ensure that no data is borrowed for a scope that exceeds\n-its lifetime. These two computations wind up being intimately related.\n-Formally, we define a predicate `LIFETIME(LV, LT, MQ)`, which states that\n-\"the lvalue `LV` can be safely borrowed for the lifetime `LT` with mutability\n-`MQ`\". The Rust code corresponding to this predicate is the module\n-`middle::borrowck::gather_loans::lifetime`.\n-\n-### The Scope function\n-\n-Several of the rules refer to a helper function `SCOPE(LV)=LT`.  The\n-`SCOPE(LV)` yields the lifetime `LT` for which the lvalue `LV` is\n-guaranteed to exist, presuming that no mutations occur.\n-\n-The scope of a local variable is the block where it is declared:\n-\n-```text\n-  SCOPE(X) = block where X is declared\n-```\n-\n-The scope of a field is the scope of the struct:\n-\n-```text\n-  SCOPE(LV.f) = SCOPE(LV)\n-```\n-\n-The scope of a unique referent is the scope of the pointer, since\n-(barring mutation or moves) the pointer will not be freed until\n-the pointer itself `LV` goes out of scope:\n-\n-```text\n-  SCOPE(*LV) = SCOPE(LV) if LV has type Box<T>\n-```\n-\n-The scope of a borrowed referent is the scope associated with the\n-pointer.  This is a conservative approximation, since the data that\n-the pointer points at may actually live longer:\n-\n-```text\n-  SCOPE(*LV) = LT if LV has type &'LT T or &'LT mut T\n-```\n-\n-### Checking lifetime of variables\n-\n-The rule for variables states that a variable can only be borrowed a\n-lifetime `LT` that is a subregion of the variable's scope:\n-\n-```text\n-LIFETIME(X, LT, MQ)                 // L-Local\n-  LT <= SCOPE(X)\n-```\n-\n-### Checking lifetime for owned content\n-\n-The lifetime of a field or owned pointer is the same as the lifetime\n-of its owner:\n-\n-```text\n-LIFETIME(LV.f, LT, MQ)              // L-Field\n-  LIFETIME(LV, LT, MQ)\n-\n-LIFETIME(*LV, LT, MQ)               // L-Deref-Send\n-  TYPE(LV) = Box<Ty>\n-  LIFETIME(LV, LT, MQ)\n-```\n-\n-### Checking lifetime for derefs of references\n-\n-References have a lifetime `LT'` associated with them.  The\n-data they point at has been guaranteed to be valid for at least this\n-lifetime. Therefore, the borrow is valid so long as the lifetime `LT`\n-of the borrow is shorter than the lifetime `LT'` of the pointer\n-itself:\n-\n-```text\n-LIFETIME(*LV, LT, MQ)               // L-Deref-Borrowed\n-  TYPE(LV) = &LT' Ty OR &LT' mut Ty\n-  LT <= LT'\n-```\n-\n-## Computing the restrictions\n-\n-The final rules govern the computation of *restrictions*, meaning that\n-we compute the set of actions that will be illegal for the life of the\n-loan. The predicate is written `RESTRICTIONS(LV, LT, ACTIONS) =\n-RESTRICTION*`, which can be read \"in order to prevent `ACTIONS` from\n-occurring on `LV`, the restrictions `RESTRICTION*` must be respected\n-for the lifetime of the loan\".\n-\n-Note that there is an initial set of restrictions: these restrictions\n-are computed based on the kind of borrow:\n-\n-```text\n-&mut LV =>   RESTRICTIONS(LV, LT, MUTATE|CLAIM|FREEZE)\n-&LV =>       RESTRICTIONS(LV, LT, MUTATE|CLAIM)\n-&const LV => RESTRICTIONS(LV, LT, [])\n-```\n-\n-The reasoning here is that a mutable borrow must be the only writer,\n-therefore it prevents other writes (`MUTATE`), mutable borrows\n-(`CLAIM`), and immutable borrows (`FREEZE`). An immutable borrow\n-permits other immutable borrows but forbids writes and mutable borrows.\n-Finally, a const borrow just wants to be sure that the value is not\n-moved out from under it, so no actions are forbidden.\n-\n-### Restrictions for loans of a local variable\n-\n-The simplest case is a borrow of a local variable `X`:\n-\n-```text\n-RESTRICTIONS(X, LT, ACTIONS) = (X, ACTIONS)            // R-Variable\n-```\n-\n-In such cases we just record the actions that are not permitted.\n-\n-### Restrictions for loans of fields\n-\n-Restricting a field is the same as restricting the owner of that\n-field:\n-\n-```text\n-RESTRICTIONS(LV.f, LT, ACTIONS) = RS, (LV.f, ACTIONS)  // R-Field\n-  RESTRICTIONS(LV, LT, ACTIONS) = RS\n-```\n-\n-The reasoning here is as follows. If the field must not be mutated,\n-then you must not mutate the owner of the field either, since that\n-would indirectly modify the field. Similarly, if the field cannot be\n-frozen or aliased, we cannot allow the owner to be frozen or aliased,\n-since doing so indirectly freezes/aliases the field. This is the\n-origin of inherited mutability.\n-\n-### Restrictions for loans of owned referents\n-\n-Because the mutability of owned referents is inherited, restricting an\n-owned referent is similar to restricting a field, in that it implies\n-restrictions on the pointer. However, owned pointers have an important\n-twist: if the owner `LV` is mutated, that causes the owned referent\n-`*LV` to be freed! So whenever an owned referent `*LV` is borrowed, we\n-must prevent the owned pointer `LV` from being mutated, which means\n-that we always add `MUTATE` and `CLAIM` to the restriction set imposed\n-on `LV`:\n-\n-```text\n-RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Send-Pointer\n-  TYPE(LV) = Box<Ty>\n-  RESTRICTIONS(LV, LT, ACTIONS|MUTATE|CLAIM) = RS\n-```\n-\n-### Restrictions for loans of immutable borrowed referents\n-\n-Immutable borrowed referents are freely aliasable, meaning that\n-the compiler does not prevent you from copying the pointer.  This\n-implies that issuing restrictions is useless. We might prevent the\n-user from acting on `*LV` itself, but there could be another path\n-`*LV1` that refers to the exact same memory, and we would not be\n-restricting that path. Therefore, the rule for `&Ty` pointers\n-always returns an empty set of restrictions, and it only permits\n-restricting `MUTATE` and `CLAIM` actions:\n-\n-```text\n-RESTRICTIONS(*LV, LT, ACTIONS) = []                    // R-Deref-Imm-Borrowed\n-  TYPE(LV) = &LT' Ty\n-  LT <= LT'                                            // (1)\n-  ACTIONS subset of [MUTATE, CLAIM]\n-```\n-\n-The reason that we can restrict `MUTATE` and `CLAIM` actions even\n-without a restrictions list is that it is never legal to mutate nor to\n-borrow mutably the contents of a `&Ty` pointer. In other words,\n-those restrictions are already inherent in the type.\n-\n-Clause (1) in the rule for `&Ty` deserves mention. Here I\n-specify that the lifetime of the loan must be less than the lifetime\n-of the `&Ty` pointer. In simple cases, this clause is redundant, since\n-the `LIFETIME()` function will already enforce the required rule:\n-\n-```\n-fn foo(point: &'a Point) -> &'static f32 {\n-    &point.x // Error\n-}\n-```\n-\n-The above example fails to compile both because of clause (1) above\n-but also by the basic `LIFETIME()` check. However, in more advanced\n-examples involving multiple nested pointers, clause (1) is needed:\n-\n-```\n-fn foo(point: &'a &'b mut Point) -> &'b f32 {\n-    &point.x // Error\n-}\n-```\n-\n-The `LIFETIME` rule here would accept `'b` because, in fact, the\n-*memory is* guaranteed to remain valid (i.e., not be freed) for the\n-lifetime `'b`, since the `&mut` pointer is valid for `'b`. However, we\n-are returning an immutable reference, so we need the memory to be both\n-valid and immutable. Even though `point.x` is referenced by an `&mut`\n-pointer, it can still be considered immutable so long as that `&mut`\n-pointer is found in an aliased location. That means the memory is\n-guaranteed to be *immutable* for the lifetime of the `&` pointer,\n-which is only `'a`, not `'b`. Hence this example yields an error.\n-\n-As a final twist, consider the case of two nested *immutable*\n-pointers, rather than a mutable pointer within an immutable one:\n-\n-```\n-fn foo(point: &'a &'b Point) -> &'b f32 {\n-    &point.x // OK\n-}\n-```\n-\n-This function is legal. The reason for this is that the inner pointer\n-(`*point : &'b Point`) is enough to guarantee the memory is immutable\n-and valid for the lifetime `'b`.  This is reflected in\n-`RESTRICTIONS()` by the fact that we do not recurse (i.e., we impose\n-no restrictions on `LV`, which in this particular case is the pointer\n-`point : &'a &'b Point`).\n-\n-#### Why both `LIFETIME()` and `RESTRICTIONS()`?\n-\n-Given the previous text, it might seem that `LIFETIME` and\n-`RESTRICTIONS` should be folded together into one check, but there is\n-a reason that they are separated. They answer separate concerns.\n-The rules pertaining to `LIFETIME` exist to ensure that we don't\n-create a borrowed pointer that outlives the memory it points at. So\n-`LIFETIME` prevents a function like this:\n-\n-```\n-fn get_1<'a>() -> &'a int {\n-    let x = 1;\n-    &x\n-}\n-```\n-\n-Here we would be returning a pointer into the stack. Clearly bad.\n-\n-However, the `RESTRICTIONS` rules are more concerned with how memory\n-is used. The example above doesn't generate an error according to\n-`RESTRICTIONS` because, for local variables, we don't require that the\n-loan lifetime be a subset of the local variable lifetime. The idea\n-here is that we *can* guarantee that `x` is not (e.g.) mutated for the\n-lifetime `'a`, even though `'a` exceeds the function body and thus\n-involves unknown code in the caller -- after all, `x` ceases to exist\n-after we return and hence the remaining code in `'a` cannot possibly\n-mutate it. This distinction is important for type checking functions\n-like this one:\n-\n-```\n-fn inc_and_get<'a>(p: &'a mut Point) -> &'a int {\n-    p.x += 1;\n-    &p.x\n-}\n-```\n-\n-In this case, we take in a `&mut` and return a frozen borrowed pointer\n-with the same lifetime. So long as the lifetime of the returned value\n-doesn't exceed the lifetime of the `&mut` we receive as input, this is\n-fine, though it may seem surprising at first (it surprised me when I\n-first worked it through). After all, we're guaranteeing that `*p`\n-won't be mutated for the lifetime `'a`, even though we can't \"see\" the\n-entirety of the code during that lifetime, since some of it occurs in\n-our caller. But we *do* know that nobody can mutate `*p` except\n-through `p`. So if we don't mutate `*p` and we don't return `p`, then\n-we know that the right to mutate `*p` has been lost to our caller --\n-in terms of capability, the caller passed in the ability to mutate\n-`*p`, and we never gave it back. (Note that we can't return `p` while\n-`*p` is borrowed since that would be a move of `p`, as `&mut` pointers\n-are affine.)\n-\n-### Restrictions for loans of const aliasable referents\n-\n-Freeze pointers are read-only. There may be `&mut` or `&` aliases, and\n-we can not prevent *anything* but moves in that case. So the\n-`RESTRICTIONS` function is only defined if `ACTIONS` is the empty set.\n-Because moves from a `&const` lvalue are never legal, it is not\n-necessary to add any restrictions at all to the final result.\n-\n-```text\n-    RESTRICTIONS(*LV, LT, []) = []                         // R-Deref-Freeze-Borrowed\n-      TYPE(LV) = &const Ty\n-```\n-\n-### Restrictions for loans of mutable borrowed referents\n-\n-Mutable borrowed pointers are guaranteed to be the only way to mutate\n-their referent. This permits us to take greater license with them; for\n-example, the referent can be frozen simply be ensuring that we do not\n-use the original pointer to perform mutate. Similarly, we can allow\n-the referent to be claimed, so long as the original pointer is unused\n-while the new claimant is live.\n-\n-The rule for mutable borrowed pointers is as follows:\n-\n-```text\n-RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Mut-Borrowed\n-  TYPE(LV) = &LT' mut Ty\n-  LT <= LT'                                            // (1)\n-  RESTRICTIONS(LV, LT, ACTIONS) = RS                   // (2)\n-```\n-\n-Let's examine the two numbered clauses:\n-\n-Clause (1) specifies that the lifetime of the loan (`LT`) cannot\n-exceed the lifetime of the `&mut` pointer (`LT'`). The reason for this\n-is that the `&mut` pointer is guaranteed to be the only legal way to\n-mutate its referent -- but only for the lifetime `LT'`.  After that\n-lifetime, the loan on the referent expires and hence the data may be\n-modified by its owner again. This implies that we are only able to\n-guarantee that the referent will not be modified or aliased for a\n-maximum of `LT'`.\n-\n-Here is a concrete example of a bug this rule prevents:\n-\n-```\n-// Test region-reborrow-from-shorter-mut-ref.rs:\n-fn copy_pointer<'a,'b,T>(x: &'a mut &'b mut T) -> &'b mut T {\n-    &mut **p // ERROR due to clause (1)\n-}\n-fn main() {\n-    let mut x = 1;\n-    let mut y = &mut x; // <-'b-----------------------------+\n-    //      +-'a--------------------+                       |\n-    //      v                       v                       |\n-    let z = copy_borrowed_ptr(&mut y); // y is lent         |\n-    *y += 1; // Here y==z, so both should not be usable...  |\n-    *z += 1; // ...and yet they would be, but for clause 1. |\n-} // <------------------------------------------------------+\n-```\n-\n-Clause (2) propagates the restrictions on the referent to the pointer\n-itself. This is the same as with an owned pointer, though the\n-reasoning is mildly different. The basic goal in all cases is to\n-prevent the user from establishing another route to the same data. To\n-see what I mean, let's examine various cases of what can go wrong and\n-show how it is prevented.\n-\n-**Example danger 1: Moving the base pointer.** One of the simplest\n-ways to violate the rules is to move the base pointer to a new name\n-and access it via that new name, thus bypassing the restrictions on\n-the old name. Here is an example:\n-\n-```\n-// src/test/compile-fail/borrowck-move-mut-base-ptr.rs\n-fn foo(t0: &mut int) {\n-    let p: &int = &*t0; // Freezes `*t0`\n-    let t1 = t0;        //~ ERROR cannot move out of `t0`\n-    *t1 = 22;           // OK, not a write through `*t0`\n-}\n-```\n-\n-Remember that `&mut` pointers are linear, and hence `let t1 = t0` is a\n-move of `t0` -- or would be, if it were legal. Instead, we get an\n-error, because clause (2) imposes restrictions on `LV` (`t0`, here),\n-and any restrictions on a path make it impossible to move from that\n-path.\n-\n-**Example danger 2: Claiming the base pointer.** Another possible\n-danger is to mutably borrow the base path. This can lead to two bad\n-scenarios. The most obvious is that the mutable borrow itself becomes\n-another path to access the same data, as shown here:\n-\n-```\n-// src/test/compile-fail/borrowck-mut-borrow-of-mut-base-ptr.rs\n-fn foo<'a>(mut t0: &'a mut int,\n-           mut t1: &'a mut int) {\n-    let p: &int = &*t0;     // Freezes `*t0`\n-    let mut t2 = &mut t0;   //~ ERROR cannot borrow `t0`\n-    **t2 += 1;              // Mutates `*t0`\n-}\n-```\n-\n-In this example, `**t2` is the same memory as `*t0`. Because `t2` is\n-an `&mut` pointer, `**t2` is a unique path and hence it would be\n-possible to mutate `**t2` even though that memory was supposed to be\n-frozen by the creation of `p`. However, an error is reported -- the\n-reason is that the freeze `&*t0` will restrict claims and mutation\n-against `*t0` which, by clause 2, in turn prevents claims and mutation\n-of `t0`. Hence the claim `&mut t0` is illegal.\n-\n-Another danger with an `&mut` pointer is that we could swap the `t0`\n-value away to create a new path:\n-\n-```\n-// src/test/compile-fail/borrowck-swap-mut-base-ptr.rs\n-fn foo<'a>(mut t0: &'a mut int,\n-           mut t1: &'a mut int) {\n-    let p: &int = &*t0;     // Freezes `*t0`\n-    swap(&mut t0, &mut t1); //~ ERROR cannot borrow `t0`\n-    *t1 = 22;\n-}\n-```\n-\n-This is illegal for the same reason as above. Note that if we added\n-back a swap operator -- as we used to have -- we would want to be very\n-careful to ensure this example is still illegal.\n-\n-**Example danger 3: Freeze the base pointer.** In the case where the\n-referent is claimed, even freezing the base pointer can be dangerous,\n-as shown in the following example:\n-\n-```\n-// src/test/compile-fail/borrowck-borrow-of-mut-base-ptr.rs\n-fn foo<'a>(mut t0: &'a mut int,\n-           mut t1: &'a mut int) {\n-    let p: &mut int = &mut *t0; // Claims `*t0`\n-    let mut t2 = &t0;           //~ ERROR cannot borrow `t0`\n-    let q: &int = &*t2;         // Freezes `*t0` but not through `*p`\n-    *p += 1;                    // violates type of `*q`\n-}\n-```\n-\n-Here the problem is that `*t0` is claimed by `p`, and hence `p` wants\n-to be the controlling pointer through which mutation or freezes occur.\n-But `t2` would -- if it were legal -- have the type `& &mut int`, and\n-hence would be a mutable pointer in an aliasable location, which is\n-considered frozen (since no one can write to `**t2` as it is not a\n-unique path). Therefore, we could reasonably create a frozen `&int`\n-pointer pointing at `*t0` that coexists with the mutable pointer `p`,\n-which is clearly unsound.\n-\n-However, it is not always unsafe to freeze the base pointer. In\n-particular, if the referent is frozen, there is no harm in it:\n-\n-```\n-// src/test/run-pass/borrowck-borrow-of-mut-base-ptr-safe.rs\n-fn foo<'a>(mut t0: &'a mut int,\n-           mut t1: &'a mut int) {\n-    let p: &int = &*t0; // Freezes `*t0`\n-    let mut t2 = &t0;\n-    let q: &int = &*t2; // Freezes `*t0`, but that's ok...\n-    let r: &int = &*t0; // ...after all, could do same thing directly.\n-}\n-```\n-\n-In this case, creating the alias `t2` of `t0` is safe because the only\n-thing `t2` can be used for is to further freeze `*t0`, which is\n-already frozen. In particular, we cannot assign to `*t0` through the\n-new alias `t2`, as demonstrated in this test case:\n-\n-```\n-// src/test/run-pass/borrowck-borrow-mut-base-ptr-in-aliasable-loc.rs\n-fn foo(t0: & &mut int) {\n-    let t1 = t0;\n-    let p: &int = &**t0;\n-    **t1 = 22; //~ ERROR cannot assign\n-}\n-```\n-\n-This distinction is reflected in the rules. When doing an `&mut`\n-borrow -- as in the first example -- the set `ACTIONS` will be\n-`CLAIM|MUTATE|FREEZE`, because claiming the referent implies that it\n-cannot be claimed, mutated, or frozen by anyone else. These\n-restrictions are propagated back to the base path and hence the base\n-path is considered unfreezable.\n-\n-In contrast, when the referent is merely frozen -- as in the second\n-example -- the set `ACTIONS` will be `CLAIM|MUTATE`, because freezing\n-the referent implies that it cannot be claimed or mutated but permits\n-others to freeze. Hence when these restrictions are propagated back to\n-the base path, it will still be considered freezable.\n-\n-\n-\n-**FIXME #10520: Restrictions against mutating the base pointer.** When\n-an `&mut` pointer is frozen or claimed, we currently pass along the\n-restriction against MUTATE to the base pointer. I do not believe this\n-restriction is needed. It dates from the days when we had a way to\n-mutate that preserved the value being mutated (i.e., swap). Nowadays\n-the only form of mutation is assignment, which destroys the pointer\n-being mutated -- therefore, a mutation cannot create a new path to the\n-same data. Rather, it removes an existing path. This implies that not\n-only can we permit mutation, we can have mutation kill restrictions in\n-the dataflow sense.\n-\n-**WARNING:** We do not currently have `const` borrows in the\n-language. If they are added back in, we must ensure that they are\n-consistent with all of these examples. The crucial question will be\n-what sorts of actions are permitted with a `&const &mut` pointer. I\n-would suggest that an `&mut` referent found in an `&const` location be\n-prohibited from both freezes and claims. This would avoid the need to\n-prevent `const` borrows of the base pointer when the referent is\n-borrowed.\n-\n-# Moves and initialization\n-\n-The borrow checker is also in charge of ensuring that:\n-\n-- all memory which is accessed is initialized\n-- immutable local variables are assigned at most once.\n-\n-These are two separate dataflow analyses built on the same\n-framework. Let's look at checking that memory is initialized first;\n-the checking of immutable local variable assignments works in a very\n-similar way.\n-\n-To track the initialization of memory, we actually track all the\n-points in the program that *create uninitialized memory*, meaning\n-moves and the declaration of uninitialized variables. For each of\n-these points, we create a bit in the dataflow set. Assignments to a\n-variable `x` or path `a.b.c` kill the move/uninitialization bits for\n-those paths and any subpaths (e.g., `x`, `x.y`, `a.b.c`, `*a.b.c`).\n-Bits are unioned when two control-flow paths join. Thus, the\n-presence of a bit indicates that the move may have occurred without an\n-intervening assignment to the same memory. At each use of a variable,\n-we examine the bits in scope, and check that none of them are\n-moves/uninitializations of the variable that is being used.\n-\n-Let's look at a simple example:\n-\n-```\n-fn foo(a: Box<int>) {\n-    let b: Box<int>;   // Gen bit 0.\n-\n-    if cond {          // Bits: 0\n-        use(&*a);\n-        b = a;         // Gen bit 1, kill bit 0.\n-        use(&*b);\n-    } else {\n-                       // Bits: 0\n-    }\n-                       // Bits: 0,1\n-    use(&*a);          // Error.\n-    use(&*b);          // Error.\n-}\n-\n-fn use(a: &int) { }\n-```\n-\n-In this example, the variable `b` is created uninitialized. In one\n-branch of an `if`, we then move the variable `a` into `b`. Once we\n-exit the `if`, therefore, it is an error to use `a` or `b` since both\n-are only conditionally initialized. I have annotated the dataflow\n-state using comments. There are two dataflow bits, with bit 0\n-corresponding to the creation of `b` without an initializer, and bit 1\n-corresponding to the move of `a`. The assignment `b = a` both\n-generates bit 1, because it is a move of `a`, and kills bit 0, because\n-`b` is now initialized. On the else branch, though, `b` is never\n-initialized, and so bit 0 remains untouched. When the two flows of\n-control join, we union the bits from both sides, resulting in both\n-bits 0 and 1 being set. Thus any attempt to use `a` uncovers the bit 1\n-from the \"then\" branch, showing that `a` may be moved, and any attempt\n-to use `b` uncovers bit 0, from the \"else\" branch, showing that `b`\n-may not be initialized.\n-\n-## Initialization of immutable variables\n-\n-Initialization of immutable variables works in a very similar way,\n-except that:\n-\n-1. we generate bits for each assignment to a variable;\n-2. the bits are never killed except when the variable goes out of scope.\n-\n-Thus the presence of an assignment bit indicates that the assignment\n-may have occurred. Note that assignments are only killed when the\n-variable goes out of scope, as it is not relevant whether or not there\n-has been a move in the meantime. Using these bits, we can declare that\n-an assignment to an immutable variable is legal iff there is no other\n-assignment bit to that same variable in scope.\n-\n-## Why is the design made this way?\n-\n-It may seem surprising that we assign dataflow bits to *each move*\n-rather than *each path being moved*. This is somewhat less efficient,\n-since on each use, we must iterate through all moves and check whether\n-any of them correspond to the path in question. Similar concerns apply\n-to the analysis for double assignments to immutable variables. The\n-main reason to do it this way is that it allows us to print better\n-error messages, because when a use occurs, we can print out the\n-precise move that may be in scope, rather than simply having to say\n-\"the variable may not be initialized\".\n-\n-## Data structures used in the move analysis\n-\n-The move analysis maintains several data structures that enable it to\n-cross-reference moves and assignments to determine when they may be\n-moving/assigning the same memory. These are all collected into the\n-`MoveData` and `FlowedMoveData` structs. The former represents the set\n-of move paths, moves, and assignments, and the latter adds in the\n-results of a dataflow computation.\n-\n-### Move paths\n-\n-The `MovePath` tree tracks every path that is moved or assigned to.\n-These paths have the same form as the `LoanPath` data structure, which\n-in turn is the \"real world version of the lvalues `LV` that we\n-introduced earlier. The difference between a `MovePath` and a `LoanPath`\n-is that move paths are:\n-\n-1. Canonicalized, so that we have exactly one copy of each, and\n-   we can refer to move paths by index;\n-2. Cross-referenced with other paths into a tree, so that given a move\n-   path we can efficiently find all parent move paths and all\n-   extensions (e.g., given the `a.b` move path, we can easily find the\n-   move path `a` and also the move paths `a.b.c`)\n-3. Cross-referenced with moves and assignments, so that we can\n-   easily find all moves and assignments to a given path.\n-\n-The mechanism that we use is to create a `MovePath` record for each\n-move path. These are arranged in an array and are referenced using\n-`MovePathIndex` values, which are newtype'd indices. The `MovePath`\n-structs are arranged into a tree, representing using the standard\n-Knuth representation where each node has a child 'pointer' and a \"next\n-sibling\" 'pointer'. In addition, each `MovePath` has a parent\n-'pointer'.  In this case, the 'pointers' are just `MovePathIndex`\n-values.\n-\n-In this way, if we want to find all base paths of a given move path,\n-we can just iterate up the parent pointers (see `each_base_path()` in\n-the `move_data` module). If we want to find all extensions, we can\n-iterate through the subtree (see `each_extending_path()`).\n-\n-### Moves and assignments\n-\n-There are structs to represent moves (`Move`) and assignments\n-(`Assignment`), and these are also placed into arrays and referenced\n-by index. All moves of a particular path are arranged into a linked\n-lists, beginning with `MovePath.first_move` and continuing through\n-`Move.next_move`.\n-\n-We distinguish between \"var\" assignments, which are assignments to a\n-variable like `x = foo`, and \"path\" assignments (`x.f = foo`).  This\n-is because we need to assign dataflows to the former, but not the\n-latter, so as to check for double initialization of immutable\n-variables.\n-\n-### Gathering and checking moves\n-\n-Like loans, we distinguish two phases. The first, gathering, is where\n-we uncover all the moves and assignments. As with loans, we do some\n-basic sanity checking in this phase, so we'll report errors if you\n-attempt to move out of a borrowed pointer etc. Then we do the dataflow\n-(see `FlowedMoveData::new`). Finally, in the `check_loans.rs` code, we\n-walk back over, identify all uses, assignments, and captures, and\n-check that they are legal given the set of dataflow bits we have\n-computed for that program point.\n-\n-# Drop flags and structural fragments\n-\n-In addition to the job of enforcing memory safety, the borrow checker\n-code is also responsible for identifying the *structural fragments* of\n-data in the function, to support out-of-band dynamic drop flags\n-allocated on the stack. (For background, see [RFC PR #320].)\n-\n-[RFC PR #320]: https://github.com/rust-lang/rfcs/pull/320\n-\n-Semantically, each piece of data that has a destructor may need a\n-boolean flag to indicate whether or not its destructor has been run\n-yet. However, in many cases there is no need to actually maintain such\n-a flag: It can be apparent from the code itself that a given path is\n-always initialized (or always deinitialized) when control reaches the\n-end of its owner's scope, and thus we can unconditionally emit (or\n-not) the destructor invocation for that path.\n-\n-A simple example of this is the following:\n-\n-```rust\n-struct D { p: int }\n-impl D { fn new(x: int) -> D { ... }\n-impl Drop for D { ... }\n-\n-fn foo(a: D, b: D, t: || -> bool) {\n-    let c: D;\n-    let d: D;\n-    if t() { c = b; }\n-}\n-```\n-\n-At the end of the body of `foo`, the compiler knows that `a` is\n-initialized, introducing a drop obligation (deallocating the boxed\n-integer) for the end of `a`'s scope that is run unconditionally.\n-Likewise the compiler knows that `d` is not initialized, and thus it\n-leave out the drop code for `d`.\n-\n-The compiler cannot statically know the drop-state of `b` nor `c` at\n-the end of their scope, since that depends on the value of\n-`t`. Therefore, we need to insert boolean flags to track whether we\n-need to drop `b` and `c`.\n-\n-However, the matter is not as simple as just mapping local variables\n-to their corresponding drop flags when necessary. In particular, in\n-addition to being able to move data out of local variables, Rust\n-allows one to move values in and out of structured data.\n-\n-Consider the following:\n-\n-```rust\n-struct S { x: D, y: D, z: D }\n-\n-fn foo(a: S, mut b: S, t: || -> bool) {\n-    let mut c: S;\n-    let d: S;\n-    let e: S = a.clone();\n-    if t() {\n-        c = b;\n-        b.x = e.y;\n-    }\n-    if t() { c.y = D::new(4); }\n-}\n-```\n-\n-As before, the drop obligations of `a` and `d` can be statically\n-determined, and again the state of `b` and `c` depend on dynamic\n-state. But additionally, the dynamic drop obligations introduced by\n-`b` and `c` are not just per-local boolean flags. For example, if the\n-first call to `t` returns `false` and the second call `true`, then at\n-the end of their scope, `b` will be completely initialized, but only\n-`c.y` in `c` will be initialized.  If both calls to `t` return `true`,\n-then at the end of their scope, `c` will be completely initialized,\n-but only `b.x` will be initialized in `b`, and only `e.x` and `e.z`\n-will be initialized in `e`.\n-\n-Note that we need to cover the `z` field in each case in some way,\n-since it may (or may not) need to be dropped, even though `z` is never\n-directly mentioned in the body of the `foo` function. We call a path\n-like `b.z` a *fragment sibling* of `b.x`, since the field `z` comes\n-from the same structure `S` that declared the field `x` in `b.x`.\n-\n-In general we need to maintain boolean flags that match the\n-`S`-structure of both `b` and `c`.  In addition, we need to consult\n-such a flag when doing an assignment (such as `c.y = D::new(4);`\n-above), in order to know whether or not there is a previous value that\n-needs to be dropped before we do the assignment.\n-\n-So for any given function, we need to determine what flags are needed\n-to track its drop obligations. Our strategy for determining the set of\n-flags is to represent the fragmentation of the structure explicitly:\n-by starting initially from the paths that are explicitly mentioned in\n-moves and assignments (such as `b.x` and `c.y` above), and then\n-traversing the structure of the path's type to identify leftover\n-*unmoved fragments*: assigning into `c.y` means that `c.x` and `c.z`\n-are leftover unmoved fragments. Each fragment represents a drop\n-obligation that may need to be tracked. Paths that are only moved or\n-assigned in their entirety (like `a` and `d`) are treated as a single\n-drop obligation.\n-\n-The fragment construction process works by piggy-backing on the\n-existing `move_data` module. We already have callbacks that visit each\n-direct move and assignment; these form the basis for the sets of\n-moved_leaf_paths and assigned_leaf_paths. From these leaves, we can\n-walk up their parent chain to identify all of their parent paths.\n-We need to identify the parents because of cases like the following:\n-\n-```rust\n-struct Pair<X,Y>{ x: X, y: Y }\n-fn foo(dd_d_d: Pair<Pair<Pair<D, D>, D>, D>) {\n-    other_function(dd_d_d.x.y);\n-}\n-```\n-\n-In this code, the move of the path `dd_d.x.y` leaves behind not only\n-the fragment drop-obligation `dd_d.x.x` but also `dd_d.y` as well.\n-\n-Once we have identified the directly-referenced leaves and their\n-parents, we compute the left-over fragments, in the function\n-`fragments::add_fragment_siblings`. As of this writing this works by\n-looking at each directly-moved or assigned path P, and blindly\n-gathering all sibling fields of P (as well as siblings for the parents\n-of P, etc). After accumulating all such siblings, we filter out the\n-entries added as siblings of P that turned out to be\n-directly-referenced paths (or parents of directly referenced paths)\n-themselves, thus leaving the never-referenced \"left-overs\" as the only\n-thing left from the gathering step.\n-\n-## Array structural fragments\n-\n-A special case of the structural fragments discussed above are\n-the elements of an array that has been passed by value, such as\n-the following:\n-\n-```rust\n-fn foo(a: [D, ..10], i: uint) -> D {\n-    a[i]\n-}\n-```\n-\n-The above code moves a single element out of the input array `a`.\n-The remainder of the array still needs to be dropped; i.e., it\n-is a structural fragment. Note that after performing such a move,\n-it is not legal to read from the array `a`. There are a number of\n-ways to deal with this, but the important thing to note is that\n-the semantics needs to distinguish in some manner between a\n-fragment that is the *entire* array versus a fragment that represents\n-all-but-one element of the array.  A place where that distinction\n-would arise is the following:\n-\n-```rust\n-fn foo(a: [D, ..10], b: [D, ..10], i: uint, t: bool) -> D {\n-    if t {\n-        a[i]\n-    } else {\n-        b[i]\n-    }\n-\n-    // When control exits, we will need either to drop all of `a`\n-    // and all-but-one of `b`, or to drop all of `b` and all-but-one\n-    // of `a`.\n-}\n-```\n-\n-There are a number of ways that the trans backend could choose to\n-compile this (e.g. a `[bool, ..10]` array for each such moved array;\n-or an `Option<uint>` for each moved array).  From the viewpoint of the\n-borrow-checker, the important thing is to record what kind of fragment\n-is implied by the relevant moves.\n-\n-# Future work\n-\n-While writing up these docs, I encountered some rules I believe to be\n-stricter than necessary:\n-\n-- I think restricting the `&mut` LV against moves and `ALIAS` is sufficient,\n-  `MUTATE` and `CLAIM` are overkill. `MUTATE` was necessary when swap was\n-  a built-in operator, but as it is not, it is implied by `CLAIM`,\n-  and `CLAIM` is implied by `ALIAS`. The only net effect of this is an\n-  extra error message in some cases, though.\n-- I have not described how closures interact. Current code is unsound.\n-  I am working on describing and implementing the fix.\n-- If we wish, we can easily extend the move checking to allow finer-grained\n-  tracking of what is initialized and what is not, enabling code like\n-  this:\n-\n-      a = x.f.g; // x.f.g is now uninitialized\n-      // here, x and x.f are not usable, but x.f.h *is*\n-      x.f.g = b; // x.f.g is not initialized\n-      // now x, x.f, x.f.g, x.f.h are all usable\n-\n-  What needs to change here, most likely, is that the `moves` module\n-  should record not only what paths are moved, but what expressions\n-  are actual *uses*. For example, the reference to `x` in `x.f.g = b`\n-  is not a true *use* in the sense that it requires `x` to be fully\n-  initialized. This is in fact why the above code produces an error\n-  today: the reference to `x` in `x.f.g = b` is considered illegal\n-  because `x` is not fully initialized.\n-\n-There are also some possible refactorings:\n-\n-- It might be nice to replace all loan paths with the MovePath mechanism,\n-  since they allow lightweight comparison using an integer.\n-\n-*/\n+//! # The Borrow Checker\n+//!\n+//! This pass has the job of enforcing memory safety. This is a subtle\n+//! topic. This docs aim to explain both the practice and the theory\n+//! behind the borrow checker. They start with a high-level overview of\n+//! how it works, and then proceed to dive into the theoretical\n+//! background. Finally, they go into detail on some of the more subtle\n+//! aspects.\n+//!\n+//! # Table of contents\n+//!\n+//! These docs are long. Search for the section you are interested in.\n+//!\n+//! - Overview\n+//! - Formal model\n+//! - Borrowing and loans\n+//! - Moves and initialization\n+//! - Drop flags and structural fragments\n+//! - Future work\n+//!\n+//! # Overview\n+//!\n+//! The borrow checker checks one function at a time. It operates in two\n+//! passes. The first pass, called `gather_loans`, walks over the function\n+//! and identifies all of the places where borrows (e.g., `&` expressions\n+//! and `ref` bindings) and moves (copies or captures of a linear value)\n+//! occur. It also tracks initialization sites. For each borrow and move,\n+//! it checks various basic safety conditions at this time (for example,\n+//! that the lifetime of the borrow doesn't exceed the lifetime of the\n+//! value being borrowed, or that there is no move out of an `&T`\n+//! referent).\n+//!\n+//! It then uses the dataflow module to propagate which of those borrows\n+//! may be in scope at each point in the procedure. A loan is considered\n+//! to come into scope at the expression that caused it and to go out of\n+//! scope when the lifetime of the resulting reference expires.\n+//!\n+//! Once the in-scope loans are known for each point in the program, the\n+//! borrow checker walks the IR again in a second pass called\n+//! `check_loans`. This pass examines each statement and makes sure that\n+//! it is safe with respect to the in-scope loans.\n+//!\n+//! # Formal model\n+//!\n+//! Throughout the docs we'll consider a simple subset of Rust in which\n+//! you can only borrow from lvalues, defined like so:\n+//!\n+//! ```text\n+//! LV = x | LV.f | *LV\n+//! ```\n+//!\n+//! Here `x` represents some variable, `LV.f` is a field reference,\n+//! and `*LV` is a pointer dereference. There is no auto-deref or other\n+//! niceties. This means that if you have a type like:\n+//!\n+//! ```text\n+//! struct S { f: uint }\n+//! ```\n+//!\n+//! and a variable `a: Box<S>`, then the rust expression `a.f` would correspond\n+//! to an `LV` of `(*a).f`.\n+//!\n+//! Here is the formal grammar for the types we'll consider:\n+//!\n+//! ```text\n+//! TY = () | S<'LT...> | Box<TY> | & 'LT MQ TY\n+//! MQ = mut | imm | const\n+//! ```\n+//!\n+//! Most of these types should be pretty self explanatory. Here `S` is a\n+//! struct name and we assume structs are declared like so:\n+//!\n+//! ```text\n+//! SD = struct S<'LT...> { (f: TY)... }\n+//! ```\n+//!\n+//! # Borrowing and loans\n+//!\n+//! ## An intuitive explanation\n+//!\n+//! ### Issuing loans\n+//!\n+//! Now, imagine we had a program like this:\n+//!\n+//! ```text\n+//! struct Foo { f: uint, g: uint }\n+//! ...\n+//! 'a: {\n+//!   let mut x: Box<Foo> = ...;\n+//!   let y = &mut (*x).f;\n+//!   x = ...;\n+//! }\n+//! ```\n+//!\n+//! This is of course dangerous because mutating `x` will free the old\n+//! value and hence invalidate `y`. The borrow checker aims to prevent\n+//! this sort of thing.\n+//!\n+//! #### Loans and restrictions\n+//!\n+//! The way the borrow checker works is that it analyzes each borrow\n+//! expression (in our simple model, that's stuff like `&LV`, though in\n+//! real life there are a few other cases to consider). For each borrow\n+//! expression, it computes a `Loan`, which is a data structure that\n+//! records (1) the value being borrowed, (2) the mutability and scope of\n+//! the borrow, and (3) a set of restrictions. In the code, `Loan` is a\n+//! struct defined in `middle::borrowck`. Formally, we define `LOAN` as\n+//! follows:\n+//!\n+//! ```text\n+//! LOAN = (LV, LT, MQ, RESTRICTION*)\n+//! RESTRICTION = (LV, ACTION*)\n+//! ACTION = MUTATE | CLAIM | FREEZE\n+//! ```\n+//!\n+//! Here the `LOAN` tuple defines the lvalue `LV` being borrowed; the\n+//! lifetime `LT` of that borrow; the mutability `MQ` of the borrow; and a\n+//! list of restrictions. The restrictions indicate actions which, if\n+//! taken, could invalidate the loan and lead to type safety violations.\n+//!\n+//! Each `RESTRICTION` is a pair of a restrictive lvalue `LV` (which will\n+//! either be the path that was borrowed or some prefix of the path that\n+//! was borrowed) and a set of restricted actions.  There are three kinds\n+//! of actions that may be restricted for the path `LV`:\n+//!\n+//! - `MUTATE` means that `LV` cannot be assigned to;\n+//! - `CLAIM` means that the `LV` cannot be borrowed mutably;\n+//! - `FREEZE` means that the `LV` cannot be borrowed immutably;\n+//!\n+//! Finally, it is never possible to move from an lvalue that appears in a\n+//! restriction. This implies that the \"empty restriction\" `(LV, [])`,\n+//! which contains an empty set of actions, still has a purpose---it\n+//! prevents moves from `LV`. I chose not to make `MOVE` a fourth kind of\n+//! action because that would imply that sometimes moves are permitted\n+//! from restrictived values, which is not the case.\n+//!\n+//! #### Example\n+//!\n+//! To give you a better feeling for what kind of restrictions derived\n+//! from a loan, let's look at the loan `L` that would be issued as a\n+//! result of the borrow `&mut (*x).f` in the example above:\n+//!\n+//! ```text\n+//! L = ((*x).f, 'a, mut, RS) where\n+//!     RS = [((*x).f, [MUTATE, CLAIM, FREEZE]),\n+//!           (*x, [MUTATE, CLAIM, FREEZE]),\n+//!           (x, [MUTATE, CLAIM, FREEZE])]\n+//! ```\n+//!\n+//! The loan states that the expression `(*x).f` has been loaned as\n+//! mutable for the lifetime `'a`. Because the loan is mutable, that means\n+//! that the value `(*x).f` may be mutated via the newly created reference\n+//! (and *only* via that pointer). This is reflected in the\n+//! restrictions `RS` that accompany the loan.\n+//!\n+//! The first restriction `((*x).f, [MUTATE, CLAIM, FREEZE])` states that\n+//! the lender may not mutate, freeze, nor alias `(*x).f`. Mutation is\n+//! illegal because `(*x).f` is only supposed to be mutated via the new\n+//! reference, not by mutating the original path `(*x).f`. Freezing is\n+//! illegal because the path now has an `&mut` alias; so even if we the\n+//! lender were to consider `(*x).f` to be immutable, it might be mutated\n+//! via this alias. They will be enforced for the lifetime `'a` of the\n+//! loan. After the loan expires, the restrictions no longer apply.\n+//!\n+//! The second restriction on `*x` is interesting because it does not\n+//! apply to the path that was lent (`(*x).f`) but rather to a prefix of\n+//! the borrowed path. This is due to the rules of inherited mutability:\n+//! if the user were to assign to (or freeze) `*x`, they would indirectly\n+//! overwrite (or freeze) `(*x).f`, and thus invalidate the reference\n+//! that was created. In general it holds that when a path is\n+//! lent, restrictions are issued for all the owning prefixes of that\n+//! path. In this case, the path `*x` owns the path `(*x).f` and,\n+//! because `x` is an owned pointer, the path `x` owns the path `*x`.\n+//! Therefore, borrowing `(*x).f` yields restrictions on both\n+//! `*x` and `x`.\n+//!\n+//! ### Checking for illegal assignments, moves, and reborrows\n+//!\n+//! Once we have computed the loans introduced by each borrow, the borrow\n+//! checker uses a data flow propagation to compute the full set of loans\n+//! in scope at each expression and then uses that set to decide whether\n+//! that expression is legal.  Remember that the scope of loan is defined\n+//! by its lifetime LT.  We sometimes say that a loan which is in-scope at\n+//! a particular point is an \"outstanding loan\", and the set of\n+//! restrictions included in those loans as the \"outstanding\n+//! restrictions\".\n+//!\n+//! The kinds of expressions which in-scope loans can render illegal are:\n+//! - *assignments* (`lv = v`): illegal if there is an in-scope restriction\n+//!   against mutating `lv`;\n+//! - *moves*: illegal if there is any in-scope restriction on `lv` at all;\n+//! - *mutable borrows* (`&mut lv`): illegal there is an in-scope restriction\n+//!   against claiming `lv`;\n+//! - *immutable borrows* (`&lv`): illegal there is an in-scope restriction\n+//!   against freezing `lv`.\n+//!\n+//! ## Formal rules\n+//!\n+//! Now that we hopefully have some kind of intuitive feeling for how the\n+//! borrow checker works, let's look a bit more closely now at the precise\n+//! conditions that it uses. For simplicity I will ignore const loans.\n+//!\n+//! I will present the rules in a modified form of standard inference\n+//! rules, which looks as follows:\n+//!\n+//! ```text\n+//! PREDICATE(X, Y, Z)                  // Rule-Name\n+//!   Condition 1\n+//!   Condition 2\n+//!   Condition 3\n+//! ```\n+//!\n+//! The initial line states the predicate that is to be satisfied.  The\n+//! indented lines indicate the conditions that must be met for the\n+//! predicate to be satisfied. The right-justified comment states the name\n+//! of this rule: there are comments in the borrowck source referencing\n+//! these names, so that you can cross reference to find the actual code\n+//! that corresponds to the formal rule.\n+//!\n+//! ### Invariants\n+//!\n+//! I want to collect, at a high-level, the invariants the borrow checker\n+//! maintains. I will give them names and refer to them throughout the\n+//! text. Together these invariants are crucial for the overall soundness\n+//! of the system.\n+//!\n+//! **Mutability requires uniqueness.** To mutate a path\n+//!\n+//! **Unique mutability.** There is only one *usable* mutable path to any\n+//! given memory at any given time. This implies that when claiming memory\n+//! with an expression like `p = &mut x`, the compiler must guarantee that\n+//! the borrowed value `x` can no longer be mutated so long as `p` is\n+//! live. (This is done via restrictions, read on.)\n+//!\n+//! **.**\n+//!\n+//!\n+//! ### The `gather_loans` pass\n+//!\n+//! We start with the `gather_loans` pass, which walks the AST looking for\n+//! borrows.  For each borrow, there are three bits of information: the\n+//! lvalue `LV` being borrowed and the mutability `MQ` and lifetime `LT`\n+//! of the resulting pointer. Given those, `gather_loans` applies four\n+//! validity tests:\n+//!\n+//! 1. `MUTABILITY(LV, MQ)`: The mutability of the reference is\n+//! compatible with the mutability of `LV` (i.e., not borrowing immutable\n+//! data as mutable).\n+//!\n+//! 2. `ALIASABLE(LV, MQ)`: The aliasability of the reference is\n+//! compatible with the aliasability of `LV`. The goal is to prevent\n+//! `&mut` borrows of aliasability data.\n+//!\n+//! 3. `LIFETIME(LV, LT, MQ)`: The lifetime of the borrow does not exceed\n+//! the lifetime of the value being borrowed.\n+//!\n+//! 4. `RESTRICTIONS(LV, LT, ACTIONS) = RS`: This pass checks and computes the\n+//! restrictions to maintain memory safety. These are the restrictions\n+//! that will go into the final loan. We'll discuss in more detail below.\n+//!\n+//! ## Checking mutability\n+//!\n+//! Checking mutability is fairly straightforward. We just want to prevent\n+//! immutable data from being borrowed as mutable. Note that it is ok to\n+//! borrow mutable data as immutable, since that is simply a\n+//! freeze. Formally we define a predicate `MUTABLE(LV, MQ)` which, if\n+//! defined, means that \"borrowing `LV` with mutability `MQ` is ok. The\n+//! Rust code corresponding to this predicate is the function\n+//! `check_mutability` in `middle::borrowck::gather_loans`.\n+//!\n+//! ### Checking mutability of variables\n+//!\n+//! *Code pointer:* Function `check_mutability()` in `gather_loans/mod.rs`,\n+//! but also the code in `mem_categorization`.\n+//!\n+//! Let's begin with the rules for variables, which state that if a\n+//! variable is declared as mutable, it may be borrowed any which way, but\n+//! otherwise the variable must be borrowed as immutable or const:\n+//!\n+//! ```text\n+//! MUTABILITY(X, MQ)                   // M-Var-Mut\n+//!   DECL(X) = mut\n+//!\n+//! MUTABILITY(X, MQ)                   // M-Var-Imm\n+//!   DECL(X) = imm\n+//!   MQ = imm | const\n+//! ```\n+//!\n+//! ### Checking mutability of owned content\n+//!\n+//! Fields and owned pointers inherit their mutability from\n+//! their base expressions, so both of their rules basically\n+//! delegate the check to the base expression `LV`:\n+//!\n+//! ```text\n+//! MUTABILITY(LV.f, MQ)                // M-Field\n+//!   MUTABILITY(LV, MQ)\n+//!\n+//! MUTABILITY(*LV, MQ)                 // M-Deref-Unique\n+//!   TYPE(LV) = Box<Ty>\n+//!   MUTABILITY(LV, MQ)\n+//! ```\n+//!\n+//! ### Checking mutability of immutable pointer types\n+//!\n+//! Immutable pointer types like `&T` can only\n+//! be borrowed if MQ is immutable or const:\n+//!\n+//! ```text\n+//! MUTABILITY(*LV, MQ)                // M-Deref-Borrowed-Imm\n+//!   TYPE(LV) = &Ty\n+//!   MQ == imm | const\n+//! ```\n+//!\n+//! ### Checking mutability of mutable pointer types\n+//!\n+//! `&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n+//!\n+//! ```text\n+//! MUTABILITY(*LV, MQ)                 // M-Deref-Borrowed-Mut\n+//!   TYPE(LV) = &mut Ty\n+//! ```\n+//!\n+//! ## Checking aliasability\n+//!\n+//! The goal of the aliasability check is to ensure that we never permit\n+//! `&mut` borrows of aliasable data. Formally we define a predicate\n+//! `ALIASABLE(LV, MQ)` which if defined means that\n+//! \"borrowing `LV` with mutability `MQ` is ok\". The\n+//! Rust code corresponding to this predicate is the function\n+//! `check_aliasability()` in `middle::borrowck::gather_loans`.\n+//!\n+//! ### Checking aliasability of variables\n+//!\n+//! Local variables are never aliasable as they are accessible only within\n+//! the stack frame.\n+//!\n+//! ```text\n+//!     ALIASABLE(X, MQ)                   // M-Var-Mut\n+//! ```\n+//!\n+//! ### Checking aliasable of owned content\n+//!\n+//! Owned content is aliasable if it is found in an aliasable location:\n+//!\n+//! ```text\n+//! ALIASABLE(LV.f, MQ)                // M-Field\n+//!   ALIASABLE(LV, MQ)\n+//!\n+//! ALIASABLE(*LV, MQ)                 // M-Deref-Unique\n+//!   ALIASABLE(LV, MQ)\n+//! ```\n+//!\n+//! ### Checking mutability of immutable pointer types\n+//!\n+//! Immutable pointer types like `&T` are aliasable, and hence can only be\n+//! borrowed immutably:\n+//!\n+//! ```text\n+//! ALIASABLE(*LV, imm)                // M-Deref-Borrowed-Imm\n+//!   TYPE(LV) = &Ty\n+//! ```\n+//!\n+//! ### Checking mutability of mutable pointer types\n+//!\n+//! `&mut T` can be frozen, so it is acceptable to borrow it as either imm or mut:\n+//!\n+//! ```text\n+//! ALIASABLE(*LV, MQ)                 // M-Deref-Borrowed-Mut\n+//!   TYPE(LV) = &mut Ty\n+//! ```\n+//!\n+//! ## Checking lifetime\n+//!\n+//! These rules aim to ensure that no data is borrowed for a scope that exceeds\n+//! its lifetime. These two computations wind up being intimately related.\n+//! Formally, we define a predicate `LIFETIME(LV, LT, MQ)`, which states that\n+//! \"the lvalue `LV` can be safely borrowed for the lifetime `LT` with mutability\n+//! `MQ`\". The Rust code corresponding to this predicate is the module\n+//! `middle::borrowck::gather_loans::lifetime`.\n+//!\n+//! ### The Scope function\n+//!\n+//! Several of the rules refer to a helper function `SCOPE(LV)=LT`.  The\n+//! `SCOPE(LV)` yields the lifetime `LT` for which the lvalue `LV` is\n+//! guaranteed to exist, presuming that no mutations occur.\n+//!\n+//! The scope of a local variable is the block where it is declared:\n+//!\n+//! ```text\n+//!   SCOPE(X) = block where X is declared\n+//! ```\n+//!\n+//! The scope of a field is the scope of the struct:\n+//!\n+//! ```text\n+//!   SCOPE(LV.f) = SCOPE(LV)\n+//! ```\n+//!\n+//! The scope of a unique referent is the scope of the pointer, since\n+//! (barring mutation or moves) the pointer will not be freed until\n+//! the pointer itself `LV` goes out of scope:\n+//!\n+//! ```text\n+//!   SCOPE(*LV) = SCOPE(LV) if LV has type Box<T>\n+//! ```\n+//!\n+//! The scope of a borrowed referent is the scope associated with the\n+//! pointer.  This is a conservative approximation, since the data that\n+//! the pointer points at may actually live longer:\n+//!\n+//! ```text\n+//!   SCOPE(*LV) = LT if LV has type &'LT T or &'LT mut T\n+//! ```\n+//!\n+//! ### Checking lifetime of variables\n+//!\n+//! The rule for variables states that a variable can only be borrowed a\n+//! lifetime `LT` that is a subregion of the variable's scope:\n+//!\n+//! ```text\n+//! LIFETIME(X, LT, MQ)                 // L-Local\n+//!   LT <= SCOPE(X)\n+//! ```\n+//!\n+//! ### Checking lifetime for owned content\n+//!\n+//! The lifetime of a field or owned pointer is the same as the lifetime\n+//! of its owner:\n+//!\n+//! ```text\n+//! LIFETIME(LV.f, LT, MQ)              // L-Field\n+//!   LIFETIME(LV, LT, MQ)\n+//!\n+//! LIFETIME(*LV, LT, MQ)               // L-Deref-Send\n+//!   TYPE(LV) = Box<Ty>\n+//!   LIFETIME(LV, LT, MQ)\n+//! ```\n+//!\n+//! ### Checking lifetime for derefs of references\n+//!\n+//! References have a lifetime `LT'` associated with them.  The\n+//! data they point at has been guaranteed to be valid for at least this\n+//! lifetime. Therefore, the borrow is valid so long as the lifetime `LT`\n+//! of the borrow is shorter than the lifetime `LT'` of the pointer\n+//! itself:\n+//!\n+//! ```text\n+//! LIFETIME(*LV, LT, MQ)               // L-Deref-Borrowed\n+//!   TYPE(LV) = &LT' Ty OR &LT' mut Ty\n+//!   LT <= LT'\n+//! ```\n+//!\n+//! ## Computing the restrictions\n+//!\n+//! The final rules govern the computation of *restrictions*, meaning that\n+//! we compute the set of actions that will be illegal for the life of the\n+//! loan. The predicate is written `RESTRICTIONS(LV, LT, ACTIONS) =\n+//! RESTRICTION*`, which can be read \"in order to prevent `ACTIONS` from\n+//! occurring on `LV`, the restrictions `RESTRICTION*` must be respected\n+//! for the lifetime of the loan\".\n+//!\n+//! Note that there is an initial set of restrictions: these restrictions\n+//! are computed based on the kind of borrow:\n+//!\n+//! ```text\n+//! &mut LV =>   RESTRICTIONS(LV, LT, MUTATE|CLAIM|FREEZE)\n+//! &LV =>       RESTRICTIONS(LV, LT, MUTATE|CLAIM)\n+//! &const LV => RESTRICTIONS(LV, LT, [])\n+//! ```\n+//!\n+//! The reasoning here is that a mutable borrow must be the only writer,\n+//! therefore it prevents other writes (`MUTATE`), mutable borrows\n+//! (`CLAIM`), and immutable borrows (`FREEZE`). An immutable borrow\n+//! permits other immutable borrows but forbids writes and mutable borrows.\n+//! Finally, a const borrow just wants to be sure that the value is not\n+//! moved out from under it, so no actions are forbidden.\n+//!\n+//! ### Restrictions for loans of a local variable\n+//!\n+//! The simplest case is a borrow of a local variable `X`:\n+//!\n+//! ```text\n+//! RESTRICTIONS(X, LT, ACTIONS) = (X, ACTIONS)            // R-Variable\n+//! ```\n+//!\n+//! In such cases we just record the actions that are not permitted.\n+//!\n+//! ### Restrictions for loans of fields\n+//!\n+//! Restricting a field is the same as restricting the owner of that\n+//! field:\n+//!\n+//! ```text\n+//! RESTRICTIONS(LV.f, LT, ACTIONS) = RS, (LV.f, ACTIONS)  // R-Field\n+//!   RESTRICTIONS(LV, LT, ACTIONS) = RS\n+//! ```\n+//!\n+//! The reasoning here is as follows. If the field must not be mutated,\n+//! then you must not mutate the owner of the field either, since that\n+//! would indirectly modify the field. Similarly, if the field cannot be\n+//! frozen or aliased, we cannot allow the owner to be frozen or aliased,\n+//! since doing so indirectly freezes/aliases the field. This is the\n+//! origin of inherited mutability.\n+//!\n+//! ### Restrictions for loans of owned referents\n+//!\n+//! Because the mutability of owned referents is inherited, restricting an\n+//! owned referent is similar to restricting a field, in that it implies\n+//! restrictions on the pointer. However, owned pointers have an important\n+//! twist: if the owner `LV` is mutated, that causes the owned referent\n+//! `*LV` to be freed! So whenever an owned referent `*LV` is borrowed, we\n+//! must prevent the owned pointer `LV` from being mutated, which means\n+//! that we always add `MUTATE` and `CLAIM` to the restriction set imposed\n+//! on `LV`:\n+//!\n+//! ```text\n+//! RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Send-Pointer\n+//!   TYPE(LV) = Box<Ty>\n+//!   RESTRICTIONS(LV, LT, ACTIONS|MUTATE|CLAIM) = RS\n+//! ```\n+//!\n+//! ### Restrictions for loans of immutable borrowed referents\n+//!\n+//! Immutable borrowed referents are freely aliasable, meaning that\n+//! the compiler does not prevent you from copying the pointer.  This\n+//! implies that issuing restrictions is useless. We might prevent the\n+//! user from acting on `*LV` itself, but there could be another path\n+//! `*LV1` that refers to the exact same memory, and we would not be\n+//! restricting that path. Therefore, the rule for `&Ty` pointers\n+//! always returns an empty set of restrictions, and it only permits\n+//! restricting `MUTATE` and `CLAIM` actions:\n+//!\n+//! ```text\n+//! RESTRICTIONS(*LV, LT, ACTIONS) = []                    // R-Deref-Imm-Borrowed\n+//!   TYPE(LV) = &LT' Ty\n+//!   LT <= LT'                                            // (1)\n+//!   ACTIONS subset of [MUTATE, CLAIM]\n+//! ```\n+//!\n+//! The reason that we can restrict `MUTATE` and `CLAIM` actions even\n+//! without a restrictions list is that it is never legal to mutate nor to\n+//! borrow mutably the contents of a `&Ty` pointer. In other words,\n+//! those restrictions are already inherent in the type.\n+//!\n+//! Clause (1) in the rule for `&Ty` deserves mention. Here I\n+//! specify that the lifetime of the loan must be less than the lifetime\n+//! of the `&Ty` pointer. In simple cases, this clause is redundant, since\n+//! the `LIFETIME()` function will already enforce the required rule:\n+//!\n+//! ```\n+//! fn foo(point: &'a Point) -> &'static f32 {\n+//!     &point.x // Error\n+//! }\n+//! ```\n+//!\n+//! The above example fails to compile both because of clause (1) above\n+//! but also by the basic `LIFETIME()` check. However, in more advanced\n+//! examples involving multiple nested pointers, clause (1) is needed:\n+//!\n+//! ```\n+//! fn foo(point: &'a &'b mut Point) -> &'b f32 {\n+//!     &point.x // Error\n+//! }\n+//! ```\n+//!\n+//! The `LIFETIME` rule here would accept `'b` because, in fact, the\n+//! *memory is* guaranteed to remain valid (i.e., not be freed) for the\n+//! lifetime `'b`, since the `&mut` pointer is valid for `'b`. However, we\n+//! are returning an immutable reference, so we need the memory to be both\n+//! valid and immutable. Even though `point.x` is referenced by an `&mut`\n+//! pointer, it can still be considered immutable so long as that `&mut`\n+//! pointer is found in an aliased location. That means the memory is\n+//! guaranteed to be *immutable* for the lifetime of the `&` pointer,\n+//! which is only `'a`, not `'b`. Hence this example yields an error.\n+//!\n+//! As a final twist, consider the case of two nested *immutable*\n+//! pointers, rather than a mutable pointer within an immutable one:\n+//!\n+//! ```\n+//! fn foo(point: &'a &'b Point) -> &'b f32 {\n+//!     &point.x // OK\n+//! }\n+//! ```\n+//!\n+//! This function is legal. The reason for this is that the inner pointer\n+//! (`*point : &'b Point`) is enough to guarantee the memory is immutable\n+//! and valid for the lifetime `'b`.  This is reflected in\n+//! `RESTRICTIONS()` by the fact that we do not recurse (i.e., we impose\n+//! no restrictions on `LV`, which in this particular case is the pointer\n+//! `point : &'a &'b Point`).\n+//!\n+//! #### Why both `LIFETIME()` and `RESTRICTIONS()`?\n+//!\n+//! Given the previous text, it might seem that `LIFETIME` and\n+//! `RESTRICTIONS` should be folded together into one check, but there is\n+//! a reason that they are separated. They answer separate concerns.\n+//! The rules pertaining to `LIFETIME` exist to ensure that we don't\n+//! create a borrowed pointer that outlives the memory it points at. So\n+//! `LIFETIME` prevents a function like this:\n+//!\n+//! ```\n+//! fn get_1<'a>() -> &'a int {\n+//!     let x = 1;\n+//!     &x\n+//! }\n+//! ```\n+//!\n+//! Here we would be returning a pointer into the stack. Clearly bad.\n+//!\n+//! However, the `RESTRICTIONS` rules are more concerned with how memory\n+//! is used. The example above doesn't generate an error according to\n+//! `RESTRICTIONS` because, for local variables, we don't require that the\n+//! loan lifetime be a subset of the local variable lifetime. The idea\n+//! here is that we *can* guarantee that `x` is not (e.g.) mutated for the\n+//! lifetime `'a`, even though `'a` exceeds the function body and thus\n+//! involves unknown code in the caller -- after all, `x` ceases to exist\n+//! after we return and hence the remaining code in `'a` cannot possibly\n+//! mutate it. This distinction is important for type checking functions\n+//! like this one:\n+//!\n+//! ```\n+//! fn inc_and_get<'a>(p: &'a mut Point) -> &'a int {\n+//!     p.x += 1;\n+//!     &p.x\n+//! }\n+//! ```\n+//!\n+//! In this case, we take in a `&mut` and return a frozen borrowed pointer\n+//! with the same lifetime. So long as the lifetime of the returned value\n+//! doesn't exceed the lifetime of the `&mut` we receive as input, this is\n+//! fine, though it may seem surprising at first (it surprised me when I\n+//! first worked it through). After all, we're guaranteeing that `*p`\n+//! won't be mutated for the lifetime `'a`, even though we can't \"see\" the\n+//! entirety of the code during that lifetime, since some of it occurs in\n+//! our caller. But we *do* know that nobody can mutate `*p` except\n+//! through `p`. So if we don't mutate `*p` and we don't return `p`, then\n+//! we know that the right to mutate `*p` has been lost to our caller --\n+//! in terms of capability, the caller passed in the ability to mutate\n+//! `*p`, and we never gave it back. (Note that we can't return `p` while\n+//! `*p` is borrowed since that would be a move of `p`, as `&mut` pointers\n+//! are affine.)\n+//!\n+//! ### Restrictions for loans of const aliasable referents\n+//!\n+//! Freeze pointers are read-only. There may be `&mut` or `&` aliases, and\n+//! we can not prevent *anything* but moves in that case. So the\n+//! `RESTRICTIONS` function is only defined if `ACTIONS` is the empty set.\n+//! Because moves from a `&const` lvalue are never legal, it is not\n+//! necessary to add any restrictions at all to the final result.\n+//!\n+//! ```text\n+//!     RESTRICTIONS(*LV, LT, []) = []                         // R-Deref-Freeze-Borrowed\n+//!       TYPE(LV) = &const Ty\n+//! ```\n+//!\n+//! ### Restrictions for loans of mutable borrowed referents\n+//!\n+//! Mutable borrowed pointers are guaranteed to be the only way to mutate\n+//! their referent. This permits us to take greater license with them; for\n+//! example, the referent can be frozen simply be ensuring that we do not\n+//! use the original pointer to perform mutate. Similarly, we can allow\n+//! the referent to be claimed, so long as the original pointer is unused\n+//! while the new claimant is live.\n+//!\n+//! The rule for mutable borrowed pointers is as follows:\n+//!\n+//! ```text\n+//! RESTRICTIONS(*LV, LT, ACTIONS) = RS, (*LV, ACTIONS)    // R-Deref-Mut-Borrowed\n+//!   TYPE(LV) = &LT' mut Ty\n+//!   LT <= LT'                                            // (1)\n+//!   RESTRICTIONS(LV, LT, ACTIONS) = RS                   // (2)\n+//! ```\n+//!\n+//! Let's examine the two numbered clauses:\n+//!\n+//! Clause (1) specifies that the lifetime of the loan (`LT`) cannot\n+//! exceed the lifetime of the `&mut` pointer (`LT'`). The reason for this\n+//! is that the `&mut` pointer is guaranteed to be the only legal way to\n+//! mutate its referent -- but only for the lifetime `LT'`.  After that\n+//! lifetime, the loan on the referent expires and hence the data may be\n+//! modified by its owner again. This implies that we are only able to\n+//! guarantee that the referent will not be modified or aliased for a\n+//! maximum of `LT'`.\n+//!\n+//! Here is a concrete example of a bug this rule prevents:\n+//!\n+//! ```\n+//! // Test region-reborrow-from-shorter-mut-ref.rs:\n+//! fn copy_pointer<'a,'b,T>(x: &'a mut &'b mut T) -> &'b mut T {\n+//!     &mut **p // ERROR due to clause (1)\n+//! }\n+//! fn main() {\n+//!     let mut x = 1;\n+//!     let mut y = &mut x; // <-'b-----------------------------+\n+//!     //      +-'a--------------------+                       |\n+//!     //      v                       v                       |\n+//!     let z = copy_borrowed_ptr(&mut y); // y is lent         |\n+//!     *y += 1; // Here y==z, so both should not be usable...  |\n+//!     *z += 1; // ...and yet they would be, but for clause 1. |\n+//! } // <------------------------------------------------------+\n+//! ```\n+//!\n+//! Clause (2) propagates the restrictions on the referent to the pointer\n+//! itself. This is the same as with an owned pointer, though the\n+//! reasoning is mildly different. The basic goal in all cases is to\n+//! prevent the user from establishing another route to the same data. To\n+//! see what I mean, let's examine various cases of what can go wrong and\n+//! show how it is prevented.\n+//!\n+//! **Example danger 1: Moving the base pointer.** One of the simplest\n+//! ways to violate the rules is to move the base pointer to a new name\n+//! and access it via that new name, thus bypassing the restrictions on\n+//! the old name. Here is an example:\n+//!\n+//! ```\n+//! // src/test/compile-fail/borrowck-move-mut-base-ptr.rs\n+//! fn foo(t0: &mut int) {\n+//!     let p: &int = &*t0; // Freezes `*t0`\n+//!     let t1 = t0;        //~ ERROR cannot move out of `t0`\n+//!     *t1 = 22;           // OK, not a write through `*t0`\n+//! }\n+//! ```\n+//!\n+//! Remember that `&mut` pointers are linear, and hence `let t1 = t0` is a\n+//! move of `t0` -- or would be, if it were legal. Instead, we get an\n+//! error, because clause (2) imposes restrictions on `LV` (`t0`, here),\n+//! and any restrictions on a path make it impossible to move from that\n+//! path.\n+//!\n+//! **Example danger 2: Claiming the base pointer.** Another possible\n+//! danger is to mutably borrow the base path. This can lead to two bad\n+//! scenarios. The most obvious is that the mutable borrow itself becomes\n+//! another path to access the same data, as shown here:\n+//!\n+//! ```\n+//! // src/test/compile-fail/borrowck-mut-borrow-of-mut-base-ptr.rs\n+//! fn foo<'a>(mut t0: &'a mut int,\n+//!            mut t1: &'a mut int) {\n+//!     let p: &int = &*t0;     // Freezes `*t0`\n+//!     let mut t2 = &mut t0;   //~ ERROR cannot borrow `t0`\n+//!     **t2 += 1;              // Mutates `*t0`\n+//! }\n+//! ```\n+//!\n+//! In this example, `**t2` is the same memory as `*t0`. Because `t2` is\n+//! an `&mut` pointer, `**t2` is a unique path and hence it would be\n+//! possible to mutate `**t2` even though that memory was supposed to be\n+//! frozen by the creation of `p`. However, an error is reported -- the\n+//! reason is that the freeze `&*t0` will restrict claims and mutation\n+//! against `*t0` which, by clause 2, in turn prevents claims and mutation\n+//! of `t0`. Hence the claim `&mut t0` is illegal.\n+//!\n+//! Another danger with an `&mut` pointer is that we could swap the `t0`\n+//! value away to create a new path:\n+//!\n+//! ```\n+//! // src/test/compile-fail/borrowck-swap-mut-base-ptr.rs\n+//! fn foo<'a>(mut t0: &'a mut int,\n+//!            mut t1: &'a mut int) {\n+//!     let p: &int = &*t0;     // Freezes `*t0`\n+//!     swap(&mut t0, &mut t1); //~ ERROR cannot borrow `t0`\n+//!     *t1 = 22;\n+//! }\n+//! ```\n+//!\n+//! This is illegal for the same reason as above. Note that if we added\n+//! back a swap operator -- as we used to have -- we would want to be very\n+//! careful to ensure this example is still illegal.\n+//!\n+//! **Example danger 3: Freeze the base pointer.** In the case where the\n+//! referent is claimed, even freezing the base pointer can be dangerous,\n+//! as shown in the following example:\n+//!\n+//! ```\n+//! // src/test/compile-fail/borrowck-borrow-of-mut-base-ptr.rs\n+//! fn foo<'a>(mut t0: &'a mut int,\n+//!            mut t1: &'a mut int) {\n+//!     let p: &mut int = &mut *t0; // Claims `*t0`\n+//!     let mut t2 = &t0;           //~ ERROR cannot borrow `t0`\n+//!     let q: &int = &*t2;         // Freezes `*t0` but not through `*p`\n+//!     *p += 1;                    // violates type of `*q`\n+//! }\n+//! ```\n+//!\n+//! Here the problem is that `*t0` is claimed by `p`, and hence `p` wants\n+//! to be the controlling pointer through which mutation or freezes occur.\n+//! But `t2` would -- if it were legal -- have the type `& &mut int`, and\n+//! hence would be a mutable pointer in an aliasable location, which is\n+//! considered frozen (since no one can write to `**t2` as it is not a\n+//! unique path). Therefore, we could reasonably create a frozen `&int`\n+//! pointer pointing at `*t0` that coexists with the mutable pointer `p`,\n+//! which is clearly unsound.\n+//!\n+//! However, it is not always unsafe to freeze the base pointer. In\n+//! particular, if the referent is frozen, there is no harm in it:\n+//!\n+//! ```\n+//! // src/test/run-pass/borrowck-borrow-of-mut-base-ptr-safe.rs\n+//! fn foo<'a>(mut t0: &'a mut int,\n+//!            mut t1: &'a mut int) {\n+//!     let p: &int = &*t0; // Freezes `*t0`\n+//!     let mut t2 = &t0;\n+//!     let q: &int = &*t2; // Freezes `*t0`, but that's ok...\n+//!     let r: &int = &*t0; // ...after all, could do same thing directly.\n+//! }\n+//! ```\n+//!\n+//! In this case, creating the alias `t2` of `t0` is safe because the only\n+//! thing `t2` can be used for is to further freeze `*t0`, which is\n+//! already frozen. In particular, we cannot assign to `*t0` through the\n+//! new alias `t2`, as demonstrated in this test case:\n+//!\n+//! ```\n+//! // src/test/run-pass/borrowck-borrow-mut-base-ptr-in-aliasable-loc.rs\n+//! fn foo(t0: & &mut int) {\n+//!     let t1 = t0;\n+//!     let p: &int = &**t0;\n+//!     **t1 = 22; //~ ERROR cannot assign\n+//! }\n+//! ```\n+//!\n+//! This distinction is reflected in the rules. When doing an `&mut`\n+//! borrow -- as in the first example -- the set `ACTIONS` will be\n+//! `CLAIM|MUTATE|FREEZE`, because claiming the referent implies that it\n+//! cannot be claimed, mutated, or frozen by anyone else. These\n+//! restrictions are propagated back to the base path and hence the base\n+//! path is considered unfreezable.\n+//!\n+//! In contrast, when the referent is merely frozen -- as in the second\n+//! example -- the set `ACTIONS` will be `CLAIM|MUTATE`, because freezing\n+//! the referent implies that it cannot be claimed or mutated but permits\n+//! others to freeze. Hence when these restrictions are propagated back to\n+//! the base path, it will still be considered freezable.\n+//!\n+//!\n+//!\n+//! **FIXME #10520: Restrictions against mutating the base pointer.** When\n+//! an `&mut` pointer is frozen or claimed, we currently pass along the\n+//! restriction against MUTATE to the base pointer. I do not believe this\n+//! restriction is needed. It dates from the days when we had a way to\n+//! mutate that preserved the value being mutated (i.e., swap). Nowadays\n+//! the only form of mutation is assignment, which destroys the pointer\n+//! being mutated -- therefore, a mutation cannot create a new path to the\n+//! same data. Rather, it removes an existing path. This implies that not\n+//! only can we permit mutation, we can have mutation kill restrictions in\n+//! the dataflow sense.\n+//!\n+//! **WARNING:** We do not currently have `const` borrows in the\n+//! language. If they are added back in, we must ensure that they are\n+//! consistent with all of these examples. The crucial question will be\n+//! what sorts of actions are permitted with a `&const &mut` pointer. I\n+//! would suggest that an `&mut` referent found in an `&const` location be\n+//! prohibited from both freezes and claims. This would avoid the need to\n+//! prevent `const` borrows of the base pointer when the referent is\n+//! borrowed.\n+//!\n+//! # Moves and initialization\n+//!\n+//! The borrow checker is also in charge of ensuring that:\n+//!\n+//! - all memory which is accessed is initialized\n+//! - immutable local variables are assigned at most once.\n+//!\n+//! These are two separate dataflow analyses built on the same\n+//! framework. Let's look at checking that memory is initialized first;\n+//! the checking of immutable local variable assignments works in a very\n+//! similar way.\n+//!\n+//! To track the initialization of memory, we actually track all the\n+//! points in the program that *create uninitialized memory*, meaning\n+//! moves and the declaration of uninitialized variables. For each of\n+//! these points, we create a bit in the dataflow set. Assignments to a\n+//! variable `x` or path `a.b.c` kill the move/uninitialization bits for\n+//! those paths and any subpaths (e.g., `x`, `x.y`, `a.b.c`, `*a.b.c`).\n+//! Bits are unioned when two control-flow paths join. Thus, the\n+//! presence of a bit indicates that the move may have occurred without an\n+//! intervening assignment to the same memory. At each use of a variable,\n+//! we examine the bits in scope, and check that none of them are\n+//! moves/uninitializations of the variable that is being used.\n+//!\n+//! Let's look at a simple example:\n+//!\n+//! ```\n+//! fn foo(a: Box<int>) {\n+//!     let b: Box<int>;   // Gen bit 0.\n+//!\n+//!     if cond {          // Bits: 0\n+//!         use(&*a);\n+//!         b = a;         // Gen bit 1, kill bit 0.\n+//!         use(&*b);\n+//!     } else {\n+//!                        // Bits: 0\n+//!     }\n+//!                        // Bits: 0,1\n+//!     use(&*a);          // Error.\n+//!     use(&*b);          // Error.\n+//! }\n+//!\n+//! fn use(a: &int) { }\n+//! ```\n+//!\n+//! In this example, the variable `b` is created uninitialized. In one\n+//! branch of an `if`, we then move the variable `a` into `b`. Once we\n+//! exit the `if`, therefore, it is an error to use `a` or `b` since both\n+//! are only conditionally initialized. I have annotated the dataflow\n+//! state using comments. There are two dataflow bits, with bit 0\n+//! corresponding to the creation of `b` without an initializer, and bit 1\n+//! corresponding to the move of `a`. The assignment `b = a` both\n+//! generates bit 1, because it is a move of `a`, and kills bit 0, because\n+//! `b` is now initialized. On the else branch, though, `b` is never\n+//! initialized, and so bit 0 remains untouched. When the two flows of\n+//! control join, we union the bits from both sides, resulting in both\n+//! bits 0 and 1 being set. Thus any attempt to use `a` uncovers the bit 1\n+//! from the \"then\" branch, showing that `a` may be moved, and any attempt\n+//! to use `b` uncovers bit 0, from the \"else\" branch, showing that `b`\n+//! may not be initialized.\n+//!\n+//! ## Initialization of immutable variables\n+//!\n+//! Initialization of immutable variables works in a very similar way,\n+//! except that:\n+//!\n+//! 1. we generate bits for each assignment to a variable;\n+//! 2. the bits are never killed except when the variable goes out of scope.\n+//!\n+//! Thus the presence of an assignment bit indicates that the assignment\n+//! may have occurred. Note that assignments are only killed when the\n+//! variable goes out of scope, as it is not relevant whether or not there\n+//! has been a move in the meantime. Using these bits, we can declare that\n+//! an assignment to an immutable variable is legal iff there is no other\n+//! assignment bit to that same variable in scope.\n+//!\n+//! ## Why is the design made this way?\n+//!\n+//! It may seem surprising that we assign dataflow bits to *each move*\n+//! rather than *each path being moved*. This is somewhat less efficient,\n+//! since on each use, we must iterate through all moves and check whether\n+//! any of them correspond to the path in question. Similar concerns apply\n+//! to the analysis for double assignments to immutable variables. The\n+//! main reason to do it this way is that it allows us to print better\n+//! error messages, because when a use occurs, we can print out the\n+//! precise move that may be in scope, rather than simply having to say\n+//! \"the variable may not be initialized\".\n+//!\n+//! ## Data structures used in the move analysis\n+//!\n+//! The move analysis maintains several data structures that enable it to\n+//! cross-reference moves and assignments to determine when they may be\n+//! moving/assigning the same memory. These are all collected into the\n+//! `MoveData` and `FlowedMoveData` structs. The former represents the set\n+//! of move paths, moves, and assignments, and the latter adds in the\n+//! results of a dataflow computation.\n+//!\n+//! ### Move paths\n+//!\n+//! The `MovePath` tree tracks every path that is moved or assigned to.\n+//! These paths have the same form as the `LoanPath` data structure, which\n+//! in turn is the \"real world version of the lvalues `LV` that we\n+//! introduced earlier. The difference between a `MovePath` and a `LoanPath`\n+//! is that move paths are:\n+//!\n+//! 1. Canonicalized, so that we have exactly one copy of each, and\n+//!    we can refer to move paths by index;\n+//! 2. Cross-referenced with other paths into a tree, so that given a move\n+//!    path we can efficiently find all parent move paths and all\n+//!    extensions (e.g., given the `a.b` move path, we can easily find the\n+//!    move path `a` and also the move paths `a.b.c`)\n+//! 3. Cross-referenced with moves and assignments, so that we can\n+//!    easily find all moves and assignments to a given path.\n+//!\n+//! The mechanism that we use is to create a `MovePath` record for each\n+//! move path. These are arranged in an array and are referenced using\n+//! `MovePathIndex` values, which are newtype'd indices. The `MovePath`\n+//! structs are arranged into a tree, representing using the standard\n+//! Knuth representation where each node has a child 'pointer' and a \"next\n+//! sibling\" 'pointer'. In addition, each `MovePath` has a parent\n+//! 'pointer'.  In this case, the 'pointers' are just `MovePathIndex`\n+//! values.\n+//!\n+//! In this way, if we want to find all base paths of a given move path,\n+//! we can just iterate up the parent pointers (see `each_base_path()` in\n+//! the `move_data` module). If we want to find all extensions, we can\n+//! iterate through the subtree (see `each_extending_path()`).\n+//!\n+//! ### Moves and assignments\n+//!\n+//! There are structs to represent moves (`Move`) and assignments\n+//! (`Assignment`), and these are also placed into arrays and referenced\n+//! by index. All moves of a particular path are arranged into a linked\n+//! lists, beginning with `MovePath.first_move` and continuing through\n+//! `Move.next_move`.\n+//!\n+//! We distinguish between \"var\" assignments, which are assignments to a\n+//! variable like `x = foo`, and \"path\" assignments (`x.f = foo`).  This\n+//! is because we need to assign dataflows to the former, but not the\n+//! latter, so as to check for double initialization of immutable\n+//! variables.\n+//!\n+//! ### Gathering and checking moves\n+//!\n+//! Like loans, we distinguish two phases. The first, gathering, is where\n+//! we uncover all the moves and assignments. As with loans, we do some\n+//! basic sanity checking in this phase, so we'll report errors if you\n+//! attempt to move out of a borrowed pointer etc. Then we do the dataflow\n+//! (see `FlowedMoveData::new`). Finally, in the `check_loans.rs` code, we\n+//! walk back over, identify all uses, assignments, and captures, and\n+//! check that they are legal given the set of dataflow bits we have\n+//! computed for that program point.\n+//!\n+//! # Drop flags and structural fragments\n+//!\n+//! In addition to the job of enforcing memory safety, the borrow checker\n+//! code is also responsible for identifying the *structural fragments* of\n+//! data in the function, to support out-of-band dynamic drop flags\n+//! allocated on the stack. (For background, see [RFC PR #320].)\n+//!\n+//! [RFC PR #320]: https://github.com/rust-lang/rfcs/pull/320\n+//!\n+//! Semantically, each piece of data that has a destructor may need a\n+//! boolean flag to indicate whether or not its destructor has been run\n+//! yet. However, in many cases there is no need to actually maintain such\n+//! a flag: It can be apparent from the code itself that a given path is\n+//! always initialized (or always deinitialized) when control reaches the\n+//! end of its owner's scope, and thus we can unconditionally emit (or\n+//! not) the destructor invocation for that path.\n+//!\n+//! A simple example of this is the following:\n+//!\n+//! ```rust\n+//! struct D { p: int }\n+//! impl D { fn new(x: int) -> D { ... }\n+//! impl Drop for D { ... }\n+//!\n+//! fn foo(a: D, b: D, t: || -> bool) {\n+//!     let c: D;\n+//!     let d: D;\n+//!     if t() { c = b; }\n+//! }\n+//! ```\n+//!\n+//! At the end of the body of `foo`, the compiler knows that `a` is\n+//! initialized, introducing a drop obligation (deallocating the boxed\n+//! integer) for the end of `a`'s scope that is run unconditionally.\n+//! Likewise the compiler knows that `d` is not initialized, and thus it\n+//! leave out the drop code for `d`.\n+//!\n+//! The compiler cannot statically know the drop-state of `b` nor `c` at\n+//! the end of their scope, since that depends on the value of\n+//! `t`. Therefore, we need to insert boolean flags to track whether we\n+//! need to drop `b` and `c`.\n+//!\n+//! However, the matter is not as simple as just mapping local variables\n+//! to their corresponding drop flags when necessary. In particular, in\n+//! addition to being able to move data out of local variables, Rust\n+//! allows one to move values in and out of structured data.\n+//!\n+//! Consider the following:\n+//!\n+//! ```rust\n+//! struct S { x: D, y: D, z: D }\n+//!\n+//! fn foo(a: S, mut b: S, t: || -> bool) {\n+//!     let mut c: S;\n+//!     let d: S;\n+//!     let e: S = a.clone();\n+//!     if t() {\n+//!         c = b;\n+//!         b.x = e.y;\n+//!     }\n+//!     if t() { c.y = D::new(4); }\n+//! }\n+//! ```\n+//!\n+//! As before, the drop obligations of `a` and `d` can be statically\n+//! determined, and again the state of `b` and `c` depend on dynamic\n+//! state. But additionally, the dynamic drop obligations introduced by\n+//! `b` and `c` are not just per-local boolean flags. For example, if the\n+//! first call to `t` returns `false` and the second call `true`, then at\n+//! the end of their scope, `b` will be completely initialized, but only\n+//! `c.y` in `c` will be initialized.  If both calls to `t` return `true`,\n+//! then at the end of their scope, `c` will be completely initialized,\n+//! but only `b.x` will be initialized in `b`, and only `e.x` and `e.z`\n+//! will be initialized in `e`.\n+//!\n+//! Note that we need to cover the `z` field in each case in some way,\n+//! since it may (or may not) need to be dropped, even though `z` is never\n+//! directly mentioned in the body of the `foo` function. We call a path\n+//! like `b.z` a *fragment sibling* of `b.x`, since the field `z` comes\n+//! from the same structure `S` that declared the field `x` in `b.x`.\n+//!\n+//! In general we need to maintain boolean flags that match the\n+//! `S`-structure of both `b` and `c`.  In addition, we need to consult\n+//! such a flag when doing an assignment (such as `c.y = D::new(4);`\n+//! above), in order to know whether or not there is a previous value that\n+//! needs to be dropped before we do the assignment.\n+//!\n+//! So for any given function, we need to determine what flags are needed\n+//! to track its drop obligations. Our strategy for determining the set of\n+//! flags is to represent the fragmentation of the structure explicitly:\n+//! by starting initially from the paths that are explicitly mentioned in\n+//! moves and assignments (such as `b.x` and `c.y` above), and then\n+//! traversing the structure of the path's type to identify leftover\n+//! *unmoved fragments*: assigning into `c.y` means that `c.x` and `c.z`\n+//! are leftover unmoved fragments. Each fragment represents a drop\n+//! obligation that may need to be tracked. Paths that are only moved or\n+//! assigned in their entirety (like `a` and `d`) are treated as a single\n+//! drop obligation.\n+//!\n+//! The fragment construction process works by piggy-backing on the\n+//! existing `move_data` module. We already have callbacks that visit each\n+//! direct move and assignment; these form the basis for the sets of\n+//! moved_leaf_paths and assigned_leaf_paths. From these leaves, we can\n+//! walk up their parent chain to identify all of their parent paths.\n+//! We need to identify the parents because of cases like the following:\n+//!\n+//! ```rust\n+//! struct Pair<X,Y>{ x: X, y: Y }\n+//! fn foo(dd_d_d: Pair<Pair<Pair<D, D>, D>, D>) {\n+//!     other_function(dd_d_d.x.y);\n+//! }\n+//! ```\n+//!\n+//! In this code, the move of the path `dd_d.x.y` leaves behind not only\n+//! the fragment drop-obligation `dd_d.x.x` but also `dd_d.y` as well.\n+//!\n+//! Once we have identified the directly-referenced leaves and their\n+//! parents, we compute the left-over fragments, in the function\n+//! `fragments::add_fragment_siblings`. As of this writing this works by\n+//! looking at each directly-moved or assigned path P, and blindly\n+//! gathering all sibling fields of P (as well as siblings for the parents\n+//! of P, etc). After accumulating all such siblings, we filter out the\n+//! entries added as siblings of P that turned out to be\n+//! directly-referenced paths (or parents of directly referenced paths)\n+//! themselves, thus leaving the never-referenced \"left-overs\" as the only\n+//! thing left from the gathering step.\n+//!\n+//! ## Array structural fragments\n+//!\n+//! A special case of the structural fragments discussed above are\n+//! the elements of an array that has been passed by value, such as\n+//! the following:\n+//!\n+//! ```rust\n+//! fn foo(a: [D, ..10], i: uint) -> D {\n+//!     a[i]\n+//! }\n+//! ```\n+//!\n+//! The above code moves a single element out of the input array `a`.\n+//! The remainder of the array still needs to be dropped; i.e., it\n+//! is a structural fragment. Note that after performing such a move,\n+//! it is not legal to read from the array `a`. There are a number of\n+//! ways to deal with this, but the important thing to note is that\n+//! the semantics needs to distinguish in some manner between a\n+//! fragment that is the *entire* array versus a fragment that represents\n+//! all-but-one element of the array.  A place where that distinction\n+//! would arise is the following:\n+//!\n+//! ```rust\n+//! fn foo(a: [D, ..10], b: [D, ..10], i: uint, t: bool) -> D {\n+//!     if t {\n+//!         a[i]\n+//!     } else {\n+//!         b[i]\n+//!     }\n+//!\n+//!     // When control exits, we will need either to drop all of `a`\n+//!     // and all-but-one of `b`, or to drop all of `b` and all-but-one\n+//!     // of `a`.\n+//! }\n+//! ```\n+//!\n+//! There are a number of ways that the trans backend could choose to\n+//! compile this (e.g. a `[bool, ..10]` array for each such moved array;\n+//! or an `Option<uint>` for each moved array).  From the viewpoint of the\n+//! borrow-checker, the important thing is to record what kind of fragment\n+//! is implied by the relevant moves.\n+//!\n+//! # Future work\n+//!\n+//! While writing up these docs, I encountered some rules I believe to be\n+//! stricter than necessary:\n+//!\n+//! - I think restricting the `&mut` LV against moves and `ALIAS` is sufficient,\n+//!   `MUTATE` and `CLAIM` are overkill. `MUTATE` was necessary when swap was\n+//!   a built-in operator, but as it is not, it is implied by `CLAIM`,\n+//!   and `CLAIM` is implied by `ALIAS`. The only net effect of this is an\n+//!   extra error message in some cases, though.\n+//! - I have not described how closures interact. Current code is unsound.\n+//!   I am working on describing and implementing the fix.\n+//! - If we wish, we can easily extend the move checking to allow finer-grained\n+//!   tracking of what is initialized and what is not, enabling code like\n+//!   this:\n+//!\n+//!       a = x.f.g; // x.f.g is now uninitialized\n+//!       // here, x and x.f are not usable, but x.f.h *is*\n+//!       x.f.g = b; // x.f.g is not initialized\n+//!       // now x, x.f, x.f.g, x.f.h are all usable\n+//!\n+//!   What needs to change here, most likely, is that the `moves` module\n+//!   should record not only what paths are moved, but what expressions\n+//!   are actual *uses*. For example, the reference to `x` in `x.f.g = b`\n+//!   is not a true *use* in the sense that it requires `x` to be fully\n+//!   initialized. This is in fact why the above code produces an error\n+//!   today: the reference to `x` in `x.f.g = b` is considered illegal\n+//!   because `x` is not fully initialized.\n+//!\n+//! There are also some possible refactorings:\n+//!\n+//! - It might be nice to replace all loan paths with the MovePath mechanism,\n+//!   since they allow lightweight comparison using an integer."}, {"sha": "24273e49c73131579bbdfc62b4225c779ff548e0", "filename": "src/librustc/middle/borrowck/fragments.rs", "status": "modified", "additions": 17, "deletions": 34, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Ffragments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Ffragments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Ffragments.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,13 +8,10 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n+//! Helper routines used for fragmenting structural paths due to moves for\n+//! tracking drop obligations. Please see the extensive comments in the\n+//! section \"Structural fragments\" in `doc.rs`.\n \n-Helper routines used for fragmenting structural paths due to moves for\n-tracking drop obligations. Please see the extensive comments in the\n-section \"Structural fragments\" in `doc.rs`.\n-\n-*/\n use self::Fragment::*;\n \n use session::config;\n@@ -176,16 +173,12 @@ pub fn instrument_move_fragments<'tcx>(this: &MoveData<'tcx>,\n     instrument_all_paths(\"assigned_leaf_path\", &fragments.assigned_leaf_paths);\n }\n \n+/// Normalizes the fragment sets in `this`; i.e., removes duplicate entries, constructs the set of\n+/// parents, and constructs the left-over fragments.\n+///\n+/// Note: \"left-over fragments\" means paths that were not directly referenced in moves nor\n+/// assignments, but must nonetheless be tracked as potential drop obligations.\n pub fn fixup_fragment_sets<'tcx>(this: &MoveData<'tcx>, tcx: &ty::ctxt<'tcx>) {\n-    /*!\n-     * Normalizes the fragment sets in `this`; i.e., removes\n-     * duplicate entries, constructs the set of parents, and\n-     * constructs the left-over fragments.\n-     *\n-     * Note: \"left-over fragments\" means paths that were not\n-     * directly referenced in moves nor assignments, but must\n-     * nonetheless be tracked as potential drop obligations.\n-     */\n \n     let mut fragments = this.fragments.borrow_mut();\n \n@@ -277,24 +270,20 @@ pub fn fixup_fragment_sets<'tcx>(this: &MoveData<'tcx>, tcx: &ty::ctxt<'tcx>) {\n \n     fn non_member(elem: MovePathIndex, set: &[MovePathIndex]) -> bool {\n         match set.binary_search_elem(&elem) {\n-            slice::Found(_) => false,\n-            slice::NotFound(_) => true,\n+            slice::BinarySearchResult::Found(_) => false,\n+            slice::BinarySearchResult::NotFound(_) => true,\n         }\n     }\n }\n \n+/// Adds all of the precisely-tracked siblings of `lp` as potential move paths of interest. For\n+/// example, if `lp` represents `s.x.j`, then adds moves paths for `s.x.i` and `s.x.k`, the\n+/// siblings of `s.x.j`.\n fn add_fragment_siblings<'tcx>(this: &MoveData<'tcx>,\n                                tcx: &ty::ctxt<'tcx>,\n                                gathered_fragments: &mut Vec<Fragment>,\n                                lp: Rc<LoanPath<'tcx>>,\n                                origin_id: Option<ast::NodeId>) {\n-    /*!\n-     * Adds all of the precisely-tracked siblings of `lp` as\n-     * potential move paths of interest. For example, if `lp`\n-     * represents `s.x.j`, then adds moves paths for `s.x.i` and\n-     * `s.x.k`, the siblings of `s.x.j`.\n-     */\n-\n     match lp.kind {\n         LpVar(_) | LpUpvar(..) => {} // Local variables have no siblings.\n \n@@ -343,6 +332,8 @@ fn add_fragment_siblings<'tcx>(this: &MoveData<'tcx>,\n     }\n }\n \n+/// We have determined that `origin_lp` destructures to LpExtend(parent, original_field_name).\n+/// Based on this, add move paths for all of the siblings of `origin_lp`.\n fn add_fragment_siblings_for_extension<'tcx>(this: &MoveData<'tcx>,\n                                              tcx: &ty::ctxt<'tcx>,\n                                              gathered_fragments: &mut Vec<Fragment>,\n@@ -353,12 +344,6 @@ fn add_fragment_siblings_for_extension<'tcx>(this: &MoveData<'tcx>,\n                                              origin_id: Option<ast::NodeId>,\n                                              enum_variant_info: Option<(ast::DefId,\n                                                                         Rc<LoanPath<'tcx>>)>) {\n-    /*!\n-     * We have determined that `origin_lp` destructures to\n-     * LpExtend(parent, original_field_name). Based on this,\n-     * add move paths for all of the siblings of `origin_lp`.\n-     */\n-\n     let parent_ty = parent_lp.to_type();\n \n     let add_fragment_sibling_local = |field_name| {\n@@ -454,17 +439,15 @@ fn add_fragment_siblings_for_extension<'tcx>(this: &MoveData<'tcx>,\n     }\n }\n \n+/// Adds the single sibling `LpExtend(parent, new_field_name)` of `origin_lp` (the original\n+/// loan-path).\n fn add_fragment_sibling_core<'tcx>(this: &MoveData<'tcx>,\n                                    tcx: &ty::ctxt<'tcx>,\n                                    gathered_fragments: &mut Vec<Fragment>,\n                                    parent: Rc<LoanPath<'tcx>>,\n                                    mc: mc::MutabilityCategory,\n                                    new_field_name: mc::FieldName,\n                                    origin_lp: &Rc<LoanPath<'tcx>>) -> MovePathIndex {\n-    /*!\n-     * Adds the single sibling `LpExtend(parent, new_field_name)`\n-     * of `origin_lp` (the original loan-path).\n-     */\n     let opt_variant_did = match parent.kind {\n         LpDowncast(_, variant_did) => Some(variant_did),\n         LpVar(..) | LpUpvar(..) | LpExtend(..) => None,"}, {"sha": "651141605042782ff943c3bbfa8181264216276e", "filename": "src/librustc/middle/borrowck/gather_loans/gather_moves.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fgather_moves.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fgather_moves.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fgather_moves.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,9 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Computes moves.\n- */\n+//! Computes moves.\n \n use middle::borrowck::*;\n use middle::borrowck::LoanPathKind::*;"}, {"sha": "e6a7c150df8f41d82ae460e1ad8f447a12e33d86", "filename": "src/librustc/middle/borrowck/gather_loans/lifetime.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Flifetime.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Flifetime.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Flifetime.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * This module implements the check that the lifetime of a borrow\n- * does not exceed the lifetime of the value being borrowed.\n- */\n+//! This module implements the check that the lifetime of a borrow\n+//! does not exceed the lifetime of the value being borrowed.\n \n use middle::borrowck::*;\n use middle::expr_use_visitor as euv;"}, {"sha": "4f7ecc99c8938e22d54d6485e95d46efdbd3a533", "filename": "src/librustc/middle/borrowck/gather_loans/mod.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -225,19 +225,16 @@ fn check_aliasability<'a, 'tcx>(bccx: &BorrowckCtxt<'a, 'tcx>,\n impl<'a, 'tcx> GatherLoanCtxt<'a, 'tcx> {\n     pub fn tcx(&self) -> &'a ty::ctxt<'tcx> { self.bccx.tcx }\n \n+    /// Guarantees that `addr_of(cmt)` will be valid for the duration of `static_scope_r`, or\n+    /// reports an error.  This may entail taking out loans, which will be added to the\n+    /// `req_loan_map`.\n     fn guarantee_valid(&mut self,\n                        borrow_id: ast::NodeId,\n                        borrow_span: Span,\n                        cmt: mc::cmt<'tcx>,\n                        req_kind: ty::BorrowKind,\n                        loan_region: ty::Region,\n                        cause: euv::LoanCause) {\n-        /*!\n-         * Guarantees that `addr_of(cmt)` will be valid for the duration of\n-         * `static_scope_r`, or reports an error.  This may entail taking\n-         * out loans, which will be added to the `req_loan_map`.\n-         */\n-\n         debug!(\"guarantee_valid(borrow_id={}, cmt={}, \\\n                 req_mutbl={}, loan_region={})\",\n                borrow_id,"}, {"sha": "bd9cf8f84b6431a1913291628956d748a1d20514", "filename": "src/librustc/middle/borrowck/gather_loans/restrictions.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Frestrictions.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Frestrictions.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fgather_loans%2Frestrictions.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,9 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Computes the restrictions that result from a borrow.\n- */\n+//! Computes the restrictions that result from a borrow.\n \n pub use self::RestrictionResult::*;\n "}, {"sha": "0bbcdfe61bb46c86d5688ad0f81c0e16c177ecab", "filename": "src/librustc/middle/borrowck/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! See doc.rs for a thorough explanation of the borrow checker */\n+//! See doc.rs for a thorough explanation of the borrow checker\n \n #![allow(non_camel_case_types)]\n "}, {"sha": "7bf3458f0ae3da3613273ea5e9ca6afa1c791574", "filename": "src/librustc/middle/borrowck/move_data.rs", "status": "modified", "additions": 23, "deletions": 54, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmove_data.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmove_data.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fborrowck%2Fmove_data.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,12 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Data structures used for tracking moves. Please see the extensive\n-comments in the section \"Moves and initialization\" in `doc.rs`.\n-\n-*/\n+//! Data structures used for tracking moves. Please see the extensive\n+//! comments in the section \"Moves and initialization\" in `doc.rs`.\n \n pub use self::MoveKind::*;\n \n@@ -297,15 +293,11 @@ impl<'tcx> MoveData<'tcx> {\n         self.path_parent(index) == InvalidMovePathIndex\n     }\n \n+    /// Returns the existing move path index for `lp`, if any, and otherwise adds a new index for\n+    /// `lp` and any of its base paths that do not yet have an index.\n     pub fn move_path(&self,\n                      tcx: &ty::ctxt<'tcx>,\n                      lp: Rc<LoanPath<'tcx>>) -> MovePathIndex {\n-        /*!\n-         * Returns the existing move path index for `lp`, if any,\n-         * and otherwise adds a new index for `lp` and any of its\n-         * base paths that do not yet have an index.\n-         */\n-\n         match self.path_map.borrow().get(&lp) {\n             Some(&index) => {\n                 return index;\n@@ -370,13 +362,10 @@ impl<'tcx> MoveData<'tcx> {\n         result\n     }\n \n+    /// Adds any existing move path indices for `lp` and any base paths of `lp` to `result`, but\n+    /// does not add new move paths\n     fn add_existing_base_paths(&self, lp: &Rc<LoanPath<'tcx>>,\n                                result: &mut Vec<MovePathIndex>) {\n-        /*!\n-         * Adds any existing move path indices for `lp` and any base\n-         * paths of `lp` to `result`, but does not add new move paths\n-         */\n-\n         match self.path_map.borrow().get(lp).cloned() {\n             Some(index) => {\n                 self.each_base_path(index, |p| {\n@@ -397,16 +386,12 @@ impl<'tcx> MoveData<'tcx> {\n \n     }\n \n+    /// Adds a new move entry for a move of `lp` that occurs at location `id` with kind `kind`.\n     pub fn add_move(&self,\n                     tcx: &ty::ctxt<'tcx>,\n                     lp: Rc<LoanPath<'tcx>>,\n                     id: ast::NodeId,\n                     kind: MoveKind) {\n-        /*!\n-         * Adds a new move entry for a move of `lp` that occurs at\n-         * location `id` with kind `kind`.\n-         */\n-\n         debug!(\"add_move(lp={}, id={}, kind={})\",\n                lp.repr(tcx),\n                id,\n@@ -428,18 +413,15 @@ impl<'tcx> MoveData<'tcx> {\n         });\n     }\n \n+    /// Adds a new record for an assignment to `lp` that occurs at location `id` with the given\n+    /// `span`.\n     pub fn add_assignment(&self,\n                           tcx: &ty::ctxt<'tcx>,\n                           lp: Rc<LoanPath<'tcx>>,\n                           assign_id: ast::NodeId,\n                           span: Span,\n                           assignee_id: ast::NodeId,\n                           mode: euv::MutateMode) {\n-        /*!\n-         * Adds a new record for an assignment to `lp` that occurs at\n-         * location `id` with the given `span`.\n-         */\n-\n         debug!(\"add_assignment(lp={}, assign_id={}, assignee_id={}\",\n                lp.repr(tcx), assign_id, assignee_id);\n \n@@ -473,18 +455,16 @@ impl<'tcx> MoveData<'tcx> {\n         }\n     }\n \n+    /// Adds a new record for a match of `base_lp`, downcast to\n+    /// variant `lp`, that occurs at location `pattern_id`.  (One\n+    /// should be able to recover the span info from the\n+    /// `pattern_id` and the ast_map, I think.)\n     pub fn add_variant_match(&self,\n                              tcx: &ty::ctxt<'tcx>,\n                              lp: Rc<LoanPath<'tcx>>,\n                              pattern_id: ast::NodeId,\n                              base_lp: Rc<LoanPath<'tcx>>,\n                              mode: euv::MatchMode) {\n-        /*!\n-         * Adds a new record for a match of `base_lp`, downcast to\n-         * variant `lp`, that occurs at location `pattern_id`.  (One\n-         * should be able to recover the span info from the\n-         * `pattern_id` and the ast_map, I think.)\n-         */\n         debug!(\"add_variant_match(lp={}, pattern_id={})\",\n                lp.repr(tcx), pattern_id);\n \n@@ -507,18 +487,15 @@ impl<'tcx> MoveData<'tcx> {\n         fragments::fixup_fragment_sets(self, tcx)\n     }\n \n+    /// Adds the gen/kills for the various moves and\n+    /// assignments into the provided data flow contexts.\n+    /// Moves are generated by moves and killed by assignments and\n+    /// scoping. Assignments are generated by assignment to variables and\n+    /// killed by scoping. See `doc.rs` for more details.\n     fn add_gen_kills(&self,\n                      tcx: &ty::ctxt<'tcx>,\n                      dfcx_moves: &mut MoveDataFlow,\n                      dfcx_assign: &mut AssignDataFlow) {\n-        /*!\n-         * Adds the gen/kills for the various moves and\n-         * assignments into the provided data flow contexts.\n-         * Moves are generated by moves and killed by assignments and\n-         * scoping. Assignments are generated by assignment to variables and\n-         * killed by scoping. See `doc.rs` for more details.\n-         */\n-\n         for (i, the_move) in self.moves.borrow().iter().enumerate() {\n             dfcx_moves.add_gen(the_move.id, i);\n         }\n@@ -695,18 +672,14 @@ impl<'a, 'tcx> FlowedMoveData<'a, 'tcx> {\n         ret\n     }\n \n+    /// Iterates through each move of `loan_path` (or some base path of `loan_path`) that *may*\n+    /// have occurred on entry to `id` without an intervening assignment. In other words, any moves\n+    /// that would invalidate a reference to `loan_path` at location `id`.\n     pub fn each_move_of(&self,\n                         id: ast::NodeId,\n                         loan_path: &Rc<LoanPath<'tcx>>,\n                         f: |&Move, &LoanPath<'tcx>| -> bool)\n                         -> bool {\n-        /*!\n-         * Iterates through each move of `loan_path` (or some base path\n-         * of `loan_path`) that *may* have occurred on entry to `id` without\n-         * an intervening assignment. In other words, any moves that\n-         * would invalidate a reference to `loan_path` at location `id`.\n-         */\n-\n         // Bad scenarios:\n         //\n         // 1. Move of `a.b.c`, use of `a.b.c`\n@@ -755,17 +728,13 @@ impl<'a, 'tcx> FlowedMoveData<'a, 'tcx> {\n         })\n     }\n \n+    /// Iterates through every assignment to `loan_path` that may have occurred on entry to `id`.\n+    /// `loan_path` must be a single variable.\n     pub fn each_assignment_of(&self,\n                               id: ast::NodeId,\n                               loan_path: &Rc<LoanPath<'tcx>>,\n                               f: |&Assignment| -> bool)\n                               -> bool {\n-        /*!\n-         * Iterates through every assignment to `loan_path` that\n-         * may have occurred on entry to `id`. `loan_path` must be\n-         * a single variable.\n-         */\n-\n         let loan_path_index = {\n             match self.move_data.existing_move_path(loan_path) {\n                 Some(i) => i,"}, {"sha": "a2e8ba8d65c3321e782a147b6512973a74c8c71d", "filename": "src/librustc/middle/cfg/mod.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fcfg%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fcfg%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fcfg%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,12 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Module that constructs a control-flow graph representing an item.\n-Uses `Graph` as the underlying representation.\n-\n-*/\n+//! Module that constructs a control-flow graph representing an item.\n+//! Uses `Graph` as the underlying representation.\n \n use middle::graph;\n use middle::ty;"}, {"sha": "41901a3f4315de778d671322cdb6638a88d6eaec", "filename": "src/librustc/middle/const_eval.rs", "status": "modified", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fconst_eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fconst_eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fconst_eval.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -567,6 +567,34 @@ pub fn eval_const_expr_partial(tcx: &ty::ctxt, e: &Expr) -> Result<const_val, St\n             None => Ok(const_int(0i64))\n         }\n       }\n+      ast::ExprTupField(ref base, index) => {\n+        // Get the base tuple if it is constant\n+        if let Some(&ast::ExprTup(ref fields)) = lookup_const(tcx, &**base).map(|s| &s.node) {\n+            // Check that the given index is within bounds and evaluate its value\n+            if fields.len() > index.node {\n+                return eval_const_expr_partial(tcx, &*fields[index.node])\n+            } else {\n+                return Err(\"tuple index out of bounds\".to_string())\n+            }\n+        }\n+\n+        Err(\"non-constant struct in constant expr\".to_string())\n+      }\n+      ast::ExprField(ref base, field_name) => {\n+        // Get the base expression if it is a struct and it is constant\n+        if let Some(&ast::ExprStruct(_, ref fields, _)) = lookup_const(tcx, &**base)\n+                                                            .map(|s| &s.node) {\n+            // Check that the given field exists and evaluate it\n+            if let Some(f) = fields.iter().find(|f|\n+                                           f.ident.node.as_str() == field_name.node.as_str()) {\n+                return eval_const_expr_partial(tcx, &*f.expr)\n+            } else {\n+                return Err(\"nonexistent struct field\".to_string())\n+            }\n+        }\n+\n+        Err(\"non-constant struct in constant expr\".to_string())\n+      }\n       _ => Err(\"unsupported constant expr\".to_string())\n     }\n }"}, {"sha": "53fea8ffc86c65e1f7519d5880fbf11cf0ed7f58", "filename": "src/librustc/middle/dataflow.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fdataflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fdataflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fdataflow.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -9,12 +9,10 @@\n // except according to those terms.\n \n \n-/*!\n- * A module for propagating forward dataflow information. The analysis\n- * assumes that the items to be propagated can be represented as bits\n- * and thus uses bitvectors. Your job is simply to specify the so-called\n- * GEN and KILL bits for each expression.\n- */\n+//! A module for propagating forward dataflow information. The analysis\n+//! assumes that the items to be propagated can be represented as bits\n+//! and thus uses bitvectors. Your job is simply to specify the so-called\n+//! GEN and KILL bits for each expression.\n \n pub use self::EntryOrExit::*;\n "}, {"sha": "cbf36aeff512c3820a255397d8c06a9c6e373dac", "filename": "src/librustc/middle/expr_use_visitor.rs", "status": "modified", "additions": 9, "deletions": 18, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fexpr_use_visitor.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,11 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * A different sort of visitor for walking fn bodies.  Unlike the\n- * normal visitor, which just walks the entire body in one shot, the\n- * `ExprUseVisitor` determines how expressions are being used.\n- */\n+//! A different sort of visitor for walking fn bodies.  Unlike the\n+//! normal visitor, which just walks the entire body in one shot, the\n+//! `ExprUseVisitor` determines how expressions are being used.\n \n pub use self::MutateMode::*;\n pub use self::LoanCause::*;\n@@ -295,7 +293,7 @@ impl OverloadedCallType {\n pub struct ExprUseVisitor<'d,'t,'tcx,TYPER:'t> {\n     typer: &'t TYPER,\n     mc: mc::MemCategorizationContext<'t,TYPER>,\n-    delegate: &'d mut Delegate<'tcx>+'d,\n+    delegate: &'d mut (Delegate<'tcx>+'d),\n }\n \n // If the TYPER results in an error, it's because the type check\n@@ -716,12 +714,9 @@ impl<'d,'t,'tcx,TYPER:mc::Typer<'tcx>> ExprUseVisitor<'d,'t,'tcx,TYPER> {\n         }\n     }\n \n+    /// Indicates that the value of `blk` will be consumed, meaning either copied or moved\n+    /// depending on its type.\n     fn walk_block(&mut self, blk: &ast::Block) {\n-        /*!\n-         * Indicates that the value of `blk` will be consumed,\n-         * meaning either copied or moved depending on its type.\n-         */\n-\n         debug!(\"walk_block(blk.id={})\", blk.id);\n \n         for stmt in blk.stmts.iter() {\n@@ -821,16 +816,12 @@ impl<'d,'t,'tcx,TYPER:mc::Typer<'tcx>> ExprUseVisitor<'d,'t,'tcx,TYPER> {\n         }\n     }\n \n+    /// Autoderefs for overloaded Deref calls in fact reference their receiver. That is, if we have\n+    /// `(*x)` where `x` is of type `Rc<T>`, then this in fact is equivalent to `x.deref()`. Since\n+    /// `deref()` is declared with `&self`, this is an autoref of `x`.\n     fn walk_autoderefs(&mut self,\n                        expr: &ast::Expr,\n                        autoderefs: uint) {\n-        /*!\n-         * Autoderefs for overloaded Deref calls in fact reference\n-         * their receiver. That is, if we have `(*x)` where `x` is of\n-         * type `Rc<T>`, then this in fact is equivalent to\n-         * `x.deref()`. Since `deref()` is declared with `&self`, this\n-         * is an autoref of `x`.\n-         */\n         debug!(\"walk_autoderefs expr={} autoderefs={}\", expr.repr(self.tcx()), autoderefs);\n \n         for i in range(0, autoderefs) {"}, {"sha": "888f01f9118fa9563c8799042c88d7119797b3ba", "filename": "src/librustc/middle/fast_reject.rs", "status": "modified", "additions": 10, "deletions": 16, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ffast_reject.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ffast_reject.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ffast_reject.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -13,7 +13,7 @@ use syntax::ast;\n \n use self::SimplifiedType::*;\n \n-/** See `simplify_type */\n+/// See `simplify_type\n #[deriving(Clone, PartialEq, Eq, Hash)]\n pub enum SimplifiedType {\n     BoolSimplifiedType,\n@@ -33,26 +33,20 @@ pub enum SimplifiedType {\n     ParameterSimplifiedType,\n }\n \n+/// Tries to simplify a type by dropping type parameters, deref'ing away any reference types, etc.\n+/// The idea is to get something simple that we can use to quickly decide if two types could unify\n+/// during method lookup.\n+///\n+/// If `can_simplify_params` is false, then we will fail to simplify type parameters entirely. This\n+/// is useful when those type parameters would be instantiated with fresh type variables, since\n+/// then we can't say much about whether two types would unify. Put another way,\n+/// `can_simplify_params` should be true if type parameters appear free in `ty` and `false` if they\n+/// are to be considered bound.\n pub fn simplify_type(tcx: &ty::ctxt,\n                      ty: Ty,\n                      can_simplify_params: bool)\n                      -> Option<SimplifiedType>\n {\n-    /*!\n-     * Tries to simplify a type by dropping type parameters, deref'ing\n-     * away any reference types, etc. The idea is to get something\n-     * simple that we can use to quickly decide if two types could\n-     * unify during method lookup.\n-     *\n-     * If `can_simplify_params` is false, then we will fail to\n-     * simplify type parameters entirely. This is useful when those\n-     * type parameters would be instantiated with fresh type\n-     * variables, since then we can't say much about whether two types\n-     * would unify. Put another way, `can_simplify_params` should be\n-     * true if type parameters appear free in `ty` and `false` if they\n-     * are to be considered bound.\n-     */\n-\n     match ty.sty {\n         ty::ty_bool => Some(BoolSimplifiedType),\n         ty::ty_char => Some(CharSimplifiedType),"}, {"sha": "2f50a96402302a5354aa540095006dcde08c53f2", "filename": "src/librustc/middle/graph.rs", "status": "modified", "additions": 21, "deletions": 25, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fgraph.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,31 +8,27 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-A graph module for use in dataflow, region resolution, and elsewhere.\n-\n-# Interface details\n-\n-You customize the graph by specifying a \"node data\" type `N` and an\n-\"edge data\" type `E`. You can then later gain access (mutable or\n-immutable) to these \"user-data\" bits. Currently, you can only add\n-nodes or edges to the graph. You cannot remove or modify them once\n-added. This could be changed if we have a need.\n-\n-# Implementation details\n-\n-The main tricky thing about this code is the way that edges are\n-stored. The edges are stored in a central array, but they are also\n-threaded onto two linked lists for each node, one for incoming edges\n-and one for outgoing edges. Note that every edge is a member of some\n-incoming list and some outgoing list.  Basically you can load the\n-first index of the linked list from the node data structures (the\n-field `first_edge`) and then, for each edge, load the next index from\n-the field `next_edge`). Each of those fields is an array that should\n-be indexed by the direction (see the type `Direction`).\n-\n-*/\n+//! A graph module for use in dataflow, region resolution, and elsewhere.\n+//!\n+//! # Interface details\n+//!\n+//! You customize the graph by specifying a \"node data\" type `N` and an\n+//! \"edge data\" type `E`. You can then later gain access (mutable or\n+//! immutable) to these \"user-data\" bits. Currently, you can only add\n+//! nodes or edges to the graph. You cannot remove or modify them once\n+//! added. This could be changed if we have a need.\n+//!\n+//! # Implementation details\n+//!\n+//! The main tricky thing about this code is the way that edges are\n+//! stored. The edges are stored in a central array, but they are also\n+//! threaded onto two linked lists for each node, one for incoming edges\n+//! and one for outgoing edges. Note that every edge is a member of some\n+//! incoming list and some outgoing list.  Basically you can load the\n+//! first index of the linked list from the node data structures (the\n+//! field `first_edge`) and then, for each edge, load the next index from\n+//! the field `next_edge`). Each of those fields is an array that should\n+//! be indexed by the direction (see the type `Direction`).\n \n #![allow(dead_code)] // still WIP\n "}, {"sha": "a09ceac11a53dae7513e0b37e30fb2dd353f237a", "filename": "src/librustc/middle/liveness.rs", "status": "modified", "additions": 97, "deletions": 99, "changes": 196, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fliveness.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fliveness.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fliveness.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,105 +8,103 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * A classic liveness analysis based on dataflow over the AST.  Computes,\n- * for each local variable in a function, whether that variable is live\n- * at a given point.  Program execution points are identified by their\n- * id.\n- *\n- * # Basic idea\n- *\n- * The basic model is that each local variable is assigned an index.  We\n- * represent sets of local variables using a vector indexed by this\n- * index.  The value in the vector is either 0, indicating the variable\n- * is dead, or the id of an expression that uses the variable.\n- *\n- * We conceptually walk over the AST in reverse execution order.  If we\n- * find a use of a variable, we add it to the set of live variables.  If\n- * we find an assignment to a variable, we remove it from the set of live\n- * variables.  When we have to merge two flows, we take the union of\n- * those two flows---if the variable is live on both paths, we simply\n- * pick one id.  In the event of loops, we continue doing this until a\n- * fixed point is reached.\n- *\n- * ## Checking initialization\n- *\n- * At the function entry point, all variables must be dead.  If this is\n- * not the case, we can report an error using the id found in the set of\n- * live variables, which identifies a use of the variable which is not\n- * dominated by an assignment.\n- *\n- * ## Checking moves\n- *\n- * After each explicit move, the variable must be dead.\n- *\n- * ## Computing last uses\n- *\n- * Any use of the variable where the variable is dead afterwards is a\n- * last use.\n- *\n- * # Implementation details\n- *\n- * The actual implementation contains two (nested) walks over the AST.\n- * The outer walk has the job of building up the ir_maps instance for the\n- * enclosing function.  On the way down the tree, it identifies those AST\n- * nodes and variable IDs that will be needed for the liveness analysis\n- * and assigns them contiguous IDs.  The liveness id for an AST node is\n- * called a `live_node` (it's a newtype'd uint) and the id for a variable\n- * is called a `variable` (another newtype'd uint).\n- *\n- * On the way back up the tree, as we are about to exit from a function\n- * declaration we allocate a `liveness` instance.  Now that we know\n- * precisely how many nodes and variables we need, we can allocate all\n- * the various arrays that we will need to precisely the right size.  We then\n- * perform the actual propagation on the `liveness` instance.\n- *\n- * This propagation is encoded in the various `propagate_through_*()`\n- * methods.  It effectively does a reverse walk of the AST; whenever we\n- * reach a loop node, we iterate until a fixed point is reached.\n- *\n- * ## The `Users` struct\n- *\n- * At each live node `N`, we track three pieces of information for each\n- * variable `V` (these are encapsulated in the `Users` struct):\n- *\n- * - `reader`: the `LiveNode` ID of some node which will read the value\n- *    that `V` holds on entry to `N`.  Formally: a node `M` such\n- *    that there exists a path `P` from `N` to `M` where `P` does not\n- *    write `V`.  If the `reader` is `invalid_node()`, then the current\n- *    value will never be read (the variable is dead, essentially).\n- *\n- * - `writer`: the `LiveNode` ID of some node which will write the\n- *    variable `V` and which is reachable from `N`.  Formally: a node `M`\n- *    such that there exists a path `P` from `N` to `M` and `M` writes\n- *    `V`.  If the `writer` is `invalid_node()`, then there is no writer\n- *    of `V` that follows `N`.\n- *\n- * - `used`: a boolean value indicating whether `V` is *used*.  We\n- *   distinguish a *read* from a *use* in that a *use* is some read that\n- *   is not just used to generate a new value.  For example, `x += 1` is\n- *   a read but not a use.  This is used to generate better warnings.\n- *\n- * ## Special Variables\n- *\n- * We generate various special variables for various, well, special purposes.\n- * These are described in the `specials` struct:\n- *\n- * - `exit_ln`: a live node that is generated to represent every 'exit' from\n- *   the function, whether it be by explicit return, panic, or other means.\n- *\n- * - `fallthrough_ln`: a live node that represents a fallthrough\n- *\n- * - `no_ret_var`: a synthetic variable that is only 'read' from, the\n- *   fallthrough node.  This allows us to detect functions where we fail\n- *   to return explicitly.\n- * - `clean_exit_var`: a synthetic variable that is only 'read' from the\n- *   fallthrough node.  It is only live if the function could converge\n- *   via means other than an explicit `return` expression. That is, it is\n- *   only dead if the end of the function's block can never be reached.\n- *   It is the responsibility of typeck to ensure that there are no\n- *   `return` expressions in a function declared as diverging.\n- */\n+//! A classic liveness analysis based on dataflow over the AST.  Computes,\n+//! for each local variable in a function, whether that variable is live\n+//! at a given point.  Program execution points are identified by their\n+//! id.\n+//!\n+//! # Basic idea\n+//!\n+//! The basic model is that each local variable is assigned an index.  We\n+//! represent sets of local variables using a vector indexed by this\n+//! index.  The value in the vector is either 0, indicating the variable\n+//! is dead, or the id of an expression that uses the variable.\n+//!\n+//! We conceptually walk over the AST in reverse execution order.  If we\n+//! find a use of a variable, we add it to the set of live variables.  If\n+//! we find an assignment to a variable, we remove it from the set of live\n+//! variables.  When we have to merge two flows, we take the union of\n+//! those two flows---if the variable is live on both paths, we simply\n+//! pick one id.  In the event of loops, we continue doing this until a\n+//! fixed point is reached.\n+//!\n+//! ## Checking initialization\n+//!\n+//! At the function entry point, all variables must be dead.  If this is\n+//! not the case, we can report an error using the id found in the set of\n+//! live variables, which identifies a use of the variable which is not\n+//! dominated by an assignment.\n+//!\n+//! ## Checking moves\n+//!\n+//! After each explicit move, the variable must be dead.\n+//!\n+//! ## Computing last uses\n+//!\n+//! Any use of the variable where the variable is dead afterwards is a\n+//! last use.\n+//!\n+//! # Implementation details\n+//!\n+//! The actual implementation contains two (nested) walks over the AST.\n+//! The outer walk has the job of building up the ir_maps instance for the\n+//! enclosing function.  On the way down the tree, it identifies those AST\n+//! nodes and variable IDs that will be needed for the liveness analysis\n+//! and assigns them contiguous IDs.  The liveness id for an AST node is\n+//! called a `live_node` (it's a newtype'd uint) and the id for a variable\n+//! is called a `variable` (another newtype'd uint).\n+//!\n+//! On the way back up the tree, as we are about to exit from a function\n+//! declaration we allocate a `liveness` instance.  Now that we know\n+//! precisely how many nodes and variables we need, we can allocate all\n+//! the various arrays that we will need to precisely the right size.  We then\n+//! perform the actual propagation on the `liveness` instance.\n+//!\n+//! This propagation is encoded in the various `propagate_through_*()`\n+//! methods.  It effectively does a reverse walk of the AST; whenever we\n+//! reach a loop node, we iterate until a fixed point is reached.\n+//!\n+//! ## The `Users` struct\n+//!\n+//! At each live node `N`, we track three pieces of information for each\n+//! variable `V` (these are encapsulated in the `Users` struct):\n+//!\n+//! - `reader`: the `LiveNode` ID of some node which will read the value\n+//!    that `V` holds on entry to `N`.  Formally: a node `M` such\n+//!    that there exists a path `P` from `N` to `M` where `P` does not\n+//!    write `V`.  If the `reader` is `invalid_node()`, then the current\n+//!    value will never be read (the variable is dead, essentially).\n+//!\n+//! - `writer`: the `LiveNode` ID of some node which will write the\n+//!    variable `V` and which is reachable from `N`.  Formally: a node `M`\n+//!    such that there exists a path `P` from `N` to `M` and `M` writes\n+//!    `V`.  If the `writer` is `invalid_node()`, then there is no writer\n+//!    of `V` that follows `N`.\n+//!\n+//! - `used`: a boolean value indicating whether `V` is *used*.  We\n+//!   distinguish a *read* from a *use* in that a *use* is some read that\n+//!   is not just used to generate a new value.  For example, `x += 1` is\n+//!   a read but not a use.  This is used to generate better warnings.\n+//!\n+//! ## Special Variables\n+//!\n+//! We generate various special variables for various, well, special purposes.\n+//! These are described in the `specials` struct:\n+//!\n+//! - `exit_ln`: a live node that is generated to represent every 'exit' from\n+//!   the function, whether it be by explicit return, panic, or other means.\n+//!\n+//! - `fallthrough_ln`: a live node that represents a fallthrough\n+//!\n+//! - `no_ret_var`: a synthetic variable that is only 'read' from, the\n+//!   fallthrough node.  This allows us to detect functions where we fail\n+//!   to return explicitly.\n+//! - `clean_exit_var`: a synthetic variable that is only 'read' from the\n+//!   fallthrough node.  It is only live if the function could converge\n+//!   via means other than an explicit `return` expression. That is, it is\n+//!   only dead if the end of the function's block can never be reached.\n+//!   It is the responsibility of typeck to ensure that there are no\n+//!   `return` expressions in a function declared as diverging.\n use self::LoopKind::*;\n use self::LiveNodeKind::*;\n use self::VarKind::*;"}, {"sha": "ce166fc5de6bb9f9e8faf5667f2d8f747b096659", "filename": "src/librustc/middle/mem_categorization.rs", "status": "modified", "additions": 76, "deletions": 91, "changes": 167, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fmem_categorization.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fmem_categorization.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fmem_categorization.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,57 +8,55 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * # Categorization\n- *\n- * The job of the categorization module is to analyze an expression to\n- * determine what kind of memory is used in evaluating it (for example,\n- * where dereferences occur and what kind of pointer is dereferenced;\n- * whether the memory is mutable; etc)\n- *\n- * Categorization effectively transforms all of our expressions into\n- * expressions of the following forms (the actual enum has many more\n- * possibilities, naturally, but they are all variants of these base\n- * forms):\n- *\n- *     E = rvalue    // some computed rvalue\n- *       | x         // address of a local variable or argument\n- *       | *E        // deref of a ptr\n- *       | E.comp    // access to an interior component\n- *\n- * Imagine a routine ToAddr(Expr) that evaluates an expression and returns an\n- * address where the result is to be found.  If Expr is an lvalue, then this\n- * is the address of the lvalue.  If Expr is an rvalue, this is the address of\n- * some temporary spot in memory where the result is stored.\n- *\n- * Now, cat_expr() classifies the expression Expr and the address A=ToAddr(Expr)\n- * as follows:\n- *\n- * - cat: what kind of expression was this?  This is a subset of the\n- *   full expression forms which only includes those that we care about\n- *   for the purpose of the analysis.\n- * - mutbl: mutability of the address A\n- * - ty: the type of data found at the address A\n- *\n- * The resulting categorization tree differs somewhat from the expressions\n- * themselves.  For example, auto-derefs are explicit.  Also, an index a[b] is\n- * decomposed into two operations: a dereference to reach the array data and\n- * then an index to jump forward to the relevant item.\n- *\n- * ## By-reference upvars\n- *\n- * One part of the translation which may be non-obvious is that we translate\n- * closure upvars into the dereference of a borrowed pointer; this more closely\n- * resembles the runtime translation. So, for example, if we had:\n- *\n- *     let mut x = 3;\n- *     let y = 5;\n- *     let inc = || x += y;\n- *\n- * Then when we categorize `x` (*within* the closure) we would yield a\n- * result of `*x'`, effectively, where `x'` is a `cat_upvar` reference\n- * tied to `x`. The type of `x'` will be a borrowed pointer.\n- */\n+//! # Categorization\n+//!\n+//! The job of the categorization module is to analyze an expression to\n+//! determine what kind of memory is used in evaluating it (for example,\n+//! where dereferences occur and what kind of pointer is dereferenced;\n+//! whether the memory is mutable; etc)\n+//!\n+//! Categorization effectively transforms all of our expressions into\n+//! expressions of the following forms (the actual enum has many more\n+//! possibilities, naturally, but they are all variants of these base\n+//! forms):\n+//!\n+//!     E = rvalue    // some computed rvalue\n+//!       | x         // address of a local variable or argument\n+//!       | *E        // deref of a ptr\n+//!       | E.comp    // access to an interior component\n+//!\n+//! Imagine a routine ToAddr(Expr) that evaluates an expression and returns an\n+//! address where the result is to be found.  If Expr is an lvalue, then this\n+//! is the address of the lvalue.  If Expr is an rvalue, this is the address of\n+//! some temporary spot in memory where the result is stored.\n+//!\n+//! Now, cat_expr() classifies the expression Expr and the address A=ToAddr(Expr)\n+//! as follows:\n+//!\n+//! - cat: what kind of expression was this?  This is a subset of the\n+//!   full expression forms which only includes those that we care about\n+//!   for the purpose of the analysis.\n+//! - mutbl: mutability of the address A\n+//! - ty: the type of data found at the address A\n+//!\n+//! The resulting categorization tree differs somewhat from the expressions\n+//! themselves.  For example, auto-derefs are explicit.  Also, an index a[b] is\n+//! decomposed into two operations: a dereference to reach the array data and\n+//! then an index to jump forward to the relevant item.\n+//!\n+//! ## By-reference upvars\n+//!\n+//! One part of the translation which may be non-obvious is that we translate\n+//! closure upvars into the dereference of a borrowed pointer; this more closely\n+//! resembles the runtime translation. So, for example, if we had:\n+//!\n+//!     let mut x = 3;\n+//!     let y = 5;\n+//!     let inc = || x += y;\n+//!\n+//! Then when we categorize `x` (*within* the closure) we would yield a\n+//! result of `*x'`, effectively, where `x'` is a `cat_upvar` reference\n+//! tied to `x`. The type of `x'` will be a borrowed pointer.\n \n #![allow(non_camel_case_types)]\n \n@@ -266,24 +264,22 @@ pub struct MemCategorizationContext<'t,TYPER:'t> {\n \n pub type McResult<T> = Result<T, ()>;\n \n-/**\n- * The `Typer` trait provides the interface for the mem-categorization\n- * module to the results of the type check. It can be used to query\n- * the type assigned to an expression node, to inquire after adjustments,\n- * and so on.\n- *\n- * This interface is needed because mem-categorization is used from\n- * two places: `regionck` and `borrowck`. `regionck` executes before\n- * type inference is complete, and hence derives types and so on from\n- * intermediate tables.  This also implies that type errors can occur,\n- * and hence `node_ty()` and friends return a `Result` type -- any\n- * error will propagate back up through the mem-categorization\n- * routines.\n- *\n- * In the borrow checker, in contrast, type checking is complete and we\n- * know that no errors have occurred, so we simply consult the tcx and we\n- * can be sure that only `Ok` results will occur.\n- */\n+/// The `Typer` trait provides the interface for the mem-categorization\n+/// module to the results of the type check. It can be used to query\n+/// the type assigned to an expression node, to inquire after adjustments,\n+/// and so on.\n+///\n+/// This interface is needed because mem-categorization is used from\n+/// two places: `regionck` and `borrowck`. `regionck` executes before\n+/// type inference is complete, and hence derives types and so on from\n+/// intermediate tables.  This also implies that type errors can occur,\n+/// and hence `node_ty()` and friends return a `Result` type -- any\n+/// error will propagate back up through the mem-categorization\n+/// routines.\n+///\n+/// In the borrow checker, in contrast, type checking is complete and we\n+/// know that no errors have occurred, so we simply consult the tcx and we\n+/// can be sure that only `Ok` results will occur.\n pub trait Typer<'tcx> {\n     fn tcx<'a>(&'a self) -> &'a ty::ctxt<'tcx>;\n     fn node_ty(&self, id: ast::NodeId) -> McResult<Ty<'tcx>>;\n@@ -1058,38 +1054,31 @@ impl<'t,'tcx,TYPER:Typer<'tcx>> MemCategorizationContext<'t,TYPER> {\n         }\n     }\n \n+    /// Given a pattern P like: `[_, ..Q, _]`, where `vec_cmt` is the cmt for `P`, `slice_pat` is\n+    /// the pattern `Q`, returns:\n+    ///\n+    /// * a cmt for `Q`\n+    /// * the mutability and region of the slice `Q`\n+    ///\n+    /// These last two bits of info happen to be things that borrowck needs.\n     pub fn cat_slice_pattern(&self,\n                              vec_cmt: cmt<'tcx>,\n                              slice_pat: &ast::Pat)\n                              -> McResult<(cmt<'tcx>, ast::Mutability, ty::Region)> {\n-        /*!\n-         * Given a pattern P like: `[_, ..Q, _]`, where `vec_cmt` is\n-         * the cmt for `P`, `slice_pat` is the pattern `Q`, returns:\n-         * - a cmt for `Q`\n-         * - the mutability and region of the slice `Q`\n-         *\n-         * These last two bits of info happen to be things that\n-         * borrowck needs.\n-         */\n-\n         let slice_ty = if_ok!(self.node_ty(slice_pat.id));\n         let (slice_mutbl, slice_r) = vec_slice_info(self.tcx(),\n                                                     slice_pat,\n                                                     slice_ty);\n         let cmt_slice = self.cat_index(slice_pat, self.deref_vec(slice_pat, vec_cmt));\n         return Ok((cmt_slice, slice_mutbl, slice_r));\n \n+        /// In a pattern like [a, b, ..c], normally `c` has slice type, but if you have [a, b,\n+        /// ..ref c], then the type of `ref c` will be `&&[]`, so to extract the slice details we\n+        /// have to recurse through rptrs.\n         fn vec_slice_info(tcx: &ty::ctxt,\n                           pat: &ast::Pat,\n                           slice_ty: Ty)\n                           -> (ast::Mutability, ty::Region) {\n-            /*!\n-             * In a pattern like [a, b, ..c], normally `c` has slice type,\n-             * but if you have [a, b, ..ref c], then the type of `ref c`\n-             * will be `&&[]`, so to extract the slice details we have\n-             * to recurse through rptrs.\n-             */\n-\n             match slice_ty.sty {\n                 ty::ty_rptr(r, ref mt) => match mt.ty.sty {\n                     ty::ty_vec(_, None) => (mt.mutbl, r),\n@@ -1428,13 +1417,9 @@ impl<'tcx> cmt_<'tcx> {\n         }\n     }\n \n+    /// Returns `Some(_)` if this lvalue represents a freely aliasable pointer type.\n     pub fn freely_aliasable(&self, ctxt: &ty::ctxt<'tcx>)\n                             -> Option<AliasableReason> {\n-        /*!\n-         * Returns `Some(_)` if this lvalue represents a freely aliasable\n-         * pointer type.\n-         */\n-\n         // Maybe non-obvious: copied upvars can only be considered\n         // non-aliasable in once closures, since any other kind can be\n         // aliased and eventually recused."}, {"sha": "ec939d19b72409a96faf3a4435de89f90105a8db", "filename": "src/librustc/middle/privacy.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fprivacy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fprivacy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fprivacy.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -243,7 +243,7 @@ impl<'a, 'tcx, 'v> Visitor<'v> for EmbargoVisitor<'a, 'tcx> {\n             // * Private trait impls for private types can be completely ignored\n             ast::ItemImpl(_, _, ref ty, ref impl_items) => {\n                 let public_ty = match ty.node {\n-                    ast::TyPath(_, _, id) => {\n+                    ast::TyPath(_, id) => {\n                         match self.tcx.def_map.borrow()[id].clone() {\n                             def::DefPrimTy(..) => true,\n                             def => {\n@@ -311,7 +311,7 @@ impl<'a, 'tcx, 'v> Visitor<'v> for EmbargoVisitor<'a, 'tcx> {\n \n             ast::ItemTy(ref ty, _) if public_first => {\n                 match ty.node {\n-                    ast::TyPath(_, _, id) => {\n+                    ast::TyPath(_, id) => {\n                         match self.tcx.def_map.borrow()[id].clone() {\n                             def::DefPrimTy(..) | def::DefTyParam(..) => {},\n                             def => {\n@@ -616,7 +616,7 @@ impl<'a, 'tcx> PrivacyVisitor<'a, 'tcx> {\n                     // was private.\n                     ast::ItemImpl(_, _, ref ty, _) => {\n                         let id = match ty.node {\n-                            ast::TyPath(_, _, id) => id,\n+                            ast::TyPath(_, id) => id,\n                             _ => return Some((err_span, err_msg, None)),\n                         };\n                         let def = self.tcx.def_map.borrow()[id].clone();\n@@ -1292,7 +1292,7 @@ impl<'a, 'tcx> VisiblePrivateTypesVisitor<'a, 'tcx> {\n impl<'a, 'b, 'tcx, 'v> Visitor<'v> for CheckTypeForPrivatenessVisitor<'a, 'b, 'tcx> {\n     fn visit_ty(&mut self, ty: &ast::Ty) {\n         match ty.node {\n-            ast::TyPath(_, _, path_id) => {\n+            ast::TyPath(_, path_id) => {\n                 if self.inner.path_is_private_type(path_id) {\n                     self.contains_private = true;\n                     // found what we're looking for so let's stop\n@@ -1493,7 +1493,7 @@ impl<'a, 'tcx, 'v> Visitor<'v> for VisiblePrivateTypesVisitor<'a, 'tcx> {\n \n     fn visit_ty(&mut self, t: &ast::Ty) {\n         match t.node {\n-            ast::TyPath(ref p, _, path_id) => {\n+            ast::TyPath(ref p, path_id) => {\n                 if !self.tcx.sess.features.borrow().visible_private_types &&\n                         self.path_is_private_type(path_id) {\n                     self.tcx.sess.span_err(p.span,"}, {"sha": "2b8dd8df249816452cc5e9d659da15f740fc6410", "filename": "src/librustc/middle/region.rs", "status": "modified", "additions": 93, "deletions": 136, "changes": 229, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fregion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fregion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fregion.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,18 +8,13 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-This file actually contains two passes related to regions.  The first\n-pass builds up the `scope_map`, which describes the parent links in\n-the region hierarchy.  The second pass infers which types must be\n-region parameterized.\n-\n-Most of the documentation on regions can be found in\n-`middle/typeck/infer/region_inference.rs`\n-\n-*/\n-\n+//! This file actually contains two passes related to regions.  The first\n+//! pass builds up the `scope_map`, which describes the parent links in\n+//! the region hierarchy.  The second pass infers which types must be\n+//! region parameterized.\n+//!\n+//! Most of the documentation on regions can be found in\n+//! `middle/typeck/infer/region_inference.rs`\n \n use session::Session;\n use middle::ty::{mod, Ty, FreeRegion};\n@@ -72,46 +67,44 @@ impl CodeExtent {\n     }\n }\n \n-/**\n-The region maps encode information about region relationships.\n-\n-- `scope_map` maps from a scope id to the enclosing scope id; this is\n-  usually corresponding to the lexical nesting, though in the case of\n-  closures the parent scope is the innermost conditional expression or repeating\n-  block\n-\n-- `var_map` maps from a variable or binding id to the block in which\n-  that variable is declared.\n-\n-- `free_region_map` maps from a free region `a` to a list of free\n-  regions `bs` such that `a <= b for all b in bs`\n-  - the free region map is populated during type check as we check\n-    each function. See the function `relate_free_regions` for\n-    more information.\n-\n-- `rvalue_scopes` includes entries for those expressions whose cleanup\n-  scope is larger than the default. The map goes from the expression\n-  id to the cleanup scope id. For rvalues not present in this table,\n-  the appropriate cleanup scope is the innermost enclosing statement,\n-  conditional expression, or repeating block (see `terminating_scopes`).\n-\n-- `terminating_scopes` is a set containing the ids of each statement,\n-  or conditional/repeating expression. These scopes are calling \"terminating\n-  scopes\" because, when attempting to find the scope of a temporary, by\n-  default we search up the enclosing scopes until we encounter the\n-  terminating scope. A conditional/repeating\n-  expression is one which is not guaranteed to execute exactly once\n-  upon entering the parent scope. This could be because the expression\n-  only executes conditionally, such as the expression `b` in `a && b`,\n-  or because the expression may execute many times, such as a loop\n-  body. The reason that we distinguish such expressions is that, upon\n-  exiting the parent scope, we cannot statically know how many times\n-  the expression executed, and thus if the expression creates\n-  temporaries we cannot know statically how many such temporaries we\n-  would have to cleanup. Therefore we ensure that the temporaries never\n-  outlast the conditional/repeating expression, preventing the need\n-  for dynamic checks and/or arbitrary amounts of stack space.\n-*/\n+/// The region maps encode information about region relationships.\n+///\n+/// - `scope_map` maps from a scope id to the enclosing scope id; this is\n+///   usually corresponding to the lexical nesting, though in the case of\n+///   closures the parent scope is the innermost conditional expression or repeating\n+///   block\n+///\n+/// - `var_map` maps from a variable or binding id to the block in which\n+///   that variable is declared.\n+///\n+/// - `free_region_map` maps from a free region `a` to a list of free\n+///   regions `bs` such that `a <= b for all b in bs`\n+///   - the free region map is populated during type check as we check\n+///     each function. See the function `relate_free_regions` for\n+///     more information.\n+///\n+/// - `rvalue_scopes` includes entries for those expressions whose cleanup\n+///   scope is larger than the default. The map goes from the expression\n+///   id to the cleanup scope id. For rvalues not present in this table,\n+///   the appropriate cleanup scope is the innermost enclosing statement,\n+///   conditional expression, or repeating block (see `terminating_scopes`).\n+///\n+/// - `terminating_scopes` is a set containing the ids of each statement,\n+///   or conditional/repeating expression. These scopes are calling \"terminating\n+///   scopes\" because, when attempting to find the scope of a temporary, by\n+///   default we search up the enclosing scopes until we encounter the\n+///   terminating scope. A conditional/repeating\n+///   expression is one which is not guaranteed to execute exactly once\n+///   upon entering the parent scope. This could be because the expression\n+///   only executes conditionally, such as the expression `b` in `a && b`,\n+///   or because the expression may execute many times, such as a loop\n+///   body. The reason that we distinguish such expressions is that, upon\n+///   exiting the parent scope, we cannot statically know how many times\n+///   the expression executed, and thus if the expression creates\n+///   temporaries we cannot know statically how many such temporaries we\n+///   would have to cleanup. Therefore we ensure that the temporaries never\n+///   outlast the conditional/repeating expression, preventing the need\n+///   for dynamic checks and/or arbitrary amounts of stack space.\n pub struct RegionMaps {\n     scope_map: RefCell<FnvHashMap<CodeExtent, CodeExtent>>,\n     var_map: RefCell<NodeMap<CodeExtent>>,\n@@ -171,14 +164,10 @@ impl RegionMaps {\n         self.rvalue_scopes.borrow_mut().insert(var, lifetime);\n     }\n \n+    /// Records that a scope is a TERMINATING SCOPE. Whenever we create automatic temporaries --\n+    /// e.g. by an expression like `a().f` -- they will be freed within the innermost terminating\n+    /// scope.\n     pub fn mark_as_terminating_scope(&self, scope_id: CodeExtent) {\n-        /*!\n-         * Records that a scope is a TERMINATING SCOPE. Whenever we\n-         * create automatic temporaries -- e.g. by an\n-         * expression like `a().f` -- they will be freed within\n-         * the innermost terminating scope.\n-         */\n-\n         debug!(\"record_terminating_scope(scope_id={})\", scope_id);\n         self.terminating_scopes.borrow_mut().insert(scope_id);\n     }\n@@ -197,10 +186,8 @@ impl RegionMaps {\n         }\n     }\n \n+    /// Returns the lifetime of the local variable `var_id`\n     pub fn var_scope(&self, var_id: ast::NodeId) -> CodeExtent {\n-        /*!\n-         * Returns the lifetime of the local variable `var_id`\n-         */\n         match self.var_map.borrow().get(&var_id) {\n             Some(&r) => r,\n             None => { panic!(\"no enclosing scope for id {}\", var_id); }\n@@ -257,15 +244,12 @@ impl RegionMaps {\n         self.is_subscope_of(scope2, scope1)\n     }\n \n+    /// Returns true if `subscope` is equal to or is lexically nested inside `superscope` and false\n+    /// otherwise.\n     pub fn is_subscope_of(&self,\n                           subscope: CodeExtent,\n                           superscope: CodeExtent)\n                           -> bool {\n-        /*!\n-         * Returns true if `subscope` is equal to or is lexically\n-         * nested inside `superscope` and false otherwise.\n-         */\n-\n         let mut s = subscope;\n         while superscope != s {\n             match self.scope_map.borrow().get(&s) {\n@@ -285,27 +269,20 @@ impl RegionMaps {\n         return true;\n     }\n \n+    /// Determines whether two free regions have a subregion relationship\n+    /// by walking the graph encoded in `free_region_map`.  Note that\n+    /// it is possible that `sub != sup` and `sub <= sup` and `sup <= sub`\n+    /// (that is, the user can give two different names to the same lifetime).\n     pub fn sub_free_region(&self, sub: FreeRegion, sup: FreeRegion) -> bool {\n-        /*!\n-         * Determines whether two free regions have a subregion relationship\n-         * by walking the graph encoded in `free_region_map`.  Note that\n-         * it is possible that `sub != sup` and `sub <= sup` and `sup <= sub`\n-         * (that is, the user can give two different names to the same lifetime).\n-         */\n-\n         can_reach(&*self.free_region_map.borrow(), sub, sup)\n     }\n \n+    /// Determines whether one region is a subregion of another.  This is intended to run *after\n+    /// inference* and sadly the logic is somewhat duplicated with the code in infer.rs.\n     pub fn is_subregion_of(&self,\n                            sub_region: ty::Region,\n                            super_region: ty::Region)\n                            -> bool {\n-        /*!\n-         * Determines whether one region is a subregion of another.  This is\n-         * intended to run *after inference* and sadly the logic is somewhat\n-         * duplicated with the code in infer.rs.\n-         */\n-\n         debug!(\"is_subregion_of(sub_region={}, super_region={})\",\n                sub_region, super_region);\n \n@@ -345,16 +322,12 @@ impl RegionMaps {\n         }\n     }\n \n+    /// Finds the nearest common ancestor (if any) of two scopes.  That is, finds the smallest\n+    /// scope which is greater than or equal to both `scope_a` and `scope_b`.\n     pub fn nearest_common_ancestor(&self,\n                                    scope_a: CodeExtent,\n                                    scope_b: CodeExtent)\n                                    -> Option<CodeExtent> {\n-        /*!\n-         * Finds the nearest common ancestor (if any) of two scopes.  That\n-         * is, finds the smallest scope which is greater than or equal to\n-         * both `scope_a` and `scope_b`.\n-         */\n-\n         if scope_a == scope_b { return Some(scope_a); }\n \n         let a_ancestors = ancestors_of(self, scope_a);\n@@ -681,18 +654,15 @@ fn resolve_local(visitor: &mut RegionResolutionVisitor, local: &ast::Local) {\n \n     visit::walk_local(visitor, local);\n \n+    /// True if `pat` match the `P&` nonterminal:\n+    ///\n+    ///     P& = ref X\n+    ///        | StructName { ..., P&, ... }\n+    ///        | VariantName(..., P&, ...)\n+    ///        | [ ..., P&, ... ]\n+    ///        | ( ..., P&, ... )\n+    ///        | box P&\n     fn is_binding_pat(pat: &ast::Pat) -> bool {\n-        /*!\n-         * True if `pat` match the `P&` nonterminal:\n-         *\n-         *     P& = ref X\n-         *        | StructName { ..., P&, ... }\n-         *        | VariantName(..., P&, ...)\n-         *        | [ ..., P&, ... ]\n-         *        | ( ..., P&, ... )\n-         *        | box P&\n-         */\n-\n         match pat.node {\n             ast::PatIdent(ast::BindByRef(_), _, _) => true,\n \n@@ -719,35 +689,27 @@ fn resolve_local(visitor: &mut RegionResolutionVisitor, local: &ast::Local) {\n         }\n     }\n \n+    /// True if `ty` is a borrowed pointer type like `&int` or `&[...]`.\n     fn is_borrowed_ty(ty: &ast::Ty) -> bool {\n-        /*!\n-         * True if `ty` is a borrowed pointer type\n-         * like `&int` or `&[...]`.\n-         */\n-\n         match ty.node {\n             ast::TyRptr(..) => true,\n             _ => false\n         }\n     }\n \n+    /// If `expr` matches the `E&` grammar, then records an extended rvalue scope as appropriate:\n+    ///\n+    ///     E& = & ET\n+    ///        | StructName { ..., f: E&, ... }\n+    ///        | [ ..., E&, ... ]\n+    ///        | ( ..., E&, ... )\n+    ///        | {...; E&}\n+    ///        | box E&\n+    ///        | E& as ...\n+    ///        | ( E& )\n     fn record_rvalue_scope_if_borrow_expr(visitor: &mut RegionResolutionVisitor,\n                                           expr: &ast::Expr,\n                                           blk_id: CodeExtent) {\n-        /*!\n-         * If `expr` matches the `E&` grammar, then records an extended\n-         * rvalue scope as appropriate:\n-         *\n-         *     E& = & ET\n-         *        | StructName { ..., f: E&, ... }\n-         *        | [ ..., E&, ... ]\n-         *        | ( ..., E&, ... )\n-         *        | {...; E&}\n-         *        | box E&\n-         *        | E& as ...\n-         *        | ( E& )\n-         */\n-\n         match expr.node {\n             ast::ExprAddrOf(_, ref subexpr) => {\n                 record_rvalue_scope_if_borrow_expr(visitor, &**subexpr, blk_id);\n@@ -787,29 +749,24 @@ fn resolve_local(visitor: &mut RegionResolutionVisitor, local: &ast::Local) {\n         }\n     }\n \n+    /// Applied to an expression `expr` if `expr` -- or something owned or partially owned by\n+    /// `expr` -- is going to be indirectly referenced by a variable in a let statement. In that\n+    /// case, the \"temporary lifetime\" or `expr` is extended to be the block enclosing the `let`\n+    /// statement.\n+    ///\n+    /// More formally, if `expr` matches the grammar `ET`, record the rvalue scope of the matching\n+    /// `<rvalue>` as `blk_id`:\n+    ///\n+    ///     ET = *ET\n+    ///        | ET[...]\n+    ///        | ET.f\n+    ///        | (ET)\n+    ///        | <rvalue>\n+    ///\n+    /// Note: ET is intended to match \"rvalues or lvalues based on rvalues\".\n     fn record_rvalue_scope<'a>(visitor: &mut RegionResolutionVisitor,\n                                expr: &'a ast::Expr,\n                                blk_scope: CodeExtent) {\n-        /*!\n-         * Applied to an expression `expr` if `expr` -- or something\n-         * owned or partially owned by `expr` -- is going to be\n-         * indirectly referenced by a variable in a let statement. In\n-         * that case, the \"temporary lifetime\" or `expr` is extended\n-         * to be the block enclosing the `let` statement.\n-         *\n-         * More formally, if `expr` matches the grammar `ET`, record\n-         * the rvalue scope of the matching `<rvalue>` as `blk_id`:\n-         *\n-         *     ET = *ET\n-         *        | ET[...]\n-         *        | ET.f\n-         *        | (ET)\n-         *        | <rvalue>\n-         *\n-         * Note: ET is intended to match \"rvalues or\n-         * lvalues based on rvalues\".\n-         */\n-\n         let mut expr = expr;\n         loop {\n             // Note: give all the expressions matching `ET` with the"}, {"sha": "ae32a10f3140b0d5c180b40a479df3e40df7299a", "filename": "src/librustc/middle/resolve.rs", "status": "modified", "additions": 76, "deletions": 62, "changes": 138, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fresolve.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fresolve.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fresolve.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -63,7 +63,7 @@ use syntax::ast::{PolyTraitRef, PrimTy, Public, SelfExplicit, SelfStatic};\n use syntax::ast::{RegionTyParamBound, StmtDecl, StructField};\n use syntax::ast::{StructVariantKind, TraitRef, TraitTyParamBound};\n use syntax::ast::{TupleVariantKind, Ty, TyBool, TyChar, TyClosure, TyF32};\n-use syntax::ast::{TyF64, TyFloat, TyI, TyI8, TyI16, TyI32, TyI64, TyInt};\n+use syntax::ast::{TyF64, TyFloat, TyI, TyI8, TyI16, TyI32, TyI64, TyInt, TyObjectSum};\n use syntax::ast::{TyParam, TyParamBound, TyPath, TyPtr, TyPolyTraitRef, TyProc, TyQPath};\n use syntax::ast::{TyRptr, TyStr, TyU, TyU8, TyU16, TyU32, TyU64, TyUint};\n use syntax::ast::{TypeImplItem, UnnamedField};\n@@ -761,10 +761,8 @@ impl NameBindings {\n         }\n     }\n \n-    /**\n-     * Returns the module node. Panics if this node does not have a module\n-     * definition.\n-     */\n+    /// Returns the module node. Panics if this node does not have a module\n+    /// definition.\n     fn get_module(&self) -> Rc<Module> {\n         match self.get_module_if_available() {\n             None => {\n@@ -1098,18 +1096,16 @@ impl<'a> Resolver<'a> {\n         visit::walk_crate(&mut visitor, krate);\n     }\n \n-    /**\n-     * Adds a new child item to the module definition of the parent node and\n-     * returns its corresponding name bindings as well as the current parent.\n-     * Or, if we're inside a block, creates (or reuses) an anonymous module\n-     * corresponding to the innermost block ID and returns the name bindings\n-     * as well as the newly-created parent.\n-     *\n-     * # Panics\n-     *\n-     * Panics if this node does not have a module definition and we are not inside\n-     * a block.\n-     */\n+    /// Adds a new child item to the module definition of the parent node and\n+    /// returns its corresponding name bindings as well as the current parent.\n+    /// Or, if we're inside a block, creates (or reuses) an anonymous module\n+    /// corresponding to the innermost block ID and returns the name bindings\n+    /// as well as the newly-created parent.\n+    ///\n+    /// # Panics\n+    ///\n+    /// Panics if this node does not have a module definition and we are not inside\n+    /// a block.\n     fn add_child(&self,\n                  name: Name,\n                  reduced_graph_parent: ReducedGraphParent,\n@@ -1396,29 +1392,53 @@ impl<'a> Resolver<'a> {\n                 // methods within to a new module, if the type was defined\n                 // within this module.\n \n-                // Create the module and add all methods.\n-                match ty.node {\n-                    TyPath(ref path, _, _) if path.segments.len() == 1 => {\n+                let mod_name = match ty.node {\n+                    TyPath(ref path, _) if path.segments.len() == 1 => {\n                         // FIXME(18446) we should distinguish between the name of\n                         // a trait and the name of an impl of that trait.\n-                        let mod_name = path.segments.last().unwrap().identifier.name;\n+                        Some(path.segments.last().unwrap().identifier.name)\n+                    }\n+                    TyObjectSum(ref lhs_ty, _) => {\n+                        match lhs_ty.node {\n+                            TyPath(ref path, _) if path.segments.len() == 1 => {\n+                                Some(path.segments.last().unwrap().identifier.name)\n+                            }\n+                            _ => {\n+                                None\n+                            }\n+                        }\n+                    }\n+                    _ => {\n+                        None\n+                    }\n+                };\n \n+                match mod_name {\n+                    None => {\n+                        self.resolve_error(ty.span,\n+                                           \"inherent implementations may \\\n+                                            only be implemented in the same \\\n+                                            module as the type they are \\\n+                                            implemented for\")\n+                    }\n+                    Some(mod_name) => {\n+                        // Create the module and add all methods.\n                         let parent_opt = parent.module().children.borrow()\n-                                               .get(&mod_name).cloned();\n+                            .get(&mod_name).cloned();\n                         let new_parent = match parent_opt {\n                             // It already exists\n                             Some(ref child) if child.get_module_if_available()\n-                                                .is_some() &&\n-                                           (child.get_module().kind.get() == ImplModuleKind ||\n-                                            child.get_module().kind.get() == TraitModuleKind) => {\n-                                ModuleReducedGraphParent(child.get_module())\n-                            }\n+                                .is_some() &&\n+                                (child.get_module().kind.get() == ImplModuleKind ||\n+                                 child.get_module().kind.get() == TraitModuleKind) => {\n+                                    ModuleReducedGraphParent(child.get_module())\n+                                }\n                             Some(ref child) if child.get_module_if_available()\n-                                                .is_some() &&\n-                                           child.get_module().kind.get() ==\n-                                                EnumModuleKind => {\n-                                ModuleReducedGraphParent(child.get_module())\n-                            }\n+                                .is_some() &&\n+                                child.get_module().kind.get() ==\n+                                EnumModuleKind => {\n+                                    ModuleReducedGraphParent(child.get_module())\n+                                }\n                             // Create the module\n                             _ => {\n                                 let name_bindings =\n@@ -1433,7 +1453,7 @@ impl<'a> Resolver<'a> {\n                                 let ns = TypeNS;\n                                 let is_public =\n                                     !name_bindings.defined_in_namespace(ns) ||\n-                                     name_bindings.defined_in_public_namespace(ns);\n+                                    name_bindings.defined_in_public_namespace(ns);\n \n                                 name_bindings.define_module(parent_link,\n                                                             Some(def_id),\n@@ -1459,21 +1479,21 @@ impl<'a> Resolver<'a> {\n                                                        ForbidDuplicateValues,\n                                                        method.span);\n                                     let def = match method.pe_explicit_self()\n-                                                          .node {\n-                                        SelfStatic => {\n-                                            // Static methods become\n-                                            // `DefStaticMethod`s.\n-                                            DefStaticMethod(local_def(method.id),\n-                                                            FromImpl(local_def(item.id)))\n-                                        }\n-                                        _ => {\n-                                            // Non-static methods become\n-                                            // `DefMethod`s.\n-                                            DefMethod(local_def(method.id),\n-                                                      None,\n-                                                      FromImpl(local_def(item.id)))\n-                                        }\n-                                    };\n+                                        .node {\n+                                            SelfStatic => {\n+                                                // Static methods become\n+                                                // `DefStaticMethod`s.\n+                                                DefStaticMethod(local_def(method.id),\n+                                                                FromImpl(local_def(item.id)))\n+                                            }\n+                                            _ => {\n+                                                // Non-static methods become\n+                                                // `DefMethod`s.\n+                                                DefMethod(local_def(method.id),\n+                                                          None,\n+                                                          FromImpl(local_def(item.id)))\n+                                            }\n+                                        };\n \n                                     // NB: not IMPORTABLE\n                                     let modifiers = if method.pe_vis() == ast::Public {\n@@ -1496,7 +1516,7 @@ impl<'a> Resolver<'a> {\n                                             ForbidDuplicateTypesAndModules,\n                                             typedef.span);\n                                     let def = DefAssociatedTy(local_def(\n-                                            typedef.id));\n+                                        typedef.id));\n                                     // NB: not IMPORTABLE\n                                     let modifiers = if typedef.vis == ast::Public {\n                                         PUBLIC\n@@ -1511,13 +1531,6 @@ impl<'a> Resolver<'a> {\n                             }\n                         }\n                     }\n-                    _ => {\n-                        self.resolve_error(ty.span,\n-                                           \"inherent implementations may \\\n-                                            only be implemented in the same \\\n-                                            module as the type they are \\\n-                                            implemented for\")\n-                    }\n                 }\n \n                 parent\n@@ -4725,7 +4738,7 @@ impl<'a> Resolver<'a> {\n                 // type, the result will be that the type name resolves to a module but not\n                 // a type (shadowing any imported modules or types with this name), leading\n                 // to weird user-visible bugs. So we ward this off here. See #15060.\n-                TyPath(ref path, _, path_id) => {\n+                TyPath(ref path, path_id) => {\n                     match self.def_map.borrow().get(&path_id) {\n                         // FIXME: should we catch other options and give more precise errors?\n                         Some(&DefMod(_)) => {\n@@ -4891,7 +4904,7 @@ impl<'a> Resolver<'a> {\n             // Like path expressions, the interpretation of path types depends\n             // on whether the path has multiple elements in it or not.\n \n-            TyPath(ref path, ref bounds, path_id) => {\n+            TyPath(ref path, path_id) => {\n                 // This is a path in the type namespace. Walk through scopes\n                 // looking for it.\n                 let mut result_def = None;\n@@ -4961,11 +4974,12 @@ impl<'a> Resolver<'a> {\n                         self.resolve_error(ty.span, msg.as_slice());\n                     }\n                 }\n+            }\n \n-                bounds.as_ref().map(|bound_vec| {\n-                    self.resolve_type_parameter_bounds(ty.id, bound_vec,\n+            TyObjectSum(ref ty, ref bound_vec) => {\n+                self.resolve_type(&**ty);\n+                self.resolve_type_parameter_bounds(ty.id, bound_vec,\n                                                        TraitBoundingTypeParameter);\n-                });\n             }\n \n             TyQPath(ref qpath) => {\n@@ -5602,7 +5616,7 @@ impl<'a> Resolver<'a> {\n         fn extract_path_and_node_id(t: &Ty, allow: FallbackChecks)\n                                                     -> Option<(Path, NodeId, FallbackChecks)> {\n             match t.node {\n-                TyPath(ref path, _, node_id) => Some((path.clone(), node_id, allow)),\n+                TyPath(ref path, node_id) => Some((path.clone(), node_id, allow)),\n                 TyPtr(ref mut_ty) => extract_path_and_node_id(&*mut_ty.ty, OnlyTraitAndStatics),\n                 TyRptr(_, ref mut_ty) => extract_path_and_node_id(&*mut_ty.ty, allow),\n                 // This doesn't handle the remaining `Ty` variants as they are not"}, {"sha": "bd8db1d51dfd5b321eda48613bc361d4c0b346c9", "filename": "src/librustc/middle/resolve_lifetime.rs", "status": "modified", "additions": 26, "deletions": 46, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fresolve_lifetime.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fresolve_lifetime.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fresolve_lifetime.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,14 +8,12 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Name resolution for lifetimes.\n- *\n- * Name resolution for lifetimes follows MUCH simpler rules than the\n- * full resolve. For example, lifetime names are never exported or\n- * used between functions, and they operate in a purely top-down\n- * way. Therefore we break lifetime name resolution into a separate pass.\n- */\n+//! Name resolution for lifetimes.\n+//!\n+//! Name resolution for lifetimes follows MUCH simpler rules than the\n+//! full resolve. For example, lifetime names are never exported or\n+//! used between functions, and they operate in a purely top-down\n+//! way. Therefore we break lifetime name resolution into a separate pass.\n \n pub use self::DefRegion::*;\n use self::ScopeChain::*;\n@@ -162,21 +160,14 @@ impl<'a, 'v> Visitor<'v> for LifetimeContext<'a> {\n                     visit::walk_ty(this, ty);\n                 });\n             }\n-            ast::TyPath(ref path, ref opt_bounds, id) => {\n+            ast::TyPath(ref path, id) => {\n                 // if this path references a trait, then this will resolve to\n                 // a trait ref, which introduces a binding scope.\n                 match self.def_map.borrow().get(&id) {\n                     Some(&def::DefTrait(..)) => {\n                         self.with(LateScope(&Vec::new(), self.scope), |this| {\n                             this.visit_path(path, id);\n                         });\n-\n-                        match *opt_bounds {\n-                            Some(ref bounds) => {\n-                                visit::walk_ty_param_bounds_helper(self, bounds);\n-                            }\n-                            None => { }\n-                        }\n                     }\n                     _ => {\n                         visit::walk_ty(self, ty);\n@@ -254,34 +245,27 @@ impl<'a> LifetimeContext<'a> {\n     }\n \n     /// Visits self by adding a scope and handling recursive walk over the contents with `walk`.\n+    ///\n+    /// Handles visiting fns and methods. These are a bit complicated because we must distinguish\n+    /// early- vs late-bound lifetime parameters. We do this by checking which lifetimes appear\n+    /// within type bounds; those are early bound lifetimes, and the rest are late bound.\n+    ///\n+    /// For example:\n+    ///\n+    ///    fn foo<'a,'b,'c,T:Trait<'b>>(...)\n+    ///\n+    /// Here `'a` and `'c` are late bound but `'b` is early bound. Note that early- and late-bound\n+    /// lifetimes may be interspersed together.\n+    ///\n+    /// If early bound lifetimes are present, we separate them into their own list (and likewise\n+    /// for late bound). They will be numbered sequentially, starting from the lowest index that is\n+    /// already in scope (for a fn item, that will be 0, but for a method it might not be). Late\n+    /// bound lifetimes are resolved by name and associated with a binder id (`binder_id`), so the\n+    /// ordering is not important there.\n     fn visit_early_late(&mut self,\n                         early_space: subst::ParamSpace,\n                         generics: &ast::Generics,\n                         walk: |&mut LifetimeContext|) {\n-        /*!\n-         * Handles visiting fns and methods. These are a bit\n-         * complicated because we must distinguish early- vs late-bound\n-         * lifetime parameters. We do this by checking which lifetimes\n-         * appear within type bounds; those are early bound lifetimes,\n-         * and the rest are late bound.\n-         *\n-         * For example:\n-         *\n-         *    fn foo<'a,'b,'c,T:Trait<'b>>(...)\n-         *\n-         * Here `'a` and `'c` are late bound but `'b` is early\n-         * bound. Note that early- and late-bound lifetimes may be\n-         * interspersed together.\n-         *\n-         * If early bound lifetimes are present, we separate them into\n-         * their own list (and likewise for late bound). They will be\n-         * numbered sequentially, starting from the lowest index that\n-         * is already in scope (for a fn item, that will be 0, but for\n-         * a method it might not be). Late bound lifetimes are\n-         * resolved by name and associated with a binder id (`binder_id`), so\n-         * the ordering is not important there.\n-         */\n-\n         let referenced_idents = early_bound_lifetime_names(generics);\n \n         debug!(\"visit_early_late: referenced_idents={}\",\n@@ -479,13 +463,9 @@ pub fn early_bound_lifetimes<'a>(generics: &'a ast::Generics) -> Vec<ast::Lifeti\n         .collect()\n }\n \n+/// Given a set of generic declarations, returns a list of names containing all early bound\n+/// lifetime names for those generics. (In fact, this list may also contain other names.)\n fn early_bound_lifetime_names(generics: &ast::Generics) -> Vec<ast::Name> {\n-    /*!\n-     * Given a set of generic declarations, returns a list of names\n-     * containing all early bound lifetime names for those\n-     * generics. (In fact, this list may also contain other names.)\n-     */\n-\n     // Create two lists, dividing the lifetimes into early/late bound.\n     // Initially, all of them are considered late, but we will move\n     // things from late into early as we go if we find references to"}, {"sha": "0a3e6c20316be4de7591e818685d5e9b0ba09934", "filename": "src/librustc/middle/subst.rs", "status": "modified", "additions": 58, "deletions": 83, "changes": 141, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fsubst.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fsubst.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fsubst.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -24,22 +24,19 @@ use syntax::codemap::{Span, DUMMY_SP};\n \n ///////////////////////////////////////////////////////////////////////////\n \n-/**\n- * A substitution mapping type/region parameters to new values. We\n- * identify each in-scope parameter by an *index* and a *parameter\n- * space* (which indices where the parameter is defined; see\n- * `ParamSpace`).\n- */\n+/// A substitution mapping type/region parameters to new values. We\n+/// identify each in-scope parameter by an *index* and a *parameter\n+/// space* (which indices where the parameter is defined; see\n+/// `ParamSpace`).\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub struct Substs<'tcx> {\n     pub types: VecPerParamSpace<Ty<'tcx>>,\n     pub regions: RegionSubsts,\n }\n \n-/**\n- * Represents the values to use when substituting lifetime parameters.\n- * If the value is `ErasedRegions`, then this subst is occurring during\n- * trans, and all region parameters will be replaced with `ty::ReStatic`. */\n+/// Represents the values to use when substituting lifetime parameters.\n+/// If the value is `ErasedRegions`, then this subst is occurring during\n+/// trans, and all region parameters will be replaced with `ty::ReStatic`.\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub enum RegionSubsts {\n     ErasedRegions,\n@@ -131,26 +128,18 @@ pub fn self_ty(&self) -> Option<Ty<'tcx>> {\n         Substs { types: types, regions: ErasedRegions }\n     }\n \n+    /// Since ErasedRegions are only to be used in trans, most of the compiler can use this method\n+    /// to easily access the set of region substitutions.\n     pub fn regions<'a>(&'a self) -> &'a VecPerParamSpace<ty::Region> {\n-        /*!\n-         * Since ErasedRegions are only to be used in trans, most of\n-         * the compiler can use this method to easily access the set\n-         * of region substitutions.\n-         */\n-\n         match self.regions {\n             ErasedRegions => panic!(\"Erased regions only expected in trans\"),\n             NonerasedRegions(ref r) => r\n         }\n     }\n \n+    /// Since ErasedRegions are only to be used in trans, most of the compiler can use this method\n+    /// to easily access the set of region substitutions.\n     pub fn mut_regions<'a>(&'a mut self) -> &'a mut VecPerParamSpace<ty::Region> {\n-        /*!\n-         * Since ErasedRegions are only to be used in trans, most of\n-         * the compiler can use this method to easily access the set\n-         * of region substitutions.\n-         */\n-\n         match self.regions {\n             ErasedRegions => panic!(\"Erased regions only expected in trans\"),\n             NonerasedRegions(ref mut r) => r\n@@ -226,11 +215,9 @@ impl ParamSpace {\n     }\n }\n \n-/**\n- * Vector of things sorted by param space. Used to keep\n- * the set of things declared on the type, self, or method\n- * distinct.\n- */\n+/// Vector of things sorted by param space. Used to keep\n+/// the set of things declared on the type, self, or method\n+/// distinct.\n #[deriving(PartialEq, Eq, Clone, Hash, Encodable, Decodable)]\n pub struct VecPerParamSpace<T> {\n     // This was originally represented as a tuple with one Vec<T> for\n@@ -250,10 +237,8 @@ pub struct VecPerParamSpace<T> {\n     content: Vec<T>,\n }\n \n-/**\n- * The `split` function converts one `VecPerParamSpace` into this\n- * `SeparateVecsPerParamSpace` structure.\n- */\n+/// The `split` function converts one `VecPerParamSpace` into this\n+/// `SeparateVecsPerParamSpace` structure.\n pub struct SeparateVecsPerParamSpace<T> {\n     pub types: Vec<T>,\n     pub selfs: Vec<T>,\n@@ -688,59 +673,49 @@ impl<'a,'tcx> SubstFolder<'a,'tcx> {\n         self.shift_regions_through_binders(ty)\n     }\n \n+    /// It is sometimes necessary to adjust the debruijn indices during substitution. This occurs\n+    /// when we are substituting a type with escaping regions into a context where we have passed\n+    /// through region binders. That's quite a mouthful. Let's see an example:\n+    ///\n+    /// ```\n+    /// type Func<A> = fn(A);\n+    /// type MetaFunc = for<'a> fn(Func<&'a int>)\n+    /// ```\n+    ///\n+    /// The type `MetaFunc`, when fully expanded, will be\n+    ///\n+    ///     for<'a> fn(fn(&'a int))\n+    ///             ^~ ^~ ^~~\n+    ///             |  |  |\n+    ///             |  |  DebruijnIndex of 2\n+    ///             Binders\n+    ///\n+    /// Here the `'a` lifetime is bound in the outer function, but appears as an argument of the\n+    /// inner one. Therefore, that appearance will have a DebruijnIndex of 2, because we must skip\n+    /// over the inner binder (remember that we count Debruijn indices from 1). However, in the\n+    /// definition of `MetaFunc`, the binder is not visible, so the type `&'a int` will have a\n+    /// debruijn index of 1. It's only during the substitution that we can see we must increase the\n+    /// depth by 1 to account for the binder that we passed through.\n+    ///\n+    /// As a second example, consider this twist:\n+    ///\n+    /// ```\n+    /// type FuncTuple<A> = (A,fn(A));\n+    /// type MetaFuncTuple = for<'a> fn(FuncTuple<&'a int>)\n+    /// ```\n+    ///\n+    /// Here the final type will be:\n+    ///\n+    ///     for<'a> fn((&'a int, fn(&'a int)))\n+    ///                 ^~~         ^~~\n+    ///                 |           |\n+    ///          DebruijnIndex of 1 |\n+    ///                      DebruijnIndex of 2\n+    ///\n+    /// As indicated in the diagram, here the same type `&'a int` is substituted once, but in the\n+    /// first case we do not increase the Debruijn index and in the second case we do. The reason\n+    /// is that only in the second case have we passed through a fn binder.\n     fn shift_regions_through_binders(&self, ty: Ty<'tcx>) -> Ty<'tcx> {\n-        /*!\n-         * It is sometimes necessary to adjust the debruijn indices\n-         * during substitution. This occurs when we are substituting a\n-         * type with escaping regions into a context where we have\n-         * passed through region binders. That's quite a\n-         * mouthful. Let's see an example:\n-         *\n-         * ```\n-         * type Func<A> = fn(A);\n-         * type MetaFunc = for<'a> fn(Func<&'a int>)\n-         * ```\n-         *\n-         * The type `MetaFunc`, when fully expanded, will be\n-         *\n-         *     for<'a> fn(fn(&'a int))\n-         *             ^~ ^~ ^~~\n-         *             |  |  |\n-         *             |  |  DebruijnIndex of 2\n-         *             Binders\n-         *\n-         * Here the `'a` lifetime is bound in the outer function, but\n-         * appears as an argument of the inner one. Therefore, that\n-         * appearance will have a DebruijnIndex of 2, because we must\n-         * skip over the inner binder (remember that we count Debruijn\n-         * indices from 1). However, in the definition of `MetaFunc`,\n-         * the binder is not visible, so the type `&'a int` will have\n-         * a debruijn index of 1. It's only during the substitution\n-         * that we can see we must increase the depth by 1 to account\n-         * for the binder that we passed through.\n-         *\n-         * As a second example, consider this twist:\n-         *\n-         * ```\n-         * type FuncTuple<A> = (A,fn(A));\n-         * type MetaFuncTuple = for<'a> fn(FuncTuple<&'a int>)\n-         * ```\n-         *\n-         * Here the final type will be:\n-         *\n-         *     for<'a> fn((&'a int, fn(&'a int)))\n-         *                 ^~~         ^~~\n-         *                 |           |\n-         *          DebruijnIndex of 1 |\n-         *                      DebruijnIndex of 2\n-         *\n-         * As indicated in the diagram, here the same type `&'a int`\n-         * is substituted once, but in the first case we do not\n-         * increase the Debruijn index and in the second case we\n-         * do. The reason is that only in the second case have we\n-         * passed through a fn binder.\n-         */\n-\n         debug!(\"shift_regions(ty={}, region_binders_passed={}, type_has_escaping_regions={})\",\n                ty.repr(self.tcx()), self.region_binders_passed, ty::type_has_escaping_regions(ty));\n "}, {"sha": "048f394224cf0b1d2e8e2133a63d4083b72c5145", "filename": "src/librustc/middle/traits/coherence.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fcoherence.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fcoherence.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Fcoherence.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! See `doc.rs` for high-level documentation */\n+//! See `doc.rs` for high-level documentation\n \n use super::SelectionContext;\n use super::Obligation;"}, {"sha": "62246b77ee9409b0c168806403ec4b1b85e8e71e", "filename": "src/librustc/middle/traits/doc.rs", "status": "modified", "additions": 396, "deletions": 400, "changes": 796, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,403 +8,399 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# TRAIT RESOLUTION\n-\n-This document describes the general process and points out some non-obvious\n-things.\n-\n-## Major concepts\n-\n-Trait resolution is the process of pairing up an impl with each\n-reference to a trait. So, for example, if there is a generic function like:\n-\n-    fn clone_slice<T:Clone>(x: &[T]) -> Vec<T> { ... }\n-\n-and then a call to that function:\n-\n-    let v: Vec<int> = clone_slice([1, 2, 3].as_slice())\n-\n-it is the job of trait resolution to figure out (in which case)\n-whether there exists an impl of `int : Clone`\n-\n-Note that in some cases, like generic functions, we may not be able to\n-find a specific impl, but we can figure out that the caller must\n-provide an impl. To see what I mean, consider the body of `clone_slice`:\n-\n-    fn clone_slice<T:Clone>(x: &[T]) -> Vec<T> {\n-        let mut v = Vec::new();\n-        for e in x.iter() {\n-            v.push((*e).clone()); // (*)\n-        }\n-    }\n-\n-The line marked `(*)` is only legal if `T` (the type of `*e`)\n-implements the `Clone` trait. Naturally, since we don't know what `T`\n-is, we can't find the specific impl; but based on the bound `T:Clone`,\n-we can say that there exists an impl which the caller must provide.\n-\n-We use the term *obligation* to refer to a trait reference in need of\n-an impl.\n-\n-## Overview\n-\n-Trait resolution consists of three major parts:\n-\n-- SELECTION: Deciding how to resolve a specific obligation. For\n-  example, selection might decide that a specific obligation can be\n-  resolved by employing an impl which matches the self type, or by\n-  using a parameter bound. In the case of an impl, Selecting one\n-  obligation can create *nested obligations* because of where clauses\n-  on the impl itself. It may also require evaluating those nested\n-  obligations to resolve ambiguities.\n-\n-- FULFILLMENT: The fulfillment code is what tracks that obligations\n-  are completely fulfilled. Basically it is a worklist of obligations\n-  to be selected: once selection is successful, the obligation is\n-  removed from the worklist and any nested obligations are enqueued.\n-\n-- COHERENCE: The coherence checks are intended to ensure that there\n-  are never overlapping impls, where two impls could be used with\n-  equal precedence.\n-\n-## Selection\n-\n-Selection is the process of deciding whether an obligation can be\n-resolved and, if so, how it is to be resolved (via impl, where clause, etc).\n-The main interface is the `select()` function, which takes an obligation\n-and returns a `SelectionResult`. There are three possible outcomes:\n-\n-- `Ok(Some(selection))` -- yes, the obligation can be resolved, and\n-  `selection` indicates how. If the impl was resolved via an impl,\n-  then `selection` may also indicate nested obligations that are required\n-  by the impl.\n-\n-- `Ok(None)` -- we are not yet sure whether the obligation can be\n-  resolved or not. This happens most commonly when the obligation\n-  contains unbound type variables.\n-\n-- `Err(err)` -- the obligation definitely cannot be resolved due to a\n-  type error, or because there are no impls that could possibly apply,\n-  etc.\n-\n-The basic algorithm for selection is broken into two big phases:\n-candidate assembly and confirmation.\n-\n-### Candidate assembly\n-\n-Searches for impls/where-clauses/etc that might\n-possibly be used to satisfy the obligation. Each of those is called\n-a candidate. To avoid ambiguity, we want to find exactly one\n-candidate that is definitively applicable. In some cases, we may not\n-know whether an impl/where-clause applies or not -- this occurs when\n-the obligation contains unbound inference variables.\n-\n-The basic idea for candidate assembly is to do a first pass in which\n-we identify all possible candidates. During this pass, all that we do\n-is try and unify the type parameters. (In particular, we ignore any\n-nested where clauses.) Presuming that this unification succeeds, the\n-impl is added as a candidate.\n-\n-Once this first pass is done, we can examine the set of candidates. If\n-it is a singleton set, then we are done: this is the only impl in\n-scope that could possibly apply. Otherwise, we can winnow down the set\n-of candidates by using where clauses and other conditions. If this\n-reduced set yields a single, unambiguous entry, we're good to go,\n-otherwise the result is considered ambiguous.\n-\n-#### The basic process: Inferring based on the impls we see\n-\n-This process is easier if we work through some examples. Consider\n-the following trait:\n-\n-```\n-trait Convert<Target> {\n-    fn convert(&self) -> Target;\n-}\n-```\n-\n-This trait just has one method. It's about as simple as it gets. It\n-converts from the (implicit) `Self` type to the `Target` type. If we\n-wanted to permit conversion between `int` and `uint`, we might\n-implement `Convert` like so:\n-\n-```rust\n-impl Convert<uint> for int { ... } // int -> uint\n-impl Convert<int> for uint { ... } // uint -> uint\n-```\n-\n-Now imagine there is some code like the following:\n-\n-```rust\n-let x: int = ...;\n-let y = x.convert();\n-```\n-\n-The call to convert will generate a trait reference `Convert<$Y> for\n-int`, where `$Y` is the type variable representing the type of\n-`y`. When we match this against the two impls we can see, we will find\n-that only one remains: `Convert<uint> for int`. Therefore, we can\n-select this impl, which will cause the type of `$Y` to be unified to\n-`uint`. (Note that while assembling candidates, we do the initial\n-unifications in a transaction, so that they don't affect one another.)\n-\n-There are tests to this effect in src/test/run-pass:\n-\n-   traits-multidispatch-infer-convert-source-and-target.rs\n-   traits-multidispatch-infer-convert-target.rs\n-\n-#### Winnowing: Resolving ambiguities\n-\n-But what happens if there are multiple impls where all the types\n-unify? Consider this example:\n-\n-```rust\n-trait Get {\n-    fn get(&self) -> Self;\n-}\n-\n-impl<T:Copy> Get for T {\n-    fn get(&self) -> T { *self }\n-}\n-\n-impl<T:Get> Get for Box<T> {\n-    fn get(&self) -> Box<T> { box get_it(&**self) }\n-}\n-```\n-\n-What happens when we invoke `get_it(&box 1_u16)`, for example? In this\n-case, the `Self` type is `Box<u16>` -- that unifies with both impls,\n-because the first applies to all types, and the second to all\n-boxes. In the olden days we'd have called this ambiguous. But what we\n-do now is do a second *winnowing* pass that considers where clauses\n-and attempts to remove candidates -- in this case, the first impl only\n-applies if `Box<u16> : Copy`, which doesn't hold. After winnowing,\n-then, we are left with just one candidate, so we can proceed. There is\n-a test of this in `src/test/run-pass/traits-conditional-dispatch.rs`.\n-\n-#### Matching\n-\n-The subroutines that decide whether a particular impl/where-clause/etc\n-applies to a particular obligation. At the moment, this amounts to\n-unifying the self types, but in the future we may also recursively\n-consider some of the nested obligations, in the case of an impl.\n-\n-#### Lifetimes and selection\n-\n-Because of how that lifetime inference works, it is not possible to\n-give back immediate feedback as to whether a unification or subtype\n-relationship between lifetimes holds or not. Therefore, lifetime\n-matching is *not* considered during selection. This is reflected in\n-the fact that subregion assignment is infallible. This may yield\n-lifetime constraints that will later be found to be in error (in\n-contrast, the non-lifetime-constraints have already been checked\n-during selection and can never cause an error, though naturally they\n-may lead to other errors downstream).\n-\n-#### Where clauses\n-\n-Besides an impl, the other major way to resolve an obligation is via a\n-where clause. The selection process is always given a *parameter\n-environment* which contains a list of where clauses, which are\n-basically obligations that can assume are satisfiable. We will iterate\n-over that list and check whether our current obligation can be found\n-in that list, and if so it is considered satisfied. More precisely, we\n-want to check whether there is a where-clause obligation that is for\n-the same trait (or some subtrait) and for which the self types match,\n-using the definition of *matching* given above.\n-\n-Consider this simple example:\n-\n-     trait A1 { ... }\n-     trait A2 : A1 { ... }\n-\n-     trait B { ... }\n-\n-     fn foo<X:A2+B> { ... }\n-\n-Clearly we can use methods offered by `A1`, `A2`, or `B` within the\n-body of `foo`. In each case, that will incur an obligation like `X :\n-A1` or `X : A2`. The parameter environment will contain two\n-where-clauses, `X : A2` and `X : B`. For each obligation, then, we\n-search this list of where-clauses.  To resolve an obligation `X:A1`,\n-we would note that `X:A2` implies that `X:A1`.\n-\n-### Confirmation\n-\n-Confirmation unifies the output type parameters of the trait with the\n-values found in the obligation, possibly yielding a type error.  If we\n-return to our example of the `Convert` trait from the previous\n-section, confirmation is where an error would be reported, because the\n-impl specified that `T` would be `uint`, but the obligation reported\n-`char`. Hence the result of selection would be an error.\n-\n-### Selection during translation\n-\n-During type checking, we do not store the results of trait selection.\n-We simply wish to verify that trait selection will succeed. Then\n-later, at trans time, when we have all concrete types available, we\n-can repeat the trait selection.  In this case, we do not consider any\n-where-clauses to be in scope. We know that therefore each resolution\n-will resolve to a particular impl.\n-\n-One interesting twist has to do with nested obligations. In general, in trans,\n-we only need to do a \"shallow\" selection for an obligation. That is, we wish to\n-identify which impl applies, but we do not (yet) need to decide how to select\n-any nested obligations. Nonetheless, we *do* currently do a complete resolution,\n-and that is because it can sometimes inform the results of type inference. That is,\n-we do not have the full substitutions in terms of the type varibales of the impl available\n-to us, so we must run trait selection to figure everything out.\n-\n-Here is an example:\n-\n-    trait Foo { ... }\n-    impl<U,T:Bar<U>> Foo for Vec<T> { ... }\n-\n-    impl Bar<uint> for int { ... }\n-\n-After one shallow round of selection for an obligation like `Vec<int>\n-: Foo`, we would know which impl we want, and we would know that\n-`T=int`, but we do not know the type of `U`.  We must select the\n-nested obligation `int : Bar<U>` to find out that `U=uint`.\n-\n-It would be good to only do *just as much* nested resolution as\n-necessary. Currently, though, we just do a full resolution.\n-\n-## Method matching\n-\n-Method dispach follows a slightly different path than normal trait\n-selection. This is because it must account for the transformed self\n-type of the receiver and various other complications. The procedure is\n-described in `select.rs` in the \"METHOD MATCHING\" section.\n-\n-# Caching and subtle considerations therewith\n-\n-In general we attempt to cache the results of trait selection.  This\n-is a somewhat complex process. Part of the reason for this is that we\n-want to be able to cache results even when all the types in the trait\n-reference are not fully known. In that case, it may happen that the\n-trait selection process is also influencing type variables, so we have\n-to be able to not only cache the *result* of the selection process,\n-but *replay* its effects on the type variables.\n-\n-## An example\n-\n-The high-level idea of how the cache works is that we first replace\n-all unbound inference variables with skolemized versions. Therefore,\n-if we had a trait reference `uint : Foo<$1>`, where `$n` is an unbound\n-inference variable, we might replace it with `uint : Foo<%0>`, where\n-`%n` is a skolemized type. We would then look this up in the cache.\n-If we found a hit, the hit would tell us the immediate next step to\n-take in the selection process: i.e., apply impl #22, or apply where\n-clause `X : Foo<Y>`. Let's say in this case there is no hit.\n-Therefore, we search through impls and where clauses and so forth, and\n-we come to the conclusion that the only possible impl is this one,\n-with def-id 22:\n-\n-    impl Foo<int> for uint { ... } // Impl #22\n-\n-We would then record in the cache `uint : Foo<%0> ==>\n-ImplCandidate(22)`. Next we would confirm `ImplCandidate(22)`, which\n-would (as a side-effect) unify `$1` with `int`.\n-\n-Now, at some later time, we might come along and see a `uint :\n-Foo<$3>`.  When skolemized, this would yield `uint : Foo<%0>`, just as\n-before, and hence the cache lookup would succeed, yielding\n-`ImplCandidate(22)`. We would confirm `ImplCandidate(22)` which would\n-(as a side-effect) unify `$3` with `int`.\n-\n-## Where clauses and the local vs global cache\n-\n-One subtle interaction is that the results of trait lookup will vary\n-depending on what where clauses are in scope. Therefore, we actually\n-have *two* caches, a local and a global cache. The local cache is\n-attached to the `ParameterEnvironment` and the global cache attached\n-to the `tcx`. We use the local cache whenever the result might depend\n-on the where clauses that are in scope. The determination of which\n-cache to use is done by the method `pick_candidate_cache` in\n-`select.rs`.\n-\n-There are two cases where we currently use the local cache. The\n-current rules are probably more conservative than necessary.\n-\n-### Trait references that involve parameter types\n-\n-The most obvious case where you need the local environment is\n-when the trait reference includes parameter types. For example,\n-consider the following function:\n-\n-    impl<T> Vec<T> {\n-        fn foo(x: T)\n-            where T : Foo\n-        { ... }\n-\n-        fn bar(x: T)\n-        { ... }\n-    }\n-\n-If there is an obligation `T : Foo`, or `int : Bar<T>`, or whatever,\n-clearly the results from `foo` and `bar` are potentially different,\n-since the set of where clauses in scope are different.\n-\n-### Trait references with unbound variables when where clauses are in scope\n-\n-There is another less obvious interaction which involves unbound variables\n-where *only* where clauses are in scope (no impls). This manifested as\n-issue #18209 (`run-pass/trait-cache-issue-18209.rs`). Consider\n-this snippet:\n-\n-```\n-pub trait Foo {\n-    fn load_from() -> Box<Self>;\n-    fn load() -> Box<Self> {\n-        Foo::load_from()\n-    }\n-}\n-```\n-\n-The default method will incur an obligation `$0 : Foo` from the call\n-to `load_from`. If there are no impls, this can be eagerly resolved to\n-`VtableParam(Self : Foo)` and cached. Because the trait reference\n-doesn't involve any parameters types (only the resolution does), this\n-result was stored in the global cache, causing later calls to\n-`Foo::load_from()` to get nonsense.\n-\n-To fix this, we always use the local cache if there are unbound\n-variables and where clauses in scope. This is more conservative than\n-necessary as far as I can tell. However, it still seems to be a simple\n-rule and I observe ~99% hit rate on rustc, so it doesn't seem to hurt\n-us in particular.\n-\n-Here is an example of the kind of subtle case that I would be worried\n-about with a more complex rule (although this particular case works\n-out ok). Imagine the trait reference doesn't directly reference a\n-where clause, but the where clause plays a role in the winnowing\n-phase. Something like this:\n-\n-```\n-pub trait Foo<T> { ... }\n-pub trait Bar { ... }\n-impl<U,T:Bar> Foo<U> for T { ... } // Impl A\n-impl Foo<char> for uint { ... }    // Impl B\n-```\n-\n-Now, in some function, we have no where clauses in scope, and we have\n-an obligation `$1 : Foo<$0>`. We might then conclude that `$0=char`\n-and `$1=uint`: this is because for impl A to apply, `uint:Bar` would\n-have to hold, and we know it does not or else the coherence check\n-would have failed.  So we might enter into our global cache: `$1 :\n-Foo<$0> => Impl B`.  Then we come along in a different scope, where a\n-generic type `A` is around with the bound `A:Bar`. Now suddenly the\n-impl is viable.\n-\n-The flaw in this imaginary DOOMSDAY SCENARIO is that we would not\n-currently conclude that `$1 : Foo<$0>` implies that `$0 == uint` and\n-`$1 == char`, even though it is true that (absent type parameters)\n-there is no other type the user could enter. However, it is not\n-*completely* implausible that we *could* draw this conclusion in the\n-future; we wouldn't have to guess types, in particular, we could be\n-led by the impls.\n-\n-*/\n+//! # TRAIT RESOLUTION\n+//!\n+//! This document describes the general process and points out some non-obvious\n+//! things.\n+//!\n+//! ## Major concepts\n+//!\n+//! Trait resolution is the process of pairing up an impl with each\n+//! reference to a trait. So, for example, if there is a generic function like:\n+//!\n+//!     fn clone_slice<T:Clone>(x: &[T]) -> Vec<T> { ... }\n+//!\n+//! and then a call to that function:\n+//!\n+//!     let v: Vec<int> = clone_slice([1, 2, 3].as_slice())\n+//!\n+//! it is the job of trait resolution to figure out (in which case)\n+//! whether there exists an impl of `int : Clone`\n+//!\n+//! Note that in some cases, like generic functions, we may not be able to\n+//! find a specific impl, but we can figure out that the caller must\n+//! provide an impl. To see what I mean, consider the body of `clone_slice`:\n+//!\n+//!     fn clone_slice<T:Clone>(x: &[T]) -> Vec<T> {\n+//!         let mut v = Vec::new();\n+//!         for e in x.iter() {\n+//!             v.push((*e).clone()); // (*)\n+//!         }\n+//!     }\n+//!\n+//! The line marked `(*)` is only legal if `T` (the type of `*e`)\n+//! implements the `Clone` trait. Naturally, since we don't know what `T`\n+//! is, we can't find the specific impl; but based on the bound `T:Clone`,\n+//! we can say that there exists an impl which the caller must provide.\n+//!\n+//! We use the term *obligation* to refer to a trait reference in need of\n+//! an impl.\n+//!\n+//! ## Overview\n+//!\n+//! Trait resolution consists of three major parts:\n+//!\n+//! - SELECTION: Deciding how to resolve a specific obligation. For\n+//!   example, selection might decide that a specific obligation can be\n+//!   resolved by employing an impl which matches the self type, or by\n+//!   using a parameter bound. In the case of an impl, Selecting one\n+//!   obligation can create *nested obligations* because of where clauses\n+//!   on the impl itself. It may also require evaluating those nested\n+//!   obligations to resolve ambiguities.\n+//!\n+//! - FULFILLMENT: The fulfillment code is what tracks that obligations\n+//!   are completely fulfilled. Basically it is a worklist of obligations\n+//!   to be selected: once selection is successful, the obligation is\n+//!   removed from the worklist and any nested obligations are enqueued.\n+//!\n+//! - COHERENCE: The coherence checks are intended to ensure that there\n+//!   are never overlapping impls, where two impls could be used with\n+//!   equal precedence.\n+//!\n+//! ## Selection\n+//!\n+//! Selection is the process of deciding whether an obligation can be\n+//! resolved and, if so, how it is to be resolved (via impl, where clause, etc).\n+//! The main interface is the `select()` function, which takes an obligation\n+//! and returns a `SelectionResult`. There are three possible outcomes:\n+//!\n+//! - `Ok(Some(selection))` -- yes, the obligation can be resolved, and\n+//!   `selection` indicates how. If the impl was resolved via an impl,\n+//!   then `selection` may also indicate nested obligations that are required\n+//!   by the impl.\n+//!\n+//! - `Ok(None)` -- we are not yet sure whether the obligation can be\n+//!   resolved or not. This happens most commonly when the obligation\n+//!   contains unbound type variables.\n+//!\n+//! - `Err(err)` -- the obligation definitely cannot be resolved due to a\n+//!   type error, or because there are no impls that could possibly apply,\n+//!   etc.\n+//!\n+//! The basic algorithm for selection is broken into two big phases:\n+//! candidate assembly and confirmation.\n+//!\n+//! ### Candidate assembly\n+//!\n+//! Searches for impls/where-clauses/etc that might\n+//! possibly be used to satisfy the obligation. Each of those is called\n+//! a candidate. To avoid ambiguity, we want to find exactly one\n+//! candidate that is definitively applicable. In some cases, we may not\n+//! know whether an impl/where-clause applies or not -- this occurs when\n+//! the obligation contains unbound inference variables.\n+//!\n+//! The basic idea for candidate assembly is to do a first pass in which\n+//! we identify all possible candidates. During this pass, all that we do\n+//! is try and unify the type parameters. (In particular, we ignore any\n+//! nested where clauses.) Presuming that this unification succeeds, the\n+//! impl is added as a candidate.\n+//!\n+//! Once this first pass is done, we can examine the set of candidates. If\n+//! it is a singleton set, then we are done: this is the only impl in\n+//! scope that could possibly apply. Otherwise, we can winnow down the set\n+//! of candidates by using where clauses and other conditions. If this\n+//! reduced set yields a single, unambiguous entry, we're good to go,\n+//! otherwise the result is considered ambiguous.\n+//!\n+//! #### The basic process: Inferring based on the impls we see\n+//!\n+//! This process is easier if we work through some examples. Consider\n+//! the following trait:\n+//!\n+//! ```\n+//! trait Convert<Target> {\n+//!     fn convert(&self) -> Target;\n+//! }\n+//! ```\n+//!\n+//! This trait just has one method. It's about as simple as it gets. It\n+//! converts from the (implicit) `Self` type to the `Target` type. If we\n+//! wanted to permit conversion between `int` and `uint`, we might\n+//! implement `Convert` like so:\n+//!\n+//! ```rust\n+//! impl Convert<uint> for int { ... } // int -> uint\n+//! impl Convert<int> for uint { ... } // uint -> uint\n+//! ```\n+//!\n+//! Now imagine there is some code like the following:\n+//!\n+//! ```rust\n+//! let x: int = ...;\n+//! let y = x.convert();\n+//! ```\n+//!\n+//! The call to convert will generate a trait reference `Convert<$Y> for\n+//! int`, where `$Y` is the type variable representing the type of\n+//! `y`. When we match this against the two impls we can see, we will find\n+//! that only one remains: `Convert<uint> for int`. Therefore, we can\n+//! select this impl, which will cause the type of `$Y` to be unified to\n+//! `uint`. (Note that while assembling candidates, we do the initial\n+//! unifications in a transaction, so that they don't affect one another.)\n+//!\n+//! There are tests to this effect in src/test/run-pass:\n+//!\n+//!    traits-multidispatch-infer-convert-source-and-target.rs\n+//!    traits-multidispatch-infer-convert-target.rs\n+//!\n+//! #### Winnowing: Resolving ambiguities\n+//!\n+//! But what happens if there are multiple impls where all the types\n+//! unify? Consider this example:\n+//!\n+//! ```rust\n+//! trait Get {\n+//!     fn get(&self) -> Self;\n+//! }\n+//!\n+//! impl<T:Copy> Get for T {\n+//!     fn get(&self) -> T { *self }\n+//! }\n+//!\n+//! impl<T:Get> Get for Box<T> {\n+//!     fn get(&self) -> Box<T> { box get_it(&**self) }\n+//! }\n+//! ```\n+//!\n+//! What happens when we invoke `get_it(&box 1_u16)`, for example? In this\n+//! case, the `Self` type is `Box<u16>` -- that unifies with both impls,\n+//! because the first applies to all types, and the second to all\n+//! boxes. In the olden days we'd have called this ambiguous. But what we\n+//! do now is do a second *winnowing* pass that considers where clauses\n+//! and attempts to remove candidates -- in this case, the first impl only\n+//! applies if `Box<u16> : Copy`, which doesn't hold. After winnowing,\n+//! then, we are left with just one candidate, so we can proceed. There is\n+//! a test of this in `src/test/run-pass/traits-conditional-dispatch.rs`.\n+//!\n+//! #### Matching\n+//!\n+//! The subroutines that decide whether a particular impl/where-clause/etc\n+//! applies to a particular obligation. At the moment, this amounts to\n+//! unifying the self types, but in the future we may also recursively\n+//! consider some of the nested obligations, in the case of an impl.\n+//!\n+//! #### Lifetimes and selection\n+//!\n+//! Because of how that lifetime inference works, it is not possible to\n+//! give back immediate feedback as to whether a unification or subtype\n+//! relationship between lifetimes holds or not. Therefore, lifetime\n+//! matching is *not* considered during selection. This is reflected in\n+//! the fact that subregion assignment is infallible. This may yield\n+//! lifetime constraints that will later be found to be in error (in\n+//! contrast, the non-lifetime-constraints have already been checked\n+//! during selection and can never cause an error, though naturally they\n+//! may lead to other errors downstream).\n+//!\n+//! #### Where clauses\n+//!\n+//! Besides an impl, the other major way to resolve an obligation is via a\n+//! where clause. The selection process is always given a *parameter\n+//! environment* which contains a list of where clauses, which are\n+//! basically obligations that can assume are satisfiable. We will iterate\n+//! over that list and check whether our current obligation can be found\n+//! in that list, and if so it is considered satisfied. More precisely, we\n+//! want to check whether there is a where-clause obligation that is for\n+//! the same trait (or some subtrait) and for which the self types match,\n+//! using the definition of *matching* given above.\n+//!\n+//! Consider this simple example:\n+//!\n+//!      trait A1 { ... }\n+//!      trait A2 : A1 { ... }\n+//!\n+//!      trait B { ... }\n+//!\n+//!      fn foo<X:A2+B> { ... }\n+//!\n+//! Clearly we can use methods offered by `A1`, `A2`, or `B` within the\n+//! body of `foo`. In each case, that will incur an obligation like `X :\n+//! A1` or `X : A2`. The parameter environment will contain two\n+//! where-clauses, `X : A2` and `X : B`. For each obligation, then, we\n+//! search this list of where-clauses.  To resolve an obligation `X:A1`,\n+//! we would note that `X:A2` implies that `X:A1`.\n+//!\n+//! ### Confirmation\n+//!\n+//! Confirmation unifies the output type parameters of the trait with the\n+//! values found in the obligation, possibly yielding a type error.  If we\n+//! return to our example of the `Convert` trait from the previous\n+//! section, confirmation is where an error would be reported, because the\n+//! impl specified that `T` would be `uint`, but the obligation reported\n+//! `char`. Hence the result of selection would be an error.\n+//!\n+//! ### Selection during translation\n+//!\n+//! During type checking, we do not store the results of trait selection.\n+//! We simply wish to verify that trait selection will succeed. Then\n+//! later, at trans time, when we have all concrete types available, we\n+//! can repeat the trait selection.  In this case, we do not consider any\n+//! where-clauses to be in scope. We know that therefore each resolution\n+//! will resolve to a particular impl.\n+//!\n+//! One interesting twist has to do with nested obligations. In general, in trans,\n+//! we only need to do a \"shallow\" selection for an obligation. That is, we wish to\n+//! identify which impl applies, but we do not (yet) need to decide how to select\n+//! any nested obligations. Nonetheless, we *do* currently do a complete resolution,\n+//! and that is because it can sometimes inform the results of type inference. That is,\n+//! we do not have the full substitutions in terms of the type varibales of the impl available\n+//! to us, so we must run trait selection to figure everything out.\n+//!\n+//! Here is an example:\n+//!\n+//!     trait Foo { ... }\n+//!     impl<U,T:Bar<U>> Foo for Vec<T> { ... }\n+//!\n+//!     impl Bar<uint> for int { ... }\n+//!\n+//! After one shallow round of selection for an obligation like `Vec<int>\n+//! : Foo`, we would know which impl we want, and we would know that\n+//! `T=int`, but we do not know the type of `U`.  We must select the\n+//! nested obligation `int : Bar<U>` to find out that `U=uint`.\n+//!\n+//! It would be good to only do *just as much* nested resolution as\n+//! necessary. Currently, though, we just do a full resolution.\n+//!\n+//! ## Method matching\n+//!\n+//! Method dispach follows a slightly different path than normal trait\n+//! selection. This is because it must account for the transformed self\n+//! type of the receiver and various other complications. The procedure is\n+//! described in `select.rs` in the \"METHOD MATCHING\" section.\n+//!\n+//! # Caching and subtle considerations therewith\n+//!\n+//! In general we attempt to cache the results of trait selection.  This\n+//! is a somewhat complex process. Part of the reason for this is that we\n+//! want to be able to cache results even when all the types in the trait\n+//! reference are not fully known. In that case, it may happen that the\n+//! trait selection process is also influencing type variables, so we have\n+//! to be able to not only cache the *result* of the selection process,\n+//! but *replay* its effects on the type variables.\n+//!\n+//! ## An example\n+//!\n+//! The high-level idea of how the cache works is that we first replace\n+//! all unbound inference variables with skolemized versions. Therefore,\n+//! if we had a trait reference `uint : Foo<$1>`, where `$n` is an unbound\n+//! inference variable, we might replace it with `uint : Foo<%0>`, where\n+//! `%n` is a skolemized type. We would then look this up in the cache.\n+//! If we found a hit, the hit would tell us the immediate next step to\n+//! take in the selection process: i.e., apply impl #22, or apply where\n+//! clause `X : Foo<Y>`. Let's say in this case there is no hit.\n+//! Therefore, we search through impls and where clauses and so forth, and\n+//! we come to the conclusion that the only possible impl is this one,\n+//! with def-id 22:\n+//!\n+//!     impl Foo<int> for uint { ... } // Impl #22\n+//!\n+//! We would then record in the cache `uint : Foo<%0> ==>\n+//! ImplCandidate(22)`. Next we would confirm `ImplCandidate(22)`, which\n+//! would (as a side-effect) unify `$1` with `int`.\n+//!\n+//! Now, at some later time, we might come along and see a `uint :\n+//! Foo<$3>`.  When skolemized, this would yield `uint : Foo<%0>`, just as\n+//! before, and hence the cache lookup would succeed, yielding\n+//! `ImplCandidate(22)`. We would confirm `ImplCandidate(22)` which would\n+//! (as a side-effect) unify `$3` with `int`.\n+//!\n+//! ## Where clauses and the local vs global cache\n+//!\n+//! One subtle interaction is that the results of trait lookup will vary\n+//! depending on what where clauses are in scope. Therefore, we actually\n+//! have *two* caches, a local and a global cache. The local cache is\n+//! attached to the `ParameterEnvironment` and the global cache attached\n+//! to the `tcx`. We use the local cache whenever the result might depend\n+//! on the where clauses that are in scope. The determination of which\n+//! cache to use is done by the method `pick_candidate_cache` in\n+//! `select.rs`.\n+//!\n+//! There are two cases where we currently use the local cache. The\n+//! current rules are probably more conservative than necessary.\n+//!\n+//! ### Trait references that involve parameter types\n+//!\n+//! The most obvious case where you need the local environment is\n+//! when the trait reference includes parameter types. For example,\n+//! consider the following function:\n+//!\n+//!     impl<T> Vec<T> {\n+//!         fn foo(x: T)\n+//!             where T : Foo\n+//!         { ... }\n+//!\n+//!         fn bar(x: T)\n+//!         { ... }\n+//!     }\n+//!\n+//! If there is an obligation `T : Foo`, or `int : Bar<T>`, or whatever,\n+//! clearly the results from `foo` and `bar` are potentially different,\n+//! since the set of where clauses in scope are different.\n+//!\n+//! ### Trait references with unbound variables when where clauses are in scope\n+//!\n+//! There is another less obvious interaction which involves unbound variables\n+//! where *only* where clauses are in scope (no impls). This manifested as\n+//! issue #18209 (`run-pass/trait-cache-issue-18209.rs`). Consider\n+//! this snippet:\n+//!\n+//! ```\n+//! pub trait Foo {\n+//!     fn load_from() -> Box<Self>;\n+//!     fn load() -> Box<Self> {\n+//!         Foo::load_from()\n+//!     }\n+//! }\n+//! ```\n+//!\n+//! The default method will incur an obligation `$0 : Foo` from the call\n+//! to `load_from`. If there are no impls, this can be eagerly resolved to\n+//! `VtableParam(Self : Foo)` and cached. Because the trait reference\n+//! doesn't involve any parameters types (only the resolution does), this\n+//! result was stored in the global cache, causing later calls to\n+//! `Foo::load_from()` to get nonsense.\n+//!\n+//! To fix this, we always use the local cache if there are unbound\n+//! variables and where clauses in scope. This is more conservative than\n+//! necessary as far as I can tell. However, it still seems to be a simple\n+//! rule and I observe ~99% hit rate on rustc, so it doesn't seem to hurt\n+//! us in particular.\n+//!\n+//! Here is an example of the kind of subtle case that I would be worried\n+//! about with a more complex rule (although this particular case works\n+//! out ok). Imagine the trait reference doesn't directly reference a\n+//! where clause, but the where clause plays a role in the winnowing\n+//! phase. Something like this:\n+//!\n+//! ```\n+//! pub trait Foo<T> { ... }\n+//! pub trait Bar { ... }\n+//! impl<U,T:Bar> Foo<U> for T { ... } // Impl A\n+//! impl Foo<char> for uint { ... }    // Impl B\n+//! ```\n+//!\n+//! Now, in some function, we have no where clauses in scope, and we have\n+//! an obligation `$1 : Foo<$0>`. We might then conclude that `$0=char`\n+//! and `$1=uint`: this is because for impl A to apply, `uint:Bar` would\n+//! have to hold, and we know it does not or else the coherence check\n+//! would have failed.  So we might enter into our global cache: `$1 :\n+//! Foo<$0> => Impl B`.  Then we come along in a different scope, where a\n+//! generic type `A` is around with the bound `A:Bar`. Now suddenly the\n+//! impl is viable.\n+//!\n+//! The flaw in this imaginary DOOMSDAY SCENARIO is that we would not\n+//! currently conclude that `$1 : Foo<$0>` implies that `$0 == uint` and\n+//! `$1 == char`, even though it is true that (absent type parameters)\n+//! there is no other type the user could enter. However, it is not\n+//! *completely* implausible that we *could* draw this conclusion in the\n+//! future; we wouldn't have to guess types, in particular, we could be\n+//! led by the impls."}, {"sha": "bf4273dbfd0819dbc01df8c1d0593476d0a6bb49", "filename": "src/librustc/middle/traits/fulfill.rs", "status": "modified", "additions": 16, "deletions": 25, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Ffulfill.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Ffulfill.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Ffulfill.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -19,18 +19,16 @@ use super::FulfillmentError;\n use super::CodeSelectionError;\n use super::select::SelectionContext;\n \n-/**\n- * The fulfillment context is used to drive trait resolution.  It\n- * consists of a list of obligations that must be (eventually)\n- * satisfied. The job is to track which are satisfied, which yielded\n- * errors, and which are still pending. At any point, users can call\n- * `select_where_possible`, and the fulfilment context will try to do\n- * selection, retaining only those obligations that remain\n- * ambiguous. This may be helpful in pushing type inference\n- * along. Once all type inference constraints have been generated, the\n- * method `select_all_or_error` can be used to report any remaining\n- * ambiguous cases as errors.\n- */\n+/// The fulfillment context is used to drive trait resolution.  It\n+/// consists of a list of obligations that must be (eventually)\n+/// satisfied. The job is to track which are satisfied, which yielded\n+/// errors, and which are still pending. At any point, users can call\n+/// `select_where_possible`, and the fulfilment context will try to do\n+/// selection, retaining only those obligations that remain\n+/// ambiguous. This may be helpful in pushing type inference\n+/// along. Once all type inference constraints have been generated, the\n+/// method `select_all_or_error` can be used to report any remaining\n+/// ambiguous cases as errors.\n pub struct FulfillmentContext<'tcx> {\n     // A list of all obligations that have been registered with this\n     // fulfillment context.\n@@ -81,20 +79,16 @@ impl<'tcx> FulfillmentContext<'tcx> {\n         }\n     }\n \n+    /// Attempts to select obligations that were registered since the call to a selection routine.\n+    /// This is used by the type checker to eagerly attempt to resolve obligations in hopes of\n+    /// gaining type information. It'd be equally valid to use `select_where_possible` but it\n+    /// results in `O(n^2)` performance (#18208).\n     pub fn select_new_obligations<'a>(&mut self,\n                                       infcx: &InferCtxt<'a,'tcx>,\n                                       param_env: &ty::ParameterEnvironment<'tcx>,\n                                       typer: &Typer<'tcx>)\n                                       -> Result<(),Vec<FulfillmentError<'tcx>>>\n     {\n-        /*!\n-         * Attempts to select obligations that were registered since\n-         * the call to a selection routine. This is used by the type checker\n-         * to eagerly attempt to resolve obligations in hopes of gaining\n-         * type information. It'd be equally valid to use `select_where_possible`\n-         * but it results in `O(n^2)` performance (#18208).\n-         */\n-\n         let mut selcx = SelectionContext::new(infcx, param_env, typer);\n         self.select(&mut selcx, true)\n     }\n@@ -113,16 +107,13 @@ impl<'tcx> FulfillmentContext<'tcx> {\n         self.trait_obligations[]\n     }\n \n+    /// Attempts to select obligations using `selcx`. If `only_new_obligations` is true, then it\n+    /// only attempts to select obligations that haven't been seen before.\n     fn select<'a>(&mut self,\n                   selcx: &mut SelectionContext<'a, 'tcx>,\n                   only_new_obligations: bool)\n                   -> Result<(),Vec<FulfillmentError<'tcx>>>\n     {\n-        /*!\n-         * Attempts to select obligations using `selcx`. If\n-         * `only_new_obligations` is true, then it only attempts to\n-         * select obligations that haven't been seen before.\n-         */\n         debug!(\"select({} obligations, only_new_obligations={}) start\",\n                self.trait_obligations.len(),\n                only_new_obligations);"}, {"sha": "34278c25cfa0b1f6ea02a7d2045a97526475da30", "filename": "src/librustc/middle/traits/mod.rs", "status": "modified", "additions": 83, "deletions": 112, "changes": 195, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,9 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Trait Resolution. See doc.rs.\n- */\n+//! Trait Resolution. See doc.rs.\n \n pub use self::SelectionError::*;\n pub use self::FulfillmentErrorCode::*;\n@@ -42,24 +40,20 @@ mod fulfill;\n mod select;\n mod util;\n \n-/**\n- * An `Obligation` represents some trait reference (e.g. `int:Eq`) for\n- * which the vtable must be found.  The process of finding a vtable is\n- * called \"resolving\" the `Obligation`. This process consists of\n- * either identifying an `impl` (e.g., `impl Eq for int`) that\n- * provides the required vtable, or else finding a bound that is in\n- * scope. The eventual result is usually a `Selection` (defined below).\n- */\n+/// An `Obligation` represents some trait reference (e.g. `int:Eq`) for\n+/// which the vtable must be found.  The process of finding a vtable is\n+/// called \"resolving\" the `Obligation`. This process consists of\n+/// either identifying an `impl` (e.g., `impl Eq for int`) that\n+/// provides the required vtable, or else finding a bound that is in\n+/// scope. The eventual result is usually a `Selection` (defined below).\n #[deriving(Clone)]\n pub struct Obligation<'tcx> {\n     pub cause: ObligationCause<'tcx>,\n     pub recursion_depth: uint,\n     pub trait_ref: Rc<ty::TraitRef<'tcx>>,\n }\n \n-/**\n- * Why did we incur this obligation? Used for error reporting.\n- */\n+/// Why did we incur this obligation? Used for error reporting.\n #[deriving(Clone)]\n pub struct ObligationCause<'tcx> {\n     pub span: Span,\n@@ -121,57 +115,53 @@ pub enum FulfillmentErrorCode<'tcx> {\n     CodeAmbiguity,\n }\n \n-/**\n- * When performing resolution, it is typically the case that there\n- * can be one of three outcomes:\n- *\n- * - `Ok(Some(r))`: success occurred with result `r`\n- * - `Ok(None)`: could not definitely determine anything, usually due\n- *   to inconclusive type inference.\n- * - `Err(e)`: error `e` occurred\n- */\n+/// When performing resolution, it is typically the case that there\n+/// can be one of three outcomes:\n+///\n+/// - `Ok(Some(r))`: success occurred with result `r`\n+/// - `Ok(None)`: could not definitely determine anything, usually due\n+///   to inconclusive type inference.\n+/// - `Err(e)`: error `e` occurred\n pub type SelectionResult<'tcx, T> = Result<Option<T>, SelectionError<'tcx>>;\n \n-/**\n- * Given the successful resolution of an obligation, the `Vtable`\n- * indicates where the vtable comes from. Note that while we call this\n- * a \"vtable\", it does not necessarily indicate dynamic dispatch at\n- * runtime. `Vtable` instances just tell the compiler where to find\n- * methods, but in generic code those methods are typically statically\n- * dispatched -- only when an object is constructed is a `Vtable`\n- * instance reified into an actual vtable.\n- *\n- * For example, the vtable may be tied to a specific impl (case A),\n- * or it may be relative to some bound that is in scope (case B).\n- *\n- *\n- * ```\n- * impl<T:Clone> Clone<T> for Option<T> { ... } // Impl_1\n- * impl<T:Clone> Clone<T> for Box<T> { ... }    // Impl_2\n- * impl Clone for int { ... }             // Impl_3\n- *\n- * fn foo<T:Clone>(concrete: Option<Box<int>>,\n- *                 param: T,\n- *                 mixed: Option<T>) {\n- *\n- *    // Case A: Vtable points at a specific impl. Only possible when\n- *    // type is concretely known. If the impl itself has bounded\n- *    // type parameters, Vtable will carry resolutions for those as well:\n- *    concrete.clone(); // Vtable(Impl_1, [Vtable(Impl_2, [Vtable(Impl_3)])])\n- *\n- *    // Case B: Vtable must be provided by caller. This applies when\n- *    // type is a type parameter.\n- *    param.clone();    // VtableParam(Oblig_1)\n- *\n- *    // Case C: A mix of cases A and B.\n- *    mixed.clone();    // Vtable(Impl_1, [VtableParam(Oblig_1)])\n- * }\n- * ```\n- *\n- * ### The type parameter `N`\n- *\n- * See explanation on `VtableImplData`.\n- */\n+/// Given the successful resolution of an obligation, the `Vtable`\n+/// indicates where the vtable comes from. Note that while we call this\n+/// a \"vtable\", it does not necessarily indicate dynamic dispatch at\n+/// runtime. `Vtable` instances just tell the compiler where to find\n+/// methods, but in generic code those methods are typically statically\n+/// dispatched -- only when an object is constructed is a `Vtable`\n+/// instance reified into an actual vtable.\n+///\n+/// For example, the vtable may be tied to a specific impl (case A),\n+/// or it may be relative to some bound that is in scope (case B).\n+///\n+///\n+/// ```\n+/// impl<T:Clone> Clone<T> for Option<T> { ... } // Impl_1\n+/// impl<T:Clone> Clone<T> for Box<T> { ... }    // Impl_2\n+/// impl Clone for int { ... }             // Impl_3\n+///\n+/// fn foo<T:Clone>(concrete: Option<Box<int>>,\n+///                 param: T,\n+///                 mixed: Option<T>) {\n+///\n+///    // Case A: Vtable points at a specific impl. Only possible when\n+///    // type is concretely known. If the impl itself has bounded\n+///    // type parameters, Vtable will carry resolutions for those as well:\n+///    concrete.clone(); // Vtable(Impl_1, [Vtable(Impl_2, [Vtable(Impl_3)])])\n+///\n+///    // Case B: Vtable must be provided by caller. This applies when\n+///    // type is a type parameter.\n+///    param.clone();    // VtableParam(Oblig_1)\n+///\n+///    // Case C: A mix of cases A and B.\n+///    mixed.clone();    // Vtable(Impl_1, [VtableParam(Oblig_1)])\n+/// }\n+/// ```\n+///\n+/// ### The type parameter `N`\n+///\n+/// See explanation on `VtableImplData`.\n #[deriving(Show,Clone)]\n pub enum Vtable<'tcx, N> {\n     /// Vtable identifying a particular impl.\n@@ -191,18 +181,16 @@ pub enum Vtable<'tcx, N> {\n     VtableBuiltin(VtableBuiltinData<N>),\n }\n \n-/**\n- * Identifies a particular impl in the source, along with a set of\n- * substitutions from the impl's type/lifetime parameters. The\n- * `nested` vector corresponds to the nested obligations attached to\n- * the impl's type parameters.\n- *\n- * The type parameter `N` indicates the type used for \"nested\n- * obligations\" that are required by the impl. During type check, this\n- * is `Obligation`, as one might expect. During trans, however, this\n- * is `()`, because trans only requires a shallow resolution of an\n- * impl, and nested obligations are satisfied later.\n- */\n+/// Identifies a particular impl in the source, along with a set of\n+/// substitutions from the impl's type/lifetime parameters. The\n+/// `nested` vector corresponds to the nested obligations attached to\n+/// the impl's type parameters.\n+///\n+/// The type parameter `N` indicates the type used for \"nested\n+/// obligations\" that are required by the impl. During type check, this\n+/// is `Obligation`, as one might expect. During trans, however, this\n+/// is `()`, because trans only requires a shallow resolution of an\n+/// impl, and nested obligations are satisfied later.\n #[deriving(Clone)]\n pub struct VtableImplData<'tcx, N> {\n     pub impl_def_id: ast::DefId,\n@@ -215,17 +203,19 @@ pub struct VtableBuiltinData<N> {\n     pub nested: subst::VecPerParamSpace<N>\n }\n \n-/**\n- * A vtable provided as a parameter by the caller. For example, in a\n- * function like `fn foo<T:Eq>(...)`, if the `eq()` method is invoked\n- * on an instance of `T`, the vtable would be of type `VtableParam`.\n- */\n+/// A vtable provided as a parameter by the caller. For example, in a\n+/// function like `fn foo<T:Eq>(...)`, if the `eq()` method is invoked\n+/// on an instance of `T`, the vtable would be of type `VtableParam`.\n #[deriving(PartialEq,Eq,Clone)]\n pub struct VtableParamData<'tcx> {\n     // In the above example, this would `Eq`\n     pub bound: Rc<ty::TraitRef<'tcx>>,\n }\n \n+/// Matches the self type of the inherent impl `impl_def_id`\n+/// against `self_ty` and returns the resulting resolution.  This\n+/// routine may modify the surrounding type context (for example,\n+/// it may unify variables).\n pub fn select_inherent_impl<'a,'tcx>(infcx: &InferCtxt<'a,'tcx>,\n                                      param_env: &ty::ParameterEnvironment<'tcx>,\n                                      typer: &Typer<'tcx>,\n@@ -235,13 +225,6 @@ pub fn select_inherent_impl<'a,'tcx>(infcx: &InferCtxt<'a,'tcx>,\n                                      -> SelectionResult<'tcx,\n                                             VtableImplData<'tcx, Obligation<'tcx>>>\n {\n-    /*!\n-     * Matches the self type of the inherent impl `impl_def_id`\n-     * against `self_ty` and returns the resulting resolution.  This\n-     * routine may modify the surrounding type context (for example,\n-     * it may unify variables).\n-     */\n-\n     // This routine is only suitable for inherent impls. This is\n     // because it does not attempt to unify the output type parameters\n     // from the trait ref against the values from the obligation.\n@@ -256,53 +239,41 @@ pub fn select_inherent_impl<'a,'tcx>(infcx: &InferCtxt<'a,'tcx>,\n     selcx.select_inherent_impl(impl_def_id, cause, self_ty)\n }\n \n+/// True if neither the trait nor self type is local. Note that `impl_def_id` must refer to an impl\n+/// of a trait, not an inherent impl.\n pub fn is_orphan_impl(tcx: &ty::ctxt,\n                       impl_def_id: ast::DefId)\n                       -> bool\n {\n-    /*!\n-     * True if neither the trait nor self type is local. Note that\n-     * `impl_def_id` must refer to an impl of a trait, not an inherent\n-     * impl.\n-     */\n-\n     !coherence::impl_is_local(tcx, impl_def_id)\n }\n \n+/// True if there exist types that satisfy both of the two given impls.\n pub fn overlapping_impls(infcx: &InferCtxt,\n                          impl1_def_id: ast::DefId,\n                          impl2_def_id: ast::DefId)\n                          -> bool\n {\n-    /*!\n-     * True if there exist types that satisfy both of the two given impls.\n-     */\n-\n     coherence::impl_can_satisfy(infcx, impl1_def_id, impl2_def_id) &&\n     coherence::impl_can_satisfy(infcx, impl2_def_id, impl1_def_id)\n }\n \n+/// Given generic bounds from an impl like:\n+///\n+///    impl<A:Foo, B:Bar+Qux> ...\n+///\n+/// along with the bindings for the types `A` and `B` (e.g., `<A=A0, B=B0>`), yields a result like\n+///\n+///    [[Foo for A0, Bar for B0, Qux for B0], [], []]\n+///\n+/// Expects that `generic_bounds` have already been fully substituted, late-bound regions liberated\n+/// and so forth, so that they are in the same namespace as `type_substs`.\n pub fn obligations_for_generics<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                       cause: ObligationCause<'tcx>,\n                                       generic_bounds: &ty::GenericBounds<'tcx>,\n                                       type_substs: &subst::VecPerParamSpace<Ty<'tcx>>)\n                                       -> subst::VecPerParamSpace<Obligation<'tcx>>\n {\n-    /*!\n-     * Given generic bounds from an impl like:\n-     *\n-     *    impl<A:Foo, B:Bar+Qux> ...\n-     *\n-     * along with the bindings for the types `A` and `B` (e.g.,\n-     * `<A=A0, B=B0>`), yields a result like\n-     *\n-     *    [[Foo for A0, Bar for B0, Qux for B0], [], []]\n-     *\n-     * Expects that `generic_bounds` have already been fully\n-     * substituted, late-bound regions liberated and so forth,\n-     * so that they are in the same namespace as `type_substs`.\n-     */\n-\n     util::obligations_for_generics(tcx, cause, 0, generic_bounds, type_substs)\n }\n "}, {"sha": "9ce6947731dc1e0c681adeefb3ce17c86cd4b9dc", "filename": "src/librustc/middle/traits/select.rs", "status": "modified", "additions": 131, "deletions": 201, "changes": 332, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fselect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Fselect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Fselect.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! See `doc.rs` for high-level documentation */\n+//! See `doc.rs` for high-level documentation\n #![allow(dead_code)] // FIXME -- just temporarily\n \n pub use self::MethodMatchResult::*;\n@@ -43,7 +43,7 @@ use util::ppaux::Repr;\n pub struct SelectionContext<'cx, 'tcx:'cx> {\n     infcx: &'cx InferCtxt<'cx, 'tcx>,\n     param_env: &'cx ty::ParameterEnvironment<'tcx>,\n-    typer: &'cx Typer<'tcx>+'cx,\n+    typer: &'cx (Typer<'tcx>+'cx),\n \n     /// Skolemizer used specifically for skolemizing entries on the\n     /// obligation stack. This ensures that all entries on the stack\n@@ -102,32 +102,30 @@ pub enum MethodMatchedData {\n     CoerciveMethodMatch(/* impl we matched */ ast::DefId)\n }\n \n-/**\n- * The selection process begins by considering all impls, where\n- * clauses, and so forth that might resolve an obligation.  Sometimes\n- * we'll be able to say definitively that (e.g.) an impl does not\n- * apply to the obligation: perhaps it is defined for `uint` but the\n- * obligation is for `int`. In that case, we drop the impl out of the\n- * list.  But the other cases are considered *candidates*.\n- *\n- * Candidates can either be definitive or ambiguous. An ambiguous\n- * candidate is one that might match or might not, depending on how\n- * type variables wind up being resolved. This only occurs during inference.\n- *\n- * For selection to suceed, there must be exactly one non-ambiguous\n- * candidate.  Usually, it is not possible to have more than one\n- * definitive candidate, due to the coherence rules. However, there is\n- * one case where it could occur: if there is a blanket impl for a\n- * trait (that is, an impl applied to all T), and a type parameter\n- * with a where clause. In that case, we can have a candidate from the\n- * where clause and a second candidate from the impl. This is not a\n- * problem because coherence guarantees us that the impl which would\n- * be used to satisfy the where clause is the same one that we see\n- * now. To resolve this issue, therefore, we ignore impls if we find a\n- * matching where clause. Part of the reason for this is that where\n- * clauses can give additional information (like, the types of output\n- * parameters) that would have to be inferred from the impl.\n- */\n+/// The selection process begins by considering all impls, where\n+/// clauses, and so forth that might resolve an obligation.  Sometimes\n+/// we'll be able to say definitively that (e.g.) an impl does not\n+/// apply to the obligation: perhaps it is defined for `uint` but the\n+/// obligation is for `int`. In that case, we drop the impl out of the\n+/// list.  But the other cases are considered *candidates*.\n+///\n+/// Candidates can either be definitive or ambiguous. An ambiguous\n+/// candidate is one that might match or might not, depending on how\n+/// type variables wind up being resolved. This only occurs during inference.\n+///\n+/// For selection to suceed, there must be exactly one non-ambiguous\n+/// candidate.  Usually, it is not possible to have more than one\n+/// definitive candidate, due to the coherence rules. However, there is\n+/// one case where it could occur: if there is a blanket impl for a\n+/// trait (that is, an impl applied to all T), and a type parameter\n+/// with a where clause. In that case, we can have a candidate from the\n+/// where clause and a second candidate from the impl. This is not a\n+/// problem because coherence guarantees us that the impl which would\n+/// be used to satisfy the where clause is the same one that we see\n+/// now. To resolve this issue, therefore, we ignore impls if we find a\n+/// matching where clause. Part of the reason for this is that where\n+/// clauses can give additional information (like, the types of output\n+/// parameters) that would have to be inferred from the impl.\n #[deriving(PartialEq,Eq,Show,Clone)]\n enum Candidate<'tcx> {\n     BuiltinCandidate(ty::BuiltinBound),\n@@ -201,15 +199,11 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n     //    is `Vec<Foo>:Iterable<Bar>`, but the impl specifies\n     //    `impl<T> Iterable<T> for Vec<T>`, than an error would result.\n \n+    /// Evaluates whether the obligation can be satisfied. Returns an indication of whether the\n+    /// obligation can be satisfied and, if so, by what means. Never affects surrounding typing\n+    /// environment.\n     pub fn select(&mut self, obligation: &Obligation<'tcx>)\n                   -> SelectionResult<'tcx, Selection<'tcx>> {\n-        /*!\n-         * Evaluates whether the obligation can be satisfied. Returns\n-         * an indication of whether the obligation can be satisfied\n-         * and, if so, by what means. Never affects surrounding typing\n-         * environment.\n-         */\n-\n         debug!(\"select({})\", obligation.repr(self.tcx()));\n         assert!(!obligation.trait_ref.has_escaping_regions());\n \n@@ -253,15 +247,11 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n     // The result is \"true\" if the obligation *may* hold and \"false\" if\n     // we can be sure it does not.\n \n+    /// Evaluates whether the obligation `obligation` can be satisfied (by any means).\n     pub fn evaluate_obligation(&mut self,\n                                obligation: &Obligation<'tcx>)\n                                -> bool\n     {\n-        /*!\n-         * Evaluates whether the obligation `obligation` can be\n-         * satisfied (by any means).\n-         */\n-\n         debug!(\"evaluate_obligation({})\",\n                obligation.repr(self.tcx()));\n         assert!(!obligation.trait_ref.has_escaping_regions());\n@@ -387,17 +377,13 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         }\n     }\n \n+    /// Evaluates whether the impl with id `impl_def_id` could be applied to the self type\n+    /// `obligation_self_ty`. This can be used either for trait or inherent impls.\n     pub fn evaluate_impl(&mut self,\n                          impl_def_id: ast::DefId,\n                          obligation: &Obligation<'tcx>)\n                          -> bool\n     {\n-        /*!\n-         * Evaluates whether the impl with id `impl_def_id` could be\n-         * applied to the self type `obligation_self_ty`. This can be\n-         * used either for trait or inherent impls.\n-         */\n-\n         debug!(\"evaluate_impl(impl_def_id={}, obligation={})\",\n                impl_def_id.repr(self.tcx()),\n                obligation.repr(self.tcx()));\n@@ -435,23 +421,20 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n     // the body of `evaluate_method_obligation()` for more details on\n     // the algorithm.\n \n+    /// Determine whether a trait-method is applicable to a receiver of\n+    /// type `rcvr_ty`. *Does not affect the inference state.*\n+    ///\n+    /// - `rcvr_ty` -- type of the receiver\n+    /// - `xform_self_ty` -- transformed self type declared on the method, with `Self`\n+    ///   to a fresh type variable\n+    /// - `obligation` -- a reference to the trait where the method is declared, with\n+    ///   the input types on the trait replaced with fresh type variables\n     pub fn evaluate_method_obligation(&mut self,\n                                       rcvr_ty: Ty<'tcx>,\n                                       xform_self_ty: Ty<'tcx>,\n                                       obligation: &Obligation<'tcx>)\n                                       -> MethodMatchResult\n     {\n-        /*!\n-         * Determine whether a trait-method is applicable to a receiver of\n-         * type `rcvr_ty`. *Does not affect the inference state.*\n-         *\n-         * - `rcvr_ty` -- type of the receiver\n-         * - `xform_self_ty` -- transformed self type declared on the method, with `Self`\n-         *   to a fresh type variable\n-         * - `obligation` -- a reference to the trait where the method is declared, with\n-         *   the input types on the trait replaced with fresh type variables\n-         */\n-\n         // Here is the situation. We have a trait method declared (say) like so:\n         //\n         //     trait TheTrait {\n@@ -563,19 +546,15 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         }\n     }\n \n+    /// Given the successful result of a method match, this function \"confirms\" the result, which\n+    /// basically repeats the various matching operations, but outside of any snapshot so that\n+    /// their effects are committed into the inference state.\n     pub fn confirm_method_match(&mut self,\n                                 rcvr_ty: Ty<'tcx>,\n                                 xform_self_ty: Ty<'tcx>,\n                                 obligation: &Obligation<'tcx>,\n                                 data: MethodMatchedData)\n     {\n-        /*!\n-         * Given the successful result of a method match, this\n-         * function \"confirms\" the result, which basically repeats the\n-         * various matching operations, but outside of any snapshot so\n-         * that their effects are committed into the inference state.\n-         */\n-\n         let is_ok = match data {\n             PreciseMethodMatch => {\n                 self.match_method_precise(rcvr_ty, xform_self_ty, obligation).is_ok()\n@@ -597,17 +576,14 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         }\n     }\n \n+    /// Implements the *precise method match* procedure described in\n+    /// `evaluate_method_obligation()`.\n     fn match_method_precise(&mut self,\n                             rcvr_ty: Ty<'tcx>,\n                             xform_self_ty: Ty<'tcx>,\n                             obligation: &Obligation<'tcx>)\n                             -> Result<(),()>\n     {\n-        /*!\n-         * Implements the *precise method match* procedure described in\n-         * `evaluate_method_obligation()`.\n-         */\n-\n         self.infcx.commit_if_ok(|| {\n             match self.infcx.sub_types(false, infer::RelateSelfType(obligation.cause.span),\n                                        rcvr_ty, xform_self_ty) {\n@@ -623,18 +599,14 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         })\n     }\n \n+    /// Assembles a list of potentially applicable impls using the *coercive match* procedure\n+    /// described in `evaluate_method_obligation()`.\n     fn assemble_method_candidates_from_impls(&mut self,\n                                              rcvr_ty: Ty<'tcx>,\n                                              xform_self_ty: Ty<'tcx>,\n                                              obligation: &Obligation<'tcx>)\n                                              -> Vec<ast::DefId>\n     {\n-        /*!\n-         * Assembles a list of potentially applicable impls using the\n-         * *coercive match* procedure described in\n-         * `evaluate_method_obligation()`.\n-         */\n-\n         let mut candidates = Vec::new();\n \n         let all_impls = self.all_impls(obligation.trait_ref.def_id);\n@@ -650,18 +622,15 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         candidates\n     }\n \n+    /// Applies the *coercive match* procedure described in `evaluate_method_obligation()` to a\n+    /// particular impl.\n     fn match_method_coerce(&mut self,\n                            impl_def_id: ast::DefId,\n                            rcvr_ty: Ty<'tcx>,\n                            xform_self_ty: Ty<'tcx>,\n                            obligation: &Obligation<'tcx>)\n                            -> Result<Substs<'tcx>, ()>\n     {\n-        /*!\n-         * Applies the *coercive match* procedure described in\n-         * `evaluate_method_obligation()` to a particular impl.\n-         */\n-\n         // This is almost always expected to succeed. It\n         // causes the impl's self-type etc to be unified with\n         // the type variable that is shared between\n@@ -683,20 +652,15 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         Ok(substs)\n     }\n \n+    /// A version of `winnow_impl` applicable to coerice method matching.  This is basically the\n+    /// same as `winnow_impl` but it uses the method matching procedure and is specific to impls.\n     fn winnow_method_impl(&mut self,\n                           impl_def_id: ast::DefId,\n                           rcvr_ty: Ty<'tcx>,\n                           xform_self_ty: Ty<'tcx>,\n                           obligation: &Obligation<'tcx>)\n                           -> bool\n     {\n-        /*!\n-         * A version of `winnow_impl` applicable to coerice method\n-         * matching.  This is basically the same as `winnow_impl` but\n-         * it uses the method matching procedure and is specific to\n-         * impls.\n-         */\n-\n         debug!(\"winnow_method_impl: impl_def_id={} rcvr_ty={} xform_self_ty={} obligation={}\",\n                impl_def_id.repr(self.tcx()),\n                rcvr_ty.repr(self.tcx()),\n@@ -962,19 +926,15 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         Ok(candidates)\n     }\n \n+    /// Given an obligation like `<SomeTrait for T>`, search the obligations that the caller\n+    /// supplied to find out whether it is listed among them.\n+    ///\n+    /// Never affects inference environment.\n     fn assemble_candidates_from_caller_bounds(&mut self,\n                                               obligation: &Obligation<'tcx>,\n                                               candidates: &mut CandidateSet<'tcx>)\n                                               -> Result<(),SelectionError<'tcx>>\n     {\n-        /*!\n-         * Given an obligation like `<SomeTrait for T>`, search the obligations\n-         * that the caller supplied to find out whether it is listed among\n-         * them.\n-         *\n-         * Never affects inference environment.\n-         */\n-\n         debug!(\"assemble_candidates_from_caller_bounds({})\",\n                obligation.repr(self.tcx()));\n \n@@ -1002,22 +962,17 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         Ok(())\n     }\n \n+    /// Check for the artificial impl that the compiler will create for an obligation like `X :\n+    /// FnMut<..>` where `X` is an unboxed closure type.\n+    ///\n+    /// Note: the type parameters on an unboxed closure candidate are modeled as *output* type\n+    /// parameters and hence do not affect whether this trait is a match or not. They will be\n+    /// unified during the confirmation step.\n     fn assemble_unboxed_candidates(&mut self,\n                                    obligation: &Obligation<'tcx>,\n                                    candidates: &mut CandidateSet<'tcx>)\n                                    -> Result<(),SelectionError<'tcx>>\n     {\n-        /*!\n-         * Check for the artificial impl that the compiler will create\n-         * for an obligation like `X : FnMut<..>` where `X` is an\n-         * unboxed closure type.\n-         *\n-         * Note: the type parameters on an unboxed closure candidate\n-         * are modeled as *output* type parameters and hence do not\n-         * affect whether this trait is a match or not. They will be\n-         * unified during the confirmation step.\n-         */\n-\n         let tcx = self.tcx();\n         let kind = if Some(obligation.trait_ref.def_id) == tcx.lang_items.fn_trait() {\n             ty::FnUnboxedClosureKind\n@@ -1060,15 +1015,12 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         Ok(())\n     }\n \n+    /// Search for impls that might apply to `obligation`.\n     fn assemble_candidates_from_impls(&mut self,\n                                       obligation: &Obligation<'tcx>,\n                                       candidates: &mut CandidateSet<'tcx>)\n                                       -> Result<(), SelectionError<'tcx>>\n     {\n-        /*!\n-         * Search for impls that might apply to `obligation`.\n-         */\n-\n         let all_impls = self.all_impls(obligation.trait_ref.def_id);\n         for &impl_def_id in all_impls.iter() {\n             self.infcx.probe(|| {\n@@ -1092,17 +1044,14 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n     // attempt to evaluate recursive bounds to see if they are\n     // satisfied.\n \n+    /// Further evaluate `candidate` to decide whether all type parameters match and whether nested\n+    /// obligations are met. Returns true if `candidate` remains viable after this further\n+    /// scrutiny.\n     fn winnow_candidate<'o>(&mut self,\n                             stack: &ObligationStack<'o, 'tcx>,\n                             candidate: &Candidate<'tcx>)\n                             -> EvaluationResult\n     {\n-        /*!\n-         * Further evaluate `candidate` to decide whether all type parameters match\n-         * and whether nested obligations are met. Returns true if `candidate` remains\n-         * viable after this further scrutiny.\n-         */\n-\n         debug!(\"winnow_candidate: candidate={}\", candidate.repr(self.tcx()));\n         self.infcx.probe(|| {\n             let candidate = (*candidate).clone();\n@@ -1129,37 +1078,35 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         result\n     }\n \n+    /// Returns true if `candidate_i` should be dropped in favor of `candidate_j`.\n+    ///\n+    /// This is generally true if either:\n+    /// - candidate i and candidate j are equivalent; or,\n+    /// - candidate i is a conrete impl and candidate j is a where clause bound,\n+    ///   and the concrete impl is applicable to the types in the where clause bound.\n+    ///\n+    /// The last case refers to cases where there are blanket impls (often conditional\n+    /// blanket impls) as well as a where clause. This can come down to one of two cases:\n+    ///\n+    /// - The impl is truly unconditional (it has no where clauses\n+    ///   of its own), in which case the where clause is\n+    ///   unnecessary, because coherence requires that we would\n+    ///   pick that particular impl anyhow (at least so long as we\n+    ///   don't have specialization).\n+    ///\n+    /// - The impl is conditional, in which case we may not have winnowed it out\n+    ///   because we don't know if the conditions apply, but the where clause is basically\n+    ///   telling us taht there is some impl, though not necessarily the one we see.\n+    ///\n+    /// In both cases we prefer to take the where clause, which is\n+    /// essentially harmless.  See issue #18453 for more details of\n+    /// a case where doing the opposite caused us harm.\n     fn candidate_should_be_dropped_in_favor_of<'o>(&mut self,\n                                                    stack: &ObligationStack<'o, 'tcx>,\n                                                    candidate_i: &Candidate<'tcx>,\n                                                    candidate_j: &Candidate<'tcx>)\n                                                    -> bool\n     {\n-        /*!\n-         * Returns true if `candidate_i` should be dropped in favor of `candidate_j`.\n-         * This is generally true if either:\n-         * - candidate i and candidate j are equivalent; or,\n-         * - candidate i is a conrete impl and candidate j is a where clause bound,\n-         *   and the concrete impl is applicable to the types in the where clause bound.\n-         *\n-         * The last case refers to cases where there are blanket impls (often conditional\n-         * blanket impls) as well as a where clause. This can come down to one of two cases:\n-         *\n-         * - The impl is truly unconditional (it has no where clauses\n-         *   of its own), in which case the where clause is\n-         *   unnecessary, because coherence requires that we would\n-         *   pick that particular impl anyhow (at least so long as we\n-         *   don't have specialization).\n-         *\n-         * - The impl is conditional, in which case we may not have winnowed it out\n-         *   because we don't know if the conditions apply, but the where clause is basically\n-         *   telling us taht there is some impl, though not necessarily the one we see.\n-         *\n-         * In both cases we prefer to take the where clause, which is\n-         * essentially harmless.  See issue #18453 for more details of\n-         * a case where doing the opposite caused us harm.\n-         */\n-\n         match (candidate_i, candidate_j) {\n             (&ImplCandidate(impl_def_id), &ParamCandidate(ref vt)) => {\n                 debug!(\"Considering whether to drop param {} in favor of impl {}\",\n@@ -1848,26 +1795,23 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         }\n     }\n \n+    /// Determines whether the self type declared against\n+    /// `impl_def_id` matches `obligation_self_ty`. If successful,\n+    /// returns the substitutions used to make them match. See\n+    /// `match_impl()`. For example, if `impl_def_id` is declared\n+    /// as:\n+    ///\n+    ///    impl<T:Copy> Foo for ~T { ... }\n+    ///\n+    /// and `obligation_self_ty` is `int`, we'd back an `Err(_)`\n+    /// result. But if `obligation_self_ty` were `~int`, we'd get\n+    /// back `Ok(T=int)`.\n     fn match_inherent_impl(&mut self,\n                            impl_def_id: ast::DefId,\n                            obligation_cause: ObligationCause,\n                            obligation_self_ty: Ty<'tcx>)\n                            -> Result<Substs<'tcx>,()>\n     {\n-        /*!\n-         * Determines whether the self type declared against\n-         * `impl_def_id` matches `obligation_self_ty`. If successful,\n-         * returns the substitutions used to make them match. See\n-         * `match_impl()`.  For example, if `impl_def_id` is declared\n-         * as:\n-         *\n-         *    impl<T:Copy> Foo for ~T { ... }\n-         *\n-         * and `obligation_self_ty` is `int`, we'd back an `Err(_)`\n-         * result. But if `obligation_self_ty` were `~int`, we'd get\n-         * back `Ok(T=int)`.\n-         */\n-\n         // Create fresh type variables for each type parameter declared\n         // on the impl etc.\n         let impl_substs = util::fresh_substs_for_impl(self.infcx,\n@@ -1928,68 +1872,57 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n     // the output type parameters from the obligation with those found\n     // on the impl/bound, which may yield type errors.\n \n+    /// Relates the output type parameters from an impl to the\n+    /// trait.  This may lead to type errors. The confirmation step\n+    /// is separated from the main match procedure because these\n+    /// type errors do not cause us to select another impl.\n+    ///\n+    /// As an example, consider matching the obligation\n+    /// `Iterator<char> for Elems<int>` using the following impl:\n+    ///\n+    ///    impl<T> Iterator<T> for Elems<T> { ... }\n+    ///\n+    /// The match phase will succeed with substitution `T=int`.\n+    /// The confirm step will then try to unify `int` and `char`\n+    /// and yield an error.\n     fn confirm_impl_vtable(&mut self,\n                            impl_def_id: ast::DefId,\n                            obligation_cause: ObligationCause<'tcx>,\n                            obligation_trait_ref: Rc<ty::TraitRef<'tcx>>,\n                            substs: &Substs<'tcx>)\n                            -> Result<(), SelectionError<'tcx>>\n     {\n-        /*!\n-         * Relates the output type parameters from an impl to the\n-         * trait.  This may lead to type errors. The confirmation step\n-         * is separated from the main match procedure because these\n-         * type errors do not cause us to select another impl.\n-         *\n-         * As an example, consider matching the obligation\n-         * `Iterator<char> for Elems<int>` using the following impl:\n-         *\n-         *    impl<T> Iterator<T> for Elems<T> { ... }\n-         *\n-         * The match phase will succeed with substitution `T=int`.\n-         * The confirm step will then try to unify `int` and `char`\n-         * and yield an error.\n-         */\n-\n         let impl_trait_ref = ty::impl_trait_ref(self.tcx(),\n                                                 impl_def_id).unwrap();\n         let impl_trait_ref = impl_trait_ref.subst(self.tcx(),\n                                                   substs);\n         self.confirm(obligation_cause, obligation_trait_ref, impl_trait_ref)\n     }\n \n+    /// After we have determined which impl applies, and with what substitutions, there is one last\n+    /// step. We have to go back and relate the \"output\" type parameters from the obligation to the\n+    /// types that are specified in the impl.\n+    ///\n+    /// For example, imagine we have:\n+    ///\n+    ///     impl<T> Iterator<T> for Vec<T> { ... }\n+    ///\n+    /// and our obligation is `Iterator<Foo> for Vec<int>` (note the mismatch in the obligation\n+    /// types). Up until this step, no error would be reported: the self type is `Vec<int>`, and\n+    /// that matches `Vec<T>` with the substitution `T=int`. At this stage, we could then go and\n+    /// check that the type parameters to the `Iterator` trait match. (In terms of the parameters,\n+    /// the `expected_trait_ref` here would be `Iterator<int> for Vec<int>`, and the\n+    /// `obligation_trait_ref` would be `Iterator<Foo> for Vec<int>`.\n+    ///\n+    /// Note that this checking occurs *after* the impl has selected, because these output type\n+    /// parameters should not affect the selection of the impl. Therefore, if there is a mismatch,\n+    /// we report an error to the user.\n     fn confirm(&mut self,\n                obligation_cause: ObligationCause,\n                obligation_trait_ref: Rc<ty::TraitRef<'tcx>>,\n                expected_trait_ref: Rc<ty::TraitRef<'tcx>>)\n                -> Result<(), SelectionError<'tcx>>\n     {\n-        /*!\n-         * After we have determined which impl applies, and with what\n-         * substitutions, there is one last step. We have to go back\n-         * and relate the \"output\" type parameters from the obligation\n-         * to the types that are specified in the impl.\n-         *\n-         * For example, imagine we have:\n-         *\n-         *     impl<T> Iterator<T> for Vec<T> { ... }\n-         *\n-         * and our obligation is `Iterator<Foo> for Vec<int>` (note\n-         * the mismatch in the obligation types). Up until this step,\n-         * no error would be reported: the self type is `Vec<int>`,\n-         * and that matches `Vec<T>` with the substitution `T=int`.\n-         * At this stage, we could then go and check that the type\n-         * parameters to the `Iterator` trait match.\n-         * (In terms of the parameters, the `expected_trait_ref`\n-         * here would be `Iterator<int> for Vec<int>`, and the\n-         * `obligation_trait_ref` would be `Iterator<Foo> for Vec<int>`.\n-         *\n-         * Note that this checking occurs *after* the impl has\n-         * selected, because these output type parameters should not\n-         * affect the selection of the impl. Therefore, if there is a\n-         * mismatch, we report an error to the user.\n-         */\n-\n         let origin = infer::RelateOutputImplTypes(obligation_cause.span);\n \n         let obligation_trait_ref = obligation_trait_ref.clone();\n@@ -2019,11 +1952,8 @@ impl<'cx, 'tcx> SelectionContext<'cx, 'tcx> {\n         }\n     }\n \n+    /// Returns set of all impls for a given trait.\n     fn all_impls(&self, trait_def_id: ast::DefId) -> Vec<ast::DefId> {\n-        /*!\n-         * Returns set of all impls for a given trait.\n-         */\n-\n         ty::populate_implementations_for_trait_if_necessary(self.tcx(),\n                                                             trait_def_id);\n         match self.tcx().trait_impls.borrow().get(&trait_def_id) {"}, {"sha": "cd7260b1812a33f9e5a4965e2ef18e20ebcdef0c", "filename": "src/librustc/middle/traits/util.rs", "status": "modified", "additions": 18, "deletions": 30, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftraits%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftraits%2Futil.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -42,21 +42,18 @@ pub fn supertraits<'cx, 'tcx>(tcx: &'cx ty::ctxt<'tcx>,\n                               trait_ref: Rc<ty::TraitRef<'tcx>>)\n                               -> Supertraits<'cx, 'tcx>\n {\n-    /*!\n-     * Returns an iterator over the trait reference `T` and all of its\n-     * supertrait references. May contain duplicates. In general\n-     * the ordering is not defined.\n-     *\n-     * Example:\n-     *\n-     * ```\n-     * trait Foo { ... }\n-     * trait Bar : Foo { ... }\n-     * trait Baz : Bar+Foo { ... }\n-     * ```\n-     *\n-     * `supertraits(Baz)` yields `[Baz, Bar, Foo, Foo]` in some order.\n-     */\n+    //! Returns an iterator over the trait reference `T` and all of its supertrait references. May\n+    //! contain duplicates. In general the ordering is not defined.\n+    //!\n+    //! Example:\n+    //!\n+    //! ```\n+    //! trait Foo { ... }\n+    //! trait Bar : Foo { ... }\n+    //! trait Baz : Bar+Foo { ... }\n+    //! ```\n+    //!\n+    //! `supertraits(Baz)` yields `[Baz, Bar, Foo, Foo]` in some order.\n \n     transitive_bounds(tcx, &[trait_ref])\n }\n@@ -97,12 +94,8 @@ impl<'cx, 'tcx> Supertraits<'cx, 'tcx> {\n         self.stack.push(entry);\n     }\n \n+    /// Returns the path taken through the trait supertraits to reach the current point.\n     pub fn indices(&self) -> Vec<uint> {\n-        /*!\n-         * Returns the path taken through the trait supertraits to\n-         * reach the current point.\n-         */\n-\n         self.stack.iter().map(|e| e.position).collect()\n     }\n }\n@@ -171,14 +164,14 @@ impl<'tcx> fmt::Show for VtableParamData<'tcx> {\n     }\n }\n \n+/// See `super::obligations_for_generics`\n pub fn obligations_for_generics<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                       cause: ObligationCause<'tcx>,\n                                       recursion_depth: uint,\n                                       generic_bounds: &ty::GenericBounds<'tcx>,\n                                       type_substs: &VecPerParamSpace<Ty<'tcx>>)\n                                       -> VecPerParamSpace<Obligation<'tcx>>\n {\n-    /*! See `super::obligations_for_generics` */\n \n     debug!(\"obligations_for_generics(generic_bounds={}, type_substs={})\",\n            generic_bounds.repr(tcx), type_substs.repr(tcx));\n@@ -272,20 +265,15 @@ pub fn obligation_for_builtin_bound<'tcx>(\n     }\n }\n \n+/// Starting from a caller obligation `caller_bound` (which has coordinates `space`/`i` in the list\n+/// of caller obligations), search through the trait and supertraits to find one where `test(d)` is\n+/// true, where `d` is the def-id of the trait/supertrait. If any is found, return `Some(p)` where\n+/// `p` is the path to that trait/supertrait. Else `None`.\n pub fn search_trait_and_supertraits_from_bound<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                                      caller_bound: Rc<ty::TraitRef<'tcx>>,\n                                                      test: |ast::DefId| -> bool)\n                                                      -> Option<VtableParamData<'tcx>>\n {\n-    /*!\n-     * Starting from a caller obligation `caller_bound` (which has\n-     * coordinates `space`/`i` in the list of caller obligations),\n-     * search through the trait and supertraits to find one where\n-     * `test(d)` is true, where `d` is the def-id of the\n-     * trait/supertrait.  If any is found, return `Some(p)` where `p`\n-     * is the path to that trait/supertrait. Else `None`.\n-     */\n-\n     for bound in transitive_bounds(tcx, &[caller_bound]) {\n         if test(bound.def_id) {\n             let vtable_param = VtableParamData { bound: bound };"}, {"sha": "0574806c1b7702e10546ba37c7e659dce907317a", "filename": "src/librustc/middle/ty.rs", "status": "modified", "additions": 214, "deletions": 297, "changes": 511, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fty.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -671,39 +671,29 @@ pub fn type_has_late_bound_regions(ty: Ty) -> bool {\n     ty.flags.intersects(HAS_RE_LATE_BOUND)\n }\n \n+/// An \"escaping region\" is a bound region whose binder is not part of `t`.\n+///\n+/// So, for example, consider a type like the following, which has two binders:\n+///\n+///    for<'a> fn(x: for<'b> fn(&'a int, &'b int))\n+///    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ outer scope\n+///                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~  inner scope\n+///\n+/// This type has *bound regions* (`'a`, `'b`), but it does not have escaping regions, because the\n+/// binders of both `'a` and `'b` are part of the type itself. However, if we consider the *inner\n+/// fn type*, that type has an escaping region: `'a`.\n+///\n+/// Note that what I'm calling an \"escaping region\" is often just called a \"free region\". However,\n+/// we already use the term \"free region\". It refers to the regions that we use to represent bound\n+/// regions on a fn definition while we are typechecking its body.\n+///\n+/// To clarify, conceptually there is no particular difference between an \"escaping\" region and a\n+/// \"free\" region. However, there is a big difference in practice. Basically, when \"entering\" a\n+/// binding level, one is generally required to do some sort of processing to a bound region, such\n+/// as replacing it with a fresh/skolemized region, or making an entry in the environment to\n+/// represent the scope to which it is attached, etc. An escaping region represents a bound region\n+/// for which this processing has not yet been done.\n pub fn type_has_escaping_regions(ty: Ty) -> bool {\n-    /*!\n-     * An \"escaping region\" is a bound region whose binder is not part of `t`.\n-     *\n-     * So, for example, consider a type like the following, which has two\n-     * binders:\n-     *\n-     *    for<'a> fn(x: for<'b> fn(&'a int, &'b int))\n-     *    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ outer scope\n-     *                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~  inner scope\n-     *\n-     * This type has *bound regions* (`'a`, `'b`), but it does not\n-     * have escaping regions, because the binders of both `'a` and\n-     * `'b` are part of the type itself. However, if we consider the\n-     * *inner fn type*, that type has an escaping region: `'a`.\n-     *\n-     * Note that what I'm calling an \"escaping region\" is often just\n-     * called a \"free region\". However, we already use the term \"free\n-     * region\". It refers to the regions that we use to represent\n-     * bound regions on a fn definition while we are typechecking its\n-     * body.\n-     *\n-     * To clarify, conceptually there is no particular difference\n-     * between an \"escaping\" region and a \"free\" region. However,\n-     * there is a big difference in practice. Basically, when\n-     * \"entering\" a binding level, one is generally required to do\n-     * some sort of processing to a bound region, such as replacing it\n-     * with a fresh/skolemized region, or making an entry in the\n-     * environment to represent the scope to which it is attached,\n-     * etc. An escaping region represents a bound region for which\n-     * this processing has not yet been done.\n-     */\n-\n     type_escapes_depth(ty, 0)\n }\n \n@@ -743,18 +733,16 @@ impl<'tcx> FnOutput<'tcx> {\n     }\n }\n \n-/**\n- * Signature of a function type, which I have arbitrarily\n- * decided to use to refer to the input/output types.\n- *\n- * - `inputs` is the list of arguments and their modes.\n- * - `output` is the return type.\n- * - `variadic` indicates whether this is a varidic function. (only true for foreign fns)\n- *\n- * Note that a `FnSig` introduces a level of region binding, to\n- * account for late-bound parameters that appear in the types of the\n- * fn's arguments or the fn's return type.\n- */\n+/// Signature of a function type, which I have arbitrarily\n+/// decided to use to refer to the input/output types.\n+///\n+/// - `inputs` is the list of arguments and their modes.\n+/// - `output` is the return type.\n+/// - `variadic` indicates whether this is a varidic function. (only true for foreign fns)\n+///\n+/// Note that a `FnSig` introduces a level of region binding, to\n+/// account for late-bound parameters that appear in the types of the\n+/// fn's arguments or the fn's return type.\n #[deriving(Clone, PartialEq, Eq, Hash)]\n pub struct FnSig<'tcx> {\n     pub inputs: Vec<Ty<'tcx>>,\n@@ -769,47 +757,45 @@ pub struct ParamTy {\n     pub def_id: DefId\n }\n \n-/**\n- * A [De Bruijn index][dbi] is a standard means of representing\n- * regions (and perhaps later types) in a higher-ranked setting. In\n- * particular, imagine a type like this:\n- *\n- *     for<'a> fn(for<'b> fn(&'b int, &'a int), &'a char)\n- *     ^          ^            |        |         |\n- *     |          |            |        |         |\n- *     |          +------------+ 1      |         |\n- *     |                                |         |\n- *     +--------------------------------+ 2       |\n- *     |                                          |\n- *     +------------------------------------------+ 1\n- *\n- * In this type, there are two binders (the outer fn and the inner\n- * fn). We need to be able to determine, for any given region, which\n- * fn type it is bound by, the inner or the outer one. There are\n- * various ways you can do this, but a De Bruijn index is one of the\n- * more convenient and has some nice properties. The basic idea is to\n- * count the number of binders, inside out. Some examples should help\n- * clarify what I mean.\n- *\n- * Let's start with the reference type `&'b int` that is the first\n- * argument to the inner function. This region `'b` is assigned a De\n- * Bruijn index of 1, meaning \"the innermost binder\" (in this case, a\n- * fn). The region `'a` that appears in the second argument type (`&'a\n- * int`) would then be assigned a De Bruijn index of 2, meaning \"the\n- * second-innermost binder\". (These indices are written on the arrays\n- * in the diagram).\n- *\n- * What is interesting is that De Bruijn index attached to a particular\n- * variable will vary depending on where it appears. For example,\n- * the final type `&'a char` also refers to the region `'a` declared on\n- * the outermost fn. But this time, this reference is not nested within\n- * any other binders (i.e., it is not an argument to the inner fn, but\n- * rather the outer one). Therefore, in this case, it is assigned a\n- * De Bruijn index of 1, because the innermost binder in that location\n- * is the outer fn.\n- *\n- * [dbi]: http://en.wikipedia.org/wiki/De_Bruijn_index\n- */\n+/// A [De Bruijn index][dbi] is a standard means of representing\n+/// regions (and perhaps later types) in a higher-ranked setting. In\n+/// particular, imagine a type like this:\n+///\n+///     for<'a> fn(for<'b> fn(&'b int, &'a int), &'a char)\n+///     ^          ^            |        |         |\n+///     |          |            |        |         |\n+///     |          +------------+ 1      |         |\n+///     |                                |         |\n+///     +--------------------------------+ 2       |\n+///     |                                          |\n+///     +------------------------------------------+ 1\n+///\n+/// In this type, there are two binders (the outer fn and the inner\n+/// fn). We need to be able to determine, for any given region, which\n+/// fn type it is bound by, the inner or the outer one. There are\n+/// various ways you can do this, but a De Bruijn index is one of the\n+/// more convenient and has some nice properties. The basic idea is to\n+/// count the number of binders, inside out. Some examples should help\n+/// clarify what I mean.\n+///\n+/// Let's start with the reference type `&'b int` that is the first\n+/// argument to the inner function. This region `'b` is assigned a De\n+/// Bruijn index of 1, meaning \"the innermost binder\" (in this case, a\n+/// fn). The region `'a` that appears in the second argument type (`&'a\n+/// int`) would then be assigned a De Bruijn index of 2, meaning \"the\n+/// second-innermost binder\". (These indices are written on the arrays\n+/// in the diagram).\n+///\n+/// What is interesting is that De Bruijn index attached to a particular\n+/// variable will vary depending on where it appears. For example,\n+/// the final type `&'a char` also refers to the region `'a` declared on\n+/// the outermost fn. But this time, this reference is not nested within\n+/// any other binders (i.e., it is not an argument to the inner fn, but\n+/// rather the outer one). Therefore, in this case, it is assigned a\n+/// De Bruijn index of 1, because the innermost binder in that location\n+/// is the outer fn.\n+///\n+/// [dbi]: http://en.wikipedia.org/wiki/De_Bruijn_index\n #[deriving(Clone, PartialEq, Eq, Hash, Encodable, Decodable, Show)]\n pub struct DebruijnIndex {\n     // We maintain the invariant that this is never 0. So 1 indicates\n@@ -856,11 +842,9 @@ pub enum Region {\n     ReEmpty,\n }\n \n-/**\n- * Upvars do not get their own node-id. Instead, we use the pair of\n- * the original var id (that is, the root variable that is referenced\n- * by the upvar) and the id of the closure expression.\n- */\n+/// Upvars do not get their own node-id. Instead, we use the pair of\n+/// the original var id (that is, the root variable that is referenced\n+/// by the upvar) and the id of the closure expression.\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub struct UpvarId {\n     pub var_id: ast::NodeId,\n@@ -913,55 +897,53 @@ pub enum BorrowKind {\n     MutBorrow\n }\n \n-/**\n- * Information describing the borrowing of an upvar. This is computed\n- * during `typeck`, specifically by `regionck`. The general idea is\n- * that the compiler analyses treat closures like:\n- *\n- *     let closure: &'e fn() = || {\n- *        x = 1;   // upvar x is assigned to\n- *        use(y);  // upvar y is read\n- *        foo(&z); // upvar z is borrowed immutably\n- *     };\n- *\n- * as if they were \"desugared\" to something loosely like:\n- *\n- *     struct Vars<'x,'y,'z> { x: &'x mut int,\n- *                             y: &'y const int,\n- *                             z: &'z int }\n- *     let closure: &'e fn() = {\n- *         fn f(env: &Vars) {\n- *             *env.x = 1;\n- *             use(*env.y);\n- *             foo(env.z);\n- *         }\n- *         let env: &'e mut Vars<'x,'y,'z> = &mut Vars { x: &'x mut x,\n- *                                                       y: &'y const y,\n- *                                                       z: &'z z };\n- *         (env, f)\n- *     };\n- *\n- * This is basically what happens at runtime. The closure is basically\n- * an existentially quantified version of the `(env, f)` pair.\n- *\n- * This data structure indicates the region and mutability of a single\n- * one of the `x...z` borrows.\n- *\n- * It may not be obvious why each borrowed variable gets its own\n- * lifetime (in the desugared version of the example, these are indicated\n- * by the lifetime parameters `'x`, `'y`, and `'z` in the `Vars` definition).\n- * Each such lifetime must encompass the lifetime `'e` of the closure itself,\n- * but need not be identical to it. The reason that this makes sense:\n- *\n- * - Callers are only permitted to invoke the closure, and hence to\n- *   use the pointers, within the lifetime `'e`, so clearly `'e` must\n- *   be a sublifetime of `'x...'z`.\n- * - The closure creator knows which upvars were borrowed by the closure\n- *   and thus `x...z` will be reserved for `'x...'z` respectively.\n- * - Through mutation, the borrowed upvars can actually escape\n- *   the closure, so sometimes it is necessary for them to be larger\n- *   than the closure lifetime itself.\n- */\n+/// Information describing the borrowing of an upvar. This is computed\n+/// during `typeck`, specifically by `regionck`. The general idea is\n+/// that the compiler analyses treat closures like:\n+///\n+///     let closure: &'e fn() = || {\n+///        x = 1;   // upvar x is assigned to\n+///        use(y);  // upvar y is read\n+///        foo(&z); // upvar z is borrowed immutably\n+///     };\n+///\n+/// as if they were \"desugared\" to something loosely like:\n+///\n+///     struct Vars<'x,'y,'z> { x: &'x mut int,\n+///                             y: &'y const int,\n+///                             z: &'z int }\n+///     let closure: &'e fn() = {\n+///         fn f(env: &Vars) {\n+///             *env.x = 1;\n+///             use(*env.y);\n+///             foo(env.z);\n+///         }\n+///         let env: &'e mut Vars<'x,'y,'z> = &mut Vars { x: &'x mut x,\n+///                                                       y: &'y const y,\n+///                                                       z: &'z z };\n+///         (env, f)\n+///     };\n+///\n+/// This is basically what happens at runtime. The closure is basically\n+/// an existentially quantified version of the `(env, f)` pair.\n+///\n+/// This data structure indicates the region and mutability of a single\n+/// one of the `x...z` borrows.\n+///\n+/// It may not be obvious why each borrowed variable gets its own\n+/// lifetime (in the desugared version of the example, these are indicated\n+/// by the lifetime parameters `'x`, `'y`, and `'z` in the `Vars` definition).\n+/// Each such lifetime must encompass the lifetime `'e` of the closure itself,\n+/// but need not be identical to it. The reason that this makes sense:\n+///\n+/// - Callers are only permitted to invoke the closure, and hence to\n+///   use the pointers, within the lifetime `'e`, so clearly `'e` must\n+///   be a sublifetime of `'x...'z`.\n+/// - The closure creator knows which upvars were borrowed by the closure\n+///   and thus `x...z` will be reserved for `'x...'z` respectively.\n+/// - Through mutation, the borrowed upvars can actually escape\n+///   the closure, so sometimes it is necessary for them to be larger\n+///   than the closure lifetime itself.\n #[deriving(PartialEq, Clone, Encodable, Decodable, Show)]\n pub struct UpvarBorrow {\n     pub kind: BorrowKind,\n@@ -1111,37 +1093,33 @@ pub struct TyTrait<'tcx> {\n     pub bounds: ExistentialBounds\n }\n \n-/**\n- * A complete reference to a trait. These take numerous guises in syntax,\n- * but perhaps the most recognizable form is in a where clause:\n- *\n- *     T : Foo<U>\n- *\n- * This would be represented by a trait-reference where the def-id is the\n- * def-id for the trait `Foo` and the substs defines `T` as parameter 0 in the\n- * `SelfSpace` and `U` as parameter 0 in the `TypeSpace`.\n- *\n- * Trait references also appear in object types like `Foo<U>`, but in\n- * that case the `Self` parameter is absent from the substitutions.\n- *\n- * Note that a `TraitRef` introduces a level of region binding, to\n- * account for higher-ranked trait bounds like `T : for<'a> Foo<&'a\n- * U>` or higher-ranked object types.\n- */\n+/// A complete reference to a trait. These take numerous guises in syntax,\n+/// but perhaps the most recognizable form is in a where clause:\n+///\n+///     T : Foo<U>\n+///\n+/// This would be represented by a trait-reference where the def-id is the\n+/// def-id for the trait `Foo` and the substs defines `T` as parameter 0 in the\n+/// `SelfSpace` and `U` as parameter 0 in the `TypeSpace`.\n+///\n+/// Trait references also appear in object types like `Foo<U>`, but in\n+/// that case the `Self` parameter is absent from the substitutions.\n+///\n+/// Note that a `TraitRef` introduces a level of region binding, to\n+/// account for higher-ranked trait bounds like `T : for<'a> Foo<&'a\n+/// U>` or higher-ranked object types.\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub struct TraitRef<'tcx> {\n     pub def_id: DefId,\n     pub substs: Substs<'tcx>,\n }\n \n-/**\n- * Binder serves as a synthetic binder for lifetimes. It is used when\n- * we wish to replace the escaping higher-ranked lifetimes in a type\n- * or something else that is not itself a binder (this is because the\n- * `replace_late_bound_regions` function replaces all lifetimes bound\n- * by the binder supplied to it; but a type is not a binder, so you\n- * must introduce an artificial one).\n- */\n+/// Binder serves as a synthetic binder for lifetimes. It is used when\n+/// we wish to replace the escaping higher-ranked lifetimes in a type\n+/// or something else that is not itself a binder (this is because the\n+/// `replace_late_bound_regions` function replaces all lifetimes bound\n+/// by the binder supplied to it; but a type is not a binder, so you\n+/// must introduce an artificial one).\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub struct Binder<T> {\n     pub value: T\n@@ -1248,11 +1226,8 @@ pub fn all_builtin_bounds() -> BuiltinBounds {\n     set\n }\n \n+/// An existential bound that does not implement any traits.\n pub fn region_existential_bound(r: ty::Region) -> ExistentialBounds {\n-    /*!\n-     * An existential bound that does not implement any traits.\n-     */\n-\n     ty::ExistentialBounds { region_bound: r,\n                             builtin_bounds: empty_builtin_bounds() }\n }\n@@ -1425,27 +1400,25 @@ impl<'tcx> Generics<'tcx> {\n     }\n }\n \n-/**\n- * Represents the bounds declared on a particular set of type\n- * parameters.  Should eventually be generalized into a flag list of\n- * where clauses.  You can obtain a `GenericBounds` list from a\n- * `Generics` by using the `to_bounds` method. Note that this method\n- * reflects an important semantic invariant of `GenericBounds`: while\n- * the bounds in a `Generics` are expressed in terms of the bound type\n- * parameters of the impl/trait/whatever, a `GenericBounds` instance\n- * represented a set of bounds for some particular instantiation,\n- * meaning that the generic parameters have been substituted with\n- * their values.\n- *\n- * Example:\n- *\n- *     struct Foo<T,U:Bar<T>> { ... }\n- *\n- * Here, the `Generics` for `Foo` would contain a list of bounds like\n- * `[[], [U:Bar<T>]]`.  Now if there were some particular reference\n- * like `Foo<int,uint>`, then the `GenericBounds` would be `[[],\n- * [uint:Bar<int>]]`.\n- */\n+/// Represents the bounds declared on a particular set of type\n+/// parameters.  Should eventually be generalized into a flag list of\n+/// where clauses.  You can obtain a `GenericBounds` list from a\n+/// `Generics` by using the `to_bounds` method. Note that this method\n+/// reflects an important semantic invariant of `GenericBounds`: while\n+/// the bounds in a `Generics` are expressed in terms of the bound type\n+/// parameters of the impl/trait/whatever, a `GenericBounds` instance\n+/// represented a set of bounds for some particular instantiation,\n+/// meaning that the generic parameters have been substituted with\n+/// their values.\n+///\n+/// Example:\n+///\n+///     struct Foo<T,U:Bar<T>> { ... }\n+///\n+/// Here, the `Generics` for `Foo` would contain a list of bounds like\n+/// `[[], [U:Bar<T>]]`.  Now if there were some particular reference\n+/// like `Foo<int,uint>`, then the `GenericBounds` would be `[[],\n+/// [uint:Bar<int>]]`.\n #[deriving(Clone, Show)]\n pub struct GenericBounds<'tcx> {\n     pub types: VecPerParamSpace<ParamBounds<'tcx>>,\n@@ -1834,12 +1807,9 @@ impl FlagComputation {\n         }\n     }\n \n+    /// Adds the flags/depth from a set of types that appear within the current type, but within a\n+    /// region binder.\n     fn add_bound_computation(&mut self, computation: &FlagComputation) {\n-        /*!\n-         * Adds the flags/depth from a set of types that appear within\n-         * the current type, but within a region binder.\n-         */\n-\n         self.add_flags(computation.flags);\n \n         // The types that contributed to `computation` occured within\n@@ -2455,18 +2425,16 @@ pub fn type_needs_unwind_cleanup<'tcx>(cx: &ctxt<'tcx>, ty: Ty<'tcx>) -> bool {\n     }\n }\n \n-/**\n- * Type contents is how the type checker reasons about kinds.\n- * They track what kinds of things are found within a type.  You can\n- * think of them as kind of an \"anti-kind\".  They track the kinds of values\n- * and thinks that are contained in types.  Having a larger contents for\n- * a type tends to rule that type *out* from various kinds.  For example,\n- * a type that contains a reference is not sendable.\n- *\n- * The reason we compute type contents and not kinds is that it is\n- * easier for me (nmatsakis) to think about what is contained within\n- * a type than to think about what is *not* contained within a type.\n- */\n+/// Type contents is how the type checker reasons about kinds.\n+/// They track what kinds of things are found within a type.  You can\n+/// think of them as kind of an \"anti-kind\".  They track the kinds of values\n+/// and thinks that are contained in types.  Having a larger contents for\n+/// a type tends to rule that type *out* from various kinds.  For example,\n+/// a type that contains a reference is not sendable.\n+///\n+/// The reason we compute type contents and not kinds is that it is\n+/// easier for me (nmatsakis) to think about what is contained within\n+/// a type than to think about what is *not* contained within a type.\n #[deriving(Clone)]\n pub struct TypeContents {\n     pub bits: u64\n@@ -2575,38 +2543,26 @@ impl TypeContents {\n         self.intersects(TC::NeedsDrop)\n     }\n \n+    /// Includes only those bits that still apply when indirected through a `Box` pointer\n     pub fn owned_pointer(&self) -> TypeContents {\n-        /*!\n-         * Includes only those bits that still apply\n-         * when indirected through a `Box` pointer\n-         */\n         TC::OwnsOwned | (\n             *self & (TC::OwnsAll | TC::ReachesAll))\n     }\n \n+    /// Includes only those bits that still apply when indirected through a reference (`&`)\n     pub fn reference(&self, bits: TypeContents) -> TypeContents {\n-        /*!\n-         * Includes only those bits that still apply\n-         * when indirected through a reference (`&`)\n-         */\n         bits | (\n             *self & TC::ReachesAll)\n     }\n \n+    /// Includes only those bits that still apply when indirected through a managed pointer (`@`)\n     pub fn managed_pointer(&self) -> TypeContents {\n-        /*!\n-         * Includes only those bits that still apply\n-         * when indirected through a managed pointer (`@`)\n-         */\n         TC::Managed | (\n             *self & TC::ReachesAll)\n     }\n \n+    /// Includes only those bits that still apply when indirected through an unsafe pointer (`*`)\n     pub fn unsafe_pointer(&self) -> TypeContents {\n-        /*!\n-         * Includes only those bits that still apply\n-         * when indirected through an unsafe pointer (`*`)\n-         */\n         *self & TC::ReachesAll\n     }\n \n@@ -2883,14 +2839,10 @@ pub fn type_contents<'tcx>(cx: &ctxt<'tcx>, ty: Ty<'tcx>) -> TypeContents {\n         }\n     }\n \n+    /// Type contents due to containing a reference with the region `region` and borrow kind `bk`\n     fn borrowed_contents(region: ty::Region,\n                          mutbl: ast::Mutability)\n                          -> TypeContents {\n-        /*!\n-         * Type contents due to containing a reference\n-         * with the region `region` and borrow kind `bk`\n-         */\n-\n         let b = match mutbl {\n             ast::MutMutable => TC::ReachesMutable | TC::OwnsAffine,\n             ast::MutImmutable => TC::None,\n@@ -3648,20 +3600,16 @@ pub fn expr_ty_opt<'tcx>(cx: &ctxt<'tcx>, expr: &ast::Expr) -> Option<Ty<'tcx>>\n     return node_id_to_type_opt(cx, expr.id);\n }\n \n+/// Returns the type of `expr`, considering any `AutoAdjustment`\n+/// entry recorded for that expression.\n+///\n+/// It would almost certainly be better to store the adjusted ty in with\n+/// the `AutoAdjustment`, but I opted not to do this because it would\n+/// require serializing and deserializing the type and, although that's not\n+/// hard to do, I just hate that code so much I didn't want to touch it\n+/// unless it was to fix it properly, which seemed a distraction from the\n+/// task at hand! -nmatsakis\n pub fn expr_ty_adjusted<'tcx>(cx: &ctxt<'tcx>, expr: &ast::Expr) -> Ty<'tcx> {\n-    /*!\n-     *\n-     * Returns the type of `expr`, considering any `AutoAdjustment`\n-     * entry recorded for that expression.\n-     *\n-     * It would almost certainly be better to store the adjusted ty in with\n-     * the `AutoAdjustment`, but I opted not to do this because it would\n-     * require serializing and deserializing the type and, although that's not\n-     * hard to do, I just hate that code so much I didn't want to touch it\n-     * unless it was to fix it properly, which seemed a distraction from the\n-     * task at hand! -nmatsakis\n-     */\n-\n     adjust_ty(cx, expr.span, expr.id, expr_ty(cx, expr),\n               cx.adjustments.borrow().get(&expr.id),\n               |method_call| cx.method_map.borrow().get(&method_call).map(|method| method.ty))\n@@ -3707,14 +3655,14 @@ pub fn local_var_name_str(cx: &ctxt, id: NodeId) -> InternedString {\n     }\n }\n \n+/// See `expr_ty_adjusted`\n pub fn adjust_ty<'tcx>(cx: &ctxt<'tcx>,\n                        span: Span,\n                        expr_id: ast::NodeId,\n                        unadjusted_ty: Ty<'tcx>,\n                        adjustment: Option<&AutoAdjustment<'tcx>>,\n                        method_type: |typeck::MethodCall| -> Option<Ty<'tcx>>)\n                        -> Ty<'tcx> {\n-    /*! See `expr_ty_adjusted` */\n \n     match unadjusted_ty.sty {\n         ty_err => return unadjusted_ty,\n@@ -4128,16 +4076,11 @@ pub fn ty_sort_string<'tcx>(cx: &ctxt<'tcx>, ty: Ty<'tcx>) -> String {\n     }\n }\n \n+/// Explains the source of a type err in a short, human readable way. This is meant to be placed\n+/// in parentheses after some larger message. You should also invoke `note_and_explain_type_err()`\n+/// afterwards to present additional details, particularly when it comes to lifetime-related\n+/// errors.\n pub fn type_err_to_str<'tcx>(cx: &ctxt<'tcx>, err: &type_err<'tcx>) -> String {\n-    /*!\n-     *\n-     * Explains the source of a type err in a short,\n-     * human readable way.  This is meant to be placed in\n-     * parentheses after some larger message.  You should\n-     * also invoke `note_and_explain_type_err()` afterwards\n-     * to present additional details, particularly when\n-     * it comes to lifetime-related errors. */\n-\n     fn tstore_to_closure(s: &TraitStore) -> String {\n         match s {\n             &UniqTraitStore => \"proc\".to_string(),\n@@ -4352,21 +4295,16 @@ pub fn provided_trait_methods<'tcx>(cx: &ctxt<'tcx>, id: ast::DefId)\n     }\n }\n \n+/// Helper for looking things up in the various maps that are populated during typeck::collect\n+/// (e.g., `cx.impl_or_trait_items`, `cx.tcache`, etc).  All of these share the pattern that if the\n+/// id is local, it should have been loaded into the map by the `typeck::collect` phase.  If the\n+/// def-id is external, then we have to go consult the crate loading code (and cache the result for\n+/// the future).\n fn lookup_locally_or_in_crate_store<V:Clone>(\n                                     descr: &str,\n                                     def_id: ast::DefId,\n                                     map: &mut DefIdMap<V>,\n                                     load_external: || -> V) -> V {\n-    /*!\n-     * Helper for looking things up in the various maps\n-     * that are populated during typeck::collect (e.g.,\n-     * `cx.impl_or_trait_items`, `cx.tcache`, etc).  All of these share\n-     * the pattern that if the id is local, it should have\n-     * been loaded into the map by the `typeck::collect` phase.\n-     * If the def-id is external, then we have to go consult\n-     * the crate loading code (and cache the result for the future).\n-     */\n-\n     match map.get(&def_id).cloned() {\n         Some(v) => { return v; }\n         None => { }\n@@ -5238,19 +5176,16 @@ pub fn each_bound_trait_and_supertraits<'tcx>(tcx: &ctxt<'tcx>,\n     return true;\n }\n \n+/// Given a type which must meet the builtin bounds and trait bounds, returns a set of lifetimes\n+/// which the type must outlive.\n+///\n+/// Requires that trait definitions have been processed.\n pub fn required_region_bounds<'tcx>(tcx: &ctxt<'tcx>,\n                                     region_bounds: &[ty::Region],\n                                     builtin_bounds: BuiltinBounds,\n                                     trait_bounds: &[Rc<TraitRef<'tcx>>])\n                                     -> Vec<ty::Region>\n {\n-    /*!\n-     * Given a type which must meet the builtin bounds and trait\n-     * bounds, returns a set of lifetimes which the type must outlive.\n-     *\n-     * Requires that trait definitions have been processed.\n-     */\n-\n     let mut all_bounds = Vec::new();\n \n     debug!(\"required_region_bounds(builtin_bounds={}, trait_bounds={})\",\n@@ -5636,28 +5571,24 @@ impl Variance {\n     }\n }\n \n+/// Construct a parameter environment suitable for static contexts or other contexts where there\n+/// are no free type/lifetime parameters in scope.\n pub fn empty_parameter_environment<'tcx>() -> ParameterEnvironment<'tcx> {\n-    /*!\n-     * Construct a parameter environment suitable for static contexts\n-     * or other contexts where there are no free type/lifetime\n-     * parameters in scope.\n-     */\n-\n     ty::ParameterEnvironment { free_substs: Substs::empty(),\n                                bounds: VecPerParamSpace::empty(),\n                                caller_obligations: VecPerParamSpace::empty(),\n                                implicit_region_bound: ty::ReEmpty,\n                                selection_cache: traits::SelectionCache::new(), }\n }\n \n+/// See `ParameterEnvironment` struct def'n for details\n pub fn construct_parameter_environment<'tcx>(\n     tcx: &ctxt<'tcx>,\n     span: Span,\n     generics: &ty::Generics<'tcx>,\n     free_id: ast::NodeId)\n     -> ParameterEnvironment<'tcx>\n {\n-    /*! See `ParameterEnvironment` struct def'n for details */\n \n     //\n     // Construct the free substs.\n@@ -5786,15 +5717,11 @@ impl BorrowKind {\n         }\n     }\n \n+    /// Returns a mutability `m` such that an `&m T` pointer could be used to obtain this borrow\n+    /// kind. Because borrow kinds are richer than mutabilities, we sometimes have to pick a\n+    /// mutability that is stronger than necessary so that it at least *would permit* the borrow in\n+    /// question.\n     pub fn to_mutbl_lossy(self) -> ast::Mutability {\n-        /*!\n-         * Returns a mutability `m` such that an `&m T` pointer could\n-         * be used to obtain this borrow kind. Because borrow kinds\n-         * are richer than mutabilities, we sometimes have to pick a\n-         * mutability that is stronger than necessary so that it at\n-         * least *would permit* the borrow in question.\n-         */\n-\n         match self {\n             MutBorrow => ast::MutMutable,\n             ImmBorrow => ast::MutImmutable,\n@@ -5959,49 +5886,39 @@ impl<'tcx> AutoDerefRef<'tcx> {\n     }\n }\n \n+/// Replace any late-bound regions bound in `value` with free variants attached to scope-id\n+/// `scope_id`.\n pub fn liberate_late_bound_regions<'tcx, HR>(\n     tcx: &ty::ctxt<'tcx>,\n     scope: region::CodeExtent,\n     value: &HR)\n     -> HR\n     where HR : HigherRankedFoldable<'tcx>\n {\n-    /*!\n-     * Replace any late-bound regions bound in `value` with free variants\n-     * attached to scope-id `scope_id`.\n-     */\n-\n     replace_late_bound_regions(\n         tcx, value,\n         |br, _| ty::ReFree(ty::FreeRegion{scope: scope, bound_region: br})).0\n }\n \n+/// Replace any late-bound regions bound in `value` with `'static`. Useful in trans but also\n+/// method lookup and a few other places where precise region relationships are not required.\n pub fn erase_late_bound_regions<'tcx, HR>(\n     tcx: &ty::ctxt<'tcx>,\n     value: &HR)\n     -> HR\n     where HR : HigherRankedFoldable<'tcx>\n {\n-    /*!\n-     * Replace any late-bound regions bound in `value` with `'static`.\n-     * Useful in trans but also method lookup and a few other places\n-     * where precise region relationships are not required.\n-     */\n-\n     replace_late_bound_regions(tcx, value, |_, _| ty::ReStatic).0\n }\n \n+/// Replaces the late-bound-regions in `value` that are bound by `value`.\n pub fn replace_late_bound_regions<'tcx, HR>(\n     tcx: &ty::ctxt<'tcx>,\n     value: &HR,\n     mapf: |BoundRegion, DebruijnIndex| -> ty::Region)\n     -> (HR, FnvHashMap<ty::BoundRegion,ty::Region>)\n     where HR : HigherRankedFoldable<'tcx>\n {\n-    /*!\n-     * Replaces the late-bound-regions in `value` that are bound by `value`.\n-     */\n-\n     debug!(\"replace_late_bound_regions({})\", value.repr(tcx));\n \n     let mut map = FnvHashMap::new();"}, {"sha": "08dcbffc9287b6a13bf0ebf75dbd741b6af47223", "filename": "src/librustc/middle/ty_fold.rs", "status": "modified", "additions": 26, "deletions": 30, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fty_fold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Fty_fold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fty_fold.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,33 +8,31 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Generalized type folding mechanism. The setup is a bit convoluted\n- * but allows for convenient usage. Let T be an instance of some\n- * \"foldable type\" (one which implements `TypeFoldable`) and F be an\n- * instance of a \"folder\" (a type which implements `TypeFolder`). Then\n- * the setup is intended to be:\n- *\n- *     T.fold_with(F) --calls--> F.fold_T(T) --calls--> super_fold_T(F, T)\n- *\n- * This way, when you define a new folder F, you can override\n- * `fold_T()` to customize the behavior, and invoke `super_fold_T()`\n- * to get the original behavior. Meanwhile, to actually fold\n- * something, you can just write `T.fold_with(F)`, which is\n- * convenient. (Note that `fold_with` will also transparently handle\n- * things like a `Vec<T>` where T is foldable and so on.)\n- *\n- * In this ideal setup, the only function that actually *does*\n- * anything is `super_fold_T`, which traverses the type `T`. Moreover,\n- * `super_fold_T` should only ever call `T.fold_with()`.\n- *\n- * In some cases, we follow a degenerate pattern where we do not have\n- * a `fold_T` nor `super_fold_T` method. Instead, `T.fold_with`\n- * traverses the structure directly. This is suboptimal because the\n- * behavior cannot be overriden, but it's much less work to implement.\n- * If you ever *do* need an override that doesn't exist, it's not hard\n- * to convert the degenerate pattern into the proper thing.\n- */\n+//! Generalized type folding mechanism. The setup is a bit convoluted\n+//! but allows for convenient usage. Let T be an instance of some\n+//! \"foldable type\" (one which implements `TypeFoldable`) and F be an\n+//! instance of a \"folder\" (a type which implements `TypeFolder`). Then\n+//! the setup is intended to be:\n+//!\n+//!     T.fold_with(F) --calls--> F.fold_T(T) --calls--> super_fold_T(F, T)\n+//!\n+//! This way, when you define a new folder F, you can override\n+//! `fold_T()` to customize the behavior, and invoke `super_fold_T()`\n+//! to get the original behavior. Meanwhile, to actually fold\n+//! something, you can just write `T.fold_with(F)`, which is\n+//! convenient. (Note that `fold_with` will also transparently handle\n+//! things like a `Vec<T>` where T is foldable and so on.)\n+//!\n+//! In this ideal setup, the only function that actually *does*\n+//! anything is `super_fold_T`, which traverses the type `T`. Moreover,\n+//! `super_fold_T` should only ever call `T.fold_with()`.\n+//!\n+//! In some cases, we follow a degenerate pattern where we do not have\n+//! a `fold_T` nor `super_fold_T` method. Instead, `T.fold_with`\n+//! traverses the structure directly. This is suboptimal because the\n+//! behavior cannot be overriden, but it's much less work to implement.\n+//! If you ever *do* need an override that doesn't exist, it's not hard\n+//! to convert the degenerate pattern into the proper thing.\n \n use middle::subst;\n use middle::subst::VecPerParamSpace;\n@@ -701,9 +699,7 @@ pub fn super_fold_obligation<'tcx, T:TypeFolder<'tcx>>(this: &mut T,\n ///////////////////////////////////////////////////////////////////////////\n // Higher-ranked things\n \n-/**\n- * Designates a \"binder\" for late-bound regions.\n- */\n+/// Designates a \"binder\" for late-bound regions.\n pub trait HigherRankedFoldable<'tcx>: Repr<'tcx> {\n     /// Folds the contents of `self`, ignoring the region binder created\n     /// by `self`."}, {"sha": "89c004fc64596e0ab192b4c87d86b6c0c59fb28d", "filename": "src/librustc/middle/typeck/astconv.rs", "status": "modified", "additions": 154, "deletions": 162, "changes": 316, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fastconv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fastconv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fastconv.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,46 +8,44 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Conversion from AST representation of types to the ty.rs\n- * representation.  The main routine here is `ast_ty_to_ty()`: each use\n- * is parameterized by an instance of `AstConv` and a `RegionScope`.\n- *\n- * The parameterization of `ast_ty_to_ty()` is because it behaves\n- * somewhat differently during the collect and check phases,\n- * particularly with respect to looking up the types of top-level\n- * items.  In the collect phase, the crate context is used as the\n- * `AstConv` instance; in this phase, the `get_item_ty()` function\n- * triggers a recursive call to `ty_of_item()`  (note that\n- * `ast_ty_to_ty()` will detect recursive types and report an error).\n- * In the check phase, when the FnCtxt is used as the `AstConv`,\n- * `get_item_ty()` just looks up the item type in `tcx.tcache`.\n- *\n- * The `RegionScope` trait controls what happens when the user does\n- * not specify a region in some location where a region is required\n- * (e.g., if the user writes `&Foo` as a type rather than `&'a Foo`).\n- * See the `rscope` module for more details.\n- *\n- * Unlike the `AstConv` trait, the region scope can change as we descend\n- * the type.  This is to accommodate the fact that (a) fn types are binding\n- * scopes and (b) the default region may change.  To understand case (a),\n- * consider something like:\n- *\n- *   type foo = { x: &a.int, y: |&a.int| }\n- *\n- * The type of `x` is an error because there is no region `a` in scope.\n- * In the type of `y`, however, region `a` is considered a bound region\n- * as it does not already appear in scope.\n- *\n- * Case (b) says that if you have a type:\n- *   type foo<'a> = ...;\n- *   type bar = fn(&foo, &a.foo)\n- * The fully expanded version of type bar is:\n- *   type bar = fn(&'foo &, &a.foo<'a>)\n- * Note that the self region for the `foo` defaulted to `&` in the first\n- * case but `&a` in the second.  Basically, defaults that appear inside\n- * an rptr (`&r.T`) use the region `r` that appears in the rptr.\n- */\n+//! Conversion from AST representation of types to the ty.rs\n+//! representation.  The main routine here is `ast_ty_to_ty()`: each use\n+//! is parameterized by an instance of `AstConv` and a `RegionScope`.\n+//!\n+//! The parameterization of `ast_ty_to_ty()` is because it behaves\n+//! somewhat differently during the collect and check phases,\n+//! particularly with respect to looking up the types of top-level\n+//! items.  In the collect phase, the crate context is used as the\n+//! `AstConv` instance; in this phase, the `get_item_ty()` function\n+//! triggers a recursive call to `ty_of_item()`  (note that\n+//! `ast_ty_to_ty()` will detect recursive types and report an error).\n+//! In the check phase, when the FnCtxt is used as the `AstConv`,\n+//! `get_item_ty()` just looks up the item type in `tcx.tcache`.\n+//!\n+//! The `RegionScope` trait controls what happens when the user does\n+//! not specify a region in some location where a region is required\n+//! (e.g., if the user writes `&Foo` as a type rather than `&'a Foo`).\n+//! See the `rscope` module for more details.\n+//!\n+//! Unlike the `AstConv` trait, the region scope can change as we descend\n+//! the type.  This is to accommodate the fact that (a) fn types are binding\n+//! scopes and (b) the default region may change.  To understand case (a),\n+//! consider something like:\n+//!\n+//!   type foo = { x: &a.int, y: |&a.int| }\n+//!\n+//! The type of `x` is an error because there is no region `a` in scope.\n+//! In the type of `y`, however, region `a` is considered a bound region\n+//! as it does not already appear in scope.\n+//!\n+//! Case (b) says that if you have a type:\n+//!   type foo<'a> = ...;\n+//!   type bar = fn(&foo, &a.foo)\n+//! The fully expanded version of type bar is:\n+//!   type bar = fn(&'foo &, &a.foo<'a>)\n+//! Note that the self region for the `foo` defaulted to `&` in the first\n+//! case but `&a` in the second.  Basically, defaults that appear inside\n+//! an rptr (`&r.T`) use the region `r` that appears in the rptr.\n use middle::const_eval;\n use middle::def;\n use middle::resolve_lifetime as rl;\n@@ -59,8 +57,9 @@ use middle::typeck::rscope::{UnelidableRscope, RegionScope, SpecificRscope,\n                              ShiftedRscope, BindingRscope};\n use middle::typeck::rscope;\n use middle::typeck::TypeAndSubsts;\n+use util::common::ErrorReported;\n use util::nodemap::DefIdMap;\n-use util::ppaux::{Repr, UserString};\n+use util::ppaux::{mod, Repr, UserString};\n \n use std::rc::Rc;\n use std::iter::AdditiveIterator;\n@@ -201,6 +200,8 @@ pub fn opt_ast_region_to_region<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n     r\n }\n \n+/// Given a path `path` that refers to an item `I` with the declared generics `decl_generics`,\n+/// returns an appropriate set of substitutions for this particular reference to `I`.\n fn ast_path_substs_for_ty<'tcx,AC,RS>(\n     this: &AC,\n     rscope: &RS,\n@@ -211,12 +212,6 @@ fn ast_path_substs_for_ty<'tcx,AC,RS>(\n     -> Substs<'tcx>\n     where AC: AstConv<'tcx>, RS: RegionScope\n {\n-    /*!\n-     * Given a path `path` that refers to an item `I` with the\n-     * declared generics `decl_generics`, returns an appropriate\n-     * set of substitutions for this particular reference to `I`.\n-     */\n-\n     let tcx = this.tcx();\n \n     // ast_path_substs() is only called to convert paths that are\n@@ -422,6 +417,9 @@ pub fn instantiate_poly_trait_ref<'tcx,AC,RS>(\n     instantiate_trait_ref(this, rscope, &ast_trait_ref.trait_ref, self_ty)\n }\n \n+/// Instantiates the path for the given trait reference, assuming that it's bound to a valid trait\n+/// type. Returns the def_id for the defining trait. Fails if the type is a type other than a trait\n+/// type.\n pub fn instantiate_trait_ref<'tcx,AC,RS>(this: &AC,\n                                          rscope: &RS,\n                                          ast_trait_ref: &ast::TraitRef,\n@@ -430,12 +428,6 @@ pub fn instantiate_trait_ref<'tcx,AC,RS>(this: &AC,\n                                          where AC: AstConv<'tcx>,\n                                                RS: RegionScope\n {\n-    /*!\n-     * Instantiates the path for the given trait reference, assuming that\n-     * it's bound to a valid trait type. Returns the def_id for the defining\n-     * trait. Fails if the type is a type other than a trait type.\n-     */\n-\n     match lookup_def_tcx(this.tcx(),\n                          ast_trait_ref.path.span,\n                          ast_trait_ref.ref_id) {\n@@ -585,7 +577,7 @@ fn check_path_args(tcx: &ty::ctxt,\n pub fn ast_ty_to_prim_ty<'tcx>(tcx: &ty::ctxt<'tcx>, ast_ty: &ast::Ty)\n                                -> Option<Ty<'tcx>> {\n     match ast_ty.node {\n-        ast::TyPath(ref path, _, id) => {\n+        ast::TyPath(ref path, id) => {\n             let a_def = match tcx.def_map.borrow().get(&id) {\n                 None => {\n                     tcx.sess.span_bug(ast_ty.span,\n@@ -642,7 +634,7 @@ pub fn ast_ty_to_builtin_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n     }\n \n     match ast_ty.node {\n-        ast::TyPath(ref path, _, id) => {\n+        ast::TyPath(ref path, id) => {\n             let a_def = match this.tcx().def_map.borrow().get(&id) {\n                 None => {\n                     this.tcx()\n@@ -682,64 +674,92 @@ pub fn ast_ty_to_builtin_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n     }\n }\n \n-// Handle `~`, `Box`, and `&` being able to mean strs and vecs.\n-// If a_seq_ty is a str or a vec, make it a str/vec.\n-// Also handle first-class trait types.\n-fn mk_pointer<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n-        this: &AC,\n-        rscope: &RS,\n-        a_seq_mutbl: ast::Mutability,\n-        a_seq_ty: &ast::Ty,\n-        region: ty::Region,\n-        constr: |Ty<'tcx>| -> Ty<'tcx>)\n-        -> Ty<'tcx>\n+fn ast_ty_to_trait_ref<'tcx,AC,RS>(this: &AC,\n+                                   rscope: &RS,\n+                                   ty: &ast::Ty,\n+                                   bounds: &[ast::TyParamBound])\n+                                   -> Result<ty::TraitRef<'tcx>, ErrorReported>\n+    where AC : AstConv<'tcx>, RS : RegionScope\n {\n-    let tcx = this.tcx();\n-\n-    debug!(\"mk_pointer(region={}, a_seq_ty={})\",\n-           region,\n-           a_seq_ty.repr(tcx));\n+    /*!\n+     * In a type like `Foo + Send`, we want to wait to collect the\n+     * full set of bounds before we make the object type, because we\n+     * need them to infer a region bound.  (For example, if we tried\n+     * made a type from just `Foo`, then it wouldn't be enough to\n+     * infer a 'static bound, and hence the user would get an error.)\n+     * So this function is used when we're dealing with a sum type to\n+     * convert the LHS. It only accepts a type that refers to a trait\n+     * name, and reports an error otherwise.\n+     */\n \n-    match a_seq_ty.node {\n-        ast::TyVec(ref ty) => {\n-            let ty = ast_ty_to_ty(this, rscope, &**ty);\n-            return constr(ty::mk_vec(tcx, ty, None));\n+    match ty.node {\n+        ast::TyPath(ref path, id) => {\n+            match this.tcx().def_map.borrow().get(&id) {\n+                Some(&def::DefTrait(trait_def_id)) => {\n+                    return Ok(ast_path_to_trait_ref(this,\n+                                                    rscope,\n+                                                    trait_def_id,\n+                                                    None,\n+                                                    path));\n+                }\n+                _ => {\n+                    span_err!(this.tcx().sess, ty.span, E0172, \"expected a reference to a trait\");\n+                    Err(ErrorReported)\n+                }\n+            }\n         }\n-        ast::TyPath(ref path, ref opt_bounds, id) => {\n-            // Note that the \"bounds must be empty if path is not a trait\"\n-            // restriction is enforced in the below case for ty_path, which\n-            // will run after this as long as the path isn't a trait.\n-            match tcx.def_map.borrow().get(&id) {\n-                Some(&def::DefPrimTy(ast::TyStr)) => {\n-                    check_path_args(tcx, path, NO_TPS | NO_REGIONS);\n-                    return ty::mk_str_slice(tcx, region, a_seq_mutbl);\n+        _ => {\n+            span_err!(this.tcx().sess, ty.span, E0171,\n+                      \"expected a path on the left-hand side of `+`, not `{}`\",\n+                      pprust::ty_to_string(ty));\n+            match ty.node {\n+                ast::TyRptr(None, ref mut_ty) => {\n+                    span_note!(this.tcx().sess, ty.span,\n+                               \"perhaps you meant `&{}({} +{})`? (per RFC 248)\",\n+                               ppaux::mutability_to_string(mut_ty.mutbl),\n+                               pprust::ty_to_string(&*mut_ty.ty),\n+                               pprust::bounds_to_string(bounds));\n                 }\n-                Some(&def::DefTrait(trait_def_id)) => {\n-                    let result = ast_path_to_trait_ref(this,\n-                                                       rscope,\n-                                                       trait_def_id,\n-                                                       None,\n-                                                       path);\n-                    let empty_vec = [];\n-                    let bounds = match *opt_bounds { None => empty_vec.as_slice(),\n-                                                     Some(ref bounds) => bounds.as_slice() };\n-                    let existential_bounds = conv_existential_bounds(this,\n-                                                                     rscope,\n-                                                                     path.span,\n-                                                                     &[Rc::new(result.clone())],\n-                                                                     bounds);\n-                    let tr = ty::mk_trait(tcx,\n-                                          result,\n-                                          existential_bounds);\n-                    return ty::mk_rptr(tcx, region, ty::mt{mutbl: a_seq_mutbl, ty: tr});\n+\n+                ast::TyRptr(Some(ref lt), ref mut_ty) => {\n+                    span_note!(this.tcx().sess, ty.span,\n+                               \"perhaps you meant `&{} {}({} +{})`? (per RFC 248)\",\n+                               pprust::lifetime_to_string(lt),\n+                               ppaux::mutability_to_string(mut_ty.mutbl),\n+                               pprust::ty_to_string(&*mut_ty.ty),\n+                               pprust::bounds_to_string(bounds));\n+                }\n+\n+                _ => {\n+                    span_note!(this.tcx().sess, ty.span,\n+                               \"perhaps you forgot parentheses? (per RFC 248)\");\n                 }\n-                _ => {}\n             }\n+            Err(ErrorReported)\n         }\n-        _ => {}\n     }\n \n-    constr(ast_ty_to_ty(this, rscope, a_seq_ty))\n+}\n+\n+fn trait_ref_to_object_type<'tcx,AC,RS>(this: &AC,\n+                                        rscope: &RS,\n+                                        span: Span,\n+                                        trait_ref: ty::TraitRef<'tcx>,\n+                                        bounds: &[ast::TyParamBound])\n+                                        -> Ty<'tcx>\n+    where AC : AstConv<'tcx>, RS : RegionScope\n+{\n+    let existential_bounds = conv_existential_bounds(this,\n+                                                     rscope,\n+                                                     span,\n+                                                     &[Rc::new(trait_ref.clone())],\n+                                                     bounds);\n+\n+    let result = ty::mk_trait(this.tcx(), trait_ref, existential_bounds);\n+    debug!(\"trait_ref_to_object_type: result={}\",\n+           result.repr(this.tcx()));\n+\n+    result\n }\n \n fn qpath_to_ty<'tcx,AC,RS>(this: &AC,\n@@ -806,6 +826,17 @@ pub fn ast_ty_to_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n             ast::TyVec(ref ty) => {\n                 ty::mk_vec(tcx, ast_ty_to_ty(this, rscope, &**ty), None)\n             }\n+            ast::TyObjectSum(ref ty, ref bounds) => {\n+                match ast_ty_to_trait_ref(this, rscope, &**ty, bounds.as_slice()) {\n+                    Ok(trait_ref) => {\n+                        trait_ref_to_object_type(this, rscope, ast_ty.span,\n+                                                 trait_ref, bounds.as_slice())\n+                    }\n+                    Err(ErrorReported) => {\n+                        ty::mk_err()\n+                    }\n+                }\n+            }\n             ast::TyPtr(ref mt) => {\n                 ty::mk_ptr(tcx, ty::mt {\n                     ty: ast_ty_to_ty(this, rscope, &*mt.ty),\n@@ -815,8 +846,8 @@ pub fn ast_ty_to_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n             ast::TyRptr(ref region, ref mt) => {\n                 let r = opt_ast_region_to_region(this, rscope, ast_ty.span, region);\n                 debug!(\"ty_rptr r={}\", r.repr(this.tcx()));\n-                mk_pointer(this, rscope, mt.mutbl, &*mt.ty, r,\n-                           |ty| ty::mk_rptr(tcx, r, ty::mt {ty: ty, mutbl: mt.mutbl}))\n+                let t = ast_ty_to_ty(this, rscope, &*mt.ty);\n+                ty::mk_rptr(tcx, r, ty::mt {ty: t, mutbl: mt.mutbl})\n             }\n             ast::TyTup(ref fields) => {\n                 let flds = fields.iter()\n@@ -874,7 +905,7 @@ pub fn ast_ty_to_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n             ast::TyPolyTraitRef(ref bounds) => {\n                 conv_ty_poly_trait_ref(this, rscope, ast_ty.span, bounds.as_slice())\n             }\n-            ast::TyPath(ref path, ref bounds, id) => {\n+            ast::TyPath(ref path, id) => {\n                 let a_def = match tcx.def_map.borrow().get(&id) {\n                     None => {\n                         tcx.sess\n@@ -884,35 +915,16 @@ pub fn ast_ty_to_ty<'tcx, AC: AstConv<'tcx>, RS: RegionScope>(\n                     }\n                     Some(&d) => d\n                 };\n-                // Kind bounds on path types are only supported for traits.\n-                match a_def {\n-                    // But don't emit the error if the user meant to do a trait anyway.\n-                    def::DefTrait(..) => { },\n-                    _ if bounds.is_some() =>\n-                        tcx.sess.span_err(ast_ty.span,\n-                                          \"kind bounds can only be used on trait types\"),\n-                    _ => { },\n-                }\n                 match a_def {\n                     def::DefTrait(trait_def_id) => {\n+                        // N.B. this case overlaps somewhat with\n+                        // TyObjectSum, see that fn for details\n                         let result = ast_path_to_trait_ref(this,\n                                                            rscope,\n                                                            trait_def_id,\n                                                            None,\n                                                            path);\n-                        let empty_bounds: &[ast::TyParamBound] = &[];\n-                        let ast_bounds = match *bounds {\n-                            Some(ref b) => b.as_slice(),\n-                            None => empty_bounds\n-                        };\n-                        let bounds = conv_existential_bounds(this,\n-                                                             rscope,\n-                                                             ast_ty.span,\n-                                                             &[Rc::new(result.clone())],\n-                                                             ast_bounds);\n-                        let result_ty = ty::mk_trait(tcx, result, bounds);\n-                        debug!(\"ast_ty_to_ty: result_ty={}\", result_ty.repr(this.tcx()));\n-                        result_ty\n+                        trait_ref_to_object_type(this, rscope, path.span, result, &[])\n                     }\n                     def::DefTy(did, _) | def::DefStruct(did) => {\n                         ast_path_to_ty(this, rscope, did, path).ty\n@@ -1318,6 +1330,10 @@ pub fn ty_of_closure<'tcx, AC: AstConv<'tcx>>(\n     }\n }\n \n+/// Given an existential type like `Foo+'a+Bar`, this routine converts the `'a` and `Bar` intos an\n+/// `ExistentialBounds` struct. The `main_trait_refs` argument specifies the `Foo` -- it is absent\n+/// for closures. Eventually this should all be normalized, I think, so that there is no \"main\n+/// trait ref\" and instead we just have a flat list of bounds as the existential type.\n pub fn conv_existential_bounds<'tcx, AC: AstConv<'tcx>, RS:RegionScope>(\n     this: &AC,\n     rscope: &RS,\n@@ -1326,16 +1342,6 @@ pub fn conv_existential_bounds<'tcx, AC: AstConv<'tcx>, RS:RegionScope>(\n     ast_bounds: &[ast::TyParamBound])\n     -> ty::ExistentialBounds\n {\n-    /*!\n-     * Given an existential type like `Foo+'a+Bar`, this routine\n-     * converts the `'a` and `Bar` intos an `ExistentialBounds`\n-     * struct. The `main_trait_refs` argument specifies the `Foo` --\n-     * it is absent for closures. Eventually this should all be\n-     * normalized, I think, so that there is no \"main trait ref\" and\n-     * instead we just have a flat list of bounds as the existential\n-     * type.\n-     */\n-\n     let ast_bound_refs: Vec<&ast::TyParamBound> =\n         ast_bounds.iter().collect();\n \n@@ -1432,23 +1438,17 @@ pub fn conv_existential_bounds_from_partitioned_bounds<'tcx, AC, RS>(\n     }\n }\n \n+/// Given the bounds on a type parameter / existential type, determines what single region bound\n+/// (if any) we can use to summarize this type. The basic idea is that we will use the bound the\n+/// user provided, if they provided one, and otherwise search the supertypes of trait bounds for\n+/// region bounds. It may be that we can derive no bound at all, in which case we return `None`.\n pub fn compute_opt_region_bound<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                       span: Span,\n                                       builtin_bounds: ty::BuiltinBounds,\n                                       region_bounds: &[&ast::Lifetime],\n                                       trait_bounds: &[Rc<ty::TraitRef<'tcx>>])\n                                       -> Option<ty::Region>\n {\n-    /*!\n-     * Given the bounds on a type parameter / existential type,\n-     * determines what single region bound (if any) we can use to\n-     * summarize this type. The basic idea is that we will use the\n-     * bound the user provided, if they provided one, and otherwise\n-     * search the supertypes of trait bounds for region bounds. It may\n-     * be that we can derive no bound at all, in which case we return\n-     * `None`.\n-     */\n-\n     if region_bounds.len() > 1 {\n         tcx.sess.span_err(\n             region_bounds[1].span,\n@@ -1495,6 +1495,9 @@ pub fn compute_opt_region_bound<'tcx>(tcx: &ty::ctxt<'tcx>,\n     return Some(r);\n }\n \n+/// A version of `compute_opt_region_bound` for use where some region bound is required\n+/// (existential types, basically). Reports an error if no region bound can be derived and we are\n+/// in an `rscope` that does not provide a default.\n fn compute_region_bound<'tcx, AC: AstConv<'tcx>, RS:RegionScope>(\n     this: &AC,\n     rscope: &RS,\n@@ -1504,13 +1507,6 @@ fn compute_region_bound<'tcx, AC: AstConv<'tcx>, RS:RegionScope>(\n     trait_bounds: &[Rc<ty::TraitRef<'tcx>>])\n     -> ty::Region\n {\n-    /*!\n-     * A version of `compute_opt_region_bound` for use where some\n-     * region bound is required (existential types,\n-     * basically). Reports an error if no region bound can be derived\n-     * and we are in an `rscope` that does not provide a default.\n-     */\n-\n     match compute_opt_region_bound(this.tcx(), span, builtin_bounds,\n                                    region_bounds, trait_bounds) {\n         Some(r) => r,\n@@ -1534,17 +1530,13 @@ pub struct PartitionedBounds<'a> {\n     pub region_bounds: Vec<&'a ast::Lifetime>,\n }\n \n+/// Divides a list of bounds from the AST into three groups: builtin bounds (Copy, Sized etc),\n+/// general trait bounds, and region bounds.\n pub fn partition_bounds<'a>(tcx: &ty::ctxt,\n                             _span: Span,\n                             ast_bounds: &'a [&ast::TyParamBound])\n                             -> PartitionedBounds<'a>\n {\n-    /*!\n-     * Divides a list of bounds from the AST into three groups:\n-     * builtin bounds (Copy, Sized etc), general trait bounds,\n-     * and region bounds.\n-     */\n-\n     let mut builtin_bounds = ty::empty_builtin_bounds();\n     let mut region_bounds = Vec::new();\n     let mut trait_bounds = Vec::new();"}, {"sha": "0a93b3a5ec7dc93326698f4b733542f9c8ac7881", "filename": "src/librustc/middle/typeck/check/closure.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fclosure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fclosure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fclosure.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,9 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Code for type-checking closure expressions.\n- */\n+//! Code for type-checking closure expressions.\n \n use super::check_fn;\n use super::{Expectation, ExpectCastableToType, ExpectHasType, NoExpectation};"}, {"sha": "e866627be3d29ad1537423dc03d6057fa55a5d12", "filename": "src/librustc/middle/typeck/check/method/confirm.rs", "status": "modified", "additions": 9, "deletions": 17, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fconfirm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fconfirm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fconfirm.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -189,22 +189,17 @@ impl<'a,'tcx> ConfirmContext<'a,'tcx> {\n     ///////////////////////////////////////////////////////////////////////////\n     //\n \n+    /// Returns a set of substitutions for the method *receiver* where all type and region\n+    /// parameters are instantiated with fresh variables. This substitution does not include any\n+    /// parameters declared on the method itself.\n+    ///\n+    /// Note that this substitution may include late-bound regions from the impl level. If so,\n+    /// these are instantiated later in the `instantiate_method_sig` routine.\n     fn fresh_receiver_substs(&mut self,\n                              self_ty: Ty<'tcx>,\n                              pick: &probe::Pick<'tcx>)\n                              -> (subst::Substs<'tcx>, MethodOrigin<'tcx>)\n     {\n-        /*!\n-         * Returns a set of substitutions for the method *receiver*\n-         * where all type and region parameters are instantiated with\n-         * fresh variables. This substitution does not include any\n-         * parameters declared on the method itself.\n-         *\n-         * Note that this substitution may include late-bound regions\n-         * from the impl level. If so, these are instantiated later in\n-         * the `instantiate_method_sig` routine.\n-         */\n-\n         match pick.kind {\n             probe::InherentImplPick(impl_def_id) => {\n                 assert!(ty::impl_trait_ref(self.tcx(), impl_def_id).is_none(),\n@@ -478,14 +473,11 @@ impl<'a,'tcx> ConfirmContext<'a,'tcx> {\n     ///////////////////////////////////////////////////////////////////////////\n     // RECONCILIATION\n \n+    /// When we select a method with an `&mut self` receiver, we have to go convert any\n+    /// auto-derefs, indices, etc from `Deref` and `Index` into `DerefMut` and `IndexMut`\n+    /// respectively.\n     fn fixup_derefs_on_method_receiver_if_necessary(&self,\n                                                     method_callee: &MethodCallee) {\n-        /*!\n-         * When we select a method with an `&mut self` receiver, we have to go\n-         * convert any auto-derefs, indices, etc from `Deref` and `Index` into\n-         * `DerefMut` and `IndexMut` respectively.\n-         */\n-\n         let sig = match method_callee.ty.sty {\n             ty::ty_bare_fn(ref f) => f.sig.clone(),\n             ty::ty_closure(ref f) => f.sig.clone(),"}, {"sha": "6129e38e39c12f9e6e0810dfd0101fcd98605996", "filename": "src/librustc/middle/typeck/check/method/doc.rs", "status": "modified", "additions": 111, "deletions": 116, "changes": 227, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,119 +8,114 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# Method lookup\n-\n-Method lookup can be rather complex due to the interaction of a number\n-of factors, such as self types, autoderef, trait lookup, etc. This\n-file provides an overview of the process. More detailed notes are in\n-the code itself, naturally.\n-\n-One way to think of method lookup is that we convert an expression of\n-the form:\n-\n-    receiver.method(...)\n-\n-into a more explicit UFCS form:\n-\n-    Trait::method(ADJ(receiver), ...) // for a trait call\n-    ReceiverType::method(ADJ(receiver), ...) // for an inherent method call\n-\n-Here `ADJ` is some kind of adjustment, which is typically a series of\n-autoderefs and then possibly an autoref (e.g., `&**receiver`). However\n-we sometimes do other adjustments and coercions along the way, in\n-particular unsizing (e.g., converting from `[T, ..n]` to `[T]`).\n-\n-## The Two Phases\n-\n-Method lookup is divided into two major phases: probing (`probe.rs`)\n-and confirmation (`confirm.rs`). The probe phase is when we decide\n-what method to call and how to adjust the receiver. The confirmation\n-phase \"applies\" this selection, updating the side-tables, unifying\n-type variables, and otherwise doing side-effectful things.\n-\n-One reason for this division is to be more amenable to caching.  The\n-probe phase produces a \"pick\" (`probe::Pick`), which is designed to be\n-cacheable across method-call sites. Therefore, it does not include\n-inference variables or other information.\n-\n-## Probe phase\n-\n-The probe phase (`probe.rs`) decides what method is being called and\n-how to adjust the receiver.\n-\n-### Steps\n-\n-The first thing that the probe phase does is to create a series of\n-*steps*. This is done by progressively dereferencing the receiver type\n-until it cannot be deref'd anymore, as well as applying an optional\n-\"unsize\" step. So if the receiver has type `Rc<Box<[T, ..3]>>`, this\n-might yield:\n-\n-    Rc<Box<[T, ..3]>>\n-    Box<[T, ..3]>\n-    [T, ..3]\n-    [T]\n-\n-### Candidate assembly\n-\n-We then search along those steps to create a list of *candidates*. A\n-`Candidate` is a method item that might plausibly be the method being\n-invoked. For each candidate, we'll derive a \"transformed self type\"\n-that takes into account explicit self.\n-\n-Candidates are grouped into two kinds, inherent and extension.\n-\n-**Inherent candidates** are those that are derived from the\n-type of the receiver itself.  So, if you have a receiver of some\n-nominal type `Foo` (e.g., a struct), any methods defined within an\n-impl like `impl Foo` are inherent methods.  Nothing needs to be\n-imported to use an inherent method, they are associated with the type\n-itself (note that inherent impls can only be defined in the same\n-module as the type itself).\n-\n-FIXME: Inherent candidates are not always derived from impls.  If you\n-have a trait object, such as a value of type `Box<ToString>`, then the\n-trait methods (`to_string()`, in this case) are inherently associated\n-with it. Another case is type parameters, in which case the methods of\n-their bounds are inherent. However, this part of the rules is subject\n-to change: when DST's \"impl Trait for Trait\" is complete, trait object\n-dispatch could be subsumed into trait matching, and the type parameter\n-behavior should be reconsidered in light of where clauses.\n-\n-**Extension candidates** are derived from imported traits.  If I have\n-the trait `ToString` imported, and I call `to_string()` on a value of\n-type `T`, then we will go off to find out whether there is an impl of\n-`ToString` for `T`.  These kinds of method calls are called \"extension\n-methods\".  They can be defined in any module, not only the one that\n-defined `T`.  Furthermore, you must import the trait to call such a\n-method.\n-\n-So, let's continue our example. Imagine that we were calling a method\n-`foo` with the receiver `Rc<Box<[T, ..3]>>` and there is a trait `Foo`\n-that defines it with `&self` for the type `Rc<U>` as well as a method\n-on the type `Box` that defines `Foo` but with `&mut self`. Then we\n-might have two candidates:\n-\n-    &Rc<Box<[T, ..3]>> from the impl of `Foo` for `Rc<U>` where `U=Box<T, ..3]>\n-    &mut Box<[T, ..3]>> from the inherent impl on `Box<U>` where `U=[T, ..3]`\n-\n-### Candidate search\n-\n-Finally, to actually pick the method, we will search down the steps,\n-trying to match the receiver type against the candidate types. At\n-each step, we also consider an auto-ref and auto-mut-ref to see whether\n-that makes any of the candidates match. We pick the first step where\n-we find a match.\n-\n-In the case of our example, the first step is `Rc<Box<[T, ..3]>>`,\n-which does not itself match any candidate. But when we autoref it, we\n-get the type `&Rc<Box<[T, ..3]>>` which does match. We would then\n-recursively consider all where-clauses that appear on the impl: if\n-those match (or we cannot rule out that they do), then this is the\n-method we would pick. Otherwise, we would continue down the series of\n-steps.\n-\n-*/\n-\n+//! # Method lookup\n+//!\n+//! Method lookup can be rather complex due to the interaction of a number\n+//! of factors, such as self types, autoderef, trait lookup, etc. This\n+//! file provides an overview of the process. More detailed notes are in\n+//! the code itself, naturally.\n+//!\n+//! One way to think of method lookup is that we convert an expression of\n+//! the form:\n+//!\n+//!     receiver.method(...)\n+//!\n+//! into a more explicit UFCS form:\n+//!\n+//!     Trait::method(ADJ(receiver), ...) // for a trait call\n+//!     ReceiverType::method(ADJ(receiver), ...) // for an inherent method call\n+//!\n+//! Here `ADJ` is some kind of adjustment, which is typically a series of\n+//! autoderefs and then possibly an autoref (e.g., `&**receiver`). However\n+//! we sometimes do other adjustments and coercions along the way, in\n+//! particular unsizing (e.g., converting from `[T, ..n]` to `[T]`).\n+//!\n+//! ## The Two Phases\n+//!\n+//! Method lookup is divided into two major phases: probing (`probe.rs`)\n+//! and confirmation (`confirm.rs`). The probe phase is when we decide\n+//! what method to call and how to adjust the receiver. The confirmation\n+//! phase \"applies\" this selection, updating the side-tables, unifying\n+//! type variables, and otherwise doing side-effectful things.\n+//!\n+//! One reason for this division is to be more amenable to caching.  The\n+//! probe phase produces a \"pick\" (`probe::Pick`), which is designed to be\n+//! cacheable across method-call sites. Therefore, it does not include\n+//! inference variables or other information.\n+//!\n+//! ## Probe phase\n+//!\n+//! The probe phase (`probe.rs`) decides what method is being called and\n+//! how to adjust the receiver.\n+//!\n+//! ### Steps\n+//!\n+//! The first thing that the probe phase does is to create a series of\n+//! *steps*. This is done by progressively dereferencing the receiver type\n+//! until it cannot be deref'd anymore, as well as applying an optional\n+//! \"unsize\" step. So if the receiver has type `Rc<Box<[T, ..3]>>`, this\n+//! might yield:\n+//!\n+//!     Rc<Box<[T, ..3]>>\n+//!     Box<[T, ..3]>\n+//!     [T, ..3]\n+//!     [T]\n+//!\n+//! ### Candidate assembly\n+//!\n+//! We then search along those steps to create a list of *candidates*. A\n+//! `Candidate` is a method item that might plausibly be the method being\n+//! invoked. For each candidate, we'll derive a \"transformed self type\"\n+//! that takes into account explicit self.\n+//!\n+//! Candidates are grouped into two kinds, inherent and extension.\n+//!\n+//! **Inherent candidates** are those that are derived from the\n+//! type of the receiver itself.  So, if you have a receiver of some\n+//! nominal type `Foo` (e.g., a struct), any methods defined within an\n+//! impl like `impl Foo` are inherent methods.  Nothing needs to be\n+//! imported to use an inherent method, they are associated with the type\n+//! itself (note that inherent impls can only be defined in the same\n+//! module as the type itself).\n+//!\n+//! FIXME: Inherent candidates are not always derived from impls.  If you\n+//! have a trait object, such as a value of type `Box<ToString>`, then the\n+//! trait methods (`to_string()`, in this case) are inherently associated\n+//! with it. Another case is type parameters, in which case the methods of\n+//! their bounds are inherent. However, this part of the rules is subject\n+//! to change: when DST's \"impl Trait for Trait\" is complete, trait object\n+//! dispatch could be subsumed into trait matching, and the type parameter\n+//! behavior should be reconsidered in light of where clauses.\n+//!\n+//! **Extension candidates** are derived from imported traits.  If I have\n+//! the trait `ToString` imported, and I call `to_string()` on a value of\n+//! type `T`, then we will go off to find out whether there is an impl of\n+//! `ToString` for `T`.  These kinds of method calls are called \"extension\n+//! methods\".  They can be defined in any module, not only the one that\n+//! defined `T`.  Furthermore, you must import the trait to call such a\n+//! method.\n+//!\n+//! So, let's continue our example. Imagine that we were calling a method\n+//! `foo` with the receiver `Rc<Box<[T, ..3]>>` and there is a trait `Foo`\n+//! that defines it with `&self` for the type `Rc<U>` as well as a method\n+//! on the type `Box` that defines `Foo` but with `&mut self`. Then we\n+//! might have two candidates:\n+//!\n+//!     &Rc<Box<[T, ..3]>> from the impl of `Foo` for `Rc<U>` where `U=Box<T, ..3]>\n+//!     &mut Box<[T, ..3]>> from the inherent impl on `Box<U>` where `U=[T, ..3]`\n+//!\n+//! ### Candidate search\n+//!\n+//! Finally, to actually pick the method, we will search down the steps,\n+//! trying to match the receiver type against the candidate types. At\n+//! each step, we also consider an auto-ref and auto-mut-ref to see whether\n+//! that makes any of the candidates match. We pick the first step where\n+//! we find a match.\n+//!\n+//! In the case of our example, the first step is `Rc<Box<[T, ..3]>>`,\n+//! which does not itself match any candidate. But when we autoref it, we\n+//! get the type `&Rc<Box<[T, ..3]>>` which does match. We would then\n+//! recursively consider all where-clauses that appear on the impl: if\n+//! those match (or we cannot rule out that they do), then this is the\n+//! method we would pick. Otherwise, we would continue down the series of\n+//! steps."}, {"sha": "34c3292f8cd69b60e515228bb1283a3729113440", "filename": "src/librustc/middle/typeck/check/method/mod.rs", "status": "modified", "additions": 27, "deletions": 42, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! Method lookup: the secret sauce of Rust. See `doc.rs`. */\n+//! Method lookup: the secret sauce of Rust. See `doc.rs`.\n \n use middle::subst;\n use middle::subst::{Subst};\n@@ -56,24 +56,35 @@ pub enum CandidateSource {\n \n type MethodIndex = uint; // just for doc purposes\n \n+/// Determines whether the type `self_ty` supports a method name `method_name` or not.\n pub fn exists<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                         span: Span,\n                         method_name: ast::Name,\n                         self_ty: Ty<'tcx>,\n                         call_expr_id: ast::NodeId)\n                         -> bool\n {\n-    /*!\n-     * Determines whether the type `self_ty` supports a method name `method_name` or not.\n-     */\n-\n     match probe::probe(fcx, span, method_name, self_ty, call_expr_id) {\n         Ok(_) => true,\n         Err(NoMatch(_)) => false,\n         Err(Ambiguity(_)) => true,\n     }\n }\n \n+/// Performs method lookup. If lookup is successful, it will return the callee and store an\n+/// appropriate adjustment for the self-expr. In some cases it may report an error (e.g., invoking\n+/// the `drop` method).\n+///\n+/// # Arguments\n+///\n+/// Given a method call like `foo.bar::<T1,...Tn>(...)`:\n+///\n+/// * `fcx`:                   the surrounding `FnCtxt` (!)\n+/// * `span`:                  the span for the method call\n+/// * `method_name`:           the name of the method being called (`bar`)\n+/// * `self_ty`:               the (unadjusted) type of the self expression (`foo`)\n+/// * `supplied_method_types`: the explicit method type parameters, if any (`T1..Tn`)\n+/// * `self_expr`:             the self expression (`foo`)\n pub fn lookup<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                         span: Span,\n                         method_name: ast::Name,\n@@ -83,23 +94,6 @@ pub fn lookup<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                         self_expr: &ast::Expr)\n                         -> Result<MethodCallee<'tcx>, MethodError>\n {\n-    /*!\n-     * Performs method lookup. If lookup is successful, it will return the callee\n-     * and store an appropriate adjustment for the self-expr. In some cases it may\n-     * report an error (e.g., invoking the `drop` method).\n-     *\n-     * # Arguments\n-     *\n-     * Given a method call like `foo.bar::<T1,...Tn>(...)`:\n-     *\n-     * - `fcx`:                   the surrounding `FnCtxt` (!)\n-     * - `span`:                  the span for the method call\n-     * - `method_name`:           the name of the method being called (`bar`)\n-     * - `self_ty`:               the (unadjusted) type of the self expression (`foo`)\n-     * - `supplied_method_types`: the explicit method type parameters, if any (`T1..Tn`)\n-     * - `self_expr`:             the self expression (`foo`)\n-     */\n-\n     debug!(\"lookup(method_name={}, self_ty={}, call_expr={}, self_expr={})\",\n            method_name.repr(fcx.tcx()),\n            self_ty.repr(fcx.tcx()),\n@@ -124,6 +118,15 @@ pub fn lookup_in_trait<'a, 'tcx>(fcx: &'a FnCtxt<'a, 'tcx>,\n                              self_ty, opt_input_types)\n }\n \n+/// `lookup_in_trait_adjusted` is used for overloaded operators. It does a very narrow slice of\n+/// what the normal probe/confirm path does. In particular, it doesn't really do any probing: it\n+/// simply constructs an obligation for a particular trait with the given self-type and checks\n+/// whether that trait is implemented.\n+///\n+/// FIXME(#18741) -- It seems likely that we can consolidate some of this code with the other\n+/// method-lookup code. In particular, autoderef on index is basically identical to autoderef with\n+/// normal probes, except that the test also looks for built-in indexing. Also, the second half of\n+/// this method is basically the same as confirmation.\n pub fn lookup_in_trait_adjusted<'a, 'tcx>(fcx: &'a FnCtxt<'a, 'tcx>,\n                                           span: Span,\n                                           self_expr: Option<&'a ast::Expr>,\n@@ -134,21 +137,6 @@ pub fn lookup_in_trait_adjusted<'a, 'tcx>(fcx: &'a FnCtxt<'a, 'tcx>,\n                                           opt_input_types: Option<Vec<Ty<'tcx>>>)\n                                           -> Option<MethodCallee<'tcx>>\n {\n-    /*!\n-     * `lookup_in_trait_adjusted` is used for overloaded operators. It\n-     * does a very narrow slice of what the normal probe/confirm path\n-     * does. In particular, it doesn't really do any probing: it\n-     * simply constructs an obligation for a particular trait with the\n-     * given self-type and checks whether that trait is implemented.\n-     *\n-     * FIXME(#18741) -- It seems likely that we can consolidate some of this\n-     * code with the other method-lookup code. In particular,\n-     * autoderef on index is basically identical to autoderef with\n-     * normal probes, except that the test also looks for built-in\n-     * indexing. Also, the second half of this method is basically\n-     * the same as confirmation.\n-     */\n-\n     debug!(\"lookup_in_trait_adjusted(self_ty={}, self_expr={}, m_name={}, trait_def_id={})\",\n            self_ty.repr(fcx.tcx()),\n            self_expr.repr(fcx.tcx()),\n@@ -408,16 +396,13 @@ pub fn report_error<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     }\n }\n \n+/// Find method with name `method_name` defined in `trait_def_id` and return it, along with its\n+/// index (or `None`, if no such method).\n fn trait_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                       trait_def_id: ast::DefId,\n                       method_name: ast::Name)\n                       -> Option<(uint, Rc<ty::Method<'tcx>>)>\n {\n-    /*!\n-     * Find method with name `method_name` defined in `trait_def_id` and return it,\n-     * along with its index (or `None`, if no such method).\n-     */\n-\n     let trait_items = ty::trait_items(tcx, trait_def_id);\n     trait_items\n         .iter()"}, {"sha": "484d72130e61d94182df0c71e57e88a4677db01f", "filename": "src/librustc/middle/typeck/check/method/probe.rs", "status": "modified", "additions": 37, "deletions": 56, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fprobe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fprobe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmethod%2Fprobe.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -807,33 +807,26 @@ impl<'a,'tcx> ProbeContext<'a,'tcx> {\n         })\n     }\n \n+    /// Sometimes we get in a situation where we have multiple probes that are all impls of the\n+    /// same trait, but we don't know which impl to use. In this case, since in all cases the\n+    /// external interface of the method can be determined from the trait, it's ok not to decide.\n+    /// We can basically just collapse all of the probes for various impls into one where-clause\n+    /// probe. This will result in a pending obligation so when more type-info is available we can\n+    /// make the final decision.\n+    ///\n+    /// Example (`src/test/run-pass/method-two-trait-defer-resolution-1.rs`):\n+    ///\n+    /// ```\n+    /// trait Foo { ... }\n+    /// impl Foo for Vec<int> { ... }\n+    /// impl Foo for Vec<uint> { ... }\n+    /// ```\n+    ///\n+    /// Now imagine the receiver is `Vec<_>`. It doesn't really matter at this time which impl we\n+    /// use, so it's ok to just commit to \"using the method from the trait Foo\".\n     fn collapse_candidates_to_trait_pick(&self,\n                                          probes: &[&Candidate<'tcx>])\n                                          -> Option<Pick<'tcx>> {\n-        /*!\n-         * Sometimes we get in a situation where we have multiple\n-         * probes that are all impls of the same trait, but we don't\n-         * know which impl to use. In this case, since in all cases\n-         * the external interface of the method can be determined from\n-         * the trait, it's ok not to decide.  We can basically just\n-         * collapse all of the probes for various impls into one\n-         * where-clause probe. This will result in a pending\n-         * obligation so when more type-info is available we can make\n-         * the final decision.\n-         *\n-         * Example (`src/test/run-pass/method-two-trait-defer-resolution-1.rs`):\n-         *\n-         * ```\n-         * trait Foo { ... }\n-         * impl Foo for Vec<int> { ... }\n-         * impl Foo for Vec<uint> { ... }\n-         * ```\n-         *\n-         * Now imagine the receiver is `Vec<_>`. It doesn't really\n-         * matter at this time which impl we use, so it's ok to just\n-         * commit to \"using the method from the trait Foo\".\n-         */\n-\n         // Do all probes correspond to the same trait?\n         let trait_data = match probes[0].to_trait_data() {\n             Some(data) => data,\n@@ -952,36 +945,27 @@ impl<'a,'tcx> ProbeContext<'a,'tcx> {\n         subst::Substs::new(type_vars, region_placeholders)\n     }\n \n+    /// Replace late-bound-regions bound by `value` with `'static` using\n+    /// `ty::erase_late_bound_regions`.\n+    ///\n+    /// This is only a reasonable thing to do during the *probe* phase, not the *confirm* phase, of\n+    /// method matching. It is reasonable during the probe phase because we don't consider region\n+    /// relationships at all. Therefore, we can just replace all the region variables with 'static\n+    /// rather than creating fresh region variables. This is nice for two reasons:\n+    ///\n+    /// 1. Because the numbers of the region variables would otherwise be fairly unique to this\n+    ///    particular method call, it winds up creating fewer types overall, which helps for memory\n+    ///    usage. (Admittedly, this is a rather small effect, though measureable.)\n+    ///\n+    /// 2. It makes it easier to deal with higher-ranked trait bounds, because we can replace any\n+    ///    late-bound regions with 'static. Otherwise, if we were going to replace late-bound\n+    ///    regions with actual region variables as is proper, we'd have to ensure that the same\n+    ///    region got replaced with the same variable, which requires a bit more coordination\n+    ///    and/or tracking the substitution and\n+    ///    so forth.\n     fn erase_late_bound_regions<T>(&self, value: &T) -> T\n         where T : HigherRankedFoldable<'tcx>\n     {\n-        /*!\n-         * Replace late-bound-regions bound by `value` with `'static`\n-         * using `ty::erase_late_bound_regions`.\n-         *\n-         * This is only a reasonable thing to do during the *probe*\n-         * phase, not the *confirm* phase, of method matching. It is\n-         * reasonable during the probe phase because we don't consider\n-         * region relationships at all. Therefore, we can just replace\n-         * all the region variables with 'static rather than creating\n-         * fresh region variables. This is nice for two reasons:\n-         *\n-         * 1. Because the numbers of the region variables would\n-         *    otherwise be fairly unique to this particular method\n-         *    call, it winds up creating fewer types overall, which\n-         *    helps for memory usage. (Admittedly, this is a rather\n-         *    small effect, though measureable.)\n-         *\n-         * 2. It makes it easier to deal with higher-ranked trait\n-         *    bounds, because we can replace any late-bound regions\n-         *    with 'static. Otherwise, if we were going to replace\n-         *    late-bound regions with actual region variables as is\n-         *    proper, we'd have to ensure that the same region got\n-         *    replaced with the same variable, which requires a bit\n-         *    more coordination and/or tracking the substitution and\n-         *    so forth.\n-         */\n-\n         ty::erase_late_bound_regions(self.tcx(), value)\n     }\n }\n@@ -1000,16 +984,13 @@ fn impl_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n         .and_then(|item| item.as_opt_method())\n }\n \n+/// Find method with name `method_name` defined in `trait_def_id` and return it, along with its\n+/// index (or `None`, if no such method).\n fn trait_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                       trait_def_id: ast::DefId,\n                       method_name: ast::Name)\n                       -> Option<(uint, Rc<ty::Method<'tcx>>)>\n {\n-    /*!\n-     * Find method with name `method_name` defined in `trait_def_id` and return it,\n-     * along with its index (or `None`, if no such method).\n-     */\n-\n     let trait_items = ty::trait_items(tcx, trait_def_id);\n     trait_items\n         .iter()"}, {"sha": "40a38d45fa0785beafb717c58d354986af4e05c6", "filename": "src/librustc/middle/typeck/check/mod.rs", "status": "modified", "additions": 114, "deletions": 182, "changes": 296, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -486,6 +486,12 @@ impl<'a, 'tcx, 'v> Visitor<'v> for GatherLocalsVisitor<'a, 'tcx> {\n \n }\n \n+/// Helper used by check_bare_fn and check_expr_fn. Does the grungy work of checking a function\n+/// body and returns the function context used for that purpose, since in the case of a fn item\n+/// there is still a bit more to do.\n+///\n+/// * ...\n+/// * inherited: other fields inherited from the enclosing fn (if any)\n fn check_fn<'a, 'tcx>(ccx: &'a CrateCtxt<'a, 'tcx>,\n                       fn_style: ast::FnStyle,\n                       fn_style_id: ast::NodeId,\n@@ -495,16 +501,6 @@ fn check_fn<'a, 'tcx>(ccx: &'a CrateCtxt<'a, 'tcx>,\n                       body: &ast::Block,\n                       inherited: &'a Inherited<'a, 'tcx>)\n                       -> FnCtxt<'a, 'tcx> {\n-    /*!\n-     * Helper used by check_bare_fn and check_expr_fn.  Does the\n-     * grungy work of checking a function body and returns the\n-     * function context used for that purpose, since in the case of a\n-     * fn item there is still a bit more to do.\n-     *\n-     * - ...\n-     * - inherited: other fields inherited from the enclosing fn (if any)\n-     */\n-\n     let tcx = ccx.tcx;\n     let err_count_on_creation = tcx.sess.err_count();\n \n@@ -701,19 +697,17 @@ pub fn check_item(ccx: &CrateCtxt, it: &ast::Item) {\n     }\n }\n \n+/// Type checks a method body.\n+///\n+/// # Parameters\n+///\n+/// * `item_generics`: generics defined on the impl/trait that contains\n+///   the method\n+/// * `self_bound`: bound for the `Self` type parameter, if any\n+/// * `method`: the method definition\n fn check_method_body<'a, 'tcx>(ccx: &CrateCtxt<'a, 'tcx>,\n                                item_generics: &ty::Generics<'tcx>,\n                                method: &ast::Method) {\n-    /*!\n-     * Type checks a method body.\n-     *\n-     * # Parameters\n-     * - `item_generics`: generics defined on the impl/trait that contains\n-     *   the method\n-     * - `self_bound`: bound for the `Self` type parameter, if any\n-     * - `method`: the method definition\n-     */\n-\n     debug!(\"check_method_body(item_generics={}, method.id={})\",\n             item_generics.repr(ccx.tcx),\n             method.id);\n@@ -897,19 +891,17 @@ fn check_impl_items_against_trait<'a, 'tcx>(ccx: &CrateCtxt<'a, 'tcx>,\n     }\n }\n \n-/**\n- * Checks that a method from an impl conforms to the signature of\n- * the same method as declared in the trait.\n- *\n- * # Parameters\n- *\n- * - impl_generics: the generics declared on the impl itself (not the method!)\n- * - impl_m: type of the method we are checking\n- * - impl_m_span: span to use for reporting errors\n- * - impl_m_body_id: id of the method body\n- * - trait_m: the method in the trait\n- * - trait_to_impl_substs: the substitutions used on the type of the trait\n- */\n+/// Checks that a method from an impl conforms to the signature of\n+/// the same method as declared in the trait.\n+///\n+/// # Parameters\n+///\n+/// - impl_generics: the generics declared on the impl itself (not the method!)\n+/// - impl_m: type of the method we are checking\n+/// - impl_m_span: span to use for reporting errors\n+/// - impl_m_body_id: id of the method body\n+/// - trait_m: the method in the trait\n+/// - trait_to_impl_substs: the substitutions used on the type of the trait\n fn compare_impl_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                              impl_m: &ty::Method<'tcx>,\n                              impl_m_span: Span,\n@@ -1222,6 +1214,33 @@ fn compare_impl_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n     // parameters.\n     infcx.resolve_regions_and_report_errors();\n \n+    /// Check that region bounds on impl method are the same as those on the trait. In principle,\n+    /// it could be ok for there to be fewer region bounds on the impl method, but this leads to an\n+    /// annoying corner case that is painful to handle (described below), so for now we can just\n+    /// forbid it.\n+    ///\n+    /// Example (see `src/test/compile-fail/regions-bound-missing-bound-in-impl.rs`):\n+    ///\n+    /// ```\n+    /// trait Foo<'a> {\n+    ///     fn method1<'b>();\n+    ///     fn method2<'b:'a>();\n+    /// }\n+    ///\n+    /// impl<'a> Foo<'a> for ... {\n+    ///     fn method1<'b:'a>() { .. case 1, definitely bad .. }\n+    ///     fn method2<'b>() { .. case 2, could be ok .. }\n+    /// }\n+    /// ```\n+    ///\n+    /// The \"definitely bad\" case is case #1. Here, the impl adds an extra constraint not present\n+    /// in the trait.\n+    ///\n+    /// The \"maybe bad\" case is case #2. Here, the impl adds an extra constraint not present in the\n+    /// trait. We could in principle allow this, but it interacts in a complex way with early/late\n+    /// bound resolution of lifetimes. Basically the presence or absence of a lifetime bound\n+    /// affects whether the lifetime is early/late bound, and right now the code breaks if the\n+    /// trait has an early bound lifetime parameter and the method does not.\n     fn check_region_bounds_on_impl_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                                 span: Span,\n                                                 impl_m: &ty::Method<'tcx>,\n@@ -1232,39 +1251,6 @@ fn compare_impl_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                                 impl_to_skol_substs: &Substs<'tcx>)\n                                                 -> bool\n     {\n-        /*!\n-\n-        Check that region bounds on impl method are the same as those\n-        on the trait. In principle, it could be ok for there to be\n-        fewer region bounds on the impl method, but this leads to an\n-        annoying corner case that is painful to handle (described\n-        below), so for now we can just forbid it.\n-\n-        Example (see\n-        `src/test/compile-fail/regions-bound-missing-bound-in-impl.rs`):\n-\n-            trait Foo<'a> {\n-                fn method1<'b>();\n-                fn method2<'b:'a>();\n-            }\n-\n-            impl<'a> Foo<'a> for ... {\n-                fn method1<'b:'a>() { .. case 1, definitely bad .. }\n-                fn method2<'b>() { .. case 2, could be ok .. }\n-            }\n-\n-        The \"definitely bad\" case is case #1. Here, the impl adds an\n-        extra constraint not present in the trait.\n-\n-        The \"maybe bad\" case is case #2. Here, the impl adds an extra\n-        constraint not present in the trait. We could in principle\n-        allow this, but it interacts in a complex way with early/late\n-        bound resolution of lifetimes. Basically the presence or\n-        absence of a lifetime bound affects whether the lifetime is\n-        early/late bound, and right now the code breaks if the trait\n-        has an early bound lifetime parameter and the method does not.\n-\n-        */\n \n         let trait_params = trait_generics.regions.get_slice(subst::FnSpace);\n         let impl_params = impl_generics.regions.get_slice(subst::FnSpace);\n@@ -1770,23 +1756,17 @@ impl<'a, 'tcx> FnCtxt<'a, 'tcx> {\n         }\n     }\n \n+    /// Returns the type of `def_id` with all generics replaced by by fresh type/region variables.\n+    /// Also returns the substitution from the type parameters on `def_id` to the fresh variables.\n+    /// Registers any trait obligations specified on `def_id` at the same time.\n+    ///\n+    /// Note that function is only intended to be used with types (notably, not impls). This is\n+    /// because it doesn't do any instantiation of late-bound regions.\n     pub fn instantiate_type(&self,\n                             span: Span,\n                             def_id: ast::DefId)\n                             -> TypeAndSubsts<'tcx>\n     {\n-        /*!\n-         * Returns the type of `def_id` with all generics replaced by\n-         * by fresh type/region variables. Also returns the\n-         * substitution from the type parameters on `def_id` to the\n-         * fresh variables. Registers any trait obligations specified\n-         * on `def_id` at the same time.\n-         *\n-         * Note that function is only intended to be used with types\n-         * (notably, not impls). This is because it doesn't do any\n-         * instantiation of late-bound regions.\n-         */\n-\n         let polytype =\n             ty::lookup_item_type(self.tcx(), def_id);\n         let substs =\n@@ -1886,26 +1866,19 @@ impl<'a, 'tcx> FnCtxt<'a, 'tcx> {\n         }\n     }\n \n+    /// Fetch type of `expr` after applying adjustments that have been recorded in the fcx.\n     pub fn expr_ty_adjusted(&self, expr: &ast::Expr) -> Ty<'tcx> {\n-        /*!\n-         * Fetch type of `expr` after applying adjustments that\n-         * have been recorded in the fcx.\n-         */\n-\n         let adjustments = self.inh.adjustments.borrow();\n         let adjustment = adjustments.get(&expr.id);\n         self.adjust_expr_ty(expr, adjustment)\n     }\n \n+    /// Apply `adjustment` to the type of `expr`\n     pub fn adjust_expr_ty(&self,\n                           expr: &ast::Expr,\n                           adjustment: Option<&ty::AutoAdjustment<'tcx>>)\n                           -> Ty<'tcx>\n     {\n-        /*!\n-         * Apply `adjustment` to the type of `expr`\n-         */\n-\n         let raw_ty = self.expr_ty(expr);\n         let raw_ty = self.infcx().shallow_resolve(raw_ty);\n         ty::adjust_ty(self.tcx(),\n@@ -2013,16 +1986,13 @@ impl<'a, 'tcx> FnCtxt<'a, 'tcx> {\n         self.infcx().report_mismatched_types(sp, e, a, err)\n     }\n \n+    /// Registers an obligation for checking later, during regionck, that the type `ty` must\n+    /// outlive the region `r`.\n     pub fn register_region_obligation(&self,\n                                       origin: infer::SubregionOrigin<'tcx>,\n                                       ty: Ty<'tcx>,\n                                       r: ty::Region)\n     {\n-        /*!\n-         * Registers an obligation for checking later, during\n-         * regionck, that the type `ty` must outlive the region `r`.\n-         */\n-\n         let mut region_obligations = self.inh.region_obligations.borrow_mut();\n         let region_obligation = RegionObligation { sub_region: r,\n                                                    sup_type: ty,\n@@ -2045,31 +2015,29 @@ impl<'a, 'tcx> FnCtxt<'a, 'tcx> {\n         }\n     }\n \n+    /// Given a fully substituted set of bounds (`generic_bounds`), and the values with which each\n+    /// type/region parameter was instantiated (`substs`), creates and registers suitable\n+    /// trait/region obligations.\n+    ///\n+    /// For example, if there is a function:\n+    ///\n+    /// ```\n+    /// fn foo<'a,T:'a>(...)\n+    /// ```\n+    ///\n+    /// and a reference:\n+    ///\n+    /// ```\n+    /// let f = foo;\n+    /// ```\n+    ///\n+    /// Then we will create a fresh region variable `'$0` and a fresh type variable `$1` for `'a`\n+    /// and `T`. This routine will add a region obligation `$1:'$0` and register it locally.\n     pub fn add_obligations_for_parameters(&self,\n                                           cause: traits::ObligationCause<'tcx>,\n                                           substs: &Substs<'tcx>,\n                                           generic_bounds: &ty::GenericBounds<'tcx>)\n     {\n-        /*!\n-         * Given a fully substituted set of bounds (`generic_bounds`),\n-         * and the values with which each type/region parameter was\n-         * instantiated (`substs`), creates and registers suitable\n-         * trait/region obligations.\n-         *\n-         * For example, if there is a function:\n-         *\n-         *    fn foo<'a,T:'a>(...)\n-         *\n-         * and a reference:\n-         *\n-         *    let f = foo;\n-         *\n-         * Then we will create a fresh region variable `'$0` and a\n-         * fresh type variable `$1` for `'a` and `T`. This routine\n-         * will add a region obligation `$1:'$0` and register it\n-         * locally.\n-         */\n-\n         assert!(!generic_bounds.has_escaping_regions());\n \n         debug!(\"add_obligations_for_parameters(substs={}, generic_bounds={})\",\n@@ -2160,22 +2128,17 @@ pub enum LvaluePreference {\n     NoPreference\n }\n \n+/// Executes an autoderef loop for the type `t`. At each step, invokes `should_stop` to decide\n+/// whether to terminate the loop. Returns the final type and number of derefs that it performed.\n+///\n+/// Note: this method does not modify the adjustments table. The caller is responsible for\n+/// inserting an AutoAdjustment record into the `fcx` using one of the suitable methods.\n pub fn autoderef<'a, 'tcx, T>(fcx: &FnCtxt<'a, 'tcx>, sp: Span,\n                               base_ty: Ty<'tcx>,\n                               expr_id: Option<ast::NodeId>,\n                               mut lvalue_pref: LvaluePreference,\n                               should_stop: |Ty<'tcx>, uint| -> Option<T>)\n                               -> (Ty<'tcx>, uint, Option<T>) {\n-    /*!\n-     * Executes an autoderef loop for the type `t`. At each step, invokes\n-     * `should_stop` to decide whether to terminate the loop. Returns\n-     * the final type and number of derefs that it performed.\n-     *\n-     * Note: this method does not modify the adjustments table. The caller is\n-     * responsible for inserting an AutoAdjustment record into the `fcx`\n-     * using one of the suitable methods.\n-     */\n-\n     let mut t = base_ty;\n     for autoderefs in range(0, fcx.tcx().sess.recursion_limit.get()) {\n         let resolved_t = structurally_resolved_type(fcx, sp, t);\n@@ -2306,19 +2269,14 @@ fn try_overloaded_deref<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     make_overloaded_lvalue_return_type(fcx, method_call, method)\n }\n \n+/// For the overloaded lvalue expressions (`*x`, `x[3]`), the trait returns a type of `&T`, but the\n+/// actual type we assign to the *expression* is `T`. So this function just peels off the return\n+/// type by one layer to yield `T`. It also inserts the `method-callee` into the method map.\n fn make_overloaded_lvalue_return_type<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                                 method_call: Option<MethodCall>,\n                                                 method: Option<MethodCallee<'tcx>>)\n                                                 -> Option<ty::mt<'tcx>>\n {\n-    /*!\n-     * For the overloaded lvalue expressions (`*x`, `x[3]`), the trait\n-     * returns a type of `&T`, but the actual type we assign to the\n-     * *expression* is `T`. So this function just peels off the return\n-     * type by one layer to yield `T`. It also inserts the\n-     * `method-callee` into the method map.\n-     */\n-\n     match method {\n         Some(method) => {\n             let ref_ty = ty::ty_fn_ret(method.ty);\n@@ -2380,6 +2338,8 @@ fn autoderef_for_index<'a, 'tcx, T>(fcx: &FnCtxt<'a, 'tcx>,\n     }\n }\n \n+/// Autoderefs `base_expr`, looking for a `Slice` impl. If it finds one, installs the relevant\n+/// method info and returns the result type (else None).\n fn try_overloaded_slice<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                   method_call: MethodCall,\n                                   expr: &ast::Expr,\n@@ -2390,12 +2350,6 @@ fn try_overloaded_slice<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                   mutbl: ast::Mutability)\n                                   -> Option<Ty<'tcx>> // return type is result of slice\n {\n-    /*!\n-     * Autoderefs `base_expr`, looking for a `Slice` impl. If it\n-     * finds one, installs the relevant method info and returns the\n-     * result type (else None).\n-     */\n-\n     let lvalue_pref = match mutbl {\n         ast::MutMutable => PreferMutLvalue,\n         ast::MutImmutable => NoPreference\n@@ -2436,6 +2390,8 @@ fn try_overloaded_slice<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     })\n }\n \n+/// Checks for a `Slice` (or `SliceMut`) impl at the relevant level of autoderef. If it finds one,\n+/// installs method info and returns type of method (else None).\n fn try_overloaded_slice_step<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                        method_call: MethodCall,\n                                        expr: &ast::Expr,\n@@ -2448,12 +2404,6 @@ fn try_overloaded_slice_step<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                        // result type is type of method being called\n                                        -> Option<Ty<'tcx>>\n {\n-    /*!\n-     * Checks for a `Slice` (or `SliceMut`) impl at the relevant level\n-     * of autoderef. If it finds one, installs method info and returns\n-     * type of method (else None).\n-     */\n-\n     let method = if mutbl == ast::MutMutable {\n         // Try `SliceMut` first, if preferred.\n         match fcx.tcx().lang_items.slice_mut_trait() {\n@@ -2510,6 +2460,10 @@ fn try_overloaded_slice_step<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     })\n }\n \n+/// To type-check `base_expr[index_expr]`, we progressively autoderef (and otherwise adjust)\n+/// `base_expr`, looking for a type which either supports builtin indexing or overloaded indexing.\n+/// This loop implements one step in that search; the autoderef loop is implemented by\n+/// `autoderef_for_index`.\n fn try_index_step<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                             method_call: MethodCall,\n                             expr: &ast::Expr,\n@@ -2519,13 +2473,6 @@ fn try_index_step<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                             lvalue_pref: LvaluePreference)\n                             -> Option<(/*index type*/ Ty<'tcx>, /*element type*/ Ty<'tcx>)>\n {\n-    /*!\n-     * To type-check `base_expr[index_expr]`, we progressively autoderef (and otherwise adjust)\n-     * `base_expr`, looking for a type which either supports builtin indexing or overloaded\n-     * indexing. This loop implements one step in that search; the autoderef loop is implemented\n-     * by `autoderef_for_index`.\n-     */\n-\n     debug!(\"try_index_step(expr={}, base_expr.id={}, adjusted_ty={}, adjustment={})\",\n            expr.repr(fcx.tcx()),\n            base_expr.repr(fcx.tcx()),\n@@ -2712,6 +2659,8 @@ fn check_method_argument_types<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     }\n }\n \n+/// Generic function that factors out common logic from function calls, method calls and overloaded\n+/// operators.\n fn check_argument_types<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                   sp: Span,\n                                   fn_inputs: &[Ty<'tcx>],\n@@ -2720,12 +2669,6 @@ fn check_argument_types<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                   deref_args: DerefArgs,\n                                   variadic: bool,\n                                   tuple_arguments: TupleArgumentsFlag) {\n-    /*!\n-     *\n-     * Generic function that factors out common logic from\n-     * function calls, method calls and overloaded operators.\n-     */\n-\n     let tcx = fcx.ccx.tcx;\n \n     // Grab the argument types, supplying fresh type variables\n@@ -5289,6 +5232,15 @@ pub fn instantiate_path<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n         }\n     }\n \n+    /// Finds the parameters that the user provided and adds them to `substs`. If too many\n+    /// parameters are provided, then reports an error and clears the output vector.\n+    ///\n+    /// We clear the output vector because that will cause the `adjust_XXX_parameters()` later to\n+    /// use inference variables. This seems less likely to lead to derived errors.\n+    ///\n+    /// Note that we *do not* check for *too few* parameters here. Due to the presence of defaults\n+    /// etc that is more complicated. I wanted however to do the reporting of *too many* parameters\n+    /// here because we can easily use the precise span of the N+1'th parameter.\n     fn push_explicit_parameters_from_segment_to_substs<'a, 'tcx>(\n         fcx: &FnCtxt<'a, 'tcx>,\n         space: subst::ParamSpace,\n@@ -5298,23 +5250,6 @@ pub fn instantiate_path<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n         segment: &ast::PathSegment,\n         substs: &mut Substs<'tcx>)\n     {\n-        /*!\n-         * Finds the parameters that the user provided and adds them\n-         * to `substs`. If too many parameters are provided, then\n-         * reports an error and clears the output vector.\n-         *\n-         * We clear the output vector because that will cause the\n-         * `adjust_XXX_parameters()` later to use inference\n-         * variables. This seems less likely to lead to derived\n-         * errors.\n-         *\n-         * Note that we *do not* check for *too few* parameters here.\n-         * Due to the presence of defaults etc that is more\n-         * complicated. I wanted however to do the reporting of *too\n-         * many* parameters here because we can easily use the precise\n-         * span of the N+1'th parameter.\n-         */\n-\n         match segment.parameters {\n             ast::AngleBracketedParameters(ref data) => {\n                 push_explicit_angle_bracketed_parameters_from_segment_to_substs(\n@@ -5373,6 +5308,12 @@ pub fn instantiate_path<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n         }\n     }\n \n+    /// As with\n+    /// `push_explicit_angle_bracketed_parameters_from_segment_to_substs`,\n+    /// but intended for `Foo(A,B) -> C` form. This expands to\n+    /// roughly the same thing as `Foo<(A,B),C>`. One important\n+    /// difference has to do with the treatment of anonymous\n+    /// regions, which are translated into bound regions (NYI).\n     fn push_explicit_parenthesized_parameters_from_segment_to_substs<'a, 'tcx>(\n         fcx: &FnCtxt<'a, 'tcx>,\n         space: subst::ParamSpace,\n@@ -5381,15 +5322,6 @@ pub fn instantiate_path<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n         data: &ast::ParenthesizedParameterData,\n         substs: &mut Substs<'tcx>)\n     {\n-        /*!\n-         * As with\n-         * `push_explicit_angle_bracketed_parameters_from_segment_to_substs`,\n-         * but intended for `Foo(A,B) -> C` form. This expands to\n-         * roughly the same thing as `Foo<(A,B),C>`. One important\n-         * difference has to do with the treatment of anonymous\n-         * regions, which are translated into bound regions (NYI).\n-         */\n-\n         let type_count = type_defs.len(space);\n         if type_count < 2 {\n             span_err!(fcx.tcx().sess, span, E0167,\n@@ -5608,7 +5540,7 @@ pub fn check_bounds_are_used<'a, 'tcx>(ccx: &CrateCtxt<'a, 'tcx>,\n         if !*b {\n             span_err!(ccx.tcx.sess, span, E0091,\n                 \"type parameter `{}` is unused\",\n-                token::get_ident(tps.get(i).ident));\n+                token::get_ident(tps[i].ident));\n         }\n     }\n }"}, {"sha": "bc6e7d9d87ffed20635b46cf075e3a000b15aa23", "filename": "src/librustc/middle/typeck/check/regionck.rs", "status": "modified", "additions": 223, "deletions": 314, "changes": 537, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionck.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,115 +8,111 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-The region check is a final pass that runs over the AST after we have\n-inferred the type constraints but before we have actually finalized\n-the types.  Its purpose is to embed a variety of region constraints.\n-Inserting these constraints as a separate pass is good because (1) it\n-localizes the code that has to do with region inference and (2) often\n-we cannot know what constraints are needed until the basic types have\n-been inferred.\n-\n-### Interaction with the borrow checker\n-\n-In general, the job of the borrowck module (which runs later) is to\n-check that all soundness criteria are met, given a particular set of\n-regions. The job of *this* module is to anticipate the needs of the\n-borrow checker and infer regions that will satisfy its requirements.\n-It is generally true that the inference doesn't need to be sound,\n-meaning that if there is a bug and we inferred bad regions, the borrow\n-checker should catch it. This is not entirely true though; for\n-example, the borrow checker doesn't check subtyping, and it doesn't\n-check that region pointers are always live when they are used. It\n-might be worthwhile to fix this so that borrowck serves as a kind of\n-verification step -- that would add confidence in the overall\n-correctness of the compiler, at the cost of duplicating some type\n-checks and effort.\n-\n-### Inferring the duration of borrows, automatic and otherwise\n-\n-Whenever we introduce a borrowed pointer, for example as the result of\n-a borrow expression `let x = &data`, the lifetime of the pointer `x`\n-is always specified as a region inference variable. `regionck` has the\n-job of adding constraints such that this inference variable is as\n-narrow as possible while still accommodating all uses (that is, every\n-dereference of the resulting pointer must be within the lifetime).\n-\n-#### Reborrows\n-\n-Generally speaking, `regionck` does NOT try to ensure that the data\n-`data` will outlive the pointer `x`. That is the job of borrowck.  The\n-one exception is when \"re-borrowing\" the contents of another borrowed\n-pointer. For example, imagine you have a borrowed pointer `b` with\n-lifetime L1 and you have an expression `&*b`. The result of this\n-expression will be another borrowed pointer with lifetime L2 (which is\n-an inference variable). The borrow checker is going to enforce the\n-constraint that L2 < L1, because otherwise you are re-borrowing data\n-for a lifetime larger than the original loan.  However, without the\n-routines in this module, the region inferencer would not know of this\n-dependency and thus it might infer the lifetime of L2 to be greater\n-than L1 (issue #3148).\n-\n-There are a number of troublesome scenarios in the tests\n-`region-dependent-*.rs`, but here is one example:\n-\n-    struct Foo { i: int }\n-    struct Bar { foo: Foo  }\n-    fn get_i(x: &'a Bar) -> &'a int {\n-       let foo = &x.foo; // Lifetime L1\n-       &foo.i            // Lifetime L2\n-    }\n-\n-Note that this comes up either with `&` expressions, `ref`\n-bindings, and `autorefs`, which are the three ways to introduce\n-a borrow.\n-\n-The key point here is that when you are borrowing a value that\n-is \"guaranteed\" by a borrowed pointer, you must link the\n-lifetime of that borrowed pointer (L1, here) to the lifetime of\n-the borrow itself (L2).  What do I mean by \"guaranteed\" by a\n-borrowed pointer? I mean any data that is reached by first\n-dereferencing a borrowed pointer and then either traversing\n-interior offsets or owned pointers.  We say that the guarantor\n-of such data it the region of the borrowed pointer that was\n-traversed.  This is essentially the same as the ownership\n-relation, except that a borrowed pointer never owns its\n-contents.\n-\n-### Inferring borrow kinds for upvars\n-\n-Whenever there is a closure expression, we need to determine how each\n-upvar is used. We do this by initially assigning each upvar an\n-immutable \"borrow kind\" (see `ty::BorrowKind` for details) and then\n-\"escalating\" the kind as needed. The borrow kind proceeds according to\n-the following lattice:\n-\n-    ty::ImmBorrow -> ty::UniqueImmBorrow -> ty::MutBorrow\n-\n-So, for example, if we see an assignment `x = 5` to an upvar `x`, we\n-will promote its borrow kind to mutable borrow. If we see an `&mut x`\n-we'll do the same. Naturally, this applies not just to the upvar, but\n-to everything owned by `x`, so the result is the same for something\n-like `x.f = 5` and so on (presuming `x` is not a borrowed pointer to a\n-struct). These adjustments are performed in\n-`adjust_upvar_borrow_kind()` (you can trace backwards through the code\n-from there).\n-\n-The fact that we are inferring borrow kinds as we go results in a\n-semi-hacky interaction with mem-categorization. In particular,\n-mem-categorization will query the current borrow kind as it\n-categorizes, and we'll return the *current* value, but this may get\n-adjusted later. Therefore, in this module, we generally ignore the\n-borrow kind (and derived mutabilities) that are returned from\n-mem-categorization, since they may be inaccurate. (Another option\n-would be to use a unification scheme, where instead of returning a\n-concrete borrow kind like `ty::ImmBorrow`, we return a\n-`ty::InferBorrow(upvar_id)` or something like that, but this would\n-then mean that all later passes would have to check for these figments\n-and report an error, and it just seems like more mess in the end.)\n-\n-*/\n+//! The region check is a final pass that runs over the AST after we have\n+//! inferred the type constraints but before we have actually finalized\n+//! the types.  Its purpose is to embed a variety of region constraints.\n+//! Inserting these constraints as a separate pass is good because (1) it\n+//! localizes the code that has to do with region inference and (2) often\n+//! we cannot know what constraints are needed until the basic types have\n+//! been inferred.\n+//!\n+//! ### Interaction with the borrow checker\n+//!\n+//! In general, the job of the borrowck module (which runs later) is to\n+//! check that all soundness criteria are met, given a particular set of\n+//! regions. The job of *this* module is to anticipate the needs of the\n+//! borrow checker and infer regions that will satisfy its requirements.\n+//! It is generally true that the inference doesn't need to be sound,\n+//! meaning that if there is a bug and we inferred bad regions, the borrow\n+//! checker should catch it. This is not entirely true though; for\n+//! example, the borrow checker doesn't check subtyping, and it doesn't\n+//! check that region pointers are always live when they are used. It\n+//! might be worthwhile to fix this so that borrowck serves as a kind of\n+//! verification step -- that would add confidence in the overall\n+//! correctness of the compiler, at the cost of duplicating some type\n+//! checks and effort.\n+//!\n+//! ### Inferring the duration of borrows, automatic and otherwise\n+//!\n+//! Whenever we introduce a borrowed pointer, for example as the result of\n+//! a borrow expression `let x = &data`, the lifetime of the pointer `x`\n+//! is always specified as a region inference variable. `regionck` has the\n+//! job of adding constraints such that this inference variable is as\n+//! narrow as possible while still accommodating all uses (that is, every\n+//! dereference of the resulting pointer must be within the lifetime).\n+//!\n+//! #### Reborrows\n+//!\n+//! Generally speaking, `regionck` does NOT try to ensure that the data\n+//! `data` will outlive the pointer `x`. That is the job of borrowck.  The\n+//! one exception is when \"re-borrowing\" the contents of another borrowed\n+//! pointer. For example, imagine you have a borrowed pointer `b` with\n+//! lifetime L1 and you have an expression `&*b`. The result of this\n+//! expression will be another borrowed pointer with lifetime L2 (which is\n+//! an inference variable). The borrow checker is going to enforce the\n+//! constraint that L2 < L1, because otherwise you are re-borrowing data\n+//! for a lifetime larger than the original loan.  However, without the\n+//! routines in this module, the region inferencer would not know of this\n+//! dependency and thus it might infer the lifetime of L2 to be greater\n+//! than L1 (issue #3148).\n+//!\n+//! There are a number of troublesome scenarios in the tests\n+//! `region-dependent-*.rs`, but here is one example:\n+//!\n+//!     struct Foo { i: int }\n+//!     struct Bar { foo: Foo  }\n+//!     fn get_i(x: &'a Bar) -> &'a int {\n+//!        let foo = &x.foo; // Lifetime L1\n+//!        &foo.i            // Lifetime L2\n+//!     }\n+//!\n+//! Note that this comes up either with `&` expressions, `ref`\n+//! bindings, and `autorefs`, which are the three ways to introduce\n+//! a borrow.\n+//!\n+//! The key point here is that when you are borrowing a value that\n+//! is \"guaranteed\" by a borrowed pointer, you must link the\n+//! lifetime of that borrowed pointer (L1, here) to the lifetime of\n+//! the borrow itself (L2).  What do I mean by \"guaranteed\" by a\n+//! borrowed pointer? I mean any data that is reached by first\n+//! dereferencing a borrowed pointer and then either traversing\n+//! interior offsets or owned pointers.  We say that the guarantor\n+//! of such data it the region of the borrowed pointer that was\n+//! traversed.  This is essentially the same as the ownership\n+//! relation, except that a borrowed pointer never owns its\n+//! contents.\n+//!\n+//! ### Inferring borrow kinds for upvars\n+//!\n+//! Whenever there is a closure expression, we need to determine how each\n+//! upvar is used. We do this by initially assigning each upvar an\n+//! immutable \"borrow kind\" (see `ty::BorrowKind` for details) and then\n+//! \"escalating\" the kind as needed. The borrow kind proceeds according to\n+//! the following lattice:\n+//!\n+//!     ty::ImmBorrow -> ty::UniqueImmBorrow -> ty::MutBorrow\n+//!\n+//! So, for example, if we see an assignment `x = 5` to an upvar `x`, we\n+//! will promote its borrow kind to mutable borrow. If we see an `&mut x`\n+//! we'll do the same. Naturally, this applies not just to the upvar, but\n+//! to everything owned by `x`, so the result is the same for something\n+//! like `x.f = 5` and so on (presuming `x` is not a borrowed pointer to a\n+//! struct). These adjustments are performed in\n+//! `adjust_upvar_borrow_kind()` (you can trace backwards through the code\n+//! from there).\n+//!\n+//! The fact that we are inferring borrow kinds as we go results in a\n+//! semi-hacky interaction with mem-categorization. In particular,\n+//! mem-categorization will query the current borrow kind as it\n+//! categorizes, and we'll return the *current* value, but this may get\n+//! adjusted later. Therefore, in this module, we generally ignore the\n+//! borrow kind (and derived mutabilities) that are returned from\n+//! mem-categorization, since they may be inaccurate. (Another option\n+//! would be to use a unification scheme, where instead of returning a\n+//! concrete borrow kind like `ty::ImmBorrow`, we return a\n+//! `ty::InferBorrow(upvar_id)` or something like that, but this would\n+//! then mean that all later passes would have to check for these figments\n+//! and report an error, and it just seems like more mess in the end.)\n \n use middle::def;\n use middle::mem_categorization as mc;\n@@ -177,15 +173,11 @@ pub fn regionck_fn(fcx: &FnCtxt, id: ast::NodeId, blk: &ast::Block) {\n     fcx.infcx().resolve_regions_and_report_errors();\n }\n \n+/// Checks that the types in `component_tys` are well-formed. This will add constraints into the\n+/// region graph. Does *not* run `resolve_regions_and_report_errors` and so forth.\n pub fn regionck_ensure_component_tys_wf<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n                                                   span: Span,\n                                                   component_tys: &[Ty<'tcx>]) {\n-    /*!\n-     * Checks that the types in `component_tys` are well-formed.\n-     * This will add constraints into the region graph.\n-     * Does *not* run `resolve_regions_and_report_errors` and so forth.\n-     */\n-\n     let mut rcx = Rcx::new(fcx, 0);\n     for &component_ty in component_tys.iter() {\n         // Check that each type outlives the empty region. Since the\n@@ -239,12 +231,8 @@ pub struct Rcx<'a, 'tcx: 'a> {\n     maybe_links: MaybeLinkMap<'tcx>\n }\n \n+/// Returns the validity region of `def` -- that is, how long is `def` valid?\n fn region_of_def(fcx: &FnCtxt, def: def::Def) -> ty::Region {\n-    /*!\n-     * Returns the validity region of `def` -- that is, how long\n-     * is `def` valid?\n-     */\n-\n     let tcx = fcx.tcx();\n     match def {\n         def::DefLocal(node_id) => {\n@@ -283,35 +271,30 @@ impl<'a, 'tcx> Rcx<'a, 'tcx> {\n         old_scope\n     }\n \n+    /// Try to resolve the type for the given node, returning t_err if an error results.  Note that\n+    /// we never care about the details of the error, the same error will be detected and reported\n+    /// in the writeback phase.\n+    ///\n+    /// Note one important point: we do not attempt to resolve *region variables* here.  This is\n+    /// because regionck is essentially adding constraints to those region variables and so may yet\n+    /// influence how they are resolved.\n+    ///\n+    /// Consider this silly example:\n+    ///\n+    /// ```\n+    /// fn borrow(x: &int) -> &int {x}\n+    /// fn foo(x: @int) -> int {  // block: B\n+    ///     let b = borrow(x);    // region: <R0>\n+    ///     *b\n+    /// }\n+    /// ```\n+    ///\n+    /// Here, the region of `b` will be `<R0>`.  `<R0>` is constrainted to be some subregion of the\n+    /// block B and some superregion of the call.  If we forced it now, we'd choose the smaller\n+    /// region (the call).  But that would make the *b illegal.  Since we don't resolve, the type\n+    /// of b will be `&<R0>.int` and then `*b` will require that `<R0>` be bigger than the let and\n+    /// the `*b` expression, so we will effectively resolve `<R0>` to be the block B.\n     pub fn resolve_type(&self, unresolved_ty: Ty<'tcx>) -> Ty<'tcx> {\n-        /*!\n-         * Try to resolve the type for the given node, returning\n-         * t_err if an error results.  Note that we never care\n-         * about the details of the error, the same error will be\n-         * detected and reported in the writeback phase.\n-         *\n-         * Note one important point: we do not attempt to resolve\n-         * *region variables* here.  This is because regionck is\n-         * essentially adding constraints to those region variables\n-         * and so may yet influence how they are resolved.\n-         *\n-         * Consider this silly example:\n-         *\n-         *     fn borrow(x: &int) -> &int {x}\n-         *     fn foo(x: @int) -> int {  // block: B\n-         *         let b = borrow(x);    // region: <R0>\n-         *         *b\n-         *     }\n-         *\n-         * Here, the region of `b` will be `<R0>`.  `<R0>` is\n-         * constrainted to be some subregion of the block B and some\n-         * superregion of the call.  If we forced it now, we'd choose\n-         * the smaller region (the call).  But that would make the *b\n-         * illegal.  Since we don't resolve, the type of b will be\n-         * `&<R0>.int` and then `*b` will require that `<R0>` be\n-         * bigger than the let and the `*b` expression, so we will\n-         * effectively resolve `<R0>` to be the block B.\n-         */\n         match resolve_type(self.fcx.infcx(), None, unresolved_ty,\n                            resolve_and_force_all_but_regions) {\n             Ok(t) => t,\n@@ -384,25 +367,19 @@ impl<'a, 'tcx> Rcx<'a, 'tcx> {\n         }\n     }\n \n+    /// This method populates the region map's `free_region_map`. It walks over the transformed\n+    /// argument and return types for each function just before we check the body of that function,\n+    /// looking for types where you have a borrowed pointer to other borrowed data (e.g., `&'a &'b\n+    /// [uint]`.  We do not allow references to outlive the things they point at, so we can assume\n+    /// that `'a <= 'b`. This holds for both the argument and return types, basically because, on\n+    /// the caller side, the caller is responsible for checking that the type of every expression\n+    /// (including the actual values for the arguments, as well as the return type of the fn call)\n+    /// is well-formed.\n+    ///\n+    /// Tests: `src/test/compile-fail/regions-free-region-ordering-*.rs`\n     fn relate_free_regions(&mut self,\n                            fn_sig_tys: &[Ty<'tcx>],\n                            body_id: ast::NodeId) {\n-        /*!\n-         * This method populates the region map's `free_region_map`.\n-         * It walks over the transformed argument and return types for\n-         * each function just before we check the body of that\n-         * function, looking for types where you have a borrowed\n-         * pointer to other borrowed data (e.g., `&'a &'b [uint]`.  We\n-         * do not allow references to outlive the things they point\n-         * at, so we can assume that `'a <= 'b`. This holds for both\n-         * the argument and return types, basically because, on the caller\n-         * side, the caller is responsible for checking that the type of\n-         * every expression (including the actual values for the arguments,\n-         * as well as the return type of the fn call) is well-formed.\n-         *\n-         * Tests: `src/test/compile-fail/regions-free-region-ordering-*.rs`\n-         */\n-\n         debug!(\"relate_free_regions >>\");\n         let tcx = self.tcx();\n \n@@ -921,19 +898,15 @@ fn check_expr_fn_block(rcx: &mut Rcx,\n         _ => {}\n     }\n \n+    /// Make sure that the type of all free variables referenced inside a closure/proc outlive the\n+    /// closure/proc's lifetime bound. This is just a special case of the usual rules about closed\n+    /// over values outliving the object's lifetime bound.\n     fn ensure_free_variable_types_outlive_closure_bound(\n         rcx: &mut Rcx,\n         bounds: ty::ExistentialBounds,\n         expr: &ast::Expr,\n         freevars: &[ty::Freevar])\n     {\n-        /*!\n-         * Make sure that the type of all free variables referenced\n-         * inside a closure/proc outlive the closure/proc's lifetime\n-         * bound. This is just a special case of the usual rules about\n-         * closed over values outliving the object's lifetime bound.\n-         */\n-\n         let tcx = rcx.fcx.ccx.tcx;\n \n         debug!(\"ensure_free_variable_types_outlive_closure_bound({}, {})\",\n@@ -984,18 +957,14 @@ fn check_expr_fn_block(rcx: &mut Rcx,\n         }\n     }\n \n+    /// Make sure that all free variables referenced inside the closure outlive the closure's\n+    /// lifetime bound. Also, create an entry in the upvar_borrows map with a region.\n     fn constrain_free_variables_in_by_ref_closure(\n         rcx: &mut Rcx,\n         region_bound: ty::Region,\n         expr: &ast::Expr,\n         freevars: &[ty::Freevar])\n     {\n-        /*!\n-         * Make sure that all free variables referenced inside the\n-         * closure outlive the closure's lifetime bound. Also, create\n-         * an entry in the upvar_borrows map with a region.\n-         */\n-\n         let tcx = rcx.fcx.ccx.tcx;\n         let infcx = rcx.fcx.infcx();\n         debug!(\"constrain_free_variables({}, {})\",\n@@ -1183,15 +1152,12 @@ fn constrain_call<'a, I: Iterator<&'a ast::Expr>>(rcx: &mut Rcx,\n     }\n }\n \n+/// Invoked on any auto-dereference that occurs. Checks that if this is a region pointer being\n+/// dereferenced, the lifetime of the pointer includes the deref expr.\n fn constrain_autoderefs<'a, 'tcx>(rcx: &mut Rcx<'a, 'tcx>,\n                                   deref_expr: &ast::Expr,\n                                   derefs: uint,\n                                   mut derefd_ty: Ty<'tcx>) {\n-    /*!\n-     * Invoked on any auto-dereference that occurs.  Checks that if\n-     * this is a region pointer being dereferenced, the lifetime of\n-     * the pointer includes the deref expr.\n-     */\n     let r_deref_expr = ty::ReScope(CodeExtent::from_node_id(deref_expr.id));\n     for i in range(0u, derefs) {\n         debug!(\"constrain_autoderefs(deref_expr=?, derefd_ty={}, derefs={}/{}\",\n@@ -1259,16 +1225,12 @@ pub fn mk_subregion_due_to_dereference(rcx: &mut Rcx,\n }\n \n \n+/// Invoked on any index expression that occurs. Checks that if this is a slice being indexed, the\n+/// lifetime of the pointer includes the deref expr.\n fn constrain_index<'a, 'tcx>(rcx: &mut Rcx<'a, 'tcx>,\n                              index_expr: &ast::Expr,\n                              indexed_ty: Ty<'tcx>)\n {\n-    /*!\n-     * Invoked on any index expression that occurs.  Checks that if\n-     * this is a slice being indexed, the lifetime of the pointer\n-     * includes the deref expr.\n-     */\n-\n     debug!(\"constrain_index(index_expr=?, indexed_ty={}\",\n            rcx.fcx.infcx().ty_to_string(indexed_ty));\n \n@@ -1286,18 +1248,14 @@ fn constrain_index<'a, 'tcx>(rcx: &mut Rcx<'a, 'tcx>,\n     }\n }\n \n+/// Guarantees that any lifetimes which appear in the type of the node `id` (after applying\n+/// adjustments) are valid for at least `minimum_lifetime`\n fn type_of_node_must_outlive<'a, 'tcx>(\n     rcx: &mut Rcx<'a, 'tcx>,\n     origin: infer::SubregionOrigin<'tcx>,\n     id: ast::NodeId,\n     minimum_lifetime: ty::Region)\n {\n-    /*!\n-     * Guarantees that any lifetimes which appear in the type of\n-     * the node `id` (after applying adjustments) are valid for at\n-     * least `minimum_lifetime`\n-     */\n-\n     let tcx = rcx.fcx.tcx();\n \n     // Try to resolve the type.  If we encounter an error, then typeck\n@@ -1314,14 +1272,10 @@ fn type_of_node_must_outlive<'a, 'tcx>(\n     type_must_outlive(rcx, origin, ty, minimum_lifetime);\n }\n \n+/// Computes the guarantor for an expression `&base` and then ensures that the lifetime of the\n+/// resulting pointer is linked to the lifetime of its guarantor (if any).\n fn link_addr_of(rcx: &mut Rcx, expr: &ast::Expr,\n                mutability: ast::Mutability, base: &ast::Expr) {\n-    /*!\n-     * Computes the guarantor for an expression `&base` and then\n-     * ensures that the lifetime of the resulting pointer is linked\n-     * to the lifetime of its guarantor (if any).\n-     */\n-\n     debug!(\"link_addr_of(base=?)\");\n \n     let cmt = {\n@@ -1331,13 +1285,10 @@ fn link_addr_of(rcx: &mut Rcx, expr: &ast::Expr,\n     link_region_from_node_type(rcx, expr.span, expr.id, mutability, cmt);\n }\n \n+/// Computes the guarantors for any ref bindings in a `let` and\n+/// then ensures that the lifetime of the resulting pointer is\n+/// linked to the lifetime of the initialization expression.\n fn link_local(rcx: &Rcx, local: &ast::Local) {\n-    /*!\n-     * Computes the guarantors for any ref bindings in a `let` and\n-     * then ensures that the lifetime of the resulting pointer is\n-     * linked to the lifetime of the initialization expression.\n-     */\n-\n     debug!(\"regionck::for_local()\");\n     let init_expr = match local.init {\n         None => { return; }\n@@ -1348,12 +1299,10 @@ fn link_local(rcx: &Rcx, local: &ast::Local) {\n     link_pattern(rcx, mc, discr_cmt, &*local.pat);\n }\n \n+/// Computes the guarantors for any ref bindings in a match and\n+/// then ensures that the lifetime of the resulting pointer is\n+/// linked to the lifetime of its guarantor (if any).\n fn link_match(rcx: &Rcx, discr: &ast::Expr, arms: &[ast::Arm]) {\n-    /*!\n-     * Computes the guarantors for any ref bindings in a match and\n-     * then ensures that the lifetime of the resulting pointer is\n-     * linked to the lifetime of its guarantor (if any).\n-     */\n \n     debug!(\"regionck::for_match()\");\n     let mc = mc::MemCategorizationContext::new(rcx);\n@@ -1366,15 +1315,12 @@ fn link_match(rcx: &Rcx, discr: &ast::Expr, arms: &[ast::Arm]) {\n     }\n }\n \n+/// Link lifetimes of any ref bindings in `root_pat` to the pointers found in the discriminant, if\n+/// needed.\n fn link_pattern<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                           mc: mc::MemCategorizationContext<Rcx<'a, 'tcx>>,\n                           discr_cmt: mc::cmt<'tcx>,\n                           root_pat: &ast::Pat) {\n-    /*!\n-     * Link lifetimes of any ref bindings in `root_pat` to\n-     * the pointers found in the discriminant, if needed.\n-     */\n-\n     let _ = mc.cat_pattern(discr_cmt, root_pat, |mc, sub_cmt, sub_pat| {\n             match sub_pat.node {\n                 // `ref x` pattern\n@@ -1400,14 +1346,12 @@ fn link_pattern<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n         });\n }\n \n+/// Link lifetime of borrowed pointer resulting from autoref to lifetimes in the value being\n+/// autoref'd.\n fn link_autoref(rcx: &Rcx,\n                 expr: &ast::Expr,\n                 autoderefs: uint,\n                 autoref: &ty::AutoRef) {\n-    /*!\n-     * Link lifetime of borrowed pointer resulting from autoref\n-     * to lifetimes in the value being autoref'd.\n-     */\n \n     debug!(\"link_autoref(autoref={})\", autoref);\n     let mc = mc::MemCategorizationContext::new(rcx);\n@@ -1424,15 +1368,11 @@ fn link_autoref(rcx: &Rcx,\n     }\n }\n \n+/// Computes the guarantor for cases where the `expr` is being passed by implicit reference and\n+/// must outlive `callee_scope`.\n fn link_by_ref(rcx: &Rcx,\n                expr: &ast::Expr,\n                callee_scope: CodeExtent) {\n-    /*!\n-     * Computes the guarantor for cases where the `expr` is\n-     * being passed by implicit reference and must outlive\n-     * `callee_scope`.\n-     */\n-\n     let tcx = rcx.tcx();\n     debug!(\"link_by_ref(expr={}, callee_scope={})\",\n            expr.repr(tcx), callee_scope);\n@@ -1442,17 +1382,13 @@ fn link_by_ref(rcx: &Rcx,\n     link_region(rcx, expr.span, borrow_region, ty::ImmBorrow, expr_cmt);\n }\n \n+/// Like `link_region()`, except that the region is extracted from the type of `id`, which must be\n+/// some reference (`&T`, `&str`, etc).\n fn link_region_from_node_type<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                                         span: Span,\n                                         id: ast::NodeId,\n                                         mutbl: ast::Mutability,\n                                         cmt_borrowed: mc::cmt<'tcx>) {\n-    /*!\n-     * Like `link_region()`, except that the region is\n-     * extracted from the type of `id`, which must be some\n-     * reference (`&T`, `&str`, etc).\n-     */\n-\n     let rptr_ty = rcx.resolve_node_type(id);\n     if !ty::type_is_error(rptr_ty) {\n         let tcx = rcx.fcx.ccx.tcx;\n@@ -1463,19 +1399,14 @@ fn link_region_from_node_type<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n     }\n }\n \n+/// Informs the inference engine that `borrow_cmt` is being borrowed with kind `borrow_kind` and\n+/// lifetime `borrow_region`. In order to ensure borrowck is satisfied, this may create constraints\n+/// between regions, as explained in `link_reborrowed_region()`.\n fn link_region<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                          span: Span,\n                          borrow_region: ty::Region,\n                          borrow_kind: ty::BorrowKind,\n                          borrow_cmt: mc::cmt<'tcx>) {\n-    /*!\n-     * Informs the inference engine that `borrow_cmt` is being\n-     * borrowed with kind `borrow_kind` and lifetime `borrow_region`.\n-     * In order to ensure borrowck is satisfied, this may create\n-     * constraints between regions, as explained in\n-     * `link_reborrowed_region()`.\n-     */\n-\n     let mut borrow_cmt = borrow_cmt;\n     let mut borrow_kind = borrow_kind;\n \n@@ -1525,6 +1456,46 @@ fn link_region<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n     }\n }\n \n+/// This is the most complicated case: the path being borrowed is\n+/// itself the referent of a borrowed pointer. Let me give an\n+/// example fragment of code to make clear(er) the situation:\n+///\n+///    let r: &'a mut T = ...;  // the original reference \"r\" has lifetime 'a\n+///    ...\n+///    &'z *r                   // the reborrow has lifetime 'z\n+///\n+/// Now, in this case, our primary job is to add the inference\n+/// constraint that `'z <= 'a`. Given this setup, let's clarify the\n+/// parameters in (roughly) terms of the example:\n+///\n+///     A borrow of: `& 'z bk * r` where `r` has type `& 'a bk T`\n+///     borrow_region   ^~                 ref_region    ^~\n+///     borrow_kind        ^~               ref_kind        ^~\n+///     ref_cmt                 ^\n+///\n+/// Here `bk` stands for some borrow-kind (e.g., `mut`, `uniq`, etc).\n+///\n+/// Unfortunately, there are some complications beyond the simple\n+/// scenario I just painted:\n+///\n+/// 1. The reference `r` might in fact be a \"by-ref\" upvar. In that\n+///    case, we have two jobs. First, we are inferring whether this reference\n+///    should be an `&T`, `&mut T`, or `&uniq T` reference, and we must\n+///    adjust that based on this borrow (e.g., if this is an `&mut` borrow,\n+///    then `r` must be an `&mut` reference). Second, whenever we link\n+///    two regions (here, `'z <= 'a`), we supply a *cause*, and in this\n+///    case we adjust the cause to indicate that the reference being\n+///    \"reborrowed\" is itself an upvar. This provides a nicer error message\n+///    should something go wrong.\n+///\n+/// 2. There may in fact be more levels of reborrowing. In the\n+///    example, I said the borrow was like `&'z *r`, but it might\n+///    in fact be a borrow like `&'z **q` where `q` has type `&'a\n+///    &'b mut T`. In that case, we want to ensure that `'z <= 'a`\n+///    and `'z <= 'b`. This is explained more below.\n+///\n+/// The return value of this function indicates whether we need to\n+/// recurse and process `ref_cmt` (see case 2 above).\n fn link_reborrowed_region<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                                     span: Span,\n                                     borrow_region: ty::Region,\n@@ -1535,49 +1506,6 @@ fn link_reborrowed_region<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                                     note: mc::Note)\n                                     -> Option<(mc::cmt<'tcx>, ty::BorrowKind)>\n {\n-    /*!\n-     * This is the most complicated case: the path being borrowed is\n-     * itself the referent of a borrowed pointer. Let me give an\n-     * example fragment of code to make clear(er) the situation:\n-     *\n-     *    let r: &'a mut T = ...;  // the original reference \"r\" has lifetime 'a\n-     *    ...\n-     *    &'z *r                   // the reborrow has lifetime 'z\n-     *\n-     * Now, in this case, our primary job is to add the inference\n-     * constraint that `'z <= 'a`. Given this setup, let's clarify the\n-     * parameters in (roughly) terms of the example:\n-     *\n-     *     A borrow of: `& 'z bk * r` where `r` has type `& 'a bk T`\n-     *     borrow_region   ^~                 ref_region    ^~\n-     *     borrow_kind        ^~               ref_kind        ^~\n-     *     ref_cmt                 ^\n-     *\n-     * Here `bk` stands for some borrow-kind (e.g., `mut`, `uniq`, etc).\n-     *\n-     * Unfortunately, there are some complications beyond the simple\n-     * scenario I just painted:\n-     *\n-     * 1. The reference `r` might in fact be a \"by-ref\" upvar. In that\n-     *    case, we have two jobs. First, we are inferring whether this reference\n-     *    should be an `&T`, `&mut T`, or `&uniq T` reference, and we must\n-     *    adjust that based on this borrow (e.g., if this is an `&mut` borrow,\n-     *    then `r` must be an `&mut` reference). Second, whenever we link\n-     *    two regions (here, `'z <= 'a`), we supply a *cause*, and in this\n-     *    case we adjust the cause to indicate that the reference being\n-     *    \"reborrowed\" is itself an upvar. This provides a nicer error message\n-     *    should something go wrong.\n-     *\n-     * 2. There may in fact be more levels of reborrowing. In the\n-     *    example, I said the borrow was like `&'z *r`, but it might\n-     *    in fact be a borrow like `&'z **q` where `q` has type `&'a\n-     *    &'b mut T`. In that case, we want to ensure that `'z <= 'a`\n-     *    and `'z <= 'b`. This is explained more below.\n-     *\n-     * The return value of this function indicates whether we need to\n-     * recurse and process `ref_cmt` (see case 2 above).\n-     */\n-\n     // Possible upvar ID we may need later to create an entry in the\n     // maybe link map.\n \n@@ -1715,27 +1643,19 @@ fn link_reborrowed_region<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n     }\n }\n \n+/// Adjusts the inferred borrow_kind as needed to account for upvars that are assigned to in an\n+/// assignment expression.\n fn adjust_borrow_kind_for_assignment_lhs(rcx: &Rcx,\n                                          lhs: &ast::Expr) {\n-    /*!\n-     * Adjusts the inferred borrow_kind as needed to account\n-     * for upvars that are assigned to in an assignment\n-     * expression.\n-     */\n-\n     let mc = mc::MemCategorizationContext::new(rcx);\n     let cmt = ignore_err!(mc.cat_expr(lhs));\n     adjust_upvar_borrow_kind_for_mut(rcx, cmt);\n }\n \n+/// Indicates that `cmt` is being directly mutated (e.g., assigned to). If cmt contains any by-ref\n+/// upvars, this implies that those upvars must be borrowed using an `&mut` borow.\n fn adjust_upvar_borrow_kind_for_mut<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>,\n                                               cmt: mc::cmt<'tcx>) {\n-    /*!\n-     * Indicates that `cmt` is being directly mutated (e.g., assigned\n-     * to).  If cmt contains any by-ref upvars, this implies that\n-     * those upvars must be borrowed using an `&mut` borow.\n-     */\n-\n     let mut cmt = cmt;\n     loop {\n         debug!(\"adjust_upvar_borrow_kind_for_mut(cmt={})\",\n@@ -1834,16 +1754,12 @@ fn adjust_upvar_borrow_kind_for_unique<'a, 'tcx>(rcx: &Rcx<'a, 'tcx>, cmt: mc::c\n     }\n }\n \n+/// Indicates that the borrow_kind of `outer_upvar_id` must permit a reborrowing with the\n+/// borrow_kind of `inner_upvar_id`. This occurs in nested closures, see comment above at the call\n+/// to this function.\n fn link_upvar_borrow_kind_for_nested_closures(rcx: &mut Rcx,\n                                               inner_upvar_id: ty::UpvarId,\n                                               outer_upvar_id: ty::UpvarId) {\n-    /*!\n-     * Indicates that the borrow_kind of `outer_upvar_id` must\n-     * permit a reborrowing with the borrow_kind of `inner_upvar_id`.\n-     * This occurs in nested closures, see comment above at the call to\n-     * this function.\n-     */\n-\n     debug!(\"link_upvar_borrow_kind: inner_upvar_id={} outer_upvar_id={}\",\n            inner_upvar_id, outer_upvar_id);\n \n@@ -1867,18 +1783,14 @@ fn adjust_upvar_borrow_kind_for_loan(rcx: &Rcx,\n     adjust_upvar_borrow_kind(rcx, upvar_id, upvar_borrow, kind)\n }\n \n+/// We infer the borrow_kind with which to borrow upvars in a stack closure. The borrow_kind\n+/// basically follows a lattice of `imm < unique-imm < mut`, moving from left to right as needed\n+/// (but never right to left). Here the argument `mutbl` is the borrow_kind that is required by\n+/// some particular use.\n fn adjust_upvar_borrow_kind(rcx: &Rcx,\n                             upvar_id: ty::UpvarId,\n                             upvar_borrow: &mut ty::UpvarBorrow,\n                             kind: ty::BorrowKind) {\n-    /*!\n-     * We infer the borrow_kind with which to borrow upvars in a stack\n-     * closure. The borrow_kind basically follows a lattice of\n-     * `imm < unique-imm < mut`, moving from left to right as needed (but never\n-     * right to left). Here the argument `mutbl` is the borrow_kind that\n-     * is required by some particular use.\n-     */\n-\n     debug!(\"adjust_upvar_borrow_kind: id={} kind=({} -> {})\",\n            upvar_id, upvar_borrow.kind, kind);\n \n@@ -1911,15 +1823,12 @@ fn adjust_upvar_borrow_kind(rcx: &Rcx,\n     }\n }\n \n+/// Ensures that all borrowed data reachable via `ty` outlives `region`.\n fn type_must_outlive<'a, 'tcx>(rcx: &mut Rcx<'a, 'tcx>,\n                                origin: infer::SubregionOrigin<'tcx>,\n                                ty: Ty<'tcx>,\n                                region: ty::Region)\n {\n-    /*!\n-     * Ensures that all borrowed data reachable via `ty` outlives `region`.\n-     */\n-\n     debug!(\"type_must_outlive(ty={}, region={})\",\n            ty.repr(rcx.tcx()),\n            region.repr(rcx.tcx()));"}, {"sha": "55214618aa90b5856bb8968487e07e45ae44617a", "filename": "src/librustc/middle/typeck/check/regionmanip.rs", "status": "modified", "additions": 6, "deletions": 17, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionmanip.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionmanip.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fregionmanip.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -33,18 +33,14 @@ struct Wf<'a, 'tcx: 'a> {\n     out: Vec<WfConstraint<'tcx>>,\n }\n \n+/// This routine computes the well-formedness constraints that must hold for the type `ty` to\n+/// appear in a context with lifetime `outer_region`\n pub fn region_wf_constraints<'tcx>(\n     tcx: &ty::ctxt<'tcx>,\n     ty: Ty<'tcx>,\n     outer_region: ty::Region)\n     -> Vec<WfConstraint<'tcx>>\n {\n-    /*!\n-     * This routine computes the well-formedness constraints that must\n-     * hold for the type `ty` to appear in a context with lifetime\n-     * `outer_region`\n-     */\n-\n     let mut stack = Vec::new();\n     stack.push((outer_region, None));\n     let mut wf = Wf { tcx: tcx,\n@@ -168,12 +164,9 @@ impl<'a, 'tcx> Wf<'a, 'tcx> {\n         self.stack.pop().unwrap();\n     }\n \n+    /// Pushes a constraint that `r_b` must outlive the top region on the stack.\n     fn push_region_constraint_from_top(&mut self,\n                                        r_b: ty::Region) {\n-        /*!\n-         * Pushes a constraint that `r_b` must outlive the\n-         * top region on the stack.\n-         */\n \n         // Indicates that we have found borrowed content with a lifetime\n         // of at least `r_b`. This adds a constraint that `r_b` must\n@@ -192,30 +185,26 @@ impl<'a, 'tcx> Wf<'a, 'tcx> {\n         self.push_sub_region_constraint(opt_ty, r_a, r_b);\n     }\n \n+    /// Pushes a constraint that `r_a <= r_b`, due to `opt_ty`\n     fn push_sub_region_constraint(&mut self,\n                                   opt_ty: Option<Ty<'tcx>>,\n                                   r_a: ty::Region,\n                                   r_b: ty::Region) {\n-        /*! Pushes a constraint that `r_a <= r_b`, due to `opt_ty` */\n         self.out.push(RegionSubRegionConstraint(opt_ty, r_a, r_b));\n     }\n \n+    /// Pushes a constraint that `param_ty` must outlive the top region on the stack.\n     fn push_param_constraint_from_top(&mut self,\n                                       param_ty: ty::ParamTy) {\n-        /*!\n-         * Pushes a constraint that `param_ty` must outlive the\n-         * top region on the stack.\n-         */\n-\n         let &(region, opt_ty) = self.stack.last().unwrap();\n         self.push_param_constraint(region, opt_ty, param_ty);\n     }\n \n+    /// Pushes a constraint that `region <= param_ty`, due to `opt_ty`\n     fn push_param_constraint(&mut self,\n                              region: ty::Region,\n                              opt_ty: Option<Ty<'tcx>>,\n                              param_ty: ty::ParamTy) {\n-        /*! Pushes a constraint that `region <= param_ty`, due to `opt_ty` */\n         self.out.push(RegionSubParamConstraint(opt_ty, region, param_ty));\n     }\n "}, {"sha": "51978a01f712410bb0f8857f3205a376e863c81c", "filename": "src/librustc/middle/typeck/check/vtable.rs", "status": "modified", "additions": 9, "deletions": 16, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fvtable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fvtable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fvtable.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -168,17 +168,14 @@ pub fn check_object_safety<'tcx>(tcx: &ty::ctxt<'tcx>,\n         }\n     }\n \n-    // Returns a vec of error messages. If hte vec is empty - no errors!\n+    /// Returns a vec of error messages. If hte vec is empty - no errors!\n+    ///\n+    /// There are some limitations to calling functions through an object, because (a) the self\n+    /// type is not known (that's the whole point of a trait instance, after all, to obscure the\n+    /// self type) and (b) the call must go through a vtable and hence cannot be monomorphized.\n     fn check_object_safety_of_method<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                            method: &ty::Method<'tcx>)\n                                            -> Vec<String> {\n-        /*!\n-         * There are some limitations to calling functions through an\n-         * object, because (a) the self type is not known\n-         * (that's the whole point of a trait instance, after all, to\n-         * obscure the self type) and (b) the call must go through a\n-         * vtable and hence cannot be monomorphized.\n-         */\n         let mut msgs = Vec::new();\n \n         let method_name = method.name.repr(tcx);\n@@ -455,8 +452,8 @@ pub fn maybe_report_ambiguity<'a, 'tcx>(fcx: &FnCtxt<'a, 'tcx>,\n     }\n }\n \n+/// Select as many obligations as we can at present.\n pub fn select_fcx_obligations_where_possible(fcx: &FnCtxt) {\n-    /*! Select as many obligations as we can at present. */\n \n     match\n         fcx.inh.fulfillment_cx\n@@ -468,14 +465,10 @@ pub fn select_fcx_obligations_where_possible(fcx: &FnCtxt) {\n     }\n }\n \n+/// Try to select any fcx obligation that we haven't tried yet, in an effort to improve inference.\n+/// You could just call `select_fcx_obligations_where_possible` except that it leads to repeated\n+/// work.\n pub fn select_new_fcx_obligations(fcx: &FnCtxt) {\n-    /*!\n-     * Try to select any fcx obligation that we haven't tried yet,\n-     * in an effort to improve inference. You could just call\n-     * `select_fcx_obligations_where_possible` except that it leads\n-     * to repeated work.\n-     */\n-\n     match\n         fcx.inh.fulfillment_cx\n         .borrow_mut()"}, {"sha": "502e37aa9f37040fcea2e16f4403a127015519d3", "filename": "src/librustc/middle/typeck/check/wf.rs", "status": "modified", "additions": 21, "deletions": 37, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fwf.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fwf.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcheck%2Fwf.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -38,24 +38,18 @@ impl<'ccx, 'tcx> CheckTypeWellFormedVisitor<'ccx, 'tcx> {\n         CheckTypeWellFormedVisitor { ccx: ccx, cache: HashSet::new() }\n     }\n \n+    /// Checks that the field types (in a struct def'n) or argument types (in an enum def'n) are\n+    /// well-formed, meaning that they do not require any constraints not declared in the struct\n+    /// definition itself. For example, this definition would be illegal:\n+    ///\n+    ///     struct Ref<'a, T> { x: &'a T }\n+    ///\n+    /// because the type did not declare that `T:'a`.\n+    ///\n+    /// We do this check as a pre-pass before checking fn bodies because if these constraints are\n+    /// not included it frequently leads to confusing errors in fn bodies. So it's better to check\n+    /// the types first.\n     fn check_item_well_formed(&mut self, item: &ast::Item) {\n-        /*!\n-         * Checks that the field types (in a struct def'n) or\n-         * argument types (in an enum def'n) are well-formed,\n-         * meaning that they do not require any constraints not\n-         * declared in the struct definition itself.\n-         * For example, this definition would be illegal:\n-         *\n-         *     struct Ref<'a, T> { x: &'a T }\n-         *\n-         * because the type did not declare that `T:'a`.\n-         *\n-         * We do this check as a pre-pass before checking fn bodies\n-         * because if these constraints are not included it frequently\n-         * leads to confusing errors in fn bodies. So it's better to check\n-         * the types first.\n-         */\n-\n         let ccx = self.ccx;\n         debug!(\"check_item_well_formed(it.id={}, it.ident={})\",\n                item.id,\n@@ -107,16 +101,12 @@ impl<'ccx, 'tcx> CheckTypeWellFormedVisitor<'ccx, 'tcx> {\n         regionck::regionck_item(&fcx, item);\n     }\n \n+    /// In a type definition, we check that to ensure that the types of the fields are well-formed.\n     fn check_type_defn(&mut self,\n                        item: &ast::Item,\n                        lookup_fields: for<'fcx> |&FnCtxt<'fcx, 'tcx>|\n                                                  -> Vec<AdtVariant<'tcx>>)\n     {\n-        /*!\n-         * In a type definition, we check that to ensure that the types of the fields are\n-         * well-formed.\n-         */\n-\n         self.with_fcx(item, |this, fcx| {\n             let variants = lookup_fields(fcx);\n             let mut bounds_checker = BoundsChecker::new(fcx,\n@@ -282,22 +272,16 @@ impl<'cx,'tcx> BoundsChecker<'cx,'tcx> {\n                         cache: cache, binding_count: 0 }\n     }\n \n+    /// Given a trait ref like `A : Trait<B>`, where `Trait` is defined as (say):\n+    ///\n+    ///     trait Trait<B:OtherTrait> : Copy { ... }\n+    ///\n+    /// This routine will check that `B : OtherTrait` and `A : Trait<B>`. It will also recursively\n+    /// check that the types `A` and `B` are well-formed.\n+    ///\n+    /// Note that it does not (currently, at least) check that `A : Copy` (that check is delegated\n+    /// to the point where impl `A : Trait<B>` is implemented).\n     pub fn check_trait_ref(&mut self, trait_ref: &ty::TraitRef<'tcx>) {\n-        /*!\n-         * Given a trait ref like `A : Trait<B>`, where `Trait` is\n-         * defined as (say):\n-         *\n-         *     trait Trait<B:OtherTrait> : Copy { ... }\n-         *\n-         * This routine will check that `B : OtherTrait` and `A :\n-         * Trait<B>`. It will also recursively check that the types\n-         * `A` and `B` are well-formed.\n-         *\n-         * Note that it does not (currently, at least)\n-         * check that `A : Copy` (that check is delegated to the point\n-         * where impl `A : Trait<B>` is implemented).\n-         */\n-\n         let trait_def = ty::lookup_trait_def(self.fcx.tcx(), trait_ref.def_id);\n \n         let bounds = trait_def.generics.to_bounds(self.tcx(), &trait_ref.substs);"}, {"sha": "758608b79c2cb226fefbce0c650d261bd93e784d", "filename": "src/librustc/middle/typeck/coherence/mod.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -477,17 +477,13 @@ impl<'a, 'tcx> CoherenceChecker<'a, 'tcx> {\n     }\n }\n \n+/// Substitutes the values for the receiver's type parameters that are found in method, leaving the\n+/// method's type parameters intact.\n pub fn make_substs_for_receiver_types<'tcx>(tcx: &ty::ctxt<'tcx>,\n                                             trait_ref: &ty::TraitRef<'tcx>,\n                                             method: &ty::Method<'tcx>)\n                                             -> subst::Substs<'tcx>\n {\n-    /*!\n-     * Substitutes the values for the receiver's type parameters\n-     * that are found in method, leaving the method's type parameters\n-     * intact.\n-     */\n-\n     let meth_tps: Vec<Ty> =\n         method.generics.types.get_slice(subst::FnSpace)\n               .iter()"}, {"sha": "dc3afaae35f615800056ddbfef49787cadf128c6", "filename": "src/librustc/middle/typeck/coherence/orphan.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Forphan.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Forphan.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Forphan.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Orphan checker: every impl either implements a trait defined in this\n- * crate or pertains to a type defined in this crate.\n- */\n+//! Orphan checker: every impl either implements a trait defined in this\n+//! crate or pertains to a type defined in this crate.\n \n use middle::traits;\n use middle::ty;"}, {"sha": "9f10a58f45852eb81c76c28f789a151639c8b9cb", "filename": "src/librustc/middle/typeck/coherence/overlap.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Foverlap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Foverlap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcoherence%2Foverlap.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Overlap: No two impls for the same trait are implemented for the\n- * same type.\n- */\n+//! Overlap: No two impls for the same trait are implemented for the\n+//! same type.\n \n use middle::traits;\n use middle::ty;"}, {"sha": "3a62978ed007a37ba900505219159153eb26ddb6", "filename": "src/librustc/middle/typeck/collect.rs", "status": "modified", "additions": 5, "deletions": 12, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcollect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcollect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fcollect.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -1944,6 +1944,9 @@ fn get_or_create_type_parameter_def<'tcx,AC>(this: &AC,\n     def\n }\n \n+/// Translate the AST's notion of ty param bounds (which are an enum consisting of a newtyped Ty or\n+/// a region) to ty's notion of ty param bounds, which can either be user-defined traits, or the\n+/// built-in trait (formerly known as kind): Send.\n fn compute_bounds<'tcx,AC>(this: &AC,\n                            name_of_bounded_thing: ast::Name,\n                            param_ty: ty::ParamTy,\n@@ -1953,13 +1956,6 @@ fn compute_bounds<'tcx,AC>(this: &AC,\n                            where_clause: &ast::WhereClause)\n                            -> ty::ParamBounds<'tcx>\n                            where AC: AstConv<'tcx> {\n-    /*!\n-     * Translate the AST's notion of ty param bounds (which are an\n-     * enum consisting of a newtyped Ty or a region) to ty's\n-     * notion of ty param bounds, which can either be user-defined\n-     * traits, or the built-in trait (formerly known as kind): Send.\n-     */\n-\n     let mut param_bounds = conv_param_bounds(this,\n                                              span,\n                                              param_ty,\n@@ -2040,16 +2036,13 @@ fn conv_param_bounds<'tcx,AC>(this: &AC,\n     }\n }\n \n+/// Merges the bounds declared on a type parameter with those found from where clauses into a\n+/// single list.\n fn merge_param_bounds<'a>(tcx: &ty::ctxt,\n                           param_ty: ty::ParamTy,\n                           ast_bounds: &'a [ast::TyParamBound],\n                           where_clause: &'a ast::WhereClause)\n                           -> Vec<&'a ast::TyParamBound> {\n-    /*!\n-     * Merges the bounds declared on a type parameter with those\n-     * found from where clauses into a single list.\n-     */\n-\n     let mut result = Vec::new();\n \n     for ast_bound in ast_bounds.iter() {"}, {"sha": "51f8668692ea71dab909949f7c5196a6c28d7851", "filename": "src/librustc/middle/typeck/infer/coercion.rs", "status": "modified", "additions": 53, "deletions": 61, "changes": 114, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcoercion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcoercion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcoercion.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,61 +8,57 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# Type Coercion\n-\n-Under certain circumstances we will coerce from one type to another,\n-for example by auto-borrowing.  This occurs in situations where the\n-compiler has a firm 'expected type' that was supplied from the user,\n-and where the actual type is similar to that expected type in purpose\n-but not in representation (so actual subtyping is inappropriate).\n-\n-## Reborrowing\n-\n-Note that if we are expecting a reference, we will *reborrow*\n-even if the argument provided was already a reference.  This is\n-useful for freezing mut/const things (that is, when the expected is &T\n-but you have &const T or &mut T) and also for avoiding the linearity\n-of mut things (when the expected is &mut T and you have &mut T).  See\n-the various `src/test/run-pass/coerce-reborrow-*.rs` tests for\n-examples of where this is useful.\n-\n-## Subtle note\n-\n-When deciding what type coercions to consider, we do not attempt to\n-resolve any type variables we may encounter.  This is because `b`\n-represents the expected type \"as the user wrote it\", meaning that if\n-the user defined a generic function like\n-\n-   fn foo<A>(a: A, b: A) { ... }\n-\n-and then we wrote `foo(&1, @2)`, we will not auto-borrow\n-either argument.  In older code we went to some lengths to\n-resolve the `b` variable, which could mean that we'd\n-auto-borrow later arguments but not earlier ones, which\n-seems very confusing.\n-\n-## Subtler note\n-\n-However, right now, if the user manually specifies the\n-values for the type variables, as so:\n-\n-   foo::<&int>(@1, @2)\n-\n-then we *will* auto-borrow, because we can't distinguish this from a\n-function that declared `&int`.  This is inconsistent but it's easiest\n-at the moment. The right thing to do, I think, is to consider the\n-*unsubstituted* type when deciding whether to auto-borrow, but the\n-*substituted* type when considering the bounds and so forth. But most\n-of our methods don't give access to the unsubstituted type, and\n-rightly so because they'd be error-prone.  So maybe the thing to do is\n-to actually determine the kind of coercions that should occur\n-separately and pass them in.  Or maybe it's ok as is.  Anyway, it's\n-sort of a minor point so I've opted to leave it for later---after all\n-we may want to adjust precisely when coercions occur.\n-\n-*/\n+//! # Type Coercion\n+//!\n+//! Under certain circumstances we will coerce from one type to another,\n+//! for example by auto-borrowing.  This occurs in situations where the\n+//! compiler has a firm 'expected type' that was supplied from the user,\n+//! and where the actual type is similar to that expected type in purpose\n+//! but not in representation (so actual subtyping is inappropriate).\n+//!\n+//! ## Reborrowing\n+//!\n+//! Note that if we are expecting a reference, we will *reborrow*\n+//! even if the argument provided was already a reference.  This is\n+//! useful for freezing mut/const things (that is, when the expected is &T\n+//! but you have &const T or &mut T) and also for avoiding the linearity\n+//! of mut things (when the expected is &mut T and you have &mut T).  See\n+//! the various `src/test/run-pass/coerce-reborrow-*.rs` tests for\n+//! examples of where this is useful.\n+//!\n+//! ## Subtle note\n+//!\n+//! When deciding what type coercions to consider, we do not attempt to\n+//! resolve any type variables we may encounter.  This is because `b`\n+//! represents the expected type \"as the user wrote it\", meaning that if\n+//! the user defined a generic function like\n+//!\n+//!    fn foo<A>(a: A, b: A) { ... }\n+//!\n+//! and then we wrote `foo(&1, @2)`, we will not auto-borrow\n+//! either argument.  In older code we went to some lengths to\n+//! resolve the `b` variable, which could mean that we'd\n+//! auto-borrow later arguments but not earlier ones, which\n+//! seems very confusing.\n+//!\n+//! ## Subtler note\n+//!\n+//! However, right now, if the user manually specifies the\n+//! values for the type variables, as so:\n+//!\n+//!    foo::<&int>(@1, @2)\n+//!\n+//! then we *will* auto-borrow, because we can't distinguish this from a\n+//! function that declared `&int`.  This is inconsistent but it's easiest\n+//! at the moment. The right thing to do, I think, is to consider the\n+//! *unsubstituted* type when deciding whether to auto-borrow, but the\n+//! *substituted* type when considering the bounds and so forth. But most\n+//! of our methods don't give access to the unsubstituted type, and\n+//! rightly so because they'd be error-prone.  So maybe the thing to do is\n+//! to actually determine the kind of coercions that should occur\n+//! separately and pass them in.  Or maybe it's ok as is.  Anyway, it's\n+//! sort of a minor point so I've opted to leave it for later---after all\n+//! we may want to adjust precisely when coercions occur.\n \n use middle::subst;\n use middle::ty::{AutoPtr, AutoDerefRef, AdjustDerefRef, AutoUnsize, AutoUnsafe};\n@@ -512,14 +508,10 @@ impl<'f, 'tcx> Coerce<'f, 'tcx> {\n         }\n     }\n \n+    ///  Attempts to coerce from a bare Rust function (`extern \"Rust\" fn`) into a closure or a\n+    ///  `proc`.\n     fn coerce_from_bare_fn(&self, a: Ty<'tcx>, fn_ty_a: &ty::BareFnTy<'tcx>, b: Ty<'tcx>)\n                            -> CoerceResult<'tcx> {\n-        /*!\n-         *\n-         * Attempts to coerce from a bare Rust function (`extern\n-         * \"Rust\" fn`) into a closure or a `proc`.\n-         */\n-\n         self.unpack_actual_value(b, |sty_b| {\n \n             debug!(\"coerce_from_bare_fn(a={}, b={})\","}, {"sha": "ba6ae00b6671f197cbb85ec9b97dcd927fc44f29", "filename": "src/librustc/middle/typeck/infer/combine.rs", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fcombine.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -642,21 +642,16 @@ impl<'f, 'tcx> CombineFields<'f, 'tcx> {\n         Ok(())\n     }\n \n+    /// Attempts to generalize `ty` for the type variable `for_vid`.  This checks for cycle -- that\n+    /// is, whether the type `ty` references `for_vid`. If `make_region_vars` is true, it will also\n+    /// replace all regions with fresh variables. Returns `ty_err` in the case of a cycle, `Ok`\n+    /// otherwise.\n     fn generalize(&self,\n                   ty: Ty<'tcx>,\n                   for_vid: ty::TyVid,\n                   make_region_vars: bool)\n                   -> cres<'tcx, Ty<'tcx>>\n     {\n-        /*!\n-         * Attempts to generalize `ty` for the type variable\n-         * `for_vid`.  This checks for cycle -- that is, whether the\n-         * type `ty` references `for_vid`. If `make_region_vars` is\n-         * true, it will also replace all regions with fresh\n-         * variables. Returns `ty_err` in the case of a cycle, `Ok`\n-         * otherwise.\n-         */\n-\n         let mut generalize = Generalizer { infcx: self.infcx,\n                                            span: self.trace.origin.span(),\n                                            for_vid: for_vid,"}, {"sha": "0e3cc5f68c868c86b00e12cb906a0da5bfc5dc71", "filename": "src/librustc/middle/typeck/infer/doc.rs", "status": "modified", "additions": 237, "deletions": 241, "changes": 478, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,244 +8,240 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# Type inference engine\n-\n-This is loosely based on standard HM-type inference, but with an\n-extension to try and accommodate subtyping.  There is nothing\n-principled about this extension; it's sound---I hope!---but it's a\n-heuristic, ultimately, and does not guarantee that it finds a valid\n-typing even if one exists (in fact, there are known scenarios where it\n-fails, some of which may eventually become problematic).\n-\n-## Key idea\n-\n-The main change is that each type variable T is associated with a\n-lower-bound L and an upper-bound U.  L and U begin as bottom and top,\n-respectively, but gradually narrow in response to new constraints\n-being introduced.  When a variable is finally resolved to a concrete\n-type, it can (theoretically) select any type that is a supertype of L\n-and a subtype of U.\n-\n-There are several critical invariants which we maintain:\n-\n-- the upper-bound of a variable only becomes lower and the lower-bound\n-  only becomes higher over time;\n-- the lower-bound L is always a subtype of the upper bound U;\n-- the lower-bound L and upper-bound U never refer to other type variables,\n-  but only to types (though those types may contain type variables).\n-\n-> An aside: if the terms upper- and lower-bound confuse you, think of\n-> \"supertype\" and \"subtype\".  The upper-bound is a \"supertype\"\n-> (super=upper in Latin, or something like that anyway) and the lower-bound\n-> is a \"subtype\" (sub=lower in Latin).  I find it helps to visualize\n-> a simple class hierarchy, like Java minus interfaces and\n-> primitive types.  The class Object is at the root (top) and other\n-> types lie in between.  The bottom type is then the Null type.\n-> So the tree looks like:\n->\n-> ```text\n->         Object\n->         /    \\\n->     String   Other\n->         \\    /\n->         (null)\n-> ```\n->\n-> So the upper bound type is the \"supertype\" and the lower bound is the\n-> \"subtype\" (also, super and sub mean upper and lower in Latin, or something\n-> like that anyway).\n-\n-## Satisfying constraints\n-\n-At a primitive level, there is only one form of constraint that the\n-inference understands: a subtype relation.  So the outside world can\n-say \"make type A a subtype of type B\".  If there are variables\n-involved, the inferencer will adjust their upper- and lower-bounds as\n-needed to ensure that this relation is satisfied. (We also allow \"make\n-type A equal to type B\", but this is translated into \"A <: B\" and \"B\n-<: A\")\n-\n-As stated above, we always maintain the invariant that type bounds\n-never refer to other variables.  This keeps the inference relatively\n-simple, avoiding the scenario of having a kind of graph where we have\n-to pump constraints along and reach a fixed point, but it does impose\n-some heuristics in the case where the user is relating two type\n-variables A <: B.\n-\n-Combining two variables such that variable A will forever be a subtype\n-of variable B is the trickiest part of the algorithm because there is\n-often no right choice---that is, the right choice will depend on\n-future constraints which we do not yet know. The problem comes about\n-because both A and B have bounds that can be adjusted in the future.\n-Let's look at some of the cases that can come up.\n-\n-Imagine, to start, the best case, where both A and B have an upper and\n-lower bound (that is, the bounds are not top nor bot respectively). In\n-that case, if we're lucky, A.ub <: B.lb, and so we know that whatever\n-A and B should become, they will forever have the desired subtyping\n-relation.  We can just leave things as they are.\n-\n-### Option 1: Unify\n-\n-However, suppose that A.ub is *not* a subtype of B.lb.  In\n-that case, we must make a decision.  One option is to unify A\n-and B so that they are one variable whose bounds are:\n-\n-    UB = GLB(A.ub, B.ub)\n-    LB = LUB(A.lb, B.lb)\n-\n-(Note that we will have to verify that LB <: UB; if it does not, the\n-types are not intersecting and there is an error) In that case, A <: B\n-holds trivially because A==B.  However, we have now lost some\n-flexibility, because perhaps the user intended for A and B to end up\n-as different types and not the same type.\n-\n-Pictorally, what this does is to take two distinct variables with\n-(hopefully not completely) distinct type ranges and produce one with\n-the intersection.\n-\n-```text\n-                  B.ub                  B.ub\n-                   /\\                    /\n-           A.ub   /  \\           A.ub   /\n-           /   \\ /    \\              \\ /\n-          /     X      \\              UB\n-         /     / \\      \\            / \\\n-        /     /   /      \\          /   /\n-        \\     \\  /       /          \\  /\n-         \\      X       /             LB\n-          \\    / \\     /             / \\\n-           \\  /   \\   /             /   \\\n-           A.lb    B.lb          A.lb    B.lb\n-```\n-\n-\n-### Option 2: Relate UB/LB\n-\n-Another option is to keep A and B as distinct variables but set their\n-bounds in such a way that, whatever happens, we know that A <: B will hold.\n-This can be achieved by ensuring that A.ub <: B.lb.  In practice there\n-are two ways to do that, depicted pictorally here:\n-\n-```text\n-    Before                Option #1            Option #2\n-\n-             B.ub                B.ub                B.ub\n-              /\\                 /  \\                /  \\\n-      A.ub   /  \\        A.ub   /(B')\\       A.ub   /(B')\\\n-      /   \\ /    \\           \\ /     /           \\ /     /\n-     /     X      \\         __UB____/             UB    /\n-    /     / \\      \\       /  |                   |    /\n-   /     /   /      \\     /   |                   |   /\n-   \\     \\  /       /    /(A')|                   |  /\n-    \\      X       /    /     LB            ______LB/\n-     \\    / \\     /    /     / \\           / (A')/ \\\n-      \\  /   \\   /     \\    /   \\          \\    /   \\\n-      A.lb    B.lb       A.lb    B.lb        A.lb    B.lb\n-```\n-\n-In these diagrams, UB and LB are defined as before.  As you can see,\n-the new ranges `A'` and `B'` are quite different from the range that\n-would be produced by unifying the variables.\n-\n-### What we do now\n-\n-Our current technique is to *try* (transactionally) to relate the\n-existing bounds of A and B, if there are any (i.e., if `UB(A) != top\n-&& LB(B) != bot`).  If that succeeds, we're done.  If it fails, then\n-we merge A and B into same variable.\n-\n-This is not clearly the correct course.  For example, if `UB(A) !=\n-top` but `LB(B) == bot`, we could conceivably set `LB(B)` to `UB(A)`\n-and leave the variables unmerged.  This is sometimes the better\n-course, it depends on the program.\n-\n-The main case which fails today that I would like to support is:\n-\n-```text\n-fn foo<T>(x: T, y: T) { ... }\n-\n-fn bar() {\n-    let x: @mut int = @mut 3;\n-    let y: @int = @3;\n-    foo(x, y);\n-}\n-```\n-\n-In principle, the inferencer ought to find that the parameter `T` to\n-`foo(x, y)` is `@const int`.  Today, however, it does not; this is\n-because the type variable `T` is merged with the type variable for\n-`X`, and thus inherits its UB/LB of `@mut int`.  This leaves no\n-flexibility for `T` to later adjust to accommodate `@int`.\n-\n-### What to do when not all bounds are present\n-\n-In the prior discussion we assumed that A.ub was not top and B.lb was\n-not bot.  Unfortunately this is rarely the case.  Often type variables\n-have \"lopsided\" bounds.  For example, if a variable in the program has\n-been initialized but has not been used, then its corresponding type\n-variable will have a lower bound but no upper bound.  When that\n-variable is then used, we would like to know its upper bound---but we\n-don't have one!  In this case we'll do different things depending on\n-how the variable is being used.\n-\n-## Transactional support\n-\n-Whenever we adjust merge variables or adjust their bounds, we always\n-keep a record of the old value.  This allows the changes to be undone.\n-\n-## Regions\n-\n-I've only talked about type variables here, but region variables\n-follow the same principle.  They have upper- and lower-bounds.  A\n-region A is a subregion of a region B if A being valid implies that B\n-is valid.  This basically corresponds to the block nesting structure:\n-the regions for outer block scopes are superregions of those for inner\n-block scopes.\n-\n-## Integral and floating-point type variables\n-\n-There is a third variety of type variable that we use only for\n-inferring the types of unsuffixed integer literals.  Integral type\n-variables differ from general-purpose type variables in that there's\n-no subtyping relationship among the various integral types, so instead\n-of associating each variable with an upper and lower bound, we just\n-use simple unification.  Each integer variable is associated with at\n-most one integer type.  Floating point types are handled similarly to\n-integral types.\n-\n-## GLB/LUB\n-\n-Computing the greatest-lower-bound and least-upper-bound of two\n-types/regions is generally straightforward except when type variables\n-are involved. In that case, we follow a similar \"try to use the bounds\n-when possible but otherwise merge the variables\" strategy.  In other\n-words, `GLB(A, B)` where `A` and `B` are variables will often result\n-in `A` and `B` being merged and the result being `A`.\n-\n-## Type coercion\n-\n-We have a notion of assignability which differs somewhat from\n-subtyping; in particular it may cause region borrowing to occur.  See\n-the big comment later in this file on Type Coercion for specifics.\n-\n-### In conclusion\n-\n-I showed you three ways to relate `A` and `B`.  There are also more,\n-of course, though I'm not sure if there are any more sensible options.\n-The main point is that there are various options, each of which\n-produce a distinct range of types for `A` and `B`.  Depending on what\n-the correct values for A and B are, one of these options will be the\n-right choice: but of course we don't know the right values for A and B\n-yet, that's what we're trying to find!  In our code, we opt to unify\n-(Option #1).\n-\n-# Implementation details\n-\n-We make use of a trait-like implementation strategy to consolidate\n-duplicated code between subtypes, GLB, and LUB computations.  See the\n-section on \"Type Combining\" below for details.\n-\n-*/\n+//! # Type inference engine\n+//!\n+//! This is loosely based on standard HM-type inference, but with an\n+//! extension to try and accommodate subtyping.  There is nothing\n+//! principled about this extension; it's sound---I hope!---but it's a\n+//! heuristic, ultimately, and does not guarantee that it finds a valid\n+//! typing even if one exists (in fact, there are known scenarios where it\n+//! fails, some of which may eventually become problematic).\n+//!\n+//! ## Key idea\n+//!\n+//! The main change is that each type variable T is associated with a\n+//! lower-bound L and an upper-bound U.  L and U begin as bottom and top,\n+//! respectively, but gradually narrow in response to new constraints\n+//! being introduced.  When a variable is finally resolved to a concrete\n+//! type, it can (theoretically) select any type that is a supertype of L\n+//! and a subtype of U.\n+//!\n+//! There are several critical invariants which we maintain:\n+//!\n+//! - the upper-bound of a variable only becomes lower and the lower-bound\n+//!   only becomes higher over time;\n+//! - the lower-bound L is always a subtype of the upper bound U;\n+//! - the lower-bound L and upper-bound U never refer to other type variables,\n+//!   but only to types (though those types may contain type variables).\n+//!\n+//! > An aside: if the terms upper- and lower-bound confuse you, think of\n+//! > \"supertype\" and \"subtype\".  The upper-bound is a \"supertype\"\n+//! > (super=upper in Latin, or something like that anyway) and the lower-bound\n+//! > is a \"subtype\" (sub=lower in Latin).  I find it helps to visualize\n+//! > a simple class hierarchy, like Java minus interfaces and\n+//! > primitive types.  The class Object is at the root (top) and other\n+//! > types lie in between.  The bottom type is then the Null type.\n+//! > So the tree looks like:\n+//! >\n+//! > ```text\n+//! >         Object\n+//! >         /    \\\n+//! >     String   Other\n+//! >         \\    /\n+//! >         (null)\n+//! > ```\n+//! >\n+//! > So the upper bound type is the \"supertype\" and the lower bound is the\n+//! > \"subtype\" (also, super and sub mean upper and lower in Latin, or something\n+//! > like that anyway).\n+//!\n+//! ## Satisfying constraints\n+//!\n+//! At a primitive level, there is only one form of constraint that the\n+//! inference understands: a subtype relation.  So the outside world can\n+//! say \"make type A a subtype of type B\".  If there are variables\n+//! involved, the inferencer will adjust their upper- and lower-bounds as\n+//! needed to ensure that this relation is satisfied. (We also allow \"make\n+//! type A equal to type B\", but this is translated into \"A <: B\" and \"B\n+//! <: A\")\n+//!\n+//! As stated above, we always maintain the invariant that type bounds\n+//! never refer to other variables.  This keeps the inference relatively\n+//! simple, avoiding the scenario of having a kind of graph where we have\n+//! to pump constraints along and reach a fixed point, but it does impose\n+//! some heuristics in the case where the user is relating two type\n+//! variables A <: B.\n+//!\n+//! Combining two variables such that variable A will forever be a subtype\n+//! of variable B is the trickiest part of the algorithm because there is\n+//! often no right choice---that is, the right choice will depend on\n+//! future constraints which we do not yet know. The problem comes about\n+//! because both A and B have bounds that can be adjusted in the future.\n+//! Let's look at some of the cases that can come up.\n+//!\n+//! Imagine, to start, the best case, where both A and B have an upper and\n+//! lower bound (that is, the bounds are not top nor bot respectively). In\n+//! that case, if we're lucky, A.ub <: B.lb, and so we know that whatever\n+//! A and B should become, they will forever have the desired subtyping\n+//! relation.  We can just leave things as they are.\n+//!\n+//! ### Option 1: Unify\n+//!\n+//! However, suppose that A.ub is *not* a subtype of B.lb.  In\n+//! that case, we must make a decision.  One option is to unify A\n+//! and B so that they are one variable whose bounds are:\n+//!\n+//!     UB = GLB(A.ub, B.ub)\n+//!     LB = LUB(A.lb, B.lb)\n+//!\n+//! (Note that we will have to verify that LB <: UB; if it does not, the\n+//! types are not intersecting and there is an error) In that case, A <: B\n+//! holds trivially because A==B.  However, we have now lost some\n+//! flexibility, because perhaps the user intended for A and B to end up\n+//! as different types and not the same type.\n+//!\n+//! Pictorally, what this does is to take two distinct variables with\n+//! (hopefully not completely) distinct type ranges and produce one with\n+//! the intersection.\n+//!\n+//! ```text\n+//!                   B.ub                  B.ub\n+//!                    /\\                    /\n+//!            A.ub   /  \\           A.ub   /\n+//!            /   \\ /    \\              \\ /\n+//!           /     X      \\              UB\n+//!          /     / \\      \\            / \\\n+//!         /     /   /      \\          /   /\n+//!         \\     \\  /       /          \\  /\n+//!          \\      X       /             LB\n+//!           \\    / \\     /             / \\\n+//!            \\  /   \\   /             /   \\\n+//!            A.lb    B.lb          A.lb    B.lb\n+//! ```\n+//!\n+//!\n+//! ### Option 2: Relate UB/LB\n+//!\n+//! Another option is to keep A and B as distinct variables but set their\n+//! bounds in such a way that, whatever happens, we know that A <: B will hold.\n+//! This can be achieved by ensuring that A.ub <: B.lb.  In practice there\n+//! are two ways to do that, depicted pictorally here:\n+//!\n+//! ```text\n+//!     Before                Option #1            Option #2\n+//!\n+//!              B.ub                B.ub                B.ub\n+//!               /\\                 /  \\                /  \\\n+//!       A.ub   /  \\        A.ub   /(B')\\       A.ub   /(B')\\\n+//!       /   \\ /    \\           \\ /     /           \\ /     /\n+//!      /     X      \\         __UB____/             UB    /\n+//!     /     / \\      \\       /  |                   |    /\n+//!    /     /   /      \\     /   |                   |   /\n+//!    \\     \\  /       /    /(A')|                   |  /\n+//!     \\      X       /    /     LB            ______LB/\n+//!      \\    / \\     /    /     / \\           / (A')/ \\\n+//!       \\  /   \\   /     \\    /   \\          \\    /   \\\n+//!       A.lb    B.lb       A.lb    B.lb        A.lb    B.lb\n+//! ```\n+//!\n+//! In these diagrams, UB and LB are defined as before.  As you can see,\n+//! the new ranges `A'` and `B'` are quite different from the range that\n+//! would be produced by unifying the variables.\n+//!\n+//! ### What we do now\n+//!\n+//! Our current technique is to *try* (transactionally) to relate the\n+//! existing bounds of A and B, if there are any (i.e., if `UB(A) != top\n+//! && LB(B) != bot`).  If that succeeds, we're done.  If it fails, then\n+//! we merge A and B into same variable.\n+//!\n+//! This is not clearly the correct course.  For example, if `UB(A) !=\n+//! top` but `LB(B) == bot`, we could conceivably set `LB(B)` to `UB(A)`\n+//! and leave the variables unmerged.  This is sometimes the better\n+//! course, it depends on the program.\n+//!\n+//! The main case which fails today that I would like to support is:\n+//!\n+//! ```text\n+//! fn foo<T>(x: T, y: T) { ... }\n+//!\n+//! fn bar() {\n+//!     let x: @mut int = @mut 3;\n+//!     let y: @int = @3;\n+//!     foo(x, y);\n+//! }\n+//! ```\n+//!\n+//! In principle, the inferencer ought to find that the parameter `T` to\n+//! `foo(x, y)` is `@const int`.  Today, however, it does not; this is\n+//! because the type variable `T` is merged with the type variable for\n+//! `X`, and thus inherits its UB/LB of `@mut int`.  This leaves no\n+//! flexibility for `T` to later adjust to accommodate `@int`.\n+//!\n+//! ### What to do when not all bounds are present\n+//!\n+//! In the prior discussion we assumed that A.ub was not top and B.lb was\n+//! not bot.  Unfortunately this is rarely the case.  Often type variables\n+//! have \"lopsided\" bounds.  For example, if a variable in the program has\n+//! been initialized but has not been used, then its corresponding type\n+//! variable will have a lower bound but no upper bound.  When that\n+//! variable is then used, we would like to know its upper bound---but we\n+//! don't have one!  In this case we'll do different things depending on\n+//! how the variable is being used.\n+//!\n+//! ## Transactional support\n+//!\n+//! Whenever we adjust merge variables or adjust their bounds, we always\n+//! keep a record of the old value.  This allows the changes to be undone.\n+//!\n+//! ## Regions\n+//!\n+//! I've only talked about type variables here, but region variables\n+//! follow the same principle.  They have upper- and lower-bounds.  A\n+//! region A is a subregion of a region B if A being valid implies that B\n+//! is valid.  This basically corresponds to the block nesting structure:\n+//! the regions for outer block scopes are superregions of those for inner\n+//! block scopes.\n+//!\n+//! ## Integral and floating-point type variables\n+//!\n+//! There is a third variety of type variable that we use only for\n+//! inferring the types of unsuffixed integer literals.  Integral type\n+//! variables differ from general-purpose type variables in that there's\n+//! no subtyping relationship among the various integral types, so instead\n+//! of associating each variable with an upper and lower bound, we just\n+//! use simple unification.  Each integer variable is associated with at\n+//! most one integer type.  Floating point types are handled similarly to\n+//! integral types.\n+//!\n+//! ## GLB/LUB\n+//!\n+//! Computing the greatest-lower-bound and least-upper-bound of two\n+//! types/regions is generally straightforward except when type variables\n+//! are involved. In that case, we follow a similar \"try to use the bounds\n+//! when possible but otherwise merge the variables\" strategy.  In other\n+//! words, `GLB(A, B)` where `A` and `B` are variables will often result\n+//! in `A` and `B` being merged and the result being `A`.\n+//!\n+//! ## Type coercion\n+//!\n+//! We have a notion of assignability which differs somewhat from\n+//! subtyping; in particular it may cause region borrowing to occur.  See\n+//! the big comment later in this file on Type Coercion for specifics.\n+//!\n+//! ### In conclusion\n+//!\n+//! I showed you three ways to relate `A` and `B`.  There are also more,\n+//! of course, though I'm not sure if there are any more sensible options.\n+//! The main point is that there are various options, each of which\n+//! produce a distinct range of types for `A` and `B`.  Depending on what\n+//! the correct values for A and B are, one of these options will be the\n+//! right choice: but of course we don't know the right values for A and B\n+//! yet, that's what we're trying to find!  In our code, we opt to unify\n+//! (Option #1).\n+//!\n+//! # Implementation details\n+//!\n+//! We make use of a trait-like implementation strategy to consolidate\n+//! duplicated code between subtypes, GLB, and LUB computations.  See the\n+//! section on \"Type Combining\" below for details."}, {"sha": "b171fdc7092c12afba1dc2edfeeba7953496b1a0", "filename": "src/librustc/middle/typeck/infer/error_reporting.rs", "status": "modified", "additions": 51, "deletions": 56, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ferror_reporting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ferror_reporting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ferror_reporting.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,56 +8,53 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Error Reporting Code for the inference engine\n-\n-Because of the way inference, and in particular region inference,\n-works, it often happens that errors are not detected until far after\n-the relevant line of code has been type-checked. Therefore, there is\n-an elaborate system to track why a particular constraint in the\n-inference graph arose so that we can explain to the user what gave\n-rise to a particular error.\n-\n-The basis of the system are the \"origin\" types. An \"origin\" is the\n-reason that a constraint or inference variable arose. There are\n-different \"origin\" enums for different kinds of constraints/variables\n-(e.g., `TypeOrigin`, `RegionVariableOrigin`). An origin always has\n-a span, but also more information so that we can generate a meaningful\n-error message.\n-\n-Having a catalogue of all the different reasons an error can arise is\n-also useful for other reasons, like cross-referencing FAQs etc, though\n-we are not really taking advantage of this yet.\n-\n-# Region Inference\n-\n-Region inference is particularly tricky because it always succeeds \"in\n-the moment\" and simply registers a constraint. Then, at the end, we\n-can compute the full graph and report errors, so we need to be able to\n-store and later report what gave rise to the conflicting constraints.\n-\n-# Subtype Trace\n-\n-Determing whether `T1 <: T2` often involves a number of subtypes and\n-subconstraints along the way. A \"TypeTrace\" is an extended version\n-of an origin that traces the types and other values that were being\n-compared. It is not necessarily comprehensive (in fact, at the time of\n-this writing it only tracks the root values being compared) but I'd\n-like to extend it to include significant \"waypoints\". For example, if\n-you are comparing `(T1, T2) <: (T3, T4)`, and the problem is that `T2\n-<: T4` fails, I'd like the trace to include enough information to say\n-\"in the 2nd element of the tuple\". Similarly, failures when comparing\n-arguments or return types in fn types should be able to cite the\n-specific position, etc.\n-\n-# Reality vs plan\n-\n-Of course, there is still a LOT of code in typeck that has yet to be\n-ported to this system, and which relies on string concatenation at the\n-time of error detection.\n-\n-*/\n+//! Error Reporting Code for the inference engine\n+//!\n+//! Because of the way inference, and in particular region inference,\n+//! works, it often happens that errors are not detected until far after\n+//! the relevant line of code has been type-checked. Therefore, there is\n+//! an elaborate system to track why a particular constraint in the\n+//! inference graph arose so that we can explain to the user what gave\n+//! rise to a particular error.\n+//!\n+//! The basis of the system are the \"origin\" types. An \"origin\" is the\n+//! reason that a constraint or inference variable arose. There are\n+//! different \"origin\" enums for different kinds of constraints/variables\n+//! (e.g., `TypeOrigin`, `RegionVariableOrigin`). An origin always has\n+//! a span, but also more information so that we can generate a meaningful\n+//! error message.\n+//!\n+//! Having a catalogue of all the different reasons an error can arise is\n+//! also useful for other reasons, like cross-referencing FAQs etc, though\n+//! we are not really taking advantage of this yet.\n+//!\n+//! # Region Inference\n+//!\n+//! Region inference is particularly tricky because it always succeeds \"in\n+//! the moment\" and simply registers a constraint. Then, at the end, we\n+//! can compute the full graph and report errors, so we need to be able to\n+//! store and later report what gave rise to the conflicting constraints.\n+//!\n+//! # Subtype Trace\n+//!\n+//! Determing whether `T1 <: T2` often involves a number of subtypes and\n+//! subconstraints along the way. A \"TypeTrace\" is an extended version\n+//! of an origin that traces the types and other values that were being\n+//! compared. It is not necessarily comprehensive (in fact, at the time of\n+//! this writing it only tracks the root values being compared) but I'd\n+//! like to extend it to include significant \"waypoints\". For example, if\n+//! you are comparing `(T1, T2) <: (T3, T4)`, and the problem is that `T2\n+//! <: T4` fails, I'd like the trace to include enough information to say\n+//! \"in the 2nd element of the tuple\". Similarly, failures when comparing\n+//! arguments or return types in fn types should be able to cite the\n+//! specific position, etc.\n+//!\n+//! # Reality vs plan\n+//!\n+//! Of course, there is still a LOT of code in typeck that has yet to be\n+//! ported to this system, and which relies on string concatenation at the\n+//! time of error detection.\n+\n use self::FreshOrKept::*;\n \n use std::collections::HashSet;\n@@ -391,11 +388,9 @@ impl<'a, 'tcx> ErrorReporting<'tcx> for InferCtxt<'a, 'tcx> {\n         ty::note_and_explain_type_err(self.tcx, terr);\n     }\n \n+    /// Returns a string of the form \"expected `{}`, found `{}`\", or None if this is a derived\n+    /// error.\n     fn values_str(&self, values: &ValuePairs<'tcx>) -> Option<String> {\n-        /*!\n-         * Returns a string of the form \"expected `{}`, found `{}`\",\n-         * or None if this is a derived error.\n-         */\n         match *values {\n             infer::Types(ref exp_found) => self.expected_found_str(exp_found),\n             infer::TraitRefs(ref exp_found) => self.expected_found_str(exp_found)\n@@ -1249,7 +1244,7 @@ impl<'a, 'tcx> Rebuilder<'a, 'tcx> {\n                     }\n                     ty_queue.push(&*mut_ty.ty);\n                 }\n-                ast::TyPath(ref path, ref bounds, id) => {\n+                ast::TyPath(ref path, id) => {\n                     let a_def = match self.tcx.def_map.borrow().get(&id) {\n                         None => {\n                             self.tcx\n@@ -1296,7 +1291,7 @@ impl<'a, 'tcx> Rebuilder<'a, 'tcx> {\n                             let new_path = self.rebuild_path(rebuild_info, lifetime);\n                             let to = ast::Ty {\n                                 id: cur_ty.id,\n-                                node: ast::TyPath(new_path, bounds.clone(), id),\n+                                node: ast::TyPath(new_path, id),\n                                 span: cur_ty.span\n                             };\n                             new_ty = self.rebuild_ty(new_ty, P(to));"}, {"sha": "2bad3616a05d19fd92f2bc67820f5cdc7a8dd7fd", "filename": "src/librustc/middle/typeck/infer/higher_ranked/doc.rs", "status": "modified", "additions": 401, "deletions": 405, "changes": 806, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,408 +8,404 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# Skolemization and functions\n-\n-One of the trickiest and most subtle aspects of regions is dealing\n-with higher-ranked things which include bound region variables, such\n-as function types. I strongly suggest that if you want to understand\n-the situation, you read this paper (which is, admittedly, very long,\n-but you don't have to read the whole thing):\n-\n-http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/\n-\n-Although my explanation will never compete with SPJ's (for one thing,\n-his is approximately 100 pages), I will attempt to explain the basic\n-problem and also how we solve it. Note that the paper only discusses\n-subtyping, not the computation of LUB/GLB.\n-\n-The problem we are addressing is that there is a kind of subtyping\n-between functions with bound region parameters. Consider, for\n-example, whether the following relation holds:\n-\n-    for<'a> fn(&'a int) <: for<'b> fn(&'b int)? (Yes, a => b)\n-\n-The answer is that of course it does. These two types are basically\n-the same, except that in one we used the name `a` and one we used\n-the name `b`.\n-\n-In the examples that follow, it becomes very important to know whether\n-a lifetime is bound in a function type (that is, is a lifetime\n-parameter) or appears free (is defined in some outer scope).\n-Therefore, from now on I will always write the bindings explicitly,\n-using the Rust syntax `for<'a> fn(&'a int)` to indicate that `a` is a\n-lifetime parameter.\n-\n-Now let's consider two more function types. Here, we assume that the\n-`'b` lifetime is defined somewhere outside and hence is not a lifetime\n-parameter bound by the function type (it \"appears free\"):\n-\n-    for<'a> fn(&'a int) <: fn(&'b int)? (Yes, a => b)\n-\n-This subtyping relation does in fact hold. To see why, you have to\n-consider what subtyping means. One way to look at `T1 <: T2` is to\n-say that it means that it is always ok to treat an instance of `T1` as\n-if it had the type `T2`. So, with our functions, it is always ok to\n-treat a function that can take pointers with any lifetime as if it\n-were a function that can only take a pointer with the specific\n-lifetime `'b`. After all, `'b` is a lifetime, after all, and\n-the function can take values of any lifetime.\n-\n-You can also look at subtyping as the *is a* relationship. This amounts\n-to the same thing: a function that accepts pointers with any lifetime\n-*is a* function that accepts pointers with some specific lifetime.\n-\n-So, what if we reverse the order of the two function types, like this:\n-\n-    fn(&'b int) <: for<'a> fn(&'a int)? (No)\n-\n-Does the subtyping relationship still hold?  The answer of course is\n-no. In this case, the function accepts *only the lifetime `'b`*,\n-so it is not reasonable to treat it as if it were a function that\n-accepted any lifetime.\n-\n-What about these two examples:\n-\n-    for<'a,'b> fn(&'a int, &'b int) <: for<'a>    fn(&'a int, &'a int)? (Yes)\n-    for<'a>    fn(&'a int, &'a int) <: for<'a,'b> fn(&'a int, &'b int)? (No)\n-\n-Here, it is true that functions which take two pointers with any two\n-lifetimes can be treated as if they only accepted two pointers with\n-the same lifetime, but not the reverse.\n-\n-## The algorithm\n-\n-Here is the algorithm we use to perform the subtyping check:\n-\n-1. Replace all bound regions in the subtype with new variables\n-2. Replace all bound regions in the supertype with skolemized\n-   equivalents. A \"skolemized\" region is just a new fresh region\n-   name.\n-3. Check that the parameter and return types match as normal\n-4. Ensure that no skolemized regions 'leak' into region variables\n-   visible from \"the outside\"\n-\n-Let's walk through some examples and see how this algorithm plays out.\n-\n-#### First example\n-\n-We'll start with the first example, which was:\n-\n-    1. for<'a> fn(&'a T) <: for<'b> fn(&'b T)?        Yes: a -> b\n-\n-After steps 1 and 2 of the algorithm we will have replaced the types\n-like so:\n-\n-    1. fn(&'A T) <: fn(&'x T)?\n-\n-Here the upper case `&A` indicates a *region variable*, that is, a\n-region whose value is being inferred by the system. I also replaced\n-`&b` with `&x`---I'll use letters late in the alphabet (`x`, `y`, `z`)\n-to indicate skolemized region names. We can assume they don't appear\n-elsewhere. Note that neither the sub- nor the supertype bind any\n-region names anymore (as indicated by the absence of `<` and `>`).\n-\n-The next step is to check that the parameter types match. Because\n-parameters are contravariant, this means that we check whether:\n-\n-    &'x T <: &'A T\n-\n-Region pointers are contravariant so this implies that\n-\n-    &A <= &x\n-\n-must hold, where `<=` is the subregion relationship. Processing\n-*this* constrain simply adds a constraint into our graph that `&A <=\n-&x` and is considered successful (it can, for example, be satisfied by\n-choosing the value `&x` for `&A`).\n-\n-So far we have encountered no error, so the subtype check succeeds.\n-\n-#### The third example\n-\n-Now let's look first at the third example, which was:\n-\n-    3. fn(&'a T)    <: for<'b> fn(&'b T)?        No!\n-\n-After steps 1 and 2 of the algorithm we will have replaced the types\n-like so:\n-\n-    3. fn(&'a T) <: fn(&'x T)?\n-\n-This looks pretty much the same as before, except that on the LHS\n-`'a` was not bound, and hence was left as-is and not replaced with\n-a variable. The next step is again to check that the parameter types\n-match. This will ultimately require (as before) that `'a` <= `&x`\n-must hold: but this does not hold. `self` and `x` are both distinct\n-free regions. So the subtype check fails.\n-\n-#### Checking for skolemization leaks\n-\n-You may be wondering about that mysterious last step in the algorithm.\n-So far it has not been relevant. The purpose of that last step is to\n-catch something like *this*:\n-\n-    for<'a> fn() -> fn(&'a T) <: fn() -> for<'b> fn(&'b T)?   No.\n-\n-Here the function types are the same but for where the binding occurs.\n-The subtype returns a function that expects a value in precisely one\n-region. The supertype returns a function that expects a value in any\n-region. If we allow an instance of the subtype to be used where the\n-supertype is expected, then, someone could call the fn and think that\n-the return value has type `fn<b>(&'b T)` when it really has type\n-`fn(&'a T)` (this is case #3, above). Bad.\n-\n-So let's step through what happens when we perform this subtype check.\n-We first replace the bound regions in the subtype (the supertype has\n-no bound regions). This gives us:\n-\n-    fn() -> fn(&'A T) <: fn() -> for<'b> fn(&'b T)?\n-\n-Now we compare the return types, which are covariant, and hence we have:\n-\n-    fn(&'A T) <: for<'b> fn(&'b T)?\n-\n-Here we skolemize the bound region in the supertype to yield:\n-\n-    fn(&'A T) <: fn(&'x T)?\n-\n-And then proceed to compare the argument types:\n-\n-    &'x T <: &'A T\n-    'A <= 'x\n-\n-Finally, this is where it gets interesting!  This is where an error\n-*should* be reported. But in fact this will not happen. The reason why\n-is that `A` is a variable: we will infer that its value is the fresh\n-region `x` and think that everything is happy. In fact, this behavior\n-is *necessary*, it was key to the first example we walked through.\n-\n-The difference between this example and the first one is that the variable\n-`A` already existed at the point where the skolemization occurred. In\n-the first example, you had two functions:\n-\n-    for<'a> fn(&'a T) <: for<'b> fn(&'b T)\n-\n-and hence `&A` and `&x` were created \"together\". In general, the\n-intention of the skolemized names is that they are supposed to be\n-fresh names that could never be equal to anything from the outside.\n-But when inference comes into play, we might not be respecting this\n-rule.\n-\n-So the way we solve this is to add a fourth step that examines the\n-constraints that refer to skolemized names. Basically, consider a\n-non-directed verison of the constraint graph. Let `Tainted(x)` be the\n-set of all things reachable from a skolemized variable `x`.\n-`Tainted(x)` should not contain any regions that existed before the\n-step at which the skolemization was performed. So this case here\n-would fail because `&x` was created alone, but is relatable to `&A`.\n-\n-## Computing the LUB and GLB\n-\n-The paper I pointed you at is written for Haskell. It does not\n-therefore considering subtyping and in particular does not consider\n-LUB or GLB computation. We have to consider this. Here is the\n-algorithm I implemented.\n-\n-First though, let's discuss what we are trying to compute in more\n-detail. The LUB is basically the \"common supertype\" and the GLB is\n-\"common subtype\"; one catch is that the LUB should be the\n-*most-specific* common supertype and the GLB should be *most general*\n-common subtype (as opposed to any common supertype or any common\n-subtype).\n-\n-Anyway, to help clarify, here is a table containing some function\n-pairs and their LUB/GLB (for conciseness, in this table, I'm just\n-including the lifetimes here, not the rest of the types, and I'm\n-writing `fn<>` instead of `for<> fn`):\n-\n-```\n-Type 1                Type 2                LUB                    GLB\n-fn<'a>('a)            fn('X)                fn('X)                 fn<'a>('a)\n-fn('a)                fn('X)                --                     fn<'a>('a)\n-fn<'a,'b>('a, 'b)     fn<'x>('x, 'x)        fn<'a>('a, 'a)         fn<'a,'b>('a, 'b)\n-fn<'a,'b>('a, 'b, 'a) fn<'x,'y>('x, 'y, 'y) fn<'a>('a, 'a, 'a)     fn<'a,'b,'c>('a,'b,'c)\n-```\n-\n-### Conventions\n-\n-I use lower-case letters (e.g., `&a`) for bound regions and upper-case\n-letters for free regions (`&A`).  Region variables written with a\n-dollar-sign (e.g., `$a`).  I will try to remember to enumerate the\n-bound-regions on the fn type as well (e.g., `for<'a> fn(&a)`).\n-\n-### High-level summary\n-\n-Both the LUB and the GLB algorithms work in a similar fashion.  They\n-begin by replacing all bound regions (on both sides) with fresh region\n-inference variables.  Therefore, both functions are converted to types\n-that contain only free regions.  We can then compute the LUB/GLB in a\n-straightforward way, as described in `combine.rs`.  This results in an\n-interim type T.  The algorithms then examine the regions that appear\n-in T and try to, in some cases, replace them with bound regions to\n-yield the final result.\n-\n-To decide whether to replace a region `R` that appears in `T` with a\n-bound region, the algorithms make use of two bits of information.\n-First is a set `V` that contains all region variables created as part\n-of the LUB/GLB computation. `V` will contain the region variables\n-created to replace the bound regions in the input types, but it also\n-contains 'intermediate' variables created to represent the LUB/GLB of\n-individual regions.  Basically, when asked to compute the LUB/GLB of a\n-region variable with another region, the inferencer cannot oblige\n-immediately since the values of that variables are not known.\n-Therefore, it creates a new variable that is related to the two\n-regions.  For example, the LUB of two variables `$x` and `$y` is a\n-fresh variable `$z` that is constrained such that `$x <= $z` and `$y\n-<= $z`.  So `V` will contain these intermediate variables as well.\n-\n-The other important factor in deciding how to replace a region in T is\n-the function `Tainted($r)` which, for a region variable, identifies\n-all regions that the region variable is related to in some way\n-(`Tainted()` made an appearance in the subtype computation as well).\n-\n-### LUB\n-\n-The LUB algorithm proceeds in three steps:\n-\n-1. Replace all bound regions (on both sides) with fresh region\n-   inference variables.\n-2. Compute the LUB \"as normal\", meaning compute the GLB of each\n-   pair of argument types and the LUB of the return types and\n-   so forth.  Combine those to a new function type `F`.\n-3. Replace each region `R` that appears in `F` as follows:\n-   - Let `V` be the set of variables created during the LUB\n-     computational steps 1 and 2, as described in the previous section.\n-   - If `R` is not in `V`, replace `R` with itself.\n-   - If `Tainted(R)` contains a region that is not in `V`,\n-     replace `R` with itself.\n-   - Otherwise, select the earliest variable in `Tainted(R)` that originates\n-     from the left-hand side and replace `R` with the bound region that\n-     this variable was a replacement for.\n-\n-So, let's work through the simplest example: `fn(&A)` and `for<'a> fn(&a)`.\n-In this case, `&a` will be replaced with `$a` and the interim LUB type\n-`fn($b)` will be computed, where `$b=GLB(&A,$a)`.  Therefore, `V =\n-{$a, $b}` and `Tainted($b) = { $b, $a, &A }`.  When we go to replace\n-`$b`, we find that since `&A \\in Tainted($b)` is not a member of `V`,\n-we leave `$b` as is.  When region inference happens, `$b` will be\n-resolved to `&A`, as we wanted.\n-\n-Let's look at a more complex one: `fn(&a, &b)` and `fn(&x, &x)`.  In\n-this case, we'll end up with a (pre-replacement) LUB type of `fn(&g,\n-&h)` and a graph that looks like:\n-\n-```\n-     $a        $b     *--$x\n-       \\        \\    /  /\n-        \\        $h-*  /\n-         $g-----------*\n-```\n-\n-Here `$g` and `$h` are fresh variables that are created to represent\n-the LUB/GLB of things requiring inference.  This means that `V` and\n-`Tainted` will look like:\n-\n-```\n-V = {$a, $b, $g, $h, $x}\n-Tainted($g) = Tainted($h) = { $a, $b, $h, $g, $x }\n-```\n-\n-Therefore we replace both `$g` and `$h` with `$a`, and end up\n-with the type `fn(&a, &a)`.\n-\n-### GLB\n-\n-The procedure for computing the GLB is similar.  The difference lies\n-in computing the replacements for the various variables. For each\n-region `R` that appears in the type `F`, we again compute `Tainted(R)`\n-and examine the results:\n-\n-1. If `R` is not in `V`, it is not replaced.\n-2. Else, if `Tainted(R)` contains only variables in `V`, and it\n-   contains exactly one variable from the LHS and one variable from\n-   the RHS, then `R` can be mapped to the bound version of the\n-   variable from the LHS.\n-3. Else, if `Tainted(R)` contains no variable from the LHS and no\n-   variable from the RHS, then `R` can be mapped to itself.\n-4. Else, `R` is mapped to a fresh bound variable.\n-\n-These rules are pretty complex.  Let's look at some examples to see\n-how they play out.\n-\n-Out first example was `fn(&a)` and `fn(&X)`.  In this case, `&a` will\n-be replaced with `$a` and we will ultimately compute a\n-(pre-replacement) GLB type of `fn($g)` where `$g=LUB($a,&X)`.\n-Therefore, `V={$a,$g}` and `Tainted($g)={$g,$a,&X}.  To find the\n-replacement for `$g` we consult the rules above:\n-- Rule (1) does not apply because `$g \\in V`\n-- Rule (2) does not apply because `&X \\in Tainted($g)`\n-- Rule (3) does not apply because `$a \\in Tainted($g)`\n-- Hence, by rule (4), we replace `$g` with a fresh bound variable `&z`.\n-So our final result is `fn(&z)`, which is correct.\n-\n-The next example is `fn(&A)` and `fn(&Z)`. In this case, we will again\n-have a (pre-replacement) GLB of `fn(&g)`, where `$g = LUB(&A,&Z)`.\n-Therefore, `V={$g}` and `Tainted($g) = {$g, &A, &Z}`.  In this case,\n-by rule (3), `$g` is mapped to itself, and hence the result is\n-`fn($g)`.  This result is correct (in this case, at least), but it is\n-indicative of a case that *can* lead us into concluding that there is\n-no GLB when in fact a GLB does exist.  See the section \"Questionable\n-Results\" below for more details.\n-\n-The next example is `fn(&a, &b)` and `fn(&c, &c)`. In this case, as\n-before, we'll end up with `F=fn($g, $h)` where `Tainted($g) =\n-Tainted($h) = {$g, $h, $a, $b, $c}`.  Only rule (4) applies and hence\n-we'll select fresh bound variables `y` and `z` and wind up with\n-`fn(&y, &z)`.\n-\n-For the last example, let's consider what may seem trivial, but is\n-not: `fn(&a, &a)` and `fn(&b, &b)`.  In this case, we'll get `F=fn($g,\n-$h)` where `Tainted($g) = {$g, $a, $x}` and `Tainted($h) = {$h, $a,\n-$x}`.  Both of these sets contain exactly one bound variable from each\n-side, so we'll map them both to `&a`, resulting in `fn(&a, &a)`, which\n-is the desired result.\n-\n-### Shortcomings and correctness\n-\n-You may be wondering whether this algorithm is correct.  The answer is\n-\"sort of\".  There are definitely cases where they fail to compute a\n-result even though a correct result exists.  I believe, though, that\n-if they succeed, then the result is valid, and I will attempt to\n-convince you.  The basic argument is that the \"pre-replacement\" step\n-computes a set of constraints.  The replacements, then, attempt to\n-satisfy those constraints, using bound identifiers where needed.\n-\n-For now I will briefly go over the cases for LUB/GLB and identify\n-their intent:\n-\n-- LUB:\n-  - The region variables that are substituted in place of bound regions\n-    are intended to collect constraints on those bound regions.\n-  - If Tainted(R) contains only values in V, then this region is unconstrained\n-    and can therefore be generalized, otherwise it cannot.\n-- GLB:\n-  - The region variables that are substituted in place of bound regions\n-    are intended to collect constraints on those bound regions.\n-  - If Tainted(R) contains exactly one variable from each side, and\n-    only variables in V, that indicates that those two bound regions\n-    must be equated.\n-  - Otherwise, if Tainted(R) references any variables from left or right\n-    side, then it is trying to combine a bound region with a free one or\n-    multiple bound regions, so we need to select fresh bound regions.\n-\n-Sorry this is more of a shorthand to myself.  I will try to write up something\n-more convincing in the future.\n-\n-#### Where are the algorithms wrong?\n-\n-- The pre-replacement computation can fail even though using a\n-  bound-region would have succeeded.\n-- We will compute GLB(fn(fn($a)), fn(fn($b))) as fn($c) where $c is the\n-  GLB of $a and $b.  But if inference finds that $a and $b must be mapped\n-  to regions without a GLB, then this is effectively a failure to compute\n-  the GLB.  However, the result `fn<$c>(fn($c))` is a valid GLB.\n-\n- */\n+//! # Skolemization and functions\n+//!\n+//! One of the trickiest and most subtle aspects of regions is dealing\n+//! with higher-ranked things which include bound region variables, such\n+//! as function types. I strongly suggest that if you want to understand\n+//! the situation, you read this paper (which is, admittedly, very long,\n+//! but you don't have to read the whole thing):\n+//!\n+//! http://research.microsoft.com/en-us/um/people/simonpj/papers/higher-rank/\n+//!\n+//! Although my explanation will never compete with SPJ's (for one thing,\n+//! his is approximately 100 pages), I will attempt to explain the basic\n+//! problem and also how we solve it. Note that the paper only discusses\n+//! subtyping, not the computation of LUB/GLB.\n+//!\n+//! The problem we are addressing is that there is a kind of subtyping\n+//! between functions with bound region parameters. Consider, for\n+//! example, whether the following relation holds:\n+//!\n+//!     for<'a> fn(&'a int) <: for<'b> fn(&'b int)? (Yes, a => b)\n+//!\n+//! The answer is that of course it does. These two types are basically\n+//! the same, except that in one we used the name `a` and one we used\n+//! the name `b`.\n+//!\n+//! In the examples that follow, it becomes very important to know whether\n+//! a lifetime is bound in a function type (that is, is a lifetime\n+//! parameter) or appears free (is defined in some outer scope).\n+//! Therefore, from now on I will always write the bindings explicitly,\n+//! using the Rust syntax `for<'a> fn(&'a int)` to indicate that `a` is a\n+//! lifetime parameter.\n+//!\n+//! Now let's consider two more function types. Here, we assume that the\n+//! `'b` lifetime is defined somewhere outside and hence is not a lifetime\n+//! parameter bound by the function type (it \"appears free\"):\n+//!\n+//!     for<'a> fn(&'a int) <: fn(&'b int)? (Yes, a => b)\n+//!\n+//! This subtyping relation does in fact hold. To see why, you have to\n+//! consider what subtyping means. One way to look at `T1 <: T2` is to\n+//! say that it means that it is always ok to treat an instance of `T1` as\n+//! if it had the type `T2`. So, with our functions, it is always ok to\n+//! treat a function that can take pointers with any lifetime as if it\n+//! were a function that can only take a pointer with the specific\n+//! lifetime `'b`. After all, `'b` is a lifetime, after all, and\n+//! the function can take values of any lifetime.\n+//!\n+//! You can also look at subtyping as the *is a* relationship. This amounts\n+//! to the same thing: a function that accepts pointers with any lifetime\n+//! *is a* function that accepts pointers with some specific lifetime.\n+//!\n+//! So, what if we reverse the order of the two function types, like this:\n+//!\n+//!     fn(&'b int) <: for<'a> fn(&'a int)? (No)\n+//!\n+//! Does the subtyping relationship still hold?  The answer of course is\n+//! no. In this case, the function accepts *only the lifetime `'b`*,\n+//! so it is not reasonable to treat it as if it were a function that\n+//! accepted any lifetime.\n+//!\n+//! What about these two examples:\n+//!\n+//!     for<'a,'b> fn(&'a int, &'b int) <: for<'a>    fn(&'a int, &'a int)? (Yes)\n+//!     for<'a>    fn(&'a int, &'a int) <: for<'a,'b> fn(&'a int, &'b int)? (No)\n+//!\n+//! Here, it is true that functions which take two pointers with any two\n+//! lifetimes can be treated as if they only accepted two pointers with\n+//! the same lifetime, but not the reverse.\n+//!\n+//! ## The algorithm\n+//!\n+//! Here is the algorithm we use to perform the subtyping check:\n+//!\n+//! 1. Replace all bound regions in the subtype with new variables\n+//! 2. Replace all bound regions in the supertype with skolemized\n+//!    equivalents. A \"skolemized\" region is just a new fresh region\n+//!    name.\n+//! 3. Check that the parameter and return types match as normal\n+//! 4. Ensure that no skolemized regions 'leak' into region variables\n+//!    visible from \"the outside\"\n+//!\n+//! Let's walk through some examples and see how this algorithm plays out.\n+//!\n+//! #### First example\n+//!\n+//! We'll start with the first example, which was:\n+//!\n+//!     1. for<'a> fn(&'a T) <: for<'b> fn(&'b T)?        Yes: a -> b\n+//!\n+//! After steps 1 and 2 of the algorithm we will have replaced the types\n+//! like so:\n+//!\n+//!     1. fn(&'A T) <: fn(&'x T)?\n+//!\n+//! Here the upper case `&A` indicates a *region variable*, that is, a\n+//! region whose value is being inferred by the system. I also replaced\n+//! `&b` with `&x`---I'll use letters late in the alphabet (`x`, `y`, `z`)\n+//! to indicate skolemized region names. We can assume they don't appear\n+//! elsewhere. Note that neither the sub- nor the supertype bind any\n+//! region names anymore (as indicated by the absence of `<` and `>`).\n+//!\n+//! The next step is to check that the parameter types match. Because\n+//! parameters are contravariant, this means that we check whether:\n+//!\n+//!     &'x T <: &'A T\n+//!\n+//! Region pointers are contravariant so this implies that\n+//!\n+//!     &A <= &x\n+//!\n+//! must hold, where `<=` is the subregion relationship. Processing\n+//! *this* constrain simply adds a constraint into our graph that `&A <=\n+//! &x` and is considered successful (it can, for example, be satisfied by\n+//! choosing the value `&x` for `&A`).\n+//!\n+//! So far we have encountered no error, so the subtype check succeeds.\n+//!\n+//! #### The third example\n+//!\n+//! Now let's look first at the third example, which was:\n+//!\n+//!     3. fn(&'a T)    <: for<'b> fn(&'b T)?        No!\n+//!\n+//! After steps 1 and 2 of the algorithm we will have replaced the types\n+//! like so:\n+//!\n+//!     3. fn(&'a T) <: fn(&'x T)?\n+//!\n+//! This looks pretty much the same as before, except that on the LHS\n+//! `'a` was not bound, and hence was left as-is and not replaced with\n+//! a variable. The next step is again to check that the parameter types\n+//! match. This will ultimately require (as before) that `'a` <= `&x`\n+//! must hold: but this does not hold. `self` and `x` are both distinct\n+//! free regions. So the subtype check fails.\n+//!\n+//! #### Checking for skolemization leaks\n+//!\n+//! You may be wondering about that mysterious last step in the algorithm.\n+//! So far it has not been relevant. The purpose of that last step is to\n+//! catch something like *this*:\n+//!\n+//!     for<'a> fn() -> fn(&'a T) <: fn() -> for<'b> fn(&'b T)?   No.\n+//!\n+//! Here the function types are the same but for where the binding occurs.\n+//! The subtype returns a function that expects a value in precisely one\n+//! region. The supertype returns a function that expects a value in any\n+//! region. If we allow an instance of the subtype to be used where the\n+//! supertype is expected, then, someone could call the fn and think that\n+//! the return value has type `fn<b>(&'b T)` when it really has type\n+//! `fn(&'a T)` (this is case #3, above). Bad.\n+//!\n+//! So let's step through what happens when we perform this subtype check.\n+//! We first replace the bound regions in the subtype (the supertype has\n+//! no bound regions). This gives us:\n+//!\n+//!     fn() -> fn(&'A T) <: fn() -> for<'b> fn(&'b T)?\n+//!\n+//! Now we compare the return types, which are covariant, and hence we have:\n+//!\n+//!     fn(&'A T) <: for<'b> fn(&'b T)?\n+//!\n+//! Here we skolemize the bound region in the supertype to yield:\n+//!\n+//!     fn(&'A T) <: fn(&'x T)?\n+//!\n+//! And then proceed to compare the argument types:\n+//!\n+//!     &'x T <: &'A T\n+//!     'A <= 'x\n+//!\n+//! Finally, this is where it gets interesting!  This is where an error\n+//! *should* be reported. But in fact this will not happen. The reason why\n+//! is that `A` is a variable: we will infer that its value is the fresh\n+//! region `x` and think that everything is happy. In fact, this behavior\n+//! is *necessary*, it was key to the first example we walked through.\n+//!\n+//! The difference between this example and the first one is that the variable\n+//! `A` already existed at the point where the skolemization occurred. In\n+//! the first example, you had two functions:\n+//!\n+//!     for<'a> fn(&'a T) <: for<'b> fn(&'b T)\n+//!\n+//! and hence `&A` and `&x` were created \"together\". In general, the\n+//! intention of the skolemized names is that they are supposed to be\n+//! fresh names that could never be equal to anything from the outside.\n+//! But when inference comes into play, we might not be respecting this\n+//! rule.\n+//!\n+//! So the way we solve this is to add a fourth step that examines the\n+//! constraints that refer to skolemized names. Basically, consider a\n+//! non-directed verison of the constraint graph. Let `Tainted(x)` be the\n+//! set of all things reachable from a skolemized variable `x`.\n+//! `Tainted(x)` should not contain any regions that existed before the\n+//! step at which the skolemization was performed. So this case here\n+//! would fail because `&x` was created alone, but is relatable to `&A`.\n+//!\n+//! ## Computing the LUB and GLB\n+//!\n+//! The paper I pointed you at is written for Haskell. It does not\n+//! therefore considering subtyping and in particular does not consider\n+//! LUB or GLB computation. We have to consider this. Here is the\n+//! algorithm I implemented.\n+//!\n+//! First though, let's discuss what we are trying to compute in more\n+//! detail. The LUB is basically the \"common supertype\" and the GLB is\n+//! \"common subtype\"; one catch is that the LUB should be the\n+//! *most-specific* common supertype and the GLB should be *most general*\n+//! common subtype (as opposed to any common supertype or any common\n+//! subtype).\n+//!\n+//! Anyway, to help clarify, here is a table containing some function\n+//! pairs and their LUB/GLB (for conciseness, in this table, I'm just\n+//! including the lifetimes here, not the rest of the types, and I'm\n+//! writing `fn<>` instead of `for<> fn`):\n+//!\n+//! ```\n+//! Type 1                Type 2                LUB                    GLB\n+//! fn<'a>('a)            fn('X)                fn('X)                 fn<'a>('a)\n+//! fn('a)                fn('X)                --                     fn<'a>('a)\n+//! fn<'a,'b>('a, 'b)     fn<'x>('x, 'x)        fn<'a>('a, 'a)         fn<'a,'b>('a, 'b)\n+//! fn<'a,'b>('a, 'b, 'a) fn<'x,'y>('x, 'y, 'y) fn<'a>('a, 'a, 'a)     fn<'a,'b,'c>('a,'b,'c)\n+//! ```\n+//!\n+//! ### Conventions\n+//!\n+//! I use lower-case letters (e.g., `&a`) for bound regions and upper-case\n+//! letters for free regions (`&A`).  Region variables written with a\n+//! dollar-sign (e.g., `$a`).  I will try to remember to enumerate the\n+//! bound-regions on the fn type as well (e.g., `for<'a> fn(&a)`).\n+//!\n+//! ### High-level summary\n+//!\n+//! Both the LUB and the GLB algorithms work in a similar fashion.  They\n+//! begin by replacing all bound regions (on both sides) with fresh region\n+//! inference variables.  Therefore, both functions are converted to types\n+//! that contain only free regions.  We can then compute the LUB/GLB in a\n+//! straightforward way, as described in `combine.rs`.  This results in an\n+//! interim type T.  The algorithms then examine the regions that appear\n+//! in T and try to, in some cases, replace them with bound regions to\n+//! yield the final result.\n+//!\n+//! To decide whether to replace a region `R` that appears in `T` with a\n+//! bound region, the algorithms make use of two bits of information.\n+//! First is a set `V` that contains all region variables created as part\n+//! of the LUB/GLB computation. `V` will contain the region variables\n+//! created to replace the bound regions in the input types, but it also\n+//! contains 'intermediate' variables created to represent the LUB/GLB of\n+//! individual regions.  Basically, when asked to compute the LUB/GLB of a\n+//! region variable with another region, the inferencer cannot oblige\n+//! immediately since the values of that variables are not known.\n+//! Therefore, it creates a new variable that is related to the two\n+//! regions.  For example, the LUB of two variables `$x` and `$y` is a\n+//! fresh variable `$z` that is constrained such that `$x <= $z` and `$y\n+//! <= $z`.  So `V` will contain these intermediate variables as well.\n+//!\n+//! The other important factor in deciding how to replace a region in T is\n+//! the function `Tainted($r)` which, for a region variable, identifies\n+//! all regions that the region variable is related to in some way\n+//! (`Tainted()` made an appearance in the subtype computation as well).\n+//!\n+//! ### LUB\n+//!\n+//! The LUB algorithm proceeds in three steps:\n+//!\n+//! 1. Replace all bound regions (on both sides) with fresh region\n+//!    inference variables.\n+//! 2. Compute the LUB \"as normal\", meaning compute the GLB of each\n+//!    pair of argument types and the LUB of the return types and\n+//!    so forth.  Combine those to a new function type `F`.\n+//! 3. Replace each region `R` that appears in `F` as follows:\n+//!    - Let `V` be the set of variables created during the LUB\n+//!      computational steps 1 and 2, as described in the previous section.\n+//!    - If `R` is not in `V`, replace `R` with itself.\n+//!    - If `Tainted(R)` contains a region that is not in `V`,\n+//!      replace `R` with itself.\n+//!    - Otherwise, select the earliest variable in `Tainted(R)` that originates\n+//!      from the left-hand side and replace `R` with the bound region that\n+//!      this variable was a replacement for.\n+//!\n+//! So, let's work through the simplest example: `fn(&A)` and `for<'a> fn(&a)`.\n+//! In this case, `&a` will be replaced with `$a` and the interim LUB type\n+//! `fn($b)` will be computed, where `$b=GLB(&A,$a)`.  Therefore, `V =\n+//! {$a, $b}` and `Tainted($b) = { $b, $a, &A }`.  When we go to replace\n+//! `$b`, we find that since `&A \\in Tainted($b)` is not a member of `V`,\n+//! we leave `$b` as is.  When region inference happens, `$b` will be\n+//! resolved to `&A`, as we wanted.\n+//!\n+//! Let's look at a more complex one: `fn(&a, &b)` and `fn(&x, &x)`.  In\n+//! this case, we'll end up with a (pre-replacement) LUB type of `fn(&g,\n+//! &h)` and a graph that looks like:\n+//!\n+//! ```\n+//!      $a        $b     *--$x\n+//!        \\        \\    /  /\n+//!         \\        $h-*  /\n+//!          $g-----------*\n+//! ```\n+//!\n+//! Here `$g` and `$h` are fresh variables that are created to represent\n+//! the LUB/GLB of things requiring inference.  This means that `V` and\n+//! `Tainted` will look like:\n+//!\n+//! ```\n+//! V = {$a, $b, $g, $h, $x}\n+//! Tainted($g) = Tainted($h) = { $a, $b, $h, $g, $x }\n+//! ```\n+//!\n+//! Therefore we replace both `$g` and `$h` with `$a`, and end up\n+//! with the type `fn(&a, &a)`.\n+//!\n+//! ### GLB\n+//!\n+//! The procedure for computing the GLB is similar.  The difference lies\n+//! in computing the replacements for the various variables. For each\n+//! region `R` that appears in the type `F`, we again compute `Tainted(R)`\n+//! and examine the results:\n+//!\n+//! 1. If `R` is not in `V`, it is not replaced.\n+//! 2. Else, if `Tainted(R)` contains only variables in `V`, and it\n+//!    contains exactly one variable from the LHS and one variable from\n+//!    the RHS, then `R` can be mapped to the bound version of the\n+//!    variable from the LHS.\n+//! 3. Else, if `Tainted(R)` contains no variable from the LHS and no\n+//!    variable from the RHS, then `R` can be mapped to itself.\n+//! 4. Else, `R` is mapped to a fresh bound variable.\n+//!\n+//! These rules are pretty complex.  Let's look at some examples to see\n+//! how they play out.\n+//!\n+//! Out first example was `fn(&a)` and `fn(&X)`.  In this case, `&a` will\n+//! be replaced with `$a` and we will ultimately compute a\n+//! (pre-replacement) GLB type of `fn($g)` where `$g=LUB($a,&X)`.\n+//! Therefore, `V={$a,$g}` and `Tainted($g)={$g,$a,&X}.  To find the\n+//! replacement for `$g` we consult the rules above:\n+//! - Rule (1) does not apply because `$g \\in V`\n+//! - Rule (2) does not apply because `&X \\in Tainted($g)`\n+//! - Rule (3) does not apply because `$a \\in Tainted($g)`\n+//! - Hence, by rule (4), we replace `$g` with a fresh bound variable `&z`.\n+//! So our final result is `fn(&z)`, which is correct.\n+//!\n+//! The next example is `fn(&A)` and `fn(&Z)`. In this case, we will again\n+//! have a (pre-replacement) GLB of `fn(&g)`, where `$g = LUB(&A,&Z)`.\n+//! Therefore, `V={$g}` and `Tainted($g) = {$g, &A, &Z}`.  In this case,\n+//! by rule (3), `$g` is mapped to itself, and hence the result is\n+//! `fn($g)`.  This result is correct (in this case, at least), but it is\n+//! indicative of a case that *can* lead us into concluding that there is\n+//! no GLB when in fact a GLB does exist.  See the section \"Questionable\n+//! Results\" below for more details.\n+//!\n+//! The next example is `fn(&a, &b)` and `fn(&c, &c)`. In this case, as\n+//! before, we'll end up with `F=fn($g, $h)` where `Tainted($g) =\n+//! Tainted($h) = {$g, $h, $a, $b, $c}`.  Only rule (4) applies and hence\n+//! we'll select fresh bound variables `y` and `z` and wind up with\n+//! `fn(&y, &z)`.\n+//!\n+//! For the last example, let's consider what may seem trivial, but is\n+//! not: `fn(&a, &a)` and `fn(&b, &b)`.  In this case, we'll get `F=fn($g,\n+//! $h)` where `Tainted($g) = {$g, $a, $x}` and `Tainted($h) = {$h, $a,\n+//! $x}`.  Both of these sets contain exactly one bound variable from each\n+//! side, so we'll map them both to `&a`, resulting in `fn(&a, &a)`, which\n+//! is the desired result.\n+//!\n+//! ### Shortcomings and correctness\n+//!\n+//! You may be wondering whether this algorithm is correct.  The answer is\n+//! \"sort of\".  There are definitely cases where they fail to compute a\n+//! result even though a correct result exists.  I believe, though, that\n+//! if they succeed, then the result is valid, and I will attempt to\n+//! convince you.  The basic argument is that the \"pre-replacement\" step\n+//! computes a set of constraints.  The replacements, then, attempt to\n+//! satisfy those constraints, using bound identifiers where needed.\n+//!\n+//! For now I will briefly go over the cases for LUB/GLB and identify\n+//! their intent:\n+//!\n+//! - LUB:\n+//!   - The region variables that are substituted in place of bound regions\n+//!     are intended to collect constraints on those bound regions.\n+//!   - If Tainted(R) contains only values in V, then this region is unconstrained\n+//!     and can therefore be generalized, otherwise it cannot.\n+//! - GLB:\n+//!   - The region variables that are substituted in place of bound regions\n+//!     are intended to collect constraints on those bound regions.\n+//!   - If Tainted(R) contains exactly one variable from each side, and\n+//!     only variables in V, that indicates that those two bound regions\n+//!     must be equated.\n+//!   - Otherwise, if Tainted(R) references any variables from left or right\n+//!     side, then it is trying to combine a bound region with a free one or\n+//!     multiple bound regions, so we need to select fresh bound regions.\n+//!\n+//! Sorry this is more of a shorthand to myself.  I will try to write up something\n+//! more convincing in the future.\n+//!\n+//! #### Where are the algorithms wrong?\n+//!\n+//! - The pre-replacement computation can fail even though using a\n+//!   bound-region would have succeeded.\n+//! - We will compute GLB(fn(fn($a)), fn(fn($b))) as fn($c) where $c is the\n+//!   GLB of $a and $b.  But if inference finds that $a and $b must be mapped\n+//!   to regions without a GLB, then this is effectively a failure to compute\n+//!   the GLB.  However, the result `fn<$c>(fn($c))` is a valid GLB."}, {"sha": "2f80a574bb18bde49fafca54e0c41ca905364a62", "filename": "src/librustc/middle/typeck/infer/higher_ranked/mod.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fhigher_ranked%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Helper routines for higher-ranked things. See the `doc` module at\n- * the end of the file for details.\n- */\n+//! Helper routines for higher-ranked things. See the `doc` module at\n+//! the end of the file for details.\n \n use middle::ty::{mod, Ty, replace_late_bound_regions};\n use middle::typeck::infer::{mod, combine, cres, InferCtxt};"}, {"sha": "daec959d11cd322efdadef224fa1c95c53a3b643", "filename": "src/librustc/middle/typeck/infer/lattice.rs", "status": "modified", "additions": 20, "deletions": 22, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Flattice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Flattice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Flattice.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,28 +8,26 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * # Lattice Variables\n- *\n- * This file contains generic code for operating on inference variables\n- * that are characterized by an upper- and lower-bound.  The logic and\n- * reasoning is explained in detail in the large comment in `infer.rs`.\n- *\n- * The code in here is defined quite generically so that it can be\n- * applied both to type variables, which represent types being inferred,\n- * and fn variables, which represent function types being inferred.\n- * It may eventually be applied to their types as well, who knows.\n- * In some cases, the functions are also generic with respect to the\n- * operation on the lattice (GLB vs LUB).\n- *\n- * Although all the functions are generic, we generally write the\n- * comments in a way that is specific to type variables and the LUB\n- * operation.  It's just easier that way.\n- *\n- * In general all of the functions are defined parametrically\n- * over a `LatticeValue`, which is a value defined with respect to\n- * a lattice.\n- */\n+//! # Lattice Variables\n+//!\n+//! This file contains generic code for operating on inference variables\n+//! that are characterized by an upper- and lower-bound.  The logic and\n+//! reasoning is explained in detail in the large comment in `infer.rs`.\n+//!\n+//! The code in here is defined quite generically so that it can be\n+//! applied both to type variables, which represent types being inferred,\n+//! and fn variables, which represent function types being inferred.\n+//! It may eventually be applied to their types as well, who knows.\n+//! In some cases, the functions are also generic with respect to the\n+//! operation on the lattice (GLB vs LUB).\n+//!\n+//! Although all the functions are generic, we generally write the\n+//! comments in a way that is specific to type variables and the LUB\n+//! operation.  It's just easier that way.\n+//!\n+//! In general all of the functions are defined parametrically\n+//! over a `LatticeValue`, which is a value defined with respect to\n+//! a lattice.\n \n use middle::ty::{TyVar};\n use middle::ty::{mod, Ty};"}, {"sha": "c5845b143af89aca4da0d3ee6b563e498d094543", "filename": "src/librustc/middle/typeck/infer/mod.rs", "status": "modified", "additions": 8, "deletions": 18, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! See doc.rs for documentation */\n+//! See doc.rs for documentation\n \n #![allow(non_camel_case_types)]\n \n@@ -305,18 +305,15 @@ pub fn new_infer_ctxt<'a, 'tcx>(tcx: &'a ty::ctxt<'tcx>)\n     }\n }\n \n+/// Computes the least upper-bound of `a` and `b`. If this is not possible, reports an error and\n+/// returns ty::err.\n pub fn common_supertype<'a, 'tcx>(cx: &InferCtxt<'a, 'tcx>,\n                                   origin: TypeOrigin,\n                                   a_is_expected: bool,\n                                   a: Ty<'tcx>,\n                                   b: Ty<'tcx>)\n                                   -> Ty<'tcx>\n {\n-    /*!\n-     * Computes the least upper-bound of `a` and `b`. If this is\n-     * not possible, reports an error and returns ty::err.\n-     */\n-\n     debug!(\"common_supertype({}, {})\",\n            a.repr(cx.tcx), b.repr(cx.tcx));\n \n@@ -754,17 +751,13 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n             .collect()\n     }\n \n+    /// Given a set of generics defined on a type or impl, returns a substitution mapping each\n+    /// type/region parameter to a fresh inference variable.\n     pub fn fresh_substs_for_generics(&self,\n                                      span: Span,\n                                      generics: &ty::Generics<'tcx>)\n                                      -> subst::Substs<'tcx>\n     {\n-        /*!\n-         * Given a set of generics defined on a type or impl, returns\n-         * a substitution mapping each type/region parameter to a\n-         * fresh inference variable.\n-         */\n-\n         let type_params =\n             generics.types.map(\n                 |_| self.next_ty_var());\n@@ -774,18 +767,15 @@ impl<'a, 'tcx> InferCtxt<'a, 'tcx> {\n         subst::Substs::new(type_params, region_params)\n     }\n \n+    /// Given a set of generics defined on a trait, returns a substitution mapping each output\n+    /// type/region parameter to a fresh inference variable, and mapping the self type to\n+    /// `self_ty`.\n     pub fn fresh_substs_for_trait(&self,\n                                   span: Span,\n                                   generics: &ty::Generics<'tcx>,\n                                   self_ty: Ty<'tcx>)\n                                   -> subst::Substs<'tcx>\n     {\n-        /*!\n-         * Given a set of generics defined on a trait, returns a\n-         * substitution mapping each output type/region parameter to a\n-         * fresh inference variable, and mapping the self type to\n-         * `self_ty`.\n-         */\n \n         assert!(generics.types.len(subst::SelfSpace) == 1);\n         assert!(generics.types.len(subst::FnSpace) == 0);"}, {"sha": "b4eac4c002677cdd87695a8d78ef60c0caf4ec20", "filename": "src/librustc/middle/typeck/infer/region_inference/doc.rs", "status": "modified", "additions": 364, "deletions": 368, "changes": 732, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,371 +8,367 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-Region inference module.\n-\n-# Terminology\n-\n-Note that we use the terms region and lifetime interchangeably,\n-though the term `lifetime` is preferred.\n-\n-# Introduction\n-\n-Region inference uses a somewhat more involved algorithm than type\n-inference.  It is not the most efficient thing ever written though it\n-seems to work well enough in practice (famous last words).  The reason\n-that we use a different algorithm is because, unlike with types, it is\n-impractical to hand-annotate with regions (in some cases, there aren't\n-even the requisite syntactic forms).  So we have to get it right, and\n-it's worth spending more time on a more involved analysis.  Moreover,\n-regions are a simpler case than types: they don't have aggregate\n-structure, for example.\n-\n-Unlike normal type inference, which is similar in spirit to H-M and thus\n-works progressively, the region type inference works by accumulating\n-constraints over the course of a function.  Finally, at the end of\n-processing a function, we process and solve the constraints all at\n-once.\n-\n-The constraints are always of one of three possible forms:\n-\n-- ConstrainVarSubVar(R_i, R_j) states that region variable R_i\n-  must be a subregion of R_j\n-- ConstrainRegSubVar(R, R_i) states that the concrete region R\n-  (which must not be a variable) must be a subregion of the varibale R_i\n-- ConstrainVarSubReg(R_i, R) is the inverse\n-\n-# Building up the constraints\n-\n-Variables and constraints are created using the following methods:\n-\n-- `new_region_var()` creates a new, unconstrained region variable;\n-- `make_subregion(R_i, R_j)` states that R_i is a subregion of R_j\n-- `lub_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-  the smallest region that is greater than both R_i and R_j\n-- `glb_regions(R_i, R_j) -> R_k` returns a region R_k which is\n-  the greatest region that is smaller than both R_i and R_j\n-\n-The actual region resolution algorithm is not entirely\n-obvious, though it is also not overly complex.\n-\n-## Snapshotting\n-\n-It is also permitted to try (and rollback) changes to the graph.  This\n-is done by invoking `start_snapshot()`, which returns a value.  Then\n-later you can call `rollback_to()` which undoes the work.\n-Alternatively, you can call `commit()` which ends all snapshots.\n-Snapshots can be recursive---so you can start a snapshot when another\n-is in progress, but only the root snapshot can \"commit\".\n-\n-# Resolving constraints\n-\n-The constraint resolution algorithm is not super complex but also not\n-entirely obvious.  Here I describe the problem somewhat abstractly,\n-then describe how the current code works.  There may be other, smarter\n-ways of doing this with which I am unfamiliar and can't be bothered to\n-research at the moment. - NDM\n-\n-## The problem\n-\n-Basically our input is a directed graph where nodes can be divided\n-into two categories: region variables and concrete regions.  Each edge\n-`R -> S` in the graph represents a constraint that the region `R` is a\n-subregion of the region `S`.\n-\n-Region variable nodes can have arbitrary degree.  There is one region\n-variable node per region variable.\n-\n-Each concrete region node is associated with some, well, concrete\n-region: e.g., a free lifetime, or the region for a particular scope.\n-Note that there may be more than one concrete region node for a\n-particular region value.  Moreover, because of how the graph is built,\n-we know that all concrete region nodes have either in-degree 1 or\n-out-degree 1.\n-\n-Before resolution begins, we build up the constraints in a hashmap\n-that maps `Constraint` keys to spans.  During resolution, we construct\n-the actual `Graph` structure that we describe here.\n-\n-## Our current algorithm\n-\n-We divide region variables into two groups: Expanding and Contracting.\n-Expanding region variables are those that have a concrete region\n-predecessor (direct or indirect).  Contracting region variables are\n-all others.\n-\n-We first resolve the values of Expanding region variables and then\n-process Contracting ones.  We currently use an iterative, fixed-point\n-procedure (but read on, I believe this could be replaced with a linear\n-walk).  Basically we iterate over the edges in the graph, ensuring\n-that, if the source of the edge has a value, then this value is a\n-subregion of the target value.  If the target does not yet have a\n-value, it takes the value from the source.  If the target already had\n-a value, then the resulting value is Least Upper Bound of the old and\n-new values. When we are done, each Expanding node will have the\n-smallest region that it could possibly have and still satisfy the\n-constraints.\n-\n-We next process the Contracting nodes.  Here we again iterate over the\n-edges, only this time we move values from target to source (if the\n-source is a Contracting node).  For each contracting node, we compute\n-its value as the GLB of all its successors.  Basically contracting\n-nodes ensure that there is overlap between their successors; we will\n-ultimately infer the largest overlap possible.\n-\n-# The Region Hierarchy\n-\n-## Without closures\n-\n-Let's first consider the region hierarchy without thinking about\n-closures, because they add a lot of complications. The region\n-hierarchy *basically* mirrors the lexical structure of the code.\n-There is a region for every piece of 'evaluation' that occurs, meaning\n-every expression, block, and pattern (patterns are considered to\n-\"execute\" by testing the value they are applied to and creating any\n-relevant bindings).  So, for example:\n-\n-    fn foo(x: int, y: int) { // -+\n-    //  +------------+       //  |\n-    //  |      +-----+       //  |\n-    //  |  +-+ +-+ +-+       //  |\n-    //  |  | | | | | |       //  |\n-    //  v  v v v v v v       //  |\n-        let z = x + y;       //  |\n-        ...                  //  |\n-    }                        // -+\n-\n-    fn bar() { ... }\n-\n-In this example, there is a region for the fn body block as a whole,\n-and then a subregion for the declaration of the local variable.\n-Within that, there are sublifetimes for the assignment pattern and\n-also the expression `x + y`. The expression itself has sublifetimes\n-for evaluating `x` and `y`.\n-\n-## Function calls\n-\n-Function calls are a bit tricky. I will describe how we handle them\n-*now* and then a bit about how we can improve them (Issue #6268).\n-\n-Consider a function call like `func(expr1, expr2)`, where `func`,\n-`arg1`, and `arg2` are all arbitrary expressions. Currently,\n-we construct a region hierarchy like:\n-\n-    +----------------+\n-    |                |\n-    +--+ +---+  +---+|\n-    v  v v   v  v   vv\n-    func(expr1, expr2)\n-\n-Here you can see that the call as a whole has a region and the\n-function plus arguments are subregions of that. As a side-effect of\n-this, we get a lot of spurious errors around nested calls, in\n-particular when combined with `&mut` functions. For example, a call\n-like this one\n-\n-    self.foo(self.bar())\n-\n-where both `foo` and `bar` are `&mut self` functions will always yield\n-an error.\n-\n-Here is a more involved example (which is safe) so we can see what's\n-going on:\n-\n-    struct Foo { f: uint, g: uint }\n-    ...\n-    fn add(p: &mut uint, v: uint) {\n-        *p += v;\n-    }\n-    ...\n-    fn inc(p: &mut uint) -> uint {\n-        *p += 1; *p\n-    }\n-    fn weird() {\n-        let mut x: Box<Foo> = box Foo { ... };\n-        'a: add(&mut (*x).f,\n-                'b: inc(&mut (*x).f)) // (..)\n-    }\n-\n-The important part is the line marked `(..)` which contains a call to\n-`add()`. The first argument is a mutable borrow of the field `f`.  The\n-second argument also borrows the field `f`. Now, in the current borrow\n-checker, the first borrow is given the lifetime of the call to\n-`add()`, `'a`.  The second borrow is given the lifetime of `'b` of the\n-call to `inc()`. Because `'b` is considered to be a sublifetime of\n-`'a`, an error is reported since there are two co-existing mutable\n-borrows of the same data.\n-\n-However, if we were to examine the lifetimes a bit more carefully, we\n-can see that this error is unnecessary. Let's examine the lifetimes\n-involved with `'a` in detail. We'll break apart all the steps involved\n-in a call expression:\n-\n-    'a: {\n-        'a_arg1: let a_temp1: ... = add;\n-        'a_arg2: let a_temp2: &'a mut uint = &'a mut (*x).f;\n-        'a_arg3: let a_temp3: uint = {\n-            let b_temp1: ... = inc;\n-            let b_temp2: &'b = &'b mut (*x).f;\n-            'b_call: b_temp1(b_temp2)\n-        };\n-        'a_call: a_temp1(a_temp2, a_temp3) // (**)\n-    }\n-\n-Here we see that the lifetime `'a` includes a number of substatements.\n-In particular, there is this lifetime I've called `'a_call` that\n-corresponds to the *actual execution of the function `add()`*, after\n-all arguments have been evaluated. There is a corresponding lifetime\n-`'b_call` for the execution of `inc()`. If we wanted to be precise\n-about it, the lifetime of the two borrows should be `'a_call` and\n-`'b_call` respectively, since the references that were created\n-will not be dereferenced except during the execution itself.\n-\n-However, this model by itself is not sound. The reason is that\n-while the two references that are created will never be used\n-simultaneously, it is still true that the first reference is\n-*created* before the second argument is evaluated, and so even though\n-it will not be *dereferenced* during the evaluation of the second\n-argument, it can still be *invalidated* by that evaluation. Consider\n-this similar but unsound example:\n-\n-    struct Foo { f: uint, g: uint }\n-    ...\n-    fn add(p: &mut uint, v: uint) {\n-        *p += v;\n-    }\n-    ...\n-    fn consume(x: Box<Foo>) -> uint {\n-        x.f + x.g\n-    }\n-    fn weird() {\n-        let mut x: Box<Foo> = box Foo { ... };\n-        'a: add(&mut (*x).f, consume(x)) // (..)\n-    }\n-\n-In this case, the second argument to `add` actually consumes `x`, thus\n-invalidating the first argument.\n-\n-So, for now, we exclude the `call` lifetimes from our model.\n-Eventually I would like to include them, but we will have to make the\n-borrow checker handle this situation correctly. In particular, if\n-there is a reference created whose lifetime does not enclose\n-the borrow expression, we must issue sufficient restrictions to ensure\n-that the pointee remains valid.\n-\n-## Adding closures\n-\n-The other significant complication to the region hierarchy is\n-closures. I will describe here how closures should work, though some\n-of the work to implement this model is ongoing at the time of this\n-writing.\n-\n-The body of closures are type-checked along with the function that\n-creates them. However, unlike other expressions that appear within the\n-function body, it is not entirely obvious when a closure body executes\n-with respect to the other expressions. This is because the closure\n-body will execute whenever the closure is called; however, we can\n-never know precisely when the closure will be called, especially\n-without some sort of alias analysis.\n-\n-However, we can place some sort of limits on when the closure\n-executes.  In particular, the type of every closure `fn:'r K` includes\n-a region bound `'r`. This bound indicates the maximum lifetime of that\n-closure; once we exit that region, the closure cannot be called\n-anymore. Therefore, we say that the lifetime of the closure body is a\n-sublifetime of the closure bound, but the closure body itself is unordered\n-with respect to other parts of the code.\n-\n-For example, consider the following fragment of code:\n-\n-    'a: {\n-         let closure: fn:'a() = || 'b: {\n-             'c: ...\n-         };\n-         'd: ...\n-    }\n-\n-Here we have four lifetimes, `'a`, `'b`, `'c`, and `'d`. The closure\n-`closure` is bounded by the lifetime `'a`. The lifetime `'b` is the\n-lifetime of the closure body, and `'c` is some statement within the\n-closure body. Finally, `'d` is a statement within the outer block that\n-created the closure.\n-\n-We can say that the closure body `'b` is a sublifetime of `'a` due to\n-the closure bound. By the usual lexical scoping conventions, the\n-statement `'c` is clearly a sublifetime of `'b`, and `'d` is a\n-sublifetime of `'d`. However, there is no ordering between `'c` and\n-`'d` per se (this kind of ordering between statements is actually only\n-an issue for dataflow; passes like the borrow checker must assume that\n-closures could execute at any time from the moment they are created\n-until they go out of scope).\n-\n-### Complications due to closure bound inference\n-\n-There is only one problem with the above model: in general, we do not\n-actually *know* the closure bounds during region inference! In fact,\n-closure bounds are almost always region variables! This is very tricky\n-because the inference system implicitly assumes that we can do things\n-like compute the LUB of two scoped lifetimes without needing to know\n-the values of any variables.\n-\n-Here is an example to illustrate the problem:\n-\n-    fn identify<T>(x: T) -> T { x }\n-\n-    fn foo() { // 'foo is the function body\n-      'a: {\n-           let closure = identity(|| 'b: {\n-               'c: ...\n-           });\n-           'd: closure();\n-      }\n-      'e: ...;\n-    }\n-\n-In this example, the closure bound is not explicit. At compile time,\n-we will create a region variable (let's call it `V0`) to represent the\n-closure bound.\n-\n-The primary difficulty arises during the constraint propagation phase.\n-Imagine there is some variable with incoming edges from `'c` and `'d`.\n-This means that the value of the variable must be `LUB('c,\n-'d)`. However, without knowing what the closure bound `V0` is, we\n-can't compute the LUB of `'c` and `'d`! Any we don't know the closure\n-bound until inference is done.\n-\n-The solution is to rely on the fixed point nature of inference.\n-Basically, when we must compute `LUB('c, 'd)`, we just use the current\n-value for `V0` as the closure's bound. If `V0`'s binding should\n-change, then we will do another round of inference, and the result of\n-`LUB('c, 'd)` will change.\n-\n-One minor implication of this is that the graph does not in fact track\n-the full set of dependencies between edges. We cannot easily know\n-whether the result of a LUB computation will change, since there may\n-be indirect dependencies on other variables that are not reflected on\n-the graph. Therefore, we must *always* iterate over all edges when\n-doing the fixed point calculation, not just those adjacent to nodes\n-whose values have changed.\n-\n-Were it not for this requirement, we could in fact avoid fixed-point\n-iteration altogether. In that universe, we could instead first\n-identify and remove strongly connected components (SCC) in the graph.\n-Note that such components must consist solely of region variables; all\n-of these variables can effectively be unified into a single variable.\n-Once SCCs are removed, we are left with a DAG.  At this point, we\n-could walk the DAG in topological order once to compute the expanding\n-nodes, and again in reverse topological order to compute the\n-contracting nodes. However, as I said, this does not work given the\n-current treatment of closure bounds, but perhaps in the future we can\n-address this problem somehow and make region inference somewhat more\n-efficient. Note that this is solely a matter of performance, not\n-expressiveness.\n-\n-### Skolemization\n-\n-For a discussion on skolemization and higher-ranked subtyping, please\n-see the module `middle::typeck::infer::higher_ranked::doc`.\n-\n-*/\n+//! Region inference module.\n+//!\n+//! # Terminology\n+//!\n+//! Note that we use the terms region and lifetime interchangeably,\n+//! though the term `lifetime` is preferred.\n+//!\n+//! # Introduction\n+//!\n+//! Region inference uses a somewhat more involved algorithm than type\n+//! inference.  It is not the most efficient thing ever written though it\n+//! seems to work well enough in practice (famous last words).  The reason\n+//! that we use a different algorithm is because, unlike with types, it is\n+//! impractical to hand-annotate with regions (in some cases, there aren't\n+//! even the requisite syntactic forms).  So we have to get it right, and\n+//! it's worth spending more time on a more involved analysis.  Moreover,\n+//! regions are a simpler case than types: they don't have aggregate\n+//! structure, for example.\n+//!\n+//! Unlike normal type inference, which is similar in spirit to H-M and thus\n+//! works progressively, the region type inference works by accumulating\n+//! constraints over the course of a function.  Finally, at the end of\n+//! processing a function, we process and solve the constraints all at\n+//! once.\n+//!\n+//! The constraints are always of one of three possible forms:\n+//!\n+//! - ConstrainVarSubVar(R_i, R_j) states that region variable R_i\n+//!   must be a subregion of R_j\n+//! - ConstrainRegSubVar(R, R_i) states that the concrete region R\n+//!   (which must not be a variable) must be a subregion of the varibale R_i\n+//! - ConstrainVarSubReg(R_i, R) is the inverse\n+//!\n+//! # Building up the constraints\n+//!\n+//! Variables and constraints are created using the following methods:\n+//!\n+//! - `new_region_var()` creates a new, unconstrained region variable;\n+//! - `make_subregion(R_i, R_j)` states that R_i is a subregion of R_j\n+//! - `lub_regions(R_i, R_j) -> R_k` returns a region R_k which is\n+//!   the smallest region that is greater than both R_i and R_j\n+//! - `glb_regions(R_i, R_j) -> R_k` returns a region R_k which is\n+//!   the greatest region that is smaller than both R_i and R_j\n+//!\n+//! The actual region resolution algorithm is not entirely\n+//! obvious, though it is also not overly complex.\n+//!\n+//! ## Snapshotting\n+//!\n+//! It is also permitted to try (and rollback) changes to the graph.  This\n+//! is done by invoking `start_snapshot()`, which returns a value.  Then\n+//! later you can call `rollback_to()` which undoes the work.\n+//! Alternatively, you can call `commit()` which ends all snapshots.\n+//! Snapshots can be recursive---so you can start a snapshot when another\n+//! is in progress, but only the root snapshot can \"commit\".\n+//!\n+//! # Resolving constraints\n+//!\n+//! The constraint resolution algorithm is not super complex but also not\n+//! entirely obvious.  Here I describe the problem somewhat abstractly,\n+//! then describe how the current code works.  There may be other, smarter\n+//! ways of doing this with which I am unfamiliar and can't be bothered to\n+//! research at the moment. - NDM\n+//!\n+//! ## The problem\n+//!\n+//! Basically our input is a directed graph where nodes can be divided\n+//! into two categories: region variables and concrete regions.  Each edge\n+//! `R -> S` in the graph represents a constraint that the region `R` is a\n+//! subregion of the region `S`.\n+//!\n+//! Region variable nodes can have arbitrary degree.  There is one region\n+//! variable node per region variable.\n+//!\n+//! Each concrete region node is associated with some, well, concrete\n+//! region: e.g., a free lifetime, or the region for a particular scope.\n+//! Note that there may be more than one concrete region node for a\n+//! particular region value.  Moreover, because of how the graph is built,\n+//! we know that all concrete region nodes have either in-degree 1 or\n+//! out-degree 1.\n+//!\n+//! Before resolution begins, we build up the constraints in a hashmap\n+//! that maps `Constraint` keys to spans.  During resolution, we construct\n+//! the actual `Graph` structure that we describe here.\n+//!\n+//! ## Our current algorithm\n+//!\n+//! We divide region variables into two groups: Expanding and Contracting.\n+//! Expanding region variables are those that have a concrete region\n+//! predecessor (direct or indirect).  Contracting region variables are\n+//! all others.\n+//!\n+//! We first resolve the values of Expanding region variables and then\n+//! process Contracting ones.  We currently use an iterative, fixed-point\n+//! procedure (but read on, I believe this could be replaced with a linear\n+//! walk).  Basically we iterate over the edges in the graph, ensuring\n+//! that, if the source of the edge has a value, then this value is a\n+//! subregion of the target value.  If the target does not yet have a\n+//! value, it takes the value from the source.  If the target already had\n+//! a value, then the resulting value is Least Upper Bound of the old and\n+//! new values. When we are done, each Expanding node will have the\n+//! smallest region that it could possibly have and still satisfy the\n+//! constraints.\n+//!\n+//! We next process the Contracting nodes.  Here we again iterate over the\n+//! edges, only this time we move values from target to source (if the\n+//! source is a Contracting node).  For each contracting node, we compute\n+//! its value as the GLB of all its successors.  Basically contracting\n+//! nodes ensure that there is overlap between their successors; we will\n+//! ultimately infer the largest overlap possible.\n+//!\n+//! # The Region Hierarchy\n+//!\n+//! ## Without closures\n+//!\n+//! Let's first consider the region hierarchy without thinking about\n+//! closures, because they add a lot of complications. The region\n+//! hierarchy *basically* mirrors the lexical structure of the code.\n+//! There is a region for every piece of 'evaluation' that occurs, meaning\n+//! every expression, block, and pattern (patterns are considered to\n+//! \"execute\" by testing the value they are applied to and creating any\n+//! relevant bindings).  So, for example:\n+//!\n+//!     fn foo(x: int, y: int) { // -+\n+//!     //  +------------+       //  |\n+//!     //  |      +-----+       //  |\n+//!     //  |  +-+ +-+ +-+       //  |\n+//!     //  |  | | | | | |       //  |\n+//!     //  v  v v v v v v       //  |\n+//!         let z = x + y;       //  |\n+//!         ...                  //  |\n+//!     }                        // -+\n+//!\n+//!     fn bar() { ... }\n+//!\n+//! In this example, there is a region for the fn body block as a whole,\n+//! and then a subregion for the declaration of the local variable.\n+//! Within that, there are sublifetimes for the assignment pattern and\n+//! also the expression `x + y`. The expression itself has sublifetimes\n+//! for evaluating `x` and `y`.\n+//!\n+//! ## Function calls\n+//!\n+//! Function calls are a bit tricky. I will describe how we handle them\n+//! *now* and then a bit about how we can improve them (Issue #6268).\n+//!\n+//! Consider a function call like `func(expr1, expr2)`, where `func`,\n+//! `arg1`, and `arg2` are all arbitrary expressions. Currently,\n+//! we construct a region hierarchy like:\n+//!\n+//!     +----------------+\n+//!     |                |\n+//!     +--+ +---+  +---+|\n+//!     v  v v   v  v   vv\n+//!     func(expr1, expr2)\n+//!\n+//! Here you can see that the call as a whole has a region and the\n+//! function plus arguments are subregions of that. As a side-effect of\n+//! this, we get a lot of spurious errors around nested calls, in\n+//! particular when combined with `&mut` functions. For example, a call\n+//! like this one\n+//!\n+//!     self.foo(self.bar())\n+//!\n+//! where both `foo` and `bar` are `&mut self` functions will always yield\n+//! an error.\n+//!\n+//! Here is a more involved example (which is safe) so we can see what's\n+//! going on:\n+//!\n+//!     struct Foo { f: uint, g: uint }\n+//!     ...\n+//!     fn add(p: &mut uint, v: uint) {\n+//!         *p += v;\n+//!     }\n+//!     ...\n+//!     fn inc(p: &mut uint) -> uint {\n+//!         *p += 1; *p\n+//!     }\n+//!     fn weird() {\n+//!         let mut x: Box<Foo> = box Foo { ... };\n+//!         'a: add(&mut (*x).f,\n+//!                 'b: inc(&mut (*x).f)) // (..)\n+//!     }\n+//!\n+//! The important part is the line marked `(..)` which contains a call to\n+//! `add()`. The first argument is a mutable borrow of the field `f`.  The\n+//! second argument also borrows the field `f`. Now, in the current borrow\n+//! checker, the first borrow is given the lifetime of the call to\n+//! `add()`, `'a`.  The second borrow is given the lifetime of `'b` of the\n+//! call to `inc()`. Because `'b` is considered to be a sublifetime of\n+//! `'a`, an error is reported since there are two co-existing mutable\n+//! borrows of the same data.\n+//!\n+//! However, if we were to examine the lifetimes a bit more carefully, we\n+//! can see that this error is unnecessary. Let's examine the lifetimes\n+//! involved with `'a` in detail. We'll break apart all the steps involved\n+//! in a call expression:\n+//!\n+//!     'a: {\n+//!         'a_arg1: let a_temp1: ... = add;\n+//!         'a_arg2: let a_temp2: &'a mut uint = &'a mut (*x).f;\n+//!         'a_arg3: let a_temp3: uint = {\n+//!             let b_temp1: ... = inc;\n+//!             let b_temp2: &'b = &'b mut (*x).f;\n+//!             'b_call: b_temp1(b_temp2)\n+//!         };\n+//!         'a_call: a_temp1(a_temp2, a_temp3) // (**)\n+//!     }\n+//!\n+//! Here we see that the lifetime `'a` includes a number of substatements.\n+//! In particular, there is this lifetime I've called `'a_call` that\n+//! corresponds to the *actual execution of the function `add()`*, after\n+//! all arguments have been evaluated. There is a corresponding lifetime\n+//! `'b_call` for the execution of `inc()`. If we wanted to be precise\n+//! about it, the lifetime of the two borrows should be `'a_call` and\n+//! `'b_call` respectively, since the references that were created\n+//! will not be dereferenced except during the execution itself.\n+//!\n+//! However, this model by itself is not sound. The reason is that\n+//! while the two references that are created will never be used\n+//! simultaneously, it is still true that the first reference is\n+//! *created* before the second argument is evaluated, and so even though\n+//! it will not be *dereferenced* during the evaluation of the second\n+//! argument, it can still be *invalidated* by that evaluation. Consider\n+//! this similar but unsound example:\n+//!\n+//!     struct Foo { f: uint, g: uint }\n+//!     ...\n+//!     fn add(p: &mut uint, v: uint) {\n+//!         *p += v;\n+//!     }\n+//!     ...\n+//!     fn consume(x: Box<Foo>) -> uint {\n+//!         x.f + x.g\n+//!     }\n+//!     fn weird() {\n+//!         let mut x: Box<Foo> = box Foo { ... };\n+//!         'a: add(&mut (*x).f, consume(x)) // (..)\n+//!     }\n+//!\n+//! In this case, the second argument to `add` actually consumes `x`, thus\n+//! invalidating the first argument.\n+//!\n+//! So, for now, we exclude the `call` lifetimes from our model.\n+//! Eventually I would like to include them, but we will have to make the\n+//! borrow checker handle this situation correctly. In particular, if\n+//! there is a reference created whose lifetime does not enclose\n+//! the borrow expression, we must issue sufficient restrictions to ensure\n+//! that the pointee remains valid.\n+//!\n+//! ## Adding closures\n+//!\n+//! The other significant complication to the region hierarchy is\n+//! closures. I will describe here how closures should work, though some\n+//! of the work to implement this model is ongoing at the time of this\n+//! writing.\n+//!\n+//! The body of closures are type-checked along with the function that\n+//! creates them. However, unlike other expressions that appear within the\n+//! function body, it is not entirely obvious when a closure body executes\n+//! with respect to the other expressions. This is because the closure\n+//! body will execute whenever the closure is called; however, we can\n+//! never know precisely when the closure will be called, especially\n+//! without some sort of alias analysis.\n+//!\n+//! However, we can place some sort of limits on when the closure\n+//! executes.  In particular, the type of every closure `fn:'r K` includes\n+//! a region bound `'r`. This bound indicates the maximum lifetime of that\n+//! closure; once we exit that region, the closure cannot be called\n+//! anymore. Therefore, we say that the lifetime of the closure body is a\n+//! sublifetime of the closure bound, but the closure body itself is unordered\n+//! with respect to other parts of the code.\n+//!\n+//! For example, consider the following fragment of code:\n+//!\n+//!     'a: {\n+//!          let closure: fn:'a() = || 'b: {\n+//!              'c: ...\n+//!          };\n+//!          'd: ...\n+//!     }\n+//!\n+//! Here we have four lifetimes, `'a`, `'b`, `'c`, and `'d`. The closure\n+//! `closure` is bounded by the lifetime `'a`. The lifetime `'b` is the\n+//! lifetime of the closure body, and `'c` is some statement within the\n+//! closure body. Finally, `'d` is a statement within the outer block that\n+//! created the closure.\n+//!\n+//! We can say that the closure body `'b` is a sublifetime of `'a` due to\n+//! the closure bound. By the usual lexical scoping conventions, the\n+//! statement `'c` is clearly a sublifetime of `'b`, and `'d` is a\n+//! sublifetime of `'d`. However, there is no ordering between `'c` and\n+//! `'d` per se (this kind of ordering between statements is actually only\n+//! an issue for dataflow; passes like the borrow checker must assume that\n+//! closures could execute at any time from the moment they are created\n+//! until they go out of scope).\n+//!\n+//! ### Complications due to closure bound inference\n+//!\n+//! There is only one problem with the above model: in general, we do not\n+//! actually *know* the closure bounds during region inference! In fact,\n+//! closure bounds are almost always region variables! This is very tricky\n+//! because the inference system implicitly assumes that we can do things\n+//! like compute the LUB of two scoped lifetimes without needing to know\n+//! the values of any variables.\n+//!\n+//! Here is an example to illustrate the problem:\n+//!\n+//!     fn identify<T>(x: T) -> T { x }\n+//!\n+//!     fn foo() { // 'foo is the function body\n+//!       'a: {\n+//!            let closure = identity(|| 'b: {\n+//!                'c: ...\n+//!            });\n+//!            'd: closure();\n+//!       }\n+//!       'e: ...;\n+//!     }\n+//!\n+//! In this example, the closure bound is not explicit. At compile time,\n+//! we will create a region variable (let's call it `V0`) to represent the\n+//! closure bound.\n+//!\n+//! The primary difficulty arises during the constraint propagation phase.\n+//! Imagine there is some variable with incoming edges from `'c` and `'d`.\n+//! This means that the value of the variable must be `LUB('c,\n+//! 'd)`. However, without knowing what the closure bound `V0` is, we\n+//! can't compute the LUB of `'c` and `'d`! Any we don't know the closure\n+//! bound until inference is done.\n+//!\n+//! The solution is to rely on the fixed point nature of inference.\n+//! Basically, when we must compute `LUB('c, 'd)`, we just use the current\n+//! value for `V0` as the closure's bound. If `V0`'s binding should\n+//! change, then we will do another round of inference, and the result of\n+//! `LUB('c, 'd)` will change.\n+//!\n+//! One minor implication of this is that the graph does not in fact track\n+//! the full set of dependencies between edges. We cannot easily know\n+//! whether the result of a LUB computation will change, since there may\n+//! be indirect dependencies on other variables that are not reflected on\n+//! the graph. Therefore, we must *always* iterate over all edges when\n+//! doing the fixed point calculation, not just those adjacent to nodes\n+//! whose values have changed.\n+//!\n+//! Were it not for this requirement, we could in fact avoid fixed-point\n+//! iteration altogether. In that universe, we could instead first\n+//! identify and remove strongly connected components (SCC) in the graph.\n+//! Note that such components must consist solely of region variables; all\n+//! of these variables can effectively be unified into a single variable.\n+//! Once SCCs are removed, we are left with a DAG.  At this point, we\n+//! could walk the DAG in topological order once to compute the expanding\n+//! nodes, and again in reverse topological order to compute the\n+//! contracting nodes. However, as I said, this does not work given the\n+//! current treatment of closure bounds, but perhaps in the future we can\n+//! address this problem somehow and make region inference somewhat more\n+//! efficient. Note that this is solely a matter of performance, not\n+//! expressiveness.\n+//!\n+//! ### Skolemization\n+//!\n+//! For a discussion on skolemization and higher-ranked subtyping, please\n+//! see the module `middle::typeck::infer::higher_ranked::doc`."}, {"sha": "e39fbe105dcfc2af0ace5a985b25f6a621ede44d", "filename": "src/librustc/middle/typeck/infer/region_inference/mod.rs", "status": "modified", "additions": 14, "deletions": 28, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fregion_inference%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*! See doc.rs */\n+//! See doc.rs\n \n pub use self::Constraint::*;\n pub use self::Verify::*;\n@@ -597,15 +597,10 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n             .collect()\n     }\n \n+    /// Computes all regions that have been related to `r0` in any way since the mark `mark` was\n+    /// made---`r0` itself will be the first entry. This is used when checking whether skolemized\n+    /// regions are being improperly related to other regions.\n     pub fn tainted(&self, mark: RegionMark, r0: Region) -> Vec<Region> {\n-        /*!\n-         * Computes all regions that have been related to `r0` in any\n-         * way since the mark `mark` was made---`r0` itself will be\n-         * the first entry. This is used when checking whether\n-         * skolemized regions are being improperly related to other\n-         * regions.\n-         */\n-\n         debug!(\"tainted(mark={}, r0={})\", mark, r0.repr(self.tcx));\n         let _indenter = indenter();\n \n@@ -694,13 +689,11 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n         }\n     }\n \n-    /**\n-    This function performs the actual region resolution.  It must be\n-    called after all constraints have been added.  It performs a\n-    fixed-point iteration to find region values which satisfy all\n-    constraints, assuming such values can be found; if they cannot,\n-    errors are reported.\n-    */\n+    /// This function performs the actual region resolution.  It must be\n+    /// called after all constraints have been added.  It performs a\n+    /// fixed-point iteration to find region values which satisfy all\n+    /// constraints, assuming such values can be found; if they cannot,\n+    /// errors are reported.\n     pub fn resolve_regions(&self) -> Vec<RegionResolutionError<'tcx>> {\n         debug!(\"RegionVarBindings: resolve_regions()\");\n         let mut errors = vec!();\n@@ -783,16 +776,12 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n         }\n     }\n \n+    /// Computes a region that encloses both free region arguments. Guarantee that if the same two\n+    /// regions are given as argument, in any order, a consistent result is returned.\n     fn lub_free_regions(&self,\n                         a: &FreeRegion,\n                         b: &FreeRegion) -> ty::Region\n     {\n-        /*!\n-         * Computes a region that encloses both free region arguments.\n-         * Guarantee that if the same two regions are given as argument,\n-         * in any order, a consistent result is returned.\n-         */\n-\n         return match a.cmp(b) {\n             Less => helper(self, a, b),\n             Greater => helper(self, b, a),\n@@ -884,16 +873,13 @@ impl<'a, 'tcx> RegionVarBindings<'a, 'tcx> {\n         }\n     }\n \n+    /// Computes a region that is enclosed by both free region arguments, if any. Guarantees that\n+    /// if the same two regions are given as argument, in any order, a consistent result is\n+    /// returned.\n     fn glb_free_regions(&self,\n                         a: &FreeRegion,\n                         b: &FreeRegion) -> cres<'tcx, ty::Region>\n     {\n-        /*!\n-         * Computes a region that is enclosed by both free region arguments,\n-         * if any. Guarantees that if the same two regions are given as argument,\n-         * in any order, a consistent result is returned.\n-         */\n-\n         return match a.cmp(b) {\n             Less => helper(self, a, b),\n             Greater => helper(self, b, a),"}, {"sha": "62bf1d0126a59d156442f1260ecd98b47d21dae2", "filename": "src/librustc/middle/typeck/infer/skolemize.rs", "status": "modified", "additions": 21, "deletions": 31, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fskolemize.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fskolemize.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Fskolemize.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,37 +8,27 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Skolemization is the process of replacing unknown variables with\n- * fresh types. The idea is that the type, after skolemization,\n- * contains no inference variables but instead contains either a value\n- * for each variable or fresh \"arbitrary\" types wherever a variable\n- * would have been.\n- *\n- * Skolemization is used primarily to get a good type for inserting\n- * into a cache. The result summarizes what the type inferencer knows\n- * \"so far\". The primary place it is used right now is in the trait\n- * matching algorithm, which needs to be able to cache whether an\n- * `impl` self type matches some other type X -- *without* affecting\n- * `X`. That means if that if the type `X` is in fact an unbound type\n- * variable, we want the match to be regarded as ambiguous, because\n- * depending on what type that type variable is ultimately assigned,\n- * the match may or may not succeed.\n- *\n- * Note that you should be careful not to allow the output of\n- * skolemization to leak to the user in error messages or in any other\n- * form. Skolemization is only really useful as an internal detail.\n- *\n- * __An important detail concerning regions.__ The skolemizer also\n- * replaces *all* regions with 'static. The reason behind this is\n- * that, in general, we do not take region relationships into account\n- * when making type-overloaded decisions. This is important because of\n- * the design of the region inferencer, which is not based on\n- * unification but rather on accumulating and then solving a set of\n- * constraints. In contrast, the type inferencer assigns a value to\n- * each type variable only once, and it does so as soon as it can, so\n- * it is reasonable to ask what the type inferencer knows \"so far\".\n- */\n+//! Skolemization is the process of replacing unknown variables with fresh types. The idea is that\n+//! the type, after skolemization, contains no inference variables but instead contains either a\n+//! value for each variable or fresh \"arbitrary\" types wherever a variable would have been.\n+//!\n+//! Skolemization is used primarily to get a good type for inserting into a cache. The result\n+//! summarizes what the type inferencer knows \"so far\". The primary place it is used right now is\n+//! in the trait matching algorithm, which needs to be able to cache whether an `impl` self type\n+//! matches some other type X -- *without* affecting `X`. That means if that if the type `X` is in\n+//! fact an unbound type variable, we want the match to be regarded as ambiguous, because depending\n+//! on what type that type variable is ultimately assigned, the match may or may not succeed.\n+//!\n+//! Note that you should be careful not to allow the output of skolemization to leak to the user in\n+//! error messages or in any other form. Skolemization is only really useful as an internal detail.\n+//!\n+//! __An important detail concerning regions.__ The skolemizer also replaces *all* regions with\n+//! 'static. The reason behind this is that, in general, we do not take region relationships into\n+//! account when making type-overloaded decisions. This is important because of the design of the\n+//! region inferencer, which is not based on unification but rather on accumulating and then\n+//! solving a set of constraints. In contrast, the type inferencer assigns a value to each type\n+//! variable only once, and it does so as soon as it can, so it is reasonable to ask what the type\n+//! inferencer knows \"so far\".\n \n use middle::ty::{mod, Ty};\n use middle::ty_fold;"}, {"sha": "3058f09a83a851d5006d846f6f1e3ddbf9aaed6f", "filename": "src/librustc/middle/typeck/infer/type_variable.rs", "status": "modified", "additions": 6, "deletions": 12, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ftype_variable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ftype_variable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Ftype_variable.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -72,12 +72,10 @@ impl<'tcx> TypeVariableTable<'tcx> {\n         self.values.get(vid.index).diverging\n     }\n \n+    /// Records that `a <: b`, `a :> b`, or `a == b`, depending on `dir`.\n+    ///\n+    /// Precondition: neither `a` nor `b` are known.\n     pub fn relate_vars(&mut self, a: ty::TyVid, dir: RelationDir, b: ty::TyVid) {\n-        /*!\n-         * Records that `a <: b`, `a :> b`, or `a == b`, depending on `dir`.\n-         *\n-         * Precondition: neither `a` nor `b` are known.\n-         */\n \n         if a != b {\n             self.relations(a).push((dir, b));\n@@ -86,19 +84,15 @@ impl<'tcx> TypeVariableTable<'tcx> {\n         }\n     }\n \n+    /// Instantiates `vid` with the type `ty` and then pushes an entry onto `stack` for each of the\n+    /// relations of `vid` to other variables. The relations will have the form `(ty, dir, vid1)`\n+    /// where `vid1` is some other variable id.\n     pub fn instantiate_and_push(\n         &mut self,\n         vid: ty::TyVid,\n         ty: Ty<'tcx>,\n         stack: &mut Vec<(Ty<'tcx>, RelationDir, ty::TyVid)>)\n     {\n-        /*!\n-         * Instantiates `vid` with the type `ty` and then pushes an\n-         * entry onto `stack` for each of the relations of `vid` to\n-         * other variables. The relations will have the form `(ty,\n-         * dir, vid1)` where `vid1` is some other variable id.\n-         */\n-\n         let old_value = {\n             let value_ptr = &mut self.values.get_mut(vid.index).value;\n             mem::replace(value_ptr, Known(ty))"}, {"sha": "1b3413bfb010400d6bc9cbb71a4dfbe07ef41216", "filename": "src/librustc/middle/typeck/infer/unify.rs", "status": "modified", "additions": 52, "deletions": 97, "changes": 149, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Funify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Funify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Finfer%2Funify.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -22,85 +22,68 @@ use syntax::ast;\n use util::ppaux::Repr;\n use util::snapshot_vec as sv;\n \n-/**\n- * This trait is implemented by any type that can serve as a type\n- * variable. We call such variables *unification keys*. For example,\n- * this trait is implemented by `IntVid`, which represents integral\n- * variables.\n- *\n- * Each key type has an associated value type `V`. For example, for\n- * `IntVid`, this is `Option<IntVarValue>`, representing some\n- * (possibly not yet known) sort of integer.\n- *\n- * Implementations of this trait are at the end of this file.\n- */\n+/// This trait is implemented by any type that can serve as a type\n+/// variable. We call such variables *unification keys*. For example,\n+/// this trait is implemented by `IntVid`, which represents integral\n+/// variables.\n+///\n+/// Each key type has an associated value type `V`. For example, for\n+/// `IntVid`, this is `Option<IntVarValue>`, representing some\n+/// (possibly not yet known) sort of integer.\n+///\n+/// Implementations of this trait are at the end of this file.\n pub trait UnifyKey<'tcx, V> : Clone + Show + PartialEq + Repr<'tcx> {\n     fn index(&self) -> uint;\n \n     fn from_index(u: uint) -> Self;\n \n-    /**\n-     * Given an inference context, returns the unification table\n-     * appropriate to this key type.\n-     */\n+    // Given an inference context, returns the unification table\n+    // appropriate to this key type.\n     fn unification_table<'v>(infcx: &'v InferCtxt)\n                              -> &'v RefCell<UnificationTable<Self,V>>;\n \n     fn tag(k: Option<Self>) -> &'static str;\n }\n \n-/**\n- * Trait for valid types that a type variable can be set to. Note that\n- * this is typically not the end type that the value will take on, but\n- * rather an `Option` wrapper (where `None` represents a variable\n- * whose value is not yet set).\n- *\n- * Implementations of this trait are at the end of this file.\n- */\n+/// Trait for valid types that a type variable can be set to. Note that\n+/// this is typically not the end type that the value will take on, but\n+/// rather an `Option` wrapper (where `None` represents a variable\n+/// whose value is not yet set).\n+///\n+/// Implementations of this trait are at the end of this file.\n pub trait UnifyValue<'tcx> : Clone + Repr<'tcx> + PartialEq {\n }\n \n-/**\n- * Value of a unification key. We implement Tarjan's union-find\n- * algorithm: when two keys are unified, one of them is converted\n- * into a \"redirect\" pointing at the other. These redirects form a\n- * DAG: the roots of the DAG (nodes that are not redirected) are each\n- * associated with a value of type `V` and a rank. The rank is used\n- * to keep the DAG relatively balanced, which helps keep the running\n- * time of the algorithm under control. For more information, see\n- * <http://en.wikipedia.org/wiki/Disjoint-set_data_structure>.\n- */\n+/// Value of a unification key. We implement Tarjan's union-find\n+/// algorithm: when two keys are unified, one of them is converted\n+/// into a \"redirect\" pointing at the other. These redirects form a\n+/// DAG: the roots of the DAG (nodes that are not redirected) are each\n+/// associated with a value of type `V` and a rank. The rank is used\n+/// to keep the DAG relatively balanced, which helps keep the running\n+/// time of the algorithm under control. For more information, see\n+/// <http://en.wikipedia.org/wiki/Disjoint-set_data_structure>.\n #[deriving(PartialEq,Clone)]\n pub enum VarValue<K,V> {\n     Redirect(K),\n     Root(V, uint),\n }\n \n-/**\n- * Table of unification keys and their values.\n- */\n+/// Table of unification keys and their values.\n pub struct UnificationTable<K,V> {\n-    /**\n-     * Indicates the current value of each key.\n-     */\n-\n+    /// Indicates the current value of each key.\n     values: sv::SnapshotVec<VarValue<K,V>,(),Delegate>,\n }\n \n-/**\n- * At any time, users may snapshot a unification table.  The changes\n- * made during the snapshot may either be *committed* or *rolled back*.\n- */\n+/// At any time, users may snapshot a unification table.  The changes\n+/// made during the snapshot may either be *committed* or *rolled back*.\n pub struct Snapshot<K> {\n     // Link snapshot to the key type `K` of the table.\n     marker: marker::CovariantType<K>,\n     snapshot: sv::Snapshot,\n }\n \n-/**\n- * Internal type used to represent the result of a `get()` operation.\n- * Conveys the current root and value of the key.\n- */\n+/// Internal type used to represent the result of a `get()` operation.\n+/// Conveys the current root and value of the key.\n pub struct Node<K,V> {\n     pub key: K,\n     pub value: V,\n@@ -121,28 +104,22 @@ impl<'tcx, V:PartialEq+Clone+Repr<'tcx>, K:UnifyKey<'tcx, V>> UnificationTable<K\n         }\n     }\n \n-    /**\n-     * Starts a new snapshot. Each snapshot must be either\n-     * rolled back or committed in a \"LIFO\" (stack) order.\n-     */\n+    /// Starts a new snapshot. Each snapshot must be either\n+    /// rolled back or committed in a \"LIFO\" (stack) order.\n     pub fn snapshot(&mut self) -> Snapshot<K> {\n         Snapshot { marker: marker::CovariantType::<K>,\n                    snapshot: self.values.start_snapshot() }\n     }\n \n-    /**\n-     * Reverses all changes since the last snapshot. Also\n-     * removes any keys that have been created since then.\n-     */\n+    /// Reverses all changes since the last snapshot. Also\n+    /// removes any keys that have been created since then.\n     pub fn rollback_to(&mut self, snapshot: Snapshot<K>) {\n         debug!(\"{}: rollback_to()\", UnifyKey::tag(None::<K>));\n         self.values.rollback_to(snapshot.snapshot);\n     }\n \n-    /**\n-     * Commits all changes since the last snapshot. Of course, they\n-     * can still be undone if there is a snapshot further out.\n-     */\n+    /// Commits all changes since the last snapshot. Of course, they\n+    /// can still be undone if there is a snapshot further out.\n     pub fn commit(&mut self, snapshot: Snapshot<K>) {\n         debug!(\"{}: commit()\", UnifyKey::tag(None::<K>));\n         self.values.commit(snapshot.snapshot);\n@@ -157,13 +134,9 @@ impl<'tcx, V:PartialEq+Clone+Repr<'tcx>, K:UnifyKey<'tcx, V>> UnificationTable<K\n         k\n     }\n \n+    /// Find the root node for `vid`. This uses the standard union-find algorithm with path\n+    /// compression: http://en.wikipedia.org/wiki/Disjoint-set_data_structure\n     pub fn get(&mut self, tcx: &ty::ctxt, vid: K) -> Node<K,V> {\n-        /*!\n-         * Find the root node for `vid`. This uses the standard\n-         * union-find algorithm with path compression:\n-         * http://en.wikipedia.org/wiki/Disjoint-set_data_structure\n-         */\n-\n         let index = vid.index();\n         let value = (*self.values.get(index)).clone();\n         match value {\n@@ -188,16 +161,13 @@ impl<'tcx, V:PartialEq+Clone+Repr<'tcx>, K:UnifyKey<'tcx, V>> UnificationTable<K\n         }\n     }\n \n+    /// Sets the value for `vid` to `new_value`. `vid` MUST be a root node! Also, we must be in the\n+    /// middle of a snapshot.\n     pub fn set(&mut self,\n                tcx: &ty::ctxt<'tcx>,\n                key: K,\n                new_value: VarValue<K,V>)\n     {\n-        /*!\n-         * Sets the value for `vid` to `new_value`. `vid` MUST be a\n-         * root node! Also, we must be in the middle of a snapshot.\n-         */\n-\n         assert!(self.is_root(&key));\n \n         debug!(\"Updating variable {} to {}\",\n@@ -207,19 +177,15 @@ impl<'tcx, V:PartialEq+Clone+Repr<'tcx>, K:UnifyKey<'tcx, V>> UnificationTable<K\n         self.values.set(key.index(), new_value);\n     }\n \n+    /// Either redirects node_a to node_b or vice versa, depending on the relative rank. Returns\n+    /// the new root and rank. You should then update the value of the new root to something\n+    /// suitable.\n     pub fn unify(&mut self,\n                  tcx: &ty::ctxt<'tcx>,\n                  node_a: &Node<K,V>,\n                  node_b: &Node<K,V>)\n                  -> (K, uint)\n     {\n-        /*!\n-         * Either redirects node_a to node_b or vice versa, depending\n-         * on the relative rank. Returns the new root and rank.  You\n-         * should then update the value of the new root to something\n-         * suitable.\n-         */\n-\n         debug!(\"unify(node_a(id={}, rank={}), node_b(id={}, rank={}))\",\n                node_a.key.repr(tcx),\n                node_a.rank,\n@@ -255,10 +221,8 @@ impl<K,V> sv::SnapshotVecDelegate<VarValue<K,V>,()> for Delegate {\n // Code to handle simple keys like ints, floats---anything that\n // doesn't have a subtyping relationship we need to worry about.\n \n-/**\n- * Indicates a type that does not have any kind of subtyping\n- * relationship.\n- */\n+/// Indicates a type that does not have any kind of subtyping\n+/// relationship.\n pub trait SimplyUnifiable<'tcx> : Clone + PartialEq + Repr<'tcx> {\n     fn to_type(&self) -> Ty<'tcx>;\n     fn to_type_err(expected_found<Self>) -> ty::type_err<'tcx>;\n@@ -295,19 +259,15 @@ pub trait InferCtxtMethodsForSimplyUnifiableTypes<'tcx, V:SimplyUnifiable<'tcx>,\n impl<'a,'tcx,V:SimplyUnifiable<'tcx>,K:UnifyKey<'tcx, Option<V>>>\n     InferCtxtMethodsForSimplyUnifiableTypes<'tcx, V, K> for InferCtxt<'a, 'tcx>\n {\n+    /// Unifies two simple keys. Because simple keys do not have any subtyping relationships, if\n+    /// both keys have already been associated with a value, then those two values must be the\n+    /// same.\n     fn simple_vars(&self,\n                    a_is_expected: bool,\n                    a_id: K,\n                    b_id: K)\n                    -> ures<'tcx>\n     {\n-        /*!\n-         * Unifies two simple keys.  Because simple keys do\n-         * not have any subtyping relationships, if both keys\n-         * have already been associated with a value, then those two\n-         * values must be the same.\n-         */\n-\n         let tcx = self.tcx;\n         let table = UnifyKey::unification_table(self);\n         let node_a = table.borrow_mut().get(tcx, a_id);\n@@ -341,19 +301,14 @@ impl<'a,'tcx,V:SimplyUnifiable<'tcx>,K:UnifyKey<'tcx, Option<V>>>\n         return Ok(())\n     }\n \n+    /// Sets the value of the key `a_id` to `b`. Because simple keys do not have any subtyping\n+    /// relationships, if `a_id` already has a value, it must be the same as `b`.\n     fn simple_var_t(&self,\n                     a_is_expected: bool,\n                     a_id: K,\n                     b: V)\n                     -> ures<'tcx>\n     {\n-        /*!\n-         * Sets the value of the key `a_id` to `b`.  Because\n-         * simple keys do not have any subtyping relationships,\n-         * if `a_id` already has a value, it must be the same as\n-         * `b`.\n-         */\n-\n         let tcx = self.tcx;\n         let table = UnifyKey::unification_table(self);\n         let node_a = table.borrow_mut().get(tcx, a_id);"}, {"sha": "501dfcb2e2d9e150f05d84a77a67aefd0848a1a4", "filename": "src/librustc/middle/typeck/mod.rs", "status": "modified", "additions": 12, "deletions": 14, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -150,20 +150,18 @@ pub struct MethodCallee<'tcx> {\n     pub substs: subst::Substs<'tcx>\n }\n \n-/**\n- * With method calls, we store some extra information in\n- * side tables (i.e method_map). We use\n- * MethodCall as a key to index into these tables instead of\n- * just directly using the expression's NodeId. The reason\n- * for this being that we may apply adjustments (coercions)\n- * with the resulting expression also needing to use the\n- * side tables. The problem with this is that we don't\n- * assign a separate NodeId to this new expression\n- * and so it would clash with the base expression if both\n- * needed to add to the side tables. Thus to disambiguate\n- * we also keep track of whether there's an adjustment in\n- * our key.\n- */\n+/// With method calls, we store some extra information in\n+/// side tables (i.e method_map). We use\n+/// MethodCall as a key to index into these tables instead of\n+/// just directly using the expression's NodeId. The reason\n+/// for this being that we may apply adjustments (coercions)\n+/// with the resulting expression also needing to use the\n+/// side tables. The problem with this is that we don't\n+/// assign a separate NodeId to this new expression\n+/// and so it would clash with the base expression if both\n+/// needed to add to the side tables. Thus to disambiguate\n+/// we also keep track of whether there's an adjustment in\n+/// our key.\n #[deriving(Clone, PartialEq, Eq, Hash, Show)]\n pub struct MethodCall {\n     pub expr_id: ast::NodeId,"}, {"sha": "3bca24f479f704d487eae5cab9944d8dd2bd609e", "filename": "src/librustc/middle/typeck/rscope.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Frscope.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Frscope.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Frscope.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -139,11 +139,11 @@ impl RegionScope for BindingRscope {\n /// A scope which simply shifts the Debruijn index of other scopes\n /// to account for binding levels.\n pub struct ShiftedRscope<'r> {\n-    base_scope: &'r RegionScope+'r\n+    base_scope: &'r (RegionScope+'r)\n }\n \n impl<'r> ShiftedRscope<'r> {\n-    pub fn new(base_scope: &'r RegionScope+'r) -> ShiftedRscope<'r> {\n+    pub fn new(base_scope: &'r (RegionScope+'r)) -> ShiftedRscope<'r> {\n         ShiftedRscope { base_scope: base_scope }\n     }\n }"}, {"sha": "ade3144ce414e8485f44a84d42179d2094aa280e", "filename": "src/librustc/middle/typeck/variance.rs", "status": "modified", "additions": 203, "deletions": 219, "changes": 422, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fvariance.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fvariance.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftypeck%2Fvariance.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,189 +8,186 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-This file infers the variance of type and lifetime parameters. The\n-algorithm is taken from Section 4 of the paper \"Taming the Wildcards:\n-Combining Definition- and Use-Site Variance\" published in PLDI'11 and\n-written by Altidor et al., and hereafter referred to as The Paper.\n-\n-This inference is explicitly designed *not* to consider the uses of\n-types within code. To determine the variance of type parameters\n-defined on type `X`, we only consider the definition of the type `X`\n-and the definitions of any types it references.\n-\n-We only infer variance for type parameters found on *types*: structs,\n-enums, and traits. We do not infer variance for type parameters found\n-on fns or impls. This is because those things are not type definitions\n-and variance doesn't really make sense in that context.\n-\n-It is worth covering what variance means in each case. For structs and\n-enums, I think it is fairly straightforward. The variance of the type\n-or lifetime parameters defines whether `T<A>` is a subtype of `T<B>`\n-(resp. `T<'a>` and `T<'b>`) based on the relationship of `A` and `B`\n-(resp. `'a` and `'b`). (FIXME #3598 -- we do not currently make use of\n-the variances we compute for type parameters.)\n-\n-### Variance on traits\n-\n-The meaning of variance for trait parameters is more subtle and worth\n-expanding upon. There are in fact two uses of the variance values we\n-compute.\n-\n-#### Trait variance and object types\n-\n-The first is for object types. Just as with structs and enums, we can\n-decide the subtyping relationship between two object types `&Trait<A>`\n-and `&Trait<B>` based on the relationship of `A` and `B`. Note that\n-for object types we ignore the `Self` type parameter -- it is unknown,\n-and the nature of dynamic dispatch ensures that we will always call a\n-function that is expected the appropriate `Self` type. However, we\n-must be careful with the other type parameters, or else we could end\n-up calling a function that is expecting one type but provided another.\n-\n-To see what I mean, consider a trait like so:\n-\n-    trait ConvertTo<A> {\n-        fn convertTo(&self) -> A;\n-    }\n-\n-Intuitively, If we had one object `O=&ConvertTo<Object>` and another\n-`S=&ConvertTo<String>`, then `S <: O` because `String <: Object`\n-(presuming Java-like \"string\" and \"object\" types, my go to examples\n-for subtyping). The actual algorithm would be to compare the\n-(explicit) type parameters pairwise respecting their variance: here,\n-the type parameter A is covariant (it appears only in a return\n-position), and hence we require that `String <: Object`.\n-\n-You'll note though that we did not consider the binding for the\n-(implicit) `Self` type parameter: in fact, it is unknown, so that's\n-good. The reason we can ignore that parameter is precisely because we\n-don't need to know its value until a call occurs, and at that time (as\n-you said) the dynamic nature of virtual dispatch means the code we run\n-will be correct for whatever value `Self` happens to be bound to for\n-the particular object whose method we called. `Self` is thus different\n-from `A`, because the caller requires that `A` be known in order to\n-know the return type of the method `convertTo()`. (As an aside, we\n-have rules preventing methods where `Self` appears outside of the\n-receiver position from being called via an object.)\n-\n-#### Trait variance and vtable resolution\n-\n-But traits aren't only used with objects. They're also used when\n-deciding whether a given impl satisfies a given trait bound. To set the\n-scene here, imagine I had a function:\n-\n-    fn convertAll<A,T:ConvertTo<A>>(v: &[T]) {\n-        ...\n-    }\n-\n-Now imagine that I have an implementation of `ConvertTo` for `Object`:\n-\n-    impl ConvertTo<int> for Object { ... }\n-\n-And I want to call `convertAll` on an array of strings. Suppose\n-further that for whatever reason I specifically supply the value of\n-`String` for the type parameter `T`:\n-\n-    let mut vector = ~[\"string\", ...];\n-    convertAll::<int, String>(v);\n-\n-Is this legal? To put another way, can we apply the `impl` for\n-`Object` to the type `String`? The answer is yes, but to see why\n-we have to expand out what will happen:\n-\n-- `convertAll` will create a pointer to one of the entries in the\n-  vector, which will have type `&String`\n-- It will then call the impl of `convertTo()` that is intended\n-  for use with objects. This has the type:\n-\n-      fn(self: &Object) -> int\n-\n-  It is ok to provide a value for `self` of type `&String` because\n-  `&String <: &Object`.\n-\n-OK, so intuitively we want this to be legal, so let's bring this back\n-to variance and see whether we are computing the correct result. We\n-must first figure out how to phrase the question \"is an impl for\n-`Object,int` usable where an impl for `String,int` is expected?\"\n-\n-Maybe it's helpful to think of a dictionary-passing implementation of\n-type classes. In that case, `convertAll()` takes an implicit parameter\n-representing the impl. In short, we *have* an impl of type:\n-\n-    V_O = ConvertTo<int> for Object\n-\n-and the function prototype expects an impl of type:\n-\n-    V_S = ConvertTo<int> for String\n-\n-As with any argument, this is legal if the type of the value given\n-(`V_O`) is a subtype of the type expected (`V_S`). So is `V_O <: V_S`?\n-The answer will depend on the variance of the various parameters. In\n-this case, because the `Self` parameter is contravariant and `A` is\n-covariant, it means that:\n-\n-    V_O <: V_S iff\n-        int <: int\n-        String <: Object\n-\n-These conditions are satisfied and so we are happy.\n+//! This file infers the variance of type and lifetime parameters. The\n+//! algorithm is taken from Section 4 of the paper \"Taming the Wildcards:\n+//! Combining Definition- and Use-Site Variance\" published in PLDI'11 and\n+//! written by Altidor et al., and hereafter referred to as The Paper.\n+//!\n+//! This inference is explicitly designed *not* to consider the uses of\n+//! types within code. To determine the variance of type parameters\n+//! defined on type `X`, we only consider the definition of the type `X`\n+//! and the definitions of any types it references.\n+//!\n+//! We only infer variance for type parameters found on *types*: structs,\n+//! enums, and traits. We do not infer variance for type parameters found\n+//! on fns or impls. This is because those things are not type definitions\n+//! and variance doesn't really make sense in that context.\n+//!\n+//! It is worth covering what variance means in each case. For structs and\n+//! enums, I think it is fairly straightforward. The variance of the type\n+//! or lifetime parameters defines whether `T<A>` is a subtype of `T<B>`\n+//! (resp. `T<'a>` and `T<'b>`) based on the relationship of `A` and `B`\n+//! (resp. `'a` and `'b`). (FIXME #3598 -- we do not currently make use of\n+//! the variances we compute for type parameters.)\n+//!\n+//! ### Variance on traits\n+//!\n+//! The meaning of variance for trait parameters is more subtle and worth\n+//! expanding upon. There are in fact two uses of the variance values we\n+//! compute.\n+//!\n+//! #### Trait variance and object types\n+//!\n+//! The first is for object types. Just as with structs and enums, we can\n+//! decide the subtyping relationship between two object types `&Trait<A>`\n+//! and `&Trait<B>` based on the relationship of `A` and `B`. Note that\n+//! for object types we ignore the `Self` type parameter -- it is unknown,\n+//! and the nature of dynamic dispatch ensures that we will always call a\n+//! function that is expected the appropriate `Self` type. However, we\n+//! must be careful with the other type parameters, or else we could end\n+//! up calling a function that is expecting one type but provided another.\n+//!\n+//! To see what I mean, consider a trait like so:\n+//!\n+//!     trait ConvertTo<A> {\n+//!         fn convertTo(&self) -> A;\n+//!     }\n+//!\n+//! Intuitively, If we had one object `O=&ConvertTo<Object>` and another\n+//! `S=&ConvertTo<String>`, then `S <: O` because `String <: Object`\n+//! (presuming Java-like \"string\" and \"object\" types, my go to examples\n+//! for subtyping). The actual algorithm would be to compare the\n+//! (explicit) type parameters pairwise respecting their variance: here,\n+//! the type parameter A is covariant (it appears only in a return\n+//! position), and hence we require that `String <: Object`.\n+//!\n+//! You'll note though that we did not consider the binding for the\n+//! (implicit) `Self` type parameter: in fact, it is unknown, so that's\n+//! good. The reason we can ignore that parameter is precisely because we\n+//! don't need to know its value until a call occurs, and at that time (as\n+//! you said) the dynamic nature of virtual dispatch means the code we run\n+//! will be correct for whatever value `Self` happens to be bound to for\n+//! the particular object whose method we called. `Self` is thus different\n+//! from `A`, because the caller requires that `A` be known in order to\n+//! know the return type of the method `convertTo()`. (As an aside, we\n+//! have rules preventing methods where `Self` appears outside of the\n+//! receiver position from being called via an object.)\n+//!\n+//! #### Trait variance and vtable resolution\n+//!\n+//! But traits aren't only used with objects. They're also used when\n+//! deciding whether a given impl satisfies a given trait bound. To set the\n+//! scene here, imagine I had a function:\n+//!\n+//!     fn convertAll<A,T:ConvertTo<A>>(v: &[T]) {\n+//!         ...\n+//!     }\n+//!\n+//! Now imagine that I have an implementation of `ConvertTo` for `Object`:\n+//!\n+//!     impl ConvertTo<int> for Object { ... }\n+//!\n+//! And I want to call `convertAll` on an array of strings. Suppose\n+//! further that for whatever reason I specifically supply the value of\n+//! `String` for the type parameter `T`:\n+//!\n+//!     let mut vector = ~[\"string\", ...];\n+//!     convertAll::<int, String>(v);\n+//!\n+//! Is this legal? To put another way, can we apply the `impl` for\n+//! `Object` to the type `String`? The answer is yes, but to see why\n+//! we have to expand out what will happen:\n+//!\n+//! - `convertAll` will create a pointer to one of the entries in the\n+//!   vector, which will have type `&String`\n+//! - It will then call the impl of `convertTo()` that is intended\n+//!   for use with objects. This has the type:\n+//!\n+//!       fn(self: &Object) -> int\n+//!\n+//!   It is ok to provide a value for `self` of type `&String` because\n+//!   `&String <: &Object`.\n+//!\n+//! OK, so intuitively we want this to be legal, so let's bring this back\n+//! to variance and see whether we are computing the correct result. We\n+//! must first figure out how to phrase the question \"is an impl for\n+//! `Object,int` usable where an impl for `String,int` is expected?\"\n+//!\n+//! Maybe it's helpful to think of a dictionary-passing implementation of\n+//! type classes. In that case, `convertAll()` takes an implicit parameter\n+//! representing the impl. In short, we *have* an impl of type:\n+//!\n+//!     V_O = ConvertTo<int> for Object\n+//!\n+//! and the function prototype expects an impl of type:\n+//!\n+//!     V_S = ConvertTo<int> for String\n+//!\n+//! As with any argument, this is legal if the type of the value given\n+//! (`V_O`) is a subtype of the type expected (`V_S`). So is `V_O <: V_S`?\n+//! The answer will depend on the variance of the various parameters. In\n+//! this case, because the `Self` parameter is contravariant and `A` is\n+//! covariant, it means that:\n+//!\n+//!     V_O <: V_S iff\n+//!         int <: int\n+//!         String <: Object\n+//!\n+//! These conditions are satisfied and so we are happy.\n+//!\n+//! ### The algorithm\n+//!\n+//! The basic idea is quite straightforward. We iterate over the types\n+//! defined and, for each use of a type parameter X, accumulate a\n+//! constraint indicating that the variance of X must be valid for the\n+//! variance of that use site. We then iteratively refine the variance of\n+//! X until all constraints are met. There is *always* a sol'n, because at\n+//! the limit we can declare all type parameters to be invariant and all\n+//! constraints will be satisfied.\n+//!\n+//! As a simple example, consider:\n+//!\n+//!     enum Option<A> { Some(A), None }\n+//!     enum OptionalFn<B> { Some(|B|), None }\n+//!     enum OptionalMap<C> { Some(|C| -> C), None }\n+//!\n+//! Here, we will generate the constraints:\n+//!\n+//!     1. V(A) <= +\n+//!     2. V(B) <= -\n+//!     3. V(C) <= +\n+//!     4. V(C) <= -\n+//!\n+//! These indicate that (1) the variance of A must be at most covariant;\n+//! (2) the variance of B must be at most contravariant; and (3, 4) the\n+//! variance of C must be at most covariant *and* contravariant. All of these\n+//! results are based on a variance lattice defined as follows:\n+//!\n+//!       *      Top (bivariant)\n+//!    -     +\n+//!       o      Bottom (invariant)\n+//!\n+//! Based on this lattice, the solution V(A)=+, V(B)=-, V(C)=o is the\n+//! optimal solution. Note that there is always a naive solution which\n+//! just declares all variables to be invariant.\n+//!\n+//! You may be wondering why fixed-point iteration is required. The reason\n+//! is that the variance of a use site may itself be a function of the\n+//! variance of other type parameters. In full generality, our constraints\n+//! take the form:\n+//!\n+//!     V(X) <= Term\n+//!     Term := + | - | * | o | V(X) | Term x Term\n+//!\n+//! Here the notation V(X) indicates the variance of a type/region\n+//! parameter `X` with respect to its defining class. `Term x Term`\n+//! represents the \"variance transform\" as defined in the paper:\n+//!\n+//!   If the variance of a type variable `X` in type expression `E` is `V2`\n+//!   and the definition-site variance of the [corresponding] type parameter\n+//!   of a class `C` is `V1`, then the variance of `X` in the type expression\n+//!   `C<E>` is `V3 = V1.xform(V2)`.\n \n-### The algorithm\n-\n-The basic idea is quite straightforward. We iterate over the types\n-defined and, for each use of a type parameter X, accumulate a\n-constraint indicating that the variance of X must be valid for the\n-variance of that use site. We then iteratively refine the variance of\n-X until all constraints are met. There is *always* a sol'n, because at\n-the limit we can declare all type parameters to be invariant and all\n-constraints will be satisfied.\n-\n-As a simple example, consider:\n-\n-    enum Option<A> { Some(A), None }\n-    enum OptionalFn<B> { Some(|B|), None }\n-    enum OptionalMap<C> { Some(|C| -> C), None }\n-\n-Here, we will generate the constraints:\n-\n-    1. V(A) <= +\n-    2. V(B) <= -\n-    3. V(C) <= +\n-    4. V(C) <= -\n-\n-These indicate that (1) the variance of A must be at most covariant;\n-(2) the variance of B must be at most contravariant; and (3, 4) the\n-variance of C must be at most covariant *and* contravariant. All of these\n-results are based on a variance lattice defined as follows:\n-\n-      *      Top (bivariant)\n-   -     +\n-      o      Bottom (invariant)\n-\n-Based on this lattice, the solution V(A)=+, V(B)=-, V(C)=o is the\n-optimal solution. Note that there is always a naive solution which\n-just declares all variables to be invariant.\n-\n-You may be wondering why fixed-point iteration is required. The reason\n-is that the variance of a use site may itself be a function of the\n-variance of other type parameters. In full generality, our constraints\n-take the form:\n-\n-    V(X) <= Term\n-    Term := + | - | * | o | V(X) | Term x Term\n-\n-Here the notation V(X) indicates the variance of a type/region\n-parameter `X` with respect to its defining class. `Term x Term`\n-represents the \"variance transform\" as defined in the paper:\n-\n-  If the variance of a type variable `X` in type expression `E` is `V2`\n-  and the definition-site variance of the [corresponding] type parameter\n-  of a class `C` is `V1`, then the variance of `X` in the type expression\n-  `C<E>` is `V3 = V1.xform(V2)`.\n-\n-*/\n use self::VarianceTerm::*;\n use self::ParamKind::*;\n \n@@ -219,18 +216,16 @@ pub fn infer_variance(tcx: &ty::ctxt) {\n     tcx.variance_computed.set(true);\n }\n \n-/**************************************************************************\n- * Representing terms\n- *\n- * Terms are structured as a straightforward tree. Rather than rely on\n- * GC, we allocate terms out of a bounded arena (the lifetime of this\n- * arena is the lifetime 'a that is threaded around).\n- *\n- * We assign a unique index to each type/region parameter whose variance\n- * is to be inferred. We refer to such variables as \"inferreds\". An\n- * `InferredIndex` is a newtype'd int representing the index of such\n- * a variable.\n- */\n+// Representing terms\n+//\n+// Terms are structured as a straightforward tree. Rather than rely on\n+// GC, we allocate terms out of a bounded arena (the lifetime of this\n+// arena is the lifetime 'a that is threaded around).\n+//\n+// We assign a unique index to each type/region parameter whose variance\n+// is to be inferred. We refer to such variables as \"inferreds\". An\n+// `InferredIndex` is a newtype'd int representing the index of such\n+// a variable.\n \n type VarianceTermPtr<'a> = &'a VarianceTerm<'a>;\n \n@@ -253,9 +248,7 @@ impl<'a> fmt::Show for VarianceTerm<'a> {\n     }\n }\n \n-/**************************************************************************\n- * The first pass over the crate simply builds up the set of inferreds.\n- */\n+// The first pass over the crate simply builds up the set of inferreds.\n \n struct TermsContext<'a, 'tcx: 'a> {\n     tcx: &'a ty::ctxt<'tcx>,\n@@ -399,12 +392,10 @@ impl<'a, 'tcx, 'v> Visitor<'v> for TermsContext<'a, 'tcx> {\n     }\n }\n \n-/**************************************************************************\n- * Constraint construction and representation\n- *\n- * The second pass over the AST determines the set of constraints.\n- * We walk the set of items and, for each member, generate new constraints.\n- */\n+// Constraint construction and representation\n+//\n+// The second pass over the AST determines the set of constraints.\n+// We walk the set of items and, for each member, generate new constraints.\n \n struct ConstraintContext<'a, 'tcx: 'a> {\n     terms_cx: TermsContext<'a, 'tcx>,\n@@ -632,18 +623,15 @@ impl<'a, 'tcx> ConstraintContext<'a, 'tcx> {\n         return result;\n     }\n \n+    /// Returns a variance term representing the declared variance of the type/region parameter\n+    /// with the given id.\n     fn declared_variance(&self,\n                          param_def_id: ast::DefId,\n                          item_def_id: ast::DefId,\n                          kind: ParamKind,\n                          space: ParamSpace,\n                          index: uint)\n                          -> VarianceTermPtr<'a> {\n-        /*!\n-         * Returns a variance term representing the declared variance of\n-         * the type/region parameter with the given id.\n-         */\n-\n         assert_eq!(param_def_id.krate, item_def_id.krate);\n \n         if self.invariant_lang_items[kind as uint] == Some(item_def_id) {\n@@ -944,14 +932,12 @@ impl<'a, 'tcx> ConstraintContext<'a, 'tcx> {\n     }\n }\n \n-/**************************************************************************\n- * Constraint solving\n- *\n- * The final phase iterates over the constraints, refining the variance\n- * for each inferred until a fixed point is reached. This will be the\n- * optimal solution to the constraints. The final variance for each\n- * inferred is then written into the `variance_map` in the tcx.\n- */\n+// Constraint solving\n+//\n+// The final phase iterates over the constraints, refining the variance\n+// for each inferred until a fixed point is reached. This will be the\n+// optimal solution to the constraints. The final variance for each\n+// inferred is then written into the `variance_map` in the tcx.\n \n struct SolveContext<'a, 'tcx: 'a> {\n     terms_cx: TermsContext<'a, 'tcx>,\n@@ -1086,9 +1072,7 @@ impl<'a, 'tcx> SolveContext<'a, 'tcx> {\n     }\n }\n \n-/**************************************************************************\n- * Miscellany transformations on variance\n- */\n+// Miscellany transformations on variance\n \n trait Xform {\n     fn xform(self, v: Self) -> Self;"}, {"sha": "8dd60880cdd56022773879ed502dcce3bc4ed8f7", "filename": "src/librustc/plugin/mod.rs", "status": "modified", "additions": 46, "deletions": 48, "changes": 94, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fplugin%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Fplugin%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fplugin%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,54 +8,52 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Infrastructure for compiler plugins.\n- *\n- * Plugins are Rust libraries which extend the behavior of `rustc`\n- * in various ways.\n- *\n- * Plugin authors will use the `Registry` type re-exported by\n- * this module, along with its methods.  The rest of the module\n- * is for use by `rustc` itself.\n- *\n- * To define a plugin, build a dylib crate with a\n- * `#[plugin_registrar]` function:\n- *\n- * ```rust,ignore\n- * #![crate_name = \"myplugin\"]\n- * #![crate_type = \"dylib\"]\n- * #![feature(plugin_registrar)]\n- *\n- * extern crate rustc;\n- *\n- * use rustc::plugin::Registry;\n- *\n- * #[plugin_registrar]\n- * pub fn plugin_registrar(reg: &mut Registry) {\n- *     reg.register_macro(\"mymacro\", expand_mymacro);\n- * }\n- *\n- * fn expand_mymacro(...) {  // details elided\n- * ```\n- *\n- * WARNING: We currently don't check that the registrar function\n- * has the appropriate type!\n- *\n- * To use a plugin while compiling another crate:\n- *\n- * ```rust\n- * #![feature(phase)]\n- *\n- * #[phase(plugin)]\n- * extern crate myplugin;\n- * ```\n- *\n- * If you also need the plugin crate available at runtime, use\n- * `phase(plugin, link)`.\n- *\n- * See [the compiler plugin guide](../../guide-plugin.html)\n- * for more examples.\n- */\n+//! Infrastructure for compiler plugins.\n+//!\n+//! Plugins are Rust libraries which extend the behavior of `rustc`\n+//! in various ways.\n+//!\n+//! Plugin authors will use the `Registry` type re-exported by\n+//! this module, along with its methods.  The rest of the module\n+//! is for use by `rustc` itself.\n+//!\n+//! To define a plugin, build a dylib crate with a\n+//! `#[plugin_registrar]` function:\n+//!\n+//! ```rust,ignore\n+//! #![crate_name = \"myplugin\"]\n+//! #![crate_type = \"dylib\"]\n+//! #![feature(plugin_registrar)]\n+//!\n+//! extern crate rustc;\n+//!\n+//! use rustc::plugin::Registry;\n+//!\n+//! #[plugin_registrar]\n+//! pub fn plugin_registrar(reg: &mut Registry) {\n+//!     reg.register_macro(\"mymacro\", expand_mymacro);\n+//! }\n+//!\n+//! fn expand_mymacro(...) {  // details elided\n+//! ```\n+//!\n+//! WARNING: We currently don't check that the registrar function\n+//! has the appropriate type!\n+//!\n+//! To use a plugin while compiling another crate:\n+//!\n+//! ```rust\n+//! #![feature(phase)]\n+//!\n+//! #[phase(plugin)]\n+//! extern crate myplugin;\n+//! ```\n+//!\n+//! If you also need the plugin crate available at runtime, use\n+//! `phase(plugin, link)`.\n+//!\n+//! See [the compiler plugin guide](../../guide-plugin.html)\n+//! for more examples.\n \n pub use self::registry::Registry;\n "}, {"sha": "ea252d9fd205c99d0abac30fdc05648ee4f9c24f", "filename": "src/librustc/util/common.rs", "status": "modified", "additions": 8, "deletions": 12, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fcommon.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -122,24 +122,20 @@ pub fn block_query(b: &ast::Block, p: |&ast::Expr| -> bool) -> bool {\n     return v.flag;\n }\n \n-// K: Eq + Hash<S>, V, S, H: Hasher<S>\n+/// K: Eq + Hash<S>, V, S, H: Hasher<S>\n+///\n+/// Determines whether there exists a path from `source` to `destination`.  The graph is defined by\n+/// the `edges_map`, which maps from a node `S` to a list of its adjacent nodes `T`.\n+///\n+/// Efficiency note: This is implemented in an inefficient way because it is typically invoked on\n+/// very small graphs. If the graphs become larger, a more efficient graph representation and\n+/// algorithm would probably be advised.\n pub fn can_reach<S,H:Hasher<S>,T:Eq+Clone+Hash<S>>(\n     edges_map: &HashMap<T,Vec<T>,H>,\n     source: T,\n     destination: T)\n     -> bool\n {\n-    /*!\n-     * Determines whether there exists a path from `source` to\n-     * `destination`.  The graph is defined by the `edges_map`, which\n-     * maps from a node `S` to a list of its adjacent nodes `T`.\n-     *\n-     * Efficiency note: This is implemented in an inefficient way\n-     * because it is typically invoked on very small graphs. If the graphs\n-     * become larger, a more efficient graph representation and algorithm\n-     * would probably be advised.\n-     */\n-\n     if source == destination {\n         return true;\n     }"}, {"sha": "b739a97f734bea228db1d3f76fa2f6ca96a43da3", "filename": "src/librustc/util/ppaux.rs", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fppaux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fppaux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fppaux.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -65,12 +65,9 @@ pub fn note_and_explain_region(cx: &ctxt,\n     }\n }\n \n+/// When a free region is associated with `item`, how should we describe the item in the error\n+/// message.\n fn item_scope_tag(item: &ast::Item) -> &'static str {\n-    /*!\n-     * When a free region is associated with `item`, how should we describe\n-     * the item in the error message.\n-     */\n-\n     match item.node {\n         ast::ItemImpl(..) => \"impl\",\n         ast::ItemStruct(..) => \"struct\","}, {"sha": "519cd6b167502f02dc53cdf1e32da89427cf9f6a", "filename": "src/librustc/util/snapshot_vec.rs", "status": "modified", "additions": 17, "deletions": 31, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fsnapshot_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc%2Futil%2Fsnapshot_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Futil%2Fsnapshot_vec.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,21 +8,16 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * A utility class for implementing \"snapshottable\" things; a\n- * snapshottable data structure permits you to take a snapshot (via\n- * `start_snapshot`) and then, after making some changes, elect either\n- * to rollback to the start of the snapshot or commit those changes.\n- *\n- * This vector is intended to be used as part of an abstraction, not\n- * serve as a complete abstraction on its own. As such, while it will\n- * roll back most changes on its own, it also supports a `get_mut`\n- * operation that gives you an abitrary mutable pointer into the\n- * vector. To ensure that any changes you make this with this pointer\n- * are rolled back, you must invoke `record` to record any changes you\n- * make and also supplying a delegate capable of reversing those\n- * changes.\n- */\n+//! A utility class for implementing \"snapshottable\" things; a snapshottable data structure permits\n+//! you to take a snapshot (via `start_snapshot`) and then, after making some changes, elect either\n+//! to rollback to the start of the snapshot or commit those changes.\n+//!\n+//! This vector is intended to be used as part of an abstraction, not serve as a complete\n+//! abstraction on its own. As such, while it will roll back most changes on its own, it also\n+//! supports a `get_mut` operation that gives you an abitrary mutable pointer into the vector. To\n+//! ensure that any changes you make this with this pointer are rolled back, you must invoke\n+//! `record` to record any changes you make and also supplying a delegate capable of reversing\n+//! those changes.\n use self::UndoLog::*;\n \n use std::kinds::marker;\n@@ -98,23 +93,16 @@ impl<T,U,D:SnapshotVecDelegate<T,U>> SnapshotVec<T,U,D> {\n         &self.values[index]\n     }\n \n+    /// Returns a mutable pointer into the vec; whatever changes you make here cannot be undone\n+    /// automatically, so you should be sure call `record()` with some sort of suitable undo\n+    /// action.\n     pub fn get_mut<'a>(&'a mut self, index: uint) -> &'a mut T {\n-        /*!\n-         * Returns a mutable pointer into the vec; whatever changes\n-         * you make here cannot be undone automatically, so you should\n-         * be sure call `record()` with some sort of suitable undo\n-         * action.\n-         */\n-\n         &mut self.values[index]\n     }\n \n+    /// Updates the element at the given index. The old value will saved (and perhaps restored) if\n+    /// a snapshot is active.\n     pub fn set(&mut self, index: uint, new_elem: T) {\n-        /*!\n-         * Updates the element at the given index. The old value will\n-         * saved (and perhaps restored) if a snapshot is active.\n-         */\n-\n         let old_elem = mem::replace(&mut self.values[index], new_elem);\n         if self.in_snapshot() {\n             self.undo_log.push(SetElem(index, old_elem));\n@@ -177,10 +165,8 @@ impl<T,U,D:SnapshotVecDelegate<T,U>> SnapshotVec<T,U,D> {\n         assert!(self.undo_log.len() == snapshot.length);\n     }\n \n-    /**\n-     * Commits all changes since the last snapshot. Of course, they\n-     * can still be undone if there is a snapshot further out.\n-     */\n+    /// Commits all changes since the last snapshot. Of course, they\n+    /// can still be undone if there is a snapshot further out.\n     pub fn commit(&mut self, snapshot: Snapshot) {\n         debug!(\"commit({})\", snapshot.length);\n "}, {"sha": "d7deb09985f78203cb4e3e7ad2fa99d964c7a0f7", "filename": "src/librustc_back/fs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_back%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_back%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_back%2Ffs.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -37,7 +37,7 @@ pub fn realpath(original: &Path) -> io::IoResult<Path> {\n \n             match fs::lstat(&result) {\n                 Err(..) => break,\n-                Ok(ref stat) if stat.kind != io::TypeSymlink => break,\n+                Ok(ref stat) if stat.kind != io::FileType::Symlink => break,\n                 Ok(..) => {\n                     followed += 1;\n                     let path = try!(fs::readlink(&result));"}, {"sha": "eef0ecaae6abaeac38495457e9a63294a15b7720", "filename": "src/librustc_llvm/lib.rs", "status": "modified", "additions": 43, "deletions": 44, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_llvm%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -45,6 +45,7 @@ pub use self::DiagnosticKind::*;\n pub use self::CallConv::*;\n pub use self::Visibility::*;\n pub use self::DiagnosticSeverity::*;\n+pub use self::Linkage::*;\n \n use std::c_str::ToCStr;\n use std::cell::RefCell;\n@@ -520,24 +521,24 @@ extern {\n     pub fn LLVMGetModuleContext(M: ModuleRef) -> ContextRef;\n     pub fn LLVMDisposeModule(M: ModuleRef);\n \n-    /** Data layout. See Module::getDataLayout. */\n+    /// Data layout. See Module::getDataLayout.\n     pub fn LLVMGetDataLayout(M: ModuleRef) -> *const c_char;\n     pub fn LLVMSetDataLayout(M: ModuleRef, Triple: *const c_char);\n \n-    /** Target triple. See Module::getTargetTriple. */\n+    /// Target triple. See Module::getTargetTriple.\n     pub fn LLVMGetTarget(M: ModuleRef) -> *const c_char;\n     pub fn LLVMSetTarget(M: ModuleRef, Triple: *const c_char);\n \n-    /** See Module::dump. */\n+    /// See Module::dump.\n     pub fn LLVMDumpModule(M: ModuleRef);\n \n-    /** See Module::setModuleInlineAsm. */\n+    /// See Module::setModuleInlineAsm.\n     pub fn LLVMSetModuleInlineAsm(M: ModuleRef, Asm: *const c_char);\n \n-    /** See llvm::LLVMTypeKind::getTypeID. */\n+    /// See llvm::LLVMTypeKind::getTypeID.\n     pub fn LLVMGetTypeKind(Ty: TypeRef) -> TypeKind;\n \n-    /** See llvm::LLVMType::getContext. */\n+    /// See llvm::LLVMType::getContext.\n     pub fn LLVMGetTypeContext(Ty: TypeRef) -> ContextRef;\n \n     /* Operations on integer types */\n@@ -1460,30 +1461,29 @@ extern {\n     pub fn LLVMIsATerminatorInst(Inst: ValueRef) -> ValueRef;\n     pub fn LLVMIsAStoreInst(Inst: ValueRef) -> ValueRef;\n \n-    /** Writes a module to the specified path. Returns 0 on success. */\n+    /// Writes a module to the specified path. Returns 0 on success.\n     pub fn LLVMWriteBitcodeToFile(M: ModuleRef, Path: *const c_char) -> c_int;\n \n-    /** Creates target data from a target layout string. */\n+    /// Creates target data from a target layout string.\n     pub fn LLVMCreateTargetData(StringRep: *const c_char) -> TargetDataRef;\n     /// Adds the target data to the given pass manager. The pass manager\n     /// references the target data only weakly.\n     pub fn LLVMAddTargetData(TD: TargetDataRef, PM: PassManagerRef);\n-    /** Number of bytes clobbered when doing a Store to *T. */\n+    /// Number of bytes clobbered when doing a Store to *T.\n     pub fn LLVMStoreSizeOfType(TD: TargetDataRef, Ty: TypeRef)\n                                -> c_ulonglong;\n \n-    /** Number of bytes clobbered when doing a Store to *T. */\n+    /// Number of bytes clobbered when doing a Store to *T.\n     pub fn LLVMSizeOfTypeInBits(TD: TargetDataRef, Ty: TypeRef)\n                                 -> c_ulonglong;\n \n-    /** Distance between successive elements in an array of T.\n-    Includes ABI padding. */\n+    /// Distance between successive elements in an array of T. Includes ABI padding.\n     pub fn LLVMABISizeOfType(TD: TargetDataRef, Ty: TypeRef) -> c_ulonglong;\n \n-    /** Returns the preferred alignment of a type. */\n+    /// Returns the preferred alignment of a type.\n     pub fn LLVMPreferredAlignmentOfType(TD: TargetDataRef, Ty: TypeRef)\n                                         -> c_uint;\n-    /** Returns the minimum alignment of a type. */\n+    /// Returns the minimum alignment of a type.\n     pub fn LLVMABIAlignmentOfType(TD: TargetDataRef, Ty: TypeRef)\n                                   -> c_uint;\n \n@@ -1494,41 +1494,39 @@ extern {\n                                Element: c_uint)\n                                -> c_ulonglong;\n \n-    /**\n-     * Returns the minimum alignment of a type when part of a call frame.\n-     */\n+    /// Returns the minimum alignment of a type when part of a call frame.\n     pub fn LLVMCallFrameAlignmentOfType(TD: TargetDataRef, Ty: TypeRef)\n                                         -> c_uint;\n \n-    /** Disposes target data. */\n+    /// Disposes target data.\n     pub fn LLVMDisposeTargetData(TD: TargetDataRef);\n \n-    /** Creates a pass manager. */\n+    /// Creates a pass manager.\n     pub fn LLVMCreatePassManager() -> PassManagerRef;\n \n-    /** Creates a function-by-function pass manager */\n+    /// Creates a function-by-function pass manager\n     pub fn LLVMCreateFunctionPassManagerForModule(M: ModuleRef)\n                                                   -> PassManagerRef;\n \n-    /** Disposes a pass manager. */\n+    /// Disposes a pass manager.\n     pub fn LLVMDisposePassManager(PM: PassManagerRef);\n \n-    /** Runs a pass manager on a module. */\n+    /// Runs a pass manager on a module.\n     pub fn LLVMRunPassManager(PM: PassManagerRef, M: ModuleRef) -> Bool;\n \n-    /** Runs the function passes on the provided function. */\n+    /// Runs the function passes on the provided function.\n     pub fn LLVMRunFunctionPassManager(FPM: PassManagerRef, F: ValueRef)\n                                       -> Bool;\n \n-    /** Initializes all the function passes scheduled in the manager */\n+    /// Initializes all the function passes scheduled in the manager\n     pub fn LLVMInitializeFunctionPassManager(FPM: PassManagerRef) -> Bool;\n \n-    /** Finalizes all the function passes scheduled in the manager */\n+    /// Finalizes all the function passes scheduled in the manager\n     pub fn LLVMFinalizeFunctionPassManager(FPM: PassManagerRef) -> Bool;\n \n     pub fn LLVMInitializePasses();\n \n-    /** Adds a verification pass. */\n+    /// Adds a verification pass.\n     pub fn LLVMAddVerifierPass(PM: PassManagerRef);\n \n     pub fn LLVMAddGlobalOptimizerPass(PM: PassManagerRef);\n@@ -1598,38 +1596,38 @@ extern {\n         Internalize: Bool,\n         RunInliner: Bool);\n \n-    /** Destroys a memory buffer. */\n+    /// Destroys a memory buffer.\n     pub fn LLVMDisposeMemoryBuffer(MemBuf: MemoryBufferRef);\n \n \n     /* Stuff that's in rustllvm/ because it's not upstream yet. */\n \n-    /** Opens an object file. */\n+    /// Opens an object file.\n     pub fn LLVMCreateObjectFile(MemBuf: MemoryBufferRef) -> ObjectFileRef;\n-    /** Closes an object file. */\n+    /// Closes an object file.\n     pub fn LLVMDisposeObjectFile(ObjFile: ObjectFileRef);\n \n-    /** Enumerates the sections in an object file. */\n+    /// Enumerates the sections in an object file.\n     pub fn LLVMGetSections(ObjFile: ObjectFileRef) -> SectionIteratorRef;\n-    /** Destroys a section iterator. */\n+    /// Destroys a section iterator.\n     pub fn LLVMDisposeSectionIterator(SI: SectionIteratorRef);\n-    /** Returns true if the section iterator is at the end of the section\n-    list: */\n+    /// Returns true if the section iterator is at the end of the section\n+    /// list:\n     pub fn LLVMIsSectionIteratorAtEnd(ObjFile: ObjectFileRef,\n                                       SI: SectionIteratorRef)\n                                       -> Bool;\n-    /** Moves the section iterator to point to the next section. */\n+    /// Moves the section iterator to point to the next section.\n     pub fn LLVMMoveToNextSection(SI: SectionIteratorRef);\n-    /** Returns the current section size. */\n+    /// Returns the current section size.\n     pub fn LLVMGetSectionSize(SI: SectionIteratorRef) -> c_ulonglong;\n-    /** Returns the current section contents as a string buffer. */\n+    /// Returns the current section contents as a string buffer.\n     pub fn LLVMGetSectionContents(SI: SectionIteratorRef) -> *const c_char;\n \n-    /** Reads the given file and returns it as a memory buffer. Use\n-    LLVMDisposeMemoryBuffer() to get rid of it. */\n+    /// Reads the given file and returns it as a memory buffer. Use\n+    /// LLVMDisposeMemoryBuffer() to get rid of it.\n     pub fn LLVMRustCreateMemoryBufferWithContentsOfFile(Path: *const c_char)\n                                                         -> MemoryBufferRef;\n-    /** Borrows the contents of the memory buffer (doesn't copy it) */\n+    /// Borrows the contents of the memory buffer (doesn't copy it)\n     pub fn LLVMCreateMemoryBufferWithMemoryRange(InputData: *const c_char,\n                                                  InputDataLength: size_t,\n                                                  BufferName: *const c_char,\n@@ -1643,8 +1641,7 @@ extern {\n     pub fn LLVMIsMultithreaded() -> Bool;\n     pub fn LLVMStartMultithreaded() -> Bool;\n \n-    /** Returns a string describing the last error caused by an LLVMRust*\n-    call. */\n+    /// Returns a string describing the last error caused by an LLVMRust* call.\n     pub fn LLVMRustGetLastError() -> *const c_char;\n \n     /// Print the pass timings since static dtors aren't picking them up.\n@@ -1662,10 +1659,10 @@ extern {\n                                 Count: c_uint)\n                                 -> ValueRef;\n \n-    /** Enables LLVM debug output. */\n+    /// Enables LLVM debug output.\n     pub fn LLVMSetDebug(Enabled: c_int);\n \n-    /** Prepares inline assembly. */\n+    /// Prepares inline assembly.\n     pub fn LLVMInlineAsm(Ty: TypeRef,\n                          AsmString: *const c_char,\n                          Constraints: *const c_char,\n@@ -2214,4 +2211,6 @@ pub unsafe fn static_link_hack_this_sucks() {\n // parts of LLVM that rustllvm depends on aren't thrown away by the linker.\n // Works to the above fix for #15460 to ensure LLVM dependencies that\n // are only used by rustllvm don't get stripped by the linker.\n-mod llvmdeps;\n+mod llvmdeps {\n+    include!(env!(\"CFG_LLVM_LINKAGE_FILE\"))\n+}"}, {"sha": "a5709a0219ba99cc91a342b4f51dc1020dc8fcdf", "filename": "src/librustc_trans/driver/driver.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -98,10 +98,8 @@ pub fn compile_input(sess: Session,\n     phase_6_link_output(&sess, &trans, &outputs);\n }\n \n-/**\n- * The name used for source code that doesn't originate in a file\n- * (e.g. source from stdin or a string)\n- */\n+/// The name used for source code that doesn't originate in a file\n+/// (e.g. source from stdin or a string)\n pub fn anon_src() -> String {\n     \"<anon>\".to_string()\n }"}, {"sha": "4186f479fcce653e985524237765d325b42dac32", "filename": "src/librustc_trans/lib.rs", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,15 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-The Rust compiler.\n-\n-# Note\n-\n-This API is completely unstable and subject to change.\n-\n-*/\n+//! The Rust compiler.\n+//!\n+//! # Note\n+//!\n+//! This API is completely unstable and subject to change.\n \n #![crate_name = \"rustc_trans\"]\n #![experimental]"}, {"sha": "f5c732d9adcf1e4e4b7db27de4a76c99af6abb0a", "filename": "src/librustc_trans/save/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Fsave%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Fsave%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fsave%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -651,7 +651,7 @@ impl <'l, 'tcx> DxrVisitor<'l, 'tcx> {\n                     typ: &ast::Ty,\n                     impl_items: &Vec<ast::ImplItem>) {\n         match typ.node {\n-            ast::TyPath(ref path, _, id) => {\n+            ast::TyPath(ref path, id) => {\n                 match self.lookup_type_ref(id) {\n                     Some(id) => {\n                         let sub_span = self.span.sub_span_for_type_name(path.span);\n@@ -1256,7 +1256,7 @@ impl<'l, 'tcx, 'v> Visitor<'v> for DxrVisitor<'l, 'tcx> {\n         }\n \n         match t.node {\n-            ast::TyPath(ref path, _, id) => {\n+            ast::TyPath(ref path, id) => {\n                 match self.lookup_type_ref(id) {\n                     Some(id) => {\n                         let sub_span = self.span.sub_span_for_type_name(t.span);"}, {"sha": "41fbe855769331291f6fb5b20845a997e633a70b", "filename": "src/librustc_trans/test.rs", "status": "modified", "additions": 8, "deletions": 22, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftest.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,11 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-\n-# Standalone Tests for the Inference Module\n-\n-*/\n+//! # Standalone Tests for the Inference Module\n \n use driver::diagnostic;\n use driver::diagnostic::Emitter;\n@@ -537,12 +533,10 @@ fn glb_bound_static() {\n     })\n }\n \n+/// Test substituting a bound region into a function, which introduces another level of binding.\n+/// This requires adjusting the Debruijn index.\n #[test]\n fn subst_ty_renumber_bound() {\n-    /*!\n-     * Test substituting a bound region into a function, which introduces another\n-     * level of binding. This requires adjusting the Debruijn index.\n-     */\n \n     test_env(EMPTY_SOURCE_STR, errors(&[]), |env| {\n         // Situation:\n@@ -575,13 +569,10 @@ fn subst_ty_renumber_bound() {\n     })\n }\n \n+/// Test substituting a bound region into a function, which introduces another level of binding.\n+/// This requires adjusting the Debruijn index.\n #[test]\n fn subst_ty_renumber_some_bounds() {\n-    /*!\n-     * Test substituting a bound region into a function, which introduces another\n-     * level of binding. This requires adjusting the Debruijn index.\n-     */\n-\n     test_env(EMPTY_SOURCE_STR, errors(&[]), |env| {\n         // Situation:\n         // Theta = [A -> &'a foo]\n@@ -615,12 +606,9 @@ fn subst_ty_renumber_some_bounds() {\n     })\n }\n \n+/// Test that we correctly compute whether a type has escaping regions or not.\n #[test]\n fn escaping() {\n-    /*!\n-     * Test that we correctly compute whether a type has escaping\n-     * regions or not.\n-     */\n \n     test_env(EMPTY_SOURCE_STR, errors(&[]), |env| {\n         // Situation:\n@@ -658,12 +646,10 @@ fn escaping() {\n     })\n }\n \n+/// Test applying a substitution where the value being substituted for an early-bound region is a\n+/// late-bound region.\n #[test]\n fn subst_region_renumber_region() {\n-    /*!\n-     * Test applying a substitution where the value being substituted\n-     * for an early-bound region is a late-bound region.\n-     */\n \n     test_env(EMPTY_SOURCE_STR, errors(&[]), |env| {\n         let re_bound1 = env.re_late_bound_with_debruijn(1, ty::DebruijnIndex::new(1));"}, {"sha": "e8b759fa1a21403089d07186af041cc246f32a59", "filename": "src/librustc_trans/trans/_match.rs", "status": "modified", "additions": 212, "deletions": 234, "changes": 446, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2F_match.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2F_match.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2F_match.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,183 +8,179 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- *\n- * # Compilation of match statements\n- *\n- * I will endeavor to explain the code as best I can.  I have only a loose\n- * understanding of some parts of it.\n- *\n- * ## Matching\n- *\n- * The basic state of the code is maintained in an array `m` of `Match`\n- * objects.  Each `Match` describes some list of patterns, all of which must\n- * match against the current list of values.  If those patterns match, then\n- * the arm listed in the match is the correct arm.  A given arm may have\n- * multiple corresponding match entries, one for each alternative that\n- * remains.  As we proceed these sets of matches are adjusted by the various\n- * `enter_XXX()` functions, each of which adjusts the set of options given\n- * some information about the value which has been matched.\n- *\n- * So, initially, there is one value and N matches, each of which have one\n- * constituent pattern.  N here is usually the number of arms but may be\n- * greater, if some arms have multiple alternatives.  For example, here:\n- *\n- *     enum Foo { A, B(int), C(uint, uint) }\n- *     match foo {\n- *         A => ...,\n- *         B(x) => ...,\n- *         C(1u, 2) => ...,\n- *         C(_) => ...\n- *     }\n- *\n- * The value would be `foo`.  There would be four matches, each of which\n- * contains one pattern (and, in one case, a guard).  We could collect the\n- * various options and then compile the code for the case where `foo` is an\n- * `A`, a `B`, and a `C`.  When we generate the code for `C`, we would (1)\n- * drop the two matches that do not match a `C` and (2) expand the other two\n- * into two patterns each.  In the first case, the two patterns would be `1u`\n- * and `2`, and the in the second case the _ pattern would be expanded into\n- * `_` and `_`.  The two values are of course the arguments to `C`.\n- *\n- * Here is a quick guide to the various functions:\n- *\n- * - `compile_submatch()`: The main workhouse.  It takes a list of values and\n- *   a list of matches and finds the various possibilities that could occur.\n- *\n- * - `enter_XXX()`: modifies the list of matches based on some information\n- *   about the value that has been matched.  For example,\n- *   `enter_rec_or_struct()` adjusts the values given that a record or struct\n- *   has been matched.  This is an infallible pattern, so *all* of the matches\n- *   must be either wildcards or record/struct patterns.  `enter_opt()`\n- *   handles the fallible cases, and it is correspondingly more complex.\n- *\n- * ## Bindings\n- *\n- * We store information about the bound variables for each arm as part of the\n- * per-arm `ArmData` struct.  There is a mapping from identifiers to\n- * `BindingInfo` structs.  These structs contain the mode/id/type of the\n- * binding, but they also contain an LLVM value which points at an alloca\n- * called `llmatch`. For by value bindings that are Copy, we also create\n- * an extra alloca that we copy the matched value to so that any changes\n- * we do to our copy is not reflected in the original and vice-versa.\n- * We don't do this if it's a move since the original value can't be used\n- * and thus allowing us to cheat in not creating an extra alloca.\n- *\n- * The `llmatch` binding always stores a pointer into the value being matched\n- * which points at the data for the binding.  If the value being matched has\n- * type `T`, then, `llmatch` will point at an alloca of type `T*` (and hence\n- * `llmatch` has type `T**`).  So, if you have a pattern like:\n- *\n- *    let a: A = ...;\n- *    let b: B = ...;\n- *    match (a, b) { (ref c, d) => { ... } }\n- *\n- * For `c` and `d`, we would generate allocas of type `C*` and `D*`\n- * respectively.  These are called the `llmatch`.  As we match, when we come\n- * up against an identifier, we store the current pointer into the\n- * corresponding alloca.\n- *\n- * Once a pattern is completely matched, and assuming that there is no guard\n- * pattern, we will branch to a block that leads to the body itself.  For any\n- * by-value bindings, this block will first load the ptr from `llmatch` (the\n- * one of type `D*`) and then load a second time to get the actual value (the\n- * one of type `D`). For by ref bindings, the value of the local variable is\n- * simply the first alloca.\n- *\n- * So, for the example above, we would generate a setup kind of like this:\n- *\n- *        +-------+\n- *        | Entry |\n- *        +-------+\n- *            |\n- *        +--------------------------------------------+\n- *        | llmatch_c = (addr of first half of tuple)  |\n- *        | llmatch_d = (addr of second half of tuple) |\n- *        +--------------------------------------------+\n- *            |\n- *        +--------------------------------------+\n- *        | *llbinding_d = **llmatch_d           |\n- *        +--------------------------------------+\n- *\n- * If there is a guard, the situation is slightly different, because we must\n- * execute the guard code.  Moreover, we need to do so once for each of the\n- * alternatives that lead to the arm, because if the guard fails, they may\n- * have different points from which to continue the search. Therefore, in that\n- * case, we generate code that looks more like:\n- *\n- *        +-------+\n- *        | Entry |\n- *        +-------+\n- *            |\n- *        +-------------------------------------------+\n- *        | llmatch_c = (addr of first half of tuple) |\n- *        | llmatch_d = (addr of first half of tuple) |\n- *        +-------------------------------------------+\n- *            |\n- *        +-------------------------------------------------+\n- *        | *llbinding_d = **llmatch_d                      |\n- *        | check condition                                 |\n- *        | if false { goto next case }                     |\n- *        | if true { goto body }                           |\n- *        +-------------------------------------------------+\n- *\n- * The handling for the cleanups is a bit... sensitive.  Basically, the body\n- * is the one that invokes `add_clean()` for each binding.  During the guard\n- * evaluation, we add temporary cleanups and revoke them after the guard is\n- * evaluated (it could fail, after all). Note that guards and moves are\n- * just plain incompatible.\n- *\n- * Some relevant helper functions that manage bindings:\n- * - `create_bindings_map()`\n- * - `insert_lllocals()`\n- *\n- *\n- * ## Notes on vector pattern matching.\n- *\n- * Vector pattern matching is surprisingly tricky. The problem is that\n- * the structure of the vector isn't fully known, and slice matches\n- * can be done on subparts of it.\n- *\n- * The way that vector pattern matches are dealt with, then, is as\n- * follows. First, we make the actual condition associated with a\n- * vector pattern simply a vector length comparison. So the pattern\n- * [1, .. x] gets the condition \"vec len >= 1\", and the pattern\n- * [.. x] gets the condition \"vec len >= 0\". The problem here is that\n- * having the condition \"vec len >= 1\" hold clearly does not mean that\n- * only a pattern that has exactly that condition will match. This\n- * means that it may well be the case that a condition holds, but none\n- * of the patterns matching that condition match; to deal with this,\n- * when doing vector length matches, we have match failures proceed to\n- * the next condition to check.\n- *\n- * There are a couple more subtleties to deal with. While the \"actual\"\n- * condition associated with vector length tests is simply a test on\n- * the vector length, the actual vec_len Opt entry contains more\n- * information used to restrict which matches are associated with it.\n- * So that all matches in a submatch are matching against the same\n- * values from inside the vector, they are split up by how many\n- * elements they match at the front and at the back of the vector. In\n- * order to make sure that arms are properly checked in order, even\n- * with the overmatching conditions, each vec_len Opt entry is\n- * associated with a range of matches.\n- * Consider the following:\n- *\n- *   match &[1, 2, 3] {\n- *       [1, 1, .. _] => 0,\n- *       [1, 2, 2, .. _] => 1,\n- *       [1, 2, 3, .. _] => 2,\n- *       [1, 2, .. _] => 3,\n- *       _ => 4\n- *   }\n- * The proper arm to match is arm 2, but arms 0 and 3 both have the\n- * condition \"len >= 2\". If arm 3 was lumped in with arm 0, then the\n- * wrong branch would be taken. Instead, vec_len Opts are associated\n- * with a contiguous range of matches that have the same \"shape\".\n- * This is sort of ugly and requires a bunch of special handling of\n- * vec_len options.\n- *\n- */\n+//! # Compilation of match statements\n+//!\n+//! I will endeavor to explain the code as best I can.  I have only a loose\n+//! understanding of some parts of it.\n+//!\n+//! ## Matching\n+//!\n+//! The basic state of the code is maintained in an array `m` of `Match`\n+//! objects.  Each `Match` describes some list of patterns, all of which must\n+//! match against the current list of values.  If those patterns match, then\n+//! the arm listed in the match is the correct arm.  A given arm may have\n+//! multiple corresponding match entries, one for each alternative that\n+//! remains.  As we proceed these sets of matches are adjusted by the various\n+//! `enter_XXX()` functions, each of which adjusts the set of options given\n+//! some information about the value which has been matched.\n+//!\n+//! So, initially, there is one value and N matches, each of which have one\n+//! constituent pattern.  N here is usually the number of arms but may be\n+//! greater, if some arms have multiple alternatives.  For example, here:\n+//!\n+//!     enum Foo { A, B(int), C(uint, uint) }\n+//!     match foo {\n+//!         A => ...,\n+//!         B(x) => ...,\n+//!         C(1u, 2) => ...,\n+//!         C(_) => ...\n+//!     }\n+//!\n+//! The value would be `foo`.  There would be four matches, each of which\n+//! contains one pattern (and, in one case, a guard).  We could collect the\n+//! various options and then compile the code for the case where `foo` is an\n+//! `A`, a `B`, and a `C`.  When we generate the code for `C`, we would (1)\n+//! drop the two matches that do not match a `C` and (2) expand the other two\n+//! into two patterns each.  In the first case, the two patterns would be `1u`\n+//! and `2`, and the in the second case the _ pattern would be expanded into\n+//! `_` and `_`.  The two values are of course the arguments to `C`.\n+//!\n+//! Here is a quick guide to the various functions:\n+//!\n+//! - `compile_submatch()`: The main workhouse.  It takes a list of values and\n+//!   a list of matches and finds the various possibilities that could occur.\n+//!\n+//! - `enter_XXX()`: modifies the list of matches based on some information\n+//!   about the value that has been matched.  For example,\n+//!   `enter_rec_or_struct()` adjusts the values given that a record or struct\n+//!   has been matched.  This is an infallible pattern, so *all* of the matches\n+//!   must be either wildcards or record/struct patterns.  `enter_opt()`\n+//!   handles the fallible cases, and it is correspondingly more complex.\n+//!\n+//! ## Bindings\n+//!\n+//! We store information about the bound variables for each arm as part of the\n+//! per-arm `ArmData` struct.  There is a mapping from identifiers to\n+//! `BindingInfo` structs.  These structs contain the mode/id/type of the\n+//! binding, but they also contain an LLVM value which points at an alloca\n+//! called `llmatch`. For by value bindings that are Copy, we also create\n+//! an extra alloca that we copy the matched value to so that any changes\n+//! we do to our copy is not reflected in the original and vice-versa.\n+//! We don't do this if it's a move since the original value can't be used\n+//! and thus allowing us to cheat in not creating an extra alloca.\n+//!\n+//! The `llmatch` binding always stores a pointer into the value being matched\n+//! which points at the data for the binding.  If the value being matched has\n+//! type `T`, then, `llmatch` will point at an alloca of type `T*` (and hence\n+//! `llmatch` has type `T**`).  So, if you have a pattern like:\n+//!\n+//!    let a: A = ...;\n+//!    let b: B = ...;\n+//!    match (a, b) { (ref c, d) => { ... } }\n+//!\n+//! For `c` and `d`, we would generate allocas of type `C*` and `D*`\n+//! respectively.  These are called the `llmatch`.  As we match, when we come\n+//! up against an identifier, we store the current pointer into the\n+//! corresponding alloca.\n+//!\n+//! Once a pattern is completely matched, and assuming that there is no guard\n+//! pattern, we will branch to a block that leads to the body itself.  For any\n+//! by-value bindings, this block will first load the ptr from `llmatch` (the\n+//! one of type `D*`) and then load a second time to get the actual value (the\n+//! one of type `D`). For by ref bindings, the value of the local variable is\n+//! simply the first alloca.\n+//!\n+//! So, for the example above, we would generate a setup kind of like this:\n+//!\n+//!        +-------+\n+//!        | Entry |\n+//!        +-------+\n+//!            |\n+//!        +--------------------------------------------+\n+//!        | llmatch_c = (addr of first half of tuple)  |\n+//!        | llmatch_d = (addr of second half of tuple) |\n+//!        +--------------------------------------------+\n+//!            |\n+//!        +--------------------------------------+\n+//!        | *llbinding_d = **llmatch_d           |\n+//!        +--------------------------------------+\n+//!\n+//! If there is a guard, the situation is slightly different, because we must\n+//! execute the guard code.  Moreover, we need to do so once for each of the\n+//! alternatives that lead to the arm, because if the guard fails, they may\n+//! have different points from which to continue the search. Therefore, in that\n+//! case, we generate code that looks more like:\n+//!\n+//!        +-------+\n+//!        | Entry |\n+//!        +-------+\n+//!            |\n+//!        +-------------------------------------------+\n+//!        | llmatch_c = (addr of first half of tuple) |\n+//!        | llmatch_d = (addr of first half of tuple) |\n+//!        +-------------------------------------------+\n+//!            |\n+//!        +-------------------------------------------------+\n+//!        | *llbinding_d = **llmatch_d                      |\n+//!        | check condition                                 |\n+//!        | if false { goto next case }                     |\n+//!        | if true { goto body }                           |\n+//!        +-------------------------------------------------+\n+//!\n+//! The handling for the cleanups is a bit... sensitive.  Basically, the body\n+//! is the one that invokes `add_clean()` for each binding.  During the guard\n+//! evaluation, we add temporary cleanups and revoke them after the guard is\n+//! evaluated (it could fail, after all). Note that guards and moves are\n+//! just plain incompatible.\n+//!\n+//! Some relevant helper functions that manage bindings:\n+//! - `create_bindings_map()`\n+//! - `insert_lllocals()`\n+//!\n+//!\n+//! ## Notes on vector pattern matching.\n+//!\n+//! Vector pattern matching is surprisingly tricky. The problem is that\n+//! the structure of the vector isn't fully known, and slice matches\n+//! can be done on subparts of it.\n+//!\n+//! The way that vector pattern matches are dealt with, then, is as\n+//! follows. First, we make the actual condition associated with a\n+//! vector pattern simply a vector length comparison. So the pattern\n+//! [1, .. x] gets the condition \"vec len >= 1\", and the pattern\n+//! [.. x] gets the condition \"vec len >= 0\". The problem here is that\n+//! having the condition \"vec len >= 1\" hold clearly does not mean that\n+//! only a pattern that has exactly that condition will match. This\n+//! means that it may well be the case that a condition holds, but none\n+//! of the patterns matching that condition match; to deal with this,\n+//! when doing vector length matches, we have match failures proceed to\n+//! the next condition to check.\n+//!\n+//! There are a couple more subtleties to deal with. While the \"actual\"\n+//! condition associated with vector length tests is simply a test on\n+//! the vector length, the actual vec_len Opt entry contains more\n+//! information used to restrict which matches are associated with it.\n+//! So that all matches in a submatch are matching against the same\n+//! values from inside the vector, they are split up by how many\n+//! elements they match at the front and at the back of the vector. In\n+//! order to make sure that arms are properly checked in order, even\n+//! with the overmatching conditions, each vec_len Opt entry is\n+//! associated with a range of matches.\n+//! Consider the following:\n+//!\n+//!   match &[1, 2, 3] {\n+//!       [1, 1, .. _] => 0,\n+//!       [1, 2, 2, .. _] => 1,\n+//!       [1, 2, 3, .. _] => 2,\n+//!       [1, 2, .. _] => 3,\n+//!       _ => 4\n+//!   }\n+//! The proper arm to match is arm 2, but arms 0 and 3 both have the\n+//! condition \"len >= 2\". If arm 3 was lumped in with arm 0, then the\n+//! wrong branch would be taken. Instead, vec_len Opts are associated\n+//! with a contiguous range of matches that have the same \"shape\".\n+//! This is sort of ugly and requires a bunch of special handling of\n+//! vec_len options.\n \n pub use self::BranchKind::*;\n pub use self::OptResult::*;\n@@ -325,15 +321,14 @@ pub enum TransBindingMode {\n     TrByRef,\n }\n \n-/**\n- * Information about a pattern binding:\n- * - `llmatch` is a pointer to a stack slot.  The stack slot contains a\n- *   pointer into the value being matched.  Hence, llmatch has type `T**`\n- *   where `T` is the value being matched.\n- * - `trmode` is the trans binding mode\n- * - `id` is the node id of the binding\n- * - `ty` is the Rust type of the binding */\n- #[deriving(Clone)]\n+/// Information about a pattern binding:\n+/// - `llmatch` is a pointer to a stack slot.  The stack slot contains a\n+///   pointer into the value being matched.  Hence, llmatch has type `T**`\n+///   where `T` is the value being matched.\n+/// - `trmode` is the trans binding mode\n+/// - `id` is the node id of the binding\n+/// - `ty` is the Rust type of the binding\n+#[deriving(Clone)]\n pub struct BindingInfo<'tcx> {\n     pub llmatch: ValueRef,\n     pub trmode: TransBindingMode,\n@@ -350,12 +345,10 @@ struct ArmData<'p, 'blk, 'tcx: 'blk> {\n     bindings_map: BindingsMap<'tcx>\n }\n \n-/**\n- * Info about Match.\n- * If all `pats` are matched then arm `data` will be executed.\n- * As we proceed `bound_ptrs` are filled with pointers to values to be bound,\n- * these pointers are stored in llmatch variables just before executing `data` arm.\n- */\n+/// Info about Match.\n+/// If all `pats` are matched then arm `data` will be executed.\n+/// As we proceed `bound_ptrs` are filled with pointers to values to be bound,\n+/// these pointers are stored in llmatch variables just before executing `data` arm.\n struct Match<'a, 'p: 'a, 'blk: 'a, 'tcx: 'blk> {\n     pats: Vec<&'p ast::Pat>,\n     data: &'a ArmData<'p, 'blk, 'tcx>,\n@@ -620,12 +613,9 @@ fn extract_variant_args<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n     ExtractedBlock { vals: args, bcx: bcx }\n }\n \n+/// Helper for converting from the ValueRef that we pass around in the match code, which is always\n+/// an lvalue, into a Datum. Eventually we should just pass around a Datum and be done with it.\n fn match_datum<'tcx>(val: ValueRef, left_ty: Ty<'tcx>) -> Datum<'tcx, Lvalue> {\n-    /*!\n-     * Helper for converting from the ValueRef that we pass around in\n-     * the match code, which is always an lvalue, into a Datum. Eventually\n-     * we should just pass around a Datum and be done with it.\n-     */\n     Datum::new(val, left_ty, Lvalue)\n }\n \n@@ -831,15 +821,11 @@ fn compare_values<'blk, 'tcx>(cx: Block<'blk, 'tcx>,\n     }\n }\n \n+/// For each binding in `data.bindings_map`, adds an appropriate entry into the `fcx.lllocals` map\n fn insert_lllocals<'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                                bindings_map: &BindingsMap<'tcx>,\n                                cs: Option<cleanup::ScopeId>)\n                                -> Block<'blk, 'tcx> {\n-    /*!\n-     * For each binding in `data.bindings_map`, adds an appropriate entry into\n-     * the `fcx.lllocals` map\n-     */\n-\n     for (&ident, &binding_info) in bindings_map.iter() {\n         let llval = match binding_info.trmode {\n             // By value mut binding for a copy type: load from the ptr\n@@ -1416,13 +1402,11 @@ fn trans_match_inner<'blk, 'tcx>(scope_cx: Block<'blk, 'tcx>,\n     return bcx;\n }\n \n+/// Generates code for a local variable declaration like `let <pat>;` or `let <pat> =\n+/// <opt_init_expr>`.\n pub fn store_local<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                local: &ast::Local)\n                                -> Block<'blk, 'tcx> {\n-    /*!\n-     * Generates code for a local variable declaration like\n-     * `let <pat>;` or `let <pat> = <opt_init_expr>`.\n-     */\n     let _icx = push_ctxt(\"match::store_local\");\n     let mut bcx = bcx;\n     let tcx = bcx.tcx();\n@@ -1482,24 +1466,21 @@ pub fn store_local<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n     }\n }\n \n+/// Generates code for argument patterns like `fn foo(<pat>: T)`.\n+/// Creates entries in the `lllocals` map for each of the bindings\n+/// in `pat`.\n+///\n+/// # Arguments\n+///\n+/// - `pat` is the argument pattern\n+/// - `llval` is a pointer to the argument value (in other words,\n+///   if the argument type is `T`, then `llval` is a `T*`). In some\n+///   cases, this code may zero out the memory `llval` points at.\n pub fn store_arg<'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                              pat: &ast::Pat,\n                              arg: Datum<'tcx, Rvalue>,\n                              arg_scope: cleanup::ScopeId)\n                              -> Block<'blk, 'tcx> {\n-    /*!\n-     * Generates code for argument patterns like `fn foo(<pat>: T)`.\n-     * Creates entries in the `lllocals` map for each of the bindings\n-     * in `pat`.\n-     *\n-     * # Arguments\n-     *\n-     * - `pat` is the argument pattern\n-     * - `llval` is a pointer to the argument value (in other words,\n-     *   if the argument type is `T`, then `llval` is a `T*`). In some\n-     *   cases, this code may zero out the memory `llval` points at.\n-     */\n-\n     let _icx = push_ctxt(\"match::store_arg\");\n \n     match simple_identifier(&*pat) {\n@@ -1583,26 +1564,23 @@ fn mk_binding_alloca<'blk, 'tcx, A>(bcx: Block<'blk, 'tcx>,\n     bcx\n }\n \n+/// A simple version of the pattern matching code that only handles\n+/// irrefutable patterns. This is used in let/argument patterns,\n+/// not in match statements. Unifying this code with the code above\n+/// sounds nice, but in practice it produces very inefficient code,\n+/// since the match code is so much more general. In most cases,\n+/// LLVM is able to optimize the code, but it causes longer compile\n+/// times and makes the generated code nigh impossible to read.\n+///\n+/// # Arguments\n+/// - bcx: starting basic block context\n+/// - pat: the irrefutable pattern being matched.\n+/// - val: the value being matched -- must be an lvalue (by ref, with cleanup)\n fn bind_irrefutable_pat<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                     pat: &ast::Pat,\n                                     val: ValueRef,\n                                     cleanup_scope: cleanup::ScopeId)\n                                     -> Block<'blk, 'tcx> {\n-    /*!\n-     * A simple version of the pattern matching code that only handles\n-     * irrefutable patterns. This is used in let/argument patterns,\n-     * not in match statements. Unifying this code with the code above\n-     * sounds nice, but in practice it produces very inefficient code,\n-     * since the match code is so much more general. In most cases,\n-     * LLVM is able to optimize the code, but it causes longer compile\n-     * times and makes the generated code nigh impossible to read.\n-     *\n-     * # Arguments\n-     * - bcx: starting basic block context\n-     * - pat: the irrefutable pattern being matched.\n-     * - val: the value being matched -- must be an lvalue (by ref, with cleanup)\n-     */\n-\n     debug!(\"bind_irrefutable_pat(bcx={}, pat={})\",\n            bcx.to_str(),\n            pat.repr(bcx.tcx()));"}, {"sha": "2f0f373325a01b457e901c7e40879e5ca9c492b8", "filename": "src/librustc_trans/trans/adt.rs", "status": "modified", "additions": 113, "deletions": 143, "changes": 256, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fadt.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,40 +8,38 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * # Representation of Algebraic Data Types\n- *\n- * This module determines how to represent enums, structs, and tuples\n- * based on their monomorphized types; it is responsible both for\n- * choosing a representation and translating basic operations on\n- * values of those types.  (Note: exporting the representations for\n- * debuggers is handled in debuginfo.rs, not here.)\n- *\n- * Note that the interface treats everything as a general case of an\n- * enum, so structs/tuples/etc. have one pseudo-variant with\n- * discriminant 0; i.e., as if they were a univariant enum.\n- *\n- * Having everything in one place will enable improvements to data\n- * structure representation; possibilities include:\n- *\n- * - User-specified alignment (e.g., cacheline-aligning parts of\n- *   concurrently accessed data structures); LLVM can't represent this\n- *   directly, so we'd have to insert padding fields in any structure\n- *   that might contain one and adjust GEP indices accordingly.  See\n- *   issue #4578.\n- *\n- * - Store nested enums' discriminants in the same word.  Rather, if\n- *   some variants start with enums, and those enums representations\n- *   have unused alignment padding between discriminant and body, the\n- *   outer enum's discriminant can be stored there and those variants\n- *   can start at offset 0.  Kind of fancy, and might need work to\n- *   make copies of the inner enum type cooperate, but it could help\n- *   with `Option` or `Result` wrapped around another enum.\n- *\n- * - Tagged pointers would be neat, but given that any type can be\n- *   used unboxed and any field can have pointers (including mutable)\n- *   taken to it, implementing them for Rust seems difficult.\n- */\n+//! # Representation of Algebraic Data Types\n+//!\n+//! This module determines how to represent enums, structs, and tuples\n+//! based on their monomorphized types; it is responsible both for\n+//! choosing a representation and translating basic operations on\n+//! values of those types.  (Note: exporting the representations for\n+//! debuggers is handled in debuginfo.rs, not here.)\n+//!\n+//! Note that the interface treats everything as a general case of an\n+//! enum, so structs/tuples/etc. have one pseudo-variant with\n+//! discriminant 0; i.e., as if they were a univariant enum.\n+//!\n+//! Having everything in one place will enable improvements to data\n+//! structure representation; possibilities include:\n+//!\n+//! - User-specified alignment (e.g., cacheline-aligning parts of\n+//!   concurrently accessed data structures); LLVM can't represent this\n+//!   directly, so we'd have to insert padding fields in any structure\n+//!   that might contain one and adjust GEP indices accordingly.  See\n+//!   issue #4578.\n+//!\n+//! - Store nested enums' discriminants in the same word.  Rather, if\n+//!   some variants start with enums, and those enums representations\n+//!   have unused alignment padding between discriminant and body, the\n+//!   outer enum's discriminant can be stored there and those variants\n+//!   can start at offset 0.  Kind of fancy, and might need work to\n+//!   make copies of the inner enum type cooperate, but it could help\n+//!   with `Option` or `Result` wrapped around another enum.\n+//!\n+//! - Tagged pointers would be neat, but given that any type can be\n+//!   used unboxed and any field can have pointers (including mutable)\n+//!   taken to it, implementing them for Rust seems difficult.\n \n #![allow(unsigned_negation)]\n \n@@ -79,46 +77,38 @@ type Hint = attr::ReprAttr;\n pub enum Repr<'tcx> {\n     /// C-like enums; basically an int.\n     CEnum(IntType, Disr, Disr), // discriminant range (signedness based on the IntType)\n-    /**\n-     * Single-case variants, and structs/tuples/records.\n-     *\n-     * Structs with destructors need a dynamic destroyedness flag to\n-     * avoid running the destructor too many times; this is included\n-     * in the `Struct` if present.\n-     */\n+    /// Single-case variants, and structs/tuples/records.\n+    ///\n+    /// Structs with destructors need a dynamic destroyedness flag to\n+    /// avoid running the destructor too many times; this is included\n+    /// in the `Struct` if present.\n     Univariant(Struct<'tcx>, bool),\n-    /**\n-     * General-case enums: for each case there is a struct, and they\n-     * all start with a field for the discriminant.\n-     *\n-     * Types with destructors need a dynamic destroyedness flag to\n-     * avoid running the destructor too many times; the last argument\n-     * indicates whether such a flag is present.\n-     */\n+    /// General-case enums: for each case there is a struct, and they\n+    /// all start with a field for the discriminant.\n+    ///\n+    /// Types with destructors need a dynamic destroyedness flag to\n+    /// avoid running the destructor too many times; the last argument\n+    /// indicates whether such a flag is present.\n     General(IntType, Vec<Struct<'tcx>>, bool),\n-    /**\n-     * Two cases distinguished by a nullable pointer: the case with discriminant\n-     * `nndiscr` must have single field which is known to be nonnull due to its type.\n-     * The other case is known to be zero sized. Hence we represent the enum\n-     * as simply a nullable pointer: if not null it indicates the `nndiscr` variant,\n-     * otherwise it indicates the other case.\n-     */\n+    /// Two cases distinguished by a nullable pointer: the case with discriminant\n+    /// `nndiscr` must have single field which is known to be nonnull due to its type.\n+    /// The other case is known to be zero sized. Hence we represent the enum\n+    /// as simply a nullable pointer: if not null it indicates the `nndiscr` variant,\n+    /// otherwise it indicates the other case.\n     RawNullablePointer {\n         nndiscr: Disr,\n         nnty: Ty<'tcx>,\n         nullfields: Vec<Ty<'tcx>>\n     },\n-    /**\n-     * Two cases distinguished by a nullable pointer: the case with discriminant\n-     * `nndiscr` is represented by the struct `nonnull`, where the `ptrfield`th\n-     * field is known to be nonnull due to its type; if that field is null, then\n-     * it represents the other case, which is inhabited by at most one value\n-     * (and all other fields are undefined/unused).\n-     *\n-     * For example, `std::option::Option` instantiated at a safe pointer type\n-     * is represented such that `None` is a null pointer and `Some` is the\n-     * identity function.\n-     */\n+    /// Two cases distinguished by a nullable pointer: the case with discriminant\n+    /// `nndiscr` is represented by the struct `nonnull`, where the `ptrfield`th\n+    /// field is known to be nonnull due to its type; if that field is null, then\n+    /// it represents the other case, which is inhabited by at most one value\n+    /// (and all other fields are undefined/unused).\n+    ///\n+    /// For example, `std::option::Option` instantiated at a safe pointer type\n+    /// is represented such that `None` is a null pointer and `Some` is the\n+    /// identity function.\n     StructWrappedNullablePointer {\n         nonnull: Struct<'tcx>,\n         nndiscr: Disr,\n@@ -139,11 +129,9 @@ pub struct Struct<'tcx> {\n     pub fields: Vec<Ty<'tcx>>\n }\n \n-/**\n- * Convenience for `represent_type`.  There should probably be more or\n- * these, for places in trans where the `Ty` isn't directly\n- * available.\n- */\n+/// Convenience for `represent_type`.  There should probably be more or\n+/// these, for places in trans where the `Ty` isn't directly\n+/// available.\n pub fn represent_node<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                   node: ast::NodeId) -> Rc<Repr<'tcx>> {\n     represent_type(bcx.ccx(), node_id_type(bcx, node))\n@@ -514,16 +502,14 @@ fn ensure_enum_fits_in_address_space<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n }\n \n \n-/**\n- * LLVM-level types are a little complicated.\n- *\n- * C-like enums need to be actual ints, not wrapped in a struct,\n- * because that changes the ABI on some platforms (see issue #10308).\n- *\n- * For nominal types, in some cases, we need to use LLVM named structs\n- * and fill in the actual contents in a second pass to prevent\n- * unbounded recursion; see also the comments in `trans::type_of`.\n- */\n+/// LLVM-level types are a little complicated.\n+///\n+/// C-like enums need to be actual ints, not wrapped in a struct,\n+/// because that changes the ABI on some platforms (see issue #10308).\n+///\n+/// For nominal types, in some cases, we need to use LLVM named structs\n+/// and fill in the actual contents in a second pass to prevent\n+/// unbounded recursion; see also the comments in `trans::type_of`.\n pub fn type_of<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>, r: &Repr<'tcx>) -> Type {\n     generic_type_of(cx, r, None, false, false)\n }\n@@ -620,12 +606,10 @@ fn struct_llfields<'a, 'tcx>(cx: &CrateContext<'a, 'tcx>, st: &Struct<'tcx>,\n     }\n }\n \n-/**\n- * Obtain a representation of the discriminant sufficient to translate\n- * destructuring; this may or may not involve the actual discriminant.\n- *\n- * This should ideally be less tightly tied to `_match`.\n- */\n+/// Obtain a representation of the discriminant sufficient to translate\n+/// destructuring; this may or may not involve the actual discriminant.\n+///\n+/// This should ideally be less tightly tied to `_match`.\n pub fn trans_switch<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                 r: &Repr<'tcx>, scrutinee: ValueRef)\n                                 -> (_match::BranchKind, Option<ValueRef>) {\n@@ -713,12 +697,10 @@ fn load_discr(bcx: Block, ity: IntType, ptr: ValueRef, min: Disr, max: Disr)\n     }\n }\n \n-/**\n- * Yield information about how to dispatch a case of the\n- * discriminant-like value returned by `trans_switch`.\n- *\n- * This should ideally be less tightly tied to `_match`.\n- */\n+/// Yield information about how to dispatch a case of the\n+/// discriminant-like value returned by `trans_switch`.\n+///\n+/// This should ideally be less tightly tied to `_match`.\n pub fn trans_case<'blk, 'tcx>(bcx: Block<'blk, 'tcx>, r: &Repr, discr: Disr)\n                               -> _match::OptResult<'blk, 'tcx> {\n     match *r {\n@@ -741,10 +723,8 @@ pub fn trans_case<'blk, 'tcx>(bcx: Block<'blk, 'tcx>, r: &Repr, discr: Disr)\n     }\n }\n \n-/**\n- * Set the discriminant for a new value of the given case of the given\n- * representation.\n- */\n+/// Set the discriminant for a new value of the given case of the given\n+/// representation.\n pub fn trans_set_discr<'blk, 'tcx>(bcx: Block<'blk, 'tcx>, r: &Repr<'tcx>,\n                                    val: ValueRef, discr: Disr) {\n     match *r {\n@@ -799,10 +779,8 @@ fn assert_discr_in_range(ity: IntType, min: Disr, max: Disr, discr: Disr) {\n     }\n }\n \n-/**\n- * The number of fields in a given case; for use when obtaining this\n- * information from the type or definition is less convenient.\n- */\n+/// The number of fields in a given case; for use when obtaining this\n+/// information from the type or definition is less convenient.\n pub fn num_args(r: &Repr, discr: Disr) -> uint {\n     match *r {\n         CEnum(..) => 0,\n@@ -946,27 +924,25 @@ pub fn trans_drop_flag_ptr<'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>, r: &Repr<'tcx\n     }\n }\n \n-/**\n- * Construct a constant value, suitable for initializing a\n- * GlobalVariable, given a case and constant values for its fields.\n- * Note that this may have a different LLVM type (and different\n- * alignment!) from the representation's `type_of`, so it needs a\n- * pointer cast before use.\n- *\n- * The LLVM type system does not directly support unions, and only\n- * pointers can be bitcast, so a constant (and, by extension, the\n- * GlobalVariable initialized by it) will have a type that can vary\n- * depending on which case of an enum it is.\n- *\n- * To understand the alignment situation, consider `enum E { V64(u64),\n- * V32(u32, u32) }` on Windows.  The type has 8-byte alignment to\n- * accommodate the u64, but `V32(x, y)` would have LLVM type `{i32,\n- * i32, i32}`, which is 4-byte aligned.\n- *\n- * Currently the returned value has the same size as the type, but\n- * this could be changed in the future to avoid allocating unnecessary\n- * space after values of shorter-than-maximum cases.\n- */\n+/// Construct a constant value, suitable for initializing a\n+/// GlobalVariable, given a case and constant values for its fields.\n+/// Note that this may have a different LLVM type (and different\n+/// alignment!) from the representation's `type_of`, so it needs a\n+/// pointer cast before use.\n+///\n+/// The LLVM type system does not directly support unions, and only\n+/// pointers can be bitcast, so a constant (and, by extension, the\n+/// GlobalVariable initialized by it) will have a type that can vary\n+/// depending on which case of an enum it is.\n+///\n+/// To understand the alignment situation, consider `enum E { V64(u64),\n+/// V32(u32, u32) }` on Windows.  The type has 8-byte alignment to\n+/// accommodate the u64, but `V32(x, y)` would have LLVM type `{i32,\n+/// i32, i32}`, which is 4-byte aligned.\n+///\n+/// Currently the returned value has the same size as the type, but\n+/// this could be changed in the future to avoid allocating unnecessary\n+/// space after values of shorter-than-maximum cases.\n pub fn trans_const<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>, r: &Repr<'tcx>, discr: Disr,\n                              vals: &[ValueRef]) -> ValueRef {\n     match *r {\n@@ -1019,9 +995,7 @@ pub fn trans_const<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>, r: &Repr<'tcx>, discr\n     }\n }\n \n-/**\n- * Compute struct field offsets relative to struct begin.\n- */\n+/// Compute struct field offsets relative to struct begin.\n fn compute_struct_field_offsets<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n                                           st: &Struct<'tcx>) -> Vec<u64> {\n     let mut offsets = vec!();\n@@ -1040,16 +1014,14 @@ fn compute_struct_field_offsets<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n     offsets\n }\n \n-/**\n- * Building structs is a little complicated, because we might need to\n- * insert padding if a field's value is less aligned than its type.\n- *\n- * Continuing the example from `trans_const`, a value of type `(u32,\n- * E)` should have the `E` at offset 8, but if that field's\n- * initializer is 4-byte aligned then simply translating the tuple as\n- * a two-element struct will locate it at offset 4, and accesses to it\n- * will read the wrong memory.\n- */\n+/// Building structs is a little complicated, because we might need to\n+/// insert padding if a field's value is less aligned than its type.\n+///\n+/// Continuing the example from `trans_const`, a value of type `(u32,\n+/// E)` should have the `E` at offset 8, but if that field's\n+/// initializer is 4-byte aligned then simply translating the tuple as\n+/// a two-element struct will locate it at offset 4, and accesses to it\n+/// will read the wrong memory.\n fn build_const_struct<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n                                 st: &Struct<'tcx>, vals: &[ValueRef])\n                                 -> Vec<ValueRef> {\n@@ -1130,13 +1102,11 @@ pub fn const_get_discrim(ccx: &CrateContext, r: &Repr, val: ValueRef)\n     }\n }\n \n-/**\n- * Extract a field of a constant value, as appropriate for its\n- * representation.\n- *\n- * (Not to be confused with `common::const_get_elt`, which operates on\n- * raw LLVM-level structs and arrays.)\n- */\n+/// Extract a field of a constant value, as appropriate for its\n+/// representation.\n+///\n+/// (Not to be confused with `common::const_get_elt`, which operates on\n+/// raw LLVM-level structs and arrays.)\n pub fn const_get_field(ccx: &CrateContext, r: &Repr, val: ValueRef,\n                        _discr: Disr, ix: uint) -> ValueRef {\n     match *r {"}, {"sha": "024df2a63adb5c7ef92d8ee500353ef9ef96f06a", "filename": "src/librustc_trans/trans/asm.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fasm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fasm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fasm.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,9 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-# Translation of inline assembly.\n-*/\n+//! # Translation of inline assembly.\n \n use llvm;\n use trans::build::*;"}, {"sha": "52e54a4a2613a41289835ffc16e3bf545ea0741b", "filename": "src/librustc_trans/trans/base.rs", "status": "modified", "additions": 5, "deletions": 10, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fbase.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -1050,14 +1050,11 @@ pub fn load_if_immediate<'blk, 'tcx>(cx: Block<'blk, 'tcx>,\n     return v;\n }\n \n+/// Helper for loading values from memory. Does the necessary conversion if the in-memory type\n+/// differs from the type used for SSA values. Also handles various special cases where the type\n+/// gives us better information about what we are loading.\n pub fn load_ty<'blk, 'tcx>(cx: Block<'blk, 'tcx>,\n                            ptr: ValueRef, t: Ty<'tcx>) -> ValueRef {\n-    /*!\n-     * Helper for loading values from memory. Does the necessary conversion if\n-     * the in-memory type differs from the type used for SSA values. Also\n-     * handles various special cases where the type gives us better information\n-     * about what we are loading.\n-     */\n     if type_is_zero_size(cx.ccx(), t) {\n         C_undef(type_of::type_of(cx.ccx(), t))\n     } else if ty::type_is_bool(t) {\n@@ -1071,11 +1068,9 @@ pub fn load_ty<'blk, 'tcx>(cx: Block<'blk, 'tcx>,\n     }\n }\n \n+/// Helper for storing values in memory. Does the necessary conversion if the in-memory type\n+/// differs from the type used for SSA values.\n pub fn store_ty(cx: Block, v: ValueRef, dst: ValueRef, t: Ty) {\n-    /*!\n-     * Helper for storing values in memory. Does the necessary conversion if\n-     * the in-memory type differs from the type used for SSA values.\n-     */\n     if ty::type_is_bool(t) {\n         Store(cx, ZExt(cx, v, Type::i8(cx.ccx())), dst);\n     } else {"}, {"sha": "328c8e616c40b945d6aef7dbfbbebb633b429fd4", "filename": "src/librustc_trans/trans/basic_block.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fbasic_block.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fbasic_block.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fbasic_block.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -17,9 +17,7 @@ pub struct BasicBlock(pub BasicBlockRef);\n \n pub type Preds<'a> = Map<'a, Value, BasicBlock, Filter<'a, Value, Users>>;\n \n-/**\n- * Wrapper for LLVM BasicBlockRef\n- */\n+/// Wrapper for LLVM BasicBlockRef\n impl BasicBlock {\n     pub fn get(&self) -> BasicBlockRef {\n         let BasicBlock(v) = *self; v"}, {"sha": "5d713526a3d6aa0bdc1be0ce95413723bd7204b7", "filename": "src/librustc_trans/trans/callee.rs", "status": "modified", "additions": 28, "deletions": 43, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcallee.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcallee.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fcallee.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,13 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Handles translation of callees as well as other call-related\n- * things.  Callees are a superset of normal rust values and sometimes\n- * have different representations.  In particular, top-level fn items\n- * and methods are represented as just a fn ptr and not a full\n- * closure.\n- */\n+//! Handles translation of callees as well as other call-related\n+//! things.  Callees are a superset of normal rust values and sometimes\n+//! have different representations.  In particular, top-level fn items\n+//! and methods are represented as just a fn ptr and not a full\n+//! closure.\n \n pub use self::AutorefArg::*;\n pub use self::CalleeData::*;\n@@ -220,13 +218,9 @@ fn trans<'blk, 'tcx>(bcx: Block<'blk, 'tcx>, expr: &ast::Expr)\n     }\n }\n \n+/// Translates a reference (with id `ref_id`) to the fn/method with id `def_id` into a function\n+/// pointer. This may require monomorphization or inlining.\n pub fn trans_fn_ref(bcx: Block, def_id: ast::DefId, node: ExprOrMethodCall) -> ValueRef {\n-    /*!\n-     * Translates a reference (with id `ref_id`) to the fn/method\n-     * with id `def_id` into a function pointer.  This may require\n-     * monomorphization or inlining.\n-     */\n-\n     let _icx = push_ctxt(\"trans_fn_ref\");\n \n     let substs = node_id_substs(bcx, node);\n@@ -398,27 +392,24 @@ pub fn trans_unboxing_shim<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n     llfn\n }\n \n+/// Translates a reference to a fn/method item, monomorphizing and\n+/// inlining as it goes.\n+///\n+/// # Parameters\n+///\n+/// - `bcx`: the current block where the reference to the fn occurs\n+/// - `def_id`: def id of the fn or method item being referenced\n+/// - `node`: node id of the reference to the fn/method, if applicable.\n+///   This parameter may be zero; but, if so, the resulting value may not\n+///   have the right type, so it must be cast before being used.\n+/// - `substs`: values for each of the fn/method's parameters\n pub fn trans_fn_ref_with_substs<'blk, 'tcx>(\n     bcx: Block<'blk, 'tcx>,      //\n     def_id: ast::DefId,          // def id of fn\n     node: ExprOrMethodCall,      // node id of use of fn; may be zero if N/A\n     substs: subst::Substs<'tcx>) // vtables for the call\n     -> ValueRef\n {\n-    /*!\n-     * Translates a reference to a fn/method item, monomorphizing and\n-     * inlining as it goes.\n-     *\n-     * # Parameters\n-     *\n-     * - `bcx`: the current block where the reference to the fn occurs\n-     * - `def_id`: def id of the fn or method item being referenced\n-     * - `node`: node id of the reference to the fn/method, if applicable.\n-     *   This parameter may be zero; but, if so, the resulting value may not\n-     *   have the right type, so it must be cast before being used.\n-     * - `substs`: values for each of the fn/method's parameters\n-     */\n-\n     let _icx = push_ctxt(\"trans_fn_ref_with_substs\");\n     let ccx = bcx.ccx();\n     let tcx = bcx.tcx();\n@@ -668,6 +659,16 @@ pub fn trans_lang_call<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                              dest)\n }\n \n+/// This behemoth of a function translates function calls. Unfortunately, in order to generate more\n+/// efficient LLVM output at -O0, it has quite a complex signature (refactoring this into two\n+/// functions seems like a good idea).\n+///\n+/// In particular, for lang items, it is invoked with a dest of None, and in that case the return\n+/// value contains the result of the fn. The lang item must not return a structural type or else\n+/// all heck breaks loose.\n+///\n+/// For non-lang items, `dest` is always Some, and hence the result is written into memory\n+/// somewhere. Nonetheless we return the actual return value of the function.\n pub fn trans_call_inner<'a, 'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                         call_info: Option<NodeInfo>,\n                                         callee_ty: Ty<'tcx>,\n@@ -677,22 +678,6 @@ pub fn trans_call_inner<'a, 'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                         args: CallArgs<'a, 'tcx>,\n                                         dest: Option<expr::Dest>)\n                                         -> Result<'blk, 'tcx> {\n-    /*!\n-     * This behemoth of a function translates function calls.\n-     * Unfortunately, in order to generate more efficient LLVM\n-     * output at -O0, it has quite a complex signature (refactoring\n-     * this into two functions seems like a good idea).\n-     *\n-     * In particular, for lang items, it is invoked with a dest of\n-     * None, and in that case the return value contains the result of\n-     * the fn. The lang item must not return a structural type or else\n-     * all heck breaks loose.\n-     *\n-     * For non-lang items, `dest` is always Some, and hence the result\n-     * is written into memory somewhere. Nonetheless we return the\n-     * actual return value of the function.\n-     */\n-\n     // Introduce a temporary cleanup scope that will contain cleanups\n     // for the arguments while they are being evaluated. The purpose\n     // this cleanup is to ensure that, should a panic occur while"}, {"sha": "d7da83ddb0d04168957d6cb59fbe2700ab0680e5", "filename": "src/librustc_trans/trans/cleanup.rs", "status": "modified", "additions": 64, "deletions": 150, "changes": 214, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fcleanup.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * Code pertaining to cleanup of temporaries as well as execution of\n- * drop glue. See discussion in `doc.rs` for a high-level summary.\n- */\n+//! Code pertaining to cleanup of temporaries as well as execution of\n+//! drop glue. See discussion in `doc.rs` for a high-level summary.\n \n pub use self::ScopeId::*;\n pub use self::CleanupScopeKind::*;\n@@ -114,12 +112,8 @@ pub enum ScopeId {\n }\n \n impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n+    /// Invoked when we start to trans the code contained within a new cleanup scope.\n     fn push_ast_cleanup_scope(&self, debug_loc: NodeInfo) {\n-        /*!\n-         * Invoked when we start to trans the code contained\n-         * within a new cleanup scope.\n-         */\n-\n         debug!(\"push_ast_cleanup_scope({})\",\n                self.ccx.tcx().map.node_to_string(debug_loc.id));\n \n@@ -189,16 +183,12 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         CustomScopeIndex { index: index }\n     }\n \n+    /// Removes the cleanup scope for id `cleanup_scope`, which must be at the top of the cleanup\n+    /// stack, and generates the code to do its cleanups for normal exit.\n     fn pop_and_trans_ast_cleanup_scope(&self,\n                                        bcx: Block<'blk, 'tcx>,\n                                        cleanup_scope: ast::NodeId)\n                                        -> Block<'blk, 'tcx> {\n-        /*!\n-         * Removes the cleanup scope for id `cleanup_scope`, which\n-         * must be at the top of the cleanup stack, and generates the\n-         * code to do its cleanups for normal exit.\n-         */\n-\n         debug!(\"pop_and_trans_ast_cleanup_scope({})\",\n                self.ccx.tcx().map.node_to_string(cleanup_scope));\n \n@@ -208,15 +198,11 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.trans_scope_cleanups(bcx, &scope)\n     }\n \n+    /// Removes the loop cleanup scope for id `cleanup_scope`, which must be at the top of the\n+    /// cleanup stack. Does not generate any cleanup code, since loop scopes should exit by\n+    /// branching to a block generated by `normal_exit_block`.\n     fn pop_loop_cleanup_scope(&self,\n                               cleanup_scope: ast::NodeId) {\n-        /*!\n-         * Removes the loop cleanup scope for id `cleanup_scope`, which\n-         * must be at the top of the cleanup stack. Does not generate\n-         * any cleanup code, since loop scopes should exit by\n-         * branching to a block generated by `normal_exit_block`.\n-         */\n-\n         debug!(\"pop_loop_cleanup_scope({})\",\n                self.ccx.tcx().map.node_to_string(cleanup_scope));\n \n@@ -225,41 +211,30 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         let _ = self.pop_scope();\n     }\n \n+    /// Removes the top cleanup scope from the stack without executing its cleanups. The top\n+    /// cleanup scope must be the temporary scope `custom_scope`.\n     fn pop_custom_cleanup_scope(&self,\n                                 custom_scope: CustomScopeIndex) {\n-        /*!\n-         * Removes the top cleanup scope from the stack without\n-         * executing its cleanups. The top cleanup scope must\n-         * be the temporary scope `custom_scope`.\n-         */\n-\n         debug!(\"pop_custom_cleanup_scope({})\", custom_scope.index);\n         assert!(self.is_valid_to_pop_custom_scope(custom_scope));\n         let _ = self.pop_scope();\n     }\n \n+    /// Removes the top cleanup scope from the stack, which must be a temporary scope, and\n+    /// generates the code to do its cleanups for normal exit.\n     fn pop_and_trans_custom_cleanup_scope(&self,\n                                           bcx: Block<'blk, 'tcx>,\n                                           custom_scope: CustomScopeIndex)\n                                           -> Block<'blk, 'tcx> {\n-        /*!\n-         * Removes the top cleanup scope from the stack, which must be\n-         * a temporary scope, and generates the code to do its\n-         * cleanups for normal exit.\n-         */\n-\n         debug!(\"pop_and_trans_custom_cleanup_scope({})\", custom_scope);\n         assert!(self.is_valid_to_pop_custom_scope(custom_scope));\n \n         let scope = self.pop_scope();\n         self.trans_scope_cleanups(bcx, &scope)\n     }\n \n+    /// Returns the id of the top-most loop scope\n     fn top_loop_scope(&self) -> ast::NodeId {\n-        /*!\n-         * Returns the id of the top-most loop scope\n-         */\n-\n         for scope in self.scopes.borrow().iter().rev() {\n             match scope.kind {\n                 LoopScopeKind(id, _) => {\n@@ -271,24 +246,17 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.ccx.sess().bug(\"no loop scope found\");\n     }\n \n+    /// Returns a block to branch to which will perform all pending cleanups and then\n+    /// break/continue (depending on `exit`) out of the loop with id `cleanup_scope`\n     fn normal_exit_block(&'blk self,\n                          cleanup_scope: ast::NodeId,\n                          exit: uint) -> BasicBlockRef {\n-        /*!\n-         * Returns a block to branch to which will perform all pending\n-         * cleanups and then break/continue (depending on `exit`) out\n-         * of the loop with id `cleanup_scope`\n-         */\n-\n         self.trans_cleanups_to_exit_scope(LoopExit(cleanup_scope, exit))\n     }\n \n+    /// Returns a block to branch to which will perform all pending cleanups and then return from\n+    /// this function\n     fn return_exit_block(&'blk self) -> BasicBlockRef {\n-        /*!\n-         * Returns a block to branch to which will perform all pending\n-         * cleanups and then return from this function\n-         */\n-\n         self.trans_cleanups_to_exit_scope(ReturnExit)\n     }\n \n@@ -306,15 +274,11 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.schedule_clean(cleanup_scope, drop as CleanupObj);\n     }\n \n+    /// Schedules a (deep) drop of `val`, which is a pointer to an instance of `ty`\n     fn schedule_drop_mem(&self,\n                          cleanup_scope: ScopeId,\n                          val: ValueRef,\n                          ty: Ty<'tcx>) {\n-        /*!\n-         * Schedules a (deep) drop of `val`, which is a pointer to an\n-         * instance of `ty`\n-         */\n-\n         if !ty::type_needs_drop(self.ccx.tcx(), ty) { return; }\n         let drop = box DropValue {\n             is_immediate: false,\n@@ -332,15 +296,11 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.schedule_clean(cleanup_scope, drop as CleanupObj);\n     }\n \n+    /// Schedules a (deep) drop and zero-ing of `val`, which is a pointer to an instance of `ty`\n     fn schedule_drop_and_zero_mem(&self,\n                                   cleanup_scope: ScopeId,\n                                   val: ValueRef,\n                                   ty: Ty<'tcx>) {\n-        /*!\n-         * Schedules a (deep) drop and zero-ing of `val`, which is a pointer\n-         * to an instance of `ty`\n-         */\n-\n         if !ty::type_needs_drop(self.ccx.tcx(), ty) { return; }\n         let drop = box DropValue {\n             is_immediate: false,\n@@ -359,13 +319,11 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.schedule_clean(cleanup_scope, drop as CleanupObj);\n     }\n \n+    /// Schedules a (deep) drop of `val`, which is an instance of `ty`\n     fn schedule_drop_immediate(&self,\n                                cleanup_scope: ScopeId,\n                                val: ValueRef,\n                                ty: Ty<'tcx>) {\n-        /*!\n-         * Schedules a (deep) drop of `val`, which is an instance of `ty`\n-         */\n \n         if !ty::type_needs_drop(self.ccx.tcx(), ty) { return; }\n         let drop = box DropValue {\n@@ -384,16 +342,12 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.schedule_clean(cleanup_scope, drop as CleanupObj);\n     }\n \n+    /// Schedules a call to `free(val)`. Note that this is a shallow operation.\n     fn schedule_free_value(&self,\n                            cleanup_scope: ScopeId,\n                            val: ValueRef,\n                            heap: Heap,\n                            content_ty: Ty<'tcx>) {\n-        /*!\n-         * Schedules a call to `free(val)`. Note that this is a shallow\n-         * operation.\n-         */\n-\n         let drop = box FreeValue { ptr: val, heap: heap, content_ty: content_ty };\n \n         debug!(\"schedule_free_value({}, val={}, heap={})\",\n@@ -404,17 +358,13 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         self.schedule_clean(cleanup_scope, drop as CleanupObj);\n     }\n \n+    /// Schedules a call to `free(val)`. Note that this is a shallow operation.\n     fn schedule_free_slice(&self,\n                            cleanup_scope: ScopeId,\n                            val: ValueRef,\n                            size: ValueRef,\n                            align: ValueRef,\n                            heap: Heap) {\n-        /*!\n-         * Schedules a call to `free(val)`. Note that this is a shallow\n-         * operation.\n-         */\n-\n         let drop = box FreeSlice { ptr: val, size: size, align: align, heap: heap };\n \n         debug!(\"schedule_free_slice({}, val={}, heap={})\",\n@@ -434,15 +384,12 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         }\n     }\n \n+    /// Schedules a cleanup to occur upon exit from `cleanup_scope`. If `cleanup_scope` is not\n+    /// provided, then the cleanup is scheduled in the topmost scope, which must be a temporary\n+    /// scope.\n     fn schedule_clean_in_ast_scope(&self,\n                                    cleanup_scope: ast::NodeId,\n                                    cleanup: CleanupObj<'tcx>) {\n-        /*!\n-         * Schedules a cleanup to occur upon exit from `cleanup_scope`.\n-         * If `cleanup_scope` is not provided, then the cleanup is scheduled\n-         * in the topmost scope, which must be a temporary scope.\n-         */\n-\n         debug!(\"schedule_clean_in_ast_scope(cleanup_scope={})\",\n                cleanup_scope);\n \n@@ -462,14 +409,10 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n                     self.ccx.tcx().map.node_to_string(cleanup_scope)).as_slice());\n     }\n \n+    /// Schedules a cleanup to occur in the top-most scope, which must be a temporary scope.\n     fn schedule_clean_in_custom_scope(&self,\n                                       custom_scope: CustomScopeIndex,\n                                       cleanup: CleanupObj<'tcx>) {\n-        /*!\n-         * Schedules a cleanup to occur in the top-most scope,\n-         * which must be a temporary scope.\n-         */\n-\n         debug!(\"schedule_clean_in_custom_scope(custom_scope={})\",\n                custom_scope.index);\n \n@@ -481,22 +424,14 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n         scope.clear_cached_exits();\n     }\n \n+    /// Returns true if there are pending cleanups that should execute on panic.\n     fn needs_invoke(&self) -> bool {\n-        /*!\n-         * Returns true if there are pending cleanups that should\n-         * execute on panic.\n-         */\n-\n         self.scopes.borrow().iter().rev().any(|s| s.needs_invoke())\n     }\n \n+    /// Returns a basic block to branch to in the event of a panic. This block will run the panic\n+    /// cleanups and eventually invoke the LLVM `Resume` instruction.\n     fn get_landing_pad(&'blk self) -> BasicBlockRef {\n-        /*!\n-         * Returns a basic block to branch to in the event of a panic.\n-         * This block will run the panic cleanups and eventually\n-         * invoke the LLVM `Resume` instruction.\n-         */\n-\n         let _icx = base::push_ctxt(\"get_landing_pad\");\n \n         debug!(\"get_landing_pad\");\n@@ -529,10 +464,8 @@ impl<'blk, 'tcx> CleanupMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n }\n \n impl<'blk, 'tcx> CleanupHelperMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx> {\n+    /// Returns the id of the current top-most AST scope, if any.\n     fn top_ast_scope(&self) -> Option<ast::NodeId> {\n-        /*!\n-         * Returns the id of the current top-most AST scope, if any.\n-         */\n         for scope in self.scopes.borrow().iter().rev() {\n             match scope.kind {\n                 CustomScopeKind | LoopScopeKind(..) => {}\n@@ -559,10 +492,10 @@ impl<'blk, 'tcx> CleanupHelperMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx\n             (*scopes)[custom_scope.index].kind.is_temp()\n     }\n \n+    /// Generates the cleanups for `scope` into `bcx`\n     fn trans_scope_cleanups(&self, // cannot borrow self, will recurse\n                             bcx: Block<'blk, 'tcx>,\n                             scope: &CleanupScope<'blk, 'tcx>) -> Block<'blk, 'tcx> {\n-        /*! Generates the cleanups for `scope` into `bcx` */\n \n         let mut bcx = bcx;\n         if !bcx.unreachable.get() {\n@@ -593,37 +526,31 @@ impl<'blk, 'tcx> CleanupHelperMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx\n         f(self.scopes.borrow().last().unwrap())\n     }\n \n+    /// Used when the caller wishes to jump to an early exit, such as a return, break, continue, or\n+    /// unwind. This function will generate all cleanups between the top of the stack and the exit\n+    /// `label` and return a basic block that the caller can branch to.\n+    ///\n+    /// For example, if the current stack of cleanups were as follows:\n+    ///\n+    ///      AST 22\n+    ///      Custom 1\n+    ///      AST 23\n+    ///      Loop 23\n+    ///      Custom 2\n+    ///      AST 24\n+    ///\n+    /// and the `label` specifies a break from `Loop 23`, then this function would generate a\n+    /// series of basic blocks as follows:\n+    ///\n+    ///      Cleanup(AST 24) -> Cleanup(Custom 2) -> break_blk\n+    ///\n+    /// where `break_blk` is the block specified in `Loop 23` as the target for breaks. The return\n+    /// value would be the first basic block in that sequence (`Cleanup(AST 24)`). The caller could\n+    /// then branch to `Cleanup(AST 24)` and it will perform all cleanups and finally branch to the\n+    /// `break_blk`.\n     fn trans_cleanups_to_exit_scope(&'blk self,\n                                     label: EarlyExitLabel)\n                                     -> BasicBlockRef {\n-        /*!\n-         * Used when the caller wishes to jump to an early exit, such\n-         * as a return, break, continue, or unwind. This function will\n-         * generate all cleanups between the top of the stack and the\n-         * exit `label` and return a basic block that the caller can\n-         * branch to.\n-         *\n-         * For example, if the current stack of cleanups were as follows:\n-         *\n-         *      AST 22\n-         *      Custom 1\n-         *      AST 23\n-         *      Loop 23\n-         *      Custom 2\n-         *      AST 24\n-         *\n-         * and the `label` specifies a break from `Loop 23`, then this\n-         * function would generate a series of basic blocks as follows:\n-         *\n-         *      Cleanup(AST 24) -> Cleanup(Custom 2) -> break_blk\n-         *\n-         * where `break_blk` is the block specified in `Loop 23` as\n-         * the target for breaks. The return value would be the first\n-         * basic block in that sequence (`Cleanup(AST 24)`). The\n-         * caller could then branch to `Cleanup(AST 24)` and it will\n-         * perform all cleanups and finally branch to the `break_blk`.\n-         */\n-\n         debug!(\"trans_cleanups_to_exit_scope label={} scopes={}\",\n                label, self.scopes_len());\n \n@@ -756,20 +683,15 @@ impl<'blk, 'tcx> CleanupHelperMethods<'blk, 'tcx> for FunctionContext<'blk, 'tcx\n         prev_llbb\n     }\n \n+    /// Creates a landing pad for the top scope, if one does not exist.  The landing pad will\n+    /// perform all cleanups necessary for an unwind and then `resume` to continue error\n+    /// propagation:\n+    ///\n+    ///     landing_pad -> ... cleanups ... -> [resume]\n+    ///\n+    /// (The cleanups and resume instruction are created by `trans_cleanups_to_exit_scope()`, not\n+    /// in this function itself.)\n     fn get_or_create_landing_pad(&'blk self) -> BasicBlockRef {\n-        /*!\n-         * Creates a landing pad for the top scope, if one does not\n-         * exist.  The landing pad will perform all cleanups necessary\n-         * for an unwind and then `resume` to continue error\n-         * propagation:\n-         *\n-         *     landing_pad -> ... cleanups ... -> [resume]\n-         *\n-         * (The cleanups and resume instruction are created by\n-         * `trans_cleanups_to_exit_scope()`, not in this function\n-         * itself.)\n-         */\n-\n         let pad_bcx;\n \n         debug!(\"get_or_create_landing_pad\");\n@@ -883,19 +805,15 @@ impl<'blk, 'tcx> CleanupScope<'blk, 'tcx> {\n                               cleanup_block: blk });\n     }\n \n+    /// True if this scope has cleanups that need unwinding\n     fn needs_invoke(&self) -> bool {\n-        /*! True if this scope has cleanups that need unwinding */\n \n         self.cached_landing_pad.is_some() ||\n             self.cleanups.iter().any(|c| c.must_unwind())\n     }\n \n+    /// Returns a suitable name to use for the basic block that handles this cleanup scope\n     fn block_name(&self, prefix: &str) -> String {\n-        /*!\n-         * Returns a suitable name to use for the basic block that\n-         * handles this cleanup scope\n-         */\n-\n         match self.kind {\n             CustomScopeKind => format!(\"{}_custom_\", prefix),\n             AstScopeKind(id) => format!(\"{}_ast_{}_\", prefix, id),\n@@ -930,14 +848,10 @@ impl<'blk, 'tcx> CleanupScopeKind<'blk, 'tcx> {\n         }\n     }\n \n+    /// If this is a loop scope with id `id`, return the early exit block `exit`, else `None`\n     fn early_exit_block(&self,\n                         id: ast::NodeId,\n                         exit: uint) -> Option<BasicBlockRef> {\n-        /*!\n-         * If this is a loop scope with id `id`, return the early\n-         * exit block `exit`, else `None`\n-         */\n-\n         match *self {\n             LoopScopeKind(i, ref exits) if id == i => Some(exits[exit].llbb),\n             _ => None,"}, {"sha": "2f82b8286c2d531da021e90752b4eba7b025b56f", "filename": "src/librustc_trans/trans/closure.rs", "status": "modified", "additions": 9, "deletions": 13, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fclosure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fclosure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fclosure.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -386,26 +386,22 @@ impl<'a, 'tcx> ClosureEnv<'a, 'tcx> {\n     }\n }\n \n+/// Translates the body of a closure expression.\n+///\n+/// - `store`\n+/// - `decl`\n+/// - `body`\n+/// - `id`: The id of the closure expression.\n+/// - `cap_clause`: information about captured variables, if any.\n+/// - `dest`: where to write the closure value, which must be a\n+///   (fn ptr, env) pair\n pub fn trans_expr_fn<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                  store: ty::TraitStore,\n                                  decl: &ast::FnDecl,\n                                  body: &ast::Block,\n                                  id: ast::NodeId,\n                                  dest: expr::Dest)\n                                  -> Block<'blk, 'tcx> {\n-    /*!\n-     *\n-     * Translates the body of a closure expression.\n-     *\n-     * - `store`\n-     * - `decl`\n-     * - `body`\n-     * - `id`: The id of the closure expression.\n-     * - `cap_clause`: information about captured variables, if any.\n-     * - `dest`: where to write the closure value, which must be a\n-         (fn ptr, env) pair\n-     */\n-\n     let _icx = push_ctxt(\"closure::trans_expr_fn\");\n \n     let dest_addr = match dest {"}, {"sha": "febb33f6c54aff7db2476556317d18cf3705d801", "filename": "src/librustc_trans/trans/common.rs", "status": "modified", "additions": 8, "deletions": 20, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fcommon.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -95,26 +95,19 @@ pub fn type_is_immediate<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>, ty: Ty<'tcx>) -\n     }\n }\n \n+/// Identify types which have size zero at runtime.\n pub fn type_is_zero_size<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>, ty: Ty<'tcx>) -> bool {\n-    /*!\n-     * Identify types which have size zero at runtime.\n-     */\n-\n     use trans::machine::llsize_of_alloc;\n     use trans::type_of::sizing_type_of;\n     let llty = sizing_type_of(ccx, ty);\n     llsize_of_alloc(ccx, llty) == 0\n }\n \n+/// Identifies types which we declare to be equivalent to `void` in C for the purpose of function\n+/// return types. These are `()`, bot, and uninhabited enums. Note that all such types are also\n+/// zero-size, but not all zero-size types use a `void` return type (in order to aid with C ABI\n+/// compatibility).\n pub fn return_type_is_void(ccx: &CrateContext, ty: Ty) -> bool {\n-    /*!\n-     * Identifies types which we declare to be equivalent to `void`\n-     * in C for the purpose of function return types. These are\n-     * `()`, bot, and uninhabited enums. Note that all such types\n-     * are also zero-size, but not all zero-size types use a `void`\n-     * return type (in order to aid with C ABI compatibility).\n-     */\n-\n     ty::type_is_nil(ty) || ty::type_is_empty(ccx.tcx(), ty)\n }\n \n@@ -768,19 +761,14 @@ pub fn expr_ty_adjusted<'blk, 'tcx>(bcx: Block<'blk, 'tcx>, ex: &ast::Expr) -> T\n     monomorphize_type(bcx, ty::expr_ty_adjusted(bcx.tcx(), ex))\n }\n \n+/// Attempts to resolve an obligation. The result is a shallow vtable resolution -- meaning that we\n+/// do not (necessarily) resolve all nested obligations on the impl. Note that type check should\n+/// guarantee to us that all nested obligations *could be* resolved if we wanted to.\n pub fn fulfill_obligation<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n                                     span: Span,\n                                     trait_ref: Rc<ty::TraitRef<'tcx>>)\n                                     -> traits::Vtable<'tcx, ()>\n {\n-    /*!\n-     * Attempts to resolve an obligation. The result is a shallow\n-     * vtable resolution -- meaning that we do not (necessarily) resolve\n-     * all nested obligations on the impl. Note that type check should\n-     * guarantee to us that all nested obligations *could be* resolved\n-     * if we wanted to.\n-     */\n-\n     let tcx = ccx.tcx();\n \n     // Remove any references to regions; this helps improve caching."}, {"sha": "f0fd94958ee97a2d68d6c336b42e540fd5e98f41", "filename": "src/librustc_trans/trans/datum.rs", "status": "modified", "additions": 67, "deletions": 148, "changes": 215, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdatum.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,10 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n- * See the section on datums in `doc.rs` for an overview of what\n- * Datums are and how they are intended to be used.\n- */\n+//! See the section on datums in `doc.rs` for an overview of what Datums are and how they are\n+//! intended to be used.\n \n pub use self::Expr::*;\n pub use self::RvalueMode::*;\n@@ -31,12 +29,10 @@ use util::ppaux::{ty_to_string};\n use std::fmt;\n use syntax::ast;\n \n-/**\n- * A `Datum` encapsulates the result of evaluating an expression.  It\n- * describes where the value is stored, what Rust type the value has,\n- * whether it is addressed by reference, and so forth. Please refer\n- * the section on datums in `doc.rs` for more details.\n- */\n+/// A `Datum` encapsulates the result of evaluating an expression.  It\n+/// describes where the value is stored, what Rust type the value has,\n+/// whether it is addressed by reference, and so forth. Please refer\n+/// the section on datums in `doc.rs` for more details.\n #[deriving(Clone)]\n pub struct Datum<'tcx, K> {\n     /// The llvm value.  This is either a pointer to the Rust value or\n@@ -107,6 +103,10 @@ pub fn immediate_rvalue_bcx<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n }\n \n \n+/// Allocates temporary space on the stack using alloca() and returns a by-ref Datum pointing to\n+/// it. The memory will be dropped upon exit from `scope`. The callback `populate` should\n+/// initialize the memory. If `zero` is true, the space will be zeroed when it is allocated; this\n+/// is not necessary unless `bcx` does not dominate the end of `scope`.\n pub fn lvalue_scratch_datum<'blk, 'tcx, A>(bcx: Block<'blk, 'tcx>,\n                                            ty: Ty<'tcx>,\n                                            name: &str,\n@@ -116,15 +116,6 @@ pub fn lvalue_scratch_datum<'blk, 'tcx, A>(bcx: Block<'blk, 'tcx>,\n                                            populate: |A, Block<'blk, 'tcx>, ValueRef|\n                                                       -> Block<'blk, 'tcx>)\n                                           -> DatumBlock<'blk, 'tcx, Lvalue> {\n-    /*!\n-     * Allocates temporary space on the stack using alloca() and\n-     * returns a by-ref Datum pointing to it. The memory will be\n-     * dropped upon exit from `scope`. The callback `populate` should\n-     * initialize the memory. If `zero` is true, the space will be\n-     * zeroed when it is allocated; this is not necessary unless `bcx`\n-     * does not dominate the end of `scope`.\n-     */\n-\n     let scratch = if zero {\n         alloca_zeroed(bcx, ty, name)\n     } else {\n@@ -140,33 +131,24 @@ pub fn lvalue_scratch_datum<'blk, 'tcx, A>(bcx: Block<'blk, 'tcx>,\n     DatumBlock::new(bcx, Datum::new(scratch, ty, Lvalue))\n }\n \n+/// Allocates temporary space on the stack using alloca() and returns a by-ref Datum pointing to\n+/// it.  If `zero` is true, the space will be zeroed when it is allocated; this is normally not\n+/// necessary, but in the case of automatic rooting in match statements it is possible to have\n+/// temporaries that may not get initialized if a certain arm is not taken, so we must zero them.\n+/// You must arrange any cleanups etc yourself!\n pub fn rvalue_scratch_datum<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                         ty: Ty<'tcx>,\n                                         name: &str)\n                                         -> Datum<'tcx, Rvalue> {\n-    /*!\n-     * Allocates temporary space on the stack using alloca() and\n-     * returns a by-ref Datum pointing to it.  If `zero` is true, the\n-     * space will be zeroed when it is allocated; this is normally not\n-     * necessary, but in the case of automatic rooting in match\n-     * statements it is possible to have temporaries that may not get\n-     * initialized if a certain arm is not taken, so we must zero\n-     * them. You must arrange any cleanups etc yourself!\n-     */\n-\n     let llty = type_of::type_of(bcx.ccx(), ty);\n     let scratch = alloca(bcx, llty, name);\n     Datum::new(scratch, ty, Rvalue::new(ByRef))\n }\n \n+/// Indicates the \"appropriate\" mode for this value, which is either by ref or by value, depending\n+/// on whether type is immediate or not.\n pub fn appropriate_rvalue_mode<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>,\n                                          ty: Ty<'tcx>) -> RvalueMode {\n-    /*!\n-     * Indicates the \"appropriate\" mode for this value,\n-     * which is either by ref or by value, depending\n-     * on whether type is immediate or not.\n-     */\n-\n     if type_is_immediate(ccx, ty) {\n         ByValue\n     } else {\n@@ -190,25 +172,19 @@ fn add_rvalue_clean<'a, 'tcx>(mode: RvalueMode,\n \n pub trait KindOps {\n \n-    /**\n-     * Take appropriate action after the value in `datum` has been\n-     * stored to a new location.\n-     */\n+    /// Take appropriate action after the value in `datum` has been\n+    /// stored to a new location.\n     fn post_store<'blk, 'tcx>(&self,\n                               bcx: Block<'blk, 'tcx>,\n                               val: ValueRef,\n                               ty: Ty<'tcx>)\n                               -> Block<'blk, 'tcx>;\n \n-    /**\n-     * True if this mode is a reference mode, meaning that the datum's\n-     * val field is a pointer to the actual value\n-     */\n+    /// True if this mode is a reference mode, meaning that the datum's\n+    /// val field is a pointer to the actual value\n     fn is_by_ref(&self) -> bool;\n \n-    /**\n-     * Converts to an Expr kind\n-     */\n+    /// Converts to an Expr kind\n     fn to_expr_kind(self) -> Expr;\n \n }\n@@ -234,17 +210,13 @@ impl KindOps for Rvalue {\n }\n \n impl KindOps for Lvalue {\n+    /// If an lvalue is moved, we must zero out the memory in which it resides so as to cancel\n+    /// cleanup. If an @T lvalue is copied, we must increment the reference count.\n     fn post_store<'blk, 'tcx>(&self,\n                               bcx: Block<'blk, 'tcx>,\n                               val: ValueRef,\n                               ty: Ty<'tcx>)\n                               -> Block<'blk, 'tcx> {\n-        /*!\n-         * If an lvalue is moved, we must zero out the memory in which\n-         * it resides so as to cancel cleanup. If an @T lvalue is\n-         * copied, we must increment the reference count.\n-         */\n-\n         if ty::type_needs_drop(bcx.tcx(), ty) {\n             // cancel cleanup of affine values by zeroing out\n             let () = zero_mem(bcx, val, ty);\n@@ -288,31 +260,24 @@ impl KindOps for Expr {\n }\n \n impl<'tcx> Datum<'tcx, Rvalue> {\n+    /// Schedules a cleanup for this datum in the given scope. That means that this datum is no\n+    /// longer an rvalue datum; hence, this function consumes the datum and returns the contained\n+    /// ValueRef.\n     pub fn add_clean<'a>(self,\n                          fcx: &FunctionContext<'a, 'tcx>,\n                          scope: cleanup::ScopeId)\n                          -> ValueRef {\n-        /*!\n-         * Schedules a cleanup for this datum in the given scope.\n-         * That means that this datum is no longer an rvalue datum;\n-         * hence, this function consumes the datum and returns the\n-         * contained ValueRef.\n-         */\n-\n         add_rvalue_clean(self.kind.mode, fcx, scope, self.val, self.ty);\n         self.val\n     }\n \n+    /// Returns an lvalue datum (that is, a by ref datum with cleanup scheduled). If `self` is not\n+    /// already an lvalue, cleanup will be scheduled in the temporary scope for `expr_id`.\n     pub fn to_lvalue_datum_in_scope<'blk>(self,\n                                           bcx: Block<'blk, 'tcx>,\n                                           name: &str,\n                                           scope: cleanup::ScopeId)\n                                           -> DatumBlock<'blk, 'tcx, Lvalue> {\n-        /*!\n-         * Returns an lvalue datum (that is, a by ref datum with\n-         * cleanup scheduled). If `self` is not already an lvalue,\n-         * cleanup will be scheduled in the temporary scope for `expr_id`.\n-         */\n         let fcx = bcx.fcx;\n \n         match self.kind.mode {\n@@ -361,14 +326,12 @@ impl<'tcx> Datum<'tcx, Rvalue> {\n     }\n }\n \n-/**\n- * Methods suitable for \"expr\" datums that could be either lvalues or\n- * rvalues. These include coercions into lvalues/rvalues but also a number\n- * of more general operations. (Some of those operations could be moved to\n- * the more general `impl<K> Datum<K>`, but it's convenient to have them\n- * here since we can `match self.kind` rather than having to implement\n- * generic methods in `KindOps`.)\n- */\n+/// Methods suitable for \"expr\" datums that could be either lvalues or\n+/// rvalues. These include coercions into lvalues/rvalues but also a number\n+/// of more general operations. (Some of those operations could be moved to\n+/// the more general `impl<K> Datum<K>`, but it's convenient to have them\n+/// here since we can `match self.kind` rather than having to implement\n+/// generic methods in `KindOps`.)\n impl<'tcx> Datum<'tcx, Expr> {\n     fn match_kind<R>(self,\n                      if_lvalue: |Datum<'tcx, Lvalue>| -> R,\n@@ -381,22 +344,16 @@ impl<'tcx> Datum<'tcx, Expr> {\n         }\n     }\n \n+    /// Asserts that this datum *is* an lvalue and returns it.\n     #[allow(dead_code)] // potentially useful\n     pub fn assert_lvalue(self, bcx: Block) -> Datum<'tcx, Lvalue> {\n-        /*!\n-         * Asserts that this datum *is* an lvalue and returns it.\n-         */\n-\n         self.match_kind(\n             |d| d,\n             |_| bcx.sess().bug(\"assert_lvalue given rvalue\"))\n     }\n \n+    /// Asserts that this datum *is* an lvalue and returns it.\n     pub fn assert_rvalue(self, bcx: Block) -> Datum<'tcx, Rvalue> {\n-        /*!\n-         * Asserts that this datum *is* an lvalue and returns it.\n-         */\n-\n         self.match_kind(\n             |_| bcx.sess().bug(\"assert_rvalue given lvalue\"),\n             |r| r)\n@@ -418,14 +375,11 @@ impl<'tcx> Datum<'tcx, Expr> {\n         }\n     }\n \n+    /// Arranges cleanup for `self` if it is an rvalue. Use when you are done working with a value\n+    /// that may need drop.\n     pub fn add_clean_if_rvalue<'blk>(self,\n                                      bcx: Block<'blk, 'tcx>,\n                                      expr_id: ast::NodeId) {\n-        /*!\n-         * Arranges cleanup for `self` if it is an rvalue. Use when\n-         * you are done working with a value that may need drop.\n-         */\n-\n         self.match_kind(\n             |_| { /* Nothing to do, cleanup already arranged */ },\n             |r| {\n@@ -434,16 +388,12 @@ impl<'tcx> Datum<'tcx, Expr> {\n             })\n     }\n \n+    /// Ensures that `self` will get cleaned up, if it is not an lvalue already.\n     pub fn clean<'blk>(self,\n                        bcx: Block<'blk, 'tcx>,\n                        name: &'static str,\n                        expr_id: ast::NodeId)\n                        -> Block<'blk, 'tcx> {\n-        /*!\n-         * Ensures that `self` will get cleaned up, if it is not an lvalue\n-         * already.\n-         */\n-\n         self.to_lvalue_datum(bcx, name, expr_id).bcx\n     }\n \n@@ -464,15 +414,11 @@ impl<'tcx> Datum<'tcx, Expr> {\n             })\n     }\n \n+    /// Ensures that we have an rvalue datum (that is, a datum with no cleanup scheduled).\n     pub fn to_rvalue_datum<'blk>(self,\n                                  bcx: Block<'blk, 'tcx>,\n                                  name: &'static str)\n                                  -> DatumBlock<'blk, 'tcx, Rvalue> {\n-        /*!\n-         * Ensures that we have an rvalue datum (that is, a datum with\n-         * no cleanup scheduled).\n-         */\n-\n         self.match_kind(\n             |l| {\n                 let mut bcx = bcx;\n@@ -494,19 +440,14 @@ impl<'tcx> Datum<'tcx, Expr> {\n \n }\n \n-/**\n- * Methods suitable only for lvalues. These include the various\n- * operations to extract components out of compound data structures,\n- * such as extracting the field from a struct or a particular element\n- * from an array.\n- */\n+/// Methods suitable only for lvalues. These include the various\n+/// operations to extract components out of compound data structures,\n+/// such as extracting the field from a struct or a particular element\n+/// from an array.\n impl<'tcx> Datum<'tcx, Lvalue> {\n+    /// Converts a datum into a by-ref value. The datum type must be one which is always passed by\n+    /// reference.\n     pub fn to_llref(self) -> ValueRef {\n-        /*!\n-         * Converts a datum into a by-ref value. The datum type must\n-         * be one which is always passed by reference.\n-         */\n-\n         self.val\n     }\n \n@@ -542,9 +483,7 @@ impl<'tcx> Datum<'tcx, Lvalue> {\n     }\n }\n \n-/**\n- * Generic methods applicable to any sort of datum.\n- */\n+/// Generic methods applicable to any sort of datum.\n impl<'tcx, K: KindOps + fmt::Show> Datum<'tcx, K> {\n     pub fn new(val: ValueRef, ty: Ty<'tcx>, kind: K) -> Datum<'tcx, K> {\n         Datum { val: val, ty: ty, kind: kind }\n@@ -555,40 +494,30 @@ impl<'tcx, K: KindOps + fmt::Show> Datum<'tcx, K> {\n         Datum { val: val, ty: ty, kind: kind.to_expr_kind() }\n     }\n \n+    /// Moves or copies this value into a new home, as appropriate depending on the type of the\n+    /// datum. This method consumes the datum, since it would be incorrect to go on using the datum\n+    /// if the value represented is affine (and hence the value is moved).\n     pub fn store_to<'blk>(self,\n                           bcx: Block<'blk, 'tcx>,\n                           dst: ValueRef)\n                           -> Block<'blk, 'tcx> {\n-        /*!\n-         * Moves or copies this value into a new home, as appropriate\n-         * depending on the type of the datum. This method consumes\n-         * the datum, since it would be incorrect to go on using the\n-         * datum if the value represented is affine (and hence the value\n-         * is moved).\n-         */\n-\n         self.shallow_copy_raw(bcx, dst);\n \n         self.kind.post_store(bcx, self.val, self.ty)\n     }\n \n+    /// Helper function that performs a shallow copy of this value into `dst`, which should be a\n+    /// pointer to a memory location suitable for `self.ty`. `dst` should contain uninitialized\n+    /// memory (either newly allocated, zeroed, or dropped).\n+    ///\n+    /// This function is private to datums because it leaves memory in an unstable state, where the\n+    /// source value has been copied but not zeroed. Public methods are `store_to` (if you no\n+    /// longer need the source value) or `shallow_copy` (if you wish the source value to remain\n+    /// valid).\n     fn shallow_copy_raw<'blk>(&self,\n                               bcx: Block<'blk, 'tcx>,\n                               dst: ValueRef)\n                               -> Block<'blk, 'tcx> {\n-        /*!\n-         * Helper function that performs a shallow copy of this value\n-         * into `dst`, which should be a pointer to a memory location\n-         * suitable for `self.ty`. `dst` should contain uninitialized\n-         * memory (either newly allocated, zeroed, or dropped).\n-         *\n-         * This function is private to datums because it leaves memory\n-         * in an unstable state, where the source value has been\n-         * copied but not zeroed. Public methods are `store_to`\n-         * (if you no longer need the source value) or `shallow_copy`\n-         * (if you wish the source value to remain valid).\n-         */\n-\n         let _icx = push_ctxt(\"copy_to_no_check\");\n \n         if type_is_zero_size(bcx.ccx(), self.ty) {\n@@ -604,17 +533,13 @@ impl<'tcx, K: KindOps + fmt::Show> Datum<'tcx, K> {\n         return bcx;\n     }\n \n+    /// Copies the value into a new location. This function always preserves the existing datum as\n+    /// a valid value. Therefore, it does not consume `self` and, also, cannot be applied to affine\n+    /// values (since they must never be duplicated).\n     pub fn shallow_copy<'blk>(&self,\n                               bcx: Block<'blk, 'tcx>,\n                               dst: ValueRef)\n                               -> Block<'blk, 'tcx> {\n-        /*!\n-         * Copies the value into a new location. This function always\n-         * preserves the existing datum as a valid value. Therefore,\n-         * it does not consume `self` and, also, cannot be applied to\n-         * affine values (since they must never be duplicated).\n-         */\n-\n         assert!(!ty::type_moves_by_default(bcx.tcx(), self.ty));\n         self.shallow_copy_raw(bcx, dst)\n     }\n@@ -627,23 +552,17 @@ impl<'tcx, K: KindOps + fmt::Show> Datum<'tcx, K> {\n                 self.kind)\n     }\n \n+    /// See the `appropriate_rvalue_mode()` function\n     pub fn appropriate_rvalue_mode<'a>(&self, ccx: &CrateContext<'a, 'tcx>)\n                                        -> RvalueMode {\n-        /*! See the `appropriate_rvalue_mode()` function */\n-\n         appropriate_rvalue_mode(ccx, self.ty)\n     }\n \n+    /// Converts `self` into a by-value `ValueRef`. Consumes this datum (i.e., absolves you of\n+    /// responsibility to cleanup the value). For this to work, the value must be something\n+    /// scalar-ish (like an int or a pointer) which (1) does not require drop glue and (2) is\n+    /// naturally passed around by value, and not by reference.\n     pub fn to_llscalarish<'blk>(self, bcx: Block<'blk, 'tcx>) -> ValueRef {\n-        /*!\n-         * Converts `self` into a by-value `ValueRef`. Consumes this\n-         * datum (i.e., absolves you of responsibility to cleanup the\n-         * value). For this to work, the value must be something\n-         * scalar-ish (like an int or a pointer) which (1) does not\n-         * require drop glue and (2) is naturally passed around by\n-         * value, and not by reference.\n-         */\n-\n         assert!(!ty::type_needs_drop(bcx.tcx(), self.ty));\n         assert!(self.appropriate_rvalue_mode(bcx.ccx()) == ByValue);\n         if self.kind.is_by_ref() {"}, {"sha": "c35de3209c61f087566f87ab65495783bdf0c5cd", "filename": "src/librustc_trans/trans/debuginfo.rs", "status": "modified", "additions": 174, "deletions": 175, "changes": 349, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdebuginfo.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad", "patch": "@@ -8,181 +8,180 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-/*!\n-# Debug Info Module\n-\n-This module serves the purpose of generating debug symbols. We use LLVM's\n-[source level debugging](http://llvm.org/docs/SourceLevelDebugging.html)\n-features for generating the debug information. The general principle is this:\n-\n-Given the right metadata in the LLVM IR, the LLVM code generator is able to\n-create DWARF debug symbols for the given code. The\n-[metadata](http://llvm.org/docs/LangRef.html#metadata-type) is structured much\n-like DWARF *debugging information entries* (DIE), representing type information\n-such as datatype layout, function signatures, block layout, variable location\n-and scope information, etc. It is the purpose of this module to generate correct\n-metadata and insert it into the LLVM IR.\n-\n-As the exact format of metadata trees may change between different LLVM\n-versions, we now use LLVM\n-[DIBuilder](http://llvm.org/docs/doxygen/html/classllvm_1_1DIBuilder.html) to\n-create metadata where possible. This will hopefully ease the adaption of this\n-module to future LLVM versions.\n-\n-The public API of the module is a set of functions that will insert the correct\n-metadata into the LLVM IR when called with the right parameters. The module is\n-thus driven from an outside client with functions like\n-`debuginfo::create_local_var_metadata(bcx: block, local: &ast::local)`.\n-\n-Internally the module will try to reuse already created metadata by utilizing a\n-cache. The way to get a shared metadata node when needed is thus to just call\n-the corresponding function in this module:\n-\n-    let file_metadata = file_metadata(crate_context, path);\n-\n-The function will take care of probing the cache for an existing node for that\n-exact file path.\n-\n-All private state used by the module is stored within either the\n-CrateDebugContext struct (owned by the CrateContext) or the FunctionDebugContext\n-(owned by the FunctionContext).\n-\n-This file consists of three conceptual sections:\n-1. The public interface of the module\n-2. Module-internal metadata creation functions\n-3. Minor utility functions\n-\n-\n-## Recursive Types\n-\n-Some kinds of types, such as structs and enums can be recursive. That means that\n-the type definition of some type X refers to some other type which in turn\n-(transitively) refers to X. This introduces cycles into the type referral graph.\n-A naive algorithm doing an on-demand, depth-first traversal of this graph when\n-describing types, can get trapped in an endless loop when it reaches such a\n-cycle.\n-\n-For example, the following simple type for a singly-linked list...\n-\n-```\n-struct List {\n-    value: int,\n-    tail: Option<Box<List>>,\n-}\n-```\n-\n-will generate the following callstack with a naive DFS algorithm:\n-\n-```\n-describe(t = List)\n-  describe(t = int)\n-  describe(t = Option<Box<List>>)\n-    describe(t = Box<List>)\n-      describe(t = List) // at the beginning again...\n-      ...\n-```\n-\n-To break cycles like these, we use \"forward declarations\". That is, when the\n-algorithm encounters a possibly recursive type (any struct or enum), it\n-immediately creates a type description node and inserts it into the cache\n-*before* describing the members of the type. This type description is just a\n-stub (as type members are not described and added to it yet) but it allows the\n-algorithm to already refer to the type. After the stub is inserted into the\n-cache, the algorithm continues as before. If it now encounters a recursive\n-reference, it will hit the cache and does not try to describe the type anew.\n-\n-This behaviour is encapsulated in the 'RecursiveTypeDescription' enum, which\n-represents a kind of continuation, storing all state needed to continue\n-traversal at the type members after the type has been registered with the cache.\n-(This implementation approach might be a tad over-engineered and may change in\n-the future)\n-\n-\n-## Source Locations and Line Information\n-\n-In addition to data type descriptions the debugging information must also allow\n-to map machine code locations back to source code locations in order to be useful.\n-This functionality is also handled in this module. The following functions allow\n-to control source mappings:\n-\n-+ set_source_location()\n-+ clear_source_location()\n-+ start_emitting_source_locations()\n-\n-`set_source_location()` allows to set the current source location. All IR\n-instructions created after a call to this function will be linked to the given\n-source location, until another location is specified with\n-`set_source_location()` or the source location is cleared with\n-`clear_source_location()`. In the later case, subsequent IR instruction will not\n-be linked to any source location. As you can see, this is a stateful API\n-(mimicking the one in LLVM), so be careful with source locations set by previous\n-calls. It's probably best to not rely on any specific state being present at a\n-given point in code.\n-\n-One topic that deserves some extra attention is *function prologues*. At the\n-beginning of a function's machine code there are typically a few instructions\n-for loading argument values into allocas and checking if there's enough stack\n-space for the function to execute. This *prologue* is not visible in the source\n-code and LLVM puts a special PROLOGUE END marker into the line table at the\n-first non-prologue instruction of the function. In order to find out where the\n-prologue ends, LLVM looks for the first instruction in the function body that is\n-linked to a source location. So, when generating prologue instructions we have\n-to make sure that we don't emit source location information until the 'real'\n-function body begins. For this reason, source location emission is disabled by\n-default for any new function being translated and is only activated after a call\n-to the third function from the list above, `start_emitting_source_locations()`.\n-This function should be called right before regularly starting to translate the\n-top-level block of the given function.\n-\n-There is one exception to the above rule: `llvm.dbg.declare` instruction must be\n-linked to the source location of the variable being declared. For function\n-parameters these `llvm.dbg.declare` instructions typically occur in the middle\n-of the prologue, however, they are ignored by LLVM's prologue detection. The\n-`create_argument_metadata()` and related functions take care of linking the\n-`llvm.dbg.declare` instructions to the correct source locations even while\n-source location emission is still disabled, so there is no need to do anything\n-special with source location handling here.\n-\n-## Unique Type Identification\n-\n-In order for link-time optimization to work properly, LLVM needs a unique type\n-identifier that tells it across compilation units which types are the same as\n-others. This type identifier is created by TypeMap::get_unique_type_id_of_type()\n-using the following algorithm:\n-\n-(1) Primitive types have their name as ID\n-(2) Structs, enums and traits have a multipart identifier\n-\n-    (1) The first part is the SVH (strict version hash) of the crate they were\n-        originally defined in\n-\n-    (2) The second part is the ast::NodeId of the definition in their original\n-        crate\n-\n-    (3) The final part is a concatenation of the type IDs of their concrete type\n-        arguments if they are generic types.\n-\n-(3) Tuple-, pointer and function types are structurally identified, which means\n-    that they are equivalent if their component types are equivalent (i.e. (int,\n-    int) is the same regardless in which crate it is used).\n-\n-This algorithm also provides a stable ID for types that are defined in one crate\n-but instantiated from metadata within another crate. We just have to take care\n-to always map crate and node IDs back to the original crate context.\n-\n-As a side-effect these unique type IDs also help to solve a problem arising from\n-lifetime parameters. Since lifetime parameters are completely omitted in\n-debuginfo, more than one `Ty` instance may map to the same debuginfo type\n-metadata, that is, some struct `Struct<'a>` may have N instantiations with\n-different concrete substitutions for `'a`, and thus there will be N `Ty`\n-instances for the type `Struct<'a>` even though it is not generic otherwise.\n-Unfortunately this means that we cannot use `ty::type_id()` as cheap identifier\n-for type metadata---we have done this in the past, but it led to unnecessary\n-metadata duplication in the best case and LLVM assertions in the worst. However,\n-the unique type ID as described above *can* be used as identifier. Since it is\n-comparatively expensive to construct, though, `ty::type_id()` is still used\n-additionally as an optimization for cases where the exact same type has been\n-seen before (which is most of the time). */\n+//! # Debug Info Module\n+//!\n+//! This module serves the purpose of generating debug symbols. We use LLVM's\n+//! [source level debugging](http://llvm.org/docs/SourceLevelDebugging.html)\n+//! features for generating the debug information. The general principle is this:\n+//!\n+//! Given the right metadata in the LLVM IR, the LLVM code generator is able to\n+//! create DWARF debug symbols for the given code. The\n+//! [metadata](http://llvm.org/docs/LangRef.html#metadata-type) is structured much\n+//! like DWARF *debugging information entries* (DIE), representing type information\n+//! such as datatype layout, function signatures, block layout, variable location\n+//! and scope information, etc. It is the purpose of this module to generate correct\n+//! metadata and insert it into the LLVM IR.\n+//!\n+//! As the exact format of metadata trees may change between different LLVM\n+//! versions, we now use LLVM\n+//! [DIBuilder](http://llvm.org/docs/doxygen/html/classllvm_1_1DIBuilder.html) to\n+//! create metadata where possible. This will hopefully ease the adaption of this\n+//! module to future LLVM versions.\n+//!\n+//! The public API of the module is a set of functions that will insert the correct\n+//! metadata into the LLVM IR when called with the right parameters. The module is\n+//! thus driven from an outside client with functions like\n+//! `debuginfo::create_local_var_metadata(bcx: block, local: &ast::local)`.\n+//!\n+//! Internally the module will try to reuse already created metadata by utilizing a\n+//! cache. The way to get a shared metadata node when needed is thus to just call\n+//! the corresponding function in this module:\n+//!\n+//!     let file_metadata = file_metadata(crate_context, path);\n+//!\n+//! The function will take care of probing the cache for an existing node for that\n+//! exact file path.\n+//!\n+//! All private state used by the module is stored within either the\n+//! CrateDebugContext struct (owned by the CrateContext) or the FunctionDebugContext\n+//! (owned by the FunctionContext).\n+//!\n+//! This file consists of three conceptual sections:\n+//! 1. The public interface of the module\n+//! 2. Module-internal metadata creation functions\n+//! 3. Minor utility functions\n+//!\n+//!\n+//! ## Recursive Types\n+//!\n+//! Some kinds of types, such as structs and enums can be recursive. That means that\n+//! the type definition of some type X refers to some other type which in turn\n+//! (transitively) refers to X. This introduces cycles into the type referral graph.\n+//! A naive algorithm doing an on-demand, depth-first traversal of this graph when\n+//! describing types, can get trapped in an endless loop when it reaches such a\n+//! cycle.\n+//!\n+//! For example, the following simple type for a singly-linked list...\n+//!\n+//! ```\n+//! struct List {\n+//!     value: int,\n+//!     tail: Option<Box<List>>,\n+//! }\n+//! ```\n+//!\n+//! will generate the following callstack with a naive DFS algorithm:\n+//!\n+//! ```\n+//! describe(t = List)\n+//!   describe(t = int)\n+//!   describe(t = Option<Box<List>>)\n+//!     describe(t = Box<List>)\n+//!       describe(t = List) // at the beginning again...\n+//!       ...\n+//! ```\n+//!\n+//! To break cycles like these, we use \"forward declarations\". That is, when the\n+//! algorithm encounters a possibly recursive type (any struct or enum), it\n+//! immediately creates a type description node and inserts it into the cache\n+//! *before* describing the members of the type. This type description is just a\n+//! stub (as type members are not described and added to it yet) but it allows the\n+//! algorithm to already refer to the type. After the stub is inserted into the\n+//! cache, the algorithm continues as before. If it now encounters a recursive\n+//! reference, it will hit the cache and does not try to describe the type anew.\n+//!\n+//! This behaviour is encapsulated in the 'RecursiveTypeDescription' enum, which\n+//! represents a kind of continuation, storing all state needed to continue\n+//! traversal at the type members after the type has been registered with the cache.\n+//! (This implementation approach might be a tad over-engineered and may change in\n+//! the future)\n+//!\n+//!\n+//! ## Source Locations and Line Information\n+//!\n+//! In addition to data type descriptions the debugging information must also allow\n+//! to map machine code locations back to source code locations in order to be useful.\n+//! This functionality is also handled in this module. The following functions allow\n+//! to control source mappings:\n+//!\n+//! + set_source_location()\n+//! + clear_source_location()\n+//! + start_emitting_source_locations()\n+//!\n+//! `set_source_location()` allows to set the current source location. All IR\n+//! instructions created after a call to this function will be linked to the given\n+//! source location, until another location is specified with\n+//! `set_source_location()` or the source location is cleared with\n+//! `clear_source_location()`. In the later case, subsequent IR instruction will not\n+//! be linked to any source location. As you can see, this is a stateful API\n+//! (mimicking the one in LLVM), so be careful with source locations set by previous\n+//! calls. It's probably best to not rely on any specific state being present at a\n+//! given point in code.\n+//!\n+//! One topic that deserves some extra attention is *function prologues*. At the\n+//! beginning of a function's machine code there are typically a few instructions\n+//! for loading argument values into allocas and checking if there's enough stack\n+//! space for the function to execute. This *prologue* is not visible in the source\n+//! code and LLVM puts a special PROLOGUE END marker into the line table at the\n+//! first non-prologue instruction of the function. In order to find out where the\n+//! prologue ends, LLVM looks for the first instruction in the function body that is\n+//! linked to a source location. So, when generating prologue instructions we have\n+//! to make sure that we don't emit source location information until the 'real'\n+//! function body begins. For this reason, source location emission is disabled by\n+//! default for any new function being translated and is only activated after a call\n+//! to the third function from the list above, `start_emitting_source_locations()`.\n+//! This function should be called right before regularly starting to translate the\n+//! top-level block of the given function.\n+//!\n+//! There is one exception to the above rule: `llvm.dbg.declare` instruction must be\n+//! linked to the source location of the variable being declared. For function\n+//! parameters these `llvm.dbg.declare` instructions typically occur in the middle\n+//! of the prologue, however, they are ignored by LLVM's prologue detection. The\n+//! `create_argument_metadata()` and related functions take care of linking the\n+//! `llvm.dbg.declare` instructions to the correct source locations even while\n+//! source location emission is still disabled, so there is no need to do anything\n+//! special with source location handling here.\n+//!\n+//! ## Unique Type Identification\n+//!\n+//! In order for link-time optimization to work properly, LLVM needs a unique type\n+//! identifier that tells it across compilation units which types are the same as\n+//! others. This type identifier is created by TypeMap::get_unique_type_id_of_type()\n+//! using the following algorithm:\n+//!\n+//! (1) Primitive types have their name as ID\n+//! (2) Structs, enums and traits have a multipart identifier\n+//!\n+//!     (1) The first part is the SVH (strict version hash) of the crate they were\n+//!         originally defined in\n+//!\n+//!     (2) The second part is the ast::NodeId of the definition in their original\n+//!         crate\n+//!\n+//!     (3) The final part is a concatenation of the type IDs of their concrete type\n+//!         arguments if they are generic types.\n+//!\n+//! (3) Tuple-, pointer and function types are structurally identified, which means\n+//!     that they are equivalent if their component types are equivalent (i.e. (int,\n+//!     int) is the same regardless in which crate it is used).\n+//!\n+//! This algorithm also provides a stable ID for types that are defined in one crate\n+//! but instantiated from metadata within another crate. We just have to take care\n+//! to always map crate and node IDs back to the original crate context.\n+//!\n+//! As a side-effect these unique type IDs also help to solve a problem arising from\n+//! lifetime parameters. Since lifetime parameters are completely omitted in\n+//! debuginfo, more than one `Ty` instance may map to the same debuginfo type\n+//! metadata, that is, some struct `Struct<'a>` may have N instantiations with\n+//! different concrete substitutions for `'a`, and thus there will be N `Ty`\n+//! instances for the type `Struct<'a>` even though it is not generic otherwise.\n+//! Unfortunately this means that we cannot use `ty::type_id()` as cheap identifier\n+//! for type metadata---we have done this in the past, but it led to unnecessary\n+//! metadata duplication in the best case and LLVM assertions in the worst. However,\n+//! the unique type ID as described above *can* be used as identifier. Since it is\n+//! comparatively expensive to construct, though, `ty::type_id()` is still used\n+//! additionally as an optimization for cases where the exact same type has been\n+//! seen before (which is most of the time).\n use self::FunctionDebugContextRepr::*;\n use self::VariableAccess::*;\n use self::VariableKind::*;"}, {"sha": "c3ab8986372ad14b8d35106f599baa95cfd664d3", "filename": "src/librustc_trans/trans/doc.rs", "status": "modified", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fdoc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "b7ac0f49754309904bb46063273d1c1762393e0c", "filename": "src/librustc_trans/trans/expr.rs", "status": "modified", "additions": 61, "deletions": 98, "changes": 159, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fexpr.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "6f97f6453fd91f5f9176c5c40326ae74153013b6", "filename": "src/librustc_trans/trans/foreign.rs", "status": "modified", "additions": 19, "deletions": 30, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fforeign.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fforeign.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fforeign.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a49b7b21627f84dde3b1076da218313e2f146a62", "filename": "src/librustc_trans/trans/meth.rs", "status": "modified", "additions": 23, "deletions": 44, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fmeth.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "9aeb4cdb8a30a7a8fd19b3a6ba5516a8fbf0f5a8", "filename": "src/librustc_trans/trans/tvec.rs", "status": "modified", "additions": 10, "deletions": 26, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Ftvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Ftvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Ftvec.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "8bff7602ddcead23ee8db815f8d61ec9db24b999", "filename": "src/librustc_trans/trans/type_.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Ftype_.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Ftype_.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Ftype_.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "33ea239412af664401d44c47031aedfc0bf9a804", "filename": "src/librustc_trans/trans/value.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustc_trans%2Ftrans%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fvalue.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "1f30dc9040d527cc1f3c817962345cf9c610c3e9", "filename": "src/librustdoc/clean/inline.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fclean%2Finline.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fclean%2Finline.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Finline.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "8270c8f3a20924c13d072a98c831368cc54b9a6e", "filename": "src/librustdoc/clean/mod.rs", "status": "modified", "additions": 46, "deletions": 14, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fclean%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fclean%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "adfd9aa821328868e7fc0419ba0f70407f676418", "filename": "src/librustdoc/doctree.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fdoctree.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fdoctree.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fdoctree.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "6e0b76d441b93f48dc2bb4a6440f9cf73ef7891f", "filename": "src/librustdoc/html/format.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fhtml%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fhtml%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fformat.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "3fbb2a8749f903fb7212e2f6f7bc9fd586c193ff", "filename": "src/librustdoc/html/render.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fhtml%2Frender.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fhtml%2Frender.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Frender.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "5b99151c5328e59bb0f0f3fd2b0ae0c8b8285800", "filename": "src/librustdoc/lib.rs", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "b5b34ef6efe6a69dde651b0145991770f62957ca", "filename": "src/librustdoc/visit_ast.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fvisit_ast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustdoc%2Fvisit_ast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fvisit_ast.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "261bd1b9f8cb88367ad0b1d30180322dbccf044e", "filename": "src/librustrt/c_str.rs", "status": "modified", "additions": 58, "deletions": 62, "changes": 120, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustrt%2Fc_str.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustrt%2Fc_str.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fc_str.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "697ee95df4c0f0f757820f4287093eecd2bd3a8b", "filename": "src/librustrt/unwind.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustrt%2Funwind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibrustrt%2Funwind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Funwind.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "b7d8885a5f99313406af29bb65b8d8f999ac2b39", "filename": "src/libserialize/base64.rs", "status": "modified", "additions": 39, "deletions": 43, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fbase64.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fbase64.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fbase64.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "2a3c410ba7c589912c5bd797377552bf7527b5b3", "filename": "src/libserialize/hex.rs", "status": "modified", "additions": 36, "deletions": 40, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fhex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fhex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fhex.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "fa82eb93faeec8df5d7eb14ffc9b479c6e6d690f", "filename": "src/libserialize/json.rs", "status": "modified", "additions": 268, "deletions": 273, "changes": 541, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fjson.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibserialize%2Fjson.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fjson.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "50a00714ea06cc036e21c750fb9cee5a6b9a9d79", "filename": "src/libstd/collections/hash/map.rs", "status": "modified", "additions": 35, "deletions": 1, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhash%2Fmap.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "3191519815ae46ed6801162eb76260dfb96cfbde", "filename": "src/libstd/comm/select.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fcomm%2Fselect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fcomm%2Fselect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fselect.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "3cd0c0eeaf290b949180286e43a689b5f7dbd14e", "filename": "src/libstd/dynamic_lib.rs", "status": "modified", "additions": 3, "deletions": 7, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fdynamic_lib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fdynamic_lib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fdynamic_lib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "d839c1484e56216492131f57df96eb384dfb9876", "filename": "src/libstd/failure.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Ffailure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Ffailure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ffailure.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "7e1bfd704a9275af3bdde7e8314bb826fd224d82", "filename": "src/libstd/fmt.rs", "status": "modified", "additions": 391, "deletions": 386, "changes": 777, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Ffmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Ffmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ffmt.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ac68e1ef121fbed040c124b42664a459b12eb472", "filename": "src/libstd/hash.rs", "status": "modified", "additions": 50, "deletions": 52, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fhash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fhash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fhash.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "e92bad592d1268cc20309b1a18750058f343db87", "filename": "src/libstd/io/buffered.rs", "status": "modified", "additions": 26, "deletions": 10, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fbuffered.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fbuffered.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fbuffered.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "bd334f52628fe75164cc4bedcff4d36c2da2d30d", "filename": "src/libstd/io/fs.rs", "status": "modified", "additions": 54, "deletions": 56, "changes": 110, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Ffs.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "5ed10eab15b808c901b2c577a51419ff83cdad51", "filename": "src/libstd/io/mod.rs", "status": "modified", "additions": 207, "deletions": 210, "changes": 417, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "7de786921309153ed13eb6eb214c32980c17583a", "filename": "src/libstd/io/net/addrinfo.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fnet%2Faddrinfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fnet%2Faddrinfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fnet%2Faddrinfo.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ec997b71986cc4782471827e2dee86a72a5d2a66", "filename": "src/libstd/io/net/pipe.rs", "status": "modified", "additions": 9, "deletions": 13, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fnet%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fnet%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fnet%2Fpipe.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "665000eae883773ccd302a23b724502455593a06", "filename": "src/libstd/io/stdio.rs", "status": "modified", "additions": 16, "deletions": 18, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fstdio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Fstdio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fstdio.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "af56735021e8646bda59f2ea981bc925817fe2fc", "filename": "src/libstd/io/test.rs", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Ftest.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ad02b534d04c647de4572bc41c4748519882a906", "filename": "src/libstd/io/timer.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ftimer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Ftimer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Ftimer.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "393283ff64c5bf079f1acc27b2ad779a3baaa7bf", "filename": "src/libstd/io/util.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fio%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Futil.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "12ca80bfaab094351c4ea9940fc8f2804669b166", "filename": "src/libstd/macros.rs", "status": "modified", "additions": 34, "deletions": 17, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fmacros.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "be6e387ad836d318e52412dd3d1954769f29d428", "filename": "src/libstd/num/strconv.rs", "status": "modified", "additions": 26, "deletions": 25, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fnum%2Fstrconv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fnum%2Fstrconv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fnum%2Fstrconv.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "90203709627ff22294bd13e45d0596d0906b678f", "filename": "src/libstd/os.rs", "status": "modified", "additions": 34, "deletions": 44, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fos.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "b17106e811f622f5201baf2d6624020c2bc01cd8", "filename": "src/libstd/path/mod.rs", "status": "modified", "additions": 50, "deletions": 56, "changes": 106, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fpath%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fpath%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fpath%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ec1cff73e96c63708755bfa1792e695ae272a8bb", "filename": "src/libstd/prelude.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fprelude.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fprelude.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fprelude.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "d375ddcc94b66a7e695cf05e116042414feb6204", "filename": "src/libstd/rt/backtrace.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Frt%2Fbacktrace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Frt%2Fbacktrace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fbacktrace.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "5ecd3ff04f1cd95c00ac9939f7b9ff0eb1cae64c", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 32, "deletions": 40, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "f2f9351fd0d58542f2610fb820cfe17da58e49c6", "filename": "src/libstd/sync/future.rs", "status": "modified", "additions": 13, "deletions": 15, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Ffuture.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Ffuture.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Ffuture.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "77f5b01351908c2aa33b123881607c627209654c", "filename": "src/libstd/sync/lock.rs", "status": "modified", "additions": 2, "deletions": 25, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Flock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Flock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Flock.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "47580a115131bb2e467b3ca2df280992da04b978", "filename": "src/libstd/sync/raw.rs", "status": "modified", "additions": 32, "deletions": 29, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Fraw.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsync%2Fraw.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fraw.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4b47b768d600c5176dda94dba70e8974b1032f0a", "filename": "src/libstd/sys/unix/fs.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Funix%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Funix%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Ffs.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "9c4ffb926b5ae5da70404d7d3b2fda0e4030b818", "filename": "src/libstd/sys/windows/fs.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Fwindows%2Ffs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Fwindows%2Ffs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Ffs.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "78a8e09dac1a002a14f1945d1ef2792150c50778", "filename": "src/libstd/sys/windows/process.rs", "status": "modified", "additions": 13, "deletions": 17, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Fwindows%2Fprocess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibstd%2Fsys%2Fwindows%2Fprocess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fprocess.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "28d5fbb96898d4c26e44681a5c706061f5a986c1", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "aa693976fe473ec44bb21763c9fff59edaf4ae71", "filename": "src/libsyntax/ast_util.rs", "status": "modified", "additions": 2, "deletions": 6, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fast_util.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fast_util.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast_util.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "27e8c265e5c340ae9517c6e1e88d3db7db973579", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 10, "deletions": 18, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "bd01e5e643020315703951e5a97f888badfeffea", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 15, "deletions": 8, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "e3cf2b68752fd78e0f000242c7742c89324b82d3", "filename": "src/libsyntax/ext/deriving/decodable.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fdecodable.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "d5f472bd827101db62d38149a374b17ff1b7ef87", "filename": "src/libsyntax/ext/deriving/generic/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "0139827316193e0577c65b7a4597e3dc89bca18e", "filename": "src/libsyntax/ext/deriving/generic/ty.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fgeneric%2Fty.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "fccef47d1ea2c875632f172315721fd71402c827", "filename": "src/libsyntax/ext/deriving/mod.rs", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fderiving%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fderiving%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "d7d6c636849a66a27fdae1ebeae2c77b9a266340", "filename": "src/libsyntax/ext/format.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fformat.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "3fca110a881c841a5331fbd4601981a74ddb22a6", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 6, "deletions": 10, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4785fe37293c0bf3a9a365a5f53e8ba6d38fe4d8", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "122f99cabb3f6a1c67f5afa41ff8c6268babd635", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "43b428b5a1c4199eac5ee7039ee3820cac001419", "filename": "src/libsyntax/owned_slice.rs", "status": "modified", "additions": 16, "deletions": 88, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fowned_slice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fowned_slice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fowned_slice.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "b46f7cdfe22ad1b43e3d9d6633781eca3db6cf4a", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "86a96fc521642569d92922eaeb1b22b79e453bc5", "filename": "src/libsyntax/parse/obsolete.rs", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fobsolete.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fobsolete.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "447f2a376e15ac8b2894da0457c9ddb91f551daf", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 93, "deletions": 120, "changes": 213, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "583ace977fe4686108e84d643f17795d3a095581", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "c12c3098279a97252f585b3b0d59853849862cc8", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 24, "deletions": 30, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "05828fc05f8c60358bb05ae27e83c2e520605094", "filename": "src/libsyntax/test.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "1385fb982e55a5bf7e692a6021103c16a2fca0a8", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 8, "deletions": 12, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "f41c93764647e891cfadc5338eecfe9eb7c513d7", "filename": "src/libterm/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibterm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibterm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibterm%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "62a49c5d902705a36aa6be92cf9c1255b76d8609", "filename": "src/libterm/terminfo/parm.rs", "status": "modified", "additions": 9, "deletions": 11, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibterm%2Fterminfo%2Fparm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibterm%2Fterminfo%2Fparm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibterm%2Fterminfo%2Fparm.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "6556ba3864c86e4ae17902b9c36d3d17c5d531e7", "filename": "src/libtest/lib.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibtest%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibtest%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibtest%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "135c8a72808800cd15c1f244d02854ad80bab51a", "filename": "src/libtime/lib.rs", "status": "modified", "additions": 27, "deletions": 43, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibtime%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibtime%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibtime%2Flib.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "cd46fc6a56dd0a85732c73eb7d6b637f6fad4dc4", "filename": "src/libunicode/normalize.rs", "status": "modified", "additions": 5, "deletions": 8, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fnormalize.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fnormalize.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibunicode%2Fnormalize.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "7cece6701dc85c0367362ec64ca365ca7a8d0a26", "filename": "src/libunicode/tables.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Ftables.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Ftables.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibunicode%2Ftables.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a73dac1a6186678cb9f5562ec6e824aa3cadd8fc", "filename": "src/libunicode/u_char.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fu_char.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fu_char.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibunicode%2Fu_char.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a5f761425759510a168fcf25601433ba1dd538ed", "filename": "src/libunicode/u_str.rs", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fu_str.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Flibunicode%2Fu_str.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibunicode%2Fu_str.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "8294d2b4594cfb00ebce192ca8d5513de99d01c1", "filename": "src/test/auxiliary/issue-13872-2.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fauxiliary%2Fissue-13872-2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fauxiliary%2Fissue-13872-2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Fissue-13872-2.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "40c8eb9b23ad7dbd57b8ede9d2fcef09daf99005", "filename": "src/test/auxiliary/issue_19293.rs", "status": "added", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fauxiliary%2Fissue_19293.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fauxiliary%2Fissue_19293.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fauxiliary%2Fissue_19293.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "f6511d68662eea478baea35e26ee5baf6f036f06", "filename": "src/test/compile-fail/dst-index.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fdst-index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fdst-index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fdst-index.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "5315e6c834ab3a629c7f5ac2cdc2a93888710c96", "filename": "src/test/compile-fail/enums-are-namespaced-xc.rs", "status": "added", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fenums-are-namespaced-xc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fenums-are-namespaced-xc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fenums-are-namespaced-xc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ff3512ad8e72a6e763d9cac9cd2065f19b5c834d", "filename": "src/test/compile-fail/hrtb-precedence-of-plus-error-message.rs", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fhrtb-precedence-of-plus-error-message.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fhrtb-precedence-of-plus-error-message.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fhrtb-precedence-of-plus-error-message.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "0202d538cf650941785177cee728144c00e99c16", "filename": "src/test/compile-fail/issue-12470.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-12470.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-12470.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-12470.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "cbf4412a81df286d23ef2da9f2bb817e797adc63", "filename": "src/test/compile-fail/issue-14285.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-14285.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-14285.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-14285.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4fcbb878890545a00d7a16af07ecd489a5663a33", "filename": "src/test/compile-fail/issue-19244-1.rs", "status": "added", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-19244-1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-19244-1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-19244-1.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "d9aeecc02222ca7d291be6fdbf11ad29895663ee", "filename": "src/test/compile-fail/issue-19244-2.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-19244-2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fissue-19244-2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-19244-2.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "202529c30b3e6b3d4691ccdbbae4fac1bcf87b49", "filename": "src/test/compile-fail/kindck-copy.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-copy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-copy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fkindck-copy.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4fbb3eab8c416234b10de8ef08ff6c2fc036cf35", "filename": "src/test/compile-fail/kindck-send-object.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fkindck-send-object.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a551975364329f7f7bbcf453674ff5ece9e7f5fb", "filename": "src/test/compile-fail/kindck-send-object1.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fkindck-send-object1.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ea8c262830633b20e1ff7c8b143dc0707106c6e6", "filename": "src/test/compile-fail/kindck-send-object2.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fkindck-send-object2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fkindck-send-object2.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4758ce71ffff5a4c77d94e8c25254a8a952e998a", "filename": "src/test/compile-fail/region-object-lifetime-1.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregion-object-lifetime-1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregion-object-lifetime-1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fregion-object-lifetime-1.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "660a9be4f63c5cd2cbfce201bb83ccb6ebebcfe2", "filename": "src/test/compile-fail/regions-bounded-by-send.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-bounded-by-send.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-bounded-by-send.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fregions-bounded-by-send.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "48945868bd35539f49f1ba584e888f4852b8df7d", "filename": "src/test/compile-fail/regions-close-object-into-object.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-close-object-into-object.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-close-object-into-object.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fregions-close-object-into-object.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4e31a41c4e07489687bfbbf59b35f65f2823aa4d", "filename": "src/test/compile-fail/regions-trait-variance.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-trait-variance.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fregions-trait-variance.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fregions-trait-variance.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a034352c4a69457e8f6cf49c31f13ac20819f90a", "filename": "src/test/compile-fail/trait-bounds-not-on-impl.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-impl.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "081efa429c3e43c1d233de5f61ebd53fd5209be3", "filename": "src/test/compile-fail/trait-bounds-not-on-struct.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-struct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-struct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-not-on-struct.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4da496621d1c942f2a4da163e051755398517976", "filename": "src/test/compile-fail/trait-bounds-sugar.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-sugar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-sugar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Ftrait-bounds-sugar.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ef991d8533737d646f9606ba53e4b89264e1db51", "filename": "src/test/compile-fail/unreachable-variant.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Funreachable-variant.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Funreachable-variant.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Funreachable-variant.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "26e055d7cbb9d93a56b80459c1a7f9ae4e00a51e", "filename": "src/test/compile-fail/xc-private-method2.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fxc-private-method2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Fcompile-fail%2Fxc-private-method2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fxc-private-method2.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "bbb049eb9603315577e73789545a5954b7bb17da", "filename": "src/test/run-pass/colorful-write-macros.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fcolorful-write-macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fcolorful-write-macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fcolorful-write-macros.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "eaf7131e1d878a36261f57ec9c8f354b7c4e5273", "filename": "src/test/run-pass/dst-index.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fdst-index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fdst-index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fdst-index.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "88e6de6d3e6ff6fb93d8aef6bd74bf0cf616f804", "filename": "src/test/run-pass/hrtb-precedence-of-plus-where-clause.rs", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus-where-clause.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus-where-clause.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus-where-clause.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "9a43b5b711eb5e0a346544dc28a89bfd3335d8bf", "filename": "src/test/run-pass/hrtb-precedence-of-plus.rs", "status": "added", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fhrtb-precedence-of-plus.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "324a1701b2febdb4f4bb38d2fa360f06a22f5403", "filename": "src/test/run-pass/issue-10902.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-10902.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-10902.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-10902.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ea138311f19b3bb25a4696a8844dc97d51bbfe41", "filename": "src/test/run-pass/issue-11205.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-11205.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-11205.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-11205.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "e41754fd1b9983b19a88171b9a6c1ef109818f79", "filename": "src/test/run-pass/issue-14901.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14901.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14901.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-14901.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "1ffd349a653853274f98c8809f857218f7cc58a0", "filename": "src/test/run-pass/issue-14958.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14958.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14958.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-14958.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "99472bb3610f80c203da9648e8a061b3e27ee8e6", "filename": "src/test/run-pass/issue-14959.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14959.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-14959.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-14959.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a885513611d3b03afb1f7bb6ae65d99437b064a1", "filename": "src/test/run-pass/issue-18619.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-18619.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-18619.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-18619.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "fecddea13e0f88855192a837826cdf0217d8550b", "filename": "src/test/run-pass/issue-19244.rs", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-19244.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-19244.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-19244.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4a446a76de38923b2e50c78222a0112d529f0268", "filename": "src/test/run-pass/issue-19293.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-19293.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-19293.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-19293.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "a6fac423bb6772f1ea86a1de55e6447df7453db1", "filename": "src/test/run-pass/issue-2316-c.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-2316-c.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-2316-c.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-2316-c.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "ec19b95ab1a48a5bd7ca936428160ab2349555f8", "filename": "src/test/run-pass/issue-2804.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-2804.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-2804.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-2804.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "61ae273aef50bdf9cd029c088a1f60c8f0363eee", "filename": "src/test/run-pass/issue-5708.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-5708.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-5708.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-5708.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "44f07def531bced6272ef9157c3f544e4f6cdb0d", "filename": "src/test/run-pass/issue-8249.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-8249.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-8249.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-8249.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "fb893873bc4d337bdb962d0f2eadf04d4bd66044", "filename": "src/test/run-pass/issue-8259.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-8259.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-8259.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-8259.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "4c6b9a3aaa0e4f98ce112ec2174254b340643e30", "filename": "src/test/run-pass/issue-9719.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-9719.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fissue-9719.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-9719.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "840e58848a742f59b31af183bcb70508365a05de", "filename": "src/test/run-pass/parameterized-trait-with-bounds.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fparameterized-trait-with-bounds.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fparameterized-trait-with-bounds.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fparameterized-trait-with-bounds.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "907f610ff25dbdcfeb098fa190b3f3ab846d8960", "filename": "src/test/run-pass/regions-early-bound-trait-param.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fregions-early-bound-trait-param.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fregions-early-bound-trait-param.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fregions-early-bound-trait-param.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "923a1427869f53bd1f73e251d33049a519be4860", "filename": "src/test/run-pass/struct_variant_xc.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fstruct_variant_xc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fstruct_variant_xc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fstruct_variant_xc.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "41dcb7ddbc86bc084853500799c585aadb1358ea", "filename": "src/test/run-pass/struct_variant_xc_match.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fstruct_variant_xc_match.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fstruct_variant_xc_match.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fstruct_variant_xc_match.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}, {"sha": "30b5f47b2ae2e30e166affded3ab62a561fb4c61", "filename": "src/test/run-pass/xcrate-unit-struct.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fxcrate-unit-struct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad/src%2Ftest%2Frun-pass%2Fxcrate-unit-struct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fxcrate-unit-struct.rs?ref=f358ca45c8cf8a5ea8922b5c66403d6a4f4d52ad"}]}