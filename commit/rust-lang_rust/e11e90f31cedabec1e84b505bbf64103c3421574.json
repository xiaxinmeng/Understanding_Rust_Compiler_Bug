{"sha": "e11e90f31cedabec1e84b505bbf64103c3421574", "node_id": "MDY6Q29tbWl0NzI0NzEyOmUxMWU5MGYzMWNlZGFiZWMxZTg0YjUwNWJiZjY0MTAzYzM0MjE1NzQ=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-07-28T02:14:46Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-07-28T02:14:46Z"}, "message": "Make macro-system type and constructor names more uniform; more comments.", "tree": {"sha": "692e73ed8b212c77a3da24cb4366a574fcb31fa0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/692e73ed8b212c77a3da24cb4366a574fcb31fa0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e11e90f31cedabec1e84b505bbf64103c3421574", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e11e90f31cedabec1e84b505bbf64103c3421574", "html_url": "https://github.com/rust-lang/rust/commit/e11e90f31cedabec1e84b505bbf64103c3421574", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e11e90f31cedabec1e84b505bbf64103c3421574/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "eabd233dcd208bc21ca0f8eea02d87d56e5314eb", "url": "https://api.github.com/repos/rust-lang/rust/commits/eabd233dcd208bc21ca0f8eea02d87d56e5314eb", "html_url": "https://github.com/rust-lang/rust/commit/eabd233dcd208bc21ca0f8eea02d87d56e5314eb"}], "stats": {"total": 426, "additions": 231, "deletions": 195}, "files": [{"sha": "a3480c633d626a5298a578c1fe26c5dbfce5710f", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 56, "deletions": 30, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -362,46 +362,68 @@ type capture_item = @{\n #[auto_serialize]\n type capture_clause = @~[capture_item];\n \n+//\n+// When the main rust parser encounters a syntax-extension invocation, it\n+// parses the arguments to the invocation as a token-tree. This is a very\n+// loose structure, such that all sorts of different AST-fragments can\n+// be passed to syntax extensions using a uniform type.\n+//\n+// If the syntax extension is an MBE macro, it will attempt to match its\n+// LHS \"matchers\" against the provided token tree, and if it finds a\n+// match, will transcribe the RHS token tree, splicing in any captured\n+// early_parser::matched_nonterminals into the tt_nonterminals it finds.\n+//\n+// The RHS of an MBE macro is the only place a tt_nonterminal or tt_seq\n+// makes any real sense. You could write them elsewhere but nothing\n+// else knows what to do with them, so you'll probably get a syntax\n+// error.\n+//\n #[auto_serialize]\n #[doc=\"For macro invocations; parsing is delegated to the macro\"]\n enum token_tree {\n+    tt_tok(span, token::token),\n     tt_delim(~[token_tree]),\n-    tt_flat(span, token::token),\n-    /* These only make sense for right-hand-sides of MBE macros*/\n-    tt_dotdotdot(span, ~[token_tree], option<token::token>, bool),\n-    tt_interpolate(span, ident)\n+    // These only make sense for right-hand-sides of MBE macros\n+    tt_seq(span, ~[token_tree], option<token::token>, bool),\n+    tt_nonterminal(span, ident)\n }\n \n-#[auto_serialize]\n-type matcher = spanned<matcher_>;\n-\n-#[auto_serialize]\n //\n // Matchers are nodes defined-by and recognized-by the main rust parser and\n-// language, but they're only ever found inside syntax-extension invocations.\n-// They represent a small sub-language for pattern-matching token-trees, and\n-// are thus primarily used by the macro-defining extension itself.\n+// language, but they're only ever found inside syntax-extension invocations;\n+// indeed, the only thing that ever _activates_ the rules in the rust parser\n+// for parsing a matcher is a matcher looking for the 'mtcs' nonterminal\n+// itself. Matchers represent a small sub-language for pattern-matching\n+// token-trees, and are thus primarily used by the macro-defining extension\n+// itself.\n //\n-// mtc_tok   ===>   A matcher that matches a single token,\n-//                  denoted by the token itself. So long as\n-//                  there's no $ involved.\n+// match_tok\n+// ---------\n //\n+//     A matcher that matches a single token, denoted by the token itself. So\n+//     long as there's no $ involved.\n //\n-// mtc_rep   ===>   A matcher that matches a sequence of\n-//                  sub-matchers, denoted various ways:\n+//\n+// match_seq\n+// ---------\n+//\n+//     A matcher that matches a sequence of sub-matchers, denoted various\n+//     possible ways:\n //\n //             $(M)*       zero or more Ms\n //             $(M)+       one or more Ms\n //             $(M),+      one or more comma-separated Ms\n //             $(A B C);*  zero or more semi-separated 'A B C' seqs\n //\n //\n-// mtc_bb ===> A matcher that matches one of a few interesting named rust\n-//             nonterminals, such as types, expressions, items, or raw\n-//             token-trees. A black-box matcher on expr, for example, binds an\n-//             expr to a given ident, and that ident can re-occur as an\n-//             interpolation in the RHS of a macro-by-example rule. For\n-//             example:\n+// match_nonterminal\n+// -----------------\n+//\n+//     A matcher that matches one of a few interesting named rust\n+//     nonterminals, such as types, expressions, items, or raw token-trees. A\n+//     black-box matcher on expr, for example, binds an expr to a given ident,\n+//     and that ident can re-occur as an interpolation in the RHS of a\n+//     macro-by-example rule. For example:\n //\n //        $foo:expr   =>     1 + $foo    // interpolate an expr\n //        $foo:tt     =>     $foo        // interpolate a token-tree\n@@ -411,21 +433,25 @@ type matcher = spanned<matcher_>;\n //\n // As a final, horrifying aside, note that macro-by-example's input is\n // also matched by one of these matchers. Holy self-referential! It is matched\n-// by an mtc_rep, specifically this one:\n+// by an match_seq, specifically this one:\n //\n //                   $( $lhs:mtcs => $rhs:tt );+\n //\n // If you understand that, you have closed to loop and understand the whole\n // macro system. Congratulations.\n //\n+#[auto_serialize]\n+type matcher = spanned<matcher_>;\n+\n+#[auto_serialize]\n enum matcher_ {\n-    /* match one token */\n-    mtc_tok(token::token),\n-    /* match repetitions of a sequence: body, separator, zero ok?,\n-    lo, hi position-in-match-array used: */\n-    mtc_rep(~[matcher], option<token::token>, bool, uint, uint),\n-    /* parse a Rust NT: name to bind, name of NT, position in match array : */\n-    mtc_bb(ident, ident, uint)\n+    // match one token\n+    match_tok(token::token),\n+    // match repetitions of a sequence: body, separator, zero ok?,\n+    // lo, hi position-in-match-array used:\n+    match_seq(~[matcher], option<token::token>, bool, uint, uint),\n+    // parse a Rust NT: name to bind, name of NT, position in match array:\n+    match_nonterminal(ident, ident, uint)\n }\n \n #[auto_serialize]"}, {"sha": "b35bd9a17e9f95d11fc75261e822ed417721d95d", "filename": "src/libsyntax/ext/base.rs", "status": "modified", "additions": 7, "deletions": 18, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbase.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -4,18 +4,6 @@ import diagnostic::span_handler;\n import codemap::{codemap, span, expn_info, expanded_from};\n import std::map::str_hash;\n \n-\n-// Nomenclature / abbreviations in the ext modules:\n-//\n-//     ms: matcher span, wraps a matcher with fake span\n-//    mtc: matcher\n-//   mtcs: matchers\n-//     tt: token tree\n-//     bt: backtrace\n-//     cx: expansion context\n-//     mr: macro result\n-//\n-\n // obsolete old-style #macro code:\n //\n //    syntax_expander, normal, macro_defining, macro_definer,\n@@ -288,28 +276,29 @@ fn get_mac_body(cx: ext_ctxt, sp: span, args: ast::mac_body)\n // using new syntax. This will be obsolete when #old_macros go away.\n fn tt_args_to_original_flavor(cx: ext_ctxt, sp: span, arg: ~[ast::token_tree])\n     -> ast::mac_arg {\n-    import ast::{matcher, matcher_, mtc_tok, mtc_rep, mtc_bb};\n+    import ast::{matcher, matcher_, match_tok, match_seq, match_nonterminal};\n     import parse::lexer::{new_tt_reader, tt_reader_as_reader, reader};\n-    import tt::earley_parser::{parse_or_else, seq, leaf};\n+    import tt::earley_parser::{parse_or_else, matched_seq,\n+                               matched_nonterminal};\n \n     // these spans won't matter, anyways\n     fn ms(m: matcher_) -> matcher {\n         {node: m, span: {lo: 0u, hi: 0u, expn_info: none}}\n     }\n \n-    let argument_gram = ~[ms(mtc_rep(~[\n-        ms(mtc_bb(@~\"arg\",@~\"expr\", 0u))\n+    let argument_gram = ~[ms(match_seq(~[\n+        ms(match_nonterminal(@~\"arg\",@~\"expr\", 0u))\n     ], some(parse::token::COMMA), true, 0u, 1u))];\n \n     let arg_reader = new_tt_reader(cx.parse_sess().span_diagnostic,\n                                    cx.parse_sess().interner, none, arg);\n     let args =\n         alt parse_or_else(cx.parse_sess(), cx.cfg(), arg_reader as reader,\n                           argument_gram).get(@~\"arg\") {\n-          @seq(s, _) {\n+          @matched_seq(s, _) {\n             do s.map() |lf| {\n                 alt lf {\n-                  @leaf(parse::token::w_expr(arg)) {\n+                  @matched_nonterminal(parse::token::nt_expr(arg)) {\n                     arg /* whew! list of exprs, here we come! */\n                   }\n                   _ { fail ~\"badly-structured parse result\"; }"}, {"sha": "caa5fd417a8f3fc651c47baff6fd7e0a61ecaa1e", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -1,7 +1,7 @@\n import std::map::hashmap;\n \n import ast::{crate, expr_, expr_mac, mac_invoc, mac_invoc_tt,\n-             tt_delim, tt_flat, item_mac};\n+             tt_delim, tt_tok, item_mac};\n import fold::*;\n import ext::base::*;\n import ext::qquote::{qq_helper};"}, {"sha": "9b6383d5d3a200ffafdbefa688a636a39ca937d6", "filename": "src/libsyntax/ext/tt/earley_parser.rs", "status": "modified", "additions": 75, "deletions": 62, "changes": 137, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fearley_parser.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -1,27 +1,29 @@\n // Earley-like parser for macros.\n import parse::token;\n-import parse::token::{token, EOF, to_str, whole_nt};\n+import parse::token::{token, EOF, to_str, nonterminal};\n import parse::lexer::*; //resolve bug?\n //import parse::lexer::{reader, tt_reader, tt_reader_as_reader};\n import parse::parser::{parser,SOURCE_FILE};\n //import parse::common::parser_common;\n import parse::common::*; //resolve bug?\n import parse::parse_sess;\n import dvec::{dvec, extensions};\n-import ast::{matcher, mtc_tok, mtc_rep, mtc_bb, ident};\n+import ast::{matcher, match_tok, match_seq, match_nonterminal, ident};\n import ast_util::mk_sp;\n import std::map::{hashmap, box_str_hash};\n \n-/* This is an Earley-like parser, without support for nonterminals.  This\n-means that there are no completer or predictor rules, and therefore no need to\n-store one column per token: instead, there's a set of current Earley items and\n-a set of next ones. Instead of NTs, we have a special case for Kleene\n-star. The big-O, in pathological cases, is worse than traditional Earley\n-parsing, but it's an easier fit for Macro-by-Example-style rules, and I think\n-the overhead is lower. */\n+/* This is an Earley-like parser, without support for in-grammar nonterminals,\n+onlyl calling out to the main rust parser for named nonterminals (which it\n+commits to fully when it hits one in a grammar). This means that there are no\n+completer or predictor rules, and therefore no need to store one column per\n+token: instead, there's a set of current Earley items and a set of next\n+ones. Instead of NTs, we have a special case for Kleene star. The big-O, in\n+pathological cases, is worse than traditional Earley parsing, but it's an\n+easier fit for Macro-by-Example-style rules, and I think the overhead is\n+lower. */\n \n \n-/* to avoid costly uniqueness checks, we require that `mtc_rep` always has a\n+/* to avoid costly uniqueness checks, we require that `match_seq` always has a\n nonempty body. */\n \n enum matcher_pos_up { /* to break a circularity */\n@@ -40,7 +42,7 @@ type matcher_pos = ~{\n     sep: option<token>,\n     mut idx: uint,\n     mut up: matcher_pos_up, // mutable for swapping only\n-    matches: ~[dvec<@arb_depth>],\n+    matches: ~[dvec<@named_match>],\n     match_lo: uint, match_hi: uint,\n     sp_lo: uint,\n };\n@@ -55,9 +57,9 @@ fn copy_up(&& mpu: matcher_pos_up) -> matcher_pos {\n fn count_names(ms: &[matcher]) -> uint {\n     vec::foldl(0u, ms, |ct, m| {\n         ct + alt m.node {\n-          mtc_tok(_) { 0u }\n-          mtc_rep(more_ms, _, _, _, _) { count_names(more_ms) }\n-          mtc_bb(_,_,_) { 1u }\n+          match_tok(_) { 0u }\n+          match_seq(more_ms, _, _, _, _) { count_names(more_ms) }\n+          match_nonterminal(_,_,_) { 1u }\n         }})\n }\n \n@@ -67,48 +69,56 @@ fn initial_matcher_pos(ms: ~[matcher], sep: option<token>, lo: uint)\n     let mut match_idx_hi = 0u;\n     for ms.each() |elt| {\n         alt elt.node {\n-          mtc_tok(_) {}\n-          mtc_rep(_,_,_,_,hi) { match_idx_hi = hi; } //it is monotonic...\n-          mtc_bb(_,_,pos) { match_idx_hi = pos+1u; } //...so latest is highest\n+          match_tok(_) {}\n+          match_seq(_,_,_,_,hi) {\n+            match_idx_hi = hi;       // it is monotonic...\n+          }\n+          match_nonterminal(_,_,pos) {\n+            match_idx_hi = pos+1u;  // ...so latest is highest\n+          }\n         }\n     }\n     ~{elts: ms, sep: sep, mut idx: 0u, mut up: matcher_pos_up(none),\n       matches: copy vec::from_fn(count_names(ms), |_i| dvec::dvec()),\n       match_lo: 0u, match_hi: match_idx_hi, sp_lo: lo}\n }\n \n-// arb_depth is a pattern-match result for a single black-box matcher\n-// (ast::mtc_bb): so it is associated with a single ident in a parse, and all\n-// leaves in the arb_depth have the same nonterminal type (expr, item,\n-// etc). All the leaves in a single arb_depth correspond to a single mtc_bb in\n-// the ast::matcher that produced it.\n+// named_match is a pattern-match result for a single ast::match_nonterminal:\n+// so it is associated with a single ident in a parse, and all\n+// matched_nonterminals in the named_match have the same nonterminal type\n+// (expr, item, etc). All the leaves in a single named_match correspond to a\n+// single matcher_nonterminal in the ast::matcher that produced it.\n //\n // It should probably be renamed, it has more or less exact correspondence to\n-// ast::match nodes, and the in-memory structure of a particular arb_depth\n+// ast::match nodes, and the in-memory structure of a particular named_match\n // represents the match that occurred when a particular subset of an\n-// ast::match -- those ast::matcher nodes leading to a single mtc_bb -- was\n-// applied to a particular token tree.\n+// ast::match -- those ast::matcher nodes leading to a single\n+// match_nonterminal -- was applied to a particular token tree.\n //\n-// The width of each seq in the arb_depth, and the identity of the leaf nodes,\n-// will depend on the token tree it was applied to: each seq corresponds to a\n-// single mtc_rep in the originating ast::matcher. The depth of the arb_depth\n-// structure will therefore depend only on the nesting depth of mtc_reps in\n-// the originating ast::matcher it was derived from.\n-\n-enum arb_depth { leaf(whole_nt), seq(~[@arb_depth], codemap::span) }\n+// The width of each matched_seq in the named_match, and the identity of the\n+// matched_nonterminals, will depend on the token tree it was applied to: each\n+// matched_seq corresponds to a single match_seq in the originating\n+// ast::matcher. The depth of the named_match structure will therefore depend\n+// only on the nesting depth of ast::match_seqs in the originating\n+// ast::matcher it was derived from.\n+\n+enum named_match {\n+    matched_seq(~[@named_match], codemap::span),\n+    matched_nonterminal(nonterminal)\n+}\n \n type earley_item = matcher_pos;\n \n-fn nameize(p_s: parse_sess, ms: ~[matcher], res: ~[@arb_depth])\n-    -> hashmap<ident,@arb_depth> {\n-    fn n_rec(p_s: parse_sess, m: matcher, res: ~[@arb_depth],\n-             ret_val: hashmap<ident, @arb_depth>) {\n+fn nameize(p_s: parse_sess, ms: ~[matcher], res: ~[@named_match])\n+    -> hashmap<ident,@named_match> {\n+    fn n_rec(p_s: parse_sess, m: matcher, res: ~[@named_match],\n+             ret_val: hashmap<ident, @named_match>) {\n         alt m {\n-          {node: mtc_tok(_), span: _} { }\n-          {node: mtc_rep(more_ms, _, _, _, _), span: _} {\n+          {node: match_tok(_), span: _} { }\n+          {node: match_seq(more_ms, _, _, _, _), span: _} {\n             for more_ms.each() |next_m| { n_rec(p_s, next_m, res, ret_val) };\n           }\n-          {node: mtc_bb(bind_name, _, idx), span: sp} {\n+          {node: match_nonterminal(bind_name, _, idx), span: sp} {\n             if ret_val.contains_key(bind_name) {\n                 p_s.span_diagnostic.span_fatal(sp, ~\"Duplicated bind name: \"\n                                                + *bind_name)\n@@ -117,18 +127,18 @@ fn nameize(p_s: parse_sess, ms: ~[matcher], res: ~[@arb_depth])\n           }\n         }\n     }\n-    let ret_val = box_str_hash::<@arb_depth>();\n+    let ret_val = box_str_hash::<@named_match>();\n     for ms.each() |m| { n_rec(p_s, m, res, ret_val) }\n     ret ret_val;\n }\n \n enum parse_result {\n-    success(hashmap<ident, @arb_depth>),\n+    success(hashmap<ident, @named_match>),\n     failure(codemap::span, ~str)\n }\n \n fn parse_or_else(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader,\n-                 ms: ~[matcher]) -> hashmap<ident, @arb_depth> {\n+                 ms: ~[matcher]) -> hashmap<ident, @named_match> {\n     alt parse(sess, cfg, rdr, ms) {\n       success(m) { m }\n       failure(sp, str) {\n@@ -182,7 +192,9 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                         for uint::range(ei.match_lo, ei.match_hi) |idx| {\n                             let sub = ei.matches[idx].get();\n                             new_pos.matches[idx]\n-                                .push(@seq(sub, mk_sp(ei.sp_lo,sp.hi)));\n+                                .push(@matched_seq(sub,\n+                                                   mk_sp(ei.sp_lo,\n+                                                         sp.hi)));\n                         }\n \n                         new_pos.idx += 1u;\n@@ -212,20 +224,21 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n             } else {\n                 alt copy ei.elts[idx].node {\n                   /* need to descend into sequence */\n-                  mtc_rep(matchers, sep, zero_ok, match_idx_lo, match_idx_hi){\n+                  match_seq(matchers, sep, zero_ok,\n+                            match_idx_lo, match_idx_hi){\n                     if zero_ok {\n                         let new_ei = copy ei;\n                         new_ei.idx += 1u;\n                         //we specifically matched zero repeats.\n                         for uint::range(match_idx_lo, match_idx_hi) |idx| {\n-                            new_ei.matches[idx].push(@seq(~[], sp));\n+                            new_ei.matches[idx].push(@matched_seq(~[], sp));\n                         }\n \n                         vec::push(cur_eis, new_ei);\n                     }\n \n                     let matches = vec::map(ei.matches, // fresh, same size:\n-                                           |_m| dvec::<@arb_depth>());\n+                                           |_m| dvec::<@named_match>());\n                     let ei_t <- ei;\n                     vec::push(cur_eis, ~{\n                         elts: matchers, sep: sep, mut idx: 0u,\n@@ -235,8 +248,8 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                         sp_lo: sp.lo\n                     });\n                   }\n-                  mtc_bb(_,_,_) { vec::push(bb_eis, ei) }\n-                  mtc_tok(t) {\n+                  match_nonterminal(_,_,_) { vec::push(bb_eis, ei) }\n+                  match_tok(t) {\n                     let ei_t <- ei;\n                     if t == tok { ei_t.idx += 1u; vec::push(next_eis, ei_t)}\n                   }\n@@ -260,7 +273,7 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n                 || bb_eis.len() > 1u {\n                 let nts = str::connect(vec::map(bb_eis, |ei| {\n                     alt ei.elts[ei.idx].node {\n-                      mtc_bb(bind,name,_) {\n+                      match_nonterminal(bind,name,_) {\n                         #fmt[\"%s ('%s')\", *name, *bind]\n                       }\n                       _ { fail; } } }), ~\" or \");\n@@ -282,8 +295,8 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n \n                 let ei = vec::pop(bb_eis);\n                 alt ei.elts[ei.idx].node {\n-                  mtc_bb(_, name, idx) {\n-                    ei.matches[idx].push(@leaf(\n+                  match_nonterminal(_, name, idx) {\n+                    ei.matches[idx].push(@matched_nonterminal(\n                         parse_nt(rust_parser, *name)));\n                     ei.idx += 1u;\n                   }\n@@ -305,31 +318,31 @@ fn parse(sess: parse_sess, cfg: ast::crate_cfg, rdr: reader, ms: ~[matcher])\n     }\n }\n \n-fn parse_nt(p: parser, name: ~str) -> whole_nt {\n+fn parse_nt(p: parser, name: ~str) -> nonterminal {\n     alt name {\n       ~\"item\" { alt p.parse_item(~[], ast::public) {\n-        some(i) { token::w_item(i) }\n+        some(i) { token::nt_item(i) }\n         none { p.fatal(~\"expected an item keyword\") }\n       }}\n-      ~\"block\" { token::w_block(p.parse_block()) }\n-      ~\"stmt\" { token::w_stmt(p.parse_stmt(~[])) }\n-      ~\"pat\" { token::w_pat(p.parse_pat()) }\n-      ~\"expr\" { token::w_expr(p.parse_expr()) }\n-      ~\"ty\" { token::w_ty(p.parse_ty(false /* no need to disambiguate*/)) }\n+      ~\"block\" { token::nt_block(p.parse_block()) }\n+      ~\"stmt\" { token::nt_stmt(p.parse_stmt(~[])) }\n+      ~\"pat\" { token::nt_pat(p.parse_pat()) }\n+      ~\"expr\" { token::nt_expr(p.parse_expr()) }\n+      ~\"ty\" { token::nt_ty(p.parse_ty(false /* no need to disambiguate*/)) }\n       // this could be handled like a token, since it is one\n       ~\"ident\" { alt copy p.token {\n-          token::IDENT(sn,b) { p.bump(); token::w_ident(sn,b) }\n+          token::IDENT(sn,b) { p.bump(); token::nt_ident(sn,b) }\n           _ { p.fatal(~\"expected ident, found \"\n                       + token::to_str(*p.reader.interner(), copy p.token)) }\n       } }\n-      ~\"path\" { token::w_path(p.parse_path_with_tps(false)) }\n+      ~\"path\" { token::nt_path(p.parse_path_with_tps(false)) }\n       ~\"tt\" {\n         p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n-        let res = token::w_tt(@p.parse_token_tree());\n+        let res = token::nt_tt(@p.parse_token_tree());\n         p.quote_depth -= 1u;\n         res\n       }\n-      ~\"mtcs\" { token::w_mtcs(p.parse_matchers()) }\n+      ~\"matchers\" { token::nt_matchers(p.parse_matchers()) }\n       _ { p.fatal(~\"Unsupported builtin nonterminal parser: \" + name)}\n     }\n }"}, {"sha": "cd6ebce4394a31f212460cb8c4483a62303bac85", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 14, "deletions": 12, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -1,10 +1,12 @@\n import base::{ext_ctxt, mac_result, mr_expr, mr_def, expr_tt};\n import codemap::span;\n-import ast::{ident, matcher_, matcher, mtc_tok, mtc_bb, mtc_rep, tt_delim};\n+import ast::{ident, matcher_, matcher, match_tok,\n+             match_nonterminal, match_seq, tt_delim};\n import parse::lexer::{new_tt_reader, tt_reader_as_reader, reader};\n-import parse::token::{FAT_ARROW, SEMI, LBRACE, RBRACE, w_mtcs, w_tt};\n+import parse::token::{FAT_ARROW, SEMI, LBRACE, RBRACE, nt_matchers, nt_tt};\n import parse::parser::{parser, SOURCE_FILE};\n-import earley_parser::{parse, success, failure, arb_depth, seq, leaf};\n+import earley_parser::{parse, success, failure, named_match,\n+                       matched_seq, matched_nonterminal};\n import std::map::hashmap;\n \n \n@@ -17,10 +19,10 @@ fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n     }\n \n     let argument_gram = ~[\n-        ms(mtc_rep(~[\n-            ms(mtc_bb(@~\"lhs\",@~\"mtcs\", 0u)),\n-            ms(mtc_tok(FAT_ARROW)),\n-            ms(mtc_bb(@~\"rhs\",@~\"tt\", 1u)),\n+        ms(match_seq(~[\n+            ms(match_nonterminal(@~\"lhs\",@~\"matchers\", 0u)),\n+            ms(match_tok(FAT_ARROW)),\n+            ms(match_nonterminal(@~\"rhs\",@~\"tt\", 1u)),\n         ], some(SEMI), false, 0u, 2u))];\n \n     let arg_reader = new_tt_reader(cx.parse_sess().span_diagnostic,\n@@ -32,16 +34,16 @@ fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n     };\n \n     let lhses = alt arguments.get(@~\"lhs\") {\n-      @seq(s, sp) { s }\n+      @matched_seq(s, sp) { s }\n       _ { cx.span_bug(sp, ~\"wrong-structured lhs\") }\n     };\n     let rhses = alt arguments.get(@~\"rhs\") {\n-      @seq(s, sp) { s }\n+      @matched_seq(s, sp) { s }\n       _ { cx.span_bug(sp, ~\"wrong-structured rhs\") }\n     };\n \n     fn generic_extension(cx: ext_ctxt, sp: span, arg: ~[ast::token_tree],\n-                         lhses: ~[@arb_depth], rhses: ~[@arb_depth])\n+                         lhses: ~[@named_match], rhses: ~[@named_match])\n     -> mac_result {\n         let mut best_fail_spot = {lo: 0u, hi: 0u, expn_info: none};\n         let mut best_fail_msg = ~\"internal error: ran no matchers\";\n@@ -51,12 +53,12 @@ fn add_new_extension(cx: ext_ctxt, sp: span, name: ident,\n \n         for lhses.eachi() |i, lhs| {\n             alt lhs {\n-              @leaf(w_mtcs(mtcs)) {\n+              @matched_nonterminal(nt_matchers(mtcs)) {\n                 let arg_rdr = new_tt_reader(s_d, itr, none, arg) as reader;\n                 alt parse(cx.parse_sess(), cx.cfg(), arg_rdr, mtcs) {\n                   success(m) {\n                     let rhs = alt rhses[i] {\n-                      @leaf(w_tt(@tt)) { tt }\n+                      @matched_nonterminal(nt_tt(@tt)) { tt }\n                       _ { cx.span_bug(sp, ~\"bad thing in rhs\") }\n                     };\n                     let trncbr = new_tt_reader(s_d, itr, some(m), ~[rhs]);"}, {"sha": "b9d490e9e287c1291a46eda8d5c6126add226d11", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 34, "deletions": 30, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -1,10 +1,10 @@\n import util::interner::interner;\n import diagnostic::span_handler;\n-import ast::{token_tree,tt_delim,tt_flat,tt_dotdotdot,tt_interpolate,ident};\n-import earley_parser::{arb_depth,seq,leaf};\n+import ast::{token_tree, tt_delim, tt_tok, tt_seq, tt_nonterminal,ident};\n+import earley_parser::{named_match, matched_seq, matched_nonterminal};\n import codemap::span;\n-import parse::token::{EOF,ACTUALLY,IDENT,token,w_ident};\n-import std::map::{hashmap,box_str_hash};\n+import parse::token::{EOF, INTERPOLATED, IDENT, token, nt_ident};\n+import std::map::{hashmap, box_str_hash};\n \n export tt_reader,  new_tt_reader, dup_tt_reader, tt_next_token;\n \n@@ -28,7 +28,7 @@ type tt_reader = @{\n     interner: @interner<@~str>,\n     mut cur: tt_frame,\n     /* for MBE-style macro transcription */\n-    interpolations: std::map::hashmap<ident, @arb_depth>,\n+    interpolations: std::map::hashmap<ident, @named_match>,\n     mut repeat_idx: ~[mut uint],\n     mut repeat_len: ~[uint],\n     /* cached: */\n@@ -37,17 +37,17 @@ type tt_reader = @{\n };\n \n /** This can do Macro-By-Example transcription. On the other hand, if\n- *  `src` contains no `tt_dotdotdot`s and `tt_interpolate`s, `interp` can (and\n+ *  `src` contains no `tt_seq`s and `tt_nonterminal`s, `interp` can (and\n  *  should) be none. */\n fn new_tt_reader(sp_diag: span_handler, itr: @interner<@~str>,\n-                 interp: option<std::map::hashmap<ident,@arb_depth>>,\n+                 interp: option<std::map::hashmap<ident,@named_match>>,\n                  src: ~[ast::token_tree])\n     -> tt_reader {\n     let r = @{sp_diag: sp_diag, interner: itr,\n               mut cur: @{readme: src, mut idx: 0u, dotdotdoted: false,\n                          sep: none, up: tt_frame_up(option::none)},\n               interpolations: alt interp { /* just a convienience */\n-                none { std::map::box_str_hash::<@arb_depth>() }\n+                none { std::map::box_str_hash::<@named_match>() }\n                 some(x) { x }\n               },\n               mut repeat_idx: ~[mut], mut repeat_len: ~[],\n@@ -79,18 +79,22 @@ pure fn dup_tt_reader(&&r: tt_reader) -> tt_reader {\n }\n \n \n-pure fn lookup_cur_ad_by_ad(r: tt_reader, start: @arb_depth) -> @arb_depth {\n-    pure fn red(&&ad: @arb_depth, &&idx: uint) -> @arb_depth {\n+pure fn lookup_cur_matched_by_matched(r: tt_reader,\n+                                      start: @named_match) -> @named_match {\n+    pure fn red(&&ad: @named_match, &&idx: uint) -> @named_match {\n         alt *ad {\n-          leaf(_) { ad /* end of the line; duplicate henceforth */ }\n-          seq(ads, _) { ads[idx] }\n+          matched_nonterminal(_) {\n+            // end of the line; duplicate henceforth\n+            ad\n+          }\n+          matched_seq(ads, _) { ads[idx] }\n         }\n     }\n     vec::foldl(start, r.repeat_idx, red)\n }\n \n-fn lookup_cur_ad(r: tt_reader, name: ident) -> @arb_depth {\n-    lookup_cur_ad_by_ad(r, r.interpolations.get(name))\n+fn lookup_cur_matched(r: tt_reader, name: ident) -> @named_match {\n+    lookup_cur_matched_by_matched(r, r.interpolations.get(name))\n }\n enum lis {\n     lis_unconstrained, lis_constraint(uint, ident), lis_contradiction(~str)\n@@ -116,15 +120,15 @@ fn lockstep_iter_size(&&t: token_tree, &&r: tt_reader) -> lis {\n         }\n     }\n     alt t {\n-      tt_delim(tts) | tt_dotdotdot(_, tts, _, _) {\n+      tt_delim(tts) | tt_seq(_, tts, _, _) {\n         vec::foldl(lis_unconstrained, tts, {|lis, tt|\n             lis_merge(lis, lockstep_iter_size(tt, r)) })\n       }\n-      tt_flat(*) { lis_unconstrained }\n-      tt_interpolate(_, name) {\n-        alt *lookup_cur_ad(r, name) {\n-          leaf(_) { lis_unconstrained }\n-          seq(ads, _) { lis_constraint(ads.len(), name) }\n+      tt_tok(*) { lis_unconstrained }\n+      tt_nonterminal(_, name) {\n+        alt *lookup_cur_matched(r, name) {\n+          matched_nonterminal(_) { lis_unconstrained }\n+          matched_seq(ads, _) { lis_constraint(ads.len(), name) }\n         }\n       }\n     }\n@@ -166,20 +170,20 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n         }\n     }\n     loop { /* because it's easiest, this handles `tt_delim` not starting\n-    with a `tt_flat`, even though it won't happen */\n+    with a `tt_tok`, even though it won't happen */\n         alt r.cur.readme[r.cur.idx] {\n           tt_delim(tts) {\n             r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: false,\n                       sep: none, up: tt_frame_up(option::some(r.cur)) };\n             // if this could be 0-length, we'd need to potentially recur here\n           }\n-          tt_flat(sp, tok) {\n+          tt_tok(sp, tok) {\n             r.cur_span = sp; r.cur_tok = tok;\n             r.cur.idx += 1u;\n             ret ret_val;\n           }\n-          tt_dotdotdot(sp, tts, sep, zerok) {\n-            alt lockstep_iter_size(tt_dotdotdot(sp, tts, sep, zerok), r) {\n+          tt_seq(sp, tts, sep, zerok) {\n+            alt lockstep_iter_size(tt_seq(sp, tts, sep, zerok), r) {\n               lis_unconstrained {\n                 r.sp_diag.span_fatal(\n                     sp, /* blame macro writer */\n@@ -211,22 +215,22 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n             }\n           }\n           // FIXME #2887: think about span stuff here\n-          tt_interpolate(sp, ident) {\n-            alt *lookup_cur_ad(r, ident) {\n+          tt_nonterminal(sp, ident) {\n+            alt *lookup_cur_matched(r, ident) {\n               /* sidestep the interpolation tricks for ident because\n               (a) idents can be in lots of places, so it'd be a pain\n               (b) we actually can, since it's a token. */\n-              leaf(w_ident(sn,b)) {\n+              matched_nonterminal(nt_ident(sn,b)) {\n                 r.cur_span = sp; r.cur_tok = IDENT(sn,b);\n                 r.cur.idx += 1u;\n                 ret ret_val;\n               }\n-              leaf(w_nt) {\n-                r.cur_span = sp; r.cur_tok = ACTUALLY(w_nt);\n+              matched_nonterminal(nt) {\n+                r.cur_span = sp; r.cur_tok = INTERPOLATED(nt);\n                 r.cur.idx += 1u;\n                 ret ret_val;\n               }\n-              seq(*) {\n+              matched_seq(*) {\n                 r.sp_diag.span_fatal(\n                     copy r.cur_span, /* blame the macro writer */\n                     #fmt[\"variable '%s' is still repeating at this depth\","}, {"sha": "7898cd648908db95d8e52f02d46174c597134644", "filename": "src/libsyntax/parse/common.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Fcommon.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Fcommon.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcommon.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -86,7 +86,7 @@ impl parser_common of parser_common for parser {\n     fn parse_ident() -> ast::ident {\n         alt copy self.token {\n           token::IDENT(i, _) { self.bump(); ret self.get_str(i); }\n-          token::ACTUALLY(token::w_ident(*)) { self.bug(\n+          token::INTERPOLATED(token::nt_ident(*)) { self.bug(\n               ~\"ident interpolation not converted to real token\"); }\n           _ { self.fatal(~\"expected ident, found `\"\n                          + token_to_str(self.reader, self.token)"}, {"sha": "888bb25685235f8ed2f249d64a90b66ead23dc60", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 20, "deletions": 20, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -3,7 +3,7 @@ import print::pprust::expr_to_str;\n import result::result;\n import either::{either, left, right};\n import std::map::{hashmap, str_hash};\n-import token::{can_begin_expr, is_ident, is_plain_ident, ACTUALLY};\n+import token::{can_begin_expr, is_ident, is_plain_ident, INTERPOLATED};\n import codemap::{span,fss_none};\n import util::interner;\n import ast_util::{spanned, respan, mk_sp, ident_to_path, operator_prec};\n@@ -39,15 +39,15 @@ import ast::{_mod, add, alt_check, alt_exhaustive, arg, arm, attribute,\n              item_ty, lit, lit_, lit_bool, lit_float, lit_int,\n              lit_int_unsuffixed, lit_nil, lit_str, lit_uint, local, m_const,\n              m_imm, m_mutbl, mac_, mac_aq, mac_ellipsis,\n-             mac_invoc, mac_invoc_tt, mac_var, matcher,\n-             method, mode, mt, mtc_bb, mtc_rep, mtc_tok, mul, mutability, neg,\n+             mac_invoc, mac_invoc_tt, mac_var, matcher, match_nonterminal,\n+             match_seq, match_tok, method, mode, mt, mul, mutability, neg,\n              noreturn, not, pat, pat_box, pat_enum, pat_ident, pat_lit,\n              pat_range, pat_rec, pat_tup, pat_uniq, pat_wild, path, private,\n              proto, proto_any, proto_bare, proto_block, proto_box, proto_uniq,\n              provided, public, pure_fn, purity, re_anon, re_named, region,\n              rem, required, ret_style, return_val, shl, shr, stmt, stmt_decl,\n              stmt_expr, stmt_semi, subtract, token_tree, trait_method,\n-             trait_ref, tt_delim, tt_dotdotdot, tt_flat, tt_interpolate, ty,\n+             trait_ref, tt_delim, tt_seq, tt_tok, tt_nonterminal, ty,\n              ty_, ty_bot, ty_box, ty_field, ty_fn, ty_infer, ty_mac,\n              ty_method, ty_nil, ty_param, ty_path, ty_ptr, ty_rec, ty_rptr,\n              ty_tup, ty_u32, ty_uniq, ty_vec, ty_fixed_length, unchecked_blk,\n@@ -104,14 +104,14 @@ type item_info = (ident, item_, option<~[attribute]>);\n \n /* The expr situation is not as complex as I thought it would be.\n The important thing is to make sure that lookahead doesn't balk\n-at ACTUALLY tokens */\n-macro_rules! maybe_whole_expr{\n+at INTERPOLATED tokens */\n+macro_rules! maybe_whole_expr {\n     {$p:expr} => { alt copy $p.token {\n-      ACTUALLY(token::w_expr(e)) {\n+      INTERPOLATED(token::nt_expr(e)) {\n         $p.bump();\n         ret pexpr(e);\n       }\n-      ACTUALLY(token::w_path(pt)) {\n+      INTERPOLATED(token::nt_path(pt)) {\n         $p.bump();\n         ret $p.mk_pexpr($p.span.lo, $p.span.lo,\n                        expr_path(pt));\n@@ -122,7 +122,7 @@ macro_rules! maybe_whole_expr{\n \n macro_rules! maybe_whole {\n     {$p:expr, $constructor:path} => { alt copy $p.token {\n-      ACTUALLY($constructor(x)) { $p.bump(); ret x; }\n+      INTERPOLATED($constructor(x)) { $p.bump(); ret x; }\n       _ {}\n     }}\n }\n@@ -133,7 +133,7 @@ fn dummy() {\n     /* we will need this to bootstrap maybe_whole! */\n     #macro[[#maybe_whole_path[p],\n             alt p.token {\n-                ACTUALLY(token::w_path(pt)) { p.bump(); ret pt; }\n+                INTERPOLATED(token::nt_path(pt)) { p.bump(); ret pt; }\n                 _ {} }]];\n }\n \n@@ -1090,7 +1090,7 @@ class parser {\n             }\n         }\n \n-        fn parse_tt_flat(p: parser, delim_ok: bool) -> token_tree {\n+        fn parse_tt_tok(p: parser, delim_ok: bool) -> token_tree {\n             alt p.token {\n               token::RPAREN | token::RBRACE | token::RBRACKET\n               if !delim_ok {\n@@ -1110,14 +1110,14 @@ class parser {\n                                           seq_sep_none(),\n                                           |p| p.parse_token_tree());\n                     let (s, z) = p.parse_sep_and_zerok();\n-                    ret tt_dotdotdot(mk_sp(sp.lo ,p.span.hi), seq.node, s, z);\n+                    ret tt_seq(mk_sp(sp.lo ,p.span.hi), seq.node, s, z);\n                 } else {\n-                    ret tt_interpolate(sp, p.parse_ident());\n+                    ret tt_nonterminal(sp, p.parse_ident());\n                 }\n               }\n               _ { /* ok */ }\n             }\n-            let res = tt_flat(p.span, p.token);\n+            let res = tt_tok(p.span, p.token);\n             p.bump();\n             ret res;\n         }\n@@ -1126,14 +1126,14 @@ class parser {\n           token::LPAREN | token::LBRACE | token::LBRACKET {\n             let ket = flip(self.token);\n             tt_delim(vec::append(\n-                ~[parse_tt_flat(self, true)],\n+                ~[parse_tt_tok(self, true)],\n                 vec::append(\n                     self.parse_seq_to_before_end(\n                         ket, seq_sep_none(),\n                         |p| p.parse_token_tree()),\n-                    ~[parse_tt_flat(self, true)])))\n+                    ~[parse_tt_tok(self, true)])))\n           }\n-          _ { parse_tt_flat(self, false) }\n+          _ { parse_tt_tok(self, false) }\n         };\n     }\n \n@@ -1177,17 +1177,17 @@ class parser {\n                     self.fatal(~\"repetition body must be nonempty\");\n                 }\n                 let (sep, zerok) = self.parse_sep_and_zerok();\n-                mtc_rep(ms, sep, zerok, name_idx_lo, *name_idx)\n+                match_seq(ms, sep, zerok, name_idx_lo, *name_idx)\n             } else {\n                 let bound_to = self.parse_ident();\n                 self.expect(token::COLON);\n                 let nt_name = self.parse_ident();\n-                let m = mtc_bb(bound_to, nt_name, *name_idx);\n+                let m = match_nonterminal(bound_to, nt_name, *name_idx);\n                 *name_idx += 1u;\n                 m\n             }\n         } else {\n-            let m = mtc_tok(self.token);\n+            let m = match_tok(self.token);\n             self.bump();\n             m\n         };"}, {"sha": "51d5d52ebe8db13335fffcee734a0e28c79da859", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 23, "deletions": 21, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e11e90f31cedabec1e84b505bbf64103c3421574/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=e11e90f31cedabec1e84b505bbf64103c3421574", "patch": "@@ -79,25 +79,25 @@ enum token {\n     UNDERSCORE,\n \n     /* For interpolation */\n-    ACTUALLY(whole_nt),\n+    INTERPOLATED(nonterminal),\n \n     DOC_COMMENT(str_num),\n     EOF,\n }\n \n #[auto_serialize]\n /// For interpolation during macro expansion.\n-enum whole_nt {\n-    w_item(@ast::item),\n-    w_block(ast::blk),\n-    w_stmt(@ast::stmt),\n-    w_pat( @ast::pat),\n-    w_expr(@ast::expr),\n-    w_ty(  @ast::ty),\n-    w_ident(str_num, bool),\n-    w_path(@ast::path),\n-    w_tt(  @ast::token_tree), //needs @ed to break a circularity\n-    w_mtcs(~[ast::matcher])\n+enum nonterminal {\n+    nt_item(@ast::item),\n+    nt_block(ast::blk),\n+    nt_stmt(@ast::stmt),\n+    nt_pat( @ast::pat),\n+    nt_expr(@ast::expr),\n+    nt_ty(  @ast::ty),\n+    nt_ident(str_num, bool),\n+    nt_path(@ast::path),\n+    nt_tt(  @ast::token_tree), //needs @ed to break a circularity\n+    nt_matchers(~[ast::matcher])\n }\n \n fn binop_to_str(o: binop) -> ~str {\n@@ -184,14 +184,14 @@ fn to_str(in: interner<@~str>, t: token) -> ~str {\n       /* Other */\n       DOC_COMMENT(s) { *interner::get(in, s) }\n       EOF { ~\"<eof>\" }\n-      ACTUALLY(w_nt) {\n+      INTERPOLATED(nt) {\n         ~\"an interpolated \" +\n-            alt w_nt {\n-              w_item(*) { ~\"item\" } w_block(*) { ~\"block\" }\n-              w_stmt(*) { ~\"statement\" } w_pat(*) { ~\"pattern\" }\n-              w_expr(*) { ~\"expression\" } w_ty(*) { ~\"type\" }\n-              w_ident(*) { ~\"identifier\" } w_path(*) { ~\"path\" }\n-              w_tt(*) { ~\"tt\" } w_mtcs(*) { ~\"matcher sequence\" }\n+            alt nt {\n+              nt_item(*) { ~\"item\" } nt_block(*) { ~\"block\" }\n+              nt_stmt(*) { ~\"statement\" } nt_pat(*) { ~\"pattern\" }\n+              nt_expr(*) { ~\"expression\" } nt_ty(*) { ~\"type\" }\n+              nt_ident(*) { ~\"identifier\" } nt_path(*) { ~\"path\" }\n+              nt_tt(*) { ~\"tt\" } nt_matchers(*) { ~\"matcher sequence\" }\n             }\n       }\n     }\n@@ -219,8 +219,10 @@ pure fn can_begin_expr(t: token) -> bool {\n       BINOP(OR) { true } // in lambda syntax\n       OROR { true } // in lambda syntax\n       MOD_SEP { true }\n-      ACTUALLY(w_expr(*)) | ACTUALLY(w_ident(*)) | ACTUALLY(w_block(*))\n-      | ACTUALLY(w_path(*)) { true }\n+      INTERPOLATED(nt_expr(*))\n+      | INTERPOLATED(nt_ident(*))\n+      | INTERPOLATED(nt_block(*))\n+      | INTERPOLATED(nt_path(*)) { true }\n       _ { false }\n     }\n }"}]}