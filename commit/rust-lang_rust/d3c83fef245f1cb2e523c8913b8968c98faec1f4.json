{"sha": "d3c83fef245f1cb2e523c8913b8968c98faec1f4", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQzYzgzZmVmMjQ1ZjFjYjJlNTIzYzg5MTNiODk2OGM5OGZhZWMxZjQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-01-13T12:22:51Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2016-01-13T12:22:51Z"}, "message": "Auto merge of #30684 - tshepang:rustfmt-lexer-part2, r=nrc", "tree": {"sha": "7fa28b8b9dd00511926acb50031588f7d044bd0b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7fa28b8b9dd00511926acb50031588f7d044bd0b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d3c83fef245f1cb2e523c8913b8968c98faec1f4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d3c83fef245f1cb2e523c8913b8968c98faec1f4", "html_url": "https://github.com/rust-lang/rust/commit/d3c83fef245f1cb2e523c8913b8968c98faec1f4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d3c83fef245f1cb2e523c8913b8968c98faec1f4/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8796e012cbfa0bf63522e409edc10cbac5afaacd", "url": "https://api.github.com/repos/rust-lang/rust/commits/8796e012cbfa0bf63522e409edc10cbac5afaacd", "html_url": "https://github.com/rust-lang/rust/commit/8796e012cbfa0bf63522e409edc10cbac5afaacd"}, {"sha": "aa3b4c668e00815c5885698887bb2412f408aced", "url": "https://api.github.com/repos/rust-lang/rust/commits/aa3b4c668e00815c5885698887bb2412f408aced", "html_url": "https://github.com/rust-lang/rust/commit/aa3b4c668e00815c5885698887bb2412f408aced"}], "stats": {"total": 1267, "additions": 756, "deletions": 511}, "files": [{"sha": "e336c98f03ca0c7d2795f2407776c12cca94c8b1", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 61, "deletions": 49, "changes": 110, "blob_url": "https://github.com/rust-lang/rust/blob/d3c83fef245f1cb2e523c8913b8968c98faec1f4/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d3c83fef245f1cb2e523c8913b8968c98faec1f4/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=d3c83fef245f1cb2e523c8913b8968c98faec1f4", "patch": "@@ -43,10 +43,8 @@ pub struct Comment {\n }\n \n pub fn is_doc_comment(s: &str) -> bool {\n-    (s.starts_with(\"///\") && super::is_doc_comment(s)) ||\n-    s.starts_with(\"//!\") ||\n-    (s.starts_with(\"/**\") && is_block_doc_comment(s)) ||\n-    s.starts_with(\"/*!\")\n+    (s.starts_with(\"///\") && super::is_doc_comment(s)) || s.starts_with(\"//!\") ||\n+    (s.starts_with(\"/**\") && is_block_doc_comment(s)) || s.starts_with(\"/*!\")\n }\n \n pub fn doc_comment_style(comment: &str) -> ast::AttrStyle {\n@@ -64,18 +62,18 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n         let mut i = 0;\n         let mut j = lines.len();\n         // first line of all-stars should be omitted\n-        if !lines.is_empty() &&\n-                lines[0].chars().all(|c| c == '*') {\n+        if !lines.is_empty() && lines[0].chars().all(|c| c == '*') {\n             i += 1;\n         }\n         while i < j && lines[i].trim().is_empty() {\n             i += 1;\n         }\n         // like the first, a last line of all stars should be omitted\n-        if j > i && lines[j - 1]\n-                         .chars()\n-                         .skip(1)\n-                         .all(|c| c == '*') {\n+        if j > i &&\n+           lines[j - 1]\n+               .chars()\n+               .skip(1)\n+               .all(|c| c == '*') {\n             j -= 1;\n         }\n         while j > i && lines[j - 1].trim().is_empty() {\n@@ -85,7 +83,7 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n     }\n \n     /// remove a \"[ \\t]*\\*\" block from each line, if possible\n-    fn horizontal_trim(lines: Vec<String> ) -> Vec<String> {\n+    fn horizontal_trim(lines: Vec<String>) -> Vec<String> {\n         let mut i = usize::MAX;\n         let mut can_trim = true;\n         let mut first = true;\n@@ -114,9 +112,9 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n         }\n \n         if can_trim {\n-            lines.iter().map(|line| {\n-                (&line[i + 1..line.len()]).to_string()\n-            }).collect()\n+            lines.iter()\n+                 .map(|line| (&line[i + 1..line.len()]).to_string())\n+                 .collect()\n         } else {\n             lines\n         }\n@@ -132,9 +130,9 @@ pub fn strip_doc_comment_decoration(comment: &str) -> String {\n \n     if comment.starts_with(\"/*\") {\n         let lines = comment[3..comment.len() - 2]\n-            .lines()\n-            .map(|s| s.to_string())\n-            .collect::<Vec<String> >();\n+                        .lines()\n+                        .map(|s| s.to_string())\n+                        .collect::<Vec<String>>();\n \n         let lines = vertical_trim(lines);\n         let lines = horizontal_trim(lines);\n@@ -154,8 +152,7 @@ fn push_blank_line_comment(rdr: &StringReader, comments: &mut Vec<Comment>) {\n     });\n }\n \n-fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader,\n-                                           comments: &mut Vec<Comment>) {\n+fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader, comments: &mut Vec<Comment>) {\n     while is_whitespace(rdr.curr) && !rdr.is_eof() {\n         if rdr.col == CharPos(0) && rdr.curr_is('\\n') {\n             push_blank_line_comment(rdr, &mut *comments);\n@@ -165,19 +162,21 @@ fn consume_whitespace_counting_blank_lines(rdr: &mut StringReader,\n }\n \n \n-fn read_shebang_comment(rdr: &mut StringReader, code_to_the_left: bool,\n+fn read_shebang_comment(rdr: &mut StringReader,\n+                        code_to_the_left: bool,\n                         comments: &mut Vec<Comment>) {\n     debug!(\">>> shebang comment\");\n     let p = rdr.last_pos;\n     debug!(\"<<< shebang comment\");\n     comments.push(Comment {\n         style: if code_to_the_left { Trailing } else { Isolated },\n-        lines: vec!(rdr.read_one_line_comment()),\n-        pos: p\n+        lines: vec![rdr.read_one_line_comment()],\n+        pos: p,\n     });\n }\n \n-fn read_line_comments(rdr: &mut StringReader, code_to_the_left: bool,\n+fn read_line_comments(rdr: &mut StringReader,\n+                      code_to_the_left: bool,\n                       comments: &mut Vec<Comment>) {\n     debug!(\">>> line comments\");\n     let p = rdr.last_pos;\n@@ -197,7 +196,7 @@ fn read_line_comments(rdr: &mut StringReader, code_to_the_left: bool,\n         comments.push(Comment {\n             style: if code_to_the_left { Trailing } else { Isolated },\n             lines: lines,\n-            pos: p\n+            pos: p,\n         });\n     }\n }\n@@ -220,8 +219,7 @@ fn all_whitespace(s: &str, col: CharPos) -> Option<usize> {\n     return Some(cursor);\n }\n \n-fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<String> ,\n-                                        s: String, col: CharPos) {\n+fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<String>, s: String, col: CharPos) {\n     let len = s.len();\n     let s1 = match all_whitespace(&s[..], col) {\n         Some(col) => {\n@@ -239,7 +237,7 @@ fn trim_whitespace_prefix_and_push_line(lines: &mut Vec<String> ,\n \n fn read_block_comment(rdr: &mut StringReader,\n                       code_to_the_left: bool,\n-                      comments: &mut Vec<Comment> ) {\n+                      comments: &mut Vec<Comment>) {\n     debug!(\">>> block comment\");\n     let p = rdr.last_pos;\n     let mut lines: Vec<String> = Vec::new();\n@@ -261,7 +259,7 @@ fn read_block_comment(rdr: &mut StringReader,\n             rdr.bump();\n         }\n         if is_block_doc_comment(&curr_line[..]) {\n-            return\n+            return;\n         }\n         assert!(!curr_line.contains('\\n'));\n         lines.push(curr_line);\n@@ -273,9 +271,7 @@ fn read_block_comment(rdr: &mut StringReader,\n                 panic!(rdr.fatal(\"unterminated block comment\"));\n             }\n             if rdr.curr_is('\\n') {\n-                trim_whitespace_prefix_and_push_line(&mut lines,\n-                                                     curr_line,\n-                                                     col);\n+                trim_whitespace_prefix_and_push_line(&mut lines, curr_line, col);\n                 curr_line = String::new();\n                 rdr.bump();\n             } else {\n@@ -291,38 +287,46 @@ fn read_block_comment(rdr: &mut StringReader,\n                         rdr.bump();\n                         curr_line.push('/');\n                         level -= 1;\n-                    } else { rdr.bump(); }\n+                    } else {\n+                        rdr.bump();\n+                    }\n                 }\n             }\n         }\n         if !curr_line.is_empty() {\n-            trim_whitespace_prefix_and_push_line(&mut lines,\n-                                                 curr_line,\n-                                                 col);\n+            trim_whitespace_prefix_and_push_line(&mut lines, curr_line, col);\n         }\n     }\n \n-    let mut style = if code_to_the_left { Trailing } else { Isolated };\n+    let mut style = if code_to_the_left {\n+        Trailing\n+    } else {\n+        Isolated\n+    };\n     rdr.consume_non_eol_whitespace();\n     if !rdr.is_eof() && !rdr.curr_is('\\n') && lines.len() == 1 {\n         style = Mixed;\n     }\n     debug!(\"<<< block comment\");\n-    comments.push(Comment {style: style, lines: lines, pos: p});\n+    comments.push(Comment {\n+        style: style,\n+        lines: lines,\n+        pos: p,\n+    });\n }\n \n \n-fn consume_comment(rdr: &mut StringReader,\n-                   code_to_the_left: bool,\n-                   comments: &mut Vec<Comment> ) {\n+fn consume_comment(rdr: &mut StringReader, code_to_the_left: bool, comments: &mut Vec<Comment>) {\n     debug!(\">>> consume comment\");\n     if rdr.curr_is('/') && rdr.nextch_is('/') {\n         read_line_comments(rdr, code_to_the_left, comments);\n     } else if rdr.curr_is('/') && rdr.nextch_is('*') {\n         read_block_comment(rdr, code_to_the_left, comments);\n     } else if rdr.curr_is('#') && rdr.nextch_is('!') {\n         read_shebang_comment(rdr, code_to_the_left, comments);\n-    } else { panic!(); }\n+    } else {\n+        panic!();\n+    }\n     debug!(\"<<< consume comment\");\n }\n \n@@ -337,7 +341,7 @@ pub struct Literal {\n pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n                                     path: String,\n                                     srdr: &mut Read)\n-                                 -> (Vec<Comment>, Vec<Literal>) {\n+                                    -> (Vec<Comment>, Vec<Literal>) {\n     let mut src = Vec::new();\n     srdr.read_to_end(&mut src).unwrap();\n     let src = String::from_utf8(src).unwrap();\n@@ -366,12 +370,15 @@ pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n \n         let bstart = rdr.last_pos;\n         rdr.next_token();\n-        //discard, and look ahead; we're working with internal state\n+        // discard, and look ahead; we're working with internal state\n         let TokenAndSpan { tok, sp } = rdr.peek();\n         if tok.is_lit() {\n             rdr.with_str_from(bstart, |s| {\n                 debug!(\"tok lit: {}\", s);\n-                literals.push(Literal {lit: s.to_string(), pos: sp.lo});\n+                literals.push(Literal {\n+                    lit: s.to_string(),\n+                    pos: sp.lo,\n+                });\n             })\n         } else {\n             debug!(\"tok: {}\", pprust::token_to_string(&tok));\n@@ -386,31 +393,36 @@ pub fn gather_comments_and_literals(span_diagnostic: &errors::Handler,\n mod tests {\n     use super::*;\n \n-    #[test] fn test_block_doc_comment_1() {\n+    #[test]\n+    fn test_block_doc_comment_1() {\n         let comment = \"/**\\n * Test \\n **  Test\\n *   Test\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n         assert_eq!(stripped, \" Test \\n*  Test\\n   Test\");\n     }\n \n-    #[test] fn test_block_doc_comment_2() {\n+    #[test]\n+    fn test_block_doc_comment_2() {\n         let comment = \"/**\\n * Test\\n *  Test\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n         assert_eq!(stripped, \" Test\\n  Test\");\n     }\n \n-    #[test] fn test_block_doc_comment_3() {\n+    #[test]\n+    fn test_block_doc_comment_3() {\n         let comment = \"/**\\n let a: *i32;\\n *a = 5;\\n*/\";\n         let stripped = strip_doc_comment_decoration(comment);\n         assert_eq!(stripped, \" let a: *i32;\\n *a = 5;\");\n     }\n \n-    #[test] fn test_block_doc_comment_4() {\n+    #[test]\n+    fn test_block_doc_comment_4() {\n         let comment = \"/*******************\\n test\\n *********************/\";\n         let stripped = strip_doc_comment_decoration(comment);\n         assert_eq!(stripped, \" test\");\n     }\n \n-    #[test] fn test_line_doc_comment() {\n+    #[test]\n+    fn test_line_doc_comment() {\n         let stripped = strip_doc_comment_decoration(\"/// test\");\n         assert_eq!(stripped, \" test\");\n         let stripped = strip_doc_comment_decoration(\"///! test\");"}, {"sha": "1402b7888dd10e7089733a6176f70f841b6645bc", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 695, "deletions": 462, "changes": 1157, "blob_url": "https://github.com/rust-lang/rust/blob/d3c83fef245f1cb2e523c8913b8968c98faec1f4/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d3c83fef245f1cb2e523c8913b8968c98faec1f4/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=d3c83fef245f1cb2e523c8913b8968c98faec1f4", "patch": "@@ -42,8 +42,8 @@ pub trait Reader {\n             match t.tok {\n                 token::Whitespace | token::Comment | token::Shebang(_) => {\n                     t = self.next_token();\n-                },\n-                _ => break\n+                }\n+                _ => break,\n             }\n         }\n         t\n@@ -67,17 +67,19 @@ pub struct StringReader<'a> {\n     /// The last character to be read\n     pub curr: Option<char>,\n     pub filemap: Rc<codemap::FileMap>,\n-    /* cached: */\n+    // cached:\n     pub peek_tok: token::Token,\n     pub peek_span: Span,\n \n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.filemap.src.as_ref().unwrap()` all the time.\n-    source_text: Rc<String>\n+    source_text: Rc<String>,\n }\n \n impl<'a> Reader for StringReader<'a> {\n-    fn is_eof(&self) -> bool { self.curr.is_none() }\n+    fn is_eof(&self) -> bool {\n+        self.curr.is_none()\n+    }\n     /// Return the next token. EFFECT: advances the string_reader.\n     fn next_token(&mut self) -> TokenAndSpan {\n         let ret_val = TokenAndSpan {\n@@ -128,10 +130,12 @@ impl<'a> Reader for TtReader<'a> {\n impl<'a> StringReader<'a> {\n     /// For comments.rs, which hackily pokes into pos and curr\n     pub fn new_raw<'b>(span_diagnostic: &'b Handler,\n-                       filemap: Rc<codemap::FileMap>) -> StringReader<'b> {\n+                       filemap: Rc<codemap::FileMap>)\n+                       -> StringReader<'b> {\n         if filemap.src.is_none() {\n-            span_diagnostic.bug(&format!(\"Cannot lex filemap without source: {}\",\n-                                                 filemap.name)[..]);\n+            span_diagnostic.bug(&format!(\"Cannot lex filemap \\\n+                                          without source: {}\",\n+                                         filemap.name)[..]);\n         }\n \n         let source_text = (*filemap.src.as_ref().unwrap()).clone();\n@@ -143,17 +147,18 @@ impl<'a> StringReader<'a> {\n             col: CharPos(0),\n             curr: Some('\\n'),\n             filemap: filemap,\n-            /* dummy values; not read */\n+            // dummy values; not read\n             peek_tok: token::Eof,\n             peek_span: codemap::DUMMY_SP,\n-            source_text: source_text\n+            source_text: source_text,\n         };\n         sr.bump();\n         sr\n     }\n \n     pub fn new<'b>(span_diagnostic: &'b Handler,\n-                   filemap: Rc<codemap::FileMap>) -> StringReader<'b> {\n+                   filemap: Rc<codemap::FileMap>)\n+                   -> StringReader<'b> {\n         let mut sr = StringReader::new_raw(span_diagnostic, filemap);\n         sr.advance_token();\n         sr\n@@ -189,18 +194,22 @@ impl<'a> StringReader<'a> {\n     fn fatal_span_char(&self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) -> FatalError {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n-        for c in c.escape_default() { m.push(c) }\n+        for c in c.escape_default() {\n+            m.push(c)\n+        }\n         self.fatal_span_(from_pos, to_pos, &m[..])\n     }\n     fn struct_fatal_span_char(&self,\n                               from_pos: BytePos,\n                               to_pos: BytePos,\n                               m: &str,\n                               c: char)\n-                              -> DiagnosticBuilder<'a>  {\n+                              -> DiagnosticBuilder<'a> {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n-        for c in c.escape_default() { m.push(c) }\n+        for c in c.escape_default() {\n+            m.push(c)\n+        }\n         self.span_diagnostic.struct_span_fatal(codemap::mk_sp(from_pos, to_pos), &m[..])\n     }\n \n@@ -209,18 +218,22 @@ impl<'a> StringReader<'a> {\n     fn err_span_char(&self, from_pos: BytePos, to_pos: BytePos, m: &str, c: char) {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n-        for c in c.escape_default() { m.push(c) }\n+        for c in c.escape_default() {\n+            m.push(c)\n+        }\n         self.err_span_(from_pos, to_pos, &m[..]);\n     }\n     fn struct_err_span_char(&self,\n                             from_pos: BytePos,\n                             to_pos: BytePos,\n                             m: &str,\n                             c: char)\n-                            -> DiagnosticBuilder<'a>  {\n+                            -> DiagnosticBuilder<'a> {\n         let mut m = m.to_string();\n         m.push_str(\": \");\n-        for c in c.escape_default() { m.push(c) }\n+        for c in c.escape_default() {\n+            m.push(c)\n+        }\n         self.span_diagnostic.struct_span_err(codemap::mk_sp(from_pos, to_pos), &m[..])\n     }\n \n@@ -241,16 +254,15 @@ impl<'a> StringReader<'a> {\n             Some(comment) => {\n                 self.peek_span = comment.sp;\n                 self.peek_tok = comment.tok;\n-            },\n+            }\n             None => {\n                 if self.is_eof() {\n                     self.peek_tok = token::Eof;\n                     self.peek_span = codemap::mk_sp(self.filemap.end_pos, self.filemap.end_pos);\n                 } else {\n                     let start_bytepos = self.last_pos;\n                     self.peek_tok = self.next_token_inner();\n-                    self.peek_span = codemap::mk_sp(start_bytepos,\n-                                                    self.last_pos);\n+                    self.peek_span = codemap::mk_sp(start_bytepos, self.last_pos);\n                 };\n             }\n         }\n@@ -263,8 +275,8 @@ impl<'a> StringReader<'a> {\n     /// Calls `f` with a string slice of the source text spanning from `start`\n     /// up to but excluding `self.last_pos`, meaning the slice does not include\n     /// the character `self.curr`.\n-    pub fn with_str_from<T, F>(&self, start: BytePos, f: F) -> T where\n-        F: FnOnce(&str) -> T,\n+    pub fn with_str_from<T, F>(&self, start: BytePos, f: F) -> T\n+        where F: FnOnce(&str) -> T\n     {\n         self.with_str_from_to(start, self.last_pos, f)\n     }\n@@ -285,16 +297,14 @@ impl<'a> StringReader<'a> {\n \n     /// Calls `f` with a string slice of the source text spanning from `start`\n     /// up to but excluding `end`.\n-    fn with_str_from_to<T, F>(&self, start: BytePos, end: BytePos, f: F) -> T where\n-        F: FnOnce(&str) -> T,\n+    fn with_str_from_to<T, F>(&self, start: BytePos, end: BytePos, f: F) -> T\n+        where F: FnOnce(&str) -> T\n     {\n-        f(&self.source_text[self.byte_offset(start).to_usize()..\n-                            self.byte_offset(end).to_usize()])\n+        f(&self.source_text[self.byte_offset(start).to_usize()..self.byte_offset(end).to_usize()])\n     }\n \n     /// Converts CRLF to LF in the given string, raising an error on bare CR.\n-    fn translate_crlf<'b>(&self, start: BytePos,\n-                          s: &'b str, errmsg: &'b str) -> Cow<'b, str> {\n+    fn translate_crlf<'b>(&self, start: BytePos, s: &'b str, errmsg: &'b str) -> Cow<'b, str> {\n         let mut i = 0;\n         while i < s.len() {\n             let ch = char_at(s, i);\n@@ -311,15 +321,21 @@ impl<'a> StringReader<'a> {\n         }\n         return s.into();\n \n-        fn translate_crlf_(rdr: &StringReader, start: BytePos,\n-                        s: &str, errmsg: &str, mut i: usize) -> String {\n+        fn translate_crlf_(rdr: &StringReader,\n+                           start: BytePos,\n+                           s: &str,\n+                           errmsg: &str,\n+                           mut i: usize)\n+                           -> String {\n             let mut buf = String::with_capacity(s.len());\n             let mut j = 0;\n             while i < s.len() {\n                 let ch = char_at(s, i);\n                 let next = i + ch.len_utf8();\n                 if ch == '\\r' {\n-                    if j < i { buf.push_str(&s[j..i]); }\n+                    if j < i {\n+                        buf.push_str(&s[j..i]);\n+                    }\n                     j = next;\n                     if next >= s.len() || char_at(s, next) != '\\n' {\n                         let pos = start + BytePos(i as u32);\n@@ -329,7 +345,9 @@ impl<'a> StringReader<'a> {\n                 }\n                 i = next;\n             }\n-            if j < s.len() { buf.push_str(&s[j..]); }\n+            if j < s.len() {\n+                buf.push_str(&s[j..]);\n+            }\n             buf\n         }\n     }\n@@ -378,7 +396,9 @@ impl<'a> StringReader<'a> {\n     pub fn nextnextch(&self) -> Option<char> {\n         let offset = self.byte_offset(self.pos).to_usize();\n         let s = &self.source_text[..];\n-        if offset >= s.len() { return None }\n+        if offset >= s.len() {\n+            return None;\n+        }\n         let next = offset + char_at(s, offset).len_utf8();\n         if next < s.len() {\n             Some(char_at(s, next))\n@@ -394,7 +414,7 @@ impl<'a> StringReader<'a> {\n     /// Eats <XID_start><XID_continue>*, if possible.\n     fn scan_optional_raw_name(&mut self) -> Option<ast::Name> {\n         if !ident_start(self.curr) {\n-            return None\n+            return None;\n         }\n         let start = self.last_pos;\n         while ident_continue(self.curr) {\n@@ -417,10 +437,11 @@ impl<'a> StringReader<'a> {\n             Some(c) => {\n                 if c.is_whitespace() {\n                     self.span_diagnostic.span_err(codemap::mk_sp(self.last_pos, self.last_pos),\n-                                    \"called consume_any_line_comment, but there was whitespace\");\n+                                                  \"called consume_any_line_comment, but there \\\n+                                                   was whitespace\");\n                 }\n-            },\n-            None => { }\n+            }\n+            None => {}\n         }\n \n         if self.curr_is('/') {\n@@ -443,13 +464,14 @@ impl<'a> StringReader<'a> {\n                             '\\r' => {\n                                 if self.nextch_is('\\n') {\n                                     // CRLF\n-                                    break\n+                                    break;\n                                 } else if doc_comment {\n-                                    self.err_span_(self.last_pos, self.pos,\n+                                    self.err_span_(self.last_pos,\n+                                                   self.pos,\n                                                    \"bare CR not allowed in doc-comment\");\n                                 }\n                             }\n-                            _ => ()\n+                            _ => (),\n                         }\n                         self.bump();\n                     }\n@@ -465,21 +487,22 @@ impl<'a> StringReader<'a> {\n \n                             Some(TokenAndSpan {\n                                 tok: tok,\n-                                sp: codemap::mk_sp(start_bpos, self.last_pos)\n+                                sp: codemap::mk_sp(start_bpos, self.last_pos),\n                             })\n                         })\n                     } else {\n                         Some(TokenAndSpan {\n                             tok: token::Comment,\n-                            sp: codemap::mk_sp(start_bpos, self.last_pos)\n+                            sp: codemap::mk_sp(start_bpos, self.last_pos),\n                         })\n-                    }\n+                    };\n                 }\n                 Some('*') => {\n-                    self.bump(); self.bump();\n+                    self.bump();\n+                    self.bump();\n                     self.scan_block_comment()\n                 }\n-                _ => None\n+                _ => None,\n             }\n         } else if self.curr_is('#') {\n             if self.nextch_is('!') {\n@@ -498,10 +521,12 @@ impl<'a> StringReader<'a> {\n                 if loc.line == 1 && loc.col == CharPos(0) {\n                     // FIXME: Add shebang \"token\", return it\n                     let start = self.last_pos;\n-                    while !self.curr_is('\\n') && !self.is_eof() { self.bump(); }\n+                    while !self.curr_is('\\n') && !self.is_eof() {\n+                        self.bump();\n+                    }\n                     return Some(TokenAndSpan {\n                         tok: token::Shebang(self.name_from(start)),\n-                        sp: codemap::mk_sp(start, self.last_pos)\n+                        sp: codemap::mk_sp(start, self.last_pos),\n                     });\n                 }\n             }\n@@ -521,18 +546,20 @@ impl<'a> StringReader<'a> {\n                 let c = self.scan_comment();\n                 debug!(\"scanning a comment {:?}\", c);\n                 c\n-            },\n+            }\n             c if is_whitespace(Some(c)) => {\n                 let start_bpos = self.last_pos;\n-                while is_whitespace(self.curr) { self.bump(); }\n+                while is_whitespace(self.curr) {\n+                    self.bump();\n+                }\n                 let c = Some(TokenAndSpan {\n                     tok: token::Whitespace,\n-                    sp: codemap::mk_sp(start_bpos, self.last_pos)\n+                    sp: codemap::mk_sp(start_bpos, self.last_pos),\n                 });\n                 debug!(\"scanning whitespace: {:?}\", c);\n                 c\n-            },\n-            _ => None\n+            }\n+            _ => None,\n         }\n     }\n \n@@ -567,7 +594,7 @@ impl<'a> StringReader<'a> {\n                 '\\r' => {\n                     has_cr = true;\n                 }\n-                _ => ()\n+                _ => (),\n             }\n             self.bump();\n         }\n@@ -576,17 +603,20 @@ impl<'a> StringReader<'a> {\n             // but comments with only \"*\"s between two \"/\"s are not\n             let tok = if is_block_doc_comment(string) {\n                 let string = if has_cr {\n-                    self.translate_crlf(start_bpos, string,\n+                    self.translate_crlf(start_bpos,\n+                                        string,\n                                         \"bare CR not allowed in block doc-comment\")\n-                } else { string.into() };\n+                } else {\n+                    string.into()\n+                };\n                 token::DocComment(token::intern(&string[..]))\n             } else {\n                 token::Comment\n             };\n \n-            Some(TokenAndSpan{\n+            Some(TokenAndSpan {\n                 tok: tok,\n-                sp: codemap::mk_sp(start_bpos, self.last_pos)\n+                sp: codemap::mk_sp(start_bpos, self.last_pos),\n             })\n         })\n     }\n@@ -602,23 +632,27 @@ impl<'a> StringReader<'a> {\n         let mut len = 0;\n         loop {\n             let c = self.curr;\n-            if c == Some('_') { debug!(\"skipping a _\"); self.bump(); continue; }\n+            if c == Some('_') {\n+                debug!(\"skipping a _\");\n+                self.bump();\n+                continue;\n+            }\n             match c.and_then(|cc| cc.to_digit(scan_radix)) {\n                 Some(_) => {\n                     debug!(\"{:?} in scan_digits\", c);\n                     // check that the hypothetical digit is actually\n                     // in range for the true radix\n                     if c.unwrap().to_digit(real_radix).is_none() {\n-                        self.err_span_(self.last_pos, self.pos,\n-                                       &format!(\"invalid digit for a base {} literal\",\n-                                                real_radix));\n+                        self.err_span_(self.last_pos,\n+                                       self.pos,\n+                                       &format!(\"invalid digit for a base {} literal\", real_radix));\n                     }\n                     len += 1;\n                     self.bump();\n                 }\n-                _ => return len\n+                _ => return len,\n             }\n-        };\n+        }\n     }\n \n     /// Lex a LIT_INTEGER or a LIT_FLOAT\n@@ -631,9 +665,21 @@ impl<'a> StringReader<'a> {\n \n         if c == '0' {\n             match self.curr.unwrap_or('\\0') {\n-                'b' => { self.bump(); base = 2; num_digits = self.scan_digits(2, 10); }\n-                'o' => { self.bump(); base = 8; num_digits = self.scan_digits(8, 10); }\n-                'x' => { self.bump(); base = 16; num_digits = self.scan_digits(16, 16); }\n+                'b' => {\n+                    self.bump();\n+                    base = 2;\n+                    num_digits = self.scan_digits(2, 10);\n+                }\n+                'o' => {\n+                    self.bump();\n+                    base = 8;\n+                    num_digits = self.scan_digits(8, 10);\n+                }\n+                'x' => {\n+                    self.bump();\n+                    base = 16;\n+                    num_digits = self.scan_digits(16, 16);\n+                }\n                 '0'...'9' | '_' | '.' => {\n                     num_digits = self.scan_digits(10, 10) + 1;\n                 }\n@@ -649,15 +695,19 @@ impl<'a> StringReader<'a> {\n         }\n \n         if num_digits == 0 {\n-            self.err_span_(start_bpos, self.last_pos, \"no valid digits found for number\");\n+            self.err_span_(start_bpos,\n+                           self.last_pos,\n+                           \"no valid digits found for number\");\n             return token::Integer(token::intern(\"0\"));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n         // integer literal followed by field/method access or a range pattern\n         // (`0..2` and `12.foo()`)\n-        if self.curr_is('.') && !self.nextch_is('.') && !self.nextch().unwrap_or('\\0')\n-                                                             .is_xid_start() {\n+        if self.curr_is('.') && !self.nextch_is('.') &&\n+           !self.nextch()\n+                .unwrap_or('\\0')\n+                .is_xid_start() {\n             // might have stuff after the ., and if it does, it needs to start\n             // with a number\n             self.bump();\n@@ -683,11 +733,7 @@ impl<'a> StringReader<'a> {\n \n     /// Scan over `n_digits` hex digits, stopping at `delim`, reporting an\n     /// error if too many or too few digits are encountered.\n-    fn scan_hex_digits(&mut self,\n-                       n_digits: usize,\n-                       delim: char,\n-                       below_0x7f_only: bool)\n-                       -> bool {\n+    fn scan_hex_digits(&mut self, n_digits: usize, delim: char, below_0x7f_only: bool) -> bool {\n         debug!(\"scanning {} digits until {:?}\", n_digits, delim);\n         let start_bpos = self.last_pos;\n         let mut accum_int = 0;\n@@ -702,15 +748,19 @@ impl<'a> StringReader<'a> {\n             }\n             if self.curr_is(delim) {\n                 let last_bpos = self.last_pos;\n-                self.err_span_(start_bpos, last_bpos, \"numeric character escape is too short\");\n+                self.err_span_(start_bpos,\n+                               last_bpos,\n+                               \"numeric character escape is too short\");\n                 valid = false;\n                 break;\n             }\n             let c = self.curr.unwrap_or('\\x00');\n             accum_int *= 16;\n             accum_int += c.to_digit(16).unwrap_or_else(|| {\n-                self.err_span_char(self.last_pos, self.pos,\n-                              \"invalid character in numeric character escape\", c);\n+                self.err_span_char(self.last_pos,\n+                                   self.pos,\n+                                   \"invalid character in numeric character escape\",\n+                                   c);\n \n                 valid = false;\n                 0\n@@ -721,8 +771,8 @@ impl<'a> StringReader<'a> {\n         if below_0x7f_only && accum_int >= 0x80 {\n             self.err_span_(start_bpos,\n                            self.last_pos,\n-                           \"this form of character escape may only be used \\\n-                            with characters in the range [\\\\x00-\\\\x7f]\");\n+                           \"this form of character escape may only be used with characters in \\\n+                            the range [\\\\x00-\\\\x7f]\");\n             valid = false;\n         }\n \n@@ -741,16 +791,20 @@ impl<'a> StringReader<'a> {\n     /// `start` is the position of `first_source_char`, which is already consumed.\n     ///\n     /// Returns true if there was a valid char/byte, false otherwise.\n-    fn scan_char_or_byte(&mut self, start: BytePos, first_source_char: char,\n-                         ascii_only: bool, delim: char) -> bool {\n+    fn scan_char_or_byte(&mut self,\n+                         start: BytePos,\n+                         first_source_char: char,\n+                         ascii_only: bool,\n+                         delim: char)\n+                         -> bool {\n         match first_source_char {\n             '\\\\' => {\n                 // '\\X' for some X must be a character constant:\n                 let escaped = self.curr;\n                 let escaped_pos = self.last_pos;\n                 self.bump();\n                 match escaped {\n-                    None => {},  // EOF here is an error that will be checked later.\n+                    None => {}  // EOF here is an error that will be checked later.\n                     Some(e) => {\n                         return match e {\n                             'n' | 'r' | 't' | '\\\\' | '\\'' | '\"' | '0' => true,\n@@ -760,46 +814,52 @@ impl<'a> StringReader<'a> {\n                                     self.scan_unicode_escape(delim) && !ascii_only\n                                 } else {\n                                     let span = codemap::mk_sp(start, self.last_pos);\n-                                    self.span_diagnostic.struct_span_err(span,\n-                                        \"incorrect unicode escape sequence\")\n+                                    self.span_diagnostic\n+                                        .struct_span_err(span, \"incorrect unicode escape sequence\")\n                                         .span_help(span,\n-                                        \"format of unicode escape sequences is `\\\\u{\u2026}`\")\n+                                                   \"format of unicode escape sequences is \\\n+                                                    `\\\\u{\u2026}`\")\n                                         .emit();\n                                     false\n                                 };\n                                 if ascii_only {\n-                                    self.err_span_(start, self.last_pos,\n-                                        \"unicode escape sequences cannot be used as a byte or in \\\n-                                        a byte string\"\n-                                    );\n+                                    self.err_span_(start,\n+                                                   self.last_pos,\n+                                                   \"unicode escape sequences cannot be used as a \\\n+                                                    byte or in a byte string\");\n                                 }\n                                 valid\n \n                             }\n                             '\\n' if delim == '\"' => {\n                                 self.consume_whitespace();\n                                 true\n-                            },\n+                            }\n                             '\\r' if delim == '\"' && self.curr_is('\\n') => {\n                                 self.consume_whitespace();\n                                 true\n                             }\n                             c => {\n                                 let last_pos = self.last_pos;\n-                                let mut err = self.struct_err_span_char(\n-                                    escaped_pos, last_pos,\n-                                    if ascii_only { \"unknown byte escape\" }\n-                                    else { \"unknown character escape\" },\n-                                    c);\n+                                let mut err = self.struct_err_span_char(escaped_pos,\n+                                                                        last_pos,\n+                                                                        if ascii_only {\n+                                                                            \"unknown byte escape\"\n+                                                                        } else {\n+                                                                            \"unknown character \\\n+                                                                             escape\"\n+                                                                        },\n+                                                                        c);\n                                 if e == '\\r' {\n                                     err.span_help(codemap::mk_sp(escaped_pos, last_pos),\n-                                        \"this is an isolated carriage return; consider checking \\\n-                                         your editor and version control settings\");\n+                                                  \"this is an isolated carriage return; consider \\\n+                                                   checking your editor and version control \\\n+                                                   settings\");\n                                 }\n                                 if (e == '{' || e == '}') && !ascii_only {\n                                     err.span_help(codemap::mk_sp(escaped_pos, last_pos),\n-                                        \"if used in a formatting string, \\\n-                                        curly braces are escaped with `{{` and `}}`\");\n+                                                  \"if used in a formatting string, curly braces \\\n+                                                   are escaped with `{{` and `}}`\");\n                                 }\n                                 err.emit();\n                                 false\n@@ -810,30 +870,37 @@ impl<'a> StringReader<'a> {\n             }\n             '\\t' | '\\n' | '\\r' | '\\'' if delim == '\\'' => {\n                 let last_pos = self.last_pos;\n-                self.err_span_char(\n-                    start, last_pos,\n-                    if ascii_only { \"byte constant must be escaped\" }\n-                    else { \"character constant must be escaped\" },\n-                    first_source_char);\n+                self.err_span_char(start,\n+                                   last_pos,\n+                                   if ascii_only {\n+                                       \"byte constant must be escaped\"\n+                                   } else {\n+                                       \"character constant must be escaped\"\n+                                   },\n+                                   first_source_char);\n                 return false;\n             }\n             '\\r' => {\n                 if self.curr_is('\\n') {\n                     self.bump();\n                     return true;\n                 } else {\n-                    self.err_span_(start, self.last_pos,\n+                    self.err_span_(start,\n+                                   self.last_pos,\n                                    \"bare CR not allowed in string, use \\\\r instead\");\n                     return false;\n                 }\n             }\n-            _ => if ascii_only && first_source_char > '\\x7F' {\n-                let last_pos = self.last_pos;\n-                self.err_span_char(\n-                    start, last_pos,\n-                    \"byte constant must be ASCII. \\\n-                     Use a \\\\xHH escape for a non-ASCII byte\", first_source_char);\n-                return false;\n+            _ => {\n+                if ascii_only && first_source_char > '\\x7F' {\n+                    let last_pos = self.last_pos;\n+                    self.err_span_char(start,\n+                                       last_pos,\n+                                       \"byte constant must be ASCII. Use a \\\\xHH escape for a \\\n+                                        non-ASCII byte\",\n+                                       first_source_char);\n+                    return false;\n+                }\n             }\n         }\n         true\n@@ -854,18 +921,22 @@ impl<'a> StringReader<'a> {\n             let c = match self.curr {\n                 Some(c) => c,\n                 None => {\n-                    panic!(self.fatal_span_(start_bpos, self.last_pos,\n+                    panic!(self.fatal_span_(start_bpos,\n+                                            self.last_pos,\n                                             \"unterminated unicode escape (found EOF)\"));\n                 }\n             };\n             accum_int *= 16;\n             accum_int += c.to_digit(16).unwrap_or_else(|| {\n                 if c == delim {\n-                    panic!(self.fatal_span_(self.last_pos, self.pos,\n+                    panic!(self.fatal_span_(self.last_pos,\n+                                            self.pos,\n                                             \"unterminated unicode escape (needed a `}`)\"));\n                 } else {\n-                    self.err_span_char(self.last_pos, self.pos,\n-                                   \"invalid character in unicode escape\", c);\n+                    self.err_span_char(self.last_pos,\n+                                       self.pos,\n+                                       \"invalid character in unicode escape\",\n+                                       c);\n                 }\n                 valid = false;\n                 0\n@@ -875,13 +946,16 @@ impl<'a> StringReader<'a> {\n         }\n \n         if count > 6 {\n-            self.err_span_(start_bpos, self.last_pos,\n-                          \"overlong unicode escape (can have at most 6 hex digits)\");\n+            self.err_span_(start_bpos,\n+                           self.last_pos,\n+                           \"overlong unicode escape (can have at most 6 hex digits)\");\n             valid = false;\n         }\n \n         if valid && (char::from_u32(accum_int).is_none() || count == 0) {\n-            self.err_span_(start_bpos, self.last_pos, \"invalid unicode character escape\");\n+            self.err_span_(start_bpos,\n+                           self.last_pos,\n+                           \"invalid unicode character escape\");\n             valid = false;\n         }\n \n@@ -897,7 +971,9 @@ impl<'a> StringReader<'a> {\n                 self.bump();\n             }\n             if self.scan_digits(10, 10) == 0 {\n-                self.err_span_(self.last_pos, self.pos, \"expected at least one digit in exponent\")\n+                self.err_span_(self.last_pos,\n+                               self.pos,\n+                               \"expected at least one digit in exponent\")\n             }\n         }\n     }\n@@ -906,11 +982,22 @@ impl<'a> StringReader<'a> {\n     /// error if it isn't.\n     fn check_float_base(&mut self, start_bpos: BytePos, last_bpos: BytePos, base: usize) {\n         match base {\n-            16 => self.err_span_(start_bpos, last_bpos, \"hexadecimal float literal is not \\\n-                                   supported\"),\n-            8 => self.err_span_(start_bpos, last_bpos, \"octal float literal is not supported\"),\n-            2 => self.err_span_(start_bpos, last_bpos, \"binary float literal is not supported\"),\n-            _   => ()\n+            16 => {\n+                self.err_span_(start_bpos,\n+                               last_bpos,\n+                               \"hexadecimal float literal is not supported\")\n+            }\n+            8 => {\n+                self.err_span_(start_bpos,\n+                               last_bpos,\n+                               \"octal float literal is not supported\")\n+            }\n+            2 => {\n+                self.err_span_(start_bpos,\n+                               last_bpos,\n+                               \"binary float literal is not supported\")\n+            }\n+            _ => (),\n         }\n     }\n \n@@ -928,14 +1015,18 @@ impl<'a> StringReader<'a> {\n     /// token, and updates the interner\n     fn next_token_inner(&mut self) -> token::Token {\n         let c = self.curr;\n-        if ident_start(c) && match (c.unwrap(), self.nextch(), self.nextnextch()) {\n+        if ident_start(c) &&\n+           match (c.unwrap(), self.nextch(), self.nextnextch()) {\n             // Note: r as in r\" or r#\" is part of a raw string literal,\n             // b as in b' is part of a byte literal.\n             // They are not identifiers, and are handled further down.\n-           ('r', Some('\"'), _) | ('r', Some('#'), _) |\n-           ('b', Some('\"'), _) | ('b', Some('\\''), _) |\n-           ('b', Some('r'), Some('\"')) | ('b', Some('r'), Some('#')) => false,\n-           _ => true\n+            ('r', Some('\"'), _) |\n+            ('r', Some('#'), _) |\n+            ('b', Some('\"'), _) |\n+            ('b', Some('\\''), _) |\n+            ('b', Some('r'), Some('\"')) |\n+            ('b', Some('r'), Some('#')) => false,\n+            _ => true,\n         } {\n             let start = self.last_pos;\n             while ident_continue(self.curr) {\n@@ -960,299 +1051,393 @@ impl<'a> StringReader<'a> {\n             let num = self.scan_number(c.unwrap());\n             let suffix = self.scan_optional_raw_name();\n             debug!(\"next_token_inner: scanned number {:?}, {:?}\", num, suffix);\n-            return token::Literal(num, suffix)\n+            return token::Literal(num, suffix);\n         }\n \n         match c.expect(\"next_token_inner called at EOF\") {\n-          // One-byte tokens.\n-          ';' => { self.bump(); return token::Semi; }\n-          ',' => { self.bump(); return token::Comma; }\n-          '.' => {\n-              self.bump();\n-              return if self.curr_is('.') {\n-                  self.bump();\n-                  if self.curr_is('.') {\n-                      self.bump();\n-                      token::DotDotDot\n-                  } else {\n-                      token::DotDot\n-                  }\n-              } else {\n-                  token::Dot\n-              };\n-          }\n-          '(' => { self.bump(); return token::OpenDelim(token::Paren); }\n-          ')' => { self.bump(); return token::CloseDelim(token::Paren); }\n-          '{' => { self.bump(); return token::OpenDelim(token::Brace); }\n-          '}' => { self.bump(); return token::CloseDelim(token::Brace); }\n-          '[' => { self.bump(); return token::OpenDelim(token::Bracket); }\n-          ']' => { self.bump(); return token::CloseDelim(token::Bracket); }\n-          '@' => { self.bump(); return token::At; }\n-          '#' => { self.bump(); return token::Pound; }\n-          '~' => { self.bump(); return token::Tilde; }\n-          '?' => { self.bump(); return token::Question; }\n-          ':' => {\n-            self.bump();\n-            if self.curr_is(':') {\n+            // One-byte tokens.\n+            ';' => {\n                 self.bump();\n-                return token::ModSep;\n-            } else {\n-                return token::Colon;\n+                return token::Semi;\n+            }\n+            ',' => {\n+                self.bump();\n+                return token::Comma;\n+            }\n+            '.' => {\n+                self.bump();\n+                return if self.curr_is('.') {\n+                    self.bump();\n+                    if self.curr_is('.') {\n+                        self.bump();\n+                        token::DotDotDot\n+                    } else {\n+                        token::DotDot\n+                    }\n+                } else {\n+                    token::Dot\n+                };\n+            }\n+            '(' => {\n+                self.bump();\n+                return token::OpenDelim(token::Paren);\n+            }\n+            ')' => {\n+                self.bump();\n+                return token::CloseDelim(token::Paren);\n+            }\n+            '{' => {\n+                self.bump();\n+                return token::OpenDelim(token::Brace);\n+            }\n+            '}' => {\n+                self.bump();\n+                return token::CloseDelim(token::Brace);\n+            }\n+            '[' => {\n+                self.bump();\n+                return token::OpenDelim(token::Bracket);\n+            }\n+            ']' => {\n+                self.bump();\n+                return token::CloseDelim(token::Bracket);\n+            }\n+            '@' => {\n+                self.bump();\n+                return token::At;\n+            }\n+            '#' => {\n+                self.bump();\n+                return token::Pound;\n+            }\n+            '~' => {\n+                self.bump();\n+                return token::Tilde;\n+            }\n+            '?' => {\n+                self.bump();\n+                return token::Question;\n+            }\n+            ':' => {\n+                self.bump();\n+                if self.curr_is(':') {\n+                    self.bump();\n+                    return token::ModSep;\n+                } else {\n+                    return token::Colon;\n+                }\n             }\n-          }\n \n-          '$' => { self.bump(); return token::Dollar; }\n+            '$' => {\n+                self.bump();\n+                return token::Dollar;\n+            }\n \n-          // Multi-byte tokens.\n-          '=' => {\n-            self.bump();\n-            if self.curr_is('=') {\n+            // Multi-byte tokens.\n+            '=' => {\n                 self.bump();\n-                return token::EqEq;\n-            } else if self.curr_is('>') {\n+                if self.curr_is('=') {\n+                    self.bump();\n+                    return token::EqEq;\n+                } else if self.curr_is('>') {\n+                    self.bump();\n+                    return token::FatArrow;\n+                } else {\n+                    return token::Eq;\n+                }\n+            }\n+            '!' => {\n                 self.bump();\n-                return token::FatArrow;\n-            } else {\n-                return token::Eq;\n+                if self.curr_is('=') {\n+                    self.bump();\n+                    return token::Ne;\n+                } else {\n+                    return token::Not;\n+                }\n             }\n-          }\n-          '!' => {\n-            self.bump();\n-            if self.curr_is('=') {\n+            '<' => {\n                 self.bump();\n-                return token::Ne;\n-            } else { return token::Not; }\n-          }\n-          '<' => {\n-            self.bump();\n-            match self.curr.unwrap_or('\\x00') {\n-              '=' => { self.bump(); return token::Le; }\n-              '<' => { return self.binop(token::Shl); }\n-              '-' => {\n+                match self.curr.unwrap_or('\\x00') {\n+                    '=' => {\n+                        self.bump();\n+                        return token::Le;\n+                    }\n+                    '<' => {\n+                        return self.binop(token::Shl);\n+                    }\n+                    '-' => {\n+                        self.bump();\n+                        match self.curr.unwrap_or('\\x00') {\n+                            _ => {\n+                                return token::LArrow;\n+                            }\n+                        }\n+                    }\n+                    _ => {\n+                        return token::Lt;\n+                    }\n+                }\n+            }\n+            '>' => {\n                 self.bump();\n                 match self.curr.unwrap_or('\\x00') {\n-                  _ => { return token::LArrow; }\n+                    '=' => {\n+                        self.bump();\n+                        return token::Ge;\n+                    }\n+                    '>' => {\n+                        return self.binop(token::Shr);\n+                    }\n+                    _ => {\n+                        return token::Gt;\n+                    }\n                 }\n-              }\n-              _ => { return token::Lt; }\n             }\n-          }\n-          '>' => {\n-            self.bump();\n-            match self.curr.unwrap_or('\\x00') {\n-              '=' => { self.bump(); return token::Ge; }\n-              '>' => { return self.binop(token::Shr); }\n-              _ => { return token::Gt; }\n-            }\n-          }\n-          '\\'' => {\n-            // Either a character constant 'a' OR a lifetime name 'abc\n-            self.bump();\n-            let start = self.last_pos;\n+            '\\'' => {\n+                // Either a character constant 'a' OR a lifetime name 'abc\n+                self.bump();\n+                let start = self.last_pos;\n \n-            // the eof will be picked up by the final `'` check below\n-            let c2 = self.curr.unwrap_or('\\x00');\n-            self.bump();\n+                // the eof will be picked up by the final `'` check below\n+                let c2 = self.curr.unwrap_or('\\x00');\n+                self.bump();\n \n-            // If the character is an ident start not followed by another single\n-            // quote, then this is a lifetime name:\n-            if ident_start(Some(c2)) && !self.curr_is('\\'') {\n-                while ident_continue(self.curr) {\n-                    self.bump();\n-                }\n+                // If the character is an ident start not followed by another single\n+                // quote, then this is a lifetime name:\n+                if ident_start(Some(c2)) && !self.curr_is('\\'') {\n+                    while ident_continue(self.curr) {\n+                        self.bump();\n+                    }\n \n-                // Include the leading `'` in the real identifier, for macro\n-                // expansion purposes. See #12512 for the gory details of why\n-                // this is necessary.\n-                let ident = self.with_str_from(start, |lifetime_name| {\n-                    str_to_ident(&format!(\"'{}\", lifetime_name))\n-                });\n+                    // Include the leading `'` in the real identifier, for macro\n+                    // expansion purposes. See #12512 for the gory details of why\n+                    // this is necessary.\n+                    let ident = self.with_str_from(start, |lifetime_name| {\n+                        str_to_ident(&format!(\"'{}\", lifetime_name))\n+                    });\n \n-                // Conjure up a \"keyword checking ident\" to make sure that\n-                // the lifetime name is not a keyword.\n-                let keyword_checking_ident =\n-                    self.with_str_from(start, |lifetime_name| {\n+                    // Conjure up a \"keyword checking ident\" to make sure that\n+                    // the lifetime name is not a keyword.\n+                    let keyword_checking_ident = self.with_str_from(start, |lifetime_name| {\n                         str_to_ident(lifetime_name)\n                     });\n-                let keyword_checking_token =\n-                    &token::Ident(keyword_checking_ident, token::Plain);\n-                let last_bpos = self.last_pos;\n-                if keyword_checking_token.is_keyword(token::keywords::SelfValue) {\n-                    self.err_span_(start,\n-                                   last_bpos,\n-                                   \"invalid lifetime name: 'self \\\n-                                    is no longer a special lifetime\");\n-                } else if keyword_checking_token.is_any_keyword() &&\n-                    !keyword_checking_token.is_keyword(token::keywords::Static)\n-                {\n-                    self.err_span_(start,\n-                                   last_bpos,\n-                                   \"invalid lifetime name\");\n+                    let keyword_checking_token = &token::Ident(keyword_checking_ident,\n+                                                               token::Plain);\n+                    let last_bpos = self.last_pos;\n+                    if keyword_checking_token.is_keyword(token::keywords::SelfValue) {\n+                        self.err_span_(start,\n+                                       last_bpos,\n+                                       \"invalid lifetime name: 'self is no longer a special \\\n+                                        lifetime\");\n+                    } else if keyword_checking_token.is_any_keyword() &&\n+                       !keyword_checking_token.is_keyword(token::keywords::Static) {\n+                        self.err_span_(start, last_bpos, \"invalid lifetime name\");\n+                    }\n+                    return token::Lifetime(ident);\n                 }\n-                return token::Lifetime(ident);\n-            }\n \n-            // Otherwise it is a character constant:\n-            let valid = self.scan_char_or_byte(start, c2, /* ascii_only = */ false, '\\'');\n-            if !self.curr_is('\\'') {\n-                let last_bpos = self.last_pos;\n-                panic!(self.fatal_span_verbose(\n-                        // Byte offsetting here is okay because the\n-                        // character before position `start` is an\n-                        // ascii single quote.\n-                        start - BytePos(1), last_bpos,\n-\n-                        String::from(\"character literal may only contain one codepoint\")));\n-            }\n-            let id = if valid { self.name_from(start) } else { token::intern(\"0\") };\n-            self.bump(); // advance curr past token\n-            let suffix = self.scan_optional_raw_name();\n-            return token::Literal(token::Char(id), suffix);\n-          }\n-          'b' => {\n-            self.bump();\n-            let lit = match self.curr {\n-                Some('\\'') => self.scan_byte(),\n-                Some('\"') => self.scan_byte_string(),\n-                Some('r') => self.scan_raw_byte_string(),\n-                _ => unreachable!()  // Should have been a token::Ident above.\n-            };\n-            let suffix = self.scan_optional_raw_name();\n-            return token::Literal(lit, suffix);\n-          }\n-          '\"' => {\n-            let start_bpos = self.last_pos;\n-            let mut valid = true;\n-            self.bump();\n-            while !self.curr_is('\"') {\n-                if self.is_eof() {\n+                // Otherwise it is a character constant:\n+                let valid = self.scan_char_or_byte(start,\n+                                                   c2,\n+                                                   // ascii_only =\n+                                                   false,\n+                                                   '\\'');\n+                if !self.curr_is('\\'') {\n                     let last_bpos = self.last_pos;\n-                    panic!(self.fatal_span_(start_bpos,\n-                                            last_bpos,\n-                                            \"unterminated double quote string\"));\n+                    panic!(self.fatal_span_verbose(// Byte offsetting here is okay because the\n+                                                   // character before position `start` is an\n+                                                   // ascii single quote.\n+                                                   start - BytePos(1),\n+                                                   last_bpos,\n+\n+                                                   String::from(\"character literal may only \\\n+                                                                 contain one codepoint\")));\n                 }\n-\n-                let ch_start = self.last_pos;\n-                let ch = self.curr.unwrap();\n-                self.bump();\n-                valid &= self.scan_char_or_byte(ch_start, ch, /* ascii_only = */ false, '\"');\n+                let id = if valid {\n+                    self.name_from(start)\n+                } else {\n+                    token::intern(\"0\")\n+                };\n+                self.bump(); // advance curr past token\n+                let suffix = self.scan_optional_raw_name();\n+                return token::Literal(token::Char(id), suffix);\n             }\n-            // adjust for the ASCII \" at the start of the literal\n-            let id = if valid { self.name_from(start_bpos + BytePos(1)) }\n-                     else { token::intern(\"??\") };\n-            self.bump();\n-            let suffix = self.scan_optional_raw_name();\n-            return token::Literal(token::Str_(id), suffix);\n-          }\n-          'r' => {\n-            let start_bpos = self.last_pos;\n-            self.bump();\n-            let mut hash_count = 0;\n-            while self.curr_is('#') {\n+            'b' => {\n                 self.bump();\n-                hash_count += 1;\n+                let lit = match self.curr {\n+                    Some('\\'') => self.scan_byte(),\n+                    Some('\"') => self.scan_byte_string(),\n+                    Some('r') => self.scan_raw_byte_string(),\n+                    _ => unreachable!(),  // Should have been a token::Ident above.\n+                };\n+                let suffix = self.scan_optional_raw_name();\n+                return token::Literal(lit, suffix);\n             }\n+            '\"' => {\n+                let start_bpos = self.last_pos;\n+                let mut valid = true;\n+                self.bump();\n+                while !self.curr_is('\"') {\n+                    if self.is_eof() {\n+                        let last_bpos = self.last_pos;\n+                        panic!(self.fatal_span_(start_bpos,\n+                                                last_bpos,\n+                                                \"unterminated double quote string\"));\n+                    }\n \n-            if self.is_eof() {\n-                let last_bpos = self.last_pos;\n-                panic!(self.fatal_span_(start_bpos, last_bpos, \"unterminated raw string\"));\n-            } else if !self.curr_is('\"') {\n-                let last_bpos = self.last_pos;\n-                let curr_char = self.curr.unwrap();\n-                panic!(self.fatal_span_char(start_bpos, last_bpos,\n-                                \"found invalid character; \\\n-                                 only `#` is allowed in raw string delimitation\",\n-                                curr_char));\n+                    let ch_start = self.last_pos;\n+                    let ch = self.curr.unwrap();\n+                    self.bump();\n+                    valid &= self.scan_char_or_byte(ch_start,\n+                                                    ch,\n+                                                    // ascii_only =\n+                                                    false,\n+                                                    '\"');\n+                }\n+                // adjust for the ASCII \" at the start of the literal\n+                let id = if valid {\n+                    self.name_from(start_bpos + BytePos(1))\n+                } else {\n+                    token::intern(\"??\")\n+                };\n+                self.bump();\n+                let suffix = self.scan_optional_raw_name();\n+                return token::Literal(token::Str_(id), suffix);\n             }\n-            self.bump();\n-            let content_start_bpos = self.last_pos;\n-            let mut content_end_bpos;\n-            let mut valid = true;\n-            'outer: loop {\n+            'r' => {\n+                let start_bpos = self.last_pos;\n+                self.bump();\n+                let mut hash_count = 0;\n+                while self.curr_is('#') {\n+                    self.bump();\n+                    hash_count += 1;\n+                }\n+\n                 if self.is_eof() {\n                     let last_bpos = self.last_pos;\n                     panic!(self.fatal_span_(start_bpos, last_bpos, \"unterminated raw string\"));\n+                } else if !self.curr_is('\"') {\n+                    let last_bpos = self.last_pos;\n+                    let curr_char = self.curr.unwrap();\n+                    panic!(self.fatal_span_char(start_bpos,\n+                                                last_bpos,\n+                                                \"found invalid character; only `#` is allowed \\\n+                                                 in raw string delimitation\",\n+                                                curr_char));\n                 }\n-                //if self.curr_is('\"') {\n-                    //content_end_bpos = self.last_pos;\n-                    //for _ in 0..hash_count {\n-                        //self.bump();\n-                        //if !self.curr_is('#') {\n-                            //continue 'outer;\n-                let c = self.curr.unwrap();\n-                match c {\n-                    '\"' => {\n-                        content_end_bpos = self.last_pos;\n-                        for _ in 0..hash_count {\n-                            self.bump();\n-                            if !self.curr_is('#') {\n-                                continue 'outer;\n+                self.bump();\n+                let content_start_bpos = self.last_pos;\n+                let mut content_end_bpos;\n+                let mut valid = true;\n+                'outer: loop {\n+                    if self.is_eof() {\n+                        let last_bpos = self.last_pos;\n+                        panic!(self.fatal_span_(start_bpos, last_bpos, \"unterminated raw string\"));\n+                    }\n+                    // if self.curr_is('\"') {\n+                    // content_end_bpos = self.last_pos;\n+                    // for _ in 0..hash_count {\n+                    // self.bump();\n+                    // if !self.curr_is('#') {\n+                    // continue 'outer;\n+                    let c = self.curr.unwrap();\n+                    match c {\n+                        '\"' => {\n+                            content_end_bpos = self.last_pos;\n+                            for _ in 0..hash_count {\n+                                self.bump();\n+                                if !self.curr_is('#') {\n+                                    continue 'outer;\n+                                }\n                             }\n+                            break;\n                         }\n-                        break;\n-                    },\n-                    '\\r' => {\n-                        if !self.nextch_is('\\n') {\n-                            let last_bpos = self.last_pos;\n-                            self.err_span_(start_bpos, last_bpos, \"bare CR not allowed in raw \\\n-                                           string, use \\\\r instead\");\n-                            valid = false;\n+                        '\\r' => {\n+                            if !self.nextch_is('\\n') {\n+                                let last_bpos = self.last_pos;\n+                                self.err_span_(start_bpos,\n+                                               last_bpos,\n+                                               \"bare CR not allowed in raw string, use \\\\r \\\n+                                                instead\");\n+                                valid = false;\n+                            }\n                         }\n+                        _ => (),\n                     }\n-                    _ => ()\n+                    self.bump();\n                 }\n                 self.bump();\n+                let id = if valid {\n+                    self.name_from_to(content_start_bpos, content_end_bpos)\n+                } else {\n+                    token::intern(\"??\")\n+                };\n+                let suffix = self.scan_optional_raw_name();\n+                return token::Literal(token::StrRaw(id, hash_count), suffix);\n+            }\n+            '-' => {\n+                if self.nextch_is('>') {\n+                    self.bump();\n+                    self.bump();\n+                    return token::RArrow;\n+                } else {\n+                    return self.binop(token::Minus);\n+                }\n+            }\n+            '&' => {\n+                if self.nextch_is('&') {\n+                    self.bump();\n+                    self.bump();\n+                    return token::AndAnd;\n+                } else {\n+                    return self.binop(token::And);\n+                }\n+            }\n+            '|' => {\n+                match self.nextch() {\n+                    Some('|') => {\n+                        self.bump();\n+                        self.bump();\n+                        return token::OrOr;\n+                    }\n+                    _ => {\n+                        return self.binop(token::Or);\n+                    }\n+                }\n+            }\n+            '+' => {\n+                return self.binop(token::Plus);\n+            }\n+            '*' => {\n+                return self.binop(token::Star);\n+            }\n+            '/' => {\n+                return self.binop(token::Slash);\n+            }\n+            '^' => {\n+                return self.binop(token::Caret);\n+            }\n+            '%' => {\n+                return self.binop(token::Percent);\n+            }\n+            c => {\n+                let last_bpos = self.last_pos;\n+                let bpos = self.pos;\n+                let mut err = self.struct_fatal_span_char(last_bpos,\n+                                                          bpos,\n+                                                          \"unknown start of token\",\n+                                                          c);\n+                unicode_chars::check_for_substitution(&self, c, &mut err);\n+                err.emit();\n+                panic!(FatalError);\n             }\n-            self.bump();\n-            let id = if valid {\n-                self.name_from_to(content_start_bpos, content_end_bpos)\n-            } else {\n-                token::intern(\"??\")\n-            };\n-            let suffix = self.scan_optional_raw_name();\n-            return token::Literal(token::StrRaw(id, hash_count), suffix);\n-          }\n-          '-' => {\n-            if self.nextch_is('>') {\n-                self.bump();\n-                self.bump();\n-                return token::RArrow;\n-            } else { return self.binop(token::Minus); }\n-          }\n-          '&' => {\n-            if self.nextch_is('&') {\n-                self.bump();\n-                self.bump();\n-                return token::AndAnd;\n-            } else { return self.binop(token::And); }\n-          }\n-          '|' => {\n-            match self.nextch() {\n-              Some('|') => { self.bump(); self.bump(); return token::OrOr; }\n-              _ => { return self.binop(token::Or); }\n-            }\n-          }\n-          '+' => { return self.binop(token::Plus); }\n-          '*' => { return self.binop(token::Star); }\n-          '/' => { return self.binop(token::Slash); }\n-          '^' => { return self.binop(token::Caret); }\n-          '%' => { return self.binop(token::Percent); }\n-          c => {\n-              let last_bpos = self.last_pos;\n-              let bpos = self.pos;\n-              let mut err = self.struct_fatal_span_char(last_bpos,\n-                                                        bpos,\n-                                                        \"unknown start of token\",\n-                                                        c);\n-              unicode_chars::check_for_substitution(&self, c, &mut err);\n-              err.emit();\n-              panic!(FatalError);\n-          }\n         }\n     }\n \n     fn consume_whitespace(&mut self) {\n-        while is_whitespace(self.curr) && !self.is_eof() { self.bump(); }\n+        while is_whitespace(self.curr) && !self.is_eof() {\n+            self.bump();\n+        }\n     }\n \n     fn read_to_eol(&mut self) -> String {\n@@ -1261,14 +1446,16 @@ impl<'a> StringReader<'a> {\n             val.push(self.curr.unwrap());\n             self.bump();\n         }\n-        if self.curr_is('\\n') { self.bump(); }\n-        return val\n+        if self.curr_is('\\n') {\n+            self.bump();\n+        }\n+        return val;\n     }\n \n     fn read_one_line_comment(&mut self) -> String {\n         let val = self.read_to_eol();\n-        assert!((val.as_bytes()[0] == b'/' && val.as_bytes()[1] == b'/')\n-             || (val.as_bytes()[0] == b'#' && val.as_bytes()[1] == b'!'));\n+        assert!((val.as_bytes()[0] == b'/' && val.as_bytes()[1] == b'/') ||\n+                (val.as_bytes()[0] == b'#' && val.as_bytes()[1] == b'!'));\n         return val;\n     }\n \n@@ -1279,10 +1466,9 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn peeking_at_comment(&self) -> bool {\n-        (self.curr_is('/') && self.nextch_is('/'))\n-     || (self.curr_is('/') && self.nextch_is('*'))\n-     // consider shebangs comments, but not inner attributes\n-     || (self.curr_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n+        (self.curr_is('/') && self.nextch_is('/')) || (self.curr_is('/') && self.nextch_is('*')) ||\n+        // consider shebangs comments, but not inner attributes\n+        (self.curr_is('#') && self.nextch_is('!') && !self.nextnextch_is('['))\n     }\n \n     fn scan_byte(&mut self) -> token::Lit {\n@@ -1293,18 +1479,26 @@ impl<'a> StringReader<'a> {\n         let c2 = self.curr.unwrap_or('\\x00');\n         self.bump();\n \n-        let valid = self.scan_char_or_byte(start, c2, /* ascii_only = */ true, '\\'');\n+        let valid = self.scan_char_or_byte(start,\n+                                           c2,\n+                                           // ascii_only =\n+                                           true,\n+                                           '\\'');\n         if !self.curr_is('\\'') {\n             // Byte offsetting here is okay because the\n             // character before position `start` are an\n             // ascii single quote and ascii 'b'.\n             let last_pos = self.last_pos;\n-            panic!(self.fatal_span_verbose(\n-                start - BytePos(2), last_pos,\n-                \"unterminated byte constant\".to_string()));\n+            panic!(self.fatal_span_verbose(start - BytePos(2),\n+                                           last_pos,\n+                                           \"unterminated byte constant\".to_string()));\n         }\n \n-        let id = if valid { self.name_from(start) } else { token::intern(\"?\") };\n+        let id = if valid {\n+            self.name_from(start)\n+        } else {\n+            token::intern(\"?\")\n+        };\n         self.bump(); // advance curr past token\n         return token::Byte(id);\n     }\n@@ -1327,9 +1521,17 @@ impl<'a> StringReader<'a> {\n             let ch_start = self.last_pos;\n             let ch = self.curr.unwrap();\n             self.bump();\n-            valid &= self.scan_char_or_byte(ch_start, ch, /* ascii_only = */ true, '\"');\n+            valid &= self.scan_char_or_byte(ch_start,\n+                                            ch,\n+                                            // ascii_only =\n+                                            true,\n+                                            '\"');\n         }\n-        let id = if valid { self.name_from(start) } else { token::intern(\"??\") };\n+        let id = if valid {\n+            self.name_from(start)\n+        } else {\n+            token::intern(\"??\")\n+        };\n         self.bump();\n         return token::ByteStr(id);\n     }\n@@ -1349,10 +1551,11 @@ impl<'a> StringReader<'a> {\n         } else if !self.curr_is('\"') {\n             let last_pos = self.last_pos;\n             let ch = self.curr.unwrap();\n-            panic!(self.fatal_span_char(start_bpos, last_pos,\n-                            \"found invalid character; \\\n-                             only `#` is allowed in raw string delimitation\",\n-                            ch));\n+            panic!(self.fatal_span_char(start_bpos,\n+                                        last_pos,\n+                                        \"found invalid character; only `#` is allowed in raw \\\n+                                         string delimitation\",\n+                                        ch));\n         }\n         self.bump();\n         let content_start_bpos = self.last_pos;\n@@ -1362,7 +1565,7 @@ impl<'a> StringReader<'a> {\n                 None => {\n                     let last_pos = self.last_pos;\n                     panic!(self.fatal_span_(start_bpos, last_pos, \"unterminated raw string\"))\n-                },\n+                }\n                 Some('\"') => {\n                     content_end_bpos = self.last_pos;\n                     for _ in 0..hash_count {\n@@ -1372,70 +1575,72 @@ impl<'a> StringReader<'a> {\n                         }\n                     }\n                     break;\n-                },\n-                Some(c) => if c > '\\x7F' {\n-                    let last_pos = self.last_pos;\n-                    self.err_span_char(\n-                        last_pos, last_pos, \"raw byte string must be ASCII\", c);\n+                }\n+                Some(c) => {\n+                    if c > '\\x7F' {\n+                        let last_pos = self.last_pos;\n+                        self.err_span_char(last_pos, last_pos, \"raw byte string must be ASCII\", c);\n+                    }\n                 }\n             }\n             self.bump();\n         }\n         self.bump();\n-        return token::ByteStrRaw(self.name_from_to(content_start_bpos,\n-                                                  content_end_bpos),\n-                                hash_count);\n+        return token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos),\n+                                 hash_count);\n     }\n }\n \n pub fn is_whitespace(c: Option<char>) -> bool {\n     match c.unwrap_or('\\x00') { // None can be null for now... it's not whitespace\n         ' ' | '\\n' | '\\t' | '\\r' => true,\n-        _ => false\n+        _ => false,\n     }\n }\n \n fn in_range(c: Option<char>, lo: char, hi: char) -> bool {\n     match c {\n         Some(c) => lo <= c && c <= hi,\n-        _ => false\n+        _ => false,\n     }\n }\n \n-fn is_dec_digit(c: Option<char>) -> bool { return in_range(c, '0', '9'); }\n+fn is_dec_digit(c: Option<char>) -> bool {\n+    return in_range(c, '0', '9');\n+}\n \n pub fn is_doc_comment(s: &str) -> bool {\n-    let res = (s.starts_with(\"///\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'/')\n-              || s.starts_with(\"//!\");\n+    let res = (s.starts_with(\"///\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'/') ||\n+              s.starts_with(\"//!\");\n     debug!(\"is {:?} a doc comment? {}\", s, res);\n     res\n }\n \n pub fn is_block_doc_comment(s: &str) -> bool {\n-    let res = ((s.starts_with(\"/**\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'*')\n-               || s.starts_with(\"/*!\"))\n-              && s.len() >= 5; // Prevent `/**/` from being parsed as a doc comment\n+    // Prevent `/**/` from being parsed as a doc comment\n+    let res = ((s.starts_with(\"/**\") && *s.as_bytes().get(3).unwrap_or(&b' ') != b'*') ||\n+               s.starts_with(\"/*!\")) && s.len() >= 5;\n     debug!(\"is {:?} a doc comment? {}\", s, res);\n     res\n }\n \n fn ident_start(c: Option<char>) -> bool {\n-    let c = match c { Some(c) => c, None => return false };\n+    let c = match c {\n+        Some(c) => c,\n+        None => return false,\n+    };\n \n-    (c >= 'a' && c <= 'z')\n-        || (c >= 'A' && c <= 'Z')\n-        || c == '_'\n-        || (c > '\\x7f' && c.is_xid_start())\n+    (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || c == '_' || (c > '\\x7f' && c.is_xid_start())\n }\n \n fn ident_continue(c: Option<char>) -> bool {\n-    let c = match c { Some(c) => c, None => return false };\n+    let c = match c {\n+        Some(c) => c,\n+        None => return false,\n+    };\n \n-    (c >= 'a' && c <= 'z')\n-        || (c >= 'A' && c <= 'Z')\n-        || (c >= '0' && c <= '9')\n-        || c == '_'\n-        || (c > '\\x7f' && c.is_xid_continue())\n+    (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || c == '_' ||\n+    (c > '\\x7f' && c.is_xid_continue())\n }\n \n #[cfg(test)]\n@@ -1445,7 +1650,7 @@ mod tests {\n     use codemap::{BytePos, CodeMap, Span, NO_EXPANSION};\n     use errors;\n     use parse::token;\n-    use parse::token::{str_to_ident};\n+    use parse::token::str_to_ident;\n     use std::io;\n     use std::rc::Rc;\n \n@@ -1458,41 +1663,54 @@ mod tests {\n     // open a string reader for the given string\n     fn setup<'a>(cm: &CodeMap,\n                  span_handler: &'a errors::Handler,\n-                 teststr: String) -> StringReader<'a> {\n+                 teststr: String)\n+                 -> StringReader<'a> {\n         let fm = cm.new_filemap(\"zebra.rs\".to_string(), teststr);\n         StringReader::new(span_handler, fm)\n     }\n \n-    #[test] fn t1 () {\n+    #[test]\n+    fn t1() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n-        let mut string_reader = setup(&cm, &sh,\n-            \"/* my source file */ \\\n-             fn main() { println!(\\\"zebra\\\"); }\\n\".to_string());\n+        let mut string_reader = setup(&cm,\n+                                      &sh,\n+                                      \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\"\n+                                          .to_string());\n         let id = str_to_ident(\"fn\");\n         assert_eq!(string_reader.next_token().tok, token::Comment);\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n         let tok1 = string_reader.next_token();\n-        let tok2 = TokenAndSpan{\n-            tok:token::Ident(id, token::Plain),\n-            sp:Span {lo:BytePos(21),hi:BytePos(23),expn_id: NO_EXPANSION}};\n-        assert_eq!(tok1,tok2);\n+        let tok2 = TokenAndSpan {\n+            tok: token::Ident(id, token::Plain),\n+            sp: Span {\n+                lo: BytePos(21),\n+                hi: BytePos(23),\n+                expn_id: NO_EXPANSION,\n+            },\n+        };\n+        assert_eq!(tok1, tok2);\n         assert_eq!(string_reader.next_token().tok, token::Whitespace);\n         // the 'main' id is already read:\n         assert_eq!(string_reader.last_pos.clone(), BytePos(28));\n         // read another token:\n         let tok3 = string_reader.next_token();\n-        let tok4 = TokenAndSpan{\n-            tok:token::Ident(str_to_ident(\"main\"), token::Plain),\n-            sp:Span {lo:BytePos(24),hi:BytePos(28),expn_id: NO_EXPANSION}};\n-        assert_eq!(tok3,tok4);\n+        let tok4 = TokenAndSpan {\n+            tok: token::Ident(str_to_ident(\"main\"), token::Plain),\n+            sp: Span {\n+                lo: BytePos(24),\n+                hi: BytePos(28),\n+                expn_id: NO_EXPANSION,\n+            },\n+        };\n+        assert_eq!(tok3, tok4);\n         // the lparen is already read:\n         assert_eq!(string_reader.last_pos.clone(), BytePos(29))\n     }\n \n     // check that the given reader produces the desired stream\n     // of tokens (stop checking after exhausting the expected vec)\n-    fn check_tokenization (mut string_reader: StringReader, expected: Vec<token::Token> ) {\n+    fn check_tokenization(mut string_reader: StringReader, expected: Vec<token::Token>) {\n         for expected_tok in &expected {\n             assert_eq!(&string_reader.next_token().tok, expected_tok);\n         }\n@@ -1503,7 +1721,8 @@ mod tests {\n         token::Ident(str_to_ident(id), style)\n     }\n \n-    #[test] fn doublecolonparsing () {\n+    #[test]\n+    fn doublecolonparsing() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n@@ -1512,16 +1731,18 @@ mod tests {\n                                 mk_ident(\"b\", token::Plain)]);\n     }\n \n-    #[test] fn dcparsing_2 () {\n+    #[test]\n+    fn dcparsing_2() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n-                           vec![mk_ident(\"a\",token::ModName),\n+                           vec![mk_ident(\"a\", token::ModName),\n                                 token::ModSep,\n                                 mk_ident(\"b\", token::Plain)]);\n     }\n \n-    #[test] fn dcparsing_3 () {\n+    #[test]\n+    fn dcparsing_3() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n@@ -1531,54 +1752,61 @@ mod tests {\n                                 mk_ident(\"b\", token::Plain)]);\n     }\n \n-    #[test] fn dcparsing_4 () {\n+    #[test]\n+    fn dcparsing_4() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n-                           vec![mk_ident(\"a\",token::ModName),\n+                           vec![mk_ident(\"a\", token::ModName),\n                                 token::ModSep,\n                                 token::Whitespace,\n                                 mk_ident(\"b\", token::Plain)]);\n     }\n \n-    #[test] fn character_a() {\n+    #[test]\n+    fn character_a() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'a'\".to_string()).next_token().tok,\n                    token::Literal(token::Char(token::intern(\"a\")), None));\n     }\n \n-    #[test] fn character_space() {\n+    #[test]\n+    fn character_space() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"' '\".to_string()).next_token().tok,\n                    token::Literal(token::Char(token::intern(\" \")), None));\n     }\n \n-    #[test] fn character_escaped() {\n+    #[test]\n+    fn character_escaped() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n                    token::Literal(token::Char(token::intern(\"\\\\n\")), None));\n     }\n \n-    #[test] fn lifetime_name() {\n+    #[test]\n+    fn lifetime_name() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         assert_eq!(setup(&cm, &sh, \"'abc\".to_string()).next_token().tok,\n                    token::Lifetime(token::str_to_ident(\"'abc\")));\n     }\n \n-    #[test] fn raw_string() {\n+    #[test]\n+    fn raw_string() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n-        assert_eq!(setup(&cm, &sh,\n-                         \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token()\n-                                                                 .tok,\n+        assert_eq!(setup(&cm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n+                       .next_token()\n+                       .tok,\n                    token::Literal(token::StrRaw(token::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n     }\n \n-    #[test] fn literal_suffixes() {\n+    #[test]\n+    fn literal_suffixes() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         macro_rules! test {\n@@ -1614,31 +1842,36 @@ mod tests {\n                                   Some(token::intern(\"suffix\"))));\n     }\n \n-    #[test] fn line_doc_comments() {\n+    #[test]\n+    fn line_doc_comments() {\n         assert!(is_doc_comment(\"///\"));\n         assert!(is_doc_comment(\"/// blah\"));\n         assert!(!is_doc_comment(\"////\"));\n     }\n \n-    #[test] fn nested_block_comments() {\n+    #[test]\n+    fn nested_block_comments() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         let mut lexer = setup(&cm, &sh, \"/* /* */ */'a'\".to_string());\n         match lexer.next_token().tok {\n-            token::Comment => { },\n-            _ => panic!(\"expected a comment!\")\n+            token::Comment => {}\n+            _ => panic!(\"expected a comment!\"),\n         }\n-        assert_eq!(lexer.next_token().tok, token::Literal(token::Char(token::intern(\"a\")), None));\n+        assert_eq!(lexer.next_token().tok,\n+                   token::Literal(token::Char(token::intern(\"a\")), None));\n     }\n \n-    #[test] fn crlf_comments() {\n+    #[test]\n+    fn crlf_comments() {\n         let cm = Rc::new(CodeMap::new());\n         let sh = mk_sh(cm.clone());\n         let mut lexer = setup(&cm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n         let comment = lexer.next_token();\n         assert_eq!(comment.tok, token::Comment);\n         assert_eq!(comment.sp, ::codemap::mk_sp(BytePos(0), BytePos(7)));\n         assert_eq!(lexer.next_token().tok, token::Whitespace);\n-        assert_eq!(lexer.next_token().tok, token::DocComment(token::intern(\"/// test\")));\n+        assert_eq!(lexer.next_token().tok,\n+                   token::DocComment(token::intern(\"/// test\")));\n     }\n }"}]}