{"sha": "c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMzZGVmZTI1MzJiYTZmZmQxMmExM2JjYmM4ZmRlZGEwMzc2NjVlZmM=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2020-07-24T12:46:55Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-07-24T12:46:55Z"}, "message": "Merge #5518\n\n5518: Use resolved paths in SSR rules r=matklad a=davidlattimore\n\nThe main user-visible changes are:\r\n* SSR now matches paths based on whether they resolve to the same thing instead of whether they're written the same.\r\n  * So `foo()` won't match `foo()` if it's a different function `foo()`, but will match `bar::foo()` if it's the same `foo`.\r\n* Paths in the replacement will now be rendered with appropriate qualification for their context.\r\n  * For example `foo::Bar` will render as just `Bar` inside the module `foo`, but might render as `baz::foo::Bar` from elsewhere.\r\n* This means that all paths in the search pattern and replacement template must be able to be resolved.\r\n* It now also matters where you invoke SSR from, since paths are resolved relative to wherever that is.\r\n* Search now uses find-uses on paths to locate places to try matching. This means that when a path is present in the pattern, search will generally be pretty fast.\r\n* Function calls can now match method calls again, but this time only if they resolve to the same function.\n\nCo-authored-by: David Lattimore <dml@google.com>", "tree": {"sha": "831bf4dd44ec83d927face4ba17e57dcdeab7fbe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/831bf4dd44ec83d927face4ba17e57dcdeab7fbe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfGtg/CRBK7hj4Ov3rIwAAdHIIAH1yk5FmQEmCXVOYgNe6pS52\nMlglIGTBAv/i8A3SSfXf55Xfxg+VZmvjyHy/IPBb1FaTulj3f5crNfFEImbDLe94\nIBrwpGllHDCojhmWmg7/6wIXwyx42o83bN0KXreFiPalJB+NPXXli5CbZX+OkzZl\nDjuu6kI3ieLgLGphn8OKFDcUOkxoBxNa98hjI1CMQS9tDMYWCWXpKFq3VchmrVQg\n6B9GynequF0/3nOSHYMJcEfkQjLl3PJPDQ4FTxb+JLYSYO0dOJWvXIdktIWY5k1g\nScq/nJF1Bf0Lro5Y8Vn3G0PKj13cPw9Qy4fjs9fnE8WicLJl4YbgGnHMwEJJphE=\n=6QSN\n-----END PGP SIGNATURE-----\n", "payload": "tree 831bf4dd44ec83d927face4ba17e57dcdeab7fbe\nparent 0e5095d3cac11d4b569c6e1594bd07937556c812\nparent 58680cb08ea535e1fb567416fa3466a744a01b99\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1595594815 +0000\ncommitter GitHub <noreply@github.com> 1595594815 +0000\n\nMerge #5518\n\n5518: Use resolved paths in SSR rules r=matklad a=davidlattimore\n\nThe main user-visible changes are:\r\n* SSR now matches paths based on whether they resolve to the same thing instead of whether they're written the same.\r\n  * So `foo()` won't match `foo()` if it's a different function `foo()`, but will match `bar::foo()` if it's the same `foo`.\r\n* Paths in the replacement will now be rendered with appropriate qualification for their context.\r\n  * For example `foo::Bar` will render as just `Bar` inside the module `foo`, but might render as `baz::foo::Bar` from elsewhere.\r\n* This means that all paths in the search pattern and replacement template must be able to be resolved.\r\n* It now also matters where you invoke SSR from, since paths are resolved relative to wherever that is.\r\n* Search now uses find-uses on paths to locate places to try matching. This means that when a path is present in the pattern, search will generally be pretty fast.\r\n* Function calls can now match method calls again, but this time only if they resolve to the same function.\n\nCo-authored-by: David Lattimore <dml@google.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "html_url": "https://github.com/rust-lang/rust/commit/c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0e5095d3cac11d4b569c6e1594bd07937556c812", "url": "https://api.github.com/repos/rust-lang/rust/commits/0e5095d3cac11d4b569c6e1594bd07937556c812", "html_url": "https://github.com/rust-lang/rust/commit/0e5095d3cac11d4b569c6e1594bd07937556c812"}, {"sha": "58680cb08ea535e1fb567416fa3466a744a01b99", "url": "https://api.github.com/repos/rust-lang/rust/commits/58680cb08ea535e1fb567416fa3466a744a01b99", "html_url": "https://github.com/rust-lang/rust/commit/58680cb08ea535e1fb567416fa3466a744a01b99"}], "stats": {"total": 1824, "additions": 1431, "deletions": 393}, "files": [{"sha": "8bed2b1afcd8e44fd312f6ac59fa59278c7535c5", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1164,6 +1164,7 @@ dependencies = [\n name = \"ra_ssr\"\n version = \"0.1.0\"\n dependencies = [\n+ \"expect\",\n  \"ra_db\",\n  \"ra_hir\",\n  \"ra_ide_db\","}, {"sha": "7356e947b98af48305442aa0a07e4f2d9258e05e", "filename": "crates/ra_ide/src/lib.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Flib.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -505,9 +505,10 @@ impl Analysis {\n         &self,\n         query: &str,\n         parse_only: bool,\n+        position: FilePosition,\n     ) -> Cancelable<Result<SourceChange, SsrError>> {\n         self.with_db(|db| {\n-            let edits = ssr::parse_search_replace(query, parse_only, db)?;\n+            let edits = ssr::parse_search_replace(query, parse_only, db, position)?;\n             Ok(SourceChange::from(edits))\n         })\n     }"}, {"sha": "95d8f79b870bef4dfed6f23c2b6baf81ce42e627", "filename": "crates/ra_ide/src/ssr.rs", "status": "modified", "additions": 20, "deletions": 15, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide%2Fsrc%2Fssr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide%2Fsrc%2Fssr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fssr.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1,5 +1,5 @@\n-use ra_db::SourceDatabaseExt;\n-use ra_ide_db::{symbol_index::SymbolsDatabase, RootDatabase};\n+use ra_db::FilePosition;\n+use ra_ide_db::RootDatabase;\n \n use crate::SourceFileEdit;\n use ra_ssr::{MatchFinder, SsrError, SsrRule};\n@@ -11,6 +11,19 @@ use ra_ssr::{MatchFinder, SsrError, SsrRule};\n // A `$<name>` placeholder in the search pattern will match any AST node and `$<name>` will reference it in the replacement.\n // Within a macro call, a placeholder will match up until whatever token follows the placeholder.\n //\n+// All paths in both the search pattern and the replacement template must resolve in the context\n+// in which this command is invoked. Paths in the search pattern will then match the code if they\n+// resolve to the same item, even if they're written differently. For example if we invoke the\n+// command in the module `foo` with a pattern of `Bar`, then code in the parent module that refers\n+// to `foo::Bar` will match.\n+//\n+// Paths in the replacement template will be rendered appropriately for the context in which the\n+// replacement occurs. For example if our replacement template is `foo::Bar` and we match some\n+// code in the `foo` module, we'll insert just `Bar`.\n+//\n+// Method calls should generally be written in UFCS form. e.g. `foo::Bar::baz($s, $a)` will match\n+// `$s.baz($a)`, provided the method call `baz` resolves to the method `foo::Bar::baz`.\n+//\n // Placeholders may be given constraints by writing them as `${<name>:<constraint1>:<constraint2>...}`.\n //\n // Supported constraints:\n@@ -43,21 +56,13 @@ pub fn parse_search_replace(\n     rule: &str,\n     parse_only: bool,\n     db: &RootDatabase,\n+    position: FilePosition,\n ) -> Result<Vec<SourceFileEdit>, SsrError> {\n-    let mut edits = vec![];\n     let rule: SsrRule = rule.parse()?;\n+    let mut match_finder = MatchFinder::in_context(db, position);\n+    match_finder.add_rule(rule)?;\n     if parse_only {\n-        return Ok(edits);\n-    }\n-    let mut match_finder = MatchFinder::new(db);\n-    match_finder.add_rule(rule);\n-    for &root in db.local_roots().iter() {\n-        let sr = db.source_root(root);\n-        for file_id in sr.iter() {\n-            if let Some(edit) = match_finder.edits_for_file(file_id) {\n-                edits.push(SourceFileEdit { file_id, edit });\n-            }\n-        }\n+        return Ok(Vec::new());\n     }\n-    Ok(edits)\n+    Ok(match_finder.edits())\n }"}, {"sha": "f391a8e43213945689c56600af2216a19b68cd67", "filename": "crates/ra_ide_db/src/defs.rs", "status": "modified", "additions": 20, "deletions": 15, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Fdefs.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -290,20 +290,25 @@ pub fn classify_name_ref(\n \n     let path = name_ref.syntax().ancestors().find_map(ast::Path::cast)?;\n     let resolved = sema.resolve_path(&path)?;\n-    let res = match resolved {\n-        PathResolution::Def(def) => Definition::ModuleDef(def),\n-        PathResolution::AssocItem(item) => {\n-            let def = match item {\n-                hir::AssocItem::Function(it) => it.into(),\n-                hir::AssocItem::Const(it) => it.into(),\n-                hir::AssocItem::TypeAlias(it) => it.into(),\n-            };\n-            Definition::ModuleDef(def)\n+    Some(NameRefClass::Definition(resolved.into()))\n+}\n+\n+impl From<PathResolution> for Definition {\n+    fn from(path_resolution: PathResolution) -> Self {\n+        match path_resolution {\n+            PathResolution::Def(def) => Definition::ModuleDef(def),\n+            PathResolution::AssocItem(item) => {\n+                let def = match item {\n+                    hir::AssocItem::Function(it) => it.into(),\n+                    hir::AssocItem::Const(it) => it.into(),\n+                    hir::AssocItem::TypeAlias(it) => it.into(),\n+                };\n+                Definition::ModuleDef(def)\n+            }\n+            PathResolution::Local(local) => Definition::Local(local),\n+            PathResolution::TypeParam(par) => Definition::TypeParam(par),\n+            PathResolution::Macro(def) => Definition::Macro(def),\n+            PathResolution::SelfType(impl_def) => Definition::SelfType(impl_def),\n         }\n-        PathResolution::Local(local) => Definition::Local(local),\n-        PathResolution::TypeParam(par) => Definition::TypeParam(par),\n-        PathResolution::Macro(def) => Definition::Macro(def),\n-        PathResolution::SelfType(impl_def) => Definition::SelfType(impl_def),\n-    };\n-    Some(NameRefClass::Definition(res))\n+    }\n }"}, {"sha": "a7cae37b0c86eed05db09e3b501cf8ee9afd56d7", "filename": "crates/ra_ide_db/src/search.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide_db%2Fsrc%2Fsearch.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ide_db%2Fsrc%2Fsearch.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Fsearch.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -60,6 +60,10 @@ impl SearchScope {\n         SearchScope::new(std::iter::once((file, None)).collect())\n     }\n \n+    pub fn files(files: &[FileId]) -> SearchScope {\n+        SearchScope::new(files.iter().map(|f| (*f, None)).collect())\n+    }\n+\n     pub fn intersection(&self, other: &SearchScope) -> SearchScope {\n         let (mut small, mut large) = (&self.entries, &other.entries);\n         if small.len() > large.len() {"}, {"sha": "84e4b171e1beb4bc4b729334c10695719ba1cf47", "filename": "crates/ra_ssr/Cargo.toml", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2FCargo.toml?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -18,3 +18,6 @@ ra_ide_db = { path = \"../ra_ide_db\" }\n hir = { path = \"../ra_hir\", package = \"ra_hir\" }\n rustc-hash = \"1.1.0\"\n test_utils = { path = \"../test_utils\" }\n+\n+[dev-dependencies]\n+expect = { path = \"../expect\" }"}, {"sha": "2fb326b45f439a33cd0ec529b172fc424a809c32", "filename": "crates/ra_ssr/src/lib.rs", "status": "modified", "additions": 123, "deletions": 110, "changes": 233, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Flib.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -4,44 +4,41 @@\n //! based on a template.\n \n mod matching;\n+mod nester;\n mod parsing;\n mod replacing;\n+mod resolving;\n+mod search;\n #[macro_use]\n mod errors;\n #[cfg(test)]\n mod tests;\n \n+use crate::errors::bail;\n pub use crate::errors::SsrError;\n pub use crate::matching::Match;\n-use crate::matching::{record_match_fails_reasons_scope, MatchFailureReason};\n+use crate::matching::MatchFailureReason;\n use hir::Semantics;\n-use ra_db::{FileId, FileRange};\n-use ra_syntax::{ast, AstNode, SmolStr, SyntaxKind, SyntaxNode, TextRange};\n-use ra_text_edit::TextEdit;\n+use ra_db::{FileId, FilePosition, FileRange};\n+use ra_ide_db::source_change::SourceFileEdit;\n+use ra_syntax::{ast, AstNode, SyntaxNode, TextRange};\n+use resolving::ResolvedRule;\n use rustc_hash::FxHashMap;\n \n // A structured search replace rule. Create by calling `parse` on a str.\n #[derive(Debug)]\n pub struct SsrRule {\n     /// A structured pattern that we're searching for.\n-    pattern: SsrPattern,\n+    pattern: parsing::RawPattern,\n     /// What we'll replace it with.\n-    template: parsing::SsrTemplate,\n+    template: parsing::RawPattern,\n+    parsed_rules: Vec<parsing::ParsedRule>,\n }\n \n #[derive(Debug)]\n pub struct SsrPattern {\n-    raw: parsing::RawSearchPattern,\n-    /// Placeholders keyed by the stand-in ident that we use in Rust source code.\n-    placeholders_by_stand_in: FxHashMap<SmolStr, parsing::Placeholder>,\n-    // We store our search pattern, parsed as each different kind of thing we can look for. As we\n-    // traverse the AST, we get the appropriate one of these for the type of node we're on. For many\n-    // search patterns, only some of these will be present.\n-    expr: Option<SyntaxNode>,\n-    type_ref: Option<SyntaxNode>,\n-    item: Option<SyntaxNode>,\n-    path: Option<SyntaxNode>,\n-    pattern: Option<SyntaxNode>,\n+    raw: parsing::RawPattern,\n+    parsed_rules: Vec<parsing::ParsedRule>,\n }\n \n #[derive(Debug, Default)]\n@@ -53,40 +50,112 @@ pub struct SsrMatches {\n pub struct MatchFinder<'db> {\n     /// Our source of information about the user's code.\n     sema: Semantics<'db, ra_ide_db::RootDatabase>,\n-    rules: Vec<SsrRule>,\n+    rules: Vec<ResolvedRule>,\n+    scope: hir::SemanticsScope<'db>,\n+    hygiene: hir::Hygiene,\n }\n \n impl<'db> MatchFinder<'db> {\n-    pub fn new(db: &'db ra_ide_db::RootDatabase) -> MatchFinder<'db> {\n-        MatchFinder { sema: Semantics::new(db), rules: Vec::new() }\n+    /// Constructs a new instance where names will be looked up as if they appeared at\n+    /// `lookup_context`.\n+    pub fn in_context(\n+        db: &'db ra_ide_db::RootDatabase,\n+        lookup_context: FilePosition,\n+    ) -> MatchFinder<'db> {\n+        let sema = Semantics::new(db);\n+        let file = sema.parse(lookup_context.file_id);\n+        // Find a node at the requested position, falling back to the whole file.\n+        let node = file\n+            .syntax()\n+            .token_at_offset(lookup_context.offset)\n+            .left_biased()\n+            .map(|token| token.parent())\n+            .unwrap_or_else(|| file.syntax().clone());\n+        let scope = sema.scope(&node);\n+        MatchFinder {\n+            sema: Semantics::new(db),\n+            rules: Vec::new(),\n+            scope,\n+            hygiene: hir::Hygiene::new(db, lookup_context.file_id.into()),\n+        }\n     }\n \n-    pub fn add_rule(&mut self, rule: SsrRule) {\n-        self.rules.push(rule);\n+    /// Constructs an instance using the start of the first file in `db` as the lookup context.\n+    pub fn at_first_file(db: &'db ra_ide_db::RootDatabase) -> Result<MatchFinder<'db>, SsrError> {\n+        use ra_db::SourceDatabaseExt;\n+        use ra_ide_db::symbol_index::SymbolsDatabase;\n+        if let Some(first_file_id) = db\n+            .local_roots()\n+            .iter()\n+            .next()\n+            .and_then(|root| db.source_root(root.clone()).iter().next())\n+        {\n+            Ok(MatchFinder::in_context(\n+                db,\n+                FilePosition { file_id: first_file_id, offset: 0.into() },\n+            ))\n+        } else {\n+            bail!(\"No files to search\");\n+        }\n     }\n \n-    /// Adds a search pattern. For use if you intend to only call `find_matches_in_file`. If you\n-    /// intend to do replacement, use `add_rule` instead.\n-    pub fn add_search_pattern(&mut self, pattern: SsrPattern) {\n-        self.add_rule(SsrRule { pattern, template: \"()\".parse().unwrap() })\n+    /// Adds a rule to be applied. The order in which rules are added matters. Earlier rules take\n+    /// precedence. If a node is matched by an earlier rule, then later rules won't be permitted to\n+    /// match to it.\n+    pub fn add_rule(&mut self, rule: SsrRule) -> Result<(), SsrError> {\n+        for parsed_rule in rule.parsed_rules {\n+            self.rules.push(ResolvedRule::new(\n+                parsed_rule,\n+                &self.scope,\n+                &self.hygiene,\n+                self.rules.len(),\n+            )?);\n+        }\n+        Ok(())\n     }\n \n-    pub fn edits_for_file(&self, file_id: FileId) -> Option<TextEdit> {\n-        let matches = self.find_matches_in_file(file_id);\n-        if matches.matches.is_empty() {\n-            None\n-        } else {\n-            use ra_db::SourceDatabaseExt;\n-            Some(replacing::matches_to_edit(&matches, &self.sema.db.file_text(file_id)))\n+    /// Finds matches for all added rules and returns edits for all found matches.\n+    pub fn edits(&self) -> Vec<SourceFileEdit> {\n+        use ra_db::SourceDatabaseExt;\n+        let mut matches_by_file = FxHashMap::default();\n+        for m in self.matches().matches {\n+            matches_by_file\n+                .entry(m.range.file_id)\n+                .or_insert_with(|| SsrMatches::default())\n+                .matches\n+                .push(m);\n+        }\n+        let mut edits = vec![];\n+        for (file_id, matches) in matches_by_file {\n+            let edit =\n+                replacing::matches_to_edit(&matches, &self.sema.db.file_text(file_id), &self.rules);\n+            edits.push(SourceFileEdit { file_id, edit });\n         }\n+        edits\n     }\n \n-    pub fn find_matches_in_file(&self, file_id: FileId) -> SsrMatches {\n-        let file = self.sema.parse(file_id);\n-        let code = file.syntax();\n-        let mut matches = SsrMatches::default();\n-        self.find_matches(code, &None, &mut matches);\n-        matches\n+    /// Adds a search pattern. For use if you intend to only call `find_matches_in_file`. If you\n+    /// intend to do replacement, use `add_rule` instead.\n+    pub fn add_search_pattern(&mut self, pattern: SsrPattern) -> Result<(), SsrError> {\n+        for parsed_rule in pattern.parsed_rules {\n+            self.rules.push(ResolvedRule::new(\n+                parsed_rule,\n+                &self.scope,\n+                &self.hygiene,\n+                self.rules.len(),\n+            )?);\n+        }\n+        Ok(())\n+    }\n+\n+    /// Returns matches for all added rules.\n+    pub fn matches(&self) -> SsrMatches {\n+        let mut matches = Vec::new();\n+        let mut usage_cache = search::UsageCache::default();\n+        for rule in &self.rules {\n+            self.find_matches_for_rule(rule, &mut usage_cache, &mut matches);\n+        }\n+        nester::nest_and_remove_collisions(matches, &self.sema)\n     }\n \n     /// Finds all nodes in `file_id` whose text is exactly equal to `snippet` and attempts to match\n@@ -115,53 +184,6 @@ impl<'db> MatchFinder<'db> {\n         res\n     }\n \n-    fn find_matches(\n-        &self,\n-        code: &SyntaxNode,\n-        restrict_range: &Option<FileRange>,\n-        matches_out: &mut SsrMatches,\n-    ) {\n-        for rule in &self.rules {\n-            if let Ok(mut m) = matching::get_match(false, rule, &code, restrict_range, &self.sema) {\n-                // Continue searching in each of our placeholders.\n-                for placeholder_value in m.placeholder_values.values_mut() {\n-                    if let Some(placeholder_node) = &placeholder_value.node {\n-                        // Don't search our placeholder if it's the entire matched node, otherwise we'd\n-                        // find the same match over and over until we got a stack overflow.\n-                        if placeholder_node != code {\n-                            self.find_matches(\n-                                placeholder_node,\n-                                restrict_range,\n-                                &mut placeholder_value.inner_matches,\n-                            );\n-                        }\n-                    }\n-                }\n-                matches_out.matches.push(m);\n-                return;\n-            }\n-        }\n-        // If we've got a macro call, we already tried matching it pre-expansion, which is the only\n-        // way to match the whole macro, now try expanding it and matching the expansion.\n-        if let Some(macro_call) = ast::MacroCall::cast(code.clone()) {\n-            if let Some(expanded) = self.sema.expand(&macro_call) {\n-                if let Some(tt) = macro_call.token_tree() {\n-                    // When matching within a macro expansion, we only want to allow matches of\n-                    // nodes that originated entirely from within the token tree of the macro call.\n-                    // i.e. we don't want to match something that came from the macro itself.\n-                    self.find_matches(\n-                        &expanded,\n-                        &Some(self.sema.original_range(tt.syntax())),\n-                        matches_out,\n-                    );\n-                }\n-            }\n-        }\n-        for child in code.children() {\n-            self.find_matches(&child, restrict_range, matches_out);\n-        }\n-    }\n-\n     fn output_debug_for_nodes_at_range(\n         &self,\n         node: &SyntaxNode,\n@@ -177,16 +199,25 @@ impl<'db> MatchFinder<'db> {\n             }\n             if node_range.range == range.range {\n                 for rule in &self.rules {\n-                    let pattern =\n-                        rule.pattern.tree_for_kind_with_reason(node.kind()).map(|p| p.clone());\n+                    // For now we ignore rules that have a different kind than our node, otherwise\n+                    // we get lots of noise. If at some point we add support for restricting rules\n+                    // to a particular kind of thing (e.g. only match type references), then we can\n+                    // relax this. We special-case expressions, since function calls can match\n+                    // method calls.\n+                    if rule.pattern.node.kind() != node.kind()\n+                        && !(ast::Expr::can_cast(rule.pattern.node.kind())\n+                            && ast::Expr::can_cast(node.kind()))\n+                    {\n+                        continue;\n+                    }\n                     out.push(MatchDebugInfo {\n                         matched: matching::get_match(true, rule, &node, restrict_range, &self.sema)\n                             .map_err(|e| MatchFailureReason {\n                                 reason: e.reason.unwrap_or_else(|| {\n                                     \"Match failed, but no reason was given\".to_owned()\n                                 }),\n                             }),\n-                        pattern,\n+                        pattern: rule.pattern.node.clone(),\n                         node: node.clone(),\n                     });\n                 }\n@@ -209,9 +240,8 @@ impl<'db> MatchFinder<'db> {\n \n pub struct MatchDebugInfo {\n     node: SyntaxNode,\n-    /// Our search pattern parsed as the same kind of syntax node as `node`. e.g. expression, item,\n-    /// etc. Will be absent if the pattern can't be parsed as that kind.\n-    pattern: Result<SyntaxNode, MatchFailureReason>,\n+    /// Our search pattern parsed as an expression or item, etc\n+    pattern: SyntaxNode,\n     matched: Result<Match, MatchFailureReason>,\n }\n \n@@ -228,29 +258,12 @@ impl std::fmt::Debug for MatchDebugInfo {\n             self.node\n         )?;\n         writeln!(f, \"========= PATTERN ==========\")?;\n-        match &self.pattern {\n-            Ok(pattern) => {\n-                writeln!(f, \"{:#?}\", pattern)?;\n-            }\n-            Err(err) => {\n-                writeln!(f, \"{}\", err.reason)?;\n-            }\n-        }\n+        writeln!(f, \"{:#?}\", self.pattern)?;\n         writeln!(f, \"============================\")?;\n         Ok(())\n     }\n }\n \n-impl SsrPattern {\n-    fn tree_for_kind_with_reason(\n-        &self,\n-        kind: SyntaxKind,\n-    ) -> Result<&SyntaxNode, MatchFailureReason> {\n-        record_match_fails_reasons_scope(true, || self.tree_for_kind(kind))\n-            .map_err(|e| MatchFailureReason { reason: e.reason.unwrap() })\n-    }\n-}\n-\n impl SsrMatches {\n     /// Returns `self` with any nested matches removed and made into top-level matches.\n     pub fn flattened(self) -> SsrMatches {"}, {"sha": "4862622bdec2256901bb4a2b50baf3d3ec4e1409", "filename": "crates/ra_ssr/src/matching.rs", "status": "modified", "additions": 156, "deletions": 47, "changes": 203, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fmatching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fmatching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fmatching.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -2,8 +2,9 @@\n //! process of matching, placeholder values are recorded.\n \n use crate::{\n-    parsing::{Constraint, NodeKind, Placeholder, SsrTemplate},\n-    SsrMatches, SsrPattern, SsrRule,\n+    parsing::{Constraint, NodeKind, Placeholder},\n+    resolving::{ResolvedPattern, ResolvedRule},\n+    SsrMatches,\n };\n use hir::Semantics;\n use ra_db::FileRange;\n@@ -48,9 +49,11 @@ pub struct Match {\n     pub(crate) matched_node: SyntaxNode,\n     pub(crate) placeholder_values: FxHashMap<Var, PlaceholderMatch>,\n     pub(crate) ignored_comments: Vec<ast::Comment>,\n-    // A copy of the template for the rule that produced this match. We store this on the match for\n-    // if/when we do replacement.\n-    pub(crate) template: SsrTemplate,\n+    pub(crate) rule_index: usize,\n+    /// The depth of matched_node.\n+    pub(crate) depth: usize,\n+    // Each path in the template rendered for the module in which the match was found.\n+    pub(crate) rendered_template_paths: FxHashMap<SyntaxNode, hir::ModPath>,\n }\n \n /// Represents a `$var` in an SSR query.\n@@ -86,7 +89,7 @@ pub(crate) struct MatchFailed {\n /// parent module, we don't populate nested matches.\n pub(crate) fn get_match(\n     debug_active: bool,\n-    rule: &SsrRule,\n+    rule: &ResolvedRule,\n     code: &SyntaxNode,\n     restrict_range: &Option<FileRange>,\n     sema: &Semantics<ra_ide_db::RootDatabase>,\n@@ -102,7 +105,7 @@ struct Matcher<'db, 'sema> {\n     /// If any placeholders come from anywhere outside of this range, then the match will be\n     /// rejected.\n     restrict_range: Option<FileRange>,\n-    rule: &'sema SsrRule,\n+    rule: &'sema ResolvedRule,\n }\n \n /// Which phase of matching we're currently performing. We do two phases because most attempted\n@@ -117,26 +120,35 @@ enum Phase<'a> {\n \n impl<'db, 'sema> Matcher<'db, 'sema> {\n     fn try_match(\n-        rule: &'sema SsrRule,\n+        rule: &ResolvedRule,\n         code: &SyntaxNode,\n         restrict_range: &Option<FileRange>,\n         sema: &'sema Semantics<'db, ra_ide_db::RootDatabase>,\n     ) -> Result<Match, MatchFailed> {\n         let match_state = Matcher { sema, restrict_range: restrict_range.clone(), rule };\n-        let pattern_tree = rule.pattern.tree_for_kind(code.kind())?;\n         // First pass at matching, where we check that node types and idents match.\n-        match_state.attempt_match_node(&mut Phase::First, &pattern_tree, code)?;\n+        match_state.attempt_match_node(&mut Phase::First, &rule.pattern.node, code)?;\n         match_state.validate_range(&sema.original_range(code))?;\n         let mut the_match = Match {\n             range: sema.original_range(code),\n             matched_node: code.clone(),\n             placeholder_values: FxHashMap::default(),\n             ignored_comments: Vec::new(),\n-            template: rule.template.clone(),\n+            rule_index: rule.index,\n+            depth: 0,\n+            rendered_template_paths: FxHashMap::default(),\n         };\n         // Second matching pass, where we record placeholder matches, ignored comments and maybe do\n         // any other more expensive checks that we didn't want to do on the first pass.\n-        match_state.attempt_match_node(&mut Phase::Second(&mut the_match), &pattern_tree, code)?;\n+        match_state.attempt_match_node(\n+            &mut Phase::Second(&mut the_match),\n+            &rule.pattern.node,\n+            code,\n+        )?;\n+        the_match.depth = sema.ancestors_with_macros(the_match.matched_node.clone()).count();\n+        if let Some(template) = &rule.template {\n+            the_match.render_template_paths(template, sema)?;\n+        }\n         Ok(the_match)\n     }\n \n@@ -177,10 +189,17 @@ impl<'db, 'sema> Matcher<'db, 'sema> {\n             }\n             return Ok(());\n         }\n-        // Non-placeholders.\n+        // We allow a UFCS call to match a method call, provided they resolve to the same function.\n+        if let Some(pattern_function) = self.rule.pattern.ufcs_function_calls.get(pattern) {\n+            if let (Some(pattern), Some(code)) =\n+                (ast::CallExpr::cast(pattern.clone()), ast::MethodCallExpr::cast(code.clone()))\n+            {\n+                return self.attempt_match_ufcs(phase, &pattern, &code, *pattern_function);\n+            }\n+        }\n         if pattern.kind() != code.kind() {\n             fail_match!(\n-                \"Pattern had a `{}` ({:?}), code had `{}` ({:?})\",\n+                \"Pattern had `{}` ({:?}), code had `{}` ({:?})\",\n                 pattern.text(),\n                 pattern.kind(),\n                 code.text(),\n@@ -194,6 +213,7 @@ impl<'db, 'sema> Matcher<'db, 'sema> {\n                 self.attempt_match_record_field_list(phase, pattern, code)\n             }\n             SyntaxKind::TOKEN_TREE => self.attempt_match_token_tree(phase, pattern, code),\n+            SyntaxKind::PATH => self.attempt_match_path(phase, pattern, code),\n             _ => self.attempt_match_node_children(phase, pattern, code),\n         }\n     }\n@@ -310,6 +330,64 @@ impl<'db, 'sema> Matcher<'db, 'sema> {\n         Ok(())\n     }\n \n+    /// Paths are matched based on whether they refer to the same thing, even if they're written\n+    /// differently.\n+    fn attempt_match_path(\n+        &self,\n+        phase: &mut Phase,\n+        pattern: &SyntaxNode,\n+        code: &SyntaxNode,\n+    ) -> Result<(), MatchFailed> {\n+        if let Some(pattern_resolved) = self.rule.pattern.resolved_paths.get(pattern) {\n+            let pattern_path = ast::Path::cast(pattern.clone()).unwrap();\n+            let code_path = ast::Path::cast(code.clone()).unwrap();\n+            if let (Some(pattern_segment), Some(code_segment)) =\n+                (pattern_path.segment(), code_path.segment())\n+            {\n+                // Match everything within the segment except for the name-ref, which is handled\n+                // separately via comparing what the path resolves to below.\n+                self.attempt_match_opt(\n+                    phase,\n+                    pattern_segment.type_arg_list(),\n+                    code_segment.type_arg_list(),\n+                )?;\n+                self.attempt_match_opt(\n+                    phase,\n+                    pattern_segment.param_list(),\n+                    code_segment.param_list(),\n+                )?;\n+            }\n+            if matches!(phase, Phase::Second(_)) {\n+                let resolution = self\n+                    .sema\n+                    .resolve_path(&code_path)\n+                    .ok_or_else(|| match_error!(\"Failed to resolve path `{}`\", code.text()))?;\n+                if pattern_resolved.resolution != resolution {\n+                    fail_match!(\"Pattern had path `{}` code had `{}`\", pattern.text(), code.text());\n+                }\n+            }\n+        } else {\n+            return self.attempt_match_node_children(phase, pattern, code);\n+        }\n+        Ok(())\n+    }\n+\n+    fn attempt_match_opt<T: AstNode>(\n+        &self,\n+        phase: &mut Phase,\n+        pattern: Option<T>,\n+        code: Option<T>,\n+    ) -> Result<(), MatchFailed> {\n+        match (pattern, code) {\n+            (Some(p), Some(c)) => self.attempt_match_node(phase, &p.syntax(), &c.syntax()),\n+            (None, None) => Ok(()),\n+            (Some(p), None) => fail_match!(\"Pattern `{}` had nothing to match\", p.syntax().text()),\n+            (None, Some(c)) => {\n+                fail_match!(\"Nothing in pattern to match code `{}`\", c.syntax().text())\n+            }\n+        }\n+    }\n+\n     /// We want to allow the records to match in any order, so we have special matching logic for\n     /// them.\n     fn attempt_match_record_field_list(\n@@ -443,9 +521,61 @@ impl<'db, 'sema> Matcher<'db, 'sema> {\n         Ok(())\n     }\n \n+    fn attempt_match_ufcs(\n+        &self,\n+        phase: &mut Phase,\n+        pattern: &ast::CallExpr,\n+        code: &ast::MethodCallExpr,\n+        pattern_function: hir::Function,\n+    ) -> Result<(), MatchFailed> {\n+        use ast::ArgListOwner;\n+        let code_resolved_function = self\n+            .sema\n+            .resolve_method_call(code)\n+            .ok_or_else(|| match_error!(\"Failed to resolve method call\"))?;\n+        if pattern_function != code_resolved_function {\n+            fail_match!(\"Method call resolved to a different function\");\n+        }\n+        // Check arguments.\n+        let mut pattern_args = pattern\n+            .arg_list()\n+            .ok_or_else(|| match_error!(\"Pattern function call has no args\"))?\n+            .args();\n+        self.attempt_match_opt(phase, pattern_args.next(), code.expr())?;\n+        let mut code_args =\n+            code.arg_list().ok_or_else(|| match_error!(\"Code method call has no args\"))?.args();\n+        loop {\n+            match (pattern_args.next(), code_args.next()) {\n+                (None, None) => return Ok(()),\n+                (p, c) => self.attempt_match_opt(phase, p, c)?,\n+            }\n+        }\n+    }\n+\n     fn get_placeholder(&self, element: &SyntaxElement) -> Option<&Placeholder> {\n-        only_ident(element.clone())\n-            .and_then(|ident| self.rule.pattern.placeholders_by_stand_in.get(ident.text()))\n+        only_ident(element.clone()).and_then(|ident| self.rule.get_placeholder(&ident))\n+    }\n+}\n+\n+impl Match {\n+    fn render_template_paths(\n+        &mut self,\n+        template: &ResolvedPattern,\n+        sema: &Semantics<ra_ide_db::RootDatabase>,\n+    ) -> Result<(), MatchFailed> {\n+        let module = sema\n+            .scope(&self.matched_node)\n+            .module()\n+            .ok_or_else(|| match_error!(\"Matched node isn't in a module\"))?;\n+        for (path, resolved_path) in &template.resolved_paths {\n+            if let hir::PathResolution::Def(module_def) = resolved_path.resolution {\n+                let mod_path = module.find_use_path(sema.db, module_def).ok_or_else(|| {\n+                    match_error!(\"Failed to render template path `{}` at match location\")\n+                })?;\n+                self.rendered_template_paths.insert(path.clone(), mod_path);\n+            }\n+        }\n+        Ok(())\n     }\n }\n \n@@ -510,28 +640,6 @@ impl PlaceholderMatch {\n     }\n }\n \n-impl SsrPattern {\n-    pub(crate) fn tree_for_kind(&self, kind: SyntaxKind) -> Result<&SyntaxNode, MatchFailed> {\n-        let (tree, kind_name) = if ast::Expr::can_cast(kind) {\n-            (&self.expr, \"expression\")\n-        } else if ast::TypeRef::can_cast(kind) {\n-            (&self.type_ref, \"type reference\")\n-        } else if ast::ModuleItem::can_cast(kind) {\n-            (&self.item, \"item\")\n-        } else if ast::Path::can_cast(kind) {\n-            (&self.path, \"path\")\n-        } else if ast::Pat::can_cast(kind) {\n-            (&self.pattern, \"pattern\")\n-        } else {\n-            fail_match!(\"Matching nodes of kind {:?} is not supported\", kind);\n-        };\n-        match tree {\n-            Some(tree) => Ok(tree),\n-            None => fail_match!(\"Pattern cannot be parsed as a {}\", kind_name),\n-        }\n-    }\n-}\n-\n impl NodeKind {\n     fn matches(&self, node: &SyntaxNode) -> Result<(), MatchFailed> {\n         let ok = match self {\n@@ -596,13 +704,12 @@ mod tests {\n     #[test]\n     fn parse_match_replace() {\n         let rule: SsrRule = \"foo($x) ==>> bar($x)\".parse().unwrap();\n-        let input = \"fn foo() {} fn main() { foo(1+2); }\";\n+        let input = \"fn foo() {} fn bar() {} fn main() { foo(1+2); }\";\n \n-        use ra_db::fixture::WithFixture;\n-        let (db, file_id) = ra_ide_db::RootDatabase::with_single_file(input);\n-        let mut match_finder = MatchFinder::new(&db);\n-        match_finder.add_rule(rule);\n-        let matches = match_finder.find_matches_in_file(file_id);\n+        let (db, position) = crate::tests::single_file(input);\n+        let mut match_finder = MatchFinder::in_context(&db, position);\n+        match_finder.add_rule(rule).unwrap();\n+        let matches = match_finder.matches();\n         assert_eq!(matches.matches.len(), 1);\n         assert_eq!(matches.matches[0].matched_node.text(), \"foo(1+2)\");\n         assert_eq!(matches.matches[0].placeholder_values.len(), 1);\n@@ -615,9 +722,11 @@ mod tests {\n             \"1+2\"\n         );\n \n-        let edit = crate::replacing::matches_to_edit(&matches, input);\n+        let edits = match_finder.edits();\n+        assert_eq!(edits.len(), 1);\n+        let edit = &edits[0];\n         let mut after = input.to_string();\n-        edit.apply(&mut after);\n-        assert_eq!(after, \"fn foo() {} fn main() { bar(1+2); }\");\n+        edit.edit.apply(&mut after);\n+        assert_eq!(after, \"fn foo() {} fn bar() {} fn main() { bar(1+2); }\");\n     }\n }"}, {"sha": "b3e20579bda0d25492eb53febb239c9dc973683f", "filename": "crates/ra_ssr/src/nester.rs", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fnester.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fnester.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fnester.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -0,0 +1,98 @@\n+//! Converts a flat collection of matches into a nested form suitable for replacement. When there\n+//! are multiple matches for a node, or that overlap, priority is given to the earlier rule. Nested\n+//! matches are only permitted if the inner match is contained entirely within a placeholder of an\n+//! outer match.\n+//!\n+//! For example, if our search pattern is `foo(foo($a))` and the code had `foo(foo(foo(foo(42))))`,\n+//! then we'll get 3 matches, however only the outermost and innermost matches can be accepted. The\n+//! middle match would take the second `foo` from the outer match.\n+\n+use crate::{Match, SsrMatches};\n+use ra_syntax::SyntaxNode;\n+use rustc_hash::FxHashMap;\n+\n+pub(crate) fn nest_and_remove_collisions(\n+    mut matches: Vec<Match>,\n+    sema: &hir::Semantics<ra_ide_db::RootDatabase>,\n+) -> SsrMatches {\n+    // We sort the matches by depth then by rule index. Sorting by depth means that by the time we\n+    // see a match, any parent matches or conflicting matches will have already been seen. Sorting\n+    // by rule_index means that if there are two matches for the same node, the rule added first\n+    // will take precedence.\n+    matches.sort_by(|a, b| a.depth.cmp(&b.depth).then_with(|| a.rule_index.cmp(&b.rule_index)));\n+    let mut collector = MatchCollector::default();\n+    for m in matches {\n+        collector.add_match(m, sema);\n+    }\n+    collector.into()\n+}\n+\n+#[derive(Default)]\n+struct MatchCollector {\n+    matches_by_node: FxHashMap<SyntaxNode, Match>,\n+}\n+\n+impl MatchCollector {\n+    /// Attempts to add `m` to matches. If it conflicts with an existing match, it is discarded. If\n+    /// it is entirely within the a placeholder of an existing match, then it is added as a child\n+    /// match of the existing match.\n+    fn add_match(&mut self, m: Match, sema: &hir::Semantics<ra_ide_db::RootDatabase>) {\n+        let matched_node = m.matched_node.clone();\n+        if let Some(existing) = self.matches_by_node.get_mut(&matched_node) {\n+            try_add_sub_match(m, existing, sema);\n+            return;\n+        }\n+        for ancestor in sema.ancestors_with_macros(m.matched_node.clone()) {\n+            if let Some(existing) = self.matches_by_node.get_mut(&ancestor) {\n+                try_add_sub_match(m, existing, sema);\n+                return;\n+            }\n+        }\n+        self.matches_by_node.insert(matched_node, m);\n+    }\n+}\n+\n+/// Attempts to add `m` as a sub-match of `existing`.\n+fn try_add_sub_match(\n+    m: Match,\n+    existing: &mut Match,\n+    sema: &hir::Semantics<ra_ide_db::RootDatabase>,\n+) {\n+    for p in existing.placeholder_values.values_mut() {\n+        // Note, no need to check if p.range.file is equal to m.range.file, since we\n+        // already know we're within `existing`.\n+        if p.range.range.contains_range(m.range.range) {\n+            // Convert the inner matches in `p` into a temporary MatchCollector. When\n+            // we're done, we then convert it back into an SsrMatches. If we expected\n+            // lots of inner matches, it might be worthwhile keeping a MatchCollector\n+            // around for each placeholder match. However we expect most placeholder\n+            // will have 0 and a few will have 1. More than that should hopefully be\n+            // exceptional.\n+            let mut collector = MatchCollector::default();\n+            for m in std::mem::replace(&mut p.inner_matches.matches, Vec::new()) {\n+                collector.matches_by_node.insert(m.matched_node.clone(), m);\n+            }\n+            collector.add_match(m, sema);\n+            p.inner_matches = collector.into();\n+            break;\n+        }\n+    }\n+}\n+\n+impl From<MatchCollector> for SsrMatches {\n+    fn from(mut match_collector: MatchCollector) -> Self {\n+        let mut matches = SsrMatches::default();\n+        for (_, m) in match_collector.matches_by_node.drain() {\n+            matches.matches.push(m);\n+        }\n+        matches.matches.sort_by(|a, b| {\n+            // Order matches by file_id then by start range. This should be sufficient since ranges\n+            // shouldn't be overlapping.\n+            a.range\n+                .file_id\n+                .cmp(&b.range.file_id)\n+                .then_with(|| a.range.range.start().cmp(&b.range.range.start()))\n+        });\n+        matches\n+    }\n+}"}, {"sha": "2d6f4e514f0d5039b360892a19d414dcc9d6bca5", "filename": "crates/ra_ssr/src/parsing.rs", "status": "modified", "additions": 75, "deletions": 48, "changes": 123, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fparsing.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -7,17 +7,19 @@\n \n use crate::errors::bail;\n use crate::{SsrError, SsrPattern, SsrRule};\n-use ra_syntax::{ast, AstNode, SmolStr, SyntaxKind, T};\n+use ra_syntax::{ast, AstNode, SmolStr, SyntaxKind, SyntaxNode, T};\n use rustc_hash::{FxHashMap, FxHashSet};\n use std::str::FromStr;\n \n-#[derive(Clone, Debug)]\n-pub(crate) struct SsrTemplate {\n-    pub(crate) tokens: Vec<PatternElement>,\n+#[derive(Debug)]\n+pub(crate) struct ParsedRule {\n+    pub(crate) placeholders_by_stand_in: FxHashMap<SmolStr, Placeholder>,\n+    pub(crate) pattern: SyntaxNode,\n+    pub(crate) template: Option<SyntaxNode>,\n }\n \n #[derive(Debug)]\n-pub(crate) struct RawSearchPattern {\n+pub(crate) struct RawPattern {\n     tokens: Vec<PatternElement>,\n }\n \n@@ -54,6 +56,60 @@ pub(crate) struct Token {\n     pub(crate) text: SmolStr,\n }\n \n+impl ParsedRule {\n+    fn new(\n+        pattern: &RawPattern,\n+        template: Option<&RawPattern>,\n+    ) -> Result<Vec<ParsedRule>, SsrError> {\n+        let raw_pattern = pattern.as_rust_code();\n+        let raw_template = template.map(|t| t.as_rust_code());\n+        let raw_template = raw_template.as_ref().map(|s| s.as_str());\n+        let mut builder = RuleBuilder {\n+            placeholders_by_stand_in: pattern.placeholders_by_stand_in(),\n+            rules: Vec::new(),\n+        };\n+        builder.try_add(ast::Expr::parse(&raw_pattern), raw_template.map(ast::Expr::parse));\n+        builder.try_add(ast::TypeRef::parse(&raw_pattern), raw_template.map(ast::TypeRef::parse));\n+        builder.try_add(\n+            ast::ModuleItem::parse(&raw_pattern),\n+            raw_template.map(ast::ModuleItem::parse),\n+        );\n+        builder.try_add(ast::Path::parse(&raw_pattern), raw_template.map(ast::Path::parse));\n+        builder.try_add(ast::Pat::parse(&raw_pattern), raw_template.map(ast::Pat::parse));\n+        builder.build()\n+    }\n+}\n+\n+struct RuleBuilder {\n+    placeholders_by_stand_in: FxHashMap<SmolStr, Placeholder>,\n+    rules: Vec<ParsedRule>,\n+}\n+\n+impl RuleBuilder {\n+    fn try_add<T: AstNode>(&mut self, pattern: Result<T, ()>, template: Option<Result<T, ()>>) {\n+        match (pattern, template) {\n+            (Ok(pattern), Some(Ok(template))) => self.rules.push(ParsedRule {\n+                placeholders_by_stand_in: self.placeholders_by_stand_in.clone(),\n+                pattern: pattern.syntax().clone(),\n+                template: Some(template.syntax().clone()),\n+            }),\n+            (Ok(pattern), None) => self.rules.push(ParsedRule {\n+                placeholders_by_stand_in: self.placeholders_by_stand_in.clone(),\n+                pattern: pattern.syntax().clone(),\n+                template: None,\n+            }),\n+            _ => {}\n+        }\n+    }\n+\n+    fn build(self) -> Result<Vec<ParsedRule>, SsrError> {\n+        if self.rules.is_empty() {\n+            bail!(\"Not a valid Rust expression, type, item, path or pattern\");\n+        }\n+        Ok(self.rules)\n+    }\n+}\n+\n impl FromStr for SsrRule {\n     type Err = SsrError;\n \n@@ -68,21 +124,24 @@ impl FromStr for SsrRule {\n         if it.next().is_some() {\n             return Err(SsrError(\"More than one delimiter found\".into()));\n         }\n-        let rule = SsrRule { pattern: pattern.parse()?, template: template.parse()? };\n+        let raw_pattern = pattern.parse()?;\n+        let raw_template = template.parse()?;\n+        let parsed_rules = ParsedRule::new(&raw_pattern, Some(&raw_template))?;\n+        let rule = SsrRule { pattern: raw_pattern, template: raw_template, parsed_rules };\n         validate_rule(&rule)?;\n         Ok(rule)\n     }\n }\n \n-impl FromStr for RawSearchPattern {\n+impl FromStr for RawPattern {\n     type Err = SsrError;\n \n-    fn from_str(pattern_str: &str) -> Result<RawSearchPattern, SsrError> {\n-        Ok(RawSearchPattern { tokens: parse_pattern(pattern_str)? })\n+    fn from_str(pattern_str: &str) -> Result<RawPattern, SsrError> {\n+        Ok(RawPattern { tokens: parse_pattern(pattern_str)? })\n     }\n }\n \n-impl RawSearchPattern {\n+impl RawPattern {\n     /// Returns this search pattern as Rust source code that we can feed to the Rust parser.\n     fn as_rust_code(&self) -> String {\n         let mut res = String::new();\n@@ -95,7 +154,7 @@ impl RawSearchPattern {\n         res\n     }\n \n-    fn placeholders_by_stand_in(&self) -> FxHashMap<SmolStr, Placeholder> {\n+    pub(crate) fn placeholders_by_stand_in(&self) -> FxHashMap<SmolStr, Placeholder> {\n         let mut res = FxHashMap::default();\n         for t in &self.tokens {\n             if let PatternElement::Placeholder(placeholder) = t {\n@@ -110,41 +169,9 @@ impl FromStr for SsrPattern {\n     type Err = SsrError;\n \n     fn from_str(pattern_str: &str) -> Result<SsrPattern, SsrError> {\n-        let raw: RawSearchPattern = pattern_str.parse()?;\n-        let raw_str = raw.as_rust_code();\n-        let res = SsrPattern {\n-            expr: ast::Expr::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n-            type_ref: ast::TypeRef::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n-            item: ast::ModuleItem::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n-            path: ast::Path::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n-            pattern: ast::Pat::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n-            placeholders_by_stand_in: raw.placeholders_by_stand_in(),\n-            raw,\n-        };\n-        if res.expr.is_none()\n-            && res.type_ref.is_none()\n-            && res.item.is_none()\n-            && res.path.is_none()\n-            && res.pattern.is_none()\n-        {\n-            bail!(\"Pattern is not a valid Rust expression, type, item, path or pattern\");\n-        }\n-        Ok(res)\n-    }\n-}\n-\n-impl FromStr for SsrTemplate {\n-    type Err = SsrError;\n-\n-    fn from_str(pattern_str: &str) -> Result<SsrTemplate, SsrError> {\n-        let tokens = parse_pattern(pattern_str)?;\n-        // Validate that the template is a valid fragment of Rust code. We reuse the validation\n-        // logic for search patterns since the only thing that differs is the error message.\n-        if SsrPattern::from_str(pattern_str).is_err() {\n-            bail!(\"Replacement is not a valid Rust expression, type, item, path or pattern\");\n-        }\n-        // Our actual template needs to preserve whitespace, so we can't reuse `tokens`.\n-        Ok(SsrTemplate { tokens })\n+        let raw_pattern = pattern_str.parse()?;\n+        let parsed_rules = ParsedRule::new(&raw_pattern, None)?;\n+        Ok(SsrPattern { raw: raw_pattern, parsed_rules })\n     }\n }\n \n@@ -173,7 +200,7 @@ fn parse_pattern(pattern_str: &str) -> Result<Vec<PatternElement>, SsrError> {\n /// pattern didn't define.\n fn validate_rule(rule: &SsrRule) -> Result<(), SsrError> {\n     let mut defined_placeholders = FxHashSet::default();\n-    for p in &rule.pattern.raw.tokens {\n+    for p in &rule.pattern.tokens {\n         if let PatternElement::Placeholder(placeholder) = p {\n             defined_placeholders.insert(&placeholder.ident);\n         }\n@@ -316,7 +343,7 @@ mod tests {\n         }\n         let result: SsrRule = \"foo($a, $b) ==>> bar($b, $a)\".parse().unwrap();\n         assert_eq!(\n-            result.pattern.raw.tokens,\n+            result.pattern.tokens,\n             vec![\n                 token(SyntaxKind::IDENT, \"foo\"),\n                 token(T!['('], \"(\"),"}, {"sha": "4b3f5509c3bdd1461f568e32f453629f30593d26", "filename": "crates/ra_ssr/src/replacing.rs", "status": "modified", "additions": 93, "deletions": 35, "changes": 128, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Freplacing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Freplacing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Freplacing.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1,66 +1,124 @@\n //! Code for applying replacement templates for matches that have previously been found.\n \n use crate::matching::Var;\n-use crate::parsing::PatternElement;\n-use crate::{Match, SsrMatches};\n-use ra_syntax::ast::AstToken;\n-use ra_syntax::TextSize;\n+use crate::{resolving::ResolvedRule, Match, SsrMatches};\n+use ra_syntax::ast::{self, AstToken};\n+use ra_syntax::{SyntaxElement, SyntaxKind, SyntaxNode, SyntaxToken, TextSize};\n use ra_text_edit::TextEdit;\n \n /// Returns a text edit that will replace each match in `matches` with its corresponding replacement\n /// template. Placeholders in the template will have been substituted with whatever they matched to\n /// in the original code.\n-pub(crate) fn matches_to_edit(matches: &SsrMatches, file_src: &str) -> TextEdit {\n-    matches_to_edit_at_offset(matches, file_src, 0.into())\n+pub(crate) fn matches_to_edit(\n+    matches: &SsrMatches,\n+    file_src: &str,\n+    rules: &[ResolvedRule],\n+) -> TextEdit {\n+    matches_to_edit_at_offset(matches, file_src, 0.into(), rules)\n }\n \n fn matches_to_edit_at_offset(\n     matches: &SsrMatches,\n     file_src: &str,\n     relative_start: TextSize,\n+    rules: &[ResolvedRule],\n ) -> TextEdit {\n     let mut edit_builder = ra_text_edit::TextEditBuilder::default();\n     for m in &matches.matches {\n         edit_builder.replace(\n             m.range.range.checked_sub(relative_start).unwrap(),\n-            render_replace(m, file_src),\n+            render_replace(m, file_src, rules),\n         );\n     }\n     edit_builder.finish()\n }\n \n-fn render_replace(match_info: &Match, file_src: &str) -> String {\n+struct ReplacementRenderer<'a> {\n+    match_info: &'a Match,\n+    file_src: &'a str,\n+    rules: &'a [ResolvedRule],\n+    rule: &'a ResolvedRule,\n+}\n+\n+fn render_replace(match_info: &Match, file_src: &str, rules: &[ResolvedRule]) -> String {\n     let mut out = String::new();\n-    for r in &match_info.template.tokens {\n-        match r {\n-            PatternElement::Token(t) => out.push_str(t.text.as_str()),\n-            PatternElement::Placeholder(p) => {\n-                if let Some(placeholder_value) =\n-                    match_info.placeholder_values.get(&Var(p.ident.to_string()))\n-                {\n-                    let range = &placeholder_value.range.range;\n-                    let mut matched_text =\n-                        file_src[usize::from(range.start())..usize::from(range.end())].to_owned();\n-                    let edit = matches_to_edit_at_offset(\n-                        &placeholder_value.inner_matches,\n-                        file_src,\n-                        range.start(),\n-                    );\n-                    edit.apply(&mut matched_text);\n-                    out.push_str(&matched_text);\n-                } else {\n-                    // We validated that all placeholder references were valid before we\n-                    // started, so this shouldn't happen.\n-                    panic!(\n-                        \"Internal error: replacement referenced unknown placeholder {}\",\n-                        p.ident\n-                    );\n+    let rule = &rules[match_info.rule_index];\n+    let template = rule\n+        .template\n+        .as_ref()\n+        .expect(\"You called MatchFinder::edits after calling MatchFinder::add_search_pattern\");\n+    let renderer = ReplacementRenderer { match_info, file_src, rules, rule };\n+    renderer.render_node(&template.node, &mut out);\n+    for comment in &match_info.ignored_comments {\n+        out.push_str(&comment.syntax().to_string());\n+    }\n+    out\n+}\n+\n+impl ReplacementRenderer<'_> {\n+    fn render_node_children(&self, node: &SyntaxNode, out: &mut String) {\n+        for node_or_token in node.children_with_tokens() {\n+            self.render_node_or_token(&node_or_token, out);\n+        }\n+    }\n+\n+    fn render_node_or_token(&self, node_or_token: &SyntaxElement, out: &mut String) {\n+        match node_or_token {\n+            SyntaxElement::Token(token) => {\n+                self.render_token(&token, out);\n+            }\n+            SyntaxElement::Node(child_node) => {\n+                self.render_node(&child_node, out);\n+            }\n+        }\n+    }\n+\n+    fn render_node(&self, node: &SyntaxNode, out: &mut String) {\n+        use ra_syntax::ast::AstNode;\n+        if let Some(mod_path) = self.match_info.rendered_template_paths.get(&node) {\n+            out.push_str(&mod_path.to_string());\n+            // Emit everything except for the segment's name-ref, since we already effectively\n+            // emitted that as part of `mod_path`.\n+            if let Some(path) = ast::Path::cast(node.clone()) {\n+                if let Some(segment) = path.segment() {\n+                    for node_or_token in segment.syntax().children_with_tokens() {\n+                        if node_or_token.kind() != SyntaxKind::NAME_REF {\n+                            self.render_node_or_token(&node_or_token, out);\n+                        }\n+                    }\n                 }\n             }\n+        } else {\n+            self.render_node_children(&node, out);\n         }\n     }\n-    for comment in &match_info.ignored_comments {\n-        out.push_str(&comment.syntax().to_string());\n+\n+    fn render_token(&self, token: &SyntaxToken, out: &mut String) {\n+        if let Some(placeholder) = self.rule.get_placeholder(&token) {\n+            if let Some(placeholder_value) =\n+                self.match_info.placeholder_values.get(&Var(placeholder.ident.to_string()))\n+            {\n+                let range = &placeholder_value.range.range;\n+                let mut matched_text =\n+                    self.file_src[usize::from(range.start())..usize::from(range.end())].to_owned();\n+                let edit = matches_to_edit_at_offset(\n+                    &placeholder_value.inner_matches,\n+                    self.file_src,\n+                    range.start(),\n+                    self.rules,\n+                );\n+                edit.apply(&mut matched_text);\n+                out.push_str(&matched_text);\n+            } else {\n+                // We validated that all placeholder references were valid before we\n+                // started, so this shouldn't happen.\n+                panic!(\n+                    \"Internal error: replacement referenced unknown placeholder {}\",\n+                    placeholder.ident\n+                );\n+            }\n+        } else {\n+            out.push_str(token.text().as_str());\n+        }\n     }\n-    out\n }"}, {"sha": "75f5567856f2d7473671e6544a2cff5de1205a9f", "filename": "crates/ra_ssr/src/resolving.rs", "status": "added", "additions": 173, "deletions": 0, "changes": 173, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fresolving.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fresolving.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fresolving.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -0,0 +1,173 @@\n+//! This module is responsible for resolving paths within rules.\n+\n+use crate::errors::error;\n+use crate::{parsing, SsrError};\n+use parsing::Placeholder;\n+use ra_syntax::{ast, SmolStr, SyntaxKind, SyntaxNode, SyntaxToken};\n+use rustc_hash::{FxHashMap, FxHashSet};\n+use test_utils::mark;\n+\n+pub(crate) struct ResolvedRule {\n+    pub(crate) pattern: ResolvedPattern,\n+    pub(crate) template: Option<ResolvedPattern>,\n+    pub(crate) index: usize,\n+}\n+\n+pub(crate) struct ResolvedPattern {\n+    pub(crate) placeholders_by_stand_in: FxHashMap<SmolStr, parsing::Placeholder>,\n+    pub(crate) node: SyntaxNode,\n+    // Paths in `node` that we've resolved.\n+    pub(crate) resolved_paths: FxHashMap<SyntaxNode, ResolvedPath>,\n+    pub(crate) ufcs_function_calls: FxHashMap<SyntaxNode, hir::Function>,\n+}\n+\n+pub(crate) struct ResolvedPath {\n+    pub(crate) resolution: hir::PathResolution,\n+    /// The depth of the ast::Path that was resolved within the pattern.\n+    pub(crate) depth: u32,\n+}\n+\n+impl ResolvedRule {\n+    pub(crate) fn new(\n+        rule: parsing::ParsedRule,\n+        scope: &hir::SemanticsScope,\n+        hygiene: &hir::Hygiene,\n+        index: usize,\n+    ) -> Result<ResolvedRule, SsrError> {\n+        let resolver =\n+            Resolver { scope, hygiene, placeholders_by_stand_in: rule.placeholders_by_stand_in };\n+        let resolved_template = if let Some(template) = rule.template {\n+            Some(resolver.resolve_pattern_tree(template)?)\n+        } else {\n+            None\n+        };\n+        Ok(ResolvedRule {\n+            pattern: resolver.resolve_pattern_tree(rule.pattern)?,\n+            template: resolved_template,\n+            index,\n+        })\n+    }\n+\n+    pub(crate) fn get_placeholder(&self, token: &SyntaxToken) -> Option<&Placeholder> {\n+        if token.kind() != SyntaxKind::IDENT {\n+            return None;\n+        }\n+        self.pattern.placeholders_by_stand_in.get(token.text())\n+    }\n+}\n+\n+struct Resolver<'a, 'db> {\n+    scope: &'a hir::SemanticsScope<'db>,\n+    hygiene: &'a hir::Hygiene,\n+    placeholders_by_stand_in: FxHashMap<SmolStr, parsing::Placeholder>,\n+}\n+\n+impl Resolver<'_, '_> {\n+    fn resolve_pattern_tree(&self, pattern: SyntaxNode) -> Result<ResolvedPattern, SsrError> {\n+        let mut resolved_paths = FxHashMap::default();\n+        self.resolve(pattern.clone(), 0, &mut resolved_paths)?;\n+        let ufcs_function_calls = resolved_paths\n+            .iter()\n+            .filter_map(|(path_node, resolved)| {\n+                if let Some(grandparent) = path_node.parent().and_then(|parent| parent.parent()) {\n+                    if grandparent.kind() == SyntaxKind::CALL_EXPR {\n+                        if let hir::PathResolution::AssocItem(hir::AssocItem::Function(function)) =\n+                            &resolved.resolution\n+                        {\n+                            return Some((grandparent, *function));\n+                        }\n+                    }\n+                }\n+                None\n+            })\n+            .collect();\n+        Ok(ResolvedPattern {\n+            node: pattern,\n+            resolved_paths,\n+            placeholders_by_stand_in: self.placeholders_by_stand_in.clone(),\n+            ufcs_function_calls,\n+        })\n+    }\n+\n+    fn resolve(\n+        &self,\n+        node: SyntaxNode,\n+        depth: u32,\n+        resolved_paths: &mut FxHashMap<SyntaxNode, ResolvedPath>,\n+    ) -> Result<(), SsrError> {\n+        use ra_syntax::ast::AstNode;\n+        if let Some(path) = ast::Path::cast(node.clone()) {\n+            // Check if this is an appropriate place in the path to resolve. If the path is\n+            // something like `a::B::<i32>::c` then we want to resolve `a::B`. If the path contains\n+            // a placeholder. e.g. `a::$b::c` then we want to resolve `a`.\n+            if !path_contains_type_arguments(path.qualifier())\n+                && !self.path_contains_placeholder(&path)\n+            {\n+                let resolution = self\n+                    .resolve_path(&path)\n+                    .ok_or_else(|| error!(\"Failed to resolve path `{}`\", node.text()))?;\n+                resolved_paths.insert(node, ResolvedPath { resolution, depth });\n+                return Ok(());\n+            }\n+        }\n+        for node in node.children() {\n+            self.resolve(node, depth + 1, resolved_paths)?;\n+        }\n+        Ok(())\n+    }\n+\n+    /// Returns whether `path` contains a placeholder, but ignores any placeholders within type\n+    /// arguments.\n+    fn path_contains_placeholder(&self, path: &ast::Path) -> bool {\n+        if let Some(segment) = path.segment() {\n+            if let Some(name_ref) = segment.name_ref() {\n+                if self.placeholders_by_stand_in.contains_key(name_ref.text()) {\n+                    return true;\n+                }\n+            }\n+        }\n+        if let Some(qualifier) = path.qualifier() {\n+            return self.path_contains_placeholder(&qualifier);\n+        }\n+        false\n+    }\n+\n+    fn resolve_path(&self, path: &ast::Path) -> Option<hir::PathResolution> {\n+        let hir_path = hir::Path::from_src(path.clone(), self.hygiene)?;\n+        // First try resolving the whole path. This will work for things like\n+        // `std::collections::HashMap`, but will fail for things like\n+        // `std::collections::HashMap::new`.\n+        if let Some(resolution) = self.scope.resolve_hir_path(&hir_path) {\n+            return Some(resolution);\n+        }\n+        // Resolution failed, try resolving the qualifier (e.g. `std::collections::HashMap` and if\n+        // that succeeds, then iterate through the candidates on the resolved type with the provided\n+        // name.\n+        let resolved_qualifier = self.scope.resolve_hir_path_qualifier(&hir_path.qualifier()?)?;\n+        if let hir::PathResolution::Def(hir::ModuleDef::Adt(adt)) = resolved_qualifier {\n+            adt.ty(self.scope.db).iterate_path_candidates(\n+                self.scope.db,\n+                self.scope.module()?.krate(),\n+                &FxHashSet::default(),\n+                Some(hir_path.segments().last()?.name),\n+                |_ty, assoc_item| Some(hir::PathResolution::AssocItem(assoc_item)),\n+            )\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+/// Returns whether `path` or any of its qualifiers contains type arguments.\n+fn path_contains_type_arguments(path: Option<ast::Path>) -> bool {\n+    if let Some(path) = path {\n+        if let Some(segment) = path.segment() {\n+            if segment.type_arg_list().is_some() {\n+                mark::hit!(type_arguments_within_path);\n+                return true;\n+            }\n+        }\n+        return path_contains_type_arguments(path.qualifier());\n+    }\n+    false\n+}"}, {"sha": "bcf0f046895dc68e3de2122b4cc5e69a9a3312e0", "filename": "crates/ra_ssr/src/search.rs", "status": "added", "additions": 232, "deletions": 0, "changes": 232, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fsearch.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Fsearch.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fsearch.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -0,0 +1,232 @@\n+//! Searching for matches.\n+\n+use crate::{\n+    matching,\n+    resolving::{ResolvedPath, ResolvedPattern, ResolvedRule},\n+    Match, MatchFinder,\n+};\n+use ra_db::FileRange;\n+use ra_ide_db::{\n+    defs::Definition,\n+    search::{Reference, SearchScope},\n+};\n+use ra_syntax::{ast, AstNode, SyntaxKind, SyntaxNode};\n+use test_utils::mark;\n+\n+/// A cache for the results of find_usages. This is for when we have multiple patterns that have the\n+/// same path. e.g. if the pattern was `foo::Bar` that can parse as a path, an expression, a type\n+/// and as a pattern. In each, the usages of `foo::Bar` are the same and we'd like to avoid finding\n+/// them more than once.\n+#[derive(Default)]\n+pub(crate) struct UsageCache {\n+    usages: Vec<(Definition, Vec<Reference>)>,\n+}\n+\n+impl<'db> MatchFinder<'db> {\n+    /// Adds all matches for `rule` to `matches_out`. Matches may overlap in ways that make\n+    /// replacement impossible, so further processing is required in order to properly nest matches\n+    /// and remove overlapping matches. This is done in the `nesting` module.\n+    pub(crate) fn find_matches_for_rule(\n+        &self,\n+        rule: &ResolvedRule,\n+        usage_cache: &mut UsageCache,\n+        matches_out: &mut Vec<Match>,\n+    ) {\n+        if pick_path_for_usages(&rule.pattern).is_none() {\n+            self.slow_scan(rule, matches_out);\n+            return;\n+        }\n+        self.find_matches_for_pattern_tree(rule, &rule.pattern, usage_cache, matches_out);\n+    }\n+\n+    fn find_matches_for_pattern_tree(\n+        &self,\n+        rule: &ResolvedRule,\n+        pattern: &ResolvedPattern,\n+        usage_cache: &mut UsageCache,\n+        matches_out: &mut Vec<Match>,\n+    ) {\n+        if let Some(resolved_path) = pick_path_for_usages(pattern) {\n+            let definition: Definition = resolved_path.resolution.clone().into();\n+            for reference in self.find_usages(usage_cache, definition) {\n+                if let Some(node_to_match) = self.find_node_to_match(resolved_path, reference) {\n+                    if !is_search_permitted_ancestors(&node_to_match) {\n+                        mark::hit!(use_declaration_with_braces);\n+                        continue;\n+                    }\n+                    if let Ok(m) =\n+                        matching::get_match(false, rule, &node_to_match, &None, &self.sema)\n+                    {\n+                        matches_out.push(m);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    fn find_node_to_match(\n+        &self,\n+        resolved_path: &ResolvedPath,\n+        reference: &Reference,\n+    ) -> Option<SyntaxNode> {\n+        let file = self.sema.parse(reference.file_range.file_id);\n+        let depth = resolved_path.depth as usize;\n+        let offset = reference.file_range.range.start();\n+        if let Some(path) =\n+            self.sema.find_node_at_offset_with_descend::<ast::Path>(file.syntax(), offset)\n+        {\n+            self.sema.ancestors_with_macros(path.syntax().clone()).skip(depth).next()\n+        } else if let Some(path) =\n+            self.sema.find_node_at_offset_with_descend::<ast::MethodCallExpr>(file.syntax(), offset)\n+        {\n+            // If the pattern contained a path and we found a reference to that path that wasn't\n+            // itself a path, but was a method call, then we need to adjust how far up to try\n+            // matching by how deep the path was within a CallExpr. The structure would have been\n+            // CallExpr, PathExpr, Path - i.e. a depth offset of 2. We don't need to check if the\n+            // path was part of a CallExpr because if it wasn't then all that will happen is we'll\n+            // fail to match, which is the desired behavior.\n+            const PATH_DEPTH_IN_CALL_EXPR: usize = 2;\n+            if depth < PATH_DEPTH_IN_CALL_EXPR {\n+                return None;\n+            }\n+            self.sema\n+                .ancestors_with_macros(path.syntax().clone())\n+                .skip(depth - PATH_DEPTH_IN_CALL_EXPR)\n+                .next()\n+        } else {\n+            None\n+        }\n+    }\n+\n+    fn find_usages<'a>(\n+        &self,\n+        usage_cache: &'a mut UsageCache,\n+        definition: Definition,\n+    ) -> &'a [Reference] {\n+        // Logically if a lookup succeeds we should just return it. Unfortunately returning it would\n+        // extend the lifetime of the borrow, then we wouldn't be able to do the insertion on a\n+        // cache miss. This is a limitation of NLL and is fixed with Polonius. For now we do two\n+        // lookups in the case of a cache hit.\n+        if usage_cache.find(&definition).is_none() {\n+            let usages = definition.find_usages(&self.sema, Some(self.search_scope()));\n+            usage_cache.usages.push((definition, usages));\n+            return &usage_cache.usages.last().unwrap().1;\n+        }\n+        usage_cache.find(&definition).unwrap()\n+    }\n+\n+    /// Returns the scope within which we want to search. We don't want un unrestricted search\n+    /// scope, since we don't want to find references in external dependencies.\n+    fn search_scope(&self) -> SearchScope {\n+        // FIXME: We should ideally have a test that checks that we edit local roots and not library\n+        // roots. This probably would require some changes to fixtures, since currently everything\n+        // seems to get put into a single source root.\n+        use ra_db::SourceDatabaseExt;\n+        use ra_ide_db::symbol_index::SymbolsDatabase;\n+        let mut files = Vec::new();\n+        for &root in self.sema.db.local_roots().iter() {\n+            let sr = self.sema.db.source_root(root);\n+            files.extend(sr.iter());\n+        }\n+        SearchScope::files(&files)\n+    }\n+\n+    fn slow_scan(&self, rule: &ResolvedRule, matches_out: &mut Vec<Match>) {\n+        use ra_db::SourceDatabaseExt;\n+        use ra_ide_db::symbol_index::SymbolsDatabase;\n+        for &root in self.sema.db.local_roots().iter() {\n+            let sr = self.sema.db.source_root(root);\n+            for file_id in sr.iter() {\n+                let file = self.sema.parse(file_id);\n+                let code = file.syntax();\n+                self.slow_scan_node(code, rule, &None, matches_out);\n+            }\n+        }\n+    }\n+\n+    fn slow_scan_node(\n+        &self,\n+        code: &SyntaxNode,\n+        rule: &ResolvedRule,\n+        restrict_range: &Option<FileRange>,\n+        matches_out: &mut Vec<Match>,\n+    ) {\n+        if !is_search_permitted(code) {\n+            return;\n+        }\n+        if let Ok(m) = matching::get_match(false, rule, &code, restrict_range, &self.sema) {\n+            matches_out.push(m);\n+        }\n+        // If we've got a macro call, we already tried matching it pre-expansion, which is the only\n+        // way to match the whole macro, now try expanding it and matching the expansion.\n+        if let Some(macro_call) = ast::MacroCall::cast(code.clone()) {\n+            if let Some(expanded) = self.sema.expand(&macro_call) {\n+                if let Some(tt) = macro_call.token_tree() {\n+                    // When matching within a macro expansion, we only want to allow matches of\n+                    // nodes that originated entirely from within the token tree of the macro call.\n+                    // i.e. we don't want to match something that came from the macro itself.\n+                    self.slow_scan_node(\n+                        &expanded,\n+                        rule,\n+                        &Some(self.sema.original_range(tt.syntax())),\n+                        matches_out,\n+                    );\n+                }\n+            }\n+        }\n+        for child in code.children() {\n+            self.slow_scan_node(&child, rule, restrict_range, matches_out);\n+        }\n+    }\n+}\n+\n+/// Returns whether we support matching within `node` and all of its ancestors.\n+fn is_search_permitted_ancestors(node: &SyntaxNode) -> bool {\n+    if let Some(parent) = node.parent() {\n+        if !is_search_permitted_ancestors(&parent) {\n+            return false;\n+        }\n+    }\n+    is_search_permitted(node)\n+}\n+\n+/// Returns whether we support matching within this kind of node.\n+fn is_search_permitted(node: &SyntaxNode) -> bool {\n+    // FIXME: Properly handle use declarations. At the moment, if our search pattern is `foo::bar`\n+    // and the code is `use foo::{baz, bar}`, we'll match `bar`, since it resolves to `foo::bar`.\n+    // However we'll then replace just the part we matched `bar`. We probably need to instead remove\n+    // `bar` and insert a new use declaration.\n+    node.kind() != SyntaxKind::USE_ITEM\n+}\n+\n+impl UsageCache {\n+    fn find(&mut self, definition: &Definition) -> Option<&[Reference]> {\n+        // We expect a very small number of cache entries (generally 1), so a linear scan should be\n+        // fast enough and avoids the need to implement Hash for Definition.\n+        for (d, refs) in &self.usages {\n+            if d == definition {\n+                return Some(refs);\n+            }\n+        }\n+        None\n+    }\n+}\n+\n+/// Returns a path that's suitable for path resolution. We exclude builtin types, since they aren't\n+/// something that we can find references to. We then somewhat arbitrarily pick the path that is the\n+/// longest as this is hopefully more likely to be less common, making it faster to find.\n+fn pick_path_for_usages(pattern: &ResolvedPattern) -> Option<&ResolvedPath> {\n+    // FIXME: Take the scope of the resolved path into account. e.g. if there are any paths that are\n+    // private to the current module, then we definitely would want to pick them over say a path\n+    // from std. Possibly we should go further than this and intersect the search scopes for all\n+    // resolved paths then search only in that scope.\n+    pattern\n+        .resolved_paths\n+        .iter()\n+        .filter(|(_, p)| {\n+            !matches!(p.resolution, hir::PathResolution::Def(hir::ModuleDef::BuiltinType(_)))\n+        })\n+        .map(|(node, resolved)| (node.text().len(), resolved))\n+        .max_by(|(a, _), (b, _)| a.cmp(b))\n+        .map(|(_, resolved)| resolved)\n+}"}, {"sha": "b38807c0f9c20303eb1be38085c6c19ed15a2885", "filename": "crates/ra_ssr/src/tests.rs", "status": "modified", "additions": 389, "deletions": 84, "changes": 473, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Fra_ssr%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Ftests.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1,5 +1,8 @@\n use crate::{MatchFinder, SsrRule};\n-use ra_db::{FileId, SourceDatabaseExt};\n+use expect::{expect, Expect};\n+use ra_db::{salsa::Durability, FileId, FilePosition, SourceDatabaseExt};\n+use rustc_hash::FxHashSet;\n+use std::sync::Arc;\n use test_utils::mark;\n \n fn parse_error_text(query: &str) -> String {\n@@ -36,15 +39,15 @@ fn parser_repeated_name() {\n fn parser_invalid_pattern() {\n     assert_eq!(\n         parse_error_text(\" ==>> ()\"),\n-        \"Parse error: Pattern is not a valid Rust expression, type, item, path or pattern\"\n+        \"Parse error: Not a valid Rust expression, type, item, path or pattern\"\n     );\n }\n \n #[test]\n fn parser_invalid_template() {\n     assert_eq!(\n         parse_error_text(\"() ==>> )\"),\n-        \"Parse error: Replacement is not a valid Rust expression, type, item, path or pattern\"\n+        \"Parse error: Not a valid Rust expression, type, item, path or pattern\"\n     );\n }\n \n@@ -56,39 +59,44 @@ fn parser_undefined_placeholder_in_replacement() {\n     );\n }\n \n-fn single_file(code: &str) -> (ra_ide_db::RootDatabase, FileId) {\n+/// `code` may optionally contain a cursor marker `<|>`. If it doesn't, then the position will be\n+/// the start of the file.\n+pub(crate) fn single_file(code: &str) -> (ra_ide_db::RootDatabase, FilePosition) {\n     use ra_db::fixture::WithFixture;\n-    ra_ide_db::RootDatabase::with_single_file(code)\n-}\n-\n-fn assert_ssr_transform(rule: &str, input: &str, result: &str) {\n-    assert_ssr_transforms(&[rule], input, result);\n+    use ra_ide_db::symbol_index::SymbolsDatabase;\n+    let (mut db, position) = if code.contains(test_utils::CURSOR_MARKER) {\n+        ra_ide_db::RootDatabase::with_position(code)\n+    } else {\n+        let (db, file_id) = ra_ide_db::RootDatabase::with_single_file(code);\n+        (db, FilePosition { file_id, offset: 0.into() })\n+    };\n+    let mut local_roots = FxHashSet::default();\n+    local_roots.insert(ra_db::fixture::WORKSPACE);\n+    db.set_local_roots_with_durability(Arc::new(local_roots), Durability::HIGH);\n+    (db, position)\n }\n \n-fn normalize_code(code: &str) -> String {\n-    let (db, file_id) = single_file(code);\n-    db.file_text(file_id).to_string()\n+fn assert_ssr_transform(rule: &str, input: &str, expected: Expect) {\n+    assert_ssr_transforms(&[rule], input, expected);\n }\n \n-fn assert_ssr_transforms(rules: &[&str], input: &str, result: &str) {\n-    let (db, file_id) = single_file(input);\n-    let mut match_finder = MatchFinder::new(&db);\n+fn assert_ssr_transforms(rules: &[&str], input: &str, expected: Expect) {\n+    let (db, position) = single_file(input);\n+    let mut match_finder = MatchFinder::in_context(&db, position);\n     for rule in rules {\n         let rule: SsrRule = rule.parse().unwrap();\n-        match_finder.add_rule(rule);\n+        match_finder.add_rule(rule).unwrap();\n     }\n-    if let Some(edits) = match_finder.edits_for_file(file_id) {\n-        // Note, db.file_text is not necessarily the same as `input`, since fixture parsing alters\n-        // stuff.\n-        let mut after = db.file_text(file_id).to_string();\n-        edits.apply(&mut after);\n-        // Likewise, we need to make sure that whatever transformations fixture parsing applies,\n-        // also get applied to our expected result.\n-        let result = normalize_code(result);\n-        assert_eq!(after, result);\n-    } else {\n+    let edits = match_finder.edits();\n+    if edits.is_empty() {\n         panic!(\"No edits were made\");\n     }\n+    assert_eq!(edits[0].file_id, position.file_id);\n+    // Note, db.file_text is not necessarily the same as `input`, since fixture parsing alters\n+    // stuff.\n+    let mut actual = db.file_text(position.file_id).to_string();\n+    edits[0].edit.apply(&mut actual);\n+    expected.assert_eq(&actual);\n }\n \n fn print_match_debug_info(match_finder: &MatchFinder, file_id: FileId, snippet: &str) {\n@@ -104,39 +112,34 @@ fn print_match_debug_info(match_finder: &MatchFinder, file_id: FileId, snippet:\n }\n \n fn assert_matches(pattern: &str, code: &str, expected: &[&str]) {\n-    let (db, file_id) = single_file(code);\n-    let mut match_finder = MatchFinder::new(&db);\n-    match_finder.add_search_pattern(pattern.parse().unwrap());\n-    let matched_strings: Vec<String> = match_finder\n-        .find_matches_in_file(file_id)\n-        .flattened()\n-        .matches\n-        .iter()\n-        .map(|m| m.matched_text())\n-        .collect();\n+    let (db, position) = single_file(code);\n+    let mut match_finder = MatchFinder::in_context(&db, position);\n+    match_finder.add_search_pattern(pattern.parse().unwrap()).unwrap();\n+    let matched_strings: Vec<String> =\n+        match_finder.matches().flattened().matches.iter().map(|m| m.matched_text()).collect();\n     if matched_strings != expected && !expected.is_empty() {\n-        print_match_debug_info(&match_finder, file_id, &expected[0]);\n+        print_match_debug_info(&match_finder, position.file_id, &expected[0]);\n     }\n     assert_eq!(matched_strings, expected);\n }\n \n fn assert_no_match(pattern: &str, code: &str) {\n-    let (db, file_id) = single_file(code);\n-    let mut match_finder = MatchFinder::new(&db);\n-    match_finder.add_search_pattern(pattern.parse().unwrap());\n-    let matches = match_finder.find_matches_in_file(file_id).flattened().matches;\n+    let (db, position) = single_file(code);\n+    let mut match_finder = MatchFinder::in_context(&db, position);\n+    match_finder.add_search_pattern(pattern.parse().unwrap()).unwrap();\n+    let matches = match_finder.matches().flattened().matches;\n     if !matches.is_empty() {\n-        print_match_debug_info(&match_finder, file_id, &matches[0].matched_text());\n+        print_match_debug_info(&match_finder, position.file_id, &matches[0].matched_text());\n         panic!(\"Got {} matches when we expected none: {:#?}\", matches.len(), matches);\n     }\n }\n \n fn assert_match_failure_reason(pattern: &str, code: &str, snippet: &str, expected_reason: &str) {\n-    let (db, file_id) = single_file(code);\n-    let mut match_finder = MatchFinder::new(&db);\n-    match_finder.add_search_pattern(pattern.parse().unwrap());\n+    let (db, position) = single_file(code);\n+    let mut match_finder = MatchFinder::in_context(&db, position);\n+    match_finder.add_search_pattern(pattern.parse().unwrap()).unwrap();\n     let mut reasons = Vec::new();\n-    for d in match_finder.debug_where_text_equal(file_id, snippet) {\n+    for d in match_finder.debug_where_text_equal(position.file_id, snippet) {\n         if let Some(reason) = d.match_failure_reason() {\n             reasons.push(reason.to_owned());\n         }\n@@ -149,16 +152,27 @@ fn ssr_function_to_method() {\n     assert_ssr_transform(\n         \"my_function($a, $b) ==>> ($a).my_method($b)\",\n         \"fn my_function() {} fn main() { loop { my_function( other_func(x, y), z + w) } }\",\n-        \"fn my_function() {} fn main() { loop { (other_func(x, y)).my_method(z + w) } }\",\n+        expect![[\"fn my_function() {} fn main() { loop { (other_func(x, y)).my_method(z + w) } }\"]],\n     )\n }\n \n #[test]\n fn ssr_nested_function() {\n     assert_ssr_transform(\n         \"foo($a, $b, $c) ==>> bar($c, baz($a, $b))\",\n-        \"fn foo() {} fn main { foo  (x + value.method(b), x+y-z, true && false) }\",\n-        \"fn foo() {} fn main { bar(true && false, baz(x + value.method(b), x+y-z)) }\",\n+        r#\"\n+            //- /lib.rs crate:foo\n+            fn foo() {}\n+            fn bar() {}\n+            fn baz() {}\n+            fn main { foo  (x + value.method(b), x+y-z, true && false) }\n+            \"#,\n+        expect![[r#\"\n+            fn foo() {}\n+            fn bar() {}\n+            fn baz() {}\n+            fn main { bar(true && false, baz(x + value.method(b), x+y-z)) }\n+        \"#]],\n     )\n }\n \n@@ -167,7 +181,7 @@ fn ssr_expected_spacing() {\n     assert_ssr_transform(\n         \"foo($x) + bar() ==>> bar($x)\",\n         \"fn foo() {} fn bar() {} fn main() { foo(5) + bar() }\",\n-        \"fn foo() {} fn bar() {} fn main() { bar(5) }\",\n+        expect![[\"fn foo() {} fn bar() {} fn main() { bar(5) }\"]],\n     );\n }\n \n@@ -176,34 +190,42 @@ fn ssr_with_extra_space() {\n     assert_ssr_transform(\n         \"foo($x  ) +    bar() ==>> bar($x)\",\n         \"fn foo() {} fn bar() {} fn main() { foo(  5 )  +bar(   ) }\",\n-        \"fn foo() {} fn bar() {} fn main() { bar(5) }\",\n+        expect![[\"fn foo() {} fn bar() {} fn main() { bar(5) }\"]],\n     );\n }\n \n #[test]\n fn ssr_keeps_nested_comment() {\n     assert_ssr_transform(\n         \"foo($x) ==>> bar($x)\",\n-        \"fn foo() {} fn main() { foo(other(5 /* using 5 */)) }\",\n-        \"fn foo() {} fn main() { bar(other(5 /* using 5 */)) }\",\n+        \"fn foo() {} fn bar() {} fn main() { foo(other(5 /* using 5 */)) }\",\n+        expect![[\"fn foo() {} fn bar() {} fn main() { bar(other(5 /* using 5 */)) }\"]],\n     )\n }\n \n #[test]\n fn ssr_keeps_comment() {\n     assert_ssr_transform(\n         \"foo($x) ==>> bar($x)\",\n-        \"fn foo() {} fn main() { foo(5 /* using 5 */) }\",\n-        \"fn foo() {} fn main() { bar(5)/* using 5 */ }\",\n+        \"fn foo() {} fn bar() {} fn main() { foo(5 /* using 5 */) }\",\n+        expect![[\"fn foo() {} fn bar() {} fn main() { bar(5)/* using 5 */ }\"]],\n     )\n }\n \n #[test]\n fn ssr_struct_lit() {\n     assert_ssr_transform(\n-        \"foo{a: $a, b: $b} ==>> foo::new($a, $b)\",\n-        \"fn foo() {} fn main() { foo{b:2, a:1} }\",\n-        \"fn foo() {} fn main() { foo::new(1, 2) }\",\n+        \"Foo{a: $a, b: $b} ==>> Foo::new($a, $b)\",\n+        r#\"\n+            struct Foo() {}\n+            impl Foo { fn new() {} }\n+            fn main() { Foo{b:2, a:1} }\n+            \"#,\n+        expect![[r#\"\n+            struct Foo() {}\n+            impl Foo { fn new() {} }\n+            fn main() { Foo::new(1, 2) }\n+        \"#]],\n     )\n }\n \n@@ -315,7 +337,7 @@ fn match_struct_instantiation() {\n fn match_path() {\n     let code = r#\"\n         mod foo {\n-            fn bar() {}\n+            pub fn bar() {}\n         }\n         fn f() {foo::bar(42)}\"#;\n     assert_matches(\"foo::bar\", code, &[\"foo::bar\"]);\n@@ -328,6 +350,60 @@ fn match_pattern() {\n     assert_matches(\"Some($a)\", \"struct Some(); fn f() {if let Some(x) = foo() {}}\", &[\"Some(x)\"]);\n }\n \n+// If our pattern has a full path, e.g. a::b::c() and the code has c(), but c resolves to\n+// a::b::c, then we should match.\n+#[test]\n+fn match_fully_qualified_fn_path() {\n+    let code = r#\"\n+        mod a {\n+            pub mod b {\n+                pub fn c(_: i32) {}\n+            }\n+        }\n+        use a::b::c;\n+        fn f1() {\n+            c(42);\n+        }\n+        \"#;\n+    assert_matches(\"a::b::c($a)\", code, &[\"c(42)\"]);\n+}\n+\n+#[test]\n+fn match_resolved_type_name() {\n+    let code = r#\"\n+        mod m1 {\n+            pub mod m2 {\n+                pub trait Foo<T> {}\n+            }\n+        }\n+        mod m3 {\n+            trait Foo<T> {}\n+            fn f1(f: Option<&dyn Foo<bool>>) {}\n+        }\n+        mod m4 {\n+            use crate::m1::m2::Foo;\n+            fn f1(f: Option<&dyn Foo<i32>>) {}\n+        }\n+        \"#;\n+    assert_matches(\"m1::m2::Foo<$t>\", code, &[\"Foo<i32>\"]);\n+}\n+\n+#[test]\n+fn type_arguments_within_path() {\n+    mark::check!(type_arguments_within_path);\n+    let code = r#\"\n+        mod foo {\n+            pub struct Bar<T> {t: T}\n+            impl<T> Bar<T> {\n+                pub fn baz() {}\n+            }\n+        }\n+        fn f1() {foo::Bar::<i32>::baz();}\n+        \"#;\n+    assert_no_match(\"foo::Bar::<i64>::baz()\", code);\n+    assert_matches(\"foo::Bar::<i32>::baz()\", code, &[\"foo::Bar::<i32>::baz()\"]);\n+}\n+\n #[test]\n fn literal_constraint() {\n     mark::check!(literal_constraint);\n@@ -416,44 +492,138 @@ fn no_match_split_expression() {\n fn replace_function_call() {\n     assert_ssr_transform(\n         \"foo() ==>> bar()\",\n-        \"fn foo() {} fn f1() {foo(); foo();}\",\n-        \"fn foo() {} fn f1() {bar(); bar();}\",\n+        \"fn foo() {} fn bar() {} fn f1() {foo(); foo();}\",\n+        expect![[\"fn foo() {} fn bar() {} fn f1() {bar(); bar();}\"]],\n     );\n }\n \n #[test]\n fn replace_function_call_with_placeholders() {\n     assert_ssr_transform(\n         \"foo($a, $b) ==>> bar($b, $a)\",\n-        \"fn foo() {} fn f1() {foo(5, 42)}\",\n-        \"fn foo() {} fn f1() {bar(42, 5)}\",\n+        \"fn foo() {} fn bar() {} fn f1() {foo(5, 42)}\",\n+        expect![[\"fn foo() {} fn bar() {} fn f1() {bar(42, 5)}\"]],\n     );\n }\n \n #[test]\n fn replace_nested_function_calls() {\n     assert_ssr_transform(\n         \"foo($a) ==>> bar($a)\",\n-        \"fn foo() {} fn f1() {foo(foo(42))}\",\n-        \"fn foo() {} fn f1() {bar(bar(42))}\",\n+        \"fn foo() {} fn bar() {} fn f1() {foo(foo(42))}\",\n+        expect![[\"fn foo() {} fn bar() {} fn f1() {bar(bar(42))}\"]],\n     );\n }\n \n #[test]\n-fn replace_type() {\n+fn replace_associated_function_call() {\n     assert_ssr_transform(\n-        \"Result<(), $a> ==>> Option<$a>\",\n-        \"struct Result<T, E> {} fn f1() -> Result<(), Vec<Error>> {foo()}\",\n-        \"struct Result<T, E> {} fn f1() -> Option<Vec<Error>> {foo()}\",\n+        \"Foo::new() ==>> Bar::new()\",\n+        r#\"\n+            struct Foo {}\n+            impl Foo { fn new() {} }\n+            struct Bar {}\n+            impl Bar { fn new() {} }\n+            fn f1() {Foo::new();}\n+            \"#,\n+        expect![[r#\"\n+            struct Foo {}\n+            impl Foo { fn new() {} }\n+            struct Bar {}\n+            impl Bar { fn new() {} }\n+            fn f1() {Bar::new();}\n+        \"#]],\n+    );\n+}\n+\n+#[test]\n+fn replace_path_in_different_contexts() {\n+    // Note the <|> inside module a::b which marks the point where the rule is interpreted. We\n+    // replace foo with bar, but both need different path qualifiers in different contexts. In f4,\n+    // foo is unqualified because of a use statement, however the replacement needs to be fully\n+    // qualified.\n+    assert_ssr_transform(\n+        \"c::foo() ==>> c::bar()\",\n+        r#\"\n+            mod a {\n+                pub mod b {<|>\n+                    pub mod c {\n+                        pub fn foo() {}\n+                        pub fn bar() {}\n+                        fn f1() { foo() }\n+                    }\n+                    fn f2() { c::foo() }\n+                }\n+                fn f3() { b::c::foo() }\n+            }\n+            use a::b::c::foo;\n+            fn f4() { foo() }\n+            \"#,\n+        expect![[r#\"\n+            mod a {\n+                pub mod b {\n+                    pub mod c {\n+                        pub fn foo() {}\n+                        pub fn bar() {}\n+                        fn f1() { bar() }\n+                    }\n+                    fn f2() { c::bar() }\n+                }\n+                fn f3() { b::c::bar() }\n+            }\n+            use a::b::c::foo;\n+            fn f4() { a::b::c::bar() }\n+            \"#]],\n     );\n }\n \n #[test]\n-fn replace_struct_init() {\n+fn replace_associated_function_with_generics() {\n     assert_ssr_transform(\n-        \"Foo {a: $a, b: $b} ==>> Foo::new($a, $b)\",\n-        \"struct Foo {} fn f1() {Foo{b: 1, a: 2}}\",\n-        \"struct Foo {} fn f1() {Foo::new(2, 1)}\",\n+        \"c::Foo::<$a>::new() ==>> d::Bar::<$a>::default()\",\n+        r#\"\n+            mod c {\n+                pub struct Foo<T> {v: T}\n+                impl<T> Foo<T> { pub fn new() {} }\n+                fn f1() {\n+                    Foo::<i32>::new();\n+                }\n+            }\n+            mod d {\n+                pub struct Bar<T> {v: T}\n+                impl<T> Bar<T> { pub fn default() {} }\n+                fn f1() {\n+                    super::c::Foo::<i32>::new();\n+                }\n+            }\n+            \"#,\n+        expect![[r#\"\n+            mod c {\n+                pub struct Foo<T> {v: T}\n+                impl<T> Foo<T> { pub fn new() {} }\n+                fn f1() {\n+                    crate::d::Bar::<i32>::default();\n+                }\n+            }\n+            mod d {\n+                pub struct Bar<T> {v: T}\n+                impl<T> Bar<T> { pub fn default() {} }\n+                fn f1() {\n+                    Bar::<i32>::default();\n+                }\n+            }\n+            \"#]],\n+    );\n+}\n+\n+#[test]\n+fn replace_type() {\n+    assert_ssr_transform(\n+        \"Result<(), $a> ==>> Option<$a>\",\n+        \"struct Result<T, E> {} struct Option<T> {} fn f1() -> Result<(), Vec<Error>> {foo()}\",\n+        expect![[\n+            \"struct Result<T, E> {} struct Option<T> {} fn f1() -> Option<Vec<Error>> {foo()}\"\n+        ]],\n     );\n }\n \n@@ -462,12 +632,12 @@ fn replace_macro_invocations() {\n     assert_ssr_transform(\n         \"try!($a) ==>> $a?\",\n         \"macro_rules! try {() => {}} fn f1() -> Result<(), E> {bar(try!(foo()));}\",\n-        \"macro_rules! try {() => {}} fn f1() -> Result<(), E> {bar(foo()?);}\",\n+        expect![[\"macro_rules! try {() => {}} fn f1() -> Result<(), E> {bar(foo()?);}\"]],\n     );\n     assert_ssr_transform(\n         \"foo!($a($b)) ==>> foo($b, $a)\",\n         \"macro_rules! foo {() => {}} fn f1() {foo!(abc(def() + 2));}\",\n-        \"macro_rules! foo {() => {}} fn f1() {foo(def() + 2, abc);}\",\n+        expect![[\"macro_rules! foo {() => {}} fn f1() {foo(def() + 2, abc);}\"]],\n     );\n }\n \n@@ -476,12 +646,12 @@ fn replace_binary_op() {\n     assert_ssr_transform(\n         \"$a + $b ==>> $b + $a\",\n         \"fn f() {2 * 3 + 4 * 5}\",\n-        \"fn f() {4 * 5 + 2 * 3}\",\n+        expect![[\"fn f() {4 * 5 + 2 * 3}\"]],\n     );\n     assert_ssr_transform(\n         \"$a + $b ==>> $b + $a\",\n         \"fn f() {1 + 2 + 3 + 4}\",\n-        \"fn f() {4 + 3 + 2 + 1}\",\n+        expect![[\"fn f() {4 + 3 + 2 + 1}\"]],\n     );\n }\n \n@@ -494,8 +664,23 @@ fn match_binary_op() {\n fn multiple_rules() {\n     assert_ssr_transforms(\n         &[\"$a + 1 ==>> add_one($a)\", \"$a + $b ==>> add($a, $b)\"],\n-        \"fn f() -> i32 {3 + 2 + 1}\",\n-        \"fn f() -> i32 {add_one(add(3, 2))}\",\n+        \"fn add() {} fn add_one() {} fn f() -> i32 {3 + 2 + 1}\",\n+        expect![[\"fn add() {} fn add_one() {} fn f() -> i32 {add_one(add(3, 2))}\"]],\n+    )\n+}\n+\n+#[test]\n+fn multiple_rules_with_nested_matches() {\n+    assert_ssr_transforms(\n+        &[\"foo1($a) ==>> bar1($a)\", \"foo2($a) ==>> bar2($a)\"],\n+        r#\"\n+            fn foo1() {} fn foo2() {} fn bar1() {} fn bar2() {}\n+            fn f() {foo1(foo2(foo1(foo2(foo1(42)))))}\n+            \"#,\n+        expect![[r#\"\n+            fn foo1() {} fn foo2() {} fn bar1() {} fn bar2() {}\n+            fn f() {bar1(bar2(bar1(bar2(bar1(42)))))}\n+        \"#]],\n     )\n }\n \n@@ -527,12 +712,37 @@ fn replace_within_macro_expansion() {\n             macro_rules! macro1 {\n                 ($a:expr) => {$a}\n             }\n-            fn f() {macro1!(5.x().foo().o2())}\"#,\n+            fn bar() {}\n+            fn f() {macro1!(5.x().foo().o2())}\n+            \"#,\n+        expect![[r#\"\n+            macro_rules! macro1 {\n+                ($a:expr) => {$a}\n+            }\n+            fn bar() {}\n+            fn f() {macro1!(bar(5.x()).o2())}\n+            \"#]],\n+    )\n+}\n+\n+#[test]\n+fn replace_outside_and_within_macro_expansion() {\n+    assert_ssr_transform(\n+        \"foo($a) ==>> bar($a)\",\n         r#\"\n+            fn foo() {} fn bar() {}\n+            macro_rules! macro1 {\n+                ($a:expr) => {$a}\n+            }\n+            fn f() {foo(foo(macro1!(foo(foo(42)))))}\n+            \"#,\n+        expect![[r#\"\n+            fn foo() {} fn bar() {}\n             macro_rules! macro1 {\n                 ($a:expr) => {$a}\n             }\n-            fn f() {macro1!(bar(5.x()).o2())}\"#,\n+            fn f() {bar(bar(macro1!(bar(bar(42)))))}\n+        \"#]],\n     )\n }\n \n@@ -544,12 +754,14 @@ fn preserves_whitespace_within_macro_expansion() {\n             macro_rules! macro1 {\n                 ($a:expr) => {$a}\n             }\n-            fn f() {macro1!(1   *   2 + 3 + 4}\"#,\n-        r#\"\n+            fn f() {macro1!(1   *   2 + 3 + 4}\n+            \"#,\n+        expect![[r#\"\n             macro_rules! macro1 {\n                 ($a:expr) => {$a}\n             }\n-            fn f() {macro1!(4 - 3 - 1   *   2}\"#,\n+            fn f() {macro1!(4 - 3 - 1   *   2}\n+            \"#]],\n     )\n }\n \n@@ -580,3 +792,96 @@ fn match_failure_reasons() {\n         r#\"Pattern wanted token '42' (INT_NUMBER), but code had token '43' (INT_NUMBER)\"#,\n     );\n }\n+\n+#[test]\n+fn overlapping_possible_matches() {\n+    // There are three possible matches here, however the middle one, `foo(foo(foo(42)))` shouldn't\n+    // match because it overlaps with the outer match. The inner match is permitted since it's is\n+    // contained entirely within the placeholder of the outer match.\n+    assert_matches(\n+        \"foo(foo($a))\",\n+        \"fn foo() {} fn main() {foo(foo(foo(foo(42))))}\",\n+        &[\"foo(foo(42))\", \"foo(foo(foo(foo(42))))\"],\n+    );\n+}\n+\n+#[test]\n+fn use_declaration_with_braces() {\n+    // It would be OK for a path rule to match and alter a use declaration. We shouldn't mess it up\n+    // though. In particular, we must not change `use foo::{baz, bar}` to `use foo::{baz,\n+    // foo2::bar2}`.\n+    mark::check!(use_declaration_with_braces);\n+    assert_ssr_transform(\n+        \"foo::bar ==>> foo2::bar2\",\n+        r#\"\n+        mod foo { pub fn bar() {} pub fn baz() {} }\n+        mod foo2 { pub fn bar2() {} }\n+        use foo::{baz, bar};\n+        fn main() { bar() }\n+        \"#,\n+        expect![[\"\n+        mod foo { pub fn bar() {} pub fn baz() {} }\n+        mod foo2 { pub fn bar2() {} }\n+        use foo::{baz, bar};\n+        fn main() { foo2::bar2() }\n+        \"]],\n+    )\n+}\n+\n+#[test]\n+fn ufcs_matches_method_call() {\n+    let code = r#\"\n+    struct Foo {}\n+    impl Foo {\n+        fn new(_: i32) -> Foo { Foo {} }\n+        fn do_stuff(&self, _: i32) {}\n+    }\n+    struct Bar {}\n+    impl Bar {\n+        fn new(_: i32) -> Bar { Bar {} }\n+        fn do_stuff(&self, v: i32) {}\n+    }\n+    fn main() {\n+        let b = Bar {};\n+        let f = Foo {};\n+        b.do_stuff(1);\n+        f.do_stuff(2);\n+        Foo::new(4).do_stuff(3);\n+        // Too many / too few args - should never match\n+        f.do_stuff(2, 10);\n+        f.do_stuff();\n+    }\n+    \"#;\n+    assert_matches(\"Foo::do_stuff($a, $b)\", code, &[\"f.do_stuff(2)\", \"Foo::new(4).do_stuff(3)\"]);\n+    // The arguments needs special handling in the case of a function call matching a method call\n+    // and the first argument is different.\n+    assert_matches(\"Foo::do_stuff($a, 2)\", code, &[\"f.do_stuff(2)\"]);\n+    assert_matches(\"Foo::do_stuff(Foo::new(4), $b)\", code, &[\"Foo::new(4).do_stuff(3)\"]);\n+\n+    assert_ssr_transform(\n+        \"Foo::do_stuff(Foo::new($a), $b) ==>> Bar::new($b).do_stuff($a)\",\n+        code,\n+        expect![[r#\"\n+            struct Foo {}\n+            impl Foo {\n+                fn new(_: i32) -> Foo { Foo {} }\n+                fn do_stuff(&self, _: i32) {}\n+            }\n+            struct Bar {}\n+            impl Bar {\n+                fn new(_: i32) -> Bar { Bar {} }\n+                fn do_stuff(&self, v: i32) {}\n+            }\n+            fn main() {\n+                let b = Bar {};\n+                let f = Foo {};\n+                b.do_stuff(1);\n+                f.do_stuff(2);\n+                Bar::new(3).do_stuff(4);\n+                // Too many / too few args - should never match\n+                f.do_stuff(2, 10);\n+                f.do_stuff();\n+            }\n+        \"#]],\n+    );\n+}"}, {"sha": "194bec008d362273d373cd9cccd2ccde220de29b", "filename": "crates/rust-analyzer/src/cli/ssr.rs", "status": "modified", "additions": 16, "deletions": 33, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fssr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fssr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fssr.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1,27 +1,17 @@\n //! Applies structured search replace rules from the command line.\n \n use crate::cli::{load_cargo::load_cargo, Result};\n-use ra_ide::SourceFileEdit;\n use ra_ssr::{MatchFinder, SsrPattern, SsrRule};\n \n pub fn apply_ssr_rules(rules: Vec<SsrRule>) -> Result<()> {\n     use ra_db::SourceDatabaseExt;\n-    use ra_ide_db::symbol_index::SymbolsDatabase;\n     let (host, vfs) = load_cargo(&std::env::current_dir()?, true, true)?;\n     let db = host.raw_database();\n-    let mut match_finder = MatchFinder::new(db);\n+    let mut match_finder = MatchFinder::at_first_file(db)?;\n     for rule in rules {\n-        match_finder.add_rule(rule);\n-    }\n-    let mut edits = Vec::new();\n-    for &root in db.local_roots().iter() {\n-        let sr = db.source_root(root);\n-        for file_id in sr.iter() {\n-            if let Some(edit) = match_finder.edits_for_file(file_id) {\n-                edits.push(SourceFileEdit { file_id, edit });\n-            }\n-        }\n+        match_finder.add_rule(rule)?;\n     }\n+    let edits = match_finder.edits();\n     for edit in edits {\n         if let Some(path) = vfs.file_path(edit.file_id).as_path() {\n             let mut contents = db.file_text(edit.file_id).to_string();\n@@ -38,34 +28,27 @@ pub fn apply_ssr_rules(rules: Vec<SsrRule>) -> Result<()> {\n pub fn search_for_patterns(patterns: Vec<SsrPattern>, debug_snippet: Option<String>) -> Result<()> {\n     use ra_db::SourceDatabaseExt;\n     use ra_ide_db::symbol_index::SymbolsDatabase;\n-    let (host, vfs) = load_cargo(&std::env::current_dir()?, true, true)?;\n+    let (host, _vfs) = load_cargo(&std::env::current_dir()?, true, true)?;\n     let db = host.raw_database();\n-    let mut match_finder = MatchFinder::new(db);\n+    let mut match_finder = MatchFinder::at_first_file(db)?;\n     for pattern in patterns {\n-        match_finder.add_search_pattern(pattern);\n+        match_finder.add_search_pattern(pattern)?;\n     }\n-    for &root in db.local_roots().iter() {\n-        let sr = db.source_root(root);\n-        for file_id in sr.iter() {\n-            if let Some(debug_snippet) = &debug_snippet {\n+    if let Some(debug_snippet) = &debug_snippet {\n+        for &root in db.local_roots().iter() {\n+            let sr = db.source_root(root);\n+            for file_id in sr.iter() {\n                 for debug_info in match_finder.debug_where_text_equal(file_id, debug_snippet) {\n                     println!(\"{:#?}\", debug_info);\n                 }\n-            } else {\n-                let matches = match_finder.find_matches_in_file(file_id);\n-                if !matches.matches.is_empty() {\n-                    let matches = matches.flattened().matches;\n-                    if let Some(path) = vfs.file_path(file_id).as_path() {\n-                        println!(\"{} matches in '{}'\", matches.len(), path.to_string_lossy());\n-                    }\n-                    // We could possibly at some point do something more useful than just printing\n-                    // the matched text. For now though, that's the easiest thing to do.\n-                    for m in matches {\n-                        println!(\"{}\", m.matched_text());\n-                    }\n-                }\n             }\n         }\n+    } else {\n+        for m in match_finder.matches().flattened().matches {\n+            // We could possibly at some point do something more useful than just printing\n+            // the matched text. For now though, that's the easiest thing to do.\n+            println!(\"{}\", m.matched_text());\n+        }\n     }\n     Ok(())\n }"}, {"sha": "cad92c444e008d41ef0108a9e1ce27d09e07ea0d", "filename": "crates/rust-analyzer/src/handlers.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Fhandlers.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Fhandlers.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fhandlers.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -1026,8 +1026,9 @@ pub(crate) fn handle_ssr(\n     params: lsp_ext::SsrParams,\n ) -> Result<lsp_types::WorkspaceEdit> {\n     let _p = profile(\"handle_ssr\");\n+    let position = from_proto::file_position(&snap, params.position)?;\n     let source_change =\n-        snap.analysis.structural_search_replace(&params.query, params.parse_only)??;\n+        snap.analysis.structural_search_replace(&params.query, params.parse_only, position)??;\n     to_proto::workspace_edit(&snap, source_change)\n }\n "}, {"sha": "113e0e070ab194dc072adebe8a6f8ff4fa7d1ac4", "filename": "crates/rust-analyzer/src/lsp_ext.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Flsp_ext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/crates%2Frust-analyzer%2Fsrc%2Flsp_ext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Flsp_ext.rs?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -216,6 +216,11 @@ impl Request for Ssr {\n pub struct SsrParams {\n     pub query: String,\n     pub parse_only: bool,\n+\n+    /// File position where SSR was invoked. Paths in `query` will be resolved relative to this\n+    /// position.\n+    #[serde(flatten)]\n+    pub position: lsp_types::TextDocumentPositionParams,\n }\n \n pub enum StatusNotification {}"}, {"sha": "1be01fd8842cc8eacb34d35a386f336075d52af3", "filename": "docs/dev/lsp-extensions.md", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/docs%2Fdev%2Flsp-extensions.md", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/docs%2Fdev%2Flsp-extensions.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2Flsp-extensions.md?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -274,6 +274,11 @@ interface SsrParams {\n     query: string,\n     /// If true, only check the syntax of the query and don't compute the actual edit.\n     parseOnly: bool,\n+    /// The current text document. This and `position` will be used to determine in what scope\n+    /// paths in `query` should be resolved.\n+    textDocument: lc.TextDocumentIdentifier;\n+    /// Position where SSR was invoked.\n+    position: lc.Position;\n }\n ```\n \n@@ -285,7 +290,7 @@ WorkspaceEdit\n \n ### Example\n \n-SSR with query `foo($a:expr, $b:expr) ==>> ($a).foo($b)` will transform, eg `foo(y + 5, z)` into `(y + 5).foo(z)`.\n+SSR with query `foo($a, $b) ==>> ($a).foo($b)` will transform, eg `foo(y + 5, z)` into `(y + 5).foo(z)`.\n \n ### Unresolved Question\n "}, {"sha": "c21e5597cb2d6f113a16402b5c469a76a52c5c0d", "filename": "editors/code/src/commands.ts", "status": "modified", "additions": 11, "deletions": 3, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/editors%2Fcode%2Fsrc%2Fcommands.ts", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/editors%2Fcode%2Fsrc%2Fcommands.ts", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/editors%2Fcode%2Fsrc%2Fcommands.ts?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -185,15 +185,21 @@ export function parentModule(ctx: Ctx): Cmd {\n \n export function ssr(ctx: Ctx): Cmd {\n     return async () => {\n+        const editor = vscode.window.activeTextEditor;\n         const client = ctx.client;\n-        if (!client) return;\n+        if (!editor || !client) return;\n+\n+        const position = editor.selection.active;\n+        const textDocument = { uri: editor.document.uri.toString() };\n \n         const options: vscode.InputBoxOptions = {\n             value: \"() ==>> ()\",\n             prompt: \"Enter request, for example 'Foo($a) ==> Foo::new($a)' \",\n             validateInput: async (x: string) => {\n                 try {\n-                    await client.sendRequest(ra.ssr, { query: x, parseOnly: true });\n+                    await client.sendRequest(ra.ssr, {\n+                        query: x, parseOnly: true, textDocument, position,\n+                    });\n                 } catch (e) {\n                     return e.toString();\n                 }\n@@ -208,7 +214,9 @@ export function ssr(ctx: Ctx): Cmd {\n             title: \"Structured search replace in progress...\",\n             cancellable: false,\n         }, async (_progress, _token) => {\n-            const edit = await client.sendRequest(ra.ssr, { query: request, parseOnly: false });\n+            const edit = await client.sendRequest(ra.ssr, {\n+                query: request, parseOnly: false, textDocument, position\n+            });\n \n             await vscode.workspace.applyEdit(client.protocol2CodeConverter.asWorkspaceEdit(edit));\n         });"}, {"sha": "149f9a0d644d16e0f73b39bad3788004a8657eed", "filename": "editors/code/src/lsp_ext.ts", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/editors%2Fcode%2Fsrc%2Flsp_ext.ts", "raw_url": "https://github.com/rust-lang/rust/raw/c3defe2532ba6ffd12a13bcbc8fdeda037665efc/editors%2Fcode%2Fsrc%2Flsp_ext.ts", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/editors%2Fcode%2Fsrc%2Flsp_ext.ts?ref=c3defe2532ba6ffd12a13bcbc8fdeda037665efc", "patch": "@@ -93,6 +93,8 @@ export const inlayHints = new lc.RequestType<InlayHintsParams, InlayHint[], void\n export interface SsrParams {\n     query: string;\n     parseOnly: boolean;\n+    textDocument: lc.TextDocumentIdentifier;\n+    position: lc.Position;\n }\n export const ssr = new lc.RequestType<SsrParams, lc.WorkspaceEdit, void>('experimental/ssr');\n "}]}