{"sha": "56d4de303fb59a7235caa1bd2c8e32675428f421", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU2ZDRkZTMwM2ZiNTlhNzIzNWNhYTFiZDJjOGUzMjY3NTQyOGY0MjE=", "commit": {"author": {"name": "Oliver Schneider", "email": "oli-obk@users.noreply.github.com", "date": "2017-07-14T06:30:30Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2017-07-14T06:30:30Z"}, "message": "Merge pull request #247 from RalfJung/packed\n\nRe-do packed memory accesses", "tree": {"sha": "aafc948bf932458a5f3cccff05e045f8fe14c926", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/aafc948bf932458a5f3cccff05e045f8fe14c926"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/56d4de303fb59a7235caa1bd2c8e32675428f421", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/56d4de303fb59a7235caa1bd2c8e32675428f421", "html_url": "https://github.com/rust-lang/rust/commit/56d4de303fb59a7235caa1bd2c8e32675428f421", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/56d4de303fb59a7235caa1bd2c8e32675428f421/comments", "author": {"login": "oli-obk", "id": 332036, "node_id": "MDQ6VXNlcjMzMjAzNg==", "avatar_url": "https://avatars.githubusercontent.com/u/332036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/oli-obk", "html_url": "https://github.com/oli-obk", "followers_url": "https://api.github.com/users/oli-obk/followers", "following_url": "https://api.github.com/users/oli-obk/following{/other_user}", "gists_url": "https://api.github.com/users/oli-obk/gists{/gist_id}", "starred_url": "https://api.github.com/users/oli-obk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/oli-obk/subscriptions", "organizations_url": "https://api.github.com/users/oli-obk/orgs", "repos_url": "https://api.github.com/users/oli-obk/repos", "events_url": "https://api.github.com/users/oli-obk/events{/privacy}", "received_events_url": "https://api.github.com/users/oli-obk/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "555fc41d5ed4922b7dd3c3ca874eb784e8d6e770", "url": "https://api.github.com/repos/rust-lang/rust/commits/555fc41d5ed4922b7dd3c3ca874eb784e8d6e770", "html_url": "https://github.com/rust-lang/rust/commit/555fc41d5ed4922b7dd3c3ca874eb784e8d6e770"}, {"sha": "0fbbcae92d868c047d3cbab43434404c7b0c8c2c", "url": "https://api.github.com/repos/rust-lang/rust/commits/0fbbcae92d868c047d3cbab43434404c7b0c8c2c", "html_url": "https://github.com/rust-lang/rust/commit/0fbbcae92d868c047d3cbab43434404c7b0c8c2c"}], "stats": {"total": 516, "additions": 286, "deletions": 230}, "files": [{"sha": "58fabf694d1ea410de78510d33793f2ea5942093", "filename": "src/eval_context.rs", "status": "modified", "additions": 50, "deletions": 51, "changes": 101, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Feval_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Feval_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Feval_context.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -17,7 +17,7 @@ use syntax::abi::Abi;\n \n use error::{EvalError, EvalResult};\n use lvalue::{Global, GlobalId, Lvalue, LvalueExtra};\n-use memory::{Memory, MemoryPointer, TlsKey};\n+use memory::{Memory, MemoryPointer, TlsKey, HasMemory};\n use operator;\n use value::{PrimVal, PrimValKind, Value, Pointer};\n \n@@ -352,7 +352,9 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                     .expect(\"global should have been cached (static)\");\n                 match global_value.value {\n                     // FIXME: to_ptr()? might be too extreme here, static zsts might reach this under certain conditions\n-                    Value::ByRef(ptr) => self.memory.mark_static_initalized(ptr.to_ptr()?.alloc_id, mutable)?,\n+                    Value::ByRef(ptr, _aligned) =>\n+                        // Alignment does not matter for this call\n+                        self.memory.mark_static_initalized(ptr.to_ptr()?.alloc_id, mutable)?,\n                     Value::ByVal(val) => if let PrimVal::Ptr(ptr) = val {\n                         self.memory.mark_inner_allocation(ptr.alloc_id, mutable)?;\n                     },\n@@ -408,7 +410,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n     }\n \n     pub fn deallocate_local(&mut self, local: Option<Value>) -> EvalResult<'tcx> {\n-        if let Some(Value::ByRef(ptr)) = local {\n+        if let Some(Value::ByRef(ptr, _aligned)) = local {\n             trace!(\"deallocating local\");\n             let ptr = ptr.to_ptr()?;\n             self.memory.dump_alloc(ptr.alloc_id);\n@@ -446,6 +448,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         let dest = Lvalue::Ptr {\n             ptr: dest_ptr.into(),\n             extra: LvalueExtra::DowncastVariant(variant_idx),\n+            aligned: true,\n         };\n \n         self.assign_fields(dest, dest_ty, operands)\n@@ -528,15 +531,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 self.inc_step_counter_and_check_limit(operands.len() as u64)?;\n                 use rustc::ty::layout::Layout::*;\n                 match *dest_layout {\n-                    Univariant { ref variant, .. } => {\n-                        if variant.packed {\n-                            let ptr = self.force_allocation(dest)?.to_ptr_and_extra().0.to_ptr()?;\n-                            self.memory.mark_packed(ptr, variant.stride().bytes());\n-                        }\n-                        self.assign_fields(dest, dest_ty, operands)?;\n-                    }\n-\n-                    Array { .. } => {\n+                    Univariant { .. } | Array { .. } => {\n                         self.assign_fields(dest, dest_ty, operands)?;\n                     }\n \n@@ -547,10 +542,6 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                                 .expect(\"broken mir: Adt variant id invalid\")\n                                 .to_u128_unchecked();\n                             let discr_size = discr.size().bytes();\n-                            if variants[variant].packed {\n-                                let ptr = self.force_allocation(dest)?.to_ptr_and_extra().0.to_ptr()?;\n-                                self.memory.mark_packed(ptr, variants[variant].stride().bytes());\n-                            }\n \n                             self.assign_discr_and_fields(\n                                 dest,\n@@ -587,12 +578,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                         }\n                     }\n \n-                    StructWrappedNullablePointer { nndiscr, ref nonnull, ref discrfield, .. } => {\n+                    StructWrappedNullablePointer { nndiscr, ref discrfield, .. } => {\n                         if let mir::AggregateKind::Adt(_, variant, _, _) = **kind {\n-                            if nonnull.packed {\n-                                let ptr = self.force_allocation(dest)?.to_ptr_and_extra().0.to_ptr()?;\n-                                self.memory.mark_packed(ptr, nonnull.stride().bytes());\n-                            }\n                             if nndiscr == variant as u64 {\n                                 self.assign_fields(dest, dest_ty, operands)?;\n                             } else {\n@@ -682,7 +669,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             Ref(_, _, ref lvalue) => {\n                 let src = self.eval_lvalue(lvalue)?;\n-                let (ptr, extra) = self.force_allocation(src)?.to_ptr_and_extra();\n+                // We ignore the alignment of the lvalue here -- this rvalue produces sth. of type &, which must always be aligned.\n+                let (ptr, extra, _aligned) = self.force_allocation(src)?.to_ptr_extra_aligned();\n                 let ty = self.lvalue_ty(lvalue);\n \n                 let val = match extra {\n@@ -695,7 +683,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n                 // Check alignment and non-NULLness.\n                 let (_, align) = self.size_and_align_of_dst(ty, val)?;\n-                self.memory.check_align(ptr, align, 0)?;\n+                self.memory.check_align(ptr, align)?;\n \n                 self.write_value(val, dest, dest_ty)?;\n             }\n@@ -737,7 +725,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                         let src_ty = self.operand_ty(operand);\n                         if self.type_is_fat_ptr(src_ty) {\n                             match (src, self.type_is_fat_ptr(dest_ty)) {\n-                                (Value::ByRef(_), _) |\n+                                (Value::ByRef(..), _) |\n                                 (Value::ByValPair(..), true) => {\n                                     self.write_value(src, dest, dest_ty)?;\n                                 },\n@@ -1018,15 +1006,15 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 // -1 since we don't store the return value\n                 match self.stack[frame].locals[local.index() - 1] {\n                     None => return Err(EvalError::DeadLocal),\n-                    Some(Value::ByRef(ptr)) => {\n-                        Lvalue::from_primval_ptr(ptr)\n+                    Some(Value::ByRef(ptr, aligned)) => {\n+                        Lvalue::Ptr { ptr, aligned, extra: LvalueExtra::None }\n                     },\n                     Some(val) => {\n                         let ty = self.stack[frame].mir.local_decls[local].ty;\n                         let ty = self.monomorphize(ty, self.stack[frame].instance.substs);\n                         let substs = self.stack[frame].instance.substs;\n                         let ptr = self.alloc_ptr_with_substs(ty, substs)?;\n-                        self.stack[frame].locals[local.index() - 1] = Some(Value::ByRef(ptr.into())); // it stays live\n+                        self.stack[frame].locals[local.index() - 1] = Some(Value::by_ref(ptr.into())); // it stays live\n                         self.write_value_to_ptr(val, ptr.into(), ty)?;\n                         Lvalue::from_ptr(ptr)\n                     }\n@@ -1036,7 +1024,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             Lvalue::Global(cid) => {\n                 let global_val = *self.globals.get(&cid).expect(\"global not cached\");\n                 match global_val.value {\n-                    Value::ByRef(ptr) => Lvalue::from_primval_ptr(ptr),\n+                    Value::ByRef(ptr, aligned) =>\n+                        Lvalue::Ptr { ptr, aligned, extra: LvalueExtra::None },\n                     _ => {\n                         let ptr = self.alloc_ptr_with_substs(global_val.ty, cid.instance.substs)?;\n                         self.memory.mark_static(ptr.alloc_id);\n@@ -1047,7 +1036,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                         }\n                         let lval = self.globals.get_mut(&cid).expect(\"already checked\");\n                         *lval = Global {\n-                            value: Value::ByRef(ptr.into()),\n+                            value: Value::by_ref(ptr.into()),\n                             .. global_val\n                         };\n                         Lvalue::from_ptr(ptr)\n@@ -1061,14 +1050,16 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n     /// ensures this Value is not a ByRef\n     pub(super) fn follow_by_ref_value(&mut self, value: Value, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n         match value {\n-            Value::ByRef(ptr) => self.read_value(ptr, ty),\n+            Value::ByRef(ptr, aligned) => {\n+                self.read_maybe_aligned(aligned, |ectx| ectx.read_value(ptr, ty))\n+            }\n             other => Ok(other),\n         }\n     }\n \n     pub(super) fn value_to_primval(&mut self, value: Value, ty: Ty<'tcx>) -> EvalResult<'tcx, PrimVal> {\n         match self.follow_by_ref_value(value, ty)? {\n-            Value::ByRef(_) => bug!(\"follow_by_ref_value can't result in `ByRef`\"),\n+            Value::ByRef(..) => bug!(\"follow_by_ref_value can't result in `ByRef`\"),\n \n             Value::ByVal(primval) => {\n                 self.ensure_valid_value(primval, ty)?;\n@@ -1131,9 +1122,10 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 self.write_value_possibly_by_val(src_val, write_dest, dest.value, dest_ty)\n             },\n \n-            Lvalue::Ptr { ptr, extra } => {\n+            Lvalue::Ptr { ptr, extra, aligned } => {\n                 assert_eq!(extra, LvalueExtra::None);\n-                self.write_value_to_ptr(src_val, ptr, dest_ty)\n+                self.write_maybe_aligned(aligned,\n+                    |ectx| ectx.write_value_to_ptr(src_val, ptr, dest_ty))\n             }\n \n             Lvalue::Local { frame, local } => {\n@@ -1156,17 +1148,18 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         old_dest_val: Value,\n         dest_ty: Ty<'tcx>,\n     ) -> EvalResult<'tcx> {\n-        if let Value::ByRef(dest_ptr) = old_dest_val {\n+        if let Value::ByRef(dest_ptr, aligned) = old_dest_val {\n             // If the value is already `ByRef` (that is, backed by an `Allocation`),\n             // then we must write the new value into this allocation, because there may be\n             // other pointers into the allocation. These other pointers are logically\n             // pointers into the local variable, and must be able to observe the change.\n             //\n             // Thus, it would be an error to replace the `ByRef` with a `ByVal`, unless we\n             // knew for certain that there were no outstanding pointers to this allocation.\n-            self.write_value_to_ptr(src_val, dest_ptr, dest_ty)?;\n+            self.write_maybe_aligned(aligned,\n+                |ectx| ectx.write_value_to_ptr(src_val, dest_ptr, dest_ty))?;\n \n-        } else if let Value::ByRef(src_ptr) = src_val {\n+        } else if let Value::ByRef(src_ptr, aligned) = src_val {\n             // If the value is not `ByRef`, then we know there are no pointers to it\n             // and we can simply overwrite the `Value` in the locals array directly.\n             //\n@@ -1178,13 +1171,16 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             // It is a valid optimization to attempt reading a primitive value out of the\n             // source and write that into the destination without making an allocation, so\n             // we do so here.\n-            if let Ok(Some(src_val)) = self.try_read_value(src_ptr, dest_ty) {\n-                write_dest(self, src_val)?;\n-            } else {\n-                let dest_ptr = self.alloc_ptr(dest_ty)?.into();\n-                self.copy(src_ptr, dest_ptr, dest_ty)?;\n-                write_dest(self, Value::ByRef(dest_ptr))?;\n-            }\n+            self.read_maybe_aligned(aligned, |ectx| {\n+                if let Ok(Some(src_val)) = ectx.try_read_value(src_ptr, dest_ty) {\n+                    write_dest(ectx, src_val)?;\n+                } else {\n+                    let dest_ptr = ectx.alloc_ptr(dest_ty)?.into();\n+                    ectx.copy(src_ptr, dest_ptr, dest_ty)?;\n+                    write_dest(ectx, Value::by_ref(dest_ptr))?;\n+                }\n+                Ok(())\n+            })?;\n \n         } else {\n             // Finally, we have the simple case where neither source nor destination are\n@@ -1201,7 +1197,9 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         dest_ty: Ty<'tcx>,\n     ) -> EvalResult<'tcx> {\n         match value {\n-            Value::ByRef(ptr) => self.copy(ptr, dest, dest_ty),\n+            Value::ByRef(ptr, aligned) => {\n+                self.read_maybe_aligned(aligned, |ectx| ectx.copy(ptr, dest, dest_ty))\n+            },\n             Value::ByVal(primval) => {\n                 let size = self.type_size(dest_ty)?.expect(\"dest type must be sized\");\n                 self.memory.write_primval(dest, primval, size)\n@@ -1464,7 +1462,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n         match (&src_pointee_ty.sty, &dest_pointee_ty.sty) {\n             (&ty::TyArray(_, length), &ty::TySlice(_)) => {\n-                let ptr = src.read_ptr(&self.memory)?;\n+                let ptr = src.into_ptr(&mut self.memory)?;\n                 // u64 cast is from usize to u64, which is always good\n                 self.write_value(ptr.to_value_with_len(length as u64), dest, dest_ty)\n             }\n@@ -1478,7 +1476,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let trait_ref = data.principal().unwrap().with_self_ty(self.tcx, src_pointee_ty);\n                 let trait_ref = self.tcx.erase_regions(&trait_ref);\n                 let vtable = self.get_vtable(src_pointee_ty, trait_ref)?;\n-                let ptr = src.read_ptr(&self.memory)?;\n+                let ptr = src.into_ptr(&mut self.memory)?;\n                 self.write_value(ptr.to_value_with_vtable(vtable), dest, dest_ty)\n             },\n \n@@ -1521,8 +1519,9 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 //let src = adt::MaybeSizedValue::sized(src);\n                 //let dst = adt::MaybeSizedValue::sized(dst);\n                 let src_ptr = match src {\n-                    Value::ByRef(ptr) => ptr,\n-                    _ => bug!(\"expected pointer, got {:?}\", src),\n+                    Value::ByRef(ptr, true) => ptr,\n+                    // TODO: Is it possible for unaligned pointers to occur here?\n+                    _ => bug!(\"expected aligned pointer, got {:?}\", src),\n                 };\n \n                 // FIXME(solson)\n@@ -1541,7 +1540,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                     if src_fty == dst_fty {\n                         self.copy(src_f_ptr, dst_f_ptr.into(), src_fty)?;\n                     } else {\n-                        self.unsize_into(Value::ByRef(src_f_ptr), src_fty, Lvalue::from_ptr(dst_f_ptr), dst_fty)?;\n+                        self.unsize_into(Value::by_ref(src_f_ptr), src_fty, Lvalue::from_ptr(dst_f_ptr), dst_fty)?;\n                     }\n                 }\n                 Ok(())\n@@ -1568,9 +1567,9 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 Err(err) => {\n                     panic!(\"Failed to access local: {:?}\", err);\n                 }\n-                Ok(Value::ByRef(ptr)) => match ptr.into_inner_primval() {\n+                Ok(Value::ByRef(ptr, aligned)) => match ptr.into_inner_primval() {\n                     PrimVal::Ptr(ptr) => {\n-                        write!(msg, \" by ref:\").unwrap();\n+                        write!(msg, \" by {}ref:\", if aligned { \"\" } else { \"unaligned \" }).unwrap();\n                         allocs.push(ptr.alloc_id);\n                     },\n                     ptr => write!(msg, \" integral by ref: {:?}\", ptr).unwrap(),"}, {"sha": "f4a1f050735aa7da3b1699ede807822b5b92bee0", "filename": "src/lvalue.rs", "status": "modified", "additions": 35, "deletions": 35, "changes": 70, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Flvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Flvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flvalue.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -4,7 +4,7 @@ use rustc::ty::{self, Ty};\n use rustc_data_structures::indexed_vec::Idx;\n \n use error::{EvalError, EvalResult};\n-use eval_context::{EvalContext};\n+use eval_context::EvalContext;\n use memory::MemoryPointer;\n use value::{PrimVal, Value, Pointer};\n \n@@ -17,6 +17,8 @@ pub enum Lvalue<'tcx> {\n         /// before ever being dereferenced.\n         ptr: Pointer,\n         extra: LvalueExtra,\n+        /// Remember whether this lvalue is *supposed* to be aligned.\n+        aligned: bool,\n     },\n \n     /// An lvalue referring to a value on the stack. Represented by a stack frame index paired with\n@@ -68,23 +70,25 @@ impl<'tcx> Lvalue<'tcx> {\n     }\n \n     pub(crate) fn from_primval_ptr(ptr: Pointer) -> Self {\n-        Lvalue::Ptr { ptr, extra: LvalueExtra::None }\n+        Lvalue::Ptr { ptr, extra: LvalueExtra::None, aligned: true }\n     }\n \n     pub(crate) fn from_ptr(ptr: MemoryPointer) -> Self {\n         Self::from_primval_ptr(ptr.into())\n     }\n \n-    pub(super) fn to_ptr_and_extra(self) -> (Pointer, LvalueExtra) {\n+    pub(super) fn to_ptr_extra_aligned(self) -> (Pointer, LvalueExtra, bool) {\n         match self {\n-            Lvalue::Ptr { ptr, extra } => (ptr, extra),\n+            Lvalue::Ptr { ptr, extra, aligned } => (ptr, extra, aligned),\n             _ => bug!(\"to_ptr_and_extra: expected Lvalue::Ptr, got {:?}\", self),\n \n         }\n     }\n \n     pub(super) fn to_ptr(self) -> EvalResult<'tcx, MemoryPointer> {\n-        let (ptr, extra) = self.to_ptr_and_extra();\n+        let (ptr, extra, _aligned) = self.to_ptr_extra_aligned();\n+        // At this point, we forget about the alignment information -- the lvalue has been turned into a reference,\n+        // and no matter where it came from, it now must be aligned.\n         assert_eq!(extra, LvalueExtra::None);\n         ptr.to_ptr()\n     }\n@@ -175,6 +179,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         }\n     }\n \n+    /// Returns a value and (in case of a ByRef) if we are supposed to use aligned accesses.\n     pub(super) fn eval_and_read_lvalue(&mut self, lvalue: &mir::Lvalue<'tcx>) -> EvalResult<'tcx, Value> {\n         let ty = self.lvalue_ty(lvalue);\n         // Shortcut for things like accessing a fat pointer's field,\n@@ -190,9 +195,9 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         }\n \n         match lvalue {\n-            Lvalue::Ptr { ptr, extra } => {\n+            Lvalue::Ptr { ptr, extra, aligned } => {\n                 assert_eq!(extra, LvalueExtra::None);\n-                Ok(Value::ByRef(ptr))\n+                Ok(Value::ByRef(ptr, aligned))\n             }\n             Lvalue::Local { frame, local } => {\n                 self.stack[frame].get_local(local)\n@@ -239,7 +244,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             },\n \n             General { ref variants, .. } => {\n-                let (_, base_extra) = base.to_ptr_and_extra();\n+                let (_, base_extra, _) = base.to_ptr_extra_aligned();\n                 if let LvalueExtra::DowncastVariant(variant_idx) = base_extra {\n                     // +1 for the discriminant, which is field 0\n                     (variants[variant_idx].offsets[field_index + 1], variants[variant_idx].packed)\n@@ -289,27 +294,27 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n         };\n \n         // Do not allocate in trivial cases\n-        let (base_ptr, base_extra) = match base {\n-            Lvalue::Ptr { ptr, extra } => (ptr, extra),\n+        let (base_ptr, base_extra, aligned) = match base {\n+            Lvalue::Ptr { ptr, extra, aligned } => (ptr, extra, aligned),\n             Lvalue::Local { frame, local } => match self.stack[frame].get_local(local)? {\n                 // in case the type has a single field, just return the value\n                 Value::ByVal(_) if self.get_field_count(base_ty).map(|c| c == 1).unwrap_or(false) => {\n                     assert_eq!(offset.bytes(), 0, \"ByVal can only have 1 non zst field with offset 0\");\n                     return Ok(base);\n                 },\n-                Value::ByRef(_) |\n+                Value::ByRef(..) |\n                 Value::ByValPair(..) |\n-                Value::ByVal(_) => self.force_allocation(base)?.to_ptr_and_extra(),\n+                Value::ByVal(_) => self.force_allocation(base)?.to_ptr_extra_aligned(),\n             },\n             Lvalue::Global(cid) => match self.globals.get(&cid).expect(\"uncached global\").value {\n                 // in case the type has a single field, just return the value\n                 Value::ByVal(_) if self.get_field_count(base_ty).map(|c| c == 1).unwrap_or(false) => {\n                     assert_eq!(offset.bytes(), 0, \"ByVal can only have 1 non zst field with offset 0\");\n                     return Ok(base);\n                 },\n-                Value::ByRef(_) |\n+                Value::ByRef(..) |\n                 Value::ByValPair(..) |\n-                Value::ByVal(_) => self.force_allocation(base)?.to_ptr_and_extra(),\n+                Value::ByVal(_) => self.force_allocation(base)?.to_ptr_extra_aligned(),\n             },\n         };\n \n@@ -325,11 +330,6 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n         let field_ty = self.monomorphize(field_ty, self.substs());\n \n-        if packed {\n-            let size = self.type_size(field_ty)?.expect(\"packed struct must be sized\");\n-            self.memory.mark_packed(ptr.to_ptr()?, size);\n-        }\n-\n         let extra = if self.type_is_sized(field_ty) {\n             LvalueExtra::None\n         } else {\n@@ -343,15 +343,15 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             base_extra\n         };\n \n-        Ok(Lvalue::Ptr { ptr, extra })\n+        Ok(Lvalue::Ptr { ptr, extra, aligned: aligned && !packed })\n     }\n \n     fn eval_lvalue_projection(\n         &mut self,\n         proj: &mir::LvalueProjection<'tcx>,\n     ) -> EvalResult<'tcx, Lvalue<'tcx>> {\n         use rustc::mir::ProjectionElem::*;\n-        let (ptr, extra) = match proj.elem {\n+        let (ptr, extra, aligned) = match proj.elem {\n             Field(field, field_ty) => {\n                 let base = self.eval_lvalue(&proj.base)?;\n                 let base_ty = self.lvalue_ty(&proj.base);\n@@ -364,15 +364,15 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let base_layout = self.type_layout(base_ty)?;\n                 // FIXME(solson)\n                 let base = self.force_allocation(base)?;\n-                let (base_ptr, base_extra) = base.to_ptr_and_extra();\n+                let (base_ptr, base_extra, aligned) = base.to_ptr_extra_aligned();\n \n                 use rustc::ty::layout::Layout::*;\n                 let extra = match *base_layout {\n                     General { .. } => LvalueExtra::DowncastVariant(variant),\n                     RawNullablePointer { .. } | StructWrappedNullablePointer { .. } => base_extra,\n                     _ => bug!(\"variant downcast on non-aggregate: {:?}\", base_layout),\n                 };\n-                (base_ptr, extra)\n+                (base_ptr, extra, aligned)\n             }\n \n             Deref => {\n@@ -390,14 +390,14 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n                 match self.tcx.struct_tail(pointee_type).sty {\n                     ty::TyDynamic(..) => {\n-                        let (ptr, vtable) = val.expect_ptr_vtable_pair(&self.memory)?;\n-                        (ptr, LvalueExtra::Vtable(vtable))\n+                        let (ptr, vtable) = val.into_ptr_vtable_pair(&mut self.memory)?;\n+                        (ptr, LvalueExtra::Vtable(vtable), true)\n                     },\n                     ty::TyStr | ty::TySlice(_) => {\n-                        let (ptr, len) = val.expect_slice(&self.memory)?;\n-                        (ptr, LvalueExtra::Length(len))\n+                        let (ptr, len) = val.into_slice(&mut self.memory)?;\n+                        (ptr, LvalueExtra::Length(len), true)\n                     },\n-                    _ => (val.read_ptr(&self.memory)?, LvalueExtra::None),\n+                    _ => (val.into_ptr(&mut self.memory)?, LvalueExtra::None, true),\n                 }\n             }\n \n@@ -406,7 +406,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let base_ty = self.lvalue_ty(&proj.base);\n                 // FIXME(solson)\n                 let base = self.force_allocation(base)?;\n-                let (base_ptr, _) = base.to_ptr_and_extra();\n+                let (base_ptr, _, aligned) = base.to_ptr_extra_aligned();\n \n                 let (elem_ty, len) = base.elem_ty_and_len(base_ty);\n                 let elem_size = self.type_size(elem_ty)?.expect(\"slice element must be sized\");\n@@ -415,15 +415,15 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let n = self.value_to_primval(n_ptr, usize)?.to_u64()?;\n                 assert!(n < len, \"Tried to access element {} of array/slice with length {}\", n, len);\n                 let ptr = base_ptr.offset(n * elem_size, self.memory.layout)?;\n-                (ptr, LvalueExtra::None)\n+                (ptr, LvalueExtra::None, aligned)\n             }\n \n             ConstantIndex { offset, min_length, from_end } => {\n                 let base = self.eval_lvalue(&proj.base)?;\n                 let base_ty = self.lvalue_ty(&proj.base);\n                 // FIXME(solson)\n                 let base = self.force_allocation(base)?;\n-                let (base_ptr, _) = base.to_ptr_and_extra();\n+                let (base_ptr, _, aligned) = base.to_ptr_extra_aligned();\n \n                 let (elem_ty, n) = base.elem_ty_and_len(base_ty);\n                 let elem_size = self.type_size(elem_ty)?.expect(\"sequence element must be sized\");\n@@ -436,26 +436,26 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 };\n \n                 let ptr = base_ptr.offset(index * elem_size, self.memory.layout)?;\n-                (ptr, LvalueExtra::None)\n+                (ptr, LvalueExtra::None, aligned)\n             }\n \n             Subslice { from, to } => {\n                 let base = self.eval_lvalue(&proj.base)?;\n                 let base_ty = self.lvalue_ty(&proj.base);\n                 // FIXME(solson)\n                 let base = self.force_allocation(base)?;\n-                let (base_ptr, _) = base.to_ptr_and_extra();\n+                let (base_ptr, _, aligned) = base.to_ptr_extra_aligned();\n \n                 let (elem_ty, n) = base.elem_ty_and_len(base_ty);\n                 let elem_size = self.type_size(elem_ty)?.expect(\"slice element must be sized\");\n                 assert!(u64::from(from) <= n - u64::from(to));\n                 let ptr = base_ptr.offset(u64::from(from) * elem_size, self.memory.layout)?;\n                 let extra = LvalueExtra::Length(n - u64::from(to) - u64::from(from));\n-                (ptr, extra)\n+                (ptr, extra, aligned)\n             }\n         };\n \n-        Ok(Lvalue::Ptr { ptr, extra })\n+        Ok(Lvalue::Ptr { ptr, extra, aligned })\n     }\n \n     pub(super) fn lvalue_ty(&self, lvalue: &mir::Lvalue<'tcx>) -> Ty<'tcx> {"}, {"sha": "6e70e3692c11fcf6e1f780bd35367cdec38946e9", "filename": "src/memory.rs", "status": "modified", "additions": 59, "deletions": 65, "changes": 124, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fmemory.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -1,12 +1,13 @@\n use byteorder::{ReadBytesExt, WriteBytesExt, LittleEndian, BigEndian};\n-use std::collections::{btree_map, BTreeMap, HashMap, HashSet, VecDeque, BTreeSet};\n+use std::collections::{btree_map, BTreeMap, HashMap, HashSet, VecDeque};\n use std::{fmt, iter, ptr, mem, io};\n \n use rustc::ty;\n use rustc::ty::layout::{self, TargetDataLayout};\n \n use error::{EvalError, EvalResult};\n use value::{PrimVal, self, Pointer};\n+use eval_context::EvalContext;\n \n ////////////////////////////////////////////////////////////////////////////////\n // Allocations and pointers\n@@ -124,20 +125,6 @@ pub struct Memory<'a, 'tcx> {\n     /// Target machine data layout to emulate.\n     pub layout: &'a TargetDataLayout,\n \n-    /// List of memory regions containing packed structures.\n-    ///\n-    /// We mark memory as \"packed\" or \"unaligned\" for a single statement, and clear the marking\n-    /// afterwards. In the case where no packed structs are present, it's just a single emptyness\n-    /// check of a set instead of heavily influencing all memory access code as other solutions\n-    /// would. This is simpler than the alternative of passing a \"packed\" parameter to every\n-    /// load/store method.\n-    ///\n-    /// One disadvantage of this solution is the fact that you can cast a pointer to a packed\n-    /// struct to a pointer to a normal struct and if you access a field of both in the same MIR\n-    /// statement, the normal struct access will succeed even though it shouldn't. But even with\n-    /// mir optimizations, that situation is hard/impossible to produce.\n-    packed: BTreeSet<Entry>,\n-\n     /// A cache for basic byte allocations keyed by their contents. This is used to deduplicate\n     /// allocations for string and bytestring literals.\n     literal_alloc_cache: HashMap<Vec<u8>, AllocId>,\n@@ -147,6 +134,11 @@ pub struct Memory<'a, 'tcx> {\n \n     /// The Key to use for the next thread-local allocation.\n     next_thread_local: TlsKey,\n+\n+    /// To avoid having to pass flags to every single memory access, we have some global state saying whether\n+    /// alignment checking is currently enforced for read and/or write accesses.\n+    reads_are_aligned: bool,\n+    writes_are_aligned: bool,\n }\n \n impl<'a, 'tcx> Memory<'a, 'tcx> {\n@@ -159,11 +151,12 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n             layout,\n             memory_size: max_memory,\n             memory_usage: 0,\n-            packed: BTreeSet::new(),\n             static_alloc: HashSet::new(),\n             literal_alloc_cache: HashMap::new(),\n             thread_local: BTreeMap::new(),\n             next_thread_local: 0,\n+            reads_are_aligned: true,\n+            writes_are_aligned: true,\n         }\n     }\n \n@@ -278,30 +271,10 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n         self.layout.endian\n     }\n \n-    pub fn check_align(&self, ptr: Pointer, align: u64, len: u64) -> EvalResult<'tcx> {\n+    pub fn check_align(&self, ptr: Pointer, align: u64) -> EvalResult<'tcx> {\n         let offset = match ptr.into_inner_primval() {\n             PrimVal::Ptr(ptr) => {\n                 let alloc = self.get(ptr.alloc_id)?;\n-                // check whether the memory was marked as packed\n-                // we select all elements that have the correct alloc_id and are within\n-                // the range given by the offset into the allocation and the length\n-                let start = Entry {\n-                    alloc_id: ptr.alloc_id,\n-                    packed_start: 0,\n-                    packed_end: ptr.offset + len,\n-                };\n-                let end = Entry {\n-                    alloc_id: ptr.alloc_id,\n-                    packed_start: ptr.offset + len,\n-                    packed_end: 0,\n-                };\n-                for &Entry { packed_start, packed_end, .. } in self.packed.range(start..end) {\n-                    // if the region we are checking is covered by a region in `packed`\n-                    // ignore the actual alignment\n-                    if packed_start <= ptr.offset && (ptr.offset + len) <= packed_end {\n-                        return Ok(());\n-                    }\n-                }\n                 if alloc.align < align {\n                     return Err(EvalError::AlignmentCheckFailed {\n                         has: alloc.align,\n@@ -338,18 +311,6 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n         Ok(())\n     }\n \n-    pub(crate) fn mark_packed(&mut self, ptr: MemoryPointer, len: u64) {\n-        self.packed.insert(Entry {\n-            alloc_id: ptr.alloc_id,\n-            packed_start: ptr.offset,\n-            packed_end: ptr.offset + len,\n-        });\n-    }\n-\n-    pub(crate) fn clear_packed(&mut self) {\n-        self.packed.clear();\n-    }\n-\n     pub(crate) fn create_tls_key(&mut self, dtor: Option<ty::Instance<'tcx>>) -> TlsKey {\n         let new_key = self.next_thread_local;\n         self.next_thread_local += 1;\n@@ -426,20 +387,6 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n     }\n }\n \n-// The derived `Ord` impl sorts first by the first field, then, if the fields are the same\n-// by the second field, and if those are the same, too, then by the third field.\n-// This is exactly what we need for our purposes, since a range within an allocation\n-// will give us all `Entry`s that have that `AllocId`, and whose `packed_start` is <= than\n-// the one we're looking for, but not > the end of the range we're checking.\n-// At the same time the `packed_end` is irrelevant for the sorting and range searching, but used for the check.\n-// This kind of search breaks, if `packed_end < packed_start`, so don't do that!\n-#[derive(Eq, PartialEq, Ord, PartialOrd)]\n-struct Entry {\n-    alloc_id: AllocId,\n-    packed_start: u64,\n-    packed_end: u64,\n-}\n-\n /// Allocation accessors\n impl<'a, 'tcx> Memory<'a, 'tcx> {\n     pub fn get(&self, id: AllocId) -> EvalResult<'tcx, &Allocation> {\n@@ -576,7 +523,9 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n             return Ok(&[]);\n         }\n         // FIXME: check alignment for zst memory accesses?\n-        self.check_align(ptr.into(), align, size)?;\n+        if self.reads_are_aligned {\n+            self.check_align(ptr.into(), align)?;\n+        }\n         self.check_bounds(ptr.offset(size, self.layout)?, true)?; // if ptr.offset is in bounds, then so is ptr (because offset checks for overflow)\n         let alloc = self.get(ptr.alloc_id)?;\n         assert_eq!(ptr.offset as usize as u64, ptr.offset);\n@@ -590,7 +539,9 @@ impl<'a, 'tcx> Memory<'a, 'tcx> {\n             return Ok(&mut []);\n         }\n         // FIXME: check alignment for zst memory accesses?\n-        self.check_align(ptr.into(), align, size)?;\n+        if self.writes_are_aligned {\n+            self.check_align(ptr.into(), align)?;\n+        }\n         self.check_bounds(ptr.offset(size, self.layout)?, true)?; // if ptr.offset is in bounds, then so is ptr (because offset checks for overflow)\n         let alloc = self.get_mut(ptr.alloc_id)?;\n         assert_eq!(ptr.offset as usize as u64, ptr.offset);\n@@ -1125,3 +1076,46 @@ fn bit_index(bits: u64) -> (usize, usize) {\n     assert_eq!(b as usize as u64, b);\n     (a as usize, b as usize)\n }\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Unaligned accesses\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub(crate) trait HasMemory<'a, 'tcx> {\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx>;\n+\n+    // These are not supposed to be overriden.\n+    fn read_maybe_aligned<F, T>(&mut self, aligned: bool, f: F) -> EvalResult<'tcx, T>\n+        where F: FnOnce(&mut Self) -> EvalResult<'tcx, T>\n+    {\n+        assert!(self.memory_mut().reads_are_aligned, \"Unaligned reads must not be nested\");\n+        self.memory_mut().reads_are_aligned = aligned;\n+        let t = f(self);\n+        self.memory_mut().reads_are_aligned = true;\n+        t\n+    }\n+\n+    fn write_maybe_aligned<F, T>(&mut self, aligned: bool, f: F) -> EvalResult<'tcx, T>\n+        where F: FnOnce(&mut Self) -> EvalResult<'tcx, T>\n+    {\n+        assert!(self.memory_mut().writes_are_aligned, \"Unaligned writes must not be nested\");\n+        self.memory_mut().writes_are_aligned = aligned;\n+        let t = f(self);\n+        self.memory_mut().writes_are_aligned = true;\n+        t\n+    }\n+}\n+\n+impl<'a, 'tcx> HasMemory<'a, 'tcx> for Memory<'a, 'tcx> {\n+    #[inline]\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx> {\n+        self\n+    }\n+}\n+\n+impl<'a, 'tcx> HasMemory<'a, 'tcx> for EvalContext<'a, 'tcx> {\n+    #[inline]\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx> {\n+        &mut self.memory\n+    }\n+}"}, {"sha": "3aafda476363da4953b4aefb6ed77e0ac75aefdb", "filename": "src/step.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fstep.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fstep.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fstep.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -28,8 +28,6 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n     /// Returns true as long as there are more things to do.\n     pub fn step(&mut self) -> EvalResult<'tcx, bool> {\n-        // see docs on the `Memory::packed` field for why we do this\n-        self.memory.clear_packed();\n         self.inc_step_counter_and_check_limit(1)?;\n         if self.stack.is_empty() {\n             return Ok(false);"}, {"sha": "c166980a150d3f76e65b7ce172d8eed1f62cf67b", "filename": "src/terminator/drop.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fdrop.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fdrop.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fterminator%2Fdrop.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -11,10 +11,13 @@ use value::Value;\n impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n     pub(crate) fn drop_lvalue(&mut self, lval: Lvalue<'tcx>, instance: ty::Instance<'tcx>, ty: Ty<'tcx>, span: Span) -> EvalResult<'tcx> {\n         trace!(\"drop_lvalue: {:#?}\", lval);\n+        // We take the address of the object.  This may well be unaligned, which is fine for us here.\n+        // However, unaligned accesses will probably make the actual drop implementation fail -- a problem shared\n+        // by rustc.\n         let val = match self.force_allocation(lval)? {\n-            Lvalue::Ptr { ptr, extra: LvalueExtra::Vtable(vtable) } => ptr.to_value_with_vtable(vtable),\n-            Lvalue::Ptr { ptr, extra: LvalueExtra::Length(len) } => ptr.to_value_with_len(len),\n-            Lvalue::Ptr { ptr, extra: LvalueExtra::None } => ptr.to_value(),\n+            Lvalue::Ptr { ptr, extra: LvalueExtra::Vtable(vtable), aligned: _ } => ptr.to_value_with_vtable(vtable),\n+            Lvalue::Ptr { ptr, extra: LvalueExtra::Length(len), aligned: _ } => ptr.to_value_with_len(len),\n+            Lvalue::Ptr { ptr, extra: LvalueExtra::None, aligned: _ } => ptr.to_value(),\n             _ => bug!(\"force_allocation broken\"),\n         };\n         self.drop(val, instance, ty, span)"}, {"sha": "da45d7b410a6095eddd4975ecf9ab92c288f73b4", "filename": "src/terminator/intrinsic.rs", "status": "modified", "additions": 34, "deletions": 33, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fterminator%2Fintrinsic.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -8,6 +8,7 @@ use error::{EvalError, EvalResult};\n use eval_context::EvalContext;\n use lvalue::{Lvalue, LvalueExtra};\n use value::{PrimVal, PrimValKind, Value, Pointer};\n+use memory::HasMemory;\n \n impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n     pub(super) fn call_intrinsic(\n@@ -44,7 +45,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"arith_offset\" => {\n                 let offset = self.value_to_primval(arg_vals[1], isize)?.to_i128()? as i64;\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let result_ptr = self.wrapping_pointer_offset(ptr, substs.type_at(0), offset)?;\n                 self.write_ptr(dest, result_ptr, dest_ty)?;\n             }\n@@ -60,16 +61,16 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             \"atomic_load_acq\" |\n             \"volatile_load\" => {\n                 let ty = substs.type_at(0);\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n-                self.write_value(Value::ByRef(ptr), dest, ty)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n+                self.write_value(Value::by_ref(ptr), dest, ty)?;\n             }\n \n             \"atomic_store\" |\n             \"atomic_store_relaxed\" |\n             \"atomic_store_rel\" |\n             \"volatile_store\" => {\n                 let ty = substs.type_at(0);\n-                let dest = arg_vals[0].read_ptr(&self.memory)?;\n+                let dest = arg_vals[0].into_ptr(&mut self.memory)?;\n                 self.write_value_to_ptr(arg_vals[1], dest, ty)?;\n             }\n \n@@ -79,12 +80,12 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             _ if intrinsic_name.starts_with(\"atomic_xchg\") => {\n                 let ty = substs.type_at(0);\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let change = self.value_to_primval(arg_vals[1], ty)?;\n                 let old = self.read_value(ptr, ty)?;\n                 let old = match old {\n                     Value::ByVal(val) => val,\n-                    Value::ByRef(_) => bug!(\"just read the value, can't be byref\"),\n+                    Value::ByRef(..) => bug!(\"just read the value, can't be byref\"),\n                     Value::ByValPair(..) => bug!(\"atomic_xchg doesn't work with nonprimitives\"),\n                 };\n                 self.write_primval(dest, old, ty)?;\n@@ -93,13 +94,13 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             _ if intrinsic_name.starts_with(\"atomic_cxchg\") => {\n                 let ty = substs.type_at(0);\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let expect_old = self.value_to_primval(arg_vals[1], ty)?;\n                 let change = self.value_to_primval(arg_vals[2], ty)?;\n                 let old = self.read_value(ptr, ty)?;\n                 let old = match old {\n                     Value::ByVal(val) => val,\n-                    Value::ByRef(_) => bug!(\"just read the value, can't be byref\"),\n+                    Value::ByRef(..) => bug!(\"just read the value, can't be byref\"),\n                     Value::ByValPair(..) => bug!(\"atomic_cxchg doesn't work with nonprimitives\"),\n                 };\n                 let (val, _) = self.binary_op(mir::BinOp::Eq, old, ty, expect_old, ty)?;\n@@ -114,12 +115,12 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             \"atomic_xadd\" | \"atomic_xadd_acq\" | \"atomic_xadd_rel\" | \"atomic_xadd_acqrel\" | \"atomic_xadd_relaxed\" |\n             \"atomic_xsub\" | \"atomic_xsub_acq\" | \"atomic_xsub_rel\" | \"atomic_xsub_acqrel\" | \"atomic_xsub_relaxed\" => {\n                 let ty = substs.type_at(0);\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let change = self.value_to_primval(arg_vals[1], ty)?;\n                 let old = self.read_value(ptr, ty)?;\n                 let old = match old {\n                     Value::ByVal(val) => val,\n-                    Value::ByRef(_) => bug!(\"just read the value, can't be byref\"),\n+                    Value::ByRef(..) => bug!(\"just read the value, can't be byref\"),\n                     Value::ByValPair(..) => bug!(\"atomic_xadd_relaxed doesn't work with nonprimitives\"),\n                 };\n                 self.write_primval(dest, old, ty)?;\n@@ -144,8 +145,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let elem_size = self.type_size(elem_ty)?.expect(\"cannot copy unsized value\");\n                 if elem_size != 0 {\n                     let elem_align = self.type_align(elem_ty)?;\n-                    let src = arg_vals[0].read_ptr(&self.memory)?;\n-                    let dest = arg_vals[1].read_ptr(&self.memory)?;\n+                    let src = arg_vals[0].into_ptr(&mut self.memory)?;\n+                    let dest = arg_vals[1].into_ptr(&mut self.memory)?;\n                     let count = self.value_to_primval(arg_vals[2], usize)?.to_u64()?;\n                     self.memory.copy(src, dest, count * elem_size, elem_align, intrinsic_name.ends_with(\"_nonoverlapping\"))?;\n                 }\n@@ -173,7 +174,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"discriminant_value\" => {\n                 let ty = substs.type_at(0);\n-                let adt_ptr = arg_vals[0].read_ptr(&self.memory)?.to_ptr()?;\n+                let adt_ptr = arg_vals[0].into_ptr(&mut self.memory)?.to_ptr()?;\n                 let discr_val = self.read_discriminant_value(adt_ptr, ty)?;\n                 self.write_primval(dest, PrimVal::Bytes(discr_val), dest_ty)?;\n             }\n@@ -248,9 +249,10 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let size = self.type_size(dest_ty)?.expect(\"cannot zero unsized value\");\n                 let init = |this: &mut Self, val: Value| {\n                     let zero_val = match val {\n-                        Value::ByRef(ptr) => {\n+                        Value::ByRef(ptr, aligned) => {\n+                            // These writes have no alignment restriction anyway.\n                             this.memory.write_repeat(ptr, 0, size)?;\n-                            Value::ByRef(ptr)\n+                            Value::ByRef(ptr, aligned)\n                         },\n                         // TODO(solson): Revisit this, it's fishy to check for Undef here.\n                         Value::ByVal(PrimVal::Undef) => match this.ty_to_primval_kind(dest_ty) {\n@@ -259,7 +261,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                                 let ptr = this.alloc_ptr_with_substs(dest_ty, substs)?;\n                                 let ptr = Pointer::from(PrimVal::Ptr(ptr));\n                                 this.memory.write_repeat(ptr, 0, size)?;\n-                                Value::ByRef(ptr)\n+                                Value::by_ref(ptr)\n                             }\n                         },\n                         Value::ByVal(_) => Value::ByVal(PrimVal::Bytes(0)),\n@@ -270,8 +272,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 };\n                 match dest {\n                     Lvalue::Local { frame, local } => self.modify_local(frame, local, init)?,\n-                    Lvalue::Ptr { ptr, extra: LvalueExtra::None } => self.memory.write_repeat(ptr, 0, size)?,\n-                    Lvalue::Ptr { .. } => bug!(\"init intrinsic tried to write to fat ptr target\"),\n+                    Lvalue::Ptr { ptr, extra: LvalueExtra::None, aligned: true } => self.memory.write_repeat(ptr, 0, size)?,\n+                    Lvalue::Ptr { .. } => bug!(\"init intrinsic tried to write to fat or unaligned ptr target\"),\n                     Lvalue::Global(cid) => self.modify_global(cid, init)?,\n                 }\n             }\n@@ -293,7 +295,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"move_val_init\" => {\n                 let ty = substs.type_at(0);\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 self.write_value_to_ptr(arg_vals[1], ptr, ty)?;\n             }\n \n@@ -306,7 +308,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"offset\" => {\n                 let offset = self.value_to_primval(arg_vals[1], isize)?.to_i128()? as i64;\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let result_ptr = self.pointer_offset(ptr, substs.type_at(0), offset)?;\n                 self.write_ptr(dest, result_ptr, dest_ty)?;\n             }\n@@ -394,11 +396,10 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"transmute\" => {\n                 let src_ty = substs.type_at(0);\n-                let dest_ty = substs.type_at(1);\n-                let size = self.type_size(dest_ty)?.expect(\"transmute() type must be sized\");\n                 let ptr = self.force_allocation(dest)?.to_ptr()?;\n-                self.memory.mark_packed(ptr, size);\n-                self.write_value_to_ptr(arg_vals[0], ptr.into(), src_ty)?;\n+                self.write_maybe_aligned(/*aligned*/false, |ectx| {\n+                    ectx.write_value_to_ptr(arg_vals[0], ptr.into(), src_ty)\n+                })?;\n             }\n \n             \"unchecked_shl\" => {\n@@ -439,18 +440,18 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let size = dest_layout.size(&self.tcx.data_layout).bytes();\n                 let uninit = |this: &mut Self, val: Value| {\n                     match val {\n-                        Value::ByRef(ptr) => {\n+                        Value::ByRef(ptr, aligned) => {\n                             this.memory.mark_definedness(ptr, size, false)?;\n-                            Ok(Value::ByRef(ptr))\n+                            Ok(Value::ByRef(ptr, aligned))\n                         },\n                         _ => Ok(Value::ByVal(PrimVal::Undef)),\n                     }\n                 };\n                 match dest {\n                     Lvalue::Local { frame, local } => self.modify_local(frame, local, uninit)?,\n-                    Lvalue::Ptr { ptr, extra: LvalueExtra::None } =>\n+                    Lvalue::Ptr { ptr, extra: LvalueExtra::None, aligned: true } =>\n                         self.memory.mark_definedness(ptr, size, false)?,\n-                    Lvalue::Ptr { .. } => bug!(\"uninit intrinsic tried to write to fat ptr target\"),\n+                    Lvalue::Ptr { .. } => bug!(\"uninit intrinsic tried to write to fat or unaligned ptr target\"),\n                     Lvalue::Global(cid) => self.modify_global(cid, uninit)?,\n                 }\n             }\n@@ -461,11 +462,11 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 let ty_align = self.type_align(ty)?;\n                 let val_byte = self.value_to_primval(arg_vals[1], u8)?.to_u128()? as u8;\n                 let size = self.type_size(ty)?.expect(\"write_bytes() type must be sized\");\n-                let ptr = arg_vals[0].read_ptr(&self.memory)?;\n+                let ptr = arg_vals[0].into_ptr(&mut self.memory)?;\n                 let count = self.value_to_primval(arg_vals[2], usize)?.to_u64()?;\n                 if count > 0 {\n                     // TODO: Should we, at least, validate the alignment? (Also see memory::copy)\n-                    self.memory.check_align(ptr, ty_align, size * count)?;\n+                    self.memory.check_align(ptr, ty_align)?;\n                     self.memory.write_repeat(ptr, val_byte, size * count)?;\n                 }\n             }\n@@ -482,7 +483,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n     }\n \n     pub fn size_and_align_of_dst(\n-        &self,\n+        &mut self,\n         ty: ty::Ty<'tcx>,\n         value: Value,\n     ) -> EvalResult<'tcx, (u64, u64)> {\n@@ -546,15 +547,15 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                     Ok((size, align.abi()))\n                 }\n                 ty::TyDynamic(..) => {\n-                    let (_, vtable) = value.expect_ptr_vtable_pair(&self.memory)?;\n+                    let (_, vtable) = value.into_ptr_vtable_pair(&mut self.memory)?;\n                     // the second entry in the vtable is the dynamic size of the object.\n                     self.read_size_and_align_from_vtable(vtable)\n                 }\n \n                 ty::TySlice(_) | ty::TyStr => {\n                     let elem_ty = ty.sequence_element_type(self.tcx);\n                     let elem_size = self.type_size(elem_ty)?.expect(\"slice element must be sized\") as u64;\n-                    let (_, len) = value.expect_slice(&self.memory)?;\n+                    let (_, len) = value.into_slice(&mut self.memory)?;\n                     let align = self.type_align(elem_ty)?;\n                     Ok((len * elem_size, align as u64))\n                 }"}, {"sha": "0c25dc3bed37b52b1feeeb079053d1cdbf319e38", "filename": "src/terminator/mod.rs", "status": "modified", "additions": 24, "deletions": 23, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fterminator%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fterminator%2Fmod.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -312,9 +312,10 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                             if self.frame().mir.args_iter().count() == fields.len() + 1 {\n                                 let offsets = variant.offsets.iter().map(|s| s.bytes());\n                                 match arg_val {\n-                                    Value::ByRef(ptr) => {\n+                                    Value::ByRef(ptr, aligned) => {\n+                                        assert!(aligned, \"Unaligned ByRef-values cannot occur as function arguments\");\n                                         for ((offset, ty), arg_local) in offsets.zip(fields).zip(arg_locals) {\n-                                            let arg = Value::ByRef(ptr.offset(offset, self.memory.layout)?);\n+                                            let arg = Value::ByRef(ptr.offset(offset, self.memory.layout)?, true);\n                                             let dest = self.eval_lvalue(&mir::Lvalue::Local(arg_local))?;\n                                             trace!(\"writing arg {:?} to {:?} (type: {})\", arg, dest, ty);\n                                             self.write_value(arg, dest, ty)?;\n@@ -395,7 +396,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             },\n             ty::InstanceDef::Virtual(_, idx) => {\n                 let ptr_size = self.memory.pointer_size();\n-                let (_, vtable) = self.eval_operand(&arg_operands[0])?.expect_ptr_vtable_pair(&self.memory)?;\n+                let (_, vtable) = self.eval_operand(&arg_operands[0])?.into_ptr_vtable_pair(&mut self.memory)?;\n                 let fn_ptr = self.memory.read_ptr(vtable.offset(ptr_size * (idx as u64 + 3), self.memory.layout)?)?;\n                 let instance = self.memory.get_fn(fn_ptr.to_ptr()?)?;\n                 let mut arg_operands = arg_operands.to_vec();\n@@ -574,7 +575,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 self.write_primval(dest, PrimVal::Ptr(ptr), dest_ty)?;\n             }\n             \"alloc::heap::::__rust_dealloc\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?.to_ptr()?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n                 let old_size = self.value_to_primval(args[1], usize)?.to_u64()?;\n                 let align = self.value_to_primval(args[2], usize)?.to_u64()?;\n                 if old_size == 0 {\n@@ -586,7 +587,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 self.memory.deallocate(ptr, Some((old_size, align)))?;\n             }\n             \"alloc::heap::::__rust_realloc\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?.to_ptr()?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n                 let old_size = self.value_to_primval(args[1], usize)?.to_u64()?;\n                 let old_align = self.value_to_primval(args[2], usize)?.to_u64()?;\n                 let new_size = self.value_to_primval(args[3], usize)?.to_u64()?;\n@@ -662,7 +663,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"free\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?;\n                 if !ptr.is_null()? {\n                     self.memory.deallocate(ptr.to_ptr()?, None)?;\n                 }\n@@ -676,8 +677,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"dlsym\" => {\n-                let _handle = args[0].read_ptr(&self.memory)?;\n-                let symbol = args[1].read_ptr(&self.memory)?.to_ptr()?;\n+                let _handle = args[0].into_ptr(&mut self.memory)?;\n+                let symbol = args[1].into_ptr(&mut self.memory)?.to_ptr()?;\n                 let symbol_name = self.memory.read_c_str(symbol)?;\n                 let err = format!(\"bad c unicode symbol: {:?}\", symbol_name);\n                 let symbol_name = ::std::str::from_utf8(symbol_name).unwrap_or(&err);\n@@ -688,8 +689,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n                 // fn __rust_maybe_catch_panic(f: fn(*mut u8), data: *mut u8, data_ptr: *mut usize, vtable_ptr: *mut usize) -> u32\n                 // We abort on panic, so not much is going on here, but we still have to call the closure\n                 let u8_ptr_ty = self.tcx.mk_mut_ptr(self.tcx.types.u8);\n-                let f = args[0].read_ptr(&self.memory)?.to_ptr()?;\n-                let data = args[1].read_ptr(&self.memory)?;\n+                let f = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n+                let data = args[1].into_ptr(&mut self.memory)?;\n                 let f_instance = self.memory.get_fn(f)?;\n                 self.write_null(dest, dest_ty)?;\n \n@@ -720,8 +721,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"memcmp\" => {\n-                let left = args[0].read_ptr(&self.memory)?;\n-                let right = args[1].read_ptr(&self.memory)?;\n+                let left = args[0].into_ptr(&mut self.memory)?;\n+                let right = args[1].into_ptr(&mut self.memory)?;\n                 let n = self.value_to_primval(args[2], usize)?.to_u64()?;\n \n                 let result = {\n@@ -740,7 +741,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"memrchr\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?;\n                 let val = self.value_to_primval(args[1], usize)?.to_u64()? as u8;\n                 let num = self.value_to_primval(args[2], usize)?.to_u64()?;\n                 if let Some(idx) = self.memory.read_bytes(ptr, num)?.iter().rev().position(|&c| c == val) {\n@@ -752,7 +753,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"memchr\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?;\n                 let val = self.value_to_primval(args[1], usize)?.to_u64()? as u8;\n                 let num = self.value_to_primval(args[2], usize)?.to_u64()?;\n                 if let Some(idx) = self.memory.read_bytes(ptr, num)?.iter().position(|&c| c == val) {\n@@ -765,7 +766,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"getenv\" => {\n                 let result = {\n-                    let name_ptr = args[0].read_ptr(&self.memory)?.to_ptr()?;\n+                    let name_ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n                     let name = self.memory.read_c_str(name_ptr)?;\n                     match self.env_vars.get(name) {\n                         Some(&var) => PrimVal::Ptr(var),\n@@ -778,7 +779,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             \"unsetenv\" => {\n                 let mut success = None;\n                 {\n-                    let name_ptr = args[0].read_ptr(&self.memory)?;\n+                    let name_ptr = args[0].into_ptr(&mut self.memory)?;\n                     if !name_ptr.is_null()? {\n                         let name = self.memory.read_c_str(name_ptr.to_ptr()?)?;\n                         if !name.is_empty() && !name.contains(&b'=') {\n@@ -799,8 +800,8 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             \"setenv\" => {\n                 let mut new = None;\n                 {\n-                    let name_ptr = args[0].read_ptr(&self.memory)?;\n-                    let value_ptr = args[1].read_ptr(&self.memory)?.to_ptr()?;\n+                    let name_ptr = args[0].into_ptr(&mut self.memory)?;\n+                    let value_ptr = args[1].into_ptr(&mut self.memory)?.to_ptr()?;\n                     let value = self.memory.read_c_str(value_ptr)?;\n                     if !name_ptr.is_null()? {\n                         let name = self.memory.read_c_str(name_ptr.to_ptr()?)?;\n@@ -825,7 +826,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             \"write\" => {\n                 let fd = self.value_to_primval(args[0], usize)?.to_u64()?;\n-                let buf = args[1].read_ptr(&self.memory)?;\n+                let buf = args[1].into_ptr(&mut self.memory)?;\n                 let n = self.value_to_primval(args[2], usize)?.to_u64()?;\n                 trace!(\"Called write({:?}, {:?}, {:?})\", fd, buf, n);\n                 let result = if fd == 1 || fd == 2 { // stdout/stderr\n@@ -842,7 +843,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             }\n \n             \"strlen\" => {\n-                let ptr = args[0].read_ptr(&self.memory)?.to_ptr()?;\n+                let ptr = args[0].into_ptr(&mut self.memory)?.to_ptr()?;\n                 let n = self.memory.read_c_str(ptr)?.len();\n                 self.write_primval(dest, PrimVal::Bytes(n as u128), dest_ty)?;\n             }\n@@ -885,10 +886,10 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n \n             // Hook pthread calls that go to the thread-local storage memory subsystem\n             \"pthread_key_create\" => {\n-                let key_ptr = args[0].read_ptr(&self.memory)?;\n+                let key_ptr = args[0].into_ptr(&mut self.memory)?;\n \n                 // Extract the function type out of the signature (that seems easier than constructing it ourselves...)\n-                let dtor = match args[1].read_ptr(&self.memory)?.into_inner_primval() {\n+                let dtor = match args[1].into_ptr(&mut self.memory)?.into_inner_primval() {\n                     PrimVal::Ptr(dtor_ptr) => Some(self.memory.get_fn(dtor_ptr)?),\n                     PrimVal::Bytes(0) => None,\n                     PrimVal::Bytes(_) => return Err(EvalError::ReadBytesAsPointer),\n@@ -930,7 +931,7 @@ impl<'a, 'tcx> EvalContext<'a, 'tcx> {\n             \"pthread_setspecific\" => {\n                 // The conversion into TlsKey here is a little fishy, but should work as long as usize >= libc::pthread_key_t\n                 let key = self.value_to_primval(args[0], usize)?.to_u64()? as TlsKey;\n-                let new_ptr = args[1].read_ptr(&self.memory)?;\n+                let new_ptr = args[1].into_ptr(&mut self.memory)?;\n                 self.memory.store_tls(key, new_ptr)?;\n                 \n                 // Return success (0)"}, {"sha": "f80a05805c2c3555ee3a07ac73a55377e473e121", "filename": "src/value.rs", "status": "modified", "additions": 31, "deletions": 17, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/src%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fvalue.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -5,7 +5,7 @@ use std::mem::transmute;\n use rustc::ty::layout::TargetDataLayout;\n \n use error::{EvalError, EvalResult};\n-use memory::{Memory, MemoryPointer};\n+use memory::{Memory, MemoryPointer, HasMemory};\n \n pub(super) fn bytes_to_f32(bytes: u128) -> f32 {\n     unsafe { transmute::<u32, f32>(bytes as u32) }\n@@ -26,14 +26,15 @@ pub(super) fn f64_to_bytes(f: f64) -> u128 {\n /// A `Value` represents a single self-contained Rust value.\n ///\n /// A `Value` can either refer to a block of memory inside an allocation (`ByRef`) or to a primitve\n-/// value held directly, outside of any allocation (`ByVal`).\n+/// value held directly, outside of any allocation (`ByVal`).  For `ByRef`-values, we remember\n+/// whether the pointer is supposed to be aligned or not (also see Lvalue).\n ///\n /// For optimization of a few very common cases, there is also a representation for a pair of\n /// primitive values (`ByValPair`). It allows Miri to avoid making allocations for checked binary\n /// operations and fat pointers. This idea was taken from rustc's trans.\n #[derive(Clone, Copy, Debug)]\n pub enum Value {\n-    ByRef(Pointer),\n+    ByRef(Pointer, bool),\n     ByVal(PrimVal),\n     ByValPair(PrimVal, PrimVal),\n }\n@@ -158,24 +159,35 @@ pub enum PrimValKind {\n }\n \n impl<'a, 'tcx: 'a> Value {\n-    pub(super) fn read_ptr(&self, mem: &Memory<'a, 'tcx>) -> EvalResult<'tcx, Pointer> {\n+    #[inline]\n+    pub(super) fn by_ref(ptr: Pointer) -> Self {\n+        Value::ByRef(ptr, true)\n+    }\n+\n+    /// Convert the value into a pointer (or a pointer-sized integer).  If the value is a ByRef,\n+    /// this may have to perform a load.\n+    pub(super) fn into_ptr(&self, mem: &mut Memory<'a, 'tcx>) -> EvalResult<'tcx, Pointer> {\n         use self::Value::*;\n         match *self {\n-            ByRef(ptr) => mem.read_ptr(ptr.to_ptr()?),\n+            ByRef(ptr, aligned) => {\n+                mem.read_maybe_aligned(aligned, |mem| mem.read_ptr(ptr.to_ptr()?) )\n+            },\n             ByVal(ptr) | ByValPair(ptr, _) => Ok(ptr.into()),\n         }\n     }\n \n-    pub(super) fn expect_ptr_vtable_pair(\n+    pub(super) fn into_ptr_vtable_pair(\n         &self,\n-        mem: &Memory<'a, 'tcx>\n+        mem: &mut Memory<'a, 'tcx>\n     ) -> EvalResult<'tcx, (Pointer, MemoryPointer)> {\n         use self::Value::*;\n         match *self {\n-            ByRef(ref_ptr) => {\n-                let ptr = mem.read_ptr(ref_ptr.to_ptr()?)?;\n-                let vtable = mem.read_ptr(ref_ptr.offset(mem.pointer_size(), mem.layout)?.to_ptr()?)?;\n-                Ok((ptr, vtable.to_ptr()?))\n+            ByRef(ref_ptr, aligned) => {\n+                mem.read_maybe_aligned(aligned, |mem| {\n+                    let ptr = mem.read_ptr(ref_ptr.to_ptr()?)?;\n+                    let vtable = mem.read_ptr(ref_ptr.offset(mem.pointer_size(), mem.layout)?.to_ptr()?)?;\n+                    Ok((ptr, vtable.to_ptr()?))\n+                })\n             }\n \n             ByValPair(ptr, vtable) => Ok((ptr.into(), vtable.to_ptr()?)),\n@@ -184,20 +196,22 @@ impl<'a, 'tcx: 'a> Value {\n         }\n     }\n \n-    pub(super) fn expect_slice(&self, mem: &Memory<'a, 'tcx>) -> EvalResult<'tcx, (Pointer, u64)> {\n+    pub(super) fn into_slice(&self, mem: &mut Memory<'a, 'tcx>) -> EvalResult<'tcx, (Pointer, u64)> {\n         use self::Value::*;\n         match *self {\n-            ByRef(ref_ptr) => {\n-                let ptr = mem.read_ptr(ref_ptr.to_ptr()?)?;\n-                let len = mem.read_usize(ref_ptr.offset(mem.pointer_size(), mem.layout)?.to_ptr()?)?;\n-                Ok((ptr, len))\n+            ByRef(ref_ptr, aligned) => {\n+                mem.write_maybe_aligned(aligned, |mem| {\n+                    let ptr = mem.read_ptr(ref_ptr.to_ptr()?)?;\n+                    let len = mem.read_usize(ref_ptr.offset(mem.pointer_size(), mem.layout)?.to_ptr()?)?;\n+                    Ok((ptr, len))\n+                })\n             },\n             ByValPair(ptr, val) => {\n                 let len = val.to_u128()?;\n                 assert_eq!(len as u64 as u128, len);\n                 Ok((ptr.into(), len as u64))\n             },\n-            ByVal(_) => unimplemented!(),\n+            ByVal(_) => bug!(\"expected ptr and length, got {:?}\", self),\n         }\n     }\n }"}, {"sha": "7219649e728c91a6135bf4c438d7ff72cc12eafa", "filename": "tests/run-pass/packed_struct.rs", "status": "modified", "additions": 47, "deletions": 1, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/56d4de303fb59a7235caa1bd2c8e32675428f421/tests%2Frun-pass%2Fpacked_struct.rs", "raw_url": "https://github.com/rust-lang/rust/raw/56d4de303fb59a7235caa1bd2c8e32675428f421/tests%2Frun-pass%2Fpacked_struct.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Frun-pass%2Fpacked_struct.rs?ref=56d4de303fb59a7235caa1bd2c8e32675428f421", "patch": "@@ -1,11 +1,50 @@\n+#![allow(dead_code)]\n+#![feature(unsize, coerce_unsized)]\n+\n #[repr(packed)]\n struct S {\n     a: i32,\n     b: i64,\n }\n \n+#[repr(packed)]\n+struct Test1<'a> {\n+    x: u8,\n+    other: &'a u32,\n+}\n+\n+#[repr(packed)]\n+struct Test2<'a> {\n+    x: u8,\n+    other: &'a Test1<'a>,\n+}\n+\n+fn test(t: Test2) {\n+    let x = *t.other.other;\n+    assert_eq!(x, 42);\n+}\n+\n+fn test_unsizing() {\n+    #[repr(packed)]\n+    struct UnalignedPtr<'a, T: ?Sized>\n+    where T: 'a,\n+    {\n+        data: &'a T,\n+    }\n+\n+    impl<'a, T, U> std::ops::CoerceUnsized<UnalignedPtr<'a, U>> for UnalignedPtr<'a, T>\n+    where\n+        T: std::marker::Unsize<U> + ?Sized,\n+        U: ?Sized,\n+    { }\n+\n+    let arr = [1, 2, 3];\n+    let arr_unaligned: UnalignedPtr<[i32; 3]> = UnalignedPtr { data: &arr };\n+    let _uns: UnalignedPtr<[i32]> = arr_unaligned;\n+}\n+\n fn main() {\n-    let x = S {\n+    let mut x = S {\n         a: 42,\n         b: 99,\n     };\n@@ -16,4 +55,11 @@ fn main() {\n     // can't do `assert_eq!(x.a, 42)`, because `assert_eq!` takes a reference\n     assert_eq!({x.a}, 42);\n     assert_eq!({x.b}, 99);\n+\n+    x.b = 77;\n+    assert_eq!({x.b}, 77);\n+\n+    test(Test2 { x: 0, other: &Test1 { x: 0, other: &42 }});\n+\n+    test_unsizing();\n }"}]}