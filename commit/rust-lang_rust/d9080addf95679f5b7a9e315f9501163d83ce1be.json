{"sha": "d9080addf95679f5b7a9e315f9501163d83ce1be", "node_id": "C_kwDOAAsO6NoAKGQ5MDgwYWRkZjk1Njc5ZjViN2E5ZTMxNWY5NTAxMTYzZDgzY2UxYmU", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-10-17T11:30:49Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-10-17T11:30:49Z"}, "message": "Merge #10562\n\n10562: fix: Fix clippy attribute completions always prefixing inserting `clippy::` r=Veykril a=Veykril\n\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/7144\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>", "tree": {"sha": "90651acc1a68f03192715d4b80981607d7efb652", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/90651acc1a68f03192715d4b80981607d7efb652"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d9080addf95679f5b7a9e315f9501163d83ce1be", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJhbAlpCRBK7hj4Ov3rIwAAEgMIACu2q3A1jWdmNTKwE17UEgaS\nCx3CG22Ef+WNquPFXajvR6G7U1Gokqr48zPFUuwmiMQPf2KWlN7GEkfkFmX/X69/\ny7QMxGyYyZDIHCmwGZru4I9pD9kGIflsnSO9dUrqk4Iv52sDF5RQg2uOMlEwHOQi\nVKvdNw7hOAuFw5ax90o7LMHkub7SBG+M7dUrgDVuUyKXbzsa4D2LVdqsnkX69Qia\n+PIY7PQog1wZqCMBqkp3OodJ5Dt/glJYZsCAz3upp1AihgA2RDy7/vHmSs040QUb\n0H7uThSARGRsQqFNF67YTHYRmQ5F5fV7TzTvYL8uAAtw9mFllez1PVlfPbRDKO8=\n=kEJc\n-----END PGP SIGNATURE-----\n", "payload": "tree 90651acc1a68f03192715d4b80981607d7efb652\nparent c16d04e494fa9424dbe2b6d95ece85188e011039\nparent 99906baa176985fe0f976ed0e2806a93b30532bc\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1634470249 +0000\ncommitter GitHub <noreply@github.com> 1634470249 +0000\n\nMerge #10562\n\n10562: fix: Fix clippy attribute completions always prefixing inserting `clippy::` r=Veykril a=Veykril\n\nFixes https://github.com/rust-analyzer/rust-analyzer/issues/7144\n\nCo-authored-by: Lukas Wirth <lukastw97@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d9080addf95679f5b7a9e315f9501163d83ce1be", "html_url": "https://github.com/rust-lang/rust/commit/d9080addf95679f5b7a9e315f9501163d83ce1be", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d9080addf95679f5b7a9e315f9501163d83ce1be/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c16d04e494fa9424dbe2b6d95ece85188e011039", "url": "https://api.github.com/repos/rust-lang/rust/commits/c16d04e494fa9424dbe2b6d95ece85188e011039", "html_url": "https://github.com/rust-lang/rust/commit/c16d04e494fa9424dbe2b6d95ece85188e011039"}, {"sha": "99906baa176985fe0f976ed0e2806a93b30532bc", "url": "https://api.github.com/repos/rust-lang/rust/commits/99906baa176985fe0f976ed0e2806a93b30532bc", "html_url": "https://github.com/rust-lang/rust/commit/99906baa176985fe0f976ed0e2806a93b30532bc"}], "stats": {"total": 777, "additions": 426, "deletions": 351}, "files": [{"sha": "6abc2a94c415ac371ec5108063feaa2e10c9b350", "filename": "crates/ide_completion/src/completions/attribute.rs", "status": "modified", "additions": 31, "deletions": 23, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -5,9 +5,10 @@\n \n use hir::HasAttrs;\n use ide_db::helpers::generated_lints::{CLIPPY_LINTS, DEFAULT_LINTS, FEATURES};\n+use itertools::Itertools;\n use once_cell::sync::Lazy;\n-use rustc_hash::{FxHashMap, FxHashSet};\n-use syntax::{algo::non_trivia_sibling, ast, AstNode, Direction, NodeOrToken, SyntaxKind, T};\n+use rustc_hash::FxHashMap;\n+use syntax::{algo::non_trivia_sibling, ast, AstNode, Direction, SyntaxKind, T};\n \n use crate::{\n     context::CompletionContext,\n@@ -303,31 +304,38 @@ const ATTRIBUTES: &[AttrCompletion] = &[\n     .prefer_inner(),\n ];\n \n-fn parse_comma_sep_input(derive_input: ast::TokenTree) -> Option<FxHashSet<String>> {\n-    let (l_paren, r_paren) = derive_input.l_paren_token().zip(derive_input.r_paren_token())?;\n-    let mut input_derives = FxHashSet::default();\n-    let mut tokens = derive_input\n+fn parse_comma_sep_paths(input: ast::TokenTree) -> Option<Vec<ast::Path>> {\n+    let r_paren = input.r_paren_token()?;\n+    let tokens = input\n         .syntax()\n         .children_with_tokens()\n-        .filter_map(NodeOrToken::into_token)\n-        .skip_while(|token| token != &l_paren)\n         .skip(1)\n-        .take_while(|token| token != &r_paren)\n-        .peekable();\n-    let mut input = String::new();\n-    while tokens.peek().is_some() {\n-        for token in tokens.by_ref().take_while(|t| t.kind() != T![,]) {\n-            input.push_str(token.text());\n-        }\n-\n-        if !input.is_empty() {\n-            input_derives.insert(input.trim().to_owned());\n-        }\n-\n-        input.clear();\n-    }\n+        .take_while(|it| it.as_token() != Some(&r_paren));\n+    let input_expressions = tokens.into_iter().group_by(|tok| tok.kind() == T![,]);\n+    Some(\n+        input_expressions\n+            .into_iter()\n+            .filter_map(|(is_sep, group)| (!is_sep).then(|| group))\n+            .filter_map(|mut tokens| ast::Path::parse(&tokens.join(\"\")).ok())\n+            .collect::<Vec<ast::Path>>(),\n+    )\n+}\n \n-    Some(input_derives)\n+fn parse_comma_sep_expr(input: ast::TokenTree) -> Option<Vec<ast::Expr>> {\n+    let r_paren = input.r_paren_token()?;\n+    let tokens = input\n+        .syntax()\n+        .children_with_tokens()\n+        .skip(1)\n+        .take_while(|it| it.as_token() != Some(&r_paren));\n+    let input_expressions = tokens.into_iter().group_by(|tok| tok.kind() == T![,]);\n+    Some(\n+        input_expressions\n+            .into_iter()\n+            .filter_map(|(is_sep, group)| (!is_sep).then(|| group))\n+            .filter_map(|mut tokens| ast::Expr::parse(&tokens.join(\"\")).ok())\n+            .collect::<Vec<ast::Expr>>(),\n+    )\n }\n \n #[test]"}, {"sha": "36758baafc027354d1cfe35fb9a2a0f0fdd88000", "filename": "crates/ide_completion/src/completions/attribute/derive.rs", "status": "modified", "additions": 18, "deletions": 13, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Fderive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Fderive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Fderive.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -2,7 +2,7 @@\n use hir::HasAttrs;\n use itertools::Itertools;\n use rustc_hash::FxHashMap;\n-use syntax::ast;\n+use syntax::{ast, SmolStr};\n \n use crate::{\n     context::CompletionContext,\n@@ -15,26 +15,31 @@ pub(super) fn complete_derive(\n     ctx: &CompletionContext,\n     derive_input: ast::TokenTree,\n ) {\n-    if let Some(existing_derives) = super::parse_comma_sep_input(derive_input) {\n+    if let Some(existing_derives) = super::parse_comma_sep_paths(derive_input) {\n         for (derive, docs) in get_derive_names_in_scope(ctx) {\n+            let label;\n             let (label, lookup) = if let Some(derive_completion) = DEFAULT_DERIVE_COMPLETIONS\n                 .iter()\n                 .find(|derive_completion| derive_completion.label == derive)\n             {\n                 let mut components = vec![derive_completion.label];\n-                components.extend(\n-                    derive_completion\n-                        .dependencies\n+                components.extend(derive_completion.dependencies.iter().filter(|&&dependency| {\n+                    !existing_derives\n                         .iter()\n-                        .filter(|&&dependency| !existing_derives.contains(dependency)),\n-                );\n+                        .filter_map(|it| it.as_single_name_ref())\n+                        .any(|it| it.text() == dependency)\n+                }));\n                 let lookup = components.join(\", \");\n-                let label = components.iter().rev().join(\", \");\n-                (label, Some(lookup))\n-            } else if existing_derives.contains(&derive) {\n+                label = components.iter().rev().join(\", \");\n+                (&*label, Some(lookup))\n+            } else if existing_derives\n+                .iter()\n+                .filter_map(|it| it.as_single_name_ref())\n+                .any(|it| it.text().as_str() == derive)\n+            {\n                 continue;\n             } else {\n-                (derive, None)\n+                (&*derive, None)\n             };\n             let mut item =\n                 CompletionItem::new(CompletionKind::Attribute, ctx.source_range(), label);\n@@ -52,12 +57,12 @@ pub(super) fn complete_derive(\n \n fn get_derive_names_in_scope(\n     ctx: &CompletionContext,\n-) -> FxHashMap<String, Option<hir::Documentation>> {\n+) -> FxHashMap<SmolStr, Option<hir::Documentation>> {\n     let mut result = FxHashMap::default();\n     ctx.process_all_names(&mut |name, scope_def| {\n         if let hir::ScopeDef::MacroDef(mac) = scope_def {\n             if mac.kind() == hir::MacroKind::Derive {\n-                result.insert(name.to_string(), mac.docs(ctx.db));\n+                result.insert(name.to_smol_str(), mac.docs(ctx.db));\n             }\n         }\n     });"}, {"sha": "4f7930d0dd9da827aa541d08a3017377e910e830", "filename": "crates/ide_completion/src/completions/attribute/lint.rs", "status": "modified", "additions": 45, "deletions": 11, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Flint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Flint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Flint.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -1,6 +1,6 @@\n //! Completion for lints\n use ide_db::helpers::generated_lints::Lint;\n-use syntax::ast;\n+use syntax::{ast, T};\n \n use crate::{\n     context::CompletionContext,\n@@ -14,17 +14,51 @@ pub(super) fn complete_lint(\n     derive_input: ast::TokenTree,\n     lints_completions: &[Lint],\n ) {\n-    if let Some(existing_lints) = super::parse_comma_sep_input(derive_input) {\n-        for lint_completion in\n-            lints_completions.iter().filter(|completion| !existing_lints.contains(completion.label))\n-        {\n-            let mut item = CompletionItem::new(\n-                CompletionKind::Attribute,\n-                ctx.source_range(),\n-                lint_completion.label,\n-            );\n+    if let Some(existing_lints) = super::parse_comma_sep_paths(derive_input) {\n+        for &Lint { label, description } in lints_completions {\n+            let (qual, name) = {\n+                // FIXME: change `Lint`'s label to not store a path in it but split the prefix off instead?\n+                let mut parts = label.split(\"::\");\n+                let ns_or_label = match parts.next() {\n+                    Some(it) => it,\n+                    None => continue,\n+                };\n+                let label = parts.next();\n+                match label {\n+                    Some(label) => (Some(ns_or_label), label),\n+                    None => (None, ns_or_label),\n+                }\n+            };\n+            let lint_already_annotated = existing_lints\n+                .iter()\n+                .filter_map(|path| {\n+                    let q = path.qualifier();\n+                    if q.as_ref().and_then(|it| it.qualifier()).is_some() {\n+                        return None;\n+                    }\n+                    Some((q.and_then(|it| it.as_single_name_ref()), path.segment()?.name_ref()?))\n+                })\n+                .any(|(q, name_ref)| {\n+                    let qualifier_matches = match (q, qual) {\n+                        (None, None) => true,\n+                        (None, Some(_)) => false,\n+                        (Some(_), None) => false,\n+                        (Some(q), Some(ns)) => q.text() == ns,\n+                    };\n+                    qualifier_matches && name_ref.text() == name\n+                });\n+            if lint_already_annotated {\n+                continue;\n+            }\n+            let insert = match qual {\n+                Some(qual) if !ctx.previous_token_is(T![:]) => format!(\"{}::{}\", qual, name),\n+                _ => name.to_owned(),\n+            };\n+            let mut item =\n+                CompletionItem::new(CompletionKind::Attribute, ctx.source_range(), label);\n             item.kind(CompletionItemKind::Attribute)\n-                .documentation(hir::Documentation::new(lint_completion.description.to_owned()));\n+                .insert_text(insert)\n+                .documentation(hir::Documentation::new(description.to_owned()));\n             item.add_to(acc)\n         }\n     }"}, {"sha": "9a12b8571c73595cd50841d795691bfdb14706fa", "filename": "crates/ide_completion/src/completions/attribute/repr.rs", "status": "modified", "additions": 22, "deletions": 17, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Frepr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Frepr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcompletions%2Fattribute%2Frepr.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -8,29 +8,34 @@ use crate::{\n     Completions,\n };\n \n-pub(super) fn complete_repr(\n-    acc: &mut Completions,\n-    ctx: &CompletionContext,\n-    derive_input: ast::TokenTree,\n-) {\n-    if let Some(existing_reprs) = super::parse_comma_sep_input(derive_input) {\n-        for repr_completion in REPR_COMPLETIONS {\n-            if existing_reprs\n+pub(super) fn complete_repr(acc: &mut Completions, ctx: &CompletionContext, input: ast::TokenTree) {\n+    if let Some(existing_reprs) = super::parse_comma_sep_expr(input) {\n+        for &ReprCompletion { label, snippet, lookup, collides } in REPR_COMPLETIONS {\n+            let repr_already_annotated = existing_reprs\n                 .iter()\n-                .any(|it| repr_completion.label == it || repr_completion.collides.contains(&&**it))\n-            {\n+                .filter_map(|expr| match expr {\n+                    ast::Expr::PathExpr(path) => path.path()?.as_single_name_ref(),\n+                    ast::Expr::CallExpr(call) => match call.expr()? {\n+                        ast::Expr::PathExpr(path) => path.path()?.as_single_name_ref(),\n+                        _ => return None,\n+                    },\n+                    _ => None,\n+                })\n+                .any(|it| {\n+                    let text = it.text();\n+                    lookup.unwrap_or(label) == text || collides.contains(&text.as_str())\n+                });\n+            if repr_already_annotated {\n                 continue;\n             }\n-            let mut item = CompletionItem::new(\n-                CompletionKind::Attribute,\n-                ctx.source_range(),\n-                repr_completion.label,\n-            );\n+\n+            let mut item =\n+                CompletionItem::new(CompletionKind::Attribute, ctx.source_range(), label);\n             item.kind(CompletionItemKind::Attribute);\n-            if let Some(lookup) = repr_completion.lookup {\n+            if let Some(lookup) = lookup {\n                 item.lookup_by(lookup);\n             }\n-            if let Some((snippet, cap)) = repr_completion.snippet.zip(ctx.config.snippet_cap) {\n+            if let Some((snippet, cap)) = snippet.zip(ctx.config.snippet_cap) {\n                 item.insert_snippet(cap, snippet);\n             }\n             item.add_to(acc);"}, {"sha": "4e3abff3b3f86223dd54278b9217c9286aedd9fa", "filename": "crates/ide_completion/src/context.rs", "status": "modified", "additions": 290, "deletions": 286, "changes": 576, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Fcontext.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -120,153 +120,6 @@ pub(crate) struct CompletionContext<'a> {\n }\n \n impl<'a> CompletionContext<'a> {\n-    pub(super) fn new(\n-        db: &'a RootDatabase,\n-        position: FilePosition,\n-        config: &'a CompletionConfig,\n-    ) -> Option<CompletionContext<'a>> {\n-        let sema = Semantics::new(db);\n-\n-        let original_file = sema.parse(position.file_id);\n-\n-        // Insert a fake ident to get a valid parse tree. We will use this file\n-        // to determine context, though the original_file will be used for\n-        // actual completion.\n-        let file_with_fake_ident = {\n-            let parse = db.parse(position.file_id);\n-            let edit = Indel::insert(position.offset, \"intellijRulezz\".to_string());\n-            parse.reparse(&edit).tree()\n-        };\n-        let fake_ident_token =\n-            file_with_fake_ident.syntax().token_at_offset(position.offset).right_biased().unwrap();\n-\n-        let original_token =\n-            original_file.syntax().token_at_offset(position.offset).left_biased()?;\n-        let token = sema.descend_into_macros_single(original_token.clone());\n-        let scope = sema.scope_at_offset(&token, position.offset);\n-        let krate = scope.krate();\n-        let mut locals = vec![];\n-        scope.process_all_names(&mut |name, scope| {\n-            if let ScopeDef::Local(local) = scope {\n-                locals.push((name, local));\n-            }\n-        });\n-        let mut ctx = CompletionContext {\n-            sema,\n-            scope,\n-            db,\n-            config,\n-            position,\n-            original_token,\n-            token,\n-            krate,\n-            expected_name: None,\n-            expected_type: None,\n-            function_def: None,\n-            impl_def: None,\n-            name_syntax: None,\n-            lifetime_ctx: None,\n-            pattern_ctx: None,\n-            completion_location: None,\n-            prev_sibling: None,\n-            attribute_under_caret: None,\n-            previous_token: None,\n-            path_context: None,\n-            locals,\n-            incomplete_let: false,\n-            no_completion_required: false,\n-        };\n-        ctx.expand_and_fill(\n-            original_file.syntax().clone(),\n-            file_with_fake_ident.syntax().clone(),\n-            position.offset,\n-            fake_ident_token,\n-        );\n-        Some(ctx)\n-    }\n-\n-    /// Do the attribute expansion at the current cursor position for both original file and fake file\n-    /// as long as possible. As soon as one of the two expansions fail we stop to stay in sync.\n-    fn expand_and_fill(\n-        &mut self,\n-        mut original_file: SyntaxNode,\n-        mut speculative_file: SyntaxNode,\n-        mut offset: TextSize,\n-        mut fake_ident_token: SyntaxToken,\n-    ) {\n-        loop {\n-            // Expand attributes\n-            if let (Some(actual_item), Some(item_with_fake_ident)) = (\n-                find_node_at_offset::<ast::Item>(&original_file, offset),\n-                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n-            ) {\n-                match (\n-                    self.sema.expand_attr_macro(&actual_item),\n-                    self.sema.speculative_expand_attr_macro(\n-                        &actual_item,\n-                        &item_with_fake_ident,\n-                        fake_ident_token.clone(),\n-                    ),\n-                ) {\n-                    (Some(actual_expansion), Some(speculative_expansion)) => {\n-                        let new_offset = speculative_expansion.1.text_range().start();\n-                        if new_offset > actual_expansion.text_range().end() {\n-                            break;\n-                        }\n-                        original_file = actual_expansion;\n-                        speculative_file = speculative_expansion.0;\n-                        fake_ident_token = speculative_expansion.1;\n-                        offset = new_offset;\n-                        continue;\n-                    }\n-                    (None, None) => (),\n-                    _ => break,\n-                }\n-            }\n-\n-            // Expand fn-like macro calls\n-            if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n-                find_node_at_offset::<ast::MacroCall>(&original_file, offset),\n-                find_node_at_offset::<ast::MacroCall>(&speculative_file, offset),\n-            ) {\n-                let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n-                let mac_call_path1 =\n-                    macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n-                if mac_call_path0 != mac_call_path1 {\n-                    break;\n-                }\n-                let speculative_args = match macro_call_with_fake_ident.token_tree() {\n-                    Some(tt) => tt,\n-                    None => break,\n-                };\n-\n-                if let (Some(actual_expansion), Some(speculative_expansion)) = (\n-                    self.sema.expand(&actual_macro_call),\n-                    self.sema.speculative_expand(\n-                        &actual_macro_call,\n-                        &speculative_args,\n-                        fake_ident_token,\n-                    ),\n-                ) {\n-                    let new_offset = speculative_expansion.1.text_range().start();\n-                    if new_offset > actual_expansion.text_range().end() {\n-                        break;\n-                    }\n-                    original_file = actual_expansion;\n-                    speculative_file = speculative_expansion.0;\n-                    fake_ident_token = speculative_expansion.1;\n-                    offset = new_offset;\n-                } else {\n-                    break;\n-                }\n-            } else {\n-                break;\n-            }\n-        }\n-\n-        self.fill(&original_file, speculative_file, offset);\n-    }\n-\n     /// Checks whether completions in that particular case don't make much sense.\n     /// Examples:\n     /// - `fn $0` -- we expect function name, it's unlikely that \"hint\" will be helpful.\n@@ -491,6 +344,156 @@ impl<'a> CompletionContext<'a> {\n \n         false\n     }\n+}\n+\n+// CompletionContext construction\n+impl<'a> CompletionContext<'a> {\n+    pub(super) fn new(\n+        db: &'a RootDatabase,\n+        position: FilePosition,\n+        config: &'a CompletionConfig,\n+    ) -> Option<CompletionContext<'a>> {\n+        let sema = Semantics::new(db);\n+\n+        let original_file = sema.parse(position.file_id);\n+\n+        // Insert a fake ident to get a valid parse tree. We will use this file\n+        // to determine context, though the original_file will be used for\n+        // actual completion.\n+        let file_with_fake_ident = {\n+            let parse = db.parse(position.file_id);\n+            let edit = Indel::insert(position.offset, \"intellijRulezz\".to_string());\n+            parse.reparse(&edit).tree()\n+        };\n+        let fake_ident_token =\n+            file_with_fake_ident.syntax().token_at_offset(position.offset).right_biased().unwrap();\n+\n+        let original_token =\n+            original_file.syntax().token_at_offset(position.offset).left_biased()?;\n+        let token = sema.descend_into_macros_single(original_token.clone());\n+        let scope = sema.scope_at_offset(&token, position.offset);\n+        let krate = scope.krate();\n+        let mut locals = vec![];\n+        scope.process_all_names(&mut |name, scope| {\n+            if let ScopeDef::Local(local) = scope {\n+                locals.push((name, local));\n+            }\n+        });\n+        let mut ctx = CompletionContext {\n+            sema,\n+            scope,\n+            db,\n+            config,\n+            position,\n+            original_token,\n+            token,\n+            krate,\n+            expected_name: None,\n+            expected_type: None,\n+            function_def: None,\n+            impl_def: None,\n+            name_syntax: None,\n+            lifetime_ctx: None,\n+            pattern_ctx: None,\n+            completion_location: None,\n+            prev_sibling: None,\n+            attribute_under_caret: None,\n+            previous_token: None,\n+            path_context: None,\n+            locals,\n+            incomplete_let: false,\n+            no_completion_required: false,\n+        };\n+        ctx.expand_and_fill(\n+            original_file.syntax().clone(),\n+            file_with_fake_ident.syntax().clone(),\n+            position.offset,\n+            fake_ident_token,\n+        );\n+        Some(ctx)\n+    }\n+\n+    /// Do the attribute expansion at the current cursor position for both original file and fake file\n+    /// as long as possible. As soon as one of the two expansions fail we stop to stay in sync.\n+    fn expand_and_fill(\n+        &mut self,\n+        mut original_file: SyntaxNode,\n+        mut speculative_file: SyntaxNode,\n+        mut offset: TextSize,\n+        mut fake_ident_token: SyntaxToken,\n+    ) {\n+        loop {\n+            // Expand attributes\n+            if let (Some(actual_item), Some(item_with_fake_ident)) = (\n+                find_node_at_offset::<ast::Item>(&original_file, offset),\n+                find_node_at_offset::<ast::Item>(&speculative_file, offset),\n+            ) {\n+                match (\n+                    self.sema.expand_attr_macro(&actual_item),\n+                    self.sema.speculative_expand_attr_macro(\n+                        &actual_item,\n+                        &item_with_fake_ident,\n+                        fake_ident_token.clone(),\n+                    ),\n+                ) {\n+                    (Some(actual_expansion), Some(speculative_expansion)) => {\n+                        let new_offset = speculative_expansion.1.text_range().start();\n+                        if new_offset > actual_expansion.text_range().end() {\n+                            break;\n+                        }\n+                        original_file = actual_expansion;\n+                        speculative_file = speculative_expansion.0;\n+                        fake_ident_token = speculative_expansion.1;\n+                        offset = new_offset;\n+                        continue;\n+                    }\n+                    (None, None) => (),\n+                    _ => break,\n+                }\n+            }\n+\n+            // Expand fn-like macro calls\n+            if let (Some(actual_macro_call), Some(macro_call_with_fake_ident)) = (\n+                find_node_at_offset::<ast::MacroCall>(&original_file, offset),\n+                find_node_at_offset::<ast::MacroCall>(&speculative_file, offset),\n+            ) {\n+                let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());\n+                let mac_call_path1 =\n+                    macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());\n+                if mac_call_path0 != mac_call_path1 {\n+                    break;\n+                }\n+                let speculative_args = match macro_call_with_fake_ident.token_tree() {\n+                    Some(tt) => tt,\n+                    None => break,\n+                };\n+\n+                if let (Some(actual_expansion), Some(speculative_expansion)) = (\n+                    self.sema.expand(&actual_macro_call),\n+                    self.sema.speculative_expand(\n+                        &actual_macro_call,\n+                        &speculative_args,\n+                        fake_ident_token,\n+                    ),\n+                ) {\n+                    let new_offset = speculative_expansion.1.text_range().start();\n+                    if new_offset > actual_expansion.text_range().end() {\n+                        break;\n+                    }\n+                    original_file = actual_expansion;\n+                    speculative_file = speculative_expansion.0;\n+                    fake_ident_token = speculative_expansion.1;\n+                    offset = new_offset;\n+                } else {\n+                    break;\n+                }\n+            } else {\n+                break;\n+            }\n+        }\n+\n+        self.fill(&original_file, speculative_file, offset);\n+    }\n \n     fn expected_type_and_name(&self) -> (Option<Type>, Option<NameOrNameRef>) {\n         let mut node = match self.token.parent() {\n@@ -658,170 +661,171 @@ impl<'a> CompletionContext<'a> {\n             .find_map(ast::Fn::cast);\n         match name_like {\n             ast::NameLike::Lifetime(lifetime) => {\n-                self.classify_lifetime(original_file, lifetime, offset);\n+                self.lifetime_ctx =\n+                    Self::classify_lifetime(&self.sema, original_file, lifetime, offset);\n             }\n             ast::NameLike::NameRef(name_ref) => {\n-                self.classify_name_ref(original_file, name_ref);\n+                self.path_context = Self::classify_name_ref(&self.sema, original_file, name_ref);\n             }\n             ast::NameLike::Name(name) => {\n-                self.classify_name(name);\n+                self.pattern_ctx = Self::classify_name(&self.sema, name);\n             }\n         }\n     }\n \n     fn classify_lifetime(\n-        &mut self,\n+        sema: &Semantics<RootDatabase>,\n         original_file: &SyntaxNode,\n         lifetime: ast::Lifetime,\n         offset: TextSize,\n-    ) {\n-        if let Some(parent) = lifetime.syntax().parent() {\n-            if parent.kind() == ERROR {\n-                return;\n+    ) -> Option<LifetimeContext> {\n+        let parent = lifetime.syntax().parent()?;\n+        if parent.kind() == ERROR {\n+            return None;\n+        }\n+\n+        Some(match_ast! {\n+            match parent {\n+                ast::LifetimeParam(_it) => LifetimeContext::LifetimeParam(sema.find_node_at_offset_with_macros(original_file, offset)),\n+                ast::BreakExpr(_it) => LifetimeContext::LabelRef,\n+                ast::ContinueExpr(_it) => LifetimeContext::LabelRef,\n+                ast::Label(_it) => LifetimeContext::LabelDef,\n+                _ => LifetimeContext::Lifetime,\n             }\n+        })\n+    }\n \n-            self.lifetime_ctx = Some(match_ast! {\n-                match parent {\n-                    ast::LifetimeParam(_it) => LifetimeContext::LifetimeParam(self.sema.find_node_at_offset_with_macros(original_file, offset)),\n-                    ast::BreakExpr(_it) => LifetimeContext::LabelRef,\n-                    ast::ContinueExpr(_it) => LifetimeContext::LabelRef,\n-                    ast::Label(_it) => LifetimeContext::LabelDef,\n-                    _ => LifetimeContext::Lifetime,\n+    fn classify_name(_sema: &Semantics<RootDatabase>, name: ast::Name) -> Option<PatternContext> {\n+        let bind_pat = name.syntax().parent().and_then(ast::IdentPat::cast)?;\n+        let is_name_in_field_pat = bind_pat\n+            .syntax()\n+            .parent()\n+            .and_then(ast::RecordPatField::cast)\n+            .map_or(false, |pat_field| pat_field.name_ref().is_none());\n+        if is_name_in_field_pat {\n+            return None;\n+        }\n+        if !bind_pat.is_simple_ident() {\n+            return None;\n+        }\n+        let mut is_param = None;\n+        let refutability = bind_pat\n+            .syntax()\n+            .ancestors()\n+            .skip_while(|it| ast::Pat::can_cast(it.kind()))\n+            .next()\n+            .map_or(PatternRefutability::Irrefutable, |node| {\n+                match_ast! {\n+                    match node {\n+                        ast::LetStmt(__) => PatternRefutability::Irrefutable,\n+                        ast::Param(param) => {\n+                            let is_closure_param = param\n+                                .syntax()\n+                                .ancestors()\n+                                .nth(2)\n+                                .and_then(ast::ClosureExpr::cast)\n+                                .is_some();\n+                            is_param = Some(if is_closure_param {\n+                                ParamKind::Closure\n+                            } else {\n+                                ParamKind::Function\n+                            });\n+                            PatternRefutability::Irrefutable\n+                        },\n+                        ast::MatchArm(__) => PatternRefutability::Refutable,\n+                        ast::Condition(__) => PatternRefutability::Refutable,\n+                        ast::ForExpr(__) => PatternRefutability::Irrefutable,\n+                        _ => PatternRefutability::Irrefutable,\n+                    }\n                 }\n             });\n-        }\n+        Some(PatternContext { refutability, is_param })\n     }\n \n-    fn classify_name(&mut self, name: ast::Name) {\n-        if let Some(bind_pat) = name.syntax().parent().and_then(ast::IdentPat::cast) {\n-            let is_name_in_field_pat = bind_pat\n-                .syntax()\n-                .parent()\n-                .and_then(ast::RecordPatField::cast)\n-                .map_or(false, |pat_field| pat_field.name_ref().is_none());\n-            if is_name_in_field_pat {\n-                return;\n-            }\n-            if bind_pat.is_simple_ident() {\n-                let mut is_param = None;\n-                let refutability = bind_pat\n-                    .syntax()\n-                    .ancestors()\n-                    .skip_while(|it| ast::Pat::can_cast(it.kind()))\n-                    .next()\n-                    .map_or(PatternRefutability::Irrefutable, |node| {\n-                        match_ast! {\n-                            match node {\n-                                ast::LetStmt(__) => PatternRefutability::Irrefutable,\n-                                ast::Param(param) => {\n-                                    let is_closure_param = param\n-                                        .syntax()\n-                                        .ancestors()\n-                                        .nth(2)\n-                                        .and_then(ast::ClosureExpr::cast)\n-                                        .is_some();\n-                                    is_param = Some(if is_closure_param {\n-                                        ParamKind::Closure\n-                                    } else {\n-                                        ParamKind::Function\n-                                    });\n-                                    PatternRefutability::Irrefutable\n-                                },\n-                                ast::MatchArm(__) => PatternRefutability::Refutable,\n-                                ast::Condition(__) => PatternRefutability::Refutable,\n-                                ast::ForExpr(__) => PatternRefutability::Irrefutable,\n-                                _ => PatternRefutability::Irrefutable,\n-                            }\n-                        }\n-                    });\n-                self.pattern_ctx = Some(PatternContext { refutability, is_param });\n-            }\n+    fn classify_name_ref(\n+        _sema: &Semantics<RootDatabase>,\n+        original_file: &SyntaxNode,\n+        name_ref: ast::NameRef,\n+    ) -> Option<PathCompletionContext> {\n+        let parent = name_ref.syntax().parent()?;\n+        let segment = ast::PathSegment::cast(parent)?;\n+\n+        let mut path_ctx = PathCompletionContext {\n+            call_kind: None,\n+            is_trivial_path: false,\n+            qualifier: None,\n+            has_type_args: false,\n+            can_be_stmt: false,\n+            in_loop_body: false,\n+            use_tree_parent: false,\n+            kind: None,\n+        };\n+        path_ctx.in_loop_body = is_in_loop_body(name_ref.syntax());\n+        let path = segment.parent_path();\n+\n+        if let Some(p) = path.syntax().parent() {\n+            path_ctx.call_kind = match_ast! {\n+                match p {\n+                    ast::PathExpr(it) => it.syntax().parent().and_then(ast::CallExpr::cast).map(|_| CallKind::Expr),\n+                    ast::MacroCall(it) => it.excl_token().and(Some(CallKind::Mac)),\n+                    ast::TupleStructPat(_it) => Some(CallKind::Pat),\n+                    _ => None\n+                }\n+            };\n         }\n-    }\n \n-    fn classify_name_ref(&mut self, original_file: &SyntaxNode, name_ref: ast::NameRef) {\n-        let parent = match name_ref.syntax().parent() {\n-            Some(it) => it,\n-            None => return,\n-        };\n+        if let Some(parent) = path.syntax().parent() {\n+            path_ctx.kind = match_ast! {\n+                match parent {\n+                    ast::PathType(_it) => Some(PathKind::Type),\n+                    ast::PathExpr(_it) => Some(PathKind::Expr),\n+                    _ => None,\n+                }\n+            };\n+        }\n+        path_ctx.has_type_args = segment.generic_arg_list().is_some();\n+\n+        if let Some((path, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n+            path_ctx.use_tree_parent = use_tree_parent;\n+            path_ctx.qualifier = path\n+                .segment()\n+                .and_then(|it| {\n+                    find_node_with_range::<ast::PathSegment>(\n+                        original_file,\n+                        it.syntax().text_range(),\n+                    )\n+                })\n+                .map(|it| it.parent_path());\n+            return Some(path_ctx);\n+        }\n \n-        if let Some(segment) = ast::PathSegment::cast(parent) {\n-            let path_ctx = self.path_context.get_or_insert(PathCompletionContext {\n-                call_kind: None,\n-                is_trivial_path: false,\n-                qualifier: None,\n-                has_type_args: false,\n-                can_be_stmt: false,\n-                in_loop_body: false,\n-                use_tree_parent: false,\n-                kind: None,\n-            });\n-            path_ctx.in_loop_body = is_in_loop_body(name_ref.syntax());\n-            let path = segment.parent_path();\n-\n-            if let Some(p) = path.syntax().parent() {\n-                path_ctx.call_kind = match_ast! {\n-                    match p {\n-                        ast::PathExpr(it) => it.syntax().parent().and_then(ast::CallExpr::cast).map(|_| CallKind::Expr),\n-                        ast::MacroCall(it) => it.excl_token().and(Some(CallKind::Mac)),\n-                        ast::TupleStructPat(_it) => Some(CallKind::Pat),\n-                        _ => None\n-                    }\n-                };\n+        if let Some(segment) = path.segment() {\n+            if segment.coloncolon_token().is_some() {\n+                return Some(path_ctx);\n             }\n+        }\n \n-            if let Some(parent) = path.syntax().parent() {\n-                path_ctx.kind = match_ast! {\n-                    match parent {\n-                        ast::PathType(_it) => Some(PathKind::Type),\n-                        ast::PathExpr(_it) => Some(PathKind::Expr),\n-                        _ => None,\n-                    }\n-                };\n-            }\n-            path_ctx.has_type_args = segment.generic_arg_list().is_some();\n-\n-            if let Some((path, use_tree_parent)) = path_or_use_tree_qualifier(&path) {\n-                path_ctx.use_tree_parent = use_tree_parent;\n-                path_ctx.qualifier = path\n-                    .segment()\n-                    .and_then(|it| {\n-                        find_node_with_range::<ast::PathSegment>(\n-                            original_file,\n-                            it.syntax().text_range(),\n-                        )\n-                    })\n-                    .map(|it| it.parent_path());\n-                return;\n-            }\n+        path_ctx.is_trivial_path = true;\n \n-            if let Some(segment) = path.segment() {\n-                if segment.coloncolon_token().is_some() {\n-                    return;\n+        // Find either enclosing expr statement (thing with `;`) or a\n+        // block. If block, check that we are the last expr.\n+        path_ctx.can_be_stmt = name_ref\n+            .syntax()\n+            .ancestors()\n+            .find_map(|node| {\n+                if let Some(stmt) = ast::ExprStmt::cast(node.clone()) {\n+                    return Some(stmt.syntax().text_range() == name_ref.syntax().text_range());\n                 }\n-            }\n-\n-            path_ctx.is_trivial_path = true;\n-\n-            // Find either enclosing expr statement (thing with `;`) or a\n-            // block. If block, check that we are the last expr.\n-            path_ctx.can_be_stmt = name_ref\n-                .syntax()\n-                .ancestors()\n-                .find_map(|node| {\n-                    if let Some(stmt) = ast::ExprStmt::cast(node.clone()) {\n-                        return Some(stmt.syntax().text_range() == name_ref.syntax().text_range());\n-                    }\n-                    if let Some(stmt_list) = ast::StmtList::cast(node) {\n-                        return Some(\n-                            stmt_list.tail_expr().map(|e| e.syntax().text_range())\n-                                == Some(name_ref.syntax().text_range()),\n-                        );\n-                    }\n-                    None\n-                })\n-                .unwrap_or(false);\n-        }\n+                if let Some(stmt_list) = ast::StmtList::cast(node) {\n+                    return Some(\n+                        stmt_list.tail_expr().map(|e| e.syntax().text_range())\n+                            == Some(name_ref.syntax().text_range()),\n+                    );\n+                }\n+                None\n+            })\n+            .unwrap_or(false);\n+        Some(path_ctx)\n     }\n }\n "}, {"sha": "9d22bb196bd664ae773aefd29caf63dc1f828540", "filename": "crates/ide_completion/src/tests/attribute.rs", "status": "modified", "additions": 18, "deletions": 1, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Ftests%2Fattribute.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Fide_completion%2Fsrc%2Ftests%2Fattribute.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide_completion%2Fsrc%2Ftests%2Fattribute.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -692,6 +692,24 @@ mod lint {\n             r#\"#[feature(box_syntax)] struct Test;\"#,\n         )\n     }\n+\n+    #[test]\n+    fn lint_clippy_unqualified() {\n+        check_edit(\n+            \"clippy::as_conversions\",\n+            r#\"#[allow($0)] struct Test;\"#,\n+            r#\"#[allow(clippy::as_conversions)] struct Test;\"#,\n+        );\n+    }\n+\n+    #[test]\n+    fn lint_clippy_qualified() {\n+        check_edit(\n+            \"clippy::as_conversions\",\n+            r#\"#[allow(clippy::$0)] struct Test;\"#,\n+            r#\"#[allow(clippy::as_conversions)] struct Test;\"#,\n+        );\n+    }\n }\n \n mod repr {\n@@ -742,7 +760,6 @@ mod repr {\n         check_repr(\n             r#\"#[repr(align(1), $0)] struct Test;\"#,\n             expect![[r#\"\n-            at align($0)\n             at transparent\n             at C\n             at u8"}, {"sha": "9be9f3afeaf1c7e830854d02233aabfe42d6e110", "filename": "crates/rust-analyzer/tests/slow-tests/tidy.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Ftidy.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d9080addf95679f5b7a9e315f9501163d83ce1be/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Ftidy.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Ftests%2Fslow-tests%2Ftidy.rs?ref=d9080addf95679f5b7a9e315f9501163d83ce1be", "patch": "@@ -192,6 +192,8 @@ fn deny_clippy(path: &Path, text: &str) {\n         \"ide_db/src/helpers/generated_lints.rs\",\n         // The tests test clippy lint hovers\n         \"ide/src/hover/tests.rs\",\n+        // The tests test clippy lint completions\n+        \"ide_completion/src/tests/attribute.rs\",\n     ];\n     if ignore.iter().any(|p| path.ends_with(p)) {\n         return;"}]}