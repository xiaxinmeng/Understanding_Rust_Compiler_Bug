{"sha": "349c9eeb355a979c2e51f832d05ce9212f0aeeba", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM0OWM5ZWViMzU1YTk3OWMyZTUxZjgzMmQwNWNlOTIxMmYwYWVlYmE=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2019-01-19T13:21:17Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-01-19T13:21:17Z"}, "message": "Rollup merge of #57486 - nnethercote:simplify-TokenStream-more, r=petrochenkov\n\nSimplify `TokenStream` some more\n\nThese commits simplify `TokenStream`, remove `ThinTokenStream`, and avoid some clones. The end result is simpler code and a slight perf win on some benchmarks.\n\nr? @petrochenkov", "tree": {"sha": "26d22fe0672d754636b44b522130612192a09363", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/26d22fe0672d754636b44b522130612192a09363"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/349c9eeb355a979c2e51f832d05ce9212f0aeeba", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJcQyRNCRBK7hj4Ov3rIwAAdHIIAGoJzk9Cp1M0KjkDyGowH/8A\naL4habJFR0qfSYa/CpsoG1wmdsPBdrZ5V/6SA0LPUMeGfSEWexv1nHayGZhLVEKO\nFCJhiYasbipI5DK3VYK9JkpVkd6qWb84X/wm0waHPhCdG5vduKkJoeS0Y5t7YkS2\nGnN1upMQftTuZwjU3qeI+Q1t2UgdOn16WzwTHr9U53ZnEWFXZ5JZ0TINjLaMzoEd\nqqCPy0X9S6+RhKoUzagll7x/lchuIwoLrZGED99KPsXI/dQGoWEiLvDq8SyPBtMy\nxSbm24dPqADkmLAp3CnvxA6fWhvj2V72xSVTaB2n6+P9pR+jNqxkKYFv6OS2aAg=\n=7IJu\n-----END PGP SIGNATURE-----\n", "payload": "tree 26d22fe0672d754636b44b522130612192a09363\nparent c87144f3caf9a1580e8734d4d1604e723a5bd6e6\nparent 728572440171d8d9c0557c89c3d71cc8d7cf6c2e\nauthor Mazdak Farrokhzad <twingoow@gmail.com> 1547904077 +0100\ncommitter GitHub <noreply@github.com> 1547904077 +0100\n\nRollup merge of #57486 - nnethercote:simplify-TokenStream-more, r=petrochenkov\n\nSimplify `TokenStream` some more\n\nThese commits simplify `TokenStream`, remove `ThinTokenStream`, and avoid some clones. The end result is simpler code and a slight perf win on some benchmarks.\n\nr? @petrochenkov\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/349c9eeb355a979c2e51f832d05ce9212f0aeeba", "html_url": "https://github.com/rust-lang/rust/commit/349c9eeb355a979c2e51f832d05ce9212f0aeeba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/349c9eeb355a979c2e51f832d05ce9212f0aeeba/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c87144f3caf9a1580e8734d4d1604e723a5bd6e6", "url": "https://api.github.com/repos/rust-lang/rust/commits/c87144f3caf9a1580e8734d4d1604e723a5bd6e6", "html_url": "https://github.com/rust-lang/rust/commit/c87144f3caf9a1580e8734d4d1604e723a5bd6e6"}, {"sha": "728572440171d8d9c0557c89c3d71cc8d7cf6c2e", "url": "https://api.github.com/repos/rust-lang/rust/commits/728572440171d8d9c0557c89c3d71cc8d7cf6c2e", "html_url": "https://github.com/rust-lang/rust/commit/728572440171d8d9c0557c89c3d71cc8d7cf6c2e"}], "stats": {"total": 248, "additions": 79, "deletions": 169}, "files": [{"sha": "de567183a3c05b14671f97009f8ed4b679a48c84", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -258,7 +258,7 @@ for tokenstream::TokenTree {\n             tokenstream::TokenTree::Delimited(span, delim, ref tts) => {\n                 span.hash_stable(hcx, hasher);\n                 std_hash::Hash::hash(&delim, hasher);\n-                for sub_tt in tts.stream().trees() {\n+                for sub_tt in tts.trees() {\n                     sub_tt.hash_stable(hcx, hasher);\n                 }\n             }"}, {"sha": "f6c381ff74cc9e42d7db24193bf8a31772d56df8", "filename": "src/librustc_lint/builtin.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibrustc_lint%2Fbuiltin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibrustc_lint%2Fbuiltin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_lint%2Fbuiltin.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -1474,7 +1474,7 @@ impl KeywordIdents {\n                     _ => {},\n                 }\n                 TokenTree::Delimited(_, _, tts) => {\n-                    self.check_tokens(cx, tts.stream())\n+                    self.check_tokens(cx, tts)\n                 },\n             }\n         }"}, {"sha": "bbcaaacbab52337380f17da188adaa78bc520346", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -15,7 +15,7 @@ use rustc_target::spec::abi::Abi;\n use source_map::{dummy_spanned, respan, Spanned};\n use symbol::{keywords, Symbol};\n use syntax_pos::{Span, DUMMY_SP};\n-use tokenstream::{ThinTokenStream, TokenStream};\n+use tokenstream::TokenStream;\n use ThinVec;\n \n use rustc_data_structures::fx::FxHashSet;\n@@ -1216,7 +1216,7 @@ pub type Mac = Spanned<Mac_>;\n pub struct Mac_ {\n     pub path: Path,\n     pub delim: MacDelimiter,\n-    pub tts: ThinTokenStream,\n+    pub tts: TokenStream,\n }\n \n #[derive(Copy, Clone, PartialEq, Eq, RustcEncodable, RustcDecodable, Debug)]\n@@ -1228,13 +1228,13 @@ pub enum MacDelimiter {\n \n impl Mac_ {\n     pub fn stream(&self) -> TokenStream {\n-        self.tts.stream()\n+        self.tts.clone()\n     }\n }\n \n #[derive(Clone, RustcEncodable, RustcDecodable, Debug)]\n pub struct MacroDef {\n-    pub tokens: ThinTokenStream,\n+    pub tokens: TokenStream,\n     pub legacy: bool,\n }\n "}, {"sha": "f6d7590a7945e8ac06446be882e6a63665cc9999", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -570,7 +570,7 @@ impl MetaItemKind {\n             }\n             Some(TokenTree::Delimited(_, delim, ref tts)) if delim == token::Paren => {\n                 tokens.next();\n-                tts.stream()\n+                tts.clone()\n             }\n             _ => return Some(MetaItemKind::Word),\n         };"}, {"sha": "c01e7f538b90d209bda9ae208c1c849e2795eec2", "filename": "src/libsyntax/ext/quote.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fext%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fext%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fquote.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -748,7 +748,7 @@ fn statements_mk_tt(cx: &ExtCtxt, tt: &TokenTree, quoted: bool) -> Vec<ast::Stmt\n         },\n         TokenTree::Delimited(span, delim, ref tts) => {\n             let mut stmts = statements_mk_tt(cx, &TokenTree::open_tt(span.open, delim), false);\n-            stmts.extend(statements_mk_tts(cx, tts.stream()));\n+            stmts.extend(statements_mk_tts(cx, tts.clone()));\n             stmts.extend(statements_mk_tt(cx, &TokenTree::close_tt(span.close, delim), false));\n             stmts\n         }"}, {"sha": "a4c3b38f691edd635c640a7ea57c3bde4e968fe7", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -598,7 +598,7 @@ pub fn noop_fold_tt<T: Folder>(tt: TokenTree, fld: &mut T) -> TokenTree {\n         TokenTree::Delimited(span, delim, tts) => TokenTree::Delimited(\n             DelimSpan::from_pair(fld.new_span(span.open), fld.new_span(span.close)),\n             delim,\n-            fld.fold_tts(tts.stream()).into(),\n+            fld.fold_tts(tts).into(),\n         ),\n     }\n }"}, {"sha": "ddb350faa546bf65022de7698b469590cc0291a8", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -817,7 +817,7 @@ mod tests {\n                 )\n                 if name_macro_rules.name == \"macro_rules\"\n                 && name_zip.name == \"zip\" => {\n-                    let tts = &macro_tts.stream().trees().collect::<Vec<_>>();\n+                    let tts = &macro_tts.trees().collect::<Vec<_>>();\n                     match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n                         (\n                             3,\n@@ -826,7 +826,7 @@ mod tests {\n                             Some(&TokenTree::Delimited(_, second_delim, ref second_tts)),\n                         )\n                         if macro_delim == token::Paren => {\n-                            let tts = &first_tts.stream().trees().collect::<Vec<_>>();\n+                            let tts = &first_tts.trees().collect::<Vec<_>>();\n                             match (tts.len(), tts.get(0), tts.get(1)) {\n                                 (\n                                     2,\n@@ -836,7 +836,7 @@ mod tests {\n                                 if first_delim == token::Paren && ident.name == \"a\" => {},\n                                 _ => panic!(\"value 3: {:?} {:?}\", first_delim, first_tts),\n                             }\n-                            let tts = &second_tts.stream().trees().collect::<Vec<_>>();\n+                            let tts = &second_tts.trees().collect::<Vec<_>>();\n                             match (tts.len(), tts.get(0), tts.get(1)) {\n                                 (\n                                     2,"}, {"sha": "bdbca30c6458aab81471723d28c626f466092b44", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 11, "deletions": 12, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -46,7 +46,7 @@ use print::pprust;\n use ptr::P;\n use parse::PResult;\n use ThinVec;\n-use tokenstream::{self, DelimSpan, ThinTokenStream, TokenTree, TokenStream};\n+use tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n use symbol::{Symbol, keywords};\n \n use std::borrow::Cow;\n@@ -280,17 +280,17 @@ struct TokenCursorFrame {\n /// on the parser.\n #[derive(Clone)]\n enum LastToken {\n-    Collecting(Vec<TokenStream>),\n-    Was(Option<TokenStream>),\n+    Collecting(Vec<TreeAndJoint>),\n+    Was(Option<TreeAndJoint>),\n }\n \n impl TokenCursorFrame {\n-    fn new(sp: DelimSpan, delim: DelimToken, tts: &ThinTokenStream) -> Self {\n+    fn new(sp: DelimSpan, delim: DelimToken, tts: &TokenStream) -> Self {\n         TokenCursorFrame {\n             delim: delim,\n             span: sp,\n             open_delim: delim == token::NoDelim,\n-            tree_cursor: tts.stream().into_trees(),\n+            tree_cursor: tts.clone().into_trees(),\n             close_delim: delim == token::NoDelim,\n             last_token: LastToken::Was(None),\n         }\n@@ -2330,7 +2330,7 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    fn expect_delimited_token_tree(&mut self) -> PResult<'a, (MacDelimiter, ThinTokenStream)> {\n+    fn expect_delimited_token_tree(&mut self) -> PResult<'a, (MacDelimiter, TokenStream)> {\n         let delim = match self.token {\n             token::OpenDelim(delim) => delim,\n             _ => {\n@@ -2350,7 +2350,7 @@ impl<'a> Parser<'a> {\n             token::Brace => MacDelimiter::Brace,\n             token::NoDelim => self.bug(\"unexpected no delimiter\"),\n         };\n-        Ok((delim, tts.stream().into()))\n+        Ok((delim, tts.into()))\n     }\n \n     /// At the bottom (top?) of the precedence hierarchy,\n@@ -4641,7 +4641,7 @@ impl<'a> Parser<'a> {\n                 let ident = self.parse_ident()?;\n                 let tokens = if self.check(&token::OpenDelim(token::Brace)) {\n                     match self.parse_token_tree() {\n-                        TokenTree::Delimited(_, _, tts) => tts.stream(),\n+                        TokenTree::Delimited(_, _, tts) => tts,\n                         _ => unreachable!(),\n                     }\n                 } else if self.check(&token::OpenDelim(token::Paren)) {\n@@ -7757,7 +7757,7 @@ impl<'a> Parser<'a> {\n             &mut self.token_cursor.stack[prev].last_token\n         };\n \n-        // Pull our the toekns that we've collected from the call to `f` above\n+        // Pull out the tokens that we've collected from the call to `f` above.\n         let mut collected_tokens = match *last_token {\n             LastToken::Collecting(ref mut v) => mem::replace(v, Vec::new()),\n             LastToken::Was(_) => panic!(\"our vector went away?\"),\n@@ -7776,10 +7776,9 @@ impl<'a> Parser<'a> {\n         // call. In that case we need to record all the tokens we collected in\n         // our parent list as well. To do that we push a clone of our stream\n         // onto the previous list.\n-        let stream = collected_tokens.into_iter().collect::<TokenStream>();\n         match prev_collecting {\n             Some(mut list) => {\n-                list.push(stream.clone());\n+                list.extend(collected_tokens.iter().cloned());\n                 list.extend(extra_token);\n                 *last_token = LastToken::Collecting(list);\n             }\n@@ -7788,7 +7787,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        Ok((ret?, stream))\n+        Ok((ret?, TokenStream::new(collected_tokens)))\n     }\n \n     pub fn parse_item(&mut self) -> PResult<'a, Option<P<Item>>> {"}, {"sha": "c53594032a00aefb006bd2dc9ead3eaf7ac61485", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -807,7 +807,7 @@ pub trait PrintState<'a> {\n             TokenTree::Delimited(_, delim, tts) => {\n                 self.writer().word(token_to_string(&token::OpenDelim(delim)))?;\n                 self.writer().space()?;\n-                self.print_tts(tts.stream())?;\n+                self.print_tts(tts)?;\n                 self.writer().space()?;\n                 self.writer().word(token_to_string(&token::CloseDelim(delim)))\n             },"}, {"sha": "f5d2d6f18ee87916f4a63d976fc3ebd2e533164c", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 53, "deletions": 142, "changes": 195, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -41,7 +41,7 @@ pub enum TokenTree {\n     /// A single token\n     Token(Span, token::Token),\n     /// A delimited sequence of token trees\n-    Delimited(DelimSpan, DelimToken, ThinTokenStream),\n+    Delimited(DelimSpan, DelimToken, TokenStream),\n }\n \n impl TokenTree {\n@@ -62,8 +62,7 @@ impl TokenTree {\n             (&TokenTree::Token(_, ref tk), &TokenTree::Token(_, ref tk2)) => tk == tk2,\n             (&TokenTree::Delimited(_, delim, ref tts),\n              &TokenTree::Delimited(_, delim2, ref tts2)) => {\n-                delim == delim2 &&\n-                tts.stream().eq_unspanned(&tts2.stream())\n+                delim == delim2 && tts.eq_unspanned(&tts2)\n             }\n             (_, _) => false,\n         }\n@@ -81,8 +80,7 @@ impl TokenTree {\n             }\n             (&TokenTree::Delimited(_, delim, ref tts),\n              &TokenTree::Delimited(_, delim2, ref tts2)) => {\n-                delim == delim2 &&\n-                tts.stream().probably_equal_for_proc_macro(&tts2.stream())\n+                delim == delim2 && tts.probably_equal_for_proc_macro(&tts2)\n             }\n             (_, _) => false,\n         }\n@@ -113,7 +111,7 @@ impl TokenTree {\n     }\n \n     pub fn joint(self) -> TokenStream {\n-        TokenStream::Tree(self, Joint)\n+        TokenStream::new(vec![(self, Joint)])\n     }\n \n     /// Returns the opening delimiter as a token tree.\n@@ -143,18 +141,19 @@ impl TokenTree {\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `Token::Interpolated` for back-compat.\n+///\n+/// The use of `Option` is an optimization that avoids the need for an\n+/// allocation when the stream is empty. However, it is not guaranteed that an\n+/// empty stream is represented with `None`; it may be represented as a `Some`\n+/// around an empty `Vec`.\n #[derive(Clone, Debug)]\n-pub enum TokenStream {\n-    Empty,\n-    Tree(TokenTree, IsJoint),\n-    Stream(Lrc<Vec<TreeAndJoint>>),\n-}\n+pub struct TokenStream(Option<Lrc<Vec<TreeAndJoint>>>);\n \n pub type TreeAndJoint = (TokenTree, IsJoint);\n \n // `TokenStream` is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(target_arch = \"x86_64\")]\n-static_assert!(MEM_SIZE_OF_TOKEN_STREAM: mem::size_of::<TokenStream>() == 32);\n+static_assert!(MEM_SIZE_OF_TOKEN_STREAM: mem::size_of::<TokenStream>() == 8);\n \n #[derive(Clone, Copy, Debug, PartialEq)]\n pub enum IsJoint {\n@@ -169,7 +168,7 @@ impl TokenStream {\n     /// separating the two arguments with a comma for diagnostic suggestions.\n     pub(crate) fn add_comma(&self) -> Option<(TokenStream, Span)> {\n         // Used to suggest if a user writes `foo!(a b);`\n-        if let TokenStream::Stream(ref stream) = self {\n+        if let Some(ref stream) = self.0 {\n             let mut suggestion = None;\n             let mut iter = stream.iter().enumerate().peekable();\n             while let Some((pos, ts)) = iter.next() {\n@@ -201,7 +200,7 @@ impl TokenStream {\n \n impl From<TokenTree> for TokenStream {\n     fn from(tree: TokenTree) -> TokenStream {\n-        TokenStream::Tree(tree, NonJoint)\n+        TokenStream::new(vec![(tree, NonJoint)])\n     }\n }\n \n@@ -233,21 +232,21 @@ impl PartialEq<TokenStream> for TokenStream {\n \n impl TokenStream {\n     pub fn len(&self) -> usize {\n-        if let TokenStream::Stream(ref slice) = self {\n+        if let Some(ref slice) = self.0 {\n             slice.len()\n         } else {\n             0\n         }\n     }\n \n     pub fn empty() -> TokenStream {\n-        TokenStream::Empty\n+        TokenStream(None)\n     }\n \n     pub fn is_empty(&self) -> bool {\n-        match self {\n-            TokenStream::Empty => true,\n-            _ => false,\n+        match self.0 {\n+            None => true,\n+            Some(ref stream) => stream.is_empty(),\n         }\n     }\n \n@@ -258,33 +257,26 @@ impl TokenStream {\n             _ => {\n                 let mut vec = vec![];\n                 for stream in streams {\n-                    match stream {\n-                        TokenStream::Empty => {},\n-                        TokenStream::Tree(tree, is_joint) => vec.push((tree, is_joint)),\n-                        TokenStream::Stream(stream2) => vec.extend(stream2.iter().cloned()),\n+                    match stream.0 {\n+                        None => {},\n+                        Some(stream2) => vec.extend(stream2.iter().cloned()),\n                     }\n                 }\n                 TokenStream::new(vec)\n             }\n         }\n     }\n \n-    pub fn new(mut streams: Vec<TreeAndJoint>) -> TokenStream {\n+    pub fn new(streams: Vec<TreeAndJoint>) -> TokenStream {\n         match streams.len() {\n-            0 => TokenStream::empty(),\n-            1 => {\n-                let (tree, is_joint) = streams.pop().unwrap();\n-                TokenStream::Tree(tree, is_joint)\n-            }\n-            _ => TokenStream::Stream(Lrc::new(streams)),\n+            0 => TokenStream(None),\n+            _ => TokenStream(Some(Lrc::new(streams))),\n         }\n     }\n \n     pub fn append_to_tree_and_joint_vec(self, vec: &mut Vec<TreeAndJoint>) {\n-        match self {\n-            TokenStream::Empty => {}\n-            TokenStream::Tree(tree, is_joint) => vec.push((tree, is_joint)),\n-            TokenStream::Stream(stream) => vec.extend(stream.iter().cloned()),\n+        if let Some(stream) = self.0 {\n+            vec.extend(stream.iter().cloned());\n         }\n     }\n \n@@ -349,51 +341,36 @@ impl TokenStream {\n     }\n \n     pub fn map_enumerated<F: FnMut(usize, TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        match self {\n-            TokenStream::Empty => TokenStream::Empty,\n-            TokenStream::Tree(tree, is_joint) => TokenStream::Tree(f(0, tree), is_joint),\n-            TokenStream::Stream(stream) => TokenStream::Stream(Lrc::new(\n+        TokenStream(self.0.map(|stream| {\n+            Lrc::new(\n                 stream\n                     .iter()\n                     .enumerate()\n                     .map(|(i, (tree, is_joint))| (f(i, tree.clone()), *is_joint))\n-                    .collect()\n-            )),\n-        }\n+                    .collect())\n+        }))\n     }\n \n     pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        match self {\n-            TokenStream::Empty => TokenStream::Empty,\n-            TokenStream::Tree(tree, is_joint) => TokenStream::Tree(f(tree), is_joint),\n-            TokenStream::Stream(stream) => TokenStream::Stream(Lrc::new(\n+        TokenStream(self.0.map(|stream| {\n+            Lrc::new(\n                 stream\n                     .iter()\n                     .map(|(tree, is_joint)| (f(tree.clone()), *is_joint))\n-                    .collect()\n-            )),\n-        }\n+                    .collect())\n+        }))\n     }\n \n-    fn first_tree_and_joint(&self) -> Option<(TokenTree, IsJoint)> {\n-        match self {\n-            TokenStream::Empty => None,\n-            TokenStream::Tree(ref tree, is_joint) => Some((tree.clone(), *is_joint)),\n-            TokenStream::Stream(ref stream) => Some(stream.first().unwrap().clone())\n-        }\n+    fn first_tree_and_joint(&self) -> Option<TreeAndJoint> {\n+        self.0.as_ref().map(|stream| {\n+            stream.first().unwrap().clone()\n+        })\n     }\n \n     fn last_tree_if_joint(&self) -> Option<TokenTree> {\n-        match self {\n-            TokenStream::Empty => None,\n-            TokenStream::Tree(ref tree, is_joint) => {\n-                if *is_joint == Joint {\n-                    Some(tree.clone())\n-                } else {\n-                    None\n-                }\n-            }\n-            TokenStream::Stream(ref stream) => {\n+        match self.0 {\n+            None => None,\n+            Some(ref stream) => {\n                 if let (tree, Joint) = stream.last().unwrap() {\n                     Some(tree.clone())\n                 } else {\n@@ -422,7 +399,7 @@ impl TokenStreamBuilder {\n                     self.push_all_but_last_tree(&last_stream);\n                     let glued_span = last_span.to(span);\n                     let glued_tt = TokenTree::Token(glued_span, glued_tok);\n-                    let glued_tokenstream = TokenStream::Tree(glued_tt, is_joint);\n+                    let glued_tokenstream = TokenStream::new(vec![(glued_tt, is_joint)]);\n                     self.0.push(glued_tokenstream);\n                     self.push_all_but_first_tree(&stream);\n                     return\n@@ -437,23 +414,21 @@ impl TokenStreamBuilder {\n     }\n \n     fn push_all_but_last_tree(&mut self, stream: &TokenStream) {\n-        if let TokenStream::Stream(ref streams) = stream {\n+        if let Some(ref streams) = stream.0 {\n             let len = streams.len();\n             match len {\n                 1 => {}\n-                2 => self.0.push(TokenStream::Tree(streams[0].0.clone(), streams[0].1)),\n-                _ => self.0.push(TokenStream::Stream(Lrc::new(streams[0 .. len - 1].to_vec()))),\n+                _ => self.0.push(TokenStream(Some(Lrc::new(streams[0 .. len - 1].to_vec())))),\n             }\n         }\n     }\n \n     fn push_all_but_first_tree(&mut self, stream: &TokenStream) {\n-        if let TokenStream::Stream(ref streams) = stream {\n+        if let Some(ref streams) = stream.0 {\n             let len = streams.len();\n             match len {\n                 1 => {}\n-                2 => self.0.push(TokenStream::Tree(streams[1].0.clone(), streams[1].1)),\n-                _ => self.0.push(TokenStream::Stream(Lrc::new(streams[1 .. len].to_vec()))),\n+                _ => self.0.push(TokenStream(Some(Lrc::new(streams[1 .. len].to_vec())))),\n             }\n         }\n     }\n@@ -479,17 +454,9 @@ impl Cursor {\n     }\n \n     pub fn next_with_joint(&mut self) -> Option<TreeAndJoint> {\n-        match self.stream {\n-            TokenStream::Empty => None,\n-            TokenStream::Tree(ref tree, ref is_joint) => {\n-                if self.index == 0 {\n-                    self.index = 1;\n-                    Some((tree.clone(), *is_joint))\n-                } else {\n-                    None\n-                }\n-            }\n-            TokenStream::Stream(ref stream) => {\n+        match self.stream.0 {\n+            None => None,\n+            Some(ref stream) => {\n                 if self.index < stream.len() {\n                     self.index += 1;\n                     Some(stream[self.index - 1].clone())\n@@ -505,63 +472,19 @@ impl Cursor {\n             return;\n         }\n         let index = self.index;\n-        let stream = mem::replace(&mut self.stream, TokenStream::Empty);\n+        let stream = mem::replace(&mut self.stream, TokenStream(None));\n         *self = TokenStream::from_streams(vec![stream, new_stream]).into_trees();\n         self.index = index;\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<TokenTree> {\n-        match self.stream {\n-            TokenStream::Empty => None,\n-            TokenStream::Tree(ref tree, _) => {\n-                if n == 0 && self.index == 0 {\n-                    Some(tree.clone())\n-                } else {\n-                    None\n-                }\n-            }\n-            TokenStream::Stream(ref stream) =>\n-                stream[self.index ..].get(n).map(|(tree, _)| tree.clone()),\n+        match self.stream.0 {\n+            None => None,\n+            Some(ref stream) => stream[self.index ..].get(n).map(|(tree, _)| tree.clone()),\n         }\n     }\n }\n \n-/// The `TokenStream` type is large enough to represent a single `TokenTree` without allocation.\n-/// `ThinTokenStream` is smaller, but needs to allocate to represent a single `TokenTree`.\n-/// We must use `ThinTokenStream` in `TokenTree::Delimited` to avoid infinite size due to recursion.\n-#[derive(Debug, Clone)]\n-pub struct ThinTokenStream(Option<Lrc<Vec<TreeAndJoint>>>);\n-\n-impl ThinTokenStream {\n-    pub fn stream(&self) -> TokenStream {\n-        self.clone().into()\n-    }\n-}\n-\n-impl From<TokenStream> for ThinTokenStream {\n-    fn from(stream: TokenStream) -> ThinTokenStream {\n-        ThinTokenStream(match stream {\n-            TokenStream::Empty => None,\n-            TokenStream::Tree(tree, is_joint) => Some(Lrc::new(vec![(tree, is_joint)])),\n-            TokenStream::Stream(stream) => Some(stream),\n-        })\n-    }\n-}\n-\n-impl From<ThinTokenStream> for TokenStream {\n-    fn from(stream: ThinTokenStream) -> TokenStream {\n-        stream.0.map(TokenStream::Stream).unwrap_or_else(TokenStream::empty)\n-    }\n-}\n-\n-impl Eq for ThinTokenStream {}\n-\n-impl PartialEq<ThinTokenStream> for ThinTokenStream {\n-    fn eq(&self, other: &ThinTokenStream) -> bool {\n-        TokenStream::from(self.clone()) == TokenStream::from(other.clone())\n-    }\n-}\n-\n impl fmt::Display for TokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n         f.write_str(&pprust::tokens_to_string(self.clone()))\n@@ -580,18 +503,6 @@ impl Decodable for TokenStream {\n     }\n }\n \n-impl Encodable for ThinTokenStream {\n-    fn encode<E: Encoder>(&self, encoder: &mut E) -> Result<(), E::Error> {\n-        TokenStream::from(self.clone()).encode(encoder)\n-    }\n-}\n-\n-impl Decodable for ThinTokenStream {\n-    fn decode<D: Decoder>(decoder: &mut D) -> Result<ThinTokenStream, D::Error> {\n-        TokenStream::decode(decoder).map(Into::into)\n-    }\n-}\n-\n #[derive(Debug, Copy, Clone, PartialEq, RustcEncodable, RustcDecodable)]\n pub struct DelimSpan {\n     pub open: Span,"}, {"sha": "8cbd47ca70fded321d9eb95b2863d2e1327f6fdf", "filename": "src/libsyntax/visit.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fvisit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax%2Fvisit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fvisit.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -832,7 +832,7 @@ pub fn walk_attribute<'a, V: Visitor<'a>>(visitor: &mut V, attr: &'a Attribute)\n pub fn walk_tt<'a, V: Visitor<'a>>(visitor: &mut V, tt: TokenTree) {\n     match tt {\n         TokenTree::Token(_, tok) => visitor.visit_token(tok),\n-        TokenTree::Delimited(_, _, tts) => visitor.visit_tts(tts.stream()),\n+        TokenTree::Delimited(_, _, tts) => visitor.visit_tts(tts),\n     }\n }\n "}, {"sha": "7de9b9343a8faceb33609b220290e37dc5ca9b92", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/349c9eeb355a979c2e51f832d05ce9212f0aeeba/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=349c9eeb355a979c2e51f832d05ce9212f0aeeba", "patch": "@@ -269,7 +269,7 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n         };\n \n         let tree = tokenstream::TokenTree::Token(span, token);\n-        TokenStream::Tree(tree, if joint { Joint } else { NonJoint })\n+        TokenStream::new(vec![(tree, if joint { Joint } else { NonJoint })])\n     }\n }\n "}]}