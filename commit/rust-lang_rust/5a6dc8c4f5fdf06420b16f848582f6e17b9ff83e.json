{"sha": "5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVhNmRjOGM0ZjVmZGYwNjQyMGIxNmY4NDg1ODJmNmUxN2I5ZmY4M2U=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-05-29T15:50:13Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2018-06-27T12:00:34Z"}, "message": "Add SSE2 accelerated version of FileMap analysis.", "tree": {"sha": "01997f0a65efc006e6e880e92b043cddf73956f3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/01997f0a65efc006e6e880e92b043cddf73956f3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "html_url": "https://github.com/rust-lang/rust/commit/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3497138634bf58a7c29ef35f1f677dbde0633af8", "url": "https://api.github.com/repos/rust-lang/rust/commits/3497138634bf58a7c29ef35f1f677dbde0633af8", "html_url": "https://github.com/rust-lang/rust/commit/3497138634bf58a7c29ef35f1f677dbde0633af8"}], "stats": {"total": 513, "additions": 445, "deletions": 68}, "files": [{"sha": "a93390552641ce7b1306cd9a6402dbb13f0aad83", "filename": "src/Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "patch": "@@ -2779,6 +2779,7 @@ name = \"syntax_pos\"\n version = \"0.0.0\"\n dependencies = [\n  \"arena 0.0.0\",\n+ \"cfg-if 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc_data_structures 0.0.0\",\n  \"scoped-tls 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"serialize 0.0.0\","}, {"sha": "08ee2e0f3762647939d95879baf4251efd979d18", "filename": "src/libsyntax_pos/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2FCargo.toml?ref=5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "patch": "@@ -14,3 +14,4 @@ rustc_data_structures = { path = \"../librustc_data_structures\" }\n arena = { path = \"../libarena\" }\n scoped-tls = { version = \"0.1.1\", features = [\"nightly\"] }\n unicode-width = \"0.1.4\"\n+cfg-if = \"0.1.2\""}, {"sha": "7828c55ce781ff80374a07f6f00432f00117c75e", "filename": "src/libsyntax_pos/analyze_filemap.rs", "status": "added", "additions": 434, "deletions": 0, "changes": 434, "blob_url": "https://github.com/rust-lang/rust/blob/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2Fanalyze_filemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2Fanalyze_filemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fanalyze_filemap.rs?ref=5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "patch": "@@ -0,0 +1,434 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use unicode_width::UnicodeWidthChar;\n+use super::*;\n+\n+/// Find all newlines, multi-byte characters, and non-narrow characters in a\n+/// FileMap.\n+///\n+/// This function will use an SSE2 enhanced implementation if hardware support\n+/// is detected at runtime.\n+pub fn analyze_filemap(\n+    src: &str,\n+    filemap_start_pos: BytePos)\n+    -> (Vec<BytePos>, Vec<MultiByteChar>, Vec<NonNarrowChar>)\n+{\n+    let mut lines = vec![filemap_start_pos];\n+    let mut multi_byte_chars = vec![];\n+    let mut non_narrow_chars = vec![];\n+\n+    // Calls the right implementation, depending on hardware support available.\n+    analyze_filemap_dispatch(src,\n+                             filemap_start_pos,\n+                             &mut lines,\n+                             &mut multi_byte_chars,\n+                             &mut non_narrow_chars);\n+\n+    // The code above optimistically registers a new line *after* each \\n\n+    // it encounters. If that point is already outside the filemap, remove\n+    // it again.\n+    if let Some(&last_line_start) = lines.last() {\n+        let file_map_end = filemap_start_pos + BytePos::from_usize(src.len());\n+        assert!(file_map_end >= last_line_start);\n+        if last_line_start == file_map_end {\n+            lines.pop();\n+        }\n+    }\n+\n+    (lines, multi_byte_chars, non_narrow_chars)\n+}\n+\n+cfg_if! {\n+    if #[cfg(all(any(target_arch = \"x86\", target_arch = \"x86_64\"),\n+                 not(stage0)))] {\n+        fn analyze_filemap_dispatch(src: &str,\n+                                    filemap_start_pos: BytePos,\n+                                    lines: &mut Vec<BytePos>,\n+                                    multi_byte_chars: &mut Vec<MultiByteChar>,\n+                                    non_narrow_chars: &mut Vec<NonNarrowChar>) {\n+            if is_x86_feature_detected!(\"sse2\") {\n+                unsafe {\n+                    analyze_filemap_sse2(src,\n+                                         filemap_start_pos,\n+                                         lines,\n+                                         multi_byte_chars,\n+                                         non_narrow_chars);\n+                }\n+            } else {\n+                analyze_filemap_generic(src,\n+                                        src.len(),\n+                                        filemap_start_pos,\n+                                        lines,\n+                                        multi_byte_chars,\n+                                        non_narrow_chars);\n+\n+            }\n+        }\n+\n+        /// Check 16 byte chunks of text at a time. If the chunk contains\n+        /// something other than printable ASCII characters and newlines, the\n+        /// function falls back to the generic implementation. Otherwise it uses\n+        /// SSE2 intrinsics to quickly find all newlines.\n+        #[target_feature(enable = \"sse2\")]\n+        unsafe fn analyze_filemap_sse2(src: &str,\n+                                       output_offset: BytePos,\n+                                       lines: &mut Vec<BytePos>,\n+                                       multi_byte_chars: &mut Vec<MultiByteChar>,\n+                                       non_narrow_chars: &mut Vec<NonNarrowChar>) {\n+            #[cfg(target_arch = \"x86\")]\n+            use std::arch::x86::*;\n+            #[cfg(target_arch = \"x86_64\")]\n+            use std::arch::x86_64::*;\n+\n+            const CHUNK_SIZE: usize = 16;\n+\n+            let src_bytes = src.as_bytes();\n+\n+            let chunk_count = src.len() / CHUNK_SIZE;\n+\n+            // This variable keeps track of where we should start decoding a\n+            // chunk. If a multi-byte character spans across chunk boundaries,\n+            // we need to skip that part in the next chunk because we already\n+            // handled it.\n+            let mut intra_chunk_offset = 0;\n+\n+            for chunk_index in 0 .. chunk_count {\n+                let ptr = src_bytes.as_ptr() as *const __m128i;\n+                let chunk = _mm_loadu_si128(ptr.offset(chunk_index as isize));\n+\n+                // For character in the chunk, see if its byte value is < 0, which\n+                // indicates that it's part of a UTF-8 char.\n+                let multibyte_test = _mm_cmplt_epi8(chunk, _mm_set1_epi8(0));\n+                // Create a bit mask from the comparison results.\n+                let multibyte_mask = _mm_movemask_epi8(multibyte_test);\n+\n+                // If the bit mask is all zero, we only have ASCII chars here:\n+                if multibyte_mask == 0 {\n+                    assert!(intra_chunk_offset == 0);\n+\n+                    // Check if there are any control characters in the chunk. All\n+                    // control characters that we can encounter at this point have a\n+                    // byte value less than 32 or ...\n+                    let control_char_test0 = _mm_cmplt_epi8(chunk, _mm_set1_epi8(32));\n+                    let control_char_mask0 = _mm_movemask_epi8(control_char_test0);\n+\n+                    // ... it's the ASCII 'DEL' character with a value of 127.\n+                    let control_char_test1 = _mm_cmpeq_epi8(chunk, _mm_set1_epi8(127));\n+                    let control_char_mask1 = _mm_movemask_epi8(control_char_test1);\n+\n+                    let control_char_mask = control_char_mask0 | control_char_mask1;\n+\n+                    if control_char_mask != 0 {\n+                        // Check for newlines in the chunk\n+                        let newlines_test = _mm_cmpeq_epi8(chunk, _mm_set1_epi8(b'\\n' as i8));\n+                        let newlines_mask = _mm_movemask_epi8(newlines_test);\n+\n+                        if control_char_mask == newlines_mask {\n+                            // All control characters are newlines, record them\n+                            let mut newlines_mask = 0xFFFF0000 | newlines_mask as u32;\n+                            let output_offset = output_offset +\n+                                BytePos::from_usize(chunk_index * CHUNK_SIZE + 1);\n+\n+                            loop {\n+                                let index = newlines_mask.trailing_zeros();\n+\n+                                if index >= CHUNK_SIZE as u32 {\n+                                    // We have arrived at the end of the chunk.\n+                                    break\n+                                }\n+\n+                                lines.push(BytePos(index) + output_offset);\n+\n+                                // Clear the bit, so we can find the next one.\n+                                newlines_mask &= (!1) << index;\n+                            }\n+\n+                            // We are done for this chunk. All control characters were\n+                            // newlines and we took care of those.\n+                            continue\n+                        } else {\n+                            // Some of the control characters are not newlines,\n+                            // fall through to the slow path below.\n+                        }\n+                    } else {\n+                        // No control characters, nothing to record for this chunk\n+                        continue\n+                    }\n+                }\n+\n+                // The slow path.\n+                // There are control chars in here, fallback to generic decoding.\n+                let scan_start = chunk_index * CHUNK_SIZE + intra_chunk_offset;\n+                intra_chunk_offset = analyze_filemap_generic(\n+                    &src[scan_start .. ],\n+                    CHUNK_SIZE - intra_chunk_offset,\n+                    BytePos::from_usize(scan_start) + output_offset,\n+                    lines,\n+                    multi_byte_chars,\n+                    non_narrow_chars\n+                );\n+            }\n+\n+            // There might still be a tail left to analyze\n+            let tail_start = chunk_count * CHUNK_SIZE + intra_chunk_offset;\n+            if tail_start < src.len() {\n+                analyze_filemap_generic(&src[tail_start as usize ..],\n+                                        src.len() - tail_start,\n+                                        output_offset + BytePos::from_usize(tail_start),\n+                                        lines,\n+                                        multi_byte_chars,\n+                                        non_narrow_chars);\n+            }\n+        }\n+    } else {\n+\n+        // The target (or compiler version) does not support SSE2 ...\n+        fn analyze_filemap_dispatch(src: &str,\n+                                    filemap_start_pos: BytePos,\n+                                    lines: &mut Vec<BytePos>,\n+                                    multi_byte_chars: &mut Vec<MultiByteChar>,\n+                                    non_narrow_chars: &mut Vec<NonNarrowChar>) {\n+            analyze_filemap_generic(src,\n+                                    src.len(),\n+                                    filemap_start_pos,\n+                                    lines,\n+                                    multi_byte_chars,\n+                                    non_narrow_chars);\n+        }\n+    }\n+}\n+\n+// `scan_len` determines the number of bytes in `src` to scan. Note that the\n+// function can read past `scan_len` if a multi-byte character start within the\n+// range but extends past it. The overflow is returned by the function.\n+fn analyze_filemap_generic(src: &str,\n+                           scan_len: usize,\n+                           output_offset: BytePos,\n+                           lines: &mut Vec<BytePos>,\n+                           multi_byte_chars: &mut Vec<MultiByteChar>,\n+                           non_narrow_chars: &mut Vec<NonNarrowChar>)\n+                           -> usize\n+{\n+    assert!(src.len() >= scan_len);\n+    let mut i = 0;\n+    let src_bytes = src.as_bytes();\n+\n+    while i < scan_len {\n+        let byte = unsafe {\n+            // We verified that i < scan_len <= src.len()\n+            *src_bytes.get_unchecked(i as usize)\n+        };\n+\n+        // How much to advance in order to get to the next UTF-8 char in the\n+        // string.\n+        let mut char_len = 1;\n+\n+        if byte < 32 {\n+            // This is an ASCII control character, it could be one of the cases\n+            // that are interesting to us.\n+\n+            let pos = BytePos::from_usize(i) + output_offset;\n+\n+            match byte {\n+                b'\\n' => {\n+                    lines.push(pos + BytePos(1));\n+                }\n+                b'\\t' => {\n+                    non_narrow_chars.push(NonNarrowChar::Tab(pos));\n+                }\n+                _ => {\n+                    non_narrow_chars.push(NonNarrowChar::ZeroWidth(pos));\n+                }\n+            }\n+        } else if byte >= 127 {\n+            // The slow path:\n+            // This is either ASCII control character \"DEL\" or the beginning of\n+            // a multibyte char. Just decode to `char`.\n+            let c = (&src[i..]).chars().next().unwrap();\n+            char_len = c.len_utf8();\n+\n+            let pos = BytePos::from_usize(i) + output_offset;\n+\n+            if char_len > 1 {\n+                assert!(char_len >=2 && char_len <= 4);\n+                let mbc = MultiByteChar {\n+                    pos,\n+                    bytes: char_len as u32,\n+                };\n+                multi_byte_chars.push(mbc);\n+            }\n+\n+            // Assume control characters are zero width.\n+            // FIXME: How can we decide between `width` and `width_cjk`?\n+            let char_width = UnicodeWidthChar::width(c).unwrap_or(0);\n+\n+            if char_width != 1 {\n+                non_narrow_chars.push(NonNarrowChar::new(pos, char_width));\n+            }\n+        }\n+\n+        i += char_len;\n+    }\n+\n+    i - scan_len\n+}\n+\n+\n+\n+macro_rules! test {\n+    (case: $test_name:ident,\n+     text: $text:expr,\n+     filemap_start_pos: $filemap_start_pos:expr,\n+     lines: $lines:expr,\n+     multi_byte_chars: $multi_byte_chars:expr,\n+     non_narrow_chars: $non_narrow_chars:expr,) => (\n+\n+    #[test]\n+    fn $test_name() {\n+\n+        let (lines, multi_byte_chars, non_narrow_chars) =\n+            analyze_filemap($text, BytePos($filemap_start_pos));\n+\n+        let expected_lines: Vec<BytePos> = $lines\n+            .into_iter()\n+            .map(|pos| BytePos(pos))\n+            .collect();\n+\n+        assert_eq!(lines, expected_lines);\n+\n+        let expected_mbcs: Vec<MultiByteChar> = $multi_byte_chars\n+            .into_iter()\n+            .map(|(pos, bytes)| MultiByteChar {\n+                pos: BytePos(pos),\n+                bytes,\n+            })\n+            .collect();\n+\n+        assert_eq!(multi_byte_chars, expected_mbcs);\n+\n+        let expected_nncs: Vec<NonNarrowChar> = $non_narrow_chars\n+            .into_iter()\n+            .map(|(pos, width)| {\n+                NonNarrowChar::new(BytePos(pos), width)\n+            })\n+            .collect();\n+\n+        assert_eq!(non_narrow_chars, expected_nncs);\n+    })\n+}\n+\n+test!(\n+    case: empty_text,\n+    text: \"\",\n+    filemap_start_pos: 0,\n+    lines: vec![],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: newlines_short,\n+    text: \"a\\nc\",\n+    filemap_start_pos: 0,\n+    lines: vec![0, 2],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: newlines_long,\n+    text: \"012345678\\nabcdef012345678\\na\",\n+    filemap_start_pos: 0,\n+    lines: vec![0, 10, 26],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: newline_and_multi_byte_char_in_same_chunk,\n+    text: \"01234\u03b2789\\nbcdef0123456789abcdef\",\n+    filemap_start_pos: 0,\n+    lines: vec![0, 11],\n+    multi_byte_chars: vec![(5, 2)],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: newline_and_control_char_in_same_chunk,\n+    text: \"01234\\u{07}6789\\nbcdef0123456789abcdef\",\n+    filemap_start_pos: 0,\n+    lines: vec![0, 11],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![(5, 0)],\n+);\n+\n+test!(\n+    case: multi_byte_char_short,\n+    text: \"a\u03b2c\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![(1, 2)],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: multi_byte_char_long,\n+    text: \"0123456789abc\u0394f012345\u03b2\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![(13, 2), (22, 2)],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: multi_byte_char_across_chunk_boundary,\n+    text: \"0123456789abcde\u0394123456789abcdef01234\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![(15, 2)],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: multi_byte_char_across_chunk_boundary_tail,\n+    text: \"0123456789abcde\u0394....\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![(15, 2)],\n+    non_narrow_chars: vec![],\n+);\n+\n+test!(\n+    case: non_narrow_short,\n+    text: \"0\\t2\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![(1, 4)],\n+);\n+\n+test!(\n+    case: non_narrow_long,\n+    text: \"01\\t3456789abcdef01234567\\u{07}9\",\n+    filemap_start_pos: 0,\n+    lines: vec![0],\n+    multi_byte_chars: vec![],\n+    non_narrow_chars: vec![(2, 4), (24, 0)],\n+);\n+\n+test!(\n+    case: output_offset_all,\n+    text: \"01\\t345\\n789abc\u0394f01234567\\u{07}9\\nbc\u0394f\",\n+    filemap_start_pos: 1000,\n+    lines: vec![0 + 1000, 7 + 1000, 27 + 1000],\n+    multi_byte_chars: vec![(13 + 1000, 2), (29 + 1000, 2)],\n+    non_narrow_chars: vec![(2 + 1000, 4), (24 + 1000, 0)],\n+);"}, {"sha": "90f3ae90c2f86a8ae1c8f2660384c2874d1b7728", "filename": "src/libsyntax_pos/lib.rs", "status": "modified", "additions": 9, "deletions": 68, "changes": 77, "blob_url": "https://github.com/rust-lang/rust/blob/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e/src%2Flibsyntax_pos%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Flib.rs?ref=5a6dc8c4f5fdf06420b16f848582f6e17b9ff83e", "patch": "@@ -24,6 +24,7 @@\n #![feature(optin_builtin_traits)]\n #![allow(unused_attributes)]\n #![feature(specialization)]\n+#![feature(stdsimd)]\n \n use std::borrow::Cow;\n use std::cell::Cell;\n@@ -47,6 +48,9 @@ use serialize::{Encodable, Decodable, Encoder, Decoder};\n extern crate serialize;\n extern crate serialize as rustc_serialize; // used by deriving\n \n+#[macro_use]\n+extern crate cfg_if;\n+\n extern crate unicode_width;\n \n pub mod edition;\n@@ -58,6 +62,8 @@ pub use span_encoding::{Span, DUMMY_SP};\n \n pub mod symbol;\n \n+mod analyze_filemap;\n+\n pub struct Globals {\n     symbol_interner: Lock<symbol::Interner>,\n     span_interner: Lock<span_encoding::SpanInterner>,\n@@ -652,7 +658,7 @@ impl From<Vec<Span>> for MultiSpan {\n pub const NO_EXPANSION: SyntaxContext = SyntaxContext::empty();\n \n /// Identifies an offset of a multi-byte character in a FileMap\n-#[derive(Copy, Clone, RustcEncodable, RustcDecodable, Eq, PartialEq)]\n+#[derive(Copy, Clone, RustcEncodable, RustcDecodable, Eq, PartialEq, Debug)]\n pub struct MultiByteChar {\n     /// The absolute offset of the character in the CodeMap\n     pub pos: BytePos,\n@@ -661,7 +667,7 @@ pub struct MultiByteChar {\n }\n \n /// Identifies an offset of a non-narrow character in a FileMap\n-#[derive(Copy, Clone, RustcEncodable, RustcDecodable, Eq, PartialEq)]\n+#[derive(Copy, Clone, RustcEncodable, RustcDecodable, Eq, PartialEq, Debug)]\n pub enum NonNarrowChar {\n     /// Represents a zero-width character\n     ZeroWidth(BytePos),\n@@ -950,7 +956,7 @@ impl FileMap {\n         let end_pos = start_pos.to_usize() + src.len();\n \n         let (lines, multibyte_chars, non_narrow_chars) =\n-            Self::find_newlines_and_special_chars(&src[..], start_pos);\n+            analyze_filemap::analyze_filemap(&src[..], start_pos);\n \n         FileMap {\n             name,\n@@ -969,71 +975,6 @@ impl FileMap {\n         }\n     }\n \n-    fn find_newlines_and_special_chars(src: &str, filemap_start_pos: BytePos)\n-        -> (Vec<BytePos>, Vec<MultiByteChar>, Vec<NonNarrowChar>) {\n-\n-        let mut index = 0;\n-        let mut lines = vec![filemap_start_pos];\n-        let mut multibyte_chars = vec![];\n-        let mut non_narrow_chars = vec![];\n-\n-        while index < src.len() {\n-            let byte_pos = BytePos::from_usize(index) + filemap_start_pos;\n-            let byte = src.as_bytes()[index];\n-\n-            if byte.is_ascii() {\n-                match byte {\n-                    b'\\n' => {\n-                        lines.push(byte_pos + BytePos(1));\n-                    }\n-                    b'\\t' => {\n-                        // Tabs will consume 4 columns.\n-                        non_narrow_chars.push(NonNarrowChar::new(byte_pos, 4));\n-                    }\n-                    c => if c.is_ascii_control() {\n-                        // Assume control characters are zero width.\n-                        non_narrow_chars.push(NonNarrowChar::new(byte_pos, 0));\n-                    }\n-                }\n-\n-                index += 1;\n-            } else {\n-                let c = (&src[index..]).chars().next().unwrap();\n-                let c_len = c.len_utf8();\n-\n-                if c_len > 1 {\n-                    assert!(c_len >=2 && c_len <= 4);\n-                    let mbc = MultiByteChar {\n-                        pos: byte_pos,\n-                        bytes: c_len,\n-                    };\n-                    multibyte_chars.push(mbc);\n-                }\n-\n-                // Assume control characters are zero width.\n-                // FIXME: How can we decide between `width` and `width_cjk`?\n-                let c_width = unicode_width::UnicodeWidthChar::width(c).unwrap_or(0);\n-\n-                if c_width != 1 {\n-                    non_narrow_chars.push(NonNarrowChar::new(byte_pos, c_width));\n-                }\n-\n-                index += c_len;\n-            }\n-        }\n-\n-        // The loop above optimistically registers a new line *after* each of \\n\n-        // it encounters. If that point is already outside the filemap, remove\n-        // it again.\n-        if let Some(&last_line_start) = lines.last() {\n-            if last_line_start == filemap_start_pos + BytePos::from_usize(src.len()) {\n-                lines.pop();\n-            }\n-        }\n-\n-        (lines, multibyte_chars, non_narrow_chars)\n-    }\n-\n     /// Return the BytePos of the beginning of the current line.\n     pub fn line_begin_pos(&self) -> BytePos {\n         match self.lines.last() {"}]}