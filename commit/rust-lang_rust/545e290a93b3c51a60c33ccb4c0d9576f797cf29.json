{"sha": "545e290a93b3c51a60c33ccb4c0d9576f797cf29", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU0NWUyOTBhOTNiM2M1MWE2MGMzM2NjYjRjMGQ5NTc2Zjc5N2NmMjk=", "commit": {"author": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2020-02-12T20:04:36Z"}, "committer": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2020-02-19T15:01:46Z"}, "message": "Split query execution into hot and cold paths", "tree": {"sha": "591b4fdbba150c9d5d7bbe1c87fb30191fd5b253", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/591b4fdbba150c9d5d7bbe1c87fb30191fd5b253"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/545e290a93b3c51a60c33ccb4c0d9576f797cf29", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/545e290a93b3c51a60c33ccb4c0d9576f797cf29", "html_url": "https://github.com/rust-lang/rust/commit/545e290a93b3c51a60c33ccb4c0d9576f797cf29", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/545e290a93b3c51a60c33ccb4c0d9576f797cf29/comments", "author": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7710ae0e2653e0fa14ff9b7797ed29340e0284a8", "url": "https://api.github.com/repos/rust-lang/rust/commits/7710ae0e2653e0fa14ff9b7797ed29340e0284a8", "html_url": "https://github.com/rust-lang/rust/commit/7710ae0e2653e0fa14ff9b7797ed29340e0284a8"}], "stats": {"total": 258, "additions": 155, "deletions": 103}, "files": [{"sha": "ae2fde9661798727c0e74cc67c507bd11238e3d9", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=545e290a93b3c51a60c33ccb4c0d9576f797cf29", "patch": "@@ -1122,6 +1122,7 @@ impl CurrentDepGraph {\n }\n \n impl DepGraphData {\n+    #[inline]\n     fn read_index(&self, source: DepNodeIndex) {\n         ty::tls::with_context_opt(|icx| {\n             let icx = if let Some(icx) = icx { icx } else { return };"}, {"sha": "68c9ccc455fa1bdabafa878f35c54b250f980a9f", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=545e290a93b3c51a60c33ccb4c0d9576f797cf29", "patch": "@@ -1688,6 +1688,7 @@ pub mod tls {\n \n     /// Gets the pointer to the current `ImplicitCtxt`.\n     #[cfg(not(parallel_compiler))]\n+    #[inline]\n     fn get_tlv() -> usize {\n         TLV.with(|tlv| tlv.get())\n     }"}, {"sha": "5ed5c2776a848253de1da19d43e371e98cc75974", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 153, "deletions": 103, "changes": 256, "blob_url": "https://github.com/rust-lang/rust/blob/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/545e290a93b3c51a60c33ccb4c0d9576f797cf29/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=545e290a93b3c51a60c33ccb4c0d9576f797cf29", "patch": "@@ -12,10 +12,8 @@ use crate::ty::{self, TyCtxt};\n #[cfg(not(parallel_compiler))]\n use rustc_data_structures::cold_path;\n use rustc_data_structures::fx::{FxHashMap, FxHasher};\n-#[cfg(parallel_compiler)]\n-use rustc_data_structures::profiling::TimingGuard;\n use rustc_data_structures::sharded::Sharded;\n-use rustc_data_structures::sync::Lock;\n+use rustc_data_structures::sync::{Lock, LockGuard};\n use rustc_data_structures::thin_vec::ThinVec;\n use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, FatalError, Handler, Level};\n use rustc_span::source_map::DUMMY_SP;\n@@ -70,6 +68,12 @@ impl<'tcx, M: QueryConfig<'tcx>> Default for QueryCache<'tcx, M> {\n     }\n }\n \n+/// Values used when checking a query cache which can be reused on a cache-miss to execute the query.\n+pub(super) struct QueryLookup<'tcx, Q: QueryDescription<'tcx>> {\n+    shard: usize,\n+    lock: LockGuard<'tcx, QueryCache<'tcx, Q>>,\n+}\n+\n /// A type representing the responsibility to execute the job in the `job` field.\n /// This will poison the relevant query if dropped.\n pub(super) struct JobOwner<'a, 'tcx, Q: QueryDescription<'tcx>> {\n@@ -81,119 +85,87 @@ pub(super) struct JobOwner<'a, 'tcx, Q: QueryDescription<'tcx>> {\n impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n     /// Either gets a `JobOwner` corresponding the query, allowing us to\n     /// start executing the query, or returns with the result of the query.\n-    /// If the query is executing elsewhere, this will wait for it.\n+    /// This function assumes that `try_get_cached` is already called and returned `lookup`.\n+    /// If the query is executing elsewhere, this will wait for it and return the result.\n     /// If the query panicked, this will silently panic.\n     ///\n     /// This function is inlined because that results in a noticeable speed-up\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n-    pub(super) fn try_get(tcx: TyCtxt<'tcx>, span: Span, key: &Q::Key) -> TryGetJob<'a, 'tcx, Q> {\n-        // Handling the `query_blocked_prof_timer` is a bit weird because of the\n-        // control flow in this function: Blocking is implemented by\n-        // awaiting a running job and, once that is done, entering the loop below\n-        // again from the top. In that second iteration we will hit the\n-        // cache which provides us with the information we need for\n-        // finishing the \"query-blocked\" event.\n-        //\n-        // We thus allocate `query_blocked_prof_timer` outside the loop,\n-        // initialize it during the first iteration and finish it during the\n-        // second iteration.\n-        #[cfg(parallel_compiler)]\n-        let mut query_blocked_prof_timer: Option<TimingGuard<'_>> = None;\n-\n-        let cache = Q::query_cache(tcx);\n-        loop {\n-            // We compute the key's hash once and then use it for both the\n-            // shard lookup and the hashmap lookup. This relies on the fact\n-            // that both of them use `FxHasher`.\n-            let mut state = FxHasher::default();\n-            key.hash(&mut state);\n-            let key_hash = state.finish();\n-\n-            let shard = cache.get_shard_index_by_hash(key_hash);\n-            let mut lock_guard = cache.get_shard_by_index(shard).lock();\n-            let lock = &mut *lock_guard;\n-\n-            if let Some((_, value)) =\n-                lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key)\n-            {\n-                if unlikely!(tcx.prof.enabled()) {\n-                    tcx.prof.query_cache_hit(value.index.into());\n-\n-                    #[cfg(parallel_compiler)]\n-                    {\n-                        if let Some(prof_timer) = query_blocked_prof_timer.take() {\n-                            prof_timer.finish_with_query_invocation_id(value.index.into());\n-                        }\n-                    }\n-                }\n+    pub(super) fn try_start(\n+        tcx: TyCtxt<'tcx>,\n+        span: Span,\n+        key: &Q::Key,\n+        mut lookup: QueryLookup<'tcx, Q>,\n+    ) -> TryGetJob<'a, 'tcx, Q> {\n+        let lock = &mut *lookup.lock;\n+\n+        let (latch, mut _query_blocked_prof_timer) = match lock.active.entry((*key).clone()) {\n+            Entry::Occupied(mut entry) => {\n+                match entry.get_mut() {\n+                    QueryResult::Started(job) => {\n+                        // For parallel queries, we'll block and wait until the query running\n+                        // in another thread has completed. Record how long we wait in the\n+                        // self-profiler.\n+                        let _query_blocked_prof_timer = if cfg!(parallel_compiler) {\n+                            Some(tcx.prof.query_blocked())\n+                        } else {\n+                            None\n+                        };\n+\n+                        // Create the id of the job we're waiting for\n+                        let id = QueryJobId::new(job.id, lookup.shard, Q::dep_kind());\n \n-                let result = (value.value.clone(), value.index);\n-                #[cfg(debug_assertions)]\n-                {\n-                    lock.cache_hits += 1;\n+                        (job.latch(id), _query_blocked_prof_timer)\n+                    }\n+                    QueryResult::Poisoned => FatalError.raise(),\n                 }\n-                return TryGetJob::JobCompleted(result);\n             }\n+            Entry::Vacant(entry) => {\n+                // No job entry for this query. Return a new one to be started later.\n \n-            let latch = match lock.active.entry((*key).clone()) {\n-                Entry::Occupied(mut entry) => {\n-                    match entry.get_mut() {\n-                        QueryResult::Started(job) => {\n-                            // For parallel queries, we'll block and wait until the query running\n-                            // in another thread has completed. Record how long we wait in the\n-                            // self-profiler.\n-                            #[cfg(parallel_compiler)]\n-                            {\n-                                query_blocked_prof_timer = Some(tcx.prof.query_blocked());\n-                            }\n+                // Generate an id unique within this shard.\n+                let id = lock.jobs.checked_add(1).unwrap();\n+                lock.jobs = id;\n+                let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n \n-                            // Create the id of the job we're waiting for\n-                            let id = QueryJobId::new(job.id, shard, Q::dep_kind());\n+                let global_id = QueryJobId::new(id, lookup.shard, Q::dep_kind());\n \n-                            job.latch(id)\n-                        }\n-                        QueryResult::Poisoned => FatalError.raise(),\n-                    }\n-                }\n-                Entry::Vacant(entry) => {\n-                    // No job entry for this query. Return a new one to be started later.\n+                let job = tls::with_related_context(tcx, |icx| QueryJob::new(id, span, icx.query));\n \n-                    // Generate an id unique within this shard.\n-                    let id = lock.jobs.checked_add(1).unwrap();\n-                    lock.jobs = id;\n-                    let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n+                entry.insert(QueryResult::Started(job));\n \n-                    let global_id = QueryJobId::new(id, shard, Q::dep_kind());\n-\n-                    let job =\n-                        tls::with_related_context(tcx, |icx| QueryJob::new(id, span, icx.query));\n+                let owner =\n+                    JobOwner { cache: Q::query_cache(tcx), id: global_id, key: (*key).clone() };\n+                return TryGetJob::NotYetStarted(owner);\n+            }\n+        };\n+        mem::drop(lookup.lock);\n \n-                    entry.insert(QueryResult::Started(job));\n+        // If we are single-threaded we know that we have cycle error,\n+        // so we just return the error.\n+        #[cfg(not(parallel_compiler))]\n+        return TryGetJob::Cycle(cold_path(|| {\n+            Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n+        }));\n \n-                    let owner = JobOwner { cache, id: global_id, key: (*key).clone() };\n-                    return TryGetJob::NotYetStarted(owner);\n-                }\n-            };\n-            mem::drop(lock_guard);\n+        // With parallel queries we might just have to wait on some other\n+        // thread.\n+        #[cfg(parallel_compiler)]\n+        {\n+            let result = latch.wait_on(tcx, span);\n \n-            // If we are single-threaded we know that we have cycle error,\n-            // so we just return the error.\n-            #[cfg(not(parallel_compiler))]\n-            return TryGetJob::Cycle(cold_path(|| {\n-                Q::handle_cycle_error(tcx, latch.find_cycle_in_stack(tcx, span))\n-            }));\n+            if let Err(cycle) = result {\n+                return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n+            }\n \n-            // With parallel queries we might just have to wait on some other\n-            // thread.\n-            #[cfg(parallel_compiler)]\n-            {\n-                let result = latch.wait_on(tcx, span);\n+            let cached = tcx.try_get_cached::<Q>(key).0.unwrap();\n \n-                if let Err(cycle) = result {\n-                    return TryGetJob::Cycle(Q::handle_cycle_error(tcx, cycle));\n-                }\n+            if let Some(prof_timer) = _query_blocked_prof_timer.take() {\n+                prof_timer.finish_with_query_invocation_id(cached.1.into());\n             }\n+\n+            return TryGetJob::JobCompleted(cached);\n         }\n     }\n \n@@ -269,6 +241,7 @@ pub(super) enum TryGetJob<'a, 'tcx, D: QueryDescription<'tcx>> {\n     /// The query was already completed.\n     /// Returns the result of the query and its dep-node index\n     /// if it succeeded or a cycle error if it failed.\n+    #[cfg(parallel_compiler)]\n     JobCompleted((D::Value, DepNodeIndex)),\n \n     /// Trying to execute the query resulted in a cycle.\n@@ -396,13 +369,76 @@ impl<'tcx> TyCtxt<'tcx> {\n         eprintln!(\"end of query stack\");\n     }\n \n+    /// Checks if the query is already computed and in the cache.\n+    /// It returns the shard index and a lock guard to the shard,\n+    /// which will be used if the query is not in the cache and we need\n+    /// to compute it.\n+    #[inline(always)]\n+    fn try_get_cached<Q: QueryDescription<'tcx>>(\n+        self,\n+        key: &Q::Key,\n+    ) -> (Option<(Q::Value, DepNodeIndex)>, QueryLookup<'tcx, Q>) {\n+        let cache = Q::query_cache(self);\n+\n+        // We compute the key's hash once and then use it for both the\n+        // shard lookup and the hashmap lookup. This relies on the fact\n+        // that both of them use `FxHasher`.\n+        let mut state = FxHasher::default();\n+        key.hash(&mut state);\n+        let key_hash = state.finish();\n+\n+        let shard = cache.get_shard_index_by_hash(key_hash);\n+        let mut lock_guard = cache.get_shard_by_index(shard).lock();\n+        let lock = &mut *lock_guard;\n+\n+        let result =\n+            lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key).map(|(_, value)| {\n+                if unlikely!(self.prof.enabled()) {\n+                    self.prof.query_cache_hit(value.index.into());\n+                }\n+\n+                (value.value.clone(), value.index)\n+            });\n+\n+        #[cfg(debug_assertions)]\n+        {\n+            if result.is_some() {\n+                lock.cache_hits += 1;\n+            }\n+        }\n+\n+        (result, QueryLookup { lock: lock_guard, shard })\n+    }\n+\n     #[inline(never)]\n-    pub(super) fn get_query<Q: QueryDescription<'tcx>>(self, span: Span, key: Q::Key) -> Q::Value {\n+    pub(super) fn get_query<Q: QueryDescription<'tcx> + 'tcx>(\n+        self,\n+        span: Span,\n+        key: Q::Key,\n+    ) -> Q::Value {\n         debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n-        let job = match JobOwner::try_get(self, span, &key) {\n+        let (cached, lookup) = self.try_get_cached::<Q>(&key);\n+\n+        if let Some((v, index)) = cached {\n+            self.dep_graph.read_index(index);\n+            return v;\n+        }\n+\n+        self.try_execute_query(span, key, lookup)\n+    }\n+\n+    #[inline(always)]\n+    pub(super) fn try_execute_query<Q: QueryDescription<'tcx>>(\n+        self,\n+        span: Span,\n+        key: Q::Key,\n+        lookup: QueryLookup<'tcx, Q>,\n+    ) -> Q::Value {\n+        let job = match JobOwner::try_start(self, span, &key, lookup) {\n             TryGetJob::NotYetStarted(job) => job,\n             TryGetJob::Cycle(result) => return result,\n+            #[cfg(parallel_compiler)]\n             TryGetJob::JobCompleted((v, index)) => {\n                 self.dep_graph.read_index(index);\n                 return v;\n@@ -615,7 +651,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     /// side-effects -- e.g., in order to report errors for erroneous programs.\n     ///\n     /// Note: The optimization is only available during incr. comp.\n-    pub(super) fn ensure_query<Q: QueryDescription<'tcx>>(self, key: Q::Key) -> () {\n+    pub(super) fn ensure_query<Q: QueryDescription<'tcx> + 'tcx>(self, key: Q::Key) -> () {\n         if Q::EVAL_ALWAYS {\n             let _ = self.get_query::<Q>(DUMMY_SP, key);\n             return;\n@@ -643,12 +679,26 @@ impl<'tcx> TyCtxt<'tcx> {\n     }\n \n     #[allow(dead_code)]\n-    fn force_query<Q: QueryDescription<'tcx>>(self, key: Q::Key, span: Span, dep_node: DepNode) {\n+    fn force_query<Q: QueryDescription<'tcx> + 'tcx>(\n+        self,\n+        key: Q::Key,\n+        span: Span,\n+        dep_node: DepNode,\n+    ) {\n         // We may be concurrently trying both execute and force a query.\n         // Ensure that only one of them runs the query.\n-        let job = match JobOwner::try_get(self, span, &key) {\n+\n+        let (cached, lookup) = self.try_get_cached::<Q>(&key);\n+\n+        if cached.is_some() {\n+            return;\n+        }\n+\n+        let job = match JobOwner::try_start(self, span, &key, lookup) {\n             TryGetJob::NotYetStarted(job) => job,\n-            TryGetJob::Cycle(_) | TryGetJob::JobCompleted(_) => return,\n+            TryGetJob::Cycle(_) => return,\n+            #[cfg(parallel_compiler)]\n+            TryGetJob::JobCompleted(_) => return,\n         };\n         self.force_query_with_job::<Q>(key, job, dep_node);\n     }"}]}