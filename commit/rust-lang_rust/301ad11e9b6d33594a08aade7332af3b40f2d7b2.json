{"sha": "301ad11e9b6d33594a08aade7332af3b40f2d7b2", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMwMWFkMTFlOWI2ZDMzNTk0YTA4YWFkZTczMzJhZjNiNDBmMmQ3YjI=", "commit": {"author": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2020-03-26T08:40:50Z"}, "committer": {"name": "Camille GILLOT", "email": "gillot.camille@gmail.com", "date": "2020-03-26T08:40:50Z"}, "message": "Rustfmt.", "tree": {"sha": "a39c40c6da80e74d72780389875b47edb4c70c96", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a39c40c6da80e74d72780389875b47edb4c70c96"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/301ad11e9b6d33594a08aade7332af3b40f2d7b2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/301ad11e9b6d33594a08aade7332af3b40f2d7b2", "html_url": "https://github.com/rust-lang/rust/commit/301ad11e9b6d33594a08aade7332af3b40f2d7b2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/301ad11e9b6d33594a08aade7332af3b40f2d7b2/comments", "author": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cjgillot", "id": 1822483, "node_id": "MDQ6VXNlcjE4MjI0ODM=", "avatar_url": "https://avatars.githubusercontent.com/u/1822483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cjgillot", "html_url": "https://github.com/cjgillot", "followers_url": "https://api.github.com/users/cjgillot/followers", "following_url": "https://api.github.com/users/cjgillot/following{/other_user}", "gists_url": "https://api.github.com/users/cjgillot/gists{/gist_id}", "starred_url": "https://api.github.com/users/cjgillot/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cjgillot/subscriptions", "organizations_url": "https://api.github.com/users/cjgillot/orgs", "repos_url": "https://api.github.com/users/cjgillot/repos", "events_url": "https://api.github.com/users/cjgillot/events{/privacy}", "received_events_url": "https://api.github.com/users/cjgillot/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dca03443a02793aed40d3796460d541311300877", "url": "https://api.github.com/repos/rust-lang/rust/commits/dca03443a02793aed40d3796460d541311300877", "html_url": "https://github.com/rust-lang/rust/commit/dca03443a02793aed40d3796460d541311300877"}], "stats": {"total": 497, "additions": 246, "deletions": 251}, "files": [{"sha": "4d9d439c526e6606ab58567b6e0eaed1317f50dd", "filename": "src/librustc/dep_graph/mod.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fmod.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -166,7 +166,11 @@ impl<'tcx> DepContext for TyCtxt<'tcx> {\n         self.queries.on_disk_cache.store_diagnostics(dep_node_index, diagnostics)\n     }\n \n-    fn store_diagnostics_for_anon_node(&self, dep_node_index: DepNodeIndex, diagnostics: ThinVec<Diagnostic>) {\n+    fn store_diagnostics_for_anon_node(\n+        &self,\n+        dep_node_index: DepNodeIndex,\n+        diagnostics: ThinVec<Diagnostic>,\n+    ) {\n         self.queries.on_disk_cache.store_diagnostics_for_anon_node(dep_node_index, diagnostics)\n     }\n "}, {"sha": "fb699c6fae0c78e4989f15d981066fbe471ce90f", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -149,7 +149,8 @@ impl<'tcx> TyCtxt<'tcx> {\n                             query_info.info.query.describe(icx.tcx)\n                         ),\n                     );\n-                    diag.span = icx.tcx.sess.source_map().guess_head_span(query_info.info.span).into();\n+                    diag.span =\n+                        icx.tcx.sess.source_map().guess_head_span(query_info.info.span).into();\n                     handler.force_print_diagnostic(diag);\n \n                     current_query = query_info.job.parent;"}, {"sha": "2faca54621340fb1b8d080d352ef313070b57555", "filename": "src/librustc_query_system/dep_graph/mod.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fdep_graph%2Fmod.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -49,7 +49,11 @@ pub trait DepContext: Copy + DepGraphSafe {\n     fn store_diagnostics(&self, dep_node_index: DepNodeIndex, diagnostics: ThinVec<Diagnostic>);\n \n     /// Register diagnostics for the given node, for use in next session.\n-    fn store_diagnostics_for_anon_node(&self, dep_node_index: DepNodeIndex, diagnostics: ThinVec<Diagnostic>);\n+    fn store_diagnostics_for_anon_node(\n+        &self,\n+        dep_node_index: DepNodeIndex,\n+        diagnostics: ThinVec<Diagnostic>,\n+    );\n \n     /// Access the profiler.\n     fn profiler(&self) -> &SelfProfilerRef;"}, {"sha": "92ab97f210a5deadd5cb90fdd7140e6ea654535d", "filename": "src/librustc_query_system/query/job.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fjob.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -1,4 +1,4 @@\n-use crate::dep_graph::{DepKind, DepContext};\n+use crate::dep_graph::{DepContext, DepKind};\n use crate::query::config::QueryContext;\n use crate::query::plumbing::CycleError;\n "}, {"sha": "9d0a6665eac60c8c6aa84f6c2e1b7066e1ef8ea6", "filename": "src/librustc_query_system/query/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fmod.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -2,9 +2,9 @@ mod plumbing;\n pub use self::plumbing::*;\n \n mod job;\n-pub use self::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n #[cfg(parallel_compiler)]\n pub use self::job::deadlock;\n+pub use self::job::{QueryInfo, QueryJob, QueryJobId, QueryJobInfo};\n \n mod caches;\n pub use self::caches::{CacheSelector, DefaultCacheSelector, QueryCache};"}, {"sha": "6fd86d65c1d4a09a9e0a0f11710b7e7a1bc64ca6", "filename": "src/librustc_query_system/query/plumbing.rs", "status": "modified", "additions": 232, "deletions": 246, "changes": 478, "blob_url": "https://github.com/rust-lang/rust/blob/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/301ad11e9b6d33594a08aade7332af3b40f2d7b2/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_query_system%2Fquery%2Fplumbing.rs?ref=301ad11e9b6d33594a08aade7332af3b40f2d7b2", "patch": "@@ -2,7 +2,7 @@\n //! generate the actual methods on tcx which find and execute the provider,\n //! manage the caches, and so forth.\n \n-use crate::dep_graph::{DepKind, DepContext, DepNode};\n+use crate::dep_graph::{DepContext, DepKind, DepNode};\n use crate::dep_graph::{DepNodeIndex, SerializedDepNodeIndex};\n use crate::query::caches::QueryCache;\n use crate::query::config::{QueryContext, QueryDescription};\n@@ -351,285 +351,275 @@ where\n     Cycle(C::Value),\n }\n \n-    /// Checks if the query is already computed and in the cache.\n-    /// It returns the shard index and a lock guard to the shard,\n-    /// which will be used if the query is not in the cache and we need\n-    /// to compute it.\n-    #[inline(always)]\n-    fn try_get_cached<CTX, C, R, OnHit, OnMiss>(\n-        tcx: CTX,\n-        state: &QueryState<CTX, C>,\n-        key: C::Key,\n-        // `on_hit` can be called while holding a lock to the query cache\n-        on_hit: OnHit,\n-        on_miss: OnMiss,\n-    ) -> R\n-    where\n-        C: QueryCache<CTX>,\n-        CTX: QueryContext,\n-        OnHit: FnOnce(&C::Value, DepNodeIndex) -> R,\n-        OnMiss: FnOnce(C::Key, QueryLookup<'_, CTX, C::Key, C::Sharded>) -> R,\n-    {\n-        state.cache.lookup(\n-            state,\n-            QueryStateShard::<CTX, C::Key, C::Sharded>::get_cache,\n-            key,\n-            |value, index| {\n-                if unlikely!(tcx.profiler().enabled()) {\n-                    tcx.profiler().query_cache_hit(index.into());\n-                }\n-                #[cfg(debug_assertions)]\n-                {\n-                    state.cache_hits.fetch_add(1, Ordering::Relaxed);\n-                }\n-                on_hit(value, index)\n-            },\n-            on_miss,\n-        )\n-    }\n-\n-    #[inline(always)]\n-    fn try_execute_query<Q, CTX, K>(\n-        tcx: CTX,\n-        span: Span,\n-        key: Q::Key,\n-        lookup: QueryLookup<\n-            '_,\n-            CTX,\n-            Q::Key,\n-            <Q::Cache as QueryCache<CTX>>::Sharded,\n-        >,\n-    ) -> Q::Value\n-    where\n-        Q: QueryDescription<CTX>,\n-        CTX: QueryContext<DepKind = K>,\n-        CTX: HashStableContextProvider<<CTX as DepContext>::StableHashingContext>,\n-        K: DepKind,\n-    {\n-        let job = match JobOwner::try_start::<Q, _>(tcx, span, &key, lookup) {\n-            TryGetJob::NotYetStarted(job) => job,\n-            TryGetJob::Cycle(result) => return result,\n-            #[cfg(parallel_compiler)]\n-            TryGetJob::JobCompleted((v, index)) => {\n-                tcx.dep_graph().read_index(index);\n-                return v;\n+/// Checks if the query is already computed and in the cache.\n+/// It returns the shard index and a lock guard to the shard,\n+/// which will be used if the query is not in the cache and we need\n+/// to compute it.\n+#[inline(always)]\n+fn try_get_cached<CTX, C, R, OnHit, OnMiss>(\n+    tcx: CTX,\n+    state: &QueryState<CTX, C>,\n+    key: C::Key,\n+    // `on_hit` can be called while holding a lock to the query cache\n+    on_hit: OnHit,\n+    on_miss: OnMiss,\n+) -> R\n+where\n+    C: QueryCache<CTX>,\n+    CTX: QueryContext,\n+    OnHit: FnOnce(&C::Value, DepNodeIndex) -> R,\n+    OnMiss: FnOnce(C::Key, QueryLookup<'_, CTX, C::Key, C::Sharded>) -> R,\n+{\n+    state.cache.lookup(\n+        state,\n+        QueryStateShard::<CTX, C::Key, C::Sharded>::get_cache,\n+        key,\n+        |value, index| {\n+            if unlikely!(tcx.profiler().enabled()) {\n+                tcx.profiler().query_cache_hit(index.into());\n             }\n-        };\n+            #[cfg(debug_assertions)]\n+            {\n+                state.cache_hits.fetch_add(1, Ordering::Relaxed);\n+            }\n+            on_hit(value, index)\n+        },\n+        on_miss,\n+    )\n+}\n \n-        // Fast path for when incr. comp. is off. `to_dep_node` is\n-        // expensive for some `DepKind`s.\n-        if !tcx.dep_graph().is_fully_enabled() {\n-            let null_dep_node = DepNode::new_no_params(DepKind::NULL);\n-            return force_query_with_job::<Q, _, _>(tcx, key, job, null_dep_node).0;\n+#[inline(always)]\n+fn try_execute_query<Q, CTX, K>(\n+    tcx: CTX,\n+    span: Span,\n+    key: Q::Key,\n+    lookup: QueryLookup<'_, CTX, Q::Key, <Q::Cache as QueryCache<CTX>>::Sharded>,\n+) -> Q::Value\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext<DepKind = K>,\n+    CTX: HashStableContextProvider<<CTX as DepContext>::StableHashingContext>,\n+    K: DepKind,\n+{\n+    let job = match JobOwner::try_start::<Q, _>(tcx, span, &key, lookup) {\n+        TryGetJob::NotYetStarted(job) => job,\n+        TryGetJob::Cycle(result) => return result,\n+        #[cfg(parallel_compiler)]\n+        TryGetJob::JobCompleted((v, index)) => {\n+            tcx.dep_graph().read_index(index);\n+            return v;\n         }\n+    };\n \n-        if Q::ANON {\n-            let prof_timer = tcx.profiler().query_provider();\n-\n-            let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-                tcx.start_query(job.id, diagnostics, |tcx| {\n-                    tcx.dep_graph().with_anon_task(Q::DEP_KIND, || Q::compute(tcx, key))\n-                })\n-            });\n+    // Fast path for when incr. comp. is off. `to_dep_node` is\n+    // expensive for some `DepKind`s.\n+    if !tcx.dep_graph().is_fully_enabled() {\n+        let null_dep_node = DepNode::new_no_params(DepKind::NULL);\n+        return force_query_with_job::<Q, _, _>(tcx, key, job, null_dep_node).0;\n+    }\n \n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+    if Q::ANON {\n+        let prof_timer = tcx.profiler().query_provider();\n \n-            tcx.dep_graph().read_index(dep_node_index);\n+        let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n+            tcx.start_query(job.id, diagnostics, |tcx| {\n+                tcx.dep_graph().with_anon_task(Q::DEP_KIND, || Q::compute(tcx, key))\n+            })\n+        });\n \n-            if unlikely!(!diagnostics.is_empty()) {\n-                tcx.store_diagnostics_for_anon_node(dep_node_index, diagnostics);\n-            }\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-            job.complete(tcx, &result, dep_node_index);\n+        tcx.dep_graph().read_index(dep_node_index);\n \n-            return result;\n+        if unlikely!(!diagnostics.is_empty()) {\n+            tcx.store_diagnostics_for_anon_node(dep_node_index, diagnostics);\n         }\n \n-        let dep_node = Q::to_dep_node(tcx, &key);\n-\n-        if !Q::EVAL_ALWAYS {\n-            // The diagnostics for this query will be\n-            // promoted to the current session during\n-            // `try_mark_green()`, so we can ignore them here.\n-            let loaded = tcx.start_query(job.id, None, |tcx| {\n-                let marked = tcx.dep_graph().try_mark_green_and_read(tcx, &dep_node);\n-                marked.map(|(prev_dep_node_index, dep_node_index)| {\n-                    (\n-                        load_from_disk_and_cache_in_memory::<Q, _>(\n-                            tcx,\n-                            key.clone(),\n-                            prev_dep_node_index,\n-                            dep_node_index,\n-                            &dep_node,\n-                        ),\n+        job.complete(tcx, &result, dep_node_index);\n+\n+        return result;\n+    }\n+\n+    let dep_node = Q::to_dep_node(tcx, &key);\n+\n+    if !Q::EVAL_ALWAYS {\n+        // The diagnostics for this query will be\n+        // promoted to the current session during\n+        // `try_mark_green()`, so we can ignore them here.\n+        let loaded = tcx.start_query(job.id, None, |tcx| {\n+            let marked = tcx.dep_graph().try_mark_green_and_read(tcx, &dep_node);\n+            marked.map(|(prev_dep_node_index, dep_node_index)| {\n+                (\n+                    load_from_disk_and_cache_in_memory::<Q, _>(\n+                        tcx,\n+                        key.clone(),\n+                        prev_dep_node_index,\n                         dep_node_index,\n-                    )\n-                })\n-            });\n-            if let Some((result, dep_node_index)) = loaded {\n-                job.complete(tcx, &result, dep_node_index);\n-                return result;\n-            }\n+                        &dep_node,\n+                    ),\n+                    dep_node_index,\n+                )\n+            })\n+        });\n+        if let Some((result, dep_node_index)) = loaded {\n+            job.complete(tcx, &result, dep_node_index);\n+            return result;\n         }\n-\n-        let (result, dep_node_index) = force_query_with_job::<Q, _, _>(tcx, key, job, dep_node);\n-        tcx.dep_graph().read_index(dep_node_index);\n-        result\n     }\n \n-    fn load_from_disk_and_cache_in_memory<Q, CTX>(\n-        tcx: CTX,\n-        key: Q::Key,\n-        prev_dep_node_index: SerializedDepNodeIndex,\n-        dep_node_index: DepNodeIndex,\n-        dep_node: &DepNode<CTX::DepKind>,\n-    ) -> Q::Value\n-    where\n-        CTX: QueryContext,\n-        Q: QueryDescription<CTX>,\n-    {\n-        // Note this function can be called concurrently from the same query\n-        // We must ensure that this is handled correctly.\n-\n-        debug_assert!(tcx.dep_graph().is_green(dep_node));\n-\n-        // First we try to load the result from the on-disk cache.\n-        let result = if Q::cache_on_disk(tcx, key.clone(), None) {\n-            let prof_timer = tcx.profiler().incr_cache_loading();\n-            let result = Q::try_load_from_disk(tcx, prev_dep_node_index);\n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n-\n-            // We always expect to find a cached result for things that\n-            // can be forced from `DepNode`.\n-            debug_assert!(\n-                !dep_node.kind.can_reconstruct_query_key() || result.is_some(),\n-                \"missing on-disk cache entry for {:?}\",\n-                dep_node\n-            );\n-            result\n-        } else {\n-            // Some things are never cached on disk.\n-            None\n-        };\n+    let (result, dep_node_index) = force_query_with_job::<Q, _, _>(tcx, key, job, dep_node);\n+    tcx.dep_graph().read_index(dep_node_index);\n+    result\n+}\n \n-        let result = if let Some(result) = result {\n-            result\n-        } else {\n-            // We could not load a result from the on-disk cache, so\n-            // recompute.\n-            let prof_timer = tcx.profiler().query_provider();\n+fn load_from_disk_and_cache_in_memory<Q, CTX>(\n+    tcx: CTX,\n+    key: Q::Key,\n+    prev_dep_node_index: SerializedDepNodeIndex,\n+    dep_node_index: DepNodeIndex,\n+    dep_node: &DepNode<CTX::DepKind>,\n+) -> Q::Value\n+where\n+    CTX: QueryContext,\n+    Q: QueryDescription<CTX>,\n+{\n+    // Note this function can be called concurrently from the same query\n+    // We must ensure that this is handled correctly.\n \n-            // The dep-graph for this computation is already in-place.\n-            let result = tcx.dep_graph().with_ignore(|| Q::compute(tcx, key));\n+    debug_assert!(tcx.dep_graph().is_green(dep_node));\n \n-            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+    // First we try to load the result from the on-disk cache.\n+    let result = if Q::cache_on_disk(tcx, key.clone(), None) {\n+        let prof_timer = tcx.profiler().incr_cache_loading();\n+        let result = Q::try_load_from_disk(tcx, prev_dep_node_index);\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-            result\n-        };\n+        // We always expect to find a cached result for things that\n+        // can be forced from `DepNode`.\n+        debug_assert!(\n+            !dep_node.kind.can_reconstruct_query_key() || result.is_some(),\n+            \"missing on-disk cache entry for {:?}\",\n+            dep_node\n+        );\n+        result\n+    } else {\n+        // Some things are never cached on disk.\n+        None\n+    };\n \n-        // If `-Zincremental-verify-ich` is specified, re-hash results from\n-        // the cache and make sure that they have the expected fingerprint.\n-        if unlikely!(tcx.session().opts.debugging_opts.incremental_verify_ich) {\n-            incremental_verify_ich::<Q, _>(tcx, &result, dep_node, dep_node_index);\n-        }\n+    let result = if let Some(result) = result {\n+        result\n+    } else {\n+        // We could not load a result from the on-disk cache, so\n+        // recompute.\n+        let prof_timer = tcx.profiler().query_provider();\n+\n+        // The dep-graph for this computation is already in-place.\n+        let result = tcx.dep_graph().with_ignore(|| Q::compute(tcx, key));\n+\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n         result\n+    };\n+\n+    // If `-Zincremental-verify-ich` is specified, re-hash results from\n+    // the cache and make sure that they have the expected fingerprint.\n+    if unlikely!(tcx.session().opts.debugging_opts.incremental_verify_ich) {\n+        incremental_verify_ich::<Q, _>(tcx, &result, dep_node, dep_node_index);\n     }\n \n-    #[inline(never)]\n-    #[cold]\n-    fn incremental_verify_ich<Q, CTX>(\n-        tcx: CTX,\n-        result: &Q::Value,\n-        dep_node: &DepNode<CTX::DepKind>,\n-        dep_node_index: DepNodeIndex,\n-    )\n-    where\n-        CTX: QueryContext,\n-        Q: QueryDescription<CTX>,\n-    {\n-        assert!(\n-            Some(tcx.dep_graph().fingerprint_of(dep_node_index))\n-                == tcx.dep_graph().prev_fingerprint_of(dep_node),\n-            \"fingerprint for green query instance not loaded from cache: {:?}\",\n-            dep_node,\n-        );\n+    result\n+}\n \n-        debug!(\"BEGIN verify_ich({:?})\", dep_node);\n-        let mut hcx = tcx.create_stable_hashing_context();\n+#[inline(never)]\n+#[cold]\n+fn incremental_verify_ich<Q, CTX>(\n+    tcx: CTX,\n+    result: &Q::Value,\n+    dep_node: &DepNode<CTX::DepKind>,\n+    dep_node_index: DepNodeIndex,\n+) where\n+    CTX: QueryContext,\n+    Q: QueryDescription<CTX>,\n+{\n+    assert!(\n+        Some(tcx.dep_graph().fingerprint_of(dep_node_index))\n+            == tcx.dep_graph().prev_fingerprint_of(dep_node),\n+        \"fingerprint for green query instance not loaded from cache: {:?}\",\n+        dep_node,\n+    );\n \n-        let new_hash = Q::hash_result(&mut hcx, result).unwrap_or(Fingerprint::ZERO);\n-        debug!(\"END verify_ich({:?})\", dep_node);\n+    debug!(\"BEGIN verify_ich({:?})\", dep_node);\n+    let mut hcx = tcx.create_stable_hashing_context();\n \n-        let old_hash = tcx.dep_graph().fingerprint_of(dep_node_index);\n+    let new_hash = Q::hash_result(&mut hcx, result).unwrap_or(Fingerprint::ZERO);\n+    debug!(\"END verify_ich({:?})\", dep_node);\n \n-        assert!(new_hash == old_hash, \"found unstable fingerprints for {:?}\", dep_node,);\n-    }\n+    let old_hash = tcx.dep_graph().fingerprint_of(dep_node_index);\n \n-    #[inline(always)]\n-    fn force_query_with_job<Q, CTX, K>(\n-        tcx: CTX,\n-        key: Q::Key,\n-        job: JobOwner<'_, CTX, Q::Cache>,\n-        dep_node: DepNode<CTX::DepKind>,\n-    ) -> (Q::Value, DepNodeIndex)\n-    where\n-        Q: QueryDescription<CTX>,\n-        CTX: QueryContext<DepKind = K>,\n-        CTX: HashStableContextProvider<<CTX as DepContext>::StableHashingContext>,\n-        K: DepKind,\n-    {\n-        // If the following assertion triggers, it can have two reasons:\n-        // 1. Something is wrong with DepNode creation, either here or\n-        //    in `DepGraph::try_mark_green()`.\n-        // 2. Two distinct query keys get mapped to the same `DepNode`\n-        //    (see for example #48923).\n-        assert!(\n-            !tcx.dep_graph().dep_node_exists(&dep_node),\n-            \"forcing query with already existing `DepNode`\\n\\\n+    assert!(new_hash == old_hash, \"found unstable fingerprints for {:?}\", dep_node,);\n+}\n+\n+#[inline(always)]\n+fn force_query_with_job<Q, CTX, K>(\n+    tcx: CTX,\n+    key: Q::Key,\n+    job: JobOwner<'_, CTX, Q::Cache>,\n+    dep_node: DepNode<CTX::DepKind>,\n+) -> (Q::Value, DepNodeIndex)\n+where\n+    Q: QueryDescription<CTX>,\n+    CTX: QueryContext<DepKind = K>,\n+    CTX: HashStableContextProvider<<CTX as DepContext>::StableHashingContext>,\n+    K: DepKind,\n+{\n+    // If the following assertion triggers, it can have two reasons:\n+    // 1. Something is wrong with DepNode creation, either here or\n+    //    in `DepGraph::try_mark_green()`.\n+    // 2. Two distinct query keys get mapped to the same `DepNode`\n+    //    (see for example #48923).\n+    assert!(\n+        !tcx.dep_graph().dep_node_exists(&dep_node),\n+        \"forcing query with already existing `DepNode`\\n\\\n                  - query-key: {:?}\\n\\\n                  - dep-node: {:?}\",\n-            key,\n-            dep_node\n-        );\n-\n-        let prof_timer = tcx.profiler().query_provider();\n+        key,\n+        dep_node\n+    );\n \n-        let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-            tcx.start_query(job.id, diagnostics, |tcx| {\n-                if Q::EVAL_ALWAYS {\n-                    tcx.dep_graph().with_eval_always_task(\n-                        dep_node,\n-                        tcx,\n-                        key,\n-                        Q::compute,\n-                        Q::hash_result,\n-                    )\n-                } else {\n-                    tcx.dep_graph().with_task(dep_node, tcx, key, Q::compute, Q::hash_result)\n-                }\n-            })\n-        });\n+    let prof_timer = tcx.profiler().query_provider();\n+\n+    let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n+        tcx.start_query(job.id, diagnostics, |tcx| {\n+            if Q::EVAL_ALWAYS {\n+                tcx.dep_graph().with_eval_always_task(\n+                    dep_node,\n+                    tcx,\n+                    key,\n+                    Q::compute,\n+                    Q::hash_result,\n+                )\n+            } else {\n+                tcx.dep_graph().with_task(dep_node, tcx, key, Q::compute, Q::hash_result)\n+            }\n+        })\n+    });\n \n-        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+    prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n-        if unlikely!(!diagnostics.is_empty()) {\n-            if dep_node.kind != DepKind::NULL {\n-                tcx.store_diagnostics(dep_node_index, diagnostics);\n-            }\n+    if unlikely!(!diagnostics.is_empty()) {\n+        if dep_node.kind != DepKind::NULL {\n+            tcx.store_diagnostics(dep_node_index, diagnostics);\n         }\n+    }\n \n-        job.complete(tcx, &result, dep_node_index);\n+    job.complete(tcx, &result, dep_node_index);\n \n-        (result, dep_node_index)\n-    }\n+    (result, dep_node_index)\n+}\n \n pub trait QueryGetter: QueryContext {\n-    fn get_query<Q: QueryDescription<Self>>(\n-        self,\n-        span: Span,\n-        key: Q::Key,\n-    ) -> Q::Value;\n+    fn get_query<Q: QueryDescription<Self>>(self, span: Span, key: Q::Key) -> Q::Value;\n \n     /// Ensure that either this query has all green inputs or been executed.\n     /// Executing `query::ensure(D)` is considered a read of the dep-node `D`.\n@@ -655,11 +645,7 @@ where\n     K: DepKind,\n {\n     #[inline(never)]\n-    fn get_query<Q: QueryDescription<Self>>(\n-        self,\n-        span: Span,\n-        key: Q::Key,\n-    ) -> Q::Value {\n+    fn get_query<Q: QueryDescription<Self>>(self, span: Span, key: Q::Key) -> Q::Value {\n         debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n         try_get_cached("}]}