{"sha": "1ae7de9a52d295a6c3d21af1915fc95951193b83", "node_id": "MDY6Q29tbWl0NzI0NzEyOjFhZTdkZTlhNTJkMjk1YTZjM2QyMWFmMTkxNWZjOTU5NTExOTNiODM=", "commit": {"author": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-05-29T04:19:10Z"}, "committer": {"name": "Aaron Hill", "email": "aa1ronham@gmail.com", "date": "2020-05-29T04:19:10Z"}, "message": "Revert \"Recursively expand nonterminals\"\n\nThis reverts commit 2af0218bf1ffca0750a352554f20a07b760a30a8.", "tree": {"sha": "90b5f22ab98bc5d0bc75290506148581c2a176fe", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/90b5f22ab98bc5d0bc75290506148581c2a176fe"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1ae7de9a52d295a6c3d21af1915fc95951193b83", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\niQIzBAABCAAdFiEE7J9Gc3TfBwj2K399tAh+UQ6YsWQFAl7QjT8ACgkQtAh+UQ6Y\nsWTM9w//UKm7gzOOXktVoYNpwaolI/ogLy/i4swalPaAOJLdp7D/v0wGqw7pXoJ4\n3mNY90iLHvXfFNpA5nAD/3X2PjnbbeV3llyJf9wqSdK/b116ebnBcfAwimydiJgH\nYQsdnnwnrX7SFKX+jgEF57mNKgkKx7OsoXVFJtUziKPzkXxgVw7km1/XTFYGZD5J\np54LDF7MDKkbc0L3khGw/dZ6idtSKiD8AItda4bH9mCng2105RSop45G52WwiF1t\nQiZ6/K+FW2dMgtXpxUQUecSg/dP7dCnfGb53XcoiAQiNGrkUUqPCgF7CwYz0PUYo\naNBzcY24U/8TzjIKhVGcZVsiNbkAmN/n+FoqkfGMW7iS1HfZM3qbQUT03/KYTEei\nCdRES8+qFu7abCzfgM1whtVMTOwLOJ1kvlDs2RUUfU8+76GEGyc7p1W55An6STRu\nwicQVTebUz4mQpFaXF9xzL9ebt9rysbGUNa9Q1FfHd/MQI8einKfxrZSXXxluM6Z\nhwvliW6OYmR+f2ud5k/YNbQrUG5IW+BqmiUS/df9Xfnd+65eDzED3SwJdXJkv6ZU\nzPrT+sovinqyddERW3G4MUm9o7jRLqtcI4qYBGDzqasJJZyd3DozzyrcoeS29Cl6\nqSNA5s1XTr674zosOjfonq4B2z0yQ+e9HSIbOwiucbYeZuit6lg=\n=MQgh\n-----END PGP SIGNATURE-----", "payload": "tree 90b5f22ab98bc5d0bc75290506148581c2a176fe\nparent 4d4facbe4f0290c511c21167e48074786ad75efd\nauthor Aaron Hill <aa1ronham@gmail.com> 1590725950 -0400\ncommitter Aaron Hill <aa1ronham@gmail.com> 1590725950 -0400\n\nRevert \"Recursively expand nonterminals\"\n\nThis reverts commit 2af0218bf1ffca0750a352554f20a07b760a30a8.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1ae7de9a52d295a6c3d21af1915fc95951193b83", "html_url": "https://github.com/rust-lang/rust/commit/1ae7de9a52d295a6c3d21af1915fc95951193b83", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1ae7de9a52d295a6c3d21af1915fc95951193b83/comments", "author": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Aaron1011", "id": 1408859, "node_id": "MDQ6VXNlcjE0MDg4NTk=", "avatar_url": "https://avatars.githubusercontent.com/u/1408859?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Aaron1011", "html_url": "https://github.com/Aaron1011", "followers_url": "https://api.github.com/users/Aaron1011/followers", "following_url": "https://api.github.com/users/Aaron1011/following{/other_user}", "gists_url": "https://api.github.com/users/Aaron1011/gists{/gist_id}", "starred_url": "https://api.github.com/users/Aaron1011/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Aaron1011/subscriptions", "organizations_url": "https://api.github.com/users/Aaron1011/orgs", "repos_url": "https://api.github.com/users/Aaron1011/repos", "events_url": "https://api.github.com/users/Aaron1011/events{/privacy}", "received_events_url": "https://api.github.com/users/Aaron1011/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "4d4facbe4f0290c511c21167e48074786ad75efd", "url": "https://api.github.com/repos/rust-lang/rust/commits/4d4facbe4f0290c511c21167e48074786ad75efd", "html_url": "https://github.com/rust-lang/rust/commit/4d4facbe4f0290c511c21167e48074786ad75efd"}], "stats": {"total": 111, "additions": 16, "deletions": 95}, "files": [{"sha": "7348c41dbe7785f9a6403b5b24090728c2492674", "filename": "src/librustc_ast/tokenstream.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/1ae7de9a52d295a6c3d21af1915fc95951193b83/src%2Flibrustc_ast%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1ae7de9a52d295a6c3d21af1915fc95951193b83/src%2Flibrustc_ast%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Ftokenstream.rs?ref=1ae7de9a52d295a6c3d21af1915fc95951193b83", "patch": "@@ -290,6 +290,8 @@ impl TokenStream {\n         t1.next().is_none() && t2.next().is_none()\n     }\n \n+\n+\n     pub fn map_enumerated<F: FnMut(usize, TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n         TokenStream(Lrc::new(\n             self.0"}, {"sha": "8aea8388d08b9508214d33f197b1cb10655f2a89", "filename": "src/librustc_parse/lib.rs", "status": "modified", "additions": 14, "deletions": 95, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/1ae7de9a52d295a6c3d21af1915fc95951193b83/src%2Flibrustc_parse%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1ae7de9a52d295a6c3d21af1915fc95951193b83/src%2Flibrustc_parse%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Flib.rs?ref=1ae7de9a52d295a6c3d21af1915fc95951193b83", "patch": "@@ -7,20 +7,20 @@\n #![feature(or_patterns)]\n \n use rustc_ast::ast;\n-use rustc_ast::token::{self, DelimToken, Nonterminal, Token, TokenKind};\n-use rustc_ast::tokenstream::{self, IsJoint, TokenStream, TokenTree};\n+use rustc_ast::token::{self, Nonterminal, Token, TokenKind, DelimToken};\n+use rustc_ast::tokenstream::{self, TokenStream, TokenTree};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Diagnostic, FatalError, Level, PResult};\n use rustc_session::parse::ParseSess;\n-use rustc_span::symbol::kw;\n use rustc_span::{FileName, SourceFile, Span};\n+use rustc_span::symbol::kw;\n \n-use std::mem;\n use std::path::Path;\n use std::str;\n+use std::mem;\n \n-use log::{debug, info};\n+use log::info;\n \n pub const MACRO_ARGUMENTS: Option<&'static str> = Some(\"macro arguments\");\n \n@@ -308,7 +308,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // modifications, including adding/removing typically non-semantic\n     // tokens such as extra braces and commas, don't happen.\n     if let Some(tokens) = tokens {\n-        if tokenstream_probably_equal_for_proc_macro(&tokens, &tokens_for_real, sess) {\n+        if tokenstream_probably_equal_for_proc_macro(&tokens, &tokens_for_real) {\n             return tokens;\n         }\n         info!(\n@@ -389,11 +389,7 @@ fn prepend_attrs(\n //\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n-pub fn tokenstream_probably_equal_for_proc_macro(\n-    first: &TokenStream,\n-    other: &TokenStream,\n-    sess: &ParseSess,\n-) -> bool {\n+pub fn tokenstream_probably_equal_for_proc_macro(first: &TokenStream, other: &TokenStream) -> bool {\n     // When checking for `probably_eq`, we ignore certain tokens that aren't\n     // preserved in the AST. Because they are not preserved, the pretty\n     // printer arbitrarily adds or removes them when printing as token\n@@ -421,83 +417,10 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n         true\n     }\n \n-    // When comparing two `TokenStream`s, we ignore the `IsJoint` information.\n-    //\n-    // However, `rustc_parse::lexer::tokentrees::TokenStreamBuilder` will\n-    // use `Token.glue` on adjacent tokens with the proper `IsJoint`.\n-    // Since we are ignoreing `IsJoint`, a 'glued' token (e.g. `BinOp(Shr)`)\n-    // and its 'split'/'unglued' compoenents (e.g. `Gt, Gt`) are equivalent\n-    // when determining if two `TokenStream`s are 'probably equal'.\n-    //\n-    // Therefore, we use `break_two_token_op` to convert all tokens\n-    // to the 'unglued' form (if it exists). This ensures that two\n-    // `TokenStream`s which differ only in how their tokens are glued\n-    // will be considered 'probably equal', which allows us to keep spans.\n-    //\n-    // This is important when the original `TokenStream` contained\n-    // extra spaces (e.g. `f :: < Vec < _ > > ( ) ;'). These extra spaces\n-    // will be omitted when we pretty-print, which can cause the original\n-    // and reparsed `TokenStream`s to differ in the assignment of `IsJoint`,\n-    // leading to some tokens being 'glued' together in one stream but not\n-    // the other. See #68489 for more details.\n-    fn break_tokens(tree: TokenTree) -> impl Iterator<Item = TokenTree> {\n-        // In almost all cases, we should have either zero or one levels\n-        // of 'unglueing'. However, in some unusual cases, we may need\n-        // to iterate breaking tokens mutliple times. For example:\n-        // '[BinOpEq(Shr)] => [Gt, Ge] -> [Gt, Gt, Eq]'\n-        let mut token_trees: SmallVec<[_; 2]>;\n-        if let TokenTree::Token(token) = &tree {\n-            let mut out = SmallVec::<[_; 2]>::new();\n-            out.push(token.clone());\n-            // Iterate to fixpoint:\n-            // * We start off with 'out' containing our initial token, and `temp` empty\n-            // * If we are able to break any tokens in `out`, then `out` will have\n-            //   at least one more element than 'temp', so we will try to break tokens\n-            //   again.\n-            // * If we cannot break any tokens in 'out', we are done\n-            loop {\n-                let mut temp = SmallVec::<[_; 2]>::new();\n-                let mut changed = false;\n-\n-                for token in out.into_iter() {\n-                    if let Some((first, second)) = token.kind.break_two_token_op() {\n-                        temp.push(Token::new(first, DUMMY_SP));\n-                        temp.push(Token::new(second, DUMMY_SP));\n-                        changed = true;\n-                    } else {\n-                        temp.push(token);\n-                    }\n-                }\n-                out = temp;\n-                if !changed {\n-                    break;\n-                }\n-            }\n-            token_trees = out.into_iter().map(|t| TokenTree::Token(t)).collect();\n-            if token_trees.len() != 1 {\n-                debug!(\"break_tokens: broke {:?} to {:?}\", tree, token_trees);\n-            }\n-        } else {\n-            token_trees = SmallVec::new();\n-            token_trees.push(tree);\n-        }\n-        token_trees.into_iter()\n-    }\n-\n-    let expand_nt = |tree: TokenTree| {\n-        if let TokenTree::Token(Token { kind: TokenKind::Interpolated(nt), span }) = &tree {\n-            nt_to_tokenstream(nt, sess, *span).into_trees()\n-        } else {\n-            TokenStream::new(vec![(tree, IsJoint::NonJoint)]).into_trees()\n-        }\n-    };\n-\n-    // Break tokens after we expand any nonterminals, so that we break tokens\n-    // that are produced as a result of nonterminal expansion.\n-    let mut t1 = first.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n-    let mut t2 = other.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n+    let mut t1 = first.trees().filter(semantic_tree);\n+    let mut t2 = other.trees().filter(semantic_tree);\n     for (t1, t2) in t1.by_ref().zip(t2.by_ref()) {\n-        if !tokentree_probably_equal_for_proc_macro(&t1, &t2, sess) {\n+        if !tokentree_probably_equal_for_proc_macro(&t1, &t2) {\n             return false;\n         }\n     }\n@@ -556,29 +479,25 @@ crate fn token_probably_equal_for_proc_macro(first: &Token, other: &Token) -> bo\n             b == d && (a == c || a == kw::DollarCrate || c == kw::DollarCrate)\n         }\n \n-        // Expanded by `tokenstream_probably_equal_for_proc_macro`\n-        (&Interpolated(_), &Interpolated(_)) => unreachable!(),\n+        (&Interpolated(_), &Interpolated(_)) => false,\n \n         _ => panic!(\"forgot to add a token?\"),\n     }\n }\n \n+\n // See comments in `Nonterminal::to_tokenstream` for why we care about\n // *probably* equal here rather than actual equality\n //\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n-pub fn tokentree_probably_equal_for_proc_macro(\n-    first: &TokenTree,\n-    other: &TokenTree,\n-    sess: &ParseSess,\n-) -> bool {\n+pub fn tokentree_probably_equal_for_proc_macro(first: &TokenTree, other: &TokenTree) -> bool {\n     match (first, other) {\n         (TokenTree::Token(token), TokenTree::Token(token2)) => {\n             token_probably_equal_for_proc_macro(token, token2)\n         }\n         (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n-            delim == delim2 && tokenstream_probably_equal_for_proc_macro(&tts, &tts2, sess)\n+            delim == delim2 && tokenstream_probably_equal_for_proc_macro(&tts, &tts2)\n         }\n         _ => false,\n     }"}]}