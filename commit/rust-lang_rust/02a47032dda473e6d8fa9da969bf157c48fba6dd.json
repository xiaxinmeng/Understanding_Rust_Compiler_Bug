{"sha": "02a47032dda473e6d8fa9da969bf157c48fba6dd", "node_id": "MDY6Q29tbWl0NzI0NzEyOjAyYTQ3MDMyZGRhNDczZTZkOGZhOWRhOTY5YmYxNTdjNDhmYmE2ZGQ=", "commit": {"author": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2016-08-06T00:14:47Z"}, "committer": {"name": "Niko Matsakis", "email": "niko@alum.mit.edu", "date": "2016-08-09T12:26:06Z"}, "message": "use preds to serialize just what we need\n\nThis massively speeds up serialization. It also\nseems to produce deterministic metadata hashes\n(before I was seeing inconsistent results).\n\nFixes #35232.", "tree": {"sha": "ad11a8b80b66e4e6f6b2a0d28e65e643046b5b9e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ad11a8b80b66e4e6f6b2a0d28e65e643046b5b9e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/02a47032dda473e6d8fa9da969bf157c48fba6dd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/02a47032dda473e6d8fa9da969bf157c48fba6dd", "html_url": "https://github.com/rust-lang/rust/commit/02a47032dda473e6d8fa9da969bf157c48fba6dd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/02a47032dda473e6d8fa9da969bf157c48fba6dd/comments", "author": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nikomatsakis", "id": 155238, "node_id": "MDQ6VXNlcjE1NTIzOA==", "avatar_url": "https://avatars.githubusercontent.com/u/155238?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikomatsakis", "html_url": "https://github.com/nikomatsakis", "followers_url": "https://api.github.com/users/nikomatsakis/followers", "following_url": "https://api.github.com/users/nikomatsakis/following{/other_user}", "gists_url": "https://api.github.com/users/nikomatsakis/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikomatsakis/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikomatsakis/subscriptions", "organizations_url": "https://api.github.com/users/nikomatsakis/orgs", "repos_url": "https://api.github.com/users/nikomatsakis/repos", "events_url": "https://api.github.com/users/nikomatsakis/events{/privacy}", "received_events_url": "https://api.github.com/users/nikomatsakis/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9978cbc8f42247ab75093b355b54e74b3efbcbf8", "url": "https://api.github.com/repos/rust-lang/rust/commits/9978cbc8f42247ab75093b355b54e74b3efbcbf8", "html_url": "https://github.com/rust-lang/rust/commit/9978cbc8f42247ab75093b355b54e74b3efbcbf8"}], "stats": {"total": 393, "additions": 178, "deletions": 215}, "files": [{"sha": "12f3ed8ae2bd4caefa6e1e32c3695ebd093e890d", "filename": "src/librustc_incremental/persist/data.rs", "status": "modified", "additions": 11, "deletions": 5, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fdata.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -19,7 +19,6 @@ use super::directory::DefPathIndex;\n /// Data for use when recompiling the **current crate**.\n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedDepGraph {\n-    pub nodes: Vec<DepNode<DefPathIndex>>,\n     pub edges: Vec<SerializedEdge>,\n \n     /// These are hashes of two things:\n@@ -44,15 +43,22 @@ pub struct SerializedDepGraph {\n     pub hashes: Vec<SerializedHash>,\n }\n \n+/// Represents a \"reduced\" dependency edge. Unlike the full dep-graph,\n+/// the dep-graph we serialize contains only edges `S -> T` where the\n+/// source `S` is something hashable (a HIR node or foreign metadata)\n+/// and the target `T` is something significant, like a work-product.\n+/// Normally, significant nodes are only those that have saved data on\n+/// disk, but in unit-testing the set of significant nodes can be\n+/// increased.\n pub type SerializedEdge = (DepNode<DefPathIndex>, DepNode<DefPathIndex>);\n \n #[derive(Debug, RustcEncodable, RustcDecodable)]\n pub struct SerializedHash {\n-    /// node being hashed; either a Hir or MetaData variant, in\n-    /// practice\n-    pub node: DepNode<DefPathIndex>,\n+    /// def-id of thing being hashed\n+    pub dep_node: DepNode<DefPathIndex>,\n \n-    /// the hash itself, computed by `calculate_item_hash`\n+    /// the hash as of previous compilation, computed by code in\n+    /// `hash` module\n     pub hash: u64,\n }\n "}, {"sha": "b704af12a6d9a0ad9dc182f92a433ba6d0c177b1", "filename": "src/librustc_incremental/persist/load.rs", "status": "modified", "additions": 69, "deletions": 120, "changes": 189, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fload.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fload.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -28,7 +28,7 @@ use super::dirty_clean;\n use super::hash::*;\n use super::util::*;\n \n-type DirtyNodes = FnvHashSet<DepNode<DefId>>;\n+type DirtyNodes = FnvHashSet<DepNode<DefPathIndex>>;\n \n type CleanEdges = Vec<(DepNode<DefId>, DepNode<DefId>)>;\n \n@@ -110,157 +110,106 @@ pub fn decode_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     // Retrace the paths in the directory to find their current location (if any).\n     let retraced = directory.retrace(tcx);\n \n-    // Compute the set of Hir nodes whose data has changed.\n-    let mut dirty_nodes =\n-        initial_dirty_nodes(tcx, &serialized_dep_graph.hashes, &retraced);\n-\n-    debug!(\"decode_dep_graph: initial dirty_nodes = {:#?}\", dirty_nodes);\n+    // TODO -- this could be more efficient if we integrated the `DefIdDirectory` and\n+    // pred set more deeply\n+\n+    // Compute the set of Hir nodes whose data has changed or which have been removed.\n+    let dirty_raw_source_nodes = dirty_nodes(tcx, &serialized_dep_graph.hashes, &retraced);\n+\n+    // Create a (maybe smaller) list of\n+    let retraced_edges: Vec<_> =\n+        serialized_dep_graph.edges.iter()\n+                                  .filter_map(|&(ref raw_source_node, ref raw_target_node)| {\n+                                      retraced.map(raw_target_node)\n+                                              .map(|target_node| (raw_source_node, target_node))\n+                                  })\n+                                  .collect();\n+\n+    // Compute which work-products have changed.\n+    let mut dirty_target_nodes = FnvHashSet();\n+    for &(raw_source_node, ref target_node) in &retraced_edges {\n+        if dirty_raw_source_nodes.contains(raw_source_node) {\n+            if !dirty_target_nodes.contains(target_node) {\n+                dirty_target_nodes.insert(target_node.clone());\n+\n+                if tcx.sess.opts.debugging_opts.incremental_info {\n+                    // It'd be nice to pretty-print these paths better than just\n+                    // using the `Debug` impls, but wev.\n+                    println!(\"module {:?} is dirty because {:?} changed or was removed\",\n+                             target_node,\n+                             raw_source_node.map_def(|&index| {\n+                                 Some(directory.def_path_string(tcx, index))\n+                             }).unwrap());\n+                }\n+            }\n+        }\n+    }\n \n-    // Find all DepNodes reachable from that core set. This loop\n-    // iterates repeatedly over the list of edges whose source is not\n-    // known to be dirty (`clean_edges`). If it finds an edge whose\n-    // source is dirty, it removes it from that list and adds the\n-    // target to `dirty_nodes`. It stops when it reaches a fixed\n-    // point.\n-    let clean_edges = compute_clean_edges(tcx,\n-                                          &directory,\n-                                          &serialized_dep_graph.edges,\n-                                          &retraced,\n-                                          &mut dirty_nodes);\n+    // For work-products that are still clean, add their deps into the\n+    // graph. This is needed because later we will have to save this\n+    // back out again!\n+    let dep_graph = tcx.dep_graph.clone();\n+    for (raw_source_node, target_node) in retraced_edges {\n+        if dirty_target_nodes.contains(&target_node) {\n+            continue;\n+        }\n \n-    // Add synthetic `foo->foo` edges for each clean node `foo` that\n-    // we had before. This is sort of a hack to create clean nodes in\n-    // the graph, since the existence of a node is a signal that the\n-    // work it represents need not be repeated.\n-    let clean_nodes =\n-        serialized_dep_graph.nodes\n-                            .iter()\n-                            .filter_map(|node| retraced.map(node))\n-                            .filter(|node| !dirty_nodes.contains(node))\n-                            .map(|node| (node.clone(), node));\n+        let source_node = retraced.map(raw_source_node).unwrap();\n \n-    // Add nodes and edges that are not dirty into our main graph.\n-    let dep_graph = tcx.dep_graph.clone();\n-    for (source, target) in clean_edges.into_iter().chain(clean_nodes) {\n-        debug!(\"decode_dep_graph: clean edge: {:?} -> {:?}\", source, target);\n+        debug!(\"decode_dep_graph: clean edge: {:?} -> {:?}\", source_node, target_node);\n \n-        let _task = dep_graph.in_task(target);\n-        dep_graph.read(source);\n+        let _task = dep_graph.in_task(target_node);\n+        dep_graph.read(source_node);\n     }\n \n     // Add in work-products that are still clean, and delete those that are\n     // dirty.\n     let mut work_product_decoder = Decoder::new(work_products_data, 0);\n     let work_products = try!(<Vec<SerializedWorkProduct>>::decode(&mut work_product_decoder));\n-    reconcile_work_products(tcx, work_products, &dirty_nodes);\n+    reconcile_work_products(tcx, work_products, &dirty_target_nodes);\n \n     Ok(())\n }\n \n-fn initial_dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                 hashes: &[SerializedHash],\n-                                 retraced: &RetracedDefIdDirectory)\n-                                 -> DirtyNodes {\n+/// Computes which of the original set of def-ids are dirty. Stored in\n+/// a bit vector where the index is the DefPathIndex.\n+fn dirty_nodes<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                         hashes: &[SerializedHash],\n+                         retraced: &RetracedDefIdDirectory)\n+                         -> DirtyNodes {\n     let mut hcx = HashContext::new(tcx);\n-    let mut items_removed = false;\n     let mut dirty_nodes = FnvHashSet();\n-    for hash in hashes {\n-        match hash.node.map_def(|&i| retraced.def_id(i)) {\n-            Some(dep_node) => {\n-                let (_, current_hash) = hcx.hash(&dep_node).unwrap();\n-                if current_hash != hash.hash {\n-                    debug!(\"initial_dirty_nodes: {:?} is dirty as hash is {:?}, was {:?}\",\n-                           dep_node.map_def(|&def_id| Some(tcx.def_path(def_id))).unwrap(),\n-                           current_hash,\n-                           hash.hash);\n-                    dirty_nodes.insert(dep_node);\n-                }\n-            }\n-            None => {\n-                items_removed = true;\n-            }\n-        }\n-    }\n \n-    // If any of the items in the krate have changed, then we consider\n-    // the meta-node `Krate` to be dirty, since that means something\n-    // which (potentially) read the contents of every single item.\n-    if items_removed || !dirty_nodes.is_empty() {\n-        dirty_nodes.insert(DepNode::Krate);\n-    }\n-\n-    dirty_nodes\n-}\n-\n-fn compute_clean_edges(tcx: TyCtxt,\n-                       directory: &DefIdDirectory,\n-                       serialized_edges: &[(SerializedEdge)],\n-                       retraced: &RetracedDefIdDirectory,\n-                       dirty_nodes: &mut DirtyNodes)\n-                       -> CleanEdges {\n-    // Build up an initial list of edges. Include an edge (source,\n-    // target) if neither node has been removed. If the source has\n-    // been removed, add target to the list of dirty nodes.\n-    let mut clean_edges = Vec::with_capacity(serialized_edges.len());\n-    for &(ref serialized_source, ref serialized_target) in serialized_edges {\n-        if let Some(target) = retraced.map(serialized_target) {\n-            if let Some(source) = retraced.map(serialized_source) {\n-                clean_edges.push((source, target))\n-            } else {\n-                // source removed, target must be dirty\n-                debug!(\"compute_clean_edges: {:?} dirty because {:?} no longer exists\",\n-                       target,\n-                       serialized_source.map_def(|&index| {\n-                           Some(directory.def_path_string(tcx, index))\n-                       }).unwrap());\n-\n-                dirty_nodes.insert(target);\n+    for hash in hashes {\n+        if let Some(dep_node) = retraced.map(&hash.dep_node) {\n+            let (_, current_hash) = hcx.hash(&dep_node).unwrap();\n+            if current_hash == hash.hash {\n+                continue;\n             }\n+            debug!(\"initial_dirty_nodes: {:?} is dirty as hash is {:?}, was {:?}\",\n+                   dep_node.map_def(|&def_id| Some(tcx.def_path(def_id))).unwrap(),\n+                   current_hash,\n+                   hash.hash);\n         } else {\n-            // target removed, ignore the edge\n+            debug!(\"initial_dirty_nodes: {:?} is dirty as it was removed\",\n+                   hash.dep_node);\n         }\n-    }\n \n-    debug!(\"compute_clean_edges: dirty_nodes={:#?}\", dirty_nodes);\n-\n-    // Propagate dirty marks by iterating repeatedly over\n-    // `clean_edges`. If we find an edge `(source, target)` where\n-    // `source` is dirty, add `target` to the list of dirty nodes and\n-    // remove it. Keep doing this until we find no more dirty nodes.\n-    let mut previous_size = 0;\n-    while dirty_nodes.len() > previous_size {\n-        debug!(\"compute_clean_edges: previous_size={}\", previous_size);\n-        previous_size = dirty_nodes.len();\n-        let mut i = 0;\n-        while i < clean_edges.len() {\n-            if dirty_nodes.contains(&clean_edges[i].0) {\n-                let (source, target) = clean_edges.swap_remove(i);\n-                debug!(\"compute_clean_edges: dirty source {:?} -> {:?}\",\n-                       source, target);\n-                dirty_nodes.insert(target);\n-            } else if dirty_nodes.contains(&clean_edges[i].1) {\n-                let (source, target) = clean_edges.swap_remove(i);\n-                debug!(\"compute_clean_edges: dirty target {:?} -> {:?}\",\n-                       source, target);\n-            } else {\n-                i += 1;\n-            }\n-        }\n+        dirty_nodes.insert(hash.dep_node.clone());\n     }\n \n-    clean_edges\n+    dirty_nodes\n }\n \n /// Go through the list of work-products produced in the previous run.\n /// Delete any whose nodes have been found to be dirty or which are\n /// otherwise no longer applicable.\n fn reconcile_work_products<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                      work_products: Vec<SerializedWorkProduct>,\n-                                     dirty_nodes: &DirtyNodes) {\n+                                     dirty_target_nodes: &FnvHashSet<DepNode<DefId>>) {\n     debug!(\"reconcile_work_products({:?})\", work_products);\n     for swp in work_products {\n-        let dep_node = DepNode::WorkProduct(swp.id.clone());\n-        if dirty_nodes.contains(&dep_node) {\n+        if dirty_target_nodes.contains(&DepNode::WorkProduct(swp.id.clone())) {\n             debug!(\"reconcile_work_products: dep-node for {:?} is dirty\", swp);\n             delete_dirty_work_product(tcx, swp);\n         } else {"}, {"sha": "049702a045103fe4abd6dd48757d35ef1bba5072", "filename": "src/librustc_incremental/persist/save.rs", "status": "modified", "additions": 86, "deletions": 84, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fpersist%2Fsave.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -9,11 +9,12 @@\n // except according to those terms.\n \n use rbml::opaque::Encoder;\n-use rustc::dep_graph::{DepGraphQuery, DepNode};\n+use rustc::dep_graph::DepNode;\n use rustc::hir::def_id::DefId;\n use rustc::middle::cstore::LOCAL_CRATE;\n use rustc::session::Session;\n use rustc::ty::TyCtxt;\n+use rustc_data_structures::fnv::FnvHashMap;\n use rustc_serialize::Encodable as RustcEncodable;\n use std::hash::{Hash, Hasher, SipHasher};\n use std::io::{self, Cursor, Write};\n@@ -23,6 +24,7 @@ use std::path::PathBuf;\n use super::data::*;\n use super::directory::*;\n use super::hash::*;\n+use super::preds::*;\n use super::util::*;\n \n pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n@@ -35,12 +37,13 @@ pub fn save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>) {\n     let mut hcx = HashContext::new(tcx);\n     let mut builder = DefIdDirectoryBuilder::new(tcx);\n     let query = tcx.dep_graph.query();\n+    let preds = Predecessors::new(&query, &mut hcx);\n     save_in(sess,\n             dep_graph_path(tcx),\n-            |e| encode_dep_graph(&mut hcx, &mut builder, &query, e));\n+            |e| encode_dep_graph(&preds, &mut builder, e));\n     save_in(sess,\n             metadata_hash_path(tcx, LOCAL_CRATE),\n-            |e| encode_metadata_hashes(&mut hcx, &mut builder, &query, e));\n+            |e| encode_metadata_hashes(tcx, &preds, &mut builder, e));\n }\n \n pub fn save_work_products(sess: &Session, local_crate_name: &str) {\n@@ -98,38 +101,37 @@ fn save_in<F>(sess: &Session, opt_path_buf: Option<PathBuf>, encode: F)\n     }\n }\n \n-pub fn encode_dep_graph<'a, 'tcx>(hcx: &mut HashContext<'a, 'tcx>,\n-                                  builder: &mut DefIdDirectoryBuilder,\n-                                  query: &DepGraphQuery<DefId>,\n-                                  encoder: &mut Encoder)\n-                                  -> io::Result<()> {\n-    let (nodes, edges) = (query.nodes(), query.edges());\n-\n-    // Create hashes for inputs.\n-    let hashes = nodes.iter()\n-        .filter_map(|dep_node| {\n-            hcx.hash(dep_node)\n-                .map(|(_, hash)| {\n-                    let node = builder.map(dep_node);\n-                    SerializedHash {\n-                        node: node,\n-                        hash: hash,\n-                    }\n-                })\n-        })\n-        .collect();\n+pub fn encode_dep_graph(preds: &Predecessors,\n+                        builder: &mut DefIdDirectoryBuilder,\n+                        encoder: &mut Encoder)\n+                        -> io::Result<()> {\n+    // Create a flat list of (Input, WorkProduct) edges for\n+    // serialization.\n+    let mut edges = vec![];\n+    for (&target, sources) in &preds.inputs {\n+        match *target {\n+            DepNode::MetaData(_) => continue, // see encode_metadata_hashes instead\n+            _ => (),\n+        }\n+        let target = builder.map(target);\n+        for &source in sources {\n+            let source = builder.map(source);\n+            edges.push((source, target.clone()));\n+        }\n+    }\n \n     // Create the serialized dep-graph.\n     let graph = SerializedDepGraph {\n-        nodes: nodes.iter().map(|node| builder.map(node)).collect(),\n-        edges: edges.iter()\n-            .map(|&(ref source_node, ref target_node)| {\n-                let source = builder.map(source_node);\n-                let target = builder.map(target_node);\n-                (source, target)\n+        edges: edges,\n+        hashes: preds.hashes\n+            .iter()\n+            .map(|(&dep_node, &hash)| {\n+                SerializedHash {\n+                    dep_node: builder.map(dep_node),\n+                    hash: hash,\n+                }\n             })\n             .collect(),\n-        hashes: hashes,\n     };\n \n     debug!(\"graph = {:#?}\", graph);\n@@ -141,70 +143,70 @@ pub fn encode_dep_graph<'a, 'tcx>(hcx: &mut HashContext<'a, 'tcx>,\n     Ok(())\n }\n \n-pub fn encode_metadata_hashes<'a, 'tcx>(hcx: &mut HashContext<'a, 'tcx>,\n-                                        builder: &mut DefIdDirectoryBuilder,\n-                                        query: &DepGraphQuery<DefId>,\n-                                        encoder: &mut Encoder)\n-                                        -> io::Result<()> {\n-    let tcx = hcx.tcx;\n-\n-    let serialized_hashes = {\n-        // Identify the `MetaData(X)` nodes where `X` is local. These are\n-        // the metadata items we export. Downstream crates will want to\n-        // see a hash that tells them whether we might have changed the\n-        // metadata for a given item since they last compiled.\n-        let meta_data_def_ids = query.nodes()\n-            .into_iter()\n-            .filter_map(|dep_node| match *dep_node {\n-                DepNode::MetaData(def_id) if def_id.is_local() => Some(def_id),\n-                _ => None,\n-            });\n+pub fn encode_metadata_hashes(tcx: TyCtxt,\n+                              preds: &Predecessors,\n+                              builder: &mut DefIdDirectoryBuilder,\n+                              encoder: &mut Encoder)\n+                              -> io::Result<()> {\n+    let mut def_id_hashes = FnvHashMap();\n+    let mut def_id_hash = |def_id: DefId| -> u64 {\n+        *def_id_hashes.entry(def_id)\n+            .or_insert_with(|| {\n+                let index = builder.add(def_id);\n+                let path = builder.lookup_def_path(index);\n+                path.deterministic_hash(tcx)\n+            })\n+    };\n+\n+    // For each `MetaData(X)` node where `X` is local, accumulate a\n+    // hash.  These are the metadata items we export. Downstream\n+    // crates will want to see a hash that tells them whether we might\n+    // have changed the metadata for a given item since they last\n+    // compiled.\n+    //\n+    // (I initially wrote this with an iterator, but it seemed harder to read.)\n+    let mut serialized_hashes = SerializedMetadataHashes { hashes: vec![] };\n+    for (&target, sources) in &preds.inputs {\n+        let def_id = match *target {\n+            DepNode::MetaData(def_id) => {\n+                assert!(def_id.is_local());\n+                def_id\n+            }\n+            _ => continue,\n+        };\n \n         // To create the hash for each item `X`, we don't hash the raw\n         // bytes of the metadata (though in principle we\n         // could). Instead, we walk the predecessors of `MetaData(X)`\n         // from the dep-graph. This corresponds to all the inputs that\n         // were read to construct the metadata. To create the hash for\n         // the metadata, we hash (the hash of) all of those inputs.\n-        let hashes = meta_data_def_ids.map(|def_id| {\n-            assert!(def_id.is_local());\n-            let dep_node = DepNode::MetaData(def_id);\n-            let mut state = SipHasher::new();\n-            debug!(\"save: computing metadata hash for {:?}\", dep_node);\n-\n-            let predecessors = query.transitive_predecessors(&dep_node);\n-            let mut hashes: Vec<_> = predecessors.iter()\n-                .filter_map(|node| hcx.hash(&node))\n-                .map(|(def_id, hash)| {\n-                    let index = builder.add(def_id);\n-                    let path = builder.lookup_def_path(index);\n-                    (path.to_string(tcx), hash) // (*)\n-                })\n-                .collect();\n-\n-            // (*) creating a `String` from each def-path is a bit inefficient,\n-            // but it's the easiest way to get a deterministic ord/hash.\n-\n-            hashes.sort();\n-            state.write_usize(hashes.len());\n-            for (path, hash) in hashes {\n-                debug!(\"save: predecessor {:?} has hash {}\", path, hash);\n-                path.hash(&mut state);\n-                state.write_u64(hash.to_le());\n-            }\n+        debug!(\"save: computing metadata hash for {:?}\", def_id);\n+\n+        // Create a vector containing a pair of (source-id, hash).\n+        // The source-id is stored as a `DepNode<u64>`, where the u64\n+        // is the det. hash of the def-path. This is convenient\n+        // because we can sort this to get a table ordering across\n+        // compilations, even if the def-ids themselves have changed.\n+        let mut hashes: Vec<(DepNode<u64>, u64)> = sources.iter()\n+            .map(|dep_node| {\n+                let hash_dep_node = dep_node.map_def(|&def_id| Some(def_id_hash(def_id))).unwrap();\n+                let hash = preds.hashes[dep_node];\n+                (hash_dep_node, hash)\n+            })\n+            .collect();\n \n-            let hash = state.finish();\n-            debug!(\"save: metadata hash for {:?} is {}\", dep_node, hash);\n+        hashes.sort();\n+        let mut state = SipHasher::new();\n+        hashes.hash(&mut state);\n+        let hash = state.finish();\n \n-            SerializedMetadataHash {\n-                def_index: def_id.index,\n-                hash: hash,\n-            }\n+        debug!(\"save: metadata hash for {:?} is {}\", def_id, hash);\n+        serialized_hashes.hashes.push(SerializedMetadataHash {\n+            def_index: def_id.index,\n+            hash: hash,\n         });\n-\n-        // Collect these up into a vector.\n-        SerializedMetadataHashes { hashes: hashes.collect() }\n-    };\n+    }\n \n     // Encode everything.\n     try!(serialized_hashes.encode(encoder));"}, {"sha": "e8b187b5454f6dbe88cafef8dac49cc7b8b03d98", "filename": "src/test/incremental/callee_caller_cross_crate/b.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fcallee_caller_cross_crate%2Fb.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -10,6 +10,7 @@\n \n // aux-build:a.rs\n // revisions:rpass1 rpass2\n+// compile-flags:-Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "64b7f2951d274595005c79abcd047ae80c409d89", "filename": "src/test/incremental/dirty_clean.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fdirty_clean.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fdirty_clean.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fdirty_clean.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -9,6 +9,7 @@\n // except according to those terms.\n \n // revisions: rpass1 cfail2\n+// compile-flags: -Z query-dep-graph\n \n #![allow(warnings)]\n #![feature(rustc_attrs)]"}, {"sha": "a06c25ac055c77b6ce313f8d345c5be8156af290", "filename": "src/test/incremental/hello_world.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fhello_world.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fhello_world.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fhello_world.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -9,6 +9,7 @@\n // except according to those terms.\n \n // revisions: rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![allow(warnings)]\n #![feature(rustc_attrs)]"}, {"sha": "21b654bdf584bcda118c948979e413395621a0e7", "filename": "src/test/incremental/rlib_cross_crate/b.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Frlib_cross_crate%2Fb.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -16,7 +16,7 @@\n // aux-build:a.rs\n // revisions:rpass1 rpass2 rpass3\n // no-prefer-dynamic\n-\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "257699cd3fce15b53a2d61ec02271eb1584858d8", "filename": "src/test/incremental/spike.rs", "status": "modified", "additions": 0, "deletions": 5, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fspike.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fspike.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fspike.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -35,14 +35,10 @@ mod x {\n         X { x: 11, y: 11 }\n     }\n \n-    #[rustc_dirty(label=\"TypeckItemBody\", cfg=\"rpass2\")]\n-    #[rustc_clean(label=\"ItemSignature\", cfg=\"rpass2\")]\n     pub fn new() -> X {\n         make()\n     }\n \n-    #[rustc_clean(label=\"TypeckItemBody\", cfg=\"rpass2\")]\n-    #[rustc_clean(label=\"ItemSignature\", cfg=\"rpass2\")]\n     pub fn sum(x: &X) -> u32 {\n         x.x + x.y\n     }\n@@ -51,7 +47,6 @@ mod x {\n mod y {\n     use x;\n \n-    #[rustc_clean(label=\"TypeckItemBody\", cfg=\"rpass2\")]\n     pub fn assert_sum() -> bool {\n         let x = x::new();\n         x::sum(&x) == 22"}, {"sha": "f40621692561b4a901d455a927048f9a33dfe27e", "filename": "src/test/incremental/string_constant.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstring_constant.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstring_constant.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstring_constant.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -9,6 +9,7 @@\n // except according to those terms.\n \n // revisions: rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![allow(warnings)]\n #![feature(rustc_attrs)]"}, {"sha": "da1b32cd73d6ebd2905d98625961c4fae4212b02", "filename": "src/test/incremental/struct_add_field.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_add_field.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_add_field.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_add_field.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -12,6 +12,7 @@\n // in between revisions (hashing should be stable).\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "ba469c62002e4da2f372eee3d77129507cc9fce4", "filename": "src/test/incremental/struct_change_field_name.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_name.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_name.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_change_field_name.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -12,6 +12,7 @@\n // in between revisions (hashing should be stable).\n \n // revisions:rpass1 cfail2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "65f3b1b4f368f54cdf32ad748c437d4ab408999e", "filename": "src/test/incremental/struct_change_field_type.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_type.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_type.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_change_field_type.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -12,6 +12,7 @@\n // in between revisions (hashing should be stable).\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "95e15d0b7f9a070f1ea618e766f278dfd678548c", "filename": "src/test/incremental/struct_change_field_type_cross_crate/b.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_change_field_type_cross_crate%2Fb.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -10,6 +10,7 @@\n \n // aux-build:a.rs\n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "2bc636153f73522a823b38d144cd61eb7b4fe388", "filename": "src/test/incremental/struct_change_nothing.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_nothing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_change_nothing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_change_nothing.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -12,6 +12,7 @@\n // in between revisions (hashing should be stable).\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "a7ed79d1a5a35036eef6e822ccd64ede592eb9b2", "filename": "src/test/incremental/struct_remove_field.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_remove_field.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Fstruct_remove_field.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Fstruct_remove_field.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -12,6 +12,7 @@\n // in between revisions (hashing should be stable).\n \n // revisions:rpass1 rpass2\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}, {"sha": "09d4db331980dcaadd6961e24fd57b77b24c61e5", "filename": "src/test/incremental/type_alias_cross_crate/b.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/02a47032dda473e6d8fa9da969bf157c48fba6dd/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fincremental%2Ftype_alias_cross_crate%2Fb.rs?ref=02a47032dda473e6d8fa9da969bf157c48fba6dd", "patch": "@@ -10,6 +10,7 @@\n \n // aux-build:a.rs\n // revisions:rpass1 rpass2 rpass3\n+// compile-flags: -Z query-dep-graph\n \n #![feature(rustc_attrs)]\n "}]}