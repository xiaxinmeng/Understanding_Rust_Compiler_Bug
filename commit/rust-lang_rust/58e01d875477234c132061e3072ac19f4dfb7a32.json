{"sha": "58e01d875477234c132061e3072ac19f4dfb7a32", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU4ZTAxZDg3NTQ3NzIzNGMxMzIwNjFlMzA3MmFjMTlmNGRmYjdhMzI=", "commit": {"author": {"name": "Veetaha", "email": "gerzoh1@gmail.com", "date": "2020-01-28T05:18:35Z"}, "committer": {"name": "Veetaha", "email": "gerzoh1@gmail.com", "date": "2020-02-03T22:00:55Z"}, "message": "ra_syntax: rename first_token() -> lex_first_token()", "tree": {"sha": "6de5660fae3b7b538e2017f44bbd2af90236abdc", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6de5660fae3b7b538e2017f44bbd2af90236abdc"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/58e01d875477234c132061e3072ac19f4dfb7a32", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/58e01d875477234c132061e3072ac19f4dfb7a32", "html_url": "https://github.com/rust-lang/rust/commit/58e01d875477234c132061e3072ac19f4dfb7a32", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/58e01d875477234c132061e3072ac19f4dfb7a32/comments", "author": null, "committer": null, "parents": [{"sha": "b1764d85fced5f3bc1db82063fca9369f9e1740b", "url": "https://api.github.com/repos/rust-lang/rust/commits/b1764d85fced5f3bc1db82063fca9369f9e1740b", "html_url": "https://github.com/rust-lang/rust/commit/b1764d85fced5f3bc1db82063fca9369f9e1740b"}], "stats": {"total": 6, "additions": 3, "deletions": 3}, "files": [{"sha": "f889e6a1d63aca64e003c98dc73621643a46a562", "filename": "crates/ra_syntax/src/parsing/lexer.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/58e01d875477234c132061e3072ac19f4dfb7a32/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/58e01d875477234c132061e3072ac19f4dfb7a32/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Flexer.rs?ref=58e01d875477234c132061e3072ac19f4dfb7a32", "patch": "@@ -64,7 +64,7 @@ pub fn tokenize(text: &str) -> (Vec<Token>, Vec<SyntaxError>) {\n ///\n /// Beware that unescape errors are not checked at tokenization time.\n pub fn lex_single_syntax_kind(text: &str) -> Option<(SyntaxKind, Option<SyntaxError>)> {\n-    first_token(text)\n+    lex_first_token(text)\n         .filter(|(token, _)| token.len.to_usize() == text.len())\n         .map(|(token, error)| (token.kind, error))\n }\n@@ -74,7 +74,7 @@ pub fn lex_single_syntax_kind(text: &str) -> Option<(SyntaxKind, Option<SyntaxEr\n ///\n /// Beware that unescape errors are not checked at tokenization time.\n pub fn lex_single_valid_syntax_kind(text: &str) -> Option<SyntaxKind> {\n-    first_token(text)\n+    lex_first_token(text)\n         .filter(|(token, error)| !error.is_some() && token.len.to_usize() == text.len())\n         .map(|(token, _error)| token.kind)\n }\n@@ -87,7 +87,7 @@ pub fn lex_single_valid_syntax_kind(text: &str) -> Option<SyntaxKind> {\n /// The token is malformed if the returned error is not `None`.\n ///\n /// Beware that unescape errors are not checked at tokenization time.\n-fn first_token(text: &str) -> Option<(Token, Option<SyntaxError>)> {\n+fn lex_first_token(text: &str) -> Option<(Token, Option<SyntaxError>)> {\n     // non-empty string is a precondtion of `rustc_lexer::first_token()`.\n     if text.is_empty() {\n         return None;"}]}