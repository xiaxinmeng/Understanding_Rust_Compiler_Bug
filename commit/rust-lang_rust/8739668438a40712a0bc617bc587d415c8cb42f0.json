{"sha": "8739668438a40712a0bc617bc587d415c8cb42f0", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg3Mzk2Njg0MzhhNDA3MTJhMGJjNjE3YmM1ODdkNDE1YzhjYjQyZjA=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-10T00:00:51Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-11T11:24:21Z"}, "message": "Simplify conversions between tokens and semantic literals", "tree": {"sha": "93892fc698e7f4abeb29e5a2f1852b6cfc624bf9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/93892fc698e7f4abeb29e5a2f1852b6cfc624bf9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/8739668438a40712a0bc617bc587d415c8cb42f0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/8739668438a40712a0bc617bc587d415c8cb42f0", "html_url": "https://github.com/rust-lang/rust/commit/8739668438a40712a0bc617bc587d415c8cb42f0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/8739668438a40712a0bc617bc587d415c8cb42f0/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a5b3f33cb90bf991342afa552bcd993e36f80fa7", "url": "https://api.github.com/repos/rust-lang/rust/commits/a5b3f33cb90bf991342afa552bcd993e36f80fa7", "html_url": "https://github.com/rust-lang/rust/commit/a5b3f33cb90bf991342afa552bcd993e36f80fa7"}], "stats": {"total": 583, "additions": 259, "deletions": 324}, "files": [{"sha": "475bf8d83723957639cd6a36471cdc782167cc26", "filename": "src/librustc/hir/print.rs", "status": "modified", "additions": 3, "deletions": 53, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibrustc%2Fhir%2Fprint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibrustc%2Fhir%2Fprint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fprint.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -5,7 +5,7 @@ use syntax::parse::ParseSess;\n use syntax::parse::lexer::comments;\n use syntax::print::pp::{self, Breaks};\n use syntax::print::pp::Breaks::{Consistent, Inconsistent};\n-use syntax::print::pprust::PrintState;\n+use syntax::print::pprust::{self, PrintState};\n use syntax::ptr::P;\n use syntax::symbol::keywords;\n use syntax::util::parser::{self, AssocOp, Fixity};\n@@ -15,7 +15,6 @@ use crate::hir;\n use crate::hir::{PatKind, GenericBound, TraitBoundModifier, RangeEnd};\n use crate::hir::{GenericParam, GenericParamKind, GenericArg};\n \n-use std::ascii;\n use std::borrow::Cow;\n use std::cell::Cell;\n use std::io::{self, Write, Read};\n@@ -1251,57 +1250,8 @@ impl<'a> State<'a> {\n \n     fn print_literal(&mut self, lit: &hir::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo())?;\n-        match lit.node {\n-            hir::LitKind::Str(st, style) => self.print_string(&st.as_str(), style),\n-            hir::LitKind::Err(st) => {\n-                let st = st.as_str().escape_debug().to_string();\n-                let mut res = String::with_capacity(st.len() + 2);\n-                res.push('\\'');\n-                res.push_str(&st);\n-                res.push('\\'');\n-                self.writer().word(res)\n-            }\n-            hir::LitKind::Byte(byte) => {\n-                let mut res = String::from(\"b'\");\n-                res.extend(ascii::escape_default(byte).map(|c| c as char));\n-                res.push('\\'');\n-                self.writer().word(res)\n-            }\n-            hir::LitKind::Char(ch) => {\n-                let mut res = String::from(\"'\");\n-                res.extend(ch.escape_default());\n-                res.push('\\'');\n-                self.writer().word(res)\n-            }\n-            hir::LitKind::Int(i, t) => {\n-                match t {\n-                    ast::LitIntType::Signed(st) => {\n-                        self.writer().word(st.val_to_string(i as i128))\n-                    }\n-                    ast::LitIntType::Unsigned(ut) => {\n-                        self.writer().word(ut.val_to_string(i))\n-                    }\n-                    ast::LitIntType::Unsuffixed => {\n-                        self.writer().word(i.to_string())\n-                    }\n-                }\n-            }\n-            hir::LitKind::Float(ref f, t) => {\n-                self.writer().word(format!(\"{}{}\", &f, t.ty_to_string()))\n-            }\n-            hir::LitKind::FloatUnsuffixed(ref f) => self.writer().word(f.as_str().to_string()),\n-            hir::LitKind::Bool(val) => {\n-                if val { self.writer().word(\"true\") } else { self.writer().word(\"false\") }\n-            }\n-            hir::LitKind::ByteStr(ref v) => {\n-                let mut escaped: String = String::new();\n-                for &ch in v.iter() {\n-                    escaped.extend(ascii::escape_default(ch)\n-                                         .map(|c| c as char));\n-                }\n-                self.writer().word(format!(\"b\\\"{}\\\"\", escaped))\n-            }\n-        }\n+        let (token, suffix) = lit.node.to_lit_token();\n+        self.writer().word(pprust::literal_to_string(token, suffix))\n     }\n \n     pub fn print_expr(&mut self, expr: &hir::Expr) -> io::Result<()> {"}, {"sha": "51fe26b374313980cf3312e1aa62cb43a76a7bed", "filename": "src/librustdoc/clean/cfg.rs", "status": "modified", "additions": 10, "deletions": 14, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibrustdoc%2Fclean%2Fcfg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibrustdoc%2Fclean%2Fcfg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fcfg.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -591,13 +591,10 @@ mod test {\n             let mi = dummy_meta_item_word(\"all\");\n             assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"all\")));\n \n-            let node = LitKind::Str(Symbol::intern(\"done\"), StrStyle::Cooked);\n-            let (token, suffix) =   node.lit_token();\n-            let mi = MetaItem {\n-                path: Path::from_ident(Ident::from_str(\"all\")),\n-                node: MetaItemKind::NameValue(Lit { node, token, suffix, span: DUMMY_SP }),\n-                span: DUMMY_SP,\n-            };\n+            let mi = attr::mk_name_value_item_str(\n+                Ident::from_str(\"all\"),\n+                dummy_spanned(Symbol::intern(\"done\"))\n+            );\n             assert_eq!(Cfg::parse(&mi), Ok(name_value_cfg(\"all\", \"done\")));\n \n             let mi = dummy_meta_item_list!(all, [a, b]);\n@@ -625,13 +622,12 @@ mod test {\n     #[test]\n     fn test_parse_err() {\n         with_globals(|| {\n-            let node = LitKind::Bool(false);\n-            let (token, suffix) = node.lit_token();\n-            let mi = MetaItem {\n-                path: Path::from_ident(Ident::from_str(\"foo\")),\n-                node: MetaItemKind::NameValue(Lit { node, token, suffix, span: DUMMY_SP }),\n-                span: DUMMY_SP,\n-            };\n+            let mi = attr::mk_name_value_item(\n+                DUMMY_SP,\n+                Ident::from_str(\"foo\"),\n+                LitKind::Bool(false),\n+                DUMMY_SP,\n+            );\n             assert!(Cfg::parse(&mi).is_err());\n \n             let mi = dummy_meta_item_list!(not, [a, b]);"}, {"sha": "c122e1994e749b934c58cc521b74afff5d5a738f", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 58, "deletions": 46, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -14,7 +14,7 @@ pub use StabilityLevel::*;\n use crate::ast;\n use crate::ast::{AttrId, Attribute, AttrStyle, Name, Ident, Path, PathSegment};\n use crate::ast::{MetaItem, MetaItemKind, NestedMetaItem};\n-use crate::ast::{Lit, LitKind, Expr, ExprKind, Item, Local, Stmt, StmtKind, GenericParam};\n+use crate::ast::{Lit, LitKind, Expr, Item, Local, Stmt, StmtKind, GenericParam};\n use crate::mut_visit::visit_clobber;\n use crate::source_map::{BytePos, Spanned, dummy_spanned};\n use crate::parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n@@ -27,9 +27,11 @@ use crate::ThinVec;\n use crate::tokenstream::{TokenStream, TokenTree, DelimSpan};\n use crate::GLOBALS;\n \n+use errors::Handler;\n use log::debug;\n use syntax_pos::{FileName, Span};\n \n+use std::ascii;\n use std::iter;\n use std::ops::DerefMut;\n \n@@ -350,14 +352,13 @@ impl Attribute {\n /* Constructors */\n \n pub fn mk_name_value_item_str(ident: Ident, value: Spanned<Symbol>) -> MetaItem {\n-    let node = LitKind::Str(value.node, ast::StrStyle::Cooked);\n-    let (token, suffix) = node.lit_token();\n-    let value = Lit { node, token, suffix, span: value.span };\n-    mk_name_value_item(ident.span.to(value.span), ident, value)\n+    let lit_kind = LitKind::Str(value.node, ast::StrStyle::Cooked);\n+    mk_name_value_item(ident.span.to(value.span), ident, lit_kind, value.span)\n }\n \n-pub fn mk_name_value_item(span: Span, ident: Ident, value: Lit) -> MetaItem {\n-    MetaItem { path: Path::from_ident(ident), span, node: MetaItemKind::NameValue(value) }\n+pub fn mk_name_value_item(span: Span, ident: Ident, lit_kind: LitKind, lit_span: Span) -> MetaItem {\n+    let lit = Lit::from_lit_kind(lit_kind, lit_span);\n+    MetaItem { path: Path::from_ident(ident), span, node: MetaItemKind::NameValue(lit) }\n }\n \n pub fn mk_list_item(span: Span, ident: Ident, items: Vec<NestedMetaItem>) -> MetaItem {\n@@ -419,9 +420,8 @@ pub fn mk_spanned_attr_outer(sp: Span, id: AttrId, item: MetaItem) -> Attribute\n \n pub fn mk_sugared_doc_attr(id: AttrId, text: Symbol, span: Span) -> Attribute {\n     let style = doc_comment_style(&text.as_str());\n-    let node = LitKind::Str(text, ast::StrStyle::Cooked);\n-    let (token, suffix) = node.lit_token();\n-    let lit = Lit { node, token, suffix, span };\n+    let lit_kind = LitKind::Str(text, ast::StrStyle::Cooked);\n+    let lit = Lit::from_lit_kind(lit_kind, span);\n     Attribute {\n         id,\n         style,\n@@ -565,9 +565,7 @@ impl MetaItemKind {\n             Some(TokenTree::Token(_, token::Eq)) => {\n                 tokens.next();\n                 return if let Some(TokenTree::Token(span, token)) = tokens.next() {\n-                    LitKind::from_token(token).map(|(node, token, suffix)| {\n-                        MetaItemKind::NameValue(Lit { node, token, suffix, span })\n-                    })\n+                    Lit::from_token(&token, span, None).map(MetaItemKind::NameValue)\n                 } else {\n                     None\n                 };\n@@ -612,9 +610,9 @@ impl NestedMetaItem {\n         where I: Iterator<Item = TokenTree>,\n     {\n         if let Some(TokenTree::Token(span, token)) = tokens.peek().cloned() {\n-            if let Some((node, token, suffix)) = LitKind::from_token(token) {\n+            if let Some(lit) = Lit::from_token(&token, span, None) {\n                 tokens.next();\n-                return Some(NestedMetaItem::Literal(Lit { node, token, suffix, span }));\n+                return Some(NestedMetaItem::Literal(lit));\n             }\n         }\n \n@@ -624,21 +622,19 @@ impl NestedMetaItem {\n \n impl Lit {\n     crate fn tokens(&self) -> TokenStream {\n-        TokenTree::Token(self.span, self.node.token()).into()\n+        let token = match self.token {\n+            token::Bool(symbol) => Token::Ident(Ident::with_empty_ctxt(symbol), false),\n+            token => Token::Literal(token, self.suffix),\n+        };\n+        TokenTree::Token(self.span, token).into()\n     }\n }\n \n impl LitKind {\n-    fn token(&self) -> Token {\n-        match self.lit_token() {\n-            (token::Bool(symbol), _) => Token::Ident(Ident::with_empty_ctxt(symbol), false),\n-            (lit, suffix) => Token::Literal(lit, suffix),\n-        }\n-    }\n-\n-    pub fn lit_token(&self) -> (token::Lit, Option<Symbol>) {\n-        use std::ascii;\n-\n+    /// Attempts to recover a token from semantic literal.\n+    /// This function is used when the original token doesn't exist (e.g. the literal is created\n+    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n+    pub fn to_lit_token(&self) -> (token::Lit, Option<Symbol>) {\n         match *self {\n             LitKind::Str(string, ast::StrStyle::Cooked) => {\n                 let escaped = string.as_str().escape_default().to_string();\n@@ -679,29 +675,45 @@ impl LitKind {\n             LitKind::Err(val) => (token::Lit::Err(val), None),\n         }\n     }\n+}\n \n-    fn from_token(token: Token) -> Option<(LitKind, token::Lit, Option<Symbol>)> {\n-        match token {\n-            Token::Ident(ident, false) if ident.name == keywords::True.name() =>\n-                Some((LitKind::Bool(true), token::Bool(ident.name), None)),\n-            Token::Ident(ident, false) if ident.name == keywords::False.name() =>\n-                Some((LitKind::Bool(false), token::Bool(ident.name), None)),\n-            Token::Interpolated(nt) => match *nt {\n-                token::NtExpr(ref v) | token::NtLiteral(ref v) => match v.node {\n-                    ExprKind::Lit(ref lit) => Some((lit.node.clone(), lit.token, lit.suffix)),\n-                    _ => None,\n-                },\n-                _ => None,\n-            },\n-            Token::Literal(lit, suf) => {\n-                let (suffix_illegal, result) = parse::lit_token(lit, suf, None);\n-                if result.is_none() || suffix_illegal && suf.is_some() {\n-                    return None;\n+impl Lit {\n+    /// Converts literal token with a suffix into an AST literal.\n+    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n+    /// If diagnostic handler is passed, may return `Some`,\n+    /// possibly after reporting non-fatal errors and recovery, or `None` for irrecoverable errors.\n+    crate fn from_token(\n+        token: &token::Token,\n+        span: Span,\n+        diag: Option<(Span, &Handler)>,\n+    ) -> Option<Lit> {\n+        let (token, suffix) = match *token {\n+            token::Ident(ident, false) if ident.name == keywords::True.name() ||\n+                                          ident.name == keywords::False.name() =>\n+                (token::Bool(ident.name), None),\n+            token::Literal(token, suffix) =>\n+                (token, suffix),\n+            token::Interpolated(ref nt) => {\n+                if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n+                    if let ast::ExprKind::Lit(lit) = &expr.node {\n+                        return Some(lit.clone());\n+                    }\n                 }\n-                Some((result.unwrap(), lit, suf))\n+                return None;\n             }\n-            _ => None,\n-        }\n+            _ => return None,\n+        };\n+\n+        let node = LitKind::from_lit_token(token, suffix, diag)?;\n+        Some(Lit { node, token, suffix, span })\n+    }\n+\n+    /// Attempts to recover an AST literal from semantic literal.\n+    /// This function is used when the original token doesn't exist (e.g. the literal is created\n+    /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n+    pub fn from_lit_kind(node: LitKind, span: Span) -> Lit {\n+        let (token, suffix) = node.to_lit_token();\n+        Lit { node, token, suffix, span }\n     }\n }\n "}, {"sha": "d24106f697e19f1470fd4a6adecfad08c73191b6", "filename": "src/libsyntax/ext/build.rs", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fext%2Fbuild.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fext%2Fbuild.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fbuild.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -697,9 +697,9 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         self.expr_struct(span, self.path_ident(span, id), fields)\n     }\n \n-    fn expr_lit(&self, span: Span, node: ast::LitKind) -> P<ast::Expr> {\n-        let (token, suffix) = node.lit_token();\n-        self.expr(span, ast::ExprKind::Lit(ast::Lit { node, token, suffix, span }))\n+    fn expr_lit(&self, span: Span, lit_kind: ast::LitKind) -> P<ast::Expr> {\n+        let lit = ast::Lit::from_lit_kind(lit_kind, span);\n+        self.expr(span, ast::ExprKind::Lit(lit))\n     }\n     fn expr_usize(&self, span: Span, i: usize) -> P<ast::Expr> {\n         self.expr_lit(span, ast::LitKind::Int(i as u128,\n@@ -1165,11 +1165,10 @@ impl<'a> AstBuilder for ExtCtxt<'a> {\n         attr::mk_list_item(sp, Ident::with_empty_ctxt(name).with_span_pos(sp), mis)\n     }\n \n-    fn meta_name_value(&self, span: Span, name: ast::Name, node: ast::LitKind)\n+    fn meta_name_value(&self, span: Span, name: ast::Name, lit_kind: ast::LitKind)\n                        -> ast::MetaItem {\n-        let (token, suffix) = node.lit_token();\n         attr::mk_name_value_item(span, Ident::with_empty_ctxt(name).with_span_pos(span),\n-                                 ast::Lit { node, token, suffix, span })\n+                                 lit_kind, span)\n     }\n \n     fn item_use(&self, sp: Span,"}, {"sha": "868b344c0658457d582ede8a170188dcdad415c3", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 133, "deletions": 79, "changes": 212, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -1,11 +1,11 @@\n //! The main parser interface.\n \n-use crate::ast::{self, CrateConfig, NodeId};\n+use crate::ast::{self, CrateConfig, LitKind, NodeId};\n use crate::early_buffered_lints::{BufferedEarlyLint, BufferedEarlyLintId};\n use crate::source_map::{SourceMap, FilePathMapping};\n use crate::feature_gate::UnstableFeatures;\n use crate::parse::parser::Parser;\n-use crate::symbol::Symbol;\n+use crate::symbol::{keywords, Symbol};\n use crate::syntax::parse::parser::emit_unclosed_delims;\n use crate::tokenstream::{TokenStream, TokenTree};\n use crate::diagnostics::plugin::ErrorMap;\n@@ -371,97 +371,151 @@ macro_rules! err {\n     }\n }\n \n-crate fn lit_token(lit: token::Lit, suf: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                 -> (bool /* suffix illegal? */, Option<ast::LitKind>) {\n-    use ast::LitKind;\n-\n-    match lit {\n-        token::Bool(_) => panic!(\"literal token contains `Lit::Bool`\"),\n-        token::Byte(i) => {\n-            let lit_kind = match unescape_byte(&i.as_str()) {\n-                Ok(c) => LitKind::Byte(c),\n-                Err(_) => LitKind::Err(i),\n-            };\n-            (true, Some(lit_kind))\n-        },\n-        token::Char(i) => {\n-            let lit_kind = match unescape_char(&i.as_str()) {\n-                Ok(c) => LitKind::Char(c),\n-                Err(_) => LitKind::Err(i),\n+crate fn expect_no_suffix(sp: Span, diag: &Handler, kind: &str, suffix: Option<ast::Name>) {\n+    match suffix {\n+        None => {/* everything ok */}\n+        Some(suf) => {\n+            let text = suf.as_str();\n+            if text.is_empty() {\n+                diag.span_bug(sp, \"found empty literal suffix in Some\")\n+            }\n+            let mut err = if kind == \"a tuple index\" &&\n+                [\"i32\", \"u32\", \"isize\", \"usize\"].contains(&text.to_string().as_str())\n+            {\n+                // #59553: warn instead of reject out of hand to allow the fix to percolate\n+                // through the ecosystem when people fix their macros\n+                let mut err = diag.struct_span_warn(\n+                    sp,\n+                    &format!(\"suffixes on {} are invalid\", kind),\n+                );\n+                err.note(&format!(\n+                    \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n+                        incorrectly accepted on stable for a few releases\",\n+                    text,\n+                ));\n+                err.help(\n+                    \"on proc macros, you'll want to use `syn::Index::from` or \\\n+                        `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n+                        to tuple field access\",\n+                );\n+                err.note(\n+                    \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n+                );\n+                err\n+            } else {\n+                diag.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n             };\n-            (true, Some(lit_kind))\n-        },\n-        token::Err(i) => (true, Some(LitKind::Err(i))),\n-\n-        // There are some valid suffixes for integer and float literals,\n-        // so all the handling is done internally.\n-        token::Integer(s) => (false, integer_lit(&s.as_str(), suf, diag)),\n-        token::Float(s) => (false, float_lit(&s.as_str(), suf, diag)),\n-\n-        token::Str_(mut sym) => {\n-            // If there are no characters requiring special treatment we can\n-            // reuse the symbol from the Token. Otherwise, we must generate a\n-            // new symbol because the string in the LitKind is different to the\n-            // string in the Token.\n-            let mut has_error = false;\n-            let s = &sym.as_str();\n-            if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n-                let mut buf = String::with_capacity(s.len());\n-                unescape_str(s, &mut |_, unescaped_char| {\n-                    match unescaped_char {\n+            err.span_label(sp, format!(\"invalid suffix `{}`\", text));\n+            err.emit();\n+        }\n+    }\n+}\n+\n+impl LitKind {\n+    /// Converts literal token with a suffix into a semantic literal.\n+    /// Works speculatively and may return `None` is diagnostic handler is not passed.\n+    /// If diagnostic handler is passed, always returns `Some`,\n+    /// possibly after reporting non-fatal errors and recovery.\n+    crate fn from_lit_token(\n+        lit: token::Lit,\n+        suf: Option<Symbol>,\n+        diag: Option<(Span, &Handler)>\n+    ) -> Option<LitKind> {\n+        if suf.is_some() && !lit.may_have_suffix() {\n+            err!(diag, |span, diag| {\n+                expect_no_suffix(span, diag, &format!(\"a {}\", lit.literal_name()), suf)\n+            });\n+        }\n+\n+        Some(match lit {\n+            token::Bool(i) => {\n+                assert!(i == keywords::True.name() || i == keywords::False.name());\n+                LitKind::Bool(i == keywords::True.name())\n+            }\n+            token::Byte(i) => {\n+                match unescape_byte(&i.as_str()) {\n+                    Ok(c) => LitKind::Byte(c),\n+                    Err(_) => LitKind::Err(i),\n+                }\n+            },\n+            token::Char(i) => {\n+                match unescape_char(&i.as_str()) {\n+                    Ok(c) => LitKind::Char(c),\n+                    Err(_) => LitKind::Err(i),\n+                }\n+            },\n+            token::Err(i) => LitKind::Err(i),\n+\n+            // There are some valid suffixes for integer and float literals,\n+            // so all the handling is done internally.\n+            token::Integer(s) => return integer_lit(&s.as_str(), suf, diag),\n+            token::Float(s) => return float_lit(&s.as_str(), suf, diag),\n+\n+            token::Str_(mut sym) => {\n+                // If there are no characters requiring special treatment we can\n+                // reuse the symbol from the Token. Otherwise, we must generate a\n+                // new symbol because the string in the LitKind is different to the\n+                // string in the Token.\n+                let mut has_error = false;\n+                let s = &sym.as_str();\n+                if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n+                    let mut buf = String::with_capacity(s.len());\n+                    unescape_str(s, &mut |_, unescaped_char| {\n+                        match unescaped_char {\n+                            Ok(c) => buf.push(c),\n+                            Err(_) => has_error = true,\n+                        }\n+                    });\n+                    if has_error {\n+                        return Some(LitKind::Err(sym));\n+                    }\n+                    sym = Symbol::intern(&buf)\n+                }\n+\n+                LitKind::Str(sym, ast::StrStyle::Cooked)\n+            }\n+            token::StrRaw(mut sym, n) => {\n+                // Ditto.\n+                let s = &sym.as_str();\n+                if s.contains('\\r') {\n+                    sym = Symbol::intern(&raw_str_lit(s));\n+                }\n+                LitKind::Str(sym, ast::StrStyle::Raw(n))\n+            }\n+            token::ByteStr(i) => {\n+                let s = &i.as_str();\n+                let mut buf = Vec::with_capacity(s.len());\n+                let mut has_error = false;\n+                unescape_byte_str(s, &mut |_, unescaped_byte| {\n+                    match unescaped_byte {\n                         Ok(c) => buf.push(c),\n                         Err(_) => has_error = true,\n                     }\n                 });\n                 if has_error {\n-                    return (true, Some(LitKind::Err(sym)));\n+                    return Some(LitKind::Err(i));\n                 }\n-                sym = Symbol::intern(&buf)\n+                buf.shrink_to_fit();\n+                LitKind::ByteStr(Lrc::new(buf))\n             }\n-\n-            (true, Some(LitKind::Str(sym, ast::StrStyle::Cooked)))\n-        }\n-        token::StrRaw(mut sym, n) => {\n-            // Ditto.\n-            let s = &sym.as_str();\n-            if s.contains('\\r') {\n-                sym = Symbol::intern(&raw_str_lit(s));\n+            token::ByteStrRaw(i, _) => {\n+                LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))\n             }\n-            (true, Some(LitKind::Str(sym, ast::StrStyle::Raw(n))))\n-        }\n-        token::ByteStr(i) => {\n-            let s = &i.as_str();\n-            let mut buf = Vec::with_capacity(s.len());\n-            let mut has_error = false;\n-            unescape_byte_str(s, &mut |_, unescaped_byte| {\n-                match unescaped_byte {\n-                    Ok(c) => buf.push(c),\n-                    Err(_) => has_error = true,\n-                }\n-            });\n-            if has_error {\n-                return (true, Some(LitKind::Err(i)));\n-            }\n-            buf.shrink_to_fit();\n-            (true, Some(LitKind::ByteStr(Lrc::new(buf))))\n-        }\n-        token::ByteStrRaw(i, _) => {\n-            (true, Some(LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))))\n-        }\n+        })\n     }\n }\n \n fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                      -> Option<ast::LitKind> {\n+                      -> Option<LitKind> {\n     debug!(\"filtered_float_lit: {}, {:?}\", data, suffix);\n     let suffix = match suffix {\n         Some(suffix) => suffix,\n-        None => return Some(ast::LitKind::FloatUnsuffixed(data)),\n+        None => return Some(LitKind::FloatUnsuffixed(data)),\n     };\n \n     Some(match &*suffix.as_str() {\n-        \"f32\" => ast::LitKind::Float(data, ast::FloatTy::F32),\n-        \"f64\" => ast::LitKind::Float(data, ast::FloatTy::F64),\n+        \"f32\" => LitKind::Float(data, ast::FloatTy::F32),\n+        \"f64\" => LitKind::Float(data, ast::FloatTy::F64),\n         suf => {\n             err!(diag, |span, diag| {\n                 if suf.len() >= 2 && looks_like_width_suffix(&['f'], suf) {\n@@ -477,12 +531,12 @@ fn filtered_float_lit(data: Symbol, suffix: Option<Symbol>, diag: Option<(Span,\n                 }\n             });\n \n-            ast::LitKind::FloatUnsuffixed(data)\n+            LitKind::FloatUnsuffixed(data)\n         }\n     })\n }\n fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                 -> Option<ast::LitKind> {\n+                 -> Option<LitKind> {\n     debug!(\"float_lit: {:?}, {:?}\", s, suffix);\n     // FIXME #2252: bounds checking float literals is deferred until trans\n \n@@ -499,7 +553,7 @@ fn float_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n }\n \n fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n-                   -> Option<ast::LitKind> {\n+                   -> Option<LitKind> {\n     // s can only be ascii, byte indexing is fine\n \n     // Strip underscores without allocating a new String unless necessary.\n@@ -595,7 +649,7 @@ fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n            string was {:?}, the original suffix was {:?}\", ty, base, s, orig, suffix);\n \n     Some(match u128::from_str_radix(s, base) {\n-        Ok(r) => ast::LitKind::Int(r, ty),\n+        Ok(r) => LitKind::Int(r, ty),\n         Err(_) => {\n             // small bases are lexed as if they were base 10, e.g, the string\n             // might be `0b10201`. This will cause the conversion above to fail,\n@@ -608,7 +662,7 @@ fn integer_lit(s: &str, suffix: Option<Symbol>, diag: Option<(Span, &Handler)>)\n             if !already_errored {\n                 err!(diag, |span, diag| diag.span_err(span, \"int literal is too large\"));\n             }\n-            ast::LitKind::Int(0, ty)\n+            LitKind::Int(0, ty)\n         }\n     })\n }"}, {"sha": "b81f7be9c2c14dd195a2c32c5d58b1088c7e0de9", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 37, "deletions": 116, "changes": 153, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -15,7 +15,7 @@ use crate::ast::{ForeignItem, ForeignItemKind, FunctionRetTy};\n use crate::ast::{GenericParam, GenericParamKind};\n use crate::ast::GenericArg;\n use crate::ast::{Ident, ImplItem, IsAsync, IsAuto, Item, ItemKind};\n-use crate::ast::{Label, Lifetime, Lit, LitKind};\n+use crate::ast::{Label, Lifetime, Lit};\n use crate::ast::{Local, LocalSource};\n use crate::ast::MacStmtStyle;\n use crate::ast::{Mac, Mac_, MacDelimiter};\n@@ -46,7 +46,7 @@ use crate::ptr::P;\n use crate::parse::PResult;\n use crate::ThinVec;\n use crate::tokenstream::{self, DelimSpan, TokenTree, TokenStream, TreeAndJoint};\n-use crate::symbol::{Symbol, keywords};\n+use crate::symbol::{keywords, Symbol};\n \n use errors::{Applicability, DiagnosticBuilder, DiagnosticId, FatalError};\n use rustc_target::spec::abi::{self, Abi};\n@@ -1109,43 +1109,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn expect_no_suffix(&self, sp: Span, kind: &str, suffix: Option<ast::Name>) {\n-        match suffix {\n-            None => {/* everything ok */}\n-            Some(suf) => {\n-                let text = suf.as_str();\n-                if text.is_empty() {\n-                    self.span_bug(sp, \"found empty literal suffix in Some\")\n-                }\n-                let mut err = if kind == \"a tuple index\" &&\n-                    [\"i32\", \"u32\", \"isize\", \"usize\"].contains(&text.to_string().as_str())\n-                {\n-                    // #59553: warn instead of reject out of hand to allow the fix to percolate\n-                    // through the ecosystem when people fix their macros\n-                    let mut err = self.struct_span_warn(\n-                        sp,\n-                        &format!(\"suffixes on {} are invalid\", kind),\n-                    );\n-                    err.note(&format!(\n-                        \"`{}` is *temporarily* accepted on tuple index fields as it was \\\n-                         incorrectly accepted on stable for a few releases\",\n-                        text,\n-                    ));\n-                    err.help(\n-                        \"on proc macros, you'll want to use `syn::Index::from` or \\\n-                         `proc_macro::Literal::*_unsuffixed` for code that will desugar \\\n-                         to tuple field access\",\n-                    );\n-                    err.note(\n-                        \"for more context, see https://github.com/rust-lang/rust/issues/60210\",\n-                    );\n-                    err\n-                } else {\n-                    self.struct_span_err(sp, &format!(\"suffixes on {} are invalid\", kind))\n-                };\n-                err.span_label(sp, format!(\"invalid suffix `{}`\", text));\n-                err.emit();\n-            }\n-        }\n+        parse::expect_no_suffix(sp, &self.sess.span_diagnostic, kind, suffix)\n     }\n \n     /// Attempts to consume a `<`. If `<<` is seen, replaces it with a single\n@@ -1452,9 +1416,6 @@ impl<'a> Parser<'a> {\n     crate fn struct_span_err<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n         self.sess.span_diagnostic.struct_span_err(sp, m)\n     }\n-    fn struct_span_warn<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> DiagnosticBuilder<'a> {\n-        self.sess.span_diagnostic.struct_span_warn(sp, m)\n-    }\n     crate fn span_bug<S: Into<MultiSpan>>(&self, sp: S, m: &str) -> ! {\n         self.sess.span_diagnostic.span_bug(sp, m)\n     }\n@@ -2069,85 +2030,45 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    /// Matches `token_lit = LIT_INTEGER | ...`.\n-    fn parse_lit_token(&mut self) -> PResult<'a, (LitKind, token::Lit, Option<Symbol>)> {\n-        let out = match self.token {\n-            token::Interpolated(ref nt) => match **nt {\n-                token::NtExpr(ref v) | token::NtLiteral(ref v) => match v.node {\n-                    ExprKind::Lit(ref lit) => { (lit.node.clone(), lit.token, lit.suffix) }\n-                    _ => { return self.unexpected_last(&self.token); }\n-                },\n-                _ => { return self.unexpected_last(&self.token); }\n-            },\n-            token::Literal(lit, suf) => {\n-                let diag = Some((self.span, &self.sess.span_diagnostic));\n-                let (suffix_illegal, result) = parse::lit_token(lit, suf, diag);\n-\n-                if suffix_illegal {\n-                    let sp = self.span;\n-                    self.expect_no_suffix(sp, &format!(\"a {}\", lit.literal_name()), suf)\n+    /// Matches `lit = true | false | token_lit`.\n+    crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n+        let diag = Some((self.span, &self.sess.span_diagnostic));\n+        if let Some(lit) = Lit::from_token(&self.token, self.span, diag) {\n+            self.bump();\n+            return Ok(lit);\n+        } else if self.token == token::Dot {\n+            // Recover `.4` as `0.4`.\n+            let recovered = self.look_ahead(1, |t| {\n+                if let token::Literal(token::Integer(val), suf) = *t {\n+                    let next_span = self.look_ahead_span(1);\n+                    if self.span.hi() == next_span.lo() {\n+                        let sym = String::from(\"0.\") + &val.as_str();\n+                        let token = token::Literal(token::Float(Symbol::intern(&sym)), suf);\n+                        return Some((token, self.span.to(next_span)));\n+                    }\n                 }\n-\n-                (result.unwrap(), lit, suf)\n-            }\n-            token::Dot if self.look_ahead(1, |t| match t {\n-                token::Literal(token::Lit::Integer(_) , _) => true,\n-                _ => false,\n-            }) => { // recover from `let x = .4;`\n-                let lo = self.span;\n-                self.bump();\n-                if let token::Literal(\n-                    token::Lit::Integer(val),\n-                    suffix,\n-                ) = self.token {\n-                    let float_suffix = suffix.and_then(|s| {\n-                        let s = s.as_str();\n-                        if s == \"f32\" {\n-                            Some(\"f32\")\n-                        } else if s == \"f64\" {\n-                            Some(\"f64\")\n-                        } else {\n-                            None\n-                        }\n-                    }).unwrap_or(\"\");\n-                    self.bump();\n-                    let sp = lo.to(self.prev_span);\n-                    let mut err = self.diagnostic()\n-                        .struct_span_err(sp, \"float literals must have an integer part\");\n-                    err.span_suggestion(\n-                        sp,\n+                None\n+            });\n+            if let Some((token, span)) = recovered {\n+                self.diagnostic()\n+                    .struct_span_err(span, \"float literals must have an integer part\")\n+                    .span_suggestion(\n+                        span,\n                         \"must have an integer part\",\n-                        format!(\"0.{}{}\", val, float_suffix),\n+                        pprust::token_to_string(&token),\n                         Applicability::MachineApplicable,\n-                    );\n-                    err.emit();\n-                    return Ok((match float_suffix {\n-                        \"f32\" => ast::LitKind::Float(val, ast::FloatTy::F32),\n-                        \"f64\" => ast::LitKind::Float(val, ast::FloatTy::F64),\n-                        _ => ast::LitKind::FloatUnsuffixed(val),\n-                    }, token::Float(val), suffix));\n-                } else {\n-                    unreachable!();\n-                };\n+                    )\n+                    .emit();\n+                let diag = Some((span, &self.sess.span_diagnostic));\n+                if let Some(lit) = Lit::from_token(&token, span, diag) {\n+                    self.bump();\n+                    self.bump();\n+                    return Ok(lit);\n+                }\n             }\n-            _ => { return self.unexpected_last(&self.token); }\n-        };\n-\n-        self.bump();\n-        Ok(out)\n-    }\n+        }\n \n-    /// Matches `lit = true | false | token_lit`.\n-    crate fn parse_lit(&mut self) -> PResult<'a, Lit> {\n-        let lo = self.span;\n-        let (node, token, suffix) = if self.eat_keyword(keywords::True) {\n-            (LitKind::Bool(true), token::Bool(keywords::True.name()), None)\n-        } else if self.eat_keyword(keywords::False) {\n-            (LitKind::Bool(false), token::Bool(keywords::False.name()), None)\n-        } else {\n-            self.parse_lit_token()?\n-        };\n-        Ok(Lit { node, token, suffix, span: lo.to(self.prev_span) })\n+        self.unexpected_last(&self.token)\n     }\n \n     /// Matches `'-' lit | lit` (cf. `ast_validation::AstValidator::check_expr_within_pat`)."}, {"sha": "0c2ea70aa20c8e015c4576a1c2aed7a271eabdec", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -90,6 +90,13 @@ impl Lit {\n         }\n     }\n \n+    crate fn may_have_suffix(&self) -> bool {\n+        match *self {\n+            Integer(..) | Float(..) => true,\n+            _ => false,\n+        }\n+    }\n+\n     // See comments in `Nonterminal::to_tokenstream` for why we care about\n     // *probably* equal here rather than actual equality\n     fn probably_equal_for_proc_macro(&self, other: &Lit) -> bool {"}, {"sha": "0e8ac6c35b9bffb3846d68a58ddd9dcee6018212", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -162,7 +162,7 @@ fn binop_to_string(op: BinOpToken) -> &'static str {\n     }\n }\n \n-fn literal_to_string(lit: token::Lit, suffix: Option<ast::Name>) -> String {\n+pub fn literal_to_string(lit: token::Lit, suffix: Option<ast::Name>) -> String {\n     let mut out = match lit {\n         token::Byte(b)           => format!(\"b'{}'\", b),\n         token::Char(c)           => format!(\"'{}'\", c),"}, {"sha": "7c4ca3c017e7b33ad8634147566bf4c234fe64b6", "filename": "src/test/ui/malformed/malformed-interpolated.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.rs?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -2,16 +2,15 @@\n \n macro_rules! check {\n     ($expr: expr) => (\n-        #[my_attr = $expr] //~ ERROR suffixed literals are not allowed in attributes\n-                           //~| ERROR unexpected token: `-0`\n+        #[my_attr = $expr] //~ ERROR unexpected token: `-0`\n                            //~| ERROR unexpected token: `0 + 0`\n         use main as _;\n     );\n }\n \n check!(\"0\"); // OK\n check!(0); // OK\n-check!(0u8); // ERROR, see above\n+check!(0u8); //~ ERROR suffixed literals are not allowed in attributes\n check!(-0); // ERROR, see above\n check!(0 + 0); // ERROR, see above\n "}, {"sha": "bc2146e409d4796fbcebea0e09c7edfcd086785f", "filename": "src/test/ui/malformed/malformed-interpolated.stderr", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/8739668438a40712a0bc617bc587d415c8cb42f0/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmalformed%2Fmalformed-interpolated.stderr?ref=8739668438a40712a0bc617bc587d415c8cb42f0", "patch": "@@ -1,11 +1,8 @@\n error: suffixed literals are not allowed in attributes\n-  --> $DIR/malformed-interpolated.rs:5:21\n+  --> $DIR/malformed-interpolated.rs:13:8\n    |\n-LL |         #[my_attr = $expr]\n-   |                     ^^^^^\n-...\n-LL | check!(0u8); // ERROR, see above\n-   | ------------ in this macro invocation\n+LL | check!(0u8);\n+   |        ^^^\n    |\n    = help: instead of using a suffixed literal (1u8, 1.0f32, etc.), use an unsuffixed version (1, 1.0, etc.).\n "}]}