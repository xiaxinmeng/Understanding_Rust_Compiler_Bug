{"sha": "11bc14d724052e5567d794c425fcef1c3c73302d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjExYmMxNGQ3MjQwNTJlNTU2N2Q3OTRjNDI1ZmNlZjFjM2M3MzMwMmQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-02-12T04:16:47Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-02-12T04:16:47Z"}, "message": "auto merge of #11578 : alexcrichton/rust/chan-changes, r=brson\n\nThe user-facing API-level change of this commit is that `SharedChan` is gone and `Chan` now has `clone`. The major parts of this patch are the internals which have changed.\r\n\r\nChannels are now internally upgraded from oneshots to streams to shared channels depending on the use case. I've noticed a 3x improvement in the oneshot case and very little slowdown (if any) in the stream/shared case.\r\n\r\nThis patch is mostly a reorganization of the `std::comm` module, and the large increase in code is from either dispatching to one of 3 impls or the duplication between the stream/shared impl (because they're not entirely separate).\r\n\r\nThe `comm` module is now divided into `oneshot`, `stream`, `shared`, and `select` modules. Each module contains the implementation for that flavor of channel (or the select implementation for select).\r\n\r\nSome notable parts of this patch\r\n\r\n* Upgrades are done through a semi-ad-hoc scheme for oneshots and messages for streams\r\n* Upgrades are processed ASAP and have some interesting interactions with select\r\n* send_deferred is gone because I expect the mutex to land before this\r\n* Some of stream/shared is straight-up duplicated, but I like having the distinction between the two modules\r\n* Select got a little worse, but it's still \"basically limping along\"\r\n* This lumps in the patch of deallocating the queue backlog on packet drop\r\n* I'll rebase this on top of the \"more errors from try_recv\" patch once it lands (all the infrastructure is here already)\r\n\r\nAll in all, this shouldn't be merged until the new mutexes are merged (because send_deferred wasn't implemented).\r\n\r\nCloses #11351", "tree": {"sha": "e1f4e0fb9dd28b0259c5c3fa10cbd0d597a9dc88", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e1f4e0fb9dd28b0259c5c3fa10cbd0d597a9dc88"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/11bc14d724052e5567d794c425fcef1c3c73302d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/11bc14d724052e5567d794c425fcef1c3c73302d", "html_url": "https://github.com/rust-lang/rust/commit/11bc14d724052e5567d794c425fcef1c3c73302d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/11bc14d724052e5567d794c425fcef1c3c73302d/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "db8a580fb42cac26d2f2c69a6ecacc8c499ab71f", "url": "https://api.github.com/repos/rust-lang/rust/commits/db8a580fb42cac26d2f2c69a6ecacc8c499ab71f", "html_url": "https://github.com/rust-lang/rust/commit/db8a580fb42cac26d2f2c69a6ecacc8c499ab71f"}, {"sha": "e633249b31d6ecfb46a4d7d85b5be4a9dd96b1c0", "url": "https://api.github.com/repos/rust-lang/rust/commits/e633249b31d6ecfb46a4d7d85b5be4a9dd96b1c0", "html_url": "https://github.com/rust-lang/rust/commit/e633249b31d6ecfb46a4d7d85b5be4a9dd96b1c0"}], "stats": {"total": 3161, "additions": 2164, "deletions": 997}, "files": [{"sha": "9ff712df0215220773ab39a90d73c182b7e76514", "filename": "src/doc/guide-tasks.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Fdoc%2Fguide-tasks.md", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Fdoc%2Fguide-tasks.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Fguide-tasks.md?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -232,7 +232,7 @@ Instead we can use a `SharedChan`, a type that allows a single\n ~~~\n # use std::task::spawn;\n \n-let (port, chan) = SharedChan::new();\n+let (port, chan) = Chan::new();\n \n for init_val in range(0u, 3) {\n     // Create a new channel handle to distribute to the child task"}, {"sha": "9ebd91bdfb6cd538d0fbc2b9d12c43c3824e8438", "filename": "src/libextra/test.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibextra%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibextra%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Ftest.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -767,7 +767,7 @@ fn run_tests(opts: &TestOpts,\n     remaining.reverse();\n     let mut pending = 0;\n \n-    let (p, ch) = SharedChan::new();\n+    let (p, ch) = Chan::new();\n \n     while pending > 0 || !remaining.is_empty() {\n         while pending < concurrency && !remaining.is_empty() {\n@@ -878,7 +878,7 @@ pub fn filter_tests(\n \n pub fn run_test(force_ignore: bool,\n                 test: TestDescAndFn,\n-                monitor_ch: SharedChan<MonitorMsg>) {\n+                monitor_ch: Chan<MonitorMsg>) {\n \n     let TestDescAndFn {desc, testfn} = test;\n \n@@ -888,7 +888,7 @@ pub fn run_test(force_ignore: bool,\n     }\n \n     fn run_test_inner(desc: TestDesc,\n-                      monitor_ch: SharedChan<MonitorMsg>,\n+                      monitor_ch: Chan<MonitorMsg>,\n                       testfn: proc()) {\n         spawn(proc() {\n             let mut task = task::task();\n@@ -1260,7 +1260,7 @@ mod tests {\n             },\n             testfn: DynTestFn(proc() f()),\n         };\n-        let (p, ch) = SharedChan::new();\n+        let (p, ch) = Chan::new();\n         run_test(false, desc, ch);\n         let (_, res) = p.recv();\n         assert!(res != TrOk);\n@@ -1277,7 +1277,7 @@ mod tests {\n             },\n             testfn: DynTestFn(proc() f()),\n         };\n-        let (p, ch) = SharedChan::new();\n+        let (p, ch) = Chan::new();\n         run_test(false, desc, ch);\n         let (_, res) = p.recv();\n         assert_eq!(res, TrIgnored);\n@@ -1294,7 +1294,7 @@ mod tests {\n             },\n             testfn: DynTestFn(proc() f()),\n         };\n-        let (p, ch) = SharedChan::new();\n+        let (p, ch) = Chan::new();\n         run_test(false, desc, ch);\n         let (_, res) = p.recv();\n         assert_eq!(res, TrOk);\n@@ -1311,7 +1311,7 @@ mod tests {\n             },\n             testfn: DynTestFn(proc() f()),\n         };\n-        let (p, ch) = SharedChan::new();\n+        let (p, ch) = Chan::new();\n         run_test(false, desc, ch);\n         let (_, res) = p.recv();\n         assert_eq!(res, TrFailed);"}, {"sha": "834bf7951ef1ce7e79be0b1405b3a05a7f2d7f25", "filename": "src/libgreen/lib.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -193,6 +193,7 @@ use task::GreenTask;\n \n mod macros;\n mod simple;\n+mod message_queue;\n \n pub mod basic;\n pub mod context;\n@@ -314,7 +315,7 @@ pub struct SchedPool {\n #[deriving(Clone)]\n struct TaskState {\n     cnt: UnsafeArc<AtomicUint>,\n-    done: SharedChan<()>,\n+    done: Chan<()>,\n }\n \n impl SchedPool {\n@@ -468,7 +469,7 @@ impl SchedPool {\n \n impl TaskState {\n     fn new() -> (Port<()>, TaskState) {\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         (p, TaskState {\n             cnt: UnsafeArc::new(AtomicUint::new(0)),\n             done: c,"}, {"sha": "3a118476affb7c3aed3ea9f515732cc058f3563b", "filename": "src/libgreen/message_queue.rs", "status": "added", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fmessage_queue.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -0,0 +1,61 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use mpsc = std::sync::mpsc_queue;\n+use std::sync::arc::UnsafeArc;\n+\n+pub enum PopResult<T> {\n+    Inconsistent,\n+    Empty,\n+    Data(T),\n+}\n+\n+pub fn queue<T: Send>() -> (Consumer<T>, Producer<T>) {\n+    let (a, b) = UnsafeArc::new2(mpsc::Queue::new());\n+    (Consumer { inner: a }, Producer { inner: b })\n+}\n+\n+pub struct Producer<T> {\n+    priv inner: UnsafeArc<mpsc::Queue<T>>,\n+}\n+\n+pub struct Consumer<T> {\n+    priv inner: UnsafeArc<mpsc::Queue<T>>,\n+}\n+\n+impl<T: Send> Consumer<T> {\n+    pub fn pop(&mut self) -> PopResult<T> {\n+        match unsafe { (*self.inner.get()).pop() } {\n+            mpsc::Inconsistent => Inconsistent,\n+            mpsc::Empty => Empty,\n+            mpsc::Data(t) => Data(t),\n+        }\n+    }\n+\n+    pub fn casual_pop(&mut self) -> Option<T> {\n+        match unsafe { (*self.inner.get()).pop() } {\n+            mpsc::Inconsistent => None,\n+            mpsc::Empty => None,\n+            mpsc::Data(t) => Some(t),\n+        }\n+    }\n+}\n+\n+impl<T: Send> Producer<T> {\n+    pub fn push(&mut self, t: T) {\n+        unsafe { (*self.inner.get()).push(t); }\n+    }\n+}\n+\n+impl<T: Send> Clone for Producer<T> {\n+    fn clone(&self) -> Producer<T> {\n+        Producer { inner: self.inner.clone() }\n+    }\n+}"}, {"sha": "bf6e0c3430e9ccb6b8d8d1aa5fe4a6f55c00cb36", "filename": "src/libgreen/sched.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -17,14 +17,14 @@ use std::rt::task::Task;\n use std::sync::deque;\n use std::unstable::mutex::Mutex;\n use std::unstable::raw;\n-use mpsc = std::sync::mpsc_queue;\n \n use TaskState;\n use context::Context;\n use coroutine::Coroutine;\n use sleeper_list::SleeperList;\n use stack::StackPool;\n use task::{TypeSched, GreenTask, HomeSched, AnySched};\n+use msgq = message_queue;\n \n /// A scheduler is responsible for coordinating the execution of Tasks\n /// on a single thread. The scheduler runs inside a slightly modified\n@@ -47,9 +47,9 @@ pub struct Scheduler {\n     /// The queue of incoming messages from other schedulers.\n     /// These are enqueued by SchedHandles after which a remote callback\n     /// is triggered to handle the message.\n-    message_queue: mpsc::Consumer<SchedMessage, ()>,\n+    message_queue: msgq::Consumer<SchedMessage>,\n     /// Producer used to clone sched handles from\n-    message_producer: mpsc::Producer<SchedMessage, ()>,\n+    message_producer: msgq::Producer<SchedMessage>,\n     /// A shared list of sleeping schedulers. We'll use this to wake\n     /// up schedulers when pushing work onto the work queue.\n     sleeper_list: SleeperList,\n@@ -143,7 +143,7 @@ impl Scheduler {\n                        state: TaskState)\n         -> Scheduler {\n \n-        let (consumer, producer) = mpsc::queue(());\n+        let (consumer, producer) = msgq::queue();\n         let mut sched = Scheduler {\n             pool_id: pool_id,\n             sleeper_list: sleeper_list,\n@@ -215,7 +215,7 @@ impl Scheduler {\n \n         // Should not have any messages\n         let message = stask.sched.get_mut_ref().message_queue.pop();\n-        rtassert!(match message { mpsc::Empty => true, _ => false });\n+        rtassert!(match message { msgq::Empty => true, _ => false });\n \n         stask.task.get_mut_ref().destroyed = true;\n     }\n@@ -340,8 +340,8 @@ impl Scheduler {\n             //\n             // I have chosen to take route #2.\n             match self.message_queue.pop() {\n-                mpsc::Data(t) => Some(t),\n-                mpsc::Empty | mpsc::Inconsistent => None\n+                msgq::Data(t) => Some(t),\n+                msgq::Empty | msgq::Inconsistent => None\n             }\n         };\n \n@@ -849,7 +849,7 @@ pub enum SchedMessage {\n \n pub struct SchedHandle {\n     priv remote: ~RemoteCallback,\n-    priv queue: mpsc::Producer<SchedMessage, ()>,\n+    priv queue: msgq::Producer<SchedMessage>,\n     sched_id: uint\n }\n "}, {"sha": "69ef10ac11bea719dfc88c39f89a1084ff6ff2dc", "filename": "src/libnative/io/mod.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibnative%2Fio%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibnative%2Fio%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fmod.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -22,7 +22,6 @@\n //! that you would find on the respective platform.\n \n use std::c_str::CString;\n-use std::comm::SharedChan;\n use std::io;\n use std::io::IoError;\n use std::io::net::ip::SocketAddr;\n@@ -289,7 +288,7 @@ impl rtio::IoFactory for IoFactory {\n             })\n         }\n     }\n-    fn signal(&mut self, _signal: Signum, _channel: SharedChan<Signum>)\n+    fn signal(&mut self, _signal: Signum, _channel: Chan<Signum>)\n         -> IoResult<~RtioSignal> {\n         Err(unimpl())\n     }"}, {"sha": "2c976e67d25b3c1b0509d3d219a4956addf35090", "filename": "src/libnative/io/timer_helper.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibnative%2Fio%2Ftimer_helper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibnative%2Fio%2Ftimer_helper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Ftimer_helper.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -33,7 +33,7 @@ use task;\n // only torn down after everything else has exited. This means that these\n // variables are read-only during use (after initialization) and both of which\n // are safe to use concurrently.\n-static mut HELPER_CHAN: *mut SharedChan<Req> = 0 as *mut SharedChan<Req>;\n+static mut HELPER_CHAN: *mut Chan<Req> = 0 as *mut Chan<Req>;\n static mut HELPER_SIGNAL: imp::signal = 0 as imp::signal;\n \n pub fn boot(helper: fn(imp::signal, Port<Req>)) {\n@@ -43,7 +43,9 @@ pub fn boot(helper: fn(imp::signal, Port<Req>)) {\n     unsafe {\n         LOCK.lock();\n         if !INITIALIZED {\n-            let (msgp, msgc) = SharedChan::new();\n+            let (msgp, msgc) = Chan::new();\n+            // promote this to a shared channel\n+            drop(msgc.clone());\n             HELPER_CHAN = cast::transmute(~msgc);\n             let (receive, send) = imp::new();\n             HELPER_SIGNAL = send;\n@@ -84,8 +86,8 @@ fn shutdown() {\n     // Clean up after ther helper thread\n     unsafe {\n         imp::close(HELPER_SIGNAL);\n-        let _chan: ~SharedChan<Req> = cast::transmute(HELPER_CHAN);\n-        HELPER_CHAN = 0 as *mut SharedChan<Req>;\n+        let _chan: ~Chan<Req> = cast::transmute(HELPER_CHAN);\n+        HELPER_CHAN = 0 as *mut Chan<Req>;\n         HELPER_SIGNAL = 0 as imp::signal;\n     }\n }"}, {"sha": "5b697e0d73d0802fbe14b3233a65c41e18701911", "filename": "src/librustuv/queue.rs", "status": "modified", "additions": 26, "deletions": 25, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fqueue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fqueue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fqueue.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -24,6 +24,7 @@ use std::cast;\n use std::libc::{c_void, c_int};\n use std::rt::task::BlockedTask;\n use std::unstable::sync::LittleLock;\n+use std::sync::arc::UnsafeArc;\n use mpsc = std::sync::mpsc_queue;\n \n use async::AsyncWatcher;\n@@ -39,46 +40,46 @@ enum Message {\n struct State {\n     handle: *uvll::uv_async_t,\n     lock: LittleLock, // see comments in async_cb for why this is needed\n+    queue: mpsc::Queue<Message>,\n }\n \n /// This structure is intended to be stored next to the event loop, and it is\n /// used to create new `Queue` structures.\n pub struct QueuePool {\n-    priv producer: mpsc::Producer<Message, State>,\n-    priv consumer: mpsc::Consumer<Message, State>,\n+    priv queue: UnsafeArc<State>,\n     priv refcnt: uint,\n }\n \n /// This type is used to send messages back to the original event loop.\n pub struct Queue {\n-    priv queue: mpsc::Producer<Message, State>,\n+    priv queue: UnsafeArc<State>,\n }\n \n extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n     assert_eq!(status, 0);\n-    let state: &mut QueuePool = unsafe {\n+    let pool: &mut QueuePool = unsafe {\n         cast::transmute(uvll::get_data_for_uv_handle(handle))\n     };\n-    let packet = unsafe { state.consumer.packet() };\n+    let state: &mut State = unsafe { cast::transmute(pool.queue.get()) };\n \n     // Remember that there is no guarantee about how many times an async\n     // callback is called with relation to the number of sends, so process the\n     // entire queue in a loop.\n     loop {\n-        match state.consumer.pop() {\n+        match state.queue.pop() {\n             mpsc::Data(Task(task)) => {\n                 let _ = task.wake().map(|t| t.reawaken());\n             }\n             mpsc::Data(Increment) => unsafe {\n-                if state.refcnt == 0 {\n-                    uvll::uv_ref((*packet).handle);\n+                if pool.refcnt == 0 {\n+                    uvll::uv_ref(state.handle);\n                 }\n-                state.refcnt += 1;\n+                pool.refcnt += 1;\n             },\n             mpsc::Data(Decrement) => unsafe {\n-                state.refcnt -= 1;\n-                if state.refcnt == 0 {\n-                    uvll::uv_unref((*packet).handle);\n+                pool.refcnt -= 1;\n+                if pool.refcnt == 0 {\n+                    uvll::uv_unref(state.handle);\n                 }\n             },\n             mpsc::Empty | mpsc::Inconsistent => break\n@@ -99,24 +100,24 @@ extern fn async_cb(handle: *uvll::uv_async_t, status: c_int) {\n     // If we acquire the mutex here, then we are guaranteed that there are no\n     // longer any senders which are holding on to their handles, so we can\n     // safely allow the event loop to exit.\n-    if state.refcnt == 0 {\n+    if pool.refcnt == 0 {\n         unsafe {\n-            let _l = (*packet).lock.lock();\n+            let _l = state.lock.lock();\n         }\n     }\n }\n \n impl QueuePool {\n     pub fn new(loop_: &mut Loop) -> ~QueuePool {\n         let handle = UvHandle::alloc(None::<AsyncWatcher>, uvll::UV_ASYNC);\n-        let (c, p) = mpsc::queue(State {\n+        let state = UnsafeArc::new(State {\n             handle: handle,\n             lock: LittleLock::new(),\n+            queue: mpsc::Queue::new(),\n         });\n         let q = ~QueuePool {\n-            producer: p,\n-            consumer: c,\n             refcnt: 0,\n+            queue: state,\n         };\n \n         unsafe {\n@@ -132,23 +133,23 @@ impl QueuePool {\n     pub fn queue(&mut self) -> Queue {\n         unsafe {\n             if self.refcnt == 0 {\n-                uvll::uv_ref((*self.producer.packet()).handle);\n+                uvll::uv_ref((*self.queue.get()).handle);\n             }\n             self.refcnt += 1;\n         }\n-        Queue { queue: self.producer.clone() }\n+        Queue { queue: self.queue.clone() }\n     }\n \n     pub fn handle(&self) -> *uvll::uv_async_t {\n-        unsafe { (*self.producer.packet()).handle }\n+        unsafe { (*self.queue.get()).handle }\n     }\n }\n \n impl Queue {\n     pub fn push(&mut self, task: BlockedTask) {\n-        self.queue.push(Task(task));\n         unsafe {\n-            uvll::uv_async_send((*self.queue.packet()).handle);\n+            (*self.queue.get()).queue.push(Task(task));\n+            uvll::uv_async_send((*self.queue.get()).handle);\n         }\n     }\n }\n@@ -161,7 +162,7 @@ impl Clone for Queue {\n         // and if the queue is dropped later on it'll see the increment for the\n         // decrement anyway.\n         unsafe {\n-            cast::transmute_mut(self).queue.push(Increment);\n+            (*self.queue.get()).queue.push(Increment);\n         }\n         Queue { queue: self.queue.clone() }\n     }\n@@ -172,9 +173,9 @@ impl Drop for Queue {\n         // See the comments in the async_cb function for why there is a lock\n         // that is acquired only on a drop.\n         unsafe {\n-            let state = self.queue.packet();\n+            let state = self.queue.get();\n             let _l = (*state).lock.lock();\n-            self.queue.push(Decrement);\n+            (*state).queue.push(Decrement);\n             uvll::uv_async_send((*state).handle);\n         }\n     }"}, {"sha": "0a66c3445ee4273a7c2bf8e9b678beae71c16bfd", "filename": "src/librustuv/signal.rs", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fsignal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fsignal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fsignal.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -10,7 +10,6 @@\n \n use std::libc::c_int;\n use std::io::signal::Signum;\n-use std::comm::SharedChan;\n use std::rt::rtio::RtioSignal;\n \n use homing::{HomingIO, HomeHandle};\n@@ -22,13 +21,13 @@ pub struct SignalWatcher {\n     handle: *uvll::uv_signal_t,\n     home: HomeHandle,\n \n-    channel: SharedChan<Signum>,\n+    channel: Chan<Signum>,\n     signal: Signum,\n }\n \n impl SignalWatcher {\n     pub fn new(io: &mut UvIoFactory, signum: Signum,\n-               channel: SharedChan<Signum>) -> Result<~SignalWatcher, UvError> {\n+               channel: Chan<Signum>) -> Result<~SignalWatcher, UvError> {\n         let s = ~SignalWatcher {\n             handle: UvHandle::alloc(None::<SignalWatcher>, uvll::UV_SIGNAL),\n             home: io.make_handle(),\n@@ -81,7 +80,7 @@ mod test {\n     #[test]\n     fn closing_channel_during_drop_doesnt_kill_everything() {\n         // see issue #10375, relates to timers as well.\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         let _signal = SignalWatcher::new(local_loop(), signal::Interrupt,\n                                          chan);\n "}, {"sha": "54db4b4d3d13f422e3cdf9974a55d2be09774901", "filename": "src/librustuv/uvio.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fuvio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibrustuv%2Fuvio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustuv%2Fuvio.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -10,7 +10,6 @@\n \n use std::c_str::CString;\n use std::cast;\n-use std::comm::SharedChan;\n use std::io::IoError;\n use std::io::net::ip::SocketAddr;\n use std::io::process::ProcessConfig;\n@@ -304,7 +303,7 @@ impl IoFactory for UvIoFactory {\n         }\n     }\n \n-    fn signal(&mut self, signum: Signum, channel: SharedChan<Signum>)\n+    fn signal(&mut self, signum: Signum, channel: Chan<Signum>)\n         -> Result<~rtio::RtioSignal, IoError> {\n         match SignalWatcher::new(self, signum, channel) {\n             Ok(s) => Ok(s as ~rtio::RtioSignal),"}, {"sha": "3487a92d8491cfa25c3274ba8a35d1716a328de1", "filename": "src/libstd/comm/mod.rs", "status": "modified", "additions": 307, "deletions": 500, "changes": 807, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fmod.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -15,17 +15,16 @@\n //! communication between concurrent tasks. The primitives defined in this\n //! module are the building blocks for synchronization in rust.\n //!\n-//! This module currently provides three main types:\n+//! This module currently provides two types:\n //!\n //! * `Chan`\n //! * `Port`\n-//! * `SharedChan`\n //!\n-//! The `Chan` and `SharedChan` types are used to send data to a `Port`. A\n-//! `SharedChan` is clone-able such that many tasks can send simultaneously to\n-//! one receiving port. These communication primitives are *task blocking*, not\n-//! *thread blocking*. This means that if one task is blocked on a channel,\n-//! other tasks can continue to make progress.\n+//! `Chan` is used to send data to a `Port`. A `Chan` is clone-able such that\n+//! many tasks can send simultaneously to one receiving port. These\n+//! communication primitives are *task blocking*, not *thread blocking*. This\n+//! means that if one task is blocked on a channel, other tasks can continue to\n+//! make progress.\n //!\n //! Rust channels can be used as if they have an infinite internal buffer. What\n //! this means is that the `send` operation will never block. `Port`s, on the\n@@ -39,8 +38,8 @@\n //! next operation `fail!`. The purpose of this is to allow propagation of\n //! failure among tasks that are linked to one another via channels.\n //!\n-//! There are methods on all of `Chan`, `SharedChan`, and `Port` to perform\n-//! their respective operations without failing, however.\n+//! There are methods on both of `Chan` and `Port` to perform their respective\n+//! operations without failing, however.\n //!\n //! ## Outside the Runtime\n //!\n@@ -66,7 +65,7 @@\n //! assert_eq!(port.recv(), 10);\n //!\n //! // Create a shared channel which can be sent along from many tasks\n-//! let (port, chan) = SharedChan::new();\n+//! let (port, chan) = Chan::new();\n //! for i in range(0, 10) {\n //!     let chan = chan.clone();\n //!     spawn(proc() {\n@@ -100,10 +99,22 @@\n //\n // ## Flavors of channels\n //\n-// Rust channels come in two flavors: streams and shared channels. A stream has\n-// one sender and one receiver while a shared channel could have multiple\n-// senders. This choice heavily influences the design of the protocol set\n-// forth for both senders/receivers.\n+// From the perspective of a consumer of this library, there is only one flavor\n+// of channel. This channel can be used as a stream and cloned to allow multiple\n+// senders. Under the hood, however, there are actually three flavors of\n+// channels in play.\n+//\n+// * Oneshots - these channels are highly optimized for the one-send use case.\n+//              They contain as few atomics as possible and involve one and\n+//              exactly one allocation.\n+// * Streams - these channels are optimized for the non-shared use case. They\n+//             use a different concurrent queue which is more tailored for this\n+//             use case. The initial allocation of this flavor of channel is not\n+//             optimized.\n+// * Shared - this is the most general form of channel that this module offers,\n+//            a channel with multiple senders. This type is as optimized as it\n+//            can be, but the previous two types mentioned are much faster for\n+//            their use-cases.\n //\n // ## Concurrent queues\n //\n@@ -226,25 +237,20 @@\n // here's the code for you to find some more!\n \n use cast;\n+use cell::Cell;\n use clone::Clone;\n-use container::Container;\n-use int;\n use iter::Iterator;\n-use kinds::marker;\n use kinds::Send;\n+use kinds::marker;\n+use mem;\n use ops::Drop;\n-use option::{Option, Some, None};\n-use result::{Ok, Err};\n+use option::{Some, None, Option};\n+use result::{Ok, Err, Result};\n use rt::local::Local;\n use rt::task::{Task, BlockedTask};\n-use rt::thread::Thread;\n-use sync::atomics::{AtomicInt, AtomicBool, SeqCst, Relaxed};\n-use vec::OwnedVector;\n-\n-use spsc = sync::spsc_queue;\n-use mpsc = sync::mpsc_queue;\n+use sync::arc::UnsafeArc;\n \n-pub use self::select::{Select, Handle};\n+pub use comm::select::{Select, Handle};\n \n macro_rules! test (\n     { fn $name:ident() $b:block $($a:attr)*} => (\n@@ -272,34 +278,19 @@ macro_rules! test (\n )\n \n mod select;\n+mod oneshot;\n+mod stream;\n+mod shared;\n \n-///////////////////////////////////////////////////////////////////////////////\n-// Helper type to abstract ports for channels and shared channels\n-///////////////////////////////////////////////////////////////////////////////\n-\n-enum Consumer<T> {\n-    SPSC(spsc::Consumer<T, Packet>),\n-    MPSC(mpsc::Consumer<T, Packet>),\n-}\n-\n-impl<T: Send> Consumer<T>{\n-    unsafe fn packet(&self) -> *mut Packet {\n-        match *self {\n-            SPSC(ref c) => c.packet(),\n-            MPSC(ref c) => c.packet(),\n-        }\n-    }\n-}\n-\n-///////////////////////////////////////////////////////////////////////////////\n-// Public structs\n-///////////////////////////////////////////////////////////////////////////////\n+// Use a power of 2 to allow LLVM to optimize to something that's not a\n+// division, this is hit pretty regularly.\n+static RESCHED_FREQ: int = 256;\n \n /// The receiving-half of Rust's channel type. This half can only be owned by\n /// one task\n pub struct Port<T> {\n-    priv queue: Consumer<T>,\n-\n+    priv inner: Flavor<T>,\n+    priv receives: Cell<uint>,\n     // can't share in an arc\n     priv marker: marker::NoFreeze,\n }\n@@ -314,23 +305,12 @@ pub struct Messages<'a, T> {\n /// The sending-half of Rust's channel type. This half can only be owned by one\n /// task\n pub struct Chan<T> {\n-    priv queue: spsc::Producer<T, Packet>,\n-\n+    priv inner: Flavor<T>,\n+    priv sends: Cell<uint>,\n     // can't share in an arc\n     priv marker: marker::NoFreeze,\n }\n \n-/// The sending-half of Rust's channel type. This half can be shared among many\n-/// tasks by creating copies of itself through the `clone` method.\n-pub struct SharedChan<T> {\n-    priv queue: mpsc::Producer<T, Packet>,\n-\n-    // can't share in an arc -- technically this implementation is\n-    // shareable, but it shouldn't be required to be shareable in an\n-    // arc\n-    priv marker: marker::NoFreeze,\n-}\n-\n /// This enumeration is the list of the possible reasons that try_recv could not\n /// return data when called.\n #[deriving(Eq, Clone)]\n@@ -345,215 +325,23 @@ pub enum TryRecvResult<T> {\n     Data(T),\n }\n \n-///////////////////////////////////////////////////////////////////////////////\n-// Internal struct definitions\n-///////////////////////////////////////////////////////////////////////////////\n-\n-struct Packet {\n-    cnt: AtomicInt, // How many items are on this channel\n-    steals: int,    // How many times has a port received without blocking?\n-    to_wake: Option<BlockedTask>, // Task to wake up\n-\n-    // This lock is used to wake up native threads blocked in select. The\n-    // `lock` field is not used because the thread blocking in select must\n-    // block on only one mutex.\n-    //selection_lock: Option<UnsafeArc<Mutex>>,\n-\n-    // The number of channels which are currently using this packet. This is\n-    // used to reference count shared channels.\n-    channels: AtomicInt,\n-\n-    selecting: AtomicBool,\n-    selection_id: uint,\n-    select_next: *mut Packet,\n-    select_prev: *mut Packet,\n-    recv_cnt: int,\n-}\n-\n-///////////////////////////////////////////////////////////////////////////////\n-// All implementations -- the fun part\n-///////////////////////////////////////////////////////////////////////////////\n-\n-static DISCONNECTED: int = int::MIN;\n-static RESCHED_FREQ: int = 200;\n-\n-impl Packet {\n-    fn new() -> Packet {\n-        Packet {\n-            cnt: AtomicInt::new(0),\n-            steals: 0,\n-            to_wake: None,\n-            channels: AtomicInt::new(1),\n-\n-            selecting: AtomicBool::new(false),\n-            selection_id: 0,\n-            select_next: 0 as *mut Packet,\n-            select_prev: 0 as *mut Packet,\n-            recv_cnt: 0,\n-        }\n-    }\n-\n-    // Increments the channel size count, preserving the disconnected state if\n-    // the other end has disconnected.\n-    fn increment(&mut self) -> int {\n-        match self.cnt.fetch_add(1, SeqCst) {\n-            DISCONNECTED => {\n-                // see the comment in 'try' for a shared channel for why this\n-                // window of \"not disconnected\" is \"ok\".\n-                self.cnt.store(DISCONNECTED, SeqCst);\n-                DISCONNECTED\n-            }\n-            n => n\n-        }\n-    }\n-\n-    // Decrements the reference count of the channel, returning whether the task\n-    // should block or not. This assumes that the task is ready to sleep in that\n-    // the `to_wake` field has already been filled in. Once this decrement\n-    // happens, the task could wake up on the other end.\n-    //\n-    // From an implementation perspective, this is also when our \"steal count\"\n-    // gets merged into the \"channel count\". Our steal count is reset to 0 after\n-    // this function completes.\n-    //\n-    // As with increment(), this preserves the disconnected state if the\n-    // channel is disconnected.\n-    fn decrement(&mut self) -> bool {\n-        let steals = self.steals;\n-        self.steals = 0;\n-        match self.cnt.fetch_sub(1 + steals, SeqCst) {\n-            DISCONNECTED => {\n-                self.cnt.store(DISCONNECTED, SeqCst);\n-                false\n-            }\n-            n => {\n-                assert!(n >= 0);\n-                n - steals <= 0\n-            }\n-        }\n-    }\n-\n-    // Helper function for select, tests whether this port can receive without\n-    // blocking (obviously not an atomic decision).\n-    fn can_recv(&self) -> bool {\n-        let cnt = self.cnt.load(SeqCst);\n-        cnt == DISCONNECTED || cnt - self.steals > 0\n-    }\n-\n-    // This function must have had at least an acquire fence before it to be\n-    // properly called.\n-    fn wakeup(&mut self) {\n-        match self.to_wake.take_unwrap().wake() {\n-            Some(task) => task.reawaken(),\n-            None => {}\n-        }\n-        self.selecting.store(false, Relaxed);\n-    }\n-\n-    // Aborts the selection process for a port. This happens as part of select()\n-    // once the task has reawoken. This will place the channel back into a\n-    // consistent state which is ready to be received from again.\n-    //\n-    // The method of doing this is a little subtle. These channels have the\n-    // invariant that if -1 is seen, then to_wake is always Some(..) and should\n-    // be woken up. This aborting process at least needs to add 1 to the\n-    // reference count, but that is not guaranteed to make the count positive\n-    // (our steal count subtraction could mean that after the addition the\n-    // channel count is still negative).\n-    //\n-    // In order to get around this, we force our channel count to go above 0 by\n-    // adding a large number >= 1 to it. This way no sender will see -1 unless\n-    // we are indeed blocking. This \"extra lump\" we took out of the channel\n-    // becomes our steal count (which will get re-factored into the count on the\n-    // next blocking recv)\n-    //\n-    // The return value of this method is whether there is data on this channel\n-    // to receive or not.\n-    fn abort_selection(&mut self, take_to_wake: bool) -> bool {\n-        // make sure steals + 1 makes the count go non-negative\n-        let steals = {\n-            let cnt = self.cnt.load(SeqCst);\n-            if cnt < 0 && cnt != DISCONNECTED {-cnt} else {0}\n-        };\n-        let prev = self.cnt.fetch_add(steals + 1, SeqCst);\n-\n-        // If we were previously disconnected, then we know for sure that there\n-        // is no task in to_wake, so just keep going\n-        if prev == DISCONNECTED {\n-            assert!(self.to_wake.is_none());\n-            self.cnt.store(DISCONNECTED, SeqCst);\n-            self.selecting.store(false, SeqCst);\n-            true // there is data, that data is that we're disconnected\n-        } else {\n-            let cur = prev + steals + 1;\n-            assert!(cur >= 0);\n-\n-            // If the previous count was negative, then we just made things go\n-            // positive, hence we passed the -1 boundary and we're responsible\n-            // for removing the to_wake() field and trashing it.\n-            if prev < 0 {\n-                if take_to_wake {\n-                    self.to_wake.take_unwrap().trash();\n-                } else {\n-                    assert!(self.to_wake.is_none());\n-                }\n-\n-                // We woke ourselves up, we're responsible for cancelling\n-                assert!(self.selecting.load(Relaxed));\n-                self.selecting.store(false, Relaxed);\n-            }\n-            assert_eq!(self.steals, 0);\n-            self.steals = steals;\n-\n-            // if we were previously positive, then there's surely data to\n-            // receive\n-            prev >= 0\n-        }\n-    }\n-\n-    // Decrement the reference count on a channel. This is called whenever a\n-    // Chan is dropped and may end up waking up a receiver. It's the receiver's\n-    // responsibility on the other end to figure out that we've disconnected.\n-    unsafe fn drop_chan(&mut self) {\n-        match self.channels.fetch_sub(1, SeqCst) {\n-            1 => {\n-                match self.cnt.swap(DISCONNECTED, SeqCst) {\n-                    -1 => { self.wakeup(); }\n-                    DISCONNECTED => {}\n-                    n => { assert!(n >= 0); }\n-                }\n-            }\n-            n if n > 1 => {},\n-            n => fail!(\"bad number of channels left {}\", n),\n-        }\n-    }\n-}\n-\n-impl Drop for Packet {\n-    fn drop(&mut self) {\n-        unsafe {\n-            // Note that this load is not only an assert for correctness about\n-            // disconnection, but also a proper fence before the read of\n-            // `to_wake`, so this assert cannot be removed with also removing\n-            // the `to_wake` assert.\n-            assert_eq!(self.cnt.load(SeqCst), DISCONNECTED);\n-            assert!(self.to_wake.is_none());\n-            assert_eq!(self.channels.load(SeqCst), 0);\n-        }\n-    }\n+enum Flavor<T> {\n+    Oneshot(UnsafeArc<oneshot::Packet<T>>),\n+    Stream(UnsafeArc<stream::Packet<T>>),\n+    Shared(UnsafeArc<shared::Packet<T>>),\n }\n \n impl<T: Send> Chan<T> {\n     /// Creates a new port/channel pair. All data send on the channel returned\n     /// will become available on the port as well. See the documentation of\n     /// `Port` and `Chan` to see what's possible with them.\n     pub fn new() -> (Port<T>, Chan<T>) {\n-        // arbitrary 128 size cache -- this is just a max cache size, not a\n-        // maximum buffer size\n-        let (c, p) = spsc::queue(128, Packet::new());\n-        let c = SPSC(c);\n-        (Port { queue: c, marker: marker::NoFreeze },\n-         Chan { queue: p, marker: marker::NoFreeze })\n+        let (a, b) = UnsafeArc::new2(oneshot::Packet::new());\n+        (Port::my_new(Oneshot(a)), Chan::my_new(Oneshot(b)))\n+    }\n+\n+    fn my_new(inner: Flavor<T>) -> Chan<T> {\n+        Chan { inner: inner, sends: Cell::new(0), marker: marker::NoFreeze }\n     }\n \n     /// Sends a value along this channel to be received by the corresponding\n@@ -595,132 +383,105 @@ impl<T: Send> Chan<T> {\n     /// Like `send`, this method will never block. If the failure of send cannot\n     /// be tolerated, then this method should be used instead.\n     pub fn try_send(&self, t: T) -> bool {\n-        unsafe {\n-            let this = cast::transmute_mut(self);\n-            this.queue.push(t);\n-            let packet = this.queue.packet();\n-            match (*packet).increment() {\n-                // As described above, -1 == wakeup\n-                -1 => { (*packet).wakeup(); true }\n-                // Also as above, SPSC queues must be >= -2\n-                -2 => true,\n-                // We succeeded if we sent data\n-                DISCONNECTED => this.queue.is_empty(),\n-                // In order to prevent starvation of other tasks in situations\n-                // where a task sends repeatedly without ever receiving, we\n-                // occassionally yield instead of doing a send immediately.\n-                // Only doing this if we're doing a rescheduling send, otherwise\n-                // the caller is expecting not to context switch.\n-                //\n-                // Note that we don't unconditionally attempt to yield because\n-                // the TLS overhead can be a bit much.\n-                n => {\n-                    assert!(n >= 0);\n-                    if n > 0 && n % RESCHED_FREQ == 0 {\n-                        let task: ~Task = Local::take();\n-                        task.maybe_yield();\n+        // In order to prevent starvation of other tasks in situations where\n+        // a task sends repeatedly without ever receiving, we occassionally\n+        // yield instead of doing a send immediately.  Only doing this if\n+        // we're doing a rescheduling send, otherwise the caller is\n+        // expecting not to context switch.\n+        //\n+        // Note that we don't unconditionally attempt to yield because the\n+        // TLS overhead can be a bit much.\n+        let cnt = self.sends.get() + 1;\n+        self.sends.set(cnt);\n+        if cnt % (RESCHED_FREQ as uint) == 0 {\n+            let task: ~Task = Local::take();\n+            task.maybe_yield();\n+        }\n+\n+        let (new_inner, ret) = match self.inner {\n+            Oneshot(ref p) => {\n+                let p = p.get();\n+                unsafe {\n+                    if !(*p).sent() {\n+                        return (*p).send(t);\n+                    } else {\n+                        let (a, b) = UnsafeArc::new2(stream::Packet::new());\n+                        match (*p).upgrade(Port::my_new(Stream(b))) {\n+                            oneshot::UpSuccess => {\n+                                (*a.get()).send(t);\n+                                (a, true)\n+                            }\n+                            oneshot::UpDisconnected => (a, false),\n+                            oneshot::UpWoke(task) => {\n+                                (*a.get()).send(t);\n+                                task.wake().map(|t| t.reawaken());\n+                                (a, true)\n+                            }\n+                        }\n                     }\n-                    true\n                 }\n             }\n-        }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<T: Send> Drop for Chan<T> {\n-    fn drop(&mut self) {\n-        unsafe { (*self.queue.packet()).drop_chan(); }\n-    }\n-}\n-\n-impl<T: Send> SharedChan<T> {\n-    /// Creates a new shared channel and port pair. The purpose of a shared\n-    /// channel is to be cloneable such that many tasks can send data at the\n-    /// same time. All data sent on any channel will become available on the\n-    /// provided port as well.\n-    pub fn new() -> (Port<T>, SharedChan<T>) {\n-        let (c, p) = mpsc::queue(Packet::new());\n-        let c = MPSC(c);\n-        (Port { queue: c, marker: marker::NoFreeze },\n-         SharedChan { queue: p, marker: marker::NoFreeze })\n-    }\n+            Stream(ref p) => return unsafe { (*p.get()).send(t) },\n+            Shared(ref p) => return unsafe { (*p.get()).send(t) },\n+        };\n \n-    /// Equivalent method to `send` on the `Chan` type (using the same\n-    /// semantics)\n-    pub fn send(&self, t: T) {\n-        if !self.try_send(t) {\n-            fail!(\"sending on a closed channel\");\n+        unsafe {\n+            let mut tmp = Chan::my_new(Stream(new_inner));\n+            mem::swap(&mut cast::transmute_mut(self).inner, &mut tmp.inner);\n         }\n+        return ret;\n     }\n+}\n \n-    /// Equivalent method to `try_send` on the `Chan` type (using the same\n-    /// semantics)\n-    pub fn try_send(&self, t: T) -> bool {\n-        unsafe {\n-            // Note that the multiple sender case is a little tricker\n-            // semantically than the single sender case. The logic for\n-            // incrementing is \"add and if disconnected store disconnected\".\n-            // This could end up leading some senders to believe that there\n-            // wasn't a disconnect if in fact there was a disconnect. This means\n-            // that while one thread is attempting to re-store the disconnected\n-            // states, other threads could walk through merrily incrementing\n-            // this very-negative disconnected count. To prevent senders from\n-            // spuriously attempting to send when the channels is actually\n-            // disconnected, the count has a ranged check here.\n-            //\n-            // This is also done for another reason. Remember that the return\n-            // value of this function is:\n-            //\n-            //  `true` == the data *may* be received, this essentially has no\n-            //            meaning\n-            //  `false` == the data will *never* be received, this has a lot of\n-            //             meaning\n-            //\n-            // In the SPSC case, we have a check of 'queue.is_empty()' to see\n-            // whether the data was actually received, but this same condition\n-            // means nothing in a multi-producer context. As a result, this\n-            // preflight check serves as the definitive \"this will never be\n-            // received\". Once we get beyond this check, we have permanently\n-            // entered the realm of \"this may be received\"\n-            let packet = self.queue.packet();\n-            if (*packet).cnt.load(Relaxed) < DISCONNECTED + 1024 {\n-                return false\n+impl<T: Send> Clone for Chan<T> {\n+    fn clone(&self) -> Chan<T> {\n+        let (packet, sleeper) = match self.inner {\n+            Oneshot(ref p) => {\n+                let (a, b) = UnsafeArc::new2(shared::Packet::new());\n+                match unsafe { (*p.get()).upgrade(Port::my_new(Shared(a))) } {\n+                    oneshot::UpSuccess | oneshot::UpDisconnected => (b, None),\n+                    oneshot::UpWoke(task) => (b, Some(task))\n+                }\n             }\n-\n-            let this = cast::transmute_mut(self);\n-            this.queue.push(t);\n-\n-            match (*packet).increment() {\n-                DISCONNECTED => {} // oh well, we tried\n-                -1 => { (*packet).wakeup(); }\n-                n => {\n-                    if n > 0 && n % RESCHED_FREQ == 0 {\n-                        let task: ~Task = Local::take();\n-                        task.maybe_yield();\n-                    }\n+            Stream(ref p) => {\n+                let (a, b) = UnsafeArc::new2(shared::Packet::new());\n+                match unsafe { (*p.get()).upgrade(Port::my_new(Shared(a))) } {\n+                    stream::UpSuccess | stream::UpDisconnected => (b, None),\n+                    stream::UpWoke(task) => (b, Some(task)),\n                 }\n             }\n-            true\n-        }\n-    }\n-}\n+            Shared(ref p) => {\n+                unsafe { (*p.get()).clone_chan(); }\n+                return Chan::my_new(Shared(p.clone()));\n+            }\n+        };\n+\n+        unsafe {\n+            (*packet.get()).inherit_blocker(sleeper);\n \n-impl<T: Send> Clone for SharedChan<T> {\n-    fn clone(&self) -> SharedChan<T> {\n-        unsafe { (*self.queue.packet()).channels.fetch_add(1, SeqCst); }\n-        SharedChan { queue: self.queue.clone(), marker: marker::NoFreeze }\n+            let mut tmp = Chan::my_new(Shared(packet.clone()));\n+            mem::swap(&mut cast::transmute_mut(self).inner, &mut tmp.inner);\n+        }\n+        Chan::my_new(Shared(packet))\n     }\n }\n \n #[unsafe_destructor]\n-impl<T: Send> Drop for SharedChan<T> {\n+impl<T: Send> Drop for Chan<T> {\n     fn drop(&mut self) {\n-        unsafe { (*self.queue.packet()).drop_chan(); }\n+        match self.inner {\n+            Oneshot(ref mut p) => unsafe { (*p.get()).drop_chan(); },\n+            Stream(ref mut p) => unsafe { (*p.get()).drop_chan(); },\n+            Shared(ref mut p) => unsafe { (*p.get()).drop_chan(); },\n+        }\n     }\n }\n \n impl<T: Send> Port<T> {\n+    fn my_new(inner: Flavor<T>) -> Port<T> {\n+        Port { inner: inner, receives: Cell::new(0), marker: marker::NoFreeze }\n+    }\n+\n     /// Blocks waiting for a value on this port\n     ///\n     /// This function will block if necessary to wait for a corresponding send\n@@ -758,100 +519,45 @@ impl<T: Send> Port<T> {\n     ///\n     /// This function cannot fail.\n     pub fn try_recv(&self) -> TryRecvResult<T> {\n-        self.try_recv_inc(true)\n-    }\n-\n-    fn try_recv_inc(&self, increment: bool) -> TryRecvResult<T> {\n-        // This is a \"best effort\" situation, so if a queue is inconsistent just\n-        // don't worry about it.\n-        let this = unsafe { cast::transmute_mut(self) };\n-\n-        // See the comment about yielding on sends, but the same applies here.\n-        // If a thread is spinning in try_recv we should try\n-        unsafe {\n-            let packet = this.queue.packet();\n-            (*packet).recv_cnt += 1;\n-            if (*packet).recv_cnt % RESCHED_FREQ == 0 {\n-                let task: ~Task = Local::take();\n-                task.maybe_yield();\n-            }\n+        // If a thread is spinning in try_recv, we should take the opportunity\n+        // to reschedule things occasionally. See notes above in scheduling on\n+        // sends for why this doesn't always hit TLS.\n+        let cnt = self.receives.get() + 1;\n+        self.receives.set(cnt);\n+        if cnt % (RESCHED_FREQ as uint) == 0 {\n+            let task: ~Task = Local::take();\n+            task.maybe_yield();\n         }\n \n-        let ret = match this.queue {\n-            SPSC(ref mut queue) => queue.pop(),\n-            MPSC(ref mut queue) => match queue.pop() {\n-                mpsc::Data(t) => Some(t),\n-                mpsc::Empty => None,\n-\n-                // This is a bit of an interesting case. The channel is\n-                // reported as having data available, but our pop() has\n-                // failed due to the queue being in an inconsistent state.\n-                // This means that there is some pusher somewhere which has\n-                // yet to complete, but we are guaranteed that a pop will\n-                // eventually succeed. In this case, we spin in a yield loop\n-                // because the remote sender should finish their enqueue\n-                // operation \"very quickly\".\n-                //\n-                // Note that this yield loop does *not* attempt to do a green\n-                // yield (regardless of the context), but *always* performs an\n-                // OS-thread yield. The reasoning for this is that the pusher in\n-                // question which is causing the inconsistent state is\n-                // guaranteed to *not* be a blocked task (green tasks can't get\n-                // pre-empted), so it must be on a different OS thread. Also,\n-                // `try_recv` is normally a \"guaranteed no rescheduling\" context\n-                // in a green-thread situation. By yielding control of the\n-                // thread, we will hopefully allow time for the remote task on\n-                // the other OS thread to make progress.\n-                //\n-                // Avoiding this yield loop would require a different queue\n-                // abstraction which provides the guarantee that after M\n-                // pushes have succeeded, at least M pops will succeed. The\n-                // current queues guarantee that if there are N active\n-                // pushes, you can pop N times once all N have finished.\n-                mpsc::Inconsistent => {\n-                    let data;\n-                    loop {\n-                        Thread::yield_now();\n-                        match queue.pop() {\n-                            mpsc::Data(t) => { data = t; break }\n-                            mpsc::Empty => fail!(\"inconsistent => empty\"),\n-                            mpsc::Inconsistent => {}\n-                        }\n+        loop {\n+            let mut new_port = match self.inner {\n+                Oneshot(ref p) => {\n+                    match unsafe { (*p.get()).try_recv() } {\n+                        Ok(t) => return Data(t),\n+                        Err(oneshot::Empty) => return Empty,\n+                        Err(oneshot::Disconnected) => return Disconnected,\n+                        Err(oneshot::Upgraded(port)) => port,\n                     }\n-                    Some(data)\n                 }\n-            }\n-        };\n-        if increment && ret.is_some() {\n-            unsafe { (*this.queue.packet()).steals += 1; }\n-        }\n-        match ret {\n-            Some(t) => Data(t),\n-            None => {\n-                // It's possible that between the time that we saw the queue was\n-                // empty and here the other side disconnected. It's also\n-                // possible for us to see the disconnection here while there is\n-                // data in the queue. It's pretty backwards-thinking to return\n-                // Disconnected when there's actually data on the queue, so if\n-                // we see a disconnected state be sure to check again to be 100%\n-                // sure that there's no data in the queue.\n-                let cnt = unsafe { (*this.queue.packet()).cnt.load(Relaxed) };\n-                if cnt != DISCONNECTED { return Empty }\n-\n-                let ret = match this.queue {\n-                    SPSC(ref mut queue) => queue.pop(),\n-                    MPSC(ref mut queue) => match queue.pop() {\n-                        mpsc::Data(t) => Some(t),\n-                        mpsc::Empty => None,\n-                        mpsc::Inconsistent => {\n-                            fail!(\"inconsistent with no senders?!\");\n-                        }\n+                Stream(ref p) => {\n+                    match unsafe { (*p.get()).try_recv() } {\n+                        Ok(t) => return Data(t),\n+                        Err(stream::Empty) => return Empty,\n+                        Err(stream::Disconnected) => return Disconnected,\n+                        Err(stream::Upgraded(port)) => port,\n+                    }\n+                }\n+                Shared(ref p) => {\n+                    match unsafe { (*p.get()).try_recv() } {\n+                        Ok(t) => return Data(t),\n+                        Err(shared::Empty) => return Empty,\n+                        Err(shared::Disconnected) => return Disconnected,\n                     }\n-                };\n-                match ret {\n-                    Some(data) => Data(data),\n-                    None => Disconnected,\n                 }\n+            };\n+            unsafe {\n+                mem::swap(&mut cast::transmute_mut(self).inner,\n+                          &mut new_port.inner);\n             }\n         }\n     }\n@@ -869,34 +575,36 @@ impl<T: Send> Port<T> {\n     /// If the channel has hung up, then `None` is returned. Otherwise `Some` of\n     /// the value found on the port is returned.\n     pub fn recv_opt(&self) -> Option<T> {\n-        // optimistic preflight check (scheduling is expensive)\n-        match self.try_recv() {\n-            Empty => {},\n-            Disconnected => return None,\n-            Data(t) => return Some(t),\n-        }\n-\n-        let packet;\n-        let this;\n-        unsafe {\n-            this = cast::transmute_mut(self);\n-            packet = this.queue.packet();\n-            let task: ~Task = Local::take();\n-            task.deschedule(1, |task| {\n-                assert!((*packet).to_wake.is_none());\n-                (*packet).to_wake = Some(task);\n-                if (*packet).decrement() {\n-                    Ok(())\n-                } else {\n-                    Err((*packet).to_wake.take_unwrap())\n+        loop {\n+            let mut new_port = match self.inner {\n+                Oneshot(ref p) => {\n+                    match unsafe { (*p.get()).recv() } {\n+                        Ok(t) => return Some(t),\n+                        Err(oneshot::Empty) => return unreachable!(),\n+                        Err(oneshot::Disconnected) => return None,\n+                        Err(oneshot::Upgraded(port)) => port,\n+                    }\n                 }\n-            });\n-        }\n-\n-        match self.try_recv_inc(false) {\n-            Data(t) => Some(t),\n-            Empty => fail!(\"bug: woke up too soon\"),\n-            Disconnected => None,\n+                Stream(ref p) => {\n+                    match unsafe { (*p.get()).recv() } {\n+                        Ok(t) => return Some(t),\n+                        Err(stream::Empty) => return unreachable!(),\n+                        Err(stream::Disconnected) => return None,\n+                        Err(stream::Upgraded(port)) => port,\n+                    }\n+                }\n+                Shared(ref p) => {\n+                    match unsafe { (*p.get()).recv() } {\n+                        Ok(t) => return Some(t),\n+                        Err(shared::Empty) => return unreachable!(),\n+                        Err(shared::Disconnected) => return None,\n+                    }\n+                }\n+            };\n+            unsafe {\n+                mem::swap(&mut cast::transmute_mut(self).inner,\n+                          &mut new_port.inner);\n+            }\n         }\n     }\n \n@@ -907,18 +615,95 @@ impl<T: Send> Port<T> {\n     }\n }\n \n+impl<T: Send> select::Packet for Port<T> {\n+    fn can_recv(&self) -> bool {\n+        loop {\n+            let mut new_port = match self.inner {\n+                Oneshot(ref p) => {\n+                    match unsafe { (*p.get()).can_recv() } {\n+                        Ok(ret) => return ret,\n+                        Err(upgrade) => upgrade,\n+                    }\n+                }\n+                Stream(ref p) => {\n+                    match unsafe { (*p.get()).can_recv() } {\n+                        Ok(ret) => return ret,\n+                        Err(upgrade) => upgrade,\n+                    }\n+                }\n+                Shared(ref p) => {\n+                    return unsafe { (*p.get()).can_recv() };\n+                }\n+            };\n+            unsafe {\n+                mem::swap(&mut cast::transmute_mut(self).inner,\n+                          &mut new_port.inner);\n+            }\n+        }\n+    }\n+\n+    fn start_selection(&self, mut task: BlockedTask) -> Result<(), BlockedTask>{\n+        loop {\n+            let (t, mut new_port) = match self.inner {\n+                Oneshot(ref p) => {\n+                    match unsafe { (*p.get()).start_selection(task) } {\n+                        oneshot::SelSuccess => return Ok(()),\n+                        oneshot::SelCanceled(task) => return Err(task),\n+                        oneshot::SelUpgraded(t, port) => (t, port),\n+                    }\n+                }\n+                Stream(ref p) => {\n+                    match unsafe { (*p.get()).start_selection(task) } {\n+                        stream::SelSuccess => return Ok(()),\n+                        stream::SelCanceled(task) => return Err(task),\n+                        stream::SelUpgraded(t, port) => (t, port),\n+                    }\n+                }\n+                Shared(ref p) => {\n+                    return unsafe { (*p.get()).start_selection(task) };\n+                }\n+            };\n+            task = t;\n+            unsafe {\n+                mem::swap(&mut cast::transmute_mut(self).inner,\n+                          &mut new_port.inner);\n+            }\n+        }\n+    }\n+\n+    fn abort_selection(&self) -> bool {\n+        let mut was_upgrade = false;\n+        loop {\n+            let result = match self.inner {\n+                Oneshot(ref p) => unsafe { (*p.get()).abort_selection() },\n+                Stream(ref p) => unsafe {\n+                    (*p.get()).abort_selection(was_upgrade)\n+                },\n+                Shared(ref p) => return unsafe {\n+                    (*p.get()).abort_selection(was_upgrade)\n+                },\n+            };\n+            let mut new_port = match result { Ok(b) => return b, Err(p) => p };\n+            was_upgrade = true;\n+            unsafe {\n+                mem::swap(&mut cast::transmute_mut(self).inner,\n+                          &mut new_port.inner);\n+            }\n+        }\n+    }\n+}\n+\n impl<'a, T: Send> Iterator<T> for Messages<'a, T> {\n     fn next(&mut self) -> Option<T> { self.port.recv_opt() }\n }\n \n #[unsafe_destructor]\n impl<T: Send> Drop for Port<T> {\n     fn drop(&mut self) {\n-        // All we need to do is store that we're disconnected. If the channel\n-        // half has already disconnected, then we'll just deallocate everything\n-        // when the shared packet is deallocated.\n-        unsafe {\n-            (*self.queue.packet()).cnt.store(DISCONNECTED, SeqCst);\n+        match self.inner {\n+            Oneshot(ref mut p) => unsafe { (*p.get()).drop_port(); },\n+            Stream(ref mut p) => unsafe { (*p.get()).drop_port(); },\n+            Shared(ref mut p) => unsafe { (*p.get()).drop_port(); },\n         }\n     }\n }\n@@ -950,12 +735,12 @@ mod test {\n     })\n \n     test!(fn drop_full_shared() {\n-        let (_p, c) = SharedChan::new();\n+        let (_p, c) = Chan::new();\n         c.send(~1);\n     })\n \n     test!(fn smoke_shared() {\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         c.send(1);\n         assert_eq!(p.recv(), 1);\n         let c = c.clone();\n@@ -978,13 +763,13 @@ mod test {\n     } #[should_fail])\n \n     test!(fn smoke_shared_port_gone() {\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         drop(p);\n         c.send(1);\n     } #[should_fail])\n \n     test!(fn smoke_shared_port_gone2() {\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         drop(p);\n         let c2 = c.clone();\n         drop(c);\n@@ -1000,7 +785,7 @@ mod test {\n     } #[should_fail])\n \n     test!(fn port_gone_concurrent_shared() {\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         let c1 = c.clone();\n         spawn(proc() {\n             p.recv();\n@@ -1018,7 +803,7 @@ mod test {\n     } #[should_fail])\n \n     test!(fn smoke_chan_gone_shared() {\n-        let (p, c) = SharedChan::<()>::new();\n+        let (p, c) = Chan::<()>::new();\n         let c2 = c.clone();\n         drop(c);\n         drop(c2);\n@@ -1047,7 +832,7 @@ mod test {\n     test!(fn stress_shared() {\n         static AMT: uint = 10000;\n         static NTHREADS: uint = 8;\n-        let (p, c) = SharedChan::<int>::new();\n+        let (p, c) = Chan::<int>::new();\n         let (p1, c1) = Chan::new();\n \n         spawn(proc() {\n@@ -1074,7 +859,7 @@ mod test {\n     fn send_from_outside_runtime() {\n         let (p, c) = Chan::<int>::new();\n         let (p1, c1) = Chan::new();\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         let chan2 = chan.clone();\n         spawn(proc() {\n             c1.send(());\n@@ -1114,7 +899,7 @@ mod test {\n     fn no_runtime() {\n         let (p1, c1) = Chan::<int>::new();\n         let (p2, c2) = Chan::<int>::new();\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         let chan2 = chan.clone();\n         native::task::spawn(proc() {\n             assert_eq!(p1.recv(), 1);\n@@ -1317,7 +1102,7 @@ mod test {\n     })\n \n     test!(fn shared_chan_stress() {\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         let total = stress_factor() + 100;\n         for _ in range(0, total) {\n             let chan_clone = chan.clone();\n@@ -1396,4 +1181,26 @@ mod test {\n         p2.recv();\n         assert_eq!(p.try_recv(), Disconnected);\n     })\n+\n+    // This bug used to end up in a livelock inside of the Port destructor\n+    // because the internal state of the Shared port was corrupted\n+    test!(fn destroy_upgraded_shared_port_when_sender_still_active() {\n+        let (p, c) = Chan::new();\n+        let (p1, c2) = Chan::new();\n+        spawn(proc() {\n+            p.recv(); // wait on a oneshot port\n+            drop(p);  // destroy a shared port\n+            c2.send(());\n+        });\n+        // make sure the other task has gone to sleep\n+        for _ in range(0, 5000) { task::deschedule(); }\n+\n+        // upgrade to a shared chan and send a message\n+        let t = c.clone();\n+        drop(c);\n+        t.send(());\n+\n+        // wait for the child task to exit before we exit\n+        p1.recv();\n+    })\n }"}, {"sha": "9deccfeb8756697399c5401c4b6ad9acc75b4935", "filename": "src/libstd/comm/oneshot.rs", "status": "added", "additions": 369, "deletions": 0, "changes": 369, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Foneshot.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Foneshot.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Foneshot.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -0,0 +1,369 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+/// Oneshot channels/ports\n+///\n+/// This is the initial flavor of channels/ports used for comm module. This is\n+/// an optimization for the one-use case of a channel. The major optimization of\n+/// this type is to have one and exactly one allocation when the chan/port pair\n+/// is created.\n+///\n+/// Another possible optimization would be to not use an UnsafeArc box because\n+/// in theory we know when the shared packet can be deallocated (no real need\n+/// for the atomic reference counting), but I was having trouble how to destroy\n+/// the data early in a drop of a Port.\n+///\n+/// # Implementation\n+///\n+/// Oneshots are implemented around one atomic uint variable. This variable\n+/// indicates both the state of the port/chan but also contains any tasks\n+/// blocked on the port. All atomic operations happen on this one word.\n+///\n+/// In order to upgrade a oneshot channel, an upgrade is considered a disconnect\n+/// on behalf of the channel side of things (it can be mentally thought of as\n+/// consuming the port). This upgrade is then also stored in the shared packet.\n+/// The one caveat to consider is that when a port sees a disconnected channel\n+/// it must check for data because there is no \"data plus upgrade\" state.\n+\n+use comm::Port;\n+use kinds::Send;\n+use mem;\n+use ops::Drop;\n+use option::{Some, None, Option};\n+use result::{Result, Ok, Err};\n+use rt::local::Local;\n+use rt::task::{Task, BlockedTask};\n+use sync::atomics;\n+\n+// Various states you can find a port in.\n+static EMPTY: uint = 0;\n+static DATA: uint = 1;\n+static DISCONNECTED: uint = 2;\n+\n+pub struct Packet<T> {\n+    // Internal state of the chan/port pair (stores the blocked task as well)\n+    state: atomics::AtomicUint,\n+    // One-shot data slot location\n+    data: Option<T>,\n+    // when used for the second time, a oneshot channel must be upgraded, and\n+    // this contains the slot for the upgrade\n+    upgrade: MyUpgrade<T>,\n+}\n+\n+pub enum Failure<T> {\n+    Empty,\n+    Disconnected,\n+    Upgraded(Port<T>),\n+}\n+\n+pub enum UpgradeResult {\n+    UpSuccess,\n+    UpDisconnected,\n+    UpWoke(BlockedTask),\n+}\n+\n+pub enum SelectionResult<T> {\n+    SelCanceled(BlockedTask),\n+    SelUpgraded(BlockedTask, Port<T>),\n+    SelSuccess,\n+}\n+\n+enum MyUpgrade<T> {\n+    NothingSent,\n+    SendUsed,\n+    GoUp(Port<T>),\n+}\n+\n+impl<T: Send> Packet<T> {\n+    pub fn new() -> Packet<T> {\n+        Packet {\n+            data: None,\n+            upgrade: NothingSent,\n+            state: atomics::AtomicUint::new(EMPTY),\n+        }\n+    }\n+\n+    pub fn send(&mut self, t: T) -> bool {\n+        // Sanity check\n+        match self.upgrade {\n+            NothingSent => {}\n+            _ => fail!(\"sending on a oneshot that's already sent on \"),\n+        }\n+        assert!(self.data.is_none());\n+        self.data = Some(t);\n+        self.upgrade = SendUsed;\n+\n+        match self.state.swap(DATA, atomics::SeqCst) {\n+            // Sent the data, no one was waiting\n+            EMPTY => true,\n+\n+            // Couldn't send the data, the port hung up first. We need to be\n+            // sure to deallocate the sent data (to not leave it stuck in the\n+            // queue)\n+            DISCONNECTED => {\n+                self.data.take_unwrap();\n+                false\n+            }\n+\n+            // Not possible, these are one-use channels\n+            DATA => unreachable!(),\n+\n+            // Anything else means that there was a task waiting on the other\n+            // end. We leave the 'DATA' state inside so it'll pick it up on the\n+            // other end.\n+            n => unsafe {\n+                let t = BlockedTask::cast_from_uint(n);\n+                t.wake().map(|t| t.reawaken());\n+                true\n+            }\n+        }\n+    }\n+\n+    // Just tests whether this channel has been sent on or not, this is only\n+    // safe to use from the sender.\n+    pub fn sent(&self) -> bool {\n+        match self.upgrade {\n+            NothingSent => false,\n+            _ => true,\n+        }\n+    }\n+\n+    pub fn recv(&mut self) -> Result<T, Failure<T>> {\n+        // Attempt to not block the task (it's a little expensive). If it looks\n+        // like we're not empty, then immediately go through to `try_recv`.\n+        if self.state.load(atomics::SeqCst) == EMPTY {\n+            let t: ~Task = Local::take();\n+            t.deschedule(1, |task| {\n+                let n = unsafe { task.cast_to_uint() };\n+                match self.state.compare_and_swap(EMPTY, n, atomics::SeqCst) {\n+                    // Nothing on the channel, we legitimately block\n+                    EMPTY => Ok(()),\n+\n+                    // If there's data or it's a disconnected channel, then we\n+                    // failed the cmpxchg, so we just wake ourselves back up\n+                    DATA | DISCONNECTED => {\n+                        unsafe { Err(BlockedTask::cast_from_uint(n)) }\n+                    }\n+\n+                    // Only one thread is allowed to sleep on this port\n+                    _ => unreachable!()\n+                }\n+            });\n+        }\n+\n+        self.try_recv()\n+    }\n+\n+    pub fn try_recv(&mut self) -> Result<T, Failure<T>> {\n+        match self.state.load(atomics::SeqCst) {\n+            EMPTY => Err(Empty),\n+\n+            // We saw some data on the channel, but the channel can be used\n+            // again to send us an upgrade. As a result, we need to re-insert\n+            // into the channel that there's no data available (otherwise we'll\n+            // just see DATA next time). This is done as a cmpxchg because if\n+            // the state changes under our feet we'd rather just see that state\n+            // change.\n+            DATA => {\n+                self.state.compare_and_swap(DATA, EMPTY, atomics::SeqCst);\n+                match self.data.take() {\n+                    Some(data) => Ok(data),\n+                    None => unreachable!(),\n+                }\n+            }\n+\n+            // There's no guarantee that we receive before an upgrade happens,\n+            // and an upgrade flags the channel as disconnected, so when we see\n+            // this we first need to check if there's data available and *then*\n+            // we go through and process the upgrade.\n+            DISCONNECTED => {\n+                match self.data.take() {\n+                    Some(data) => Ok(data),\n+                    None => {\n+                        match mem::replace(&mut self.upgrade, SendUsed) {\n+                            SendUsed | NothingSent => Err(Disconnected),\n+                            GoUp(upgrade) => Err(Upgraded(upgrade))\n+                        }\n+                    }\n+                }\n+            }\n+            _ => unreachable!()\n+        }\n+    }\n+\n+    // Returns whether the upgrade was completed. If the upgrade wasn't\n+    // completed, then the port couldn't get sent to the other half (it will\n+    // never receive it).\n+    pub fn upgrade(&mut self, up: Port<T>) -> UpgradeResult {\n+        let prev = match self.upgrade {\n+            NothingSent => NothingSent,\n+            SendUsed => SendUsed,\n+            _ => fail!(\"upgrading again\"),\n+        };\n+        self.upgrade = GoUp(up);\n+\n+        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+            // If the channel is empty or has data on it, then we're good to go.\n+            // Senders will check the data before the upgrade (in case we\n+            // plastered over the DATA state).\n+            DATA | EMPTY => UpSuccess,\n+\n+            // If the other end is already disconnected, then we failed the\n+            // upgrade. Be sure to trash the port we were given.\n+            DISCONNECTED => { self.upgrade = prev; UpDisconnected }\n+\n+            // If someone's waiting, we gotta wake them up\n+            n => UpWoke(unsafe { BlockedTask::cast_from_uint(n) })\n+        }\n+    }\n+\n+    pub fn drop_chan(&mut self) {\n+        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+            DATA | DISCONNECTED | EMPTY => {}\n+\n+            // If someone's waiting, we gotta wake them up\n+            n => unsafe {\n+                let t = BlockedTask::cast_from_uint(n);\n+                t.wake().map(|t| t.reawaken());\n+            }\n+        }\n+    }\n+\n+    pub fn drop_port(&mut self) {\n+        match self.state.swap(DISCONNECTED, atomics::SeqCst) {\n+            // An empty channel has nothing to do, and a remotely disconnected\n+            // channel also has nothing to do b/c we're about to run the drop\n+            // glue\n+            DISCONNECTED | EMPTY => {}\n+\n+            // There's data on the channel, so make sure we destroy it promptly.\n+            // This is why not using an arc is a little difficult (need the box\n+            // to stay valid while we take the data).\n+            DATA => { self.data.take_unwrap(); }\n+\n+            // We're the only ones that can block on this port\n+            _ => unreachable!()\n+        }\n+    }\n+\n+    ////////////////////////////////////////////////////////////////////////////\n+    // select implementation\n+    ////////////////////////////////////////////////////////////////////////////\n+\n+    // If Ok, the value is whether this port has data, if Err, then the upgraded\n+    // port needs to be checked instead of this one.\n+    pub fn can_recv(&mut self) -> Result<bool, Port<T>> {\n+        match self.state.load(atomics::SeqCst) {\n+            EMPTY => Ok(false), // Welp, we tried\n+            DATA => Ok(true),   // we have some un-acquired data\n+            DISCONNECTED if self.data.is_some() => Ok(true), // we have data\n+            DISCONNECTED => {\n+                match mem::replace(&mut self.upgrade, SendUsed) {\n+                    // The other end sent us an upgrade, so we need to\n+                    // propagate upwards whether the upgrade can receive\n+                    // data\n+                    GoUp(upgrade) => Err(upgrade),\n+\n+                    // If the other end disconnected without sending an\n+                    // upgrade, then we have data to receive (the channel is\n+                    // disconnected).\n+                    up => { self.upgrade = up; Ok(true) }\n+                }\n+            }\n+            _ => unreachable!(), // we're the \"one blocker\"\n+        }\n+    }\n+\n+    // Attempts to start selection on this port. This can either succeed, fail\n+    // because there is data, or fail because there is an upgrade pending.\n+    pub fn start_selection(&mut self, task: BlockedTask) -> SelectionResult<T> {\n+        let n = unsafe { task.cast_to_uint() };\n+        match self.state.compare_and_swap(EMPTY, n, atomics::SeqCst) {\n+            EMPTY => SelSuccess,\n+            DATA => SelCanceled(unsafe { BlockedTask::cast_from_uint(n) }),\n+            DISCONNECTED if self.data.is_some() => {\n+                SelCanceled(unsafe { BlockedTask::cast_from_uint(n) })\n+            }\n+            DISCONNECTED => {\n+                match mem::replace(&mut self.upgrade, SendUsed) {\n+                    // The other end sent us an upgrade, so we need to\n+                    // propagate upwards whether the upgrade can receive\n+                    // data\n+                    GoUp(upgrade) => {\n+                        SelUpgraded(unsafe { BlockedTask::cast_from_uint(n) },\n+                                    upgrade)\n+                    }\n+\n+                    // If the other end disconnected without sending an\n+                    // upgrade, then we have data to receive (the channel is\n+                    // disconnected).\n+                    up => {\n+                        self.upgrade = up;\n+                        SelCanceled(unsafe { BlockedTask::cast_from_uint(n) })\n+                    }\n+                }\n+            }\n+            _ => unreachable!(), // we're the \"one blocker\"\n+        }\n+    }\n+\n+    // Remove a previous selecting task from this port. This ensures that the\n+    // blocked task will no longer be visible to any other threads.\n+    //\n+    // The return value indicates whether there's data on this port.\n+    pub fn abort_selection(&mut self) -> Result<bool, Port<T>> {\n+        let state = match self.state.load(atomics::SeqCst) {\n+            // Each of these states means that no further activity will happen\n+            // with regard to abortion selection\n+            s @ EMPTY |\n+            s @ DATA |\n+            s @ DISCONNECTED => s,\n+\n+            // If we've got a blocked task, then use an atomic to gain ownership\n+            // of it (may fail)\n+            n => self.state.compare_and_swap(n, EMPTY, atomics::SeqCst)\n+        };\n+\n+        // Now that we've got ownership of our state, figure out what to do\n+        // about it.\n+        match state {\n+            EMPTY => unreachable!(),\n+            // our task used for select was stolen\n+            DATA => Ok(true),\n+\n+            // If the other end has hung up, then we have complete ownership\n+            // of the port. We need to check to see if there was an upgrade\n+            // requested, and if so, the other end needs to have its selection\n+            // aborted.\n+            DISCONNECTED => {\n+                assert!(self.data.is_none());\n+                match mem::replace(&mut self.upgrade, SendUsed) {\n+                    GoUp(port) => Err(port),\n+                    _ => Ok(true),\n+                }\n+            }\n+\n+            // We woke ourselves up from select. Assert that the task should be\n+            // trashed and returne that we don't have any data.\n+            n => {\n+                let t = unsafe { BlockedTask::cast_from_uint(n) };\n+                t.trash();\n+                Ok(false)\n+            }\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<T: Send> Drop for Packet<T> {\n+    fn drop(&mut self) {\n+        assert_eq!(self.state.load(atomics::SeqCst), DISCONNECTED);\n+    }\n+}"}, {"sha": "b6b35ccc3579042546a464ca323b1546abf0209b", "filename": "src/libstd/comm/select.rs", "status": "modified", "additions": 192, "deletions": 120, "changes": 312, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fselect.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fselect.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fselect.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -45,19 +45,17 @@\n #[allow(dead_code)];\n \n use cast;\n-use comm;\n+use cell::Cell;\n use iter::Iterator;\n use kinds::marker;\n use kinds::Send;\n use ops::Drop;\n use option::{Some, None, Option};\n use ptr::RawPtr;\n-use result::{Ok, Err};\n+use result::{Ok, Err, Result};\n use rt::local::Local;\n-use rt::task::Task;\n-use super::{Packet, Port};\n-use sync::atomics::{Relaxed, SeqCst};\n-use task;\n+use rt::task::{Task, BlockedTask};\n+use super::Port;\n use uint;\n \n macro_rules! select {\n@@ -67,8 +65,12 @@ macro_rules! select {\n     ) => ({\n         use std::comm::Select;\n         let sel = Select::new();\n-        let mut $port1 = sel.add(&mut $port1);\n-        $( let mut $port = sel.add(&mut $port); )*\n+        let mut $port1 = sel.handle(&$port1);\n+        $( let mut $port = sel.handle(&$port); )*\n+        unsafe {\n+            $port1.add();\n+            $( $port.add(); )*\n+        }\n         let ret = sel.wait();\n         if ret == $port1.id { let $name1 = $port1.$meth1(); $code1 }\n         $( else if ret == $port.id { let $name = $port.$meth(); $code } )*\n@@ -79,9 +81,9 @@ macro_rules! select {\n /// The \"port set\" of the select interface. This structure is used to manage a\n /// set of ports which are being selected over.\n pub struct Select {\n-    priv head: *mut Packet,\n-    priv tail: *mut Packet,\n-    priv next_id: uint,\n+    priv head: *mut Handle<'static, ()>,\n+    priv tail: *mut Handle<'static, ()>,\n+    priv next_id: Cell<uint>,\n     priv marker1: marker::NoSend,\n     priv marker2: marker::NoFreeze,\n }\n@@ -90,13 +92,28 @@ pub struct Select {\n /// This handle is used to keep the port in the set as well as interact with the\n /// underlying port.\n pub struct Handle<'port, T> {\n-    /// A unique ID for this Handle.\n+    /// The ID of this handle, used to compare against the return value of\n+    /// `Select::wait()`\n     id: uint,\n     priv selector: &'port Select,\n-    priv port: &'port mut Port<T>,\n+    priv next: *mut Handle<'static, ()>,\n+    priv prev: *mut Handle<'static, ()>,\n+    priv added: bool,\n+    priv packet: &'port Packet,\n+\n+    // due to our fun transmutes, we be sure to place this at the end. (nothing\n+    // previous relies on T)\n+    priv port: &'port Port<T>,\n }\n \n-struct Packets { cur: *mut Packet }\n+struct Packets { cur: *mut Handle<'static, ()> }\n+\n+#[doc(hidden)]\n+pub trait Packet {\n+    fn can_recv(&self) -> bool;\n+    fn start_selection(&self, task: BlockedTask) -> Result<(), BlockedTask>;\n+    fn abort_selection(&self) -> bool;\n+}\n \n impl Select {\n     /// Creates a new selection structure. This set is initially empty and\n@@ -106,45 +123,29 @@ impl Select {\n     /// rather much easier through the `select!` macro.\n     pub fn new() -> Select {\n         Select {\n-            head: 0 as *mut Packet,\n-            tail: 0 as *mut Packet,\n-            next_id: 1,\n             marker1: marker::NoSend,\n             marker2: marker::NoFreeze,\n+            head: 0 as *mut Handle<'static, ()>,\n+            tail: 0 as *mut Handle<'static, ()>,\n+            next_id: Cell::new(1),\n         }\n     }\n \n-    /// Adds a new port to this set, returning a handle which is then used to\n-    /// receive on the port.\n-    ///\n-    /// Note that this port parameter takes `&mut Port` instead of `&Port`. None\n-    /// of the methods of receiving on a port require `&mut self`, but `&mut` is\n-    /// used here in order to have the compiler guarantee that the same port is\n-    /// not added to this set more than once.\n-    ///\n-    /// When the returned handle falls out of scope, the port will be removed\n-    /// from this set. While the handle is in this set, usage of the port can be\n-    /// done through the `Handle`'s receiving methods.\n-    pub fn add<'a, T: Send>(&'a self, port: &'a mut Port<T>) -> Handle<'a, T> {\n-        let this = unsafe { cast::transmute_mut(self) };\n-        let id = this.next_id;\n-        this.next_id += 1;\n-        unsafe {\n-            let packet = port.queue.packet();\n-            assert!(!(*packet).selecting.load(Relaxed));\n-            assert_eq!((*packet).selection_id, 0);\n-            (*packet).selection_id = id;\n-            if this.head.is_null() {\n-                this.head = packet;\n-                this.tail = packet;\n-            } else {\n-                (*packet).select_prev = this.tail;\n-                assert!((*packet).select_next.is_null());\n-                (*this.tail).select_next = packet;\n-                this.tail = packet;\n-            }\n+    /// Creates a new handle into this port set for a new port. Note that this\n+    /// does *not* add the port to the port set, for that you must call the\n+    /// `add` method on the handle itself.\n+    pub fn handle<'a, T: Send>(&'a self, port: &'a Port<T>) -> Handle<'a, T> {\n+        let id = self.next_id.get();\n+        self.next_id.set(id + 1);\n+        Handle {\n+            id: id,\n+            selector: self,\n+            next: 0 as *mut Handle<'static, ()>,\n+            prev: 0 as *mut Handle<'static, ()>,\n+            added: false,\n+            port: port,\n+            packet: port,\n         }\n-        Handle { id: id, selector: this, port: port }\n     }\n \n     /// Waits for an event on this port set. The returned valus is *not* and\n@@ -177,10 +178,9 @@ impl Select {\n         unsafe {\n             let mut amt = 0;\n             for p in self.iter() {\n-                assert!(!(*p).selecting.load(Relaxed));\n                 amt += 1;\n-                if (*p).can_recv() {\n-                    return (*p).selection_id;\n+                if (*p).packet.can_recv() {\n+                    return (*p).id;\n                 }\n             }\n             assert!(amt > 0);\n@@ -195,22 +195,14 @@ impl Select {\n             let task: ~Task = Local::take();\n             task.deschedule(amt, |task| {\n                 // Prepare for the block\n-                let (i, packet) = iter.next().unwrap();\n-                assert!((*packet).to_wake.is_none());\n-                (*packet).to_wake = Some(task);\n-                (*packet).selecting.store(true, SeqCst);\n-\n-                if (*packet).decrement() {\n-                    Ok(())\n-                } else {\n-                    // Empty to_wake first to avoid tripping an assertion in\n-                    // abort_selection in the disconnected case.\n-                    let task = (*packet).to_wake.take_unwrap();\n-                    (*packet).abort_selection(false);\n-                    (*packet).selecting.store(false, SeqCst);\n-                    ready_index = i;\n-                    ready_id = (*packet).selection_id;\n-                    Err(task)\n+                let (i, handle) = iter.next().unwrap();\n+                match (*handle).packet.start_selection(task) {\n+                    Ok(()) => Ok(()),\n+                    Err(task) => {\n+                        ready_index = i;\n+                        ready_id = (*handle).id;\n+                        Err(task)\n+                    }\n                 }\n             });\n \n@@ -235,45 +227,17 @@ impl Select {\n             // A rewrite should focus on avoiding a yield loop, and for now this\n             // implementation is tying us over to a more efficient \"don't\n             // iterate over everything every time\" implementation.\n-            for packet in self.iter().take(ready_index) {\n-                if (*packet).abort_selection(true) {\n-                    ready_id = (*packet).selection_id;\n-                    while (*packet).selecting.load(Relaxed) {\n-                        task::deschedule();\n-                    }\n+            for handle in self.iter().take(ready_index) {\n+                if (*handle).packet.abort_selection() {\n+                    ready_id = (*handle).id;\n                 }\n             }\n \n-            // Sanity check for now to make sure that everyone is turned off.\n-            for packet in self.iter() {\n-                assert!(!(*packet).selecting.load(Relaxed));\n-            }\n-\n             assert!(ready_id != uint::MAX);\n             return ready_id;\n         }\n     }\n \n-    unsafe fn remove(&self, packet: *mut Packet) {\n-        let this = cast::transmute_mut(self);\n-        assert!(!(*packet).selecting.load(Relaxed));\n-        if (*packet).select_prev.is_null() {\n-            assert_eq!(packet, this.head);\n-            this.head = (*packet).select_next;\n-        } else {\n-            (*(*packet).select_prev).select_next = (*packet).select_next;\n-        }\n-        if (*packet).select_next.is_null() {\n-            assert_eq!(packet, this.tail);\n-            this.tail = (*packet).select_prev;\n-        } else {\n-            (*(*packet).select_next).select_prev = (*packet).select_prev;\n-        }\n-        (*packet).select_next = 0 as *mut Packet;\n-        (*packet).select_prev = 0 as *mut Packet;\n-        (*packet).selection_id = 0;\n-    }\n-\n     fn iter(&self) -> Packets { Packets { cur: self.head } }\n }\n \n@@ -285,10 +249,56 @@ impl<'port, T: Send> Handle<'port, T> {\n     /// success or `None` if the channel disconnects. This function has the same\n     /// semantics as `Port.recv_opt`\n     pub fn recv_opt(&mut self) -> Option<T> { self.port.recv_opt() }\n-    /// Immediately attempt to receive a value on a port, this function will\n-    /// never block. Has the same semantics as `Port.try_recv`.\n-    pub fn try_recv(&mut self) -> comm::TryRecvResult<T> {\n-        self.port.try_recv()\n+\n+    /// Adds this handle to the port set that the handle was created from. This\n+    /// method can be called multiple times, but it has no effect if `add` was\n+    /// called previously.\n+    ///\n+    /// This method is unsafe because it requires that the `Handle` is not moved\n+    /// while it is added to the `Select` set.\n+    pub unsafe fn add(&mut self) {\n+        if self.added { return }\n+        let selector: &mut Select = cast::transmute(&*self.selector);\n+        let me: *mut Handle<'static, ()> = cast::transmute(&*self);\n+\n+        if selector.head.is_null() {\n+            selector.head = me;\n+            selector.tail = me;\n+        } else {\n+            (*me).prev = selector.tail;\n+            assert!((*me).next.is_null());\n+            (*selector.tail).next = me;\n+            selector.tail = me;\n+        }\n+        self.added = true;\n+    }\n+\n+    /// Removes this handle from the `Select` set. This method is unsafe because\n+    /// it has no guarantee that the `Handle` was not moved since `add` was\n+    /// called.\n+    pub unsafe fn remove(&mut self) {\n+        if !self.added { return }\n+\n+        let selector: &mut Select = cast::transmute(&*self.selector);\n+        let me: *mut Handle<'static, ()> = cast::transmute(&*self);\n+\n+        if self.prev.is_null() {\n+            assert_eq!(selector.head, me);\n+            selector.head = self.next;\n+        } else {\n+            (*self.prev).next = self.next;\n+        }\n+        if self.next.is_null() {\n+            assert_eq!(selector.tail, me);\n+            selector.tail = self.prev;\n+        } else {\n+            (*self.next).prev = self.prev;\n+        }\n+\n+        self.next = 0 as *mut Handle<'static, ()>;\n+        self.prev = 0 as *mut Handle<'static, ()>;\n+\n+        self.added = false;\n     }\n }\n \n@@ -303,17 +313,17 @@ impl Drop for Select {\n #[unsafe_destructor]\n impl<'port, T: Send> Drop for Handle<'port, T> {\n     fn drop(&mut self) {\n-        unsafe { self.selector.remove(self.port.queue.packet()) }\n+        unsafe { self.remove() }\n     }\n }\n \n-impl Iterator<*mut Packet> for Packets {\n-    fn next(&mut self) -> Option<*mut Packet> {\n+impl Iterator<*mut Handle<'static, ()>> for Packets {\n+    fn next(&mut self) -> Option<*mut Handle<'static, ()>> {\n         if self.cur.is_null() {\n             None\n         } else {\n             let ret = Some(self.cur);\n-            unsafe { self.cur = (*self.cur).select_next; }\n+            unsafe { self.cur = (*self.cur).next; }\n             ret\n         }\n     }\n@@ -326,8 +336,8 @@ mod test {\n     use prelude::*;\n \n     test!(fn smoke() {\n-        let (mut p1, c1) = Chan::<int>::new();\n-        let (mut p2, c2) = Chan::<int>::new();\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, c2) = Chan::<int>::new();\n         c1.send(1);\n         select! (\n             foo = p1.recv() => { assert_eq!(foo, 1); },\n@@ -350,11 +360,11 @@ mod test {\n     })\n \n     test!(fn smoke2() {\n-        let (mut p1, _c1) = Chan::<int>::new();\n-        let (mut p2, _c2) = Chan::<int>::new();\n-        let (mut p3, _c3) = Chan::<int>::new();\n-        let (mut p4, _c4) = Chan::<int>::new();\n-        let (mut p5, c5) = Chan::<int>::new();\n+        let (p1, _c1) = Chan::<int>::new();\n+        let (p2, _c2) = Chan::<int>::new();\n+        let (p3, _c3) = Chan::<int>::new();\n+        let (p4, _c4) = Chan::<int>::new();\n+        let (p5, c5) = Chan::<int>::new();\n         c5.send(4);\n         select! (\n             _foo = p1.recv() => { fail!(\"1\") },\n@@ -366,8 +376,8 @@ mod test {\n     })\n \n     test!(fn closed() {\n-        let (mut p1, _c1) = Chan::<int>::new();\n-        let (mut p2, c2) = Chan::<int>::new();\n+        let (p1, _c1) = Chan::<int>::new();\n+        let (p2, c2) = Chan::<int>::new();\n         drop(c2);\n \n         select! (\n@@ -377,8 +387,8 @@ mod test {\n     })\n \n     test!(fn unblocks() {\n-        let (mut p1, c1) = Chan::<int>::new();\n-        let (mut p2, _c2) = Chan::<int>::new();\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, _c2) = Chan::<int>::new();\n         let (p3, c3) = Chan::<int>::new();\n \n         spawn(proc() {\n@@ -400,8 +410,8 @@ mod test {\n     })\n \n     test!(fn both_ready() {\n-        let (mut p1, c1) = Chan::<int>::new();\n-        let (mut p2, c2) = Chan::<int>::new();\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, c2) = Chan::<int>::new();\n         let (p3, c3) = Chan::<()>::new();\n \n         spawn(proc() {\n@@ -426,8 +436,8 @@ mod test {\n \n     test!(fn stress() {\n         static AMT: int = 10000;\n-        let (mut p1, c1) = Chan::<int>::new();\n-        let (mut p2, c2) = Chan::<int>::new();\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, c2) = Chan::<int>::new();\n         let (p3, c3) = Chan::<()>::new();\n \n         spawn(proc() {\n@@ -449,4 +459,66 @@ mod test {\n             c3.send(());\n         }\n     })\n+\n+    test!(fn cloning() {\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, _c2) = Chan::<int>::new();\n+        let (p3, c3) = Chan::<()>::new();\n+\n+        spawn(proc() {\n+            p3.recv();\n+            c1.clone();\n+            assert_eq!(p3.try_recv(), Empty);\n+            c1.send(2);\n+            p3.recv();\n+        });\n+\n+        c3.send(());\n+        select!(\n+            _i1 = p1.recv() => {},\n+            _i2 = p2.recv() => fail!()\n+        )\n+        c3.send(());\n+    })\n+\n+    test!(fn cloning2() {\n+        let (p1, c1) = Chan::<int>::new();\n+        let (p2, _c2) = Chan::<int>::new();\n+        let (p3, c3) = Chan::<()>::new();\n+\n+        spawn(proc() {\n+            p3.recv();\n+            c1.clone();\n+            assert_eq!(p3.try_recv(), Empty);\n+            c1.send(2);\n+            p3.recv();\n+        });\n+\n+        c3.send(());\n+        select!(\n+            _i1 = p1.recv() => {},\n+            _i2 = p2.recv() => fail!()\n+        )\n+        c3.send(());\n+    })\n+\n+    test!(fn cloning3() {\n+        let (p1, c1) = Chan::<()>::new();\n+        let (p2, c2) = Chan::<()>::new();\n+        let (p, c) = Chan::new();\n+        spawn(proc() {\n+            let mut s = Select::new();\n+            let mut h1 = s.handle(&p1);\n+            let mut h2 = s.handle(&p2);\n+            unsafe { h2.add(); }\n+            unsafe { h1.add(); }\n+            assert_eq!(s.wait(), h2.id);\n+            c.send(());\n+        });\n+\n+        for _ in range(0, 1000) { task::deschedule(); }\n+        drop(c1.clone());\n+        c2.send(());\n+        p.recv();\n+    })\n }"}, {"sha": "30e061bb7b9165aa18c7016ad90130e3266db026", "filename": "src/libstd/comm/shared.rs", "status": "added", "additions": 483, "deletions": 0, "changes": 483, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fshared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fshared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fshared.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -0,0 +1,483 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+/// Shared channels\n+///\n+/// This is the flavor of channels which are not necessarily optimized for any\n+/// particular use case, but are the most general in how they are used. Shared\n+/// channels are cloneable allowing for multiple senders.\n+///\n+/// High level implementation details can be found in the comment of the parent\n+/// module. You'll also note that the implementation of the shared and stream\n+/// channels are quite similar, and this is no coincidence!\n+\n+use int;\n+use iter::Iterator;\n+use kinds::Send;\n+use ops::Drop;\n+use option::{Some, None, Option};\n+use result::{Ok, Err, Result};\n+use rt::local::Local;\n+use rt::task::{Task, BlockedTask};\n+use rt::thread::Thread;\n+use sync::atomics;\n+use unstable::mutex::Mutex;\n+use vec::OwnedVector;\n+\n+use mpsc = sync::mpsc_queue;\n+\n+static DISCONNECTED: int = int::MIN;\n+static FUDGE: int = 1024;\n+static MAX_STEALS: int = 1 << 20;\n+\n+pub struct Packet<T> {\n+    queue: mpsc::Queue<T>,\n+    cnt: atomics::AtomicInt, // How many items are on this channel\n+    steals: int, // How many times has a port received without blocking?\n+    to_wake: atomics::AtomicUint, // Task to wake up\n+\n+    // The number of channels which are currently using this packet.\n+    channels: atomics::AtomicInt,\n+\n+    // See the discussion in Port::drop and the channel send methods for what\n+    // these are used for\n+    port_dropped: atomics::AtomicBool,\n+    sender_drain: atomics::AtomicInt,\n+\n+    // this lock protects various portions of this implementation during\n+    // select()\n+    select_lock: Mutex,\n+}\n+\n+pub enum Failure {\n+    Empty,\n+    Disconnected,\n+}\n+\n+impl<T: Send> Packet<T> {\n+    // Creation of a packet *must* be followed by a call to inherit_blocker\n+    pub fn new() -> Packet<T> {\n+        let mut p = Packet {\n+            queue: mpsc::Queue::new(),\n+            cnt: atomics::AtomicInt::new(0),\n+            steals: 0,\n+            to_wake: atomics::AtomicUint::new(0),\n+            channels: atomics::AtomicInt::new(2),\n+            port_dropped: atomics::AtomicBool::new(false),\n+            sender_drain: atomics::AtomicInt::new(0),\n+            select_lock: unsafe { Mutex::new() },\n+        };\n+        // see comments in inherit_blocker about why we grab this lock\n+        unsafe { p.select_lock.lock() }\n+        return p;\n+    }\n+\n+    // This function is used at the creation of a shared packet to inherit a\n+    // previously blocked task. This is done to prevent spurious wakeups of\n+    // tasks in select().\n+    //\n+    // This can only be called at channel-creation time\n+    pub fn inherit_blocker(&mut self, task: Option<BlockedTask>) {\n+        match task {\n+            Some(task) => {\n+                assert_eq!(self.cnt.load(atomics::SeqCst), 0);\n+                assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+                self.to_wake.store(unsafe { task.cast_to_uint() },\n+                                   atomics::SeqCst);\n+                self.cnt.store(-1, atomics::SeqCst);\n+\n+                // This store is a little sketchy. What's happening here is\n+                // that we're transferring a blocker from a oneshot or stream\n+                // channel to this shared channel. In doing so, we never\n+                // spuriously wake them up and rather only wake them up at the\n+                // appropriate time. This implementation of shared channels\n+                // assumes that any blocking recv() will undo the increment of\n+                // steals performed in try_recv() once the recv is complete.\n+                // This thread that we're inheriting, however, is not in the\n+                // middle of recv. Hence, the first time we wake them up,\n+                // they're going to wake up from their old port, move on to the\n+                // upgraded port, and then call the block recv() function.\n+                //\n+                // When calling this function, they'll find there's data\n+                // immediately available, counting it as a steal. This in fact\n+                // wasn't a steal because we appropriately blocked them waiting\n+                // for data.\n+                //\n+                // To offset this bad increment, we initially set the steal\n+                // count to -1. You'll find some special code in\n+                // abort_selection() as well to ensure that this -1 steal count\n+                // doesn't escape too far.\n+                self.steals = -1;\n+            }\n+            None => {}\n+        }\n+\n+        // When the shared packet is constructed, we grabbed this lock. The\n+        // purpose of this lock is to ensure that abort_selection() doesn't\n+        // interfere with this method. After we unlock this lock, we're\n+        // signifying that we're done modifying self.cnt and self.to_wake and\n+        // the port is ready for the world to continue using it.\n+        unsafe { self.select_lock.unlock() }\n+    }\n+\n+    pub fn send(&mut self, t: T) -> bool {\n+        // See Port::drop for what's going on\n+        if self.port_dropped.load(atomics::SeqCst) { return false }\n+\n+        // Note that the multiple sender case is a little tricker\n+        // semantically than the single sender case. The logic for\n+        // incrementing is \"add and if disconnected store disconnected\".\n+        // This could end up leading some senders to believe that there\n+        // wasn't a disconnect if in fact there was a disconnect. This means\n+        // that while one thread is attempting to re-store the disconnected\n+        // states, other threads could walk through merrily incrementing\n+        // this very-negative disconnected count. To prevent senders from\n+        // spuriously attempting to send when the channels is actually\n+        // disconnected, the count has a ranged check here.\n+        //\n+        // This is also done for another reason. Remember that the return\n+        // value of this function is:\n+        //\n+        //  `true` == the data *may* be received, this essentially has no\n+        //            meaning\n+        //  `false` == the data will *never* be received, this has a lot of\n+        //             meaning\n+        //\n+        // In the SPSC case, we have a check of 'queue.is_empty()' to see\n+        // whether the data was actually received, but this same condition\n+        // means nothing in a multi-producer context. As a result, this\n+        // preflight check serves as the definitive \"this will never be\n+        // received\". Once we get beyond this check, we have permanently\n+        // entered the realm of \"this may be received\"\n+        if self.cnt.load(atomics::SeqCst) < DISCONNECTED + FUDGE {\n+            return false\n+        }\n+\n+        self.queue.push(t);\n+        match self.cnt.fetch_add(1, atomics::SeqCst) {\n+            -1 => {\n+                self.take_to_wake().wake().map(|t| t.reawaken());\n+            }\n+\n+            // In this case, we have possibly failed to send our data, and\n+            // we need to consider re-popping the data in order to fully\n+            // destroy it. We must arbitrate among the multiple senders,\n+            // however, because the queues that we're using are\n+            // single-consumer queues. In order to do this, all exiting\n+            // pushers will use an atomic count in order to count those\n+            // flowing through. Pushers who see 0 are required to drain as\n+            // much as possible, and then can only exit when they are the\n+            // only pusher (otherwise they must try again).\n+            n if n < DISCONNECTED + FUDGE => {\n+                // see the comment in 'try' for a shared channel for why this\n+                // window of \"not disconnected\" is ok.\n+                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+\n+                if self.sender_drain.fetch_add(1, atomics::SeqCst) == 0 {\n+                    loop {\n+                        // drain the queue, for info on the thread yield see the\n+                        // discussion in try_recv\n+                        loop {\n+                            match self.queue.pop() {\n+                                mpsc::Data(..) => {}\n+                                mpsc::Empty => break,\n+                                mpsc::Inconsistent => Thread::yield_now(),\n+                            }\n+                        }\n+                        // maybe we're done, if we're not the last ones\n+                        // here, then we need to go try again.\n+                        if self.sender_drain.fetch_sub(1, atomics::SeqCst) == 1 {\n+                            break\n+                        }\n+                    }\n+\n+                    // At this point, there may still be data on the queue,\n+                    // but only if the count hasn't been incremented and\n+                    // some other sender hasn't finished pushing data just\n+                    // yet. That sender in question will drain its own data.\n+                }\n+            }\n+\n+            // Can't make any assumptions about this case like in the SPSC case.\n+            _ => {}\n+        }\n+\n+        true\n+    }\n+\n+    pub fn recv(&mut self) -> Result<T, Failure> {\n+        // This code is essentially the exact same as that found in the stream\n+        // case (see stream.rs)\n+        match self.try_recv() {\n+            Err(Empty) => {}\n+            data => return data,\n+        }\n+\n+        let task: ~Task = Local::take();\n+        task.deschedule(1, |task| {\n+            self.decrement(task)\n+        });\n+\n+        match self.try_recv() {\n+            data @ Ok(..) => { self.steals -= 1; data }\n+            data => data,\n+        }\n+    }\n+\n+    // Essentially the exact same thing as the stream decrement function.\n+    fn decrement(&mut self, task: BlockedTask) -> Result<(), BlockedTask> {\n+        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        let n = unsafe { task.cast_to_uint() };\n+        self.to_wake.store(n, atomics::SeqCst);\n+\n+        let steals = self.steals;\n+        self.steals = 0;\n+\n+        match self.cnt.fetch_sub(1 + steals, atomics::SeqCst) {\n+            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomics::SeqCst); }\n+            // If we factor in our steals and notice that the channel has no\n+            // data, we successfully sleep\n+            n => {\n+                assert!(n >= 0);\n+                if n - steals <= 0 { return Ok(()) }\n+            }\n+        }\n+\n+        self.to_wake.store(0, atomics::SeqCst);\n+        Err(unsafe { BlockedTask::cast_from_uint(n) })\n+    }\n+\n+    pub fn try_recv(&mut self) -> Result<T, Failure> {\n+        let ret = match self.queue.pop() {\n+            mpsc::Data(t) => Some(t),\n+            mpsc::Empty => None,\n+\n+            // This is a bit of an interesting case. The channel is\n+            // reported as having data available, but our pop() has\n+            // failed due to the queue being in an inconsistent state.\n+            // This means that there is some pusher somewhere which has\n+            // yet to complete, but we are guaranteed that a pop will\n+            // eventually succeed. In this case, we spin in a yield loop\n+            // because the remote sender should finish their enqueue\n+            // operation \"very quickly\".\n+            //\n+            // Note that this yield loop does *not* attempt to do a green\n+            // yield (regardless of the context), but *always* performs an\n+            // OS-thread yield. The reasoning for this is that the pusher in\n+            // question which is causing the inconsistent state is\n+            // guaranteed to *not* be a blocked task (green tasks can't get\n+            // pre-empted), so it must be on a different OS thread. Also,\n+            // `try_recv` is normally a \"guaranteed no rescheduling\" context\n+            // in a green-thread situation. By yielding control of the\n+            // thread, we will hopefully allow time for the remote task on\n+            // the other OS thread to make progress.\n+            //\n+            // Avoiding this yield loop would require a different queue\n+            // abstraction which provides the guarantee that after M\n+            // pushes have succeeded, at least M pops will succeed. The\n+            // current queues guarantee that if there are N active\n+            // pushes, you can pop N times once all N have finished.\n+            mpsc::Inconsistent => {\n+                let data;\n+                loop {\n+                    Thread::yield_now();\n+                    match self.queue.pop() {\n+                        mpsc::Data(t) => { data = t; break }\n+                        mpsc::Empty => fail!(\"inconsistent => empty\"),\n+                        mpsc::Inconsistent => {}\n+                    }\n+                }\n+                Some(data)\n+            }\n+        };\n+        match ret {\n+            // See the discussion in the stream implementation for why we we\n+            // might decrement steals.\n+            Some(data) => {\n+                self.steals += 1;\n+                if self.steals > MAX_STEALS {\n+                    match self.cnt.swap(0, atomics::SeqCst) {\n+                        DISCONNECTED => {\n+                            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                        }\n+                        n => { self.steals -= n; }\n+                    }\n+                    assert!(self.steals >= 0);\n+                }\n+                Ok(data)\n+            }\n+\n+            // See the discussion in the stream implementation for why we try\n+            // again.\n+            None => {\n+                match self.cnt.load(atomics::SeqCst) {\n+                    n if n != DISCONNECTED => Err(Empty),\n+                    _ => {\n+                        match self.queue.pop() {\n+                            mpsc::Data(t) => Ok(t),\n+                            mpsc::Empty => Err(Disconnected),\n+                            // with no senders, an inconsistency is impossible.\n+                            mpsc::Inconsistent => unreachable!(),\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    // Prepares this shared packet for a channel clone, essentially just bumping\n+    // a refcount.\n+    pub fn clone_chan(&mut self) {\n+        self.channels.fetch_add(1, atomics::SeqCst);\n+    }\n+\n+    // Decrement the reference count on a channel. This is called whenever a\n+    // Chan is dropped and may end up waking up a receiver. It's the receiver's\n+    // responsibility on the other end to figure out that we've disconnected.\n+    pub fn drop_chan(&mut self) {\n+        match self.channels.fetch_sub(1, atomics::SeqCst) {\n+            1 => {}\n+            n if n > 1 => return,\n+            n => fail!(\"bad number of channels left {}\", n),\n+        }\n+\n+        match self.cnt.swap(DISCONNECTED, atomics::SeqCst) {\n+            -1 => { self.take_to_wake().wake().map(|t| t.reawaken()); }\n+            DISCONNECTED => {}\n+            n => { assert!(n >= 0); }\n+        }\n+    }\n+\n+    // See the long discussion inside of stream.rs for why the queue is drained,\n+    // and why it is done in this fashion.\n+    pub fn drop_port(&mut self) {\n+        self.port_dropped.store(true, atomics::SeqCst);\n+        let mut steals = self.steals;\n+        while {\n+            let cnt = self.cnt.compare_and_swap(\n+                            steals, DISCONNECTED, atomics::SeqCst);\n+            cnt != DISCONNECTED && cnt != steals\n+        } {\n+            // See the discussion in 'try_recv' for why we yield\n+            // control of this thread.\n+            loop {\n+                match self.queue.pop() {\n+                    mpsc::Data(..) => { steals += 1; }\n+                    mpsc::Empty | mpsc::Inconsistent => break,\n+                }\n+            }\n+        }\n+    }\n+\n+    // Consumes ownership of the 'to_wake' field.\n+    fn take_to_wake(&mut self) -> BlockedTask {\n+        let task = self.to_wake.load(atomics::SeqCst);\n+        self.to_wake.store(0, atomics::SeqCst);\n+        assert!(task != 0);\n+        unsafe { BlockedTask::cast_from_uint(task) }\n+    }\n+\n+    ////////////////////////////////////////////////////////////////////////////\n+    // select implementation\n+    ////////////////////////////////////////////////////////////////////////////\n+\n+    // Helper function for select, tests whether this port can receive without\n+    // blocking (obviously not an atomic decision).\n+    //\n+    // This is different than the stream version because there's no need to peek\n+    // at the queue, we can just look at the local count.\n+    pub fn can_recv(&mut self) -> bool {\n+        let cnt = self.cnt.load(atomics::SeqCst);\n+        cnt == DISCONNECTED || cnt - self.steals > 0\n+    }\n+\n+    // Inserts the blocked task for selection on this port, returning it back if\n+    // the port already has data on it.\n+    //\n+    // The code here is the same as in stream.rs, except that it doesn't need to\n+    // peek at the channel to see if an upgrade is pending.\n+    pub fn start_selection(&mut self,\n+                           task: BlockedTask) -> Result<(), BlockedTask> {\n+        match self.decrement(task) {\n+            Ok(()) => Ok(()),\n+            Err(task) => {\n+                let prev = self.cnt.fetch_add(1, atomics::SeqCst);\n+                assert!(prev >= 0);\n+                return Err(task);\n+            }\n+        }\n+    }\n+\n+    // Cancels a previous task waiting on this port, returning whether there's\n+    // data on the port.\n+    //\n+    // This is similar to the stream implementation (hence fewer comments), but\n+    // uses a different value for the \"steals\" variable.\n+    pub fn abort_selection(&mut self, _was_upgrade: bool) -> bool {\n+        // Before we do anything else, we bounce on this lock. The reason for\n+        // doing this is to ensure that any upgrade-in-progress is gone and\n+        // done with. Without this bounce, we can race with inherit_blocker\n+        // about looking at and dealing with to_wake. Once we have acquired the\n+        // lock, we are guaranteed that inherit_blocker is done.\n+        unsafe {\n+            self.select_lock.lock();\n+            self.select_lock.unlock();\n+        }\n+\n+        // Like the stream implementation, we want to make sure that the count\n+        // on the channel goes non-negative. We don't know how negative the\n+        // stream currently is, so instead of using a steal value of 1, we load\n+        // the channel count and figure out what we should do to make it\n+        // positive.\n+        let steals = {\n+            let cnt = self.cnt.load(atomics::SeqCst);\n+            if cnt < 0 && cnt != DISCONNECTED {-cnt} else {0}\n+        };\n+        let prev = self.cnt.fetch_add(steals + 1, atomics::SeqCst);\n+\n+        if prev == DISCONNECTED {\n+            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+            true\n+        } else {\n+            let cur = prev + steals + 1;\n+            assert!(cur >= 0);\n+            if prev < 0 {\n+                self.take_to_wake().trash();\n+            } else {\n+                while self.to_wake.load(atomics::SeqCst) != 0 {\n+                    Thread::yield_now();\n+                }\n+            }\n+            // if the number of steals is -1, it was the pre-emptive -1 steal\n+            // count from when we inherited a blocker. This is fine because\n+            // we're just going to overwrite it with a real value.\n+            assert!(self.steals == 0 || self.steals == -1);\n+            self.steals = steals;\n+            prev >= 0\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<T: Send> Drop for Packet<T> {\n+    fn drop(&mut self) {\n+        unsafe {\n+            // Note that this load is not only an assert for correctness about\n+            // disconnection, but also a proper fence before the read of\n+            // `to_wake`, so this assert cannot be removed with also removing\n+            // the `to_wake` assert.\n+            assert_eq!(self.cnt.load(atomics::SeqCst), DISCONNECTED);\n+            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            assert_eq!(self.channels.load(atomics::SeqCst), 0);\n+            self.select_lock.destroy();\n+        }\n+    }\n+}"}, {"sha": "0e249a55f870791172286f2878f622f080bca180", "filename": "src/libstd/comm/stream.rs", "status": "added", "additions": 460, "deletions": 0, "changes": 460, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fcomm%2Fstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcomm%2Fstream.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -0,0 +1,460 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+/// Stream channels\n+///\n+/// This is the flavor of channels which are optimized for one sender and one\n+/// receiver. The sender will be upgraded to a shared channel if the channel is\n+/// cloned.\n+///\n+/// High level implementation details can be found in the comment of the parent\n+/// module.\n+\n+use comm::Port;\n+use int;\n+use iter::Iterator;\n+use kinds::Send;\n+use ops::Drop;\n+use option::{Some, None};\n+use result::{Ok, Err, Result};\n+use rt::local::Local;\n+use rt::task::{Task, BlockedTask};\n+use rt::thread::Thread;\n+use spsc = sync::spsc_queue;\n+use sync::atomics;\n+use vec::OwnedVector;\n+\n+static DISCONNECTED: int = int::MIN;\n+static MAX_STEALS: int = 1 << 20;\n+\n+pub struct Packet<T> {\n+    queue: spsc::Queue<Message<T>>, // internal queue for all message\n+\n+    cnt: atomics::AtomicInt, // How many items are on this channel\n+    steals: int, // How many times has a port received without blocking?\n+    to_wake: atomics::AtomicUint, // Task to wake up\n+\n+    port_dropped: atomics::AtomicBool, // flag if the channel has been destroyed.\n+}\n+\n+pub enum Failure<T> {\n+    Empty,\n+    Disconnected,\n+    Upgraded(Port<T>),\n+}\n+\n+pub enum UpgradeResult {\n+    UpSuccess,\n+    UpDisconnected,\n+    UpWoke(BlockedTask),\n+}\n+\n+pub enum SelectionResult<T> {\n+    SelSuccess,\n+    SelCanceled(BlockedTask),\n+    SelUpgraded(BlockedTask, Port<T>),\n+}\n+\n+// Any message could contain an \"upgrade request\" to a new shared port, so the\n+// internal queue it's a queue of T, but rather Message<T>\n+enum Message<T> {\n+    Data(T),\n+    GoUp(Port<T>),\n+}\n+\n+impl<T: Send> Packet<T> {\n+    pub fn new() -> Packet<T> {\n+        Packet {\n+            queue: spsc::Queue::new(128),\n+\n+            cnt: atomics::AtomicInt::new(0),\n+            steals: 0,\n+            to_wake: atomics::AtomicUint::new(0),\n+\n+            port_dropped: atomics::AtomicBool::new(false),\n+        }\n+    }\n+\n+\n+    pub fn send(&mut self, t: T) -> bool {\n+        match self.do_send(Data(t)) {\n+            UpSuccess => true,\n+            UpDisconnected => false,\n+            UpWoke(task) => {\n+                task.wake().map(|t| t.reawaken());\n+                true\n+            }\n+        }\n+    }\n+    pub fn upgrade(&mut self, up: Port<T>) -> UpgradeResult {\n+        self.do_send(GoUp(up))\n+    }\n+\n+    fn do_send(&mut self, t: Message<T>) -> UpgradeResult {\n+        // Use an acquire/release ordering to maintain the same position with\n+        // respect to the atomic loads below\n+        if self.port_dropped.load(atomics::SeqCst) { return UpDisconnected }\n+\n+        self.queue.push(t);\n+        match self.cnt.fetch_add(1, atomics::SeqCst) {\n+            // As described in the mod's doc comment, -1 == wakeup\n+            -1 => UpWoke(self.take_to_wake()),\n+            // As as described before, SPSC queues must be >= -2\n+            -2 => UpSuccess,\n+\n+            // Be sure to preserve the disconnected state, and the return value\n+            // in this case is going to be whether our data was received or not.\n+            // This manifests itself on whether we have an empty queue or not.\n+            //\n+            // Primarily, are required to drain the queue here because the port\n+            // will never remove this data. We can only have at most one item to\n+            // drain (the port drains the rest).\n+            DISCONNECTED => {\n+                self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                let first = self.queue.pop();\n+                let second = self.queue.pop();\n+                assert!(second.is_none());\n+\n+                match first {\n+                    Some(..) => UpSuccess,  // we failed to send the data\n+                    None => UpDisconnected, // we successfully sent data\n+                }\n+            }\n+\n+            // Otherwise we just sent some data on a non-waiting queue, so just\n+            // make sure the world is sane and carry on!\n+            n => { assert!(n >= 0); UpSuccess }\n+        }\n+    }\n+\n+    // Consumes ownership of the 'to_wake' field.\n+    fn take_to_wake(&mut self) -> BlockedTask {\n+        let task = self.to_wake.load(atomics::SeqCst);\n+        self.to_wake.store(0, atomics::SeqCst);\n+        assert!(task != 0);\n+        unsafe { BlockedTask::cast_from_uint(task) }\n+    }\n+\n+    // Decrements the count on the channel for a sleeper, returning the sleeper\n+    // back if it shouldn't sleep. Note that this is the location where we take\n+    // steals into account.\n+    fn decrement(&mut self, task: BlockedTask) -> Result<(), BlockedTask> {\n+        assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        let n = unsafe { task.cast_to_uint() };\n+        self.to_wake.store(n, atomics::SeqCst);\n+\n+        let steals = self.steals;\n+        self.steals = 0;\n+\n+        match self.cnt.fetch_sub(1 + steals, atomics::SeqCst) {\n+            DISCONNECTED => { self.cnt.store(DISCONNECTED, atomics::SeqCst); }\n+            // If we factor in our steals and notice that the channel has no\n+            // data, we successfully sleep\n+            n => {\n+                assert!(n >= 0);\n+                if n - steals <= 0 { return Ok(()) }\n+            }\n+        }\n+\n+        self.to_wake.store(0, atomics::SeqCst);\n+        Err(unsafe { BlockedTask::cast_from_uint(n) })\n+    }\n+\n+    pub fn recv(&mut self) -> Result<T, Failure<T>> {\n+        // Optimistic preflight check (scheduling is expensive).\n+        match self.try_recv() {\n+            Err(Empty) => {}\n+            data => return data,\n+        }\n+\n+        // Welp, our channel has no data. Deschedule the current task and\n+        // initiate the blocking protocol.\n+        let task: ~Task = Local::take();\n+        task.deschedule(1, |task| {\n+            self.decrement(task)\n+        });\n+\n+        match self.try_recv() {\n+            // Messages which actually popped from the queue shouldn't count as\n+            // a steal, so offset the decrement here (we already have our\n+            // \"steal\" factored into the channel count above).\n+            data @ Ok(..) |\n+            data @ Err(Upgraded(..)) => {\n+                self.steals -= 1;\n+                data\n+            }\n+\n+            data => data,\n+        }\n+    }\n+\n+    pub fn try_recv(&mut self) -> Result<T, Failure<T>> {\n+        match self.queue.pop() {\n+            // If we stole some data, record to that effect (this will be\n+            // factored into cnt later on). Note that we don't allow steals to\n+            // grow without bound in order to prevent eventual overflow of\n+            // either steals or cnt as an overflow would have catastrophic\n+            // results. Also note that we don't unconditionally set steals to 0\n+            // because it can be true that steals > cnt.\n+            Some(data) => {\n+                self.steals += 1;\n+                if self.steals > MAX_STEALS {\n+                    match self.cnt.swap(0, atomics::SeqCst) {\n+                        DISCONNECTED => {\n+                            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+                        }\n+                        n => { self.steals -= n; }\n+                    }\n+                    assert!(self.steals >= 0);\n+                }\n+                match data {\n+                    Data(t) => Ok(t),\n+                    GoUp(up) => Err(Upgraded(up)),\n+                }\n+            }\n+\n+            None => {\n+                match self.cnt.load(atomics::SeqCst) {\n+                    n if n != DISCONNECTED => Err(Empty),\n+\n+                    // This is a little bit of a tricky case. We failed to pop\n+                    // data above, and then we have viewed that the channel is\n+                    // disconnected. In this window more data could have been\n+                    // sent on the channel. It doesn't really make sense to\n+                    // return that the channel is disconnected when there's\n+                    // actually data on it, so be extra sure there's no data by\n+                    // popping one more time.\n+                    //\n+                    // We can ignore steals because the other end is\n+                    // disconnected and we'll never need to really factor in our\n+                    // steals again.\n+                    _ => {\n+                        match self.queue.pop() {\n+                            Some(Data(t)) => Ok(t),\n+                            Some(GoUp(up)) => Err(Upgraded(up)),\n+                            None => Err(Disconnected),\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    pub fn drop_chan(&mut self) {\n+        // Dropping a channel is pretty simple, we just flag it as disconnected\n+        // and then wakeup a blocker if there is one.\n+        match self.cnt.swap(DISCONNECTED, atomics::SeqCst) {\n+            -1 => { self.take_to_wake().wake().map(|t| t.reawaken()); }\n+            DISCONNECTED => {}\n+            n => { assert!(n >= 0); }\n+        }\n+    }\n+\n+    pub fn drop_port(&mut self) {\n+        // Dropping a port seems like a fairly trivial thing. In theory all we\n+        // need to do is flag that we're disconnected and then everything else\n+        // can take over (we don't have anyone to wake up).\n+        //\n+        // The catch for Ports is that we want to drop the entire contents of\n+        // the queue. There are multiple reasons for having this property, the\n+        // largest of which is that if another chan is waiting in this channel\n+        // (but not received yet), then waiting on that port will cause a\n+        // deadlock.\n+        //\n+        // So if we accept that we must now destroy the entire contents of the\n+        // queue, this code may make a bit more sense. The tricky part is that\n+        // we can't let any in-flight sends go un-dropped, we have to make sure\n+        // *everything* is dropped and nothing new will come onto the channel.\n+\n+        // The first thing we do is set a flag saying that we're done for. All\n+        // sends are gated on this flag, so we're immediately guaranteed that\n+        // there are a bounded number of active sends that we'll have to deal\n+        // with.\n+        self.port_dropped.store(true, atomics::SeqCst);\n+\n+        // Now that we're guaranteed to deal with a bounded number of senders,\n+        // we need to drain the queue. This draining process happens atomically\n+        // with respect to the \"count\" of the channel. If the count is nonzero\n+        // (with steals taken into account), then there must be data on the\n+        // channel. In this case we drain everything and then try again. We will\n+        // continue to fail while active senders send data while we're dropping\n+        // data, but eventually we're guaranteed to break out of this loop\n+        // (because there is a bounded number of senders).\n+        let mut steals = self.steals;\n+        while {\n+            let cnt = self.cnt.compare_and_swap(\n+                            steals, DISCONNECTED, atomics::SeqCst);\n+            cnt != DISCONNECTED && cnt != steals\n+        } {\n+            loop {\n+                match self.queue.pop() {\n+                    Some(..) => { steals += 1; }\n+                    None => break\n+                }\n+            }\n+        }\n+\n+        // At this point in time, we have gated all future senders from sending,\n+        // and we have flagged the channel as being disconnected. The senders\n+        // still have some responsibility, however, because some sends may not\n+        // complete until after we flag the disconnection. There are more\n+        // details in the sending methods that see DISCONNECTED\n+    }\n+\n+    ////////////////////////////////////////////////////////////////////////////\n+    // select implementation\n+    ////////////////////////////////////////////////////////////////////////////\n+\n+    // Tests to see whether this port can receive without blocking. If Ok is\n+    // returned, then that's the answer. If Err is returned, then the returned\n+    // port needs to be queried instead (an upgrade happened)\n+    pub fn can_recv(&mut self) -> Result<bool, Port<T>> {\n+        // We peek at the queue to see if there's anything on it, and we use\n+        // this return value to determine if we should pop from the queue and\n+        // upgrade this channel immediately. If it looks like we've got an\n+        // upgrade pending, then go through the whole recv rigamarole to update\n+        // the internal state.\n+        match self.queue.peek() {\n+            Some(&GoUp(..)) => {\n+                match self.recv() {\n+                    Err(Upgraded(port)) => Err(port),\n+                    _ => unreachable!(),\n+                }\n+            }\n+            Some(..) => Ok(true),\n+            None => Ok(false)\n+        }\n+    }\n+\n+    // Attempts to start selecting on this port. Like a oneshot, this can fail\n+    // immediately because of an upgrade.\n+    pub fn start_selection(&mut self, task: BlockedTask) -> SelectionResult<T> {\n+        match self.decrement(task) {\n+            Ok(()) => SelSuccess,\n+            Err(task) => {\n+                let ret = match self.queue.peek() {\n+                    Some(&GoUp(..)) => {\n+                        match self.queue.pop() {\n+                            Some(GoUp(port)) => SelUpgraded(task, port),\n+                            _ => unreachable!(),\n+                        }\n+                    }\n+                    Some(..) => SelCanceled(task),\n+                    None => SelCanceled(task),\n+                };\n+                // Undo our decrement above, and we should be guaranteed that the\n+                // previous value is positive because we're not going to sleep\n+                let prev = self.cnt.fetch_add(1, atomics::SeqCst);\n+                assert!(prev >= 0);\n+                return ret;\n+            }\n+        }\n+    }\n+\n+    // Removes a previous task from being blocked in this port\n+    pub fn abort_selection(&mut self,\n+                           was_upgrade: bool) -> Result<bool, Port<T>> {\n+        // If we're aborting selection after upgrading from a oneshot, then\n+        // we're guarantee that no one is waiting. The only way that we could\n+        // have seen the upgrade is if data was actually sent on the channel\n+        // half again. For us, this means that there is guaranteed to be data on\n+        // this channel. Furthermore, we're guaranteed that there was no\n+        // start_selection previously, so there's no need to modify `self.cnt`\n+        // at all.\n+        //\n+        // Hence, because of these invariants, we immediately return `Ok(true)`.\n+        // Note that the data may not actually be sent on the channel just yet.\n+        // The other end could have flagged the upgrade but not sent data to\n+        // this end. This is fine because we know it's a small bounded windows\n+        // of time until the data is actually sent.\n+        if was_upgrade {\n+            assert_eq!(self.steals, 0);\n+            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            return Ok(true)\n+        }\n+\n+        // We want to make sure that the count on the channel goes non-negative,\n+        // and in the stream case we can have at most one steal, so just assume\n+        // that we had one steal.\n+        let steals = 1;\n+        let prev = self.cnt.fetch_add(steals + 1, atomics::SeqCst);\n+\n+        // If we were previously disconnected, then we know for sure that there\n+        // is no task in to_wake, so just keep going\n+        let has_data = if prev == DISCONNECTED {\n+            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+            self.cnt.store(DISCONNECTED, atomics::SeqCst);\n+            true // there is data, that data is that we're disconnected\n+        } else {\n+            let cur = prev + steals + 1;\n+            assert!(cur >= 0);\n+\n+            // If the previous count was negative, then we just made things go\n+            // positive, hence we passed the -1 boundary and we're responsible\n+            // for removing the to_wake() field and trashing it.\n+            //\n+            // If the previous count was positive then we're in a tougher\n+            // situation. A possible race is that a sender just incremented\n+            // through -1 (meaning it's going to try to wake a task up), but it\n+            // hasn't yet read the to_wake. In order to prevent a future recv()\n+            // from waking up too early (this sender picking up the plastered\n+            // over to_wake), we spin loop here waiting for to_wake to be 0.\n+            // Note that this entire select() implementation needs an overhaul,\n+            // and this is *not* the worst part of it, so this is not done as a\n+            // final solution but rather out of necessity for now to get\n+            // something working.\n+            if prev < 0 {\n+                self.take_to_wake().trash();\n+            } else {\n+                while self.to_wake.load(atomics::SeqCst) != 0 {\n+                    Thread::yield_now();\n+                }\n+            }\n+            assert_eq!(self.steals, 0);\n+            self.steals = steals;\n+\n+            // if we were previously positive, then there's surely data to\n+            // receive\n+            prev >= 0\n+        };\n+\n+        // Now that we've determined that this queue \"has data\", we peek at the\n+        // queue to see if the data is an upgrade or not. If it's an upgrade,\n+        // then we need to destroy this port and abort selection on the\n+        // upgraded port.\n+        if has_data {\n+            match self.queue.peek() {\n+                Some(&GoUp(..)) => {\n+                    match self.queue.pop() {\n+                        Some(GoUp(port)) => Err(port),\n+                        _ => unreachable!(),\n+                    }\n+                }\n+                _ => Ok(true),\n+            }\n+        } else {\n+            Ok(false)\n+        }\n+    }\n+}\n+\n+#[unsafe_destructor]\n+impl<T: Send> Drop for Packet<T> {\n+    fn drop(&mut self) {\n+        unsafe {\n+            // Note that this load is not only an assert for correctness about\n+            // disconnection, but also a proper fence before the read of\n+            // `to_wake`, so this assert cannot be removed with also removing\n+            // the `to_wake` assert.\n+            assert_eq!(self.cnt.load(atomics::SeqCst), DISCONNECTED);\n+            assert_eq!(self.to_wake.load(atomics::SeqCst), 0);\n+        }\n+    }\n+}"}, {"sha": "53129f3df9b6ffa2d8caa58666db4672dbc7e338", "filename": "src/libstd/io/net/tcp.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Ftcp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Ftcp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fnet%2Ftcp.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -698,7 +698,7 @@ mod test {\n     iotest!(fn tcp_clone_two_read() {\n         let addr = next_test_ip6();\n         let mut acceptor = TcpListener::bind(addr).listen();\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         let c2 = c.clone();\n \n         spawn(proc() {"}, {"sha": "f779d80976f6b4b522981b1ae7b04915a70ca15c", "filename": "src/libstd/io/net/udp.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Fudp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Fudp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fnet%2Fudp.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -301,7 +301,7 @@ mod test {\n         let addr2 = next_test_ip4();\n         let mut sock1 = UdpSocket::bind(addr1).unwrap();\n         let sock2 = UdpSocket::bind(addr2).unwrap();\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         let c2 = c.clone();\n \n         spawn(proc() {\n@@ -335,7 +335,7 @@ mod test {\n         let mut sock1 = UdpSocket::bind(addr1).unwrap();\n         let sock2 = UdpSocket::bind(addr2).unwrap();\n \n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         let (serv_port, serv_chan) = Chan::new();\n \n         spawn(proc() {"}, {"sha": "6ce4a6fdc875815ecfeaf5870c2190075f5d868f", "filename": "src/libstd/io/net/unix.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Funix.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fnet%2Funix.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fnet%2Funix.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -270,7 +270,7 @@ mod tests {\n     fn unix_clone_two_read() {\n         let addr = next_test_unix();\n         let mut acceptor = UnixListener::bind(&addr).listen();\n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         let c2 = c.clone();\n \n         spawn(proc() {"}, {"sha": "46c106234db754bfa6af388ff5761c7b1425c2df", "filename": "src/libstd/io/signal.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fsignal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fio%2Fsignal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fsignal.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -21,7 +21,7 @@ definitions for a number of signals.\n \n use clone::Clone;\n use result::{Ok, Err};\n-use comm::{Port, SharedChan};\n+use comm::{Port, Chan};\n use container::{Map, MutableMap};\n use hashmap;\n use io;\n@@ -81,7 +81,7 @@ pub struct Listener {\n     priv handles: hashmap::HashMap<Signum, ~RtioSignal>,\n     /// chan is where all the handles send signums, which are received by\n     /// the clients from port.\n-    priv chan: SharedChan<Signum>,\n+    priv chan: Chan<Signum>,\n \n     /// Clients of Listener can `recv()` from this port. This is exposed to\n     /// allow selection over this port as well as manipulation of the port\n@@ -93,7 +93,7 @@ impl Listener {\n     /// Creates a new listener for signals. Once created, signals are bound via\n     /// the `register` method (otherwise nothing will ever be received)\n     pub fn new() -> Listener {\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         Listener {\n             chan: chan,\n             port: port,"}, {"sha": "4849b83037f09b3367dd6aff85605300941c6b79", "filename": "src/libstd/prelude.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fprelude.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fprelude.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fprelude.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -80,7 +80,7 @@ pub use vec::{MutableVector, MutableTotalOrdVector};\n pub use vec::{Vector, VectorVector, CloneableVector, ImmutableVector};\n \n // Reexported runtime types\n-pub use comm::{Port, Chan, SharedChan};\n+pub use comm::{Port, Chan};\n pub use task::spawn;\n \n // Reexported statics"}, {"sha": "b751c57c0fa311a0753da40153c5ce375ca17e06", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -73,6 +73,7 @@ pub use self::unwind::{begin_unwind, begin_unwind_raw, begin_unwind_fmt};\n // FIXME: these probably shouldn't be public...\n #[doc(hidden)]\n pub mod shouldnt_be_public {\n+    #[cfg(not(test))]\n     pub use super::local_ptr::native::maybe_tls_key;\n     #[cfg(not(windows), not(target_os = \"android\"))]\n     pub use super::local_ptr::compiled::RT_TLS_PTR;"}, {"sha": "39623e329eae928095361fa01228b425a85378ea", "filename": "src/libstd/rt/rtio.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frtio.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -10,7 +10,7 @@\n \n use c_str::CString;\n use cast;\n-use comm::{SharedChan, Port};\n+use comm::{Chan, Port};\n use libc::c_int;\n use libc;\n use ops::Drop;\n@@ -181,7 +181,7 @@ pub trait IoFactory {\n     fn pipe_open(&mut self, fd: c_int) -> Result<~RtioPipe, IoError>;\n     fn tty_open(&mut self, fd: c_int, readable: bool)\n             -> Result<~RtioTTY, IoError>;\n-    fn signal(&mut self, signal: Signum, channel: SharedChan<Signum>)\n+    fn signal(&mut self, signal: Signum, channel: Chan<Signum>)\n         -> Result<~RtioSignal, IoError>;\n }\n "}, {"sha": "e2b94e655e87055ff8bac245e7000ba1ff35051d", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -449,7 +449,7 @@ mod test {\n \n     #[test]\n     fn comm_shared_chan() {\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n         chan.send(10);\n         assert!(port.recv() == 10);\n     }"}, {"sha": "9f89becaef9c9c23e9cb285b37c9e09b9fc6a5f9", "filename": "src/libstd/rt/unwind.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Funwind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frt%2Funwind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Funwind.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -73,6 +73,7 @@ use unstable::intrinsics;\n \n use uw = self::libunwind;\n \n+#[allow(dead_code)]\n mod libunwind {\n     //! Unwind library interface\n "}, {"sha": "6f684f23d4760f98834ee352802373260bc7c994", "filename": "src/libstd/run.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frun.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Frun.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frun.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -13,7 +13,7 @@\n #[allow(missing_doc)];\n #[deny(unused_must_use)];\n \n-use comm::SharedChan;\n+use comm::Chan;\n use io::Reader;\n use io::process::ProcessExit;\n use io::process;\n@@ -225,7 +225,7 @@ impl Process {\n         // in parallel so we don't deadlock while blocking on one\n         // or the other. FIXME (#2625): Surely there's a much more\n         // clever way to do this.\n-        let (p, ch) = SharedChan::new();\n+        let (p, ch) = Chan::new();\n         let ch_clone = ch.clone();\n \n         spawn(proc() {"}, {"sha": "44825a1ef945b02bf917261ba0e99d605ee4042c", "filename": "src/libstd/sync/mpmc_bounded_queue.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmpmc_bounded_queue.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -172,7 +172,7 @@ mod tests {\n         let nmsgs = 1000u;\n         let mut q = Queue::with_capacity(nthreads*nmsgs);\n         assert_eq!(None, q.pop());\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n \n         for _ in range(0, nthreads) {\n             let q = q.clone();"}, {"sha": "b5a55f3f8c973c930acd682436ecf0ae9ffdc52f", "filename": "src/libstd/sync/mpsc_queue.rs", "status": "modified", "additions": 59, "deletions": 104, "changes": 163, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fmpsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fmpsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fmpsc_queue.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -39,12 +39,10 @@\n //                         /queues/non-intrusive-mpsc-node-based-queue\n \n use cast;\n-use clone::Clone;\n use kinds::Send;\n use ops::Drop;\n use option::{Option, None, Some};\n use ptr::RawPtr;\n-use sync::arc::UnsafeArc;\n use sync::atomics::{AtomicPtr, Release, Acquire, AcqRel, Relaxed};\n \n /// A result of the `pop` function.\n@@ -65,40 +63,12 @@ struct Node<T> {\n     value: Option<T>,\n }\n \n-struct State<T, P> {\n-    head: AtomicPtr<Node<T>>,\n-    tail: *mut Node<T>,\n-    packet: P,\n-}\n-\n-/// The consumer half of this concurrent queue. This half is used to receive\n-/// data from the producers.\n-pub struct Consumer<T, P> {\n-    priv state: UnsafeArc<State<T, P>>,\n-}\n-\n-/// The production half of the concurrent queue. This handle may be cloned in\n-/// order to make handles for new producers.\n-pub struct Producer<T, P> {\n-    priv state: UnsafeArc<State<T, P>>,\n-}\n-\n-impl<T: Send, P: Send> Clone for Producer<T, P> {\n-    fn clone(&self) -> Producer<T, P> {\n-        Producer { state: self.state.clone() }\n-    }\n-}\n-\n-/// Creates a new MPSC queue. The given argument `p` is a user-defined \"packet\"\n-/// of information which will be shared by the consumer and the producer which\n-/// can be re-acquired via the `packet` function. This is helpful when extra\n-/// state is shared between the producer and consumer, but note that there is no\n-/// synchronization performed of this data.\n-pub fn queue<T: Send, P: Send>(p: P) -> (Consumer<T, P>, Producer<T, P>) {\n-    unsafe {\n-        let (a, b) = UnsafeArc::new2(State::new(p));\n-        (Consumer { state: a }, Producer { state: b })\n-    }\n+/// The multi-producer single-consumer structure. This is not cloneable, but it\n+/// may be safely shared so long as it is guaranteed that there is only one\n+/// popper at a time (many pushers are allowed).\n+pub struct Queue<T> {\n+    priv head: AtomicPtr<Node<T>>,\n+    priv tail: *mut Node<T>,\n }\n \n impl<T> Node<T> {\n@@ -110,67 +80,26 @@ impl<T> Node<T> {\n     }\n }\n \n-impl<T: Send, P: Send> State<T, P> {\n-    unsafe fn new(p: P) -> State<T, P> {\n-        let stub = Node::new(None);\n-        State {\n+impl<T: Send> Queue<T> {\n+    /// Creates a new queue that is safe to share among multiple producers and\n+    /// one consumer.\n+    pub fn new() -> Queue<T> {\n+        let stub = unsafe { Node::new(None) };\n+        Queue {\n             head: AtomicPtr::new(stub),\n             tail: stub,\n-            packet: p,\n         }\n     }\n \n-    unsafe fn push(&mut self, t: T) {\n-        let n = Node::new(Some(t));\n-        let prev = self.head.swap(n, AcqRel);\n-        (*prev).next.store(n, Release);\n-    }\n-\n-    unsafe fn pop(&mut self) -> PopResult<T> {\n-        let tail = self.tail;\n-        let next = (*tail).next.load(Acquire);\n-\n-        if !next.is_null() {\n-            self.tail = next;\n-            assert!((*tail).value.is_none());\n-            assert!((*next).value.is_some());\n-            let ret = (*next).value.take_unwrap();\n-            let _: ~Node<T> = cast::transmute(tail);\n-            return Data(ret);\n-        }\n-\n-        if self.head.load(Acquire) == tail {Empty} else {Inconsistent}\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<T: Send, P: Send> Drop for State<T, P> {\n-    fn drop(&mut self) {\n+    /// Pushes a new value onto this queue.\n+    pub fn push(&mut self, t: T) {\n         unsafe {\n-            let mut cur = self.tail;\n-            while !cur.is_null() {\n-                let next = (*cur).next.load(Relaxed);\n-                let _: ~Node<T> = cast::transmute(cur);\n-                cur = next;\n-            }\n+            let n = Node::new(Some(t));\n+            let prev = self.head.swap(n, AcqRel);\n+            (*prev).next.store(n, Release);\n         }\n     }\n-}\n-\n-impl<T: Send, P: Send> Producer<T, P> {\n-    /// Pushes a new value onto this queue.\n-    pub fn push(&mut self, value: T) {\n-        unsafe { (*self.state.get()).push(value) }\n-    }\n-    /// Gets an unsafe pointer to the user-defined packet shared by the\n-    /// producers and the consumer. Note that care must be taken to ensure that\n-    /// the lifetime of the queue outlives the usage of the returned pointer.\n-    pub unsafe fn packet(&self) -> *mut P {\n-        &mut (*self.state.get()).packet as *mut P\n-    }\n-}\n \n-impl<T: Send, P: Send> Consumer<T, P> {\n     /// Pops some data from this queue.\n     ///\n     /// Note that the current implementation means that this function cannot\n@@ -182,8 +111,23 @@ impl<T: Send, P: Send> Consumer<T, P> {\n     /// This inconsistent state means that this queue does indeed have data, but\n     /// it does not currently have access to it at this time.\n     pub fn pop(&mut self) -> PopResult<T> {\n-        unsafe { (*self.state.get()).pop() }\n+        unsafe {\n+            let tail = self.tail;\n+            let next = (*tail).next.load(Acquire);\n+\n+            if !next.is_null() {\n+                self.tail = next;\n+                assert!((*tail).value.is_none());\n+                assert!((*next).value.is_some());\n+                let ret = (*next).value.take_unwrap();\n+                let _: ~Node<T> = cast::transmute(tail);\n+                return Data(ret);\n+            }\n+\n+            if self.head.load(Acquire) == tail {Empty} else {Inconsistent}\n+        }\n     }\n+\n     /// Attempts to pop data from this queue, but doesn't attempt too hard. This\n     /// will canonicalize inconsistent states to a `None` value.\n     pub fn casual_pop(&mut self) -> Option<T> {\n@@ -192,57 +136,68 @@ impl<T: Send, P: Send> Consumer<T, P> {\n             Empty | Inconsistent => None,\n         }\n     }\n-    /// Gets an unsafe pointer to the underlying user-defined packet. See\n-    /// `Producer.packet` for more information.\n-    pub unsafe fn packet(&self) -> *mut P {\n-        &mut (*self.state.get()).packet as *mut P\n+}\n+\n+#[unsafe_destructor]\n+impl<T: Send> Drop for Queue<T> {\n+    fn drop(&mut self) {\n+        unsafe {\n+            let mut cur = self.tail;\n+            while !cur.is_null() {\n+                let next = (*cur).next.load(Relaxed);\n+                let _: ~Node<T> = cast::transmute(cur);\n+                cur = next;\n+            }\n+        }\n     }\n }\n \n #[cfg(test)]\n mod tests {\n     use prelude::*;\n \n-    use super::{queue, Data, Empty, Inconsistent};\n     use native;\n+    use super::{Queue, Data, Empty, Inconsistent};\n+    use sync::arc::UnsafeArc;\n \n     #[test]\n     fn test_full() {\n-        let (_, mut p) = queue(());\n-        p.push(~1);\n-        p.push(~2);\n+        let mut q = Queue::new();\n+        q.push(~1);\n+        q.push(~2);\n     }\n \n     #[test]\n     fn test() {\n         let nthreads = 8u;\n         let nmsgs = 1000u;\n-        let (mut c, p) = queue(());\n-        match c.pop() {\n+        let mut q = Queue::new();\n+        match q.pop() {\n             Empty => {}\n             Inconsistent | Data(..) => fail!()\n         }\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n+        let q = UnsafeArc::new(q);\n \n         for _ in range(0, nthreads) {\n-            let q = p.clone();\n             let chan = chan.clone();\n+            let q = q.clone();\n             native::task::spawn(proc() {\n-                let mut q = q;\n                 for i in range(0, nmsgs) {\n-                    q.push(i);\n+                    unsafe { (*q.get()).push(i); }\n                 }\n                 chan.send(());\n             });\n         }\n \n         let mut i = 0u;\n         while i < nthreads * nmsgs {\n-            match c.pop() {\n+            match unsafe { (*q.get()).pop() } {\n                 Empty | Inconsistent => {},\n                 Data(_) => { i += 1 }\n             }\n         }\n+        drop(chan);\n         for _ in range(0, nthreads) {\n             port.recv();\n         }"}, {"sha": "a2c61a2b13579d5d63e3b8670b61370fbe5a3959", "filename": "src/libstd/sync/spsc_queue.rs", "status": "modified", "additions": 126, "deletions": 168, "changes": 294, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fspsc_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Fsync%2Fspsc_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsync%2Fspsc_queue.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -38,7 +38,6 @@ use kinds::Send;\n use ops::Drop;\n use option::{Some, None, Option};\n use ptr::RawPtr;\n-use sync::arc::UnsafeArc;\n use sync::atomics::{AtomicPtr, Relaxed, AtomicUint, Acquire, Release};\n \n // Node within the linked list queue of messages to send\n@@ -50,75 +49,25 @@ struct Node<T> {\n     next: AtomicPtr<Node<T>>,   // next node in the queue\n }\n \n-// The producer/consumer halves both need access to the `tail` field, and if\n-// they both have access to that we may as well just give them both access\n-// to this whole structure.\n-struct State<T, P> {\n+/// The single-producer single-consumer queue. This structure is not cloneable,\n+/// but it can be safely shared in an UnsafeArc if it is guaranteed that there\n+/// is only one popper and one pusher touching the queue at any one point in\n+/// time.\n+pub struct Queue<T> {\n     // consumer fields\n-    tail: *mut Node<T>, // where to pop from\n-    tail_prev: AtomicPtr<Node<T>>, // where to pop from\n+    priv tail: *mut Node<T>, // where to pop from\n+    priv tail_prev: AtomicPtr<Node<T>>, // where to pop from\n \n     // producer fields\n-    head: *mut Node<T>,      // where to push to\n-    first: *mut Node<T>,     // where to get new nodes from\n-    tail_copy: *mut Node<T>, // between first/tail\n+    priv head: *mut Node<T>,      // where to push to\n+    priv first: *mut Node<T>,     // where to get new nodes from\n+    priv tail_copy: *mut Node<T>, // between first/tail\n \n     // Cache maintenance fields. Additions and subtractions are stored\n     // separately in order to allow them to use nonatomic addition/subtraction.\n-    cache_bound: uint,\n-    cache_additions: AtomicUint,\n-    cache_subtractions: AtomicUint,\n-\n-    packet: P,\n-}\n-\n-/// Producer half of this queue. This handle is used to push data to the\n-/// consumer.\n-pub struct Producer<T, P> {\n-    priv state: UnsafeArc<State<T, P>>,\n-}\n-\n-/// Consumer half of this queue. This handle is used to receive data from the\n-/// producer.\n-pub struct Consumer<T, P> {\n-    priv state: UnsafeArc<State<T, P>>,\n-}\n-\n-/// Creates a new queue. The producer returned is connected to the consumer to\n-/// push all data to the consumer.\n-///\n-/// # Arguments\n-///\n-///   * `bound` - This queue implementation is implemented with a linked list,\n-///               and this means that a push is always a malloc. In order to\n-///               amortize this cost, an internal cache of nodes is maintained\n-///               to prevent a malloc from always being necessary. This bound is\n-///               the limit on the size of the cache (if desired). If the value\n-///               is 0, then the cache has no bound. Otherwise, the cache will\n-///               never grow larger than `bound` (although the queue itself\n-///               could be much larger.\n-///\n-///   * `p` - This is the user-defined packet of data which will also be shared\n-///           between the producer and consumer.\n-pub fn queue<T: Send, P: Send>(bound: uint,\n-                               p: P) -> (Consumer<T, P>, Producer<T, P>)\n-{\n-    let n1 = Node::new();\n-    let n2 = Node::new();\n-    unsafe { (*n1).next.store(n2, Relaxed) }\n-    let state = State {\n-        tail: n2,\n-        tail_prev: AtomicPtr::new(n1),\n-        head: n2,\n-        first: n1,\n-        tail_copy: n1,\n-        cache_bound: bound,\n-        cache_additions: AtomicUint::new(0),\n-        cache_subtractions: AtomicUint::new(0),\n-        packet: p,\n-    };\n-    let (arc1, arc2) = UnsafeArc::new2(state);\n-    (Consumer { state: arc1 }, Producer { state: arc2 })\n+    priv cache_bound: uint,\n+    priv cache_additions: AtomicUint,\n+    priv cache_subtractions: AtomicUint,\n }\n \n impl<T: Send> Node<T> {\n@@ -132,49 +81,49 @@ impl<T: Send> Node<T> {\n     }\n }\n \n-impl<T: Send, P: Send> Producer<T, P> {\n-    /// Pushes data onto the queue\n-    pub fn push(&mut self, t: T) {\n-        unsafe { (*self.state.get()).push(t) }\n-    }\n-    /// Tests whether the queue is empty. Note that if this function returns\n-    /// `false`, the return value is significant, but if the return value is\n-    /// `true` then almost no meaning can be attached to the return value.\n-    pub fn is_empty(&self) -> bool {\n-        unsafe { (*self.state.get()).is_empty() }\n-    }\n-    /// Acquires an unsafe pointer to the underlying user-defined packet. Note\n-    /// that care must be taken to ensure that the queue outlives the usage of\n-    /// the packet (because it is an unsafe pointer).\n-    pub unsafe fn packet(&self) -> *mut P {\n-        &mut (*self.state.get()).packet as *mut P\n-    }\n-}\n-\n-impl<T: Send, P: Send> Consumer<T, P> {\n-    /// Pops some data from this queue, returning `None` when the queue is\n-    /// empty.\n-    pub fn pop(&mut self) -> Option<T> {\n-        unsafe { (*self.state.get()).pop() }\n-    }\n-    /// Same function as the producer's `packet` method.\n-    pub unsafe fn packet(&self) -> *mut P {\n-        &mut (*self.state.get()).packet as *mut P\n+impl<T: Send> Queue<T> {\n+    /// Creates a new queue. The producer returned is connected to the consumer\n+    /// to push all data to the consumer.\n+    ///\n+    /// # Arguments\n+    ///\n+    ///   * `bound` - This queue implementation is implemented with a linked\n+    ///               list, and this means that a push is always a malloc. In\n+    ///               order to amortize this cost, an internal cache of nodes is\n+    ///               maintained to prevent a malloc from always being\n+    ///               necessary. This bound is the limit on the size of the\n+    ///               cache (if desired). If the value is 0, then the cache has\n+    ///               no bound. Otherwise, the cache will never grow larger than\n+    ///               `bound` (although the queue itself could be much larger.\n+    pub fn new(bound: uint) -> Queue<T> {\n+        let n1 = Node::new();\n+        let n2 = Node::new();\n+        unsafe { (*n1).next.store(n2, Relaxed) }\n+        Queue {\n+            tail: n2,\n+            tail_prev: AtomicPtr::new(n1),\n+            head: n2,\n+            first: n1,\n+            tail_copy: n1,\n+            cache_bound: bound,\n+            cache_additions: AtomicUint::new(0),\n+            cache_subtractions: AtomicUint::new(0),\n+        }\n     }\n-}\n \n-impl<T: Send, P: Send> State<T, P> {\n-    // remember that there is only one thread executing `push` (and only one\n-    // thread executing `pop`)\n-    unsafe fn push(&mut self, t: T) {\n-        // Acquire a node (which either uses a cached one or allocates a new\n-        // one), and then append this to the 'head' node.\n-        let n = self.alloc();\n-        assert!((*n).value.is_none());\n-        (*n).value = Some(t);\n-        (*n).next.store(0 as *mut Node<T>, Relaxed);\n-        (*self.head).next.store(n, Release);\n-        self.head = n;\n+    /// Pushes a new value onto this queue. Note that to use this function\n+    /// safely, it must be externally guaranteed that there is only one pusher.\n+    pub fn push(&mut self, t: T) {\n+        unsafe {\n+            // Acquire a node (which either uses a cached one or allocates a new\n+            // one), and then append this to the 'head' node.\n+            let n = self.alloc();\n+            assert!((*n).value.is_none());\n+            (*n).value = Some(t);\n+            (*n).next.store(0 as *mut Node<T>, Relaxed);\n+            (*self.head).next.store(n, Release);\n+            self.head = n;\n+        }\n     }\n \n     unsafe fn alloc(&mut self) -> *mut Node<T> {\n@@ -208,50 +157,59 @@ impl<T: Send, P: Send> State<T, P> {\n         Node::new()\n     }\n \n-    // remember that there is only one thread executing `pop` (and only one\n-    // thread executing `push`)\n-    unsafe fn pop(&mut self) -> Option<T> {\n-        // The `tail` node is not actually a used node, but rather a\n-        // sentinel from where we should start popping from. Hence, look at\n-        // tail's next field and see if we can use it. If we do a pop, then\n-        // the current tail node is a candidate for going into the cache.\n-        let tail = self.tail;\n-        let next = (*tail).next.load(Acquire);\n-        if next.is_null() { return None }\n-        assert!((*next).value.is_some());\n-        let ret = (*next).value.take();\n-\n-        self.tail = next;\n-        if self.cache_bound == 0 {\n-            self.tail_prev.store(tail, Release);\n-        } else {\n-            // FIXME: this is dubious with overflow.\n-            let additions = self.cache_additions.load(Relaxed);\n-            let subtractions = self.cache_subtractions.load(Relaxed);\n-            let size = additions - subtractions;\n+    /// Attempts to pop a value from this queue. Remember that to use this type\n+    /// safely you must ensure that there is only one popper at a time.\n+    pub fn pop(&mut self) -> Option<T> {\n+        unsafe {\n+            // The `tail` node is not actually a used node, but rather a\n+            // sentinel from where we should start popping from. Hence, look at\n+            // tail's next field and see if we can use it. If we do a pop, then\n+            // the current tail node is a candidate for going into the cache.\n+            let tail = self.tail;\n+            let next = (*tail).next.load(Acquire);\n+            if next.is_null() { return None }\n+            assert!((*next).value.is_some());\n+            let ret = (*next).value.take();\n \n-            if size < self.cache_bound {\n+            self.tail = next;\n+            if self.cache_bound == 0 {\n                 self.tail_prev.store(tail, Release);\n-                self.cache_additions.store(additions + 1, Relaxed);\n             } else {\n-                (*self.tail_prev.load(Relaxed)).next.store(next, Relaxed);\n-                // We have successfully erased all references to 'tail', so\n-                // now we can safely drop it.\n-                let _: ~Node<T> = cast::transmute(tail);\n+                // FIXME: this is dubious with overflow.\n+                let additions = self.cache_additions.load(Relaxed);\n+                let subtractions = self.cache_subtractions.load(Relaxed);\n+                let size = additions - subtractions;\n+\n+                if size < self.cache_bound {\n+                    self.tail_prev.store(tail, Release);\n+                    self.cache_additions.store(additions + 1, Relaxed);\n+                } else {\n+                    (*self.tail_prev.load(Relaxed)).next.store(next, Relaxed);\n+                    // We have successfully erased all references to 'tail', so\n+                    // now we can safely drop it.\n+                    let _: ~Node<T> = cast::transmute(tail);\n+                }\n             }\n+            return ret;\n         }\n-        return ret;\n     }\n \n-    unsafe fn is_empty(&self) -> bool {\n-        let tail = self.tail;\n-        let next = (*tail).next.load(Acquire);\n-        return next.is_null();\n+    /// Attempts to peek at the head of the queue, returning `None` if the queue\n+    /// has no data currently\n+    pub fn peek<'a>(&'a mut self) -> Option<&'a mut T> {\n+        // This is essentially the same as above with all the popping bits\n+        // stripped out.\n+        unsafe {\n+            let tail = self.tail;\n+            let next = (*tail).next.load(Acquire);\n+            if next.is_null() { return None }\n+            return (*next).value.as_mut();\n+        }\n     }\n }\n \n #[unsafe_destructor]\n-impl<T: Send, P: Send> Drop for State<T, P> {\n+impl<T: Send> Drop for Queue<T> {\n     fn drop(&mut self) {\n         unsafe {\n             let mut cur = self.first;\n@@ -267,44 +225,45 @@ impl<T: Send, P: Send> Drop for State<T, P> {\n #[cfg(test)]\n mod test {\n     use prelude::*;\n-    use super::queue;\n     use native;\n+    use super::Queue;\n+    use sync::arc::UnsafeArc;\n \n     #[test]\n     fn smoke() {\n-        let (mut c, mut p) = queue(0, ());\n-        p.push(1);\n-        p.push(2);\n-        assert_eq!(c.pop(), Some(1));\n-        assert_eq!(c.pop(), Some(2));\n-        assert_eq!(c.pop(), None);\n-        p.push(3);\n-        p.push(4);\n-        assert_eq!(c.pop(), Some(3));\n-        assert_eq!(c.pop(), Some(4));\n-        assert_eq!(c.pop(), None);\n+        let mut q = Queue::new(0);\n+        q.push(1);\n+        q.push(2);\n+        assert_eq!(q.pop(), Some(1));\n+        assert_eq!(q.pop(), Some(2));\n+        assert_eq!(q.pop(), None);\n+        q.push(3);\n+        q.push(4);\n+        assert_eq!(q.pop(), Some(3));\n+        assert_eq!(q.pop(), Some(4));\n+        assert_eq!(q.pop(), None);\n     }\n \n     #[test]\n     fn drop_full() {\n-        let (_, mut p) = queue(0, ());\n-        p.push(~1);\n-        p.push(~2);\n+        let mut q = Queue::new(0);\n+        q.push(~1);\n+        q.push(~2);\n     }\n \n     #[test]\n     fn smoke_bound() {\n-        let (mut c, mut p) = queue(1, ());\n-        p.push(1);\n-        p.push(2);\n-        assert_eq!(c.pop(), Some(1));\n-        assert_eq!(c.pop(), Some(2));\n-        assert_eq!(c.pop(), None);\n-        p.push(3);\n-        p.push(4);\n-        assert_eq!(c.pop(), Some(3));\n-        assert_eq!(c.pop(), Some(4));\n-        assert_eq!(c.pop(), None);\n+        let mut q = Queue::new(1);\n+        q.push(1);\n+        q.push(2);\n+        assert_eq!(q.pop(), Some(1));\n+        assert_eq!(q.pop(), Some(2));\n+        assert_eq!(q.pop(), None);\n+        q.push(3);\n+        q.push(4);\n+        assert_eq!(q.pop(), Some(3));\n+        assert_eq!(q.pop(), Some(4));\n+        assert_eq!(q.pop(), None);\n     }\n \n     #[test]\n@@ -313,13 +272,12 @@ mod test {\n         stress_bound(1);\n \n         fn stress_bound(bound: uint) {\n-            let (c, mut p) = queue(bound, ());\n+            let (a, b) = UnsafeArc::new2(Queue::new(bound));\n             let (port, chan) = Chan::new();\n             native::task::spawn(proc() {\n-                let mut c = c;\n                 for _ in range(0, 100000) {\n                     loop {\n-                        match c.pop() {\n+                        match unsafe { (*b.get()).pop() } {\n                             Some(1) => break,\n                             Some(_) => fail!(),\n                             None => {}\n@@ -329,7 +287,7 @@ mod test {\n                 chan.send(());\n             });\n             for _ in range(0, 100000) {\n-                p.push(1);\n+                unsafe { (*a.get()).push(1); }\n             }\n             port.recv();\n         }"}, {"sha": "5d8c4a87b39357e1028f1e5036b9fcc48e5d38d8", "filename": "src/libstd/task.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibstd%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -65,7 +65,6 @@ use rt::task::Task;\n use str::{Str, SendStr, IntoMaybeOwned};\n \n #[cfg(test)] use any::{AnyOwnExt, AnyRefExt};\n-#[cfg(test)] use comm::SharedChan;\n #[cfg(test)] use ptr;\n #[cfg(test)] use result;\n \n@@ -474,9 +473,9 @@ fn test_try_fail() {\n fn test_spawn_sched() {\n     use clone::Clone;\n \n-    let (po, ch) = SharedChan::new();\n+    let (po, ch) = Chan::new();\n \n-    fn f(i: int, ch: SharedChan<()>) {\n+    fn f(i: int, ch: Chan<()>) {\n         let ch = ch.clone();\n         spawn(proc() {\n             if i == 0 {"}, {"sha": "7078f01945e96febdb5489a577fadb73e551f2a1", "filename": "src/libsync/sync/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fsync%2Fmod.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -764,7 +764,7 @@ mod tests {\n     use std::cast;\n     use std::result;\n     use std::task;\n-    use std::comm::{SharedChan, Empty};\n+    use std::comm::Empty;\n \n     /************************************************************************\n      * Semaphore tests\n@@ -1393,7 +1393,7 @@ mod tests {\n     #[test]\n     fn test_barrier() {\n         let barrier = Barrier::new(10);\n-        let (port, chan) = SharedChan::new();\n+        let (port, chan) = Chan::new();\n \n         for _ in range(0, 9) {\n             let c = barrier.clone();"}, {"sha": "3726528a5e9c8d8729474564832ee2880c59e4ba", "filename": "src/libsync/sync/mutex.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fsync%2Fmutex.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -531,7 +531,7 @@ mod test {\n             }\n         }\n \n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         for _ in range(0, N) {\n             let c2 = c.clone();\n             native::task::spawn(proc() { inc(); c2.send(()); });"}, {"sha": "a651f3b9d4c3ec2e1ff05b3edf8c5bb375884ac1", "filename": "src/libsync/sync/one.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fone.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Flibsync%2Fsync%2Fone.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fsync%2Fone.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -137,7 +137,7 @@ mod test {\n         static mut o: Once = ONCE_INIT;\n         static mut run: bool = false;\n \n-        let (p, c) = SharedChan::new();\n+        let (p, c) = Chan::new();\n         for _ in range(0, 10) {\n             let c = c.clone();\n             spawn(proc() {"}, {"sha": "b766be88d2309047aac82666d5a26e905429cbde", "filename": "src/test/bench/msgsend-pipes-shared.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-pipes-shared.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -53,7 +53,7 @@ fn server(requests: &Port<request>, responses: &Chan<uint>) {\n \n fn run(args: &[~str]) {\n     let (from_child, to_parent) = Chan::new();\n-    let (from_parent, to_child) = SharedChan::new();\n+    let (from_parent, to_child) = Chan::new();\n \n     let size = from_str::<uint>(args[1]).unwrap();\n     let workers = from_str::<uint>(args[2]).unwrap();"}, {"sha": "89e0bcf33263833f067c05524901f62f542f0f98", "filename": "src/test/bench/msgsend-pipes.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fmsgsend-pipes.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -67,7 +67,7 @@ fn run(args: &[~str]) {\n         });\n         from_parent\n     } else {\n-        let (from_parent, to_child) = SharedChan::new();\n+        let (from_parent, to_child) = Chan::new();\n         for _ in range(0u, workers) {\n             let to_child = to_child.clone();\n             let mut builder = task::task();"}, {"sha": "5c237b306fbd820424da02f8b9e22fc40e703a0f", "filename": "src/test/bench/shootout-chameneos-redux.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-chameneos-redux.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -100,8 +100,8 @@ fn creature(\n     name: uint,\n     color: color,\n     from_rendezvous: Port<Option<CreatureInfo>>,\n-    to_rendezvous: SharedChan<CreatureInfo>,\n-    to_rendezvous_log: SharedChan<~str>\n+    to_rendezvous: Chan<CreatureInfo>,\n+    to_rendezvous_log: Chan<~str>\n ) {\n     let mut color = color;\n     let mut creatures_met = 0;\n@@ -137,8 +137,8 @@ fn creature(\n fn rendezvous(nn: uint, set: ~[color]) {\n \n     // these ports will allow us to hear from the creatures\n-    let (from_creatures, to_rendezvous) = SharedChan::<CreatureInfo>::new();\n-    let (from_creatures_log, to_rendezvous_log) = SharedChan::<~str>::new();\n+    let (from_creatures, to_rendezvous) = Chan::<CreatureInfo>::new();\n+    let (from_creatures_log, to_rendezvous_log) = Chan::<~str>::new();\n \n     // these channels will be passed to the creatures so they can talk to us\n "}, {"sha": "7f4fd3cf94ce1320fbbf43131da6bd9e1d29fd23", "filename": "src/test/bench/shootout-pfib.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fshootout-pfib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Fshootout-pfib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fshootout-pfib.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -28,13 +28,13 @@ use std::task;\n use std::uint;\n \n fn fib(n: int) -> int {\n-    fn pfib(c: &SharedChan<int>, n: int) {\n+    fn pfib(c: &Chan<int>, n: int) {\n         if n == 0 {\n             c.send(0);\n         } else if n <= 2 {\n             c.send(1);\n         } else {\n-            let (pp, cc) = SharedChan::new();\n+            let (pp, cc) = Chan::new();\n             let ch = cc.clone();\n             task::spawn(proc() pfib(&ch, n - 1));\n             let ch = cc.clone();\n@@ -43,7 +43,7 @@ fn fib(n: int) -> int {\n         }\n     }\n \n-    let (p, ch) = SharedChan::new();\n+    let (p, ch) = Chan::new();\n     let _t = task::spawn(proc() pfib(&ch, n) );\n     p.recv()\n }"}, {"sha": "189a3ac74480ef09986ba1d796cfb7f7ad2c4876", "filename": "src/test/bench/task-perf-linked-failure.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Ftask-perf-linked-failure.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -33,15 +33,15 @@\n // Creates in the background 'num_tasks' tasks, all blocked forever.\n // Doesn't return until all such tasks are ready, but doesn't block forever itself.\n \n-use std::comm::{stream, SharedChan};\n+use std::comm::{stream, Chan};\n use std::os;\n use std::result;\n use std::task;\n use std::uint;\n \n fn grandchild_group(num_tasks: uint) {\n     let (po, ch) = stream();\n-    let ch = SharedChan::new(ch);\n+    let ch = Chan::new(ch);\n \n     for _ in range(0, num_tasks) {\n         let ch = ch.clone();"}, {"sha": "ef5bd21f913944dc40feb45c1d7d46c4b863fecc", "filename": "src/test/compile-fail/comm-not-freeze.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fcompile-fail%2Fcomm-not-freeze.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Fcompile-fail%2Fcomm-not-freeze.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fcomm-not-freeze.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -13,5 +13,5 @@ fn test<T: Freeze>() {}\n fn main() {\n     test::<Chan<int>>();        //~ ERROR: does not fulfill `Freeze`\n     test::<Port<int>>();        //~ ERROR: does not fulfill `Freeze`\n-    test::<SharedChan<int>>();  //~ ERROR: does not fulfill `Freeze`\n+    test::<Chan<int>>();  //~ ERROR: does not fulfill `Freeze`\n }"}, {"sha": "9c05dae46bd2828ef47245e010940c3da48777c5", "filename": "src/test/run-pass/hashmap-memory.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Fhashmap-memory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Fhashmap-memory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fhashmap-memory.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -31,19 +31,19 @@ mod map_reduce {\n \n     enum ctrl_proto { find_reducer(~[u8], Chan<int>), mapper_done, }\n \n-    fn start_mappers(ctrl: SharedChan<ctrl_proto>, inputs: ~[~str]) {\n+    fn start_mappers(ctrl: Chan<ctrl_proto>, inputs: ~[~str]) {\n         for i in inputs.iter() {\n             let ctrl = ctrl.clone();\n             let i = i.clone();\n             task::spawn(proc() map_task(ctrl.clone(), i.clone()) );\n         }\n     }\n \n-    fn map_task(ctrl: SharedChan<ctrl_proto>, input: ~str) {\n+    fn map_task(ctrl: Chan<ctrl_proto>, input: ~str) {\n         let mut intermediates = HashMap::new();\n \n         fn emit(im: &mut HashMap<~str, int>,\n-                ctrl: SharedChan<ctrl_proto>, key: ~str,\n+                ctrl: Chan<ctrl_proto>, key: ~str,\n                 _val: ~str) {\n             if im.contains_key(&key) {\n                 return;\n@@ -63,7 +63,7 @@ mod map_reduce {\n     }\n \n     pub fn map_reduce(inputs: ~[~str]) {\n-        let (ctrl_port, ctrl_chan) = SharedChan::new();\n+        let (ctrl_port, ctrl_chan) = Chan::new();\n \n         // This task becomes the master control task. It spawns others\n         // to do the rest."}, {"sha": "0403284e55f5ea81a1838c2f340d2970e52c50cc", "filename": "src/test/run-pass/task-comm-14.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-14.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-14.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Ftask-comm-14.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -13,7 +13,7 @@\n use std::task;\n \n pub fn main() {\n-    let (po, ch) = SharedChan::new();\n+    let (po, ch) = Chan::new();\n \n     // Spawn 10 tasks each sending us back one int.\n     let mut i = 10;\n@@ -37,7 +37,7 @@ pub fn main() {\n     info!(\"main thread exiting\");\n }\n \n-fn child(x: int, ch: &SharedChan<int>) {\n+fn child(x: int, ch: &Chan<int>) {\n     info!(\"{}\", x);\n     ch.send(x);\n }"}, {"sha": "f5374e7df05a90b948f06cd320714a8d2b945ae2", "filename": "src/test/run-pass/task-comm-3.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-3.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-3.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Ftask-comm-3.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -16,7 +16,7 @@ use std::task;\n \n pub fn main() { info!(\"===== WITHOUT THREADS =====\"); test00(); }\n \n-fn test00_start(ch: &SharedChan<int>, message: int, count: int) {\n+fn test00_start(ch: &Chan<int>, message: int, count: int) {\n     info!(\"Starting test00_start\");\n     let mut i: int = 0;\n     while i < count {\n@@ -33,7 +33,7 @@ fn test00() {\n \n     info!(\"Creating tasks\");\n \n-    let (po, ch) = SharedChan::new();\n+    let (po, ch) = Chan::new();\n \n     let mut i: int = 0;\n "}, {"sha": "c63bf8bc856594068c96e74eeac200d611d4a512", "filename": "src/test/run-pass/task-comm-6.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-6.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-6.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Ftask-comm-6.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -15,7 +15,7 @@ pub fn main() { test00(); }\n fn test00() {\n     let mut r: int = 0;\n     let mut sum: int = 0;\n-    let (p, ch) = SharedChan::new();\n+    let (p, ch) = Chan::new();\n     let mut c0 = ch.clone();\n     let mut c1 = ch.clone();\n     let mut c2 = ch.clone();"}, {"sha": "ff43a80adaca1ecba4efb3e4ce795287db9e8419", "filename": "src/test/run-pass/task-comm-7.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-7.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Ftask-comm-7.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Ftask-comm-7.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -18,7 +18,7 @@ use std::task;\n \n pub fn main() { test00(); }\n \n-fn test00_start(c: &SharedChan<int>, start: int,\n+fn test00_start(c: &Chan<int>, start: int,\n                 number_of_messages: int) {\n     let mut i: int = 0;\n     while i < number_of_messages { c.send(start + i); i += 1; }\n@@ -27,7 +27,7 @@ fn test00_start(c: &SharedChan<int>, start: int,\n fn test00() {\n     let mut r: int = 0;\n     let mut sum: int = 0;\n-    let (p, ch) = SharedChan::new();\n+    let (p, ch) = Chan::new();\n     let number_of_messages: int = 10;\n \n     let c = ch.clone();"}, {"sha": "299fed735ab186b3d7c06c54871323abef927005", "filename": "src/test/run-pass/unique-send-2.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Funique-send-2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Funique-send-2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Funique-send-2.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -10,12 +10,12 @@\n \n use std::task;\n \n-fn child(c: &SharedChan<~uint>, i: uint) {\n+fn child(c: &Chan<~uint>, i: uint) {\n     c.send(~i);\n }\n \n pub fn main() {\n-    let (p, ch) = SharedChan::new();\n+    let (p, ch) = Chan::new();\n     let n = 100u;\n     let mut expected = 0u;\n     for i in range(0u, n) {"}, {"sha": "e643a20436e0cb4fc21b5cf379fe7f9936df827a", "filename": "src/test/run-pass/unwind-resource.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Funwind-resource.rs", "raw_url": "https://github.com/rust-lang/rust/raw/11bc14d724052e5567d794c425fcef1c3c73302d/src%2Ftest%2Frun-pass%2Funwind-resource.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Funwind-resource.rs?ref=11bc14d724052e5567d794c425fcef1c3c73302d", "patch": "@@ -15,7 +15,7 @@ extern mod extra;\n use std::task;\n \n struct complainer {\n-  c: SharedChan<bool>,\n+  c: Chan<bool>,\n }\n \n impl Drop for complainer {\n@@ -26,20 +26,20 @@ impl Drop for complainer {\n     }\n }\n \n-fn complainer(c: SharedChan<bool>) -> complainer {\n+fn complainer(c: Chan<bool>) -> complainer {\n     error!(\"Hello!\");\n     complainer {\n         c: c\n     }\n }\n \n-fn f(c: SharedChan<bool>) {\n+fn f(c: Chan<bool>) {\n     let _c = complainer(c);\n     fail!();\n }\n \n pub fn main() {\n-    let (p, c) = SharedChan::new();\n+    let (p, c) = Chan::new();\n     task::spawn(proc() f(c.clone()));\n     error!(\"hiiiiiiiii\");\n     assert!(p.recv());"}]}