{"sha": "75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "node_id": "C_kwDOAAsO6NoAKDc1ZmQzOTFhYWEzZTIxYzdhMWU5NDAzZjIwZWFjZjIzYzMyYWE3Yzc", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-04-11T00:55:49Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-04-13T23:01:23Z"}, "message": "Introduce `TtHandle` and use it in `TokenSet`.\n\nThis removes the last use of `<mbe::TokenTree as Clone>`. It also\nremoves two trivial methods on `Delimited`.", "tree": {"sha": "7a73e84c3cba078c905047943b491b731638570e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7a73e84c3cba078c905047943b491b731638570e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "html_url": "https://github.com/rust-lang/rust/commit/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2657d8f7b3bbdebb7c6428b8d08279504fbfbc3f", "url": "https://api.github.com/repos/rust-lang/rust/commits/2657d8f7b3bbdebb7c6428b8d08279504fbfbc3f", "html_url": "https://github.com/rust-lang/rust/commit/2657d8f7b3bbdebb7c6428b8d08279504fbfbc3f"}], "stats": {"total": 164, "additions": 111, "deletions": 53}, "files": [{"sha": "845d1ff5b515efd4f1a75f0dddde0c68e79d439d", "filename": "compiler/rustc_expand/src/mbe.rs", "status": "modified", "additions": 0, "deletions": 12, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs?ref=75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "patch": "@@ -26,18 +26,6 @@ struct Delimited {\n     tts: Vec<TokenTree>,\n }\n \n-impl Delimited {\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the opening delimiter.\n-    fn open_tt(&self, span: DelimSpan) -> TokenTree {\n-        TokenTree::token(token::OpenDelim(self.delim), span.open)\n-    }\n-\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n-    fn close_tt(&self, span: DelimSpan) -> TokenTree {\n-        TokenTree::token(token::CloseDelim(self.delim), span.close)\n-    }\n-}\n-\n #[derive(PartialEq, Encodable, Decodable, Debug)]\n struct SequenceRepetition {\n     /// The sequence of token trees"}, {"sha": "74b8450f756d34321fc66c10e42f22767ccc800f", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "patch": "@@ -142,10 +142,13 @@ pub(super) fn compute_locs(sess: &ParseSess, matcher: &[TokenTree]) -> Vec<Match\n                     locs.push(MatcherLoc::Token { token: token.clone() });\n                 }\n                 TokenTree::Delimited(span, delimited) => {\n+                    let open_token = Token::new(token::OpenDelim(delimited.delim), span.open);\n+                    let close_token = Token::new(token::CloseDelim(delimited.delim), span.close);\n+\n                     locs.push(MatcherLoc::Delimited);\n-                    inner(sess, &[delimited.open_tt(*span)], locs, next_metavar, seq_depth);\n+                    locs.push(MatcherLoc::Token { token: open_token });\n                     inner(sess, &delimited.tts, locs, next_metavar, seq_depth);\n-                    inner(sess, &[delimited.close_tt(*span)], locs, next_metavar, seq_depth);\n+                    locs.push(MatcherLoc::Token { token: close_token });\n                 }\n                 TokenTree::Sequence(_, seq) => {\n                     // We can't determine `idx_first_after` and construct the final"}, {"sha": "f9d24eeadd0c8b4d576f109321aaf71bfd34e3b9", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 106, "deletions": 39, "changes": 145, "blob_url": "https://github.com/rust-lang/rust/blob/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=75fd391aaa3e21c7a1e9403f20eacf23c32aa7c7", "patch": "@@ -8,7 +8,7 @@ use crate::mbe::macro_parser::{MatchedSeq, MatchedTokenTree, MatcherLoc};\n use crate::mbe::transcribe::transcribe;\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, NonterminalKind, Token, TokenKind::*};\n+use rustc_ast::token::{self, NonterminalKind, Token, TokenKind, TokenKind::*};\n use rustc_ast::tokenstream::{DelimSpan, TokenStream};\n use rustc_ast::{NodeId, DUMMY_NODE_ID};\n use rustc_ast_pretty::pprust;\n@@ -658,18 +658,18 @@ fn check_matcher(\n // that do not try to inject artificial span information. My plan is\n // to try to catch such cases ahead of time and not include them in\n // the precomputed mapping.)\n-struct FirstSets {\n+struct FirstSets<'tt> {\n     // this maps each TokenTree::Sequence `$(tt ...) SEP OP` that is uniquely identified by its\n     // span in the original matcher to the First set for the inner sequence `tt ...`.\n     //\n     // If two sequences have the same span in a matcher, then map that\n     // span to None (invalidating the mapping here and forcing the code to\n     // use a slow path).\n-    first: FxHashMap<Span, Option<TokenSet>>,\n+    first: FxHashMap<Span, Option<TokenSet<'tt>>>,\n }\n \n-impl FirstSets {\n-    fn new(tts: &[mbe::TokenTree]) -> FirstSets {\n+impl<'tt> FirstSets<'tt> {\n+    fn new(tts: &'tt [mbe::TokenTree]) -> FirstSets<'tt> {\n         use mbe::TokenTree;\n \n         let mut sets = FirstSets { first: FxHashMap::default() };\n@@ -679,19 +679,22 @@ impl FirstSets {\n         // walks backward over `tts`, returning the FIRST for `tts`\n         // and updating `sets` at the same time for all sequence\n         // substructure we find within `tts`.\n-        fn build_recur(sets: &mut FirstSets, tts: &[TokenTree]) -> TokenSet {\n+        fn build_recur<'tt>(sets: &mut FirstSets<'tt>, tts: &'tt [TokenTree]) -> TokenSet<'tt> {\n             let mut first = TokenSet::empty();\n             for tt in tts.iter().rev() {\n                 match *tt {\n                     TokenTree::Token(..)\n                     | TokenTree::MetaVar(..)\n                     | TokenTree::MetaVarDecl(..)\n                     | TokenTree::MetaVarExpr(..) => {\n-                        first.replace_with(tt.clone());\n+                        first.replace_with(TtHandle::TtRef(tt));\n                     }\n                     TokenTree::Delimited(span, ref delimited) => {\n                         build_recur(sets, &delimited.tts);\n-                        first.replace_with(delimited.open_tt(span));\n+                        first.replace_with(TtHandle::from_token_kind(\n+                            token::OpenDelim(delimited.delim),\n+                            span.open,\n+                        ));\n                     }\n                     TokenTree::Sequence(sp, ref seq_rep) => {\n                         let subfirst = build_recur(sets, &seq_rep.tts);\n@@ -715,7 +718,7 @@ impl FirstSets {\n                         // token could be the separator token itself.\n \n                         if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n-                            first.add_one_maybe(TokenTree::Token(sep.clone()));\n+                            first.add_one_maybe(TtHandle::from_token(sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -741,7 +744,7 @@ impl FirstSets {\n \n     // walks forward over `tts` until all potential FIRST tokens are\n     // identified.\n-    fn first(&self, tts: &[mbe::TokenTree]) -> TokenSet {\n+    fn first(&self, tts: &'tt [mbe::TokenTree]) -> TokenSet<'tt> {\n         use mbe::TokenTree;\n \n         let mut first = TokenSet::empty();\n@@ -752,11 +755,14 @@ impl FirstSets {\n                 | TokenTree::MetaVar(..)\n                 | TokenTree::MetaVarDecl(..)\n                 | TokenTree::MetaVarExpr(..) => {\n-                    first.add_one(tt.clone());\n+                    first.add_one(TtHandle::TtRef(tt));\n                     return first;\n                 }\n                 TokenTree::Delimited(span, ref delimited) => {\n-                    first.add_one(delimited.open_tt(span));\n+                    first.add_one(TtHandle::from_token_kind(\n+                        token::OpenDelim(delimited.delim),\n+                        span.open,\n+                    ));\n                     return first;\n                 }\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n@@ -775,7 +781,7 @@ impl FirstSets {\n                     // If the sequence contents can be empty, then the first\n                     // token could be the separator token itself.\n                     if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n-                        first.add_one_maybe(TokenTree::Token(sep.clone()));\n+                        first.add_one_maybe(TtHandle::from_token(sep.clone()));\n                     }\n \n                     assert!(first.maybe_empty);\n@@ -803,6 +809,62 @@ impl FirstSets {\n     }\n }\n \n+// Most `mbe::TokenTree`s are pre-existing in the matcher, but some are defined\n+// implicitly, such as opening/closing delimiters and sequence repetition ops.\n+// This type encapsulates both kinds. It implements `Clone` while avoiding the\n+// need for `mbe::TokenTree` to implement `Clone`.\n+#[derive(Debug)]\n+enum TtHandle<'tt> {\n+    /// This is used in most cases.\n+    TtRef(&'tt mbe::TokenTree),\n+\n+    /// This is only used for implicit token trees. The `mbe::TokenTree` *must*\n+    /// be `mbe::TokenTree::Token`. No other variants are allowed. We store an\n+    /// `mbe::TokenTree` rather than a `Token` so that `get()` can return a\n+    /// `&mbe::TokenTree`.\n+    Token(mbe::TokenTree),\n+}\n+\n+impl<'tt> TtHandle<'tt> {\n+    fn from_token(tok: Token) -> Self {\n+        TtHandle::Token(mbe::TokenTree::Token(tok))\n+    }\n+\n+    fn from_token_kind(kind: TokenKind, span: Span) -> Self {\n+        TtHandle::from_token(Token::new(kind, span))\n+    }\n+\n+    // Get a reference to a token tree.\n+    fn get(&'tt self) -> &'tt mbe::TokenTree {\n+        match self {\n+            TtHandle::TtRef(tt) => tt,\n+            TtHandle::Token(token_tt) => &token_tt,\n+        }\n+    }\n+}\n+\n+impl<'tt> PartialEq for TtHandle<'tt> {\n+    fn eq(&self, other: &TtHandle<'tt>) -> bool {\n+        self.get() == other.get()\n+    }\n+}\n+\n+impl<'tt> Clone for TtHandle<'tt> {\n+    fn clone(&self) -> Self {\n+        match self {\n+            TtHandle::TtRef(tt) => TtHandle::TtRef(tt),\n+\n+            // This variant *must* contain a `mbe::TokenTree::Token`, and not\n+            // any other variant of `mbe::TokenTree`.\n+            TtHandle::Token(mbe::TokenTree::Token(tok)) => {\n+                TtHandle::Token(mbe::TokenTree::Token(tok.clone()))\n+            }\n+\n+            _ => unreachable!(),\n+        }\n+    }\n+}\n+\n // A set of `mbe::TokenTree`s, which may include `TokenTree::Match`s\n // (for macro-by-example syntactic variables). It also carries the\n // `maybe_empty` flag; that is true if and only if the matcher can\n@@ -814,28 +876,28 @@ impl FirstSets {\n //\n // (Notably, we must allow for *-op to occur zero times.)\n #[derive(Clone, Debug)]\n-struct TokenSet {\n-    tokens: Vec<mbe::TokenTree>,\n+struct TokenSet<'tt> {\n+    tokens: Vec<TtHandle<'tt>>,\n     maybe_empty: bool,\n }\n \n-impl TokenSet {\n+impl<'tt> TokenSet<'tt> {\n     // Returns a set for the empty sequence.\n     fn empty() -> Self {\n         TokenSet { tokens: Vec::new(), maybe_empty: true }\n     }\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n-    fn singleton(tok: mbe::TokenTree) -> Self {\n-        TokenSet { tokens: vec![tok], maybe_empty: false }\n+    fn singleton(tt: TtHandle<'tt>) -> Self {\n+        TokenSet { tokens: vec![tt], maybe_empty: false }\n     }\n \n     // Changes self to be the set `{ tok }`.\n     // Since `tok` is always present, marks self as non-empty.\n-    fn replace_with(&mut self, tok: mbe::TokenTree) {\n+    fn replace_with(&mut self, tt: TtHandle<'tt>) {\n         self.tokens.clear();\n-        self.tokens.push(tok);\n+        self.tokens.push(tt);\n         self.maybe_empty = false;\n     }\n \n@@ -848,17 +910,17 @@ impl TokenSet {\n     }\n \n     // Adds `tok` to the set for `self`, marking sequence as non-empy.\n-    fn add_one(&mut self, tok: mbe::TokenTree) {\n-        if !self.tokens.contains(&tok) {\n-            self.tokens.push(tok);\n+    fn add_one(&mut self, tt: TtHandle<'tt>) {\n+        if !self.tokens.contains(&tt) {\n+            self.tokens.push(tt);\n         }\n         self.maybe_empty = false;\n     }\n \n     // Adds `tok` to the set for `self`. (Leaves `maybe_empty` flag alone.)\n-    fn add_one_maybe(&mut self, tok: mbe::TokenTree) {\n-        if !self.tokens.contains(&tok) {\n-            self.tokens.push(tok);\n+    fn add_one_maybe(&mut self, tt: TtHandle<'tt>) {\n+        if !self.tokens.contains(&tt) {\n+            self.tokens.push(tt);\n         }\n     }\n \n@@ -870,9 +932,9 @@ impl TokenSet {\n     // setting of the empty flag of `self`. If `other` is guaranteed\n     // non-empty, then `self` is marked non-empty.\n     fn add_all(&mut self, other: &Self) {\n-        for tok in &other.tokens {\n-            if !self.tokens.contains(tok) {\n-                self.tokens.push(tok.clone());\n+        for tt in &other.tokens {\n+            if !self.tokens.contains(tt) {\n+                self.tokens.push(tt.clone());\n             }\n         }\n         if !other.maybe_empty {\n@@ -892,14 +954,14 @@ impl TokenSet {\n //\n // Requires that `first_sets` is pre-computed for `matcher`;\n // see `FirstSets::new`.\n-fn check_matcher_core(\n+fn check_matcher_core<'tt>(\n     sess: &ParseSess,\n     features: &Features,\n     def: &ast::Item,\n-    first_sets: &FirstSets,\n-    matcher: &[mbe::TokenTree],\n-    follow: &TokenSet,\n-) -> TokenSet {\n+    first_sets: &FirstSets<'tt>,\n+    matcher: &'tt [mbe::TokenTree],\n+    follow: &TokenSet<'tt>,\n+) -> TokenSet<'tt> {\n     use mbe::TokenTree;\n \n     let mut last = TokenSet::empty();\n@@ -938,12 +1000,15 @@ fn check_matcher_core(\n                     // followed by anything against SUFFIX.\n                     continue 'each_token;\n                 } else {\n-                    last.replace_with(token.clone());\n+                    last.replace_with(TtHandle::TtRef(token));\n                     suffix_first = build_suffix_first();\n                 }\n             }\n             TokenTree::Delimited(span, ref d) => {\n-                let my_suffix = TokenSet::singleton(d.close_tt(span));\n+                let my_suffix = TokenSet::singleton(TtHandle::from_token_kind(\n+                    token::CloseDelim(d.delim),\n+                    span.close,\n+                ));\n                 check_matcher_core(sess, features, def, first_sets, &d.tts, &my_suffix);\n                 // don't track non NT tokens\n                 last.replace_with_irrelevant();\n@@ -967,7 +1032,7 @@ fn check_matcher_core(\n                 let mut new;\n                 let my_suffix = if let Some(sep) = &seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe(TokenTree::Token(sep.clone()));\n+                    new.add_one_maybe(TtHandle::from_token(sep.clone()));\n                     &new\n                 } else {\n                     &suffix_first\n@@ -994,9 +1059,11 @@ fn check_matcher_core(\n \n         // Now `last` holds the complete set of NT tokens that could\n         // end the sequence before SUFFIX. Check that every one works with `suffix`.\n-        for token in &last.tokens {\n-            if let TokenTree::MetaVarDecl(span, name, Some(kind)) = *token {\n+        for tt in &last.tokens {\n+            if let &TokenTree::MetaVarDecl(span, name, Some(kind)) = tt.get() {\n                 for next_token in &suffix_first.tokens {\n+                    let next_token = next_token.get();\n+\n                     // Check if the old pat is used and the next token is `|`\n                     // to warn about incompatibility with Rust 2021.\n                     // We only emit this lint if we're parsing the original"}]}