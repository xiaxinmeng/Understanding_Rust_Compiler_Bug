{"sha": "f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "node_id": "C_kwDOAAsO6NoAKGY5ZDRkMTJiNmFiOTdmYWU4YjlhNmY2MDc0NzNmZTE0OWYzOGY2YmQ", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-14T06:36:04Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-04-14T06:36:04Z"}, "message": "Auto merge of #95928 - nnethercote:rm-TokenTree-Clone, r=petrochenkov\n\nRemove `<mbe::TokenTree as Clone>`\n\n`mbe::TokenTree` doesn't really need to implement `Clone`, and getting rid of that impl leads to some speed-ups.\n\nr? `@petrochenkov`", "tree": {"sha": "e634583136462b71bb9699a7a674f4f7afabb37c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e634583136462b71bb9699a7a674f4f7afabb37c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "html_url": "https://github.com/rust-lang/rust/commit/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f387c930ee7c84357f8fa9f4c38903c00404ac46", "url": "https://api.github.com/repos/rust-lang/rust/commits/f387c930ee7c84357f8fa9f4c38903c00404ac46", "html_url": "https://github.com/rust-lang/rust/commit/f387c930ee7c84357f8fa9f4c38903c00404ac46"}, {"sha": "dd9028a8c43f6770bb93073fb9d1b161ab3f68d3", "url": "https://api.github.com/repos/rust-lang/rust/commits/dd9028a8c43f6770bb93073fb9d1b161ab3f68d3", "html_url": "https://github.com/rust-lang/rust/commit/dd9028a8c43f6770bb93073fb9d1b161ab3f68d3"}], "stats": {"total": 270, "additions": 164, "deletions": 106}, "files": [{"sha": "a5b8571fefe54f36a83558a9e362bd7c9475f729", "filename": "compiler/rustc_expand/src/mbe.rs", "status": "modified", "additions": 5, "deletions": 18, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe.rs?ref=f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "patch": "@@ -13,32 +13,19 @@ crate mod transcribe;\n use metavar_expr::MetaVarExpr;\n use rustc_ast::token::{self, NonterminalKind, Token, TokenKind};\n use rustc_ast::tokenstream::DelimSpan;\n-use rustc_data_structures::sync::Lrc;\n use rustc_span::symbol::Ident;\n use rustc_span::Span;\n \n /// Contains the sub-token-trees of a \"delimited\" token tree such as `(a b c)`. The delimiters\n /// might be `NoDelim`, but they are not represented explicitly.\n-#[derive(Clone, PartialEq, Encodable, Decodable, Debug)]\n+#[derive(PartialEq, Encodable, Decodable, Debug)]\n struct Delimited {\n     delim: token::DelimToken,\n     /// FIXME: #67062 has details about why this is sub-optimal.\n     tts: Vec<TokenTree>,\n }\n \n-impl Delimited {\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the opening delimiter.\n-    fn open_tt(&self, span: DelimSpan) -> TokenTree {\n-        TokenTree::token(token::OpenDelim(self.delim), span.open)\n-    }\n-\n-    /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n-    fn close_tt(&self, span: DelimSpan) -> TokenTree {\n-        TokenTree::token(token::CloseDelim(self.delim), span.close)\n-    }\n-}\n-\n-#[derive(Clone, PartialEq, Encodable, Decodable, Debug)]\n+#[derive(PartialEq, Encodable, Decodable, Debug)]\n struct SequenceRepetition {\n     /// The sequence of token trees\n     tts: Vec<TokenTree>,\n@@ -76,13 +63,13 @@ enum KleeneOp {\n \n /// Similar to `tokenstream::TokenTree`, except that `Sequence`, `MetaVar`, `MetaVarDecl`, and\n /// `MetaVarExpr` are \"first-class\" token trees. Useful for parsing macros.\n-#[derive(Debug, Clone, PartialEq, Encodable, Decodable)]\n+#[derive(Debug, PartialEq, Encodable, Decodable)]\n enum TokenTree {\n     Token(Token),\n     /// A delimited sequence, e.g. `($e:expr)` (RHS) or `{ $e }` (LHS).\n-    Delimited(DelimSpan, Lrc<Delimited>),\n+    Delimited(DelimSpan, Delimited),\n     /// A kleene-style repetition sequence, e.g. `$($e:expr)*` (RHS) or `$($e),*` (LHS).\n-    Sequence(DelimSpan, Lrc<SequenceRepetition>),\n+    Sequence(DelimSpan, SequenceRepetition),\n     /// e.g., `$var`.\n     MetaVar(Span, Ident),\n     /// e.g., `$var:expr`. Only appears on the LHS."}, {"sha": "74b8450f756d34321fc66c10e42f22767ccc800f", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "patch": "@@ -142,10 +142,13 @@ pub(super) fn compute_locs(sess: &ParseSess, matcher: &[TokenTree]) -> Vec<Match\n                     locs.push(MatcherLoc::Token { token: token.clone() });\n                 }\n                 TokenTree::Delimited(span, delimited) => {\n+                    let open_token = Token::new(token::OpenDelim(delimited.delim), span.open);\n+                    let close_token = Token::new(token::CloseDelim(delimited.delim), span.close);\n+\n                     locs.push(MatcherLoc::Delimited);\n-                    inner(sess, &[delimited.open_tt(*span)], locs, next_metavar, seq_depth);\n+                    locs.push(MatcherLoc::Token { token: open_token });\n                     inner(sess, &delimited.tts, locs, next_metavar, seq_depth);\n-                    inner(sess, &[delimited.close_tt(*span)], locs, next_metavar, seq_depth);\n+                    locs.push(MatcherLoc::Token { token: close_token });\n                 }\n                 TokenTree::Sequence(_, seq) => {\n                     // We can't determine `idx_first_after` and construct the final"}, {"sha": "ef174c3c45e97760559bd17db5d11e7cc704f328", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 112, "deletions": 46, "changes": 158, "blob_url": "https://github.com/rust-lang/rust/blob/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "patch": "@@ -8,13 +8,12 @@ use crate::mbe::macro_parser::{MatchedSeq, MatchedTokenTree, MatcherLoc};\n use crate::mbe::transcribe::transcribe;\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, NonterminalKind, Token, TokenKind::*};\n+use rustc_ast::token::{self, NonterminalKind, Token, TokenKind, TokenKind::*};\n use rustc_ast::tokenstream::{DelimSpan, TokenStream};\n use rustc_ast::{NodeId, DUMMY_NODE_ID};\n use rustc_ast_pretty::pprust;\n use rustc_attr::{self as attr, TransparencyError};\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Applicability, Diagnostic, DiagnosticBuilder};\n use rustc_feature::Features;\n use rustc_lint_defs::builtin::{\n@@ -263,14 +262,14 @@ fn generic_extension<'cx, 'tt>(\n \n                 // Ignore the delimiters on the RHS.\n                 let rhs = match &rhses[i] {\n-                    mbe::TokenTree::Delimited(_, delimited) => delimited.tts.to_vec(),\n+                    mbe::TokenTree::Delimited(_, delimited) => &delimited.tts,\n                     _ => cx.span_bug(sp, \"malformed macro rhs\"),\n                 };\n                 let arm_span = rhses[i].span();\n \n                 let rhs_spans = rhs.iter().map(|t| t.span()).collect::<Vec<_>>();\n                 // rhs has holes ( `$id` and `$(...)` that need filled)\n-                let mut tts = match transcribe(cx, &named_matches, rhs, transparency) {\n+                let mut tts = match transcribe(cx, &named_matches, &rhs, transparency) {\n                     Ok(tts) => tts,\n                     Err(mut err) => {\n                         err.emit();\n@@ -407,7 +406,7 @@ pub fn compile_declarative_macro(\n     let argument_gram = vec![\n         mbe::TokenTree::Sequence(\n             DelimSpan::dummy(),\n-            Lrc::new(mbe::SequenceRepetition {\n+            mbe::SequenceRepetition {\n                 tts: vec![\n                     mbe::TokenTree::MetaVarDecl(def.span, lhs_nm, tt_spec),\n                     mbe::TokenTree::token(token::FatArrow, def.span),\n@@ -419,20 +418,20 @@ pub fn compile_declarative_macro(\n                 )),\n                 kleene: mbe::KleeneToken::new(mbe::KleeneOp::OneOrMore, def.span),\n                 num_captures: 2,\n-            }),\n+            },\n         ),\n         // to phase into semicolon-termination instead of semicolon-separation\n         mbe::TokenTree::Sequence(\n             DelimSpan::dummy(),\n-            Lrc::new(mbe::SequenceRepetition {\n+            mbe::SequenceRepetition {\n                 tts: vec![mbe::TokenTree::token(\n                     if macro_rules { token::Semi } else { token::Comma },\n                     def.span,\n                 )],\n                 separator: None,\n                 kleene: mbe::KleeneToken::new(mbe::KleeneOp::ZeroOrMore, def.span),\n                 num_captures: 0,\n-            }),\n+            },\n         ),\n     ];\n     // Convert it into `MatcherLoc` form.\n@@ -658,18 +657,18 @@ fn check_matcher(\n // that do not try to inject artificial span information. My plan is\n // to try to catch such cases ahead of time and not include them in\n // the precomputed mapping.)\n-struct FirstSets {\n+struct FirstSets<'tt> {\n     // this maps each TokenTree::Sequence `$(tt ...) SEP OP` that is uniquely identified by its\n     // span in the original matcher to the First set for the inner sequence `tt ...`.\n     //\n     // If two sequences have the same span in a matcher, then map that\n     // span to None (invalidating the mapping here and forcing the code to\n     // use a slow path).\n-    first: FxHashMap<Span, Option<TokenSet>>,\n+    first: FxHashMap<Span, Option<TokenSet<'tt>>>,\n }\n \n-impl FirstSets {\n-    fn new(tts: &[mbe::TokenTree]) -> FirstSets {\n+impl<'tt> FirstSets<'tt> {\n+    fn new(tts: &'tt [mbe::TokenTree]) -> FirstSets<'tt> {\n         use mbe::TokenTree;\n \n         let mut sets = FirstSets { first: FxHashMap::default() };\n@@ -679,19 +678,22 @@ impl FirstSets {\n         // walks backward over `tts`, returning the FIRST for `tts`\n         // and updating `sets` at the same time for all sequence\n         // substructure we find within `tts`.\n-        fn build_recur(sets: &mut FirstSets, tts: &[TokenTree]) -> TokenSet {\n+        fn build_recur<'tt>(sets: &mut FirstSets<'tt>, tts: &'tt [TokenTree]) -> TokenSet<'tt> {\n             let mut first = TokenSet::empty();\n             for tt in tts.iter().rev() {\n                 match *tt {\n                     TokenTree::Token(..)\n                     | TokenTree::MetaVar(..)\n                     | TokenTree::MetaVarDecl(..)\n                     | TokenTree::MetaVarExpr(..) => {\n-                        first.replace_with(tt.clone());\n+                        first.replace_with(TtHandle::TtRef(tt));\n                     }\n                     TokenTree::Delimited(span, ref delimited) => {\n                         build_recur(sets, &delimited.tts);\n-                        first.replace_with(delimited.open_tt(span));\n+                        first.replace_with(TtHandle::from_token_kind(\n+                            token::OpenDelim(delimited.delim),\n+                            span.open,\n+                        ));\n                     }\n                     TokenTree::Sequence(sp, ref seq_rep) => {\n                         let subfirst = build_recur(sets, &seq_rep.tts);\n@@ -715,7 +717,7 @@ impl FirstSets {\n                         // token could be the separator token itself.\n \n                         if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n-                            first.add_one_maybe(TokenTree::Token(sep.clone()));\n+                            first.add_one_maybe(TtHandle::from_token(sep.clone()));\n                         }\n \n                         // Reverse scan: Sequence comes before `first`.\n@@ -741,7 +743,7 @@ impl FirstSets {\n \n     // walks forward over `tts` until all potential FIRST tokens are\n     // identified.\n-    fn first(&self, tts: &[mbe::TokenTree]) -> TokenSet {\n+    fn first(&self, tts: &'tt [mbe::TokenTree]) -> TokenSet<'tt> {\n         use mbe::TokenTree;\n \n         let mut first = TokenSet::empty();\n@@ -752,11 +754,14 @@ impl FirstSets {\n                 | TokenTree::MetaVar(..)\n                 | TokenTree::MetaVarDecl(..)\n                 | TokenTree::MetaVarExpr(..) => {\n-                    first.add_one(tt.clone());\n+                    first.add_one(TtHandle::TtRef(tt));\n                     return first;\n                 }\n                 TokenTree::Delimited(span, ref delimited) => {\n-                    first.add_one(delimited.open_tt(span));\n+                    first.add_one(TtHandle::from_token_kind(\n+                        token::OpenDelim(delimited.delim),\n+                        span.open,\n+                    ));\n                     return first;\n                 }\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n@@ -775,7 +780,7 @@ impl FirstSets {\n                     // If the sequence contents can be empty, then the first\n                     // token could be the separator token itself.\n                     if let (Some(sep), true) = (&seq_rep.separator, subfirst.maybe_empty) {\n-                        first.add_one_maybe(TokenTree::Token(sep.clone()));\n+                        first.add_one_maybe(TtHandle::from_token(sep.clone()));\n                     }\n \n                     assert!(first.maybe_empty);\n@@ -803,6 +808,62 @@ impl FirstSets {\n     }\n }\n \n+// Most `mbe::TokenTree`s are pre-existing in the matcher, but some are defined\n+// implicitly, such as opening/closing delimiters and sequence repetition ops.\n+// This type encapsulates both kinds. It implements `Clone` while avoiding the\n+// need for `mbe::TokenTree` to implement `Clone`.\n+#[derive(Debug)]\n+enum TtHandle<'tt> {\n+    /// This is used in most cases.\n+    TtRef(&'tt mbe::TokenTree),\n+\n+    /// This is only used for implicit token trees. The `mbe::TokenTree` *must*\n+    /// be `mbe::TokenTree::Token`. No other variants are allowed. We store an\n+    /// `mbe::TokenTree` rather than a `Token` so that `get()` can return a\n+    /// `&mbe::TokenTree`.\n+    Token(mbe::TokenTree),\n+}\n+\n+impl<'tt> TtHandle<'tt> {\n+    fn from_token(tok: Token) -> Self {\n+        TtHandle::Token(mbe::TokenTree::Token(tok))\n+    }\n+\n+    fn from_token_kind(kind: TokenKind, span: Span) -> Self {\n+        TtHandle::from_token(Token::new(kind, span))\n+    }\n+\n+    // Get a reference to a token tree.\n+    fn get(&'tt self) -> &'tt mbe::TokenTree {\n+        match self {\n+            TtHandle::TtRef(tt) => tt,\n+            TtHandle::Token(token_tt) => &token_tt,\n+        }\n+    }\n+}\n+\n+impl<'tt> PartialEq for TtHandle<'tt> {\n+    fn eq(&self, other: &TtHandle<'tt>) -> bool {\n+        self.get() == other.get()\n+    }\n+}\n+\n+impl<'tt> Clone for TtHandle<'tt> {\n+    fn clone(&self) -> Self {\n+        match self {\n+            TtHandle::TtRef(tt) => TtHandle::TtRef(tt),\n+\n+            // This variant *must* contain a `mbe::TokenTree::Token`, and not\n+            // any other variant of `mbe::TokenTree`.\n+            TtHandle::Token(mbe::TokenTree::Token(tok)) => {\n+                TtHandle::Token(mbe::TokenTree::Token(tok.clone()))\n+            }\n+\n+            _ => unreachable!(),\n+        }\n+    }\n+}\n+\n // A set of `mbe::TokenTree`s, which may include `TokenTree::Match`s\n // (for macro-by-example syntactic variables). It also carries the\n // `maybe_empty` flag; that is true if and only if the matcher can\n@@ -814,28 +875,28 @@ impl FirstSets {\n //\n // (Notably, we must allow for *-op to occur zero times.)\n #[derive(Clone, Debug)]\n-struct TokenSet {\n-    tokens: Vec<mbe::TokenTree>,\n+struct TokenSet<'tt> {\n+    tokens: Vec<TtHandle<'tt>>,\n     maybe_empty: bool,\n }\n \n-impl TokenSet {\n+impl<'tt> TokenSet<'tt> {\n     // Returns a set for the empty sequence.\n     fn empty() -> Self {\n         TokenSet { tokens: Vec::new(), maybe_empty: true }\n     }\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n-    fn singleton(tok: mbe::TokenTree) -> Self {\n-        TokenSet { tokens: vec![tok], maybe_empty: false }\n+    fn singleton(tt: TtHandle<'tt>) -> Self {\n+        TokenSet { tokens: vec![tt], maybe_empty: false }\n     }\n \n     // Changes self to be the set `{ tok }`.\n     // Since `tok` is always present, marks self as non-empty.\n-    fn replace_with(&mut self, tok: mbe::TokenTree) {\n+    fn replace_with(&mut self, tt: TtHandle<'tt>) {\n         self.tokens.clear();\n-        self.tokens.push(tok);\n+        self.tokens.push(tt);\n         self.maybe_empty = false;\n     }\n \n@@ -848,17 +909,17 @@ impl TokenSet {\n     }\n \n     // Adds `tok` to the set for `self`, marking sequence as non-empy.\n-    fn add_one(&mut self, tok: mbe::TokenTree) {\n-        if !self.tokens.contains(&tok) {\n-            self.tokens.push(tok);\n+    fn add_one(&mut self, tt: TtHandle<'tt>) {\n+        if !self.tokens.contains(&tt) {\n+            self.tokens.push(tt);\n         }\n         self.maybe_empty = false;\n     }\n \n     // Adds `tok` to the set for `self`. (Leaves `maybe_empty` flag alone.)\n-    fn add_one_maybe(&mut self, tok: mbe::TokenTree) {\n-        if !self.tokens.contains(&tok) {\n-            self.tokens.push(tok);\n+    fn add_one_maybe(&mut self, tt: TtHandle<'tt>) {\n+        if !self.tokens.contains(&tt) {\n+            self.tokens.push(tt);\n         }\n     }\n \n@@ -870,9 +931,9 @@ impl TokenSet {\n     // setting of the empty flag of `self`. If `other` is guaranteed\n     // non-empty, then `self` is marked non-empty.\n     fn add_all(&mut self, other: &Self) {\n-        for tok in &other.tokens {\n-            if !self.tokens.contains(tok) {\n-                self.tokens.push(tok.clone());\n+        for tt in &other.tokens {\n+            if !self.tokens.contains(tt) {\n+                self.tokens.push(tt.clone());\n             }\n         }\n         if !other.maybe_empty {\n@@ -892,14 +953,14 @@ impl TokenSet {\n //\n // Requires that `first_sets` is pre-computed for `matcher`;\n // see `FirstSets::new`.\n-fn check_matcher_core(\n+fn check_matcher_core<'tt>(\n     sess: &ParseSess,\n     features: &Features,\n     def: &ast::Item,\n-    first_sets: &FirstSets,\n-    matcher: &[mbe::TokenTree],\n-    follow: &TokenSet,\n-) -> TokenSet {\n+    first_sets: &FirstSets<'tt>,\n+    matcher: &'tt [mbe::TokenTree],\n+    follow: &TokenSet<'tt>,\n+) -> TokenSet<'tt> {\n     use mbe::TokenTree;\n \n     let mut last = TokenSet::empty();\n@@ -938,12 +999,15 @@ fn check_matcher_core(\n                     // followed by anything against SUFFIX.\n                     continue 'each_token;\n                 } else {\n-                    last.replace_with(token.clone());\n+                    last.replace_with(TtHandle::TtRef(token));\n                     suffix_first = build_suffix_first();\n                 }\n             }\n             TokenTree::Delimited(span, ref d) => {\n-                let my_suffix = TokenSet::singleton(d.close_tt(span));\n+                let my_suffix = TokenSet::singleton(TtHandle::from_token_kind(\n+                    token::CloseDelim(d.delim),\n+                    span.close,\n+                ));\n                 check_matcher_core(sess, features, def, first_sets, &d.tts, &my_suffix);\n                 // don't track non NT tokens\n                 last.replace_with_irrelevant();\n@@ -967,7 +1031,7 @@ fn check_matcher_core(\n                 let mut new;\n                 let my_suffix = if let Some(sep) = &seq_rep.separator {\n                     new = suffix_first.clone();\n-                    new.add_one_maybe(TokenTree::Token(sep.clone()));\n+                    new.add_one_maybe(TtHandle::from_token(sep.clone()));\n                     &new\n                 } else {\n                     &suffix_first\n@@ -994,9 +1058,11 @@ fn check_matcher_core(\n \n         // Now `last` holds the complete set of NT tokens that could\n         // end the sequence before SUFFIX. Check that every one works with `suffix`.\n-        for token in &last.tokens {\n-            if let TokenTree::MetaVarDecl(span, name, Some(kind)) = *token {\n+        for tt in &last.tokens {\n+            if let &TokenTree::MetaVarDecl(span, name, Some(kind)) = tt.get() {\n                 for next_token in &suffix_first.tokens {\n+                    let next_token = next_token.get();\n+\n                     // Check if the old pat is used and the next token is `|`\n                     // to warn about incompatibility with Rust 2021.\n                     // We only emit this lint if we're parsing the original"}, {"sha": "0bce6967a10ddb3a495b563802ba8c3af4167ed5", "filename": "compiler/rustc_expand/src/mbe/quoted.rs", "status": "modified", "additions": 3, "deletions": 10, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs?ref=f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "patch": "@@ -11,8 +11,6 @@ use rustc_span::symbol::{kw, sym, Ident};\n use rustc_span::edition::Edition;\n use rustc_span::{Span, SyntaxContext};\n \n-use rustc_data_structures::sync::Lrc;\n-\n const VALID_FRAGMENT_NAMES_MSG: &str = \"valid fragment specifiers are \\\n                                         `ident`, `block`, `stmt`, `expr`, `pat`, `ty`, `lifetime`, \\\n                                         `literal`, `path`, `meta`, `tt`, `item` and `vis`\";\n@@ -213,12 +211,7 @@ fn parse_tree(\n                         if parsing_patterns { count_metavar_decls(&sequence) } else { 0 };\n                     TokenTree::Sequence(\n                         delim_span,\n-                        Lrc::new(SequenceRepetition {\n-                            tts: sequence,\n-                            separator,\n-                            kleene,\n-                            num_captures,\n-                        }),\n+                        SequenceRepetition { tts: sequence, separator, kleene, num_captures },\n                     )\n                 }\n \n@@ -269,10 +262,10 @@ fn parse_tree(\n         // descend into the delimited set and further parse it.\n         tokenstream::TokenTree::Delimited(span, delim, tts) => TokenTree::Delimited(\n             span,\n-            Lrc::new(Delimited {\n+            Delimited {\n                 delim,\n                 tts: parse(tts, parsing_patterns, sess, node_id, features, edition),\n-            }),\n+            },\n         ),\n     }\n }"}, {"sha": "d25f044234cf4727ff6d1b8a3b593ec12bc69a5f", "filename": "compiler/rustc_expand/src/mbe/transcribe.rs", "status": "modified", "additions": 39, "deletions": 30, "changes": 69, "blob_url": "https://github.com/rust-lang/rust/blob/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Ftranscribe.rs?ref=f9d4d12b6ab97fae8b9a6f607473fe149f38f6bd", "patch": "@@ -5,7 +5,6 @@ use rustc_ast::mut_visit::{self, MutVisitor};\n use rustc_ast::token::{self, Token, TokenKind};\n use rustc_ast::tokenstream::{DelimSpan, TokenStream, TokenTree, TreeAndSpacing};\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_data_structures::sync::Lrc;\n use rustc_errors::{pluralize, PResult};\n use rustc_errors::{DiagnosticBuilder, ErrorGuaranteed};\n use rustc_span::hygiene::{LocalExpnId, Transparency};\n@@ -27,31 +26,35 @@ impl MutVisitor for Marker {\n }\n \n /// An iterator over the token trees in a delimited token tree (`{ ... }`) or a sequence (`$(...)`).\n-enum Frame {\n-    Delimited { forest: Lrc<mbe::Delimited>, idx: usize, span: DelimSpan },\n-    Sequence { forest: Lrc<mbe::SequenceRepetition>, idx: usize, sep: Option<Token> },\n+enum Frame<'a> {\n+    Delimited {\n+        tts: &'a [mbe::TokenTree],\n+        delim_token: token::DelimToken,\n+        idx: usize,\n+        span: DelimSpan,\n+    },\n+    Sequence {\n+        tts: &'a [mbe::TokenTree],\n+        idx: usize,\n+        sep: Option<Token>,\n+    },\n }\n \n-impl Frame {\n+impl<'a> Frame<'a> {\n     /// Construct a new frame around the delimited set of tokens.\n-    fn new(tts: Vec<mbe::TokenTree>) -> Frame {\n-        let forest = Lrc::new(mbe::Delimited { delim: token::NoDelim, tts });\n-        Frame::Delimited { forest, idx: 0, span: DelimSpan::dummy() }\n+    fn new(tts: &'a [mbe::TokenTree]) -> Frame<'a> {\n+        Frame::Delimited { tts, delim_token: token::NoDelim, idx: 0, span: DelimSpan::dummy() }\n     }\n }\n \n-impl Iterator for Frame {\n-    type Item = mbe::TokenTree;\n+impl<'a> Iterator for Frame<'a> {\n+    type Item = &'a mbe::TokenTree;\n \n-    fn next(&mut self) -> Option<mbe::TokenTree> {\n-        match *self {\n-            Frame::Delimited { ref forest, ref mut idx, .. } => {\n-                let res = forest.tts.get(*idx).cloned();\n-                *idx += 1;\n-                res\n-            }\n-            Frame::Sequence { ref forest, ref mut idx, .. } => {\n-                let res = forest.tts.get(*idx).cloned();\n+    fn next(&mut self) -> Option<&'a mbe::TokenTree> {\n+        match self {\n+            Frame::Delimited { tts, ref mut idx, .. }\n+            | Frame::Sequence { tts, ref mut idx, .. } => {\n+                let res = tts.get(*idx);\n                 *idx += 1;\n                 res\n             }\n@@ -82,7 +85,7 @@ impl Iterator for Frame {\n pub(super) fn transcribe<'a>(\n     cx: &ExtCtxt<'a>,\n     interp: &FxHashMap<MacroRulesNormalizedIdent, NamedMatch>,\n-    src: Vec<mbe::TokenTree>,\n+    src: &[mbe::TokenTree],\n     transparency: Transparency,\n ) -> PResult<'a, TokenStream> {\n     // Nothing for us to transcribe...\n@@ -92,7 +95,7 @@ pub(super) fn transcribe<'a>(\n \n     // We descend into the RHS (`src`), expanding things as we go. This stack contains the things\n     // we have yet to expand/are still expanding. We start the stack off with the whole RHS.\n-    let mut stack: SmallVec<[Frame; 1]> = smallvec![Frame::new(src)];\n+    let mut stack: SmallVec<[Frame<'_>; 1]> = smallvec![Frame::new(&src)];\n \n     // As we descend in the RHS, we will need to be able to match nested sequences of matchers.\n     // `repeats` keeps track of where we are in matching at each level, with the last element being\n@@ -146,14 +149,14 @@ pub(super) fn transcribe<'a>(\n                 // We are done processing a Delimited. If this is the top-level delimited, we are\n                 // done. Otherwise, we unwind the result_stack to append what we have produced to\n                 // any previous results.\n-                Frame::Delimited { forest, span, .. } => {\n+                Frame::Delimited { delim_token, span, .. } => {\n                     if result_stack.is_empty() {\n                         // No results left to compute! We are back at the top-level.\n                         return Ok(TokenStream::new(result));\n                     }\n \n                     // Step back into the parent Delimited.\n-                    let tree = TokenTree::Delimited(span, forest.delim, TokenStream::new(result));\n+                    let tree = TokenTree::Delimited(span, delim_token, TokenStream::new(result));\n                     result = result_stack.pop().unwrap();\n                     result.push(tree.into());\n                 }\n@@ -167,7 +170,7 @@ pub(super) fn transcribe<'a>(\n             // We are descending into a sequence. We first make sure that the matchers in the RHS\n             // and the matches in `interp` have the same shape. Otherwise, either the caller or the\n             // macro writer has made a mistake.\n-            seq @ mbe::TokenTree::Sequence(..) => {\n+            seq @ mbe::TokenTree::Sequence(_, delimited) => {\n                 match lockstep_iter_size(&seq, interp, &repeats) {\n                     LockstepIterSize::Unconstrained => {\n                         return Err(cx.struct_span_err(\n@@ -214,7 +217,7 @@ pub(super) fn transcribe<'a>(\n                             stack.push(Frame::Sequence {\n                                 idx: 0,\n                                 sep: seq.separator.clone(),\n-                                forest: seq,\n+                                tts: &delimited.tts,\n                             });\n                         }\n                     }\n@@ -272,15 +275,21 @@ pub(super) fn transcribe<'a>(\n             // the previous results (from outside the Delimited).\n             mbe::TokenTree::Delimited(mut span, delimited) => {\n                 mut_visit::visit_delim_span(&mut span, &mut marker);\n-                stack.push(Frame::Delimited { forest: delimited, idx: 0, span });\n+                stack.push(Frame::Delimited {\n+                    tts: &delimited.tts,\n+                    delim_token: delimited.delim,\n+                    idx: 0,\n+                    span,\n+                });\n                 result_stack.push(mem::take(&mut result));\n             }\n \n             // Nothing much to do here. Just push the token to the result, being careful to\n             // preserve syntax context.\n             mbe::TokenTree::Token(token) => {\n-                let mut tt = TokenTree::Token(token);\n-                mut_visit::visit_tt(&mut tt, &mut marker);\n+                let mut token = token.clone();\n+                mut_visit::visit_token(&mut token, &mut marker);\n+                let tt = TokenTree::Token(token);\n                 result.push(tt.into());\n             }\n \n@@ -516,7 +525,7 @@ fn out_of_bounds_err<'a>(\n \n fn transcribe_metavar_expr<'a>(\n     cx: &ExtCtxt<'a>,\n-    expr: MetaVarExpr,\n+    expr: &MetaVarExpr,\n     interp: &FxHashMap<MacroRulesNormalizedIdent, NamedMatch>,\n     marker: &mut Marker,\n     repeats: &[(usize, usize)],\n@@ -528,7 +537,7 @@ fn transcribe_metavar_expr<'a>(\n         marker.visit_span(&mut span);\n         span\n     };\n-    match expr {\n+    match *expr {\n         MetaVarExpr::Count(original_ident, depth_opt) => {\n             let matched = matched_from_ident(cx, original_ident, interp)?;\n             let count = count_repetitions(cx, depth_opt, matched, &repeats, sp)?;"}]}