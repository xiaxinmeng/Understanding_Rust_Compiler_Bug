{"sha": "5fa22fe6f821ac3801d05f624b123dda25fde32c", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVmYTIyZmU2ZjgyMWFjMzgwMWQwNWY2MjRiMTIzZGRhMjVmZGUzMmM=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-14T15:00:52Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-02-14T15:00:52Z"}, "message": "Auto merge of #81286 - Aaron1011:collect-tokens-attrs, r=petrochenkov\n\nRequire passing an `AttrWrapper` to `collect_tokens_trailing_token`\n\nThis is a pure refactoring split out from #80689.\nIt represents the most invasive part of that PR, requiring changes in\nevery caller of `parse_outer_attributes`\n\nIn order to eagerly expand `#[cfg]` attributes while preserving the\noriginal `TokenStream`, we need to know the range of tokens that\ncorresponds to every attribute target. This is accomplished by making\n`parse_outer_attributes` return an opaque `AttrWrapper` struct. An\n`AttrWrapper` must be converted to a plain `AttrVec` by passing it to\n`collect_tokens_trailing_token`. This makes it difficult to accidentally\nconstruct an AST node with attributes without calling `collect_tokens_trailing_token`,\nsince AST nodes store an `AttrVec`, not an `AttrWrapper`.\n\nAs a result, we now call `collect_tokens_trailing_token` for attribute\ntargets which only support inert attributes, such as generic arguments\nand struct fields. Currently, the constructed `LazyTokenStream` is\nsimply discarded. Future PRs will record the token range corresponding\nto the attribute target, allowing those tokens to be removed from an\nenclosing `collect_tokens_trailing_token` call if necessary.", "tree": {"sha": "2c773140aace7b0b477a108bf12f869faf5781c9", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2c773140aace7b0b477a108bf12f869faf5781c9"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5fa22fe6f821ac3801d05f624b123dda25fde32c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5fa22fe6f821ac3801d05f624b123dda25fde32c", "html_url": "https://github.com/rust-lang/rust/commit/5fa22fe6f821ac3801d05f624b123dda25fde32c", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5fa22fe6f821ac3801d05f624b123dda25fde32c/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b86674e7cc8ac9c846ed5aca84aaefc2d0d12e4a", "url": "https://api.github.com/repos/rust-lang/rust/commits/b86674e7cc8ac9c846ed5aca84aaefc2d0d12e4a", "html_url": "https://github.com/rust-lang/rust/commit/b86674e7cc8ac9c846ed5aca84aaefc2d0d12e4a"}, {"sha": "3321d701617d5ba3ef348d9273f5fcca126d8f04", "url": "https://api.github.com/repos/rust-lang/rust/commits/3321d701617d5ba3ef348d9273f5fcca126d8f04", "html_url": "https://github.com/rust-lang/rust/commit/3321d701617d5ba3ef348d9273f5fcca126d8f04"}], "stats": {"total": 1318, "additions": 777, "deletions": 541}, "files": [{"sha": "cd0ad2b0150bec5a91f190aa07ee977e22f83ae8", "filename": "compiler/rustc_ast/src/ast.rs", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_ast%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -2975,3 +2975,18 @@ macro_rules! derive_has_tokens {\n derive_has_tokens! {\n     Item, Expr, Ty, AttrItem, Visibility, Path, Block, Pat\n }\n+\n+macro_rules! derive_has_attrs_no_tokens {\n+    ($($ty:path),*) => { $(\n+        impl HasTokens for $ty {\n+            fn finalize_tokens(&mut self, _tokens: LazyTokenStream) {}\n+        }\n+    )* }\n+}\n+\n+// These ast nodes only support inert attributes, so they don't\n+// store tokens (since nothing can observe them)\n+derive_has_attrs_no_tokens! {\n+    StructField, Arm,\n+    Field, FieldPat, Variant, Param, GenericParam\n+}"}, {"sha": "95d4a48b845ef99952660f06c82dc7ca833712d1", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,4 +1,4 @@\n-use super::{Parser, PathStyle};\n+use super::{AttrWrapper, Parser, PathStyle};\n use rustc_ast as ast;\n use rustc_ast::attr;\n use rustc_ast::token::{self, Nonterminal};\n@@ -26,7 +26,7 @@ pub(super) const DEFAULT_INNER_ATTR_FORBIDDEN: InnerAttrPolicy<'_> = InnerAttrPo\n \n impl<'a> Parser<'a> {\n     /// Parses attributes that appear before an item.\n-    pub(super) fn parse_outer_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n+    pub(super) fn parse_outer_attributes(&mut self) -> PResult<'a, AttrWrapper> {\n         let mut attrs: Vec<ast::Attribute> = Vec::new();\n         let mut just_parsed_doc_comment = false;\n         loop {\n@@ -74,7 +74,7 @@ impl<'a> Parser<'a> {\n                 break;\n             }\n         }\n-        Ok(attrs)\n+        Ok(AttrWrapper::new(attrs))\n     }\n \n     /// Matches `attribute = # ! [ meta_item ]`.\n@@ -89,7 +89,8 @@ impl<'a> Parser<'a> {\n             inner_parse_policy, self.token\n         );\n         let lo = self.token.span;\n-        self.collect_tokens(|this| {\n+        // Attributse can't have attributes of their own\n+        self.collect_tokens_no_attrs(|this| {\n             if this.eat(&token::Pound) {\n                 let style = if this.eat(&token::Not) {\n                     ast::AttrStyle::Inner\n@@ -163,7 +164,8 @@ impl<'a> Parser<'a> {\n                 let args = this.parse_attr_args()?;\n                 Ok(ast::AttrItem { path, args, tokens: None })\n             };\n-            if capture_tokens { self.collect_tokens(do_parse) } else { do_parse(self) }?\n+            // Attr items don't have attributes\n+            if capture_tokens { self.collect_tokens_no_attrs(do_parse) } else { do_parse(self) }?\n         })\n     }\n "}, {"sha": "aea7c6b42cf07801566ac1df5a421ef2a31df06f", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "added", "additions": 185, "deletions": 0, "changes": 185, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -0,0 +1,185 @@\n+use super::attr;\n+use super::{ForceCollect, Parser, TokenCursor, TrailingToken};\n+use rustc_ast::token::{self, Token, TokenKind};\n+use rustc_ast::tokenstream::{CreateTokenStream, TokenStream, TokenTree, TreeAndSpacing};\n+use rustc_ast::tokenstream::{DelimSpan, LazyTokenStream, Spacing};\n+use rustc_ast::HasTokens;\n+use rustc_ast::{self as ast};\n+use rustc_errors::PResult;\n+use rustc_span::{Span, DUMMY_SP};\n+\n+/// A wrapper type to ensure that the parser handles outer attributes correctly.\n+/// When we parse outer attributes, we need to ensure that we capture tokens\n+/// for the attribute target. This allows us to perform cfg-expansion on\n+/// a token stream before we invoke a derive proc-macro.\n+///\n+/// This wrapper prevents direct access to the underlying `Vec<ast::Attribute>`.\n+/// Parsing code can only get access to the underlying attributes\n+/// by passing an `AttrWrapper` to `collect_tokens_trailing_tokens`.\n+/// This makes it difficult to accidentally construct an AST node\n+/// (which stores a `Vec<ast::Attribute>`) without first collecting tokens.\n+///\n+/// This struct has its own module, to ensure that the parser code\n+/// cannot directly access the `attrs` field\n+#[derive(Debug, Clone)]\n+pub struct AttrWrapper {\n+    attrs: Vec<ast::Attribute>,\n+}\n+\n+impl AttrWrapper {\n+    pub fn empty() -> AttrWrapper {\n+        AttrWrapper { attrs: vec![] }\n+    }\n+    pub fn new(attrs: Vec<ast::Attribute>) -> AttrWrapper {\n+        AttrWrapper { attrs }\n+    }\n+    // FIXME: Delay span bug here?\n+    pub(crate) fn take_for_recovery(self) -> Vec<ast::Attribute> {\n+        self.attrs\n+    }\n+    pub fn is_empty(&self) -> bool {\n+        self.attrs.is_empty()\n+    }\n+}\n+\n+impl<'a> Parser<'a> {\n+    /// Records all tokens consumed by the provided callback,\n+    /// including the current token. These tokens are collected\n+    /// into a `LazyTokenStream`, and returned along with the result\n+    /// of the callback.\n+    ///\n+    /// Note: If your callback consumes an opening delimiter\n+    /// (including the case where you call `collect_tokens`\n+    /// when the current token is an opening delimeter),\n+    /// you must also consume the corresponding closing delimiter.\n+    ///\n+    /// That is, you can consume\n+    /// `something ([{ }])` or `([{}])`, but not `([{}]`\n+    ///\n+    /// This restriction shouldn't be an issue in practice,\n+    /// since this function is used to record the tokens for\n+    /// a parsed AST item, which always has matching delimiters.\n+    pub fn collect_tokens_trailing_token<R: HasTokens>(\n+        &mut self,\n+        attrs: AttrWrapper,\n+        force_collect: ForceCollect,\n+        f: impl FnOnce(&mut Self, Vec<ast::Attribute>) -> PResult<'a, (R, TrailingToken)>,\n+    ) -> PResult<'a, R> {\n+        if matches!(force_collect, ForceCollect::No) && !attr::maybe_needs_tokens(&attrs.attrs) {\n+            return Ok(f(self, attrs.attrs)?.0);\n+        }\n+        let start_token = (self.token.clone(), self.token_spacing);\n+        let cursor_snapshot = self.token_cursor.clone();\n+\n+        let (mut ret, trailing_token) = f(self, attrs.attrs)?;\n+\n+        // Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n+        // and `num_calls`, we can reconstruct the `TokenStream` seen\n+        // by the callback. This allows us to avoid producing a `TokenStream`\n+        // if it is never needed - for example, a captured `macro_rules!`\n+        // argument that is never passed to a proc macro.\n+        // In practice token stream creation happens rarely compared to\n+        // calls to `collect_tokens` (see some statistics in #78736),\n+        // so we are doing as little up-front work as possible.\n+        //\n+        // This also makes `Parser` very cheap to clone, since\n+        // there is no intermediate collection buffer to clone.\n+        #[derive(Clone)]\n+        struct LazyTokenStreamImpl {\n+            start_token: (Token, Spacing),\n+            cursor_snapshot: TokenCursor,\n+            num_calls: usize,\n+            desugar_doc_comments: bool,\n+            append_unglued_token: Option<TreeAndSpacing>,\n+        }\n+        impl CreateTokenStream for LazyTokenStreamImpl {\n+            fn create_token_stream(&self) -> TokenStream {\n+                // The token produced by the final call to `next` or `next_desugared`\n+                // was not actually consumed by the callback. The combination\n+                // of chaining the initial token and using `take` produces the desired\n+                // result - we produce an empty `TokenStream` if no calls were made,\n+                // and omit the final token otherwise.\n+                let mut cursor_snapshot = self.cursor_snapshot.clone();\n+                let tokens = std::iter::once(self.start_token.clone())\n+                    .chain((0..self.num_calls).map(|_| {\n+                        if self.desugar_doc_comments {\n+                            cursor_snapshot.next_desugared()\n+                        } else {\n+                            cursor_snapshot.next()\n+                        }\n+                    }))\n+                    .take(self.num_calls);\n+\n+                make_token_stream(tokens, self.append_unglued_token.clone())\n+            }\n+        }\n+\n+        let mut num_calls = self.token_cursor.num_next_calls - cursor_snapshot.num_next_calls;\n+        match trailing_token {\n+            TrailingToken::None => {}\n+            TrailingToken::Semi => {\n+                assert_eq!(self.token.kind, token::Semi);\n+                num_calls += 1;\n+            }\n+            TrailingToken::MaybeComma => {\n+                if self.token.kind == token::Comma {\n+                    num_calls += 1;\n+                }\n+            }\n+        }\n+\n+        let lazy_impl = LazyTokenStreamImpl {\n+            start_token,\n+            num_calls,\n+            cursor_snapshot,\n+            desugar_doc_comments: self.desugar_doc_comments,\n+            append_unglued_token: self.token_cursor.append_unglued_token.clone(),\n+        };\n+        ret.finalize_tokens(LazyTokenStream::new(lazy_impl));\n+        Ok(ret)\n+    }\n+}\n+\n+/// Converts a flattened iterator of tokens (including open and close delimiter tokens)\n+/// into a `TokenStream`, creating a `TokenTree::Delimited` for each matching pair\n+/// of open and close delims.\n+fn make_token_stream(\n+    tokens: impl Iterator<Item = (Token, Spacing)>,\n+    append_unglued_token: Option<TreeAndSpacing>,\n+) -> TokenStream {\n+    #[derive(Debug)]\n+    struct FrameData {\n+        open: Span,\n+        inner: Vec<(TokenTree, Spacing)>,\n+    }\n+    let mut stack = vec![FrameData { open: DUMMY_SP, inner: vec![] }];\n+    for (token, spacing) in tokens {\n+        match token {\n+            Token { kind: TokenKind::OpenDelim(_), span } => {\n+                stack.push(FrameData { open: span, inner: vec![] });\n+            }\n+            Token { kind: TokenKind::CloseDelim(delim), span } => {\n+                let frame_data = stack.pop().expect(\"Token stack was empty!\");\n+                let dspan = DelimSpan::from_pair(frame_data.open, span);\n+                let stream = TokenStream::new(frame_data.inner);\n+                let delimited = TokenTree::Delimited(dspan, delim, stream);\n+                stack\n+                    .last_mut()\n+                    .unwrap_or_else(|| panic!(\"Bottom token frame is missing for tokens!\"))\n+                    .inner\n+                    .push((delimited, Spacing::Alone));\n+            }\n+            token => {\n+                stack\n+                    .last_mut()\n+                    .expect(\"Bottom token frame is missing!\")\n+                    .inner\n+                    .push((TokenTree::Token(token), spacing));\n+            }\n+        }\n+    }\n+    let mut final_buf = stack.pop().expect(\"Missing final buf!\");\n+    final_buf.inner.extend(append_unglued_token);\n+    assert!(stack.is_empty(), \"Stack should be empty: final_buf={:?} stack={:?}\", final_buf, stack);\n+    TokenStream::new(final_buf.inner)\n+}"}, {"sha": "20430ece05b06b3874d98920c98296e7c0a38dd7", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 224, "deletions": 161, "changes": 385, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,7 +1,7 @@\n use super::pat::{GateOr, RecoverComma, PARAM_EXPECTED};\n use super::ty::{AllowPlus, RecoverQPath, RecoverReturnSign};\n-use super::{BlockMode, Parser, PathStyle, Restrictions, TokenType};\n-use super::{SemiColonMode, SeqSep, TokenExpectType};\n+use super::{AttrWrapper, BlockMode, ForceCollect, Parser, PathStyle, Restrictions, TokenType};\n+use super::{SemiColonMode, SeqSep, TokenExpectType, TrailingToken};\n use crate::maybe_recover_from_interpolated_ty_qpath;\n \n use rustc_ast::ptr::P;\n@@ -62,16 +62,16 @@ macro_rules! maybe_whole_expr {\n #[derive(Debug)]\n pub(super) enum LhsExpr {\n     NotYetParsed,\n-    AttributesParsed(AttrVec),\n+    AttributesParsed(AttrWrapper),\n     AlreadyParsed(P<Expr>),\n }\n \n-impl From<Option<AttrVec>> for LhsExpr {\n+impl From<Option<AttrWrapper>> for LhsExpr {\n     /// Converts `Some(attrs)` into `LhsExpr::AttributesParsed(attrs)`\n     /// and `None` into `LhsExpr::NotYetParsed`.\n     ///\n     /// This conversion does not allocate.\n-    fn from(o: Option<AttrVec>) -> Self {\n+    fn from(o: Option<AttrWrapper>) -> Self {\n         if let Some(attrs) = o { LhsExpr::AttributesParsed(attrs) } else { LhsExpr::NotYetParsed }\n     }\n }\n@@ -123,7 +123,7 @@ impl<'a> Parser<'a> {\n     pub(super) fn parse_expr_res(\n         &mut self,\n         r: Restrictions,\n-        already_parsed_attrs: Option<AttrVec>,\n+        already_parsed_attrs: Option<AttrWrapper>,\n     ) -> PResult<'a, P<Expr>> {\n         self.with_res(r, |this| this.parse_assoc_expr(already_parsed_attrs))\n     }\n@@ -133,7 +133,10 @@ impl<'a> Parser<'a> {\n     /// This parses an expression accounting for associativity and precedence of the operators in\n     /// the expression.\n     #[inline]\n-    fn parse_assoc_expr(&mut self, already_parsed_attrs: Option<AttrVec>) -> PResult<'a, P<Expr>> {\n+    fn parse_assoc_expr(\n+        &mut self,\n+        already_parsed_attrs: Option<AttrWrapper>,\n+    ) -> PResult<'a, P<Expr>> {\n         self.parse_assoc_expr_with(0, already_parsed_attrs.into())\n     }\n \n@@ -439,7 +442,7 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses prefix-forms of range notation: `..expr`, `..`, `..=expr`.\n-    fn parse_prefix_range_expr(&mut self, attrs: Option<AttrVec>) -> PResult<'a, P<Expr>> {\n+    fn parse_prefix_range_expr(&mut self, attrs: Option<AttrWrapper>) -> PResult<'a, P<Expr>> {\n         // Check for deprecated `...` syntax.\n         if self.token == token::DotDotDot {\n             self.err_dotdotdot_syntax(self.token.span);\n@@ -456,45 +459,62 @@ impl<'a> Parser<'a> {\n             _ => RangeLimits::Closed,\n         };\n         let op = AssocOp::from_token(&self.token);\n+        // FIXME: `parse_prefix_range_expr` is called when the current\n+        // token is `DotDot`, `DotDotDot`, or `DotDotEq`. If we haven't already\n+        // parsed attributes, then trying to parse them here will always fail.\n+        // We should figure out how we want attributes on range expressions to work.\n         let attrs = self.parse_or_use_outer_attributes(attrs)?;\n-        let lo = self.token.span;\n-        self.bump();\n-        let (span, opt_end) = if self.is_at_start_of_range_notation_rhs() {\n-            // RHS must be parsed with more associativity than the dots.\n-            self.parse_assoc_expr_with(op.unwrap().precedence() + 1, LhsExpr::NotYetParsed)\n-                .map(|x| (lo.to(x.span), Some(x)))?\n-        } else {\n-            (lo, None)\n-        };\n-        Ok(self.mk_expr(span, self.mk_range(None, opt_end, limits)?, attrs))\n+        self.collect_tokens_for_expr(attrs, |this, attrs| {\n+            let lo = this.token.span;\n+            this.bump();\n+            let (span, opt_end) = if this.is_at_start_of_range_notation_rhs() {\n+                // RHS must be parsed with more associativity than the dots.\n+                this.parse_assoc_expr_with(op.unwrap().precedence() + 1, LhsExpr::NotYetParsed)\n+                    .map(|x| (lo.to(x.span), Some(x)))?\n+            } else {\n+                (lo, None)\n+            };\n+            Ok(this.mk_expr(span, this.mk_range(None, opt_end, limits)?, attrs.into()))\n+        })\n     }\n \n     /// Parses a prefix-unary-operator expr.\n-    fn parse_prefix_expr(&mut self, attrs: Option<AttrVec>) -> PResult<'a, P<Expr>> {\n+    fn parse_prefix_expr(&mut self, attrs: Option<AttrWrapper>) -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(attrs)?;\n-        // FIXME: Use super::attr::maybe_needs_tokens(&attrs) once we come up\n-        // with a good way of passing `force_tokens` through from `parse_nonterminal`.\n-        // Checking !attrs.is_empty() is correct, but will cause us to unnecessarily\n-        // capture tokens in some circumstances.\n-        let needs_tokens = !attrs.is_empty();\n-        let do_parse = |this: &mut Parser<'a>| {\n-            let lo = this.token.span;\n-            // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n-            let (hi, ex) = match this.token.uninterpolate().kind {\n-                token::Not => this.parse_unary_expr(lo, UnOp::Not), // `!expr`\n-                token::Tilde => this.recover_tilde_expr(lo),        // `~expr`\n-                token::BinOp(token::Minus) => this.parse_unary_expr(lo, UnOp::Neg), // `-expr`\n-                token::BinOp(token::Star) => this.parse_unary_expr(lo, UnOp::Deref), // `*expr`\n-                token::BinOp(token::And) | token::AndAnd => this.parse_borrow_expr(lo),\n-                token::Ident(..) if this.token.is_keyword(kw::Box) => this.parse_box_expr(lo),\n-                token::Ident(..) if this.is_mistaken_not_ident_negation() => {\n-                    this.recover_not_expr(lo)\n-                }\n-                _ => return this.parse_dot_or_call_expr(Some(attrs)),\n-            }?;\n-            Ok(this.mk_expr(lo.to(hi), ex, attrs))\n-        };\n-        if needs_tokens { self.collect_tokens(do_parse) } else { do_parse(self) }\n+        let lo = self.token.span;\n+\n+        macro_rules! make_it {\n+            ($this:ident, $attrs:expr, |this, _| $body:expr) => {\n+                $this.collect_tokens_for_expr($attrs, |$this, attrs| {\n+                    let (hi, ex) = $body?;\n+                    Ok($this.mk_expr(lo.to(hi), ex, attrs.into()))\n+                })\n+            };\n+        }\n+\n+        let this = self;\n+\n+        // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n+        match this.token.uninterpolate().kind {\n+            token::Not => make_it!(this, attrs, |this, _| this.parse_unary_expr(lo, UnOp::Not)), // `!expr`\n+            token::Tilde => make_it!(this, attrs, |this, _| this.recover_tilde_expr(lo)), // `~expr`\n+            token::BinOp(token::Minus) => {\n+                make_it!(this, attrs, |this, _| this.parse_unary_expr(lo, UnOp::Neg))\n+            } // `-expr`\n+            token::BinOp(token::Star) => {\n+                make_it!(this, attrs, |this, _| this.parse_unary_expr(lo, UnOp::Deref))\n+            } // `*expr`\n+            token::BinOp(token::And) | token::AndAnd => {\n+                make_it!(this, attrs, |this, _| this.parse_borrow_expr(lo))\n+            }\n+            token::Ident(..) if this.token.is_keyword(kw::Box) => {\n+                make_it!(this, attrs, |this, _| this.parse_box_expr(lo))\n+            }\n+            token::Ident(..) if this.is_mistaken_not_ident_negation() => {\n+                make_it!(this, attrs, |this, _| this.recover_not_expr(lo))\n+            }\n+            _ => return this.parse_dot_or_call_expr(Some(attrs.into())),\n+        }\n     }\n \n     fn parse_prefix_expr_common(&mut self, lo: Span) -> PResult<'a, (Span, P<Expr>)> {\n@@ -805,26 +825,28 @@ impl<'a> Parser<'a> {\n     }\n \n     /// Parses `a.b` or `a(13)` or `a[4]` or just `a`.\n-    fn parse_dot_or_call_expr(&mut self, attrs: Option<AttrVec>) -> PResult<'a, P<Expr>> {\n+    fn parse_dot_or_call_expr(&mut self, attrs: Option<AttrWrapper>) -> PResult<'a, P<Expr>> {\n         let attrs = self.parse_or_use_outer_attributes(attrs)?;\n-        let base = self.parse_bottom_expr();\n-        let (span, base) = self.interpolated_or_expr_span(base)?;\n-        self.parse_dot_or_call_expr_with(base, span, attrs)\n+        self.collect_tokens_for_expr(attrs, |this, attrs| {\n+            let base = this.parse_bottom_expr();\n+            let (span, base) = this.interpolated_or_expr_span(base)?;\n+            this.parse_dot_or_call_expr_with(base, span, attrs)\n+        })\n     }\n \n     pub(super) fn parse_dot_or_call_expr_with(\n         &mut self,\n         e0: P<Expr>,\n         lo: Span,\n-        mut attrs: AttrVec,\n+        mut attrs: Vec<ast::Attribute>,\n     ) -> PResult<'a, P<Expr>> {\n         // Stitch the list of outer attributes onto the return value.\n         // A little bit ugly, but the best way given the current code\n         // structure\n         self.parse_dot_or_call_expr_with_(e0, lo).map(|expr| {\n             expr.map(|mut expr| {\n                 attrs.extend::<Vec<_>>(expr.attrs.into());\n-                expr.attrs = attrs;\n+                expr.attrs = attrs.into();\n                 expr\n             })\n         })\n@@ -1703,19 +1725,25 @@ impl<'a> Parser<'a> {\n     fn parse_fn_block_param(&mut self) -> PResult<'a, Param> {\n         let lo = self.token.span;\n         let attrs = self.parse_outer_attributes()?;\n-        let pat = self.parse_pat(PARAM_EXPECTED)?;\n-        let ty = if self.eat(&token::Colon) {\n-            self.parse_ty()?\n-        } else {\n-            self.mk_ty(self.prev_token.span, TyKind::Infer)\n-        };\n-        Ok(Param {\n-            attrs: attrs.into(),\n-            ty,\n-            pat,\n-            span: lo.to(self.token.span),\n-            id: DUMMY_NODE_ID,\n-            is_placeholder: false,\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            let pat = this.parse_pat(PARAM_EXPECTED)?;\n+            let ty = if this.eat(&token::Colon) {\n+                this.parse_ty()?\n+            } else {\n+                this.mk_ty(this.prev_token.span, TyKind::Infer)\n+            };\n+\n+            Ok((\n+                Param {\n+                    attrs: attrs.into(),\n+                    ty,\n+                    pat,\n+                    span: lo.to(this.token.span),\n+                    id: DUMMY_NODE_ID,\n+                    is_placeholder: false,\n+                },\n+                TrailingToken::MaybeComma,\n+            ))\n         })\n     }\n \n@@ -1731,7 +1759,7 @@ impl<'a> Parser<'a> {\n         let thn = if self.eat_keyword(kw::Else) || !cond.returns() {\n             self.error_missing_if_cond(lo, cond.span)\n         } else {\n-            let attrs = self.parse_outer_attributes()?; // For recovery.\n+            let attrs = self.parse_outer_attributes()?.take_for_recovery(); // For recovery.\n             let not_block = self.token != token::OpenDelim(token::Brace);\n             let block = self.parse_block().map_err(|mut err| {\n                 if not_block {\n@@ -1788,7 +1816,7 @@ impl<'a> Parser<'a> {\n     /// Parses an `else { ... }` expression (`else` token already eaten).\n     fn parse_else_expr(&mut self) -> PResult<'a, P<Expr>> {\n         let ctx_span = self.prev_token.span; // `else`\n-        let attrs = self.parse_outer_attributes()?; // For recovery.\n+        let attrs = self.parse_outer_attributes()?.take_for_recovery(); // For recovery.\n         let expr = if self.eat_keyword(kw::If) {\n             self.parse_if_expr(AttrVec::new())?\n         } else {\n@@ -1947,85 +1975,91 @@ impl<'a> Parser<'a> {\n \n     pub(super) fn parse_arm(&mut self) -> PResult<'a, Arm> {\n         let attrs = self.parse_outer_attributes()?;\n-        let lo = self.token.span;\n-        let pat = self.parse_top_pat(GateOr::No, RecoverComma::Yes)?;\n-        let guard = if self.eat_keyword(kw::If) {\n-            let if_span = self.prev_token.span;\n-            let cond = self.parse_expr()?;\n-            if let ExprKind::Let(..) = cond.kind {\n-                // Remove the last feature gating of a `let` expression since it's stable.\n-                self.sess.gated_spans.ungate_last(sym::let_chains, cond.span);\n-                let span = if_span.to(cond.span);\n-                self.sess.gated_spans.gate(sym::if_let_guard, span);\n-            }\n-            Some(cond)\n-        } else {\n-            None\n-        };\n-        let arrow_span = self.token.span;\n-        self.expect(&token::FatArrow)?;\n-        let arm_start_span = self.token.span;\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            let lo = this.token.span;\n+            let pat = this.parse_top_pat(GateOr::No, RecoverComma::Yes)?;\n+            let guard = if this.eat_keyword(kw::If) {\n+                let if_span = this.prev_token.span;\n+                let cond = this.parse_expr()?;\n+                if let ExprKind::Let(..) = cond.kind {\n+                    // Remove the last feature gating of a `let` expression since it's stable.\n+                    this.sess.gated_spans.ungate_last(sym::let_chains, cond.span);\n+                    let span = if_span.to(cond.span);\n+                    this.sess.gated_spans.gate(sym::if_let_guard, span);\n+                }\n+                Some(cond)\n+            } else {\n+                None\n+            };\n+            let arrow_span = this.token.span;\n+            this.expect(&token::FatArrow)?;\n+            let arm_start_span = this.token.span;\n \n-        let expr = self.parse_expr_res(Restrictions::STMT_EXPR, None).map_err(|mut err| {\n-            err.span_label(arrow_span, \"while parsing the `match` arm starting here\");\n-            err\n-        })?;\n+            let expr = this.parse_expr_res(Restrictions::STMT_EXPR, None).map_err(|mut err| {\n+                err.span_label(arrow_span, \"while parsing the `match` arm starting here\");\n+                err\n+            })?;\n \n-        let require_comma = classify::expr_requires_semi_to_be_stmt(&expr)\n-            && self.token != token::CloseDelim(token::Brace);\n-\n-        let hi = self.prev_token.span;\n-\n-        if require_comma {\n-            let sm = self.sess.source_map();\n-            self.expect_one_of(&[token::Comma], &[token::CloseDelim(token::Brace)]).map_err(\n-                |mut err| {\n-                    match (sm.span_to_lines(expr.span), sm.span_to_lines(arm_start_span)) {\n-                        (Ok(ref expr_lines), Ok(ref arm_start_lines))\n-                            if arm_start_lines.lines[0].end_col == expr_lines.lines[0].end_col\n-                                && expr_lines.lines.len() == 2\n-                                && self.token == token::FatArrow =>\n-                        {\n-                            // We check whether there's any trailing code in the parse span,\n-                            // if there isn't, we very likely have the following:\n-                            //\n-                            // X |     &Y => \"y\"\n-                            //   |        --    - missing comma\n-                            //   |        |\n-                            //   |        arrow_span\n-                            // X |     &X => \"x\"\n-                            //   |      - ^^ self.token.span\n-                            //   |      |\n-                            //   |      parsed until here as `\"y\" & X`\n-                            err.span_suggestion_short(\n-                                arm_start_span.shrink_to_hi(),\n-                                \"missing a comma here to end this `match` arm\",\n-                                \",\".to_owned(),\n-                                Applicability::MachineApplicable,\n-                            );\n-                        }\n-                        _ => {\n-                            err.span_label(\n-                                arrow_span,\n-                                \"while parsing the `match` arm starting here\",\n-                            );\n+            let require_comma = classify::expr_requires_semi_to_be_stmt(&expr)\n+                && this.token != token::CloseDelim(token::Brace);\n+\n+            let hi = this.prev_token.span;\n+\n+            if require_comma {\n+                let sm = this.sess.source_map();\n+                this.expect_one_of(&[token::Comma], &[token::CloseDelim(token::Brace)]).map_err(\n+                    |mut err| {\n+                        match (sm.span_to_lines(expr.span), sm.span_to_lines(arm_start_span)) {\n+                            (Ok(ref expr_lines), Ok(ref arm_start_lines))\n+                                if arm_start_lines.lines[0].end_col\n+                                    == expr_lines.lines[0].end_col\n+                                    && expr_lines.lines.len() == 2\n+                                    && this.token == token::FatArrow =>\n+                            {\n+                                // We check whether there's any trailing code in the parse span,\n+                                // if there isn't, we very likely have the following:\n+                                //\n+                                // X |     &Y => \"y\"\n+                                //   |        --    - missing comma\n+                                //   |        |\n+                                //   |        arrow_span\n+                                // X |     &X => \"x\"\n+                                //   |      - ^^ self.token.span\n+                                //   |      |\n+                                //   |      parsed until here as `\"y\" & X`\n+                                err.span_suggestion_short(\n+                                    arm_start_span.shrink_to_hi(),\n+                                    \"missing a comma here to end this `match` arm\",\n+                                    \",\".to_owned(),\n+                                    Applicability::MachineApplicable,\n+                                );\n+                            }\n+                            _ => {\n+                                err.span_label(\n+                                    arrow_span,\n+                                    \"while parsing the `match` arm starting here\",\n+                                );\n+                            }\n                         }\n-                    }\n-                    err\n-                },\n-            )?;\n-        } else {\n-            self.eat(&token::Comma);\n-        }\n+                        err\n+                    },\n+                )?;\n+            } else {\n+                this.eat(&token::Comma);\n+            }\n \n-        Ok(ast::Arm {\n-            attrs,\n-            pat,\n-            guard,\n-            body: expr,\n-            span: lo.to(hi),\n-            id: DUMMY_NODE_ID,\n-            is_placeholder: false,\n+            Ok((\n+                ast::Arm {\n+                    attrs,\n+                    pat,\n+                    guard,\n+                    body: expr,\n+                    span: lo.to(hi),\n+                    id: DUMMY_NODE_ID,\n+                    is_placeholder: false,\n+                },\n+                TrailingToken::None,\n+            ))\n         })\n     }\n \n@@ -2274,30 +2308,36 @@ impl<'a> Parser<'a> {\n \n     /// Parses `ident (COLON expr)?`.\n     fn parse_field(&mut self) -> PResult<'a, Field> {\n-        let attrs = self.parse_outer_attributes()?.into();\n-        let lo = self.token.span;\n+        let attrs = self.parse_outer_attributes()?;\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            let lo = this.token.span;\n \n-        // Check if a colon exists one ahead. This means we're parsing a fieldname.\n-        let is_shorthand = !self.look_ahead(1, |t| t == &token::Colon || t == &token::Eq);\n-        let (ident, expr) = if is_shorthand {\n-            // Mimic `x: x` for the `x` field shorthand.\n-            let ident = self.parse_ident_common(false)?;\n-            let path = ast::Path::from_ident(ident);\n-            (ident, self.mk_expr(ident.span, ExprKind::Path(None, path), AttrVec::new()))\n-        } else {\n-            let ident = self.parse_field_name()?;\n-            self.error_on_eq_field_init(ident);\n-            self.bump(); // `:`\n-            (ident, self.parse_expr()?)\n-        };\n-        Ok(ast::Field {\n-            ident,\n-            span: lo.to(expr.span),\n-            expr,\n-            is_shorthand,\n-            attrs,\n-            id: DUMMY_NODE_ID,\n-            is_placeholder: false,\n+            // Check if a colon exists one ahead. This means we're parsing a fieldname.\n+            let is_shorthand = !this.look_ahead(1, |t| t == &token::Colon || t == &token::Eq);\n+            let (ident, expr) = if is_shorthand {\n+                // Mimic `x: x` for the `x` field shorthand.\n+                let ident = this.parse_ident_common(false)?;\n+                let path = ast::Path::from_ident(ident);\n+                (ident, this.mk_expr(ident.span, ExprKind::Path(None, path), AttrVec::new()))\n+            } else {\n+                let ident = this.parse_field_name()?;\n+                this.error_on_eq_field_init(ident);\n+                this.bump(); // `:`\n+                (ident, this.parse_expr()?)\n+            };\n+\n+            Ok((\n+                ast::Field {\n+                    ident,\n+                    span: lo.to(expr.span),\n+                    expr,\n+                    is_shorthand,\n+                    attrs: attrs.into(),\n+                    id: DUMMY_NODE_ID,\n+                    is_placeholder: false,\n+                },\n+                TrailingToken::MaybeComma,\n+            ))\n         })\n     }\n \n@@ -2405,4 +2445,27 @@ impl<'a> Parser<'a> {\n             .map_or(lhs_span, |a| a.span)\n             .to(rhs_span)\n     }\n+\n+    fn collect_tokens_for_expr(\n+        &mut self,\n+        attrs: AttrWrapper,\n+        f: impl FnOnce(&mut Self, Vec<ast::Attribute>) -> PResult<'a, P<Expr>>,\n+    ) -> PResult<'a, P<Expr>> {\n+        // FIXME - come up with a nice way to properly forward `ForceCollect`from\n+        // the nonterminal parsing code. TThis approach iscorrect, but will cause\n+        // us to unnecessarily capture tokens for exprs that have only builtin\n+        // attributes. Revisit this before #![feature(stmt_expr_attributes)] is stabilized\n+        let force_collect = if attrs.is_empty() { ForceCollect::No } else { ForceCollect::Yes };\n+        self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n+            let res = f(this, attrs)?;\n+            let trailing = if this.restrictions.contains(Restrictions::STMT_EXPR)\n+                && this.token.kind == token::Semi\n+            {\n+                TrailingToken::Semi\n+            } else {\n+                TrailingToken::None\n+            };\n+            Ok((res, trailing))\n+        })\n+    }\n }"}, {"sha": "f175c5b50b3978b9e131357455f76398122cfcdf", "filename": "compiler/rustc_parse/src/parser/generics.rs", "status": "modified", "additions": 80, "deletions": 59, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fgenerics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fgenerics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fgenerics.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,4 +1,4 @@\n-use super::Parser;\n+use super::{ForceCollect, Parser, TrailingToken};\n \n use rustc_ast::token;\n use rustc_ast::{\n@@ -84,68 +84,89 @@ impl<'a> Parser<'a> {\n     /// a trailing comma and erroneous trailing attributes.\n     pub(super) fn parse_generic_params(&mut self) -> PResult<'a, Vec<ast::GenericParam>> {\n         let mut params = Vec::new();\n-        loop {\n+        let mut done = false;\n+        while !done {\n             let attrs = self.parse_outer_attributes()?;\n-            if self.check_lifetime() {\n-                let lifetime = self.expect_lifetime();\n-                // Parse lifetime parameter.\n-                let bounds =\n-                    if self.eat(&token::Colon) { self.parse_lt_param_bounds() } else { Vec::new() };\n-                params.push(ast::GenericParam {\n-                    ident: lifetime.ident,\n-                    id: lifetime.id,\n-                    attrs: attrs.into(),\n-                    bounds,\n-                    kind: ast::GenericParamKind::Lifetime,\n-                    is_placeholder: false,\n-                });\n-            } else if self.check_keyword(kw::Const) {\n-                // Parse const parameter.\n-                params.push(self.parse_const_param(attrs)?);\n-            } else if self.check_ident() {\n-                // Parse type parameter.\n-                params.push(self.parse_ty_param(attrs)?);\n-            } else if self.token.can_begin_type() {\n-                // Trying to write an associated type bound? (#26271)\n-                let snapshot = self.clone();\n-                match self.parse_ty_where_predicate() {\n-                    Ok(where_predicate) => {\n-                        self.struct_span_err(\n-                            where_predicate.span(),\n-                            \"bounds on associated types do not belong here\",\n-                        )\n-                        .span_label(where_predicate.span(), \"belongs in `where` clause\")\n-                        .emit();\n-                    }\n-                    Err(mut err) => {\n-                        err.cancel();\n-                        *self = snapshot;\n-                        break;\n-                    }\n-                }\n-            } else {\n-                // Check for trailing attributes and stop parsing.\n-                if !attrs.is_empty() {\n-                    if !params.is_empty() {\n-                        self.struct_span_err(\n-                            attrs[0].span,\n-                            \"trailing attribute after generic parameter\",\n-                        )\n-                        .span_label(attrs[0].span, \"attributes must go before parameters\")\n-                        .emit();\n+            let param =\n+                self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+                    let param = if this.check_lifetime() {\n+                        let lifetime = this.expect_lifetime();\n+                        // Parse lifetime parameter.\n+                        let bounds = if this.eat(&token::Colon) {\n+                            this.parse_lt_param_bounds()\n+                        } else {\n+                            Vec::new()\n+                        };\n+                        Some(ast::GenericParam {\n+                            ident: lifetime.ident,\n+                            id: lifetime.id,\n+                            attrs: attrs.into(),\n+                            bounds,\n+                            kind: ast::GenericParamKind::Lifetime,\n+                            is_placeholder: false,\n+                        })\n+                    } else if this.check_keyword(kw::Const) {\n+                        // Parse const parameter.\n+                        Some(this.parse_const_param(attrs)?)\n+                    } else if this.check_ident() {\n+                        // Parse type parameter.\n+                        Some(this.parse_ty_param(attrs)?)\n+                    } else if this.token.can_begin_type() {\n+                        // Trying to write an associated type bound? (#26271)\n+                        let snapshot = this.clone();\n+                        match this.parse_ty_where_predicate() {\n+                            Ok(where_predicate) => {\n+                                this.struct_span_err(\n+                                    where_predicate.span(),\n+                                    \"bounds on associated types do not belong here\",\n+                                )\n+                                .span_label(where_predicate.span(), \"belongs in `where` clause\")\n+                                .emit();\n+                                // FIXME - try to continue parsing other generics?\n+                                return Ok((None, TrailingToken::None));\n+                            }\n+                            Err(mut err) => {\n+                                err.cancel();\n+                                // FIXME - maybe we should overwrite 'self' outside of `collect_tokens`?\n+                                *this = snapshot;\n+                                return Ok((None, TrailingToken::None));\n+                            }\n+                        }\n                     } else {\n-                        self.struct_span_err(attrs[0].span, \"attribute without generic parameters\")\n-                            .span_label(\n-                                attrs[0].span,\n-                                \"attributes are only permitted when preceding parameters\",\n-                            )\n-                            .emit();\n+                        // Check for trailing attributes and stop parsing.\n+                        if !attrs.is_empty() {\n+                            if !params.is_empty() {\n+                                this.struct_span_err(\n+                                    attrs[0].span,\n+                                    \"trailing attribute after generic parameter\",\n+                                )\n+                                .span_label(attrs[0].span, \"attributes must go before parameters\")\n+                                .emit();\n+                            } else {\n+                                this.struct_span_err(\n+                                    attrs[0].span,\n+                                    \"attribute without generic parameters\",\n+                                )\n+                                .span_label(\n+                                    attrs[0].span,\n+                                    \"attributes are only permitted when preceding parameters\",\n+                                )\n+                                .emit();\n+                            }\n+                        }\n+                        return Ok((None, TrailingToken::None));\n+                    };\n+\n+                    if !this.eat(&token::Comma) {\n+                        done = true;\n                     }\n-                }\n-                break;\n-            }\n+                    // We just ate the comma, so no need to use `TrailingToken`\n+                    Ok((param, TrailingToken::None))\n+                })?;\n \n-            if !self.eat(&token::Comma) {\n+            if let Some(param) = param {\n+                params.push(param);\n+            } else {\n                 break;\n             }\n         }"}, {"sha": "cdea82f50ede488610ac573bb9cbc1c18d0f79d2", "filename": "compiler/rustc_parse/src/parser/item.rs", "status": "modified", "additions": 154, "deletions": 122, "changes": 276, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,8 +1,6 @@\n use super::diagnostics::{dummy_arg, ConsumeClosingDelim, Error};\n use super::ty::{AllowPlus, RecoverQPath, RecoverReturnSign};\n-use super::{FollowedByType, ForceCollect, Parser, PathStyle, TrailingToken};\n-\n-use crate::{maybe_collect_tokens, maybe_whole};\n+use super::{AttrWrapper, FollowedByType, ForceCollect, Parser, PathStyle, TrailingToken};\n \n use rustc_ast::ast::*;\n use rustc_ast::ptr::P;\n@@ -108,25 +106,40 @@ impl<'a> Parser<'a> {\n \n     pub(super) fn parse_item_common(\n         &mut self,\n-        mut attrs: Vec<Attribute>,\n+        attrs: AttrWrapper,\n         mac_allowed: bool,\n         attrs_allowed: bool,\n         req_name: ReqName,\n         force_collect: ForceCollect,\n     ) -> PResult<'a, Option<Item>> {\n-        maybe_whole!(self, NtItem, |item| {\n-            let mut item = item;\n-            mem::swap(&mut item.attrs, &mut attrs);\n-            item.attrs.extend(attrs);\n-            Some(item.into_inner())\n-        });\n+        // Don't use `maybe_whole` so that we have precise control\n+        // over when we bump the parser\n+        if let token::Interpolated(nt) = &self.token.kind {\n+            if let token::NtItem(item) = &**nt {\n+                let item = item.clone();\n+\n+                return self.collect_tokens_trailing_token(\n+                    attrs,\n+                    force_collect,\n+                    |this, mut attrs| {\n+                        let mut item = item;\n+                        mem::swap(&mut item.attrs, &mut attrs);\n+                        item.attrs.extend(attrs);\n+                        // Bump the parser so the we capture the token::Interpolated\n+                        this.bump();\n+                        Ok((Some(item.into_inner()), TrailingToken::None))\n+                    },\n+                );\n+            }\n+        };\n \n         let mut unclosed_delims = vec![];\n-        let item = maybe_collect_tokens!(self, force_collect, &attrs, |this: &mut Self| {\n-            let item = this.parse_item_common_(attrs, mac_allowed, attrs_allowed, req_name);\n-            unclosed_delims.append(&mut this.unclosed_delims);\n-            Ok((item?, TrailingToken::None))\n-        })?;\n+        let item =\n+            self.collect_tokens_trailing_token(attrs, force_collect, |this: &mut Self, attrs| {\n+                let item = this.parse_item_common_(attrs, mac_allowed, attrs_allowed, req_name);\n+                unclosed_delims.append(&mut this.unclosed_delims);\n+                Ok((item?, TrailingToken::None))\n+            })?;\n \n         self.unclosed_delims.append(&mut unclosed_delims);\n         Ok(item)\n@@ -1109,39 +1122,45 @@ impl<'a> Parser<'a> {\n \n     fn parse_enum_variant(&mut self) -> PResult<'a, Option<Variant>> {\n         let variant_attrs = self.parse_outer_attributes()?;\n-        let vlo = self.token.span;\n-\n-        let vis = self.parse_visibility(FollowedByType::No)?;\n-        if !self.recover_nested_adt_item(kw::Enum)? {\n-            return Ok(None);\n-        }\n-        let ident = self.parse_ident()?;\n-\n-        let struct_def = if self.check(&token::OpenDelim(token::Brace)) {\n-            // Parse a struct variant.\n-            let (fields, recovered) = self.parse_record_struct_body()?;\n-            VariantData::Struct(fields, recovered)\n-        } else if self.check(&token::OpenDelim(token::Paren)) {\n-            VariantData::Tuple(self.parse_tuple_struct_body()?, DUMMY_NODE_ID)\n-        } else {\n-            VariantData::Unit(DUMMY_NODE_ID)\n-        };\n-\n-        let disr_expr =\n-            if self.eat(&token::Eq) { Some(self.parse_anon_const_expr()?) } else { None };\n+        self.collect_tokens_trailing_token(\n+            variant_attrs,\n+            ForceCollect::No,\n+            |this, variant_attrs| {\n+                let vlo = this.token.span;\n+\n+                let vis = this.parse_visibility(FollowedByType::No)?;\n+                if !this.recover_nested_adt_item(kw::Enum)? {\n+                    return Ok((None, TrailingToken::None));\n+                }\n+                let ident = this.parse_ident()?;\n+\n+                let struct_def = if this.check(&token::OpenDelim(token::Brace)) {\n+                    // Parse a struct variant.\n+                    let (fields, recovered) = this.parse_record_struct_body()?;\n+                    VariantData::Struct(fields, recovered)\n+                } else if this.check(&token::OpenDelim(token::Paren)) {\n+                    VariantData::Tuple(this.parse_tuple_struct_body()?, DUMMY_NODE_ID)\n+                } else {\n+                    VariantData::Unit(DUMMY_NODE_ID)\n+                };\n \n-        let vr = ast::Variant {\n-            ident,\n-            vis,\n-            id: DUMMY_NODE_ID,\n-            attrs: variant_attrs,\n-            data: struct_def,\n-            disr_expr,\n-            span: vlo.to(self.prev_token.span),\n-            is_placeholder: false,\n-        };\n+                let disr_expr =\n+                    if this.eat(&token::Eq) { Some(this.parse_anon_const_expr()?) } else { None };\n+\n+                let vr = ast::Variant {\n+                    ident,\n+                    vis,\n+                    id: DUMMY_NODE_ID,\n+                    attrs: variant_attrs,\n+                    data: struct_def,\n+                    disr_expr,\n+                    span: vlo.to(this.prev_token.span),\n+                    is_placeholder: false,\n+                };\n \n-        Ok(Some(vr))\n+                Ok((Some(vr), TrailingToken::MaybeComma))\n+            },\n+        )\n     }\n \n     /// Parses `struct Foo { ... }`.\n@@ -1262,17 +1281,23 @@ impl<'a> Parser<'a> {\n         // Unit like structs are handled in parse_item_struct function\n         self.parse_paren_comma_seq(|p| {\n             let attrs = p.parse_outer_attributes()?;\n-            let lo = p.token.span;\n-            let vis = p.parse_visibility(FollowedByType::Yes)?;\n-            let ty = p.parse_ty()?;\n-            Ok(StructField {\n-                span: lo.to(ty.span),\n-                vis,\n-                ident: None,\n-                id: DUMMY_NODE_ID,\n-                ty,\n-                attrs,\n-                is_placeholder: false,\n+            p.collect_tokens_trailing_token(attrs, ForceCollect::No, |p, attrs| {\n+                let lo = p.token.span;\n+                let vis = p.parse_visibility(FollowedByType::Yes)?;\n+                let ty = p.parse_ty()?;\n+\n+                Ok((\n+                    StructField {\n+                        span: lo.to(ty.span),\n+                        vis,\n+                        ident: None,\n+                        id: DUMMY_NODE_ID,\n+                        ty,\n+                        attrs,\n+                        is_placeholder: false,\n+                    },\n+                    TrailingToken::MaybeComma,\n+                ))\n             })\n         })\n         .map(|(r, _)| r)\n@@ -1281,9 +1306,11 @@ impl<'a> Parser<'a> {\n     /// Parses an element of a struct declaration.\n     fn parse_struct_decl_field(&mut self) -> PResult<'a, StructField> {\n         let attrs = self.parse_outer_attributes()?;\n-        let lo = self.token.span;\n-        let vis = self.parse_visibility(FollowedByType::No)?;\n-        self.parse_single_struct_field(lo, vis, attrs)\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            let lo = this.token.span;\n+            let vis = this.parse_visibility(FollowedByType::No)?;\n+            Ok((this.parse_single_struct_field(lo, vis, attrs)?, TrailingToken::None))\n+        })\n     }\n \n     /// Parses a structure field declaration.\n@@ -1736,74 +1763,79 @@ impl<'a> Parser<'a> {\n     fn parse_param_general(&mut self, req_name: ReqName, first_param: bool) -> PResult<'a, Param> {\n         let lo = self.token.span;\n         let attrs = self.parse_outer_attributes()?;\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            // Possibly parse `self`. Recover if we parsed it and it wasn't allowed here.\n+            if let Some(mut param) = this.parse_self_param()? {\n+                param.attrs = attrs.into();\n+                let res = if first_param { Ok(param) } else { this.recover_bad_self_param(param) };\n+                return Ok((res?, TrailingToken::None));\n+            }\n \n-        // Possibly parse `self`. Recover if we parsed it and it wasn't allowed here.\n-        if let Some(mut param) = self.parse_self_param()? {\n-            param.attrs = attrs.into();\n-            return if first_param { Ok(param) } else { self.recover_bad_self_param(param) };\n-        }\n-\n-        let is_name_required = match self.token.kind {\n-            token::DotDotDot => false,\n-            _ => req_name(self.token.span.edition()),\n-        };\n-        let (pat, ty) = if is_name_required || self.is_named_param() {\n-            debug!(\"parse_param_general parse_pat (is_name_required:{})\", is_name_required);\n+            let is_name_required = match this.token.kind {\n+                token::DotDotDot => false,\n+                _ => req_name(this.token.span.edition()),\n+            };\n+            let (pat, ty) = if is_name_required || this.is_named_param() {\n+                debug!(\"parse_param_general parse_pat (is_name_required:{})\", is_name_required);\n+\n+                let pat = this.parse_fn_param_pat()?;\n+                if let Err(mut err) = this.expect(&token::Colon) {\n+                    return if let Some(ident) =\n+                        this.parameter_without_type(&mut err, pat, is_name_required, first_param)\n+                    {\n+                        err.emit();\n+                        Ok((dummy_arg(ident), TrailingToken::None))\n+                    } else {\n+                        Err(err)\n+                    };\n+                }\n \n-            let pat = self.parse_fn_param_pat()?;\n-            if let Err(mut err) = self.expect(&token::Colon) {\n-                return if let Some(ident) =\n-                    self.parameter_without_type(&mut err, pat, is_name_required, first_param)\n+                this.eat_incorrect_doc_comment_for_param_type();\n+                (pat, this.parse_ty_for_param()?)\n+            } else {\n+                debug!(\"parse_param_general ident_to_pat\");\n+                let parser_snapshot_before_ty = this.clone();\n+                this.eat_incorrect_doc_comment_for_param_type();\n+                let mut ty = this.parse_ty_for_param();\n+                if ty.is_ok()\n+                    && this.token != token::Comma\n+                    && this.token != token::CloseDelim(token::Paren)\n                 {\n-                    err.emit();\n-                    Ok(dummy_arg(ident))\n-                } else {\n-                    Err(err)\n-                };\n-            }\n-\n-            self.eat_incorrect_doc_comment_for_param_type();\n-            (pat, self.parse_ty_for_param()?)\n-        } else {\n-            debug!(\"parse_param_general ident_to_pat\");\n-            let parser_snapshot_before_ty = self.clone();\n-            self.eat_incorrect_doc_comment_for_param_type();\n-            let mut ty = self.parse_ty_for_param();\n-            if ty.is_ok()\n-                && self.token != token::Comma\n-                && self.token != token::CloseDelim(token::Paren)\n-            {\n-                // This wasn't actually a type, but a pattern looking like a type,\n-                // so we are going to rollback and re-parse for recovery.\n-                ty = self.unexpected();\n-            }\n-            match ty {\n-                Ok(ty) => {\n-                    let ident = Ident::new(kw::Empty, self.prev_token.span);\n-                    let bm = BindingMode::ByValue(Mutability::Not);\n-                    let pat = self.mk_pat_ident(ty.span, bm, ident);\n-                    (pat, ty)\n+                    // This wasn't actually a type, but a pattern looking like a type,\n+                    // so we are going to rollback and re-parse for recovery.\n+                    ty = this.unexpected();\n                 }\n-                // If this is a C-variadic argument and we hit an error, return the error.\n-                Err(err) if self.token == token::DotDotDot => return Err(err),\n-                // Recover from attempting to parse the argument as a type without pattern.\n-                Err(mut err) => {\n-                    err.cancel();\n-                    *self = parser_snapshot_before_ty;\n-                    self.recover_arg_parse()?\n+                match ty {\n+                    Ok(ty) => {\n+                        let ident = Ident::new(kw::Empty, this.prev_token.span);\n+                        let bm = BindingMode::ByValue(Mutability::Not);\n+                        let pat = this.mk_pat_ident(ty.span, bm, ident);\n+                        (pat, ty)\n+                    }\n+                    // If this is a C-variadic argument and we hit an error, return the error.\n+                    Err(err) if this.token == token::DotDotDot => return Err(err),\n+                    // Recover from attempting to parse the argument as a type without pattern.\n+                    Err(mut err) => {\n+                        err.cancel();\n+                        *this = parser_snapshot_before_ty;\n+                        this.recover_arg_parse()?\n+                    }\n                 }\n-            }\n-        };\n-\n-        let span = lo.until(self.token.span);\n+            };\n \n-        Ok(Param {\n-            attrs: attrs.into(),\n-            id: ast::DUMMY_NODE_ID,\n-            is_placeholder: false,\n-            pat,\n-            span,\n-            ty,\n+            let span = lo.until(this.token.span);\n+\n+            Ok((\n+                Param {\n+                    attrs: attrs.into(),\n+                    id: ast::DUMMY_NODE_ID,\n+                    is_placeholder: false,\n+                    pat,\n+                    span,\n+                    ty,\n+                },\n+                TrailingToken::None,\n+            ))\n         })\n     }\n "}, {"sha": "18013f1250bdba70f5317434895909d5303a3bd0", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 19, "deletions": 151, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,4 +1,5 @@\n pub mod attr;\n+mod attr_wrapper;\n mod diagnostics;\n mod expr;\n mod generics;\n@@ -10,14 +11,15 @@ mod stmt;\n mod ty;\n \n use crate::lexer::UnmatchedBrace;\n+pub use attr_wrapper::AttrWrapper;\n pub use diagnostics::AttemptLocalParseRecovery;\n use diagnostics::Error;\n pub use path::PathStyle;\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, DelimToken, Token, TokenKind};\n-use rustc_ast::tokenstream::{self, DelimSpan, LazyTokenStream, Spacing};\n-use rustc_ast::tokenstream::{CreateTokenStream, TokenStream, TokenTree, TreeAndSpacing};\n+use rustc_ast::tokenstream::{self, DelimSpan, Spacing};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree, TreeAndSpacing};\n use rustc_ast::DUMMY_NODE_ID;\n use rustc_ast::{self as ast, AnonConst, AttrStyle, AttrVec, Const, CrateSugar, Extern, HasTokens};\n use rustc_ast::{Async, Expr, ExprKind, MacArgs, MacDelimiter, Mutability, StrLit, Unsafe};\n@@ -64,6 +66,9 @@ pub enum ForceCollect {\n pub enum TrailingToken {\n     None,\n     Semi,\n+    /// If the trailing token is a comma, then capture it\n+    /// Otherwise, ignore the trailing token\n+    MaybeComma,\n }\n \n /// Like `maybe_whole_expr`, but for things other than expressions.\n@@ -981,7 +986,7 @@ impl<'a> Parser<'a> {\n                     }\n \n                     // Collect tokens because they are used during lowering to HIR.\n-                    let expr = self.collect_tokens(|this| this.parse_expr())?;\n+                    let expr = self.collect_tokens_no_attrs(|this| this.parse_expr())?;\n                     let span = expr.span;\n \n                     match &expr.kind {\n@@ -1004,12 +1009,12 @@ impl<'a> Parser<'a> {\n \n     fn parse_or_use_outer_attributes(\n         &mut self,\n-        already_parsed_attrs: Option<AttrVec>,\n-    ) -> PResult<'a, AttrVec> {\n+        already_parsed_attrs: Option<AttrWrapper>,\n+    ) -> PResult<'a, AttrWrapper> {\n         if let Some(attrs) = already_parsed_attrs {\n             Ok(attrs)\n         } else {\n-            self.parse_outer_attributes().map(|a| a.into())\n+            self.parse_outer_attributes()\n         }\n     }\n \n@@ -1226,97 +1231,17 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn collect_tokens<R: HasTokens>(\n+    pub fn collect_tokens_no_attrs<R: HasTokens>(\n         &mut self,\n         f: impl FnOnce(&mut Self) -> PResult<'a, R>,\n     ) -> PResult<'a, R> {\n-        self.collect_tokens_trailing_token(|this| Ok((f(this)?, TrailingToken::None)))\n-    }\n-\n-    /// Records all tokens consumed by the provided callback,\n-    /// including the current token. These tokens are collected\n-    /// into a `LazyTokenStream`, and returned along with the result\n-    /// of the callback.\n-    ///\n-    /// Note: If your callback consumes an opening delimiter\n-    /// (including the case where you call `collect_tokens`\n-    /// when the current token is an opening delimeter),\n-    /// you must also consume the corresponding closing delimiter.\n-    ///\n-    /// That is, you can consume\n-    /// `something ([{ }])` or `([{}])`, but not `([{}]`\n-    ///\n-    /// This restriction shouldn't be an issue in practice,\n-    /// since this function is used to record the tokens for\n-    /// a parsed AST item, which always has matching delimiters.\n-    pub fn collect_tokens_trailing_token<R: HasTokens>(\n-        &mut self,\n-        f: impl FnOnce(&mut Self) -> PResult<'a, (R, TrailingToken)>,\n-    ) -> PResult<'a, R> {\n-        let start_token = (self.token.clone(), self.token_spacing);\n-        let cursor_snapshot = self.token_cursor.clone();\n-\n-        let (mut ret, trailing_token) = f(self)?;\n-\n-        // Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n-        // and `num_calls`, we can reconstruct the `TokenStream` seen\n-        // by the callback. This allows us to avoid producing a `TokenStream`\n-        // if it is never needed - for example, a captured `macro_rules!`\n-        // argument that is never passed to a proc macro.\n-        // In practice token stream creation happens rarely compared to\n-        // calls to `collect_tokens` (see some statistics in #78736),\n-        // so we are doing as little up-front work as possible.\n-        //\n-        // This also makes `Parser` very cheap to clone, since\n-        // there is no intermediate collection buffer to clone.\n-        #[derive(Clone)]\n-        struct LazyTokenStreamImpl {\n-            start_token: (Token, Spacing),\n-            cursor_snapshot: TokenCursor,\n-            num_calls: usize,\n-            desugar_doc_comments: bool,\n-            append_unglued_token: Option<TreeAndSpacing>,\n-        }\n-        impl CreateTokenStream for LazyTokenStreamImpl {\n-            fn create_token_stream(&self) -> TokenStream {\n-                // The token produced by the final call to `next` or `next_desugared`\n-                // was not actually consumed by the callback. The combination\n-                // of chaining the initial token and using `take` produces the desired\n-                // result - we produce an empty `TokenStream` if no calls were made,\n-                // and omit the final token otherwise.\n-                let mut cursor_snapshot = self.cursor_snapshot.clone();\n-                let tokens = std::iter::once(self.start_token.clone())\n-                    .chain((0..self.num_calls).map(|_| {\n-                        if self.desugar_doc_comments {\n-                            cursor_snapshot.next_desugared()\n-                        } else {\n-                            cursor_snapshot.next()\n-                        }\n-                    }))\n-                    .take(self.num_calls);\n-\n-                make_token_stream(tokens, self.append_unglued_token.clone())\n-            }\n-        }\n-\n-        let mut num_calls = self.token_cursor.num_next_calls - cursor_snapshot.num_next_calls;\n-        match trailing_token {\n-            TrailingToken::None => {}\n-            TrailingToken::Semi => {\n-                assert_eq!(self.token.kind, token::Semi);\n-                num_calls += 1;\n-            }\n-        }\n-\n-        let lazy_impl = LazyTokenStreamImpl {\n-            start_token,\n-            num_calls,\n-            cursor_snapshot,\n-            desugar_doc_comments: self.desugar_doc_comments,\n-            append_unglued_token: self.token_cursor.append_unglued_token.clone(),\n-        };\n-        ret.finalize_tokens(LazyTokenStream::new(lazy_impl));\n-        Ok(ret)\n+        // The only reason to call `collect_tokens_no_attrs` is if you want tokens, so use\n+        // `ForceCollect::Yes`\n+        self.collect_tokens_trailing_token(\n+            AttrWrapper::empty(),\n+            ForceCollect::Yes,\n+            |this, _attrs| Ok((f(this)?, TrailingToken::None)),\n+        )\n     }\n \n     /// `::{` or `::*`\n@@ -1365,60 +1290,3 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, sess: &Pa\n         }\n     }\n }\n-\n-/// Converts a flattened iterator of tokens (including open and close delimiter tokens)\n-/// into a `TokenStream`, creating a `TokenTree::Delimited` for each matching pair\n-/// of open and close delims.\n-fn make_token_stream(\n-    tokens: impl Iterator<Item = (Token, Spacing)>,\n-    append_unglued_token: Option<TreeAndSpacing>,\n-) -> TokenStream {\n-    #[derive(Debug)]\n-    struct FrameData {\n-        open: Span,\n-        inner: Vec<(TokenTree, Spacing)>,\n-    }\n-    let mut stack = vec![FrameData { open: DUMMY_SP, inner: vec![] }];\n-    for (token, spacing) in tokens {\n-        match token {\n-            Token { kind: TokenKind::OpenDelim(_), span } => {\n-                stack.push(FrameData { open: span, inner: vec![] });\n-            }\n-            Token { kind: TokenKind::CloseDelim(delim), span } => {\n-                let frame_data = stack.pop().expect(\"Token stack was empty!\");\n-                let dspan = DelimSpan::from_pair(frame_data.open, span);\n-                let stream = TokenStream::new(frame_data.inner);\n-                let delimited = TokenTree::Delimited(dspan, delim, stream);\n-                stack\n-                    .last_mut()\n-                    .unwrap_or_else(|| panic!(\"Bottom token frame is missing for tokens!\"))\n-                    .inner\n-                    .push((delimited, Spacing::Alone));\n-            }\n-            token => {\n-                stack\n-                    .last_mut()\n-                    .expect(\"Bottom token frame is missing!\")\n-                    .inner\n-                    .push((TokenTree::Token(token), spacing));\n-            }\n-        }\n-    }\n-    let mut final_buf = stack.pop().expect(\"Missing final buf!\");\n-    final_buf.inner.extend(append_unglued_token);\n-    assert!(stack.is_empty(), \"Stack should be empty: final_buf={:?} stack={:?}\", final_buf, stack);\n-    TokenStream::new(final_buf.inner)\n-}\n-\n-#[macro_export]\n-macro_rules! maybe_collect_tokens {\n-    ($self:ident, $force_collect:expr, $attrs:expr, $f:expr) => {\n-        if matches!($force_collect, ForceCollect::Yes)\n-            || $crate::parser::attr::maybe_needs_tokens($attrs)\n-        {\n-            $self.collect_tokens_trailing_token($f)\n-        } else {\n-            Ok($f($self)?.0)\n-        }\n-    };\n-}"}, {"sha": "40dd938f000e371f8d75bd71f1f79b9d80e76d17", "filename": "compiler/rustc_parse/src/parser/nonterminal.rs", "status": "modified", "additions": 34, "deletions": 10, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -108,7 +108,9 @@ impl<'a> Parser<'a> {\n                 }\n             },\n             NonterminalKind::Block => {\n-                token::NtBlock(self.collect_tokens(|this| this.parse_block())?)\n+                // While a block *expression* may have attributes (e.g. `#[my_attr] { ... }`),\n+                // the ':block' matcher does not support them\n+                token::NtBlock(self.collect_tokens_no_attrs(|this| this.parse_block())?)\n             }\n             NonterminalKind::Stmt => match self.parse_stmt(ForceCollect::Yes)? {\n                 Some(s) => token::NtStmt(s),\n@@ -117,19 +119,41 @@ impl<'a> Parser<'a> {\n                 }\n             },\n             NonterminalKind::Pat2018 { .. } | NonterminalKind::Pat2021 { .. } => {\n-                token::NtPat(self.collect_tokens(|this| match kind {\n+                token::NtPat(self.collect_tokens_no_attrs(|this| match kind {\n                     NonterminalKind::Pat2018 { .. } => this.parse_pat(None),\n                     NonterminalKind::Pat2021 { .. } => {\n                         this.parse_top_pat(GateOr::Yes, RecoverComma::No)\n                     }\n                     _ => unreachable!(),\n                 })?)\n             }\n-            NonterminalKind::Expr => token::NtExpr(self.collect_tokens(|this| this.parse_expr())?),\n+\n+            // If there are attributes present, then `parse_expr` will end up collecting tokens,\n+            // turning the outer `collect_tokens_no_attrs` into a no-op due to the already present\n+            // tokens. If there are *not* attributes present, then the outer\n+            // `collect_tokens_no_attrs` will ensure that we will end up collecting tokens for the\n+            // expressions.\n+            //\n+            // This is less efficient than it could be, since the outer `collect_tokens_no_attrs`\n+            // still needs to snapshot the `TokenCursor` before calling `parse_expr`, even when\n+            // `parse_expr` will end up collecting tokens. Ideally, this would work more like\n+            // `parse_item`, and take in a `ForceCollect` parameter. However, this would require\n+            // adding a `ForceCollect` parameter in a bunch of places in expression parsing\n+            // for little gain. If the perf impact from this turns out to be noticeable, we should\n+            // revisit this apporach.\n+            NonterminalKind::Expr => {\n+                token::NtExpr(self.collect_tokens_no_attrs(|this| this.parse_expr())?)\n+            }\n             NonterminalKind::Literal => {\n-                token::NtLiteral(self.collect_tokens(|this| this.parse_literal_maybe_minus())?)\n+                // The `:literal` matcher does not support attributes\n+                token::NtLiteral(\n+                    self.collect_tokens_no_attrs(|this| this.parse_literal_maybe_minus())?,\n+                )\n+            }\n+\n+            NonterminalKind::Ty => {\n+                token::NtTy(self.collect_tokens_no_attrs(|this| this.parse_ty())?)\n             }\n-            NonterminalKind::Ty => token::NtTy(self.collect_tokens(|this| this.parse_ty())?),\n             // this could be handled like a token, since it is one\n             NonterminalKind::Ident => {\n                 if let Some((ident, is_raw)) = get_macro_ident(&self.token) {\n@@ -141,15 +165,15 @@ impl<'a> Parser<'a> {\n                     return Err(self.struct_span_err(self.token.span, msg));\n                 }\n             }\n-            NonterminalKind::Path => {\n-                token::NtPath(self.collect_tokens(|this| this.parse_path(PathStyle::Type))?)\n-            }\n+            NonterminalKind::Path => token::NtPath(\n+                self.collect_tokens_no_attrs(|this| this.parse_path(PathStyle::Type))?,\n+            ),\n             NonterminalKind::Meta => {\n-                token::NtMeta(P(self.collect_tokens(|this| this.parse_attr_item(false))?))\n+                token::NtMeta(P(self.collect_tokens_no_attrs(|this| this.parse_attr_item(false))?))\n             }\n             NonterminalKind::TT => token::NtTT(self.parse_token_tree()),\n             NonterminalKind::Vis => token::NtVis(\n-                self.collect_tokens(|this| this.parse_visibility(FollowedByType::Yes))?,\n+                self.collect_tokens_no_attrs(|this| this.parse_visibility(FollowedByType::Yes))?,\n             ),\n             NonterminalKind::Lifetime => {\n                 if self.check_lifetime() {"}, {"sha": "317ef84742c2168cd8f9056403d5baa341ab1eec", "filename": "compiler/rustc_parse/src/parser/pat.rs", "status": "modified", "additions": 19, "deletions": 11, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fpat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fpat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fpat.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -1,4 +1,4 @@\n-use super::{Parser, PathStyle};\n+use super::{ForceCollect, Parser, PathStyle, TrailingToken};\n use crate::{maybe_recover_from_interpolated_ty_qpath, maybe_whole};\n use rustc_ast::mut_visit::{noop_visit_pat, MutVisitor};\n use rustc_ast::ptr::P;\n@@ -938,16 +938,24 @@ impl<'a> Parser<'a> {\n                 }\n             }\n \n-            fields.push(match self.parse_pat_field(lo, attrs) {\n-                Ok(field) => field,\n-                Err(err) => {\n-                    if let Some(mut delayed_err) = delayed_err {\n-                        delayed_err.emit();\n-                    }\n-                    return Err(err);\n-                }\n-            });\n-            ate_comma = self.eat(&token::Comma);\n+            let field =\n+                self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+                    let field = match this.parse_pat_field(lo, attrs) {\n+                        Ok(field) => Ok(field),\n+                        Err(err) => {\n+                            if let Some(mut delayed_err) = delayed_err.take() {\n+                                delayed_err.emit();\n+                            }\n+                            return Err(err);\n+                        }\n+                    }?;\n+                    ate_comma = this.eat(&token::Comma);\n+                    // We just ate a comma, so there's no need to use\n+                    // `TrailingToken::Comma`\n+                    Ok((field, TrailingToken::None))\n+                })?;\n+\n+            fields.push(field)\n         }\n \n         if let Some(mut err) = delayed_err {"}, {"sha": "e36ebd5e481137de6733ebcb22f7e1e65e453994", "filename": "compiler/rustc_parse/src/parser/stmt.rs", "status": "modified", "additions": 40, "deletions": 22, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5fa22fe6f821ac3801d05f624b123dda25fde32c/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs?ref=5fa22fe6f821ac3801d05f624b123dda25fde32c", "patch": "@@ -3,8 +3,9 @@ use super::diagnostics::{AttemptLocalParseRecovery, Error};\n use super::expr::LhsExpr;\n use super::pat::{GateOr, RecoverComma};\n use super::path::PathStyle;\n-use super::{BlockMode, ForceCollect, Parser, Restrictions, SemiColonMode, TrailingToken};\n-use crate::{maybe_collect_tokens, maybe_whole};\n+use super::TrailingToken;\n+use super::{AttrWrapper, BlockMode, ForceCollect, Parser, Restrictions, SemiColonMode};\n+use crate::maybe_whole;\n \n use rustc_ast as ast;\n use rustc_ast::attr::HasAttrs;\n@@ -38,30 +39,47 @@ impl<'a> Parser<'a> {\n         capture_semi: bool,\n         force_collect: ForceCollect,\n     ) -> PResult<'a, Option<Stmt>> {\n-        let mut attrs = self.parse_outer_attributes()?;\n+        let attrs = self.parse_outer_attributes()?;\n         let lo = self.token.span;\n \n-        maybe_whole!(self, NtStmt, |stmt| {\n-            let mut stmt = stmt;\n-            stmt.visit_attrs(|stmt_attrs| {\n-                mem::swap(stmt_attrs, &mut attrs);\n-                stmt_attrs.extend(attrs);\n-            });\n-            Some(stmt)\n-        });\n+        // Don't use `maybe_whole` so that we have precise control\n+        // over when we bump the parser\n+        if let token::Interpolated(nt) = &self.token.kind {\n+            if let token::NtStmt(stmt) = &**nt {\n+                let mut stmt = stmt.clone();\n+                return self.collect_tokens_trailing_token(\n+                    attrs,\n+                    force_collect,\n+                    |this, mut attrs| {\n+                        stmt.visit_attrs(|stmt_attrs| {\n+                            mem::swap(stmt_attrs, &mut attrs);\n+                            stmt_attrs.extend(attrs);\n+                        });\n+                        // Make sure we capture the token::Interpolated\n+                        this.bump();\n+                        Ok((Some(stmt), TrailingToken::None))\n+                    },\n+                );\n+            }\n+        }\n \n         Ok(Some(if self.token.is_keyword(kw::Let) {\n-            self.parse_local_mk(lo, attrs.into(), capture_semi, force_collect)?\n+            self.parse_local_mk(lo, attrs, capture_semi, force_collect)?\n         } else if self.is_kw_followed_by_ident(kw::Mut) {\n-            self.recover_stmt_local(lo, attrs.into(), \"missing keyword\", \"let mut\")?\n+            self.recover_stmt_local(\n+                lo,\n+                attrs.take_for_recovery().into(),\n+                \"missing keyword\",\n+                \"let mut\",\n+            )?\n         } else if self.is_kw_followed_by_ident(kw::Auto) {\n             self.bump(); // `auto`\n             let msg = \"write `let` instead of `auto` to introduce a new variable\";\n-            self.recover_stmt_local(lo, attrs.into(), msg, \"let\")?\n+            self.recover_stmt_local(lo, attrs.take_for_recovery().into(), msg, \"let\")?\n         } else if self.is_kw_followed_by_ident(sym::var) {\n             self.bump(); // `var`\n             let msg = \"write `let` instead of `var` to introduce a new variable\";\n-            self.recover_stmt_local(lo, attrs.into(), msg, \"let\")?\n+            self.recover_stmt_local(lo, attrs.take_for_recovery().into(), msg, \"let\")?\n         } else if self.check_path() && !self.token.is_qpath_start() && !self.is_path_start_item() {\n             // We have avoided contextual keywords like `union`, items with `crate` visibility,\n             // or `auto trait` items. We aim to parse an arbitrary path `a::b` but not something\n@@ -75,25 +93,25 @@ impl<'a> Parser<'a> {\n             self.mk_stmt(lo.to(item.span), StmtKind::Item(P(item)))\n         } else if self.eat(&token::Semi) {\n             // Do not attempt to parse an expression if we're done here.\n-            self.error_outer_attrs(&attrs);\n+            self.error_outer_attrs(&attrs.take_for_recovery());\n             self.mk_stmt(lo, StmtKind::Empty)\n         } else if self.token != token::CloseDelim(token::Brace) {\n             // Remainder are line-expr stmts.\n             let e = self.parse_expr_res(Restrictions::STMT_EXPR, Some(attrs.into()))?;\n             self.mk_stmt(lo.to(e.span), StmtKind::Expr(e))\n         } else {\n-            self.error_outer_attrs(&attrs);\n+            self.error_outer_attrs(&attrs.take_for_recovery());\n             return Ok(None);\n         }))\n     }\n \n     fn parse_stmt_path_start(\n         &mut self,\n         lo: Span,\n-        attrs: Vec<Attribute>,\n+        attrs: AttrWrapper,\n         force_collect: ForceCollect,\n     ) -> PResult<'a, Stmt> {\n-        maybe_collect_tokens!(self, force_collect, &attrs, |this: &mut Parser<'a>| {\n+        self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n             let path = this.parse_path(PathStyle::Expr)?;\n \n             if this.eat(&token::Not) {\n@@ -142,7 +160,7 @@ impl<'a> Parser<'a> {\n             // Since none of the above applied, this is an expression statement macro.\n             let e = self.mk_expr(lo.to(hi), ExprKind::MacCall(mac), AttrVec::new());\n             let e = self.maybe_recover_from_bad_qpath(e, true)?;\n-            let e = self.parse_dot_or_call_expr_with(e, lo, attrs)?;\n+            let e = self.parse_dot_or_call_expr_with(e, lo, attrs.into())?;\n             let e = self.parse_assoc_expr_with(0, LhsExpr::AlreadyParsed(e))?;\n             StmtKind::Expr(e)\n         };\n@@ -178,11 +196,11 @@ impl<'a> Parser<'a> {\n     fn parse_local_mk(\n         &mut self,\n         lo: Span,\n-        attrs: AttrVec,\n+        attrs: AttrWrapper,\n         capture_semi: bool,\n         force_collect: ForceCollect,\n     ) -> PResult<'a, Stmt> {\n-        maybe_collect_tokens!(self, force_collect, &attrs, |this: &mut Parser<'a>| {\n+        self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n             this.expect_keyword(kw::Let)?;\n             let local = this.parse_local(attrs.into())?;\n             let trailing = if capture_semi && this.token.kind == token::Semi {"}]}