{"sha": "1428b59a19610d838d7849c7ac518c40281fddd1", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE0MjhiNTlhMTk2MTBkODM4ZDc4NDljN2FjNTE4YzQwMjgxZmRkZDE=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2010-08-27T19:36:57Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2010-08-27T20:08:47Z"}, "message": "Modify rustboot to use lexer.reader.", "tree": {"sha": "0487fee69e199737150c8f48f9149224d2412203", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0487fee69e199737150c8f48f9149224d2412203"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/1428b59a19610d838d7849c7ac518c40281fddd1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/1428b59a19610d838d7849c7ac518c40281fddd1", "html_url": "https://github.com/rust-lang/rust/commit/1428b59a19610d838d7849c7ac518c40281fddd1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/1428b59a19610d838d7849c7ac518c40281fddd1/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "88c9759347dddb61cb9e9a1e9d524b365857cf67", "url": "https://api.github.com/repos/rust-lang/rust/commits/88c9759347dddb61cb9e9a1e9d524b365857cf67", "html_url": "https://github.com/rust-lang/rust/commit/88c9759347dddb61cb9e9a1e9d524b365857cf67"}], "stats": {"total": 197, "additions": 103, "deletions": 94}, "files": [{"sha": "8ef8cea9d4fb059ce18738ef83ab577b9750c11e", "filename": "src/comp/fe/lexer.rs", "status": "modified", "additions": 100, "deletions": 92, "changes": 192, "blob_url": "https://github.com/rust-lang/rust/blob/1428b59a19610d838d7849c7ac518c40281fddd1/src%2Fcomp%2Ffe%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1428b59a19610d838d7849c7ac518c40281fddd1/src%2Fcomp%2Ffe%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffe%2Flexer.rs?ref=1428b59a19610d838d7849c7ac518c40281fddd1", "patch": "@@ -11,9 +11,10 @@ fn new_str_hash[V]() -> map.hashmap[str,V] {\n \n type reader = obj {\n               fn is_eof() -> bool;\n-              fn peek() -> char;\n+              fn curr() -> char;\n+              fn next() -> char;\n               fn bump();\n-              fn get_pos() -> tup(str,uint,uint);\n+              fn get_curr_pos() -> tup(str,uint,uint);\n               fn get_keywords() -> hashmap[str,token.token];\n               fn get_reserved() -> hashmap[str,()];\n };\n@@ -23,6 +24,7 @@ fn new_reader(stdio_reader rdr, str filename) -> reader\n     obj reader(stdio_reader rdr,\n                str filename,\n                mutable char c,\n+               mutable char n,\n                mutable uint line,\n                mutable uint col,\n                hashmap[str,token.token] keywords,\n@@ -32,22 +34,33 @@ fn new_reader(stdio_reader rdr, str filename) -> reader\n                 ret c == (-1) as char;\n             }\n \n-            fn get_pos() -> tup(str,uint,uint) {\n+            fn get_curr_pos() -> tup(str,uint,uint) {\n                 ret tup(filename, line, col);\n             }\n \n-            fn peek() -> char {\n+            fn curr() -> char {\n                 ret c;\n             }\n \n+            fn next() -> char {\n+                ret n;\n+            }\n+\n             fn bump() {\n-                c = rdr.getc() as char;\n+                c = n;\n+\n+                if (c == (-1) as char) {\n+                    ret;\n+                }\n+\n                 if (c == '\\n') {\n                     line += 1u;\n                     col = 0u;\n                 } else {\n                     col += 1u;\n                 }\n+\n+                n = rdr.getc() as char;\n             }\n \n             fn get_keywords() -> hashmap[str,token.token] {\n@@ -82,8 +95,8 @@ fn new_reader(stdio_reader rdr, str filename) -> reader\n     keywords.insert(\"ret\", token.RET());\n     keywords.insert(\"be\", token.BE());\n \n-    ret reader(rdr, filename, rdr.getc() as char, 1u, 1u,\n-               keywords, reserved);\n+    ret reader(rdr, filename, rdr.getc() as char, rdr.getc() as char,\n+               1u, 1u, keywords, reserved);\n }\n \n \n@@ -116,201 +129,196 @@ fn is_whitespace(char c) -> bool {\n     ret c == ' ' || c == '\\t' || c == '\\r' || c == '\\n';\n }\n \n-fn consume_any_whitespace(stdio_reader rdr, char c) -> char {\n-    auto c1 = c;\n-    while (is_whitespace(c1)) {\n-        c1 = rdr.getc() as char;\n+fn consume_any_whitespace(reader rdr) {\n+    while (is_whitespace(rdr.curr())) {\n+        rdr.bump();\n     }\n-    be consume_any_line_comment(rdr, c1);\n+    be consume_any_line_comment(rdr);\n }\n \n-fn consume_any_line_comment(stdio_reader rdr, char c) -> char {\n-    auto c1 = c;\n-    if (c1 == '/') {\n-        auto c2 = rdr.getc() as char;\n-        if (c2 == '/') {\n-            while (c1 != '\\n') {\n-                c1 = rdr.getc() as char;\n+fn consume_any_line_comment(reader rdr) {\n+    if (rdr.curr() == '/') {\n+        if (rdr.next() == '/') {\n+            while (rdr.curr() != '\\n') {\n+                rdr.bump();\n             }\n             // Restart whitespace munch.\n-            be consume_any_whitespace(rdr, c1);\n+            be consume_any_whitespace(rdr);\n         }\n     }\n-    ret c;\n }\n \n-fn next_token(stdio_reader rdr) -> token.token {\n-    auto eof = (-1) as char;\n-    auto c = rdr.getc() as char;\n+fn next_token(reader rdr) -> token.token {\n     auto accum_str = \"\";\n     auto accum_int = 0;\n \n-    fn next(stdio_reader rdr) -> char {\n-        ret rdr.getc() as char;\n-    }\n-\n-    fn forget(stdio_reader rdr, char c) {\n-        rdr.ungetc(c as int);\n-    }\n+    consume_any_whitespace(rdr);\n \n-    c = consume_any_whitespace(rdr, c);\n+    if (rdr.is_eof()) { ret token.EOF(); }\n \n-    if (c == eof) { ret token.EOF(); }\n+    auto c = rdr.curr();\n \n     if (is_alpha(c)) {\n-        while (is_alpha(c)) {\n+        while (is_alpha(rdr.curr())) {\n+            c = rdr.curr();\n             accum_str += (c as u8);\n-            c = next(rdr);\n+            rdr.bump();\n         }\n-        forget(rdr, c);\n         ret token.IDENT(accum_str);\n     }\n \n     if (is_dec_digit(c)) {\n         if (c == '0') {\n+            log \"fixme: leading zero\";\n+            fail;\n         } else {\n             while (is_dec_digit(c)) {\n+                c = rdr.curr();\n                 accum_int *= 10;\n                 accum_int += (c as int) - ('0' as int);\n-                c = next(rdr);\n+                rdr.bump();\n             }\n-            forget(rdr, c);\n             ret token.LIT_INT(accum_int);\n         }\n     }\n \n \n-    fn op_or_opeq(stdio_reader rdr, char c2,\n-                  token.op op) -> token.token {\n-        if (c2 == '=') {\n+    fn op_or_opeq(reader rdr, token.op op) -> token.token {\n+        rdr.bump();\n+        if (rdr.next() == '=') {\n+            rdr.bump();\n             ret token.OPEQ(op);\n         } else {\n-            forget(rdr, c2);\n             ret token.OP(op);\n         }\n     }\n \n     alt (c) {\n         // One-byte tokens.\n-        case (';') { ret token.SEMI(); }\n-        case (',') { ret token.COMMA(); }\n-        case ('.') { ret token.DOT(); }\n-        case ('(') { ret token.LPAREN(); }\n-        case (')') { ret token.RPAREN(); }\n-        case ('{') { ret token.LBRACE(); }\n-        case ('}') { ret token.RBRACE(); }\n-        case ('[') { ret token.LBRACKET(); }\n-        case (']') { ret token.RBRACKET(); }\n-        case ('@') { ret token.AT(); }\n-        case ('#') { ret token.POUND(); }\n+        case (';') { rdr.bump(); ret token.SEMI(); }\n+        case (',') { rdr.bump(); ret token.COMMA(); }\n+        case ('.') { rdr.bump(); ret token.DOT(); }\n+        case ('(') { rdr.bump(); ret token.LPAREN(); }\n+        case (')') { rdr.bump(); ret token.RPAREN(); }\n+        case ('{') { rdr.bump(); ret token.LBRACE(); }\n+        case ('}') { rdr.bump(); ret token.RBRACE(); }\n+        case ('[') { rdr.bump(); ret token.LBRACKET(); }\n+        case (']') { rdr.bump(); ret token.RBRACKET(); }\n+        case ('@') { rdr.bump(); ret token.AT(); }\n+        case ('#') { rdr.bump(); ret token.POUND(); }\n \n         // Multi-byte tokens.\n         case ('=') {\n-            auto c2 = next(rdr);\n-            if (c2 == '=') {\n+            if (rdr.next() == '=') {\n+                rdr.bump();\n+                rdr.bump();\n                 ret token.OP(token.EQEQ());\n             } else {\n-                forget(rdr, c2);\n+                rdr.bump();\n                 ret token.OP(token.EQ());\n             }\n         }\n \n         case ('\\'') {\n-            // FIXME: general utf8-consumption support.\n-            auto c2 = next(rdr);\n+            rdr.bump();\n+            auto c2 = rdr.curr();\n             if (c2 == '\\\\') {\n-                c2 = next(rdr);\n-                alt (c2) {\n-                    case ('n') { c2 = '\\n'; }\n-                    case ('r') { c2 = '\\r'; }\n-                    case ('t') { c2 = '\\t'; }\n-                    case ('\\\\') { c2 = '\\\\'; }\n-                    case ('\\'') { c2 = '\\''; }\n+                alt (rdr.next()) {\n+                    case ('n') { rdr.bump(); c2 = '\\n'; }\n+                    case ('r') { rdr.bump(); c2 = '\\r'; }\n+                    case ('t') { rdr.bump(); c2 = '\\t'; }\n+                    case ('\\\\') { rdr.bump(); c2 = '\\\\'; }\n+                    case ('\\'') { rdr.bump(); c2 = '\\''; }\n                     // FIXME: unicode numeric escapes.\n-                    case (_) {\n+                    case (c2) {\n                         log \"unknown character escape\";\n                         log c2;\n                         fail;\n                     }\n                 }\n             }\n-            if (next(rdr) != '\\'') {\n+\n+            if (rdr.next() != '\\'') {\n                 log \"unterminated character constant\";\n                 fail;\n             }\n+            rdr.bump();\n+            rdr.bump();\n             ret token.LIT_CHAR(c2);\n         }\n \n         case ('\"') {\n+            rdr.bump();\n             // FIXME: general utf8-consumption support.\n-            auto c2 = next(rdr);\n-            while (c2 != '\"') {\n-                alt (c2) {\n+            while (rdr.curr() != '\"') {\n+                alt (rdr.curr()) {\n                     case ('\\\\') {\n-                        c2 = next(rdr);\n-                        alt (c2) {\n-                            case ('n') { accum_str += '\\n' as u8; }\n-                            case ('r') { accum_str += '\\r' as u8; }\n-                            case ('t') { accum_str += '\\t' as u8; }\n-                            case ('\\\\') { accum_str += '\\\\' as u8; }\n-                            case ('\"') { accum_str += '\"' as u8; }\n+                        alt (rdr.next()) {\n+                            case ('n') { rdr.bump(); accum_str += '\\n' as u8; }\n+                            case ('r') { rdr.bump(); accum_str += '\\r' as u8; }\n+                            case ('t') { rdr.bump(); accum_str += '\\t' as u8; }\n+                            case ('\\\\') { rdr.bump(); accum_str += '\\\\' as u8; }\n+                            case ('\"') { rdr.bump(); accum_str += '\"' as u8; }\n                             // FIXME: unicode numeric escapes.\n-                            case (_) {\n+                            case (c2) {\n                                 log \"unknown string escape\";\n                                 log c2;\n                                 fail;\n                             }\n                         }\n                     }\n                     case (_) {\n-                        accum_str += c2 as u8;\n+                        accum_str += rdr.curr() as u8;\n                     }\n                 }\n-                c2 = next(rdr);\n+                rdr.bump();\n             }\n+            rdr.bump();\n             ret token.LIT_STR(accum_str);\n         }\n \n         case ('-') {\n-            auto c2 = next(rdr);\n-            if (c2 == '>') {\n+            if (rdr.next() == '>') {\n+                rdr.bump();\n+                rdr.bump();\n                 ret token.RARROW();\n             } else {\n-                ret op_or_opeq(rdr, c2, token.MINUS());\n+                ret op_or_opeq(rdr, token.MINUS());\n             }\n         }\n \n         case ('&') {\n-            auto c2 = next(rdr);\n-            if (c2 == '&') {\n+            if (rdr.next() == '&') {\n+                rdr.bump();\n+                rdr.bump();\n                 ret token.OP(token.ANDAND());\n             } else {\n-                ret op_or_opeq(rdr, c2, token.AND());\n+                ret op_or_opeq(rdr, token.AND());\n             }\n         }\n \n         case ('+') {\n-            ret op_or_opeq(rdr, next(rdr), token.PLUS());\n+            ret op_or_opeq(rdr, token.PLUS());\n         }\n \n         case ('*') {\n-            ret op_or_opeq(rdr, next(rdr), token.STAR());\n+            ret op_or_opeq(rdr, token.STAR());\n         }\n \n         case ('/') {\n-            ret op_or_opeq(rdr, next(rdr), token.STAR());\n+            ret op_or_opeq(rdr, token.STAR());\n         }\n \n         case ('!') {\n-            ret op_or_opeq(rdr, next(rdr), token.NOT());\n+            ret op_or_opeq(rdr, token.NOT());\n         }\n \n         case ('^') {\n-            ret op_or_opeq(rdr, next(rdr), token.CARET());\n+            ret op_or_opeq(rdr, token.CARET());\n         }\n \n         case ('%') {\n-            ret op_or_opeq(rdr, next(rdr), token.PERCENT());\n+            ret op_or_opeq(rdr, token.PERCENT());\n         }\n \n     }"}, {"sha": "d2da791017e2b4a620ad1976674e551c9e623cc2", "filename": "src/comp/fe/parser.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/1428b59a19610d838d7849c7ac518c40281fddd1/src%2Fcomp%2Ffe%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/1428b59a19610d838d7849c7ac518c40281fddd1/src%2Fcomp%2Ffe%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fcomp%2Ffe%2Fparser.rs?ref=1428b59a19610d838d7849c7ac518c40281fddd1", "patch": "@@ -8,7 +8,7 @@ state type parser =\n \n fn new_parser(str path) -> parser {\n     state obj stdio_parser(mutable token.token tok,\n-                           _io.stdio_reader rdr)\n+                           lexer.reader rdr)\n         {\n             state fn peek() -> token.token {\n                 ret tok;\n@@ -17,7 +17,8 @@ fn new_parser(str path) -> parser {\n                 tok = lexer.next_token(rdr);\n             }\n         }\n-    auto rdr = _io.new_stdio_reader(path);\n+    auto srdr = _io.new_stdio_reader(path);\n+    auto rdr = lexer.new_reader(srdr, path);\n     ret stdio_parser(lexer.next_token(rdr), rdr);\n }\n "}]}