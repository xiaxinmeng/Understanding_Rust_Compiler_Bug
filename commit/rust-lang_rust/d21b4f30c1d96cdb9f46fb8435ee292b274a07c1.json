{"sha": "d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "node_id": "C_kwDOAAsO6NoAKGQyMWI0ZjMwYzFkOTZjZGI5ZjQ2ZmI4NDM1ZWUyOTJiMjc0YTA3YzE", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-18T20:47:22Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-18T20:47:22Z"}, "message": "Introduce `TtParser`.\n\nIt currently has no state, just the three methods `parse_tt`,\n`parse_tt_inner`, and `bb_items_ambiguity_error`.\n\nThis commit is large but trivial, and mostly consists of changes to the\nindentation of those methods. Subsequent commits will do more.", "tree": {"sha": "f583c8516c9d056ac9c9ff2b04c3221abce64933", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f583c8516c9d056ac9c9ff2b04c3221abce64933"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "html_url": "https://github.com/rust-lang/rust/commit/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "1bfe40d11c3630254504fb73eeccfca28d50df52", "url": "https://api.github.com/repos/rust-lang/rust/commits/1bfe40d11c3630254504fb73eeccfca28d50df52", "html_url": "https://github.com/rust-lang/rust/commit/1bfe40d11c3630254504fb73eeccfca28d50df52"}], "stats": {"total": 627, "additions": 323, "deletions": 304}, "files": [{"sha": "7b5835fce5401ea0e5da13a0f76bb7bcefdc3ecc", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 294, "deletions": 279, "changes": 573, "blob_url": "https://github.com/rust-lang/rust/blob/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "patch": "@@ -492,319 +492,334 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     }\n }\n \n-/// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n-/// produce more items in `next_items` and `bb_items`.\n-///\n-/// For more info about the how this happens, see the module-level doc comments and the inline\n-/// comments of this function.\n-///\n-/// # Parameters\n-///\n-/// - `cur_items`: the set of current items to be processed. This should be empty by the end of a\n-///   successful execution of this function.\n-/// - `next_items`: the set of newly generated items. These are used to replenish `cur_items` in\n-///   the function `parse`.\n-/// - `bb_items`: the set of items that are waiting for the black-box parser.\n-/// - `token`: the current token of the parser.\n-///\n-/// # Returns\n-///\n-/// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept track of\n-/// through the items generated.\n-fn parse_tt_inner<'root, 'tt>(\n-    sess: &ParseSess,\n-    ms: &[TokenTree],\n-    cur_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    next_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    token: &Token,\n-) -> Option<NamedParseResult> {\n-    // Matcher positions that would be valid if the macro invocation was over now. Only modified if\n-    // `token == Eof`.\n-    let mut eof_items = EofItems::None;\n-\n-    while let Some(mut item) = cur_items.pop() {\n-        // When unzipped trees end, remove them. This corresponds to backtracking out of a\n-        // delimited submatcher into which we already descended. When backtracking out again, we\n-        // need to advance the \"dot\" past the delimiters in the outer matcher.\n-        while item.idx >= item.top_elts.len() {\n-            match item.stack.pop() {\n-                Some(MatcherTtFrame { elts, idx }) => {\n-                    item.top_elts = elts;\n-                    item.idx = idx + 1;\n+pub struct TtParser;\n+\n+impl TtParser {\n+    /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n+    /// produce more items in `next_items` and `bb_items`.\n+    ///\n+    /// For more info about the how this happens, see the module-level doc comments and the inline\n+    /// comments of this function.\n+    ///\n+    /// # Parameters\n+    ///\n+    /// - `cur_items`: the set of current items to be processed. This should be empty by the end of\n+    ///   a successful execution of this function.\n+    /// - `next_items`: the set of newly generated items. These are used to replenish `cur_items` in\n+    ///   the function `parse`.\n+    /// - `bb_items`: the set of items that are waiting for the black-box parser.\n+    /// - `token`: the current token of the parser.\n+    ///\n+    /// # Returns\n+    ///\n+    /// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept\n+    /// track of through the items generated.\n+    fn parse_tt_inner<'root, 'tt>(\n+        &self,\n+        sess: &ParseSess,\n+        ms: &[TokenTree],\n+        cur_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+        next_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+        bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+        token: &Token,\n+    ) -> Option<NamedParseResult> {\n+        // Matcher positions that would be valid if the macro invocation was over now. Only\n+        // modified if `token == Eof`.\n+        let mut eof_items = EofItems::None;\n+\n+        while let Some(mut item) = cur_items.pop() {\n+            // When unzipped trees end, remove them. This corresponds to backtracking out of a\n+            // delimited submatcher into which we already descended. When backtracking out again, we\n+            // need to advance the \"dot\" past the delimiters in the outer matcher.\n+            while item.idx >= item.top_elts.len() {\n+                match item.stack.pop() {\n+                    Some(MatcherTtFrame { elts, idx }) => {\n+                        item.top_elts = elts;\n+                        item.idx = idx + 1;\n+                    }\n+                    None => break,\n                 }\n-                None => break,\n             }\n-        }\n \n-        // Get the current position of the \"dot\" (`idx`) in `item` and the number of token trees in\n-        // the matcher (`len`).\n-        let idx = item.idx;\n-        let len = item.top_elts.len();\n-\n-        if idx < len {\n-            // We are in the middle of a matcher. Compare the matcher's current tt against `token`.\n-            match item.top_elts.get_tt(idx) {\n-                TokenTree::Sequence(sp, seq) => {\n-                    let op = seq.kleene.op;\n-                    if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n-                        // Allow for the possibility of zero matches of this sequence.\n-                        let mut new_item = item.clone();\n-                        new_item.match_cur += seq.num_captures;\n-                        new_item.idx += 1;\n-                        for idx in item.match_cur..item.match_cur + seq.num_captures {\n-                            new_item.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n+            // Get the current position of the \"dot\" (`idx`) in `item` and the number of token\n+            // trees in the matcher (`len`).\n+            let idx = item.idx;\n+            let len = item.top_elts.len();\n+\n+            if idx < len {\n+                // We are in the middle of a matcher. Compare the matcher's current tt against\n+                // `token`.\n+                match item.top_elts.get_tt(idx) {\n+                    TokenTree::Sequence(sp, seq) => {\n+                        let op = seq.kleene.op;\n+                        if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n+                            // Allow for the possibility of zero matches of this sequence.\n+                            let mut new_item = item.clone();\n+                            new_item.match_cur += seq.num_captures;\n+                            new_item.idx += 1;\n+                            for idx in item.match_cur..item.match_cur + seq.num_captures {\n+                                new_item.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n+                            }\n+                            cur_items.push(new_item);\n                         }\n-                        cur_items.push(new_item);\n+\n+                        // Allow for the possibility of one or more matches of this sequence.\n+                        cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos::repetition(\n+                            item, sp, seq,\n+                        ))));\n                     }\n \n-                    // Allow for the possibility of one or more matches of this sequence.\n-                    cur_items.push(MatcherPosHandle::Box(Box::new(MatcherPos::repetition(\n-                        item, sp, seq,\n-                    ))));\n-                }\n+                    TokenTree::MetaVarDecl(span, _, None) => {\n+                        // E.g. `$e` instead of `$e:expr`.\n+                        if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n+                            return Some(Error(span, \"missing fragment specifier\".to_string()));\n+                        }\n+                    }\n \n-                TokenTree::MetaVarDecl(span, _, None) => {\n-                    // E.g. `$e` instead of `$e:expr`.\n-                    if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n-                        return Some(Error(span, \"missing fragment specifier\".to_string()));\n+                    TokenTree::MetaVarDecl(_, _, Some(kind)) => {\n+                        // Built-in nonterminals never start with these tokens, so we can eliminate\n+                        // them from consideration.\n+                        //\n+                        // We use the span of the metavariable declaration to determine any\n+                        // edition-specific matching behavior for non-terminals.\n+                        if Parser::nonterminal_may_begin_with(kind, token) {\n+                            bb_items.push(item);\n+                        }\n                     }\n-                }\n \n-                TokenTree::MetaVarDecl(_, _, Some(kind)) => {\n-                    // Built-in nonterminals never start with these tokens, so we can eliminate\n-                    // them from consideration.\n-                    //\n-                    // We use the span of the metavariable declaration to determine any\n-                    // edition-specific matching behavior for non-terminals.\n-                    if Parser::nonterminal_may_begin_with(kind, token) {\n-                        bb_items.push(item);\n+                    seq @ (TokenTree::Delimited(..)\n+                    | TokenTree::Token(Token { kind: DocComment(..), .. })) => {\n+                        // To descend into a delimited submatcher or a doc comment, we push the\n+                        // current matcher onto a stack and push a new item containing the\n+                        // submatcher onto `cur_items`.\n+                        //\n+                        // At the beginning of the loop, if we reach the end of the delimited\n+                        // submatcher, we pop the stack to backtrack out of the descent.\n+                        let lower_elts = mem::replace(&mut item.top_elts, Tt(seq));\n+                        let idx = item.idx;\n+                        item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n+                        item.idx = 0;\n+                        cur_items.push(item);\n                     }\n-                }\n \n-                seq @ (TokenTree::Delimited(..)\n-                | TokenTree::Token(Token { kind: DocComment(..), .. })) => {\n-                    // To descend into a delimited submatcher or a doc comment, we push the current\n-                    // matcher onto a stack and push a new item containing the submatcher onto\n-                    // `cur_items`.\n-                    //\n-                    // At the beginning of the loop, if we reach the end of the delimited\n-                    // submatcher, we pop the stack to backtrack out of the descent.\n-                    let lower_elts = mem::replace(&mut item.top_elts, Tt(seq));\n-                    let idx = item.idx;\n-                    item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n-                    item.idx = 0;\n-                    cur_items.push(item);\n+                    TokenTree::Token(t) => {\n+                        // If the token matches, we can just advance the parser. Otherwise, this\n+                        // match hash failed, there is nothing to do, and hopefully another item in\n+                        // `cur_items` will match.\n+                        if token_name_eq(&t, token) {\n+                            item.idx += 1;\n+                            next_items.push(item);\n+                        }\n+                    }\n+\n+                    // These cannot appear in a matcher.\n+                    TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n+                }\n+            } else if let Some(repetition) = &item.repetition {\n+                // We are past the end of a repetition.\n+                debug_assert!(idx <= len + 1);\n+                debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n+\n+                if idx == len {\n+                    // Add all matches from the sequence to `up`, and move the \"dot\" past the\n+                    // repetition in `up`. This allows for the case where the sequence matching is\n+                    // finished.\n+                    let mut new_pos = repetition.up.clone();\n+                    for idx in item.match_lo..item.match_hi {\n+                        let sub = item.matches[idx].clone();\n+                        new_pos.push_match(idx, MatchedSeq(sub));\n+                    }\n+                    new_pos.match_cur = item.match_hi;\n+                    new_pos.idx += 1;\n+                    cur_items.push(new_pos);\n                 }\n \n-                TokenTree::Token(t) => {\n-                    // If the token matches, we can just advance the parser. Otherwise, this match\n-                    // hash failed, there is nothing to do, and hopefully another item in\n-                    // `cur_items` will match.\n-                    if token_name_eq(&t, token) {\n+                if idx == len && repetition.sep.is_some() {\n+                    if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n+                        // The matcher has a separator, and it matches the current token. We can\n+                        // advance past the separator token.\n                         item.idx += 1;\n                         next_items.push(item);\n                     }\n+                } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n+                    // We don't need a separator. Move the \"dot\" back to the beginning of the\n+                    // matcher and try to match again UNLESS we are only allowed to have _one_\n+                    // repetition.\n+                    item.match_cur = item.match_lo;\n+                    item.idx = 0;\n+                    cur_items.push(item);\n                 }\n-\n-                // These cannot appear in a matcher.\n-                TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n-            }\n-        } else if let Some(repetition) = &item.repetition {\n-            // We are past the end of a repetition.\n-            debug_assert!(idx <= len + 1);\n-            debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n-\n-            if idx == len {\n-                // Add all matches from the sequence to `up`, and move the \"dot\" past the\n-                // repetition in `up`. This allows for the case where the sequence matching is\n-                // finished.\n-                let mut new_pos = repetition.up.clone();\n-                for idx in item.match_lo..item.match_hi {\n-                    let sub = item.matches[idx].clone();\n-                    new_pos.push_match(idx, MatchedSeq(sub));\n+            } else {\n+                // We are past the end of the matcher, and not in a repetition. Look for end of\n+                // input.\n+                debug_assert_eq!(idx, len);\n+                if *token == token::Eof {\n+                    eof_items = match eof_items {\n+                        EofItems::None => EofItems::One(item),\n+                        EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                    }\n                 }\n-                new_pos.match_cur = item.match_hi;\n-                new_pos.idx += 1;\n-                cur_items.push(new_pos);\n             }\n+        }\n \n-            if idx == len && repetition.sep.is_some() {\n-                if repetition.sep.as_ref().map_or(false, |sep| token_name_eq(token, sep)) {\n-                    // The matcher has a separator, and it matches the current token. We can\n-                    // advance past the separator token.\n-                    item.idx += 1;\n-                    next_items.push(item);\n+        // If we reached the end of input, check that there is EXACTLY ONE possible matcher.\n+        // Otherwise, either the parse is ambiguous (which is an error) or there is a syntax error.\n+        if *token == token::Eof {\n+            Some(match eof_items {\n+                EofItems::One(mut eof_item) => {\n+                    let matches =\n+                        eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n+                    nameize(sess, ms, matches)\n                 }\n-            } else if repetition.seq_op != mbe::KleeneOp::ZeroOrOne {\n-                // We don't need a separator. Move the \"dot\" back to the beginning of the\n-                // matcher and try to match again UNLESS we are only allowed to have _one_\n-                // repetition.\n-                item.match_cur = item.match_lo;\n-                item.idx = 0;\n-                cur_items.push(item);\n-            }\n-        } else {\n-            // We are past the end of the matcher, and not in a repetition. Look for end of input.\n-            debug_assert_eq!(idx, len);\n-            if *token == token::Eof {\n-                eof_items = match eof_items {\n-                    EofItems::None => EofItems::One(item),\n-                    EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                EofItems::Multiple => {\n+                    Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n                 }\n-            }\n+                EofItems::None => Failure(\n+                    Token::new(\n+                        token::Eof,\n+                        if token.span.is_dummy() { token.span } else { token.span.shrink_to_hi() },\n+                    ),\n+                    \"missing tokens in macro arguments\",\n+                ),\n+            })\n+        } else {\n+            None\n         }\n     }\n \n-    // If we reached the end of input, check that there is EXACTLY ONE possible matcher. Otherwise,\n-    // either the parse is ambiguous (which is an error) or there is a syntax error.\n-    if *token == token::Eof {\n-        Some(match eof_items {\n-            EofItems::One(mut eof_item) => {\n-                let matches =\n-                    eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n-                nameize(sess, ms, matches)\n+    /// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the\n+    /// given `parser` against it and return the match.\n+    pub(super) fn parse_tt(\n+        &self,\n+        parser: &mut Cow<'_, Parser<'_>>,\n+        ms: &[TokenTree],\n+        macro_name: Ident,\n+    ) -> NamedParseResult {\n+        // A queue of possible matcher positions. We initialize it with the matcher position in\n+        // which the \"dot\" is before the first token of the first token tree in `ms`.\n+        // `parse_tt_inner` then processes all of these possible matcher positions and produces\n+        // possible next positions into `next_items`. After some post-processing, the contents of\n+        // `next_items` replenish `cur_items` and we start over again.\n+        //\n+        // This MatcherPos instance is allocated on the stack. All others -- and there are\n+        // frequently *no* others! -- are allocated on the heap.\n+        let mut initial = MatcherPos::new(ms);\n+        let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n+\n+        loop {\n+            let mut next_items = SmallVec::new();\n+\n+            // Matcher positions black-box parsed by `Parser`.\n+            let mut bb_items = SmallVec::new();\n+\n+            // Process `cur_items` until either we have finished the input or we need to get some\n+            // parsing from the black-box parser done.\n+            if let Some(result) = self.parse_tt_inner(\n+                parser.sess,\n+                ms,\n+                &mut cur_items,\n+                &mut next_items,\n+                &mut bb_items,\n+                &parser.token,\n+            ) {\n+                return result;\n             }\n-            EofItems::Multiple => {\n-                Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n-            }\n-            EofItems::None => Failure(\n-                Token::new(\n-                    token::Eof,\n-                    if token.span.is_dummy() { token.span } else { token.span.shrink_to_hi() },\n-                ),\n-                \"missing tokens in macro arguments\",\n-            ),\n-        })\n-    } else {\n-        None\n-    }\n-}\n \n-/// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the given\n-/// `parser` against it and return the match.\n-pub(super) fn parse_tt(\n-    parser: &mut Cow<'_, Parser<'_>>,\n-    ms: &[TokenTree],\n-    macro_name: Ident,\n-) -> NamedParseResult {\n-    // A queue of possible matcher positions. We initialize it with the matcher position in which\n-    // the \"dot\" is before the first token of the first token tree in `ms`. `parse_tt_inner` then\n-    // processes all of these possible matcher positions and produces possible next positions into\n-    // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n-    // and we start over again.\n-    //\n-    // This MatcherPos instance is allocated on the stack. All others -- and there are frequently\n-    // *no* others! -- are allocated on the heap.\n-    let mut initial = MatcherPos::new(ms);\n-    let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n-\n-    loop {\n-        let mut next_items = SmallVec::new();\n-\n-        // Matcher positions black-box parsed by `Parser`.\n-        let mut bb_items = SmallVec::new();\n-\n-        // Process `cur_items` until either we have finished the input or we need to get some\n-        // parsing from the black-box parser done.\n-        if let Some(result) = parse_tt_inner(\n-            parser.sess,\n-            ms,\n-            &mut cur_items,\n-            &mut next_items,\n-            &mut bb_items,\n-            &parser.token,\n-        ) {\n-            return result;\n-        }\n-\n-        // `parse_tt_inner` handled all cur_items, so it's empty.\n-        assert!(cur_items.is_empty());\n+            // `parse_tt_inner` handled all cur_items, so it's empty.\n+            assert!(cur_items.is_empty());\n+\n+            // Error messages here could be improved with links to original rules.\n+            match (next_items.len(), bb_items.len()) {\n+                (0, 0) => {\n+                    // There are no possible next positions AND we aren't waiting for the black-box\n+                    // parser: syntax error.\n+                    return Failure(\n+                        parser.token.clone(),\n+                        \"no rules expected this token in macro call\",\n+                    );\n+                }\n \n-        // Error messages here could be improved with links to original rules.\n-        match (next_items.len(), bb_items.len()) {\n-            (0, 0) => {\n-                // There are no possible next positions AND we aren't waiting for the black-box\n-                // parser: syntax error.\n-                return Failure(parser.token.clone(), \"no rules expected this token in macro call\");\n-            }\n+                (_, 0) => {\n+                    // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n+                    // process the next token.\n+                    cur_items.extend(next_items.drain(..));\n+                    parser.to_mut().bump();\n+                }\n \n-            (_, 0) => {\n-                // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n-                // process the next token.\n-                cur_items.extend(next_items.drain(..));\n-                parser.to_mut().bump();\n-            }\n+                (0, 1) => {\n+                    // We need to call the black-box parser to get some nonterminal.\n+                    let mut item = bb_items.pop().unwrap();\n+                    if let TokenTree::MetaVarDecl(span, _, Some(kind)) =\n+                        item.top_elts.get_tt(item.idx)\n+                    {\n+                        let match_cur = item.match_cur;\n+                        // We use the span of the metavariable declaration to determine any\n+                        // edition-specific matching behavior for non-terminals.\n+                        let nt = match parser.to_mut().parse_nonterminal(kind) {\n+                            Err(mut err) => {\n+                                err.span_label(\n+                                    span,\n+                                    format!(\n+                                        \"while parsing argument for this `{kind}` macro fragment\"\n+                                    ),\n+                                )\n+                                .emit();\n+                                return ErrorReported;\n+                            }\n+                            Ok(nt) => nt,\n+                        };\n+                        item.push_match(match_cur, MatchedNonterminal(Lrc::new(nt)));\n+                        item.idx += 1;\n+                        item.match_cur += 1;\n+                    } else {\n+                        unreachable!()\n+                    }\n+                    cur_items.push(item);\n+                }\n \n-            (0, 1) => {\n-                // We need to call the black-box parser to get some nonterminal.\n-                let mut item = bb_items.pop().unwrap();\n-                if let TokenTree::MetaVarDecl(span, _, Some(kind)) = item.top_elts.get_tt(item.idx)\n-                {\n-                    let match_cur = item.match_cur;\n-                    // We use the span of the metavariable declaration to determine any\n-                    // edition-specific matching behavior for non-terminals.\n-                    let nt = match parser.to_mut().parse_nonterminal(kind) {\n-                        Err(mut err) => {\n-                            err.span_label(\n-                                span,\n-                                format!(\"while parsing argument for this `{kind}` macro fragment\"),\n-                            )\n-                            .emit();\n-                            return ErrorReported;\n-                        }\n-                        Ok(nt) => nt,\n-                    };\n-                    item.push_match(match_cur, MatchedNonterminal(Lrc::new(nt)));\n-                    item.idx += 1;\n-                    item.match_cur += 1;\n-                } else {\n-                    unreachable!()\n+                (_, _) => {\n+                    // Too many possibilities!\n+                    return self.bb_items_ambiguity_error(\n+                        macro_name,\n+                        next_items,\n+                        bb_items,\n+                        parser.token.span,\n+                    );\n                 }\n-                cur_items.push(item);\n             }\n \n-            (_, _) => {\n-                // Too many possibilities!\n-                return bb_items_ambiguity_error(\n-                    macro_name,\n-                    next_items,\n-                    bb_items,\n-                    parser.token.span,\n-                );\n-            }\n+            assert!(!cur_items.is_empty());\n         }\n-\n-        assert!(!cur_items.is_empty());\n     }\n-}\n \n-fn bb_items_ambiguity_error<'root, 'tt>(\n-    macro_name: Ident,\n-    next_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    bb_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    token_span: rustc_span::Span,\n-) -> NamedParseResult {\n-    let nts = bb_items\n-        .iter()\n-        .map(|item| match item.top_elts.get_tt(item.idx) {\n-            TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n-                format!(\"{} ('{}')\", kind, bind)\n-            }\n-            _ => panic!(),\n-        })\n-        .collect::<Vec<String>>()\n-        .join(\" or \");\n-\n-    Error(\n-        token_span,\n-        format!(\n-            \"local ambiguity when calling macro `{macro_name}`: multiple parsing options: {}\",\n-            match next_items.len() {\n-                0 => format!(\"built-in NTs {}.\", nts),\n-                1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n-                n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n-            }\n-        ),\n-    )\n+    fn bb_items_ambiguity_error<'root, 'tt>(\n+        &self,\n+        macro_name: Ident,\n+        next_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+        bb_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+        token_span: rustc_span::Span,\n+    ) -> NamedParseResult {\n+        let nts = bb_items\n+            .iter()\n+            .map(|item| match item.top_elts.get_tt(item.idx) {\n+                TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n+                    format!(\"{} ('{}')\", kind, bind)\n+                }\n+                _ => panic!(),\n+            })\n+            .collect::<Vec<String>>()\n+            .join(\" or \");\n+\n+        Error(\n+            token_span,\n+            format!(\n+                \"local ambiguity when calling macro `{macro_name}`: multiple parsing options: {}\",\n+                match next_items.len() {\n+                    0 => format!(\"built-in NTs {}.\", nts),\n+                    1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n+                    n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n+                }\n+            ),\n+        )\n+    }\n }"}, {"sha": "eaf02607e701c0476e4c959950f7712bc27b51f3", "filename": "compiler/rustc_expand/src/mbe/macro_rules.rs", "status": "modified", "additions": 29, "deletions": 25, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d21b4f30c1d96cdb9f46fb8435ee292b274a07c1/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_rules.rs?ref=d21b4f30c1d96cdb9f46fb8435ee292b274a07c1", "patch": "@@ -3,8 +3,7 @@ use crate::base::{SyntaxExtension, SyntaxExtensionKind};\n use crate::expand::{ensure_complete_parse, parse_ast_fragment, AstFragment, AstFragmentKind};\n use crate::mbe;\n use crate::mbe::macro_check;\n-use crate::mbe::macro_parser::parse_tt;\n-use crate::mbe::macro_parser::{Error, ErrorReported, Failure, Success};\n+use crate::mbe::macro_parser::{Error, ErrorReported, Failure, Success, TtParser};\n use crate::mbe::macro_parser::{MatchedNonterminal, MatchedSeq};\n use crate::mbe::transcribe::transcribe;\n \n@@ -246,6 +245,7 @@ fn generic_extension<'cx>(\n     // this situation.)\n     let parser = parser_from_cx(sess, arg.clone());\n \n+    let tt_parser = TtParser;\n     for (i, lhs) in lhses.iter().enumerate() {\n         // try each arm's matchers\n         let lhs_tt = match *lhs {\n@@ -259,7 +259,7 @@ fn generic_extension<'cx>(\n         // are not recorded. On the first `Success(..)`ful matcher, the spans are merged.\n         let mut gated_spans_snapshot = mem::take(&mut *sess.gated_spans.spans.borrow_mut());\n \n-        match parse_tt(&mut Cow::Borrowed(&parser), lhs_tt, name) {\n+        match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), lhs_tt, name) {\n             Success(named_matches) => {\n                 // The matcher was `Success(..)`ful.\n                 // Merge the gated spans from parsing the matcher with the pre-existing ones.\n@@ -352,9 +352,11 @@ fn generic_extension<'cx>(\n                 mbe::TokenTree::Delimited(_, ref delim) => &delim.tts,\n                 _ => continue,\n             };\n-            if let Success(_) =\n-                parse_tt(&mut Cow::Borrowed(&parser_from_cx(sess, arg.clone())), lhs_tt, name)\n-            {\n+            if let Success(_) = tt_parser.parse_tt(\n+                &mut Cow::Borrowed(&parser_from_cx(sess, arg.clone())),\n+                lhs_tt,\n+                name,\n+            ) {\n                 if comma_span.is_dummy() {\n                     err.note(\"you might be missing a comma\");\n                 } else {\n@@ -447,25 +449,27 @@ pub fn compile_declarative_macro(\n     ];\n \n     let parser = Parser::new(&sess.parse_sess, body, true, rustc_parse::MACRO_ARGUMENTS);\n-    let argument_map = match parse_tt(&mut Cow::Borrowed(&parser), &argument_gram, def.ident) {\n-        Success(m) => m,\n-        Failure(token, msg) => {\n-            let s = parse_failure_msg(&token);\n-            let sp = token.span.substitute_dummy(def.span);\n-            sess.parse_sess.span_diagnostic.struct_span_err(sp, &s).span_label(sp, msg).emit();\n-            return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n-        }\n-        Error(sp, msg) => {\n-            sess.parse_sess\n-                .span_diagnostic\n-                .struct_span_err(sp.substitute_dummy(def.span), &msg)\n-                .emit();\n-            return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n-        }\n-        ErrorReported => {\n-            return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n-        }\n-    };\n+    let tt_parser = TtParser;\n+    let argument_map =\n+        match tt_parser.parse_tt(&mut Cow::Borrowed(&parser), &argument_gram, def.ident) {\n+            Success(m) => m,\n+            Failure(token, msg) => {\n+                let s = parse_failure_msg(&token);\n+                let sp = token.span.substitute_dummy(def.span);\n+                sess.parse_sess.span_diagnostic.struct_span_err(sp, &s).span_label(sp, msg).emit();\n+                return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n+            }\n+            Error(sp, msg) => {\n+                sess.parse_sess\n+                    .span_diagnostic\n+                    .struct_span_err(sp.substitute_dummy(def.span), &msg)\n+                    .emit();\n+                return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n+            }\n+            ErrorReported => {\n+                return mk_syn_ext(Box::new(macro_rules_dummy_expander));\n+            }\n+        };\n \n     let mut valid = true;\n "}]}