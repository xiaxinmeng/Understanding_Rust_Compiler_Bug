{"sha": "2a56b5c4f096736d6795eecb835cc2dc14b00107", "node_id": "MDY6Q29tbWl0NzI0NzEyOjJhNTZiNWM0ZjA5NjczNmQ2Nzk1ZWVjYjgzNWNjMmRjMTRiMDAxMDc=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2018-09-15T20:57:06Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2018-09-15T20:57:06Z"}, "message": "Merge #69\n\n69: Incremental reparsing for single tokens  r=matklad a=darksv\n\nImplement incremental reparsing for `WHITESPACE`, `COMMENT`, `DOC_COMMENT`, `IDENT`, `STRING` and `RAW_STRING`. This allows to avoid reparsing whole blocks when a change was made only within these tokens.\n\nCo-authored-by: darksv <darek969-12@o2.pl>", "tree": {"sha": "a57d09a900dcd0aec2357c7368bbc2dfe6a1b423", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a57d09a900dcd0aec2357c7368bbc2dfe6a1b423"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2a56b5c4f096736d6795eecb835cc2dc14b00107", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2a56b5c4f096736d6795eecb835cc2dc14b00107", "html_url": "https://github.com/rust-lang/rust/commit/2a56b5c4f096736d6795eecb835cc2dc14b00107", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2a56b5c4f096736d6795eecb835cc2dc14b00107/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "6ee4c287f9c95738f0482bf635ccc3801fc2fea2", "url": "https://api.github.com/repos/rust-lang/rust/commits/6ee4c287f9c95738f0482bf635ccc3801fc2fea2", "html_url": "https://github.com/rust-lang/rust/commit/6ee4c287f9c95738f0482bf635ccc3801fc2fea2"}, {"sha": "ab00639032981f8b959e06c4015dd72201df651d", "url": "https://api.github.com/repos/rust-lang/rust/commits/ab00639032981f8b959e06c4015dd72201df651d", "html_url": "https://github.com/rust-lang/rust/commit/ab00639032981f8b959e06c4015dd72201df651d"}], "stats": {"total": 558, "additions": 360, "deletions": 198}, "files": [{"sha": "886195660035aea9716c2beef9b610b50e78cbc0", "filename": "crates/libsyntax2/src/lib.rs", "status": "modified", "additions": 9, "deletions": 123, "changes": 132, "blob_url": "https://github.com/rust-lang/rust/blob/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Flib.rs?ref=2a56b5c4f096736d6795eecb835cc2dc14b00107", "patch": "@@ -27,6 +27,10 @@ extern crate parking_lot;\n extern crate smol_str;\n extern crate text_unit;\n \n+#[cfg(test)]\n+#[macro_use]\n+extern crate test_utils;\n+\n pub mod algo;\n pub mod ast;\n mod lexer;\n@@ -35,6 +39,7 @@ mod token_set;\n mod parser_api;\n mod grammar;\n mod parser_impl;\n+mod reparsing;\n \n mod syntax_kinds;\n mod yellow;\n@@ -49,12 +54,11 @@ pub use {\n     lexer::{tokenize, Token},\n     syntax_kinds::SyntaxKind,\n     yellow::{SyntaxNode, SyntaxNodeRef, OwnedRoot, RefRoot, TreeRoot, SyntaxError},\n+    reparsing::AtomEdit,\n };\n \n use {\n-    SyntaxKind::*,\n     yellow::{GreenNode, SyntaxRoot},\n-    parser_api::Parser,\n };\n \n #[derive(Clone, Debug)]\n@@ -82,25 +86,11 @@ impl File {\n         self.incremental_reparse(edit).unwrap_or_else(|| self.full_reparse(edit))\n     }\n     pub fn incremental_reparse(&self, edit: &AtomEdit) -> Option<File> {\n-        let (node, reparser) = find_reparsable_node(self.syntax(), edit.delete)?;\n-        let text = replace_range(\n-            node.text().to_string(),\n-            edit.delete - node.range().start(),\n-            &edit.insert,\n-        );\n-        let tokens = tokenize(&text);\n-        if !is_balanced(&tokens) {\n-            return None;\n-        }\n-        let (green, new_errors) = parser_impl::parse_with::<yellow::GreenBuilder>(\n-            &text, &tokens, reparser,\n-        );\n-        let green_root = node.replace_with(green);\n-        let errors = merge_errors(self.errors(), new_errors, node, edit);\n-        Some(File::new(green_root, errors))\n+        reparsing::incremental_reparse(self.syntax(), edit, self.errors())\n+            .map(|(green_node, errors)| File::new(green_node, errors))\n     }\n     fn full_reparse(&self, edit: &AtomEdit) -> File {\n-        let text = replace_range(self.syntax().text().to_string(), edit.delete, &edit.insert);\n+        let text = text_utils::replace_range(self.syntax().text().to_string(), edit.delete, &edit.insert);\n         File::parse(&text)\n     }\n     pub fn ast(&self) -> ast::Root {\n@@ -113,107 +103,3 @@ impl File {\n         self.syntax().root.syntax_root().errors.clone()\n     }\n }\n-\n-#[derive(Debug, Clone)]\n-pub struct AtomEdit {\n-    pub delete: TextRange,\n-    pub insert: String,\n-}\n-\n-impl AtomEdit {\n-    pub fn replace(range: TextRange, replace_with: String) -> AtomEdit {\n-        AtomEdit { delete: range, insert: replace_with }\n-    }\n-\n-    pub fn delete(range: TextRange) -> AtomEdit {\n-        AtomEdit::replace(range, String::new())\n-    }\n-\n-    pub fn insert(offset: TextUnit, text: String) -> AtomEdit {\n-        AtomEdit::replace(TextRange::offset_len(offset, 0.into()), text)\n-    }\n-}\n-\n-fn find_reparsable_node(node: SyntaxNodeRef, range: TextRange) -> Option<(SyntaxNodeRef, fn(&mut Parser))> {\n-    let node = algo::find_covering_node(node, range);\n-    return algo::ancestors(node)\n-        .filter_map(|node| reparser(node).map(|r| (node, r)))\n-        .next();\n-\n-    fn reparser(node: SyntaxNodeRef) -> Option<fn(&mut Parser)> {\n-        let res = match node.kind() {\n-            BLOCK => grammar::block,\n-            NAMED_FIELD_DEF_LIST => grammar::named_field_def_list,\n-            NAMED_FIELD_LIST => grammar::named_field_list,\n-            ENUM_VARIANT_LIST => grammar::enum_variant_list,\n-            MATCH_ARM_LIST => grammar::match_arm_list,\n-            USE_TREE_LIST => grammar::use_tree_list,\n-            EXTERN_ITEM_LIST => grammar::extern_item_list,\n-            TOKEN_TREE if node.first_child().unwrap().kind() == L_CURLY => grammar::token_tree,\n-            ITEM_LIST => {\n-                let parent = node.parent().unwrap();\n-                match parent.kind() {\n-                    IMPL_ITEM => grammar::impl_item_list,\n-                    TRAIT_DEF => grammar::trait_item_list,\n-                    MODULE => grammar::mod_item_list,\n-                    _ => return None,\n-                }\n-            },\n-            _ => return None,\n-        };\n-        Some(res)\n-    }\n-}\n-\n-pub /*(meh)*/ fn replace_range(mut text: String, range: TextRange, replace_with: &str) -> String {\n-    let start = u32::from(range.start()) as usize;\n-    let end = u32::from(range.end()) as usize;\n-    text.replace_range(start..end, replace_with);\n-    text\n-}\n-\n-fn is_balanced(tokens: &[Token]) -> bool {\n-    if tokens.len() == 0\n-       || tokens.first().unwrap().kind != L_CURLY\n-       || tokens.last().unwrap().kind != R_CURLY {\n-        return false\n-    }\n-    let mut balance = 0usize;\n-    for t in tokens.iter() {\n-        match t.kind {\n-            L_CURLY => balance += 1,\n-            R_CURLY => balance = match balance.checked_sub(1) {\n-                Some(b) => b,\n-                None => return false,\n-            },\n-            _ => (),\n-        }\n-    }\n-    balance == 0\n-}\n-\n-fn merge_errors(\n-    old_errors: Vec<SyntaxError>,\n-    new_errors: Vec<SyntaxError>,\n-    old_node: SyntaxNodeRef,\n-    edit: &AtomEdit,\n-) -> Vec<SyntaxError> {\n-    let mut res = Vec::new();\n-    for e in old_errors {\n-        if e.offset < old_node.range().start() {\n-            res.push(e)\n-        } else if e.offset > old_node.range().end() {\n-            res.push(SyntaxError {\n-                msg: e.msg,\n-                offset: e.offset + TextUnit::of_str(&edit.insert) - edit.delete.len(),\n-            })\n-        }\n-    }\n-    for e in new_errors {\n-        res.push(SyntaxError {\n-            msg: e.msg,\n-            offset: e.offset + old_node.range().start(),\n-        })\n-    }\n-    res\n-}"}, {"sha": "da44913c53825d65261d65bb213a56b9d9418059", "filename": "crates/libsyntax2/src/reparsing.rs", "status": "added", "additions": 343, "deletions": 0, "changes": 343, "blob_url": "https://github.com/rust-lang/rust/blob/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Freparsing.rs?ref=2a56b5c4f096736d6795eecb835cc2dc14b00107", "patch": "@@ -0,0 +1,343 @@\n+use algo;\n+use grammar;\n+use lexer::{tokenize, Token};\n+use text_unit::{TextRange, TextUnit};\n+use yellow::{self, SyntaxNodeRef, GreenNode, SyntaxError};\n+use parser_impl;\n+use parser_api::Parser;\n+use {\n+    SyntaxKind::*,\n+};\n+use text_utils::replace_range;\n+\n+#[derive(Debug, Clone)]\n+pub struct AtomEdit {\n+    pub delete: TextRange,\n+    pub insert: String,\n+}\n+\n+impl AtomEdit {\n+    pub fn replace(range: TextRange, replace_with: String) -> AtomEdit {\n+        AtomEdit { delete: range, insert: replace_with }\n+    }\n+\n+    pub fn delete(range: TextRange) -> AtomEdit {\n+        AtomEdit::replace(range, String::new())\n+    }\n+\n+    pub fn insert(offset: TextUnit, text: String) -> AtomEdit {\n+        AtomEdit::replace(TextRange::offset_len(offset, 0.into()), text)\n+    }\n+}\n+\n+pub(crate) fn incremental_reparse(\n+    node: SyntaxNodeRef,\n+    edit: &AtomEdit,\n+    errors: Vec<SyntaxError>,\n+) -> Option<(GreenNode, Vec<SyntaxError>)> {\n+    let (node, green, new_errors) =\n+        reparse_leaf(node, &edit).or_else(|| reparse_block(node, &edit))?;\n+    let green_root = node.replace_with(green);\n+    let errors = merge_errors(errors, new_errors, node, edit);\n+    Some((green_root, errors))\n+}\n+\n+fn reparse_leaf<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    edit: &AtomEdit,\n+) -> Option<(SyntaxNodeRef<'node>, GreenNode, Vec<SyntaxError>)> {\n+    let node = algo::find_covering_node(node, edit.delete);\n+    match node.kind() {\n+        | WHITESPACE\n+        | COMMENT\n+        | DOC_COMMENT\n+        | IDENT\n+        | STRING\n+        | RAW_STRING => {\n+            let text = get_text_after_edit(node, &edit);\n+            let tokens = tokenize(&text);\n+            let token = match tokens[..] {\n+                [token] if token.kind == node.kind() => token,\n+                _ => return None,\n+            };\n+\n+            if token.kind == IDENT && is_contextual_kw(&text) {\n+                return None;\n+            }\n+\n+            let green = GreenNode::new_leaf(node.kind(), &text);\n+            let new_errors = vec![];\n+            Some((node, green, new_errors))\n+        }\n+        _ => None,\n+    }\n+}\n+\n+fn reparse_block<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    edit: &AtomEdit,\n+) -> Option<(SyntaxNodeRef<'node>, GreenNode, Vec<SyntaxError>)> {\n+    let (node, reparser) = find_reparsable_node(node, edit.delete)?;\n+    let text = get_text_after_edit(node, &edit);\n+    let tokens = tokenize(&text);\n+    if !is_balanced(&tokens) {\n+        return None;\n+    }\n+    let (green, new_errors) =\n+        parser_impl::parse_with::<yellow::GreenBuilder>(\n+            &text, &tokens, reparser,\n+        );\n+    Some((node, green, new_errors))\n+}\n+\n+fn get_text_after_edit(node: SyntaxNodeRef, edit: &AtomEdit) -> String {\n+    replace_range(\n+        node.text().to_string(),\n+        edit.delete - node.range().start(),\n+        &edit.insert,\n+    )\n+}\n+\n+fn is_contextual_kw(text: &str) -> bool {\n+    match text {\n+        | \"auto\"\n+        | \"default\"\n+        | \"union\" => true,\n+        _ => false,\n+    }\n+}\n+\n+fn find_reparsable_node<'node>(\n+    node: SyntaxNodeRef<'node>,\n+    range: TextRange,\n+) -> Option<(SyntaxNodeRef<'node>, fn(&mut Parser))> {\n+    let node = algo::find_covering_node(node, range);\n+    return algo::ancestors(node)\n+        .filter_map(|node| reparser(node).map(|r| (node, r)))\n+        .next();\n+\n+    fn reparser(node: SyntaxNodeRef) -> Option<fn(&mut Parser)> {\n+        let res = match node.kind() {\n+            BLOCK => grammar::block,\n+            NAMED_FIELD_DEF_LIST => grammar::named_field_def_list,\n+            NAMED_FIELD_LIST => grammar::named_field_list,\n+            ENUM_VARIANT_LIST => grammar::enum_variant_list,\n+            MATCH_ARM_LIST => grammar::match_arm_list,\n+            USE_TREE_LIST => grammar::use_tree_list,\n+            EXTERN_ITEM_LIST => grammar::extern_item_list,\n+            TOKEN_TREE if node.first_child().unwrap().kind() == L_CURLY => grammar::token_tree,\n+            ITEM_LIST => {\n+                let parent = node.parent().unwrap();\n+                match parent.kind() {\n+                    IMPL_ITEM => grammar::impl_item_list,\n+                    TRAIT_DEF => grammar::trait_item_list,\n+                    MODULE => grammar::mod_item_list,\n+                    _ => return None,\n+                }\n+            }\n+            _ => return None,\n+        };\n+        Some(res)\n+    }\n+}\n+\n+fn is_balanced(tokens: &[Token]) -> bool {\n+    if tokens.len() == 0\n+        || tokens.first().unwrap().kind != L_CURLY\n+        || tokens.last().unwrap().kind != R_CURLY {\n+        return false;\n+    }\n+    let mut balance = 0usize;\n+    for t in tokens.iter() {\n+        match t.kind {\n+            L_CURLY => balance += 1,\n+            R_CURLY => balance = match balance.checked_sub(1) {\n+                Some(b) => b,\n+                None => return false,\n+            },\n+            _ => (),\n+        }\n+    }\n+    balance == 0\n+}\n+\n+fn merge_errors(\n+    old_errors: Vec<SyntaxError>,\n+    new_errors: Vec<SyntaxError>,\n+    old_node: SyntaxNodeRef,\n+    edit: &AtomEdit,\n+) -> Vec<SyntaxError> {\n+    let mut res = Vec::new();\n+    for e in old_errors {\n+        if e.offset <= old_node.range().start() {\n+            res.push(e)\n+        } else if e.offset >= old_node.range().end() {\n+            res.push(SyntaxError {\n+                msg: e.msg,\n+                offset: e.offset + TextUnit::of_str(&edit.insert) - edit.delete.len(),\n+            })\n+        }\n+    }\n+    for e in new_errors {\n+        res.push(SyntaxError {\n+            msg: e.msg,\n+            offset: e.offset + old_node.range().start(),\n+        })\n+    }\n+    res\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::{\n+        super::{\n+            File,\n+            test_utils::extract_range,\n+            text_utils::replace_range,\n+            utils::dump_tree,\n+        },\n+        reparse_leaf, reparse_block, AtomEdit, GreenNode, SyntaxError, SyntaxNodeRef,\n+    };\n+\n+    fn do_check<F>(\n+        before: &str,\n+        replace_with: &str,\n+        reparser: F,\n+    ) where\n+        for<'a> F: Fn(\n+            SyntaxNodeRef<'a>,\n+            &AtomEdit,\n+        ) -> Option<(SyntaxNodeRef<'a>, GreenNode, Vec<SyntaxError>)>\n+    {\n+        let (range, before) = extract_range(before);\n+        let after = replace_range(before.clone(), range, replace_with);\n+\n+        let fully_reparsed = File::parse(&after);\n+        let incrementally_reparsed = {\n+            let f = File::parse(&before);\n+            let edit = AtomEdit { delete: range, insert: replace_with.to_string() };\n+            let (node, green, new_errors) =\n+                reparser(f.syntax(), &edit).expect(\"cannot incrementally reparse\");\n+            let green_root = node.replace_with(green);\n+            let errors = super::merge_errors(f.errors(), new_errors, node, &edit);\n+            File::new(green_root, errors)\n+        };\n+\n+        assert_eq_text!(\n+            &dump_tree(fully_reparsed.syntax()),\n+            &dump_tree(incrementally_reparsed.syntax()),\n+        )\n+    }\n+\n+    #[test]\n+    fn reparse_block_tests() {\n+        let do_check = |before, replace_to|\n+            do_check(before, replace_to, reparse_block);\n+\n+        do_check(r\"\n+fn foo() {\n+    let x = foo + <|>bar<|>\n+}\n+\", \"baz\");\n+        do_check(r\"\n+fn foo() {\n+    let x = foo<|> + bar<|>\n+}\n+\", \"baz\");\n+        do_check(r\"\n+struct Foo {\n+    f: foo<|><|>\n+}\n+\", \",\\n    g: (),\");\n+        do_check(r\"\n+fn foo {\n+    let;\n+    1 + 1;\n+    <|>92<|>;\n+}\n+\", \"62\");\n+        do_check(r\"\n+mod foo {\n+    fn <|><|>\n+}\n+\", \"bar\");\n+        do_check(r\"\n+trait Foo {\n+    type <|>Foo<|>;\n+}\n+\", \"Output\");\n+        do_check(r\"\n+impl IntoIterator<Item=i32> for Foo {\n+    f<|><|>\n+}\n+\", \"n next(\");\n+        do_check(r\"\n+use a::b::{foo,<|>,bar<|>};\n+    \", \"baz\");\n+        do_check(r\"\n+pub enum A {\n+    Foo<|><|>\n+}\n+\", \"\\nBar;\\n\");\n+        do_check(r\"\n+foo!{a, b<|><|> d}\n+\", \", c[3]\");\n+        do_check(r\"\n+fn foo() {\n+    vec![<|><|>]\n+}\n+\", \"123\");\n+        do_check(r\"\n+extern {\n+    fn<|>;<|>\n+}\n+\", \" exit(code: c_int)\");\n+    }\n+\n+    #[test]\n+    fn reparse_leaf_tests() {\n+        let do_check = |before, replace_to|\n+            do_check(before, replace_to, reparse_leaf);\n+\n+        do_check(r\"<|><|>\n+fn foo() -> i32 { 1 }\n+\", \"\\n\\n\\n   \\n\");\n+        do_check(r\"\n+fn foo() -> <|><|> {}\n+\", \"  \\n\");\n+        do_check(r\"\n+fn <|>foo<|>() -> i32 { 1 }\n+\", \"bar\");\n+        do_check(r\"\n+fn foo<|><|>foo() {  }\n+\", \"bar\");\n+        do_check(r\"\n+fn foo /* <|><|> */ () {}\n+\", \"some comment\");\n+        do_check(r\"\n+fn baz <|><|> () {}\n+\", \"    \\t\\t\\n\\n\");\n+        do_check(r\"\n+fn baz <|><|> () {}\n+\", \"    \\t\\t\\n\\n\");\n+        do_check(r\"\n+/// foo <|><|>omment\n+mod { }\n+\", \"c\");\n+        do_check(r#\"\n+fn -> &str { \"Hello<|><|>\" }\n+\"#, \", world\");\n+        do_check(r#\"\n+fn -> &str { // \"Hello<|><|>\"\n+\"#, \", world\");\n+        do_check(r##\"\n+fn -> &str { r#\"Hello<|><|>\"#\n+\"##, \", world\");\n+        do_check(r\"\n+#[derive(<|>Copy<|>)]\n+enum Foo {\n+\n+}\n+\", \"Clone\");\n+    }\n+}\n\\ No newline at end of file"}, {"sha": "58ae1e43e0a119ed559a84fddebf6349c25ec3fd", "filename": "crates/libsyntax2/src/text_utils.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Fsrc%2Ftext_utils.rs?ref=2a56b5c4f096736d6795eecb835cc2dc14b00107", "patch": "@@ -17,3 +17,10 @@ pub fn intersect(r1: TextRange, r2: TextRange) -> Option<TextRange> {\n         None\n     }\n }\n+\n+pub fn replace_range(mut text: String, range: TextRange, replace_with: &str) -> String {\n+    let start = u32::from(range.start()) as usize;\n+    let end = u32::from(range.end()) as usize;\n+    text.replace_range(start..end, replace_with);\n+    text\n+}\n\\ No newline at end of file"}, {"sha": "5a8879fcedc240eefc175aa7dd24e6d6e5587ab0", "filename": "crates/libsyntax2/tests/test/main.rs", "status": "modified", "additions": 1, "deletions": 75, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Ftests%2Ftest%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2a56b5c4f096736d6795eecb835cc2dc14b00107/crates%2Flibsyntax2%2Ftests%2Ftest%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Flibsyntax2%2Ftests%2Ftest%2Fmain.rs?ref=2a56b5c4f096736d6795eecb835cc2dc14b00107", "patch": "@@ -9,9 +9,8 @@ use std::{\n     fmt::Write,\n };\n \n-use test_utils::extract_range;\n use libsyntax2::{\n-    File, AtomEdit,\n+    File,\n     utils::{dump_tree, check_fuzz_invariants},\n };\n \n@@ -23,79 +22,6 @@ fn lexer_tests() {\n     })\n }\n \n-#[test]\n-fn reparse_test() {\n-    fn do_check(before: &str, replace_with: &str) {\n-        let (range, before) = extract_range(before);\n-        let after = libsyntax2::replace_range(before.clone(), range, replace_with);\n-\n-        let fully_reparsed = File::parse(&after);\n-        let incrementally_reparsed = {\n-            let f = File::parse(&before);\n-            let edit = AtomEdit { delete: range, insert: replace_with.to_string() };\n-            f.incremental_reparse(&edit).unwrap()\n-        };\n-        assert_eq_text!(\n-            &dump_tree(fully_reparsed.syntax()),\n-            &dump_tree(incrementally_reparsed.syntax()),\n-        )\n-    }\n-\n-    do_check(r\"\n-fn foo() {\n-    let x = foo + <|>bar<|>\n-}\n-\", \"baz\");\n-    do_check(r\"\n-struct Foo {\n-    f: foo<|><|>\n-}\n-\", \",\\n    g: (),\");\n-    do_check(r\"\n-fn foo {\n-    let;\n-    1 + 1;\n-    <|>92<|>;\n-}\n-\", \"62\");\n-    do_check(r\"\n-mod foo {\n-    fn <|><|>\n-}\n-\", \"bar\");\n-    do_check(r\"\n-trait Foo {\n-    type <|>Foo<|>;\n-}\n-\", \"Output\");\n-    do_check(r\"\n-impl IntoIterator<Item=i32> for Foo {\n-    f<|><|>\n-}\n-\", \"n next(\");\n-    do_check(r\"\n-use a::b::{foo,<|>,bar<|>};\n-    \", \"baz\");\n-    do_check(r\"\n-pub enum A {\n-    Foo<|><|>\n-}\n-\", \"\\nBar;\\n\");\n-    do_check(r\"\n-foo!{a, b<|><|> d}\n-\", \", c[3]\");\n-    do_check(r\"\n-fn foo() {\n-    vec![<|><|>]\n-}\n-\", \"123\");\n-    do_check(r\"\n-extern {\n-    fn<|>;<|>\n-}\n-\", \" exit(code: c_int)\");\n-}\n-\n #[test]\n fn parser_tests() {\n     dir_tests(&[\"parser/inline\", \"parser/ok\", \"parser/err\"], |text| {"}]}