{"sha": "86376e3aeae46f31ba14e82835ed27a063fb31e5", "node_id": "C_kwDOAAsO6NoAKDg2Mzc2ZTNhZWFlNDZmMzFiYTE0ZTgyODM1ZWQyN2EwNjNmYjMxZTU", "commit": {"author": {"name": "Dylan DPC", "email": "99973273+Dylan-DPC@users.noreply.github.com", "date": "2022-03-11T19:29:44Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-03-11T19:29:44Z"}, "message": "Rollup merge of #94798 - nnethercote:parse_tt-refactor, r=petrochenkov\n\n`parse_tt` refactorings\n\nSome readability improvements.\n\nr? ``@petrochenkov``", "tree": {"sha": "94afa2077dd644ff13444ddbff59333ca9b644ee", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/94afa2077dd644ff13444ddbff59333ca9b644ee"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/86376e3aeae46f31ba14e82835ed27a063fb31e5", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJiK6MoCRBK7hj4Ov3rIwAAwfgIAH2rPdWUEJyjw2o79ytVhiWb\nYyvu2TedeGGPBRMzv/mmAETWhHEZIFNgoea0runXh0N7ORaj7oHS+1BNHVlswsyo\nfHumhNRRaUm8pli/ZtfpV80i9XibmOy8KacDHuMlbO4XQ/GvQHGGn1PHLJOxWQ8r\nhDB+/Ap0Pe8uYGln0fC6gx6/BI6MvpeSVziRjPv43A7WkzLwYOajY19W+TwiPstq\nUG49jtKnzKdYI64YT8doXlPTG5MFN/QedVaxgx/01vRT2+tc6n4sWL/Uezb0wokM\nAezNCFqOP0bHG4yfg/3bUU7HW3xO36/Gv34Jzy/hHTI3GehYbqrSNtna47E9Lww=\n=n29D\n-----END PGP SIGNATURE-----\n", "payload": "tree 94afa2077dd644ff13444ddbff59333ca9b644ee\nparent 0e3ae8d2bf5fb892c79c7e22192c87f54adefa54\nparent 95d13fa37db8ddc6a7a45d5748a4484904830e25\nauthor Dylan DPC <99973273+Dylan-DPC@users.noreply.github.com> 1647026984 +0100\ncommitter GitHub <noreply@github.com> 1647026984 +0100\n\nRollup merge of #94798 - nnethercote:parse_tt-refactor, r=petrochenkov\n\n`parse_tt` refactorings\n\nSome readability improvements.\n\nr? ``@petrochenkov``\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/86376e3aeae46f31ba14e82835ed27a063fb31e5", "html_url": "https://github.com/rust-lang/rust/commit/86376e3aeae46f31ba14e82835ed27a063fb31e5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/86376e3aeae46f31ba14e82835ed27a063fb31e5/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0e3ae8d2bf5fb892c79c7e22192c87f54adefa54", "url": "https://api.github.com/repos/rust-lang/rust/commits/0e3ae8d2bf5fb892c79c7e22192c87f54adefa54", "html_url": "https://github.com/rust-lang/rust/commit/0e3ae8d2bf5fb892c79c7e22192c87f54adefa54"}, {"sha": "95d13fa37db8ddc6a7a45d5748a4484904830e25", "url": "https://api.github.com/repos/rust-lang/rust/commits/95d13fa37db8ddc6a7a45d5748a4484904830e25", "html_url": "https://github.com/rust-lang/rust/commit/95d13fa37db8ddc6a7a45d5748a4484904830e25"}], "stats": {"total": 246, "additions": 128, "deletions": 118}, "files": [{"sha": "dedfd779bb416d7af3459540a860919a7b7244e9", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 128, "deletions": 118, "changes": 246, "blob_url": "https://github.com/rust-lang/rust/blob/86376e3aeae46f31ba14e82835ed27a063fb31e5/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/86376e3aeae46f31ba14e82835ed27a063fb31e5/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=86376e3aeae46f31ba14e82835ed27a063fb31e5", "patch": "@@ -122,7 +122,7 @@ impl<'tt> TokenTreeOrTokenTreeSlice<'tt> {\n \n /// An unzipping of `TokenTree`s... see the `stack` field of `MatcherPos`.\n ///\n-/// This is used by `inner_parse_loop` to keep track of delimited submatchers that we have\n+/// This is used by `parse_tt_inner` to keep track of delimited submatchers that we have\n /// descended into.\n #[derive(Clone)]\n struct MatcherTtFrame<'tt> {\n@@ -439,9 +439,8 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n                 }\n                 Occupied(..) => return Err((sp, format!(\"duplicated bind name: {}\", bind_name))),\n             },\n-            // FIXME(c410-f3r) MetaVar and MetaVarExpr should be handled instead of being ignored\n-            // https://github.com/rust-lang/rust/issues/9390\n-            TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) | TokenTree::Token(..) => {}\n+            TokenTree::Token(..) => (),\n+            TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n         }\n \n         Ok(())\n@@ -481,21 +480,24 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n ///   successful execution of this function.\n /// - `next_items`: the set of newly generated items. These are used to replenish `cur_items` in\n ///   the function `parse`.\n-/// - `eof_items`: the set of items that would be valid if this was the EOF.\n /// - `bb_items`: the set of items that are waiting for the black-box parser.\n /// - `token`: the current token of the parser.\n ///\n /// # Returns\n ///\n-/// A `ParseResult`. Note that matches are kept track of through the items generated.\n-fn inner_parse_loop<'root, 'tt>(\n+/// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept track of\n+/// through the items generated.\n+fn parse_tt_inner<'root, 'tt>(\n     sess: &ParseSess,\n+    ms: &[TokenTree],\n     cur_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    next_items: &mut Vec<MatcherPosHandle<'root, 'tt>>,\n+    next_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n     bb_items: &mut SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n-    eof_items: &mut EofItems<'root, 'tt>,\n     token: &Token,\n-) -> Result<(), (rustc_span::Span, String)> {\n+) -> Option<NamedParseResult> {\n+    // Matcher positions that would be valid if the macro invocation was over now\n+    let mut eof_items = EofItems::None;\n+\n     // Pop items from `cur_items` until it is empty.\n     while let Some(mut item) = cur_items.pop() {\n         // When unzipped trees end, remove them. This corresponds to backtracking out of a\n@@ -522,6 +524,8 @@ fn inner_parse_loop<'root, 'tt>(\n             // then we could be at the end of a sequence or at the beginning of the next\n             // repetition.\n             if let Some(repetition) = &item.repetition {\n+                debug_assert!(matches!(item.top_elts, Tt(TokenTree::Sequence(..))));\n+\n                 // At this point, regardless of whether there is a separator, we should add all\n                 // matches from the complete repetition of the sequence to the shared, top-level\n                 // `matches` list (actually, `up.matches`, which could itself not be the top-level,\n@@ -565,7 +569,7 @@ fn inner_parse_loop<'root, 'tt>(\n             } else {\n                 // If we are not in a repetition, then being at the end of a matcher means that we\n                 // have reached the potential end of the input.\n-                *eof_items = match eof_items {\n+                eof_items = match eof_items {\n                     EofItems::None => EofItems::One(item),\n                     EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n                 }\n@@ -613,7 +617,7 @@ fn inner_parse_loop<'root, 'tt>(\n                 // We need to match a metavar (but the identifier is invalid)... this is an error\n                 TokenTree::MetaVarDecl(span, _, None) => {\n                     if sess.missing_fragment_specifiers.borrow_mut().remove(&span).is_some() {\n-                        return Err((span, \"missing fragment specifier\".to_string()));\n+                        return Some(Error(span, \"missing fragment specifier\".to_string()));\n                     }\n                 }\n \n@@ -655,13 +659,36 @@ fn inner_parse_loop<'root, 'tt>(\n                 // rules. NOTE that this is not necessarily an error unless _all_ items in\n                 // `cur_items` end up doing this. There may still be some other matchers that do\n                 // end up working out.\n-                TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => {}\n+                TokenTree::Token(..) => {}\n+\n+                TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n             }\n         }\n     }\n \n-    // Yay a successful parse (so far)!\n-    Ok(())\n+    // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n+    // either the parse is ambiguous (which should never happen) or there is a syntax error.\n+    if *token == token::Eof {\n+        Some(match eof_items {\n+            EofItems::One(mut eof_item) => {\n+                let matches =\n+                    eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n+                nameize(sess, ms, matches)\n+            }\n+            EofItems::Multiple => {\n+                Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n+            }\n+            EofItems::None => Failure(\n+                Token::new(\n+                    token::Eof,\n+                    if token.span.is_dummy() { token.span } else { token.span.shrink_to_hi() },\n+                ),\n+                \"missing tokens in macro arguments\",\n+            ),\n+        })\n+    } else {\n+        None\n+    }\n }\n \n /// Use the given sequence of token trees (`ms`) as a matcher. Match the token\n@@ -672,7 +699,7 @@ pub(super) fn parse_tt(\n     macro_name: Ident,\n ) -> NamedParseResult {\n     // A queue of possible matcher positions. We initialize it with the matcher position in which\n-    // the \"dot\" is before the first token of the first token tree in `ms`. `inner_parse_loop` then\n+    // the \"dot\" is before the first token of the first token tree in `ms`. `parse_tt_inner` then\n     // processes all of these possible matcher positions and produces possible next positions into\n     // `next_items`. After some post-processing, the contents of `next_items` replenish `cur_items`\n     // and we start over again.\n@@ -681,135 +708,118 @@ pub(super) fn parse_tt(\n     // there are frequently *no* others! -- are allocated on the heap.\n     let mut initial = MatcherPos::new(ms);\n     let mut cur_items = smallvec![MatcherPosHandle::Ref(&mut initial)];\n-    let mut next_items = Vec::new();\n \n     loop {\n-        assert!(next_items.is_empty());\n+        let mut next_items = SmallVec::new();\n \n         // Matcher positions black-box parsed by parser.rs (`parser`)\n         let mut bb_items = SmallVec::new();\n \n-        // Matcher positions that would be valid if the macro invocation was over now\n-        let mut eof_items = EofItems::None;\n-\n         // Process `cur_items` until either we have finished the input or we need to get some\n         // parsing from the black-box parser done. The result is that `next_items` will contain a\n         // bunch of possible next matcher positions in `next_items`.\n-        match inner_parse_loop(\n+        if let Some(result) = parse_tt_inner(\n             parser.sess,\n+            ms,\n             &mut cur_items,\n             &mut next_items,\n             &mut bb_items,\n-            &mut eof_items,\n             &parser.token,\n         ) {\n-            Ok(()) => {}\n-            Err((sp, msg)) => return Error(sp, msg),\n+            return result;\n         }\n \n-        // inner parse loop handled all cur_items, so it's empty\n+        // `parse_tt_inner` handled all cur_items, so it's empty.\n         assert!(cur_items.is_empty());\n \n-        // We need to do some post processing after the `inner_parse_loop`.\n+        // We need to do some post processing after the `parse_tt_inner`.\n         //\n         // Error messages here could be improved with links to original rules.\n \n-        // If we reached the EOF, check that there is EXACTLY ONE possible matcher. Otherwise,\n-        // either the parse is ambiguous (which should never happen) or there is a syntax error.\n-        if parser.token == token::Eof {\n-            return match eof_items {\n-                EofItems::One(mut eof_item) => {\n-                    let matches =\n-                        eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n-                    nameize(parser.sess, ms, matches)\n-                }\n-                EofItems::Multiple => {\n-                    Error(parser.token.span, \"ambiguity: multiple successful parses\".to_string())\n-                }\n-                EofItems::None => Failure(\n-                    Token::new(\n-                        token::Eof,\n-                        if parser.token.span.is_dummy() {\n-                            parser.token.span\n-                        } else {\n-                            parser.token.span.shrink_to_hi()\n-                        },\n-                    ),\n-                    \"missing tokens in macro arguments\",\n-                ),\n-            };\n-        }\n-        // Performance hack: `eof_items` may share matchers via `Rc` with other things that we want\n-        // to modify. Dropping `eof_items` now may drop these refcounts to 1, preventing an\n-        // unnecessary implicit clone later in `Rc::make_mut`.\n-        drop(eof_items);\n-\n-        // If there are no possible next positions AND we aren't waiting for the black-box parser,\n-        // then there is a syntax error.\n-        if bb_items.is_empty() && next_items.is_empty() {\n-            return Failure(parser.token.clone(), \"no rules expected this token in macro call\");\n-        }\n+        match (next_items.len(), bb_items.len()) {\n+            (0, 0) => {\n+                // There are no possible next positions AND we aren't waiting for the black-box\n+                // parser: syntax error.\n+                return Failure(parser.token.clone(), \"no rules expected this token in macro call\");\n+            }\n \n-        if (!bb_items.is_empty() && !next_items.is_empty()) || bb_items.len() > 1 {\n-            // We need to call out to parse some rust nonterminal (black-box) parser. But something\n-            // is wrong, because there is not EXACTLY ONE of these.\n-            let nts = bb_items\n-                .iter()\n-                .map(|item| match item.top_elts.get_tt(item.idx) {\n-                    TokenTree::MetaVarDecl(_, bind, Some(kind)) => format!(\"{} ('{}')\", kind, bind),\n-                    _ => panic!(),\n-                })\n-                .collect::<Vec<String>>()\n-                .join(\" or \");\n-\n-            return Error(\n-                parser.token.span,\n-                format!(\n-                    \"local ambiguity when calling macro `{macro_name}`: multiple parsing options: {}\",\n-                    match next_items.len() {\n-                        0 => format!(\"built-in NTs {}.\", nts),\n-                        1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n-                        n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n-                    }\n-                ),\n-            );\n-        }\n+            (_, 0) => {\n+                // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n+                // process the next token.\n+                cur_items.extend(next_items.drain(..));\n+                parser.to_mut().bump();\n+            }\n \n-        if !next_items.is_empty() {\n-            // Dump all possible `next_items` into `cur_items` for the next iteration. Then process\n-            // the next token.\n-            cur_items.extend(next_items.drain(..));\n-            parser.to_mut().bump();\n-        } else {\n-            // Finally, we have the case where we need to call the black-box parser to get some\n-            // nonterminal.\n-            assert_eq!(bb_items.len(), 1);\n-\n-            let mut item = bb_items.pop().unwrap();\n-            if let TokenTree::MetaVarDecl(span, _, Some(kind)) = item.top_elts.get_tt(item.idx) {\n-                let match_cur = item.match_cur;\n-                // We use the span of the metavariable declaration to determine any\n-                // edition-specific matching behavior for non-terminals.\n-                let nt = match parser.to_mut().parse_nonterminal(kind) {\n-                    Err(mut err) => {\n-                        err.span_label(\n-                            span,\n-                            format!(\"while parsing argument for this `{}` macro fragment\", kind),\n-                        )\n-                        .emit();\n-                        return ErrorReported;\n-                    }\n-                    Ok(nt) => nt,\n-                };\n-                item.push_match(match_cur, MatchedNonterminal(Lrc::new(nt)));\n-                item.idx += 1;\n-                item.match_cur += 1;\n-            } else {\n-                unreachable!()\n+            (0, 1) => {\n+                // We need to call the black-box parser to get some nonterminal.\n+                let mut item = bb_items.pop().unwrap();\n+                if let TokenTree::MetaVarDecl(span, _, Some(kind)) = item.top_elts.get_tt(item.idx)\n+                {\n+                    let match_cur = item.match_cur;\n+                    // We use the span of the metavariable declaration to determine any\n+                    // edition-specific matching behavior for non-terminals.\n+                    let nt = match parser.to_mut().parse_nonterminal(kind) {\n+                        Err(mut err) => {\n+                            err.span_label(\n+                                span,\n+                                format!(\"while parsing argument for this `{kind}` macro fragment\"),\n+                            )\n+                            .emit();\n+                            return ErrorReported;\n+                        }\n+                        Ok(nt) => nt,\n+                    };\n+                    item.push_match(match_cur, MatchedNonterminal(Lrc::new(nt)));\n+                    item.idx += 1;\n+                    item.match_cur += 1;\n+                } else {\n+                    unreachable!()\n+                }\n+                cur_items.push(item);\n+            }\n+\n+            (_, _) => {\n+                // We need to call the black-box parser to get some nonterminal, but something is\n+                // wrong.\n+                return bb_items_ambiguity_error(\n+                    macro_name,\n+                    next_items,\n+                    bb_items,\n+                    parser.token.span,\n+                );\n             }\n-            cur_items.push(item);\n         }\n \n         assert!(!cur_items.is_empty());\n     }\n }\n+\n+fn bb_items_ambiguity_error<'root, 'tt>(\n+    macro_name: Ident,\n+    next_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+    bb_items: SmallVec<[MatcherPosHandle<'root, 'tt>; 1]>,\n+    token_span: rustc_span::Span,\n+) -> NamedParseResult {\n+    let nts = bb_items\n+        .iter()\n+        .map(|item| match item.top_elts.get_tt(item.idx) {\n+            TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n+                format!(\"{} ('{}')\", kind, bind)\n+            }\n+            _ => panic!(),\n+        })\n+        .collect::<Vec<String>>()\n+        .join(\" or \");\n+\n+    Error(\n+        token_span,\n+        format!(\n+            \"local ambiguity when calling macro `{macro_name}`: multiple parsing options: {}\",\n+            match next_items.len() {\n+                0 => format!(\"built-in NTs {}.\", nts),\n+                1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n+                n => format!(\"built-in NTs {} or {} other options.\", nts, n),\n+            }\n+        ),\n+    )\n+}"}]}