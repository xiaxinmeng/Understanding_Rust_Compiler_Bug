{"sha": "27bf62b70eeb6f4cb620be5630c4c4506be3539f", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI3YmY2MmI3MGVlYjZmNGNiNjIwYmU1NjMwYzRjNDUwNmJlMzUzOWY=", "commit": {"author": {"name": "Jonas Schievink", "email": "jonasschievink@gmail.com", "date": "2021-05-24T16:43:42Z"}, "committer": {"name": "Jonas Schievink", "email": "jonasschievink@gmail.com", "date": "2021-05-24T16:43:42Z"}, "message": "Move `TokenMap` to its own file", "tree": {"sha": "4630dfb5f82b533f013a706aed14a31e8721a899", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4630dfb5f82b533f013a706aed14a31e8721a899"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/27bf62b70eeb6f4cb620be5630c4c4506be3539f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/27bf62b70eeb6f4cb620be5630c4c4506be3539f", "html_url": "https://github.com/rust-lang/rust/commit/27bf62b70eeb6f4cb620be5630c4c4506be3539f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/27bf62b70eeb6f4cb620be5630c4c4506be3539f/comments", "author": {"login": "jonas-schievink", "id": 1786438, "node_id": "MDQ6VXNlcjE3ODY0Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1786438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonas-schievink", "html_url": "https://github.com/jonas-schievink", "followers_url": "https://api.github.com/users/jonas-schievink/followers", "following_url": "https://api.github.com/users/jonas-schievink/following{/other_user}", "gists_url": "https://api.github.com/users/jonas-schievink/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonas-schievink/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonas-schievink/subscriptions", "organizations_url": "https://api.github.com/users/jonas-schievink/orgs", "repos_url": "https://api.github.com/users/jonas-schievink/repos", "events_url": "https://api.github.com/users/jonas-schievink/events{/privacy}", "received_events_url": "https://api.github.com/users/jonas-schievink/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jonas-schievink", "id": 1786438, "node_id": "MDQ6VXNlcjE3ODY0Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1786438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonas-schievink", "html_url": "https://github.com/jonas-schievink", "followers_url": "https://api.github.com/users/jonas-schievink/followers", "following_url": "https://api.github.com/users/jonas-schievink/following{/other_user}", "gists_url": "https://api.github.com/users/jonas-schievink/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonas-schievink/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonas-schievink/subscriptions", "organizations_url": "https://api.github.com/users/jonas-schievink/orgs", "repos_url": "https://api.github.com/users/jonas-schievink/repos", "events_url": "https://api.github.com/users/jonas-schievink/events{/privacy}", "received_events_url": "https://api.github.com/users/jonas-schievink/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "01f8d40c5cb28854091d2081b7aa607ad9902930", "url": "https://api.github.com/repos/rust-lang/rust/commits/01f8d40c5cb28854091d2081b7aa607ad9902930", "html_url": "https://github.com/rust-lang/rust/commit/01f8d40c5cb28854091d2081b7aa607ad9902930"}], "stats": {"total": 170, "additions": 89, "deletions": 81}, "files": [{"sha": "b7aa647136ee25c6e24de7e92f9f09613047d45b", "filename": "crates/mbe/src/lib.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Flib.rs?ref=27bf62b70eeb6f4cb620be5630c4c4506be3539f", "patch": "@@ -14,6 +14,7 @@ mod tests;\n \n #[cfg(test)]\n mod benchmark;\n+mod token_map;\n \n use std::fmt;\n \n@@ -65,8 +66,9 @@ impl fmt::Display for ExpandError {\n \n pub use crate::syntax_bridge::{\n     ast_to_token_tree, parse_exprs_with_sep, parse_to_token_tree, syntax_node_to_token_tree,\n-    token_tree_to_syntax_node, TokenMap,\n+    token_tree_to_syntax_node,\n };\n+pub use crate::token_map::TokenMap;\n \n /// This struct contains AST for a single `macro_rules` definition. What might\n /// be very confusing is that AST has almost exactly the same shape as"}, {"sha": "b11172caf026f6bd1fb8182ae9d05259f1c8b768", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 3, "deletions": 80, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=27bf62b70eeb6f4cb620be5630c4c4506be3539f", "patch": "@@ -10,36 +10,8 @@ use syntax::{\n };\n use tt::buffer::{Cursor, TokenBuffer};\n \n-use crate::ExpandError;\n use crate::{subtree_source::SubtreeTokenSource, tt_iter::TtIter};\n-\n-#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n-pub enum TokenTextRange {\n-    Token(TextRange),\n-    Delimiter(TextRange),\n-}\n-\n-impl TokenTextRange {\n-    pub fn by_kind(self, kind: SyntaxKind) -> Option<TextRange> {\n-        match self {\n-            TokenTextRange::Token(it) => Some(it),\n-            TokenTextRange::Delimiter(it) => match kind {\n-                T!['{'] | T!['('] | T!['['] => Some(TextRange::at(it.start(), 1.into())),\n-                T!['}'] | T![')'] | T![']'] => {\n-                    Some(TextRange::at(it.end() - TextSize::of('}'), 1.into()))\n-                }\n-                _ => None,\n-            },\n-        }\n-    }\n-}\n-\n-/// Maps `tt::TokenId` to the relative range of the original token.\n-#[derive(Debug, PartialEq, Eq, Clone, Default)]\n-pub struct TokenMap {\n-    /// Maps `tt::TokenId` to the *relative* source range.\n-    entries: Vec<(tt::TokenId, TokenTextRange)>,\n-}\n+use crate::{ExpandError, TokenMap};\n \n /// Convert the syntax tree (what user has written) to a `TokenTree` (what macro\n /// will consume).\n@@ -53,7 +25,7 @@ pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> (tt::Subtree, TokenMap) {\n     let global_offset = node.text_range().start();\n     let mut c = Convertor::new(node, global_offset);\n     let subtree = c.go();\n-    c.id_alloc.map.entries.shrink_to_fit();\n+    c.id_alloc.map.shrink_to_fit();\n     (subtree, c.id_alloc.map)\n }\n \n@@ -149,55 +121,6 @@ pub fn parse_exprs_with_sep(tt: &tt::Subtree, sep: char) -> Vec<tt::Subtree> {\n     res\n }\n \n-impl TokenMap {\n-    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n-        let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {\n-            TokenTextRange::Token(it) => *it == relative_range,\n-            TokenTextRange::Delimiter(it) => {\n-                let open = TextRange::at(it.start(), 1.into());\n-                let close = TextRange::at(it.end() - TextSize::of('}'), 1.into());\n-                open == relative_range || close == relative_range\n-            }\n-        })?;\n-        Some(token_id)\n-    }\n-\n-    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TokenTextRange> {\n-        let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n-        Some(range)\n-    }\n-\n-    fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n-        self.entries.push((token_id, TokenTextRange::Token(relative_range)));\n-    }\n-\n-    fn insert_delim(\n-        &mut self,\n-        token_id: tt::TokenId,\n-        open_relative_range: TextRange,\n-        close_relative_range: TextRange,\n-    ) -> usize {\n-        let res = self.entries.len();\n-        let cover = open_relative_range.cover(close_relative_range);\n-\n-        self.entries.push((token_id, TokenTextRange::Delimiter(cover)));\n-        res\n-    }\n-\n-    fn update_close_delim(&mut self, idx: usize, close_relative_range: TextRange) {\n-        let (_, token_text_range) = &mut self.entries[idx];\n-        if let TokenTextRange::Delimiter(dim) = token_text_range {\n-            let cover = dim.cover(close_relative_range);\n-            *token_text_range = TokenTextRange::Delimiter(cover);\n-        }\n-    }\n-\n-    fn remove_delim(&mut self, idx: usize) {\n-        // FIXME: This could be accidentally quadratic\n-        self.entries.remove(idx);\n-    }\n-}\n-\n /// Returns the textual content of a doc comment block as a quoted string\n /// That is, strips leading `///` (or `/**`, etc)\n /// and strips the ending `*/`\n@@ -634,7 +557,7 @@ impl<'a> TtTreeSink<'a> {\n     }\n \n     fn finish(mut self) -> (Parse<SyntaxNode>, TokenMap) {\n-        self.token_map.entries.shrink_to_fit();\n+        self.token_map.shrink_to_fit();\n         (self.inner.finish(), self.token_map)\n     }\n }"}, {"sha": "58c9f5aa5245c07dbe9992274af91c664ac02661", "filename": "crates/mbe/src/token_map.rs", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27bf62b70eeb6f4cb620be5630c4c4506be3539f/crates%2Fmbe%2Fsrc%2Ftoken_map.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftoken_map.rs?ref=27bf62b70eeb6f4cb620be5630c4c4506be3539f", "patch": "@@ -0,0 +1,83 @@\n+use parser::{SyntaxKind, T};\n+use syntax::{TextRange, TextSize};\n+\n+#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n+pub enum TokenTextRange {\n+    Token(TextRange),\n+    Delimiter(TextRange),\n+}\n+\n+impl TokenTextRange {\n+    pub fn by_kind(self, kind: SyntaxKind) -> Option<TextRange> {\n+        match self {\n+            TokenTextRange::Token(it) => Some(it),\n+            TokenTextRange::Delimiter(it) => match kind {\n+                T!['{'] | T!['('] | T!['['] => Some(TextRange::at(it.start(), 1.into())),\n+                T!['}'] | T![')'] | T![']'] => {\n+                    Some(TextRange::at(it.end() - TextSize::of('}'), 1.into()))\n+                }\n+                _ => None,\n+            },\n+        }\n+    }\n+}\n+\n+/// Maps `tt::TokenId` to the relative range of the original token.\n+#[derive(Debug, PartialEq, Eq, Clone, Default)]\n+pub struct TokenMap {\n+    /// Maps `tt::TokenId` to the *relative* source range.\n+    entries: Vec<(tt::TokenId, TokenTextRange)>,\n+}\n+\n+impl TokenMap {\n+    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n+        let &(token_id, _) = self.entries.iter().find(|(_, range)| match range {\n+            TokenTextRange::Token(it) => *it == relative_range,\n+            TokenTextRange::Delimiter(it) => {\n+                let open = TextRange::at(it.start(), 1.into());\n+                let close = TextRange::at(it.end() - TextSize::of('}'), 1.into());\n+                open == relative_range || close == relative_range\n+            }\n+        })?;\n+        Some(token_id)\n+    }\n+\n+    pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TokenTextRange> {\n+        let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n+        Some(range)\n+    }\n+\n+    pub(crate) fn shrink_to_fit(&mut self) {\n+        self.entries.shrink_to_fit();\n+    }\n+\n+    pub(crate) fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n+        self.entries.push((token_id, TokenTextRange::Token(relative_range)));\n+    }\n+\n+    pub(crate) fn insert_delim(\n+        &mut self,\n+        token_id: tt::TokenId,\n+        open_relative_range: TextRange,\n+        close_relative_range: TextRange,\n+    ) -> usize {\n+        let res = self.entries.len();\n+        let cover = open_relative_range.cover(close_relative_range);\n+\n+        self.entries.push((token_id, TokenTextRange::Delimiter(cover)));\n+        res\n+    }\n+\n+    pub(crate) fn update_close_delim(&mut self, idx: usize, close_relative_range: TextRange) {\n+        let (_, token_text_range) = &mut self.entries[idx];\n+        if let TokenTextRange::Delimiter(dim) = token_text_range {\n+            let cover = dim.cover(close_relative_range);\n+            *token_text_range = TokenTextRange::Delimiter(cover);\n+        }\n+    }\n+\n+    pub(crate) fn remove_delim(&mut self, idx: usize) {\n+        // FIXME: This could be accidentally quadratic\n+        self.entries.remove(idx);\n+    }\n+}"}]}