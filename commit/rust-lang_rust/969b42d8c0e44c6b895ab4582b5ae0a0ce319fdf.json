{"sha": "969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "node_id": "MDY6Q29tbWl0NzI0NzEyOjk2OWI0MmQ4YzBlNDRjNmI4OTVhYjQ1ODJiNWFlMGEwY2UzMTlmZGY=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-12-22T21:51:04Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2020-12-22T21:51:04Z"}, "message": "Auto merge of #80242 - Nadrieril:explain-and-factor-splitting, r=varkor\n\nClarify constructor splitting in exhaustiveness checking\n\nI reworked the explanation of the algorithm completely to make it properly account for the various extensions we've added. This includes constructor splitting, which was previously not clearly included in the algorithm. This makes wildcards less magical; I added some detailed examples; and this distinguishes clearly between constructors that only make sense in patterns (like ranges) and those that make sense for values (like `Some`). This reformulation had been floating around in my mind for a while, and I'm quite happy with how it turned out. Let me know how you feel about it.\nI also factored out all three cases of splitting (wildcards, ranges and slices) into dedicated structs to encapsulate the complicated bits.\nI measured no perf impact but I don't trust my local measurements for refactors since https://github.com/rust-lang/rust/pull/79284.\n\nr? `@varkor`\n`@rustbot` modify labels: +A-exhaustiveness-checking", "tree": {"sha": "ff50a6612e3b57bc1a121247d9f967ed287c6ff6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ff50a6612e3b57bc1a121247d9f967ed287c6ff6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "html_url": "https://github.com/rust-lang/rust/commit/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bb1fbbf84455fbad9afd26c17e0f725019322655", "url": "https://api.github.com/repos/rust-lang/rust/commits/bb1fbbf84455fbad9afd26c17e0f725019322655", "html_url": "https://github.com/rust-lang/rust/commit/bb1fbbf84455fbad9afd26c17e0f725019322655"}, {"sha": "be23694622609c27d52042be6b506bf69848acbe", "url": "https://api.github.com/repos/rust-lang/rust/commits/be23694622609c27d52042be6b506bf69848acbe", "html_url": "https://github.com/rust-lang/rust/commit/be23694622609c27d52042be6b506bf69848acbe"}], "stats": {"total": 1682, "additions": 895, "deletions": 787}, "files": [{"sha": "d79dd97a69a75a61e1300ea5b24493f055e55855", "filename": "compiler/rustc_mir_build/src/thir/pattern/deconstruct_pat.rs", "status": "modified", "additions": 573, "deletions": 507, "changes": 1080, "blob_url": "https://github.com/rust-lang/rust/blob/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fdeconstruct_pat.rs?ref=969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "patch": "@@ -1,6 +1,47 @@\n-//! This module provides functions to deconstruct and reconstruct patterns into a constructor\n-//! applied to some fields. This is used by the `_match` module to compute pattern\n-//! usefulness/exhaustiveness.\n+//! [`super::usefulness`] explains most of what is happening in this file. As explained there,\n+//! values and patterns are made from constructors applied to fields. This file defines a\n+//! `Constructor` enum, a `Fields` struct, and various operations to manipulate them and convert\n+//! them from/to patterns.\n+//!\n+//! There's one idea that is not detailed in [`super::usefulness`] because the details are not\n+//! needed there: _constructor splitting_.\n+//!\n+//! # Constructor splitting\n+//!\n+//! The idea is as follows: given a constructor `c` and a matrix, we want to specialize in turn\n+//! with all the value constructors that are covered by `c`, and compute usefulness for each.\n+//! Instead of listing all those constructors (which is intractable), we group those value\n+//! constructors together as much as possible. Example:\n+//!\n+//! ```\n+//! match (0, false) {\n+//!     (0 ..=100, true) => {} // `p_1`\n+//!     (50..=150, false) => {} // `p_2`\n+//!     (0 ..=200, _) => {} // `q`\n+//! }\n+//! ```\n+//!\n+//! The naive approach would try all numbers in the range `0..=200`. But we can be a lot more\n+//! clever: `0` and `1` for example will match the exact same rows, and return equivalent\n+//! witnesses. In fact all of `0..50` would. We can thus restrict our exploration to 4\n+//! constructors: `0..50`, `50..=100`, `101..=150` and `151..=200`. That is enough and infinitely\n+//! more tractable.\n+//!\n+//! We capture this idea in a function `split(p_1 ... p_n, c)` which returns a list of constructors\n+//! `c'` covered by `c`. Given such a `c'`, we require that all value ctors `c''` covered by `c'`\n+//! return an equivalent set of witnesses after specializing and computing usefulness.\n+//! In the example above, witnesses for specializing by `c''` covered by `0..50` will only differ\n+//! in their first element.\n+//!\n+//! We usually also ask that the `c'` together cover all of the original `c`. However we allow\n+//! skipping some constructors as long as it doesn't change whether the resulting list of witnesses\n+//! is empty of not. We use this in the wildcard `_` case.\n+//!\n+//! Splitting is implemented in the [`Constructor::split`] function. We don't do splitting for\n+//! or-patterns; instead we just try the alternatives one-by-one. For details on splitting\n+//! wildcards, see [`SplitWildcard`]; for integer ranges, see [`SplitIntRange`]; for slices, see\n+//! [`SplitVarLenSlice`].\n+\n use self::Constructor::*;\n use self::SliceKind::*;\n \n@@ -24,7 +65,7 @@ use rustc_target::abi::{Integer, Size, VariantIdx};\n \n use smallvec::{smallvec, SmallVec};\n use std::cmp::{self, max, min, Ordering};\n-use std::iter::IntoIterator;\n+use std::iter::{once, IntoIterator};\n use std::ops::RangeInclusive;\n \n /// An inclusive interval, used for precise integer exhaustiveness checking.\n@@ -183,126 +224,39 @@ impl IntRange {\n         Pat { ty, span: DUMMY_SP, kind: Box::new(kind) }\n     }\n \n-    /// For exhaustive integer matching, some constructors are grouped within other constructors\n-    /// (namely integer typed values are grouped within ranges). However, when specialising these\n-    /// constructors, we want to be specialising for the underlying constructors (the integers), not\n-    /// the groups (the ranges). Thus we need to split the groups up. Splitting them up na\u00efvely would\n-    /// mean creating a separate constructor for every single value in the range, which is clearly\n-    /// impractical. However, observe that for some ranges of integers, the specialisation will be\n-    /// identical across all values in that range (i.e., there are equivalence classes of ranges of\n-    /// constructors based on their `U(S(c, P), S(c, p))` outcome). These classes are grouped by\n-    /// the patterns that apply to them (in the matrix `P`). We can split the range whenever the\n-    /// patterns that apply to that range (specifically: the patterns that *intersect* with that range)\n-    /// change.\n-    /// Our solution, therefore, is to split the range constructor into subranges at every single point\n-    /// the group of intersecting patterns changes (using the method described below).\n-    /// And voil\u00e0! We're testing precisely those ranges that we need to, without any exhaustive matching\n-    /// on actual integers. The nice thing about this is that the number of subranges is linear in the\n-    /// number of rows in the matrix (i.e., the number of cases in the `match` statement), so we don't\n-    /// need to be worried about matching over gargantuan ranges.\n-    ///\n-    /// Essentially, given the first column of a matrix representing ranges, looking like the following:\n-    ///\n-    /// |------|  |----------| |-------|    ||\n-    ///    |-------| |-------|            |----| ||\n-    ///       |---------|\n-    ///\n-    /// We split the ranges up into equivalence classes so the ranges are no longer overlapping:\n-    ///\n-    /// |--|--|||-||||--||---|||-------|  |-|||| ||\n-    ///\n-    /// The logic for determining how to split the ranges is fairly straightforward: we calculate\n-    /// boundaries for each interval range, sort them, then create constructors for each new interval\n-    /// between every pair of boundary points. (This essentially sums up to performing the intuitive\n-    /// merging operation depicted above.)\n-    fn split<'p, 'tcx>(\n+    /// Lint on likely incorrect range patterns (#63987)\n+    pub(super) fn lint_overlapping_range_endpoints<'a, 'tcx: 'a>(\n         &self,\n-        pcx: PatCtxt<'_, 'p, 'tcx>,\n-        hir_id: Option<HirId>,\n-    ) -> SmallVec<[Constructor<'tcx>; 1]> {\n-        /// Represents a border between 2 integers. Because the intervals spanning borders\n-        /// must be able to cover every integer, we need to be able to represent\n-        /// 2^128 + 1 such borders.\n-        #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Debug)]\n-        enum Border {\n-            JustBefore(u128),\n-            AfterMax,\n+        pcx: PatCtxt<'_, '_, 'tcx>,\n+        ctors: impl Iterator<Item = (&'a Constructor<'tcx>, Span)>,\n+        column_count: usize,\n+        hir_id: HirId,\n+    ) {\n+        if self.is_singleton() {\n+            return;\n         }\n \n-        // A function for extracting the borders of an integer interval.\n-        fn range_borders(r: IntRange) -> impl Iterator<Item = Border> {\n-            let (lo, hi) = r.range.into_inner();\n-            let from = Border::JustBefore(lo);\n-            let to = match hi.checked_add(1) {\n-                Some(m) => Border::JustBefore(m),\n-                None => Border::AfterMax,\n-            };\n-            vec![from, to].into_iter()\n+        if column_count != 1 {\n+            // FIXME: for now, only check for overlapping ranges on simple range\n+            // patterns. Otherwise with the current logic the following is detected\n+            // as overlapping:\n+            // ```\n+            // match (0u8, true) {\n+            //   (0 ..= 125, false) => {}\n+            //   (125 ..= 255, true) => {}\n+            //   _ => {}\n+            // }\n+            // ```\n+            return;\n         }\n \n-        // Collect the span and range of all the intersecting ranges to lint on likely\n-        // incorrect range patterns. (#63987)\n-        let mut overlaps = vec![];\n-        let row_len = pcx.matrix.column_count().unwrap_or(0);\n-        // `borders` is the set of borders between equivalence classes: each equivalence\n-        // class lies between 2 borders.\n-        let row_borders = pcx\n-            .matrix\n-            .head_ctors_and_spans(pcx.cx)\n+        let overlaps: Vec<_> = ctors\n             .filter_map(|(ctor, span)| Some((ctor.as_int_range()?, span)))\n-            .filter_map(|(range, span)| {\n-                let intersection = self.intersection(&range);\n-                let should_lint = self.suspicious_intersection(&range);\n-                if let (Some(range), 1, true) = (&intersection, row_len, should_lint) {\n-                    // FIXME: for now, only check for overlapping ranges on simple range\n-                    // patterns. Otherwise with the current logic the following is detected\n-                    // as overlapping:\n-                    // ```\n-                    // match (0u8, true) {\n-                    //   (0 ..= 125, false) => {}\n-                    //   (125 ..= 255, true) => {}\n-                    //   _ => {}\n-                    // }\n-                    // ```\n-                    overlaps.push((range.clone(), span));\n-                }\n-                intersection\n-            })\n-            .flat_map(range_borders);\n-        let self_borders = range_borders(self.clone());\n-        let mut borders: Vec<_> = row_borders.chain(self_borders).collect();\n-        borders.sort_unstable();\n-\n-        self.lint_overlapping_range_endpoints(pcx, hir_id, overlaps);\n-\n-        // We're going to iterate through every adjacent pair of borders, making sure that\n-        // each represents an interval of nonnegative length, and convert each such\n-        // interval into a constructor.\n-        borders\n-            .array_windows()\n-            .filter_map(|&pair| match pair {\n-                [Border::JustBefore(n), Border::JustBefore(m)] => {\n-                    if n < m {\n-                        Some(n..=(m - 1))\n-                    } else {\n-                        None\n-                    }\n-                }\n-                [Border::JustBefore(n), Border::AfterMax] => Some(n..=u128::MAX),\n-                [Border::AfterMax, _] => None,\n-            })\n-            .map(|range| IntRange { range })\n-            .map(IntRange)\n-            .collect()\n-    }\n+            .filter(|(range, _)| self.suspicious_intersection(range))\n+            .map(|(range, span)| (self.intersection(&range).unwrap(), span))\n+            .collect();\n \n-    fn lint_overlapping_range_endpoints(\n-        &self,\n-        pcx: PatCtxt<'_, '_, '_>,\n-        hir_id: Option<HirId>,\n-        overlaps: Vec<(IntRange, Span)>,\n-    ) {\n-        if let (true, Some(hir_id)) = (!overlaps.is_empty(), hir_id) {\n+        if !overlaps.is_empty() {\n             pcx.cx.tcx.struct_span_lint_hir(\n                 lint::builtin::OVERLAPPING_RANGE_ENDPOINTS,\n                 hir_id,\n@@ -339,6 +293,101 @@ impl IntRange {\n     }\n }\n \n+/// Represents a border between 2 integers. Because the intervals spanning borders must be able to\n+/// cover every integer, we need to be able to represent 2^128 + 1 such borders.\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\n+enum IntBorder {\n+    JustBefore(u128),\n+    AfterMax,\n+}\n+\n+/// A range of integers that is partitioned into disjoint subranges. This does constructor\n+/// splitting for integer ranges as explained at the top of the file.\n+///\n+/// This is fed multiple ranges, and returns an output that covers the input, but is split so that\n+/// the only intersections between an output range and a seen range are inclusions. No output range\n+/// straddles the boundary of one of the inputs.\n+///\n+/// The following input:\n+/// ```\n+///   |-------------------------| // `self`\n+/// |------|  |----------|   |----|\n+///    |-------| |-------|\n+/// ```\n+/// would be iterated over as follows:\n+/// ```\n+///   ||---|--||-|---|---|---|--|\n+/// ```\n+#[derive(Debug, Clone)]\n+struct SplitIntRange {\n+    /// The range we are splitting\n+    range: IntRange,\n+    /// The borders of ranges we have seen. They are all contained within `range`. This is kept\n+    /// sorted.\n+    borders: Vec<IntBorder>,\n+}\n+\n+impl SplitIntRange {\n+    fn new(r: IntRange) -> Self {\n+        SplitIntRange { range: r.clone(), borders: Vec::new() }\n+    }\n+\n+    /// Internal use\n+    fn to_borders(r: IntRange) -> [IntBorder; 2] {\n+        use IntBorder::*;\n+        let (lo, hi) = r.boundaries();\n+        let lo = JustBefore(lo);\n+        let hi = match hi.checked_add(1) {\n+            Some(m) => JustBefore(m),\n+            None => AfterMax,\n+        };\n+        [lo, hi]\n+    }\n+\n+    /// Add ranges relative to which we split.\n+    fn split(&mut self, ranges: impl Iterator<Item = IntRange>) {\n+        let this_range = &self.range;\n+        let included_ranges = ranges.filter_map(|r| this_range.intersection(&r));\n+        let included_borders = included_ranges.flat_map(|r| {\n+            let borders = Self::to_borders(r);\n+            once(borders[0]).chain(once(borders[1]))\n+        });\n+        self.borders.extend(included_borders);\n+        self.borders.sort_unstable();\n+    }\n+\n+    /// Iterate over the contained ranges.\n+    fn iter<'a>(&'a self) -> impl Iterator<Item = IntRange> + Captures<'a> {\n+        use IntBorder::*;\n+\n+        let self_range = Self::to_borders(self.range.clone());\n+        // Start with the start of the range.\n+        let mut prev_border = self_range[0];\n+        self.borders\n+            .iter()\n+            .copied()\n+            // End with the end of the range.\n+            .chain(once(self_range[1]))\n+            // List pairs of adjacent borders.\n+            .map(move |border| {\n+                let ret = (prev_border, border);\n+                prev_border = border;\n+                ret\n+            })\n+            // Skip duplicates.\n+            .filter(|(prev_border, border)| prev_border != border)\n+            // Finally, convert to ranges.\n+            .map(|(prev_border, border)| {\n+                let range = match (prev_border, border) {\n+                    (JustBefore(n), JustBefore(m)) if n < m => n..=(m - 1),\n+                    (JustBefore(n), AfterMax) => n..=u128::MAX,\n+                    _ => unreachable!(), // Ruled out by the sorting and filtering we did\n+                };\n+                IntRange { range }\n+            })\n+    }\n+}\n+\n #[derive(Copy, Clone, Debug, PartialEq, Eq)]\n enum SliceKind {\n     /// Patterns of length `n` (`[x, y]`).\n@@ -391,129 +440,141 @@ impl Slice {\n         self.kind.arity()\n     }\n \n-    /// The exhaustiveness-checking paper does not include any details on\n-    /// checking variable-length slice patterns. However, they may be\n-    /// matched by an infinite collection of fixed-length array patterns.\n-    ///\n-    /// Checking the infinite set directly would take an infinite amount\n-    /// of time. However, it turns out that for each finite set of\n-    /// patterns `P`, all sufficiently large array lengths are equivalent:\n-    ///\n-    /// Each slice `s` with a \"sufficiently-large\" length `l \u2265 L` that applies\n-    /// to exactly the subset `P\u209c` of `P` can be transformed to a slice\n-    /// `s\u2098` for each sufficiently-large length `m` that applies to exactly\n-    /// the same subset of `P`.\n-    ///\n-    /// Because of that, each witness for reachability-checking of one\n-    /// of the sufficiently-large lengths can be transformed to an\n-    /// equally-valid witness of any other length, so we only have\n-    /// to check slices of the \"minimal sufficiently-large length\"\n-    /// and less.\n-    ///\n-    /// Note that the fact that there is a *single* `s\u2098` for each `m`\n-    /// not depending on the specific pattern in `P` is important: if\n-    /// you look at the pair of patterns\n-    ///     `[true, ..]`\n-    ///     `[.., false]`\n-    /// Then any slice of length \u22651 that matches one of these two\n-    /// patterns can be trivially turned to a slice of any\n-    /// other length \u22651 that matches them and vice-versa,\n-    /// but the slice of length 2 `[false, true]` that matches neither\n-    /// of these patterns can't be turned to a slice from length 1 that\n-    /// matches neither of these patterns, so we have to consider\n-    /// slices from length 2 there.\n-    ///\n-    /// Now, to see that that length exists and find it, observe that slice\n-    /// patterns are either \"fixed-length\" patterns (`[_, _, _]`) or\n-    /// \"variable-length\" patterns (`[_, .., _]`).\n-    ///\n-    /// For fixed-length patterns, all slices with lengths *longer* than\n-    /// the pattern's length have the same outcome (of not matching), so\n-    /// as long as `L` is greater than the pattern's length we can pick\n-    /// any `s\u2098` from that length and get the same result.\n-    ///\n-    /// For variable-length patterns, the situation is more complicated,\n-    /// because as seen above the precise value of `s\u2098` matters.\n-    ///\n-    /// However, for each variable-length pattern `p` with a prefix of length\n-    /// `pl\u209a` and suffix of length `sl\u209a`, only the first `pl\u209a` and the last\n-    /// `sl\u209a` elements are examined.\n-    ///\n-    /// Therefore, as long as `L` is positive (to avoid concerns about empty\n-    /// types), all elements after the maximum prefix length and before\n-    /// the maximum suffix length are not examined by any variable-length\n-    /// pattern, and therefore can be added/removed without affecting\n-    /// them - creating equivalent patterns from any sufficiently-large\n-    /// length.\n-    ///\n-    /// Of course, if fixed-length patterns exist, we must be sure\n-    /// that our length is large enough to miss them all, so\n-    /// we can pick `L = max(max(FIXED_LEN)+1, max(PREFIX_LEN) + max(SUFFIX_LEN))`\n-    ///\n-    /// for example, with the above pair of patterns, all elements\n-    /// but the first and last can be added/removed, so any\n-    /// witness of length \u22652 (say, `[false, false, true]`) can be\n-    /// turned to a witness from any other length \u22652.\n-    fn split<'p, 'tcx>(self, pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Constructor<'tcx>; 1]> {\n-        let (self_prefix, self_suffix) = match self.kind {\n-            VarLen(self_prefix, self_suffix) => (self_prefix, self_suffix),\n-            _ => return smallvec![Slice(self)],\n-        };\n+    /// See `Constructor::is_covered_by`\n+    fn is_covered_by(self, other: Self) -> bool {\n+        other.kind.covers_length(self.arity())\n+    }\n+}\n+\n+/// This computes constructor splitting for variable-length slices, as explained at the top of the\n+/// file.\n+///\n+/// A slice pattern `[x, .., y]` behaves like the infinite or-pattern `[x, y] | [x, _, y] | [x, _,\n+/// _, y] | ...`. The corresponding value constructors are fixed-length array constructors above a\n+/// given minimum length. We obviously can't list this infinitude of constructors. Thankfully,\n+/// it turns out that for each finite set of slice patterns, all sufficiently large array lengths\n+/// are equivalent.\n+///\n+/// Let's look at an example, where we are trying to split the last pattern:\n+/// ```\n+/// match x {\n+///     [true, true, ..] => {}\n+///     [.., false, false] => {}\n+///     [..] => {}\n+/// }\n+/// ```\n+/// Here are the results of specialization for the first few lengths:\n+/// ```\n+/// // length 0\n+/// [] => {}\n+/// // length 1\n+/// [_] => {}\n+/// // length 2\n+/// [true, true] => {}\n+/// [false, false] => {}\n+/// [_, _] => {}\n+/// // length 3\n+/// [true, true,  _    ] => {}\n+/// [_,    false, false] => {}\n+/// [_,    _,     _    ] => {}\n+/// // length 4\n+/// [true, true, _,     _    ] => {}\n+/// [_,    _,    false, false] => {}\n+/// [_,    _,    _,     _    ] => {}\n+/// // length 5\n+/// [true, true, _, _,     _    ] => {}\n+/// [_,    _,    _, false, false] => {}\n+/// [_,    _,    _, _,     _    ] => {}\n+/// ```\n+///\n+/// If we went above length 5, we would simply be inserting more columns full of wildcards in the\n+/// middle. This means that the set of witnesses for length `l >= 5` if equivalent to the set for\n+/// any other `l' >= 5`: simply add or remove wildcards in the middle to convert between them.\n+///\n+/// This applies to any set of slice patterns: there will be a length `L` above which all lengths\n+/// behave the same. This is exactly what we need for constructor splitting. Therefore a\n+/// variable-length slice can be split into a variable-length slice of minimal length `L`, and many\n+/// fixed-length slices of lengths `< L`.\n+///\n+/// For each variable-length pattern `p` with a prefix of length `pl\u209a` and suffix of length `sl\u209a`,\n+/// only the first `pl\u209a` and the last `sl\u209a` elements are examined. Therefore, as long as `L` is\n+/// positive (to avoid concerns about empty types), all elements after the maximum prefix length\n+/// and before the maximum suffix length are not examined by any variable-length pattern, and\n+/// therefore can be added/removed without affecting them - creating equivalent patterns from any\n+/// sufficiently-large length.\n+///\n+/// Of course, if fixed-length patterns exist, we must be sure that our length is large enough to\n+/// miss them all, so we can pick `L = max(max(FIXED_LEN)+1, max(PREFIX_LEN) + max(SUFFIX_LEN))`\n+///\n+/// `max_slice` below will be made to have arity `L`.\n+#[derive(Debug)]\n+struct SplitVarLenSlice {\n+    /// If the type is an array, this is its size.\n+    array_len: Option<u64>,\n+    /// The arity of the input slice.\n+    arity: u64,\n+    /// The smallest slice bigger than any slice seen. `max_slice.arity()` is the length `L`\n+    /// described above.\n+    max_slice: SliceKind,\n+}\n \n-        let head_ctors = pcx.matrix.head_ctors(pcx.cx).filter(|c| !c.is_wildcard());\n+impl SplitVarLenSlice {\n+    fn new(prefix: u64, suffix: u64, array_len: Option<u64>) -> Self {\n+        SplitVarLenSlice { array_len, arity: prefix + suffix, max_slice: VarLen(prefix, suffix) }\n+    }\n \n-        let mut max_prefix_len = self_prefix;\n-        let mut max_suffix_len = self_suffix;\n+    /// Pass a set of slices relative to which to split this one.\n+    fn split(&mut self, slices: impl Iterator<Item = SliceKind>) {\n+        let (max_prefix_len, max_suffix_len) = match &mut self.max_slice {\n+            VarLen(prefix, suffix) => (prefix, suffix),\n+            FixedLen(_) => return, // No need to split\n+        };\n+        // We grow `self.max_slice` to be larger than all slices encountered, as described above.\n+        // For diagnostics, we keep the prefix and suffix lengths separate, but grow them so that\n+        // `L = max_prefix_len + max_suffix_len`.\n         let mut max_fixed_len = 0;\n-\n-        for ctor in head_ctors {\n-            if let Slice(slice) = ctor {\n-                match slice.kind {\n-                    FixedLen(len) => {\n-                        max_fixed_len = cmp::max(max_fixed_len, len);\n-                    }\n-                    VarLen(prefix, suffix) => {\n-                        max_prefix_len = cmp::max(max_prefix_len, prefix);\n-                        max_suffix_len = cmp::max(max_suffix_len, suffix);\n-                    }\n+        for slice in slices {\n+            match slice {\n+                FixedLen(len) => {\n+                    max_fixed_len = cmp::max(max_fixed_len, len);\n+                }\n+                VarLen(prefix, suffix) => {\n+                    *max_prefix_len = cmp::max(*max_prefix_len, prefix);\n+                    *max_suffix_len = cmp::max(*max_suffix_len, suffix);\n                 }\n-            } else {\n-                bug!(\"unexpected ctor for slice type: {:?}\", ctor);\n             }\n         }\n-\n-        // For diagnostics, we keep the prefix and suffix lengths separate, so in the case\n-        // where `max_fixed_len + 1` is the largest, we adapt `max_prefix_len` accordingly,\n-        // so that `L = max_prefix_len + max_suffix_len`.\n-        if max_fixed_len + 1 >= max_prefix_len + max_suffix_len {\n+        // We want `L = max(L, max_fixed_len + 1)`, modulo the fact that we keep prefix and\n+        // suffix separate.\n+        if max_fixed_len + 1 >= *max_prefix_len + *max_suffix_len {\n             // The subtraction can't overflow thanks to the above check.\n-            // The new `max_prefix_len` is also guaranteed to be larger than its previous\n-            // value.\n-            max_prefix_len = max_fixed_len + 1 - max_suffix_len;\n+            // The new `max_prefix_len` is larger than its previous value.\n+            *max_prefix_len = max_fixed_len + 1 - *max_suffix_len;\n         }\n \n-        let final_slice = VarLen(max_prefix_len, max_suffix_len);\n-        let final_slice = Slice::new(self.array_len, final_slice);\n+        // We cap the arity of `max_slice` at the array size.\n         match self.array_len {\n-            Some(_) => smallvec![Slice(final_slice)],\n-            None => {\n-                // `self` originally covered the range `(self.arity()..infinity)`. We split that\n-                // range into two: lengths smaller than `final_slice.arity()` are treated\n-                // independently as fixed-lengths slices, and lengths above are captured by\n-                // `final_slice`.\n-                let smaller_lengths = (self.arity()..final_slice.arity()).map(FixedLen);\n-                smaller_lengths\n-                    .map(|kind| Slice::new(self.array_len, kind))\n-                    .chain(Some(final_slice))\n-                    .map(Slice)\n-                    .collect()\n-            }\n+            Some(len) if self.max_slice.arity() >= len => self.max_slice = FixedLen(len),\n+            _ => {}\n         }\n     }\n \n-    /// See `Constructor::is_covered_by`\n-    fn is_covered_by(self, other: Self) -> bool {\n-        other.kind.covers_length(self.arity())\n+    /// Iterate over the partition of this slice.\n+    fn iter<'a>(&'a self) -> impl Iterator<Item = Slice> + Captures<'a> {\n+        let smaller_lengths = match self.array_len {\n+            // The only admissible fixed-length slice is one of the array size. Whether `max_slice`\n+            // is fixed-length or variable-length, it will be the only relevant slice to output\n+            // here.\n+            Some(_) => (0..0), // empty range\n+            // We cover all arities in the range `(self.arity..infinity)`. We split that range into\n+            // two: lengths smaller than `max_slice.arity()` are treated independently as\n+            // fixed-lengths slices, and lengths above are captured by `max_slice`.\n+            None => self.arity..self.max_slice.arity(),\n+        };\n+        smaller_lengths\n+            .map(FixedLen)\n+            .chain(once(self.max_slice))\n+            .map(move |kind| Slice::new(self.array_len, kind))\n     }\n }\n \n@@ -546,6 +607,9 @@ pub(super) enum Constructor<'tcx> {\n     /// Fake extra constructor for enums that aren't allowed to be matched exhaustively. Also used\n     /// for those types for which we cannot list constructors explicitly, like `f64` and `str`.\n     NonExhaustive,\n+    /// Stands for constructors that are not seen in the matrix, as explained in the documentation\n+    /// for [`SplitWildcard`].\n+    Missing,\n     /// Wildcard pattern.\n     Wildcard,\n }\n@@ -652,48 +716,41 @@ impl<'tcx> Constructor<'tcx> {\n     /// This function may discard some irrelevant constructors if this preserves behavior and\n     /// diagnostics. Eg. for the `_` case, we ignore the constructors already present in the\n     /// matrix, unless all of them are.\n-    ///\n-    /// `hir_id` is `None` when we're evaluating the wildcard pattern. In that case we do not want\n-    /// to lint for overlapping ranges.\n-    pub(super) fn split<'p>(\n+    pub(super) fn split<'a>(\n         &self,\n-        pcx: PatCtxt<'_, 'p, 'tcx>,\n-        hir_id: Option<HirId>,\n-    ) -> SmallVec<[Self; 1]> {\n-        debug!(\"Constructor::split({:#?}, {:#?})\", self, pcx.matrix);\n+        pcx: PatCtxt<'_, '_, 'tcx>,\n+        ctors: impl Iterator<Item = &'a Constructor<'tcx>> + Clone,\n+    ) -> SmallVec<[Self; 1]>\n+    where\n+        'tcx: 'a,\n+    {\n+        debug!(\"Constructor::split({:#?})\", self);\n \n         match self {\n-            Wildcard => Constructor::split_wildcard(pcx),\n+            Wildcard => {\n+                let mut split_wildcard = SplitWildcard::new(pcx);\n+                split_wildcard.split(pcx, ctors);\n+                split_wildcard.into_ctors(pcx)\n+            }\n             // Fast-track if the range is trivial. In particular, we don't do the overlapping\n             // ranges check.\n-            IntRange(ctor_range) if !ctor_range.is_singleton() => ctor_range.split(pcx, hir_id),\n-            Slice(slice @ Slice { kind: VarLen(..), .. }) => slice.split(pcx),\n+            IntRange(ctor_range) if !ctor_range.is_singleton() => {\n+                let mut split_range = SplitIntRange::new(ctor_range.clone());\n+                let int_ranges = ctors.filter_map(|ctor| ctor.as_int_range());\n+                split_range.split(int_ranges.cloned());\n+                split_range.iter().map(IntRange).collect()\n+            }\n+            &Slice(Slice { kind: VarLen(self_prefix, self_suffix), array_len }) => {\n+                let mut split_self = SplitVarLenSlice::new(self_prefix, self_suffix, array_len);\n+                let slices = ctors.filter_map(|c| c.as_slice()).map(|s| s.kind);\n+                split_self.split(slices);\n+                split_self.iter().map(Slice).collect()\n+            }\n             // Any other constructor can be used unchanged.\n             _ => smallvec![self.clone()],\n         }\n     }\n \n-    /// For wildcards, there are two groups of constructors: there are the constructors actually\n-    /// present in the matrix (`head_ctors`), and the constructors not present (`missing_ctors`).\n-    /// Two constructors that are not in the matrix will either both be caught (by a wildcard), or\n-    /// both not be caught. Therefore we can keep the missing constructors grouped together.\n-    fn split_wildcard<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> SmallVec<[Self; 1]> {\n-        // Missing constructors are those that are not matched by any non-wildcard patterns in the\n-        // current column. We only fully construct them on-demand, because they're rarely used and\n-        // can be big.\n-        let missing_ctors = MissingConstructors::new(pcx);\n-        if missing_ctors.is_empty(pcx) {\n-            // All the constructors are present in the matrix, so we just go through them all.\n-            // We must also split them first.\n-            missing_ctors.all_ctors\n-        } else {\n-            // Some constructors are missing, thus we can specialize with the wildcard constructor,\n-            // which will stand for those constructors that are missing, and behaves like any of\n-            // them.\n-            smallvec![Wildcard]\n-        }\n-    }\n-\n     /// Returns whether `self` is covered by `other`, i.e. whether `self` is a subset of `other`.\n     /// For the simple cases, this is simply checking for equality. For the \"grouped\" constructors,\n     /// this checks for inclusion.\n@@ -704,8 +761,8 @@ impl<'tcx> Constructor<'tcx> {\n         match (self, other) {\n             // Wildcards cover anything\n             (_, Wildcard) => true,\n-            // Wildcards are only covered by wildcards\n-            (Wildcard, _) => false,\n+            // The missing ctors are not covered by anything in the matrix except wildcards.\n+            (Missing | Wildcard, _) => false,\n \n             (Single, Single) => true,\n             (Variant(self_id), Variant(other_id)) => self_id == other_id,\n@@ -778,247 +835,253 @@ impl<'tcx> Constructor<'tcx> {\n                 .any(|other| slice.is_covered_by(other)),\n             // This constructor is never covered by anything else\n             NonExhaustive => false,\n-            Str(..) | FloatRange(..) | Opaque | Wildcard => {\n+            Str(..) | FloatRange(..) | Opaque | Missing | Wildcard => {\n                 span_bug!(pcx.span, \"found unexpected ctor in all_ctors: {:?}\", self)\n             }\n         }\n     }\n }\n \n-/// This determines the set of all possible constructors of a pattern matching\n-/// values of type `left_ty`. For vectors, this would normally be an infinite set\n-/// but is instead bounded by the maximum fixed length of slice patterns in\n-/// the column of patterns being analyzed.\n+/// A wildcard constructor that we split relative to the constructors in the matrix, as explained\n+/// at the top of the file.\n ///\n-/// We make sure to omit constructors that are statically impossible. E.g., for\n-/// `Option<!>`, we do not include `Some(_)` in the returned list of constructors.\n-/// Invariant: this returns an empty `Vec` if and only if the type is uninhabited (as determined by\n-/// `cx.is_uninhabited()`).\n-fn all_constructors<'p, 'tcx>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Vec<Constructor<'tcx>> {\n-    debug!(\"all_constructors({:?})\", pcx.ty);\n-    let cx = pcx.cx;\n-    let make_range = |start, end| {\n-        IntRange(\n-            // `unwrap()` is ok because we know the type is an integer.\n-            IntRange::from_range(cx.tcx, start, end, pcx.ty, &RangeEnd::Included).unwrap(),\n-        )\n-    };\n-    match pcx.ty.kind() {\n-        ty::Bool => vec![make_range(0, 1)],\n-        ty::Array(sub_ty, len) if len.try_eval_usize(cx.tcx, cx.param_env).is_some() => {\n-            let len = len.eval_usize(cx.tcx, cx.param_env);\n-            if len != 0 && cx.is_uninhabited(sub_ty) {\n-                vec![]\n-            } else {\n-                vec![Slice(Slice::new(Some(len), VarLen(0, 0)))]\n-            }\n-        }\n-        // Treat arrays of a constant but unknown length like slices.\n-        ty::Array(sub_ty, _) | ty::Slice(sub_ty) => {\n-            let kind = if cx.is_uninhabited(sub_ty) { FixedLen(0) } else { VarLen(0, 0) };\n-            vec![Slice(Slice::new(None, kind))]\n-        }\n-        ty::Adt(def, substs) if def.is_enum() => {\n-            // If the enum is declared as `#[non_exhaustive]`, we treat it as if it had an\n-            // additional \"unknown\" constructor.\n-            // There is no point in enumerating all possible variants, because the user can't\n-            // actually match against them all themselves. So we always return only the fictitious\n-            // constructor.\n-            // E.g., in an example like:\n-            //\n-            // ```\n-            //     let err: io::ErrorKind = ...;\n-            //     match err {\n-            //         io::ErrorKind::NotFound => {},\n-            //     }\n-            // ```\n-            //\n-            // we don't want to show every possible IO error, but instead have only `_` as the\n-            // witness.\n-            let is_declared_nonexhaustive = cx.is_foreign_non_exhaustive_enum(pcx.ty);\n-\n-            // If `exhaustive_patterns` is disabled and our scrutinee is an empty enum, we treat it\n-            // as though it had an \"unknown\" constructor to avoid exposing its emptiness. The\n-            // exception is if the pattern is at the top level, because we want empty matches to be\n-            // considered exhaustive.\n-            let is_secretly_empty = def.variants.is_empty()\n-                && !cx.tcx.features().exhaustive_patterns\n-                && !pcx.is_top_level;\n-\n-            if is_secretly_empty || is_declared_nonexhaustive {\n-                vec![NonExhaustive]\n-            } else if cx.tcx.features().exhaustive_patterns {\n-                // If `exhaustive_patterns` is enabled, we exclude variants known to be\n-                // uninhabited.\n-                def.variants\n-                    .iter()\n-                    .filter(|v| {\n-                        !v.uninhabited_from(cx.tcx, substs, def.adt_kind(), cx.param_env)\n-                            .contains(cx.tcx, cx.module)\n-                    })\n-                    .map(|v| Variant(v.def_id))\n-                    .collect()\n-            } else {\n-                def.variants.iter().map(|v| Variant(v.def_id)).collect()\n-            }\n-        }\n-        ty::Char => {\n-            vec![\n-                // The valid Unicode Scalar Value ranges.\n-                make_range('\\u{0000}' as u128, '\\u{D7FF}' as u128),\n-                make_range('\\u{E000}' as u128, '\\u{10FFFF}' as u128),\n-            ]\n-        }\n-        ty::Int(_) | ty::Uint(_)\n-            if pcx.ty.is_ptr_sized_integral()\n-                && !cx.tcx.features().precise_pointer_size_matching =>\n-        {\n-            // `usize`/`isize` are not allowed to be matched exhaustively unless the\n-            // `precise_pointer_size_matching` feature is enabled. So we treat those types like\n-            // `#[non_exhaustive]` enums by returning a special unmatcheable constructor.\n-            vec![NonExhaustive]\n-        }\n-        &ty::Int(ity) => {\n-            let bits = Integer::from_attr(&cx.tcx, SignedInt(ity)).size().bits() as u128;\n-            let min = 1u128 << (bits - 1);\n-            let max = min - 1;\n-            vec![make_range(min, max)]\n-        }\n-        &ty::Uint(uty) => {\n-            let size = Integer::from_attr(&cx.tcx, UnsignedInt(uty)).size();\n-            let max = size.truncate(u128::MAX);\n-            vec![make_range(0, max)]\n-        }\n-        // If `exhaustive_patterns` is disabled and our scrutinee is the never type, we cannot\n-        // expose its emptiness. The exception is if the pattern is at the top level, because we\n-        // want empty matches to be considered exhaustive.\n-        ty::Never if !cx.tcx.features().exhaustive_patterns && !pcx.is_top_level => {\n-            vec![NonExhaustive]\n-        }\n-        ty::Never => vec![],\n-        _ if cx.is_uninhabited(pcx.ty) => vec![],\n-        ty::Adt(..) | ty::Tuple(..) | ty::Ref(..) => vec![Single],\n-        // This type is one for which we cannot list constructors, like `str` or `f64`.\n-        _ => vec![NonExhaustive],\n-    }\n-}\n-\n-// A struct to compute a set of constructors equivalent to `all_ctors \\ used_ctors`.\n+/// A constructor that is not present in the matrix rows will only be covered by the rows that have\n+/// wildcards. Thus we can group all of those constructors together; we call them \"missing\n+/// constructors\". Splitting a wildcard would therefore list all present constructors individually\n+/// (or grouped if they are integers or slices), and then all missing constructors together as a\n+/// group.\n+///\n+/// However we can go further: since any constructor will match the wildcard rows, and having more\n+/// rows can only reduce the amount of usefulness witnesses, we can skip the present constructors\n+/// and only try the missing ones.\n+/// This will not preserve the whole list of witnesses, but will preserve whether the list is empty\n+/// or not. In fact this is quite natural from the point of view of diagnostics too. This is done\n+/// in `to_ctors`: in some cases we only return `Missing`.\n #[derive(Debug)]\n-pub(super) struct MissingConstructors<'tcx> {\n+pub(super) struct SplitWildcard<'tcx> {\n+    /// Constructors seen in the matrix.\n+    matrix_ctors: Vec<Constructor<'tcx>>,\n+    /// All the constructors for this type\n     all_ctors: SmallVec<[Constructor<'tcx>; 1]>,\n-    used_ctors: Vec<Constructor<'tcx>>,\n }\n \n-impl<'tcx> MissingConstructors<'tcx> {\n+impl<'tcx> SplitWildcard<'tcx> {\n     pub(super) fn new<'p>(pcx: PatCtxt<'_, 'p, 'tcx>) -> Self {\n-        let used_ctors: Vec<Constructor<'_>> =\n-            pcx.matrix.head_ctors(pcx.cx).cloned().filter(|c| !c.is_wildcard()).collect();\n-        // Since `all_ctors` never contains wildcards, this won't recurse further.\n-        let all_ctors =\n-            all_constructors(pcx).into_iter().flat_map(|ctor| ctor.split(pcx, None)).collect();\n+        debug!(\"SplitWildcard::new({:?})\", pcx.ty);\n+        let cx = pcx.cx;\n+        let make_range = |start, end| {\n+            IntRange(\n+                // `unwrap()` is ok because we know the type is an integer.\n+                IntRange::from_range(cx.tcx, start, end, pcx.ty, &RangeEnd::Included).unwrap(),\n+            )\n+        };\n+        // This determines the set of all possible constructors for the type `pcx.ty`. For numbers,\n+        // arrays and slices we use ranges and variable-length slices when appropriate.\n+        //\n+        // If the `exhaustive_patterns` feature is enabled, we make sure to omit constructors that\n+        // are statically impossible. E.g., for `Option<!>`, we do not include `Some(_)` in the\n+        // returned list of constructors.\n+        // Invariant: this is empty if and only if the type is uninhabited (as determined by\n+        // `cx.is_uninhabited()`).\n+        let all_ctors = match pcx.ty.kind() {\n+            ty::Bool => smallvec![make_range(0, 1)],\n+            ty::Array(sub_ty, len) if len.try_eval_usize(cx.tcx, cx.param_env).is_some() => {\n+                let len = len.eval_usize(cx.tcx, cx.param_env);\n+                if len != 0 && cx.is_uninhabited(sub_ty) {\n+                    smallvec![]\n+                } else {\n+                    smallvec![Slice(Slice::new(Some(len), VarLen(0, 0)))]\n+                }\n+            }\n+            // Treat arrays of a constant but unknown length like slices.\n+            ty::Array(sub_ty, _) | ty::Slice(sub_ty) => {\n+                let kind = if cx.is_uninhabited(sub_ty) { FixedLen(0) } else { VarLen(0, 0) };\n+                smallvec![Slice(Slice::new(None, kind))]\n+            }\n+            ty::Adt(def, substs) if def.is_enum() => {\n+                // If the enum is declared as `#[non_exhaustive]`, we treat it as if it had an\n+                // additional \"unknown\" constructor.\n+                // There is no point in enumerating all possible variants, because the user can't\n+                // actually match against them all themselves. So we always return only the fictitious\n+                // constructor.\n+                // E.g., in an example like:\n+                //\n+                // ```\n+                //     let err: io::ErrorKind = ...;\n+                //     match err {\n+                //         io::ErrorKind::NotFound => {},\n+                //     }\n+                // ```\n+                //\n+                // we don't want to show every possible IO error, but instead have only `_` as the\n+                // witness.\n+                let is_declared_nonexhaustive = cx.is_foreign_non_exhaustive_enum(pcx.ty);\n+\n+                // If `exhaustive_patterns` is disabled and our scrutinee is an empty enum, we treat it\n+                // as though it had an \"unknown\" constructor to avoid exposing its emptiness. The\n+                // exception is if the pattern is at the top level, because we want empty matches to be\n+                // considered exhaustive.\n+                let is_secretly_empty = def.variants.is_empty()\n+                    && !cx.tcx.features().exhaustive_patterns\n+                    && !pcx.is_top_level;\n+\n+                if is_secretly_empty || is_declared_nonexhaustive {\n+                    smallvec![NonExhaustive]\n+                } else if cx.tcx.features().exhaustive_patterns {\n+                    // If `exhaustive_patterns` is enabled, we exclude variants known to be\n+                    // uninhabited.\n+                    def.variants\n+                        .iter()\n+                        .filter(|v| {\n+                            !v.uninhabited_from(cx.tcx, substs, def.adt_kind(), cx.param_env)\n+                                .contains(cx.tcx, cx.module)\n+                        })\n+                        .map(|v| Variant(v.def_id))\n+                        .collect()\n+                } else {\n+                    def.variants.iter().map(|v| Variant(v.def_id)).collect()\n+                }\n+            }\n+            ty::Char => {\n+                smallvec![\n+                    // The valid Unicode Scalar Value ranges.\n+                    make_range('\\u{0000}' as u128, '\\u{D7FF}' as u128),\n+                    make_range('\\u{E000}' as u128, '\\u{10FFFF}' as u128),\n+                ]\n+            }\n+            ty::Int(_) | ty::Uint(_)\n+                if pcx.ty.is_ptr_sized_integral()\n+                    && !cx.tcx.features().precise_pointer_size_matching =>\n+            {\n+                // `usize`/`isize` are not allowed to be matched exhaustively unless the\n+                // `precise_pointer_size_matching` feature is enabled. So we treat those types like\n+                // `#[non_exhaustive]` enums by returning a special unmatcheable constructor.\n+                smallvec![NonExhaustive]\n+            }\n+            &ty::Int(ity) => {\n+                let bits = Integer::from_attr(&cx.tcx, SignedInt(ity)).size().bits() as u128;\n+                let min = 1u128 << (bits - 1);\n+                let max = min - 1;\n+                smallvec![make_range(min, max)]\n+            }\n+            &ty::Uint(uty) => {\n+                let size = Integer::from_attr(&cx.tcx, UnsignedInt(uty)).size();\n+                let max = size.truncate(u128::MAX);\n+                smallvec![make_range(0, max)]\n+            }\n+            // If `exhaustive_patterns` is disabled and our scrutinee is the never type, we cannot\n+            // expose its emptiness. The exception is if the pattern is at the top level, because we\n+            // want empty matches to be considered exhaustive.\n+            ty::Never if !cx.tcx.features().exhaustive_patterns && !pcx.is_top_level => {\n+                smallvec![NonExhaustive]\n+            }\n+            ty::Never => smallvec![],\n+            _ if cx.is_uninhabited(pcx.ty) => smallvec![],\n+            ty::Adt(..) | ty::Tuple(..) | ty::Ref(..) => smallvec![Single],\n+            // This type is one for which we cannot list constructors, like `str` or `f64`.\n+            _ => smallvec![NonExhaustive],\n+        };\n+        SplitWildcard { matrix_ctors: Vec::new(), all_ctors }\n+    }\n \n-        MissingConstructors { all_ctors, used_ctors }\n+    /// Pass a set of constructors relative to which to split this one. Don't call twice, it won't\n+    /// do what you want.\n+    pub(super) fn split<'a>(\n+        &mut self,\n+        pcx: PatCtxt<'_, '_, 'tcx>,\n+        ctors: impl Iterator<Item = &'a Constructor<'tcx>> + Clone,\n+    ) where\n+        'tcx: 'a,\n+    {\n+        // Since `all_ctors` never contains wildcards, this won't recurse further.\n+        self.all_ctors =\n+            self.all_ctors.iter().flat_map(|ctor| ctor.split(pcx, ctors.clone())).collect();\n+        self.matrix_ctors = ctors.filter(|c| !c.is_wildcard()).cloned().collect();\n     }\n \n-    fn is_empty<'p>(&self, pcx: PatCtxt<'_, 'p, 'tcx>) -> bool {\n-        self.iter(pcx).next().is_none()\n+    /// Whether there are any value constructors for this type that are not present in the matrix.\n+    fn any_missing(&self, pcx: PatCtxt<'_, '_, 'tcx>) -> bool {\n+        self.iter_missing(pcx).next().is_some()\n     }\n \n-    /// Iterate over all_ctors \\ used_ctors\n-    fn iter<'a, 'p>(\n+    /// Iterate over the constructors for this type that are not present in the matrix.\n+    pub(super) fn iter_missing<'a, 'p>(\n         &'a self,\n         pcx: PatCtxt<'a, 'p, 'tcx>,\n     ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'p> {\n-        self.all_ctors.iter().filter(move |ctor| !ctor.is_covered_by_any(pcx, &self.used_ctors))\n+        self.all_ctors.iter().filter(move |ctor| !ctor.is_covered_by_any(pcx, &self.matrix_ctors))\n     }\n \n-    /// List the patterns corresponding to the missing constructors. In some cases, instead of\n-    /// listing all constructors of a given type, we prefer to simply report a wildcard.\n-    pub(super) fn report_patterns<'p>(\n-        &self,\n-        pcx: PatCtxt<'_, 'p, 'tcx>,\n-    ) -> SmallVec<[Pat<'tcx>; 1]> {\n-        // There are 2 ways we can report a witness here.\n-        // Commonly, we can report all the \"free\"\n-        // constructors as witnesses, e.g., if we have:\n-        //\n-        // ```\n-        //     enum Direction { N, S, E, W }\n-        //     let Direction::N = ...;\n-        // ```\n-        //\n-        // we can report 3 witnesses: `S`, `E`, and `W`.\n-        //\n-        // However, there is a case where we don't want\n-        // to do this and instead report a single `_` witness:\n-        // if the user didn't actually specify a constructor\n-        // in this arm, e.g., in\n-        //\n-        // ```\n-        //     let x: (Direction, Direction, bool) = ...;\n-        //     let (_, _, false) = x;\n-        // ```\n-        //\n-        // we don't want to show all 16 possible witnesses\n-        // `(<direction-1>, <direction-2>, true)` - we are\n-        // satisfied with `(_, _, true)`. In this case,\n-        // `used_ctors` is empty.\n-        // The exception is: if we are at the top-level, for example in an empty match, we\n-        // sometimes prefer reporting the list of constructors instead of just `_`.\n-        let report_when_all_missing = pcx.is_top_level && !IntRange::is_integral(pcx.ty);\n-        if self.used_ctors.is_empty() && !report_when_all_missing {\n-            // All constructors are unused. Report only a wildcard\n-            // rather than each individual constructor.\n-            smallvec![Pat::wildcard_from_ty(pcx.ty)]\n-        } else {\n-            // Construct for each missing constructor a \"wild\" version of this\n-            // constructor, that matches everything that can be built with\n-            // it. For example, if `ctor` is a `Constructor::Variant` for\n-            // `Option::Some`, we get the pattern `Some(_)`.\n-            self.iter(pcx)\n-                .map(|missing_ctor| Fields::wildcards(pcx, &missing_ctor).apply(pcx, missing_ctor))\n-                .collect()\n+    /// Return the set of constructors resulting from splitting the wildcard. As explained at the\n+    /// top of the file, if any constructors are missing we can ignore the present ones.\n+    fn into_ctors(self, pcx: PatCtxt<'_, '_, 'tcx>) -> SmallVec<[Constructor<'tcx>; 1]> {\n+        if self.any_missing(pcx) {\n+            // Some constructors are missing, thus we can specialize with the special `Missing`\n+            // constructor, which stands for those constructors that are not seen in the matrix,\n+            // and matches the same rows as any of them (namely the wildcard rows). See the top of\n+            // the file for details.\n+            // However, when all constructors are missing we can also specialize with the full\n+            // `Wildcard` constructor. The difference will depend on what we want in diagnostics.\n+\n+            // If some constructors are missing, we typically want to report those constructors,\n+            // e.g.:\n+            // ```\n+            //     enum Direction { N, S, E, W }\n+            //     let Direction::N = ...;\n+            // ```\n+            // we can report 3 witnesses: `S`, `E`, and `W`.\n+            //\n+            // However, if the user didn't actually specify a constructor\n+            // in this arm, e.g., in\n+            // ```\n+            //     let x: (Direction, Direction, bool) = ...;\n+            //     let (_, _, false) = x;\n+            // ```\n+            // we don't want to show all 16 possible witnesses `(<direction-1>, <direction-2>,\n+            // true)` - we are satisfied with `(_, _, true)`. So if all constructors are missing we\n+            // prefer to report just a wildcard `_`.\n+            //\n+            // The exception is: if we are at the top-level, for example in an empty match, we\n+            // sometimes prefer reporting the list of constructors instead of just `_`.\n+            let report_when_all_missing = pcx.is_top_level && !IntRange::is_integral(pcx.ty);\n+            let ctor = if !self.matrix_ctors.is_empty() || report_when_all_missing {\n+                Missing\n+            } else {\n+                Wildcard\n+            };\n+            return smallvec![ctor];\n         }\n+\n+        // All the constructors are present in the matrix, so we just go through them all.\n+        self.all_ctors\n     }\n }\n \n /// Some fields need to be explicitly hidden away in certain cases; see the comment above the\n-/// `Fields` struct. This struct represents such a potentially-hidden field. When a field is hidden\n-/// we still keep its type around.\n+/// `Fields` struct. This struct represents such a potentially-hidden field.\n #[derive(Debug, Copy, Clone)]\n pub(super) enum FilteredField<'p, 'tcx> {\n     Kept(&'p Pat<'tcx>),\n-    Hidden(Ty<'tcx>),\n+    Hidden,\n }\n \n impl<'p, 'tcx> FilteredField<'p, 'tcx> {\n     fn kept(self) -> Option<&'p Pat<'tcx>> {\n         match self {\n             FilteredField::Kept(p) => Some(p),\n-            FilteredField::Hidden(_) => None,\n-        }\n-    }\n-\n-    fn to_pattern(self) -> Pat<'tcx> {\n-        match self {\n-            FilteredField::Kept(p) => p.clone(),\n-            FilteredField::Hidden(ty) => Pat::wildcard_from_ty(ty),\n+            FilteredField::Hidden => None,\n         }\n     }\n }\n \n /// A value can be decomposed into a constructor applied to some fields. This struct represents\n /// those fields, generalized to allow patterns in each field. See also `Constructor`.\n+/// This is constructed from a constructor using [`Fields::wildcards()`].\n ///\n /// If a private or `non_exhaustive` field is uninhabited, the code mustn't observe that it is\n-/// uninhabited. For that, we filter these fields out of the matrix. This is subtle because we\n-/// still need to have those fields back when going to/from a `Pat`. Most of this is handled\n-/// automatically in `Fields`, but when constructing or deconstructing `Fields` you need to be\n-/// careful. As a rule, when going to/from the matrix, use the filtered field list; when going\n-/// to/from `Pat`, use the full field list.\n-/// This filtering is uncommon in practice, because uninhabited fields are rarely used, so we avoid\n-/// it when possible to preserve performance.\n+/// uninhabited. For that, we filter these fields out of the matrix. This is handled automatically\n+/// in `Fields`. This filtering is uncommon in practice, because uninhabited fields are rarely used,\n+/// so we avoid it when possible to preserve performance.\n #[derive(Debug, Clone)]\n pub(super) enum Fields<'p, 'tcx> {\n     /// Lists of patterns that don't contain any filtered fields.\n@@ -1027,21 +1090,19 @@ pub(super) enum Fields<'p, 'tcx> {\n     /// have not measured if it really made a difference.\n     Slice(&'p [Pat<'tcx>]),\n     Vec(SmallVec<[&'p Pat<'tcx>; 2]>),\n-    /// Patterns where some of the fields need to be hidden. `kept_count` caches the number of\n-    /// non-hidden fields.\n+    /// Patterns where some of the fields need to be hidden. For all intents and purposes we only\n+    /// care about the non-hidden fields. We need to keep the real field index for those fields;\n+    /// we're morally storing a `Vec<(usize, &Pat)>` but what we do is more convenient.\n+    /// `len` counts the number of non-hidden fields\n     Filtered {\n         fields: SmallVec<[FilteredField<'p, 'tcx>; 2]>,\n-        kept_count: usize,\n+        len: usize,\n     },\n }\n \n impl<'p, 'tcx> Fields<'p, 'tcx> {\n-    fn empty() -> Self {\n-        Fields::Slice(&[])\n-    }\n-\n-    /// Construct a new `Fields` from the given pattern. Must not be used if the pattern is a field\n-    /// of a struct/tuple/variant.\n+    /// Internal use. Use `Fields::wildcards()` instead.\n+    /// Must not be used if the pattern is a field of a struct/tuple/variant.\n     fn from_single_pattern(pat: &'p Pat<'tcx>) -> Self {\n         Fields::Slice(std::slice::from_ref(pat))\n     }\n@@ -1086,7 +1147,7 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n                         if has_no_hidden_fields {\n                             Fields::wildcards_from_tys(cx, field_tys)\n                         } else {\n-                            let mut kept_count = 0;\n+                            let mut len = 0;\n                             let fields = variant\n                                 .fields\n                                 .iter()\n@@ -1101,14 +1162,14 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n                                     // order not to reveal the uninhabitedness of the whole\n                                     // variant.\n                                     if is_uninhabited && (!is_visible || is_non_exhaustive) {\n-                                        FilteredField::Hidden(ty)\n+                                        FilteredField::Hidden\n                                     } else {\n-                                        kept_count += 1;\n+                                        len += 1;\n                                         FilteredField::Kept(wildcard_from_ty(ty))\n                                     }\n                                 })\n                                 .collect();\n-                            Fields::Filtered { fields, kept_count }\n+                            Fields::Filtered { fields, len }\n                         }\n                     }\n                 }\n@@ -1121,9 +1182,8 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n                 }\n                 _ => bug!(\"bad slice pattern {:?} {:?}\", constructor, ty),\n             },\n-            Str(..) | FloatRange(..) | IntRange(..) | NonExhaustive | Opaque | Wildcard => {\n-                Fields::empty()\n-            }\n+            Str(..) | FloatRange(..) | IntRange(..) | NonExhaustive | Opaque | Missing\n+            | Wildcard => Fields::Slice(&[]),\n         };\n         debug!(\"Fields::wildcards({:?}, {:?}) = {:#?}\", constructor, ty, ret);\n         ret\n@@ -1145,14 +1205,16 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n     /// `self`: `[false]`\n     /// returns `Some(false)`\n     pub(super) fn apply(self, pcx: PatCtxt<'_, 'p, 'tcx>, ctor: &Constructor<'tcx>) -> Pat<'tcx> {\n-        let mut subpatterns = self.all_patterns();\n+        let subpatterns_and_indices = self.patterns_and_indices();\n+        let mut subpatterns = subpatterns_and_indices.iter().map(|&(_, p)| p).cloned();\n \n         let pat = match ctor {\n             Single | Variant(_) => match pcx.ty.kind() {\n                 ty::Adt(..) | ty::Tuple(..) => {\n-                    let subpatterns = subpatterns\n-                        .enumerate()\n-                        .map(|(i, p)| FieldPat { field: Field::new(i), pattern: p })\n+                    // We want the real indices here.\n+                    let subpatterns = subpatterns_and_indices\n+                        .iter()\n+                        .map(|&(field, p)| FieldPat { field, pattern: p.clone() })\n                         .collect();\n \n                     if let ty::Adt(adt, substs) = pcx.ty.kind() {\n@@ -1207,48 +1269,52 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n             &FloatRange(lo, hi, end) => PatKind::Range(PatRange { lo, hi, end }),\n             IntRange(range) => return range.to_pat(pcx.cx.tcx, pcx.ty),\n             NonExhaustive => PatKind::Wild,\n+            Wildcard => return Pat::wildcard_from_ty(pcx.ty),\n             Opaque => bug!(\"we should not try to apply an opaque constructor\"),\n-            Wildcard => bug!(\n-                \"trying to apply a wildcard constructor; this should have been done in `apply_constructors`\"\n+            Missing => bug!(\n+                \"trying to apply the `Missing` constructor; this should have been done in `apply_constructors`\"\n             ),\n         };\n \n         Pat { ty: pcx.ty, span: DUMMY_SP, kind: Box::new(pat) }\n     }\n \n-    /// Returns the number of patterns from the viewpoint of match-checking, i.e. excluding hidden\n-    /// fields. This is what we want in most cases in this file, the only exception being\n-    /// conversion to/from `Pat`.\n+    /// Returns the number of patterns. This is the same as the arity of the constructor used to\n+    /// construct `self`.\n     pub(super) fn len(&self) -> usize {\n         match self {\n             Fields::Slice(pats) => pats.len(),\n             Fields::Vec(pats) => pats.len(),\n-            Fields::Filtered { kept_count, .. } => *kept_count,\n+            Fields::Filtered { len, .. } => *len,\n         }\n     }\n \n-    /// Returns the complete list of patterns, including hidden fields.\n-    fn all_patterns(self) -> impl Iterator<Item = Pat<'tcx>> {\n-        let pats: SmallVec<[_; 2]> = match self {\n-            Fields::Slice(pats) => pats.iter().cloned().collect(),\n-            Fields::Vec(pats) => pats.into_iter().cloned().collect(),\n+    /// Returns the list of patterns along with the corresponding field indices.\n+    fn patterns_and_indices(&self) -> SmallVec<[(Field, &'p Pat<'tcx>); 2]> {\n+        match self {\n+            Fields::Slice(pats) => {\n+                pats.iter().enumerate().map(|(i, p)| (Field::new(i), p)).collect()\n+            }\n+            Fields::Vec(pats) => {\n+                pats.iter().copied().enumerate().map(|(i, p)| (Field::new(i), p)).collect()\n+            }\n             Fields::Filtered { fields, .. } => {\n-                // We don't skip any fields here.\n-                fields.into_iter().map(|p| p.to_pattern()).collect()\n+                // Indices must be relative to the full list of patterns\n+                fields\n+                    .iter()\n+                    .enumerate()\n+                    .filter_map(|(i, p)| Some((Field::new(i), p.kept()?)))\n+                    .collect()\n             }\n-        };\n-        pats.into_iter()\n+        }\n     }\n \n-    /// Returns the filtered list of patterns, not including hidden fields.\n-    pub(super) fn filtered_patterns(self) -> SmallVec<[&'p Pat<'tcx>; 2]> {\n+    /// Returns the list of patterns.\n+    pub(super) fn into_patterns(self) -> SmallVec<[&'p Pat<'tcx>; 2]> {\n         match self {\n             Fields::Slice(pats) => pats.iter().collect(),\n             Fields::Vec(pats) => pats,\n-            Fields::Filtered { fields, .. } => {\n-                // We skip hidden fields here\n-                fields.into_iter().filter_map(|p| p.kept()).collect()\n-            }\n+            Fields::Filtered { fields, .. } => fields.iter().filter_map(|p| p.kept()).collect(),\n         }\n     }\n \n@@ -1264,10 +1330,10 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n     }\n \n     /// Overrides some of the fields with the provided patterns. This is used when a pattern\n-    /// defines some fields but not all, for example `Foo { field1: Some(_), .. }`: here we start with a\n-    /// `Fields` that is just one wildcard per field of the `Foo` struct, and override the entry\n-    /// corresponding to `field1` with the pattern `Some(_)`. This is also used for slice patterns\n-    /// for the same reason.\n+    /// defines some fields but not all, for example `Foo { field1: Some(_), .. }`: here we start\n+    /// with a `Fields` that is just one wildcard per field of the `Foo` struct, and override the\n+    /// entry corresponding to `field1` with the pattern `Some(_)`. This is also used for slice\n+    /// patterns for the same reason.\n     fn replace_fields_indexed(\n         &self,\n         new_pats: impl IntoIterator<Item = (usize, &'p Pat<'tcx>)>,\n@@ -1295,8 +1361,8 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n         fields\n     }\n \n-    /// Replaces contained fields with the given filtered list of patterns, e.g. taken from the\n-    /// matrix. There must be `len()` patterns in `pats`.\n+    /// Replaces contained fields with the given list of patterns. There must be `len()` patterns\n+    /// in `pats`.\n     pub(super) fn replace_fields(\n         &self,\n         cx: &MatchCheckCtxt<'p, 'tcx>,\n@@ -1305,7 +1371,7 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n         let pats: &[_] = cx.pattern_arena.alloc_from_iter(pats);\n \n         match self {\n-            Fields::Filtered { fields, kept_count } => {\n+            Fields::Filtered { fields, len } => {\n                 let mut pats = pats.iter();\n                 let mut fields = fields.clone();\n                 for f in &mut fields {\n@@ -1314,7 +1380,7 @@ impl<'p, 'tcx> Fields<'p, 'tcx> {\n                         *p = pats.next().unwrap();\n                     }\n                 }\n-                Fields::Filtered { fields, kept_count: *kept_count }\n+                Fields::Filtered { fields, len: *len }\n             }\n             _ => Fields::Slice(pats),\n         }"}, {"sha": "83fee380ccce7196038d4e1d438596990112cb9f", "filename": "compiler/rustc_mir_build/src/thir/pattern/usefulness.rs", "status": "modified", "additions": 251, "deletions": 252, "changes": 503, "blob_url": "https://github.com/rust-lang/rust/blob/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fusefulness.rs", "raw_url": "https://github.com/rust-lang/rust/raw/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fusefulness.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_mir_build%2Fsrc%2Fthir%2Fpattern%2Fusefulness.rs?ref=969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "patch": "@@ -12,301 +12,278 @@\n //!\n //! -----\n //!\n-//! This file includes the logic for exhaustiveness and usefulness checking for\n-//! pattern-matching. Specifically, given a list of patterns for a type, we can\n-//! tell whether:\n-//! (a) the patterns cover every possible constructor for the type (exhaustiveness)\n-//! (b) each pattern is necessary (usefulness)\n+//! This file includes the logic for exhaustiveness and reachability checking for pattern-matching.\n+//! Specifically, given a list of patterns for a type, we can tell whether:\n+//! (a) each pattern is reachable (reachability)\n+//! (b) the patterns cover every possible value for the type (exhaustiveness)\n //!\n-//! The algorithm implemented here is a modified version of the one described in\n-//! [this paper](http://moscova.inria.fr/~maranget/papers/warn/index.html).\n-//! However, to save future implementors from reading the original paper, we\n-//! summarise the algorithm here to hopefully save time and be a little clearer\n-//! (without being so rigorous).\n+//! The algorithm implemented here is a modified version of the one described in [this\n+//! paper](http://moscova.inria.fr/~maranget/papers/warn/index.html). We have however generalized\n+//! it to accommodate the variety of patterns that Rust supports. We thus explain our version here,\n+//! without being as rigorous.\n //!\n-//! # Premise\n //!\n-//! The core of the algorithm revolves about a \"usefulness\" check. In particular, we\n-//! are trying to compute a predicate `U(P, p)` where `P` is a list of patterns (we refer to this as\n-//! a matrix). `U(P, p)` represents whether, given an existing list of patterns\n-//! `P_1 ..= P_m`, adding a new pattern `p` will be \"useful\" (that is, cover previously-\n-//! uncovered values of the type).\n+//! # Summary\n //!\n-//! If we have this predicate, then we can easily compute both exhaustiveness of an\n-//! entire set of patterns and the individual usefulness of each one.\n-//! (a) the set of patterns is exhaustive iff `U(P, _)` is false (i.e., adding a wildcard\n-//! match doesn't increase the number of values we're matching)\n-//! (b) a pattern `P_i` is not useful if `U(P[0..=(i-1), P_i)` is false (i.e., adding a\n-//! pattern to those that have come before it doesn't increase the number of values\n-//! we're matching).\n+//! The core of the algorithm is the notion of \"usefulness\". A pattern `q` is said to be *useful*\n+//! relative to another pattern `p` of the same type if there is a value that is matched by `q` and\n+//! not matched by `p`. This generalizes to many `p`s: `q` is useful w.r.t. a list of patterns\n+//! `p_1 .. p_n` if there is a value that is matched by `q` and by none of the `p_i`. We write\n+//! `usefulness(p_1 .. p_n, q)` for a function that returns a list of such values. The aim of this\n+//! file is to compute it efficiently.\n //!\n-//! # Core concept\n+//! This is enough to compute reachability: a pattern in a `match` expression is reachable iff it\n+//! is useful w.r.t. the patterns above it:\n+//! ```rust\n+//! match x {\n+//!     Some(_) => ...,\n+//!     None => ..., // reachable: `None` is matched by this but not the branch above\n+//!     Some(0) => ..., // unreachable: all the values this matches are already matched by\n+//!                     // `Some(_)` above\n+//! }\n+//! ```\n+//!\n+//! This is also enough to compute exhaustiveness: a match is exhaustive iff the wildcard `_`\n+//! pattern is _not_ useful w.r.t. the patterns in the match. The values returned by `usefulness`\n+//! are used to tell the user which values are missing.\n+//! ```rust\n+//! match x {\n+//!     Some(0) => ...,\n+//!     None => ...,\n+//!     // not exhaustive: `_` is useful because it matches `Some(1)`\n+//! }\n+//! ```\n //!\n-//! The idea that powers everything that is done in this file is the following: a value is made\n-//! from a constructor applied to some fields. Examples of constructors are `Some`, `None`, `(,)`\n-//! (the 2-tuple constructor), `Foo {..}` (the constructor for a struct `Foo`), and `2` (the\n-//! constructor for the number `2`). Fields are just a (possibly empty) list of values.\n+//! The entrypoint of this file is the [`compute_match_usefulness`] function, which computes\n+//! reachability for each match branch and exhaustiveness for the whole match.\n //!\n-//! Some of the constructors listed above might feel weird: `None` and `2` don't take any\n-//! arguments. This is part of what makes constructors so general: we will consider plain values\n-//! like numbers and string literals to be constructors that take no arguments, also called \"0-ary\n-//! constructors\"; they are the simplest case of constructors. This allows us to see any value as\n-//! made up from a tree of constructors, each having a given number of children. For example:\n-//! `(None, Ok(0))` is made from 4 different constructors.\n //!\n-//! This idea can be extended to patterns: a pattern captures a set of possible values, and we can\n-//! describe this set using constructors. For example, `Err(_)` captures all values of the type\n-//! `Result<T, E>` that start with the `Err` constructor (for some choice of `T` and `E`). The\n-//! wildcard `_` captures all values of the given type starting with any of the constructors for\n-//! that type.\n+//! # Constructors and fields\n //!\n-//! We use this to compute whether different patterns might capture a same value. Do the patterns\n-//! `Ok(\"foo\")` and `Err(_)` capture a common value? The answer is no, because the first pattern\n-//! captures only values starting with the `Ok` constructor and the second only values starting\n-//! with the `Err` constructor. Do the patterns `Some(42)` and `Some(1..10)` intersect? They might,\n-//! since they both capture values starting with `Some`. To be certain, we need to dig under the\n-//! `Some` constructor and continue asking the question. This is the main idea behind the\n-//! exhaustiveness algorithm: by looking at patterns constructor-by-constructor, we can efficiently\n-//! figure out if some new pattern might capture a value that hadn't been captured by previous\n-//! patterns.\n+//! Note: we will often abbreviate \"constructor\" as \"ctor\".\n //!\n-//! Constructors are represented by the `Constructor` enum, and its fields by the `Fields` enum.\n-//! Most of the complexity of this file resides in transforming between patterns and\n-//! (`Constructor`, `Fields`) pairs, handling all the special cases correctly.\n+//! The idea that powers everything that is done in this file is the following: a (matcheable)\n+//! value is made from a constructor applied to a number of subvalues. Examples of constructors are\n+//! `Some`, `None`, `(,)` (the 2-tuple constructor), `Foo {..}` (the constructor for a struct\n+//! `Foo`), and `2` (the constructor for the number `2`). This is natural when we think of\n+//! pattern-matching, and this is the basis for what follows.\n //!\n-//! Caveat: this constructors/fields distinction doesn't quite cover every Rust value. For example\n-//! a value of type `Rc<u64>` doesn't fit this idea very well, nor do various other things.\n-//! However, this idea covers most of the cases that are relevant to exhaustiveness checking.\n+//! Some of the ctors listed above might feel weird: `None` and `2` don't take any arguments.\n+//! That's ok: those are ctors that take a list of 0 arguments; they are the simplest case of\n+//! ctors. We treat `2` as a ctor because `u64` and other number types behave exactly like a huge\n+//! `enum`, with one variant for each number. This allows us to see any matcheable value as made up\n+//! from a tree of ctors, each having a set number of children. For example: `Foo { bar: None,\n+//! baz: Ok(0) }` is made from 4 different ctors, namely `Foo{..}`, `None`, `Ok` and `0`.\n //!\n+//! This idea can be extended to patterns: they are also made from constructors applied to fields.\n+//! A pattern for a given type is allowed to use all the ctors for values of that type (which we\n+//! call \"value constructors\"), but there are also pattern-only ctors. The most important one is\n+//! the wildcard (`_`), and the others are integer ranges (`0..=10`), variable-length slices (`[x,\n+//! ..]`), and or-patterns (`Ok(0) | Err(_)`). Examples of valid patterns are `42`, `Some(_)`, `Foo\n+//! { bar: Some(0) | None, baz: _ }`. Note that a binder in a pattern (e.g. `Some(x)`) matches the\n+//! same values as a wildcard (e.g. `Some(_)`), so we treat both as wildcards.\n //!\n-//! # Algorithm\n+//! From this deconstruction we can compute whether a given value matches a given pattern; we\n+//! simply look at ctors one at a time. Given a pattern `p` and a value `v`, we want to compute\n+//! `matches!(v, p)`. It's mostly straightforward: we compare the head ctors and when they match\n+//! we compare their fields recursively. A few representative examples:\n //!\n-//! Recall that `U(P, p)` represents whether, given an existing list of patterns (aka matrix) `P`,\n-//! adding a new pattern `p` will cover previously-uncovered values of the type.\n-//! During the course of the algorithm, the rows of the matrix won't just be individual patterns,\n-//! but rather partially-deconstructed patterns in the form of a list of fields. The paper\n-//! calls those pattern-vectors, and we will call them pattern-stacks. The same holds for the\n-//! new pattern `p`.\n+//! - `matches!(v, _) := true`\n+//! - `matches!((v0,  v1), (p0,  p1)) := matches!(v0, p0) && matches!(v1, p1)`\n+//! - `matches!(Foo { bar: v0, baz: v1 }, Foo { bar: p0, baz: p1 }) := matches!(v0, p0) && matches!(v1, p1)`\n+//! - `matches!(Ok(v0), Ok(p0)) := matches!(v0, p0)`\n+//! - `matches!(Ok(v0), Err(p0)) := false` (incompatible variants)\n+//! - `matches!(v, 1..=100) := matches!(v, 1) || ... || matches!(v, 100)`\n+//! - `matches!([v0], [p0, .., p1]) := false` (incompatible lengths)\n+//! - `matches!([v0, v1, v2], [p0, .., p1]) := matches!(v0, p0) && matches!(v2, p1)`\n+//! - `matches!(v, p0 | p1) := matches!(v, p0) || matches!(v, p1)`\n //!\n-//! For example, say we have the following:\n+//! Constructors, fields and relevant operations are defined in the [`super::deconstruct_pat`] module.\n //!\n+//! Note: this constructors/fields distinction may not straightforwardly apply to every Rust type.\n+//! For example a value of type `Rc<u64>` can't be deconstructed that way, and `&str` has an\n+//! infinitude of constructors. There are also subtleties with visibility of fields and\n+//! uninhabitedness and various other things. The constructors idea can be extended to handle most\n+//! of these subtleties though; caveats are documented where relevant throughout the code.\n+//!\n+//! Whether constructors cover each other is computed by [`Constructor::is_covered_by`].\n+//!\n+//!\n+//! # Specialization\n+//!\n+//! Recall that we wish to compute `usefulness(p_1 .. p_n, q)`: given a list of patterns `p_1 ..\n+//! p_n` and a pattern `q`, all of the same type, we want to find a list of values (called\n+//! \"witnesses\") that are matched by `q` and by none of the `p_i`. We obviously don't just\n+//! enumerate all possible values. From the discussion above we see that we can proceed\n+//! ctor-by-ctor: for each value ctor of the given type, we ask \"is there a value that starts with\n+//! this constructor and matches `q` and none of the `p_i`?\". As we saw above, there's a lot we can\n+//! say from knowing only the first constructor of our candidate value.\n+//!\n+//! Let's take the following example:\n //! ```\n-//! // x: (Option<bool>, Result<()>)\n //! match x {\n-//!     (Some(true), _) => {}\n-//!     (None, Err(())) => {}\n-//!     (None, Err(_)) => {}\n+//!     Enum::Variant1(_) => {} // `p1`\n+//!     Enum::Variant2(None, 0) => {} // `p2`\n+//!     Enum::Variant2(Some(_), 0) => {} // `q`\n //! }\n //! ```\n //!\n-//! Here, the matrix `P` starts as:\n+//! We can easily see that if our candidate value `v` starts with `Variant1` it will not match `q`.\n+//! If `v = Variant2(v0, v1)` however, whether or not it matches `p2` and `q` will depend on `v0`\n+//! and `v1`. In fact, such a `v` will be a witness of usefulness of `q` exactly when the tuple\n+//! `(v0, v1)` is a witness of usefulness of `q'` in the following reduced match:\n //!\n //! ```\n-//! [\n-//!     [(Some(true), _)],\n-//!     [(None, Err(()))],\n-//!     [(None, Err(_))],\n-//! ]\n+//! match x {\n+//!     (None, 0) => {} // `p2'`\n+//!     (Some(_), 0) => {} // `q'`\n+//! }\n //! ```\n //!\n-//! We can tell it's not exhaustive, because `U(P, _)` is true (we're not covering\n-//! `[(Some(false), _)]`, for instance). In addition, row 3 is not useful, because\n-//! all the values it covers are already covered by row 2.\n+//! This motivates a new step in computing usefulness, that we call _specialization_.\n+//! Specialization consist of filtering a list of patterns for those that match a constructor, and\n+//! then looking into the constructor's fields. This enables usefulness to be computed recursively.\n //!\n-//! A list of patterns can be thought of as a stack, because we are mainly interested in the top of\n-//! the stack at any given point, and we can pop or apply constructors to get new pattern-stacks.\n-//! To match the paper, the top of the stack is at the beginning / on the left.\n+//! Instead of acting on a single pattern in each row, we will consider a list of patterns for each\n+//! row, and we call such a list a _pattern-stack_. The idea is that we will specialize the\n+//! leftmost pattern, which amounts to popping the constructor and pushing its fields, which feels\n+//! like a stack. We note a pattern-stack simply with `[p_1 ... p_n]`.\n+//! Here's a sequence of specializations of a list of pattern-stacks, to illustrate what's\n+//! happening:\n+//! ```\n+//! [Enum::Variant1(_)]\n+//! [Enum::Variant2(None, 0)]\n+//! [Enum::Variant2(Some(_), 0)]\n+//! //==>> specialize with `Variant2`\n+//! [None, 0]\n+//! [Some(_), 0]\n+//! //==>> specialize with `Some`\n+//! [_, 0]\n+//! //==>> specialize with `true` (say the type was `bool`)\n+//! [0]\n+//! //==>> specialize with `0`\n+//! []\n+//! ```\n //!\n-//! There are two important operations on pattern-stacks necessary to understand the algorithm:\n+//! The function `specialize(c, p)` takes a value constructor `c` and a pattern `p`, and returns 0\n+//! or more pattern-stacks. If `c` does not match the head constructor of `p`, it returns nothing;\n+//! otherwise if returns the fields of the constructor. This only returns more than one\n+//! pattern-stack if `p` has a pattern-only constructor.\n //!\n-//! 1. We can pop a given constructor off the top of a stack. This operation is called\n-//!    `specialize`, and is denoted `S(c, p)` where `c` is a constructor (like `Some` or\n-//!    `None`) and `p` a pattern-stack.\n-//!    If the pattern on top of the stack can cover `c`, this removes the constructor and\n-//!    pushes its arguments onto the stack. It also expands OR-patterns into distinct patterns.\n-//!    Otherwise the pattern-stack is discarded.\n-//!    This essentially filters those pattern-stacks whose top covers the constructor `c` and\n-//!    discards the others.\n+//! - Specializing for the wrong constructor returns nothing\n //!\n-//!    For example, the first pattern above initially gives a stack `[(Some(true), _)]`. If we\n-//!    pop the tuple constructor, we are left with `[Some(true), _]`, and if we then pop the\n-//!    `Some` constructor we get `[true, _]`. If we had popped `None` instead, we would get\n-//!    nothing back.\n+//!   `specialize(None, Some(p0)) := []`\n //!\n-//!    This returns zero or more new pattern-stacks, as follows. We look at the pattern `p_1`\n-//!    on top of the stack, and we have four cases:\n+//! - Specializing for the correct constructor returns a single row with the fields\n //!\n-//!      1.1. `p_1 = c(r_1, .., r_a)`, i.e. the top of the stack has constructor `c`. We\n-//!           push onto the stack the arguments of this constructor, and return the result:\n-//!              `r_1, .., r_a, p_2, .., p_n`\n+//!   `specialize(Variant1, Variant1(p0, p1, p2)) := [[p0, p1, p2]]`\n //!\n-//!      1.2. `p_1 = c'(r_1, .., r_a')` where `c \u2260 c'`. We discard the current stack and\n-//!           return nothing.\n+//!   `specialize(Foo{..}, Foo { bar: p0, baz: p1 }) := [[p0, p1]]`\n //!\n-//!         1.3. `p_1 = _`. We push onto the stack as many wildcards as the constructor `c` has\n-//!              arguments (its arity), and return the resulting stack:\n-//!                 `_, .., _, p_2, .., p_n`\n+//! - For or-patterns, we specialize each branch and concatenate the results\n //!\n-//!         1.4. `p_1 = r_1 | r_2`. We expand the OR-pattern and then recurse on each resulting\n-//!              stack:\n-//!                 - `S(c, (r_1, p_2, .., p_n))`\n-//!                 - `S(c, (r_2, p_2, .., p_n))`\n+//!   `specialize(c, p0 | p1) := specialize(c, p0) ++ specialize(c, p1)`\n //!\n-//! 2. We can pop a wildcard off the top of the stack. This is called `S(_, p)`, where `p` is\n-//!    a pattern-stack. Note: the paper calls this `D(p)`.\n-//!    This is used when we know there are missing constructor cases, but there might be\n-//!    existing wildcard patterns, so to check the usefulness of the matrix, we have to check\n-//!    all its *other* components.\n+//! - We treat the other pattern constructors as if they were a large or-pattern of all the\n+//!   possibilities:\n //!\n-//!    It is computed as follows. We look at the pattern `p_1` on top of the stack,\n-//!    and we have three cases:\n-//!         2.1. `p_1 = c(r_1, .., r_a)`. We discard the current stack and return nothing.\n-//!         2.2. `p_1 = _`. We return the rest of the stack:\n-//!                 p_2, .., p_n\n-//!         2.3. `p_1 = r_1 | r_2`. We expand the OR-pattern and then recurse on each resulting\n-//!           stack.\n-//!                 - `S(_, (r_1, p_2, .., p_n))`\n-//!                 - `S(_, (r_2, p_2, .., p_n))`\n+//!   `specialize(c, _) := specialize(c, Variant1(_) | Variant2(_, _) | ...)`\n //!\n-//! Note that the OR-patterns are not always used directly in Rust, but are used to derive the\n-//! exhaustive integer matching rules, so they're written here for posterity.\n+//!   `specialize(c, 1..=100) := specialize(c, 1 | ... | 100)`\n //!\n-//! Both those operations extend straightforwardly to a list or pattern-stacks, i.e. a matrix, by\n-//! working row-by-row. Popping a constructor ends up keeping only the matrix rows that start with\n-//! the given constructor, and popping a wildcard keeps those rows that start with a wildcard.\n+//!   `specialize(c, [p0, .., p1]) := specialize(c, [p0, p1] | [p0, _, p1] | [p0, _, _, p1] | ...)`\n //!\n+//! - If `c` is a pattern-only constructor, `specialize` is defined on a case-by-case basis. See\n+//!   the discussion about constructor splitting in [`super::deconstruct_pat`].\n //!\n-//! The algorithm for computing `U`\n-//! -------------------------------\n-//! The algorithm is inductive (on the number of columns: i.e., components of tuple patterns).\n-//! That means we're going to check the components from left-to-right, so the algorithm\n-//! operates principally on the first component of the matrix and new pattern-stack `p`.\n-//! This algorithm is realised in the `is_useful` function.\n //!\n-//! Base case. (`n = 0`, i.e., an empty tuple pattern)\n-//!     - If `P` already contains an empty pattern (i.e., if the number of patterns `m > 0`),\n-//!       then `U(P, p)` is false.\n-//!     - Otherwise, `P` must be empty, so `U(P, p)` is true.\n+//! We then extend this function to work with pattern-stacks as input, by acting on the first\n+//! column and keeping the other columns untouched.\n //!\n-//! Inductive step. (`n > 0`, i.e., whether there's at least one column\n-//!                  [which may then be expanded into further columns later])\n-//! We're going to match on the top of the new pattern-stack, `p_1`.\n-//!     - If `p_1 == c(r_1, .., r_a)`, i.e. we have a constructor pattern.\n-//! Then, the usefulness of `p_1` can be reduced to whether it is useful when\n-//! we ignore all the patterns in the first column of `P` that involve other constructors.\n-//! This is where `S(c, P)` comes in:\n-//! `U(P, p) := U(S(c, P), S(c, p))`\n+//! Specialization for the whole matrix is done in [`Matrix::specialize_constructor`]. Note that\n+//! or-patterns in the first column are expanded before being stored in the matrix. Specialization\n+//! for a single patstack is done from a combination of [`Constructor::is_covered_by`] and\n+//! [`PatStack::pop_head_constructor`]. The internals of how it's done mostly live in the\n+//! [`Fields`] struct.\n //!\n-//! For example, if `P` is:\n //!\n-//! ```\n-//! [\n-//!     [Some(true), _],\n-//!     [None, 0],\n-//! ]\n-//! ```\n+//! # Computing usefulness\n //!\n-//! and `p` is `[Some(false), 0]`, then we don't care about row 2 since we know `p` only\n-//! matches values that row 2 doesn't. For row 1 however, we need to dig into the\n-//! arguments of `Some` to know whether some new value is covered. So we compute\n-//! `U([[true, _]], [false, 0])`.\n+//! We now have all we need to compute usefulness. The inputs to usefulness are a list of\n+//! pattern-stacks `p_1 ... p_n` (one per row), and a new pattern_stack `q`. The paper and this\n+//! file calls the list of patstacks a _matrix_. They must all have the same number of columns and\n+//! the patterns in a given column must all have the same type. `usefulness` returns a (possibly\n+//! empty) list of witnesses of usefulness. These witnesses will also be pattern-stacks.\n //!\n-//!   - If `p_1 == _`, then we look at the list of constructors that appear in the first\n-//! component of the rows of `P`:\n-//!   + If there are some constructors that aren't present, then we might think that the\n-//! wildcard `_` is useful, since it covers those constructors that weren't covered\n-//! before.\n-//! That's almost correct, but only works if there were no wildcards in those first\n-//! components. So we need to check that `p` is useful with respect to the rows that\n-//! start with a wildcard, if there are any. This is where `S(_, x)` comes in:\n-//! `U(P, p) := U(S(_, P), S(_, p))`\n+//! - base case: `n_columns == 0`.\n+//!     Since a pattern-stack functions like a tuple of patterns, an empty one functions like the\n+//!     unit type. Thus `q` is useful iff there are no rows above it, i.e. if `n == 0`.\n //!\n-//! For example, if `P` is:\n+//! - inductive case: `n_columns > 0`.\n+//!     We need a way to list the constructors we want to try. We will be more clever in the next\n+//!     section but for now assume we list all value constructors for the type of the first column.\n //!\n-//! ```\n-//! [\n-//!     [_, true, _],\n-//!     [None, false, 1],\n-//! ]\n-//! ```\n+//!     - for each such ctor `c`:\n+//!\n+//!         - for each `q'` returned by `specialize(c, q)`:\n //!\n-//! and `p` is `[_, false, _]`, the `Some` constructor doesn't appear in `P`. So if we\n-//! only had row 2, we'd know that `p` is useful. However row 1 starts with a\n-//! wildcard, so we need to check whether `U([[true, _]], [false, 1])`.\n+//!             - we compute `usefulness(specialize(c, p_1) ... specialize(c, p_n), q')`\n //!\n-//!   + Otherwise, all possible constructors (for the relevant type) are present. In this\n-//! case we must check whether the wildcard pattern covers any unmatched value. For\n-//! that, we can think of the `_` pattern as a big OR-pattern that covers all\n-//! possible constructors. For `Option`, that would mean `_ = None | Some(_)` for\n-//! example. The wildcard pattern is useful in this case if it is useful when\n-//! specialized to one of the possible constructors. So we compute:\n-//! `U(P, p) := \u2203(k \u03f5 constructors) U(S(k, P), S(k, p))`\n+//!         - for each witness found, we revert specialization by pushing the constructor `c` on top.\n //!\n-//! For example, if `P` is:\n+//!     - We return the concatenation of all the witnesses found, if any.\n //!\n+//! Example:\n //! ```\n-//! [\n-//!     [Some(true), _],\n-//!     [None, false],\n-//! ]\n+//! [Some(true)] // p_1\n+//! [None] // p_2\n+//! [Some(_)] // q\n+//! //==>> try `None`: `specialize(None, q)` returns nothing\n+//! //==>> try `Some`: `specialize(Some, q)` returns a single row\n+//! [true] // p_1'\n+//! [_] // q'\n+//! //==>> try `true`: `specialize(true, q')` returns a single row\n+//! [] // p_1''\n+//! [] // q''\n+//! //==>> base case; `n != 0` so `q''` is not useful.\n+//! //==>> go back up a step\n+//! [true] // p_1'\n+//! [_] // q'\n+//! //==>> try `false`: `specialize(false, q')` returns a single row\n+//! [] // q''\n+//! //==>> base case; `n == 0` so `q''` is useful. We return the single witness `[]`\n+//! witnesses:\n+//! []\n+//! //==>> undo the specialization with `false`\n+//! witnesses:\n+//! [false]\n+//! //==>> undo the specialization with `Some`\n+//! witnesses:\n+//! [Some(false)]\n+//! //==>> we have tried all the constructors. The output is the single witness `[Some(false)]`.\n //! ```\n //!\n-//! and `p` is `[_, false]`, both `None` and `Some` constructors appear in the first\n-//! components of `P`. We will therefore try popping both constructors in turn: we\n-//! compute `U([[true, _]], [_, false])` for the `Some` constructor, and `U([[false]],\n-//! [false])` for the `None` constructor. The first case returns true, so we know that\n-//! `p` is useful for `P`. Indeed, it matches `[Some(false), _]` that wasn't matched\n-//! before.\n+//! This computation is done in [`is_useful`]. In practice we don't care about the list of\n+//! witnesses when computing reachability; we only need to know whether any exist. We do keep the\n+//! witnesses when computing exhaustiveness to report them to the user.\n+//!\n //!\n-//!   - If `p_1 == r_1 | r_2`, then the usefulness depends on each `r_i` separately:\n-//! `U(P, p) := U(P, (r_1, p_2, .., p_n))\n-//!  || U(P, (r_2, p_2, .., p_n))`\n+//! # Making usefulness tractable: constructor splitting\n //!\n-//! Modifications to the algorithm\n-//! ------------------------------\n-//! The algorithm in the paper doesn't cover some of the special cases that arise in Rust, for\n-//! example uninhabited types and variable-length slice patterns. These are drawn attention to\n-//! throughout the code below. I'll make a quick note here about how exhaustive integer matching is\n-//! accounted for, though.\n+//! We're missing one last detail: which constructors do we list? Naively listing all value\n+//! constructors cannot work for types like `u64` or `&str`, so we need to be more clever. The\n+//! first obvious insight is that we only want to list constructors that are covered by the head\n+//! constructor of `q`. If it's a value constructor, we only try that one. If it's a pattern-only\n+//! constructor, we use the final clever idea for this algorithm: _constructor splitting_, where we\n+//! group together constructors that behave the same.\n //!\n-//! Exhaustive integer matching\n-//! ---------------------------\n-//! An integer type can be thought of as a (huge) sum type: 1 | 2 | 3 | ...\n-//! So to support exhaustive integer matching, we can make use of the logic in the paper for\n-//! OR-patterns. However, we obviously can't just treat ranges x..=y as individual sums, because\n-//! they are likely gigantic. So we instead treat ranges as constructors of the integers. This means\n-//! that we have a constructor *of* constructors (the integers themselves). We then need to work\n-//! through all the inductive step rules above, deriving how the ranges would be treated as\n-//! OR-patterns, and making sure that they're treated in the same way even when they're ranges.\n-//! There are really only four special cases here:\n-//! - When we match on a constructor that's actually a range, we have to treat it as if we would\n-//!   an OR-pattern.\n-//!     + It turns out that we can simply extend the case for single-value patterns in\n-//!      `specialize` to either be *equal* to a value constructor, or *contained within* a range\n-//!      constructor.\n-//!     + When the pattern itself is a range, you just want to tell whether any of the values in\n-//!       the pattern range coincide with values in the constructor range, which is precisely\n-//!       intersection.\n-//!   Since when encountering a range pattern for a value constructor, we also use inclusion, it\n-//!   means that whenever the constructor is a value/range and the pattern is also a value/range,\n-//!   we can simply use intersection to test usefulness.\n-//! - When we're testing for usefulness of a pattern and the pattern's first component is a\n-//!   wildcard.\n-//!     + If all the constructors appear in the matrix, we have a slight complication. By default,\n-//!       the behaviour (i.e., a disjunction over specialised matrices for each constructor) is\n-//!       invalid, because we want a disjunction over every *integer* in each range, not just a\n-//!       disjunction over every range. This is a bit more tricky to deal with: essentially we need\n-//!       to form equivalence classes of subranges of the constructor range for which the behaviour\n-//!       of the matrix `P` and new pattern `p` are the same. This is described in more\n-//!       detail in `Constructor::split`.\n-//!     + If some constructors are missing from the matrix, it turns out we don't need to do\n-//!       anything special (because we know none of the integers are actually wildcards: i.e., we\n-//!       can't span wildcards using ranges).\n+//! The details are not necessary to understand this file, so we explain them in\n+//! [`super::deconstruct_pat`]. Splitting is done by the [`Constructor::split`] function.\n \n use self::Usefulness::*;\n use self::WitnessPreference::*;\n \n-use super::deconstruct_pat::{Constructor, Fields, MissingConstructors};\n+use super::deconstruct_pat::{Constructor, Fields, SplitWildcard};\n use super::{Pat, PatKind};\n use super::{PatternFoldable, PatternFolder};\n \n@@ -358,8 +335,6 @@ impl<'a, 'tcx> MatchCheckCtxt<'a, 'tcx> {\n #[derive(Copy, Clone)]\n pub(super) struct PatCtxt<'a, 'p, 'tcx> {\n     pub(super) cx: &'a MatchCheckCtxt<'p, 'tcx>,\n-    /// Current state of the matrix.\n-    pub(super) matrix: &'a Matrix<'p, 'tcx>,\n     /// Type of the current column under investigation.\n     pub(super) ty: Ty<'tcx>,\n     /// Span of the current pattern under investigation.\n@@ -473,7 +448,7 @@ impl<'p, 'tcx> PatStack<'p, 'tcx> {\n         // We pop the head pattern and push the new fields extracted from the arguments of\n         // `self.head()`.\n         let mut new_fields =\n-            ctor_wild_subpatterns.replace_with_pattern_arguments(self.head()).filtered_patterns();\n+            ctor_wild_subpatterns.replace_with_pattern_arguments(self.head()).into_patterns();\n         new_fields.extend_from_slice(&self.pats[1..]);\n         PatStack::from_vec(new_fields)\n     }\n@@ -538,7 +513,7 @@ impl<'p, 'tcx> Matrix<'p, 'tcx> {\n     pub(super) fn head_ctors<'a>(\n         &'a self,\n         cx: &'a MatchCheckCtxt<'p, 'tcx>,\n-    ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'p> {\n+    ) -> impl Iterator<Item = &'a Constructor<'tcx>> + Captures<'p> + Clone {\n         self.patterns.iter().map(move |r| r.head_ctor(cx))\n     }\n \n@@ -804,14 +779,25 @@ impl<'tcx> Usefulness<'tcx> {\n     fn apply_constructor<'p>(\n         self,\n         pcx: PatCtxt<'_, 'p, 'tcx>,\n+        matrix: &Matrix<'p, 'tcx>, // used to compute missing ctors\n         ctor: &Constructor<'tcx>,\n         ctor_wild_subpatterns: &Fields<'p, 'tcx>,\n     ) -> Self {\n         match self {\n             UsefulWithWitness(witnesses) => {\n-                let new_witnesses = if ctor.is_wildcard() {\n-                    let missing_ctors = MissingConstructors::new(pcx);\n-                    let new_patterns = missing_ctors.report_patterns(pcx);\n+                let new_witnesses = if matches!(ctor, Constructor::Missing) {\n+                    let mut split_wildcard = SplitWildcard::new(pcx);\n+                    split_wildcard.split(pcx, matrix.head_ctors(pcx.cx));\n+                    // Construct for each missing constructor a \"wild\" version of this\n+                    // constructor, that matches everything that can be built with\n+                    // it. For example, if `ctor` is a `Constructor::Variant` for\n+                    // `Option::Some`, we get the pattern `Some(_)`.\n+                    let new_patterns: Vec<_> = split_wildcard\n+                        .iter_missing(pcx)\n+                        .map(|missing_ctor| {\n+                            Fields::wildcards(pcx, missing_ctor).apply(pcx, missing_ctor)\n+                        })\n+                        .collect();\n                     witnesses\n                         .into_iter()\n                         .flat_map(|witness| {\n@@ -866,10 +852,10 @@ enum WitnessPreference {\n /// We'll perform the following steps:\n /// 1. Start with an empty witness\n ///     `Witness(vec![])`\n-/// 2. Push a witness `Some(_)` against the `None`\n-///     `Witness(vec![Some(_)])`\n-/// 3. Push a witness `true` against the `false`\n-///     `Witness(vec![Some(_), true])`\n+/// 2. Push a witness `true` against the `false`\n+///     `Witness(vec![true])`\n+/// 3. Push a witness `Some(_)` against the `None`\n+///     `Witness(vec![true, Some(_)])`\n /// 4. Apply the `Pair` constructor to the witnesses\n ///     `Witness(vec![Pair(Some(_), true)])`\n ///\n@@ -967,7 +953,7 @@ fn is_useful<'p, 'tcx>(\n \n     // FIXME(Nadrieril): Hack to work around type normalization issues (see #72476).\n     let ty = matrix.heads().next().map(|r| r.ty).unwrap_or(v.head().ty);\n-    let pcx = PatCtxt { cx, matrix, ty, span: v.head().span, is_top_level };\n+    let pcx = PatCtxt { cx, ty, span: v.head().span, is_top_level };\n \n     debug!(\"is_useful_expand_first_col: ty={:#?}, expanding {:#?}\", pcx.ty, v.head());\n \n@@ -991,18 +977,30 @@ fn is_useful<'p, 'tcx>(\n         });\n         Usefulness::merge(usefulnesses)\n     } else {\n+        let v_ctor = v.head_ctor(cx);\n+        if let Constructor::IntRange(ctor_range) = &v_ctor {\n+            // Lint on likely incorrect range patterns (#63987)\n+            ctor_range.lint_overlapping_range_endpoints(\n+                pcx,\n+                matrix.head_ctors_and_spans(cx),\n+                matrix.column_count().unwrap_or(0),\n+                hir_id,\n+            )\n+        }\n         // We split the head constructor of `v`.\n-        let ctors = v.head_ctor(cx).split(pcx, Some(hir_id));\n+        let split_ctors = v_ctor.split(pcx, matrix.head_ctors(cx));\n         // For each constructor, we compute whether there's a value that starts with it that would\n         // witness the usefulness of `v`.\n-        let usefulnesses = ctors.into_iter().map(|ctor| {\n+        let start_matrix = &matrix;\n+        let usefulnesses = split_ctors.into_iter().map(|ctor| {\n             // We cache the result of `Fields::wildcards` because it is used a lot.\n             let ctor_wild_subpatterns = Fields::wildcards(pcx, &ctor);\n-            let matrix = pcx.matrix.specialize_constructor(pcx, &ctor, &ctor_wild_subpatterns);\n+            let spec_matrix =\n+                start_matrix.specialize_constructor(pcx, &ctor, &ctor_wild_subpatterns);\n             let v = v.pop_head_constructor(&ctor_wild_subpatterns);\n             let usefulness =\n-                is_useful(pcx.cx, &matrix, &v, witness_preference, hir_id, is_under_guard, false);\n-            usefulness.apply_constructor(pcx, &ctor, &ctor_wild_subpatterns)\n+                is_useful(cx, &spec_matrix, &v, witness_preference, hir_id, is_under_guard, false);\n+            usefulness.apply_constructor(pcx, start_matrix, &ctor, &ctor_wild_subpatterns)\n         });\n         Usefulness::merge(usefulnesses)\n     };\n@@ -1013,7 +1011,7 @@ fn is_useful<'p, 'tcx>(\n /// The arm of a match expression.\n #[derive(Clone, Copy)]\n crate struct MatchArm<'p, 'tcx> {\n-    /// The pattern must have been lowered through `MatchVisitor::lower_pattern`.\n+    /// The pattern must have been lowered through `check_match::MatchVisitor::lower_pattern`.\n     crate pat: &'p super::Pat<'tcx>,\n     crate hir_id: HirId,\n     crate has_guard: bool,\n@@ -1031,7 +1029,8 @@ crate struct UsefulnessReport<'p, 'tcx> {\n /// The entrypoint for the usefulness algorithm. Computes whether a match is exhaustive and which\n /// of its arms are reachable.\n ///\n-/// Note: the input patterns must have been lowered through `MatchVisitor::lower_pattern`.\n+/// Note: the input patterns must have been lowered through\n+/// `check_match::MatchVisitor::lower_pattern`.\n crate fn compute_match_usefulness<'p, 'tcx>(\n     cx: &MatchCheckCtxt<'p, 'tcx>,\n     arms: &[MatchArm<'p, 'tcx>],"}, {"sha": "ca4fcd85bb6df2f6b15dac79c5fd874997e2bf4b", "filename": "src/test/ui/pattern/usefulness/consts-opaque.rs", "status": "modified", "additions": 35, "deletions": 4, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.rs?ref=969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "patch": "@@ -25,10 +25,6 @@ enum Baz {\n impl Eq for Baz {}\n const BAZ: Baz = Baz::Baz1;\n \n-type Quux = fn(usize, usize) -> usize;\n-fn quux(a: usize, b: usize) -> usize { a + b }\n-const QUUX: Quux = quux;\n-\n fn main() {\n     match FOO {\n         FOO => {}\n@@ -106,9 +102,44 @@ fn main() {\n         //~^ ERROR unreachable pattern\n     }\n \n+    type Quux = fn(usize, usize) -> usize;\n+    fn quux(a: usize, b: usize) -> usize { a + b }\n+    const QUUX: Quux = quux;\n+\n     match QUUX {\n         QUUX => {}\n         QUUX => {}\n         _ => {}\n     }\n+\n+    #[derive(PartialEq, Eq)]\n+    struct Wrap<T>(T);\n+    const WRAPQUUX: Wrap<Quux> = Wrap(quux);\n+\n+    match WRAPQUUX {\n+        WRAPQUUX => {}\n+        WRAPQUUX => {}\n+        Wrap(_) => {}\n+    }\n+\n+    match WRAPQUUX {\n+        Wrap(_) => {}\n+        WRAPQUUX => {} // detected unreachable because we do inspect the `Wrap` layer\n+        //~^ ERROR unreachable pattern\n+    }\n+\n+    #[derive(PartialEq, Eq)]\n+    enum WhoKnows<T> {\n+        Yay(T),\n+        Nope,\n+    };\n+    const WHOKNOWSQUUX: WhoKnows<Quux> = WhoKnows::Yay(quux);\n+\n+    match WHOKNOWSQUUX {\n+        WHOKNOWSQUUX => {}\n+        WhoKnows::Yay(_) => {}\n+        WHOKNOWSQUUX => {} // detected unreachable because we do inspect the `WhoKnows` layer\n+        //~^ ERROR unreachable pattern\n+        WhoKnows::Nope => {}\n+    }\n }"}, {"sha": "68451043cf5403918670794bb2c4cd63d298628f", "filename": "src/test/ui/pattern/usefulness/consts-opaque.stderr", "status": "modified", "additions": 36, "deletions": 24, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fpattern%2Fusefulness%2Fconsts-opaque.stderr?ref=969b42d8c0e44c6b895ab4582b5ae0a0ce319fdf", "patch": "@@ -1,11 +1,11 @@\n error: to use a constant of type `Foo` in a pattern, `Foo` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:34:9\n+  --> $DIR/consts-opaque.rs:30:9\n    |\n LL |         FOO => {}\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:36:9\n+  --> $DIR/consts-opaque.rs:32:9\n    |\n LL |         _ => {} // should not be emitting unreachable warning\n    |         ^\n@@ -17,19 +17,19 @@ LL | #![deny(unreachable_patterns)]\n    |         ^^^^^^^^^^^^^^^^^^^^\n \n error: to use a constant of type `Foo` in a pattern, `Foo` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:41:9\n+  --> $DIR/consts-opaque.rs:37:9\n    |\n LL |         FOO_REF => {}\n    |         ^^^^^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:43:9\n+  --> $DIR/consts-opaque.rs:39:9\n    |\n LL |         Foo(_) => {} // should not be emitting unreachable warning\n    |         ^^^^^^\n \n warning: to use a constant of type `Foo` in a pattern, `Foo` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:49:9\n+  --> $DIR/consts-opaque.rs:45:9\n    |\n LL |         FOO_REF_REF => {}\n    |         ^^^^^^^^^^^\n@@ -39,21 +39,21 @@ LL |         FOO_REF_REF => {}\n    = note: for more information, see issue #62411 <https://github.com/rust-lang/rust/issues/62411>\n \n error: to use a constant of type `Bar` in a pattern, `Bar` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:57:9\n+  --> $DIR/consts-opaque.rs:53:9\n    |\n LL |         BAR => {} // should not be emitting unreachable warning\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:57:9\n+  --> $DIR/consts-opaque.rs:53:9\n    |\n LL |         Bar => {}\n    |         --- matches any value\n LL |         BAR => {} // should not be emitting unreachable warning\n    |         ^^^ unreachable pattern\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:60:9\n+  --> $DIR/consts-opaque.rs:56:9\n    |\n LL |         Bar => {}\n    |         --- matches any value\n@@ -62,19 +62,19 @@ LL |         _ => {}\n    |         ^ unreachable pattern\n \n error: to use a constant of type `Bar` in a pattern, `Bar` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:65:9\n+  --> $DIR/consts-opaque.rs:61:9\n    |\n LL |         BAR => {}\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:67:9\n+  --> $DIR/consts-opaque.rs:63:9\n    |\n LL |         Bar => {} // should not be emitting unreachable warning\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:69:9\n+  --> $DIR/consts-opaque.rs:65:9\n    |\n LL |         Bar => {} // should not be emitting unreachable warning\n    |         --- matches any value\n@@ -83,76 +83,88 @@ LL |         _ => {}\n    |         ^ unreachable pattern\n \n error: to use a constant of type `Bar` in a pattern, `Bar` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:74:9\n+  --> $DIR/consts-opaque.rs:70:9\n    |\n LL |         BAR => {}\n    |         ^^^\n \n error: to use a constant of type `Bar` in a pattern, `Bar` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:76:9\n+  --> $DIR/consts-opaque.rs:72:9\n    |\n LL |         BAR => {} // should not be emitting unreachable warning\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:76:9\n+  --> $DIR/consts-opaque.rs:72:9\n    |\n LL |         BAR => {} // should not be emitting unreachable warning\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:79:9\n+  --> $DIR/consts-opaque.rs:75:9\n    |\n LL |         _ => {} // should not be emitting unreachable warning\n    |         ^\n \n error: to use a constant of type `Baz` in a pattern, `Baz` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:84:9\n+  --> $DIR/consts-opaque.rs:80:9\n    |\n LL |         BAZ => {}\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:86:9\n+  --> $DIR/consts-opaque.rs:82:9\n    |\n LL |         Baz::Baz1 => {} // should not be emitting unreachable warning\n    |         ^^^^^^^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:88:9\n+  --> $DIR/consts-opaque.rs:84:9\n    |\n LL |         _ => {}\n    |         ^\n \n error: to use a constant of type `Baz` in a pattern, `Baz` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:94:9\n+  --> $DIR/consts-opaque.rs:90:9\n    |\n LL |         BAZ => {}\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:96:9\n+  --> $DIR/consts-opaque.rs:92:9\n    |\n LL |         _ => {}\n    |         ^\n \n error: to use a constant of type `Baz` in a pattern, `Baz` must be annotated with `#[derive(PartialEq, Eq)]`\n-  --> $DIR/consts-opaque.rs:101:9\n+  --> $DIR/consts-opaque.rs:97:9\n    |\n LL |         BAZ => {}\n    |         ^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:103:9\n+  --> $DIR/consts-opaque.rs:99:9\n    |\n LL |         Baz::Baz2 => {} // should not be emitting unreachable warning\n    |         ^^^^^^^^^\n \n error: unreachable pattern\n-  --> $DIR/consts-opaque.rs:105:9\n+  --> $DIR/consts-opaque.rs:101:9\n    |\n LL |         _ => {} // should not be emitting unreachable warning\n    |         ^\n \n-error: aborting due to 22 previous errors; 1 warning emitted\n+error: unreachable pattern\n+  --> $DIR/consts-opaque.rs:127:9\n+   |\n+LL |         WRAPQUUX => {} // detected unreachable because we do inspect the `Wrap` layer\n+   |         ^^^^^^^^\n+\n+error: unreachable pattern\n+  --> $DIR/consts-opaque.rs:141:9\n+   |\n+LL |         WHOKNOWSQUUX => {} // detected unreachable because we do inspect the `WhoKnows` layer\n+   |         ^^^^^^^^^^^^\n+\n+error: aborting due to 24 previous errors; 1 warning emitted\n "}]}