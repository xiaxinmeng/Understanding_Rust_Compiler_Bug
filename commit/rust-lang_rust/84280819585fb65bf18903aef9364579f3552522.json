{"sha": "84280819585fb65bf18903aef9364579f3552522", "node_id": "MDY6Q29tbWl0NzI0NzEyOjg0MjgwODE5NTg1ZmI2NWJmMTg5MDNhZWY5MzY0NTc5ZjM1NTI1MjI=", "commit": {"author": {"name": "toddaaro", "email": "github@opprobrio.us", "date": "2013-06-12T18:32:22Z"}, "committer": {"name": "toddaaro", "email": "github@opprobrio.us", "date": "2013-06-12T18:32:22Z"}, "message": "A basic implementation of pinning tasks to schedulers. No IO interactions have been planned for, and no forwarding of tasks off special schedulers is supported.", "tree": {"sha": "2c0284b08190435f8811323f6dc92f8ebe1b71d0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2c0284b08190435f8811323f6dc92f8ebe1b71d0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/84280819585fb65bf18903aef9364579f3552522", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/84280819585fb65bf18903aef9364579f3552522", "html_url": "https://github.com/rust-lang/rust/commit/84280819585fb65bf18903aef9364579f3552522", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/84280819585fb65bf18903aef9364579f3552522/comments", "author": {"login": "toddaaro", "id": 366431, "node_id": "MDQ6VXNlcjM2NjQzMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/366431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/toddaaro", "html_url": "https://github.com/toddaaro", "followers_url": "https://api.github.com/users/toddaaro/followers", "following_url": "https://api.github.com/users/toddaaro/following{/other_user}", "gists_url": "https://api.github.com/users/toddaaro/gists{/gist_id}", "starred_url": "https://api.github.com/users/toddaaro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/toddaaro/subscriptions", "organizations_url": "https://api.github.com/users/toddaaro/orgs", "repos_url": "https://api.github.com/users/toddaaro/repos", "events_url": "https://api.github.com/users/toddaaro/events{/privacy}", "received_events_url": "https://api.github.com/users/toddaaro/received_events", "type": "User", "site_admin": false}, "committer": {"login": "toddaaro", "id": 366431, "node_id": "MDQ6VXNlcjM2NjQzMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/366431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/toddaaro", "html_url": "https://github.com/toddaaro", "followers_url": "https://api.github.com/users/toddaaro/followers", "following_url": "https://api.github.com/users/toddaaro/following{/other_user}", "gists_url": "https://api.github.com/users/toddaaro/gists{/gist_id}", "starred_url": "https://api.github.com/users/toddaaro/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/toddaaro/subscriptions", "organizations_url": "https://api.github.com/users/toddaaro/orgs", "repos_url": "https://api.github.com/users/toddaaro/repos", "events_url": "https://api.github.com/users/toddaaro/events{/privacy}", "received_events_url": "https://api.github.com/users/toddaaro/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d64d26cd39a86a40feb0db7a9147cc2ae5e82994", "url": "https://api.github.com/repos/rust-lang/rust/commits/d64d26cd39a86a40feb0db7a9147cc2ae5e82994", "html_url": "https://github.com/rust-lang/rust/commit/d64d26cd39a86a40feb0db7a9147cc2ae5e82994"}], "stats": {"total": 538, "additions": 496, "deletions": 42}, "files": [{"sha": "698cafdf8c615d016e4145e6d564b07d230cd151", "filename": "src/libstd/rt/sched.rs", "status": "modified", "additions": 372, "deletions": 42, "changes": 414, "blob_url": "https://github.com/rust-lang/rust/blob/84280819585fb65bf18903aef9364579f3552522/src%2Flibstd%2Frt%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84280819585fb65bf18903aef9364579f3552522/src%2Flibstd%2Frt%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fsched.rs?ref=84280819585fb65bf18903aef9364579f3552522", "patch": "@@ -26,6 +26,11 @@ use rt::local::Local;\n use rt::rtio::RemoteCallback;\n use rt::metrics::SchedMetrics;\n \n+//use to_str::ToStr;\n+\n+/// To allow for using pointers as scheduler ids\n+use ptr::{to_uint};\n+\n /// The Scheduler is responsible for coordinating execution of Coroutines\n /// on a single thread. When the scheduler is running it is owned by\n /// thread local storage and the running task is owned by the\n@@ -70,7 +75,8 @@ pub struct Scheduler {\n \n pub struct SchedHandle {\n     priv remote: ~RemoteCallbackObject,\n-    priv queue: MessageQueue<SchedMessage>\n+    priv queue: MessageQueue<SchedMessage>,\n+    sched_id: uint\n }\n \n pub struct Coroutine {\n@@ -81,12 +87,37 @@ pub struct Coroutine {\n     /// the task is dead\n     priv saved_context: Context,\n     /// The heap, GC, unwinding, local storage, logging\n+    task: ~Task,\n+    /// The scheduler that this task calls home\n+    home_sched: SchedHome\n+}\n+\n+// To send a Coroutine to another task we have to use contained home\n+// information (the SchedHandle). So we need a form that doesn't\n+// include one.\n+\n+// XXX perf: Evaluate this structure - there should be a clever way to\n+// make it such that we don't need to deal with building/destructing\n+// on Coroutines that aren't homed.\n+\n+pub struct HomelessCoroutine {\n+    priv current_stack_segment: StackSegment,\n+    priv saved_context: Context,\n     task: ~Task\n }\n+   \n+// A scheduler home is either a handle to the home scheduler, or an\n+// explicit \"AnySched\".\n+        \n+pub enum SchedHome {\n+    AnySched,\n+    Sched(SchedHandle)\n+}\n \n pub enum SchedMessage {\n     Wake,\n-    Shutdown\n+    Shutdown,\n+    BiasedTask(~HomelessCoroutine)\n }\n \n enum CleanupJob {\n@@ -96,6 +127,8 @@ enum CleanupJob {\n \n pub impl Scheduler {\n \n+    pub fn sched_id(&self) -> uint { to_uint(self) }\n+\n     fn in_task_context(&self) -> bool { self.current_task.is_some() }\n \n     fn new(event_loop: ~EventLoopObject,\n@@ -151,7 +184,8 @@ pub impl Scheduler {\n         // XXX: Reenable this once we're using a per-task queue. With a shared\n         // queue this is not true\n         //assert!(sched.work_queue.is_empty());\n-        rtdebug!(\"scheduler metrics: %s\\n\", sched.metrics.to_str());\n+//        let out = sched.metrics.to_str();\n+//        rtdebug!(\"scheduler metrics: %s\\n\", out);\n         return sched;\n     }\n \n@@ -209,35 +243,122 @@ pub impl Scheduler {\n \n         return SchedHandle {\n             remote: remote,\n-            queue: self.message_queue.clone()\n+            queue: self.message_queue.clone(),\n+            sched_id: self.sched_id()\n         };\n     }\n \n     /// Schedule a task to be executed later.\n     ///\n-    /// Pushes the task onto the work stealing queue and tells the event loop\n-    /// to run it later. Always use this instead of pushing to the work queue\n-    /// directly.\n-    fn enqueue_task(&mut self, task: ~Coroutine) {\n-        self.work_queue.push(task);\n-        self.event_loop.callback(Scheduler::run_sched_once);\n-\n-        // We've made work available. Notify a sleeping scheduler.\n-        // XXX: perf. Check for a sleeper without synchronizing memory.\n-        // It's not critical that we always find it.\n-        // XXX: perf. If there's a sleeper then we might as well just send\n-        // it the task directly instead of pushing it to the\n-        // queue. That is essentially the intent here and it is less\n-        // work.\n-        match self.sleeper_list.pop() {\n-            Some(handle) => {\n-                let mut handle = handle;\n-                handle.send(Wake)\n+    /// Pushes the task onto the work stealing queue and tells the\n+    /// event loop to run it later. Always use this instead of pushing\n+    /// to the work queue directly.\n+\n+    fn enqueue_task(&mut self, mut task: ~Coroutine) {\n+\n+        // We don't want to queue tasks that belong on other threads,\n+        // so we send them home at enqueue time.\n+        \n+        // The borrow checker doesn't like our disassembly of the\n+        // Coroutine struct and partial use and mutation of the\n+        // fields. So completely disassemble here and stop using?\n+\n+        // XXX perf: I think we might be able to shuffle this code to\n+        // only destruct when we need to.\n+\n+        rtdebug!(\"a task was queued on: %u\", self.sched_id());\n+\n+        let this = self;\n+\n+        match task {\n+            ~Coroutine { current_stack_segment: css,\n+                         saved_context: sc,\n+                         task: t,\n+                         home_sched: home_sched } => {\n+                \n+                let mut home_sched = home_sched;\n+\n+                match home_sched {\n+                    Sched(ref mut home_handle) \n+                      if home_handle.sched_id != this.sched_id() => {\n+\n+                          // In this branch we know the task is not\n+                          // home, so we send it home.\n+\n+                        rtdebug!(\"home_handle_id: %u, loc: %u\", \n+                                 home_handle.sched_id,\n+                                 this.sched_id());\n+                            let homeless = ~HomelessCoroutine {\n+                                current_stack_segment: css,\n+                                saved_context: sc,\n+                                task: t\n+                            };\n+                            home_handle.send(BiasedTask(homeless));\n+                            rtdebug!(\"sent task home\");\n+                        return ();\n+                    }\n+                    Sched( ref mut home_handle) => {\n+\n+                        // Here we know the task is home, so we need\n+                        // to \"keep\" it home. Since we don't have a\n+                        // scheduler-local queue for this purpose, we\n+                        // just use our message queue.\n+\n+                        rtdebug!(\"homed task at home, sending to self\");\n+                        let homeless = ~HomelessCoroutine {\n+                            current_stack_segment: css,\n+                            saved_context: sc,\n+                            task: t\n+                        };\n+                        home_handle.send(BiasedTask(homeless));\n+                        rtdebug!(\"sent home to self\");\n+                        return ();\n+                         \n+                    }                    \n+                    _ => {\n+                        \n+                        // We just destroyed our Coroutine ... but now\n+                        // we want it back. Build a new one?  \n+                        // XXX: perf: see above comment about not\n+                        // destroying\n+\n+                        let task = ~Coroutine {\n+                            current_stack_segment: css,\n+                            saved_context: sc,\n+                            task: t,\n+                            home_sched: AnySched };\n+\n+                        \n+                        // We push the task onto our local queue.\n+                        this.work_queue.push(task);\n+                        this.event_loop.callback(Scheduler::run_sched_once);\n+\n+                        // We've made work available. Notify a\n+                        // sleeping scheduler.\n+                        \n+                        // XXX: perf. Check for a sleeper without\n+                        // synchronizing memory.  It's not critical\n+                        // that we always find it.\n+                        \n+                        // XXX: perf. If there's a sleeper then we\n+                        // might as well just send it the task\n+                        // directly instead of pushing it to the\n+                        // queue. That is essentially the intent here\n+                        // and it is less work.\n+                        match this.sleeper_list.pop() {\n+                            Some(handle) => {\n+                                let mut handle = handle;\n+                                handle.send(Wake)\n+                            }\n+                            None => { (/* pass */) }\n+                        };\n+                    }\n+                }\n             }\n-            None => (/* pass */)\n         }\n     }\n \n+\n     // * Scheduler-context operations\n \n     fn interpret_message_queue(~self) -> bool {\n@@ -247,6 +368,27 @@ pub impl Scheduler {\n \n         let mut this = self;\n         match this.message_queue.pop() {\n+            Some(BiasedTask(~HomelessCoroutine { \n+                current_stack_segment: css,\n+                saved_context: sc,\n+                task: t})) => {\n+                rtdebug!(\"recv BiasedTask message in sched: %u\",\n+                         this.sched_id());\n+            \n+                // Since this was the \"send home\" message for a task,\n+                // we know that this is the home. So we rebuild the\n+                // sched_handle.\n+                \n+                let task = ~Coroutine {\n+                    current_stack_segment: css,\n+                    saved_context: sc,\n+                    task: t,\n+                    home_sched: Sched(this.make_handle())\n+                };\n+                this.resume_task_immediately(task);\n+                return true;\n+            }\n+\n             Some(Wake) => {\n                 rtdebug!(\"recv Wake message\");\n                 this.sleepy = false;\n@@ -256,8 +398,9 @@ pub impl Scheduler {\n             Some(Shutdown) => {\n                 rtdebug!(\"recv Shutdown message\");\n                 if this.sleepy {\n-                    // There may be an outstanding handle on the sleeper list.\n-                    // Pop them all to make sure that's not the case.\n+                    // There may be an outstanding handle on the\n+                    // sleeper list.  Pop them all to make sure that's\n+                    // not the case.\n                     loop {\n                         match this.sleeper_list.pop() {\n                             Some(handle) => {\n@@ -268,8 +411,8 @@ pub impl Scheduler {\n                         }\n                     }\n                 }\n-                // No more sleeping. After there are no outstanding event loop\n-                // references we will shut down.\n+                // No more sleeping. After there are no outstanding\n+                // event loop references we will shut down.\n                 this.no_sleep = true;\n                 this.sleepy = false;\n                 Local::put(this);\n@@ -515,27 +658,60 @@ impl SchedHandle {\n }\n \n pub impl Coroutine {\n+\n+\n+    /// This function checks that a coroutine is running \"home\". \n+    fn am_home(&self) -> bool {\n+        do Local::borrow::<Scheduler,bool> |sched| {\n+            match self.home_sched {\n+                AnySched => { true }\n+                Sched(SchedHandle { sched_id: ref id, _ }) => {\n+                    *id == sched.sched_id()\n+                }\n+            }\n+        }\n+    }                                      \n+    \n+    // Created new variants of \"new\" that takes a home scheduler\n+    // parameter. The original with_task now calls with_task_homed\n+    // using the AnySched paramter.\n+\n+    fn new_homed(stack_pool: &mut StackPool, home: SchedHome, start: ~fn()) -> Coroutine {\n+        Coroutine::with_task_homed(stack_pool, ~Task::new(), start, home)\n+    }\n+\n     fn new(stack_pool: &mut StackPool, start: ~fn()) -> Coroutine {\n         Coroutine::with_task(stack_pool, ~Task::new(), start)\n     }\n \n-    fn with_task(stack_pool: &mut StackPool,\n-                  task: ~Task,\n-                  start: ~fn()) -> Coroutine {\n-\n+    fn with_task_homed(stack_pool: &mut StackPool,\n+                       task: ~Task,\n+                       start: ~fn(),\n+                       home: SchedHome) -> Coroutine {\n+        \n         static MIN_STACK_SIZE: uint = 10000000; // XXX: Too much stack\n-\n+        \n         let start = Coroutine::build_start_wrapper(start);\n         let mut stack = stack_pool.take_segment(MIN_STACK_SIZE);\n         // NB: Context holds a pointer to that ~fn\n         let initial_context = Context::new(start, &mut stack);\n         return Coroutine {\n             current_stack_segment: stack,\n             saved_context: initial_context,\n-            task: task\n+            task: task,\n+            home_sched: home\n         };\n     }\n \n+    fn with_task(stack_pool: &mut StackPool,\n+                 task: ~Task,\n+                 start: ~fn()) -> Coroutine {\n+        Coroutine::with_task_homed(stack_pool,\n+                                   task,\n+                                   start,\n+                                   AnySched)\n+    }\n+\n     priv fn build_start_wrapper(start: ~fn()) -> ~fn() {\n         // XXX: The old code didn't have this extra allocation\n         let start_cell = Cell(start);\n@@ -549,17 +725,20 @@ pub impl Coroutine {\n \n                 let sched = Local::unsafe_borrow::<Scheduler>();\n                 let task = (*sched).current_task.get_mut_ref();\n-                // FIXME #6141: shouldn't neet to put `start()` in another closure\n+                // FIXME #6141: shouldn't neet to put `start()` in\n+                // another closure\n                 let start_cell = Cell(start_cell.take());\n                 do task.task.run {\n-                    // N.B. Removing `start` from the start wrapper closure\n-                    // by emptying a cell is critical for correctness. The ~Task\n-                    // pointer, and in turn the closure used to initialize the first\n-                    // call frame, is destroyed in scheduler context, not task context.\n-                    // So any captured closures must not contain user-definable dtors\n-                    // that expect to be in task context. By moving `start` out of\n-                    // the closure, all the user code goes out of scope while\n-                    // the task is still running.\n+                    // N.B. Removing `start` from the start wrapper\n+                    // closure by emptying a cell is critical for\n+                    // correctness. The ~Task pointer, and in turn the\n+                    // closure used to initialize the first call\n+                    // frame, is destroyed in scheduler context, not\n+                    // task context.  So any captured closures must\n+                    // not contain user-definable dtors that expect to\n+                    // be in task context. By moving `start` out of\n+                    // the closure, all the user code goes out of\n+                    // scope while the task is still running.\n                     let start = start_cell.take();\n                     start();\n                 };\n@@ -603,6 +782,156 @@ mod test {\n     use rt::test::*;\n     use super::*;\n     use rt::thread::Thread;\n+    use ptr::to_uint;\n+\n+    // Confirm that a sched_id actually is the uint form of the\n+    // pointer to the scheduler struct.\n+\n+    #[test]\n+    fn simple_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched = ~new_test_uv_sched();\n+            assert!(to_uint(sched) == sched.sched_id());\n+        }\n+    }\n+\n+    // Compare two scheduler ids that are different, this should never\n+    // fail but may catch a mistake someday.\n+\n+    #[test]\n+    fn compare_sched_id_test() {\n+        do run_in_bare_thread {\n+            let sched_one = ~new_test_uv_sched();\n+            let sched_two = ~new_test_uv_sched();\n+            assert!(sched_one.sched_id() != sched_two.sched_id());\n+        }\n+    }\n+\n+    // A simple test to check if a homed task run on a single\n+    // scheduler ends up executing while home.\n+\n+    #[test]\n+    fn test_home_sched() {\n+        do run_in_bare_thread {\n+            let mut task_ran = false;\n+            let task_ran_ptr: *mut bool = &mut task_ran;\n+            let mut sched = ~new_test_uv_sched();\n+\n+            let sched_handle = sched.make_handle();\n+            let sched_id = sched.sched_id();\n+            \n+            let task = ~do Coroutine::new_homed(&mut sched.stack_pool,\n+                                                Sched(sched_handle)) {\n+                unsafe { *task_ran_ptr = true };\n+                let sched = Local::take::<Scheduler>();\n+                assert!(sched.sched_id() == sched_id);\n+                Local::put::<Scheduler>(sched);\n+            };\n+            sched.enqueue_task(task);\n+            sched.run();\n+            assert!(task_ran);\n+        }\n+    }\n+\n+    // The following test is a bit of a mess, but it trys to do\n+    // something tricky so I'm not sure how to get around this in the\n+    // short term.\n+\n+    // A number of schedulers are created, and then a task is created\n+    // and assigned a home scheduler. It is then \"started\" on a\n+    // different scheduler. The scheduler it is started on should\n+    // observe that the task is not home, and send it home.\n+\n+    // This test is light in that it does very little.\n+                \n+    #[test]\n+    fn test_transfer_task_home() {        \n+\n+        use rt::uv::uvio::UvEventLoop;\n+        use rt::sched::Shutdown;\n+        use rt::sleeper_list::SleeperList;\n+        use rt::work_queue::WorkQueue;\n+        use uint;\n+        use container::Container;\n+        use old_iter::MutableIter;\n+        use vec::OwnedVector;\n+\n+        do run_in_bare_thread {\n+            \n+            static N: uint = 8;\n+            \n+            let sleepers = SleeperList::new();\n+            let work_queue = WorkQueue::new();\n+            \n+            let mut handles = ~[];\n+            let mut scheds = ~[];\n+            \n+            for uint::range(0, N) |_| {\n+                let loop_ = ~UvEventLoop::new();\n+                let mut sched = ~Scheduler::new(loop_, \n+                                                work_queue.clone(),\n+                                                sleepers.clone());\n+                let handle = sched.make_handle();\n+                rtdebug!(\"sched id: %u\", handle.sched_id);\n+                handles.push(handle);\n+                scheds.push(sched);\n+            };\n+\n+            let handles = Cell(handles);\n+\n+            let home_handle = scheds[6].make_handle();               \n+            let home_id = home_handle.sched_id;\n+            let home = Sched(home_handle);\n+\n+            let main_task = ~do Coroutine::new_homed(&mut scheds[1].stack_pool, home) {\n+\n+                // Here we check if the task is running on its home.\n+                let sched = Local::take::<Scheduler>();\n+                rtdebug!(\"run location scheduler id: %u, home: %u\",\n+                         sched.sched_id(),\n+                         home_id);\n+                assert!(sched.sched_id() == home_id);\n+                Local::put::<Scheduler>(sched);                 \n+\n+                let mut handles = handles.take();\n+                for handles.each_mut |handle| {\n+                    handle.send(Shutdown);\n+                }\n+            };\n+                \n+            scheds[0].enqueue_task(main_task);\n+            \n+            let mut threads = ~[];\n+            \n+            while !scheds.is_empty() {\n+                let sched = scheds.pop();\n+                let sched_cell = Cell(sched);\n+                let thread = do Thread::start {\n+                    let sched = sched_cell.take();\n+                    sched.run();\n+                };\n+                threads.push(thread);\n+            }\n+                \n+            let _threads = threads;\n+        }\n+    }\n+    \n+    // The goal is that this is the high-stress test for making sure\n+    // homing is working. It allocates 120*RUST_RT_STRESS tasks that\n+    // do nothing but assert that they are home at execution\n+    // time. These tasks are queued to random schedulers, so sometimes\n+    // they are home and sometimes not. It also runs RUST_RT_STRESS\n+    // times.\n+\n+    #[test]\n+    fn test_stress_homed_tasks() {\n+        let n = stress_factor();\n+        for int::range(0,n as int) |_| {\n+            run_in_mt_newsched_task_random_homed();\n+        }\n+    }\n+            \n \n     #[test]\n     fn test_simple_scheduling() {\n@@ -877,4 +1206,5 @@ mod test {\n             }\n         }        \n     }\n+\n }"}, {"sha": "97aa76d7db69970425155fe5128f829509566421", "filename": "src/libstd/rt/test.rs", "status": "modified", "additions": 124, "deletions": 0, "changes": 124, "blob_url": "https://github.com/rust-lang/rust/blob/84280819585fb65bf18903aef9364579f3552522/src%2Flibstd%2Frt%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/84280819585fb65bf18903aef9364579f3552522/src%2Flibstd%2Frt%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftest.rs?ref=84280819585fb65bf18903aef9364579f3552522", "patch": "@@ -88,6 +88,7 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n             let loop_ = ~UvEventLoop::new();\n             let mut sched = ~Scheduler::new(loop_, work_queue.clone(), sleepers.clone());\n             let handle = sched.make_handle();\n+\n             handles.push(handle);\n             scheds.push(sched);\n         }\n@@ -128,6 +129,96 @@ pub fn run_in_mt_newsched_task(f: ~fn()) {\n     }\n }\n \n+// THIS IS AWFUL. Copy-pasted the above initialization function but\n+// with a number of hacks to make it spawn tasks on a variety of\n+// schedulers with a variety of homes using the new spawn.\n+\n+pub fn run_in_mt_newsched_task_random_homed() {\n+    use libc;\n+    use os;\n+    use from_str::FromStr;\n+    use rt::uv::uvio::UvEventLoop;\n+    use rt::sched::Shutdown;\n+\n+    do run_in_bare_thread {\n+        let nthreads = match os::getenv(\"RUST_TEST_THREADS\") {\n+            Some(nstr) => FromStr::from_str(nstr).get(),\n+            None => unsafe {\n+                // Using more threads than cores in test code to force\n+                // the OS to preempt them frequently.  Assuming that\n+                // this help stress test concurrent types.\n+                rust_get_num_cpus() * 2\n+            }\n+        };\n+\n+        let sleepers = SleeperList::new();\n+        let work_queue = WorkQueue::new();\n+\n+        let mut handles = ~[];\n+        let mut scheds = ~[];\n+\n+        for uint::range(0, nthreads) |_| {\n+            let loop_ = ~UvEventLoop::new();\n+            let mut sched = ~Scheduler::new(loop_, work_queue.clone(), sleepers.clone());\n+            let handle = sched.make_handle();\n+            handles.push(handle);\n+            scheds.push(sched);\n+        }\n+\n+        // Schedule a pile o tasks\n+        let n = 120*stress_factor();        \n+        for uint::range(0,n) |_i| {\n+                rtdebug!(\"creating task: %u\", _i);\n+                let hf: ~fn() = || { assert!(true) };\n+                spawntask_homed(&mut scheds, hf);            \n+            }\n+\n+        let f: ~fn() = || { assert!(true); };\n+        \n+        let f_cell = Cell(f);\n+        let handles = Cell(handles);\n+\n+        rtdebug!(\"creating main task\");\n+        \n+        let main_task = ~do Coroutine::new(&mut scheds[0].stack_pool) {\n+            f_cell.take()();\n+            let mut handles = handles.take();\n+            // Tell schedulers to exit\n+            for handles.each_mut |handle| {\n+                handle.send(Shutdown);\n+            }\n+        };\n+\n+        rtdebug!(\"queuing main task\")\n+        \n+        scheds[0].enqueue_task(main_task);\n+\n+        let mut threads = ~[];\n+\n+        while !scheds.is_empty() {\n+            let sched = scheds.pop();\n+            let sched_cell = Cell(sched);\n+            let thread = do Thread::start {\n+                let sched = sched_cell.take();\n+                rtdebug!(\"running sched: %u\", sched.sched_id());\n+                sched.run();\n+            };\n+\n+            threads.push(thread);\n+        }\n+\n+        rtdebug!(\"waiting on scheduler threads\");\n+\n+        // Wait for schedulers\n+        let _threads = threads;\n+    }\n+\n+    extern {\n+        fn rust_get_num_cpus() -> libc::uintptr_t;\n+    }\n+}\n+\n+\n /// Test tasks will abort on failure instead of unwinding\n pub fn spawntask(f: ~fn()) {\n     use super::sched::*;\n@@ -188,6 +279,38 @@ pub fn spawntask_random(f: ~fn()) {\n     }\n }\n \n+/// Spawn a task, with the current scheduler as home, and queue it to\n+/// run later.\n+pub fn spawntask_homed(scheds: &mut ~[~Scheduler], f: ~fn()) {\n+    use super::sched::*;\n+    use rand::{rng, RngUtil};\n+    let mut rng = rng();\n+    \n+    let task = {\n+        let sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+        let handle = sched.make_handle();\n+        let home_id = handle.sched_id;\n+\n+        // now that we know where this is going, build a new function\n+        // that can assert it is in the right place\n+        let af: ~fn() = || {\n+            do Local::borrow::<Scheduler,()>() |sched| {\n+                rtdebug!(\"home_id: %u, runtime loc: %u\",\n+                         home_id,\n+                         sched.sched_id());\n+                assert!(home_id == sched.sched_id());\n+            };\n+            f()\n+        };            \n+    \n+        ~Coroutine::with_task_homed(&mut sched.stack_pool,\n+                                    ~Task::without_unwinding(),\n+                                    af,\n+                                    Sched(handle))\n+    };\n+    let dest_sched = &mut scheds[rng.gen_int_range(0,scheds.len() as int)];\n+    dest_sched.enqueue_task(task);\n+}\n \n /// Spawn a task and wait for it to finish, returning whether it completed successfully or failed\n pub fn spawntask_try(f: ~fn()) -> Result<(), ()> {\n@@ -266,3 +389,4 @@ pub fn stress_factor() -> uint {\n     }\n }\n \n+"}]}