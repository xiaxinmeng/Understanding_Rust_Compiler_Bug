{"sha": "b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "node_id": "MDY6Q29tbWl0NzI0NzEyOmI1ZTM1YjEyOGVmZWVkNGJmZGI0YjFlZTlkMDY5NzM4OWVjOWYxNjQ=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-07-30T09:33:32Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-08-05T10:15:11Z"}, "message": "remove special code path for unknown tokens", "tree": {"sha": "6ef17b7b48b314b6b7aef0e42eb7f17f15d076cf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6ef17b7b48b314b6b7aef0e42eb7f17f15d076cf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "html_url": "https://github.com/rust-lang/rust/commit/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e1d7e4ae82c5500407e606c0b2b595597b9981f3", "url": "https://api.github.com/repos/rust-lang/rust/commits/e1d7e4ae82c5500407e606c0b2b595597b9981f3", "html_url": "https://github.com/rust-lang/rust/commit/e1d7e4ae82c5500407e606c0b2b595597b9981f3"}], "stats": {"total": 98, "additions": 37, "deletions": 61}, "files": [{"sha": "c209ae1cb9f1f9db9830a27ee3ce69f7deb41713", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 13, "deletions": 60, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "patch": "@@ -3,7 +3,7 @@ use crate::parse::token::{self, Token, TokenKind};\n use crate::symbol::{sym, Symbol};\n use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_char};\n \n-use errors::{FatalError, Diagnostic, DiagnosticBuilder};\n+use errors::{FatalError, DiagnosticBuilder};\n use syntax_pos::{BytePos, Pos, Span, NO_EXPANSION};\n use rustc_lexer::Base;\n use rustc_lexer::unescape;\n@@ -39,7 +39,6 @@ pub struct StringReader<'a> {\n     pos: BytePos,\n     /// Stop reading src at this index.\n     end_src_index: usize,\n-    fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     /// Source text to tokenize.\n     src: Lrc<String>,\n     override_span: Option<Span>,\n@@ -62,7 +61,6 @@ impl<'a> StringReader<'a> {\n             pos: source_file.start_pos,\n             end_src_index: src.len(),\n             src,\n-            fatal_errs: Vec::new(),\n             override_span,\n         }\n     }\n@@ -89,29 +87,17 @@ impl<'a> StringReader<'a> {\n         self.override_span.unwrap_or_else(|| Span::new(lo, hi, NO_EXPANSION))\n     }\n \n-    fn unwrap_or_abort(&mut self, res: Result<Token, ()>) -> Token {\n-        match res {\n-            Ok(tok) => tok,\n-            Err(_) => {\n-                self.emit_fatal_errors();\n-                FatalError.raise();\n-            }\n-        }\n-    }\n-\n     /// Returns the next token, including trivia like whitespace or comments.\n     ///\n     /// `Err(())` means that some errors were encountered, which can be\n     /// retrieved using `buffer_fatal_errors`.\n-    pub fn try_next_token(&mut self) -> Result<Token, ()> {\n-        assert!(self.fatal_errs.is_empty());\n-\n+    pub fn next_token(&mut self) -> Token {\n         let start_src_index = self.src_index(self.pos);\n         let text: &str = &self.src[start_src_index..self.end_src_index];\n \n         if text.is_empty() {\n             let span = self.mk_sp(self.pos, self.pos);\n-            return Ok(Token::new(token::Eof, span));\n+            return Token::new(token::Eof, span);\n         }\n \n         {\n@@ -125,7 +111,7 @@ impl<'a> StringReader<'a> {\n                     let kind = token::Shebang(sym);\n \n                     let span = self.mk_sp(start, self.pos);\n-                    return Ok(Token::new(kind, span));\n+                    return Token::new(kind, span);\n                 }\n             }\n         }\n@@ -139,39 +125,10 @@ impl<'a> StringReader<'a> {\n \n         // This could use `?`, but that makes code significantly (10-20%) slower.\n         // https://github.com/rust-lang/rust/issues/37939\n-        let kind = match self.cook_lexer_token(token.kind, start) {\n-            Ok(it) => it,\n-            Err(err) => return Err(self.fatal_errs.push(err)),\n-        };\n+        let kind = self.cook_lexer_token(token.kind, start);\n \n         let span = self.mk_sp(start, self.pos);\n-        Ok(Token::new(kind, span))\n-    }\n-\n-    /// Returns the next token, including trivia like whitespace or comments.\n-    ///\n-    /// Aborts in case of an error.\n-    pub fn next_token(&mut self) -> Token {\n-        let res = self.try_next_token();\n-        self.unwrap_or_abort(res)\n-    }\n-\n-    fn emit_fatal_errors(&mut self) {\n-        for err in &mut self.fatal_errs {\n-            err.emit();\n-        }\n-\n-        self.fatal_errs.clear();\n-    }\n-\n-    pub fn buffer_fatal_errors(&mut self) -> Vec<Diagnostic> {\n-        let mut buffer = Vec::new();\n-\n-        for err in self.fatal_errs.drain(..) {\n-            err.buffer(&mut buffer);\n-        }\n-\n-        buffer\n+        Token::new(kind, span)\n     }\n \n     /// Report a fatal lexical error with a given span.\n@@ -218,8 +175,8 @@ impl<'a> StringReader<'a> {\n         &self,\n         token: rustc_lexer::TokenKind,\n         start: BytePos,\n-    ) -> Result<TokenKind, DiagnosticBuilder<'a>> {\n-        let kind = match token {\n+    ) -> TokenKind {\n+        match token {\n             rustc_lexer::TokenKind::LineComment => {\n                 let string = self.str_from(start);\n                 // comments with only more \"/\"s are not doc comments\n@@ -396,16 +353,12 @@ impl<'a> StringReader<'a> {\n                 // this should be inside `rustc_lexer`. However, we should first remove compound\n                 // tokens like `<<` from `rustc_lexer`, and then add fancier error recovery to it,\n                 // as there will be less overall work to do this way.\n-                return match unicode_chars::check_for_substitution(self, start, c, &mut err) {\n-                    Some(token) => {\n-                        err.emit();\n-                        Ok(token)\n-                    }\n-                    None => Err(err),\n-                }\n+                let token = unicode_chars::check_for_substitution(self, start, c, &mut err)\n+                    .unwrap_or(token::Whitespace);\n+                err.emit();\n+                token\n             }\n-        };\n-        Ok(kind)\n+        }\n     }\n \n     fn cook_lexer_literal("}, {"sha": "9e4824611128d1d64fdc4234da5716a7758af2e5", "filename": "src/test/ui/parser/lex-bad-token.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-bad-token.rs?ref=b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "patch": "@@ -1 +1,3 @@\n \u25cf //~ ERROR: unknown start of token\n+\n+fn main() {}"}, {"sha": "bb27f44c279f7ccf4c903c8f5e82a29e20b937b5", "filename": "src/test/ui/parser/lex-stray-backslash.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Flex-stray-backslash.rs?ref=b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "patch": "@@ -1 +1,3 @@\n \\ //~ ERROR: unknown start of token: \\\n+\n+fn main() {}"}, {"sha": "1812dad81afc34b92c0f1a998d8447e86be5ba9c", "filename": "src/test/ui/parser/unicode-quote-chars.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.rs?ref=b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "patch": "@@ -4,4 +4,7 @@ fn main() {\n     println!(\u201chello world\u201d);\n     //~^ ERROR unknown start of token: \\u{201c}\n     //~^^ HELP Unicode characters '\u201c' (Left Double Quotation Mark) and '\u201d' (Right Double Quotation Mark) look like '\"' (Quotation Mark), but are not\n+    //~^^^ ERROR unknown start of token: \\u{201d}\n+    //~^^^^ HELP Unicode character '\u201d' (Right Double Quotation Mark) looks like '\"' (Quotation Mark), but it is not\n+    //~^^^^^ ERROR expected token: `,`\n }"}, {"sha": "84e45ecd873a4852564cf35c13800b5e4299492d", "filename": "src/test/ui/parser/unicode-quote-chars.stderr", "status": "modified", "additions": 17, "deletions": 1, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/b5e35b128efeed4bfdb4b1ee9d0697389ec9f164/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fparser%2Funicode-quote-chars.stderr?ref=b5e35b128efeed4bfdb4b1ee9d0697389ec9f164", "patch": "@@ -8,5 +8,21 @@ help: Unicode characters '\u201c' (Left Double Quotation Mark) and '\u201d' (Right Dou\n LL |     println!(\"hello world\");\n    |              ^^^^^^^^^^^^^\n \n-error: aborting due to previous error\n+error: unknown start of token: \\u{201d}\n+  --> $DIR/unicode-quote-chars.rs:4:26\n+   |\n+LL |     println!(\u201chello world\u201d);\n+   |                          ^\n+help: Unicode character '\u201d' (Right Double Quotation Mark) looks like '\"' (Quotation Mark), but it is not\n+   |\n+LL |     println!(\u201chello world\");\n+   |                          ^\n+\n+error: expected token: `,`\n+  --> $DIR/unicode-quote-chars.rs:4:21\n+   |\n+LL |     println!(\u201chello world\u201d);\n+   |                     ^^^^^ expected `,`\n+\n+error: aborting due to 3 previous errors\n "}]}