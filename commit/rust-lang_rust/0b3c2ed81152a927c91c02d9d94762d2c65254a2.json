{"sha": "0b3c2ed81152a927c91c02d9d94762d2c65254a2", "node_id": "C_kwDOAAsO6NoAKDBiM2MyZWQ4MTE1MmE5MjdjOTFjMDJkOWQ5NDc2MmQyYzY1MjU0YTI", "commit": {"author": {"name": "Jason Newcomb", "email": "jsnewcomb@pm.me", "date": "2023-03-08T03:51:35Z"}, "committer": {"name": "Jason Newcomb", "email": "jsnewcomb@pm.me", "date": "2023-05-18T19:43:23Z"}, "message": "Search for inactive `cfg` attributes and empty macro expansion through\nthe entire block", "tree": {"sha": "88c39fb9c211fac0e61ba0b9796f46ecca6a260f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/88c39fb9c211fac0e61ba0b9796f46ecca6a260f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0b3c2ed81152a927c91c02d9d94762d2c65254a2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0b3c2ed81152a927c91c02d9d94762d2c65254a2", "html_url": "https://github.com/rust-lang/rust/commit/0b3c2ed81152a927c91c02d9d94762d2c65254a2", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0b3c2ed81152a927c91c02d9d94762d2c65254a2/comments", "author": {"login": "Jarcho", "id": 7761774, "node_id": "MDQ6VXNlcjc3NjE3NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/7761774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jarcho", "html_url": "https://github.com/Jarcho", "followers_url": "https://api.github.com/users/Jarcho/followers", "following_url": "https://api.github.com/users/Jarcho/following{/other_user}", "gists_url": "https://api.github.com/users/Jarcho/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jarcho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jarcho/subscriptions", "organizations_url": "https://api.github.com/users/Jarcho/orgs", "repos_url": "https://api.github.com/users/Jarcho/repos", "events_url": "https://api.github.com/users/Jarcho/events{/privacy}", "received_events_url": "https://api.github.com/users/Jarcho/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Jarcho", "id": 7761774, "node_id": "MDQ6VXNlcjc3NjE3NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/7761774?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jarcho", "html_url": "https://github.com/Jarcho", "followers_url": "https://api.github.com/users/Jarcho/followers", "following_url": "https://api.github.com/users/Jarcho/following{/other_user}", "gists_url": "https://api.github.com/users/Jarcho/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jarcho/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jarcho/subscriptions", "organizations_url": "https://api.github.com/users/Jarcho/orgs", "repos_url": "https://api.github.com/users/Jarcho/repos", "events_url": "https://api.github.com/users/Jarcho/events{/privacy}", "received_events_url": "https://api.github.com/users/Jarcho/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "392e9551d422f40a3077e31ea04fd81134bbeed1", "url": "https://api.github.com/repos/rust-lang/rust/commits/392e9551d422f40a3077e31ea04fd81134bbeed1", "html_url": "https://github.com/rust-lang/rust/commit/392e9551d422f40a3077e31ea04fd81134bbeed1"}], "stats": {"total": 303, "additions": 229, "deletions": 74}, "files": [{"sha": "55ec9d4474f59de08eef3a39d1c7ed28c296e581", "filename": "clippy_lints/src/matches/mod.rs", "status": "modified", "additions": 4, "deletions": 9, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_lints%2Fsrc%2Fmatches%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_lints%2Fsrc%2Fmatches%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_lints%2Fsrc%2Fmatches%2Fmod.rs?ref=0b3c2ed81152a927c91c02d9d94762d2c65254a2", "patch": "@@ -25,9 +25,9 @@ mod wild_in_or_pats;\n \n use clippy_utils::msrvs::{self, Msrv};\n use clippy_utils::source::{snippet_opt, walk_span_to_context};\n-use clippy_utils::{higher, in_constant, is_span_match};\n+use clippy_utils::{higher, in_constant, is_span_match, tokenize_with_text};\n use rustc_hir::{Arm, Expr, ExprKind, Local, MatchSource, Pat};\n-use rustc_lexer::{tokenize, TokenKind};\n+use rustc_lexer::TokenKind;\n use rustc_lint::{LateContext, LateLintPass, LintContext};\n use rustc_middle::lint::in_external_macro;\n use rustc_session::{declare_tool_lint, impl_lint_pass};\n@@ -1147,12 +1147,7 @@ fn span_contains_cfg(cx: &LateContext<'_>, s: Span) -> bool {\n         // Assume true. This would require either an invalid span, or one which crosses file boundaries.\n         return true;\n     };\n-    let mut pos = 0usize;\n-    let mut iter = tokenize(&snip).map(|t| {\n-        let start = pos;\n-        pos += t.len as usize;\n-        (t.kind, start..pos)\n-    });\n+    let mut iter = tokenize_with_text(&snip);\n \n     // Search for the token sequence [`#`, `[`, `cfg`]\n     while iter.any(|(t, _)| matches!(t, TokenKind::Pound)) {\n@@ -1163,7 +1158,7 @@ fn span_contains_cfg(cx: &LateContext<'_>, s: Span) -> bool {\n             )\n         });\n         if matches!(iter.next(), Some((TokenKind::OpenBracket, _)))\n-            && matches!(iter.next(), Some((TokenKind::Ident, range)) if &snip[range.clone()] == \"cfg\")\n+            && matches!(iter.next(), Some((TokenKind::Ident, \"cfg\")))\n         {\n             return true;\n         }"}, {"sha": "3561e760ac99d393d3b15b7ad63d1de3cd00de45", "filename": "clippy_utils/src/hir_utils.rs", "status": "modified", "additions": 110, "deletions": 46, "changes": 156, "blob_url": "https://github.com/rust-lang/rust/blob/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Fhir_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Fhir_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_utils%2Fsrc%2Fhir_utils.rs?ref=0b3c2ed81152a927c91c02d9d94762d2c65254a2", "patch": "@@ -1,6 +1,7 @@\n use crate::consts::constant_simple;\n use crate::macros::macro_backtrace;\n-use crate::source::snippet_opt;\n+use crate::source::{get_source_text, snippet_opt, walk_span_to_context, SpanRange};\n+use crate::tokenize_with_text;\n use rustc_ast::ast::InlineAsmTemplatePiece;\n use rustc_data_structures::fx::FxHasher;\n use rustc_hir::def::Res;\n@@ -13,8 +14,9 @@ use rustc_hir::{\n use rustc_lexer::{tokenize, TokenKind};\n use rustc_lint::LateContext;\n use rustc_middle::ty::TypeckResults;\n-use rustc_span::{sym, Symbol};\n+use rustc_span::{sym, BytePos, Symbol, SyntaxContext};\n use std::hash::{Hash, Hasher};\n+use std::ops::Range;\n \n /// Callback that is called when two expressions are not equal in the sense of `SpanlessEq`, but\n /// other conditions would make them equal.\n@@ -127,51 +129,83 @@ impl HirEqInterExpr<'_, '_, '_> {\n \n     /// Checks whether two blocks are the same.\n     fn eq_block(&mut self, left: &Block<'_>, right: &Block<'_>) -> bool {\n-        match (left.stmts, left.expr, right.stmts, right.expr) {\n-            ([], None, [], None) => {\n-                // For empty blocks, check to see if the tokens are equal. This will catch the case where a macro\n-                // expanded to nothing, or the cfg attribute was used.\n-                let (Some(left), Some(right)) = (\n-                    snippet_opt(self.inner.cx, left.span),\n-                    snippet_opt(self.inner.cx, right.span),\n-                ) else { return true };\n-                let mut left_pos = 0;\n-                let left = tokenize(&left)\n-                    .map(|t| {\n-                        let end = left_pos + t.len as usize;\n-                        let s = &left[left_pos..end];\n-                        left_pos = end;\n-                        (t, s)\n-                    })\n-                    .filter(|(t, _)| {\n-                        !matches!(\n-                            t.kind,\n-                            TokenKind::LineComment { .. } | TokenKind::BlockComment { .. } | TokenKind::Whitespace\n-                        )\n-                    })\n-                    .map(|(_, s)| s);\n-                let mut right_pos = 0;\n-                let right = tokenize(&right)\n-                    .map(|t| {\n-                        let end = right_pos + t.len as usize;\n-                        let s = &right[right_pos..end];\n-                        right_pos = end;\n-                        (t, s)\n-                    })\n-                    .filter(|(t, _)| {\n-                        !matches!(\n-                            t.kind,\n-                            TokenKind::LineComment { .. } | TokenKind::BlockComment { .. } | TokenKind::Whitespace\n-                        )\n-                    })\n-                    .map(|(_, s)| s);\n-                left.eq(right)\n-            },\n-            _ => {\n-                over(left.stmts, right.stmts, |l, r| self.eq_stmt(l, r))\n-                    && both(&left.expr, &right.expr, |l, r| self.eq_expr(l, r))\n-            },\n+        use TokenKind::{BlockComment, LineComment, Semi, Whitespace};\n+        if left.stmts.len() != right.stmts.len() {\n+            return false;\n         }\n+        let lspan = left.span.data();\n+        let rspan = right.span.data();\n+        if lspan.ctxt != SyntaxContext::root() && rspan.ctxt != SyntaxContext::root() {\n+            // Don't try to check in between statements inside macros.\n+            return over(left.stmts, right.stmts, |left, right| self.eq_stmt(left, right))\n+                && both(&left.expr, &right.expr, |left, right| self.eq_expr(left, right));\n+        }\n+        if lspan.ctxt != rspan.ctxt {\n+            return false;\n+        }\n+\n+        let mut lstart = lspan.lo;\n+        let mut rstart = rspan.lo;\n+\n+        for (left, right) in left.stmts.iter().zip(right.stmts) {\n+            if !self.eq_stmt(left, right) {\n+                return false;\n+            }\n+            let Some(lstmt_span) = walk_span_to_context(left.span, lspan.ctxt) else {\n+                return false;\n+            };\n+            let Some(rstmt_span) = walk_span_to_context(right.span, rspan.ctxt) else {\n+                return false;\n+            };\n+            let lstmt_span = lstmt_span.data();\n+            let rstmt_span = rstmt_span.data();\n+\n+            if lstmt_span.lo < lstart && rstmt_span.lo < rstart {\n+                // Can happen when macros expand to multiple statements, or rearrange statements.\n+                // Nothing in between the statements to check in this case.\n+                continue;\n+            } else if lstmt_span.lo < lstart || rstmt_span.lo < rstart {\n+                // Only one of the blocks had a weird macro.\n+                return false;\n+            }\n+            if !eq_span_tokens(self.inner.cx, lstart..lstmt_span.lo, rstart..rstmt_span.lo, |t| {\n+                !matches!(t, Whitespace | LineComment { .. } | BlockComment { .. } | Semi)\n+            }) {\n+                return false;\n+            }\n+\n+            lstart = lstmt_span.hi;\n+            rstart = rstmt_span.hi;\n+        }\n+\n+        let (lend, rend) = match (left.expr, right.expr) {\n+            (Some(left), Some(right)) => {\n+                if !self.eq_expr(left, right) {\n+                    return false;\n+                }\n+                let Some(lexpr_span) = walk_span_to_context(left.span, lspan.ctxt) else {\n+                    return false;\n+                };\n+                let Some(rexpr_span) = walk_span_to_context(right.span, rspan.ctxt) else {\n+                    return false;\n+                };\n+                (lexpr_span.lo(), rexpr_span.lo())\n+            },\n+            (None, None) => (lspan.hi, rspan.hi),\n+            (Some(_), None) | (None, Some(_)) => return false,\n+        };\n+\n+        if lend < lstart && rend < rstart {\n+            // Can happen when macros rearrange the input.\n+            // Nothing in between the statements to check in this case.\n+            return true;\n+        } else if lend < lstart || rend < rstart {\n+            // Only one of the blocks had a weird macro\n+            return false;\n+        }\n+        eq_span_tokens(self.inner.cx, lstart..lend, rstart..rend, |t| {\n+            !matches!(t, Whitespace | LineComment { .. } | BlockComment { .. } | Semi)\n+        })\n     }\n \n     fn should_ignore(&mut self, expr: &Expr<'_>) -> bool {\n@@ -1038,3 +1072,33 @@ pub fn hash_expr(cx: &LateContext<'_>, e: &Expr<'_>) -> u64 {\n     h.hash_expr(e);\n     h.finish()\n }\n+\n+fn eq_span_tokens(\n+    cx: &LateContext<'_>,\n+    left: impl SpanRange,\n+    right: impl SpanRange,\n+    pred: impl Fn(TokenKind) -> bool,\n+) -> bool {\n+    fn f(cx: &LateContext<'_>, left: Range<BytePos>, right: Range<BytePos>, pred: impl Fn(TokenKind) -> bool) -> bool {\n+        if let Some(lsrc) = get_source_text(cx, left)\n+            && let Some(lsrc) = lsrc.as_str()\n+            && let Some(rsrc) = get_source_text(cx, right)\n+            && let Some(rsrc) = rsrc.as_str()\n+        {\n+            let pred = |t: &(_, _)| pred(t.0);\n+            let map = |(_, x)| x;\n+\n+            let ltok = tokenize_with_text(lsrc)\n+                .filter(pred)\n+                .map(map);\n+            let rtok = tokenize_with_text(rsrc)\n+                .filter(pred)\n+                .map(map);\n+            ltok.eq(rtok)\n+        } else {\n+            // Unable to access the source. Conservatively assume the blocks aren't equal.\n+            false\n+        }\n+    }\n+    f(cx, left.into_range(), right.into_range(), pred)\n+}"}, {"sha": "2ddd2ade6ae4da0af00084070f4a924a276bd812", "filename": "clippy_utils/src/lib.rs", "status": "modified", "additions": 17, "deletions": 17, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_utils%2Fsrc%2Flib.rs?ref=0b3c2ed81152a927c91c02d9d94762d2c65254a2", "patch": "@@ -77,6 +77,7 @@ use std::sync::OnceLock;\n use std::sync::{Mutex, MutexGuard};\n \n use if_chain::if_chain;\n+use itertools::Itertools;\n use rustc_ast::ast::{self, LitKind, RangeLimits};\n use rustc_ast::Attribute;\n use rustc_data_structures::fx::FxHashMap;\n@@ -2490,6 +2491,17 @@ pub fn walk_to_expr_usage<'tcx, T>(\n     None\n }\n \n+/// Tokenizes the input while keeping the text associated with each token.\n+pub fn tokenize_with_text(s: &str) -> impl Iterator<Item = (TokenKind, &str)> {\n+    let mut pos = 0;\n+    tokenize(s).map(move |t| {\n+        let end = pos + t.len;\n+        let range = pos as usize..end as usize;\n+        pos = end;\n+        (t.kind, s.get(range).unwrap_or_default())\n+    })\n+}\n+\n /// Checks whether a given span has any comment token\n /// This checks for all types of comment: line \"//\", block \"/**\", doc \"///\" \"//!\"\n pub fn span_contains_comment(sm: &SourceMap, span: Span) -> bool {\n@@ -2506,23 +2518,11 @@ pub fn span_contains_comment(sm: &SourceMap, span: Span) -> bool {\n /// Comments are returned wrapped with their relevant delimiters\n pub fn span_extract_comment(sm: &SourceMap, span: Span) -> String {\n     let snippet = sm.span_to_snippet(span).unwrap_or_default();\n-    let mut comments_buf: Vec<String> = Vec::new();\n-    let mut index: usize = 0;\n-\n-    for token in tokenize(&snippet) {\n-        let token_range = index..(index + token.len as usize);\n-        index += token.len as usize;\n-        match token.kind {\n-            TokenKind::BlockComment { .. } | TokenKind::LineComment { .. } => {\n-                if let Some(comment) = snippet.get(token_range) {\n-                    comments_buf.push(comment.to_string());\n-                }\n-            },\n-            _ => (),\n-        }\n-    }\n-\n-    comments_buf.join(\"\\n\")\n+    let res = tokenize_with_text(&snippet)\n+        .filter(|(t, _)| matches!(t, TokenKind::BlockComment { .. } | TokenKind::LineComment { .. }))\n+        .map(|(_, s)| s)\n+        .join(\"\\n\");\n+    res\n }\n \n pub fn span_find_starting_semi(sm: &SourceMap, span: Span) -> Span {"}, {"sha": "0f60290644a18daba5232f76b4502961756e57d5", "filename": "clippy_utils/src/source.rs", "status": "modified", "additions": 51, "deletions": 1, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Fsource.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b3c2ed81152a927c91c02d9d94762d2c65254a2/clippy_utils%2Fsrc%2Fsource.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_utils%2Fsrc%2Fsource.rs?ref=0b3c2ed81152a927c91c02d9d94762d2c65254a2", "patch": "@@ -2,14 +2,64 @@\n \n #![allow(clippy::module_name_repetitions)]\n \n+use rustc_data_structures::sync::Lrc;\n use rustc_errors::Applicability;\n use rustc_hir::{Expr, ExprKind};\n use rustc_lint::{LateContext, LintContext};\n use rustc_session::Session;\n-use rustc_span::hygiene;\n use rustc_span::source_map::{original_sp, SourceMap};\n+use rustc_span::{hygiene, SourceFile};\n use rustc_span::{BytePos, Pos, Span, SpanData, SyntaxContext, DUMMY_SP};\n use std::borrow::Cow;\n+use std::ops::Range;\n+\n+/// A type which can be converted to the range portion of a `Span`.\n+pub trait SpanRange {\n+    fn into_range(self) -> Range<BytePos>;\n+}\n+impl SpanRange for Span {\n+    fn into_range(self) -> Range<BytePos> {\n+        let data = self.data();\n+        data.lo..data.hi\n+    }\n+}\n+impl SpanRange for SpanData {\n+    fn into_range(self) -> Range<BytePos> {\n+        self.lo..self.hi\n+    }\n+}\n+impl SpanRange for Range<BytePos> {\n+    fn into_range(self) -> Range<BytePos> {\n+        self\n+    }\n+}\n+\n+pub struct SourceFileRange {\n+    pub sf: Lrc<SourceFile>,\n+    pub range: Range<usize>,\n+}\n+impl SourceFileRange {\n+    /// Attempts to get the text from the source file. This can fail if the source text isn't\n+    /// loaded.\n+    pub fn as_str(&self) -> Option<&str> {\n+        self.sf.src.as_ref().and_then(|x| x.get(self.range.clone()))\n+    }\n+}\n+\n+/// Gets the source file, and range in the file, of the given span. Returns `None` if the span\n+/// extends through multiple files, or is malformed.\n+pub fn get_source_text(cx: &impl LintContext, sp: impl SpanRange) -> Option<SourceFileRange> {\n+    fn f(sm: &SourceMap, sp: Range<BytePos>) -> Option<SourceFileRange> {\n+        let start = sm.lookup_byte_offset(sp.start);\n+        let end = sm.lookup_byte_offset(sp.end);\n+        if !Lrc::ptr_eq(&start.sf, &end.sf) || start.pos > end.pos {\n+            return None;\n+        }\n+        let range = start.pos.to_usize()..end.pos.to_usize();\n+        Some(SourceFileRange { sf: start.sf, range })\n+    }\n+    f(cx.sess().source_map(), sp.into_range())\n+}\n \n /// Like `snippet_block`, but add braces if the expr is not an `ExprKind::Block`.\n pub fn expr_block<T: LintContext>("}, {"sha": "15410734dec0b103ee81383e37fd205d427849c9", "filename": "tests/ui/match_same_arms.rs", "status": "modified", "additions": 47, "deletions": 1, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/0b3c2ed81152a927c91c02d9d94762d2c65254a2/tests%2Fui%2Fmatch_same_arms.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0b3c2ed81152a927c91c02d9d94762d2c65254a2/tests%2Fui%2Fmatch_same_arms.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/tests%2Fui%2Fmatch_same_arms.rs?ref=0b3c2ed81152a927c91c02d9d94762d2c65254a2", "patch": "@@ -53,4 +53,50 @@ mod issue4244 {\n     }\n }\n \n-fn main() {}\n+macro_rules! m {\n+    (foo) => {};\n+    (bar) => {};\n+}\n+\n+fn main() {\n+    let x = 0;\n+    let _ = match 0 {\n+        0 => {\n+            m!(foo);\n+            x\n+        },\n+        1 => {\n+            m!(bar);\n+            x\n+        },\n+        _ => 1,\n+    };\n+\n+    let _ = match 0 {\n+        0 => {\n+            let mut x = 0;\n+            #[cfg(not_enabled)]\n+            {\n+                x = 5;\n+            }\n+            #[cfg(not(not_enabled))]\n+            {\n+                x = 6;\n+            }\n+            x\n+        },\n+        1 => {\n+            let mut x = 0;\n+            #[cfg(also_not_enabled)]\n+            {\n+                x = 5;\n+            }\n+            #[cfg(not(also_not_enabled))]\n+            {\n+                x = 6;\n+            }\n+            x\n+        },\n+        _ => 0,\n+    };\n+}"}]}