{"sha": "48918fab7226593a4ad406cd83edb46e5c15dd15", "node_id": "MDY6Q29tbWl0NzI0NzEyOjQ4OTE4ZmFiNzIyNjU5M2E0YWQ0MDZjZDgzZWRiNDZlNWMxNWRkMTU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-01-01T21:21:48Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-01-01T21:21:48Z"}, "message": "auto merge of #11212 : alexcrichton/rust/local-task-count, r=brson\n\nFor libgreen, bookeeping should not be global but rather on a per-pool basis.\r\nInside libnative, it's known that there must be a global counter with a\r\nmutex/cvar.\r\n\r\nThe benefit of taking this strategy is to remove this functionality from libstd\r\nto allow fine-grained control of it through libnative/libgreen. Notably, helper\r\nthreads in libnative can manually decrement the global count so they don't count\r\ntowards the global count of threads. Also, the shutdown process of *all* sched\r\npools is now dependent on the number of tasks in the pool being 0 rather than\r\nthis only being a hardcoded solution for the initial sched pool in libgreen.\r\n\r\nThis involved adding a Local::try_take() method on the Local trait in order for\r\nthe channel wakeup to work inside of libgreen. The channel send was happening\r\nfrom a SchedTask when there is no Task available in TLS, and now this is\r\npossible to work (remote wakeups are always possible, just a little slower).", "tree": {"sha": "26b5b7697a984e21b9fb7aae896fee6e484405ca", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/26b5b7697a984e21b9fb7aae896fee6e484405ca"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/48918fab7226593a4ad406cd83edb46e5c15dd15", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/48918fab7226593a4ad406cd83edb46e5c15dd15", "html_url": "https://github.com/rust-lang/rust/commit/48918fab7226593a4ad406cd83edb46e5c15dd15", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/48918fab7226593a4ad406cd83edb46e5c15dd15/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c34ef5d7e4f44f8e65600a2c3866f5861c401ea1", "url": "https://api.github.com/repos/rust-lang/rust/commits/c34ef5d7e4f44f8e65600a2c3866f5861c401ea1", "html_url": "https://github.com/rust-lang/rust/commit/c34ef5d7e4f44f8e65600a2c3866f5861c401ea1"}, {"sha": "3f11f8738201dcf230a1647e30c312c980513b37", "url": "https://api.github.com/repos/rust-lang/rust/commits/3f11f8738201dcf230a1647e30c312c980513b37", "html_url": "https://github.com/rust-lang/rust/commit/3f11f8738201dcf230a1647e30c312c980513b37"}], "stats": {"total": 315, "additions": 244, "deletions": 71}, "files": [{"sha": "3ddd1f05f254dc629b704f913b4236ca3296130c", "filename": "src/libgreen/lib.rs", "status": "modified", "additions": 77, "deletions": 15, "changes": 92, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -25,18 +25,20 @@\n // NB this does *not* include globs, please keep it that way.\n #[feature(macro_rules)];\n \n+// Allow check-stage0-green for now\n+#[cfg(test, stage0)] extern mod green;\n+\n use std::os;\n use std::rt::crate_map;\n-use std::rt::local::Local;\n use std::rt::rtio;\n-use std::rt::task::Task;\n use std::rt::thread::Thread;\n use std::rt;\n use std::sync::atomics::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n use std::sync::deque;\n use std::task::TaskOpts;\n use std::util;\n use std::vec;\n+use std::sync::arc::UnsafeArc;\n \n use sched::{Shutdown, Scheduler, SchedHandle, TaskFromFriend, NewNeighbor};\n use sleeper_list::SleeperList;\n@@ -118,14 +120,6 @@ pub fn run(main: proc()) -> int {\n         os::set_exit_status(rt::DEFAULT_ERROR_CODE);\n     }\n \n-    // Once the main task has exited and we've set our exit code, wait for all\n-    // spawned sub-tasks to finish running. This is done to allow all schedulers\n-    // to remain active while there are still tasks possibly running.\n-    unsafe {\n-        let mut task = Local::borrow(None::<Task>);\n-        task.get().wait_for_other_tasks();\n-    }\n-\n     // Now that we're sure all tasks are dead, shut down the pool of schedulers,\n     // waiting for them all to return.\n     pool.shutdown();\n@@ -164,6 +158,17 @@ pub struct SchedPool {\n     priv deque_pool: deque::BufferPool<~task::GreenTask>,\n     priv sleepers: SleeperList,\n     priv factory: fn() -> ~rtio::EventLoop,\n+    priv task_state: TaskState,\n+    priv tasks_done: Port<()>,\n+}\n+\n+/// This is an internal state shared among a pool of schedulers. This is used to\n+/// keep track of how many tasks are currently running in the pool and then\n+/// sending on a channel once the entire pool has been drained of all tasks.\n+#[deriving(Clone)]\n+struct TaskState {\n+    cnt: UnsafeArc<AtomicUint>,\n+    done: SharedChan<()>,\n }\n \n impl SchedPool {\n@@ -182,6 +187,7 @@ impl SchedPool {\n         assert!(nscheds > 0);\n \n         // The pool of schedulers that will be returned from this function\n+        let (p, state) = TaskState::new();\n         let mut pool = SchedPool {\n             threads: ~[],\n             handles: ~[],\n@@ -192,6 +198,8 @@ impl SchedPool {\n             deque_pool: deque::BufferPool::new(),\n             next_friend: 0,\n             factory: factory,\n+            task_state: state,\n+            tasks_done: p,\n         };\n \n         // Create a work queue for each scheduler, ntimes. Create an extra\n@@ -210,21 +218,30 @@ impl SchedPool {\n                                             (pool.factory)(),\n                                             worker,\n                                             pool.stealers.clone(),\n-                                            pool.sleepers.clone());\n+                                            pool.sleepers.clone(),\n+                                            pool.task_state.clone());\n             pool.handles.push(sched.make_handle());\n             let sched = sched;\n-            pool.threads.push(do Thread::start {\n-                sched.bootstrap();\n-            });\n+            pool.threads.push(do Thread::start { sched.bootstrap(); });\n         }\n \n         return pool;\n     }\n \n+    /// Creates a new task configured to run inside of this pool of schedulers.\n+    /// This is useful to create a task which can then be sent to a specific\n+    /// scheduler created by `spawn_sched` (and possibly pin it to that\n+    /// scheduler).\n     pub fn task(&mut self, opts: TaskOpts, f: proc()) -> ~GreenTask {\n         GreenTask::configure(&mut self.stack_pool, opts, f)\n     }\n \n+    /// Spawns a new task into this pool of schedulers, using the specified\n+    /// options to configure the new task which is spawned.\n+    ///\n+    /// New tasks are spawned in a round-robin fashion to the schedulers in this\n+    /// pool, but tasks can certainly migrate among schedulers once they're in\n+    /// the pool.\n     pub fn spawn(&mut self, opts: TaskOpts, f: proc()) {\n         let task = self.task(opts, f);\n \n@@ -262,7 +279,8 @@ impl SchedPool {\n                                         (self.factory)(),\n                                         worker,\n                                         self.stealers.clone(),\n-                                        self.sleepers.clone());\n+                                        self.sleepers.clone(),\n+                                        self.task_state.clone());\n         let ret = sched.make_handle();\n         self.handles.push(sched.make_handle());\n         let sched = sched;\n@@ -271,9 +289,28 @@ impl SchedPool {\n         return ret;\n     }\n \n+    /// Consumes the pool of schedulers, waiting for all tasks to exit and all\n+    /// schedulers to shut down.\n+    ///\n+    /// This function is required to be called in order to drop a pool of\n+    /// schedulers, it is considered an error to drop a pool without calling\n+    /// this method.\n+    ///\n+    /// This only waits for all tasks in *this pool* of schedulers to exit, any\n+    /// native tasks or extern pools will not be waited on\n     pub fn shutdown(mut self) {\n         self.stealers = ~[];\n \n+        // Wait for everyone to exit. We may have reached a 0-task count\n+        // multiple times in the past, meaning there could be several buffered\n+        // messages on the `tasks_done` port. We're guaranteed that after *some*\n+        // message the current task count will be 0, so we just receive in a\n+        // loop until everything is totally dead.\n+        while self.task_state.active() {\n+            self.tasks_done.recv();\n+        }\n+\n+        // Now that everyone's gone, tell everything to shut down.\n         for mut handle in util::replace(&mut self.handles, ~[]).move_iter() {\n             handle.send(Shutdown);\n         }\n@@ -283,6 +320,31 @@ impl SchedPool {\n     }\n }\n \n+impl TaskState {\n+    fn new() -> (Port<()>, TaskState) {\n+        let (p, c) = SharedChan::new();\n+        (p, TaskState {\n+            cnt: UnsafeArc::new(AtomicUint::new(0)),\n+            done: c,\n+        })\n+    }\n+\n+    fn increment(&mut self) {\n+        unsafe { (*self.cnt.get()).fetch_add(1, SeqCst); }\n+    }\n+\n+    fn active(&self) -> bool {\n+        unsafe { (*self.cnt.get()).load(SeqCst) != 0 }\n+    }\n+\n+    fn decrement(&mut self) {\n+        let prev = unsafe { (*self.cnt.get()).fetch_sub(1, SeqCst) };\n+        if prev == 1 {\n+            self.done.send(());\n+        }\n+    }\n+}\n+\n impl Drop for SchedPool {\n     fn drop(&mut self) {\n         if self.threads.len() > 0 {"}, {"sha": "b0b88e4be7936033f630b5126313f4a2e7861319", "filename": "src/libgreen/sched.rs", "status": "modified", "additions": 18, "deletions": 8, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -19,6 +19,7 @@ use std::unstable::mutex::Mutex;\n use std::unstable::raw;\n use mpsc = std::sync::mpsc_queue;\n \n+use TaskState;\n use context::Context;\n use coroutine::Coroutine;\n use sleeper_list::SleeperList;\n@@ -85,6 +86,9 @@ pub struct Scheduler {\n     /// A flag to tell the scheduler loop it needs to do some stealing\n     /// in order to introduce randomness as part of a yield\n     steal_for_yield: bool,\n+    /// Bookeeping for the number of tasks which are currently running around\n+    /// inside this pool of schedulers\n+    task_state: TaskState,\n \n     // n.b. currently destructors of an object are run in top-to-bottom in order\n     //      of field declaration. Due to its nature, the pausable idle callback\n@@ -120,11 +124,12 @@ impl Scheduler {\n                event_loop: ~EventLoop,\n                work_queue: deque::Worker<~GreenTask>,\n                work_queues: ~[deque::Stealer<~GreenTask>],\n-               sleeper_list: SleeperList)\n+               sleeper_list: SleeperList,\n+               state: TaskState)\n         -> Scheduler {\n \n         Scheduler::new_special(pool_id, event_loop, work_queue, work_queues,\n-                               sleeper_list, true, None)\n+                               sleeper_list, true, None, state)\n \n     }\n \n@@ -134,7 +139,8 @@ impl Scheduler {\n                        work_queues: ~[deque::Stealer<~GreenTask>],\n                        sleeper_list: SleeperList,\n                        run_anything: bool,\n-                       friend: Option<SchedHandle>)\n+                       friend: Option<SchedHandle>,\n+                       state: TaskState)\n         -> Scheduler {\n \n         let (consumer, producer) = mpsc::queue(());\n@@ -156,7 +162,8 @@ impl Scheduler {\n             rng: new_sched_rng(),\n             idle_callback: None,\n             yield_check_count: 0,\n-            steal_for_yield: false\n+            steal_for_yield: false,\n+            task_state: state,\n         };\n \n         sched.yield_check_count = reset_yield_check(&mut sched.rng);\n@@ -756,6 +763,7 @@ impl Scheduler {\n         let _cur = self.change_task_context(cur, stask, |sched, mut dead_task| {\n             let coroutine = dead_task.coroutine.take_unwrap();\n             coroutine.recycle(&mut sched.stack_pool);\n+            sched.task_state.decrement();\n         });\n         fail!(\"should never return!\");\n     }\n@@ -955,11 +963,10 @@ mod test {\n     use std::rt::task::Task;\n     use std::rt::local::Local;\n \n+    use {TaskState, PoolConfig, SchedPool};\n     use basic;\n     use sched::{TaskFromFriend, PinnedTask};\n     use task::{GreenTask, HomeSched};\n-    use PoolConfig;\n-    use SchedPool;\n \n     fn pool() -> SchedPool {\n         SchedPool::new(PoolConfig {\n@@ -1078,14 +1085,16 @@ mod test {\n             let (normal_worker, normal_stealer) = pool.deque();\n             let (special_worker, special_stealer) = pool.deque();\n             let queues = ~[normal_stealer, special_stealer];\n+            let (_p, state) = TaskState::new();\n \n             // Our normal scheduler\n             let mut normal_sched = ~Scheduler::new(\n                 1,\n                 basic::event_loop(),\n                 normal_worker,\n                 queues.clone(),\n-                sleepers.clone());\n+                sleepers.clone(),\n+                state.clone());\n \n             let normal_handle = normal_sched.make_handle();\n             let friend_handle = normal_sched.make_handle();\n@@ -1098,7 +1107,8 @@ mod test {\n                 queues.clone(),\n                 sleepers.clone(),\n                 false,\n-                Some(friend_handle));\n+                Some(friend_handle),\n+                state);\n \n             let special_handle = special_sched.make_handle();\n "}, {"sha": "fc4e1c08ba5a1c023824e8233e9159dc2a77f2a9", "filename": "src/libgreen/task.rs", "status": "modified", "additions": 36, "deletions": 3, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibgreen%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Ftask.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -33,11 +33,32 @@ use stack::StackPool;\n /// The necessary fields needed to keep track of a green task (as opposed to a\n /// 1:1 task).\n pub struct GreenTask {\n+    /// Coroutine that this task is running on, otherwise known as the register\n+    /// context and the stack that this task owns. This field is optional to\n+    /// relinquish ownership back to a scheduler to recycle stacks at a later\n+    /// date.\n     coroutine: Option<Coroutine>,\n+\n+    /// Optional handle back into the home sched pool of this task. This field\n+    /// is lazily initialized.\n     handle: Option<SchedHandle>,\n+\n+    /// Slot for maintaining ownership of a scheduler. If a task is running,\n+    /// this value will be Some(sched) where the task is running on \"sched\".\n     sched: Option<~Scheduler>,\n+\n+    /// Temporary ownership slot of a std::rt::task::Task object. This is used\n+    /// to squirrel that libstd task away while we're performing green task\n+    /// operations.\n     task: Option<~Task>,\n+\n+    /// Dictates whether this is a sched task or a normal green task\n     task_type: TaskType,\n+\n+    /// Home pool that this task was spawned into. This field is lazily\n+    /// initialized until when the task is initially scheduled, and is used to\n+    /// make sure that tasks are always woken up in the correct pool of\n+    /// schedulers.\n     pool_id: uint,\n \n     // See the comments in the scheduler about why this is necessary\n@@ -147,10 +168,15 @@ impl GreenTask {\n             // cleanup job after we have re-acquired ownership of the green\n             // task.\n             let mut task: ~GreenTask = unsafe { GreenTask::from_uint(ops) };\n-            task.sched.get_mut_ref().run_cleanup_job();\n+            task.pool_id = {\n+                let sched = task.sched.get_mut_ref();\n+                sched.run_cleanup_job();\n+                sched.task_state.increment();\n+                sched.pool_id\n+            };\n \n             // Convert our green task to a libstd task and then execute the code\n-            // requeted. This is the \"try/catch\" block for this green task and\n+            // requested. This is the \"try/catch\" block for this green task and\n             // is the wrapper for *all* code run in the task.\n             let mut start = Some(start);\n             let task = task.swap().run(|| start.take_unwrap()());\n@@ -350,6 +376,14 @@ impl Runtime for GreenTask {\n         self.put_task(to_wake);\n         assert!(self.sched.is_none());\n \n+        // Optimistically look for a local task, but if one's not available to\n+        // inspect (in order to see if it's in the same sched pool as we are),\n+        // then just use our remote wakeup routine and carry on!\n+        let mut running_task: ~Task = match Local::try_take() {\n+            Some(task) => task,\n+            None => return self.reawaken_remotely()\n+        };\n+\n         // Waking up a green thread is a bit of a tricky situation. We have no\n         // guarantee about where the current task is running. The options we\n         // have for where this current task is running are:\n@@ -368,7 +402,6 @@ impl Runtime for GreenTask {\n         //\n         // In case 2 and 3, we need to remotely reawaken ourself in order to be\n         // transplanted back to the correct scheduler pool.\n-        let mut running_task: ~Task = Local::take();\n         match running_task.maybe_take_runtime::<GreenTask>() {\n             Some(mut running_green_task) => {\n                 running_green_task.put_task(running_task);"}, {"sha": "ca40c1a1958c95d8b8fb954044add9514c372d3f", "filename": "src/libnative/bookeeping.rs", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Fbookeeping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Fbookeeping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fbookeeping.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -0,0 +1,49 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! 1:1 Task bookeeping\n+//!\n+//! This module keeps track of the number of running 1:1 tasks so that entry\n+//! points with libnative know when it's possible to exit the program (once all\n+//! tasks have exited).\n+//!\n+//! The green counterpart for this is bookeeping on sched pools.\n+\n+use std::sync::atomics;\n+use std::unstable::mutex::{Mutex, MUTEX_INIT};\n+\n+static mut TASK_COUNT: atomics::AtomicUint = atomics::INIT_ATOMIC_UINT;\n+static mut TASK_LOCK: Mutex = MUTEX_INIT;\n+\n+pub fn increment() {\n+    unsafe { TASK_COUNT.fetch_add(1, atomics::SeqCst); }\n+}\n+\n+pub fn decrement() {\n+    unsafe {\n+        if TASK_COUNT.fetch_sub(1, atomics::SeqCst) == 1 {\n+            TASK_LOCK.lock();\n+            TASK_LOCK.signal();\n+            TASK_LOCK.unlock();\n+        }\n+    }\n+}\n+\n+/// Waits for all other native tasks in the system to exit. This is only used by\n+/// the entry points of native programs\n+pub fn wait_for_other_tasks() {\n+    unsafe {\n+        TASK_LOCK.lock();\n+        while TASK_COUNT.load(atomics::SeqCst) > 0 {\n+            TASK_LOCK.wait();\n+        }\n+        TASK_LOCK.unlock();\n+    }\n+}"}, {"sha": "498945a04cb91e2eefa8721731488cbf0cfa2edf", "filename": "src/libnative/lib.rs", "status": "modified", "additions": 2, "deletions": 8, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Flib.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -27,14 +27,12 @@\n //    answer is that you don't need them)\n \n use std::os;\n-use std::rt::local::Local;\n-use std::rt::task::Task;\n use std::rt;\n \n+mod bookeeping;\n pub mod io;\n pub mod task;\n \n-\n // XXX: this should not exist here\n #[cfg(stage0)]\n #[lang = \"start\"]\n@@ -83,11 +81,7 @@ pub fn start(argc: int, argv: **u8, main: proc()) -> int {\n /// This function has all of the same details as `start` except for a different\n /// number of arguments.\n pub fn run(main: proc()) -> int {\n-    // Run the main procedure and then wait for everything to finish\n     main();\n-    unsafe {\n-        let mut task = Local::borrow(None::<Task>);\n-        task.get().wait_for_other_tasks();\n-    }\n+    bookeeping::wait_for_other_tasks();\n     os::get_exit_status()\n }"}, {"sha": "c4d3f65177753ac09a617b7c4a4705b87039c7ba", "filename": "src/libnative/task.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibnative%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Ftask.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -27,6 +27,7 @@ use std::unstable::stack;\n \n use io;\n use task;\n+use bookeeping;\n \n /// Creates a new Task which is ready to execute as a 1:1 task.\n pub fn new() -> ~Task {\n@@ -79,8 +80,10 @@ pub fn spawn_opts(opts: TaskOpts, f: proc()) {\n             stack::record_stack_bounds(my_stack - stack + 1024, my_stack);\n         }\n \n+        bookeeping::increment();\n         let mut f = Some(f);\n         task.run(|| { f.take_unwrap()() });\n+        bookeeping::decrement();\n     })\n }\n "}, {"sha": "b4a6f06c2a4c49568c4a203c0e1d74c9d1914b9a", "filename": "src/libstd/rt/local.rs", "status": "modified", "additions": 18, "deletions": 5, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -16,6 +16,7 @@ use rt::local_ptr;\n pub trait Local<Borrowed> {\n     fn put(value: ~Self);\n     fn take() -> ~Self;\n+    fn try_take() -> Option<~Self>;\n     fn exists(unused_value: Option<Self>) -> bool;\n     fn borrow(unused_value: Option<Self>) -> Borrowed;\n     unsafe fn unsafe_take() -> ~Self;\n@@ -28,6 +29,8 @@ impl Local<local_ptr::Borrowed<Task>> for Task {\n     fn put(value: ~Task) { unsafe { local_ptr::put(value) } }\n     #[inline]\n     fn take() -> ~Task { unsafe { local_ptr::take() } }\n+    #[inline]\n+    fn try_take() -> Option<~Task> { unsafe { local_ptr::try_take() } }\n     fn exists(_: Option<Task>) -> bool { local_ptr::exists() }\n     #[inline]\n     fn borrow(_: Option<Task>) -> local_ptr::Borrowed<Task> {\n@@ -47,7 +50,7 @@ impl Local<local_ptr::Borrowed<Task>> for Task {\n \n #[cfg(test)]\n mod test {\n-    use option::None;\n+    use option::{None, Option};\n     use unstable::run_in_bare_thread;\n     use super::*;\n     use rt::task::Task;\n@@ -56,7 +59,6 @@ mod test {\n     #[test]\n     fn thread_local_task_smoke_test() {\n         do run_in_bare_thread {\n-            local_ptr::init();\n             let task = ~Task::new();\n             Local::put(task);\n             let task: ~Task = Local::take();\n@@ -67,7 +69,6 @@ mod test {\n     #[test]\n     fn thread_local_task_two_instances() {\n         do run_in_bare_thread {\n-            local_ptr::init();\n             let task = ~Task::new();\n             Local::put(task);\n             let task: ~Task = Local::take();\n@@ -83,7 +84,6 @@ mod test {\n     #[test]\n     fn borrow_smoke_test() {\n         do run_in_bare_thread {\n-            local_ptr::init();\n             let task = ~Task::new();\n             Local::put(task);\n \n@@ -98,7 +98,6 @@ mod test {\n     #[test]\n     fn borrow_with_return() {\n         do run_in_bare_thread {\n-            local_ptr::init();\n             let task = ~Task::new();\n             Local::put(task);\n \n@@ -111,6 +110,20 @@ mod test {\n         }\n     }\n \n+    #[test]\n+    fn try_take() {\n+        do run_in_bare_thread {\n+            let task = ~Task::new();\n+            Local::put(task);\n+\n+            let t: ~Task = Local::try_take().unwrap();\n+            let u: Option<~Task> = Local::try_take();\n+            assert!(u.is_none());\n+\n+            cleanup_task(t);\n+        }\n+    }\n+\n     fn cleanup_task(mut t: ~Task) {\n         t.destroyed = true;\n     }"}, {"sha": "546a6476b57d3f04921ef194e8b5bbbdbfc160d3", "filename": "src/libstd/rt/local_ptr.rs", "status": "modified", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Flocal_ptr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Flocal_ptr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal_ptr.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -117,6 +117,24 @@ pub mod compiled {\n         ptr\n     }\n \n+    /// Optionally take ownership of a pointer from thread-local storage.\n+    ///\n+    /// # Safety note\n+    ///\n+    /// Does not validate the pointer type.\n+    #[inline]\n+    pub unsafe fn try_take<T>() -> Option<~T> {\n+        let ptr = RT_TLS_PTR;\n+        if ptr.is_null() {\n+            None\n+        } else {\n+            let ptr: ~T = cast::transmute(ptr);\n+            // can't use `as`, due to type not matching with `cfg(test)`\n+            RT_TLS_PTR = cast::transmute(0);\n+            Some(ptr)\n+        }\n+    }\n+\n     /// Take ownership of a pointer from thread-local storage.\n     ///\n     /// # Safety note\n@@ -205,6 +223,28 @@ pub mod native {\n         return ptr;\n     }\n \n+    /// Optionally take ownership of a pointer from thread-local storage.\n+    ///\n+    /// # Safety note\n+    ///\n+    /// Does not validate the pointer type.\n+    #[inline]\n+    pub unsafe fn try_take<T>() -> Option<~T> {\n+        match maybe_tls_key() {\n+            Some(key) => {\n+                let void_ptr: *mut c_void = tls::get(key);\n+                if void_ptr.is_null() {\n+                    None\n+                } else {\n+                    let ptr: ~T = cast::transmute(void_ptr);\n+                    tls::set(key, ptr::mut_null());\n+                    Some(ptr)\n+                }\n+            }\n+            None => None\n+        }\n+    }\n+\n     /// Take ownership of a pointer from thread-local storage.\n     ///\n     /// # Safety note"}, {"sha": "583a1e0657cf86bd128b89299aa90a38e67c79a7", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 1, "deletions": 32, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48918fab7226593a4ad406cd83edb46e5c15dd15/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=48918fab7226593a4ad406cd83edb46e5c15dd15", "patch": "@@ -34,21 +34,13 @@ use rt::rtio::LocalIo;\n use rt::unwind::Unwinder;\n use send_str::SendStr;\n use sync::arc::UnsafeArc;\n-use sync::atomics::{AtomicUint, SeqCst, INIT_ATOMIC_UINT};\n+use sync::atomics::{AtomicUint, SeqCst};\n use task::{TaskResult, TaskOpts};\n use unstable::finally::Finally;\n-use unstable::mutex::{Mutex, MUTEX_INIT};\n \n #[cfg(stage0)]\n pub use rt::unwind::begin_unwind;\n \n-// These two statics are used as bookeeping to keep track of the rust runtime's\n-// count of threads. In 1:1 contexts, this is used to know when to return from\n-// the main function, and in M:N contexts this is used to know when to shut down\n-// the pool of schedulers.\n-static mut TASK_COUNT: AtomicUint = INIT_ATOMIC_UINT;\n-static mut TASK_LOCK: Mutex = MUTEX_INIT;\n-\n // The Task struct represents all state associated with a rust\n // task. There are at this point two primary \"subtypes\" of task,\n // however instead of using a subtype we just have a \"task_type\" field\n@@ -127,7 +119,6 @@ impl Task {\n             *cast::transmute::<&~Task, &*mut Task>(&self)\n         };\n         Local::put(self);\n-        unsafe { TASK_COUNT.fetch_add(1, SeqCst); }\n \n         // The only try/catch block in the world. Attempt to run the task's\n         // client-specified code and catch any failures.\n@@ -194,13 +185,6 @@ impl Task {\n         unsafe {\n             let me: *mut Task = Local::unsafe_borrow();\n             (*me).death.collect_failure((*me).unwinder.result());\n-\n-            // see comments on these statics for why they're used\n-            if TASK_COUNT.fetch_sub(1, SeqCst) == 1 {\n-                TASK_LOCK.lock();\n-                TASK_LOCK.signal();\n-                TASK_LOCK.unlock();\n-            }\n         }\n         let mut me: ~Task = Local::take();\n         me.destroyed = true;\n@@ -293,21 +277,6 @@ impl Task {\n     pub fn local_io<'a>(&'a mut self) -> Option<LocalIo<'a>> {\n         self.imp.get_mut_ref().local_io()\n     }\n-\n-    /// The main function of all rust executables will by default use this\n-    /// function. This function will *block* the OS thread (hence the `unsafe`)\n-    /// waiting for all known tasks to complete. Once this function has\n-    /// returned, it is guaranteed that no more user-defined code is still\n-    /// running.\n-    pub unsafe fn wait_for_other_tasks(&mut self) {\n-        TASK_COUNT.fetch_sub(1, SeqCst); // don't count ourselves\n-        TASK_LOCK.lock();\n-        while TASK_COUNT.load(SeqCst) > 0 {\n-            TASK_LOCK.wait();\n-        }\n-        TASK_LOCK.unlock();\n-        TASK_COUNT.fetch_add(1, SeqCst); // add ourselves back in\n-    }\n }\n \n impl Drop for Task {"}]}