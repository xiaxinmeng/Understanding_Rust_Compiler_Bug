{"sha": "c5cf08d37b85f953b132951e868df5b924250fdc", "node_id": "C_kwDOAAsO6NoAKGM1Y2YwOGQzN2I4NWY5NTNiMTMyOTUxZTg2OGRmNWI5MjQyNTBmZGM", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-30T19:08:01Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-03-30T19:08:01Z"}, "message": "Auto merge of #95425 - nnethercote:yet-more-parse_tt-improvements, r=petrochenkov\n\nYet more `parse_tt` improvements\n\nIncluding lots of comment improvements, and an overhaul of how `matches` work that gives big speedups.\n\nr? `@petrochenkov`", "tree": {"sha": "94b102545a18992e43c1199fbe5dcf7df4854ede", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/94b102545a18992e43c1199fbe5dcf7df4854ede"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c5cf08d37b85f953b132951e868df5b924250fdc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c5cf08d37b85f953b132951e868df5b924250fdc", "html_url": "https://github.com/rust-lang/rust/commit/c5cf08d37b85f953b132951e868df5b924250fdc", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c5cf08d37b85f953b132951e868df5b924250fdc/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bb5c437a2ce9ccf2204c974300c5ea9eb32d3635", "url": "https://api.github.com/repos/rust-lang/rust/commits/bb5c437a2ce9ccf2204c974300c5ea9eb32d3635", "html_url": "https://github.com/rust-lang/rust/commit/bb5c437a2ce9ccf2204c974300c5ea9eb32d3635"}, {"sha": "6b0a16ab1ad689679d5b2376f842ef0606bd81c7", "url": "https://api.github.com/repos/rust-lang/rust/commits/6b0a16ab1ad689679d5b2376f842ef0606bd81c7", "html_url": "https://github.com/rust-lang/rust/commit/6b0a16ab1ad689679d5b2376f842ef0606bd81c7"}], "stats": {"total": 485, "additions": 252, "deletions": 233}, "files": [{"sha": "18302ffdb8e1054cb0b109c9dd4b01bd5db41940", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 248, "deletions": 230, "changes": 478, "blob_url": "https://github.com/rust-lang/rust/blob/c5cf08d37b85f953b132951e868df5b924250fdc/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c5cf08d37b85f953b132951e868df5b924250fdc/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=c5cf08d37b85f953b132951e868df5b924250fdc", "patch": "@@ -6,27 +6,27 @@\n //!\n //! (In order to prevent the pathological case, we'd need to lazily construct the resulting\n //! `NamedMatch`es at the very end. It'd be a pain, and require more memory to keep around old\n-//! items, but it would also save overhead)\n+//! matcher positions, but it would also save overhead)\n //!\n //! We don't say this parser uses the Earley algorithm, because it's unnecessarily inaccurate.\n //! The macro parser restricts itself to the features of finite state automata. Earley parsers\n //! can be described as an extension of NFAs with completion rules, prediction rules, and recursion.\n //!\n //! Quick intro to how the parser works:\n //!\n-//! A 'position' is a dot in the middle of a matcher, usually represented as a\n-//! dot. For example `\u00b7 a $( a )* a b` is a position, as is `a $( \u00b7 a )* a b`.\n+//! A \"matcher position\" (a.k.a. \"position\" or \"mp\") is a dot in the middle of a matcher, usually\n+//! written as a `\u00b7`. For example `\u00b7 a $( a )* a b` is one, as is `a $( \u00b7 a )* a b`.\n //!\n //! The parser walks through the input a character at a time, maintaining a list\n-//! of threads consistent with the current position in the input string: `cur_items`.\n+//! of threads consistent with the current position in the input string: `cur_mps`.\n //!\n-//! As it processes them, it fills up `eof_items` with threads that would be valid if\n-//! the macro invocation is now over, `bb_items` with threads that are waiting on\n-//! a Rust non-terminal like `$e:expr`, and `next_items` with threads that are waiting\n+//! As it processes them, it fills up `eof_mps` with threads that would be valid if\n+//! the macro invocation is now over, `bb_mps` with threads that are waiting on\n+//! a Rust non-terminal like `$e:expr`, and `next_mps` with threads that are waiting\n //! on a particular token. Most of the logic concerns moving the \u00b7 through the\n //! repetitions indicated by Kleene stars. The rules for moving the \u00b7 without\n //! consuming any input are called epsilon transitions. It only advances or calls\n-//! out to the real Rust parser when no `cur_items` threads remain.\n+//! out to the real Rust parser when no `cur_mps` threads remain.\n //!\n //! Example:\n //!\n@@ -40,28 +40,28 @@\n //!\n //! Remaining input: a a a b\n //! cur: [a \u00b7 $( a )* a b]\n-//! Descend/Skip (first item).\n+//! Descend/Skip (first position).\n //! next: [a $( \u00b7 a )* a b]  [a $( a )* \u00b7 a b].\n //!\n //! - - - Advance over an a. - - -\n //!\n //! Remaining input: a a b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n //! Remaining input: a b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n //! Remaining input: b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over a b. - - -\n@@ -89,15 +89,13 @@ use std::borrow::Cow;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n use std::mem;\n \n-/// An unzipping of `TokenTree`s... see the `stack` field of `MatcherPos`.\n-///\n /// This is used by `parse_tt_inner` to keep track of delimited submatchers that we have\n /// descended into.\n #[derive(Clone)]\n-struct MatcherTtFrame<'tt> {\n-    /// The \"parent\" matcher that we are descending into.\n-    elts: &'tt [TokenTree],\n-    /// The position of the \"dot\" in `elts` at the time we descended.\n+struct MatcherPosFrame<'tt> {\n+    /// The \"parent\" matcher that we have descended from.\n+    tts: &'tt [TokenTree],\n+    /// The position of the \"dot\" in `tt` at the time we descended.\n     idx: usize,\n }\n \n@@ -110,128 +108,135 @@ type NamedMatchVec = SmallVec<[NamedMatch; 1]>;\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n rustc_data_structures::static_assert_size!(NamedMatchVec, 48);\n \n-/// Represents a single \"position\" (aka \"matcher position\", aka \"item\"), as\n-/// described in the module documentation.\n+/// A single matcher position, which could be within the top-level matcher, a submatcher, a\n+/// subsubmatcher, etc. For example:\n+/// ```text\n+/// macro_rules! m { $id:ident ( $($e:expr),* ) } => { ... }\n+///                              <---------->     second submatcher; one tt, one metavar\n+///                            <-------------->   first submatcher; three tts, zero metavars\n+///                  <--------------------------> top-level matcher; two tts, one metavar\n+/// ```\n #[derive(Clone)]\n struct MatcherPos<'tt> {\n-    /// The token or slice of tokens that make up the matcher. `elts` is short for \"elements\".\n-    top_elts: &'tt [TokenTree],\n+    /// The tokens that make up the current matcher. When we are within a `Sequence` or `Delimited`\n+    /// submatcher, this is just the contents of that submatcher.\n+    tts: &'tt [TokenTree],\n \n-    /// The position of the \"dot\" in this matcher\n+    /// The \"dot\" position within the current submatcher, i.e. the index into `tts`.\n     idx: usize,\n \n-    /// For each named metavar in the matcher, we keep track of token trees matched against the\n-    /// metavar by the black box parser. In particular, there may be more than one match per\n-    /// metavar if we are in a repetition (each repetition matches each of the variables).\n-    /// Moreover, matchers and repetitions can be nested; the `matches` field is shared (hence the\n-    /// `Rc`) among all \"nested\" matchers. `match_lo`, `match_cur`, and `match_hi` keep track of\n-    /// the current position of the `self` matcher position in the shared `matches` list.\n-    ///\n-    /// Also, note that while we are descending into a sequence, matchers are given their own\n-    /// `matches` vector. Only once we reach the end of a full repetition of the sequence do we add\n-    /// all bound matches from the submatcher into the shared top-level `matches` vector. If `sep`\n-    /// and `up` are `Some`, then `matches` is _not_ the shared top-level list. Instead, if one\n-    /// wants the shared `matches`, one should use `up.matches`.\n-    matches: Box<[Lrc<NamedMatchVec>]>,\n-    /// The position in `matches` corresponding to the first metavar in this matcher's sequence of\n-    /// token trees. In other words, the first metavar in the first token of `top_elts` corresponds\n-    /// to `matches[match_lo]`.\n+    /// This vector ends up with one element per metavar in the *top-level* matcher, even when this\n+    /// `MatcherPos` is for a submatcher. Each element records token trees matched against the\n+    /// relevant metavar by the black box parser. The element will be a `MatchedSeq` if the\n+    /// corresponding metavar is within a sequence.\n+    matches: Lrc<NamedMatchVec>,\n+\n+    /// The number of sequences this mp is within.\n+    seq_depth: usize,\n+\n+    /// The position in `matches` of the first metavar in this (sub)matcher. Zero if there are\n+    /// no metavars.\n     match_lo: usize,\n-    /// The position in `matches` corresponding to the metavar we are currently trying to match\n-    /// against the source token stream. `match_lo <= match_cur <= match_hi`.\n+\n+    /// The position in `matches` of the next metavar to be matched against the source token\n+    /// stream. Should not be used if there are no metavars.\n     match_cur: usize,\n-    /// Similar to `match_lo` except `match_hi` is the position in `matches` of the _last_ metavar\n-    /// in this matcher.\n-    match_hi: usize,\n \n-    /// This field is only used if we are matching a repetition.\n-    repetition: Option<MatcherPosRepetition<'tt>>,\n+    /// This field is only used if we are matching a sequence.\n+    sequence: Option<MatcherPosSequence<'tt>>,\n \n-    /// Specifically used to \"unzip\" token trees. By \"unzip\", we mean to unwrap the delimiters from\n-    /// a delimited token tree (e.g., something wrapped in `(` `)`) or to get the contents of a doc\n-    /// comment...\n-    ///\n-    /// When matching against matchers with nested delimited submatchers (e.g., `pat ( pat ( .. )\n-    /// pat ) pat`), we need to keep track of the matchers we are descending into. This stack does\n-    /// that where the bottom of the stack is the outermost matcher.\n-    /// Also, throughout the comments, this \"descent\" is often referred to as \"unzipping\"...\n-    stack: SmallVec<[MatcherTtFrame<'tt>; 1]>,\n+    /// When we are within a `Delimited` submatcher (or subsubmatcher), this tracks the parent\n+    /// matcher(s). The bottom of the stack is the top-level matcher.\n+    stack: SmallVec<[MatcherPosFrame<'tt>; 1]>,\n }\n \n // This type is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(MatcherPos<'_>, 112);\n+rustc_data_structures::static_assert_size!(MatcherPos<'_>, 104);\n \n impl<'tt> MatcherPos<'tt> {\n-    /// `len` `Vec`s (initially shared and empty) that will store matches of metavars.\n-    fn create_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n-        if len == 0 {\n-            vec![]\n-        } else {\n-            let empty_matches = Lrc::new(SmallVec::new());\n-            vec![empty_matches; len]\n-        }\n-        .into_boxed_slice()\n-    }\n-\n-    /// Generates the top-level matcher position in which the \"dot\" is before the first token of\n-    /// the matcher `ms`.\n-    fn new(ms: &'tt [TokenTree]) -> Self {\n-        let match_idx_hi = count_names(ms);\n+    fn top_level(matcher: &'tt [TokenTree], empty_matches: Lrc<NamedMatchVec>) -> Self {\n         MatcherPos {\n-            // Start with the top level matcher given to us.\n-            top_elts: ms,\n-\n-            // The \"dot\" is before the first token of the matcher.\n+            tts: matcher,\n             idx: 0,\n-\n-            // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in\n-            // `top_elts`. `match_lo` for `top_elts` is 0 and `match_hi` is `match_idx_hi`.\n-            // `match_cur` is 0 since we haven't actually matched anything yet.\n-            matches: Self::create_matches(match_idx_hi),\n+            matches: empty_matches,\n+            seq_depth: 0,\n             match_lo: 0,\n             match_cur: 0,\n-            match_hi: match_idx_hi,\n-\n-            // Haven't descended into any delimiters, so this is empty.\n             stack: smallvec![],\n-\n-            // Haven't descended into any sequences, so this is `None`.\n-            repetition: None,\n+            sequence: None,\n         }\n     }\n \n-    fn repetition(up: Box<MatcherPos<'tt>>, seq: &'tt SequenceRepetition) -> Self {\n-        MatcherPos {\n-            top_elts: &seq.tts,\n+    fn sequence(\n+        parent: Box<MatcherPos<'tt>>,\n+        seq: &'tt SequenceRepetition,\n+        empty_matches: Lrc<NamedMatchVec>,\n+    ) -> Self {\n+        let mut mp = MatcherPos {\n+            tts: &seq.tts,\n             idx: 0,\n-            matches: Self::create_matches(up.matches.len()),\n-            match_lo: up.match_cur,\n-            match_cur: up.match_cur,\n-            match_hi: up.match_cur + seq.num_captures,\n-            repetition: Some(MatcherPosRepetition { up, seq }),\n+            matches: parent.matches.clone(),\n+            seq_depth: parent.seq_depth,\n+            match_lo: parent.match_cur,\n+            match_cur: parent.match_cur,\n+            sequence: Some(MatcherPosSequence { parent, seq }),\n             stack: smallvec![],\n+        };\n+        // Start with an empty vec for each metavar within the sequence. Note that `mp.seq_depth`\n+        // must have the parent's depth at this point for these `push_match` calls to work.\n+        for idx in mp.match_lo..mp.match_lo + seq.num_captures {\n+            mp.push_match(idx, MatchedSeq(empty_matches.clone()));\n         }\n+        mp.seq_depth += 1;\n+        mp\n     }\n \n     /// Adds `m` as a named match for the `idx`-th metavar.\n     fn push_match(&mut self, idx: usize, m: NamedMatch) {\n-        let matches = Lrc::make_mut(&mut self.matches[idx]);\n-        matches.push(m);\n+        let matches = Lrc::make_mut(&mut self.matches);\n+        match self.seq_depth {\n+            0 => {\n+                // We are not within a sequence. Just append `m`.\n+                assert_eq!(idx, matches.len());\n+                matches.push(m);\n+            }\n+            _ => {\n+                // We are within a sequence. Find the final `MatchedSeq` at the appropriate depth\n+                // and append `m` to its vector.\n+                let mut curr = &mut matches[idx];\n+                for _ in 0..self.seq_depth - 1 {\n+                    match curr {\n+                        MatchedSeq(seq) => {\n+                            let seq = Lrc::make_mut(seq);\n+                            curr = seq.last_mut().unwrap();\n+                        }\n+                        _ => unreachable!(),\n+                    }\n+                }\n+                match curr {\n+                    MatchedSeq(seq) => {\n+                        let seq = Lrc::make_mut(seq);\n+                        seq.push(m);\n+                    }\n+                    _ => unreachable!(),\n+                }\n+            }\n+        }\n     }\n }\n \n #[derive(Clone)]\n-struct MatcherPosRepetition<'tt> {\n-    /// The \"parent\" matcher position. That is, the matcher position just before we enter the\n-    /// sequence.\n-    up: Box<MatcherPos<'tt>>,\n+struct MatcherPosSequence<'tt> {\n+    /// The parent matcher position. Effectively gives a linked list of matches all the way to the\n+    /// top-level matcher.\n+    parent: Box<MatcherPos<'tt>>,\n \n     /// The sequence itself.\n     seq: &'tt SequenceRepetition,\n }\n \n-enum EofItems<'tt> {\n+enum EofMatcherPositions<'tt> {\n     None,\n     One(Box<MatcherPos<'tt>>),\n     Multiple,\n@@ -254,24 +259,24 @@ crate enum ParseResult<T> {\n /// of metavars to the token trees they bind to.\n crate type NamedParseResult = ParseResult<FxHashMap<MacroRulesNormalizedIdent, NamedMatch>>;\n \n-/// Count how many metavars are named in the given matcher `ms`.\n-pub(super) fn count_names(ms: &[TokenTree]) -> usize {\n-    ms.iter().fold(0, |count, elt| {\n-        count\n-            + match elt {\n-                TokenTree::Delimited(_, delim) => count_names(delim.inner_tts()),\n+/// Count how many metavars declarations are in `matcher`.\n+pub(super) fn count_metavar_decls(matcher: &[TokenTree]) -> usize {\n+    matcher\n+        .iter()\n+        .map(|tt| {\n+            match tt {\n+                TokenTree::Delimited(_, delim) => count_metavar_decls(delim.inner_tts()),\n                 TokenTree::MetaVar(..) => 0,\n                 TokenTree::MetaVarDecl(..) => 1,\n-                // Panicking here would abort execution because `parse_tree` makes use of this\n-                // function. In other words, RHS meta-variable expressions eventually end-up here.\n-                //\n-                // `0` is still returned to inform that no meta-variable was found. `Meta-variables\n-                // != Meta-variable expressions`\n+                // RHS meta-variable expressions eventually end-up here. `0` is returned to inform\n+                // that no meta-variable was found, because \"meta-variables\" != \"meta-variable\n+                // expressions\".\n                 TokenTree::MetaVarExpr(..) => 0,\n                 TokenTree::Sequence(_, seq) => seq.num_captures,\n                 TokenTree::Token(..) => 0,\n             }\n-    })\n+        })\n+        .sum()\n }\n \n /// `NamedMatch` is a pattern-match result for a single metavar. All\n@@ -331,11 +336,9 @@ crate enum NamedMatch {\n     MatchedNonterminal(Lrc<Nonterminal>),\n }\n \n-/// Takes a slice of token trees `ms` representing a matcher which successfully matched input\n-/// and an iterator of items that matched input and produces a `NamedParseResult`.\n fn nameize<I: Iterator<Item = NamedMatch>>(\n     sess: &ParseSess,\n-    ms: &[TokenTree],\n+    matcher: &[TokenTree],\n     mut res: I,\n ) -> NamedParseResult {\n     // Recursively descend into each type of matcher (e.g., sequences, delimited, metavars) and make\n@@ -344,11 +347,11 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n     // `NamedParseResult`.\n     fn n_rec<I: Iterator<Item = NamedMatch>>(\n         sess: &ParseSess,\n-        m: &TokenTree,\n+        tt: &TokenTree,\n         res: &mut I,\n         ret_val: &mut FxHashMap<MacroRulesNormalizedIdent, NamedMatch>,\n     ) -> Result<(), (rustc_span::Span, String)> {\n-        match *m {\n+        match *tt {\n             TokenTree::Sequence(_, ref seq) => {\n                 for next_m in &seq.tts {\n                     n_rec(sess, next_m, res.by_ref(), ret_val)?\n@@ -380,8 +383,8 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n     }\n \n     let mut ret_val = FxHashMap::default();\n-    for m in ms {\n-        match n_rec(sess, m, res.by_ref(), &mut ret_val) {\n+    for tt in matcher {\n+        match n_rec(sess, tt, res.by_ref(), &mut ret_val) {\n             Ok(_) => {}\n             Err((sp, msg)) => return Error(sp, msg),\n         }\n@@ -401,86 +404,96 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     }\n }\n \n-// Note: the item vectors could be created and dropped within `parse_tt`, but to avoid excess\n+// Note: the position vectors could be created and dropped within `parse_tt`, but to avoid excess\n // allocations we have a single vector fo each kind that is cleared and reused repeatedly.\n pub struct TtParser<'tt> {\n     macro_name: Ident,\n \n-    /// The set of current items to be processed. This should be empty by the end of a successful\n+    /// The set of current mps to be processed. This should be empty by the end of a successful\n     /// execution of `parse_tt_inner`.\n-    cur_items: Vec<Box<MatcherPos<'tt>>>,\n+    cur_mps: Vec<Box<MatcherPos<'tt>>>,\n \n-    /// The set of newly generated items. These are used to replenish `cur_items` in the function\n+    /// The set of newly generated mps. These are used to replenish `cur_mps` in the function\n     /// `parse_tt`.\n-    next_items: Vec<Box<MatcherPos<'tt>>>,\n+    next_mps: Vec<Box<MatcherPos<'tt>>>,\n \n-    /// The set of items that are waiting for the black-box parser.\n-    bb_items: Vec<Box<MatcherPos<'tt>>>,\n+    /// The set of mps that are waiting for the black-box parser.\n+    bb_mps: Vec<Box<MatcherPos<'tt>>>,\n+\n+    /// Pre-allocate an empty match array, so it can be cloned cheaply for macros with many rules\n+    /// that have no metavars.\n+    empty_matches: Lrc<NamedMatchVec>,\n }\n \n impl<'tt> TtParser<'tt> {\n     pub(super) fn new(macro_name: Ident) -> TtParser<'tt> {\n-        TtParser { macro_name, cur_items: vec![], next_items: vec![], bb_items: vec![] }\n+        TtParser {\n+            macro_name,\n+            cur_mps: vec![],\n+            next_mps: vec![],\n+            bb_mps: vec![],\n+            empty_matches: Lrc::new(smallvec![]),\n+        }\n     }\n \n-    /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n-    /// produce more items in `next_items` and `bb_items`.\n-    ///\n-    /// For more info about the how this happens, see the module-level doc comments and the inline\n-    /// comments of this function.\n+    /// Process the matcher positions of `cur_mps` until it is empty. In the process, this will\n+    /// produce more mps in `next_mps` and `bb_mps`.\n     ///\n     /// # Returns\n     ///\n     /// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept\n-    /// track of through the items generated.\n+    /// track of through the mps generated.\n     fn parse_tt_inner(\n         &mut self,\n         sess: &ParseSess,\n-        ms: &[TokenTree],\n+        matcher: &[TokenTree],\n         token: &Token,\n     ) -> Option<NamedParseResult> {\n         // Matcher positions that would be valid if the macro invocation was over now. Only\n         // modified if `token == Eof`.\n-        let mut eof_items = EofItems::None;\n-\n-        while let Some(mut item) = self.cur_items.pop() {\n-            // When unzipped trees end, remove them. This corresponds to backtracking out of a\n-            // delimited submatcher into which we already descended. When backtracking out again, we\n-            // need to advance the \"dot\" past the delimiters in the outer matcher.\n-            while item.idx >= item.top_elts.len() {\n-                match item.stack.pop() {\n-                    Some(MatcherTtFrame { elts, idx }) => {\n-                        item.top_elts = elts;\n-                        item.idx = idx + 1;\n+        let mut eof_mps = EofMatcherPositions::None;\n+\n+        while let Some(mut mp) = self.cur_mps.pop() {\n+            // Backtrack out of delimited submatcher when necessary. When backtracking out again,\n+            // we need to advance the \"dot\" past the delimiters in the parent matcher(s).\n+            while mp.idx >= mp.tts.len() {\n+                match mp.stack.pop() {\n+                    Some(MatcherPosFrame { tts, idx }) => {\n+                        mp.tts = tts;\n+                        mp.idx = idx + 1;\n                     }\n                     None => break,\n                 }\n             }\n \n-            // Get the current position of the \"dot\" (`idx`) in `item` and the number of token\n+            // Get the current position of the \"dot\" (`idx`) in `mp` and the number of token\n             // trees in the matcher (`len`).\n-            let idx = item.idx;\n-            let len = item.top_elts.len();\n+            let idx = mp.idx;\n+            let len = mp.tts.len();\n \n             if idx < len {\n                 // We are in the middle of a matcher. Compare the matcher's current tt against\n                 // `token`.\n-                match &item.top_elts[idx] {\n+                match &mp.tts[idx] {\n                     TokenTree::Sequence(_sp, seq) => {\n                         let op = seq.kleene.op;\n                         if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n                             // Allow for the possibility of zero matches of this sequence.\n-                            let mut new_item = item.clone();\n-                            new_item.match_cur += seq.num_captures;\n-                            new_item.idx += 1;\n-                            for idx in item.match_cur..item.match_cur + seq.num_captures {\n-                                new_item.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n+                            let mut new_mp = mp.clone();\n+                            new_mp.match_cur += seq.num_captures;\n+                            new_mp.idx += 1;\n+                            for idx in mp.match_cur..mp.match_cur + seq.num_captures {\n+                                new_mp.push_match(idx, MatchedSeq(self.empty_matches.clone()));\n                             }\n-                            self.cur_items.push(new_item);\n+                            self.cur_mps.push(new_mp);\n                         }\n \n                         // Allow for the possibility of one or more matches of this sequence.\n-                        self.cur_items.push(box MatcherPos::repetition(item, &seq));\n+                        self.cur_mps.push(box MatcherPos::sequence(\n+                            mp,\n+                            &seq,\n+                            self.empty_matches.clone(),\n+                        ));\n                     }\n \n                     &TokenTree::MetaVarDecl(span, _, None) => {\n@@ -497,87 +510,91 @@ impl<'tt> TtParser<'tt> {\n                         // We use the span of the metavariable declaration to determine any\n                         // edition-specific matching behavior for non-terminals.\n                         if Parser::nonterminal_may_begin_with(kind, token) {\n-                            self.bb_items.push(item);\n+                            self.bb_mps.push(mp);\n                         }\n                     }\n \n                     TokenTree::Delimited(_, delimited) => {\n                         // To descend into a delimited submatcher, we push the current matcher onto\n-                        // a stack and push a new item containing the submatcher onto `cur_items`.\n+                        // a stack and push a new mp containing the submatcher onto `cur_mps`.\n                         //\n                         // At the beginning of the loop, if we reach the end of the delimited\n                         // submatcher, we pop the stack to backtrack out of the descent. Note that\n                         // we use `all_tts` to include the open and close delimiter tokens.\n-                        let lower_elts = mem::replace(&mut item.top_elts, &delimited.all_tts);\n-                        let idx = item.idx;\n-                        item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n-                        item.idx = 0;\n-                        self.cur_items.push(item);\n+                        let tts = mem::replace(&mut mp.tts, &delimited.all_tts);\n+                        let idx = mp.idx;\n+                        mp.stack.push(MatcherPosFrame { tts, idx });\n+                        mp.idx = 0;\n+                        self.cur_mps.push(mp);\n                     }\n \n                     TokenTree::Token(t) => {\n                         // If it's a doc comment, we just ignore it and move on to the next tt in\n-                        // the matcher. If the token matches, we can just advance the parser.\n+                        // the matcher. This is a bug, but #95267 showed that existing programs\n+                        // rely on this behaviour, and changing it would require some care and a\n+                        // transition period.\n+                        //\n+                        // If the token matches, we can just advance the parser.\n+                        //\n                         // Otherwise, this match has failed, there is nothing to do, and hopefully\n-                        // another item in `cur_items` will match.\n+                        // another mp in `cur_mps` will match.\n                         if matches!(t, Token { kind: DocComment(..), .. }) {\n-                            item.idx += 1;\n-                            self.cur_items.push(item);\n+                            mp.idx += 1;\n+                            self.cur_mps.push(mp);\n                         } else if token_name_eq(&t, token) {\n-                            item.idx += 1;\n-                            self.next_items.push(item);\n+                            mp.idx += 1;\n+                            self.next_mps.push(mp);\n                         }\n                     }\n \n                     // These cannot appear in a matcher.\n                     TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n                 }\n-            } else if let Some(repetition) = &item.repetition {\n-                // We are past the end of a repetition.\n+            } else if let Some(sequence) = &mp.sequence {\n+                // We are past the end of a sequence.\n                 debug_assert!(idx <= len + 1);\n \n                 if idx == len {\n-                    // Add all matches from the sequence to `up`, and move the \"dot\" past the\n-                    // repetition in `up`. This allows for the case where the sequence matching is\n-                    // finished.\n-                    let mut new_pos = repetition.up.clone();\n-                    for idx in item.match_lo..item.match_hi {\n-                        let sub = item.matches[idx].clone();\n-                        new_pos.push_match(idx, MatchedSeq(sub));\n-                    }\n-                    new_pos.match_cur = item.match_hi;\n-                    new_pos.idx += 1;\n-                    self.cur_items.push(new_pos);\n+                    // Add all matches from the sequence to `parent`, and move the \"dot\" past the\n+                    // sequence in `parent`. This allows for the case where the sequence matching\n+                    // is finished.\n+                    let mut new_mp = sequence.parent.clone();\n+                    new_mp.matches = mp.matches.clone();\n+                    new_mp.match_cur = mp.match_lo + sequence.seq.num_captures;\n+                    new_mp.idx += 1;\n+                    self.cur_mps.push(new_mp);\n                 }\n \n-                if idx == len && repetition.seq.separator.is_some() {\n-                    if repetition\n+                if idx == len && sequence.seq.separator.is_some() {\n+                    if sequence\n                         .seq\n                         .separator\n                         .as_ref()\n                         .map_or(false, |sep| token_name_eq(token, sep))\n                     {\n                         // The matcher has a separator, and it matches the current token. We can\n                         // advance past the separator token.\n-                        item.idx += 1;\n-                        self.next_items.push(item);\n+                        mp.idx += 1;\n+                        self.next_mps.push(mp);\n                     }\n-                } else if repetition.seq.kleene.op != mbe::KleeneOp::ZeroOrOne {\n+                } else if sequence.seq.kleene.op != mbe::KleeneOp::ZeroOrOne {\n                     // We don't need a separator. Move the \"dot\" back to the beginning of the\n                     // matcher and try to match again UNLESS we are only allowed to have _one_\n                     // repetition.\n-                    item.match_cur = item.match_lo;\n-                    item.idx = 0;\n-                    self.cur_items.push(item);\n+                    mp.match_cur = mp.match_lo;\n+                    mp.idx = 0;\n+                    self.cur_mps.push(mp);\n                 }\n             } else {\n-                // We are past the end of the matcher, and not in a repetition. Look for end of\n+                // We are past the end of the matcher, and not in a sequence. Look for end of\n                 // input.\n                 debug_assert_eq!(idx, len);\n                 if *token == token::Eof {\n-                    eof_items = match eof_items {\n-                        EofItems::None => EofItems::One(item),\n-                        EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                    eof_mps = match eof_mps {\n+                        EofMatcherPositions::None => EofMatcherPositions::One(mp),\n+                        EofMatcherPositions::One(_) | EofMatcherPositions::Multiple => {\n+                            EofMatcherPositions::Multiple\n+                        }\n                     }\n                 }\n             }\n@@ -586,16 +603,18 @@ impl<'tt> TtParser<'tt> {\n         // If we reached the end of input, check that there is EXACTLY ONE possible matcher.\n         // Otherwise, either the parse is ambiguous (which is an error) or there is a syntax error.\n         if *token == token::Eof {\n-            Some(match eof_items {\n-                EofItems::One(mut eof_item) => {\n-                    let matches =\n-                        eof_item.matches.iter_mut().map(|dv| Lrc::make_mut(dv).pop().unwrap());\n-                    nameize(sess, ms, matches)\n+            Some(match eof_mps {\n+                EofMatcherPositions::One(mut eof_mp) => {\n+                    assert_eq!(eof_mp.matches.len(), count_metavar_decls(matcher));\n+                    // Need to take ownership of the matches from within the `Lrc`.\n+                    Lrc::make_mut(&mut eof_mp.matches);\n+                    let matches = Lrc::try_unwrap(eof_mp.matches).unwrap().into_iter();\n+                    nameize(sess, matcher, matches)\n                 }\n-                EofItems::Multiple => {\n+                EofMatcherPositions::Multiple => {\n                     Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n                 }\n-                EofItems::None => Failure(\n+                EofMatcherPositions::None => Failure(\n                     Token::new(\n                         token::Eof,\n                         if token.span.is_dummy() { token.span } else { token.span.shrink_to_hi() },\n@@ -608,36 +627,35 @@ impl<'tt> TtParser<'tt> {\n         }\n     }\n \n-    /// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the\n-    /// given `parser` against it and return the match.\n+    /// Match the token stream from `parser` against `matcher`.\n     pub(super) fn parse_tt(\n         &mut self,\n         parser: &mut Cow<'_, Parser<'_>>,\n-        ms: &'tt [TokenTree],\n+        matcher: &'tt [TokenTree],\n     ) -> NamedParseResult {\n         // A queue of possible matcher positions. We initialize it with the matcher position in\n-        // which the \"dot\" is before the first token of the first token tree in `ms`.\n+        // which the \"dot\" is before the first token of the first token tree in `matcher`.\n         // `parse_tt_inner` then processes all of these possible matcher positions and produces\n-        // possible next positions into `next_items`. After some post-processing, the contents of\n-        // `next_items` replenish `cur_items` and we start over again.\n-        self.cur_items.clear();\n-        self.cur_items.push(box MatcherPos::new(ms));\n+        // possible next positions into `next_mps`. After some post-processing, the contents of\n+        // `next_mps` replenish `cur_mps` and we start over again.\n+        self.cur_mps.clear();\n+        self.cur_mps.push(box MatcherPos::top_level(matcher, self.empty_matches.clone()));\n \n         loop {\n-            self.next_items.clear();\n-            self.bb_items.clear();\n+            self.next_mps.clear();\n+            self.bb_mps.clear();\n \n-            // Process `cur_items` until either we have finished the input or we need to get some\n+            // Process `cur_mps` until either we have finished the input or we need to get some\n             // parsing from the black-box parser done.\n-            if let Some(result) = self.parse_tt_inner(parser.sess, ms, &parser.token) {\n+            if let Some(result) = self.parse_tt_inner(parser.sess, matcher, &parser.token) {\n                 return result;\n             }\n \n-            // `parse_tt_inner` handled all cur_items, so it's empty.\n-            assert!(self.cur_items.is_empty());\n+            // `parse_tt_inner` handled all of `cur_mps`, so it's empty.\n+            assert!(self.cur_mps.is_empty());\n \n             // Error messages here could be improved with links to original rules.\n-            match (self.next_items.len(), self.bb_items.len()) {\n+            match (self.next_mps.len(), self.bb_mps.len()) {\n                 (0, 0) => {\n                     // There are no possible next positions AND we aren't waiting for the black-box\n                     // parser: syntax error.\n@@ -648,17 +666,17 @@ impl<'tt> TtParser<'tt> {\n                 }\n \n                 (_, 0) => {\n-                    // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n+                    // Dump all possible `next_mps` into `cur_mps` for the next iteration. Then\n                     // process the next token.\n-                    self.cur_items.extend(self.next_items.drain(..));\n+                    self.cur_mps.extend(self.next_mps.drain(..));\n                     parser.to_mut().bump();\n                 }\n \n                 (0, 1) => {\n                     // We need to call the black-box parser to get some nonterminal.\n-                    let mut item = self.bb_items.pop().unwrap();\n-                    if let TokenTree::MetaVarDecl(span, _, Some(kind)) = item.top_elts[item.idx] {\n-                        let match_cur = item.match_cur;\n+                    let mut mp = self.bb_mps.pop().unwrap();\n+                    if let TokenTree::MetaVarDecl(span, _, Some(kind)) = mp.tts[mp.idx] {\n+                        let match_cur = mp.match_cur;\n                         // We use the span of the metavariable declaration to determine any\n                         // edition-specific matching behavior for non-terminals.\n                         let nt = match parser.to_mut().parse_nonterminal(kind) {\n@@ -678,13 +696,13 @@ impl<'tt> TtParser<'tt> {\n                             NtOrTt::Nt(nt) => MatchedNonterminal(Lrc::new(nt)),\n                             NtOrTt::Tt(tt) => MatchedTokenTree(tt),\n                         };\n-                        item.push_match(match_cur, m);\n-                        item.idx += 1;\n-                        item.match_cur += 1;\n+                        mp.push_match(match_cur, m);\n+                        mp.idx += 1;\n+                        mp.match_cur += 1;\n                     } else {\n                         unreachable!()\n                     }\n-                    self.cur_items.push(item);\n+                    self.cur_mps.push(mp);\n                 }\n \n                 (_, _) => {\n@@ -693,15 +711,15 @@ impl<'tt> TtParser<'tt> {\n                 }\n             }\n \n-            assert!(!self.cur_items.is_empty());\n+            assert!(!self.cur_mps.is_empty());\n         }\n     }\n \n     fn ambiguity_error(&self, token_span: rustc_span::Span) -> NamedParseResult {\n         let nts = self\n-            .bb_items\n+            .bb_mps\n             .iter()\n-            .map(|item| match item.top_elts[item.idx] {\n+            .map(|mp| match mp.tts[mp.idx] {\n                 TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n                     format!(\"{} ('{}')\", kind, bind)\n                 }\n@@ -715,7 +733,7 @@ impl<'tt> TtParser<'tt> {\n             format!(\n                 \"local ambiguity when calling macro `{}`: multiple parsing options: {}\",\n                 self.macro_name,\n-                match self.next_items.len() {\n+                match self.next_mps.len() {\n                     0 => format!(\"built-in NTs {}.\", nts),\n                     1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n                     n => format!(\"built-in NTs {} or {} other options.\", nts, n),"}, {"sha": "d91871c7e57db143be6791bd2e8e86a81c5f2a85", "filename": "compiler/rustc_expand/src/mbe/quoted.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c5cf08d37b85f953b132951e868df5b924250fdc/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c5cf08d37b85f953b132951e868df5b924250fdc/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fquoted.rs?ref=c5cf08d37b85f953b132951e868df5b924250fdc", "patch": "@@ -211,7 +211,7 @@ fn parse_tree(\n                     let (separator, kleene) =\n                         parse_sep_and_kleene_op(&mut trees, delim_span.entire(), sess);\n                     // Count the number of captured \"names\" (i.e., named metavars)\n-                    let name_captures = macro_parser::count_names(&sequence);\n+                    let name_captures = macro_parser::count_metavar_decls(&sequence);\n                     TokenTree::Sequence(\n                         delim_span,\n                         Lrc::new(SequenceRepetition {"}, {"sha": "a2fe402bccf8ff325b6dd0907652bb044321b618", "filename": "src/test/ui/macros/issue-95267.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c5cf08d37b85f953b132951e868df5b924250fdc/src%2Ftest%2Fui%2Fmacros%2Fissue-95267.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c5cf08d37b85f953b132951e868df5b924250fdc/src%2Ftest%2Fui%2Fmacros%2Fissue-95267.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fmacros%2Fissue-95267.rs?ref=c5cf08d37b85f953b132951e868df5b924250fdc", "patch": "@@ -1,7 +1,8 @@\n // check-pass\n \n-// This is a valid macro. Commit 4 in #95159 broke things such that it failed\n-// with a \"missing tokens in macro arguments\" error, as reported in #95267.\n+// The doc comment here is ignored. This is a bug, but #95267 showed that\n+// existing programs rely on this behaviour, and changing it would require some\n+// care and a transition period.\n macro_rules! f {\n     (\n         /// ab"}]}