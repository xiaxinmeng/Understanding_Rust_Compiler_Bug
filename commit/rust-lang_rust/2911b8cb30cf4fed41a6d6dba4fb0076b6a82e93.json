{"sha": "2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI5MTFiOGNiMzBjZjRmZWQ0MWE2ZDZkYmE0ZmIwMDc2YjZhODJlOTM=", "commit": {"author": {"name": "Ralf Jung", "email": "post@ralfj.de", "date": "2020-09-20T10:08:13Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-09-20T10:08:13Z"}, "message": "Rollup merge of #76766 - khyperia:generic_intrinsics, r=eddyb\n\nExtract some intrinsics out of rustc_codegen_llvm\n\nA significant amount of intrinsics do not actually need backend-specific behaviors to be implemented, instead relying on methods already in rustc_codegen_ssa. So, extract those methods out to rustc_codegen_ssa, so that each backend doesn't need to reimplement the same code.\n\nAlmost everything should be a pretty direct translation. A notable not-direct-translation is `add_with_overflow` and friends being changed to `bx.checked_binop`, but it's pretty simple.\n\nI could have been a lot more aggressive here and pulled out way more methods, and add a few new methods in the rustc_codegen_ssa \"API\". However, because this is my second rustc PR, I thought that moving those to a follow-up PR and doing more incremental changes here would be better (and I guess ask if this work is even desired in the first place). I'm hoping to eventually remove the mess of intrinsic handling in the backend entirely, which would be hecking fantastic :sparkles:", "tree": {"sha": "42dda65eb7ed4708d8d856dcd82cd4b0e51b7f8c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/42dda65eb7ed4708d8d856dcd82cd4b0e51b7f8c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfZyoOCRBK7hj4Ov3rIwAAdHIIAH+/4s8HsbYef5FmeK/fq4JE\n+fzMO+qKzyLz0eRbNua+LONZZV6GGggXLAObwL+e797QW9MKOjqOSTSJa+6GO4zn\nO13tGOVrUWHkIulti9TuYFSmFLPgGaTwxKrl5pBHXFDh2OdB71CETT0SZuGdBTKT\npV1Oz0bDJ7pAO4vkzPf2XRPHurJ6kHMTeVYgSh7KLaFHv56f/anrXewcK62WbcCV\nm5iuYMt7BXHnoVkhalkhsWScuSoDZh3ZMCtr99nzSf0UswrAXXQTcWNfEwbwJSab\nBtrqdEVhV7q1gPT/uU6h7jPdkRZvFz1unzoZP97jMUyKYbNQyprwteoz/4ZvIcc=\n=I44o\n-----END PGP SIGNATURE-----\n", "payload": "tree 42dda65eb7ed4708d8d856dcd82cd4b0e51b7f8c\nparent f5e19a355a2a16e0ed122e3f7728490b9e6357b8\nparent 21b0c1286a1f01cb8a21bda0973833ca11889364\nauthor Ralf Jung <post@ralfj.de> 1600596493 +0200\ncommitter GitHub <noreply@github.com> 1600596493 +0200\n\nRollup merge of #76766 - khyperia:generic_intrinsics, r=eddyb\n\nExtract some intrinsics out of rustc_codegen_llvm\n\nA significant amount of intrinsics do not actually need backend-specific behaviors to be implemented, instead relying on methods already in rustc_codegen_ssa. So, extract those methods out to rustc_codegen_ssa, so that each backend doesn't need to reimplement the same code.\n\nAlmost everything should be a pretty direct translation. A notable not-direct-translation is `add_with_overflow` and friends being changed to `bx.checked_binop`, but it's pretty simple.\n\nI could have been a lot more aggressive here and pulled out way more methods, and add a few new methods in the rustc_codegen_ssa \"API\". However, because this is my second rustc PR, I thought that moving those to a follow-up PR and doing more incremental changes here would be better (and I guess ask if this work is even desired in the first place). I'm hoping to eventually remove the mess of intrinsic handling in the backend entirely, which would be hecking fantastic :sparkles:\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "html_url": "https://github.com/rust-lang/rust/commit/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/comments", "author": {"login": "RalfJung", "id": 330628, "node_id": "MDQ6VXNlcjMzMDYyOA==", "avatar_url": "https://avatars.githubusercontent.com/u/330628?v=4", "gravatar_id": "", "url": "https://api.github.com/users/RalfJung", "html_url": "https://github.com/RalfJung", "followers_url": "https://api.github.com/users/RalfJung/followers", "following_url": "https://api.github.com/users/RalfJung/following{/other_user}", "gists_url": "https://api.github.com/users/RalfJung/gists{/gist_id}", "starred_url": "https://api.github.com/users/RalfJung/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/RalfJung/subscriptions", "organizations_url": "https://api.github.com/users/RalfJung/orgs", "repos_url": "https://api.github.com/users/RalfJung/repos", "events_url": "https://api.github.com/users/RalfJung/events{/privacy}", "received_events_url": "https://api.github.com/users/RalfJung/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f5e19a355a2a16e0ed122e3f7728490b9e6357b8", "url": "https://api.github.com/repos/rust-lang/rust/commits/f5e19a355a2a16e0ed122e3f7728490b9e6357b8", "html_url": "https://github.com/rust-lang/rust/commit/f5e19a355a2a16e0ed122e3f7728490b9e6357b8"}, {"sha": "21b0c1286a1f01cb8a21bda0973833ca11889364", "url": "https://api.github.com/repos/rust-lang/rust/commits/21b0c1286a1f01cb8a21bda0973833ca11889364", "html_url": "https://github.com/rust-lang/rust/commit/21b0c1286a1f01cb8a21bda0973833ca11889364"}], "stats": {"total": 1127, "additions": 606, "deletions": 521}, "files": [{"sha": "7f5b09eac4f9e0215e054bcfe42ca24abbb4702d", "filename": "compiler/rustc_codegen_llvm/src/intrinsic.rs", "status": "modified", "additions": 7, "deletions": 520, "changes": 527, "blob_url": "https://github.com/rust-lang/rust/blob/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_llvm%2Fsrc%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_llvm%2Fsrc%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_llvm%2Fsrc%2Fintrinsic.rs?ref=2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "patch": "@@ -7,15 +7,12 @@ use crate::type_of::LayoutLlvmExt;\n use crate::va_arg::emit_va_arg;\n use crate::value::Value;\n \n-use rustc_ast as ast;\n use rustc_codegen_ssa::base::{compare_simd_types, wants_msvc_seh};\n use rustc_codegen_ssa::common::span_invalid_monomorphization_error;\n use rustc_codegen_ssa::common::{IntPredicate, TypeKind};\n-use rustc_codegen_ssa::glue;\n-use rustc_codegen_ssa::mir::operand::{OperandRef, OperandValue};\n+use rustc_codegen_ssa::mir::operand::OperandRef;\n use rustc_codegen_ssa::mir::place::PlaceRef;\n use rustc_codegen_ssa::traits::*;\n-use rustc_codegen_ssa::MemFlags;\n use rustc_hir as hir;\n use rustc_middle::ty::layout::{FnAbiExt, HasTyCtxt};\n use rustc_middle::ty::{self, Ty};\n@@ -71,8 +68,6 @@ fn get_simple_intrinsic(cx: &CodegenCx<'ll, '_>, name: Symbol) -> Option<&'ll Va\n         sym::nearbyintf64 => \"llvm.nearbyint.f64\",\n         sym::roundf32 => \"llvm.round.f32\",\n         sym::roundf64 => \"llvm.round.f64\",\n-        sym::assume => \"llvm.assume\",\n-        sym::abort => \"llvm.trap\",\n         _ => return None,\n     };\n     Some(cx.get_intrinsic(&llvm_name))\n@@ -112,9 +107,6 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n                 &args.iter().map(|arg| arg.immediate()).collect::<Vec<_>>(),\n                 None,\n             ),\n-            sym::unreachable => {\n-                return;\n-            }\n             sym::likely => {\n                 let expect = self.get_intrinsic(&(\"llvm.expect.i1\"));\n                 self.call(expect, &[args[0].immediate(), self.const_bool(true)], None)\n@@ -137,8 +129,6 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n                 let llfn = self.get_intrinsic(&(\"llvm.debugtrap\"));\n                 self.call(llfn, &[], None)\n             }\n-            sym::va_start => self.va_start(args[0].immediate()),\n-            sym::va_end => self.va_end(args[0].immediate()),\n             sym::va_copy => {\n                 let intrinsic = self.cx().get_intrinsic(&(\"llvm.va_copy\"));\n                 self.call(intrinsic, &[args[0].immediate(), args[1].immediate()], None)\n@@ -169,123 +159,7 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n                     _ => bug!(\"the va_arg intrinsic does not work with non-scalar types\"),\n                 }\n             }\n-            sym::size_of_val => {\n-                let tp_ty = substs.type_at(0);\n-                if let OperandValue::Pair(_, meta) = args[0].val {\n-                    let (llsize, _) = glue::size_and_align_of_dst(self, tp_ty, Some(meta));\n-                    llsize\n-                } else {\n-                    self.const_usize(self.size_of(tp_ty).bytes())\n-                }\n-            }\n-            sym::min_align_of_val => {\n-                let tp_ty = substs.type_at(0);\n-                if let OperandValue::Pair(_, meta) = args[0].val {\n-                    let (_, llalign) = glue::size_and_align_of_dst(self, tp_ty, Some(meta));\n-                    llalign\n-                } else {\n-                    self.const_usize(self.align_of(tp_ty).bytes())\n-                }\n-            }\n-            sym::size_of\n-            | sym::pref_align_of\n-            | sym::min_align_of\n-            | sym::needs_drop\n-            | sym::type_id\n-            | sym::type_name\n-            | sym::variant_count => {\n-                let value = self\n-                    .tcx\n-                    .const_eval_instance(ty::ParamEnv::reveal_all(), instance, None)\n-                    .unwrap();\n-                OperandRef::from_const(self, value, ret_ty).immediate_or_packed_pair(self)\n-            }\n-            // Effectively no-op\n-            sym::forget => {\n-                return;\n-            }\n-            sym::offset => {\n-                let ptr = args[0].immediate();\n-                let offset = args[1].immediate();\n-                self.inbounds_gep(ptr, &[offset])\n-            }\n-            sym::arith_offset => {\n-                let ptr = args[0].immediate();\n-                let offset = args[1].immediate();\n-                self.gep(ptr, &[offset])\n-            }\n-\n-            sym::copy_nonoverlapping => {\n-                copy_intrinsic(\n-                    self,\n-                    false,\n-                    false,\n-                    substs.type_at(0),\n-                    args[1].immediate(),\n-                    args[0].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n-            sym::copy => {\n-                copy_intrinsic(\n-                    self,\n-                    true,\n-                    false,\n-                    substs.type_at(0),\n-                    args[1].immediate(),\n-                    args[0].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n-            sym::write_bytes => {\n-                memset_intrinsic(\n-                    self,\n-                    false,\n-                    substs.type_at(0),\n-                    args[0].immediate(),\n-                    args[1].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n \n-            sym::volatile_copy_nonoverlapping_memory => {\n-                copy_intrinsic(\n-                    self,\n-                    false,\n-                    true,\n-                    substs.type_at(0),\n-                    args[0].immediate(),\n-                    args[1].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n-            sym::volatile_copy_memory => {\n-                copy_intrinsic(\n-                    self,\n-                    true,\n-                    true,\n-                    substs.type_at(0),\n-                    args[0].immediate(),\n-                    args[1].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n-            sym::volatile_set_memory => {\n-                memset_intrinsic(\n-                    self,\n-                    true,\n-                    substs.type_at(0),\n-                    args[0].immediate(),\n-                    args[1].immediate(),\n-                    args[2].immediate(),\n-                );\n-                return;\n-            }\n             sym::volatile_load | sym::unaligned_volatile_load => {\n                 let tp_ty = substs.type_at(0);\n                 let mut ptr = args[0].immediate();\n@@ -343,20 +217,6 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n             | sym::ctpop\n             | sym::bswap\n             | sym::bitreverse\n-            | sym::add_with_overflow\n-            | sym::sub_with_overflow\n-            | sym::mul_with_overflow\n-            | sym::wrapping_add\n-            | sym::wrapping_sub\n-            | sym::wrapping_mul\n-            | sym::unchecked_div\n-            | sym::unchecked_rem\n-            | sym::unchecked_shl\n-            | sym::unchecked_shr\n-            | sym::unchecked_add\n-            | sym::unchecked_sub\n-            | sym::unchecked_mul\n-            | sym::exact_div\n             | sym::rotate_left\n             | sym::rotate_right\n             | sym::saturating_add\n@@ -396,84 +256,6 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n                             &[args[0].immediate()],\n                             None,\n                         ),\n-                        sym::add_with_overflow\n-                        | sym::sub_with_overflow\n-                        | sym::mul_with_overflow => {\n-                            let intrinsic = format!(\n-                                \"llvm.{}{}.with.overflow.i{}\",\n-                                if signed { 's' } else { 'u' },\n-                                &name_str[..3],\n-                                width\n-                            );\n-                            let llfn = self.get_intrinsic(&intrinsic);\n-\n-                            // Convert `i1` to a `bool`, and write it to the out parameter\n-                            let pair =\n-                                self.call(llfn, &[args[0].immediate(), args[1].immediate()], None);\n-                            let val = self.extract_value(pair, 0);\n-                            let overflow = self.extract_value(pair, 1);\n-                            let overflow = self.zext(overflow, self.type_bool());\n-\n-                            let dest = result.project_field(self, 0);\n-                            self.store(val, dest.llval, dest.align);\n-                            let dest = result.project_field(self, 1);\n-                            self.store(overflow, dest.llval, dest.align);\n-\n-                            return;\n-                        }\n-                        sym::wrapping_add => self.add(args[0].immediate(), args[1].immediate()),\n-                        sym::wrapping_sub => self.sub(args[0].immediate(), args[1].immediate()),\n-                        sym::wrapping_mul => self.mul(args[0].immediate(), args[1].immediate()),\n-                        sym::exact_div => {\n-                            if signed {\n-                                self.exactsdiv(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.exactudiv(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_div => {\n-                            if signed {\n-                                self.sdiv(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.udiv(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_rem => {\n-                            if signed {\n-                                self.srem(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.urem(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_shl => self.shl(args[0].immediate(), args[1].immediate()),\n-                        sym::unchecked_shr => {\n-                            if signed {\n-                                self.ashr(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.lshr(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_add => {\n-                            if signed {\n-                                self.unchecked_sadd(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.unchecked_uadd(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_sub => {\n-                            if signed {\n-                                self.unchecked_ssub(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.unchecked_usub(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n-                        sym::unchecked_mul => {\n-                            if signed {\n-                                self.unchecked_smul(args[0].immediate(), args[1].immediate())\n-                            } else {\n-                                self.unchecked_umul(args[0].immediate(), args[1].immediate())\n-                            }\n-                        }\n                         sym::rotate_left | sym::rotate_right => {\n                             let is_left = name == sym::rotate_left;\n                             let val = args[0].immediate();\n@@ -513,250 +295,13 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n                     }\n                 }\n             }\n-            sym::fadd_fast | sym::fsub_fast | sym::fmul_fast | sym::fdiv_fast | sym::frem_fast => {\n-                match float_type_width(arg_tys[0]) {\n-                    Some(_width) => match name {\n-                        sym::fadd_fast => self.fadd_fast(args[0].immediate(), args[1].immediate()),\n-                        sym::fsub_fast => self.fsub_fast(args[0].immediate(), args[1].immediate()),\n-                        sym::fmul_fast => self.fmul_fast(args[0].immediate(), args[1].immediate()),\n-                        sym::fdiv_fast => self.fdiv_fast(args[0].immediate(), args[1].immediate()),\n-                        sym::frem_fast => self.frem_fast(args[0].immediate(), args[1].immediate()),\n-                        _ => bug!(),\n-                    },\n-                    None => {\n-                        span_invalid_monomorphization_error(\n-                            tcx.sess,\n-                            span,\n-                            &format!(\n-                                \"invalid monomorphization of `{}` intrinsic: \\\n-                                      expected basic float type, found `{}`\",\n-                                name, arg_tys[0]\n-                            ),\n-                        );\n-                        return;\n-                    }\n-                }\n-            }\n-\n-            sym::float_to_int_unchecked => {\n-                if float_type_width(arg_tys[0]).is_none() {\n-                    span_invalid_monomorphization_error(\n-                        tcx.sess,\n-                        span,\n-                        &format!(\n-                            \"invalid monomorphization of `float_to_int_unchecked` \\\n-                                  intrinsic: expected basic float type, \\\n-                                  found `{}`\",\n-                            arg_tys[0]\n-                        ),\n-                    );\n-                    return;\n-                }\n-                let (width, signed) = match int_type_width_signed(ret_ty, self.cx) {\n-                    Some(pair) => pair,\n-                    None => {\n-                        span_invalid_monomorphization_error(\n-                            tcx.sess,\n-                            span,\n-                            &format!(\n-                                \"invalid monomorphization of `float_to_int_unchecked` \\\n-                                      intrinsic:  expected basic integer type, \\\n-                                      found `{}`\",\n-                                ret_ty\n-                            ),\n-                        );\n-                        return;\n-                    }\n-                };\n-                if signed {\n-                    self.fptosi(args[0].immediate(), self.cx.type_ix(width))\n-                } else {\n-                    self.fptoui(args[0].immediate(), self.cx.type_ix(width))\n-                }\n-            }\n-\n-            sym::discriminant_value => {\n-                if ret_ty.is_integral() {\n-                    args[0].deref(self.cx()).codegen_get_discr(self, ret_ty)\n-                } else {\n-                    span_bug!(span, \"Invalid discriminant type for `{:?}`\", arg_tys[0])\n-                }\n-            }\n \n             _ if name_str.starts_with(\"simd_\") => {\n                 match generic_simd_intrinsic(self, name, callee_ty, args, ret_ty, llret_ty, span) {\n                     Ok(llval) => llval,\n                     Err(()) => return,\n                 }\n             }\n-            // This requires that atomic intrinsics follow a specific naming pattern:\n-            // \"atomic_<operation>[_<ordering>]\", and no ordering means SeqCst\n-            name if name_str.starts_with(\"atomic_\") => {\n-                use rustc_codegen_ssa::common::AtomicOrdering::*;\n-                use rustc_codegen_ssa::common::{AtomicRmwBinOp, SynchronizationScope};\n-\n-                let split: Vec<&str> = name_str.split('_').collect();\n-\n-                let is_cxchg = split[1] == \"cxchg\" || split[1] == \"cxchgweak\";\n-                let (order, failorder) = match split.len() {\n-                    2 => (SequentiallyConsistent, SequentiallyConsistent),\n-                    3 => match split[2] {\n-                        \"unordered\" => (Unordered, Unordered),\n-                        \"relaxed\" => (Monotonic, Monotonic),\n-                        \"acq\" => (Acquire, Acquire),\n-                        \"rel\" => (Release, Monotonic),\n-                        \"acqrel\" => (AcquireRelease, Acquire),\n-                        \"failrelaxed\" if is_cxchg => (SequentiallyConsistent, Monotonic),\n-                        \"failacq\" if is_cxchg => (SequentiallyConsistent, Acquire),\n-                        _ => self.sess().fatal(\"unknown ordering in atomic intrinsic\"),\n-                    },\n-                    4 => match (split[2], split[3]) {\n-                        (\"acq\", \"failrelaxed\") if is_cxchg => (Acquire, Monotonic),\n-                        (\"acqrel\", \"failrelaxed\") if is_cxchg => (AcquireRelease, Monotonic),\n-                        _ => self.sess().fatal(\"unknown ordering in atomic intrinsic\"),\n-                    },\n-                    _ => self.sess().fatal(\"Atomic intrinsic not in correct format\"),\n-                };\n-\n-                let invalid_monomorphization = |ty| {\n-                    span_invalid_monomorphization_error(\n-                        tcx.sess,\n-                        span,\n-                        &format!(\n-                            \"invalid monomorphization of `{}` intrinsic: \\\n-                                  expected basic integer type, found `{}`\",\n-                            name, ty\n-                        ),\n-                    );\n-                };\n-\n-                match split[1] {\n-                    \"cxchg\" | \"cxchgweak\" => {\n-                        let ty = substs.type_at(0);\n-                        if int_type_width_signed(ty, self).is_some() {\n-                            let weak = split[1] == \"cxchgweak\";\n-                            let pair = self.atomic_cmpxchg(\n-                                args[0].immediate(),\n-                                args[1].immediate(),\n-                                args[2].immediate(),\n-                                order,\n-                                failorder,\n-                                weak,\n-                            );\n-                            let val = self.extract_value(pair, 0);\n-                            let success = self.extract_value(pair, 1);\n-                            let success = self.zext(success, self.type_bool());\n-\n-                            let dest = result.project_field(self, 0);\n-                            self.store(val, dest.llval, dest.align);\n-                            let dest = result.project_field(self, 1);\n-                            self.store(success, dest.llval, dest.align);\n-                            return;\n-                        } else {\n-                            return invalid_monomorphization(ty);\n-                        }\n-                    }\n-\n-                    \"load\" => {\n-                        let ty = substs.type_at(0);\n-                        if int_type_width_signed(ty, self).is_some() {\n-                            let size = self.size_of(ty);\n-                            self.atomic_load(args[0].immediate(), order, size)\n-                        } else {\n-                            return invalid_monomorphization(ty);\n-                        }\n-                    }\n-\n-                    \"store\" => {\n-                        let ty = substs.type_at(0);\n-                        if int_type_width_signed(ty, self).is_some() {\n-                            let size = self.size_of(ty);\n-                            self.atomic_store(\n-                                args[1].immediate(),\n-                                args[0].immediate(),\n-                                order,\n-                                size,\n-                            );\n-                            return;\n-                        } else {\n-                            return invalid_monomorphization(ty);\n-                        }\n-                    }\n-\n-                    \"fence\" => {\n-                        self.atomic_fence(order, SynchronizationScope::CrossThread);\n-                        return;\n-                    }\n-\n-                    \"singlethreadfence\" => {\n-                        self.atomic_fence(order, SynchronizationScope::SingleThread);\n-                        return;\n-                    }\n-\n-                    // These are all AtomicRMW ops\n-                    op => {\n-                        let atom_op = match op {\n-                            \"xchg\" => AtomicRmwBinOp::AtomicXchg,\n-                            \"xadd\" => AtomicRmwBinOp::AtomicAdd,\n-                            \"xsub\" => AtomicRmwBinOp::AtomicSub,\n-                            \"and\" => AtomicRmwBinOp::AtomicAnd,\n-                            \"nand\" => AtomicRmwBinOp::AtomicNand,\n-                            \"or\" => AtomicRmwBinOp::AtomicOr,\n-                            \"xor\" => AtomicRmwBinOp::AtomicXor,\n-                            \"max\" => AtomicRmwBinOp::AtomicMax,\n-                            \"min\" => AtomicRmwBinOp::AtomicMin,\n-                            \"umax\" => AtomicRmwBinOp::AtomicUMax,\n-                            \"umin\" => AtomicRmwBinOp::AtomicUMin,\n-                            _ => self.sess().fatal(\"unknown atomic operation\"),\n-                        };\n-\n-                        let ty = substs.type_at(0);\n-                        if int_type_width_signed(ty, self).is_some() {\n-                            self.atomic_rmw(\n-                                atom_op,\n-                                args[0].immediate(),\n-                                args[1].immediate(),\n-                                order,\n-                            )\n-                        } else {\n-                            return invalid_monomorphization(ty);\n-                        }\n-                    }\n-                }\n-            }\n-\n-            sym::nontemporal_store => {\n-                let dst = args[0].deref(self.cx());\n-                args[1].val.nontemporal_store(self, dst);\n-                return;\n-            }\n-\n-            sym::ptr_guaranteed_eq | sym::ptr_guaranteed_ne => {\n-                let a = args[0].immediate();\n-                let b = args[1].immediate();\n-                if name == sym::ptr_guaranteed_eq {\n-                    self.icmp(IntPredicate::IntEQ, a, b)\n-                } else {\n-                    self.icmp(IntPredicate::IntNE, a, b)\n-                }\n-            }\n-\n-            sym::ptr_offset_from => {\n-                let ty = substs.type_at(0);\n-                let pointee_size = self.size_of(ty);\n-\n-                // This is the same sequence that Clang emits for pointer subtraction.\n-                // It can be neither `nsw` nor `nuw` because the input is treated as\n-                // unsigned but then the output is treated as signed, so neither works.\n-                let a = args[0].immediate();\n-                let b = args[1].immediate();\n-                let a = self.ptrtoint(a, self.type_isize());\n-                let b = self.ptrtoint(b, self.type_isize());\n-                let d = self.sub(a, b);\n-                let pointee_size = self.const_usize(pointee_size.bytes());\n-                // this is where the signed magic happens (notice the `s` in `exactsdiv`)\n-                self.exactsdiv(d, pointee_size)\n-            }\n \n             _ => bug!(\"unknown intrinsic '{}'\", name),\n         };\n@@ -807,39 +352,6 @@ impl IntrinsicCallMethods<'tcx> for Builder<'a, 'll, 'tcx> {\n     }\n }\n \n-fn copy_intrinsic(\n-    bx: &mut Builder<'a, 'll, 'tcx>,\n-    allow_overlap: bool,\n-    volatile: bool,\n-    ty: Ty<'tcx>,\n-    dst: &'ll Value,\n-    src: &'ll Value,\n-    count: &'ll Value,\n-) {\n-    let (size, align) = bx.size_and_align_of(ty);\n-    let size = bx.mul(bx.const_usize(size.bytes()), count);\n-    let flags = if volatile { MemFlags::VOLATILE } else { MemFlags::empty() };\n-    if allow_overlap {\n-        bx.memmove(dst, align, src, align, size, flags);\n-    } else {\n-        bx.memcpy(dst, align, src, align, size, flags);\n-    }\n-}\n-\n-fn memset_intrinsic(\n-    bx: &mut Builder<'a, 'll, 'tcx>,\n-    volatile: bool,\n-    ty: Ty<'tcx>,\n-    dst: &'ll Value,\n-    val: &'ll Value,\n-    count: &'ll Value,\n-) {\n-    let (size, align) = bx.size_and_align_of(ty);\n-    let size = bx.mul(bx.const_usize(size.bytes()), count);\n-    let flags = if volatile { MemFlags::VOLATILE } else { MemFlags::empty() };\n-    bx.memset(dst, val, size, align, flags);\n-}\n-\n fn try_intrinsic(\n     bx: &mut Builder<'a, 'll, 'tcx>,\n     try_func: &'ll Value,\n@@ -2205,37 +1717,12 @@ unsupported {} from `{}` with element `{}` of size `{}` to `{}`\"#,\n // stuffs.\n fn int_type_width_signed(ty: Ty<'_>, cx: &CodegenCx<'_, '_>) -> Option<(u64, bool)> {\n     match ty.kind() {\n-        ty::Int(t) => Some((\n-            match t {\n-                ast::IntTy::Isize => u64::from(cx.tcx.sess.target.ptr_width),\n-                ast::IntTy::I8 => 8,\n-                ast::IntTy::I16 => 16,\n-                ast::IntTy::I32 => 32,\n-                ast::IntTy::I64 => 64,\n-                ast::IntTy::I128 => 128,\n-            },\n-            true,\n-        )),\n-        ty::Uint(t) => Some((\n-            match t {\n-                ast::UintTy::Usize => u64::from(cx.tcx.sess.target.ptr_width),\n-                ast::UintTy::U8 => 8,\n-                ast::UintTy::U16 => 16,\n-                ast::UintTy::U32 => 32,\n-                ast::UintTy::U64 => 64,\n-                ast::UintTy::U128 => 128,\n-            },\n-            false,\n-        )),\n-        _ => None,\n-    }\n-}\n-\n-// Returns the width of a float Ty\n-// Returns None if the type is not a float\n-fn float_type_width(ty: Ty<'_>) -> Option<u64> {\n-    match ty.kind() {\n-        ty::Float(t) => Some(t.bit_width()),\n+        ty::Int(t) => {\n+            Some((t.bit_width().unwrap_or(u64::from(cx.tcx.sess.target.ptr_width)), true))\n+        }\n+        ty::Uint(t) => {\n+            Some((t.bit_width().unwrap_or(u64::from(cx.tcx.sess.target.ptr_width)), false))\n+        }\n         _ => None,\n     }\n }"}, {"sha": "4f85d232caa685d4403a17472c51ca1346421bc1", "filename": "compiler/rustc_codegen_ssa/src/mir/block.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fblock.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fblock.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fblock.rs?ref=2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "patch": "@@ -687,7 +687,8 @@ impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n                 })\n                 .collect();\n \n-            bx.codegen_intrinsic_call(\n+            Self::codegen_intrinsic_call(\n+                &mut bx,\n                 *instance.as_ref().unwrap(),\n                 &fn_abi,\n                 &args,"}, {"sha": "14f1ed59a67c5f1704e9f5d7a0100df80c0e80b7", "filename": "compiler/rustc_codegen_ssa/src/mir/intrinsic.rs", "status": "added", "additions": 596, "deletions": 0, "changes": 596, "blob_url": "https://github.com/rust-lang/rust/blob/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fintrinsic.rs?ref=2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "patch": "@@ -0,0 +1,596 @@\n+use super::operand::{OperandRef, OperandValue};\n+use super::place::PlaceRef;\n+use super::FunctionCx;\n+use crate::common::{span_invalid_monomorphization_error, IntPredicate};\n+use crate::glue;\n+use crate::traits::*;\n+use crate::MemFlags;\n+\n+use rustc_middle::ty::{self, Ty, TyCtxt};\n+use rustc_span::{sym, Span};\n+use rustc_target::abi::call::{FnAbi, PassMode};\n+\n+fn copy_intrinsic<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>>(\n+    bx: &mut Bx,\n+    allow_overlap: bool,\n+    volatile: bool,\n+    ty: Ty<'tcx>,\n+    dst: Bx::Value,\n+    src: Bx::Value,\n+    count: Bx::Value,\n+) {\n+    let layout = bx.layout_of(ty);\n+    let size = layout.size;\n+    let align = layout.align.abi;\n+    let size = bx.mul(bx.const_usize(size.bytes()), count);\n+    let flags = if volatile { MemFlags::VOLATILE } else { MemFlags::empty() };\n+    if allow_overlap {\n+        bx.memmove(dst, align, src, align, size, flags);\n+    } else {\n+        bx.memcpy(dst, align, src, align, size, flags);\n+    }\n+}\n+\n+fn memset_intrinsic<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>>(\n+    bx: &mut Bx,\n+    volatile: bool,\n+    ty: Ty<'tcx>,\n+    dst: Bx::Value,\n+    val: Bx::Value,\n+    count: Bx::Value,\n+) {\n+    let layout = bx.layout_of(ty);\n+    let size = layout.size;\n+    let align = layout.align.abi;\n+    let size = bx.mul(bx.const_usize(size.bytes()), count);\n+    let flags = if volatile { MemFlags::VOLATILE } else { MemFlags::empty() };\n+    bx.memset(dst, val, size, align, flags);\n+}\n+\n+impl<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>> FunctionCx<'a, 'tcx, Bx> {\n+    pub fn codegen_intrinsic_call(\n+        bx: &mut Bx,\n+        instance: ty::Instance<'tcx>,\n+        fn_abi: &FnAbi<'tcx, Ty<'tcx>>,\n+        args: &[OperandRef<'tcx, Bx::Value>],\n+        llresult: Bx::Value,\n+        span: Span,\n+    ) {\n+        let callee_ty = instance.ty(bx.tcx(), ty::ParamEnv::reveal_all());\n+\n+        let (def_id, substs) = match *callee_ty.kind() {\n+            ty::FnDef(def_id, substs) => (def_id, substs),\n+            _ => bug!(\"expected fn item type, found {}\", callee_ty),\n+        };\n+\n+        let sig = callee_ty.fn_sig(bx.tcx());\n+        let sig = bx.tcx().normalize_erasing_late_bound_regions(ty::ParamEnv::reveal_all(), &sig);\n+        let arg_tys = sig.inputs();\n+        let ret_ty = sig.output();\n+        let name = bx.tcx().item_name(def_id);\n+        let name_str = &*name.as_str();\n+\n+        let llret_ty = bx.backend_type(bx.layout_of(ret_ty));\n+        let result = PlaceRef::new_sized(llresult, fn_abi.ret.layout);\n+\n+        let llval = match name {\n+            sym::assume => {\n+                bx.assume(args[0].immediate());\n+                return;\n+            }\n+            sym::abort => {\n+                bx.abort();\n+                return;\n+            }\n+\n+            sym::unreachable => {\n+                return;\n+            }\n+            sym::va_start => bx.va_start(args[0].immediate()),\n+            sym::va_end => bx.va_end(args[0].immediate()),\n+            sym::size_of_val => {\n+                let tp_ty = substs.type_at(0);\n+                if let OperandValue::Pair(_, meta) = args[0].val {\n+                    let (llsize, _) = glue::size_and_align_of_dst(bx, tp_ty, Some(meta));\n+                    llsize\n+                } else {\n+                    bx.const_usize(bx.layout_of(tp_ty).size.bytes())\n+                }\n+            }\n+            sym::min_align_of_val => {\n+                let tp_ty = substs.type_at(0);\n+                if let OperandValue::Pair(_, meta) = args[0].val {\n+                    let (_, llalign) = glue::size_and_align_of_dst(bx, tp_ty, Some(meta));\n+                    llalign\n+                } else {\n+                    bx.const_usize(bx.layout_of(tp_ty).align.abi.bytes())\n+                }\n+            }\n+            sym::size_of\n+            | sym::pref_align_of\n+            | sym::min_align_of\n+            | sym::needs_drop\n+            | sym::type_id\n+            | sym::type_name\n+            | sym::variant_count => {\n+                let value = bx\n+                    .tcx()\n+                    .const_eval_instance(ty::ParamEnv::reveal_all(), instance, None)\n+                    .unwrap();\n+                OperandRef::from_const(bx, value, ret_ty).immediate_or_packed_pair(bx)\n+            }\n+            // Effectively no-op\n+            sym::forget => {\n+                return;\n+            }\n+            sym::offset => {\n+                let ptr = args[0].immediate();\n+                let offset = args[1].immediate();\n+                bx.inbounds_gep(ptr, &[offset])\n+            }\n+            sym::arith_offset => {\n+                let ptr = args[0].immediate();\n+                let offset = args[1].immediate();\n+                bx.gep(ptr, &[offset])\n+            }\n+\n+            sym::copy_nonoverlapping => {\n+                copy_intrinsic(\n+                    bx,\n+                    false,\n+                    false,\n+                    substs.type_at(0),\n+                    args[1].immediate(),\n+                    args[0].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+            sym::copy => {\n+                copy_intrinsic(\n+                    bx,\n+                    true,\n+                    false,\n+                    substs.type_at(0),\n+                    args[1].immediate(),\n+                    args[0].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+            sym::write_bytes => {\n+                memset_intrinsic(\n+                    bx,\n+                    false,\n+                    substs.type_at(0),\n+                    args[0].immediate(),\n+                    args[1].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+\n+            sym::volatile_copy_nonoverlapping_memory => {\n+                copy_intrinsic(\n+                    bx,\n+                    false,\n+                    true,\n+                    substs.type_at(0),\n+                    args[0].immediate(),\n+                    args[1].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+            sym::volatile_copy_memory => {\n+                copy_intrinsic(\n+                    bx,\n+                    true,\n+                    true,\n+                    substs.type_at(0),\n+                    args[0].immediate(),\n+                    args[1].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+            sym::volatile_set_memory => {\n+                memset_intrinsic(\n+                    bx,\n+                    true,\n+                    substs.type_at(0),\n+                    args[0].immediate(),\n+                    args[1].immediate(),\n+                    args[2].immediate(),\n+                );\n+                return;\n+            }\n+            sym::volatile_store => {\n+                let dst = args[0].deref(bx.cx());\n+                args[1].val.volatile_store(bx, dst);\n+                return;\n+            }\n+            sym::unaligned_volatile_store => {\n+                let dst = args[0].deref(bx.cx());\n+                args[1].val.unaligned_volatile_store(bx, dst);\n+                return;\n+            }\n+            sym::add_with_overflow\n+            | sym::sub_with_overflow\n+            | sym::mul_with_overflow\n+            | sym::wrapping_add\n+            | sym::wrapping_sub\n+            | sym::wrapping_mul\n+            | sym::unchecked_div\n+            | sym::unchecked_rem\n+            | sym::unchecked_shl\n+            | sym::unchecked_shr\n+            | sym::unchecked_add\n+            | sym::unchecked_sub\n+            | sym::unchecked_mul\n+            | sym::exact_div => {\n+                let ty = arg_tys[0];\n+                match int_type_width_signed(ty, bx.tcx()) {\n+                    Some((_width, signed)) => match name {\n+                        sym::add_with_overflow\n+                        | sym::sub_with_overflow\n+                        | sym::mul_with_overflow => {\n+                            let op = match name {\n+                                sym::add_with_overflow => OverflowOp::Add,\n+                                sym::sub_with_overflow => OverflowOp::Sub,\n+                                sym::mul_with_overflow => OverflowOp::Mul,\n+                                _ => bug!(),\n+                            };\n+                            let (val, overflow) =\n+                                bx.checked_binop(op, ty, args[0].immediate(), args[1].immediate());\n+                            // Convert `i1` to a `bool`, and write it to the out parameter\n+                            let val = bx.from_immediate(val);\n+                            let overflow = bx.from_immediate(overflow);\n+\n+                            let dest = result.project_field(bx, 0);\n+                            bx.store(val, dest.llval, dest.align);\n+                            let dest = result.project_field(bx, 1);\n+                            bx.store(overflow, dest.llval, dest.align);\n+\n+                            return;\n+                        }\n+                        sym::wrapping_add => bx.add(args[0].immediate(), args[1].immediate()),\n+                        sym::wrapping_sub => bx.sub(args[0].immediate(), args[1].immediate()),\n+                        sym::wrapping_mul => bx.mul(args[0].immediate(), args[1].immediate()),\n+                        sym::exact_div => {\n+                            if signed {\n+                                bx.exactsdiv(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.exactudiv(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_div => {\n+                            if signed {\n+                                bx.sdiv(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.udiv(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_rem => {\n+                            if signed {\n+                                bx.srem(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.urem(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_shl => bx.shl(args[0].immediate(), args[1].immediate()),\n+                        sym::unchecked_shr => {\n+                            if signed {\n+                                bx.ashr(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.lshr(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_add => {\n+                            if signed {\n+                                bx.unchecked_sadd(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.unchecked_uadd(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_sub => {\n+                            if signed {\n+                                bx.unchecked_ssub(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.unchecked_usub(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        sym::unchecked_mul => {\n+                            if signed {\n+                                bx.unchecked_smul(args[0].immediate(), args[1].immediate())\n+                            } else {\n+                                bx.unchecked_umul(args[0].immediate(), args[1].immediate())\n+                            }\n+                        }\n+                        _ => bug!(),\n+                    },\n+                    None => {\n+                        span_invalid_monomorphization_error(\n+                            bx.tcx().sess,\n+                            span,\n+                            &format!(\n+                                \"invalid monomorphization of `{}` intrinsic: \\\n+                                      expected basic integer type, found `{}`\",\n+                                name, ty\n+                            ),\n+                        );\n+                        return;\n+                    }\n+                }\n+            }\n+            sym::fadd_fast | sym::fsub_fast | sym::fmul_fast | sym::fdiv_fast | sym::frem_fast => {\n+                match float_type_width(arg_tys[0]) {\n+                    Some(_width) => match name {\n+                        sym::fadd_fast => bx.fadd_fast(args[0].immediate(), args[1].immediate()),\n+                        sym::fsub_fast => bx.fsub_fast(args[0].immediate(), args[1].immediate()),\n+                        sym::fmul_fast => bx.fmul_fast(args[0].immediate(), args[1].immediate()),\n+                        sym::fdiv_fast => bx.fdiv_fast(args[0].immediate(), args[1].immediate()),\n+                        sym::frem_fast => bx.frem_fast(args[0].immediate(), args[1].immediate()),\n+                        _ => bug!(),\n+                    },\n+                    None => {\n+                        span_invalid_monomorphization_error(\n+                            bx.tcx().sess,\n+                            span,\n+                            &format!(\n+                                \"invalid monomorphization of `{}` intrinsic: \\\n+                                      expected basic float type, found `{}`\",\n+                                name, arg_tys[0]\n+                            ),\n+                        );\n+                        return;\n+                    }\n+                }\n+            }\n+\n+            sym::float_to_int_unchecked => {\n+                if float_type_width(arg_tys[0]).is_none() {\n+                    span_invalid_monomorphization_error(\n+                        bx.tcx().sess,\n+                        span,\n+                        &format!(\n+                            \"invalid monomorphization of `float_to_int_unchecked` \\\n+                                  intrinsic: expected basic float type, \\\n+                                  found `{}`\",\n+                            arg_tys[0]\n+                        ),\n+                    );\n+                    return;\n+                }\n+                let (_width, signed) = match int_type_width_signed(ret_ty, bx.tcx()) {\n+                    Some(pair) => pair,\n+                    None => {\n+                        span_invalid_monomorphization_error(\n+                            bx.tcx().sess,\n+                            span,\n+                            &format!(\n+                                \"invalid monomorphization of `float_to_int_unchecked` \\\n+                                      intrinsic:  expected basic integer type, \\\n+                                      found `{}`\",\n+                                ret_ty\n+                            ),\n+                        );\n+                        return;\n+                    }\n+                };\n+                if signed {\n+                    bx.fptosi(args[0].immediate(), llret_ty)\n+                } else {\n+                    bx.fptoui(args[0].immediate(), llret_ty)\n+                }\n+            }\n+\n+            sym::discriminant_value => {\n+                if ret_ty.is_integral() {\n+                    args[0].deref(bx.cx()).codegen_get_discr(bx, ret_ty)\n+                } else {\n+                    span_bug!(span, \"Invalid discriminant type for `{:?}`\", arg_tys[0])\n+                }\n+            }\n+\n+            // This requires that atomic intrinsics follow a specific naming pattern:\n+            // \"atomic_<operation>[_<ordering>]\", and no ordering means SeqCst\n+            name if name_str.starts_with(\"atomic_\") => {\n+                use crate::common::AtomicOrdering::*;\n+                use crate::common::{AtomicRmwBinOp, SynchronizationScope};\n+\n+                let split: Vec<&str> = name_str.split('_').collect();\n+\n+                let is_cxchg = split[1] == \"cxchg\" || split[1] == \"cxchgweak\";\n+                let (order, failorder) = match split.len() {\n+                    2 => (SequentiallyConsistent, SequentiallyConsistent),\n+                    3 => match split[2] {\n+                        \"unordered\" => (Unordered, Unordered),\n+                        \"relaxed\" => (Monotonic, Monotonic),\n+                        \"acq\" => (Acquire, Acquire),\n+                        \"rel\" => (Release, Monotonic),\n+                        \"acqrel\" => (AcquireRelease, Acquire),\n+                        \"failrelaxed\" if is_cxchg => (SequentiallyConsistent, Monotonic),\n+                        \"failacq\" if is_cxchg => (SequentiallyConsistent, Acquire),\n+                        _ => bx.sess().fatal(\"unknown ordering in atomic intrinsic\"),\n+                    },\n+                    4 => match (split[2], split[3]) {\n+                        (\"acq\", \"failrelaxed\") if is_cxchg => (Acquire, Monotonic),\n+                        (\"acqrel\", \"failrelaxed\") if is_cxchg => (AcquireRelease, Monotonic),\n+                        _ => bx.sess().fatal(\"unknown ordering in atomic intrinsic\"),\n+                    },\n+                    _ => bx.sess().fatal(\"Atomic intrinsic not in correct format\"),\n+                };\n+\n+                let invalid_monomorphization = |ty| {\n+                    span_invalid_monomorphization_error(\n+                        bx.tcx().sess,\n+                        span,\n+                        &format!(\n+                            \"invalid monomorphization of `{}` intrinsic: \\\n+                                  expected basic integer type, found `{}`\",\n+                            name, ty\n+                        ),\n+                    );\n+                };\n+\n+                match split[1] {\n+                    \"cxchg\" | \"cxchgweak\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, bx.tcx()).is_some() {\n+                            let weak = split[1] == \"cxchgweak\";\n+                            let pair = bx.atomic_cmpxchg(\n+                                args[0].immediate(),\n+                                args[1].immediate(),\n+                                args[2].immediate(),\n+                                order,\n+                                failorder,\n+                                weak,\n+                            );\n+                            let val = bx.extract_value(pair, 0);\n+                            let success = bx.extract_value(pair, 1);\n+                            let val = bx.from_immediate(val);\n+                            let success = bx.from_immediate(success);\n+\n+                            let dest = result.project_field(bx, 0);\n+                            bx.store(val, dest.llval, dest.align);\n+                            let dest = result.project_field(bx, 1);\n+                            bx.store(success, dest.llval, dest.align);\n+                            return;\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n+                    }\n+\n+                    \"load\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, bx.tcx()).is_some() {\n+                            let size = bx.layout_of(ty).size;\n+                            bx.atomic_load(args[0].immediate(), order, size)\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n+                    }\n+\n+                    \"store\" => {\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, bx.tcx()).is_some() {\n+                            let size = bx.layout_of(ty).size;\n+                            bx.atomic_store(args[1].immediate(), args[0].immediate(), order, size);\n+                            return;\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n+                    }\n+\n+                    \"fence\" => {\n+                        bx.atomic_fence(order, SynchronizationScope::CrossThread);\n+                        return;\n+                    }\n+\n+                    \"singlethreadfence\" => {\n+                        bx.atomic_fence(order, SynchronizationScope::SingleThread);\n+                        return;\n+                    }\n+\n+                    // These are all AtomicRMW ops\n+                    op => {\n+                        let atom_op = match op {\n+                            \"xchg\" => AtomicRmwBinOp::AtomicXchg,\n+                            \"xadd\" => AtomicRmwBinOp::AtomicAdd,\n+                            \"xsub\" => AtomicRmwBinOp::AtomicSub,\n+                            \"and\" => AtomicRmwBinOp::AtomicAnd,\n+                            \"nand\" => AtomicRmwBinOp::AtomicNand,\n+                            \"or\" => AtomicRmwBinOp::AtomicOr,\n+                            \"xor\" => AtomicRmwBinOp::AtomicXor,\n+                            \"max\" => AtomicRmwBinOp::AtomicMax,\n+                            \"min\" => AtomicRmwBinOp::AtomicMin,\n+                            \"umax\" => AtomicRmwBinOp::AtomicUMax,\n+                            \"umin\" => AtomicRmwBinOp::AtomicUMin,\n+                            _ => bx.sess().fatal(\"unknown atomic operation\"),\n+                        };\n+\n+                        let ty = substs.type_at(0);\n+                        if int_type_width_signed(ty, bx.tcx()).is_some() {\n+                            bx.atomic_rmw(atom_op, args[0].immediate(), args[1].immediate(), order)\n+                        } else {\n+                            return invalid_monomorphization(ty);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            sym::nontemporal_store => {\n+                let dst = args[0].deref(bx.cx());\n+                args[1].val.nontemporal_store(bx, dst);\n+                return;\n+            }\n+\n+            sym::ptr_guaranteed_eq | sym::ptr_guaranteed_ne => {\n+                let a = args[0].immediate();\n+                let b = args[1].immediate();\n+                if name == sym::ptr_guaranteed_eq {\n+                    bx.icmp(IntPredicate::IntEQ, a, b)\n+                } else {\n+                    bx.icmp(IntPredicate::IntNE, a, b)\n+                }\n+            }\n+\n+            sym::ptr_offset_from => {\n+                let ty = substs.type_at(0);\n+                let pointee_size = bx.layout_of(ty).size;\n+\n+                // This is the same sequence that Clang emits for pointer subtraction.\n+                // It can be neither `nsw` nor `nuw` because the input is treated as\n+                // unsigned but then the output is treated as signed, so neither works.\n+                let a = args[0].immediate();\n+                let b = args[1].immediate();\n+                let a = bx.ptrtoint(a, bx.type_isize());\n+                let b = bx.ptrtoint(b, bx.type_isize());\n+                let d = bx.sub(a, b);\n+                let pointee_size = bx.const_usize(pointee_size.bytes());\n+                // this is where the signed magic happens (notice the `s` in `exactsdiv`)\n+                bx.exactsdiv(d, pointee_size)\n+            }\n+\n+            _ => {\n+                // Need to use backend-specific things in the implementation.\n+                bx.codegen_intrinsic_call(instance, fn_abi, args, llresult, span);\n+                return;\n+            }\n+        };\n+\n+        if !fn_abi.ret.is_ignore() {\n+            if let PassMode::Cast(ty) = fn_abi.ret.mode {\n+                let ptr_llty = bx.type_ptr_to(bx.cast_backend_type(&ty));\n+                let ptr = bx.pointercast(result.llval, ptr_llty);\n+                bx.store(llval, ptr, result.align);\n+            } else {\n+                OperandRef::from_immediate_or_packed_pair(bx, llval, result.layout)\n+                    .val\n+                    .store(bx, result);\n+            }\n+        }\n+    }\n+}\n+\n+// Returns the width of an int Ty, and if it's signed or not\n+// Returns None if the type is not an integer\n+// FIXME: there\u2019s multiple of this functions, investigate using some of the already existing\n+// stuffs.\n+fn int_type_width_signed(ty: Ty<'_>, tcx: TyCtxt<'_>) -> Option<(u64, bool)> {\n+    match ty.kind() {\n+        ty::Int(t) => Some((t.bit_width().unwrap_or(u64::from(tcx.sess.target.ptr_width)), true)),\n+        ty::Uint(t) => Some((t.bit_width().unwrap_or(u64::from(tcx.sess.target.ptr_width)), false)),\n+        _ => None,\n+    }\n+}\n+\n+// Returns the width of a float Ty\n+// Returns None if the type is not a float\n+fn float_type_width(ty: Ty<'_>) -> Option<u64> {\n+    match ty.kind() {\n+        ty::Float(t) => Some(t.bit_width()),\n+        _ => None,\n+    }\n+}"}, {"sha": "64d456fb7aa67b8dd6afb816e61d215eb31873a2", "filename": "compiler/rustc_codegen_ssa/src/mir/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_codegen_ssa%2Fsrc%2Fmir%2Fmod.rs?ref=2911b8cb30cf4fed41a6d6dba4fb0076b6a82e93", "patch": "@@ -486,6 +486,7 @@ mod block;\n pub mod constant;\n pub mod coverageinfo;\n pub mod debuginfo;\n+mod intrinsic;\n pub mod operand;\n pub mod place;\n mod rvalue;"}]}