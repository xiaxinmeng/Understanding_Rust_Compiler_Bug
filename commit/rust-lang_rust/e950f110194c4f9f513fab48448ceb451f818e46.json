{"sha": "e950f110194c4f9f513fab48448ceb451f818e46", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU5NTBmMTEwMTk0YzRmOWY1MTNmYWI0ODQ0OGNlYjQ1MWY4MThlNDY=", "commit": {"author": {"name": "Erik Desjardins", "email": "erikdesjardins@users.noreply.github.com", "date": "2021-08-14T18:13:06Z"}, "committer": {"name": "Erik Desjardins", "email": "erikdesjardins@users.noreply.github.com", "date": "2021-08-25T21:49:28Z"}, "message": "put code in a more logical order", "tree": {"sha": "e815f86528e625a14d453a34be88f2c4994d7b47", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e815f86528e625a14d453a34be88f2c4994d7b47"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e950f110194c4f9f513fab48448ceb451f818e46", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e950f110194c4f9f513fab48448ceb451f818e46", "html_url": "https://github.com/rust-lang/rust/commit/e950f110194c4f9f513fab48448ceb451f818e46", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e950f110194c4f9f513fab48448ceb451f818e46/comments", "author": {"login": "erikdesjardins", "id": 7673145, "node_id": "MDQ6VXNlcjc2NzMxNDU=", "avatar_url": "https://avatars.githubusercontent.com/u/7673145?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erikdesjardins", "html_url": "https://github.com/erikdesjardins", "followers_url": "https://api.github.com/users/erikdesjardins/followers", "following_url": "https://api.github.com/users/erikdesjardins/following{/other_user}", "gists_url": "https://api.github.com/users/erikdesjardins/gists{/gist_id}", "starred_url": "https://api.github.com/users/erikdesjardins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erikdesjardins/subscriptions", "organizations_url": "https://api.github.com/users/erikdesjardins/orgs", "repos_url": "https://api.github.com/users/erikdesjardins/repos", "events_url": "https://api.github.com/users/erikdesjardins/events{/privacy}", "received_events_url": "https://api.github.com/users/erikdesjardins/received_events", "type": "User", "site_admin": false}, "committer": {"login": "erikdesjardins", "id": 7673145, "node_id": "MDQ6VXNlcjc2NzMxNDU=", "avatar_url": "https://avatars.githubusercontent.com/u/7673145?v=4", "gravatar_id": "", "url": "https://api.github.com/users/erikdesjardins", "html_url": "https://github.com/erikdesjardins", "followers_url": "https://api.github.com/users/erikdesjardins/followers", "following_url": "https://api.github.com/users/erikdesjardins/following{/other_user}", "gists_url": "https://api.github.com/users/erikdesjardins/gists{/gist_id}", "starred_url": "https://api.github.com/users/erikdesjardins/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/erikdesjardins/subscriptions", "organizations_url": "https://api.github.com/users/erikdesjardins/orgs", "repos_url": "https://api.github.com/users/erikdesjardins/repos", "events_url": "https://api.github.com/users/erikdesjardins/events{/privacy}", "received_events_url": "https://api.github.com/users/erikdesjardins/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5bef23d0fac977c9a57fd2900df3381bbbace86a", "url": "https://api.github.com/repos/rust-lang/rust/commits/5bef23d0fac977c9a57fd2900df3381bbbace86a", "html_url": "https://github.com/rust-lang/rust/commit/5bef23d0fac977c9a57fd2900df3381bbbace86a"}], "stats": {"total": 695, "additions": 350, "deletions": 345}, "files": [{"sha": "27a637f2f4f791cc61e8e5aae471798bd84499d9", "filename": "compiler/rustc_middle/src/mir/interpret/allocation.rs", "status": "modified", "additions": 350, "deletions": 345, "changes": 695, "blob_url": "https://github.com/rust-lang/rust/blob/e950f110194c4f9f513fab48448ceb451f818e46/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e950f110194c4f9f513fab48448ceb451f818e46/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Finterpret%2Fallocation.rs?ref=e950f110194c4f9f513fab48448ceb451f818e46", "patch": "@@ -495,122 +495,6 @@ impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n     }\n }\n \n-/// Uninitialized bytes.\n-impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n-    /// Checks whether the given range  is entirely initialized.\n-    ///\n-    /// Returns `Ok(())` if it's initialized. Otherwise returns the range of byte\n-    /// indexes of the first contiguous uninitialized access.\n-    fn is_init(&self, range: AllocRange) -> Result<(), Range<Size>> {\n-        self.init_mask.is_range_initialized(range.start, range.end()) // `Size` addition\n-    }\n-\n-    /// Checks that a range of bytes is initialized. If not, returns the `InvalidUninitBytes`\n-    /// error which will report the first range of bytes which is uninitialized.\n-    fn check_init(&self, range: AllocRange) -> AllocResult {\n-        self.is_init(range).or_else(|idx_range| {\n-            Err(AllocError::InvalidUninitBytes(Some(UninitBytesAccess {\n-                access_offset: range.start,\n-                access_size: range.size,\n-                uninit_offset: idx_range.start,\n-                uninit_size: idx_range.end - idx_range.start, // `Size` subtraction\n-            })))\n-        })\n-    }\n-\n-    pub fn mark_init(&mut self, range: AllocRange, is_init: bool) {\n-        if range.size.bytes() == 0 {\n-            return;\n-        }\n-        assert!(self.mutability == Mutability::Mut);\n-        self.init_mask.set_range(range.start, range.end(), is_init);\n-    }\n-}\n-\n-/// Run-length encoding of the uninit mask.\n-/// Used to copy parts of a mask multiple times to another allocation.\n-pub struct InitMaskCompressed {\n-    /// Whether the first range is initialized.\n-    initial: bool,\n-    /// The lengths of ranges that are run-length encoded.\n-    /// The initialization state of the ranges alternate starting with `initial`.\n-    ranges: smallvec::SmallVec<[u64; 1]>,\n-}\n-\n-impl InitMaskCompressed {\n-    pub fn no_bytes_init(&self) -> bool {\n-        // The `ranges` are run-length encoded and of alternating initialization state.\n-        // So if `ranges.len() > 1` then the second block is an initialized range.\n-        !self.initial && self.ranges.len() == 1\n-    }\n-}\n-\n-/// Transferring the initialization mask to other allocations.\n-impl<Tag, Extra> Allocation<Tag, Extra> {\n-    /// Creates a run-length encoding of the initialization mask.\n-    ///\n-    /// This is essentially a more space-efficient version of\n-    /// `InitMask::range_as_init_chunks(...).collect::<Vec<_>>()`.\n-    pub fn compress_uninit_range(&self, range: AllocRange) -> InitMaskCompressed {\n-        // Since we are copying `size` bytes from `src` to `dest + i * size` (`for i in 0..repeat`),\n-        // a naive initialization mask copying algorithm would repeatedly have to read the initialization mask from\n-        // the source and write it to the destination. Even if we optimized the memory accesses,\n-        // we'd be doing all of this `repeat` times.\n-        // Therefore we precompute a compressed version of the initialization mask of the source value and\n-        // then write it back `repeat` times without computing any more information from the source.\n-\n-        // A precomputed cache for ranges of initialized / uninitialized bits\n-        // 0000010010001110 will become\n-        // `[5, 1, 2, 1, 3, 3, 1]`,\n-        // where each element toggles the state.\n-\n-        let mut ranges = smallvec::SmallVec::<[u64; 1]>::new();\n-        let initial = self.init_mask.get(range.start);\n-\n-        for chunk in self.init_mask.range_as_init_chunks(range.start, range.end()) {\n-            let len = chunk.range().end.bytes() - chunk.range().start.bytes();\n-            ranges.push(len);\n-        }\n-\n-        InitMaskCompressed { ranges, initial }\n-    }\n-\n-    /// Applies multiple instances of the run-length encoding to the initialization mask.\n-    pub fn mark_compressed_init_range(\n-        &mut self,\n-        defined: &InitMaskCompressed,\n-        range: AllocRange,\n-        repeat: u64,\n-    ) {\n-        // An optimization where we can just overwrite an entire range of initialization\n-        // bits if they are going to be uniformly `1` or `0`.\n-        if defined.ranges.len() <= 1 {\n-            self.init_mask.set_range_inbounds(\n-                range.start,\n-                range.start + range.size * repeat, // `Size` operations\n-                defined.initial,\n-            );\n-            return;\n-        }\n-\n-        for mut j in 0..repeat {\n-            j *= range.size.bytes();\n-            j += range.start.bytes();\n-            let mut cur = defined.initial;\n-            for range in &defined.ranges {\n-                let old_j = j;\n-                j += range;\n-                self.init_mask.set_range_inbounds(\n-                    Size::from_bytes(old_j),\n-                    Size::from_bytes(j),\n-                    cur,\n-                );\n-                cur = !cur;\n-            }\n-        }\n-    }\n-}\n-\n /// \"Relocations\" stores the provenance information of pointers stored in memory.\n #[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug, TyEncodable, TyDecodable)]\n pub struct Relocations<Tag = AllocId>(SortedMap<Size, Tag>);\n@@ -697,44 +581,25 @@ pub struct InitMask {\n impl InitMask {\n     pub const BLOCK_SIZE: u64 = 64;\n \n-    pub fn new(size: Size, state: bool) -> Self {\n-        let mut m = InitMask { blocks: vec![], len: Size::ZERO };\n-        m.grow(size, state);\n-        m\n+    #[inline]\n+    fn bit_index(bits: Size) -> (usize, usize) {\n+        let bits = bits.bytes();\n+        let a = bits / InitMask::BLOCK_SIZE;\n+        let b = bits % InitMask::BLOCK_SIZE;\n+        (usize::try_from(a).unwrap(), usize::try_from(b).unwrap())\n     }\n \n-    /// Checks whether the range `start..end` (end-exclusive) is entirely initialized.\n-    ///\n-    /// Returns `Ok(())` if it's initialized. Otherwise returns a range of byte\n-    /// indexes for the first contiguous span of the uninitialized access.\n     #[inline]\n-    pub fn is_range_initialized(&self, start: Size, end: Size) -> Result<(), Range<Size>> {\n-        if end > self.len {\n-            return Err(self.len..end);\n-        }\n-\n-        let uninit_start = find_bit(self, start, end, false);\n-\n-        match uninit_start {\n-            Some(uninit_start) => {\n-                let uninit_end = find_bit(self, uninit_start, end, true).unwrap_or(end);\n-                Err(uninit_start..uninit_end)\n-            }\n-            None => Ok(()),\n-        }\n+    fn size_from_bit_index(block: impl TryInto<u64>, bit: impl TryInto<u64>) -> Size {\n+        let block = block.try_into().ok().unwrap();\n+        let bit = bit.try_into().ok().unwrap();\n+        Size::from_bytes(block * InitMask::BLOCK_SIZE + bit)\n     }\n \n-    /// Returns an iterator, yielding a range of byte indexes for each contiguous region\n-    /// of initialized or uninitialized bytes inside the range `start..end` (end-exclusive).\n-    ///\n-    /// The iterator guarantees the following:\n-    /// - Chunks are nonempty.\n-    /// - Chunks are adjacent (each range's start is equal to the previous range's end).\n-    /// - Chunks span exactly `start..end` (the first starts at `start`, the last ends at `end`).\n-    /// - Chunks alternate between [`InitChunk::Init`] and [`InitChunk::Uninit`].\n-    #[inline]\n-    pub fn range_as_init_chunks(&self, start: Size, end: Size) -> InitChunkIter<'_> {\n-        InitChunkIter::new(self, start, end)\n+    pub fn new(size: Size, state: bool) -> Self {\n+        let mut m = InitMask { blocks: vec![], len: Size::ZERO };\n+        m.grow(size, state);\n+        m\n     }\n \n     pub fn set_range(&mut self, start: Size, end: Size, new_state: bool) {\n@@ -746,8 +611,8 @@ impl InitMask {\n     }\n \n     pub fn set_range_inbounds(&mut self, start: Size, end: Size, new_state: bool) {\n-        let (blocka, bita) = bit_index(start);\n-        let (blockb, bitb) = bit_index(end);\n+        let (blocka, bita) = Self::bit_index(start);\n+        let (blockb, bitb) = Self::bit_index(end);\n         if blocka == blockb {\n             // First set all bits except the first `bita`,\n             // then unset the last `64 - bitb` bits.\n@@ -791,13 +656,13 @@ impl InitMask {\n \n     #[inline]\n     pub fn get(&self, i: Size) -> bool {\n-        let (block, bit) = bit_index(i);\n+        let (block, bit) = Self::bit_index(i);\n         (self.blocks[block] & (1 << bit)) != 0\n     }\n \n     #[inline]\n     pub fn set(&mut self, i: Size, new_state: bool) {\n-        let (block, bit) = bit_index(i);\n+        let (block, bit) = Self::bit_index(i);\n         self.set_bit(block, bit, new_state);\n     }\n \n@@ -827,6 +692,195 @@ impl InitMask {\n         self.len += amount;\n         self.set_range_inbounds(start, start + amount, new_state); // `Size` operation\n     }\n+\n+    /// Returns the index of the first bit in `start..end` (end-exclusive) that is equal to is_init.\n+    fn find_bit(&self, start: Size, end: Size, is_init: bool) -> Option<Size> {\n+        /// A fast implementation of `find_bit`,\n+        /// which skips over an entire block at a time if it's all 0s (resp. 1s),\n+        /// and finds the first 1 (resp. 0) bit inside a block using `trailing_zeros` instead of a loop.\n+        ///\n+        /// Note that all examples below are written with 8 (instead of 64) bit blocks for simplicity,\n+        /// and with the least significant bit (and lowest block) first:\n+        ///\n+        ///          00000000|00000000\n+        ///          ^      ^ ^      ^\n+        ///   index: 0      7 8      15\n+        ///\n+        /// Also, if not stated, assume that `is_init = true`, that is, we are searching for the first 1 bit.\n+        fn find_bit_fast(\n+            init_mask: &InitMask,\n+            start: Size,\n+            end: Size,\n+            is_init: bool,\n+        ) -> Option<Size> {\n+            /// Search one block, returning the index of the first bit equal to `is_init`.\n+            fn search_block(\n+                bits: Block,\n+                block: usize,\n+                start_bit: usize,\n+                is_init: bool,\n+            ) -> Option<Size> {\n+                // For the following examples, assume this function was called with:\n+                //   bits = 11011100\n+                //   start_bit = 3\n+                //   is_init = false\n+                // Note again that the least significant bit is written first,\n+                // which is backwards compared to how we normally write numbers.\n+\n+                // Invert bits so we're always looking for the first set bit.\n+                //        ! 11011100\n+                //   bits = 00100011\n+                let bits = if is_init { bits } else { !bits };\n+                // Mask off unused start bits.\n+                //          00100011\n+                //        & 00011111\n+                //   bits = 00000011\n+                let bits = bits & (!0 << start_bit);\n+                // Find set bit, if any.\n+                //   bit = trailing_zeros(00000011)\n+                //   bit = 6\n+                if bits == 0 {\n+                    None\n+                } else {\n+                    let bit = bits.trailing_zeros();\n+                    Some(InitMask::size_from_bit_index(block, bit))\n+                }\n+            }\n+\n+            if start >= end {\n+                return None;\n+            }\n+\n+            // Convert `start` and `end` to block indexes and bit indexes within each block.\n+            // We must convert `end` to an inclusive bound to handle block boundaries correctly.\n+            //\n+            // For example:\n+            //\n+            //   (a) 00000000|00000000    (b) 00000000|\n+            //       ^~~~~~~~~~~^             ^~~~~~~~~^\n+            //     start       end          start     end\n+            //\n+            // In both cases, the block index of `end` is 1.\n+            // But we do want to search block 1 in (a), and we don't in (b).\n+            //\n+            // If we subtract 1 from both end positions to make them inclusive:\n+            //\n+            //   (a) 00000000|00000000    (b) 00000000|\n+            //       ^~~~~~~~~~^              ^~~~~~~^\n+            //     start    end_inclusive   start end_inclusive\n+            //\n+            // For (a), the block index of `end_inclusive` is 1, and for (b), it's 0.\n+            // This provides the desired behavior of searching blocks 0 and 1 for (a),\n+            // and searching only block 0 for (b).\n+            let (start_block, start_bit) = InitMask::bit_index(start);\n+            let end_inclusive = Size::from_bytes(end.bytes() - 1);\n+            let (end_block_inclusive, _) = InitMask::bit_index(end_inclusive);\n+\n+            // Handle first block: need to skip `start_bit` bits.\n+            //\n+            // We need to handle the first block separately,\n+            // because there may be bits earlier in the block that should be ignored,\n+            // such as the bit marked (1) in this example:\n+            //\n+            //       (1)\n+            //       -|------\n+            //   (c) 01000000|00000000|00000001\n+            //          ^~~~~~~~~~~~~~~~~~^\n+            //        start              end\n+            if let Some(i) =\n+                search_block(init_mask.blocks[start_block], start_block, start_bit, is_init)\n+            {\n+                // If the range is less than a block, we may find a matching bit after `end`.\n+                //\n+                // For example, we shouldn't successfully find bit (2), because it's after `end`:\n+                //\n+                //             (2)\n+                //       -------|\n+                //   (d) 00000001|00000000|00000001\n+                //        ^~~~~^\n+                //      start end\n+                //\n+                // An alternative would be to mask off end bits in the same way as we do for start bits,\n+                // but performing this check afterwards is faster and simpler to implement.\n+                if i < end {\n+                    return Some(i);\n+                } else {\n+                    return None;\n+                }\n+            }\n+\n+            // Handle remaining blocks.\n+            //\n+            // We can skip over an entire block at once if it's all 0s (resp. 1s).\n+            // The block marked (3) in this example is the first block that will be handled by this loop,\n+            // and it will be skipped for that reason:\n+            //\n+            //                   (3)\n+            //                --------\n+            //   (e) 01000000|00000000|00000001\n+            //          ^~~~~~~~~~~~~~~~~~^\n+            //        start              end\n+            if start_block < end_block_inclusive {\n+                // This loop is written in a specific way for performance.\n+                // Notably: `..end_block_inclusive + 1` is used for an inclusive range instead of `..=end_block_inclusive`,\n+                // and `.zip(start_block + 1..)` is used to track the index instead of `.enumerate().skip().take()`,\n+                // because both alternatives result in significantly worse codegen.\n+                // `end_block_inclusive + 1` is guaranteed not to wrap, because `end_block_inclusive <= end / BLOCK_SIZE`,\n+                // and `BLOCK_SIZE` (the number of bits per block) will always be at least 8 (1 byte).\n+                for (&bits, block) in init_mask.blocks[start_block + 1..end_block_inclusive + 1]\n+                    .iter()\n+                    .zip(start_block + 1..)\n+                {\n+                    if let Some(i) = search_block(bits, block, 0, is_init) {\n+                        // If this is the last block, we may find a matching bit after `end`.\n+                        //\n+                        // For example, we shouldn't successfully find bit (4), because it's after `end`:\n+                        //\n+                        //                               (4)\n+                        //                         -------|\n+                        //   (f) 00000001|00000000|00000001\n+                        //          ^~~~~~~~~~~~~~~~~~^\n+                        //        start              end\n+                        //\n+                        // As above with example (d), we could handle the end block separately and mask off end bits,\n+                        // but unconditionally searching an entire block at once and performing this check afterwards\n+                        // is faster and much simpler to implement.\n+                        if i < end {\n+                            return Some(i);\n+                        } else {\n+                            return None;\n+                        }\n+                    }\n+                }\n+            }\n+\n+            None\n+        }\n+\n+        #[cfg_attr(not(debug_assertions), allow(dead_code))]\n+        fn find_bit_slow(\n+            init_mask: &InitMask,\n+            start: Size,\n+            end: Size,\n+            is_init: bool,\n+        ) -> Option<Size> {\n+            (start..end).find(|&i| init_mask.get(i) == is_init)\n+        }\n+\n+        let result = find_bit_fast(self, start, end, is_init);\n+\n+        debug_assert_eq!(\n+            result,\n+            find_bit_slow(self, start, end, is_init),\n+            \"optimized implementation of find_bit is wrong for start={:?} end={:?} is_init={} init_mask={:#?}\",\n+            start,\n+            end,\n+            is_init,\n+            self\n+        );\n+\n+        result\n+    }\n }\n \n /// A contiguous chunk of initialized or uninitialized memory.\n@@ -845,29 +899,58 @@ impl InitChunk {\n     }\n }\n \n+impl InitMask {\n+    /// Checks whether the range `start..end` (end-exclusive) is entirely initialized.\n+    ///\n+    /// Returns `Ok(())` if it's initialized. Otherwise returns a range of byte\n+    /// indexes for the first contiguous span of the uninitialized access.\n+    #[inline]\n+    pub fn is_range_initialized(&self, start: Size, end: Size) -> Result<(), Range<Size>> {\n+        if end > self.len {\n+            return Err(self.len..end);\n+        }\n+\n+        let uninit_start = self.find_bit(start, end, false);\n+\n+        match uninit_start {\n+            Some(uninit_start) => {\n+                let uninit_end = self.find_bit(uninit_start, end, true).unwrap_or(end);\n+                Err(uninit_start..uninit_end)\n+            }\n+            None => Ok(()),\n+        }\n+    }\n+\n+    /// Returns an iterator, yielding a range of byte indexes for each contiguous region\n+    /// of initialized or uninitialized bytes inside the range `start..end` (end-exclusive).\n+    ///\n+    /// The iterator guarantees the following:\n+    /// - Chunks are nonempty.\n+    /// - Chunks are adjacent (each range's start is equal to the previous range's end).\n+    /// - Chunks span exactly `start..end` (the first starts at `start`, the last ends at `end`).\n+    /// - Chunks alternate between [`InitChunk::Init`] and [`InitChunk::Uninit`].\n+    #[inline]\n+    pub fn range_as_init_chunks(&self, start: Size, end: Size) -> InitChunkIter<'_> {\n+        assert!(end <= self.len);\n+\n+        let is_init = if start < end { self.get(start) } else { false };\n+\n+        InitChunkIter { init_mask: self, is_init, start, end }\n+    }\n+}\n+\n /// Yields [`InitChunk`]s. See [`InitMask::range_as_init_chunks`].\n pub struct InitChunkIter<'a> {\n     init_mask: &'a InitMask,\n     /// Whether the next chunk we will return is initialized.\n+    /// If there are no more chunks, contains some arbitrary value.\n     is_init: bool,\n     /// The current byte index into `init_mask`.\n     start: Size,\n     /// The end byte index into `init_mask`.\n     end: Size,\n }\n \n-impl<'a> InitChunkIter<'a> {\n-    #[inline]\n-    fn new(init_mask: &'a InitMask, start: Size, end: Size) -> Self {\n-        assert!(start <= end);\n-        assert!(end <= init_mask.len);\n-\n-        let is_init = if start < end { init_mask.get(start) } else { false };\n-\n-        Self { init_mask, is_init, start, end }\n-    }\n-}\n-\n impl<'a> Iterator for InitChunkIter<'a> {\n     type Item = InitChunk;\n \n@@ -878,7 +961,7 @@ impl<'a> Iterator for InitChunkIter<'a> {\n         }\n \n         let end_of_chunk =\n-            find_bit(&self.init_mask, self.start, self.end, !self.is_init).unwrap_or(self.end);\n+            self.init_mask.find_bit(self.start, self.end, !self.is_init).unwrap_or(self.end);\n         let range = self.start..end_of_chunk;\n \n         let ret =\n@@ -891,196 +974,118 @@ impl<'a> Iterator for InitChunkIter<'a> {\n     }\n }\n \n-/// Returns the index of the first bit in `start..end` (end-exclusive) that is equal to is_init.\n-fn find_bit(init_mask: &InitMask, start: Size, end: Size, is_init: bool) -> Option<Size> {\n-    /// A fast implementation of `find_bit`,\n-    /// which skips over an entire block at a time if it's all 0s (resp. 1s),\n-    /// and finds the first 1 (resp. 0) bit inside a block using `trailing_zeros` instead of a loop.\n-    ///\n-    /// Note that all examples below are written with 8 (instead of 64) bit blocks for simplicity,\n-    /// and with the least significant bit (and lowest block) first:\n-    ///\n-    ///          00000000|00000000\n-    ///          ^      ^ ^      ^\n-    ///   index: 0      7 8      15\n+/// Uninitialized bytes.\n+impl<Tag: Copy, Extra> Allocation<Tag, Extra> {\n+    /// Checks whether the given range  is entirely initialized.\n     ///\n-    /// Also, if not stated, assume that `is_init = true`, that is, we are searching for the first 1 bit.\n-    fn find_bit_fast(init_mask: &InitMask, start: Size, end: Size, is_init: bool) -> Option<Size> {\n-        /// Search one block, returning the index of the first bit equal to `is_init`.\n-        fn search_block(\n-            bits: Block,\n-            block: usize,\n-            start_bit: usize,\n-            is_init: bool,\n-        ) -> Option<Size> {\n-            // For the following examples, assume this function was called with:\n-            //   bits = 11011100\n-            //   start_bit = 3\n-            //   is_init = false\n-            // Note again that the least significant bit is written first,\n-            // which is backwards compared to how we normally write numbers.\n-\n-            // Invert bits so we're always looking for the first set bit.\n-            //        ! 11011100\n-            //   bits = 00100011\n-            let bits = if is_init { bits } else { !bits };\n-            // Mask off unused start bits.\n-            //          00100011\n-            //        & 00011111\n-            //   bits = 00000011\n-            let bits = bits & (!0 << start_bit);\n-            // Find set bit, if any.\n-            //   bit = trailing_zeros(00000011)\n-            //   bit = 6\n-            if bits == 0 {\n-                None\n-            } else {\n-                let bit = bits.trailing_zeros();\n-                Some(size_from_bit_index(block, bit))\n-            }\n-        }\n+    /// Returns `Ok(())` if it's initialized. Otherwise returns the range of byte\n+    /// indexes of the first contiguous uninitialized access.\n+    fn is_init(&self, range: AllocRange) -> Result<(), Range<Size>> {\n+        self.init_mask.is_range_initialized(range.start, range.end()) // `Size` addition\n+    }\n \n-        if start >= end {\n-            return None;\n-        }\n+    /// Checks that a range of bytes is initialized. If not, returns the `InvalidUninitBytes`\n+    /// error which will report the first range of bytes which is uninitialized.\n+    fn check_init(&self, range: AllocRange) -> AllocResult {\n+        self.is_init(range).or_else(|idx_range| {\n+            Err(AllocError::InvalidUninitBytes(Some(UninitBytesAccess {\n+                access_offset: range.start,\n+                access_size: range.size,\n+                uninit_offset: idx_range.start,\n+                uninit_size: idx_range.end - idx_range.start, // `Size` subtraction\n+            })))\n+        })\n+    }\n \n-        // Convert `start` and `end` to block indexes and bit indexes within each block.\n-        // We must convert `end` to an inclusive bound to handle block boundaries correctly.\n-        //\n-        // For example:\n-        //\n-        //   (a) 00000000|00000000    (b) 00000000|\n-        //       ^~~~~~~~~~~^             ^~~~~~~~~^\n-        //     start       end          start     end\n-        //\n-        // In both cases, the block index of `end` is 1.\n-        // But we do want to search block 1 in (a), and we don't in (b).\n-        //\n-        // If we subtract 1 from both end positions to make them inclusive:\n-        //\n-        //   (a) 00000000|00000000    (b) 00000000|\n-        //       ^~~~~~~~~~^              ^~~~~~~^\n-        //     start    end_inclusive   start end_inclusive\n-        //\n-        // For (a), the block index of `end_inclusive` is 1, and for (b), it's 0.\n-        // This provides the desired behavior of searching blocks 0 and 1 for (a),\n-        // and searching only block 0 for (b).\n-        let (start_block, start_bit) = bit_index(start);\n-        let end_inclusive = Size::from_bytes(end.bytes() - 1);\n-        let (end_block_inclusive, _) = bit_index(end_inclusive);\n-\n-        // Handle first block: need to skip `start_bit` bits.\n-        //\n-        // We need to handle the first block separately,\n-        // because there may be bits earlier in the block that should be ignored,\n-        // such as the bit marked (1) in this example:\n-        //\n-        //       (1)\n-        //       -|------\n-        //   (c) 01000000|00000000|00000001\n-        //          ^~~~~~~~~~~~~~~~~~^\n-        //        start              end\n-        if let Some(i) =\n-            search_block(init_mask.blocks[start_block], start_block, start_bit, is_init)\n-        {\n-            if i < end {\n-                return Some(i);\n-            } else {\n-                // If the range is less than a block, we may find a matching bit after `end`.\n-                //\n-                // For example, we shouldn't successfully find bit (2), because it's after `end`:\n-                //\n-                //             (2)\n-                //       -------|\n-                //   (d) 00000001|00000000|00000001\n-                //        ^~~~~^\n-                //      start end\n-                //\n-                // An alternative would be to mask off end bits in the same way as we do for start bits,\n-                // but performing this check afterwards is faster and simpler to implement.\n-                return None;\n-            }\n+    pub fn mark_init(&mut self, range: AllocRange, is_init: bool) {\n+        if range.size.bytes() == 0 {\n+            return;\n         }\n+        assert!(self.mutability == Mutability::Mut);\n+        self.init_mask.set_range(range.start, range.end(), is_init);\n+    }\n+}\n \n-        // Handle remaining blocks.\n-        //\n-        // We can skip over an entire block at once if it's all 0s (resp. 1s).\n-        // The block marked (3) in this example is the first block that will be handled by this loop,\n-        // and it will be skipped for that reason:\n-        //\n-        //                   (3)\n-        //                --------\n-        //   (e) 01000000|00000000|00000001\n-        //          ^~~~~~~~~~~~~~~~~~^\n-        //        start              end\n-        if start_block < end_block_inclusive {\n-            // This loop is written in a specific way for performance.\n-            // Notably: `..end_block_inclusive + 1` is used for an inclusive range instead of `..=end_block_inclusive`,\n-            // and `.zip(start_block + 1..)` is used to track the index instead of `.enumerate().skip().take()`,\n-            // because both alternatives result in significantly worse codegen.\n-            // `end_block_inclusive + 1` is guaranteed not to wrap, because `end_block_inclusive <= end / BLOCK_SIZE`,\n-            // and `BLOCK_SIZE` (the number of bits per block) will always be at least 8 (1 byte).\n-            for (&bits, block) in init_mask.blocks[start_block + 1..end_block_inclusive + 1]\n-                .iter()\n-                .zip(start_block + 1..)\n-            {\n-                if let Some(i) = search_block(bits, block, 0, is_init) {\n-                    if i < end {\n-                        return Some(i);\n-                    } else {\n-                        // If this is the last block, we may find a matching bit after `end`.\n-                        //\n-                        // For example, we shouldn't successfully find bit (4), because it's after `end`:\n-                        //\n-                        //                               (4)\n-                        //                         -------|\n-                        //   (f) 00000001|00000000|00000001\n-                        //          ^~~~~~~~~~~~~~~~~~^\n-                        //        start              end\n-                        //\n-                        // As above with example (d), we could handle the end block separately and mask off end bits,\n-                        // but unconditionally searching an entire block at once and performing this check afterwards\n-                        // is faster and much simpler to implement.\n-                        return None;\n-                    }\n-                }\n-            }\n-        }\n+/// Run-length encoding of the uninit mask.\n+/// Used to copy parts of a mask multiple times to another allocation.\n+pub struct InitMaskCompressed {\n+    /// Whether the first range is initialized.\n+    initial: bool,\n+    /// The lengths of ranges that are run-length encoded.\n+    /// The initialization state of the ranges alternate starting with `initial`.\n+    ranges: smallvec::SmallVec<[u64; 1]>,\n+}\n \n-        None\n+impl InitMaskCompressed {\n+    pub fn no_bytes_init(&self) -> bool {\n+        // The `ranges` are run-length encoded and of alternating initialization state.\n+        // So if `ranges.len() > 1` then the second block is an initialized range.\n+        !self.initial && self.ranges.len() == 1\n     }\n+}\n \n-    #[cfg_attr(not(debug_assertions), allow(dead_code))]\n-    fn find_bit_slow(init_mask: &InitMask, start: Size, end: Size, is_init: bool) -> Option<Size> {\n-        (start..end).find(|&i| init_mask.get(i) == is_init)\n-    }\n+/// Transferring the initialization mask to other allocations.\n+impl<Tag, Extra> Allocation<Tag, Extra> {\n+    /// Creates a run-length encoding of the initialization mask.\n+    ///\n+    /// This is essentially a more space-efficient version of\n+    /// `InitMask::range_as_init_chunks(...).collect::<Vec<_>>()`.\n+    pub fn compress_uninit_range(&self, range: AllocRange) -> InitMaskCompressed {\n+        // Since we are copying `size` bytes from `src` to `dest + i * size` (`for i in 0..repeat`),\n+        // a naive initialization mask copying algorithm would repeatedly have to read the initialization mask from\n+        // the source and write it to the destination. Even if we optimized the memory accesses,\n+        // we'd be doing all of this `repeat` times.\n+        // Therefore we precompute a compressed version of the initialization mask of the source value and\n+        // then write it back `repeat` times without computing any more information from the source.\n \n-    let result = find_bit_fast(init_mask, start, end, is_init);\n+        // A precomputed cache for ranges of initialized / uninitialized bits\n+        // 0000010010001110 will become\n+        // `[5, 1, 2, 1, 3, 3, 1]`,\n+        // where each element toggles the state.\n \n-    debug_assert_eq!(\n-        result,\n-        find_bit_slow(init_mask, start, end, is_init),\n-        \"optimized implementation of find_bit is wrong for start={:?} end={:?} is_init={} init_mask={:#?}\",\n-        start,\n-        end,\n-        is_init,\n-        init_mask\n-    );\n+        let mut ranges = smallvec::SmallVec::<[u64; 1]>::new();\n+        let initial = self.init_mask.get(range.start);\n \n-    result\n-}\n+        for chunk in self.init_mask.range_as_init_chunks(range.start, range.end()) {\n+            let len = chunk.range().end.bytes() - chunk.range().start.bytes();\n+            ranges.push(len);\n+        }\n \n-#[inline]\n-fn bit_index(bits: Size) -> (usize, usize) {\n-    let bits = bits.bytes();\n-    let a = bits / InitMask::BLOCK_SIZE;\n-    let b = bits % InitMask::BLOCK_SIZE;\n-    (usize::try_from(a).unwrap(), usize::try_from(b).unwrap())\n-}\n+        InitMaskCompressed { ranges, initial }\n+    }\n+\n+    /// Applies multiple instances of the run-length encoding to the initialization mask.\n+    pub fn mark_compressed_init_range(\n+        &mut self,\n+        defined: &InitMaskCompressed,\n+        range: AllocRange,\n+        repeat: u64,\n+    ) {\n+        // An optimization where we can just overwrite an entire range of initialization\n+        // bits if they are going to be uniformly `1` or `0`.\n+        if defined.ranges.len() <= 1 {\n+            self.init_mask.set_range_inbounds(\n+                range.start,\n+                range.start + range.size * repeat, // `Size` operations\n+                defined.initial,\n+            );\n+            return;\n+        }\n \n-#[inline]\n-fn size_from_bit_index(block: impl TryInto<u64>, bit: impl TryInto<u64>) -> Size {\n-    let block = block.try_into().ok().unwrap();\n-    let bit = bit.try_into().ok().unwrap();\n-    Size::from_bytes(block * InitMask::BLOCK_SIZE + bit)\n+        for mut j in 0..repeat {\n+            j *= range.size.bytes();\n+            j += range.start.bytes();\n+            let mut cur = defined.initial;\n+            for range in &defined.ranges {\n+                let old_j = j;\n+                j += range;\n+                self.init_mask.set_range_inbounds(\n+                    Size::from_bytes(old_j),\n+                    Size::from_bytes(j),\n+                    cur,\n+                );\n+                cur = !cur;\n+            }\n+        }\n+    }\n }"}]}