{"sha": "d2ef1b318d72909d029910389abeabbf13547f01", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQyZWYxYjMxOGQ3MjkwOWQwMjk5MTAzODlhYmVhYmJmMTM1NDdmMDE=", "commit": {"author": {"name": "mcarton", "email": "cartonmartin+git@gmail.com", "date": "2017-05-28T22:12:43Z"}, "committer": {"name": "mcarton", "email": "cartonmartin+git@gmail.com", "date": "2017-06-17T16:23:37Z"}, "message": "Rewrite `doc_markdown` to use `pulldown-cmark`", "tree": {"sha": "2e645790329a4e6701fb5b05406ca054a67995f4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2e645790329a4e6701fb5b05406ca054a67995f4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d2ef1b318d72909d029910389abeabbf13547f01", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d2ef1b318d72909d029910389abeabbf13547f01", "html_url": "https://github.com/rust-lang/rust/commit/d2ef1b318d72909d029910389abeabbf13547f01", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d2ef1b318d72909d029910389abeabbf13547f01/comments", "author": {"login": "mcarton", "id": 3751788, "node_id": "MDQ6VXNlcjM3NTE3ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/3751788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarton", "html_url": "https://github.com/mcarton", "followers_url": "https://api.github.com/users/mcarton/followers", "following_url": "https://api.github.com/users/mcarton/following{/other_user}", "gists_url": "https://api.github.com/users/mcarton/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarton/subscriptions", "organizations_url": "https://api.github.com/users/mcarton/orgs", "repos_url": "https://api.github.com/users/mcarton/repos", "events_url": "https://api.github.com/users/mcarton/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mcarton", "id": 3751788, "node_id": "MDQ6VXNlcjM3NTE3ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/3751788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarton", "html_url": "https://github.com/mcarton", "followers_url": "https://api.github.com/users/mcarton/followers", "following_url": "https://api.github.com/users/mcarton/following{/other_user}", "gists_url": "https://api.github.com/users/mcarton/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarton/subscriptions", "organizations_url": "https://api.github.com/users/mcarton/orgs", "repos_url": "https://api.github.com/users/mcarton/repos", "events_url": "https://api.github.com/users/mcarton/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "9c9ad3e2810282441de85ed9d19afed7f4b03292", "url": "https://api.github.com/repos/rust-lang/rust/commits/9c9ad3e2810282441de85ed9d19afed7f4b03292", "html_url": "https://github.com/rust-lang/rust/commit/9c9ad3e2810282441de85ed9d19afed7f4b03292"}], "stats": {"total": 395, "additions": 110, "deletions": 285}, "files": [{"sha": "b8f80bb3081fb81d80ae27bced2fe1ffcdcd3441", "filename": "clippy_lints/src/doc.rs", "status": "modified", "additions": 110, "deletions": 285, "changes": 395, "blob_url": "https://github.com/rust-lang/rust/blob/d2ef1b318d72909d029910389abeabbf13547f01/clippy_lints%2Fsrc%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d2ef1b318d72909d029910389abeabbf13547f01/clippy_lints%2Fsrc%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_lints%2Fsrc%2Fdoc.rs?ref=d2ef1b318d72909d029910389abeabbf13547f01", "patch": "@@ -1,3 +1,5 @@\n+use itertools::Itertools;\n+use pulldown_cmark;\n use rustc::lint::*;\n use syntax::ast;\n use syntax::codemap::{Span, BytePos};\n@@ -53,324 +55,156 @@ impl EarlyLintPass for Doc {\n     }\n }\n \n+struct Parser<'a> {\n+    parser: pulldown_cmark::Parser<'a>,\n+}\n+\n+impl<'a> Parser<'a> {\n+    fn new(parser: pulldown_cmark::Parser<'a>) -> Parser<'a> {\n+        Self { parser }\n+    }\n+}\n+\n+impl<'a> Iterator for Parser<'a> {\n+    type Item = (usize, pulldown_cmark::Event<'a>);\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        let offset = self.parser.get_offset();\n+        self.parser.next().map(|event| (offset, event))\n+    }\n+}\n+\n /// Cleanup documentation decoration (`///` and such).\n ///\n /// We can't use `syntax::attr::AttributeMethods::with_desugared_doc` or\n /// `syntax::parse::lexer::comments::strip_doc_comment_decoration` because we need to keep track of\n-/// the span but this function is inspired from the later.\n+/// the spans but this function is inspired from the later.\n #[allow(cast_possible_truncation)]\n-pub fn strip_doc_comment_decoration((comment, span): (String, Span)) -> Vec<(String, Span)> {\n+pub fn strip_doc_comment_decoration(comment: String, span: Span) -> (String, Vec<(usize, Span)>) {\n     // one-line comments lose their prefix\n     const ONELINERS: &'static [&'static str] = &[\"///!\", \"///\", \"//!\", \"//\"];\n     for prefix in ONELINERS {\n         if comment.starts_with(*prefix) {\n-            return vec![(comment[prefix.len()..].to_owned(),\n-                         Span { lo: span.lo + BytePos(prefix.len() as u32), ..span })];\n+            let doc = &comment[prefix.len()..];\n+            let mut doc = doc.to_owned();\n+            doc.push('\\n');\n+            return (\n+                doc.to_owned(),\n+                vec![(doc.len(), Span { lo: span.lo + BytePos(prefix.len() as u32), ..span })]\n+            );\n         }\n     }\n \n     if comment.starts_with(\"/*\") {\n-        return comment[3..comment.len() - 2]\n-            .lines()\n-            .map(|line| {\n-                let offset = line.as_ptr() as usize - comment.as_ptr() as usize;\n-                debug_assert_eq!(offset as u32 as usize, offset);\n-\n-                (line.to_owned(), Span { lo: span.lo + BytePos(offset as u32), ..span })\n-            })\n-            .collect();\n+        let doc = &comment[3..comment.len() - 2];\n+        let mut sizes = vec![];\n+\n+        for line in doc.lines() {\n+            let offset = line.as_ptr() as usize - comment.as_ptr() as usize;\n+            debug_assert_eq!(offset as u32 as usize, offset);\n+\n+            sizes.push((line.len(), Span { lo: span.lo + BytePos(offset as u32), ..span }));\n+        }\n+\n+        return (doc.to_string(), sizes);\n     }\n \n     panic!(\"not a doc-comment: {}\", comment);\n }\n \n pub fn check_attrs<'a>(cx: &EarlyContext, valid_idents: &[String], attrs: &'a [ast::Attribute]) {\n-    let mut docs = vec![];\n+    let mut doc = String::new();\n+    let mut spans = vec![];\n \n     for attr in attrs {\n         if attr.is_sugared_doc {\n-            if let Some(ref doc) = attr.value_str() {\n-                let doc = doc.to_string();\n-                docs.extend_from_slice(&strip_doc_comment_decoration((doc, attr.span)));\n+            if let Some(ref current) = attr.value_str() {\n+                let current = current.to_string();\n+                let (current, current_spans) = strip_doc_comment_decoration(current, attr.span);\n+                spans.extend_from_slice(&current_spans);\n+                doc.push_str(&current);\n             }\n         }\n     }\n \n-    if !docs.is_empty() {\n-        let _ = check_doc(cx, valid_idents, &docs);\n-    }\n-}\n-\n-#[allow(while_let_loop)] // #362\n-fn check_doc(cx: &EarlyContext, valid_idents: &[String], docs: &[(String, Span)]) -> Result<(), ()> {\n-    // In markdown, `_` can be used to emphasize something, or, is a raw `_` depending on context.\n-    // There really is no markdown specification that would disambiguate this properly. This is\n-    // what GitHub and Rustdoc do:\n-    //\n-    // foo_bar test_quz    \u2192 foo_bar test_quz\n-    // foo_bar_baz         \u2192 foo_bar_baz (note that the \u201cofficial\u201d spec says this should be emphasized)\n-    // _foo bar_ test_quz_ \u2192 <em>foo bar</em> test_quz_\n-    // \\_foo bar\\_         \u2192 _foo bar_\n-    // (_baz_)             \u2192 (<em>baz</em>)\n-    // foo _ bar _ baz     \u2192 foo _ bar _ baz\n-\n-    /// Character that can appear in a path\n-    fn is_path_char(c: char) -> bool {\n-        match c {\n-            t if t.is_alphanumeric() => true,\n-            ':' | '_' => true,\n-            _ => false,\n-        }\n-    }\n-\n-    #[derive(Clone, Debug)]\n-    /// This type is used to iterate through the documentation characters, keeping the span at the\n-    /// same time.\n-    struct Parser<'a> {\n-        /// First byte of the current potential match\n-        current_word_begin: usize,\n-        /// List of lines and their associated span\n-        docs: &'a [(String, Span)],\n-        /// Index of the current line we are parsing\n-        line: usize,\n-        /// Whether we are in a link\n-        link: bool,\n-        /// Whether we are at the beginning of a line\n-        new_line: bool,\n-        /// Whether we were to the end of a line last time `next` was called\n-        reset: bool,\n-        /// The position of the current character within the current line\n-        pos: usize,\n+    let mut current = 0;\n+    for &mut (ref mut offset, _) in &mut spans {\n+        let offset_copy = *offset;\n+        *offset = current;\n+        current += offset_copy;\n     }\n \n-    impl<'a> Parser<'a> {\n-        fn advance_begin(&mut self) {\n-            self.current_word_begin = self.pos;\n-        }\n-\n-        fn line(&self) -> (&'a str, Span) {\n-            let (ref doc, span) = self.docs[self.line];\n-            (doc, span)\n-        }\n+    println!(\"{:?}\", spans);\n+    if !doc.is_empty() {\n+        let parser = Parser::new(pulldown_cmark::Parser::new(&doc));\n+        let parser = parser.coalesce(|x, y| {\n+            use pulldown_cmark::Event::*;\n \n-        fn peek(&self) -> Option<char> {\n-            self.line().0[self.pos..].chars().next()\n-        }\n+            let x_offset = x.0;\n+            let y_offset = y.0;\n \n-        #[allow(while_let_on_iterator)] // borrowck complains about for\n-        fn jump_to(&mut self, n: char) -> Result<bool, ()> {\n-            while let Some((new_line, c)) = self.next() {\n-                if c == n {\n-                    self.advance_begin();\n-                    return Ok(new_line);\n-                }\n+            match (x.1, y.1) {\n+                (Text(x), Text(y)) => Ok((x_offset, Text((x.into_owned() + &y).into()))),\n+                (x, y) => Err(((x_offset, x), (y_offset, y))),\n             }\n-\n-            Err(())\n-        }\n-\n-        fn next_line(&mut self) {\n-            self.pos = 0;\n-            self.current_word_begin = 0;\n-            self.line += 1;\n-            self.new_line = true;\n-        }\n-\n-        fn put_back(&mut self, c: char) {\n-            self.pos -= c.len_utf8();\n-        }\n-\n-        #[allow(cast_possible_truncation)]\n-        fn word(&self) -> (&'a str, Span) {\n-            let begin = self.current_word_begin;\n-            let end = self.pos;\n-\n-            debug_assert_eq!(end as u32 as usize, end);\n-            debug_assert_eq!(begin as u32 as usize, begin);\n-\n-            let (doc, mut span) = self.line();\n-            span.hi = span.lo + BytePos(end as u32);\n-            span.lo = span.lo + BytePos(begin as u32);\n-\n-            (&doc[begin..end], span)\n-        }\n+        });\n+        check_doc(cx, valid_idents, parser, &spans);\n     }\n+}\n \n-    impl<'a> Iterator for Parser<'a> {\n-        type Item = (bool, char);\n-\n-        fn next(&mut self) -> Option<(bool, char)> {\n-            if self.line < self.docs.len() {\n-                if self.reset {\n-                    self.line += 1;\n-                    self.reset = false;\n-                    self.pos = 0;\n-                    self.current_word_begin = 0;\n-                }\n-\n-                let mut chars = self.line().0[self.pos..].chars();\n-                let c = chars.next();\n-\n-                if let Some(c) = c {\n-                    self.pos += c.len_utf8();\n-                    let new_line = self.new_line;\n-                    self.new_line = c == '\\n' || (self.new_line && c.is_whitespace());\n-                    Some((new_line, c))\n-                } else if self.line == self.docs.len() - 1 {\n-                    None\n-                } else {\n-                    self.new_line = true;\n-                    self.reset = true;\n-                    self.pos += 1;\n-                    Some((true, '\\n'))\n+fn check_doc<'a, Events: Iterator<Item=(usize, pulldown_cmark::Event<'a>)>>(\n+    cx: &EarlyContext,\n+    valid_idents: &[String],\n+    docs: Events,\n+    spans: &[(usize, Span)]\n+) {\n+    use pulldown_cmark::Event::*;\n+    use pulldown_cmark::Tag::*;\n+\n+    let mut in_code = false;\n+\n+    for (offset, event) in docs {\n+        println!(\"{:?}, {:?}\", offset, event);\n+        match event {\n+            Start(CodeBlock(_)) | Start(Code) => in_code = true,\n+            End(CodeBlock(_)) | End(Code) => in_code = false,\n+            Start(_tag) | End(_tag) => (), // We don't care about other tags\n+            Html(_html) | InlineHtml(_html) => (), // HTML is weird, just ignore it\n+            FootnoteReference(footnote) => (), // TODO\n+            SoftBreak => (),\n+            HardBreak => (),\n+            Text(text) => {\n+                if !in_code {\n+                    let index = match spans.binary_search_by(|c| c.0.cmp(&offset)) {\n+                        Ok(o) => o,\n+                        Err(e) => e-1,\n+                    };\n+\n+                    let (_, span) = spans[index];\n+                    check_text(cx, valid_idents, &text, span);\n                 }\n-            } else {\n-                None\n-            }\n+            },\n         }\n     }\n+}\n \n-    let mut parser = Parser {\n-        current_word_begin: 0,\n-        docs: docs,\n-        line: 0,\n-        link: false,\n-        new_line: true,\n-        reset: false,\n-        pos: 0,\n-    };\n-\n-    /// Check for fanced code block.\n-    macro_rules! check_block {\n-        ($parser:expr, $c:tt, $new_line:expr) => {{\n-            check_block!($parser, $c, $c, $new_line)\n-        }};\n-\n-        ($parser:expr, $c:pat, $c_expr:expr, $new_line:expr) => {{\n-            fn check_block(parser: &mut Parser, new_line: bool) -> Result<bool, ()> {\n-                if new_line {\n-                    let mut lookup_parser = parser.clone();\n-                    if let (Some((false, $c)), Some((false, $c))) = (lookup_parser.next(), lookup_parser.next()) {\n-                        *parser = lookup_parser;\n-                        // 3 or more ` or ~ open a code block to be closed with the same number of ` or ~\n-                        let mut open_count = 3;\n-                        while let Some((false, $c)) = parser.next() {\n-                            open_count += 1;\n-                        }\n-\n-                        loop {\n-                            loop {\n-                                if try!(parser.jump_to($c_expr)) {\n-                                    break;\n-                                }\n-                            }\n-\n-                            lookup_parser = parser.clone();\n-                            let a = lookup_parser.next();\n-                            let b = lookup_parser.next();\n-                            if let (Some((false, $c)), Some((false, $c))) = (a, b) {\n-                                let mut close_count = 3;\n-                                while let Some((false, $c)) = lookup_parser.next() {\n-                                    close_count += 1;\n-                                }\n-\n-                                if close_count == open_count {\n-                                    *parser = lookup_parser;\n-                                    return Ok(true);\n-                                }\n-                            }\n-                        }\n-                    }\n-                }\n-\n-                Ok(false)\n-            }\n-\n-            check_block(&mut $parser, $new_line)\n-        }};\n-    }\n-\n-    loop {\n-        match parser.next() {\n-            Some((new_line, c)) => {\n-                match c {\n-                    '#' if new_line => {\n-                        // don\u2019t warn on titles\n-                        parser.next_line();\n-                    },\n-                    '`' => {\n-                        if try!(check_block!(parser, '`', new_line)) {\n-                            continue;\n-                        }\n-\n-                        // not a code block, just inline code\n-                        try!(parser.jump_to('`'));\n-                    },\n-                    '~' => {\n-                        if try!(check_block!(parser, '~', new_line)) {\n-                            continue;\n-                        }\n-\n-                        // ~ does not introduce inline code, but two of them introduce\n-                        // strikethrough. Too bad for the consistency but we don't care about\n-                        // strikethrough.\n-                    },\n-                    '[' => {\n-                        // Check for a reference definition `[foo]:` at the beginning of a line\n-                        let mut link = true;\n-\n-                        if new_line {\n-                            let mut lookup_parser = parser.clone();\n-                            if lookup_parser.any(|(_, c)| c == ']') {\n-                                if let Some((_, ':')) = lookup_parser.next() {\n-                                    lookup_parser.next_line();\n-                                    parser = lookup_parser;\n-                                    link = false;\n-                                }\n-                            }\n-                        }\n-\n-                        parser.advance_begin();\n-                        parser.link = link;\n-                    },\n-                    ']' if parser.link => {\n-                        parser.link = false;\n-\n-                        match parser.peek() {\n-                            Some('(') => {\n-                                try!(parser.jump_to(')'));\n-                            },\n-                            Some('[') => {\n-                                try!(parser.jump_to(']'));\n-                            },\n-                            Some(_) => continue,\n-                            None => return Err(()),\n-                        }\n-                    },\n-                    c if !is_path_char(c) => {\n-                        parser.advance_begin();\n-                    },\n-                    _ => {\n-                        if let Some((_, c)) = parser.find(|&(_, c)| !is_path_char(c)) {\n-                            parser.put_back(c);\n-                        }\n-\n-                        let (word, span) = parser.word();\n-                        check_word(cx, valid_idents, word, span);\n-                        parser.advance_begin();\n-                    },\n-                }\n+fn check_text(cx: &EarlyContext, valid_idents: &[String], text: &str, span: Span) {\n+    for word in text.split_whitespace() {\n+        // Trim punctuation as in `some comment (see foo::bar).`\n+        //                                                   ^^\n+        // Or even as in `_foo bar_` which is emphasized.\n+        let word = word.trim_matches(|c: char| !c.is_alphanumeric());\n \n-            },\n-            None => break,\n+        if valid_idents.iter().any(|i| i == word) {\n+            continue;\n         }\n-    }\n \n-    Ok(())\n+        check_word(cx, word, span);\n+    }\n }\n \n-fn check_word(cx: &EarlyContext, valid_idents: &[String], word: &str, span: Span) {\n-    /// Checks if a string a camel-case, ie. contains at least two uppercase letter (`Clippy` is\n+fn check_word(cx: &EarlyContext, word: &str, span: Span) {\n+    /// Checks if a string is camel-case, ie. contains at least two uppercase letter (`Clippy` is\n     /// ok) and one lower-case letter (`NASA` is ok). Plural are also excluded (`IDs` is ok).\n     fn is_camel_case(s: &str) -> bool {\n         if s.starts_with(|c: char| c.is_digit(10)) {\n@@ -391,15 +225,6 @@ fn check_word(cx: &EarlyContext, valid_idents: &[String], word: &str, span: Span\n         s != \"_\" && !s.contains(\"\\\\_\") && s.contains('_')\n     }\n \n-    // Trim punctuation as in `some comment (see foo::bar).`\n-    //                                                   ^^\n-    // Or even as in `_foo bar_` which is emphasized.\n-    let word = word.trim_matches(|c: char| !c.is_alphanumeric());\n-\n-    if valid_idents.iter().any(|i| i == word) {\n-        return;\n-    }\n-\n     if has_underscore(word) || word.contains(\"::\") || is_camel_case(word) {\n         span_lint(cx,\n                   DOC_MARKDOWN,"}]}