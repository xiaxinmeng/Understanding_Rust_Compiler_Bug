{"sha": "083f61304461b48273dce6c2d11445d3166755ec", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA4M2Y2MTMwNDQ2MWI0ODI3M2RjZTZjMmQxMTQ0NWQzMTY2NzU1ZWM=", "commit": {"author": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2015-08-29T02:40:36Z"}, "committer": {"name": "Huon Wilson", "email": "dbau.pp+github@gmail.com", "date": "2015-08-29T22:36:16Z"}, "message": "Autogenerate most ARM platform intrinsics.", "tree": {"sha": "51111ab7ee6839c1effbfb3c16fa4b71a15a4c86", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/51111ab7ee6839c1effbfb3c16fa4b71a15a4c86"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/083f61304461b48273dce6c2d11445d3166755ec", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/083f61304461b48273dce6c2d11445d3166755ec", "html_url": "https://github.com/rust-lang/rust/commit/083f61304461b48273dce6c2d11445d3166755ec", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/083f61304461b48273dce6c2d11445d3166755ec/comments", "author": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "committer": {"login": "huonw", "id": 1203825, "node_id": "MDQ6VXNlcjEyMDM4MjU=", "avatar_url": "https://avatars.githubusercontent.com/u/1203825?v=4", "gravatar_id": "", "url": "https://api.github.com/users/huonw", "html_url": "https://github.com/huonw", "followers_url": "https://api.github.com/users/huonw/followers", "following_url": "https://api.github.com/users/huonw/following{/other_user}", "gists_url": "https://api.github.com/users/huonw/gists{/gist_id}", "starred_url": "https://api.github.com/users/huonw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/huonw/subscriptions", "organizations_url": "https://api.github.com/users/huonw/orgs", "repos_url": "https://api.github.com/users/huonw/repos", "events_url": "https://api.github.com/users/huonw/events{/privacy}", "received_events_url": "https://api.github.com/users/huonw/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3ef610b627fc64bfdef0a07ddfd06839a473e65d", "url": "https://api.github.com/repos/rust-lang/rust/commits/3ef610b627fc64bfdef0a07ddfd06839a473e65d", "html_url": "https://github.com/rust-lang/rust/commit/3ef610b627fc64bfdef0a07ddfd06839a473e65d"}], "stats": {"total": 2790, "additions": 2461, "deletions": 329}, "files": [{"sha": "0a48a50cf28fe4d62f8b801ccc8c0c1ae22f4a2b", "filename": "src/etc/platform-intrinsics/arm.json", "status": "added", "additions": 396, "deletions": 0, "changes": 396, "blob_url": "https://github.com/rust-lang/rust/blob/083f61304461b48273dce6c2d11445d3166755ec/src%2Fetc%2Fplatform-intrinsics%2Farm.json", "raw_url": "https://github.com/rust-lang/rust/raw/083f61304461b48273dce6c2d11445d3166755ec/src%2Fetc%2Fplatform-intrinsics%2Farm.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Farm.json?ref=083f61304461b48273dce6c2d11445d3166755ec", "patch": "@@ -0,0 +1,396 @@\n+{\n+    \"platform\": \"arm\",\n+    \"intrinsic_prefix\": \"arm_v\",\n+    \"llvm_prefix\": \"llvm.neon.v\",\n+    \"number_info\": {\n+        \"signed\": {\n+            \"kind\": \"s\",\n+            \"data_type\": { \"pattern\": \"s{bitwidth}\" }\n+        },\n+        \"unsigned\": {\n+            \"kind\": \"u\",\n+            \"data_type\": { \"pattern\": \"u{bitwidth}\" }\n+        },\n+        \"float\": {\n+            \"kind\": \"f\",\n+            \"data_type\": { \"pattern\": \"f{bitwidth}\" }\n+        }\n+    },\n+    \"widths\": {\n+        \"64\": \"\",\n+        \"128\": \"q\"\n+    },\n+    \"intrinsics\": [\n+        {\n+            \"intrinsic\": \"hadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"hadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rhadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rhadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qadd{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qadd{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"raddhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"raddhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"fma{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fma.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrdmulh{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqrdmulh.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"mull_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"mull{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"qdmull{0.width}_{1.data_type}\",\n+            \"width\": [128],\n+            \"llvm\": \"sqdmull.{0.llvm_name}\",\n+            \"ret\": \"s(16-32)\",\n+            \"args\": [\"0n\", \"0n\"]\n+        },\n+        {\n+            \"intrinsic\": \"hsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"hsub{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qsub{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qsub{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsubhn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rsubhn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abd{0.width}_{1.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"abd{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"max{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"max{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"min{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"min{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"shl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"shl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"qrshl{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0s\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrun_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"sqrshrun.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qshrn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"rshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"rshrn.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"qrshrn_n_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qrshrn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\", \"U32\"]\n+        },\n+        {\n+            \"intrinsic\": \"sri{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsri.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sli{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"vsli.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"vqmovn_{1.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"qxtn{0.kind}.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0w\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"abs.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"abs{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.fabs.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qabs{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"sqabs.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qneg{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"sqneg.{0.llvm_name}\",\n+            \"ret\": \"s(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"clz{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctlz.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cls{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"cls.{0.llvm_name}\",\n+            \"ret\": \"i(8-32)\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"cnt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.ctpop.{0.llvm_name}\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recpe{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"recpe.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f32\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"recps{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"frecps.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"sqrt{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"!llvm.sqrt.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrte{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"rsqrte.{0.llvm_name}\",\n+            \"ret\": [\"u32\",\"f32\"],\n+            \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"rsqrts{0.width}_{0.data_type}\",\n+            \"width\": [64,128],\n+            \"llvm\": \"rsqrts.{0.llvm_name}\",\n+            \"ret\": \"f32\",\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"bsl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"bsl.{0.llvm_name}\",\n+            \"ret\": \"i(8-64)\",\n+            \"args\": [\"0u\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"padd{0.width}_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"padd.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"paddl{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"paddl{0.kind}.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"padal{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"padal{0.kind}.{0.llvm_name}.{1.llvm_name}\",\n+            \"ret\": \"i(16-64)\",\n+            \"args\": [\"0\", \"0dn\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmax{0.width}_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"pmax{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"pmin{0.width}_{0.data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"pmin{0.kind}.{0.llvm_name}\",\n+            \"ret\": [\"i(8-32)\",\"f32\"],\n+            \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl1_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl1\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0x128\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx1_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx1\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"0\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl2_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl2\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx2_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx2\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl3_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl3\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx3_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx3\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbl4_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbl4\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"(0,0,0,0)f\", \"0u\"]\n+        },\n+        {\n+            \"intrinsic\": \"qtbx4_{0.data_type}\",\n+            \"width\": [64],\n+            \"llvm\": \"tbx4\",\n+            \"ret\": \"i8\",\n+            \"args\": [\"0\", \"(0,0,0,0)f\", \"0u\"]\n+        }\n+    ]\n+}"}, {"sha": "7398dcf79835e67537ad9eae9e71aabfe6da8f95", "filename": "src/librustc_platform_intrinsics/arm.rs", "status": "modified", "additions": 2065, "deletions": 329, "changes": 2394, "blob_url": "https://github.com/rust-lang/rust/blob/083f61304461b48273dce6c2d11445d3166755ec/src%2Flibrustc_platform_intrinsics%2Farm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/083f61304461b48273dce6c2d11445d3166755ec/src%2Flibrustc_platform_intrinsics%2Farm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Farm.rs?ref=083f61304461b48273dce6c2d11445d3166755ec", "patch": "@@ -8,340 +8,2076 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use {Intrinsic, i, f, v};\n+// DO NOT EDIT: autogenerated by etc/platform-intrinsics/generator.py\n+// ignore-tidy-linelength\n+\n+use {Intrinsic, i, u, f, v, agg};\n+use IntrinsicDef::Named;\n use rustc::middle::ty;\n \n-macro_rules! p {\n-    ($name: expr, ($($inputs: tt),*) -> $output: tt) => {\n-        plain!(concat!(\"llvm.arm.neon.\", $name), ($($inputs),*) -> $output)\n-    }\n-}\n pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n     if !name.starts_with(\"arm_v\") { return None }\n     Some(match &name[\"arm_v\".len()..] {\n-        \"sqrtq_f32\" => plain!(\"llvm.sqrt.v4f32\", (f32x4) -> f32x4),\n-        \"sqrtq_f64\" => plain!(\"llvm.sqrt.v2f64\", (f64x2) -> f64x2),\n-\n-        \"hadd_s8\" => p!(\"vhadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"haddq_s8\" => p!(\"vhadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hadd_s16\" => p!(\"vhadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"haddq_s16\" => p!(\"vhadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hadd_s32\" => p!(\"vhadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"haddq_s32\" => p!(\"vhadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"hadd_u8\" => p!(\"vhaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"haddq_u8\" => p!(\"vhaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hadd_u16\" => p!(\"vhaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"haddq_u16\" => p!(\"vhaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hadd_u32\" => p!(\"vhaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"haddq_u32\" => p!(\"vhaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rhadd_s8\" => p!(\"vrhadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rhaddq_s8\" => p!(\"vrhadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rhadd_s16\" => p!(\"vrhadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rhaddq_s16\" => p!(\"vrhadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rhadd_s32\" => p!(\"vrhadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rhaddq_s32\" => p!(\"vrhadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rhadd_u8\" => p!(\"vrhaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rhaddq_u8\" => p!(\"vrhaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rhadd_u16\" => p!(\"vrhaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rhaddq_u16\" => p!(\"vrhaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rhadd_u32\" => p!(\"vrhaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rhaddq_u32\" => p!(\"vrhaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_s8\" => p!(\"vqadds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qaddq_s8\" => p!(\"vqadds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qadd_s16\" => p!(\"vqadds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qaddq_s16\" => p!(\"vqadds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qadd_s32\" => p!(\"vqadds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qaddq_s32\" => p!(\"vqadds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_s64\" => p!(\"vqaddu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qaddq_s64\" => p!(\"vqaddu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qadd_u8\" => p!(\"vqaddu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qaddq_u8\" => p!(\"vqaddu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qadd_u16\" => p!(\"vqaddu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qaddq_u16\" => p!(\"vqaddu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qadd_u32\" => p!(\"vqaddu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qaddq_u32\" => p!(\"vqaddu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qadd_u64\" => p!(\"vqaddu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qaddq_u64\" => p!(\"vqaddu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"raddhn_s16\" => p!(\"vraddhn.v8i8\", (i16x8, i16x8) -> i8x8),\n-        \"raddhn_s32\" => p!(\"vraddhn.v4i16\", (i32x4, i32x4) -> i16x4),\n-        \"raddhn_s64\" => p!(\"vraddhn.v2i32\", (i64x2, i64x2) -> i32x2),\n-        \"fma_f32\" => plain!(\"llvm.fma.v2f32\", (f32x2, f32x2, f32x2) -> f32x2),\n-        \"fmaq_f32\" => plain!(\"llvm.fma.v4f32\", (f32x4, f32x4, f32x4) -> f32x4),\n-        \"qdmulh_s16\" => p!(\"vqdmulh.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qdmulhq_s16\" => p!(\"vqdmulh.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qdmulh_s32\" => p!(\"vqdmulh.v2i32\", (i32x2, i32x2) -> i32x4),\n-        \"qdmulhq_s32\" => p!(\"vqdmulh.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrdmulh_s16\" => p!(\"vqrdmulh.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrdmulhqr_s16\" => p!(\"vqrdmulh.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrdmulh_s32\" => p!(\"vqrdmulh.v2i32\", (i32x2, i32x2) -> i32x4),\n-        \"qrdmulhqr_s32\" => p!(\"vqrdmulh.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"mull_s8\" => p!(\"vmulls.v8i16\", (i8x8, i8x8) -> i16x8),\n-        \"mull_s16\" => p!(\"vmulls.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"mull_s32\" => p!(\"vmulls.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"mull_u8\" => p!(\"vmullu.v8i16\", (i8x8, i8x8) -> i16x8),\n-        \"mull_u16\" => p!(\"vmullu.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"mull_u32\" => p!(\"vmullu.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"qdmull_s16\" => p!(\"vqdmull.v4i32\", (i16x4, i16x4) -> i32x4),\n-        \"qdmull_s32\" => p!(\"vqdmull.v2i64\", (i32x2, i32x2) -> i64x2),\n-        \"hsub_s8\" => p!(\"vhsubs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"hsubq_s8\" => p!(\"vhsubs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hsub_s16\" => p!(\"vhsubs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"hsubq_s16\" => p!(\"vhsubs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hsub_s32\" => p!(\"vhsubs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"hsubq_s32\" => p!(\"vhsubs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"hsub_u8\" => p!(\"vhsubu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"hsubq_u8\" => p!(\"vhsubu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"hsub_u16\" => p!(\"vhsubu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"hsubq_u16\" => p!(\"vhsubu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"hsub_u32\" => p!(\"vhsubu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"hsubq_u32\" => p!(\"vhsubu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_s8\" => p!(\"vqsubs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qsubq_s8\" => p!(\"vqsubs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qsub_s16\" => p!(\"vqsubs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qsubq_s16\" => p!(\"vqsubs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qsub_s32\" => p!(\"vqsubs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qsubq_s32\" => p!(\"vqsubs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_s64\" => p!(\"vqsubu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qsubq_s64\" => p!(\"vqsubu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qsub_u8\" => p!(\"vqsubu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qsubq_u8\" => p!(\"vqsubu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qsub_u16\" => p!(\"vqsubu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qsubq_u16\" => p!(\"vqsubu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qsub_u32\" => p!(\"vqsubu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qsubq_u32\" => p!(\"vqsubu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qsub_u64\" => p!(\"vqsubu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qsubq_u64\" => p!(\"vqsubu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"abd_s8\" => p!(\"vabds.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"abdq_s8\" => p!(\"vabds.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abd_s16\" => p!(\"vabds.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"abdq_s16\" => p!(\"vabds.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abd_s32\" => p!(\"vabds.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"abdq_s32\" => p!(\"vabds.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abd_u8\" => p!(\"vabdu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"abdq_u8\" => p!(\"vabdu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abd_u16\" => p!(\"vabdu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"abdq_u16\" => p!(\"vabdu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abd_u32\" => p!(\"vabdu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"abdq_u32\" => p!(\"vabdu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abd_f32\" => p!(\"vabds.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"abdq_f32\" => p!(\"vabds.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"max_s8\" => p!(\"vmaxs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"maxq_s8\" => p!(\"vmaxs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"max_s16\" => p!(\"vmaxs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"maxq_s16\" => p!(\"vmaxs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"max_s32\" => p!(\"vmaxs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"maxq_s32\" => p!(\"vmaxs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"max_u8\" => p!(\"vmaxu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"maxq_u8\" => p!(\"vmaxu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"max_u16\" => p!(\"vmaxu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"maxq_u16\" => p!(\"vmaxu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"max_u32\" => p!(\"vmaxu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"maxq_u32\" => p!(\"vmaxu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"max_f32\" => p!(\"vmaxs.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"maxq_f32\" => p!(\"vmaxs.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"min_s8\" => p!(\"vmins.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"minq_s8\" => p!(\"vmins.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"min_s16\" => p!(\"vmins.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"minq_s16\" => p!(\"vmins.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"min_s32\" => p!(\"vmins.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"minq_s32\" => p!(\"vmins.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"min_u8\" => p!(\"vminu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"minq_u8\" => p!(\"vminu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"min_u16\" => p!(\"vminu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"minq_u16\" => p!(\"vminu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"min_u32\" => p!(\"vminu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"minq_u32\" => p!(\"vminu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"min_f32\" => p!(\"vmins.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"minq_f32\" => p!(\"vmins.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"shl_s8\" => p!(\"vshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"shlq_s8\" => p!(\"vshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"shl_s16\" => p!(\"vshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"shlq_s16\" => p!(\"vshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"shl_s32\" => p!(\"vshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"shlq_s32\" => p!(\"vshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"shl_s64\" => p!(\"vshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"shlq_s64\" => p!(\"vshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"shl_u8\" => p!(\"vshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"shlq_u8\" => p!(\"vshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"shl_u16\" => p!(\"vshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"shlq_u16\" => p!(\"vshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"shl_u32\" => p!(\"vshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"shlq_u32\" => p!(\"vshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"shl_u64\" => p!(\"vshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"shlq_u64\" => p!(\"vshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qshl_s8\" => p!(\"vqshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qshlq_s8\" => p!(\"vqshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qshl_s16\" => p!(\"vqshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qshlq_s16\" => p!(\"vqshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qshl_s32\" => p!(\"vqshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qshlq_s32\" => p!(\"vqshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qshl_s64\" => p!(\"vqshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qshlq_s64\" => p!(\"vqshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qshl_u8\" => p!(\"vqshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qshlq_u8\" => p!(\"vqshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qshl_u16\" => p!(\"vqshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qshlq_u16\" => p!(\"vqshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qshl_u32\" => p!(\"vqshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qshlq_u32\" => p!(\"vqshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qshl_u64\" => p!(\"vqshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qshlq_u64\" => p!(\"vqshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"rshl_s8\" => p!(\"vrshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rshlr_s8\" => p!(\"vrshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rshl_s16\" => p!(\"vrshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rshlr_s16\" => p!(\"vrshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rshl_s32\" => p!(\"vrshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rshlr_s32\" => p!(\"vrshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rshl_s64\" => p!(\"vrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"rshlr_s64\" => p!(\"vrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"rshl_u8\" => p!(\"vrshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"rshlr_u8\" => p!(\"vrshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"rshl_u16\" => p!(\"vrshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"rshlr_u16\" => p!(\"vrshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"rshl_u32\" => p!(\"vrshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"rshlr_u32\" => p!(\"vrshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"rshl_u64\" => p!(\"vrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"rshlr_u64\" => p!(\"vrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qrshl_s8\" => p!(\"vqrshifts.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qrshlqr_s8\" => p!(\"vqrshifts.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qrshl_s16\" => p!(\"vqrshifts.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrshlqr_s16\" => p!(\"vqrshifts.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrshl_s32\" => p!(\"vqrshifts.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qrshlqr_s32\" => p!(\"vqrshifts.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrshl_s64\" => p!(\"vqrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qrshlqr_s64\" => p!(\"vqrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qrshl_u8\" => p!(\"vqrshiftu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qrshlqr_u8\" => p!(\"vqrshiftu.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qrshl_u16\" => p!(\"vqrshiftu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qrshlqr_u16\" => p!(\"vqrshiftu.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qrshl_u32\" => p!(\"vqrshiftu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qrshlqr_u32\" => p!(\"vqrshiftu.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"qrshl_u64\" => p!(\"vqrshiftu.v1i64\", (i64x1, i64x1) -> i64x1),\n-        \"qrshlqr_u64\" => p!(\"vqrshiftu.v2i64\", (i64x2, i64x2) -> i64x2),\n-        \"qmovn_s16\" => p!(\"vqmovns.v8i8\", (i16x8) -> i8x8),\n-        \"qmovn_s32\" => p!(\"vqmovns.v4i16\", (i32x4) -> i16x4),\n-        \"qmovn_s64\" => p!(\"vqmovns.v2i32\", (i64x2) -> i32x2),\n-        \"qmovn_u16\" => p!(\"vqmovnu.v8i8\", (i16x8) -> i8x8),\n-        \"qmovn_u32\" => p!(\"vqmovnu.v4i16\", (i32x4) -> i16x4),\n-        \"qmovn_u64\" => p!(\"vqmovnu.v2i32\", (i64x2) -> i32x2),\n-        \"qmovun_s16\" => p!(\"vqmovnsu.v8i8\", (i16x8) -> i8x8),\n-        \"qmovun_s32\" => p!(\"vqmovnsu.v4i16\", (i32x4) -> i16x4),\n-        \"qmovun_s64\" => p!(\"vqmovnsu.v2i32\", (i64x2) -> i32x2),\n-        \"abs_s8\" => p!(\"vabs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"absq_s8\" => p!(\"vabs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"abs_s16\" => p!(\"vabs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"absq_s16\" => p!(\"vabs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"abs_s32\" => p!(\"vabs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"absq_s32\" => p!(\"vabs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"abs_f32\" => p!(\"vabs.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"absq_f32\" => p!(\"vabs.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"qabs_s8\" => p!(\"vqabs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"qabsq_s8\" => p!(\"vqabs.v16i8\", (i8x16, i8x16) -> i8x16),\n-        \"qabs_s16\" => p!(\"vqabs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"qabsq_s16\" => p!(\"vqabs.v8i16\", (i16x8, i16x8) -> i16x8),\n-        \"qabs_s32\" => p!(\"vqabs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"qabsq_s32\" => p!(\"vqabs.v4i32\", (i32x4, i32x4) -> i32x4),\n-        \"neg_s8\" => p!(\"vneg.v8i8\", (i8x8) -> i8x8),\n-        \"negq_s8\" => p!(\"vneg.v16i8\", (i8x16) -> i8x16),\n-        \"neg_s16\" => p!(\"vneg.v4i16\", (i16x4) -> i16x4),\n-        \"negq_s16\" => p!(\"vneg.v8i16\", (i16x8) -> i16x8),\n-        \"neg_s32\" => p!(\"vneg.v2i32\", (i32x2) -> i32x2),\n-        \"negq_s32\" => p!(\"vneg.v4i32\", (i32x4) -> i32x4),\n-        \"neg_f32\" => p!(\"vneg.v2f32\", (f32x2) -> f32x2),\n-        \"negq_f32\" => p!(\"vneg.v4f32\", (f32x4) -> f32x4),\n-        \"qneg_s8\" => p!(\"vqneg.v8i8\", (i8x8) -> i8x8),\n-        \"qnegq_s8\" => p!(\"vqneg.v16i8\", (i8x16) -> i8x16),\n-        \"qneg_s16\" => p!(\"vqneg.v4i16\", (i16x4) -> i16x4),\n-        \"qnegq_s16\" => p!(\"vqneg.v8i16\", (i16x8) -> i16x8),\n-        \"qneg_s32\" => p!(\"vqneg.v2i32\", (i32x2) -> i32x2),\n-        \"qnegq_s32\" => p!(\"vqneg.v4i32\", (i32x4) -> i32x4),\n-        \"cls_s8\" => p!(\"vcls.v8i8\", (i8x8) -> i8x8),\n-        \"clsq_s8\" => p!(\"vcls.v16i8\", (i8x16) -> i8x16),\n-        \"cls_s16\" => p!(\"vcls.v4i16\", (i16x4) -> i16x4),\n-        \"clsq_s16\" => p!(\"vcls.v8i16\", (i16x8) -> i16x8),\n-        \"cls_s32\" => p!(\"vcls.v2i32\", (i32x2) -> i32x2),\n-        \"clsq_s32\" => p!(\"vcls.v4i32\", (i32x4) -> i32x4),\n-        \"clz_s8\" => p!(\"vclz.v8i8\", (i8x8) -> i8x8),\n-        \"clzq_s8\" => p!(\"vclz.v16i8\", (i8x16) -> i8x16),\n-        \"clz_s16\" => p!(\"vclz.v4i16\", (i16x4) -> i16x4),\n-        \"clzq_s16\" => p!(\"vclz.v8i16\", (i16x8) -> i16x8),\n-        \"clz_s32\" => p!(\"vclz.v2i32\", (i32x2) -> i32x2),\n-        \"clzq_s32\" => p!(\"vclz.v4i32\", (i32x4) -> i32x4),\n-        \"cnt_s8\" => p!(\"vcnt.v8i8\", (i8x8) -> i8x8),\n-        \"cntq_s8\" => p!(\"vcnt.v16i8\", (i8x16) -> i8x16),\n-        \"recpe_u32\" => p!(\"vrecpe.v2i32\", (i32x2) -> i32x2),\n-        \"recpeq_u32\" => p!(\"vrecpe.v4i32\", (i32x4) -> i32x4),\n-        \"recpe_f32\" => p!(\"vrecpe.v2f32\", (f32x2) -> f32x2),\n-        \"recpeq_f32\" => p!(\"vrecpe.v4f32\", (f32x4) -> f32x4),\n-        \"recps_f32\" => p!(\"vrecps.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"recpsq_f32\" => p!(\"vrecps.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"rsqrte_u32\" => p!(\"vrsqrte.v2i32\", (i32x2) -> i32x2),\n-        \"rsqrteq_u32\" => p!(\"vrsqrte.v4i32\", (i32x4) -> i32x4),\n-        \"rsqrte_f32\" => p!(\"vrsqrte.v2f32\", (f32x2) -> f32x2),\n-        \"rsqrteq_f32\" => p!(\"vrsqrte.v4f32\", (f32x4) -> f32x4),\n-        \"rsqrts_f32\" => p!(\"vrsqrts.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"rsqrtsq_f32\" => p!(\"vrsqrts.v4f32\", (f32x4, f32x4) -> f32x4),\n-        \"bsl_s8\" => p!(\"vsl.v8i8\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"bslq_s8\" => p!(\"vsl.v16i8\", (i8x16, i8x16, i8x16) -> i8x16),\n-        \"padd_s8\" => p!(\"vpadd.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"padd_s16\" => p!(\"vpadd.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"padd_s32\" => p!(\"vpadd.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"padd_u8\" => p!(\"vpadd.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"padd_u16\" => p!(\"vpadd.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"padd_u32\" => p!(\"vpadd.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"padd_f32\" => p!(\"vpadd.v2f32\", (f32x2, f32x2) -> f32x2),\n-        \"paddl_s8\" => p!(\"vpaddls.v4i16.v8i8\", (i8x8) -> i16x4),\n-        \"paddlq_s8\" => p!(\"vpaddls.v8i16.v16i8\", (i8x16) -> i16x8),\n-        \"paddl_s16\" => p!(\"vpaddls.v2i32.v4i16\", (i16x4) -> i32x2),\n-        \"paddlq_s16\" => p!(\"vpaddls.v4i32.v8i16\", (i16x8) -> i32x4),\n-        \"paddl_s32\" => p!(\"vpaddls.v1i64.v2i32\", (i32x2) -> i64x1),\n-        \"paddlq_s32\" => p!(\"vpaddls.v2i64.v4i32\", (i32x4) -> i64x2),\n-        \"paddl_u8\" => p!(\"vpaddlu.v4i16.v8i8\", (i8x8) -> i16x4),\n-        \"paddlq_u8\" => p!(\"vpaddlu.v8i16.v16i8\", (i8x16) -> i16x8),\n-        \"paddl_u16\" => p!(\"vpaddlu.v2i32.v4i16\", (i16x4) -> i32x2),\n-        \"paddlq_u16\" => p!(\"vpaddlu.v4i32.v8i16\", (i16x8) -> i32x4),\n-        \"paddl_u32\" => p!(\"vpaddlu.v1i64.v2i32\", (i32x2) -> i64x1),\n-        \"paddlq_u32\" => p!(\"vpaddlu.v2i64.v4i32\", (i32x4) -> i64x2),\n-        \"padal_s8\" => p!(\"vpadals.v4i16.v8i8\", (i16x4, i8x8) -> i16x4),\n-        \"padalq_s8\" => p!(\"vpadals.v8i16.v16i8\", (i16x8, i8x16) -> i16x8),\n-        \"padal_s16\" => p!(\"vpadals.v2i32.v4i16\", (i32x2, i16x4) -> i32x2),\n-        \"padalq_s16\" => p!(\"vpadals.v4i32.v8i16\", (i32x4, i16x8) -> i32x4),\n-        \"padal_s32\" => p!(\"vpadals.v1i64.v2i32\", (i64x1, i32x2) -> i64x1),\n-        \"padalq_s32\" => p!(\"vpadals.v2i64.v4i32\", (i64x2, i32x4) -> i64x2),\n-        \"padal_u8\" => p!(\"vpadalu.v4i16.v8i8\", (i16x4, i8x8) -> i16x4),\n-        \"padalq_u8\" => p!(\"vpadalu.v8i16.v16i8\", (i16x8, i8x16) -> i16x8),\n-        \"padal_u16\" => p!(\"vpadalu.v2i32.v4i16\", (i32x2, i16x4) -> i32x2),\n-        \"padalq_u16\" => p!(\"vpadalu.v4i32.v8i16\", (i32x4, i16x8) -> i32x4),\n-        \"padal_u32\" => p!(\"vpadalu.v1i64.v2i32\", (i64x1, i32x2) -> i64x1),\n-        \"padalq_u32\" => p!(\"vpadalu.v2i64.v4i32\", (i64x2, i32x4) -> i64x2),\n-        \"pmax_s16\" => p!(\"vpmaxs.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmax_s32\" => p!(\"vpmaxs.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmax_s8\" => p!(\"vpmaxs.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmax_u16\" => p!(\"vpmaxu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmax_u32\" => p!(\"vpmaxu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmax_u8\" => p!(\"vpmaxu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmin_s16\" => p!(\"vpmins.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmin_s32\" => p!(\"vpmins.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmin_s8\" => p!(\"vpmins.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"pmin_u16\" => p!(\"vpminu.v4i16\", (i16x4, i16x4) -> i16x4),\n-        \"pmin_u32\" => p!(\"vpminu.v2i32\", (i32x2, i32x2) -> i32x2),\n-        \"pmin_u8\" => p!(\"vpminu.v8i8\", (i8x8, i8x8) -> i8x8),\n-        \"tbl1_s8\" => p!(\"vtbl1\", (i8x8, i8x8) -> i8x8),\n-        \"tbl1_u8\" => p!(\"vtbl1\", (i8x8, i8x8) -> i8x8),\n-        // these aren't exactly the C intrinsics (they take one argument)\n-        \"tbl2_s8\" => p!(\"vtbl2\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl2_u8\" => p!(\"vtbl2\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl3_s8\" => p!(\"vtbl3\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl3_u8\" => p!(\"vtbl3\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl4_s8\" => p!(\"vtbl4\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbl4_u8\" => p!(\"vtbl4\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx1_s8\" => p!(\"vtbx1\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx1_u8\" => p!(\"vtbx1\", (i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx2_s8\" => p!(\"vtbx2\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx2_u8\" => p!(\"vtbx2\", (i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx3_s8\" => p!(\"vtbx3\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx3_u8\" => p!(\"vtbx3\", (i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx4_s8\" => p!(\"vtbx4\", (i8x8, i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n-        \"tbx4_u8\" => p!(\"vtbx4\", (i8x8, i8x8, i8x8, i8x8, i8x8, i8x8) -> i8x8),\n+        \"hadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vhadds.v8i8\")\n+        },\n+        \"hadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vhaddu.v8i8\")\n+        },\n+        \"hadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vhadds.v4i16\")\n+        },\n+        \"hadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vhaddu.v4i16\")\n+        },\n+        \"hadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vhadds.v2i32\")\n+        },\n+        \"hadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vhaddu.v2i32\")\n+        },\n+        \"haddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vhadds.v16i8\")\n+        },\n+        \"haddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vhaddu.v16i8\")\n+        },\n+        \"haddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vhadds.v8i16\")\n+        },\n+        \"haddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vhaddu.v8i16\")\n+        },\n+        \"haddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vhadds.v4i32\")\n+        },\n+        \"haddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vhaddu.v4i32\")\n+        },\n+        \"rhadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrhadds.v8i8\")\n+        },\n+        \"rhadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrhaddu.v8i8\")\n+        },\n+        \"rhadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrhadds.v4i16\")\n+        },\n+        \"rhadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrhaddu.v4i16\")\n+        },\n+        \"rhadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrhadds.v2i32\")\n+        },\n+        \"rhadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrhaddu.v2i32\")\n+        },\n+        \"rhaddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vrhadds.v16i8\")\n+        },\n+        \"rhaddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vrhaddu.v16i8\")\n+        },\n+        \"rhaddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vrhadds.v8i16\")\n+        },\n+        \"rhaddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vrhaddu.v8i16\")\n+        },\n+        \"rhaddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vrhadds.v4i32\")\n+        },\n+        \"rhaddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrhaddu.v4i32\")\n+        },\n+        \"qadd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqadds.v8i8\")\n+        },\n+        \"qadd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqaddu.v8i8\")\n+        },\n+        \"qadd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqadds.v4i16\")\n+        },\n+        \"qadd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqaddu.v4i16\")\n+        },\n+        \"qadd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqadds.v2i32\")\n+        },\n+        \"qadd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqaddu.v2i32\")\n+        },\n+        \"qadd_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqadds.v1i64\")\n+        },\n+        \"qadd_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqaddu.v1i64\")\n+        },\n+        \"qaddq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqadds.v16i8\")\n+        },\n+        \"qaddq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqaddu.v16i8\")\n+        },\n+        \"qaddq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqadds.v8i16\")\n+        },\n+        \"qaddq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqaddu.v8i16\")\n+        },\n+        \"qaddq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqadds.v4i32\")\n+        },\n+        \"qaddq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqaddu.v4i32\")\n+        },\n+        \"qaddq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqadds.v2i64\")\n+        },\n+        \"qaddq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqaddu.v2i64\")\n+        },\n+        \"raddhn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vraddhn.v8i8\")\n+        },\n+        \"raddhn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vraddhn.v8i8\")\n+        },\n+        \"raddhn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vraddhn.v4i16\")\n+        },\n+        \"raddhn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vraddhn.v4i16\")\n+        },\n+        \"raddhn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vraddhn.v2i32\")\n+        },\n+        \"raddhn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vraddhn.v2i32\")\n+        },\n+        \"fma_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.fma.v2f32\")\n+        },\n+        \"fmaq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.fma.v4f32\")\n+        },\n+        \"qdmulh_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqdmulh.v4i16\")\n+        },\n+        \"qdmulh_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqdmulh.v2i32\")\n+        },\n+        \"qdmulhq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqdmulh.v8i16\")\n+        },\n+        \"qdmulhq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqdmulh.v4i32\")\n+        },\n+        \"qrdmulh_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v4i16\")\n+        },\n+        \"qrdmulh_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v2i32\")\n+        },\n+        \"qrdmulhq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v8i16\")\n+        },\n+        \"qrdmulhq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqrdmulh.v4i32\")\n+        },\n+        \"mull_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmulls.v8i16\")\n+        },\n+        \"mull_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vmullu.v8i16\")\n+        },\n+        \"mull_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmulls.v4i32\")\n+        },\n+        \"mull_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vmullu.v4i32\")\n+        },\n+        \"mull_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vmulls.v2i64\")\n+        },\n+        \"mull_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vmullu.v2i64\")\n+        },\n+        \"qdmullq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqdmull.v8i16\")\n+        },\n+        \"qdmullq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqdmull.v4i32\")\n+        },\n+        \"hsub_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vhsubs.v8i8\")\n+        },\n+        \"hsub_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vhsubu.v8i8\")\n+        },\n+        \"hsub_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vhsubs.v4i16\")\n+        },\n+        \"hsub_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vhsubu.v4i16\")\n+        },\n+        \"hsub_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vhsubs.v2i32\")\n+        },\n+        \"hsub_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vhsubu.v2i32\")\n+        },\n+        \"hsubq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vhsubs.v16i8\")\n+        },\n+        \"hsubq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vhsubu.v16i8\")\n+        },\n+        \"hsubq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vhsubs.v8i16\")\n+        },\n+        \"hsubq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vhsubu.v8i16\")\n+        },\n+        \"hsubq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vhsubs.v4i32\")\n+        },\n+        \"hsubq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vhsubu.v4i32\")\n+        },\n+        \"qsub_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqsubs.v8i8\")\n+        },\n+        \"qsub_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqsubu.v8i8\")\n+        },\n+        \"qsub_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqsubs.v4i16\")\n+        },\n+        \"qsub_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqsubu.v4i16\")\n+        },\n+        \"qsub_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqsubs.v2i32\")\n+        },\n+        \"qsub_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqsubu.v2i32\")\n+        },\n+        \"qsub_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqsubs.v1i64\")\n+        },\n+        \"qsub_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqsubu.v1i64\")\n+        },\n+        \"qsubq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqsubs.v16i8\")\n+        },\n+        \"qsubq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqsubu.v16i8\")\n+        },\n+        \"qsubq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqsubs.v8i16\")\n+        },\n+        \"qsubq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqsubu.v8i16\")\n+        },\n+        \"qsubq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqsubs.v4i32\")\n+        },\n+        \"qsubq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqsubu.v4i32\")\n+        },\n+        \"qsubq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqsubs.v2i64\")\n+        },\n+        \"qsubq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqsubu.v2i64\")\n+        },\n+        \"rsubhn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrsubhn.v8i8\")\n+        },\n+        \"rsubhn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrsubhn.v8i8\")\n+        },\n+        \"rsubhn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrsubhn.v4i16\")\n+        },\n+        \"rsubhn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrsubhn.v4i16\")\n+        },\n+        \"rsubhn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrsubhn.v2i32\")\n+        },\n+        \"rsubhn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrsubhn.v2i32\")\n+        },\n+        \"abd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vabds.v8i8\")\n+        },\n+        \"abd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vabdu.v8i8\")\n+        },\n+        \"abd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vabds.v4i16\")\n+        },\n+        \"abd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vabdu.v4i16\")\n+        },\n+        \"abd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vabds.v2i32\")\n+        },\n+        \"abd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vabdu.v2i32\")\n+        },\n+        \"abd_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vabdf.v2f32\")\n+        },\n+        \"abdq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vabds.v16i8\")\n+        },\n+        \"abdq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vabdu.v16i8\")\n+        },\n+        \"abdq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vabds.v8i16\")\n+        },\n+        \"abdq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vabdu.v8i16\")\n+        },\n+        \"abdq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vabds.v4i32\")\n+        },\n+        \"abdq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vabdu.v4i32\")\n+        },\n+        \"abdq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vabdf.v4f32\")\n+        },\n+        \"max_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vmaxs.v8i8\")\n+        },\n+        \"max_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vmaxu.v8i8\")\n+        },\n+        \"max_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vmaxs.v4i16\")\n+        },\n+        \"max_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vmaxu.v4i16\")\n+        },\n+        \"max_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vmaxs.v2i32\")\n+        },\n+        \"max_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vmaxu.v2i32\")\n+        },\n+        \"max_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vmaxf.v2f32\")\n+        },\n+        \"maxq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vmaxs.v16i8\")\n+        },\n+        \"maxq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vmaxu.v16i8\")\n+        },\n+        \"maxq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmaxs.v8i16\")\n+        },\n+        \"maxq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vmaxu.v8i16\")\n+        },\n+        \"maxq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmaxs.v4i32\")\n+        },\n+        \"maxq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vmaxu.v4i32\")\n+        },\n+        \"maxq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vmaxf.v4f32\")\n+        },\n+        \"min_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vmins.v8i8\")\n+        },\n+        \"min_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vminu.v8i8\")\n+        },\n+        \"min_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vmins.v4i16\")\n+        },\n+        \"min_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vminu.v4i16\")\n+        },\n+        \"min_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vmins.v2i32\")\n+        },\n+        \"min_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vminu.v2i32\")\n+        },\n+        \"min_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vminf.v2f32\")\n+        },\n+        \"minq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vmins.v16i8\")\n+        },\n+        \"minq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vminu.v16i8\")\n+        },\n+        \"minq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vmins.v8i16\")\n+        },\n+        \"minq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vminu.v8i16\")\n+        },\n+        \"minq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vmins.v4i32\")\n+        },\n+        \"minq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vminu.v4i32\")\n+        },\n+        \"minq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vminf.v4f32\")\n+        },\n+        \"shl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vshls.v8i8\")\n+        },\n+        \"shl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vshlu.v8i8\")\n+        },\n+        \"shl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vshls.v4i16\")\n+        },\n+        \"shl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vshlu.v4i16\")\n+        },\n+        \"shl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vshls.v2i32\")\n+        },\n+        \"shl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vshlu.v2i32\")\n+        },\n+        \"shl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vshls.v1i64\")\n+        },\n+        \"shl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vshlu.v1i64\")\n+        },\n+        \"shlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vshls.v16i8\")\n+        },\n+        \"shlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vshlu.v16i8\")\n+        },\n+        \"shlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vshls.v8i16\")\n+        },\n+        \"shlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vshlu.v8i16\")\n+        },\n+        \"shlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vshls.v4i32\")\n+        },\n+        \"shlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vshlu.v4i32\")\n+        },\n+        \"shlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vshls.v2i64\")\n+        },\n+        \"shlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vshlu.v2i64\")\n+        },\n+        \"qshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqshls.v8i8\")\n+        },\n+        \"qshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqshlu.v8i8\")\n+        },\n+        \"qshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqshls.v4i16\")\n+        },\n+        \"qshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqshlu.v4i16\")\n+        },\n+        \"qshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqshls.v2i32\")\n+        },\n+        \"qshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqshlu.v2i32\")\n+        },\n+        \"qshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqshls.v1i64\")\n+        },\n+        \"qshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqshlu.v1i64\")\n+        },\n+        \"qshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqshls.v16i8\")\n+        },\n+        \"qshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqshlu.v16i8\")\n+        },\n+        \"qshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqshls.v8i16\")\n+        },\n+        \"qshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqshlu.v8i16\")\n+        },\n+        \"qshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqshls.v4i32\")\n+        },\n+        \"qshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqshlu.v4i32\")\n+        },\n+        \"qshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqshls.v2i64\")\n+        },\n+        \"qshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqshlu.v2i64\")\n+        },\n+        \"rshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrshls.v8i8\")\n+        },\n+        \"rshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrshlu.v8i8\")\n+        },\n+        \"rshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrshls.v4i16\")\n+        },\n+        \"rshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrshlu.v4i16\")\n+        },\n+        \"rshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrshls.v2i32\")\n+        },\n+        \"rshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrshlu.v2i32\")\n+        },\n+        \"rshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vrshls.v1i64\")\n+        },\n+        \"rshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vrshlu.v1i64\")\n+        },\n+        \"rshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vrshls.v16i8\")\n+        },\n+        \"rshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vrshlu.v16i8\")\n+        },\n+        \"rshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vrshls.v8i16\")\n+        },\n+        \"rshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vrshlu.v8i16\")\n+        },\n+        \"rshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vrshls.v4i32\")\n+        },\n+        \"rshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrshlu.v4i32\")\n+        },\n+        \"rshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vrshls.v2i64\")\n+        },\n+        \"rshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vrshlu.v2i64\")\n+        },\n+        \"qrshl_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqrshls.v8i8\")\n+        },\n+        \"qrshl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqrshlu.v8i8\")\n+        },\n+        \"qrshl_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqrshls.v4i16\")\n+        },\n+        \"qrshl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqrshlu.v4i16\")\n+        },\n+        \"qrshl_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqrshls.v2i32\")\n+        },\n+        \"qrshl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqrshlu.v2i32\")\n+        },\n+        \"qrshl_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vqrshls.v1i64\")\n+        },\n+        \"qrshl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vqrshlu.v1i64\")\n+        },\n+        \"qrshlq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vqrshls.v16i8\")\n+        },\n+        \"qrshlq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vqrshlu.v16i8\")\n+        },\n+        \"qrshlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vqrshls.v8i16\")\n+        },\n+        \"qrshlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vqrshlu.v8i16\")\n+        },\n+        \"qrshlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vqrshls.v4i32\")\n+        },\n+        \"qrshlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vqrshlu.v4i32\")\n+        },\n+        \"qrshlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vqrshls.v2i64\")\n+        },\n+        \"qrshlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vqrshlu.v2i64\")\n+        },\n+        \"qshrun_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqshrun.v8i8\")\n+        },\n+        \"qshrun_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqshrun.v4i16\")\n+        },\n+        \"qshrun_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqshrun.v2i32\")\n+        },\n+        \"qrshrun_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqrshrun.v8i8\")\n+        },\n+        \"qrshrun_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqrshrun.v4i16\")\n+        },\n+        \"qrshrun_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqrshrun.v2i32\")\n+        },\n+        \"qshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqshrns.v8i8\")\n+        },\n+        \"qshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqshrnu.v8i8\")\n+        },\n+        \"qshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqshrns.v4i16\")\n+        },\n+        \"qshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqshrnu.v4i16\")\n+        },\n+        \"qshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqshrns.v2i32\")\n+        },\n+        \"qshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqshrnu.v2i32\")\n+        },\n+        \"rshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vrshrn.v8i8\")\n+        },\n+        \"rshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vrshrn.v8i8\")\n+        },\n+        \"rshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vrshrn.v4i16\")\n+        },\n+        \"rshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vrshrn.v4i16\")\n+        },\n+        \"rshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vrshrn.v2i32\")\n+        },\n+        \"rshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrshrn.v2i32\")\n+        },\n+        \"qrshrn_n_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), u(32)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqrshrns.v8i8\")\n+        },\n+        \"qrshrn_n_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), u(32)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqrshrnu.v8i8\")\n+        },\n+        \"qrshrn_n_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), u(32)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqrshrns.v4i16\")\n+        },\n+        \"qrshrn_n_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), u(32)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqrshrnu.v4i16\")\n+        },\n+        \"qrshrn_n_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), u(32)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqrshrns.v2i32\")\n+        },\n+        \"qrshrn_n_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), u(32)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqrshrnu.v2i32\")\n+        },\n+        \"sri_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i8\")\n+        },\n+        \"sri_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i8\")\n+        },\n+        \"sri_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i16\")\n+        },\n+        \"sri_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i16\")\n+        },\n+        \"sri_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i32\")\n+        },\n+        \"sri_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i32\")\n+        },\n+        \"sri_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vvsri.v1i64\")\n+        },\n+        \"sri_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vvsri.v1i64\")\n+        },\n+        \"sriq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vvsri.v16i8\")\n+        },\n+        \"sriq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vvsri.v16i8\")\n+        },\n+        \"sriq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i16\")\n+        },\n+        \"sriq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vvsri.v8i16\")\n+        },\n+        \"sriq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i32\")\n+        },\n+        \"sriq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vvsri.v4i32\")\n+        },\n+        \"sriq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i64\")\n+        },\n+        \"sriq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vvsri.v2i64\")\n+        },\n+        \"sli_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i8\")\n+        },\n+        \"sli_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i8\")\n+        },\n+        \"sli_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i16\")\n+        },\n+        \"sli_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i16\")\n+        },\n+        \"sli_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i32\")\n+        },\n+        \"sli_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i32\")\n+        },\n+        \"sli_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vvsli.v1i64\")\n+        },\n+        \"sli_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vvsli.v1i64\")\n+        },\n+        \"sliq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vvsli.v16i8\")\n+        },\n+        \"sliq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vvsli.v16i8\")\n+        },\n+        \"sliq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i16\")\n+        },\n+        \"sliq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vvsli.v8i16\")\n+        },\n+        \"sliq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i32\")\n+        },\n+        \"sliq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vvsli.v4i32\")\n+        },\n+        \"sliq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i64\")\n+        },\n+        \"sliq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vvsli.v2i64\")\n+        },\n+        \"vqmovn_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vqxtns.v8i8\")\n+        },\n+        \"vqmovn_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vqxtnu.v8i8\")\n+        },\n+        \"vqmovn_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vqxtns.v4i16\")\n+        },\n+        \"vqmovn_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vqxtnu.v4i16\")\n+        },\n+        \"vqmovn_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vqxtns.v2i32\")\n+        },\n+        \"vqmovn_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vqxtnu.v2i32\")\n+        },\n+        \"abs_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vabs.v8i8\")\n+        },\n+        \"abs_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vabs.v4i16\")\n+        },\n+        \"abs_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vabs.v2i32\")\n+        },\n+        \"absq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vabs.v16i8\")\n+        },\n+        \"absq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vabs.v8i16\")\n+        },\n+        \"absq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vabs.v4i32\")\n+        },\n+        \"abs_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.fabs.v2f32\")\n+        },\n+        \"absq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.fabs.v4f32\")\n+        },\n+        \"qabs_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqabs.v8i8\")\n+        },\n+        \"qabs_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqabs.v4i16\")\n+        },\n+        \"qabs_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqabs.v2i32\")\n+        },\n+        \"qabsq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vsqabs.v16i8\")\n+        },\n+        \"qabsq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqabs.v8i16\")\n+        },\n+        \"qabsq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqabs.v4i32\")\n+        },\n+        \"qneg_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vsqneg.v8i8\")\n+        },\n+        \"qneg_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vsqneg.v4i16\")\n+        },\n+        \"qneg_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vsqneg.v2i32\")\n+        },\n+        \"qnegq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vsqneg.v16i8\")\n+        },\n+        \"qnegq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vsqneg.v8i16\")\n+        },\n+        \"qnegq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vsqneg.v4i32\")\n+        },\n+        \"clz_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.ctlz.v8i8\")\n+        },\n+        \"clz_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.ctlz.v8i8\")\n+        },\n+        \"clz_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.ctlz.v4i16\")\n+        },\n+        \"clz_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.ctlz.v4i16\")\n+        },\n+        \"clz_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.ctlz.v2i32\")\n+        },\n+        \"clz_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.ctlz.v2i32\")\n+        },\n+        \"clzq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.ctlz.v16i8\")\n+        },\n+        \"clzq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.ctlz.v16i8\")\n+        },\n+        \"clzq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.ctlz.v8i16\")\n+        },\n+        \"clzq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.ctlz.v8i16\")\n+        },\n+        \"clzq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.ctlz.v4i32\")\n+        },\n+        \"clzq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.ctlz.v4i32\")\n+        },\n+        \"cls_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i8\")\n+        },\n+        \"cls_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i8\")\n+        },\n+        \"cls_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i16\")\n+        },\n+        \"cls_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i16\")\n+        },\n+        \"cls_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vcls.v2i32\")\n+        },\n+        \"cls_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vcls.v2i32\")\n+        },\n+        \"clsq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vcls.v16i8\")\n+        },\n+        \"clsq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vcls.v16i8\")\n+        },\n+        \"clsq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i16\")\n+        },\n+        \"clsq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vcls.v8i16\")\n+        },\n+        \"clsq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i32\")\n+        },\n+        \"clsq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vcls.v4i32\")\n+        },\n+        \"cnt_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.ctpop.v8i8\")\n+        },\n+        \"cnt_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.ctpop.v8i8\")\n+        },\n+        \"cntq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.ctpop.v16i8\")\n+        },\n+        \"cntq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.ctpop.v16i8\")\n+        },\n+        \"recpe_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrecpe.v2i32\")\n+        },\n+        \"recpe_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrecpe.v2f32\")\n+        },\n+        \"recpeq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrecpe.v4i32\")\n+        },\n+        \"recpeq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrecpe.v4f32\")\n+        },\n+        \"recps_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vfrecps.v2f32\")\n+        },\n+        \"recpsq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vfrecps.v4f32\")\n+        },\n+        \"sqrt_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.sqrt.v2f32\")\n+        },\n+        \"sqrtq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.sqrt.v4f32\")\n+        },\n+        \"rsqrte_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrte.v2i32\")\n+        },\n+        \"rsqrte_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrte.v2f32\")\n+        },\n+        \"rsqrteq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrte.v4i32\")\n+        },\n+        \"rsqrteq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrte.v4f32\")\n+        },\n+        \"rsqrts_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vrsqrts.v2f32\")\n+        },\n+        \"rsqrtsq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vrsqrts.v4f32\")\n+        },\n+        \"bsl_s8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i8\")\n+        },\n+        \"bsl_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i8\")\n+        },\n+        \"bsl_s16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i16\")\n+        },\n+        \"bsl_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i16\")\n+        },\n+        \"bsl_s32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i32\")\n+        },\n+        \"bsl_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i32\")\n+        },\n+        \"bsl_s64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(i(64), 1)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vbsl.v1i64\")\n+        },\n+        \"bsl_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(64), 1)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vbsl.v1i64\")\n+        },\n+        \"bslq_s8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vbsl.v16i8\")\n+        },\n+        \"bslq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vbsl.v16i8\")\n+        },\n+        \"bslq_s16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i16\")\n+        },\n+        \"bslq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vbsl.v8i16\")\n+        },\n+        \"bslq_s32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i32\")\n+        },\n+        \"bslq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vbsl.v4i32\")\n+        },\n+        \"bslq_s64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i64\")\n+        },\n+        \"bslq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(64), 2)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vbsl.v2i64\")\n+        },\n+        \"padd_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpadd.v8i8\")\n+        },\n+        \"padd_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpadd.v8i8\")\n+        },\n+        \"padd_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpadd.v4i16\")\n+        },\n+        \"padd_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpadd.v4i16\")\n+        },\n+        \"padd_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2i32\")\n+        },\n+        \"padd_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2i32\")\n+        },\n+        \"padd_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpadd.v2f32\")\n+        },\n+        \"paddl_s16\" => Intrinsic {\n+            inputs: vec![v(i(8), 8)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpaddls.v4i16.v8i8\")\n+        },\n+        \"paddl_u16\" => Intrinsic {\n+            inputs: vec![v(u(8), 8)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpaddlu.v4i16.v8i8\")\n+        },\n+        \"paddl_s32\" => Intrinsic {\n+            inputs: vec![v(i(16), 4)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpaddls.v2i32.v4i16\")\n+        },\n+        \"paddl_u32\" => Intrinsic {\n+            inputs: vec![v(u(16), 4)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpaddlu.v2i32.v4i16\")\n+        },\n+        \"paddl_s64\" => Intrinsic {\n+            inputs: vec![v(i(32), 2)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vpaddls.v1i64.v2i32\")\n+        },\n+        \"paddl_u64\" => Intrinsic {\n+            inputs: vec![v(u(32), 2)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vpaddlu.v1i64.v2i32\")\n+        },\n+        \"paddlq_s16\" => Intrinsic {\n+            inputs: vec![v(i(8), 16)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpaddls.v8i16.v16i8\")\n+        },\n+        \"paddlq_u16\" => Intrinsic {\n+            inputs: vec![v(u(8), 16)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpaddlu.v8i16.v16i8\")\n+        },\n+        \"paddlq_s32\" => Intrinsic {\n+            inputs: vec![v(i(16), 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpaddls.v4i32.v8i16\")\n+        },\n+        \"paddlq_u32\" => Intrinsic {\n+            inputs: vec![v(u(16), 8)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpaddlu.v4i32.v8i16\")\n+        },\n+        \"paddlq_s64\" => Intrinsic {\n+            inputs: vec![v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vpaddls.v2i64.v4i32\")\n+        },\n+        \"paddlq_u64\" => Intrinsic {\n+            inputs: vec![v(u(32), 4)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vpaddlu.v2i64.v4i32\")\n+        },\n+        \"padal_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(8), 8)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpadals.v4i16.v4i16\")\n+        },\n+        \"padal_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(8), 8)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpadalu.v4i16.v4i16\")\n+        },\n+        \"padal_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(16), 4)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpadals.v2i32.v2i32\")\n+        },\n+        \"padal_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(16), 4)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpadalu.v2i32.v2i32\")\n+        },\n+        \"padal_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 1), v(i(32), 2)],\n+            output: v(i(64), 1),\n+            definition: Named(\"llvm.neon.vpadals.v1i64.v1i64\")\n+        },\n+        \"padal_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 1), v(u(32), 2)],\n+            output: v(u(64), 1),\n+            definition: Named(\"llvm.neon.vpadalu.v1i64.v1i64\")\n+        },\n+        \"padalq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(8), 16)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpadals.v8i16.v8i16\")\n+        },\n+        \"padalq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(8), 16)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpadalu.v8i16.v8i16\")\n+        },\n+        \"padalq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(16), 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpadals.v4i32.v4i32\")\n+        },\n+        \"padalq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(16), 8)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpadalu.v4i32.v4i32\")\n+        },\n+        \"padalq_s64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), v(i(32), 4)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.neon.vpadals.v2i64.v2i64\")\n+        },\n+        \"padalq_u64\" => Intrinsic {\n+            inputs: vec![v(u(64), 2), v(u(32), 4)],\n+            output: v(u(64), 2),\n+            definition: Named(\"llvm.neon.vpadalu.v2i64.v2i64\")\n+        },\n+        \"pmax_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpmaxs.v8i8\")\n+        },\n+        \"pmax_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpmaxu.v8i8\")\n+        },\n+        \"pmax_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpmaxs.v4i16\")\n+        },\n+        \"pmax_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpmaxu.v4i16\")\n+        },\n+        \"pmax_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxs.v2i32\")\n+        },\n+        \"pmax_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxu.v2i32\")\n+        },\n+        \"pmax_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpmaxf.v2f32\")\n+        },\n+        \"pmin_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vpmins.v8i8\")\n+        },\n+        \"pmin_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vpminu.v8i8\")\n+        },\n+        \"pmin_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 4), v(i(16), 4)],\n+            output: v(i(16), 4),\n+            definition: Named(\"llvm.neon.vpmins.v4i16\")\n+        },\n+        \"pmin_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 4), v(u(16), 4)],\n+            output: v(u(16), 4),\n+            definition: Named(\"llvm.neon.vpminu.v4i16\")\n+        },\n+        \"pmin_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 2), v(i(32), 2)],\n+            output: v(i(32), 2),\n+            definition: Named(\"llvm.neon.vpmins.v2i32\")\n+        },\n+        \"pmin_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 2), v(u(32), 2)],\n+            output: v(u(32), 2),\n+            definition: Named(\"llvm.neon.vpminu.v2i32\")\n+        },\n+        \"pmin_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 2), v(f(32), 2)],\n+            output: v(f(32), 2),\n+            definition: Named(\"llvm.neon.vpminf.v2f32\")\n+        },\n+        \"pminq_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(i(8), 16)],\n+            output: v(i(8), 16),\n+            definition: Named(\"llvm.neon.vpmins.v16i8\")\n+        },\n+        \"pminq_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16)],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.neon.vpminu.v16i8\")\n+        },\n+        \"pminq_s16\" => Intrinsic {\n+            inputs: vec![v(i(16), 8), v(i(16), 8)],\n+            output: v(i(16), 8),\n+            definition: Named(\"llvm.neon.vpmins.v8i16\")\n+        },\n+        \"pminq_u16\" => Intrinsic {\n+            inputs: vec![v(u(16), 8), v(u(16), 8)],\n+            output: v(u(16), 8),\n+            definition: Named(\"llvm.neon.vpminu.v8i16\")\n+        },\n+        \"pminq_s32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.neon.vpmins.v4i32\")\n+        },\n+        \"pminq_u32\" => Intrinsic {\n+            inputs: vec![v(u(32), 4), v(u(32), 4)],\n+            output: v(u(32), 4),\n+            definition: Named(\"llvm.neon.vpminu.v4i32\")\n+        },\n+        \"pminq_f32\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), v(f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.neon.vpminf.v4f32\")\n+        },\n+        \"qtbl1_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 16), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl1\")\n+        },\n+        \"qtbl1_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl1\")\n+        },\n+        \"qtbx1_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), v(i(8), 8), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx1\")\n+        },\n+        \"qtbx1_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx1\")\n+        },\n+        \"qtbl2_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl2\")\n+        },\n+        \"qtbl2_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl2\")\n+        },\n+        \"qtbx2_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx2\")\n+        },\n+        \"qtbx2_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx2\")\n+        },\n+        \"qtbl3_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl3\")\n+        },\n+        \"qtbl3_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl3\")\n+        },\n+        \"qtbx3_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx3\")\n+        },\n+        \"qtbx3_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx3\")\n+        },\n+        \"qtbl4_s8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbl4\")\n+        },\n+        \"qtbl4_u8\" => Intrinsic {\n+            inputs: vec![agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbl4\")\n+        },\n+        \"qtbx4_s8\" => Intrinsic {\n+            inputs: vec![v(i(8), 8), agg(true, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]), v(u(8), 8)],\n+            output: v(i(8), 8),\n+            definition: Named(\"llvm.neon.vtbx4\")\n+        },\n+        \"qtbx4_u8\" => Intrinsic {\n+            inputs: vec![v(u(8), 8), agg(true, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]), v(u(8), 8)],\n+            output: v(u(8), 8),\n+            definition: Named(\"llvm.neon.vtbx4\")\n+        },\n         _ => return None,\n     })\n }"}]}