{"sha": "bfa0e1f58acf1c28d500c34ed258f09ae021893e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJmYTBlMWY1OGFjZjFjMjhkNTAwYzM0ZWQyNThmMDlhZTAyMTg5M2U=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-10T04:57:21Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-17T15:29:15Z"}, "message": "Add RawVec to unify raw Vecish code", "tree": {"sha": "2ce46adfc3ce6be3e7b9d12a14277b644e61cf5b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2ce46adfc3ce6be3e7b9d12a14277b644e61cf5b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bfa0e1f58acf1c28d500c34ed258f09ae021893e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bfa0e1f58acf1c28d500c34ed258f09ae021893e", "html_url": "https://github.com/rust-lang/rust/commit/bfa0e1f58acf1c28d500c34ed258f09ae021893e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bfa0e1f58acf1c28d500c34ed258f09ae021893e/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b5dad7dcb22ed6bf8ebaae56b4339bd64f6983eb", "url": "https://api.github.com/repos/rust-lang/rust/commits/b5dad7dcb22ed6bf8ebaae56b4339bd64f6983eb", "html_url": "https://github.com/rust-lang/rust/commit/b5dad7dcb22ed6bf8ebaae56b4339bd64f6983eb"}], "stats": {"total": 1106, "additions": 631, "deletions": 475}, "files": [{"sha": "d9653cecc73cfe17bbcf8204d828e39f9ce5593a", "filename": "src/liballoc/boxed.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Fboxed.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Fboxed.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fboxed.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -62,7 +62,7 @@ use core::hash::{self, Hash};\n use core::marker::Unsize;\n use core::mem;\n use core::ops::{CoerceUnsized, Deref, DerefMut};\n-use core::ptr::{Unique};\n+use core::ptr::Unique;\n use core::raw::{TraitObject};\n \n /// A value that represents the heap. This is the default place that the `box`"}, {"sha": "5c1fd2a1aa1f487661a8a88383ceb79cf8a09db6", "filename": "src/liballoc/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Flib.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -88,6 +88,7 @@\n #![feature(unique)]\n #![feature(unsafe_no_drop_flag, filling_drop)]\n #![feature(unsize)]\n+#![feature(core_slice_ext)]\n \n #![cfg_attr(test, feature(test, alloc, rustc_private, box_raw))]\n #![cfg_attr(all(not(feature = \"external_funcs\"), not(feature = \"external_crate\")),\n@@ -122,6 +123,7 @@ mod boxed { pub use std::boxed::{Box, HEAP}; }\n mod boxed_test;\n pub mod arc;\n pub mod rc;\n+pub mod raw_vec;\n \n /// Common out-of-memory routine\n #[cold]"}, {"sha": "9311f44d9df00ff321b3a8d7b94469b9fc3f3b16", "filename": "src/liballoc/raw_vec.rs", "status": "added", "additions": 453, "deletions": 0, "changes": 453, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Fraw_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Fliballoc%2Fraw_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -0,0 +1,453 @@\n+// Copyright 2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use core::ptr::Unique;\n+use core::mem;\n+use core::slice::{self, SliceExt};\n+use heap;\n+use super::oom;\n+use super::boxed::Box;\n+use core::ops::Drop;\n+\n+/// A low-level utility for more ergonomically allocating, reallocating, and deallocating a\n+/// a buffer of memory on the heap without having to worry about all the corner cases\n+/// involved. This type is excellent for building your own data structures like Vec and VecDeque.\n+/// In particular:\n+///\n+/// * Produces heap::EMPTY on zero-sized types\n+/// * Produces heap::EMPTY on zero-length allocations\n+/// * Catches all overflows in capacity computations (promotes them to \"capacity overflow\" panics)\n+/// * Guards against 32-bit systems allocating more than isize::MAX bytes\n+/// * Guards against overflowing your length\n+/// * Aborts on OOM\n+/// * Avoids freeing heap::EMPTY\n+/// * Contains a ptr::Unique and thus endows the user with all related benefits\n+///\n+/// This type does not in anyway inspect the memory that it manages. When dropped it *will*\n+/// free its memory, but it *won't* try to Drop its contents. It is up to the user of RawVec\n+/// to handle the actual things *stored* inside of a RawVec.\n+///\n+/// Note that a RawVec always forces its capacity to be usize::MAX for zero-sized types.\n+/// This enables you to use capacity growing logic catch the overflows in your length\n+/// that might occur with zero-sized types.\n+///\n+/// However this means that you need to be careful when roundtripping this type\n+/// with a `Box<[T]>`: `cap()` won't yield the len. However `with_capacity`,\n+/// `shrink_to_fit`, and `from_box` will actually set RawVec's private capacity\n+/// field. This allows zero-sized types to not be special-cased by consumers of\n+/// this type.\n+#[unsafe_no_drop_flag]\n+pub struct RawVec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+}\n+\n+impl<T> RawVec<T> {\n+    /// Creates the biggest possible RawVec without allocating. If T has positive\n+    /// size, then this makes a RawVec with capacity 0. If T has 0 size, then it\n+    /// it makes a RawVec with capacity `usize::MAX`. Useful for implementing\n+    /// delayed allocation.\n+    pub fn new() -> Self {\n+        unsafe {\n+            // !0 is usize::MAX. This branch should be stripped at compile time.\n+            let cap = if mem::size_of::<T>() == 0 { !0 } else { 0 };\n+\n+            // heap::EMPTY doubles as \"unallocated\" and \"zero-sized allocation\"\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: cap }\n+        }\n+    }\n+\n+    /// Creates a RawVec with exactly the capacity and alignment requirements\n+    /// for a `[T; cap]`. This is equivalent to calling RawVec::new when `cap` is 0\n+    /// or T is zero-sized. Note that if `T` is zero-sized this means you will *not*\n+    /// get a RawVec with the requested capacity!\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM\n+    pub fn with_capacity(cap: usize) -> Self {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            let alloc_size = cap.checked_mul(elem_size).expect(\"capacity overflow\");\n+            alloc_guard(alloc_size);\n+\n+            // handles ZSTs and `cap = 0` alike\n+            let ptr = if alloc_size == 0 {\n+                heap::EMPTY as *mut u8\n+            } else {\n+                let align = mem::align_of::<T>();\n+                let ptr = heap::allocate(alloc_size, align);\n+                if ptr.is_null() { oom() }\n+                ptr\n+            };\n+\n+            RawVec { ptr: Unique::new(ptr as *mut _), cap: cap }\n+        }\n+    }\n+\n+    /// Reconstitutes a RawVec from a pointer and capacity.\n+    ///\n+    /// # Undefined Behaviour\n+    ///\n+    /// The ptr must be allocated, and with the given capacity. The\n+    /// capacity cannot exceed `isize::MAX` (only a concern on 32-bit systems).\n+    /// If the ptr and capacity come from a RawVec, then this is guaranteed.\n+    pub unsafe fn from_raw_parts(ptr: *mut T, cap: usize) -> Self {\n+        RawVec { ptr: Unique::new(ptr), cap: cap }\n+    }\n+\n+    /// Converts a `Box<[T]>` into a `RawVec<T>`.\n+    pub fn from_box(mut slice: Box<[T]>) -> Self {\n+        unsafe {\n+            let result = RawVec::from_raw_parts(slice.as_mut_ptr(), slice.len());\n+            mem::forget(slice);\n+            result\n+        }\n+    }\n+}\n+\n+impl<T> RawVec<T> {\n+    /// Gets a raw pointer to the start of the allocation. Note that this is\n+    /// heap::EMPTY if `cap = 0` or T is zero-sized. In the former case, you must\n+    /// be careful.\n+    pub fn ptr(&self) -> *mut T {\n+        *self.ptr\n+    }\n+\n+    /// Gets the capacity of the allocation.\n+    ///\n+    /// This will always be `usize::MAX` if `T` is zero-sized.\n+    pub fn cap(&self) -> usize {\n+        if mem::size_of::<T>() == 0 { !0 } else { self.cap }\n+    }\n+\n+    /// Doubles the size of the type's backing allocation. This is common enough\n+    /// to want to do that it's easiest to just have a dedicated method. Slightly\n+    /// more efficient logic can be provided for this than the general case.\n+    ///\n+    /// This function is ideal for when pushing elements one-at-a-time because\n+    /// you don't need to incur the costs of the more general computations\n+    /// reserve needs to do to guard against overflow. You do however need to\n+    /// manually check if your `len == cap`.\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if T is zero-sized on the assumption that you managed to exhaust\n+    ///   all `usize::MAX` slots in your imaginary buffer.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```ignore\n+    /// struct MyVec<T> {\n+    ///     buf: RawVec<T>,\n+    ///     len: usize,\n+    /// }\n+    ///\n+    /// impl<T> MyVec<T> {\n+    ///     pub fn push(&mut self, elem: T) {\n+    ///         if self.len == self.buf.cap() { self.buf.double(); }\n+    ///         // double would have aborted or panicked if the len exceeded\n+    ///         // `isize::MAX` so this is safe to do unchecked now.\n+    ///         unsafe {\n+    ///             ptr::write(self.buf.ptr().offset(self.len as isize), elem);\n+    ///         }\n+    ///         self.len += 1;\n+    ///     }\n+    /// }\n+    /// ```\n+    #[inline(never)]\n+    #[cold]\n+    pub fn double(&mut self) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the RawVec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            let align = mem::align_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                // skip to 4 because tiny Vec's are dumb; but not if that would cause overflow\n+                let new_cap = if elem_size > (!0) / 8 { 1 } else { 4 };\n+                let ptr = heap::allocate(new_cap * elem_size, align);\n+                (new_cap, ptr)\n+            } else {\n+                // Since we guarantee that we never allocate more than isize::MAX bytes,\n+                // `elem_size * self.cap <= isize::MAX` as a precondition, so this can't overflow\n+                let new_cap = 2 * self.cap;\n+                let new_alloc_size = new_cap * elem_size;\n+                alloc_guard(new_alloc_size);\n+                let ptr = heap::reallocate(self.ptr() as *mut _,\n+                                           self.cap * elem_size,\n+                                           new_alloc_size,\n+                                           align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+\n+    /// Ensures that the buffer contains at least enough space to hold\n+    /// `used_cap + needed_extra_cap` elements. If it doesn't already,\n+    /// will reallocate the minimum possible amount of memory necessary.\n+    /// Generally this will be exactly the amount of memory necessary,\n+    /// but in principle the allocator is free to give back more than\n+    /// we asked for.\n+    ///\n+    /// If `used_cap` exceeds `self.cap()`, this may fail to actually allocate\n+    /// the requested space. This is not really unsafe, but the unsafe\n+    /// code *you* write that relies on the behaviour of this function may break.\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM\n+    pub fn reserve_exact(&mut self, used_cap: usize, needed_extra_cap: usize) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+            let align = mem::align_of::<T>();\n+\n+            // NOTE: we don't early branch on ZSTs here because we want this\n+            // to actually catch \"asking for more than usize::MAX\" in that case.\n+            // If we make it past the first branch then we are guaranteed to\n+            // panic.\n+\n+            // Don't actually need any more capacity.\n+            // Wrapping in case they gave a bad `used_cap`.\n+            if self.cap().wrapping_sub(used_cap) >= needed_extra_cap { return; }\n+\n+            // Nothing we can really do about these checks :(\n+            let new_cap = used_cap.checked_add(needed_extra_cap).expect(\"capacity overflow\");\n+            let new_alloc_size = new_cap.checked_mul(elem_size).expect(\"capacity overflow\");\n+            alloc_guard(new_alloc_size);\n+\n+            let ptr = if self.cap == 0 {\n+                heap::allocate(new_alloc_size, align)\n+            } else {\n+                heap::reallocate(self.ptr() as *mut _,\n+                                 self.cap * elem_size,\n+                                 new_alloc_size,\n+                                 align)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+\n+    /// Ensures that the buffer contains at least enough space to hold\n+    /// `used_cap + needed_extra_cap` elements. If it doesn't already have\n+    /// enough capacity, will reallocate enough space plus comfortable slack\n+    /// space to get amortized `O(1)` behaviour. Will limit this behaviour\n+    /// if it would needlessly cause itself to panic.\n+    ///\n+    /// If `used_cap` exceeds `self.cap()`, this may fail to actually allocate\n+    /// the requested space. This is not really unsafe, but the unsafe\n+    /// code *you* write that relies on the behaviour of this function may break.\n+    ///\n+    /// This is ideal for implementing a bulk-push operation like `extend`.\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```ignore\n+    /// struct MyVec<T> {\n+    ///     buf: RawVec<T>,\n+    ///     len: usize,\n+    /// }\n+    ///\n+    /// impl<T> MyVec<T> {\n+    ///     pub fn push_all(&mut self, elems: &[T]) {\n+    ///         self.buf.reserve(self.len, elems.len());\n+    ///         // reserve would have aborted or panicked if the len exceeded\n+    ///         // `isize::MAX` so this is safe to do unchecked now.\n+    ///         for x in elems {\n+    ///             unsafe {\n+    ///                 ptr::write(self.buf.ptr().offset(self.len as isize), x.clone());\n+    ///             }\n+    ///             self.len += 1;\n+    ///         }\n+    ///     }\n+    /// }\n+    /// ```\n+    pub fn reserve(&mut self, used_cap: usize, needed_extra_cap: usize) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+            let align = mem::align_of::<T>();\n+\n+            // NOTE: we don't early branch on ZSTs here because we want this\n+            // to actually catch \"asking for more than usize::MAX\" in that case.\n+            // If we make it past the first branch then we are guaranteed to\n+            // panic.\n+\n+            // Don't actually need any more capacity.\n+            // Wrapping in case they give a bas `used_cap`\n+            if self.cap().wrapping_sub(used_cap) >= needed_extra_cap { return; }\n+\n+            // Nothing we can really do about these checks :(\n+            let new_cap = used_cap.checked_add(needed_extra_cap)\n+                                  .and_then(|cap| cap.checked_mul(2))\n+                                  .expect(\"capacity overflow\");\n+            let new_alloc_size = new_cap.checked_mul(elem_size).expect(\"capacity overflow\");\n+            // FIXME: may crash and burn on over-reserve\n+            alloc_guard(new_alloc_size);\n+\n+            let ptr = if self.cap == 0 {\n+                heap::allocate(new_alloc_size, align)\n+            } else {\n+                heap::reallocate(self.ptr() as *mut _,\n+                                 self.cap * elem_size,\n+                                 new_alloc_size,\n+                                 align)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+\n+    /// Shrinks the allocation down to the specified amount. If the given amount\n+    /// is 0, actually completely deallocates.\n+    ///\n+    /// # Panics\n+    ///\n+    /// Panics if the given amount is *larger* than the current capacity.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM.\n+    pub fn shrink_to_fit(&mut self, amount: usize) {\n+        let elem_size = mem::size_of::<T>();\n+        let align = mem::align_of::<T>();\n+\n+        // Set the `cap` because they might be about to promote to a `Box<[T]>`\n+        if elem_size == 0 {\n+            self.cap = amount;\n+            return;\n+        }\n+\n+        // This check is my waterloo; it's the only thing Vec wouldn't have to do.\n+        assert!(self.cap >= amount, \"Tried to shrink to a larger capacity\");\n+\n+        if amount == 0 {\n+            mem::replace(self, RawVec::new());\n+        } else if self.cap != amount {\n+            unsafe {\n+                // Overflow check is unnecessary as the vector is already at\n+                // least this large.\n+                let ptr = heap::reallocate(self.ptr() as *mut _,\n+                                           self.cap * elem_size,\n+                                           amount * elem_size,\n+                                           align);\n+                if ptr.is_null() { oom() }\n+                self.ptr = Unique::new(ptr as *mut _);\n+            }\n+            self.cap = amount;\n+        }\n+    }\n+\n+    /// Converts the entire buffer into `Box<[T]>`.\n+    ///\n+    /// While it is not *strictly* Undefined Behaviour to call\n+    /// this procedure while some of the RawVec is unintialized,\n+    /// it cetainly makes it trivial to trigger it.\n+    ///\n+    /// Note that this will correctly reconstitute any `cap` changes\n+    /// that may have been performed. (see description of type for details)\n+    pub unsafe fn into_box(self) -> Box<[T]> {\n+        // NOTE: not calling `cap()` here, actually using the real `cap` field!\n+        let slice = slice::from_raw_parts_mut(self.ptr(), self.cap);\n+        let output: Box<[T]> = Box::from_raw(slice);\n+        mem::forget(self);\n+        output\n+    }\n+\n+    /// This is a stupid name in the hopes that someone will find this in the\n+    /// not too distant future and remove it with the rest of\n+    /// #[unsafe_no_drop_flag]\n+    pub fn unsafe_no_drop_flag_needs_drop(&self) -> bool {\n+        self.cap != mem::POST_DROP_USIZE\n+    }\n+}\n+\n+impl<T> Drop for RawVec<T> {\n+    /// Frees the memory owned by the RawVec *without* trying to Drop its contents.\n+    fn drop(&mut self) {\n+        let elem_size = mem::size_of::<T>();\n+        if elem_size != 0 && self.cap != 0 && self.unsafe_no_drop_flag_needs_drop() {\n+            let align = mem::align_of::<T>();\n+\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+\n+\n+\n+// We need to guarantee the following:\n+// * We don't ever allocate `> isize::MAX` byte-size objects\n+// * We don't overflow `usize::MAX` and actually allocate too little\n+//\n+// On 64-bit we just need to check for overflow since trying to allocate\n+// `> isize::MAX` bytes will surely fail. On 32-bit we need to add an extra\n+// guard for this in case we're running on a platform which can use all 4GB in\n+// user-space. e.g. PAE or x32\n+\n+#[inline]\n+#[cfg(target_pointer_width = \"64\")]\n+fn alloc_guard(_alloc_size: usize) { }\n+\n+#[inline]\n+#[cfg(target_pointer_width = \"32\")]\n+fn alloc_guard(alloc_size: usize) {\n+    assert!(alloc_size <= ::core::isize::MAX as usize, \"capacity overflow\");\n+}"}, {"sha": "a2b2ae220f88ed1e8a6c3304d878750436b77f49", "filename": "src/libcollections/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Flib.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -32,7 +32,6 @@\n \n #![feature(alloc)]\n #![feature(box_patterns)]\n-#![feature(box_raw)]\n #![feature(box_syntax)]\n #![feature(core)]\n #![feature(core_intrinsics)]"}, {"sha": "ebff4a9126dafa2beb466067d1a0e6fb5797ac89", "filename": "src/libcollections/string.rs", "status": "modified", "additions": 1, "deletions": 44, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fstring.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fstring.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fstring.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -28,7 +28,7 @@ use rustc_unicode::str::Utf16Item;\n use borrow::{Cow, IntoCow};\n use range::RangeArgument;\n use str::{self, FromStr, Utf8Error, Chars};\n-use vec::{DerefVec, Vec, as_vec};\n+use vec::Vec;\n use boxed::Box;\n \n /// A growable string stored as a UTF-8 encoded buffer.\n@@ -1029,49 +1029,6 @@ impl ops::DerefMut for String {\n     }\n }\n \n-/// Wrapper type providing a `&String` reference via `Deref`.\n-#[unstable(feature = \"collections\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-#[allow(deprecated)]\n-pub struct DerefString<'a> {\n-    x: DerefVec<'a, u8>\n-}\n-\n-#[allow(deprecated)]\n-impl<'a> Deref for DerefString<'a> {\n-    type Target = String;\n-\n-    #[inline]\n-    fn deref<'b>(&'b self) -> &'b String {\n-        unsafe { mem::transmute(&*self.x) }\n-    }\n-}\n-\n-/// Converts a string slice to a wrapper type providing a `&String` reference.\n-///\n-/// # Examples\n-///\n-/// ```\n-/// # #![feature(collections)]\n-/// use std::string::as_string;\n-///\n-/// // Let's pretend we have a function that requires `&String`\n-/// fn string_consumer(s: &String) {\n-///     assert_eq!(s, \"foo\");\n-/// }\n-///\n-/// // Provide a `&String` from a `&str` without allocating\n-/// string_consumer(&as_string(\"foo\"));\n-/// ```\n-#[unstable(feature = \"collections\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-#[allow(deprecated)]\n-pub fn as_string<'a>(x: &'a str) -> DerefString<'a> {\n-    DerefString { x: as_vec(x.as_bytes()) }\n-}\n-\n /// Error returned from `String::from`\n #[unstable(feature = \"str_parse_error\", reason = \"may want to be replaced with \\\n                                                   Void if it ever exists\")]"}, {"sha": "58fe65face691a33514fd89730a340e49134313b", "filename": "src/libcollections/vec.rs", "status": "modified", "additions": 44, "deletions": 246, "changes": 290, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fvec.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -59,32 +59,25 @@\n #![stable(feature = \"rust1\", since = \"1.0.0\")]\n \n use core::prelude::*;\n-\n+use alloc::raw_vec::RawVec;\n use alloc::boxed::Box;\n-use alloc::heap::{EMPTY, allocate, reallocate, deallocate};\n-use core::cmp::max;\n+use alloc::heap::EMPTY;\n use core::cmp::Ordering;\n use core::fmt;\n use core::hash::{self, Hash};\n-use core::intrinsics::{arith_offset, assume};\n+use core::intrinsics::{arith_offset, assume, drop_in_place};\n use core::iter::FromIterator;\n use core::marker::PhantomData;\n use core::mem;\n use core::ops::{Index, IndexMut, Deref};\n use core::ops;\n use core::ptr;\n-use core::ptr::Unique;\n use core::slice;\n-use core::isize;\n-use core::usize;\n \n use borrow::{Cow, IntoCow};\n \n use super::range::RangeArgument;\n \n-// FIXME- fix places which assume the max vector allowed has memory usize::MAX.\n-const MAX_MEMORY_SIZE: usize = isize::MAX as usize;\n-\n /// A growable list type, written `Vec<T>` but pronounced 'vector.'\n ///\n /// # Examples\n@@ -152,9 +145,8 @@ const MAX_MEMORY_SIZE: usize = isize::MAX as usize;\n #[unsafe_no_drop_flag]\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub struct Vec<T> {\n-    ptr: Unique<T>,\n+    buf: RawVec<T>,\n     len: usize,\n-    cap: usize,\n }\n \n ////////////////////////////////////////////////////////////////////////////////\n@@ -174,11 +166,7 @@ impl<T> Vec<T> {\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn new() -> Vec<T> {\n-        // We want ptr to never be NULL so instead we set it to some arbitrary\n-        // non-null value which is fine since we never call deallocate on the ptr\n-        // if cap is 0. The reason for this is because the pointer of a slice\n-        // being NULL would break the null pointer optimization for enums.\n-        unsafe { Vec::from_raw_parts(EMPTY as *mut T, 0, 0) }\n+        Vec { buf: RawVec::new(), len: 0 }\n     }\n \n     /// Constructs a new, empty `Vec<T>` with the specified capacity.\n@@ -209,17 +197,7 @@ impl<T> Vec<T> {\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn with_capacity(capacity: usize) -> Vec<T> {\n-        if mem::size_of::<T>() == 0 {\n-            unsafe { Vec::from_raw_parts(EMPTY as *mut T, 0, usize::MAX) }\n-        } else if capacity == 0 {\n-            Vec::new()\n-        } else {\n-            let size = capacity.checked_mul(mem::size_of::<T>())\n-                               .expect(\"capacity overflow\");\n-            let ptr = unsafe { allocate(size, mem::align_of::<T>()) };\n-            if ptr.is_null() { ::alloc::oom() }\n-            unsafe { Vec::from_raw_parts(ptr as *mut T, 0, capacity) }\n-        }\n+        Vec { buf: RawVec::with_capacity(capacity), len: 0 }\n     }\n \n     /// Creates a `Vec<T>` directly from the raw components of another vector.\n@@ -270,9 +248,8 @@ impl<T> Vec<T> {\n     pub unsafe fn from_raw_parts(ptr: *mut T, length: usize,\n                                  capacity: usize) -> Vec<T> {\n         Vec {\n-            ptr: Unique::new(ptr),\n+            buf: RawVec::from_raw_parts(ptr, capacity),\n             len: length,\n-            cap: capacity,\n         }\n     }\n \n@@ -306,7 +283,7 @@ impl<T> Vec<T> {\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn capacity(&self) -> usize {\n-        self.cap\n+        self.buf.cap()\n     }\n \n     /// Reserves capacity for at least `additional` more elements to be inserted\n@@ -326,17 +303,7 @@ impl<T> Vec<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn reserve(&mut self, additional: usize) {\n-        if self.cap - self.len < additional {\n-            const ERR_MSG: &'static str  = \"Vec::reserve: `isize` overflow\";\n-\n-            let new_min_cap = self.len.checked_add(additional).expect(ERR_MSG);\n-            if new_min_cap > MAX_MEMORY_SIZE { panic!(ERR_MSG) }\n-            self.grow_capacity(match new_min_cap.checked_next_power_of_two() {\n-                Some(x) if x > MAX_MEMORY_SIZE => MAX_MEMORY_SIZE,\n-                None => MAX_MEMORY_SIZE,\n-                Some(x) => x,\n-            });\n-        }\n+        self.buf.reserve(self.len, additional);\n     }\n \n     /// Reserves the minimum capacity for exactly `additional` more elements to\n@@ -360,12 +327,7 @@ impl<T> Vec<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn reserve_exact(&mut self, additional: usize) {\n-        if self.cap - self.len < additional {\n-            match self.len.checked_add(additional) {\n-                None => panic!(\"Vec::reserve: `usize` overflow\"),\n-                Some(new_cap) => self.grow_capacity(new_cap)\n-            }\n-        }\n+        self.buf.reserve_exact(self.len, additional);\n     }\n \n     /// Shrinks the capacity of the vector as much as possible.\n@@ -384,28 +346,7 @@ impl<T> Vec<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn shrink_to_fit(&mut self) {\n-        if mem::size_of::<T>() == 0 { return }\n-\n-        if self.len == 0 {\n-            if self.cap != 0 {\n-                unsafe {\n-                    dealloc(*self.ptr, self.cap)\n-                }\n-                self.cap = 0;\n-            }\n-        } else if self.cap != self.len {\n-            unsafe {\n-                // Overflow check is unnecessary as the vector is already at\n-                // least this large.\n-                let ptr = reallocate(*self.ptr as *mut u8,\n-                                     self.cap * mem::size_of::<T>(),\n-                                     self.len * mem::size_of::<T>(),\n-                                     mem::align_of::<T>()) as *mut T;\n-                if ptr.is_null() { ::alloc::oom() }\n-                self.ptr = Unique::new(ptr);\n-            }\n-            self.cap = self.len;\n-        }\n+        self.buf.shrink_to_fit(self.len);\n     }\n \n     /// Converts the vector into Box<[T]>.\n@@ -415,11 +356,11 @@ impl<T> Vec<T> {\n     /// `shrink_to_fit()`.\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn into_boxed_slice(mut self) -> Box<[T]> {\n-        self.shrink_to_fit();\n         unsafe {\n-            let xs: Box<[T]> = Box::from_raw(&mut *self);\n+            self.shrink_to_fit();\n+            let buf = ptr::read(&self.buf);\n             mem::forget(self);\n-            xs\n+            buf.into_box()\n         }\n     }\n \n@@ -536,19 +477,20 @@ impl<T> Vec<T> {\n     pub fn insert(&mut self, index: usize, element: T) {\n         let len = self.len();\n         assert!(index <= len);\n+\n         // space for the new element\n-        self.reserve(1);\n+        if len == self.buf.cap() { self.buf.double(); }\n \n         unsafe { // infallible\n             // The spot to put the new value\n             {\n                 let p = self.as_mut_ptr().offset(index as isize);\n                 // Shift everything over to make space. (Duplicating the\n                 // `index`th element into two consecutive places.)\n-                ptr::copy(&*p, p.offset(1), len - index);\n+                ptr::copy(p, p.offset(1), len - index);\n                 // Write it in, overwriting the first copy of the `index`th\n                 // element.\n-                ptr::write(&mut *p, element);\n+                ptr::write(p, element);\n             }\n             self.set_len(len + 1);\n         }\n@@ -582,7 +524,7 @@ impl<T> Vec<T> {\n                 ret = ptr::read(ptr);\n \n                 // Shift everything down to fill in that spot.\n-                ptr::copy(&*ptr.offset(1), ptr, len - index - 1);\n+                ptr::copy(ptr.offset(1), ptr, len - index - 1);\n             }\n             self.set_len(len - 1);\n             ret\n@@ -638,38 +580,12 @@ impl<T> Vec<T> {\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn push(&mut self, value: T) {\n-        #[cold]\n-        #[inline(never)]\n-        fn resize<T>(vec: &mut Vec<T>) {\n-            let old_size = vec.cap * mem::size_of::<T>();\n-            if old_size >= MAX_MEMORY_SIZE { panic!(\"capacity overflow\") }\n-            let mut size = max(old_size, 2 * mem::size_of::<T>()) * 2;\n-            if old_size > size || size > MAX_MEMORY_SIZE {\n-                size = MAX_MEMORY_SIZE;\n-            }\n-            unsafe {\n-                let ptr = alloc_or_realloc(*vec.ptr, old_size, size);\n-                if ptr.is_null() { ::alloc::oom() }\n-                vec.ptr = Unique::new(ptr);\n-            }\n-            vec.cap = max(vec.cap, 2) * 2;\n-        }\n-\n-        if mem::size_of::<T>() == 0 {\n-            // zero-size types consume no memory, so we can't rely on the\n-            // address space running out\n-            self.len = self.len.checked_add(1).expect(\"length overflow\");\n-            mem::forget(value);\n-            return\n-        }\n-\n-        if self.len == self.cap {\n-            resize(self);\n-        }\n-\n+        // This will panic or abort if we would allocate > isize::MAX bytes\n+        // or if the length increment would overflow for zero-sized types.\n+        if self.len == self.buf.cap() { self.buf.double(); }\n         unsafe {\n-            let end = (*self.ptr).offset(self.len as isize);\n-            ptr::write(&mut *end, value);\n+            let end = self.as_mut_ptr().offset(self.len as isize);\n+            ptr::write(end, value);\n             self.len += 1;\n         }\n     }\n@@ -716,13 +632,6 @@ impl<T> Vec<T> {\n     #[unstable(feature = \"append\",\n                reason = \"new API, waiting for dust to settle\")]\n     pub fn append(&mut self, other: &mut Self) {\n-        if mem::size_of::<T>() == 0 {\n-            // zero-size types consume no memory, so we can't rely on the\n-            // address space running out\n-            self.len = self.len.checked_add(other.len()).expect(\"length overflow\");\n-            unsafe { other.set_len(0) }\n-            return;\n-        }\n         self.reserve(other.len());\n         let len = self.len();\n         unsafe {\n@@ -1274,46 +1183,6 @@ impl<T: PartialEq> Vec<T> {\n // Internal methods and functions\n ////////////////////////////////////////////////////////////////////////////////\n \n-impl<T> Vec<T> {\n-    /// Reserves capacity for exactly `capacity` elements in the given vector.\n-    ///\n-    /// If the capacity for `self` is already equal to or greater than the\n-    /// requested capacity, then no action is taken.\n-    fn grow_capacity(&mut self, capacity: usize) {\n-        if mem::size_of::<T>() == 0 { return }\n-\n-        if capacity > self.cap {\n-            let size = capacity.checked_mul(mem::size_of::<T>())\n-                               .expect(\"capacity overflow\");\n-            unsafe {\n-                let ptr = alloc_or_realloc(*self.ptr, self.cap * mem::size_of::<T>(), size);\n-                if ptr.is_null() { ::alloc::oom() }\n-                self.ptr = Unique::new(ptr);\n-            }\n-            self.cap = capacity;\n-        }\n-    }\n-}\n-\n-// FIXME: #13996: need a way to mark the return value as `noalias`\n-#[inline(never)]\n-unsafe fn alloc_or_realloc<T>(ptr: *mut T, old_size: usize, size: usize) -> *mut T {\n-    if old_size == 0 {\n-        allocate(size, mem::align_of::<T>()) as *mut T\n-    } else {\n-        reallocate(ptr as *mut u8, old_size, size, mem::align_of::<T>()) as *mut T\n-    }\n-}\n-\n-#[inline]\n-unsafe fn dealloc<T>(ptr: *mut T, len: usize) {\n-    if mem::size_of::<T>() != 0 {\n-        deallocate(ptr as *mut u8,\n-                   len * mem::size_of::<T>(),\n-                   mem::align_of::<T>())\n-    }\n-}\n-\n #[doc(hidden)]\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub fn from_elem<T: Clone>(elem: T, n: usize) -> Vec<T> {\n@@ -1463,7 +1332,7 @@ impl<T> ops::Deref for Vec<T> {\n \n     fn deref(&self) -> &[T] {\n         unsafe {\n-            let p = *self.ptr;\n+            let p = self.buf.ptr();\n             assume(p != 0 as *mut T);\n             slice::from_raw_parts(p, self.len)\n         }\n@@ -1474,7 +1343,7 @@ impl<T> ops::Deref for Vec<T> {\n impl<T> ops::DerefMut for Vec<T> {\n     fn deref_mut(&mut self) -> &mut [T] {\n         unsafe {\n-            let ptr = *self.ptr;\n+            let ptr = self.buf.ptr();\n             assume(!ptr.is_null());\n             slice::from_raw_parts_mut(ptr, self.len)\n         }\n@@ -1528,19 +1397,19 @@ impl<T> IntoIterator for Vec<T> {\n     /// }\n     /// ```\n     #[inline]\n-    fn into_iter(self) -> IntoIter<T> {\n+    fn into_iter(mut self) -> IntoIter<T> {\n         unsafe {\n-            let ptr = *self.ptr;\n+            let ptr = self.as_mut_ptr();\n             assume(!ptr.is_null());\n-            let cap = self.cap;\n             let begin = ptr as *const T;\n             let end = if mem::size_of::<T>() == 0 {\n                 arith_offset(ptr as *const i8, self.len() as isize) as *const T\n             } else {\n                 ptr.offset(self.len() as isize) as *const T\n             };\n+            let buf = ptr::read(&self.buf);\n             mem::forget(self);\n-            IntoIter { allocation: ptr, cap: cap, ptr: begin, end: end }\n+            IntoIter { buf: buf, ptr: begin, end: end }\n         }\n     }\n }\n@@ -1652,16 +1521,16 @@ impl<T: Ord> Ord for Vec<T> {\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<T> Drop for Vec<T> {\n     fn drop(&mut self) {\n-        // This is (and should always remain) a no-op if the fields are\n-        // zeroed (when moving out, because of #[unsafe_no_drop_flag]).\n-        if self.cap != 0 && self.cap != mem::POST_DROP_USIZE {\n-            unsafe {\n-                for x in self.iter() {\n-                    ptr::read(x);\n-                }\n-                dealloc(*self.ptr, self.cap)\n+        // NOTE: this is currently abusing the fact that ZSTs can't impl Drop.\n+        // Or rather, that impl'ing Drop makes them not zero-sized. This is\n+        // OK because exactly when this stops being a valid assumption, we\n+        // don't need unsafe_no_drop_flag shenanigans anymore.\n+        if self.buf.unsafe_no_drop_flag_needs_drop() {\n+            for x in self.iter_mut() {\n+                unsafe { drop_in_place(x); }\n             }\n         }\n+        // RawVec handles deallocation\n     }\n }\n \n@@ -1745,8 +1614,7 @@ impl<'a, T> IntoCow<'a, [T]> for &'a [T] where T: Clone {\n /// An iterator that moves out of a vector.\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n pub struct IntoIter<T> {\n-    allocation: *mut T, // the block of memory allocated for the vector\n-    cap: usize, // the capacity of the vector\n+    buf: RawVec<T>,\n     ptr: *const T,\n     end: *const T\n }\n@@ -1761,9 +1629,9 @@ impl<T> IntoIter<T> {\n     pub fn into_inner(mut self) -> Vec<T> {\n         unsafe {\n             for _x in self.by_ref() { }\n-            let IntoIter { allocation, cap, ptr: _ptr, end: _end } = self;\n+            let buf = ptr::read(&self.buf);\n             mem::forget(self);\n-            Vec::from_raw_parts(allocation, 0, cap)\n+            Vec { buf: buf, len: 0 }\n         }\n     }\n }\n@@ -1841,12 +1709,9 @@ impl<T> ExactSizeIterator for IntoIter<T> {}\n impl<T> Drop for IntoIter<T> {\n     fn drop(&mut self) {\n         // destroy the remaining elements\n-        if self.cap != 0 {\n-            for _x in self.by_ref() {}\n-            unsafe {\n-                dealloc(self.allocation, self.cap);\n-            }\n-        }\n+        for _x in self.by_ref() {}\n+\n+        // RawVec handles deallocation\n     }\n }\n \n@@ -1920,73 +1785,6 @@ impl<'a, T> Drop for Drain<'a, T> {\n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n impl<'a, T> ExactSizeIterator for Drain<'a, T> {}\n \n-////////////////////////////////////////////////////////////////////////////////\n-// Conversion from &[T] to &Vec<T>\n-////////////////////////////////////////////////////////////////////////////////\n-\n-/// Wrapper type providing a `&Vec<T>` reference via `Deref`.\n-#[unstable(feature = \"collections\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-pub struct DerefVec<'a, T:'a> {\n-    x: Vec<T>,\n-    l: PhantomData<&'a T>,\n-}\n-\n-#[unstable(feature = \"collections\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-#[allow(deprecated)]\n-impl<'a, T> Deref for DerefVec<'a, T> {\n-    type Target = Vec<T>;\n-\n-    fn deref<'b>(&'b self) -> &'b Vec<T> {\n-        &self.x\n-    }\n-}\n-\n-// Prevent the inner `Vec<T>` from attempting to deallocate memory.\n-#[stable(feature = \"rust1\", since = \"1.0.0\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-#[allow(deprecated)]\n-impl<'a, T> Drop for DerefVec<'a, T> {\n-    fn drop(&mut self) {\n-        self.x.len = 0;\n-        self.x.cap = 0;\n-    }\n-}\n-\n-/// Converts a slice to a wrapper type providing a `&Vec<T>` reference.\n-///\n-/// # Examples\n-///\n-/// ```\n-/// # #![feature(collections)]\n-/// use std::vec::as_vec;\n-///\n-/// // Let's pretend we have a function that requires `&Vec<i32>`\n-/// fn vec_consumer(s: &Vec<i32>) {\n-///     assert_eq!(s, &[1, 2, 3]);\n-/// }\n-///\n-/// // Provide a `&Vec<i32>` from a `&[i32]` without allocating\n-/// let values = [1, 2, 3];\n-/// vec_consumer(&as_vec(&values));\n-/// ```\n-#[unstable(feature = \"collections\")]\n-#[deprecated(since = \"1.2.0\",\n-             reason = \"replaced with deref coercions or Borrow\")]\n-#[allow(deprecated)]\n-pub fn as_vec<'a, T>(x: &'a [T]) -> DerefVec<'a, T> {\n-    unsafe {\n-        DerefVec {\n-            x: Vec::from_raw_parts(x.as_ptr() as *mut T, x.len(), x.len()),\n-            l: PhantomData,\n-        }\n-    }\n-}\n-\n ////////////////////////////////////////////////////////////////////////////////\n // Partial vec, used for map_in_place\n ////////////////////////////////////////////////////////////////////////////////"}, {"sha": "664fb506784147ebccf6d653047ec627fea19fd7", "filename": "src/libcollections/vec_deque.rs", "status": "modified", "additions": 130, "deletions": 153, "changes": 283, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fvec_deque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollections%2Fvec_deque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fvec_deque.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -23,15 +23,14 @@ use core::prelude::*;\n use core::cmp::Ordering;\n use core::fmt;\n use core::iter::{self, repeat, FromIterator, RandomAccessIterator};\n-use core::mem;\n use core::ops::{Index, IndexMut};\n-use core::ptr::{self, Unique};\n+use core::ptr;\n use core::slice;\n \n use core::hash::{Hash, Hasher};\n use core::cmp;\n \n-use alloc::heap;\n+use alloc::raw_vec::RawVec;\n \n const INITIAL_CAPACITY: usize = 7; // 2^3 - 1\n const MINIMUM_CAPACITY: usize = 1; // 2 - 1\n@@ -52,8 +51,7 @@ pub struct VecDeque<T> {\n \n     tail: usize,\n     head: usize,\n-    cap: usize,\n-    ptr: Unique<T>,\n+    buf: RawVec<T>,\n }\n \n #[stable(feature = \"rust1\", since = \"1.0.0\")]\n@@ -67,13 +65,7 @@ impl<T: Clone> Clone for VecDeque<T> {\n impl<T> Drop for VecDeque<T> {\n     fn drop(&mut self) {\n         self.clear();\n-        unsafe {\n-            if mem::size_of::<T>() != 0 {\n-                heap::deallocate(*self.ptr as *mut u8,\n-                                 self.cap * mem::size_of::<T>(),\n-                                 mem::align_of::<T>())\n-            }\n-        }\n+        // RawVec handles deallocation\n     }\n }\n \n@@ -84,78 +76,127 @@ impl<T> Default for VecDeque<T> {\n }\n \n impl<T> VecDeque<T> {\n+    /// Marginally more convenient\n+    #[inline]\n+    fn ptr(&self) -> *mut T {\n+        self.buf.ptr()\n+    }\n+\n+    /// Marginally more convenient\n+    #[inline]\n+    fn cap(&self) -> usize {\n+        self.buf.cap()\n+    }\n+\n     /// Turn ptr into a slice\n     #[inline]\n     unsafe fn buffer_as_slice(&self) -> &[T] {\n-        slice::from_raw_parts(*self.ptr, self.cap)\n+        slice::from_raw_parts(self.ptr(), self.cap())\n     }\n \n     /// Turn ptr into a mut slice\n     #[inline]\n     unsafe fn buffer_as_mut_slice(&mut self) -> &mut [T] {\n-        slice::from_raw_parts_mut(*self.ptr, self.cap)\n+        slice::from_raw_parts_mut(self.ptr(), self.cap())\n     }\n \n     /// Moves an element out of the buffer\n     #[inline]\n     unsafe fn buffer_read(&mut self, off: usize) -> T {\n-        ptr::read(self.ptr.offset(off as isize))\n+        ptr::read(self.ptr().offset(off as isize))\n     }\n \n     /// Writes an element into the buffer, moving it.\n     #[inline]\n     unsafe fn buffer_write(&mut self, off: usize, t: T) {\n-        ptr::write(self.ptr.offset(off as isize), t);\n+        ptr::write(self.ptr().offset(off as isize), t);\n     }\n \n     /// Returns true if and only if the buffer is at capacity\n     #[inline]\n-    fn is_full(&self) -> bool { self.cap - self.len() == 1 }\n+    fn is_full(&self) -> bool { self.cap() - self.len() == 1 }\n \n     /// Returns the index in the underlying buffer for a given logical element\n     /// index.\n     #[inline]\n-    fn wrap_index(&self, idx: usize) -> usize { wrap_index(idx, self.cap) }\n+    fn wrap_index(&self, idx: usize) -> usize { wrap_index(idx, self.cap()) }\n \n     /// Returns the index in the underlying buffer for a given logical element\n     /// index + addend.\n     #[inline]\n     fn wrap_add(&self, idx: usize, addend: usize) -> usize {\n-        wrap_index(idx.wrapping_add(addend), self.cap)\n+        wrap_index(idx.wrapping_add(addend), self.cap())\n     }\n \n     /// Returns the index in the underlying buffer for a given logical element\n     /// index - subtrahend.\n     #[inline]\n     fn wrap_sub(&self, idx: usize, subtrahend: usize) -> usize {\n-        wrap_index(idx.wrapping_sub(subtrahend), self.cap)\n+        wrap_index(idx.wrapping_sub(subtrahend), self.cap())\n     }\n \n     /// Copies a contiguous block of memory len long from src to dst\n     #[inline]\n     unsafe fn copy(&self, dst: usize, src: usize, len: usize) {\n-        debug_assert!(dst + len <= self.cap, \"dst={} src={} len={} cap={}\", dst, src, len,\n-                      self.cap);\n-        debug_assert!(src + len <= self.cap, \"dst={} src={} len={} cap={}\", dst, src, len,\n-                      self.cap);\n+        debug_assert!(dst + len <= self.cap(), \"dst={} src={} len={} cap={}\", dst, src, len,\n+                      self.cap());\n+        debug_assert!(src + len <= self.cap(), \"dst={} src={} len={} cap={}\", dst, src, len,\n+                      self.cap());\n         ptr::copy(\n-            self.ptr.offset(src as isize),\n-            self.ptr.offset(dst as isize),\n+            self.ptr().offset(src as isize),\n+            self.ptr().offset(dst as isize),\n             len);\n     }\n \n     /// Copies a contiguous block of memory len long from src to dst\n     #[inline]\n     unsafe fn copy_nonoverlapping(&self, dst: usize, src: usize, len: usize) {\n-        debug_assert!(dst + len <= self.cap, \"dst={} src={} len={} cap={}\", dst, src, len,\n-                      self.cap);\n-        debug_assert!(src + len <= self.cap, \"dst={} src={} len={} cap={}\", dst, src, len,\n-                      self.cap);\n+        debug_assert!(dst + len <= self.cap(), \"dst={} src={} len={} cap={}\", dst, src, len,\n+                      self.cap());\n+        debug_assert!(src + len <= self.cap(), \"dst={} src={} len={} cap={}\", dst, src, len,\n+                      self.cap());\n         ptr::copy_nonoverlapping(\n-            self.ptr.offset(src as isize),\n-            self.ptr.offset(dst as isize),\n+            self.ptr().offset(src as isize),\n+            self.ptr().offset(dst as isize),\n             len);\n     }\n+\n+    /// Frobs the head and tail sections around to handle the fact that we\n+    /// just reallocated. Unsafe because it trusts old_cap.\n+    #[inline]\n+    unsafe fn handle_cap_increase(&mut self, old_cap: usize) {\n+        let new_cap = self.cap();\n+\n+        // Move the shortest contiguous section of the ring buffer\n+        //    T             H\n+        //   [o o o o o o o . ]\n+        //    T             H\n+        // A [o o o o o o o . . . . . . . . . ]\n+        //        H T\n+        //   [o o . o o o o o ]\n+        //          T             H\n+        // B [. . . o o o o o o o . . . . . . ]\n+        //              H T\n+        //   [o o o o o . o o ]\n+        //              H                 T\n+        // C [o o o o o . . . . . . . . . o o ]\n+\n+        if self.tail <= self.head { // A\n+            // Nop\n+        } else if self.head < old_cap - self.tail { // B\n+            self.copy_nonoverlapping(old_cap, 0, self.head);\n+            self.head += old_cap;\n+            debug_assert!(self.head > self.tail);\n+        } else { // C\n+            let new_tail = new_cap - (old_cap - self.tail);\n+            self.copy_nonoverlapping(new_tail, self.tail, old_cap - self.tail);\n+            self.tail = new_tail;\n+            debug_assert!(self.head < self.tail);\n+        }\n+        debug_assert!(self.head < self.cap());\n+        debug_assert!(self.tail < self.cap());\n+        debug_assert!(self.cap().count_ones() == 1);\n+    }\n }\n \n impl<T> VecDeque<T> {\n@@ -171,24 +212,11 @@ impl<T> VecDeque<T> {\n         // +1 since the ringbuffer always leaves one space empty\n         let cap = cmp::max(n + 1, MINIMUM_CAPACITY + 1).next_power_of_two();\n         assert!(cap > n, \"capacity overflow\");\n-        let size = cap.checked_mul(mem::size_of::<T>())\n-                      .expect(\"capacity overflow\");\n-\n-        let ptr = unsafe {\n-            if mem::size_of::<T>() != 0 {\n-                let ptr = heap::allocate(size, mem::align_of::<T>())  as *mut T;;\n-                if ptr.is_null() { ::alloc::oom() }\n-                Unique::new(ptr)\n-            } else {\n-                Unique::new(heap::EMPTY as *mut T)\n-            }\n-        };\n \n         VecDeque {\n             tail: 0,\n             head: 0,\n-            cap: cap,\n-            ptr: ptr,\n+            buf: RawVec::with_capacity(cap),\n         }\n     }\n \n@@ -209,7 +237,7 @@ impl<T> VecDeque<T> {\n     pub fn get(&self, i: usize) -> Option<&T> {\n         if i < self.len() {\n             let idx = self.wrap_add(self.tail, i);\n-            unsafe { Some(&*self.ptr.offset(idx as isize)) }\n+            unsafe { Some(&*self.ptr().offset(idx as isize)) }\n         } else {\n             None\n         }\n@@ -236,7 +264,7 @@ impl<T> VecDeque<T> {\n     pub fn get_mut(&mut self, i: usize) -> Option<&mut T> {\n         if i < self.len() {\n             let idx = self.wrap_add(self.tail, i);\n-            unsafe { Some(&mut *self.ptr.offset(idx as isize)) }\n+            unsafe { Some(&mut *self.ptr().offset(idx as isize)) }\n         } else {\n             None\n         }\n@@ -268,7 +296,7 @@ impl<T> VecDeque<T> {\n         let ri = self.wrap_add(self.tail, i);\n         let rj = self.wrap_add(self.tail, j);\n         unsafe {\n-            ptr::swap(self.ptr.offset(ri as isize), self.ptr.offset(rj as isize))\n+            ptr::swap(self.ptr().offset(ri as isize), self.ptr().offset(rj as isize))\n         }\n     }\n \n@@ -285,7 +313,7 @@ impl<T> VecDeque<T> {\n     /// ```\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    pub fn capacity(&self) -> usize { self.cap - 1 }\n+    pub fn capacity(&self) -> usize { self.cap() - 1 }\n \n     /// Reserves the minimum capacity for exactly `additional` more elements to be inserted in the\n     /// given `VecDeque`. Does nothing if the capacity is already sufficient.\n@@ -330,62 +358,16 @@ impl<T> VecDeque<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn reserve(&mut self, additional: usize) {\n-        let new_len = self.len() + additional;\n-        assert!(new_len + 1 > self.len(), \"capacity overflow\");\n-        if new_len > self.capacity() {\n-            let count = (new_len + 1).next_power_of_two();\n-            assert!(count >= new_len + 1);\n-\n-            if mem::size_of::<T>() != 0 {\n-                let old = self.cap * mem::size_of::<T>();\n-                let new = count.checked_mul(mem::size_of::<T>())\n-                               .expect(\"capacity overflow\");\n-                unsafe {\n-                    let ptr = heap::reallocate(*self.ptr as *mut u8,\n-                                               old,\n-                                               new,\n-                                               mem::align_of::<T>()) as *mut T;\n-                    if ptr.is_null() { ::alloc::oom() }\n-                    self.ptr = Unique::new(ptr);\n-                }\n-            }\n-\n-            // Move the shortest contiguous section of the ring buffer\n-            //    T             H\n-            //   [o o o o o o o . ]\n-            //    T             H\n-            // A [o o o o o o o . . . . . . . . . ]\n-            //        H T\n-            //   [o o . o o o o o ]\n-            //          T             H\n-            // B [. . . o o o o o o o . . . . . . ]\n-            //              H T\n-            //   [o o o o o . o o ]\n-            //              H                 T\n-            // C [o o o o o . . . . . . . . . o o ]\n-\n-            let oldcap = self.cap;\n-            self.cap = count;\n-\n-            if self.tail <= self.head { // A\n-                // Nop\n-            } else if self.head < oldcap - self.tail { // B\n-                unsafe {\n-                    self.copy_nonoverlapping(oldcap, 0, self.head);\n-                }\n-                self.head += oldcap;\n-                debug_assert!(self.head > self.tail);\n-            } else { // C\n-                let new_tail = count - (oldcap - self.tail);\n-                unsafe {\n-                    self.copy_nonoverlapping(new_tail, self.tail, oldcap - self.tail);\n-                }\n-                self.tail = new_tail;\n-                debug_assert!(self.head < self.tail);\n-            }\n-            debug_assert!(self.head < self.cap);\n-            debug_assert!(self.tail < self.cap);\n-            debug_assert!(self.cap.count_ones() == 1);\n+        let old_cap = self.cap();\n+        let used_cap = self.len() + 1;\n+        let new_cap = used_cap\n+            .checked_add(additional)\n+            .and_then(|needed_cap| needed_cap.checked_next_power_of_two())\n+            .expect(\"capacity overflow\");\n+\n+        if new_cap > self.capacity() {\n+            self.buf.reserve_exact(used_cap, new_cap - used_cap);\n+            unsafe { self.handle_cap_increase(old_cap); }\n         }\n     }\n \n@@ -410,7 +392,7 @@ impl<T> VecDeque<T> {\n         // +1 since the ringbuffer always leaves one space empty\n         // len + 1 can't overflow for an existing, well-formed ringbuffer.\n         let target_cap = cmp::max(self.len() + 1, MINIMUM_CAPACITY + 1).next_power_of_two();\n-        if target_cap < self.cap {\n+        if target_cap < self.cap() {\n             // There are three cases of interest:\n             //   All elements are out of desired bounds\n             //   Elements are contiguous, and head is out of desired bounds\n@@ -448,7 +430,7 @@ impl<T> VecDeque<T> {\n                 //              H T\n                 //   [o o o o o . o o ]\n                 debug_assert!(self.wrap_sub(self.head, 1) < target_cap);\n-                let len = self.cap - self.tail;\n+                let len = self.cap() - self.tail;\n                 let new_tail = target_cap - len;\n                 unsafe {\n                     self.copy_nonoverlapping(new_tail, self.tail, len);\n@@ -457,22 +439,11 @@ impl<T> VecDeque<T> {\n                 debug_assert!(self.head < self.tail);\n             }\n \n-            if mem::size_of::<T>() != 0 {\n-                let old = self.cap * mem::size_of::<T>();\n-                let new_size = target_cap * mem::size_of::<T>();\n-                unsafe {\n-                    let ptr = heap::reallocate(*self.ptr as *mut u8,\n-                                               old,\n-                                               new_size,\n-                                               mem::align_of::<T>()) as *mut T;\n-                    if ptr.is_null() { ::alloc::oom() }\n-                    self.ptr = Unique::new(ptr);\n-                }\n-            }\n-            self.cap = target_cap;\n-            debug_assert!(self.head < self.cap);\n-            debug_assert!(self.tail < self.cap);\n-            debug_assert!(self.cap.count_ones() == 1);\n+            self.buf.shrink_to_fit(target_cap);\n+\n+            debug_assert!(self.head < self.cap());\n+            debug_assert!(self.tail < self.cap());\n+            debug_assert!(self.cap().count_ones() == 1);\n         }\n     }\n \n@@ -610,7 +581,7 @@ impl<T> VecDeque<T> {\n     /// assert_eq!(v.len(), 1);\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n-    pub fn len(&self) -> usize { count(self.tail, self.head, self.cap) }\n+    pub fn len(&self) -> usize { count(self.tail, self.head, self.cap()) }\n \n     /// Returns true if the buffer contains no elements\n     ///\n@@ -799,7 +770,9 @@ impl<T> VecDeque<T> {\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn push_front(&mut self, t: T) {\n         if self.is_full() {\n-            self.reserve(1);\n+            let old_cap = self.cap();\n+            self.buf.double();\n+            unsafe { self.handle_cap_increase(old_cap); }\n             debug_assert!(!self.is_full());\n         }\n \n@@ -823,7 +796,9 @@ impl<T> VecDeque<T> {\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub fn push_back(&mut self, t: T) {\n         if self.is_full() {\n-            self.reserve(1);\n+            let old_cap = self.cap();\n+            self.buf.double();\n+            unsafe { self.handle_cap_increase(old_cap); }\n             debug_assert!(!self.is_full());\n         }\n \n@@ -952,7 +927,9 @@ impl<T> VecDeque<T> {\n     pub fn insert(&mut self, i: usize, t: T) {\n         assert!(i <= self.len(), \"index out of bounds\");\n         if self.is_full() {\n-            self.reserve(1);\n+            let old_cap = self.cap();\n+            self.buf.double();\n+            unsafe { self.handle_cap_increase(old_cap); }\n             debug_assert!(!self.is_full());\n         }\n \n@@ -1067,10 +1044,10 @@ impl<T> VecDeque<T> {\n                 self.copy(1, 0, self.head);\n \n                 // copy last element into empty spot at bottom of buffer\n-                self.copy(0, self.cap - 1, 1);\n+                self.copy(0, self.cap() - 1, 1);\n \n                 // move elements from idx to end forward not including ^ element\n-                self.copy(idx + 1, idx, self.cap - 1 - idx);\n+                self.copy(idx + 1, idx, self.cap() - 1 - idx);\n \n                 self.head += 1;\n             },\n@@ -1086,10 +1063,10 @@ impl<T> VecDeque<T> {\n                 //                               M M M\n \n                 // copy elements up to new tail\n-                self.copy(self.tail - 1, self.tail, self.cap - self.tail);\n+                self.copy(self.tail - 1, self.tail, self.cap() - self.tail);\n \n                 // copy last element into empty spot at bottom of buffer\n-                self.copy(self.cap - 1, 0, 1);\n+                self.copy(self.cap() - 1, 0, 1);\n \n                 self.tail -= 1;\n             },\n@@ -1104,10 +1081,10 @@ impl<T> VecDeque<T> {\n                 //       M M                     M M M M\n \n                 // copy elements up to new tail\n-                self.copy(self.tail - 1, self.tail, self.cap - self.tail);\n+                self.copy(self.tail - 1, self.tail, self.cap() - self.tail);\n \n                 // copy last element into empty spot at bottom of buffer\n-                self.copy(self.cap - 1, 0, 1);\n+                self.copy(self.cap() - 1, 0, 1);\n \n                 // move elements from idx-1 to end forward not including ^ element\n                 self.copy(0, 1, idx - 1);\n@@ -1261,12 +1238,12 @@ impl<T> VecDeque<T> {\n                 //                                   M\n \n                 // draw in elements in the tail section\n-                self.copy(idx, idx + 1, self.cap - idx - 1);\n+                self.copy(idx, idx + 1, self.cap() - idx - 1);\n \n                 // Prevents underflow.\n                 if self.head != 0 {\n                     // copy first element into empty spot\n-                    self.copy(self.cap - 1, 0, 1);\n+                    self.copy(self.cap() - 1, 0, 1);\n \n                     // move elements in the head section backwards\n                     self.copy(0, 1, self.head - 1);\n@@ -1288,10 +1265,10 @@ impl<T> VecDeque<T> {\n                 self.copy(1, 0, idx);\n \n                 // copy last element into empty spot\n-                self.copy(0, self.cap - 1, 1);\n+                self.copy(0, self.cap() - 1, 1);\n \n                 // move elements from tail to end forward, excluding the last one\n-                self.copy(self.tail + 1, self.tail, self.cap - self.tail - 1);\n+                self.copy(self.tail + 1, self.tail, self.cap() - self.tail - 1);\n \n                 self.tail = self.wrap_add(self.tail, 1);\n             }\n@@ -1343,20 +1320,20 @@ impl<T> VecDeque<T> {\n                 let amount_in_first = first_len - at;\n \n                 ptr::copy_nonoverlapping(first_half.as_ptr().offset(at as isize),\n-                                         *other.ptr,\n+                                         other.ptr(),\n                                          amount_in_first);\n \n                 // just take all of the second half.\n                 ptr::copy_nonoverlapping(second_half.as_ptr(),\n-                                         other.ptr.offset(amount_in_first as isize),\n+                                         other.ptr().offset(amount_in_first as isize),\n                                          second_len);\n             } else {\n                 // `at` lies in the second half, need to factor in the elements we skipped\n                 // in the first half.\n                 let offset = at - first_len;\n                 let amount_in_second = second_len - offset;\n                 ptr::copy_nonoverlapping(second_half.as_ptr().offset(offset as isize),\n-                                         *other.ptr,\n+                                         other.ptr(),\n                                          amount_in_second);\n             }\n         }\n@@ -1904,8 +1881,8 @@ mod tests {\n                             assert_eq!(tester.swap_front_remove(idx), Some(len * 2 - 1 - i));\n                         }\n                     }\n-                    assert!(tester.tail < tester.cap);\n-                    assert!(tester.head < tester.cap);\n+                    assert!(tester.tail < tester.cap());\n+                    assert!(tester.head < tester.cap());\n                     assert_eq!(tester, expected);\n                 }\n             }\n@@ -1940,8 +1917,8 @@ mod tests {\n                         }\n                     }\n                     tester.insert(to_insert, to_insert);\n-                    assert!(tester.tail < tester.cap);\n-                    assert!(tester.head < tester.cap);\n+                    assert!(tester.tail < tester.cap());\n+                    assert!(tester.head < tester.cap());\n                     assert_eq!(tester, expected);\n                 }\n             }\n@@ -1977,8 +1954,8 @@ mod tests {\n                         tester.push_back(1234);\n                     }\n                     tester.remove(to_remove);\n-                    assert!(tester.tail < tester.cap);\n-                    assert!(tester.head < tester.cap);\n+                    assert!(tester.tail < tester.cap());\n+                    assert!(tester.head < tester.cap());\n                     assert_eq!(tester, expected);\n                 }\n             }\n@@ -2010,8 +1987,8 @@ mod tests {\n                 }\n                 tester.shrink_to_fit();\n                 assert!(tester.capacity() <= cap);\n-                assert!(tester.tail < tester.cap);\n-                assert!(tester.head < tester.cap);\n+                assert!(tester.tail < tester.cap());\n+                assert!(tester.head < tester.cap());\n                 assert_eq!(tester, expected);\n             }\n         }\n@@ -2044,10 +2021,10 @@ mod tests {\n                         tester.push_back(i);\n                     }\n                     let result = tester.split_off(at);\n-                    assert!(tester.tail < tester.cap);\n-                    assert!(tester.head < tester.cap);\n-                    assert!(result.tail < result.cap);\n-                    assert!(result.head < result.cap);\n+                    assert!(tester.tail < tester.cap());\n+                    assert!(tester.head < tester.cap());\n+                    assert!(result.tail < result.cap());\n+                    assert!(result.head < result.cap());\n                     assert_eq!(tester, expected_self);\n                     assert_eq!(result, expected_other);\n                 }"}, {"sha": "80283741cccdf5d44d7481a52d2996c82eb91caa", "filename": "src/libcollectionstest/string.rs", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollectionstest%2Fstring.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollectionstest%2Fstring.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollectionstest%2Fstring.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -10,18 +10,9 @@\n \n use std::borrow::{IntoCow, Cow};\n use std::iter::repeat;\n-#[allow(deprecated)]\n-use std::string::as_string;\n \n use test::Bencher;\n \n-#[test]\n-#[allow(deprecated)]\n-fn test_as_string() {\n-    let x = \"foo\";\n-    assert_eq!(x, &**as_string(x));\n-}\n-\n #[test]\n fn test_from_str() {\n   let owned: Option<::std::string::String> = \"string\".parse().ok();"}, {"sha": "7b340dc5be42ae2cf20c119bd1549bc37bd99075", "filename": "src/libcollectionstest/vec.rs", "status": "modified", "additions": 0, "deletions": 21, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollectionstest%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfa0e1f58acf1c28d500c34ed258f09ae021893e/src%2Flibcollectionstest%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollectionstest%2Fvec.rs?ref=bfa0e1f58acf1c28d500c34ed258f09ae021893e", "patch": "@@ -10,8 +10,6 @@\n \n use std::iter::{FromIterator, repeat};\n use std::mem::size_of;\n-#[allow(deprecated)]\n-use std::vec::as_vec;\n \n use test::Bencher;\n \n@@ -25,25 +23,6 @@ impl<'a> Drop for DropCounter<'a> {\n     }\n }\n \n-#[test]\n-#[allow(deprecated)]\n-fn test_as_vec() {\n-    let xs = [1u8, 2u8, 3u8];\n-    assert_eq!(&**as_vec(&xs), xs);\n-}\n-\n-#[test]\n-#[allow(deprecated)]\n-fn test_as_vec_dtor() {\n-    let (mut count_x, mut count_y) = (0, 0);\n-    {\n-        let xs = &[DropCounter { count: &mut count_x }, DropCounter { count: &mut count_y }];\n-        assert_eq!(as_vec(xs).len(), 2);\n-    }\n-    assert_eq!(count_x, 1);\n-    assert_eq!(count_y, 1);\n-}\n-\n #[test]\n fn test_small_vec_struct() {\n     assert!(size_of::<Vec<u8>>() == size_of::<usize>() * 3);"}]}