{"sha": "78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "node_id": "C_kwDOAAsO6NoAKDc4Y2MxMTdmN2JiOTk0ZjQ5YzdmOWI1OGRjZjc4MDdiMThkNjllMjg", "commit": {"author": {"name": "Matthias Kr\u00fcger", "email": "matthias.krueger@famsik.de", "date": "2023-05-26T06:24:07Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2023-05-26T06:24:07Z"}, "message": "Rollup merge of #111899 - nnethercote:cgu-cleanups, r=wesleywiser\n\nCGU cleanups\n\nSome code clarity improvements I found when reading this code closely.\n\nr? ``@wesleywiser``", "tree": {"sha": "968ea521e9ee62d2977397bf8aeb2dc00fc159f8", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/968ea521e9ee62d2977397bf8aeb2dc00fc159f8"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJkcFCHCRBK7hj4Ov3rIwAAhBcIABqTG4yDIyWT6KMQPq2IqTqV\nVMUlf8GK7ub/zrc0GYc06ZM7En/Qlm2zzmwDOgyNWzvzADHc6qHs17rWwjpkgaz2\nNDI6idazHbt1o0oykf/r0L6UuYVvOTg1F5Mx99cY6356+pr7E1C+fpLcgEvNFV5U\nNCNqI2hheQ+neUzlLFtnIXkXgjUz1q5y+FbQMOA53M/KN/vjY5rkTmg9nOxu1Q7B\nAGHFa8NM83AUwKuMKLp3nl4OdoYADhUxZMedMd61MQl7QtEOQHhCVn/7+lQXNmDD\ndNnuGrqbFJjIKKRjw/YmZccxqESPLZTtQBa0G4OYfr5JpmLX9nryiRI1+2Kn0LY=\n=a+V2\n-----END PGP SIGNATURE-----\n", "payload": "tree 968ea521e9ee62d2977397bf8aeb2dc00fc159f8\nparent 42c7b8a7de4a90d9d040f7132403d49bc6783032\nparent e6b99a6521535d79a53b2111f236f82fae0b123e\nauthor Matthias Kr\u00fcger <matthias.krueger@famsik.de> 1685082247 +0200\ncommitter GitHub <noreply@github.com> 1685082247 +0200\n\nRollup merge of #111899 - nnethercote:cgu-cleanups, r=wesleywiser\n\nCGU cleanups\n\nSome code clarity improvements I found when reading this code closely.\n\nr? ``@wesleywiser``\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "html_url": "https://github.com/rust-lang/rust/commit/78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/comments", "author": {"login": "matthiaskrgr", "id": 476013, "node_id": "MDQ6VXNlcjQ3NjAxMw==", "avatar_url": "https://avatars.githubusercontent.com/u/476013?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matthiaskrgr", "html_url": "https://github.com/matthiaskrgr", "followers_url": "https://api.github.com/users/matthiaskrgr/followers", "following_url": "https://api.github.com/users/matthiaskrgr/following{/other_user}", "gists_url": "https://api.github.com/users/matthiaskrgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/matthiaskrgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matthiaskrgr/subscriptions", "organizations_url": "https://api.github.com/users/matthiaskrgr/orgs", "repos_url": "https://api.github.com/users/matthiaskrgr/repos", "events_url": "https://api.github.com/users/matthiaskrgr/events{/privacy}", "received_events_url": "https://api.github.com/users/matthiaskrgr/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "42c7b8a7de4a90d9d040f7132403d49bc6783032", "url": "https://api.github.com/repos/rust-lang/rust/commits/42c7b8a7de4a90d9d040f7132403d49bc6783032", "html_url": "https://github.com/rust-lang/rust/commit/42c7b8a7de4a90d9d040f7132403d49bc6783032"}, {"sha": "e6b99a6521535d79a53b2111f236f82fae0b123e", "url": "https://api.github.com/repos/rust-lang/rust/commits/e6b99a6521535d79a53b2111f236f82fae0b123e", "html_url": "https://github.com/rust-lang/rust/commit/e6b99a6521535d79a53b2111f236f82fae0b123e"}], "stats": {"total": 375, "additions": 169, "deletions": 206}, "files": [{"sha": "f31b343c94704bc2ba3bbf22483d1209eb67c29c", "filename": "compiler/rustc_middle/src/mir/mono.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmono.rs", "raw_url": "https://github.com/rust-lang/rust/raw/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmono.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_middle%2Fsrc%2Fmir%2Fmono.rs?ref=78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "patch": "@@ -334,10 +334,7 @@ impl<'tcx> CodegenUnit<'tcx> {\n     }\n \n     pub fn modify_size_estimate(&mut self, delta: usize) {\n-        assert!(self.size_estimate.is_some());\n-        if let Some(size_estimate) = self.size_estimate {\n-            self.size_estimate = Some(size_estimate + delta);\n-        }\n+        *self.size_estimate.as_mut().unwrap() += delta;\n     }\n \n     pub fn contains_item(&self, item: &MonoItem<'tcx>) -> bool {"}, {"sha": "603b3ddc106e931ea2864506243a43b35fd9e819", "filename": "compiler/rustc_monomorphize/src/partitioning/default.rs", "status": "modified", "additions": 113, "deletions": 37, "changes": 150, "blob_url": "https://github.com/rust-lang/rust/blob/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fdefault.rs", "raw_url": "https://github.com/rust-lang/rust/raw/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fdefault.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fdefault.rs?ref=78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "patch": "@@ -1,3 +1,4 @@\n+use std::cmp;\n use std::collections::hash_map::Entry;\n \n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n@@ -14,10 +15,7 @@ use rustc_span::symbol::Symbol;\n \n use super::PartitioningCx;\n use crate::collector::InliningMap;\n-use crate::partitioning::merging;\n-use crate::partitioning::{\n-    MonoItemPlacement, Partition, PostInliningPartitioning, PreInliningPartitioning,\n-};\n+use crate::partitioning::{MonoItemPlacement, Partition, PlacedRootMonoItems};\n \n pub struct DefaultPartitioning;\n \n@@ -26,7 +24,7 @@ impl<'tcx> Partition<'tcx> for DefaultPartitioning {\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n         mono_items: &mut I,\n-    ) -> PreInliningPartitioning<'tcx>\n+    ) -> PlacedRootMonoItems<'tcx>\n     where\n         I: Iterator<Item = MonoItem<'tcx>>,\n     {\n@@ -91,38 +89,120 @@ impl<'tcx> Partition<'tcx> for DefaultPartitioning {\n             codegen_units.insert(codegen_unit_name, CodegenUnit::new(codegen_unit_name));\n         }\n \n-        PreInliningPartitioning {\n-            codegen_units: codegen_units.into_values().collect(),\n-            roots,\n-            internalization_candidates,\n-        }\n+        let codegen_units = codegen_units.into_values().collect();\n+        PlacedRootMonoItems { codegen_units, roots, internalization_candidates }\n     }\n \n     fn merge_codegen_units(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: &mut PreInliningPartitioning<'tcx>,\n+        codegen_units: &mut Vec<CodegenUnit<'tcx>>,\n     ) {\n-        merging::merge_codegen_units(cx, initial_partitioning);\n+        assert!(cx.target_cgu_count >= 1);\n+\n+        // Note that at this point in time the `codegen_units` here may not be\n+        // in a deterministic order (but we know they're deterministically the\n+        // same set). We want this merging to produce a deterministic ordering\n+        // of codegen units from the input.\n+        //\n+        // Due to basically how we've implemented the merging below (merge the\n+        // two smallest into each other) we're sure to start off with a\n+        // deterministic order (sorted by name). This'll mean that if two cgus\n+        // have the same size the stable sort below will keep everything nice\n+        // and deterministic.\n+        codegen_units.sort_by(|a, b| a.name().as_str().cmp(b.name().as_str()));\n+\n+        // This map keeps track of what got merged into what.\n+        let mut cgu_contents: FxHashMap<Symbol, Vec<Symbol>> =\n+            codegen_units.iter().map(|cgu| (cgu.name(), vec![cgu.name()])).collect();\n+\n+        // Merge the two smallest codegen units until the target size is\n+        // reached.\n+        while codegen_units.len() > cx.target_cgu_count {\n+            // Sort small cgus to the back\n+            codegen_units.sort_by_cached_key(|cgu| cmp::Reverse(cgu.size_estimate()));\n+            let mut smallest = codegen_units.pop().unwrap();\n+            let second_smallest = codegen_units.last_mut().unwrap();\n+\n+            // Move the mono-items from `smallest` to `second_smallest`\n+            second_smallest.modify_size_estimate(smallest.size_estimate());\n+            for (k, v) in smallest.items_mut().drain() {\n+                second_smallest.items_mut().insert(k, v);\n+            }\n+\n+            // Record that `second_smallest` now contains all the stuff that was\n+            // in `smallest` before.\n+            let mut consumed_cgu_names = cgu_contents.remove(&smallest.name()).unwrap();\n+            cgu_contents.get_mut(&second_smallest.name()).unwrap().append(&mut consumed_cgu_names);\n+\n+            debug!(\n+                \"CodegenUnit {} merged into CodegenUnit {}\",\n+                smallest.name(),\n+                second_smallest.name()\n+            );\n+        }\n+\n+        let cgu_name_builder = &mut CodegenUnitNameBuilder::new(cx.tcx);\n+\n+        if cx.tcx.sess.opts.incremental.is_some() {\n+            // If we are doing incremental compilation, we want CGU names to\n+            // reflect the path of the source level module they correspond to.\n+            // For CGUs that contain the code of multiple modules because of the\n+            // merging done above, we use a concatenation of the names of all\n+            // contained CGUs.\n+            let new_cgu_names: FxHashMap<Symbol, String> = cgu_contents\n+                .into_iter()\n+                // This `filter` makes sure we only update the name of CGUs that\n+                // were actually modified by merging.\n+                .filter(|(_, cgu_contents)| cgu_contents.len() > 1)\n+                .map(|(current_cgu_name, cgu_contents)| {\n+                    let mut cgu_contents: Vec<&str> =\n+                        cgu_contents.iter().map(|s| s.as_str()).collect();\n+\n+                    // Sort the names, so things are deterministic and easy to\n+                    // predict. We are sorting primitive `&str`s here so we can\n+                    // use unstable sort.\n+                    cgu_contents.sort_unstable();\n+\n+                    (current_cgu_name, cgu_contents.join(\"--\"))\n+                })\n+                .collect();\n+\n+            for cgu in codegen_units.iter_mut() {\n+                if let Some(new_cgu_name) = new_cgu_names.get(&cgu.name()) {\n+                    if cx.tcx.sess.opts.unstable_opts.human_readable_cgu_names {\n+                        cgu.set_name(Symbol::intern(&new_cgu_name));\n+                    } else {\n+                        // If we don't require CGU names to be human-readable,\n+                        // we use a fixed length hash of the composite CGU name\n+                        // instead.\n+                        let new_cgu_name = CodegenUnit::mangle_name(&new_cgu_name);\n+                        cgu.set_name(Symbol::intern(&new_cgu_name));\n+                    }\n+                }\n+            }\n+        } else {\n+            // If we are compiling non-incrementally we just generate simple CGU\n+            // names containing an index.\n+            for (index, cgu) in codegen_units.iter_mut().enumerate() {\n+                let numbered_codegen_unit_name =\n+                    cgu_name_builder.build_cgu_name_no_mangle(LOCAL_CRATE, &[\"cgu\"], Some(index));\n+                cgu.set_name(numbered_codegen_unit_name);\n+            }\n+        }\n     }\n \n     fn place_inlined_mono_items(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: PreInliningPartitioning<'tcx>,\n-    ) -> PostInliningPartitioning<'tcx> {\n-        let mut new_partitioning = Vec::new();\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        roots: FxHashSet<MonoItem<'tcx>>,\n+    ) -> FxHashMap<MonoItem<'tcx>, MonoItemPlacement> {\n         let mut mono_item_placements = FxHashMap::default();\n \n-        let PreInliningPartitioning {\n-            codegen_units: initial_cgus,\n-            roots,\n-            internalization_candidates,\n-        } = initial_partitioning;\n-\n-        let single_codegen_unit = initial_cgus.len() == 1;\n+        let single_codegen_unit = codegen_units.len() == 1;\n \n-        for old_codegen_unit in initial_cgus {\n+        for old_codegen_unit in codegen_units.iter_mut() {\n             // Collect all items that need to be available in this codegen unit.\n             let mut reachable = FxHashSet::default();\n             for root in old_codegen_unit.items().keys() {\n@@ -174,14 +254,10 @@ impl<'tcx> Partition<'tcx> for DefaultPartitioning {\n                 }\n             }\n \n-            new_partitioning.push(new_codegen_unit);\n+            *old_codegen_unit = new_codegen_unit;\n         }\n \n-        return PostInliningPartitioning {\n-            codegen_units: new_partitioning,\n-            mono_item_placements,\n-            internalization_candidates,\n-        };\n+        return mono_item_placements;\n \n         fn follow_inlining<'tcx>(\n             mono_item: MonoItem<'tcx>,\n@@ -201,14 +277,16 @@ impl<'tcx> Partition<'tcx> for DefaultPartitioning {\n     fn internalize_symbols(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        partitioning: &mut PostInliningPartitioning<'tcx>,\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        mono_item_placements: FxHashMap<MonoItem<'tcx>, MonoItemPlacement>,\n+        internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n     ) {\n-        if partitioning.codegen_units.len() == 1 {\n+        if codegen_units.len() == 1 {\n             // Fast path for when there is only one codegen unit. In this case we\n             // can internalize all candidates, since there is nowhere else they\n             // could be accessed from.\n-            for cgu in &mut partitioning.codegen_units {\n-                for candidate in &partitioning.internalization_candidates {\n+            for cgu in codegen_units {\n+                for candidate in &internalization_candidates {\n                     cgu.items_mut().insert(*candidate, (Linkage::Internal, Visibility::Default));\n                 }\n             }\n@@ -225,15 +303,13 @@ impl<'tcx> Partition<'tcx> for DefaultPartitioning {\n             }\n         });\n \n-        let mono_item_placements = &partitioning.mono_item_placements;\n-\n         // For each internalization candidates in each codegen unit, check if it is\n         // accessed from outside its defining codegen unit.\n-        for cgu in &mut partitioning.codegen_units {\n+        for cgu in codegen_units {\n             let home_cgu = MonoItemPlacement::SingleCgu { cgu_name: cgu.name() };\n \n             for (accessee, linkage_and_visibility) in cgu.items_mut() {\n-                if !partitioning.internalization_candidates.contains(accessee) {\n+                if !internalization_candidates.contains(accessee) {\n                     // This item is no candidate for internalizing, so skip it.\n                     continue;\n                 }"}, {"sha": "5c524a18454ec515026c68537cf84d1b0cccd5c8", "filename": "compiler/rustc_monomorphize/src/partitioning/merging.rs", "status": "removed", "additions": 0, "deletions": 111, "changes": 111, "blob_url": "https://github.com/rust-lang/rust/blob/42c7b8a7de4a90d9d040f7132403d49bc6783032/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmerging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/42c7b8a7de4a90d9d040f7132403d49bc6783032/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmerging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmerging.rs?ref=42c7b8a7de4a90d9d040f7132403d49bc6783032", "patch": "@@ -1,111 +0,0 @@\n-use std::cmp;\n-\n-use rustc_data_structures::fx::FxHashMap;\n-use rustc_hir::def_id::LOCAL_CRATE;\n-use rustc_middle::mir::mono::{CodegenUnit, CodegenUnitNameBuilder};\n-use rustc_span::symbol::Symbol;\n-\n-use super::PartitioningCx;\n-use crate::partitioning::PreInliningPartitioning;\n-\n-pub fn merge_codegen_units<'tcx>(\n-    cx: &PartitioningCx<'_, 'tcx>,\n-    initial_partitioning: &mut PreInliningPartitioning<'tcx>,\n-) {\n-    assert!(cx.target_cgu_count >= 1);\n-    let codegen_units = &mut initial_partitioning.codegen_units;\n-\n-    // Note that at this point in time the `codegen_units` here may not be in a\n-    // deterministic order (but we know they're deterministically the same set).\n-    // We want this merging to produce a deterministic ordering of codegen units\n-    // from the input.\n-    //\n-    // Due to basically how we've implemented the merging below (merge the two\n-    // smallest into each other) we're sure to start off with a deterministic\n-    // order (sorted by name). This'll mean that if two cgus have the same size\n-    // the stable sort below will keep everything nice and deterministic.\n-    codegen_units.sort_by(|a, b| a.name().as_str().cmp(b.name().as_str()));\n-\n-    // This map keeps track of what got merged into what.\n-    let mut cgu_contents: FxHashMap<Symbol, Vec<Symbol>> =\n-        codegen_units.iter().map(|cgu| (cgu.name(), vec![cgu.name()])).collect();\n-\n-    // Merge the two smallest codegen units until the target size is reached.\n-    while codegen_units.len() > cx.target_cgu_count {\n-        // Sort small cgus to the back\n-        codegen_units.sort_by_cached_key(|cgu| cmp::Reverse(cgu.size_estimate()));\n-        let mut smallest = codegen_units.pop().unwrap();\n-        let second_smallest = codegen_units.last_mut().unwrap();\n-\n-        // Move the mono-items from `smallest` to `second_smallest`\n-        second_smallest.modify_size_estimate(smallest.size_estimate());\n-        for (k, v) in smallest.items_mut().drain() {\n-            second_smallest.items_mut().insert(k, v);\n-        }\n-\n-        // Record that `second_smallest` now contains all the stuff that was in\n-        // `smallest` before.\n-        let mut consumed_cgu_names = cgu_contents.remove(&smallest.name()).unwrap();\n-        cgu_contents.get_mut(&second_smallest.name()).unwrap().append(&mut consumed_cgu_names);\n-\n-        debug!(\n-            \"CodegenUnit {} merged into CodegenUnit {}\",\n-            smallest.name(),\n-            second_smallest.name()\n-        );\n-    }\n-\n-    let cgu_name_builder = &mut CodegenUnitNameBuilder::new(cx.tcx);\n-\n-    if cx.tcx.sess.opts.incremental.is_some() {\n-        // If we are doing incremental compilation, we want CGU names to\n-        // reflect the path of the source level module they correspond to.\n-        // For CGUs that contain the code of multiple modules because of the\n-        // merging done above, we use a concatenation of the names of\n-        // all contained CGUs.\n-        let new_cgu_names: FxHashMap<Symbol, String> = cgu_contents\n-            .into_iter()\n-            // This `filter` makes sure we only update the name of CGUs that\n-            // were actually modified by merging.\n-            .filter(|(_, cgu_contents)| cgu_contents.len() > 1)\n-            .map(|(current_cgu_name, cgu_contents)| {\n-                let mut cgu_contents: Vec<&str> = cgu_contents.iter().map(|s| s.as_str()).collect();\n-\n-                // Sort the names, so things are deterministic and easy to\n-                // predict.\n-\n-                // We are sorting primitive &strs here so we can use unstable sort\n-                cgu_contents.sort_unstable();\n-\n-                (current_cgu_name, cgu_contents.join(\"--\"))\n-            })\n-            .collect();\n-\n-        for cgu in codegen_units.iter_mut() {\n-            if let Some(new_cgu_name) = new_cgu_names.get(&cgu.name()) {\n-                if cx.tcx.sess.opts.unstable_opts.human_readable_cgu_names {\n-                    cgu.set_name(Symbol::intern(&new_cgu_name));\n-                } else {\n-                    // If we don't require CGU names to be human-readable, we\n-                    // use a fixed length hash of the composite CGU name\n-                    // instead.\n-                    let new_cgu_name = CodegenUnit::mangle_name(&new_cgu_name);\n-                    cgu.set_name(Symbol::intern(&new_cgu_name));\n-                }\n-            }\n-        }\n-    } else {\n-        // If we are compiling non-incrementally we just generate simple CGU\n-        // names containing an index.\n-        for (index, cgu) in codegen_units.iter_mut().enumerate() {\n-            cgu.set_name(numbered_codegen_unit_name(cgu_name_builder, index));\n-        }\n-    }\n-}\n-\n-fn numbered_codegen_unit_name(\n-    name_builder: &mut CodegenUnitNameBuilder<'_>,\n-    index: usize,\n-) -> Symbol {\n-    name_builder.build_cgu_name_no_mangle(LOCAL_CRATE, &[\"cgu\"], Some(index))\n-}"}, {"sha": "d0b23ca9ea44494dcc9dbe891f998bda48a31dc4", "filename": "compiler/rustc_monomorphize/src/partitioning/mod.rs", "status": "modified", "additions": 55, "deletions": 54, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/78cc117f7bb994f49c7f9b58dcf7807b18d69e28/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_monomorphize%2Fsrc%2Fpartitioning%2Fmod.rs?ref=78cc117f7bb994f49c7f9b58dcf7807b18d69e28", "patch": "@@ -93,7 +93,6 @@\n //! inlining, even when they are not marked `#[inline]`.\n \n mod default;\n-mod merging;\n \n use std::cmp;\n use std::fs::{self, File};\n@@ -129,7 +128,7 @@ impl<'tcx> Partition<'tcx> for Partitioner {\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n         mono_items: &mut I,\n-    ) -> PreInliningPartitioning<'tcx>\n+    ) -> PlacedRootMonoItems<'tcx>\n     where\n         I: Iterator<Item = MonoItem<'tcx>>,\n     {\n@@ -142,24 +141,23 @@ impl<'tcx> Partition<'tcx> for Partitioner {\n     fn merge_codegen_units(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: &mut PreInliningPartitioning<'tcx>,\n+        codegen_units: &mut Vec<CodegenUnit<'tcx>>,\n     ) {\n         match self {\n-            Partitioner::Default(partitioner) => {\n-                partitioner.merge_codegen_units(cx, initial_partitioning)\n-            }\n+            Partitioner::Default(partitioner) => partitioner.merge_codegen_units(cx, codegen_units),\n             Partitioner::Unknown => cx.tcx.sess.emit_fatal(UnknownPartitionStrategy),\n         }\n     }\n \n     fn place_inlined_mono_items(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: PreInliningPartitioning<'tcx>,\n-    ) -> PostInliningPartitioning<'tcx> {\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        roots: FxHashSet<MonoItem<'tcx>>,\n+    ) -> FxHashMap<MonoItem<'tcx>, MonoItemPlacement> {\n         match self {\n             Partitioner::Default(partitioner) => {\n-                partitioner.place_inlined_mono_items(cx, initial_partitioning)\n+                partitioner.place_inlined_mono_items(cx, codegen_units, roots)\n             }\n             Partitioner::Unknown => cx.tcx.sess.emit_fatal(UnknownPartitionStrategy),\n         }\n@@ -168,48 +166,62 @@ impl<'tcx> Partition<'tcx> for Partitioner {\n     fn internalize_symbols(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        post_inlining_partitioning: &mut PostInliningPartitioning<'tcx>,\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        mono_item_placements: FxHashMap<MonoItem<'tcx>, MonoItemPlacement>,\n+        internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n     ) {\n         match self {\n-            Partitioner::Default(partitioner) => {\n-                partitioner.internalize_symbols(cx, post_inlining_partitioning)\n-            }\n+            Partitioner::Default(partitioner) => partitioner.internalize_symbols(\n+                cx,\n+                codegen_units,\n+                mono_item_placements,\n+                internalization_candidates,\n+            ),\n             Partitioner::Unknown => cx.tcx.sess.emit_fatal(UnknownPartitionStrategy),\n         }\n     }\n }\n \n-pub struct PartitioningCx<'a, 'tcx> {\n+struct PartitioningCx<'a, 'tcx> {\n     tcx: TyCtxt<'tcx>,\n     target_cgu_count: usize,\n     inlining_map: &'a InliningMap<'tcx>,\n }\n \n+pub struct PlacedRootMonoItems<'tcx> {\n+    codegen_units: Vec<CodegenUnit<'tcx>>,\n+    roots: FxHashSet<MonoItem<'tcx>>,\n+    internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n+}\n+\n trait Partition<'tcx> {\n     fn place_root_mono_items<I>(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n         mono_items: &mut I,\n-    ) -> PreInliningPartitioning<'tcx>\n+    ) -> PlacedRootMonoItems<'tcx>\n     where\n         I: Iterator<Item = MonoItem<'tcx>>;\n \n     fn merge_codegen_units(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: &mut PreInliningPartitioning<'tcx>,\n+        codegen_units: &mut Vec<CodegenUnit<'tcx>>,\n     );\n \n     fn place_inlined_mono_items(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        initial_partitioning: PreInliningPartitioning<'tcx>,\n-    ) -> PostInliningPartitioning<'tcx>;\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        roots: FxHashSet<MonoItem<'tcx>>,\n+    ) -> FxHashMap<MonoItem<'tcx>, MonoItemPlacement>;\n \n     fn internalize_symbols(\n         &mut self,\n         cx: &PartitioningCx<'_, 'tcx>,\n-        partitioning: &mut PostInliningPartitioning<'tcx>,\n+        codegen_units: &mut [CodegenUnit<'tcx>],\n+        mono_item_placements: FxHashMap<MonoItem<'tcx>, MonoItemPlacement>,\n+        internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n     );\n }\n \n@@ -225,7 +237,7 @@ fn get_partitioner(tcx: TyCtxt<'_>) -> Partitioner {\n     }\n }\n \n-pub fn partition<'tcx, I>(\n+fn partition<'tcx, I>(\n     tcx: TyCtxt<'tcx>,\n     mono_items: &mut I,\n     max_cgu_count: usize,\n@@ -241,52 +253,59 @@ where\n     // In the first step, we place all regular monomorphizations into their\n     // respective 'home' codegen unit. Regular monomorphizations are all\n     // functions and statics defined in the local crate.\n-    let mut initial_partitioning = {\n+    let PlacedRootMonoItems { mut codegen_units, roots, internalization_candidates } = {\n         let _prof_timer = tcx.prof.generic_activity(\"cgu_partitioning_place_roots\");\n         partitioner.place_root_mono_items(cx, mono_items)\n     };\n \n-    for cgu in &mut initial_partitioning.codegen_units {\n+    for cgu in &mut codegen_units {\n         cgu.create_size_estimate(tcx);\n     }\n \n-    debug_dump(tcx, \"INITIAL PARTITIONING\", &initial_partitioning.codegen_units);\n+    debug_dump(tcx, \"INITIAL PARTITIONING\", &codegen_units);\n \n     // Merge until we have at most `max_cgu_count` codegen units.\n+    // `merge_codegen_units` is responsible for updating the CGU size\n+    // estimates.\n     {\n         let _prof_timer = tcx.prof.generic_activity(\"cgu_partitioning_merge_cgus\");\n-        partitioner.merge_codegen_units(cx, &mut initial_partitioning);\n-        debug_dump(tcx, \"POST MERGING\", &initial_partitioning.codegen_units);\n+        partitioner.merge_codegen_units(cx, &mut codegen_units);\n+        debug_dump(tcx, \"POST MERGING\", &codegen_units);\n     }\n \n     // In the next step, we use the inlining map to determine which additional\n     // monomorphizations have to go into each codegen unit. These additional\n     // monomorphizations can be drop-glue, functions from external crates, and\n     // local functions the definition of which is marked with `#[inline]`.\n-    let mut post_inlining = {\n+    let mono_item_placements = {\n         let _prof_timer = tcx.prof.generic_activity(\"cgu_partitioning_place_inline_items\");\n-        partitioner.place_inlined_mono_items(cx, initial_partitioning)\n+        partitioner.place_inlined_mono_items(cx, &mut codegen_units, roots)\n     };\n \n-    for cgu in &mut post_inlining.codegen_units {\n+    for cgu in &mut codegen_units {\n         cgu.create_size_estimate(tcx);\n     }\n \n-    debug_dump(tcx, \"POST INLINING\", &post_inlining.codegen_units);\n+    debug_dump(tcx, \"POST INLINING\", &codegen_units);\n \n     // Next we try to make as many symbols \"internal\" as possible, so LLVM has\n     // more freedom to optimize.\n     if !tcx.sess.link_dead_code() {\n         let _prof_timer = tcx.prof.generic_activity(\"cgu_partitioning_internalize_symbols\");\n-        partitioner.internalize_symbols(cx, &mut post_inlining);\n+        partitioner.internalize_symbols(\n+            cx,\n+            &mut codegen_units,\n+            mono_item_placements,\n+            internalization_candidates,\n+        );\n     }\n \n     let instrument_dead_code =\n         tcx.sess.instrument_coverage() && !tcx.sess.instrument_coverage_except_unused_functions();\n \n     if instrument_dead_code {\n         assert!(\n-            post_inlining.codegen_units.len() > 0,\n+            codegen_units.len() > 0,\n             \"There must be at least one CGU that code coverage data can be generated in.\"\n         );\n \n@@ -297,7 +316,7 @@ where\n         // the object file (CGU) containing the dead function stubs is included\n         // in the final binary. This will probably require forcing these\n         // function symbols to be included via `-u` or `/include` linker args.\n-        let mut cgus: Vec<_> = post_inlining.codegen_units.iter_mut().collect();\n+        let mut cgus: Vec<_> = codegen_units.iter_mut().collect();\n         cgus.sort_by_key(|cgu| cgu.size_estimate());\n \n         let dead_code_cgu =\n@@ -308,29 +327,17 @@ where\n             } else {\n                 // If there are no CGUs that have externally linked items,\n                 // then we just pick the first CGU as a fallback.\n-                &mut post_inlining.codegen_units[0]\n+                &mut codegen_units[0]\n             };\n         dead_code_cgu.make_code_coverage_dead_code_cgu();\n     }\n \n     // Finally, sort by codegen unit name, so that we get deterministic results.\n-    let PostInliningPartitioning {\n-        codegen_units: mut result,\n-        mono_item_placements: _,\n-        internalization_candidates: _,\n-    } = post_inlining;\n+    codegen_units.sort_by(|a, b| a.name().as_str().cmp(b.name().as_str()));\n \n-    result.sort_by(|a, b| a.name().as_str().cmp(b.name().as_str()));\n+    debug_dump(tcx, \"FINAL\", &codegen_units);\n \n-    debug_dump(tcx, \"FINAL\", &result);\n-\n-    result\n-}\n-\n-pub struct PreInliningPartitioning<'tcx> {\n-    codegen_units: Vec<CodegenUnit<'tcx>>,\n-    roots: FxHashSet<MonoItem<'tcx>>,\n-    internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n+    codegen_units\n }\n \n /// For symbol internalization, we need to know whether a symbol/mono-item is\n@@ -342,12 +349,6 @@ enum MonoItemPlacement {\n     MultipleCgus,\n }\n \n-struct PostInliningPartitioning<'tcx> {\n-    codegen_units: Vec<CodegenUnit<'tcx>>,\n-    mono_item_placements: FxHashMap<MonoItem<'tcx>, MonoItemPlacement>,\n-    internalization_candidates: FxHashSet<MonoItem<'tcx>>,\n-}\n-\n fn debug_dump<'a, 'tcx: 'a>(tcx: TyCtxt<'tcx>, label: &str, cgus: &[CodegenUnit<'tcx>]) {\n     let dump = move || {\n         use std::fmt::Write;"}]}