{"sha": "25b05147b3ec0a1ed9df9614910a10171b8cf211", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI1YjA1MTQ3YjNlYzBhMWVkOWRmOTYxNDkxMGExMDE3MWI4Y2YyMTE=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-08T19:38:23Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-08T19:38:23Z"}, "message": "syntax: Remove `Deref` impl from `Token`", "tree": {"sha": "40e348a9fd8394e15c873a56c24957131ba3a977", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/40e348a9fd8394e15c873a56c24957131ba3a977"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/25b05147b3ec0a1ed9df9614910a10171b8cf211", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/25b05147b3ec0a1ed9df9614910a10171b8cf211", "html_url": "https://github.com/rust-lang/rust/commit/25b05147b3ec0a1ed9df9614910a10171b8cf211", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/25b05147b3ec0a1ed9df9614910a10171b8cf211/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0ca3c2f881fc4bc51bfa92f1adcd1b845b812534", "url": "https://api.github.com/repos/rust-lang/rust/commits/0ca3c2f881fc4bc51bfa92f1adcd1b845b812534", "html_url": "https://github.com/rust-lang/rust/commit/0ca3c2f881fc4bc51bfa92f1adcd1b845b812534"}], "stats": {"total": 111, "additions": 45, "deletions": 66}, "files": [{"sha": "4758b6a50e520f8a4f3c5b9ff3e77b16a0fe65fa", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -78,7 +78,7 @@ use crate::ast::{Ident, Name};\n use crate::ext::tt::quoted::{self, TokenTree};\n use crate::parse::{Directory, ParseSess};\n use crate::parse::parser::{Parser, PathStyle};\n-use crate::parse::token::{self, DocComment, Nonterminal, Token, TokenKind};\n+use crate::parse::token::{self, DocComment, Nonterminal, Token};\n use crate::print::pprust;\n use crate::symbol::{kw, sym, Symbol};\n use crate::tokenstream::{DelimSpan, TokenStream};\n@@ -417,12 +417,12 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n \n /// Generates an appropriate parsing failure message. For EOF, this is \"unexpected end...\". For\n /// other tokens, this is \"unexpected token...\".\n-pub fn parse_failure_msg(tok: TokenKind) -> String {\n-    match tok {\n+pub fn parse_failure_msg(tok: &Token) -> String {\n+    match tok.kind {\n         token::Eof => \"unexpected end of macro invocation\".to_string(),\n         _ => format!(\n             \"no rules expected the token `{}`\",\n-            pprust::token_to_string(&tok)\n+            pprust::token_to_string(tok)\n         ),\n     }\n }\n@@ -804,8 +804,8 @@ pub fn parse(\n \n /// The token is an identifier, but not `_`.\n /// We prohibit passing `_` to macros expecting `ident` for now.\n-fn get_macro_name(token: &TokenKind) -> Option<(Name, bool)> {\n-    match *token {\n+fn get_macro_name(token: &Token) -> Option<(Name, bool)> {\n+    match token.kind {\n         token::Ident(name, is_raw) if name != kw::Underscore => Some((name, is_raw)),\n         _ => None,\n     }"}, {"sha": "e7da195c0055fe0721ff847d3a61b9d6d47ab576", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -200,7 +200,7 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n \n     let (token, label) = best_failure.expect(\"ran no matchers\");\n     let span = token.span.substitute_dummy(sp);\n-    let mut err = cx.struct_span_err(span, &parse_failure_msg(token.kind));\n+    let mut err = cx.struct_span_err(span, &parse_failure_msg(&token));\n     err.span_label(span, label);\n     if let Some(sp) = def_span {\n         if cx.source_map().span_to_filename(sp).is_real() && !sp.is_dummy() {\n@@ -288,7 +288,7 @@ pub fn compile(\n     let argument_map = match parse(sess, body.stream(), &argument_gram, None, true) {\n         Success(m) => m,\n         Failure(token, msg) => {\n-            let s = parse_failure_msg(token.kind);\n+            let s = parse_failure_msg(&token);\n             let sp = token.span.substitute_dummy(def.span);\n             let mut err = sess.span_diagnostic.struct_span_fatal(sp, &s);\n             err.span_label(sp, msg);"}, {"sha": "707fb65bcc52bfb363c18689714a81d449456a92", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 5, "deletions": 15, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -23,24 +23,14 @@ pub struct Delimited {\n }\n \n impl Delimited {\n-    /// Returns the opening delimiter (possibly `NoDelim`).\n-    pub fn open_token(&self) -> TokenKind {\n-        token::OpenDelim(self.delim)\n-    }\n-\n-    /// Returns the closing delimiter (possibly `NoDelim`).\n-    pub fn close_token(&self) -> TokenKind {\n-        token::CloseDelim(self.delim)\n-    }\n-\n     /// Returns a `self::TokenTree` with a `Span` corresponding to the opening delimiter.\n     pub fn open_tt(&self, span: Span) -> TokenTree {\n         let open_span = if span.is_dummy() {\n             span\n         } else {\n             span.with_lo(span.lo() + BytePos(self.delim.len() as u32))\n         };\n-        TokenTree::token(self.open_token(), open_span)\n+        TokenTree::token(token::OpenDelim(self.delim), open_span)\n     }\n \n     /// Returns a `self::TokenTree` with a `Span` corresponding to the closing delimiter.\n@@ -50,7 +40,7 @@ impl Delimited {\n         } else {\n             span.with_lo(span.hi() - BytePos(self.delim.len() as u32))\n         };\n-        TokenTree::token(self.close_token(), close_span)\n+        TokenTree::token(token::CloseDelim(self.delim), close_span)\n     }\n }\n \n@@ -282,7 +272,7 @@ where\n             Some(tokenstream::TokenTree::Delimited(span, delim, tts)) => {\n                 // Must have `(` not `{` or `[`\n                 if delim != token::Paren {\n-                    let tok = pprust::token_to_string(&token::OpenDelim(delim));\n+                    let tok = pprust::token_kind_to_string(&token::OpenDelim(delim));\n                     let msg = format!(\"expected `(`, found `{}`\", tok);\n                     sess.span_diagnostic.span_err(span.entire(), &msg);\n                 }\n@@ -371,8 +361,8 @@ where\n \n /// Takes a token and returns `Some(KleeneOp)` if the token is `+` `*` or `?`. Otherwise, return\n /// `None`.\n-fn kleene_op(token: &TokenKind) -> Option<KleeneOp> {\n-    match *token {\n+fn kleene_op(token: &Token) -> Option<KleeneOp> {\n+    match token.kind {\n         token::BinOp(token::Star) => Some(KleeneOp::ZeroOrMore),\n         token::BinOp(token::Plus) => Some(KleeneOp::OneOrMore),\n         token::Question => Some(KleeneOp::ZeroOrOne),"}, {"sha": "9d2ac5b4b51688a82c2e94f86f4c3f650b3da221", "filename": "src/libsyntax/parse/diagnostics.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fdiagnostics.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -729,7 +729,7 @@ impl<'a> Parser<'a> {\n         &mut self,\n         t: &TokenKind,\n     ) -> PResult<'a, bool /* recovered */> {\n-        let token_str = pprust::token_to_string(t);\n+        let token_str = pprust::token_kind_to_string(t);\n         let this_token_str = self.this_token_descr();\n         let (prev_sp, sp) = match (&self.token.kind, self.subparser_name) {\n             // Point at the end of the macro call when reaching end of macro arguments."}, {"sha": "99d9d40a45b931b353ee3e8eb037e206c51269f0", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -211,7 +211,7 @@ impl<'a> TokenTreesReader<'a> {\n                 let raw = self.string_reader.peek_span_src_raw;\n                 self.real_token();\n                 let is_joint = raw.hi() == self.string_reader.peek_span_src_raw.lo()\n-                    && token::is_op(&self.token);\n+                    && self.token.is_op();\n                 Ok((tt, if is_joint { Joint } else { NonJoint }))\n             }\n         }"}, {"sha": "cde35681988db905f0188fab5343ba82d7a62037", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -9,7 +9,7 @@ use crate::parse::parser::emit_unclosed_delims;\n use crate::parse::token::TokenKind;\n use crate::tokenstream::{TokenStream, TokenTree};\n use crate::diagnostics::plugin::ErrorMap;\n-use crate::print::pprust::token_to_string;\n+use crate::print::pprust;\n \n use errors::{Applicability, FatalError, Level, Handler, ColorConfig, Diagnostic, DiagnosticBuilder};\n use rustc_data_structures::sync::{Lrc, Lock};\n@@ -312,7 +312,7 @@ pub fn maybe_file_to_stream(\n             for unmatched in unmatched_braces {\n                 let mut db = sess.span_diagnostic.struct_span_err(unmatched.found_span, &format!(\n                     \"incorrect close delimiter: `{}`\",\n-                    token_to_string(&token::CloseDelim(unmatched.found_delim)),\n+                    pprust::token_kind_to_string(&token::CloseDelim(unmatched.found_delim)),\n                 ));\n                 db.span_label(unmatched.found_span, \"incorrect close delimiter\");\n                 if let Some(sp) = unmatched.candidate_span {"}, {"sha": "d9eba3bbadb687a1964868c433541c8431766981", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -401,7 +401,7 @@ crate enum TokenType {\n impl TokenType {\n     crate fn to_string(&self) -> String {\n         match *self {\n-            TokenType::Token(ref t) => format!(\"`{}`\", pprust::token_to_string(t)),\n+            TokenType::Token(ref t) => format!(\"`{}`\", pprust::token_kind_to_string(t)),\n             TokenType::Keyword(kw) => format!(\"`{}`\", kw),\n             TokenType::Operator => \"an operator\".to_string(),\n             TokenType::Lifetime => \"lifetime\".to_string(),\n@@ -418,7 +418,7 @@ impl TokenType {\n ///\n /// Types can also be of the form `IDENT(u8, u8) -> u8`, however this assumes\n /// that `IDENT` is not the ident of a fn trait.\n-fn can_continue_type_after_non_fn_ident(t: &TokenKind) -> bool {\n+fn can_continue_type_after_non_fn_ident(t: &Token) -> bool {\n     t == &token::ModSep || t == &token::Lt ||\n     t == &token::BinOp(token::Shl)\n }\n@@ -586,10 +586,10 @@ impl<'a> Parser<'a> {\n         edible: &[TokenKind],\n         inedible: &[TokenKind],\n     ) -> PResult<'a, bool /* recovered */> {\n-        if edible.contains(&self.token) {\n+        if edible.contains(&self.token.kind) {\n             self.bump();\n             Ok(false)\n-        } else if inedible.contains(&self.token) {\n+        } else if inedible.contains(&self.token.kind) {\n             // leave it in the input\n             Ok(false)\n         } else if self.last_unexpected_token_span == Some(self.token.span) {\n@@ -951,7 +951,7 @@ impl<'a> Parser<'a> {\n                         Err(mut e) => {\n                             // Attempt to keep parsing if it was a similar separator\n                             if let Some(ref tokens) = t.similar_tokens() {\n-                                if tokens.contains(&self.token) {\n+                                if tokens.contains(&self.token.kind) {\n                                     self.bump();\n                                 }\n                             }\n@@ -1756,7 +1756,7 @@ impl<'a> Parser<'a> {\n     fn parse_path_segment(&mut self, style: PathStyle) -> PResult<'a, PathSegment> {\n         let ident = self.parse_path_segment_ident()?;\n \n-        let is_args_start = |token: &TokenKind| match *token {\n+        let is_args_start = |token: &Token| match token.kind {\n             token::Lt | token::BinOp(token::Shl) | token::OpenDelim(token::Paren)\n             | token::LArrow => true,\n             _ => false,\n@@ -2822,7 +2822,7 @@ impl<'a> Parser<'a> {\n                 LhsExpr::AttributesParsed(attrs) => Some(attrs),\n                 _ => None,\n             };\n-            if [token::DotDot, token::DotDotDot, token::DotDotEq].contains(&self.token) {\n+            if [token::DotDot, token::DotDotDot, token::DotDotEq].contains(&self.token.kind) {\n                 return self.parse_prefix_range_expr(attrs);\n             } else {\n                 self.parse_prefix_expr(attrs)?\n@@ -3099,7 +3099,7 @@ impl<'a> Parser<'a> {\n             self.err_dotdotdot_syntax(self.token.span);\n         }\n \n-        debug_assert!([token::DotDot, token::DotDotDot, token::DotDotEq].contains(&self.token),\n+        debug_assert!([token::DotDot, token::DotDotDot, token::DotDotEq].contains(&self.token.kind),\n                       \"parse_prefix_range_expr: token {:?} is not DotDot/DotDotEq\",\n                       self.token);\n         let tok = self.token.clone();\n@@ -7867,7 +7867,7 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, handler:\n     for unmatched in unclosed_delims.iter() {\n         let mut err = handler.struct_span_err(unmatched.found_span, &format!(\n             \"incorrect close delimiter: `{}`\",\n-            pprust::token_to_string(&token::CloseDelim(unmatched.found_delim)),\n+            pprust::token_kind_to_string(&token::CloseDelim(unmatched.found_delim)),\n         ));\n         err.span_label(unmatched.found_span, \"incorrect close delimiter\");\n         if let Some(sp) = unmatched.candidate_span {"}, {"sha": "9b845ca524e8b527d676f83d1d459e40d9e07d48", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 11, "deletions": 18, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -17,7 +17,6 @@ use log::info;\n \n use std::fmt;\n use std::mem;\n-use std::ops::Deref;\n #[cfg(target_arch = \"x86_64\")]\n use rustc_data_structures::static_assert_size;\n use rustc_data_structures::sync::Lrc;\n@@ -553,11 +552,11 @@ impl TokenKind {\n impl Token {\n     // See comments in `Nonterminal::to_tokenstream` for why we care about\n     // *probably* equal here rather than actual equality\n-    crate fn probably_equal_for_proc_macro(&self, other: &TokenKind) -> bool {\n-        if mem::discriminant(&self.kind) != mem::discriminant(other) {\n+    crate fn probably_equal_for_proc_macro(&self, other: &Token) -> bool {\n+        if mem::discriminant(&self.kind) != mem::discriminant(&other.kind) {\n             return false\n         }\n-        match (&self.kind, other) {\n+        match (&self.kind, &other.kind) {\n             (&Eq, &Eq) |\n             (&Lt, &Lt) |\n             (&Le, &Le) |\n@@ -631,14 +630,6 @@ impl PartialEq<TokenKind> for Token {\n     }\n }\n \n-// FIXME: Remove this after all necessary methods are moved from `TokenKind` to `Token`.\n-impl Deref for Token {\n-    type Target = TokenKind;\n-    fn deref(&self) -> &Self::Target {\n-        &self.kind\n-    }\n-}\n-\n #[derive(Clone, RustcEncodable, RustcDecodable)]\n /// For interpolation during macro expansion.\n pub enum Nonterminal {\n@@ -778,12 +769,14 @@ impl Nonterminal {\n     }\n }\n \n-crate fn is_op(tok: &TokenKind) -> bool {\n-    match *tok {\n-        OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) |\n-        Ident(..) | Lifetime(..) | Interpolated(..) |\n-        Whitespace | Comment | Shebang(..) | Eof => false,\n-        _ => true,\n+impl Token {\n+    crate fn is_op(&self) -> bool {\n+        match self.kind {\n+            OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) |\n+            Ident(..) | Lifetime(..) | Interpolated(..) |\n+            Whitespace | Comment | Shebang(..) | Eof => false,\n+            _ => true,\n+        }\n     }\n }\n "}, {"sha": "4cbe590d44bfee9da94ac36e265f07c7bba801c6", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -6,7 +6,7 @@ use crate::ast::{Attribute, MacDelimiter, GenericArg};\n use crate::util::parser::{self, AssocOp, Fixity};\n use crate::attr;\n use crate::source_map::{self, SourceMap, Spanned};\n-use crate::parse::token::{self, BinOpToken, Nonterminal, TokenKind};\n+use crate::parse::token::{self, BinOpToken, Nonterminal, Token, TokenKind};\n use crate::parse::lexer::comments;\n use crate::parse::{self, ParseSess};\n use crate::print::pp::{self, Breaks};\n@@ -189,7 +189,7 @@ pub fn literal_to_string(lit: token::Lit) -> String {\n     out\n }\n \n-pub fn token_to_string(tok: &TokenKind) -> String {\n+pub fn token_kind_to_string(tok: &TokenKind) -> String {\n     match *tok {\n         token::Eq                   => \"=\".to_string(),\n         token::Lt                   => \"<\".to_string(),\n@@ -250,6 +250,10 @@ pub fn token_to_string(tok: &TokenKind) -> String {\n     }\n }\n \n+pub fn token_to_string(token: &Token) -> String {\n+    token_kind_to_string(&token.kind)\n+}\n+\n pub fn nonterminal_to_string(nt: &Nonterminal) -> String {\n     match *nt {\n         token::NtExpr(ref e)        => expr_to_string(e),\n@@ -734,11 +738,11 @@ pub trait PrintState<'a> {\n                 }\n             }\n             TokenTree::Delimited(_, delim, tts) => {\n-                self.writer().word(token_to_string(&token::OpenDelim(delim)))?;\n+                self.writer().word(token_kind_to_string(&token::OpenDelim(delim)))?;\n                 self.writer().space()?;\n                 self.print_tts(tts)?;\n                 self.writer().space()?;\n-                self.writer().word(token_to_string(&token::CloseDelim(delim)))\n+                self.writer().word(token_kind_to_string(&token::CloseDelim(delim)))\n             },\n         }\n     }"}, {"sha": "2daec9702798fd1ef5c97e2a2a5231929743f168", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/25b05147b3ec0a1ed9df9614910a10171b8cf211/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=25b05147b3ec0a1ed9df9614910a10171b8cf211", "patch": "@@ -126,14 +126,6 @@ impl TokenTree {\n         }\n     }\n \n-    /// Indicates if the stream is a token that is equal to the provided token.\n-    pub fn eq_token(&self, t: TokenKind) -> bool {\n-        match self {\n-            TokenTree::Token(token) => *token == t,\n-            _ => false,\n-        }\n-    }\n-\n     pub fn joint(self) -> TokenStream {\n         TokenStream::new(vec![(self, Joint)])\n     }"}]}