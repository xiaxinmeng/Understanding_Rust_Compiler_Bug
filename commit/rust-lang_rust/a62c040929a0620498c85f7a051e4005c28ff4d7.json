{"sha": "a62c040929a0620498c85f7a051e4005c28ff4d7", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE2MmMwNDA5MjlhMDYyMDQ5OGM4NWY3YTA1MWU0MDA1YzI4ZmY0ZDc=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2019-12-13T13:44:08Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2020-01-10T09:18:21Z"}, "message": "self-profile: Switch to new approach for event_id generation that enables query-invocation-specific event_ids.", "tree": {"sha": "b5f20294d842b230947f3881f19eb5227b665ca1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/b5f20294d842b230947f3881f19eb5227b665ca1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a62c040929a0620498c85f7a051e4005c28ff4d7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a62c040929a0620498c85f7a051e4005c28ff4d7", "html_url": "https://github.com/rust-lang/rust/commit/a62c040929a0620498c85f7a051e4005c28ff4d7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a62c040929a0620498c85f7a051e4005c28ff4d7/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2d8d559bbecf6272eb41f8a800e319238aa9d621", "url": "https://api.github.com/repos/rust-lang/rust/commits/2d8d559bbecf6272eb41f8a800e319238aa9d621", "html_url": "https://github.com/rust-lang/rust/commit/2d8d559bbecf6272eb41f8a800e319238aa9d621"}], "stats": {"total": 385, "additions": 277, "deletions": 108}, "files": [{"sha": "96f37457a0e05907abb874cba198b1b868fe1d6b", "filename": "Cargo.lock", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -1995,9 +1995,9 @@ dependencies = [\n \n [[package]]\n name = \"measureme\"\n-version = \"0.5.0\"\n+version = \"0.6.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"c420bbc064623934620b5ab2dc0cf96451b34163329e82f95e7fa1b7b99a6ac8\"\n+checksum = \"36dcc09c1a633097649f7d48bde3d8a61d2a43c01ce75525e31fbbc82c0fccf4\"\n dependencies = [\n  \"byteorder\",\n  \"memmap\","}, {"sha": "567dc85213ab6d7d7032e4499daed31dce5bf565", "filename": "src/librustc/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2FCargo.toml?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -36,5 +36,6 @@ parking_lot = \"0.9\"\n byteorder = { version = \"1.3\" }\n chalk-engine = { version = \"0.9.0\", default-features=false }\n smallvec = { version = \"1.0\", features = [\"union\", \"may_dangle\"] }\n+measureme = \"0.6.0\"\n rustc_error_codes = { path = \"../librustc_error_codes\" }\n rustc_session = { path = \"../librustc_session\" }"}, {"sha": "0616f00b8c472a070cad8f28dfea0bb27bb828c4", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 27, "deletions": 3, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -8,6 +8,8 @@ use rustc_data_structures::sync::{AtomicU32, AtomicU64, Lock, Lrc, Ordering};\n use rustc_index::vec::{Idx, IndexVec};\n use smallvec::SmallVec;\n use std::collections::hash_map::Entry;\n+use rustc_data_structures::profiling::QueryInvocationId;\n+use std::sync::atomic::Ordering::Relaxed;\n use std::env;\n use std::hash::Hash;\n use std::mem;\n@@ -25,6 +27,12 @@ use super::serialized::{SerializedDepGraph, SerializedDepNodeIndex};\n #[derive(Clone)]\n pub struct DepGraph {\n     data: Option<Lrc<DepGraphData>>,\n+\n+    /// This field is used for assigning DepNodeIndices when running in\n+    /// non-incremental mode. Even in non-incremental mode we make sure that\n+    /// each task as a `DepNodeIndex` that uniquely identifies it. This unique\n+    /// ID is used for self-profiling.\n+    virtual_dep_node_index: Lrc<AtomicU32>,\n }\n \n rustc_index::newtype_index! {\n@@ -35,6 +43,13 @@ impl DepNodeIndex {\n     pub const INVALID: DepNodeIndex = DepNodeIndex::MAX;\n }\n \n+impl std::convert::From<DepNodeIndex> for QueryInvocationId {\n+    #[inline]\n+    fn from(dep_node_index: DepNodeIndex) -> Self {\n+         QueryInvocationId(dep_node_index.as_u32())\n+    }\n+}\n+\n #[derive(PartialEq)]\n pub enum DepNodeColor {\n     Red,\n@@ -105,11 +120,15 @@ impl DepGraph {\n                 previous: prev_graph,\n                 colors: DepNodeColorMap::new(prev_graph_node_count),\n             })),\n+            virtual_dep_node_index: Lrc::new(AtomicU32::new(0)),\n         }\n     }\n \n     pub fn new_disabled() -> DepGraph {\n-        DepGraph { data: None }\n+        DepGraph {\n+            data: None,\n+            virtual_dep_node_index: Lrc::new(AtomicU32::new(0)),\n+        }\n     }\n \n     /// Returns `true` if we are actually building the full dep-graph, and `false` otherwise.\n@@ -322,7 +341,7 @@ impl DepGraph {\n \n             (result, dep_node_index)\n         } else {\n-            (task(cx, arg), DepNodeIndex::INVALID)\n+            (task(cx, arg), self.next_virtual_depnode_index())\n         }\n     }\n \n@@ -352,7 +371,7 @@ impl DepGraph {\n             let dep_node_index = data.current.complete_anon_task(dep_kind, task_deps);\n             (result, dep_node_index)\n         } else {\n-            (op(), DepNodeIndex::INVALID)\n+            (op(), self.next_virtual_depnode_index())\n         }\n     }\n \n@@ -877,6 +896,11 @@ impl DepGraph {\n             }\n         }\n     }\n+\n+    fn next_virtual_depnode_index(&self) -> DepNodeIndex {\n+        let index = self.virtual_dep_node_index.fetch_add(1, Relaxed);\n+        DepNodeIndex::from_u32(index)\n+    }\n }\n \n /// A \"work product\" is an intermediate result that we save into the"}, {"sha": "dbb6a1080e6d46f6a305ea5ab0a8dd186d718226", "filename": "src/librustc/ty/query/config.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fconfig.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -2,8 +2,7 @@ use crate::dep_graph::SerializedDepNodeIndex;\n use crate::dep_graph::{DepKind, DepNode};\n use crate::ty::query::plumbing::CycleError;\n use crate::ty::query::queries;\n-use crate::ty::query::QueryCache;\n-use crate::ty::query::{Query, QueryName};\n+use crate::ty::query::{Query, QueryCache};\n use crate::ty::TyCtxt;\n use rustc_data_structures::profiling::ProfileCategory;\n use rustc_hir::def_id::{CrateNum, DefId};\n@@ -20,7 +19,7 @@ use std::hash::Hash;\n // FIXME(eddyb) false positive, the lifetime parameter is used for `Key`/`Value`.\n #[allow(unused_lifetimes)]\n pub trait QueryConfig<'tcx> {\n-    const NAME: QueryName;\n+    const NAME: &'static str;\n     const CATEGORY: ProfileCategory;\n \n     type Key: Eq + Hash + Clone + Debug;"}, {"sha": "5792995826781d150b86c89c0fd71da056c744d7", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 61, "deletions": 56, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -95,7 +95,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             if let Some((_, value)) =\n                 lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key)\n             {\n-                tcx.prof.query_cache_hit(Q::NAME);\n+                tcx.prof.query_cache_hit(value.index.into());\n                 let result = (value.value.clone(), value.index);\n                 #[cfg(debug_assertions)]\n                 {\n@@ -347,7 +347,7 @@ impl<'tcx> TyCtxt<'tcx> {\n \n     #[inline(never)]\n     pub(super) fn get_query<Q: QueryDescription<'tcx>>(self, span: Span, key: Q::Key) -> Q::Value {\n-        debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME.as_str(), key, span);\n+        debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n         let job = match JobOwner::try_get(self, span, &key) {\n             TryGetJob::NotYetStarted(job) => job,\n@@ -366,15 +366,15 @@ impl<'tcx> TyCtxt<'tcx> {\n         }\n \n         if Q::ANON {\n-            let prof_timer = self.prof.query_provider(Q::NAME);\n+            let prof_timer = self.prof.query_provider();\n \n             let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n                 self.start_query(job.job.clone(), diagnostics, |tcx| {\n                     tcx.dep_graph.with_anon_task(Q::dep_kind(), || Q::compute(tcx, key))\n                 })\n             });\n \n-            drop(prof_timer);\n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n             self.dep_graph.read_index(dep_node_index);\n \n@@ -436,8 +436,9 @@ impl<'tcx> TyCtxt<'tcx> {\n         let result = if Q::cache_on_disk(self, key.clone(), None)\n             && self.sess.opts.debugging_opts.incremental_queries\n         {\n-            let _prof_timer = self.prof.incr_cache_loading(Q::NAME);\n+            let prof_timer = self.prof.incr_cache_loading();\n             let result = Q::try_load_from_disk(self, prev_dep_node_index);\n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n             // We always expect to find a cached result for things that\n             // can be forced from `DepNode`.\n@@ -457,11 +458,13 @@ impl<'tcx> TyCtxt<'tcx> {\n         } else {\n             // We could not load a result from the on-disk cache, so\n             // recompute.\n-            let _prof_timer = self.prof.query_provider(Q::NAME);\n+            let prof_timer = self.prof.query_provider();\n \n             // The dep-graph for this computation is already in-place.\n             let result = self.dep_graph.with_ignore(|| Q::compute(self, key));\n \n+            prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n+\n             result\n         };\n \n@@ -523,7 +526,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             dep_node\n         );\n \n-        let prof_timer = self.prof.query_provider(Q::NAME);\n+        let prof_timer = self.prof.query_provider();\n \n         let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n             self.start_query(job.job.clone(), diagnostics, |tcx| {\n@@ -541,7 +544,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             })\n         });\n \n-        drop(prof_timer);\n+        prof_timer.finish_with_query_invocation_id(dep_node_index.into());\n \n         if unlikely!(!diagnostics.is_empty()) {\n             if dep_node.kind != crate::dep_graph::DepKind::Null {\n@@ -572,17 +575,19 @@ impl<'tcx> TyCtxt<'tcx> {\n \n         let dep_node = Q::to_dep_node(self, &key);\n \n-        if self.dep_graph.try_mark_green_and_read(self, &dep_node).is_none() {\n-            // A None return from `try_mark_green_and_read` means that this is either\n-            // a new dep node or that the dep node has already been marked red.\n-            // Either way, we can't call `dep_graph.read()` as we don't have the\n-            // DepNodeIndex. We must invoke the query itself. The performance cost\n-            // this introduces should be negligible as we'll immediately hit the\n-            // in-memory cache, or another query down the line will.\n-\n-            let _ = self.get_query::<Q>(DUMMY_SP, key);\n-        } else {\n-            self.prof.query_cache_hit(Q::NAME);\n+        match self.dep_graph.try_mark_green_and_read(self, &dep_node) {\n+            None => {\n+                // A None return from `try_mark_green_and_read` means that this is either\n+                // a new dep node or that the dep node has already been marked red.\n+                // Either way, we can't call `dep_graph.read()` as we don't have the\n+                // DepNodeIndex. We must invoke the query itself. The performance cost\n+                // this introduces should be negligible as we'll immediately hit the\n+                // in-memory cache, or another query down the line will.\n+                let _ = self.get_query::<Q>(DUMMY_SP, key);\n+            }\n+            Some((_, dep_node_index)) => {\n+                self.prof.query_cache_hit(dep_node_index.into());\n+            }\n         }\n     }\n \n@@ -696,6 +701,42 @@ macro_rules! define_queries_inner {\n                 }\n             }\n \n+            /// All self-profiling events generated by the query engine use a\n+            /// virtual `StringId`s for their `event_id`. This method makes all\n+            /// those virtual `StringId`s point to actual strings.\n+            ///\n+            /// If we are recording only summary data, the ids will point to\n+            /// just the query names. If we are recording query keys too, we\n+            /// allocate the corresponding strings here. (The latter is not yet\n+            /// implemented.)\n+            pub fn allocate_self_profile_query_strings(\n+                &self,\n+                profiler: &rustc_data_structures::profiling::SelfProfiler\n+            ) {\n+                // Walk the entire query cache and allocate the appropriate\n+                // string representation. Each cache entry is uniquely\n+                // identified by its dep_node_index.\n+                $({\n+                    let query_name_string_id =\n+                        profiler.get_or_alloc_cached_string(stringify!($name));\n+\n+                    let result_cache = self.$name.lock_shards();\n+\n+                    for shard in result_cache.iter() {\n+                        let query_invocation_ids = shard\n+                            .results\n+                            .values()\n+                            .map(|v| v.index)\n+                            .map(|dep_node_index| dep_node_index.into());\n+\n+                        profiler.bulk_map_query_invocation_id_to_single_string(\n+                            query_invocation_ids,\n+                            query_name_string_id\n+                        );\n+                    }\n+                })*\n+            }\n+\n             #[cfg(parallel_compiler)]\n             pub fn collect_active_jobs(&self) -> Vec<Lrc<QueryJob<$tcx>>> {\n                 let mut jobs = Vec::new();\n@@ -813,36 +854,6 @@ macro_rules! define_queries_inner {\n             }\n         }\n \n-        #[allow(nonstandard_style)]\n-        #[derive(Clone, Copy)]\n-        pub enum QueryName {\n-            $($name),*\n-        }\n-\n-        impl rustc_data_structures::profiling::QueryName for QueryName {\n-            fn discriminant(self) -> std::mem::Discriminant<QueryName> {\n-                std::mem::discriminant(&self)\n-            }\n-\n-            fn as_str(self) -> &'static str {\n-                QueryName::as_str(&self)\n-            }\n-        }\n-\n-        impl QueryName {\n-            pub fn register_with_profiler(\n-                profiler: &rustc_data_structures::profiling::SelfProfiler,\n-            ) {\n-                $(profiler.register_query_name(QueryName::$name);)*\n-            }\n-\n-            pub fn as_str(&self) -> &'static str {\n-                match self {\n-                    $(QueryName::$name => stringify!($name),)*\n-                }\n-            }\n-        }\n-\n         #[allow(nonstandard_style)]\n         #[derive(Clone, Debug)]\n         pub enum Query<$tcx> {\n@@ -883,12 +894,6 @@ macro_rules! define_queries_inner {\n                     $(Query::$name(key) => key.default_span(tcx),)*\n                 }\n             }\n-\n-            pub fn query_name(&self) -> QueryName {\n-                match self {\n-                    $(Query::$name(_) => QueryName::$name,)*\n-                }\n-            }\n         }\n \n         impl<'a, $tcx> HashStable<StableHashingContext<'a>> for Query<$tcx> {\n@@ -923,7 +928,7 @@ macro_rules! define_queries_inner {\n             type Key = $K;\n             type Value = $V;\n \n-            const NAME: QueryName = QueryName::$name;\n+            const NAME: &'static str = stringify!($name);\n             const CATEGORY: ProfileCategory = $category;\n         }\n "}, {"sha": "8087db9fabc2f1dc1a42b3f07946570ff31d99ee", "filename": "src/librustc_codegen_ssa/base.rs", "status": "modified", "additions": 23, "deletions": 8, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_codegen_ssa%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_codegen_ssa%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fbase.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -85,7 +85,7 @@ pub fn bin_op_to_icmp_predicate(op: hir::BinOpKind, signed: bool) -> IntPredicat\n         }\n         op => bug!(\n             \"comparison_op_to_icmp_predicate: expected comparison operator, \\\n-                  found {:?}\",\n+             found {:?}\",\n             op\n         ),\n     }\n@@ -102,7 +102,7 @@ pub fn bin_op_to_fcmp_predicate(op: hir::BinOpKind) -> RealPredicate {\n         op => {\n             bug!(\n                 \"comparison_op_to_fcmp_predicate: expected comparison operator, \\\n-                  found {:?}\",\n+                 found {:?}\",\n                 op\n             );\n         }\n@@ -334,7 +334,11 @@ pub fn from_immediate<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>>(\n     bx: &mut Bx,\n     val: Bx::Value,\n ) -> Bx::Value {\n-    if bx.cx().val_ty(val) == bx.cx().type_i1() { bx.zext(val, bx.cx().type_i8()) } else { val }\n+    if bx.cx().val_ty(val) == bx.cx().type_i1() {\n+        bx.zext(val, bx.cx().type_i8())\n+    } else {\n+        val\n+    }\n }\n \n pub fn to_immediate<'a, 'tcx, Bx: BuilderMethods<'a, 'tcx>>(\n@@ -519,7 +523,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n         ongoing_codegen.codegen_finished(tcx);\n \n-        assert_and_save_dep_graph(tcx);\n+        finalize_tcx(tcx);\n \n         ongoing_codegen.check_for_errors(tcx.sess);\n \n@@ -660,7 +664,8 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n \n     ongoing_codegen.check_for_errors(tcx.sess);\n \n-    assert_and_save_dep_graph(tcx);\n+    finalize_tcx(tcx);\n+\n     ongoing_codegen.into_inner()\n }\n \n@@ -711,10 +716,16 @@ impl<B: ExtraBackendMethods> Drop for AbortCodegenOnDrop<B> {\n     }\n }\n \n-fn assert_and_save_dep_graph(tcx: TyCtxt<'_>) {\n+fn finalize_tcx(tcx: TyCtxt<'_>) {\n     tcx.sess.time(\"assert_dep_graph\", || ::rustc_incremental::assert_dep_graph(tcx));\n-\n     tcx.sess.time(\"serialize_dep_graph\", || ::rustc_incremental::save_dep_graph(tcx));\n+\n+    // We assume that no queries are run past here. If there are new queries\n+    // after this point, they'll show up as \"<unknown>\" in self-profiling data.\n+    tcx.prof.with_profiler(|profiler| {\n+        let _prof_timer = tcx.prof.generic_activity(\"self_profile_alloc_query_strings\");\n+        tcx.queries.allocate_self_profile_query_strings(profiler);\n+    });\n }\n \n impl CrateInfo {\n@@ -876,7 +887,11 @@ fn determine_cgu_reuse<'tcx>(tcx: TyCtxt<'tcx>, cgu: &CodegenUnit<'tcx>) -> CguR\n \n     if tcx.dep_graph.try_mark_green(tcx, &dep_node).is_some() {\n         // We can re-use either the pre- or the post-thinlto state\n-        if tcx.sess.lto() != Lto::No { CguReuse::PreLto } else { CguReuse::PostLto }\n+        if tcx.sess.lto() != Lto::No {\n+            CguReuse::PreLto\n+        } else {\n+            CguReuse::PostLto\n+        }\n     } else {\n         CguReuse::No\n     }"}, {"sha": "9c42f3633f2c0b7edfa8d2b943ad79df96294b23", "filename": "src/librustc_data_structures/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_data_structures%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_data_structures%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2FCargo.toml?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -26,7 +26,7 @@ rustc-hash = \"1.0.1\"\n smallvec = { version = \"1.0\", features = [\"union\", \"may_dangle\"] }\n rustc_index = { path = \"../librustc_index\", package = \"rustc_index\" }\n bitflags = \"1.2.1\"\n-measureme = \"0.5\"\n+measureme = \"0.6.0\"\n \n [dependencies.parking_lot]\n version = \"0.9\""}, {"sha": "db56023560a0dee8769c2e3b61602dbd94fe3b8d", "filename": "src/librustc_data_structures/profiling.rs", "status": "modified", "additions": 160, "deletions": 31, "changes": 191, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_data_structures%2Fprofiling.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_data_structures%2Fprofiling.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fprofiling.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -1,6 +1,90 @@\n+//! # Rust Compiler Self-Profiling\n+//!\n+//! This module implements the basic framework for the compiler's self-\n+//! profiling support. It provides the `SelfProfiler` type which enables\n+//! recording \"events\". An event is something that starts and ends at a given\n+//! point in time and has an ID and a kind attached to it. This allows for\n+//! tracing the compiler's activity.\n+//!\n+//! Internally this module uses the custom tailored [measureme][mm] crate for\n+//! efficiently recording events to disk in a compact format that can be\n+//! post-processed and analyzed by the suite of tools in the `measureme`\n+//! project. The highest priority for the tracing framework is on incurring as\n+//! little overhead as possible.\n+//!\n+//!\n+//! ## Event Overview\n+//!\n+//! Events have a few properties:\n+//!\n+//! - The `event_kind` designates the broad category of an event (e.g. does it\n+//!   correspond to the execution of a query provider or to loading something\n+//!   from the incr. comp. on-disk cache, etc).\n+//! - The `event_id` designates the query invocation or function call it\n+//!   corresponds to, possibly including the query key or function arguments.\n+//! - Each event stores the ID of the thread it was recorded on.\n+//! - The timestamp stores beginning and end of the event, or the single point\n+//!   in time it occurred at for \"instant\" events.\n+//!\n+//!\n+//! ## Event Filtering\n+//!\n+//! Event generation can be filtered by event kind. Recording all possible\n+//! events generates a lot of data, much of which is not needed for most kinds\n+//! of analysis. So, in order to keep overhead as low as possible for a given\n+//! use case, the `SelfProfiler` will only record the kinds of events that\n+//! pass the filter specified as a command line argument to the compiler.\n+//!\n+//!\n+//! ## `event_id` Assignment\n+//!\n+//! As far as `measureme` is concerned, `event_id`s are just strings. However,\n+//! it would incur way too much overhead to generate and persist each `event_id`\n+//! string at the point where the event is recorded. In order to make this more\n+//! efficient `measureme` has two features:\n+//!\n+//! - Strings can share their content, so that re-occurring parts don't have to\n+//!   be copied over and over again. One allocates a string in `measureme` and\n+//!   gets back a `StringId`. This `StringId` is then used to refer to that\n+//!   string. `measureme` strings are actually DAGs of string components so that\n+//!   arbitrary sharing of substrings can be done efficiently. This is useful\n+//!   because `event_id`s contain lots of redundant text like query names or\n+//!   def-path components.\n+//!\n+//! - `StringId`s can be \"virtual\" which means that the client picks a numeric\n+//!   ID according to some application-specific scheme and can later make that\n+//!   ID be mapped to an actual string. This is used to cheaply generate\n+//!   `event_id`s while the events actually occur, causing little timing\n+//!   distortion, and then later map those `StringId`s, in bulk, to actual\n+//!   `event_id` strings. This way the largest part of tracing overhead is\n+//!   localized to one contiguous chunk of time.\n+//!\n+//! How are these `event_id`s generated in the compiler? For things that occur\n+//! infrequently (e.g. \"generic activities\"), we just allocate the string the\n+//! first time it is used and then keep the `StringId` in a hash table. This\n+//! is implemented in `SelfProfiler::get_or_alloc_cached_string()`.\n+//!\n+//! For queries it gets more interesting: First we need a unique numeric ID for\n+//! each query invocation (the `QueryInvocationId`). This ID is used as the\n+//! virtual `StringId` we use as `event_id` for a given event. This ID has to\n+//! be available both when the query is executed and later, together with the\n+//! query key, when we allocate the actual `event_id` strings in bulk.\n+//!\n+//! We could make the compiler generate and keep track of such an ID for each\n+//! query invocation but luckily we already have something that fits all the\n+//! the requirements: the query's `DepNodeIndex`. So we use the numeric value\n+//! of the `DepNodeIndex` as `event_id` when recording the event and then,\n+//! just before the query context is dropped, we walk the entire query cache\n+//! (which stores the `DepNodeIndex` along with the query key for each\n+//! invocation) and allocate the corresponding strings together with a mapping\n+//! for `DepNodeIndex as StringId`.\n+//!\n+//! [mm]: https://github.com/rust-lang/measureme/\n+\n+use crate::fx::FxHashMap;\n+\n use std::error::Error;\n use std::fs;\n-use std::mem::{self, Discriminant};\n use std::path::Path;\n use std::process;\n use std::sync::Arc;\n@@ -9,6 +93,7 @@ use std::time::{Duration, Instant};\n use std::u32;\n \n use measureme::StringId;\n+use parking_lot::RwLock;\n \n /// MmapSerializatioSink is faster on macOS and Linux\n /// but FileSerializationSink is faster on Windows\n@@ -19,11 +104,6 @@ type SerializationSink = measureme::FileSerializationSink;\n \n type Profiler = measureme::Profiler<SerializationSink>;\n \n-pub trait QueryName: Sized + Copy {\n-    fn discriminant(self) -> Discriminant<Self>;\n-    fn as_str(self) -> &'static str;\n-}\n-\n #[derive(Clone, Copy, Debug, PartialEq, Eq, Ord, PartialOrd)]\n pub enum ProfileCategory {\n     Parsing,\n@@ -65,9 +145,12 @@ const EVENT_FILTERS_BY_NAME: &[(&str, EventFilter)] = &[\n ];\n \n fn thread_id_to_u32(tid: ThreadId) -> u32 {\n-    unsafe { mem::transmute::<ThreadId, u64>(tid) as u32 }\n+    unsafe { std::mem::transmute::<ThreadId, u64>(tid) as u32 }\n }\n \n+/// Something that uniquely identifies a query invocation.\n+pub struct QueryInvocationId(pub u32);\n+\n /// A reference to the SelfProfiler. It can be cloned and sent across thread\n /// boundaries at will.\n #[derive(Clone)]\n@@ -167,29 +250,32 @@ impl SelfProfilerRef {\n     /// Start profiling a generic activity. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn generic_activity(&self, event_id: &str) -> TimingGuard<'_> {\n+    pub fn generic_activity(&self, event_id: &'static str) -> TimingGuard<'_> {\n         self.exec(EventFilter::GENERIC_ACTIVITIES, |profiler| {\n-            let event_id = profiler.profiler.alloc_string(event_id);\n-            TimingGuard::start(profiler, profiler.generic_activity_event_kind, event_id)\n+            let event_id = profiler.get_or_alloc_cached_string(event_id);\n+            TimingGuard::start(\n+                profiler,\n+                profiler.generic_activity_event_kind,\n+                event_id\n+            )\n         })\n     }\n \n     /// Start profiling a query provider. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn query_provider(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn query_provider(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::QUERY_PROVIDERS, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.query_event_kind, event_id)\n+            TimingGuard::start(profiler, profiler.query_event_kind, StringId::INVALID)\n         })\n     }\n \n     /// Record a query in-memory cache hit.\n     #[inline(always)]\n-    pub fn query_cache_hit(&self, query_name: impl QueryName) {\n+    pub fn query_cache_hit(&self, query_invocation_id: QueryInvocationId) {\n         self.instant_query_event(\n             |profiler| profiler.query_cache_hit_event_kind,\n-            query_name,\n+            query_invocation_id,\n             EventFilter::QUERY_CACHE_HITS,\n         );\n     }\n@@ -198,33 +284,39 @@ impl SelfProfilerRef {\n     /// Profiling continues until the TimingGuard returned from this call is\n     /// dropped.\n     #[inline(always)]\n-    pub fn query_blocked(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn query_blocked(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::QUERY_BLOCKED, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.query_blocked_event_kind, event_id)\n+            TimingGuard::start(\n+                profiler,\n+                profiler.query_blocked_event_kind,\n+                StringId::INVALID,\n+            )\n         })\n     }\n \n     /// Start profiling how long it takes to load a query result from the\n     /// incremental compilation on-disk cache. Profiling continues until the\n     /// TimingGuard returned from this call is dropped.\n     #[inline(always)]\n-    pub fn incr_cache_loading(&self, query_name: impl QueryName) -> TimingGuard<'_> {\n+    pub fn incr_cache_loading(&self) -> TimingGuard<'_> {\n         self.exec(EventFilter::INCR_CACHE_LOADS, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n-            TimingGuard::start(profiler, profiler.incremental_load_result_event_kind, event_id)\n+            TimingGuard::start(\n+                profiler,\n+                profiler.incremental_load_result_event_kind,\n+                StringId::INVALID,\n+            )\n         })\n     }\n \n     #[inline(always)]\n     fn instant_query_event(\n         &self,\n         event_kind: fn(&SelfProfiler) -> StringId,\n-        query_name: impl QueryName,\n+        query_invocation_id: QueryInvocationId,\n         event_filter: EventFilter,\n     ) {\n         drop(self.exec(event_filter, |profiler| {\n-            let event_id = SelfProfiler::get_query_name_string_id(query_name);\n+            let event_id = StringId::new_virtual(query_invocation_id.0);\n             let thread_id = thread_id_to_u32(std::thread::current().id());\n \n             profiler.profiler.record_instant_event(event_kind(profiler), event_id, thread_id);\n@@ -233,7 +325,7 @@ impl SelfProfilerRef {\n         }));\n     }\n \n-    pub fn register_queries(&self, f: impl FnOnce(&SelfProfiler)) {\n+    pub fn with_profiler(&self, f: impl FnOnce(&SelfProfiler)) {\n         if let Some(profiler) = &self.profiler {\n             f(&profiler)\n         }\n@@ -243,6 +335,9 @@ impl SelfProfilerRef {\n pub struct SelfProfiler {\n     profiler: Profiler,\n     event_filter_mask: EventFilter,\n+\n+    string_cache: RwLock<FxHashMap<&'static str, StringId>>,\n+\n     query_event_kind: StringId,\n     generic_activity_event_kind: StringId,\n     incremental_load_result_event_kind: StringId,\n@@ -305,6 +400,7 @@ impl SelfProfiler {\n         Ok(SelfProfiler {\n             profiler,\n             event_filter_mask,\n+            string_cache: RwLock::new(FxHashMap::default()),\n             query_event_kind,\n             generic_activity_event_kind,\n             incremental_load_result_event_kind,\n@@ -313,16 +409,41 @@ impl SelfProfiler {\n         })\n     }\n \n-    fn get_query_name_string_id(query_name: impl QueryName) -> StringId {\n-        let discriminant =\n-            unsafe { mem::transmute::<Discriminant<_>, u64>(query_name.discriminant()) };\n+    pub fn get_or_alloc_cached_string(&self, s: &'static str) -> StringId {\n+        // Only acquire a read-lock first since we assume that the string is\n+        // already present in the common case.\n+        {\n+            let string_cache = self.string_cache.read();\n+\n+            if let Some(&id) = string_cache.get(s) {\n+                return id\n+            }\n+        }\n+\n+        let mut string_cache = self.string_cache.write();\n+        // Check if the string has already been added in the small time window\n+        // between dropping the read lock and acquiring the write lock.\n+        *string_cache.entry(s).or_insert_with(|| self.profiler.alloc_string(s))\n+    }\n \n-        StringId::reserved(discriminant as u32)\n+    pub fn map_query_invocation_id_to_string(\n+        &self,\n+        from: QueryInvocationId,\n+        to: StringId\n+    ) {\n+        let from = StringId::new_virtual(from.0);\n+        self.profiler.map_virtual_to_concrete_string(from, to);\n     }\n \n-    pub fn register_query_name(&self, query_name: impl QueryName) {\n-        let id = SelfProfiler::get_query_name_string_id(query_name);\n-        self.profiler.alloc_string_with_reserved_id(id, query_name.as_str());\n+    pub fn bulk_map_query_invocation_id_to_single_string<I>(\n+        &self,\n+        from: I,\n+        to: StringId\n+    )\n+        where I: Iterator<Item=QueryInvocationId> + ExactSizeIterator\n+    {\n+        let from = from.map(|qid| StringId::new_virtual(qid.0));\n+        self.profiler.bulk_map_virtual_to_single_concrete_string(from, to);\n     }\n }\n \n@@ -343,6 +464,14 @@ impl<'a> TimingGuard<'a> {\n         TimingGuard(Some(timing_guard))\n     }\n \n+    #[inline]\n+    pub fn finish_with_query_invocation_id(self, query_invocation_id: QueryInvocationId) {\n+        if let Some(guard) = self.0 {\n+            let event_id = StringId::new_virtual(query_invocation_id.0);\n+            guard.finish_with_override_event_id(event_id);\n+        }\n+    }\n+\n     #[inline]\n     pub fn none() -> TimingGuard<'a> {\n         TimingGuard(None)"}, {"sha": "8e381a27b414f335da858c0da5f651f037c23088", "filename": "src/librustc_interface/util.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_interface%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a62c040929a0620498c85f7a051e4005c28ff4d7/src%2Flibrustc_interface%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_interface%2Futil.rs?ref=a62c040929a0620498c85f7a051e4005c28ff4d7", "patch": "@@ -71,10 +71,6 @@ pub fn create_session(\n         lint_caps,\n     );\n \n-    sess.prof.register_queries(|profiler| {\n-        rustc::ty::query::QueryName::register_with_profiler(&profiler);\n-    });\n-\n     let codegen_backend = get_codegen_backend(&sess);\n \n     let mut cfg = config::build_configuration(&sess, config::to_crate_config(cfg));"}]}