{"sha": "e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "node_id": "MDY6Q29tbWl0NzI0NzEyOmUyYjVmNGZhYzQ5NjdmZGMxOGU1MWMyMzk0ZTM0OTMyYjlhMjFkOTQ=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-14T06:16:33Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-07-14T06:16:33Z"}, "message": "move everything into the Rust tree", "tree": {"sha": "cb39dbc92af5d0b8ef149a53d69ca84b79d8877d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/cb39dbc92af5d0b8ef149a53d69ca84b79d8877d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "html_url": "https://github.com/rust-lang/rust/commit/e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dd46cf8b22c39a74b786361e00af22314a32b196", "url": "https://api.github.com/repos/rust-lang/rust/commits/dd46cf8b22c39a74b786361e00af22314a32b196", "html_url": "https://github.com/rust-lang/rust/commit/dd46cf8b22c39a74b786361e00af22314a32b196"}, {"sha": "a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8", "url": "https://api.github.com/repos/rust-lang/rust/commits/a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8", "html_url": "https://github.com/rust-lang/rust/commit/a54e64b3c41103c4f6ab840d8ddd3a56ec6b5da8"}], "stats": {"total": 4697, "additions": 4697, "deletions": 0}, "files": [{"sha": "874f6f2ac61211038f544a7e06471cb8f8b7333c", "filename": "src/doc/tarpl/README.md", "status": "added", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2FREADME.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,39 @@\n+% The Advanced Rust Programming Language\n+\n+# NOTE: This is a draft document, and may contain serious errors\n+\n+So you've played around with Rust a bit. You've written a few simple programs and\n+you think you grok the basics. Maybe you've even read through\n+*[The Rust Programming Language][trpl]*. Now you want to get neck-deep in all the\n+nitty-gritty details of the language. You want to know those weird corner-cases.\n+You want to know what the heck `unsafe` really means, and how to properly use it.\n+This is the book for you.\n+\n+To be clear, this book goes into *serious* detail. We're going to dig into\n+exception-safety and pointer aliasing. We're going to talk about memory\n+models. We're even going to do some type-theory. This is stuff that you\n+absolutely *don't* need to know to write fast and safe Rust programs.\n+You could probably close this book *right now* and still have a productive\n+and happy career in Rust.\n+\n+However if you intend to write unsafe code -- or just *really* want to dig into\n+the guts of the language -- this book contains *invaluable* information.\n+\n+Unlike *The Rust Programming Language* we *will* be assuming considerable prior\n+knowledge. In particular, you should be comfortable with:\n+\n+* Basic Systems Programming:\n+    * Pointers\n+    * [The stack and heap][]\n+    * The memory hierarchy (caches)\n+    * Threads\n+\n+* [Basic Rust][]\n+\n+Due to the nature of advanced Rust programming, we will be spending a lot of time\n+talking about *safety* and *guarantees*. In particular, a significant portion of\n+the book will be dedicated to correctly writing and understanding Unsafe Rust.\n+\n+[trpl]: https://doc.rust-lang.org/book/\n+[The stack and heap]: https://doc.rust-lang.org/book/the-stack-and-the-heap.html\n+[Basic Rust]: https://doc.rust-lang.org/book/syntax-and-semantics.html"}, {"sha": "8a8ea6dfab7994b6acde6dcf0726ca217acec147", "filename": "src/doc/tarpl/SUMMARY.md", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2FSUMMARY.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2FSUMMARY.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2FSUMMARY.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,49 @@\n+# Summary\n+\n+* [Meet Safe and Unsafe](meet-safe-and-unsafe.md)\n+\t* [How Safe and Unsafe Interact](safe-unsafe-meaning.md)\n+\t* [Working with Unsafe](working-with-unsafe.md)\n+* [Data Layout](data.md)\n+\t* [repr(Rust)](repr-rust.md)\n+\t* [Exotically Sized Types](exotic-sizes.md)\n+\t* [Other reprs](other-reprs.md)\n+* [Ownership](ownership.md)\n+\t* [References](references.md)\n+\t* [Lifetimes](lifetimes.md)\n+\t* [Limits of lifetimes](lifetime-mismatch.md)\n+\t* [Lifetime Elision](lifetime-elision.md)\n+\t* [Unbounded Lifetimes](unbounded-lifetimes.md)\n+\t* [Higher-Rank Trait Bounds](hrtb.md)\n+\t* [Subtyping and Variance](subtyping.md)\n+\t* [Misc](lifetime-misc.md)\n+* [Type Conversions](conversions.md)\n+\t* [Coercions](coercions.md)\n+\t* [The Dot Operator](dot-operator.md)\n+\t* [Casts](casts.md)\n+\t* [Transmutes](transmutes.md)\n+* [Uninitialized Memory](uninitialized.md)\n+\t* [Checked](checked-uninit.md)\n+\t* [Drop Flags](drop-flags.md)\n+\t* [Unchecked](unchecked-uninit.md)\n+* [Ownership-Oriented Resource Management](raii.md)\n+\t* [Constructors](constructors.md)\n+\t* [Destructors](destructors.md)\n+\t* [Leaking](leaking.md)\n+* [Unwinding](unwinding.md)\n+\t* [Exception Safety](exception-safety.md)\n+\t* [Poisoning](poisoning.md)\n+* [Concurrency](concurrency.md)\n+\t* [Races](races.md)\n+\t* [Send and Sync](send-and-sync.md)\n+\t* [Atomics](atomics.md)\n+* [Implementing Vec](vec.md)\n+\t* [Layout](vec-layout.md)\n+\t* [Allocating](vec-alloc.md)\n+\t* [Push and Pop](vec-push-pop.md)\n+\t* [Deallocating](vec-dealloc.md)\n+\t* [Deref](vec-deref.md)\n+\t* [Insert and Remove](vec-insert-remove.md)\n+\t* [IntoIter](vec-into-iter.md)\n+\t* [Drain](vec-drain.md)\n+\t* [Final Code](vec-final.md)\n+* [Implementing Arc and Mutex](arc-and-mutex.md)"}, {"sha": "d28180fa9cf589cf8a59115de1ca5ca934ff7374", "filename": "src/doc/tarpl/arc-and-mutex.md", "status": "added", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Farc-and-mutex.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Farc-and-mutex.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Farc-and-mutex.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,7 @@\n+% Implementing Arc and Mutex\n+\n+Knowing the theory is all fine and good, but the *best* was to understand\n+something is to use it. To better understand atomics and interior mutability,\n+we'll be implementing versions of the standard library's Arc and Mutex types.\n+\n+TODO: ALL OF THIS OMG"}, {"sha": "82e69dd2e13fc0bd6f091dedcdbe734a0508684c", "filename": "src/doc/tarpl/atomics.md", "status": "added", "additions": 251, "deletions": 0, "changes": 251, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fatomics.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fatomics.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fatomics.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,251 @@\n+% Atomics\n+\n+Rust pretty blatantly just inherits C11's memory model for atomics. This is not\n+due this model being particularly excellent or easy to understand. Indeed, this\n+model is quite complex and known to have [several flaws][C11-busted]. Rather,\n+it is a pragmatic concession to the fact that *everyone* is pretty bad at modeling\n+atomics. At very least, we can benefit from existing tooling and research around\n+C.\n+\n+Trying to fully explain the model in this book is fairly hopeless. It's defined\n+in terms of madness-inducing causality graphs that require a full book to properly\n+understand in a practical way. If you want all the nitty-gritty details, you\n+should check out [C's specification (Section 7.17)][C11-model]. Still, we'll try\n+to cover the basics and some of the problems Rust developers face.\n+\n+The C11 memory model is fundamentally about trying to bridge the gap between\n+the semantics we want, the optimizations compilers want, and the inconsistent\n+chaos our hardware wants. *We* would like to just write programs and have them\n+do exactly what we said but, you know, *fast*. Wouldn't that be great?\n+\n+\n+\n+\n+# Compiler Reordering\n+\n+Compilers fundamentally want to be able to do all sorts of crazy transformations\n+to reduce data dependencies and eliminate dead code. In particular, they may\n+radically change the actual order of events, or make events never occur! If we\n+write something like\n+\n+```rust,ignore\n+x = 1;\n+y = 3;\n+x = 2;\n+```\n+\n+The compiler may conclude that it would *really* be best if your program did\n+\n+```rust,ignore\n+x = 2;\n+y = 3;\n+```\n+\n+This has inverted the order of events *and* completely eliminated one event. From\n+a single-threaded perspective this is completely unobservable: after all the\n+statements have executed we are in exactly the same state. But if our program is\n+multi-threaded, we may have been relying on `x` to *actually* be assigned to 1 before\n+`y` was assigned. We would *really* like the compiler to be able to make these kinds\n+of optimizations, because they can seriously improve performance. On the other hand,\n+we'd really like to be able to depend on our program *doing the thing we said*.\n+\n+\n+\n+\n+# Hardware Reordering\n+\n+On the other hand, even if the compiler totally understood what we wanted and\n+respected our wishes, our *hardware* might instead get us in trouble. Trouble comes\n+from CPUs in the form of memory hierarchies. There is indeed a global shared memory\n+space somewhere in your hardware, but from the perspective of each CPU core it is\n+*so very far away* and *so very slow*. Each CPU would rather work with its local\n+cache of the data and only go through all the *anguish* of talking to shared\n+memory *only* when it doesn't actually have that memory in cache.\n+\n+After all, that's the whole *point* of the cache, right? If every read from the\n+cache had to run back to shared memory to double check that it hadn't changed,\n+what would the point be? The end result is that the hardware doesn't guarantee\n+that events that occur in the same order on *one* thread, occur in the same order\n+on *another* thread. To guarantee this, we must issue special instructions to\n+the CPU telling it to be a bit less smart.\n+\n+For instance, say we convince the compiler to emit this logic:\n+\n+```text\n+initial state: x = 0, y = 1\n+\n+THREAD 1        THREAD2\n+y = 3;          if x == 1 {\n+x = 1;              y *= 2;\n+                }\n+```\n+\n+Ideally this program has 2 possible final states:\n+\n+* `y = 3`: (thread 2 did the check before thread 1 completed)\n+* `y = 6`: (thread 2 did the check after thread 1 completed)\n+\n+However there's a third potential state that the hardware enables:\n+\n+* `y = 2`: (thread 2 saw `x = 2`, but not `y = 3`, and then overwrote `y = 3`)\n+\n+It's worth noting that different kinds of CPU provide different guarantees. It\n+is common to seperate hardware into two categories: strongly-ordered and weakly-\n+ordered. Most notably x86/64 provides strong ordering guarantees, while ARM and\n+provides weak ordering guarantees. This has two consequences for\n+concurrent programming:\n+\n+* Asking for stronger guarantees on strongly-ordered hardware may be cheap or\n+  even *free* because they already provide strong guarantees unconditionally.\n+  Weaker guarantees may only yield performance wins on weakly-ordered hardware.\n+\n+* Asking for guarantees that are *too* weak on strongly-ordered hardware\n+  is more likely to *happen* to work, even though your program is strictly\n+  incorrect. If possible, concurrent algorithms should be tested on\n+  weakly-ordered hardware.\n+\n+\n+\n+\n+\n+# Data Accesses\n+\n+The C11 memory model attempts to bridge the gap by allowing us to talk about\n+the *causality* of our program. Generally, this is by establishing a\n+*happens before* relationships between parts of the program and the threads\n+that are running them. This gives the hardware and compiler room to optimize the\n+program more aggressively where a strict happens-before relationship isn't\n+established, but forces them to be more careful where one *is* established.\n+The way we communicate these relationships are through *data accesses* and\n+*atomic accesses*.\n+\n+Data accesses are the bread-and-butter of the programming world. They are\n+fundamentally unsynchronized and compilers are free to aggressively optimize\n+them. In particular, data accesses are free to be reordered by the compiler\n+on the assumption that the program is single-threaded. The hardware is also free\n+to propagate the changes made in data accesses to other threads\n+as lazily and inconsistently as it wants. Mostly critically, data accesses are\n+how data races happen. Data accesses are very friendly to the hardware and\n+compiler, but as we've seen they offer *awful* semantics to try to\n+write synchronized code with. Actually, that's too weak. *It is literally\n+impossible to write correct synchronized code using only data accesses*.\n+\n+Atomic accesses are how we tell the hardware and compiler that our program is\n+multi-threaded. Each atomic access can be marked with\n+an *ordering* that specifies what kind of relationship it establishes with\n+other accesses. In practice, this boils down to telling the compiler and hardware\n+certain things they *can't* do. For the compiler, this largely revolves\n+around re-ordering of instructions. For the hardware, this largely revolves\n+around how writes are propagated to other threads. The set of orderings Rust\n+exposes are:\n+\n+* Sequentially Consistent (SeqCst)\n+* Release\n+* Acquire\n+* Relaxed\n+\n+(Note: We explicitly do not expose the C11 *consume* ordering)\n+\n+TODO: negative reasoning vs positive reasoning?\n+TODO: \"can't forget to synchronize\"\n+\n+\n+\n+# Sequentially Consistent\n+\n+Sequentially Consistent is the most powerful of all, implying the restrictions\n+of all other orderings. Intuitively, a sequentially consistent operation *cannot*\n+be reordered: all accesses on one thread that happen before and after it *stay*\n+before and after it. A data-race-free program that uses only sequentially consistent\n+atomics and data accesses has the very nice property that there is a single global\n+execution of the program's instructions that all threads agree on. This execution\n+is also particularly nice to reason about: it's just an interleaving of each thread's\n+individual executions. This *does not* hold if you start using the weaker atomic\n+orderings.\n+\n+The relative developer-friendliness of sequential consistency doesn't come for\n+free. Even on strongly-ordered platforms sequential consistency involves\n+emitting memory fences.\n+\n+In practice, sequential consistency is rarely necessary for program correctness.\n+However sequential consistency is definitely the right choice if you're not\n+confident about the other memory orders. Having your program run a bit slower\n+than it needs to is certainly better than it running incorrectly! It's also\n+*mechanically* trivial to downgrade atomic operations to have a weaker\n+consistency later on. Just change `SeqCst` to e.g. `Relaxed` and you're done! Of\n+course, proving that this transformation is *correct* is whole other matter.\n+\n+\n+\n+\n+# Acquire-Release\n+\n+Acquire and Release are largely intended to be paired. Their names hint at\n+their use case: they're perfectly suited for acquiring and releasing locks,\n+and ensuring that critical sections don't overlap.\n+\n+Intuitively, an acquire access ensures that every access after it *stays* after\n+it. However operations that occur before an acquire are free to be reordered to\n+occur after it. Similarly, a release access ensures that every access before it\n+*stays* before it. However operations that occur after a release are free to\n+be reordered to occur before it.\n+\n+When thread A releases a location in memory and then thread B subsequently\n+acquires *the same* location in memory, causality is established. Every write\n+that happened *before* A's release will be observed by B *after* it's release.\n+However no causality is established with any other threads. Similarly, no\n+causality is established if A and B access *different* locations in memory.\n+\n+Basic use of release-acquire is therefore simple: you acquire a location of\n+memory to begin the critical section, and then release that location to end it.\n+For instance, a simple spinlock might look like:\n+\n+```rust\n+use std::sync::Arc;\n+use std::sync::atomic::{AtomicBool, Ordering};\n+use std::thread;\n+\n+fn main() {\n+    let lock = Arc::new(AtomicBool::new(true)); // value answers \"am I locked?\"\n+\n+    // ... distribute lock to threads somehow ...\n+\n+    // Try to acquire the lock by setting it to false\n+    while !lock.compare_and_swap(true, false, Ordering::Acquire) { }\n+    // broke out of the loop, so we successfully acquired the lock!\n+\n+    // ... scary data accesses ...\n+\n+    // ok we're done, release the lock\n+    lock.store(true, Ordering::Release);\n+}\n+```\n+\n+On strongly-ordered platforms most accesses have release or acquire semantics,\n+making release and acquire often totally free. This is not the case on\n+weakly-ordered platforms.\n+\n+\n+\n+\n+# Relaxed\n+\n+Relaxed accesses are the absolute weakest. They can be freely re-ordered and\n+provide no happens-before relationship. Still, relaxed operations *are* still\n+atomic. That is, they don't count as data accesses and any read-modify-write\n+operations done to them occur atomically. Relaxed operations are appropriate for\n+things that you definitely want to happen, but don't particularly otherwise care\n+about. For instance, incrementing a counter can be safely done by multiple\n+threads using a relaxed `fetch_add` if you're not using the counter to\n+synchronize any other accesses.\n+\n+There's rarely a benefit in making an operation relaxed on strongly-ordered\n+platforms, since they usually provide release-acquire semantics anyway. However\n+relaxed operations can be cheaper on weakly-ordered platforms.\n+\n+\n+\n+\n+\n+[C11-busted]: http://plv.mpi-sws.org/c11comp/popl15.pdf\n+[C11-model]: http://www.open-std.org/jtc1/sc22/wg14/www/standards.html#9899"}, {"sha": "730d8499acfea453d7d60fe534534e9f9ac4f7c2", "filename": "src/doc/tarpl/casts.md", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fcasts.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fcasts.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fcasts.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,55 @@\n+% Casts\n+\n+Casts are a superset of coercions: every coercion can be explicitly invoked via a\n+cast, but some conversions *require* a cast. These \"true casts\" are generally regarded\n+as dangerous or problematic actions. True casts revolve around raw pointers and\n+the primitive numeric types. True casts aren't checked.\n+\n+Here's an exhaustive list of all the true casts. For brevity, we will use `*`\n+to denote either a `*const` or `*mut`, and `integer` to denote any integral primitive:\n+\n+ * `*T as *U` where `T, U: Sized`\n+ * `*T as *U` TODO: explain unsized situation\n+ * `*T as integer`\n+ * `integer as *T`\n+ * `number as number`\n+ * `C-like-enum as integer`\n+ * `bool as integer`\n+ * `char as integer`\n+ * `u8 as char`\n+ * `&[T; n] as *const T`\n+ * `fn as *T` where `T: Sized`\n+ * `fn as integer`\n+\n+where `&.T` and `*T` are references of either mutability,\n+and where unsize_kind(`T`) is the kind of the unsize info\n+in `T` - the vtable for a trait definition (e.g. `fmt::Display` or\n+`Iterator`, not `Iterator<Item=u8>`) or a length (or `()` if `T: Sized`).\n+\n+Note that lengths are not adjusted when casting raw slices -\n+`T: *const [u16] as *const [u8]` creates a slice that only includes\n+half of the original memory.\n+\n+Casting is not transitive, that is, even if `e as U1 as U2` is a valid\n+expression, `e as U2` is not necessarily so (in fact it will only be valid if\n+`U1` coerces to `U2`).\n+\n+For numeric casts, there are quite a few cases to consider:\n+\n+* casting between two integers of the same size (e.g. i32 -> u32) is a no-op\n+* casting from a larger integer to a smaller integer (e.g. u32 -> u8) will truncate\n+* casting from a smaller integer to a larger integer (e.g. u8 -> u32) will\n+    * zero-extend if the source is unsigned\n+    * sign-extend if the source is signed\n+* casting from a float to an integer will round the float towards zero\n+    * **NOTE: currently this will cause Undefined Behaviour if the rounded\n+      value cannot be represented by the target integer type**. This is a bug\n+      and will be fixed. (TODO: figure out what Inf and NaN do)\n+* casting from an integer to float will produce the floating point representation\n+  of the integer, rounded if necessary (rounding strategy unspecified).\n+* casting from an f32 to an f64 is perfect and lossless.\n+* casting from an f64 to an f32 will produce the closest possible value\n+  (rounding strategy unspecified).\n+    * **NOTE: currently this will cause Undefined Behaviour if the value\n+      is finite but larger or smaller than the largest or smallest finite\n+      value representable by f32**. This is a bug and will be fixed."}, {"sha": "8896fc9de0199d22169c288c942182db585799f5", "filename": "src/doc/tarpl/checked-uninit.md", "status": "added", "additions": 85, "deletions": 0, "changes": 85, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fchecked-uninit.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fchecked-uninit.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fchecked-uninit.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,85 @@\n+% Checked Uninitialized Memory\n+\n+Like C, all stack variables in Rust are uninitialized until a\n+value is explicitly assigned to them. Unlike C, Rust statically prevents you\n+from ever reading them until you do:\n+\n+```rust\n+fn main() {\n+\tlet x: i32;\n+\tprintln!(\"{}\", x);\n+}\n+```\n+\n+```text\n+src/main.rs:3:20: 3:21 error: use of possibly uninitialized variable: `x`\n+src/main.rs:3     println!(\"{}\", x);\n+                                 ^\n+```\n+\n+This is based off of a basic branch analysis: every branch must assign a value\n+to `x` before it is first used. Interestingly, Rust doesn't require the variable\n+to be mutable to perform a delayed initialization if every branch assigns\n+exactly once. However the analysis does not take advantage of constant analysis\n+or anything like that. So this compiles:\n+\n+```rust\n+fn main() {\n+\tlet x: i32;\n+\n+\tif true {\n+\t\tx = 1;\n+\t} else {\n+\t\tx = 2;\n+\t}\n+\n+    println!(\"{}\", x);\n+}\n+```\n+\n+but this doesn't:\n+\n+```rust\n+fn main() {\n+\tlet x: i32;\n+\tif true {\n+\t\tx = 1;\n+\t}\n+\tprintln!(\"{}\", x);\n+}\n+```\n+\n+```text\n+src/main.rs:6:17: 6:18 error: use of possibly uninitialized variable: `x`\n+src/main.rs:6 \tprintln!(\"{}\", x);\n+```\n+\n+while this does:\n+\n+```rust\n+fn main() {\n+\tlet x: i32;\n+\tif true {\n+\t\tx = 1;\n+\t\tprintln!(\"{}\", x);\n+\t}\n+\t// Don't care that there are branches where it's not initialized\n+\t// since we don't use the value in those branches\n+}\n+```\n+\n+If a value is moved out of a variable, that variable becomes logically\n+uninitialized if the type of the value isn't Copy. That is:\n+\n+```rust\n+fn main() {\n+\tlet x = 0;\n+\tlet y = Box::new(0);\n+\tlet z1 = x; // x is still valid because i32 is Copy\n+\tlet z2 = y; // y is now logically uninitialized because Box isn't Copy\n+}\n+```\n+\n+However reassigning `y` in this example *would* require `y` to be marked as\n+mutable, as a Safe Rust program could observe that the value of `y` changed.\n+Otherwise the variable is exactly like new."}, {"sha": "fad9b09c3c38dbc226180dda4f3f146a187f1021", "filename": "src/doc/tarpl/coercions.md", "status": "added", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fcoercions.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fcoercions.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fcoercions.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,72 @@\n+% Coercions\n+\n+Types can implicitly be coerced to change in certain contexts. These changes are\n+generally just *weakening* of types, largely focused around pointers and lifetimes.\n+They mostly exist to make Rust \"just work\" in more cases, and are largely harmless.\n+\n+Here's all the kinds of coercion:\n+\n+\n+Coercion is allowed between the following types:\n+\n+* Subtyping: `T` to `U` if `T` is a [subtype](lifetimes.html#subtyping-and-variance)\n+  of `U`\n+* Transitivity: `T_1` to `T_3` where `T_1` coerces to `T_2` and `T_2` coerces to `T_3`\n+* Pointer Weakening:\n+    * `&mut T` to `&T`\n+    * `*mut T` to `*const T`\n+    * `&T` to `*const T`\n+    * `&mut T` to `*mut T`\n+* Unsizing: `T` to `U` if `T` implements `CoerceUnsized<U>`\n+\n+`CoerceUnsized<Pointer<U>> for Pointer<T> where T: Unsize<U>` is implemented\n+for all pointer types (including smart pointers like Box and Rc). Unsize is\n+only implemented automatically, and enables the following transformations:\n+\n+* `[T, ..n]` => `[T]`\n+* `T` => `Trait` where `T: Trait`\n+* `SubTrait` => `Trait` where `SubTrait: Trait` (TODO: is this now implied by the previous?)\n+* `Foo<..., T, ...>` => `Foo<..., U, ...>` where:\n+    * `T: Unsize<U>`\n+    * `Foo` is a struct\n+    * Only the last field has type `T`\n+    * `T` is not part of the type of any other fields\n+\n+Coercions occur at a *coercion site*. Any location that is explicitly typed\n+will cause a coercion to its type. If inference is necessary, the coercion will\n+not be performed. Exhaustively, the coercion sites for an expression `e` to\n+type `U` are:\n+\n+* let statements, statics, and consts: `let x: U = e`\n+* Arguments to functions: `takes_a_U(e)`\n+* Any expression that will be returned: `fn foo() -> U { e }`\n+* Struct literals: `Foo { some_u: e }`\n+* Array literals: `let x: [U; 10] = [e, ..]`\n+* Tuple literals: `let x: (U, ..) = (e, ..)`\n+* The last expression in a block: `let x: U = { ..; e }`\n+\n+Note that we do not perform coercions when matching traits (except for\n+receivers, see below). If there is an impl for some type `U` and `T` coerces to\n+`U`, that does not constitute an implementation for `T`. For example, the\n+following will not type check, even though it is OK to coerce `t` to `&T` and\n+there is an impl for `&T`:\n+\n+```rust\n+trait Trait {}\n+\n+fn foo<X: Trait>(t: X) {}\n+\n+impl<'a> Trait for &'a i32 {}\n+\n+\n+fn main() {\n+    let t: &mut i32 = &mut 0;\n+    foo(t);\n+}\n+```\n+\n+```text\n+<anon>:10:5: 10:8 error: the trait `Trait` is not implemented for the type `&mut i32` [E0277]\n+<anon>:10     foo(t);\n+              ^~~\n+```"}, {"sha": "95973b35d4ffe88583f86c1ec7db0b63258cafe6", "filename": "src/doc/tarpl/concurrency.md", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconcurrency.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconcurrency.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fconcurrency.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,13 @@\n+% Concurrency and Paralellism\n+\n+Rust as a language doesn't *really* have an opinion on how to do concurrency or\n+parallelism. The standard library exposes OS threads and blocking sys-calls\n+because *everyone* has those, and they're uniform enough that you can provide\n+an abstraction over them in a relatively uncontroversial way. Message passing,\n+green threads, and async APIs are all diverse enough that any abstraction over\n+them tends to involve trade-offs that we weren't willing to commit to for 1.0.\n+\n+However the way Rust models concurrency makes it relatively easy design your own\n+concurrency paradigm as a library and have *everyone else's* code Just Work\n+with yours. Just require the right lifetimes and Send and Sync where appropriate\n+and you're off to the races. Or rather, off to the... not... having... races.\n\\ No newline at end of file"}, {"sha": "99bcf5e283ee38a3667e482fd9eb498c454ffc6f", "filename": "src/doc/tarpl/constructors.md", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconstructors.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconstructors.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fconstructors.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,55 @@\n+% Constructors\n+\n+There is exactly one way to create an instance of a user-defined type: name it,\n+and initialize all its fields at once:\n+\n+```rust\n+struct Foo {\n+\ta: u8,\n+\tb: u32,\n+\tc: bool,\n+}\n+\n+enum Bar {\n+\tX(u32),\n+\tY(bool),\n+}\n+\n+struct Empty;\n+\n+let foo = Foo { a: 0, b: 1, c: false };\n+let bar = Bar::X(0);\n+let empty = Empty;\n+```\n+\n+That's it. Every other way you make an instance of a type is just calling a\n+totally vanilla function that does some stuff and eventually bottoms out to The\n+One True Constructor.\n+\n+Unlike C++, Rust does not come with a slew of built in kinds of constructor.\n+There are no Copy, Default, Assignment, Move, or whatever constructors. The\n+reasons for this are varied, but it largely boils down to Rust's philosophy\n+of *being explicit*.\n+\n+Move constructors are meaningless in Rust because we don't enable types to\n+\"care\" about their location in memory. Every type must be ready for it to be\n+blindly memcopied to somewhere else in memory. This means pure on-the-stack-but-\n+still-movable intrusive linked lists are simply not happening in Rust (safely).\n+\n+Assignment and copy constructors similarly don't exist because move semantics\n+are the *only* semantics in Rust. At most `x = y` just moves the bits of y into the x\n+variable. Rust *does* provide two facilities for providing C++'s copy-oriented\n+semantics: `Copy` and `Clone`. Clone is our moral equivalent of a copy\n+constructor, but it's never implicitly invoked. You have to explicitly call\n+`clone` on an element you want to be cloned. Copy is a special case of Clone\n+where the implementation is just \"copy the bits\". Copy types *are* implicitly\n+cloned whenever they're moved, but because of the definition of Copy this just\n+means *not* treating the old copy as uninitialized -- a no-op.\n+\n+While Rust provides a `Default` trait for specifying the moral equivalent of a\n+default constructor, it's incredibly rare for this trait to be used. This is\n+because variables [aren't implicitly initialized][uninit]. Default is basically\n+only useful for generic programming. In concrete contexts, a type will provide a\n+static `new` method for any kind of \"default\" constructor. This has no relation\n+to `new` in other languages and has no special meaning. It's just a naming\n+convention."}, {"sha": "388516fc7e9e202d5c32d630d2986e67875fd642", "filename": "src/doc/tarpl/conversions.md", "status": "added", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconversions.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fconversions.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fconversions.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,31 @@\n+% Type Conversions\n+\n+At the end of the day, everything is just a pile of bits somewhere, and type systems\n+are just there to help us use those bits right. Needing to reinterpret those piles\n+of bits as different types is a common problem and Rust consequently gives you\n+several ways to do that.\n+\n+First we'll look at the ways that *Safe Rust* gives you to reinterpret values. The\n+most trivial way to do this is to just destructure a value into its constituent\n+parts and then build a new type out of them. e.g.\n+\n+```rust\n+struct Foo {\n+    x: u32,\n+    y: u16,\n+}\n+\n+struct Bar {\n+    a: u32,\n+    b: u16,\n+}\n+\n+fn reinterpret(foo: Foo) -> Bar {\n+    let Foo { x, y } = foo;\n+    Bar { a: x, b: y }\n+}\n+```\n+\n+But this is, at best, annoying to do. For common conversions, rust provides\n+more ergonomic alternatives.\n+"}, {"sha": "88d169c3709aa1cc83164df41fa487801cd82b22", "filename": "src/doc/tarpl/data.md", "status": "added", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdata.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdata.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fdata.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,5 @@\n+% Data Representation in Rust\n+\n+Low-level programming cares a lot about data layout. It's a big deal. It also pervasively\n+influences the rest of the language, so we're going to start by digging into how data is\n+represented in Rust."}, {"sha": "3bc75c132bf69bca317479f5a181fe0ce13d3fd5", "filename": "src/doc/tarpl/destructors.md", "status": "added", "additions": 140, "deletions": 0, "changes": 140, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdestructors.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdestructors.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fdestructors.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,140 @@\n+% Destructors\n+\n+What the language *does* provide is full-blown automatic destructors through the `Drop` trait,\n+which provides the following method:\n+\n+```rust\n+fn drop(&mut self);\n+```\n+\n+This method gives the type time to somehow finish what it was doing. **After `drop` is run,\n+Rust will recursively try to drop all of the fields of `self`**. This is a\n+convenience feature so that you don't have to write \"destructor boilerplate\" to drop\n+children. If a struct has no special logic for being dropped other than dropping its\n+children, then it means `Drop` doesn't need to be implemented at all!\n+\n+**There is no stable way to prevent this behaviour in Rust 1.0**.\n+\n+Note that taking `&mut self` means that even if you *could* suppress recursive Drop,\n+Rust will prevent you from e.g. moving fields out of self. For most types, this\n+is totally fine.\n+\n+For instance, a custom implementation of `Box` might write `Drop` like this:\n+\n+```rust\n+struct Box<T>{ ptr: *mut T }\n+\n+impl<T> Drop for Box<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\t(*self.ptr).drop();\n+\t\t\theap::deallocate(self.ptr);\n+\t\t}\n+\t}\n+}\n+```\n+\n+and this works fine because when Rust goes to drop the `ptr` field it just sees a *mut that\n+has no actual `Drop` implementation. Similarly nothing can use-after-free the `ptr` because\n+the Box is immediately marked as uninitialized.\n+\n+However this wouldn't work:\n+\n+```rust\n+struct Box<T>{ ptr: *mut T }\n+\n+impl<T> Drop for Box<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\t(*self.ptr).drop();\n+\t\t\theap::deallocate(self.ptr);\n+\t\t}\n+\t}\n+}\n+\n+struct SuperBox<T> { box: Box<T> }\n+\n+impl<T> Drop for SuperBox<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\t// Hyper-optimized: deallocate the box's contents for it\n+\t\t\t// without `drop`ing the contents\n+\t\t\theap::deallocate(self.box.ptr);\n+\t\t}\n+\t}\n+}\n+```\n+\n+After we deallocate the `box`'s ptr in SuperBox's destructor, Rust will\n+happily proceed to tell the box to Drop itself and everything will blow up with\n+use-after-frees and double-frees.\n+\n+Note that the recursive drop behaviour applies to *all* structs and enums\n+regardless of whether they implement Drop. Therefore something like\n+\n+```rust\n+struct Boxy<T> {\n+\tdata1: Box<T>,\n+\tdata2: Box<T>,\n+\tinfo: u32,\n+}\n+```\n+\n+will have its data1 and data2's fields destructors whenever it \"would\" be\n+dropped, even though it itself doesn't implement Drop. We say that such a type\n+*needs Drop*, even though it is not itself Drop.\n+\n+Similarly,\n+\n+```rust\n+enum Link {\n+\tNext(Box<Link>),\n+\tNone,\n+}\n+```\n+\n+will have its inner Box field dropped *if and only if* an instance stores the Next variant.\n+\n+In general this works really nice because you don't need to worry about adding/removing\n+drops when you refactor your data layout. Still there's certainly many valid usecases for\n+needing to do trickier things with destructors.\n+\n+The classic safe solution to overriding recursive drop and allowing moving out\n+of Self during `drop` is to use an Option:\n+\n+```rust\n+struct Box<T>{ ptr: *mut T }\n+\n+impl<T> Drop for Box<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\t(*self.ptr).drop();\n+\t\t\theap::deallocate(self.ptr);\n+\t\t}\n+\t}\n+}\n+\n+struct SuperBox<T> { box: Option<Box<T>> }\n+\n+impl<T> Drop for SuperBox<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\t// Hyper-optimized: deallocate the box's contents for it\n+\t\t\t// without `drop`ing the contents. Need to set the `box`\n+\t\t\t// field as `None` to prevent Rust from trying to Drop it.\n+\t\t\theap::deallocate(self.box.take().unwrap().ptr);\n+\t\t}\n+\t}\n+}\n+```\n+\n+However this has fairly odd semantics: you're saying that a field that *should* always\n+be Some may be None, just because that happens in the destructor. Of course this\n+conversely makes a lot of sense: you can call arbitrary methods on self during\n+the destructor, and this should prevent you from ever doing so after deinitializing\n+the field. Not that it will prevent you from producing any other\n+arbitrarily invalid state in there.\n+\n+On balance this is an ok choice. Certainly what you should reach for by default.\n+However, in the future we expect there to be a first-class way to announce that\n+a field shouldn't be automatically dropped.\n\\ No newline at end of file"}, {"sha": "5d2010d15a80381e735dc1dc375d4e1b40b0e220", "filename": "src/doc/tarpl/dot-operator.md", "status": "added", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdot-operator.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdot-operator.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fdot-operator.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,6 @@\n+% The Dot Operator\n+\n+The dot operator will perform a lot of magic to convert types. It will perform\n+auto-referencing, auto-dereferencing, and coercion until types match.\n+\n+TODO: steal information from http://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules/28552082#28552082"}, {"sha": "2d5bae6dcfe9c7729eb35b5777aa871f66c662a2", "filename": "src/doc/tarpl/drop-flags.md", "status": "added", "additions": 78, "deletions": 0, "changes": 78, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdrop-flags.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fdrop-flags.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fdrop-flags.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,78 @@\n+% Drop Flags\n+\n+The examples in the previous section introduce an interesting problem for Rust.\n+We have seen that's possible to conditionally initialize, deinitialize, and\n+*reinitialize* locations of memory totally safely. For Copy types, this isn't\n+particularly notable since they're just a random pile of bits. However types with\n+destructors are a different story: Rust needs to know whether to call a destructor\n+whenever a variable is assigned to, or a variable goes out of scope. How can it\n+do this with conditional initialization?\n+\n+It turns out that Rust actually tracks whether a type should be dropped or not *at\n+runtime*. As a variable becomes initialized and uninitialized, a *drop flag* for\n+that variable is toggled. When a variable *might* need to be dropped, this flag\n+is evaluated to determine if it *should* be dropped.\n+\n+Of course, it is *often* the case that a value's initialization state can be\n+*statically* known at every point in the program. If this is the case, then the\n+compiler can theoretically generate more effecient code! For instance,\n+straight-line code has such *static drop semantics*:\n+\n+```rust\n+let mut x = Box::new(0); // x was uninit\n+let mut y = x;\t\t\t // y was uninit\n+x = Box::new(0);\t \t // x was uninit\n+y = x;\t\t\t\t \t // y was init; Drop y!\n+\t\t\t\t     \t // y was init; Drop y!\n+\t\t\t\t     \t // x was uninit\n+```\n+\n+And even branched code where all branches have the same behaviour with respect\n+to initialization:\n+\n+```rust\n+let mut x = Box::new(0);\t// x was uninit\n+if condition {\n+\tdrop(x)\t\t\t\t\t// x gets moved out\n+} else {\n+\tprintln!(\"{}\", x);\n+\tdrop(x)\t\t\t\t\t// x gets moved out\n+}\n+x = Box::new(0);\t\t\t// x was uninit\n+\t\t\t\t\t\t\t// x was init; Drop x!\n+```\n+\n+However code like this *requires* runtime information to correctly Drop:\n+\n+```rust\n+let x;\n+if condition {\n+\tx = Box::new(0);\t\t// x was uninit\n+\tprintln!(\"{}\", x);\n+}\n+\t\t\t\t\t\t\t// x might be uninit; check the flag!\n+```\n+\n+Of course, in this case it's trivial to retrieve static drop semantics:\n+\n+```rust\n+if condition {\n+\tlet x = Box::new(0);\n+\tprintln!(\"{}\", x);\n+}\n+```\n+\n+As of Rust 1.0, the drop flags are actually not-so-secretly stashed in a hidden\n+field of any type that implements Drop. Rust sets the drop flag by\n+overwriting the *entire* value with a particular byte. This is pretty obviously\n+Not The Fastest and causes a bunch of trouble with optimizing code. It's legacy\n+from a time when you could do much more complex conditional initialization.\n+\n+As such work is currently under way to move the flags out onto the stack frame\n+where they more reasonably belong. Unfortunately, this work will take some time\n+as it requires fairly substantial changes to the compiler.\n+\n+Regardless, Rust programs don't need to worry about uninitialized values on\n+the stack for correctness. Although they might care for performance. Thankfully,\n+Rust makes it easy to take control here! Uninitialized values are there, and\n+you can work with them in Safe Rust, but you're *never* in danger.\n\\ No newline at end of file"}, {"sha": "12e000b5ef6e4b099653cd157123a80afdbb7935", "filename": "src/doc/tarpl/exception-safety.md", "status": "added", "additions": 217, "deletions": 0, "changes": 217, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fexception-safety.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fexception-safety.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fexception-safety.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,217 @@\n+% Exception Safety\n+\n+Although programs should use unwinding sparingly, there's *a lot* of code that\n+*can* panic. If you unwrap a None, index out of bounds, or divide by 0, your\n+program *will* panic. On debug builds, *every* arithmetic operation can panic\n+if it overflows. Unless you are very careful and tightly control what code runs,\n+pretty much everything can unwind, and you need to be ready for it.\n+\n+Being ready for unwinding is often referred to as *exception safety*\n+in the broader programming world. In Rust, their are two levels of exception\n+safety that one may concern themselves with:\n+\n+* In unsafe code, we *must* be exception safe to the point of not violating\n+  memory safety. We'll call this *minimal* exception safety.\n+\n+* In safe code, it is *good* to be exception safe to the point of your program\n+  doing the right thing. We'll call this *maximal* exception safety.\n+\n+As is the case in many places in Rust, Unsafe code must be ready to deal with\n+bad Safe code when it comes to unwinding. Code that transiently creates\n+unsound states must be careful that a panic does not cause that state to be\n+used. Generally this means ensuring that only non-panicking code is run while\n+these states exist, or making a guard that cleans up the state in the case of\n+a panic. This does not necessarily mean that the state a panic witnesses is a\n+fully *coherent* state. We need only guarantee that it's a *safe* state.\n+\n+Most Unsafe code is leaf-like, and therefore fairly easy to make exception-safe.\n+It controls all the code that runs, and most of that code can't panic. However\n+it is not uncommon for Unsafe code to work with arrays of temporarily\n+uninitialized data while repeatedly invoking caller-provided code. Such code\n+needs to be careful and consider exception safety.\n+\n+\n+\n+\n+\n+## Vec::push_all\n+\n+`Vec::push_all` is a temporary hack to get extending a Vec by a slice reliably\n+effecient without specialization. Here's a simple implementation:\n+\n+```rust,ignore\n+impl<T: Clone> Vec<T> {\n+    fn push_all(&mut self, to_push: &[T]) {\n+        self.reserve(to_push.len());\n+        unsafe {\n+            // can't overflow because we just reserved this\n+            self.set_len(self.len() + to_push.len());\n+\n+            for (i, x) in to_push.iter().enumerate() {\n+                self.ptr().offset(i as isize).write(x.clone());\n+            }\n+        }\n+    }\n+}\n+```\n+\n+We bypass `push` in order to avoid redundant capacity and `len` checks on the\n+Vec that we definitely know has capacity. The logic is totally correct, except\n+there's a subtle problem with our code: it's not exception-safe! `set_len`,\n+`offset`, and `write` are all fine, but *clone* is the panic bomb we over-looked.\n+\n+Clone is completely out of our control, and is totally free to panic. If it does,\n+our function will exit early with the length of the Vec set too large. If\n+the Vec is looked at or dropped, uninitialized memory will be read!\n+\n+The fix in this case is fairly simple. If we want to guarantee that the values\n+we *did* clone are dropped we can set the len *in* the loop. If we just want to\n+guarantee that uninitialized memory can't be observed, we can set the len *after*\n+the loop.\n+\n+\n+\n+\n+\n+## BinaryHeap::sift_up\n+\n+Bubbling an element up a heap is a bit more complicated than extending a Vec.\n+The pseudocode is as follows:\n+\n+```text\n+bubble_up(heap, index):\n+    while index != 0 && heap[index] < heap[parent(index)]:\n+        heap.swap(index, parent(index))\n+        index = parent(index)\n+\n+```\n+\n+A literal transcription of this code to Rust is totally fine, but has an annoying\n+performance characteristic: the `self` element is swapped over and over again\n+uselessly. We would *rather* have the following:\n+\n+```text\n+bubble_up(heap, index):\n+    let elem = heap[index]\n+    while index != 0 && element < heap[parent(index)]:\n+        heap[index] = heap[parent(index)]\n+        index = parent(index)\n+    heap[index] = elem\n+```\n+\n+This code ensures that each element is copied as little as possible (it is in\n+fact necessary that elem be copied twice in general). However it now exposes\n+some exception safety trouble! At all times, there exists two copies of one\n+value. If we panic in this function something will be double-dropped.\n+Unfortunately, we also don't have full control of the code: that comparison is\n+user-defined!\n+\n+Unlike Vec, the fix isn't as easy here. One option is to break the user-defined\n+code and the unsafe code into two separate phases:\n+\n+```text\n+bubble_up(heap, index):\n+    let end_index = index;\n+    while end_index != 0 && heap[end_index] < heap[parent(end_index)]:\n+        end_index = parent(end_index)\n+\n+    let elem = heap[index]\n+    while index != end_index:\n+        heap[index] = heap[parent(index)]\n+        index = parent(index)\n+    heap[index] = elem\n+```\n+\n+If the user-defined code blows up, that's no problem anymore, because we haven't\n+actually touched the state of the heap yet. Once we do start messing with the\n+heap, we're working with only data and functions that we trust, so there's no\n+concern of panics.\n+\n+Perhaps you're not happy with this design. Surely, it's cheating! And we have\n+to do the complex heap traversal *twice*! Alright, let's bite the bullet. Let's\n+intermix untrusted and unsafe code *for reals*.\n+\n+If Rust had `try` and `finally` like in Java, we could do the following:\n+\n+```text\n+bubble_up(heap, index):\n+    let elem = heap[index]\n+    try:\n+        while index != 0 && element < heap[parent(index)]:\n+            heap[index] = heap[parent(index)]\n+            index = parent(index)\n+    finally:\n+        heap[index] = elem\n+```\n+\n+The basic idea is simple: if the comparison panics, we just toss the loose\n+element in the logically uninitialized index and bail out. Anyone who observes\n+the heap will see a potentially *inconsistent* heap, but at least it won't\n+cause any double-drops! If the algorithm terminates normally, then this\n+operation happens to coincide precisely with the how we finish up regardless.\n+\n+Sadly, Rust has no such construct, so we're going to need to roll our own! The\n+way to do this is to store the algorithm's state in a separate struct with a\n+destructor for the \"finally\" logic. Whether we panic or not, that destructor\n+will run and clean up after us.\n+\n+```rust\n+struct Hole<'a, T: 'a> {\n+    data: &'a mut [T],\n+    /// `elt` is always `Some` from new until drop.\n+    elt: Option<T>,\n+    pos: usize,\n+}\n+\n+impl<'a, T> Hole<'a, T> {\n+    fn new(data: &'a mut [T], pos: usize) -> Self {\n+        unsafe {\n+            let elt = ptr::read(&data[pos]);\n+            Hole {\n+                data: data,\n+                elt: Some(elt),\n+                pos: pos,\n+            }\n+        }\n+    }\n+\n+    fn pos(&self) -> usize { self.pos }\n+\n+    fn removed(&self) -> &T { self.elt.as_ref().unwrap() }\n+\n+    unsafe fn get(&self, index: usize) -> &T { &self.data[index] }\n+\n+    unsafe fn move_to(&mut self, index: usize) {\n+        let index_ptr: *const _ = &self.data[index];\n+        let hole_ptr = &mut self.data[self.pos];\n+        ptr::copy_nonoverlapping(index_ptr, hole_ptr, 1);\n+        self.pos = index;\n+    }\n+}\n+\n+impl<'a, T> Drop for Hole<'a, T> {\n+    fn drop(&mut self) {\n+        // fill the hole again\n+        unsafe {\n+            let pos = self.pos;\n+            ptr::write(&mut self.data[pos], self.elt.take().unwrap());\n+        }\n+    }\n+}\n+\n+impl<T: Ord> BinaryHeap<T> {\n+    fn sift_up(&mut self, pos: usize) {\n+        unsafe {\n+            // Take out the value at `pos` and create a hole.\n+            let mut hole = Hole::new(&mut self.data, pos);\n+\n+            while hole.pos() != 0 {\n+                let parent = parent(hole.pos());\n+                if hole.removed() <= hole.get(parent) { break }\n+                hole.move_to(parent);\n+            }\n+            // Hole will be unconditionally filled here; panic or not!\n+        }\n+    }\n+}\n+```"}, {"sha": "ea8dc86d1f0acace49a456a9cf8219aaba5a71ba", "filename": "src/doc/tarpl/exotic-sizes.md", "status": "added", "additions": 87, "deletions": 0, "changes": 87, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fexotic-sizes.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fexotic-sizes.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fexotic-sizes.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,87 @@\n+% Exotically Sized Types\n+\n+Most of the time, we think in terms of types with a fixed, positive size. This\n+is not always the case, however.\n+\n+\n+\n+\n+\n+# Dynamically Sized Types (DSTs)\n+\n+Rust also supports types without a statically known size. On the surface,\n+this is a bit nonsensical: Rust *must* know the size of something in order to\n+work with it! DSTs are generally produced as views, or through type-erasure\n+of types that *do* have a known size. Due to their lack of a statically known\n+size, these types can only exist *behind* some kind of pointer. They consequently\n+produce a *fat* pointer consisting of the pointer and the information that\n+*completes* them.\n+\n+For instance, the slice type, `[T]`, is some statically unknown number of elements\n+stored contiguously. `&[T]` consequently consists of a `(&T, usize)` pair that specifies\n+where the slice starts, and how many elements it contains. Similarly, Trait Objects\n+support interface-oriented type erasure through a `(data_ptr, vtable_ptr)` pair.\n+\n+Structs can actually store a single DST directly as their last field, but this\n+makes them a DST as well:\n+\n+```rust\n+// Can't be stored on the stack directly\n+struct Foo {\n+    info: u32,\n+    data: [u8],\n+}\n+```\n+\n+**NOTE: As of Rust 1.0 struct DSTs are broken if the last field has\n+a variable position based on its alignment.**\n+\n+\n+\n+\n+\n+# Zero Sized Types (ZSTs)\n+\n+Rust actually allows types to be specified that occupy *no* space:\n+\n+```rust\n+struct Foo; // No fields = no size\n+\n+// All fields have no size = no size\n+struct Baz {\n+    foo: Foo,\n+    qux: (), \t  // empty tuple has no size\n+    baz: [u8; 0], // empty array has no size\n+}\n+```\n+\n+On their own, ZSTs are, for obvious reasons, pretty useless. However\n+as with many curious layout choices in Rust, their potential is realized in a generic\n+context.\n+\n+Rust largely understands that any operation that produces or stores a ZST\n+can be reduced to a no-op. For instance, a `HashSet<T>` can be effeciently implemented\n+as a thin wrapper around `HashMap<T, ()>` because all the operations `HashMap` normally\n+does to store and retrieve keys will be completely stripped in monomorphization.\n+\n+Similarly `Result<(), ()>` and `Option<()>` are effectively just fancy `bool`s.\n+\n+Safe code need not worry about ZSTs, but *unsafe* code must be careful about the\n+consequence of types with no size. In particular, pointer offsets are no-ops, and\n+standard allocators (including jemalloc, the one used by Rust) generally consider\n+passing in `0` as Undefined Behaviour.\n+\n+\n+\n+\n+\n+# Void Types\n+\n+Rust also enables types to be declared that *cannot even be instantiated*. These\n+types can only be talked about at the type level, and never at the value level.\n+\n+```rust\n+enum Foo { } // No variants = VOID\n+```\n+\n+TODO: WHY?!\n\\ No newline at end of file"}, {"sha": "c3f25026ef48c93014cc6d9529f207f942614766", "filename": "src/doc/tarpl/hrtb.md", "status": "added", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fhrtb.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fhrtb.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fhrtb.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,72 @@\n+% Higher-Rank Trait Bounds (HRTBs)\n+\n+Rust's Fn traits are a little bit magic. For instance, we can write the\n+following code:\n+\n+```rust\n+struct Closure<F> {\n+    data: (u8, u16),\n+    func: F,\n+}\n+\n+impl<F> Closure<F>\n+    where F: Fn(&(u8, u16)) -> &u8,\n+{\n+    fn call(&self) -> &u8 {\n+        (self.func)(&self.data)\n+    }\n+}\n+\n+fn do_it(data: &(u8, u16)) -> &u8 { &data.0 }\n+\n+fn main() {\n+    let clo = Closure { data: (0, 1), func: do_it };\n+    println!(\"{}\", clo.call());\n+}\n+```\n+\n+If we try to naively desugar this code in the same way that we did in the\n+lifetimes section, we run into some trouble:\n+\n+```rust\n+struct Closure<F> {\n+    data: (u8, u16),\n+    func: F,\n+}\n+\n+impl<F> Closure<F>\n+    // where F: Fn(&'??? (u8, u16)) -> &'??? u8,\n+{\n+    fn call<'a>(&'a self) -> &'a u8 {\n+        (self.func)(&self.data)\n+    }\n+}\n+\n+fn do_it<'b>(data: &'b (u8, u16)) -> &'b u8 { &'b data.0 }\n+\n+fn main() {\n+    'x: {\n+        let clo = Closure { data: (0, 1), func: do_it };\n+        println!(\"{}\", clo.call());\n+    }\n+}\n+```\n+\n+How on earth are we supposed to express the lifetimes on F's trait bound? We need\n+to provide some lifetime there, but the lifetime we care about can't be named until\n+we enter the body of `call`! Also, that isn't some fixed lifetime; call works with\n+*any* lifetime `&self` happens to have at that point.\n+\n+This job requires The Magic of Higher-Rank Trait Bounds. The way we desugar\n+this is as follows:\n+\n+```rust\n+where for<'a> F: Fn(&'a (u8, u16)) -> &'a u8,\n+```\n+\n+(Where `Fn(a, b, c) -> d` is itself just sugar for the unstable *real* Fn trait)\n+\n+`for<'a>` can be read as \"for all choices of `'a`\", and basically produces an\n+*inifinite list* of trait bounds that F must satisfy. Intense. There aren't many\n+places outside of the Fn traits where we encounter HRTBs, and even for those we\n+have a nice magic sugar for the common cases.\n\\ No newline at end of file"}, {"sha": "5d66b1a424c457736a6f82040fde9de2e2ad4bf9", "filename": "src/doc/tarpl/leaking.md", "status": "added", "additions": 229, "deletions": 0, "changes": 229, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fleaking.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fleaking.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fleaking.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,229 @@\n+% Leaking\n+\n+Ownership based resource management is intended to simplify composition. You\n+acquire resources when you create the object, and you release the resources\n+when it gets destroyed. Since destruction is handled for you, it means you\n+can't forget to release the resources, and it happens as soon as possible!\n+Surely this is perfect and all of our problems are solved.\n+\n+Everything is terrible and we have new and exotic problems to try to solve.\n+\n+Many people like to believe that Rust eliminates resource leaks, but this\n+is absolutely not the case, no matter how you look at it. In the strictest\n+sense, \"leaking\" is so abstract as to be unpreventable. It's quite trivial\n+to initialize a collection at the start of a program, fill it with tons of\n+objects with destructors, and then enter an infinite event loop that never\n+refers to it. The collection will sit around uselessly, holding on to its\n+precious resources until the program terminates (at which point all those\n+resources would have been reclaimed by the OS anyway).\n+\n+We may consider a more restricted form of leak: failing to drop a value that\n+is unreachable. Rust also doesn't prevent this. In fact Rust has a *function\n+for doing this*: `mem::forget`. This function consumes the value it is passed\n+*and then doesn't run its destructor*.\n+\n+In the past `mem::forget` was marked as unsafe as a sort of lint against using\n+it, since failing to call a destructor is generally not a well-behaved thing to\n+do (though useful for some special unsafe code). However this was generally\n+determined to be an untenable stance to take: there are *many* ways to fail to\n+call a destructor in safe code. The most famous example is creating a cycle\n+of reference counted pointers using interior mutability.\n+\n+It is reasonable for safe code to assume that destructor leaks do not happen,\n+as any program that leaks destructors is probably wrong. However *unsafe* code\n+cannot rely on destructors to be run to be *safe*. For most types this doesn't\n+matter: if you leak the destructor then the type is *by definition* inaccessible,\n+so it doesn't matter, right? For instance, if you leak a `Box<u8>` then you\n+waste some memory but that's hardly going to violate memory-safety.\n+\n+However where we must be careful with destructor leaks are *proxy* types.\n+These are types which manage access to a distinct object, but don't actually\n+own it. Proxy objects are quite rare. Proxy objects you'll need to care about\n+are even rarer. However we'll focus on three interesting examples in the\n+standard library:\n+\n+* `vec::Drain`\n+* `Rc`\n+* `thread::scoped::JoinGuard`\n+\n+\n+\n+## Drain\n+\n+`drain` is a collections API that moves data out of the container without\n+consuming the container. This enables us to reuse the allocation of a `Vec`\n+after claiming ownership over all of its contents. It produces an iterator\n+(Drain) that returns the contents of the Vec by-value.\n+\n+Now, consider Drain in the middle of iteration: some values have been moved out,\n+and others haven't. This means that part of the Vec is now full of logically\n+uninitialized data! We could backshift all the elements in the Vec every time we\n+remove a value, but this would have pretty catastrophic performance consequences.\n+\n+Instead, we would like Drain to *fix* the Vec's backing storage when it is\n+dropped. It should run itself to completion, backshift any elements that weren't\n+removed (drain supports subranges), and then fix Vec's `len`. It's even\n+unwinding-safe! Easy!\n+\n+Now consider the following:\n+\n+```\n+let mut vec = vec![Box::new(0); 4];\n+\n+{\n+\t// start draining, vec can no longer be accessed\n+\tlet mut drainer = vec.drain(..);\n+\n+\t// pull out two elements and immediately drop them\n+\tdrainer.next();\n+\tdrainer.next();\n+\n+\t// get rid of drainer, but don't call its destructor\n+\tmem::forget(drainer);\n+}\n+\n+// Oops, vec[0] was dropped, we're reading a pointer into free'd memory!\n+println!(\"{}\", vec[0]);\n+```\n+\n+This is pretty clearly Not Good. Unfortunately, we're kind've stuck between\n+a rock and a hard place: maintaining consistent state at every step has\n+an enormous cost (and would negate any benefits of the API). Failing to maintain\n+consistent state gives us Undefined Behaviour in safe code (making the API\n+unsound).\n+\n+So what can we do? Well, we can pick a trivially consistent state: set the Vec's\n+len to be 0 when we *start* the iteration, and fix it up if necessary in the\n+destructor. That way, if everything executes like normal we get the desired\n+behaviour with minimal overhead. But if someone has the *audacity* to mem::forget\n+us in the middle of the iteration, all that does is *leak even more* (and possibly\n+leave the Vec in an *unexpected* but consistent state). Since we've\n+accepted that mem::forget is safe, this is definitely safe. We call leaks causing\n+more leaks a *leak amplification*.\n+\n+\n+\n+\n+## Rc\n+\n+Rc is an interesting case because at first glance it doesn't appear to be a\n+proxy value at all. After all, it manages the data it points to, and dropping\n+all the Rcs for a value will drop that value. leaking an Rc doesn't seem like\n+it would be particularly dangerous. It will leave the refcount permanently\n+incremented and prevent the data from being freed or dropped, but that seems\n+just like Box, right?\n+\n+Nope.\n+\n+Let's consider a simplified implementation of Rc:\n+\n+```rust\n+struct Rc<T> {\n+\tptr: *mut RcBox<T>,\n+}\n+\n+struct RcBox<T> {\n+\tdata: T,\n+\tref_count: usize,\n+}\n+\n+impl<T> Rc<T> {\n+\tfn new(data: T) -> Self {\n+\t\tunsafe {\n+\t\t\t// Wouldn't it be nice if heap::allocate worked like this?\n+\t\t\tlet ptr = heap::allocate<RcBox<T>>();\n+\t\t\tptr::write(ptr, RcBox {\n+\t\t\t\tdata: data,\n+\t\t\t\tref_count: 1,\n+\t\t\t});\n+\t\t\tRc { ptr: ptr }\n+\t\t}\n+\t}\n+\n+\tfn clone(&self) -> Self {\n+\t\tunsafe {\n+\t\t\t(*self.ptr).ref_count += 1;\n+\t\t}\n+\t\tRc { ptr: self.ptr }\n+\t}\n+}\n+\n+impl<T> Drop for Rc<T> {\n+\tfn drop(&mut self) {\n+\t\tunsafe {\n+\t\t\tlet inner = &mut ;\n+\t\t\t(*self.ptr).ref_count -= 1;\n+\t\t\tif (*self.ptr).ref_count == 0 {\n+\t\t\t\t// drop the data and then free it\n+\t\t\t\tptr::read(self.ptr);\n+\t\t\t\theap::deallocate(self.ptr);\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+```\n+\n+This code contains an implicit and subtle assumption: ref_count can fit in a\n+`usize`, because there can't be more than `usize::MAX` Rcs in memory. However\n+this itself assumes that the ref_count accurately reflects the number of Rcs\n+in memory, which we know is false with mem::forget. Using mem::forget we can\n+overflow the ref_count, and then get it down to 0 with outstanding Rcs. Then we\n+can happily use-after-free the inner data. Bad Bad Not Good.\n+\n+This can be solved by *saturating* the ref_count, which is sound because\n+decreasing the refcount by `n` still requires `n` Rcs simultaneously living\n+in memory.\n+\n+\n+\n+\n+## thread::scoped::JoinGuard\n+\n+The thread::scoped API intends to allow threads to be spawned that reference\n+data on the stack without any synchronization over that data. Usage looked like:\n+\n+```rust\n+let mut data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n+{\n+\tlet guards = vec![];\n+\tfor x in &mut data {\n+\t\t// Move the mutable reference into the closure, and execute\n+\t\t// it on a different thread. The closure has a lifetime bound\n+\t\t// by the lifetime of the mutable reference `x` we store in it.\n+\t\t// The guard that is returned is in turn assigned the lifetime\n+\t\t// of the closure, so it also mutably borrows `data` as `x` did.\n+\t\t// This means we cannot access `data` until the guard goes away.\n+\t\tlet guard = thread::scoped(move || {\n+\t\t\t*x *= 2;\n+\t\t});\n+\t\t// store the thread's guard for later\n+\t\tguards.push(guard);\n+\t}\n+\t// All guards are dropped here, forcing the threads to join\n+\t// (this thread blocks here until the others terminate).\n+\t// Once the threads join, the borrow expires and the data becomes\n+\t// accessible again in this thread.\n+}\n+// data is definitely mutated here.\n+```\n+\n+In principle, this totally works! Rust's ownership system perfectly ensures it!\n+...except it relies on a destructor being called to be safe.\n+\n+```\n+let mut data = Box::new(0);\n+{\n+\tlet guard = thread::scoped(|| {\n+\t\t// This is at best a data race. At worst, it's *also* a use-after-free.\n+\t\t*data += 1;\n+\t});\n+\t// Because the guard is forgotten, expiring the loan without blocking this\n+\t// thread.\n+\tmem::forget(guard);\n+}\n+// So the Box is dropped here while the scoped thread may or may not be trying\n+// to access it.\n+```\n+\n+Dang. Here the destructor running was pretty fundamental to the API, and it had\n+to be scrapped in favour of a completely different design.\n\\ No newline at end of file"}, {"sha": "eac24330911f4713d23accaa4c6368af3fab9ad5", "filename": "src/doc/tarpl/lifetime-elision.md", "status": "added", "additions": 64, "deletions": 0, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-elision.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-elision.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Flifetime-elision.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,64 @@\n+% Lifetime Elision\n+\n+In order to make common patterns more ergonomic, Rust allows lifetimes to be\n+*elided* in function signatures.\n+\n+A *lifetime position* is anywhere you can write a lifetime in a type:\n+\n+```rust\n+&'a T\n+&'a mut T\n+T<'a>\n+```\n+\n+Lifetime positions can appear as either \"input\" or \"output\":\n+\n+* For `fn` definitions, input refers to the types of the formal arguments\n+  in the `fn` definition, while output refers to\n+  result types. So `fn foo(s: &str) -> (&str, &str)` has elided one lifetime in\n+  input position and two lifetimes in output position.\n+  Note that the input positions of a `fn` method definition do not\n+  include the lifetimes that occur in the method's `impl` header\n+  (nor lifetimes that occur in the trait header, for a default method).\n+\n+* In the future, it should be possible to elide `impl` headers in the same manner.\n+\n+Elision rules are as follows:\n+\n+* Each elided lifetime in input position becomes a distinct lifetime\n+  parameter.\n+\n+* If there is exactly one input lifetime position (elided or not), that lifetime\n+  is assigned to *all* elided output lifetimes.\n+\n+* If there are multiple input lifetime positions, but one of them is `&self` or\n+  `&mut self`, the lifetime of `self` is assigned to *all* elided output lifetimes.\n+\n+* Otherwise, it is an error to elide an output lifetime.\n+\n+Examples:\n+\n+```rust\n+fn print(s: &str);                                      // elided\n+fn print<'a>(s: &'a str);                               // expanded\n+\n+fn debug(lvl: uint, s: &str);                           // elided\n+fn debug<'a>(lvl: uint, s: &'a str);                    // expanded\n+\n+fn substr(s: &str, until: uint) -> &str;                // elided\n+fn substr<'a>(s: &'a str, until: uint) -> &'a str;      // expanded\n+\n+fn get_str() -> &str;                                   // ILLEGAL\n+\n+fn frob(s: &str, t: &str) -> &str;                      // ILLEGAL\n+\n+fn get_mut(&mut self) -> &mut T;                        // elided\n+fn get_mut<'a>(&'a mut self) -> &'a mut T;              // expanded\n+\n+fn args<T:ToCStr>(&mut self, args: &[T]) -> &mut Command                  // elided\n+fn args<'a, 'b, T:ToCStr>(&'a mut self, args: &'b [T]) -> &'a mut Command // expanded\n+\n+fn new(buf: &mut [u8]) -> BufWriter;                    // elided\n+fn new<'a>(buf: &'a mut [u8]) -> BufWriter<'a>          // expanded\n+\n+```\n\\ No newline at end of file"}, {"sha": "faf7f9a1f60b023fd85ace297e6eeb901367ab36", "filename": "src/doc/tarpl/lifetime-misc.md", "status": "added", "additions": 229, "deletions": 0, "changes": 229, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-misc.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-misc.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Flifetime-misc.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,229 @@\n+% misc\n+\n+This is just a dumping ground while I work out what to do with this stuff\n+\n+\n+# PhantomData\n+\n+When working with unsafe code, we can often end up in a situation where\n+types or lifetimes are logically associated with a struct, but not actually\n+part of a field. This most commonly occurs with lifetimes. For instance, the `Iter`\n+for `&'a [T]` is (approximately) defined as follows:\n+\n+```rust\n+pub struct Iter<'a, T: 'a> {\n+    ptr: *const T,\n+    end: *const T,\n+}\n+```\n+\n+However because `'a` is unused within the struct's body, it's *unbound*.\n+Because of the troubles this has historically caused, unbound lifetimes and\n+types are *illegal* in struct definitions. Therefore we must somehow refer\n+to these types in the body. Correctly doing this is necessary to have\n+correct variance and drop checking.\n+\n+We do this using *PhantomData*, which is a special marker type. PhantomData\n+consumes no space, but simulates a field of the given type for the purpose of\n+static analysis. This was deemed to be less error-prone than explicitly telling\n+the type-system the kind of variance that you want, while also providing other\n+useful information.\n+\n+Iter logically contains `&'a T`, so this is exactly what we tell\n+the PhantomData to simulate:\n+\n+```\n+pub struct Iter<'a, T: 'a> {\n+    ptr: *const T,\n+    end: *const T,\n+    _marker: marker::PhantomData<&'a T>,\n+}\n+```\n+\n+\n+\n+\n+# Dropck\n+\n+When a type is going out of scope, Rust will try to Drop it. Drop executes\n+arbitrary code, and in fact allows us to \"smuggle\" arbitrary code execution\n+into many places. As such additional soundness checks (dropck) are necessary to\n+ensure that a type T can be safely instantiated and dropped. It turns out that we\n+*really* don't need to care about dropck in practice, as it often \"just works\".\n+\n+However the one exception is with PhantomData. Given a struct like Vec:\n+\n+```\n+struct Vec<T> {\n+    data: *const T, // *const for variance!\n+    len: usize,\n+    cap: usize,\n+}\n+```\n+\n+dropck will generously determine that Vec<T> does not own any values of\n+type T. This will unfortunately allow people to construct unsound Drop\n+implementations that access data that has already been dropped. In order to\n+tell dropck that we *do* own values of type T, and may call destructors of that\n+type, we must add extra PhantomData:\n+\n+```\n+struct Vec<T> {\n+    data: *const T, // *const for covariance!\n+    len: usize,\n+    cap: usize,\n+    _marker: marker::PhantomData<T>,\n+}\n+```\n+\n+Raw pointers that own an allocation is such a pervasive pattern that the\n+standard library made a utility for itself called `Unique<T>` which:\n+\n+* wraps a `*const T`,\n+* includes a `PhantomData<T>`,\n+* auto-derives Send/Sync as if T was contained\n+* marks the pointer as NonZero for the null-pointer optimization\n+\n+\n+\n+\n+# Splitting Lifetimes\n+\n+The mutual exclusion property of mutable references can be very limiting when\n+working with a composite structure. The borrow checker understands some basic stuff, but\n+will fall over pretty easily. It *does* understand structs sufficiently to\n+know that it's possible to borrow disjoint fields of a struct simultaneously.\n+So this works today:\n+\n+```rust\n+struct Foo {\n+    a: i32,\n+    b: i32,\n+    c: i32,\n+}\n+\n+let mut x = Foo {a: 0, b: 0, c: 0};\n+let a = &mut x.a;\n+let b = &mut x.b;\n+let c = &x.c;\n+*b += 1;\n+let c2 = &x.c;\n+*a += 10;\n+println!(\"{} {} {} {}\", a, b, c, c2);\n+```\n+\n+However borrowck doesn't understand arrays or slices in any way, so this doesn't\n+work:\n+\n+```rust\n+let x = [1, 2, 3];\n+let a = &mut x[0];\n+let b = &mut x[1];\n+println!(\"{} {}\", a, b);\n+```\n+\n+```text\n+<anon>:3:18: 3:22 error: cannot borrow immutable indexed content `x[..]` as mutable\n+<anon>:3     let a = &mut x[0];\n+                          ^~~~\n+<anon>:4:18: 4:22 error: cannot borrow immutable indexed content `x[..]` as mutable\n+<anon>:4     let b = &mut x[1];\n+                          ^~~~\n+error: aborting due to 2 previous errors\n+```\n+\n+While it was plausible that borrowck could understand this simple case, it's\n+pretty clearly hopeless for borrowck to understand disjointness in general\n+container types like a tree, especially if distinct keys actually *do* map\n+to the same value.\n+\n+In order to \"teach\" borrowck that what we're doing is ok, we need to drop down\n+to unsafe code. For instance, mutable slices expose a `split_at_mut` function that\n+consumes the slice and returns *two* mutable slices. One for everything to the\n+left of the index, and one for everything to the right. Intuitively we know this\n+is safe because the slices don't alias. However the implementation requires some\n+unsafety:\n+\n+```rust\n+fn split_at_mut(&mut self, mid: usize) -> (&mut [T], &mut [T]) {\n+    unsafe {\n+        let self2: &mut [T] = mem::transmute_copy(&self);\n+\n+        (ops::IndexMut::index_mut(self, ops::RangeTo { end: mid } ),\n+         ops::IndexMut::index_mut(self2, ops::RangeFrom { start: mid } ))\n+    }\n+}\n+```\n+\n+This is pretty plainly dangerous. We use transmute to duplicate the slice with an\n+*unbounded* lifetime, so that it can be treated as disjoint from the other until\n+we unify them when we return.\n+\n+However more subtle is how iterators that yield mutable references work.\n+The iterator trait is defined as follows:\n+\n+```rust\n+trait Iterator {\n+    type Item;\n+\n+    fn next(&mut self) -> Option<Self::Item>;\n+}\n+```\n+\n+Given this definition, Self::Item has *no* connection to `self`. This means\n+that we can call `next` several times in a row, and hold onto all the results\n+*concurrently*. This is perfectly fine for by-value iterators, which have exactly\n+these semantics. It's also actually fine for shared references, as they admit\n+arbitrarily many references to the same thing (although the\n+iterator needs to be a separate object from the thing being shared). But mutable\n+references make this a mess. At first glance, they might seem completely\n+incompatible with this API, as it would produce multiple mutable references to\n+the same object!\n+\n+However it actually *does* work, exactly because iterators are one-shot objects.\n+Everything an IterMut yields will be yielded *at most* once, so we don't *actually*\n+ever yield multiple mutable references to the same piece of data.\n+\n+In general all mutable iterators require *some* unsafe code *somewhere*, though.\n+Whether it's raw pointers, or safely composing on top of *another* IterMut.\n+\n+For instance, VecDeque's IterMut:\n+\n+```rust\n+pub struct IterMut<'a, T:'a> {\n+    // The whole backing array. Some of these indices are initialized!\n+    ring: &'a mut [T],\n+    tail: usize,\n+    head: usize,\n+}\n+\n+impl<'a, T> Iterator for IterMut<'a, T> {\n+    type Item = &'a mut T;\n+\n+    fn next(&mut self) -> Option<&'a mut T> {\n+        if self.tail == self.head {\n+            return None;\n+        }\n+        let tail = self.tail;\n+        self.tail = wrap_index(self.tail.wrapping_add(1), self.ring.len());\n+\n+        unsafe {\n+            // might as well do unchecked indexing since wrap_index has us\n+            // in-bounds, and many of the \"middle\" indices are uninitialized\n+            // anyway.\n+            let elem = self.ring.get_unchecked_mut(tail);\n+\n+            // round-trip through a raw pointer to unbound the lifetime from\n+            // ourselves\n+            Some(&mut *(elem as *mut _))\n+        }\n+    }\n+}\n+```\n+\n+A very subtle but interesting detail in this design is that it *relies on\n+privacy to be sound*. Borrowck works on some very simple rules. One of those rules\n+is that if we have a live &mut Foo and Foo contains an &mut Bar, then that &mut\n+Bar is *also* live. Since IterMut is always live when `next` can be called, if\n+`ring` were public then we could mutate `ring` while outstanding mutable borrows\n+to it exist!"}, {"sha": "93ecb51c010db266b2c444ac93acb8ff13886399", "filename": "src/doc/tarpl/lifetime-mismatch.md", "status": "added", "additions": 81, "deletions": 0, "changes": 81, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-mismatch.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetime-mismatch.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Flifetime-mismatch.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,81 @@\n+% Limits of Lifetimes\n+\n+Given the following code:\n+\n+```rust,ignore\n+struct Foo;\n+\n+impl Foo {\n+    fn mutate_and_share(&mut self) -> &Self { &*self }\n+    fn share(&self) {}\n+}\n+\n+fn main() {\n+    let mut foo = Foo;\n+    let loan = foo.mutate_and_share();\n+    foo.share();\n+}\n+```\n+\n+One might expect it to compile. We call `mutate_and_share`, which mutably borrows\n+`foo` *temporarily*, but then returns *only* a shared reference. Therefore we\n+would expect `foo.share()` to succeed as `foo` shouldn't be mutably borrowed.\n+\n+However when we try to compile it:\n+\n+```text\n+<anon>:11:5: 11:8 error: cannot borrow `foo` as immutable because it is also borrowed as mutable\n+<anon>:11     foo.share();\n+              ^~~\n+<anon>:10:16: 10:19 note: previous borrow of `foo` occurs here; the mutable borrow prevents subsequent moves, borrows, or modification of `foo` until the borrow ends\n+<anon>:10     let loan = foo.mutate_and_share();\n+                         ^~~\n+<anon>:12:2: 12:2 note: previous borrow ends here\n+<anon>:8 fn main() {\n+<anon>:9     let mut foo = Foo;\n+<anon>:10     let loan = foo.mutate_and_share();\n+<anon>:11     foo.share();\n+<anon>:12 }\n+          ^\n+```\n+\n+What happened? Well, we got the exact same reasoning as we did for\n+[Example 2 in the previous section][ex2]. We desugar the program and we get\n+the following:\n+\n+```rust,ignore\n+struct Foo;\n+\n+impl Foo {\n+    fn mutate_and_share<'a>(&'a mut self) -> &'a Self { &'a *self }\n+    fn share<'a>(&'a self) {}\n+}\n+\n+fn main() {\n+\t'b: {\n+    \tlet mut foo: Foo = Foo;\n+    \t'c: {\n+    \t\tlet loan: &'c Foo = Foo::mutate_and_share::<'c>(&'c mut foo);\n+    \t\t'd: {\n+    \t\t\tFoo::share::<'d>(&'d foo);\n+    \t\t}\n+    \t}\n+    }\n+}\n+```\n+\n+The lifetime system is forced to extend the `&mut foo` to have lifetime `'c`,\n+due to the lifetime of `loan` and mutate_and_share's signature. Then when we\n+try to call `share`, and it sees we're trying to alias that `&'c mut foo` and\n+blows up in our face!\n+\n+This program is clearly correct according to the reference semantics we *actually*\n+care about, but the lifetime system is too coarse-grained to handle that.\n+\n+\n+TODO: other common problems? SEME regions stuff, mostly?\n+\n+\n+\n+\n+[ex2]: lifetimes.html#example-2:-aliasing-a-mutable-reference\n\\ No newline at end of file"}, {"sha": "a06363a92d73981a05897193ccea6c08e97a7125", "filename": "src/doc/tarpl/lifetimes.md", "status": "added", "additions": 222, "deletions": 0, "changes": 222, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetimes.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Flifetimes.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Flifetimes.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,222 @@\n+% Lifetimes\n+\n+Rust enforces these rules through *lifetimes*. Lifetimes are effectively\n+just names for scopes somewhere in the program. Each reference,\n+and anything that contains a reference, is tagged with a lifetime specifying\n+the scope it's valid for.\n+\n+Within a function body, Rust generally doesn't let you explicitly name the\n+lifetimes involved. This is because it's generally not really *necessary*\n+to talk about lifetimes in a local context; rust has all the information and\n+can work out everything. It's also a good thing because the scope of a borrow\n+is often significantly smaller than the scope its referent is *actually* valid\n+for. Rust will introduce *many* anonymous scopes and temporaries to make your\n+code *just work*.\n+\n+However once you cross the function boundary, you need to start talking about\n+lifetimes. Lifetimes are denoted with an apostrophe: `'a`, `'static`. To dip\n+our toes with lifetimes, we're going to pretend that we're actually allowed\n+to label scopes with lifetimes, and desugar the examples from the start of\n+this chapter.\n+\n+Our examples made use of *aggressive* sugar -- high fructose corn syrup even --\n+around scopes and lifetimes, because writing everything out explicitly is\n+*extremely noisy*. All Rust code relies on aggressive inference and elision of\n+\"obvious\" things.\n+\n+One particularly interesting piece of sugar is that each `let` statement implicitly\n+introduces a scope. For the most part, this doesn't really matter. However it\n+does matter for variables that refer to each other. As a simple example, let's\n+completely desugar this simple piece of Rust code:\n+\n+```rust\n+let x = 0;\n+let y = &x;\n+let z = &y;\n+```\n+\n+The borrow checker always tries to minimize the extent of a lifetime, so it will\n+likely desugar to the following:\n+\n+```rust\n+// NOTE: `'a: {` and `&'b x` is not valid syntax!\n+'a: {\n+    let x: i32 = 0;\n+    'b: {\n+        // lifetime used is 'b because that's *good enough*.\n+        let y: &'b i32 = &'b x;\n+        'c: {\n+            // ditto on 'c\n+            let z: &'c &'b i32 = &'c y;\n+        }\n+    }\n+}\n+```\n+\n+Wow. That's... awful. Let's all take a moment to thank Rust for being a\n+diabetes-inducing torrent of syrupy-goodness.\n+\n+Actually passing references to outer scopes will cause Rust to infer\n+a larger lifetime:\n+\n+```rust\n+let x = 0;\n+let z;\n+let y = &x;\n+z = y;\n+```\n+\n+The borrow checker always tries to minimize the extent of a lifetime, so it will\n+likely desugar to something like the following:\n+\n+```rust\n+// NOTE: `'a: {` and `&'b x` is not valid syntax!\n+'a: {\n+    let x: i32 = 0;\n+    'b: {\n+        let z: &'b i32;\n+        'c: {\n+            // Must use 'b here because this reference is\n+            // being passed to that scope.\n+            let y: &'b i32 = &'b x;\n+            z = y;\n+        }\n+    }\n+}\n+```\n+\n+\n+\n+# Example: references that outlive referents\n+\n+Alright, let's look at some of those examples from before:\n+\n+```rust,ignore\n+fn as_str(data: &u32) -> &str {\n+    let s = format!(\"{}\", data);\n+    &s\n+}\n+```\n+\n+desugars to:\n+\n+```rust,ignore\n+fn as_str<'a>(data: &'a u32) -> &'a str {\n+    'b: {\n+        let s = format!(\"{}\", data);\n+        return &'a s;\n+    }\n+}\n+```\n+\n+This signature of `as_str` takes a reference to a u32 with *some* lifetime, and\n+promises that it can produce a reference to a str that can live *just as long*.\n+Already we can see why this signature might be trouble. That basically implies\n+that we're going to *find* a str somewhere in the scope the scope the reference\n+to the u32 originated in, or somewhere *even* earlier. That's a *bit* of a big ask.\n+\n+We then proceed to compute the string `s`, and return a reference to it. Since\n+the contract of our function says the reference must outlive `'a`, that's the\n+lifetime we infer for the reference. Unfortunately, `s` was defined in the\n+scope `'b`, so the only way this is sound is if `'b` contains `'a` -- which is\n+clearly false since `'a` must contain the function call itself. We have therefore\n+created a reference whose lifetime outlives its referent, which is *literally*\n+the first thing we said that references can't do. The compiler rightfully blows\n+up in our face.\n+\n+To make this more clear, we can expand the example:\n+\n+```rust,ignore\n+fn as_str<'a>(data: &'a u32) -> &'a str {\n+    'b: {\n+        let s = format!(\"{}\", data);\n+        return &'a s\n+    }\n+}\n+\n+fn main() {\n+    'c: {\n+        let x: u32 = 0;\n+        'd: {\n+            // An anonymous scope is introduced because the borrow does not\n+            // need to last for the whole scope x is valid for. The return\n+            // of as_str must find a str somewhere *before* this function\n+            // call. Obviously not happening.\n+            println!(\"{}\", as_str::<'d>(&'d temp));\n+        }\n+    }\n+}\n+```\n+\n+Shoot!\n+\n+Of course, the right way to write this function is as follows:\n+\n+```rust\n+fn to_string(data: &u32) -> String {\n+    format!(\"{}\", data)\n+}\n+```\n+\n+We must produce an owned value inside the function to return it! The only way\n+we could have returned an `&'a str` would have been if it was in a field of the\n+`&'a u32`, which is obviously not the case.\n+\n+(Actually we could have also just returned a string literal, which as a global\n+can be considered to reside at the bottom of the stack; though this limits\n+our implementation *just a bit*.)\n+\n+\n+\n+\n+\n+# Example 2: aliasing a mutable reference\n+\n+How about the other example:\n+\n+```rust\n+let mut data = vec![1, 2, 3];\n+let x = &data[0];\n+data.push(4);\n+println!(\"{}\", x);\n+```\n+\n+```rust\n+'a: {\n+    let mut data: Vec<i32> = vec![1, 2, 3];\n+    'b: {\n+        // 'b is as big as we need this borrow to be\n+        // (just need to get to `println!`)\n+        let x: &'b i32 = Index::index::<'b>(&'b data, 0);\n+        'c: {\n+            // Temporary scope because we don't need the\n+            // &mut to last any longer.\n+\n+            // NOTE: Vec::push is not valid syntax\n+            Vec::push(&'c mut data, 4);\n+        }\n+        println!(\"{}\", x);\n+    }\n+}\n+```\n+\n+The problem here is is bit more subtle and interesting. We want Rust to\n+reject this program for the following reason: We have a live shared reference `x`\n+to a descendent of `data` when try to take a *mutable* reference to `data`\n+when we call `push`. This would create an aliased mutable reference, which would\n+violate the *second* rule of references.\n+\n+However this is *not at all* how Rust reasons that this program is bad. Rust\n+doesn't understand that `x` is a reference to a subpath of `data`. It doesn't\n+understand Vec at all. What it *does* see is that `x` has to live for `'b` to\n+be printed. The signature of `Index::index` subsequently demands that the\n+reference we take to *data* has to survive for `'b`. When we try to call `push`,\n+it then sees us try to make an `&'c mut data`. Rust knows that `'c` is contained\n+within `'b`, and rejects our program because the `&'b data` must still be live!\n+\n+Here we see that the lifetime system is *much* more coarse than the reference\n+semantics we're actually interested in preserving. For the most part, *that's\n+totally ok*, because it keeps us from spending all day explaining our program\n+to the compiler. However it does mean that several programs that are *totally*\n+correct with respect to Rust's *true* semantics are rejected because lifetimes\n+are too dumb.\n\\ No newline at end of file"}, {"sha": "5ff000f2bbce9d486a1d41dd64edb2f4c8c0ace8", "filename": "src/doc/tarpl/meet-safe-and-unsafe.md", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fmeet-safe-and-unsafe.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fmeet-safe-and-unsafe.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fmeet-safe-and-unsafe.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,98 @@\n+% Meet Safe and Unsafe\n+\n+Programmers in safe \"high-level\" languages face a fundamental dilemma. On one\n+hand, it would be *really* great to just say what you want and not worry about\n+how it's done. On the other hand, that can lead to some *really* poor\n+performance. It may be necessary to drop down to less clear or idiomatic\n+practices to get the performance characteristics you want. Or maybe you just\n+throw up your hands in disgust and decide to shell out to an implementation in\n+a less sugary-wonderful *unsafe* language.\n+\n+Worse, when you want to talk directly to the operating system, you *have* to\n+talk to an unsafe language: *C*. C is ever-present and unavoidable. It's the\n+lingua-franca of the programming world.\n+Even other safe languages generally expose C interfaces for the world at large!\n+Regardless of *why* you're doing it, as soon as your program starts talking to\n+C it stops being safe.\n+\n+With that said, Rust is *totally* a safe programming language.\n+\n+Well, Rust *has* a safe programming language. Let's step back a bit.\n+\n+Rust can be thought of as being composed of two\n+programming languages: *Safe* and *Unsafe*. Safe is For Reals Totally Safe.\n+Unsafe, unsurprisingly, is *not* For Reals Totally Safe. In fact, Unsafe lets\n+you do some really crazy unsafe things.\n+\n+Safe is *the* Rust programming language. If all you do is write Safe Rust,\n+you will never have to worry about type-safety or memory-safety. You will never\n+endure a null or dangling pointer, or any of that Undefined Behaviour nonsense.\n+\n+*That's totally awesome*.\n+\n+The standard library also gives you enough utilities out-of-the-box that you'll\n+be able to write awesome high-performance applications and libraries in pure\n+idiomatic Safe Rust.\n+\n+But maybe you want to talk to another language. Maybe you're writing a\n+low-level abstraction not exposed by the standard library. Maybe you're\n+*writing* the standard library (which is written entirely in Rust). Maybe you\n+need to do something the type-system doesn't understand and just *frob some dang\n+bits*. Maybe you need Unsafe Rust.\n+\n+Unsafe Rust is exactly like Safe Rust with *all* the same rules and semantics.\n+However Unsafe Rust lets you do some *extra* things that are Definitely Not Safe.\n+\n+The only things that are different in Unsafe Rust are that you can:\n+\n+* Dereference raw pointers\n+* Call `unsafe` functions (including C functions, intrinsics, and the raw allocator)\n+* Implement `unsafe` traits\n+* Mutate statics\n+\n+That's it. The reason these operations are relegated to Unsafe is that misusing\n+any of these things will cause the ever dreaded Undefined Behaviour. Invoking\n+Undefined Behaviour gives the compiler full rights to do arbitrarily bad things\n+to your program. You definitely *should not* invoke Undefined Behaviour.\n+\n+Unlike C, Undefined Behaviour is pretty limited in scope in Rust. All the core\n+language cares about is preventing the following things:\n+\n+* Dereferencing null or dangling pointers\n+* Reading [uninitialized memory][]\n+* Breaking the [pointer aliasing rules][]\n+* Producing invalid primitive values:\n+    * dangling/null references\n+    * a `bool` that isn't 0 or 1\n+    * an undefined `enum` discriminant\n+    * a `char` outside the ranges [0x0, 0xD7FF] and [0xE000, 0x10FFFF]\n+    * A non-utf8 `str`\n+* Unwinding into another language\n+* Causing a [data race][race]\n+* Double-dropping a value\n+\n+That's it. That's all the Undefined Behaviour baked into Rust. Of course, unsafe\n+functions and traits are free to declare arbitrary other constraints that a\n+program must maintain to avoid Undefined Behaviour. However these are generally\n+just things that will transitively lead to one of the above problems. Some\n+additional constraints may also derive from compiler intrinsics that make special\n+assumptions about how code can be optimized.\n+\n+Rust is otherwise quite permissive with respect to other dubious operations. Rust\n+considers it \"safe\" to:\n+\n+* Deadlock\n+* Have a [race condition][race]\n+* Leak memory\n+* Fail to call destructors\n+* Overflow integers\n+* Abort the program\n+* Delete the production database\n+\n+However any program that actually manages to do such a thing is *probably*\n+incorrect. Rust provides lots of tools to make these things rare, but\n+these problems are considered impractical to categorically prevent.\n+\n+[pointer aliasing rules]: references.html\n+[uninitialized memory]: uninitialized.html\n+[race]: races.html"}, {"sha": "829a15e6355b2c099f23a77203096c7c24c373f9", "filename": "src/doc/tarpl/other-reprs.md", "status": "added", "additions": 71, "deletions": 0, "changes": 71, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fother-reprs.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fother-reprs.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fother-reprs.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,71 @@\n+% Alternative representations\n+\n+Rust allows you to specify alternative data layout strategies from the default.\n+\n+\n+\n+\n+# repr(C)\n+\n+This is the most important `repr`. It has fairly simple intent: do what C does.\n+The order, size, and alignment of fields is exactly what you would expect from\n+C or C++. Any type you expect to pass through an FFI boundary should have `repr(C)`,\n+as C is the lingua-franca of the programming world. This is also necessary\n+to soundly do more elaborate tricks with data layout such as reintepretting values\n+as a different type.\n+\n+However, the interaction with Rust's more exotic data layout features must be kept\n+in mind. Due to its dual purpose as \"for FFI\" and \"for layout control\", `repr(C)`\n+can be applied to types that will be nonsensical or problematic if passed through\n+the FFI boundary.\n+\n+* ZSTs are still zero-sized, even though this is not a standard behaviour\n+  in C, and is explicitly contrary to the behaviour of an empty type in C++, which\n+  still consumes a byte of space.\n+\n+* DSTs, tuples, and tagged unions are not a concept in C and as such are never\n+  FFI safe.\n+\n+* **The [drop flag][] will still be added**\n+\n+* This is equivalent to one of `repr(u*)` (see the next section) for enums. The\n+  chosen size is the default enum size for the target platform's C ABI. Note that\n+  enum representation in C is undefined, and this may be incorrect when the C\n+  code is compiled with certain flags.\n+\n+\n+\n+# repr(u8), repr(u16), repr(u32), repr(u64)\n+\n+These specify the size to make a C-like enum. If the discriminant overflows the\n+integer it has to fit in, it will be an error. You can manually ask Rust to\n+allow this by setting the overflowing element to explicitly be 0. However Rust\n+will not allow you to create an enum where two variants have the same discriminant.\n+\n+On non-C-like enums, this will inhibit certain optimizations like the null-pointer\n+optimization.\n+\n+These reprs have no affect on a struct.\n+\n+\n+\n+\n+# repr(packed)\n+\n+`repr(packed)` forces rust to strip any padding, and only align the type to a\n+byte. This may improve the memory footprint, but will likely have other\n+negative side-effects.\n+\n+In particular, most architectures *strongly* prefer values to be aligned. This\n+may mean the unaligned loads are penalized (x86), or even fault (some ARM chips).\n+For simple cases like directly loading or storing a packed field, the compiler\n+might be able to paper over alignment issues with shifts and masks. However if\n+you take a reference to a packed field, it's unlikely that the compiler will be\n+able to emit code to avoid an unaligned load.\n+\n+`repr(packed)` is not to be used lightly. Unless you have extreme requirements,\n+this should not be used.\n+\n+This repr is a modifier on `repr(C)` and `repr(rust)`.\n+\n+[drop flag]: drop-flags.html"}, {"sha": "9c4f92a4394ee3109be9770017fbccfd7e24ad3d", "filename": "src/doc/tarpl/ownership.md", "status": "added", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fownership.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fownership.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fownership.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,66 @@\n+% Ownership and Lifetimes\n+\n+Ownership is the breakout feature of Rust. It allows Rust to be completely\n+memory-safe and efficient, while avoiding garbage collection. Before getting\n+into the ownership system in detail, we will consider the motivation of this\n+design.\n+\n+We will assume that you accept that garbage collection is not always an optimal\n+solution, and that it is desirable to manually manage memory to some extent.\n+If you do not accept this, might I interest you in a different language?\n+\n+Regardless of your feelings on GC, it is pretty clearly a *massive* boon to\n+making code safe. You never have to worry about things going away *too soon*\n+(although whether you still *wanted* to be pointing at that thing is a different\n+issue...). This is a pervasive problem that C and C++ need to deal with.\n+Consider this simple mistake that all of us who have used a non-GC'd language\n+have made at one point:\n+\n+```rust\n+fn as_str(data: &u32) -> &str {\n+    // compute the string\n+    let s = format!(\"{}\", data);\n+\n+    // OH NO! We returned a reference to something that\n+    // exists only in this function!\n+    // Dangling pointer! Use after free! Alas!\n+    // (this does not compile in Rust)\n+    &s\n+}\n+```\n+\n+This is exactly what Rust's ownership system was built to solve.\n+Rust knows the scope in which the `&s` lives, and as such can prevent it from\n+escaping. However this is a simple case that even a C compiler could plausibly\n+catch. Things get more complicated as code gets bigger and pointers get fed through\n+various functions. Eventually, a C compiler will fall down and won't be able to\n+perform sufficient escape analysis to prove your code unsound. It will consequently\n+be forced to accept your program on the assumption that it is correct.\n+\n+This will never happen to Rust. It's up to the programmer to prove to the\n+compiler that everything is sound.\n+\n+Of course, rust's story around ownership is much more complicated than just\n+verifying that references don't escape the scope of their referent. That's\n+because ensuring pointers are always valid is much more complicated than this.\n+For instance in this code,\n+\n+```rust\n+let mut data = vec![1, 2, 3];\n+// get an internal reference\n+let x = &data[0];\n+\n+// OH NO! `push` causes the backing storage of `data` to be reallocated.\n+// Dangling pointer! User after free! Alas!\n+// (this does not compile in Rust)\n+data.push(4);\n+\n+println!(\"{}\", x);\n+```\n+\n+naive scope analysis would be insufficient to prevent this bug, because `data`\n+does in fact live as long as we needed. However it was *changed* while we had\n+a reference into it. This is why Rust requires any references to freeze the\n+referent and its owners.\n+\n+"}, {"sha": "6fb16f28e343501828e78067a21859bc1d83edee", "filename": "src/doc/tarpl/poisoning.md", "status": "added", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fpoisoning.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fpoisoning.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fpoisoning.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,35 @@\n+% Poisoning\n+\n+Although all unsafe code *must* ensure it has minimal exception safety, not all\n+types ensure *maximal* exception safety. Even if the type does, your code may\n+ascribe additional meaning to it. For instance, an integer is certainly\n+exception-safe, but has no semantics on its own. It's possible that code that\n+panics could fail to correctly update the integer, producing an inconsistent\n+program state.\n+\n+This is *usually* fine, because anything that witnesses an exception is about\n+to get destroyed. For instance, if you send a Vec to another thread and that\n+thread panics, it doesn't matter if the Vec is in a weird state. It will be\n+dropped and go away forever. However some types are especially good at smuggling\n+values across the panic boundary.\n+\n+These types may choose to explicitly *poison* themselves if they witness a panic.\n+Poisoning doesn't entail anything in particular. Generally it just means\n+preventing normal usage from proceeding. The most notable example of this is the\n+standard library's Mutex type. A Mutex will poison itself if one of its\n+MutexGuards (the thing it returns when a lock is obtained) is dropped during a\n+panic. Any future attempts to lock the Mutex will return an `Err` or panic.\n+\n+Mutex poisons not for *true* safety in the sense that Rust normally cares about. It\n+poisons as a safety-guard against blindly using the data that comes out of a Mutex\n+that has witnessed a panic while locked. The data in such a Mutex was likely in the\n+middle of being modified, and as such may be in an inconsistent or incomplete state.\n+It is important to note that one cannot violate memory safety with such a type\n+if it is correctly written. After all, it must be minimally exception-safe!\n+\n+However if the Mutex contained, say, a BinaryHeap that does not actually have the\n+heap property, it's unlikely that any code that uses it will do\n+what the author intended. As such, the program should not proceed normally.\n+Still, if you're double-plus-sure that you can do *something* with the value,\n+the Mutex exposes a method to get the lock anyway. It *is* safe, after all.\n+Just maybe nonsense."}, {"sha": "240e4aca7f6b6a6df9fb7220d912905535709bfc", "filename": "src/doc/tarpl/races.md", "status": "added", "additions": 66, "deletions": 0, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fraces.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fraces.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fraces.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,66 @@\n+% Data Races and Race Conditions\n+\n+Safe Rust guarantees an absence of data races, which are defined as:\n+\n+* two or more threads concurrently accessing a location of memory\n+* one of them is a write\n+* one of them is unsynchronized\n+\n+A data race has Undefined Behaviour, and is therefore impossible to perform\n+in Safe Rust. Data races are *mostly* prevented through rust's ownership system:\n+it's impossible to alias a mutable reference, so it's impossible to perform a\n+data race. Interior mutability makes this more complicated, which is largely why\n+we have the Send and Sync traits (see below).\n+\n+However Rust *does not* prevent general race conditions. This is\n+pretty fundamentally impossible, and probably honestly undesirable. Your hardware\n+is racy, your OS is racy, the other programs on your computer are racy, and the\n+world this all runs in is racy. Any system that could genuinely claim to prevent\n+*all* race conditions would be pretty awful to use, if not just incorrect.\n+\n+So it's perfectly \"fine\" for a Safe Rust program to get deadlocked or do\n+something incredibly stupid with incorrect synchronization. Obviously such a\n+program isn't very good, but Rust can only hold your hand so far. Still, a\n+race condition can't violate memory safety in a Rust program on\n+its own. Only in conjunction with some other unsafe code can a race condition\n+actually violate memory safety. For instance:\n+\n+```rust\n+use std::thread;\n+use std::sync::atomic::{AtomicUsize, Ordering};\n+use std::sync::Arc;\n+\n+let data = vec![1, 2, 3, 4];\n+// Arc so that the memory the AtomicUsize is stored in still exists for\n+// the other thread to increment, even if we completely finish executing\n+// before it. Rust won't compile the program without it, because of the\n+// lifetime requirements of thread::spawn!\n+let idx = Arc::new(AtomicUsize::new(0));\n+let other_idx = idx.clone();\n+\n+// `move` captures other_idx by-value, moving it into this thread\n+thread::spawn(move || {\n+    // It's ok to mutate idx because this value\n+    // is an atomic, so it can't cause a Data Race.\n+    other_idx.fetch_add(10, Ordering::SeqCst);\n+});\n+\n+// Index with the value loaded from the atomic. This is safe because we\n+// read the atomic memory only once, and then pass a *copy* of that value\n+// to the Vec's indexing implementation. This indexing will be correctly\n+// bounds checked, and there's no chance of the value getting changed\n+// in the middle. However our program may panic if the thread we spawned\n+// managed to increment before this ran. A race condition because correct\n+// program execution (panicing is rarely correct) depends on order of\n+// thread execution.\n+println!(\"{}\", data[idx.load(Ordering::SeqCst)]);\n+\n+if idx.load(Ordering::SeqCst) < data.len() {\n+    unsafe {\n+        // Incorrectly loading the idx *after* we did the bounds check.\n+        // It could have changed. This is a race condition, *and dangerous*\n+        // because we decided to do `get_unchecked`, which is `unsafe`.\n+        println!(\"{}\", data.get_unchecked(idx.load(Ordering::SeqCst)));\n+    }\n+}\n+```"}, {"sha": "e9b92c69ccd2d1d747b955315567bdd32d2a21c0", "filename": "src/doc/tarpl/raii.md", "status": "added", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fraii.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fraii.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fraii.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,14 @@\n+% The Perils Of RAII\n+\n+Ownership Based Resource Management (AKA RAII: Resource Acquisition Is Initialization) is\n+something you'll interact with a lot in Rust. Especially if you use the standard library.\n+\n+Roughly speaking the pattern is as follows: to acquire a resource, you create an object that\n+manages it. To release the resource, you simply destroy the object, and it cleans up the\n+resource for you. The most common \"resource\"\n+this pattern manages is simply *memory*. `Box`, `Rc`, and basically everything in\n+`std::collections` is a convenience to enable correctly managing memory. This is particularly\n+important in Rust because we have no pervasive GC to rely on for memory management. Which is the\n+point, really: Rust is about control. However we are not limited to just memory.\n+Pretty much every other system resource like a thread, file, or socket is exposed through\n+this kind of API."}, {"sha": "24c6b607840d887a9968d6fb9da1f96c8fa3aac4", "filename": "src/doc/tarpl/references.md", "status": "added", "additions": 150, "deletions": 0, "changes": 150, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Freferences.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Freferences.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Freferences.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,150 @@\n+% References\n+\n+There are two kinds of reference:\n+\n+* Shared reference: `&`\n+* Mutable reference: `&mut`\n+\n+Which obey the following rules:\n+\n+* A reference cannot outlive its referent\n+* A mutable reference cannot be aliased\n+\n+To define aliasing, we must define the notion of *paths* and *liveness*.\n+\n+\n+\n+\n+# Paths\n+\n+If all Rust had were values, then every value would be uniquely owned\n+by a variable or composite structure. From this we naturally derive a *tree*\n+of ownership. The stack itself is the root of the tree, with every variable\n+as its direct children. Each variable's direct children would be their fields\n+(if any), and so on.\n+\n+From this view, every value in Rust has a unique *path* in the tree of ownership.\n+References to a value can subsequently be interpreted as a path in this tree.\n+Of particular interest are *ancestors* and *descendants*: if `x` owns `y`, then\n+`x` is an *ancestor* of `y`, and `y` is a *descendant* of `x`. Note that this is\n+an inclusive relationship: `x` is a descendant and ancestor of itself.\n+\n+Tragically, plenty of data doesn't reside on the stack, and we must also accommodate this.\n+Globals and thread-locals are simple enough to model as residing at the bottom\n+of the stack (though we must be careful with mutable globals). Data on\n+the heap poses a different problem.\n+\n+If all Rust had on the heap was data uniquely owned by a pointer on the stack,\n+then we can just treat that pointer as a struct that owns the value on\n+the heap. Box, Vec, String, and HashMap, are examples of types which uniquely\n+own data on the heap.\n+\n+Unfortunately, data on the heap is not *always* uniquely owned. Rc for instance\n+introduces a notion of *shared* ownership. Shared ownership means there is no\n+unique path. A value with no unique path limits what we can do with it. In general, only\n+shared references can be created to these values. However mechanisms which ensure\n+mutual exclusion may establish One True Owner temporarily, establishing a unique path\n+to that value (and therefore all its children).\n+\n+The most common way to establish such a path is through *interior mutability*,\n+in contrast to the *inherited mutability* that everything in Rust normally uses.\n+Cell, RefCell, Mutex, and RWLock are all examples of interior mutability types. These\n+types provide exclusive access through runtime restrictions. However it is also\n+possible to establish unique ownership without interior mutability. For instance,\n+if an Rc has refcount 1, then it is safe to mutate or move its internals.\n+\n+In order to correctly communicate to the type system that a variable or field of\n+a struct can have interior mutability, it must be wrapped in an UnsafeCell. This\n+does not in itself make it safe to perform interior mutability operations on that\n+value. You still must yourself ensure that mutual exclusion is upheld.\n+\n+\n+\n+# Liveness\n+\n+Roughly, a reference is *live* at some point in a program if it can be\n+dereferenced. Shared references are always live unless they are literally unreachable\n+(for instance, they reside in freed or leaked memory). Mutable references can be\n+reachable but *not* live through the process of *reborrowing*.\n+\n+A mutable reference can be reborrowed to either a shared or mutable reference to\n+one of its descendants. A reborrowed reference will only be live again once all\n+reborrows derived from it expire. For instance, a mutable reference can be reborrowed\n+to point to a field of its referent:\n+\n+```rust\n+let x = &mut (1, 2);\n+{\n+    // reborrow x to a subfield\n+    let y = &mut x.0;\n+    // y is now live, but x isn't\n+    *y = 3;\n+}\n+// y goes out of scope, so x is live again\n+*x = (5, 7);\n+```\n+\n+It is also possible to reborrow into *multiple* mutable references, as long as\n+they are *disjoint*: no reference is an ancestor of another. Rust\n+explicitly enables this to be done with disjoint struct fields, because\n+disjointness can be statically proven:\n+\n+```rust\n+let x = &mut (1, 2);\n+{\n+    // reborrow x to two disjoint subfields\n+    let y = &mut x.0;\n+    let z = &mut x.1;\n+\n+    // y and z are now live, but x isn't\n+    *y = 3;\n+    *z = 4;\n+}\n+// y and z go out of scope, so x is live again\n+*x = (5, 7);\n+```\n+\n+However it's often the case that Rust isn't sufficiently smart to prove that\n+multiple borrows are disjoint. *This does not mean it is fundamentally illegal\n+to make such a borrow*, just that Rust isn't as smart as you want.\n+\n+To simplify things, we can model variables as a fake type of reference: *owned*\n+references. Owned references have much the same semantics as mutable references:\n+they can be re-borrowed in a mutable or shared manner, which makes them no longer\n+live. Live owned references have the unique property that they can be moved\n+out of (though mutable references *can* be swapped out of). This power is\n+only given to *live* owned references because moving its referent would of\n+course invalidate all outstanding references prematurely.\n+\n+As a local lint against inappropriate mutation, only variables that are marked\n+as `mut` can be borrowed mutably.\n+\n+It is interesting to note that Box behaves exactly like an owned\n+reference. It can be moved out of, and Rust understands it sufficiently to\n+reason about its paths like a normal variable.\n+\n+\n+\n+\n+# Aliasing\n+\n+With liveness and paths defined, we can now properly define *aliasing*:\n+\n+**A mutable reference is aliased if there exists another live reference to one of\n+its ancestors or descendants.**\n+\n+(If you prefer, you may also say the two live references alias *each other*.\n+This has no semantic consequences, but is probably a more useful notion when\n+verifying the soundness of a construct.)\n+\n+That's it. Super simple right? Except for the fact that it took us two pages\n+to define all of the terms in that definition. You know: Super. Simple.\n+\n+Actually it's a bit more complicated than that. In addition to references,\n+Rust has *raw pointers*: `*const T` and `*mut T`. Raw pointers have no inherent\n+ownership or aliasing semantics. As a result, Rust makes absolutely no effort\n+to track that they are used correctly, and they are wildly unsafe.\n+\n+**It is an open question to what degree raw pointers have alias semantics.\n+However it is important for these definitions to be sound that the existence\n+of a raw pointer does not imply some kind of live path.**"}, {"sha": "caf60bed8c53b9d2dd989090fd378c5cf4696beb", "filename": "src/doc/tarpl/repr-rust.md", "status": "added", "additions": 124, "deletions": 0, "changes": 124, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Frepr-rust.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Frepr-rust.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Frepr-rust.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,124 @@\n+% repr(Rust)\n+\n+Rust gives you the following ways to lay out composite data:\n+\n+* structs (named product types)\n+* tuples (anonymous product types)\n+* arrays (homogeneous product types)\n+* enums (named sum types -- tagged unions)\n+\n+An enum is said to be *C-like* if none of its variants have associated data.\n+\n+For all these, individual fields are aligned to their preferred alignment. For\n+primitives this is usually equal to their size. For instance, a u32 will be\n+aligned to a multiple of 32 bits, and a u16 will be aligned to a multiple of 16\n+bits. Composite structures will have a preferred alignment equal to the maximum\n+of their fields' preferred alignment, and a size equal to a multiple of their\n+preferred alignment. This ensures that arrays of T can be correctly iterated\n+by offsetting by their size. So for instance,\n+\n+```rust\n+struct A {\n+    a: u8,\n+    c: u32,\n+    b: u16,\n+}\n+```\n+\n+will have a size that is a multiple of 32-bits, and 32-bit alignment.\n+\n+There is *no indirection* for these types; all data is stored contiguously as you would\n+expect in C. However with the exception of arrays (which are densely packed and\n+in-order), the layout of data is not by default specified in Rust. Given the two\n+following struct definitions:\n+\n+```rust\n+struct A {\n+    a: i32,\n+    b: u64,\n+}\n+\n+struct B {\n+    x: i32,\n+    b: u64,\n+}\n+```\n+\n+Rust *does* guarantee that two instances of A have their data laid out in exactly\n+the same way. However Rust *does not* guarantee that an instance of A has the same\n+field ordering or padding as an instance of B (in practice there's no *particular*\n+reason why they wouldn't, other than that its not currently guaranteed).\n+\n+With A and B as written, this is basically nonsensical, but several other features\n+of Rust make it desirable for the language to play with data layout in complex ways.\n+\n+For instance, consider this struct:\n+\n+```rust\n+struct Foo<T, U> {\n+    count: u16,\n+    data1: T,\n+    data2: U,\n+}\n+```\n+\n+Now consider the monomorphizations of `Foo<u32, u16>` and `Foo<u16, u32>`. If Rust lays out the\n+fields in the order specified, we expect it to *pad* the values in the struct to satisfy\n+their *alignment* requirements. So if Rust didn't reorder fields, we would expect Rust to\n+produce the following:\n+\n+```rust\n+struct Foo<u16, u32> {\n+    count: u16,\n+    data1: u16,\n+    data2: u32,\n+}\n+\n+struct Foo<u32, u16> {\n+    count: u16,\n+    _pad1: u16,\n+    data1: u32,\n+    data2: u16,\n+    _pad2: u16,\n+}\n+```\n+\n+The latter case quite simply wastes space. An optimal use of space therefore requires\n+different monomorphizations to have *different field orderings*.\n+\n+**Note: this is a hypothetical optimization that is not yet implemented in Rust 1.0**\n+\n+Enums make this consideration even more complicated. Naively, an enum such as:\n+\n+```rust\n+enum Foo {\n+    A(u32),\n+    B(u64),\n+    C(u8),\n+}\n+```\n+\n+would be laid out as:\n+\n+```rust\n+struct FooRepr {\n+    data: u64, // this is *really* either a u64, u32, or u8 based on `tag`\n+    tag: u8, // 0 = A, 1 = B, 2 = C\n+}\n+```\n+\n+And indeed this is approximately how it would be laid out in general\n+(modulo the size and position of `tag`). However there are several cases where\n+such a representation is ineffiecient. The classic case of this is Rust's\n+\"null pointer optimization\". Given a pointer that is known to not be null\n+(e.g. `&u32`), an enum can *store* a discriminant bit *inside* the pointer\n+by using null as a special value. The net result is that\n+`size_of::<Option<&T>>() == size_of::<&T>()`\n+\n+There are many types in Rust that are, or contain, \"not null\" pointers such as\n+`Box<T>`, `Vec<T>`, `String`, `&T`, and `&mut T`. Similarly, one can imagine\n+nested enums pooling their tags into a single descriminant, as they are by\n+definition known to have a limited range of valid values. In principle enums can\n+use fairly elaborate algorithms to cache bits throughout nested types with\n+special constrained representations. As such it is *especially* desirable that\n+we leave enum layout unspecified today.\n\\ No newline at end of file"}, {"sha": "2a593ffc5a7a1d585813dd6cee846af07e55d0e4", "filename": "src/doc/tarpl/safe-unsafe-meaning.md", "status": "added", "additions": 132, "deletions": 0, "changes": 132, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsafe-unsafe-meaning.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsafe-unsafe-meaning.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fsafe-unsafe-meaning.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,132 @@\n+% How Safe and Unsafe Interact\n+\n+So what's the relationship between Safe and Unsafe? How do they interact?\n+\n+Rust models the seperation between Safe and Unsafe with the `unsafe` keyword, which\n+can be thought as a sort of *foreign function interface* (FFI) between Safe and Unsafe.\n+This is the magic behind why we can say Safe is a safe language: all the scary unsafe\n+bits are relagated *exclusively* to FFI *just like every other safe language*.\n+\n+However because one language is a subset of the other, the two can be cleanly\n+intermixed as long as the boundary between Safe and Unsafe is denoted with the\n+`unsafe` keyword. No need to write headers, initialize runtimes, or any of that\n+other FFI boiler-plate.\n+\n+There are several places `unsafe` can appear in Rust today, which can largely be\n+grouped into two categories:\n+\n+* There are unchecked contracts here. To declare you understand this, I require\n+you to write `unsafe` elsewhere:\n+    * On functions, `unsafe` is declaring the function to be unsafe to call. Users\n+      of the function must check the documentation to determine what this means,\n+      and then have to write `unsafe` somewhere to identify that they're aware of\n+      the danger.\n+    * On trait declarations, `unsafe` is declaring that *implementing* the trait\n+      is an unsafe operation, as it has contracts that other unsafe code is free to\n+      trust blindly. (More on this below.)\n+\n+* I am declaring that I have, to the best of my knowledge, adhered to the\n+unchecked contracts:\n+    * On trait implementations, `unsafe` is declaring that the contract of the\n+      `unsafe` trait has been upheld.\n+    * On blocks, `unsafe` is declaring any unsafety from an unsafe\n+      operation within to be handled, and therefore the parent function is safe.\n+\n+There is also `#[unsafe_no_drop_flag]`, which is a special case that exists for\n+historical reasons and is in the process of being phased out. See the section on\n+[drop flags][] for details.\n+\n+Some examples of unsafe functions:\n+\n+* `slice::get_unchecked` will perform unchecked indexing, allowing memory\n+  safety to be freely violated.\n+* `ptr::offset` is an intrinsic that invokes Undefined Behaviour if it is\n+  not \"in bounds\" as defined by LLVM.\n+* `mem::transmute` reinterprets some value as having the given type,\n+  bypassing type safety in arbitrary ways. (see [conversions][] for details)\n+* All FFI functions are `unsafe` because they can do arbitrary things.\n+  C being an obvious culprit, but generally any language can do something\n+  that Rust isn't happy about.\n+\n+As of Rust 1.0 there are exactly two unsafe traits:\n+\n+* `Send` is a marker trait (it has no actual API) that promises implementors\n+  are safe to send (move) to another thread.\n+* `Sync` is a marker trait that promises that threads can safely share\n+  implementors through a shared reference.\n+\n+The need for unsafe traits boils down to the fundamental property of safe code:\n+\n+**No matter how completely awful Safe code is, it can't cause Undefined\n+Behaviour.**\n+\n+This means that Unsafe, **the royal vanguard of Undefined Behaviour**, has to be\n+*super paranoid* about generic safe code. Unsafe is free to trust *specific* safe\n+code (or else you would degenerate into infinite spirals of paranoid despair).\n+It is generally regarded as ok to trust the standard library to be correct, as\n+std is effectively an extension of the language (and you *really* just have to trust\n+the language). If `std` fails to uphold the guarantees it declares, then it's\n+basically a language bug.\n+\n+That said, it would be best to minimize *needlessly* relying on properties of\n+concrete safe code. Bugs happen! Of course, I must reinforce that this is only\n+a concern for Unsafe code. Safe code can blindly trust anyone and everyone\n+as far as basic memory-safety is concerned.\n+\n+On the other hand, safe traits are free to declare arbitrary contracts, but because\n+implementing them is Safe, Unsafe can't trust those contracts to actually\n+be upheld. This is different from the concrete case because *anyone* can\n+randomly implement the interface. There is something fundamentally different\n+about trusting a *particular* piece of code to be correct, and trusting *all the\n+code that will ever be written* to be correct.\n+\n+For instance Rust has `PartialOrd` and `Ord` traits to try to differentiate\n+between types which can \"just\" be compared, and those that actually implement a\n+*total* ordering. Pretty much every API that wants to work with data that can be\n+compared *really* wants Ord data. For instance, a sorted map like BTreeMap\n+*doesn't even make sense* for partially ordered types. If you claim to implement\n+Ord for a type, but don't actually provide a proper total ordering, BTreeMap will\n+get *really confused* and start making a total mess of itself. Data that is\n+inserted may be impossible to find!\n+\n+But that's ok. BTreeMap is safe, so it guarantees that even if you give it a\n+*completely* garbage Ord implementation, it will still do something *safe*. You\n+won't start reading uninitialized memory or unallocated memory. In fact, BTreeMap\n+manages to not actually lose any of your data. When the map is dropped, all the\n+destructors will be successfully called! Hooray!\n+\n+However BTreeMap is implemented using a modest spoonful of Unsafe (most collections\n+are). That means that it is not necessarily *trivially true* that a bad Ord\n+implementation will make BTreeMap behave safely. Unsafe must be sure not to rely\n+on Ord *where safety is at stake*. Ord is provided by Safe, and safety is not\n+Safe's responsibility to uphold.\n+\n+But wouldn't it be grand if there was some way for Unsafe to trust *some* trait\n+contracts *somewhere*? This is the problem that unsafe traits tackle: by marking\n+*the trait itself* as unsafe *to implement*, Unsafe can trust the implementation\n+to be correct.\n+\n+Rust has traditionally avoided making traits unsafe because it makes Unsafe\n+pervasive, which is not desirable. Send and Sync are unsafe is because\n+thread safety is a *fundamental property* that Unsafe cannot possibly hope to\n+defend against in the same way it would defend against a bad Ord implementation.\n+The only way to possibly defend against thread-unsafety would be to *not use\n+threading at all*. Making every operation atomic isn't even sufficient, because\n+it's possible for complex invariants to exist between disjoint locations in\n+memory. For instance, the pointer and capacity of a Vec must be in sync.\n+\n+Even concurrent paradigms that are traditionally regarded as Totally Safe like\n+message passing implicitly rely on some notion of thread safety -- are you\n+really message-passing if you pass a *pointer*? Send and Sync therefore require\n+some *fundamental* level of trust that Safe code can't provide, so they must be\n+unsafe to implement. To help obviate the pervasive unsafety that this would\n+introduce, Send (resp. Sync) is *automatically* derived for all types composed only\n+of Send (resp. Sync) values. 99% of types are Send and Sync, and 99% of those\n+never actually say it (the remaining 1% is overwhelmingly synchronization\n+primitives).\n+\n+\n+\n+\n+[drop flags]: drop-flags.html\n+[conversions]: conversions.html"}, {"sha": "0ac14a85f847f24a1fba89b6faac7a121a7c8fb2", "filename": "src/doc/tarpl/send-and-sync.md", "status": "added", "additions": 76, "deletions": 0, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsend-and-sync.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsend-and-sync.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fsend-and-sync.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,76 @@\n+% Send and Sync\n+\n+Not everything obeys inherited mutability, though. Some types allow you to multiply\n+alias a location in memory while mutating it. Unless these types use synchronization\n+to manage this access, they are absolutely not thread safe. Rust captures this with\n+through the `Send` and `Sync` traits.\n+\n+* A type is Send if it is safe to send it to another thread.\n+* A type is Sync if it is safe to share between threads (`&T` is Send).\n+\n+Send and Sync are *very* fundamental to Rust's concurrency story. As such, a\n+substantial amount of special tooling exists to make them work right. First and\n+foremost, they're *unsafe traits*. This means that they are unsafe *to implement*,\n+and other unsafe code can *trust* that they are correctly implemented. Since\n+they're *marker traits* (they have no associated items like methods), correctly\n+implemented simply means that they have the intrinsic properties an implementor\n+should have. Incorrectly implementing Send or Sync can cause Undefined Behaviour.\n+\n+Send and Sync are also what Rust calls *opt-in builtin traits*.\n+This means that, unlike every other trait, they are *automatically* derived:\n+if a type is composed entirely of Send or Sync types, then it is Send or Sync.\n+Almost all primitives are Send and Sync, and as a consequence pretty much\n+all types you'll ever interact with are Send and Sync.\n+\n+Major exceptions include:\n+\n+* raw pointers are neither Send nor Sync (because they have no safety guards)\n+* `UnsafeCell` isn't Sync (and therefore `Cell` and `RefCell` aren't)\n+* `Rc` isn't Send or Sync (because the refcount is shared and unsynchronized)\n+\n+`Rc` and `UnsafeCell` are very fundamentally not thread-safe: they enable\n+unsynchronized shared mutable state. However raw pointers are, strictly speaking,\n+marked as thread-unsafe as more of a *lint*. Doing anything useful\n+with a raw pointer requires dereferencing it, which is already unsafe. In that\n+sense, one could argue that it would be \"fine\" for them to be marked as thread safe.\n+\n+However it's important that they aren't thread safe to prevent types that\n+*contain them* from being automatically marked as thread safe. These types have\n+non-trivial untracked ownership, and it's unlikely that their author was\n+necessarily thinking hard about thread safety. In the case of Rc, we have a nice\n+example of a type that contains a `*mut` that is *definitely* not thread safe.\n+\n+Types that aren't automatically derived can *opt-in* to Send and Sync by simply\n+implementing them:\n+\n+```rust\n+struct MyBox(*mut u8);\n+\n+unsafe impl Send for MyBox {}\n+unsafe impl Sync for MyBox {}\n+```\n+\n+In the *incredibly rare* case that a type is *inappropriately* automatically\n+derived to be Send or Sync, then one can also *unimplement* Send and Sync:\n+\n+```rust\n+struct SpecialThreadToken(u8);\n+\n+impl !Send for SpecialThreadToken {}\n+impl !Sync for SpecialThreadToken {}\n+```\n+\n+Note that *in and of itself* it is impossible to incorrectly derive Send and Sync.\n+Only types that are ascribed special meaning by other unsafe code can possible cause\n+trouble by being incorrectly Send or Sync.\n+\n+Most uses of raw pointers should be encapsulated behind a sufficient abstraction\n+that Send and Sync can be derived. For instance all of Rust's standard\n+collections are Send and Sync (when they contain Send and Sync types)\n+in spite of their pervasive use raw pointers to\n+manage allocations and complex ownership. Similarly, most iterators into these\n+collections are Send and Sync because they largely behave like an `&` or `&mut`\n+into the collection.\n+\n+TODO: better explain what can or can't be Send or Sync. Sufficient to appeal\n+only to data races?\n\\ No newline at end of file"}, {"sha": "24f974ca73ac8baacbcd02d8bf5110eb568bcc32", "filename": "src/doc/tarpl/subtyping.md", "status": "added", "additions": 185, "deletions": 0, "changes": 185, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsubtyping.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fsubtyping.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fsubtyping.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,185 @@\n+% Subtyping and Variance\n+\n+Although Rust doesn't have any notion of inheritance, it *does* include subtyping.\n+In Rust, subtyping derives entirely from *lifetimes*. Since lifetimes are scopes,\n+we can partially order them based on the *contains* (outlives) relationship. We\n+can even express this as a generic bound.\n+\n+Subtyping on lifetimes in terms of that relationship: if `'a: 'b`\n+(\"a contains b\" or \"a outlives b\"), then `'a` is a subtype of `'b`. This is a\n+large source of confusion, because it seems intuitively backwards to many:\n+the bigger scope is a *sub type* of the smaller scope.\n+\n+This does in fact make sense, though. The intuitive reason for this is that if\n+you expect an `&'a u8`, then it's totally fine for me to hand you an `&'static u8`,\n+in the same way that if you expect an Animal in Java, it's totally fine for me to\n+hand you a Cat. Cats are just Animals *and more*, just as `'static` is just `'a`\n+*and more*.\n+\n+(Note, the subtyping relationship and typed-ness of lifetimes is a fairly arbitrary\n+construct that some disagree with. However it simplifies our analysis to treat\n+lifetimes and types uniformly.)\n+\n+Higher-ranked lifetimes are also subtypes of every concrete lifetime. This is because\n+taking an arbitrary lifetime is strictly more general than taking a specific one.\n+\n+\n+\n+# Variance\n+\n+Variance is where things get a bit complicated.\n+\n+Variance is a property that *type constructors* have. A type constructor in Rust\n+is a generic type with unbound arguments. For instance `Vec` is a type constructor\n+that takes a `T` and returns a `Vec<T>`. `&` and `&mut` are type constructors that\n+take a two types: a lifetime, and a type to point to.\n+\n+A type constructor's *variance* is how the subtyping of its inputs affects the\n+subtyping of its outputs. There are two kinds of variance in Rust:\n+\n+* F is *variant* if `T` being a subtype of `U` implies `F<T>` is a subtype of `F<U>`\n+* F is *invariant* otherwise (no subtyping relation can be derived)\n+\n+(For those of you who are familiar with variance from other languages, what we refer\n+to as \"just\" variance is in fact *covariance*. Rust does not have contravariance.\n+Historically Rust did have some contravariance but it was scrapped due to poor\n+interactions with other features.)\n+\n+Some important variances:\n+\n+* `&` is variant (as is `*const` by metaphor)\n+* `&mut` is invariant\n+* `Fn(T) -> U` is invariant with respect to `T`, but variant with respect to `U`\n+* `Box`, `Vec`, and all other collections are variant\n+* `UnsafeCell`, `Cell`, `RefCell`, `Mutex` and all \"interior mutability\"\n+  types are invariant (as is `*mut` by metaphor)\n+\n+To understand why these variances are correct and desirable, we will consider several\n+examples. We have already covered why `&` should be variant when introducing subtyping:\n+it's desirable to be able to pass longer-lived things where shorter-lived things are\n+needed.\n+\n+To see why `&mut` should be invariant, consider the following code:\n+\n+```rust,ignore\n+fn overwrite<T: Copy>(input: &mut T, new: &mut T) {\n+    *input = *new;\n+}\n+\n+fn main() {\n+    let mut forever_str: &'static str = \"hello\";\n+    {\n+        let string = String::from(\"world\");\n+        overwrite(&mut forever_str, &mut &*string);\n+    }\n+    // Oops, printing free'd memory\n+    println!(\"{}\", forever_str);\n+}\n+```\n+\n+The signature of `overwrite` is clearly valid: it takes mutable references to\n+two values of the same type, and overwrites one with the other. If `&mut` was\n+variant, then `&mut &'a str` would be a subtype of `&mut &'static str`, since\n+`&'a str` is a subtype of `&'static str`. Therefore the lifetime of\n+`forever_str` would successfully be \"shrunk\" down to the shorter lifetime of\n+`string`, and `overwrite` would be called successfully. `string` would\n+subsequently be dropped, and `forever_str` would point to freed memory when we\n+print it! Therefore `&mut` should be invariant.\n+\n+This is the general theme of variance vs\n+invariance: if variance would allow you to *store* a short-lived value in a\n+longer-lived slot, then you must be invariant.\n+\n+`Box` and `Vec` are interesting cases because they're variant, but you can\n+definitely store values in them! This is where Rust gets really clever: it's\n+fine for them to be variant because you can only store values\n+in them *via a mutable reference*! The mutable reference makes the whole type\n+invariant, and therefore prevents you from smuggling a short-lived type into\n+them.\n+\n+Being variant *does* allows them to be weakened when shared immutably.\n+So you can pass a `&Box<&'static str>` where a `&Box<&'a str>` is expected.\n+\n+However what should happen when passing *by-value* is less obvious. It turns out\n+that, yes, you can use subtyping when passing by-value. That is, this works:\n+\n+```rust\n+fn get_box<'a>(&'a u8) -> Box<&'a str> {\n+    // string literals are `&'static str`s\n+    Box::new(\"hello\")\n+}\n+```\n+\n+Weakening when you pass by-value is fine because there's no one else who\n+\"remembers\" the old lifetime in the Box. The reason a variant `&mut` was\n+trouble was because there's always someone else who remembers the original\n+subtype: the actual owner.\n+\n+The invariance of the cell types can be seen as follows: `&` is like an `&mut` for a\n+cell, because you can still store values in them through an `&`. Therefore cells\n+must be invariant to avoid lifetime smuggling.\n+\n+`Fn` is the most subtle case because it has mixed variance. To see why\n+`Fn(T) -> U` should be invariant over T, consider the following function\n+signature:\n+\n+```rust\n+// 'a is derived from some parent scope\n+fn foo(&'a str) -> usize;\n+```\n+\n+This signature claims that it can handle any `&str` that lives *at least* as long\n+as `'a`. Now if this signature was variant with respect to `&str`, that would mean\n+\n+```rust\n+fn foo(&'static str) -> usize;\n+```\n+\n+could be provided in its place, as it would be a subtype. However this function\n+has a *stronger* requirement: it says that it can *only* handle `&'static str`s,\n+and nothing else. Therefore functions are not variant over their arguments.\n+\n+To see why `Fn(T) -> U` should be *variant* over U, consider the following\n+function signature:\n+\n+```rust\n+// 'a is derived from some parent scope\n+fn foo(usize) -> &'a str;\n+```\n+\n+This signature claims that it will return something that outlives `'a`. It is\n+therefore completely reasonable to provide\n+\n+```rust\n+fn foo(usize) -> &'static str;\n+```\n+\n+in its place. Therefore functions *are* variant over their return type.\n+\n+`*const` has the exact same semantics as `&`, so variance follows. `*mut` on the\n+other hand can dereference to an &mut whether shared or not, so it is marked\n+as invariant just like cells.\n+\n+This is all well and good for the types the standard library provides, but\n+how is variance determined for type that *you* define? A struct, informally\n+speaking, inherits the variance of its fields. If a struct `Foo`\n+has a generic argument `A` that is used in a field `a`, then Foo's variance\n+over `A` is exactly `a`'s variance. However this is complicated if `A` is used\n+in multiple fields.\n+\n+* If all uses of A are variant, then Foo is variant over A\n+* Otherwise, Foo is invariant over A\n+\n+```rust\n+struct Foo<'a, 'b, A, B, C, D, E, F, G, H> {\n+    a: &'a A,     // variant over 'a and A\n+    b: &'b mut B, // invariant over 'b and B\n+    c: *const C,  // variant over C\n+    d: *mut D,    // invariant over D\n+    e: Vec<E>,    // variant over E\n+    f: Cell<F>,   // invariant over F\n+    g: G          // variant over G\n+    h1: H         // would also be variant over H except...\n+    h2: Cell<H>   // invariant over H, because invariance wins\n+}\n+```\n\\ No newline at end of file"}, {"sha": "577d35ddb56dcc55c703d9456c20d440828d82f9", "filename": "src/doc/tarpl/transmutes.md", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Ftransmutes.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Ftransmutes.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Ftransmutes.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,29 @@\n+% Transmutes\n+\n+Get out of our way type system! We're going to reinterpret these bits or die\n+trying! Even though this book is all about doing things that are unsafe, I really\n+can't emphasize that you should deeply think about finding Another Way than the\n+operations covered in this section. This is really, truly, the most horribly\n+unsafe thing you can do in Rust. The railguards here are dental floss.\n+\n+`mem::transmute<T, U>` takes a value of type `T` and reinterprets it to have\n+type `U`. The only restriction is that the `T` and `U` are verified to have the\n+same size. The ways to cause Undefined Behaviour with this are mind boggling.\n+\n+* First and foremost, creating an instance of *any* type with an invalid state\n+  is going to cause arbitrary chaos that can't really be predicted.\n+* Transmute has an overloaded return type. If you do not specify the return type\n+  it may produce a surprising type to satisfy inference.\n+* Making a primitive with an invalid value is UB\n+* Transmuting between non-repr(C) types is UB\n+* Transmuting an & to &mut is UB\n+* Transmuting to a reference without an explicitly provided lifetime\n+  produces an [unbound lifetime](lifetimes.html#unbounded-lifetimes)\n+\n+`mem::transmute_copy<T, U>` somehow manages to be *even more* wildly unsafe than\n+this. It copies `size_of<U>` bytes out of an `&T` and interprets them as a `U`.\n+The size check that `mem::transmute` has is gone (as it may be valid to copy\n+out a prefix), though it is Undefined Behaviour for `U` to be larger than `T`.\n+\n+Also of course you can get most of the functionality of these functions using\n+pointer casts.\n\\ No newline at end of file"}, {"sha": "24caeeb36aaab6da11e2e8bbe3dcc671ec892836", "filename": "src/doc/tarpl/unbounded-lifetimes.md", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funbounded-lifetimes.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funbounded-lifetimes.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Funbounded-lifetimes.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,37 @@\n+% Unbounded Lifetimes\n+\n+Unsafe code can often end up producing references or lifetimes out of thin air.\n+Such lifetimes come into the world as *unbounded*. The most common source of this\n+is derefencing a raw pointer, which produces a reference with an unbounded lifetime.\n+Such a lifetime becomes as big as context demands. This is in fact more powerful\n+than simply becoming `'static`, because for instance `&'static &'a T`\n+will fail to typecheck, but the unbound lifetime will perfectly mold into\n+`&'a &'a T` as needed. However for most intents and purposes, such an unbounded\n+lifetime can be regarded as `'static`.\n+\n+Almost no reference is `'static`, so this is probably wrong. `transmute` and\n+`transmute_copy` are the two other primary offenders. One should endeavour to\n+bound an unbounded lifetime as quick as possible, especially across function\n+boundaries.\n+\n+Given a function, any output lifetimes that don't derive from inputs are\n+unbounded. For instance:\n+\n+```rust\n+fn get_str<'a>() -> &'a str;\n+```\n+\n+will produce an `&str` with an unbounded lifetime. The easiest way to avoid\n+unbounded lifetimes is to use lifetime elision at the function boundary.\n+If an output lifetime is elided, then it *must* be bounded by an input lifetime.\n+Of course it might be bounded by the *wrong* lifetime, but this will usually\n+just cause a compiler error, rather than allow memory safety to be trivially\n+violated.\n+\n+Within a function, bounding lifetimes is more error-prone. The safest and easiest\n+way to bound a lifetime is to return it from a function with a bound lifetime.\n+However if this is unacceptable, the reference can be placed in a location with\n+a specific lifetime. Unfortunately it's impossible to name all lifetimes involved\n+in a function. To get around this, you can in principle use `copy_lifetime`, though\n+these are unstable due to their awkward nature and questionable utility.\n+"}, {"sha": "f5c0fb4059935761cb5eed8e7758afad672854af", "filename": "src/doc/tarpl/unchecked-uninit.md", "status": "added", "additions": 86, "deletions": 0, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funchecked-uninit.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funchecked-uninit.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Funchecked-uninit.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,86 @@\n+% Unchecked Uninitialized Memory\n+\n+One interesting exception to this rule is working with arrays. Safe Rust doesn't\n+permit you to partially initialize an array. When you initialize an array, you\n+can either set every value to the same thing with `let x = [val; N]`, or you can\n+specify each member individually with `let x = [val1, val2, val3]`.\n+Unfortunately this is pretty rigid, especially if you need to initialize your\n+array in a more incremental or dynamic way.\n+\n+Unsafe Rust gives us a powerful tool to handle this problem:\n+`mem::uninitialized`. This function pretends to return a value when really\n+it does nothing at all. Using it, we can convince Rust that we have initialized\n+a variable, allowing us to do trickier things with conditional and incremental\n+initialization.\n+\n+Unfortunately, this opens us up to all kinds of problems. Assignment has a\n+different meaning to Rust based on whether it believes that a variable is\n+initialized or not. If it's uninitialized, then Rust will semantically just\n+memcopy the bits over the uninitialized ones, and do nothing else. However if Rust\n+believes a value to be initialized, it will try to `Drop` the old value!\n+Since we've tricked Rust into believing that the value is initialized, we\n+can no longer safely use normal assignment.\n+\n+This is also a problem if you're working with a raw system allocator, which\n+returns a pointer to uninitialized memory.\n+\n+To handle this, we must use the `ptr` module. In particular, it provides\n+three functions that allow us to assign bytes to a location in memory without\n+evaluating the old value: `write`, `copy`, and `copy_nonoverlapping`.\n+\n+* `ptr::write(ptr, val)` takes a `val` and moves it into the address pointed\n+  to by `ptr`.\n+* `ptr::copy(src, dest, count)` copies the bits that `count` T's would occupy\n+  from src to dest. (this is equivalent to memmove -- note that the argument\n+  order is reversed!)\n+* `ptr::copy_nonoverlapping(src, dest, count)` does what `copy` does, but a\n+  little faster on the assumption that the two ranges of memory don't overlap.\n+  (this is equivalent to memcopy -- note that the argument order is reversed!)\n+\n+It should go without saying that these functions, if misused, will cause serious\n+havoc or just straight up Undefined Behaviour. The only things that these\n+functions *themselves* require is that the locations you want to read and write\n+are allocated. However the ways writing arbitrary bits to arbitrary\n+locations of memory can break things are basically uncountable!\n+\n+Putting this all together, we get the following:\n+\n+```rust\n+fn main() {\n+\tuse std::mem;\n+\n+\t// size of the array is hard-coded but easy to change. This means we can't\n+\t// use [a, b, c] syntax to initialize the array, though!\n+\tconst SIZE = 10;\n+\n+\tlet x: [Box<u32>; SIZE];\n+\n+\tunsafe {\n+\t\t// convince Rust that x is Totally Initialized\n+\t\tx = mem::uninitialized();\n+\t\tfor i in 0..SIZE {\n+\t\t\t// very carefully overwrite each index without reading it\n+\t\t\t// NOTE: exception safety is not a concern; Box can't panic\n+\t\t\tptr::write(&mut x[i], Box::new(i));\n+\t\t}\n+\t}\n+\n+\tprintln!(\"{}\", x);\n+}\n+```\n+\n+It's worth noting that you don't need to worry about ptr::write-style\n+shenanigans with types which don't implement Drop or\n+contain Drop types, because Rust knows not to try to Drop them. Similarly you\n+should be able to assign to fields of partially initialized structs\n+directly if those fields don't contain any Drop types.\n+\n+However when working with uninitialized memory you need to be ever-vigilant for\n+Rust trying to Drop values you make like this before they're fully initialized.\n+Every control path through that variable's scope must initialize the value\n+before it ends, if has a destructor.\n+*[This includes code panicking](unwinding.html)*.\n+\n+And that's about it for working with uninitialized memory! Basically nothing\n+anywhere expects to be handed uninitialized memory, so if you're going to pass\n+it around at all, be sure to be *really* careful.\n\\ No newline at end of file"}, {"sha": "915ea8602918e6133e419b041f5128eb9b620b17", "filename": "src/doc/tarpl/uninitialized.md", "status": "added", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funinitialized.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funinitialized.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Funinitialized.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,10 @@\n+% Working With Uninitialized Memory\n+\n+All runtime-allocated memory in a Rust program begins its life as\n+*uninitialized*. In this state the value of the memory is an indeterminate pile\n+of bits that may or may not even reflect a valid state for the type that is\n+supposed to inhabit that location of memory. Attempting to interpret this memory\n+as a value of *any* type will cause Undefined Behaviour. Do Not Do This.\n+\n+Rust provides mechanisms to work with uninitialized memory in checked (safe) and\n+unchecked (unsafe) ways.\n\\ No newline at end of file"}, {"sha": "59494d8647467921b74c33ce81f6a65ab0b42e8a", "filename": "src/doc/tarpl/unwinding.md", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funwinding.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Funwinding.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Funwinding.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,49 @@\n+% Unwinding\n+\n+Rust has a *tiered* error-handling scheme:\n+\n+* If something might reasonably be absent, Option is used.\n+* If something goes wrong and can reasonably be handled, Result is used.\n+* If something goes wrong and cannot reasonably be handled, the thread panics.\n+* If something catastrophic happens, the program aborts.\n+\n+Option and Result are overwhelmingly preferred in most situations, especially\n+since they can be promoted into a panic or abort at the API user's discretion.\n+Panics cause the thread to halt normal execution and unwind its stack, calling\n+destructors as if every function instantly returned.\n+\n+As of 1.0, Rust is of two minds when it comes to panics. In the long-long-ago,\n+Rust was much more like Erlang. Like Erlang, Rust had lightweight tasks,\n+and tasks were intended to kill themselves with a panic when they reached an\n+untenable state. Unlike an exception in Java or C++, a panic could not be\n+caught at any time. Panics could only be caught by the owner of the task, at which\n+point they had to be handled or *that* task would itself panic.\n+\n+Unwinding was important to this story because if a task's\n+destructors weren't called, it would cause memory and other system resources to\n+leak. Since tasks were expected to die during normal execution, this would make\n+Rust very poor for long-running systems!\n+\n+As the Rust we know today came to be, this style of programming grew out of\n+fashion in the push for less-and-less abstraction. Light-weight tasks were\n+killed in the name of heavy-weight OS threads. Still, on stable Rust as of 1.0\n+panics can only be caught by the parent thread. This means catching a panic\n+requires spinning up an entire OS thread! This unfortunately stands in conflict\n+to Rust's philosophy of zero-cost abstractions.\n+\n+There is an *unstable* API called `catch_panic` that enables catching a panic\n+without spawning a thread. Still, we would encourage you to only do this\n+sparingly. In particular, Rust's current unwinding implementation is heavily\n+optimized for the \"doesn't unwind\" case. If a program doesn't unwind, there\n+should be no runtime cost for the program being *ready* to unwind. As a\n+consequence, *actually* unwinding will be more expensive than in e.g. Java.\n+Don't build your programs to unwind under normal circumstances. Ideally, you\n+should only panic for programming errors or *extreme* problems.\n+\n+Rust's unwinding strategy is not specified to be fundamentally compatible\n+with any other language's unwinding. As such, unwinding into Rust from another\n+language, or unwinding into another language from Rust is Undefined Behaviour.\n+You must *absolutely* catch any panics at the FFI boundary! What you do at that\n+point is up to you, but *something* must be done. If you fail to do this,\n+at best, your application will crash and burn. At worst, your application *won't*\n+crash and burn, and will proceed with completely clobbered state."}, {"sha": "a51f23ca4b8b18cc14676bbbf62cd61682fdec55", "filename": "src/doc/tarpl/vec-alloc.md", "status": "added", "additions": 117, "deletions": 0, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-alloc.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-alloc.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-alloc.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,117 @@\n+% Allocating Memory\n+\n+So:\n+\n+```rust\n+#![feature(heap_api)]\n+\n+use std::rt::heap::EMPTY;\n+use std::mem;\n+\n+impl<T> Vec<T> {\n+    fn new() -> Self {\n+        assert!(mem::size_of::<T>() != 0, \"We're not ready to handle ZSTs\");\n+        unsafe {\n+            // need to cast EMPTY to the actual ptr type we want, let\n+            // inference handle it.\n+            Vec { ptr: Unique::new(heap::EMPTY as *mut _), len: 0, cap: 0 }\n+        }\n+    }\n+}\n+```\n+\n+I slipped in that assert there because zero-sized types will require some\n+special handling throughout our code, and I want to defer the issue for now.\n+Without this assert, some of our early drafts will do some Very Bad Things.\n+\n+Next we need to figure out what to actually do when we *do* want space. For that,\n+we'll need to use the rest of the heap APIs. These basically allow us to\n+talk directly to Rust's instance of jemalloc.\n+\n+We'll also need a way to handle out-of-memory conditions. The standard library\n+calls the `abort` intrinsic, but calling intrinsics from normal Rust code is a\n+pretty bad idea. Unfortunately, the `abort` exposed by the standard library\n+allocates. Not something we want to do during `oom`! Instead, we'll call\n+`std::process::exit`.\n+\n+```rust\n+fn oom() {\n+    ::std::process::exit(-9999);\n+}\n+```\n+\n+Okay, now we can write growing. Roughly, we want to have this logic:\n+\n+```text\n+if cap == 0:\n+    allocate()\n+    cap = 1\n+else\n+    reallocate\n+    cap *= 2\n+```\n+\n+But Rust's only supported allocator API is so low level that we'll need to\n+do a fair bit of extra work, though. We also need to guard against some special\n+conditions that can occur with really large allocations. In particular, we index\n+into arrays using unsigned integers, but `ptr::offset` takes signed integers. This\n+means Bad Things will happen if we ever manage to grow to contain more than\n+`isize::MAX` elements. Thankfully, this isn't something we need to worry about\n+in most cases.\n+\n+On 64-bit targets we're artifically limited to only 48-bits, so we'll run out\n+of memory far before we reach that point. However on 32-bit targets, particularly\n+those with extensions to use more of the address space, it's theoretically possible\n+to successfully allocate more than `isize::MAX` bytes of memory. Still, we only\n+really need to worry about that if we're allocating elements that are a byte large.\n+Anything else will use up too much space.\n+\n+However since this is a tutorial, we're not going to be particularly optimal here,\n+and just unconditionally check, rather than use clever platform-specific `cfg`s.\n+\n+```rust\n+fn grow(&mut self) {\n+    // this is all pretty delicate, so let's say it's all unsafe\n+    unsafe {\n+        let align = mem::min_align_of::<T>();\n+        let elem_size = mem::size_of::<T>();\n+\n+        let (new_cap, ptr) = if self.cap == 0 {\n+            let ptr = heap::allocate(elem_size, align);\n+            (1, ptr)\n+        } else {\n+            // as an invariant, we can assume that `self.cap < isize::MAX`,\n+            // so this doesn't need to be checked.\n+            let new_cap = self.cap * 2;\n+            // Similarly this can't overflow due to previously allocating this\n+            let old_num_bytes = self.cap * elem_size;\n+\n+            // check that the new allocation doesn't exceed `isize::MAX` at all\n+            // regardless of the actual size of the capacity. This combines the\n+            // `new_cap <= isize::MAX` and `new_num_bytes <= usize::MAX` checks\n+            // we need to make. We lose the ability to allocate e.g. 2/3rds of\n+            // the address space with a single Vec of i16's on 32-bit though.\n+            // Alas, poor Yorick -- I knew him, Horatio.\n+            assert!(old_num_bytes <= (::std::isize::MAX as usize) / 2,\n+                    \"capacity overflow\");\n+\n+            let new_num_bytes = old_num_bytes * 2;\n+            let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                        old_num_bytes,\n+                                        new_num_bytes,\n+                                        align);\n+            (new_cap, ptr)\n+        };\n+\n+        // If allocate or reallocate fail, we'll get `null` back\n+        if ptr.is_null() { oom(); }\n+\n+        self.ptr = Unique::new(ptr as *mut _);\n+        self.cap = new_cap;\n+    }\n+}\n+```\n+\n+Nothing particularly tricky here. Just computing sizes and alignments and doing\n+some careful multiplication checks.\n+"}, {"sha": "a83d24d7b49c97fa0ae239555b101001957dd30c", "filename": "src/doc/tarpl/vec-dealloc.md", "status": "added", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-dealloc.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-dealloc.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-dealloc.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,29 @@\n+% Deallocating\n+\n+Next we should implement Drop so that we don't massively leak tons of resources.\n+The easiest way is to just call `pop` until it yields None, and then deallocate\n+our buffer. Note that calling `pop` is uneeded if `T: !Drop`. In theory we can\n+ask Rust if T needs_drop and omit the calls to `pop`. However in practice LLVM\n+is *really* good at removing simple side-effect free code like this, so I wouldn't\n+bother unless you notice it's not being stripped (in this case it is).\n+\n+We must not call `heap::deallocate` when `self.cap == 0`, as in this case we haven't\n+actually allocated any memory.\n+\n+\n+```rust\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            while let Some(_) = self.pop() { }\n+\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```"}, {"sha": "b07d784939ae61a9864a4507bb1602ceef66b99e", "filename": "src/doc/tarpl/vec-deref.md", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-deref.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-deref.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-deref.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,40 @@\n+% Deref\n+\n+Alright! We've got a decent minimal ArrayStack implemented. We can push, we can\n+pop, and we can clean up after ourselves. However there's a whole mess of functionality\n+we'd reasonably want. In particular, we have a proper array, but none of the slice\n+functionality. That's actually pretty easy to solve: we can implement `Deref<Target=[T]>`.\n+This will magically make our Vec coerce to and behave like a slice in all sorts of\n+conditions.\n+\n+All we need is `slice::from_raw_parts`.\n+\n+```rust\n+use std::ops::Deref;\n+\n+impl<T> Deref for Vec<T> {\n+    type Target = [T];\n+    fn deref(&self) -> &[T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts(*self.ptr, self.len)\n+        }\n+    }\n+}\n+```\n+\n+And let's do DerefMut too:\n+\n+```rust\n+use std::ops::DerefMut;\n+\n+impl<T> DerefMut for Vec<T> {\n+    fn deref_mut(&mut self) -> &mut [T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts_mut(*self.ptr, self.len)\n+        }\n+    }\n+}\n+```\n+\n+Now we have `len`, `first`, `last`, indexing, slicing, sorting, `iter`, `iter_mut`,\n+and all other sorts of bells and whistles provided by slice. Sweet!"}, {"sha": "0a53e8bdfad9c2da11d744cf03340c0ed999b09a", "filename": "src/doc/tarpl/vec-drain.md", "status": "added", "additions": 318, "deletions": 0, "changes": 318, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-drain.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-drain.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-drain.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,318 @@\n+% Drain\n+\n+Let's move on to Drain. Drain is largely the same as IntoIter, except that\n+instead of consuming the Vec, it borrows the Vec and leaves its allocation\n+free. For now we'll only implement the \"basic\" full-range version.\n+\n+```rust,ignore\n+use std::marker::PhantomData;\n+\n+struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+```\n+\n+-- wait, this is seeming familiar. Let's do some more compression. Both\n+IntoIter and Drain have the exact same structure, let's just factor it out.\n+\n+```rust\n+struct RawValIter<T> {\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<T> RawValIter<T> {\n+    // unsafe to construct because it has no associated lifetimes.\n+    // This is necessary to store a RawValIter in the same struct as\n+    // its actual allocation. OK since it's a private implementation\n+    // detail.\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n+        }\n+    }\n+}\n+\n+// Iterator and DoubleEndedIterator impls identical to IntoIter.\n+```\n+\n+And IntoIter becomes the following:\n+\n+```\n+pub struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    iter: RawValIter<T>,\n+}\n+\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            let iter = RawValIter::new(&self);\n+            let buf = ptr::read(&self.buf);\n+            mem::forget(self);\n+\n+            IntoIter {\n+                iter: iter,\n+                _buf: buf,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Note that I've left a few quirks in this design to make upgrading Drain to work\n+with arbitrary subranges a bit easier. In particular we *could* have RawValIter\n+drain itself on drop, but that won't work right for a more complex Drain.\n+We also take a slice to simplify Drain initialization.\n+\n+Alright, now Drain is really easy:\n+\n+```rust\n+use std::marker::PhantomData;\n+\n+pub struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>,\n+    iter: RawValIter<T>,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next_back() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<'a, T> DoubleEndedIterator for Drain<'a, T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<'a, T> Drop for Drain<'a, T> {\n+    fn drop(&mut self) {\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn drain(&mut self) -> Drain<T> {\n+        // this is a mem::forget safety thing. If Drain is forgotten, we just\n+        // leak the whole Vec's contents. Also we need to do this *eventually*\n+        // anyway, so why not do it now?\n+        self.len = 0;\n+\n+        unsafe {\n+            Drain {\n+                iter: RawValIter::new(&self),\n+                vec: PhantomData,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+\n+\n+\n+# Handling Zero-Sized Types\n+\n+It's time. We're going to fight the spectre that is zero-sized types. Safe Rust\n+*never* needs to care about this, but Vec is very intensive on raw pointers and\n+raw allocations, which are exactly the *only* two things that care about\n+zero-sized types. We need to be careful of two things:\n+\n+* The raw allocator API has undefined behaviour if you pass in 0 for an\n+  allocation size.\n+* raw pointer offsets are no-ops for zero-sized types, which will break our\n+  C-style pointer iterator.\n+\n+Thankfully we abstracted out pointer-iterators and allocating handling into\n+RawValIter and RawVec respectively. How mysteriously convenient.\n+\n+\n+\n+\n+## Allocating Zero-Sized Types\n+\n+So if the allocator API doesn't support zero-sized allocations, what on earth\n+do we store as our allocation? Why, `heap::EMPTY` of course! Almost every operation\n+with a ZST is a no-op since ZSTs have exactly one value, and therefore no state needs\n+to be considered to store or load them. This actually extends to `ptr::read` and\n+`ptr::write`: they won't actually look at the pointer at all. As such we *never* need\n+to change the pointer.\n+\n+Note however that our previous reliance on running out of memory before overflow is\n+no longer valid with zero-sized types. We must explicitly guard against capacity\n+overflow for zero-sized types.\n+\n+Due to our current architecture, all this means is writing 3 guards, one in each\n+method of RawVec.\n+\n+```rust\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        unsafe {\n+            // !0 is usize::MAX. This branch should be stripped at compile time.\n+            let cap = if mem::size_of::<T>() == 0 { !0 } else { 0 };\n+\n+            // heap::EMPTY doubles as \"unallocated\" and \"zero-sized allocation\"\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: cap }\n+        }\n+    }\n+\n+    fn grow(&mut self) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the Vec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            let align = mem::min_align_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        let elem_size = mem::size_of::<T>();\n+\n+        // don't free zero-sized allocations, as they were never allocated.\n+        if self.cap != 0 && elem_size != 0 {\n+            let align = mem::min_align_of::<T>();\n+\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+That's it. We support pushing and popping zero-sized types now. Our iterators\n+(that aren't provided by slice Deref) are still busted, though.\n+\n+\n+\n+\n+## Iterating Zero-Sized Types\n+\n+Zero-sized offsets are no-ops. This means that our current design will always\n+initialize `start` and `end` as the same value, and our iterators will yield\n+nothing. The current solution to this is to cast the pointers to integers,\n+increment, and then cast them back:\n+\n+```\n+impl<T> RawValIter<T> {\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: if mem::size_of::<T>() == 0 {\n+                ((slice.as_ptr() as usize) + slice.len()) as *const _\n+            } else if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Now we have a different bug. Instead of our iterators not running at all, our\n+iterators now run *forever*. We need to do the same trick in our iterator impls.\n+Also, our size_hint computation code will divide by 0 for ZSTs. Since we'll\n+basically be treating the two pointers as if they point to bytes, we'll just\n+map size 0 to divide by 1.\n+\n+```\n+impl<T> Iterator for RawValIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = if mem::size_of::<T>() == 0 {\n+                    (self.start as usize + 1) as *const _\n+                } else {\n+                    self.start.offset(1);\n+                }\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let elem_size = mem::size_of::<T>();\n+        let len = (self.end as usize - self.start as usize)\n+                  / if elem_size == 0 { 1 } else { elem_size };\n+        (len, Some(len))\n+    }\n+}\n+\n+impl<T> DoubleEndedIterator for RawValIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = if mem::size_of::<T>() == 0 {\n+                    (self.end as usize - 1) as *const _\n+                } else {\n+                    self.end.offset(-1);\n+                }\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+```\n+\n+And that's it. Iteration works!\n\\ No newline at end of file"}, {"sha": "96fcf6d471030b35f5adafb20d9d72d81f9d98ab", "filename": "src/doc/tarpl/vec-final.md", "status": "added", "additions": 309, "deletions": 0, "changes": 309, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-final.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-final.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-final.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,309 @@\n+% The Final Code\n+\n+```rust\n+#![feature(unique)]\n+#![feature(heap_api)]\n+\n+use std::ptr::{Unique, self};\n+use std::rt::heap;\n+use std::mem;\n+use std::ops::{Deref, DerefMut};\n+use std::marker::PhantomData;\n+\n+\n+\n+\n+\n+struct RawVec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+}\n+\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        unsafe {\n+            // !0 is usize::MAX. This branch should be stripped at compile time.\n+            let cap = if mem::size_of::<T>() == 0 { !0 } else { 0 };\n+\n+            // heap::EMPTY doubles as \"unallocated\" and \"zero-sized allocation\"\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: cap }\n+        }\n+    }\n+\n+    fn grow(&mut self) {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the Vec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            let align = mem::min_align_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        let elem_size = mem::size_of::<T>();\n+        if self.cap != 0 && elem_size != 0 {\n+            let align = mem::min_align_of::<T>();\n+\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+\n+\n+\n+\n+\n+pub struct Vec<T> {\n+    buf: RawVec<T>,\n+    len: usize,\n+}\n+\n+impl<T> Vec<T> {\n+    fn ptr(&self) -> *mut T { *self.buf.ptr }\n+\n+    fn cap(&self) -> usize { self.buf.cap }\n+\n+    pub fn new() -> Self {\n+        Vec { buf: RawVec::new(), len: 0 }\n+    }\n+    pub fn push(&mut self, elem: T) {\n+        if self.len == self.cap() { self.buf.grow(); }\n+\n+        unsafe {\n+            ptr::write(self.ptr().offset(self.len as isize), elem);\n+        }\n+\n+        // Can't fail, we'll OOM first.\n+        self.len += 1;\n+    }\n+\n+    pub fn pop(&mut self) -> Option<T> {\n+        if self.len == 0 {\n+            None\n+        } else {\n+            self.len -= 1;\n+            unsafe {\n+                Some(ptr::read(self.ptr().offset(self.len as isize)))\n+            }\n+        }\n+    }\n+\n+    pub fn insert(&mut self, index: usize, elem: T) {\n+        assert!(index <= self.len, \"index out of bounds\");\n+        if self.cap() == self.len { self.buf.grow(); }\n+\n+        unsafe {\n+            if index < self.len {\n+                ptr::copy(self.ptr().offset(index as isize),\n+                          self.ptr().offset(index as isize + 1),\n+                          self.len - index);\n+            }\n+            ptr::write(self.ptr().offset(index as isize), elem);\n+            self.len += 1;\n+        }\n+    }\n+\n+    pub fn remove(&mut self, index: usize) -> T {\n+        assert!(index < self.len, \"index out of bounds\");\n+        unsafe {\n+            self.len -= 1;\n+            let result = ptr::read(self.ptr().offset(index as isize));\n+            ptr::copy(self.ptr().offset(index as isize + 1),\n+                      self.ptr().offset(index as isize),\n+                      self.len - index);\n+            result\n+        }\n+    }\n+\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            let iter = RawValIter::new(&self);\n+            let buf = ptr::read(&self.buf);\n+            mem::forget(self);\n+\n+            IntoIter {\n+                iter: iter,\n+                _buf: buf,\n+            }\n+        }\n+    }\n+\n+    pub fn drain(&mut self) -> Drain<T> {\n+        // this is a mem::forget safety thing. If this is forgotten, we just\n+        // leak the whole Vec's contents. Also we need to do this *eventually*\n+        // anyway, so why not do it now?\n+        self.len = 0;\n+        unsafe {\n+            Drain {\n+                iter: RawValIter::new(&self),\n+                vec: PhantomData,\n+            }\n+        }\n+    }\n+}\n+\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        while let Some(_) = self.pop() {}\n+        // allocation is handled by RawVec\n+    }\n+}\n+\n+impl<T> Deref for Vec<T> {\n+    type Target = [T];\n+    fn deref(&self) -> &[T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts(self.ptr(), self.len)\n+        }\n+    }\n+}\n+\n+impl<T> DerefMut for Vec<T> {\n+    fn deref_mut(&mut self) -> &mut [T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts_mut(self.ptr(), self.len)\n+        }\n+    }\n+}\n+\n+\n+\n+\n+\n+struct RawValIter<T> {\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<T> RawValIter<T> {\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: if mem::size_of::<T>() == 0 {\n+                ((slice.as_ptr() as usize) + slice.len()) as *const _\n+            } else if slice.len() == 0 {\n+                slice.as_ptr()\n+            } else {\n+                slice.as_ptr().offset(slice.len() as isize)\n+            }\n+        }\n+    }\n+}\n+\n+impl<T> Iterator for RawValIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = self.start.offset(1);\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let elem_size = mem::size_of::<T>();\n+        let len = (self.end as usize - self.start as usize)\n+                  / if elem_size == 0 { 1 } else { elem_size };\n+        (len, Some(len))\n+    }\n+}\n+\n+impl<T> DoubleEndedIterator for RawValIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = self.end.offset(-1);\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+\n+\n+\n+\n+pub struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    iter: RawValIter<T>,\n+}\n+\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        for _ in &mut *self {}\n+    }\n+}\n+\n+\n+\n+\n+pub struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>,\n+    iter: RawValIter<T>,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next_back() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<'a, T> DoubleEndedIterator for Drain<'a, T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<'a, T> Drop for Drain<'a, T> {\n+    fn drop(&mut self) {\n+        // pre-drain the iter\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+/// Abort the process, we're out of memory!\n+///\n+/// In practice this is probably dead code on most OSes\n+fn oom() {\n+    ::std::process::exit(-9999);\n+}\n+```\n\\ No newline at end of file"}, {"sha": "42d114c4a4495267407d8e62cc0e450e9f8048c9", "filename": "src/doc/tarpl/vec-insert-remove.md", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-insert-remove.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-insert-remove.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-insert-remove.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,50 @@\n+% Insert and Remove\n+\n+Something *not* provided but slice is `insert` and `remove`, so let's do those next.\n+\n+Insert needs to shift all the elements at the target index to the right by one.\n+To do this we need to use `ptr::copy`, which is our version of C's `memmove`.\n+This copies some chunk of memory from one location to another, correctly handling\n+the case where the source and destination overlap (which will definitely happen\n+here).\n+\n+If we insert at index `i`, we want to shift the `[i .. len]` to `[i+1 .. len+1]`\n+using the *old* len.\n+\n+```rust\n+pub fn insert(&mut self, index: usize, elem: T) {\n+    // Note: `<=` because it's valid to insert after everything\n+    // which would be equivalent to push.\n+    assert!(index <= self.len, \"index out of bounds\");\n+    if self.cap == self.len { self.grow(); }\n+\n+    unsafe {\n+        if index < self.len {\n+            // ptr::copy(src, dest, len): \"copy from source to dest len elems\"\n+            ptr::copy(self.ptr.offset(index as isize),\n+                      self.ptr.offset(index as isize + 1),\n+                      len - index);\n+        }\n+        ptr::write(self.ptr.offset(index as isize), elem);\n+        self.len += 1;\n+    }\n+}\n+```\n+\n+Remove behaves in the opposite manner. We need to shift all the elements from\n+`[i+1 .. len + 1]` to `[i .. len]` using the *new* len.\n+\n+```rust\n+pub fn remove(&mut self, index: usize) -> T {\n+    // Note: `<` because it's *not* valid to remove after everything\n+    assert!(index < self.len, \"index out of bounds\");\n+    unsafe {\n+        self.len -= 1;\n+        let result = ptr::read(self.ptr.offset(index as isize));\n+        ptr::copy(self.ptr.offset(index as isize + 1),\n+                  self.ptr.offset(index as isize),\n+                  len - index);\n+        result\n+    }\n+}\n+```\n\\ No newline at end of file"}, {"sha": "b7e7d2bdc42df46544f15f4bf7db1e1ae3a5bd26", "filename": "src/doc/tarpl/vec-into-iter.md", "status": "added", "additions": 293, "deletions": 0, "changes": 293, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-into-iter.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-into-iter.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-into-iter.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,293 @@\n+% IntoIter\n+\n+Let's move on to writing iterators. `iter` and `iter_mut` have already been\n+written for us thanks to The Magic of Deref. However there's two interesting\n+iterators that Vec provides that slices can't: `into_iter` and `drain`.\n+\n+IntoIter consumes the Vec by-value, and can consequently yield its elements\n+by-value. In order to enable this, IntoIter needs to take control of Vec's\n+allocation.\n+\n+IntoIter needs to be DoubleEnded as well, to enable reading from both ends.\n+Reading from the back could just be implemented as calling `pop`, but reading\n+from the front is harder. We could call `remove(0)` but that would be insanely\n+expensive. Instead we're going to just use ptr::read to copy values out of either\n+end of the Vec without mutating the buffer at all.\n+\n+To do this we're going to use a very common C idiom for array iteration. We'll\n+make two pointers; one that points to the start of the array, and one that points\n+to one-element past the end. When we want an element from one end, we'll read out\n+the value pointed to at that end and move the pointer over by one. When the two\n+pointers are equal, we know we're done.\n+\n+Note that the order of read and offset are reversed for `next` and `next_back`\n+For `next_back` the pointer is always *after* the element it wants to read next,\n+while for `next` the pointer is always *at* the element it wants to read next.\n+To see why this is, consider the case where every element but one has been yielded.\n+\n+The array looks like this:\n+\n+```text\n+          S  E\n+[X, X, X, O, X, X, X]\n+```\n+\n+If E pointed directly at the element it wanted to yield next, it would be\n+indistinguishable from the case where there are no more elements to yield.\n+\n+So we're going to use the following struct:\n+\n+```rust\n+struct IntoIter<T> {\n+    buf: Unique<T>,\n+    cap: usize,\n+    start: *const T,\n+    end: *const T,\n+}\n+```\n+\n+One last subtle detail: if our Vec is empty, we want to produce an empty iterator.\n+This will actually technically fall out doing the naive thing of:\n+\n+```text\n+start = ptr\n+end = ptr.offset(len)\n+```\n+\n+However because `offset` is marked as a GEP inbounds instruction, this will tell\n+LLVM that ptr is allocated and won't alias other allocated memory. This is fine\n+for zero-sized types, as they can't alias anything. However if we're using\n+`heap::EMPTY` as a sentinel for a non-allocation for a *non-zero-sized* type,\n+this can cause undefined behaviour. Alas, we must therefore special case either\n+cap or len being 0 to not do the offset.\n+\n+So this is what we end up with for initialization:\n+\n+```rust\n+impl<T> Vec<T> {\n+    fn into_iter(self) -> IntoIter<T> {\n+        // Can't destructure Vec since it's Drop\n+        let ptr = self.ptr;\n+        let cap = self.cap;\n+        let len = self.len;\n+\n+        // Make sure not to drop Vec since that will free the buffer\n+        mem::forget(self);\n+\n+        unsafe {\n+            IntoIter {\n+                buf: ptr,\n+                cap: cap,\n+                start: *ptr,\n+                end: if cap == 0 {\n+                    // can't offset off this pointer, it's not allocated!\n+                    *ptr\n+                } else {\n+                    ptr.offset(len as isize)\n+                }\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Here's iterating forward:\n+\n+```rust\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = self.start.offset(1);\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let len = (self.end as usize - self.start as usize)\n+                  / mem::size_of::<T>();\n+        (len, Some(len))\n+    }\n+}\n+```\n+\n+And here's iterating backwards.\n+\n+```rust\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = self.end.offset(-1);\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Because IntoIter takes ownership of its allocation, it needs to implement Drop\n+to free it. However it *also* wants to implement Drop to drop any elements it\n+contains that weren't yielded.\n+\n+\n+```rust\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            // drop any remaining elements\n+            for _ in &mut *self {}\n+\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.buf as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+We've actually reached an interesting situation here: we've duplicated the logic\n+for specifying a buffer and freeing its memory. Now that we've implemented it and\n+identified *actual* logic duplication, this is a good time to perform some logic\n+compression.\n+\n+We're going to abstract out the `(ptr, cap)` pair and give them the logic for\n+allocating, growing, and freeing:\n+\n+```rust\n+\n+struct RawVec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+}\n+\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        assert!(mem::size_of::<T>() != 0, \"TODO: implement ZST support\");\n+        unsafe {\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: 0 }\n+        }\n+    }\n+\n+    // unchanged from Vec\n+    fn grow(&mut self) {\n+        unsafe {\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+And change vec as follows:\n+\n+```rust\n+pub struct Vec<T> {\n+    buf: RawVec<T>,\n+    len: usize,\n+}\n+\n+impl<T> Vec<T> {\n+    fn ptr(&self) -> *mut T { *self.buf.ptr }\n+\n+    fn cap(&self) -> usize { self.buf.cap }\n+\n+    pub fn new() -> Self {\n+        Vec { buf: RawVec::new(), len: 0 }\n+    }\n+\n+    // push/pop/insert/remove largely unchanged:\n+    // * `self.ptr -> self.ptr()`\n+    // * `self.cap -> self.cap()`\n+    // * `self.grow -> self.buf.grow()`\n+}\n+\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        while let Some(_) = self.pop() {}\n+        // deallocation is handled by RawVec\n+    }\n+}\n+```\n+\n+And finally we can really simplify IntoIter:\n+\n+```rust\n+struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+// next and next_back litterally unchanged since they never referred to the buf\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        // only need to ensure all our elements are read;\n+        // buffer will clean itself up afterwards.\n+        for _ in &mut *self {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            // need to use ptr::read to unsafely move the buf out since it's\n+            // not Copy.\n+            let buf = ptr::read(&self.buf);\n+            let len = self.len;\n+            mem::forget(self);\n+\n+            IntoIter {\n+                start: *buf.ptr,\n+                end: buf.ptr.offset(len as isize),\n+                _buf: buf,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Much better.\n\\ No newline at end of file"}, {"sha": "0f85e4d27cefe9ae6596969788e4c198e5212a2e", "filename": "src/doc/tarpl/vec-layout.md", "status": "added", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-layout.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-layout.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-layout.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,61 @@\n+% Layout\n+\n+First off, we need to come up with the struct layout. Naively we want this\n+design:\n+\n+```rust\n+struct Vec<T> {\n+    ptr: *mut T,\n+    cap: usize,\n+    len: usize,\n+}\n+```\n+\n+And indeed this would compile. Unfortunately, it would be incorrect. The compiler\n+will give us too strict variance, so e.g. an `&Vec<&'static str>` couldn't be used\n+where an `&Vec<&'a str>` was expected. More importantly, it will give incorrect\n+ownership information to dropck, as it will conservatively assume we don't own\n+any values of type `T`. See [the chapter on ownership and lifetimes]\n+(lifetimes.html) for details.\n+\n+As we saw in the lifetimes chapter, we should use `Unique<T>` in place of `*mut T`\n+when we have a raw pointer to an allocation we own:\n+\n+\n+```rust\n+#![feature(unique)]\n+\n+use std::ptr::{Unique, self};\n+\n+pub struct Vec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+    len: usize,\n+}\n+```\n+\n+As a recap, Unique is a wrapper around a raw pointer that declares that:\n+\n+* We own at least one value of type `T`\n+* We are Send/Sync iff `T` is Send/Sync\n+* Our pointer is never null (and therefore `Option<Vec>` is null-pointer-optimized)\n+\n+That last point is subtle. First, it makes `Unique::new` unsafe to call, because\n+putting `null` inside of it is Undefined Behaviour. It also throws a\n+wrench in an important feature of Vec (and indeed all of the std collections):\n+an empty Vec doesn't actually allocate at all. So if we can't allocate,\n+but also can't put a null pointer in `ptr`, what do we do in\n+`Vec::new`? Well, we just put some other garbage in there!\n+\n+This is perfectly fine because we already have `cap == 0` as our sentinel for no\n+allocation. We don't even need to handle it specially in almost any code because\n+we usually need to check if `cap > len` or `len > 0` anyway. The traditional\n+Rust value to put here is `0x01`. The standard library actually exposes this\n+as `std::rt::heap::EMPTY`. There are quite a few places where we'll want to use\n+`heap::EMPTY` because there's no real allocation to talk about but `null` would\n+make the compiler angry.\n+\n+All of the `heap` API is totally unstable under the `heap_api` feature, though.\n+We could trivially define `heap::EMPTY` ourselves, but we'll want the rest of\n+the `heap` API anyway, so let's just get that dependency over with.\n+"}, {"sha": "d1584a234210010172a5a4998581067809da54d6", "filename": "src/doc/tarpl/vec-push-pop.md", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-push-pop.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec-push-pop.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec-push-pop.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,55 @@\n+% Push and Pop\n+\n+Alright. We can initialize. We can allocate. Let's actually implement some\n+functionality! Let's start with `push`. All it needs to do is check if we're\n+full to grow, unconditionally write to the next index, and then increment our\n+length.\n+\n+To do the write we have to be careful not to evaluate the memory we want to write\n+to. At worst, it's truly uninitialized memory from the allocator. At best it's the\n+bits of some old value we popped off. Either way, we can't just index to the memory\n+and dereference it, because that will evaluate the memory as a valid instance of\n+T. Worse, `foo[idx] = x` will try to call `drop` on the old value of `foo[idx]`!\n+\n+The correct way to do this is with `ptr::write`, which just blindly overwrites the\n+target address with the bits of the value we provide. No evaluation involved.\n+\n+For `push`, if the old len (before push was called) is 0, then we want to write\n+to the 0th index. So we should offset by the old len.\n+\n+```rust\n+pub fn push(&mut self, elem: T) {\n+    if self.len == self.cap { self.grow(); }\n+\n+    unsafe {\n+        ptr::write(self.ptr.offset(self.len as isize), elem);\n+    }\n+\n+    // Can't fail, we'll OOM first.\n+    self.len += 1;\n+}\n+```\n+\n+Easy! How about `pop`? Although this time the index we want to access is\n+initialized, Rust won't just let us dereference the location of memory to move\n+the value out, because that *would* leave the memory uninitialized! For this we\n+need `ptr::read`, which just copies out the bits from the target address and\n+intrprets it as a value of type T. This will leave the memory at this address\n+*logically* uninitialized, even though there is in fact a perfectly good instance\n+of T there.\n+\n+For `pop`, if the old len is 1, we want to read out of the 0th index. So we\n+should offset by the *new* len.\n+\n+```rust\n+pub fn pop(&mut self) -> Option<T> {\n+    if self.len == 0 {\n+        None\n+    } else {\n+        self.len -= 1;\n+        unsafe {\n+            Some(ptr::read(self.ptr.offset(self.len as isize)))\n+        }\n+    }\n+}\n+```\n\\ No newline at end of file"}, {"sha": "a613f259b70f2698d9a90b5a3edc159a7af2a2db", "filename": "src/doc/tarpl/vec.md", "status": "added", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fvec.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fvec.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,6 @@\n+% Example: Implementing Vec\n+\n+To bring everything together, we're going to write `std::Vec` from scratch.\n+Because all the best tools for writing unsafe code are unstable, this\n+project will only work on nightly (as of Rust 1.2.0).\n+"}, {"sha": "69d0b31cf88d64c0fac72e979baa267dd1487ba6", "filename": "src/doc/tarpl/working-with-unsafe.md", "status": "added", "additions": 104, "deletions": 0, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fworking-with-unsafe.md", "raw_url": "https://github.com/rust-lang/rust/raw/e2b5f4fac4967fdc18e51c2394e34932b9a21d94/src%2Fdoc%2Ftarpl%2Fworking-with-unsafe.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftarpl%2Fworking-with-unsafe.md?ref=e2b5f4fac4967fdc18e51c2394e34932b9a21d94", "patch": "@@ -0,0 +1,104 @@\n+% Working with Unsafe\n+\n+Rust generally only gives us the tools to talk about Unsafe in a scoped and\n+binary manner. Unfortunately, reality is significantly more complicated than that.\n+For instance, consider the following toy function:\n+\n+```rust\n+pub fn index(idx: usize, arr: &[u8]) -> Option<u8> {\n+    if idx < arr.len() {\n+        unsafe {\n+            Some(*arr.get_unchecked(idx))\n+        }\n+    } else {\n+        None\n+    }\n+}\n+```\n+\n+Clearly, this function is safe. We check that the index is in bounds, and if it\n+is, index into the array in an unchecked manner. But even in such a trivial\n+function, the scope of the unsafe block is questionable. Consider changing the\n+`<` to a `<=`:\n+\n+```rust\n+pub fn index(idx: usize, arr: &[u8]) -> Option<u8> {\n+    if idx <= arr.len() {\n+        unsafe {\n+            Some(*arr.get_unchecked(idx))\n+        }\n+    } else {\n+        None\n+    }\n+}\n+```\n+\n+This program is now unsound, and yet *we only modified safe code*. This is the\n+fundamental problem of safety: it's non-local. The soundness of our unsafe\n+operations necessarily depends on the state established by \"safe\" operations.\n+Although safety *is* modular (we *still* don't need to worry about about\n+unrelated safety issues like uninitialized memory), it quickly contaminates the\n+surrounding code.\n+\n+Trickier than that is when we get into actual statefulness. Consider a simple\n+implementation of `Vec`:\n+\n+```rust\n+// Note this definition is insufficient. See the section on lifetimes.\n+pub struct Vec<T> {\n+    ptr: *mut T,\n+    len: usize,\n+    cap: usize,\n+}\n+\n+// Note this implementation does not correctly handle zero-sized types.\n+// We currently live in a nice imaginary world of only positive fixed-size\n+// types.\n+impl<T> Vec<T> {\n+    pub fn push(&mut self, elem: T) {\n+        if self.len == self.cap {\n+            // not important for this example\n+            self.reallocate();\n+        }\n+        unsafe {\n+            ptr::write(self.ptr.offset(len as isize), elem);\n+            self.len += 1;\n+        }\n+    }\n+}\n+```\n+\n+This code is simple enough to reasonably audit and verify. Now consider\n+adding the following method:\n+\n+```rust\n+    fn make_room(&mut self) {\n+        // grow the capacity\n+        self.cap += 1;\n+    }\n+```\n+\n+This code is safe, but it is also completely unsound. Changing the capacity\n+violates the invariants of Vec (that `cap` reflects the allocated space in the\n+Vec). This is not something the rest of Vec can guard against. It *has* to\n+trust the capacity field because there's no way to verify it.\n+\n+`unsafe` does more than pollute a whole function: it pollutes a whole *module*.\n+Generally, the only bullet-proof way to limit the scope of unsafe code is at the\n+module boundary with privacy.\n+\n+However this works *perfectly*. The existence of `make_room` is *not* a\n+problem for the soundness of Vec because we didn't mark it as public. Only the\n+module that defines this function can call it. Also, `make_room` directly\n+accesses the private fields of Vec, so it can only be written in the same module\n+as Vec.\n+\n+It is therefore possible for us to write a completely safe abstraction that\n+relies on complex invariants. This is *critical* to the relationship between\n+Safe Rust and Unsafe Rust. We have already seen that Unsafe code must trust\n+*some* Safe code, but can't trust *arbitrary* Safe code. However if Unsafe\n+couldn't prevent client Safe code from messing with its state in arbitrary ways,\n+safety would be a lost cause.\n+\n+Safety lives!\n+"}]}