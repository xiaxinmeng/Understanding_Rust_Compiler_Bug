{"sha": "4bdb6351ac557851607df9d142c9e573c0fb5e1d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjRiZGI2MzUxYWM1NTc4NTE2MDdkZjlkMTQyYzllNTczYzBmYjVlMWQ=", "commit": {"author": {"name": "Seivan Heidari", "email": "seivan.heidari@icloud.com", "date": "2019-11-18T19:53:40Z"}, "committer": {"name": "Seivan Heidari", "email": "seivan.heidari@icloud.com", "date": "2019-11-18T19:53:40Z"}, "message": "Merge branch 'master' of https://github.com/rust-analyzer/rust-analyzer into feature/themes", "tree": {"sha": "48b349958afceeeebecccd63e55004d5a924baff", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/48b349958afceeeebecccd63e55004d5a924baff"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4bdb6351ac557851607df9d142c9e573c0fb5e1d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4bdb6351ac557851607df9d142c9e573c0fb5e1d", "html_url": "https://github.com/rust-lang/rust/commit/4bdb6351ac557851607df9d142c9e573c0fb5e1d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4bdb6351ac557851607df9d142c9e573c0fb5e1d/comments", "author": {"login": "seivan", "id": 55424, "node_id": "MDQ6VXNlcjU1NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/55424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seivan", "html_url": "https://github.com/seivan", "followers_url": "https://api.github.com/users/seivan/followers", "following_url": "https://api.github.com/users/seivan/following{/other_user}", "gists_url": "https://api.github.com/users/seivan/gists{/gist_id}", "starred_url": "https://api.github.com/users/seivan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seivan/subscriptions", "organizations_url": "https://api.github.com/users/seivan/orgs", "repos_url": "https://api.github.com/users/seivan/repos", "events_url": "https://api.github.com/users/seivan/events{/privacy}", "received_events_url": "https://api.github.com/users/seivan/received_events", "type": "User", "site_admin": false}, "committer": {"login": "seivan", "id": 55424, "node_id": "MDQ6VXNlcjU1NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/55424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seivan", "html_url": "https://github.com/seivan", "followers_url": "https://api.github.com/users/seivan/followers", "following_url": "https://api.github.com/users/seivan/following{/other_user}", "gists_url": "https://api.github.com/users/seivan/gists{/gist_id}", "starred_url": "https://api.github.com/users/seivan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seivan/subscriptions", "organizations_url": "https://api.github.com/users/seivan/orgs", "repos_url": "https://api.github.com/users/seivan/repos", "events_url": "https://api.github.com/users/seivan/events{/privacy}", "received_events_url": "https://api.github.com/users/seivan/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "aceeb0b85ee8228503f970ea602af71ff22216a0", "url": "https://api.github.com/repos/rust-lang/rust/commits/aceeb0b85ee8228503f970ea602af71ff22216a0", "html_url": "https://github.com/rust-lang/rust/commit/aceeb0b85ee8228503f970ea602af71ff22216a0"}, {"sha": "a4f21801c54c65eafa337edc5e86de2c46b37544", "url": "https://api.github.com/repos/rust-lang/rust/commits/a4f21801c54c65eafa337edc5e86de2c46b37544", "html_url": "https://github.com/rust-lang/rust/commit/a4f21801c54c65eafa337edc5e86de2c46b37544"}], "stats": {"total": 799, "additions": 370, "deletions": 429}, "files": [{"sha": "b70d005fb9b51d38106ce2eb74e45bee9f810986", "filename": ".github/workflows/ci.yaml", "status": "modified", "additions": 21, "deletions": 30, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/.github%2Fworkflows%2Fci.yaml", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/.github%2Fworkflows%2Fci.yaml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.github%2Fworkflows%2Fci.yaml?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,74 +1,69 @@\n-name: Continuous integration\n-on: [pull_request, push]\n+name: CI\n+on:\n+  pull_request:\n+  push:\n+    branches:\n+      - master\n+      - staging\n \n jobs:\n-  rust-tests:\n-    name: Rust tests\n+  rust:\n+    name: Rust\n     runs-on: ubuntu-latest\n     env:\n       RUSTFLAGS: -D warnings\n       CARGO_INCREMENTAL: 0\n     steps:\n+\n       - name: Checkout repository\n         uses: actions/checkout@v1\n+\n       - name: Install Rust toolchain\n         uses: actions-rs/toolchain@v1\n         with:\n           toolchain: stable\n           profile: minimal\n           override: true\n           components: rustfmt, rust-src\n-      - name: Generate lockfile\n-        uses: actions-rs/cargo@v1\n-        with:\n-          command: generate-lockfile\n+\n       - name: Cargo target cache\n         uses: actions/cache@v1\n         with:\n           path: target\n           key: ${{ runner.os }}-cargo-build-target-${{ hashFiles('**/Cargo.lock') }}\n+\n       - name: Compile\n         uses: actions-rs/cargo@v1\n         with:\n           command: test\n           args: --no-run\n+\n       - name: Test\n         uses: actions-rs/cargo@v1\n         with:\n           command: test\n+\n       - name: Prepare build directory for cache\n         run: |\n           find ./target/debug -maxdepth 1 -type f -delete && \\\n           rm -fr ./target/debug/{deps,.fingerprint}/{*ra_*,*heavy_test*,*gen_lsp*,*thread_worker*} && \\\n           rm -f  ./target/.rustc_info.json\n-  vscode-tests:\n-    name: VS Code tests\n+\n+  type-script:\n+    name: TypeScript\n     runs-on: ubuntu-latest\n     env:\n       CXX: g++-4.9\n       CC: gcc-4.9\n     steps:\n       - name: Checkout repository\n         uses: actions/checkout@v1\n-      - name: Install Rust toolchain\n-        uses: actions-rs/toolchain@v1\n-        with:\n-          toolchain: stable\n-          profile: minimal\n-          override: true\n-      - name: Generate lockfile\n-        uses: actions-rs/cargo@v1\n-        with:\n-          command: generate-lockfile\n-      - name: Cargo target cache\n-        uses: actions/cache@v1\n-        with:\n-          path: target\n-          key: ${{ runner.os }}-cargo-build-target-${{ hashFiles('**/Cargo.lock') }}\n+\n       - name: Install Nodejs\n         uses: actions/setup-node@v1\n         with:\n           node-version: 12.x\n+\n       - name: Install xvfb\n         run: sudo apt-get install xvfb\n       - run: npm ci\n@@ -77,10 +72,6 @@ jobs:\n         working-directory: ./editors/code\n       - run: xvfb-run --auto-servernum npm run travis\n         working-directory: ./editors/code\n+\n       - name: Cleanup xvfb\n         uses: bcomnes/cleanup-xvfb@v1\n-      - name: Prepare build directory for cache\n-        run: |\n-          find ./target/debug -maxdepth 1 -type f -delete && \\\n-          rm -fr ./target/debug/{deps,.fingerprint}/{*ra_*,*heavy_test*,*gen_lsp*,*thread_worker*} && \\\n-          rm -f  ./target/.rustc_info.json"}, {"sha": "caa1dcc30c543e2418352cc7cda316c10a468157", "filename": ".github/workflows/rustdoc.yaml", "status": "added", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/.github%2Fworkflows%2Frustdoc.yaml", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/.github%2Fworkflows%2Frustdoc.yaml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.github%2Fworkflows%2Frustdoc.yaml?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -0,0 +1,39 @@\n+name: rustdoc\n+on:\n+  push:\n+   branches:\n+     - master\n+\n+jobs:\n+  rustdoc:\n+    runs-on: ubuntu-latest\n+    env:\n+      RUSTFLAGS: -D warnings\n+      CARGO_INCREMENTAL: 0\n+\n+    steps:\n+      - name: Checkout repository\n+        uses: actions/checkout@v1\n+\n+      - name: Install Rust toolchain\n+        uses: actions-rs/toolchain@v1\n+        with:\n+          toolchain: stable\n+          profile: minimal\n+          override: true\n+          components: rustfmt, rust-src\n+\n+      - name: Build Documentation\n+        uses: actions-rs/cargo@v1\n+        with:\n+          command: doc\n+          args: --all --no-deps\n+\n+      - name: Deploy Docs\n+        uses: peaceiris/actions-gh-pages@v2.6.0-rc0\n+        env:\n+          ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }}\n+          PUBLISH_BRANCH: gh-pages\n+          PUBLISH_DIR: ./target/doc\n+        with:\n+          forceOrphan: true"}, {"sha": "af71a9ccea2f16306ab5600820a63328985fe85c", "filename": ".travis.yml", "status": "removed", "additions": 0, "deletions": 64, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/aceeb0b85ee8228503f970ea602af71ff22216a0/.travis.yml", "raw_url": "https://github.com/rust-lang/rust/raw/aceeb0b85ee8228503f970ea602af71ff22216a0/.travis.yml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.travis.yml?ref=aceeb0b85ee8228503f970ea602af71ff22216a0", "patch": "@@ -1,64 +0,0 @@\n-cache: cargo\n-before_cache:\n-    - find ./target/debug -maxdepth 1 -type f -delete\n-    - rm -fr ./target/debug/{deps,.fingerprint}/{*ra_*,*heavy_test*,*gen_lsp*,*thread_worker*}\n-    - rm -f  ./target/.rustc_info.json\n-\n-matrix:\n-    include:\n-        - name: \"Rust Tests\"\n-          os: linux\n-          dist: xenial\n-          language: rust\n-          rust: stable\n-          script:\n-              - rustup component add rustfmt\n-              - rustup component add rust-src\n-              - cargo test --no-run  # let's measure compile time separately\n-              - cargo test\n-          env:\n-              - RUSTFLAGS=\"-D warnings\", CARGO_INCREMENTAL=0\n-\n-        - name: \"Rust Docs\"\n-          os: linux\n-          if: branch = master AND type = push\n-          before_script:\n-              - DEPLOY_DOCS=1\n-          language: rust\n-          rust: stable\n-          script:\n-              - cargo doc --all --no-deps\n-          env:\n-              - RUSTFLAGS=\"-D warnings\", CARGO_INCREMENTAL=0\n-\n-        - name: \"VS Code Tests\"\n-          os: linux\n-          language: node_js\n-          dist: xenial\n-          node_js: node\n-          services:\n-            - xvfb\n-          before_install: cd editors/code\n-          install:\n-            - npm ci\n-            - npm run vscode:prepublish\n-          script:\n-            - npm run travis\n-          env:\n-            - CXX=\"g++-4.9\", CC=\"gcc-4.9\"\n-\n-branches:\n-    only:\n-        - staging\n-        - master\n-        - trying\n-\n-deploy:\n-    provider: pages\n-    skip-cleanup: true\n-    github-token: $DOCS_TOKEN  # Set in the settings page of your repository, as a secure variable\n-    keep-history: false\n-    local-dir: target/doc\n-    on:\n-        branch: master\n-        condition: $DEPLOY_DOCS = 1"}, {"sha": "ee7afebcecc172539d2b0df527fad0281dce9f4c", "filename": "README.md", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/README.md", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/README.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/README.md?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,7 +1,5 @@\n # Rust Analyzer\n \n-[![Build Status](https://travis-ci.org/rust-analyzer/rust-analyzer.svg?branch=master)](https://travis-ci.org/rust-analyzer/rust-analyzer)\n-\n Rust Analyzer is an **experimental** modular compiler frontend for the Rust\n language. It is a part of a larger rls-2.0 effort to create excellent IDE\n support for Rust. If you want to get involved, check the rls-2.0 working group\n@@ -58,9 +56,7 @@ https://rust-lang.zulipchat.com/#narrow/stream/185405-t-compiler.2Frls-2.2E0\n \n ## Quick Links\n \n-* Work List: https://paper.dropbox.com/doc/RLS-2.0-work-list--AZ3BgHKKCtqszbsi3gi6sjchAQ-42vbnxzuKq2lKwW0mkn8Y\n * API docs: https://rust-analyzer.github.io/rust-analyzer/ra_ide_api/\n-* CI: https://travis-ci.org/rust-analyzer/rust-analyzer\n \n ## License\n "}, {"sha": "7ffbc92943a54cf781f389e71b26febdc6c2d0ef", "filename": "bors.toml", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/bors.toml", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/bors.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/bors.toml?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,4 +1,2 @@\n-status = [\n-  \"continuous-integration/travis-ci/push\",\n-]\n+status = [\"Rust\", \"TypeScript\"]\n delete_merged_branches = true"}, {"sha": "3c11c8a22814f59e576e4be16d536da518b7f7bb", "filename": "crates/ra_hir_expand/src/db.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Fdb.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -59,10 +59,8 @@ pub trait AstDatabase: SourceDatabase {\n     fn intern_macro(&self, macro_call: MacroCallLoc) -> MacroCallId;\n     fn macro_arg(&self, id: MacroCallId) -> Option<Arc<(tt::Subtree, mbe::TokenMap)>>;\n     fn macro_def(&self, id: MacroDefId) -> Option<Arc<(TokenExpander, mbe::TokenMap)>>;\n-    fn parse_macro(\n-        &self,\n-        macro_file: MacroFile,\n-    ) -> Option<(Parse<SyntaxNode>, Arc<mbe::RevTokenMap>)>;\n+    fn parse_macro(&self, macro_file: MacroFile)\n+        -> Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)>;\n     fn macro_expand(&self, macro_call: MacroCallId) -> Result<Arc<tt::Subtree>, String>;\n }\n \n@@ -136,7 +134,7 @@ pub(crate) fn parse_or_expand(db: &dyn AstDatabase, file_id: HirFileId) -> Optio\n pub(crate) fn parse_macro(\n     db: &dyn AstDatabase,\n     macro_file: MacroFile,\n-) -> Option<(Parse<SyntaxNode>, Arc<mbe::RevTokenMap>)> {\n+) -> Option<(Parse<SyntaxNode>, Arc<mbe::TokenMap>)> {\n     let _p = profile(\"parse_macro_query\");\n \n     let macro_call_id = macro_file.macro_call_id;"}, {"sha": "cfe7e6d15909665eafbb3aef6c93f84373fc9642", "filename": "crates/ra_hir_expand/src/lib.rs", "status": "modified", "additions": 24, "deletions": 31, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Flib.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -20,7 +20,7 @@ use ra_db::{salsa, CrateId, FileId};\n use ra_syntax::{\n     algo,\n     ast::{self, AstNode},\n-    SyntaxNode, SyntaxToken, TextRange, TextUnit,\n+    SyntaxNode, SyntaxToken, TextUnit,\n };\n \n use crate::ast_id_map::FileAstId;\n@@ -79,22 +79,17 @@ impl HirFileId {\n             HirFileIdRepr::MacroFile(macro_file) => {\n                 let loc: MacroCallLoc = db.lookup_intern_macro(macro_file.macro_call_id);\n \n-                let arg_start = loc.ast_id.to_node(db).token_tree()?.syntax().text_range().start();\n-                let def_start =\n-                    loc.def.ast_id.to_node(db).token_tree()?.syntax().text_range().start();\n+                let arg_tt = loc.ast_id.to_node(db).token_tree()?;\n+                let def_tt = loc.def.ast_id.to_node(db).token_tree()?;\n \n                 let macro_def = db.macro_def(loc.def)?;\n                 let (parse, exp_map) = db.parse_macro(macro_file)?;\n-                let expanded = Source::new(self, parse.syntax_node());\n                 let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n \n-                let arg_start = (loc.ast_id.file_id, arg_start);\n-                let def_start = (loc.def.ast_id.file_id, def_start);\n-\n                 Some(ExpansionInfo {\n-                    expanded,\n-                    arg_start,\n-                    def_start,\n+                    expanded: Source::new(self, parse.syntax_node()),\n+                    arg: Source::new(loc.ast_id.file_id, arg_tt),\n+                    def: Source::new(loc.ast_id.file_id, def_tt),\n                     macro_arg,\n                     macro_def,\n                     exp_map,\n@@ -159,18 +154,19 @@ impl MacroCallId {\n #[derive(Debug, Clone, PartialEq, Eq)]\n pub struct ExpansionInfo {\n     expanded: Source<SyntaxNode>,\n-    arg_start: (HirFileId, TextUnit),\n-    def_start: (HirFileId, TextUnit),\n+    arg: Source<ast::TokenTree>,\n+    def: Source<ast::TokenTree>,\n \n     macro_def: Arc<(db::TokenExpander, mbe::TokenMap)>,\n     macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n-    exp_map: Arc<mbe::RevTokenMap>,\n+    exp_map: Arc<mbe::TokenMap>,\n }\n \n impl ExpansionInfo {\n     pub fn map_token_down(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>> {\n-        assert_eq!(token.file_id, self.arg_start.0);\n-        let range = token.ast.text_range().checked_sub(self.arg_start.1)?;\n+        assert_eq!(token.file_id, self.arg.file_id);\n+        let range =\n+            token.ast.text_range().checked_sub(self.arg.ast.syntax().text_range().start())?;\n         let token_id = self.macro_arg.1.token_by_range(range)?;\n         let token_id = self.macro_def.0.map_id_down(token_id);\n \n@@ -181,25 +177,22 @@ impl ExpansionInfo {\n         Some(self.expanded.with_ast(token))\n     }\n \n-    // FIXME: a more correct signature would be\n-    // `pub fn map_token_up(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>>`\n-    pub fn find_range(&self, from: TextRange) -> Option<(HirFileId, TextRange)> {\n-        let token_id = look_in_rev_map(&self.exp_map, from)?;\n+    pub fn map_token_up(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>> {\n+        let token_id = self.exp_map.token_by_range(token.ast.text_range())?;\n \n         let (token_id, origin) = self.macro_def.0.map_id_up(token_id);\n-\n-        let (token_map, (file_id, start_offset)) = match origin {\n-            mbe::Origin::Call => (&self.macro_arg.1, self.arg_start),\n-            mbe::Origin::Def => (&self.macro_def.1, self.def_start),\n+        let (token_map, tt) = match origin {\n+            mbe::Origin::Call => (&self.macro_arg.1, &self.arg),\n+            mbe::Origin::Def => (&self.macro_def.1, &self.def),\n         };\n \n-        let range = token_map.relative_range_of(token_id)?;\n-\n-        return Some((file_id, range + start_offset));\n-\n-        fn look_in_rev_map(exp_map: &mbe::RevTokenMap, from: TextRange) -> Option<tt::TokenId> {\n-            exp_map.ranges.iter().find(|&it| it.0.is_subrange(&from)).map(|it| it.1)\n-        }\n+        let range = token_map.range_by_token(token_id)?;\n+        let token = algo::find_covering_element(\n+            tt.ast.syntax(),\n+            range + tt.ast.syntax().text_range().start(),\n+        )\n+        .into_token()?;\n+        Some(tt.with_ast(token))\n     }\n }\n "}, {"sha": "b30ef8e054b70d3bf9d4c2dab0b7394727c20f51", "filename": "crates/ra_ide_api/src/display/navigation_target.rs", "status": "modified", "additions": 44, "deletions": 55, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fdisplay%2Fnavigation_target.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fdisplay%2Fnavigation_target.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fdisplay%2Fnavigation_target.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,16 +1,17 @@\n //! FIXME: write short doc here\n \n-use hir::{AssocItem, Either, FieldSource, HasSource, ModuleSource};\n+use hir::{AssocItem, Either, FieldSource, HasSource, ModuleSource, Source};\n use ra_db::{FileId, SourceDatabase};\n use ra_syntax::{\n     ast::{self, DocCommentsOwner, NameOwner},\n     match_ast, AstNode, SmolStr,\n     SyntaxKind::{self, BIND_PAT},\n-    SyntaxNode, TextRange,\n+    TextRange,\n };\n \n+use crate::{db::RootDatabase, expand::original_range, FileSymbol};\n+\n use super::short_label::ShortLabel;\n-use crate::{db::RootDatabase, FileSymbol};\n \n /// `NavigationTarget` represents and element in the editor's UI which you can\n /// click on to navigate to a particular piece of code.\n@@ -79,13 +80,13 @@ impl NavigationTarget {\n     pub(crate) fn from_module_to_decl(db: &RootDatabase, module: hir::Module) -> NavigationTarget {\n         let name = module.name(db).map(|it| it.to_string().into()).unwrap_or_default();\n         if let Some(src) = module.declaration_source(db) {\n-            let (file_id, text_range) = find_range_from_node(db, src.file_id, src.ast.syntax());\n+            let frange = original_range(db, src.as_ref().map(|it| it.syntax()));\n             return NavigationTarget::from_syntax(\n-                file_id,\n+                frange.file_id,\n                 name,\n                 None,\n-                text_range,\n-                src.ast.syntax(),\n+                frange.range,\n+                src.ast.syntax().kind(),\n                 src.ast.doc_comment_text(),\n                 src.ast.short_label(),\n             );\n@@ -140,22 +141,22 @@ impl NavigationTarget {\n     /// Allows `NavigationTarget` to be created from a `NameOwner`\n     pub(crate) fn from_named(\n         db: &RootDatabase,\n-        file_id: hir::HirFileId,\n-        node: &impl ast::NameOwner,\n+        node: Source<&dyn ast::NameOwner>,\n         docs: Option<String>,\n         description: Option<String>,\n     ) -> NavigationTarget {\n         //FIXME: use `_` instead of empty string\n-        let name = node.name().map(|it| it.text().clone()).unwrap_or_default();\n-        let focus_range = node.name().map(|it| find_range_from_node(db, file_id, it.syntax()).1);\n-        let (file_id, full_range) = find_range_from_node(db, file_id, node.syntax());\n+        let name = node.ast.name().map(|it| it.text().clone()).unwrap_or_default();\n+        let focus_range =\n+            node.ast.name().map(|it| original_range(db, node.with_ast(it.syntax())).range);\n+        let frange = original_range(db, node.map(|it| it.syntax()));\n \n         NavigationTarget::from_syntax(\n-            file_id,\n+            frange.file_id,\n             name,\n             focus_range,\n-            full_range,\n-            node.syntax(),\n+            frange.range,\n+            node.ast.syntax().kind(),\n             docs,\n             description,\n         )\n@@ -166,14 +167,14 @@ impl NavigationTarget {\n         name: SmolStr,\n         focus_range: Option<TextRange>,\n         full_range: TextRange,\n-        node: &SyntaxNode,\n+        kind: SyntaxKind,\n         docs: Option<String>,\n         description: Option<String>,\n     ) -> NavigationTarget {\n         NavigationTarget {\n             file_id,\n             name,\n-            kind: node.kind(),\n+            kind,\n             full_range,\n             focus_range,\n             container_name: None,\n@@ -218,8 +219,7 @@ where\n         let src = self.source(db);\n         NavigationTarget::from_named(\n             db,\n-            src.file_id,\n-            &src.ast,\n+            src.as_ref().map(|it| it as &dyn ast::NameOwner),\n             src.ast.doc_comment_text(),\n             src.ast.short_label(),\n         )\n@@ -230,29 +230,29 @@ impl ToNav for hir::Module {\n     fn to_nav(&self, db: &RootDatabase) -> NavigationTarget {\n         let src = self.definition_source(db);\n         let name = self.name(db).map(|it| it.to_string().into()).unwrap_or_default();\n-        match src.ast {\n+        match &src.ast {\n             ModuleSource::SourceFile(node) => {\n-                let (file_id, text_range) = find_range_from_node(db, src.file_id, node.syntax());\n+                let frange = original_range(db, src.with_ast(node.syntax()));\n \n                 NavigationTarget::from_syntax(\n-                    file_id,\n+                    frange.file_id,\n                     name,\n                     None,\n-                    text_range,\n-                    node.syntax(),\n+                    frange.range,\n+                    node.syntax().kind(),\n                     None,\n                     None,\n                 )\n             }\n             ModuleSource::Module(node) => {\n-                let (file_id, text_range) = find_range_from_node(db, src.file_id, node.syntax());\n+                let frange = original_range(db, src.with_ast(node.syntax()));\n \n                 NavigationTarget::from_syntax(\n-                    file_id,\n+                    frange.file_id,\n                     name,\n                     None,\n-                    text_range,\n-                    node.syntax(),\n+                    frange.range,\n+                    node.syntax().kind(),\n                     node.doc_comment_text(),\n                     node.short_label(),\n                 )\n@@ -264,14 +264,14 @@ impl ToNav for hir::Module {\n impl ToNav for hir::ImplBlock {\n     fn to_nav(&self, db: &RootDatabase) -> NavigationTarget {\n         let src = self.source(db);\n-        let (file_id, text_range) = find_range_from_node(db, src.file_id, src.ast.syntax());\n+        let frange = original_range(db, src.as_ref().map(|it| it.syntax()));\n \n         NavigationTarget::from_syntax(\n-            file_id,\n+            frange.file_id,\n             \"impl\".into(),\n             None,\n-            text_range,\n-            src.ast.syntax(),\n+            frange.range,\n+            src.ast.syntax().kind(),\n             None,\n             None,\n         )\n@@ -282,22 +282,21 @@ impl ToNav for hir::StructField {\n     fn to_nav(&self, db: &RootDatabase) -> NavigationTarget {\n         let src = self.source(db);\n \n-        match src.ast {\n+        match &src.ast {\n             FieldSource::Named(it) => NavigationTarget::from_named(\n                 db,\n-                src.file_id,\n-                &it,\n+                src.with_ast(it),\n                 it.doc_comment_text(),\n                 it.short_label(),\n             ),\n             FieldSource::Pos(it) => {\n-                let (file_id, text_range) = find_range_from_node(db, src.file_id, it.syntax());\n+                let frange = original_range(db, src.with_ast(it.syntax()));\n                 NavigationTarget::from_syntax(\n-                    file_id,\n+                    frange.file_id,\n                     \"\".into(),\n                     None,\n-                    text_range,\n-                    it.syntax(),\n+                    frange.range,\n+                    it.syntax().kind(),\n                     None,\n                     None,\n                 )\n@@ -310,7 +309,12 @@ impl ToNav for hir::MacroDef {\n     fn to_nav(&self, db: &RootDatabase) -> NavigationTarget {\n         let src = self.source(db);\n         log::debug!(\"nav target {:#?}\", src.ast.syntax());\n-        NavigationTarget::from_named(db, src.file_id, &src.ast, src.ast.doc_comment_text(), None)\n+        NavigationTarget::from_named(\n+            db,\n+            src.as_ref().map(|it| it as &dyn ast::NameOwner),\n+            src.ast.doc_comment_text(),\n+            None,\n+        )\n     }\n }\n \n@@ -360,21 +364,6 @@ impl ToNav for hir::Local {\n     }\n }\n \n-fn find_range_from_node(\n-    db: &RootDatabase,\n-    src: hir::HirFileId,\n-    node: &SyntaxNode,\n-) -> (FileId, TextRange) {\n-    let text_range = node.text_range();\n-    let (file_id, text_range) = src\n-        .expansion_info(db)\n-        .and_then(|expansion_info| expansion_info.find_range(text_range))\n-        .unwrap_or((src, text_range));\n-\n-    // FIXME: handle recursive macro generated macro\n-    (file_id.original_file(db), text_range)\n-}\n-\n pub(crate) fn docs_from_symbol(db: &RootDatabase, symbol: &FileSymbol) -> Option<String> {\n     let parse = db.parse(symbol.file_id);\n     let node = symbol.ptr.to_node(parse.tree().syntax());"}, {"sha": "7f59e46d26bd390de6931f43646f5e0a0fb2566b", "filename": "crates/ra_ide_api/src/expand.rs", "status": "added", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -0,0 +1,59 @@\n+//! Utilities to work with files, produced by macros.\n+use std::iter::successors;\n+\n+use hir::Source;\n+use ra_db::FileId;\n+use ra_syntax::{ast, AstNode, SyntaxNode, SyntaxToken};\n+\n+use crate::{db::RootDatabase, FileRange};\n+\n+pub(crate) fn original_range(db: &RootDatabase, node: Source<&SyntaxNode>) -> FileRange {\n+    let expansion = match node.file_id.expansion_info(db) {\n+        None => {\n+            return FileRange {\n+                file_id: node.file_id.original_file(db),\n+                range: node.ast.text_range(),\n+            }\n+        }\n+        Some(it) => it,\n+    };\n+    // FIXME: the following completely wrong.\n+    //\n+    // *First*, we should try to map first and last tokens of node, and, if that\n+    // fails, return the range of the overall macro expansions.\n+    //\n+    // *Second*, we should handle recurside macro expansions\n+\n+    let token = node\n+        .ast\n+        .descendants_with_tokens()\n+        .filter_map(|it| it.into_token())\n+        .find_map(|it| expansion.map_token_up(node.with_ast(&it)));\n+\n+    match token {\n+        Some(it) => FileRange { file_id: it.file_id.original_file(db), range: it.ast.text_range() },\n+        None => FileRange { file_id: node.file_id.original_file(db), range: node.ast.text_range() },\n+    }\n+}\n+\n+pub(crate) fn descend_into_macros(\n+    db: &RootDatabase,\n+    file_id: FileId,\n+    token: SyntaxToken,\n+) -> Source<SyntaxToken> {\n+    let src = Source::new(file_id.into(), token);\n+\n+    successors(Some(src), |token| {\n+        let macro_call = token.ast.ancestors().find_map(ast::MacroCall::cast)?;\n+        let tt = macro_call.token_tree()?;\n+        if !token.ast.text_range().is_subrange(&tt.syntax().text_range()) {\n+            return None;\n+        }\n+        let source_analyzer =\n+            hir::SourceAnalyzer::new(db, token.with_ast(token.ast.parent()).as_ref(), None);\n+        let exp = source_analyzer.expand(db, &macro_call)?;\n+        exp.map_token_down(db, token.as_ref())\n+    })\n+    .last()\n+    .unwrap()\n+}"}, {"sha": "3f16e9566134388cc53b54a4aeb1ea30d01b5ab0", "filename": "crates/ra_ide_api/src/goto_definition.rs", "status": "modified", "additions": 16, "deletions": 44, "changes": 60, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fgoto_definition.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,16 +1,15 @@\n //! FIXME: write short doc here\n \n-use std::iter::successors;\n-\n use hir::{db::AstDatabase, Source};\n use ra_syntax::{\n     ast::{self, DocCommentsOwner},\n-    match_ast, AstNode, SyntaxNode, SyntaxToken,\n+    match_ast, AstNode, SyntaxNode,\n };\n \n use crate::{\n     db::RootDatabase,\n     display::{ShortLabel, ToNav},\n+    expand::descend_into_macros,\n     references::{classify_name_ref, NameKind::*},\n     FilePosition, NavigationTarget, RangeInfo,\n };\n@@ -19,7 +18,9 @@ pub(crate) fn goto_definition(\n     db: &RootDatabase,\n     position: FilePosition,\n ) -> Option<RangeInfo<Vec<NavigationTarget>>> {\n-    let token = descend_into_macros(db, position)?;\n+    let file = db.parse_or_expand(position.file_id.into())?;\n+    let token = file.token_at_offset(position.offset).filter(|it| !it.kind().is_trivia()).next()?;\n+    let token = descend_into_macros(db, position.file_id, token);\n \n     let res = match_ast! {\n         match (token.ast.parent()) {\n@@ -39,24 +40,6 @@ pub(crate) fn goto_definition(\n     Some(res)\n }\n \n-fn descend_into_macros(db: &RootDatabase, position: FilePosition) -> Option<Source<SyntaxToken>> {\n-    let file = db.parse_or_expand(position.file_id.into())?;\n-    let token = file.token_at_offset(position.offset).filter(|it| !it.kind().is_trivia()).next()?;\n-\n-    successors(Some(Source::new(position.file_id.into(), token)), |token| {\n-        let macro_call = token.ast.ancestors().find_map(ast::MacroCall::cast)?;\n-        let tt = macro_call.token_tree()?;\n-        if !token.ast.text_range().is_subrange(&tt.syntax().text_range()) {\n-            return None;\n-        }\n-        let source_analyzer =\n-            hir::SourceAnalyzer::new(db, token.with_ast(token.ast.parent()).as_ref(), None);\n-        let exp = source_analyzer.expand(db, &macro_call)?;\n-        exp.map_token_down(db, token.as_ref())\n-    })\n-    .last()\n-}\n-\n #[derive(Debug)]\n pub(crate) enum ReferenceResult {\n     Exact(NavigationTarget),\n@@ -137,98 +120,87 @@ fn named_target(db: &RootDatabase, node: Source<&SyntaxNode>) -> Option<Navigati\n             ast::StructDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::EnumDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::EnumVariant(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::FnDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::TypeAliasDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::ConstDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::StaticDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::TraitDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::RecordFieldDef(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::Module(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     it.short_label(),\n                 ))\n             },\n             ast::MacroCall(it) => {\n                 Some(NavigationTarget::from_named(\n                     db,\n-                    node.file_id,\n-                    &it,\n+                    node.with_ast(&it),\n                     it.doc_comment_text(),\n                     None,\n                 ))"}, {"sha": "c6d678c0c7d02de799ee481de3c493368372d89f", "filename": "crates/ra_ide_api/src/hover.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fhover.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fhover.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fhover.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -193,7 +193,9 @@ pub(crate) fn hover(db: &RootDatabase, position: FilePosition) -> Option<RangeIn\n             None\n         }\n     } else if let Some(name) = find_node_at_offset::<ast::Name>(file.syntax(), position.offset) {\n-        if let Some(name_kind) = classify_name(db, position.file_id, &name).map(|d| d.kind) {\n+        if let Some(name_kind) =\n+            classify_name(db, Source::new(position.file_id.into(), &name)).map(|d| d.kind)\n+        {\n             let mut _b: bool = true;\n             res.extend(hover_text_from_name_kind(db, name_kind, &mut _b));\n         }"}, {"sha": "110ddcd6265020d7d753a0f5db40e6f825d7cfcf", "filename": "crates/ra_ide_api/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Flib.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -41,6 +41,7 @@ mod matching_brace;\n mod display;\n mod inlay_hints;\n mod wasm_shims;\n+mod expand;\n \n #[cfg(test)]\n mod marks;"}, {"sha": "cb343e59a093215b84d741a63171ea7ceac968dd", "filename": "crates/ra_ide_api/src/references.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Freferences.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Freferences.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Freferences.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -110,7 +110,7 @@ fn find_name<'a>(\n     position: FilePosition,\n ) -> Option<RangeInfo<(String, NameDefinition)>> {\n     if let Some(name) = find_node_at_offset::<ast::Name>(&syntax, position.offset) {\n-        let def = classify_name(db, position.file_id, &name)?;\n+        let def = classify_name(db, Source::new(position.file_id.into(), &name))?;\n         let range = name.syntax().text_range();\n         return Some(RangeInfo::new(range, (name.text().to_string(), def)));\n     }"}, {"sha": "ea9d20e715acca43446aa109d242d7172a6a9c57", "filename": "crates/ra_ide_api/src/references/classify.rs", "status": "modified", "additions": 16, "deletions": 22, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Freferences%2Fclassify.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Freferences%2Fclassify.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Freferences%2Fclassify.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1,7 +1,6 @@\n //! Functions that are used to classify an element from its definition or reference.\n \n use hir::{FromSource, Module, ModuleSource, Path, PathResolution, Source, SourceAnalyzer};\n-use ra_db::FileId;\n use ra_prof::profile;\n use ra_syntax::{ast, match_ast, AstNode};\n use test_utils::tested_by;\n@@ -12,19 +11,14 @@ use super::{\n };\n use crate::db::RootDatabase;\n \n-pub(crate) fn classify_name(\n-    db: &RootDatabase,\n-    file_id: FileId,\n-    name: &ast::Name,\n-) -> Option<NameDefinition> {\n+pub(crate) fn classify_name(db: &RootDatabase, name: Source<&ast::Name>) -> Option<NameDefinition> {\n     let _p = profile(\"classify_name\");\n-    let parent = name.syntax().parent()?;\n-    let file_id = file_id.into();\n+    let parent = name.ast.syntax().parent()?;\n \n     match_ast! {\n         match parent {\n             ast::BindPat(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let local = hir::Local::from_source(db, src)?;\n                 Some(NameDefinition {\n                     visibility: None,\n@@ -34,50 +28,50 @@ pub(crate) fn classify_name(\n             },\n             ast::RecordFieldDef(it) => {\n                 let ast = hir::FieldSource::Named(it);\n-                let src = hir::Source { file_id, ast };\n+                let src = name.with_ast(ast);\n                 let field = hir::StructField::from_source(db, src)?;\n                 Some(from_struct_field(db, field))\n             },\n             ast::Module(it) => {\n                 let def = {\n                     if !it.has_semi() {\n                         let ast = hir::ModuleSource::Module(it);\n-                        let src = hir::Source { file_id, ast };\n+                        let src = name.with_ast(ast);\n                         hir::Module::from_definition(db, src)\n                     } else {\n-                        let src = hir::Source { file_id, ast: it };\n+                        let src = name.with_ast(it);\n                         hir::Module::from_declaration(db, src)\n                     }\n                 }?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::StructDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Struct::from_source(db, src)?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::EnumDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Enum::from_source(db, src)?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::TraitDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Trait::from_source(db, src)?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::StaticDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Static::from_source(db, src)?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::EnumVariant(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::EnumVariant::from_source(db, src)?;\n                 Some(from_module_def(db, def.into(), None))\n             },\n             ast::FnDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Function::from_source(db, src)?;\n                 if parent.parent().and_then(ast::ItemList::cast).is_some() {\n                     Some(from_assoc_item(db, def.into()))\n@@ -86,7 +80,7 @@ pub(crate) fn classify_name(\n                 }\n             },\n             ast::ConstDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::Const::from_source(db, src)?;\n                 if parent.parent().and_then(ast::ItemList::cast).is_some() {\n                     Some(from_assoc_item(db, def.into()))\n@@ -95,7 +89,7 @@ pub(crate) fn classify_name(\n                 }\n             },\n             ast::TypeAliasDef(it) => {\n-                let src = hir::Source { file_id, ast: it };\n+                let src = name.with_ast(it);\n                 let def = hir::TypeAlias::from_source(db, src)?;\n                 if parent.parent().and_then(ast::ItemList::cast).is_some() {\n                     Some(from_assoc_item(db, def.into()))\n@@ -104,11 +98,11 @@ pub(crate) fn classify_name(\n                 }\n             },\n             ast::MacroCall(it) => {\n-                let src = hir::Source { file_id, ast: it};\n+                let src = name.with_ast(it);\n                 let def = hir::MacroDef::from_source(db, src.clone())?;\n \n                 let module_src = ModuleSource::from_child_node(db, src.as_ref().map(|it| it.syntax()));\n-                let module = Module::from_definition(db, Source::new(file_id, module_src))?;\n+                let module = Module::from_definition(db, src.with_ast(module_src))?;\n \n                 Some(NameDefinition {\n                     visibility: None,"}, {"sha": "2b653fe8fa2bfdf8f69c63117c3fd2faad3b8a26", "filename": "crates/ra_ide_api/src/syntax_highlighting.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -94,7 +94,8 @@ pub(crate) fn highlight(db: &RootDatabase, file_id: FileId) -> Vec<HighlightedRa\n             }\n             NAME => {\n                 let name = node.as_node().cloned().and_then(ast::Name::cast).unwrap();\n-                let name_kind = classify_name(db, file_id, &name).map(|d| d.kind);\n+                let name_kind =\n+                    classify_name(db, Source::new(file_id.into(), &name)).map(|d| d.kind);\n \n                 if let Some(Local(local)) = &name_kind {\n                     if let Some(name) = local.name(db) {"}, {"sha": "bbddebe67f4be9bc14b8e888d29202d7acb9177e", "filename": "crates/ra_mbe/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_mbe%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_mbe%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Flib.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -31,7 +31,7 @@ pub enum ExpandError {\n }\n \n pub use crate::syntax_bridge::{\n-    ast_to_token_tree, syntax_node_to_token_tree, token_tree_to_syntax_node, RevTokenMap, TokenMap,\n+    ast_to_token_tree, syntax_node_to_token_tree, token_tree_to_syntax_node, TokenMap,\n };\n \n /// This struct contains AST for a single `macro_rules` definition. What might"}, {"sha": "d1c49c0b3f37439d496806c15c82fff8ee7d3c67", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 99, "deletions": 107, "changes": 206, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -14,30 +14,22 @@ use crate::ExpandError;\n #[derive(Debug, PartialEq, Eq, Default)]\n pub struct TokenMap {\n     /// Maps `tt::TokenId` to the *relative* source range.\n-    tokens: Vec<TextRange>,\n-}\n-\n-/// Maps relative range of the expanded syntax node to `tt::TokenId`\n-#[derive(Debug, PartialEq, Eq, Default)]\n-pub struct RevTokenMap {\n-    pub ranges: Vec<(TextRange, tt::TokenId)>,\n+    entries: Vec<(tt::TokenId, TextRange)>,\n }\n \n /// Convert the syntax tree (what user has written) to a `TokenTree` (what macro\n /// will consume).\n pub fn ast_to_token_tree(ast: &ast::TokenTree) -> Option<(tt::Subtree, TokenMap)> {\n-    let mut token_map = TokenMap::default();\n-    let node = ast.syntax();\n-    let tt = convert_tt(&mut token_map, node.text_range().start(), node)?;\n-    Some((tt, token_map))\n+    syntax_node_to_token_tree(ast.syntax())\n }\n \n /// Convert the syntax node to a `TokenTree` (what macro\n /// will consume).\n pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> Option<(tt::Subtree, TokenMap)> {\n-    let mut token_map = TokenMap::default();\n-    let tt = convert_tt(&mut token_map, node.text_range().start(), node)?;\n-    Some((tt, token_map))\n+    let global_offset = node.text_range().start();\n+    let mut c = Convertor { map: TokenMap::default(), global_offset, next_id: 0 };\n+    let subtree = c.go(node)?;\n+    Some((subtree, c.map))\n }\n \n // The following items are what `rustc` macro can be parsed into :\n@@ -55,7 +47,7 @@ pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> Option<(tt::Subtree, Toke\n pub fn token_tree_to_syntax_node(\n     tt: &tt::Subtree,\n     fragment_kind: FragmentKind,\n-) -> Result<(Parse<SyntaxNode>, RevTokenMap), ExpandError> {\n+) -> Result<(Parse<SyntaxNode>, TokenMap), ExpandError> {\n     let tmp;\n     let tokens = match tt {\n         tt::Subtree { delimiter: tt::Delimiter::None, token_trees } => token_trees.as_slice(),\n@@ -78,31 +70,17 @@ pub fn token_tree_to_syntax_node(\n \n impl TokenMap {\n     pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n-        let (idx, _) =\n-            self.tokens.iter().enumerate().find(|(_, range)| **range == relative_range)?;\n-        Some(tt::TokenId(idx as u32))\n-    }\n-\n-    pub fn relative_range_of(&self, token_id: tt::TokenId) -> Option<TextRange> {\n-        let idx = token_id.0 as usize;\n-        self.tokens.get(idx).copied()\n-    }\n-\n-    fn alloc(&mut self, relative_range: TextRange) -> tt::TokenId {\n-        let id = self.tokens.len();\n-        self.tokens.push(relative_range);\n-        tt::TokenId(id as u32)\n+        let &(token_id, _) = self.entries.iter().find(|(_, range)| *range == relative_range)?;\n+        Some(token_id)\n     }\n-}\n \n-impl RevTokenMap {\n     pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TextRange> {\n-        let &(r, _) = self.ranges.iter().find(|(_, tid)| *tid == token_id)?;\n-        Some(r)\n+        let &(_, range) = self.entries.iter().find(|(tid, _)| *tid == token_id)?;\n+        Some(range)\n     }\n \n-    fn add(&mut self, relative_range: TextRange, token_id: tt::TokenId) {\n-        self.ranges.push((relative_range, token_id.clone()))\n+    fn insert(&mut self, token_id: tt::TokenId, relative_range: TextRange) {\n+        self.entries.push((token_id, relative_range));\n     }\n }\n \n@@ -167,92 +145,106 @@ fn convert_doc_comment(token: &ra_syntax::SyntaxToken) -> Option<Vec<tt::TokenTr\n     }\n }\n \n-fn convert_tt(\n-    token_map: &mut TokenMap,\n+struct Convertor {\n+    map: TokenMap,\n     global_offset: TextUnit,\n-    tt: &SyntaxNode,\n-) -> Option<tt::Subtree> {\n-    // This tree is empty\n-    if tt.first_child_or_token().is_none() {\n-        return Some(tt::Subtree { token_trees: vec![], delimiter: tt::Delimiter::None });\n-    }\n+    next_id: u32,\n+}\n \n-    let first_child = tt.first_child_or_token()?;\n-    let last_child = tt.last_child_or_token()?;\n-    let (delimiter, skip_first) = match (first_child.kind(), last_child.kind()) {\n-        (T!['('], T![')']) => (tt::Delimiter::Parenthesis, true),\n-        (T!['{'], T!['}']) => (tt::Delimiter::Brace, true),\n-        (T!['['], T![']']) => (tt::Delimiter::Bracket, true),\n-        _ => (tt::Delimiter::None, false),\n-    };\n+impl Convertor {\n+    fn go(&mut self, tt: &SyntaxNode) -> Option<tt::Subtree> {\n+        // This tree is empty\n+        if tt.first_child_or_token().is_none() {\n+            return Some(tt::Subtree { token_trees: vec![], delimiter: tt::Delimiter::None });\n+        }\n \n-    let mut token_trees = Vec::new();\n-    let mut child_iter = tt.children_with_tokens().skip(skip_first as usize).peekable();\n+        let first_child = tt.first_child_or_token()?;\n+        let last_child = tt.last_child_or_token()?;\n+        let (delimiter, skip_first) = match (first_child.kind(), last_child.kind()) {\n+            (T!['('], T![')']) => (tt::Delimiter::Parenthesis, true),\n+            (T!['{'], T!['}']) => (tt::Delimiter::Brace, true),\n+            (T!['['], T![']']) => (tt::Delimiter::Bracket, true),\n+            _ => (tt::Delimiter::None, false),\n+        };\n \n-    while let Some(child) = child_iter.next() {\n-        if skip_first && (child == first_child || child == last_child) {\n-            continue;\n-        }\n+        let mut token_trees = Vec::new();\n+        let mut child_iter = tt.children_with_tokens().skip(skip_first as usize).peekable();\n \n-        match child {\n-            NodeOrToken::Token(token) => {\n-                if let Some(doc_tokens) = convert_doc_comment(&token) {\n-                    token_trees.extend(doc_tokens);\n-                } else if token.kind().is_trivia() {\n-                    continue;\n-                } else if token.kind().is_punct() {\n-                    assert!(token.text().len() == 1, \"Input ast::token punct must be single char.\");\n-                    let char = token.text().chars().next().unwrap();\n-\n-                    let spacing = match child_iter.peek() {\n-                        Some(NodeOrToken::Token(token)) => {\n-                            if token.kind().is_punct() {\n-                                tt::Spacing::Joint\n-                            } else {\n-                                tt::Spacing::Alone\n+        while let Some(child) = child_iter.next() {\n+            if skip_first && (child == first_child || child == last_child) {\n+                continue;\n+            }\n+\n+            match child {\n+                NodeOrToken::Token(token) => {\n+                    if let Some(doc_tokens) = convert_doc_comment(&token) {\n+                        token_trees.extend(doc_tokens);\n+                    } else if token.kind().is_trivia() {\n+                        continue;\n+                    } else if token.kind().is_punct() {\n+                        assert!(\n+                            token.text().len() == 1,\n+                            \"Input ast::token punct must be single char.\"\n+                        );\n+                        let char = token.text().chars().next().unwrap();\n+\n+                        let spacing = match child_iter.peek() {\n+                            Some(NodeOrToken::Token(token)) => {\n+                                if token.kind().is_punct() {\n+                                    tt::Spacing::Joint\n+                                } else {\n+                                    tt::Spacing::Alone\n+                                }\n                             }\n-                        }\n-                        _ => tt::Spacing::Alone,\n-                    };\n-\n-                    token_trees.push(tt::Leaf::from(tt::Punct { char, spacing }).into());\n-                } else {\n-                    let child: tt::TokenTree =\n-                        if token.kind() == T![true] || token.kind() == T![false] {\n-                            tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n-                        } else if token.kind().is_keyword()\n-                            || token.kind() == IDENT\n-                            || token.kind() == LIFETIME\n-                        {\n-                            let relative_range = token.text_range() - global_offset;\n-                            let id = token_map.alloc(relative_range);\n-                            let text = token.text().clone();\n-                            tt::Leaf::from(tt::Ident { text, id }).into()\n-                        } else if token.kind().is_literal() {\n-                            tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n-                        } else {\n-                            return None;\n+                            _ => tt::Spacing::Alone,\n                         };\n+\n+                        token_trees.push(tt::Leaf::from(tt::Punct { char, spacing }).into());\n+                    } else {\n+                        let child: tt::TokenTree =\n+                            if token.kind() == T![true] || token.kind() == T![false] {\n+                                tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n+                            } else if token.kind().is_keyword()\n+                                || token.kind() == IDENT\n+                                || token.kind() == LIFETIME\n+                            {\n+                                let id = self.alloc(token.text_range());\n+                                let text = token.text().clone();\n+                                tt::Leaf::from(tt::Ident { text, id }).into()\n+                            } else if token.kind().is_literal() {\n+                                tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n+                            } else {\n+                                return None;\n+                            };\n+                        token_trees.push(child);\n+                    }\n+                }\n+                NodeOrToken::Node(node) => {\n+                    let child = self.go(&node)?.into();\n                     token_trees.push(child);\n                 }\n-            }\n-            NodeOrToken::Node(node) => {\n-                let child = convert_tt(token_map, global_offset, &node)?.into();\n-                token_trees.push(child);\n-            }\n-        };\n+            };\n+        }\n+\n+        let res = tt::Subtree { delimiter, token_trees };\n+        Some(res)\n     }\n \n-    let res = tt::Subtree { delimiter, token_trees };\n-    Some(res)\n+    fn alloc(&mut self, absolute_range: TextRange) -> tt::TokenId {\n+        let relative_range = absolute_range - self.global_offset;\n+        let token_id = tt::TokenId(self.next_id);\n+        self.next_id += 1;\n+        self.map.insert(token_id, relative_range);\n+        token_id\n+    }\n }\n \n struct TtTreeSink<'a> {\n     buf: String,\n     cursor: Cursor<'a>,\n     text_pos: TextUnit,\n     inner: SyntaxTreeBuilder,\n-    range_map: RevTokenMap,\n+    token_map: TokenMap,\n \n     // Number of roots\n     // Use for detect ill-form tree which is not single root\n@@ -267,12 +259,12 @@ impl<'a> TtTreeSink<'a> {\n             text_pos: 0.into(),\n             inner: SyntaxTreeBuilder::default(),\n             roots: smallvec::SmallVec::new(),\n-            range_map: RevTokenMap::default(),\n+            token_map: TokenMap::default(),\n         }\n     }\n \n-    fn finish(self) -> (Parse<SyntaxNode>, RevTokenMap) {\n-        (self.inner.finish(), self.range_map)\n+    fn finish(self) -> (Parse<SyntaxNode>, TokenMap) {\n+        (self.inner.finish(), self.token_map)\n     }\n }\n \n@@ -308,7 +300,7 @@ impl<'a> TreeSink for TtTreeSink<'a> {\n                         if kind == IDENT {\n                             let range =\n                                 TextRange::offset_len(self.text_pos, TextUnit::of_str(&ident.text));\n-                            self.range_map.add(range, ident.id);\n+                            self.token_map.insert(ident.id, range);\n                         }\n                     }\n "}, {"sha": "761b2435cc737c22c8c5f4162e46cbc997e03239", "filename": "crates/ra_syntax/src/ast/extensions.rs", "status": "modified", "additions": 1, "deletions": 11, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fast%2Fextensions.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fast%2Fextensions.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fast%2Fextensions.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -2,7 +2,7 @@\n //! Extensions for various expressions live in a sibling `expr_extensions` module.\n \n use crate::{\n-    ast::{self, child_opt, children, AstChildren, AstNode, AttrInput, SyntaxNode},\n+    ast::{self, child_opt, children, AstNode, AttrInput, SyntaxNode},\n     SmolStr, SyntaxElement,\n     SyntaxKind::*,\n     SyntaxToken, T,\n@@ -176,16 +176,6 @@ impl ast::ImplBlock {\n     }\n }\n \n-impl ast::AttrsOwner for ast::ImplItem {\n-    fn attrs(&self) -> AstChildren<ast::Attr> {\n-        match self {\n-            ast::ImplItem::FnDef(it) => it.attrs(),\n-            ast::ImplItem::TypeAliasDef(it) => it.attrs(),\n-            ast::ImplItem::ConstDef(it) => it.attrs(),\n-        }\n-    }\n-}\n-\n #[derive(Debug, Clone, PartialEq, Eq)]\n pub enum StructKind {\n     Tuple(ast::TupleFieldDefList),"}, {"sha": "2b381dcdba2aaf29e45edf0d54a2a75b7d66bf46", "filename": "crates/ra_syntax/src/ast/generated.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -1298,6 +1298,7 @@ impl AstNode for ImplItem {\n         }\n     }\n }\n+impl ast::AttrsOwner for ImplItem {}\n impl ImplItem {}\n #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n pub struct ImplTraitType {"}, {"sha": "70d85a8e6a6542d71e009136177ae806092dbccc", "filename": "crates/ra_syntax/src/grammar.ron", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -401,7 +401,8 @@ Grammar(\n             traits: [\"AttrsOwner\"]\n         ),\n         \"ImplItem\": (\n-            enum: [\"FnDef\", \"TypeAliasDef\", \"ConstDef\"]\n+            enum: [\"FnDef\", \"TypeAliasDef\", \"ConstDef\"],\n+            traits: [\"AttrsOwner\"]\n         ),\n \n         \"TupleExpr\": ("}, {"sha": "0823ca09ab1a1c56e0eafc48c5e45f7405e29a46", "filename": "docs/dev/README.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/docs%2Fdev%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/docs%2Fdev%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2FREADME.md?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -55,7 +55,7 @@ We use Travis for CI. Most of the things, including formatting, are checked by\n be green as well. We use bors-ng to enforce the [not rocket\n science](https://graydon2.dreamwidth.org/1597.html) rule.\n \n-You can run `cargo format-hook` to install git-hook to run rustfmt on commit.\n+You can run `cargo xtask install-pre-commit-hook` to install git-hook to run rustfmt on commit.\n \n # Code organization\n "}, {"sha": "44507fb74873e15ef28941ef0acc0831c6233196", "filename": "xtask/src/bin/pre-commit.rs", "status": "removed", "additions": 0, "deletions": 31, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/aceeb0b85ee8228503f970ea602af71ff22216a0/xtask%2Fsrc%2Fbin%2Fpre-commit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/aceeb0b85ee8228503f970ea602af71ff22216a0/xtask%2Fsrc%2Fbin%2Fpre-commit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fbin%2Fpre-commit.rs?ref=aceeb0b85ee8228503f970ea602af71ff22216a0", "patch": "@@ -1,31 +0,0 @@\n-//! FIXME: write short doc here\n-\n-use std::process::Command;\n-\n-use xtask::{codegen::Mode, project_root, run, run_rustfmt, Result};\n-\n-fn main() -> Result<()> {\n-    run_rustfmt(Mode::Overwrite)?;\n-    update_staged()\n-}\n-\n-fn update_staged() -> Result<()> {\n-    let root = project_root();\n-    let output = Command::new(\"git\")\n-        .arg(\"diff\")\n-        .arg(\"--diff-filter=MAR\")\n-        .arg(\"--name-only\")\n-        .arg(\"--cached\")\n-        .current_dir(&root)\n-        .output()?;\n-    if !output.status.success() {\n-        anyhow::bail!(\n-            \"`git diff --diff-filter=MAR --name-only --cached` exited with {}\",\n-            output.status\n-        );\n-    }\n-    for line in String::from_utf8(output.stdout)?.lines() {\n-        run(&format!(\"git update-index --add {}\", root.join(line).to_string_lossy()), \".\")?;\n-    }\n-    Ok(())\n-}"}, {"sha": "f4e25dcde9d28f4723ceb4dbabd9741f168aa08c", "filename": "xtask/src/help.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Fhelp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Fhelp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fhelp.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -10,7 +10,7 @@ FLAGS:\n \n SUBCOMMANDS:\n     format\n-    format-hook\n+    install-pre-commit-hook\n     fuzz-tests\n     codegen\n     install"}, {"sha": "7332a40729f77c0e5a7f49bbb5b026d680da3956", "filename": "xtask/src/lib.rs", "status": "modified", "additions": 26, "deletions": 12, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Flib.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -83,19 +83,12 @@ pub fn install_rustfmt() -> Result<()> {\n     run(&format!(\"rustup component add rustfmt --toolchain {}\", TOOLCHAIN), \".\")\n }\n \n-pub fn install_format_hook() -> Result<()> {\n-    let result_path = Path::new(if cfg!(windows) {\n-        \"./.git/hooks/pre-commit.exe\"\n-    } else {\n-        \"./.git/hooks/pre-commit\"\n-    });\n+pub fn install_pre_commit_hook() -> Result<()> {\n+    let result_path =\n+        PathBuf::from(format!(\"./.git/hooks/pre-commit{}\", std::env::consts::EXE_SUFFIX));\n     if !result_path.exists() {\n-        run(\"cargo build --package xtask --bin pre-commit\", \".\")?;\n-        if cfg!(windows) {\n-            fs::copy(\"./target/debug/pre-commit.exe\", result_path)?;\n-        } else {\n-            fs::copy(\"./target/debug/pre-commit\", result_path)?;\n-        }\n+        let me = std::env::current_exe()?;\n+        fs::copy(me, result_path)?;\n     } else {\n         Err(IoError::new(ErrorKind::AlreadyExists, \"Git hook already created\"))?;\n     }\n@@ -150,6 +143,27 @@ pub fn run_fuzzer() -> Result<()> {\n     run(\"rustup run nightly -- cargo fuzz run parser\", \"./crates/ra_syntax\")\n }\n \n+pub fn reformat_staged_files() -> Result<()> {\n+    let root = project_root();\n+    let output = Command::new(\"git\")\n+        .arg(\"diff\")\n+        .arg(\"--diff-filter=MAR\")\n+        .arg(\"--name-only\")\n+        .arg(\"--cached\")\n+        .current_dir(&root)\n+        .output()?;\n+    if !output.status.success() {\n+        anyhow::bail!(\n+            \"`git diff --diff-filter=MAR --name-only --cached` exited with {}\",\n+            output.status\n+        );\n+    }\n+    for line in String::from_utf8(output.stdout)?.lines() {\n+        run(&format!(\"git update-index --add {}\", root.join(line).to_string_lossy()), \".\")?;\n+    }\n+    Ok(())\n+}\n+\n fn do_run<F>(cmdline: &str, dir: &str, mut f: F) -> Result<Output>\n where\n     F: FnMut(&mut Command),"}, {"sha": "663e281035f43ecb9142e6064b74efefbf80c2a7", "filename": "xtask/src/main.rs", "status": "modified", "additions": 8, "deletions": 3, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4bdb6351ac557851607df9d142c9e573c0fb5e1d/xtask%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fmain.rs?ref=4bdb6351ac557851607df9d142c9e573c0fb5e1d", "patch": "@@ -16,7 +16,8 @@ use pico_args::Arguments;\n use std::{env, path::PathBuf};\n use xtask::{\n     codegen::{self, Mode},\n-    install_format_hook, run, run_clippy, run_fuzzer, run_rustfmt, run_with_output, Cmd, Result,\n+    install_pre_commit_hook, reformat_staged_files, run, run_clippy, run_fuzzer, run_rustfmt,\n+    run_with_output, Cmd, Result,\n };\n \n // Latest stable, feel free to send a PR if this lags behind.\n@@ -36,6 +37,10 @@ struct ServerOpt {\n }\n \n fn main() -> Result<()> {\n+    if std::env::args().next().map(|it| it.contains(\"pre-commit\")) == Some(true) {\n+        return reformat_staged_files();\n+    }\n+\n     let subcommand = match std::env::args_os().nth(1) {\n         None => {\n             eprintln!(\"{}\", help::GLOBAL_HELP);\n@@ -81,12 +86,12 @@ fn main() -> Result<()> {\n             }\n             run_rustfmt(Mode::Overwrite)?\n         }\n-        \"format-hook\" => {\n+        \"install-pre-commit-hook\" => {\n             if matches.contains([\"-h\", \"--help\"]) {\n                 help::print_no_param_subcommand_help(&subcommand);\n                 return Ok(());\n             }\n-            install_format_hook()?\n+            install_pre_commit_hook()?\n         }\n         \"lint\" => {\n             if matches.contains([\"-h\", \"--help\"]) {"}]}