{"sha": "b738b0616093dbe6ce14bd640d44cf4252981d56", "node_id": "C_kwDOAAsO6NoAKGI3MzhiMDYxNjA5M2RiZTZjZTE0YmQ2NDBkNDRjZjQyNTI5ODFkNTY", "commit": {"author": {"name": "lcnr", "email": "rust@lcnr.de", "date": "2023-01-11T12:39:02Z"}, "committer": {"name": "lcnr", "email": "rust@lcnr.de", "date": "2023-01-18T07:09:01Z"}, "message": "update cache", "tree": {"sha": "f07cdbc001ea07a18adb0d183060b7283edf97b4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f07cdbc001ea07a18adb0d183060b7283edf97b4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b738b0616093dbe6ce14bd640d44cf4252981d56", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b738b0616093dbe6ce14bd640d44cf4252981d56", "html_url": "https://github.com/rust-lang/rust/commit/b738b0616093dbe6ce14bd640d44cf4252981d56", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b738b0616093dbe6ce14bd640d44cf4252981d56/comments", "author": {"login": "lcnr", "id": 29864074, "node_id": "MDQ6VXNlcjI5ODY0MDc0", "avatar_url": "https://avatars.githubusercontent.com/u/29864074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lcnr", "html_url": "https://github.com/lcnr", "followers_url": "https://api.github.com/users/lcnr/followers", "following_url": "https://api.github.com/users/lcnr/following{/other_user}", "gists_url": "https://api.github.com/users/lcnr/gists{/gist_id}", "starred_url": "https://api.github.com/users/lcnr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lcnr/subscriptions", "organizations_url": "https://api.github.com/users/lcnr/orgs", "repos_url": "https://api.github.com/users/lcnr/repos", "events_url": "https://api.github.com/users/lcnr/events{/privacy}", "received_events_url": "https://api.github.com/users/lcnr/received_events", "type": "User", "site_admin": false}, "committer": {"login": "lcnr", "id": 29864074, "node_id": "MDQ6VXNlcjI5ODY0MDc0", "avatar_url": "https://avatars.githubusercontent.com/u/29864074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lcnr", "html_url": "https://github.com/lcnr", "followers_url": "https://api.github.com/users/lcnr/followers", "following_url": "https://api.github.com/users/lcnr/following{/other_user}", "gists_url": "https://api.github.com/users/lcnr/gists{/gist_id}", "starred_url": "https://api.github.com/users/lcnr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lcnr/subscriptions", "organizations_url": "https://api.github.com/users/lcnr/orgs", "repos_url": "https://api.github.com/users/lcnr/repos", "events_url": "https://api.github.com/users/lcnr/events{/privacy}", "received_events_url": "https://api.github.com/users/lcnr/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "aaa9bb9e7bb4b8b565f2e1570587d6c21b13ab2d", "url": "https://api.github.com/repos/rust-lang/rust/commits/aaa9bb9e7bb4b8b565f2e1570587d6c21b13ab2d", "html_url": "https://github.com/rust-lang/rust/commit/aaa9bb9e7bb4b8b565f2e1570587d6c21b13ab2d"}], "stats": {"total": 203, "additions": 91, "deletions": 112}, "files": [{"sha": "b3afaaa35c0a2511c346e87720e0239bb66d5521", "filename": "Cargo.lock", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b738b0616093dbe6ce14bd640d44cf4252981d56/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/b738b0616093dbe6ce14bd640d44cf4252981d56/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=b738b0616093dbe6ce14bd640d44cf4252981d56", "patch": "@@ -4783,6 +4783,7 @@ dependencies = [\n  \"rustc_middle\",\n  \"rustc_parse_format\",\n  \"rustc_query_system\",\n+ \"rustc_serialize\",\n  \"rustc_session\",\n  \"rustc_span\",\n  \"rustc_target\","}, {"sha": "90d879976c260cb33d84020b09a0ff33c9423d71", "filename": "compiler/rustc_trait_selection/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_trait_selection%2FCargo.toml?ref=b738b0616093dbe6ce14bd640d44cf4252981d56", "patch": "@@ -19,6 +19,7 @@ rustc_infer = { path = \"../rustc_infer\" }\n rustc_lint_defs = { path = \"../rustc_lint_defs\" }\n rustc_macros = { path = \"../rustc_macros\" }\n rustc_query_system = { path = \"../rustc_query_system\" }\n+rustc_serialize = { path = \"../rustc_serialize\" }\n rustc_session = { path = \"../rustc_session\" }\n rustc_span = { path = \"../rustc_span\" }\n rustc_target = { path = \"../rustc_target\" }"}, {"sha": "6fa0941036390a675beafe5305269c0e9633c740", "filename": "compiler/rustc_trait_selection/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_trait_selection%2Fsrc%2Flib.rs?ref=b738b0616093dbe6ce14bd640d44cf4252981d56", "patch": "@@ -21,6 +21,7 @@\n #![feature(never_type)]\n #![feature(result_option_inspect)]\n #![feature(type_alias_impl_trait)]\n+#![feature(min_specialization)]\n #![recursion_limit = \"512\"] // For rustdoc\n \n #[macro_use]"}, {"sha": "9ac629980eb725b8e2b9420f3324a627e75d5f23", "filename": "compiler/rustc_trait_selection/src/solve/cache.rs", "status": "modified", "additions": 88, "deletions": 112, "changes": 200, "blob_url": "https://github.com/rust-lang/rust/blob/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2Fsrc%2Fsolve%2Fcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b738b0616093dbe6ce14bd640d44cf4252981d56/compiler%2Frustc_trait_selection%2Fsrc%2Fsolve%2Fcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_trait_selection%2Fsrc%2Fsolve%2Fcache.rs?ref=b738b0616093dbe6ce14bd640d44cf4252981d56", "patch": "@@ -11,84 +11,60 @@\n use super::overflow::OverflowData;\n use super::{CanonicalGoal, Certainty, MaybeCause, Response};\n use super::{EvalCtxt, QueryResult};\n-\n use rustc_data_structures::fx::FxHashMap;\n+use rustc_index::vec::IndexVec;\n use rustc_infer::infer::canonical::{Canonical, CanonicalVarKind, CanonicalVarValues};\n use rustc_middle::ty::{self, TyCtxt};\n-use std::{cmp::Ordering, collections::hash_map::Entry};\n+use std::collections::hash_map::Entry;\n+\n+rustc_index::newtype_index! {\n+    pub struct StackDepth {}\n+}\n+rustc_index::newtype_index! {\n+    pub struct EntryIndex {}\n+}\n \n #[derive(Debug, Clone)]\n struct ProvisionalEntry<'tcx> {\n     // In case we have a coinductive cycle, this is the\n     // the currently least restrictive result of this goal.\n     response: QueryResult<'tcx>,\n-    // The lowest element on the stack on which this result\n-    // relies on. Starts out as just being the depth at which\n-    // we've proven this obligation, but gets lowered to the\n-    // depth of another goal if we rely on it in a cycle.\n-    depth: usize,\n+    // In case of a cycle, the depth of lowest stack entry involved\n+    // in that cycle. This is monotonically decreasing in the stack as all\n+    // elements between the current stack element in the lowest stack entry\n+    // involved have to also be involved in that cycle.\n+    //\n+    // We can only move entries to the global cache once we're complete done\n+    // with the cycle. If this entry has not been involved in a cycle,\n+    // this is just its own depth.\n+    depth: StackDepth,\n+\n+    // The goal for this entry. Should always be equal to the corresponding goal\n+    // in the lookup table.\n+    goal: CanonicalGoal<'tcx>,\n }\n \n struct StackElem<'tcx> {\n     goal: CanonicalGoal<'tcx>,\n     has_been_used: bool,\n }\n \n-/// The cache used for goals which are currently in progress or which depend\n-/// on in progress results.\n-///\n-/// Once we're done with a goal we can store it in the global trait solver\n-/// cache of the `TyCtxt`. For goals which we're currently proving, or which\n-/// have only been proven via a coinductive cycle using a goal still on our stack\n-/// we have to use this separate data structure.\n-///\n-/// The current data structure is not perfect, so there may still be room for\n-/// improvement here. We have the following requirements:\n-///\n-/// ## Is there is a provisional entry for the given goal:\n-///\n-/// ```ignore (for syntax highlighting)\n-/// self.entries.get(goal)\n-/// ```\n-///\n-/// ## Get all goals on the stack involved in a cycle:\n-///\n-/// ```ignore (for syntax highlighting)\n-/// let entry = self.entries.get(goal).unwrap();\n-/// let involved_goals = self.stack.iter().skip(entry.depth);\n-/// ```\n-///\n-/// ## Capping the depth of all entries\n-///\n-/// Needed whenever we encounter a cycle. The current implementation always\n-/// iterates over all entries instead of only the ones with a larger depth.\n-/// Changing this may result in notable performance improvements.\n-///\n-/// ```ignore (for syntax highlighting)\n-/// let cycle_depth = self.entries.get(goal).unwrap().depth;\n-/// for e in &mut self.entries {\n-///     e.depth = e.depth.min(cycle_depth);\n-/// }\n-/// ```\n-///\n-/// ## Checking whether we have to rerun the current goal\n-///\n-/// A goal has to be rerun if its provisional result was used in a cycle\n-/// and that result is different from its final result. We update\n-/// [StackElem::has_been_used] for the deepest stack element involved in a cycle.\n-///\n-/// ## Moving all finished goals into the global cache\n-///\n-/// If `stack_elem.has_been_used` is true, iterate over all entries, moving the ones\n-/// with equal depth. If not, simply move this single entry.\n pub(super) struct ProvisionalCache<'tcx> {\n-    stack: Vec<StackElem<'tcx>>,\n-    entries: FxHashMap<CanonicalGoal<'tcx>, ProvisionalEntry<'tcx>>,\n+    stack: IndexVec<StackDepth, StackElem<'tcx>>,\n+    entries: IndexVec<EntryIndex, ProvisionalEntry<'tcx>>,\n+    // FIXME: This is only used to quickly check whether a given goal\n+    // is in the cache. We should experiment with using something like\n+    // `SsoHashSet` here because in most cases there are only a few entries.\n+    lookup_table: FxHashMap<CanonicalGoal<'tcx>, EntryIndex>,\n }\n \n impl<'tcx> ProvisionalCache<'tcx> {\n     pub(super) fn empty() -> ProvisionalCache<'tcx> {\n-        ProvisionalCache { stack: Vec::new(), entries: Default::default() }\n+        ProvisionalCache {\n+            stack: Default::default(),\n+            entries: Default::default(),\n+            lookup_table: Default::default(),\n+        }\n     }\n \n     pub(super) fn current_depth(&self) -> usize {\n@@ -108,18 +84,17 @@ impl<'tcx> EvalCtxt<'tcx> {\n \n         // Look at the provisional cache to check for cycles.\n         let cache = &mut self.provisional_cache;\n-        match cache.entries.entry(goal) {\n+        match cache.lookup_table.entry(goal) {\n             // No entry, simply push this goal on the stack after dealing with overflow.\n             Entry::Vacant(v) => {\n                 if self.overflow_data.has_overflow(cache.stack.len()) {\n                     return Err(self.deal_with_overflow(goal));\n                 }\n \n-                v.insert(ProvisionalEntry {\n-                    response: response_no_constraints(self.tcx, goal, Certainty::Yes),\n-                    depth: cache.stack.len(),\n-                });\n-                cache.stack.push(StackElem { goal, has_been_used: false });\n+                let depth = cache.stack.push(StackElem { goal, has_been_used: false });\n+                let response = response_no_constraints(self.tcx, goal, Certainty::Yes);\n+                let entry_index = cache.entries.push(ProvisionalEntry { response, depth, goal });\n+                v.insert(entry_index);\n                 Ok(())\n             }\n             // We have a nested goal which relies on a goal `root` deeper in the stack.\n@@ -131,21 +106,22 @@ impl<'tcx> EvalCtxt<'tcx> {\n             //\n             // Finally we can return either the provisional response for that goal if we have a\n             // coinductive cycle or an ambiguous result if the cycle is inductive.\n-            Entry::Occupied(entry) => {\n-                // FIXME: `ProvisionalEntry` should be `Copy`.\n-                let entry = entry.get().clone();\n+            Entry::Occupied(entry_index) => {\n+                let entry_index = *entry_index.get();\n+                // FIXME `ProvisionalEntry` should be `Copy`.\n+                let entry = cache.entries.get(entry_index).unwrap().clone();\n                 cache.stack[entry.depth].has_been_used = true;\n-                for provisional_entry in cache.entries.values_mut() {\n+                for provisional_entry in cache.entries.iter_mut().skip(entry_index.index()) {\n                     provisional_entry.depth = provisional_entry.depth.min(entry.depth);\n                 }\n \n                 // NOTE: The goals on the stack aren't the only goals involved in this cycle.\n                 // We can also depend on goals which aren't part of the stack but coinductively\n                 // depend on the stack themselves. We already checked whether all the goals\n                 // between these goals and their root on the stack. This means that as long as\n-                // each goal in a cycle is checked for coinductivity by itself simply checking\n+                // each goal in a cycle is checked for coinductivity by itself, simply checking\n                 // the stack is enough.\n-                if cache.stack[entry.depth..]\n+                if cache.stack.raw[entry.depth.index()..]\n                     .iter()\n                     .all(|g| g.goal.value.predicate.is_coinductive(self.tcx))\n                 {\n@@ -154,7 +130,7 @@ impl<'tcx> EvalCtxt<'tcx> {\n                     Err(response_no_constraints(\n                         self.tcx,\n                         goal,\n-                        Certainty::Maybe(MaybeCause::Ambiguity),\n+                        Certainty::Maybe(MaybeCause::Overflow),\n                     ))\n                 }\n             }\n@@ -182,57 +158,57 @@ impl<'tcx> EvalCtxt<'tcx> {\n         let StackElem { goal, has_been_used } = cache.stack.pop().unwrap();\n         assert_eq!(goal, actual_goal);\n \n-        let provisional_entry = cache.entries.get_mut(&goal).unwrap();\n-        // Check whether the current stack entry is the root of a cycle.\n-        //\n-        // If so, we either move all participants of that cycle to the global cache\n-        // or, in case the provisional response used in the cycle is not equal to the\n-        // final response, have to recompute the goal after updating the provisional\n-        // response to the final response of this iteration.\n-        if has_been_used {\n-            if provisional_entry.response == response {\n-                // We simply drop all entries according to an immutable condition, so\n-                // query instability is not a concern here.\n-                #[allow(rustc::potential_query_instability)]\n-                cache.entries.retain(|goal, entry| match entry.depth.cmp(&cache.stack.len()) {\n-                    Ordering::Less => true,\n-                    Ordering::Equal => {\n-                        Self::try_move_finished_goal_to_global_cache(\n-                            self.tcx,\n-                            &mut self.overflow_data,\n-                            &cache.stack,\n-                            // FIXME: these should be `Copy` :(\n-                            goal.clone(),\n-                            entry.response.clone(),\n-                        );\n-                        false\n-                    }\n-                    Ordering::Greater => bug!(\"entry with greater depth than the current leaf\"),\n-                });\n+        let provisional_entry_index = *cache.lookup_table.get(&goal).unwrap();\n+        let provisional_entry = &mut cache.entries[provisional_entry_index];\n+        // Was the current goal the root of a cycle and was the provisional response\n+        // different from the final one.\n+        if has_been_used && provisional_entry.response != response {\n+            // If so, update the provisional reponse for this goal...\n+            provisional_entry.response = response;\n+            // ...remove all entries whose result depends on this goal\n+            // from the provisional cache...\n+            //\n+            // That's not completely correct, as a nested goal can also\n+            // depend on a goal which is lower in the stack so it doesn't\n+            // actually depend on the current goal. This should be fairly\n+            // rare and is hopefully not relevant for performance.\n+            #[allow(rustc::potential_query_instability)]\n+            cache.lookup_table.retain(|_key, index| *index <= provisional_entry_index);\n+            cache.entries.truncate(provisional_entry_index.index() + 1);\n \n-                true\n-            } else {\n-                provisional_entry.response = response;\n-                cache.stack.push(StackElem { goal, has_been_used: false });\n-                false\n-            }\n+            // ...and finally push our goal back on the stack and reevaluate it.\n+            cache.stack.push(StackElem { goal, has_been_used: false });\n+            false\n         } else {\n-            Self::try_move_finished_goal_to_global_cache(\n-                self.tcx,\n-                &mut self.overflow_data,\n-                &cache.stack,\n-                goal,\n-                response,\n-            );\n-            cache.entries.remove(&goal);\n+            // If not, we're done with this goal.\n+            //\n+            // Check whether that this goal doesn't depend on a goal deeper on the stack\n+            // and if so, move it and all nested goals to the global cache.\n+            //\n+            // Note that if any nested goal were to depend on something deeper on the stack,\n+            // this would have also updated the depth of this goal.\n+            if provisional_entry.depth == cache.stack.next_index() {\n+                for (i, entry) in cache.entries.drain_enumerated(provisional_entry_index.index()..)\n+                {\n+                    let actual_index = cache.lookup_table.remove(&entry.goal);\n+                    debug_assert_eq!(Some(i), actual_index);\n+                    Self::try_move_finished_goal_to_global_cache(\n+                        self.tcx,\n+                        &mut self.overflow_data,\n+                        &cache.stack,\n+                        entry.goal,\n+                        entry.response,\n+                    );\n+                }\n+            }\n             true\n         }\n     }\n \n     fn try_move_finished_goal_to_global_cache(\n         tcx: TyCtxt<'tcx>,\n         overflow_data: &mut OverflowData,\n-        stack: &[StackElem<'tcx>],\n+        stack: &IndexVec<StackDepth, StackElem<'tcx>>,\n         goal: CanonicalGoal<'tcx>,\n         response: QueryResult<'tcx>,\n     ) {"}]}