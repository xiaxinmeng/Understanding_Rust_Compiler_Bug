{"sha": "ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNhMmE1MGZhZDc0MzlmMDJhOWU5OWY4MTA3ZmZlZDg0NjBmYzhjNDQ=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-18T22:04:26Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-05-23T09:46:24Z"}, "message": "syntax: Turn `token::Lit` into a struct", "tree": {"sha": "4552fd5c786238aa51f716f983804f8c101dc1fd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4552fd5c786238aa51f716f983804f8c101dc1fd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "html_url": "https://github.com/rust-lang/rust/commit/ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "558559e70f648ff518da5ada726da2f04b617197", "url": "https://api.github.com/repos/rust-lang/rust/commits/558559e70f648ff518da5ada726da2f04b617197", "html_url": "https://github.com/rust-lang/rust/commit/558559e70f648ff518da5ada726da2f04b617197"}], "stats": {"total": 561, "additions": 275, "deletions": 286}, "files": [{"sha": "c5337381a3d4f3dc7ae1722a361288d82ab7bbeb", "filename": "src/librustc/hir/print.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustc%2Fhir%2Fprint.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustc%2Fhir%2Fprint.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fhir%2Fprint.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -1249,8 +1249,7 @@ impl<'a> State<'a> {\n \n     fn print_literal(&mut self, lit: &hir::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo())?;\n-        let (token, suffix) = lit.node.to_lit_token();\n-        self.writer().word(pprust::literal_to_string(token, suffix))\n+        self.writer().word(pprust::literal_to_string(lit.node.to_lit_token()))\n     }\n \n     pub fn print_expr(&mut self, expr: &hir::Expr) -> io::Result<()> {"}, {"sha": "af53f686ae5481409b9e526c75a14c7fcd4747fc", "filename": "src/librustc/ich/impls_syntax.rs", "status": "modified", "additions": 18, "deletions": 16, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustc%2Fich%2Fimpls_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fich%2Fimpls_syntax.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -165,7 +165,6 @@ impl_stable_hash_for!(enum ::syntax::ast::LitIntType {\n impl_stable_hash_for!(struct ::syntax::ast::Lit {\n     node,\n     token,\n-    suffix,\n     span\n });\n \n@@ -288,17 +287,23 @@ for tokenstream::TokenStream {\n     }\n }\n \n-impl_stable_hash_for!(enum token::Lit {\n-    Bool(val),\n-    Byte(val),\n-    Char(val),\n-    Err(val),\n-    Integer(val),\n-    Float(val),\n-    Str_(val),\n-    ByteStr(val),\n-    StrRaw(val, n),\n-    ByteStrRaw(val, n)\n+impl_stable_hash_for!(enum token::LitKind {\n+    Bool,\n+    Byte,\n+    Char,\n+    Integer,\n+    Float,\n+    Str,\n+    ByteStr,\n+    StrRaw(n),\n+    ByteStrRaw(n),\n+    Err\n+});\n+\n+impl_stable_hash_for!(struct token::Lit {\n+    kind,\n+    symbol,\n+    suffix\n });\n \n fn hash_token<'a, 'gcx, W: StableHasherResult>(\n@@ -348,10 +353,7 @@ fn hash_token<'a, 'gcx, W: StableHasherResult>(\n         token::Token::CloseDelim(delim_token) => {\n             std_hash::Hash::hash(&delim_token, hasher);\n         }\n-        token::Token::Literal(lit, opt_name) => {\n-            lit.hash_stable(hcx, hasher);\n-            opt_name.hash_stable(hcx, hasher);\n-        }\n+        token::Token::Literal(lit) => lit.hash_stable(hcx, hasher),\n \n         token::Token::Ident(ident, is_raw) => {\n             ident.name.hash_stable(hcx, hasher);"}, {"sha": "932419c78f22c1f03d6d09828e53e51d5e39b966", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -310,17 +310,17 @@ impl<'a> Classifier<'a> {\n                 }\n             }\n \n-            token::Literal(lit, _suf) => {\n-                match lit {\n+            token::Literal(lit) => {\n+                match lit.kind {\n                     // Text literals.\n-                    token::Byte(..) | token::Char(..) | token::Err(..) |\n-                        token::ByteStr(..) | token::ByteStrRaw(..) |\n-                        token::Str_(..) | token::StrRaw(..) => Class::String,\n+                    token::Byte | token::Char | token::Err |\n+                    token::ByteStr | token::ByteStrRaw(..) |\n+                    token::Str | token::StrRaw(..) => Class::String,\n \n                     // Number literals.\n-                    token::Integer(..) | token::Float(..) => Class::Number,\n+                    token::Integer | token::Float => Class::Number,\n \n-                    token::Bool(..) => panic!(\"literal token contains `Lit::Bool`\"),\n+                    token::Bool => panic!(\"literal token contains `Lit::Bool`\"),\n                 }\n             }\n "}, {"sha": "84ef0468cac7a420db1f694a6535b00c20cdcb6e", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -1347,8 +1347,6 @@ pub enum StrStyle {\n pub struct Lit {\n     /// The original literal token as written in source code.\n     pub token: token::Lit,\n-    /// The original literal suffix as written in source code.\n-    pub suffix: Option<Symbol>,\n     /// The \"semantic\" representation of the literal lowered from the original tokens.\n     /// Strings are unescaped, hexadecimal forms are eliminated, etc.\n     /// FIXME: Remove this and only create the semantic representation during lowering to HIR."}, {"sha": "0c57c23b2b5c4102e61a83e5be5f4e99fafb46b4", "filename": "src/libsyntax/diagnostics/plugin.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fdiagnostics%2Fplugin.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -77,8 +77,8 @@ pub fn expand_register_diagnostic<'cx>(ecx: &'cx mut ExtCtxt<'_>,\n         },\n         (3, Some(&TokenTree::Token(_, token::Ident(ref code, _))),\n             Some(&TokenTree::Token(_, token::Comma)),\n-            Some(&TokenTree::Token(_, token::Literal(token::StrRaw(description, _), None)))) => {\n-            (code, Some(description))\n+            Some(&TokenTree::Token(_, token::Literal(token::Lit { symbol, .. })))) => {\n+            (code, Some(symbol))\n         }\n         _ => unreachable!()\n     };"}, {"sha": "deb76d6d70a33f319d49ff15897cbfdcd4715d5c", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 51, "deletions": 54, "changes": 105, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -1,5 +1,6 @@\n use crate::ast::{self, Ident};\n-use crate::parse::{token, ParseSess};\n+use crate::parse::ParseSess;\n+use crate::parse::token::{self, Token};\n use crate::symbol::Symbol;\n use crate::parse::unescape;\n use crate::parse::unescape_error_reporting::{emit_unescape_error, push_escaped_char};\n@@ -21,7 +22,7 @@ mod unicode_chars;\n \n #[derive(Clone, Debug)]\n pub struct TokenAndSpan {\n-    pub tok: token::Token,\n+    pub tok: Token,\n     pub sp: Span,\n }\n \n@@ -55,7 +56,7 @@ pub struct StringReader<'a> {\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n     // cached:\n-    peek_tok: token::Token,\n+    peek_tok: Token,\n     peek_span: Span,\n     peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n@@ -726,7 +727,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     /// Lex a LIT_INTEGER or a LIT_FLOAT\n-    fn scan_number(&mut self, c: char) -> token::Lit {\n+    fn scan_number(&mut self, c: char) -> (token::LitKind, Symbol) {\n         let mut base = 10;\n         let start_bpos = self.pos;\n         self.bump();\n@@ -753,7 +754,7 @@ impl<'a> StringReader<'a> {\n                 }\n                 _ => {\n                     // just a 0\n-                    return token::Integer(self.name_from(start_bpos));\n+                    return (token::Integer, self.name_from(start_bpos));\n                 }\n             }\n         } else if c.is_digit(10) {\n@@ -765,7 +766,7 @@ impl<'a> StringReader<'a> {\n         if num_digits == 0 {\n             self.err_span_(start_bpos, self.pos, \"no valid digits found for number\");\n \n-            return token::Integer(Symbol::intern(\"0\"));\n+            return (token::Integer, Symbol::intern(\"0\"));\n         }\n \n         // might be a float, but don't be greedy if this is actually an\n@@ -783,17 +784,17 @@ impl<'a> StringReader<'a> {\n             let pos = self.pos;\n             self.check_float_base(start_bpos, pos, base);\n \n-            token::Float(self.name_from(start_bpos))\n+            (token::Float, self.name_from(start_bpos))\n         } else {\n             // it might be a float if it has an exponent\n             if self.ch_is('e') || self.ch_is('E') {\n                 self.scan_float_exponent();\n                 let pos = self.pos;\n                 self.check_float_base(start_bpos, pos, base);\n-                return token::Float(self.name_from(start_bpos));\n+                return (token::Float, self.name_from(start_bpos));\n             }\n             // but we certainly have an integer!\n-            token::Integer(self.name_from(start_bpos))\n+            (token::Integer, self.name_from(start_bpos))\n         }\n     }\n \n@@ -846,7 +847,7 @@ impl<'a> StringReader<'a> {\n         }\n     }\n \n-    fn binop(&mut self, op: token::BinOpToken) -> token::Token {\n+    fn binop(&mut self, op: token::BinOpToken) -> Token {\n         self.bump();\n         if self.ch_is('=') {\n             self.bump();\n@@ -858,7 +859,7 @@ impl<'a> StringReader<'a> {\n \n     /// Returns the next token from the string, advances the input past that\n     /// token, and updates the interner\n-    fn next_token_inner(&mut self) -> Result<token::Token, ()> {\n+    fn next_token_inner(&mut self) -> Result<Token, ()> {\n         let c = self.ch;\n \n         if ident_start(c) {\n@@ -912,10 +913,10 @@ impl<'a> StringReader<'a> {\n         }\n \n         if is_dec_digit(c) {\n-            let num = self.scan_number(c.unwrap());\n+            let (kind, symbol) = self.scan_number(c.unwrap());\n             let suffix = self.scan_optional_raw_name();\n-            debug!(\"next_token_inner: scanned number {:?}, {:?}\", num, suffix);\n-            return Ok(token::Literal(num, suffix));\n+            debug!(\"next_token_inner: scanned number {:?}, {:?}, {:?}\", kind, symbol, suffix);\n+            return Ok(Token::lit(kind, symbol, suffix));\n         }\n \n         match c.expect(\"next_token_inner called at EOF\") {\n@@ -1073,10 +1074,10 @@ impl<'a> StringReader<'a> {\n                     // lifetimes shouldn't end with a single quote\n                     // if we find one, then this is an invalid character literal\n                     if self.ch_is('\\'') {\n-                        let id = self.name_from(start);\n+                        let symbol = self.name_from(start);\n                         self.bump();\n                         self.validate_char_escape(start_with_quote);\n-                        return Ok(token::Literal(token::Char(id), None))\n+                        return Ok(Token::lit(token::Char, symbol, None));\n                     }\n \n                     // Include the leading `'` in the real identifier, for macro\n@@ -1098,43 +1099,43 @@ impl<'a> StringReader<'a> {\n                     return Ok(token::Lifetime(ident));\n                 }\n                 let msg = \"unterminated character literal\";\n-                let id = self.scan_single_quoted_string(start_with_quote, msg);\n+                let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n                 self.validate_char_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(token::Literal(token::Char(id), suffix))\n+                Ok(Token::lit(token::Char, symbol, suffix))\n             }\n             'b' => {\n                 self.bump();\n-                let lit = match self.ch {\n+                let (kind, symbol) = match self.ch {\n                     Some('\\'') => {\n                         let start_with_quote = self.pos;\n                         self.bump();\n                         let msg = \"unterminated byte constant\";\n-                        let id = self.scan_single_quoted_string(start_with_quote, msg);\n+                        let symbol = self.scan_single_quoted_string(start_with_quote, msg);\n                         self.validate_byte_escape(start_with_quote);\n-                        token::Byte(id)\n+                        (token::Byte, symbol)\n                     },\n                     Some('\"') => {\n                         let start_with_quote = self.pos;\n                         let msg = \"unterminated double quote byte string\";\n-                        let id = self.scan_double_quoted_string(msg);\n+                        let symbol = self.scan_double_quoted_string(msg);\n                         self.validate_byte_str_escape(start_with_quote);\n-                        token::ByteStr(id)\n+                        (token::ByteStr, symbol)\n                     },\n                     Some('r') => self.scan_raw_byte_string(),\n                     _ => unreachable!(),  // Should have been a token::Ident above.\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(token::Literal(lit, suffix))\n+                Ok(Token::lit(kind, symbol, suffix))\n             }\n             '\"' => {\n                 let start_with_quote = self.pos;\n                 let msg = \"unterminated double quote string\";\n-                let id = self.scan_double_quoted_string(msg);\n+                let symbol = self.scan_double_quoted_string(msg);\n                 self.validate_str_escape(start_with_quote);\n                 let suffix = self.scan_optional_raw_name();\n-                Ok(token::Literal(token::Str_(id), suffix))\n+                Ok(Token::lit(token::Str, symbol, suffix))\n             }\n             'r' => {\n                 let start_bpos = self.pos;\n@@ -1205,14 +1206,14 @@ impl<'a> StringReader<'a> {\n                 }\n \n                 self.bump();\n-                let id = if valid {\n+                let symbol = if valid {\n                     self.name_from_to(content_start_bpos, content_end_bpos)\n                 } else {\n                     Symbol::intern(\"??\")\n                 };\n                 let suffix = self.scan_optional_raw_name();\n \n-                Ok(token::Literal(token::StrRaw(id, hash_count), suffix))\n+                Ok(Token::lit(token::StrRaw(hash_count), symbol, suffix))\n             }\n             '-' => {\n                 if self.nextch_is('>') {\n@@ -1366,7 +1367,7 @@ impl<'a> StringReader<'a> {\n         id\n     }\n \n-    fn scan_raw_byte_string(&mut self) -> token::Lit {\n+    fn scan_raw_byte_string(&mut self) -> (token::LitKind, Symbol) {\n         let start_bpos = self.pos;\n         self.bump();\n         let mut hash_count = 0;\n@@ -1423,7 +1424,7 @@ impl<'a> StringReader<'a> {\n \n         self.bump();\n \n-        token::ByteStrRaw(self.name_from_to(content_start_bpos, content_end_bpos), hash_count)\n+        (token::ByteStrRaw(hash_count), self.name_from_to(content_start_bpos, content_end_bpos))\n     }\n \n     fn validate_char_escape(&self, start_with_quote: BytePos) {\n@@ -1637,15 +1638,19 @@ mod tests {\n \n     // check that the given reader produces the desired stream\n     // of tokens (stop checking after exhausting the expected vec)\n-    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<token::Token>) {\n+    fn check_tokenization(mut string_reader: StringReader<'_>, expected: Vec<Token>) {\n         for expected_tok in &expected {\n             assert_eq!(&string_reader.next_token().tok, expected_tok);\n         }\n     }\n \n     // make the identifier by looking up the string in the interner\n-    fn mk_ident(id: &str) -> token::Token {\n-        token::Token::from_ast_ident(Ident::from_str(id))\n+    fn mk_ident(id: &str) -> Token {\n+        Token::from_ast_ident(Ident::from_str(id))\n+    }\n+\n+    fn mk_lit(kind: token::LitKind, symbol: &str, suffix: Option<&str>) -> Token {\n+        Token::lit(kind, Symbol::intern(symbol), suffix.map(Symbol::intern))\n     }\n \n     #[test]\n@@ -1694,7 +1699,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'a'\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+                       mk_lit(token::Char, \"a\", None));\n         })\n     }\n \n@@ -1704,7 +1709,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"' '\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\" \")), None));\n+                       mk_lit(token::Char, \" \", None));\n         })\n     }\n \n@@ -1714,7 +1719,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n+                       mk_lit(token::Char, \"\\\\n\", None));\n         })\n     }\n \n@@ -1724,7 +1729,7 @@ mod tests {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n             assert_eq!(setup(&sm, &sh, \"'abc\".to_string()).next_token().tok,\n-                    token::Lifetime(Ident::from_str(\"'abc\")));\n+                       token::Lifetime(Ident::from_str(\"'abc\")));\n         })\n     }\n \n@@ -1733,10 +1738,8 @@ mod tests {\n         with_default_globals(|| {\n             let sm = Lrc::new(SourceMap::new(FilePathMapping::empty()));\n             let sh = mk_sess(sm.clone());\n-            assert_eq!(setup(&sm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n-                        .next_token()\n-                        .tok,\n-                    token::Literal(token::StrRaw(Symbol::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n+            assert_eq!(setup(&sm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string()).next_token().tok,\n+                       mk_lit(token::StrRaw(3), \"\\\"#a\\\\b\\x00c\\\"\", None));\n         })\n     }\n \n@@ -1748,18 +1751,16 @@ mod tests {\n             macro_rules! test {\n                 ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n                     assert_eq!(setup(&sm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n-                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                            Some(Symbol::intern(\"suffix\"))));\n+                               mk_lit(token::$tok_type, $tok_contents, Some(\"suffix\")));\n                     // with a whitespace separator:\n                     assert_eq!(setup(&sm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n-                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                            None));\n+                               mk_lit(token::$tok_type, $tok_contents, None));\n                 }}\n             }\n \n             test!(\"'a'\", Char, \"a\");\n             test!(\"b'a'\", Byte, \"a\");\n-            test!(\"\\\"a\\\"\", Str_, \"a\");\n+            test!(\"\\\"a\\\"\", Str, \"a\");\n             test!(\"b\\\"a\\\"\", ByteStr, \"a\");\n             test!(\"1234\", Integer, \"1234\");\n             test!(\"0b101\", Integer, \"0b101\");\n@@ -1768,14 +1769,11 @@ mod tests {\n             test!(\"1.0e10\", Float, \"1.0e10\");\n \n             assert_eq!(setup(&sm, &sh, \"2us\".to_string()).next_token().tok,\n-                    token::Literal(token::Integer(Symbol::intern(\"2\")),\n-                                    Some(Symbol::intern(\"us\"))));\n+                       mk_lit(token::Integer, \"2\", Some(\"us\")));\n             assert_eq!(setup(&sm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                    token::Literal(token::StrRaw(Symbol::intern(\"raw\"), 3),\n-                                    Some(Symbol::intern(\"suffix\"))));\n+                       mk_lit(token::StrRaw(3), \"raw\", Some(\"suffix\")));\n             assert_eq!(setup(&sm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                    token::Literal(token::ByteStrRaw(Symbol::intern(\"raw\"), 3),\n-                                    Some(Symbol::intern(\"suffix\"))));\n+                       mk_lit(token::ByteStrRaw(3), \"raw\", Some(\"suffix\")));\n         })\n     }\n \n@@ -1796,8 +1794,7 @@ mod tests {\n                 token::Comment => {}\n                 _ => panic!(\"expected a comment!\"),\n             }\n-            assert_eq!(lexer.next_token().tok,\n-                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+            assert_eq!(lexer.next_token().tok, mk_lit(token::Char, \"a\", None));\n         })\n     }\n "}, {"sha": "7554c7119932ef3d2e886ed7af00feedc8bad7ee", "filename": "src/libsyntax/parse/literal.rs", "status": "modified", "additions": 71, "deletions": 59, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fliteral.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -3,7 +3,7 @@\n use crate::ast::{self, Ident, Lit, LitKind};\n use crate::parse::parser::Parser;\n use crate::parse::PResult;\n-use crate::parse::token;\n+use crate::parse::token::{self, Token};\n use crate::parse::unescape::{unescape_str, unescape_char, unescape_byte_str, unescape_byte};\n use crate::print::pprust;\n use crate::symbol::{kw, Symbol};\n@@ -27,14 +27,21 @@ crate enum LitError {\n }\n \n impl LitError {\n-    crate fn report(&self, diag: &Handler, lit: token::Lit, suf: Option<Symbol>, span: Span) {\n+    crate fn report(\n+        &self,\n+        diag: &Handler,\n+        token::Lit { kind, suffix, .. }: token::Lit,\n+        span: Span,\n+    ) {\n         match *self {\n             LitError::NotLiteral | LitError::LexerError => {}\n             LitError::InvalidSuffix => {\n-                expect_no_suffix(diag, span, &format!(\"{} {}\", lit.article(), lit.descr()), suf);\n+                expect_no_suffix(\n+                    diag, span, &format!(\"{} {}\", kind.article(), kind.descr()), suffix\n+                );\n             }\n             LitError::InvalidIntSuffix => {\n-                let suf = suf.expect(\"suffix error with no suffix\").as_str();\n+                let suf = suffix.expect(\"suffix error with no suffix\").as_str();\n                 if looks_like_width_suffix(&['i', 'u'], &suf) {\n                     // If it looks like a width, try to be helpful.\n                     let msg = format!(\"invalid width `{}` for integer literal\", &suf[1..]);\n@@ -50,7 +57,7 @@ impl LitError {\n                 }\n             }\n             LitError::InvalidFloatSuffix => {\n-                let suf = suf.expect(\"suffix error with no suffix\").as_str();\n+                let suf = suffix.expect(\"suffix error with no suffix\").as_str();\n                 if looks_like_width_suffix(&['f'], &suf) {\n                     // If it looks like a width, try to be helpful.\n                     let msg = format!(\"invalid width `{}` for float literal\", &suf[1..]);\n@@ -84,43 +91,42 @@ impl LitKind {\n     /// If diagnostic handler is passed, always returns `Some`,\n     /// possibly after reporting non-fatal errors and recovery.\n     fn from_lit_token(\n-        lit: token::Lit,\n-        suf: Option<Symbol>,\n+        token::Lit { kind, symbol, suffix }: token::Lit,\n     ) -> Result<LitKind, LitError> {\n-        if suf.is_some() && !lit.may_have_suffix() {\n+        if suffix.is_some() && !kind.may_have_suffix() {\n             return Err(LitError::InvalidSuffix);\n         }\n \n-        Ok(match lit {\n-            token::Bool(i) => {\n-                assert!(i == kw::True || i == kw::False);\n-                LitKind::Bool(i == kw::True)\n+        Ok(match kind {\n+            token::Bool => {\n+                assert!(symbol == kw::True || symbol == kw::False);\n+                LitKind::Bool(symbol == kw::True)\n             }\n-            token::Byte(i) => {\n-                match unescape_byte(&i.as_str()) {\n+            token::Byte => {\n+                match unescape_byte(&symbol.as_str()) {\n                     Ok(c) => LitKind::Byte(c),\n-                    Err(_) => LitKind::Err(i),\n+                    Err(_) => return Err(LitError::LexerError),\n                 }\n             },\n-            token::Char(i) => {\n-                match unescape_char(&i.as_str()) {\n+            token::Char => {\n+                match unescape_char(&symbol.as_str()) {\n                     Ok(c) => LitKind::Char(c),\n                     Err(_) => return Err(LitError::LexerError),\n                 }\n             },\n-            token::Err(i) => LitKind::Err(i),\n \n             // There are some valid suffixes for integer and float literals,\n             // so all the handling is done internally.\n-            token::Integer(s) => return integer_lit(s, suf),\n-            token::Float(s) => return float_lit(s, suf),\n+            token::Integer => return integer_lit(symbol, suffix),\n+            token::Float => return float_lit(symbol, suffix),\n \n-            token::Str_(mut sym) => {\n+            token::Str => {\n                 // If there are no characters requiring special treatment we can\n                 // reuse the symbol from the token. Otherwise, we must generate a\n                 // new symbol because the string in the LitKind is different to the\n                 // string in the token.\n                 let mut error = None;\n+                let mut sym = symbol;\n                 let s = &sym.as_str();\n                 if s.as_bytes().iter().any(|&c| c == b'\\\\' || c == b'\\r') {\n                     let mut buf = String::with_capacity(s.len());\n@@ -138,16 +144,17 @@ impl LitKind {\n \n                 LitKind::Str(sym, ast::StrStyle::Cooked)\n             }\n-            token::StrRaw(mut sym, n) => {\n+            token::StrRaw(n) => {\n                 // Ditto.\n+                let mut sym = symbol;\n                 let s = &sym.as_str();\n                 if s.contains('\\r') {\n                     sym = Symbol::intern(&raw_str_lit(s));\n                 }\n                 LitKind::Str(sym, ast::StrStyle::Raw(n))\n             }\n-            token::ByteStr(i) => {\n-                let s = &i.as_str();\n+            token::ByteStr => {\n+                let s = &symbol.as_str();\n                 let mut buf = Vec::with_capacity(s.len());\n                 let mut error = None;\n                 unescape_byte_str(s, &mut |_, unescaped_byte| {\n@@ -162,66 +169,71 @@ impl LitKind {\n                 buf.shrink_to_fit();\n                 LitKind::ByteStr(Lrc::new(buf))\n             }\n-            token::ByteStrRaw(i, _) => {\n-                LitKind::ByteStr(Lrc::new(i.to_string().into_bytes()))\n+            token::ByteStrRaw(_) => {\n+                LitKind::ByteStr(Lrc::new(symbol.to_string().into_bytes()))\n             }\n+            token::Err => LitKind::Err(symbol),\n         })\n     }\n \n     /// Attempts to recover a token from semantic literal.\n     /// This function is used when the original token doesn't exist (e.g. the literal is created\n     /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n-    pub fn to_lit_token(&self) -> (token::Lit, Option<Symbol>) {\n-        match *self {\n+    pub fn to_lit_token(&self) -> token::Lit {\n+        let (kind, symbol, suffix) = match *self {\n             LitKind::Str(string, ast::StrStyle::Cooked) => {\n                 let escaped = string.as_str().escape_default().to_string();\n-                (token::Lit::Str_(Symbol::intern(&escaped)), None)\n+                (token::Str, Symbol::intern(&escaped), None)\n             }\n             LitKind::Str(string, ast::StrStyle::Raw(n)) => {\n-                (token::Lit::StrRaw(string, n), None)\n+                (token::StrRaw(n), string, None)\n             }\n             LitKind::ByteStr(ref bytes) => {\n                 let string = bytes.iter().cloned().flat_map(ascii::escape_default)\n                     .map(Into::<char>::into).collect::<String>();\n-                (token::Lit::ByteStr(Symbol::intern(&string)), None)\n+                (token::ByteStr, Symbol::intern(&string), None)\n             }\n             LitKind::Byte(byte) => {\n                 let string: String = ascii::escape_default(byte).map(Into::<char>::into).collect();\n-                (token::Lit::Byte(Symbol::intern(&string)), None)\n+                (token::Byte, Symbol::intern(&string), None)\n             }\n             LitKind::Char(ch) => {\n                 let string: String = ch.escape_default().map(Into::<char>::into).collect();\n-                (token::Lit::Char(Symbol::intern(&string)), None)\n+                (token::Char, Symbol::intern(&string), None)\n             }\n             LitKind::Int(n, ty) => {\n                 let suffix = match ty {\n                     ast::LitIntType::Unsigned(ty) => Some(Symbol::intern(ty.ty_to_string())),\n                     ast::LitIntType::Signed(ty) => Some(Symbol::intern(ty.ty_to_string())),\n                     ast::LitIntType::Unsuffixed => None,\n                 };\n-                (token::Lit::Integer(Symbol::intern(&n.to_string())), suffix)\n+                (token::Integer, Symbol::intern(&n.to_string()), suffix)\n             }\n             LitKind::Float(symbol, ty) => {\n-                (token::Lit::Float(symbol), Some(Symbol::intern(ty.ty_to_string())))\n+                (token::Float, symbol, Some(Symbol::intern(ty.ty_to_string())))\n+            }\n+            LitKind::FloatUnsuffixed(symbol) => {\n+                (token::Float, symbol, None)\n             }\n-            LitKind::FloatUnsuffixed(symbol) => (token::Lit::Float(symbol), None),\n             LitKind::Bool(value) => {\n-                let kw = if value { kw::True } else { kw::False };\n-                (token::Lit::Bool(kw), None)\n+                let symbol = if value { kw::True } else { kw::False };\n+                (token::Bool, symbol, None)\n             }\n-            LitKind::Err(val) => (token::Lit::Err(val), None),\n-        }\n+            LitKind::Err(symbol) => {\n+                (token::Err, symbol, None)\n+            }\n+        };\n+\n+        token::Lit::new(kind, symbol, suffix)\n     }\n }\n \n impl Lit {\n     fn from_lit_token(\n         token: token::Lit,\n-        suffix: Option<Symbol>,\n         span: Span,\n     ) -> Result<Lit, LitError> {\n-        let node = LitKind::from_lit_token(token, suffix)?;\n-        Ok(Lit { node, token, suffix, span })\n+        Ok(Lit { token, node: LitKind::from_lit_token(token)?, span })\n     }\n \n     /// Converts literal token with a suffix into an AST literal.\n@@ -232,11 +244,11 @@ impl Lit {\n         token: &token::Token,\n         span: Span,\n     ) -> Result<Lit, LitError> {\n-        let (lit, suf) = match *token {\n+        let lit = match *token {\n             token::Ident(ident, false) if ident.name == kw::True || ident.name == kw::False =>\n-                (token::Bool(ident.name), None),\n-            token::Literal(token, suffix) =>\n-                (token, suffix),\n+                token::Lit::new(token::Bool, ident.name, None),\n+            token::Literal(lit) =>\n+                lit,\n             token::Interpolated(ref nt) => {\n                 if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n                     if let ast::ExprKind::Lit(lit) = &expr.node {\n@@ -248,22 +260,21 @@ impl Lit {\n             _ => return Err(LitError::NotLiteral)\n         };\n \n-        Lit::from_lit_token(lit, suf, span)\n+        Lit::from_lit_token(lit, span)\n     }\n \n     /// Attempts to recover an AST literal from semantic literal.\n     /// This function is used when the original token doesn't exist (e.g. the literal is created\n     /// by an AST-based macro) or unavailable (e.g. from HIR pretty-printing).\n     pub fn from_lit_kind(node: LitKind, span: Span) -> Lit {\n-        let (token, suffix) = node.to_lit_token();\n-        Lit { node, token, suffix, span }\n+        Lit { token: node.to_lit_token(), node, span }\n     }\n \n     /// Losslessly convert an AST literal into a token stream.\n     crate fn tokens(&self) -> TokenStream {\n-        let token = match self.token {\n-            token::Bool(symbol) => token::Ident(Ident::new(symbol, self.span), false),\n-            token => token::Literal(token, self.suffix),\n+        let token = match self.token.kind {\n+            token::Bool => token::Ident(Ident::new(self.token.symbol, self.span), false),\n+            _ => token::Literal(self.token),\n         };\n         TokenTree::Token(self.span, token).into()\n     }\n@@ -276,11 +287,11 @@ impl<'a> Parser<'a> {\n         if self.token == token::Dot {\n             // Attempt to recover `.4` as `0.4`.\n             recovered = self.look_ahead(1, |t| {\n-                if let token::Literal(token::Integer(val), suf) = *t {\n+                if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = *t {\n                     let next_span = self.look_ahead_span(1);\n                     if self.span.hi() == next_span.lo() {\n-                        let sym = String::from(\"0.\") + &val.as_str();\n-                        let token = token::Literal(token::Float(Symbol::intern(&sym)), suf);\n+                        let s = String::from(\"0.\") + &symbol.as_str();\n+                        let token = Token::lit(token::Float, Symbol::intern(&s), suffix);\n                         return Some((token, self.span.to(next_span)));\n                     }\n                 }\n@@ -313,10 +324,11 @@ impl<'a> Parser<'a> {\n                 return Err(self.span_fatal(span, &msg));\n             }\n             Err(err) => {\n-                let (lit, suf) = token.expect_lit();\n+                let lit = token.expect_lit();\n                 self.bump();\n-                err.report(&self.sess.span_diagnostic, lit, suf, span);\n-                return Ok(Lit::from_lit_token(token::Err(lit.symbol()), suf, span).ok().unwrap());\n+                err.report(&self.sess.span_diagnostic, lit, span);\n+                let lit = token::Lit::new(token::Err, lit.symbol, lit.suffix);\n+                return Ok(Lit::from_lit_token(lit, span).ok().unwrap());\n             }\n         }\n     }"}, {"sha": "ae3665c834bd3e9c0b949a5281d3f4ff9eac5d34", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 23, "deletions": 18, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -352,10 +352,12 @@ impl TokenCursor {\n         let body = TokenTree::Delimited(\n             delim_span,\n             token::Bracket,\n-            [TokenTree::Token(sp, token::Ident(ast::Ident::with_empty_ctxt(sym::doc), false)),\n-             TokenTree::Token(sp, token::Eq),\n-             TokenTree::Token(sp, token::Literal(\n-                token::StrRaw(Symbol::intern(&stripped), num_of_hashes), None))\n+            [\n+                TokenTree::Token(sp, token::Ident(ast::Ident::with_empty_ctxt(sym::doc), false)),\n+                TokenTree::Token(sp, token::Eq),\n+                TokenTree::Token(sp, token::Token::lit(\n+                    token::StrRaw(num_of_hashes), Symbol::intern(&stripped), None\n+                )),\n             ]\n             .iter().cloned().collect::<TokenStream>().into(),\n         );\n@@ -2241,10 +2243,10 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_field_name(&mut self) -> PResult<'a, Ident> {\n-        if let token::Literal(token::Integer(name), suffix) = self.token {\n+        if let token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) = self.token {\n             self.expect_no_suffix(self.span, \"a tuple index\", suffix);\n             self.bump();\n-            Ok(Ident::new(name, self.prev_span))\n+            Ok(Ident::new(symbol, self.prev_span))\n         } else {\n             self.parse_ident_common(false)\n         }\n@@ -3045,19 +3047,19 @@ impl<'a> Parser<'a> {\n                     token::Ident(..) => {\n                         e = self.parse_dot_suffix(e, lo)?;\n                     }\n-                    token::Literal(token::Integer(name), suffix) => {\n+                    token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) => {\n                         let span = self.span;\n                         self.bump();\n-                        let field = ExprKind::Field(e, Ident::new(name, span));\n+                        let field = ExprKind::Field(e, Ident::new(symbol, span));\n                         e = self.mk_expr(lo.to(span), field, ThinVec::new());\n \n                         self.expect_no_suffix(span, \"a tuple index\", suffix);\n                     }\n-                    token::Literal(token::Float(n), _suf) => {\n+                    token::Literal(token::Lit { kind: token::Float, symbol, .. }) => {\n                       self.bump();\n-                      let fstr = n.as_str();\n-                      let mut err = self.diagnostic()\n-                          .struct_span_err(self.prev_span, &format!(\"unexpected token: `{}`\", n));\n+                      let fstr = symbol.as_str();\n+                      let msg = format!(\"unexpected token: `{}`\", symbol);\n+                      let mut err = self.diagnostic().struct_span_err(self.prev_span, &msg);\n                       err.span_label(self.prev_span, \"unexpected token\");\n                       if fstr.chars().all(|x| \"0123456789.\".contains(x)) {\n                           let float = match fstr.parse::<f64>().ok() {\n@@ -7557,11 +7559,12 @@ impl<'a> Parser<'a> {\n     /// the `extern` keyword, if one is found.\n     fn parse_opt_abi(&mut self) -> PResult<'a, Option<Abi>> {\n         match self.token {\n-            token::Literal(token::Str_(s), suf) | token::Literal(token::StrRaw(s, _), suf) => {\n+            token::Literal(token::Lit { kind: token::Str, symbol, suffix }) |\n+            token::Literal(token::Lit { kind: token::StrRaw(..), symbol, suffix }) => {\n                 let sp = self.span;\n-                self.expect_no_suffix(sp, \"an ABI spec\", suf);\n+                self.expect_no_suffix(sp, \"an ABI spec\", suffix);\n                 self.bump();\n-                match abi::lookup(&s.as_str()) {\n+                match abi::lookup(&symbol.as_str()) {\n                     Some(abi) => Ok(Some(abi)),\n                     None => {\n                         let prev_span = self.prev_span;\n@@ -7570,7 +7573,7 @@ impl<'a> Parser<'a> {\n                             prev_span,\n                             E0703,\n                             \"invalid ABI: found `{}`\",\n-                            s);\n+                            symbol);\n                         err.span_label(prev_span, \"invalid ABI\");\n                         err.help(&format!(\"valid ABIs: {}\", abi::all_names().join(\", \")));\n                         err.emit();\n@@ -8370,8 +8373,10 @@ impl<'a> Parser<'a> {\n \n     pub fn parse_optional_str(&mut self) -> Option<(Symbol, ast::StrStyle, Option<ast::Name>)> {\n         let ret = match self.token {\n-            token::Literal(token::Str_(s), suf) => (s, ast::StrStyle::Cooked, suf),\n-            token::Literal(token::StrRaw(s, n), suf) => (s, ast::StrStyle::Raw(n), suf),\n+            token::Literal(token::Lit { kind: token::Str, symbol, suffix }) =>\n+                (symbol, ast::StrStyle::Cooked, suffix),\n+            token::Literal(token::Lit { kind: token::StrRaw(n), symbol, suffix }) =>\n+                (symbol, ast::StrStyle::Raw(n), suffix),\n             _ => return None\n         };\n         self.bump();"}, {"sha": "4711a156ab15b3d7d370de9f35d5a471c459583d", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 51, "deletions": 44, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -1,7 +1,7 @@\n pub use BinOpToken::*;\n pub use Nonterminal::*;\n pub use DelimToken::*;\n-pub use Lit::*;\n+pub use LitKind::*;\n pub use Token::*;\n \n use crate::ast::{self};\n@@ -59,59 +59,62 @@ impl DelimToken {\n     }\n }\n \n-#[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n-pub enum Lit {\n-    Bool(ast::Name), // AST only, must never appear in a `Token`\n-    Byte(ast::Name),\n-    Char(ast::Name),\n-    Err(ast::Name),\n-    Integer(ast::Name),\n-    Float(ast::Name),\n-    Str_(ast::Name),\n-    StrRaw(ast::Name, u16), /* raw str delimited by n hash symbols */\n-    ByteStr(ast::Name),\n-    ByteStrRaw(ast::Name, u16), /* raw byte str delimited by n hash symbols */\n+#[derive(Clone, Copy, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+pub enum LitKind {\n+    Bool, // AST only, must never appear in a `Token`\n+    Byte,\n+    Char,\n+    Integer,\n+    Float,\n+    Str,\n+    StrRaw(u16), // raw string delimited by `n` hash symbols\n+    ByteStr,\n+    ByteStrRaw(u16), // raw byte string delimited by `n` hash symbols\n+    Err,\n }\n \n-#[cfg(target_arch = \"x86_64\")]\n-static_assert_size!(Lit, 8);\n-\n-impl Lit {\n-    crate fn symbol(&self) -> Symbol {\n-        match *self {\n-            Bool(s) | Byte(s) | Char(s) | Integer(s) | Float(s) | Err(s) |\n-            Str_(s) | StrRaw(s, _) | ByteStr(s) | ByteStrRaw(s, _) => s\n-        }\n-    }\n+#[derive(Clone, Copy, PartialEq, RustcEncodable, RustcDecodable, Debug)]\n+pub struct Lit {\n+    pub kind: LitKind,\n+    pub symbol: Symbol,\n+    pub suffix: Option<Symbol>,\n+}\n \n-    crate fn article(&self) -> &'static str {\n-        match *self {\n-            Integer(_) | Err(_) => \"an\",\n+impl LitKind {\n+    crate fn article(self) -> &'static str {\n+        match self {\n+            Integer | Err => \"an\",\n             _ => \"a\",\n         }\n     }\n \n-    crate fn descr(&self) -> &'static str {\n-        match *self {\n-            Bool(_) => panic!(\"literal token contains `Lit::Bool`\"),\n-            Byte(_) => \"byte literal\",\n-            Char(_) => \"char literal\",\n-            Err(_) => \"invalid literal\",\n-            Integer(_) => \"integer literal\",\n-            Float(_) => \"float literal\",\n-            Str_(_) | StrRaw(..) => \"string literal\",\n-            ByteStr(_) | ByteStrRaw(..) => \"byte string literal\"\n+    crate fn descr(self) -> &'static str {\n+        match self {\n+            Bool => panic!(\"literal token contains `Lit::Bool`\"),\n+            Byte => \"byte literal\",\n+            Char => \"char literal\",\n+            Integer => \"integer literal\",\n+            Float => \"float literal\",\n+            Str | StrRaw(..) => \"string literal\",\n+            ByteStr | ByteStrRaw(..) => \"byte string literal\",\n+            Err => \"invalid literal\",\n         }\n     }\n \n-    crate fn may_have_suffix(&self) -> bool {\n-        match *self {\n-            Integer(..) | Float(..) | Err(..) => true,\n+    crate fn may_have_suffix(self) -> bool {\n+        match self {\n+            Integer | Float | Err => true,\n             _ => false,\n         }\n     }\n }\n \n+impl Lit {\n+    pub fn new(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Lit {\n+        Lit { kind, symbol, suffix }\n+    }\n+}\n+\n pub(crate) fn ident_can_begin_expr(ident: ast::Ident, is_raw: bool) -> bool {\n     let ident_token: Token = Ident(ident, is_raw);\n \n@@ -201,7 +204,7 @@ pub enum Token {\n     CloseDelim(DelimToken),\n \n     /* Literals */\n-    Literal(Lit, Option<ast::Name>),\n+    Literal(Lit),\n \n     /* Name components */\n     Ident(ast::Ident, /* is_raw */ bool),\n@@ -318,6 +321,10 @@ impl Token {\n         self == &Question || self == &OpenDelim(Paren)\n     }\n \n+    pub fn lit(kind: LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Token {\n+        Literal(Lit::new(kind, symbol, suffix))\n+    }\n+\n     /// Returns `true` if the token is any literal\n     crate fn is_lit(&self) -> bool {\n         match *self {\n@@ -326,9 +333,9 @@ impl Token {\n         }\n     }\n \n-    crate fn expect_lit(&self) -> (Lit, Option<Symbol>) {\n+    crate fn expect_lit(&self) -> Lit {\n         match *self {\n-            Literal(lit, suf) => (lit, suf),\n+            Literal(lit) => lit,\n             _=> panic!(\"`expect_lit` called on non-literal\"),\n         }\n     }\n@@ -579,13 +586,13 @@ impl Token {\n             (&DocComment(a), &DocComment(b)) |\n             (&Shebang(a), &Shebang(b)) => a == b,\n \n+            (&Literal(a), &Literal(b)) => a == b,\n+\n             (&Lifetime(a), &Lifetime(b)) => a.name == b.name,\n             (&Ident(a, b), &Ident(c, d)) => b == d && (a.name == c.name ||\n                                                        a.name == kw::DollarCrate ||\n                                                        c.name == kw::DollarCrate),\n \n-            (&Literal(a, b), &Literal(c, d)) => b == d && a == c,\n-\n             (&Interpolated(_), &Interpolated(_)) => false,\n \n             _ => panic!(\"forgot to add a token?\"),"}, {"sha": "67f57a7ed00524f50fcd6e7d99ff093628429c6b", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 18, "deletions": 18, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -163,22 +163,22 @@ fn binop_to_string(op: BinOpToken) -> &'static str {\n     }\n }\n \n-pub fn literal_to_string(lit: token::Lit, suffix: Option<ast::Name>) -> String {\n-    let mut out = match lit {\n-        token::Byte(b)           => format!(\"b'{}'\", b),\n-        token::Char(c)           => format!(\"'{}'\", c),\n-        token::Err(c)            => format!(\"'{}'\", c),\n-        token::Bool(c)           |\n-        token::Float(c)          |\n-        token::Integer(c)        => c.to_string(),\n-        token::Str_(s)           => format!(\"\\\"{}\\\"\", s),\n-        token::StrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                                            delim=\"#\".repeat(n as usize),\n-                                            string=s),\n-        token::ByteStr(v)        => format!(\"b\\\"{}\\\"\", v),\n-        token::ByteStrRaw(s, n)  => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n-                                            delim=\"#\".repeat(n as usize),\n-                                            string=s),\n+pub fn literal_to_string(token::Lit { kind, symbol, suffix }: token::Lit) -> String {\n+    let mut out = match kind {\n+        token::Byte          => format!(\"b'{}'\", symbol),\n+        token::Char          => format!(\"'{}'\", symbol),\n+        token::Bool          |\n+        token::Float         |\n+        token::Integer       => symbol.to_string(),\n+        token::Str           => format!(\"\\\"{}\\\"\", symbol),\n+        token::StrRaw(n)     => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                                        delim=\"#\".repeat(n as usize),\n+                                        string=symbol),\n+        token::ByteStr       => format!(\"b\\\"{}\\\"\", symbol),\n+        token::ByteStrRaw(n) => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n+                                        delim=\"#\".repeat(n as usize),\n+                                        string=symbol),\n+        token::Err           => format!(\"'{}'\", symbol),\n     };\n \n     if let Some(suffix) = suffix {\n@@ -231,7 +231,7 @@ pub fn token_to_string(tok: &Token) -> String {\n         token::SingleQuote          => \"'\".to_string(),\n \n         /* Literals */\n-        token::Literal(lit, suf) => literal_to_string(lit, suf),\n+        token::Literal(lit) => literal_to_string(lit),\n \n         /* Name components */\n         token::Ident(s, false)      => s.to_string(),\n@@ -571,7 +571,7 @@ pub trait PrintState<'a> {\n \n     fn print_literal(&mut self, lit: &ast::Lit) -> io::Result<()> {\n         self.maybe_print_comment(lit.span.lo())?;\n-        self.writer().word(literal_to_string(lit.token, lit.suffix))\n+        self.writer().word(literal_to_string(lit.token))\n     }\n \n     fn print_string(&mut self, st: &str,"}, {"sha": "a11cd9c6f761dbab4b714eb77e5b73f46381c1d8", "filename": "src/libsyntax_ext/assert.rs", "status": "modified", "additions": 6, "deletions": 9, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax_ext%2Fassert.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax_ext%2Fassert.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fassert.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -4,7 +4,7 @@ use syntax::ast::{self, *};\n use syntax::source_map::Spanned;\n use syntax::ext::base::*;\n use syntax::ext::build::AstBuilder;\n-use syntax::parse::token;\n+use syntax::parse::token::{self, Token};\n use syntax::parse::parser::Parser;\n use syntax::print::pprust;\n use syntax::ptr::P;\n@@ -31,13 +31,10 @@ pub fn expand_assert<'cx>(\n         tts: custom_message.unwrap_or_else(|| {\n             TokenStream::from(TokenTree::Token(\n                 DUMMY_SP,\n-                token::Literal(\n-                    token::Lit::Str_(Name::intern(&format!(\n-                        \"assertion failed: {}\",\n-                        pprust::expr_to_string(&cond_expr).escape_debug()\n-                    ))),\n-                    None,\n-                ),\n+                Token::lit(token::Str, Symbol::intern(&format!(\n+                    \"assertion failed: {}\",\n+                    pprust::expr_to_string(&cond_expr).escape_debug()\n+                )), None),\n             ))\n         }).into(),\n         delim: MacDelimiter::Parenthesis,\n@@ -106,7 +103,7 @@ fn parse_assert<'a>(\n     //\n     // Parse this as an actual message, and suggest inserting a comma. Eventually, this should be\n     // turned into an error.\n-    let custom_message = if let token::Literal(token::Lit::Str_(_), _) = parser.token {\n+    let custom_message = if let token::Literal(token::Lit { kind: token::Str, .. }) = parser.token {\n         let mut err = cx.struct_span_warn(parser.span, \"unexpected string literal\");\n         let comma_span = cx.source_map().next_point(parser.prev_span);\n         err.span_suggestion_short("}, {"sha": "a9bc5fe357d60b8923b139bd742201515c5ae593", "filename": "src/libsyntax_ext/proc_macro_server.rs", "status": "modified", "additions": 27, "deletions": 55, "changes": 82, "blob_url": "https://github.com/rust-lang/rust/blob/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ca2a50fad7439f02a9e99f8107ffed8460fc8c44/src%2Flibsyntax_ext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fproc_macro_server.rs?ref=ca2a50fad7439f02a9e99f8107ffed8460fc8c44", "patch": "@@ -150,7 +150,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                 stack.push(tt!(Ident::new(ident.name, false)));\n                 tt!(Punct::new('\\'', true))\n             }\n-            Literal(lit, suffix) => tt!(Literal { lit, suffix }),\n+            Literal(lit) => tt!(Literal { lit }),\n             DocComment(c) => {\n                 let style = comments::doc_comment_style(&c.as_str());\n                 let stripped = comments::strip_doc_comment_decoration(&c.as_str());\n@@ -161,7 +161,7 @@ impl FromInternal<(TreeAndJoint, &'_ ParseSess, &'_ mut Vec<Self>)>\n                 let stream = vec![\n                     Ident(ast::Ident::new(Symbol::intern(\"doc\"), span), false),\n                     Eq,\n-                    Literal(Lit::Str_(Symbol::intern(&escaped)), None),\n+                    Token::lit(token::Str, Symbol::intern(&escaped), None),\n                 ]\n                 .into_iter()\n                 .map(|token| tokenstream::TokenTree::Token(span, token))\n@@ -215,31 +215,29 @@ impl ToInternal<TokenStream> for TokenTree<Group, Punct, Ident, Literal> {\n                 return tokenstream::TokenTree::Token(span, token).into();\n             }\n             TokenTree::Literal(self::Literal {\n-                lit: Lit::Integer(ref a),\n-                suffix,\n+                lit: token::Lit { kind: token::Integer, symbol, suffix },\n                 span,\n-            }) if a.as_str().starts_with(\"-\") => {\n+            }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n-                let integer = Symbol::intern(&a.as_str()[1..]);\n-                let integer = Literal(Lit::Integer(integer), suffix);\n+                let symbol = Symbol::intern(&symbol.as_str()[1..]);\n+                let integer = Token::lit(token::Integer, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, integer);\n                 return vec![a, b].into_iter().collect();\n             }\n             TokenTree::Literal(self::Literal {\n-                lit: Lit::Float(ref a),\n-                suffix,\n+                lit: token::Lit { kind: token::Float, symbol, suffix },\n                 span,\n-            }) if a.as_str().starts_with(\"-\") => {\n+            }) if symbol.as_str().starts_with(\"-\") => {\n                 let minus = BinOp(BinOpToken::Minus);\n-                let float = Symbol::intern(&a.as_str()[1..]);\n-                let float = Literal(Lit::Float(float), suffix);\n+                let symbol = Symbol::intern(&symbol.as_str()[1..]);\n+                let float = Token::lit(token::Float, symbol, suffix);\n                 let a = tokenstream::TokenTree::Token(span, minus);\n                 let b = tokenstream::TokenTree::Token(span, float);\n                 return vec![a, b].into_iter().collect();\n             }\n-            TokenTree::Literal(self::Literal { lit, suffix, span }) => {\n-                return tokenstream::TokenTree::Token(span, Literal(lit, suffix)).into()\n+            TokenTree::Literal(self::Literal { lit, span }) => {\n+                return tokenstream::TokenTree::Token(span, Literal(lit)).into()\n             }\n         };\n \n@@ -355,7 +353,6 @@ impl Ident {\n #[derive(Clone, Debug)]\n pub struct Literal {\n     lit: token::Lit,\n-    suffix: Option<Symbol>,\n     span: Span,\n }\n \n@@ -381,6 +378,13 @@ impl<'a> Rustc<'a> {\n             call_site: to_span(Transparency::Transparent),\n         }\n     }\n+\n+    pub fn lit(&mut self, kind: token::LitKind, symbol: Symbol, suffix: Option<Symbol>) -> Literal {\n+        Literal {\n+            lit: token::Lit::new(kind, symbol, suffix),\n+            span: server::Span::call_site(self),\n+        }\n+    }\n }\n \n impl server::Types for Rustc<'_> {\n@@ -536,59 +540,31 @@ impl server::Literal for Rustc<'_> {\n         format!(\"{:?}\", literal)\n     }\n     fn integer(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Integer(Symbol::intern(n)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Integer, Symbol::intern(n), None)\n     }\n     fn typed_integer(&mut self, n: &str, kind: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Integer(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(kind)),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Integer, Symbol::intern(n), Some(Symbol::intern(kind)))\n     }\n     fn float(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), None)\n     }\n     fn f32(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(\"f32\")),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), Some(Symbol::intern(\"f32\")))\n     }\n     fn f64(&mut self, n: &str) -> Self::Literal {\n-        Literal {\n-            lit: token::Lit::Float(Symbol::intern(n)),\n-            suffix: Some(Symbol::intern(\"f64\")),\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Float, Symbol::intern(n), Some(Symbol::intern(\"f64\")))\n     }\n     fn string(&mut self, string: &str) -> Self::Literal {\n         let mut escaped = String::new();\n         for ch in string.chars() {\n             escaped.extend(ch.escape_debug());\n         }\n-        Literal {\n-            lit: token::Lit::Str_(Symbol::intern(&escaped)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Str, Symbol::intern(&escaped), None)\n     }\n     fn character(&mut self, ch: char) -> Self::Literal {\n         let mut escaped = String::new();\n         escaped.extend(ch.escape_unicode());\n-        Literal {\n-            lit: token::Lit::Char(Symbol::intern(&escaped)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::Char, Symbol::intern(&escaped), None)\n     }\n     fn byte_string(&mut self, bytes: &[u8]) -> Self::Literal {\n         let string = bytes\n@@ -597,11 +573,7 @@ impl server::Literal for Rustc<'_> {\n             .flat_map(ascii::escape_default)\n             .map(Into::<char>::into)\n             .collect::<String>();\n-        Literal {\n-            lit: token::Lit::ByteStr(Symbol::intern(&string)),\n-            suffix: None,\n-            span: server::Span::call_site(self),\n-        }\n+        self.lit(token::ByteStr, Symbol::intern(&string), None)\n     }\n     fn span(&mut self, literal: &Self::Literal) -> Self::Span {\n         literal.span"}]}