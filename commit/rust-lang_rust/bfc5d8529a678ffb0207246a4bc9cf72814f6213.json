{"sha": "bfc5d8529a678ffb0207246a4bc9cf72814f6213", "node_id": "C_kwDOAAsO6NoAKGJmYzVkODUyOWE2NzhmZmIwMjA3MjQ2YTRiYzljZjcyODE0ZjYyMTM", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-10-10T12:11:33Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2021-10-10T12:11:33Z"}, "message": "drop obsolete tests", "tree": {"sha": "a769d4ae97d39283f3d97a18a8a0d91ac2804cbf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a769d4ae97d39283f3d97a18a8a0d91ac2804cbf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bfc5d8529a678ffb0207246a4bc9cf72814f6213", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bfc5d8529a678ffb0207246a4bc9cf72814f6213", "html_url": "https://github.com/rust-lang/rust/commit/bfc5d8529a678ffb0207246a4bc9cf72814f6213", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bfc5d8529a678ffb0207246a4bc9cf72814f6213/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0f849a7a35e21d0b17eeed702ac91d0273dc8848", "url": "https://api.github.com/repos/rust-lang/rust/commits/0f849a7a35e21d0b17eeed702ac91d0273dc8848", "html_url": "https://github.com/rust-lang/rust/commit/0f849a7a35e21d0b17eeed702ac91d0273dc8848"}], "stats": {"total": 303, "additions": 2, "deletions": 301}, "files": [{"sha": "f4d7e60595939d319e574986c31dd13beca88417", "filename": "crates/mbe/src/tests.rs", "status": "modified", "additions": 2, "deletions": 203, "changes": 205, "blob_url": "https://github.com/rust-lang/rust/blob/bfc5d8529a678ffb0207246a4bc9cf72814f6213/crates%2Fmbe%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bfc5d8529a678ffb0207246a4bc9cf72814f6213/crates%2Fmbe%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftests.rs?ref=bfc5d8529a678ffb0207246a4bc9cf72814f6213", "patch": "@@ -1,210 +1,9 @@\n-mod expand;\n+use std::iter;\n \n-use std::{fmt::Write, iter};\n-\n-use syntax::{ast, AstNode, NodeOrToken, SyntaxNode, WalkEvent};\n-use test_utils::assert_eq_text;\n-\n-use crate::ParserEntryPoint;\n+use syntax::{ast, AstNode};\n \n use super::*;\n \n-pub(crate) struct MacroFixture {\n-    rules: MacroRules,\n-}\n-\n-pub(crate) struct MacroFixture2 {\n-    rules: MacroDef,\n-}\n-\n-macro_rules! impl_fixture {\n-    ($name:ident) => {\n-        impl $name {\n-            pub(crate) fn expand_tt(&self, invocation: &str) -> tt::Subtree {\n-                self.try_expand_tt(invocation).unwrap()\n-            }\n-\n-            fn try_expand_tt(&self, invocation: &str) -> Result<tt::Subtree, ExpandError> {\n-                let source_file = ast::SourceFile::parse(invocation).tree();\n-                let macro_invocation =\n-                    source_file.syntax().descendants().find_map(ast::MacroCall::cast).unwrap();\n-\n-                let (invocation_tt, _) =\n-                    syntax_node_to_token_tree(macro_invocation.token_tree().unwrap().syntax());\n-\n-                self.rules.expand(&invocation_tt).result()\n-            }\n-\n-            #[allow(unused)]\n-            fn assert_expand_err(&self, invocation: &str, err: &ExpandError) {\n-                assert_eq!(self.try_expand_tt(invocation).as_ref(), Err(err));\n-            }\n-\n-            #[allow(unused)]\n-            fn expand_items(&self, invocation: &str) -> SyntaxNode {\n-                let expanded = self.expand_tt(invocation);\n-                token_tree_to_syntax_node(&expanded, ParserEntryPoint::Items)\n-                    .unwrap()\n-                    .0\n-                    .syntax_node()\n-            }\n-\n-            #[allow(unused)]\n-            fn expand_statements(&self, invocation: &str) -> SyntaxNode {\n-                let expanded = self.expand_tt(invocation);\n-                token_tree_to_syntax_node(&expanded, ParserEntryPoint::Statements)\n-                    .unwrap()\n-                    .0\n-                    .syntax_node()\n-            }\n-\n-            #[allow(unused)]\n-            fn expand_expr(&self, invocation: &str) -> SyntaxNode {\n-                let expanded = self.expand_tt(invocation);\n-                token_tree_to_syntax_node(&expanded, ParserEntryPoint::Expr)\n-                    .unwrap()\n-                    .0\n-                    .syntax_node()\n-            }\n-\n-            #[allow(unused)]\n-            fn assert_expand_tt(&self, invocation: &str, expected: &str) {\n-                let expansion = self.expand_tt(invocation);\n-                assert_eq!(expansion.to_string(), expected);\n-            }\n-\n-            #[allow(unused)]\n-            fn assert_expand(&self, invocation: &str, expected: &str) {\n-                let expansion = self.expand_tt(invocation);\n-                let actual = format!(\"{:?}\", expansion);\n-                test_utils::assert_eq_text!(&expected.trim(), &actual.trim());\n-            }\n-\n-            #[allow(unused)]\n-            fn assert_expand_items(&self, invocation: &str, expected: &str) -> &$name {\n-                self.assert_expansion(ParserEntryPoint::Items, invocation, expected);\n-                self\n-            }\n-\n-            #[allow(unused)]\n-            fn assert_expand_statements(&self, invocation: &str, expected: &str) -> &$name {\n-                self.assert_expansion(ParserEntryPoint::Statements, invocation, expected);\n-                self\n-            }\n-\n-            fn assert_expansion(&self, kind: ParserEntryPoint, invocation: &str, expected: &str) {\n-                let expanded = self.expand_tt(invocation);\n-                assert_eq!(expanded.to_string(), expected);\n-\n-                let expected = expected.replace(\"$crate\", \"C_C__C\");\n-\n-                // wrap the given text to a macro call\n-                let expected = {\n-                    let wrapped = format!(\"wrap_macro!( {} )\", expected);\n-                    let wrapped = ast::SourceFile::parse(&wrapped);\n-                    let wrapped = wrapped\n-                        .tree()\n-                        .syntax()\n-                        .descendants()\n-                        .find_map(ast::TokenTree::cast)\n-                        .unwrap();\n-                    let mut wrapped = syntax_node_to_token_tree(wrapped.syntax()).0;\n-                    wrapped.delimiter = None;\n-                    wrapped\n-                };\n-\n-                let expanded_tree =\n-                    token_tree_to_syntax_node(&expanded, kind).unwrap().0.syntax_node();\n-                let expanded_tree = debug_dump_ignore_spaces(&expanded_tree).trim().to_string();\n-\n-                let expected_tree =\n-                    token_tree_to_syntax_node(&expected, kind).unwrap().0.syntax_node();\n-                let expected_tree = debug_dump_ignore_spaces(&expected_tree).trim().to_string();\n-\n-                let expected_tree = expected_tree.replace(\"C_C__C\", \"$crate\");\n-                assert_eq!(\n-                    expanded_tree, expected_tree,\n-                    \"\\nleft:\\n{}\\nright:\\n{}\",\n-                    expanded_tree, expected_tree,\n-                );\n-            }\n-        }\n-    };\n-}\n-\n-impl_fixture!(MacroFixture);\n-impl_fixture!(MacroFixture2);\n-\n-pub(crate) fn parse_macro(ra_fixture: &str) -> MacroFixture {\n-    let definition_tt = parse_macro_rules_to_tt(ra_fixture);\n-    let rules = MacroRules::parse(&definition_tt).unwrap();\n-    MacroFixture { rules }\n-}\n-\n-pub(crate) fn parse_to_token_tree_by_syntax(ra_fixture: &str) -> tt::Subtree {\n-    let source_file = ast::SourceFile::parse(ra_fixture).ok().unwrap();\n-    let tt = syntax_node_to_token_tree(source_file.syntax()).0;\n-\n-    let parsed = parse_to_token_tree(ra_fixture).unwrap().0;\n-    assert_eq!(tt, parsed);\n-\n-    parsed\n-}\n-\n-fn parse_macro_rules_to_tt(ra_fixture: &str) -> tt::Subtree {\n-    let source_file = ast::SourceFile::parse(ra_fixture).ok().unwrap();\n-    let macro_definition =\n-        source_file.syntax().descendants().find_map(ast::MacroRules::cast).unwrap();\n-\n-    let (definition_tt, _) =\n-        syntax_node_to_token_tree(macro_definition.token_tree().unwrap().syntax());\n-\n-    let parsed = parse_to_token_tree(\n-        &ra_fixture[macro_definition.token_tree().unwrap().syntax().text_range()],\n-    )\n-    .unwrap()\n-    .0;\n-    assert_eq!(definition_tt, parsed);\n-\n-    definition_tt\n-}\n-\n-fn debug_dump_ignore_spaces(node: &syntax::SyntaxNode) -> String {\n-    let mut level = 0;\n-    let mut buf = String::new();\n-    macro_rules! indent {\n-        () => {\n-            for _ in 0..level {\n-                buf.push_str(\"  \");\n-            }\n-        };\n-    }\n-\n-    for event in node.preorder_with_tokens() {\n-        match event {\n-            WalkEvent::Enter(element) => {\n-                match element {\n-                    NodeOrToken::Node(node) => {\n-                        indent!();\n-                        writeln!(buf, \"{:?}\", node.kind()).unwrap();\n-                    }\n-                    NodeOrToken::Token(token) => match token.kind() {\n-                        syntax::SyntaxKind::WHITESPACE => {}\n-                        _ => {\n-                            indent!();\n-                            writeln!(buf, \"{:?}\", token.kind()).unwrap();\n-                        }\n-                    },\n-                }\n-                level += 1;\n-            }\n-            WalkEvent::Leave(_) => level -= 1,\n-        }\n-    }\n-\n-    buf\n-}\n-\n #[test]\n fn test_node_to_tt_censor() {\n     use syntax::ast::{HasAttrs, HasModuleItem};"}, {"sha": "3380e01fbc7af74f05f4166ce1b0d5be03b05b56", "filename": "crates/mbe/src/tests/expand.rs", "status": "removed", "additions": 0, "deletions": 98, "changes": 98, "blob_url": "https://github.com/rust-lang/rust/blob/0f849a7a35e21d0b17eeed702ac91d0273dc8848/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0f849a7a35e21d0b17eeed702ac91d0273dc8848/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Ftests%2Fexpand.rs?ref=0f849a7a35e21d0b17eeed702ac91d0273dc8848", "patch": "@@ -1,98 +0,0 @@\n-use ::parser::ParserEntryPoint;\n-use syntax::{SyntaxKind::IDENT, T};\n-\n-use super::*;\n-\n-// Good first issue (although a slightly challenging one):\n-//\n-// * Pick a random test from here\n-//   https://github.com/intellij-rust/intellij-rust/blob/c4e9feee4ad46e7953b1948c112533360b6087bb/src/test/kotlin/org/rust/lang/core/macros/RsMacroExpansionTest.kt\n-// * Port the test to rust and add it to this module\n-// * Make it pass :-)\n-\n-#[test]\n-fn test_token_id_shift() {\n-    let expansion = parse_macro(\n-        r#\"\n-macro_rules! foobar {\n-    ($e:ident) => { foo bar $e }\n-}\n-\"#,\n-    )\n-    .expand_tt(\"foobar!(baz);\");\n-\n-    fn get_id(t: &tt::TokenTree) -> Option<u32> {\n-        if let tt::TokenTree::Leaf(tt::Leaf::Ident(ident)) = t {\n-            return Some(ident.id.0);\n-        }\n-        None\n-    }\n-\n-    assert_eq!(expansion.token_trees.len(), 3);\n-    // {($e:ident) => { foo bar $e }}\n-    // 012345      67 8 9   T   12\n-    assert_eq!(get_id(&expansion.token_trees[0]), Some(9));\n-    assert_eq!(get_id(&expansion.token_trees[1]), Some(10));\n-\n-    // The input args of macro call include parentheses:\n-    // (baz)\n-    // So baz should be 12+1+1\n-    assert_eq!(get_id(&expansion.token_trees[2]), Some(14));\n-}\n-\n-#[test]\n-fn test_token_map() {\n-    let expanded = parse_macro(\n-        r#\"\n-macro_rules! foobar {\n-    ($e:ident) => { fn $e() {} }\n-}\n-\"#,\n-    )\n-    .expand_tt(\"foobar!(baz);\");\n-\n-    let (node, token_map) = token_tree_to_syntax_node(&expanded, ParserEntryPoint::Items).unwrap();\n-    let content = node.syntax_node().to_string();\n-\n-    let get_text = |id, kind| -> String {\n-        content[token_map.first_range_by_token(id, kind).unwrap()].to_string()\n-    };\n-\n-    assert_eq!(expanded.token_trees.len(), 4);\n-    // {($e:ident) => { fn $e() {} }}\n-    // 012345      67 8 9  T12  3\n-\n-    assert_eq!(get_text(tt::TokenId(9), IDENT), \"fn\");\n-    assert_eq!(get_text(tt::TokenId(12), T!['(']), \"(\");\n-    assert_eq!(get_text(tt::TokenId(13), T!['{']), \"{\");\n-}\n-\n-fn to_subtree(tt: &tt::TokenTree) -> &tt::Subtree {\n-    if let tt::TokenTree::Subtree(subtree) = tt {\n-        return subtree;\n-    }\n-    unreachable!(\"It is not a subtree\");\n-}\n-\n-fn to_punct(tt: &tt::TokenTree) -> &tt::Punct {\n-    if let tt::TokenTree::Leaf(tt::Leaf::Punct(lit)) = tt {\n-        return lit;\n-    }\n-    unreachable!(\"It is not a Punct\");\n-}\n-\n-#[test]\n-fn test_attr_to_token_tree() {\n-    let expansion = parse_to_token_tree_by_syntax(\n-        r#\"\n-            #[derive(Copy)]\n-            struct Foo;\n-            \"#,\n-    );\n-\n-    assert_eq!(to_punct(&expansion.token_trees[0]).char, '#');\n-    assert_eq!(\n-        to_subtree(&expansion.token_trees[1]).delimiter_kind(),\n-        Some(tt::DelimiterKind::Bracket)\n-    );\n-}"}]}