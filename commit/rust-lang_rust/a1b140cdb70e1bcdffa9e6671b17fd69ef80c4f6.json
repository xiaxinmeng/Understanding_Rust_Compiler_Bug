{"sha": "a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6", "node_id": "C_kwDOAAsO6NoAKGExYjE0MGNkYjcwZTFiY2RmZmE5ZTY2NzFiMTdmZDY5ZWY4MGM0ZjY", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-25T05:20:39Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2022-03-29T23:50:17Z"}, "message": "Improve comments and rename many things for consistency.\n\nIn particular:\n- Replace use of \"item\" with \"matcher position/\"mp\".\n- Replace use of \"repetition\" with \"sequence\".\n- Replace `ms` with `matcher`.", "tree": {"sha": "a4de75f5d0716900a894e39018105b1f97e40f4c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a4de75f5d0716900a894e39018105b1f97e40f4c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6", "html_url": "https://github.com/rust-lang/rust/commit/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ac3d8ce1c6c5a40dfe1203e9873ace219a6e20cf", "url": "https://api.github.com/repos/rust-lang/rust/commits/ac3d8ce1c6c5a40dfe1203e9873ace219a6e20cf", "html_url": "https://github.com/rust-lang/rust/commit/ac3d8ce1c6c5a40dfe1203e9873ace219a6e20cf"}], "stats": {"total": 379, "additions": 181, "deletions": 198}, "files": [{"sha": "bbd83d0bc3eabec3e30ceed57e977b88bbeb938c", "filename": "compiler/rustc_expand/src/mbe/macro_parser.rs", "status": "modified", "additions": 181, "deletions": 198, "changes": 379, "blob_url": "https://github.com/rust-lang/rust/blob/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fmbe%2Fmacro_parser.rs?ref=a1b140cdb70e1bcdffa9e6671b17fd69ef80c4f6", "patch": "@@ -6,27 +6,27 @@\n //!\n //! (In order to prevent the pathological case, we'd need to lazily construct the resulting\n //! `NamedMatch`es at the very end. It'd be a pain, and require more memory to keep around old\n-//! items, but it would also save overhead)\n+//! matcher positions, but it would also save overhead)\n //!\n //! We don't say this parser uses the Earley algorithm, because it's unnecessarily inaccurate.\n //! The macro parser restricts itself to the features of finite state automata. Earley parsers\n //! can be described as an extension of NFAs with completion rules, prediction rules, and recursion.\n //!\n //! Quick intro to how the parser works:\n //!\n-//! A 'position' is a dot in the middle of a matcher, usually represented as a\n-//! dot. For example `\u00b7 a $( a )* a b` is a position, as is `a $( \u00b7 a )* a b`.\n+//! A \"matcher position\" (a.k.a. \"position\" or \"mp\") is a dot in the middle of a matcher, usually\n+//! written as a `\u00b7`. For example `\u00b7 a $( a )* a b` is one, as is `a $( \u00b7 a )* a b`.\n //!\n //! The parser walks through the input a character at a time, maintaining a list\n-//! of threads consistent with the current position in the input string: `cur_items`.\n+//! of threads consistent with the current position in the input string: `cur_mps`.\n //!\n-//! As it processes them, it fills up `eof_items` with threads that would be valid if\n-//! the macro invocation is now over, `bb_items` with threads that are waiting on\n-//! a Rust non-terminal like `$e:expr`, and `next_items` with threads that are waiting\n+//! As it processes them, it fills up `eof_mps` with threads that would be valid if\n+//! the macro invocation is now over, `bb_mps` with threads that are waiting on\n+//! a Rust non-terminal like `$e:expr`, and `next_mps` with threads that are waiting\n //! on a particular token. Most of the logic concerns moving the \u00b7 through the\n //! repetitions indicated by Kleene stars. The rules for moving the \u00b7 without\n //! consuming any input are called epsilon transitions. It only advances or calls\n-//! out to the real Rust parser when no `cur_items` threads remain.\n+//! out to the real Rust parser when no `cur_mps` threads remain.\n //!\n //! Example:\n //!\n@@ -40,28 +40,28 @@\n //!\n //! Remaining input: a a a b\n //! cur: [a \u00b7 $( a )* a b]\n-//! Descend/Skip (first item).\n+//! Descend/Skip (first position).\n //! next: [a $( \u00b7 a )* a b]  [a $( a )* \u00b7 a b].\n //!\n //! - - - Advance over an a. - - -\n //!\n //! Remaining input: a a b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n //! Remaining input: a b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over an a. - - - (this looks exactly like the last step)\n //!\n //! Remaining input: b\n //! cur: [a $( a \u00b7 )* a b]  [a $( a )* a \u00b7 b]\n-//! Follow epsilon transition: Finish/Repeat (first item)\n+//! Follow epsilon transition: Finish/Repeat (first position)\n //! next: [a $( a )* \u00b7 a b]  [a $( \u00b7 a )* a b]  [a $( a )* a \u00b7 b]\n //!\n //! - - - Advance over a b. - - -\n@@ -89,15 +89,13 @@ use std::borrow::Cow;\n use std::collections::hash_map::Entry::{Occupied, Vacant};\n use std::mem;\n \n-/// An unzipping of `TokenTree`s... see the `stack` field of `MatcherPos`.\n-///\n /// This is used by `parse_tt_inner` to keep track of delimited submatchers that we have\n /// descended into.\n #[derive(Clone)]\n-struct MatcherTtFrame<'tt> {\n-    /// The \"parent\" matcher that we are descending into.\n-    elts: &'tt [TokenTree],\n-    /// The position of the \"dot\" in `elts` at the time we descended.\n+struct MatcherPosFrame<'tt> {\n+    /// The \"parent\" matcher that we have descended from.\n+    tts: &'tt [TokenTree],\n+    /// The position of the \"dot\" in `tt` at the time we descended.\n     idx: usize,\n }\n \n@@ -110,61 +108,64 @@ type NamedMatchVec = SmallVec<[NamedMatch; 1]>;\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n rustc_data_structures::static_assert_size!(NamedMatchVec, 48);\n \n-/// Represents a single \"position\" (aka \"matcher position\", aka \"item\"), as\n-/// described in the module documentation.\n+/// A single matcher position, which could be within the top-level matcher, a submatcher, a\n+/// subsubmatcher, etc. For example:\n+/// ```text\n+/// macro_rules! m { $id:ident ( $($e:expr),* ) } => { ... }\n+///                              <---------->     second submatcher; one tt, one metavar\n+///                            <-------------->   first submatcher; three tts, zero metavars\n+///                  <--------------------------> top-level matcher; two tts, one metavar\n+/// ```\n #[derive(Clone)]\n struct MatcherPos<'tt> {\n-    /// The token or slice of tokens that make up the matcher. `elts` is short for \"elements\".\n-    top_elts: &'tt [TokenTree],\n+    /// The tokens that make up the current matcher. When we are within a `Sequence` or `Delimited`\n+    /// submatcher, this is just the contents of that submatcher.\n+    tts: &'tt [TokenTree],\n \n-    /// The position of the \"dot\" in this matcher\n+    /// The \"dot\" position within the current submatcher, i.e. the index into `tts`.\n     idx: usize,\n \n-    /// For each named metavar in the matcher, we keep track of token trees matched against the\n-    /// metavar by the black box parser. In particular, there may be more than one match per\n-    /// metavar if we are in a repetition (each repetition matches each of the variables).\n-    /// Moreover, matchers and repetitions can be nested; the `matches` field is shared (hence the\n-    /// `Rc`) among all \"nested\" matchers. `match_lo`, `match_cur`, and `match_hi` keep track of\n-    /// the current position of the `self` matcher position in the shared `matches` list.\n+    /// This boxed slice has one element per metavar in the *top-level* matcher, even when this\n+    /// `MatcherPos` is for a submatcher. Each element records token trees matched against the\n+    /// relevant metavar by the black box parser.\n     ///\n-    /// Also, note that while we are descending into a sequence, matchers are given their own\n-    /// `matches` vector. Only once we reach the end of a full repetition of the sequence do we add\n-    /// all bound matches from the submatcher into the shared top-level `matches` vector. If `sep`\n-    /// and `up` are `Some`, then `matches` is _not_ the shared top-level list. Instead, if one\n-    /// wants the shared `matches`, one should use `up.matches`.\n+    /// In a top-level `MatcherPos` each `NamedMatchVec` will have zero elements before processing\n+    /// and one element after processing; the one element will be a `MatchedSeq` if the\n+    /// corresponding metavar is within a sequence.\n+    ///\n+    /// In a sequence submatcher each `NamedMatchVec` will have zero elements before processing and\n+    /// any number of elements after processing (as allowed by the sequence's Kleene op, i.e.\n+    /// zero-or-one, zero-or-more, one-or-more). After processing these elements will be merged\n+    /// into the parent `MatcherPos`'s matches (within a `MatchedSeq`).\n     matches: Box<[Lrc<NamedMatchVec>]>,\n-    /// The position in `matches` corresponding to the first metavar in this matcher's sequence of\n-    /// token trees. In other words, the first metavar in the first token of `top_elts` corresponds\n-    /// to `matches[match_lo]`.\n+\n+    /// The position in `matches` of the first metavar in this (sub)matcher. Zero if there are\n+    /// no metavars.\n     match_lo: usize,\n-    /// The position in `matches` corresponding to the metavar we are currently trying to match\n-    /// against the source token stream. `match_lo <= match_cur <= match_hi`.\n+\n+    /// The position in `matches` of the next metavar to be matched against the source token\n+    /// stream. `match_lo <= match_cur <= match_hi`. Should not be used if there are no metavars,\n+    /// i.e. `match_lo == match_hi`.\n     match_cur: usize,\n-    /// Similar to `match_lo` except `match_hi` is the position in `matches` of the _last_ metavar\n-    /// in this matcher.\n+\n+    /// The position in `matches` one past the last metavar in this (sub)matcher. Equal to\n+    /// `match_lo` if there are not metavars.\n     match_hi: usize,\n \n-    /// This field is only used if we are matching a repetition.\n-    repetition: Option<MatcherPosRepetition<'tt>>,\n+    /// This field is only used if we are matching a sequence.\n+    sequence: Option<MatcherPosSequence<'tt>>,\n \n-    /// Specifically used to \"unzip\" token trees. By \"unzip\", we mean to unwrap the delimiters from\n-    /// a delimited token tree (e.g., something wrapped in `(` `)`) or to get the contents of a doc\n-    /// comment...\n-    ///\n-    /// When matching against matchers with nested delimited submatchers (e.g., `pat ( pat ( .. )\n-    /// pat ) pat`), we need to keep track of the matchers we are descending into. This stack does\n-    /// that where the bottom of the stack is the outermost matcher.\n-    /// Also, throughout the comments, this \"descent\" is often referred to as \"unzipping\"...\n-    stack: SmallVec<[MatcherTtFrame<'tt>; 1]>,\n+    /// When we are within a `Delimited` submatcher (or subsubmatcher), this tracks the parent\n+    /// matcher(s). The bottom of the stack is the top-level matcher.\n+    stack: SmallVec<[MatcherPosFrame<'tt>; 1]>,\n }\n \n // This type is used a lot. Make sure it doesn't unintentionally get bigger.\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n rustc_data_structures::static_assert_size!(MatcherPos<'_>, 112);\n \n impl<'tt> MatcherPos<'tt> {\n-    /// `len` `Vec`s (initially shared and empty) that will store matches of metavars.\n-    fn create_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n+    fn empty_matches(len: usize) -> Box<[Lrc<NamedMatchVec>]> {\n         if len == 0 {\n             vec![]\n         } else {\n@@ -174,42 +175,29 @@ impl<'tt> MatcherPos<'tt> {\n         .into_boxed_slice()\n     }\n \n-    /// Generates the top-level matcher position in which the \"dot\" is before the first token of\n-    /// the matcher `ms`.\n-    fn new(ms: &'tt [TokenTree]) -> Self {\n-        let match_idx_hi = count_metavar_decls(ms);\n+    fn top_level(matcher: &'tt [TokenTree]) -> Self {\n+        let match_idx_hi = count_metavar_decls(matcher);\n         MatcherPos {\n-            // Start with the top level matcher given to us.\n-            top_elts: ms,\n-\n-            // The \"dot\" is before the first token of the matcher.\n+            tts: matcher,\n             idx: 0,\n-\n-            // Initialize `matches` to a bunch of empty `Vec`s -- one for each metavar in\n-            // `top_elts`. `match_lo` for `top_elts` is 0 and `match_hi` is `match_idx_hi`.\n-            // `match_cur` is 0 since we haven't actually matched anything yet.\n-            matches: Self::create_matches(match_idx_hi),\n+            matches: Self::empty_matches(match_idx_hi),\n             match_lo: 0,\n             match_cur: 0,\n             match_hi: match_idx_hi,\n-\n-            // Haven't descended into any delimiters, so this is empty.\n             stack: smallvec![],\n-\n-            // Haven't descended into any sequences, so this is `None`.\n-            repetition: None,\n+            sequence: None,\n         }\n     }\n \n-    fn repetition(up: Box<MatcherPos<'tt>>, seq: &'tt SequenceRepetition) -> Self {\n+    fn sequence(parent: Box<MatcherPos<'tt>>, seq: &'tt SequenceRepetition) -> Self {\n         MatcherPos {\n-            top_elts: &seq.tts,\n+            tts: &seq.tts,\n             idx: 0,\n-            matches: Self::create_matches(up.matches.len()),\n-            match_lo: up.match_cur,\n-            match_cur: up.match_cur,\n-            match_hi: up.match_cur + seq.num_captures,\n-            repetition: Some(MatcherPosRepetition { up, seq }),\n+            matches: Self::empty_matches(parent.matches.len()),\n+            match_lo: parent.match_cur,\n+            match_cur: parent.match_cur,\n+            match_hi: parent.match_cur + seq.num_captures,\n+            sequence: Some(MatcherPosSequence { parent, seq }),\n             stack: smallvec![],\n         }\n     }\n@@ -222,16 +210,16 @@ impl<'tt> MatcherPos<'tt> {\n }\n \n #[derive(Clone)]\n-struct MatcherPosRepetition<'tt> {\n-    /// The \"parent\" matcher position. That is, the matcher position just before we enter the\n-    /// sequence.\n-    up: Box<MatcherPos<'tt>>,\n+struct MatcherPosSequence<'tt> {\n+    /// The parent matcher position. Effectively gives a linked list of matches all the way to the\n+    /// top-level matcher.\n+    parent: Box<MatcherPos<'tt>>,\n \n     /// The sequence itself.\n     seq: &'tt SequenceRepetition,\n }\n \n-enum EofItems<'tt> {\n+enum EofMatcherPositions<'tt> {\n     None,\n     One(Box<MatcherPos<'tt>>),\n     Multiple,\n@@ -331,11 +319,9 @@ crate enum NamedMatch {\n     MatchedNonterminal(Lrc<Nonterminal>),\n }\n \n-/// Takes a slice of token trees `ms` representing a matcher which successfully matched input\n-/// and an iterator of items that matched input and produces a `NamedParseResult`.\n fn nameize<I: Iterator<Item = NamedMatch>>(\n     sess: &ParseSess,\n-    ms: &[TokenTree],\n+    matcher: &[TokenTree],\n     mut res: I,\n ) -> NamedParseResult {\n     // Recursively descend into each type of matcher (e.g., sequences, delimited, metavars) and make\n@@ -344,11 +330,11 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n     // `NamedParseResult`.\n     fn n_rec<I: Iterator<Item = NamedMatch>>(\n         sess: &ParseSess,\n-        m: &TokenTree,\n+        tt: &TokenTree,\n         res: &mut I,\n         ret_val: &mut FxHashMap<MacroRulesNormalizedIdent, NamedMatch>,\n     ) -> Result<(), (rustc_span::Span, String)> {\n-        match *m {\n+        match *tt {\n             TokenTree::Sequence(_, ref seq) => {\n                 for next_m in &seq.tts {\n                     n_rec(sess, next_m, res.by_ref(), ret_val)?\n@@ -380,8 +366,8 @@ fn nameize<I: Iterator<Item = NamedMatch>>(\n     }\n \n     let mut ret_val = FxHashMap::default();\n-    for m in ms {\n-        match n_rec(sess, m, res.by_ref(), &mut ret_val) {\n+    for tt in matcher {\n+        match n_rec(sess, tt, res.by_ref(), &mut ret_val) {\n             Ok(_) => {}\n             Err((sp, msg)) => return Error(sp, msg),\n         }\n@@ -401,86 +387,82 @@ fn token_name_eq(t1: &Token, t2: &Token) -> bool {\n     }\n }\n \n-// Note: the item vectors could be created and dropped within `parse_tt`, but to avoid excess\n+// Note: the position vectors could be created and dropped within `parse_tt`, but to avoid excess\n // allocations we have a single vector fo each kind that is cleared and reused repeatedly.\n pub struct TtParser<'tt> {\n     macro_name: Ident,\n \n-    /// The set of current items to be processed. This should be empty by the end of a successful\n+    /// The set of current mps to be processed. This should be empty by the end of a successful\n     /// execution of `parse_tt_inner`.\n-    cur_items: Vec<Box<MatcherPos<'tt>>>,\n+    cur_mps: Vec<Box<MatcherPos<'tt>>>,\n \n-    /// The set of newly generated items. These are used to replenish `cur_items` in the function\n+    /// The set of newly generated mps. These are used to replenish `cur_mps` in the function\n     /// `parse_tt`.\n-    next_items: Vec<Box<MatcherPos<'tt>>>,\n+    next_mps: Vec<Box<MatcherPos<'tt>>>,\n \n-    /// The set of items that are waiting for the black-box parser.\n-    bb_items: Vec<Box<MatcherPos<'tt>>>,\n+    /// The set of mps that are waiting for the black-box parser.\n+    bb_mps: Vec<Box<MatcherPos<'tt>>>,\n }\n \n impl<'tt> TtParser<'tt> {\n     pub(super) fn new(macro_name: Ident) -> TtParser<'tt> {\n-        TtParser { macro_name, cur_items: vec![], next_items: vec![], bb_items: vec![] }\n+        TtParser { macro_name, cur_mps: vec![], next_mps: vec![], bb_mps: vec![] }\n     }\n \n-    /// Process the matcher positions of `cur_items` until it is empty. In the process, this will\n-    /// produce more items in `next_items` and `bb_items`.\n-    ///\n-    /// For more info about the how this happens, see the module-level doc comments and the inline\n-    /// comments of this function.\n+    /// Process the matcher positions of `cur_mps` until it is empty. In the process, this will\n+    /// produce more mps in `next_mps` and `bb_mps`.\n     ///\n     /// # Returns\n     ///\n     /// `Some(result)` if everything is finished, `None` otherwise. Note that matches are kept\n-    /// track of through the items generated.\n+    /// track of through the mps generated.\n     fn parse_tt_inner(\n         &mut self,\n         sess: &ParseSess,\n-        ms: &[TokenTree],\n+        matcher: &[TokenTree],\n         token: &Token,\n     ) -> Option<NamedParseResult> {\n         // Matcher positions that would be valid if the macro invocation was over now. Only\n         // modified if `token == Eof`.\n-        let mut eof_items = EofItems::None;\n-\n-        while let Some(mut item) = self.cur_items.pop() {\n-            // When unzipped trees end, remove them. This corresponds to backtracking out of a\n-            // delimited submatcher into which we already descended. When backtracking out again, we\n-            // need to advance the \"dot\" past the delimiters in the outer matcher.\n-            while item.idx >= item.top_elts.len() {\n-                match item.stack.pop() {\n-                    Some(MatcherTtFrame { elts, idx }) => {\n-                        item.top_elts = elts;\n-                        item.idx = idx + 1;\n+        let mut eof_mps = EofMatcherPositions::None;\n+\n+        while let Some(mut mp) = self.cur_mps.pop() {\n+            // Backtrack out of delimited submatcher when necessary. When backtracking out again,\n+            // we need to advance the \"dot\" past the delimiters in the parent matcher(s).\n+            while mp.idx >= mp.tts.len() {\n+                match mp.stack.pop() {\n+                    Some(MatcherPosFrame { tts, idx }) => {\n+                        mp.tts = tts;\n+                        mp.idx = idx + 1;\n                     }\n                     None => break,\n                 }\n             }\n \n-            // Get the current position of the \"dot\" (`idx`) in `item` and the number of token\n+            // Get the current position of the \"dot\" (`idx`) in `mp` and the number of token\n             // trees in the matcher (`len`).\n-            let idx = item.idx;\n-            let len = item.top_elts.len();\n+            let idx = mp.idx;\n+            let len = mp.tts.len();\n \n             if idx < len {\n                 // We are in the middle of a matcher. Compare the matcher's current tt against\n                 // `token`.\n-                match &item.top_elts[idx] {\n+                match &mp.tts[idx] {\n                     TokenTree::Sequence(_sp, seq) => {\n                         let op = seq.kleene.op;\n                         if op == mbe::KleeneOp::ZeroOrMore || op == mbe::KleeneOp::ZeroOrOne {\n                             // Allow for the possibility of zero matches of this sequence.\n-                            let mut new_item = item.clone();\n-                            new_item.match_cur += seq.num_captures;\n-                            new_item.idx += 1;\n-                            for idx in item.match_cur..item.match_cur + seq.num_captures {\n-                                new_item.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n+                            let mut new_mp = mp.clone();\n+                            new_mp.match_cur += seq.num_captures;\n+                            new_mp.idx += 1;\n+                            for idx in mp.match_cur..mp.match_cur + seq.num_captures {\n+                                new_mp.push_match(idx, MatchedSeq(Lrc::new(smallvec![])));\n                             }\n-                            self.cur_items.push(new_item);\n+                            self.cur_mps.push(new_mp);\n                         }\n \n                         // Allow for the possibility of one or more matches of this sequence.\n-                        self.cur_items.push(box MatcherPos::repetition(item, &seq));\n+                        self.cur_mps.push(box MatcherPos::sequence(mp, &seq));\n                     }\n \n                     &TokenTree::MetaVarDecl(span, _, None) => {\n@@ -497,22 +479,22 @@ impl<'tt> TtParser<'tt> {\n                         // We use the span of the metavariable declaration to determine any\n                         // edition-specific matching behavior for non-terminals.\n                         if Parser::nonterminal_may_begin_with(kind, token) {\n-                            self.bb_items.push(item);\n+                            self.bb_mps.push(mp);\n                         }\n                     }\n \n                     TokenTree::Delimited(_, delimited) => {\n                         // To descend into a delimited submatcher, we push the current matcher onto\n-                        // a stack and push a new item containing the submatcher onto `cur_items`.\n+                        // a stack and push a new mp containing the submatcher onto `cur_mps`.\n                         //\n                         // At the beginning of the loop, if we reach the end of the delimited\n                         // submatcher, we pop the stack to backtrack out of the descent. Note that\n                         // we use `all_tts` to include the open and close delimiter tokens.\n-                        let lower_elts = mem::replace(&mut item.top_elts, &delimited.all_tts);\n-                        let idx = item.idx;\n-                        item.stack.push(MatcherTtFrame { elts: lower_elts, idx });\n-                        item.idx = 0;\n-                        self.cur_items.push(item);\n+                        let tts = mem::replace(&mut mp.tts, &delimited.all_tts);\n+                        let idx = mp.idx;\n+                        mp.stack.push(MatcherPosFrame { tts, idx });\n+                        mp.idx = 0;\n+                        self.cur_mps.push(mp);\n                     }\n \n                     TokenTree::Token(t) => {\n@@ -524,65 +506,67 @@ impl<'tt> TtParser<'tt> {\n                         // If the token matches, we can just advance the parser.\n                         //\n                         // Otherwise, this match has failed, there is nothing to do, and hopefully\n-                        // another item in `cur_items` will match.\n+                        // another mp in `cur_mps` will match.\n                         if matches!(t, Token { kind: DocComment(..), .. }) {\n-                            item.idx += 1;\n-                            self.cur_items.push(item);\n+                            mp.idx += 1;\n+                            self.cur_mps.push(mp);\n                         } else if token_name_eq(&t, token) {\n-                            item.idx += 1;\n-                            self.next_items.push(item);\n+                            mp.idx += 1;\n+                            self.next_mps.push(mp);\n                         }\n                     }\n \n                     // These cannot appear in a matcher.\n                     TokenTree::MetaVar(..) | TokenTree::MetaVarExpr(..) => unreachable!(),\n                 }\n-            } else if let Some(repetition) = &item.repetition {\n-                // We are past the end of a repetition.\n+            } else if let Some(sequence) = &mp.sequence {\n+                // We are past the end of a sequence.\n                 debug_assert!(idx <= len + 1);\n \n                 if idx == len {\n-                    // Add all matches from the sequence to `up`, and move the \"dot\" past the\n-                    // repetition in `up`. This allows for the case where the sequence matching is\n-                    // finished.\n-                    let mut new_pos = repetition.up.clone();\n-                    for idx in item.match_lo..item.match_hi {\n-                        let sub = item.matches[idx].clone();\n-                        new_pos.push_match(idx, MatchedSeq(sub));\n+                    // Add all matches from the sequence to `parent`, and move the \"dot\" past the\n+                    // sequence in `parent`. This allows for the case where the sequence matching\n+                    // is finished.\n+                    let mut new_mp = sequence.parent.clone();\n+                    for idx in mp.match_lo..mp.match_hi {\n+                        let sub = mp.matches[idx].clone();\n+                        new_mp.push_match(idx, MatchedSeq(sub));\n                     }\n-                    new_pos.match_cur = item.match_hi;\n-                    new_pos.idx += 1;\n-                    self.cur_items.push(new_pos);\n+                    new_mp.match_cur = mp.match_hi;\n+                    new_mp.idx += 1;\n+                    self.cur_mps.push(new_mp);\n                 }\n \n-                if idx == len && repetition.seq.separator.is_some() {\n-                    if repetition\n+                if idx == len && sequence.seq.separator.is_some() {\n+                    if sequence\n                         .seq\n                         .separator\n                         .as_ref()\n                         .map_or(false, |sep| token_name_eq(token, sep))\n                     {\n                         // The matcher has a separator, and it matches the current token. We can\n                         // advance past the separator token.\n-                        item.idx += 1;\n-                        self.next_items.push(item);\n+                        mp.idx += 1;\n+                        self.next_mps.push(mp);\n                     }\n-                } else if repetition.seq.kleene.op != mbe::KleeneOp::ZeroOrOne {\n+                } else if sequence.seq.kleene.op != mbe::KleeneOp::ZeroOrOne {\n                     // We don't need a separator. Move the \"dot\" back to the beginning of the\n                     // matcher and try to match again UNLESS we are only allowed to have _one_\n                     // repetition.\n-                    item.match_cur = item.match_lo;\n-                    item.idx = 0;\n-                    self.cur_items.push(item);\n+                    mp.match_cur = mp.match_lo;\n+                    mp.idx = 0;\n+                    self.cur_mps.push(mp);\n                 }\n             } else {\n-                // We are past the end of the matcher, and not in a repetition. Look for end of\n+                // We are past the end of the matcher, and not in a sequence. Look for end of\n                 // input.\n                 debug_assert_eq!(idx, len);\n                 if *token == token::Eof {\n-                    eof_items = match eof_items {\n-                        EofItems::None => EofItems::One(item),\n-                        EofItems::One(_) | EofItems::Multiple => EofItems::Multiple,\n+                    eof_mps = match eof_mps {\n+                        EofMatcherPositions::None => EofMatcherPositions::One(mp),\n+                        EofMatcherPositions::One(_) | EofMatcherPositions::Multiple => {\n+                            EofMatcherPositions::Multiple\n+                        }\n                     }\n                 }\n             }\n@@ -591,21 +575,21 @@ impl<'tt> TtParser<'tt> {\n         // If we reached the end of input, check that there is EXACTLY ONE possible matcher.\n         // Otherwise, either the parse is ambiguous (which is an error) or there is a syntax error.\n         if *token == token::Eof {\n-            Some(match eof_items {\n-                EofItems::One(mut eof_item) => {\n-                    let matches = eof_item.matches.iter_mut().map(|dv| {\n+            Some(match eof_mps {\n+                EofMatcherPositions::One(mut eof_mp) => {\n+                    let matches = eof_mp.matches.iter_mut().map(|dv| {\n                         // Top-level metavars only ever get one match. (Sub-matchers can get\n                         // multiple matches, which get aggregated into a `MatcherSeq` before being\n                         // put into the top-level.)\n                         debug_assert_eq!(dv.len(), 1);\n                         Lrc::make_mut(dv).pop().unwrap()\n                     });\n-                    nameize(sess, ms, matches)\n+                    nameize(sess, matcher, matches)\n                 }\n-                EofItems::Multiple => {\n+                EofMatcherPositions::Multiple => {\n                     Error(token.span, \"ambiguity: multiple successful parses\".to_string())\n                 }\n-                EofItems::None => Failure(\n+                EofMatcherPositions::None => Failure(\n                     Token::new(\n                         token::Eof,\n                         if token.span.is_dummy() { token.span } else { token.span.shrink_to_hi() },\n@@ -618,36 +602,35 @@ impl<'tt> TtParser<'tt> {\n         }\n     }\n \n-    /// Use the given slice of token trees (`ms`) as a matcher. Match the token stream from the\n-    /// given `parser` against it and return the match.\n+    /// Match the token stream from `parser` against `matcher`.\n     pub(super) fn parse_tt(\n         &mut self,\n         parser: &mut Cow<'_, Parser<'_>>,\n-        ms: &'tt [TokenTree],\n+        matcher: &'tt [TokenTree],\n     ) -> NamedParseResult {\n         // A queue of possible matcher positions. We initialize it with the matcher position in\n-        // which the \"dot\" is before the first token of the first token tree in `ms`.\n+        // which the \"dot\" is before the first token of the first token tree in `matcher`.\n         // `parse_tt_inner` then processes all of these possible matcher positions and produces\n-        // possible next positions into `next_items`. After some post-processing, the contents of\n-        // `next_items` replenish `cur_items` and we start over again.\n-        self.cur_items.clear();\n-        self.cur_items.push(box MatcherPos::new(ms));\n+        // possible next positions into `next_mps`. After some post-processing, the contents of\n+        // `next_mps` replenish `cur_mps` and we start over again.\n+        self.cur_mps.clear();\n+        self.cur_mps.push(box MatcherPos::top_level(matcher));\n \n         loop {\n-            self.next_items.clear();\n-            self.bb_items.clear();\n+            self.next_mps.clear();\n+            self.bb_mps.clear();\n \n-            // Process `cur_items` until either we have finished the input or we need to get some\n+            // Process `cur_mps` until either we have finished the input or we need to get some\n             // parsing from the black-box parser done.\n-            if let Some(result) = self.parse_tt_inner(parser.sess, ms, &parser.token) {\n+            if let Some(result) = self.parse_tt_inner(parser.sess, matcher, &parser.token) {\n                 return result;\n             }\n \n-            // `parse_tt_inner` handled all cur_items, so it's empty.\n-            assert!(self.cur_items.is_empty());\n+            // `parse_tt_inner` handled all of `cur_mps`, so it's empty.\n+            assert!(self.cur_mps.is_empty());\n \n             // Error messages here could be improved with links to original rules.\n-            match (self.next_items.len(), self.bb_items.len()) {\n+            match (self.next_mps.len(), self.bb_mps.len()) {\n                 (0, 0) => {\n                     // There are no possible next positions AND we aren't waiting for the black-box\n                     // parser: syntax error.\n@@ -658,17 +641,17 @@ impl<'tt> TtParser<'tt> {\n                 }\n \n                 (_, 0) => {\n-                    // Dump all possible `next_items` into `cur_items` for the next iteration. Then\n+                    // Dump all possible `next_mps` into `cur_mps` for the next iteration. Then\n                     // process the next token.\n-                    self.cur_items.extend(self.next_items.drain(..));\n+                    self.cur_mps.extend(self.next_mps.drain(..));\n                     parser.to_mut().bump();\n                 }\n \n                 (0, 1) => {\n                     // We need to call the black-box parser to get some nonterminal.\n-                    let mut item = self.bb_items.pop().unwrap();\n-                    if let TokenTree::MetaVarDecl(span, _, Some(kind)) = item.top_elts[item.idx] {\n-                        let match_cur = item.match_cur;\n+                    let mut mp = self.bb_mps.pop().unwrap();\n+                    if let TokenTree::MetaVarDecl(span, _, Some(kind)) = mp.tts[mp.idx] {\n+                        let match_cur = mp.match_cur;\n                         // We use the span of the metavariable declaration to determine any\n                         // edition-specific matching behavior for non-terminals.\n                         let nt = match parser.to_mut().parse_nonterminal(kind) {\n@@ -688,13 +671,13 @@ impl<'tt> TtParser<'tt> {\n                             NtOrTt::Nt(nt) => MatchedNonterminal(Lrc::new(nt)),\n                             NtOrTt::Tt(tt) => MatchedTokenTree(tt),\n                         };\n-                        item.push_match(match_cur, m);\n-                        item.idx += 1;\n-                        item.match_cur += 1;\n+                        mp.push_match(match_cur, m);\n+                        mp.idx += 1;\n+                        mp.match_cur += 1;\n                     } else {\n                         unreachable!()\n                     }\n-                    self.cur_items.push(item);\n+                    self.cur_mps.push(mp);\n                 }\n \n                 (_, _) => {\n@@ -703,15 +686,15 @@ impl<'tt> TtParser<'tt> {\n                 }\n             }\n \n-            assert!(!self.cur_items.is_empty());\n+            assert!(!self.cur_mps.is_empty());\n         }\n     }\n \n     fn ambiguity_error(&self, token_span: rustc_span::Span) -> NamedParseResult {\n         let nts = self\n-            .bb_items\n+            .bb_mps\n             .iter()\n-            .map(|item| match item.top_elts[item.idx] {\n+            .map(|mp| match mp.tts[mp.idx] {\n                 TokenTree::MetaVarDecl(_, bind, Some(kind)) => {\n                     format!(\"{} ('{}')\", kind, bind)\n                 }\n@@ -725,7 +708,7 @@ impl<'tt> TtParser<'tt> {\n             format!(\n                 \"local ambiguity when calling macro `{}`: multiple parsing options: {}\",\n                 self.macro_name,\n-                match self.next_items.len() {\n+                match self.next_mps.len() {\n                     0 => format!(\"built-in NTs {}.\", nts),\n                     1 => format!(\"built-in NTs {} or 1 other option.\", nts),\n                     n => format!(\"built-in NTs {} or {} other options.\", nts, n),"}]}