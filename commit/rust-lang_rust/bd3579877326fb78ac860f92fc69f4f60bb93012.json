{"sha": "bd3579877326fb78ac860f92fc69f4f60bb93012", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJkMzU3OTg3NzMyNmZiNzhhYzg2MGY5MmZjNjlmNGY2MGJiOTMwMTI=", "commit": {"author": {"name": "Ben Blum", "email": "bblum@andrew.cmu.edu", "date": "2013-08-02T21:09:32Z"}, "committer": {"name": "Ben Blum", "email": "bblum@andrew.cmu.edu", "date": "2013-08-02T21:31:45Z"}, "message": "(cleanup) Use more do...finally in extra::sync.", "tree": {"sha": "76746d91dc3389bf805eafee2030dc2205d9fd49", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/76746d91dc3389bf805eafee2030dc2205d9fd49"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/bd3579877326fb78ac860f92fc69f4f60bb93012", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/bd3579877326fb78ac860f92fc69f4f60bb93012", "html_url": "https://github.com/rust-lang/rust/commit/bd3579877326fb78ac860f92fc69f4f60bb93012", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/bd3579877326fb78ac860f92fc69f4f60bb93012/comments", "author": {"login": "bblum", "id": 1820515, "node_id": "MDQ6VXNlcjE4MjA1MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1820515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bblum", "html_url": "https://github.com/bblum", "followers_url": "https://api.github.com/users/bblum/followers", "following_url": "https://api.github.com/users/bblum/following{/other_user}", "gists_url": "https://api.github.com/users/bblum/gists{/gist_id}", "starred_url": "https://api.github.com/users/bblum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bblum/subscriptions", "organizations_url": "https://api.github.com/users/bblum/orgs", "repos_url": "https://api.github.com/users/bblum/repos", "events_url": "https://api.github.com/users/bblum/events{/privacy}", "received_events_url": "https://api.github.com/users/bblum/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bblum", "id": 1820515, "node_id": "MDQ6VXNlcjE4MjA1MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/1820515?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bblum", "html_url": "https://github.com/bblum", "followers_url": "https://api.github.com/users/bblum/followers", "following_url": "https://api.github.com/users/bblum/following{/other_user}", "gists_url": "https://api.github.com/users/bblum/gists{/gist_id}", "starred_url": "https://api.github.com/users/bblum/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bblum/subscriptions", "organizations_url": "https://api.github.com/users/bblum/orgs", "repos_url": "https://api.github.com/users/bblum/repos", "events_url": "https://api.github.com/users/bblum/events{/privacy}", "received_events_url": "https://api.github.com/users/bblum/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d30cca46e61f8e5e604a87f0e623cb852be6c85f", "url": "https://api.github.com/repos/rust-lang/rust/commits/d30cca46e61f8e5e604a87f0e623cb852be6c85f", "html_url": "https://github.com/rust-lang/rust/commit/d30cca46e61f8e5e604a87f0e623cb852be6c85f"}], "stats": {"total": 315, "additions": 108, "deletions": 207}, "files": [{"sha": "276f9cad7c6d0ac8dfcf8a4559d3dd03ea8d5102", "filename": "src/libextra/sync.rs", "status": "modified", "additions": 102, "deletions": 207, "changes": 309, "blob_url": "https://github.com/rust-lang/rust/blob/bd3579877326fb78ac860f92fc69f4f60bb93012/src%2Flibextra%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bd3579877326fb78ac860f92fc69f4f60bb93012/src%2Flibextra%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Fsync.rs?ref=bd3579877326fb78ac860f92fc69f4f60bb93012", "patch": "@@ -22,7 +22,9 @@ use std::comm::SendDeferred;\n use std::task;\n use std::unstable::sync::{Exclusive, UnsafeAtomicRcBox};\n use std::unstable::atomics;\n+use std::unstable::finally::Finally;\n use std::util;\n+use std::util::NonCopyable;\n \n /****************************************************************************\n  * Internals\n@@ -84,7 +86,6 @@ struct SemInner<Q> {\n #[doc(hidden)]\n struct Sem<Q>(Exclusive<SemInner<Q>>);\n \n-\n #[doc(hidden)]\n impl<Q:Send> Sem<Q> {\n     fn new(count: int, q: Q) -> Sem<Q> {\n@@ -125,17 +126,18 @@ impl<Q:Send> Sem<Q> {\n             }\n         }\n     }\n-}\n-// FIXME(#3154) move both copies of this into Sem<Q>, and unify the 2 structs\n-#[doc(hidden)]\n-impl Sem<()> {\n+\n     pub fn access<U>(&self, blk: &fn() -> U) -> U {\n-        let mut release = None;\n         do task::unkillable {\n-            self.acquire();\n-            release = Some(SemRelease(self));\n+            do (|| {\n+                self.acquire();\n+                unsafe {\n+                    do task::rekillable { blk() }\n+                }\n+            }).finally {\n+                self.release();\n+            }\n         }\n-        blk()\n     }\n }\n \n@@ -149,46 +151,6 @@ impl Sem<~[WaitQueue]> {\n         }\n         Sem::new(count, queues)\n     }\n-\n-    pub fn access_waitqueue<U>(&self, blk: &fn() -> U) -> U {\n-        let mut release = None;\n-        do task::unkillable {\n-            self.acquire();\n-            release = Some(SemAndSignalRelease(self));\n-        }\n-        blk()\n-    }\n-}\n-\n-// FIXME(#3588) should go inside of access()\n-#[doc(hidden)]\n-type SemRelease<'self> = SemReleaseGeneric<'self, ()>;\n-#[doc(hidden)]\n-type SemAndSignalRelease<'self> = SemReleaseGeneric<'self, ~[WaitQueue]>;\n-#[doc(hidden)]\n-struct SemReleaseGeneric<'self, Q> { sem: &'self Sem<Q> }\n-\n-#[doc(hidden)]\n-#[unsafe_destructor]\n-impl<'self, Q:Send> Drop for SemReleaseGeneric<'self, Q> {\n-    fn drop(&self) {\n-        self.sem.release();\n-    }\n-}\n-\n-#[doc(hidden)]\n-fn SemRelease<'r>(sem: &'r Sem<()>) -> SemRelease<'r> {\n-    SemReleaseGeneric {\n-        sem: sem\n-    }\n-}\n-\n-#[doc(hidden)]\n-fn SemAndSignalRelease<'r>(sem: &'r Sem<~[WaitQueue]>)\n-                        -> SemAndSignalRelease<'r> {\n-    SemReleaseGeneric {\n-        sem: sem\n-    }\n }\n \n // FIXME(#3598): Want to use an Option down below, but we need a custom enum\n@@ -211,11 +173,10 @@ pub struct Condvar<'self> {\n     // writer waking up from a cvar wait can't race with a reader to steal it,\n     // See the comment in write_cond for more detail.\n     priv order: ReacquireOrderLock<'self>,\n+    // Make sure condvars are non-copyable.\n+    priv token: util::NonCopyable,\n }\n \n-#[unsafe_destructor]\n-impl<'self> Drop for Condvar<'self> { fn drop(&self) {} }\n-\n impl<'self> Condvar<'self> {\n     /**\n      * Atomically drop the associated lock, and block until a signal is sent.\n@@ -243,11 +204,10 @@ impl<'self> Condvar<'self> {\n         let (WaitEnd, SignalEnd) = comm::oneshot();\n         let mut WaitEnd   = Some(WaitEnd);\n         let mut SignalEnd = Some(SignalEnd);\n-        let mut reacquire = None;\n         let mut out_of_bounds = None;\n-        unsafe {\n-            do task::unkillable {\n-                // Release lock, 'atomically' enqueuing ourselves in so doing.\n+        do task::unkillable {\n+            // Release lock, 'atomically' enqueuing ourselves in so doing.\n+            unsafe {\n                 do (**self.sem).with |state| {\n                     if condvar_id < state.blocked.len() {\n                         // Drop the lock.\n@@ -262,37 +222,25 @@ impl<'self> Condvar<'self> {\n                         out_of_bounds = Some(state.blocked.len());\n                     }\n                 }\n-\n-                // If yield checks start getting inserted anywhere, we can be\n-                // killed before or after enqueueing. Deciding whether to\n-                // unkillably reacquire the lock needs to happen atomically\n-                // wrt enqueuing.\n-                if out_of_bounds.is_none() {\n-                    reacquire = Some(CondvarReacquire { sem:   self.sem,\n-                                                        order: self.order });\n-                }\n             }\n-        }\n-        do check_cvar_bounds(out_of_bounds, condvar_id, \"cond.wait_on()\") {\n-            // Unconditionally \"block\". (Might not actually block if a\n-            // signaller already sent -- I mean 'unconditionally' in contrast\n-            // with acquire().)\n-            let _ = comm::recv_one(WaitEnd.take_unwrap());\n-        }\n \n-        // This is needed for a failing condition variable to reacquire the\n-        // mutex during unwinding. As long as the wrapper (mutex, etc) is\n-        // bounded in when it gets released, this shouldn't hang forever.\n-        struct CondvarReacquire<'self> {\n-            sem: &'self Sem<~[WaitQueue]>,\n-            order: ReacquireOrderLock<'self>,\n-        }\n-\n-        #[unsafe_destructor]\n-        impl<'self> Drop for CondvarReacquire<'self> {\n-            fn drop(&self) {\n-                // Needs to succeed, instead of itself dying.\n-                do task::unkillable {\n+            // If yield checks start getting inserted anywhere, we can be\n+            // killed before or after enqueueing. Deciding whether to\n+            // unkillably reacquire the lock needs to happen atomically\n+            // wrt enqueuing.\n+            do check_cvar_bounds(out_of_bounds, condvar_id, \"cond.wait_on()\") {\n+                // Unconditionally \"block\". (Might not actually block if a\n+                // signaller already sent -- I mean 'unconditionally' in contrast\n+                // with acquire().)\n+                do (|| {\n+                    unsafe {\n+                        do task::rekillable {\n+                            let _ = comm::recv_one(WaitEnd.take_unwrap());\n+                        }\n+                    }\n+                }).finally {\n+                    // Reacquire the condvar. Note this is back in the unkillable\n+                    // section; it needs to succeed, instead of itself dying.\n                     match self.order {\n                         Just(lock) => do lock.access {\n                             self.sem.acquire();\n@@ -374,8 +322,8 @@ impl Sem<~[WaitQueue]> {\n     // The only other places that condvars get built are rwlock.write_cond()\n     // and rwlock_write_mode.\n     pub fn access_cond<U>(&self, blk: &fn(c: &Condvar) -> U) -> U {\n-        do self.access_waitqueue {\n-            blk(&Condvar { sem: self, order: Nothing })\n+        do self.access {\n+            blk(&Condvar { sem: self, order: Nothing, token: NonCopyable::new() })\n         }\n     }\n }\n@@ -453,7 +401,7 @@ impl Mutex {\n \n     /// Run a function with ownership of the mutex.\n     pub fn lock<U>(&self, blk: &fn() -> U) -> U {\n-        (&self.sem).access_waitqueue(blk)\n+        (&self.sem).access(blk)\n     }\n \n     /// Run a function with ownership of the mutex and a handle to a condvar.\n@@ -532,7 +480,6 @@ impl RWLock {\n      * tasks may run concurrently with this one.\n      */\n     pub fn read<U>(&self, blk: &fn() -> U) -> U {\n-        let mut release = None;\n         unsafe {\n             do task::unkillable {\n                 do (&self.order_lock).access {\n@@ -543,10 +490,24 @@ impl RWLock {\n                         state.read_mode = true;\n                     }\n                 }\n-                release = Some(RWLockReleaseRead(self));\n+                do (|| {\n+                    do task::rekillable { blk() }\n+                }).finally {\n+                    let state = &mut *self.state.get();\n+                    assert!(state.read_mode);\n+                    let old_count = state.read_count.fetch_sub(1, atomics::Release);\n+                    assert!(old_count > 0);\n+                    if old_count == 1 {\n+                        state.read_mode = false;\n+                        // Note: this release used to be outside of a locked access\n+                        // to exclusive-protected state. If this code is ever\n+                        // converted back to such (instead of using atomic ops),\n+                        // this access MUST NOT go inside the exclusive access.\n+                        (&self.access_lock).release();\n+                    }\n+                }\n             }\n         }\n-        blk()\n     }\n \n     /**\n@@ -557,7 +518,7 @@ impl RWLock {\n         unsafe {\n             do task::unkillable {\n                 (&self.order_lock).acquire();\n-                do (&self.access_lock).access_waitqueue {\n+                do (&self.access_lock).access {\n                     (&self.order_lock).release();\n                     do task::rekillable {\n                         blk()\n@@ -607,7 +568,8 @@ impl RWLock {\n                     (&self.order_lock).release();\n                     do task::rekillable {\n                         let opt_lock = Just(&self.order_lock);\n-                        blk(&Condvar { order: opt_lock, ..*cond })\n+                        blk(&Condvar { sem: cond.sem, order: opt_lock,\n+                                       token: NonCopyable::new() })\n                     }\n                 }\n             }\n@@ -638,14 +600,43 @@ impl RWLock {\n     pub fn write_downgrade<U>(&self, blk: &fn(v: RWLockWriteMode) -> U) -> U {\n         // Implementation slightly different from the slicker 'write's above.\n         // The exit path is conditional on whether the caller downgrades.\n-        let mut _release = None;\n         do task::unkillable {\n             (&self.order_lock).acquire();\n             (&self.access_lock).acquire();\n             (&self.order_lock).release();\n+            do (|| {\n+                unsafe {\n+                    do task::rekillable {\n+                        blk(RWLockWriteMode { lock: self, token: NonCopyable::new() })\n+                    }\n+                }\n+            }).finally {\n+                let writer_or_last_reader;\n+                // Check if we're releasing from read mode or from write mode.\n+                let state = unsafe { &mut *self.state.get() };\n+                if state.read_mode {\n+                    // Releasing from read mode.\n+                    let old_count = state.read_count.fetch_sub(1, atomics::Release);\n+                    assert!(old_count > 0);\n+                    // Check if other readers remain.\n+                    if old_count == 1 {\n+                        // Case 1: Writer downgraded & was the last reader\n+                        writer_or_last_reader = true;\n+                        state.read_mode = false;\n+                    } else {\n+                        // Case 2: Writer downgraded & was not the last reader\n+                        writer_or_last_reader = false;\n+                    }\n+                } else {\n+                    // Case 3: Writer did not downgrade\n+                    writer_or_last_reader = true;\n+                }\n+                if writer_or_last_reader {\n+                    // Nobody left inside; release the \"reader cloud\" lock.\n+                    (&self.access_lock).release();\n+                }\n+            }\n         }\n-        _release = Some(RWLockReleaseDowngrade(self));\n-        blk(RWLockWriteMode { lock: self })\n     }\n \n     /// To be called inside of the write_downgrade block.\n@@ -674,105 +665,16 @@ impl RWLock {\n                 }\n             }\n         }\n-        RWLockReadMode { lock: token.lock }\n-    }\n-}\n-\n-// FIXME(#3588) should go inside of read()\n-#[doc(hidden)]\n-struct RWLockReleaseRead<'self> {\n-    lock: &'self RWLock,\n-}\n-\n-#[doc(hidden)]\n-#[unsafe_destructor]\n-impl<'self> Drop for RWLockReleaseRead<'self> {\n-    fn drop(&self) {\n-        unsafe {\n-            do task::unkillable {\n-                let state = &mut *self.lock.state.get();\n-                assert!(state.read_mode);\n-                let old_count = state.read_count.fetch_sub(1, atomics::Release);\n-                assert!(old_count > 0);\n-                if old_count == 1 {\n-                    state.read_mode = false;\n-                    // Note: this release used to be outside of a locked access\n-                    // to exclusive-protected state. If this code is ever\n-                    // converted back to such (instead of using atomic ops),\n-                    // this access MUST NOT go inside the exclusive access.\n-                    (&self.lock.access_lock).release();\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-#[doc(hidden)]\n-fn RWLockReleaseRead<'r>(lock: &'r RWLock) -> RWLockReleaseRead<'r> {\n-    RWLockReleaseRead {\n-        lock: lock\n-    }\n-}\n-\n-// FIXME(#3588) should go inside of downgrade()\n-#[doc(hidden)]\n-#[unsafe_destructor]\n-struct RWLockReleaseDowngrade<'self> {\n-    lock: &'self RWLock,\n-}\n-\n-#[doc(hidden)]\n-#[unsafe_destructor]\n-impl<'self> Drop for RWLockReleaseDowngrade<'self> {\n-    fn drop(&self) {\n-        unsafe {\n-            do task::unkillable {\n-                let writer_or_last_reader;\n-                // Check if we're releasing from read mode or from write mode.\n-                let state = &mut *self.lock.state.get();\n-                if state.read_mode {\n-                    // Releasing from read mode.\n-                    let old_count = state.read_count.fetch_sub(1, atomics::Release);\n-                    assert!(old_count > 0);\n-                    // Check if other readers remain.\n-                    if old_count == 1 {\n-                        // Case 1: Writer downgraded & was the last reader\n-                        writer_or_last_reader = true;\n-                        state.read_mode = false;\n-                    } else {\n-                        // Case 2: Writer downgraded & was not the last reader\n-                        writer_or_last_reader = false;\n-                    }\n-                } else {\n-                    // Case 3: Writer did not downgrade\n-                    writer_or_last_reader = true;\n-                }\n-                if writer_or_last_reader {\n-                    // Nobody left inside; release the \"reader cloud\" lock.\n-                    (&self.lock.access_lock).release();\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-#[doc(hidden)]\n-fn RWLockReleaseDowngrade<'r>(lock: &'r RWLock)\n-                           -> RWLockReleaseDowngrade<'r> {\n-    RWLockReleaseDowngrade {\n-        lock: lock\n+        RWLockReadMode { lock: token.lock, token: NonCopyable::new() }\n     }\n }\n \n /// The \"write permission\" token used for rwlock.write_downgrade().\n-pub struct RWLockWriteMode<'self> { priv lock: &'self RWLock }\n-#[unsafe_destructor]\n-impl<'self> Drop for RWLockWriteMode<'self> { fn drop(&self) {} }\n+pub struct RWLockWriteMode<'self> { priv lock: &'self RWLock, priv token: NonCopyable }\n \n /// The \"read permission\" token used for rwlock.write_downgrade().\n-pub struct RWLockReadMode<'self> { priv lock: &'self RWLock }\n-#[unsafe_destructor]\n-impl<'self> Drop for RWLockReadMode<'self> { fn drop(&self) {} }\n+pub struct RWLockReadMode<'self> { priv lock: &'self RWLock,\n+                                   priv token: NonCopyable }\n \n impl<'self> RWLockWriteMode<'self> {\n     /// Access the pre-downgrade rwlock in write mode.\n@@ -782,7 +684,8 @@ impl<'self> RWLockWriteMode<'self> {\n         // Need to make the condvar use the order lock when reacquiring the\n         // access lock. See comment in RWLock::write_cond for why.\n         blk(&Condvar { sem:        &self.lock.access_lock,\n-                       order: Just(&self.lock.order_lock), })\n+                       order: Just(&self.lock.order_lock),\n+                       token: NonCopyable::new() })\n     }\n }\n \n@@ -1060,6 +963,8 @@ mod tests {\n     }\n     #[test] #[ignore(cfg(windows))]\n     fn test_mutex_killed_broadcast() {\n+        use std::unstable::finally::Finally;\n+\n         let m = ~Mutex::new();\n         let m2 = ~m.clone();\n         let (p,c) = comm::stream();\n@@ -1076,8 +981,13 @@ mod tests {\n                     do mi.lock_cond |cond| {\n                         let c = c.take();\n                         c.send(()); // tell sibling to go ahead\n-                        let _z = SendOnFailure(c);\n-                        cond.wait(); // block forever\n+                        do (|| {\n+                            cond.wait(); // block forever\n+                        }).finally {\n+                            error!(\"task unwinding and sending\");\n+                            c.send(());\n+                            error!(\"task unwinding and done sending\");\n+                        }\n                     }\n                 }\n             }\n@@ -1096,21 +1006,6 @@ mod tests {\n             let woken = cond.broadcast();\n             assert_eq!(woken, 0);\n         }\n-        struct SendOnFailure {\n-            c: comm::Chan<()>,\n-        }\n-\n-        impl Drop for SendOnFailure {\n-            fn drop(&self) {\n-                self.c.send(());\n-            }\n-        }\n-\n-        fn SendOnFailure(c: comm::Chan<()>) -> SendOnFailure {\n-            SendOnFailure {\n-                c: c\n-            }\n-        }\n     }\n     #[test]\n     fn test_mutex_cond_signal_on_0() {"}, {"sha": "b46876ad3fe44db96389a84194f9be1ac2009680", "filename": "src/libstd/util.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/bd3579877326fb78ac860f92fc69f4f60bb93012/src%2Flibstd%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/bd3579877326fb78ac860f92fc69f4f60bb93012/src%2Flibstd%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Futil.rs?ref=bd3579877326fb78ac860f92fc69f4f60bb93012", "patch": "@@ -79,6 +79,12 @@ pub fn replace<T>(dest: &mut T, mut src: T) -> T {\n #[unsafe_no_drop_flag]\n pub struct NonCopyable;\n \n+impl NonCopyable {\n+    // FIXME(#8233) should not be necessary\n+    /// Create a new noncopyable token.\n+    pub fn new() -> NonCopyable { NonCopyable }\n+}\n+\n impl Drop for NonCopyable {\n     fn drop(&self) { }\n }"}]}