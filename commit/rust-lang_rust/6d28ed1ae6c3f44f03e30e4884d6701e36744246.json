{"sha": "6d28ed1ae6c3f44f03e30e4884d6701e36744246", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZkMjhlZDFhZTZjM2Y0NGYwM2UzMGU0ODg0ZDY3MDFlMzY3NDQyNDY=", "commit": {"author": {"name": "Tyler Mandry", "email": "tmandry@gmail.com", "date": "2019-10-15T00:52:35Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-10-15T00:52:35Z"}, "message": "Rollup merge of #65261 - nnethercote:rm-Option-from-TokenStream, r=petrochenkov\n\nRemove `Option` from `TokenStream`\n\nA code simplification.\n\nr? @petrochenkov", "tree": {"sha": "a0d427b499474c674bec40a57bb905ddbc64556c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a0d427b499474c674bec40a57bb905ddbc64556c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6d28ed1ae6c3f44f03e30e4884d6701e36744246", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJdpRhTCRBK7hj4Ov3rIwAAdHIIAKLX3JWBzhK9jxrKVbDCANW9\nZ4TSILBfa3AjM14p75DGO0pO0EINZZmLoIcbFicSP5hZgUpSLS8cCyH12x9L4WiH\nHAYckjZa/hE2dsZcuKEmy1p75ckN9fy59NfXkdFjS/56hGWiE1CFhfzVuaAkxpf8\n0pX4A0lKCNTg+dvFaPShykVVLqtU0osb2eNF8dayHGPhghZuzBvPDYSQPN6VxSWt\ngnwDqeXC+4xWyj+isr7tnstL3icKxI2TH4Y6+f1ubV4B9hZHgFJUixvriklKqcU/\nL80p1aqTNHQ67hsnPNKObU6iJpJU4lvMHEAH/SjYrvb9lQ0jDC+akyOVjRU1rCc=\n=hbWy\n-----END PGP SIGNATURE-----\n", "payload": "tree a0d427b499474c674bec40a57bb905ddbc64556c\nparent a9a4d4033d3d5b4d8ad2593088196114f7254eda\nparent 18b48bf4b9158611cd77bd5fae123a5fa3f052a5\nauthor Tyler Mandry <tmandry@gmail.com> 1571100755 -0700\ncommitter GitHub <noreply@github.com> 1571100755 -0700\n\nRollup merge of #65261 - nnethercote:rm-Option-from-TokenStream, r=petrochenkov\n\nRemove `Option` from `TokenStream`\n\nA code simplification.\n\nr? @petrochenkov\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6d28ed1ae6c3f44f03e30e4884d6701e36744246", "html_url": "https://github.com/rust-lang/rust/commit/6d28ed1ae6c3f44f03e30e4884d6701e36744246", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6d28ed1ae6c3f44f03e30e4884d6701e36744246/comments", "author": {"login": "tmandry", "id": 2280544, "node_id": "MDQ6VXNlcjIyODA1NDQ=", "avatar_url": "https://avatars.githubusercontent.com/u/2280544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tmandry", "html_url": "https://github.com/tmandry", "followers_url": "https://api.github.com/users/tmandry/followers", "following_url": "https://api.github.com/users/tmandry/following{/other_user}", "gists_url": "https://api.github.com/users/tmandry/gists{/gist_id}", "starred_url": "https://api.github.com/users/tmandry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tmandry/subscriptions", "organizations_url": "https://api.github.com/users/tmandry/orgs", "repos_url": "https://api.github.com/users/tmandry/repos", "events_url": "https://api.github.com/users/tmandry/events{/privacy}", "received_events_url": "https://api.github.com/users/tmandry/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a9a4d4033d3d5b4d8ad2593088196114f7254eda", "url": "https://api.github.com/repos/rust-lang/rust/commits/a9a4d4033d3d5b4d8ad2593088196114f7254eda", "html_url": "https://github.com/rust-lang/rust/commit/a9a4d4033d3d5b4d8ad2593088196114f7254eda"}, {"sha": "18b48bf4b9158611cd77bd5fae123a5fa3f052a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/18b48bf4b9158611cd77bd5fae123a5fa3f052a5", "html_url": "https://github.com/rust-lang/rust/commit/18b48bf4b9158611cd77bd5fae123a5fa3f052a5"}], "stats": {"total": 264, "additions": 110, "deletions": 154}, "files": [{"sha": "c2c883fd20e7adbe6104108a6aec71faa25961b4", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -551,7 +551,7 @@ impl MetaItem {\n impl MetaItemKind {\n     pub fn tokens(&self, span: Span) -> TokenStream {\n         match *self {\n-            MetaItemKind::Word => TokenStream::empty(),\n+            MetaItemKind::Word => TokenStream::default(),\n             MetaItemKind::NameValue(ref lit) => {\n                 let mut vec = vec![TokenTree::token(token::Eq, span).into()];\n                 lit.tokens().append_to_tree_and_joint_vec(&mut vec);"}, {"sha": "9fcd918cef1746050dc7b1c95e824cfdf4efca4c", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -676,12 +676,12 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                 }\n             }\n             Some(TokenTree::Token(..)) => {}\n-            None => return TokenStream::empty(),\n+            None => return TokenStream::default(),\n         }\n         self.cx.span_err(span, \"custom attribute invocations must be \\\n             of the form `#[foo]` or `#[foo(..)]`, the macro name must only be \\\n             followed by a delimiter token\");\n-        TokenStream::empty()\n+        TokenStream::default()\n     }\n \n     fn gate_proc_macro_attr_item(&self, span: Span, item: &Annotatable) {"}, {"sha": "da930436d817b6d57a474a4270f9c58766bf2835", "filename": "src/libsyntax/ext/mbe/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -95,7 +95,7 @@ pub(super) fn transcribe(\n ) -> TokenStream {\n     // Nothing for us to transcribe...\n     if src.is_empty() {\n-        return TokenStream::empty();\n+        return TokenStream::default();\n     }\n \n     // We descend into the RHS (`src`), expanding things as we go. This stack contains the things"}, {"sha": "4fae25bbde62cc20ce7fd48611cb22a586946fdc", "filename": "src/libsyntax/ext/placeholders.rs", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fplaceholders.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fplaceholders.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fplaceholders.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -15,7 +15,7 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n     fn mac_placeholder() -> ast::Mac {\n         ast::Mac {\n             path: ast::Path { span: DUMMY_SP, segments: Vec::new() },\n-            tts: TokenStream::empty().into(),\n+            tts: TokenStream::default().into(),\n             delim: ast::MacDelimiter::Brace,\n             span: DUMMY_SP,\n             prior_type_ascription: None,\n@@ -32,12 +32,12 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n         attrs: ThinVec::new(),\n         kind: ast::ExprKind::Mac(mac_placeholder()),\n     });\n-    let ty = P(ast::Ty {\n+    let ty = || P(ast::Ty {\n         id,\n         kind: ast::TyKind::Mac(mac_placeholder()),\n         span,\n     });\n-    let pat = P(ast::Pat {\n+    let pat = || P(ast::Pat {\n         id,\n         kind: ast::PatKind::Mac(mac_placeholder()),\n         span,\n@@ -83,7 +83,7 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n                 body: expr_placeholder(),\n                 guard: None,\n                 id,\n-                pat,\n+                pat: pat(),\n                 span,\n                 is_placeholder: true,\n             }\n@@ -105,7 +105,7 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n                 id,\n                 ident,\n                 is_shorthand: false,\n-                pat,\n+                pat: pat(),\n                 span,\n                 is_placeholder: true,\n             }\n@@ -124,9 +124,9 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n             ast::Param {\n                 attrs: Default::default(),\n                 id,\n-                pat,\n+                pat: pat(),\n                 span,\n-                ty,\n+                ty: ty(),\n                 is_placeholder: true,\n             }\n         ]),\n@@ -136,7 +136,7 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n                 id,\n                 ident: None,\n                 span,\n-                ty,\n+                ty: ty(),\n                 vis,\n                 is_placeholder: true,\n             }"}, {"sha": "08142ba6c58c5bb343e476bd390ca5a24d65973d", "filename": "src/libsyntax/ext/proc_macro_server.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -394,7 +394,7 @@ impl server::Types for Rustc<'_> {\n \n impl server::TokenStream for Rustc<'_> {\n     fn new(&mut self) -> Self::TokenStream {\n-        TokenStream::empty()\n+        TokenStream::default()\n     }\n     fn is_empty(&mut self, stream: &Self::TokenStream) -> bool {\n         stream.is_empty()"}, {"sha": "60ee17d09b7557dcb42cbceb6fe1abdd0632737d", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -610,10 +610,8 @@ pub fn noop_visit_tt<T: MutVisitor>(tt: &mut TokenTree, vis: &mut T) {\n }\n \n pub fn noop_visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &mut T) {\n-    visit_opt(tts, |tts| {\n-        let tts = Lrc::make_mut(tts);\n-        visit_vec(tts, |(tree, _is_joint)| vis.visit_tt(tree));\n-    })\n+    let tts = Lrc::make_mut(tts);\n+    visit_vec(tts, |(tree, _is_joint)| vis.visit_tt(tree));\n }\n \n // Applies ident visitor if it's an ident; applies other visits to interpolated nodes."}, {"sha": "0963efcfc8ac082610d73722eb80b1f3d11f1ce3", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -203,7 +203,7 @@ impl<'a> Parser<'a> {\n                 };\n                 TokenStream::from_streams(smallvec![eq.into(), tokens])\n             } else {\n-                TokenStream::empty()\n+                TokenStream::default()\n             };\n             ast::AttrItem { path, tokens }\n         })"}, {"sha": "478cfefc2247bdc74b682115499874732112f7b9", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -1273,7 +1273,7 @@ impl<'a> Parser<'a> {\n             // This can happen due to a bad interaction of two unrelated recovery mechanisms with\n             // mismatched delimiters *and* recovery lookahead on the likely typo `pub ident(`\n             // (#62881).\n-            return Ok((ret?, TokenStream::new(vec![])));\n+            return Ok((ret?, TokenStream::default()));\n         } else {\n             &mut self.token_cursor.stack[prev].last_token\n         };\n@@ -1288,7 +1288,7 @@ impl<'a> Parser<'a> {\n                 // This can happen due to a bad interaction of two unrelated recovery mechanisms\n                 // with mismatched delimiters *and* recovery lookahead on the likely typo\n                 // `pub ident(` (#62895, different but similar to the case above).\n-                return Ok((ret?, TokenStream::new(vec![])));\n+                return Ok((ret?, TokenStream::default()));\n             }\n         };\n "}, {"sha": "0ff1c26bac2b277a2a311e0a50f81b7a393b14f6", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 91, "deletions": 133, "changes": 224, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -136,13 +136,8 @@ impl TokenTree {\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n-///\n-/// The use of `Option` is an optimization that avoids the need for an\n-/// allocation when the stream is empty. However, it is not guaranteed that an\n-/// empty stream is represented with `None`; it may be represented as a `Some`\n-/// around an empty `Vec`.\n-#[derive(Clone, Debug)]\n-pub struct TokenStream(pub Option<Lrc<Vec<TreeAndJoint>>>);\n+#[derive(Clone, Debug, Default)]\n+pub struct TokenStream(pub Lrc<Vec<TreeAndJoint>>);\n \n pub type TreeAndJoint = (TokenTree, IsJoint);\n \n@@ -163,36 +158,34 @@ impl TokenStream {\n     /// separating the two arguments with a comma for diagnostic suggestions.\n     pub(crate) fn add_comma(&self) -> Option<(TokenStream, Span)> {\n         // Used to suggest if a user writes `foo!(a b);`\n-        if let Some(ref stream) = self.0 {\n-            let mut suggestion = None;\n-            let mut iter = stream.iter().enumerate().peekable();\n-            while let Some((pos, ts)) = iter.next() {\n-                if let Some((_, next)) = iter.peek() {\n-                    let sp = match (&ts, &next) {\n-                        (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n-                        ((TokenTree::Token(token_left), NonJoint),\n-                         (TokenTree::Token(token_right), _))\n-                        if ((token_left.is_ident() && !token_left.is_reserved_ident())\n-                            || token_left.is_lit()) &&\n-                            ((token_right.is_ident() && !token_right.is_reserved_ident())\n-                            || token_right.is_lit()) => token_left.span,\n-                        ((TokenTree::Delimited(sp, ..), NonJoint), _) => sp.entire(),\n-                        _ => continue,\n-                    };\n-                    let sp = sp.shrink_to_hi();\n-                    let comma = (TokenTree::token(token::Comma, sp), NonJoint);\n-                    suggestion = Some((pos, comma, sp));\n-                }\n-            }\n-            if let Some((pos, comma, sp)) = suggestion {\n-                let mut new_stream = vec![];\n-                let parts = stream.split_at(pos + 1);\n-                new_stream.extend_from_slice(parts.0);\n-                new_stream.push(comma);\n-                new_stream.extend_from_slice(parts.1);\n-                return Some((TokenStream::new(new_stream), sp));\n+        let mut suggestion = None;\n+        let mut iter = self.0.iter().enumerate().peekable();\n+        while let Some((pos, ts)) = iter.next() {\n+            if let Some((_, next)) = iter.peek() {\n+                let sp = match (&ts, &next) {\n+                    (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n+                    ((TokenTree::Token(token_left), NonJoint),\n+                     (TokenTree::Token(token_right), _))\n+                    if ((token_left.is_ident() && !token_left.is_reserved_ident())\n+                        || token_left.is_lit()) &&\n+                        ((token_right.is_ident() && !token_right.is_reserved_ident())\n+                        || token_right.is_lit()) => token_left.span,\n+                    ((TokenTree::Delimited(sp, ..), NonJoint), _) => sp.entire(),\n+                    _ => continue,\n+                };\n+                let sp = sp.shrink_to_hi();\n+                let comma = (TokenTree::token(token::Comma, sp), NonJoint);\n+                suggestion = Some((pos, comma, sp));\n             }\n         }\n+        if let Some((pos, comma, sp)) = suggestion {\n+            let mut new_stream = vec![];\n+            let parts = self.0.split_at(pos + 1);\n+            new_stream.extend_from_slice(parts.0);\n+            new_stream.push(comma);\n+            new_stream.extend_from_slice(parts.1);\n+            return Some((TokenStream::new(new_stream), sp));\n+        }\n         None\n     }\n }\n@@ -224,28 +217,21 @@ impl PartialEq<TokenStream> for TokenStream {\n }\n \n impl TokenStream {\n-    pub fn len(&self) -> usize {\n-        if let Some(ref slice) = self.0 {\n-            slice.len()\n-        } else {\n-            0\n-        }\n+    pub fn new(streams: Vec<TreeAndJoint>) -> TokenStream {\n+        TokenStream(Lrc::new(streams))\n     }\n \n-    pub fn empty() -> TokenStream {\n-        TokenStream(None)\n+    pub fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n     }\n \n-    pub fn is_empty(&self) -> bool {\n-        match self.0 {\n-            None => true,\n-            Some(ref stream) => stream.is_empty(),\n-        }\n+    pub fn len(&self) -> usize {\n+        self.0.len()\n     }\n \n     pub(crate) fn from_streams(mut streams: SmallVec<[TokenStream; 2]>) -> TokenStream {\n         match streams.len() {\n-            0 => TokenStream::empty(),\n+            0 => TokenStream::default(),\n             1 => streams.pop().unwrap(),\n             _ => {\n                 // We are going to extend the first stream in `streams` with\n@@ -269,41 +255,24 @@ impl TokenStream {\n                 // Get the first stream. If it's `None`, create an empty\n                 // stream.\n                 let mut iter = streams.drain();\n-                let mut first_stream_lrc = match iter.next().unwrap().0 {\n-                    Some(first_stream_lrc) => first_stream_lrc,\n-                    None => Lrc::new(vec![]),\n-                };\n+                let mut first_stream_lrc = iter.next().unwrap().0;\n \n                 // Append the elements to the first stream, after reserving\n                 // space for them.\n                 let first_vec_mut = Lrc::make_mut(&mut first_stream_lrc);\n                 first_vec_mut.reserve(num_appends);\n                 for stream in iter {\n-                    if let Some(stream) = stream.0 {\n-                        first_vec_mut.extend(stream.iter().cloned());\n-                    }\n+                    first_vec_mut.extend(stream.0.iter().cloned());\n                 }\n \n                 // Create the final `TokenStream`.\n-                match first_vec_mut.len() {\n-                    0 => TokenStream(None),\n-                    _ => TokenStream(Some(first_stream_lrc)),\n-                }\n+                TokenStream(first_stream_lrc)\n             }\n         }\n     }\n \n-    pub fn new(streams: Vec<TreeAndJoint>) -> TokenStream {\n-        match streams.len() {\n-            0 => TokenStream(None),\n-            _ => TokenStream(Some(Lrc::new(streams))),\n-        }\n-    }\n-\n     pub fn append_to_tree_and_joint_vec(self, vec: &mut Vec<TreeAndJoint>) {\n-        if let Some(stream) = self.0 {\n-            vec.extend(stream.iter().cloned());\n-        }\n+        vec.extend(self.0.iter().cloned());\n     }\n \n     pub fn trees(&self) -> Cursor {\n@@ -370,24 +339,22 @@ impl TokenStream {\n     }\n \n     pub fn map_enumerated<F: FnMut(usize, TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        TokenStream(self.0.map(|stream| {\n-            Lrc::new(\n-                stream\n-                    .iter()\n-                    .enumerate()\n-                    .map(|(i, (tree, is_joint))| (f(i, tree.clone()), *is_joint))\n-                    .collect())\n-        }))\n+        TokenStream(Lrc::new(\n+            self.0\n+                .iter()\n+                .enumerate()\n+                .map(|(i, (tree, is_joint))| (f(i, tree.clone()), *is_joint))\n+                .collect()\n+        ))\n     }\n \n     pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        TokenStream(self.0.map(|stream| {\n-            Lrc::new(\n-                stream\n-                    .iter()\n-                    .map(|(tree, is_joint)| (f(tree.clone()), *is_joint))\n-                    .collect())\n-        }))\n+        TokenStream(Lrc::new(\n+            self.0\n+                .iter()\n+                .map(|(tree, is_joint)| (f(tree.clone()), *is_joint))\n+                .collect()\n+        ))\n     }\n }\n \n@@ -405,44 +372,43 @@ impl TokenStreamBuilder {\n \n         // If `self` is not empty and the last tree within the last stream is a\n         // token tree marked with `Joint`...\n-        if let Some(TokenStream(Some(ref mut last_stream_lrc))) = self.0.last_mut() {\n+        if let Some(TokenStream(ref mut last_stream_lrc)) = self.0.last_mut() {\n             if let Some((TokenTree::Token(last_token), Joint)) = last_stream_lrc.last() {\n \n                 // ...and `stream` is not empty and the first tree within it is\n                 // a token tree...\n-                if let TokenStream(Some(ref mut stream_lrc)) = stream {\n-                    if let Some((TokenTree::Token(token), is_joint)) = stream_lrc.first() {\n-\n-                        // ...and the two tokens can be glued together...\n-                        if let Some(glued_tok) = last_token.glue(&token) {\n-\n-                            // ...then do so, by overwriting the last token\n-                            // tree in `self` and removing the first token tree\n-                            // from `stream`. This requires using `make_mut()`\n-                            // on the last stream in `self` and on `stream`,\n-                            // and in practice this doesn't cause cloning 99.9%\n-                            // of the time.\n-\n-                            // Overwrite the last token tree with the merged\n-                            // token.\n-                            let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n-                            *last_vec_mut.last_mut().unwrap() =\n-                                (TokenTree::Token(glued_tok), *is_joint);\n-\n-                            // Remove the first token tree from `stream`. (This\n-                            // is almost always the only tree in `stream`.)\n-                            let stream_vec_mut = Lrc::make_mut(stream_lrc);\n-                            stream_vec_mut.remove(0);\n-\n-                            // Don't push `stream` if it's empty -- that could\n-                            // block subsequent token gluing, by getting\n-                            // between two token trees that should be glued\n-                            // together.\n-                            if !stream.is_empty() {\n-                                self.0.push(stream);\n-                            }\n-                            return;\n+                let TokenStream(ref mut stream_lrc) = stream;\n+                if let Some((TokenTree::Token(token), is_joint)) = stream_lrc.first() {\n+\n+                    // ...and the two tokens can be glued together...\n+                    if let Some(glued_tok) = last_token.glue(&token) {\n+\n+                        // ...then do so, by overwriting the last token\n+                        // tree in `self` and removing the first token tree\n+                        // from `stream`. This requires using `make_mut()`\n+                        // on the last stream in `self` and on `stream`,\n+                        // and in practice this doesn't cause cloning 99.9%\n+                        // of the time.\n+\n+                        // Overwrite the last token tree with the merged\n+                        // token.\n+                        let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n+                        *last_vec_mut.last_mut().unwrap() =\n+                            (TokenTree::Token(glued_tok), *is_joint);\n+\n+                        // Remove the first token tree from `stream`. (This\n+                        // is almost always the only tree in `stream`.)\n+                        let stream_vec_mut = Lrc::make_mut(stream_lrc);\n+                        stream_vec_mut.remove(0);\n+\n+                        // Don't push `stream` if it's empty -- that could\n+                        // block subsequent token gluing, by getting\n+                        // between two token trees that should be glued\n+                        // together.\n+                        if !stream.is_empty() {\n+                            self.0.push(stream);\n                         }\n+                        return;\n                     }\n                 }\n             }\n@@ -475,16 +441,11 @@ impl Cursor {\n     }\n \n     pub fn next_with_joint(&mut self) -> Option<TreeAndJoint> {\n-        match self.stream.0 {\n-            None => None,\n-            Some(ref stream) => {\n-                if self.index < stream.len() {\n-                    self.index += 1;\n-                    Some(stream[self.index - 1].clone())\n-                } else {\n-                    None\n-                }\n-            }\n+        if self.index < self.stream.len() {\n+            self.index += 1;\n+            Some(self.stream.0[self.index - 1].clone())\n+        } else {\n+            None\n         }\n     }\n \n@@ -493,16 +454,13 @@ impl Cursor {\n             return;\n         }\n         let index = self.index;\n-        let stream = mem::replace(&mut self.stream, TokenStream(None));\n+        let stream = mem::take(&mut self.stream);\n         *self = TokenStream::from_streams(smallvec![stream, new_stream]).into_trees();\n         self.index = index;\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<TokenTree> {\n-        match self.stream.0 {\n-            None => None,\n-            Some(ref stream) => stream[self.index ..].get(n).map(|(tree, _)| tree.clone()),\n-        }\n+        self.stream.0[self.index ..].get(n).map(|(tree, _)| tree.clone())\n     }\n }\n "}, {"sha": "62c7e188eba27e5fad48b6cae0e18a43fa1b063f", "filename": "src/libsyntax_ext/plugin_macro_defs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d28ed1ae6c3f44f03e30e4884d6701e36744246/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs?ref=6d28ed1ae6c3f44f03e30e4884d6701e36744246", "patch": "@@ -20,7 +20,7 @@ fn plugin_macro_def(name: Name, span: Span) -> P<Item> {\n         attr::mk_word_item(Ident::new(sym::rustc_builtin_macro, span)));\n \n     let parens: TreeAndJoint = TokenTree::Delimited(\n-        DelimSpan::from_single(span), token::Paren, TokenStream::empty()\n+        DelimSpan::from_single(span), token::Paren, TokenStream::default()\n     ).into();\n     let trees = vec![parens.clone(), TokenTree::token(token::FatArrow, span).into(), parens];\n "}]}