{"sha": "6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZkNjE0ZGRjMmViYzI1ZDM5ODdiMWVmYzg0YzBjN2ZlYTAwY2UzMjU=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2017-09-14T03:26:39Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2017-09-17T17:25:50Z"}, "message": "rustc: Move codegen to a query\n\nThis commit moves the actual code generation in the compiler behind a query\nkeyed by a codegen unit's name. This ended up entailing quite a few internal\nrefactorings to enable this, along with a few cut corners:\n\n* The `OutputFilenames` structure is now tracked in the `TyCtxt` as it affects a\n  whole bunch of trans and such. This is now behind a query and threaded into\n  the construction of the `TyCtxt`.\n\n* The `TyCtxt` now has a channel \"out the back\" intended to send data to worker\n  threads in rustc_trans. This is used as a sort of side effect of the codegen\n  query but morally what's happening here is the return value of the query\n  (currently unit but morally a path) is only valid once the background threads\n  have all finished.\n\n* Dispatching work items to the codegen threads was refactored to only rely on\n  data in `TyCtxt`, which mostly just involved refactoring where data was\n  stored, moving it from the translation thread to the controller thread's\n  `CodegenContext` or the like.\n\n* A new thread locals was introduced in trans to work around the query\n  system. This is used in the implementation of `assert_module_sources` which\n  looks like an artifact of the old query system and will presumably go away\n  once red/green is up and running.", "tree": {"sha": "92b7f2d6ef29e86f4e09bad8b818c3f2a414a6d2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/92b7f2d6ef29e86f4e09bad8b818c3f2a414a6d2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "html_url": "https://github.com/rust-lang/rust/commit/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3021c1d0bf45d7628f6bf75aefce952ddf26193d", "url": "https://api.github.com/repos/rust-lang/rust/commits/3021c1d0bf45d7628f6bf75aefce952ddf26193d", "html_url": "https://github.com/rust-lang/rust/commit/3021c1d0bf45d7628f6bf75aefce952ddf26193d"}], "stats": {"total": 912, "additions": 484, "deletions": 428}, "files": [{"sha": "06469c16bc22e214f15aa926ba826f1b0e016acd", "filename": "src/librustc/dep_graph/dep_node.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fdep_node.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -71,6 +71,7 @@ use rustc_data_structures::stable_hasher::{StableHasher, HashStable};\n use ich::StableHashingContext;\n use std::fmt;\n use std::hash::Hash;\n+use syntax_pos::symbol::InternedString;\n \n // erase!() just makes tokens go away. It's used to specify which macro argument\n // is repeated (i.e. which sub-expression of the macro we are in) but don't need\n@@ -580,6 +581,9 @@ define_dep_nodes!( <'tcx>\n     [] ExportName(DefId),\n     [] ContainsExternIndicator(DefId),\n     [] IsTranslatedFunction(DefId),\n+    [] CodegenUnit(InternedString),\n+    [] CompileCodegenUnit(InternedString),\n+    [] OutputFilenames,\n );\n \n trait DepNodeParams<'a, 'gcx: 'tcx + 'a, 'tcx: 'a> : fmt::Debug {"}, {"sha": "9a50125754846f2ba017360929460db7f6de319c", "filename": "src/librustc/middle/trans.rs", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fmiddle%2Ftrans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fmiddle%2Ftrans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Ftrans.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -77,3 +77,34 @@ impl<'tcx> CodegenUnit<'tcx> {\n         &mut self.items\n     }\n }\n+\n+#[derive(Clone, Default)]\n+pub struct Stats {\n+    pub n_glues_created: usize,\n+    pub n_null_glues: usize,\n+    pub n_real_glues: usize,\n+    pub n_fns: usize,\n+    pub n_inlines: usize,\n+    pub n_closures: usize,\n+    pub n_llvm_insns: usize,\n+    pub llvm_insns: FxHashMap<String, usize>,\n+    // (ident, llvm-instructions)\n+    pub fn_stats: Vec<(String, usize)>,\n+}\n+\n+impl Stats {\n+    pub fn extend(&mut self, stats: Stats) {\n+        self.n_glues_created += stats.n_glues_created;\n+        self.n_null_glues += stats.n_null_glues;\n+        self.n_real_glues += stats.n_real_glues;\n+        self.n_fns += stats.n_fns;\n+        self.n_inlines += stats.n_inlines;\n+        self.n_closures += stats.n_closures;\n+        self.n_llvm_insns += stats.n_llvm_insns;\n+\n+        for (k, v) in stats.llvm_insns {\n+            *self.llvm_insns.entry(k).or_insert(0) += v;\n+        }\n+        self.fn_stats.extend(stats.fn_stats);\n+    }\n+}"}, {"sha": "945a08144275015aff769ed66a265f76eb3f387d", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -13,6 +13,7 @@\n use dep_graph::DepGraph;\n use errors::DiagnosticBuilder;\n use session::Session;\n+use session::config::OutputFilenames;\n use middle;\n use hir::{TraitCandidate, HirId, ItemLocalId};\n use hir::def::{Def, Export};\n@@ -65,6 +66,7 @@ use std::ops::Deref;\n use std::iter;\n use std::rc::Rc;\n use std::sync::mpsc;\n+use std::sync::Arc;\n use syntax::abi;\n use syntax::ast::{self, Name, NodeId};\n use syntax::attr;\n@@ -910,6 +912,8 @@ pub struct GlobalCtxt<'tcx> {\n     /// when satisfying the query for a particular codegen unit. Internally in\n     /// the query it'll send data along this channel to get processed later.\n     pub tx_to_llvm_workers: mpsc::Sender<Box<Any + Send>>,\n+\n+    output_filenames: Arc<OutputFilenames>,\n }\n \n impl<'tcx> GlobalCtxt<'tcx> {\n@@ -1035,6 +1039,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                                   hir: hir_map::Map<'tcx>,\n                                   crate_name: &str,\n                                   tx: mpsc::Sender<Box<Any + Send>>,\n+                                  output_filenames: &OutputFilenames,\n                                   f: F) -> R\n                                   where F: for<'b> FnOnce(TyCtxt<'b, 'tcx, 'tcx>) -> R\n     {\n@@ -1156,6 +1161,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n             stability_interner: RefCell::new(FxHashSet()),\n             all_traits: RefCell::new(None),\n             tx_to_llvm_workers: tx,\n+            output_filenames: Arc::new(output_filenames.clone()),\n        }, f)\n     }\n \n@@ -2229,4 +2235,8 @@ pub fn provide(providers: &mut ty::maps::Providers) {\n         assert_eq!(cnum, LOCAL_CRATE);\n         Rc::new(tcx.cstore.postorder_cnums_untracked())\n     };\n+    providers.output_filenames = |tcx, cnum| {\n+        assert_eq!(cnum, LOCAL_CRATE);\n+        tcx.output_filenames.clone()\n+    };\n }"}, {"sha": "bf17b82535cc1491d71e2800fe732ddebccfaa41", "filename": "src/librustc/ty/maps.rs", "status": "modified", "additions": 38, "deletions": 1, "changes": 39, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fty%2Fmaps.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc%2Fty%2Fmaps.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -24,10 +24,11 @@ use middle::resolve_lifetime::{Region, ObjectLifetimeDefault};\n use middle::stability::{self, DeprecationEntry};\n use middle::lang_items::{LanguageItems, LangItem};\n use middle::exported_symbols::SymbolExportLevel;\n-use middle::trans::CodegenUnit;\n+use middle::trans::{CodegenUnit, Stats};\n use mir;\n use mir::transform::{MirSuite, MirPassIndex};\n use session::CompileResult;\n+use session::config::OutputFilenames;\n use traits::specialization_graph;\n use ty::{self, CrateInherentImpls, Ty, TyCtxt};\n use ty::layout::{Layout, LayoutError};\n@@ -52,6 +53,7 @@ use std::ops::Deref;\n use std::rc::Rc;\n use std::sync::Arc;\n use syntax_pos::{Span, DUMMY_SP};\n+use syntax_pos::symbol::InternedString;\n use syntax::attr;\n use syntax::ast;\n use syntax::symbol::Symbol;\n@@ -180,6 +182,15 @@ impl<'tcx, T: Key> Key for ty::ParamEnvAnd<'tcx, T> {\n     }\n }\n \n+impl Key for InternedString {\n+    fn map_crate(&self) -> CrateNum {\n+        LOCAL_CRATE\n+    }\n+    fn default_span(&self, _tcx: TyCtxt) -> Span {\n+        DUMMY_SP\n+    }\n+}\n+\n trait Value<'tcx>: Sized {\n     fn from_cycle_error<'a>(tcx: TyCtxt<'a, 'tcx, 'tcx>) -> Self;\n }\n@@ -760,6 +771,24 @@ impl<'tcx> QueryDescription for queries::collect_and_partition_translation_items\n     }\n }\n \n+impl<'tcx> QueryDescription for queries::codegen_unit<'tcx> {\n+    fn describe(_tcx: TyCtxt, _: InternedString) -> String {\n+        format!(\"codegen_unit\")\n+    }\n+}\n+\n+impl<'tcx> QueryDescription for queries::compile_codegen_unit<'tcx> {\n+    fn describe(_tcx: TyCtxt, _: InternedString) -> String {\n+        format!(\"compile_codegen_unit\")\n+    }\n+}\n+\n+impl<'tcx> QueryDescription for queries::output_filenames<'tcx> {\n+    fn describe(_tcx: TyCtxt, _: CrateNum) -> String {\n+        format!(\"output_filenames\")\n+    }\n+}\n+\n // If enabled, send a message to the profile-queries thread\n macro_rules! profq_msg {\n     ($tcx:expr, $msg:expr) => {\n@@ -1395,6 +1424,10 @@ define_maps! { <'tcx>\n     [] fn export_name: ExportName(DefId) -> Option<Symbol>,\n     [] fn contains_extern_indicator: ContainsExternIndicator(DefId) -> bool,\n     [] fn is_translated_function: IsTranslatedFunction(DefId) -> bool,\n+    [] fn codegen_unit: CodegenUnit(InternedString) -> Arc<CodegenUnit<'tcx>>,\n+    [] fn compile_codegen_unit: CompileCodegenUnit(InternedString) -> Stats,\n+    [] fn output_filenames: output_filenames_node(CrateNum)\n+        -> Arc<OutputFilenames>,\n }\n \n fn type_param_predicates<'tcx>((item_id, param_id): (DefId, DefId)) -> DepConstructor<'tcx> {\n@@ -1512,3 +1545,7 @@ fn all_crate_nums_node<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n fn collect_and_partition_translation_items_node<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n     DepConstructor::CollectAndPartitionTranslationItems\n }\n+\n+fn output_filenames_node<'tcx>(_: CrateNum) -> DepConstructor<'tcx> {\n+    DepConstructor::OutputFilenames\n+}"}, {"sha": "32a160bcffcef21c66285350061f883ed1b31f5b", "filename": "src/librustc_driver/driver.rs", "status": "modified", "additions": 15, "deletions": 10, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fdriver.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -193,6 +193,7 @@ pub fn compile_input(sess: &Session,\n                                                                   &resolutions,\n                                                                   &expanded_crate,\n                                                                   &hir_map.krate(),\n+                                                                  &outputs,\n                                                                   &crate_name),\n                                     Ok(()));\n         }\n@@ -216,6 +217,7 @@ pub fn compile_input(sess: &Session,\n                                     &arena,\n                                     &arenas,\n                                     &crate_name,\n+                                    &outputs,\n                                     |tcx, analysis, incremental_hashes_map, rx, result| {\n             {\n                 // Eventually, we will want to track plugins.\n@@ -246,8 +248,7 @@ pub fn compile_input(sess: &Session,\n \n             let trans = phase_4_translate_to_llvm(tcx,\n                                                   incremental_hashes_map,\n-                                                  rx,\n-                                                  &outputs);\n+                                                  rx);\n \n             if log_enabled!(::log::LogLevel::Info) {\n                 println!(\"Post-trans\");\n@@ -261,7 +262,7 @@ pub fn compile_input(sess: &Session,\n                 }\n             }\n \n-            Ok((outputs, trans, tcx.dep_graph.clone()))\n+            Ok((outputs.clone(), trans, tcx.dep_graph.clone()))\n         })??\n     };\n \n@@ -486,6 +487,7 @@ impl<'a, 'tcx> CompileState<'a, 'tcx> {\n                                 resolutions: &'a Resolutions,\n                                 krate: &'a ast::Crate,\n                                 hir_crate: &'a hir::Crate,\n+                                output_filenames: &'a OutputFilenames,\n                                 crate_name: &'a str)\n                                 -> Self {\n         CompileState {\n@@ -498,6 +500,7 @@ impl<'a, 'tcx> CompileState<'a, 'tcx> {\n             resolutions: Some(resolutions),\n             expanded_crate: Some(krate),\n             hir_crate: Some(hir_crate),\n+            output_filenames: Some(output_filenames),\n             out_file: out_file.as_ref().map(|s| &**s),\n             ..CompileState::empty(input, session, out_dir)\n         }\n@@ -913,6 +916,7 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n                                                arena: &'tcx DroplessArena,\n                                                arenas: &'tcx GlobalArenas<'tcx>,\n                                                name: &str,\n+                                               output_filenames: &OutputFilenames,\n                                                f: F)\n                                                -> Result<R, CompileIncomplete>\n     where F: for<'a> FnOnce(TyCtxt<'a, 'tcx, 'tcx>,\n@@ -922,11 +926,11 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n                             CompileResult) -> R\n {\n     macro_rules! try_with_f {\n-        ($e: expr, ($t: expr, $a: expr, $h: expr)) => {\n+        ($e: expr, ($($t:tt)*)) => {\n             match $e {\n                 Ok(x) => x,\n                 Err(x) => {\n-                    f($t, $a, $h, Err(x));\n+                    f($($t)*, Err(x));\n                     return Err(x);\n                 }\n             }\n@@ -1047,6 +1051,7 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n                              hir_map,\n                              name,\n                              tx,\n+                             output_filenames,\n                              |tcx| {\n         let incremental_hashes_map =\n             time(time_passes,\n@@ -1062,7 +1067,8 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n              || stability::check_unstable_api_usage(tcx));\n \n         // passes are timed inside typeck\n-        try_with_f!(typeck::check_crate(tcx), (tcx, analysis, incremental_hashes_map));\n+        try_with_f!(typeck::check_crate(tcx),\n+                    (tcx, analysis, incremental_hashes_map, rx));\n \n         time(time_passes,\n              \"const checking\",\n@@ -1106,7 +1112,7 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n         // lint warnings and so on -- kindck used to do this abort, but\n         // kindck is gone now). -nmatsakis\n         if sess.err_count() > 0 {\n-            return Ok(f(tcx, analysis, incremental_hashes_map, sess.compile_status()));\n+            return Ok(f(tcx, analysis, incremental_hashes_map, rx, sess.compile_status()));\n         }\n \n         time(time_passes, \"death checking\", || middle::dead::check_crate(tcx));\n@@ -1125,8 +1131,7 @@ pub fn phase_3_run_analysis_passes<'tcx, F, R>(sess: &'tcx Session,\n /// be discarded.\n pub fn phase_4_translate_to_llvm<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                            incremental_hashes_map: IncrementalHashesMap,\n-                                           rx: mpsc::Receiver<Box<Any + Send>>,\n-                                           output_filenames: &OutputFilenames)\n+                                           rx: mpsc::Receiver<Box<Any + Send>>)\n                                            -> write::OngoingCrateTranslation {\n     let time_passes = tcx.sess.time_passes();\n \n@@ -1136,7 +1141,7 @@ pub fn phase_4_translate_to_llvm<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     let translation =\n         time(time_passes, \"translation\", move || {\n-            trans::trans_crate(tcx, incremental_hashes_map, rx, output_filenames)\n+            trans::trans_crate(tcx, incremental_hashes_map, rx)\n         });\n \n     if tcx.sess.profile_queries() {"}, {"sha": "044f4a5eaf512bec0ff28ccb98aa4e3ef190a943", "filename": "src/librustc_driver/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Flib.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -645,6 +645,7 @@ impl<'a> CompilerCalls<'a> for RustcDefaultCalls {\n                                                      ppm,\n                                                      state.arena.unwrap(),\n                                                      state.arenas.unwrap(),\n+                                                     state.output_filenames.unwrap(),\n                                                      opt_uii.clone(),\n                                                      state.out_file);\n                 };"}, {"sha": "cd153b820776e97e9f1a9827572e7d713d1b26cb", "filename": "src/librustc_driver/pretty.rs", "status": "modified", "additions": 11, "deletions": 3, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Fpretty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Fpretty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Fpretty.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -23,7 +23,7 @@ use rustc::cfg::graphviz::LabelledCFG;\n use rustc::dep_graph::DepGraph;\n use rustc::middle::cstore::CrateStore;\n use rustc::session::Session;\n-use rustc::session::config::Input;\n+use rustc::session::config::{Input, OutputFilenames};\n use rustc_borrowck as borrowck;\n use rustc_borrowck::graphviz as borrowck_dot;\n \n@@ -205,6 +205,7 @@ impl PpSourceMode {\n                                                resolutions: &Resolutions,\n                                                arena: &'tcx DroplessArena,\n                                                arenas: &'tcx GlobalArenas<'tcx>,\n+                                               output_filenames: &OutputFilenames,\n                                                id: &str,\n                                                f: F)\n                                                -> A\n@@ -235,7 +236,8 @@ impl PpSourceMode {\n                                                                  arena,\n                                                                  arenas,\n                                                                  id,\n-                                                                 |tcx, _, _, _| {\n+                                                                 output_filenames,\n+                                                                 |tcx, _, _, _, _| {\n                     let empty_tables = ty::TypeckTables::empty(None);\n                     let annotation = TypedAnnotation {\n                         tcx,\n@@ -888,6 +890,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                                                 ppm: PpMode,\n                                                 arena: &'tcx DroplessArena,\n                                                 arenas: &'tcx GlobalArenas<'tcx>,\n+                                                output_filenames: &OutputFilenames,\n                                                 opt_uii: Option<UserIdentifiedItem>,\n                                                 ofile: Option<&Path>) {\n     let dep_graph = DepGraph::new(false);\n@@ -902,6 +905,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                             crate_name,\n                             arena,\n                             arenas,\n+                            output_filenames,\n                             ppm,\n                             opt_uii,\n                             ofile);\n@@ -940,6 +944,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                                            resolutions,\n                                            arena,\n                                            arenas,\n+                                           output_filenames,\n                                            crate_name,\n                                            move |annotation, krate| {\n                     debug!(\"pretty printing source code {:?}\", s);\n@@ -964,6 +969,7 @@ pub fn print_after_hir_lowering<'tcx, 'a: 'tcx>(sess: &'a Session,\n                                            resolutions,\n                                            arena,\n                                            arenas,\n+                                           output_filenames,\n                                            crate_name,\n                                            move |annotation, _| {\n                     debug!(\"pretty printing source code {:?}\", s);\n@@ -1007,6 +1013,7 @@ fn print_with_analysis<'tcx, 'a: 'tcx>(sess: &'a Session,\n                                        crate_name: &str,\n                                        arena: &'tcx DroplessArena,\n                                        arenas: &'tcx GlobalArenas<'tcx>,\n+                                       output_filenames: &OutputFilenames,\n                                        ppm: PpMode,\n                                        uii: Option<UserIdentifiedItem>,\n                                        ofile: Option<&Path>) {\n@@ -1028,7 +1035,8 @@ fn print_with_analysis<'tcx, 'a: 'tcx>(sess: &'a Session,\n                                                      arena,\n                                                      arenas,\n                                                      crate_name,\n-                                                     |tcx, _, _, _| {\n+                                                     output_filenames,\n+                                                     |tcx, _, _, _, _| {\n         match ppm {\n             PpmMir | PpmMirCFG => {\n                 if let Some(nodeid) = nodeid {"}, {"sha": "34f4e0e7b0c959f6e3dfaadb688fdca2ad2c7c17", "filename": "src/librustc_driver/test.rs", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_driver%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Ftest.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -10,6 +10,9 @@\n \n //! # Standalone Tests for the Inference Module\n \n+use std::path::PathBuf;\n+use std::sync::mpsc;\n+\n use driver;\n use rustc_lint;\n use rustc_resolve::MakeGlobMap;\n@@ -26,6 +29,7 @@ use rustc_metadata::cstore::CStore;\n use rustc::hir::map as hir_map;\n use rustc::mir::transform::Passes;\n use rustc::session::{self, config};\n+use rustc::session::config::{OutputFilenames, OutputTypes};\n use std::rc::Rc;\n use syntax::ast;\n use syntax::abi::Abi;\n@@ -133,6 +137,14 @@ fn test_env<F>(source_string: &str,\n \n     // run just enough stuff to build a tcx:\n     let named_region_map = resolve_lifetime::krate(&sess, &*cstore, &hir_map);\n+    let (tx, _rx) = mpsc::channel();\n+    let outputs = OutputFilenames {\n+        out_directory: PathBuf::new(),\n+        out_filestem: String::new(),\n+        single_output_file: None,\n+        extra: String::new(),\n+        outputs: OutputTypes::new(&[]),\n+    };\n     TyCtxt::create_and_enter(&sess,\n                              &*cstore,\n                              ty::maps::Providers::default(),\n@@ -144,6 +156,8 @@ fn test_env<F>(source_string: &str,\n                              named_region_map.unwrap(),\n                              hir_map,\n                              \"test_crate\",\n+                             tx,\n+                             &outputs,\n                              |tcx| {\n         tcx.infer_ctxt().enter(|infcx| {\n             let mut region_scope_tree = region::ScopeTree::default();"}, {"sha": "ef6bf2504f3121ba65dbba1a9b28e5679ec59767", "filename": "src/librustc_trans/back/write.rs", "status": "modified", "additions": 109, "deletions": 139, "changes": 248, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fback%2Fwrite.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -203,8 +203,6 @@ pub fn create_target_machine(sess: &Session) -> TargetMachineRef {\n \n /// Module-specific configuration for `optimize_and_codegen`.\n pub struct ModuleConfig {\n-    /// LLVM TargetMachine to use for codegen.\n-    tm: TargetMachineRef,\n     /// Names of additional optimization passes to run.\n     passes: Vec<String>,\n     /// Some(level) to optimize at a certain level, or None to run\n@@ -237,12 +235,9 @@ pub struct ModuleConfig {\n     obj_is_bitcode: bool,\n }\n \n-unsafe impl Send for ModuleConfig { }\n-\n impl ModuleConfig {\n-    fn new(sess: &Session, passes: Vec<String>) -> ModuleConfig {\n+    fn new(passes: Vec<String>) -> ModuleConfig {\n         ModuleConfig {\n-            tm: create_target_machine(sess),\n             passes,\n             opt_level: None,\n             opt_size: None,\n@@ -290,40 +285,6 @@ impl ModuleConfig {\n         self.merge_functions = sess.opts.optimize == config::OptLevel::Default ||\n                                sess.opts.optimize == config::OptLevel::Aggressive;\n     }\n-\n-    fn clone(&self, sess: &Session) -> ModuleConfig {\n-        ModuleConfig {\n-            tm: create_target_machine(sess),\n-            passes: self.passes.clone(),\n-            opt_level: self.opt_level,\n-            opt_size: self.opt_size,\n-\n-            emit_no_opt_bc: self.emit_no_opt_bc,\n-            emit_bc: self.emit_bc,\n-            emit_lto_bc: self.emit_lto_bc,\n-            emit_ir: self.emit_ir,\n-            emit_asm: self.emit_asm,\n-            emit_obj: self.emit_obj,\n-            obj_is_bitcode: self.obj_is_bitcode,\n-\n-            no_verify: self.no_verify,\n-            no_prepopulate_passes: self.no_prepopulate_passes,\n-            no_builtins: self.no_builtins,\n-            time_passes: self.time_passes,\n-            vectorize_loop: self.vectorize_loop,\n-            vectorize_slp: self.vectorize_slp,\n-            merge_functions: self.merge_functions,\n-            inline_threshold: self.inline_threshold,\n-        }\n-    }\n-}\n-\n-impl Drop for ModuleConfig {\n-    fn drop(&mut self) {\n-        unsafe {\n-            llvm::LLVMRustDisposeTargetMachine(self.tm);\n-        }\n-    }\n }\n \n /// Additional resources used by optimize_and_codegen (not module specific)\n@@ -337,6 +298,11 @@ pub struct CodegenContext {\n     pub opts: Arc<config::Options>,\n     pub crate_types: Vec<config::CrateType>,\n     pub each_linked_rlib_for_lto: Vec<(CrateNum, PathBuf)>,\n+    output_filenames: Arc<OutputFilenames>,\n+    regular_module_config: Arc<ModuleConfig>,\n+    metadata_module_config: Arc<ModuleConfig>,\n+    allocator_module_config: Arc<ModuleConfig>,\n+\n     // Handler to use for diagnostics produced during codegen.\n     pub diag_emitter: SharedEmitter,\n     // LLVM passes added by plugins.\n@@ -359,6 +325,14 @@ impl CodegenContext {\n     fn create_diag_handler(&self) -> Handler {\n         Handler::with_emitter(true, false, Box::new(self.diag_emitter.clone()))\n     }\n+\n+    fn config(&self, kind: ModuleKind) -> &ModuleConfig {\n+        match kind {\n+            ModuleKind::Regular => &self.regular_module_config,\n+            ModuleKind::Metadata => &self.metadata_module_config,\n+            ModuleKind::Allocator => &self.allocator_module_config,\n+        }\n+    }\n }\n \n struct HandlerFreeVars<'a> {\n@@ -418,8 +392,8 @@ unsafe extern \"C\" fn diagnostic_handler(info: DiagnosticInfoRef, user: *mut c_vo\n unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n                                diag_handler: &Handler,\n                                mtrans: ModuleTranslation,\n-                               config: ModuleConfig,\n-                               output_names: OutputFilenames)\n+                               tm: TargetMachineRef,\n+                               config: &ModuleConfig)\n     -> Result<CompiledModule, FatalError>\n {\n     let (llmod, llcx) = match mtrans.source {\n@@ -429,8 +403,6 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n         }\n     };\n \n-    let tm = config.tm;\n-\n     let fv = HandlerFreeVars {\n         cgcx,\n         diag_handler,\n@@ -444,7 +416,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n     let module_name = Some(&module_name[..]);\n \n     if config.emit_no_opt_bc {\n-        let out = output_names.temp_path_ext(\"no-opt.bc\", module_name);\n+        let out = cgcx.output_filenames.temp_path_ext(\"no-opt.bc\", module_name);\n         let out = path2cstr(&out);\n         llvm::LLVMWriteBitcodeToFile(llmod, out.as_ptr());\n     }\n@@ -517,7 +489,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n         if cgcx.lto {\n             time(cgcx.time_passes, \"all lto passes\", || {\n                 let temp_no_opt_bc_filename =\n-                    output_names.temp_path_ext(\"no-opt.lto.bc\", module_name);\n+                    cgcx.output_filenames.temp_path_ext(\"no-opt.lto.bc\", module_name);\n                 lto::run(cgcx,\n                          diag_handler,\n                          llmod,\n@@ -526,7 +498,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n                          &temp_no_opt_bc_filename)\n             })?;\n             if config.emit_lto_bc {\n-                let out = output_names.temp_path_ext(\"lto.bc\", module_name);\n+                let out = cgcx.output_filenames.temp_path_ext(\"lto.bc\", module_name);\n                 let out = path2cstr(&out);\n                 llvm::LLVMWriteBitcodeToFile(llmod, out.as_ptr());\n             }\n@@ -562,8 +534,8 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n     let write_obj = config.emit_obj && !config.obj_is_bitcode;\n     let copy_bc_to_obj = config.emit_obj && config.obj_is_bitcode;\n \n-    let bc_out = output_names.temp_path(OutputType::Bitcode, module_name);\n-    let obj_out = output_names.temp_path(OutputType::Object, module_name);\n+    let bc_out = cgcx.output_filenames.temp_path(OutputType::Bitcode, module_name);\n+    let obj_out = cgcx.output_filenames.temp_path(OutputType::Object, module_name);\n \n     if write_bc {\n         let bc_out_c = path2cstr(&bc_out);\n@@ -573,7 +545,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n     time(config.time_passes, &format!(\"codegen passes [{}]\", module_name.unwrap()),\n          || -> Result<(), FatalError> {\n         if config.emit_ir {\n-            let out = output_names.temp_path(OutputType::LlvmAssembly, module_name);\n+            let out = cgcx.output_filenames.temp_path(OutputType::LlvmAssembly, module_name);\n             let out = path2cstr(&out);\n \n             extern \"C\" fn demangle_callback(input_ptr: *const c_char,\n@@ -614,7 +586,7 @@ unsafe fn optimize_and_codegen(cgcx: &CodegenContext,\n         }\n \n         if config.emit_asm {\n-            let path = output_names.temp_path(OutputType::Assembly, module_name);\n+            let path = cgcx.output_filenames.temp_path(OutputType::Assembly, module_name);\n \n             // We can't use the same module for asm and binary output, because that triggers\n             // various errors like invalid IR or broken binaries, so we might have to clone the\n@@ -672,13 +644,13 @@ fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n }\n \n pub fn start_async_translation(tcx: TyCtxt,\n-                               crate_output: &OutputFilenames,\n                                time_graph: Option<TimeGraph>,\n                                link: LinkMeta,\n                                metadata: EncodedMetadata,\n                                coordinator_receive: Receiver<Box<Any + Send>>)\n                                -> OngoingCrateTranslation {\n     let sess = tcx.sess;\n+    let crate_output = tcx.output_filenames(LOCAL_CRATE);\n     let crate_name = tcx.crate_name(LOCAL_CRATE);\n     let no_builtins = attr::contains_name(&tcx.hir.krate().attrs, \"no_builtins\");\n     let subsystem = attr::first_attr_value_str_by_name(&tcx.hir.krate().attrs,\n@@ -699,23 +671,16 @@ pub fn start_async_translation(tcx: TyCtxt,\n     let linker_info = LinkerInfo::new(tcx);\n     let crate_info = CrateInfo::new(tcx);\n \n-    let mut exported_symbols = FxHashMap();\n-    exported_symbols.insert(LOCAL_CRATE, tcx.exported_symbols(LOCAL_CRATE));\n-    for &cnum in tcx.crates().iter() {\n-        exported_symbols.insert(cnum, tcx.exported_symbols(cnum));\n-    }\n-    let exported_symbols = Arc::new(exported_symbols);\n-\n     let output_types_override = if no_integrated_as {\n         OutputTypes::new(&[(OutputType::Assembly, None)])\n     } else {\n         sess.opts.output_types.clone()\n     };\n \n     // Figure out what we actually need to build.\n-    let mut modules_config = ModuleConfig::new(sess, sess.opts.cg.passes.clone());\n-    let mut metadata_config = ModuleConfig::new(sess, vec![]);\n-    let mut allocator_config = ModuleConfig::new(sess, vec![]);\n+    let mut modules_config = ModuleConfig::new(sess.opts.cg.passes.clone());\n+    let mut metadata_config = ModuleConfig::new(vec![]);\n+    let mut allocator_config = ModuleConfig::new(vec![]);\n \n     if let Some(ref sanitizer) = sess.opts.debugging_opts.sanitizer {\n         match *sanitizer {\n@@ -801,15 +766,17 @@ pub fn start_async_translation(tcx: TyCtxt,\n     let (shared_emitter, shared_emitter_main) = SharedEmitter::new();\n     let (trans_worker_send, trans_worker_receive) = channel();\n \n-    let coordinator_thread = start_executing_work(sess,\n+    let coordinator_thread = start_executing_work(tcx,\n                                                   &crate_info,\n                                                   shared_emitter,\n                                                   trans_worker_send,\n-                                                  tcx.tx_to_llvm_workers.clone(),\n                                                   coordinator_receive,\n                                                   client,\n                                                   time_graph.clone(),\n-                                                  exported_symbols.clone());\n+                                                  Arc::new(modules_config),\n+                                                  Arc::new(metadata_config),\n+                                                  Arc::new(allocator_config));\n+\n     OngoingCrateTranslation {\n         crate_name,\n         link,\n@@ -819,16 +786,12 @@ pub fn start_async_translation(tcx: TyCtxt,\n         no_integrated_as,\n         crate_info,\n \n-        regular_module_config: modules_config,\n-        metadata_module_config: metadata_config,\n-        allocator_module_config: allocator_config,\n-\n         time_graph,\n-        output_filenames: crate_output.clone(),\n         coordinator_send: tcx.tx_to_llvm_workers.clone(),\n         trans_worker_receive,\n         shared_emitter_main,\n-        future: coordinator_thread\n+        future: coordinator_thread,\n+        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n     }\n }\n \n@@ -1029,8 +992,7 @@ pub fn dump_incremental_data(trans: &CrateTranslation) {\n \n struct WorkItem {\n     mtrans: ModuleTranslation,\n-    config: ModuleConfig,\n-    output_names: OutputFilenames\n+    tm: TargetMachine,\n }\n \n impl fmt::Debug for WorkItem {\n@@ -1039,15 +1001,15 @@ impl fmt::Debug for WorkItem {\n     }\n }\n \n-fn build_work_item(mtrans: ModuleTranslation,\n-                   config: ModuleConfig,\n-                   output_names: OutputFilenames)\n-                   -> WorkItem\n-{\n-    WorkItem {\n-        mtrans,\n-        config,\n-        output_names,\n+struct TargetMachine(TargetMachineRef);\n+\n+unsafe impl Send for TargetMachine {}\n+\n+impl Drop for TargetMachine {\n+    fn drop(&mut self) {\n+        unsafe {\n+            llvm::LLVMRustDisposeTargetMachine(self.0);\n+        }\n     }\n }\n \n@@ -1056,6 +1018,7 @@ fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n {\n     let diag_handler = cgcx.create_diag_handler();\n     let module_name = work_item.mtrans.name.clone();\n+    let config = cgcx.config(work_item.mtrans.kind);\n \n     let pre_existing = match work_item.mtrans.source {\n         ModuleSource::Translated(_) => None,\n@@ -1068,7 +1031,7 @@ fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n                                         .unwrap();\n         let name = &work_item.mtrans.name;\n         for (kind, saved_file) in wp.saved_files {\n-            let obj_out = work_item.output_names.temp_path(kind, Some(name));\n+            let obj_out = cgcx.output_filenames.temp_path(kind, Some(name));\n             let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n                                                &saved_file);\n             debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n@@ -1091,8 +1054,8 @@ fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n             kind: ModuleKind::Regular,\n             pre_existing: true,\n             symbol_name_hash: work_item.mtrans.symbol_name_hash,\n-            emit_bc: work_item.config.emit_bc,\n-            emit_obj: work_item.config.emit_obj,\n+            emit_bc: config.emit_bc,\n+            emit_obj: config.emit_obj,\n         })\n     } else {\n         debug!(\"llvm-optimizing {:?}\", module_name);\n@@ -1101,8 +1064,8 @@ fn execute_work_item(cgcx: &CodegenContext, work_item: WorkItem)\n             optimize_and_codegen(cgcx,\n                                  &diag_handler,\n                                  work_item.mtrans,\n-                                 work_item.config,\n-                                 work_item.output_names)\n+                                 work_item.tm.0,\n+                                 config)\n         }\n     }\n }\n@@ -1117,8 +1080,8 @@ enum Message {\n     TranslationDone {\n         llvm_work_item: WorkItem,\n         cost: u64,\n-        is_last: bool,\n     },\n+    TranslationComplete,\n     TranslateItem,\n }\n \n@@ -1135,16 +1098,26 @@ enum MainThreadWorkerState {\n     LLVMing,\n }\n \n-fn start_executing_work(sess: &Session,\n+fn start_executing_work(tcx: TyCtxt,\n                         crate_info: &CrateInfo,\n                         shared_emitter: SharedEmitter,\n                         trans_worker_send: Sender<Message>,\n-                        coordinator_send: Sender<Box<Any + Send>>,\n                         coordinator_receive: Receiver<Box<Any + Send>>,\n                         jobserver: Client,\n                         time_graph: Option<TimeGraph>,\n-                        exported_symbols: Arc<ExportedSymbols>)\n+                        modules_config: Arc<ModuleConfig>,\n+                        metadata_config: Arc<ModuleConfig>,\n+                        allocator_config: Arc<ModuleConfig>)\n                         -> thread::JoinHandle<CompiledModules> {\n+    let coordinator_send = tcx.tx_to_llvm_workers.clone();\n+    let mut exported_symbols = FxHashMap();\n+    exported_symbols.insert(LOCAL_CRATE, tcx.exported_symbols(LOCAL_CRATE));\n+    for &cnum in tcx.crates().iter() {\n+        exported_symbols.insert(cnum, tcx.exported_symbols(cnum));\n+    }\n+    let exported_symbols = Arc::new(exported_symbols);\n+    let sess = tcx.sess;\n+\n     // First up, convert our jobserver into a helper thread so we can use normal\n     // mpsc channels to manage our messages and such. Once we've got the helper\n     // thread then request `n-1` tokens because all of our work items are ready\n@@ -1183,6 +1156,10 @@ fn start_executing_work(sess: &Session,\n         coordinator_send,\n         diag_emitter: shared_emitter.clone(),\n         time_graph,\n+        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n+        regular_module_config: modules_config,\n+        metadata_module_config: metadata_config,\n+        allocator_module_config: allocator_config,\n     };\n \n     // This is the \"main loop\" of parallel work happening for parallel codegen.\n@@ -1332,7 +1309,7 @@ fn start_executing_work(sess: &Session,\n         let mut translation_done = false;\n \n         // This is the queue of LLVM work items that still need processing.\n-        let mut work_items = Vec::new();\n+        let mut work_items = Vec::<(WorkItem, u64)>::new();\n \n         // This are the Jobserver Tokens we currently hold. Does not include\n         // the implicit Token the compiler process owns no matter what.\n@@ -1371,7 +1348,8 @@ fn start_executing_work(sess: &Session,\n                             worker: get_worker_id(&mut free_worker_ids),\n                             .. cgcx.clone()\n                         };\n-                        maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+                        maybe_start_llvm_timer(cgcx.config(item.mtrans.kind),\n+                                               &mut llvm_start_time);\n                         main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                         spawn_work(cgcx, item);\n                     }\n@@ -1387,7 +1365,8 @@ fn start_executing_work(sess: &Session,\n                                 worker: get_worker_id(&mut free_worker_ids),\n                                 .. cgcx.clone()\n                             };\n-                            maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+                            maybe_start_llvm_timer(cgcx.config(item.mtrans.kind),\n+                                                   &mut llvm_start_time);\n                             main_thread_worker_state = MainThreadWorkerState::LLVMing;\n                             spawn_work(cgcx, item);\n                         } else {\n@@ -1417,7 +1396,8 @@ fn start_executing_work(sess: &Session,\n             while work_items.len() > 0 && running < tokens.len() {\n                 let (item, _) = work_items.pop().unwrap();\n \n-                maybe_start_llvm_timer(&item, &mut llvm_start_time);\n+                maybe_start_llvm_timer(cgcx.config(item.mtrans.kind),\n+                                       &mut llvm_start_time);\n \n                 let cgcx = CodegenContext {\n                     worker: get_worker_id(&mut free_worker_ids),\n@@ -1459,7 +1439,7 @@ fn start_executing_work(sess: &Session,\n                     }\n                 }\n \n-                Message::TranslationDone { llvm_work_item, cost, is_last } => {\n+                Message::TranslationDone { llvm_work_item, cost } => {\n                     // We keep the queue sorted by estimated processing cost,\n                     // so that more expensive items are processed earlier. This\n                     // is good for throughput as it gives the main thread more\n@@ -1475,15 +1455,14 @@ fn start_executing_work(sess: &Session,\n                     };\n                     work_items.insert(insertion_index, (llvm_work_item, cost));\n \n-                    if is_last {\n-                        // If this is the last, don't request a token because\n-                        // the trans worker thread will be free to handle this\n-                        // immediately.\n-                        translation_done = true;\n-                    } else {\n-                        helper.request_token();\n-                    }\n+                    helper.request_token();\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Translating);\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n+                }\n \n+                Message::TranslationComplete => {\n+                    translation_done = true;\n                     assert_eq!(main_thread_worker_state,\n                                MainThreadWorkerState::Translating);\n                     main_thread_worker_state = MainThreadWorkerState::Idle;\n@@ -1561,11 +1540,11 @@ fn start_executing_work(sess: &Session,\n         items_in_queue >= max_workers.saturating_sub(workers_running / 2)\n     }\n \n-    fn maybe_start_llvm_timer(work_item: &WorkItem,\n+    fn maybe_start_llvm_timer(config: &ModuleConfig,\n                               llvm_start_time: &mut Option<Instant>) {\n         // We keep track of the -Ztime-passes output manually,\n         // since the closure-based interface does not fit well here.\n-        if work_item.config.time_passes {\n+        if config.time_passes {\n             if llvm_start_time.is_none() {\n                 *llvm_start_time = Some(Instant::now());\n             }\n@@ -1840,17 +1819,12 @@ pub struct OngoingCrateTranslation {\n     linker_info: LinkerInfo,\n     no_integrated_as: bool,\n     crate_info: CrateInfo,\n-\n-    output_filenames: OutputFilenames,\n-    regular_module_config: ModuleConfig,\n-    metadata_module_config: ModuleConfig,\n-    allocator_module_config: ModuleConfig,\n-\n     time_graph: Option<TimeGraph>,\n     coordinator_send: Sender<Box<Any + Send>>,\n     trans_worker_receive: Receiver<Message>,\n     shared_emitter_main: SharedEmitterMain,\n     future: thread::JoinHandle<CompiledModules>,\n+    output_filenames: Arc<OutputFilenames>,\n }\n \n impl OngoingCrateTranslation {\n@@ -1918,38 +1892,21 @@ impl OngoingCrateTranslation {\n         trans\n     }\n \n-    pub fn submit_translated_module_to_llvm(&self,\n-                                            sess: &Session,\n-                                            mtrans: ModuleTranslation,\n-                                            cost: u64,\n-                                            is_last: bool) {\n-        let module_config = match mtrans.kind {\n-            ModuleKind::Regular => self.regular_module_config.clone(sess),\n-            ModuleKind::Metadata => self.metadata_module_config.clone(sess),\n-            ModuleKind::Allocator => self.allocator_module_config.clone(sess),\n-        };\n-\n-        let llvm_work_item = build_work_item(mtrans,\n-                                             module_config,\n-                                             self.output_filenames.clone());\n-\n-        drop(self.coordinator_send.send(Box::new(Message::TranslationDone {\n-            llvm_work_item,\n-            cost,\n-            is_last\n-        })));\n-    }\n-\n     pub fn submit_pre_translated_module_to_llvm(&self,\n-                                                sess: &Session,\n-                                                mtrans: ModuleTranslation,\n-                                                is_last: bool) {\n+                                                tcx: TyCtxt,\n+                                                mtrans: ModuleTranslation) {\n         self.wait_for_signal_to_translate_item();\n-        self.check_for_errors(sess);\n+        self.check_for_errors(tcx.sess);\n \n         // These are generally cheap and won't through off scheduling.\n         let cost = 0;\n-        self.submit_translated_module_to_llvm(sess, mtrans, cost, is_last);\n+        submit_translated_module_to_llvm(tcx, mtrans, cost);\n+    }\n+\n+    pub fn translation_finished(&self, tcx: TyCtxt) {\n+        self.wait_for_signal_to_translate_item();\n+        self.check_for_errors(tcx.sess);\n+        drop(self.coordinator_send.send(Box::new(Message::TranslationComplete)));\n     }\n \n     pub fn check_for_errors(&self, sess: &Session) {\n@@ -1971,3 +1928,16 @@ impl OngoingCrateTranslation {\n         }\n     }\n }\n+\n+pub fn submit_translated_module_to_llvm(tcx: TyCtxt,\n+                                        mtrans: ModuleTranslation,\n+                                        cost: u64) {\n+    let llvm_work_item = WorkItem {\n+        mtrans,\n+        tm: TargetMachine(create_target_machine(tcx.sess)),\n+    };\n+    drop(tcx.tx_to_llvm_workers.send(Box::new(Message::TranslationDone {\n+        llvm_work_item,\n+        cost,\n+    })));\n+}"}, {"sha": "d86f88d4c7da0af8b0b73cb798737f33d358fb7d", "filename": "src/librustc_trans/base.rs", "status": "modified", "additions": 221, "deletions": 212, "changes": 433, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbase.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -28,7 +28,7 @@ use super::ModuleSource;\n use super::ModuleTranslation;\n use super::ModuleKind;\n \n-use assert_module_sources;\n+use assert_module_sources::{self, Disposition};\n use back::link;\n use back::symbol_export;\n use back::write::{self, OngoingCrateTranslation};\n@@ -37,15 +37,15 @@ use llvm;\n use metadata;\n use rustc::hir::def_id::{CrateNum, DefId, LOCAL_CRATE};\n use rustc::middle::lang_items::StartFnLangItem;\n-use rustc::middle::trans::{Linkage, Visibility};\n+use rustc::middle::trans::{Linkage, Visibility, Stats};\n use rustc::middle::cstore::{EncodedMetadata, EncodedMetadataHashes};\n use rustc::ty::{self, Ty, TyCtxt};\n use rustc::ty::maps::Providers;\n use rustc::dep_graph::AssertDepGraphSafe;\n use rustc::middle::cstore::{self, LinkMeta, LinkagePreference};\n use rustc::hir::map as hir_map;\n use rustc::util::common::{time, print_time_passes_entry};\n-use rustc::session::config::{self, NoDebugInfo, OutputFilenames};\n+use rustc::session::config::{self, NoDebugInfo};\n use rustc::session::Session;\n use rustc_incremental::{self, IncrementalHashesMap};\n use abi;\n@@ -61,7 +61,7 @@ use common::CrateContext;\n use common::{type_is_zero_size, val_ty};\n use common;\n use consts;\n-use context::{self, LocalCrateContext, SharedCrateContext, Stats};\n+use context::{self, LocalCrateContext, SharedCrateContext};\n use debuginfo;\n use declare;\n use machine;\n@@ -80,13 +80,15 @@ use CrateInfo;\n \n use libc::c_uint;\n use std::any::Any;\n+use std::cell::RefCell;\n use std::ffi::{CStr, CString};\n use std::str;\n use std::sync::Arc;\n use std::time::{Instant, Duration};\n use std::i32;\n use std::sync::mpsc;\n use syntax_pos::Span;\n+use syntax_pos::symbol::InternedString;\n use syntax::attr;\n use rustc::hir;\n use syntax::ast;\n@@ -101,7 +103,7 @@ pub struct StatRecorder<'a, 'tcx: 'a> {\n \n impl<'a, 'tcx> StatRecorder<'a, 'tcx> {\n     pub fn new(ccx: &'a CrateContext<'a, 'tcx>, name: String) -> StatRecorder<'a, 'tcx> {\n-        let istart = ccx.stats().n_llvm_insns.get();\n+        let istart = ccx.stats().borrow().n_llvm_insns;\n         StatRecorder {\n             ccx,\n             name: Some(name),\n@@ -113,12 +115,12 @@ impl<'a, 'tcx> StatRecorder<'a, 'tcx> {\n impl<'a, 'tcx> Drop for StatRecorder<'a, 'tcx> {\n     fn drop(&mut self) {\n         if self.ccx.sess().trans_stats() {\n-            let iend = self.ccx.stats().n_llvm_insns.get();\n-            self.ccx.stats().fn_stats.borrow_mut()\n-                .push((self.name.take().unwrap(), iend - self.istart));\n-            self.ccx.stats().n_fns.set(self.ccx.stats().n_fns.get() + 1);\n+            let mut stats = self.ccx.stats().borrow_mut();\n+            let iend = stats.n_llvm_insns;\n+            stats.fn_stats.push((self.name.take().unwrap(), iend - self.istart));\n+            stats.n_fns += 1;\n             // Reset LLVM insn count to avoid compound costs.\n-            self.ccx.stats().n_llvm_insns.set(self.istart);\n+            stats.n_llvm_insns = self.istart;\n         }\n     }\n }\n@@ -590,7 +592,7 @@ pub fn trans_instance<'a, 'tcx>(ccx: &CrateContext<'a, 'tcx>, instance: Instance\n         None => bug!(\"Instance `{:?}` not already declared\", instance)\n     };\n \n-    ccx.stats().n_closures.set(ccx.stats().n_closures.get() + 1);\n+    ccx.stats().borrow_mut().n_closures += 1;\n \n     // The `uwtable` attribute according to LLVM is:\n     //\n@@ -935,18 +937,14 @@ pub fn find_exported_symbols(tcx: TyCtxt) -> NodeSet {\n \n pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                              incremental_hashes_map: IncrementalHashesMap,\n-                             rx: mpsc::Receiver<Box<Any + Send>>,\n-                             output_filenames: &OutputFilenames)\n+                             rx: mpsc::Receiver<Box<Any + Send>>)\n                              -> OngoingCrateTranslation {\n     check_for_rustc_errors_attr(tcx);\n \n-    let check_overflow = tcx.sess.overflow_checks();\n     let link_meta = link::build_link_meta(&incremental_hashes_map);\n     let exported_symbol_node_ids = find_exported_symbols(tcx);\n \n-    let shared_ccx = SharedCrateContext::new(tcx,\n-                                             check_overflow,\n-                                             output_filenames);\n+    let shared_ccx = SharedCrateContext::new(tcx);\n     // Translate the metadata.\n     let (metadata_llcx, metadata_llmod, metadata, metadata_incr_hashes) =\n         time(tcx.sess.time_passes(), \"write metadata\", || {\n@@ -974,13 +972,13 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n        !tcx.sess.opts.output_types.should_trans() {\n         let ongoing_translation = write::start_async_translation(\n             tcx,\n-            output_filenames,\n             time_graph.clone(),\n             link_meta,\n             metadata,\n             rx);\n \n-        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, metadata_module, true);\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx, metadata_module);\n+        ongoing_translation.translation_finished(tcx);\n \n         assert_and_save_dep_graph(tcx,\n                                   incremental_hashes_map,\n@@ -1002,7 +1000,6 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n \n     let ongoing_translation = write::start_async_translation(\n         tcx,\n-        output_filenames,\n         time_graph.clone(),\n         link_meta,\n         metadata,\n@@ -1044,16 +1041,10 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     };\n \n     if let Some(allocator_module) = allocator_module {\n-        ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess, allocator_module, false);\n+        ongoing_translation.submit_pre_translated_module_to_llvm(tcx, allocator_module);\n     }\n \n-    let codegen_unit_count = codegen_units.len();\n-    ongoing_translation.submit_pre_translated_module_to_llvm(tcx.sess,\n-                                                             metadata_module,\n-                                                             codegen_unit_count == 0);\n-\n-    let mut all_stats = Stats::default();\n-    let mut module_dispositions = tcx.sess.opts.incremental.as_ref().map(|_| Vec::new());\n+    ongoing_translation.submit_pre_translated_module_to_llvm(tcx, metadata_module);\n \n     // We sort the codegen units by size. This way we can schedule work for LLVM\n     // a bit more efficiently. Note that \"size\" is defined rather crudely at the\n@@ -1066,217 +1057,57 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     };\n \n     let mut total_trans_time = Duration::new(0, 0);\n+    let mut all_stats = Stats::default();\n \n-    for (cgu_index, cgu) in codegen_units.into_iter().enumerate() {\n+    for cgu in codegen_units.into_iter() {\n         ongoing_translation.wait_for_signal_to_translate_item();\n         ongoing_translation.check_for_errors(tcx.sess);\n \n+        let _timing_guard = time_graph\n+            .as_ref()\n+            .map(|time_graph| time_graph.start(write::TRANS_WORKER_TIMELINE,\n+                                               write::TRANS_WORK_PACKAGE_KIND));\n         let start_time = Instant::now();\n+        all_stats.extend(tcx.compile_codegen_unit(*cgu.name()));\n+        total_trans_time += start_time.elapsed();\n \n-        let module = {\n-            let _timing_guard = time_graph\n-                .as_ref()\n-                .map(|time_graph| time_graph.start(write::TRANS_WORKER_TIMELINE,\n-                                                   write::TRANS_WORK_PACKAGE_KIND));\n-            let dep_node = cgu.work_product_dep_node();\n-            let ((stats, module), _) =\n-                tcx.dep_graph.with_task(dep_node,\n-                                        AssertDepGraphSafe(&shared_ccx),\n-                                        AssertDepGraphSafe(cgu),\n-                                        module_translation);\n-            all_stats.extend(stats);\n-\n-            if let Some(ref mut module_dispositions) = module_dispositions {\n-                module_dispositions.push(module.disposition());\n-            }\n-\n-            module\n-        };\n-\n-        let time_to_translate = Instant::now().duration_since(start_time);\n-\n-        // We assume that the cost to run LLVM on a CGU is proportional to\n-        // the time we needed for translating it.\n-        let cost = time_to_translate.as_secs() * 1_000_000_000 +\n-                   time_to_translate.subsec_nanos() as u64;\n-\n-        total_trans_time += time_to_translate;\n-\n-        let is_last_cgu = (cgu_index + 1) == codegen_unit_count;\n-\n-        ongoing_translation.submit_translated_module_to_llvm(tcx.sess,\n-                                                             module,\n-                                                             cost,\n-                                                             is_last_cgu);\n         ongoing_translation.check_for_errors(tcx.sess);\n     }\n \n+    ongoing_translation.translation_finished(tcx);\n+\n     // Since the main thread is sometimes blocked during trans, we keep track\n     // -Ztime-passes output manually.\n     print_time_passes_entry(tcx.sess.time_passes(),\n                             \"translate to LLVM IR\",\n                             total_trans_time);\n \n-    if let Some(module_dispositions) = module_dispositions {\n-        assert_module_sources::assert_module_sources(tcx, &module_dispositions);\n-    }\n-\n-    fn module_translation<'a, 'tcx>(\n-        scx: AssertDepGraphSafe<&SharedCrateContext<'a, 'tcx>>,\n-        args: AssertDepGraphSafe<Arc<CodegenUnit<'tcx>>>)\n-        -> (Stats, ModuleTranslation)\n-    {\n-        // FIXME(#40304): We ought to be using the id as a key and some queries, I think.\n-        let AssertDepGraphSafe(scx) = scx;\n-        let AssertDepGraphSafe(cgu) = args;\n-\n-        let cgu_name = cgu.name().to_string();\n-        let cgu_id = cgu.work_product_id();\n-        let symbol_name_hash = cgu.compute_symbol_name_hash(scx);\n-\n-        // Check whether there is a previous work-product we can\n-        // re-use.  Not only must the file exist, and the inputs not\n-        // be dirty, but the hash of the symbols we will generate must\n-        // be the same.\n-        let previous_work_product =\n-            scx.dep_graph().previous_work_product(&cgu_id).and_then(|work_product| {\n-                if work_product.input_hash == symbol_name_hash {\n-                    debug!(\"trans_reuse_previous_work_products: reusing {:?}\", work_product);\n-                    Some(work_product)\n-                } else {\n-                    if scx.sess().opts.debugging_opts.incremental_info {\n-                        eprintln!(\"incremental: CGU `{}` invalidated because of \\\n-                                   changed partitioning hash.\",\n-                                   cgu.name());\n-                    }\n-                    debug!(\"trans_reuse_previous_work_products: \\\n-                            not reusing {:?} because hash changed to {:?}\",\n-                           work_product, symbol_name_hash);\n-                    None\n-                }\n-            });\n-\n-        if let Some(buf) = previous_work_product {\n-            // Don't need to translate this module.\n-            let module = ModuleTranslation {\n-                name: cgu_name,\n-                symbol_name_hash,\n-                source: ModuleSource::Preexisting(buf.clone()),\n-                kind: ModuleKind::Regular,\n-            };\n-            return (Stats::default(), module);\n-        }\n-\n-        // Instantiate translation items without filling out definitions yet...\n-        let lcx = LocalCrateContext::new(scx, cgu);\n-        let module = {\n-            let ccx = CrateContext::new(scx, &lcx);\n-            let trans_items = ccx.codegen_unit()\n-                                 .items_in_deterministic_order(ccx.tcx());\n-            for &(trans_item, (linkage, visibility)) in &trans_items {\n-                trans_item.predefine(&ccx, linkage, visibility);\n-            }\n-\n-            // ... and now that we have everything pre-defined, fill out those definitions.\n-            for &(trans_item, _) in &trans_items {\n-                trans_item.define(&ccx);\n-            }\n-\n-            // If this codegen unit contains the main function, also create the\n-            // wrapper here\n-            maybe_create_entry_wrapper(&ccx);\n-\n-            // Run replace-all-uses-with for statics that need it\n-            for &(old_g, new_g) in ccx.statics_to_rauw().borrow().iter() {\n-                unsafe {\n-                    let bitcast = llvm::LLVMConstPointerCast(new_g, llvm::LLVMTypeOf(old_g));\n-                    llvm::LLVMReplaceAllUsesWith(old_g, bitcast);\n-                    llvm::LLVMDeleteGlobal(old_g);\n-                }\n-            }\n-\n-            // Create the llvm.used variable\n-            // This variable has type [N x i8*] and is stored in the llvm.metadata section\n-            if !ccx.used_statics().borrow().is_empty() {\n-                let name = CString::new(\"llvm.used\").unwrap();\n-                let section = CString::new(\"llvm.metadata\").unwrap();\n-                let array = C_array(Type::i8(&ccx).ptr_to(), &*ccx.used_statics().borrow());\n-\n-                unsafe {\n-                    let g = llvm::LLVMAddGlobal(ccx.llmod(),\n-                                                val_ty(array).to_ref(),\n-                                                name.as_ptr());\n-                    llvm::LLVMSetInitializer(g, array);\n-                    llvm::LLVMRustSetLinkage(g, llvm::Linkage::AppendingLinkage);\n-                    llvm::LLVMSetSection(g, section.as_ptr());\n-                }\n-            }\n-\n-            // Finalize debuginfo\n-            if ccx.sess().opts.debuginfo != NoDebugInfo {\n-                debuginfo::finalize(&ccx);\n-            }\n-\n-            let llvm_module = ModuleLlvm {\n-                llcx: ccx.llcx(),\n-                llmod: ccx.llmod(),\n-            };\n-\n-            // In LTO mode we inject the allocator shim into the existing\n-            // module.\n-            if ccx.sess().lto() {\n-                if let Some(kind) = ccx.sess().allocator_kind.get() {\n-                    time(ccx.sess().time_passes(), \"write allocator module\", || {\n-                        unsafe {\n-                            allocator::trans(ccx.tcx(), &llvm_module, kind);\n-                        }\n-                    });\n-                }\n-            }\n-\n-            // Adjust exported symbols for MSVC dllimport\n-            if ccx.sess().target.target.options.is_like_msvc &&\n-               ccx.sess().crate_types.borrow().iter().any(|ct| *ct == config::CrateTypeRlib) {\n-                create_imps(ccx.sess(), &llvm_module);\n-            }\n-\n-            ModuleTranslation {\n-                name: cgu_name,\n-                symbol_name_hash,\n-                source: ModuleSource::Translated(llvm_module),\n-                kind: ModuleKind::Regular,\n-            }\n-        };\n-\n-        (lcx.into_stats(), module)\n+    if tcx.sess.opts.incremental.is_some() {\n+        DISPOSITIONS.with(|d| {\n+            assert_module_sources::assert_module_sources(tcx, &d.borrow());\n+        });\n     }\n \n     symbol_names_test::report_symbol_names(tcx);\n \n     if shared_ccx.sess().trans_stats() {\n         println!(\"--- trans stats ---\");\n-        println!(\"n_glues_created: {}\", all_stats.n_glues_created.get());\n-        println!(\"n_null_glues: {}\", all_stats.n_null_glues.get());\n-        println!(\"n_real_glues: {}\", all_stats.n_real_glues.get());\n+        println!(\"n_glues_created: {}\", all_stats.n_glues_created);\n+        println!(\"n_null_glues: {}\", all_stats.n_null_glues);\n+        println!(\"n_real_glues: {}\", all_stats.n_real_glues);\n \n-        println!(\"n_fns: {}\", all_stats.n_fns.get());\n-        println!(\"n_inlines: {}\", all_stats.n_inlines.get());\n-        println!(\"n_closures: {}\", all_stats.n_closures.get());\n+        println!(\"n_fns: {}\", all_stats.n_fns);\n+        println!(\"n_inlines: {}\", all_stats.n_inlines);\n+        println!(\"n_closures: {}\", all_stats.n_closures);\n         println!(\"fn stats:\");\n-        all_stats.fn_stats.borrow_mut().sort_by(|&(_, insns_a), &(_, insns_b)| {\n-            insns_b.cmp(&insns_a)\n-        });\n-        for tuple in all_stats.fn_stats.borrow().iter() {\n-            match *tuple {\n-                (ref name, insns) => {\n-                    println!(\"{} insns, {}\", insns, *name);\n-                }\n-            }\n+        all_stats.fn_stats.sort_by_key(|&(_, insns)| insns);\n+        for &(ref name, insns) in all_stats.fn_stats.iter() {\n+            println!(\"{} insns, {}\", insns, *name);\n         }\n     }\n \n     if shared_ccx.sess().count_llvm_insns() {\n-        for (k, v) in all_stats.llvm_insns.borrow().iter() {\n+        for (k, v) in all_stats.llvm_insns.iter() {\n             println!(\"{:7} {}\", *v, *k);\n         }\n     }\n@@ -1290,6 +1121,10 @@ pub fn trans_crate<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     ongoing_translation\n }\n \n+// FIXME(#42293) hopefully once red/green is enabled we're testing everything\n+// via a method that doesn't require this!\n+thread_local!(static DISPOSITIONS: RefCell<Vec<(String, Disposition)>> = Default::default());\n+\n fn assert_and_save_dep_graph<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n                                        incremental_hashes_map: IncrementalHashesMap,\n                                        metadata_incr_hashes: EncodedMetadataHashes,\n@@ -1524,11 +1359,185 @@ fn is_translated_function(tcx: TyCtxt, id: DefId) -> bool {\n     })\n }\n \n+fn compile_codegen_unit<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                  cgu: InternedString) -> Stats {\n+    // FIXME(#42293) needs red/green tracking to avoid failing a bunch of\n+    // existing tests\n+    let cgu = tcx.dep_graph.with_ignore(|| {\n+        tcx.codegen_unit(cgu)\n+    });\n+\n+    let start_time = Instant::now();\n+    let dep_node = cgu.work_product_dep_node();\n+    let ((stats, module), _) =\n+        tcx.dep_graph.with_task(dep_node,\n+                                AssertDepGraphSafe(tcx),\n+                                AssertDepGraphSafe(cgu),\n+                                module_translation);\n+    let time_to_translate = start_time.elapsed();\n+\n+    if tcx.sess.opts.incremental.is_some() {\n+        DISPOSITIONS.with(|d| {\n+            d.borrow_mut().push(module.disposition());\n+        });\n+    }\n+\n+    // We assume that the cost to run LLVM on a CGU is proportional to\n+    // the time we needed for translating it.\n+    let cost = time_to_translate.as_secs() * 1_000_000_000 +\n+               time_to_translate.subsec_nanos() as u64;\n+\n+    write::submit_translated_module_to_llvm(tcx,\n+                                            module,\n+                                            cost);\n+    return stats;\n+\n+    fn module_translation<'a, 'tcx>(\n+        tcx: AssertDepGraphSafe<TyCtxt<'a, 'tcx, 'tcx>>,\n+        args: AssertDepGraphSafe<Arc<CodegenUnit<'tcx>>>)\n+        -> (Stats, ModuleTranslation)\n+    {\n+        // FIXME(#40304): We ought to be using the id as a key and some queries, I think.\n+        let AssertDepGraphSafe(tcx) = tcx;\n+        let AssertDepGraphSafe(cgu) = args;\n+\n+        let cgu_name = cgu.name().to_string();\n+        let cgu_id = cgu.work_product_id();\n+        let symbol_name_hash = cgu.compute_symbol_name_hash(tcx);\n+\n+        // Check whether there is a previous work-product we can\n+        // re-use.  Not only must the file exist, and the inputs not\n+        // be dirty, but the hash of the symbols we will generate must\n+        // be the same.\n+        let previous_work_product =\n+            tcx.dep_graph.previous_work_product(&cgu_id).and_then(|work_product| {\n+                if work_product.input_hash == symbol_name_hash {\n+                    debug!(\"trans_reuse_previous_work_products: reusing {:?}\", work_product);\n+                    Some(work_product)\n+                } else {\n+                    if tcx.sess.opts.debugging_opts.incremental_info {\n+                        eprintln!(\"incremental: CGU `{}` invalidated because of \\\n+                                   changed partitioning hash.\",\n+                                   cgu.name());\n+                    }\n+                    debug!(\"trans_reuse_previous_work_products: \\\n+                            not reusing {:?} because hash changed to {:?}\",\n+                           work_product, symbol_name_hash);\n+                    None\n+                }\n+            });\n+\n+        if let Some(buf) = previous_work_product {\n+            // Don't need to translate this module.\n+            let module = ModuleTranslation {\n+                name: cgu_name,\n+                symbol_name_hash,\n+                source: ModuleSource::Preexisting(buf.clone()),\n+                kind: ModuleKind::Regular,\n+            };\n+            return (Stats::default(), module);\n+        }\n+\n+        // Instantiate translation items without filling out definitions yet...\n+        let scx = SharedCrateContext::new(tcx);\n+        let lcx = LocalCrateContext::new(&scx, cgu);\n+        let module = {\n+            let ccx = CrateContext::new(&scx, &lcx);\n+            let trans_items = ccx.codegen_unit()\n+                                 .items_in_deterministic_order(ccx.tcx());\n+            for &(trans_item, (linkage, visibility)) in &trans_items {\n+                trans_item.predefine(&ccx, linkage, visibility);\n+            }\n+\n+            // ... and now that we have everything pre-defined, fill out those definitions.\n+            for &(trans_item, _) in &trans_items {\n+                trans_item.define(&ccx);\n+            }\n+\n+            // If this codegen unit contains the main function, also create the\n+            // wrapper here\n+            maybe_create_entry_wrapper(&ccx);\n+\n+            // Run replace-all-uses-with for statics that need it\n+            for &(old_g, new_g) in ccx.statics_to_rauw().borrow().iter() {\n+                unsafe {\n+                    let bitcast = llvm::LLVMConstPointerCast(new_g, llvm::LLVMTypeOf(old_g));\n+                    llvm::LLVMReplaceAllUsesWith(old_g, bitcast);\n+                    llvm::LLVMDeleteGlobal(old_g);\n+                }\n+            }\n+\n+            // Create the llvm.used variable\n+            // This variable has type [N x i8*] and is stored in the llvm.metadata section\n+            if !ccx.used_statics().borrow().is_empty() {\n+                let name = CString::new(\"llvm.used\").unwrap();\n+                let section = CString::new(\"llvm.metadata\").unwrap();\n+                let array = C_array(Type::i8(&ccx).ptr_to(), &*ccx.used_statics().borrow());\n+\n+                unsafe {\n+                    let g = llvm::LLVMAddGlobal(ccx.llmod(),\n+                                                val_ty(array).to_ref(),\n+                                                name.as_ptr());\n+                    llvm::LLVMSetInitializer(g, array);\n+                    llvm::LLVMRustSetLinkage(g, llvm::Linkage::AppendingLinkage);\n+                    llvm::LLVMSetSection(g, section.as_ptr());\n+                }\n+            }\n+\n+            // Finalize debuginfo\n+            if ccx.sess().opts.debuginfo != NoDebugInfo {\n+                debuginfo::finalize(&ccx);\n+            }\n+\n+            let llvm_module = ModuleLlvm {\n+                llcx: ccx.llcx(),\n+                llmod: ccx.llmod(),\n+            };\n+\n+            // In LTO mode we inject the allocator shim into the existing\n+            // module.\n+            if ccx.sess().lto() {\n+                if let Some(kind) = ccx.sess().allocator_kind.get() {\n+                    time(ccx.sess().time_passes(), \"write allocator module\", || {\n+                        unsafe {\n+                            allocator::trans(ccx.tcx(), &llvm_module, kind);\n+                        }\n+                    });\n+                }\n+            }\n+\n+            // Adjust exported symbols for MSVC dllimport\n+            if ccx.sess().target.target.options.is_like_msvc &&\n+               ccx.sess().crate_types.borrow().iter().any(|ct| *ct == config::CrateTypeRlib) {\n+                create_imps(ccx.sess(), &llvm_module);\n+            }\n+\n+            ModuleTranslation {\n+                name: cgu_name,\n+                symbol_name_hash,\n+                source: ModuleSource::Translated(llvm_module),\n+                kind: ModuleKind::Regular,\n+            }\n+        };\n+\n+        (lcx.into_stats(), module)\n+    }\n+}\n+\n pub fn provide_local(providers: &mut Providers) {\n     providers.collect_and_partition_translation_items =\n         collect_and_partition_translation_items;\n \n     providers.is_translated_function = is_translated_function;\n+\n+    providers.codegen_unit = |tcx, name| {\n+        let (_, all) = tcx.collect_and_partition_translation_items(LOCAL_CRATE);\n+        all.iter()\n+            .find(|cgu| *cgu.name() == name)\n+            .cloned()\n+            .expect(&format!(\"failed to find cgu with name {:?}\", name))\n+    };\n+    providers.compile_codegen_unit = compile_codegen_unit;\n }\n \n pub fn provide_extern(providers: &mut Providers) {"}, {"sha": "41a238ea8e3fae0f1b954fed5f0693b279c8fa28", "filename": "src/librustc_trans/builder.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fbuilder.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -101,11 +101,14 @@ impl<'a, 'tcx> Builder<'a, 'tcx> {\n \n     fn count_insn(&self, category: &str) {\n         if self.ccx.sess().trans_stats() {\n-            self.ccx.stats().n_llvm_insns.set(self.ccx.stats().n_llvm_insns.get() + 1);\n+            self.ccx.stats().borrow_mut().n_llvm_insns += 1;\n         }\n         if self.ccx.sess().count_llvm_insns() {\n-            let mut h = self.ccx.stats().llvm_insns.borrow_mut();\n-            *h.entry(category.to_string()).or_insert(0) += 1;\n+            *self.ccx.stats()\n+                .borrow_mut()\n+                .llvm_insns\n+                .entry(category.to_string())\n+                .or_insert(0) += 1;\n         }\n     }\n "}, {"sha": "8b18bf2e1ff1f0cb99fdc5191b80a7ec3955df0c", "filename": "src/librustc_trans/context.rs", "status": "modified", "additions": 10, "deletions": 48, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcontext.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -24,10 +24,11 @@ use monomorphize::Instance;\n use partitioning::CodegenUnit;\n use type_::Type;\n use rustc_data_structures::base_n;\n-use rustc::session::config::{self, NoDebugInfo, OutputFilenames};\n+use rustc::middle::trans::Stats;\n use rustc::session::Session;\n-use rustc::ty::{self, Ty, TyCtxt};\n+use rustc::session::config::{self, NoDebugInfo};\n use rustc::ty::layout::{LayoutCx, LayoutError, LayoutTyper, TyLayout};\n+use rustc::ty::{self, Ty, TyCtxt};\n use rustc::util::nodemap::FxHashMap;\n \n use std::ffi::{CStr, CString};\n@@ -40,47 +41,14 @@ use std::marker::PhantomData;\n use syntax::symbol::InternedString;\n use abi::Abi;\n \n-#[derive(Clone, Default)]\n-pub struct Stats {\n-    pub n_glues_created: Cell<usize>,\n-    pub n_null_glues: Cell<usize>,\n-    pub n_real_glues: Cell<usize>,\n-    pub n_fns: Cell<usize>,\n-    pub n_inlines: Cell<usize>,\n-    pub n_closures: Cell<usize>,\n-    pub n_llvm_insns: Cell<usize>,\n-    pub llvm_insns: RefCell<FxHashMap<String, usize>>,\n-    // (ident, llvm-instructions)\n-    pub fn_stats: RefCell<Vec<(String, usize)> >,\n-}\n-\n-impl Stats {\n-    pub fn extend(&mut self, stats: Stats) {\n-        self.n_glues_created.set(self.n_glues_created.get() + stats.n_glues_created.get());\n-        self.n_null_glues.set(self.n_null_glues.get() + stats.n_null_glues.get());\n-        self.n_real_glues.set(self.n_real_glues.get() + stats.n_real_glues.get());\n-        self.n_fns.set(self.n_fns.get() + stats.n_fns.get());\n-        self.n_inlines.set(self.n_inlines.get() + stats.n_inlines.get());\n-        self.n_closures.set(self.n_closures.get() + stats.n_closures.get());\n-        self.n_llvm_insns.set(self.n_llvm_insns.get() + stats.n_llvm_insns.get());\n-        self.llvm_insns.borrow_mut().extend(\n-            stats.llvm_insns.borrow().iter()\n-                                     .map(|(key, value)| (key.clone(), value.clone())));\n-        self.fn_stats.borrow_mut().append(&mut *stats.fn_stats.borrow_mut());\n-    }\n-}\n-\n /// The shared portion of a `CrateContext`.  There is one `SharedCrateContext`\n /// per crate.  The data here is shared between all compilation units of the\n /// crate, so it must not contain references to any LLVM data structures\n /// (aside from metadata-related ones).\n pub struct SharedCrateContext<'a, 'tcx: 'a> {\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     check_overflow: bool,\n-\n     use_dll_storage_attrs: bool,\n-\n-    output_filenames: &'a OutputFilenames,\n }\n \n /// The local portion of a `CrateContext`.  There is one `LocalCrateContext`\n@@ -90,7 +58,7 @@ pub struct SharedCrateContext<'a, 'tcx: 'a> {\n pub struct LocalCrateContext<'a, 'tcx: 'a> {\n     llmod: ModuleRef,\n     llcx: ContextRef,\n-    stats: Stats,\n+    stats: RefCell<Stats>,\n     codegen_unit: Arc<CodegenUnit<'tcx>>,\n \n     /// Cache instances of monomorphic and polymorphic items\n@@ -253,10 +221,7 @@ pub unsafe fn create_context_and_module(sess: &Session, mod_name: &str) -> (Cont\n }\n \n impl<'b, 'tcx> SharedCrateContext<'b, 'tcx> {\n-    pub fn new(tcx: TyCtxt<'b, 'tcx, 'tcx>,\n-               check_overflow: bool,\n-               output_filenames: &'b OutputFilenames)\n-               -> SharedCrateContext<'b, 'tcx> {\n+    pub fn new(tcx: TyCtxt<'b, 'tcx, 'tcx>) -> SharedCrateContext<'b, 'tcx> {\n         // An interesting part of Windows which MSVC forces our hand on (and\n         // apparently MinGW didn't) is the usage of `dllimport` and `dllexport`\n         // attributes in LLVM IR as well as native dependencies (in C these\n@@ -302,11 +267,12 @@ impl<'b, 'tcx> SharedCrateContext<'b, 'tcx> {\n         // start) and then strongly recommending static linkage on MSVC!\n         let use_dll_storage_attrs = tcx.sess.target.target.options.is_like_msvc;\n \n+        let check_overflow = tcx.sess.overflow_checks();\n+\n         SharedCrateContext {\n             tcx,\n             check_overflow,\n             use_dll_storage_attrs,\n-            output_filenames,\n         }\n     }\n \n@@ -337,10 +303,6 @@ impl<'b, 'tcx> SharedCrateContext<'b, 'tcx> {\n     pub fn use_dll_storage_attrs(&self) -> bool {\n         self.use_dll_storage_attrs\n     }\n-\n-    pub fn output_filenames(&self) -> &OutputFilenames {\n-        self.output_filenames\n-    }\n }\n \n impl<'a, 'tcx> LocalCrateContext<'a, 'tcx> {\n@@ -375,7 +337,7 @@ impl<'a, 'tcx> LocalCrateContext<'a, 'tcx> {\n             let local_ccx = LocalCrateContext {\n                 llmod,\n                 llcx,\n-                stats: Stats::default(),\n+                stats: RefCell::new(Stats::default()),\n                 codegen_unit,\n                 instances: RefCell::new(FxHashMap()),\n                 vtables: RefCell::new(FxHashMap()),\n@@ -440,7 +402,7 @@ impl<'a, 'tcx> LocalCrateContext<'a, 'tcx> {\n     }\n \n     pub fn into_stats(self) -> Stats {\n-        self.stats\n+        self.stats.into_inner()\n     }\n }\n \n@@ -525,7 +487,7 @@ impl<'b, 'tcx> CrateContext<'b, 'tcx> {\n         &self.local().lltypes\n     }\n \n-    pub fn stats<'a>(&'a self) -> &'a Stats {\n+    pub fn stats<'a>(&'a self) -> &'a RefCell<Stats> {\n         &self.local().stats\n     }\n "}, {"sha": "8a89bfee4ac26c43626c00b1b1aeda28db437730", "filename": "src/librustc_trans/debuginfo/metadata.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fdebuginfo%2Fmetadata.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -822,9 +822,9 @@ pub fn compile_unit_metadata(scc: &SharedCrateContext,\n \n             let gcov_cu_info = [\n                 path_to_mdstring(debug_context.llcontext,\n-                                 &scc.output_filenames().with_extension(\"gcno\")),\n+                                 &scc.tcx().output_filenames(LOCAL_CRATE).with_extension(\"gcno\")),\n                 path_to_mdstring(debug_context.llcontext,\n-                                 &scc.output_filenames().with_extension(\"gcda\")),\n+                                 &scc.tcx().output_filenames(LOCAL_CRATE).with_extension(\"gcda\")),\n                 cu_desc_metadata,\n             ];\n             let gcov_metadata = llvm::LLVMMDNodeInContext(debug_context.llcontext,"}, {"sha": "453b98a1d74f796f7931862fbcfd7d3e55c12abc", "filename": "src/librustc_trans/glue.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fglue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fglue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fglue.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -20,9 +20,8 @@ use llvm::{ValueRef};\n use llvm;\n use meth;\n use monomorphize;\n-use rustc::traits;\n use rustc::ty::layout::LayoutTyper;\n-use rustc::ty::{self, Ty, TypeFoldable, TyCtxt};\n+use rustc::ty::{self, Ty};\n use value::Value;\n \n pub fn size_and_align_of_dst<'a, 'tcx>(bcx: &Builder<'a, 'tcx>, t: Ty<'tcx>, info: ValueRef)"}, {"sha": "2be7a81b1cd4945af9c2a28e45ea4606503db628", "filename": "src/librustc_trans/monomorphize.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fmonomorphize.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fmonomorphize.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fmonomorphize.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -187,7 +187,7 @@ pub fn resolve<'a, 'tcx>(\n             _ => {\n                 if Some(def_id) == tcx.lang_items().drop_in_place_fn() {\n                     let ty = substs.type_at(0);\n-                    if common::type_needs_drop(tcx, ty) {\n+                    if type_needs_drop(tcx, ty) {\n                         debug!(\" => nontrivial drop glue\");\n                         ty::InstanceDef::DropGlue(def_id, Some(ty))\n                     } else {"}, {"sha": "9b617c35d93197f1fbfd333c57557cab146476c3", "filename": "src/librustc_trans/partitioning.rs", "status": "modified", "additions": 3, "deletions": 6, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fpartitioning.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustc_trans%2Fpartitioning.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fpartitioning.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -104,7 +104,6 @@\n \n use collector::InliningMap;\n use common;\n-use context::SharedCrateContext;\n use rustc::dep_graph::{DepNode, WorkProductId};\n use rustc::hir::def_id::DefId;\n use rustc::hir::map::DefPathData;\n@@ -155,13 +154,11 @@ pub trait CodegenUnitExt<'tcx> {\n         self.work_product_id().to_dep_node()\n     }\n \n-    fn compute_symbol_name_hash<'a>(&self,\n-                                    scx: &SharedCrateContext<'a, 'tcx>)\n-                                    -> u64 {\n+    fn compute_symbol_name_hash<'a>(&self, tcx: TyCtxt<'a, 'tcx, 'tcx>) -> u64 {\n         let mut state = IchHasher::new();\n-        let all_items = self.items_in_deterministic_order(scx.tcx());\n+        let all_items = self.items_in_deterministic_order(tcx);\n         for (item, (linkage, visibility)) in all_items {\n-            let symbol_name = item.symbol_name(scx.tcx());\n+            let symbol_name = item.symbol_name(tcx);\n             symbol_name.len().hash(&mut state);\n             symbol_name.hash(&mut state);\n             linkage.hash(&mut state);"}, {"sha": "0c0748cf673c1ebc3c1e4f0c78f6b4c44f369817", "filename": "src/librustdoc/core.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustdoc%2Fcore.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6d614ddc2ebc25d3987b1efc84c0c7fea00ce325/src%2Flibrustdoc%2Fcore.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fcore.rs?ref=6d614ddc2ebc25d3987b1efc84c0c7fea00ce325", "patch": "@@ -176,6 +176,11 @@ pub fn run_core(search_paths: SearchPaths,\n     let arena = DroplessArena::new();\n     let arenas = GlobalArenas::new();\n     let hir_map = hir_map::map_crate(&mut hir_forest, defs);\n+    let output_filenames = driver::build_output_filenames(&input,\n+                                                          &None,\n+                                                          &None,\n+                                                          &[],\n+                                                          &sess);\n \n     abort_on_err(driver::phase_3_run_analysis_passes(&sess,\n                                                      &*cstore,\n@@ -185,7 +190,8 @@ pub fn run_core(search_paths: SearchPaths,\n                                                      &arena,\n                                                      &arenas,\n                                                      &name,\n-                                                     |tcx, analysis, _, result| {\n+                                                     &output_filenames,\n+                                                     |tcx, analysis, _, _, result| {\n         if let Err(_) = result {\n             sess.fatal(\"Compilation failed, aborting rustdoc\");\n         }"}]}