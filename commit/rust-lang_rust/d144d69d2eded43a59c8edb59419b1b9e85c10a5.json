{"sha": "d144d69d2eded43a59c8edb59419b1b9e85c10a5", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQxNDRkNjlkMmVkZWQ0M2E1OWM4ZWRiNTk0MTliMWI5ZTg1YzEwYTU=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2020-06-22T11:50:34Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-06-22T11:50:34Z"}, "message": "Merge #4921\n\n4921: Allow SSR to match type references, items, paths and patterns r=davidlattimore a=davidlattimore\n\nPart of #3186\n\nCo-authored-by: David Lattimore <dml@google.com>", "tree": {"sha": "0d52bdbb15723d25b7d3fff9ad25274c72e43434", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0d52bdbb15723d25b7d3fff9ad25274c72e43434"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d144d69d2eded43a59c8edb59419b1b9e85c10a5", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe8JsKCRBK7hj4Ov3rIwAAdHIIAIOR7715glYXkQkckQKTGxf+\n16dtpHV+oIiaLm1uue1kuD+Xp/WX0x/e5Akeo00i7XK2FW39o4o4s7mY66qEpDnI\nbGogc2a8BznXSbeyoJ6h6GsOaLMZM9iQVnikM5M+JQgiZF92m2g7Y4zU9JVv5+uR\nSKJ7gbMQBRfnsHF/yKafNl/uL93aBawcAbh+s8cq8R7AyW5NqK6po3v/nSbfKbr8\nhq7YEMddq2jfg8G8wdiZqHDh9gV39wu6QF05uXEhVwRrENwckEnmr9bD1XToup3e\nFpcInqz6m3htuSRWPE7ifIYtn0jdOo0EGekinf4jnhZUoe78RUBMCPzvxglFu10=\n=JhSW\n-----END PGP SIGNATURE-----\n", "payload": "tree 0d52bdbb15723d25b7d3fff9ad25274c72e43434\nparent 19701b39ac232b023ff9ab077a33c743df96d178\nparent 662ab2ecc8e29eb5995b3c162fac869838bea9a2\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1592826634 +0000\ncommitter GitHub <noreply@github.com> 1592826634 +0000\n\nMerge #4921\n\n4921: Allow SSR to match type references, items, paths and patterns r=davidlattimore a=davidlattimore\n\nPart of #3186\n\nCo-authored-by: David Lattimore <dml@google.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d144d69d2eded43a59c8edb59419b1b9e85c10a5", "html_url": "https://github.com/rust-lang/rust/commit/d144d69d2eded43a59c8edb59419b1b9e85c10a5", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d144d69d2eded43a59c8edb59419b1b9e85c10a5/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "19701b39ac232b023ff9ab077a33c743df96d178", "url": "https://api.github.com/repos/rust-lang/rust/commits/19701b39ac232b023ff9ab077a33c743df96d178", "html_url": "https://github.com/rust-lang/rust/commit/19701b39ac232b023ff9ab077a33c743df96d178"}, {"sha": "662ab2ecc8e29eb5995b3c162fac869838bea9a2", "url": "https://api.github.com/repos/rust-lang/rust/commits/662ab2ecc8e29eb5995b3c162fac869838bea9a2", "html_url": "https://github.com/rust-lang/rust/commit/662ab2ecc8e29eb5995b3c162fac869838bea9a2"}], "stats": {"total": 2035, "additions": 1480, "deletions": 555}, "files": [{"sha": "d909bc3d5e19431d6d82f3dc234ffebaab7ade3e", "filename": "Cargo.lock", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -1075,6 +1075,7 @@ dependencies = [\n  \"ra_hir\",\n  \"ra_ide_db\",\n  \"ra_prof\",\n+ \"ra_ssr\",\n  \"ra_syntax\",\n  \"ra_text_edit\",\n  \"rand\",\n@@ -1179,6 +1180,18 @@ dependencies = [\n  \"serde_json\",\n ]\n \n+[[package]]\n+name = \"ra_ssr\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"ra_db\",\n+ \"ra_hir\",\n+ \"ra_ide_db\",\n+ \"ra_syntax\",\n+ \"ra_text_edit\",\n+ \"rustc-hash\",\n+]\n+\n [[package]]\n name = \"ra_syntax\"\n version = \"0.1.0\""}, {"sha": "bbc6a5c9b8afb34f672f366895304ac2754435d2", "filename": "crates/ra_ide/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2FCargo.toml?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -29,6 +29,7 @@ ra_fmt = { path = \"../ra_fmt\" }\n ra_prof = { path = \"../ra_prof\" }\n test_utils = { path = \"../test_utils\" }\n ra_assists = { path = \"../ra_assists\" }\n+ra_ssr = { path = \"../ra_ssr\" }\n \n # ra_ide should depend only on the top-level `hir` package. if you need\n # something from some `hir_xxx` subpackage, reexport the API via `hir`."}, {"sha": "47823718fd18d6dda4a697c7adcebb14dfb0cc1e", "filename": "crates/ra_ide/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Flib.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -70,7 +70,6 @@ pub use crate::{\n     inlay_hints::{InlayHint, InlayHintsConfig, InlayKind},\n     references::{Declaration, Reference, ReferenceAccess, ReferenceKind, ReferenceSearchResult},\n     runnables::{Runnable, RunnableKind, TestId},\n-    ssr::SsrError,\n     syntax_highlighting::{\n         Highlight, HighlightModifier, HighlightModifiers, HighlightTag, HighlightedRange,\n     },\n@@ -89,6 +88,7 @@ pub use ra_ide_db::{\n     symbol_index::Query,\n     RootDatabase,\n };\n+pub use ra_ssr::SsrError;\n pub use ra_text_edit::{Indel, TextEdit};\n \n pub type Cancelable<T> = Result<T, Canceled>;"}, {"sha": "59c230f6cd86180d08fffa3f01151701b73b3ea2", "filename": "crates/ra_ide/src/ssr.rs", "status": "modified", "additions": 9, "deletions": 554, "changes": 563, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2Fsrc%2Fssr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ide%2Fsrc%2Fssr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide%2Fsrc%2Fssr.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -1,31 +1,12 @@\n-use std::{collections::HashMap, iter::once, str::FromStr};\n-\n-use ra_db::{SourceDatabase, SourceDatabaseExt};\n+use ra_db::SourceDatabaseExt;\n use ra_ide_db::{symbol_index::SymbolsDatabase, RootDatabase};\n-use ra_syntax::ast::{\n-    make::try_expr_from_text, ArgList, AstToken, CallExpr, Comment, Expr, MethodCallExpr,\n-    RecordField, RecordLit,\n-};\n-use ra_syntax::{AstNode, SyntaxElement, SyntaxKind, SyntaxNode};\n-use ra_text_edit::{TextEdit, TextEditBuilder};\n-use rustc_hash::FxHashMap;\n \n use crate::SourceFileEdit;\n-\n-#[derive(Debug, PartialEq)]\n-pub struct SsrError(String);\n-\n-impl std::fmt::Display for SsrError {\n-    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n-        write!(f, \"Parse error: {}\", self.0)\n-    }\n-}\n-\n-impl std::error::Error for SsrError {}\n+use ra_ssr::{MatchFinder, SsrError, SsrRule};\n \n // Feature: Structural Seach and Replace\n //\n-// Search and replace with named wildcards that will match any expression.\n+// Search and replace with named wildcards that will match any expression, type, path, pattern or item.\n // The syntax for a structural search replace command is `<search_pattern> ==>> <replace_pattern>`.\n // A `$<name>` placeholder in the search pattern will match any AST node and `$<name>` will reference it in the replacement.\n // Available via the command `rust-analyzer.ssr`.\n@@ -46,550 +27,24 @@ impl std::error::Error for SsrError {}\n // | VS Code | **Rust Analyzer: Structural Search Replace**\n // |===\n pub fn parse_search_replace(\n-    query: &str,\n+    rule: &str,\n     parse_only: bool,\n     db: &RootDatabase,\n ) -> Result<Vec<SourceFileEdit>, SsrError> {\n     let mut edits = vec![];\n-    let query: SsrQuery = query.parse()?;\n+    let rule: SsrRule = rule.parse()?;\n     if parse_only {\n         return Ok(edits);\n     }\n+    let mut match_finder = MatchFinder::new(db);\n+    match_finder.add_rule(rule);\n     for &root in db.local_roots().iter() {\n         let sr = db.source_root(root);\n         for file_id in sr.walk() {\n-            let matches = find(&query.pattern, db.parse(file_id).tree().syntax());\n-            if !matches.matches.is_empty() {\n-                edits.push(SourceFileEdit { file_id, edit: replace(&matches, &query.template) });\n+            if let Some(edit) = match_finder.edits_for_file(file_id) {\n+                edits.push(SourceFileEdit { file_id, edit });\n             }\n         }\n     }\n     Ok(edits)\n }\n-\n-#[derive(Debug)]\n-struct SsrQuery {\n-    pattern: SsrPattern,\n-    template: SsrTemplate,\n-}\n-\n-#[derive(Debug)]\n-struct SsrPattern {\n-    pattern: SyntaxNode,\n-    vars: Vec<Var>,\n-}\n-\n-/// Represents a `$var` in an SSR query.\n-#[derive(Debug, Clone, PartialEq, Eq, Hash)]\n-struct Var(String);\n-\n-#[derive(Debug)]\n-struct SsrTemplate {\n-    template: SyntaxNode,\n-    placeholders: FxHashMap<SyntaxNode, Var>,\n-}\n-\n-type Binding = HashMap<Var, SyntaxNode>;\n-\n-#[derive(Debug)]\n-struct Match {\n-    place: SyntaxNode,\n-    binding: Binding,\n-    ignored_comments: Vec<Comment>,\n-}\n-\n-#[derive(Debug)]\n-struct SsrMatches {\n-    matches: Vec<Match>,\n-}\n-\n-impl FromStr for SsrQuery {\n-    type Err = SsrError;\n-\n-    fn from_str(query: &str) -> Result<SsrQuery, SsrError> {\n-        let mut it = query.split(\"==>>\");\n-        let pattern = it.next().expect(\"at least empty string\").trim();\n-        let mut template = it\n-            .next()\n-            .ok_or_else(|| SsrError(\"Cannot find delemiter `==>>`\".into()))?\n-            .trim()\n-            .to_string();\n-        if it.next().is_some() {\n-            return Err(SsrError(\"More than one delimiter found\".into()));\n-        }\n-        let mut vars = vec![];\n-        let mut it = pattern.split('$');\n-        let mut pattern = it.next().expect(\"something\").to_string();\n-\n-        for part in it.map(split_by_var) {\n-            let (var, remainder) = part?;\n-            let new_var = create_name(var, &mut vars)?;\n-            pattern.push_str(new_var);\n-            pattern.push_str(remainder);\n-            template = replace_in_template(template, var, new_var);\n-        }\n-\n-        let template = try_expr_from_text(&template)\n-            .ok_or(SsrError(\"Template is not an expression\".into()))?\n-            .syntax()\n-            .clone();\n-        let mut placeholders = FxHashMap::default();\n-\n-        traverse(&template, &mut |n| {\n-            if let Some(v) = vars.iter().find(|v| v.0.as_str() == n.text()) {\n-                placeholders.insert(n.clone(), v.clone());\n-                false\n-            } else {\n-                true\n-            }\n-        });\n-\n-        let pattern = SsrPattern {\n-            pattern: try_expr_from_text(&pattern)\n-                .ok_or(SsrError(\"Pattern is not an expression\".into()))?\n-                .syntax()\n-                .clone(),\n-            vars,\n-        };\n-        let template = SsrTemplate { template, placeholders };\n-        Ok(SsrQuery { pattern, template })\n-    }\n-}\n-\n-fn traverse(node: &SyntaxNode, go: &mut impl FnMut(&SyntaxNode) -> bool) {\n-    if !go(node) {\n-        return;\n-    }\n-    for ref child in node.children() {\n-        traverse(child, go);\n-    }\n-}\n-\n-fn split_by_var(s: &str) -> Result<(&str, &str), SsrError> {\n-    let end_of_name = s.find(|c| !char::is_ascii_alphanumeric(&c)).unwrap_or_else(|| s.len());\n-    let name = &s[..end_of_name];\n-    is_name(name)?;\n-    Ok((name, &s[end_of_name..]))\n-}\n-\n-fn is_name(s: &str) -> Result<(), SsrError> {\n-    if s.chars().all(|c| c.is_ascii_alphanumeric() || c == '_') {\n-        Ok(())\n-    } else {\n-        Err(SsrError(\"Name can contain only alphanumerics and _\".into()))\n-    }\n-}\n-\n-fn replace_in_template(template: String, var: &str, new_var: &str) -> String {\n-    let name = format!(\"${}\", var);\n-    template.replace(&name, new_var)\n-}\n-\n-fn create_name<'a>(name: &str, vars: &'a mut Vec<Var>) -> Result<&'a str, SsrError> {\n-    let sanitized_name = format!(\"__search_pattern_{}\", name);\n-    if vars.iter().any(|a| a.0 == sanitized_name) {\n-        return Err(SsrError(format!(\"Name `{}` repeats more than once\", name)));\n-    }\n-    vars.push(Var(sanitized_name));\n-    Ok(&vars.last().unwrap().0)\n-}\n-\n-fn find(pattern: &SsrPattern, code: &SyntaxNode) -> SsrMatches {\n-    fn check_record_lit(\n-        pattern: RecordLit,\n-        code: RecordLit,\n-        placeholders: &[Var],\n-        match_: Match,\n-    ) -> Option<Match> {\n-        let match_ = check_opt_nodes(pattern.path(), code.path(), placeholders, match_)?;\n-\n-        let mut pattern_fields: Vec<RecordField> =\n-            pattern.record_field_list().map(|x| x.fields().collect()).unwrap_or_default();\n-        let mut code_fields: Vec<RecordField> =\n-            code.record_field_list().map(|x| x.fields().collect()).unwrap_or_default();\n-\n-        if pattern_fields.len() != code_fields.len() {\n-            return None;\n-        }\n-\n-        let by_name = |a: &RecordField, b: &RecordField| {\n-            a.name_ref()\n-                .map(|x| x.syntax().text().to_string())\n-                .cmp(&b.name_ref().map(|x| x.syntax().text().to_string()))\n-        };\n-        pattern_fields.sort_by(by_name);\n-        code_fields.sort_by(by_name);\n-\n-        pattern_fields.into_iter().zip(code_fields.into_iter()).fold(\n-            Some(match_),\n-            |accum, (a, b)| {\n-                accum.and_then(|match_| check_opt_nodes(Some(a), Some(b), placeholders, match_))\n-            },\n-        )\n-    }\n-\n-    fn check_call_and_method_call(\n-        pattern: CallExpr,\n-        code: MethodCallExpr,\n-        placeholders: &[Var],\n-        match_: Match,\n-    ) -> Option<Match> {\n-        let (pattern_name, pattern_type_args) = if let Some(Expr::PathExpr(path_exr)) =\n-            pattern.expr()\n-        {\n-            let segment = path_exr.path().and_then(|p| p.segment());\n-            (segment.as_ref().and_then(|s| s.name_ref()), segment.and_then(|s| s.type_arg_list()))\n-        } else {\n-            (None, None)\n-        };\n-        let match_ = check_opt_nodes(pattern_name, code.name_ref(), placeholders, match_)?;\n-        let match_ =\n-            check_opt_nodes(pattern_type_args, code.type_arg_list(), placeholders, match_)?;\n-        let pattern_args = pattern.syntax().children().find_map(ArgList::cast)?.args();\n-        let code_args = code.syntax().children().find_map(ArgList::cast)?.args();\n-        let code_args = once(code.expr()?).chain(code_args);\n-        check_iter(pattern_args, code_args, placeholders, match_)\n-    }\n-\n-    fn check_method_call_and_call(\n-        pattern: MethodCallExpr,\n-        code: CallExpr,\n-        placeholders: &[Var],\n-        match_: Match,\n-    ) -> Option<Match> {\n-        let (code_name, code_type_args) = if let Some(Expr::PathExpr(path_exr)) = code.expr() {\n-            let segment = path_exr.path().and_then(|p| p.segment());\n-            (segment.as_ref().and_then(|s| s.name_ref()), segment.and_then(|s| s.type_arg_list()))\n-        } else {\n-            (None, None)\n-        };\n-        let match_ = check_opt_nodes(pattern.name_ref(), code_name, placeholders, match_)?;\n-        let match_ =\n-            check_opt_nodes(pattern.type_arg_list(), code_type_args, placeholders, match_)?;\n-        let code_args = code.syntax().children().find_map(ArgList::cast)?.args();\n-        let pattern_args = pattern.syntax().children().find_map(ArgList::cast)?.args();\n-        let pattern_args = once(pattern.expr()?).chain(pattern_args);\n-        check_iter(pattern_args, code_args, placeholders, match_)\n-    }\n-\n-    fn check_opt_nodes(\n-        pattern: Option<impl AstNode>,\n-        code: Option<impl AstNode>,\n-        placeholders: &[Var],\n-        match_: Match,\n-    ) -> Option<Match> {\n-        match (pattern, code) {\n-            (Some(pattern), Some(code)) => check(\n-                &pattern.syntax().clone().into(),\n-                &code.syntax().clone().into(),\n-                placeholders,\n-                match_,\n-            ),\n-            (None, None) => Some(match_),\n-            _ => None,\n-        }\n-    }\n-\n-    fn check_iter<T, I1, I2>(\n-        mut pattern: I1,\n-        mut code: I2,\n-        placeholders: &[Var],\n-        match_: Match,\n-    ) -> Option<Match>\n-    where\n-        T: AstNode,\n-        I1: Iterator<Item = T>,\n-        I2: Iterator<Item = T>,\n-    {\n-        pattern\n-            .by_ref()\n-            .zip(code.by_ref())\n-            .fold(Some(match_), |accum, (a, b)| {\n-                accum.and_then(|match_| {\n-                    check(\n-                        &a.syntax().clone().into(),\n-                        &b.syntax().clone().into(),\n-                        placeholders,\n-                        match_,\n-                    )\n-                })\n-            })\n-            .filter(|_| pattern.next().is_none() && code.next().is_none())\n-    }\n-\n-    fn check(\n-        pattern: &SyntaxElement,\n-        code: &SyntaxElement,\n-        placeholders: &[Var],\n-        mut match_: Match,\n-    ) -> Option<Match> {\n-        match (&pattern, &code) {\n-            (SyntaxElement::Token(pattern), SyntaxElement::Token(code)) => {\n-                if pattern.text() == code.text() {\n-                    Some(match_)\n-                } else {\n-                    None\n-                }\n-            }\n-            (SyntaxElement::Node(pattern), SyntaxElement::Node(code)) => {\n-                if placeholders.iter().any(|n| n.0.as_str() == pattern.text()) {\n-                    match_.binding.insert(Var(pattern.text().to_string()), code.clone());\n-                    Some(match_)\n-                } else {\n-                    if let (Some(pattern), Some(code)) =\n-                        (RecordLit::cast(pattern.clone()), RecordLit::cast(code.clone()))\n-                    {\n-                        check_record_lit(pattern, code, placeholders, match_)\n-                    } else if let (Some(pattern), Some(code)) =\n-                        (CallExpr::cast(pattern.clone()), MethodCallExpr::cast(code.clone()))\n-                    {\n-                        check_call_and_method_call(pattern, code, placeholders, match_)\n-                    } else if let (Some(pattern), Some(code)) =\n-                        (MethodCallExpr::cast(pattern.clone()), CallExpr::cast(code.clone()))\n-                    {\n-                        check_method_call_and_call(pattern, code, placeholders, match_)\n-                    } else {\n-                        let mut pattern_children = pattern\n-                            .children_with_tokens()\n-                            .filter(|element| !element.kind().is_trivia());\n-                        let mut code_children = code\n-                            .children_with_tokens()\n-                            .filter(|element| !element.kind().is_trivia());\n-                        let new_ignored_comments =\n-                            code.children_with_tokens().filter_map(|element| {\n-                                element.as_token().and_then(|token| Comment::cast(token.clone()))\n-                            });\n-                        match_.ignored_comments.extend(new_ignored_comments);\n-                        pattern_children\n-                            .by_ref()\n-                            .zip(code_children.by_ref())\n-                            .fold(Some(match_), |accum, (a, b)| {\n-                                accum.and_then(|match_| check(&a, &b, placeholders, match_))\n-                            })\n-                            .filter(|_| {\n-                                pattern_children.next().is_none() && code_children.next().is_none()\n-                            })\n-                    }\n-                }\n-            }\n-            _ => None,\n-        }\n-    }\n-    let kind = pattern.pattern.kind();\n-    let matches = code\n-        .descendants()\n-        .filter(|n| {\n-            n.kind() == kind\n-                || (kind == SyntaxKind::CALL_EXPR && n.kind() == SyntaxKind::METHOD_CALL_EXPR)\n-                || (kind == SyntaxKind::METHOD_CALL_EXPR && n.kind() == SyntaxKind::CALL_EXPR)\n-        })\n-        .filter_map(|code| {\n-            let match_ =\n-                Match { place: code.clone(), binding: HashMap::new(), ignored_comments: vec![] };\n-            check(&pattern.pattern.clone().into(), &code.into(), &pattern.vars, match_)\n-        })\n-        .collect();\n-    SsrMatches { matches }\n-}\n-\n-fn replace(matches: &SsrMatches, template: &SsrTemplate) -> TextEdit {\n-    let mut builder = TextEditBuilder::default();\n-    for match_ in &matches.matches {\n-        builder.replace(\n-            match_.place.text_range(),\n-            render_replace(&match_.binding, &match_.ignored_comments, template),\n-        );\n-    }\n-    builder.finish()\n-}\n-\n-fn render_replace(\n-    binding: &Binding,\n-    ignored_comments: &Vec<Comment>,\n-    template: &SsrTemplate,\n-) -> String {\n-    let edit = {\n-        let mut builder = TextEditBuilder::default();\n-        for element in template.template.descendants() {\n-            if let Some(var) = template.placeholders.get(&element) {\n-                builder.replace(element.text_range(), binding[var].to_string())\n-            }\n-        }\n-        for comment in ignored_comments {\n-            builder.insert(template.template.text_range().end(), comment.syntax().to_string())\n-        }\n-        builder.finish()\n-    };\n-\n-    let mut text = template.template.text().to_string();\n-    edit.apply(&mut text);\n-    text\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use super::*;\n-    use ra_syntax::SourceFile;\n-\n-    fn parse_error_text(query: &str) -> String {\n-        format!(\"{}\", query.parse::<SsrQuery>().unwrap_err())\n-    }\n-\n-    #[test]\n-    fn parser_happy_case() {\n-        let result: SsrQuery = \"foo($a, $b) ==>> bar($b, $a)\".parse().unwrap();\n-        assert_eq!(&result.pattern.pattern.text(), \"foo(__search_pattern_a, __search_pattern_b)\");\n-        assert_eq!(result.pattern.vars.len(), 2);\n-        assert_eq!(result.pattern.vars[0].0, \"__search_pattern_a\");\n-        assert_eq!(result.pattern.vars[1].0, \"__search_pattern_b\");\n-        assert_eq!(&result.template.template.text(), \"bar(__search_pattern_b, __search_pattern_a)\");\n-    }\n-\n-    #[test]\n-    fn parser_empty_query() {\n-        assert_eq!(parse_error_text(\"\"), \"Parse error: Cannot find delemiter `==>>`\");\n-    }\n-\n-    #[test]\n-    fn parser_no_delimiter() {\n-        assert_eq!(parse_error_text(\"foo()\"), \"Parse error: Cannot find delemiter `==>>`\");\n-    }\n-\n-    #[test]\n-    fn parser_two_delimiters() {\n-        assert_eq!(\n-            parse_error_text(\"foo() ==>> a ==>> b \"),\n-            \"Parse error: More than one delimiter found\"\n-        );\n-    }\n-\n-    #[test]\n-    fn parser_repeated_name() {\n-        assert_eq!(\n-            parse_error_text(\"foo($a, $a) ==>>\"),\n-            \"Parse error: Name `a` repeats more than once\"\n-        );\n-    }\n-\n-    #[test]\n-    fn parser_invlid_pattern() {\n-        assert_eq!(parse_error_text(\" ==>> ()\"), \"Parse error: Pattern is not an expression\");\n-    }\n-\n-    #[test]\n-    fn parser_invlid_template() {\n-        assert_eq!(parse_error_text(\"() ==>> )\"), \"Parse error: Template is not an expression\");\n-    }\n-\n-    #[test]\n-    fn parse_match_replace() {\n-        let query: SsrQuery = \"foo($x) ==>> bar($x)\".parse().unwrap();\n-        let input = \"fn main() { foo(1+2); }\";\n-\n-        let code = SourceFile::parse(input).tree();\n-        let matches = find(&query.pattern, code.syntax());\n-        assert_eq!(matches.matches.len(), 1);\n-        assert_eq!(matches.matches[0].place.text(), \"foo(1+2)\");\n-        assert_eq!(matches.matches[0].binding.len(), 1);\n-        assert_eq!(\n-            matches.matches[0].binding[&Var(\"__search_pattern_x\".to_string())].text(),\n-            \"1+2\"\n-        );\n-\n-        let edit = replace(&matches, &query.template);\n-        let mut after = input.to_string();\n-        edit.apply(&mut after);\n-        assert_eq!(after, \"fn main() { bar(1+2); }\");\n-    }\n-\n-    fn assert_ssr_transform(query: &str, input: &str, result: &str) {\n-        let query: SsrQuery = query.parse().unwrap();\n-        let code = SourceFile::parse(input).tree();\n-        let matches = find(&query.pattern, code.syntax());\n-        let edit = replace(&matches, &query.template);\n-        let mut after = input.to_string();\n-        edit.apply(&mut after);\n-        assert_eq!(after, result);\n-    }\n-\n-    #[test]\n-    fn ssr_function_to_method() {\n-        assert_ssr_transform(\n-            \"my_function($a, $b) ==>> ($a).my_method($b)\",\n-            \"loop { my_function( other_func(x, y), z + w) }\",\n-            \"loop { (other_func(x, y)).my_method(z + w) }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_nested_function() {\n-        assert_ssr_transform(\n-            \"foo($a, $b, $c) ==>> bar($c, baz($a, $b))\",\n-            \"fn main { foo  (x + value.method(b), x+y-z, true && false) }\",\n-            \"fn main { bar(true && false, baz(x + value.method(b), x+y-z)) }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_expected_spacing() {\n-        assert_ssr_transform(\n-            \"foo($x) + bar() ==>> bar($x)\",\n-            \"fn main() { foo(5) + bar() }\",\n-            \"fn main() { bar(5) }\",\n-        );\n-    }\n-\n-    #[test]\n-    fn ssr_with_extra_space() {\n-        assert_ssr_transform(\n-            \"foo($x  ) +    bar() ==>> bar($x)\",\n-            \"fn main() { foo(  5 )  +bar(   ) }\",\n-            \"fn main() { bar(5) }\",\n-        );\n-    }\n-\n-    #[test]\n-    fn ssr_keeps_nested_comment() {\n-        assert_ssr_transform(\n-            \"foo($x) ==>> bar($x)\",\n-            \"fn main() { foo(other(5 /* using 5 */)) }\",\n-            \"fn main() { bar(other(5 /* using 5 */)) }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_keeps_comment() {\n-        assert_ssr_transform(\n-            \"foo($x) ==>> bar($x)\",\n-            \"fn main() { foo(5 /* using 5 */) }\",\n-            \"fn main() { bar(5)/* using 5 */ }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_struct_lit() {\n-        assert_ssr_transform(\n-            \"foo{a: $a, b: $b} ==>> foo::new($a, $b)\",\n-            \"fn main() { foo{b:2, a:1} }\",\n-            \"fn main() { foo::new(1, 2) }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_call_and_method_call() {\n-        assert_ssr_transform(\n-            \"foo::<'a>($a, $b)) ==>> foo2($a, $b)\",\n-            \"fn main() { get().bar.foo::<'a>(1); }\",\n-            \"fn main() { foo2(get().bar, 1); }\",\n-        )\n-    }\n-\n-    #[test]\n-    fn ssr_method_call_and_call() {\n-        assert_ssr_transform(\n-            \"$o.foo::<i32>($a)) ==>> $o.foo2($a)\",\n-            \"fn main() { X::foo::<i32>(x, 1); }\",\n-            \"fn main() { x.foo2(1); }\",\n-        )\n-    }\n-}"}, {"sha": "3c2f15a833223f1b957eda260c2229b90a712c59", "filename": "crates/ra_ssr/Cargo.toml", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2FCargo.toml?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,19 @@\n+[package]\n+edition = \"2018\"\n+name = \"ra_ssr\"\n+version = \"0.1.0\"\n+authors = [\"rust-analyzer developers\"]\n+license = \"MIT OR Apache-2.0\"\n+description = \"Structural search and replace of Rust code\"\n+repository = \"https://github.com/rust-analyzer/rust-analyzer\"\n+\n+[lib]\n+doctest = false\n+\n+[dependencies]\n+ra_text_edit = { path = \"../ra_text_edit\" }\n+ra_syntax = { path = \"../ra_syntax\" }\n+ra_db = { path = \"../ra_db\" }\n+ra_ide_db = { path = \"../ra_ide_db\" }\n+hir = { path = \"../ra_hir\", package = \"ra_hir\" }\n+rustc-hash = \"1.1.0\""}, {"sha": "fc716ae82936d16ee7c07456748b81a9429f7036", "filename": "crates/ra_ssr/src/lib.rs", "status": "added", "additions": 120, "deletions": 0, "changes": 120, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Flib.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,120 @@\n+//! Structural Search Replace\n+//!\n+//! Allows searching the AST for code that matches one or more patterns and then replacing that code\n+//! based on a template.\n+\n+mod matching;\n+mod parsing;\n+mod replacing;\n+#[cfg(test)]\n+mod tests;\n+\n+use crate::matching::Match;\n+use hir::Semantics;\n+use ra_db::{FileId, FileRange};\n+use ra_syntax::{AstNode, SmolStr, SyntaxNode};\n+use ra_text_edit::TextEdit;\n+use rustc_hash::FxHashMap;\n+\n+// A structured search replace rule. Create by calling `parse` on a str.\n+#[derive(Debug)]\n+pub struct SsrRule {\n+    /// A structured pattern that we're searching for.\n+    pattern: SsrPattern,\n+    /// What we'll replace it with.\n+    template: parsing::SsrTemplate,\n+}\n+\n+#[derive(Debug)]\n+struct SsrPattern {\n+    raw: parsing::RawSearchPattern,\n+    /// Placeholders keyed by the stand-in ident that we use in Rust source code.\n+    placeholders_by_stand_in: FxHashMap<SmolStr, parsing::Placeholder>,\n+    // We store our search pattern, parsed as each different kind of thing we can look for. As we\n+    // traverse the AST, we get the appropriate one of these for the type of node we're on. For many\n+    // search patterns, only some of these will be present.\n+    expr: Option<SyntaxNode>,\n+    type_ref: Option<SyntaxNode>,\n+    item: Option<SyntaxNode>,\n+    path: Option<SyntaxNode>,\n+    pattern: Option<SyntaxNode>,\n+}\n+\n+#[derive(Debug, PartialEq)]\n+pub struct SsrError(String);\n+\n+#[derive(Debug, Default)]\n+pub struct SsrMatches {\n+    matches: Vec<Match>,\n+}\n+\n+/// Searches a crate for pattern matches and possibly replaces them with something else.\n+pub struct MatchFinder<'db> {\n+    /// Our source of information about the user's code.\n+    sema: Semantics<'db, ra_ide_db::RootDatabase>,\n+    rules: Vec<SsrRule>,\n+}\n+\n+impl<'db> MatchFinder<'db> {\n+    pub fn new(db: &'db ra_ide_db::RootDatabase) -> MatchFinder<'db> {\n+        MatchFinder { sema: Semantics::new(db), rules: Vec::new() }\n+    }\n+\n+    pub fn add_rule(&mut self, rule: SsrRule) {\n+        self.rules.push(rule);\n+    }\n+\n+    pub fn edits_for_file(&self, file_id: FileId) -> Option<TextEdit> {\n+        let matches = self.find_matches_in_file(file_id);\n+        if matches.matches.is_empty() {\n+            None\n+        } else {\n+            Some(replacing::matches_to_edit(&matches))\n+        }\n+    }\n+\n+    fn find_matches_in_file(&self, file_id: FileId) -> SsrMatches {\n+        let file = self.sema.parse(file_id);\n+        let code = file.syntax();\n+        let mut matches = SsrMatches::default();\n+        self.find_matches(code, &None, &mut matches);\n+        matches\n+    }\n+\n+    fn find_matches(\n+        &self,\n+        code: &SyntaxNode,\n+        restrict_range: &Option<FileRange>,\n+        matches_out: &mut SsrMatches,\n+    ) {\n+        for rule in &self.rules {\n+            if let Ok(mut m) = matching::get_match(false, rule, &code, restrict_range, &self.sema) {\n+                // Continue searching in each of our placeholders.\n+                for placeholder_value in m.placeholder_values.values_mut() {\n+                    // Don't search our placeholder if it's the entire matched node, otherwise we'd\n+                    // find the same match over and over until we got a stack overflow.\n+                    if placeholder_value.node != *code {\n+                        self.find_matches(\n+                            &placeholder_value.node,\n+                            restrict_range,\n+                            &mut placeholder_value.inner_matches,\n+                        );\n+                    }\n+                }\n+                matches_out.matches.push(m);\n+                return;\n+            }\n+        }\n+        for child in code.children() {\n+            self.find_matches(&child, restrict_range, matches_out);\n+        }\n+    }\n+}\n+\n+impl std::fmt::Display for SsrError {\n+    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {\n+        write!(f, \"Parse error: {}\", self.0)\n+    }\n+}\n+\n+impl std::error::Error for SsrError {}"}, {"sha": "265b6d793e76088f8b6586c57f683575aeaf46a9", "filename": "crates/ra_ssr/src/matching.rs", "status": "added", "additions": 494, "deletions": 0, "changes": 494, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Fmatching.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Fmatching.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fmatching.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,494 @@\n+//! This module is responsible for matching a search pattern against a node in the AST. In the\n+//! process of matching, placeholder values are recorded.\n+\n+use crate::{\n+    parsing::{Placeholder, SsrTemplate},\n+    SsrMatches, SsrPattern, SsrRule,\n+};\n+use hir::Semantics;\n+use ra_db::FileRange;\n+use ra_syntax::ast::{AstNode, AstToken};\n+use ra_syntax::{\n+    ast, SyntaxElement, SyntaxElementChildren, SyntaxKind, SyntaxNode, SyntaxToken, TextRange,\n+};\n+use rustc_hash::FxHashMap;\n+use std::{cell::Cell, iter::Peekable};\n+\n+// Creates a match error. If we're currently attempting to match some code that we thought we were\n+// going to match, as indicated by the --debug-snippet flag, then populate the reason field.\n+macro_rules! match_error {\n+    ($e:expr) => {{\n+            MatchFailed {\n+                reason: if recording_match_fail_reasons() {\n+                    Some(format!(\"{}\", $e))\n+                } else {\n+                    None\n+                }\n+            }\n+    }};\n+    ($fmt:expr, $($arg:tt)+) => {{\n+        MatchFailed {\n+            reason: if recording_match_fail_reasons() {\n+                Some(format!($fmt, $($arg)+))\n+            } else {\n+                None\n+            }\n+        }\n+    }};\n+}\n+\n+// Fails the current match attempt, recording the supplied reason if we're recording match fail reasons.\n+macro_rules! fail_match {\n+    ($($args:tt)*) => {return Err(match_error!($($args)*))};\n+}\n+\n+/// Information about a match that was found.\n+#[derive(Debug)]\n+pub(crate) struct Match {\n+    pub(crate) range: TextRange,\n+    pub(crate) matched_node: SyntaxNode,\n+    pub(crate) placeholder_values: FxHashMap<Var, PlaceholderMatch>,\n+    pub(crate) ignored_comments: Vec<ast::Comment>,\n+    // A copy of the template for the rule that produced this match. We store this on the match for\n+    // if/when we do replacement.\n+    pub(crate) template: SsrTemplate,\n+}\n+\n+/// Represents a `$var` in an SSR query.\n+#[derive(Debug, Clone, PartialEq, Eq, Hash)]\n+pub(crate) struct Var(pub String);\n+\n+/// Information about a placeholder bound in a match.\n+#[derive(Debug)]\n+pub(crate) struct PlaceholderMatch {\n+    /// The node that the placeholder matched to.\n+    pub(crate) node: SyntaxNode,\n+    pub(crate) range: FileRange,\n+    /// More matches, found within `node`.\n+    pub(crate) inner_matches: SsrMatches,\n+}\n+\n+#[derive(Debug)]\n+pub(crate) struct MatchFailureReason {\n+    pub(crate) reason: String,\n+}\n+\n+/// An \"error\" indicating that matching failed. Use the fail_match! macro to create and return this.\n+#[derive(Clone)]\n+pub(crate) struct MatchFailed {\n+    /// The reason why we failed to match. Only present when debug_active true in call to\n+    /// `get_match`.\n+    pub(crate) reason: Option<String>,\n+}\n+\n+/// Checks if `code` matches the search pattern found in `search_scope`, returning information about\n+/// the match, if it does. Since we only do matching in this module and searching is done by the\n+/// parent module, we don't populate nested matches.\n+pub(crate) fn get_match(\n+    debug_active: bool,\n+    rule: &SsrRule,\n+    code: &SyntaxNode,\n+    restrict_range: &Option<FileRange>,\n+    sema: &Semantics<ra_ide_db::RootDatabase>,\n+) -> Result<Match, MatchFailed> {\n+    record_match_fails_reasons_scope(debug_active, || {\n+        MatchState::try_match(rule, code, restrict_range, sema)\n+    })\n+}\n+\n+/// Inputs to matching. This cannot be part of `MatchState`, since we mutate `MatchState` and in at\n+/// least one case need to hold a borrow of a placeholder from the input pattern while calling a\n+/// mutable `MatchState` method.\n+struct MatchInputs<'pattern> {\n+    ssr_pattern: &'pattern SsrPattern,\n+}\n+\n+/// State used while attempting to match our search pattern against a particular node of the AST.\n+struct MatchState<'db, 'sema> {\n+    sema: &'sema Semantics<'db, ra_ide_db::RootDatabase>,\n+    /// If any placeholders come from anywhere outside of this range, then the match will be\n+    /// rejected.\n+    restrict_range: Option<FileRange>,\n+    /// The match that we're building. We do two passes for a successful match. On the first pass,\n+    /// this is None so that we can avoid doing things like storing copies of what placeholders\n+    /// matched to. If that pass succeeds, then we do a second pass where we collect those details.\n+    /// This means that if we have a pattern like `$a.foo()` we won't do an insert into the\n+    /// placeholders map for every single method call in the codebase. Instead we'll discard all the\n+    /// method calls that aren't calls to `foo` on the first pass and only insert into the\n+    /// placeholders map on the second pass. Likewise for ignored comments.\n+    match_out: Option<Match>,\n+}\n+\n+impl<'db, 'sema> MatchState<'db, 'sema> {\n+    fn try_match(\n+        rule: &SsrRule,\n+        code: &SyntaxNode,\n+        restrict_range: &Option<FileRange>,\n+        sema: &'sema Semantics<'db, ra_ide_db::RootDatabase>,\n+    ) -> Result<Match, MatchFailed> {\n+        let mut match_state =\n+            MatchState { sema, restrict_range: restrict_range.clone(), match_out: None };\n+        let match_inputs = MatchInputs { ssr_pattern: &rule.pattern };\n+        let pattern_tree = rule.pattern.tree_for_kind(code.kind())?;\n+        // First pass at matching, where we check that node types and idents match.\n+        match_state.attempt_match_node(&match_inputs, &pattern_tree, code)?;\n+        match_state.validate_range(&sema.original_range(code))?;\n+        match_state.match_out = Some(Match {\n+            range: sema.original_range(code).range,\n+            matched_node: code.clone(),\n+            placeholder_values: FxHashMap::default(),\n+            ignored_comments: Vec::new(),\n+            template: rule.template.clone(),\n+        });\n+        // Second matching pass, where we record placeholder matches, ignored comments and maybe do\n+        // any other more expensive checks that we didn't want to do on the first pass.\n+        match_state.attempt_match_node(&match_inputs, &pattern_tree, code)?;\n+        Ok(match_state.match_out.unwrap())\n+    }\n+\n+    /// Checks that `range` is within the permitted range if any. This is applicable when we're\n+    /// processing a macro expansion and we want to fail the match if we're working with a node that\n+    /// didn't originate from the token tree of the macro call.\n+    fn validate_range(&self, range: &FileRange) -> Result<(), MatchFailed> {\n+        if let Some(restrict_range) = &self.restrict_range {\n+            if restrict_range.file_id != range.file_id\n+                || !restrict_range.range.contains_range(range.range)\n+            {\n+                fail_match!(\"Node originated from a macro\");\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    fn attempt_match_node(\n+        &mut self,\n+        match_inputs: &MatchInputs,\n+        pattern: &SyntaxNode,\n+        code: &SyntaxNode,\n+    ) -> Result<(), MatchFailed> {\n+        // Handle placeholders.\n+        if let Some(placeholder) =\n+            match_inputs.get_placeholder(&SyntaxElement::Node(pattern.clone()))\n+        {\n+            if self.match_out.is_none() {\n+                return Ok(());\n+            }\n+            let original_range = self.sema.original_range(code);\n+            // We validated the range for the node when we started the match, so the placeholder\n+            // probably can't fail range validation, but just to be safe...\n+            self.validate_range(&original_range)?;\n+            if let Some(match_out) = &mut self.match_out {\n+                match_out.placeholder_values.insert(\n+                    Var(placeholder.ident.to_string()),\n+                    PlaceholderMatch::new(code, original_range),\n+                );\n+            }\n+            return Ok(());\n+        }\n+        // Non-placeholders.\n+        if pattern.kind() != code.kind() {\n+            fail_match!(\"Pattern had a {:?}, code had {:?}\", pattern.kind(), code.kind());\n+        }\n+        // Some kinds of nodes have special handling. For everything else, we fall back to default\n+        // matching.\n+        match code.kind() {\n+            SyntaxKind::RECORD_FIELD_LIST => {\n+                self.attempt_match_record_field_list(match_inputs, pattern, code)\n+            }\n+            _ => self.attempt_match_node_children(match_inputs, pattern, code),\n+        }\n+    }\n+\n+    fn attempt_match_node_children(\n+        &mut self,\n+        match_inputs: &MatchInputs,\n+        pattern: &SyntaxNode,\n+        code: &SyntaxNode,\n+    ) -> Result<(), MatchFailed> {\n+        self.attempt_match_sequences(\n+            match_inputs,\n+            PatternIterator::new(pattern),\n+            code.children_with_tokens(),\n+        )\n+    }\n+\n+    fn attempt_match_sequences(\n+        &mut self,\n+        match_inputs: &MatchInputs,\n+        pattern_it: PatternIterator,\n+        mut code_it: SyntaxElementChildren,\n+    ) -> Result<(), MatchFailed> {\n+        let mut pattern_it = pattern_it.peekable();\n+        loop {\n+            match self.next_non_trivial(&mut code_it) {\n+                None => {\n+                    if let Some(p) = pattern_it.next() {\n+                        fail_match!(\"Part of the pattern was unmached: {:?}\", p);\n+                    }\n+                    return Ok(());\n+                }\n+                Some(SyntaxElement::Token(c)) => {\n+                    self.attempt_match_token(&mut pattern_it, &c)?;\n+                }\n+                Some(SyntaxElement::Node(c)) => match pattern_it.next() {\n+                    Some(SyntaxElement::Node(p)) => {\n+                        self.attempt_match_node(match_inputs, &p, &c)?;\n+                    }\n+                    Some(p) => fail_match!(\"Pattern wanted '{}', code has {}\", p, c.text()),\n+                    None => fail_match!(\"Pattern reached end, code has {}\", c.text()),\n+                },\n+            }\n+        }\n+    }\n+\n+    fn attempt_match_token(\n+        &mut self,\n+        pattern: &mut Peekable<PatternIterator>,\n+        code: &ra_syntax::SyntaxToken,\n+    ) -> Result<(), MatchFailed> {\n+        self.record_ignored_comments(code);\n+        // Ignore whitespace and comments.\n+        if code.kind().is_trivia() {\n+            return Ok(());\n+        }\n+        if let Some(SyntaxElement::Token(p)) = pattern.peek() {\n+            // If the code has a comma and the pattern is about to close something, then accept the\n+            // comma without advancing the pattern. i.e. ignore trailing commas.\n+            if code.kind() == SyntaxKind::COMMA && is_closing_token(p.kind()) {\n+                return Ok(());\n+            }\n+            // Conversely, if the pattern has a comma and the code doesn't, skip that part of the\n+            // pattern and continue to match the code.\n+            if p.kind() == SyntaxKind::COMMA && is_closing_token(code.kind()) {\n+                pattern.next();\n+            }\n+        }\n+        // Consume an element from the pattern and make sure it matches.\n+        match pattern.next() {\n+            Some(SyntaxElement::Token(p)) => {\n+                if p.kind() != code.kind() || p.text() != code.text() {\n+                    fail_match!(\n+                        \"Pattern wanted token '{}' ({:?}), but code had token '{}' ({:?})\",\n+                        p.text(),\n+                        p.kind(),\n+                        code.text(),\n+                        code.kind()\n+                    )\n+                }\n+            }\n+            Some(SyntaxElement::Node(p)) => {\n+                // Not sure if this is actually reachable.\n+                fail_match!(\n+                    \"Pattern wanted {:?}, but code had token '{}' ({:?})\",\n+                    p,\n+                    code.text(),\n+                    code.kind()\n+                );\n+            }\n+            None => {\n+                fail_match!(\"Pattern exhausted, while code remains: `{}`\", code.text());\n+            }\n+        }\n+        Ok(())\n+    }\n+\n+    /// We want to allow the records to match in any order, so we have special matching logic for\n+    /// them.\n+    fn attempt_match_record_field_list(\n+        &mut self,\n+        match_inputs: &MatchInputs,\n+        pattern: &SyntaxNode,\n+        code: &SyntaxNode,\n+    ) -> Result<(), MatchFailed> {\n+        // Build a map keyed by field name.\n+        let mut fields_by_name = FxHashMap::default();\n+        for child in code.children() {\n+            if let Some(record) = ast::RecordField::cast(child.clone()) {\n+                if let Some(name) = record.field_name() {\n+                    fields_by_name.insert(name.text().clone(), child.clone());\n+                }\n+            }\n+        }\n+        for p in pattern.children_with_tokens() {\n+            if let SyntaxElement::Node(p) = p {\n+                if let Some(name_element) = p.first_child_or_token() {\n+                    if match_inputs.get_placeholder(&name_element).is_some() {\n+                        // If the pattern is using placeholders for field names then order\n+                        // independence doesn't make sense. Fall back to regular ordered\n+                        // matching.\n+                        return self.attempt_match_node_children(match_inputs, pattern, code);\n+                    }\n+                    if let Some(ident) = only_ident(name_element) {\n+                        let code_record = fields_by_name.remove(ident.text()).ok_or_else(|| {\n+                            match_error!(\n+                                \"Placeholder has record field '{}', but code doesn't\",\n+                                ident\n+                            )\n+                        })?;\n+                        self.attempt_match_node(match_inputs, &p, &code_record)?;\n+                    }\n+                }\n+            }\n+        }\n+        if let Some(unmatched_fields) = fields_by_name.keys().next() {\n+            fail_match!(\n+                \"{} field(s) of a record literal failed to match, starting with {}\",\n+                fields_by_name.len(),\n+                unmatched_fields\n+            );\n+        }\n+        Ok(())\n+    }\n+\n+    fn next_non_trivial(&mut self, code_it: &mut SyntaxElementChildren) -> Option<SyntaxElement> {\n+        loop {\n+            let c = code_it.next();\n+            if let Some(SyntaxElement::Token(t)) = &c {\n+                self.record_ignored_comments(t);\n+                if t.kind().is_trivia() {\n+                    continue;\n+                }\n+            }\n+            return c;\n+        }\n+    }\n+\n+    fn record_ignored_comments(&mut self, token: &SyntaxToken) {\n+        if token.kind() == SyntaxKind::COMMENT {\n+            if let Some(match_out) = &mut self.match_out {\n+                if let Some(comment) = ast::Comment::cast(token.clone()) {\n+                    match_out.ignored_comments.push(comment);\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+impl MatchInputs<'_> {\n+    fn get_placeholder(&self, element: &SyntaxElement) -> Option<&Placeholder> {\n+        only_ident(element.clone())\n+            .and_then(|ident| self.ssr_pattern.placeholders_by_stand_in.get(ident.text()))\n+    }\n+}\n+\n+fn is_closing_token(kind: SyntaxKind) -> bool {\n+    kind == SyntaxKind::R_PAREN || kind == SyntaxKind::R_CURLY || kind == SyntaxKind::R_BRACK\n+}\n+\n+pub(crate) fn record_match_fails_reasons_scope<F, T>(debug_active: bool, f: F) -> T\n+where\n+    F: Fn() -> T,\n+{\n+    RECORDING_MATCH_FAIL_REASONS.with(|c| c.set(debug_active));\n+    let res = f();\n+    RECORDING_MATCH_FAIL_REASONS.with(|c| c.set(false));\n+    res\n+}\n+\n+// For performance reasons, we don't want to record the reason why every match fails, only the bit\n+// of code that the user indicated they thought would match. We use a thread local to indicate when\n+// we are trying to match that bit of code. This saves us having to pass a boolean into all the bits\n+// of code that can make the decision to not match.\n+thread_local! {\n+    pub static RECORDING_MATCH_FAIL_REASONS: Cell<bool> = Cell::new(false);\n+}\n+\n+fn recording_match_fail_reasons() -> bool {\n+    RECORDING_MATCH_FAIL_REASONS.with(|c| c.get())\n+}\n+\n+impl PlaceholderMatch {\n+    fn new(node: &SyntaxNode, range: FileRange) -> Self {\n+        Self { node: node.clone(), range, inner_matches: SsrMatches::default() }\n+    }\n+}\n+\n+impl SsrPattern {\n+    pub(crate) fn tree_for_kind(&self, kind: SyntaxKind) -> Result<&SyntaxNode, MatchFailed> {\n+        let (tree, kind_name) = if ast::Expr::can_cast(kind) {\n+            (&self.expr, \"expression\")\n+        } else if ast::TypeRef::can_cast(kind) {\n+            (&self.type_ref, \"type reference\")\n+        } else if ast::ModuleItem::can_cast(kind) {\n+            (&self.item, \"item\")\n+        } else if ast::Path::can_cast(kind) {\n+            (&self.path, \"path\")\n+        } else if ast::Pat::can_cast(kind) {\n+            (&self.pattern, \"pattern\")\n+        } else {\n+            fail_match!(\"Matching nodes of kind {:?} is not supported\", kind);\n+        };\n+        match tree {\n+            Some(tree) => Ok(tree),\n+            None => fail_match!(\"Pattern cannot be parsed as a {}\", kind_name),\n+        }\n+    }\n+}\n+\n+// If `node` contains nothing but an ident then return it, otherwise return None.\n+fn only_ident(element: SyntaxElement) -> Option<SyntaxToken> {\n+    match element {\n+        SyntaxElement::Token(t) => {\n+            if t.kind() == SyntaxKind::IDENT {\n+                return Some(t);\n+            }\n+        }\n+        SyntaxElement::Node(n) => {\n+            let mut children = n.children_with_tokens();\n+            if let (Some(only_child), None) = (children.next(), children.next()) {\n+                return only_ident(only_child);\n+            }\n+        }\n+    }\n+    None\n+}\n+\n+struct PatternIterator {\n+    iter: SyntaxElementChildren,\n+}\n+\n+impl Iterator for PatternIterator {\n+    type Item = SyntaxElement;\n+\n+    fn next(&mut self) -> Option<SyntaxElement> {\n+        while let Some(element) = self.iter.next() {\n+            if !element.kind().is_trivia() {\n+                return Some(element);\n+            }\n+        }\n+        None\n+    }\n+}\n+\n+impl PatternIterator {\n+    fn new(parent: &SyntaxNode) -> Self {\n+        Self { iter: parent.children_with_tokens() }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use crate::MatchFinder;\n+\n+    #[test]\n+    fn parse_match_replace() {\n+        let rule: SsrRule = \"foo($x) ==>> bar($x)\".parse().unwrap();\n+        let input = \"fn main() { foo(1+2); }\";\n+\n+        use ra_db::fixture::WithFixture;\n+        let (db, file_id) = ra_ide_db::RootDatabase::with_single_file(input);\n+        let mut match_finder = MatchFinder::new(&db);\n+        match_finder.add_rule(rule);\n+        let matches = match_finder.find_matches_in_file(file_id);\n+        assert_eq!(matches.matches.len(), 1);\n+        assert_eq!(matches.matches[0].matched_node.text(), \"foo(1+2)\");\n+        assert_eq!(matches.matches[0].placeholder_values.len(), 1);\n+        assert_eq!(matches.matches[0].placeholder_values[&Var(\"x\".to_string())].node.text(), \"1+2\");\n+\n+        let edit = crate::replacing::matches_to_edit(&matches);\n+        let mut after = input.to_string();\n+        edit.apply(&mut after);\n+        assert_eq!(after, \"fn main() { bar(1+2); }\");\n+    }\n+}"}, {"sha": "90c13dbc26063fbd732ae68316b9797b8036b75a", "filename": "crates/ra_ssr/src/parsing.rs", "status": "added", "additions": 272, "deletions": 0, "changes": 272, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Fparsing.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,272 @@\n+//! This file contains code for parsing SSR rules, which look something like `foo($a) ==>> bar($b)`.\n+//! We first split everything before and after the separator `==>>`. Next, both the search pattern\n+//! and the replacement template get tokenized by the Rust tokenizer. Tokens are then searched for\n+//! placeholders, which start with `$`. For replacement templates, this is the final form. For\n+//! search patterns, we go further and parse the pattern as each kind of thing that we can match.\n+//! e.g. expressions, type references etc.\n+\n+use crate::{SsrError, SsrPattern, SsrRule};\n+use ra_syntax::{ast, AstNode, SmolStr, SyntaxKind};\n+use rustc_hash::{FxHashMap, FxHashSet};\n+use std::str::FromStr;\n+\n+/// Returns from the current function with an error, supplied by arguments as for format!\n+macro_rules! bail {\n+    ($e:expr) => {return Err($crate::SsrError::new($e))};\n+    ($fmt:expr, $($arg:tt)+) => {return Err($crate::SsrError::new(format!($fmt, $($arg)+)))}\n+}\n+\n+#[derive(Clone, Debug)]\n+pub(crate) struct SsrTemplate {\n+    pub(crate) tokens: Vec<PatternElement>,\n+}\n+\n+#[derive(Debug)]\n+pub(crate) struct RawSearchPattern {\n+    tokens: Vec<PatternElement>,\n+}\n+\n+// Part of a search or replace pattern.\n+#[derive(Clone, Debug, PartialEq, Eq)]\n+pub(crate) enum PatternElement {\n+    Token(Token),\n+    Placeholder(Placeholder),\n+}\n+\n+#[derive(Clone, Debug, PartialEq, Eq)]\n+pub(crate) struct Placeholder {\n+    /// The name of this placeholder. e.g. for \"$a\", this would be \"a\"\n+    pub(crate) ident: SmolStr,\n+    /// A unique name used in place of this placeholder when we parse the pattern as Rust code.\n+    stand_in_name: String,\n+}\n+\n+#[derive(Debug, Clone, PartialEq, Eq)]\n+pub(crate) struct Token {\n+    kind: SyntaxKind,\n+    pub(crate) text: SmolStr,\n+}\n+\n+impl FromStr for SsrRule {\n+    type Err = SsrError;\n+\n+    fn from_str(query: &str) -> Result<SsrRule, SsrError> {\n+        let mut it = query.split(\"==>>\");\n+        let pattern = it.next().expect(\"at least empty string\").trim();\n+        let template = it\n+            .next()\n+            .ok_or_else(|| SsrError(\"Cannot find delemiter `==>>`\".into()))?\n+            .trim()\n+            .to_string();\n+        if it.next().is_some() {\n+            return Err(SsrError(\"More than one delimiter found\".into()));\n+        }\n+        let rule = SsrRule { pattern: pattern.parse()?, template: template.parse()? };\n+        validate_rule(&rule)?;\n+        Ok(rule)\n+    }\n+}\n+\n+impl FromStr for RawSearchPattern {\n+    type Err = SsrError;\n+\n+    fn from_str(pattern_str: &str) -> Result<RawSearchPattern, SsrError> {\n+        Ok(RawSearchPattern { tokens: parse_pattern(pattern_str)? })\n+    }\n+}\n+\n+impl RawSearchPattern {\n+    /// Returns this search pattern as Rust source code that we can feed to the Rust parser.\n+    fn as_rust_code(&self) -> String {\n+        let mut res = String::new();\n+        for t in &self.tokens {\n+            res.push_str(match t {\n+                PatternElement::Token(token) => token.text.as_str(),\n+                PatternElement::Placeholder(placeholder) => placeholder.stand_in_name.as_str(),\n+            });\n+        }\n+        res\n+    }\n+\n+    fn placeholders_by_stand_in(&self) -> FxHashMap<SmolStr, Placeholder> {\n+        let mut res = FxHashMap::default();\n+        for t in &self.tokens {\n+            if let PatternElement::Placeholder(placeholder) = t {\n+                res.insert(SmolStr::new(placeholder.stand_in_name.clone()), placeholder.clone());\n+            }\n+        }\n+        res\n+    }\n+}\n+\n+impl FromStr for SsrPattern {\n+    type Err = SsrError;\n+\n+    fn from_str(pattern_str: &str) -> Result<SsrPattern, SsrError> {\n+        let raw: RawSearchPattern = pattern_str.parse()?;\n+        let raw_str = raw.as_rust_code();\n+        let res = SsrPattern {\n+            expr: ast::Expr::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n+            type_ref: ast::TypeRef::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n+            item: ast::ModuleItem::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n+            path: ast::Path::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n+            pattern: ast::Pat::parse(&raw_str).ok().map(|n| n.syntax().clone()),\n+            placeholders_by_stand_in: raw.placeholders_by_stand_in(),\n+            raw,\n+        };\n+        if res.expr.is_none()\n+            && res.type_ref.is_none()\n+            && res.item.is_none()\n+            && res.path.is_none()\n+            && res.pattern.is_none()\n+        {\n+            bail!(\"Pattern is not a valid Rust expression, type, item, path or pattern\");\n+        }\n+        Ok(res)\n+    }\n+}\n+\n+impl FromStr for SsrTemplate {\n+    type Err = SsrError;\n+\n+    fn from_str(pattern_str: &str) -> Result<SsrTemplate, SsrError> {\n+        let tokens = parse_pattern(pattern_str)?;\n+        // Validate that the template is a valid fragment of Rust code. We reuse the validation\n+        // logic for search patterns since the only thing that differs is the error message.\n+        if SsrPattern::from_str(pattern_str).is_err() {\n+            bail!(\"Replacement is not a valid Rust expression, type, item, path or pattern\");\n+        }\n+        // Our actual template needs to preserve whitespace, so we can't reuse `tokens`.\n+        Ok(SsrTemplate { tokens })\n+    }\n+}\n+\n+/// Returns `pattern_str`, parsed as a search or replace pattern. If `remove_whitespace` is true,\n+/// then any whitespace tokens will be removed, which we do for the search pattern, but not for the\n+/// replace pattern.\n+fn parse_pattern(pattern_str: &str) -> Result<Vec<PatternElement>, SsrError> {\n+    let mut res = Vec::new();\n+    let mut placeholder_names = FxHashSet::default();\n+    let mut tokens = tokenize(pattern_str)?.into_iter();\n+    while let Some(token) = tokens.next() {\n+        if token.kind == SyntaxKind::DOLLAR {\n+            let placeholder = parse_placeholder(&mut tokens)?;\n+            if !placeholder_names.insert(placeholder.ident.clone()) {\n+                bail!(\"Name `{}` repeats more than once\", placeholder.ident);\n+            }\n+            res.push(PatternElement::Placeholder(placeholder));\n+        } else {\n+            res.push(PatternElement::Token(token));\n+        }\n+    }\n+    Ok(res)\n+}\n+\n+/// Checks for errors in a rule. e.g. the replace pattern referencing placeholders that the search\n+/// pattern didn't define.\n+fn validate_rule(rule: &SsrRule) -> Result<(), SsrError> {\n+    let mut defined_placeholders = std::collections::HashSet::new();\n+    for p in &rule.pattern.raw.tokens {\n+        if let PatternElement::Placeholder(placeholder) = p {\n+            defined_placeholders.insert(&placeholder.ident);\n+        }\n+    }\n+    let mut undefined = Vec::new();\n+    for p in &rule.template.tokens {\n+        if let PatternElement::Placeholder(placeholder) = p {\n+            if !defined_placeholders.contains(&placeholder.ident) {\n+                undefined.push(format!(\"${}\", placeholder.ident));\n+            }\n+        }\n+    }\n+    if !undefined.is_empty() {\n+        bail!(\"Replacement contains undefined placeholders: {}\", undefined.join(\", \"));\n+    }\n+    Ok(())\n+}\n+\n+fn tokenize(source: &str) -> Result<Vec<Token>, SsrError> {\n+    let mut start = 0;\n+    let (raw_tokens, errors) = ra_syntax::tokenize(source);\n+    if let Some(first_error) = errors.first() {\n+        bail!(\"Failed to parse pattern: {}\", first_error);\n+    }\n+    let mut tokens: Vec<Token> = Vec::new();\n+    for raw_token in raw_tokens {\n+        let token_len = usize::from(raw_token.len);\n+        tokens.push(Token {\n+            kind: raw_token.kind,\n+            text: SmolStr::new(&source[start..start + token_len]),\n+        });\n+        start += token_len;\n+    }\n+    Ok(tokens)\n+}\n+\n+fn parse_placeholder(tokens: &mut std::vec::IntoIter<Token>) -> Result<Placeholder, SsrError> {\n+    let mut name = None;\n+    if let Some(token) = tokens.next() {\n+        match token.kind {\n+            SyntaxKind::IDENT => {\n+                name = Some(token.text);\n+            }\n+            _ => {\n+                bail!(\"Placeholders should be $name\");\n+            }\n+        }\n+    }\n+    let name = name.ok_or_else(|| SsrError::new(\"Placeholder ($) with no name\"))?;\n+    Ok(Placeholder::new(name))\n+}\n+\n+impl Placeholder {\n+    fn new(name: SmolStr) -> Self {\n+        Self { stand_in_name: format!(\"__placeholder_{}\", name), ident: name }\n+    }\n+}\n+\n+impl SsrError {\n+    fn new(message: impl Into<String>) -> SsrError {\n+        SsrError(message.into())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+\n+    #[test]\n+    fn parser_happy_case() {\n+        fn token(kind: SyntaxKind, text: &str) -> PatternElement {\n+            PatternElement::Token(Token { kind, text: SmolStr::new(text) })\n+        }\n+        fn placeholder(name: &str) -> PatternElement {\n+            PatternElement::Placeholder(Placeholder::new(SmolStr::new(name)))\n+        }\n+        let result: SsrRule = \"foo($a, $b) ==>> bar($b, $a)\".parse().unwrap();\n+        assert_eq!(\n+            result.pattern.raw.tokens,\n+            vec![\n+                token(SyntaxKind::IDENT, \"foo\"),\n+                token(SyntaxKind::L_PAREN, \"(\"),\n+                placeholder(\"a\"),\n+                token(SyntaxKind::COMMA, \",\"),\n+                token(SyntaxKind::WHITESPACE, \" \"),\n+                placeholder(\"b\"),\n+                token(SyntaxKind::R_PAREN, \")\"),\n+            ]\n+        );\n+        assert_eq!(\n+            result.template.tokens,\n+            vec![\n+                token(SyntaxKind::IDENT, \"bar\"),\n+                token(SyntaxKind::L_PAREN, \"(\"),\n+                placeholder(\"b\"),\n+                token(SyntaxKind::COMMA, \",\"),\n+                token(SyntaxKind::WHITESPACE, \" \"),\n+                placeholder(\"a\"),\n+                token(SyntaxKind::R_PAREN, \")\"),\n+            ]\n+        );\n+    }\n+}"}, {"sha": "81a5e06a9c86468dec28011f611202d94ca80cd6", "filename": "crates/ra_ssr/src/replacing.rs", "status": "added", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Freplacing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Freplacing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Freplacing.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,55 @@\n+//! Code for applying replacement templates for matches that have previously been found.\n+\n+use crate::matching::Var;\n+use crate::parsing::PatternElement;\n+use crate::{Match, SsrMatches};\n+use ra_syntax::ast::AstToken;\n+use ra_syntax::TextSize;\n+use ra_text_edit::TextEdit;\n+\n+/// Returns a text edit that will replace each match in `matches` with its corresponding replacement\n+/// template. Placeholders in the template will have been substituted with whatever they matched to\n+/// in the original code.\n+pub(crate) fn matches_to_edit(matches: &SsrMatches) -> TextEdit {\n+    matches_to_edit_at_offset(matches, 0.into())\n+}\n+\n+fn matches_to_edit_at_offset(matches: &SsrMatches, relative_start: TextSize) -> TextEdit {\n+    let mut edit_builder = ra_text_edit::TextEditBuilder::default();\n+    for m in &matches.matches {\n+        edit_builder.replace(m.range.checked_sub(relative_start).unwrap(), render_replace(m));\n+    }\n+    edit_builder.finish()\n+}\n+\n+fn render_replace(match_info: &Match) -> String {\n+    let mut out = String::new();\n+    for r in &match_info.template.tokens {\n+        match r {\n+            PatternElement::Token(t) => out.push_str(t.text.as_str()),\n+            PatternElement::Placeholder(p) => {\n+                if let Some(placeholder_value) =\n+                    match_info.placeholder_values.get(&Var(p.ident.to_string()))\n+                {\n+                    let range = &placeholder_value.range.range;\n+                    let mut matched_text = placeholder_value.node.text().to_string();\n+                    let edit =\n+                        matches_to_edit_at_offset(&placeholder_value.inner_matches, range.start());\n+                    edit.apply(&mut matched_text);\n+                    out.push_str(&matched_text);\n+                } else {\n+                    // We validated that all placeholder references were valid before we\n+                    // started, so this shouldn't happen.\n+                    panic!(\n+                        \"Internal error: replacement referenced unknown placeholder {}\",\n+                        p.ident\n+                    );\n+                }\n+            }\n+        }\n+    }\n+    for comment in &match_info.ignored_comments {\n+        out.push_str(&comment.syntax().to_string());\n+    }\n+    out\n+}"}, {"sha": "4b747fe18034ed4fd777e292f4f763b2a3feb416", "filename": "crates/ra_ssr/src/tests.rs", "status": "added", "additions": 496, "deletions": 0, "changes": 496, "blob_url": "https://github.com/rust-lang/rust/blob/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d144d69d2eded43a59c8edb59419b1b9e85c10a5/crates%2Fra_ssr%2Fsrc%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ssr%2Fsrc%2Ftests.rs?ref=d144d69d2eded43a59c8edb59419b1b9e85c10a5", "patch": "@@ -0,0 +1,496 @@\n+use crate::matching::MatchFailureReason;\n+use crate::{matching, Match, MatchFinder, SsrMatches, SsrPattern, SsrRule};\n+use matching::record_match_fails_reasons_scope;\n+use ra_db::{FileId, FileRange, SourceDatabaseExt};\n+use ra_syntax::ast::AstNode;\n+use ra_syntax::{ast, SyntaxKind, SyntaxNode, TextRange};\n+\n+struct MatchDebugInfo {\n+    node: SyntaxNode,\n+    /// Our search pattern parsed as the same kind of syntax node as `node`. e.g. expression, item,\n+    /// etc. Will be absent if the pattern can't be parsed as that kind.\n+    pattern: Result<SyntaxNode, MatchFailureReason>,\n+    matched: Result<Match, MatchFailureReason>,\n+}\n+\n+impl SsrPattern {\n+    pub(crate) fn tree_for_kind_with_reason(\n+        &self,\n+        kind: SyntaxKind,\n+    ) -> Result<&SyntaxNode, MatchFailureReason> {\n+        record_match_fails_reasons_scope(true, || self.tree_for_kind(kind))\n+            .map_err(|e| MatchFailureReason { reason: e.reason.unwrap() })\n+    }\n+}\n+\n+impl std::fmt::Debug for MatchDebugInfo {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"========= PATTERN ==========\\n\")?;\n+        match &self.pattern {\n+            Ok(pattern) => {\n+                write!(f, \"{:#?}\", pattern)?;\n+            }\n+            Err(err) => {\n+                write!(f, \"{}\", err.reason)?;\n+            }\n+        }\n+        write!(\n+            f,\n+            \"\\n============ AST ===========\\n\\\n+            {:#?}\\n============================\",\n+            self.node\n+        )?;\n+        match &self.matched {\n+            Ok(_) => write!(f, \"Node matched\")?,\n+            Err(reason) => write!(f, \"Node failed to match because: {}\", reason.reason)?,\n+        }\n+        Ok(())\n+    }\n+}\n+\n+impl SsrMatches {\n+    /// Returns `self` with any nested matches removed and made into top-level matches.\n+    pub(crate) fn flattened(self) -> SsrMatches {\n+        let mut out = SsrMatches::default();\n+        self.flatten_into(&mut out);\n+        out\n+    }\n+\n+    fn flatten_into(self, out: &mut SsrMatches) {\n+        for mut m in self.matches {\n+            for p in m.placeholder_values.values_mut() {\n+                std::mem::replace(&mut p.inner_matches, SsrMatches::default()).flatten_into(out);\n+            }\n+            out.matches.push(m);\n+        }\n+    }\n+}\n+\n+impl Match {\n+    pub(crate) fn matched_text(&self) -> String {\n+        self.matched_node.text().to_string()\n+    }\n+}\n+\n+impl<'db> MatchFinder<'db> {\n+    /// Adds a search pattern. For use if you intend to only call `find_matches_in_file`. If you\n+    /// intend to do replacement, use `add_rule` instead.\n+    fn add_search_pattern(&mut self, pattern: SsrPattern) {\n+        self.add_rule(SsrRule { pattern, template: \"()\".parse().unwrap() })\n+    }\n+\n+    /// Finds all nodes in `file_id` whose text is exactly equal to `snippet` and attempts to match\n+    /// them, while recording reasons why they don't match. This API is useful for command\n+    /// line-based debugging where providing a range is difficult.\n+    fn debug_where_text_equal(&self, file_id: FileId, snippet: &str) -> Vec<MatchDebugInfo> {\n+        let file = self.sema.parse(file_id);\n+        let mut res = Vec::new();\n+        let file_text = self.sema.db.file_text(file_id);\n+        let mut remaining_text = file_text.as_str();\n+        let mut base = 0;\n+        let len = snippet.len() as u32;\n+        while let Some(offset) = remaining_text.find(snippet) {\n+            let start = base + offset as u32;\n+            let end = start + len;\n+            self.output_debug_for_nodes_at_range(\n+                file.syntax(),\n+                TextRange::new(start.into(), end.into()),\n+                &None,\n+                &mut res,\n+            );\n+            remaining_text = &remaining_text[offset + snippet.len()..];\n+            base = end;\n+        }\n+        res\n+    }\n+\n+    fn output_debug_for_nodes_at_range(\n+        &self,\n+        node: &SyntaxNode,\n+        range: TextRange,\n+        restrict_range: &Option<FileRange>,\n+        out: &mut Vec<MatchDebugInfo>,\n+    ) {\n+        for node in node.children() {\n+            if !node.text_range().contains_range(range) {\n+                continue;\n+            }\n+            if node.text_range() == range {\n+                for rule in &self.rules {\n+                    let pattern =\n+                        rule.pattern.tree_for_kind_with_reason(node.kind()).map(|p| p.clone());\n+                    out.push(MatchDebugInfo {\n+                        matched: matching::get_match(true, rule, &node, restrict_range, &self.sema)\n+                            .map_err(|e| MatchFailureReason {\n+                                reason: e.reason.unwrap_or_else(|| {\n+                                    \"Match failed, but no reason was given\".to_owned()\n+                                }),\n+                            }),\n+                        pattern,\n+                        node: node.clone(),\n+                    });\n+                }\n+            } else if let Some(macro_call) = ast::MacroCall::cast(node.clone()) {\n+                if let Some(expanded) = self.sema.expand(&macro_call) {\n+                    if let Some(tt) = macro_call.token_tree() {\n+                        self.output_debug_for_nodes_at_range(\n+                            &expanded,\n+                            range,\n+                            &Some(self.sema.original_range(tt.syntax())),\n+                            out,\n+                        );\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+fn parse_error_text(query: &str) -> String {\n+    format!(\"{}\", query.parse::<SsrRule>().unwrap_err())\n+}\n+\n+#[test]\n+fn parser_empty_query() {\n+    assert_eq!(parse_error_text(\"\"), \"Parse error: Cannot find delemiter `==>>`\");\n+}\n+\n+#[test]\n+fn parser_no_delimiter() {\n+    assert_eq!(parse_error_text(\"foo()\"), \"Parse error: Cannot find delemiter `==>>`\");\n+}\n+\n+#[test]\n+fn parser_two_delimiters() {\n+    assert_eq!(\n+        parse_error_text(\"foo() ==>> a ==>> b \"),\n+        \"Parse error: More than one delimiter found\"\n+    );\n+}\n+\n+#[test]\n+fn parser_repeated_name() {\n+    assert_eq!(\n+        parse_error_text(\"foo($a, $a) ==>>\"),\n+        \"Parse error: Name `a` repeats more than once\"\n+    );\n+}\n+\n+#[test]\n+fn parser_invalid_pattern() {\n+    assert_eq!(\n+        parse_error_text(\" ==>> ()\"),\n+        \"Parse error: Pattern is not a valid Rust expression, type, item, path or pattern\"\n+    );\n+}\n+\n+#[test]\n+fn parser_invalid_template() {\n+    assert_eq!(\n+        parse_error_text(\"() ==>> )\"),\n+        \"Parse error: Replacement is not a valid Rust expression, type, item, path or pattern\"\n+    );\n+}\n+\n+#[test]\n+fn parser_undefined_placeholder_in_replacement() {\n+    assert_eq!(\n+        parse_error_text(\"42 ==>> $a\"),\n+        \"Parse error: Replacement contains undefined placeholders: $a\"\n+    );\n+}\n+\n+fn single_file(code: &str) -> (ra_ide_db::RootDatabase, FileId) {\n+    use ra_db::fixture::WithFixture;\n+    ra_ide_db::RootDatabase::with_single_file(code)\n+}\n+\n+fn assert_ssr_transform(rule: &str, input: &str, result: &str) {\n+    assert_ssr_transforms(&[rule], input, result);\n+}\n+\n+fn assert_ssr_transforms(rules: &[&str], input: &str, result: &str) {\n+    let (db, file_id) = single_file(input);\n+    let mut match_finder = MatchFinder::new(&db);\n+    for rule in rules {\n+        let rule: SsrRule = rule.parse().unwrap();\n+        match_finder.add_rule(rule);\n+    }\n+    if let Some(edits) = match_finder.edits_for_file(file_id) {\n+        let mut after = input.to_string();\n+        edits.apply(&mut after);\n+        assert_eq!(after, result);\n+    } else {\n+        panic!(\"No edits were made\");\n+    }\n+}\n+\n+fn assert_matches(pattern: &str, code: &str, expected: &[&str]) {\n+    let (db, file_id) = single_file(code);\n+    let mut match_finder = MatchFinder::new(&db);\n+    match_finder.add_search_pattern(pattern.parse().unwrap());\n+    let matched_strings: Vec<String> = match_finder\n+        .find_matches_in_file(file_id)\n+        .flattened()\n+        .matches\n+        .iter()\n+        .map(|m| m.matched_text())\n+        .collect();\n+    if matched_strings != expected && !expected.is_empty() {\n+        let debug_info = match_finder.debug_where_text_equal(file_id, &expected[0]);\n+        eprintln!(\"Test is about to fail. Some possibly useful info: {} nodes had text exactly equal to '{}'\", debug_info.len(), &expected[0]);\n+        for d in debug_info {\n+            eprintln!(\"{:#?}\", d);\n+        }\n+    }\n+    assert_eq!(matched_strings, expected);\n+}\n+\n+fn assert_no_match(pattern: &str, code: &str) {\n+    assert_matches(pattern, code, &[]);\n+}\n+\n+#[test]\n+fn ssr_function_to_method() {\n+    assert_ssr_transform(\n+        \"my_function($a, $b) ==>> ($a).my_method($b)\",\n+        \"loop { my_function( other_func(x, y), z + w) }\",\n+        \"loop { (other_func(x, y)).my_method(z + w) }\",\n+    )\n+}\n+\n+#[test]\n+fn ssr_nested_function() {\n+    assert_ssr_transform(\n+        \"foo($a, $b, $c) ==>> bar($c, baz($a, $b))\",\n+        \"fn main { foo  (x + value.method(b), x+y-z, true && false) }\",\n+        \"fn main { bar(true && false, baz(x + value.method(b), x+y-z)) }\",\n+    )\n+}\n+\n+#[test]\n+fn ssr_expected_spacing() {\n+    assert_ssr_transform(\n+        \"foo($x) + bar() ==>> bar($x)\",\n+        \"fn main() { foo(5) + bar() }\",\n+        \"fn main() { bar(5) }\",\n+    );\n+}\n+\n+#[test]\n+fn ssr_with_extra_space() {\n+    assert_ssr_transform(\n+        \"foo($x  ) +    bar() ==>> bar($x)\",\n+        \"fn main() { foo(  5 )  +bar(   ) }\",\n+        \"fn main() { bar(5) }\",\n+    );\n+}\n+\n+#[test]\n+fn ssr_keeps_nested_comment() {\n+    assert_ssr_transform(\n+        \"foo($x) ==>> bar($x)\",\n+        \"fn main() { foo(other(5 /* using 5 */)) }\",\n+        \"fn main() { bar(other(5 /* using 5 */)) }\",\n+    )\n+}\n+\n+#[test]\n+fn ssr_keeps_comment() {\n+    assert_ssr_transform(\n+        \"foo($x) ==>> bar($x)\",\n+        \"fn main() { foo(5 /* using 5 */) }\",\n+        \"fn main() { bar(5)/* using 5 */ }\",\n+    )\n+}\n+\n+#[test]\n+fn ssr_struct_lit() {\n+    assert_ssr_transform(\n+        \"foo{a: $a, b: $b} ==>> foo::new($a, $b)\",\n+        \"fn main() { foo{b:2, a:1} }\",\n+        \"fn main() { foo::new(1, 2) }\",\n+    )\n+}\n+\n+#[test]\n+fn ignores_whitespace() {\n+    assert_matches(\"1+2\", \"fn f() -> i32 {1  +  2}\", &[\"1  +  2\"]);\n+    assert_matches(\"1 + 2\", \"fn f() -> i32 {1+2}\", &[\"1+2\"]);\n+}\n+\n+#[test]\n+fn no_match() {\n+    assert_no_match(\"1 + 3\", \"fn f() -> i32 {1  +  2}\");\n+}\n+\n+#[test]\n+fn match_fn_definition() {\n+    assert_matches(\"fn $a($b: $t) {$c}\", \"fn f(a: i32) {bar()}\", &[\"fn f(a: i32) {bar()}\"]);\n+}\n+\n+#[test]\n+fn match_struct_definition() {\n+    assert_matches(\n+        \"struct $n {$f: Option<String>}\",\n+        \"struct Bar {} struct Foo {name: Option<String>}\",\n+        &[\"struct Foo {name: Option<String>}\"],\n+    );\n+}\n+\n+#[test]\n+fn match_expr() {\n+    let code = \"fn f() -> i32 {foo(40 + 2, 42)}\";\n+    assert_matches(\"foo($a, $b)\", code, &[\"foo(40 + 2, 42)\"]);\n+    assert_no_match(\"foo($a, $b, $c)\", code);\n+    assert_no_match(\"foo($a)\", code);\n+}\n+\n+#[test]\n+fn match_nested_method_calls() {\n+    assert_matches(\n+        \"$a.z().z().z()\",\n+        \"fn f() {h().i().j().z().z().z().d().e()}\",\n+        &[\"h().i().j().z().z().z()\"],\n+    );\n+}\n+\n+#[test]\n+fn match_complex_expr() {\n+    let code = \"fn f() -> i32 {foo(bar(40, 2), 42)}\";\n+    assert_matches(\"foo($a, $b)\", code, &[\"foo(bar(40, 2), 42)\"]);\n+    assert_no_match(\"foo($a, $b, $c)\", code);\n+    assert_no_match(\"foo($a)\", code);\n+    assert_matches(\"bar($a, $b)\", code, &[\"bar(40, 2)\"]);\n+}\n+\n+// Trailing commas in the code should be ignored.\n+#[test]\n+fn match_with_trailing_commas() {\n+    // Code has comma, pattern doesn't.\n+    assert_matches(\"foo($a, $b)\", \"fn f() {foo(1, 2,);}\", &[\"foo(1, 2,)\"]);\n+    assert_matches(\"Foo{$a, $b}\", \"fn f() {Foo{1, 2,};}\", &[\"Foo{1, 2,}\"]);\n+\n+    // Pattern has comma, code doesn't.\n+    assert_matches(\"foo($a, $b,)\", \"fn f() {foo(1, 2);}\", &[\"foo(1, 2)\"]);\n+    assert_matches(\"Foo{$a, $b,}\", \"fn f() {Foo{1, 2};}\", &[\"Foo{1, 2}\"]);\n+}\n+\n+#[test]\n+fn match_type() {\n+    assert_matches(\"i32\", \"fn f() -> i32 {1  +  2}\", &[\"i32\"]);\n+    assert_matches(\"Option<$a>\", \"fn f() -> Option<i32> {42}\", &[\"Option<i32>\"]);\n+    assert_no_match(\"Option<$a>\", \"fn f() -> Result<i32, ()> {42}\");\n+}\n+\n+#[test]\n+fn match_struct_instantiation() {\n+    assert_matches(\n+        \"Foo {bar: 1, baz: 2}\",\n+        \"fn f() {Foo {bar: 1, baz: 2}}\",\n+        &[\"Foo {bar: 1, baz: 2}\"],\n+    );\n+    // Now with placeholders for all parts of the struct.\n+    assert_matches(\n+        \"Foo {$a: $b, $c: $d}\",\n+        \"fn f() {Foo {bar: 1, baz: 2}}\",\n+        &[\"Foo {bar: 1, baz: 2}\"],\n+    );\n+    assert_matches(\"Foo {}\", \"fn f() {Foo {}}\", &[\"Foo {}\"]);\n+}\n+\n+#[test]\n+fn match_path() {\n+    assert_matches(\"foo::bar\", \"fn f() {foo::bar(42)}\", &[\"foo::bar\"]);\n+    assert_matches(\"$a::bar\", \"fn f() {foo::bar(42)}\", &[\"foo::bar\"]);\n+    assert_matches(\"foo::$b\", \"fn f() {foo::bar(42)}\", &[\"foo::bar\"]);\n+}\n+\n+#[test]\n+fn match_pattern() {\n+    assert_matches(\"Some($a)\", \"fn f() {if let Some(x) = foo() {}}\", &[\"Some(x)\"]);\n+}\n+\n+#[test]\n+fn match_reordered_struct_instantiation() {\n+    assert_matches(\n+        \"Foo {aa: 1, b: 2, ccc: 3}\",\n+        \"fn f() {Foo {b: 2, ccc: 3, aa: 1}}\",\n+        &[\"Foo {b: 2, ccc: 3, aa: 1}\"],\n+    );\n+    assert_no_match(\"Foo {a: 1}\", \"fn f() {Foo {b: 1}}\");\n+    assert_no_match(\"Foo {a: 1}\", \"fn f() {Foo {a: 2}}\");\n+    assert_no_match(\"Foo {a: 1, b: 2}\", \"fn f() {Foo {a: 1}}\");\n+    assert_no_match(\"Foo {a: 1, b: 2}\", \"fn f() {Foo {b: 2}}\");\n+    assert_no_match(\"Foo {a: 1, }\", \"fn f() {Foo {a: 1, b: 2}}\");\n+    assert_no_match(\"Foo {a: 1, z: 9}\", \"fn f() {Foo {a: 1}}\");\n+}\n+\n+#[test]\n+fn replace_function_call() {\n+    assert_ssr_transform(\"foo() ==>> bar()\", \"fn f1() {foo(); foo();}\", \"fn f1() {bar(); bar();}\");\n+}\n+\n+#[test]\n+fn replace_function_call_with_placeholders() {\n+    assert_ssr_transform(\n+        \"foo($a, $b) ==>> bar($b, $a)\",\n+        \"fn f1() {foo(5, 42)}\",\n+        \"fn f1() {bar(42, 5)}\",\n+    );\n+}\n+\n+#[test]\n+fn replace_nested_function_calls() {\n+    assert_ssr_transform(\n+        \"foo($a) ==>> bar($a)\",\n+        \"fn f1() {foo(foo(42))}\",\n+        \"fn f1() {bar(bar(42))}\",\n+    );\n+}\n+\n+#[test]\n+fn replace_type() {\n+    assert_ssr_transform(\n+        \"Result<(), $a> ==>> Option<$a>\",\n+        \"fn f1() -> Result<(), Vec<Error>> {foo()}\",\n+        \"fn f1() -> Option<Vec<Error>> {foo()}\",\n+    );\n+}\n+\n+#[test]\n+fn replace_struct_init() {\n+    assert_ssr_transform(\n+        \"Foo {a: $a, b: $b} ==>> Foo::new($a, $b)\",\n+        \"fn f1() {Foo{b: 1, a: 2}}\",\n+        \"fn f1() {Foo::new(2, 1)}\",\n+    );\n+}\n+\n+#[test]\n+fn replace_binary_op() {\n+    assert_ssr_transform(\n+        \"$a + $b ==>> $b + $a\",\n+        \"fn f() {2 * 3 + 4 * 5}\",\n+        \"fn f() {4 * 5 + 2 * 3}\",\n+    );\n+    assert_ssr_transform(\n+        \"$a + $b ==>> $b + $a\",\n+        \"fn f() {1 + 2 + 3 + 4}\",\n+        \"fn f() {4 + 3 + 2 + 1}\",\n+    );\n+}\n+\n+#[test]\n+fn match_binary_op() {\n+    assert_matches(\"$a + $b\", \"fn f() {1 + 2 + 3 + 4}\", &[\"1 + 2\", \"1 + 2 + 3\", \"1 + 2 + 3 + 4\"]);\n+}\n+\n+#[test]\n+fn multiple_rules() {\n+    assert_ssr_transforms(\n+        &[\"$a + 1 ==>> add_one($a)\", \"$a + $b ==>> add($a, $b)\"],\n+        \"fn f() -> i32 {3 + 2 + 1}\",\n+        \"fn f() -> i32 {add_one(add(3, 2))}\",\n+    )\n+}"}]}