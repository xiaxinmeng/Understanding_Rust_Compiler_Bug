{"sha": "d089fe974edc53fa34384e8e76eeb1eca0d89042", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQwODlmZTk3NGVkYzUzZmEzNDM4NGU4ZTc2ZWViMWVjYTBkODkwNDI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-03-14T12:44:17Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2018-03-14T12:44:17Z"}, "message": "Auto merge of #48811 - Zoxc:syntax-globals, r=michaelwoerister\n\nRemove syntax and syntax_pos thread locals\n\nThis moves `syntax` and `syntax_pos` globals into a struct which are pointed to by thread locals. Most of the changes here are indentation changes in test. It would probably be a good idea to ignore whitespace changes while reviewing. Some indentation is unchanged to avoid merge conflicts.\n\nr? @michaelwoerister", "tree": {"sha": "7c3e9927e9b2932fa4d888d5f85c0ecfa0581559", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/7c3e9927e9b2932fa4d888d5f85c0ecfa0581559"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d089fe974edc53fa34384e8e76eeb1eca0d89042", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d089fe974edc53fa34384e8e76eeb1eca0d89042", "html_url": "https://github.com/rust-lang/rust/commit/d089fe974edc53fa34384e8e76eeb1eca0d89042", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d089fe974edc53fa34384e8e76eeb1eca0d89042/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "24e679c375da94b0f7db732c45c4c53724e8854d", "url": "https://api.github.com/repos/rust-lang/rust/commits/24e679c375da94b0f7db732c45c4c53724e8854d", "html_url": "https://github.com/rust-lang/rust/commit/24e679c375da94b0f7db732c45c4c53724e8854d"}, {"sha": "cbdf4ec03e92ed36c162bb8c645993e48a1caa02", "url": "https://api.github.com/repos/rust-lang/rust/commits/cbdf4ec03e92ed36c162bb8c645993e48a1caa02", "html_url": "https://github.com/rust-lang/rust/commit/cbdf4ec03e92ed36c162bb8c645993e48a1caa02"}], "stats": {"total": 2300, "additions": 1257, "deletions": 1043}, "files": [{"sha": "e34983e23c023b1211e5012aaf89acd72a2fa86f", "filename": "src/Cargo.lock", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -2432,6 +2432,7 @@ dependencies = [\n  \"rustc_cratesio_shim 0.0.0\",\n  \"rustc_data_structures 0.0.0\",\n  \"rustc_errors 0.0.0\",\n+ \"scoped-tls 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"serialize 0.0.0\",\n  \"syntax_pos 0.0.0\",\n ]\n@@ -2453,6 +2454,7 @@ name = \"syntax_pos\"\n version = \"0.0.0\"\n dependencies = [\n  \"rustc_data_structures 0.0.0\",\n+ \"scoped-tls 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"serialize 0.0.0\",\n  \"unicode-width 0.1.4 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]"}, {"sha": "885658df56546873ea75b3b98a2f23fbf88f4b21", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 32, "deletions": 26, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -2391,6 +2391,7 @@ mod tests {\n     use super::{Externs, OutputType, OutputTypes};\n     use rustc_back::{PanicStrategy, RelroLevel};\n     use syntax::symbol::Symbol;\n+    use syntax;\n \n     fn optgroups() -> getopts::Options {\n         let mut opts = getopts::Options::new();\n@@ -2411,61 +2412,66 @@ mod tests {\n     // When the user supplies --test we should implicitly supply --cfg test\n     #[test]\n     fn test_switch_implies_cfg_test() {\n-        let matches = &match optgroups().parse(&[\"--test\".to_string()]) {\n-            Ok(m) => m,\n-            Err(f) => panic!(\"test_switch_implies_cfg_test: {}\", f),\n-        };\n-        let registry = errors::registry::Registry::new(&[]);\n-        let (sessopts, cfg) = build_session_options_and_crate_config(matches);\n-        let sess = build_session(sessopts, None, registry);\n-        let cfg = build_configuration(&sess, cfg);\n-        assert!(cfg.contains(&(Symbol::intern(\"test\"), None)));\n+        syntax::with_globals(|| {\n+            let matches = &match optgroups().parse(&[\"--test\".to_string()]) {\n+                Ok(m) => m,\n+                Err(f) => panic!(\"test_switch_implies_cfg_test: {}\", f),\n+            };\n+            let registry = errors::registry::Registry::new(&[]);\n+            let (sessopts, cfg) = build_session_options_and_crate_config(matches);\n+            let sess = build_session(sessopts, None, registry);\n+            let cfg = build_configuration(&sess, cfg);\n+            assert!(cfg.contains(&(Symbol::intern(\"test\"), None)));\n+        });\n     }\n \n     // When the user supplies --test and --cfg test, don't implicitly add\n     // another --cfg test\n     #[test]\n     fn test_switch_implies_cfg_test_unless_cfg_test() {\n-        let matches = &match optgroups().parse(&[\"--test\".to_string(), \"--cfg=test\".to_string()]) {\n-            Ok(m) => m,\n-            Err(f) => panic!(\"test_switch_implies_cfg_test_unless_cfg_test: {}\", f),\n-        };\n-        let registry = errors::registry::Registry::new(&[]);\n-        let (sessopts, cfg) = build_session_options_and_crate_config(matches);\n-        let sess = build_session(sessopts, None, registry);\n-        let cfg = build_configuration(&sess, cfg);\n-        let mut test_items = cfg.iter().filter(|&&(name, _)| name == \"test\");\n-        assert!(test_items.next().is_some());\n-        assert!(test_items.next().is_none());\n+        syntax::with_globals(|| {\n+            let matches = &match optgroups().parse(&[\"--test\".to_string(),\n+                                                     \"--cfg=test\".to_string()]) {\n+                Ok(m) => m,\n+                Err(f) => panic!(\"test_switch_implies_cfg_test_unless_cfg_test: {}\", f),\n+            };\n+            let registry = errors::registry::Registry::new(&[]);\n+            let (sessopts, cfg) = build_session_options_and_crate_config(matches);\n+            let sess = build_session(sessopts, None, registry);\n+            let cfg = build_configuration(&sess, cfg);\n+            let mut test_items = cfg.iter().filter(|&&(name, _)| name == \"test\");\n+            assert!(test_items.next().is_some());\n+            assert!(test_items.next().is_none());\n+        });\n     }\n \n     #[test]\n     fn test_can_print_warnings() {\n-        {\n+        syntax::with_globals(|| {\n             let matches = optgroups().parse(&[\"-Awarnings\".to_string()]).unwrap();\n             let registry = errors::registry::Registry::new(&[]);\n             let (sessopts, _) = build_session_options_and_crate_config(&matches);\n             let sess = build_session(sessopts, None, registry);\n             assert!(!sess.diagnostic().flags.can_emit_warnings);\n-        }\n+        });\n \n-        {\n+        syntax::with_globals(|| {\n             let matches = optgroups()\n                 .parse(&[\"-Awarnings\".to_string(), \"-Dwarnings\".to_string()])\n                 .unwrap();\n             let registry = errors::registry::Registry::new(&[]);\n             let (sessopts, _) = build_session_options_and_crate_config(&matches);\n             let sess = build_session(sessopts, None, registry);\n             assert!(sess.diagnostic().flags.can_emit_warnings);\n-        }\n+        });\n \n-        {\n+        syntax::with_globals(|| {\n             let matches = optgroups().parse(&[\"-Adead_code\".to_string()]).unwrap();\n             let registry = errors::registry::Registry::new(&[]);\n             let (sessopts, _) = build_session_options_and_crate_config(&matches);\n             let sess = build_session(sessopts, None, registry);\n             assert!(sess.diagnostic().flags.can_emit_warnings);\n-        }\n+        });\n     }\n \n     #[test]"}, {"sha": "04513bfa53d043fb58fbc727ec153bebe3a95854", "filename": "src/librustc_driver/lib.rs", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc_driver%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc_driver%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Flib.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -447,6 +447,17 @@ pub fn run_compiler<'a>(args: &[String],\n                         file_loader: Option<Box<FileLoader + 'static>>,\n                         emitter_dest: Option<Box<Write + Send>>)\n                         -> (CompileResult, Option<Session>)\n+{\n+    syntax::with_globals(|| {\n+        run_compiler_impl(args, callbacks, file_loader, emitter_dest)\n+    })\n+}\n+\n+fn run_compiler_impl<'a>(args: &[String],\n+                         callbacks: &mut CompilerCalls<'a>,\n+                         file_loader: Option<Box<FileLoader + 'static>>,\n+                         emitter_dest: Option<Box<Write + Send>>)\n+                         -> (CompileResult, Option<Session>)\n {\n     macro_rules! do_or_return {($expr: expr, $sess: expr) => {\n         match $expr {"}, {"sha": "fb48f900be522be2559f28788c8f656266734434", "filename": "src/librustc_driver/test.rs", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc_driver%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustc_driver%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_driver%2Ftest.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -29,6 +29,7 @@ use rustc::hir::map as hir_map;\n use rustc::session::{self, config};\n use rustc::session::config::{OutputFilenames, OutputTypes};\n use rustc_data_structures::sync::Lrc;\n+use syntax;\n use syntax::ast;\n use syntax::abi::Abi;\n use syntax::codemap::{CodeMap, FilePathMapping, FileName};\n@@ -93,9 +94,19 @@ fn errors(msgs: &[&str]) -> (Box<Emitter + Send>, usize) {\n }\n \n fn test_env<F>(source_string: &str,\n-               (emitter, expected_err_count): (Box<Emitter + Send>, usize),\n+               args: (Box<Emitter + Send>, usize),\n                body: F)\n     where F: FnOnce(Env)\n+{\n+    syntax::with_globals(|| {\n+        test_env_impl(source_string, args, body)\n+    });\n+}\n+\n+fn test_env_impl<F>(source_string: &str,\n+                    (emitter, expected_err_count): (Box<Emitter + Send>, usize),\n+                    body: F)\n+    where F: FnOnce(Env)\n {\n     let mut options = config::basic_options();\n     options.debugging_opts.verbose = true;"}, {"sha": "5cac2d1bbe7eeb1e0a5e55b1a26a218b1ed8df00", "filename": "src/librustdoc/clean/cfg.rs", "status": "modified", "additions": 466, "deletions": 450, "changes": 916, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Fclean%2Fcfg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Fclean%2Fcfg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fclean%2Fcfg.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -398,6 +398,7 @@ mod test {\n     use syntax::ast::*;\n     use syntax::codemap::dummy_spanned;\n     use syntax_pos::DUMMY_SP;\n+    use syntax::with_globals;\n \n     fn word_cfg(s: &str) -> Cfg {\n         Cfg::Cfg(Symbol::intern(s), None)\n@@ -409,479 +410,494 @@ mod test {\n \n     #[test]\n     fn test_cfg_not() {\n-        assert_eq!(!Cfg::False, Cfg::True);\n-        assert_eq!(!Cfg::True, Cfg::False);\n-        assert_eq!(!word_cfg(\"test\"), Cfg::Not(Box::new(word_cfg(\"test\"))));\n-        assert_eq!(\n-            !Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n-            Cfg::Not(Box::new(Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")])))\n-        );\n-        assert_eq!(\n-            !Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n-            Cfg::Not(Box::new(Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")])))\n-        );\n-        assert_eq!(!Cfg::Not(Box::new(word_cfg(\"test\"))), word_cfg(\"test\"));\n+        with_globals(|| {\n+            assert_eq!(!Cfg::False, Cfg::True);\n+            assert_eq!(!Cfg::True, Cfg::False);\n+            assert_eq!(!word_cfg(\"test\"), Cfg::Not(Box::new(word_cfg(\"test\"))));\n+            assert_eq!(\n+                !Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n+                Cfg::Not(Box::new(Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")])))\n+            );\n+            assert_eq!(\n+                !Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n+                Cfg::Not(Box::new(Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")])))\n+            );\n+            assert_eq!(!Cfg::Not(Box::new(word_cfg(\"test\"))), word_cfg(\"test\"));\n+        })\n     }\n \n     #[test]\n     fn test_cfg_and() {\n-        let mut x = Cfg::False;\n-        x &= Cfg::True;\n-        assert_eq!(x, Cfg::False);\n-\n-        x = word_cfg(\"test\");\n-        x &= Cfg::False;\n-        assert_eq!(x, Cfg::False);\n-\n-        x = word_cfg(\"test2\");\n-        x &= Cfg::True;\n-        assert_eq!(x, word_cfg(\"test2\"));\n-\n-        x = Cfg::True;\n-        x &= word_cfg(\"test3\");\n-        assert_eq!(x, word_cfg(\"test3\"));\n-\n-        x &= word_cfg(\"test4\");\n-        assert_eq!(x, Cfg::All(vec![word_cfg(\"test3\"), word_cfg(\"test4\")]));\n-\n-        x &= word_cfg(\"test5\");\n-        assert_eq!(x, Cfg::All(vec![word_cfg(\"test3\"), word_cfg(\"test4\"), word_cfg(\"test5\")]));\n-\n-        x &= Cfg::All(vec![word_cfg(\"test6\"), word_cfg(\"test7\")]);\n-        assert_eq!(x, Cfg::All(vec![\n-            word_cfg(\"test3\"),\n-            word_cfg(\"test4\"),\n-            word_cfg(\"test5\"),\n-            word_cfg(\"test6\"),\n-            word_cfg(\"test7\"),\n-        ]));\n-\n-        let mut y = Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]);\n-        y &= x;\n-        assert_eq!(y, Cfg::All(vec![\n-            word_cfg(\"test3\"),\n-            word_cfg(\"test4\"),\n-            word_cfg(\"test5\"),\n-            word_cfg(\"test6\"),\n-            word_cfg(\"test7\"),\n-            Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n-        ]));\n-\n-        assert_eq!(\n-            word_cfg(\"a\") & word_cfg(\"b\") & word_cfg(\"c\"),\n-            Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\"), word_cfg(\"c\")])\n-        );\n+        with_globals(|| {\n+            let mut x = Cfg::False;\n+            x &= Cfg::True;\n+            assert_eq!(x, Cfg::False);\n+\n+            x = word_cfg(\"test\");\n+            x &= Cfg::False;\n+            assert_eq!(x, Cfg::False);\n+\n+            x = word_cfg(\"test2\");\n+            x &= Cfg::True;\n+            assert_eq!(x, word_cfg(\"test2\"));\n+\n+            x = Cfg::True;\n+            x &= word_cfg(\"test3\");\n+            assert_eq!(x, word_cfg(\"test3\"));\n+\n+            x &= word_cfg(\"test4\");\n+            assert_eq!(x, Cfg::All(vec![word_cfg(\"test3\"), word_cfg(\"test4\")]));\n+\n+            x &= word_cfg(\"test5\");\n+            assert_eq!(x, Cfg::All(vec![word_cfg(\"test3\"), word_cfg(\"test4\"), word_cfg(\"test5\")]));\n+\n+            x &= Cfg::All(vec![word_cfg(\"test6\"), word_cfg(\"test7\")]);\n+            assert_eq!(x, Cfg::All(vec![\n+                word_cfg(\"test3\"),\n+                word_cfg(\"test4\"),\n+                word_cfg(\"test5\"),\n+                word_cfg(\"test6\"),\n+                word_cfg(\"test7\"),\n+            ]));\n+\n+            let mut y = Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]);\n+            y &= x;\n+            assert_eq!(y, Cfg::All(vec![\n+                word_cfg(\"test3\"),\n+                word_cfg(\"test4\"),\n+                word_cfg(\"test5\"),\n+                word_cfg(\"test6\"),\n+                word_cfg(\"test7\"),\n+                Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n+            ]));\n+\n+            assert_eq!(\n+                word_cfg(\"a\") & word_cfg(\"b\") & word_cfg(\"c\"),\n+                Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\"), word_cfg(\"c\")])\n+            );\n+        })\n     }\n \n     #[test]\n     fn test_cfg_or() {\n-        let mut x = Cfg::True;\n-        x |= Cfg::False;\n-        assert_eq!(x, Cfg::True);\n-\n-        x = word_cfg(\"test\");\n-        x |= Cfg::True;\n-        assert_eq!(x, Cfg::True);\n-\n-        x = word_cfg(\"test2\");\n-        x |= Cfg::False;\n-        assert_eq!(x, word_cfg(\"test2\"));\n-\n-        x = Cfg::False;\n-        x |= word_cfg(\"test3\");\n-        assert_eq!(x, word_cfg(\"test3\"));\n-\n-        x |= word_cfg(\"test4\");\n-        assert_eq!(x, Cfg::Any(vec![word_cfg(\"test3\"), word_cfg(\"test4\")]));\n-\n-        x |= word_cfg(\"test5\");\n-        assert_eq!(x, Cfg::Any(vec![word_cfg(\"test3\"), word_cfg(\"test4\"), word_cfg(\"test5\")]));\n-\n-        x |= Cfg::Any(vec![word_cfg(\"test6\"), word_cfg(\"test7\")]);\n-        assert_eq!(x, Cfg::Any(vec![\n-            word_cfg(\"test3\"),\n-            word_cfg(\"test4\"),\n-            word_cfg(\"test5\"),\n-            word_cfg(\"test6\"),\n-            word_cfg(\"test7\"),\n-        ]));\n-\n-        let mut y = Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]);\n-        y |= x;\n-        assert_eq!(y, Cfg::Any(vec![\n-            word_cfg(\"test3\"),\n-            word_cfg(\"test4\"),\n-            word_cfg(\"test5\"),\n-            word_cfg(\"test6\"),\n-            word_cfg(\"test7\"),\n-            Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n-        ]));\n-\n-        assert_eq!(\n-            word_cfg(\"a\") | word_cfg(\"b\") | word_cfg(\"c\"),\n-            Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\"), word_cfg(\"c\")])\n-        );\n+        with_globals(|| {\n+            let mut x = Cfg::True;\n+            x |= Cfg::False;\n+            assert_eq!(x, Cfg::True);\n+\n+            x = word_cfg(\"test\");\n+            x |= Cfg::True;\n+            assert_eq!(x, Cfg::True);\n+\n+            x = word_cfg(\"test2\");\n+            x |= Cfg::False;\n+            assert_eq!(x, word_cfg(\"test2\"));\n+\n+            x = Cfg::False;\n+            x |= word_cfg(\"test3\");\n+            assert_eq!(x, word_cfg(\"test3\"));\n+\n+            x |= word_cfg(\"test4\");\n+            assert_eq!(x, Cfg::Any(vec![word_cfg(\"test3\"), word_cfg(\"test4\")]));\n+\n+            x |= word_cfg(\"test5\");\n+            assert_eq!(x, Cfg::Any(vec![word_cfg(\"test3\"), word_cfg(\"test4\"), word_cfg(\"test5\")]));\n+\n+            x |= Cfg::Any(vec![word_cfg(\"test6\"), word_cfg(\"test7\")]);\n+            assert_eq!(x, Cfg::Any(vec![\n+                word_cfg(\"test3\"),\n+                word_cfg(\"test4\"),\n+                word_cfg(\"test5\"),\n+                word_cfg(\"test6\"),\n+                word_cfg(\"test7\"),\n+            ]));\n+\n+            let mut y = Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]);\n+            y |= x;\n+            assert_eq!(y, Cfg::Any(vec![\n+                word_cfg(\"test3\"),\n+                word_cfg(\"test4\"),\n+                word_cfg(\"test5\"),\n+                word_cfg(\"test6\"),\n+                word_cfg(\"test7\"),\n+                Cfg::All(vec![word_cfg(\"a\"), word_cfg(\"b\")]),\n+            ]));\n+\n+            assert_eq!(\n+                word_cfg(\"a\") | word_cfg(\"b\") | word_cfg(\"c\"),\n+                Cfg::Any(vec![word_cfg(\"a\"), word_cfg(\"b\"), word_cfg(\"c\")])\n+            );\n+        })\n     }\n \n     #[test]\n     fn test_parse_ok() {\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"all\"),\n-            node: MetaItemKind::Word,\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"all\")));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"all\"),\n-            node: MetaItemKind::NameValue(dummy_spanned(LitKind::Str(\n-                Symbol::intern(\"done\"),\n-                StrStyle::Cooked,\n-            ))),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(name_value_cfg(\"all\", \"done\")));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"all\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"b\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") & word_cfg(\"b\")));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"any\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"b\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") | word_cfg(\"b\")));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"not\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(!word_cfg(\"a\")));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"not\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"any\"),\n-                    node: MetaItemKind::List(vec![\n-                        dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                            name: Symbol::intern(\"a\"),\n-                            node: MetaItemKind::Word,\n-                            span: DUMMY_SP,\n-                        })),\n-                        dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                            name: Symbol::intern(\"all\"),\n-                            node: MetaItemKind::List(vec![\n-                                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                                    name: Symbol::intern(\"b\"),\n-                                    node: MetaItemKind::Word,\n-                                    span: DUMMY_SP,\n-                                })),\n-                                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                                    name: Symbol::intern(\"c\"),\n-                                    node: MetaItemKind::Word,\n-                                    span: DUMMY_SP,\n-                                })),\n-                            ]),\n-                            span: DUMMY_SP,\n-                        })),\n-                    ]),\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(!(word_cfg(\"a\") | (word_cfg(\"b\") & word_cfg(\"c\")))));\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"all\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"b\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"c\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") & word_cfg(\"b\") & word_cfg(\"c\")));\n+        with_globals(|| {\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"all\"),\n+                node: MetaItemKind::Word,\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"all\")));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"all\"),\n+                node: MetaItemKind::NameValue(dummy_spanned(LitKind::Str(\n+                    Symbol::intern(\"done\"),\n+                    StrStyle::Cooked,\n+                ))),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(name_value_cfg(\"all\", \"done\")));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"all\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"b\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") & word_cfg(\"b\")));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"any\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"b\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") | word_cfg(\"b\")));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"not\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(!word_cfg(\"a\")));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"not\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"any\"),\n+                        node: MetaItemKind::List(vec![\n+                            dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                                name: Symbol::intern(\"a\"),\n+                                node: MetaItemKind::Word,\n+                                span: DUMMY_SP,\n+                            })),\n+                            dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                                name: Symbol::intern(\"all\"),\n+                                node: MetaItemKind::List(vec![\n+                                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                                        name: Symbol::intern(\"b\"),\n+                                        node: MetaItemKind::Word,\n+                                        span: DUMMY_SP,\n+                                    })),\n+                                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                                        name: Symbol::intern(\"c\"),\n+                                        node: MetaItemKind::Word,\n+                                        span: DUMMY_SP,\n+                                    })),\n+                                ]),\n+                                span: DUMMY_SP,\n+                            })),\n+                        ]),\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(!(word_cfg(\"a\") | (word_cfg(\"b\") & word_cfg(\"c\")))));\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"all\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"b\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"c\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert_eq!(Cfg::parse(&mi), Ok(word_cfg(\"a\") & word_cfg(\"b\") & word_cfg(\"c\")));\n+        })\n     }\n \n     #[test]\n     fn test_parse_err() {\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"foo\"),\n-            node: MetaItemKind::NameValue(dummy_spanned(LitKind::Bool(false))),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"not\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"b\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"not\"),\n-            node: MetaItemKind::List(vec![]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"foo\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"all\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"foo\"),\n-                    node: MetaItemKind::List(vec![]),\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"b\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"any\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"a\"),\n-                    node: MetaItemKind::Word,\n-                    span: DUMMY_SP,\n-                })),\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"foo\"),\n-                    node: MetaItemKind::List(vec![]),\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n-\n-        let mi = MetaItem {\n-            name: Symbol::intern(\"not\"),\n-            node: MetaItemKind::List(vec![\n-                dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n-                    name: Symbol::intern(\"foo\"),\n-                    node: MetaItemKind::List(vec![]),\n-                    span: DUMMY_SP,\n-                })),\n-            ]),\n-            span: DUMMY_SP,\n-        };\n-        assert!(Cfg::parse(&mi).is_err());\n+        with_globals(|| {\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"foo\"),\n+                node: MetaItemKind::NameValue(dummy_spanned(LitKind::Bool(false))),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"not\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"b\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"not\"),\n+                node: MetaItemKind::List(vec![]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"foo\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"all\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"foo\"),\n+                        node: MetaItemKind::List(vec![]),\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"b\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"any\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"a\"),\n+                        node: MetaItemKind::Word,\n+                        span: DUMMY_SP,\n+                    })),\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"foo\"),\n+                        node: MetaItemKind::List(vec![]),\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+\n+            let mi = MetaItem {\n+                name: Symbol::intern(\"not\"),\n+                node: MetaItemKind::List(vec![\n+                    dummy_spanned(NestedMetaItemKind::MetaItem(MetaItem {\n+                        name: Symbol::intern(\"foo\"),\n+                        node: MetaItemKind::List(vec![]),\n+                        span: DUMMY_SP,\n+                    })),\n+                ]),\n+                span: DUMMY_SP,\n+            };\n+            assert!(Cfg::parse(&mi).is_err());\n+        })\n     }\n \n     #[test]\n     fn test_render_short_html() {\n-        assert_eq!(\n-            word_cfg(\"unix\").render_short_html(),\n-            \"Unix\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_os\", \"macos\").render_short_html(),\n-            \"macOS\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_pointer_width\", \"16\").render_short_html(),\n-            \"16-bit\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_endian\", \"little\").render_short_html(),\n-            \"Little-endian\"\n-        );\n-        assert_eq!(\n-            (!word_cfg(\"windows\")).render_short_html(),\n-            \"Non-Windows\"\n-        );\n-        assert_eq!(\n-            (word_cfg(\"unix\") & word_cfg(\"windows\")).render_short_html(),\n-            \"Unix and Windows\"\n-        );\n-        assert_eq!(\n-            (word_cfg(\"unix\") | word_cfg(\"windows\")).render_short_html(),\n-            \"Unix or Windows\"\n-        );\n-        assert_eq!(\n-            (\n-                word_cfg(\"unix\") & word_cfg(\"windows\") & word_cfg(\"debug_assertions\")\n-            ).render_short_html(),\n-            \"Unix and Windows and debug-assertions enabled\"\n-        );\n-        assert_eq!(\n-            (\n-                word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\")\n-            ).render_short_html(),\n-            \"Unix or Windows or debug-assertions enabled\"\n-        );\n-        assert_eq!(\n-            (\n-                !(word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\"))\n-            ).render_short_html(),\n-            \"Neither Unix nor Windows nor debug-assertions enabled\"\n-        );\n-        assert_eq!(\n-            (\n-                (word_cfg(\"unix\") & name_value_cfg(\"target_arch\", \"x86_64\")) |\n-                (word_cfg(\"windows\") & name_value_cfg(\"target_pointer_width\", \"64\"))\n-            ).render_short_html(),\n-            \"Unix and x86-64, or Windows and 64-bit\"\n-        );\n-        assert_eq!(\n-            (!(word_cfg(\"unix\") & word_cfg(\"windows\"))).render_short_html(),\n-            \"Not (Unix and Windows)\"\n-        );\n-        assert_eq!(\n-            (\n-                (word_cfg(\"debug_assertions\") | word_cfg(\"windows\")) & word_cfg(\"unix\")\n-            ).render_short_html(),\n-            \"(Debug-assertions enabled or Windows) and Unix\"\n-        );\n+        with_globals(|| {\n+            assert_eq!(\n+                word_cfg(\"unix\").render_short_html(),\n+                \"Unix\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_os\", \"macos\").render_short_html(),\n+                \"macOS\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_pointer_width\", \"16\").render_short_html(),\n+                \"16-bit\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_endian\", \"little\").render_short_html(),\n+                \"Little-endian\"\n+            );\n+            assert_eq!(\n+                (!word_cfg(\"windows\")).render_short_html(),\n+                \"Non-Windows\"\n+            );\n+            assert_eq!(\n+                (word_cfg(\"unix\") & word_cfg(\"windows\")).render_short_html(),\n+                \"Unix and Windows\"\n+            );\n+            assert_eq!(\n+                (word_cfg(\"unix\") | word_cfg(\"windows\")).render_short_html(),\n+                \"Unix or Windows\"\n+            );\n+            assert_eq!(\n+                (\n+                    word_cfg(\"unix\") & word_cfg(\"windows\") & word_cfg(\"debug_assertions\")\n+                ).render_short_html(),\n+                \"Unix and Windows and debug-assertions enabled\"\n+            );\n+            assert_eq!(\n+                (\n+                    word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\")\n+                ).render_short_html(),\n+                \"Unix or Windows or debug-assertions enabled\"\n+            );\n+            assert_eq!(\n+                (\n+                    !(word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\"))\n+                ).render_short_html(),\n+                \"Neither Unix nor Windows nor debug-assertions enabled\"\n+            );\n+            assert_eq!(\n+                (\n+                    (word_cfg(\"unix\") & name_value_cfg(\"target_arch\", \"x86_64\")) |\n+                    (word_cfg(\"windows\") & name_value_cfg(\"target_pointer_width\", \"64\"))\n+                ).render_short_html(),\n+                \"Unix and x86-64, or Windows and 64-bit\"\n+            );\n+            assert_eq!(\n+                (!(word_cfg(\"unix\") & word_cfg(\"windows\"))).render_short_html(),\n+                \"Not (Unix and Windows)\"\n+            );\n+            assert_eq!(\n+                (\n+                    (word_cfg(\"debug_assertions\") | word_cfg(\"windows\")) & word_cfg(\"unix\")\n+                ).render_short_html(),\n+                \"(Debug-assertions enabled or Windows) and Unix\"\n+            );\n+        })\n     }\n \n     #[test]\n     fn test_render_long_html() {\n-        assert_eq!(\n-            word_cfg(\"unix\").render_long_html(),\n-            \"This is supported on <strong>Unix</strong> only.\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_os\", \"macos\").render_long_html(),\n-            \"This is supported on <strong>macOS</strong> only.\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_pointer_width\", \"16\").render_long_html(),\n-            \"This is supported on <strong>16-bit</strong> only.\"\n-        );\n-        assert_eq!(\n-            name_value_cfg(\"target_endian\", \"little\").render_long_html(),\n-            \"This is supported on <strong>little-endian</strong> only.\"\n-        );\n-        assert_eq!(\n-            (!word_cfg(\"windows\")).render_long_html(),\n-            \"This is supported on <strong>non-Windows</strong> only.\"\n-        );\n-        assert_eq!(\n-            (word_cfg(\"unix\") & word_cfg(\"windows\")).render_long_html(),\n-            \"This is supported on <strong>Unix and Windows</strong> only.\"\n-        );\n-        assert_eq!(\n-            (word_cfg(\"unix\") | word_cfg(\"windows\")).render_long_html(),\n-            \"This is supported on <strong>Unix or Windows</strong> only.\"\n-        );\n-        assert_eq!(\n-            (\n-                word_cfg(\"unix\") & word_cfg(\"windows\") & word_cfg(\"debug_assertions\")\n-            ).render_long_html(),\n-            \"This is supported on <strong>Unix and Windows and debug-assertions enabled</strong> \\\n-                only.\"\n-        );\n-        assert_eq!(\n-            (\n-                word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\")\n-            ).render_long_html(),\n-            \"This is supported on <strong>Unix or Windows or debug-assertions enabled</strong> \\\n-                only.\"\n-        );\n-        assert_eq!(\n-            (\n-                !(word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\"))\n-            ).render_long_html(),\n-            \"This is supported on <strong>neither Unix nor Windows nor debug-assertions \\\n-                enabled</strong>.\"\n-        );\n-        assert_eq!(\n-            (\n-                (word_cfg(\"unix\") & name_value_cfg(\"target_arch\", \"x86_64\")) |\n-                (word_cfg(\"windows\") & name_value_cfg(\"target_pointer_width\", \"64\"))\n-            ).render_long_html(),\n-            \"This is supported on <strong>Unix and x86-64, or Windows and 64-bit</strong> only.\"\n-        );\n-        assert_eq!(\n-            (!(word_cfg(\"unix\") & word_cfg(\"windows\"))).render_long_html(),\n-            \"This is supported on <strong>not (Unix and Windows)</strong>.\"\n-        );\n-        assert_eq!(\n-            (\n-                (word_cfg(\"debug_assertions\") | word_cfg(\"windows\")) & word_cfg(\"unix\")\n-            ).render_long_html(),\n-            \"This is supported on <strong>(debug-assertions enabled or Windows) and Unix</strong> \\\n-                only.\"\n-        );\n+        with_globals(|| {\n+            assert_eq!(\n+                word_cfg(\"unix\").render_long_html(),\n+                \"This is supported on <strong>Unix</strong> only.\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_os\", \"macos\").render_long_html(),\n+                \"This is supported on <strong>macOS</strong> only.\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_pointer_width\", \"16\").render_long_html(),\n+                \"This is supported on <strong>16-bit</strong> only.\"\n+            );\n+            assert_eq!(\n+                name_value_cfg(\"target_endian\", \"little\").render_long_html(),\n+                \"This is supported on <strong>little-endian</strong> only.\"\n+            );\n+            assert_eq!(\n+                (!word_cfg(\"windows\")).render_long_html(),\n+                \"This is supported on <strong>non-Windows</strong> only.\"\n+            );\n+            assert_eq!(\n+                (word_cfg(\"unix\") & word_cfg(\"windows\")).render_long_html(),\n+                \"This is supported on <strong>Unix and Windows</strong> only.\"\n+            );\n+            assert_eq!(\n+                (word_cfg(\"unix\") | word_cfg(\"windows\")).render_long_html(),\n+                \"This is supported on <strong>Unix or Windows</strong> only.\"\n+            );\n+            assert_eq!(\n+                (\n+                    word_cfg(\"unix\") & word_cfg(\"windows\") & word_cfg(\"debug_assertions\")\n+                ).render_long_html(),\n+                \"This is supported on <strong>Unix and Windows and debug-assertions enabled\\\n+                 </strong> only.\"\n+            );\n+            assert_eq!(\n+                (\n+                    word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\")\n+                ).render_long_html(),\n+                \"This is supported on <strong>Unix or Windows or debug-assertions enabled\\\n+                 </strong> only.\"\n+            );\n+            assert_eq!(\n+                (\n+                    !(word_cfg(\"unix\") | word_cfg(\"windows\") | word_cfg(\"debug_assertions\"))\n+                ).render_long_html(),\n+                \"This is supported on <strong>neither Unix nor Windows nor debug-assertions \\\n+                    enabled</strong>.\"\n+            );\n+            assert_eq!(\n+                (\n+                    (word_cfg(\"unix\") & name_value_cfg(\"target_arch\", \"x86_64\")) |\n+                    (word_cfg(\"windows\") & name_value_cfg(\"target_pointer_width\", \"64\"))\n+                ).render_long_html(),\n+                \"This is supported on <strong>Unix and x86-64, or Windows and 64-bit</strong> \\\n+                 only.\"\n+            );\n+            assert_eq!(\n+                (!(word_cfg(\"unix\") & word_cfg(\"windows\"))).render_long_html(),\n+                \"This is supported on <strong>not (Unix and Windows)</strong>.\"\n+            );\n+            assert_eq!(\n+                (\n+                    (word_cfg(\"debug_assertions\") | word_cfg(\"windows\")) & word_cfg(\"unix\")\n+                ).render_long_html(),\n+                \"This is supported on <strong>(debug-assertions enabled or Windows) and Unix\\\n+                </strong> only.\"\n+            );\n+        })\n     }\n }"}, {"sha": "da52fd5aa37253aa854db04bb2cc5a770627615d", "filename": "src/librustdoc/lib.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Flib.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -102,7 +102,9 @@ pub fn main() {\n     const STACK_SIZE: usize = 32_000_000; // 32MB\n     env_logger::init();\n     let res = std::thread::Builder::new().stack_size(STACK_SIZE).spawn(move || {\n-        get_args().map(|args| main_args(&args)).unwrap_or(1)\n+        syntax::with_globals(move || {\n+            get_args().map(|args| main_args(&args)).unwrap_or(1)\n+        })\n     }).unwrap().join().unwrap_or(101);\n     process::exit(res as i32);\n }\n@@ -554,7 +556,8 @@ where R: 'static + Send, F: 'static + Send + FnOnce(Output) -> R {\n     });\n \n     let (tx, rx) = channel();\n-    rustc_driver::monitor(move || {\n+\n+    rustc_driver::monitor(move || syntax::with_globals(move || {\n         use rustc::session::config::Input;\n \n         let (mut krate, renderinfo) =\n@@ -623,7 +626,7 @@ where R: 'static + Send, F: 'static + Send + FnOnce(Output) -> R {\n         let krate = pm.run_plugins(krate);\n \n         tx.send(f(Output { krate: krate, renderinfo: renderinfo, passes: passes })).unwrap();\n-    });\n+    }));\n     rx.recv().unwrap()\n }\n "}, {"sha": "117b21d47587f830121b43e9c2ff46b375b1dce3", "filename": "src/librustdoc/test.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Ftest.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibrustdoc%2Ftest.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Ftest.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -35,6 +35,7 @@ use rustc_resolve::MakeGlobMap;\n use syntax::ast;\n use syntax::codemap::CodeMap;\n use syntax::feature_gate::UnstableFeatures;\n+use syntax::with_globals;\n use syntax_pos::{BytePos, DUMMY_SP, Pos, Span, FileName};\n use errors;\n use errors::emitter::ColorConfig;\n@@ -518,7 +519,7 @@ impl Collector {\n                 let panic = io::set_panic(None);\n                 let print = io::set_print(None);\n                 match {\n-                    rustc_driver::in_rustc_thread(move || {\n+                    rustc_driver::in_rustc_thread(move || with_globals(move || {\n                         io::set_panic(panic);\n                         io::set_print(print);\n                         run_test(&test,\n@@ -536,7 +537,7 @@ impl Collector {\n                                  &opts,\n                                  maybe_sysroot,\n                                  linker)\n-                    })\n+                    }))\n                 } {\n                     Ok(()) => (),\n                     Err(err) => panic::resume_unwind(err),"}, {"sha": "8c24f36615bd219662f9ffc8bd6974e0a3249aa3", "filename": "src/libsyntax/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2FCargo.toml?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -12,6 +12,7 @@ crate-type = [\"dylib\"]\n bitflags = \"1.0\"\n serialize = { path = \"../libserialize\" }\n log = \"0.4\"\n+scoped-tls = \"0.1\"\n syntax_pos = { path = \"../libsyntax_pos\" }\n rustc_cratesio_shim = { path = \"../librustc_cratesio_shim\" }\n rustc_errors = { path = \"../librustc_errors\" }"}, {"sha": "f2cdcda98da5173a44974a9a2f4a4e8a7a0cd841", "filename": "src/libsyntax/attr.rs", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -30,15 +30,10 @@ use ptr::P;\n use symbol::Symbol;\n use tokenstream::{TokenStream, TokenTree, Delimited};\n use util::ThinVec;\n+use GLOBALS;\n \n-use std::cell::RefCell;\n use std::iter;\n \n-thread_local! {\n-    static USED_ATTRS: RefCell<Vec<u64>> = RefCell::new(Vec::new());\n-    static KNOWN_ATTRS: RefCell<Vec<u64>> = RefCell::new(Vec::new());\n-}\n-\n enum AttrError {\n     MultipleItem(Name),\n     UnknownMetaItem(Name),\n@@ -65,45 +60,49 @@ fn handle_errors(diag: &Handler, span: Span, error: AttrError) {\n pub fn mark_used(attr: &Attribute) {\n     debug!(\"Marking {:?} as used.\", attr);\n     let AttrId(id) = attr.id;\n-    USED_ATTRS.with(|slot| {\n+    GLOBALS.with(|globals| {\n+        let mut slot = globals.used_attrs.lock();\n         let idx = (id / 64) as usize;\n         let shift = id % 64;\n-        if slot.borrow().len() <= idx {\n-            slot.borrow_mut().resize(idx + 1, 0);\n+        if slot.len() <= idx {\n+            slot.resize(idx + 1, 0);\n         }\n-        slot.borrow_mut()[idx] |= 1 << shift;\n+        slot[idx] |= 1 << shift;\n     });\n }\n \n pub fn is_used(attr: &Attribute) -> bool {\n     let AttrId(id) = attr.id;\n-    USED_ATTRS.with(|slot| {\n+    GLOBALS.with(|globals| {\n+        let slot = globals.used_attrs.lock();\n         let idx = (id / 64) as usize;\n         let shift = id % 64;\n-        slot.borrow().get(idx).map(|bits| bits & (1 << shift) != 0)\n+        slot.get(idx).map(|bits| bits & (1 << shift) != 0)\n             .unwrap_or(false)\n     })\n }\n \n pub fn mark_known(attr: &Attribute) {\n     debug!(\"Marking {:?} as known.\", attr);\n     let AttrId(id) = attr.id;\n-    KNOWN_ATTRS.with(|slot| {\n+    GLOBALS.with(|globals| {\n+        let mut slot = globals.known_attrs.lock();\n         let idx = (id / 64) as usize;\n         let shift = id % 64;\n-        if slot.borrow().len() <= idx {\n-            slot.borrow_mut().resize(idx + 1, 0);\n+        if slot.len() <= idx {\n+            slot.resize(idx + 1, 0);\n         }\n-        slot.borrow_mut()[idx] |= 1 << shift;\n+        slot[idx] |= 1 << shift;\n     });\n }\n \n pub fn is_known(attr: &Attribute) -> bool {\n     let AttrId(id) = attr.id;\n-    KNOWN_ATTRS.with(|slot| {\n+    GLOBALS.with(|globals| {\n+        let slot = globals.known_attrs.lock();\n         let idx = (id / 64) as usize;\n         let shift = id % 64;\n-        slot.borrow().get(idx).map(|bits| bits & (1 << shift) != 0)\n+        slot.get(idx).map(|bits| bits & (1 << shift) != 0)\n             .unwrap_or(false)\n     })\n }"}, {"sha": "2cf99e15d1f9b987d4975495a8b87704a93cbc7c", "filename": "src/libsyntax/fold.rs", "status": "modified", "additions": 24, "deletions": 19, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ffold.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ffold.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ffold.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -1386,6 +1386,7 @@ mod tests {\n     use util::parser_testing::{string_to_crate, matches_codepattern};\n     use print::pprust;\n     use fold;\n+    use with_globals;\n     use super::*;\n \n     // this version doesn't care about getting comments or docstrings in.\n@@ -1423,28 +1424,32 @@ mod tests {\n \n     // make sure idents get transformed everywhere\n     #[test] fn ident_transformation () {\n-        let mut zz_fold = ToZzIdentFolder;\n-        let ast = string_to_crate(\n-            \"#[a] mod b {fn c (d : e, f : g) {h!(i,j,k);l;m}}\".to_string());\n-        let folded_crate = zz_fold.fold_crate(ast);\n-        assert_pred!(\n-            matches_codepattern,\n-            \"matches_codepattern\",\n-            pprust::to_string(|s| fake_print_crate(s, &folded_crate)),\n-            \"#[zz]mod zz{fn zz(zz:zz,zz:zz){zz!(zz,zz,zz);zz;zz}}\".to_string());\n+        with_globals(|| {\n+            let mut zz_fold = ToZzIdentFolder;\n+            let ast = string_to_crate(\n+                \"#[a] mod b {fn c (d : e, f : g) {h!(i,j,k);l;m}}\".to_string());\n+            let folded_crate = zz_fold.fold_crate(ast);\n+            assert_pred!(\n+                matches_codepattern,\n+                \"matches_codepattern\",\n+                pprust::to_string(|s| fake_print_crate(s, &folded_crate)),\n+                \"#[zz]mod zz{fn zz(zz:zz,zz:zz){zz!(zz,zz,zz);zz;zz}}\".to_string());\n+        })\n     }\n \n     // even inside macro defs....\n     #[test] fn ident_transformation_in_defs () {\n-        let mut zz_fold = ToZzIdentFolder;\n-        let ast = string_to_crate(\n-            \"macro_rules! a {(b $c:expr $(d $e:token)f+ => \\\n-             (g $(d $d $e)+))} \".to_string());\n-        let folded_crate = zz_fold.fold_crate(ast);\n-        assert_pred!(\n-            matches_codepattern,\n-            \"matches_codepattern\",\n-            pprust::to_string(|s| fake_print_crate(s, &folded_crate)),\n-            \"macro_rules! zz((zz$zz:zz$(zz $zz:zz)zz+=>(zz$(zz$zz$zz)+)));\".to_string());\n+        with_globals(|| {\n+            let mut zz_fold = ToZzIdentFolder;\n+            let ast = string_to_crate(\n+                \"macro_rules! a {(b $c:expr $(d $e:token)f+ => \\\n+                (g $(d $d $e)+))} \".to_string());\n+            let folded_crate = zz_fold.fold_crate(ast);\n+            assert_pred!(\n+                matches_codepattern,\n+                \"matches_codepattern\",\n+                pprust::to_string(|s| fake_print_crate(s, &folded_crate)),\n+                \"macro_rules! zz((zz$zz:zz$(zz $zz:zz)zz+=>(zz$(zz$zz$zz)+)));\".to_string());\n+        })\n     }\n }"}, {"sha": "5f58b3bc3a0503b4c2db1c03d693866d32e4b9b6", "filename": "src/libsyntax/lib.rs", "status": "modified", "additions": 30, "deletions": 0, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Flib.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -39,9 +39,12 @@ extern crate std_unicode;\n pub extern crate rustc_errors as errors;\n extern crate syntax_pos;\n extern crate rustc_data_structures;\n+#[macro_use] extern crate scoped_tls;\n \n extern crate serialize as rustc_serialize; // used by deriving\n \n+use rustc_data_structures::sync::Lock;\n+\n // A variant of 'try!' that panics on an Err. This is used as a crutch on the\n // way towards a non-panic!-prone parser. It should be used for fatal parsing\n // errors; eventually we plan to convert all code using panictry to just use\n@@ -72,6 +75,33 @@ macro_rules! unwrap_or {\n     }\n }\n \n+struct Globals {\n+    used_attrs: Lock<Vec<u64>>,\n+    known_attrs: Lock<Vec<u64>>,\n+    syntax_pos_globals: syntax_pos::Globals,\n+}\n+\n+impl Globals {\n+    fn new() -> Globals {\n+        Globals {\n+            used_attrs: Lock::new(Vec::new()),\n+            known_attrs: Lock::new(Vec::new()),\n+            syntax_pos_globals: syntax_pos::Globals::new(),\n+        }\n+    }\n+}\n+\n+pub fn with_globals<F, R>(f: F) -> R\n+    where F: FnOnce() -> R\n+{\n+    let globals = Globals::new();\n+    GLOBALS.set(&globals, || {\n+        syntax_pos::GLOBALS.set(&globals.syntax_pos_globals, f)\n+    })\n+}\n+\n+scoped_thread_local!(static GLOBALS: Globals);\n+\n #[macro_use]\n pub mod diagnostics {\n     #[macro_use]"}, {"sha": "d0075c896567bc4ac48684cfc93d1908c0bb0b41", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 143, "deletions": 116, "changes": 259, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -1766,6 +1766,7 @@ mod tests {\n     use std::path::PathBuf;\n     use diagnostics::plugin::ErrorMap;\n     use rustc_data_structures::sync::Lock;\n+    use with_globals;\n     fn mk_sess(cm: Lrc<CodeMap>) -> ParseSess {\n         let emitter = errors::emitter::EmitterWriter::new(Box::new(io::sink()),\n                                                           Some(cm.clone()),\n@@ -1794,33 +1795,35 @@ mod tests {\n \n     #[test]\n     fn t1() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        let mut string_reader = setup(&cm,\n-                                      &sh,\n-                                      \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\"\n-                                          .to_string());\n-        let id = Ident::from_str(\"fn\");\n-        assert_eq!(string_reader.next_token().tok, token::Comment);\n-        assert_eq!(string_reader.next_token().tok, token::Whitespace);\n-        let tok1 = string_reader.next_token();\n-        let tok2 = TokenAndSpan {\n-            tok: token::Ident(id),\n-            sp: Span::new(BytePos(21), BytePos(23), NO_EXPANSION),\n-        };\n-        assert_eq!(tok1, tok2);\n-        assert_eq!(string_reader.next_token().tok, token::Whitespace);\n-        // the 'main' id is already read:\n-        assert_eq!(string_reader.pos.clone(), BytePos(28));\n-        // read another token:\n-        let tok3 = string_reader.next_token();\n-        let tok4 = TokenAndSpan {\n-            tok: token::Ident(Ident::from_str(\"main\")),\n-            sp: Span::new(BytePos(24), BytePos(28), NO_EXPANSION),\n-        };\n-        assert_eq!(tok3, tok4);\n-        // the lparen is already read:\n-        assert_eq!(string_reader.pos.clone(), BytePos(29))\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            let mut string_reader = setup(&cm,\n+                                        &sh,\n+                                        \"/* my source file */ fn main() { println!(\\\"zebra\\\"); }\\n\"\n+                                            .to_string());\n+            let id = Ident::from_str(\"fn\");\n+            assert_eq!(string_reader.next_token().tok, token::Comment);\n+            assert_eq!(string_reader.next_token().tok, token::Whitespace);\n+            let tok1 = string_reader.next_token();\n+            let tok2 = TokenAndSpan {\n+                tok: token::Ident(id),\n+                sp: Span::new(BytePos(21), BytePos(23), NO_EXPANSION),\n+            };\n+            assert_eq!(tok1, tok2);\n+            assert_eq!(string_reader.next_token().tok, token::Whitespace);\n+            // the 'main' id is already read:\n+            assert_eq!(string_reader.pos.clone(), BytePos(28));\n+            // read another token:\n+            let tok3 = string_reader.next_token();\n+            let tok4 = TokenAndSpan {\n+                tok: token::Ident(Ident::from_str(\"main\")),\n+                sp: Span::new(BytePos(24), BytePos(28), NO_EXPANSION),\n+            };\n+            assert_eq!(tok3, tok4);\n+            // the lparen is already read:\n+            assert_eq!(string_reader.pos.clone(), BytePos(29))\n+        })\n     }\n \n     // check that the given reader produces the desired stream\n@@ -1838,113 +1841,133 @@ mod tests {\n \n     #[test]\n     fn doublecolonparsing() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n-                           vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            check_tokenization(setup(&cm, &sh, \"a b\".to_string()),\n+                            vec![mk_ident(\"a\"), token::Whitespace, mk_ident(\"b\")]);\n+        })\n     }\n \n     #[test]\n     fn dcparsing_2() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n-                           vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            check_tokenization(setup(&cm, &sh, \"a::b\".to_string()),\n+                            vec![mk_ident(\"a\"), token::ModSep, mk_ident(\"b\")]);\n+        })\n     }\n \n     #[test]\n     fn dcparsing_3() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n-                           vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            check_tokenization(setup(&cm, &sh, \"a ::b\".to_string()),\n+                            vec![mk_ident(\"a\"), token::Whitespace, token::ModSep, mk_ident(\"b\")]);\n+        })\n     }\n \n     #[test]\n     fn dcparsing_4() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n-                           vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            check_tokenization(setup(&cm, &sh, \"a:: b\".to_string()),\n+                            vec![mk_ident(\"a\"), token::ModSep, token::Whitespace, mk_ident(\"b\")]);\n+        })\n     }\n \n     #[test]\n     fn character_a() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        assert_eq!(setup(&cm, &sh, \"'a'\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            assert_eq!(setup(&cm, &sh, \"'a'\".to_string()).next_token().tok,\n+                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+        })\n     }\n \n     #[test]\n     fn character_space() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        assert_eq!(setup(&cm, &sh, \"' '\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(Symbol::intern(\" \")), None));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            assert_eq!(setup(&cm, &sh, \"' '\".to_string()).next_token().tok,\n+                    token::Literal(token::Char(Symbol::intern(\" \")), None));\n+        })\n     }\n \n     #[test]\n     fn character_escaped() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        assert_eq!(setup(&cm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n-                   token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            assert_eq!(setup(&cm, &sh, \"'\\\\n'\".to_string()).next_token().tok,\n+                    token::Literal(token::Char(Symbol::intern(\"\\\\n\")), None));\n+        })\n     }\n \n     #[test]\n     fn lifetime_name() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        assert_eq!(setup(&cm, &sh, \"'abc\".to_string()).next_token().tok,\n-                   token::Lifetime(Ident::from_str(\"'abc\")));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            assert_eq!(setup(&cm, &sh, \"'abc\".to_string()).next_token().tok,\n+                    token::Lifetime(Ident::from_str(\"'abc\")));\n+        })\n     }\n \n     #[test]\n     fn raw_string() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        assert_eq!(setup(&cm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n-                       .next_token()\n-                       .tok,\n-                   token::Literal(token::StrRaw(Symbol::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            assert_eq!(setup(&cm, &sh, \"r###\\\"\\\"#a\\\\b\\x00c\\\"\\\"###\".to_string())\n+                        .next_token()\n+                        .tok,\n+                    token::Literal(token::StrRaw(Symbol::intern(\"\\\"#a\\\\b\\x00c\\\"\"), 3), None));\n+        })\n     }\n \n     #[test]\n     fn literal_suffixes() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        macro_rules! test {\n-            ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n-                assert_eq!(setup(&cm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n-                           token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                          Some(Symbol::intern(\"suffix\"))));\n-                // with a whitespace separator:\n-                assert_eq!(setup(&cm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n-                           token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n-                                          None));\n-            }}\n-        }\n-\n-        test!(\"'a'\", Char, \"a\");\n-        test!(\"b'a'\", Byte, \"a\");\n-        test!(\"\\\"a\\\"\", Str_, \"a\");\n-        test!(\"b\\\"a\\\"\", ByteStr, \"a\");\n-        test!(\"1234\", Integer, \"1234\");\n-        test!(\"0b101\", Integer, \"0b101\");\n-        test!(\"0xABC\", Integer, \"0xABC\");\n-        test!(\"1.0\", Float, \"1.0\");\n-        test!(\"1.0e10\", Float, \"1.0e10\");\n-\n-        assert_eq!(setup(&cm, &sh, \"2us\".to_string()).next_token().tok,\n-                   token::Literal(token::Integer(Symbol::intern(\"2\")),\n-                                  Some(Symbol::intern(\"us\"))));\n-        assert_eq!(setup(&cm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                   token::Literal(token::StrRaw(Symbol::intern(\"raw\"), 3),\n-                                  Some(Symbol::intern(\"suffix\"))));\n-        assert_eq!(setup(&cm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n-                   token::Literal(token::ByteStrRaw(Symbol::intern(\"raw\"), 3),\n-                                  Some(Symbol::intern(\"suffix\"))));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            macro_rules! test {\n+                ($input: expr, $tok_type: ident, $tok_contents: expr) => {{\n+                    assert_eq!(setup(&cm, &sh, format!(\"{}suffix\", $input)).next_token().tok,\n+                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n+                                            Some(Symbol::intern(\"suffix\"))));\n+                    // with a whitespace separator:\n+                    assert_eq!(setup(&cm, &sh, format!(\"{} suffix\", $input)).next_token().tok,\n+                            token::Literal(token::$tok_type(Symbol::intern($tok_contents)),\n+                                            None));\n+                }}\n+            }\n+\n+            test!(\"'a'\", Char, \"a\");\n+            test!(\"b'a'\", Byte, \"a\");\n+            test!(\"\\\"a\\\"\", Str_, \"a\");\n+            test!(\"b\\\"a\\\"\", ByteStr, \"a\");\n+            test!(\"1234\", Integer, \"1234\");\n+            test!(\"0b101\", Integer, \"0b101\");\n+            test!(\"0xABC\", Integer, \"0xABC\");\n+            test!(\"1.0\", Float, \"1.0\");\n+            test!(\"1.0e10\", Float, \"1.0e10\");\n+\n+            assert_eq!(setup(&cm, &sh, \"2us\".to_string()).next_token().tok,\n+                    token::Literal(token::Integer(Symbol::intern(\"2\")),\n+                                    Some(Symbol::intern(\"us\"))));\n+            assert_eq!(setup(&cm, &sh, \"r###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+                    token::Literal(token::StrRaw(Symbol::intern(\"raw\"), 3),\n+                                    Some(Symbol::intern(\"suffix\"))));\n+            assert_eq!(setup(&cm, &sh, \"br###\\\"raw\\\"###suffix\".to_string()).next_token().tok,\n+                    token::Literal(token::ByteStrRaw(Symbol::intern(\"raw\"), 3),\n+                                    Some(Symbol::intern(\"suffix\"))));\n+        })\n     }\n \n     #[test]\n@@ -1956,27 +1979,31 @@ mod tests {\n \n     #[test]\n     fn nested_block_comments() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        let mut lexer = setup(&cm, &sh, \"/* /* */ */'a'\".to_string());\n-        match lexer.next_token().tok {\n-            token::Comment => {}\n-            _ => panic!(\"expected a comment!\"),\n-        }\n-        assert_eq!(lexer.next_token().tok,\n-                   token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            let mut lexer = setup(&cm, &sh, \"/* /* */ */'a'\".to_string());\n+            match lexer.next_token().tok {\n+                token::Comment => {}\n+                _ => panic!(\"expected a comment!\"),\n+            }\n+            assert_eq!(lexer.next_token().tok,\n+                    token::Literal(token::Char(Symbol::intern(\"a\")), None));\n+        })\n     }\n \n     #[test]\n     fn crlf_comments() {\n-        let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-        let sh = mk_sess(cm.clone());\n-        let mut lexer = setup(&cm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n-        let comment = lexer.next_token();\n-        assert_eq!(comment.tok, token::Comment);\n-        assert_eq!((comment.sp.lo(), comment.sp.hi()), (BytePos(0), BytePos(7)));\n-        assert_eq!(lexer.next_token().tok, token::Whitespace);\n-        assert_eq!(lexer.next_token().tok,\n-                   token::DocComment(Symbol::intern(\"/// test\")));\n+        with_globals(|| {\n+            let cm = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+            let sh = mk_sess(cm.clone());\n+            let mut lexer = setup(&cm, &sh, \"// test\\r\\n/// test\\r\\n\".to_string());\n+            let comment = lexer.next_token();\n+            assert_eq!(comment.tok, token::Comment);\n+            assert_eq!((comment.sp.lo(), comment.sp.hi()), (BytePos(0), BytePos(7)));\n+            assert_eq!(lexer.next_token().tok, token::Whitespace);\n+            assert_eq!(lexer.next_token().tok,\n+                    token::DocComment(Symbol::intern(\"/// test\")));\n+        })\n     }\n }"}, {"sha": "ff097c362fe6101761a1034f2dd9db4df8837777", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 322, "deletions": 287, "changes": 609, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -680,6 +680,7 @@ mod tests {\n     use util::parser_testing::{string_to_stream, string_to_parser};\n     use util::parser_testing::{string_to_expr, string_to_item, string_to_stmt};\n     use util::ThinVec;\n+    use with_globals;\n \n     // produce a syntax_pos::span\n     fn sp(a: u32, b: u32) -> Span {\n@@ -691,277 +692,299 @@ mod tests {\n     }\n \n     #[test] fn path_exprs_1() {\n-        assert!(string_to_expr(\"a\".to_string()) ==\n-                   P(ast::Expr{\n-                    id: ast::DUMMY_NODE_ID,\n-                    node: ast::ExprKind::Path(None, ast::Path {\n+        with_globals(|| {\n+            assert!(string_to_expr(\"a\".to_string()) ==\n+                    P(ast::Expr{\n+                        id: ast::DUMMY_NODE_ID,\n+                        node: ast::ExprKind::Path(None, ast::Path {\n+                            span: sp(0, 1),\n+                            segments: vec![str2seg(\"a\", 0, 1)],\n+                        }),\n                         span: sp(0, 1),\n-                        segments: vec![str2seg(\"a\", 0, 1)],\n-                    }),\n-                    span: sp(0, 1),\n-                    attrs: ThinVec::new(),\n-                   }))\n+                        attrs: ThinVec::new(),\n+                    }))\n+        })\n     }\n \n     #[test] fn path_exprs_2 () {\n-        assert!(string_to_expr(\"::a::b\".to_string()) ==\n-                   P(ast::Expr {\n-                    id: ast::DUMMY_NODE_ID,\n-                    node: ast::ExprKind::Path(None, ast::Path {\n+        with_globals(|| {\n+            assert!(string_to_expr(\"::a::b\".to_string()) ==\n+                    P(ast::Expr {\n+                        id: ast::DUMMY_NODE_ID,\n+                        node: ast::ExprKind::Path(None, ast::Path {\n+                            span: sp(0, 6),\n+                            segments: vec![ast::PathSegment::crate_root(sp(0, 2)),\n+                                        str2seg(\"a\", 2, 3),\n+                                        str2seg(\"b\", 5, 6)]\n+                        }),\n                         span: sp(0, 6),\n-                        segments: vec![ast::PathSegment::crate_root(sp(0, 2)),\n-                                       str2seg(\"a\", 2, 3),\n-                                       str2seg(\"b\", 5, 6)]\n-                    }),\n-                    span: sp(0, 6),\n-                    attrs: ThinVec::new(),\n-                   }))\n+                        attrs: ThinVec::new(),\n+                    }))\n+        })\n     }\n \n     #[should_panic]\n     #[test] fn bad_path_expr_1() {\n-        string_to_expr(\"::abc::def::return\".to_string());\n+        with_globals(|| {\n+            string_to_expr(\"::abc::def::return\".to_string());\n+        })\n     }\n \n     // check the token-tree-ization of macros\n     #[test]\n     fn string_to_tts_macro () {\n-        let tts: Vec<_> =\n-            string_to_stream(\"macro_rules! zip (($a)=>($a))\".to_string()).trees().collect();\n-        let tts: &[TokenTree] = &tts[..];\n-\n-        match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n-            (\n-                4,\n-                Some(&TokenTree::Token(_, token::Ident(name_macro_rules))),\n-                Some(&TokenTree::Token(_, token::Not)),\n-                Some(&TokenTree::Token(_, token::Ident(name_zip))),\n-                Some(&TokenTree::Delimited(_, ref macro_delimed)),\n-            )\n-            if name_macro_rules.name == \"macro_rules\"\n-            && name_zip.name == \"zip\" => {\n-                let tts = &macro_delimed.stream().trees().collect::<Vec<_>>();\n-                match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n-                    (\n-                        3,\n-                        Some(&TokenTree::Delimited(_, ref first_delimed)),\n-                        Some(&TokenTree::Token(_, token::FatArrow)),\n-                        Some(&TokenTree::Delimited(_, ref second_delimed)),\n-                    )\n-                    if macro_delimed.delim == token::Paren => {\n-                        let tts = &first_delimed.stream().trees().collect::<Vec<_>>();\n-                        match (tts.len(), tts.get(0), tts.get(1)) {\n-                            (\n-                                2,\n-                                Some(&TokenTree::Token(_, token::Dollar)),\n-                                Some(&TokenTree::Token(_, token::Ident(ident))),\n-                            )\n-                            if first_delimed.delim == token::Paren && ident.name == \"a\" => {},\n-                            _ => panic!(\"value 3: {:?}\", *first_delimed),\n-                        }\n-                        let tts = &second_delimed.stream().trees().collect::<Vec<_>>();\n-                        match (tts.len(), tts.get(0), tts.get(1)) {\n-                            (\n-                                2,\n-                                Some(&TokenTree::Token(_, token::Dollar)),\n-                                Some(&TokenTree::Token(_, token::Ident(ident))),\n-                            )\n-                            if second_delimed.delim == token::Paren\n-                            && ident.name == \"a\" => {},\n-                            _ => panic!(\"value 4: {:?}\", *second_delimed),\n-                        }\n-                    },\n-                    _ => panic!(\"value 2: {:?}\", *macro_delimed),\n-                }\n-            },\n-            _ => panic!(\"value: {:?}\",tts),\n-        }\n+        with_globals(|| {\n+            let tts: Vec<_> =\n+                string_to_stream(\"macro_rules! zip (($a)=>($a))\".to_string()).trees().collect();\n+            let tts: &[TokenTree] = &tts[..];\n+\n+            match (tts.len(), tts.get(0), tts.get(1), tts.get(2), tts.get(3)) {\n+                (\n+                    4,\n+                    Some(&TokenTree::Token(_, token::Ident(name_macro_rules))),\n+                    Some(&TokenTree::Token(_, token::Not)),\n+                    Some(&TokenTree::Token(_, token::Ident(name_zip))),\n+                    Some(&TokenTree::Delimited(_, ref macro_delimed)),\n+                )\n+                if name_macro_rules.name == \"macro_rules\"\n+                && name_zip.name == \"zip\" => {\n+                    let tts = &macro_delimed.stream().trees().collect::<Vec<_>>();\n+                    match (tts.len(), tts.get(0), tts.get(1), tts.get(2)) {\n+                        (\n+                            3,\n+                            Some(&TokenTree::Delimited(_, ref first_delimed)),\n+                            Some(&TokenTree::Token(_, token::FatArrow)),\n+                            Some(&TokenTree::Delimited(_, ref second_delimed)),\n+                        )\n+                        if macro_delimed.delim == token::Paren => {\n+                            let tts = &first_delimed.stream().trees().collect::<Vec<_>>();\n+                            match (tts.len(), tts.get(0), tts.get(1)) {\n+                                (\n+                                    2,\n+                                    Some(&TokenTree::Token(_, token::Dollar)),\n+                                    Some(&TokenTree::Token(_, token::Ident(ident))),\n+                                )\n+                                if first_delimed.delim == token::Paren && ident.name == \"a\" => {},\n+                                _ => panic!(\"value 3: {:?}\", *first_delimed),\n+                            }\n+                            let tts = &second_delimed.stream().trees().collect::<Vec<_>>();\n+                            match (tts.len(), tts.get(0), tts.get(1)) {\n+                                (\n+                                    2,\n+                                    Some(&TokenTree::Token(_, token::Dollar)),\n+                                    Some(&TokenTree::Token(_, token::Ident(ident))),\n+                                )\n+                                if second_delimed.delim == token::Paren\n+                                && ident.name == \"a\" => {},\n+                                _ => panic!(\"value 4: {:?}\", *second_delimed),\n+                            }\n+                        },\n+                        _ => panic!(\"value 2: {:?}\", *macro_delimed),\n+                    }\n+                },\n+                _ => panic!(\"value: {:?}\",tts),\n+            }\n+        })\n     }\n \n     #[test]\n     fn string_to_tts_1() {\n-        let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n-\n-        let expected = TokenStream::concat(vec![\n-            TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"))).into(),\n-            TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"))).into(),\n-            TokenTree::Delimited(\n-                sp(5, 14),\n-                tokenstream::Delimited {\n-                    delim: token::DelimToken::Paren,\n-                    tts: TokenStream::concat(vec![\n-                        TokenTree::Token(sp(6, 7), token::Ident(Ident::from_str(\"b\"))).into(),\n-                        TokenTree::Token(sp(8, 9), token::Colon).into(),\n-                        TokenTree::Token(sp(10, 13), token::Ident(Ident::from_str(\"i32\"))).into(),\n-                    ]).into(),\n-                }).into(),\n-            TokenTree::Delimited(\n-                sp(15, 21),\n-                tokenstream::Delimited {\n-                    delim: token::DelimToken::Brace,\n-                    tts: TokenStream::concat(vec![\n-                        TokenTree::Token(sp(17, 18), token::Ident(Ident::from_str(\"b\"))).into(),\n-                        TokenTree::Token(sp(18, 19), token::Semi).into(),\n-                    ]).into(),\n-                }).into()\n-        ]);\n-\n-        assert_eq!(tts, expected);\n+        with_globals(|| {\n+            let tts = string_to_stream(\"fn a (b : i32) { b; }\".to_string());\n+\n+            let expected = TokenStream::concat(vec![\n+                TokenTree::Token(sp(0, 2), token::Ident(Ident::from_str(\"fn\"))).into(),\n+                TokenTree::Token(sp(3, 4), token::Ident(Ident::from_str(\"a\"))).into(),\n+                TokenTree::Delimited(\n+                    sp(5, 14),\n+                    tokenstream::Delimited {\n+                        delim: token::DelimToken::Paren,\n+                        tts: TokenStream::concat(vec![\n+                            TokenTree::Token(sp(6, 7), token::Ident(Ident::from_str(\"b\"))).into(),\n+                            TokenTree::Token(sp(8, 9), token::Colon).into(),\n+                            TokenTree::Token(sp(10, 13),\n+                                             token::Ident(Ident::from_str(\"i32\"))).into(),\n+                        ]).into(),\n+                    }).into(),\n+                TokenTree::Delimited(\n+                    sp(15, 21),\n+                    tokenstream::Delimited {\n+                        delim: token::DelimToken::Brace,\n+                        tts: TokenStream::concat(vec![\n+                            TokenTree::Token(sp(17, 18), token::Ident(Ident::from_str(\"b\"))).into(),\n+                            TokenTree::Token(sp(18, 19), token::Semi).into(),\n+                        ]).into(),\n+                    }).into()\n+            ]);\n+\n+            assert_eq!(tts, expected);\n+        })\n     }\n \n     #[test] fn ret_expr() {\n-        assert!(string_to_expr(\"return d\".to_string()) ==\n-                   P(ast::Expr{\n-                    id: ast::DUMMY_NODE_ID,\n-                    node:ast::ExprKind::Ret(Some(P(ast::Expr{\n+        with_globals(|| {\n+            assert!(string_to_expr(\"return d\".to_string()) ==\n+                    P(ast::Expr{\n                         id: ast::DUMMY_NODE_ID,\n-                        node:ast::ExprKind::Path(None, ast::Path{\n-                            span: sp(7, 8),\n-                            segments: vec![str2seg(\"d\", 7, 8)],\n-                        }),\n-                        span:sp(7,8),\n+                        node:ast::ExprKind::Ret(Some(P(ast::Expr{\n+                            id: ast::DUMMY_NODE_ID,\n+                            node:ast::ExprKind::Path(None, ast::Path{\n+                                span: sp(7, 8),\n+                                segments: vec![str2seg(\"d\", 7, 8)],\n+                            }),\n+                            span:sp(7,8),\n+                            attrs: ThinVec::new(),\n+                        }))),\n+                        span:sp(0,8),\n                         attrs: ThinVec::new(),\n-                    }))),\n-                    span:sp(0,8),\n-                    attrs: ThinVec::new(),\n-                   }))\n+                    }))\n+        })\n     }\n \n     #[test] fn parse_stmt_1 () {\n-        assert!(string_to_stmt(\"b;\".to_string()) ==\n-                   Some(ast::Stmt {\n-                       node: ast::StmtKind::Expr(P(ast::Expr {\n-                           id: ast::DUMMY_NODE_ID,\n-                           node: ast::ExprKind::Path(None, ast::Path {\n-                               span:sp(0,1),\n-                               segments: vec![str2seg(\"b\", 0, 1)],\n-                            }),\n-                           span: sp(0,1),\n-                           attrs: ThinVec::new()})),\n-                       id: ast::DUMMY_NODE_ID,\n-                       span: sp(0,1)}))\n-\n+        with_globals(|| {\n+            assert!(string_to_stmt(\"b;\".to_string()) ==\n+                    Some(ast::Stmt {\n+                        node: ast::StmtKind::Expr(P(ast::Expr {\n+                            id: ast::DUMMY_NODE_ID,\n+                            node: ast::ExprKind::Path(None, ast::Path {\n+                                span:sp(0,1),\n+                                segments: vec![str2seg(\"b\", 0, 1)],\n+                                }),\n+                            span: sp(0,1),\n+                            attrs: ThinVec::new()})),\n+                        id: ast::DUMMY_NODE_ID,\n+                        span: sp(0,1)}))\n+        })\n     }\n \n     fn parser_done(p: Parser){\n         assert_eq!(p.token.clone(), token::Eof);\n     }\n \n     #[test] fn parse_ident_pat () {\n-        let sess = ParseSess::new(FilePathMapping::empty());\n-        let mut parser = string_to_parser(&sess, \"b\".to_string());\n-        assert!(panictry!(parser.parse_pat())\n-                == P(ast::Pat{\n-                id: ast::DUMMY_NODE_ID,\n-                node: PatKind::Ident(ast::BindingMode::ByValue(ast::Mutability::Immutable),\n-                                    Spanned{ span:sp(0, 1),\n-                                             node: Ident::from_str(\"b\")\n-                    },\n-                                    None),\n-                span: sp(0,1)}));\n-        parser_done(parser);\n+        with_globals(|| {\n+            let sess = ParseSess::new(FilePathMapping::empty());\n+            let mut parser = string_to_parser(&sess, \"b\".to_string());\n+            assert!(panictry!(parser.parse_pat())\n+                    == P(ast::Pat{\n+                    id: ast::DUMMY_NODE_ID,\n+                    node: PatKind::Ident(ast::BindingMode::ByValue(ast::Mutability::Immutable),\n+                                        Spanned{ span:sp(0, 1),\n+                                                node: Ident::from_str(\"b\")\n+                        },\n+                                        None),\n+                    span: sp(0,1)}));\n+            parser_done(parser);\n+        })\n     }\n \n     // check the contents of the tt manually:\n     #[test] fn parse_fundecl () {\n-        // this test depends on the intern order of \"fn\" and \"i32\"\n-        let item = string_to_item(\"fn a (b : i32) { b; }\".to_string()).map(|m| {\n-            m.map(|mut m| {\n-                m.tokens = None;\n-                m\n-            })\n-        });\n-        assert_eq!(item,\n-                  Some(\n-                      P(ast::Item{ident:Ident::from_str(\"a\"),\n-                            attrs:Vec::new(),\n-                            id: ast::DUMMY_NODE_ID,\n-                            tokens: None,\n-                            node: ast::ItemKind::Fn(P(ast::FnDecl {\n-                                inputs: vec![ast::Arg{\n-                                    ty: P(ast::Ty{id: ast::DUMMY_NODE_ID,\n-                                                  node: ast::TyKind::Path(None, ast::Path{\n-                                        span:sp(10,13),\n-                                        segments: vec![str2seg(\"i32\", 10, 13)],\n+        with_globals(|| {\n+            // this test depends on the intern order of \"fn\" and \"i32\"\n+            let item = string_to_item(\"fn a (b : i32) { b; }\".to_string()).map(|m| {\n+                m.map(|mut m| {\n+                    m.tokens = None;\n+                    m\n+                })\n+            });\n+            assert_eq!(item,\n+                    Some(\n+                        P(ast::Item{ident:Ident::from_str(\"a\"),\n+                                attrs:Vec::new(),\n+                                id: ast::DUMMY_NODE_ID,\n+                                tokens: None,\n+                                node: ast::ItemKind::Fn(P(ast::FnDecl {\n+                                    inputs: vec![ast::Arg{\n+                                        ty: P(ast::Ty{id: ast::DUMMY_NODE_ID,\n+                                                    node: ast::TyKind::Path(None, ast::Path{\n+                                            span:sp(10,13),\n+                                            segments: vec![str2seg(\"i32\", 10, 13)],\n+                                            }),\n+                                            span:sp(10,13)\n                                         }),\n-                                        span:sp(10,13)\n-                                    }),\n-                                    pat: P(ast::Pat {\n-                                        id: ast::DUMMY_NODE_ID,\n-                                        node: PatKind::Ident(\n-                                            ast::BindingMode::ByValue(\n-                                                ast::Mutability::Immutable),\n-                                            Spanned{\n-                                                span: sp(6,7),\n-                                                node: Ident::from_str(\"b\")},\n-                                            None\n-                                        ),\n-                                        span: sp(6,7)\n-                                    }),\n-                                        id: ast::DUMMY_NODE_ID\n-                                    }],\n-                                output: ast::FunctionRetTy::Default(sp(15, 15)),\n-                                variadic: false\n-                            }),\n-                                    ast::Unsafety::Normal,\n-                                    Spanned {\n-                                        span: sp(0,2),\n-                                        node: ast::Constness::NotConst,\n-                                    },\n-                                    Abi::Rust,\n-                                    ast::Generics{\n-                                        params: Vec::new(),\n-                                        where_clause: ast::WhereClause {\n+                                        pat: P(ast::Pat {\n                                             id: ast::DUMMY_NODE_ID,\n-                                            predicates: Vec::new(),\n+                                            node: PatKind::Ident(\n+                                                ast::BindingMode::ByValue(\n+                                                    ast::Mutability::Immutable),\n+                                                Spanned{\n+                                                    span: sp(6,7),\n+                                                    node: Ident::from_str(\"b\")},\n+                                                None\n+                                            ),\n+                                            span: sp(6,7)\n+                                        }),\n+                                            id: ast::DUMMY_NODE_ID\n+                                        }],\n+                                    output: ast::FunctionRetTy::Default(sp(15, 15)),\n+                                    variadic: false\n+                                }),\n+                                        ast::Unsafety::Normal,\n+                                        Spanned {\n+                                            span: sp(0,2),\n+                                            node: ast::Constness::NotConst,\n+                                        },\n+                                        Abi::Rust,\n+                                        ast::Generics{\n+                                            params: Vec::new(),\n+                                            where_clause: ast::WhereClause {\n+                                                id: ast::DUMMY_NODE_ID,\n+                                                predicates: Vec::new(),\n+                                                span: syntax_pos::DUMMY_SP,\n+                                            },\n                                             span: syntax_pos::DUMMY_SP,\n                                         },\n-                                        span: syntax_pos::DUMMY_SP,\n-                                    },\n-                                    P(ast::Block {\n-                                        stmts: vec![ast::Stmt {\n-                                            node: ast::StmtKind::Semi(P(ast::Expr{\n+                                        P(ast::Block {\n+                                            stmts: vec![ast::Stmt {\n+                                                node: ast::StmtKind::Semi(P(ast::Expr{\n+                                                    id: ast::DUMMY_NODE_ID,\n+                                                    node: ast::ExprKind::Path(None,\n+                                                        ast::Path{\n+                                                            span:sp(17,18),\n+                                                            segments: vec![str2seg(\"b\", 17, 18)],\n+                                                        }),\n+                                                    span: sp(17,18),\n+                                                    attrs: ThinVec::new()})),\n                                                 id: ast::DUMMY_NODE_ID,\n-                                                node: ast::ExprKind::Path(None,\n-                                                      ast::Path{\n-                                                        span:sp(17,18),\n-                                                        segments: vec![str2seg(\"b\", 17, 18)],\n-                                                      }),\n-                                                span: sp(17,18),\n-                                                attrs: ThinVec::new()})),\n+                                                span: sp(17,19)}],\n                                             id: ast::DUMMY_NODE_ID,\n-                                            span: sp(17,19)}],\n-                                        id: ast::DUMMY_NODE_ID,\n-                                        rules: ast::BlockCheckMode::Default, // no idea\n-                                        span: sp(15,21),\n-                                        recovered: false,\n-                                    })),\n-                            vis: respan(sp(0, 0), ast::VisibilityKind::Inherited),\n-                            span: sp(0,21)})));\n+                                            rules: ast::BlockCheckMode::Default, // no idea\n+                                            span: sp(15,21),\n+                                            recovered: false,\n+                                        })),\n+                                vis: respan(sp(0, 0), ast::VisibilityKind::Inherited),\n+                                span: sp(0,21)})));\n+        })\n     }\n \n     #[test] fn parse_use() {\n-        let use_s = \"use foo::bar::baz;\";\n-        let vitem = string_to_item(use_s.to_string()).unwrap();\n-        let vitem_s = item_to_string(&vitem);\n-        assert_eq!(&vitem_s[..], use_s);\n-\n-        let use_s = \"use foo::bar as baz;\";\n-        let vitem = string_to_item(use_s.to_string()).unwrap();\n-        let vitem_s = item_to_string(&vitem);\n-        assert_eq!(&vitem_s[..], use_s);\n+        with_globals(|| {\n+            let use_s = \"use foo::bar::baz;\";\n+            let vitem = string_to_item(use_s.to_string()).unwrap();\n+            let vitem_s = item_to_string(&vitem);\n+            assert_eq!(&vitem_s[..], use_s);\n+\n+            let use_s = \"use foo::bar as baz;\";\n+            let vitem = string_to_item(use_s.to_string()).unwrap();\n+            let vitem_s = item_to_string(&vitem);\n+            assert_eq!(&vitem_s[..], use_s);\n+        })\n     }\n \n     #[test] fn parse_extern_crate() {\n-        let ex_s = \"extern crate foo;\";\n-        let vitem = string_to_item(ex_s.to_string()).unwrap();\n-        let vitem_s = item_to_string(&vitem);\n-        assert_eq!(&vitem_s[..], ex_s);\n-\n-        let ex_s = \"extern crate foo as bar;\";\n-        let vitem = string_to_item(ex_s.to_string()).unwrap();\n-        let vitem_s = item_to_string(&vitem);\n-        assert_eq!(&vitem_s[..], ex_s);\n+        with_globals(|| {\n+            let ex_s = \"extern crate foo;\";\n+            let vitem = string_to_item(ex_s.to_string()).unwrap();\n+            let vitem_s = item_to_string(&vitem);\n+            assert_eq!(&vitem_s[..], ex_s);\n+\n+            let ex_s = \"extern crate foo as bar;\";\n+            let vitem = string_to_item(ex_s.to_string()).unwrap();\n+            let vitem_s = item_to_string(&vitem);\n+            assert_eq!(&vitem_s[..], ex_s);\n+        })\n     }\n \n     fn get_spans_of_pat_idents(src: &str) -> Vec<Span> {\n@@ -988,31 +1011,36 @@ mod tests {\n     }\n \n     #[test] fn span_of_self_arg_pat_idents_are_correct() {\n-\n-        let srcs = [\"impl z { fn a (&self, &myarg: i32) {} }\",\n-                    \"impl z { fn a (&mut self, &myarg: i32) {} }\",\n-                    \"impl z { fn a (&'a self, &myarg: i32) {} }\",\n-                    \"impl z { fn a (self, &myarg: i32) {} }\",\n-                    \"impl z { fn a (self: Foo, &myarg: i32) {} }\",\n-                    ];\n-\n-        for &src in &srcs {\n-            let spans = get_spans_of_pat_idents(src);\n-            let (lo, hi) = (spans[0].lo(), spans[0].hi());\n-            assert!(\"self\" == &src[lo.to_usize()..hi.to_usize()],\n-                    \"\\\"{}\\\" != \\\"self\\\". src=\\\"{}\\\"\",\n-                    &src[lo.to_usize()..hi.to_usize()], src)\n-        }\n+        with_globals(|| {\n+\n+            let srcs = [\"impl z { fn a (&self, &myarg: i32) {} }\",\n+                        \"impl z { fn a (&mut self, &myarg: i32) {} }\",\n+                        \"impl z { fn a (&'a self, &myarg: i32) {} }\",\n+                        \"impl z { fn a (self, &myarg: i32) {} }\",\n+                        \"impl z { fn a (self: Foo, &myarg: i32) {} }\",\n+                        ];\n+\n+            for &src in &srcs {\n+                let spans = get_spans_of_pat_idents(src);\n+                let (lo, hi) = (spans[0].lo(), spans[0].hi());\n+                assert!(\"self\" == &src[lo.to_usize()..hi.to_usize()],\n+                        \"\\\"{}\\\" != \\\"self\\\". src=\\\"{}\\\"\",\n+                        &src[lo.to_usize()..hi.to_usize()], src)\n+            }\n+        })\n     }\n \n     #[test] fn parse_exprs () {\n-        // just make sure that they parse....\n-        string_to_expr(\"3 + 4\".to_string());\n-        string_to_expr(\"a::z.froob(b,&(987+3))\".to_string());\n+        with_globals(|| {\n+            // just make sure that they parse....\n+            string_to_expr(\"3 + 4\".to_string());\n+            string_to_expr(\"a::z.froob(b,&(987+3))\".to_string());\n+        })\n     }\n \n     #[test] fn attrs_fix_bug () {\n-        string_to_item(\"pub fn mk_file_writer(path: &Path, flags: &[FileFlag])\n+        with_globals(|| {\n+            string_to_item(\"pub fn mk_file_writer(path: &Path, flags: &[FileFlag])\n                    -> Result<Box<Writer>, String> {\n     #[cfg(windows)]\n     fn wb() -> c_int {\n@@ -1024,67 +1052,74 @@ mod tests {\n \n     let mut fflags: c_int = wb();\n }\".to_string());\n+        })\n     }\n \n     #[test] fn crlf_doc_comments() {\n-        let sess = ParseSess::new(FilePathMapping::empty());\n-\n-        let name = FileName::Custom(\"source\".to_string());\n-        let source = \"/// doc comment\\r\\nfn foo() {}\".to_string();\n-        let item = parse_item_from_source_str(name.clone(), source, &sess)\n-            .unwrap().unwrap();\n-        let doc = first_attr_value_str_by_name(&item.attrs, \"doc\").unwrap();\n-        assert_eq!(doc, \"/// doc comment\");\n-\n-        let source = \"/// doc comment\\r\\n/// line 2\\r\\nfn foo() {}\".to_string();\n-        let item = parse_item_from_source_str(name.clone(), source, &sess)\n-            .unwrap().unwrap();\n-        let docs = item.attrs.iter().filter(|a| a.path == \"doc\")\n-                    .map(|a| a.value_str().unwrap().to_string()).collect::<Vec<_>>();\n-        let b: &[_] = &[\"/// doc comment\".to_string(), \"/// line 2\".to_string()];\n-        assert_eq!(&docs[..], b);\n-\n-        let source = \"/** doc comment\\r\\n *  with CRLF */\\r\\nfn foo() {}\".to_string();\n-        let item = parse_item_from_source_str(name, source, &sess).unwrap().unwrap();\n-        let doc = first_attr_value_str_by_name(&item.attrs, \"doc\").unwrap();\n-        assert_eq!(doc, \"/** doc comment\\n *  with CRLF */\");\n+        with_globals(|| {\n+            let sess = ParseSess::new(FilePathMapping::empty());\n+\n+            let name = FileName::Custom(\"source\".to_string());\n+            let source = \"/// doc comment\\r\\nfn foo() {}\".to_string();\n+            let item = parse_item_from_source_str(name.clone(), source, &sess)\n+                .unwrap().unwrap();\n+            let doc = first_attr_value_str_by_name(&item.attrs, \"doc\").unwrap();\n+            assert_eq!(doc, \"/// doc comment\");\n+\n+            let source = \"/// doc comment\\r\\n/// line 2\\r\\nfn foo() {}\".to_string();\n+            let item = parse_item_from_source_str(name.clone(), source, &sess)\n+                .unwrap().unwrap();\n+            let docs = item.attrs.iter().filter(|a| a.path == \"doc\")\n+                        .map(|a| a.value_str().unwrap().to_string()).collect::<Vec<_>>();\n+            let b: &[_] = &[\"/// doc comment\".to_string(), \"/// line 2\".to_string()];\n+            assert_eq!(&docs[..], b);\n+\n+            let source = \"/** doc comment\\r\\n *  with CRLF */\\r\\nfn foo() {}\".to_string();\n+            let item = parse_item_from_source_str(name, source, &sess).unwrap().unwrap();\n+            let doc = first_attr_value_str_by_name(&item.attrs, \"doc\").unwrap();\n+            assert_eq!(doc, \"/** doc comment\\n *  with CRLF */\");\n+        });\n     }\n \n     #[test]\n     fn ttdelim_span() {\n-        let sess = ParseSess::new(FilePathMapping::empty());\n-        let expr = parse::parse_expr_from_source_str(PathBuf::from(\"foo\").into(),\n-            \"foo!( fn main() { body } )\".to_string(), &sess).unwrap();\n-\n-        let tts: Vec<_> = match expr.node {\n-            ast::ExprKind::Mac(ref mac) => mac.node.stream().trees().collect(),\n-            _ => panic!(\"not a macro\"),\n-        };\n+        with_globals(|| {\n+            let sess = ParseSess::new(FilePathMapping::empty());\n+            let expr = parse::parse_expr_from_source_str(PathBuf::from(\"foo\").into(),\n+                \"foo!( fn main() { body } )\".to_string(), &sess).unwrap();\n+\n+            let tts: Vec<_> = match expr.node {\n+                ast::ExprKind::Mac(ref mac) => mac.node.stream().trees().collect(),\n+                _ => panic!(\"not a macro\"),\n+            };\n \n-        let span = tts.iter().rev().next().unwrap().span();\n+            let span = tts.iter().rev().next().unwrap().span();\n \n-        match sess.codemap().span_to_snippet(span) {\n-            Ok(s) => assert_eq!(&s[..], \"{ body }\"),\n-            Err(_) => panic!(\"could not get snippet\"),\n-        }\n+            match sess.codemap().span_to_snippet(span) {\n+                Ok(s) => assert_eq!(&s[..], \"{ body }\"),\n+                Err(_) => panic!(\"could not get snippet\"),\n+            }\n+        });\n     }\n \n     // This tests that when parsing a string (rather than a file) we don't try\n     // and read in a file for a module declaration and just parse a stub.\n     // See `recurse_into_file_modules` in the parser.\n     #[test]\n     fn out_of_line_mod() {\n-        let sess = ParseSess::new(FilePathMapping::empty());\n-        let item = parse_item_from_source_str(\n-            PathBuf::from(\"foo\").into(),\n-            \"mod foo { struct S; mod this_does_not_exist; }\".to_owned(),\n-            &sess,\n-        ).unwrap().unwrap();\n-\n-        if let ast::ItemKind::Mod(ref m) = item.node {\n-            assert!(m.items.len() == 2);\n-        } else {\n-            panic!();\n-        }\n+        with_globals(|| {\n+            let sess = ParseSess::new(FilePathMapping::empty());\n+            let item = parse_item_from_source_str(\n+                PathBuf::from(\"foo\").into(),\n+                \"mod foo { struct S; mod this_does_not_exist; }\".to_owned(),\n+                &sess,\n+            ).unwrap().unwrap();\n+\n+            if let ast::ItemKind::Mod(ref m) = item.node {\n+                assert!(m.items.len() == 2);\n+            } else {\n+                panic!();\n+            }\n+        });\n     }\n }"}, {"sha": "1cf2b7a44bc1728e026d83e6a868f4ed7a9537e0", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 28, "deletions": 23, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -3178,36 +3178,41 @@ mod tests {\n     use ast;\n     use codemap;\n     use syntax_pos;\n+    use with_globals;\n \n     #[test]\n     fn test_fun_to_string() {\n-        let abba_ident = ast::Ident::from_str(\"abba\");\n+        with_globals(|| {\n+            let abba_ident = ast::Ident::from_str(\"abba\");\n \n-        let decl = ast::FnDecl {\n-            inputs: Vec::new(),\n-            output: ast::FunctionRetTy::Default(syntax_pos::DUMMY_SP),\n-            variadic: false\n-        };\n-        let generics = ast::Generics::default();\n-        assert_eq!(fun_to_string(&decl, ast::Unsafety::Normal,\n-                                 ast::Constness::NotConst,\n-                                 abba_ident, &generics),\n-                   \"fn abba()\");\n+            let decl = ast::FnDecl {\n+                inputs: Vec::new(),\n+                output: ast::FunctionRetTy::Default(syntax_pos::DUMMY_SP),\n+                variadic: false\n+            };\n+            let generics = ast::Generics::default();\n+            assert_eq!(fun_to_string(&decl, ast::Unsafety::Normal,\n+                                    ast::Constness::NotConst,\n+                                    abba_ident, &generics),\n+                    \"fn abba()\");\n+        })\n     }\n \n     #[test]\n     fn test_variant_to_string() {\n-        let ident = ast::Ident::from_str(\"principal_skinner\");\n-\n-        let var = codemap::respan(syntax_pos::DUMMY_SP, ast::Variant_ {\n-            name: ident,\n-            attrs: Vec::new(),\n-            // making this up as I go.... ?\n-            data: ast::VariantData::Unit(ast::DUMMY_NODE_ID),\n-            disr_expr: None,\n-        });\n-\n-        let varstr = variant_to_string(&var);\n-        assert_eq!(varstr, \"principal_skinner\");\n+        with_globals(|| {\n+            let ident = ast::Ident::from_str(\"principal_skinner\");\n+\n+            let var = codemap::respan(syntax_pos::DUMMY_SP, ast::Variant_ {\n+                name: ident,\n+                attrs: Vec::new(),\n+                // making this up as I go.... ?\n+                data: ast::VariantData::Unit(ast::DUMMY_NODE_ID),\n+                disr_expr: None,\n+            });\n+\n+            let varstr = variant_to_string(&var);\n+            assert_eq!(varstr, \"principal_skinner\");\n+        })\n     }\n }"}, {"sha": "81dcc1998edd1c7a6b43b7fb0d7011fae9a77d0c", "filename": "src/libsyntax/test_snippet.rs", "status": "modified", "additions": 28, "deletions": 25, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ftest_snippet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ftest_snippet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftest_snippet.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -18,6 +18,7 @@ use std::str;\n use std::sync::{Arc, Mutex};\n use std::path::Path;\n use syntax_pos::{BytePos, NO_EXPANSION, Span, MultiSpan};\n+use with_globals;\n \n /// Identify a position in the text by the Nth occurrence of a string.\n struct Position {\n@@ -46,37 +47,39 @@ impl<T: Write> Write for Shared<T> {\n }\n \n fn test_harness(file_text: &str, span_labels: Vec<SpanLabel>, expected_output: &str) {\n-    let output = Arc::new(Mutex::new(Vec::new()));\n+    with_globals(|| {\n+        let output = Arc::new(Mutex::new(Vec::new()));\n \n-    let code_map = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n-    code_map.new_filemap_and_lines(Path::new(\"test.rs\"), &file_text);\n+        let code_map = Lrc::new(CodeMap::new(FilePathMapping::empty()));\n+        code_map.new_filemap_and_lines(Path::new(\"test.rs\"), &file_text);\n \n-    let primary_span = make_span(&file_text, &span_labels[0].start, &span_labels[0].end);\n-    let mut msp = MultiSpan::from_span(primary_span);\n-    for span_label in span_labels {\n-        let span = make_span(&file_text, &span_label.start, &span_label.end);\n-        msp.push_span_label(span, span_label.label.to_string());\n-        println!(\"span: {:?} label: {:?}\", span, span_label.label);\n-        println!(\"text: {:?}\", code_map.span_to_snippet(span));\n-    }\n+        let primary_span = make_span(&file_text, &span_labels[0].start, &span_labels[0].end);\n+        let mut msp = MultiSpan::from_span(primary_span);\n+        for span_label in span_labels {\n+            let span = make_span(&file_text, &span_label.start, &span_label.end);\n+            msp.push_span_label(span, span_label.label.to_string());\n+            println!(\"span: {:?} label: {:?}\", span, span_label.label);\n+            println!(\"text: {:?}\", code_map.span_to_snippet(span));\n+        }\n \n-    let emitter = EmitterWriter::new(Box::new(Shared { data: output.clone() }),\n-                                     Some(code_map.clone()),\n-                                     false,\n-                                     false);\n-    let handler = Handler::with_emitter(true, false, Box::new(emitter));\n-    handler.span_err(msp, \"foo\");\n+        let emitter = EmitterWriter::new(Box::new(Shared { data: output.clone() }),\n+                                        Some(code_map.clone()),\n+                                        false,\n+                                        false);\n+        let handler = Handler::with_emitter(true, false, Box::new(emitter));\n+        handler.span_err(msp, \"foo\");\n \n-    assert!(expected_output.chars().next() == Some('\\n'),\n-            \"expected output should begin with newline\");\n-    let expected_output = &expected_output[1..];\n+        assert!(expected_output.chars().next() == Some('\\n'),\n+                \"expected output should begin with newline\");\n+        let expected_output = &expected_output[1..];\n \n-    let bytes = output.lock().unwrap();\n-    let actual_output = str::from_utf8(&bytes).unwrap();\n-    println!(\"expected output:\\n------\\n{}------\", expected_output);\n-    println!(\"actual output:\\n------\\n{}------\", actual_output);\n+        let bytes = output.lock().unwrap();\n+        let actual_output = str::from_utf8(&bytes).unwrap();\n+        println!(\"expected output:\\n------\\n{}------\", expected_output);\n+        println!(\"actual output:\\n------\\n{}------\", actual_output);\n \n-    assert!(expected_output == actual_output)\n+        assert!(expected_output == actual_output)\n+    })\n }\n \n fn make_span(file_text: &str, start: &Position, end: &Position) -> Span {"}, {"sha": "1219e909e121a6b405a7a01c0ac910eff69b3c2c", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 50, "deletions": 33, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -599,6 +599,7 @@ impl Hash for ThinTokenStream {\n mod tests {\n     use super::*;\n     use syntax::ast::Ident;\n+    use with_globals;\n     use syntax_pos::{Span, BytePos, NO_EXPANSION};\n     use parse::token::Token;\n     use util::parser_testing::string_to_stream;\n@@ -613,67 +614,83 @@ mod tests {\n \n     #[test]\n     fn test_concat() {\n-        let test_res = string_to_ts(\"foo::bar::baz\");\n-        let test_fst = string_to_ts(\"foo::bar\");\n-        let test_snd = string_to_ts(\"::baz\");\n-        let eq_res = TokenStream::concat(vec![test_fst, test_snd]);\n-        assert_eq!(test_res.trees().count(), 5);\n-        assert_eq!(eq_res.trees().count(), 5);\n-        assert_eq!(test_res.eq_unspanned(&eq_res), true);\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"foo::bar::baz\");\n+            let test_fst = string_to_ts(\"foo::bar\");\n+            let test_snd = string_to_ts(\"::baz\");\n+            let eq_res = TokenStream::concat(vec![test_fst, test_snd]);\n+            assert_eq!(test_res.trees().count(), 5);\n+            assert_eq!(eq_res.trees().count(), 5);\n+            assert_eq!(test_res.eq_unspanned(&eq_res), true);\n+        })\n     }\n \n     #[test]\n     fn test_to_from_bijection() {\n-        let test_start = string_to_ts(\"foo::bar(baz)\");\n-        let test_end = test_start.trees().collect();\n-        assert_eq!(test_start, test_end)\n+        with_globals(|| {\n+            let test_start = string_to_ts(\"foo::bar(baz)\");\n+            let test_end = test_start.trees().collect();\n+            assert_eq!(test_start, test_end)\n+        })\n     }\n \n     #[test]\n     fn test_eq_0() {\n-        let test_res = string_to_ts(\"foo\");\n-        let test_eqs = string_to_ts(\"foo\");\n-        assert_eq!(test_res, test_eqs)\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"foo\");\n+            let test_eqs = string_to_ts(\"foo\");\n+            assert_eq!(test_res, test_eqs)\n+        })\n     }\n \n     #[test]\n     fn test_eq_1() {\n-        let test_res = string_to_ts(\"::bar::baz\");\n-        let test_eqs = string_to_ts(\"::bar::baz\");\n-        assert_eq!(test_res, test_eqs)\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"::bar::baz\");\n+            let test_eqs = string_to_ts(\"::bar::baz\");\n+            assert_eq!(test_res, test_eqs)\n+        })\n     }\n \n     #[test]\n     fn test_eq_3() {\n-        let test_res = string_to_ts(\"\");\n-        let test_eqs = string_to_ts(\"\");\n-        assert_eq!(test_res, test_eqs)\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"\");\n+            let test_eqs = string_to_ts(\"\");\n+            assert_eq!(test_res, test_eqs)\n+        })\n     }\n \n     #[test]\n     fn test_diseq_0() {\n-        let test_res = string_to_ts(\"::bar::baz\");\n-        let test_eqs = string_to_ts(\"bar::baz\");\n-        assert_eq!(test_res == test_eqs, false)\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"::bar::baz\");\n+            let test_eqs = string_to_ts(\"bar::baz\");\n+            assert_eq!(test_res == test_eqs, false)\n+        })\n     }\n \n     #[test]\n     fn test_diseq_1() {\n-        let test_res = string_to_ts(\"(bar,baz)\");\n-        let test_eqs = string_to_ts(\"bar,baz\");\n-        assert_eq!(test_res == test_eqs, false)\n+        with_globals(|| {\n+            let test_res = string_to_ts(\"(bar,baz)\");\n+            let test_eqs = string_to_ts(\"bar,baz\");\n+            assert_eq!(test_res == test_eqs, false)\n+        })\n     }\n \n     #[test]\n     fn test_is_empty() {\n-        let test0: TokenStream = Vec::<TokenTree>::new().into_iter().collect();\n-        let test1: TokenStream =\n-            TokenTree::Token(sp(0, 1), Token::Ident(Ident::from_str(\"a\"))).into();\n-        let test2 = string_to_ts(\"foo(bar::baz)\");\n-\n-        assert_eq!(test0.is_empty(), true);\n-        assert_eq!(test1.is_empty(), false);\n-        assert_eq!(test2.is_empty(), false);\n+        with_globals(|| {\n+            let test0: TokenStream = Vec::<TokenTree>::new().into_iter().collect();\n+            let test1: TokenStream =\n+                TokenTree::Token(sp(0, 1), Token::Ident(Ident::from_str(\"a\"))).into();\n+            let test2 = string_to_ts(\"foo(bar::baz)\");\n+\n+            assert_eq!(test0.is_empty(), true);\n+            assert_eq!(test1.is_empty(), false);\n+            assert_eq!(test2.is_empty(), false);\n+        })\n     }\n \n     #[test]"}, {"sha": "b9637b1855ef08760a3ed96b6afdedd1aae4ecb5", "filename": "src/libsyntax_pos/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2FCargo.toml?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -11,4 +11,5 @@ crate-type = [\"dylib\"]\n [dependencies]\n serialize = { path = \"../libserialize\" }\n rustc_data_structures = { path = \"../librustc_data_structures\" }\n+scoped-tls = { version = \"0.1.1\", features = [\"nightly\"] }\n unicode-width = \"0.1.4\""}, {"sha": "85a2940ec442e0c80658ed1ffaa6bece9bf8a82c", "filename": "src/libsyntax_pos/hygiene.rs", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fhygiene.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -15,11 +15,11 @@\n //! and definition contexts*. J. Funct. Program. 22, 2 (March 2012), 181-216.\n //! DOI=10.1017/S0956796812000093 <http://dx.doi.org/10.1017/S0956796812000093>\n \n+use GLOBALS;\n use Span;\n use symbol::{Ident, Symbol};\n \n use serialize::{Encodable, Decodable, Encoder, Decoder};\n-use std::cell::RefCell;\n use std::collections::HashMap;\n use std::fmt;\n \n@@ -119,15 +119,15 @@ impl Mark {\n     }\n }\n \n-struct HygieneData {\n+pub struct HygieneData {\n     marks: Vec<MarkData>,\n     syntax_contexts: Vec<SyntaxContextData>,\n     markings: HashMap<(SyntaxContext, Mark), SyntaxContext>,\n     gensym_to_ctxt: HashMap<Symbol, SyntaxContext>,\n }\n \n impl HygieneData {\n-    fn new() -> Self {\n+    pub fn new() -> Self {\n         HygieneData {\n             marks: vec![MarkData {\n                 parent: Mark::root(),\n@@ -145,10 +145,7 @@ impl HygieneData {\n     }\n \n     fn with<T, F: FnOnce(&mut HygieneData) -> T>(f: F) -> T {\n-        thread_local! {\n-            static HYGIENE_DATA: RefCell<HygieneData> = RefCell::new(HygieneData::new());\n-        }\n-        HYGIENE_DATA.with(|data| f(&mut *data.borrow_mut()))\n+        GLOBALS.with(|globals| f(&mut *globals.hygiene_data.borrow_mut()))\n     }\n }\n "}, {"sha": "bec46ff3d797c6c82b2f1e7a570d9638ea337941", "filename": "src/libsyntax_pos/lib.rs", "status": "modified", "additions": 22, "deletions": 1, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Flib.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -35,10 +35,13 @@ use std::ops::{Add, Sub};\n use std::path::PathBuf;\n \n use rustc_data_structures::stable_hasher::StableHasher;\n-use rustc_data_structures::sync::Lrc;\n+use rustc_data_structures::sync::{Lrc, Lock};\n \n extern crate rustc_data_structures;\n \n+#[macro_use]\n+extern crate scoped_tls;\n+\n use serialize::{Encodable, Decodable, Encoder, Decoder};\n \n extern crate serialize;\n@@ -54,6 +57,24 @@ pub use span_encoding::{Span, DUMMY_SP};\n \n pub mod symbol;\n \n+pub struct Globals {\n+    symbol_interner: Lock<symbol::Interner>,\n+    span_interner: Lock<span_encoding::SpanInterner>,\n+    hygiene_data: Lock<hygiene::HygieneData>,\n+}\n+\n+impl Globals {\n+    pub fn new() -> Globals {\n+        Globals {\n+            symbol_interner: Lock::new(symbol::Interner::fresh()),\n+            span_interner: Lock::new(span_encoding::SpanInterner::default()),\n+            hygiene_data: Lock::new(hygiene::HygieneData::new()),\n+        }\n+    }\n+}\n+\n+scoped_thread_local!(pub static GLOBALS: Globals);\n+\n /// Differentiates between real files and common virtual files\n #[derive(Debug, Eq, PartialEq, Clone, Ord, PartialOrd, Hash, RustcDecodable, RustcEncodable)]\n pub enum FileName {"}, {"sha": "b55fe4bcb26721ad8f913adbb441a9ade7294cc1", "filename": "src/libsyntax_pos/span_encoding.rs", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fspan_encoding.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fspan_encoding.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fspan_encoding.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -14,11 +14,11 @@\n // The encoding format for inline spans were obtained by optimizing over crates in rustc/libstd.\n // See https://internals.rust-lang.org/t/rfc-compiler-refactoring-spans/1357/28\n \n+use GLOBALS;\n use {BytePos, SpanData};\n use hygiene::SyntaxContext;\n \n use rustc_data_structures::fx::FxHashMap;\n-use std::cell::RefCell;\n use std::hash::{Hash, Hasher};\n \n /// A compressed span.\n@@ -133,7 +133,7 @@ fn decode(span: Span) -> SpanData {\n }\n \n #[derive(Default)]\n-struct SpanInterner {\n+pub struct SpanInterner {\n     spans: FxHashMap<SpanData, u32>,\n     span_data: Vec<SpanData>,\n }\n@@ -156,11 +156,8 @@ impl SpanInterner {\n     }\n }\n \n-// If an interner exists in TLS, return it. Otherwise, prepare a fresh one.\n+// If an interner exists, return it. Otherwise, prepare a fresh one.\n #[inline]\n fn with_span_interner<T, F: FnOnce(&mut SpanInterner) -> T>(f: F) -> T {\n-    thread_local!(static INTERNER: RefCell<SpanInterner> = {\n-        RefCell::new(SpanInterner::default())\n-    });\n-    INTERNER.with(|interner| f(&mut *interner.borrow_mut()))\n+    GLOBALS.with(|globals| f(&mut *globals.span_interner.lock()))\n }"}, {"sha": "e95079f7c88dd412db2455fa1a0bbe4b81bdd398", "filename": "src/libsyntax_pos/symbol.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fsymbol.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Flibsyntax_pos%2Fsymbol.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_pos%2Fsymbol.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -13,9 +13,9 @@\n //! type, and vice versa.\n \n use hygiene::SyntaxContext;\n+use GLOBALS;\n \n use serialize::{Decodable, Decoder, Encodable, Encoder};\n-use std::cell::RefCell;\n use std::collections::HashMap;\n use std::fmt;\n \n@@ -247,7 +247,7 @@ macro_rules! declare_keywords {(\n     }\n \n     impl Interner {\n-        fn fresh() -> Self {\n+        pub fn fresh() -> Self {\n             Interner::prefill(&[$($string,)*])\n         }\n     }\n@@ -330,12 +330,10 @@ declare_keywords! {\n     (60, Union,          \"union\")\n }\n \n-// If an interner exists in TLS, return it. Otherwise, prepare a fresh one.\n+// If an interner exists, return it. Otherwise, prepare a fresh one.\n+#[inline]\n fn with_interner<T, F: FnOnce(&mut Interner) -> T>(f: F) -> T {\n-    thread_local!(static INTERNER: RefCell<Interner> = {\n-        RefCell::new(Interner::fresh())\n-    });\n-    INTERNER.with(|interner| f(&mut *interner.borrow_mut()))\n+    GLOBALS.with(|globals| f(&mut *globals.symbol_interner.lock()))\n }\n \n /// Represents a string stored in the thread-local interner. Because the\n@@ -422,6 +420,7 @@ impl Encodable for InternedString {\n #[cfg(test)]\n mod tests {\n     use super::*;\n+    use Globals;\n \n     #[test]\n     fn interner_tests() {\n@@ -444,7 +443,9 @@ mod tests {\n \n     #[test]\n     fn without_first_quote_test() {\n-        let i = Ident::from_str(\"'break\");\n-        assert_eq!(i.without_first_quote().name, keywords::Break.name());\n+        GLOBALS.set(&Globals::new(), || {\n+            let i = Ident::from_str(\"'break\");\n+            assert_eq!(i.without_first_quote().name, keywords::Break.name());\n+        });\n     }\n }"}, {"sha": "c8c80b7759c99819eda7b4f51903408187988591", "filename": "src/test/run-fail-fulldeps/qquote.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-fail-fulldeps%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-fail-fulldeps%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-fail-fulldeps%2Fqquote.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -24,6 +24,10 @@ use syntax::symbol::Symbol;\n use syntax_pos::DUMMY_SP;\n \n fn main() {\n+    syntax::with_globals(|| run());\n+}\n+\n+fn run() {\n     let ps = syntax::parse::ParseSess::new(codemap::FilePathMapping::empty());\n     let mut resolver = syntax::ext::base::DummyResolver;\n     let mut cx = syntax::ext::base::ExtCtxt::new("}, {"sha": "e0db2627d853acfdbb874f27786a92ea314be7b6", "filename": "src/test/run-make/issue-19371/foo.rs", "status": "modified", "additions": 16, "deletions": 14, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-make%2Fissue-19371%2Ffoo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-make%2Fissue-19371%2Ffoo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-make%2Fissue-19371%2Ffoo.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -69,18 +69,20 @@ fn basic_sess(sysroot: PathBuf) -> (Session, Rc<CStore>, Box<TransCrate>) {\n }\n \n fn compile(code: String, output: PathBuf, sysroot: PathBuf) {\n-    let (sess, cstore, trans) = basic_sess(sysroot);\n-    let control = CompileController::basic();\n-    let input = Input::Str { name: FileName::Anon, input: code };\n-    let _ = compile_input(\n-        trans,\n-        &sess,\n-        &cstore,\n-        &None,\n-        &input,\n-        &None,\n-        &Some(output),\n-        None,\n-        &control\n-    );\n+    syntax::with_globals(|| {\n+        let (sess, cstore, trans) = basic_sess(sysroot);\n+        let control = CompileController::basic();\n+        let input = Input::Str { name: FileName::Anon, input: code };\n+        let _ = compile_input(\n+            trans,\n+            &sess,\n+            &cstore,\n+            &None,\n+            &input,\n+            &None,\n+            &Some(output),\n+            None,\n+            &control\n+        );\n+    });\n }"}, {"sha": "f3f7777d8d40427fd8d6f1d5b46ad415e96714a6", "filename": "src/test/run-pass-fulldeps/ast_stmt_expr_attr.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fast_stmt_expr_attr.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -115,6 +115,10 @@ fn reject_stmt_parse(es: &str) {\n }\n \n fn main() {\n+    syntax::with_globals(|| run());\n+}\n+\n+fn run() {\n     let both = &[\"#[attr]\", \"#![attr]\"];\n     let outer = &[\"#[attr]\"];\n     let none = &[];"}, {"sha": "c420243325038935751310fe5866dda7f12d6abe", "filename": "src/test/run-pass-fulldeps/issue-35829.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fissue-35829.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fissue-35829.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fissue-35829.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -27,6 +27,10 @@ use syntax::ptr::P;\n use rustc_data_structures::sync::Lrc;\n \n fn main() {\n+    syntax::with_globals(|| run());\n+}\n+\n+fn run() {\n     let parse_sess = ParseSess::new(FilePathMapping::empty());\n     let exp_cfg = ExpansionConfig::default(\"issue_35829\".to_owned());\n     let mut resolver = DummyResolver;"}, {"sha": "05fe274c49f35166fd13539106ca79348fef2a96", "filename": "src/test/run-pass-fulldeps/pprust-expr-roundtrip.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fpprust-expr-roundtrip.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fpprust-expr-roundtrip.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fpprust-expr-roundtrip.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -221,8 +221,11 @@ impl Folder for AddParens {\n     }\n }\n \n-\n fn main() {\n+    syntax::with_globals(|| run());\n+}\n+\n+fn run() {\n     let ps = ParseSess::new(FilePathMapping::empty());\n \n     iter_exprs(2, &mut |e| {"}, {"sha": "c597360c0426fb38f5eb5f973aea8fbae2c43e22", "filename": "src/test/run-pass-fulldeps/qquote.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fqquote.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -21,6 +21,10 @@ use syntax::symbol::Symbol;\n use syntax_pos::DUMMY_SP;\n \n fn main() {\n+    syntax::with_globals(|| run());\n+}\n+\n+fn run() {\n     let ps = syntax::parse::ParseSess::new(FilePathMapping::empty());\n     let mut resolver = syntax::ext::base::DummyResolver;\n     let mut cx = syntax::ext::base::ExtCtxt::new("}, {"sha": "cdeb60156725623ab4c746aed1b96aacfb857212", "filename": "src/tools/error_index_generator/main.rs", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftools%2Ferror_index_generator%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftools%2Ferror_index_generator%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ferror_index_generator%2Fmain.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -263,7 +263,10 @@ fn main() {\n         *slot.borrow_mut() = Some((None, String::from(\"https://play.rust-lang.org/\")));\n     });\n     let (format, dst) = parse_args();\n-    if let Err(e) = main_with_result(format, &dst) {\n+    let result = syntax::with_globals(move || {\n+        main_with_result(format, &dst)\n+    });\n+    if let Err(e) = result {\n         panic!(\"{}\", e.description());\n     }\n }"}, {"sha": "63f40110225ecb7c796d0ba833bf436e40ed3e13", "filename": "src/tools/tidy/src/deps.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d089fe974edc53fa34384e8e76eeb1eca0d89042/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Fdeps.rs?ref=d089fe974edc53fa34384e8e76eeb1eca0d89042", "patch": "@@ -93,6 +93,7 @@ static WHITELIST: &'static [Crate] = &[\n     Crate(\"regex-syntax\"),\n     Crate(\"remove_dir_all\"),\n     Crate(\"rustc-demangle\"),\n+    Crate(\"scoped-tls\"),\n     Crate(\"smallvec\"),\n     Crate(\"stable_deref_trait\"),\n     Crate(\"tempdir\"),"}]}