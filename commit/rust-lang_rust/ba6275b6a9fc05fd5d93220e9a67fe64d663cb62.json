{"sha": "ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "node_id": "MDY6Q29tbWl0NzI0NzEyOmJhNjI3NWI2YTlmYzA1ZmQ1ZDkzMjIwZTlhNjdmZTY0ZDY2M2NiNjI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-04-11T07:36:33Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2021-04-11T07:36:33Z"}, "message": "Auto merge of #82608 - Aaron1011:feature/final-preexp-tts, r=petrochenkov\n\nImplement token-based handling of attributes during expansion\n\nThis PR modifies the macro expansion infrastructure to handle attributes\nin a fully token-based manner. As a result:\n\n* Derives macros no longer lose spans when their input is modified\n  by eager cfg-expansion. This is accomplished by performing eager\n  cfg-expansion on the token stream that we pass to the derive\n  proc-macro\n* Inner attributes now preserve spans in all cases, including when we\n  have multiple inner attributes in a row.\n\nThis is accomplished through the following changes:\n\n* New structs `AttrAnnotatedTokenStream` and `AttrAnnotatedTokenTree` are introduced.\n  These are very similar to a normal `TokenTree`, but they also track\n  the position of attributes and attribute targets within the stream.\n  They are built when we collect tokens during parsing.\n  An `AttrAnnotatedTokenStream` is converted to a regular `TokenStream` when\n  we invoke a macro.\n* Token capturing and `LazyTokenStream` are modified to work with\n  `AttrAnnotatedTokenStream`. A new `ReplaceRange` type is introduced, which\n  is created during the parsing of a nested AST node to make the 'outer'\n  AST node aware of the attributes and attribute target stored deeper in the token stream.\n* When we need to perform eager cfg-expansion (either due to `#[derive]` or `#[cfg_eval]`), we tokenize and reparse our target, capturing additional information about the locations of `#[cfg]` and `#[cfg_attr]` attributes at any depth within the target. This is a performance optimization, allowing us to perform less work in the typical case where captured tokens never have eager cfg-expansion run.", "tree": {"sha": "2c6fa2b3968f6fccbf8e44a70a873edeb4124946", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/2c6fa2b3968f6fccbf8e44a70a873edeb4124946"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "html_url": "https://github.com/rust-lang/rust/commit/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "28b948fc5c0163b76c69d792b91a0e83850e7e54", "url": "https://api.github.com/repos/rust-lang/rust/commits/28b948fc5c0163b76c69d792b91a0e83850e7e54", "html_url": "https://github.com/rust-lang/rust/commit/28b948fc5c0163b76c69d792b91a0e83850e7e54"}, {"sha": "a93c4f05de5c5cdd8158e23de7c3cf86a548447f", "url": "https://api.github.com/repos/rust-lang/rust/commits/a93c4f05de5c5cdd8158e23de7c3cf86a548447f", "html_url": "https://github.com/rust-lang/rust/commit/a93c4f05de5c5cdd8158e23de7c3cf86a548447f"}], "stats": {"total": 3228, "additions": 2041, "deletions": 1187}, "files": [{"sha": "945a44ab66371ccbae0b8e3cec39975ae5168396", "filename": "compiler/rustc_ast/src/ast_like.rs", "status": "modified", "additions": 95, "deletions": 7, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fast_like.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,20 +1,32 @@\n use super::ptr::P;\n+use super::token::Nonterminal;\n use super::tokenstream::LazyTokenStream;\n use super::{Arm, ExprField, FieldDef, GenericParam, Param, PatField, Variant};\n-use super::{AssocItem, Expr, ForeignItem, Item, Local};\n+use super::{AssocItem, Expr, ForeignItem, Item, Local, MacCallStmt};\n use super::{AttrItem, AttrKind, Block, Pat, Path, Ty, Visibility};\n use super::{AttrVec, Attribute, Stmt, StmtKind};\n \n+use std::fmt::Debug;\n+\n /// An `AstLike` represents an AST node (or some wrapper around\n /// and AST node) which stores some combination of attributes\n /// and tokens.\n-pub trait AstLike: Sized {\n+pub trait AstLike: Sized + Debug {\n+    /// This is `true` if this `AstLike` might support 'custom' (proc-macro) inner\n+    /// attributes. Attributes like `#![cfg]` and `#![cfg_attr]` are not\n+    /// considered 'custom' attributes\n+    ///\n+    /// If this is `false`, then this `AstLike` definitely does\n+    /// not support 'custom' inner attributes, which enables some optimizations\n+    /// during token collection.\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool;\n     fn attrs(&self) -> &[Attribute];\n     fn visit_attrs(&mut self, f: impl FnOnce(&mut Vec<Attribute>));\n     fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>>;\n }\n \n impl<T: AstLike + 'static> AstLike for P<T> {\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = T::SUPPORTS_CUSTOM_INNER_ATTRS;\n     fn attrs(&self) -> &[Attribute] {\n         (**self).attrs()\n     }\n@@ -26,6 +38,55 @@ impl<T: AstLike + 'static> AstLike for P<T> {\n     }\n }\n \n+impl AstLike for crate::token::Nonterminal {\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = true;\n+    fn attrs(&self) -> &[Attribute] {\n+        match self {\n+            Nonterminal::NtItem(item) => item.attrs(),\n+            Nonterminal::NtStmt(stmt) => stmt.attrs(),\n+            Nonterminal::NtExpr(expr) | Nonterminal::NtLiteral(expr) => expr.attrs(),\n+            Nonterminal::NtPat(_)\n+            | Nonterminal::NtTy(_)\n+            | Nonterminal::NtMeta(_)\n+            | Nonterminal::NtPath(_)\n+            | Nonterminal::NtVis(_)\n+            | Nonterminal::NtTT(_)\n+            | Nonterminal::NtBlock(_)\n+            | Nonterminal::NtIdent(..)\n+            | Nonterminal::NtLifetime(_) => &[],\n+        }\n+    }\n+    fn visit_attrs(&mut self, f: impl FnOnce(&mut Vec<Attribute>)) {\n+        match self {\n+            Nonterminal::NtItem(item) => item.visit_attrs(f),\n+            Nonterminal::NtStmt(stmt) => stmt.visit_attrs(f),\n+            Nonterminal::NtExpr(expr) | Nonterminal::NtLiteral(expr) => expr.visit_attrs(f),\n+            Nonterminal::NtPat(_)\n+            | Nonterminal::NtTy(_)\n+            | Nonterminal::NtMeta(_)\n+            | Nonterminal::NtPath(_)\n+            | Nonterminal::NtVis(_)\n+            | Nonterminal::NtTT(_)\n+            | Nonterminal::NtBlock(_)\n+            | Nonterminal::NtIdent(..)\n+            | Nonterminal::NtLifetime(_) => {}\n+        }\n+    }\n+    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n+        match self {\n+            Nonterminal::NtItem(item) => item.tokens_mut(),\n+            Nonterminal::NtStmt(stmt) => stmt.tokens_mut(),\n+            Nonterminal::NtExpr(expr) | Nonterminal::NtLiteral(expr) => expr.tokens_mut(),\n+            Nonterminal::NtPat(pat) => pat.tokens_mut(),\n+            Nonterminal::NtTy(ty) => ty.tokens_mut(),\n+            Nonterminal::NtMeta(attr_item) => attr_item.tokens_mut(),\n+            Nonterminal::NtPath(path) => path.tokens_mut(),\n+            Nonterminal::NtVis(vis) => vis.tokens_mut(),\n+            _ => panic!(\"Called tokens_mut on {:?}\", self),\n+        }\n+    }\n+}\n+\n fn visit_attrvec(attrs: &mut AttrVec, f: impl FnOnce(&mut Vec<Attribute>)) {\n     crate::mut_visit::visit_clobber(attrs, |attrs| {\n         let mut vec = attrs.into();\n@@ -35,6 +96,10 @@ fn visit_attrvec(attrs: &mut AttrVec, f: impl FnOnce(&mut Vec<Attribute>)) {\n }\n \n impl AstLike for StmtKind {\n+    // This might be an `StmtKind::Item`, which contains\n+    // an item that supports inner attrs\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = true;\n+\n     fn attrs(&self) -> &[Attribute] {\n         match self {\n             StmtKind::Local(local) => local.attrs(),\n@@ -66,6 +131,8 @@ impl AstLike for StmtKind {\n }\n \n impl AstLike for Stmt {\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = StmtKind::SUPPORTS_CUSTOM_INNER_ATTRS;\n+\n     fn attrs(&self) -> &[Attribute] {\n         self.kind.attrs()\n     }\n@@ -79,6 +146,8 @@ impl AstLike for Stmt {\n }\n \n impl AstLike for Attribute {\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = false;\n+\n     fn attrs(&self) -> &[Attribute] {\n         &[]\n     }\n@@ -94,6 +163,8 @@ impl AstLike for Attribute {\n }\n \n impl<T: AstLike> AstLike for Option<T> {\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = T::SUPPORTS_CUSTOM_INNER_ATTRS;\n+\n     fn attrs(&self) -> &[Attribute] {\n         self.as_ref().map(|inner| inner.attrs()).unwrap_or(&[])\n     }\n@@ -127,8 +198,13 @@ impl VecOrAttrVec for AttrVec {\n }\n \n macro_rules! derive_has_tokens_and_attrs {\n-    ($($ty:path),*) => { $(\n+    (\n+        const SUPPORTS_CUSTOM_INNER_ATTRS: bool = $inner_attrs:literal;\n+        $($ty:path),*\n+    ) => { $(\n         impl AstLike for $ty {\n+            const SUPPORTS_CUSTOM_INNER_ATTRS: bool = $inner_attrs;\n+\n             fn attrs(&self) -> &[Attribute] {\n                 &self.attrs\n             }\n@@ -140,13 +216,16 @@ macro_rules! derive_has_tokens_and_attrs {\n             fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n                 Some(&mut self.tokens)\n             }\n+\n         }\n     )* }\n }\n \n macro_rules! derive_has_attrs_no_tokens {\n     ($($ty:path),*) => { $(\n         impl AstLike for $ty {\n+            const SUPPORTS_CUSTOM_INNER_ATTRS: bool = false;\n+\n             fn attrs(&self) -> &[Attribute] {\n                 &self.attrs\n             }\n@@ -165,23 +244,32 @@ macro_rules! derive_has_attrs_no_tokens {\n macro_rules! derive_has_tokens_no_attrs {\n     ($($ty:path),*) => { $(\n         impl AstLike for $ty {\n+            const SUPPORTS_CUSTOM_INNER_ATTRS: bool = false;\n+\n             fn attrs(&self) -> &[Attribute] {\n                 &[]\n             }\n \n             fn visit_attrs(&mut self, _f: impl FnOnce(&mut Vec<Attribute>)) {}\n-\n             fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n                 Some(&mut self.tokens)\n             }\n         }\n     )* }\n }\n \n-// These AST nodes support both inert and active\n-// attributes, so they also have tokens.\n+// These ast nodes support both active and inert attributes,\n+// so they have tokens collected to pass to proc macros\n+derive_has_tokens_and_attrs! {\n+    // Both `Item` and `AssocItem` can have bodies, which\n+    // can contain inner attributes\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = true;\n+    Item, AssocItem, ForeignItem\n+}\n+\n derive_has_tokens_and_attrs! {\n-    Item, Expr, Local, AssocItem, ForeignItem\n+    const SUPPORTS_CUSTOM_INNER_ATTRS: bool = false;\n+    Local, MacCallStmt, Expr\n }\n \n // These ast nodes only support inert attributes, so they don't"}, {"sha": "41121d095f3ed79bf3c12f997bf885b28e75f469", "filename": "compiler/rustc_ast/src/attr/mod.rs", "status": "modified", "additions": 10, "deletions": 4, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fattr%2Fmod.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -6,7 +6,9 @@ use crate::ast::{Lit, LitKind};\n use crate::ast::{MacArgs, MacDelimiter, MetaItem, MetaItemKind, NestedMetaItem};\n use crate::ast::{Path, PathSegment};\n use crate::token::{self, CommentKind, Token};\n-use crate::tokenstream::{DelimSpan, LazyTokenStream, TokenStream, TokenTree, TreeAndSpacing};\n+use crate::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n+use crate::tokenstream::{DelimSpan, Spacing, TokenTree, TreeAndSpacing};\n+use crate::tokenstream::{LazyTokenStream, TokenStream};\n \n use rustc_index::bit_set::GrowableBitSet;\n use rustc_span::source_map::BytePos;\n@@ -268,14 +270,18 @@ impl Attribute {\n         }\n     }\n \n-    pub fn tokens(&self) -> TokenStream {\n+    pub fn tokens(&self) -> AttrAnnotatedTokenStream {\n         match self.kind {\n             AttrKind::Normal(_, ref tokens) => tokens\n                 .as_ref()\n                 .unwrap_or_else(|| panic!(\"attribute is missing tokens: {:?}\", self))\n                 .create_token_stream(),\n-            AttrKind::DocComment(comment_kind, data) => TokenStream::from(TokenTree::Token(\n-                Token::new(token::DocComment(comment_kind, self.style, data), self.span),\n+            AttrKind::DocComment(comment_kind, data) => AttrAnnotatedTokenStream::from((\n+                AttrAnnotatedTokenTree::Token(Token::new(\n+                    token::DocComment(comment_kind, self.style, data),\n+                    self.span,\n+                )),\n+                Spacing::Alone,\n             )),\n         }\n     }"}, {"sha": "05f57f978c7a4c3313abc1e15fbb556eaf96153f", "filename": "compiler/rustc_ast/src/mut_visit.rs", "status": "modified", "additions": 45, "deletions": 4, "changes": 49, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Fmut_visit.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -630,6 +630,33 @@ pub fn noop_flat_map_param<T: MutVisitor>(mut param: Param, vis: &mut T) -> Smal\n     smallvec![param]\n }\n \n+// No `noop_` prefix because there isn't a corresponding method in `MutVisitor`.\n+pub fn visit_attr_annotated_tt<T: MutVisitor>(tt: &mut AttrAnnotatedTokenTree, vis: &mut T) {\n+    match tt {\n+        AttrAnnotatedTokenTree::Token(token) => {\n+            visit_token(token, vis);\n+        }\n+        AttrAnnotatedTokenTree::Delimited(DelimSpan { open, close }, _delim, tts) => {\n+            vis.visit_span(open);\n+            vis.visit_span(close);\n+            visit_attr_annotated_tts(tts, vis);\n+        }\n+        AttrAnnotatedTokenTree::Attributes(data) => {\n+            for attr in &mut *data.attrs {\n+                match &mut attr.kind {\n+                    AttrKind::Normal(_, attr_tokens) => {\n+                        visit_lazy_tts(attr_tokens, vis);\n+                    }\n+                    AttrKind::DocComment(..) => {\n+                        vis.visit_span(&mut attr.span);\n+                    }\n+                }\n+            }\n+            visit_lazy_tts_opt_mut(Some(&mut data.tokens), vis);\n+        }\n+    }\n+}\n+\n // No `noop_` prefix because there isn't a corresponding method in `MutVisitor`.\n pub fn visit_tt<T: MutVisitor>(tt: &mut TokenTree, vis: &mut T) {\n     match tt {\n@@ -652,16 +679,30 @@ pub fn visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &mut T)\n     }\n }\n \n-pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyTokenStream>, vis: &mut T) {\n+pub fn visit_attr_annotated_tts<T: MutVisitor>(\n+    AttrAnnotatedTokenStream(tts): &mut AttrAnnotatedTokenStream,\n+    vis: &mut T,\n+) {\n+    if vis.token_visiting_enabled() && !tts.is_empty() {\n+        let tts = Lrc::make_mut(tts);\n+        visit_vec(tts, |(tree, _is_joint)| visit_attr_annotated_tt(tree, vis));\n+    }\n+}\n+\n+pub fn visit_lazy_tts_opt_mut<T: MutVisitor>(lazy_tts: Option<&mut LazyTokenStream>, vis: &mut T) {\n     if vis.token_visiting_enabled() {\n-        visit_opt(lazy_tts, |lazy_tts| {\n+        if let Some(lazy_tts) = lazy_tts {\n             let mut tts = lazy_tts.create_token_stream();\n-            visit_tts(&mut tts, vis);\n+            visit_attr_annotated_tts(&mut tts, vis);\n             *lazy_tts = LazyTokenStream::new(tts);\n-        })\n+        }\n     }\n }\n \n+pub fn visit_lazy_tts<T: MutVisitor>(lazy_tts: &mut Option<LazyTokenStream>, vis: &mut T) {\n+    visit_lazy_tts_opt_mut(lazy_tts.as_mut(), vis);\n+}\n+\n // No `noop_` prefix because there isn't a corresponding method in `MutVisitor`.\n // Applies ident visitor if it's an ident; applies other visits to interpolated nodes.\n // In practice the ident part is not actually used by specific visitors right now,"}, {"sha": "8318b242cae94462e8415e4b11186aa61563f1e8", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 155, "deletions": 5, "changes": 160, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -14,6 +14,7 @@\n //! ownership of the original.\n \n use crate::token::{self, DelimToken, Token, TokenKind};\n+use crate::AttrVec;\n \n use rustc_data_structures::stable_hasher::{HashStable, StableHasher};\n use rustc_data_structures::sync::{self, Lrc};\n@@ -123,11 +124,11 @@ where\n }\n \n pub trait CreateTokenStream: sync::Send + sync::Sync {\n-    fn create_token_stream(&self) -> TokenStream;\n+    fn create_token_stream(&self) -> AttrAnnotatedTokenStream;\n }\n \n-impl CreateTokenStream for TokenStream {\n-    fn create_token_stream(&self) -> TokenStream {\n+impl CreateTokenStream for AttrAnnotatedTokenStream {\n+    fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n         self.clone()\n     }\n }\n@@ -143,14 +144,14 @@ impl LazyTokenStream {\n         LazyTokenStream(Lrc::new(Box::new(inner)))\n     }\n \n-    pub fn create_token_stream(&self) -> TokenStream {\n+    pub fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n         self.0.create_token_stream()\n     }\n }\n \n impl fmt::Debug for LazyTokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        fmt::Debug::fmt(\"LazyTokenStream\", f)\n+        write!(f, \"LazyTokenStream({:?})\", self.create_token_stream())\n     }\n }\n \n@@ -173,6 +174,145 @@ impl<CTX> HashStable<CTX> for LazyTokenStream {\n     }\n }\n \n+/// A `AttrAnnotatedTokenStream` is similar to a `TokenStream`, but with extra\n+/// information about the tokens for attribute targets. This is used\n+/// during expansion to perform early cfg-expansion, and to process attributes\n+/// during proc-macro invocations.\n+#[derive(Clone, Debug, Default, Encodable, Decodable)]\n+pub struct AttrAnnotatedTokenStream(pub Lrc<Vec<(AttrAnnotatedTokenTree, Spacing)>>);\n+\n+/// Like `TokenTree`, but for `AttrAnnotatedTokenStream`\n+#[derive(Clone, Debug, Encodable, Decodable)]\n+pub enum AttrAnnotatedTokenTree {\n+    Token(Token),\n+    Delimited(DelimSpan, DelimToken, AttrAnnotatedTokenStream),\n+    /// Stores the attributes for an attribute target,\n+    /// along with the tokens for that attribute target.\n+    /// See `AttributesData` for more information\n+    Attributes(AttributesData),\n+}\n+\n+impl AttrAnnotatedTokenStream {\n+    pub fn new(tokens: Vec<(AttrAnnotatedTokenTree, Spacing)>) -> AttrAnnotatedTokenStream {\n+        AttrAnnotatedTokenStream(Lrc::new(tokens))\n+    }\n+\n+    /// Converts this `AttrAnnotatedTokenStream` to a plain `TokenStream\n+    /// During conversion, `AttrAnnotatedTokenTree::Attributes` get 'flattened'\n+    /// back to a `TokenStream` of the form `outer_attr attr_target`.\n+    /// If there are inner attributes, they are inserted into the proper\n+    /// place in the attribute target tokens.\n+    pub fn to_tokenstream(&self) -> TokenStream {\n+        let trees: Vec<_> = self\n+            .0\n+            .iter()\n+            .flat_map(|tree| match &tree.0 {\n+                AttrAnnotatedTokenTree::Token(inner) => {\n+                    smallvec![(TokenTree::Token(inner.clone()), tree.1)].into_iter()\n+                }\n+                AttrAnnotatedTokenTree::Delimited(span, delim, stream) => smallvec![(\n+                    TokenTree::Delimited(*span, *delim, stream.to_tokenstream()),\n+                    tree.1,\n+                )]\n+                .into_iter(),\n+                AttrAnnotatedTokenTree::Attributes(data) => {\n+                    let mut outer_attrs = Vec::new();\n+                    let mut inner_attrs = Vec::new();\n+                    let attrs: Vec<_> = data.attrs.clone().into();\n+                    for attr in attrs {\n+                        match attr.style {\n+                            crate::AttrStyle::Outer => {\n+                                assert!(\n+                                    inner_attrs.len() == 0,\n+                                    \"Found outer attribute {:?} after inner attrs {:?}\",\n+                                    attr,\n+                                    inner_attrs\n+                                );\n+                                outer_attrs.push(attr);\n+                            }\n+                            crate::AttrStyle::Inner => {\n+                                inner_attrs.push(attr);\n+                            }\n+                        }\n+                    }\n+\n+                    let mut target_tokens: Vec<_> = data\n+                        .tokens\n+                        .create_token_stream()\n+                        .to_tokenstream()\n+                        .0\n+                        .iter()\n+                        .cloned()\n+                        .collect();\n+                    if !inner_attrs.is_empty() {\n+                        let mut found = false;\n+                        // Check the last two trees (to account for a trailing semi)\n+                        for (tree, _) in target_tokens.iter_mut().rev().take(2) {\n+                            if let TokenTree::Delimited(span, delim, delim_tokens) = tree {\n+                                // Inner attributes are only supported on extern blocks, functions, impls,\n+                                // and modules. All of these have their inner attributes placed at\n+                                // the beginning of the rightmost outermost braced group:\n+                                // e.g. fn foo() { #![my_attr} }\n+                                //\n+                                // Therefore, we can insert them back into the right location\n+                                // without needing to do any extra position tracking.\n+                                //\n+                                // Note: Outline modules are an exception - they can\n+                                // have attributes like `#![my_attr]` at the start of a file.\n+                                // Support for custom attributes in this position is not\n+                                // properly implemented - we always synthesize fake tokens,\n+                                // so we never reach this code.\n+\n+                                let mut builder = TokenStreamBuilder::new();\n+                                for inner_attr in &inner_attrs {\n+                                    builder.push(inner_attr.tokens().to_tokenstream());\n+                                }\n+                                builder.push(delim_tokens.clone());\n+                                *tree = TokenTree::Delimited(*span, *delim, builder.build());\n+                                found = true;\n+                                break;\n+                            }\n+                        }\n+\n+                        assert!(\n+                            found,\n+                            \"Failed to find trailing delimited group in: {:?}\",\n+                            target_tokens\n+                        );\n+                    }\n+                    let mut flat: SmallVec<[_; 1]> = SmallVec::new();\n+                    for attr in outer_attrs {\n+                        // FIXME: Make this more efficient\n+                        flat.extend(attr.tokens().to_tokenstream().0.clone().iter().cloned());\n+                    }\n+                    flat.extend(target_tokens);\n+                    flat.into_iter()\n+                }\n+            })\n+            .collect();\n+        TokenStream::new(trees)\n+    }\n+}\n+\n+/// Stores the tokens for an attribute target, along\n+/// with its attributes.\n+///\n+/// This is constructed during parsing when we need to capture\n+/// tokens.\n+///\n+/// For example, `#[cfg(FALSE)] struct Foo {}` would\n+/// have an `attrs` field contaiing the `#[cfg(FALSE)]` attr,\n+/// and a `tokens` field storing the (unparesd) tokens `struct Foo {}`\n+#[derive(Clone, Debug, Encodable, Decodable)]\n+pub struct AttributesData {\n+    /// Attributes, both outer and inner.\n+    /// These are stored in the original order that they were parsed in.\n+    pub attrs: AttrVec,\n+    /// The underlying tokens for the attribute target that `attrs`\n+    /// are applied to\n+    pub tokens: LazyTokenStream,\n+}\n+\n /// A `TokenStream` is an abstract sequence of tokens, organized into [`TokenTree`]s.\n ///\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n@@ -235,6 +375,12 @@ impl TokenStream {\n     }\n }\n \n+impl From<(AttrAnnotatedTokenTree, Spacing)> for AttrAnnotatedTokenStream {\n+    fn from((tree, spacing): (AttrAnnotatedTokenTree, Spacing)) -> AttrAnnotatedTokenStream {\n+        AttrAnnotatedTokenStream::new(vec![(tree, spacing)])\n+    }\n+}\n+\n impl From<TokenTree> for TokenStream {\n     fn from(tree: TokenTree) -> TokenStream {\n         TokenStream::new(vec![(tree, Spacing::Alone)])\n@@ -457,6 +603,10 @@ impl Cursor {\n         }\n     }\n \n+    pub fn index(&self) -> usize {\n+        self.index\n+    }\n+\n     pub fn append(&mut self, new_stream: TokenStream) {\n         if new_stream.is_empty() {\n             return;"}, {"sha": "44056df4ab911744d0ab935a29f23f6c0aa5f778", "filename": "compiler/rustc_ast_lowering/src/lib.rs", "status": "modified", "additions": 7, "deletions": 45, "changes": 52, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast_lowering%2Fsrc%2Flib.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -37,8 +37,8 @@\n #![recursion_limit = \"256\"]\n \n use rustc_ast::node_id::NodeMap;\n-use rustc_ast::token::{self, DelimToken, Nonterminal, Token};\n-use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, DelimSpan, TokenStream, TokenTree};\n+use rustc_ast::token::{self, Token};\n+use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, TokenStream, TokenTree};\n use rustc_ast::visit::{self, AssocCtxt, Visitor};\n use rustc_ast::walk_list;\n use rustc_ast::{self as ast, *};\n@@ -56,7 +56,7 @@ use rustc_hir::{ConstArg, GenericArg, ParamName};\n use rustc_index::vec::{Idx, IndexVec};\n use rustc_session::lint::builtin::{BARE_TRAIT_OBJECTS, MISSING_ABI};\n use rustc_session::lint::{BuiltinLintDiagnostics, LintBuffer};\n-use rustc_session::parse::ParseSess;\n+use rustc_session::utils::{FlattenNonterminals, NtToTokenstream};\n use rustc_session::Session;\n use rustc_span::hygiene::ExpnId;\n use rustc_span::source_map::{respan, DesugaringKind};\n@@ -213,8 +213,6 @@ pub trait ResolverAstLowering {\n     ) -> LocalDefId;\n }\n \n-type NtToTokenstream = fn(&Nonterminal, &ParseSess, CanSynthesizeMissingTokens) -> TokenStream;\n-\n /// Context of `impl Trait` in code, which determines whether it is allowed in an HIR subtree,\n /// and if so, what meaning it has.\n #[derive(Debug)]\n@@ -403,42 +401,6 @@ enum AnonymousLifetimeMode {\n     PassThrough,\n }\n \n-struct TokenStreamLowering<'a> {\n-    parse_sess: &'a ParseSess,\n-    synthesize_tokens: CanSynthesizeMissingTokens,\n-    nt_to_tokenstream: NtToTokenstream,\n-}\n-\n-impl<'a> TokenStreamLowering<'a> {\n-    fn lower_token_stream(&mut self, tokens: TokenStream) -> TokenStream {\n-        tokens.into_trees().flat_map(|tree| self.lower_token_tree(tree).into_trees()).collect()\n-    }\n-\n-    fn lower_token_tree(&mut self, tree: TokenTree) -> TokenStream {\n-        match tree {\n-            TokenTree::Token(token) => self.lower_token(token),\n-            TokenTree::Delimited(span, delim, tts) => {\n-                TokenTree::Delimited(span, delim, self.lower_token_stream(tts)).into()\n-            }\n-        }\n-    }\n-\n-    fn lower_token(&mut self, token: Token) -> TokenStream {\n-        match token.kind {\n-            token::Interpolated(nt) => {\n-                let tts = (self.nt_to_tokenstream)(&nt, self.parse_sess, self.synthesize_tokens);\n-                TokenTree::Delimited(\n-                    DelimSpan::from_single(token.span),\n-                    DelimToken::NoDelim,\n-                    self.lower_token_stream(tts),\n-                )\n-                .into()\n-            }\n-            _ => TokenTree::Token(token).into(),\n-        }\n-    }\n-}\n-\n impl<'a, 'hir> LoweringContext<'a, 'hir> {\n     fn lower_crate(mut self, c: &Crate) -> hir::Crate<'hir> {\n         /// Full-crate AST visitor that inserts into a fresh\n@@ -1037,12 +999,12 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n                     }\n                 }\n \n-                let tokens = TokenStreamLowering {\n+                let tokens = FlattenNonterminals {\n                     parse_sess: &self.sess.parse_sess,\n                     synthesize_tokens: CanSynthesizeMissingTokens::Yes,\n                     nt_to_tokenstream: self.nt_to_tokenstream,\n                 }\n-                .lower_token(token.clone());\n+                .process_token(token.clone());\n                 MacArgs::Eq(eq_span, unwrap_single_token(self.sess, tokens, token.span))\n             }\n         }\n@@ -1053,12 +1015,12 @@ impl<'a, 'hir> LoweringContext<'a, 'hir> {\n         tokens: TokenStream,\n         synthesize_tokens: CanSynthesizeMissingTokens,\n     ) -> TokenStream {\n-        TokenStreamLowering {\n+        FlattenNonterminals {\n             parse_sess: &self.sess.parse_sess,\n             synthesize_tokens,\n             nt_to_tokenstream: self.nt_to_tokenstream,\n         }\n-        .lower_token_stream(tokens)\n+        .process_token_stream(tokens)\n     }\n \n     /// Given an associated type constraint like one of these:"}, {"sha": "79dc857074d5990ae1320deea5668f8db9c922eb", "filename": "compiler/rustc_builtin_macros/src/cfg_eval.rs", "status": "modified", "additions": 167, "deletions": 55, "changes": 222, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_builtin_macros%2Fsrc%2Fcfg_eval.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,11 +1,18 @@\n use crate::util::check_builtin_macro_attribute;\n \n-use rustc_ast::mut_visit::{self, MutVisitor};\n-use rustc_ast::ptr::P;\n-use rustc_ast::{self as ast, AstLike};\n+use rustc_ast as ast;\n+use rustc_ast::mut_visit::MutVisitor;\n+use rustc_ast::tokenstream::CanSynthesizeMissingTokens;\n+use rustc_ast::visit::Visitor;\n+use rustc_ast::{mut_visit, visit};\n+use rustc_ast::{AstLike, Attribute};\n use rustc_expand::base::{Annotatable, ExtCtxt};\n use rustc_expand::config::StripUnconfigured;\n use rustc_expand::configure;\n+use rustc_parse::parser::ForceCollect;\n+use rustc_session::utils::FlattenNonterminals;\n+\n+use rustc_ast::ptr::P;\n use rustc_span::symbol::sym;\n use rustc_span::Span;\n use smallvec::SmallVec;\n@@ -22,74 +29,179 @@ crate fn expand(\n \n crate fn cfg_eval(ecx: &ExtCtxt<'_>, annotatable: Annotatable) -> Vec<Annotatable> {\n     let mut visitor = CfgEval {\n-        cfg: StripUnconfigured { sess: ecx.sess, features: ecx.ecfg.features, modified: false },\n+        cfg: &mut StripUnconfigured {\n+            sess: ecx.sess,\n+            features: ecx.ecfg.features,\n+            config_tokens: true,\n+        },\n     };\n-    let mut annotatable = visitor.configure_annotatable(annotatable);\n-    if visitor.cfg.modified {\n-        // Erase the tokens if cfg-stripping modified the item\n-        // This will cause us to synthesize fake tokens\n-        // when `nt_to_tokenstream` is called on this item.\n-        if let Some(tokens) = annotatable.tokens_mut() {\n-            *tokens = None;\n+    let annotatable = visitor.configure_annotatable(annotatable);\n+    vec![annotatable]\n+}\n+\n+struct CfgEval<'a, 'b> {\n+    cfg: &'a mut StripUnconfigured<'b>,\n+}\n+\n+fn flat_map_annotatable(vis: &mut impl MutVisitor, annotatable: Annotatable) -> Annotatable {\n+    // Since the item itself has already been configured by the InvocationCollector,\n+    // we know that fold result vector will contain exactly one element\n+    match annotatable {\n+        Annotatable::Item(item) => Annotatable::Item(vis.flat_map_item(item).pop().unwrap()),\n+        Annotatable::TraitItem(item) => {\n+            Annotatable::TraitItem(vis.flat_map_trait_item(item).pop().unwrap())\n+        }\n+        Annotatable::ImplItem(item) => {\n+            Annotatable::ImplItem(vis.flat_map_impl_item(item).pop().unwrap())\n+        }\n+        Annotatable::ForeignItem(item) => {\n+            Annotatable::ForeignItem(vis.flat_map_foreign_item(item).pop().unwrap())\n         }\n+        Annotatable::Stmt(stmt) => {\n+            Annotatable::Stmt(stmt.map(|stmt| vis.flat_map_stmt(stmt).pop().unwrap()))\n+        }\n+        Annotatable::Expr(mut expr) => Annotatable::Expr({\n+            vis.visit_expr(&mut expr);\n+            expr\n+        }),\n+        Annotatable::Arm(arm) => Annotatable::Arm(vis.flat_map_arm(arm).pop().unwrap()),\n+        Annotatable::ExprField(field) => {\n+            Annotatable::ExprField(vis.flat_map_expr_field(field).pop().unwrap())\n+        }\n+        Annotatable::PatField(fp) => {\n+            Annotatable::PatField(vis.flat_map_pat_field(fp).pop().unwrap())\n+        }\n+        Annotatable::GenericParam(param) => {\n+            Annotatable::GenericParam(vis.flat_map_generic_param(param).pop().unwrap())\n+        }\n+        Annotatable::Param(param) => Annotatable::Param(vis.flat_map_param(param).pop().unwrap()),\n+        Annotatable::FieldDef(sf) => {\n+            Annotatable::FieldDef(vis.flat_map_field_def(sf).pop().unwrap())\n+        }\n+        Annotatable::Variant(v) => Annotatable::Variant(vis.flat_map_variant(v).pop().unwrap()),\n+    }\n+}\n+\n+struct CfgFinder {\n+    has_cfg_or_cfg_attr: bool,\n+}\n+\n+impl CfgFinder {\n+    fn has_cfg_or_cfg_attr(annotatable: &Annotatable) -> bool {\n+        let mut finder = CfgFinder { has_cfg_or_cfg_attr: false };\n+        match annotatable {\n+            Annotatable::Item(item) => finder.visit_item(&item),\n+            Annotatable::TraitItem(item) => finder.visit_assoc_item(&item, visit::AssocCtxt::Trait),\n+            Annotatable::ImplItem(item) => finder.visit_assoc_item(&item, visit::AssocCtxt::Impl),\n+            Annotatable::ForeignItem(item) => finder.visit_foreign_item(&item),\n+            Annotatable::Stmt(stmt) => finder.visit_stmt(&stmt),\n+            Annotatable::Expr(expr) => finder.visit_expr(&expr),\n+            Annotatable::Arm(arm) => finder.visit_arm(&arm),\n+            Annotatable::ExprField(field) => finder.visit_expr_field(&field),\n+            Annotatable::PatField(field) => finder.visit_pat_field(&field),\n+            Annotatable::GenericParam(param) => finder.visit_generic_param(&param),\n+            Annotatable::Param(param) => finder.visit_param(&param),\n+            Annotatable::FieldDef(field) => finder.visit_field_def(&field),\n+            Annotatable::Variant(variant) => finder.visit_variant(&variant),\n+        };\n+        finder.has_cfg_or_cfg_attr\n     }\n-    vec![annotatable]\n }\n \n-struct CfgEval<'a> {\n-    cfg: StripUnconfigured<'a>,\n+impl<'ast> visit::Visitor<'ast> for CfgFinder {\n+    fn visit_attribute(&mut self, attr: &'ast Attribute) {\n+        // We want short-circuiting behavior, so don't use the '|=' operator.\n+        self.has_cfg_or_cfg_attr = self.has_cfg_or_cfg_attr\n+            || attr\n+                .ident()\n+                .map_or(false, |ident| ident.name == sym::cfg || ident.name == sym::cfg_attr);\n+    }\n }\n \n-impl CfgEval<'_> {\n+impl CfgEval<'_, '_> {\n     fn configure<T: AstLike>(&mut self, node: T) -> Option<T> {\n         self.cfg.configure(node)\n     }\n \n-    fn configure_annotatable(&mut self, annotatable: Annotatable) -> Annotatable {\n-        // Since the item itself has already been configured by the InvocationCollector,\n-        // we know that fold result vector will contain exactly one element\n-        match annotatable {\n-            Annotatable::Item(item) => Annotatable::Item(self.flat_map_item(item).pop().unwrap()),\n-            Annotatable::TraitItem(item) => {\n-                Annotatable::TraitItem(self.flat_map_trait_item(item).pop().unwrap())\n-            }\n-            Annotatable::ImplItem(item) => {\n-                Annotatable::ImplItem(self.flat_map_impl_item(item).pop().unwrap())\n-            }\n-            Annotatable::ForeignItem(item) => {\n-                Annotatable::ForeignItem(self.flat_map_foreign_item(item).pop().unwrap())\n-            }\n-            Annotatable::Stmt(stmt) => {\n-                Annotatable::Stmt(stmt.map(|stmt| self.flat_map_stmt(stmt).pop().unwrap()))\n-            }\n-            Annotatable::Expr(mut expr) => Annotatable::Expr({\n-                self.visit_expr(&mut expr);\n-                expr\n-            }),\n-            Annotatable::Arm(arm) => Annotatable::Arm(self.flat_map_arm(arm).pop().unwrap()),\n-            Annotatable::ExprField(field) => {\n-                Annotatable::ExprField(self.flat_map_expr_field(field).pop().unwrap())\n-            }\n-            Annotatable::PatField(fp) => {\n-                Annotatable::PatField(self.flat_map_pat_field(fp).pop().unwrap())\n-            }\n-            Annotatable::GenericParam(param) => {\n-                Annotatable::GenericParam(self.flat_map_generic_param(param).pop().unwrap())\n-            }\n-            Annotatable::Param(param) => {\n-                Annotatable::Param(self.flat_map_param(param).pop().unwrap())\n-            }\n-            Annotatable::FieldDef(sf) => {\n-                Annotatable::FieldDef(self.flat_map_field_def(sf).pop().unwrap())\n+    pub fn configure_annotatable(&mut self, mut annotatable: Annotatable) -> Annotatable {\n+        // Tokenizing and re-parsing the `Annotatable` can have a significant\n+        // performance impact, so try to avoid it if possible\n+        if !CfgFinder::has_cfg_or_cfg_attr(&annotatable) {\n+            return annotatable;\n+        }\n+\n+        // The majority of parsed attribute targets will never need to have early cfg-expansion\n+        // run (e.g. they are not part of a `#[derive]` or `#[cfg_eval]` macro inoput).\n+        // Therefore, we normally do not capture the necessary information about `#[cfg]`\n+        // and `#[cfg_attr]` attributes during parsing.\n+        //\n+        // Therefore, when we actually *do* run early cfg-expansion, we need to tokenize\n+        // and re-parse the attribute target, this time capturing information about\n+        // the location of `#[cfg]` and `#[cfg_attr]` in the token stream. The tokenization\n+        // process is lossless, so this process is invisible to proc-macros.\n+\n+        // FIXME - get rid of this clone\n+        let nt = annotatable.clone().into_nonterminal();\n+\n+        let mut orig_tokens = rustc_parse::nt_to_tokenstream(\n+            &nt,\n+            &self.cfg.sess.parse_sess,\n+            CanSynthesizeMissingTokens::No,\n+        );\n+\n+        // 'Flatten' all nonterminals (i.e. `TokenKind::Interpolated`)\n+        // to `None`-delimited groups containing the corresponding tokens. This\n+        // is normally delayed until the proc-macro server actually needs to\n+        // provide a `TokenKind::Interpolated` to a proc-macro. We do this earlier,\n+        // so that we can handle cases like:\n+        //\n+        // ```rust\n+        // #[cfg_eval] #[cfg] $item\n+        //```\n+        //\n+        // where `$item` is `#[cfg_attr] struct Foo {}`. We want to make\n+        // sure to evaluate *all* `#[cfg]` and `#[cfg_attr]` attributes - the simplest\n+        // way to do this is to do a single parse of a stream without any nonterminals.\n+        let mut flatten = FlattenNonterminals {\n+            nt_to_tokenstream: rustc_parse::nt_to_tokenstream,\n+            parse_sess: &self.cfg.sess.parse_sess,\n+            synthesize_tokens: CanSynthesizeMissingTokens::No,\n+        };\n+        orig_tokens = flatten.process_token_stream(orig_tokens);\n+\n+        // Re-parse the tokens, setting the `capture_cfg` flag to save extra information\n+        // to the captured `AttrAnnotatedTokenStream` (specifically, we capture\n+        // `AttrAnnotatedTokenTree::AttributesData` for all occurences of `#[cfg]` and `#[cfg_attr]`)\n+        let mut parser =\n+            rustc_parse::stream_to_parser(&self.cfg.sess.parse_sess, orig_tokens, None);\n+        parser.capture_cfg = true;\n+        annotatable = match annotatable {\n+            Annotatable::Item(_) => {\n+                Annotatable::Item(parser.parse_item(ForceCollect::Yes).unwrap().unwrap())\n             }\n-            Annotatable::Variant(v) => {\n-                Annotatable::Variant(self.flat_map_variant(v).pop().unwrap())\n+            Annotatable::TraitItem(_) => Annotatable::TraitItem(\n+                parser.parse_trait_item(ForceCollect::Yes).unwrap().unwrap().unwrap(),\n+            ),\n+            Annotatable::ImplItem(_) => Annotatable::ImplItem(\n+                parser.parse_impl_item(ForceCollect::Yes).unwrap().unwrap().unwrap(),\n+            ),\n+            Annotatable::ForeignItem(_) => Annotatable::ForeignItem(\n+                parser.parse_foreign_item(ForceCollect::Yes).unwrap().unwrap().unwrap(),\n+            ),\n+            Annotatable::Stmt(_) => {\n+                Annotatable::Stmt(P(parser.parse_stmt(ForceCollect::Yes).unwrap().unwrap()))\n             }\n-        }\n+            Annotatable::Expr(_) => Annotatable::Expr(parser.parse_expr_force_collect().unwrap()),\n+            _ => unreachable!(),\n+        };\n+\n+        // Now that we have our re-parsed `AttrAnnotatedTokenStream`, recursively configuring\n+        // our attribute target will correctly the tokens as well.\n+        flat_map_annotatable(self, annotatable)\n     }\n }\n \n-impl MutVisitor for CfgEval<'_> {\n+impl MutVisitor for CfgEval<'_, '_> {\n     fn visit_expr(&mut self, expr: &mut P<ast::Expr>) {\n         self.cfg.configure_expr(expr);\n         mut_visit::noop_visit_expr(expr, self);"}, {"sha": "595058428164995a6975dcfde5431fbec3a7d17d", "filename": "compiler/rustc_expand/src/base.rs", "status": "modified", "additions": 19, "deletions": 60, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fbase.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -3,7 +3,7 @@ use crate::module::DirOwnership;\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, Nonterminal};\n-use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, LazyTokenStream, TokenStream};\n+use rustc_ast::tokenstream::{CanSynthesizeMissingTokens, TokenStream};\n use rustc_ast::visit::{AssocCtxt, Visitor};\n use rustc_ast::{self as ast, AstLike, Attribute, Item, NodeId, PatKind};\n use rustc_attr::{self as attr, Deprecation, Stability};\n@@ -46,26 +46,26 @@ pub enum Annotatable {\n     Variant(ast::Variant),\n }\n \n-impl AstLike for Annotatable {\n-    fn attrs(&self) -> &[Attribute] {\n+impl Annotatable {\n+    pub fn span(&self) -> Span {\n         match *self {\n-            Annotatable::Item(ref item) => &item.attrs,\n-            Annotatable::TraitItem(ref trait_item) => &trait_item.attrs,\n-            Annotatable::ImplItem(ref impl_item) => &impl_item.attrs,\n-            Annotatable::ForeignItem(ref foreign_item) => &foreign_item.attrs,\n-            Annotatable::Stmt(ref stmt) => stmt.attrs(),\n-            Annotatable::Expr(ref expr) => &expr.attrs,\n-            Annotatable::Arm(ref arm) => &arm.attrs,\n-            Annotatable::ExprField(ref field) => &field.attrs,\n-            Annotatable::PatField(ref fp) => &fp.attrs,\n-            Annotatable::GenericParam(ref gp) => &gp.attrs,\n-            Annotatable::Param(ref p) => &p.attrs,\n-            Annotatable::FieldDef(ref sf) => &sf.attrs,\n-            Annotatable::Variant(ref v) => &v.attrs(),\n+            Annotatable::Item(ref item) => item.span,\n+            Annotatable::TraitItem(ref trait_item) => trait_item.span,\n+            Annotatable::ImplItem(ref impl_item) => impl_item.span,\n+            Annotatable::ForeignItem(ref foreign_item) => foreign_item.span,\n+            Annotatable::Stmt(ref stmt) => stmt.span,\n+            Annotatable::Expr(ref expr) => expr.span,\n+            Annotatable::Arm(ref arm) => arm.span,\n+            Annotatable::ExprField(ref field) => field.span,\n+            Annotatable::PatField(ref fp) => fp.pat.span,\n+            Annotatable::GenericParam(ref gp) => gp.ident.span,\n+            Annotatable::Param(ref p) => p.span,\n+            Annotatable::FieldDef(ref sf) => sf.span,\n+            Annotatable::Variant(ref v) => v.span,\n         }\n     }\n \n-    fn visit_attrs(&mut self, f: impl FnOnce(&mut Vec<Attribute>)) {\n+    pub fn visit_attrs(&mut self, f: impl FnOnce(&mut Vec<Attribute>)) {\n         match self {\n             Annotatable::Item(item) => item.visit_attrs(f),\n             Annotatable::TraitItem(trait_item) => trait_item.visit_attrs(f),\n@@ -83,44 +83,6 @@ impl AstLike for Annotatable {\n         }\n     }\n \n-    fn tokens_mut(&mut self) -> Option<&mut Option<LazyTokenStream>> {\n-        match self {\n-            Annotatable::Item(item) => item.tokens_mut(),\n-            Annotatable::TraitItem(trait_item) => trait_item.tokens_mut(),\n-            Annotatable::ImplItem(impl_item) => impl_item.tokens_mut(),\n-            Annotatable::ForeignItem(foreign_item) => foreign_item.tokens_mut(),\n-            Annotatable::Stmt(stmt) => stmt.tokens_mut(),\n-            Annotatable::Expr(expr) => expr.tokens_mut(),\n-            Annotatable::Arm(arm) => arm.tokens_mut(),\n-            Annotatable::ExprField(field) => field.tokens_mut(),\n-            Annotatable::PatField(fp) => fp.tokens_mut(),\n-            Annotatable::GenericParam(gp) => gp.tokens_mut(),\n-            Annotatable::Param(p) => p.tokens_mut(),\n-            Annotatable::FieldDef(sf) => sf.tokens_mut(),\n-            Annotatable::Variant(v) => v.tokens_mut(),\n-        }\n-    }\n-}\n-\n-impl Annotatable {\n-    pub fn span(&self) -> Span {\n-        match *self {\n-            Annotatable::Item(ref item) => item.span,\n-            Annotatable::TraitItem(ref trait_item) => trait_item.span,\n-            Annotatable::ImplItem(ref impl_item) => impl_item.span,\n-            Annotatable::ForeignItem(ref foreign_item) => foreign_item.span,\n-            Annotatable::Stmt(ref stmt) => stmt.span,\n-            Annotatable::Expr(ref expr) => expr.span,\n-            Annotatable::Arm(ref arm) => arm.span,\n-            Annotatable::ExprField(ref field) => field.span,\n-            Annotatable::PatField(ref fp) => fp.pat.span,\n-            Annotatable::GenericParam(ref gp) => gp.ident.span,\n-            Annotatable::Param(ref p) => p.span,\n-            Annotatable::FieldDef(ref sf) => sf.span,\n-            Annotatable::Variant(ref v) => v.span,\n-        }\n-    }\n-\n     pub fn visit_with<'a, V: Visitor<'a>>(&'a self, visitor: &mut V) {\n         match self {\n             Annotatable::Item(item) => visitor.visit_item(item),\n@@ -139,7 +101,7 @@ impl Annotatable {\n         }\n     }\n \n-    crate fn into_nonterminal(self) -> Nonterminal {\n+    pub fn into_nonterminal(self) -> Nonterminal {\n         match self {\n             Annotatable::Item(item) => token::NtItem(item),\n             Annotatable::TraitItem(item) | Annotatable::ImplItem(item) => {\n@@ -161,10 +123,7 @@ impl Annotatable {\n     }\n \n     crate fn into_tokens(self, sess: &ParseSess) -> TokenStream {\n-        // Tokens of an attribute target may be invalidated by some outer `#[derive]` performing\n-        // \"full configuration\" (attributes following derives on the same item should be the most\n-        // common case), that's why synthesizing tokens is allowed.\n-        nt_to_tokenstream(&self.into_nonterminal(), sess, CanSynthesizeMissingTokens::Yes)\n+        nt_to_tokenstream(&self.into_nonterminal(), sess, CanSynthesizeMissingTokens::No)\n     }\n \n     pub fn expect_item(self) -> P<ast::Item> {"}, {"sha": "03c83f9c07b5d99acd3b1b7d6efdfe1614a1456c", "filename": "compiler/rustc_expand/src/config.rs", "status": "modified", "additions": 96, "deletions": 25, "changes": 121, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fconfig.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -2,8 +2,10 @@\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{DelimToken, Token, TokenKind};\n-use rustc_ast::tokenstream::{DelimSpan, LazyTokenStream, Spacing, TokenStream, TokenTree};\n-use rustc_ast::{self as ast, AstLike, AttrItem, Attribute, MetaItem};\n+use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n+use rustc_ast::tokenstream::{DelimSpan, Spacing};\n+use rustc_ast::tokenstream::{LazyTokenStream, TokenTree};\n+use rustc_ast::{self as ast, AstLike, AttrItem, AttrStyle, Attribute, MetaItem};\n use rustc_attr as attr;\n use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::map_in_place::MapInPlace;\n@@ -23,7 +25,10 @@ use rustc_span::{Span, DUMMY_SP};\n pub struct StripUnconfigured<'a> {\n     pub sess: &'a Session,\n     pub features: Option<&'a Features>,\n-    pub modified: bool,\n+    /// If `true`, perform cfg-stripping on attached tokens.\n+    /// This is only used for the input to derive macros,\n+    /// which needs eager expansion of `cfg` and `cfg_attr`\n+    pub config_tokens: bool,\n }\n \n fn get_features(\n@@ -194,7 +199,7 @@ fn get_features(\n \n // `cfg_attr`-process the crate's attributes and compute the crate's features.\n pub fn features(sess: &Session, mut krate: ast::Crate) -> (ast::Crate, Features) {\n-    let mut strip_unconfigured = StripUnconfigured { sess, features: None, modified: false };\n+    let mut strip_unconfigured = StripUnconfigured { sess, features: None, config_tokens: false };\n \n     let unconfigured_attrs = krate.attrs.clone();\n     let diag = &sess.parse_sess.span_diagnostic;\n@@ -241,24 +246,83 @@ impl<'a> StripUnconfigured<'a> {\n     pub fn configure<T: AstLike>(&mut self, mut node: T) -> Option<T> {\n         self.process_cfg_attrs(&mut node);\n         if self.in_cfg(node.attrs()) {\n+            self.try_configure_tokens(&mut node);\n             Some(node)\n         } else {\n-            self.modified = true;\n             None\n         }\n     }\n \n+    fn try_configure_tokens<T: AstLike>(&mut self, node: &mut T) {\n+        if self.config_tokens {\n+            if let Some(Some(tokens)) = node.tokens_mut() {\n+                let attr_annotated_tokens = tokens.create_token_stream();\n+                *tokens = LazyTokenStream::new(self.configure_tokens(&attr_annotated_tokens));\n+            }\n+        }\n+    }\n+\n     fn configure_krate_attrs(\n         &mut self,\n         mut attrs: Vec<ast::Attribute>,\n     ) -> Option<Vec<ast::Attribute>> {\n         attrs.flat_map_in_place(|attr| self.process_cfg_attr(attr));\n-        if self.in_cfg(&attrs) {\n-            Some(attrs)\n-        } else {\n-            self.modified = true;\n-            None\n+        if self.in_cfg(&attrs) { Some(attrs) } else { None }\n+    }\n+\n+    /// Performs cfg-expansion on `stream`, producing a new `AttrAnnotatedTokenStream`.\n+    /// This is only used during the invocation of `derive` proc-macros,\n+    /// which require that we cfg-expand their entire input.\n+    /// Normal cfg-expansion operates on parsed AST nodes via the `configure` method\n+    fn configure_tokens(&mut self, stream: &AttrAnnotatedTokenStream) -> AttrAnnotatedTokenStream {\n+        fn can_skip(stream: &AttrAnnotatedTokenStream) -> bool {\n+            stream.0.iter().all(|(tree, _spacing)| match tree {\n+                AttrAnnotatedTokenTree::Attributes(_) => false,\n+                AttrAnnotatedTokenTree::Token(_) => true,\n+                AttrAnnotatedTokenTree::Delimited(_, _, inner) => can_skip(inner),\n+            })\n+        }\n+\n+        if can_skip(stream) {\n+            return stream.clone();\n         }\n+\n+        let trees: Vec<_> = stream\n+            .0\n+            .iter()\n+            .flat_map(|(tree, spacing)| match tree.clone() {\n+                AttrAnnotatedTokenTree::Attributes(mut data) => {\n+                    let mut attrs: Vec<_> = std::mem::take(&mut data.attrs).into();\n+                    attrs.flat_map_in_place(|attr| self.process_cfg_attr(attr));\n+                    data.attrs = attrs.into();\n+\n+                    if self.in_cfg(&data.attrs) {\n+                        data.tokens = LazyTokenStream::new(\n+                            self.configure_tokens(&data.tokens.create_token_stream()),\n+                        );\n+                        Some((AttrAnnotatedTokenTree::Attributes(data), *spacing)).into_iter()\n+                    } else {\n+                        None.into_iter()\n+                    }\n+                }\n+                AttrAnnotatedTokenTree::Delimited(sp, delim, mut inner) => {\n+                    inner = self.configure_tokens(&inner);\n+                    Some((AttrAnnotatedTokenTree::Delimited(sp, delim, inner), *spacing))\n+                        .into_iter()\n+                }\n+                AttrAnnotatedTokenTree::Token(token) => {\n+                    if let TokenKind::Interpolated(nt) = token.kind {\n+                        panic!(\n+                            \"Nonterminal should have been flattened at {:?}: {:?}\",\n+                            token.span, nt\n+                        );\n+                    } else {\n+                        Some((AttrAnnotatedTokenTree::Token(token), *spacing)).into_iter()\n+                    }\n+                }\n+            })\n+            .collect();\n+        AttrAnnotatedTokenStream::new(trees)\n     }\n \n     /// Parse and expand all `cfg_attr` attributes into a list of attributes\n@@ -285,9 +349,6 @@ impl<'a> StripUnconfigured<'a> {\n             return vec![attr];\n         }\n \n-        // A `#[cfg_attr]` either gets removed, or replaced with a new attribute\n-        self.modified = true;\n-\n         let (cfg_predicate, expanded_attrs) = match self.parse_cfg_attr(&attr) {\n             None => return vec![],\n             Some(r) => r,\n@@ -311,7 +372,7 @@ impl<'a> StripUnconfigured<'a> {\n         expanded_attrs\n             .into_iter()\n             .flat_map(|(item, span)| {\n-                let orig_tokens = attr.tokens();\n+                let orig_tokens = attr.tokens().to_tokenstream();\n \n                 // We are taking an attribute of the form `#[cfg_attr(pred, attr)]`\n                 // and producing an attribute of the form `#[attr]`. We\n@@ -321,25 +382,34 @@ impl<'a> StripUnconfigured<'a> {\n \n                 // Use the `#` in `#[cfg_attr(pred, attr)]` as the `#` token\n                 // for `attr` when we expand it to `#[attr]`\n-                let pound_token = orig_tokens.trees().next().unwrap();\n-                if !matches!(pound_token, TokenTree::Token(Token { kind: TokenKind::Pound, .. })) {\n-                    panic!(\"Bad tokens for attribute {:?}\", attr);\n+                let mut orig_trees = orig_tokens.trees();\n+                let pound_token = match orig_trees.next().unwrap() {\n+                    TokenTree::Token(token @ Token { kind: TokenKind::Pound, .. }) => token,\n+                    _ => panic!(\"Bad tokens for attribute {:?}\", attr),\n+                };\n+                let pound_span = pound_token.span;\n+\n+                let mut trees = vec![(AttrAnnotatedTokenTree::Token(pound_token), Spacing::Alone)];\n+                if attr.style == AttrStyle::Inner {\n+                    // For inner attributes, we do the same thing for the `!` in `#![some_attr]`\n+                    let bang_token = match orig_trees.next().unwrap() {\n+                        TokenTree::Token(token @ Token { kind: TokenKind::Not, .. }) => token,\n+                        _ => panic!(\"Bad tokens for attribute {:?}\", attr),\n+                    };\n+                    trees.push((AttrAnnotatedTokenTree::Token(bang_token), Spacing::Alone));\n                 }\n                 // We don't really have a good span to use for the syntheized `[]`\n                 // in `#[attr]`, so just use the span of the `#` token.\n-                let bracket_group = TokenTree::Delimited(\n-                    DelimSpan::from_single(pound_token.span()),\n+                let bracket_group = AttrAnnotatedTokenTree::Delimited(\n+                    DelimSpan::from_single(pound_span),\n                     DelimToken::Bracket,\n                     item.tokens\n                         .as_ref()\n                         .unwrap_or_else(|| panic!(\"Missing tokens for {:?}\", item))\n                         .create_token_stream(),\n                 );\n-                let tokens = Some(LazyTokenStream::new(TokenStream::new(vec![\n-                    (pound_token, Spacing::Alone),\n-                    (bracket_group, Spacing::Alone),\n-                ])));\n-\n+                trees.push((bracket_group, Spacing::Alone));\n+                let tokens = Some(LazyTokenStream::new(AttrAnnotatedTokenStream::new(trees)));\n                 self.process_cfg_attr(attr::mk_attr_from_item(item, tokens, attr.style, span))\n             })\n             .collect()\n@@ -457,7 +527,8 @@ impl<'a> StripUnconfigured<'a> {\n             self.sess.parse_sess.span_diagnostic.span_err(attr.span, msg);\n         }\n \n-        self.process_cfg_attrs(expr)\n+        self.process_cfg_attrs(expr);\n+        self.try_configure_tokens(&mut *expr);\n     }\n }\n "}, {"sha": "529ef7e4611e277cc8904029fe2bb78a39fb94ca", "filename": "compiler/rustc_expand/src/expand.rs", "status": "modified", "additions": 28, "deletions": 10, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fexpand.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -12,7 +12,7 @@ use rustc_ast::ptr::P;\n use rustc_ast::token;\n use rustc_ast::tokenstream::TokenStream;\n use rustc_ast::visit::{self, AssocCtxt, Visitor};\n-use rustc_ast::{AstLike, AttrItem, AttrStyle, Block, Inline, ItemKind, LitKind, MacArgs};\n+use rustc_ast::{AstLike, AttrItem, Block, Inline, ItemKind, LitKind, MacArgs};\n use rustc_ast::{MacCallStmt, MacStmtStyle, MetaItemKind, ModKind, NestedMetaItem};\n use rustc_ast::{NodeId, PatKind, Path, StmtKind, Unsafe};\n use rustc_ast_pretty::pprust;\n@@ -611,10 +611,15 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n \n         let invocations = {\n             let mut collector = InvocationCollector {\n+                // Non-derive macro invocations cannot see the results of cfg expansion - they\n+                // will either be removed along with the item, or invoked before the cfg/cfg_attr\n+                // attribute is expanded. Therefore, we don't need to configure the tokens\n+                // Derive macros *can* see the results of cfg-expansion - they are handled\n+                // specially in `fully_expand_fragment`\n                 cfg: StripUnconfigured {\n                     sess: &self.cx.sess,\n                     features: self.cx.ecfg.features,\n-                    modified: false,\n+                    config_tokens: false,\n                 },\n                 cx: self.cx,\n                 invocations: Vec::new(),\n@@ -709,13 +714,26 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                 SyntaxExtensionKind::Attr(expander) => {\n                     self.gate_proc_macro_input(&item);\n                     self.gate_proc_macro_attr_item(span, &item);\n-                    let tokens = match attr.style {\n-                        AttrStyle::Outer => item.into_tokens(&self.cx.sess.parse_sess),\n-                        // FIXME: Properly collect tokens for inner attributes\n-                        AttrStyle::Inner => rustc_parse::fake_token_stream(\n+                    let mut fake_tokens = false;\n+                    if let Annotatable::Item(item_inner) = &item {\n+                        if let ItemKind::Mod(_, mod_kind) = &item_inner.kind {\n+                            // FIXME: Collect tokens and use them instead of generating\n+                            // fake ones. These are unstable, so it needs to be\n+                            // fixed prior to stabilization\n+                            // Fake tokens when we are invoking an inner attribute, and:\n+                            fake_tokens = matches!(attr.style, ast::AttrStyle::Inner) &&\n+                                // We are invoking an attribute on the crate root, or an outline\n+                                // module\n+                                (item_inner.ident.name.is_empty() || !matches!(mod_kind, ast::ModKind::Loaded(_, Inline::Yes, _)));\n+                        }\n+                    }\n+                    let tokens = if fake_tokens {\n+                        rustc_parse::fake_token_stream(\n                             &self.cx.sess.parse_sess,\n                             &item.into_nonterminal(),\n-                        ),\n+                        )\n+                    } else {\n+                        item.into_tokens(&self.cx.sess.parse_sess)\n                     };\n                     let attr_item = attr.unwrap_normal_item();\n                     if let MacArgs::Eq(..) = attr_item.args {\n@@ -897,21 +915,21 @@ pub fn parse_ast_fragment<'a>(\n         }\n         AstFragmentKind::TraitItems => {\n             let mut items = SmallVec::new();\n-            while let Some(item) = this.parse_trait_item()? {\n+            while let Some(item) = this.parse_trait_item(ForceCollect::No)? {\n                 items.extend(item);\n             }\n             AstFragment::TraitItems(items)\n         }\n         AstFragmentKind::ImplItems => {\n             let mut items = SmallVec::new();\n-            while let Some(item) = this.parse_impl_item()? {\n+            while let Some(item) = this.parse_impl_item(ForceCollect::No)? {\n                 items.extend(item);\n             }\n             AstFragment::ImplItems(items)\n         }\n         AstFragmentKind::ForeignItems => {\n             let mut items = SmallVec::new();\n-            while let Some(item) = this.parse_foreign_item()? {\n+            while let Some(item) = this.parse_foreign_item(ForceCollect::No)? {\n                 items.extend(item);\n             }\n             AstFragment::ForeignItems(items)"}, {"sha": "3f84979ac05e762bbc26b4bd404c52b2352356a2", "filename": "compiler/rustc_expand/src/proc_macro.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -94,7 +94,7 @@ impl MultiItemModifier for ProcMacroDerive {\n         {\n             TokenTree::token(token::Interpolated(Lrc::new(item)), DUMMY_SP).into()\n         } else {\n-            nt_to_tokenstream(&item, &ecx.sess.parse_sess, CanSynthesizeMissingTokens::Yes)\n+            nt_to_tokenstream(&item, &ecx.sess.parse_sess, CanSynthesizeMissingTokens::No)\n         };\n \n         let server = proc_macro_server::Rustc::new(ecx);"}, {"sha": "905077a48e25a76de0244a5f5cd36a5a210f7a51", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 37, "deletions": 38, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,5 +1,6 @@\n //! The main parser interface.\n \n+#![feature(array_windows)]\n #![feature(crate_visibility_modifier)]\n #![feature(bindings_after_at)]\n #![feature(iter_order_by)]\n@@ -9,9 +10,12 @@\n #![recursion_limit = \"256\"]\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, Nonterminal};\n-use rustc_ast::tokenstream::{self, CanSynthesizeMissingTokens, LazyTokenStream, TokenStream};\n+use rustc_ast::token::{self, Nonterminal, Token, TokenKind};\n+use rustc_ast::tokenstream::{self, AttributesData, CanSynthesizeMissingTokens, LazyTokenStream};\n+use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttrAnnotatedTokenTree};\n+use rustc_ast::tokenstream::{Spacing, TokenStream};\n use rustc_ast::AstLike;\n+use rustc_ast::Attribute;\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::{Diagnostic, FatalError, Level, PResult};\n@@ -21,8 +25,6 @@ use rustc_span::{FileName, SourceFile, Span};\n use std::path::Path;\n use std::str;\n \n-use tracing::debug;\n-\n pub const MACRO_ARGUMENTS: Option<&str> = Some(\"macro arguments\");\n \n #[macro_use]\n@@ -255,19 +257,23 @@ pub fn nt_to_tokenstream(\n     // before we fall back to the stringification.\n \n     let convert_tokens =\n-        |tokens: Option<&LazyTokenStream>| tokens.as_ref().map(|t| t.create_token_stream());\n+        |tokens: Option<&LazyTokenStream>| Some(tokens?.create_token_stream().to_tokenstream());\n \n     let tokens = match *nt {\n-        Nonterminal::NtItem(ref item) => prepend_attrs(sess, &item.attrs, nt, item.tokens.as_ref()),\n+        Nonterminal::NtItem(ref item) => prepend_attrs(&item.attrs, item.tokens.as_ref()),\n         Nonterminal::NtBlock(ref block) => convert_tokens(block.tokens.as_ref()),\n         Nonterminal::NtStmt(ref stmt) => {\n-            let do_prepend = |tokens| prepend_attrs(sess, stmt.attrs(), nt, tokens);\n             if let ast::StmtKind::Empty = stmt.kind {\n-                let tokens: TokenStream =\n-                    tokenstream::TokenTree::token(token::Semi, stmt.span).into();\n-                do_prepend(Some(&LazyTokenStream::new(tokens)))\n+                let tokens = AttrAnnotatedTokenStream::new(vec![(\n+                    tokenstream::AttrAnnotatedTokenTree::Token(Token::new(\n+                        TokenKind::Semi,\n+                        stmt.span,\n+                    )),\n+                    Spacing::Alone,\n+                )]);\n+                prepend_attrs(&stmt.attrs(), Some(&LazyTokenStream::new(tokens)))\n             } else {\n-                do_prepend(stmt.tokens())\n+                prepend_attrs(&stmt.attrs(), stmt.tokens())\n             }\n         }\n         Nonterminal::NtPat(ref pat) => convert_tokens(pat.tokens.as_ref()),\n@@ -283,10 +289,7 @@ pub fn nt_to_tokenstream(\n         Nonterminal::NtVis(ref vis) => convert_tokens(vis.tokens.as_ref()),\n         Nonterminal::NtTT(ref tt) => Some(tt.clone().into()),\n         Nonterminal::NtExpr(ref expr) | Nonterminal::NtLiteral(ref expr) => {\n-            if expr.tokens.is_none() {\n-                debug!(\"missing tokens for expr {:?}\", expr);\n-            }\n-            prepend_attrs(sess, &expr.attrs, nt, expr.tokens.as_ref())\n+            prepend_attrs(&expr.attrs, expr.tokens.as_ref())\n         }\n     };\n \n@@ -295,34 +298,30 @@ pub fn nt_to_tokenstream(\n     } else if matches!(synthesize_tokens, CanSynthesizeMissingTokens::Yes) {\n         return fake_token_stream(sess, nt);\n     } else {\n-        panic!(\"Missing tokens for nt at {:?}: {:?}\", nt.span(), pprust::nonterminal_to_string(nt));\n+        panic!(\n+            \"Missing tokens for nt {:?} at {:?}: {:?}\",\n+            nt,\n+            nt.span(),\n+            pprust::nonterminal_to_string(nt)\n+        );\n     }\n }\n \n+fn prepend_attrs(attrs: &[Attribute], tokens: Option<&LazyTokenStream>) -> Option<TokenStream> {\n+    let tokens = tokens?;\n+    if attrs.is_empty() {\n+        return Some(tokens.create_token_stream().to_tokenstream());\n+    }\n+    let attr_data = AttributesData { attrs: attrs.to_vec().into(), tokens: tokens.clone() };\n+    let wrapped = AttrAnnotatedTokenStream::new(vec![(\n+        AttrAnnotatedTokenTree::Attributes(attr_data),\n+        Spacing::Alone,\n+    )]);\n+    Some(wrapped.to_tokenstream())\n+}\n+\n pub fn fake_token_stream(sess: &ParseSess, nt: &Nonterminal) -> TokenStream {\n     let source = pprust::nonterminal_to_string(nt);\n     let filename = FileName::macro_expansion_source_code(&source);\n     parse_stream_from_source_str(filename, source, sess, Some(nt.span()))\n }\n-\n-fn prepend_attrs(\n-    sess: &ParseSess,\n-    attrs: &[ast::Attribute],\n-    nt: &Nonterminal,\n-    tokens: Option<&tokenstream::LazyTokenStream>,\n-) -> Option<tokenstream::TokenStream> {\n-    if attrs.is_empty() {\n-        return Some(tokens?.create_token_stream());\n-    }\n-    let mut builder = tokenstream::TokenStreamBuilder::new();\n-    for attr in attrs {\n-        // FIXME: Correctly handle tokens for inner attributes.\n-        // For now, we fall back to reparsing the original AST node\n-        if attr.style == ast::AttrStyle::Inner {\n-            return Some(fake_token_stream(sess, nt));\n-        }\n-        builder.push(attr.tokens());\n-    }\n-    builder.push(tokens?.create_token_stream());\n-    Some(builder.build())\n-}"}, {"sha": "ee6ff4dba396ae66e2d46bacfa9d154a86d65e35", "filename": "compiler/rustc_parse/src/parser/attr.rs", "status": "modified", "additions": 20, "deletions": 2, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,10 +1,11 @@\n-use super::{AttrWrapper, Parser, PathStyle};\n+use super::{AttrWrapper, Capturing, Parser, PathStyle};\n use rustc_ast as ast;\n use rustc_ast::attr;\n use rustc_ast::token::{self, Nonterminal};\n use rustc_ast_pretty::pprust;\n use rustc_errors::{error_code, PResult};\n use rustc_span::{sym, Span};\n+use std::convert::TryInto;\n \n use tracing::debug;\n \n@@ -29,6 +30,7 @@ impl<'a> Parser<'a> {\n     pub(super) fn parse_outer_attributes(&mut self) -> PResult<'a, AttrWrapper> {\n         let mut attrs: Vec<ast::Attribute> = Vec::new();\n         let mut just_parsed_doc_comment = false;\n+        let start_pos = self.token_cursor.num_next_calls;\n         loop {\n             debug!(\"parse_outer_attributes: self.token={:?}\", self.token);\n             let attr = if self.check(&token::Pound) {\n@@ -74,7 +76,7 @@ impl<'a> Parser<'a> {\n                 break;\n             }\n         }\n-        Ok(AttrWrapper::new(attrs))\n+        Ok(AttrWrapper::new(attrs.into(), start_pos))\n     }\n \n     /// Matches `attribute = # ! [ meta_item ]`.\n@@ -177,6 +179,7 @@ impl<'a> Parser<'a> {\n     crate fn parse_inner_attributes(&mut self) -> PResult<'a, Vec<ast::Attribute>> {\n         let mut attrs: Vec<ast::Attribute> = vec![];\n         loop {\n+            let start_pos: u32 = self.token_cursor.num_next_calls.try_into().unwrap();\n             // Only try to parse if it is an inner attribute (has `!`).\n             let attr = if self.check(&token::Pound) && self.look_ahead(1, |t| t == &token::Not) {\n                 Some(self.parse_attribute(InnerAttrPolicy::Permitted)?)\n@@ -191,6 +194,18 @@ impl<'a> Parser<'a> {\n                 None\n             };\n             if let Some(attr) = attr {\n+                let end_pos: u32 = self.token_cursor.num_next_calls.try_into().unwrap();\n+                // If we are currently capturing tokens, mark the location of this inner attribute.\n+                // If capturing ends up creating a `LazyTokenStream`, we will include\n+                // this replace range with it, removing the inner attribute from the final\n+                // `AttrAnnotatedTokenStream`. Inner attributes are stored in the parsed AST note.\n+                // During macro expansion, they are selectively inserted back into the\n+                // token stream (the first inner attribute is remoevd each time we invoke the\n+                // corresponding macro).\n+                let range = start_pos..end_pos;\n+                if let Capturing::Yes = self.capture_state.capturing {\n+                    self.capture_state.inner_attr_ranges.insert(attr.id, (range, vec![]));\n+                }\n                 attrs.push(attr);\n             } else {\n                 break;\n@@ -311,6 +326,9 @@ pub fn maybe_needs_tokens(attrs: &[ast::Attribute]) -> bool {\n     // One of the attributes may either itself be a macro,\n     // or expand to macro attributes (`cfg_attr`).\n     attrs.iter().any(|attr| {\n+        if attr.is_doc_comment() {\n+            return false;\n+        }\n         attr.ident().map_or(true, |ident| {\n             ident.name == sym::cfg_attr || !rustc_feature::is_builtin_attr_name(ident.name)\n         })"}, {"sha": "35759a396e87cb3786422ed3446e67af25b23975", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 406, "deletions": 111, "changes": 517, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,12 +1,14 @@\n-use super::attr;\n-use super::{ForceCollect, Parser, TokenCursor, TrailingToken};\n-use rustc_ast::token::{self, Token, TokenKind};\n-use rustc_ast::tokenstream::{CreateTokenStream, TokenStream, TokenTree, TreeAndSpacing};\n-use rustc_ast::tokenstream::{DelimSpan, LazyTokenStream, Spacing};\n-use rustc_ast::AstLike;\n+use super::{Capturing, FlatToken, ForceCollect, Parser, ReplaceRange, TokenCursor, TrailingToken};\n+use rustc_ast::token::{self, DelimToken, Token, TokenKind};\n+use rustc_ast::tokenstream::{AttrAnnotatedTokenStream, AttributesData, CreateTokenStream};\n+use rustc_ast::tokenstream::{AttrAnnotatedTokenTree, DelimSpan, LazyTokenStream, Spacing};\n use rustc_ast::{self as ast};\n+use rustc_ast::{AstLike, AttrVec, Attribute};\n use rustc_errors::PResult;\n-use rustc_span::{Span, DUMMY_SP};\n+use rustc_span::{sym, Span, DUMMY_SP};\n+\n+use std::convert::TryInto;\n+use std::ops::Range;\n \n /// A wrapper type to ensure that the parser handles outer attributes correctly.\n /// When we parse outer attributes, we need to ensure that we capture tokens\n@@ -23,23 +25,158 @@ use rustc_span::{Span, DUMMY_SP};\n /// cannot directly access the `attrs` field\n #[derive(Debug, Clone)]\n pub struct AttrWrapper {\n-    attrs: Vec<ast::Attribute>,\n+    attrs: AttrVec,\n+    // The start of the outer attributes in the token cursor.\n+    // This allows us to create a `ReplaceRange` for the entire attribute\n+    // target, including outer attributes.\n+    start_pos: usize,\n }\n \n+// This struct is passed around very frequently,\n+// so make sure it doesn't accidentally get larger\n+#[cfg(target_arch = \"x86_64\")]\n+rustc_data_structures::static_assert_size!(AttrWrapper, 16);\n+\n impl AttrWrapper {\n-    pub fn empty() -> AttrWrapper {\n-        AttrWrapper { attrs: vec![] }\n+    pub(super) fn new(attrs: AttrVec, start_pos: usize) -> AttrWrapper {\n+        AttrWrapper { attrs, start_pos }\n     }\n-    pub fn new(attrs: Vec<ast::Attribute>) -> AttrWrapper {\n-        AttrWrapper { attrs }\n+    pub fn empty() -> AttrWrapper {\n+        AttrWrapper { attrs: AttrVec::new(), start_pos: usize::MAX }\n     }\n     // FIXME: Delay span bug here?\n-    pub(crate) fn take_for_recovery(self) -> Vec<ast::Attribute> {\n+    pub(crate) fn take_for_recovery(self) -> AttrVec {\n         self.attrs\n     }\n+\n+    // FIXME: require passing an NT to prevent misuse of this method\n+    pub(crate) fn prepend_to_nt_inner(self, attrs: &mut Vec<Attribute>) {\n+        let mut self_attrs: Vec<_> = self.attrs.into();\n+        std::mem::swap(attrs, &mut self_attrs);\n+        attrs.extend(self_attrs);\n+    }\n+\n     pub fn is_empty(&self) -> bool {\n         self.attrs.is_empty()\n     }\n+\n+    pub fn maybe_needs_tokens(&self) -> bool {\n+        crate::parser::attr::maybe_needs_tokens(&self.attrs)\n+    }\n+}\n+\n+/// Returns `true` if `attrs` contains a `cfg` or `cfg_attr` attribute\n+fn has_cfg_or_cfg_attr(attrs: &[Attribute]) -> bool {\n+    // NOTE: Builtin attributes like `cfg` and `cfg_attr` cannot be renamed via imports.\n+    // Therefore, the absence of a literal `cfg` or `cfg_attr` guarantees that\n+    // we don't need to do any eager expansion.\n+    attrs.iter().any(|attr| {\n+        attr.ident().map_or(false, |ident| ident.name == sym::cfg || ident.name == sym::cfg_attr)\n+    })\n+}\n+\n+// Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n+// and `num_calls`, we can reconstruct the `TokenStream` seen\n+// by the callback. This allows us to avoid producing a `TokenStream`\n+// if it is never needed - for example, a captured `macro_rules!`\n+// argument that is never passed to a proc macro.\n+// In practice token stream creation happens rarely compared to\n+// calls to `collect_tokens` (see some statistics in #78736),\n+// so we are doing as little up-front work as possible.\n+//\n+// This also makes `Parser` very cheap to clone, since\n+// there is no intermediate collection buffer to clone.\n+#[derive(Clone)]\n+struct LazyTokenStreamImpl {\n+    start_token: (Token, Spacing),\n+    cursor_snapshot: TokenCursor,\n+    num_calls: usize,\n+    break_last_token: bool,\n+    replace_ranges: Box<[ReplaceRange]>,\n+}\n+\n+#[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n+rustc_data_structures::static_assert_size!(LazyTokenStreamImpl, 144);\n+\n+impl CreateTokenStream for LazyTokenStreamImpl {\n+    fn create_token_stream(&self) -> AttrAnnotatedTokenStream {\n+        // The token produced by the final call to `next` or `next_desugared`\n+        // was not actually consumed by the callback. The combination\n+        // of chaining the initial token and using `take` produces the desired\n+        // result - we produce an empty `TokenStream` if no calls were made,\n+        // and omit the final token otherwise.\n+        let mut cursor_snapshot = self.cursor_snapshot.clone();\n+        let tokens =\n+            std::iter::once((FlatToken::Token(self.start_token.0.clone()), self.start_token.1))\n+                .chain((0..self.num_calls).map(|_| {\n+                    let token = if cursor_snapshot.desugar_doc_comments {\n+                        cursor_snapshot.next_desugared()\n+                    } else {\n+                        cursor_snapshot.next()\n+                    };\n+                    (FlatToken::Token(token.0), token.1)\n+                }))\n+                .take(self.num_calls);\n+\n+        if !self.replace_ranges.is_empty() {\n+            let mut tokens: Vec<_> = tokens.collect();\n+            let mut replace_ranges = self.replace_ranges.clone();\n+            replace_ranges.sort_by_key(|(range, _)| range.start);\n+\n+            #[cfg(debug_assertions)]\n+            {\n+                for [(range, tokens), (next_range, next_tokens)] in replace_ranges.array_windows() {\n+                    assert!(\n+                        range.end <= next_range.start || range.end >= next_range.end,\n+                        \"Replace ranges should either be disjoint or nested: ({:?}, {:?}) ({:?}, {:?})\",\n+                        range,\n+                        tokens,\n+                        next_range,\n+                        next_tokens,\n+                    );\n+                }\n+            }\n+\n+            // Process the replace ranges, starting from the highest start\n+            // position and working our way back. If have tokens like:\n+            //\n+            // `#[cfg(FALSE)]` struct Foo { #[cfg(FALSE)] field: bool }`\n+            //\n+            // Then we will generate replace ranges for both\n+            // the `#[cfg(FALSE)] field: bool` and the entire\n+            // `#[cfg(FALSE)]` struct Foo { #[cfg(FALSE)] field: bool }`\n+            //\n+            // By starting processing from the replace range with the greatest\n+            // start position, we ensure that any replace range which encloses\n+            // another replace range will capture the *replaced* tokens for the inner\n+            // range, not the original tokens.\n+            for (range, new_tokens) in replace_ranges.iter().rev() {\n+                assert!(!range.is_empty(), \"Cannot replace an empty range: {:?}\", range);\n+                // Replace ranges are only allowed to decrease the number of tokens.\n+                assert!(\n+                    range.len() >= new_tokens.len(),\n+                    \"Range {:?} has greater len than {:?}\",\n+                    range,\n+                    new_tokens\n+                );\n+\n+                // Replace any removed tokens with `FlatToken::Empty`.\n+                // This keeps the total length of `tokens` constant throughout the\n+                // replacement process, allowing us to use all of the `ReplaceRanges` entries\n+                // without adjusting indices.\n+                let filler = std::iter::repeat((FlatToken::Empty, Spacing::Alone))\n+                    .take(range.len() - new_tokens.len());\n+\n+                tokens.splice(\n+                    (range.start as usize)..(range.end as usize),\n+                    new_tokens.clone().into_iter().chain(filler),\n+                );\n+            }\n+            make_token_stream(tokens.into_iter(), self.break_last_token)\n+        } else {\n+            make_token_stream(tokens, self.break_last_token)\n+        }\n+    }\n }\n \n impl<'a> Parser<'a> {\n@@ -65,150 +202,308 @@ impl<'a> Parser<'a> {\n         force_collect: ForceCollect,\n         f: impl FnOnce(&mut Self, Vec<ast::Attribute>) -> PResult<'a, (R, TrailingToken)>,\n     ) -> PResult<'a, R> {\n-        if matches!(force_collect, ForceCollect::No) && !attr::maybe_needs_tokens(&attrs.attrs) {\n-            return Ok(f(self, attrs.attrs)?.0);\n+        // We only bail out when nothing could possibly observe the collected tokens:\n+        // 1. We cannot be force collecting tokens (since force-collecting requires tokens\n+        //    by definition\n+        if matches!(force_collect, ForceCollect::No)\n+            // None of our outer attributes can require tokens (e.g. a proc-macro)\n+            && !attrs.maybe_needs_tokens()\n+            // If our target supports custom inner attributes, then we cannot bail\n+            // out early, since we may need to capture tokens for a custom inner attribute\n+            // invocation.\n+            && !R::SUPPORTS_CUSTOM_INNER_ATTRS\n+            // Never bail out early in `capture_cfg` mode, since there might be `#[cfg]`\n+            // or `#[cfg_attr]` attributes.\n+            && !self.capture_cfg\n+        {\n+            return Ok(f(self, attrs.attrs.into())?.0);\n         }\n+\n         let start_token = (self.token.clone(), self.token_spacing);\n         let cursor_snapshot = self.token_cursor.clone();\n \n-        let (mut ret, trailing_token) = f(self, attrs.attrs)?;\n-        let tokens = match ret.tokens_mut() {\n-            Some(tokens) if tokens.is_none() => tokens,\n-            _ => return Ok(ret),\n-        };\n+        let has_outer_attrs = !attrs.attrs.is_empty();\n+        let prev_capturing = std::mem::replace(&mut self.capture_state.capturing, Capturing::Yes);\n+        let replace_ranges_start = self.capture_state.replace_ranges.len();\n+\n+        let ret = f(self, attrs.attrs.into());\n+\n+        self.capture_state.capturing = prev_capturing;\n+\n+        let (mut ret, trailing) = ret?;\n \n-        // Produces a `TokenStream` on-demand. Using `cursor_snapshot`\n-        // and `num_calls`, we can reconstruct the `TokenStream` seen\n-        // by the callback. This allows us to avoid producing a `TokenStream`\n-        // if it is never needed - for example, a captured `macro_rules!`\n-        // argument that is never passed to a proc macro.\n-        // In practice token stream creation happens rarely compared to\n-        // calls to `collect_tokens` (see some statistics in #78736),\n-        // so we are doing as little up-front work as possible.\n-        //\n-        // This also makes `Parser` very cheap to clone, since\n-        // there is no intermediate collection buffer to clone.\n-        #[derive(Clone)]\n-        struct LazyTokenStreamImpl {\n-            start_token: (Token, Spacing),\n-            cursor_snapshot: TokenCursor,\n-            num_calls: usize,\n-            desugar_doc_comments: bool,\n-            append_unglued_token: Option<TreeAndSpacing>,\n+        // When we're not in `capture-cfg` mode, then bail out early if:\n+        // 1. Our target doesn't support tokens at all (e.g we're parsing an `NtIdent`)\n+        //    so there's nothing for us to do.\n+        // 2. Our target already has tokens set (e.g. we've parsed something\n+        // like `#[my_attr] $item`. The actual parsing code takes care of prepending\n+        // any attributes to the nonterminal, so we don't need to modify the\n+        // already captured tokens.\n+        // Note that this check is independent of `force_collect`- if we already\n+        // have tokens, or can't even store them, then there's never a need to\n+        // force collection of new tokens.\n+        if !self.capture_cfg && matches!(ret.tokens_mut(), None | Some(Some(_))) {\n+            return Ok(ret);\n+        }\n+\n+        // This is very similar to the bail out check at the start of this function.\n+        // Now that we've parsed an AST node, we have more information available.\n+        if matches!(force_collect, ForceCollect::No)\n+            // We now have inner attributes available, so this check is more precise\n+            // than `attrs.maybe_needs_tokens()` at the start of the function.\n+            // As a result, we don't need to check `R::SUPPORTS_CUSTOM_INNER_ATTRS`\n+            && !crate::parser::attr::maybe_needs_tokens(ret.attrs())\n+            // Subtle: We call `has_cfg_or_cfg_attr` with the attrs from `ret`.\n+            // This ensures that we consider inner attributes (e.g. `#![cfg]`),\n+            // which require us to have tokens available\n+            // We also call `has_cfg_or_cfg_attr` at the beginning of this function,\n+            // but we only bail out if there's no possibility of inner attributes\n+            // (!R::SUPPORTS_CUSTOM_INNER_ATTRS)\n+            // We only catpure about `#[cfg]` or `#[cfg_attr]` in `capture_cfg`\n+            // mode - during normal parsing, we don't need any special capturing\n+            // for those attributes, since they're builtin.\n+            && !(self.capture_cfg && has_cfg_or_cfg_attr(ret.attrs()))\n+        {\n+            return Ok(ret);\n         }\n-        impl CreateTokenStream for LazyTokenStreamImpl {\n-            fn create_token_stream(&self) -> TokenStream {\n-                if self.num_calls == 0 {\n-                    return TokenStream::new(vec![]);\n-                }\n \n-                let mut cursor_snapshot = self.cursor_snapshot.clone();\n-                // Don't skip `None` delimiters, since we want to pass them to\n-                // proc macros. Normally, we'll end up capturing `TokenKind::Interpolated`,\n-                // which gets converted to a `None`-delimited group when we invoke\n-                // a proc-macro. However, it's possible to already have a `None`-delimited\n-                // group in the stream (such as when parsing the output of a proc-macro,\n-                // or in certain unusual cases with cross-crate `macro_rules!` macros).\n-                cursor_snapshot.skip_none_delims = false;\n-\n-                // The token produced by the final call to `next` or `next_desugared`\n-                // was not actually consumed by the callback.\n-                let num_calls = self.num_calls - 1;\n-                let mut i = 0;\n-                let tokens =\n-                    std::iter::once(self.start_token.clone()).chain(std::iter::from_fn(|| {\n-                        if i >= num_calls {\n-                            return None;\n-                        }\n-\n-                        let token = if self.desugar_doc_comments {\n-                            cursor_snapshot.next_desugared()\n-                        } else {\n-                            cursor_snapshot.next()\n-                        };\n-\n-                        // When the `LazyTokenStreamImpl` was original produced, we did *not*\n-                        // include `NoDelim` tokens in `num_calls`, since they are normally ignored\n-                        // by the parser. Therefore, we only increment our counter for other types of tokens.\n-                        if !matches!(\n-                            token.0.kind,\n-                            token::OpenDelim(token::NoDelim) | token::CloseDelim(token::NoDelim)\n-                        ) {\n-                            i += 1;\n-                        }\n-                        Some(token)\n-                    }));\n-\n-                make_token_stream(tokens, self.append_unglued_token.clone())\n+        let mut inner_attr_replace_ranges = Vec::new();\n+        // Take the captured ranges for any inner attributes that we parsed.\n+        for inner_attr in ret.attrs().iter().filter(|a| a.style == ast::AttrStyle::Inner) {\n+            if let Some(attr_range) = self.capture_state.inner_attr_ranges.remove(&inner_attr.id) {\n+                inner_attr_replace_ranges.push(attr_range);\n+            } else {\n+                self.sess\n+                    .span_diagnostic\n+                    .delay_span_bug(inner_attr.span, \"Missing token range for attribute\");\n             }\n         }\n \n-        let mut num_calls = self.token_cursor.num_next_calls - cursor_snapshot.num_next_calls;\n-        match trailing_token {\n+        let replace_ranges_end = self.capture_state.replace_ranges.len();\n+\n+        let cursor_snapshot_next_calls = cursor_snapshot.num_next_calls;\n+        let mut end_pos = self.token_cursor.num_next_calls;\n+\n+        // Capture a trailing token if requested by the callback 'f'\n+        match trailing {\n             TrailingToken::None => {}\n             TrailingToken::Semi => {\n                 assert_eq!(self.token.kind, token::Semi);\n-                num_calls += 1;\n+                end_pos += 1;\n             }\n             TrailingToken::MaybeComma => {\n                 if self.token.kind == token::Comma {\n-                    num_calls += 1;\n+                    end_pos += 1;\n                 }\n             }\n         }\n \n-        *tokens = Some(LazyTokenStream::new(LazyTokenStreamImpl {\n+        // If we 'broke' the last token (e.g. breaking a '>>' token to two '>' tokens),\n+        // then extend the range of captured tokens to include it, since the parser\n+        // was not actually bumped past it. When the `LazyTokenStream` gets converted\n+        // into a `AttrAnnotatedTokenStream`, we will create the proper token.\n+        if self.token_cursor.break_last_token {\n+            assert_eq!(\n+                trailing,\n+                TrailingToken::None,\n+                \"Cannot set `break_last_token` and have trailing token\"\n+            );\n+            end_pos += 1;\n+        }\n+\n+        let num_calls = end_pos - cursor_snapshot_next_calls;\n+\n+        // If we have no attributes, then we will never need to\n+        // use any replace ranges.\n+        let replace_ranges: Box<[ReplaceRange]> = if ret.attrs().is_empty() && !self.capture_cfg {\n+            Box::new([])\n+        } else {\n+            // Grab any replace ranges that occur *inside* the current AST node.\n+            // We will perform the actual replacement when we convert the `LazyTokenStream`\n+            // to a `AttrAnnotatedTokenStream`\n+            let start_calls: u32 = cursor_snapshot_next_calls.try_into().unwrap();\n+            self.capture_state.replace_ranges[replace_ranges_start..replace_ranges_end]\n+                .iter()\n+                .cloned()\n+                .chain(inner_attr_replace_ranges.clone().into_iter())\n+                .map(|(range, tokens)| {\n+                    ((range.start - start_calls)..(range.end - start_calls), tokens)\n+                })\n+                .collect()\n+        };\n+\n+        let tokens = LazyTokenStream::new(LazyTokenStreamImpl {\n             start_token,\n             num_calls,\n             cursor_snapshot,\n-            desugar_doc_comments: self.desugar_doc_comments,\n-            append_unglued_token: self.token_cursor.append_unglued_token.clone(),\n-        }));\n+            break_last_token: self.token_cursor.break_last_token,\n+            replace_ranges,\n+        });\n+\n+        // If we support tokens at all\n+        if let Some(target_tokens) = ret.tokens_mut() {\n+            if let Some(target_tokens) = target_tokens {\n+                assert!(\n+                    !self.capture_cfg,\n+                    \"Encountered existing tokens with capture_cfg set: {:?}\",\n+                    target_tokens\n+                );\n+            } else {\n+                // Store se our newly captured tokens into the AST node\n+                *target_tokens = Some(tokens.clone());\n+            };\n+        }\n \n+        let final_attrs = ret.attrs();\n+\n+        // If `capture_cfg` is set and we're inside a recursive call to\n+        // `collect_tokens_trailing_token`, then we need to register a replace range\n+        // if we have `#[cfg]` or `#[cfg_attr]`. This allows us to run eager cfg-expansion\n+        // on the captured token stream.\n+        if self.capture_cfg\n+            && matches!(self.capture_state.capturing, Capturing::Yes)\n+            && has_cfg_or_cfg_attr(&final_attrs)\n+        {\n+            let attr_data = AttributesData { attrs: final_attrs.to_vec().into(), tokens };\n+\n+            // Replace the entire AST node that we just parsed, including attributes,\n+            // with a `FlatToken::AttrTarget`. If this AST node is inside an item\n+            // that has `#[derive]`, then this will allow us to cfg-expand this\n+            // AST node.\n+            let start_pos =\n+                if has_outer_attrs { attrs.start_pos } else { cursor_snapshot_next_calls };\n+            let new_tokens = vec![(FlatToken::AttrTarget(attr_data), Spacing::Alone)];\n+\n+            assert!(\n+                !self.token_cursor.break_last_token,\n+                \"Should not have unglued last token with cfg attr\"\n+            );\n+            let range: Range<u32> = (start_pos.try_into().unwrap())..(end_pos.try_into().unwrap());\n+            self.capture_state.replace_ranges.push((range, new_tokens));\n+            self.capture_state.replace_ranges.extend(inner_attr_replace_ranges);\n+        }\n+\n+        // Only clear our `replace_ranges` when we're finished capturing entirely.\n+        if matches!(self.capture_state.capturing, Capturing::No) {\n+            self.capture_state.replace_ranges.clear();\n+            // We don't clear `inner_attr_ranges`, as doing so repeatedly\n+            // had a measureable performance impact. Most inner attributes that\n+            // we insert will get removed - when we drop the parser, we'll free\n+            // up the memory used by any attributes that we didn't remove from the map.\n+        }\n         Ok(ret)\n     }\n }\n \n /// Converts a flattened iterator of tokens (including open and close delimiter tokens)\n /// into a `TokenStream`, creating a `TokenTree::Delimited` for each matching pair\n /// of open and close delims.\n+// FIXME(#67062): Currently, we don't parse `None`-delimited groups correctly,\n+// which can cause us to end up with mismatched `None` delimiters in our\n+// captured tokens. This function contains several hacks to work around this -\n+// essentially, we throw away mismatched `None` delimiters when we encounter them.\n+// Once we properly parse `None` delimiters, they can be captured just like any\n+// other tokens, and these hacks can be removed.\n fn make_token_stream(\n-    tokens: impl Iterator<Item = (Token, Spacing)>,\n-    append_unglued_token: Option<TreeAndSpacing>,\n-) -> TokenStream {\n+    mut iter: impl Iterator<Item = (FlatToken, Spacing)>,\n+    break_last_token: bool,\n+) -> AttrAnnotatedTokenStream {\n     #[derive(Debug)]\n     struct FrameData {\n         open: Span,\n-        inner: Vec<(TokenTree, Spacing)>,\n+        open_delim: DelimToken,\n+        inner: Vec<(AttrAnnotatedTokenTree, Spacing)>,\n     }\n-    let mut stack = vec![FrameData { open: DUMMY_SP, inner: vec![] }];\n-    for (token, spacing) in tokens {\n+    let mut stack =\n+        vec![FrameData { open: DUMMY_SP, open_delim: DelimToken::NoDelim, inner: vec![] }];\n+    let mut token_and_spacing = iter.next();\n+    while let Some((token, spacing)) = token_and_spacing {\n         match token {\n-            Token { kind: TokenKind::OpenDelim(_), span } => {\n-                stack.push(FrameData { open: span, inner: vec![] });\n+            FlatToken::Token(Token { kind: TokenKind::OpenDelim(delim), span }) => {\n+                stack.push(FrameData { open: span, open_delim: delim, inner: vec![] });\n             }\n-            Token { kind: TokenKind::CloseDelim(delim), span } => {\n-                let frame_data = stack.pop().expect(\"Token stack was empty!\");\n+            FlatToken::Token(Token { kind: TokenKind::CloseDelim(delim), span }) => {\n+                // HACK: If we enconter a mismatched `None` delimiter at the top\n+                // level, just ignore it.\n+                if matches!(delim, DelimToken::NoDelim)\n+                    && (stack.len() == 1\n+                        || !matches!(stack.last_mut().unwrap().open_delim, DelimToken::NoDelim))\n+                {\n+                    token_and_spacing = iter.next();\n+                    continue;\n+                }\n+                let frame_data = stack\n+                    .pop()\n+                    .unwrap_or_else(|| panic!(\"Token stack was empty for token: {:?}\", token));\n+\n+                // HACK: If our current frame has a mismatched opening `None` delimiter,\n+                // merge our current frame with the one above it. That is, transform\n+                // `[ { < first second } third ]` into `[ { first second } third ]`\n+                if !matches!(delim, DelimToken::NoDelim)\n+                    && matches!(frame_data.open_delim, DelimToken::NoDelim)\n+                {\n+                    stack.last_mut().unwrap().inner.extend(frame_data.inner);\n+                    // Process our closing delimiter again, this time at the previous\n+                    // frame in the stack\n+                    token_and_spacing = Some((token, spacing));\n+                    continue;\n+                }\n+\n+                assert_eq!(\n+                    frame_data.open_delim, delim,\n+                    \"Mismatched open/close delims: open={:?} close={:?}\",\n+                    frame_data.open, span\n+                );\n                 let dspan = DelimSpan::from_pair(frame_data.open, span);\n-                let stream = TokenStream::new(frame_data.inner);\n-                let delimited = TokenTree::Delimited(dspan, delim, stream);\n+                let stream = AttrAnnotatedTokenStream::new(frame_data.inner);\n+                let delimited = AttrAnnotatedTokenTree::Delimited(dspan, delim, stream);\n                 stack\n                     .last_mut()\n-                    .unwrap_or_else(|| panic!(\"Bottom token frame is missing for tokens!\"))\n+                    .unwrap_or_else(|| {\n+                        panic!(\"Bottom token frame is missing for token: {:?}\", token)\n+                    })\n                     .inner\n                     .push((delimited, Spacing::Alone));\n             }\n-            token => {\n-                stack\n-                    .last_mut()\n-                    .expect(\"Bottom token frame is missing!\")\n-                    .inner\n-                    .push((TokenTree::Token(token), spacing));\n-            }\n+            FlatToken::Token(token) => stack\n+                .last_mut()\n+                .expect(\"Bottom token frame is missing!\")\n+                .inner\n+                .push((AttrAnnotatedTokenTree::Token(token), spacing)),\n+            FlatToken::AttrTarget(data) => stack\n+                .last_mut()\n+                .expect(\"Bottom token frame is missing!\")\n+                .inner\n+                .push((AttrAnnotatedTokenTree::Attributes(data), spacing)),\n+            FlatToken::Empty => {}\n         }\n+        token_and_spacing = iter.next();\n+    }\n+    // HACK: If we don't have a closing `None` delimiter for our last\n+    // frame, merge the frame with the top-level frame. That is,\n+    // turn `< first second` into `first second`\n+    if stack.len() == 2 && stack[1].open_delim == DelimToken::NoDelim {\n+        let temp_buf = stack.pop().unwrap();\n+        stack.last_mut().unwrap().inner.extend(temp_buf.inner);\n     }\n     let mut final_buf = stack.pop().expect(\"Missing final buf!\");\n-    final_buf.inner.extend(append_unglued_token);\n+    if break_last_token {\n+        let (last_token, spacing) = final_buf.inner.pop().unwrap();\n+        if let AttrAnnotatedTokenTree::Token(last_token) = last_token {\n+            let unglued_first = last_token.kind.break_two_token_op().unwrap().0;\n+\n+            // A 'unglued' token is always two ASCII characters\n+            let mut first_span = last_token.span.shrink_to_lo();\n+            first_span = first_span.with_hi(first_span.lo() + rustc_span::BytePos(1));\n+\n+            final_buf.inner.push((\n+                AttrAnnotatedTokenTree::Token(Token::new(unglued_first, first_span)),\n+                spacing,\n+            ));\n+        } else {\n+            panic!(\"Unexpected last token {:?}\", last_token)\n+        }\n+    }\n     assert!(stack.is_empty(), \"Stack should be empty: final_buf={:?} stack={:?}\", final_buf, stack);\n-    TokenStream::new(final_buf.inner)\n+    AttrAnnotatedTokenStream::new(final_buf.inner)\n }"}, {"sha": "e155b3fa77391919e339bfe1ab5a76b2cfaacf47", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -2581,19 +2581,17 @@ impl<'a> Parser<'a> {\n         attrs: AttrWrapper,\n         f: impl FnOnce(&mut Self, Vec<ast::Attribute>) -> PResult<'a, P<Expr>>,\n     ) -> PResult<'a, P<Expr>> {\n-        // FIXME - come up with a nice way to properly forward `ForceCollect`from\n-        // the nonterminal parsing code. TThis approach iscorrect, but will cause\n-        // us to unnecessarily capture tokens for exprs that have only builtin\n-        // attributes. Revisit this before #![feature(stmt_expr_attributes)] is stabilized\n-        let force_collect = if attrs.is_empty() { ForceCollect::No } else { ForceCollect::Yes };\n-        self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n             let res = f(this, attrs)?;\n             let trailing = if this.restrictions.contains(Restrictions::STMT_EXPR)\n                 && this.token.kind == token::Semi\n             {\n                 TrailingToken::Semi\n             } else {\n-                TrailingToken::None\n+                // FIXME - pass this through from the place where we know\n+                // we need a comma, rather than assuming that `#[attr] expr,`\n+                // always captures a trailing comma\n+                TrailingToken::MaybeComma\n             };\n             Ok((res, trailing))\n         })"}, {"sha": "2b7b58459c0a880cf783a79386622775b58ebbe4", "filename": "compiler/rustc_parse/src/parser/item.rs", "status": "modified", "additions": 29, "deletions": 25, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fitem.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -103,20 +103,11 @@ impl<'a> Parser<'a> {\n         // over when we bump the parser\n         if let token::Interpolated(nt) = &self.token.kind {\n             if let token::NtItem(item) = &**nt {\n-                let item = item.clone();\n-\n-                return self.collect_tokens_trailing_token(\n-                    attrs,\n-                    force_collect,\n-                    |this, mut attrs| {\n-                        let mut item = item;\n-                        mem::swap(&mut item.attrs, &mut attrs);\n-                        item.attrs.extend(attrs);\n-                        // Bump the parser so the we capture the token::Interpolated\n-                        this.bump();\n-                        Ok((Some(item.into_inner()), TrailingToken::None))\n-                    },\n-                );\n+                let mut item = item.clone();\n+                self.bump();\n+\n+                attrs.prepend_to_nt_inner(&mut item.attrs);\n+                return Ok(Some(item.into_inner()));\n             }\n         };\n \n@@ -530,7 +521,7 @@ impl<'a> Parser<'a> {\n \n         generics.where_clause = self.parse_where_clause()?;\n \n-        let impl_items = self.parse_item_list(attrs, |p| p.parse_impl_item())?;\n+        let impl_items = self.parse_item_list(attrs, |p| p.parse_impl_item(ForceCollect::No))?;\n \n         let item_kind = match ty_second {\n             Some(ty_second) => {\n@@ -718,22 +709,32 @@ impl<'a> Parser<'a> {\n         } else {\n             // It's a normal trait.\n             tps.where_clause = self.parse_where_clause()?;\n-            let items = self.parse_item_list(attrs, |p| p.parse_trait_item())?;\n+            let items = self.parse_item_list(attrs, |p| p.parse_trait_item(ForceCollect::No))?;\n             Ok((ident, ItemKind::Trait(box TraitKind(is_auto, unsafety, tps, bounds, items))))\n         }\n     }\n \n-    pub fn parse_impl_item(&mut self) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n-        self.parse_assoc_item(|_| true)\n+    pub fn parse_impl_item(\n+        &mut self,\n+        force_collect: ForceCollect,\n+    ) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n+        self.parse_assoc_item(|_| true, force_collect)\n     }\n \n-    pub fn parse_trait_item(&mut self) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n-        self.parse_assoc_item(|edition| edition >= Edition::Edition2018)\n+    pub fn parse_trait_item(\n+        &mut self,\n+        force_collect: ForceCollect,\n+    ) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n+        self.parse_assoc_item(|edition| edition >= Edition::Edition2018, force_collect)\n     }\n \n     /// Parses associated items.\n-    fn parse_assoc_item(&mut self, req_name: ReqName) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n-        Ok(self.parse_item_(req_name, ForceCollect::No)?.map(\n+    fn parse_assoc_item(\n+        &mut self,\n+        req_name: ReqName,\n+        force_collect: ForceCollect,\n+    ) -> PResult<'a, Option<Option<P<AssocItem>>>> {\n+        Ok(self.parse_item_(req_name, force_collect)?.map(\n             |Item { attrs, id, span, vis, ident, kind, tokens }| {\n                 let kind = match AssocItemKind::try_from(kind) {\n                     Ok(kind) => kind,\n@@ -918,14 +919,17 @@ impl<'a> Parser<'a> {\n         unsafety: Unsafe,\n     ) -> PResult<'a, ItemInfo> {\n         let abi = self.parse_abi(); // ABI?\n-        let items = self.parse_item_list(attrs, |p| p.parse_foreign_item())?;\n+        let items = self.parse_item_list(attrs, |p| p.parse_foreign_item(ForceCollect::No))?;\n         let module = ast::ForeignMod { unsafety, abi, items };\n         Ok((Ident::invalid(), ItemKind::ForeignMod(module)))\n     }\n \n     /// Parses a foreign item (one in an `extern { ... }` block).\n-    pub fn parse_foreign_item(&mut self) -> PResult<'a, Option<Option<P<ForeignItem>>>> {\n-        Ok(self.parse_item_(|_| true, ForceCollect::No)?.map(\n+    pub fn parse_foreign_item(\n+        &mut self,\n+        force_collect: ForceCollect,\n+    ) -> PResult<'a, Option<Option<P<ForeignItem>>>> {\n+        Ok(self.parse_item_(|_| true, force_collect)?.map(\n             |Item { attrs, id, span, vis, ident, kind, tokens }| {\n                 let kind = match ForeignItemKind::try_from(kind) {\n                     Ok(kind) => kind,"}, {"sha": "4b97c8b0a81e1abe10c0be36b8fbb55659073110", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 107, "deletions": 40, "changes": 147, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -19,13 +19,16 @@ pub use path::PathStyle;\n \n use rustc_ast::ptr::P;\n use rustc_ast::token::{self, DelimToken, Token, TokenKind};\n+use rustc_ast::tokenstream::AttributesData;\n use rustc_ast::tokenstream::{self, DelimSpan, Spacing};\n-use rustc_ast::tokenstream::{TokenStream, TokenTree, TreeAndSpacing};\n+use rustc_ast::tokenstream::{TokenStream, TokenTree};\n+use rustc_ast::AttrId;\n use rustc_ast::DUMMY_NODE_ID;\n use rustc_ast::{self as ast, AnonConst, AstLike, AttrStyle, AttrVec, Const, CrateSugar, Extern};\n use rustc_ast::{Async, Expr, ExprKind, MacArgs, MacDelimiter, Mutability, StrLit, Unsafe};\n use rustc_ast::{Visibility, VisibilityKind};\n use rustc_ast_pretty::pprust;\n+use rustc_data_structures::fx::FxHashMap;\n use rustc_data_structures::sync::Lrc;\n use rustc_errors::PResult;\n use rustc_errors::{struct_span_err, Applicability, DiagnosticBuilder, FatalError};\n@@ -34,6 +37,7 @@ use rustc_span::source_map::{Span, DUMMY_SP};\n use rustc_span::symbol::{kw, sym, Ident, Symbol};\n use tracing::debug;\n \n+use std::ops::Range;\n use std::{cmp, mem, slice};\n \n bitflags::bitflags! {\n@@ -64,6 +68,7 @@ pub enum ForceCollect {\n     No,\n }\n \n+#[derive(Debug, Eq, PartialEq)]\n pub enum TrailingToken {\n     None,\n     Semi,\n@@ -111,6 +116,7 @@ pub struct Parser<'a> {\n     pub token_spacing: Spacing,\n     /// The previous token.\n     pub prev_token: Token,\n+    pub capture_cfg: bool,\n     restrictions: Restrictions,\n     expected_tokens: Vec<TokenType>,\n     // Important: This must only be advanced from `next_tok`\n@@ -134,6 +140,44 @@ pub struct Parser<'a> {\n     pub last_type_ascription: Option<(Span, bool /* likely path typo */)>,\n     /// If present, this `Parser` is not parsing Rust code but rather a macro call.\n     subparser_name: Option<&'static str>,\n+    capture_state: CaptureState,\n+}\n+\n+/// Indicates a range of tokens that should be replaced by\n+/// the tokens in the provided vector. This is used in two\n+/// places during token collection:\n+///\n+/// 1. During the parsing of an AST node that may have a `#[derive]`\n+/// attribute, we parse a nested AST node that has `#[cfg]` or `#[cfg_attr]`\n+/// In this case, we use a `ReplaceRange` to replace the entire inner AST node\n+/// with `FlatToken::AttrTarget`, allowing us to perform eager cfg-expansion\n+/// on a `AttrAnnotatedTokenStream`\n+///\n+/// 2. When we parse an inner attribute while collecting tokens. We\n+/// remove inner attributes from the token stream entirely, and\n+/// instead track them through the `attrs` field on the AST node.\n+/// This allows us to easily manipulate them (for example, removing\n+/// the first macro inner attribute to invoke a proc-macro).\n+/// When create a `TokenStream`, the inner attributes get inserted\n+/// into the proper place in the token stream.\n+pub type ReplaceRange = (Range<u32>, Vec<(FlatToken, Spacing)>);\n+\n+/// Controls how we capture tokens. Capturing can be expensive,\n+/// so we try to avoid performing capturing in cases where\n+/// we will never need a `AttrAnnotatedTokenStream`\n+#[derive(Copy, Clone)]\n+pub enum Capturing {\n+    /// We aren't performing any capturing - this is the default mode.\n+    No,\n+    /// We are capturing tokens\n+    Yes,\n+}\n+\n+#[derive(Clone)]\n+struct CaptureState {\n+    capturing: Capturing,\n+    replace_ranges: Vec<ReplaceRange>,\n+    inner_attr_ranges: FxHashMap<AttrId, ReplaceRange>,\n }\n \n impl<'a> Drop for Parser<'a> {\n@@ -167,18 +211,11 @@ struct TokenCursor {\n     // want to capture just the first 'unglued' token.\n     // For example, capturing the `Vec<u8>`\n     // in `Option<Vec<u8>>` requires us to unglue\n-    // the trailing `>>` token. The `append_unglued_token`\n+    // the trailing `>>` token. The `break_last_token`\n     // field is used to track this token - it gets\n     // appended to the captured stream when\n     // we evaluate a `LazyTokenStream`\n-    append_unglued_token: Option<TreeAndSpacing>,\n-    // If `true`, skip the delimiters for `None`-delimited groups,\n-    // and just yield the inner tokens. This is `true` during\n-    // normal parsing, since the parser code is not currently prepared\n-    // to handle `None` delimiters. When capturing a `TokenStream`,\n-    // however, we want to handle `None`-delimiters, since\n-    // proc-macros always see `None`-delimited groups.\n-    skip_none_delims: bool,\n+    break_last_token: bool,\n }\n \n #[derive(Clone)]\n@@ -191,13 +228,13 @@ struct TokenCursorFrame {\n }\n \n impl TokenCursorFrame {\n-    fn new(span: DelimSpan, delim: DelimToken, tts: TokenStream, skip_none_delims: bool) -> Self {\n+    fn new(span: DelimSpan, delim: DelimToken, tts: TokenStream) -> Self {\n         TokenCursorFrame {\n             delim,\n             span,\n-            open_delim: delim == token::NoDelim && skip_none_delims,\n+            open_delim: false,\n             tree_cursor: tts.into_trees(),\n-            close_delim: delim == token::NoDelim && skip_none_delims,\n+            close_delim: false,\n         }\n     }\n }\n@@ -225,7 +262,7 @@ impl TokenCursor {\n                     return (token, spacing);\n                 }\n                 TokenTree::Delimited(sp, delim, tts) => {\n-                    let frame = TokenCursorFrame::new(sp, delim, tts, self.skip_none_delims);\n+                    let frame = TokenCursorFrame::new(sp, delim, tts);\n                     self.stack.push(mem::replace(&mut self.frame, frame));\n                 }\n             }\n@@ -283,7 +320,6 @@ impl TokenCursor {\n                         .cloned()\n                         .collect::<TokenStream>()\n                 },\n-                self.skip_none_delims,\n             ),\n         ));\n \n@@ -372,26 +408,24 @@ impl<'a> Parser<'a> {\n         desugar_doc_comments: bool,\n         subparser_name: Option<&'static str>,\n     ) -> Self {\n+        let mut start_frame = TokenCursorFrame::new(DelimSpan::dummy(), token::NoDelim, tokens);\n+        start_frame.open_delim = true;\n+        start_frame.close_delim = true;\n+\n         let mut parser = Parser {\n             sess,\n             token: Token::dummy(),\n             token_spacing: Spacing::Alone,\n             prev_token: Token::dummy(),\n+            capture_cfg: false,\n             restrictions: Restrictions::empty(),\n             expected_tokens: Vec::new(),\n-            // Skip over the delimiters for `None`-delimited groups\n             token_cursor: TokenCursor {\n-                frame: TokenCursorFrame::new(\n-                    DelimSpan::dummy(),\n-                    token::NoDelim,\n-                    tokens,\n-                    /* skip_none_delims */ true,\n-                ),\n+                frame: start_frame,\n                 stack: Vec::new(),\n                 num_next_calls: 0,\n                 desugar_doc_comments,\n-                append_unglued_token: None,\n-                skip_none_delims: true,\n+                break_last_token: false,\n             },\n             desugar_doc_comments,\n             unmatched_angle_bracket_count: 0,\n@@ -400,6 +434,11 @@ impl<'a> Parser<'a> {\n             last_unexpected_token_span: None,\n             last_type_ascription: None,\n             subparser_name,\n+            capture_state: CaptureState {\n+                capturing: Capturing::No,\n+                replace_ranges: Vec::new(),\n+                inner_attr_ranges: Default::default(),\n+            },\n         };\n \n         // Make parser point to the first token.\n@@ -409,21 +448,29 @@ impl<'a> Parser<'a> {\n     }\n \n     fn next_tok(&mut self, fallback_span: Span) -> (Token, Spacing) {\n-        let (mut next, spacing) = if self.desugar_doc_comments {\n-            self.token_cursor.next_desugared()\n-        } else {\n-            self.token_cursor.next()\n-        };\n-        self.token_cursor.num_next_calls += 1;\n-        // We've retrieved an token from the underlying\n-        // cursor, so we no longer need to worry about\n-        // an unglued token. See `break_and_eat` for more details\n-        self.token_cursor.append_unglued_token = None;\n-        if next.span.is_dummy() {\n-            // Tweak the location for better diagnostics, but keep syntactic context intact.\n-            next.span = fallback_span.with_ctxt(next.span.ctxt());\n+        loop {\n+            let (mut next, spacing) = if self.desugar_doc_comments {\n+                self.token_cursor.next_desugared()\n+            } else {\n+                self.token_cursor.next()\n+            };\n+            self.token_cursor.num_next_calls += 1;\n+            // We've retrieved an token from the underlying\n+            // cursor, so we no longer need to worry about\n+            // an unglued token. See `break_and_eat` for more details\n+            self.token_cursor.break_last_token = false;\n+            if next.span.is_dummy() {\n+                // Tweak the location for better diagnostics, but keep syntactic context intact.\n+                next.span = fallback_span.with_ctxt(next.span.ctxt());\n+            }\n+            if matches!(\n+                next.kind,\n+                token::OpenDelim(token::NoDelim) | token::CloseDelim(token::NoDelim)\n+            ) {\n+                continue;\n+            }\n+            return (next, spacing);\n         }\n-        (next, spacing)\n     }\n \n     pub fn unexpected<T>(&mut self) -> PResult<'a, T> {\n@@ -621,8 +668,7 @@ impl<'a> Parser<'a> {\n                 // If we consume any additional tokens, then this token\n                 // is not needed (we'll capture the entire 'glued' token),\n                 // and `next_tok` will set this field to `None`\n-                self.token_cursor.append_unglued_token =\n-                    Some((TokenTree::Token(self.token.clone()), Spacing::Alone));\n+                self.token_cursor.break_last_token = true;\n                 // Use the spacing of the glued token as the spacing\n                 // of the unglued second token.\n                 self.bump_with((Token::new(second, second_span), self.token_spacing));\n@@ -1304,3 +1350,24 @@ pub fn emit_unclosed_delims(unclosed_delims: &mut Vec<UnmatchedBrace>, sess: &Pa\n         }\n     }\n }\n+\n+/// A helper struct used when building a `AttrAnnotatedTokenStream` from\n+/// a `LazyTokenStream`. Both delimiter and non-delimited tokens\n+/// are stored as `FlatToken::Token`. A vector of `FlatToken`s\n+/// is then 'parsed' to build up a `AttrAnnotatedTokenStream` with nested\n+/// `AttrAnnotatedTokenTree::Delimited` tokens\n+#[derive(Debug, Clone)]\n+pub enum FlatToken {\n+    /// A token - this holds both delimiter (e.g. '{' and '}')\n+    /// and non-delimiter tokens\n+    Token(Token),\n+    /// Holds the `AttributesData` for an AST node. The\n+    /// `AttributesData` is inserted directly into the\n+    /// constructed `AttrAnnotatedTokenStream` as\n+    /// a `AttrAnnotatedTokenTree::Attributes`\n+    AttrTarget(AttributesData),\n+    /// A special 'empty' token that is ignored during the conversion\n+    /// to a `AttrAnnotatedTokenStream`. This is used to simplify the\n+    /// handling of replace ranges.\n+    Empty,\n+}"}, {"sha": "5c4a2785d6e2631d64455e8e265d89c0df822ff0", "filename": "compiler/rustc_parse/src/parser/nonterminal.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fnonterminal.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -153,9 +153,7 @@ impl<'a> Parser<'a> {\n             NonterminalKind::Path => token::NtPath(\n                 self.collect_tokens_no_attrs(|this| this.parse_path(PathStyle::Type))?,\n             ),\n-            NonterminalKind::Meta => {\n-                token::NtMeta(P(self.collect_tokens_no_attrs(|this| this.parse_attr_item(false))?))\n-            }\n+            NonterminalKind::Meta => token::NtMeta(P(self.parse_attr_item(true)?)),\n             NonterminalKind::TT => token::NtTT(self.parse_token_tree()),\n             NonterminalKind::Vis => token::NtVis(\n                 self.collect_tokens_no_attrs(|this| this.parse_visibility(FollowedByType::Yes))?,"}, {"sha": "592f64f4a399fce133b4757986379fd5b0b55993", "filename": "compiler/rustc_parse/src/parser/stmt.rs", "status": "modified", "additions": 33, "deletions": 32, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fstmt.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -48,39 +48,26 @@ impl<'a> Parser<'a> {\n         if let token::Interpolated(nt) = &self.token.kind {\n             if let token::NtStmt(stmt) = &**nt {\n                 let mut stmt = stmt.clone();\n-                return self.collect_tokens_trailing_token(\n-                    attrs,\n-                    force_collect,\n-                    |this, mut attrs| {\n-                        stmt.visit_attrs(|stmt_attrs| {\n-                            mem::swap(stmt_attrs, &mut attrs);\n-                            stmt_attrs.extend(attrs);\n-                        });\n-                        // Make sure we capture the token::Interpolated\n-                        this.bump();\n-                        Ok((Some(stmt), TrailingToken::None))\n-                    },\n-                );\n+                self.bump();\n+                stmt.visit_attrs(|stmt_attrs| {\n+                    attrs.prepend_to_nt_inner(stmt_attrs);\n+                });\n+                return Ok(Some(stmt));\n             }\n         }\n \n         Ok(Some(if self.token.is_keyword(kw::Let) {\n             self.parse_local_mk(lo, attrs, capture_semi, force_collect)?\n         } else if self.is_kw_followed_by_ident(kw::Mut) {\n-            self.recover_stmt_local(\n-                lo,\n-                attrs.take_for_recovery().into(),\n-                \"missing keyword\",\n-                \"let mut\",\n-            )?\n+            self.recover_stmt_local(lo, attrs, \"missing keyword\", \"let mut\")?\n         } else if self.is_kw_followed_by_ident(kw::Auto) {\n             self.bump(); // `auto`\n             let msg = \"write `let` instead of `auto` to introduce a new variable\";\n-            self.recover_stmt_local(lo, attrs.take_for_recovery().into(), msg, \"let\")?\n+            self.recover_stmt_local(lo, attrs, msg, \"let\")?\n         } else if self.is_kw_followed_by_ident(sym::var) {\n             self.bump(); // `var`\n             let msg = \"write `let` instead of `var` to introduce a new variable\";\n-            self.recover_stmt_local(lo, attrs.take_for_recovery().into(), msg, \"let\")?\n+            self.recover_stmt_local(lo, attrs, msg, \"let\")?\n         } else if self.check_path() && !self.token.is_qpath_start() && !self.is_path_start_item() {\n             // We have avoided contextual keywords like `union`, items with `crate` visibility,\n             // or `auto trait` items. We aim to parse an arbitrary path `a::b` but not something\n@@ -112,7 +99,7 @@ impl<'a> Parser<'a> {\n         attrs: AttrWrapper,\n         force_collect: ForceCollect,\n     ) -> PResult<'a, Stmt> {\n-        self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n+        let stmt = self.collect_tokens_trailing_token(attrs, force_collect, |this, attrs| {\n             let path = this.parse_path(PathStyle::Expr)?;\n \n             if this.eat(&token::Not) {\n@@ -132,14 +119,22 @@ impl<'a> Parser<'a> {\n             };\n \n             let expr = this.with_res(Restrictions::STMT_EXPR, |this| {\n-                let expr = this.parse_dot_or_call_expr_with(expr, lo, attrs)?;\n+                this.parse_dot_or_call_expr_with(expr, lo, attrs)\n+            })?;\n+            // `DUMMY_SP` will get overwritten later in this function\n+            Ok((this.mk_stmt(rustc_span::DUMMY_SP, StmtKind::Expr(expr)), TrailingToken::None))\n+        })?;\n+\n+        if let StmtKind::Expr(expr) = stmt.kind {\n+            // Perform this outside of the `collect_tokens_trailing_token` closure,\n+            // since our outer attributes do not apply to this part of the expression\n+            let expr = self.with_res(Restrictions::STMT_EXPR, |this| {\n                 this.parse_assoc_expr_with(0, LhsExpr::AlreadyParsed(expr))\n             })?;\n-            Ok((\n-                this.mk_stmt(lo.to(this.prev_token.span), StmtKind::Expr(expr)),\n-                TrailingToken::None,\n-            ))\n-        })\n+            Ok(self.mk_stmt(lo.to(self.prev_token.span), StmtKind::Expr(expr)))\n+        } else {\n+            Ok(stmt)\n+        }\n     }\n \n     /// Parses a statement macro `mac!(args)` provided a `path` representing `mac`.\n@@ -183,7 +178,7 @@ impl<'a> Parser<'a> {\n     fn recover_stmt_local(\n         &mut self,\n         lo: Span,\n-        attrs: AttrVec,\n+        attrs: AttrWrapper,\n         msg: &str,\n         sugg: &str,\n     ) -> PResult<'a, Stmt> {\n@@ -213,9 +208,15 @@ impl<'a> Parser<'a> {\n         })\n     }\n \n-    fn recover_local_after_let(&mut self, lo: Span, attrs: AttrVec) -> PResult<'a, Stmt> {\n-        let local = self.parse_local(attrs)?;\n-        Ok(self.mk_stmt(lo.to(self.prev_token.span), StmtKind::Local(local)))\n+    fn recover_local_after_let(&mut self, lo: Span, attrs: AttrWrapper) -> PResult<'a, Stmt> {\n+        self.collect_tokens_trailing_token(attrs, ForceCollect::No, |this, attrs| {\n+            let local = this.parse_local(attrs.into())?;\n+            // FIXME - maybe capture semicolon in recovery?\n+            Ok((\n+                this.mk_stmt(lo.to(this.prev_token.span), StmtKind::Local(local)),\n+                TrailingToken::None,\n+            ))\n+        })\n     }\n \n     /// Parses a local variable declaration."}, {"sha": "e9d597d1ba65c322d95af9af7dac561b8b252f8a", "filename": "compiler/rustc_session/src/utils.rs", "status": "modified", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_session%2Fsrc%2Futils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/compiler%2Frustc_session%2Fsrc%2Futils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_session%2Fsrc%2Futils.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,7 +1,13 @@\n+use crate::parse::ParseSess;\n use crate::session::Session;\n+use rustc_ast::token::{self, DelimToken, Nonterminal, Token};\n+use rustc_ast::tokenstream::CanSynthesizeMissingTokens;\n+use rustc_ast::tokenstream::{DelimSpan, TokenStream, TokenTree};\n use rustc_data_structures::profiling::VerboseTimingGuard;\n use std::path::{Path, PathBuf};\n \n+pub type NtToTokenstream = fn(&Nonterminal, &ParseSess, CanSynthesizeMissingTokens) -> TokenStream;\n+\n impl Session {\n     pub fn timer<'a>(&'a self, what: &'static str) -> VerboseTimingGuard<'a> {\n         self.prof.verbose_generic_activity(what)\n@@ -53,3 +59,52 @@ impl CanonicalizedPath {\n         &self.original\n     }\n }\n+\n+// FIXME: Find a better spot for this - it needs to be accessible from `rustc_ast_lowering`,\n+// and needs to access `ParseSess\n+pub struct FlattenNonterminals<'a> {\n+    pub parse_sess: &'a ParseSess,\n+    pub synthesize_tokens: CanSynthesizeMissingTokens,\n+    pub nt_to_tokenstream: NtToTokenstream,\n+}\n+\n+impl<'a> FlattenNonterminals<'a> {\n+    pub fn process_token_stream(&mut self, tokens: TokenStream) -> TokenStream {\n+        fn can_skip(stream: &TokenStream) -> bool {\n+            stream.trees().all(|tree| match tree {\n+                TokenTree::Token(token) => !matches!(token.kind, token::Interpolated(_)),\n+                TokenTree::Delimited(_, _, inner) => can_skip(&inner),\n+            })\n+        }\n+\n+        if can_skip(&tokens) {\n+            return tokens;\n+        }\n+\n+        tokens.into_trees().flat_map(|tree| self.process_token_tree(tree).into_trees()).collect()\n+    }\n+\n+    pub fn process_token_tree(&mut self, tree: TokenTree) -> TokenStream {\n+        match tree {\n+            TokenTree::Token(token) => self.process_token(token),\n+            TokenTree::Delimited(span, delim, tts) => {\n+                TokenTree::Delimited(span, delim, self.process_token_stream(tts)).into()\n+            }\n+        }\n+    }\n+\n+    pub fn process_token(&mut self, token: Token) -> TokenStream {\n+        match token.kind {\n+            token::Interpolated(nt) => {\n+                let tts = (self.nt_to_tokenstream)(&nt, self.parse_sess, self.synthesize_tokens);\n+                TokenTree::Delimited(\n+                    DelimSpan::from_single(token.span),\n+                    DelimToken::NoDelim,\n+                    self.process_token_stream(tts),\n+                )\n+                .into()\n+            }\n+            _ => TokenTree::Token(token).into(),\n+        }\n+    }\n+}"}, {"sha": "72783efe08dba53740d9361f85cf4813c956af05", "filename": "src/test/ui/proc-macro/attr-complex-fn.stdout", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fattr-complex-fn.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fattr-complex-fn.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fattr-complex-fn.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -80,92 +80,92 @@ PRINT-ATTR INPUT (DISPLAY): impl < T > MyTrait < T > for MyStruct < { true } > {\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:1: 21:5 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:5: 21:6 (#0),\n     },\n     Ident {\n         ident: \"T\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:6: 21:7 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:7: 21:8 (#0),\n     },\n     Ident {\n         ident: \"MyTrait\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:9: 21:16 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:16: 21:17 (#0),\n     },\n     Ident {\n         ident: \"T\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:17: 21:18 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:18: 21:19 (#0),\n     },\n     Ident {\n         ident: \"for\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:20: 21:23 (#0),\n     },\n     Ident {\n         ident: \"MyStruct\",\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:24: 21:32 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:32: 21:33 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+                span: $DIR/attr-complex-fn.rs:21:34: 21:38 (#0),\n             },\n         ],\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:33: 21:39 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:39: 21:40 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+                span: $DIR/attr-complex-fn.rs:23:5: 23:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+                span: $DIR/attr-complex-fn.rs:23:6: 23:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"rustc_dummy\",\n-                        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+                        span: $DIR/attr-complex-fn.rs:23:8: 23:19 (#0),\n                     },\n                 ],\n-                span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+                span: $DIR/attr-complex-fn.rs:23:7: 23:20 (#0),\n             },\n         ],\n-        span: $DIR/attr-complex-fn.rs:21:1: 24:2 (#0),\n+        span: $DIR/attr-complex-fn.rs:21:41: 24:2 (#0),\n     },\n ]"}, {"sha": "4c48e41ff338b38c62b93a9fb5660c20a97e90a9", "filename": "src/test/ui/proc-macro/attribute-after-derive.stdout", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fattribute-after-derive.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fattribute-after-derive.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fattribute-after-derive.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -87,62 +87,62 @@ PRINT-DERIVE INPUT (DISPLAY): struct AttributeDerive { }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/attribute-after-derive.rs:18:1: 21:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:18:1: 18:7 (#0),\n     },\n     Ident {\n         ident: \"AttributeDerive\",\n-        span: $DIR/attribute-after-derive.rs:18:1: 21:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:18:8: 18:23 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/attribute-after-derive.rs:18:1: 21:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:18:24: 21:2 (#0),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): #[print_attr] struct DeriveAttribute { }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:24:1: 24:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_attr\",\n-                span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+                span: $DIR/attribute-after-derive.rs:24:3: 24:13 (#0),\n             },\n         ],\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:24:2: 24:14 (#0),\n     },\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:1: 25:7 (#0),\n     },\n     Ident {\n         ident: \"DeriveAttribute\",\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:8: 25:23 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:24: 28:2 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): struct DeriveAttribute { }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:1: 25:7 (#0),\n     },\n     Ident {\n         ident: \"DeriveAttribute\",\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:8: 25:23 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/attribute-after-derive.rs:25:1: 28:2 (#0),\n+        span: $DIR/attribute-after-derive.rs:25:24: 28:2 (#0),\n     },\n ]"}, {"sha": "1f2b00395890853d749d900858e03883c736e776", "filename": "src/test/ui/proc-macro/cfg-eval-inner.stdout", "status": "modified", "additions": 52, "deletions": 57, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval-inner.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval-inner.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval-inner.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -2,251 +2,246 @@ PRINT-ATTR INPUT (DISPLAY): impl Foo <\n [u8 ;\n  {\n      # ! [rustc_dummy(cursed_inner)] # ! [allow(unused)] struct Inner\n-     { field : [u8 ; { # ! [rustc_dummy(another_cursed_inner)] 1 }], } 0\n+     { field : [u8 ; { # ! [rustc_dummy(another_cursed_inner)] 1 }] } 0\n  }] > { # ! [rustc_dummy(evaluated_attr)] fn bar() { } }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:18:1: 18:5 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:18:6: 18:9 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:18:9: 18:10 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"u8\",\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:18:11: 18:13 (#0),\n             },\n             Punct {\n                 ch: ';',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:18:13: 18:14 (#0),\n             },\n             Group {\n                 delimiter: Brace,\n                 stream: TokenStream [\n                     Punct {\n                         ch: '#',\n-                        spacing: Joint,\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        spacing: Alone,\n+                        span: $DIR/cfg-eval-inner.rs:19:5: 19:6 (#0),\n                     },\n                     Punct {\n                         ch: '!',\n                         spacing: Alone,\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:19:6: 19:7 (#0),\n                     },\n                     Group {\n                         delimiter: Bracket,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"rustc_dummy\",\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:19:29: 19:40 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"cursed_inner\",\n-                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                        span: $DIR/cfg-eval-inner.rs:19:41: 19:53 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:19:40: 19:54 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:19:5: 19:6 (#0),\n                     },\n                     Punct {\n                         ch: '#',\n                         spacing: Joint,\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:20:5: 20:6 (#0),\n                     },\n                     Punct {\n                         ch: '!',\n                         spacing: Alone,\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:20:6: 20:7 (#0),\n                     },\n                     Group {\n                         delimiter: Bracket,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"allow\",\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:20:8: 20:13 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"unused\",\n-                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                        span: $DIR/cfg-eval-inner.rs:20:14: 20:20 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:20:13: 20:21 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:20:7: 20:22 (#0),\n                     },\n                     Ident {\n                         ident: \"struct\",\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:21:5: 21:11 (#0),\n                     },\n                     Ident {\n                         ident: \"Inner\",\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:21:12: 21:17 (#0),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"field\",\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:22:9: 22:14 (#0),\n                             },\n                             Punct {\n                                 ch: ':',\n                                 spacing: Alone,\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:22:14: 22:15 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"u8\",\n-                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                        span: $DIR/cfg-eval-inner.rs:22:17: 22:19 (#0),\n                                     },\n                                     Punct {\n                                         ch: ';',\n                                         spacing: Alone,\n-                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                        span: $DIR/cfg-eval-inner.rs:22:19: 22:20 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Brace,\n                                         stream: TokenStream [\n                                             Punct {\n                                                 ch: '#',\n-                                                spacing: Joint,\n-                                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                spacing: Alone,\n+                                                span: $DIR/cfg-eval-inner.rs:23:13: 23:14 (#0),\n                                             },\n                                             Punct {\n                                                 ch: '!',\n                                                 spacing: Alone,\n-                                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                span: $DIR/cfg-eval-inner.rs:23:14: 23:15 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Bracket,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"rustc_dummy\",\n-                                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                        span: $DIR/cfg-eval-inner.rs:23:37: 23:48 (#0),\n                                                     },\n                                                     Group {\n                                                         delimiter: Parenthesis,\n                                                         stream: TokenStream [\n                                                             Ident {\n                                                                 ident: \"another_cursed_inner\",\n-                                                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                                span: $DIR/cfg-eval-inner.rs:23:49: 23:69 (#0),\n                                                             },\n                                                         ],\n-                                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                        span: $DIR/cfg-eval-inner.rs:23:48: 23:70 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                span: $DIR/cfg-eval-inner.rs:23:13: 23:14 (#0),\n                                             },\n                                             Literal {\n                                                 kind: Integer,\n                                                 symbol: \"1\",\n                                                 suffix: None,\n-                                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                                span: $DIR/cfg-eval-inner.rs:24:13: 24:14 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                        span: $DIR/cfg-eval-inner.rs:22:21: 25:10 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n-                            },\n-                            Punct {\n-                                ch: ',',\n-                                spacing: Alone,\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:22:16: 25:11 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:21:18: 26:6 (#0),\n                     },\n                     Literal {\n                         kind: Integer,\n                         symbol: \"0\",\n                         suffix: None,\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:28:5: 28:6 (#0),\n                     },\n                 ],\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:18:15: 29:2 (#0),\n             },\n         ],\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:18:10: 29:3 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:29:3: 29:4 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n-                spacing: Joint,\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                spacing: Alone,\n+                span: $DIR/cfg-eval-inner.rs:32:5: 32:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:32:6: 32:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"rustc_dummy\",\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:32:29: 32:40 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"evaluated_attr\",\n-                                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                                span: $DIR/cfg-eval-inner.rs:32:41: 32:55 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                        span: $DIR/cfg-eval-inner.rs:32:40: 32:56 (#0),\n                     },\n                 ],\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:32:5: 32:6 (#0),\n             },\n             Ident {\n                 ident: \"fn\",\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:34:5: 34:7 (#0),\n             },\n             Ident {\n                 ident: \"bar\",\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:34:8: 34:11 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [],\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:34:11: 34:13 (#0),\n             },\n             Group {\n                 delimiter: Brace,\n                 stream: TokenStream [],\n-                span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+                span: $DIR/cfg-eval-inner.rs:34:14: 36:6 (#0),\n             },\n         ],\n-        span: $DIR/cfg-eval-inner.rs:18:1: 37:2 (#0),\n+        span: $DIR/cfg-eval-inner.rs:29:5: 37:2 (#0),\n     },\n ]"}, {"sha": "6732caf08dd76586ab0c0974fc5d655b42e6a164", "filename": "src/test/ui/proc-macro/cfg-eval.stdout", "status": "modified", "additions": 28, "deletions": 28, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fcfg-eval.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -2,147 +2,147 @@ PRINT-ATTR INPUT (DISPLAY): struct S1 { #[cfg(all())] #[allow()] field_true : u8\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+        span: $DIR/cfg-eval.rs:17:1: 17:7 (#0),\n     },\n     Ident {\n         ident: \"S1\",\n-        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+        span: $DIR/cfg-eval.rs:17:8: 17:10 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:20:5: 20:6 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"cfg\",\n-                        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                        span: $DIR/cfg-eval.rs:20:7: 20:10 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"all\",\n-                                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                                span: $DIR/cfg-eval.rs:20:11: 20:14 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [],\n-                                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                                span: $DIR/cfg-eval.rs:20:14: 20:24 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                        span: $DIR/cfg-eval.rs:20:10: 20:25 (#0),\n                     },\n                 ],\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:20:6: 20:26 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:22:5: 22:6 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"allow\",\n-                        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                        span: $DIR/cfg-eval.rs:22:31: 22:36 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [],\n-                        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                        span: $DIR/cfg-eval.rs:22:36: 22:38 (#0),\n                     },\n                 ],\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:22:5: 22:6 (#0),\n             },\n             Ident {\n                 ident: \"field_true\",\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:23:5: 23:15 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:23:15: 23:16 (#0),\n             },\n             Ident {\n                 ident: \"u8\",\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:23:17: 23:19 (#0),\n             },\n             Punct {\n                 ch: ',',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+                span: $DIR/cfg-eval.rs:23:19: 23:20 (#0),\n             },\n         ],\n-        span: $DIR/cfg-eval.rs:17:1: 24:2 (#0),\n+        span: $DIR/cfg-eval.rs:17:11: 24:2 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): #[rustc_dummy] (#[cfg(all())] 1,)\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+        span: $DIR/cfg-eval.rs:35:39: 35:40 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"rustc_dummy\",\n-                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                span: $DIR/cfg-eval.rs:35:62: 35:73 (#0),\n             },\n         ],\n-        span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+        span: $DIR/cfg-eval.rs:35:39: 35:40 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                span: $DIR/cfg-eval.rs:36:23: 36:24 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"cfg\",\n-                        span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                        span: $DIR/cfg-eval.rs:36:25: 36:28 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"all\",\n-                                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                                span: $DIR/cfg-eval.rs:36:29: 36:32 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [],\n-                                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                                span: $DIR/cfg-eval.rs:36:32: 36:42 (#0),\n                             },\n                         ],\n-                        span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                        span: $DIR/cfg-eval.rs:36:28: 36:43 (#0),\n                     },\n                 ],\n-                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                span: $DIR/cfg-eval.rs:36:24: 36:44 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                span: $DIR/cfg-eval.rs:36:45: 36:46 (#0),\n             },\n             Punct {\n                 ch: ',',\n                 spacing: Alone,\n-                span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),\n+                span: $DIR/cfg-eval.rs:36:46: 36:47 (#0),\n             },\n         ],\n         span: $DIR/cfg-eval.rs:36:5: 36:48 (#0),"}, {"sha": "a6437982a37372abc7d5807c2f50adfb334b1348", "filename": "src/test/ui/proc-macro/expand-to-derive.stdout", "status": "modified", "additions": 21, "deletions": 26, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fexpand-to-derive.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fexpand-to-derive.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fexpand-to-derive.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,109 +1,104 @@\n PRINT-DERIVE INPUT (DISPLAY): struct Foo\n {\n     field :\n-    [bool ; { #[rustc_dummy] struct Inner { other_inner_field : u8, } 0 }],\n+    [bool ; { #[rustc_dummy] struct Inner { other_inner_field : u8, } 0 }]\n }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+        span: $DIR/expand-to-derive.rs:16:9: 16:15 (#4),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+        span: $DIR/expand-to-derive.rs:16:16: 16:19 (#4),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"field\",\n-                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                span: $DIR/expand-to-derive.rs:18:13: 18:18 (#4),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                span: $DIR/expand-to-derive.rs:18:18: 18:19 (#4),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"bool\",\n-                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                        span: $DIR/expand-to-derive.rs:18:21: 18:25 (#4),\n                     },\n                     Punct {\n                         ch: ';',\n                         spacing: Alone,\n-                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                        span: $DIR/expand-to-derive.rs:18:25: 18:26 (#4),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:27:5: 27:6 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"rustc_dummy\",\n-                                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                        span: $DIR/expand-to-derive.rs:27:28: 27:39 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:27:5: 27:6 (#0),\n                             },\n                             Ident {\n                                 ident: \"struct\",\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:28:5: 28:11 (#0),\n                             },\n                             Ident {\n                                 ident: \"Inner\",\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:28:12: 28:17 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"other_inner_field\",\n-                                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                        span: $DIR/expand-to-derive.rs:30:9: 30:26 (#0),\n                                     },\n                                     Punct {\n                                         ch: ':',\n                                         spacing: Alone,\n-                                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                        span: $DIR/expand-to-derive.rs:30:26: 30:27 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"u8\",\n-                                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                        span: $DIR/expand-to-derive.rs:30:28: 30:30 (#0),\n                                     },\n                                     Punct {\n                                         ch: ',',\n                                         spacing: Alone,\n-                                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                        span: $DIR/expand-to-derive.rs:30:30: 30:31 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:28:18: 31:6 (#0),\n                             },\n                             Literal {\n                                 kind: Integer,\n                                 symbol: \"0\",\n                                 suffix: None,\n-                                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                                span: $DIR/expand-to-derive.rs:20:17: 20:18 (#4),\n                             },\n                         ],\n-                        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                        span: $DIR/expand-to-derive.rs:18:27: 21:14 (#4),\n                     },\n                 ],\n-                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n-            },\n-            Punct {\n-                ch: ',',\n-                spacing: Alone,\n-                span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+                span: $DIR/expand-to-derive.rs:18:20: 21:15 (#4),\n             },\n         ],\n-        span: $DIR/expand-to-derive.rs:16:9: 22:10 (#4),\n+        span: $DIR/expand-to-derive.rs:16:20: 22:10 (#4),\n     },\n ]"}, {"sha": "14ec57ad62606b073fafd2a933bcfd744250efb1", "filename": "src/test/ui/proc-macro/inner-attrs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -37,7 +37,7 @@ struct MyDerivePrint {\n             #![cfg_attr(not(FALSE), rustc_dummy(first))]\n             #![cfg_attr(not(FALSE), rustc_dummy(second))]\n             _ => {\n-                #![cfg_attr(not(FALSE), rustc_dummy(second))]\n+                #![cfg_attr(not(FALSE), rustc_dummy(third))]\n                 true\n             }\n         };"}, {"sha": "2f442e83002ea0b3a8f4b08a7ee61ab9041084ac", "filename": "src/test/ui/proc-macro/inner-attrs.stdout", "status": "modified", "additions": 200, "deletions": 253, "changes": 453, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Finner-attrs.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -11,283 +11,283 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:16:1: 16:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_target_and_args\",\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:16:3: 16:24 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"second\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:16:25: 16:31 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:16:24: 16:32 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:16:2: 16:33 (#0),\n     },\n     Ident {\n         ident: \"fn\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:1: 17:3 (#0),\n     },\n     Ident {\n         ident: \"foo\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:4: 17:7 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:7: 17:9 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:5: 18:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:6: 18:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:18:8: 18:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"third\",\n-                                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                                span: $DIR/inner-attrs.rs:18:30: 18:35 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:18:29: 18:36 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:7: 18:37 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:5: 19:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:6: 19:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:8: 19:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"fourth\",\n-                                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                                span: $DIR/inner-attrs.rs:19:30: 19:36 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:29: 19:37 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:7: 19:38 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:10: 20:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): second\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"second\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:16:25: 16:31 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): fn foo()\n { # ! [print_target_and_args(third)] # ! [print_target_and_args(fourth)] }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"fn\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:1: 17:3 (#0),\n     },\n     Ident {\n         ident: \"foo\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:4: 17:7 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:7: 17:9 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:5: 18:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:6: 18:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:18:8: 18:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"third\",\n-                                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                                span: $DIR/inner-attrs.rs:18:30: 18:35 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:18:29: 18:36 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:18:7: 18:37 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:5: 19:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:6: 19:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:8: 19:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"fourth\",\n-                                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                                span: $DIR/inner-attrs.rs:19:30: 19:36 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:29: 19:37 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:7: 19:38 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:10: 20:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): third\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"third\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:18:30: 18:35 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): fn foo() { # ! [print_target_and_args(fourth)] }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"fn\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:1: 17:3 (#0),\n     },\n     Ident {\n         ident: \"foo\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:4: 17:7 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:7: 17:9 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:5: 19:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:6: 19:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:8: 19:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"fourth\",\n-                                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                                span: $DIR/inner-attrs.rs:19:30: 19:36 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                        span: $DIR/inner-attrs.rs:19:29: 19:37 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+                span: $DIR/inner-attrs.rs:19:7: 19:38 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:10: 20:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): fourth\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"fourth\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:19:30: 19:36 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): fn foo() { }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"fn\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:1: 17:3 (#0),\n     },\n     Ident {\n         ident: \"foo\",\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:4: 17:7 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:7: 17:9 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:17:1: 20:2 (#0),\n+        span: $DIR/inner-attrs.rs:17:10: 20:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): mod_first\n@@ -306,108 +306,108 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:23:1: 23:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_target_and_args\",\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:23:3: 23:24 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"mod_second\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:23:25: 23:35 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:23:24: 23:36 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:23:2: 23:37 (#0),\n     },\n     Ident {\n         ident: \"mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:1: 24:4 (#0),\n     },\n     Ident {\n         ident: \"inline_mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:5: 24:15 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:5: 25:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:6: 25:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:25:8: 25:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"mod_third\",\n-                                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                                span: $DIR/inner-attrs.rs:25:30: 25:39 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:25:29: 25:40 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:7: 25:41 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:5: 26:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:6: 26:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:8: 26:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"mod_fourth\",\n-                                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                                span: $DIR/inner-attrs.rs:26:30: 26:40 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:29: 26:41 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:7: 26:42 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:16: 27:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): mod_second\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod_second\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:23:25: 23:35 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): mod inline_mod\n@@ -418,154 +418,154 @@ PRINT-ATTR INPUT (DISPLAY): mod inline_mod\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:1: 24:4 (#0),\n     },\n     Ident {\n         ident: \"inline_mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:5: 24:15 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:5: 25:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:6: 25:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:25:8: 25:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"mod_third\",\n-                                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                                span: $DIR/inner-attrs.rs:25:30: 25:39 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:25:29: 25:40 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:25:7: 25:41 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:5: 26:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:6: 26:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:8: 26:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"mod_fourth\",\n-                                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                                span: $DIR/inner-attrs.rs:26:30: 26:40 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:29: 26:41 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:7: 26:42 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:16: 27:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): mod_third\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod_third\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:25:30: 25:39 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): mod inline_mod { # ! [print_target_and_args(mod_fourth)] }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:1: 24:4 (#0),\n     },\n     Ident {\n         ident: \"inline_mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:5: 24:15 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:5: 26:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:6: 26:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:8: 26:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"mod_fourth\",\n-                                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                                span: $DIR/inner-attrs.rs:26:30: 26:40 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                        span: $DIR/inner-attrs.rs:26:29: 26:41 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+                span: $DIR/inner-attrs.rs:26:7: 26:42 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:16: 27:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): mod_fourth\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod_fourth\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:26:30: 26:40 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): mod inline_mod { }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:1: 24:4 (#0),\n     },\n     Ident {\n         ident: \"inline_mod\",\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:5: 24:15 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:24:1: 27:2 (#0),\n+        span: $DIR/inner-attrs.rs:24:16: 27:2 (#0),\n     },\n ]\n PRINT-DERIVE INPUT (DISPLAY): struct MyDerivePrint\n@@ -574,168 +574,195 @@ PRINT-DERIVE INPUT (DISPLAY): struct MyDerivePrint\n     [u8 ;\n      {\n          match true\n-         { # ! [rustc_dummy(first)] # ! [rustc_dummy(second)] _ => { true } }\n-         ; 0\n-     }],\n+         {\n+             # ! [rustc_dummy(first)] # ! [rustc_dummy(second)] _ =>\n+             { # ! [rustc_dummy(third)] true }\n+         } ; 0\n+     }]\n }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+        span: $DIR/inner-attrs.rs:34:1: 34:7 (#0),\n     },\n     Ident {\n         ident: \"MyDerivePrint\",\n-        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+        span: $DIR/inner-attrs.rs:34:8: 34:21 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"field\",\n-                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                span: $DIR/inner-attrs.rs:35:5: 35:10 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                span: $DIR/inner-attrs.rs:35:10: 35:11 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"u8\",\n-                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                        span: $DIR/inner-attrs.rs:35:13: 35:15 (#0),\n                     },\n                     Punct {\n                         ch: ';',\n                         spacing: Alone,\n-                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                        span: $DIR/inner-attrs.rs:35:15: 35:16 (#0),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"match\",\n-                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                span: $DIR/inner-attrs.rs:36:9: 36:14 (#0),\n                             },\n                             Ident {\n                                 ident: \"true\",\n-                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                span: $DIR/inner-attrs.rs:36:15: 36:19 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Punct {\n                                         ch: '#',\n-                                        spacing: Joint,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        spacing: Alone,\n+                                        span: $DIR/inner-attrs.rs:37:13: 37:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '!',\n                                         spacing: Alone,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:37:14: 37:15 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"rustc_dummy\",\n-                                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                span: $DIR/inner-attrs.rs:37:37: 37:48 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"first\",\n-                                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                        span: $DIR/inner-attrs.rs:37:49: 37:54 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                span: $DIR/inner-attrs.rs:37:48: 37:55 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:37:13: 37:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '#',\n-                                        spacing: Joint,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        spacing: Alone,\n+                                        span: $DIR/inner-attrs.rs:38:13: 38:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '!',\n                                         spacing: Alone,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:38:14: 38:15 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"rustc_dummy\",\n-                                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                span: $DIR/inner-attrs.rs:38:37: 38:48 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"second\",\n-                                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                        span: $DIR/inner-attrs.rs:38:49: 38:55 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                span: $DIR/inner-attrs.rs:38:48: 38:56 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:38:13: 38:14 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"_\",\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:39:13: 39:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '=',\n                                         spacing: Joint,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:39:15: 39:17 (#0),\n                                     },\n                                     Punct {\n                                         ch: '>',\n                                         spacing: Alone,\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:39:15: 39:17 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Brace,\n                                         stream: TokenStream [\n+                                            Punct {\n+                                                ch: '#',\n+                                                spacing: Alone,\n+                                                span: $DIR/inner-attrs.rs:40:17: 40:18 (#0),\n+                                            },\n+                                            Punct {\n+                                                ch: '!',\n+                                                spacing: Alone,\n+                                                span: $DIR/inner-attrs.rs:40:18: 40:19 (#0),\n+                                            },\n+                                            Group {\n+                                                delimiter: Bracket,\n+                                                stream: TokenStream [\n+                                                    Ident {\n+                                                        ident: \"rustc_dummy\",\n+                                                        span: $DIR/inner-attrs.rs:40:41: 40:52 (#0),\n+                                                    },\n+                                                    Group {\n+                                                        delimiter: Parenthesis,\n+                                                        stream: TokenStream [\n+                                                            Ident {\n+                                                                ident: \"third\",\n+                                                                span: $DIR/inner-attrs.rs:40:53: 40:58 (#0),\n+                                                            },\n+                                                        ],\n+                                                        span: $DIR/inner-attrs.rs:40:52: 40:59 (#0),\n+                                                    },\n+                                                ],\n+                                                span: $DIR/inner-attrs.rs:40:17: 40:18 (#0),\n+                                            },\n                                             Ident {\n                                                 ident: \"true\",\n-                                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                                span: $DIR/inner-attrs.rs:41:17: 41:21 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                        span: $DIR/inner-attrs.rs:39:18: 42:14 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                span: $DIR/inner-attrs.rs:36:20: 43:10 (#0),\n                             },\n                             Punct {\n                                 ch: ';',\n                                 spacing: Alone,\n-                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                span: $DIR/inner-attrs.rs:43:10: 43:11 (#0),\n                             },\n                             Literal {\n                                 kind: Integer,\n                                 symbol: \"0\",\n                                 suffix: None,\n-                                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                                span: $DIR/inner-attrs.rs:44:9: 44:10 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                        span: $DIR/inner-attrs.rs:35:17: 45:6 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n-            },\n-            Punct {\n-                ch: ',',\n-                spacing: Alone,\n-                span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+                span: $DIR/inner-attrs.rs:35:12: 45:7 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:34:1: 46:2 (#0),\n+        span: $DIR/inner-attrs.rs:34:22: 46:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): tuple_attrs\n@@ -745,51 +772,11 @@ PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n         span: $DIR/inner-attrs.rs:52:29: 52:40 (#0),\n     },\n ]\n-PRINT-ATTR INPUT (DISPLAY): (# ! [cfg_attr(FALSE, rustc_dummy)] 3, 4,\n- { # ! [cfg_attr(not(FALSE), rustc_dummy(innermost))] 5 }) ;\n+PRINT-ATTR INPUT (DISPLAY): (3, 4, { # ! [cfg_attr(not(FALSE), rustc_dummy(innermost))] 5 }) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n-            Punct {\n-                ch: '#',\n-                spacing: Joint,\n-                span: $DIR/inner-attrs.rs:53:9: 53:10 (#0),\n-            },\n-            Punct {\n-                ch: '!',\n-                spacing: Alone,\n-                span: $DIR/inner-attrs.rs:53:10: 53:11 (#0),\n-            },\n-            Group {\n-                delimiter: Bracket,\n-                stream: TokenStream [\n-                    Ident {\n-                        ident: \"cfg_attr\",\n-                        span: $DIR/inner-attrs.rs:53:12: 53:20 (#0),\n-                    },\n-                    Group {\n-                        delimiter: Parenthesis,\n-                        stream: TokenStream [\n-                            Ident {\n-                                ident: \"FALSE\",\n-                                span: $DIR/inner-attrs.rs:53:21: 53:26 (#0),\n-                            },\n-                            Punct {\n-                                ch: ',',\n-                                spacing: Alone,\n-                                span: $DIR/inner-attrs.rs:53:26: 53:27 (#0),\n-                            },\n-                            Ident {\n-                                ident: \"rustc_dummy\",\n-                                span: $DIR/inner-attrs.rs:53:28: 53:39 (#0),\n-                            },\n-                        ],\n-                        span: $DIR/inner-attrs.rs:53:20: 53:40 (#0),\n-                    },\n-                ],\n-                span: $DIR/inner-attrs.rs:53:11: 53:41 (#0),\n-            },\n             Literal {\n                 kind: Integer,\n                 symbol: \"3\",\n@@ -907,55 +894,55 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:61:9: 61:10 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:61:10: 61:11 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"rustc_dummy\",\n-                        span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                        span: $DIR/inner-attrs.rs:61:12: 61:23 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"inner\",\n-                                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                                span: $DIR/inner-attrs.rs:61:24: 61:29 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                        span: $DIR/inner-attrs.rs:61:23: 61:30 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:61:11: 61:31 (#0),\n             },\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:62:9: 62:13 (#0),\n             },\n             Punct {\n                 ch: ';',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:62:13: 62:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+                span: $DIR/inner-attrs.rs:62:15: 62:16 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+        span: $DIR/inner-attrs.rs:60:43: 63:6 (#0),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: $DIR/inner-attrs.rs:60:43: 63:7 (#0),\n+        span: $DIR/inner-attrs.rs:63:6: 63:7 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): tuple_attrs\n@@ -965,51 +952,11 @@ PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n         span: $DIR/inner-attrs.rs:65:29: 65:40 (#0),\n     },\n ]\n-PRINT-ATTR INPUT (DISPLAY): (# ! [cfg_attr(FALSE, rustc_dummy)] 3, 4,\n- { # ! [cfg_attr(not(FALSE), rustc_dummy(innermost))] 5 }) ;\n+PRINT-ATTR INPUT (DISPLAY): (3, 4, { # ! [cfg_attr(not(FALSE), rustc_dummy(innermost))] 5 }) ;\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [\n-            Punct {\n-                ch: '#',\n-                spacing: Joint,\n-                span: $DIR/inner-attrs.rs:66:9: 66:10 (#0),\n-            },\n-            Punct {\n-                ch: '!',\n-                spacing: Alone,\n-                span: $DIR/inner-attrs.rs:66:10: 66:11 (#0),\n-            },\n-            Group {\n-                delimiter: Bracket,\n-                stream: TokenStream [\n-                    Ident {\n-                        ident: \"cfg_attr\",\n-                        span: $DIR/inner-attrs.rs:66:12: 66:20 (#0),\n-                    },\n-                    Group {\n-                        delimiter: Parenthesis,\n-                        stream: TokenStream [\n-                            Ident {\n-                                ident: \"FALSE\",\n-                                span: $DIR/inner-attrs.rs:66:21: 66:26 (#0),\n-                            },\n-                            Punct {\n-                                ch: ',',\n-                                spacing: Alone,\n-                                span: $DIR/inner-attrs.rs:66:26: 66:27 (#0),\n-                            },\n-                            Ident {\n-                                ident: \"rustc_dummy\",\n-                                span: $DIR/inner-attrs.rs:66:28: 66:39 (#0),\n-                            },\n-                        ],\n-                        span: $DIR/inner-attrs.rs:66:20: 66:40 (#0),\n-                    },\n-                ],\n-                span: $DIR/inner-attrs.rs:66:11: 66:41 (#0),\n-            },\n             Literal {\n                 kind: Integer,\n                 symbol: \"3\",\n@@ -1127,55 +1074,55 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:74:9: 74:10 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:74:10: 74:11 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"rustc_dummy\",\n-                        span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                        span: $DIR/inner-attrs.rs:74:12: 74:23 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"inner\",\n-                                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                                span: $DIR/inner-attrs.rs:74:24: 74:29 (#0),\n                             },\n                         ],\n-                        span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                        span: $DIR/inner-attrs.rs:74:23: 74:30 (#0),\n                     },\n                 ],\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:74:11: 74:31 (#0),\n             },\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:75:9: 75:13 (#0),\n             },\n             Punct {\n                 ch: ';',\n                 spacing: Alone,\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:75:13: 75:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+                span: $DIR/inner-attrs.rs:75:15: 75:16 (#0),\n             },\n         ],\n-        span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+        span: $DIR/inner-attrs.rs:73:43: 76:6 (#0),\n     },\n     Punct {\n         ch: ';',\n         spacing: Alone,\n-        span: $DIR/inner-attrs.rs:73:43: 76:7 (#0),\n+        span: $DIR/inner-attrs.rs:76:6: 76:7 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): tenth\n@@ -1189,20 +1136,20 @@ PRINT-ATTR INPUT (DISPLAY): fn weird_extern() { }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"fn\",\n-        span: $DIR/inner-attrs.rs:111:5: 113:6 (#0),\n+        span: $DIR/inner-attrs.rs:111:5: 111:7 (#0),\n     },\n     Ident {\n         ident: \"weird_extern\",\n-        span: $DIR/inner-attrs.rs:111:5: 113:6 (#0),\n+        span: $DIR/inner-attrs.rs:111:8: 111:20 (#0),\n     },\n     Group {\n         delimiter: Parenthesis,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:111:5: 113:6 (#0),\n+        span: $DIR/inner-attrs.rs:111:20: 111:22 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/inner-attrs.rs:111:5: 113:6 (#0),\n+        span: $DIR/inner-attrs.rs:111:23: 113:6 (#0),\n     },\n ]"}, {"sha": "d7adc5331cd777949c8ee466c08ab71e2a3d74a9", "filename": "src/test/ui/proc-macro/issue-75930-derive-cfg.stdout", "status": "modified", "additions": 135, "deletions": 140, "changes": 275, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fissue-75930-derive-cfg.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1279,632 +1279,627 @@ PRINT-DERIVE INPUT (DISPLAY): #[print_helper(a)] #[allow(dead_code)] #[print_hel\n     [u8 ;\n      {\n          #[cfg(not(FALSE))] struct Inner ; match true\n-         { #[allow(warnings)] false => { } _ => { } } ; #[print_helper(c)]\n+         { #[allow(warnings)] false => { }, _ => { } } ; #[print_helper(c)]\n          #[cfg(not(FALSE))] fn kept_fn()\n          { # ! [cfg(not(FALSE))] let my_val = true ; } enum TupleEnum\n-         { Foo(#[cfg(not(FALSE))] i32, u8), } struct\n+         { Foo(#[cfg(not(FALSE))] i32, u8) } struct\n          TupleStruct(#[cfg(not(FALSE))] i32, u8) ; 0\n-     }], #[print_helper(d)] fourth : B,\n+     }], #[print_helper(d)] fourth : B\n }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:19:1: 19:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_helper\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:19:3: 19:15 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"a\",\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:19:16: 19:17 (#0),\n                     },\n                 ],\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:19:15: 19:18 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:19:2: 19:19 (#0),\n     },\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:21:1: 21:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"allow\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:21:24: 21:29 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"dead_code\",\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:21:30: 21:39 (#0),\n                     },\n                 ],\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:21:29: 21:40 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:21:1: 21:2 (#0),\n     },\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:24:1: 24:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_helper\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:24:3: 24:15 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"b\",\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:24:16: 24:17 (#0),\n                     },\n                 ],\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:24:15: 24:18 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:24:2: 24:19 (#0),\n     },\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:25:1: 25:7 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:25:8: 25:11 (#0),\n     },\n     Punct {\n         ch: '<',\n-        spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        spacing: Joint,\n+        span: $DIR/issue-75930-derive-cfg.rs:25:11: 25:12 (#0),\n     },\n     Ident {\n         ident: \"B\",\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:25:29: 25:30 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:25:30: 25:31 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"second\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:27:40: 27:46 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:27:46: 27:47 (#0),\n             },\n             Ident {\n                 ident: \"bool\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:27:48: 27:52 (#0),\n             },\n             Punct {\n                 ch: ',',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:27:52: 27:53 (#0),\n             },\n             Ident {\n                 ident: \"third\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:28:5: 28:10 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:28:10: 28:11 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"u8\",\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:28:13: 28:15 (#0),\n                     },\n                     Punct {\n                         ch: ';',\n                         spacing: Alone,\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:28:15: 28:16 (#0),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:30:9: 30:10 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"cfg\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:30:11: 30:14 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"not\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:30:15: 30:18 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"FALSE\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:30:19: 30:24 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:30:18: 30:25 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:30:14: 30:26 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:30:10: 30:27 (#0),\n                             },\n                             Ident {\n                                 ident: \"struct\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:30:28: 30:34 (#0),\n                             },\n                             Ident {\n                                 ident: \"Inner\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:30:35: 30:40 (#0),\n                             },\n                             Punct {\n                                 ch: ';',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:30:40: 30:41 (#0),\n                             },\n                             Ident {\n                                 ident: \"match\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:32:9: 32:14 (#0),\n                             },\n                             Ident {\n                                 ident: \"true\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:32:15: 32:19 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Punct {\n                                         ch: '#',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:13: 34:14 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"allow\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:34:36: 34:41 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"warnings\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:34:42: 34:50 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:34:41: 34:51 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:13: 34:14 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"false\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:54: 34:59 (#0),\n                                     },\n                                     Punct {\n                                         ch: '=',\n                                         spacing: Joint,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:60: 34:62 (#0),\n                                     },\n                                     Punct {\n                                         ch: '>',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:60: 34:62 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Brace,\n                                         stream: TokenStream [],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:63: 34:65 (#0),\n+                                    },\n+                                    Punct {\n+                                        ch: ',',\n+                                        spacing: Alone,\n+                                        span: $DIR/issue-75930-derive-cfg.rs:34:65: 34:66 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"_\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:35:13: 35:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '=',\n                                         spacing: Joint,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:35:15: 35:17 (#0),\n                                     },\n                                     Punct {\n                                         ch: '>',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:35:15: 35:17 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Brace,\n                                         stream: TokenStream [],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:35:18: 35:20 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:32:20: 36:10 (#0),\n                             },\n                             Punct {\n                                 ch: ';',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:36:10: 36:11 (#0),\n                             },\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:9: 43:10 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"print_helper\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:43:11: 43:23 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"c\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:43:24: 43:25 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:43:23: 43:26 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:10: 43:27 (#0),\n                             },\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:28: 43:29 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"cfg\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:43:30: 43:33 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"not\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:43:34: 43:37 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"FALSE\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:43:38: 43:43 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:43:37: 43:44 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:43:33: 43:45 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:29: 43:46 (#0),\n                             },\n                             Ident {\n                                 ident: \"fn\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:47: 43:49 (#0),\n                             },\n                             Ident {\n                                 ident: \"kept_fn\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:50: 43:57 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:57: 43:59 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Punct {\n                                         ch: '#',\n                                         spacing: Joint,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:44:13: 44:14 (#0),\n                                     },\n                                     Punct {\n                                         ch: '!',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:44:14: 44:15 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"cfg\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:44:16: 44:19 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"not\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:44:20: 44:23 (#0),\n                                                     },\n                                                     Group {\n                                                         delimiter: Parenthesis,\n                                                         stream: TokenStream [\n                                                             Ident {\n                                                                 ident: \"FALSE\",\n-                                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                                span: $DIR/issue-75930-derive-cfg.rs:44:24: 44:29 (#0),\n                                                             },\n                                                         ],\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:44:23: 44:30 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:44:19: 44:31 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:44:15: 44:32 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"let\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:45:13: 45:16 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"my_val\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:45:17: 45:23 (#0),\n                                     },\n                                     Punct {\n                                         ch: '=',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:45:24: 45:25 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"true\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:45:26: 45:30 (#0),\n                                     },\n                                     Punct {\n                                         ch: ';',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:45:30: 45:31 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:43:60: 46:10 (#0),\n                             },\n                             Ident {\n                                 ident: \"enum\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:48:9: 48:13 (#0),\n                             },\n                             Ident {\n                                 ident: \"TupleEnum\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:48:14: 48:23 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"Foo\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:49:13: 49:16 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Punct {\n                                                 ch: '#',\n                                                 spacing: Alone,\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:52:17: 52:18 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Bracket,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"cfg\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:52:19: 52:22 (#0),\n                                                     },\n                                                     Group {\n                                                         delimiter: Parenthesis,\n                                                         stream: TokenStream [\n                                                             Ident {\n                                                                 ident: \"not\",\n-                                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                                span: $DIR/issue-75930-derive-cfg.rs:52:23: 52:26 (#0),\n                                                             },\n                                                             Group {\n                                                                 delimiter: Parenthesis,\n                                                                 stream: TokenStream [\n                                                                     Ident {\n                                                                         ident: \"FALSE\",\n-                                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                                        span: $DIR/issue-75930-derive-cfg.rs:52:27: 52:32 (#0),\n                                                                     },\n                                                                 ],\n-                                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                                span: $DIR/issue-75930-derive-cfg.rs:52:26: 52:33 (#0),\n                                                             },\n                                                         ],\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:52:22: 52:34 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:52:18: 52:35 (#0),\n                                             },\n                                             Ident {\n                                                 ident: \"i32\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:52:36: 52:39 (#0),\n                                             },\n                                             Punct {\n                                                 ch: ',',\n                                                 spacing: Alone,\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:52:39: 52:40 (#0),\n                                             },\n                                             Ident {\n                                                 ident: \"u8\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:53:39: 53:41 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n-                                    },\n-                                    Punct {\n-                                        ch: ',',\n-                                        spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:49:16: 54:14 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:48:24: 55:10 (#0),\n                             },\n                             Ident {\n                                 ident: \"struct\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:57:9: 57:15 (#0),\n                             },\n                             Ident {\n                                 ident: \"TupleStruct\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:57:16: 57:27 (#0),\n                             },\n                             Group {\n                                 delimiter: Parenthesis,\n                                 stream: TokenStream [\n                                     Punct {\n                                         ch: '#',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:59:13: 59:14 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"cfg\",\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:59:15: 59:18 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"not\",\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:59:19: 59:22 (#0),\n                                                     },\n                                                     Group {\n                                                         delimiter: Parenthesis,\n                                                         stream: TokenStream [\n                                                             Ident {\n                                                                 ident: \"FALSE\",\n-                                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                                span: $DIR/issue-75930-derive-cfg.rs:59:23: 59:28 (#0),\n                                                             },\n                                                         ],\n-                                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                        span: $DIR/issue-75930-derive-cfg.rs:59:22: 59:29 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                                span: $DIR/issue-75930-derive-cfg.rs:59:18: 59:30 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:59:14: 59:31 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"i32\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:59:32: 59:35 (#0),\n                                     },\n                                     Punct {\n                                         ch: ',',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:59:35: 59:36 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"u8\",\n-                                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                        span: $DIR/issue-75930-derive-cfg.rs:61:13: 61:15 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:57:27: 62:10 (#0),\n                             },\n                             Punct {\n                                 ch: ';',\n                                 spacing: Alone,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:62:10: 62:11 (#0),\n                             },\n                             Literal {\n                                 kind: Integer,\n                                 symbol: \"0\",\n                                 suffix: None,\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:68:9: 68:10 (#0),\n                             },\n                         ],\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:28:17: 69:6 (#0),\n                     },\n                 ],\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:28:12: 69:7 (#0),\n             },\n             Punct {\n                 ch: ',',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:69:7: 69:8 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:70:5: 70:6 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_helper\",\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:70:7: 70:19 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"d\",\n-                                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                                span: $DIR/issue-75930-derive-cfg.rs:70:20: 70:21 (#0),\n                             },\n                         ],\n-                        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                        span: $DIR/issue-75930-derive-cfg.rs:70:19: 70:22 (#0),\n                     },\n                 ],\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:70:6: 70:23 (#0),\n             },\n             Ident {\n                 ident: \"fourth\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:71:5: 71:11 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:71:11: 71:12 (#0),\n             },\n             Ident {\n                 ident: \"B\",\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n-            },\n-            Punct {\n-                ch: ',',\n-                spacing: Alone,\n-                span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+                span: $DIR/issue-75930-derive-cfg.rs:71:13: 71:14 (#0),\n             },\n         ],\n-        span: $DIR/issue-75930-derive-cfg.rs:25:1: 72:2 (#0),\n+        span: $DIR/issue-75930-derive-cfg.rs:25:32: 72:2 (#0),\n     },\n ]"}, {"sha": "607c2954c7cf5fb191523bc3ca4261a7f9b45e5f", "filename": "src/test/ui/proc-macro/issue-78675-captured-inner-attrs.stdout", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fissue-78675-captured-inner-attrs.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fissue-78675-captured-inner-attrs.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fissue-78675-captured-inner-attrs.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -35,48 +35,48 @@ PRINT-BANG INPUT (DEBUG): TokenStream [\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"mod\",\n-                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 27:8 (#0),\n                     },\n                     Ident {\n                         ident: \"bar\",\n-                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:9: 27:12 (#0),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Punct {\n                                 ch: '#',\n-                                spacing: Joint,\n-                                span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                spacing: Alone,\n+                                span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                             },\n                             Punct {\n                                 ch: '!',\n                                 spacing: Alone,\n-                                span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"doc\",\n-                                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                        span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                                     },\n                                     Punct {\n                                         ch: '=',\n                                         spacing: Alone,\n-                                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                        span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                                     },\n                                     Literal {\n                                         kind: StrRaw(0),\n                                         symbol: \" Foo\",\n                                         suffix: None,\n-                                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                        span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                                span: $DIR/issue-78675-captured-inner-attrs.rs:28:9: 28:16 (#0),\n                             },\n                         ],\n-                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:5: 29:6 (#0),\n+                        span: $DIR/issue-78675-captured-inner-attrs.rs:27:13: 29:6 (#0),\n                     },\n                 ],\n                 span: $DIR/issue-78675-captured-inner-attrs.rs:22:13: 22:18 (#4),"}, {"sha": "a0b0cbb19e4db7754ca1093824cd86b02f5bae09", "filename": "src/test/ui/proc-macro/macro-rules-derive-cfg.stdout", "status": "modified", "additions": 34, "deletions": 39, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fmacro-rules-derive-cfg.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fmacro-rules-derive-cfg.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fmacro-rules-derive-cfg.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -5,172 +5,167 @@ PRINT-DERIVE INPUT (DISPLAY): struct Foo\n      {\n          let a = #[rustc_dummy(first)] #[rustc_dummy(second)]\n          { # ! [allow(unused)] 30 } ; 0\n-     }],\n+     }]\n }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+        span: $DIR/macro-rules-derive-cfg.rs:17:9: 17:15 (#4),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+        span: $DIR/macro-rules-derive-cfg.rs:17:16: 17:19 (#4),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"val\",\n-                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                span: $DIR/macro-rules-derive-cfg.rs:18:13: 18:16 (#4),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                span: $DIR/macro-rules-derive-cfg.rs:18:16: 18:17 (#4),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"bool\",\n-                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                        span: $DIR/macro-rules-derive-cfg.rs:18:19: 18:23 (#4),\n                     },\n                     Punct {\n                         ch: ';',\n                         spacing: Alone,\n-                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                        span: $DIR/macro-rules-derive-cfg.rs:18:23: 18:24 (#4),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"let\",\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:17: 19:20 (#4),\n                             },\n                             Ident {\n                                 ident: \"a\",\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:21: 19:22 (#4),\n                             },\n                             Punct {\n                                 ch: '=',\n                                 spacing: Alone,\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:23: 19:24 (#4),\n                             },\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:25: 19:26 (#4),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"rustc_dummy\",\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:19:48: 19:59 (#4),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"first\",\n-                                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                                span: $DIR/macro-rules-derive-cfg.rs:19:60: 19:65 (#4),\n                                             },\n                                         ],\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:19:59: 19:66 (#4),\n                                     },\n                                 ],\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:25: 19:26 (#4),\n                             },\n                             Punct {\n                                 ch: '#',\n                                 spacing: Alone,\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:26:13: 26:14 (#0),\n                             },\n                             Group {\n                                 delimiter: Bracket,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"rustc_dummy\",\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:26:36: 26:47 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Parenthesis,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"second\",\n-                                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                                span: $DIR/macro-rules-derive-cfg.rs:26:48: 26:54 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:26:47: 26:55 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:26:13: 26:14 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Punct {\n                                         ch: '#',\n-                                        spacing: Joint,\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        spacing: Alone,\n+                                        span: $DIR/macro-rules-derive-cfg.rs:27:5: 27:6 (#0),\n                                     },\n                                     Punct {\n                                         ch: '!',\n                                         spacing: Alone,\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:27:6: 27:7 (#0),\n                                     },\n                                     Group {\n                                         delimiter: Bracket,\n                                         stream: TokenStream [\n                                             Ident {\n                                                 ident: \"allow\",\n-                                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                                span: $DIR/macro-rules-derive-cfg.rs:27:29: 27:34 (#0),\n                                             },\n                                             Group {\n                                                 delimiter: Parenthesis,\n                                                 stream: TokenStream [\n                                                     Ident {\n                                                         ident: \"unused\",\n-                                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                                        span: $DIR/macro-rules-derive-cfg.rs:27:35: 27:41 (#0),\n                                                     },\n                                                 ],\n-                                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                                span: $DIR/macro-rules-derive-cfg.rs:27:34: 27:42 (#0),\n                                             },\n                                         ],\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:27:5: 27:6 (#0),\n                                     },\n                                     Literal {\n                                         kind: Integer,\n                                         symbol: \"30\",\n                                         suffix: None,\n-                                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                        span: $DIR/macro-rules-derive-cfg.rs:28:5: 28:7 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:26:58: 29:2 (#0),\n                             },\n                             Punct {\n                                 ch: ';',\n                                 spacing: Alone,\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:19:74: 19:75 (#4),\n                             },\n                             Literal {\n                                 kind: Integer,\n                                 symbol: \"0\",\n                                 suffix: None,\n-                                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                                span: $DIR/macro-rules-derive-cfg.rs:20:17: 20:18 (#4),\n                             },\n                         ],\n-                        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                        span: $DIR/macro-rules-derive-cfg.rs:18:25: 21:14 (#4),\n                     },\n                 ],\n-                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n-            },\n-            Punct {\n-                ch: ',',\n-                spacing: Alone,\n-                span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+                span: $DIR/macro-rules-derive-cfg.rs:18:18: 21:15 (#4),\n             },\n         ],\n-        span: $DIR/macro-rules-derive-cfg.rs:17:9: 22:10 (#4),\n+        span: $DIR/macro-rules-derive-cfg.rs:17:20: 22:10 (#4),\n     },\n ]"}, {"sha": "9a562c971c887d213f1dae4e8e938d2c706c8faa", "filename": "src/test/ui/proc-macro/nested-derive-cfg.stdout", "status": "modified", "additions": 17, "deletions": 30, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fnested-derive-cfg.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fnested-derive-cfg.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fnested-derive-cfg.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -1,94 +1,81 @@\n PRINT-DERIVE INPUT (DISPLAY): struct Foo\n-{\n-    my_array :\n-    [bool ; { struct Inner { non_removed_inner_field : usize, } 0 }],\n-}\n+{ my_array : [bool ; { struct Inner { non_removed_inner_field : usize } 0 }] }\n PRINT-DERIVE INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"struct\",\n-        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+        span: $DIR/nested-derive-cfg.rs:12:1: 12:7 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+        span: $DIR/nested-derive-cfg.rs:12:8: 12:11 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"my_array\",\n-                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                span: $DIR/nested-derive-cfg.rs:14:5: 14:13 (#0),\n             },\n             Punct {\n                 ch: ':',\n                 spacing: Alone,\n-                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                span: $DIR/nested-derive-cfg.rs:14:13: 14:14 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"bool\",\n-                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                        span: $DIR/nested-derive-cfg.rs:14:16: 14:20 (#0),\n                     },\n                     Punct {\n                         ch: ';',\n                         spacing: Alone,\n-                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                        span: $DIR/nested-derive-cfg.rs:14:20: 14:21 (#0),\n                     },\n                     Group {\n                         delimiter: Brace,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"struct\",\n-                                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                span: $DIR/nested-derive-cfg.rs:15:9: 15:15 (#0),\n                             },\n                             Ident {\n                                 ident: \"Inner\",\n-                                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                span: $DIR/nested-derive-cfg.rs:15:16: 15:21 (#0),\n                             },\n                             Group {\n                                 delimiter: Brace,\n                                 stream: TokenStream [\n                                     Ident {\n                                         ident: \"non_removed_inner_field\",\n-                                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                        span: $DIR/nested-derive-cfg.rs:17:13: 17:36 (#0),\n                                     },\n                                     Punct {\n                                         ch: ':',\n                                         spacing: Alone,\n-                                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                        span: $DIR/nested-derive-cfg.rs:17:36: 17:37 (#0),\n                                     },\n                                     Ident {\n                                         ident: \"usize\",\n-                                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n-                                    },\n-                                    Punct {\n-                                        ch: ',',\n-                                        spacing: Alone,\n-                                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                        span: $DIR/nested-derive-cfg.rs:17:38: 17:43 (#0),\n                                     },\n                                 ],\n-                                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                span: $DIR/nested-derive-cfg.rs:15:22: 18:10 (#0),\n                             },\n                             Literal {\n                                 kind: Integer,\n                                 symbol: \"0\",\n                                 suffix: None,\n-                                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                                span: $DIR/nested-derive-cfg.rs:19:9: 19:10 (#0),\n                             },\n                         ],\n-                        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                        span: $DIR/nested-derive-cfg.rs:14:22: 20:6 (#0),\n                     },\n                 ],\n-                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n-            },\n-            Punct {\n-                ch: ',',\n-                spacing: Alone,\n-                span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+                span: $DIR/nested-derive-cfg.rs:14:15: 20:7 (#0),\n             },\n         ],\n-        span: $DIR/nested-derive-cfg.rs:12:1: 21:2 (#0),\n+        span: $DIR/nested-derive-cfg.rs:12:12: 21:2 (#0),\n     },\n ]"}, {"sha": "c94c5877e2240560bdfb240e229326d1c43ac60e", "filename": "src/test/ui/proc-macro/simple-tuple.rs", "status": "added", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.rs?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -0,0 +1,19 @@\n+// check-pass\n+// compile-flags: -Z span-debug --error-format human\n+// aux-build:test-macros.rs\n+// edition:2018\n+\n+#![feature(proc_macro_hygiene)]\n+\n+#![no_std] // Don't load unnecessary hygiene information from std\n+extern crate std;\n+\n+#[macro_use]\n+extern crate test_macros;\n+\n+fn main() {\n+    #[print_target_and_args(my_arg)] (\n+        #![cfg_attr(not(FALSE), allow(unused))]\n+        1, 2, 3\n+    );\n+}"}, {"sha": "1cc8579a4675ad91987adf14455bb5f4ccac3f46", "filename": "src/test/ui/proc-macro/simple-tuple.stdout", "status": "added", "additions": 79, "deletions": 0, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fsimple-tuple.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -0,0 +1,79 @@\n+PRINT-ATTR_ARGS INPUT (DISPLAY): my_arg\n+PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n+    Ident {\n+        ident: \"my_arg\",\n+        span: $DIR/simple-tuple.rs:15:29: 15:35 (#0),\n+    },\n+]\n+PRINT-ATTR INPUT (DISPLAY): (# ! [allow(unused)] 1, 2, 3) ;\n+PRINT-ATTR INPUT (DEBUG): TokenStream [\n+    Group {\n+        delimiter: Parenthesis,\n+        stream: TokenStream [\n+            Punct {\n+                ch: '#',\n+                spacing: Alone,\n+                span: $DIR/simple-tuple.rs:16:9: 16:10 (#0),\n+            },\n+            Punct {\n+                ch: '!',\n+                spacing: Alone,\n+                span: $DIR/simple-tuple.rs:16:10: 16:11 (#0),\n+            },\n+            Group {\n+                delimiter: Bracket,\n+                stream: TokenStream [\n+                    Ident {\n+                        ident: \"allow\",\n+                        span: $DIR/simple-tuple.rs:16:33: 16:38 (#0),\n+                    },\n+                    Group {\n+                        delimiter: Parenthesis,\n+                        stream: TokenStream [\n+                            Ident {\n+                                ident: \"unused\",\n+                                span: $DIR/simple-tuple.rs:16:39: 16:45 (#0),\n+                            },\n+                        ],\n+                        span: $DIR/simple-tuple.rs:16:38: 16:46 (#0),\n+                    },\n+                ],\n+                span: $DIR/simple-tuple.rs:16:9: 16:10 (#0),\n+            },\n+            Literal {\n+                kind: Integer,\n+                symbol: \"1\",\n+                suffix: None,\n+                span: $DIR/simple-tuple.rs:17:9: 17:10 (#0),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: $DIR/simple-tuple.rs:17:10: 17:11 (#0),\n+            },\n+            Literal {\n+                kind: Integer,\n+                symbol: \"2\",\n+                suffix: None,\n+                span: $DIR/simple-tuple.rs:17:12: 17:13 (#0),\n+            },\n+            Punct {\n+                ch: ',',\n+                spacing: Alone,\n+                span: $DIR/simple-tuple.rs:17:13: 17:14 (#0),\n+            },\n+            Literal {\n+                kind: Integer,\n+                symbol: \"3\",\n+                suffix: None,\n+                span: $DIR/simple-tuple.rs:17:15: 17:16 (#0),\n+            },\n+        ],\n+        span: $DIR/simple-tuple.rs:15:38: 18:6 (#0),\n+    },\n+    Punct {\n+        ch: ';',\n+        spacing: Alone,\n+        span: $DIR/simple-tuple.rs:18:6: 18:7 (#0),\n+    },\n+]"}, {"sha": "990829456e88af9096080435af6113f22019cdc2", "filename": "src/test/ui/proc-macro/weird-braces.stdout", "status": "modified", "additions": 98, "deletions": 98, "changes": 196, "blob_url": "https://github.com/rust-lang/rust/blob/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fweird-braces.stdout", "raw_url": "https://github.com/rust-lang/rust/raw/ba6275b6a9fc05fd5d93220e9a67fe64d663cb62/src%2Ftest%2Fui%2Fproc-macro%2Fweird-braces.stdout", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fui%2Fproc-macro%2Fweird-braces.stdout?ref=ba6275b6a9fc05fd5d93220e9a67fe64d663cb62", "patch": "@@ -15,40 +15,40 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Punct {\n         ch: '#',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:17:1: 17:2 (#0),\n     },\n     Group {\n         delimiter: Bracket,\n         stream: TokenStream [\n             Ident {\n                 ident: \"print_target_and_args\",\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:17:3: 17:24 (#0),\n             },\n             Group {\n                 delimiter: Parenthesis,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"second_outer\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:17:25: 17:37 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:17:24: 17:38 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:17:2: 17:39 (#0),\n     },\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:1: 18:5 (#0),\n     },\n     Ident {\n         ident: \"Bar\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:6: 18:9 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:9: 18:10 (#0),\n     },\n     Group {\n         delimiter: Brace,\n@@ -57,127 +57,127 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:11: 18:12 (#0),\n             },\n             Punct {\n                 ch: '>',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:13: 18:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:15: 18:16 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:10: 18:17 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:17: 18:18 (#0),\n     },\n     Ident {\n         ident: \"for\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:19: 18:22 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:23: 18:26 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:26: 18:27 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:28: 18:32 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:27: 18:33 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:33: 18:34 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:5: 19:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:6: 19:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:19:8: 19:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"first_inner\",\n-                                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                                span: $DIR/weird-braces.rs:19:30: 19:41 (#0),\n                             },\n                         ],\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:19:29: 19:42 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:7: 19:43 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:5: 20:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:6: 20:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:8: 20:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"second_inner\",\n-                                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                                span: $DIR/weird-braces.rs:20:30: 20:42 (#0),\n                             },\n                         ],\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:29: 20:43 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:7: 20:44 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:35: 21:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): second_outer\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"second_outer\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:17:25: 17:37 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): impl Bar < { 1 > 0 } > for Foo < { true } >\n@@ -188,16 +188,16 @@ PRINT-ATTR INPUT (DISPLAY): impl Bar < { 1 > 0 } > for Foo < { true } >\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:1: 18:5 (#0),\n     },\n     Ident {\n         ident: \"Bar\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:6: 18:9 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:9: 18:10 (#0),\n     },\n     Group {\n         delimiter: Brace,\n@@ -206,144 +206,144 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:11: 18:12 (#0),\n             },\n             Punct {\n                 ch: '>',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:13: 18:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:15: 18:16 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:10: 18:17 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:17: 18:18 (#0),\n     },\n     Ident {\n         ident: \"for\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:19: 18:22 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:23: 18:26 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:26: 18:27 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:28: 18:32 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:27: 18:33 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:33: 18:34 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:5: 19:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:6: 19:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:19:8: 19:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"first_inner\",\n-                                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                                span: $DIR/weird-braces.rs:19:30: 19:41 (#0),\n                             },\n                         ],\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:19:29: 19:42 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:19:7: 19:43 (#0),\n             },\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:5: 20:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:6: 20:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:8: 20:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"second_inner\",\n-                                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                                span: $DIR/weird-braces.rs:20:30: 20:42 (#0),\n                             },\n                         ],\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:29: 20:43 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:7: 20:44 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:35: 21:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): first_inner\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"first_inner\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:19:30: 19:41 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): impl Bar < { 1 > 0 } > for Foo < { true } >\n { # ! [print_target_and_args(second_inner)] }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:1: 18:5 (#0),\n     },\n     Ident {\n         ident: \"Bar\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:6: 18:9 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:9: 18:10 (#0),\n     },\n     Group {\n         delimiter: Brace,\n@@ -352,113 +352,113 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:11: 18:12 (#0),\n             },\n             Punct {\n                 ch: '>',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:13: 18:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:15: 18:16 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:10: 18:17 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:17: 18:18 (#0),\n     },\n     Ident {\n         ident: \"for\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:19: 18:22 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:23: 18:26 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:26: 18:27 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:28: 18:32 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:27: 18:33 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:33: 18:34 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Punct {\n                 ch: '#',\n                 spacing: Joint,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:5: 20:6 (#0),\n             },\n             Punct {\n                 ch: '!',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:6: 20:7 (#0),\n             },\n             Group {\n                 delimiter: Bracket,\n                 stream: TokenStream [\n                     Ident {\n                         ident: \"print_target_and_args\",\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:8: 20:29 (#0),\n                     },\n                     Group {\n                         delimiter: Parenthesis,\n                         stream: TokenStream [\n                             Ident {\n                                 ident: \"second_inner\",\n-                                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                                span: $DIR/weird-braces.rs:20:30: 20:42 (#0),\n                             },\n                         ],\n-                        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                        span: $DIR/weird-braces.rs:20:29: 20:43 (#0),\n                     },\n                 ],\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:20:7: 20:44 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:35: 21:2 (#0),\n     },\n ]\n PRINT-ATTR_ARGS INPUT (DISPLAY): second_inner\n PRINT-ATTR_ARGS INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"second_inner\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:20:30: 20:42 (#0),\n     },\n ]\n PRINT-ATTR INPUT (DISPLAY): impl Bar < { 1 > 0 } > for Foo < { true } > { }\n PRINT-ATTR INPUT (DEBUG): TokenStream [\n     Ident {\n         ident: \"impl\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:1: 18:5 (#0),\n     },\n     Ident {\n         ident: \"Bar\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:6: 18:9 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:9: 18:10 (#0),\n     },\n     Group {\n         delimiter: Brace,\n@@ -467,58 +467,58 @@ PRINT-ATTR INPUT (DEBUG): TokenStream [\n                 kind: Integer,\n                 symbol: \"1\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:11: 18:12 (#0),\n             },\n             Punct {\n                 ch: '>',\n                 spacing: Alone,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:13: 18:14 (#0),\n             },\n             Literal {\n                 kind: Integer,\n                 symbol: \"0\",\n                 suffix: None,\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:15: 18:16 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:10: 18:17 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:17: 18:18 (#0),\n     },\n     Ident {\n         ident: \"for\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:19: 18:22 (#0),\n     },\n     Ident {\n         ident: \"Foo\",\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:23: 18:26 (#0),\n     },\n     Punct {\n         ch: '<',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:26: 18:27 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [\n             Ident {\n                 ident: \"true\",\n-                span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+                span: $DIR/weird-braces.rs:18:28: 18:32 (#0),\n             },\n         ],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:27: 18:33 (#0),\n     },\n     Punct {\n         ch: '>',\n         spacing: Alone,\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:33: 18:34 (#0),\n     },\n     Group {\n         delimiter: Brace,\n         stream: TokenStream [],\n-        span: $DIR/weird-braces.rs:18:1: 21:2 (#0),\n+        span: $DIR/weird-braces.rs:18:35: 21:2 (#0),\n     },\n ]"}]}