{"sha": "d02b31ca3c2c438d88ff8f029791e80050508dcd", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQwMmIzMWNhM2MyYzQzOGQ4OGZmOGYwMjk3OTFlODAwNTA1MDhkY2Q=", "commit": {"author": {"name": "Yuki Okushi", "email": "huyuumi.dev@gmail.com", "date": "2021-01-07T17:06:07Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-01-07T17:06:07Z"}, "message": "Rollup merge of #80659 - pierwill:edit-tokenstream, r=davidtwco\n\nEdit rustc_ast::tokenstream docs\n\nFix some punctuation and wording, and add intra-documentation links.", "tree": {"sha": "f451c29ed1e7e848485b9458257b4f3c71de172e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f451c29ed1e7e848485b9458257b4f3c71de172e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d02b31ca3c2c438d88ff8f029791e80050508dcd", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJf9z+ACRBK7hj4Ov3rIwAAdHIIAE6VlNclGKTUYB0/3nwdvybk\nJLLeR/3End8O42XvzPJhegkm206I3ePS2E9ejvXVVMNme9JoyLMPuzUlUGzQBmms\nWrwU4ChvziJP14Y6yBjo97a308+xQGleCwp15tbAp60qtPexmZ6+mgZrDehVPE/V\nSiKhLR8lxBx8kVwC8KJ/JRQ+Db1nkgvSmfNdifRdaR+MH2zK3eBC4V3pgP4Nnb7G\nzXdxm0m/2zjZIMnsXkmdAyT+Y6uRAy3n8x2husxGSoMhVk1cN3VpooTTDdx+2smD\n/KA5g046iMmQ2WViVAtBZkjS+hbOPEXJkU08GE7C1v9oEciZrvK2XjBKH4eIYCI=\n=TpVV\n-----END PGP SIGNATURE-----\n", "payload": "tree f451c29ed1e7e848485b9458257b4f3c71de172e\nparent 3acd75dd25bd59712d92cee23ff4932fe27cf7ce\nparent 9a240e485758889426af78a230f198c00c77f967\nauthor Yuki Okushi <huyuumi.dev@gmail.com> 1610039167 +0900\ncommitter GitHub <noreply@github.com> 1610039167 +0900\n\nRollup merge of #80659 - pierwill:edit-tokenstream, r=davidtwco\n\nEdit rustc_ast::tokenstream docs\n\nFix some punctuation and wording, and add intra-documentation links.\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d02b31ca3c2c438d88ff8f029791e80050508dcd", "html_url": "https://github.com/rust-lang/rust/commit/d02b31ca3c2c438d88ff8f029791e80050508dcd", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d02b31ca3c2c438d88ff8f029791e80050508dcd/comments", "author": {"login": "JohnTitor", "id": 25030997, "node_id": "MDQ6VXNlcjI1MDMwOTk3", "avatar_url": "https://avatars.githubusercontent.com/u/25030997?v=4", "gravatar_id": "", "url": "https://api.github.com/users/JohnTitor", "html_url": "https://github.com/JohnTitor", "followers_url": "https://api.github.com/users/JohnTitor/followers", "following_url": "https://api.github.com/users/JohnTitor/following{/other_user}", "gists_url": "https://api.github.com/users/JohnTitor/gists{/gist_id}", "starred_url": "https://api.github.com/users/JohnTitor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/JohnTitor/subscriptions", "organizations_url": "https://api.github.com/users/JohnTitor/orgs", "repos_url": "https://api.github.com/users/JohnTitor/repos", "events_url": "https://api.github.com/users/JohnTitor/events{/privacy}", "received_events_url": "https://api.github.com/users/JohnTitor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3acd75dd25bd59712d92cee23ff4932fe27cf7ce", "url": "https://api.github.com/repos/rust-lang/rust/commits/3acd75dd25bd59712d92cee23ff4932fe27cf7ce", "html_url": "https://github.com/rust-lang/rust/commit/3acd75dd25bd59712d92cee23ff4932fe27cf7ce"}, {"sha": "9a240e485758889426af78a230f198c00c77f967", "url": "https://api.github.com/repos/rust-lang/rust/commits/9a240e485758889426af78a230f198c00c77f967", "html_url": "https://github.com/rust-lang/rust/commit/9a240e485758889426af78a230f198c00c77f967"}], "stats": {"total": 33, "additions": 17, "deletions": 16}, "files": [{"sha": "00354b42ebb7c85bc36026fca438b054a9267c8f", "filename": "compiler/rustc_ast/src/tokenstream.rs", "status": "modified", "additions": 17, "deletions": 16, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/d02b31ca3c2c438d88ff8f029791e80050508dcd/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d02b31ca3c2c438d88ff8f029791e80050508dcd/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_ast%2Fsrc%2Ftokenstream.rs?ref=d02b31ca3c2c438d88ff8f029791e80050508dcd", "patch": "@@ -1,15 +1,15 @@\n //! # Token Streams\n //!\n //! `TokenStream`s represent syntactic objects before they are converted into ASTs.\n-//! A `TokenStream` is, roughly speaking, a sequence (eg stream) of `TokenTree`s,\n-//! which are themselves a single `Token` or a `Delimited` subsequence of tokens.\n+//! A `TokenStream` is, roughly speaking, a sequence of [`TokenTree`]s,\n+//! which are themselves a single [`Token`] or a `Delimited` subsequence of tokens.\n //!\n //! ## Ownership\n //!\n //! `TokenStream`s are persistent data structures constructed as ropes with reference\n //! counted-children. In general, this means that calling an operation on a `TokenStream`\n //! (such as `slice`) produces an entirely new `TokenStream` from the borrowed reference to\n-//! the original. This essentially coerces `TokenStream`s into 'views' of their subparts,\n+//! the original. This essentially coerces `TokenStream`s into \"views\" of their subparts,\n //! and a borrowed `TokenStream` is sufficient to build an owned `TokenStream` without taking\n //! ownership of the original.\n \n@@ -24,9 +24,9 @@ use smallvec::{smallvec, SmallVec};\n \n use std::{fmt, iter, mem};\n \n-/// When the main rust parser encounters a syntax-extension invocation, it\n-/// parses the arguments to the invocation as a token-tree. This is a very\n-/// loose structure, such that all sorts of different AST-fragments can\n+/// When the main Rust parser encounters a syntax-extension invocation, it\n+/// parses the arguments to the invocation as a token tree. This is a very\n+/// loose structure, such that all sorts of different AST fragments can\n /// be passed to syntax extensions using a uniform type.\n ///\n /// If the syntax extension is an MBE macro, it will attempt to match its\n@@ -38,9 +38,9 @@ use std::{fmt, iter, mem};\n /// Nothing special happens to misnamed or misplaced `SubstNt`s.\n #[derive(Debug, Clone, PartialEq, Encodable, Decodable, HashStable_Generic)]\n pub enum TokenTree {\n-    /// A single token\n+    /// A single token.\n     Token(Token),\n-    /// A delimited sequence of token trees\n+    /// A delimited sequence of token trees.\n     Delimited(DelimSpan, DelimToken, TokenStream),\n }\n \n@@ -62,7 +62,7 @@ where\n }\n \n impl TokenTree {\n-    /// Checks if this TokenTree is equal to the other, regardless of span information.\n+    /// Checks if this `TokenTree` is equal to the other, regardless of span information.\n     pub fn eq_unspanned(&self, other: &TokenTree) -> bool {\n         match (self, other) {\n             (TokenTree::Token(token), TokenTree::Token(token2)) => token.kind == token2.kind,\n@@ -73,7 +73,7 @@ impl TokenTree {\n         }\n     }\n \n-    /// Retrieves the TokenTree's span.\n+    /// Retrieves the `TokenTree`'s span.\n     pub fn span(&self) -> Span {\n         match self {\n             TokenTree::Token(token) => token.span,\n@@ -140,7 +140,7 @@ impl CreateTokenStream for TokenStream {\n     }\n }\n \n-/// A lazy version of `TokenStream`, which defers creation\n+/// A lazy version of [`TokenStream`], which defers creation\n /// of an actual `TokenStream` until it is needed.\n /// `Box` is here only to reduce the structure size.\n #[derive(Clone)]\n@@ -188,11 +188,12 @@ impl<CTX> HashStable<CTX> for LazyTokenStream {\n     }\n }\n \n-/// A `TokenStream` is an abstract sequence of tokens, organized into `TokenTree`s.\n+/// A `TokenStream` is an abstract sequence of tokens, organized into [`TokenTree`]s.\n ///\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n-/// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n+/// Today's `TokenTree`s can still contain AST via `token::Interpolated` for\n+/// backwards compatability.\n #[derive(Clone, Debug, Default, Encodable, Decodable)]\n pub struct TokenStream(pub(crate) Lrc<Vec<TreeAndSpacing>>);\n \n@@ -429,7 +430,7 @@ impl TokenStreamBuilder {\n     }\n }\n \n-/// By-reference iterator over a `TokenStream`.\n+/// By-reference iterator over a [`TokenStream`].\n #[derive(Clone)]\n pub struct CursorRef<'t> {\n     stream: &'t TokenStream,\n@@ -457,8 +458,8 @@ impl<'t> Iterator for CursorRef<'t> {\n     }\n }\n \n-/// Owning by-value iterator over a `TokenStream`.\n-/// FIXME: Many uses of this can be replaced with by-reference iterator to avoid clones.\n+/// Owning by-value iterator over a [`TokenStream`].\n+// FIXME: Many uses of this can be replaced with by-reference iterator to avoid clones.\n #[derive(Clone)]\n pub struct Cursor {\n     pub stream: TokenStream,"}]}