{"sha": "b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "node_id": "C_kwDOAAsO6NoAKGI1ZWNiYmI5OThhYWU4MDU0MWQ3MGJmNWM5M2JlOTJlNmM1OWE3YTg", "commit": {"author": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2023-02-01T01:43:13Z"}, "committer": {"name": "Nicholas Nethercote", "email": "n.nethercote@gmail.com", "date": "2023-02-02T23:06:52Z"}, "message": "Remove `TokenCursorFrame`.\n\nThe motivation here is to eliminate the `Option<(Delimiter,\nDelimSpan)>`, which is `None` for the outermost token stream and `Some`\nfor all other token streams.\n\nWe are already treating the innermost frame specially -- this is the\n`frame` vs `stack` distinction in `TokenCursor`. We can push that\nfurther so that `frame` only contains the cursor, and `stack` elements\ncontain the delimiters for their children. When we are in the outermost\ntoken stream `stack` is empty, so there are no stored delimiters, which\nis what we want because the outermost token stream *has* no delimiters.\n\nThis change also shrinks `TokenCursor`, which shrinks `Parser` and\n`LazyAttrTokenStreamImpl`, which is nice.", "tree": {"sha": "5113f17ff004a5b175a4d5a23e0f17b14e1c79dd", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5113f17ff004a5b175a4d5a23e0f17b14e1c79dd"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "html_url": "https://github.com/rust-lang/rust/commit/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b23f272db017c3bfd8cdf57fad6e5fdd057168c6", "url": "https://api.github.com/repos/rust-lang/rust/commits/b23f272db017c3bfd8cdf57fad6e5fdd057168c6", "html_url": "https://github.com/rust-lang/rust/commit/b23f272db017c3bfd8cdf57fad6e5fdd057168c6"}], "stats": {"total": 76, "additions": 34, "deletions": 42}, "files": [{"sha": "dbd3b76786f42c56d67f44aee2c6d5f588212baa", "filename": "compiler/rustc_parse/src/parser/attr_wrapper.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fattr_wrapper.rs?ref=b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "patch": "@@ -469,6 +469,6 @@ mod size_asserts {\n     use rustc_data_structures::static_assert_size;\n     // tidy-alphabetical-start\n     static_assert_size!(AttrWrapper, 16);\n-    static_assert_size!(LazyAttrTokenStreamImpl, 144);\n+    static_assert_size!(LazyAttrTokenStreamImpl, 120);\n     // tidy-alphabetical-end\n }"}, {"sha": "68849f817aa5a4df977650960c908dfbf21df144", "filename": "compiler/rustc_parse/src/parser/expr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fexpr.rs?ref=b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "patch": "@@ -2141,7 +2141,7 @@ impl<'a> Parser<'a> {\n         }\n \n         if self.token.kind == TokenKind::Semi\n-            && matches!(self.token_cursor.frame.delim_sp, Some((Delimiter::Parenthesis, _)))\n+            && matches!(self.token_cursor.stack.last(), Some((_, Delimiter::Parenthesis, _)))\n             && self.may_recover()\n         {\n             // It is likely that the closure body is a block but where the"}, {"sha": "982fde727c8983e6418169e3f4c95d709b8b2f91", "filename": "compiler/rustc_parse/src/parser/mod.rs", "status": "modified", "additions": 32, "deletions": 40, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b5ecbbb998aae80541d70bf5c93be92e6c59a7a8/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Fparser%2Fmod.rs?ref=b5ecbbb998aae80541d70bf5c93be92e6c59a7a8", "patch": "@@ -168,7 +168,7 @@ pub struct Parser<'a> {\n // This type is used a lot, e.g. it's cloned when matching many declarative macro rules with nonterminals. Make sure\n // it doesn't unintentionally get bigger.\n #[cfg(all(target_arch = \"x86_64\", target_pointer_width = \"64\"))]\n-rustc_data_structures::static_assert_size!(Parser<'_>, 336);\n+rustc_data_structures::static_assert_size!(Parser<'_>, 312);\n \n /// Stores span information about a closure.\n #[derive(Clone)]\n@@ -223,16 +223,21 @@ impl<'a> Drop for Parser<'a> {\n \n #[derive(Clone)]\n struct TokenCursor {\n-    // The current (innermost) frame. `frame` and `stack` could be combined,\n-    // but it's faster to keep them separate and access `frame` directly\n-    // rather than via something like `stack.last().unwrap()` or\n-    // `stack[stack.len() - 1]`.\n-    frame: TokenCursorFrame,\n-    // Additional frames that enclose `frame`.\n-    stack: Vec<TokenCursorFrame>,\n+    // Cursor for the current (innermost) token stream. The delimiters for this\n+    // token stream are found in `self.stack.last()`; when that is `None` then\n+    // we are in the outermost token stream which never has delimiters.\n+    tree_cursor: tokenstream::Cursor,\n+\n+    // Token streams surrounding the current one. The delimiters for stack[n]'s\n+    // tokens are in `stack[n-1]`. `stack[0]` (when present) has no delimiters\n+    // because it's the outermost token stream which never has delimiters.\n+    stack: Vec<(tokenstream::Cursor, Delimiter, DelimSpan)>,\n+\n     desugar_doc_comments: bool,\n+\n     // Counts the number of calls to `{,inlined_}next`.\n     num_next_calls: usize,\n+\n     // During parsing, we may sometimes need to 'unglue' a\n     // glued token into two component tokens\n     // (e.g. '>>' into '>' and '>), so that the parser\n@@ -257,19 +262,6 @@ struct TokenCursor {\n     break_last_token: bool,\n }\n \n-#[derive(Clone)]\n-struct TokenCursorFrame {\n-    // This is `None` only for the outermost frame.\n-    delim_sp: Option<(Delimiter, DelimSpan)>,\n-    tree_cursor: tokenstream::Cursor,\n-}\n-\n-impl TokenCursorFrame {\n-    fn new(delim_sp: Option<(Delimiter, DelimSpan)>, tts: TokenStream) -> Self {\n-        TokenCursorFrame { delim_sp, tree_cursor: tts.into_trees() }\n-    }\n-}\n-\n impl TokenCursor {\n     fn next(&mut self, desugar_doc_comments: bool) -> (Token, Spacing) {\n         self.inlined_next(desugar_doc_comments)\n@@ -282,12 +274,12 @@ impl TokenCursor {\n             // FIXME: we currently don't return `Delimiter` open/close delims. To fix #67062 we will\n             // need to, whereupon the `delim != Delimiter::Invisible` conditions below can be\n             // removed.\n-            if let Some(tree) = self.frame.tree_cursor.next_ref() {\n+            if let Some(tree) = self.tree_cursor.next_ref() {\n                 match tree {\n                     &TokenTree::Token(ref token, spacing) => match (desugar_doc_comments, token) {\n                         (true, &Token { kind: token::DocComment(_, attr_style, data), span }) => {\n                             let desugared = self.desugar(attr_style, data, span);\n-                            self.frame.tree_cursor.replace_prev_and_rewind(desugared);\n+                            self.tree_cursor.replace_prev_and_rewind(desugared);\n                             // Continue to get the first token of the desugared doc comment.\n                         }\n                         _ => {\n@@ -299,25 +291,23 @@ impl TokenCursor {\n                         }\n                     },\n                     &TokenTree::Delimited(sp, delim, ref tts) => {\n-                        // Set `open_delim` to true here because we deal with it immediately.\n-                        let frame = TokenCursorFrame::new(Some((delim, sp)), tts.clone());\n-                        self.stack.push(mem::replace(&mut self.frame, frame));\n+                        let trees = tts.clone().into_trees();\n+                        self.stack.push((mem::replace(&mut self.tree_cursor, trees), delim, sp));\n                         if delim != Delimiter::Invisible {\n                             return (Token::new(token::OpenDelim(delim), sp.open), Spacing::Alone);\n                         }\n                         // No open delimiter to return; continue on to the next iteration.\n                     }\n                 };\n-            } else if let Some(frame) = self.stack.pop() {\n-                // We have exhausted this frame. Move back to its parent frame.\n-                let (delim, span) = self.frame.delim_sp.unwrap();\n-                self.frame = frame;\n+            } else if let Some((tree_cursor, delim, span)) = self.stack.pop() {\n+                // We have exhausted this token stream. Move back to its parent token stream.\n+                self.tree_cursor = tree_cursor;\n                 if delim != Delimiter::Invisible {\n                     return (Token::new(token::CloseDelim(delim), span.close), Spacing::Alone);\n                 }\n                 // No close delimiter to return; continue on to the next iteration.\n             } else {\n-                // We have exhausted the outermost frame.\n+                // We have exhausted the outermost token stream.\n                 return (Token::new(token::Eof, DUMMY_SP), Spacing::Alone);\n             }\n         }\n@@ -475,7 +465,7 @@ impl<'a> Parser<'a> {\n             restrictions: Restrictions::empty(),\n             expected_tokens: Vec::new(),\n             token_cursor: TokenCursor {\n-                frame: TokenCursorFrame::new(None, tokens),\n+                tree_cursor: tokens.into_trees(),\n                 stack: Vec::new(),\n                 num_next_calls: 0,\n                 desugar_doc_comments,\n@@ -1142,14 +1132,16 @@ impl<'a> Parser<'a> {\n             return looker(&self.token);\n         }\n \n-        let frame = &self.token_cursor.frame;\n-        if let Some((delim, span)) = frame.delim_sp && delim != Delimiter::Invisible {\n+        let tree_cursor = &self.token_cursor.tree_cursor;\n+        if let Some(&(_, delim, span)) = self.token_cursor.stack.last()\n+            && delim != Delimiter::Invisible\n+        {\n             let all_normal = (0..dist).all(|i| {\n-                let token = frame.tree_cursor.look_ahead(i);\n+                let token = tree_cursor.look_ahead(i);\n                 !matches!(token, Some(TokenTree::Delimited(_, Delimiter::Invisible, _)))\n             });\n             if all_normal {\n-                return match frame.tree_cursor.look_ahead(dist - 1) {\n+                return match tree_cursor.look_ahead(dist - 1) {\n                     Some(tree) => match tree {\n                         TokenTree::Token(token, _) => looker(token),\n                         TokenTree::Delimited(dspan, delim, _) => {\n@@ -1310,10 +1302,10 @@ impl<'a> Parser<'a> {\n     pub(crate) fn parse_token_tree(&mut self) -> TokenTree {\n         match self.token.kind {\n             token::OpenDelim(..) => {\n-                // Grab the tokens from this frame.\n-                let frame = &self.token_cursor.frame;\n-                let stream = frame.tree_cursor.stream.clone();\n-                let (delim, span) = frame.delim_sp.unwrap();\n+                // Grab the tokens within the delimiters.\n+                let tree_cursor = &self.token_cursor.tree_cursor;\n+                let stream = tree_cursor.stream.clone();\n+                let (_, delim, span) = *self.token_cursor.stack.last().unwrap();\n \n                 // Advance the token cursor through the entire delimited\n                 // sequence. After getting the `OpenDelim` we are *within* the"}]}