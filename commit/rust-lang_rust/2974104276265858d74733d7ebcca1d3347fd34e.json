{"sha": "2974104276265858d74733d7ebcca1d3347fd34e", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI5NzQxMDQyNzYyNjU4NThkNzQ3MzNkN2ViY2NhMWQzMzQ3ZmQzNGU=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-12-14T15:37:39Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-12-14T15:37:39Z"}, "message": "Auto merge of #45002 - oli-obk:miri, r=eddyb\n\nValidate miri against the HIR const evaluator\n\nr? @eddyb\n\ncc @alexcrichton @arielb1 @RalfJung\n\nThe interesting parts are the last few functions in `librustc_const_eval/eval.rs`\n\n* We warn if miri produces an error while HIR const eval does not.\n* We warn if miri produces a value that does not match the value produced by HIR const eval\n* if miri succeeds and HIR const eval fails, nothing is emitted, but we still return the HIR error\n* if both error, nothing is emitted and the HIR const eval error is returned\n\nSo there are no actual changes, except that miri is forced to produce the same values as the old const eval.\n\n* This does **not** touch the const evaluator in trans at all. That will come in a future PR.\n* This does **not** cause any code to compile that didn't compile before. That will also come in the future\n\nIt would be great if someone could start a crater run if travis passes", "tree": {"sha": "3095c0f81251260b751ccc6c6fe855ba116339a4", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3095c0f81251260b751ccc6c6fe855ba116339a4"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2974104276265858d74733d7ebcca1d3347fd34e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2974104276265858d74733d7ebcca1d3347fd34e", "html_url": "https://github.com/rust-lang/rust/commit/2974104276265858d74733d7ebcca1d3347fd34e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2974104276265858d74733d7ebcca1d3347fd34e/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8624ea51172c8a86d5c7c47d740be65a3a9efbc6", "url": "https://api.github.com/repos/rust-lang/rust/commits/8624ea51172c8a86d5c7c47d740be65a3a9efbc6", "html_url": "https://github.com/rust-lang/rust/commit/8624ea51172c8a86d5c7c47d740be65a3a9efbc6"}, {"sha": "7a2bff7f1a253f6f3d713c153d651f4d52038be5", "url": "https://api.github.com/repos/rust-lang/rust/commits/7a2bff7f1a253f6f3d713c153d651f4d52038be5", "html_url": "https://github.com/rust-lang/rust/commit/7a2bff7f1a253f6f3d713c153d651f4d52038be5"}], "stats": {"total": 6607, "additions": 6548, "deletions": 59}, "files": [{"sha": "d0f1dbcfd3c9afdea237b33b7cb0bf0b53a310cf", "filename": ".travis.yml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/.travis.yml", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/.travis.yml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.travis.yml?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -294,6 +294,7 @@ before_deploy:\n           cp -r obj/build/dist/* deploy/$TRAVIS_COMMIT;\n       fi\n   - travis_retry gem update --system\n+  - ls -la deploy/$TRAVIS_COMMIT\n \n deploy:\n   - provider: s3"}, {"sha": "27e7438ddfd2602bf9a1de72a564bcc85ac536cf", "filename": "src/Cargo.lock", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -164,6 +164,11 @@ dependencies = [\n  \"filetime 0.1.14 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n+[[package]]\n+name = \"byteorder\"\n+version = \"1.1.0\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+\n [[package]]\n name = \"cargo\"\n version = \"0.25.0\"\n@@ -1020,6 +1025,14 @@ name = \"log\"\n version = \"0.3.8\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \n+[[package]]\n+name = \"log_settings\"\n+version = \"0.1.1\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+dependencies = [\n+ \"lazy_static 0.2.11 (registry+https://github.com/rust-lang/crates.io-index)\",\n+]\n+\n [[package]]\n name = \"lzma-sys\"\n version = \"0.1.9\"\n@@ -1598,13 +1611,16 @@ name = \"rustc\"\n version = \"0.0.0\"\n dependencies = [\n  \"arena 0.0.0\",\n+ \"backtrace 0.3.4 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"bitflags 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"byteorder 1.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"flate2 0.2.20 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"fmt_macros 0.0.0\",\n  \"graphviz 0.0.0\",\n  \"jobserver 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"log 0.3.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"owning_ref 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"rustc_apfloat 0.0.0\",\n  \"rustc_back 0.0.0\",\n  \"rustc_const_math 0.0.0\",\n  \"rustc_data_structures 0.0.0\",\n@@ -1844,9 +1860,12 @@ name = \"rustc_mir\"\n version = \"0.0.0\"\n dependencies = [\n  \"bitflags 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"byteorder 1.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"graphviz 0.0.0\",\n  \"log 0.3.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"log_settings 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc 0.0.0\",\n+ \"rustc_apfloat 0.0.0\",\n  \"rustc_const_eval 0.0.0\",\n  \"rustc_const_math 0.0.0\",\n  \"rustc_data_structures 0.0.0\",\n@@ -2679,6 +2698,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \"checksum bitflags 0.9.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"4efd02e230a02e18f92fc2735f44597385ed02ad8f831e7c1c1156ee5e1ab3a5\"\n \"checksum bitflags 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"b3c30d3802dfb7281680d6285f2ccdaa8c2d8fee41f93805dba5c4cf50dc23cf\"\n \"checksum bufstream 0.1.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"f2f382711e76b9de6c744cc00d0497baba02fb00a787f088c879f01d09468e32\"\n+\"checksum byteorder 1.1.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"ff81738b726f5d099632ceaffe7fb65b90212e8dce59d518729e7e8634032d3d\"\n \"checksum cargo_metadata 0.2.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"be1057b8462184f634c3a208ee35b0f935cfd94b694b26deadccd98732088d7b\"\n \"checksum cargo_metadata 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"1f56ec3e469bca7c276f2eea015aa05c5e381356febdbb0683c2580189604537\"\n \"checksum cc 1.0.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"a9b13a57efd6b30ecd6598ebdb302cca617930b5470647570468a65d12ef9719\"\n@@ -2749,6 +2769,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \"checksum libssh2-sys 0.2.6 (registry+https://github.com/rust-lang/crates.io-index)\" = \"0db4ec23611747ef772db1c4d650f8bd762f07b461727ec998f953c614024b75\"\n \"checksum libz-sys 1.0.18 (registry+https://github.com/rust-lang/crates.io-index)\" = \"87f737ad6cc6fd6eefe3d9dc5412f1573865bded441300904d2f42269e140f16\"\n \"checksum log 0.3.8 (registry+https://github.com/rust-lang/crates.io-index)\" = \"880f77541efa6e5cc74e76910c9884d9859683118839d6a1dc3b11e63512565b\"\n+\"checksum log_settings 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"3d382732ea0fbc09790c4899db3255bdea0fc78b54bf234bd18a63bb603915b6\"\n \"checksum lzma-sys 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\" = \"c1b93b78f89e8737dac81837fc8f5521ac162abcba902e1a3db949d55346d1da\"\n \"checksum mac 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"c41e0c4fef86961ac6d6f8a82609f55f31b05e4fce149ac5710e439df7619ba4\"\n \"checksum markup5ever 0.5.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"047150a0e03b57e638fc45af33a0b63a0362305d5b9f92ecef81df472a4cceb0\""}, {"sha": "30afd52f4482401896dad3f7c97c51ef16ccfbbf", "filename": "src/bootstrap/bin/rustc.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fbin%2Frustc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fbin%2Frustc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbin%2Frustc.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -246,6 +246,9 @@ fn main() {\n         // When running miri tests, we need to generate MIR for all libraries\n         if env::var(\"TEST_MIRI\").ok().map_or(false, |val| val == \"true\") {\n             cmd.arg(\"-Zalways-encode-mir\");\n+            if stage != \"0\" {\n+                cmd.arg(\"-Zmiri\");\n+            }\n             cmd.arg(\"-Zmir-emit-validate=1\");\n         }\n "}, {"sha": "bdc00295a2041073dd15476f4ff91dae482d0886", "filename": "src/bootstrap/builder.rs", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fbuilder.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -499,9 +499,10 @@ impl<'a> Builder<'a> {\n         if mode != Mode::Tool {\n             // Tools don't get debuginfo right now, e.g. cargo and rls don't\n             // get compiled with debuginfo.\n-            cargo.env(\"RUSTC_DEBUGINFO\", self.config.rust_debuginfo.to_string())\n-                 .env(\"RUSTC_DEBUGINFO_LINES\", self.config.rust_debuginfo_lines.to_string())\n-                 .env(\"RUSTC_FORCE_UNSTABLE\", \"1\");\n+            // Adding debuginfo increases their sizes by a factor of 3-4.\n+            cargo.env(\"RUSTC_DEBUGINFO\", self.config.rust_debuginfo.to_string());\n+            cargo.env(\"RUSTC_DEBUGINFO_LINES\", self.config.rust_debuginfo_lines.to_string());\n+            cargo.env(\"RUSTC_FORCE_UNSTABLE\", \"1\");\n \n             // Currently the compiler depends on crates from crates.io, and\n             // then other crates can depend on the compiler (e.g. proc-macro"}, {"sha": "eee403dcbe3e759f5ffeebb473107146fe5d9d6c", "filename": "src/bootstrap/check.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fcheck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Fbootstrap%2Fcheck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fbootstrap%2Fcheck.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -321,6 +321,7 @@ impl Step for Rustfmt {\n \n #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]\n pub struct Miri {\n+    stage: u32,\n     host: Interned<String>,\n }\n \n@@ -336,15 +337,17 @@ impl Step for Miri {\n \n     fn make_run(run: RunConfig) {\n         run.builder.ensure(Miri {\n+            stage: run.builder.top_stage,\n             host: run.target,\n         });\n     }\n \n     /// Runs `cargo test` for miri.\n     fn run(self, builder: &Builder) {\n         let build = builder.build;\n+        let stage = self.stage;\n         let host = self.host;\n-        let compiler = builder.compiler(1, host);\n+        let compiler = builder.compiler(stage, host);\n \n         if let Some(miri) = builder.ensure(tool::Miri { compiler, target: self.host }) {\n             let mut cargo = builder.cargo(compiler, Mode::Tool, host, \"test\");\n@@ -766,6 +769,7 @@ impl Step for Compiletest {\n         if build.config.rust_debuginfo_tests {\n             flags.push(\"-g\".to_string());\n         }\n+        flags.push(\"-Zmiri -Zunstable-options\".to_string());\n \n         if let Some(linker) = build.linker(target) {\n             cmd.arg(\"--linker\").arg(linker);"}, {"sha": "a8892cb22101a6245cedd353d4c250f54d4d18f7", "filename": "src/librustc/Cargo.toml", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2FCargo.toml?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -16,13 +16,17 @@ graphviz = { path = \"../libgraphviz\" }\n jobserver = \"0.1\"\n log = \"0.3\"\n owning_ref = \"0.3.3\"\n+rustc_apfloat = { path = \"../librustc_apfloat\" }\n rustc_back = { path = \"../librustc_back\" }\n rustc_const_math = { path = \"../librustc_const_math\" }\n rustc_data_structures = { path = \"../librustc_data_structures\" }\n rustc_errors = { path = \"../librustc_errors\" }\n serialize = { path = \"../libserialize\" }\n syntax = { path = \"../libsyntax\" }\n syntax_pos = { path = \"../libsyntax_pos\" }\n+backtrace = \"0.3.3\"\n+byteorder = { version = \"1.1\", features = [\"i128\"]}\n+\n \n # Note that these dependencies are a lie, they're just here to get linkage to\n # work."}, {"sha": "bf7484156a64a0dff0d95dea4a92fdb1ae5273aa", "filename": "src/librustc/lib.rs", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Flib.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -64,6 +64,7 @@\n #![feature(unboxed_closures)]\n #![feature(underscore_lifetimes)]\n #![feature(trace_macros)]\n+#![feature(catch_expr)]\n #![feature(test)]\n \n #![recursion_limit=\"512\"]\n@@ -89,6 +90,10 @@ extern crate jobserver;\n \n extern crate serialize as rustc_serialize; // used by deriving\n \n+extern crate rustc_apfloat;\n+extern crate byteorder;\n+extern crate backtrace;\n+\n // Note that librustc doesn't actually depend on these crates, see the note in\n // `Cargo.toml` for this crate about why these are here.\n #[allow(unused_extern_crates)]"}, {"sha": "9ebfe25c107a909ec6a6fa11f078be9a842df75f", "filename": "src/librustc/mir/interpret/error.rs", "status": "added", "additions": 322, "deletions": 0, "changes": 322, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Ferror.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,322 @@\n+use std::error::Error;\n+use std::{fmt, env};\n+\n+use mir;\n+use ty::{FnSig, Ty, layout};\n+\n+use super::{\n+    MemoryPointer, Lock, AccessKind\n+};\n+\n+use rustc_const_math::ConstMathErr;\n+use syntax::codemap::Span;\n+use backtrace::Backtrace;\n+\n+#[derive(Debug)]\n+pub struct EvalError<'tcx> {\n+    pub kind: EvalErrorKind<'tcx>,\n+    pub backtrace: Option<Backtrace>,\n+}\n+\n+impl<'tcx> From<EvalErrorKind<'tcx>> for EvalError<'tcx> {\n+    fn from(kind: EvalErrorKind<'tcx>) -> Self {\n+        let backtrace = match env::var(\"RUST_BACKTRACE\") {\n+            Ok(ref val) if !val.is_empty() => Some(Backtrace::new_unresolved()),\n+            _ => None\n+        };\n+        EvalError {\n+            kind,\n+            backtrace,\n+        }\n+    }\n+}\n+\n+#[derive(Debug)]\n+pub enum EvalErrorKind<'tcx> {\n+    /// This variant is used by machines to signal their own errors that do not\n+    /// match an existing variant\n+    MachineError(Box<Error>),\n+    FunctionPointerTyMismatch(FnSig<'tcx>, FnSig<'tcx>),\n+    NoMirFor(String),\n+    UnterminatedCString(MemoryPointer),\n+    DanglingPointerDeref,\n+    DoubleFree,\n+    InvalidMemoryAccess,\n+    InvalidFunctionPointer,\n+    InvalidBool,\n+    InvalidDiscriminant,\n+    PointerOutOfBounds {\n+        ptr: MemoryPointer,\n+        access: bool,\n+        allocation_size: u64,\n+    },\n+    InvalidNullPointerUsage,\n+    ReadPointerAsBytes,\n+    ReadBytesAsPointer,\n+    InvalidPointerMath,\n+    ReadUndefBytes,\n+    DeadLocal,\n+    InvalidBoolOp(mir::BinOp),\n+    Unimplemented(String),\n+    DerefFunctionPointer,\n+    ExecuteMemory,\n+    ArrayIndexOutOfBounds(Span, u64, u64),\n+    Math(Span, ConstMathErr),\n+    Intrinsic(String),\n+    OverflowingMath,\n+    InvalidChar(u128),\n+    OutOfMemory {\n+        allocation_size: u64,\n+        memory_size: u64,\n+        memory_usage: u64,\n+    },\n+    ExecutionTimeLimitReached,\n+    StackFrameLimitReached,\n+    OutOfTls,\n+    TlsOutOfBounds,\n+    AbiViolation(String),\n+    AlignmentCheckFailed {\n+        required: u64,\n+        has: u64,\n+    },\n+    MemoryLockViolation {\n+        ptr: MemoryPointer,\n+        len: u64,\n+        frame: usize,\n+        access: AccessKind,\n+        lock: Lock,\n+    },\n+    MemoryAcquireConflict {\n+        ptr: MemoryPointer,\n+        len: u64,\n+        kind: AccessKind,\n+        lock: Lock,\n+    },\n+    InvalidMemoryLockRelease {\n+        ptr: MemoryPointer,\n+        len: u64,\n+        frame: usize,\n+        lock: Lock,\n+    },\n+    DeallocatedLockedMemory {\n+        ptr: MemoryPointer,\n+        lock: Lock,\n+    },\n+    ValidationFailure(String),\n+    CalledClosureAsFunction,\n+    VtableForArgumentlessMethod,\n+    ModifiedConstantMemory,\n+    AssumptionNotHeld,\n+    InlineAsm,\n+    TypeNotPrimitive(Ty<'tcx>),\n+    ReallocatedWrongMemoryKind(String, String),\n+    DeallocatedWrongMemoryKind(String, String),\n+    ReallocateNonBasePtr,\n+    DeallocateNonBasePtr,\n+    IncorrectAllocationInformation(u64, usize, u64, u64),\n+    Layout(layout::LayoutError<'tcx>),\n+    HeapAllocZeroBytes,\n+    HeapAllocNonPowerOfTwoAlignment(u64),\n+    Unreachable,\n+    Panic,\n+    ReadFromReturnPointer,\n+    PathNotFound(Vec<String>),\n+    UnimplementedTraitSelection,\n+    /// Abort in case type errors are reached\n+    TypeckError,\n+}\n+\n+pub type EvalResult<'tcx, T = ()> = Result<T, EvalError<'tcx>>;\n+\n+impl<'tcx> Error for EvalError<'tcx> {\n+    fn description(&self) -> &str {\n+        use self::EvalErrorKind::*;\n+        match self.kind {\n+            MachineError(ref inner) => inner.description(),\n+            FunctionPointerTyMismatch(..) =>\n+                \"tried to call a function through a function pointer of a different type\",\n+            InvalidMemoryAccess =>\n+                \"tried to access memory through an invalid pointer\",\n+            DanglingPointerDeref =>\n+                \"dangling pointer was dereferenced\",\n+            DoubleFree =>\n+                \"tried to deallocate dangling pointer\",\n+            InvalidFunctionPointer =>\n+                \"tried to use a function pointer after offsetting it\",\n+            InvalidBool =>\n+                \"invalid boolean value read\",\n+            InvalidDiscriminant =>\n+                \"invalid enum discriminant value read\",\n+            PointerOutOfBounds { .. } =>\n+                \"pointer offset outside bounds of allocation\",\n+            InvalidNullPointerUsage =>\n+                \"invalid use of NULL pointer\",\n+            MemoryLockViolation { .. } =>\n+                \"memory access conflicts with lock\",\n+            MemoryAcquireConflict { .. } =>\n+                \"new memory lock conflicts with existing lock\",\n+            ValidationFailure(..) =>\n+                \"type validation failed\",\n+            InvalidMemoryLockRelease { .. } =>\n+                \"invalid attempt to release write lock\",\n+            DeallocatedLockedMemory { .. } =>\n+                \"tried to deallocate memory in conflict with a lock\",\n+            ReadPointerAsBytes =>\n+                \"a raw memory access tried to access part of a pointer value as raw bytes\",\n+            ReadBytesAsPointer =>\n+                \"a memory access tried to interpret some bytes as a pointer\",\n+            InvalidPointerMath =>\n+                \"attempted to do invalid arithmetic on pointers that would leak base addresses, e.g. comparing pointers into different allocations\",\n+            ReadUndefBytes =>\n+                \"attempted to read undefined bytes\",\n+            DeadLocal =>\n+                \"tried to access a dead local variable\",\n+            InvalidBoolOp(_) =>\n+                \"invalid boolean operation\",\n+            Unimplemented(ref msg) => msg,\n+            DerefFunctionPointer =>\n+                \"tried to dereference a function pointer\",\n+            ExecuteMemory =>\n+                \"tried to treat a memory pointer as a function pointer\",\n+            ArrayIndexOutOfBounds(..) =>\n+                \"array index out of bounds\",\n+            Math(..) =>\n+                \"mathematical operation failed\",\n+            Intrinsic(..) =>\n+                \"intrinsic failed\",\n+            OverflowingMath =>\n+                \"attempted to do overflowing math\",\n+            NoMirFor(..) =>\n+                \"mir not found\",\n+            InvalidChar(..) =>\n+                \"tried to interpret an invalid 32-bit value as a char\",\n+            OutOfMemory{..} =>\n+                \"could not allocate more memory\",\n+            ExecutionTimeLimitReached =>\n+                \"reached the configured maximum execution time\",\n+            StackFrameLimitReached =>\n+                \"reached the configured maximum number of stack frames\",\n+            OutOfTls =>\n+                \"reached the maximum number of representable TLS keys\",\n+            TlsOutOfBounds =>\n+                \"accessed an invalid (unallocated) TLS key\",\n+            AbiViolation(ref msg) => msg,\n+            AlignmentCheckFailed{..} =>\n+                \"tried to execute a misaligned read or write\",\n+            CalledClosureAsFunction =>\n+                \"tried to call a closure through a function pointer\",\n+            VtableForArgumentlessMethod =>\n+                \"tried to call a vtable function without arguments\",\n+            ModifiedConstantMemory =>\n+                \"tried to modify constant memory\",\n+            AssumptionNotHeld =>\n+                \"`assume` argument was false\",\n+            InlineAsm =>\n+                \"miri does not support inline assembly\",\n+            TypeNotPrimitive(_) =>\n+                \"expected primitive type, got nonprimitive\",\n+            ReallocatedWrongMemoryKind(_, _) =>\n+                \"tried to reallocate memory from one kind to another\",\n+            DeallocatedWrongMemoryKind(_, _) =>\n+                \"tried to deallocate memory of the wrong kind\",\n+            ReallocateNonBasePtr =>\n+                \"tried to reallocate with a pointer not to the beginning of an existing object\",\n+            DeallocateNonBasePtr =>\n+                \"tried to deallocate with a pointer not to the beginning of an existing object\",\n+            IncorrectAllocationInformation(..) =>\n+                \"tried to deallocate or reallocate using incorrect alignment or size\",\n+            Layout(_) =>\n+                \"rustc layout computation failed\",\n+            UnterminatedCString(_) =>\n+                \"attempted to get length of a null terminated string, but no null found before end of allocation\",\n+            HeapAllocZeroBytes =>\n+                \"tried to re-, de- or allocate zero bytes on the heap\",\n+            HeapAllocNonPowerOfTwoAlignment(_) =>\n+                \"tried to re-, de-, or allocate heap memory with alignment that is not a power of two\",\n+            Unreachable =>\n+                \"entered unreachable code\",\n+            Panic =>\n+                \"the evaluated program panicked\",\n+            ReadFromReturnPointer =>\n+                \"tried to read from the return pointer\",\n+            EvalErrorKind::PathNotFound(_) =>\n+                \"a path could not be resolved, maybe the crate is not loaded\",\n+            UnimplementedTraitSelection =>\n+                \"there were unresolved type arguments during trait selection\",\n+            TypeckError =>\n+                \"encountered constants with type errors, stopping evaluation\",\n+        }\n+    }\n+\n+    fn cause(&self) -> Option<&Error> {\n+        use self::EvalErrorKind::*;\n+        match self.kind {\n+            MachineError(ref inner) => Some(&**inner),\n+            _ => None,\n+        }\n+    }\n+}\n+\n+impl<'tcx> fmt::Display for EvalError<'tcx> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        use self::EvalErrorKind::*;\n+        match self.kind {\n+            PointerOutOfBounds { ptr, access, allocation_size } => {\n+                write!(f, \"{} at offset {}, outside bounds of allocation {} which has size {}\",\n+                       if access { \"memory access\" } else { \"pointer computed\" },\n+                       ptr.offset, ptr.alloc_id, allocation_size)\n+            },\n+            MemoryLockViolation { ptr, len, frame, access, ref lock } => {\n+                write!(f, \"{:?} access by frame {} at {:?}, size {}, is in conflict with lock {:?}\",\n+                       access, frame, ptr, len, lock)\n+            }\n+            MemoryAcquireConflict { ptr, len, kind, ref lock } => {\n+                write!(f, \"new {:?} lock at {:?}, size {}, is in conflict with lock {:?}\",\n+                       kind, ptr, len, lock)\n+            }\n+            InvalidMemoryLockRelease { ptr, len, frame, ref lock } => {\n+                write!(f, \"frame {} tried to release memory write lock at {:?}, size {}, but cannot release lock {:?}\",\n+                       frame, ptr, len, lock)\n+            }\n+            DeallocatedLockedMemory { ptr, ref lock } => {\n+                write!(f, \"tried to deallocate memory at {:?} in conflict with lock {:?}\",\n+                       ptr, lock)\n+            }\n+            ValidationFailure(ref err) => {\n+                write!(f, \"type validation failed: {}\", err)\n+            }\n+            NoMirFor(ref func) => write!(f, \"no mir for `{}`\", func),\n+            FunctionPointerTyMismatch(sig, got) =>\n+                write!(f, \"tried to call a function with sig {} through a function pointer of type {}\", sig, got),\n+            ArrayIndexOutOfBounds(span, len, index) =>\n+                write!(f, \"index out of bounds: the len is {} but the index is {} at {:?}\", len, index, span),\n+            ReallocatedWrongMemoryKind(ref old, ref new) =>\n+                write!(f, \"tried to reallocate memory from {} to {}\", old, new),\n+            DeallocatedWrongMemoryKind(ref old, ref new) =>\n+                write!(f, \"tried to deallocate {} memory but gave {} as the kind\", old, new),\n+            Math(span, ref err) =>\n+                write!(f, \"{:?} at {:?}\", err, span),\n+            Intrinsic(ref err) =>\n+                write!(f, \"{}\", err),\n+            InvalidChar(c) =>\n+                write!(f, \"tried to interpret an invalid 32-bit value as a char: {}\", c),\n+            OutOfMemory { allocation_size, memory_size, memory_usage } =>\n+                write!(f, \"tried to allocate {} more bytes, but only {} bytes are free of the {} byte memory\",\n+                       allocation_size, memory_size - memory_usage, memory_size),\n+            AlignmentCheckFailed { required, has } =>\n+               write!(f, \"tried to access memory with alignment {}, but alignment {} is required\",\n+                      has, required),\n+            TypeNotPrimitive(ty) =>\n+                write!(f, \"expected primitive type, got {}\", ty),\n+            Layout(ref err) =>\n+                write!(f, \"rustc layout computation failed: {:?}\", err),\n+            PathNotFound(ref path) =>\n+                write!(f, \"Cannot find path {:?}\", path),\n+            MachineError(ref inner) =>\n+                write!(f, \"machine error: {}\", inner),\n+            IncorrectAllocationInformation(size, size2, align, align2) =>\n+                write!(f, \"incorrect alloc info: expected size {} and align {}, got size {} and align {}\", size, align, size2, align2),\n+            _ => write!(f, \"{}\", self.description()),\n+        }\n+    }\n+}"}, {"sha": "c5d2ec1668c8238774dc0046098f7e2e978a4958", "filename": "src/librustc/mir/interpret/mod.rs", "status": "added", "additions": 270, "deletions": 0, "changes": 270, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fmod.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,270 @@\n+//! An interpreter for MIR used in CTFE and by miri\n+\n+#[macro_export]\n+macro_rules! err {\n+    ($($tt:tt)*) => { Err($crate::mir::interpret::EvalErrorKind::$($tt)*.into()) };\n+}\n+\n+mod error;\n+mod value;\n+\n+pub use self::error::{EvalError, EvalResult, EvalErrorKind};\n+\n+pub use self::value::{PrimVal, PrimValKind, Value, Pointer, PtrAndAlign, bytes_to_f32, bytes_to_f64};\n+\n+use std::collections::BTreeMap;\n+use ty::layout::HasDataLayout;\n+use std::fmt;\n+use ty::layout;\n+use mir;\n+use ty;\n+use middle::region;\n+use std::iter;\n+\n+#[derive(Clone, Debug, PartialEq)]\n+pub enum Lock {\n+    NoLock,\n+    WriteLock(DynamicLifetime),\n+    /// This should never be empty -- that would be a read lock held and nobody there to release it...\n+    ReadLock(Vec<DynamicLifetime>),\n+}\n+\n+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]\n+pub struct DynamicLifetime {\n+    pub frame: usize,\n+    pub region: Option<region::Scope>, // \"None\" indicates \"until the function ends\"\n+}\n+\n+#[derive(Copy, Clone, Debug, PartialEq, Eq)]\n+pub enum AccessKind {\n+    Read,\n+    Write,\n+}\n+\n+/// Uniquely identifies a specific constant or static.\n+#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)]\n+pub struct GlobalId<'tcx> {\n+    /// For a constant or static, the `Instance` of the item itself.\n+    /// For a promoted global, the `Instance` of the function they belong to.\n+    pub instance: ty::Instance<'tcx>,\n+\n+    /// The index for promoted globals within their function's `Mir`.\n+    pub promoted: Option<mir::Promoted>,\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Pointer arithmetic\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub trait PointerArithmetic: layout::HasDataLayout {\n+    // These are not supposed to be overriden.\n+\n+    //// Trunace the given value to the pointer size; also return whether there was an overflow\n+    fn truncate_to_ptr(self, val: u128) -> (u64, bool) {\n+        let max_ptr_plus_1 = 1u128 << self.data_layout().pointer_size.bits();\n+        ((val % max_ptr_plus_1) as u64, val >= max_ptr_plus_1)\n+    }\n+\n+    // Overflow checking only works properly on the range from -u64 to +u64.\n+    fn overflowing_signed_offset(self, val: u64, i: i128) -> (u64, bool) {\n+        // FIXME: is it possible to over/underflow here?\n+        if i < 0 {\n+            // trickery to ensure that i64::min_value() works fine\n+            // this formula only works for true negative values, it panics for zero!\n+            let n = u64::max_value() - (i as u64) + 1;\n+            val.overflowing_sub(n)\n+        } else {\n+            self.overflowing_offset(val, i as u64)\n+        }\n+    }\n+\n+    fn overflowing_offset(self, val: u64, i: u64) -> (u64, bool) {\n+        let (res, over1) = val.overflowing_add(i);\n+        let (res, over2) = self.truncate_to_ptr(res as u128);\n+        (res, over1 || over2)\n+    }\n+\n+    fn signed_offset<'tcx>(self, val: u64, i: i64) -> EvalResult<'tcx, u64> {\n+        let (res, over) = self.overflowing_signed_offset(val, i as i128);\n+        if over { err!(OverflowingMath) } else { Ok(res) }\n+    }\n+\n+    fn offset<'tcx>(self, val: u64, i: u64) -> EvalResult<'tcx, u64> {\n+        let (res, over) = self.overflowing_offset(val, i);\n+        if over { err!(OverflowingMath) } else { Ok(res) }\n+    }\n+\n+    fn wrapping_signed_offset(self, val: u64, i: i64) -> u64 {\n+        self.overflowing_signed_offset(val, i as i128).0\n+    }\n+}\n+\n+impl<T: layout::HasDataLayout> PointerArithmetic for T {}\n+\n+\n+#[derive(Copy, Clone, Debug, Eq, PartialEq)]\n+pub struct MemoryPointer {\n+    pub alloc_id: AllocId,\n+    pub offset: u64,\n+}\n+\n+impl<'tcx> MemoryPointer {\n+    pub fn new(alloc_id: AllocId, offset: u64) -> Self {\n+        MemoryPointer { alloc_id, offset }\n+    }\n+\n+    pub(crate) fn wrapping_signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> Self {\n+        MemoryPointer::new(\n+            self.alloc_id,\n+            cx.data_layout().wrapping_signed_offset(self.offset, i),\n+        )\n+    }\n+\n+    pub fn overflowing_signed_offset<C: HasDataLayout>(self, i: i128, cx: C) -> (Self, bool) {\n+        let (res, over) = cx.data_layout().overflowing_signed_offset(self.offset, i);\n+        (MemoryPointer::new(self.alloc_id, res), over)\n+    }\n+\n+    pub(crate) fn signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> EvalResult<'tcx, Self> {\n+        Ok(MemoryPointer::new(\n+            self.alloc_id,\n+            cx.data_layout().signed_offset(self.offset, i)?,\n+        ))\n+    }\n+\n+    pub fn overflowing_offset<C: HasDataLayout>(self, i: u64, cx: C) -> (Self, bool) {\n+        let (res, over) = cx.data_layout().overflowing_offset(self.offset, i);\n+        (MemoryPointer::new(self.alloc_id, res), over)\n+    }\n+\n+    pub fn offset<C: HasDataLayout>(self, i: u64, cx: C) -> EvalResult<'tcx, Self> {\n+        Ok(MemoryPointer::new(\n+            self.alloc_id,\n+            cx.data_layout().offset(self.offset, i)?,\n+        ))\n+    }\n+}\n+\n+\n+#[derive(Copy, Clone, Eq, Hash, Ord, PartialEq, PartialOrd, Debug)]\n+pub struct AllocId(pub u64);\n+\n+impl fmt::Display for AllocId {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        write!(f, \"{}\", self.0)\n+    }\n+}\n+\n+#[derive(Debug, Eq, PartialEq, Hash)]\n+pub struct Allocation {\n+    /// The actual bytes of the allocation.\n+    /// Note that the bytes of a pointer represent the offset of the pointer\n+    pub bytes: Vec<u8>,\n+    /// Maps from byte addresses to allocations.\n+    /// Only the first byte of a pointer is inserted into the map.\n+    pub relocations: BTreeMap<u64, AllocId>,\n+    /// Denotes undefined memory. Reading from undefined memory is forbidden in miri\n+    pub undef_mask: UndefMask,\n+    /// The alignment of the allocation to detect unaligned reads.\n+    pub align: u64,\n+}\n+\n+impl Allocation {\n+    pub fn from_bytes(slice: &[u8]) -> Self {\n+        let mut undef_mask = UndefMask::new(0);\n+        undef_mask.grow(slice.len() as u64, true);\n+        Self {\n+            bytes: slice.to_owned(),\n+            relocations: BTreeMap::new(),\n+            undef_mask,\n+            align: 1,\n+        }\n+    }\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Undefined byte tracking\n+////////////////////////////////////////////////////////////////////////////////\n+\n+type Block = u64;\n+const BLOCK_SIZE: u64 = 64;\n+\n+#[derive(Clone, Debug, Eq, PartialEq, Hash)]\n+pub struct UndefMask {\n+    blocks: Vec<Block>,\n+    len: u64,\n+}\n+\n+impl UndefMask {\n+    pub fn new(size: u64) -> Self {\n+        let mut m = UndefMask {\n+            blocks: vec![],\n+            len: 0,\n+        };\n+        m.grow(size, false);\n+        m\n+    }\n+\n+    /// Check whether the range `start..end` (end-exclusive) is entirely defined.\n+    pub fn is_range_defined(&self, start: u64, end: u64) -> bool {\n+        if end > self.len {\n+            return false;\n+        }\n+        for i in start..end {\n+            if !self.get(i) {\n+                return false;\n+            }\n+        }\n+        true\n+    }\n+\n+    pub fn set_range(&mut self, start: u64, end: u64, new_state: bool) {\n+        let len = self.len;\n+        if end > len {\n+            self.grow(end - len, new_state);\n+        }\n+        self.set_range_inbounds(start, end, new_state);\n+    }\n+\n+    pub fn set_range_inbounds(&mut self, start: u64, end: u64, new_state: bool) {\n+        for i in start..end {\n+            self.set(i, new_state);\n+        }\n+    }\n+\n+    pub fn get(&self, i: u64) -> bool {\n+        let (block, bit) = bit_index(i);\n+        (self.blocks[block] & 1 << bit) != 0\n+    }\n+\n+    pub fn set(&mut self, i: u64, new_state: bool) {\n+        let (block, bit) = bit_index(i);\n+        if new_state {\n+            self.blocks[block] |= 1 << bit;\n+        } else {\n+            self.blocks[block] &= !(1 << bit);\n+        }\n+    }\n+\n+    pub fn grow(&mut self, amount: u64, new_state: bool) {\n+        let unused_trailing_bits = self.blocks.len() as u64 * BLOCK_SIZE - self.len;\n+        if amount > unused_trailing_bits {\n+            let additional_blocks = amount / BLOCK_SIZE + 1;\n+            assert_eq!(additional_blocks as usize as u64, additional_blocks);\n+            self.blocks.extend(\n+                iter::repeat(0).take(additional_blocks as usize),\n+            );\n+        }\n+        let start = self.len;\n+        self.len += amount;\n+        self.set_range_inbounds(start, start + amount, new_state);\n+    }\n+}\n+\n+fn bit_index(bits: u64) -> (usize, usize) {\n+    let a = bits / BLOCK_SIZE;\n+    let b = bits % BLOCK_SIZE;\n+    assert_eq!(a as usize as u64, a);\n+    assert_eq!(b as usize as u64, b);\n+    (a as usize, b as usize)\n+}"}, {"sha": "33b177b60a81b03550c1985e6c33a9664378bb69", "filename": "src/librustc/mir/interpret/value.rs", "status": "added", "additions": 350, "deletions": 0, "changes": 350, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fvalue.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,350 @@\n+#![allow(unknown_lints)]\n+\n+use ty::layout::HasDataLayout;\n+\n+use super::{EvalResult, MemoryPointer, PointerArithmetic};\n+use syntax::ast::FloatTy;\n+use rustc_const_math::ConstFloat;\n+\n+#[derive(Copy, Clone, Debug)]\n+pub struct PtrAndAlign {\n+    pub ptr: Pointer,\n+    /// Remember whether this place is *supposed* to be aligned.\n+    pub aligned: bool,\n+}\n+\n+impl PtrAndAlign {\n+    pub fn to_ptr<'tcx>(self) -> EvalResult<'tcx, MemoryPointer> {\n+        self.ptr.to_ptr()\n+    }\n+    pub fn offset<'tcx, C: HasDataLayout>(self, i: u64, cx: C) -> EvalResult<'tcx, Self> {\n+        Ok(PtrAndAlign {\n+            ptr: self.ptr.offset(i, cx)?,\n+            aligned: self.aligned,\n+        })\n+    }\n+}\n+\n+pub fn bytes_to_f32(bits: u128) -> ConstFloat {\n+    ConstFloat {\n+        bits,\n+        ty: FloatTy::F32,\n+    }\n+}\n+\n+pub fn bytes_to_f64(bits: u128) -> ConstFloat {\n+    ConstFloat {\n+        bits,\n+        ty: FloatTy::F64,\n+    }\n+}\n+\n+/// A `Value` represents a single self-contained Rust value.\n+///\n+/// A `Value` can either refer to a block of memory inside an allocation (`ByRef`) or to a primitve\n+/// value held directly, outside of any allocation (`ByVal`).  For `ByRef`-values, we remember\n+/// whether the pointer is supposed to be aligned or not (also see Place).\n+///\n+/// For optimization of a few very common cases, there is also a representation for a pair of\n+/// primitive values (`ByValPair`). It allows Miri to avoid making allocations for checked binary\n+/// operations and fat pointers. This idea was taken from rustc's trans.\n+#[derive(Clone, Copy, Debug)]\n+pub enum Value {\n+    ByRef(PtrAndAlign),\n+    ByVal(PrimVal),\n+    ByValPair(PrimVal, PrimVal),\n+}\n+\n+/// A wrapper type around `PrimVal` that cannot be turned back into a `PrimVal` accidentally.\n+/// This type clears up a few APIs where having a `PrimVal` argument for something that is\n+/// potentially an integer pointer or a pointer to an allocation was unclear.\n+///\n+/// I (@oli-obk) believe it is less easy to mix up generic primvals and primvals that are just\n+/// the representation of pointers. Also all the sites that convert between primvals and pointers\n+/// are explicit now (and rare!)\n+#[derive(Clone, Copy, Debug)]\n+pub struct Pointer {\n+    primval: PrimVal,\n+}\n+\n+impl<'tcx> Pointer {\n+    pub fn null() -> Self {\n+        PrimVal::Bytes(0).into()\n+    }\n+    pub fn to_ptr(self) -> EvalResult<'tcx, MemoryPointer> {\n+        self.primval.to_ptr()\n+    }\n+    pub fn into_inner_primval(self) -> PrimVal {\n+        self.primval\n+    }\n+\n+    pub fn signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> EvalResult<'tcx, Self> {\n+        let layout = cx.data_layout();\n+        match self.primval {\n+            PrimVal::Bytes(b) => {\n+                assert_eq!(b as u64 as u128, b);\n+                Ok(Pointer::from(\n+                    PrimVal::Bytes(layout.signed_offset(b as u64, i)? as u128),\n+                ))\n+            }\n+            PrimVal::Ptr(ptr) => ptr.signed_offset(i, layout).map(Pointer::from),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn offset<C: HasDataLayout>(self, i: u64, cx: C) -> EvalResult<'tcx, Self> {\n+        let layout = cx.data_layout();\n+        match self.primval {\n+            PrimVal::Bytes(b) => {\n+                assert_eq!(b as u64 as u128, b);\n+                Ok(Pointer::from(\n+                    PrimVal::Bytes(layout.offset(b as u64, i)? as u128),\n+                ))\n+            }\n+            PrimVal::Ptr(ptr) => ptr.offset(i, layout).map(Pointer::from),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn wrapping_signed_offset<C: HasDataLayout>(self, i: i64, cx: C) -> EvalResult<'tcx, Self> {\n+        let layout = cx.data_layout();\n+        match self.primval {\n+            PrimVal::Bytes(b) => {\n+                assert_eq!(b as u64 as u128, b);\n+                Ok(Pointer::from(PrimVal::Bytes(\n+                    layout.wrapping_signed_offset(b as u64, i) as u128,\n+                )))\n+            }\n+            PrimVal::Ptr(ptr) => Ok(Pointer::from(ptr.wrapping_signed_offset(i, layout))),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn is_null(self) -> EvalResult<'tcx, bool> {\n+        match self.primval {\n+            PrimVal::Bytes(b) => Ok(b == 0),\n+            PrimVal::Ptr(_) => Ok(false),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn to_value_with_len(self, len: u64) -> Value {\n+        Value::ByValPair(self.primval, PrimVal::from_u128(len as u128))\n+    }\n+\n+    pub fn to_value_with_vtable(self, vtable: MemoryPointer) -> Value {\n+        Value::ByValPair(self.primval, PrimVal::Ptr(vtable))\n+    }\n+\n+    pub fn to_value(self) -> Value {\n+        Value::ByVal(self.primval)\n+    }\n+}\n+\n+impl ::std::convert::From<PrimVal> for Pointer {\n+    fn from(primval: PrimVal) -> Self {\n+        Pointer { primval }\n+    }\n+}\n+\n+impl ::std::convert::From<MemoryPointer> for Pointer {\n+    fn from(ptr: MemoryPointer) -> Self {\n+        PrimVal::Ptr(ptr).into()\n+    }\n+}\n+\n+/// A `PrimVal` represents an immediate, primitive value existing outside of a\n+/// `memory::Allocation`. It is in many ways like a small chunk of a `Allocation`, up to 8 bytes in\n+/// size. Like a range of bytes in an `Allocation`, a `PrimVal` can either represent the raw bytes\n+/// of a simple value, a pointer into another `Allocation`, or be undefined.\n+#[derive(Clone, Copy, Debug)]\n+pub enum PrimVal {\n+    /// The raw bytes of a simple value.\n+    Bytes(u128),\n+\n+    /// A pointer into an `Allocation`. An `Allocation` in the `memory` module has a list of\n+    /// relocations, but a `PrimVal` is only large enough to contain one, so we just represent the\n+    /// relocation and its associated offset together as a `MemoryPointer` here.\n+    Ptr(MemoryPointer),\n+\n+    /// An undefined `PrimVal`, for representing values that aren't safe to examine, but are safe\n+    /// to copy around, just like undefined bytes in an `Allocation`.\n+    Undef,\n+}\n+\n+#[derive(Clone, Copy, Debug, PartialEq)]\n+pub enum PrimValKind {\n+    I8, I16, I32, I64, I128,\n+    U8, U16, U32, U64, U128,\n+    F32, F64,\n+    Ptr, FnPtr,\n+    Bool,\n+    Char,\n+}\n+\n+impl<'a, 'tcx: 'a> Value {\n+    #[inline]\n+    pub fn by_ref(ptr: Pointer) -> Self {\n+        Value::ByRef(PtrAndAlign { ptr, aligned: true })\n+    }\n+}\n+\n+impl<'tcx> PrimVal {\n+    pub fn from_u128(n: u128) -> Self {\n+        PrimVal::Bytes(n)\n+    }\n+\n+    pub fn from_i128(n: i128) -> Self {\n+        PrimVal::Bytes(n as u128)\n+    }\n+\n+    pub fn from_float(f: ConstFloat) -> Self {\n+        PrimVal::Bytes(f.bits)\n+    }\n+\n+    pub fn from_bool(b: bool) -> Self {\n+        PrimVal::Bytes(b as u128)\n+    }\n+\n+    pub fn from_char(c: char) -> Self {\n+        PrimVal::Bytes(c as u128)\n+    }\n+\n+    pub fn to_bytes(self) -> EvalResult<'tcx, u128> {\n+        match self {\n+            PrimVal::Bytes(b) => Ok(b),\n+            PrimVal::Ptr(_) => err!(ReadPointerAsBytes),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn to_ptr(self) -> EvalResult<'tcx, MemoryPointer> {\n+        match self {\n+            PrimVal::Bytes(_) => err!(ReadBytesAsPointer),\n+            PrimVal::Ptr(p) => Ok(p),\n+            PrimVal::Undef => err!(ReadUndefBytes),\n+        }\n+    }\n+\n+    pub fn is_bytes(self) -> bool {\n+        match self {\n+            PrimVal::Bytes(_) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn is_ptr(self) -> bool {\n+        match self {\n+            PrimVal::Ptr(_) => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn is_undef(self) -> bool {\n+        match self {\n+            PrimVal::Undef => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn to_u128(self) -> EvalResult<'tcx, u128> {\n+        self.to_bytes()\n+    }\n+\n+    pub fn to_u64(self) -> EvalResult<'tcx, u64> {\n+        self.to_bytes().map(|b| {\n+            assert_eq!(b as u64 as u128, b);\n+            b as u64\n+        })\n+    }\n+\n+    pub fn to_i32(self) -> EvalResult<'tcx, i32> {\n+        self.to_bytes().map(|b| {\n+            assert_eq!(b as i32 as u128, b);\n+            b as i32\n+        })\n+    }\n+\n+    pub fn to_i128(self) -> EvalResult<'tcx, i128> {\n+        self.to_bytes().map(|b| b as i128)\n+    }\n+\n+    pub fn to_i64(self) -> EvalResult<'tcx, i64> {\n+        self.to_bytes().map(|b| {\n+            assert_eq!(b as i64 as u128, b);\n+            b as i64\n+        })\n+    }\n+\n+    pub fn to_f32(self) -> EvalResult<'tcx, ConstFloat> {\n+        self.to_bytes().map(bytes_to_f32)\n+    }\n+\n+    pub fn to_f64(self) -> EvalResult<'tcx, ConstFloat> {\n+        self.to_bytes().map(bytes_to_f64)\n+    }\n+\n+    pub fn to_bool(self) -> EvalResult<'tcx, bool> {\n+        match self.to_bytes()? {\n+            0 => Ok(false),\n+            1 => Ok(true),\n+            _ => err!(InvalidBool),\n+        }\n+    }\n+}\n+\n+impl PrimValKind {\n+    pub fn is_int(self) -> bool {\n+        use self::PrimValKind::*;\n+        match self {\n+            I8 | I16 | I32 | I64 | I128 | U8 | U16 | U32 | U64 | U128 => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn is_signed_int(self) -> bool {\n+        use self::PrimValKind::*;\n+        match self {\n+            I8 | I16 | I32 | I64 | I128 => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn is_float(self) -> bool {\n+        use self::PrimValKind::*;\n+        match self {\n+            F32 | F64 => true,\n+            _ => false,\n+        }\n+    }\n+\n+    pub fn from_uint_size(size: u64) -> Self {\n+        match size {\n+            1 => PrimValKind::U8,\n+            2 => PrimValKind::U16,\n+            4 => PrimValKind::U32,\n+            8 => PrimValKind::U64,\n+            16 => PrimValKind::U128,\n+            _ => bug!(\"can't make uint with size {}\", size),\n+        }\n+    }\n+\n+    pub fn from_int_size(size: u64) -> Self {\n+        match size {\n+            1 => PrimValKind::I8,\n+            2 => PrimValKind::I16,\n+            4 => PrimValKind::I32,\n+            8 => PrimValKind::I64,\n+            16 => PrimValKind::I128,\n+            _ => bug!(\"can't make int with size {}\", size),\n+        }\n+    }\n+\n+    pub fn is_ptr(self) -> bool {\n+        use self::PrimValKind::*;\n+        match self {\n+            Ptr | FnPtr => true,\n+            _ => false,\n+        }\n+    }\n+}"}, {"sha": "c61e776c6157c9e5ebf4f1c44962429851172337", "filename": "src/librustc/mir/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fmir%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Fmod.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -43,6 +43,7 @@ mod cache;\n pub mod tcx;\n pub mod visit;\n pub mod traversal;\n+pub mod interpret;\n \n /// Types for locals\n type LocalDecls<'tcx> = IndexVec<Local, LocalDecl<'tcx>>;"}, {"sha": "1319b08ca3863fc50ca7d431361b5eca18e94ee5", "filename": "src/librustc/session/config.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fsession%2Fconfig.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fsession%2Fconfig.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fsession%2Fconfig.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -1158,6 +1158,8 @@ options! {DebuggingOptions, DebuggingSetter, basic_debugging_options,\n           \"print some statistics about MIR\"),\n     always_encode_mir: bool = (false, parse_bool, [TRACKED],\n           \"encode MIR of all functions into the crate metadata\"),\n+    miri: bool = (false, parse_bool, [TRACKED],\n+          \"check the miri const evaluator against the old ctfe\"),\n     osx_rpath_install_name: bool = (false, parse_bool, [TRACKED],\n           \"pass `-install_name @rpath/...` to the macOS linker\"),\n     sanitizer: Option<Sanitizer> = (None, parse_sanitizer, [TRACKED],"}, {"sha": "9ebdd592922fc57dc14731246714b7c437a77934", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 142, "deletions": 1, "changes": 143, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -30,9 +30,10 @@ use middle::cstore::EncodedMetadata;\n use middle::lang_items;\n use middle::resolve_lifetime::{self, ObjectLifetimeDefault};\n use middle::stability;\n-use mir::Mir;\n+use mir::{Mir, interpret};\n use ty::subst::{Kind, Substs};\n use ty::ReprOptions;\n+use ty::Instance;\n use traits;\n use ty::{self, Ty, TypeAndMut};\n use ty::{TyS, TypeVariants, Slice};\n@@ -87,6 +88,8 @@ pub struct GlobalArenas<'tcx> {\n     steal_mir: TypedArena<Steal<Mir<'tcx>>>,\n     mir: TypedArena<Mir<'tcx>>,\n     tables: TypedArena<ty::TypeckTables<'tcx>>,\n+    /// miri allocations\n+    const_allocs: TypedArena<interpret::Allocation>,\n }\n \n impl<'tcx> GlobalArenas<'tcx> {\n@@ -99,6 +102,7 @@ impl<'tcx> GlobalArenas<'tcx> {\n             steal_mir: TypedArena::new(),\n             mir: TypedArena::new(),\n             tables: TypedArena::new(),\n+            const_allocs: TypedArena::new(),\n         }\n     }\n }\n@@ -847,6 +851,8 @@ pub struct GlobalCtxt<'tcx> {\n \n     stability_interner: RefCell<FxHashSet<&'tcx attr::Stability>>,\n \n+    pub interpret_interner: RefCell<InterpretInterner<'tcx>>,\n+\n     layout_interner: RefCell<FxHashSet<&'tcx LayoutDetails>>,\n \n     /// A vector of every trait accessible in the whole crate\n@@ -866,6 +872,104 @@ pub struct GlobalCtxt<'tcx> {\n     output_filenames: Arc<OutputFilenames>,\n }\n \n+/// Everything needed to efficiently work with interned allocations\n+#[derive(Debug, Default)]\n+pub struct InterpretInterner<'tcx> {\n+    /// Stores the value of constants (and deduplicates the actual memory)\n+    allocs: FxHashSet<&'tcx interpret::Allocation>,\n+\n+    /// Allows obtaining function instance handles via a unique identifier\n+    functions: FxHashMap<u64, Instance<'tcx>>,\n+\n+    /// Inverse map of `interpret_functions`.\n+    /// Used so we don't allocate a new pointer every time we need one\n+    function_cache: FxHashMap<Instance<'tcx>, u64>,\n+\n+    /// Allows obtaining const allocs via a unique identifier\n+    alloc_by_id: FxHashMap<u64, &'tcx interpret::Allocation>,\n+\n+    /// The AllocId to assign to the next new regular allocation.\n+    /// Always incremented, never gets smaller.\n+    next_id: u64,\n+\n+    /// Allows checking whether a constant already has an allocation\n+    ///\n+    /// The pointers are to the beginning of an `alloc_by_id` allocation\n+    alloc_cache: FxHashMap<interpret::GlobalId<'tcx>, interpret::PtrAndAlign>,\n+\n+    /// A cache for basic byte allocations keyed by their contents. This is used to deduplicate\n+    /// allocations for string and bytestring literals.\n+    literal_alloc_cache: FxHashMap<Vec<u8>, u64>,\n+}\n+\n+impl<'tcx> InterpretInterner<'tcx> {\n+    pub fn create_fn_alloc(&mut self, instance: Instance<'tcx>) -> u64 {\n+        if let Some(&alloc_id) = self.function_cache.get(&instance) {\n+            return alloc_id;\n+        }\n+        let id = self.reserve();\n+        debug!(\"creating fn ptr: {}\", id);\n+        self.functions.insert(id, instance);\n+        self.function_cache.insert(instance, id);\n+        id\n+    }\n+\n+    pub fn get_fn(\n+        &self,\n+        id: u64,\n+    ) -> Option<Instance<'tcx>> {\n+        self.functions.get(&id).cloned()\n+    }\n+\n+    pub fn get_alloc(\n+        &self,\n+        id: u64,\n+    ) -> Option<&'tcx interpret::Allocation> {\n+        self.alloc_by_id.get(&id).cloned()\n+    }\n+\n+    pub fn get_cached(\n+        &self,\n+        global_id: interpret::GlobalId<'tcx>,\n+    ) -> Option<interpret::PtrAndAlign> {\n+        self.alloc_cache.get(&global_id).cloned()\n+    }\n+\n+    pub fn cache(\n+        &mut self,\n+        global_id: interpret::GlobalId<'tcx>,\n+        ptr: interpret::PtrAndAlign,\n+    ) {\n+        if let Some(old) = self.alloc_cache.insert(global_id, ptr) {\n+            bug!(\"tried to cache {:?}, but was already existing as {:#?}\", global_id, old);\n+        }\n+    }\n+\n+    pub fn intern_at_reserved(\n+        &mut self,\n+        id: u64,\n+        alloc: &'tcx interpret::Allocation,\n+    ) {\n+        if let Some(old) = self.alloc_by_id.insert(id, alloc) {\n+            bug!(\"tried to intern allocation at {}, but was already existing as {:#?}\", id, old);\n+        }\n+    }\n+\n+    /// obtains a new allocation ID that can be referenced but does not\n+    /// yet have an allocation backing it.\n+    pub fn reserve(\n+        &mut self,\n+    ) -> u64 {\n+        let next = self.next_id;\n+        self.next_id = self.next_id\n+            .checked_add(1)\n+            .expect(\"You overflowed a u64 by incrementing by 1... \\\n+                     You've just earned yourself a free drink if we ever meet. \\\n+                     Seriously, how did you do that?!\");\n+        next\n+    }\n+}\n+\n impl<'tcx> GlobalCtxt<'tcx> {\n     /// Get the global TyCtxt.\n     pub fn global_tcx<'a>(&'a self) -> TyCtxt<'a, 'tcx, 'tcx> {\n@@ -933,6 +1037,41 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n         }\n     }\n \n+    pub fn intern_const_alloc(\n+        self,\n+        alloc: interpret::Allocation,\n+    ) -> &'gcx interpret::Allocation {\n+        if let Some(alloc) = self.interpret_interner.borrow().allocs.get(&alloc) {\n+            return alloc;\n+        }\n+\n+        let interned = self.global_arenas.const_allocs.alloc(alloc);\n+        if let Some(prev) = self.interpret_interner.borrow_mut().allocs.replace(interned) {\n+            bug!(\"Tried to overwrite interned Allocation: {:#?}\", prev)\n+        }\n+        interned\n+    }\n+\n+    /// Allocates a byte or string literal for `mir::interpret`\n+    pub fn allocate_cached(self, bytes: &[u8]) -> u64 {\n+        // check whether we already allocated this literal or a constant with the same memory\n+        if let Some(&alloc_id) = self.interpret_interner.borrow().literal_alloc_cache.get(bytes) {\n+            return alloc_id;\n+        }\n+        // create an allocation that just contains these bytes\n+        let alloc = interpret::Allocation::from_bytes(bytes);\n+        let alloc = self.intern_const_alloc(alloc);\n+\n+        let mut int = self.interpret_interner.borrow_mut();\n+        // the next unique id\n+        let id = int.reserve();\n+        // make the allocation identifiable\n+        int.alloc_by_id.insert(id, alloc);\n+        // cache it for the future\n+        int.literal_alloc_cache.insert(bytes.to_owned(), id);\n+        id\n+    }\n+\n     pub fn intern_stability(self, stab: attr::Stability) -> &'gcx attr::Stability {\n         if let Some(st) = self.stability_interner.borrow().get(&stab) {\n             return st;\n@@ -1079,6 +1218,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n             layout_depth: Cell::new(0),\n             derive_macros: RefCell::new(NodeMap()),\n             stability_interner: RefCell::new(FxHashSet()),\n+            interpret_interner: Default::default(),\n             all_traits: RefCell::new(None),\n             tx_to_llvm_workers: tx,\n             output_filenames: Arc::new(output_filenames.clone()),\n@@ -1525,6 +1665,7 @@ impl<'a, 'tcx> TyCtxt<'a, 'tcx, 'tcx> {\n         println!(\"Substs interner: #{}\", self.interners.substs.borrow().len());\n         println!(\"Region interner: #{}\", self.interners.region.borrow().len());\n         println!(\"Stability interner: #{}\", self.stability_interner.borrow().len());\n+        println!(\"Interpret interner: #{}\", self.interpret_interner.borrow().allocs.len());\n         println!(\"Layout interner: #{}\", self.layout_interner.borrow().len());\n     }\n }"}, {"sha": "61b19227744c10f97cf242e1a512ef0956068912", "filename": "src/librustc/ty/instance.rs", "status": "modified", "additions": 15, "deletions": 15, "changes": 30, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fty%2Finstance.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc%2Fty%2Finstance.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Finstance.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -180,20 +180,20 @@ impl<'a, 'b, 'tcx> Instance<'tcx> {\n         debug!(\"resolve(def_id={:?}, substs={:?}) = {:?}\", def_id, substs, result);\n         result\n     }\n-}\n \n-fn resolve_closure<'a, 'tcx>(\n-                   tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                   def_id: DefId,\n-                   substs: ty::ClosureSubsts<'tcx>,\n-                   requested_kind: ty::ClosureKind)\n--> Instance<'tcx>\n-{\n-    let actual_kind = substs.closure_kind(def_id, tcx);\n+    pub fn resolve_closure(\n+                    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                    def_id: DefId,\n+                    substs: ty::ClosureSubsts<'tcx>,\n+                    requested_kind: ty::ClosureKind)\n+    -> Instance<'tcx>\n+    {\n+        let actual_kind = substs.closure_kind(def_id, tcx);\n \n-    match needs_fn_once_adapter_shim(actual_kind, requested_kind) {\n-        Ok(true) => fn_once_adapter_instance(tcx, def_id, substs),\n-        _ => Instance::new(def_id, substs.substs)\n+        match needs_fn_once_adapter_shim(actual_kind, requested_kind) {\n+            Ok(true) => fn_once_adapter_instance(tcx, def_id, substs),\n+            _ => Instance::new(def_id, substs.substs)\n+        }\n     }\n }\n \n@@ -202,8 +202,8 @@ fn resolve_associated_item<'a, 'tcx>(\n     trait_item: &ty::AssociatedItem,\n     param_env: ty::ParamEnv<'tcx>,\n     trait_id: DefId,\n-    rcvr_substs: &'tcx Substs<'tcx>\n-    ) -> Option<Instance<'tcx>> {\n+    rcvr_substs: &'tcx Substs<'tcx>,\n+) -> Option<Instance<'tcx>> {\n     let def_id = trait_item.def_id;\n     debug!(\"resolve_associated_item(trait_item={:?}, \\\n                                     trait_id={:?}, \\\n@@ -230,7 +230,7 @@ fn resolve_associated_item<'a, 'tcx>(\n         }\n         traits::VtableClosure(closure_data) => {\n             let trait_closure_kind = tcx.lang_items().fn_trait_kind(trait_id).unwrap();\n-            Some(resolve_closure(tcx, closure_data.closure_def_id, closure_data.substs,\n+            Some(Instance::resolve_closure(tcx, closure_data.closure_def_id, closure_data.substs,\n                                  trait_closure_kind))\n         }\n         traits::VtableFnPointer(ref data) => {"}, {"sha": "81cd63b5407c3b67de09c43e47442e4d21ae53d1", "filename": "src/librustc_const_eval/eval.rs", "status": "modified", "additions": 0, "deletions": 32, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_const_eval%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_const_eval%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_const_eval%2Feval.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -682,35 +682,3 @@ impl<'a, 'tcx> ConstContext<'a, 'tcx> {\n         compare_const_vals(tcx, span, &a.val, &b.val)\n     }\n }\n-\n-pub(crate) fn const_eval<'a, 'tcx>(tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                        key: ty::ParamEnvAnd<'tcx, (DefId, &'tcx Substs<'tcx>)>)\n-                        -> EvalResult<'tcx> {\n-    let (def_id, substs) = if let Some(resolved) = lookup_const_by_id(tcx, key) {\n-        resolved\n-    } else {\n-        return Err(ConstEvalErr {\n-            span: tcx.def_span(key.value.0),\n-            kind: TypeckError\n-        });\n-    };\n-\n-    let tables = tcx.typeck_tables_of(def_id);\n-    let body = if let Some(id) = tcx.hir.as_local_node_id(def_id) {\n-        let body_id = tcx.hir.body_owned_by(id);\n-\n-        // Do match-check before building MIR\n-        if tcx.check_match(def_id).is_err() {\n-            return Err(ConstEvalErr {\n-                span: tcx.def_span(key.value.0),\n-                kind: CheckMatchError,\n-            });\n-        }\n-\n-        tcx.mir_const_qualif(def_id);\n-        tcx.hir.body(body_id)\n-    } else {\n-        tcx.extern_const_body(def_id).body\n-    };\n-    ConstContext::new(tcx, key.param_env.and(substs), tables).eval(&body.value)\n-}"}, {"sha": "9d636b48bd0c5d4ae6d524cf0289e0114c5e470d", "filename": "src/librustc_const_eval/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_const_eval%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_const_eval%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_const_eval%2Flib.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -50,7 +50,6 @@ use rustc::ty::maps::Providers;\n \n pub fn provide(providers: &mut Providers) {\n     *providers = Providers {\n-        const_eval: eval::const_eval,\n         check_match: check_match::check_match,\n         ..*providers\n     };"}, {"sha": "40ea4e1801b2680a817fab520760e0a7be23ccd8", "filename": "src/librustc_mir/Cargo.toml", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2FCargo.toml?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -12,6 +12,7 @@ crate-type = [\"dylib\"]\n bitflags = \"1.0\"\n graphviz = { path = \"../libgraphviz\" }\n log = \"0.3\"\n+log_settings = \"0.1.1\"\n rustc = { path = \"../librustc\" }\n rustc_const_eval = { path = \"../librustc_const_eval\" }\n rustc_const_math = { path = \"../librustc_const_math\" }\n@@ -20,3 +21,5 @@ rustc_errors = { path = \"../librustc_errors\" }\n serialize = { path = \"../libserialize\" }\n syntax = { path = \"../libsyntax\" }\n syntax_pos = { path = \"../libsyntax_pos\" }\n+byteorder = { version = \"1.1\", features = [\"i128\"] }\n+rustc_apfloat = { path = \"../librustc_apfloat\" }"}, {"sha": "6f4a28fb28f013534f7bcf9ba739b707645b2071", "filename": "src/librustc_mir/interpret/cast.rs", "status": "added", "additions": 133, "deletions": 0, "changes": 133, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fcast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fcast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fcast.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,133 @@\n+use rustc::ty::Ty;\n+use syntax::ast::{FloatTy, IntTy, UintTy};\n+\n+use rustc_const_math::ConstFloat;\n+use super::{EvalContext, Machine};\n+use rustc::mir::interpret::{PrimVal, EvalResult, MemoryPointer, PointerArithmetic};\n+use rustc_apfloat::ieee::{Single, Double};\n+use rustc_apfloat::Float;\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    pub(super) fn cast_primval(\n+        &self,\n+        val: PrimVal,\n+        src_ty: Ty<'tcx>,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, PrimVal> {\n+        trace!(\"Casting {:?}: {:?} to {:?}\", val, src_ty, dest_ty);\n+        let src_kind = self.ty_to_primval_kind(src_ty)?;\n+\n+        match val {\n+            PrimVal::Undef => Ok(PrimVal::Undef),\n+            PrimVal::Ptr(ptr) => self.cast_from_ptr(ptr, dest_ty),\n+            val @ PrimVal::Bytes(_) => {\n+                use rustc::mir::interpret::PrimValKind::*;\n+                match src_kind {\n+                    F32 => self.cast_from_float(val.to_f32()?, dest_ty),\n+                    F64 => self.cast_from_float(val.to_f64()?, dest_ty),\n+\n+                    I8 | I16 | I32 | I64 | I128 => {\n+                        self.cast_from_signed_int(val.to_i128()?, dest_ty)\n+                    }\n+\n+                    Bool | Char | U8 | U16 | U32 | U64 | U128 | FnPtr | Ptr => {\n+                        self.cast_from_int(val.to_u128()?, dest_ty, false)\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    fn cast_from_signed_int(&self, val: i128, ty: Ty<'tcx>) -> EvalResult<'tcx, PrimVal> {\n+        self.cast_from_int(val as u128, ty, val < 0)\n+    }\n+\n+    fn int_to_int(&self, v: i128, ty: IntTy) -> u128 {\n+        match ty {\n+            IntTy::I8 => v as i8 as u128,\n+            IntTy::I16 => v as i16 as u128,\n+            IntTy::I32 => v as i32 as u128,\n+            IntTy::I64 => v as i64 as u128,\n+            IntTy::I128 => v as u128,\n+            IntTy::Is => {\n+                let ty = self.tcx.sess.target.isize_ty;\n+                self.int_to_int(v, ty)\n+            }\n+        }\n+    }\n+    fn int_to_uint(&self, v: u128, ty: UintTy) -> u128 {\n+        match ty {\n+            UintTy::U8 => v as u8 as u128,\n+            UintTy::U16 => v as u16 as u128,\n+            UintTy::U32 => v as u32 as u128,\n+            UintTy::U64 => v as u64 as u128,\n+            UintTy::U128 => v,\n+            UintTy::Us => {\n+                let ty = self.tcx.sess.target.usize_ty;\n+                self.int_to_uint(v, ty)\n+            }\n+        }\n+    }\n+\n+    fn cast_from_int(\n+        &self,\n+        v: u128,\n+        ty: Ty<'tcx>,\n+        negative: bool,\n+    ) -> EvalResult<'tcx, PrimVal> {\n+        trace!(\"cast_from_int: {}, {}, {}\", v, ty, negative);\n+        use rustc::ty::TypeVariants::*;\n+        match ty.sty {\n+            // Casts to bool are not permitted by rustc, no need to handle them here.\n+            TyInt(ty) => Ok(PrimVal::Bytes(self.int_to_int(v as i128, ty))),\n+            TyUint(ty) => Ok(PrimVal::Bytes(self.int_to_uint(v, ty))),\n+\n+            TyFloat(fty) if negative => Ok(PrimVal::Bytes(ConstFloat::from_i128(v as i128, fty).bits)),\n+            TyFloat(fty) => Ok(PrimVal::Bytes(ConstFloat::from_u128(v, fty).bits)),\n+\n+            TyChar if v as u8 as u128 == v => Ok(PrimVal::Bytes(v)),\n+            TyChar => err!(InvalidChar(v)),\n+\n+            // No alignment check needed for raw pointers.  But we have to truncate to target ptr size.\n+            TyRawPtr(_) => Ok(PrimVal::Bytes(self.memory.truncate_to_ptr(v).0 as u128)),\n+\n+            _ => err!(Unimplemented(format!(\"int to {:?} cast\", ty))),\n+        }\n+    }\n+\n+    fn cast_from_float(&self, val: ConstFloat, ty: Ty<'tcx>) -> EvalResult<'tcx, PrimVal> {\n+        use rustc::ty::TypeVariants::*;\n+        match ty.sty {\n+            TyUint(t) => {\n+                let width = t.bit_width().unwrap_or(self.memory.pointer_size() as usize * 8);\n+                match val.ty {\n+                    FloatTy::F32 => Ok(PrimVal::Bytes(Single::from_bits(val.bits).to_u128(width).value)),\n+                    FloatTy::F64 => Ok(PrimVal::Bytes(Double::from_bits(val.bits).to_u128(width).value)),\n+                }\n+            },\n+\n+            TyInt(t) => {\n+                let width = t.bit_width().unwrap_or(self.memory.pointer_size() as usize * 8);\n+                match val.ty {\n+                    FloatTy::F32 => Ok(PrimVal::from_i128(Single::from_bits(val.bits).to_i128(width).value)),\n+                    FloatTy::F64 => Ok(PrimVal::from_i128(Double::from_bits(val.bits).to_i128(width).value)),\n+                }\n+            },\n+\n+            TyFloat(fty) => Ok(PrimVal::from_float(val.convert(fty))),\n+            _ => err!(Unimplemented(format!(\"float to {:?} cast\", ty))),\n+        }\n+    }\n+\n+    fn cast_from_ptr(&self, ptr: MemoryPointer, ty: Ty<'tcx>) -> EvalResult<'tcx, PrimVal> {\n+        use rustc::ty::TypeVariants::*;\n+        match ty.sty {\n+            // Casting to a reference or fn pointer is not permitted by rustc, no need to support it here.\n+            TyRawPtr(_) |\n+            TyInt(IntTy::Is) |\n+            TyUint(UintTy::Us) => Ok(PrimVal::Ptr(ptr)),\n+            TyInt(_) | TyUint(_) => err!(ReadPointerAsBytes),\n+            _ => err!(Unimplemented(format!(\"ptr to {:?} cast\", ty))),\n+        }\n+    }\n+}"}, {"sha": "a78cd8477617f4fd57d14ebd696acd488d7c11df", "filename": "src/librustc_mir/interpret/const_eval.rs", "status": "added", "additions": 587, "deletions": 0, "changes": 587, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fconst_eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fconst_eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fconst_eval.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,587 @@\n+use rustc::ty::{self, TyCtxt, Ty, Instance};\n+use rustc::ty::layout::{self, LayoutOf};\n+use rustc::ty::subst::Substs;\n+use rustc::hir::def_id::DefId;\n+use rustc::mir;\n+use rustc::middle::const_val::ErrKind::{CheckMatchError, TypeckError};\n+use rustc::middle::const_val::{ConstEvalErr, ConstVal};\n+use rustc_const_eval::{lookup_const_by_id, ConstContext};\n+use rustc::mir::Field;\n+use rustc_data_structures::indexed_vec::Idx;\n+\n+use syntax::ast::Mutability;\n+use syntax::codemap::Span;\n+\n+use rustc::mir::interpret::{EvalResult, EvalError, EvalErrorKind, GlobalId, Value, PrimVal, PtrAndAlign};\n+use super::{Place, PlaceExtra, EvalContext, StackPopCleanup, ValTy, HasMemory};\n+\n+use rustc_const_math::ConstInt;\n+\n+use std::fmt;\n+use std::error::Error;\n+\n+pub fn eval_body<'a, 'tcx>(\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    instance: Instance<'tcx>,\n+    param_env: ty::ParamEnv<'tcx>,\n+) -> (EvalResult<'tcx, (PtrAndAlign, Ty<'tcx>)>, EvalContext<'a, 'tcx, CompileTimeEvaluator>) {\n+    debug!(\"eval_body: {:?}, {:?}\", instance, param_env);\n+    let limits = super::ResourceLimits::default();\n+    let mut ecx = EvalContext::new(tcx, param_env, limits, CompileTimeEvaluator, ());\n+    let cid = GlobalId {\n+        instance,\n+        promoted: None,\n+    };\n+\n+    let try = (|| {\n+        if ecx.tcx.has_attr(instance.def_id(), \"linkage\") {\n+            return Err(ConstEvalError::NotConst(\"extern global\".to_string()).into());\n+        }\n+        // FIXME(eddyb) use `Instance::ty` when it becomes available.\n+        let instance_ty =\n+            ecx.monomorphize(instance.def.def_ty(tcx), instance.substs);\n+        if tcx.interpret_interner.borrow().get_cached(cid).is_none() {\n+            let mir = ecx.load_mir(instance.def)?;\n+            let layout = ecx.layout_of(instance_ty)?;\n+            assert!(!layout.is_unsized());\n+            let ptr = ecx.memory.allocate(\n+                layout.size.bytes(),\n+                layout.align.abi(),\n+                None,\n+            )?;\n+            tcx.interpret_interner.borrow_mut().cache(\n+                cid,\n+                PtrAndAlign {\n+                    ptr: ptr.into(),\n+                    aligned: !layout.is_packed(),\n+                },\n+            );\n+            let cleanup = StackPopCleanup::MarkStatic(Mutability::Immutable);\n+            let name = ty::tls::with(|tcx| tcx.item_path_str(instance.def_id()));\n+            trace!(\"const_eval: pushing stack frame for global: {}\", name);\n+            ecx.push_stack_frame(\n+                instance,\n+                mir.span,\n+                mir,\n+                Place::from_ptr(ptr),\n+                cleanup.clone(),\n+            )?;\n+\n+            while ecx.step()? {}\n+\n+            // reinsert the stack frame so any future queries have the correct substs\n+            ecx.push_stack_frame(\n+                instance,\n+                mir.span,\n+                mir,\n+                Place::from_ptr(ptr),\n+                cleanup,\n+            )?;\n+        }\n+        let value = tcx.interpret_interner.borrow().get_cached(cid).expect(\"global not cached\");\n+        Ok((value, instance_ty))\n+    })();\n+    (try, ecx)\n+}\n+\n+pub fn eval_body_as_integer<'a, 'tcx>(\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    param_env: ty::ParamEnv<'tcx>,\n+    instance: Instance<'tcx>,\n+) -> EvalResult<'tcx, ConstInt> {\n+    let (ptr_ty, ecx) = eval_body(tcx, instance, param_env);\n+    let (ptr, ty) = ptr_ty?;\n+    let prim = match ecx.read_maybe_aligned(ptr.aligned, |ectx| ectx.try_read_value(ptr.ptr, ty))? {\n+        Some(Value::ByVal(prim)) => prim.to_bytes()?,\n+        _ => return err!(TypeNotPrimitive(ty)),\n+    };\n+    use syntax::ast::{IntTy, UintTy};\n+    use rustc::ty::TypeVariants::*;\n+    use rustc_const_math::{ConstIsize, ConstUsize};\n+    Ok(match ty.sty {\n+        TyInt(IntTy::I8) => ConstInt::I8(prim as i128 as i8),\n+        TyInt(IntTy::I16) => ConstInt::I16(prim as i128 as i16),\n+        TyInt(IntTy::I32) => ConstInt::I32(prim as i128 as i32),\n+        TyInt(IntTy::I64) => ConstInt::I64(prim as i128 as i64),\n+        TyInt(IntTy::I128) => ConstInt::I128(prim as i128),\n+        TyInt(IntTy::Is) => ConstInt::Isize(\n+            ConstIsize::new(prim as i128 as i64, tcx.sess.target.isize_ty)\n+                .expect(\"miri should already have errored\"),\n+        ),\n+        TyUint(UintTy::U8) => ConstInt::U8(prim as u8),\n+        TyUint(UintTy::U16) => ConstInt::U16(prim as u16),\n+        TyUint(UintTy::U32) => ConstInt::U32(prim as u32),\n+        TyUint(UintTy::U64) => ConstInt::U64(prim as u64),\n+        TyUint(UintTy::U128) => ConstInt::U128(prim),\n+        TyUint(UintTy::Us) => ConstInt::Usize(\n+            ConstUsize::new(prim as u64, tcx.sess.target.usize_ty)\n+                .expect(\"miri should already have errored\"),\n+        ),\n+        _ => {\n+            return Err(\n+                ConstEvalError::NeedsRfc(\n+                    \"evaluating anything other than isize/usize during typeck\".to_string(),\n+                ).into(),\n+            )\n+        }\n+    })\n+}\n+\n+pub struct CompileTimeEvaluator;\n+\n+impl<'tcx> Into<EvalError<'tcx>> for ConstEvalError {\n+    fn into(self) -> EvalError<'tcx> {\n+        EvalErrorKind::MachineError(Box::new(self)).into()\n+    }\n+}\n+\n+#[derive(Clone, Debug)]\n+enum ConstEvalError {\n+    NeedsRfc(String),\n+    NotConst(String),\n+}\n+\n+impl fmt::Display for ConstEvalError {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        use self::ConstEvalError::*;\n+        match *self {\n+            NeedsRfc(ref msg) => {\n+                write!(\n+                    f,\n+                    \"\\\"{}\\\" needs an rfc before being allowed inside constants\",\n+                    msg\n+                )\n+            }\n+            NotConst(ref msg) => write!(f, \"Cannot evaluate within constants: \\\"{}\\\"\", msg),\n+        }\n+    }\n+}\n+\n+impl Error for ConstEvalError {\n+    fn description(&self) -> &str {\n+        use self::ConstEvalError::*;\n+        match *self {\n+            NeedsRfc(_) => \"this feature needs an rfc before being allowed inside constants\",\n+            NotConst(_) => \"this feature is not compatible with constant evaluation\",\n+        }\n+    }\n+\n+    fn cause(&self) -> Option<&Error> {\n+        None\n+    }\n+}\n+\n+impl<'tcx> super::Machine<'tcx> for CompileTimeEvaluator {\n+    type MemoryData = ();\n+    type MemoryKinds = !;\n+    fn eval_fn_call<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        instance: ty::Instance<'tcx>,\n+        destination: Option<(Place, mir::BasicBlock)>,\n+        _args: &[ValTy<'tcx>],\n+        span: Span,\n+        _sig: ty::FnSig<'tcx>,\n+    ) -> EvalResult<'tcx, bool> {\n+        debug!(\"eval_fn_call: {:?}\", instance);\n+        if !ecx.tcx.is_const_fn(instance.def_id()) {\n+            return Err(\n+                ConstEvalError::NotConst(format!(\"calling non-const fn `{}`\", instance)).into(),\n+            );\n+        }\n+        let mir = match ecx.load_mir(instance.def) {\n+            Ok(mir) => mir,\n+            Err(EvalError { kind: EvalErrorKind::NoMirFor(path), .. }) => {\n+                // some simple things like `malloc` might get accepted in the future\n+                return Err(\n+                    ConstEvalError::NeedsRfc(format!(\"calling extern function `{}`\", path))\n+                        .into(),\n+                );\n+            }\n+            Err(other) => return Err(other),\n+        };\n+        let (return_place, return_to_block) = match destination {\n+            Some((place, block)) => (place, StackPopCleanup::Goto(block)),\n+            None => (Place::undef(), StackPopCleanup::None),\n+        };\n+\n+        ecx.push_stack_frame(\n+            instance,\n+            span,\n+            mir,\n+            return_place,\n+            return_to_block,\n+        )?;\n+\n+        Ok(false)\n+    }\n+\n+\n+    fn call_intrinsic<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        instance: ty::Instance<'tcx>,\n+        _args: &[ValTy<'tcx>],\n+        dest: Place,\n+        dest_layout: layout::TyLayout<'tcx>,\n+        target: mir::BasicBlock,\n+    ) -> EvalResult<'tcx> {\n+        let substs = instance.substs;\n+\n+        let intrinsic_name = &ecx.tcx.item_name(instance.def_id())[..];\n+        match intrinsic_name {\n+            \"min_align_of\" => {\n+                let elem_ty = substs.type_at(0);\n+                let elem_align = ecx.layout_of(elem_ty)?.align.abi();\n+                let align_val = PrimVal::from_u128(elem_align as u128);\n+                ecx.write_primval(dest, align_val, dest_layout.ty)?;\n+            }\n+\n+            \"size_of\" => {\n+                let ty = substs.type_at(0);\n+                let size = ecx.layout_of(ty)?.size.bytes() as u128;\n+                ecx.write_primval(dest, PrimVal::from_u128(size), dest_layout.ty)?;\n+            }\n+\n+            name => return Err(ConstEvalError::NeedsRfc(format!(\"calling intrinsic `{}`\", name)).into()),\n+        }\n+\n+        ecx.goto_block(target);\n+\n+        // Since we pushed no stack frame, the main loop will act\n+        // as if the call just completed and it's returning to the\n+        // current frame.\n+        Ok(())\n+    }\n+\n+    fn try_ptr_op<'a>(\n+        _ecx: &EvalContext<'a, 'tcx, Self>,\n+        _bin_op: mir::BinOp,\n+        left: PrimVal,\n+        _left_ty: Ty<'tcx>,\n+        right: PrimVal,\n+        _right_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, Option<(PrimVal, bool)>> {\n+        if left.is_bytes() && right.is_bytes() {\n+            Ok(None)\n+        } else {\n+            Err(\n+                ConstEvalError::NeedsRfc(\"Pointer arithmetic or comparison\".to_string()).into(),\n+            )\n+        }\n+    }\n+\n+    fn mark_static_initialized(m: !) -> EvalResult<'tcx> {\n+        m\n+    }\n+\n+    fn box_alloc<'a>(\n+        _ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        _ty: Ty<'tcx>,\n+        _dest: Place,\n+    ) -> EvalResult<'tcx> {\n+        Err(\n+            ConstEvalError::NeedsRfc(\"Heap allocations via `box` keyword\".to_string()).into(),\n+        )\n+    }\n+\n+    fn global_item_with_linkage<'a>(\n+        _ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        _instance: ty::Instance<'tcx>,\n+        _mutability: Mutability,\n+    ) -> EvalResult<'tcx> {\n+        Err(\n+            ConstEvalError::NotConst(\"statics with `linkage` attribute\".to_string()).into(),\n+        )\n+    }\n+}\n+\n+pub fn const_eval_provider<'a, 'tcx>(\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    key: ty::ParamEnvAnd<'tcx, (DefId, &'tcx Substs<'tcx>)>,\n+) -> ::rustc::middle::const_val::EvalResult<'tcx> {\n+    trace!(\"const eval: {:?}\", key);\n+    let (def_id, substs) = if let Some(resolved) = lookup_const_by_id(tcx, key) {\n+        resolved\n+    } else {\n+        return Err(ConstEvalErr {\n+            span: tcx.def_span(key.value.0),\n+            kind: TypeckError\n+        });\n+    };\n+\n+    let tables = tcx.typeck_tables_of(def_id);\n+    let body = if let Some(id) = tcx.hir.as_local_node_id(def_id) {\n+        let body_id = tcx.hir.body_owned_by(id);\n+\n+        // Do match-check before building MIR\n+        if tcx.check_match(def_id).is_err() {\n+            return Err(ConstEvalErr {\n+                span: tcx.def_span(key.value.0),\n+                kind: CheckMatchError,\n+            });\n+        }\n+\n+        tcx.mir_const_qualif(def_id);\n+        tcx.hir.body(body_id)\n+    } else {\n+        tcx.extern_const_body(def_id).body\n+    };\n+\n+    // do not continue into miri if typeck errors occurred\n+    // it will fail horribly\n+    if tables.tainted_by_errors {\n+        return Err(ConstEvalErr { span: body.value.span, kind: TypeckError })\n+    }\n+\n+    trace!(\"running old const eval\");\n+    let old_result = ConstContext::new(tcx, key.param_env.and(substs), tables).eval(&body.value);\n+    trace!(\"old const eval produced {:?}\", old_result);\n+    if tcx.sess.opts.debugging_opts.miri {\n+        let instance = ty::Instance::new(def_id, substs);\n+        trace!(\"const eval instance: {:?}, {:?}\", instance, key.param_env);\n+        let miri_result = ::interpret::eval_body(tcx, instance, key.param_env);\n+        match (miri_result, old_result) {\n+            ((Err(err), ecx), Ok(ok)) => {\n+                trace!(\"miri failed, ctfe returned {:?}\", ok);\n+                tcx.sess.span_warn(\n+                    tcx.def_span(key.value.0),\n+                    \"miri failed to eval, while ctfe succeeded\",\n+                );\n+                let () = unwrap_miri(&ecx, Err(err));\n+                Ok(ok)\n+            },\n+            ((Ok(_), _), Err(err)) => {\n+                Err(err)\n+            },\n+            ((Err(_), _), Err(err)) => Err(err),\n+            ((Ok((miri_val, miri_ty)), mut ecx), Ok(ctfe)) => {\n+                check_ctfe_against_miri(&mut ecx, miri_val, miri_ty, ctfe.val);\n+                Ok(ctfe)\n+            }\n+        }\n+    } else {\n+        old_result\n+    }\n+}\n+\n+fn check_ctfe_against_miri<'a, 'tcx>(\n+    ecx: &mut EvalContext<'a, 'tcx, CompileTimeEvaluator>,\n+    miri_val: PtrAndAlign,\n+    miri_ty: Ty<'tcx>,\n+    ctfe: ConstVal<'tcx>,\n+) {\n+    use rustc::middle::const_val::ConstAggregate::*;\n+    use rustc_const_math::ConstFloat;\n+    use rustc::ty::TypeVariants::*;\n+    match miri_ty.sty {\n+        TyInt(int_ty) => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let prim = get_prim(ecx, value);\n+            let c = ConstInt::new_signed_truncating(prim as i128,\n+                                                    int_ty,\n+                                                    ecx.tcx.sess.target.isize_ty);\n+            let c = ConstVal::Integral(c);\n+            assert_eq!(c, ctfe, \"miri evaluated to {:?}, but ctfe yielded {:?}\", c, ctfe);\n+        },\n+        TyUint(uint_ty) => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let prim = get_prim(ecx, value);\n+            let c = ConstInt::new_unsigned_truncating(prim,\n+                                                     uint_ty,\n+                                                     ecx.tcx.sess.target.usize_ty);\n+            let c = ConstVal::Integral(c);\n+            assert_eq!(c, ctfe, \"miri evaluated to {:?}, but ctfe yielded {:?}\", c, ctfe);\n+        },\n+        TyFloat(ty) => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let prim = get_prim(ecx, value);\n+            let f = ConstVal::Float(ConstFloat { bits: prim, ty });\n+            assert_eq!(f, ctfe, \"miri evaluated to {:?}, but ctfe yielded {:?}\", f, ctfe);\n+        },\n+        TyBool => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let bits = get_prim(ecx, value);\n+            if bits > 1 {\n+                bug!(\"miri evaluated to {}, but expected a bool {:?}\", bits, ctfe);\n+            }\n+            let b = ConstVal::Bool(bits == 1);\n+            assert_eq!(b, ctfe, \"miri evaluated to {:?}, but ctfe yielded {:?}\", b, ctfe);\n+        },\n+        TyChar => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let bits = get_prim(ecx, value);\n+            if let Some(cm) = ::std::char::from_u32(bits as u32) {\n+                assert_eq!(\n+                    ConstVal::Char(cm), ctfe,\n+                    \"miri evaluated to {:?}, but expected {:?}\", cm, ctfe,\n+                );\n+            } else {\n+                bug!(\"miri evaluated to {}, but expected a char {:?}\", bits, ctfe);\n+            }\n+        },\n+        TyStr => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            if let Ok(Some(Value::ByValPair(PrimVal::Ptr(ptr), PrimVal::Bytes(len)))) = value {\n+                let bytes = ecx\n+                    .memory\n+                    .read_bytes(ptr.into(), len as u64)\n+                    .expect(\"bad miri memory for str\");\n+                if let Ok(s) = ::std::str::from_utf8(bytes) {\n+                    if let ConstVal::Str(s2) = ctfe {\n+                        assert_eq!(s, s2, \"miri produced {:?}, but expected {:?}\", s, s2);\n+                    } else {\n+                        bug!(\"miri produced {:?}, but expected {:?}\", s, ctfe);\n+                    }\n+                } else {\n+                    bug!(\n+                        \"miri failed to produce valid utf8 {:?}, while ctfe produced {:?}\",\n+                        bytes,\n+                        ctfe,\n+                    );\n+                }\n+            } else {\n+                bug!(\"miri evaluated to {:?}, but expected a str {:?}\", value, ctfe);\n+            }\n+        },\n+        TyArray(elem_ty, n) => {\n+            let n = n.val.to_const_int().unwrap().to_u64().unwrap();\n+            let size = ecx.layout_of(elem_ty).unwrap().size.bytes();\n+            let vec: Vec<(ConstVal, Ty<'tcx>)> = match ctfe {\n+                ConstVal::ByteStr(arr) => arr.data.iter().map(|&b| {\n+                    (ConstVal::Integral(ConstInt::U8(b)), ecx.tcx.types.u8)\n+                }).collect(),\n+                ConstVal::Aggregate(Array(v)) => {\n+                    v.iter().map(|c| (c.val, c.ty)).collect()\n+                },\n+                ConstVal::Aggregate(Repeat(v, n)) => {\n+                    vec![(v.val, v.ty); n as usize]\n+                },\n+                _ => bug!(\"miri produced {:?}, but ctfe yielded {:?}\", miri_ty, ctfe),\n+            };\n+            for (i, elem) in vec.into_iter().enumerate() {\n+                assert!((i as u64) < n);\n+                let ptr = miri_val.offset(size * i as u64, &ecx).unwrap();\n+                check_ctfe_against_miri(ecx, ptr, elem_ty, elem.0);\n+            }\n+        },\n+        TyTuple(..) => {\n+            let vec = match ctfe {\n+                ConstVal::Aggregate(Tuple(v)) => v,\n+                _ => bug!(\"miri produced {:?}, but ctfe yielded {:?}\", miri_ty, ctfe),\n+            };\n+            let layout = ecx.layout_of(miri_ty).unwrap();\n+            for (i, elem) in vec.into_iter().enumerate() {\n+                let offset = layout.fields.offset(i);\n+                let ptr = miri_val.offset(offset.bytes(), &ecx).unwrap();\n+                check_ctfe_against_miri(ecx, ptr, elem.ty, elem.val);\n+            }\n+        },\n+        TyAdt(def, _) => {\n+            let (struct_variant, extra) = if def.is_enum() {\n+                let discr = ecx.read_discriminant_value(\n+                    Place::Ptr { ptr: miri_val, extra: PlaceExtra::None },\n+                    miri_ty).unwrap();\n+                let variant = def.discriminants(ecx.tcx).position(|variant_discr| {\n+                    variant_discr.to_u128_unchecked() == discr\n+                }).expect(\"miri produced invalid enum discriminant\");\n+                (&def.variants[variant], PlaceExtra::DowncastVariant(variant))\n+            } else {\n+                (def.struct_variant(), PlaceExtra::None)\n+            };\n+            let vec = match ctfe {\n+                ConstVal::Aggregate(Struct(v)) => v,\n+                ConstVal::Variant(did) => {\n+                    assert_eq!(struct_variant.fields.len(), 0);\n+                    assert_eq!(did, struct_variant.did);\n+                    return;\n+                },\n+                ctfe => bug!(\"miri produced {:?}, but ctfe yielded {:?}\", miri_ty, ctfe),\n+            };\n+            let layout = ecx.layout_of(miri_ty).unwrap();\n+            for &(name, elem) in vec.into_iter() {\n+                let field = struct_variant.fields.iter().position(|f| f.name == name).unwrap();\n+                let (place, _) = ecx.place_field(\n+                    Place::Ptr { ptr: miri_val, extra },\n+                    Field::new(field),\n+                    layout,\n+                ).unwrap();\n+                let ptr = place.to_ptr_extra_aligned().0;\n+                check_ctfe_against_miri(ecx, ptr, elem.ty, elem.val);\n+            }\n+        },\n+        TySlice(_) => bug!(\"miri produced a slice?\"),\n+        // not supported by ctfe\n+        TyRawPtr(_) |\n+        TyRef(..) => {}\n+        TyDynamic(..) => bug!(\"miri produced a trait object\"),\n+        TyClosure(..) => bug!(\"miri produced a closure\"),\n+        TyGenerator(..) => bug!(\"miri produced a generator\"),\n+        TyNever => bug!(\"miri produced a value of the never type\"),\n+        TyProjection(_) => bug!(\"miri produced a projection\"),\n+        TyAnon(..) => bug!(\"miri produced an impl Trait type\"),\n+        TyParam(_) => bug!(\"miri produced an unmonomorphized type\"),\n+        TyInfer(_) => bug!(\"miri produced an uninferred type\"),\n+        TyError => bug!(\"miri produced a type error\"),\n+        TyForeign(_) => bug!(\"miri produced an extern type\"),\n+        // should be fine\n+        TyFnDef(..) => {}\n+        TyFnPtr(_) => {\n+            let value = ecx.read_maybe_aligned(miri_val.aligned, |ectx| {\n+                ectx.try_read_value(miri_val.ptr, miri_ty)\n+            });\n+            let ptr = match value {\n+                Ok(Some(Value::ByVal(PrimVal::Ptr(ptr)))) => ptr,\n+                value => bug!(\"expected fn ptr, got {:?}\", value),\n+            };\n+            let inst = ecx.memory.get_fn(ptr).unwrap();\n+            match ctfe {\n+                ConstVal::Function(did, substs) => {\n+                    let ctfe = ty::Instance::resolve(\n+                        ecx.tcx,\n+                        ecx.param_env,\n+                        did,\n+                        substs,\n+                    ).unwrap();\n+                    assert_eq!(inst, ctfe, \"expected fn ptr {:?}, but got {:?}\", ctfe, inst);\n+                },\n+                _ => bug!(\"ctfe produced {:?}, but miri produced function {:?}\", ctfe, inst),\n+            }\n+        },\n+    }\n+}\n+\n+fn get_prim<'a, 'tcx>(\n+    ecx: &mut EvalContext<'a, 'tcx, CompileTimeEvaluator>,\n+    res: Result<Option<Value>, EvalError<'tcx>>,\n+) -> u128 {\n+    match res {\n+        Ok(Some(Value::ByVal(prim))) => unwrap_miri(ecx, prim.to_bytes()),\n+        Err(err) => unwrap_miri(ecx, Err(err)),\n+        val => bug!(\"got {:?}\", val),\n+    }\n+}\n+\n+fn unwrap_miri<'a, 'tcx, T>(\n+    ecx: &EvalContext<'a, 'tcx, CompileTimeEvaluator>,\n+    res: Result<T, EvalError<'tcx>>,\n+) -> T {\n+    match res {\n+        Ok(val) => val,\n+        Err(mut err) => {\n+            ecx.report(&mut err);\n+            ecx.tcx.sess.abort_if_errors();\n+            bug!(\"{:#?}\", err);\n+        }\n+    }\n+}"}, {"sha": "6b33fd246daa874da1f3751e6ad03c180be8c8f0", "filename": "src/librustc_mir/interpret/eval_context.rs", "status": "added", "additions": 1739, "deletions": 0, "changes": 1739, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Feval_context.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,1739 @@\n+use std::collections::HashSet;\n+use std::fmt::Write;\n+\n+use rustc::hir::def_id::DefId;\n+use rustc::hir::map::definitions::DefPathData;\n+use rustc::middle::const_val::ConstVal;\n+use rustc::mir;\n+use rustc::traits::Reveal;\n+use rustc::ty::layout::{self, Size, Align, HasDataLayout, LayoutOf, TyLayout};\n+use rustc::ty::subst::{Subst, Substs, Kind};\n+use rustc::ty::{self, Ty, TyCtxt};\n+use rustc_data_structures::indexed_vec::Idx;\n+use syntax::codemap::{self, DUMMY_SP};\n+use syntax::ast::Mutability;\n+use rustc::mir::interpret::{\n+    PtrAndAlign, GlobalId, Value, Pointer, PrimVal, PrimValKind,\n+    EvalError, EvalResult, EvalErrorKind, MemoryPointer,\n+};\n+\n+use super::{Place, PlaceExtra, Memory,\n+            HasMemory, MemoryKind, operator,\n+            Machine};\n+\n+pub struct EvalContext<'a, 'tcx: 'a, M: Machine<'tcx>> {\n+    /// Stores the `Machine` instance.\n+    pub machine: M,\n+\n+    /// The results of the type checker, from rustc.\n+    pub tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+\n+    /// Bounds in scope for polymorphic evaluations.\n+    pub param_env: ty::ParamEnv<'tcx>,\n+\n+    /// The virtual memory system.\n+    pub memory: Memory<'a, 'tcx, M>,\n+\n+    /// The virtual call stack.\n+    pub(crate) stack: Vec<Frame<'tcx>>,\n+\n+    /// The maximum number of stack frames allowed\n+    pub(crate) stack_limit: usize,\n+\n+    /// The maximum number of operations that may be executed.\n+    /// This prevents infinite loops and huge computations from freezing up const eval.\n+    /// Remove once halting problem is solved.\n+    pub(crate) steps_remaining: u64,\n+}\n+\n+/// A stack frame.\n+pub struct Frame<'tcx> {\n+    ////////////////////////////////////////////////////////////////////////////////\n+    // Function and callsite information\n+    ////////////////////////////////////////////////////////////////////////////////\n+    /// The MIR for the function called on this frame.\n+    pub mir: &'tcx mir::Mir<'tcx>,\n+\n+    /// The def_id and substs of the current function\n+    pub instance: ty::Instance<'tcx>,\n+\n+    /// The span of the call site.\n+    pub span: codemap::Span,\n+\n+    ////////////////////////////////////////////////////////////////////////////////\n+    // Return place and locals\n+    ////////////////////////////////////////////////////////////////////////////////\n+    /// The block to return to when returning from the current stack frame\n+    pub return_to_block: StackPopCleanup,\n+\n+    /// The location where the result of the current stack frame should be written to.\n+    pub return_place: Place,\n+\n+    /// The list of locals for this stack frame, stored in order as\n+    /// `[arguments..., variables..., temporaries...]`. The locals are stored as `Option<Value>`s.\n+    /// `None` represents a local that is currently dead, while a live local\n+    /// can either directly contain `PrimVal` or refer to some part of an `Allocation`.\n+    ///\n+    /// Before being initialized, arguments are `Value::ByVal(PrimVal::Undef)` and other locals are `None`.\n+    pub locals: Vec<Option<Value>>,\n+\n+    ////////////////////////////////////////////////////////////////////////////////\n+    // Current position within the function\n+    ////////////////////////////////////////////////////////////////////////////////\n+    /// The block that is currently executed (or will be executed after the above call stacks\n+    /// return).\n+    pub block: mir::BasicBlock,\n+\n+    /// The index of the currently evaluated statment.\n+    pub stmt: usize,\n+}\n+\n+#[derive(Clone, Debug, Eq, PartialEq, Hash)]\n+pub enum StackPopCleanup {\n+    /// The stackframe existed to compute the initial value of a static/constant, make sure it\n+    /// isn't modifyable afterwards in case of constants.\n+    /// In case of `static mut`, mark the memory to ensure it's never marked as immutable through\n+    /// references or deallocated\n+    MarkStatic(Mutability),\n+    /// A regular stackframe added due to a function call will need to get forwarded to the next\n+    /// block\n+    Goto(mir::BasicBlock),\n+    /// The main function and diverging functions have nowhere to return to\n+    None,\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub struct ResourceLimits {\n+    pub memory_size: u64,\n+    pub step_limit: u64,\n+    pub stack_limit: usize,\n+}\n+\n+impl Default for ResourceLimits {\n+    fn default() -> Self {\n+        ResourceLimits {\n+            memory_size: 100 * 1024 * 1024, // 100 MB\n+            step_limit: 1_000_000,\n+            stack_limit: 100,\n+        }\n+    }\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub struct TyAndPacked<'tcx> {\n+    pub ty: Ty<'tcx>,\n+    pub packed: bool,\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub struct ValTy<'tcx> {\n+    pub value: Value,\n+    pub ty: Ty<'tcx>,\n+}\n+\n+impl<'tcx> ::std::ops::Deref for ValTy<'tcx> {\n+    type Target = Value;\n+    fn deref(&self) -> &Value {\n+        &self.value\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> HasDataLayout for &'a EvalContext<'a, 'tcx, M> {\n+    #[inline]\n+    fn data_layout(&self) -> &layout::TargetDataLayout {\n+        &self.tcx.data_layout\n+    }\n+}\n+\n+impl<'c, 'b, 'a, 'tcx, M: Machine<'tcx>> HasDataLayout\n+    for &'c &'b mut EvalContext<'a, 'tcx, M> {\n+    #[inline]\n+    fn data_layout(&self) -> &layout::TargetDataLayout {\n+        &self.tcx.data_layout\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> layout::HasTyCtxt<'tcx> for &'a EvalContext<'a, 'tcx, M> {\n+    #[inline]\n+    fn tcx<'b>(&'b self) -> TyCtxt<'b, 'tcx, 'tcx> {\n+        self.tcx\n+    }\n+}\n+\n+impl<'c, 'b, 'a, 'tcx, M: Machine<'tcx>> layout::HasTyCtxt<'tcx>\n+    for &'c &'b mut EvalContext<'a, 'tcx, M> {\n+    #[inline]\n+    fn tcx<'d>(&'d self) -> TyCtxt<'d, 'tcx, 'tcx> {\n+        self.tcx\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> LayoutOf<Ty<'tcx>> for &'a EvalContext<'a, 'tcx, M> {\n+    type TyLayout = EvalResult<'tcx, TyLayout<'tcx>>;\n+\n+    fn layout_of(self, ty: Ty<'tcx>) -> Self::TyLayout {\n+        (self.tcx, self.param_env).layout_of(ty)\n+            .map_err(|layout| EvalErrorKind::Layout(layout).into())\n+    }\n+}\n+\n+impl<'c, 'b, 'a, 'tcx, M: Machine<'tcx>> LayoutOf<Ty<'tcx>>\n+    for &'c &'b mut EvalContext<'a, 'tcx, M> {\n+    type TyLayout = EvalResult<'tcx, TyLayout<'tcx>>;\n+\n+    #[inline]\n+    fn layout_of(self, ty: Ty<'tcx>) -> Self::TyLayout {\n+        (&**self).layout_of(ty)\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    pub fn new(\n+        tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+        param_env: ty::ParamEnv<'tcx>,\n+        limits: ResourceLimits,\n+        machine: M,\n+        memory_data: M::MemoryData,\n+    ) -> Self {\n+        EvalContext {\n+            machine,\n+            tcx,\n+            param_env,\n+            memory: Memory::new(tcx, limits.memory_size, memory_data),\n+            stack: Vec::new(),\n+            stack_limit: limits.stack_limit,\n+            steps_remaining: limits.step_limit,\n+        }\n+    }\n+\n+    pub fn alloc_ptr(&mut self, ty: Ty<'tcx>) -> EvalResult<'tcx, MemoryPointer> {\n+        let layout = self.layout_of(ty)?;\n+        assert!(!layout.is_unsized(), \"cannot alloc memory for unsized type\");\n+\n+        let size = layout.size.bytes();\n+        let align = layout.align.abi();\n+        self.memory.allocate(size, align, Some(MemoryKind::Stack))\n+    }\n+\n+    pub fn memory(&self) -> &Memory<'a, 'tcx, M> {\n+        &self.memory\n+    }\n+\n+    pub fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx, M> {\n+        &mut self.memory\n+    }\n+\n+    pub fn stack(&self) -> &[Frame<'tcx>] {\n+        &self.stack\n+    }\n+\n+    #[inline]\n+    pub fn cur_frame(&self) -> usize {\n+        assert!(self.stack.len() > 0);\n+        self.stack.len() - 1\n+    }\n+\n+    pub fn str_to_value(&mut self, s: &str) -> EvalResult<'tcx, Value> {\n+        let ptr = self.memory.allocate_cached(s.as_bytes());\n+        Ok(Value::ByValPair(\n+            PrimVal::Ptr(ptr),\n+            PrimVal::from_u128(s.len() as u128),\n+        ))\n+    }\n+\n+    pub(super) fn const_to_value(&mut self, const_val: &ConstVal<'tcx>) -> EvalResult<'tcx, Value> {\n+        use rustc::middle::const_val::ConstVal::*;\n+\n+        let primval = match *const_val {\n+            Integral(const_int) => PrimVal::Bytes(const_int.to_u128_unchecked()),\n+\n+            Float(val) => PrimVal::Bytes(val.bits),\n+\n+            Bool(b) => PrimVal::from_bool(b),\n+            Char(c) => PrimVal::from_char(c),\n+\n+            Str(ref s) => return self.str_to_value(s),\n+\n+            ByteStr(ref bs) => {\n+                let ptr = self.memory.allocate_cached(bs.data);\n+                PrimVal::Ptr(ptr)\n+            }\n+\n+            Unevaluated(def_id, substs) => {\n+                let instance = self.resolve(def_id, substs)?;\n+                let cid = GlobalId {\n+                    instance,\n+                    promoted: None,\n+                };\n+                return Ok(Value::ByRef(self.tcx.interpret_interner.borrow().get_cached(cid).expect(\"static/const not cached\")));\n+            }\n+\n+            Aggregate(..) |\n+            Variant(_) => bug!(\"should not have aggregate or variant constants in MIR\"),\n+            // function items are zero sized and thus have no readable value\n+            Function(..) => PrimVal::Undef,\n+        };\n+\n+        Ok(Value::ByVal(primval))\n+    }\n+\n+    pub(super) fn resolve(&self, def_id: DefId, substs: &'tcx Substs<'tcx>) -> EvalResult<'tcx, ty::Instance<'tcx>> {\n+        let substs = self.tcx.trans_apply_param_substs(self.substs(), &substs);\n+        ty::Instance::resolve(\n+            self.tcx,\n+            self.param_env,\n+            def_id,\n+            substs,\n+        ).ok_or(EvalErrorKind::TypeckError.into()) // turn error prop into a panic to expose associated type in const issue\n+    }\n+\n+    pub(super) fn type_is_sized(&self, ty: Ty<'tcx>) -> bool {\n+        ty.is_sized(self.tcx, self.param_env, DUMMY_SP)\n+    }\n+\n+    pub fn load_mir(\n+        &self,\n+        instance: ty::InstanceDef<'tcx>,\n+    ) -> EvalResult<'tcx, &'tcx mir::Mir<'tcx>> {\n+        // do not continue if typeck errors occurred (can only occur in local crate)\n+        let did = instance.def_id();\n+        if did.is_local() && self.tcx.has_typeck_tables(did) && self.tcx.typeck_tables_of(did).tainted_by_errors {\n+            return err!(TypeckError);\n+        }\n+        trace!(\"load mir {:?}\", instance);\n+        match instance {\n+            ty::InstanceDef::Item(def_id) => {\n+                self.tcx.maybe_optimized_mir(def_id).ok_or_else(|| {\n+                    EvalErrorKind::NoMirFor(self.tcx.item_path_str(def_id)).into()\n+                })\n+            }\n+            _ => Ok(self.tcx.instance_mir(instance)),\n+        }\n+    }\n+\n+    pub fn monomorphize(&self, ty: Ty<'tcx>, substs: &'tcx Substs<'tcx>) -> Ty<'tcx> {\n+        // miri doesn't care about lifetimes, and will choke on some crazy ones\n+        // let's simply get rid of them\n+        let without_lifetimes = self.tcx.erase_regions(&ty);\n+        let substituted = without_lifetimes.subst(self.tcx, substs);\n+        let substituted = self.tcx.fully_normalize_monormophic_ty(&substituted);\n+        substituted\n+    }\n+\n+    /// Return the size and aligment of the value at the given type.\n+    /// Note that the value does not matter if the type is sized. For unsized types,\n+    /// the value has to be a fat pointer, and we only care about the \"extra\" data in it.\n+    pub fn size_and_align_of_dst(\n+        &mut self,\n+        ty: Ty<'tcx>,\n+        value: Value,\n+    ) -> EvalResult<'tcx, (Size, Align)> {\n+        let layout = self.layout_of(ty)?;\n+        if !layout.is_unsized() {\n+            Ok(layout.size_and_align())\n+        } else {\n+            match ty.sty {\n+                ty::TyAdt(..) | ty::TyTuple(..) => {\n+                    // First get the size of all statically known fields.\n+                    // Don't use type_of::sizing_type_of because that expects t to be sized,\n+                    // and it also rounds up to alignment, which we want to avoid,\n+                    // as the unsized field's alignment could be smaller.\n+                    assert!(!ty.is_simd());\n+                    debug!(\"DST {} layout: {:?}\", ty, layout);\n+\n+                    let sized_size = layout.fields.offset(layout.fields.count() - 1);\n+                    let sized_align = layout.align;\n+                    debug!(\n+                        \"DST {} statically sized prefix size: {:?} align: {:?}\",\n+                        ty,\n+                        sized_size,\n+                        sized_align\n+                    );\n+\n+                    // Recurse to get the size of the dynamically sized field (must be\n+                    // the last field).\n+                    let field_ty = layout.field(&self, layout.fields.count() - 1)?.ty;\n+                    let (unsized_size, unsized_align) =\n+                        self.size_and_align_of_dst(field_ty, value)?;\n+\n+                    // FIXME (#26403, #27023): We should be adding padding\n+                    // to `sized_size` (to accommodate the `unsized_align`\n+                    // required of the unsized field that follows) before\n+                    // summing it with `sized_size`. (Note that since #26403\n+                    // is unfixed, we do not yet add the necessary padding\n+                    // here. But this is where the add would go.)\n+\n+                    // Return the sum of sizes and max of aligns.\n+                    let size = sized_size + unsized_size;\n+\n+                    // Choose max of two known alignments (combined value must\n+                    // be aligned according to more restrictive of the two).\n+                    let align = sized_align.max(unsized_align);\n+\n+                    // Issue #27023: must add any necessary padding to `size`\n+                    // (to make it a multiple of `align`) before returning it.\n+                    //\n+                    // Namely, the returned size should be, in C notation:\n+                    //\n+                    //   `size + ((size & (align-1)) ? align : 0)`\n+                    //\n+                    // emulated via the semi-standard fast bit trick:\n+                    //\n+                    //   `(size + (align-1)) & -align`\n+\n+                    Ok((size.abi_align(align), align))\n+                }\n+                ty::TyDynamic(..) => {\n+                    let (_, vtable) = self.into_ptr_vtable_pair(value)?;\n+                    // the second entry in the vtable is the dynamic size of the object.\n+                    self.read_size_and_align_from_vtable(vtable)\n+                }\n+\n+                ty::TySlice(_) | ty::TyStr => {\n+                    let (elem_size, align) = layout.field(&self, 0)?.size_and_align();\n+                    let (_, len) = self.into_slice(value)?;\n+                    Ok((elem_size * len, align))\n+                }\n+\n+                _ => bug!(\"size_of_val::<{:?}>\", ty),\n+            }\n+        }\n+    }\n+\n+    pub fn push_stack_frame(\n+        &mut self,\n+        instance: ty::Instance<'tcx>,\n+        span: codemap::Span,\n+        mir: &'tcx mir::Mir<'tcx>,\n+        return_place: Place,\n+        return_to_block: StackPopCleanup,\n+    ) -> EvalResult<'tcx> {\n+        ::log_settings::settings().indentation += 1;\n+\n+        /// Return the set of locals that have a storage annotation anywhere\n+        fn collect_storage_annotations<'tcx>(mir: &'tcx mir::Mir<'tcx>) -> HashSet<mir::Local> {\n+            use rustc::mir::StatementKind::*;\n+\n+            let mut set = HashSet::new();\n+            for block in mir.basic_blocks() {\n+                for stmt in block.statements.iter() {\n+                    match stmt.kind {\n+                        StorageLive(local) |\n+                        StorageDead(local) => {\n+                            set.insert(local);\n+                        }\n+                        _ => {}\n+                    }\n+                }\n+            }\n+            set\n+        }\n+\n+        // Subtract 1 because `local_decls` includes the ReturnMemoryPointer, but we don't store a local\n+        // `Value` for that.\n+        let num_locals = mir.local_decls.len() - 1;\n+\n+        let locals = {\n+            let annotated_locals = collect_storage_annotations(mir);\n+            let mut locals = vec![None; num_locals];\n+            for i in 0..num_locals {\n+                let local = mir::Local::new(i + 1);\n+                if !annotated_locals.contains(&local) {\n+                    locals[i] = Some(Value::ByVal(PrimVal::Undef));\n+                }\n+            }\n+            locals\n+        };\n+\n+        self.stack.push(Frame {\n+            mir,\n+            block: mir::START_BLOCK,\n+            return_to_block,\n+            return_place,\n+            locals,\n+            span,\n+            instance,\n+            stmt: 0,\n+        });\n+\n+        self.memory.cur_frame = self.cur_frame();\n+\n+        if self.stack.len() > self.stack_limit {\n+            err!(StackFrameLimitReached)\n+        } else {\n+            Ok(())\n+        }\n+    }\n+\n+    pub(super) fn pop_stack_frame(&mut self) -> EvalResult<'tcx> {\n+        ::log_settings::settings().indentation -= 1;\n+        M::end_region(self, None)?;\n+        let frame = self.stack.pop().expect(\n+            \"tried to pop a stack frame, but there were none\",\n+        );\n+        if !self.stack.is_empty() {\n+            // TODO: Is this the correct time to start considering these accesses as originating from the returned-to stack frame?\n+            self.memory.cur_frame = self.cur_frame();\n+        }\n+        match frame.return_to_block {\n+            StackPopCleanup::MarkStatic(mutable) => {\n+                if let Place::Ptr { ptr, .. } = frame.return_place {\n+                    // FIXME: to_ptr()? might be too extreme here, static zsts might reach this under certain conditions\n+                    self.memory.mark_static_initalized(\n+                        ptr.to_ptr()?.alloc_id,\n+                        mutable,\n+                    )?\n+                } else {\n+                    bug!(\"StackPopCleanup::MarkStatic on: {:?}\", frame.return_place);\n+                }\n+            }\n+            StackPopCleanup::Goto(target) => self.goto_block(target),\n+            StackPopCleanup::None => {}\n+        }\n+        // deallocate all locals that are backed by an allocation\n+        for local in frame.locals {\n+            self.deallocate_local(local)?;\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub fn deallocate_local(&mut self, local: Option<Value>) -> EvalResult<'tcx> {\n+        if let Some(Value::ByRef(ptr)) = local {\n+            trace!(\"deallocating local\");\n+            let ptr = ptr.to_ptr()?;\n+            self.memory.dump_alloc(ptr.alloc_id);\n+            self.memory.deallocate_local(ptr)?;\n+        };\n+        Ok(())\n+    }\n+\n+    /// Evaluate an assignment statement.\n+    ///\n+    /// There is no separate `eval_rvalue` function. Instead, the code for handling each rvalue\n+    /// type writes its results directly into the memory specified by the place.\n+    pub(super) fn eval_rvalue_into_place(\n+        &mut self,\n+        rvalue: &mir::Rvalue<'tcx>,\n+        place: &mir::Place<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let dest = self.eval_place(place)?;\n+        let dest_ty = self.place_ty(place);\n+\n+        use rustc::mir::Rvalue::*;\n+        match *rvalue {\n+            Use(ref operand) => {\n+                let value = self.eval_operand(operand)?.value;\n+                let valty = ValTy {\n+                    value,\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)?;\n+            }\n+\n+            BinaryOp(bin_op, ref left, ref right) => {\n+                let left = self.eval_operand(left)?;\n+                let right = self.eval_operand(right)?;\n+                if self.intrinsic_overflowing(\n+                    bin_op,\n+                    left,\n+                    right,\n+                    dest,\n+                    dest_ty,\n+                )?\n+                {\n+                    // There was an overflow in an unchecked binop.  Right now, we consider this an error and bail out.\n+                    // The rationale is that the reason rustc emits unchecked binops in release mode (vs. the checked binops\n+                    // it emits in debug mode) is performance, but it doesn't cost us any performance in miri.\n+                    // If, however, the compiler ever starts transforming unchecked intrinsics into unchecked binops,\n+                    // we have to go back to just ignoring the overflow here.\n+                    return err!(OverflowingMath);\n+                }\n+            }\n+\n+            CheckedBinaryOp(bin_op, ref left, ref right) => {\n+                let left = self.eval_operand(left)?;\n+                let right = self.eval_operand(right)?;\n+                self.intrinsic_with_overflow(\n+                    bin_op,\n+                    left,\n+                    right,\n+                    dest,\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            UnaryOp(un_op, ref operand) => {\n+                let val = self.eval_operand_to_primval(operand)?;\n+                let kind = self.ty_to_primval_kind(dest_ty)?;\n+                self.write_primval(\n+                    dest,\n+                    operator::unary_op(un_op, val, kind)?,\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Aggregate(ref kind, ref operands) => {\n+                self.inc_step_counter_and_check_limit(operands.len() as u64)?;\n+\n+                let (dest, active_field_index) = match **kind {\n+                    mir::AggregateKind::Adt(adt_def, variant_index, _, active_field_index) => {\n+                        self.write_discriminant_value(dest_ty, dest, variant_index)?;\n+                        if adt_def.is_enum() {\n+                            (self.place_downcast(dest, variant_index)?, active_field_index)\n+                        } else {\n+                            (dest, active_field_index)\n+                        }\n+                    }\n+                    _ => (dest, None)\n+                };\n+\n+                let layout = self.layout_of(dest_ty)?;\n+                for (i, operand) in operands.iter().enumerate() {\n+                    let value = self.eval_operand(operand)?;\n+                    // Ignore zero-sized fields.\n+                    if !self.layout_of(value.ty)?.is_zst() {\n+                        let field_index = active_field_index.unwrap_or(i);\n+                        let (field_dest, _) = self.place_field(dest, mir::Field::new(field_index), layout)?;\n+                        self.write_value(value, field_dest)?;\n+                    }\n+                }\n+            }\n+\n+            Repeat(ref operand, _) => {\n+                let (elem_ty, length) = match dest_ty.sty {\n+                    ty::TyArray(elem_ty, n) => (elem_ty, n.val.to_const_int().unwrap().to_u64().unwrap()),\n+                    _ => {\n+                        bug!(\n+                            \"tried to assign array-repeat to non-array type {:?}\",\n+                            dest_ty\n+                        )\n+                    }\n+                };\n+                let elem_size = self.layout_of(elem_ty)?.size.bytes();\n+                let value = self.eval_operand(operand)?.value;\n+\n+                let dest = Pointer::from(self.force_allocation(dest)?.to_ptr()?);\n+\n+                // FIXME: speed up repeat filling\n+                for i in 0..length {\n+                    let elem_dest = dest.offset(i * elem_size, &self)?;\n+                    self.write_value_to_ptr(value, elem_dest, elem_ty)?;\n+                }\n+            }\n+\n+            Len(ref place) => {\n+                // FIXME(CTFE): don't allow computing the length of arrays in const eval\n+                let src = self.eval_place(place)?;\n+                let ty = self.place_ty(place);\n+                let (_, len) = src.elem_ty_and_len(ty);\n+                self.write_primval(\n+                    dest,\n+                    PrimVal::from_u128(len as u128),\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Ref(_, _, ref place) => {\n+                let src = self.eval_place(place)?;\n+                // We ignore the alignment of the place here -- special handling for packed structs ends\n+                // at the `&` operator.\n+                let (ptr, extra) = self.force_allocation(src)?.to_ptr_extra_aligned();\n+\n+                let val = match extra {\n+                    PlaceExtra::None => ptr.ptr.to_value(),\n+                    PlaceExtra::Length(len) => ptr.ptr.to_value_with_len(len),\n+                    PlaceExtra::Vtable(vtable) => ptr.ptr.to_value_with_vtable(vtable),\n+                    PlaceExtra::DowncastVariant(..) => {\n+                        bug!(\"attempted to take a reference to an enum downcast place\")\n+                    }\n+                };\n+                let valty = ValTy {\n+                    value: val,\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)?;\n+            }\n+\n+            NullaryOp(mir::NullOp::Box, ty) => {\n+                let ty = self.monomorphize(ty, self.substs());\n+                M::box_alloc(self, ty, dest)?;\n+            }\n+\n+            NullaryOp(mir::NullOp::SizeOf, ty) => {\n+                let ty = self.monomorphize(ty, self.substs());\n+                let layout = self.layout_of(ty)?;\n+                assert!(!layout.is_unsized(),\n+                        \"SizeOf nullary MIR operator called for unsized type\");\n+                self.write_primval(\n+                    dest,\n+                    PrimVal::from_u128(layout.size.bytes() as u128),\n+                    dest_ty,\n+                )?;\n+            }\n+\n+            Cast(kind, ref operand, cast_ty) => {\n+                debug_assert_eq!(self.monomorphize(cast_ty, self.substs()), dest_ty);\n+                use rustc::mir::CastKind::*;\n+                match kind {\n+                    Unsize => {\n+                        let src = self.eval_operand(operand)?;\n+                        self.unsize_into(src.value, src.ty, dest, dest_ty)?;\n+                    }\n+\n+                    Misc => {\n+                        let src = self.eval_operand(operand)?;\n+                        if self.type_is_fat_ptr(src.ty) {\n+                            match (src.value, self.type_is_fat_ptr(dest_ty)) {\n+                                (Value::ByRef { .. }, _) |\n+                                (Value::ByValPair(..), true) => {\n+                                    let valty = ValTy {\n+                                        value: src.value,\n+                                        ty: dest_ty,\n+                                    };\n+                                    self.write_value(valty, dest)?;\n+                                }\n+                                (Value::ByValPair(data, _), false) => {\n+                                    let valty = ValTy {\n+                                        value: Value::ByVal(data),\n+                                        ty: dest_ty,\n+                                    };\n+                                    self.write_value(valty, dest)?;\n+                                }\n+                                (Value::ByVal(_), _) => bug!(\"expected fat ptr\"),\n+                            }\n+                        } else {\n+                            let src_val = self.value_to_primval(src)?;\n+                            let dest_val = self.cast_primval(src_val, src.ty, dest_ty)?;\n+                            let valty = ValTy {\n+                                value: Value::ByVal(dest_val),\n+                                ty: dest_ty,\n+                            };\n+                            self.write_value(valty, dest)?;\n+                        }\n+                    }\n+\n+                    ReifyFnPointer => {\n+                        match self.eval_operand(operand)?.ty.sty {\n+                            ty::TyFnDef(def_id, substs) => {\n+                                let instance = self.resolve(def_id, substs)?;\n+                                let fn_ptr = self.memory.create_fn_alloc(instance);\n+                                let valty = ValTy {\n+                                    value: Value::ByVal(PrimVal::Ptr(fn_ptr)),\n+                                    ty: dest_ty,\n+                                };\n+                                self.write_value(valty, dest)?;\n+                            }\n+                            ref other => bug!(\"reify fn pointer on {:?}\", other),\n+                        }\n+                    }\n+\n+                    UnsafeFnPointer => {\n+                        match dest_ty.sty {\n+                            ty::TyFnPtr(_) => {\n+                                let mut src = self.eval_operand(operand)?;\n+                                src.ty = dest_ty;\n+                                self.write_value(src, dest)?;\n+                            }\n+                            ref other => bug!(\"fn to unsafe fn cast on {:?}\", other),\n+                        }\n+                    }\n+\n+                    ClosureFnPointer => {\n+                        match self.eval_operand(operand)?.ty.sty {\n+                            ty::TyClosure(def_id, substs) => {\n+                                let substs = self.tcx.trans_apply_param_substs(self.substs(), &substs);\n+                                let instance = ty::Instance::resolve_closure(\n+                                    self.tcx,\n+                                    def_id,\n+                                    substs,\n+                                    ty::ClosureKind::FnOnce,\n+                                );\n+                                let fn_ptr = self.memory.create_fn_alloc(instance);\n+                                let valty = ValTy {\n+                                    value: Value::ByVal(PrimVal::Ptr(fn_ptr)),\n+                                    ty: dest_ty,\n+                                };\n+                                self.write_value(valty, dest)?;\n+                            }\n+                            ref other => bug!(\"closure fn pointer on {:?}\", other),\n+                        }\n+                    }\n+                }\n+            }\n+\n+            Discriminant(ref place) => {\n+                let ty = self.place_ty(place);\n+                let place = self.eval_place(place)?;\n+                let discr_val = self.read_discriminant_value(place, ty)?;\n+                if let ty::TyAdt(adt_def, _) = ty.sty {\n+                    trace!(\"Read discriminant {}, valid discriminants {:?}\", discr_val, adt_def.discriminants(self.tcx).collect::<Vec<_>>());\n+                    if adt_def.discriminants(self.tcx).all(|v| {\n+                        discr_val != v.to_u128_unchecked()\n+                    })\n+                    {\n+                        return err!(InvalidDiscriminant);\n+                    }\n+                    self.write_primval(dest, PrimVal::Bytes(discr_val), dest_ty)?;\n+                } else {\n+                    bug!(\"rustc only generates Rvalue::Discriminant for enums\");\n+                }\n+            }\n+        }\n+\n+        if log_enabled!(::log::LogLevel::Trace) {\n+            self.dump_local(dest);\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub(super) fn type_is_fat_ptr(&self, ty: Ty<'tcx>) -> bool {\n+        match ty.sty {\n+            ty::TyRawPtr(ref tam) |\n+            ty::TyRef(_, ref tam) => !self.type_is_sized(tam.ty),\n+            ty::TyAdt(def, _) if def.is_box() => !self.type_is_sized(ty.boxed_ty()),\n+            _ => false,\n+        }\n+    }\n+\n+    pub(super) fn eval_operand_to_primval(\n+        &mut self,\n+        op: &mir::Operand<'tcx>,\n+    ) -> EvalResult<'tcx, PrimVal> {\n+        let valty = self.eval_operand(op)?;\n+        self.value_to_primval(valty)\n+    }\n+\n+    pub(crate) fn operands_to_args(\n+        &mut self,\n+        ops: &[mir::Operand<'tcx>],\n+    ) -> EvalResult<'tcx, Vec<ValTy<'tcx>>> {\n+        ops.into_iter()\n+            .map(|op| self.eval_operand(op))\n+            .collect()\n+    }\n+\n+    pub fn eval_operand(&mut self, op: &mir::Operand<'tcx>) -> EvalResult<'tcx, ValTy<'tcx>> {\n+        use rustc::mir::Operand::*;\n+        let ty = self.monomorphize(op.ty(self.mir(), self.tcx), self.substs());\n+        match *op {\n+            // FIXME: do some more logic on `move` to invalidate the old location\n+            Copy(ref place) |\n+            Move(ref place) => {\n+                Ok(ValTy {\n+                    value: self.eval_and_read_place(place)?,\n+                    ty\n+                })\n+            },\n+\n+            Constant(ref constant) => {\n+                use rustc::mir::Literal;\n+                let mir::Constant { ref literal, .. } = **constant;\n+                let value = match *literal {\n+                    Literal::Value { ref value } => self.const_to_value(&value.val)?,\n+\n+                    Literal::Promoted { index } => {\n+                        let cid = GlobalId {\n+                            instance: self.frame().instance,\n+                            promoted: Some(index),\n+                        };\n+                        Value::ByRef(self.tcx.interpret_interner.borrow().get_cached(cid).expect(\"promoted not cached\"))\n+                    }\n+                };\n+\n+                Ok(ValTy {\n+                    value,\n+                    ty,\n+                })\n+            }\n+        }\n+    }\n+\n+    pub fn read_discriminant_value(\n+        &mut self,\n+        place: Place,\n+        ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, u128> {\n+        let layout = self.layout_of(ty)?;\n+        //trace!(\"read_discriminant_value {:#?}\", layout);\n+\n+        match layout.variants {\n+            layout::Variants::Single { index } => {\n+                return Ok(index as u128);\n+            }\n+            layout::Variants::Tagged { .. } |\n+            layout::Variants::NicheFilling { .. } => {},\n+        }\n+\n+        let (discr_place, discr) = self.place_field(place, mir::Field::new(0), layout)?;\n+        let raw_discr = self.value_to_primval(ValTy {\n+            value: self.read_place(discr_place)?,\n+            ty: discr.ty\n+        })?;\n+        let discr_val = match layout.variants {\n+            layout::Variants::Single { .. } => bug!(),\n+            layout::Variants::Tagged { .. } => raw_discr.to_bytes()?,\n+            layout::Variants::NicheFilling {\n+                dataful_variant,\n+                ref niche_variants,\n+                niche_start,\n+                ..\n+            } => {\n+                let variants_start = niche_variants.start as u128;\n+                let variants_end = niche_variants.end as u128;\n+                match raw_discr {\n+                    PrimVal::Ptr(_) => {\n+                        assert!(niche_start == 0);\n+                        assert!(variants_start == variants_end);\n+                        dataful_variant as u128\n+                    },\n+                    PrimVal::Bytes(raw_discr) => {\n+                        let discr = raw_discr.wrapping_sub(niche_start)\n+                            .wrapping_add(variants_start);\n+                        if variants_start <= discr && discr <= variants_end {\n+                            discr\n+                        } else {\n+                            dataful_variant as u128\n+                        }\n+                    },\n+                    PrimVal::Undef => return err!(ReadUndefBytes),\n+                }\n+            }\n+        };\n+\n+        Ok(discr_val)\n+    }\n+\n+\n+    pub(crate) fn write_discriminant_value(\n+        &mut self,\n+        dest_ty: Ty<'tcx>,\n+        dest: Place,\n+        variant_index: usize,\n+    ) -> EvalResult<'tcx> {\n+        let layout = self.layout_of(dest_ty)?;\n+\n+        match layout.variants {\n+            layout::Variants::Single { index } => {\n+                if index != variant_index {\n+                    // If the layout of an enum is `Single`, all\n+                    // other variants are necessarily uninhabited.\n+                    assert_eq!(layout.for_variant(&self, variant_index).abi,\n+                               layout::Abi::Uninhabited);\n+                }\n+            }\n+            layout::Variants::Tagged { .. } => {\n+                let discr_val = dest_ty.ty_adt_def().unwrap()\n+                    .discriminant_for_variant(self.tcx, variant_index)\n+                    .to_u128_unchecked();\n+\n+                let (discr_dest, discr) = self.place_field(dest, mir::Field::new(0), layout)?;\n+                self.write_primval(discr_dest, PrimVal::Bytes(discr_val), discr.ty)?;\n+            }\n+            layout::Variants::NicheFilling {\n+                dataful_variant,\n+                ref niche_variants,\n+                niche_start,\n+                ..\n+            } => {\n+                if variant_index != dataful_variant {\n+                    let (niche_dest, niche) =\n+                        self.place_field(dest, mir::Field::new(0), layout)?;\n+                    let niche_value = ((variant_index - niche_variants.start) as u128)\n+                        .wrapping_add(niche_start);\n+                    self.write_primval(niche_dest, PrimVal::Bytes(niche_value), niche.ty)?;\n+                }\n+            }\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub fn read_global_as_value(&self, gid: GlobalId) -> Value {\n+        Value::ByRef(self.tcx.interpret_interner.borrow().get_cached(gid).expect(\"global not cached\"))\n+    }\n+\n+    fn copy(&mut self, src: Pointer, dest: Pointer, ty: Ty<'tcx>) -> EvalResult<'tcx> {\n+        let layout = self.layout_of(ty)?;\n+        assert!(!layout.is_unsized(), \"cannot copy from an unsized type\");\n+        let size = layout.size.bytes();\n+        let align = layout.align.abi();\n+        self.memory.copy(src, dest, size, align, false)?;\n+        Ok(())\n+    }\n+\n+    pub fn force_allocation(&mut self, place: Place) -> EvalResult<'tcx, Place> {\n+        let new_place = match place {\n+            Place::Local { frame, local } => {\n+                // -1 since we don't store the return value\n+                match self.stack[frame].locals[local.index() - 1] {\n+                    None => return err!(DeadLocal),\n+                    Some(Value::ByRef(ptr)) => {\n+                        Place::Ptr {\n+                            ptr,\n+                            extra: PlaceExtra::None,\n+                        }\n+                    }\n+                    Some(val) => {\n+                        let ty = self.stack[frame].mir.local_decls[local].ty;\n+                        let ty = self.monomorphize(ty, self.stack[frame].instance.substs);\n+                        let ptr = self.alloc_ptr(ty)?;\n+                        self.stack[frame].locals[local.index() - 1] =\n+                            Some(Value::by_ref(ptr.into())); // it stays live\n+                        self.write_value_to_ptr(val, ptr.into(), ty)?;\n+                        Place::from_ptr(ptr)\n+                    }\n+                }\n+            }\n+            Place::Ptr { .. } => place,\n+        };\n+        Ok(new_place)\n+    }\n+\n+    /// ensures this Value is not a ByRef\n+    pub fn follow_by_ref_value(\n+        &self,\n+        value: Value,\n+        ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, Value> {\n+        match value {\n+            Value::ByRef(PtrAndAlign { ptr, aligned }) => {\n+                self.read_maybe_aligned(aligned, |ectx| ectx.read_value(ptr, ty))\n+            }\n+            other => Ok(other),\n+        }\n+    }\n+\n+    pub fn value_to_primval(\n+        &self,\n+        ValTy { value, ty } : ValTy<'tcx>,\n+    ) -> EvalResult<'tcx, PrimVal> {\n+        match self.follow_by_ref_value(value, ty)? {\n+            Value::ByRef { .. } => bug!(\"follow_by_ref_value can't result in `ByRef`\"),\n+\n+            Value::ByVal(primval) => {\n+                // TODO: Do we really want insta-UB here?\n+                self.ensure_valid_value(primval, ty)?;\n+                Ok(primval)\n+            }\n+\n+            Value::ByValPair(..) => bug!(\"value_to_primval can't work with fat pointers\"),\n+        }\n+    }\n+\n+    pub fn write_ptr(&mut self, dest: Place, val: Pointer, dest_ty: Ty<'tcx>) -> EvalResult<'tcx> {\n+        let valty = ValTy {\n+            value: val.to_value(),\n+            ty: dest_ty,\n+        };\n+        self.write_value(valty, dest)\n+    }\n+\n+    pub fn write_primval(\n+        &mut self,\n+        dest: Place,\n+        val: PrimVal,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let valty = ValTy {\n+            value: Value::ByVal(val),\n+            ty: dest_ty,\n+        };\n+        self.write_value(valty, dest)\n+    }\n+\n+    pub fn write_value(\n+        &mut self,\n+        ValTy { value: src_val, ty: dest_ty } : ValTy<'tcx>,\n+        dest: Place,\n+    ) -> EvalResult<'tcx> {\n+        //trace!(\"Writing {:?} to {:?} at type {:?}\", src_val, dest, dest_ty);\n+        // Note that it is really important that the type here is the right one, and matches the type things are read at.\n+        // In case `src_val` is a `ByValPair`, we don't do any magic here to handle padding properly, which is only\n+        // correct if we never look at this data with the wrong type.\n+\n+        match dest {\n+            Place::Ptr {\n+                ptr: PtrAndAlign { ptr, aligned },\n+                extra,\n+            } => {\n+                assert_eq!(extra, PlaceExtra::None);\n+                self.write_maybe_aligned_mut(\n+                    aligned,\n+                    |ectx| ectx.write_value_to_ptr(src_val, ptr, dest_ty),\n+                )\n+            }\n+\n+            Place::Local { frame, local } => {\n+                let dest = self.stack[frame].get_local(local)?;\n+                self.write_value_possibly_by_val(\n+                    src_val,\n+                    |this, val| this.stack[frame].set_local(local, val),\n+                    dest,\n+                    dest_ty,\n+                )\n+            }\n+        }\n+    }\n+\n+    // The cases here can be a bit subtle. Read carefully!\n+    fn write_value_possibly_by_val<F: FnOnce(&mut Self, Value) -> EvalResult<'tcx>>(\n+        &mut self,\n+        src_val: Value,\n+        write_dest: F,\n+        old_dest_val: Value,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        if let Value::ByRef(PtrAndAlign {\n+                                ptr: dest_ptr,\n+                                aligned,\n+                            }) = old_dest_val\n+        {\n+            // If the value is already `ByRef` (that is, backed by an `Allocation`),\n+            // then we must write the new value into this allocation, because there may be\n+            // other pointers into the allocation. These other pointers are logically\n+            // pointers into the local variable, and must be able to observe the change.\n+            //\n+            // Thus, it would be an error to replace the `ByRef` with a `ByVal`, unless we\n+            // knew for certain that there were no outstanding pointers to this allocation.\n+            self.write_maybe_aligned_mut(aligned, |ectx| {\n+                ectx.write_value_to_ptr(src_val, dest_ptr, dest_ty)\n+            })?;\n+\n+        } else if let Value::ByRef(PtrAndAlign {\n+                                       ptr: src_ptr,\n+                                       aligned,\n+                                   }) = src_val\n+        {\n+            // If the value is not `ByRef`, then we know there are no pointers to it\n+            // and we can simply overwrite the `Value` in the locals array directly.\n+            //\n+            // In this specific case, where the source value is `ByRef`, we must duplicate\n+            // the allocation, because this is a by-value operation. It would be incorrect\n+            // if they referred to the same allocation, since then a change to one would\n+            // implicitly change the other.\n+            //\n+            // It is a valid optimization to attempt reading a primitive value out of the\n+            // source and write that into the destination without making an allocation, so\n+            // we do so here.\n+            self.read_maybe_aligned_mut(aligned, |ectx| {\n+                if let Ok(Some(src_val)) = ectx.try_read_value(src_ptr, dest_ty) {\n+                    write_dest(ectx, src_val)?;\n+                } else {\n+                    let dest_ptr = ectx.alloc_ptr(dest_ty)?.into();\n+                    ectx.copy(src_ptr, dest_ptr, dest_ty)?;\n+                    write_dest(ectx, Value::by_ref(dest_ptr))?;\n+                }\n+                Ok(())\n+            })?;\n+\n+        } else {\n+            // Finally, we have the simple case where neither source nor destination are\n+            // `ByRef`. We may simply copy the source value over the the destintion.\n+            write_dest(self, src_val)?;\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn write_value_to_ptr(\n+        &mut self,\n+        value: Value,\n+        dest: Pointer,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\"write_value_to_ptr: {:#?}\", value);\n+        match value {\n+            Value::ByRef(PtrAndAlign { ptr, aligned }) => {\n+                self.read_maybe_aligned_mut(aligned, |ectx| ectx.copy(ptr, dest, dest_ty))\n+            }\n+            Value::ByVal(primval) => {\n+                let layout = self.layout_of(dest_ty)?;\n+                if layout.is_zst() {\n+                    assert!(primval.is_undef());\n+                    Ok(())\n+                } else {\n+                    // TODO: Do we need signedness?\n+                    self.memory.write_maybe_aligned_mut(!layout.is_packed(), |mem| {\n+                        mem.write_primval(dest.to_ptr()?, primval, layout.size.bytes(), false)\n+                    })\n+                }\n+            }\n+            Value::ByValPair(a, b) => {\n+                let ptr = dest.to_ptr()?;\n+                let mut layout = self.layout_of(dest_ty)?;\n+                trace!(\"write_value_to_ptr valpair: {:#?}\", layout);\n+                let mut packed = layout.is_packed();\n+                'outer: loop {\n+                    for i in 0..layout.fields.count() {\n+                        let field = layout.field(&self, i)?;\n+                        if layout.fields.offset(i).bytes() == 0 && layout.size == field.size {\n+                            layout = field;\n+                            packed |= layout.is_packed();\n+                            continue 'outer;\n+                        }\n+                    }\n+                    break;\n+                }\n+                trace!(\"write_value_to_ptr valpair: {:#?}\", layout);\n+                assert_eq!(layout.fields.count(), 2);\n+                let field_0 = layout.field(&self, 0)?;\n+                let field_1 = layout.field(&self, 1)?;\n+                trace!(\"write_value_to_ptr field 0: {:#?}\", field_0);\n+                trace!(\"write_value_to_ptr field 1: {:#?}\", field_1);\n+                assert_eq!(\n+                    field_0.is_packed(),\n+                    field_1.is_packed(),\n+                    \"the two fields must agree on being packed\"\n+                );\n+                packed |= field_0.is_packed();\n+                let field_0_ptr = ptr.offset(layout.fields.offset(0).bytes(), &self)?.into();\n+                let field_1_ptr = ptr.offset(layout.fields.offset(1).bytes(), &self)?.into();\n+                // TODO: What about signedess?\n+                self.memory.write_maybe_aligned_mut(!packed, |mem| {\n+                    mem.write_primval(field_0_ptr, a, field_0.size.bytes(), false)?;\n+                    mem.write_primval(field_1_ptr, b, field_1.size.bytes(), false)\n+                })?;\n+                Ok(())\n+            }\n+        }\n+    }\n+\n+    pub fn ty_to_primval_kind(&self, ty: Ty<'tcx>) -> EvalResult<'tcx, PrimValKind> {\n+        use syntax::ast::FloatTy;\n+\n+        let kind = match ty.sty {\n+            ty::TyBool => PrimValKind::Bool,\n+            ty::TyChar => PrimValKind::Char,\n+\n+            ty::TyInt(int_ty) => {\n+                use syntax::ast::IntTy::*;\n+                let size = match int_ty {\n+                    I8 => 1,\n+                    I16 => 2,\n+                    I32 => 4,\n+                    I64 => 8,\n+                    I128 => 16,\n+                    Is => self.memory.pointer_size(),\n+                };\n+                PrimValKind::from_int_size(size)\n+            }\n+\n+            ty::TyUint(uint_ty) => {\n+                use syntax::ast::UintTy::*;\n+                let size = match uint_ty {\n+                    U8 => 1,\n+                    U16 => 2,\n+                    U32 => 4,\n+                    U64 => 8,\n+                    U128 => 16,\n+                    Us => self.memory.pointer_size(),\n+                };\n+                PrimValKind::from_uint_size(size)\n+            }\n+\n+            ty::TyFloat(FloatTy::F32) => PrimValKind::F32,\n+            ty::TyFloat(FloatTy::F64) => PrimValKind::F64,\n+\n+            ty::TyFnPtr(_) => PrimValKind::FnPtr,\n+\n+            ty::TyRef(_, ref tam) |\n+            ty::TyRawPtr(ref tam) if self.type_is_sized(tam.ty) => PrimValKind::Ptr,\n+\n+            ty::TyAdt(def, _) if def.is_box() => PrimValKind::Ptr,\n+\n+            ty::TyAdt(..) => {\n+                match self.layout_of(ty)?.abi {\n+                    layout::Abi::Scalar(ref scalar) => {\n+                        use rustc::ty::layout::Primitive::*;\n+                        match scalar.value {\n+                            Int(i, false) => PrimValKind::from_uint_size(i.size().bytes()),\n+                            Int(i, true) => PrimValKind::from_int_size(i.size().bytes()),\n+                            F32 => PrimValKind::F32,\n+                            F64 => PrimValKind::F64,\n+                            Pointer => PrimValKind::Ptr,\n+                        }\n+                    }\n+\n+                    _ => return err!(TypeNotPrimitive(ty)),\n+                }\n+            }\n+\n+            _ => return err!(TypeNotPrimitive(ty)),\n+        };\n+\n+        Ok(kind)\n+    }\n+\n+    fn ensure_valid_value(&self, val: PrimVal, ty: Ty<'tcx>) -> EvalResult<'tcx> {\n+        match ty.sty {\n+            ty::TyBool if val.to_bytes()? > 1 => err!(InvalidBool),\n+\n+            ty::TyChar if ::std::char::from_u32(val.to_bytes()? as u32).is_none() => {\n+                err!(InvalidChar(val.to_bytes()? as u32 as u128))\n+            }\n+\n+            _ => Ok(()),\n+        }\n+    }\n+\n+    pub fn read_value(&self, ptr: Pointer, ty: Ty<'tcx>) -> EvalResult<'tcx, Value> {\n+        if let Some(val) = self.try_read_value(ptr, ty)? {\n+            Ok(val)\n+        } else {\n+            bug!(\"primitive read failed for type: {:?}\", ty);\n+        }\n+    }\n+\n+    pub(crate) fn read_ptr(\n+        &self,\n+        ptr: MemoryPointer,\n+        pointee_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, Value> {\n+        let ptr_size = self.memory.pointer_size();\n+        let p : Pointer = self.memory.read_ptr_sized_unsigned(ptr)?.into();\n+        if self.type_is_sized(pointee_ty) {\n+            Ok(p.to_value())\n+        } else {\n+            trace!(\"reading fat pointer extra of type {}\", pointee_ty);\n+            let extra = ptr.offset(ptr_size, self)?;\n+            match self.tcx.struct_tail(pointee_ty).sty {\n+                ty::TyDynamic(..) => Ok(p.to_value_with_vtable(\n+                    self.memory.read_ptr_sized_unsigned(extra)?.to_ptr()?,\n+                )),\n+                ty::TySlice(..) | ty::TyStr => Ok(\n+                    p.to_value_with_len(self.memory.read_ptr_sized_unsigned(extra)?.to_bytes()? as u64),\n+                ),\n+                _ => bug!(\"unsized primval ptr read from {:?}\", pointee_ty),\n+            }\n+        }\n+    }\n+\n+    pub fn try_read_value(&self, ptr: Pointer, ty: Ty<'tcx>) -> EvalResult<'tcx, Option<Value>> {\n+        use syntax::ast::FloatTy;\n+\n+        let ptr = ptr.to_ptr()?;\n+        let val = match ty.sty {\n+            ty::TyBool => {\n+                let val = self.memory.read_primval(ptr, 1, false)?;\n+                let val = match val {\n+                    PrimVal::Bytes(0) => false,\n+                    PrimVal::Bytes(1) => true,\n+                    // TODO: This seems a little overeager, should reading at bool type already be insta-UB?\n+                    _ => return err!(InvalidBool),\n+                };\n+                PrimVal::from_bool(val)\n+            }\n+            ty::TyChar => {\n+                let c = self.memory.read_primval(ptr, 4, false)?.to_bytes()? as u32;\n+                match ::std::char::from_u32(c) {\n+                    Some(ch) => PrimVal::from_char(ch),\n+                    None => return err!(InvalidChar(c as u128)),\n+                }\n+            }\n+\n+            ty::TyInt(int_ty) => {\n+                use syntax::ast::IntTy::*;\n+                let size = match int_ty {\n+                    I8 => 1,\n+                    I16 => 2,\n+                    I32 => 4,\n+                    I64 => 8,\n+                    I128 => 16,\n+                    Is => self.memory.pointer_size(),\n+                };\n+                self.memory.read_primval(ptr, size, true)?\n+            }\n+\n+            ty::TyUint(uint_ty) => {\n+                use syntax::ast::UintTy::*;\n+                let size = match uint_ty {\n+                    U8 => 1,\n+                    U16 => 2,\n+                    U32 => 4,\n+                    U64 => 8,\n+                    U128 => 16,\n+                    Us => self.memory.pointer_size(),\n+                };\n+                self.memory.read_primval(ptr, size, false)?\n+            }\n+\n+            ty::TyFloat(FloatTy::F32) => PrimVal::Bytes(self.memory.read_primval(ptr, 4, false)?.to_bytes()?),\n+            ty::TyFloat(FloatTy::F64) => PrimVal::Bytes(self.memory.read_primval(ptr, 8, false)?.to_bytes()?),\n+\n+            ty::TyFnPtr(_) => self.memory.read_ptr_sized_unsigned(ptr)?,\n+            ty::TyRef(_, ref tam) |\n+            ty::TyRawPtr(ref tam) => return self.read_ptr(ptr, tam.ty).map(Some),\n+\n+            ty::TyAdt(def, _) => {\n+                if def.is_box() {\n+                    return self.read_ptr(ptr, ty.boxed_ty()).map(Some);\n+                }\n+\n+                if let layout::Abi::Scalar(ref scalar) = self.layout_of(ty)?.abi {\n+                    let mut signed = false;\n+                    if let layout::Int(_, s) = scalar.value {\n+                        signed = s;\n+                    }\n+                    let size = scalar.value.size(self).bytes();\n+                    self.memory.read_primval(ptr, size, signed)?\n+                } else {\n+                    return Ok(None);\n+                }\n+            }\n+\n+            _ => return Ok(None),\n+        };\n+\n+        Ok(Some(Value::ByVal(val)))\n+    }\n+\n+    pub fn frame(&self) -> &Frame<'tcx> {\n+        self.stack.last().expect(\"no call frames exist\")\n+    }\n+\n+    pub fn frame_mut(&mut self) -> &mut Frame<'tcx> {\n+        self.stack.last_mut().expect(\"no call frames exist\")\n+    }\n+\n+    pub(super) fn mir(&self) -> &'tcx mir::Mir<'tcx> {\n+        self.frame().mir\n+    }\n+\n+    pub fn substs(&self) -> &'tcx Substs<'tcx> {\n+        if let Some(frame) = self.stack.last() {\n+            frame.instance.substs\n+        } else {\n+            Substs::empty()\n+        }\n+    }\n+\n+    fn unsize_into_ptr(\n+        &mut self,\n+        src: Value,\n+        src_ty: Ty<'tcx>,\n+        dest: Place,\n+        dest_ty: Ty<'tcx>,\n+        sty: Ty<'tcx>,\n+        dty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        // A<Struct> -> A<Trait> conversion\n+        let (src_pointee_ty, dest_pointee_ty) = self.tcx.struct_lockstep_tails(sty, dty);\n+\n+        match (&src_pointee_ty.sty, &dest_pointee_ty.sty) {\n+            (&ty::TyArray(_, length), &ty::TySlice(_)) => {\n+                let ptr = self.into_ptr(src)?;\n+                // u64 cast is from usize to u64, which is always good\n+                let valty = ValTy {\n+                    value: ptr.to_value_with_len(length.val.to_const_int().unwrap().to_u64().unwrap() ),\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)\n+            }\n+            (&ty::TyDynamic(..), &ty::TyDynamic(..)) => {\n+                // For now, upcasts are limited to changes in marker\n+                // traits, and hence never actually require an actual\n+                // change to the vtable.\n+                let valty = ValTy {\n+                    value: src,\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)\n+            }\n+            (_, &ty::TyDynamic(ref data, _)) => {\n+                let trait_ref = data.principal().unwrap().with_self_ty(\n+                    self.tcx,\n+                    src_pointee_ty,\n+                );\n+                let trait_ref = self.tcx.erase_regions(&trait_ref);\n+                let vtable = self.get_vtable(src_pointee_ty, trait_ref)?;\n+                let ptr = self.into_ptr(src)?;\n+                let valty = ValTy {\n+                    value: ptr.to_value_with_vtable(vtable),\n+                    ty: dest_ty,\n+                };\n+                self.write_value(valty, dest)\n+            }\n+\n+            _ => bug!(\"invalid unsizing {:?} -> {:?}\", src_ty, dest_ty),\n+        }\n+    }\n+\n+    fn unsize_into(\n+        &mut self,\n+        src: Value,\n+        src_ty: Ty<'tcx>,\n+        dst: Place,\n+        dst_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let src_layout = self.layout_of(src_ty)?;\n+        let dst_layout = self.layout_of(dst_ty)?;\n+        match (&src_ty.sty, &dst_ty.sty) {\n+            (&ty::TyRef(_, ref s), &ty::TyRef(_, ref d)) |\n+            (&ty::TyRef(_, ref s), &ty::TyRawPtr(ref d)) |\n+            (&ty::TyRawPtr(ref s), &ty::TyRawPtr(ref d)) => {\n+                self.unsize_into_ptr(src, src_ty, dst, dst_ty, s.ty, d.ty)\n+            }\n+            (&ty::TyAdt(def_a, _), &ty::TyAdt(def_b, _)) => {\n+                if def_a.is_box() || def_b.is_box() {\n+                    if !def_a.is_box() || !def_b.is_box() {\n+                        panic!(\"invalid unsizing between {:?} -> {:?}\", src_ty, dst_ty);\n+                    }\n+                    return self.unsize_into_ptr(\n+                        src,\n+                        src_ty,\n+                        dst,\n+                        dst_ty,\n+                        src_ty.boxed_ty(),\n+                        dst_ty.boxed_ty(),\n+                    );\n+                }\n+                if self.ty_to_primval_kind(src_ty).is_ok() {\n+                    // TODO: We ignore the packed flag here\n+                    let sty = src_layout.field(&self, 0)?.ty;\n+                    let dty = dst_layout.field(&self, 0)?.ty;\n+                    return self.unsize_into(src, sty, dst, dty);\n+                }\n+                // unsizing of generic struct with pointer fields\n+                // Example: `Arc<T>` -> `Arc<Trait>`\n+                // here we need to increase the size of every &T thin ptr field to a fat ptr\n+\n+                assert_eq!(def_a, def_b);\n+\n+                let src_ptr = match src {\n+                    Value::ByRef(PtrAndAlign { ptr, aligned: true }) => ptr,\n+                    // the entire struct is just a pointer\n+                    Value::ByVal(_) => {\n+                        for i in 0..src_layout.fields.count() {\n+                            let src_field = src_layout.field(&self, i)?;\n+                            let dst_field = dst_layout.field(&self, i)?;\n+                            if dst_layout.is_zst() {\n+                                continue;\n+                            }\n+                            assert_eq!(src_layout.fields.offset(i).bytes(), 0);\n+                            assert_eq!(dst_layout.fields.offset(i).bytes(), 0);\n+                            assert_eq!(src_field.size, src_layout.size);\n+                            assert_eq!(dst_field.size, dst_layout.size);\n+                            return self.unsize_into(\n+                                src,\n+                                src_field.ty,\n+                                dst,\n+                                dst_field.ty,\n+                            );\n+                        }\n+                        bug!(\"by val unsize into where the value doesn't cover the entire type\")\n+                    }\n+                    // TODO: Is it possible for unaligned pointers to occur here?\n+                    _ => bug!(\"expected aligned pointer, got {:?}\", src),\n+                };\n+\n+                // FIXME(solson)\n+                let dst = self.force_allocation(dst)?.to_ptr()?;\n+                for i in 0..src_layout.fields.count() {\n+                    let src_field = src_layout.field(&self, i)?;\n+                    let dst_field = dst_layout.field(&self, i)?;\n+                    if dst_field.is_zst() {\n+                        continue;\n+                    }\n+                    let src_field_offset = src_layout.fields.offset(i).bytes();\n+                    let dst_field_offset = dst_layout.fields.offset(i).bytes();\n+                    let src_f_ptr = src_ptr.offset(src_field_offset, &self)?;\n+                    let dst_f_ptr = dst.offset(dst_field_offset, &self)?;\n+                    if src_field.ty == dst_field.ty {\n+                        self.copy(src_f_ptr, dst_f_ptr.into(), src_field.ty)?;\n+                    } else {\n+                        self.unsize_into(\n+                            Value::by_ref(src_f_ptr),\n+                            src_field.ty,\n+                            Place::from_ptr(dst_f_ptr),\n+                            dst_field.ty,\n+                        )?;\n+                    }\n+                }\n+                Ok(())\n+            }\n+            _ => {\n+                bug!(\n+                    \"unsize_into: invalid conversion: {:?} -> {:?}\",\n+                    src_ty,\n+                    dst_ty\n+                )\n+            }\n+        }\n+    }\n+\n+    pub fn dump_local(&self, place: Place) {\n+        // Debug output\n+        match place {\n+            Place::Local { frame, local } => {\n+                let mut allocs = Vec::new();\n+                let mut msg = format!(\"{:?}\", local);\n+                if frame != self.cur_frame() {\n+                    write!(msg, \" ({} frames up)\", self.cur_frame() - frame).unwrap();\n+                }\n+                write!(msg, \":\").unwrap();\n+\n+                match self.stack[frame].get_local(local) {\n+                    Err(EvalError { kind: EvalErrorKind::DeadLocal, .. }) => {\n+                        write!(msg, \" is dead\").unwrap();\n+                    }\n+                    Err(err) => {\n+                        panic!(\"Failed to access local: {:?}\", err);\n+                    }\n+                    Ok(Value::ByRef(PtrAndAlign { ptr, aligned })) => {\n+                        match ptr.into_inner_primval() {\n+                            PrimVal::Ptr(ptr) => {\n+                                write!(msg, \" by {}ref:\", if aligned { \"\" } else { \"unaligned \" })\n+                                    .unwrap();\n+                                allocs.push(ptr.alloc_id);\n+                            }\n+                            ptr => write!(msg, \" integral by ref: {:?}\", ptr).unwrap(),\n+                        }\n+                    }\n+                    Ok(Value::ByVal(val)) => {\n+                        write!(msg, \" {:?}\", val).unwrap();\n+                        if let PrimVal::Ptr(ptr) = val {\n+                            allocs.push(ptr.alloc_id);\n+                        }\n+                    }\n+                    Ok(Value::ByValPair(val1, val2)) => {\n+                        write!(msg, \" ({:?}, {:?})\", val1, val2).unwrap();\n+                        if let PrimVal::Ptr(ptr) = val1 {\n+                            allocs.push(ptr.alloc_id);\n+                        }\n+                        if let PrimVal::Ptr(ptr) = val2 {\n+                            allocs.push(ptr.alloc_id);\n+                        }\n+                    }\n+                }\n+\n+                trace!(\"{}\", msg);\n+                self.memory.dump_allocs(allocs);\n+            }\n+            Place::Ptr { ptr: PtrAndAlign { ptr, aligned }, .. } => {\n+                match ptr.into_inner_primval() {\n+                    PrimVal::Ptr(ptr) => {\n+                        trace!(\"by {}ref:\", if aligned { \"\" } else { \"unaligned \" });\n+                        self.memory.dump_alloc(ptr.alloc_id);\n+                    }\n+                    ptr => trace!(\" integral by ref: {:?}\", ptr),\n+                }\n+            }\n+        }\n+    }\n+\n+    /// Convenience function to ensure correct usage of locals\n+    pub fn modify_local<F>(&mut self, frame: usize, local: mir::Local, f: F) -> EvalResult<'tcx>\n+    where\n+        F: FnOnce(&mut Self, Value) -> EvalResult<'tcx, Value>,\n+    {\n+        let val = self.stack[frame].get_local(local)?;\n+        let new_val = f(self, val)?;\n+        self.stack[frame].set_local(local, new_val)?;\n+        // FIXME(solson): Run this when setting to Undef? (See previous version of this code.)\n+        // if let Value::ByRef(ptr) = self.stack[frame].get_local(local) {\n+        //     self.memory.deallocate(ptr)?;\n+        // }\n+        Ok(())\n+    }\n+\n+    pub fn report(&self, e: &mut EvalError) {\n+        if let Some(ref mut backtrace) = e.backtrace {\n+            let mut trace_text = \"\\n\\nAn error occurred in miri:\\n\".to_string();\n+            backtrace.resolve();\n+            write!(trace_text, \"backtrace frames: {}\\n\", backtrace.frames().len()).unwrap();\n+            'frames: for (i, frame) in backtrace.frames().iter().enumerate() {\n+                if frame.symbols().is_empty() {\n+                    write!(trace_text, \"{}: no symbols\\n\", i).unwrap();\n+                }\n+                for symbol in frame.symbols() {\n+                    write!(trace_text, \"{}: \", i).unwrap();\n+                    if let Some(name) = symbol.name() {\n+                        write!(trace_text, \"{}\\n\", name).unwrap();\n+                    } else {\n+                        write!(trace_text, \"<unknown>\\n\").unwrap();\n+                    }\n+                    write!(trace_text, \"\\tat \").unwrap();\n+                    if let Some(file_path) = symbol.filename() {\n+                        write!(trace_text, \"{}\", file_path.display()).unwrap();\n+                    } else {\n+                        write!(trace_text, \"<unknown_file>\").unwrap();\n+                    }\n+                    if let Some(line) = symbol.lineno() {\n+                        write!(trace_text, \":{}\\n\", line).unwrap();\n+                    } else {\n+                        write!(trace_text, \"\\n\").unwrap();\n+                    }\n+                }\n+            }\n+            error!(\"{}\", trace_text);\n+        }\n+        if let Some(frame) = self.stack().last() {\n+            let block = &frame.mir.basic_blocks()[frame.block];\n+            let span = if frame.stmt < block.statements.len() {\n+                block.statements[frame.stmt].source_info.span\n+            } else {\n+                block.terminator().source_info.span\n+            };\n+            let mut err = self.tcx.sess.struct_span_err(span, &e.to_string());\n+            for &Frame { instance, span, .. } in self.stack().iter().rev() {\n+                if self.tcx.def_key(instance.def_id()).disambiguated_data.data ==\n+                    DefPathData::ClosureExpr\n+                {\n+                    err.span_note(span, \"inside call to closure\");\n+                    continue;\n+                }\n+                err.span_note(span, &format!(\"inside call to {}\", instance));\n+            }\n+            err.emit();\n+        } else {\n+            self.tcx.sess.err(&e.to_string());\n+        }\n+    }\n+}\n+\n+impl<'tcx> Frame<'tcx> {\n+    pub fn get_local(&self, local: mir::Local) -> EvalResult<'tcx, Value> {\n+        // Subtract 1 because we don't store a value for the ReturnPointer, the local with index 0.\n+        self.locals[local.index() - 1].ok_or(EvalErrorKind::DeadLocal.into())\n+    }\n+\n+    fn set_local(&mut self, local: mir::Local, value: Value) -> EvalResult<'tcx> {\n+        // Subtract 1 because we don't store a value for the ReturnPointer, the local with index 0.\n+        match self.locals[local.index() - 1] {\n+            None => err!(DeadLocal),\n+            Some(ref mut local) => {\n+                *local = value;\n+                Ok(())\n+            }\n+        }\n+    }\n+\n+    pub fn storage_live(&mut self, local: mir::Local) -> EvalResult<'tcx, Option<Value>> {\n+        trace!(\"{:?} is now live\", local);\n+\n+        let old = self.locals[local.index() - 1];\n+        self.locals[local.index() - 1] = Some(Value::ByVal(PrimVal::Undef)); // StorageLive *always* kills the value that's currently stored\n+        return Ok(old);\n+    }\n+\n+    /// Returns the old value of the local\n+    pub fn storage_dead(&mut self, local: mir::Local) -> EvalResult<'tcx, Option<Value>> {\n+        trace!(\"{:?} is now dead\", local);\n+\n+        let old = self.locals[local.index() - 1];\n+        self.locals[local.index() - 1] = None;\n+        return Ok(old);\n+    }\n+}\n+\n+// TODO(solson): Upstream these methods into rustc::ty::layout.\n+\n+pub fn resolve_drop_in_place<'a, 'tcx>(\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+    ty: Ty<'tcx>,\n+) -> ty::Instance<'tcx> {\n+    let def_id = tcx.require_lang_item(::rustc::middle::lang_items::DropInPlaceFnLangItem);\n+    let substs = tcx.intern_substs(&[Kind::from(ty)]);\n+    ty::Instance::resolve(tcx, ty::ParamEnv::empty(Reveal::All), def_id, substs).unwrap()\n+}"}, {"sha": "47a6bfeb37ba3088f8f45bad6e28cb6c2711b500", "filename": "src/librustc_mir/interpret/machine.rs", "status": "added", "additions": 117, "deletions": 0, "changes": 117, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmachine.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,117 @@\n+//! This module contains everything needed to instantiate an interpreter.\n+//! This separation exists to ensure that no fancy miri features like\n+//! interpreting common C functions leak into CTFE.\n+\n+use rustc::mir::interpret::{EvalResult, PrimVal, MemoryPointer, AccessKind};\n+use super::{EvalContext, Place, ValTy, Memory};\n+\n+use rustc::mir;\n+use rustc::ty::{self, Ty};\n+use syntax::codemap::Span;\n+use syntax::ast::Mutability;\n+\n+/// Methods of this trait signifies a point where CTFE evaluation would fail\n+/// and some use case dependent behaviour can instead be applied\n+pub trait Machine<'tcx>: Sized {\n+    /// Additional data that can be accessed via the Memory\n+    type MemoryData;\n+\n+    /// Additional memory kinds a machine wishes to distinguish from the builtin ones\n+    type MemoryKinds: ::std::fmt::Debug + PartialEq + Copy + Clone;\n+\n+    /// Entry point to all function calls.\n+    ///\n+    /// Returns Ok(true) when the function was handled completely\n+    /// e.g. due to missing mir\n+    ///\n+    /// Returns Ok(false) if a new stack frame was pushed\n+    fn eval_fn_call<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        instance: ty::Instance<'tcx>,\n+        destination: Option<(Place, mir::BasicBlock)>,\n+        args: &[ValTy<'tcx>],\n+        span: Span,\n+        sig: ty::FnSig<'tcx>,\n+    ) -> EvalResult<'tcx, bool>;\n+\n+    /// directly process an intrinsic without pushing a stack frame.\n+    fn call_intrinsic<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        instance: ty::Instance<'tcx>,\n+        args: &[ValTy<'tcx>],\n+        dest: Place,\n+        dest_layout: ty::layout::TyLayout<'tcx>,\n+        target: mir::BasicBlock,\n+    ) -> EvalResult<'tcx>;\n+\n+    /// Called for all binary operations except on float types.\n+    ///\n+    /// Returns `None` if the operation should be handled by the integer\n+    /// op code in order to share more code between machines\n+    ///\n+    /// Returns a (value, overflowed) pair if the operation succeeded\n+    fn try_ptr_op<'a>(\n+        ecx: &EvalContext<'a, 'tcx, Self>,\n+        bin_op: mir::BinOp,\n+        left: PrimVal,\n+        left_ty: Ty<'tcx>,\n+        right: PrimVal,\n+        right_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, Option<(PrimVal, bool)>>;\n+\n+    /// Called when trying to mark machine defined `MemoryKinds` as static\n+    fn mark_static_initialized(m: Self::MemoryKinds) -> EvalResult<'tcx>;\n+\n+    /// Heap allocations via the `box` keyword\n+    ///\n+    /// Returns a pointer to the allocated memory\n+    fn box_alloc<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        ty: Ty<'tcx>,\n+        dest: Place,\n+    ) -> EvalResult<'tcx>;\n+\n+    /// Called when trying to access a global declared with a `linkage` attribute\n+    fn global_item_with_linkage<'a>(\n+        ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        instance: ty::Instance<'tcx>,\n+        mutability: Mutability,\n+    ) -> EvalResult<'tcx>;\n+\n+    fn check_locks<'a>(\n+        _mem: &Memory<'a, 'tcx, Self>,\n+        _ptr: MemoryPointer,\n+        _size: u64,\n+        _access: AccessKind,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+\n+    fn add_lock<'a>(\n+        _mem: &mut Memory<'a, 'tcx, Self>,\n+        _id: u64,\n+    ) {}\n+\n+    fn free_lock<'a>(\n+        _mem: &mut Memory<'a, 'tcx, Self>,\n+        _id: u64,\n+        _len: u64,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+\n+    fn end_region<'a>(\n+        _ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        _reg: Option<::rustc::middle::region::Scope>,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+\n+    fn validation_op<'a>(\n+        _ecx: &mut EvalContext<'a, 'tcx, Self>,\n+        _op: ::rustc::mir::ValidationOp,\n+        _operand: &::rustc::mir::ValidationOperand<'tcx, ::rustc::mir::Place<'tcx>>,\n+    ) -> EvalResult<'tcx> {\n+        Ok(())\n+    }\n+}"}, {"sha": "490ac0e0fb76754222b5cd98e2161a6c5b027ced", "filename": "src/librustc_mir/interpret/memory.rs", "status": "added", "additions": 1141, "deletions": 0, "changes": 1141, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,1141 @@\n+use byteorder::{ReadBytesExt, WriteBytesExt, LittleEndian, BigEndian};\n+use std::collections::{btree_map, BTreeMap, HashMap, HashSet, VecDeque};\n+use std::{ptr, mem, io};\n+use std::cell::Cell;\n+\n+use rustc::ty::{Instance, TyCtxt};\n+use rustc::ty::layout::{self, TargetDataLayout};\n+use syntax::ast::Mutability;\n+\n+use rustc::mir::interpret::{MemoryPointer, AllocId, Allocation, AccessKind, UndefMask, PtrAndAlign, Value, Pointer,\n+                            EvalResult, PrimVal, EvalErrorKind};\n+\n+use super::{EvalContext, Machine};\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Allocations and pointers\n+////////////////////////////////////////////////////////////////////////////////\n+\n+#[derive(Debug, PartialEq, Copy, Clone)]\n+pub enum MemoryKind<T> {\n+    /// Error if deallocated except during a stack pop\n+    Stack,\n+    /// A mutable Static. All the others are interned in the tcx\n+    MutableStatic, // FIXME: move me into the machine, rustc const eval doesn't need them\n+    /// Additional memory kinds a machine wishes to distinguish from the builtin ones\n+    Machine(T),\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Top-level interpreter memory\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub struct Memory<'a, 'tcx: 'a, M: Machine<'tcx>> {\n+    /// Additional data required by the Machine\n+    pub data: M::MemoryData,\n+\n+    /// Helps guarantee that stack allocations aren't deallocated via `rust_deallocate`\n+    alloc_kind: HashMap<u64, MemoryKind<M::MemoryKinds>>,\n+\n+    /// Actual memory allocations (arbitrary bytes, may contain pointers into other allocations).\n+    alloc_map: HashMap<u64, Allocation>,\n+\n+    /// Actual memory allocations (arbitrary bytes, may contain pointers into other allocations).\n+    ///\n+    /// Stores statics while they are being processed, before they are interned and thus frozen\n+    uninitialized_statics: HashMap<u64, Allocation>,\n+\n+    /// Number of virtual bytes allocated.\n+    memory_usage: u64,\n+\n+    /// Maximum number of virtual bytes that may be allocated.\n+    memory_size: u64,\n+\n+    /// To avoid having to pass flags to every single memory access, we have some global state saying whether\n+    /// alignment checking is currently enforced for read and/or write accesses.\n+    reads_are_aligned: Cell<bool>,\n+    writes_are_aligned: Cell<bool>,\n+\n+    /// The current stack frame.  Used to check accesses against locks.\n+    pub cur_frame: usize,\n+\n+    pub tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    pub fn new(tcx: TyCtxt<'a, 'tcx, 'tcx>, max_memory: u64, data: M::MemoryData) -> Self {\n+        Memory {\n+            data,\n+            alloc_kind: HashMap::new(),\n+            alloc_map: HashMap::new(),\n+            uninitialized_statics: HashMap::new(),\n+            tcx,\n+            memory_size: max_memory,\n+            memory_usage: 0,\n+            reads_are_aligned: Cell::new(true),\n+            writes_are_aligned: Cell::new(true),\n+            cur_frame: usize::max_value(),\n+        }\n+    }\n+\n+    pub fn allocations<'x>(\n+        &'x self,\n+    ) -> impl Iterator<Item = (AllocId, &'x Allocation)> {\n+        self.alloc_map.iter().map(|(&id, alloc)| (AllocId(id), alloc))\n+    }\n+\n+    pub fn create_fn_alloc(&mut self, instance: Instance<'tcx>) -> MemoryPointer {\n+        let id = self.tcx.interpret_interner.borrow_mut().create_fn_alloc(instance);\n+        MemoryPointer::new(AllocId(id), 0)\n+    }\n+\n+    pub fn allocate_cached(&mut self, bytes: &[u8]) -> MemoryPointer {\n+        let id = self.tcx.allocate_cached(bytes);\n+        MemoryPointer::new(AllocId(id), 0)\n+    }\n+\n+    /// kind is `None` for statics\n+    pub fn allocate(\n+        &mut self,\n+        size: u64,\n+        align: u64,\n+        kind: Option<MemoryKind<M::MemoryKinds>>,\n+    ) -> EvalResult<'tcx, MemoryPointer> {\n+        assert_ne!(align, 0);\n+        assert!(align.is_power_of_two());\n+\n+        if self.memory_size - self.memory_usage < size {\n+            return err!(OutOfMemory {\n+                allocation_size: size,\n+                memory_size: self.memory_size,\n+                memory_usage: self.memory_usage,\n+            });\n+        }\n+        self.memory_usage += size;\n+        assert_eq!(size as usize as u64, size);\n+        let alloc = Allocation {\n+            bytes: vec![0; size as usize],\n+            relocations: BTreeMap::new(),\n+            undef_mask: UndefMask::new(size),\n+            align,\n+        };\n+        let id = self.tcx.interpret_interner.borrow_mut().reserve();\n+        M::add_lock(self, id);\n+        match kind {\n+            Some(kind @ MemoryKind::Stack) |\n+            Some(kind @ MemoryKind::Machine(_)) => {\n+                self.alloc_map.insert(id, alloc);\n+                self.alloc_kind.insert(id, kind);\n+            },\n+            None => {\n+                self.uninitialized_statics.insert(id, alloc);\n+            },\n+            Some(MemoryKind::MutableStatic) => bug!(\"don't allocate mutable statics directly\")\n+        }\n+        Ok(MemoryPointer::new(AllocId(id), 0))\n+    }\n+\n+    pub fn reallocate(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        old_size: u64,\n+        old_align: u64,\n+        new_size: u64,\n+        new_align: u64,\n+        kind: MemoryKind<M::MemoryKinds>,\n+    ) -> EvalResult<'tcx, MemoryPointer> {\n+        use std::cmp::min;\n+\n+        if ptr.offset != 0 {\n+            return err!(ReallocateNonBasePtr);\n+        }\n+        if self.alloc_map.contains_key(&ptr.alloc_id.0) {\n+            let alloc_kind = self.alloc_kind[&ptr.alloc_id.0];\n+            if alloc_kind != kind {\n+                return err!(ReallocatedWrongMemoryKind(\n+                    format!(\"{:?}\", alloc_kind),\n+                    format!(\"{:?}\", kind),\n+                ));\n+            }\n+        }\n+\n+        // For simplicities' sake, we implement reallocate as \"alloc, copy, dealloc\"\n+        let new_ptr = self.allocate(new_size, new_align, Some(kind))?;\n+        self.copy(\n+            ptr.into(),\n+            new_ptr.into(),\n+            min(old_size, new_size),\n+            min(old_align, new_align),\n+            /*nonoverlapping*/\n+            true,\n+        )?;\n+        self.deallocate(ptr, Some((old_size, old_align)), kind)?;\n+\n+        Ok(new_ptr)\n+    }\n+\n+    pub fn deallocate_local(&mut self, ptr: MemoryPointer) -> EvalResult<'tcx> {\n+        match self.alloc_kind.get(&ptr.alloc_id.0).cloned() {\n+            // for a constant like `const FOO: &i32 = &1;` the local containing\n+            // the `1` is referred to by the global. We transitively marked everything\n+            // the global refers to as static itself, so we don't free it here\n+            Some(MemoryKind::MutableStatic) => Ok(()),\n+            Some(MemoryKind::Stack) => self.deallocate(ptr, None, MemoryKind::Stack),\n+            // Happens if the memory was interned into immutable memory\n+            None => Ok(()),\n+            other => bug!(\"local contained non-stack memory: {:?}\", other),\n+        }\n+    }\n+\n+    pub fn deallocate(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        size_and_align: Option<(u64, u64)>,\n+        kind: MemoryKind<M::MemoryKinds>,\n+    ) -> EvalResult<'tcx> {\n+        if ptr.offset != 0 {\n+            return err!(DeallocateNonBasePtr);\n+        }\n+\n+        let alloc = match self.alloc_map.remove(&ptr.alloc_id.0) {\n+            Some(alloc) => alloc,\n+            None => if self.uninitialized_statics.contains_key(&ptr.alloc_id.0) {\n+                return err!(DeallocatedWrongMemoryKind(\n+                    \"uninitializedstatic\".to_string(),\n+                    format!(\"{:?}\", kind),\n+                ))\n+            } else if self.tcx.interpret_interner.borrow().get_fn(ptr.alloc_id.0).is_some() {\n+                return err!(DeallocatedWrongMemoryKind(\n+                    \"function\".to_string(),\n+                    format!(\"{:?}\", kind),\n+                ))\n+            } else if self.tcx.interpret_interner.borrow().get_alloc(ptr.alloc_id.0).is_some() {\n+                return err!(DeallocatedWrongMemoryKind(\n+                    \"static\".to_string(),\n+                    format!(\"{:?}\", kind),\n+                ))\n+            } else {\n+                return err!(DoubleFree)\n+            },\n+        };\n+\n+        let alloc_kind = self.alloc_kind.remove(&ptr.alloc_id.0).expect(\"alloc_map out of sync with alloc_kind\");\n+\n+        // It is okay for us to still holds locks on deallocation -- for example, we could store data we own\n+        // in a local, and the local could be deallocated (from StorageDead) before the function returns.\n+        // However, we should check *something*.  For now, we make sure that there is no conflicting write\n+        // lock by another frame.  We *have* to permit deallocation if we hold a read lock.\n+        // TODO: Figure out the exact rules here.\n+        M::free_lock(self, ptr.alloc_id.0, alloc.bytes.len() as u64)?;\n+\n+        if alloc_kind != kind {\n+            return err!(DeallocatedWrongMemoryKind(\n+                format!(\"{:?}\", alloc_kind),\n+                format!(\"{:?}\", kind),\n+            ));\n+        }\n+        if let Some((size, align)) = size_and_align {\n+            if size != alloc.bytes.len() as u64 || align != alloc.align {\n+                return err!(IncorrectAllocationInformation(size, alloc.bytes.len(), align, alloc.align));\n+            }\n+        }\n+\n+        self.memory_usage -= alloc.bytes.len() as u64;\n+        debug!(\"deallocated : {}\", ptr.alloc_id);\n+\n+        Ok(())\n+    }\n+\n+    pub fn pointer_size(&self) -> u64 {\n+        self.tcx.data_layout.pointer_size.bytes()\n+    }\n+\n+    pub fn endianess(&self) -> layout::Endian {\n+        self.tcx.data_layout.endian\n+    }\n+\n+    /// Check that the pointer is aligned AND non-NULL.\n+    pub fn check_align(&self, ptr: Pointer, align: u64, access: Option<AccessKind>) -> EvalResult<'tcx> {\n+        // Check non-NULL/Undef, extract offset\n+        let (offset, alloc_align) = match ptr.into_inner_primval() {\n+            PrimVal::Ptr(ptr) => {\n+                let alloc = self.get(ptr.alloc_id)?;\n+                (ptr.offset, alloc.align)\n+            }\n+            PrimVal::Bytes(bytes) => {\n+                let v = ((bytes as u128) % (1 << self.pointer_size())) as u64;\n+                if v == 0 {\n+                    return err!(InvalidNullPointerUsage);\n+                }\n+                (v, align) // the base address if the \"integer allocation\" is 0 and hence always aligned\n+            }\n+            PrimVal::Undef => return err!(ReadUndefBytes),\n+        };\n+        // See if alignment checking is disabled\n+        let enforce_alignment = match access {\n+            Some(AccessKind::Read) => self.reads_are_aligned.get(),\n+            Some(AccessKind::Write) => self.writes_are_aligned.get(),\n+            None => true,\n+        };\n+        if !enforce_alignment {\n+            return Ok(());\n+        }\n+        // Check alignment\n+        if alloc_align < align {\n+            return err!(AlignmentCheckFailed {\n+                has: alloc_align,\n+                required: align,\n+            });\n+        }\n+        if offset % align == 0 {\n+            Ok(())\n+        } else {\n+            err!(AlignmentCheckFailed {\n+                has: offset % align,\n+                required: align,\n+            })\n+        }\n+    }\n+\n+    pub fn check_bounds(&self, ptr: MemoryPointer, access: bool) -> EvalResult<'tcx> {\n+        let alloc = self.get(ptr.alloc_id)?;\n+        let allocation_size = alloc.bytes.len() as u64;\n+        if ptr.offset > allocation_size {\n+            return err!(PointerOutOfBounds {\n+                ptr,\n+                access,\n+                allocation_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+}\n+\n+/// Allocation accessors\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    pub fn get(&self, id: AllocId) -> EvalResult<'tcx, &Allocation> {\n+        // normal alloc?\n+        match self.alloc_map.get(&id.0) {\n+                    Some(alloc) => Ok(alloc),\n+            // uninitialized static alloc?\n+            None => match self.uninitialized_statics.get(&id.0) {\n+                Some(alloc) => Ok(alloc),\n+                None => {\n+                    let int = self.tcx.interpret_interner.borrow();\n+                    // static alloc?\n+                    int.get_alloc(id.0)\n+                        // no alloc? produce an error\n+                        .ok_or_else(|| if int.get_fn(id.0).is_some() {\n+                            EvalErrorKind::DerefFunctionPointer.into()\n+                        } else {\n+                            EvalErrorKind::DanglingPointerDeref.into()\n+                        })\n+                },\n+            },\n+        }\n+    }\n+\n+    fn get_mut(\n+        &mut self,\n+        id: AllocId,\n+    ) -> EvalResult<'tcx, &mut Allocation> {\n+        // normal alloc?\n+        match self.alloc_map.get_mut(&id.0) {\n+            Some(alloc) => Ok(alloc),\n+            // uninitialized static alloc?\n+            None => match self.uninitialized_statics.get_mut(&id.0) {\n+                Some(alloc) => Ok(alloc),\n+                None => {\n+                    let int = self.tcx.interpret_interner.borrow();\n+                    // no alloc or immutable alloc? produce an error\n+                    if int.get_alloc(id.0).is_some() {\n+                        err!(ModifiedConstantMemory)\n+                    } else if int.get_fn(id.0).is_some() {\n+                        err!(DerefFunctionPointer)\n+                    } else {\n+                        err!(DanglingPointerDeref)\n+                    }\n+                },\n+            },\n+        }\n+    }\n+\n+    pub fn get_fn(&self, ptr: MemoryPointer) -> EvalResult<'tcx, Instance<'tcx>> {\n+        if ptr.offset != 0 {\n+            return err!(InvalidFunctionPointer);\n+        }\n+        debug!(\"reading fn ptr: {}\", ptr.alloc_id);\n+        self.tcx\n+            .interpret_interner\n+            .borrow()\n+            .get_fn(ptr.alloc_id.0)\n+            .ok_or(EvalErrorKind::ExecuteMemory.into())\n+    }\n+\n+    /// For debugging, print an allocation and all allocations it points to, recursively.\n+    pub fn dump_alloc(&self, id: AllocId) {\n+        self.dump_allocs(vec![id]);\n+    }\n+\n+    /// For debugging, print a list of allocations and all allocations they point to, recursively.\n+    pub fn dump_allocs(&self, mut allocs: Vec<AllocId>) {\n+        use std::fmt::Write;\n+        allocs.sort();\n+        allocs.dedup();\n+        let mut allocs_to_print = VecDeque::from(allocs);\n+        let mut allocs_seen = HashSet::new();\n+\n+        while let Some(id) = allocs_to_print.pop_front() {\n+            let mut msg = format!(\"Alloc {:<5} \", format!(\"{}:\", id));\n+            let prefix_len = msg.len();\n+            let mut relocations = vec![];\n+\n+            let (alloc, immutable) =\n+                // normal alloc?\n+                match self.alloc_map.get(&id.0) {\n+                    Some(a) => (a, match self.alloc_kind[&id.0] {\n+                        MemoryKind::Stack => \" (stack)\".to_owned(),\n+                        MemoryKind::Machine(m) => format!(\" ({:?})\", m),\n+                        MemoryKind::MutableStatic => \" (static mut)\".to_owned(),\n+                    }),\n+                    // uninitialized static alloc?\n+                    None => match self.uninitialized_statics.get(&id.0) {\n+                        Some(a) => (a, \" (static in the process of initialization)\".to_owned()),\n+                        None => {\n+                            let int = self.tcx.interpret_interner.borrow();\n+                            // static alloc?\n+                            match int.get_alloc(id.0) {\n+                                Some(a) => (a, \"(immutable)\".to_owned()),\n+                                None => if let Some(func) = int.get_fn(id.0) {\n+                                    trace!(\"{} {}\", msg, func);\n+                    continue;\n+                                } else {\n+                            trace!(\"{} (deallocated)\", msg);\n+                            continue;\n+                                },\n+                }\n+                        },\n+                    },\n+            };\n+\n+            for i in 0..(alloc.bytes.len() as u64) {\n+                if let Some(&target_id) = alloc.relocations.get(&i) {\n+                    if allocs_seen.insert(target_id) {\n+                        allocs_to_print.push_back(target_id);\n+                    }\n+                    relocations.push((i, target_id));\n+                }\n+                if alloc.undef_mask.is_range_defined(i, i + 1) {\n+                    // this `as usize` is fine, since `i` came from a `usize`\n+                    write!(msg, \"{:02x} \", alloc.bytes[i as usize]).unwrap();\n+                } else {\n+                    msg.push_str(\"__ \");\n+                }\n+            }\n+\n+            trace!(\n+                \"{}({} bytes, alignment {}){}\",\n+                msg,\n+                alloc.bytes.len(),\n+                alloc.align,\n+                immutable\n+            );\n+\n+            if !relocations.is_empty() {\n+                msg.clear();\n+                write!(msg, \"{:1$}\", \"\", prefix_len).unwrap(); // Print spaces.\n+                let mut pos = 0;\n+                let relocation_width = (self.pointer_size() - 1) * 3;\n+                for (i, target_id) in relocations {\n+                    // this `as usize` is fine, since we can't print more chars than `usize::MAX`\n+                    write!(msg, \"{:1$}\", \"\", ((i - pos) * 3) as usize).unwrap();\n+                    let target = format!(\"({})\", target_id);\n+                    // this `as usize` is fine, since we can't print more chars than `usize::MAX`\n+                    write!(msg, \"\u2514{0:\u2500^1$}\u2518 \", target, relocation_width as usize).unwrap();\n+                    pos = i + self.pointer_size();\n+                }\n+                trace!(\"{}\", msg);\n+            }\n+        }\n+    }\n+\n+    pub fn leak_report(&self) -> usize {\n+        trace!(\"### LEAK REPORT ###\");\n+        let kinds = &self.alloc_kind;\n+        let leaks: Vec<_> = self.alloc_map\n+            .keys()\n+            .filter_map(|key| if kinds[key] != MemoryKind::MutableStatic {\n+                Some(AllocId(*key))\n+            } else {\n+                None\n+            })\n+            .collect();\n+        let n = leaks.len();\n+        self.dump_allocs(leaks);\n+        n\n+    }\n+}\n+\n+/// Byte accessors\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    fn get_bytes_unchecked(\n+        &self,\n+        ptr: MemoryPointer,\n+        size: u64,\n+        align: u64,\n+    ) -> EvalResult<'tcx, &[u8]> {\n+        // Zero-sized accesses can use dangling pointers, but they still have to be aligned and non-NULL\n+        self.check_align(ptr.into(), align, Some(AccessKind::Read))?;\n+        if size == 0 {\n+            return Ok(&[]);\n+        }\n+        M::check_locks(self, ptr, size, AccessKind::Read)?;\n+        self.check_bounds(ptr.offset(size, self)?, true)?; // if ptr.offset is in bounds, then so is ptr (because offset checks for overflow)\n+        let alloc = self.get(ptr.alloc_id)?;\n+        assert_eq!(ptr.offset as usize as u64, ptr.offset);\n+        assert_eq!(size as usize as u64, size);\n+        let offset = ptr.offset as usize;\n+        Ok(&alloc.bytes[offset..offset + size as usize])\n+    }\n+\n+    fn get_bytes_unchecked_mut(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        size: u64,\n+        align: u64,\n+    ) -> EvalResult<'tcx, &mut [u8]> {\n+        // Zero-sized accesses can use dangling pointers, but they still have to be aligned and non-NULL\n+        self.check_align(ptr.into(), align, Some(AccessKind::Write))?;\n+        if size == 0 {\n+            return Ok(&mut []);\n+        }\n+        M::check_locks(self, ptr, size, AccessKind::Write)?;\n+        self.check_bounds(ptr.offset(size, &*self)?, true)?; // if ptr.offset is in bounds, then so is ptr (because offset checks for overflow)\n+        let alloc = self.get_mut(ptr.alloc_id)?;\n+        assert_eq!(ptr.offset as usize as u64, ptr.offset);\n+        assert_eq!(size as usize as u64, size);\n+        let offset = ptr.offset as usize;\n+        Ok(&mut alloc.bytes[offset..offset + size as usize])\n+    }\n+\n+    fn get_bytes(&self, ptr: MemoryPointer, size: u64, align: u64) -> EvalResult<'tcx, &[u8]> {\n+        assert_ne!(size, 0);\n+        if self.relocations(ptr, size)?.count() != 0 {\n+            return err!(ReadPointerAsBytes);\n+        }\n+        self.check_defined(ptr, size)?;\n+        self.get_bytes_unchecked(ptr, size, align)\n+    }\n+\n+    fn get_bytes_mut(\n+        &mut self,\n+        ptr: MemoryPointer,\n+        size: u64,\n+        align: u64,\n+    ) -> EvalResult<'tcx, &mut [u8]> {\n+        assert_ne!(size, 0);\n+        self.clear_relocations(ptr, size)?;\n+        self.mark_definedness(ptr.into(), size, true)?;\n+        self.get_bytes_unchecked_mut(ptr, size, align)\n+    }\n+}\n+\n+/// Reading and writing\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    /// mark an allocation pointed to by a static as static and initialized\n+    fn mark_inner_allocation_initialized(\n+        &mut self,\n+        alloc: AllocId,\n+        mutability: Mutability,\n+    ) -> EvalResult<'tcx> {\n+        match self.alloc_kind.get(&alloc.0) {\n+            // do not go into immutable statics\n+            None |\n+            // or mutable statics\n+            Some(&MemoryKind::MutableStatic) => Ok(()),\n+            // just locals and machine allocs\n+            Some(_) => self.mark_static_initalized(alloc, mutability),\n+        }\n+    }\n+\n+    /// mark an allocation as static and initialized, either mutable or not\n+    pub fn mark_static_initalized(\n+        &mut self,\n+        alloc_id: AllocId,\n+        mutability: Mutability,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\n+            \"mark_static_initalized {:?}, mutability: {:?}\",\n+            alloc_id,\n+            mutability\n+        );\n+        if mutability == Mutability::Immutable {\n+            let alloc = self.alloc_map.remove(&alloc_id.0);\n+            let kind = self.alloc_kind.remove(&alloc_id.0);\n+            assert_ne!(kind, Some(MemoryKind::MutableStatic));\n+            let uninit = self.uninitialized_statics.remove(&alloc_id.0);\n+            if let Some(alloc) = alloc.or(uninit) {\n+                let alloc = self.tcx.intern_const_alloc(alloc);\n+                self.tcx.interpret_interner.borrow_mut().intern_at_reserved(alloc_id.0, alloc);\n+                // recurse into inner allocations\n+                for &alloc in alloc.relocations.values() {\n+                    self.mark_inner_allocation_initialized(alloc, mutability)?;\n+                }\n+            }\n+            return Ok(());\n+        }\n+        // We are marking the static as initialized, so move it out of the uninit map\n+        if let Some(uninit) = self.uninitialized_statics.remove(&alloc_id.0) {\n+            self.alloc_map.insert(alloc_id.0, uninit);\n+        }\n+        // do not use `self.get_mut(alloc_id)` here, because we might have already marked a\n+        // sub-element or have circular pointers (e.g. `Rc`-cycles)\n+        let relocations = match self.alloc_map.get_mut(&alloc_id.0) {\n+            Some(&mut Allocation {\n+                     ref mut relocations,\n+                     ..\n+                 }) => {\n+                match self.alloc_kind.get(&alloc_id.0) {\n+                    // const eval results can refer to \"locals\".\n+                    // E.g. `const Foo: &u32 = &1;` refers to the temp local that stores the `1`\n+                    None |\n+                    Some(&MemoryKind::Stack) => {},\n+                    Some(&MemoryKind::Machine(m)) => M::mark_static_initialized(m)?,\n+                    Some(&MemoryKind::MutableStatic) => {\n+                        trace!(\"mark_static_initalized: skipping already initialized static referred to by static currently being initialized\");\n+                        return Ok(());\n+                    },\n+                }\n+                // overwrite or insert\n+                self.alloc_kind.insert(alloc_id.0, MemoryKind::MutableStatic);\n+                // take out the relocations vector to free the borrow on self, so we can call\n+                // mark recursively\n+                mem::replace(relocations, Default::default())\n+            }\n+            None => return err!(DanglingPointerDeref),\n+        };\n+        // recurse into inner allocations\n+        for &alloc in relocations.values() {\n+            self.mark_inner_allocation_initialized(alloc, mutability)?;\n+        }\n+        // put back the relocations\n+        self.alloc_map\n+            .get_mut(&alloc_id.0)\n+            .expect(\"checked above\")\n+            .relocations = relocations;\n+        Ok(())\n+    }\n+\n+    pub fn copy(\n+        &mut self,\n+        src: Pointer,\n+        dest: Pointer,\n+        size: u64,\n+        align: u64,\n+        nonoverlapping: bool,\n+    ) -> EvalResult<'tcx> {\n+        // Empty accesses don't need to be valid pointers, but they should still be aligned\n+        self.check_align(src, align, Some(AccessKind::Read))?;\n+        self.check_align(dest, align, Some(AccessKind::Write))?;\n+        if size == 0 {\n+            return Ok(());\n+        }\n+        let src = src.to_ptr()?;\n+        let dest = dest.to_ptr()?;\n+        self.check_relocation_edges(src, size)?;\n+\n+        // first copy the relocations to a temporary buffer, because\n+        // `get_bytes_mut` will clear the relocations, which is correct,\n+        // since we don't want to keep any relocations at the target.\n+\n+        let relocations: Vec<_> = self.relocations(src, size)?\n+            .map(|(&offset, &alloc_id)| {\n+                // Update relocation offsets for the new positions in the destination allocation.\n+                (offset + dest.offset - src.offset, alloc_id)\n+            })\n+            .collect();\n+\n+        let src_bytes = self.get_bytes_unchecked(src, size, align)?.as_ptr();\n+        let dest_bytes = self.get_bytes_mut(dest, size, align)?.as_mut_ptr();\n+\n+        // SAFE: The above indexing would have panicked if there weren't at least `size` bytes\n+        // behind `src` and `dest`. Also, we use the overlapping-safe `ptr::copy` if `src` and\n+        // `dest` could possibly overlap.\n+        unsafe {\n+            assert_eq!(size as usize as u64, size);\n+            if src.alloc_id == dest.alloc_id {\n+                if nonoverlapping {\n+                    if (src.offset <= dest.offset && src.offset + size > dest.offset) ||\n+                        (dest.offset <= src.offset && dest.offset + size > src.offset)\n+                    {\n+                        return err!(Intrinsic(\n+                            format!(\"copy_nonoverlapping called on overlapping ranges\"),\n+                        ));\n+                    }\n+                }\n+                ptr::copy(src_bytes, dest_bytes, size as usize);\n+            } else {\n+                ptr::copy_nonoverlapping(src_bytes, dest_bytes, size as usize);\n+            }\n+        }\n+\n+        self.copy_undef_mask(src, dest, size)?;\n+        // copy back the relocations\n+        self.get_mut(dest.alloc_id)?.relocations.extend(relocations);\n+\n+        Ok(())\n+    }\n+\n+    pub fn read_c_str(&self, ptr: MemoryPointer) -> EvalResult<'tcx, &[u8]> {\n+        let alloc = self.get(ptr.alloc_id)?;\n+        assert_eq!(ptr.offset as usize as u64, ptr.offset);\n+        let offset = ptr.offset as usize;\n+        match alloc.bytes[offset..].iter().position(|&c| c == 0) {\n+            Some(size) => {\n+                if self.relocations(ptr, (size + 1) as u64)?.count() != 0 {\n+                    return err!(ReadPointerAsBytes);\n+                }\n+                self.check_defined(ptr, (size + 1) as u64)?;\n+                M::check_locks(self, ptr, (size + 1) as u64, AccessKind::Read)?;\n+                Ok(&alloc.bytes[offset..offset + size])\n+            }\n+            None => err!(UnterminatedCString(ptr)),\n+        }\n+    }\n+\n+    pub fn read_bytes(&self, ptr: Pointer, size: u64) -> EvalResult<'tcx, &[u8]> {\n+        // Empty accesses don't need to be valid pointers, but they should still be non-NULL\n+        self.check_align(ptr, 1, Some(AccessKind::Read))?;\n+        if size == 0 {\n+            return Ok(&[]);\n+        }\n+        self.get_bytes(ptr.to_ptr()?, size, 1)\n+    }\n+\n+    pub fn write_bytes(&mut self, ptr: Pointer, src: &[u8]) -> EvalResult<'tcx> {\n+        // Empty accesses don't need to be valid pointers, but they should still be non-NULL\n+        self.check_align(ptr, 1, Some(AccessKind::Write))?;\n+        if src.is_empty() {\n+            return Ok(());\n+        }\n+        let bytes = self.get_bytes_mut(ptr.to_ptr()?, src.len() as u64, 1)?;\n+        bytes.clone_from_slice(src);\n+        Ok(())\n+    }\n+\n+    pub fn write_repeat(&mut self, ptr: Pointer, val: u8, count: u64) -> EvalResult<'tcx> {\n+        // Empty accesses don't need to be valid pointers, but they should still be non-NULL\n+        self.check_align(ptr, 1, Some(AccessKind::Write))?;\n+        if count == 0 {\n+            return Ok(());\n+        }\n+        let bytes = self.get_bytes_mut(ptr.to_ptr()?, count, 1)?;\n+        for b in bytes {\n+            *b = val;\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn read_primval(&self, ptr: MemoryPointer, size: u64, signed: bool) -> EvalResult<'tcx, PrimVal> {\n+        self.check_relocation_edges(ptr, size)?; // Make sure we don't read part of a pointer as a pointer\n+        let endianess = self.endianess();\n+        let bytes = self.get_bytes_unchecked(ptr, size, self.int_align(size))?;\n+        // Undef check happens *after* we established that the alignment is correct.\n+        // We must not return Ok() for unaligned pointers!\n+        if self.check_defined(ptr, size).is_err() {\n+            return Ok(PrimVal::Undef.into());\n+        }\n+        // Now we do the actual reading\n+        let bytes = if signed {\n+            read_target_int(endianess, bytes).unwrap() as u128\n+        } else {\n+            read_target_uint(endianess, bytes).unwrap()\n+        };\n+        // See if we got a pointer\n+        if size != self.pointer_size() {\n+            if self.relocations(ptr, size)?.count() != 0 {\n+                return err!(ReadPointerAsBytes);\n+            }\n+        } else {\n+            let alloc = self.get(ptr.alloc_id)?;\n+            match alloc.relocations.get(&ptr.offset) {\n+                Some(&alloc_id) => return Ok(PrimVal::Ptr(MemoryPointer::new(alloc_id, bytes as u64))),\n+                None => {},\n+            }\n+        }\n+        // We don't. Just return the bytes.\n+        Ok(PrimVal::Bytes(bytes))\n+    }\n+\n+    pub fn read_ptr_sized_unsigned(&self, ptr: MemoryPointer) -> EvalResult<'tcx, PrimVal> {\n+        self.read_primval(ptr, self.pointer_size(), false)\n+    }\n+\n+    pub fn write_primval(&mut self, ptr: MemoryPointer, val: PrimVal, size: u64, signed: bool) -> EvalResult<'tcx> {\n+        let endianess = self.endianess();\n+\n+        let bytes = match val {\n+            PrimVal::Ptr(val) => {\n+                assert_eq!(size, self.pointer_size());\n+                val.offset as u128\n+            }\n+\n+            PrimVal::Bytes(bytes) => {\n+                // We need to mask here, or the byteorder crate can die when given a u64 larger\n+                // than fits in an integer of the requested size.\n+                let mask = match size {\n+                    1 => !0u8 as u128,\n+                    2 => !0u16 as u128,\n+                    4 => !0u32 as u128,\n+                    8 => !0u64 as u128,\n+                    16 => !0,\n+                    n => bug!(\"unexpected PrimVal::Bytes size: {}\", n),\n+                };\n+                bytes & mask\n+            }\n+\n+            PrimVal::Undef => {\n+                self.mark_definedness(PrimVal::Ptr(ptr).into(), size, false)?;\n+                return Ok(());\n+            }\n+        };\n+\n+        {\n+            let align = self.int_align(size);\n+            let dst = self.get_bytes_mut(ptr, size, align)?;\n+            if signed {\n+                write_target_int(endianess, dst, bytes as i128).unwrap();\n+            } else {\n+                write_target_uint(endianess, dst, bytes).unwrap();\n+            }\n+        }\n+\n+        // See if we have to also write a relocation\n+        match val {\n+            PrimVal::Ptr(val) => {\n+                self.get_mut(ptr.alloc_id)?.relocations.insert(\n+                    ptr.offset,\n+                    val.alloc_id,\n+                );\n+            }\n+            _ => {}\n+        }\n+\n+        Ok(())\n+    }\n+\n+    pub fn write_ptr_sized_unsigned(&mut self, ptr: MemoryPointer, val: PrimVal) -> EvalResult<'tcx> {\n+        let ptr_size = self.pointer_size();\n+        self.write_primval(ptr, val, ptr_size, false)\n+    }\n+\n+    fn int_align(&self, size: u64) -> u64 {\n+        // We assume pointer-sized integers have the same alignment as pointers.\n+        // We also assume signed and unsigned integers of the same size have the same alignment.\n+        match size {\n+            1 => self.tcx.data_layout.i8_align.abi(),\n+            2 => self.tcx.data_layout.i16_align.abi(),\n+            4 => self.tcx.data_layout.i32_align.abi(),\n+            8 => self.tcx.data_layout.i64_align.abi(),\n+            16 => self.tcx.data_layout.i128_align.abi(),\n+            _ => bug!(\"bad integer size: {}\", size),\n+        }\n+    }\n+}\n+\n+/// Relocations\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    fn relocations(\n+        &self,\n+        ptr: MemoryPointer,\n+        size: u64,\n+    ) -> EvalResult<'tcx, btree_map::Range<u64, AllocId>> {\n+        let start = ptr.offset.saturating_sub(self.pointer_size() - 1);\n+        let end = ptr.offset + size;\n+        Ok(self.get(ptr.alloc_id)?.relocations.range(start..end))\n+    }\n+\n+    fn clear_relocations(&mut self, ptr: MemoryPointer, size: u64) -> EvalResult<'tcx> {\n+        // Find all relocations overlapping the given range.\n+        let keys: Vec<_> = self.relocations(ptr, size)?.map(|(&k, _)| k).collect();\n+        if keys.is_empty() {\n+            return Ok(());\n+        }\n+\n+        // Find the start and end of the given range and its outermost relocations.\n+        let start = ptr.offset;\n+        let end = start + size;\n+        let first = *keys.first().unwrap();\n+        let last = *keys.last().unwrap() + self.pointer_size();\n+\n+        let alloc = self.get_mut(ptr.alloc_id)?;\n+\n+        // Mark parts of the outermost relocations as undefined if they partially fall outside the\n+        // given range.\n+        if first < start {\n+            alloc.undef_mask.set_range(first, start, false);\n+        }\n+        if last > end {\n+            alloc.undef_mask.set_range(end, last, false);\n+        }\n+\n+        // Forget all the relocations.\n+        for k in keys {\n+            alloc.relocations.remove(&k);\n+        }\n+\n+        Ok(())\n+    }\n+\n+    fn check_relocation_edges(&self, ptr: MemoryPointer, size: u64) -> EvalResult<'tcx> {\n+        let overlapping_start = self.relocations(ptr, 0)?.count();\n+        let overlapping_end = self.relocations(ptr.offset(size, self)?, 0)?.count();\n+        if overlapping_start + overlapping_end != 0 {\n+            return err!(ReadPointerAsBytes);\n+        }\n+        Ok(())\n+    }\n+}\n+\n+/// Undefined bytes\n+impl<'a, 'tcx, M: Machine<'tcx>> Memory<'a, 'tcx, M> {\n+    // FIXME(solson): This is a very naive, slow version.\n+    fn copy_undef_mask(\n+        &mut self,\n+        src: MemoryPointer,\n+        dest: MemoryPointer,\n+        size: u64,\n+    ) -> EvalResult<'tcx> {\n+        // The bits have to be saved locally before writing to dest in case src and dest overlap.\n+        assert_eq!(size as usize as u64, size);\n+        let mut v = Vec::with_capacity(size as usize);\n+        for i in 0..size {\n+            let defined = self.get(src.alloc_id)?.undef_mask.get(src.offset + i);\n+            v.push(defined);\n+        }\n+        for (i, defined) in v.into_iter().enumerate() {\n+            self.get_mut(dest.alloc_id)?.undef_mask.set(\n+                dest.offset +\n+                    i as u64,\n+                defined,\n+            );\n+        }\n+        Ok(())\n+    }\n+\n+    fn check_defined(&self, ptr: MemoryPointer, size: u64) -> EvalResult<'tcx> {\n+        let alloc = self.get(ptr.alloc_id)?;\n+        if !alloc.undef_mask.is_range_defined(\n+            ptr.offset,\n+            ptr.offset + size,\n+        )\n+        {\n+            return err!(ReadUndefBytes);\n+        }\n+        Ok(())\n+    }\n+\n+    pub fn mark_definedness(\n+        &mut self,\n+        ptr: Pointer,\n+        size: u64,\n+        new_state: bool,\n+    ) -> EvalResult<'tcx> {\n+        if size == 0 {\n+            return Ok(());\n+        }\n+        let ptr = ptr.to_ptr()?;\n+        let alloc = self.get_mut(ptr.alloc_id)?;\n+        alloc.undef_mask.set_range(\n+            ptr.offset,\n+            ptr.offset + size,\n+            new_state,\n+        );\n+        Ok(())\n+    }\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Methods to access integers in the target endianess\n+////////////////////////////////////////////////////////////////////////////////\n+\n+fn write_target_uint(\n+    endianess: layout::Endian,\n+    mut target: &mut [u8],\n+    data: u128,\n+) -> Result<(), io::Error> {\n+    let len = target.len();\n+    match endianess {\n+        layout::Endian::Little => target.write_uint128::<LittleEndian>(data, len),\n+        layout::Endian::Big => target.write_uint128::<BigEndian>(data, len),\n+    }\n+}\n+fn write_target_int(\n+    endianess: layout::Endian,\n+    mut target: &mut [u8],\n+    data: i128,\n+) -> Result<(), io::Error> {\n+    let len = target.len();\n+    match endianess {\n+        layout::Endian::Little => target.write_int128::<LittleEndian>(data, len),\n+        layout::Endian::Big => target.write_int128::<BigEndian>(data, len),\n+    }\n+}\n+\n+fn read_target_uint(endianess: layout::Endian, mut source: &[u8]) -> Result<u128, io::Error> {\n+    match endianess {\n+        layout::Endian::Little => source.read_uint128::<LittleEndian>(source.len()),\n+        layout::Endian::Big => source.read_uint128::<BigEndian>(source.len()),\n+    }\n+}\n+\n+fn read_target_int(endianess: layout::Endian, mut source: &[u8]) -> Result<i128, io::Error> {\n+    match endianess {\n+        layout::Endian::Little => source.read_int128::<LittleEndian>(source.len()),\n+        layout::Endian::Big => source.read_int128::<BigEndian>(source.len()),\n+    }\n+}\n+\n+////////////////////////////////////////////////////////////////////////////////\n+// Unaligned accesses\n+////////////////////////////////////////////////////////////////////////////////\n+\n+pub trait HasMemory<'a, 'tcx: 'a, M: Machine<'tcx>> {\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx, M>;\n+    fn memory(&self) -> &Memory<'a, 'tcx, M>;\n+\n+    // These are not supposed to be overriden.\n+    fn read_maybe_aligned<F, T>(&self, aligned: bool, f: F) -> EvalResult<'tcx, T>\n+    where\n+        F: FnOnce(&Self) -> EvalResult<'tcx, T>,\n+    {\n+        let old = self.memory().reads_are_aligned.get();\n+        // Do alignment checking if *all* nested calls say it has to be aligned.\n+        self.memory().reads_are_aligned.set(old && aligned);\n+        let t = f(self);\n+        self.memory().reads_are_aligned.set(old);\n+        t\n+    }\n+\n+    fn read_maybe_aligned_mut<F, T>(&mut self, aligned: bool, f: F) -> EvalResult<'tcx, T>\n+    where\n+        F: FnOnce(&mut Self) -> EvalResult<'tcx, T>,\n+    {\n+        let old = self.memory().reads_are_aligned.get();\n+        // Do alignment checking if *all* nested calls say it has to be aligned.\n+        self.memory().reads_are_aligned.set(old && aligned);\n+        let t = f(self);\n+        self.memory().reads_are_aligned.set(old);\n+        t\n+    }\n+\n+    fn write_maybe_aligned_mut<F, T>(&mut self, aligned: bool, f: F) -> EvalResult<'tcx, T>\n+    where\n+        F: FnOnce(&mut Self) -> EvalResult<'tcx, T>,\n+    {\n+        let old = self.memory().writes_are_aligned.get();\n+        // Do alignment checking if *all* nested calls say it has to be aligned.\n+        self.memory().writes_are_aligned.set(old && aligned);\n+        let t = f(self);\n+        self.memory().writes_are_aligned.set(old);\n+        t\n+    }\n+\n+    /// Convert the value into a pointer (or a pointer-sized integer).  If the value is a ByRef,\n+    /// this may have to perform a load.\n+    fn into_ptr(\n+        &self,\n+        value: Value,\n+    ) -> EvalResult<'tcx, Pointer> {\n+        Ok(match value {\n+            Value::ByRef(PtrAndAlign { ptr, aligned }) => {\n+                self.memory().read_maybe_aligned(aligned, |mem| mem.read_ptr_sized_unsigned(ptr.to_ptr()?))?\n+            }\n+            Value::ByVal(ptr) |\n+            Value::ByValPair(ptr, _) => ptr,\n+        }.into())\n+    }\n+\n+    fn into_ptr_vtable_pair(\n+        &self,\n+        value: Value,\n+    ) -> EvalResult<'tcx, (Pointer, MemoryPointer)> {\n+        match value {\n+            Value::ByRef(PtrAndAlign {\n+                      ptr: ref_ptr,\n+                      aligned,\n+                  }) => {\n+                self.memory().read_maybe_aligned(aligned, |mem| {\n+                    let ptr = mem.read_ptr_sized_unsigned(ref_ptr.to_ptr()?)?.into();\n+                    let vtable = mem.read_ptr_sized_unsigned(\n+                        ref_ptr.offset(mem.pointer_size(), &mem.tcx.data_layout)?.to_ptr()?,\n+                    )?.to_ptr()?;\n+                    Ok((ptr, vtable))\n+                })\n+            }\n+\n+            Value::ByValPair(ptr, vtable) => Ok((ptr.into(), vtable.to_ptr()?)),\n+\n+            Value::ByVal(PrimVal::Undef) => err!(ReadUndefBytes),\n+            _ => bug!(\"expected ptr and vtable, got {:?}\", value),\n+        }\n+    }\n+\n+    fn into_slice(\n+        &self,\n+        value: Value,\n+    ) -> EvalResult<'tcx, (Pointer, u64)> {\n+        match value {\n+            Value::ByRef(PtrAndAlign {\n+                      ptr: ref_ptr,\n+                      aligned,\n+                  }) => {\n+                self.memory().read_maybe_aligned(aligned, |mem| {\n+                    let ptr = mem.read_ptr_sized_unsigned(ref_ptr.to_ptr()?)?.into();\n+                    let len = mem.read_ptr_sized_unsigned(\n+                        ref_ptr.offset(mem.pointer_size(), &mem.tcx.data_layout)?.to_ptr()?,\n+                    )?.to_bytes()? as u64;\n+                    Ok((ptr, len))\n+                })\n+            }\n+            Value::ByValPair(ptr, val) => {\n+                let len = val.to_u128()?;\n+                assert_eq!(len as u64 as u128, len);\n+                Ok((ptr.into(), len as u64))\n+            }\n+            Value::ByVal(PrimVal::Undef) => err!(ReadUndefBytes),\n+            Value::ByVal(_) => bug!(\"expected ptr and length, got {:?}\", value),\n+        }\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> HasMemory<'a, 'tcx, M> for Memory<'a, 'tcx, M> {\n+    #[inline]\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx, M> {\n+        self\n+    }\n+\n+    #[inline]\n+    fn memory(&self) -> &Memory<'a, 'tcx, M> {\n+        self\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> HasMemory<'a, 'tcx, M> for EvalContext<'a, 'tcx, M> {\n+    #[inline]\n+    fn memory_mut(&mut self) -> &mut Memory<'a, 'tcx, M> {\n+        &mut self.memory\n+    }\n+\n+    #[inline]\n+    fn memory(&self) -> &Memory<'a, 'tcx, M> {\n+        &self.memory\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> layout::HasDataLayout for &'a Memory<'a, 'tcx, M> {\n+    #[inline]\n+    fn data_layout(&self) -> &TargetDataLayout {\n+        &self.tcx.data_layout\n+    }\n+}"}, {"sha": "fee62c8a82e2f08a2895fb02949919143612cff4", "filename": "src/librustc_mir/interpret/mod.rs", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmod.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,23 @@\n+//! An interpreter for MIR used in CTFE and by miri\n+\n+mod cast;\n+mod const_eval;\n+mod eval_context;\n+mod place;\n+mod machine;\n+mod memory;\n+mod operator;\n+mod step;\n+mod terminator;\n+mod traits;\n+\n+pub use self::eval_context::{EvalContext, Frame, ResourceLimits, StackPopCleanup,\n+                             TyAndPacked, ValTy};\n+\n+pub use self::place::{Place, PlaceExtra};\n+\n+pub use self::memory::{Memory, MemoryKind, HasMemory};\n+\n+pub use self::const_eval::{eval_body_as_integer, eval_body, CompileTimeEvaluator, const_eval_provider};\n+\n+pub use self::machine::Machine;"}, {"sha": "6ab1aec38b863cade1c7195ab072ee3771f1fcb8", "filename": "src/librustc_mir/interpret/operator.rs", "status": "added", "additions": 267, "deletions": 0, "changes": 267, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Foperator.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Foperator.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Foperator.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,267 @@\n+use rustc::mir;\n+use rustc::ty::Ty;\n+use rustc_const_math::ConstFloat;\n+use syntax::ast::FloatTy;\n+use std::cmp::Ordering;\n+\n+use super::{EvalContext, Place, Machine, ValTy};\n+\n+use rustc::mir::interpret::{EvalResult, PrimVal, PrimValKind, Value, bytes_to_f32, bytes_to_f64};\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    fn binop_with_overflow(\n+        &mut self,\n+        op: mir::BinOp,\n+        left: ValTy<'tcx>,\n+        right: ValTy<'tcx>,\n+    ) -> EvalResult<'tcx, (PrimVal, bool)> {\n+        let left_val = self.value_to_primval(left)?;\n+        let right_val = self.value_to_primval(right)?;\n+        self.binary_op(op, left_val, left.ty, right_val, right.ty)\n+    }\n+\n+    /// Applies the binary operation `op` to the two operands and writes a tuple of the result\n+    /// and a boolean signifying the potential overflow to the destination.\n+    pub fn intrinsic_with_overflow(\n+        &mut self,\n+        op: mir::BinOp,\n+        left: ValTy<'tcx>,\n+        right: ValTy<'tcx>,\n+        dest: Place,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        let (val, overflowed) = self.binop_with_overflow(op, left, right)?;\n+        let val = Value::ByValPair(val, PrimVal::from_bool(overflowed));\n+        let valty = ValTy {\n+            value: val,\n+            ty: dest_ty,\n+        };\n+        self.write_value(valty, dest)\n+    }\n+\n+    /// Applies the binary operation `op` to the arguments and writes the result to the\n+    /// destination. Returns `true` if the operation overflowed.\n+    pub fn intrinsic_overflowing(\n+        &mut self,\n+        op: mir::BinOp,\n+        left: ValTy<'tcx>,\n+        right: ValTy<'tcx>,\n+        dest: Place,\n+        dest_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, bool> {\n+        let (val, overflowed) = self.binop_with_overflow(op, left, right)?;\n+        self.write_primval(dest, val, dest_ty)?;\n+        Ok(overflowed)\n+    }\n+}\n+\n+macro_rules! overflow {\n+    ($op:ident, $l:expr, $r:expr) => ({\n+        let (val, overflowed) = $l.$op($r);\n+        let primval = PrimVal::Bytes(val as u128);\n+        Ok((primval, overflowed))\n+    })\n+}\n+\n+macro_rules! int_arithmetic {\n+    ($kind:expr, $int_op:ident, $l:expr, $r:expr) => ({\n+        let l = $l;\n+        let r = $r;\n+        use rustc::mir::interpret::PrimValKind::*;\n+        match $kind {\n+            I8  => overflow!($int_op, l as i8,  r as i8),\n+            I16 => overflow!($int_op, l as i16, r as i16),\n+            I32 => overflow!($int_op, l as i32, r as i32),\n+            I64 => overflow!($int_op, l as i64, r as i64),\n+            I128 => overflow!($int_op, l as i128, r as i128),\n+            U8  => overflow!($int_op, l as u8,  r as u8),\n+            U16 => overflow!($int_op, l as u16, r as u16),\n+            U32 => overflow!($int_op, l as u32, r as u32),\n+            U64 => overflow!($int_op, l as u64, r as u64),\n+            U128 => overflow!($int_op, l as u128, r as u128),\n+            _ => bug!(\"int_arithmetic should only be called on int primvals\"),\n+        }\n+    })\n+}\n+\n+macro_rules! int_shift {\n+    ($kind:expr, $int_op:ident, $l:expr, $r:expr) => ({\n+        let l = $l;\n+        let r = $r;\n+        let r_wrapped = r as u32;\n+        match $kind {\n+            I8  => overflow!($int_op, l as i8,  r_wrapped),\n+            I16 => overflow!($int_op, l as i16, r_wrapped),\n+            I32 => overflow!($int_op, l as i32, r_wrapped),\n+            I64 => overflow!($int_op, l as i64, r_wrapped),\n+            I128 => overflow!($int_op, l as i128, r_wrapped),\n+            U8  => overflow!($int_op, l as u8,  r_wrapped),\n+            U16 => overflow!($int_op, l as u16, r_wrapped),\n+            U32 => overflow!($int_op, l as u32, r_wrapped),\n+            U64 => overflow!($int_op, l as u64, r_wrapped),\n+            U128 => overflow!($int_op, l as u128, r_wrapped),\n+            _ => bug!(\"int_shift should only be called on int primvals\"),\n+        }.map(|(val, over)| (val, over || r != r_wrapped as u128))\n+    })\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    /// Returns the result of the specified operation and whether it overflowed.\n+    pub fn binary_op(\n+        &self,\n+        bin_op: mir::BinOp,\n+        left: PrimVal,\n+        left_ty: Ty<'tcx>,\n+        right: PrimVal,\n+        right_ty: Ty<'tcx>,\n+    ) -> EvalResult<'tcx, (PrimVal, bool)> {\n+        use rustc::mir::BinOp::*;\n+        use rustc::mir::interpret::PrimValKind::*;\n+\n+        let left_kind = self.ty_to_primval_kind(left_ty)?;\n+        let right_kind = self.ty_to_primval_kind(right_ty)?;\n+        //trace!(\"Running binary op {:?}: {:?} ({:?}), {:?} ({:?})\", bin_op, left, left_kind, right, right_kind);\n+\n+        // I: Handle operations that support pointers\n+        if !left_kind.is_float() && !right_kind.is_float() {\n+            if let Some(handled) = M::try_ptr_op(self, bin_op, left, left_ty, right, right_ty)? {\n+                return Ok(handled);\n+            }\n+        }\n+\n+        // II: From now on, everything must be bytes, no pointers\n+        let l = left.to_bytes()?;\n+        let r = right.to_bytes()?;\n+\n+        // These ops can have an RHS with a different numeric type.\n+        if right_kind.is_int() && (bin_op == Shl || bin_op == Shr) {\n+            return match bin_op {\n+                Shl => int_shift!(left_kind, overflowing_shl, l, r),\n+                Shr => int_shift!(left_kind, overflowing_shr, l, r),\n+                _ => bug!(\"it has already been checked that this is a shift op\"),\n+            };\n+        }\n+\n+        if left_kind != right_kind {\n+            let msg = format!(\n+                \"unimplemented binary op {:?}: {:?} ({:?}), {:?} ({:?})\",\n+                bin_op,\n+                left,\n+                left_kind,\n+                right,\n+                right_kind\n+            );\n+            return err!(Unimplemented(msg));\n+        }\n+\n+        let float_op = |op, l, r, ty| {\n+            let l = ConstFloat {\n+                bits: l,\n+                ty,\n+            };\n+            let r = ConstFloat {\n+                bits: r,\n+                ty,\n+            };\n+            match op {\n+                Eq => PrimVal::from_bool(l.try_cmp(r).unwrap() == Ordering::Equal),\n+                Ne => PrimVal::from_bool(l.try_cmp(r).unwrap() != Ordering::Equal),\n+                Lt => PrimVal::from_bool(l.try_cmp(r).unwrap() == Ordering::Less),\n+                Le => PrimVal::from_bool(l.try_cmp(r).unwrap() != Ordering::Greater),\n+                Gt => PrimVal::from_bool(l.try_cmp(r).unwrap() == Ordering::Greater),\n+                Ge => PrimVal::from_bool(l.try_cmp(r).unwrap() != Ordering::Less),\n+                Add => PrimVal::Bytes((l + r).unwrap().bits),\n+                Sub => PrimVal::Bytes((l - r).unwrap().bits),\n+                Mul => PrimVal::Bytes((l * r).unwrap().bits),\n+                Div => PrimVal::Bytes((l / r).unwrap().bits),\n+                Rem => PrimVal::Bytes((l % r).unwrap().bits),\n+                _ => bug!(\"invalid float op: `{:?}`\", op),\n+            }\n+        };\n+\n+        let val = match (bin_op, left_kind) {\n+            (_, F32) => float_op(bin_op, l, r, FloatTy::F32),\n+            (_, F64) => float_op(bin_op, l, r, FloatTy::F64),\n+\n+\n+            (Eq, _) => PrimVal::from_bool(l == r),\n+            (Ne, _) => PrimVal::from_bool(l != r),\n+\n+            (Lt, k) if k.is_signed_int() => PrimVal::from_bool((l as i128) < (r as i128)),\n+            (Lt, _) => PrimVal::from_bool(l < r),\n+            (Le, k) if k.is_signed_int() => PrimVal::from_bool((l as i128) <= (r as i128)),\n+            (Le, _) => PrimVal::from_bool(l <= r),\n+            (Gt, k) if k.is_signed_int() => PrimVal::from_bool((l as i128) > (r as i128)),\n+            (Gt, _) => PrimVal::from_bool(l > r),\n+            (Ge, k) if k.is_signed_int() => PrimVal::from_bool((l as i128) >= (r as i128)),\n+            (Ge, _) => PrimVal::from_bool(l >= r),\n+\n+            (BitOr, _) => PrimVal::Bytes(l | r),\n+            (BitAnd, _) => PrimVal::Bytes(l & r),\n+            (BitXor, _) => PrimVal::Bytes(l ^ r),\n+\n+            (Add, k) if k.is_int() => return int_arithmetic!(k, overflowing_add, l, r),\n+            (Sub, k) if k.is_int() => return int_arithmetic!(k, overflowing_sub, l, r),\n+            (Mul, k) if k.is_int() => return int_arithmetic!(k, overflowing_mul, l, r),\n+            (Div, k) if k.is_int() => return int_arithmetic!(k, overflowing_div, l, r),\n+            (Rem, k) if k.is_int() => return int_arithmetic!(k, overflowing_rem, l, r),\n+\n+            _ => {\n+                let msg = format!(\n+                    \"unimplemented binary op {:?}: {:?} ({:?}), {:?} ({:?})\",\n+                    bin_op,\n+                    left,\n+                    left_kind,\n+                    right,\n+                    right_kind\n+                );\n+                return err!(Unimplemented(msg));\n+            }\n+        };\n+\n+        Ok((val, false))\n+    }\n+}\n+\n+pub fn unary_op<'tcx>(\n+    un_op: mir::UnOp,\n+    val: PrimVal,\n+    val_kind: PrimValKind,\n+) -> EvalResult<'tcx, PrimVal> {\n+    use rustc::mir::UnOp::*;\n+    use rustc::mir::interpret::PrimValKind::*;\n+\n+    let bytes = val.to_bytes()?;\n+\n+    let result_bytes = match (un_op, val_kind) {\n+        (Not, Bool) => !val.to_bool()? as u128,\n+\n+        (Not, U8) => !(bytes as u8) as u128,\n+        (Not, U16) => !(bytes as u16) as u128,\n+        (Not, U32) => !(bytes as u32) as u128,\n+        (Not, U64) => !(bytes as u64) as u128,\n+        (Not, U128) => !bytes,\n+\n+        (Not, I8) => !(bytes as i8) as u128,\n+        (Not, I16) => !(bytes as i16) as u128,\n+        (Not, I32) => !(bytes as i32) as u128,\n+        (Not, I64) => !(bytes as i64) as u128,\n+        (Not, I128) => !(bytes as i128) as u128,\n+\n+        (Neg, I8) => -(bytes as i8) as u128,\n+        (Neg, I16) => -(bytes as i16) as u128,\n+        (Neg, I32) => -(bytes as i32) as u128,\n+        (Neg, I64) => -(bytes as i64) as u128,\n+        (Neg, I128) => -(bytes as i128) as u128,\n+\n+        (Neg, F32) => (-bytes_to_f32(bytes)).bits,\n+        (Neg, F64) => (-bytes_to_f64(bytes)).bits,\n+\n+        _ => {\n+            let msg = format!(\"unimplemented unary op: {:?}, {:?}\", un_op, val);\n+            return err!(Unimplemented(msg));\n+        }\n+    };\n+\n+    Ok(PrimVal::Bytes(result_bytes))\n+}"}, {"sha": "0e44b414d7fe5ce98eb79d691868fa67a3e91363", "filename": "src/librustc_mir/interpret/place.rs", "status": "added", "additions": 428, "deletions": 0, "changes": 428, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fplace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fplace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fplace.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,428 @@\n+use rustc::mir;\n+use rustc::ty::{self, Ty};\n+use rustc::ty::layout::{LayoutOf, TyLayout};\n+use rustc_data_structures::indexed_vec::Idx;\n+use rustc::mir::interpret::{GlobalId, PtrAndAlign};\n+\n+use rustc::mir::interpret::{Value, PrimVal, EvalResult, Pointer, MemoryPointer};\n+use super::{EvalContext, Machine, ValTy};\n+use interpret::memory::HasMemory;\n+\n+#[derive(Copy, Clone, Debug)]\n+pub enum Place {\n+    /// An place referring to a value allocated in the `Memory` system.\n+    Ptr {\n+        /// An place may have an invalid (integral or undef) pointer,\n+        /// since it might be turned back into a reference\n+        /// before ever being dereferenced.\n+        ptr: PtrAndAlign,\n+        extra: PlaceExtra,\n+    },\n+\n+    /// An place referring to a value on the stack. Represented by a stack frame index paired with\n+    /// a Mir local index.\n+    Local { frame: usize, local: mir::Local },\n+}\n+\n+#[derive(Copy, Clone, Debug, Eq, PartialEq)]\n+pub enum PlaceExtra {\n+    None,\n+    Length(u64),\n+    Vtable(MemoryPointer),\n+    DowncastVariant(usize),\n+}\n+\n+impl<'tcx> Place {\n+    /// Produces an Place that will error if attempted to be read from\n+    pub fn undef() -> Self {\n+        Self::from_primval_ptr(PrimVal::Undef.into())\n+    }\n+\n+    pub fn from_primval_ptr(ptr: Pointer) -> Self {\n+        Place::Ptr {\n+            ptr: PtrAndAlign { ptr, aligned: true },\n+            extra: PlaceExtra::None,\n+        }\n+    }\n+\n+    pub fn from_ptr(ptr: MemoryPointer) -> Self {\n+        Self::from_primval_ptr(ptr.into())\n+    }\n+\n+    pub fn to_ptr_extra_aligned(self) -> (PtrAndAlign, PlaceExtra) {\n+        match self {\n+            Place::Ptr { ptr, extra } => (ptr, extra),\n+            _ => bug!(\"to_ptr_and_extra: expected Place::Ptr, got {:?}\", self),\n+\n+        }\n+    }\n+\n+    pub fn to_ptr(self) -> EvalResult<'tcx, MemoryPointer> {\n+        let (ptr, extra) = self.to_ptr_extra_aligned();\n+        // At this point, we forget about the alignment information -- the place has been turned into a reference,\n+        // and no matter where it came from, it now must be aligned.\n+        assert_eq!(extra, PlaceExtra::None);\n+        ptr.to_ptr()\n+    }\n+\n+    pub(super) fn elem_ty_and_len(self, ty: Ty<'tcx>) -> (Ty<'tcx>, u64) {\n+        match ty.sty {\n+            ty::TyArray(elem, n) => (elem, n.val.to_const_int().unwrap().to_u64().unwrap() as u64),\n+\n+            ty::TySlice(elem) => {\n+                match self {\n+                    Place::Ptr { extra: PlaceExtra::Length(len), .. } => (elem, len),\n+                    _ => {\n+                        bug!(\n+                            \"elem_ty_and_len of a TySlice given non-slice place: {:?}\",\n+                            self\n+                        )\n+                    }\n+                }\n+            }\n+\n+            _ => bug!(\"elem_ty_and_len expected array or slice, got {:?}\", ty),\n+        }\n+    }\n+}\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    /// Reads a value from the place without going through the intermediate step of obtaining\n+    /// a `miri::Place`\n+    pub fn try_read_place(\n+        &mut self,\n+        place: &mir::Place<'tcx>,\n+    ) -> EvalResult<'tcx, Option<Value>> {\n+        use rustc::mir::Place::*;\n+        match *place {\n+            // Might allow this in the future, right now there's no way to do this from Rust code anyway\n+            Local(mir::RETURN_PLACE) => err!(ReadFromReturnPointer),\n+            // Directly reading a local will always succeed\n+            Local(local) => self.frame().get_local(local).map(Some),\n+            // Directly reading a static will always succeed\n+            Static(ref static_) => {\n+                let instance = ty::Instance::mono(self.tcx, static_.def_id);\n+                let cid = GlobalId {\n+                    instance,\n+                    promoted: None,\n+                };\n+                Ok(Some(Value::ByRef(\n+                    self.tcx.interpret_interner.borrow().get_cached(cid).expect(\"global not cached\"),\n+                )))\n+            }\n+            Projection(ref proj) => self.try_read_place_projection(proj),\n+        }\n+    }\n+\n+    fn try_read_place_projection(\n+        &mut self,\n+        proj: &mir::PlaceProjection<'tcx>,\n+    ) -> EvalResult<'tcx, Option<Value>> {\n+        use rustc::mir::ProjectionElem::*;\n+        let base = match self.try_read_place(&proj.base)? {\n+            Some(base) => base,\n+            None => return Ok(None),\n+        };\n+        let base_ty = self.place_ty(&proj.base);\n+        match proj.elem {\n+            Field(field, _) => {\n+                let base_layout = self.layout_of(base_ty)?;\n+                let field_index = field.index();\n+                let field = base_layout.field(&self, field_index)?;\n+                let offset = base_layout.fields.offset(field_index);\n+                match base {\n+                    // the field covers the entire type\n+                    Value::ByValPair(..) |\n+                    Value::ByVal(_) if offset.bytes() == 0 && field.size == base_layout.size => Ok(Some(base)),\n+                    // split fat pointers, 2 element tuples, ...\n+                    Value::ByValPair(a, b) if base_layout.fields.count() == 2 => {\n+                        let val = [a, b][field_index];\n+                        Ok(Some(Value::ByVal(val)))\n+                    },\n+                    _ => Ok(None),\n+                }\n+            },\n+            // The NullablePointer cases should work fine, need to take care for normal enums\n+            Downcast(..) |\n+            Subslice { .. } |\n+            // reading index 0 or index 1 from a ByVal or ByVal pair could be optimized\n+            ConstantIndex { .. } | Index(_) |\n+            // No way to optimize this projection any better than the normal place path\n+            Deref => Ok(None),\n+        }\n+    }\n+\n+    /// Returns a value and (in case of a ByRef) if we are supposed to use aligned accesses.\n+    pub(super) fn eval_and_read_place(\n+        &mut self,\n+        place: &mir::Place<'tcx>,\n+    ) -> EvalResult<'tcx, Value> {\n+        // Shortcut for things like accessing a fat pointer's field,\n+        // which would otherwise (in the `eval_place` path) require moving a `ByValPair` to memory\n+        // and returning an `Place::Ptr` to it\n+        if let Some(val) = self.try_read_place(place)? {\n+            return Ok(val);\n+        }\n+        let place = self.eval_place(place)?;\n+        self.read_place(place)\n+    }\n+\n+    pub fn read_place(&self, place: Place) -> EvalResult<'tcx, Value> {\n+        match place {\n+            Place::Ptr { ptr, extra } => {\n+                assert_eq!(extra, PlaceExtra::None);\n+                Ok(Value::ByRef(ptr))\n+            }\n+            Place::Local { frame, local } => self.stack[frame].get_local(local),\n+        }\n+    }\n+\n+    pub fn eval_place(&mut self, mir_place: &mir::Place<'tcx>) -> EvalResult<'tcx, Place> {\n+        use rustc::mir::Place::*;\n+        let place = match *mir_place {\n+            Local(mir::RETURN_PLACE) => self.frame().return_place,\n+            Local(local) => Place::Local {\n+                frame: self.cur_frame(),\n+                local,\n+            },\n+\n+            Static(ref static_) => {\n+                let instance = ty::Instance::mono(self.tcx, static_.def_id);\n+                let gid = GlobalId {\n+                    instance,\n+                    promoted: None,\n+                };\n+                Place::Ptr {\n+                    ptr: self.tcx.interpret_interner.borrow().get_cached(gid).expect(\"uncached global\"),\n+                    extra: PlaceExtra::None,\n+                }\n+            }\n+\n+            Projection(ref proj) => {\n+                let ty = self.place_ty(&proj.base);\n+                let place = self.eval_place(&proj.base)?;\n+                return self.eval_place_projection(place, ty, &proj.elem);\n+            }\n+        };\n+\n+        if log_enabled!(::log::LogLevel::Trace) {\n+            self.dump_local(place);\n+        }\n+\n+        Ok(place)\n+    }\n+\n+    pub fn place_field(\n+        &mut self,\n+        base: Place,\n+        field: mir::Field,\n+        mut base_layout: TyLayout<'tcx>,\n+    ) -> EvalResult<'tcx, (Place, TyLayout<'tcx>)> {\n+        match base {\n+            Place::Ptr { extra: PlaceExtra::DowncastVariant(variant_index), .. } => {\n+                base_layout = base_layout.for_variant(&self, variant_index);\n+            }\n+            _ => {}\n+        }\n+        let field_index = field.index();\n+        let field = base_layout.field(&self, field_index)?;\n+        let offset = base_layout.fields.offset(field_index);\n+\n+        // Do not allocate in trivial cases\n+        let (base_ptr, base_extra) = match base {\n+            Place::Ptr { ptr, extra } => (ptr, extra),\n+            Place::Local { frame, local } => {\n+                match self.stack[frame].get_local(local)? {\n+                    // in case the field covers the entire type, just return the value\n+                    Value::ByVal(_) if offset.bytes() == 0 &&\n+                                       field.size == base_layout.size => {\n+                        return Ok((base, field));\n+                    }\n+                    Value::ByRef { .. } |\n+                    Value::ByValPair(..) |\n+                    Value::ByVal(_) => self.force_allocation(base)?.to_ptr_extra_aligned(),\n+                }\n+            }\n+        };\n+\n+        let offset = match base_extra {\n+            PlaceExtra::Vtable(tab) => {\n+                let (_, align) = self.size_and_align_of_dst(\n+                    base_layout.ty,\n+                    base_ptr.ptr.to_value_with_vtable(tab),\n+                )?;\n+                offset.abi_align(align).bytes()\n+            }\n+            _ => offset.bytes(),\n+        };\n+\n+        let mut ptr = base_ptr.offset(offset, &self)?;\n+        // if we were unaligned, stay unaligned\n+        // no matter what we were, if we are packed, we must not be aligned anymore\n+        ptr.aligned &= !base_layout.is_packed();\n+\n+        let extra = if !field.is_unsized() {\n+            PlaceExtra::None\n+        } else {\n+            match base_extra {\n+                PlaceExtra::None => bug!(\"expected fat pointer\"),\n+                PlaceExtra::DowncastVariant(..) => {\n+                    bug!(\"Rust doesn't support unsized fields in enum variants\")\n+                }\n+                PlaceExtra::Vtable(_) |\n+                PlaceExtra::Length(_) => {}\n+            }\n+            base_extra\n+        };\n+\n+        Ok((Place::Ptr { ptr, extra }, field))\n+    }\n+\n+    pub fn val_to_place(&self, val: Value, ty: Ty<'tcx>) -> EvalResult<'tcx, Place> {\n+        Ok(match self.tcx.struct_tail(ty).sty {\n+            ty::TyDynamic(..) => {\n+                let (ptr, vtable) = self.into_ptr_vtable_pair(val)?;\n+                Place::Ptr {\n+                    ptr: PtrAndAlign { ptr, aligned: true },\n+                    extra: PlaceExtra::Vtable(vtable),\n+                }\n+            }\n+            ty::TyStr | ty::TySlice(_) => {\n+                let (ptr, len) = self.into_slice(val)?;\n+                Place::Ptr {\n+                    ptr: PtrAndAlign { ptr, aligned: true },\n+                    extra: PlaceExtra::Length(len),\n+                }\n+            }\n+            _ => Place::from_primval_ptr(self.into_ptr(val)?),\n+        })\n+    }\n+\n+    pub fn place_index(\n+        &mut self,\n+        base: Place,\n+        outer_ty: Ty<'tcx>,\n+        n: u64,\n+    ) -> EvalResult<'tcx, Place> {\n+        // Taking the outer type here may seem odd; it's needed because for array types, the outer type gives away the length.\n+        let base = self.force_allocation(base)?;\n+        let (base_ptr, _) = base.to_ptr_extra_aligned();\n+\n+        let (elem_ty, len) = base.elem_ty_and_len(outer_ty);\n+        let elem_size = self.layout_of(elem_ty)?.size.bytes();\n+        assert!(\n+            n < len,\n+            \"Tried to access element {} of array/slice with length {}\",\n+            n,\n+            len\n+        );\n+        let ptr = base_ptr.offset(n * elem_size, &*self)?;\n+        Ok(Place::Ptr {\n+            ptr,\n+            extra: PlaceExtra::None,\n+        })\n+    }\n+\n+    pub(super) fn place_downcast(\n+        &mut self,\n+        base: Place,\n+        variant: usize,\n+    ) -> EvalResult<'tcx, Place> {\n+        // FIXME(solson)\n+        let base = self.force_allocation(base)?;\n+        let (ptr, _) = base.to_ptr_extra_aligned();\n+        let extra = PlaceExtra::DowncastVariant(variant);\n+        Ok(Place::Ptr { ptr, extra })\n+    }\n+\n+    pub fn eval_place_projection(\n+        &mut self,\n+        base: Place,\n+        base_ty: Ty<'tcx>,\n+        proj_elem: &mir::ProjectionElem<'tcx, mir::Local, Ty<'tcx>>,\n+    ) -> EvalResult<'tcx, Place> {\n+        use rustc::mir::ProjectionElem::*;\n+        let (ptr, extra) = match *proj_elem {\n+            Field(field, _) => {\n+                let layout = self.layout_of(base_ty)?;\n+                return Ok(self.place_field(base, field, layout)?.0);\n+            }\n+\n+            Downcast(_, variant) => {\n+                return self.place_downcast(base, variant);\n+            }\n+\n+            Deref => {\n+                let val = self.read_place(base)?;\n+\n+                let pointee_type = match base_ty.sty {\n+                    ty::TyRawPtr(ref tam) |\n+                    ty::TyRef(_, ref tam) => tam.ty,\n+                    ty::TyAdt(def, _) if def.is_box() => base_ty.boxed_ty(),\n+                    _ => bug!(\"can only deref pointer types\"),\n+                };\n+\n+                trace!(\"deref to {} on {:?}\", pointee_type, val);\n+\n+                return self.val_to_place(val, pointee_type);\n+            }\n+\n+            Index(local) => {\n+                let value = self.frame().get_local(local)?;\n+                let ty = self.tcx.types.usize;\n+                let n = self.value_to_primval(ValTy { value, ty })?.to_u64()?;\n+                return self.place_index(base, base_ty, n);\n+            }\n+\n+            ConstantIndex {\n+                offset,\n+                min_length,\n+                from_end,\n+            } => {\n+                // FIXME(solson)\n+                let base = self.force_allocation(base)?;\n+                let (base_ptr, _) = base.to_ptr_extra_aligned();\n+\n+                let (elem_ty, n) = base.elem_ty_and_len(base_ty);\n+                let elem_size = self.layout_of(elem_ty)?.size.bytes();\n+                assert!(n >= min_length as u64);\n+\n+                let index = if from_end {\n+                    n - u64::from(offset)\n+                } else {\n+                    u64::from(offset)\n+                };\n+\n+                let ptr = base_ptr.offset(index * elem_size, &self)?;\n+                (ptr, PlaceExtra::None)\n+            }\n+\n+            Subslice { from, to } => {\n+                // FIXME(solson)\n+                let base = self.force_allocation(base)?;\n+                let (base_ptr, _) = base.to_ptr_extra_aligned();\n+\n+                let (elem_ty, n) = base.elem_ty_and_len(base_ty);\n+                let elem_size = self.layout_of(elem_ty)?.size.bytes();\n+                assert!(u64::from(from) <= n - u64::from(to));\n+                let ptr = base_ptr.offset(u64::from(from) * elem_size, &self)?;\n+                // sublicing arrays produces arrays\n+                let extra = if self.type_is_sized(base_ty) {\n+                    PlaceExtra::None\n+                } else {\n+                    PlaceExtra::Length(n - u64::from(to) - u64::from(from))\n+                };\n+                (ptr, extra)\n+            }\n+        };\n+\n+        Ok(Place::Ptr { ptr, extra })\n+    }\n+\n+    pub fn place_ty(&self, place: &mir::Place<'tcx>) -> Ty<'tcx> {\n+        self.monomorphize(\n+            place.ty(self.mir(), self.tcx).to_ty(self.tcx),\n+            self.substs(),\n+        )\n+    }\n+}"}, {"sha": "352e151e3a19566a5319d194bc403ec325ee0954", "filename": "src/librustc_mir/interpret/step.rs", "status": "added", "additions": 349, "deletions": 0, "changes": 349, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fstep.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fstep.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fstep.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,349 @@\n+//! This module contains the `EvalContext` methods for executing a single step of the interpreter.\n+//!\n+//! The main entry point is the `step` method.\n+\n+use rustc::hir;\n+use rustc::mir::visit::{Visitor, PlaceContext};\n+use rustc::mir;\n+use rustc::ty::{self, Instance};\n+use rustc::ty::layout::LayoutOf;\n+use rustc::middle::const_val::ConstVal;\n+use rustc::mir::interpret::{PtrAndAlign, GlobalId};\n+\n+use rustc::mir::interpret::{EvalResult, EvalErrorKind};\n+use super::{EvalContext, StackPopCleanup, Place, Machine};\n+\n+use syntax::codemap::Span;\n+use syntax::ast::Mutability;\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    pub fn inc_step_counter_and_check_limit(&mut self, n: u64) -> EvalResult<'tcx> {\n+        self.steps_remaining = self.steps_remaining.saturating_sub(n);\n+        if self.steps_remaining > 0 {\n+            Ok(())\n+        } else {\n+            err!(ExecutionTimeLimitReached)\n+        }\n+    }\n+\n+    /// Returns true as long as there are more things to do.\n+    pub fn step(&mut self) -> EvalResult<'tcx, bool> {\n+        self.inc_step_counter_and_check_limit(1)?;\n+        if self.stack.is_empty() {\n+            return Ok(false);\n+        }\n+\n+        let block = self.frame().block;\n+        let stmt_id = self.frame().stmt;\n+        let mir = self.mir();\n+        let basic_block = &mir.basic_blocks()[block];\n+\n+        let old_frames = self.cur_frame();\n+\n+        if let Some(stmt) = basic_block.statements.get(stmt_id) {\n+            let mut new = Ok(false);\n+            ConstantExtractor {\n+                span: stmt.source_info.span,\n+                instance: self.frame().instance,\n+                ecx: self,\n+                mir,\n+                new_constant: &mut new,\n+            }.visit_statement(\n+                block,\n+                stmt,\n+                mir::Location {\n+                    block,\n+                    statement_index: stmt_id,\n+                },\n+            );\n+            // if ConstantExtractor added a new frame, we don't execute anything here\n+            // but await the next call to step\n+            if !new? {\n+                assert_eq!(old_frames, self.cur_frame());\n+                self.statement(stmt)?;\n+            }\n+            return Ok(true);\n+        }\n+\n+        let terminator = basic_block.terminator();\n+        let mut new = Ok(false);\n+        ConstantExtractor {\n+            span: terminator.source_info.span,\n+            instance: self.frame().instance,\n+            ecx: self,\n+            mir,\n+            new_constant: &mut new,\n+        }.visit_terminator(\n+            block,\n+            terminator,\n+            mir::Location {\n+                block,\n+                statement_index: stmt_id,\n+            },\n+        );\n+        // if ConstantExtractor added a new frame, we don't execute anything here\n+        // but await the next call to step\n+        if !new? {\n+            assert_eq!(old_frames, self.cur_frame());\n+            self.terminator(terminator)?;\n+        }\n+        Ok(true)\n+    }\n+\n+    fn statement(&mut self, stmt: &mir::Statement<'tcx>) -> EvalResult<'tcx> {\n+        trace!(\"{:?}\", stmt);\n+\n+        use rustc::mir::StatementKind::*;\n+\n+        // Some statements (e.g. box) push new stack frames.  We have to record the stack frame number\n+        // *before* executing the statement.\n+        let frame_idx = self.cur_frame();\n+\n+        match stmt.kind {\n+            Assign(ref place, ref rvalue) => self.eval_rvalue_into_place(rvalue, place)?,\n+\n+            SetDiscriminant {\n+                ref place,\n+                variant_index,\n+            } => {\n+                let dest = self.eval_place(place)?;\n+                let dest_ty = self.place_ty(place);\n+                self.write_discriminant_value(dest_ty, dest, variant_index)?;\n+            }\n+\n+            // Mark locals as alive\n+            StorageLive(local) => {\n+                let old_val = self.frame_mut().storage_live(local)?;\n+                self.deallocate_local(old_val)?;\n+            }\n+\n+            // Mark locals as dead\n+            StorageDead(local) => {\n+                let old_val = self.frame_mut().storage_dead(local)?;\n+                self.deallocate_local(old_val)?;\n+            }\n+\n+            // Validity checks.\n+            Validate(op, ref places) => {\n+                for operand in places {\n+                    M::validation_op(self, op, operand)?;\n+                }\n+            }\n+            EndRegion(ce) => {\n+                M::end_region(self, Some(ce))?;\n+            }\n+\n+            // Defined to do nothing. These are added by optimization passes, to avoid changing the\n+            // size of MIR constantly.\n+            Nop => {}\n+\n+            InlineAsm { .. } => return err!(InlineAsm),\n+        }\n+\n+        self.stack[frame_idx].stmt += 1;\n+        Ok(())\n+    }\n+\n+    fn terminator(&mut self, terminator: &mir::Terminator<'tcx>) -> EvalResult<'tcx> {\n+        trace!(\"{:?}\", terminator.kind);\n+        self.eval_terminator(terminator)?;\n+        if !self.stack.is_empty() {\n+            trace!(\"// {:?}\", self.frame().block);\n+        }\n+        Ok(())\n+    }\n+\n+    /// returns `true` if a stackframe was pushed\n+    fn global_item(\n+        &mut self,\n+        instance: Instance<'tcx>,\n+        span: Span,\n+        mutability: Mutability,\n+    ) -> EvalResult<'tcx, bool> {\n+        debug!(\"global_item: {:?}\", instance);\n+        let cid = GlobalId {\n+            instance,\n+            promoted: None,\n+        };\n+        if self.tcx.interpret_interner.borrow().get_cached(cid).is_some() {\n+            return Ok(false);\n+        }\n+        if self.tcx.has_attr(instance.def_id(), \"linkage\") {\n+            M::global_item_with_linkage(self, cid.instance, mutability)?;\n+            return Ok(false);\n+        }\n+        // FIXME(eddyb) use `Instance::ty` when it becomes available.\n+        let instance_ty =\n+            self.monomorphize(instance.def.def_ty(self.tcx), instance.substs);\n+        let layout = self.layout_of(instance_ty)?;\n+        assert!(!layout.is_unsized());\n+        let ptr = self.memory.allocate(\n+            layout.size.bytes(),\n+            layout.align.abi(),\n+            None,\n+        )?;\n+        self.tcx.interpret_interner.borrow_mut().cache(\n+            cid,\n+            PtrAndAlign {\n+                ptr: ptr.into(),\n+                aligned: !layout.is_packed(),\n+            },\n+        );\n+        let internally_mutable = !layout.ty.is_freeze(self.tcx, self.param_env, span);\n+        let mutability = if mutability == Mutability::Mutable || internally_mutable {\n+            Mutability::Mutable\n+        } else {\n+            Mutability::Immutable\n+        };\n+        let cleanup = StackPopCleanup::MarkStatic(mutability);\n+        let name = ty::tls::with(|tcx| tcx.item_path_str(instance.def_id()));\n+        trace!(\"pushing stack frame for global: {}\", name);\n+        let mir = self.load_mir(instance.def)?;\n+        self.push_stack_frame(\n+            instance,\n+            span,\n+            mir,\n+            Place::from_ptr(ptr),\n+            cleanup,\n+        )?;\n+        Ok(true)\n+    }\n+}\n+\n+struct ConstantExtractor<'a, 'b: 'a, 'tcx: 'b, M: Machine<'tcx> + 'a> {\n+    span: Span,\n+    ecx: &'a mut EvalContext<'b, 'tcx, M>,\n+    mir: &'tcx mir::Mir<'tcx>,\n+    instance: ty::Instance<'tcx>,\n+    // Whether a stackframe for a new constant has been pushed\n+    new_constant: &'a mut EvalResult<'tcx, bool>,\n+}\n+\n+impl<'a, 'b, 'tcx, M: Machine<'tcx>> ConstantExtractor<'a, 'b, 'tcx, M> {\n+    fn try<F: FnOnce(&mut Self) -> EvalResult<'tcx, bool>>(&mut self, f: F) {\n+        match *self.new_constant {\n+            // already computed a constant, don't do more than one per iteration\n+            Ok(true) => {},\n+            // no constants computed yet\n+            Ok(false) => *self.new_constant = f(self),\n+            // error happened, abort the visitor traversing\n+            Err(_) => {},\n+        }\n+    }\n+}\n+\n+impl<'a, 'b, 'tcx, M: Machine<'tcx>> Visitor<'tcx> for ConstantExtractor<'a, 'b, 'tcx, M> {\n+    fn visit_constant(&mut self, constant: &mir::Constant<'tcx>, location: mir::Location) {\n+        self.super_constant(constant, location);\n+        self.try(|this| {\n+            match constant.literal {\n+                // already computed by rustc\n+                mir::Literal::Value { value: &ty::Const { val: ConstVal::Unevaluated(def_id, substs), .. } } => {\n+                    debug!(\"global_item: {:?}, {:#?}\", def_id, substs);\n+                    let substs = this.ecx.tcx.trans_apply_param_substs(this.instance.substs, &substs);\n+                    debug!(\"global_item_new_substs: {:#?}\", substs);\n+                    debug!(\"global_item_param_env: {:#?}\", this.ecx.param_env);\n+                    let instance = Instance::resolve(\n+                        this.ecx.tcx,\n+                        this.ecx.param_env,\n+                        def_id,\n+                        substs,\n+                    ).ok_or(EvalErrorKind::TypeckError)?; // turn error prop into a panic to expose associated type in const issue\n+                    this.ecx.global_item(\n+                        instance,\n+                        constant.span,\n+                        Mutability::Immutable,\n+                    )\n+                }\n+                mir::Literal::Value { .. } => Ok(false),\n+                mir::Literal::Promoted { index } => {\n+                    let cid = GlobalId {\n+                        instance: this.instance,\n+                        promoted: Some(index),\n+                    };\n+                    if this.ecx.tcx.interpret_interner.borrow().get_cached(cid).is_some() {\n+                        return Ok(false);\n+                    }\n+                    let mir = &this.mir.promoted[index];\n+                    let ty = this.ecx.monomorphize(mir.return_ty(), this.instance.substs);\n+                    let layout = this.ecx.layout_of(ty)?;\n+                    assert!(!layout.is_unsized());\n+                    let ptr = this.ecx.memory.allocate(\n+                        layout.size.bytes(),\n+                        layout.align.abi(),\n+                        None,\n+                    )?;\n+                    this.ecx.tcx.interpret_interner.borrow_mut().cache(\n+                        cid,\n+                        PtrAndAlign {\n+                            ptr: ptr.into(),\n+                            aligned: !layout.is_packed(),\n+                        },\n+                    );\n+                    trace!(\"pushing stack frame for {:?}\", index);\n+                    this.ecx.push_stack_frame(\n+                        this.instance,\n+                        constant.span,\n+                        mir,\n+                        Place::from_ptr(ptr),\n+                        StackPopCleanup::MarkStatic(Mutability::Immutable),\n+                    )?;\n+                    Ok(true)\n+                }\n+            }\n+        });\n+    }\n+\n+    fn visit_place(\n+        &mut self,\n+        place: &mir::Place<'tcx>,\n+        context: PlaceContext<'tcx>,\n+        location: mir::Location,\n+    ) {\n+        self.super_place(place, context, location);\n+        self.try(|this| {\n+            if let mir::Place::Static(ref static_) = *place {\n+                let def_id = static_.def_id;\n+                let span = this.span;\n+                if let Some(node_item) = this.ecx.tcx.hir.get_if_local(def_id) {\n+                    if let hir::map::Node::NodeItem(&hir::Item { ref node, .. }) = node_item {\n+                        if let hir::ItemStatic(_, m, _) = *node {\n+                            let instance = Instance::mono(this.ecx.tcx, def_id);\n+                            this.ecx.global_item(\n+                                instance,\n+                                span,\n+                                if m == hir::MutMutable {\n+                                    Mutability::Mutable\n+                                } else {\n+                                    Mutability::Immutable\n+                                },\n+                            )\n+                        } else {\n+                            bug!(\"static def id doesn't point to static\");\n+                        }\n+                    } else {\n+                        bug!(\"static def id doesn't point to item\");\n+                    }\n+                } else {\n+                    let def = this.ecx.tcx.describe_def(def_id).expect(\"static not found\");\n+                    if let hir::def::Def::Static(_, mutable) = def {\n+                        let instance = Instance::mono(this.ecx.tcx, def_id);\n+                        this.ecx.global_item(\n+                            instance,\n+                            span,\n+                            if mutable {\n+                                Mutability::Mutable\n+                            } else {\n+                                Mutability::Immutable\n+                            },\n+                        )\n+                    } else {\n+                        bug!(\"static found but isn't a static: {:?}\", def);\n+                    }\n+                }\n+            } else {\n+                Ok(false)\n+            }\n+        });\n+    }\n+}"}, {"sha": "5db46149834d24b82ef353f6bb20aab962c6241c", "filename": "src/librustc_mir/interpret/terminator/drop.rs", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fdrop.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fdrop.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fdrop.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,83 @@\n+use rustc::mir::BasicBlock;\n+use rustc::ty::{self, Ty};\n+use syntax::codemap::Span;\n+\n+use rustc::mir::interpret::{EvalResult, PrimVal, Value};\n+use interpret::{Machine, ValTy, EvalContext, Place, PlaceExtra};\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    pub(crate) fn drop_place(\n+        &mut self,\n+        place: Place,\n+        instance: ty::Instance<'tcx>,\n+        ty: Ty<'tcx>,\n+        span: Span,\n+        target: BasicBlock,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\"drop_place: {:#?}\", place);\n+        // We take the address of the object.  This may well be unaligned, which is fine for us here.\n+        // However, unaligned accesses will probably make the actual drop implementation fail -- a problem shared\n+        // by rustc.\n+        let val = match self.force_allocation(place)? {\n+            Place::Ptr {\n+                ptr,\n+                extra: PlaceExtra::Vtable(vtable),\n+            } => ptr.ptr.to_value_with_vtable(vtable),\n+            Place::Ptr {\n+                ptr,\n+                extra: PlaceExtra::Length(len),\n+            } => ptr.ptr.to_value_with_len(len),\n+            Place::Ptr {\n+                ptr,\n+                extra: PlaceExtra::None,\n+            } => ptr.ptr.to_value(),\n+            _ => bug!(\"force_allocation broken\"),\n+        };\n+        self.drop(val, instance, ty, span, target)\n+    }\n+\n+    fn drop(\n+        &mut self,\n+        arg: Value,\n+        instance: ty::Instance<'tcx>,\n+        ty: Ty<'tcx>,\n+        span: Span,\n+        target: BasicBlock,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\"drop: {:#?}, {:?}, {:?}\", arg, ty.sty, instance.def);\n+\n+        let instance = match ty.sty {\n+            ty::TyDynamic(..) => {\n+                let vtable = match arg {\n+                    Value::ByValPair(_, PrimVal::Ptr(vtable)) => vtable,\n+                    _ => bug!(\"expected fat ptr, got {:?}\", arg),\n+                };\n+                match self.read_drop_type_from_vtable(vtable)? {\n+                    Some(func) => func,\n+                    // no drop fn -> bail out\n+                    None => {\n+                        self.goto_block(target);\n+                        return Ok(())\n+                    },\n+                }\n+            }\n+            _ => instance,\n+        };\n+\n+        // the drop function expects a reference to the value\n+        let valty = ValTy {\n+            value: arg,\n+            ty: self.tcx.mk_mut_ptr(ty),\n+        };\n+\n+        let fn_sig = self.tcx.fn_sig(instance.def_id()).skip_binder().clone();\n+\n+        self.eval_fn_call(\n+            instance,\n+            Some((Place::undef(), target)),\n+            &vec![valty],\n+            span,\n+            fn_sig,\n+        )\n+    }\n+}"}, {"sha": "1cdfe1ff9ceacce0a81268c9c074698acbdabd10", "filename": "src/librustc_mir/interpret/terminator/mod.rs", "status": "added", "additions": 420, "deletions": 0, "changes": 420, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fterminator%2Fmod.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,420 @@\n+use rustc::mir;\n+use rustc::ty::{self, Ty};\n+use rustc::ty::layout::LayoutOf;\n+use syntax::codemap::Span;\n+use syntax::abi::Abi;\n+\n+use rustc::mir::interpret::{PtrAndAlign, EvalResult, PrimVal, Value};\n+use super::{EvalContext, eval_context,\n+            Place, Machine, ValTy};\n+\n+use rustc_data_structures::indexed_vec::Idx;\n+use interpret::memory::HasMemory;\n+\n+mod drop;\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    pub fn goto_block(&mut self, target: mir::BasicBlock) {\n+        self.frame_mut().block = target;\n+        self.frame_mut().stmt = 0;\n+    }\n+\n+    pub(super) fn eval_terminator(\n+        &mut self,\n+        terminator: &mir::Terminator<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        use rustc::mir::TerminatorKind::*;\n+        match terminator.kind {\n+            Return => {\n+                self.dump_local(self.frame().return_place);\n+                self.pop_stack_frame()?\n+            }\n+\n+            Goto { target } => self.goto_block(target),\n+\n+            SwitchInt {\n+                ref discr,\n+                ref values,\n+                ref targets,\n+                ..\n+            } => {\n+                // FIXME(CTFE): forbid branching\n+                let discr_val = self.eval_operand(discr)?;\n+                let discr_prim = self.value_to_primval(discr_val)?;\n+\n+                // Branch to the `otherwise` case by default, if no match is found.\n+                let mut target_block = targets[targets.len() - 1];\n+\n+                for (index, const_int) in values.iter().enumerate() {\n+                    let prim = PrimVal::Bytes(const_int.to_u128_unchecked());\n+                    if discr_prim.to_bytes()? == prim.to_bytes()? {\n+                        target_block = targets[index];\n+                        break;\n+                    }\n+                }\n+\n+                self.goto_block(target_block);\n+            }\n+\n+            Call {\n+                ref func,\n+                ref args,\n+                ref destination,\n+                ..\n+            } => {\n+                let destination = match *destination {\n+                    Some((ref lv, target)) => Some((self.eval_place(lv)?, target)),\n+                    None => None,\n+                };\n+\n+                let func = self.eval_operand(func)?;\n+                let (fn_def, sig) = match func.ty.sty {\n+                    ty::TyFnPtr(sig) => {\n+                        let fn_ptr = self.value_to_primval(func)?.to_ptr()?;\n+                        let instance = self.memory.get_fn(fn_ptr)?;\n+                        // FIXME(eddyb) use `Instance::ty` when it becomes available.\n+                        let instance_ty =\n+                            self.monomorphize(instance.def.def_ty(self.tcx), instance.substs);\n+                        match instance_ty.sty {\n+                            ty::TyFnDef(..) => {\n+                                let real_sig = instance_ty.fn_sig(self.tcx);\n+                                let sig = self.tcx.erase_late_bound_regions_and_normalize(&sig);\n+                                let real_sig = self.tcx.erase_late_bound_regions_and_normalize(&real_sig);\n+                                if !self.check_sig_compat(sig, real_sig)? {\n+                                    return err!(FunctionPointerTyMismatch(real_sig, sig));\n+                                }\n+                            }\n+                            ref other => bug!(\"instance def ty: {:?}\", other),\n+                        }\n+                        (instance, sig)\n+                    }\n+                    ty::TyFnDef(def_id, substs) => (\n+                        self.resolve(def_id, substs)?,\n+                        func.ty.fn_sig(self.tcx),\n+                    ),\n+                    _ => {\n+                        let msg = format!(\"can't handle callee of type {:?}\", func.ty);\n+                        return err!(Unimplemented(msg));\n+                    }\n+                };\n+                let args = self.operands_to_args(args)?;\n+                let sig = self.tcx.erase_late_bound_regions_and_normalize(&sig);\n+                self.eval_fn_call(\n+                    fn_def,\n+                    destination,\n+                    &args,\n+                    terminator.source_info.span,\n+                    sig,\n+                )?;\n+            }\n+\n+            Drop {\n+                ref location,\n+                target,\n+                ..\n+            } => {\n+                // FIXME(CTFE): forbid drop in const eval\n+                let place = self.eval_place(location)?;\n+                let ty = self.place_ty(location);\n+                let ty = self.tcx.trans_apply_param_substs(self.substs(), &ty);\n+                trace!(\"TerminatorKind::drop: {:?}, type {}\", location, ty);\n+\n+                let instance = eval_context::resolve_drop_in_place(self.tcx, ty);\n+                self.drop_place(\n+                    place,\n+                    instance,\n+                    ty,\n+                    terminator.source_info.span,\n+                    target,\n+                )?;\n+            }\n+\n+            Assert {\n+                ref cond,\n+                expected,\n+                ref msg,\n+                target,\n+                ..\n+            } => {\n+                let cond_val = self.eval_operand_to_primval(cond)?.to_bool()?;\n+                if expected == cond_val {\n+                    self.goto_block(target);\n+                } else {\n+                    use rustc::mir::AssertMessage::*;\n+                    return match *msg {\n+                        BoundsCheck { ref len, ref index } => {\n+                            let span = terminator.source_info.span;\n+                            let len = self.eval_operand_to_primval(len)\n+                                .expect(\"can't eval len\")\n+                                .to_u64()?;\n+                            let index = self.eval_operand_to_primval(index)\n+                                .expect(\"can't eval index\")\n+                                .to_u64()?;\n+                            err!(ArrayIndexOutOfBounds(span, len, index))\n+                        }\n+                        Math(ref err) => {\n+                            err!(Math(terminator.source_info.span, err.clone()))\n+                        }\n+                        GeneratorResumedAfterReturn |\n+                        GeneratorResumedAfterPanic => unimplemented!(),\n+                    };\n+                }\n+            }\n+\n+            Yield { .. } => unimplemented!(\"{:#?}\", terminator.kind),\n+            GeneratorDrop => unimplemented!(),\n+            DropAndReplace { .. } => unimplemented!(),\n+            Resume => unimplemented!(),\n+            FalseEdges { .. } => bug!(\"should have been eliminated by `simplify_branches` mir pass\"),\n+            Unreachable => return err!(Unreachable),\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Decides whether it is okay to call the method with signature `real_sig` using signature `sig`.\n+    /// FIXME: This should take into account the platform-dependent ABI description.\n+    fn check_sig_compat(\n+        &mut self,\n+        sig: ty::FnSig<'tcx>,\n+        real_sig: ty::FnSig<'tcx>,\n+    ) -> EvalResult<'tcx, bool> {\n+        fn check_ty_compat<'tcx>(ty: Ty<'tcx>, real_ty: Ty<'tcx>) -> bool {\n+            if ty == real_ty {\n+                return true;\n+            } // This is actually a fast pointer comparison\n+            return match (&ty.sty, &real_ty.sty) {\n+                // Permit changing the pointer type of raw pointers and references as well as\n+                // mutability of raw pointers.\n+                // TODO: Should not be allowed when fat pointers are involved.\n+                (&ty::TyRawPtr(_), &ty::TyRawPtr(_)) => true,\n+                (&ty::TyRef(_, _), &ty::TyRef(_, _)) => {\n+                    ty.is_mutable_pointer() == real_ty.is_mutable_pointer()\n+                }\n+                // rule out everything else\n+                _ => false,\n+            };\n+        }\n+\n+        if sig.abi == real_sig.abi && sig.variadic == real_sig.variadic &&\n+            sig.inputs_and_output.len() == real_sig.inputs_and_output.len() &&\n+            sig.inputs_and_output\n+                .iter()\n+                .zip(real_sig.inputs_and_output)\n+                .all(|(ty, real_ty)| check_ty_compat(ty, real_ty))\n+        {\n+            // Definitely good.\n+            return Ok(true);\n+        }\n+\n+        if sig.variadic || real_sig.variadic {\n+            // We're not touching this\n+            return Ok(false);\n+        }\n+\n+        // We need to allow what comes up when a non-capturing closure is cast to a fn().\n+        match (sig.abi, real_sig.abi) {\n+            (Abi::Rust, Abi::RustCall) // check the ABIs.  This makes the test here non-symmetric.\n+                if check_ty_compat(sig.output(), real_sig.output()) && real_sig.inputs_and_output.len() == 3 => {\n+                // First argument of real_sig must be a ZST\n+                let fst_ty = real_sig.inputs_and_output[0];\n+                if self.layout_of(fst_ty)?.is_zst() {\n+                    // Second argument must be a tuple matching the argument list of sig\n+                    let snd_ty = real_sig.inputs_and_output[1];\n+                    match snd_ty.sty {\n+                        ty::TyTuple(tys, _) if sig.inputs().len() == tys.len() =>\n+                            if sig.inputs().iter().zip(tys).all(|(ty, real_ty)| check_ty_compat(ty, real_ty)) {\n+                                return Ok(true)\n+                            },\n+                        _ => {}\n+                    }\n+                }\n+            }\n+            _ => {}\n+        };\n+\n+        // Nope, this doesn't work.\n+        return Ok(false);\n+    }\n+\n+    fn eval_fn_call(\n+        &mut self,\n+        instance: ty::Instance<'tcx>,\n+        destination: Option<(Place, mir::BasicBlock)>,\n+        args: &[ValTy<'tcx>],\n+        span: Span,\n+        sig: ty::FnSig<'tcx>,\n+    ) -> EvalResult<'tcx> {\n+        trace!(\"eval_fn_call: {:#?}\", instance);\n+        match instance.def {\n+            ty::InstanceDef::Intrinsic(..) => {\n+                let (ret, target) = match destination {\n+                    Some(dest) => dest,\n+                    _ => return err!(Unreachable),\n+                };\n+                let ty = sig.output();\n+                let layout = self.layout_of(ty)?;\n+                M::call_intrinsic(self, instance, args, ret, layout, target)?;\n+                self.dump_local(ret);\n+                Ok(())\n+            }\n+            // FIXME: figure out why we can't just go through the shim\n+            ty::InstanceDef::ClosureOnceShim { .. } => {\n+                if M::eval_fn_call(self, instance, destination, args, span, sig)? {\n+                    return Ok(());\n+                }\n+                let mut arg_locals = self.frame().mir.args_iter();\n+                match sig.abi {\n+                    // closure as closure once\n+                    Abi::RustCall => {\n+                        for (arg_local, &valty) in arg_locals.zip(args) {\n+                            let dest = self.eval_place(&mir::Place::Local(arg_local))?;\n+                            self.write_value(valty, dest)?;\n+                        }\n+                    }\n+                    // non capture closure as fn ptr\n+                    // need to inject zst ptr for closure object (aka do nothing)\n+                    // and need to pack arguments\n+                    Abi::Rust => {\n+                        trace!(\n+                            \"arg_locals: {:?}\",\n+                            self.frame().mir.args_iter().collect::<Vec<_>>()\n+                        );\n+                        trace!(\"args: {:?}\", args);\n+                        let local = arg_locals.nth(1).unwrap();\n+                        for (i, &valty) in args.into_iter().enumerate() {\n+                            let dest = self.eval_place(&mir::Place::Local(local).field(\n+                                mir::Field::new(i),\n+                                valty.ty,\n+                            ))?;\n+                            self.write_value(valty, dest)?;\n+                        }\n+                    }\n+                    _ => bug!(\"bad ABI for ClosureOnceShim: {:?}\", sig.abi),\n+                }\n+                Ok(())\n+            }\n+            ty::InstanceDef::FnPtrShim(..) |\n+            ty::InstanceDef::DropGlue(..) |\n+            ty::InstanceDef::CloneShim(..) |\n+            ty::InstanceDef::Item(_) => {\n+                // Push the stack frame, and potentially be entirely done if the call got hooked\n+                if M::eval_fn_call(self, instance, destination, args, span, sig)? {\n+                    return Ok(());\n+                }\n+\n+                // Pass the arguments\n+                let mut arg_locals = self.frame().mir.args_iter();\n+                trace!(\"ABI: {:?}\", sig.abi);\n+                trace!(\n+                    \"arg_locals: {:?}\",\n+                    self.frame().mir.args_iter().collect::<Vec<_>>()\n+                );\n+                trace!(\"args: {:?}\", args);\n+                match sig.abi {\n+                    Abi::RustCall => {\n+                        assert_eq!(args.len(), 2);\n+\n+                        {\n+                            // write first argument\n+                            let first_local = arg_locals.next().unwrap();\n+                            let dest = self.eval_place(&mir::Place::Local(first_local))?;\n+                            self.write_value(args[0], dest)?;\n+                        }\n+\n+                        // unpack and write all other args\n+                        let layout = self.layout_of(args[1].ty)?;\n+                        if let ty::TyTuple(..) = args[1].ty.sty {\n+                            if self.frame().mir.args_iter().count() == layout.fields.count() + 1 {\n+                                match args[1].value {\n+                                    Value::ByRef(PtrAndAlign { ptr, aligned }) => {\n+                                        assert!(\n+                                            aligned,\n+                                            \"Unaligned ByRef-values cannot occur as function arguments\"\n+                                        );\n+                                        for (i, arg_local) in arg_locals.enumerate() {\n+                                            let field = layout.field(&self, i)?;\n+                                            let offset = layout.fields.offset(i).bytes();\n+                                            let arg = Value::by_ref(ptr.offset(offset, &self)?);\n+                                            let dest =\n+                                                self.eval_place(&mir::Place::Local(arg_local))?;\n+                                            trace!(\n+                                                \"writing arg {:?} to {:?} (type: {})\",\n+                                                arg,\n+                                                dest,\n+                                                field.ty\n+                                            );\n+                                            let valty = ValTy {\n+                                                value: arg,\n+                                                ty: field.ty,\n+                                            };\n+                                            self.write_value(valty, dest)?;\n+                                        }\n+                                    }\n+                                    Value::ByVal(PrimVal::Undef) => {}\n+                                    other => {\n+                                        trace!(\"{:#?}, {:#?}\", other, layout);\n+                                        let mut layout = layout;\n+                                        'outer: loop {\n+                                            for i in 0..layout.fields.count() {\n+                                                let field = layout.field(&self, i)?;\n+                                                if layout.fields.offset(i).bytes() == 0 && layout.size == field.size {\n+                                                    layout = field;\n+                                                    continue 'outer;\n+                                                }\n+                                            }\n+                                            break;\n+                                        }\n+                                        let dest = self.eval_place(&mir::Place::Local(\n+                                            arg_locals.next().unwrap(),\n+                                        ))?;\n+                                        let valty = ValTy {\n+                                            value: other,\n+                                            ty: layout.ty,\n+                                        };\n+                                        self.write_value(valty, dest)?;\n+                                    }\n+                                }\n+                            } else {\n+                                trace!(\"manual impl of rust-call ABI\");\n+                                // called a manual impl of a rust-call function\n+                                let dest = self.eval_place(\n+                                    &mir::Place::Local(arg_locals.next().unwrap()),\n+                                )?;\n+                                self.write_value(args[1], dest)?;\n+                            }\n+                        } else {\n+                            bug!(\n+                                \"rust-call ABI tuple argument was {:#?}, {:#?}\",\n+                                args[1].ty,\n+                                layout\n+                            );\n+                        }\n+                    }\n+                    _ => {\n+                        for (arg_local, &valty) in arg_locals.zip(args) {\n+                            let dest = self.eval_place(&mir::Place::Local(arg_local))?;\n+                            self.write_value(valty, dest)?;\n+                        }\n+                    }\n+                }\n+                Ok(())\n+            }\n+            // cannot use the shim here, because that will only result in infinite recursion\n+            ty::InstanceDef::Virtual(_, idx) => {\n+                let ptr_size = self.memory.pointer_size();\n+                let (ptr, vtable) = self.into_ptr_vtable_pair(args[0].value)?;\n+                let fn_ptr = self.memory.read_ptr_sized_unsigned(\n+                    vtable.offset(ptr_size * (idx as u64 + 3), &self)?\n+                )?.to_ptr()?;\n+                let instance = self.memory.get_fn(fn_ptr)?;\n+                let mut args = args.to_vec();\n+                let ty = self.layout_of(args[0].ty)?.field(&self, 0)?.ty;\n+                args[0].ty = ty;\n+                args[0].value = ptr.to_value();\n+                // recurse with concrete function\n+                self.eval_fn_call(instance, destination, &args, span, sig)\n+            }\n+        }\n+    }\n+}"}, {"sha": "c73b95c717c3de1e89e016222cc03f04a2a0921e", "filename": "src/librustc_mir/interpret/traits.rs", "status": "added", "additions": 86, "deletions": 0, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Ftraits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Finterpret%2Ftraits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Ftraits.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -0,0 +1,86 @@\n+use rustc::ty::{self, Ty};\n+use rustc::ty::layout::{Size, Align, LayoutOf};\n+use syntax::ast::Mutability;\n+\n+use rustc::mir::interpret::{PrimVal, Value, MemoryPointer, EvalResult};\n+use super::{EvalContext, eval_context,\n+            Machine};\n+\n+impl<'a, 'tcx, M: Machine<'tcx>> EvalContext<'a, 'tcx, M> {\n+    /// Creates a dynamic vtable for the given type and vtable origin. This is used only for\n+    /// objects.\n+    ///\n+    /// The `trait_ref` encodes the erased self type. Hence if we are\n+    /// making an object `Foo<Trait>` from a value of type `Foo<T>`, then\n+    /// `trait_ref` would map `T:Trait`.\n+    pub fn get_vtable(\n+        &mut self,\n+        ty: Ty<'tcx>,\n+        trait_ref: ty::PolyTraitRef<'tcx>,\n+    ) -> EvalResult<'tcx, MemoryPointer> {\n+        debug!(\"get_vtable(trait_ref={:?})\", trait_ref);\n+\n+        let layout = self.layout_of(trait_ref.self_ty())?;\n+        assert!(!layout.is_unsized(), \"can't create a vtable for an unsized type\");\n+        let size = layout.size.bytes();\n+        let align = layout.align.abi();\n+\n+        let ptr_size = self.memory.pointer_size();\n+        let methods = self.tcx.vtable_methods(trait_ref);\n+        let vtable = self.memory.allocate(\n+            ptr_size * (3 + methods.len() as u64),\n+            ptr_size,\n+            None,\n+        )?;\n+\n+        let drop = eval_context::resolve_drop_in_place(self.tcx, ty);\n+        let drop = self.memory.create_fn_alloc(drop);\n+        self.memory.write_ptr_sized_unsigned(vtable, PrimVal::Ptr(drop))?;\n+\n+        let size_ptr = vtable.offset(ptr_size, &self)?;\n+        self.memory.write_ptr_sized_unsigned(size_ptr, PrimVal::Bytes(size as u128))?;\n+        let align_ptr = vtable.offset(ptr_size * 2, &self)?;\n+        self.memory.write_ptr_sized_unsigned(align_ptr, PrimVal::Bytes(align as u128))?;\n+\n+        for (i, method) in methods.iter().enumerate() {\n+            if let Some((def_id, substs)) = *method {\n+                let instance = self.resolve(def_id, substs)?;\n+                let fn_ptr = self.memory.create_fn_alloc(instance);\n+                let method_ptr = vtable.offset(ptr_size * (3 + i as u64), &self)?;\n+                self.memory.write_ptr_sized_unsigned(method_ptr, PrimVal::Ptr(fn_ptr))?;\n+            }\n+        }\n+\n+        self.memory.mark_static_initalized(\n+            vtable.alloc_id,\n+            Mutability::Mutable,\n+        )?;\n+\n+        Ok(vtable)\n+    }\n+\n+    pub fn read_drop_type_from_vtable(\n+        &self,\n+        vtable: MemoryPointer,\n+    ) -> EvalResult<'tcx, Option<ty::Instance<'tcx>>> {\n+        // we don't care about the pointee type, we just want a pointer\n+        match self.read_ptr(vtable, self.tcx.mk_nil_ptr())? {\n+            // some values don't need to call a drop impl, so the value is null\n+            Value::ByVal(PrimVal::Bytes(0)) => Ok(None),\n+            Value::ByVal(PrimVal::Ptr(drop_fn)) => self.memory.get_fn(drop_fn).map(Some),\n+            _ => err!(ReadBytesAsPointer),\n+        }\n+    }\n+\n+    pub fn read_size_and_align_from_vtable(\n+        &self,\n+        vtable: MemoryPointer,\n+    ) -> EvalResult<'tcx, (Size, Align)> {\n+        let pointer_size = self.memory.pointer_size();\n+        let size = self.memory.read_ptr_sized_unsigned(vtable.offset(pointer_size, self)?)?.to_bytes()? as u64;\n+        let align = self.memory.read_ptr_sized_unsigned(\n+            vtable.offset(pointer_size * 2, self)?\n+        )?.to_bytes()? as u64;\n+        Ok((Size::from_bytes(size), Align::from_bytes(align, align).unwrap()))\n+    }\n+}"}, {"sha": "e7dd94f75e5b4774a7730566daab1f6692fc0e57", "filename": "src/librustc_mir/lib.rs", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibrustc_mir%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Flib.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -25,7 +25,10 @@ Rust MIR: a lowered representation of Rust. Also: an experiment!\n #![feature(decl_macro)]\n #![feature(i128_type)]\n #![feature(inclusive_range_syntax)]\n+#![feature(inclusive_range)]\n+#![feature(macro_vis_matcher)]\n #![feature(match_default_bindings)]\n+#![feature(never_type)]\n #![feature(range_contains)]\n #![feature(rustc_diagnostic_macros)]\n #![feature(placement_in_syntax)]\n@@ -48,6 +51,9 @@ extern crate syntax_pos;\n extern crate rustc_const_math;\n extern crate rustc_const_eval;\n extern crate core; // for NonZero\n+extern crate log_settings;\n+extern crate rustc_apfloat;\n+extern crate byteorder;\n \n mod diagnostics;\n \n@@ -58,13 +64,15 @@ mod hair;\n mod shim;\n pub mod transform;\n pub mod util;\n+pub mod interpret;\n \n use rustc::ty::maps::Providers;\n \n pub fn provide(providers: &mut Providers) {\n     borrow_check::provide(providers);\n     shim::provide(providers);\n     transform::provide(providers);\n+    providers.const_eval = interpret::const_eval_provider;\n }\n \n __build_diagnostic_array! { librustc_mir, DIAGNOSTICS }"}, {"sha": "6a007e98827b62686a71e79f71e4b0bf3a0e6ca9", "filename": "src/libstd/sys/redox/fast_thread_local.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibstd%2Fsys%2Fredox%2Ffast_thread_local.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibstd%2Fsys%2Fredox%2Ffast_thread_local.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fredox%2Ffast_thread_local.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -81,7 +81,7 @@ pub unsafe fn register_dtor(t: *mut u8, dtor: unsafe extern fn(*mut u8)) {\n     unsafe extern fn run_dtors(mut ptr: *mut u8) {\n         while !ptr.is_null() {\n             let list: Box<List> = Box::from_raw(ptr as *mut List);\n-            for &(ptr, dtor) in list.iter() {\n+            for (ptr, dtor) in list.into_iter() {\n                 dtor(ptr);\n             }\n             ptr = DTORS.get();"}, {"sha": "a4aa3d96d25c00f5c399236b2e0275b595fc6ac0", "filename": "src/libstd/sys_common/thread_local.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibstd%2Fsys_common%2Fthread_local.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Flibstd%2Fsys_common%2Fthread_local.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys_common%2Fthread_local.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -262,7 +262,7 @@ pub unsafe fn register_dtor_fallback(t: *mut u8,\n     unsafe extern fn run_dtors(mut ptr: *mut u8) {\n         while !ptr.is_null() {\n             let list: Box<List> = Box::from_raw(ptr as *mut List);\n-            for &(ptr, dtor) in list.iter() {\n+            for (ptr, dtor) in list.into_iter() {\n                 dtor(ptr);\n             }\n             ptr = DTORS.get();"}, {"sha": "2f199c48e46e780d642fd48dae266af9e9c1dc80", "filename": "src/test/compile-fail/E0080.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2FE0080.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2FE0080.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2FE0080.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -10,7 +10,9 @@\n \n enum Enum {\n     X = (1 << 500), //~ ERROR E0080\n+    //~| WARNING shift left with overflow\n     Y = (1 / 0) //~ ERROR E0080\n+    //~| WARNING divide by zero\n }\n \n fn main() {"}, {"sha": "2b1c1017b5b00971c4d5bcc0a4cc912185379204", "filename": "src/test/compile-fail/const-eval-overflow-4.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-eval-overflow-4.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-eval-overflow-4.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fconst-eval-overflow-4.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -23,6 +23,8 @@ const A_I8_T\n     : [u32; (i8::MAX as i8 + 1i8) as usize]\n     //~^ ERROR constant evaluation error\n     //~^^ NOTE attempt to add with overflow\n+    //~| WARNING constant evaluation error\n+    //~| NOTE on by default\n     = [0; (i8::MAX as usize) + 1];\n \n fn main() {"}, {"sha": "baf836b4dad1b9915e08fa273cbbc45504b69642", "filename": "src/test/compile-fail/const-fn-error.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-fn-error.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-fn-error.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fconst-fn-error.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -13,8 +13,9 @@\n const X : usize = 2;\n \n const fn f(x: usize) -> usize {\n-    let mut sum = 0;\n-    for i in 0..x {\n+    let mut sum = 0; //~ ERROR blocks in constant functions are limited\n+    for i in 0..x { //~ ERROR calls in constant functions\n+    //~| ERROR constant function contains unimplemented\n         sum += i;\n     }\n     sum //~ ERROR E0080\n@@ -24,4 +25,6 @@ const fn f(x: usize) -> usize {\n #[allow(unused_variables)]\n fn main() {\n     let a : [i32; f(X)]; //~ NOTE for constant expression here\n+    //~| WARNING constant evaluation error: non-constant path\n+    //~| on by default\n }"}, {"sha": "eaad9e7e92bab3bbc813aa224a4fdca43358947e", "filename": "src/test/compile-fail/const-len-underflow-separate-spans.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-len-underflow-separate-spans.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Fconst-len-underflow-separate-spans.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fconst-len-underflow-separate-spans.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -17,6 +17,8 @@ const TWO: usize = 2;\n const LEN: usize = ONE - TWO;\n //~^ ERROR E0080\n //~| attempt to subtract with overflow\n+//~| NOTE attempt to subtract with overflow\n+//~| NOTE on by default\n \n fn main() {\n     let a: [i8; LEN] = unimplemented!();"}, {"sha": "73b7743fc45c7d20ece5dff59f0d3eea37541cf1", "filename": "src/test/compile-fail/union/union-const-eval.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Funion%2Funion-const-eval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftest%2Fcompile-fail%2Funion%2Funion-const-eval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Funion%2Funion-const-eval.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -20,5 +20,7 @@ fn main() {\n         let a: [u8; C.a]; // OK\n         let b: [u8; C.b]; //~ ERROR constant evaluation error\n                           //~^ NOTE nonexistent struct field\n+                          //~| WARNING constant evaluation error\n+                          //~| NOTE on by default\n     }\n }"}, {"sha": "bde093fa140cbf95023482a94b92b0b16af4b521", "filename": "src/tools/miri", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": null, "raw_url": null, "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Fmiri?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -1 +1 @@\n-Subproject commit 6dbfe23c4d1af109c894ff9d7d5da97c025584e5\n+Subproject commit bde093fa140cbf95023482a94b92b0b16af4b521"}, {"sha": "3fd844f326184a76d87602e19559bd31cad836c2", "filename": "src/tools/tidy/src/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftools%2Ftidy%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftools%2Ftidy%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftidy%2Fsrc%2Flib.rs?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -66,6 +66,8 @@ fn filter_dirs(path: &Path) -> bool {\n         \"src/tools/rust-installer\",\n         \"src/tools/rustfmt\",\n         \"src/tools/miri\",\n+        \"src/librustc/mir/interpret\",\n+        \"src/librustc_mir/interpret\",\n     ];\n     skip.iter().any(|p| path.ends_with(p))\n }"}, {"sha": "13295ef3ee70a8e707a592f244bb7c4c3a09f963", "filename": "src/tools/toolstate.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftools%2Ftoolstate.toml", "raw_url": "https://github.com/rust-lang/rust/raw/2974104276265858d74733d7ebcca1d3347fd34e/src%2Ftools%2Ftoolstate.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftools%2Ftoolstate.toml?ref=2974104276265858d74733d7ebcca1d3347fd34e", "patch": "@@ -23,7 +23,7 @@\n # Each tool has a list of people to ping\n \n # ping @oli-obk @RalfJung @eddyb\n-miri = \"Broken\"\n+miri = \"Testing\"\n \n # ping @Manishearth @llogiq @mcarton @oli-obk\n clippy = \"Testing\""}]}