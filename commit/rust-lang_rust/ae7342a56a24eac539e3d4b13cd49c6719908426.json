{"sha": "ae7342a56a24eac539e3d4b13cd49c6719908426", "node_id": "MDY6Q29tbWl0NzI0NzEyOmFlNzM0MmE1NmEyNGVhYzUzOWUzZDRiMTNjZDQ5YzY3MTk5MDg0MjY=", "commit": {"author": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2014-07-15T20:58:35Z"}, "committer": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2014-09-04T22:22:32Z"}, "message": "std: Refine and document HashMap's code\n\n* branchless `bucket.next()`\n* robin_hood is a free function\n* fixed the resize policy that was off by one\n* documented the growth algorithm\n* updated documentation after interface changes\n* removed old fixmes", "tree": {"sha": "bed51fcf5e2665d039d88ff04e2a366a0912ef32", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bed51fcf5e2665d039d88ff04e2a366a0912ef32"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/ae7342a56a24eac539e3d4b13cd49c6719908426", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/ae7342a56a24eac539e3d4b13cd49c6719908426", "html_url": "https://github.com/rust-lang/rust/commit/ae7342a56a24eac539e3d4b13cd49c6719908426", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/ae7342a56a24eac539e3d4b13cd49c6719908426/comments", "author": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fc636ae8f4c44f4594f2191e1fcc7c3cdf4948fd", "url": "https://api.github.com/repos/rust-lang/rust/commits/fc636ae8f4c44f4594f2191e1fcc7c3cdf4948fd", "html_url": "https://github.com/rust-lang/rust/commit/fc636ae8f4c44f4594f2191e1fcc7c3cdf4948fd"}], "stats": {"total": 1186, "additions": 704, "deletions": 482}, "files": [{"sha": "21bbb38f4893671686fff78f2230e2a42c09a6ba", "filename": "src/libstd/collections/hashmap/bench.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fbench.rs?ref=ae7342a56a24eac539e3d4b13cd49c6719908426", "patch": "@@ -38,7 +38,7 @@ fn new_insert_drop(b : &mut Bencher) {\n }\n \n #[bench]\n-fn insert(b: &mut Bencher) {\n+fn grow_by_insertion(b: &mut Bencher) {\n     use super::HashMap;\n \n     let mut m = HashMap::new();"}, {"sha": "a50c6a59f7e04b463411fcbb00f1a073c6b16e95", "filename": "src/libstd/collections/hashmap/map.rs", "status": "modified", "additions": 385, "deletions": 173, "changes": 558, "blob_url": "https://github.com/rust-lang/rust/blob/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fmap.rs?ref=ae7342a56a24eac539e3d4b13cd49c6719908426", "patch": "@@ -16,28 +16,37 @@ use collections::{Collection, Mutable, MutableSet, Map, MutableMap};\n use default::Default;\n use fmt::Show;\n use fmt;\n-use RandomSipHasher;\n-use hash::{Hash, Hasher};\n-use iter::{Iterator, FromIterator, Extendable, range};\n+use hash::{Hash, Hasher, RandomSipHasher};\n+use iter::{Iterator, FromIterator, Extendable};\n use iter;\n use mem::replace;\n use num;\n-use ops::Deref;\n+use ops::{Deref, DerefMut};\n use option::{Some, None, Option};\n use result::{Ok, Err};\n use ops::Index;\n \n-use super::table::{BucketWithTable, FullBucketImm, RawTable, FullBucket, FullBucketMut, Bucket};\n use super::table;\n+use super::table::{\n+    Bucket,\n+    Empty,\n+    Full,\n+    FullBucket,\n+    FullBucketImm,\n+    FullBucketMut,\n+    RawTable,\n+    SafeHash\n+};\n \n static INITIAL_LOG2_CAP: uint = 5;\n pub static INITIAL_CAPACITY: uint = 1 << INITIAL_LOG2_CAP; // 2^5\n \n /// The default behavior of HashMap implements a load factor of 90.9%.\n /// This behavior is characterized by the following conditions:\n ///\n-/// - if `size * 1.1 < cap < size * 4` then shouldn't resize\n-/// - if `cap < minimum_capacity * 2` then shouldn't shrink\n+/// - if size > 0.909 * capacity: grow\n+/// - if size < 0.25 * capacity: shrink (if this won't bring capacity lower\n+///   than the minimum)\n #[deriving(Clone)]\n struct DefaultResizePolicy {\n     /// Doubled minimal capacity. The capacity must never drop below\n@@ -55,7 +64,12 @@ impl DefaultResizePolicy {\n \n     #[inline]\n     fn capacity_range(&self, new_size: uint) -> (uint, uint) {\n-        ((new_size * 11) / 10, max(new_size << 3, self.minimum_capacity2))\n+        // Here, we are rephrasing the logic by specifying the ranges:\n+        //\n+        // - if `size * 1.1 < cap < size * 4`: don't resize\n+        // - if `cap < minimum_capacity * 2`: don't shrink\n+        // - otherwise, resize accordingly\n+        ((new_size * 11) / 10, max(new_size << 2, self.minimum_capacity2))\n     }\n \n     #[inline]\n@@ -65,9 +79,9 @@ impl DefaultResizePolicy {\n }\n \n // The main performance trick in this hashmap is called Robin Hood Hashing.\n-// It gains its excellent performance from one crucial operation:\n+// It gains its excellent performance from one essential operation:\n //\n-//    If an insertion collides with an existing element, and that elements\n+//    If an insertion collides with an existing element, and that element's\n //    \"probe distance\" (how far away the element is from its ideal location)\n //    is higher than how far we've already probed, swap the elements.\n //\n@@ -94,6 +108,15 @@ impl DefaultResizePolicy {\n // \u03b1^3, etc. Therefore, the odds of colliding k times is \u03b1^k. The odds of NOT\n // colliding after k tries is 1-\u03b1^k.\n //\n+// The paper from 1986 cited below mentions an implementation which keeps track\n+// of the distance-to-initial-bucket histogram. This approach is not suitable\n+// for modern architectures because it requires maintaining an internal data\n+// structure. This allows very good first guesses, but we are most concerned\n+// with guessing entire cache lines, not individual indexes. Furthermore, array\n+// accesses are no longer linear and in one direction, as we have now. There\n+// is also memory and cache pressure that this would entail that would be very\n+// difficult to properly see in a microbenchmark.\n+//\n // Future Improvements (FIXME!)\n // ============================\n //\n@@ -106,15 +129,6 @@ impl DefaultResizePolicy {\n // Future Optimizations (FIXME!)\n // =============================\n //\n-// The paper cited below mentions an implementation which keeps track of the\n-// distance-to-initial-bucket histogram. I'm suspicious of this approach because\n-// it requires maintaining an internal map. If this map were replaced with a\n-// hashmap, it would be faster, but now our data structure is self-referential\n-// and blows up. Also, this allows very good first guesses, but array accesses\n-// are no longer linear and in one direction, as we have now. There is also\n-// memory and cache pressure that this map would entail that would be very\n-// difficult to properly see in a microbenchmark.\n-//\n // Another possible design choice that I made without any real reason is\n // parameterizing the raw table over keys and values. Technically, all we need\n // is the size and alignment of keys and values, and the code should be just as\n@@ -125,12 +139,56 @@ impl DefaultResizePolicy {\n // This would definitely be an avenue worth exploring if people start complaining\n // about the size of rust executables.\n //\n-// There's also an \"optimization\" that has been omitted regarding how the\n-// hashtable allocates. The vector type has set the expectation that a hashtable\n-// which never has an element inserted should not allocate. I'm suspicious of\n-// implementing this for hashtables, because supporting it has no performance\n-// benefit over using an `Option<HashMap<K, V>>`, and is significantly more\n-// complicated.\n+// Annotate exceedingly likely branches in `table::make_hash`\n+// and `search_hashed_generic` to reduce instruction cache pressure\n+// and mispredictions once it becomes possible (blocked on issue #11092).\n+//\n+// Shrinking the table could simply reallocate in place after moving buckets\n+// to the first half.\n+//\n+// The growth algorithm (fragment of the Proof of Correctness)\n+// --------------------\n+//\n+// The growth algorithm is basically a fast path of the naive reinsertion-\n+// during-resize algorithm. Other paths should never be taken.\n+//\n+// Consider growing a robin hood hashtable of capacity n. Normally, we do this\n+// by allocating a new table of capacity `2n`, and then individually reinsert\n+// each element in the old table into the new one. This guarantees that the\n+// new table is a valid robin hood hashtable with all the desired statistical\n+// properties. Remark that the order we reinsert the elements in should not\n+// matter. For simplicity and efficiency, we will consider only linear\n+// reinsertions, which consist of reinserting all elements in the old table\n+// into the new one by increasing order of index. However we will not be\n+// starting our reinsertions from index 0 in general. If we start from index\n+// i, for the purpose of reinsertion we will consider all elements with real\n+// index j < i to have virtual index n + j.\n+//\n+// Our hash generation scheme consists of generating a 64-bit hash and\n+// truncating the most significant bits. When moving to the new table, we\n+// simply introduce a new bit to the front of the hash. Therefore, if an\n+// elements has ideal index i in the old table, it can have one of two ideal\n+// locations in the new table. If the new bit is 0, then the new ideal index\n+// is i. If the new bit is 1, then the new ideal index is n + i. Intutively,\n+// we are producing two independent tables of size n, and for each element we\n+// independently choose which table to insert it into with equal probability.\n+// However the rather than wrapping around themselves on overflowing their\n+// indexes, the first table overflows into the first, and the first into the\n+// second. Visually, our new table will look something like:\n+//\n+// [yy_xxx_xxxx_xxx|xx_yyy_yyyy_yyy]\n+//\n+// Where x's are elements inserted into the first table, y's are elements\n+// inserted into the second, and _'s are empty sections. We now define a few\n+// key concepts that we will use later. Note that this is a very abstract\n+// perspective of the table. A real resized table would be at least half\n+// empty.\n+//\n+// Theorem: A linear robin hood reinsertion from the first ideal element\n+// produces identical results to a linear naive reinsertion from the same\n+// element.\n+//\n+// FIXME(Gankro, pczarn): review the proof and put it all in a separate doc.rs\n \n /// A hash map implementation which uses linear probing with Robin\n /// Hood bucket stealing.\n@@ -219,27 +277,31 @@ pub struct HashMap<K, V, H = RandomSipHasher> {\n     // All hashes are keyed on these values, to prevent hash collision attacks.\n     hasher: H,\n \n-    table: table::RawTable<K, V>,\n+    table: RawTable<K, V>,\n \n     // We keep this at the end since it might as well have tail padding.\n     resize_policy: DefaultResizePolicy,\n }\n \n /// Search for a pre-hashed key.\n-fn search_hashed_generic<K, V, M: Deref<RawTable<K, V>>>(table: M, hash: &table::SafeHash, is_match: |&K| -> bool)\n-                        -> Option<FullBucket<K, V, M>> {\n+fn search_hashed_generic<K, V, M: Deref<RawTable<K, V>>>(table: M,\n+                                                         hash: &SafeHash,\n+                                                         is_match: |&K| -> bool)\n+                                                         -> SearchResult<K, V, M> {\n     let size = table.size();\n     let mut probe = Bucket::new(table, hash);\n     let ib = probe.index();\n \n     while probe.index() != ib + size {\n         let full = match probe.peek() {\n-            table::Empty(_) => return None, // hit an empty bucket\n-            table::Full(b) => b\n+            Empty(b) => return TableRef(b.into_table()), // hit an empty bucket\n+            Full(b) => b\n         };\n \n         if full.distance() + ib < full.index() {\n-            return None;\n+            // We can finish the search early if we hit any bucket\n+            // with a lower distance to initial bucket than we've probed.\n+            return TableRef(full.into_table());\n         }\n \n         // If the hash doesn't match, it can't be this one..\n@@ -251,91 +313,179 @@ fn search_hashed_generic<K, V, M: Deref<RawTable<K, V>>>(table: M, hash: &table:\n \n             // If the key doesn't match, it can't be this one..\n             if matched {\n-                return Some(full);\n+                return FoundExisting(full);\n             }\n         }\n \n         probe = full.next();\n     }\n \n-    None\n+    TableRef(probe.into_table())\n }\n \n-fn search_hashed<K: Eq, V, M: Deref<RawTable<K, V>>>(table: M, hash: &table::SafeHash, k: &K)\n-                -> Option<table::FullBucket<K, V, M>> {\n+fn search_hashed<K: Eq, V, M: Deref<RawTable<K, V>>>(table: M, hash: &SafeHash, k: &K)\n+                                                     -> SearchResult<K, V, M> {\n     search_hashed_generic(table, hash, |k_| *k == *k_)\n }\n \n fn pop_internal<K, V>(starting_bucket: FullBucketMut<K, V>) -> V {\n-    let size = {\n-        let table = starting_bucket.table();\n-        table.size()\n-    };\n     let (empty, _k, retval) = starting_bucket.take();\n     let mut gap = match empty.gap_peek() {\n         Some(b) => b,\n         None => return retval\n     };\n-    // COMPILER error! wrong enum optimization. sets ptr to 0\n \n-    for _ in range(0, size) {\n-        if gap.full().distance() != 0 {\n-            gap = match gap.shift() {\n-                Some(b) => b,\n-                None => return retval\n+    while gap.full().distance() != 0 {\n+        gap = match gap.shift() {\n+            Some(b) => b,\n+            None => break\n+        };\n+    }\n+\n+    // Now we've done all our shifting. Return the value we grabbed earlier.\n+    return retval;\n+}\n+\n+/// Perform robin hood bucket stealing at the given `bucket`. You must\n+/// also pass the position of that bucket's initial bucket so we don't have\n+/// to recalculate it.\n+///\n+/// `hash`, `k`, and `v` are the elements to \"robin hood\" into the hashtable.\n+fn robin_hood<'a, K: 'a, V: 'a>(mut bucket: FullBucketMut<'a, K, V>,\n+                        mut ib: uint,\n+                        mut hash: SafeHash,\n+                        mut k: K,\n+                        mut v: V)\n+                        -> &'a mut V {\n+    let starting_index = bucket.index();\n+    let size = {\n+        let table = bucket.table(); // FIXME \"lifetime too short\".\n+        table.size()\n+    };\n+    // There can be at most `size - dib` buckets to displace, because\n+    // in the worst case, there are `size` elements and we already are\n+    // `distance` buckets away from the initial one.\n+    let idx_end = starting_index + size - bucket.distance();\n+\n+    loop {\n+        let (old_hash, old_key, old_val) = bucket.replace(hash, k, v);\n+        loop {\n+            let probe = bucket.next();\n+            assert!(probe.index() != idx_end);\n+\n+            let full_bucket = match probe.peek() {\n+                table::Empty(bucket) => {\n+                    // Found a hole!\n+                    let b = bucket.put(old_hash, old_key, old_val);\n+                    // Now that it's stolen, just read the value's pointer\n+                    // right out of the table!\n+                    let (_, v) = Bucket::at_index(b.into_table(), starting_index).peek()\n+                                                                                 .expect_full()\n+                                                                                 .into_mut_refs();\n+                    return v;\n+                },\n+                table::Full(bucket) => bucket\n             };\n-            continue;\n+\n+            let probe_ib = full_bucket.index() - full_bucket.distance();\n+\n+            bucket = full_bucket;\n+\n+            // Robin hood! Steal the spot.\n+            if ib < probe_ib {\n+                ib = probe_ib;\n+                hash = old_hash;\n+                k = old_key;\n+                v = old_val;\n+                break;\n+            }\n+        }\n+    }\n+}\n+\n+/// A result that works like Option<FullBucket<..>> but preserves\n+/// the reference that grants us access to the table in any case.\n+enum SearchResult<K, V, M> {\n+    // This is an entry that holds the given key:\n+    FoundExisting(FullBucket<K, V, M>),\n+\n+    // There was no such entry. The reference is given back:\n+    TableRef(M)\n+}\n+\n+impl<K, V, M> SearchResult<K, V, M> {\n+    fn into_option(self) -> Option<FullBucket<K, V, M>> {\n+        match self {\n+            FoundExisting(bucket) => Some(bucket),\n+            TableRef(_) => None\n         }\n+    }\n+}\n \n-        break;\n+/// A newtyped mutable reference to the hashmap that allows e.g. Deref to be\n+/// implemented without making changes to the visible interface of HashMap.\n+/// Used internally because it's accepted by the search functions above.\n+struct MapMutRef<'a, K: 'a, V: 'a, H: 'a> {\n+    map_ref: &'a mut HashMap<K, V, H>\n+}\n+\n+impl<'a, K, V, H> Deref<RawTable<K, V>> for MapMutRef<'a, K, V, H> {\n+    fn deref(&self) -> &RawTable<K, V> {\n+        &self.map_ref.table\n     }\n+}\n \n-    // Now we're done all our shifting. Return the value we grabbed\n-    // earlier.\n-    return retval;\n+impl<'a, K, V, H> DerefMut<RawTable<K, V>> for MapMutRef<'a, K, V, H> {\n+    fn deref_mut(&mut self) -> &mut RawTable<K, V> {\n+        &mut self.map_ref.table\n+    }\n }\n \n impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n-    fn make_hash<X: Hash<S>>(&self, x: &X) -> table::SafeHash {\n+    fn make_hash<X: Hash<S>>(&self, x: &X) -> SafeHash {\n         table::make_hash(&self.hasher, x)\n     }\n \n     fn search_equiv<'a, Q: Hash<S> + Equiv<K>>(&'a self, q: &Q)\n                     -> Option<FullBucketImm<'a, K, V>> {\n         let hash = self.make_hash(q);\n-        search_hashed_generic(&self.table, &hash, |k| q.equiv(k))\n+        search_hashed_generic(&self.table, &hash, |k| q.equiv(k)).into_option()\n     }\n \n     fn search_equiv_mut<'a, Q: Hash<S> + Equiv<K>>(&'a mut self, q: &Q)\n                     -> Option<FullBucketMut<'a, K, V>> {\n         let hash = self.make_hash(q);\n-        search_hashed_generic(&mut self.table, &hash, |k| q.equiv(k))\n+        search_hashed_generic(&mut self.table, &hash, |k| q.equiv(k)).into_option()\n     }\n \n     /// Search for a key, yielding the index if it's found in the hashtable.\n     /// If you already have the hash for the key lying around, use\n     /// search_hashed.\n     fn search<'a>(&'a self, k: &K) -> Option<FullBucketImm<'a, K, V>> {\n         let hash = self.make_hash(k);\n-        search_hashed(&self.table, &hash, k)\n+        search_hashed(&self.table, &hash, k).into_option()\n     }\n \n     fn search_mut<'a>(&'a mut self, k: &K) -> Option<FullBucketMut<'a, K, V>> {\n         let hash = self.make_hash(k);\n-        search_hashed(&mut self.table, &hash, k)\n+        search_hashed(&mut self.table, &hash, k).into_option()\n     }\n \n-    fn insert_hashed_ordered(&mut self, hash: table::SafeHash, k: K, v: V) {\n+    // The caller should ensure that invariants by Robin Hood Hashing hold.\n+    fn insert_hashed_ordered(&mut self, hash: SafeHash, k: K, v: V) {\n         let cap = self.table.capacity();\n         let mut buckets = Bucket::new(&mut self.table, &hash);\n         let ib = buckets.index();\n+\n         while buckets.index() != ib + cap {\n+            // We don't need to compare hashes for value swap.\n+            // Not even DIBs for Robin Hood.\n             buckets = match buckets.peek() {\n-                table::Empty(empty) => {\n+                Empty(empty) => {\n                     empty.put(hash, k, v);\n                     return;\n                 }\n-                table::Full(b) => b.into_bucket()\n+                Full(b) => b.into_bucket()\n             };\n             buckets.next();\n         }\n@@ -361,8 +511,8 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Mutable for HashMap<K, V, H> {\n \n         while buckets.index() != cap {\n             buckets = match buckets.peek() {\n-                table::Empty(b)  => b.next(),\n-                table::Full(full) => {\n+                Empty(b)  => b.next(),\n+                Full(full) => {\n                     let (b, _, _) = full.take();\n                     b.next()\n                 }\n@@ -401,7 +551,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> MutableMap<K, V> for HashMap<K, V, H>\n         self.make_some_room(potential_new_size);\n \n         let mut retval = None;\n-        self.insert_or_replace_with(hash, k, v, |val_ref, val| {\n+        self.insert_or_replace_with(hash, k, v, |_, val_ref, val| {\n             retval = Some(replace(val_ref, val));\n         });\n         retval\n@@ -472,7 +622,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n         HashMap {\n             hasher:        hasher,\n             resize_policy: DefaultResizePolicy::new(INITIAL_CAPACITY),\n-            table:         table::RawTable::new(0),\n+            table:         RawTable::new(0),\n         }\n     }\n \n@@ -500,7 +650,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n         HashMap {\n             hasher:        hasher,\n             resize_policy: DefaultResizePolicy::new(cap),\n-            table:         table::RawTable::new(cap),\n+            table:         RawTable::new(cap),\n         }\n     }\n \n@@ -537,49 +687,78 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n         assert!(self.table.size() <= new_capacity);\n         assert!(num::is_power_of_two(new_capacity));\n \n-        let mut old_table = replace(&mut self.table, table::RawTable::new(new_capacity));\n+        let mut old_table = replace(&mut self.table, RawTable::new(new_capacity));\n         let old_size = old_table.size();\n \n-        if old_table.capacity() == 0 {\n+        if old_table.capacity() == 0 || old_table.size() == 0 {\n             return;\n         }\n \n         if new_capacity < old_table.capacity() {\n+            // Shrink the table. Naive algorithm for resizing:\n             for (h, k, v) in old_table.move_iter() {\n                 self.insert_hashed_nocheck(h, k, v);\n             }\n         } else {\n+            // Grow the table.\n+            // Specialization of the other branch.\n             let mut bucket = Bucket::first(&mut old_table);\n \n+            // \"So a few of the first shall be last: for many be called,\n+            // but few chosen.\"\n+            //\n+            // We'll most likely encounter a few buckets at the beginning that\n+            // have their initial buckets near the end of the table. They were\n+            // placed at the beginning as the probe wrapped around the table\n+            // during insertion. We must skip forward to a bucket that won't\n+            // get reinserted too early and won't unfairly steal others spot.\n+            // This eliminates the need for robin hood.\n             loop {\n-                match bucket.peek() {\n-                    table::Full(full) => {\n+                bucket = match bucket.peek() {\n+                    Full(full) => {\n                         if full.distance() == 0 {\n+                            // This bucket occupies its ideal spot.\n+                            // It indicates the start of another \"cluster\".\n                             bucket = full.into_bucket();\n                             break;\n                         }\n-                        bucket = full.next();\n+                        // Leaving this bucket in the last cluster for later.\n+                        full.into_bucket()\n                     }\n-                    table::Empty(b) => {\n-                        bucket = b.next();\n-                        break;\n+                    Empty(b) => {\n+                        // Encountered a hole between clusters.\n+                        b.into_bucket()\n                     }\n                 };\n+                bucket.next();\n             }\n \n+            // This is how the buckets might be laid out in memory:\n+            // ($ marks an initialized bucket)\n+            //  ________________\n+            // |$$$_$$$$$$_$$$$$|\n+            //\n+            // But we've skipped the entire initial cluster of buckets\n+            // and will continue iteration in this order:\n+            //  ________________\n+            //     |$$$$$$_$$$$$\n+            //                  ^ wrap around once end is reached\n+            //  ________________\n+            //  $$$_____________|\n+            //    ^ exit once table.size == 0\n             loop {\n                 bucket = match bucket.peek() {\n-                    table::Full(bucket) => {\n-                        {\n-                            let t = bucket.table();\n-                            if t.size() == 0 { break }\n-                        }\n+                    Full(bucket) => {\n                         let h = bucket.hash();\n                         let (b, k, v) = bucket.take();\n                         self.insert_hashed_ordered(h, k, v);\n+                        {\n+                            let t = b.table(); // FIXME \"lifetime too short\".\n+                            if t.size() == 0 { break }\n+                        };\n                         b.into_bucket()\n                     }\n-                    table::Empty(b) => b.into_bucket()\n+                    Empty(b) => b.into_bucket()\n                 };\n                 bucket.next();\n             }\n@@ -612,95 +791,62 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     ///\n     /// If the key already exists, the hashtable will be returned untouched\n     /// and a reference to the existing element will be returned.\n-    fn insert_hashed_nocheck<'a>(\n-        &'a mut self, hash: table::SafeHash, k: K, v: V) -> &'a mut V {\n-        self.insert_or_replace_with(hash, k, v, |_, _| ())\n+    fn insert_hashed_nocheck(&mut self, hash: SafeHash, k: K, v: V) -> &mut V {\n+        self.insert_or_replace_with(hash, k, v, |_, _, _| ())\n     }\n \n-    fn insert_or_replace_with<'a>(\n-        &'a mut self, hash: table::SafeHash, k: K, v: V,\n-        found_existing: |&mut V, V|\n-    ) -> &'a mut V {\n-\n+    fn insert_or_replace_with<'a>(&'a mut self,\n+                                  hash: SafeHash,\n+                                  k: K,\n+                                  v: V,\n+                                  found_existing: |&mut K, &mut V, V|)\n+                                  -> &'a mut V {\n         // Worst case, we'll find one empty bucket among `size + 1` buckets.\n         let size = self.table.size();\n-        let mut rbucket = Bucket::new(&mut self.table, &hash);\n-        let ib = rbucket.index();\n+        let mut probe = Bucket::new(&mut self.table, &hash);\n+        let ib = probe.index();\n \n         loop {\n-            let mut bucket = match rbucket.peek() {\n-                table::Empty(bucket) => {\n+            let mut bucket = match probe.peek() {\n+                Empty(bucket) => {\n                     // Found a hole!\n                     let bucket = bucket.put(hash, k, v);\n                     let (_, val) = bucket.into_mut_refs();\n                     return val;\n                 },\n-                table::Full(bucket) => bucket\n+                Full(bucket) => bucket\n             };\n \n             if bucket.hash() == hash {\n-                let (bucket_k, bucket_v) = bucket.read_mut();\n-                // FIXME #12147 the conditional return confuses\n-                // borrowck if we return bucket_v directly\n-                let bv: *mut V = bucket_v;\n-                if k == *bucket_k {\n+                let found_match = {\n+                    let (bucket_k, _) = bucket.read_mut();\n+                    k == *bucket_k\n+                };\n+                if found_match {\n+                    let (bucket_k, bucket_v) = bucket.into_mut_refs();\n+                    debug_assert!(k == *bucket_k);\n                     // Key already exists. Get its reference.\n-                    found_existing(bucket_v, v);\n-                    return unsafe {&mut *bv};\n+                    found_existing(bucket_k, bucket_v, v);\n+                    return bucket_v;\n                 }\n             }\n \n             let robin_ib = bucket.index() as int - bucket.distance() as int;\n \n             if (ib as int) < robin_ib {\n                 // Found a luckier bucket than me. Better steal his spot.\n-                let (mut hash, mut k, mut v) = bucket.replace(hash, k, v);\n-                let robin_index = bucket.index();\n-                let mut robin_ib = robin_ib as uint;\n-                let mut rbucket = bucket.next();\n-                loop {\n-                    let mut bucket = match rbucket.peek() {\n-                        table::Empty(bucket) => {\n-                            // Found a hole!\n-                            let b = bucket.put(hash, k, v);\n-                            // Now that it's stolen, just read the value's pointer\n-                            // right out of the table!\n-                            let (_, v) = match Bucket::at_index(b.into_table(), robin_index).peek() {\n-                                table::Full(b) => b.into_mut_refs(),\n-                                _ => fail!()\n-                            };\n-                            return v;\n-                        },\n-                        table::Full(bucket) => bucket\n-                    };\n-\n-                    let probe_ib = bucket.index() - bucket.distance();\n-\n-                    // Robin hood! Steal the spot.\n-                    if robin_ib < probe_ib {\n-                        robin_ib = probe_ib;\n-                        let (old_hash, old_key, old_val) = bucket.replace(hash, k, v);\n-                        hash = old_hash;\n-                        k = old_key;\n-                        v = old_val;\n-                    }\n-                    rbucket = bucket.next();\n-                    if rbucket.index() == ib + size + 1 {\n-                        fail!(\"HashMap fatal error: 100% load factor?\")\n-                    }\n-                }\n-            }\n-            rbucket = bucket.next();\n-            if rbucket.index() == ib + size + 1 {\n-                fail!(\"Internal HashMap error: Out of space.\")\n+                return robin_hood(bucket, robin_ib as uint, hash, k, v);\n             }\n+\n+            probe = bucket.next();\n+            assert!(probe.index() != ib + size + 1);\n         }\n     }\n \n     /// Inserts an element which has already been hashed, returning a reference\n     /// to that element inside the hashtable. This is more efficient that using\n     /// `insert`, since the key will not be rehashed.\n-    fn insert_hashed<'a>(&'a mut self, hash: table::SafeHash, k: K, v: V) -> &'a mut V {\n+    fn insert_hashed(&mut self, hash: SafeHash, k: K, v: V) -> &mut V {\n         let potential_new_size = self.table.size() + 1;\n         self.make_some_room(potential_new_size);\n         self.insert_hashed_nocheck(hash, k, v)\n@@ -721,7 +867,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     /// // Find the existing key\n     /// assert_eq!(*map.find_or_insert(\"a\", -2), 1);\n     /// ```\n-    pub fn find_or_insert<'a>(&'a mut self, k: K, v: V) -> &'a mut V {\n+    pub fn find_or_insert(&mut self, k: K, v: V) -> &mut V {\n         self.find_with_or_insert_with(k, v, |_k, _v, _a| (), |_k, a| a)\n     }\n \n@@ -768,7 +914,11 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n                                  v: V,\n                                  f: |&K, &mut V|)\n                                  -> &'a mut V {\n-        self.find_with_or_insert_with(k, v, |k, v, _a| f(k, v), |_k, a| a)\n+        let potential_new_size = self.table.size() + 1;\n+        self.make_some_room(potential_new_size);\n+\n+        let hash = self.make_hash(&k);\n+        self.insert_or_replace_with(hash, k, v, |kref, vref, _v| f(kref, vref))\n     }\n \n     /// Modify and return the value corresponding to the key in the map, or\n@@ -820,21 +970,22 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n                                            a: A,\n                                            found: |&K, &mut V, A|,\n                                            not_found: |&K, A| -> V)\n-                                          -> &'a mut V {\n+                                          -> &'a mut V\n+    {\n         let hash = self.make_hash(&k);\n-        {\n-            match search_hashed(&mut self.table, &hash, &k) {\n-                Some(bucket) => {\n-                    let (_, v_ref) = bucket.into_mut_refs();\n-                    found(&k, v_ref, a);\n-                    return v_ref;\n-                }\n-                _ => {\n-                }\n-            };\n+        let this = MapMutRef { map_ref: self };\n+\n+        match search_hashed(this, &hash, &k) {\n+            FoundExisting(bucket) => {\n+                let (_, v_ref) = bucket.into_mut_refs();\n+                found(&k, v_ref, a);\n+                v_ref\n+            }\n+            TableRef(this) => {\n+                let v = not_found(&k, a);\n+                this.map_ref.insert_hashed(hash, k, v)\n+            }\n         }\n-        let v = not_found(&k, a);\n-        self.insert_hashed(hash, k, v)\n     }\n \n     /// Retrieves a value for the given key.\n@@ -996,7 +1147,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     ///     println!(\"{}\", key);\n     /// }\n     /// ```\n-    pub fn keys<'a>(&'a self) -> Keys<'a, K, V> {\n+    pub fn keys(&self) -> Keys<K, V> {\n         self.iter().map(|(k, _v)| k)\n     }\n \n@@ -1017,7 +1168,7 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     ///     println!(\"{}\", key);\n     /// }\n     /// ```\n-    pub fn values<'a>(&'a self) -> Values<'a, K, V> {\n+    pub fn values(&self) -> Values<K, V> {\n         self.iter().map(|(_k, v)| v)\n     }\n \n@@ -1038,8 +1189,8 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     ///     println!(\"key: {} val: {}\", key, val);\n     /// }\n     /// ```\n-    pub fn iter<'a>(&'a self) -> Entries<'a, K, V> {\n-        self.table.iter()\n+    pub fn iter(&self) -> Entries<K, V> {\n+        Entries { inner: self.table.iter() }\n     }\n \n     /// An iterator visiting all key-value pairs in arbitrary order,\n@@ -1065,8 +1216,8 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     ///     println!(\"key: {} val: {}\", key, val);\n     /// }\n     /// ```\n-    pub fn mut_iter<'a>(&'a mut self) -> MutEntries<'a, K, V> {\n-        self.table.mut_iter()\n+    pub fn mut_iter(&mut self) -> MutEntries<K, V> {\n+        MutEntries { inner: self.table.mut_iter() }\n     }\n \n     /// Creates a consuming iterator, that is, one that moves each key-value\n@@ -1087,7 +1238,9 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> HashMap<K, V, H> {\n     /// let vec: Vec<(&str, int)> = map.move_iter().collect();\n     /// ```\n     pub fn move_iter(self) -> MoveEntries<K, V> {\n-        self.table.move_iter().map(|(_, k, v)| (k, v))\n+        MoveEntries {\n+            inner: self.table.move_iter().map(|(_, k, v)| (k, v))\n+        }\n     }\n }\n \n@@ -1131,13 +1284,9 @@ impl<K: Eq + Hash<S>, V: PartialEq, S, H: Hasher<S>> PartialEq for HashMap<K, V,\n     fn eq(&self, other: &HashMap<K, V, H>) -> bool {\n         if self.len() != other.len() { return false; }\n \n-        self.iter()\n-          .all(|(key, value)| {\n-            match other.find(key) {\n-                None    => false,\n-                Some(v) => *value == *v\n-            }\n-        })\n+        self.iter().all(|(key, value)|\n+            other.find(key).map_or(false, |v| *value == *v)\n+        )\n     }\n }\n \n@@ -1178,14 +1327,52 @@ impl<K: Eq + Hash<S>, V, S, H: Hasher<S>> Index<K, V> for HashMap<K, V, H> {\n }*/\n \n /// HashMap iterator\n-pub type Entries<'a, K, V> = table::Entries<'a, K, V>;\n+pub struct Entries<'a, K: 'a, V: 'a> {\n+    inner: table::Entries<'a, K, V>\n+}\n \n /// HashMap mutable values iterator\n-pub type MutEntries<'a, K, V> = table::MutEntries<'a, K, V>;\n+pub struct MutEntries<'a, K: 'a, V: 'a> {\n+    inner: table::MutEntries<'a, K, V>\n+}\n \n /// HashMap move iterator\n-pub type MoveEntries<K, V> =\n-    iter::Map<'static, (table::SafeHash, K, V), (K, V), table::MoveEntries<K, V>>;\n+pub struct MoveEntries<K, V> {\n+    inner: iter::Map<'static, (SafeHash, K, V), (K, V), table::MoveEntries<K, V>>\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a V)> for Entries<'a, K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n+\n+impl<'a, K, V> Iterator<(&'a K, &'a mut V)> for MutEntries<'a, K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n+\n+impl<K, V> Iterator<(K, V)> for MoveEntries<K, V> {\n+    #[inline]\n+    fn next(&mut self) -> Option<(K, V)> {\n+        self.inner.next()\n+    }\n+    #[inline]\n+    fn size_hint(&self) -> (uint, Option<uint>) {\n+        self.inner.size_hint()\n+    }\n+}\n \n /// HashMap keys iterator\n pub type Keys<'a, K, V> =\n@@ -1266,7 +1453,6 @@ mod test_map {\n         k: uint\n     }\n \n-\n     impl Dropable {\n         fn new(k: uint) -> Dropable {\n             let v = drop_vector.get().unwrap();\n@@ -1371,6 +1557,7 @@ mod test_map {\n             hm\n         };\n \n+        // By the way, ensure that cloning doesn't screw up the dropping.\n         drop(hm.clone());\n \n         {\n@@ -1505,6 +1692,28 @@ mod test_map {\n         assert_eq!(*m.find(&1).unwrap(), 2);\n     }\n \n+    #[test]\n+    fn test_update_with() {\n+        let mut m = HashMap::with_capacity(4);\n+        assert!(m.insert(1i, 2i));\n+\n+        for i in range(1i, 1000) {\n+            assert_eq!(\n+                i + 2,\n+                *m.insert_or_update_with(i + 1, i + 2, |_k, _v| {\n+                    fail!(\"Key not yet present\");\n+                })\n+            );\n+            assert_eq!(\n+                i + 1,\n+                *m.insert_or_update_with(i, i + 3, |k, v| {\n+                    assert_eq!(*k, i);\n+                    assert_eq!(*v, i + 1);\n+                })\n+            );\n+        }\n+    }\n+\n     #[test]\n     fn test_conflict_remove() {\n         let mut m = HashMap::with_capacity(4);\n@@ -1698,6 +1907,7 @@ mod test_map {\n             m.insert(i, i);\n             i += 1;\n         }\n+        // three quarters full\n \n         assert_eq!(m.len(), i);\n         assert_eq!(m.table.capacity(), cap);\n@@ -1706,16 +1916,18 @@ mod test_map {\n             m.insert(i, i);\n             i += 1;\n         }\n+        // half full\n \n         let new_cap = m.table.capacity();\n         assert_eq!(new_cap, cap * 2);\n \n-        for _ in range(0, cap / 2) {\n+        for _ in range(0, cap / 2 - 1) {\n             i -= 1;\n             m.remove(&i);\n             assert_eq!(m.table.capacity(), new_cap);\n         }\n-\n+        // A little more than one quarter full.\n+        // Shrinking starts as we remove more elements:\n         for _ in range(0, cap / 2 - 1) {\n             i -= 1;\n             m.remove(&i);"}, {"sha": "b5612ce0f077d05cf8f525c2983ec1c836085cb2", "filename": "src/libstd/collections/hashmap/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fmod.rs?ref=ae7342a56a24eac539e3d4b13cd49c6719908426", "patch": "@@ -12,6 +12,7 @@\n \n pub use self::map::HashMap;\n pub use self::map::Entries;\n+pub use self::map::MutEntries;\n pub use self::map::MoveEntries;\n pub use self::map::Keys;\n pub use self::map::Values;"}, {"sha": "4a2a04cbc9f66b0ee452926fc5cda3361e39e37a", "filename": "src/libstd/collections/hashmap/set.rs", "status": "modified", "additions": 15, "deletions": 8, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Fset.rs?ref=ae7342a56a24eac539e3d4b13cd49c6719908426", "patch": "@@ -16,22 +16,21 @@ use collections::{Collection, Mutable, Set, MutableSet, Map, MutableMap};\n use default::Default;\n use fmt::Show;\n use fmt;\n-use RandomSipHasher;\n-use hash::{Hash, Hasher};\n+use hash::{Hash, Hasher, RandomSipHasher};\n use iter::{Iterator, FromIterator, FilterMap, Chain, Repeat, Zip, Extendable};\n use iter;\n use option::{Some, None};\n use result::{Ok, Err};\n \n use super::{HashMap, Entries, MoveEntries, INITIAL_CAPACITY};\n \n-/// HashSet iterator\n-pub type SetItems<'a, K> =\n-    iter::Map<'static, (&'a K, &'a ()), &'a K, Entries<'a, K, ()>>;\n \n-/// HashSet move iterator\n-pub type SetMoveItems<K> =\n-    iter::Map<'static, (K, ()), K, MoveEntries<K, ()>>;\n+// Future Optimization (FIXME!)\n+// =============================\n+//\n+// Iteration over zero sized values is a noop. There is no need\n+// for `bucket.val` in the case of HashSet. I suppose we would need HKT\n+// to get rid of it properly.\n \n /// An implementation of a hash set using the underlying representation of a\n /// HashMap where the value is (). As with the `HashMap` type, a `HashSet`\n@@ -444,6 +443,14 @@ impl<T: Eq + Hash<S>, S, H: Hasher<S> + Default> Default for HashSet<T, H> {\n     }\n }\n \n+/// HashSet iterator\n+pub type SetItems<'a, K> =\n+    iter::Map<'static, (&'a K, &'a ()), &'a K, Entries<'a, K, ()>>;\n+\n+/// HashSet move iterator\n+pub type SetMoveItems<K> =\n+    iter::Map<'static, (K, ()), K, MoveEntries<K, ()>>;\n+\n // `Repeat` is used to feed the filter closure an explicit capture\n // of a reference to the other set\n /// Set operations iterator"}, {"sha": "54469baaef5fa06d555bffaba1b1149adb66df43", "filename": "src/libstd/collections/hashmap/table.rs", "status": "modified", "additions": 302, "deletions": 300, "changes": 602, "blob_url": "https://github.com/rust-lang/rust/blob/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/ae7342a56a24eac539e3d4b13cd49c6719908426/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fcollections%2Fhashmap%2Ftable.rs?ref=ae7342a56a24eac539e3d4b13cd49c6719908426", "patch": "@@ -14,14 +14,13 @@ use clone::Clone;\n use cmp;\n use hash::{Hash, Hasher};\n use iter::{Iterator, count};\n+use kinds::marker;\n use mem::{min_align_of, size_of};\n use mem;\n-use num::{CheckedMul, is_power_of_two};\n+use num::{CheckedAdd, CheckedMul, is_power_of_two};\n use ops::{Deref, DerefMut, Drop};\n use option::{Some, None, Option};\n-use ptr::RawPtr;\n-use ptr::set_memory;\n-use ptr::write;\n+use ptr::{RawPtr, copy_nonoverlapping_memory, zero_memory};\n use ptr;\n use rt::heap::{allocate, deallocate};\n \n@@ -34,17 +33,17 @@ static EMPTY_BUCKET: u64 = 0u64;\n /// `Vec<Option<u64, K, V>>`, because we don't pay for the overhead of an\n /// option on every element, and we get a generally more cache-aware design.\n ///\n-/// Key invariants of this structure:\n+/// Essential invariants of this structure:\n ///\n-///   - if hashes[i] == EMPTY_BUCKET, then keys[i] and vals[i] have\n-///     'undefined' contents. Don't read from them. This invariant is\n-///     enforced outside this module with the `EmptyIndex`, `FullIndex`,\n+///   - if t.hashes[i] == EMPTY_BUCKET, then `Bucket::at_index(&t, i).raw`\n+///     points to 'undefined' contents. Don't read from it. This invariant is\n+///     enforced outside this module with the `EmptyBucket`, `FullBucket`,\n ///     and `SafeHash` types.\n ///\n-///   - An `EmptyIndex` is only constructed for a bucket at an index with\n+///   - An `EmptyBucket` is only constructed at an index with\n ///     a hash of EMPTY_BUCKET.\n ///\n-///   - A `FullIndex` is only constructed for a bucket at an index with a\n+///   - A `FullBucket` is only constructed at an index with a\n ///     non-EMPTY_BUCKET hash.\n ///\n ///   - A `SafeHash` is only constructed for non-`EMPTY_BUCKET` hash. We get\n@@ -56,48 +55,21 @@ static EMPTY_BUCKET: u64 = 0u64;\n ///     `capacity`. This is set at creation and never changes. The arrays\n ///     are unzipped to save space (we don't have to pay for the padding\n ///     between odd sized elements, such as in a map from u64 to u8), and\n-///     be more cache aware (scanning through 8 hashes brings in 2 cache\n-///     lines, since they're all right beside each other).\n+///     be more cache aware (scanning through 8 hashes brings in at most\n+///     2 cache lines, since they're all right beside each other).\n ///\n /// You can kind of think of this module/data structure as a safe wrapper\n /// around just the \"table\" part of the hashtable. It enforces some\n /// invariants at the type level and employs some performance trickery,\n /// but in general is just a tricked out `Vec<Option<u64, K, V>>`.\n-///\n-/// FIXME(cgaebel):\n-///\n-/// Feb 11, 2014: This hashtable was just implemented, and, hard as I tried,\n-/// isn't yet totally safe. There's a \"known exploit\" that you can create\n-/// multiple FullIndexes for a bucket, `take` one, and then still `take`\n-/// the other causing undefined behavior. Currently, there's no story\n-/// for how to protect against this statically. Therefore, there are asserts\n-/// on `take`, `get`, `get_mut`, and `put` which check the bucket state.\n-/// With time, and when we're confident this works correctly, they should\n-/// be removed. Also, the bounds check in `peek` is especially painful,\n-/// as that's called in the innermost loops of the hashtable and has the\n-/// potential to be a major performance drain. Remove this too.\n-///\n-/// Or, better than remove, only enable these checks for debug builds.\n-/// There's currently no \"debug-only\" asserts in rust, so if you're reading\n-/// this and going \"what? of course there are debug-only asserts!\", then\n-/// please make this use them!\n #[unsafe_no_drop_flag]\n pub struct RawTable<K, V> {\n     capacity: uint,\n     size:     uint,\n-    hashes:   *mut u64\n-}\n-\n-/// A bucket that holds a reference to the table\n-pub trait BucketWithTable<M> {\n-    /// A bucket that holds a reference to the table\n-    fn table<'a>(&'a self) -> &'a M;\n-\n-    /// Move out the reference to the table.\n-    fn into_table(self) -> M;\n-\n-    /// Get the raw index.\n-    fn index(&self) -> uint;\n+    hashes:   *mut u64,\n+    // Because K/V do not appear directly in any of the types in the struct,\n+    // inform rustc that in fact instances of K and V are reachable from here.\n+    marker:   marker::CovariantType<(K,V)>,\n }\n \n struct RawBucket<K, V> {\n@@ -124,83 +96,210 @@ pub struct FullBucket<K, V, M> {\n     table: M\n }\n \n-pub type EmptyBucketImm<'table,K,V> = EmptyBucket<K, V, &'table RawTable<K,V>>;\n-pub type  FullBucketImm<'table,K,V> =  FullBucket<K, V, &'table RawTable<K,V>>;\n+pub type EmptyBucketImm<'table, K, V> = EmptyBucket<K, V, &'table RawTable<K, V>>;\n+pub type  FullBucketImm<'table, K, V> =  FullBucket<K, V, &'table RawTable<K, V>>;\n \n-pub type EmptyBucketMut<'table,K,V> = EmptyBucket<K, V, &'table mut RawTable<K,V>>;\n-pub type  FullBucketMut<'table,K,V> =  FullBucket<K, V, &'table mut RawTable<K,V>>;\n+pub type EmptyBucketMut<'table, K, V> = EmptyBucket<K, V, &'table mut RawTable<K, V>>;\n+pub type  FullBucketMut<'table, K, V> =  FullBucket<K, V, &'table mut RawTable<K, V>>;\n \n+pub enum BucketState<K, V, M> {\n+    Empty(EmptyBucket<K, V, M>),\n+    Full(FullBucket<K, V, M>),\n+}\n+\n+// A GapThenFull encapsulates the state of two consecutive buckets at once.\n+// The first bucket, called the gap, is known to be empty.\n+// The second bucket is full.\n struct GapThenFull<K, V, M> {\n     gap: EmptyBucket<K, V, ()>,\n-    full: FullBucket<K, V, M>\n+    full: FullBucket<K, V, M>,\n }\n \n-impl<K, V, M: Deref<RawTable<K,V>>> GapThenFull<K, V, M> {\n-    pub fn full<'a>(&'a self) -> &'a FullBucket<K, V, M> {\n-        &self.full\n-    }\n-\n-    pub fn shift(mut self) -> Option<GapThenFull<K, V, M>> {\n-        unsafe {\n-            *self.gap.raw.hash = mem::replace(&mut *self.full.raw.hash, EMPTY_BUCKET);\n-            mem::overwrite(self.gap.raw.key, ptr::read(self.full.raw.key as *const K));\n-            mem::overwrite(self.gap.raw.val, ptr::read(self.full.raw.val as *const V));\n-        }\n-\n-        let FullBucket { raw, idx, .. } = self.full;\n-\n-        match self.full.next().peek() {\n-            Empty(_) => None,\n-            Full(bucket) => {\n-                self.gap.raw = raw;\n-                self.gap.idx = idx;\n+/// A hash that is not zero, since we use a hash of zero to represent empty\n+/// buckets.\n+#[deriving(PartialEq)]\n+pub struct SafeHash {\n+    hash: u64,\n+}\n \n-                self.full = bucket;\n-                self.full.idx &= self.full.table.capacity - 1;\n+impl SafeHash {\n+    /// Peek at the hash value, which is guaranteed to be non-zero.\n+    #[inline(always)]\n+    pub fn inspect(&self) -> u64 { self.hash }\n+}\n \n-                Some(self)\n-            }\n-        }\n+/// We need to remove hashes of 0. That's reserved for empty buckets.\n+/// This function wraps up `hash_keyed` to be the only way outside this\n+/// module to generate a SafeHash.\n+pub fn make_hash<T: Hash<S>, S, H: Hasher<S>>(hasher: &H, t: &T) -> SafeHash {\n+    match hasher.hash(t) {\n+        // This constant is exceedingly likely to hash to the same\n+        // bucket, but it won't be counted as empty! Just so we can maintain\n+        // our precious uniform distribution of initial indexes.\n+        EMPTY_BUCKET => SafeHash { hash: 0x8000_0000_0000_0000 },\n+        h            => SafeHash { hash: h },\n     }\n }\n \n-impl<K, V> RawPtr<u64> for RawBucket<K, V> {\n+// `replace` casts a `*u64` to a `*SafeHash`. Since we statically\n+// ensure that a `FullBucket` points to an index with a non-zero hash,\n+// and a `SafeHash` is just a `u64` with a different name, this is\n+// safe.\n+//\n+// This test ensures that a `SafeHash` really IS the same size as a\n+// `u64`. If you need to change the size of `SafeHash` (and\n+// consequently made this test fail), `replace` needs to be\n+// modified to no longer assume this.\n+#[test]\n+fn can_alias_safehash_as_u64() {\n+    assert_eq!(size_of::<SafeHash>(), size_of::<u64>())\n+}\n+\n+impl<K, V> RawBucket<K, V> {\n     unsafe fn offset(self, count: int) -> RawBucket<K, V> {\n         RawBucket {\n             hash: self.hash.offset(count),\n             key:  self.key.offset(count),\n             val:  self.val.offset(count),\n         }\n     }\n+}\n \n-    fn null() -> RawBucket<K, V> {\n-        RawBucket {\n-            hash: RawPtr::null(),\n-            key:  RawPtr::null(),\n-            val:  RawPtr::null()\n+// For parameterizing over mutability.\n+impl<'t, K, V> Deref<RawTable<K, V>> for &'t RawTable<K, V> {\n+    fn deref(&self) -> &RawTable<K, V> {\n+        &**self\n+    }\n+}\n+\n+impl<'t, K, V> Deref<RawTable<K, V>> for &'t mut RawTable<K, V> {\n+    fn deref(&self) -> &RawTable<K,V> {\n+        &**self\n+    }\n+}\n+\n+impl<'t, K, V> DerefMut<RawTable<K, V>> for &'t mut RawTable<K, V> {\n+    fn deref_mut(&mut self) -> &mut RawTable<K,V> {\n+        &mut **self\n+    }\n+}\n+\n+// Buckets hold references to the table.\n+impl<K, V, M> FullBucket<K, V, M> {\n+    /// Borrow a reference to the table.\n+    pub fn table(&self) -> &M {\n+        &self.table\n+    }\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+    /// Get the raw index.\n+    pub fn index(&self) -> uint {\n+        self.idx\n+    }\n+}\n+\n+impl<K, V, M> EmptyBucket<K, V, M> {\n+    /// Borrow a reference to the table.\n+    pub fn table(&self) -> &M {\n+        &self.table\n+    }\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+}\n+\n+impl<K, V, M> Bucket<K, V, M> {\n+    /// Move out the reference to the table.\n+    pub fn into_table(self) -> M {\n+        self.table\n+    }\n+    /// Get the raw index.\n+    pub fn index(&self) -> uint {\n+        self.idx\n+    }\n+}\n+\n+impl<K, V, M: Deref<RawTable<K, V>>> Bucket<K, V, M> {\n+    pub fn new(table: M, hash: &SafeHash) -> Bucket<K, V, M> {\n+        Bucket::at_index(table, hash.inspect() as uint)\n+    }\n+\n+    pub fn at_index(table: M, ib_index: uint) -> Bucket<K, V, M> {\n+        let ib_index = ib_index & (table.capacity() - 1);\n+        Bucket {\n+            raw: unsafe {\n+               table.first_bucket_raw().offset(ib_index as int)\n+            },\n+            idx: ib_index,\n+            table: table\n         }\n     }\n \n-    fn is_null(&self) -> bool {\n-        self.hash.is_null()\n+    pub fn first(table: M) -> Bucket<K, V, M> {\n+        Bucket {\n+            raw: table.first_bucket_raw(),\n+            idx: 0,\n+            table: table\n+        }\n     }\n \n-    fn to_uint(&self) -> uint {\n-        self.hash.to_uint()\n+    /// Reads a bucket at a given index, returning an enum indicating whether\n+    /// it's initialized or not. You need to match on this enum to get\n+    /// the appropriate types to call most of the other functions in\n+    /// this module.\n+    pub fn peek(self) -> BucketState<K, V, M> {\n+        match unsafe { *self.raw.hash } {\n+            EMPTY_BUCKET =>\n+                Empty(EmptyBucket {\n+                    raw: self.raw,\n+                    idx: self.idx,\n+                    table: self.table\n+                }),\n+            _ =>\n+                Full(FullBucket {\n+                    raw: self.raw,\n+                    idx: self.idx,\n+                    table: self.table\n+                })\n+        }\n     }\n \n-    unsafe fn to_option(&self) -> Option<&u64> {\n-        self.hash.to_option()\n+    /// Modifies the bucket pointer in place to make it point to the next slot.\n+    pub fn next(&mut self) {\n+        // Branchless bucket iteration step.\n+        // As we reach the end of the table...\n+        // We take the current idx:          0111111b\n+        // Xor it by its increment:        ^ 1000000b\n+        //                               ------------\n+        //                                   1111111b\n+        // Then AND with the capacity:     & 1000000b\n+        //                               ------------\n+        // to get the backwards offset:      1000000b\n+        // ... and it's zero at all other times.\n+        let maybe_wraparound_dist = (self.idx ^ (self.idx + 1)) & self.table.capacity();\n+        // Finally, we obtain the offset 1 or the offset -cap + 1.\n+        let dist = 1i - (maybe_wraparound_dist as int);\n+\n+        self.idx += 1;\n+\n+        unsafe {\n+            self.raw = self.raw.offset(dist);\n+        }\n     }\n }\n \n-impl<K, V, M: Deref<RawTable<K,V>>> EmptyBucket<K, V, M> {\n+impl<K, V, M: Deref<RawTable<K, V>>> EmptyBucket<K, V, M> {\n+    #[inline]\n     pub fn next(self) -> Bucket<K, V, M> {\n         let mut bucket = self.into_bucket();\n         bucket.next();\n         bucket\n     }\n \n+    #[inline]\n     pub fn into_bucket(self) -> Bucket<K, V, M> {\n         Bucket {\n             raw: self.raw,\n@@ -217,24 +316,31 @@ impl<K, V, M: Deref<RawTable<K,V>>> EmptyBucket<K, V, M> {\n         };\n \n         match self.next().peek() {\n-            Empty(_) => None,\n             Full(bucket) => {\n                 Some(GapThenFull {\n                     gap: gap,\n                     full: bucket\n                 })\n             }\n+            Empty(..) => None\n         }\n     }\n }\n \n-impl<K, V, M: DerefMut<RawTable<K,V>>> EmptyBucket<K, V, M> {\n+impl<K, V, M: DerefMut<RawTable<K, V>>> EmptyBucket<K, V, M> {\n+    /// Puts given key and value pair, along with the key's hash,\n+    /// into this bucket in the hashtable. Note how `self` is 'moved' into\n+    /// this function, because this slot will no longer be empty when\n+    /// we return! A `FullBucket` is returned for later use, pointing to\n+    /// the newly-filled slot in the hashtable.\n+    ///\n+    /// Use `make_hash` to construct a `SafeHash` to pass to this function.\n     pub fn put(mut self, hash: SafeHash, key: K, value: V)\n                -> FullBucket<K, V, M> {\n         unsafe {\n             *self.raw.hash = hash.inspect();\n-            write(self.raw.key, key);\n-            write(self.raw.val, value);\n+            ptr::write(self.raw.key, key);\n+            ptr::write(self.raw.val, value);\n         }\n \n         self.table.size += 1;\n@@ -243,13 +349,15 @@ impl<K, V, M: DerefMut<RawTable<K,V>>> EmptyBucket<K, V, M> {\n     }\n }\n \n-impl<K, V, M: Deref<RawTable<K,V>>> FullBucket<K, V, M> {\n+impl<K, V, M: Deref<RawTable<K, V>>> FullBucket<K, V, M> {\n+    #[inline]\n     pub fn next(self) -> Bucket<K, V, M> {\n         let mut bucket = self.into_bucket();\n         bucket.next();\n         bucket\n     }\n \n+    #[inline]\n     pub fn into_bucket(self) -> Bucket<K, V, M> {\n         Bucket {\n             raw: self.raw,\n@@ -258,10 +366,19 @@ impl<K, V, M: Deref<RawTable<K,V>>> FullBucket<K, V, M> {\n         }\n     }\n \n+    /// Get the distance between this bucket and the 'ideal' location\n+    /// as determined by the key's hash stored in it.\n+    ///\n+    /// In the cited blog posts above, this is called the \"distance to\n+    /// initial bucket\", or DIB. Also known as \"probe count\".\n     pub fn distance(&self) -> uint {\n+        // Calculates the distance one has to travel when going from\n+        // `hash mod capacity` onwards to `idx mod capacity`, wrapping around\n+        // if the destination is not reached before the end of the table.\n         (self.idx - self.hash().inspect() as uint) & (self.table.capacity() - 1)\n     }\n \n+    #[inline]\n     pub fn hash(&self) -> SafeHash {\n         unsafe {\n             SafeHash {\n@@ -270,23 +387,20 @@ impl<K, V, M: Deref<RawTable<K,V>>> FullBucket<K, V, M> {\n         }\n     }\n \n-    pub fn read<'a>(&'a self) -> (&'a K, &'a V) {\n-        unsafe {\n-            (&*self.raw.key,\n-             &*self.raw.val)\n-        }\n-    }\n-\n-    pub fn into_refs(self) -> (&K, &V) {\n+    /// Gets references to the key and value at a given index.\n+    pub fn read(&self) -> (&K, &V) {\n         unsafe {\n-            // debug_assert!(*self.raw.hash != EMPTY_BUCKET);\n             (&*self.raw.key,\n              &*self.raw.val)\n         }\n     }\n }\n \n-impl<K, V, M: DerefMut<RawTable<K,V>>> FullBucket<K, V, M> {\n+impl<K, V, M: DerefMut<RawTable<K, V>>> FullBucket<K, V, M> {\n+    /// Removes this bucket's key and value from the hashtable.\n+    ///\n+    /// This works similarly to `put`, building an `EmptyBucket` out of the\n+    /// taken bucket.\n     pub fn take(mut self) -> (EmptyBucket<K, V, M>, K, V) {\n         let key = self.raw.key as *const K;\n         let val = self.raw.val as *const V;\n@@ -317,176 +431,86 @@ impl<K, V, M: DerefMut<RawTable<K,V>>> FullBucket<K, V, M> {\n         }\n     }\n \n-    pub fn read_mut<'a>(&'a self) -> (&'a mut K, &'a mut V) {\n+    /// Gets mutable references to the key and value at a given index.\n+    pub fn read_mut(&mut self) -> (&mut K, &mut V) {\n         unsafe {\n-            // debug_assert!(*self.raw.hash != EMPTY_BUCKET);\n             (&mut *self.raw.key,\n              &mut *self.raw.val)\n         }\n     }\n+}\n \n-    pub fn into_mut_refs(self) -> (&mut K, &mut V) {\n+impl<'t, K, V, M: Deref<RawTable<K, V>> + 't> FullBucket<K, V, M> {\n+    /// Exchange a bucket state for immutable references into the table.\n+    /// Because the underlying reference to the table is also consumed,\n+    /// no further changes to the structure of the table are possible;\n+    /// in exchange for this, the returned references have a longer lifetime\n+    /// than the references returned by `read()`.\n+    pub fn into_refs(self) -> (&'t K, &'t V) {\n         unsafe {\n-            // debug_assert!(*self.raw.hash != EMPTY_BUCKET);\n-            (&mut *self.raw.key,\n-             &mut *self.raw.val)\n+            (&*self.raw.key,\n+             &*self.raw.val)\n         }\n     }\n }\n \n-impl<K, V, M: Deref<RawTable<K,V>>> Bucket<K, V, M> {\n-    pub fn new(table: M, hash: &SafeHash) -> Bucket<K, V, M> {\n-        let ib_index = (hash.inspect() as uint) & (table.capacity() - 1);\n-        Bucket {\n-            raw: unsafe {\n-               table.as_mut_ptrs().offset(ib_index as int)\n-            },\n-            idx: ib_index,\n-            table: table\n-        }\n-    }\n-\n-    pub fn at_index(table: M, ib_index: uint) -> Bucket<K, V, M> {\n-        let ib_index = ib_index & (table.capacity() - 1);\n-        Bucket {\n-            raw: unsafe {\n-               table.as_mut_ptrs().offset(ib_index as int)\n-            },\n-            idx: ib_index,\n-            table: table\n-        }\n-    }\n-\n-    pub fn first(table: M) -> Bucket<K, V, M> {\n-        Bucket {\n-            raw: table.as_mut_ptrs(),\n-            idx: 0,\n-            table: table\n-        }\n-    }\n-\n-    pub fn peek(self) -> BucketState<K, V, M> {\n-        match unsafe { *self.raw.hash } {\n-            EMPTY_BUCKET =>\n-                Empty(EmptyBucket {\n-                    raw: self.raw,\n-                    idx: self.idx,\n-                    table: self.table\n-                }),\n-            _ =>\n-                Full(FullBucket {\n-                    raw: self.raw,\n-                    idx: self.idx,\n-                    table: self.table\n-                })\n-        }\n-    }\n-\n-    pub fn next(&mut self) {\n-        self.idx += 1;\n-\n-        let dist = if self.idx == self.table.capacity() {\n-            -(self.table.capacity() as int - 1)\n-        } else {\n-            1i\n-        };\n-\n+impl<'t, K, V, M: DerefMut<RawTable<K, V>> + 't> FullBucket<K, V, M> {\n+    /// This works similarly to `into_refs`, exchanging a bucket state\n+    /// for mutable references into the table.\n+    pub fn into_mut_refs(self) -> (&'t mut K, &'t mut V) {\n         unsafe {\n-            self.raw = self.raw.offset(dist);\n+            (&mut *self.raw.key,\n+             &mut *self.raw.val)\n         }\n     }\n }\n \n-impl<K, V, M> BucketWithTable<M> for FullBucket<K, V, M> {\n-    fn table<'a>(&'a self) -> &'a M {\n-        &self.table\n-    }\n-\n-    fn into_table(self) -> M {\n-        self.table\n-    }\n-\n-    fn index(&self) -> uint {\n-        self.idx\n-    }\n-}\n-\n-impl<K, V, M> BucketWithTable<M> for EmptyBucket<K, V, M> {\n-    fn table<'a>(&'a self) -> &'a M {\n-        &self.table\n-    }\n-\n-    fn into_table(self) -> M {\n-        self.table\n-    }\n-\n-    fn index(&self) -> uint {\n-        self.idx\n+impl<K, V, M> BucketState<K, V, M> {\n+    // For convenience.\n+    pub fn expect_full(self) -> FullBucket<K, V, M> {\n+        match self {\n+            Full(full) => full,\n+            Empty(..) => fail!(\"Expected full bucket\")\n+        }\n     }\n }\n \n-impl<K, V, M> BucketWithTable<M> for Bucket<K, V, M> {\n-    fn table<'a>(&'a self) -> &'a M {\n-        &self.table\n+impl<K, V, M: Deref<RawTable<K, V>>> GapThenFull<K, V, M> {\n+    #[inline]\n+    pub fn full(&self) -> &FullBucket<K, V, M> {\n+        &self.full\n     }\n \n-    fn into_table(self) -> M {\n-        self.table\n-    }\n+    pub fn shift(mut self) -> Option<GapThenFull<K, V, M>> {\n+        unsafe {\n+            *self.gap.raw.hash = mem::replace(&mut *self.full.raw.hash, EMPTY_BUCKET);\n+            copy_nonoverlapping_memory(self.gap.raw.key, self.full.raw.key as *const K, 1);\n+            copy_nonoverlapping_memory(self.gap.raw.val, self.full.raw.val as *const V, 1);\n+        }\n \n-    fn index(&self) -> uint {\n-        self.idx\n-    }\n-}\n+        let FullBucket { raw: prev_raw, idx: prev_idx, .. } = self.full;\n \n-impl<'table,K,V> Deref<RawTable<K,V>> for &'table RawTable<K,V> {\n-    fn deref<'a>(&'a self) -> &'a RawTable<K,V> {\n-        &**self\n-    }\n-}\n+        match self.full.next().peek() {\n+            Full(bucket) => {\n+                self.gap.raw = prev_raw;\n+                self.gap.idx = prev_idx;\n \n-impl<'table,K,V> Deref<RawTable<K,V>> for &'table mut RawTable<K,V> {\n-    fn deref<'a>(&'a self) -> &'a RawTable<K,V> {\n-        &**self\n-    }\n-}\n+                self.full = bucket;\n \n-impl<'table,K,V> DerefMut<RawTable<K,V>> for &'table mut RawTable<K,V> {\n-    fn deref_mut<'a>(&'a mut self) -> &'a mut RawTable<K,V> {\n-        &mut **self\n+                Some(self)\n+            }\n+            Empty(..) => None\n+        }\n     }\n }\n \n-pub enum BucketState<K, V, M> {\n-    Empty(EmptyBucket<K, V, M>),\n-    Full(FullBucket<K, V, M>),\n-}\n-\n-/// A hash that is not zero, since we use a hash of zero to represent empty\n-/// buckets.\n-#[deriving(PartialEq)]\n-pub struct SafeHash {\n-    hash: u64,\n-}\n-\n-impl SafeHash {\n-    /// Peek at the hash value, which is guaranteed to be non-zero.\n-    #[inline(always)]\n-    pub fn inspect(&self) -> u64 { self.hash }\n-}\n-\n-/// We need to remove hashes of 0. That's reserved for empty buckets.\n-/// This function wraps up `hash_keyed` to be the only way outside this\n-/// module to generate a SafeHash.\n-pub fn make_hash<T: Hash<S>, S, H: Hasher<S>>(hasher: &H, t: &T) -> SafeHash {\n-    match hasher.hash(t) {\n-        // This constant is exceedingly likely to hash to the same\n-        // bucket, but it won't be counted as empty!\n-        EMPTY_BUCKET => SafeHash { hash: 0x8000_0000_0000_0000 },\n-        h            => SafeHash { hash: h },\n-    }\n-}\n \n+/// Rounds up to a multiple of a power of two. Returns the closest multiple\n+/// of `target_alignment` that is higher or equal to `unrounded`.\n+///\n+/// # Failure\n+///\n+/// Fails if `target_alignment` is not a power of two.\n fn round_up_to_next(unrounded: uint, target_alignment: uint) -> uint {\n     assert!(is_power_of_two(target_alignment));\n     (unrounded + target_alignment - 1) & !(target_alignment - 1)\n@@ -531,7 +555,6 @@ fn test_offset_calculation() {\n }\n \n impl<K, V> RawTable<K, V> {\n-\n     /// Does not initialize the buckets. The caller should ensure they,\n     /// at the very least, set every hash to EMPTY_BUCKET.\n     unsafe fn new_uninitialized(capacity: uint) -> RawTable<K, V> {\n@@ -540,6 +563,7 @@ impl<K, V> RawTable<K, V> {\n                 size: 0,\n                 capacity: 0,\n                 hashes: 0 as *mut u64,\n+                marker: marker::CovariantType,\n             };\n         }\n         let hashes_size = capacity.checked_mul(&size_of::<u64>())\n@@ -571,17 +595,18 @@ impl<K, V> RawTable<K, V> {\n             capacity: capacity,\n             size:     0,\n             hashes:   hashes,\n+            marker:   marker::CovariantType,\n         }\n     }\n \n-    fn as_mut_ptrs(&self) -> RawBucket<K, V> {\n+    fn first_bucket_raw(&self) -> RawBucket<K, V> {\n         let hashes_size = self.capacity * size_of::<u64>();\n         let keys_size = self.capacity * size_of::<K>();\n \n-        let keys_offset = (hashes_size + min_align_of::< K >() - 1) & !(min_align_of::< K >() - 1);\n+        let keys_offset = (hashes_size + min_align_of::<K>() - 1) & !(min_align_of::<K>() - 1);\n         let end_of_keys = keys_offset + keys_size;\n \n-        let vals_offset = (end_of_keys + min_align_of::< V >() - 1) & !(min_align_of::< V >() - 1);\n+        let vals_offset = (end_of_keys + min_align_of::<V>() - 1) & !(min_align_of::<V>() - 1);\n \n         let buffer = self.hashes as *mut u8;\n \n@@ -600,7 +625,7 @@ impl<K, V> RawTable<K, V> {\n     pub fn new(capacity: uint) -> RawTable<K, V> {\n         unsafe {\n             let ret = RawTable::new_uninitialized(capacity);\n-            set_memory(ret.hashes, 0u8, capacity);\n+            zero_memory(ret.hashes, capacity);\n             ret\n         }\n     }\n@@ -616,49 +641,51 @@ impl<K, V> RawTable<K, V> {\n         self.size\n     }\n \n-    fn ptrs<'a>(&'a self) -> RawBuckets<'a, K, V> {\n+    fn raw_buckets(&self) -> RawBuckets<K, V> {\n         RawBuckets {\n-            raw: self.as_mut_ptrs(),\n+            raw: self.first_bucket_raw(),\n             hashes_end: unsafe {\n                 self.hashes.offset(self.capacity as int)\n             }\n         }\n     }\n \n-    pub fn iter<'a>(&'a self) -> Entries<'a, K, V> {\n+    pub fn iter(&self) -> Entries<K, V> {\n         Entries {\n-            iter: self.ptrs(),\n+            iter: self.raw_buckets(),\n             elems_left: self.size(),\n         }\n     }\n \n-    pub fn mut_iter<'a>(&'a mut self) -> MutEntries<'a, K, V> {\n+    pub fn mut_iter(&mut self) -> MutEntries<K, V> {\n         MutEntries {\n-            iter: self.ptrs(),\n+            iter: self.raw_buckets(),\n             elems_left: self.size(),\n         }\n     }\n \n     pub fn move_iter(self) -> MoveEntries<K, V> {\n         MoveEntries {\n-            iter: self.ptrs(),\n+            iter: self.raw_buckets(),\n             table: self,\n         }\n     }\n \n-    pub fn rev_move_buckets<'a>(&'a mut self) -> RevMoveBuckets<'a, K, V> {\n-        let raw_bucket = self.as_mut_ptrs();\n-        unsafe {\n-            RevMoveBuckets {\n-                raw: raw_bucket.offset(self.capacity as int),\n-                hashes_end: raw_bucket.hash,\n-                elems_left: self.size\n-            }\n+    /// Returns an iterator that copies out each entry. Used while the table\n+    /// is being dropped.\n+    unsafe fn rev_move_buckets(&mut self) -> RevMoveBuckets<K, V> {\n+        let raw_bucket = self.first_bucket_raw();\n+        RevMoveBuckets {\n+            raw: raw_bucket.offset(self.capacity as int),\n+            hashes_end: raw_bucket.hash,\n+            elems_left: self.size\n         }\n     }\n }\n \n-pub struct RawBuckets<'a, K, V> {\n+/// A raw iterator. The basis for some other iterators in this module. Although\n+/// this interface is safe, it's not used outside this module.\n+struct RawBuckets<'a, K, V> {\n     raw: RawBucket<K, V>,\n     hashes_end: *mut u64\n }\n@@ -667,6 +694,8 @@ impl<'a, K, V> Iterator<RawBucket<K, V>> for RawBuckets<'a, K, V> {\n     fn next(&mut self) -> Option<RawBucket<K, V>> {\n         while self.raw.hash != self.hashes_end {\n             unsafe {\n+                // We are swapping out the pointer to a bucket and replacing\n+                // it with the pointer to the next one.\n                 let prev = ptr::replace(&mut self.raw, self.raw.offset(1));\n                 if *prev.hash != EMPTY_BUCKET {\n                     return Some(prev);\n@@ -678,7 +707,10 @@ impl<'a, K, V> Iterator<RawBucket<K, V>> for RawBuckets<'a, K, V> {\n     }\n }\n \n-pub struct RevMoveBuckets<'a, K, V> {\n+/// An iterator that moves out buckets in reverse order. It leaves the table\n+/// in an an inconsistent state and should only be used for dropping\n+/// the table's remaining entries. It's used in the implementation of Drop.\n+struct RevMoveBuckets<'a, K, V> {\n     raw: RawBucket<K, V>,\n     hashes_end: *mut u64,\n     elems_left: uint\n@@ -708,43 +740,13 @@ impl<'a, K, V> Iterator<(K, V)> for RevMoveBuckets<'a, K, V> {\n     }\n }\n \n-// `read_all_mut` casts a `*u64` to a `*SafeHash`. Since we statically\n-// ensure that a `FullIndex` points to an index with a non-zero hash,\n-// and a `SafeHash` is just a `u64` with a different name, this is\n-// safe.\n-//\n-// This test ensures that a `SafeHash` really IS the same size as a\n-// `u64`. If you need to change the size of `SafeHash` (and\n-// consequently made this test fail), `read_all_mut` needs to be\n-// modified to no longer assume this.\n-#[test]\n-fn can_alias_safehash_as_u64() {\n-    assert_eq!(size_of::<SafeHash>(), size_of::<u64>())\n-}\n-\n-/// Note: stage0-specific version that lacks bound.\n-#[cfg(stage0)]\n-pub struct Entries<'a, K, V> {\n-    iter: RawBuckets<'a, K, V>,\n-    elems_left: uint,\n-}\n-\n /// Iterator over shared references to entries in a table.\n-#[cfg(not(stage0))]\n pub struct Entries<'a, K: 'a, V: 'a> {\n     iter: RawBuckets<'a, K, V>,\n     elems_left: uint,\n }\n \n-/// Note: stage0-specific version that lacks bound.\n-#[cfg(stage0)]\n-pub struct MutEntries<'a, K, V> {\n-    iter: RawBuckets<'a, K, V>,\n-    elems_left: uint,\n-}\n-\n /// Iterator over mutable references to entries in a table.\n-#[cfg(not(stage0))]\n pub struct MutEntries<'a, K: 'a, V: 'a> {\n     iter: RawBuckets<'a, K, V>,\n     elems_left: uint,\n@@ -830,14 +832,14 @@ impl<K: Clone, V: Clone> Clone for RawTable<K, V> {\n                             mem::overwrite(new_buckets.raw.key, k);\n                             mem::overwrite(new_buckets.raw.val, v);\n                         }\n-                        _  => {\n+                        Empty(..) => {\n                             *new_buckets.raw.hash = EMPTY_BUCKET;\n                         }\n                     }\n                     new_buckets.next();\n                     buckets.next();\n                 }\n-            }\n+            };\n \n             new_ht.size = self.size();\n \n@@ -852,12 +854,14 @@ impl<K, V> Drop for RawTable<K, V> {\n         if self.hashes.is_null() {\n             return;\n         }\n-        // This is in reverse because we're likely to have partially taken\n+        // This is done in reverse because we've likely partially taken\n         // some elements out with `.move_iter()` from the front.\n         // Check if the size is 0, so we don't do a useless scan when\n         // dropping empty tables such as on resize.\n-        // Avoid double free of elements already moved out.\n-        for _ in self.rev_move_buckets() {}\n+        // Also avoid double drop of elements that have been already moved out.\n+        unsafe {\n+            for _ in self.rev_move_buckets() {}\n+        }\n \n         let hashes_size = self.capacity * size_of::<u64>();\n         let keys_size = self.capacity * size_of::<K>();\n@@ -871,7 +875,5 @@ impl<K, V> Drop for RawTable<K, V> {\n             // Remember how everything was allocated out of one buffer\n             // during initialization? We only need one call to free here.\n         }\n-\n-        self.hashes = RawPtr::null();\n     }\n }"}]}