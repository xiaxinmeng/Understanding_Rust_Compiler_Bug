{"sha": "7f9b1fbe350ee16008f16f13254420da3679f60d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdmOWIxZmJlMzUwZWUxNjAwOGYxNmYxMzI1NDQyMGRhMzY3OWY2MGQ=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-07-05T21:30:56Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-07-06T01:09:31Z"}, "message": "Add new syntax for interpolation and repetition, and allow the transcription of separators.", "tree": {"sha": "76ac374725059aa4801ab9712937277aaa0a843d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/76ac374725059aa4801ab9712937277aaa0a843d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7f9b1fbe350ee16008f16f13254420da3679f60d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7f9b1fbe350ee16008f16f13254420da3679f60d", "html_url": "https://github.com/rust-lang/rust/commit/7f9b1fbe350ee16008f16f13254420da3679f60d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7f9b1fbe350ee16008f16f13254420da3679f60d/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "62db5706e668166f7196463bf34939da7d51093d", "url": "https://api.github.com/repos/rust-lang/rust/commits/62db5706e668166f7196463bf34939da7d51093d", "html_url": "https://github.com/rust-lang/rust/commit/62db5706e668166f7196463bf34939da7d51093d"}], "stats": {"total": 109, "additions": 70, "deletions": 39}, "files": [{"sha": "a817faad0691e2993c18337c81b7aeac725183a4", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=7f9b1fbe350ee16008f16f13254420da3679f60d", "patch": "@@ -379,7 +379,7 @@ enum token_tree {\n     tt_delim(~[token_tree]),\n     tt_flat(span, token::token),\n     /* These only make sense for right-hand-sides of MBE macros*/\n-    tt_dotdotdot(span, ~[token_tree]),\n+    tt_dotdotdot(span, ~[token_tree], option<token::token>, bool),\n     tt_interpolate(span, ident)\n }\n "}, {"sha": "e84bc5c5421ae1bef04aba058b8f5e5d3464e378", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 20, "deletions": 8, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=7f9b1fbe350ee16008f16f13254420da3679f60d", "patch": "@@ -18,7 +18,8 @@ type tt_frame = @{\n     readme: ~[ast::token_tree],\n     mut idx: uint,\n     dotdotdoted: bool,\n-    up: tt_frame_up\n+    sep: option<token>,\n+    up: tt_frame_up,\n };\n \n type tt_reader = @{\n@@ -43,7 +44,7 @@ fn new_tt_reader(span_diagnostic: span_handler, itr: @interner<@str>,\n     -> tt_reader {\n     let r = @{span_diagnostic: span_diagnostic, interner: itr,\n               mut cur: @{readme: src, mut idx: 0u, dotdotdoted: false,\n-                         up: tt_frame_up(option::none)},\n+                         sep: none, up: tt_frame_up(option::none)},\n               interpolations: alt interp { /* just a convienience */\n                 none { std::map::box_str_hash::<@arb_depth>() }\n                 some(x) { x }\n@@ -59,7 +60,7 @@ fn new_tt_reader(span_diagnostic: span_handler, itr: @interner<@str>,\n \n pure fn dup_tt_frame(&&f: tt_frame) -> tt_frame {\n     @{readme: f.readme, mut idx: f.idx, dotdotdoted: f.dotdotdoted,\n-      up: alt f.up {\n+      sep: f.sep, up: alt f.up {\n         tt_frame_up(some(up_frame)) {\n           tt_frame_up(some(dup_tt_frame(up_frame)))\n         }\n@@ -114,7 +115,7 @@ fn lockstep_iter_size(&&t: token_tree, &&r: tt_reader) -> lis {\n         }\n     }\n     alt t {\n-      tt_delim(tts) | tt_dotdotdot(_, tts) {\n+      tt_delim(tts) | tt_dotdotdot(_, tts, _, _) {\n         vec::foldl(lis_unconstrained, tts, {|lis, tt|\n             lis_merge(lis, lockstep_iter_size(tt, r)) })\n       }\n@@ -155,6 +156,13 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n         } else {\n             r.cur.idx = 0u;\n             r.repeat_idx[r.repeat_idx.len() - 1u] += 1u;\n+            alt r.cur.sep {\n+              some(tk) {\n+                r.cur_tok = tk; /* repeat same span, I guess */\n+                ret ret_val;\n+              }\n+              none {}\n+            }\n         }\n     }\n     /* if `tt_delim`s could be 0-length, we'd need to be able to switch\n@@ -164,15 +172,15 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n         alt r.cur.readme[r.cur.idx] {\n           tt_delim(tts) {\n             r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: false,\n-                      up: tt_frame_up(option::some(r.cur)) };\n+                      sep: none, up: tt_frame_up(option::some(r.cur)) };\n           }\n           tt_flat(sp, tok) {\n             r.cur_span = sp; r.cur_tok = tok;\n             r.cur.idx += 1u;\n             ret ret_val;\n           }\n-          tt_dotdotdot(sp, tts) {\n-            alt lockstep_iter_size(tt_dotdotdot(sp, tts), r) {\n+          tt_dotdotdot(sp, tts, sep, zerok) {\n+            alt lockstep_iter_size(tt_dotdotdot(sp, tts, sep, zerok), r) {\n               lis_unconstrained {\n                 r.span_diagnostic.span_fatal(\n                     copy r.cur_span, /* blame macro writer */\n@@ -183,10 +191,14 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token, sp: span} {\n                 r.span_diagnostic.span_fatal(sp, msg);\n               }\n               lis_constraint(len, _) {\n+                if len == 0 && !zerok {\n+                    r.span_diagnostic.span_fatal(sp, \"this must repeat \\\n+                                                      at least once\");\n+                }\n                 vec::push(r.repeat_len, len);\n                 vec::push(r.repeat_idx, 0u);\n                 r.cur = @{readme: tts, mut idx: 0u, dotdotdoted: true,\n-                      up: tt_frame_up(option::some(r.cur)) };\n+                          sep: sep, up: tt_frame_up(option::some(r.cur)) };\n               }\n             }\n           }"}, {"sha": "ae3cbc141c238380d84d960abd61e672b7e53662", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 48, "deletions": 27, "changes": 75, "blob_url": "https://github.com/rust-lang/rust/blob/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=7f9b1fbe350ee16008f16f13254420da3679f60d", "patch": "@@ -1130,6 +1130,26 @@ class parser {\n         ret e;\n     }\n \n+    fn parse_sep_and_zerok() -> (option<token::token>, bool) {\n+        if self.token == token::BINOP(token::STAR)\n+            || self.token == token::BINOP(token::PLUS) {\n+            let zerok = self.token == token::BINOP(token::STAR);\n+            self.bump();\n+            ret (none, zerok);\n+        } else {\n+            let sep = self.token;\n+            self.bump();\n+            if self.token == token::BINOP(token::STAR)\n+                || self.token == token::BINOP(token::PLUS) {\n+                let zerok = self.token == token::BINOP(token::STAR);\n+                self.bump();\n+                ret (some(sep), zerok);\n+            } else {\n+                self.fatal(\"expected '*' or '+'\");\n+            }\n+        }\n+    }\n+\n     fn parse_token_tree() -> token_tree {\n         /// what's the opposite delimiter?\n         fn flip(&t: token::token) -> token::token {\n@@ -1142,12 +1162,6 @@ class parser {\n         }\n \n         fn parse_tt_flat(p: parser, delim_ok: bool) -> token_tree {\n-            if p.eat_keyword(\"many\") && p.quote_depth > 0u {\n-                let seq = p.parse_seq(token::LPAREN, token::RPAREN,\n-                                      seq_sep_none(),\n-                                      |p| p.parse_token_tree());\n-                ret tt_dotdotdot(seq.span, seq.node);\n-            }\n             alt p.token {\n               token::RPAREN | token::RBRACE | token::RBRACKET\n               if !delim_ok {\n@@ -1161,7 +1175,16 @@ class parser {\n               token::DOLLAR if p.quote_depth > 0u {\n                 p.bump();\n                 let sp = p.span;\n-                ret tt_interpolate(sp, p.parse_ident());\n+\n+                if p.token == token::LPAREN {\n+                    let seq = p.parse_seq(token::LPAREN, token::RPAREN,\n+                                          seq_sep_none(),\n+                                          |p| p.parse_token_tree());\n+                    let (s, z) = p.parse_sep_and_zerok();\n+                    ret tt_dotdotdot(mk_sp(sp.lo ,p.span.hi), seq.node, s, z);\n+                } else {\n+                    ret tt_interpolate(sp, p.parse_ident());\n+                }\n               }\n               _ { /* ok */ }\n             }\n@@ -1221,34 +1244,32 @@ class parser {\n \n     fn parse_matcher(name_idx: @mut uint) -> matcher {\n         let lo = self.span.lo;\n-        let mut sep = none;\n-        if self.eat_keyword(\"sep\") { sep = some(self.token); self.bump(); }\n \n-        let m = if self.is_keyword(\"many\")||self.is_keyword(\"at_least_one\") {\n-            let zero_ok = self.is_keyword(\"many\");\n+        let m = if self.token == token::DOLLAR {\n             self.bump();\n-            let ms = (self.parse_seq(token::LPAREN, token::RPAREN,\n-                                     common::seq_sep_none(),\n-                                     |p| p.parse_matcher(name_idx)).node);\n-            if ms.len() == 0u {\n-                self.fatal(\"repetition body must be nonempty\");\n+            if self.token == token::LPAREN {\n+                let ms = (self.parse_seq(token::LPAREN, token::RPAREN,\n+                                         common::seq_sep_none(),\n+                                         |p| p.parse_matcher(name_idx)).node);\n+                if ms.len() == 0u {\n+                    self.fatal(\"repetition body must be nonempty\");\n+                }\n+                let (sep, zerok) = self.parse_sep_and_zerok();\n+                mtc_rep(ms, sep, zerok)\n+            } else {\n+                let bound_to = self.parse_ident();\n+                self.expect(token::COLON);\n+                let nt_name = self.parse_ident();\n+                let m = mtc_bb(bound_to, nt_name, *name_idx);\n+                *name_idx += 1u;\n+                m\n             }\n-            mtc_rep(ms, sep, zero_ok)\n-        } else if option::is_some(sep) {\n-            self.fatal(\"`sep <tok>` must preceed `many` or `at_least_one`\");\n-        } else if self.eat_keyword(\"parse\") {\n-            let bound_to = self.parse_ident();\n-            self.expect(token::EQ);\n-            let nt_name = self.parse_ident();\n-\n-            let m = mtc_bb(bound_to, nt_name, *name_idx);\n-            *name_idx += 1u;\n-            m\n         } else {\n             let m = mtc_tok(self.token);\n             self.bump();\n             m\n         };\n+\n         ret spanned(lo, self.span.hi, m);\n     }\n "}, {"sha": "1fc8b10f38573cf43acaccf3b2480cdc5e6f45c0", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7f9b1fbe350ee16008f16f13254420da3679f60d/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=7f9b1fbe350ee16008f16f13254420da3679f60d", "patch": "@@ -274,9 +274,7 @@ fn contextual_keyword_table() -> hashmap<str, ()> {\n         \"self\", \"send\", \"static\",\n         \"to\",\n         \"use\",\n-        \"with\",\n-        /* temp */\n-        \"sep\", \"many\", \"at_least_one\", \"parse\"\n+        \"with\"\n     ];\n     for keys.each |word| {\n         words.insert(word, ());"}]}