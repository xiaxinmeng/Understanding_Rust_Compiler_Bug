{"sha": "fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZjYjc4ZDY1ZjJhM2I1NTNiOWFhY2E3NjI5MTBkYWYxMGZiYjFkY2U=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-27T12:33:30Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-28T04:55:37Z"}, "message": "Convert some token  functions into methods", "tree": {"sha": "1c3bfdaa6a50f90d377fdac1dac1bccd18550fd0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1c3bfdaa6a50f90d377fdac1dac1bccd18550fd0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "html_url": "https://github.com/rust-lang/rust/commit/fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d8b1fa0ae0c27e54d3539190683c01e194d36fbd", "url": "https://api.github.com/repos/rust-lang/rust/commits/d8b1fa0ae0c27e54d3539190683c01e194d36fbd", "html_url": "https://github.com/rust-lang/rust/commit/d8b1fa0ae0c27e54d3539190683c01e194d36fbd"}], "stats": {"total": 616, "additions": 305, "deletions": 311}, "files": [{"sha": "511d8aa5bace67bc0db2c35e342d0a7c84672451", "filename": "src/librustc/middle/save/span_utils.rs", "status": "modified", "additions": 10, "deletions": 10, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmiddle%2Fsave%2Fspan_utils.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -19,7 +19,7 @@ use syntax::codemap::*;\n use syntax::parse::lexer;\n use syntax::parse::lexer::{Reader,StringReader};\n use syntax::parse::token;\n-use syntax::parse::token::{is_keyword,keywords,is_ident,Token};\n+use syntax::parse::token::{keywords, Token};\n \n pub struct SpanUtils<'a> {\n     pub sess: &'a Session,\n@@ -97,7 +97,7 @@ impl<'a> SpanUtils<'a> {\n                 return self.make_sub_span(span, result)\n             }\n             if bracket_count == 0 &&\n-               (is_ident(&ts.tok) || is_keyword(keywords::Self, &ts.tok)) {\n+               (ts.tok.is_ident() || ts.tok.is_keyword(keywords::Self)) {\n                 result = Some(ts.sp);\n             }\n \n@@ -120,7 +120,7 @@ impl<'a> SpanUtils<'a> {\n                 return None;\n             }\n             if bracket_count == 0 &&\n-               (is_ident(&ts.tok) || is_keyword(keywords::Self, &ts.tok)) {\n+               (ts.tok.is_ident() || ts.tok.is_keyword(keywords::Self)) {\n                 return self.make_sub_span(span, Some(ts.sp));\n             }\n \n@@ -148,7 +148,7 @@ impl<'a> SpanUtils<'a> {\n             if (next.tok == token::LParen ||\n                 next.tok == token::Lt) &&\n                bracket_count == 0 &&\n-               is_ident(&prev.tok) {\n+               prev.tok.is_ident() {\n                 result = Some(prev.sp);\n             }\n \n@@ -158,7 +158,7 @@ impl<'a> SpanUtils<'a> {\n                 prev = next;\n                 next = toks.next_token();\n                 if next.tok == token::Lt &&\n-                   is_ident(&old.tok) {\n+                   old.tok.is_ident() {\n                     result = Some(old.sp);\n                 }\n             }\n@@ -170,7 +170,7 @@ impl<'a> SpanUtils<'a> {\n                 _ => 0\n             };\n \n-            if is_ident(&prev.tok) && bracket_count == 0 {\n+            if prev.tok.is_ident() && bracket_count == 0 {\n                 last_span = Some(prev.sp);\n             }\n             prev = next;\n@@ -194,7 +194,7 @@ impl<'a> SpanUtils<'a> {\n             if (next.tok == token::Lt ||\n                 next.tok == token::Colon) &&\n                bracket_count == 0 &&\n-               is_ident(&prev.tok) {\n+               prev.tok.is_ident() {\n                 result = Some(prev.sp);\n             }\n \n@@ -216,7 +216,7 @@ impl<'a> SpanUtils<'a> {\n                 format!(\"Mis-counted brackets when breaking path? Parsing '{}' in {}, line {}\",\n                         self.snippet(span), loc.file.name, loc.line).as_slice());\n         }\n-        if result.is_none() && is_ident(&prev.tok) && bracket_count == 0 {\n+        if result.is_none() && prev.tok.is_ident() && bracket_count == 0 {\n             return self.make_sub_span(span, Some(prev.sp));\n         }\n         self.make_sub_span(span, result)\n@@ -254,7 +254,7 @@ impl<'a> SpanUtils<'a> {\n                 token::BinOp(token::Shr) => -2,\n                 _ => 0\n             };\n-            if is_ident(&ts.tok) &&\n+            if ts.tok.is_ident() &&\n                bracket_count == nesting {\n                 result.push(self.make_sub_span(span, Some(ts.sp)).unwrap());\n             }\n@@ -285,7 +285,7 @@ impl<'a> SpanUtils<'a> {\n             if ts.tok == token::Eof {\n                 return None;\n             }\n-            if is_keyword(keyword, &ts.tok) {\n+            if ts.tok.is_keyword(keyword) {\n                 let ts = toks.next_token();\n                 if ts.tok == token::Eof {\n                     return None"}, {"sha": "0441e6b791f57aa018001ebf7e0082a6fecc6c34", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -101,7 +101,7 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n                 token::RParen | token::LBracket | token::LBrace | token::RBrace |\n                 token::Question => \"\",\n             token::Dollar => {\n-                if token::is_ident(&lexer.peek().tok) {\n+                if lexer.peek().tok.is_ident() {\n                     is_macro_nonterminal = true;\n                     \"macro-nonterminal\"\n                 } else {\n@@ -146,7 +146,7 @@ fn doit(sess: &parse::ParseSess, mut lexer: lexer::StringReader,\n                     \"Option\" | \"Result\" => \"prelude-ty\",\n                     \"Some\" | \"None\" | \"Ok\" | \"Err\" => \"prelude-val\",\n \n-                    _ if token::is_any_keyword(&next.tok) => \"kw\",\n+                    _ if next.tok.is_any_keyword() => \"kw\",\n                     _ => {\n                         if is_macro_nonterminal {\n                             is_macro_nonterminal = false;"}, {"sha": "a4f060cd9fc1e10d230590242a6141ba5deb3b4b", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -82,7 +82,7 @@ impl PartialEq for Ident {\n             //\n             // On the other hand, if the comparison does need to be hygienic,\n             // one example and its non-hygienic counterpart would be:\n-            //      syntax::parse::token::mtwt_token_eq\n+            //      syntax::parse::token::Token::mtwt_eq\n             //      syntax::ext::tt::macro_parser::token_name_eq\n             fail!(\"not allowed to compare these idents: {}, {}. \\\n                    Probably related to issue \\\\#6993\", self, other);"}, {"sha": "1b12ae67ee5cb11fdadaaca1d13d088ccf2eac79", "filename": "src/libsyntax/ext/format.rs", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fext%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fext%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fformat.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -116,8 +116,7 @@ fn parse_args(ecx: &mut ExtCtxt, sp: Span, allow_method: bool,\n             return (invocation, None);\n         }\n         if p.token == token::Eof { break } // accept trailing commas\n-        if named || (token::is_ident(&p.token) &&\n-                     p.look_ahead(1, |t| *t == token::Eq)) {\n+        if named || (p.token.is_ident() && p.look_ahead(1, |t| *t == token::Eq)) {\n             named = true;\n             let ident = match p.token {\n                 token::Ident(i, _) => {"}, {"sha": "76f7b7b0d7b3b18c95f0dbb37fbc479436060da9", "filename": "src/libsyntax/ext/trace_macros.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fext%2Ftrace_macros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftrace_macros.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -12,18 +12,18 @@ use ast;\n use codemap::Span;\n use ext::base::ExtCtxt;\n use ext::base;\n-use parse::token::{keywords, is_keyword};\n+use parse::token::keywords;\n \n \n pub fn expand_trace_macros(cx: &mut ExtCtxt,\n                            sp: Span,\n                            tt: &[ast::TokenTree])\n                            -> Box<base::MacResult+'static> {\n     match tt {\n-        [ast::TtToken(_, ref tok)] if is_keyword(keywords::True, tok) => {\n+        [ast::TtToken(_, ref tok)] if tok.is_keyword(keywords::True) => {\n             cx.set_trace_macros(true);\n         }\n-        [ast::TtToken(_, ref tok)] if is_keyword(keywords::False, tok) => {\n+        [ast::TtToken(_, ref tok)] if tok.is_keyword(keywords::False) => {\n             cx.set_trace_macros(false);\n         }\n         _ => cx.span_err(sp, \"trace_macros! accepts only `true` or `false`\"),"}, {"sha": "66b21aed5525db09e4ab6496e94dada0871852ac", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -367,7 +367,7 @@ pub fn gather_comments_and_literals(span_diagnostic: &diagnostic::SpanHandler,\n         rdr.next_token();\n         //discard, and look ahead; we're working with internal state\n         let TokenAndSpan { tok, sp } = rdr.peek();\n-        if token::is_lit(&tok) {\n+        if tok.is_lit() {\n             rdr.with_str_from(bstart, |s| {\n                 debug!(\"tok lit: {}\", s);\n                 literals.push(Literal {lit: s.to_string(), pos: sp.lo});"}, {"sha": "5c642f4096a21826e8c146545334fd4b4e29c295", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -1058,15 +1058,14 @@ impl<'a> StringReader<'a> {\n                 let keyword_checking_token =\n                     &token::Ident(keyword_checking_ident, false);\n                 let last_bpos = self.last_pos;\n-                if token::is_keyword(token::keywords::Self,\n-                                     keyword_checking_token) {\n+                if keyword_checking_token.is_keyword(token::keywords::Self) {\n                     self.err_span_(start,\n                                    last_bpos,\n                                    \"invalid lifetime name: 'self \\\n                                     is no longer a special lifetime\");\n-                } else if token::is_any_keyword(keyword_checking_token) &&\n-                    !token::is_keyword(token::keywords::Static,\n-                                       keyword_checking_token) {\n+                } else if keyword_checking_token.is_any_keyword() &&\n+                    !keyword_checking_token.is_keyword(token::keywords::Static)\n+                {\n                     self.err_span_(start,\n                                    last_bpos,\n                                    \"invalid lifetime name\");"}, {"sha": "bcea14491397f3dd088108894084cc0580203d02", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 81, "deletions": 109, "changes": 190, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -74,9 +74,8 @@ use parse::common::{seq_sep_trailing_allowed};\n use parse::lexer::Reader;\n use parse::lexer::TokenAndSpan;\n use parse::obsolete::*;\n-use parse::token::{InternedString, can_begin_expr};\n-use parse::token::{is_ident, is_ident_or_path, is_plain_ident};\n-use parse::token::{keywords, special_idents, token_to_binop};\n+use parse::token::InternedString;\n+use parse::token::{keywords, special_idents};\n use parse::token;\n use parse::{new_sub_parser_from_file, ParseSess};\n use ptr::P;\n@@ -335,7 +334,7 @@ pub struct Parser<'a> {\n }\n \n fn is_plain_ident_or_underscore(t: &token::Token) -> bool {\n-    is_plain_ident(t) || *t == token::Underscore\n+    t.is_plain_ident() || *t == token::Underscore\n }\n \n /// Get a token the parser cares about\n@@ -517,7 +516,7 @@ impl<'a> Parser<'a> {\n     pub fn commit_stmt(&mut self, edible: &[token::Token], inedible: &[token::Token]) {\n         if self.last_token\n                .as_ref()\n-               .map_or(false, |t| is_ident_or_path(&**t)) {\n+               .map_or(false, |t| t.is_ident() || t.is_path()) {\n             let mut expected = edible.iter().map(|x| x.clone()).collect::<Vec<_>>();\n             expected.push_all(inedible.as_slice());\n             self.check_for_erroneous_unit_struct_expecting(\n@@ -569,14 +568,10 @@ impl<'a> Parser<'a> {\n         is_present\n     }\n \n-    pub fn is_keyword(&mut self, kw: keywords::Keyword) -> bool {\n-        token::is_keyword(kw, &self.token)\n-    }\n-\n     /// If the next token is the given keyword, eat it and return\n     /// true. Otherwise, return false.\n     pub fn eat_keyword(&mut self, kw: keywords::Keyword) -> bool {\n-        if self.is_keyword(kw) {\n+        if self.token.is_keyword(kw) {\n             self.bump();\n             true\n         } else {\n@@ -598,7 +593,7 @@ impl<'a> Parser<'a> {\n \n     /// Signal an error if the given string is a strict keyword\n     pub fn check_strict_keywords(&mut self) {\n-        if token::is_strict_keyword(&self.token) {\n+        if self.token.is_strict_keyword() {\n             let token_str = self.this_token_to_string();\n             let span = self.span;\n             self.span_err(span,\n@@ -609,7 +604,7 @@ impl<'a> Parser<'a> {\n \n     /// Signal an error if the current token is a reserved keyword\n     pub fn check_reserved_keywords(&mut self) {\n-        if token::is_reserved_keyword(&self.token) {\n+        if self.token.is_reserved_keyword() {\n             let token_str = self.this_token_to_string();\n             self.fatal(format!(\"`{}` is a reserved keyword\",\n                                token_str).as_slice())\n@@ -896,7 +891,7 @@ impl<'a> Parser<'a> {\n     pub fn bump(&mut self) {\n         self.last_span = self.span;\n         // Stash token for error recovery (sometimes; clone is not necessarily cheap).\n-        self.last_token = if is_ident_or_path(&self.token) {\n+        self.last_token = if self.token.is_ident() || self.token.is_path() {\n             Some(box self.token.clone())\n         } else {\n             None\n@@ -986,37 +981,30 @@ impl<'a> Parser<'a> {\n     /// Is the current token one of the keywords that signals a bare function\n     /// type?\n     pub fn token_is_bare_fn_keyword(&mut self) -> bool {\n-        if token::is_keyword(keywords::Fn, &self.token) {\n+        if self.token.is_keyword(keywords::Fn) {\n             return true\n         }\n \n-        if token::is_keyword(keywords::Unsafe, &self.token) ||\n-            token::is_keyword(keywords::Once, &self.token) {\n-            return self.look_ahead(1, |t| token::is_keyword(keywords::Fn, t))\n+        if self.token.is_keyword(keywords::Unsafe) ||\n+            self.token.is_keyword(keywords::Once) {\n+            return self.look_ahead(1, |t| t.is_keyword(keywords::Fn))\n         }\n \n         false\n     }\n \n     /// Is the current token one of the keywords that signals a closure type?\n     pub fn token_is_closure_keyword(&mut self) -> bool {\n-        token::is_keyword(keywords::Unsafe, &self.token) ||\n-            token::is_keyword(keywords::Once, &self.token)\n+        self.token.is_keyword(keywords::Unsafe) ||\n+            self.token.is_keyword(keywords::Once)\n     }\n \n     /// Is the current token one of the keywords that signals an old-style\n     /// closure type (with explicit sigil)?\n     pub fn token_is_old_style_closure_keyword(&mut self) -> bool {\n-        token::is_keyword(keywords::Unsafe, &self.token) ||\n-            token::is_keyword(keywords::Once, &self.token) ||\n-            token::is_keyword(keywords::Fn, &self.token)\n-    }\n-\n-    pub fn token_is_lifetime(tok: &token::Token) -> bool {\n-        match *tok {\n-            token::Lifetime(..) => true,\n-            _ => false,\n-        }\n+        self.token.is_keyword(keywords::Unsafe) ||\n+            self.token.is_keyword(keywords::Once) ||\n+            self.token.is_keyword(keywords::Fn)\n     }\n \n     pub fn get_lifetime(&mut self) -> ast::Ident {\n@@ -1103,10 +1091,8 @@ impl<'a> Parser<'a> {\n     pub fn parse_optional_unboxed_closure_kind(&mut self)\n                                                -> Option<UnboxedClosureKind> {\n         if self.token == token::BinOp(token::And) &&\n-                    self.look_ahead(1, |t| {\n-                        token::is_keyword(keywords::Mut, t)\n-                    }) &&\n-                    self.look_ahead(2, |t| *t == token::Colon) {\n+                self.look_ahead(1, |t| t.is_keyword(keywords::Mut)) &&\n+                self.look_ahead(2, |t| *t == token::Colon) {\n             self.bump();\n             self.bump();\n             self.bump();\n@@ -1485,8 +1471,8 @@ impl<'a> Parser<'a> {\n             // BORROWED POINTER\n             self.expect_and();\n             self.parse_borrowed_pointee()\n-        } else if self.is_keyword(keywords::Extern) ||\n-                  self.is_keyword(keywords::Unsafe) ||\n+        } else if self.token.is_keyword(keywords::Extern) ||\n+                  self.token.is_keyword(keywords::Unsafe) ||\n                 self.token_is_bare_fn_keyword() {\n             // BARE FUNCTION\n             self.parse_ty_bare_fn()\n@@ -1495,7 +1481,7 @@ impl<'a> Parser<'a> {\n                 self.token == token::OrOr ||\n                 (self.token == token::Lt &&\n                  self.look_ahead(1, |t| {\n-                     *t == token::Gt || Parser::token_is_lifetime(t)\n+                     *t == token::Gt || t.is_lifetime()\n                  })) {\n             // CLOSURE\n \n@@ -1524,7 +1510,8 @@ impl<'a> Parser<'a> {\n                 item_name: item_name,\n             }))\n         } else if self.token == token::ModSep\n-            || is_ident_or_path(&self.token) {\n+            || self.token.is_ident()\n+            || self.token.is_path() {\n             // NAMED TYPE\n             let mode = if plus_allowed {\n                 LifetimeAndTypesAndBounds\n@@ -1577,7 +1564,7 @@ impl<'a> Parser<'a> {\n         let offset = match self.token {\n             token::BinOp(token::And) => 1,\n             token::AndAnd => 1,\n-            _ if token::is_keyword(keywords::Mut, &self.token) => 1,\n+            _ if self.token.is_keyword(keywords::Mut) => 1,\n             _ => 0\n         };\n \n@@ -1925,11 +1912,6 @@ impl<'a> Parser<'a> {\n         }\n     }\n \n-    pub fn token_is_mutability(tok: &token::Token) -> bool {\n-        token::is_keyword(keywords::Mut, tok) ||\n-        token::is_keyword(keywords::Const, tok)\n-    }\n-\n     /// Parse mutability declaration (mut/const/imm)\n     pub fn parse_mutability(&mut self) -> Mutability {\n         if self.eat_keyword(keywords::Mut) {\n@@ -2157,7 +2139,7 @@ impl<'a> Parser<'a> {\n                 if self.eat_keyword(keywords::While) {\n                     return self.parse_while_expr(None);\n                 }\n-                if Parser::token_is_lifetime(&self.token) {\n+                if self.token.is_lifetime() {\n                     let lifetime = self.get_lifetime();\n                     self.bump();\n                     self.expect(&token::Colon);\n@@ -2177,7 +2159,7 @@ impl<'a> Parser<'a> {\n                 }\n                 if self.eat_keyword(keywords::Continue) {\n                     let lo = self.span.lo;\n-                    let ex = if Parser::token_is_lifetime(&self.token) {\n+                    let ex = if self.token.is_lifetime() {\n                         let lifetime = self.get_lifetime();\n                         self.bump();\n                         ExprAgain(Some(lifetime))\n@@ -2197,7 +2179,7 @@ impl<'a> Parser<'a> {\n                 }\n                 if self.eat_keyword(keywords::Return) {\n                     // RETURN expression\n-                    if can_begin_expr(&self.token) {\n+                    if self.token.can_begin_expr() {\n                         let e = self.parse_expr();\n                         hi = e.span.hi;\n                         ex = ExprRet(Some(e));\n@@ -2206,7 +2188,7 @@ impl<'a> Parser<'a> {\n                     }\n                 } else if self.eat_keyword(keywords::Break) {\n                     // BREAK expression\n-                    if Parser::token_is_lifetime(&self.token) {\n+                    if self.token.is_lifetime() {\n                         let lifetime = self.get_lifetime();\n                         self.bump();\n                         ex = ExprBreak(Some(lifetime));\n@@ -2215,9 +2197,9 @@ impl<'a> Parser<'a> {\n                     }\n                     hi = self.span.hi;\n                 } else if self.token == token::ModSep ||\n-                        is_ident(&self.token) &&\n-                        !self.is_keyword(keywords::True) &&\n-                        !self.is_keyword(keywords::False) {\n+                        self.token.is_ident() &&\n+                        !self.token.is_keyword(keywords::True) &&\n+                        !self.token.is_keyword(keywords::False) {\n                     let pth =\n                         self.parse_path(LifetimeAndTypesWithColons).path;\n \n@@ -2226,7 +2208,7 @@ impl<'a> Parser<'a> {\n                         // MACRO INVOCATION expression\n                         self.bump();\n \n-                        let ket = token::close_delimiter_for(&self.token)\n+                        let ket = self.token.get_close_delimiter()\n                             .unwrap_or_else(|| {\n                                 self.fatal(\"expected open delimiter\")\n                             });\n@@ -2581,7 +2563,7 @@ impl<'a> Parser<'a> {\n             }\n         }\n \n-        match (&self.token, token::close_delimiter_for(&self.token)) {\n+        match (&self.token, self.token.get_close_delimiter()) {\n             (&token::Eof, _) => {\n                 let open_braces = self.open_braces.clone();\n                 for sp in open_braces.iter() {\n@@ -2638,7 +2620,7 @@ impl<'a> Parser<'a> {\n         // the interpolation of Matcher's\n         maybe_whole!(self, NtMatchers);\n         let mut name_idx = 0u;\n-        match token::close_delimiter_for(&self.token) {\n+        match self.token.get_close_delimiter() {\n             Some(other_delimiter) => {\n                 self.bump();\n                 self.parse_matcher_subseq_upto(&mut name_idx, &other_delimiter)\n@@ -2743,7 +2725,7 @@ impl<'a> Parser<'a> {\n             ex = self.mk_unary(UnUniq, e);\n           }\n           token::Ident(_, _) => {\n-            if !self.is_keyword(keywords::Box) {\n+            if !self.token.is_keyword(keywords::Box) {\n                 return self.parse_dot_or_call_expr();\n             }\n \n@@ -2789,7 +2771,7 @@ impl<'a> Parser<'a> {\n             return lhs;\n         }\n \n-        let cur_opt = token_to_binop(&self.token);\n+        let cur_opt = self.token.to_binop();\n         match cur_opt {\n             Some(cur_op) => {\n                 let cur_prec = operator_prec(cur_op);\n@@ -2860,7 +2842,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse an 'if' or 'if let' expression ('if' token already eaten)\n     pub fn parse_if_expr(&mut self) -> P<Expr> {\n-        if self.is_keyword(keywords::Let) {\n+        if self.token.is_keyword(keywords::Let) {\n             return self.parse_if_let_expr();\n         }\n         let lo = self.last_span.lo;\n@@ -2951,7 +2933,7 @@ impl<'a> Parser<'a> {\n \n     /// Parse a 'while' or 'while let' expression ('while' token already eaten)\n     pub fn parse_while_expr(&mut self, opt_ident: Option<ast::Ident>) -> P<Expr> {\n-        if self.is_keyword(keywords::Let) {\n+        if self.token.is_keyword(keywords::Let) {\n             return self.parse_while_let_expr(opt_ident);\n         }\n         let lo = self.last_span.lo;\n@@ -3272,9 +3254,10 @@ impl<'a> Parser<'a> {\n         }\n         // at this point, token != _, ~, &, &&, (, [\n \n-        if (!is_ident_or_path(&self.token) && self.token != token::ModSep)\n-                || self.is_keyword(keywords::True)\n-                || self.is_keyword(keywords::False) {\n+        if (!(self.token.is_ident() || self.token.is_path())\n+              && self.token != token::ModSep)\n+                || self.token.is_keyword(keywords::True)\n+                || self.token.is_keyword(keywords::False) {\n             // Parse an expression pattern or exp .. exp.\n             //\n             // These expressions are limited to literals (possibly\n@@ -3285,7 +3268,7 @@ impl<'a> Parser<'a> {\n                         *t != token::Comma && *t != token::RBracket\n                     }) {\n                 self.bump();\n-                let end = if is_ident_or_path(&self.token) {\n+                let end = if self.token.is_ident() || self.token.is_path() {\n                     let path = self.parse_path(LifetimeAndTypesWithColons)\n                                    .path;\n                     let hi = self.span.hi;\n@@ -3333,13 +3316,13 @@ impl<'a> Parser<'a> {\n                 self.eat(&token::DotDotDot);\n                 let end = self.parse_expr_res(RESTRICTION_NO_BAR_OP);\n                 pat = PatRange(start, end);\n-            } else if is_plain_ident(&self.token) && !can_be_enum_or_struct {\n+            } else if self.token.is_plain_ident() && !can_be_enum_or_struct {\n                 let id = self.parse_ident();\n                 let id_span = self.last_span;\n                 let pth1 = codemap::Spanned{span:id_span, node: id};\n                 if self.eat(&token::Not) {\n                     // macro invocation\n-                    let ket = token::close_delimiter_for(&self.token)\n+                    let ket = self.token.get_close_delimiter()\n                                     .unwrap_or_else(|| self.fatal(\"expected open delimiter\"));\n                     self.bump();\n \n@@ -3438,7 +3421,7 @@ impl<'a> Parser<'a> {\n     fn parse_pat_ident(&mut self,\n                        binding_mode: ast::BindingMode)\n                        -> ast::Pat_ {\n-        if !is_plain_ident(&self.token) {\n+        if !self.token.is_plain_ident() {\n             let span = self.span;\n             let tok_str = self.this_token_to_string();\n             self.span_fatal(span,\n@@ -3504,7 +3487,7 @@ impl<'a> Parser<'a> {\n     fn parse_name_and_ty(&mut self, pr: Visibility,\n                          attrs: Vec<Attribute> ) -> StructField {\n         let lo = self.span.lo;\n-        if !is_plain_ident(&self.token) {\n+        if !self.token.is_plain_ident() {\n             self.fatal(\"expected ident\");\n         }\n         let name = self.parse_ident();\n@@ -3542,13 +3525,13 @@ impl<'a> Parser<'a> {\n         }\n \n         let lo = self.span.lo;\n-        if self.is_keyword(keywords::Let) {\n+        if self.token.is_keyword(keywords::Let) {\n             check_expected_item(self, item_attrs.as_slice());\n             self.expect_keyword(keywords::Let);\n             let decl = self.parse_let();\n             P(spanned(lo, decl.span.hi, StmtDecl(decl, ast::DUMMY_NODE_ID)))\n-        } else if is_ident(&self.token)\n-            && !token::is_any_keyword(&self.token)\n+        } else if self.token.is_ident()\n+            && !self.token.is_any_keyword()\n             && self.look_ahead(1, |t| *t == token::Not) {\n             // it's a macro invocation:\n \n@@ -3559,7 +3542,7 @@ impl<'a> Parser<'a> {\n             let pth = self.parse_path(NoTypesAllowed).path;\n             self.bump();\n \n-            let id = if token::close_delimiter_for(&self.token).is_some() {\n+            let id = if self.token.get_close_delimiter().is_some() {\n                 token::special_idents::invalid // no special identifier\n             } else {\n                 self.parse_ident()\n@@ -3568,7 +3551,7 @@ impl<'a> Parser<'a> {\n             // check that we're pointing at delimiters (need to check\n             // again after the `if`, because of `parse_ident`\n             // consuming more tokens).\n-            let (bra, ket) = match token::close_delimiter_for(&self.token) {\n+            let (bra, ket) = match self.token.get_close_delimiter() {\n                 Some(ket) => (self.token.clone(), ket),\n                 None      => {\n                     // we only expect an ident if we didn't parse one\n@@ -3993,7 +3976,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn forbid_lifetime(&mut self) {\n-        if Parser::token_is_lifetime(&self.token) {\n+        if self.token.is_lifetime() {\n             let span = self.span;\n             self.span_fatal(span, \"lifetime parameters must be declared \\\n                                         prior to type parameters\");\n@@ -4145,29 +4128,22 @@ impl<'a> Parser<'a> {\n             //\n             // We already know that the current token is `&`.\n \n-            if this.look_ahead(1, |t| token::is_keyword(keywords::Self, t)) {\n+            if this.look_ahead(1, |t| t.is_keyword(keywords::Self)) {\n                 this.bump();\n                 SelfRegion(None, MutImmutable, this.expect_self_ident())\n-            } else if this.look_ahead(1, |t| Parser::token_is_mutability(t)) &&\n-                    this.look_ahead(2,\n-                                    |t| token::is_keyword(keywords::Self,\n-                                                          t)) {\n+            } else if this.look_ahead(1, |t| t.is_mutability()) &&\n+                      this.look_ahead(2, |t| t.is_keyword(keywords::Self)) {\n                 this.bump();\n                 let mutability = this.parse_mutability();\n                 SelfRegion(None, mutability, this.expect_self_ident())\n-            } else if this.look_ahead(1, |t| Parser::token_is_lifetime(t)) &&\n-                       this.look_ahead(2,\n-                                       |t| token::is_keyword(keywords::Self,\n-                                                             t)) {\n+            } else if this.look_ahead(1, |t| t.is_lifetime()) &&\n+                      this.look_ahead(2, |t| t.is_keyword(keywords::Self)) {\n                 this.bump();\n                 let lifetime = this.parse_lifetime();\n                 SelfRegion(Some(lifetime), MutImmutable, this.expect_self_ident())\n-            } else if this.look_ahead(1, |t| Parser::token_is_lifetime(t)) &&\n-                      this.look_ahead(2, |t| {\n-                          Parser::token_is_mutability(t)\n-                      }) &&\n-                      this.look_ahead(3, |t| token::is_keyword(keywords::Self,\n-                                                               t)) {\n+            } else if this.look_ahead(1, |t| t.is_lifetime()) &&\n+                      this.look_ahead(2, |t| t.is_mutability()) &&\n+                      this.look_ahead(3, |t| t.is_keyword(keywords::Self)) {\n                 this.bump();\n                 let lifetime = this.parse_lifetime();\n                 let mutability = this.parse_mutability();\n@@ -4195,7 +4171,7 @@ impl<'a> Parser<'a> {\n             }\n             token::Tilde => {\n                 // We need to make sure it isn't a type\n-                if self.look_ahead(1, |t| token::is_keyword(keywords::Self, t)) {\n+                if self.look_ahead(1, |t| t.is_keyword(keywords::Self)) {\n                     self.bump();\n                     drop(self.expect_self_ident());\n                     let last_span = self.last_span;\n@@ -4207,7 +4183,7 @@ impl<'a> Parser<'a> {\n                 // Possibly \"*self\" or \"*mut self\" -- not supported. Try to avoid\n                 // emitting cryptic \"unexpected token\" errors.\n                 self.bump();\n-                let _mutability = if Parser::token_is_mutability(&self.token) {\n+                let _mutability = if self.token.is_mutability() {\n                     self.parse_mutability()\n                 } else {\n                     MutImmutable\n@@ -4231,10 +4207,8 @@ impl<'a> Parser<'a> {\n                     } else {\n                         SelfValue(self_ident)\n                     }\n-                } else if Parser::token_is_mutability(&self.token) &&\n-                        self.look_ahead(1, |t| {\n-                            token::is_keyword(keywords::Self, t)\n-                        }) {\n+                } else if self.token.is_mutability() &&\n+                        self.look_ahead(1, |t| t.is_keyword(keywords::Self)) {\n                     mutbl_self = self.parse_mutability();\n                     let self_ident = self.expect_self_ident();\n \n@@ -4245,11 +4219,9 @@ impl<'a> Parser<'a> {\n                     } else {\n                         SelfValue(self_ident)\n                     }\n-                } else if Parser::token_is_mutability(&self.token) &&\n+                } else if self.token.is_mutability() &&\n                         self.look_ahead(1, |t| *t == token::Tilde) &&\n-                        self.look_ahead(2, |t| {\n-                            token::is_keyword(keywords::Self, t)\n-                        }) {\n+                        self.look_ahead(2, |t| t.is_keyword(keywords::Self)) {\n                     mutbl_self = self.parse_mutability();\n                     self.bump();\n                     drop(self.expect_self_ident());\n@@ -4430,7 +4402,7 @@ impl<'a> Parser<'a> {\n \n         // code copied from parse_macro_use_or_failure... abstraction!\n         let (method_, hi, new_attrs) = {\n-            if !token::is_any_keyword(&self.token)\n+            if !self.token.is_any_keyword()\n                 && self.look_ahead(1, |t| *t == token::Not)\n                 && (self.look_ahead(2, |t| *t == token::LParen)\n                     || self.look_ahead(2, |t| *t == token::LBrace)) {\n@@ -4439,7 +4411,7 @@ impl<'a> Parser<'a> {\n                 self.expect(&token::Not);\n \n                 // eat a matched-delimiter token tree:\n-                let tts = match token::close_delimiter_for(&self.token) {\n+                let tts = match self.token.get_close_delimiter() {\n                     Some(ket) => {\n                         self.bump();\n                         self.parse_seq_to_end(&ket,\n@@ -5037,7 +5009,7 @@ impl<'a> Parser<'a> {\n                     Some(path)\n                 } else if self.eat_keyword(keywords::As) {\n                     // skip the ident if there is one\n-                    if is_ident(&self.token) { self.bump(); }\n+                    if self.token.is_ident() { self.bump(); }\n \n                     self.span_err(span,\n                                   format!(\"expected `;`, found `as`; perhaps you meant \\\n@@ -5335,7 +5307,7 @@ impl<'a> Parser<'a> {\n         }\n \n         // the rest are all guaranteed to be items:\n-        if self.is_keyword(keywords::Static) {\n+        if self.token.is_keyword(keywords::Static) {\n             // STATIC ITEM\n             self.bump();\n             let m = if self.eat_keyword(keywords::Mut) {MutMutable} else {MutImmutable};\n@@ -5349,7 +5321,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return IoviItem(item);\n         }\n-        if self.is_keyword(keywords::Const) {\n+        if self.token.is_keyword(keywords::Const) {\n             // CONST ITEM\n             self.bump();\n             if self.eat_keyword(keywords::Mut) {\n@@ -5367,7 +5339,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return IoviItem(item);\n         }\n-        if self.is_keyword(keywords::Fn) &&\n+        if self.token.is_keyword(keywords::Fn) &&\n                 self.look_ahead(1, |f| !Parser::fn_expr_lookahead(f)) {\n             // FUNCTION ITEM\n             self.bump();\n@@ -5382,7 +5354,7 @@ impl<'a> Parser<'a> {\n                                     maybe_append(attrs, extra_attrs));\n             return IoviItem(item);\n         }\n-        if self.is_keyword(keywords::Unsafe)\n+        if self.token.is_keyword(keywords::Unsafe)\n             && self.look_ahead(1u, |t| *t != token::LBrace) {\n             // UNSAFE FUNCTION ITEM\n             self.bump();\n@@ -5489,12 +5461,12 @@ impl<'a> Parser<'a> {\n \n         let visibility = self.parse_visibility();\n \n-        if self.is_keyword(keywords::Static) {\n+        if self.token.is_keyword(keywords::Static) {\n             // FOREIGN STATIC ITEM\n             let item = self.parse_item_foreign_static(visibility, attrs);\n             return IoviForeignItem(item);\n         }\n-        if self.is_keyword(keywords::Fn) || self.is_keyword(keywords::Unsafe) {\n+        if self.token.is_keyword(keywords::Fn) || self.token.is_keyword(keywords::Unsafe) {\n             // FOREIGN FUNCTION ITEM\n             let item = self.parse_item_foreign_fn(visibility, attrs);\n             return IoviForeignItem(item);\n@@ -5510,9 +5482,9 @@ impl<'a> Parser<'a> {\n         lo: BytePos,\n         visibility: Visibility\n     ) -> ItemOrViewItem {\n-        if macros_allowed && !token::is_any_keyword(&self.token)\n+        if macros_allowed && !self.token.is_any_keyword()\n                 && self.look_ahead(1, |t| *t == token::Not)\n-                && (self.look_ahead(2, |t| is_plain_ident(t))\n+                && (self.look_ahead(2, |t| t.is_plain_ident())\n                     || self.look_ahead(2, |t| *t == token::LParen)\n                     || self.look_ahead(2, |t| *t == token::LBrace)) {\n             // MACRO INVOCATION ITEM\n@@ -5524,13 +5496,13 @@ impl<'a> Parser<'a> {\n             // a 'special' identifier (like what `macro_rules!` uses)\n             // is optional. We should eventually unify invoc syntax\n             // and remove this.\n-            let id = if is_plain_ident(&self.token) {\n+            let id = if self.token.is_plain_ident() {\n                 self.parse_ident()\n             } else {\n                 token::special_idents::invalid // no special identifier\n             };\n             // eat a matched-delimiter token tree:\n-            let tts = match token::close_delimiter_for(&self.token) {\n+            let tts = match self.token.get_close_delimiter() {\n                 Some(ket) => {\n                     self.bump();\n                     self.parse_seq_to_end(&ket,"}, {"sha": "6ffe766684dba96bc11ff4c77d8d609ecfa2c8bd", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 202, "deletions": 178, "changes": 380, "blob_url": "https://github.com/rust-lang/rust/blob/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fcb78d65f2a3b553b9aaca762910daf10fbb1dce/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=fcb78d65f2a3b553b9aaca762910daf10fbb1dce", "patch": "@@ -173,6 +173,206 @@ pub enum Token {\n     Eof,\n }\n \n+impl Token {\n+    /// Returns `true` if the token can appear at the start of an expression.\n+    pub fn can_begin_expr(&self) -> bool {\n+        match *self {\n+            LParen                      => true,\n+            LBrace                      => true,\n+            LBracket                    => true,\n+            Ident(_, _)                 => true,\n+            Underscore                  => true,\n+            Tilde                       => true,\n+            LitByte(_)                  => true,\n+            LitChar(_)                  => true,\n+            LitInteger(_)               => true,\n+            LitFloat(_)                 => true,\n+            LitStr(_)                   => true,\n+            LitStrRaw(_, _)             => true,\n+            LitBinary(_)                => true,\n+            LitBinaryRaw(_, _)          => true,\n+            Pound                       => true,\n+            At                          => true,\n+            Not                         => true,\n+            BinOp(Minus)                => true,\n+            BinOp(Star)                 => true,\n+            BinOp(And)                  => true,\n+            BinOp(Or)                   => true, // in lambda syntax\n+            OrOr                        => true, // in lambda syntax\n+            ModSep                      => true,\n+            Interpolated(NtExpr(..))    => true,\n+            Interpolated(NtIdent(..))   => true,\n+            Interpolated(NtBlock(..))   => true,\n+            Interpolated(NtPath(..))    => true,\n+            _                           => false,\n+        }\n+    }\n+\n+    /// Returns the matching close delimiter if this is an open delimiter,\n+    /// otherwise `None`.\n+    pub fn get_close_delimiter(&self) -> Option<Token> {\n+        match *self {\n+            LParen   => Some(RParen),\n+            LBrace   => Some(RBrace),\n+            LBracket => Some(RBracket),\n+            _        => None,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is any literal\n+    pub fn is_lit(&self) -> bool {\n+        match *self {\n+            LitByte(_)          => true,\n+            LitChar(_)          => true,\n+            LitInteger(_)       => true,\n+            LitFloat(_)         => true,\n+            LitStr(_)           => true,\n+            LitStrRaw(_, _)     => true,\n+            LitBinary(_)        => true,\n+            LitBinaryRaw(_, _)  => true,\n+            _                   => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is an identifier.\n+    pub fn is_ident(&self) -> bool {\n+        match *self {\n+            Ident(_, _) => true,\n+            _           => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is an interpolated path.\n+    pub fn is_path(&self) -> bool {\n+        match *self {\n+            Interpolated(NtPath(..))    => true,\n+            _                           => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is a path that is not followed by a `::`\n+    /// token.\n+    pub fn is_plain_ident(&self) -> bool {\n+        match *self {\n+            Ident(_, false) => true,\n+            _               => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is a lifetime.\n+    pub fn is_lifetime(&self) -> bool {\n+        match *self {\n+            Lifetime(..) => true,\n+            _            => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is either the `mut` or `const` keyword.\n+    pub fn is_mutability(&self) -> bool {\n+        self.is_keyword(keywords::Mut) ||\n+        self.is_keyword(keywords::Const)\n+    }\n+\n+    /// Maps a token to its corresponding binary operator.\n+    pub fn to_binop(&self) -> Option<ast::BinOp> {\n+        match *self {\n+            BinOp(Star)     => Some(ast::BiMul),\n+            BinOp(Slash)    => Some(ast::BiDiv),\n+            BinOp(Percent)  => Some(ast::BiRem),\n+            BinOp(Plus)     => Some(ast::BiAdd),\n+            BinOp(Minus)    => Some(ast::BiSub),\n+            BinOp(Shl)      => Some(ast::BiShl),\n+            BinOp(Shr)      => Some(ast::BiShr),\n+            BinOp(And)      => Some(ast::BiBitAnd),\n+            BinOp(Caret)    => Some(ast::BiBitXor),\n+            BinOp(Or)       => Some(ast::BiBitOr),\n+            Lt              => Some(ast::BiLt),\n+            Le              => Some(ast::BiLe),\n+            Ge              => Some(ast::BiGe),\n+            Gt              => Some(ast::BiGt),\n+            EqEq            => Some(ast::BiEq),\n+            Ne              => Some(ast::BiNe),\n+            AndAnd          => Some(ast::BiAnd),\n+            OrOr            => Some(ast::BiOr),\n+            _               => None,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is a given keyword, `kw`.\n+    pub fn is_keyword(&self, kw: keywords::Keyword) -> bool {\n+        match *self {\n+            Ident(sid, false)   => kw.to_name() == sid.name,\n+            _                   => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is either a special identifier, or a strict\n+    /// or reserved keyword.\n+    pub fn is_any_keyword(&self) -> bool {\n+        match *self {\n+            Ident(sid, false) => {\n+                let n = sid.name;\n+\n+                   n == SELF_KEYWORD_NAME\n+                || n == STATIC_KEYWORD_NAME\n+                || n == SUPER_KEYWORD_NAME\n+                || STRICT_KEYWORD_START <= n\n+                && n <= RESERVED_KEYWORD_FINAL\n+            },\n+            _ => false\n+        }\n+    }\n+\n+    /// Returns `true` if the token may not appear as an identifier.\n+    pub fn is_strict_keyword(&self) -> bool {\n+        match *self {\n+            Ident(sid, false) => {\n+                let n = sid.name;\n+\n+                   n == SELF_KEYWORD_NAME\n+                || n == STATIC_KEYWORD_NAME\n+                || n == SUPER_KEYWORD_NAME\n+                || STRICT_KEYWORD_START <= n\n+                && n <= STRICT_KEYWORD_FINAL\n+            },\n+            Ident(sid, true) => {\n+                let n = sid.name;\n+\n+                   n != SELF_KEYWORD_NAME\n+                && n != SUPER_KEYWORD_NAME\n+                && STRICT_KEYWORD_START <= n\n+                && n <= STRICT_KEYWORD_FINAL\n+            }\n+            _ => false,\n+        }\n+    }\n+\n+    /// Returns `true` if the token is a keyword that has been reserved for\n+    /// possible future use.\n+    pub fn is_reserved_keyword(&self) -> bool {\n+        match *self {\n+            Ident(sid, false) => {\n+                let n = sid.name;\n+\n+                   RESERVED_KEYWORD_START <= n\n+                && n <= RESERVED_KEYWORD_FINAL\n+            },\n+            _ => false,\n+        }\n+    }\n+\n+    /// Hygienic identifier equality comparison.\n+    ///\n+    /// See `styntax::ext::mtwt`.\n+    pub fn mtwt_eq(&self, other : &Token) -> bool {\n+        match (self, other) {\n+            (&Ident(id1,_), &Ident(id2,_)) | (&Lifetime(id1), &Lifetime(id2)) =>\n+                mtwt::resolve(id1) == mtwt::resolve(id2),\n+            _ => *self == *other\n+        }\n+    }\n+}\n+\n #[deriving(Clone, Encodable, Decodable, PartialEq, Eq, Hash)]\n /// For interpolation during macro expansion.\n pub enum Nonterminal {\n@@ -304,86 +504,6 @@ pub fn to_string(t: &Token) -> String {\n     }\n }\n \n-pub fn can_begin_expr(t: &Token) -> bool {\n-    match *t {\n-        LParen              => true,\n-        LBrace              => true,\n-        LBracket            => true,\n-        Ident(_, _)         => true,\n-        Underscore          => true,\n-        Tilde               => true,\n-        LitByte(_)          => true,\n-        LitChar(_)          => true,\n-        LitInteger(_)       => true,\n-        LitFloat(_)         => true,\n-        LitStr(_)           => true,\n-        LitStrRaw(_, _)     => true,\n-        LitBinary(_)        => true,\n-        LitBinaryRaw(_, _)  => true,\n-        Pound               => true,\n-        At                  => true,\n-        Not                 => true,\n-        BinOp(Minus)        => true,\n-        BinOp(Star)         => true,\n-        BinOp(And)          => true,\n-        BinOp(Or)           => true, // in lambda syntax\n-        OrOr                => true, // in lambda syntax\n-        ModSep              => true,\n-        Interpolated(NtExpr(..))    => true,\n-        Interpolated(NtIdent(..))   => true,\n-        Interpolated(NtBlock(..))   => true,\n-        Interpolated(NtPath(..))    => true,\n-        _                   => false,\n-    }\n-}\n-\n-/// Returns the matching close delimiter if this is an open delimiter,\n-/// otherwise `None`.\n-pub fn close_delimiter_for(t: &Token) -> Option<Token> {\n-    match *t {\n-        LParen   => Some(RParen),\n-        LBrace   => Some(RBrace),\n-        LBracket => Some(RBracket),\n-        _        => None,\n-    }\n-}\n-\n-pub fn is_lit(t: &Token) -> bool {\n-    match *t {\n-        LitByte(_)          => true,\n-        LitChar(_)          => true,\n-        LitInteger(_)       => true,\n-        LitFloat(_)         => true,\n-        LitStr(_)           => true,\n-        LitStrRaw(_, _)     => true,\n-        LitBinary(_)        => true,\n-        LitBinaryRaw(_, _)  => true,\n-        _ => false,\n-    }\n-}\n-\n-pub fn is_ident(t: &Token) -> bool {\n-    match *t {\n-        Ident(_, _) => true,\n-        _           => false,\n-    }\n-}\n-\n-pub fn is_ident_or_path(t: &Token) -> bool {\n-    match *t {\n-        Ident(_, _)                 => true,\n-        Interpolated(NtPath(..))    => true,\n-        _                           => false,\n-    }\n-}\n-\n-pub fn is_plain_ident(t: &Token) -> bool {\n-    match *t {\n-        Ident(_, false) => true,\n-        _               => false,\n-    }\n-}\n-\n // Get the first \"argument\"\n macro_rules! first {\n     ( $first:expr, $( $remainder:expr, )* ) => ( $first )\n@@ -570,34 +690,6 @@ declare_special_idents_and_keywords! {\n     }\n }\n \n-/**\n- * Maps a token to a record specifying the corresponding binary\n- * operator\n- */\n-pub fn token_to_binop(tok: &Token) -> Option<ast::BinOp> {\n-    match *tok {\n-        BinOp(Star)     => Some(ast::BiMul),\n-        BinOp(Slash)    => Some(ast::BiDiv),\n-        BinOp(Percent)  => Some(ast::BiRem),\n-        BinOp(Plus)     => Some(ast::BiAdd),\n-        BinOp(Minus)    => Some(ast::BiSub),\n-        BinOp(Shl)      => Some(ast::BiShl),\n-        BinOp(Shr)      => Some(ast::BiShr),\n-        BinOp(And)      => Some(ast::BiBitAnd),\n-        BinOp(Caret)    => Some(ast::BiBitXor),\n-        BinOp(Or)       => Some(ast::BiBitOr),\n-        Lt              => Some(ast::BiLt),\n-        Le              => Some(ast::BiLe),\n-        Ge              => Some(ast::BiGe),\n-        Gt              => Some(ast::BiGt),\n-        EqEq            => Some(ast::BiEq),\n-        Ne              => Some(ast::BiNe),\n-        AndAnd          => Some(ast::BiAnd),\n-        OrOr            => Some(ast::BiOr),\n-        _               => None\n-    }\n-}\n-\n // looks like we can get rid of this completely...\n pub type IdentInterner = StrInterner;\n \n@@ -751,74 +843,6 @@ pub fn fresh_mark() -> ast::Mrk {\n     gensym(\"mark\").uint() as u32\n }\n \n-// See the macro above about the types of keywords\n-\n-pub fn is_keyword(kw: keywords::Keyword, tok: &Token) -> bool {\n-    match *tok {\n-        Ident(sid, false) => { kw.to_name() == sid.name }\n-        _ => { false }\n-    }\n-}\n-\n-pub fn is_any_keyword(tok: &Token) -> bool {\n-    match *tok {\n-        Ident(sid, false) => {\n-            let n = sid.name;\n-\n-               n == SELF_KEYWORD_NAME\n-            || n == STATIC_KEYWORD_NAME\n-            || n == SUPER_KEYWORD_NAME\n-            || STRICT_KEYWORD_START <= n\n-            && n <= RESERVED_KEYWORD_FINAL\n-        },\n-        _ => false\n-    }\n-}\n-\n-pub fn is_strict_keyword(tok: &Token) -> bool {\n-    match *tok {\n-        Ident(sid, false) => {\n-            let n = sid.name;\n-\n-               n == SELF_KEYWORD_NAME\n-            || n == STATIC_KEYWORD_NAME\n-            || n == SUPER_KEYWORD_NAME\n-            || STRICT_KEYWORD_START <= n\n-            && n <= STRICT_KEYWORD_FINAL\n-        },\n-        Ident(sid, true) => {\n-            let n = sid.name;\n-\n-               n != SELF_KEYWORD_NAME\n-            && n != SUPER_KEYWORD_NAME\n-            && STRICT_KEYWORD_START <= n\n-            && n <= STRICT_KEYWORD_FINAL\n-        }\n-        _ => false,\n-    }\n-}\n-\n-pub fn is_reserved_keyword(tok: &Token) -> bool {\n-    match *tok {\n-        Ident(sid, false) => {\n-            let n = sid.name;\n-\n-               RESERVED_KEYWORD_START <= n\n-            && n <= RESERVED_KEYWORD_FINAL\n-        },\n-        _ => false,\n-    }\n-}\n-\n-pub fn mtwt_token_eq(t1 : &Token, t2 : &Token) -> bool {\n-    match (t1,t2) {\n-        (&Ident(id1,_),&Ident(id2,_)) | (&Lifetime(id1),&Lifetime(id2)) =>\n-            mtwt::resolve(id1) == mtwt::resolve(id2),\n-        _ => *t1 == *t2\n-    }\n-}\n-\n-\n #[cfg(test)]\n mod test {\n     use super::*;\n@@ -830,9 +854,9 @@ mod test {\n     }\n \n     #[test] fn mtwt_token_eq_test() {\n-        assert!(mtwt_token_eq(&Gt,&Gt));\n+        assert!(Gt.mtwt_eq(&Gt));\n         let a = str_to_ident(\"bac\");\n         let a1 = mark_ident(a,92);\n-        assert!(mtwt_token_eq(&Ident(a,true),&Ident(a1,false)));\n+        assert!(Ident(a,true).mtwt_eq(&Ident(a1,false)));\n     }\n }"}]}