{"sha": "a602d155f06bb3fb7129c036f372e1cb4595ab01", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE2MDJkMTU1ZjA2YmIzZmI3MTI5YzAzNmYzNzJlMWNiNDU5NWFiMDE=", "commit": {"author": {"name": "Tyson Nottingham", "email": "tgnottingham@gmail.com", "date": "2020-10-12T06:16:01Z"}, "committer": {"name": "Tyson Nottingham", "email": "tgnottingham@gmail.com", "date": "2020-10-12T06:48:35Z"}, "message": "SipHasher128: improve constant names and add more comments", "tree": {"sha": "bc5c5fb572f0128ba28018c85c786b0e4282f0e6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bc5c5fb572f0128ba28018c85c786b0e4282f0e6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a602d155f06bb3fb7129c036f372e1cb4595ab01", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a602d155f06bb3fb7129c036f372e1cb4595ab01", "html_url": "https://github.com/rust-lang/rust/commit/a602d155f06bb3fb7129c036f372e1cb4595ab01", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a602d155f06bb3fb7129c036f372e1cb4595ab01/comments", "author": {"login": "tgnottingham", "id": 3668166, "node_id": "MDQ6VXNlcjM2NjgxNjY=", "avatar_url": "https://avatars.githubusercontent.com/u/3668166?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgnottingham", "html_url": "https://github.com/tgnottingham", "followers_url": "https://api.github.com/users/tgnottingham/followers", "following_url": "https://api.github.com/users/tgnottingham/following{/other_user}", "gists_url": "https://api.github.com/users/tgnottingham/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgnottingham/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgnottingham/subscriptions", "organizations_url": "https://api.github.com/users/tgnottingham/orgs", "repos_url": "https://api.github.com/users/tgnottingham/repos", "events_url": "https://api.github.com/users/tgnottingham/events{/privacy}", "received_events_url": "https://api.github.com/users/tgnottingham/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tgnottingham", "id": 3668166, "node_id": "MDQ6VXNlcjM2NjgxNjY=", "avatar_url": "https://avatars.githubusercontent.com/u/3668166?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tgnottingham", "html_url": "https://github.com/tgnottingham", "followers_url": "https://api.github.com/users/tgnottingham/followers", "following_url": "https://api.github.com/users/tgnottingham/following{/other_user}", "gists_url": "https://api.github.com/users/tgnottingham/gists{/gist_id}", "starred_url": "https://api.github.com/users/tgnottingham/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tgnottingham/subscriptions", "organizations_url": "https://api.github.com/users/tgnottingham/orgs", "repos_url": "https://api.github.com/users/tgnottingham/repos", "events_url": "https://api.github.com/users/tgnottingham/events{/privacy}", "received_events_url": "https://api.github.com/users/tgnottingham/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "581cc4abf5dd2802914cf4fee832cda2ae7a89a0", "url": "https://api.github.com/repos/rust-lang/rust/commits/581cc4abf5dd2802914cf4fee832cda2ae7a89a0", "html_url": "https://github.com/rust-lang/rust/commit/581cc4abf5dd2802914cf4fee832cda2ae7a89a0"}], "stats": {"total": 106, "additions": 68, "deletions": 38}, "files": [{"sha": "53062b9c20da8b8e6e6118730a518ff98c3bbf3f", "filename": "compiler/rustc_data_structures/src/sip128.rs", "status": "modified", "additions": 66, "deletions": 36, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/a602d155f06bb3fb7129c036f372e1cb4595ab01/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a602d155f06bb3fb7129c036f372e1cb4595ab01/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fsip128.rs?ref=a602d155f06bb3fb7129c036f372e1cb4595ab01", "patch": "@@ -7,12 +7,34 @@ use std::ptr;\n #[cfg(test)]\n mod tests;\n \n+// The SipHash algorithm operates on 8-byte chunks.\n const ELEM_SIZE: usize = mem::size_of::<u64>();\n-const BUFFER_SIZE_ELEMS: usize = 8;\n-const BUFFER_SIZE_BYTES: usize = BUFFER_SIZE_ELEMS * ELEM_SIZE;\n-const BUFFER_SIZE_ELEMS_SPILL: usize = BUFFER_SIZE_ELEMS + 1;\n-const BUFFER_SIZE_BYTES_SPILL: usize = BUFFER_SIZE_ELEMS_SPILL * ELEM_SIZE;\n-const BUFFER_SPILL_INDEX: usize = BUFFER_SIZE_ELEMS_SPILL - 1;\n+\n+// Size of the buffer in number of elements, not including the spill.\n+//\n+// The selection of this size was guided by rustc-perf benchmark comparisons of\n+// different buffer sizes. It should be periodically reevaluated as the compiler\n+// implementation and input characteristics change.\n+//\n+// Using the same-sized buffer for everything we hash is a performance versus\n+// complexity tradeoff. The ideal buffer size, and whether buffering should even\n+// be used, depends on what is being hashed. It may be worth it to size the\n+// buffer appropriately (perhaps by making SipHasher128 generic over the buffer\n+// size) or disable buffering depending on what is being hashed. But at this\n+// time, we use the same buffer size for everything.\n+const BUFFER_CAPACITY: usize = 8;\n+\n+// Size of the buffer in bytes, not including the spill.\n+const BUFFER_SIZE: usize = BUFFER_CAPACITY * ELEM_SIZE;\n+\n+// Size of the buffer in number of elements, including the spill.\n+const BUFFER_WITH_SPILL_CAPACITY: usize = BUFFER_CAPACITY + 1;\n+\n+// Size of the buffer in bytes, including the spill.\n+const BUFFER_WITH_SPILL_SIZE: usize = BUFFER_WITH_SPILL_CAPACITY * ELEM_SIZE;\n+\n+// Index of the spill element in the buffer.\n+const BUFFER_SPILL_INDEX: usize = BUFFER_WITH_SPILL_CAPACITY - 1;\n \n #[derive(Debug, Clone)]\n #[repr(C)]\n@@ -22,10 +44,10 @@ pub struct SipHasher128 {\n     // `processed`, and then repetition of that pattern until hashing is done.\n     // This is the basis for the ordering of fields below. However, in practice\n     // the cache miss-rate for data access is extremely low regardless of order.\n-    nbuf: usize,                                      // how many bytes in buf are valid\n-    buf: [MaybeUninit<u64>; BUFFER_SIZE_ELEMS_SPILL], // unprocessed bytes le\n-    state: State,                                     // hash State\n-    processed: usize,                                 // how many bytes we've processed\n+    nbuf: usize, // how many bytes in buf are valid\n+    buf: [MaybeUninit<u64>; BUFFER_WITH_SPILL_CAPACITY], // unprocessed bytes le\n+    state: State, // hash State\n+    processed: usize, // how many bytes we've processed\n }\n \n #[derive(Debug, Clone, Copy)]\n@@ -64,13 +86,18 @@ macro_rules! compress {\n // Copies up to 8 bytes from source to destination. This performs better than\n // `ptr::copy_nonoverlapping` on microbenchmarks and may perform better on real\n // workloads since all of the copies have fixed sizes and avoid calling memcpy.\n+//\n+// This is specifically designed for copies of up to 8 bytes, because that's the\n+// maximum of number bytes needed to fill an 8-byte-sized element on which\n+// SipHash operates. Note that for variable-sized copies which are known to be\n+// less than 8 bytes, this function will perform more work than necessary unless\n+// the compiler is able to optimize the extra work away.\n #[inline]\n unsafe fn copy_nonoverlapping_small(src: *const u8, dst: *mut u8, count: usize) {\n-    const COUNT_MAX: usize = 8;\n-    debug_assert!(count <= COUNT_MAX);\n+    debug_assert!(count <= 8);\n \n-    if count == COUNT_MAX {\n-        ptr::copy_nonoverlapping(src, dst, COUNT_MAX);\n+    if count == 8 {\n+        ptr::copy_nonoverlapping(src, dst, 8);\n         return;\n     }\n \n@@ -116,10 +143,13 @@ unsafe fn copy_nonoverlapping_small(src: *const u8, dst: *mut u8, count: usize)\n // The buffer includes a \"spill\"--an extra element at the end--which simplifies\n // the integer write buffer processing path. The value that fills the buffer can\n // be written with a statically sized write that may spill over into the spill.\n-// After the buffer is processed, the part of the value that spilled over can\n+// After the buffer is processed, the part of the value that spilled over can be\n // written from the spill to the beginning of the buffer with another statically\n-// sized write. Due to static sizes, this scheme performs better than copying\n-// the exact number of bytes needed into the end and beginning of the buffer.\n+// sized write. This write may copy more bytes than actually spilled over, but\n+// we maintain the metadata such that any extra copied bytes will be ignored by\n+// subsequent processing. Due to the static sizes, this scheme performs better\n+// than copying the exact number of bytes needed into the end and beginning of\n+// the buffer.\n //\n // The buffer is uninitialized, which improves performance, but may preclude\n // efficient implementation of alternative approaches. The improvement is not so\n@@ -142,12 +172,12 @@ unsafe fn copy_nonoverlapping_small(src: *const u8, dst: *mut u8, count: usize)\n //\n // In order to make `SipHasher128` consistent with `SipHasher` in libstd, we\n // choose to do the integer to byte sequence conversion in the platform-\n-// dependent way. Clients can achieve (nearly) platform-independent hashing by\n-// widening `isize` and `usize` integers to 64 bits on 32-bit systems and\n-// byte-swapping integers on big-endian systems before passing them to the\n-// writing functions. This causes the input byte sequence to look identical on\n-// big- and little- endian systems (supposing `isize` and `usize` values can be\n-// represented in 32 bits), which ensures platform-independent results.\n+// dependent way. Clients can achieve platform-independent hashing by widening\n+// `isize` and `usize` integers to 64 bits on 32-bit systems and byte-swapping\n+// integers on big-endian systems before passing them to the writing functions.\n+// This causes the input byte sequence to look identical on big- and little-\n+// endian systems (supposing `isize` and `usize` values can be represented in 32\n+// bits), which ensures platform-independent results.\n impl SipHasher128 {\n     #[inline]\n     pub fn new_with_keys(key0: u64, key1: u64) -> SipHasher128 {\n@@ -178,10 +208,10 @@ impl SipHasher128 {\n         let size = mem::size_of::<T>();\n         let nbuf = self.nbuf;\n         debug_assert!(size <= 8);\n-        debug_assert!(nbuf < BUFFER_SIZE_BYTES);\n-        debug_assert!(nbuf + size < BUFFER_SIZE_BYTES_SPILL);\n+        debug_assert!(nbuf < BUFFER_SIZE);\n+        debug_assert!(nbuf + size < BUFFER_WITH_SPILL_SIZE);\n \n-        if nbuf + size < BUFFER_SIZE_BYTES {\n+        if nbuf + size < BUFFER_SIZE {\n             unsafe {\n                 // The memcpy call is optimized away because the size is known.\n                 let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n@@ -207,17 +237,17 @@ impl SipHasher128 {\n         let size = mem::size_of::<T>();\n         let nbuf = self.nbuf;\n         debug_assert!(size <= 8);\n-        debug_assert!(nbuf < BUFFER_SIZE_BYTES);\n-        debug_assert!(nbuf + size >= BUFFER_SIZE_BYTES);\n-        debug_assert!(nbuf + size < BUFFER_SIZE_BYTES_SPILL);\n+        debug_assert!(nbuf < BUFFER_SIZE);\n+        debug_assert!(nbuf + size >= BUFFER_SIZE);\n+        debug_assert!(nbuf + size < BUFFER_WITH_SPILL_SIZE);\n \n         // Copy first part of input into end of buffer, possibly into spill\n         // element. The memcpy call is optimized away because the size is known.\n         let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n         ptr::copy_nonoverlapping(&x as *const _ as *const u8, dst, size);\n \n         // Process buffer.\n-        for i in 0..BUFFER_SIZE_ELEMS {\n+        for i in 0..BUFFER_CAPACITY {\n             let elem = self.buf.get_unchecked(i).assume_init().to_le();\n             self.state.v3 ^= elem;\n             Sip24Rounds::c_rounds(&mut self.state);\n@@ -234,18 +264,18 @@ impl SipHasher128 {\n         // This function should only be called when the write fills the buffer.\n         // Therefore, when size == 1, the new `self.nbuf` must be zero. The size\n         // is statically known, so the branch is optimized away.\n-        self.nbuf = if size == 1 { 0 } else { nbuf + size - BUFFER_SIZE_BYTES };\n-        self.processed += BUFFER_SIZE_BYTES;\n+        self.nbuf = if size == 1 { 0 } else { nbuf + size - BUFFER_SIZE };\n+        self.processed += BUFFER_SIZE;\n     }\n \n     // A write function for byte slices.\n     #[inline]\n     fn slice_write(&mut self, msg: &[u8]) {\n         let length = msg.len();\n         let nbuf = self.nbuf;\n-        debug_assert!(nbuf < BUFFER_SIZE_BYTES);\n+        debug_assert!(nbuf < BUFFER_SIZE);\n \n-        if nbuf + length < BUFFER_SIZE_BYTES {\n+        if nbuf + length < BUFFER_SIZE {\n             unsafe {\n                 let dst = (self.buf.as_mut_ptr() as *mut u8).add(nbuf);\n \n@@ -275,8 +305,8 @@ impl SipHasher128 {\n     unsafe fn slice_write_process_buffer(&mut self, msg: &[u8]) {\n         let length = msg.len();\n         let nbuf = self.nbuf;\n-        debug_assert!(nbuf < BUFFER_SIZE_BYTES);\n-        debug_assert!(nbuf + length >= BUFFER_SIZE_BYTES);\n+        debug_assert!(nbuf < BUFFER_SIZE);\n+        debug_assert!(nbuf + length >= BUFFER_SIZE);\n \n         // Always copy first part of input into current element of buffer.\n         // This function should only be called when the write fills the buffer,\n@@ -328,7 +358,7 @@ impl SipHasher128 {\n \n     #[inline]\n     pub fn finish128(mut self) -> (u64, u64) {\n-        debug_assert!(self.nbuf < BUFFER_SIZE_BYTES);\n+        debug_assert!(self.nbuf < BUFFER_SIZE);\n \n         // Process full elements in buffer.\n         let last = self.nbuf / ELEM_SIZE;"}, {"sha": "5fe967c4158fe3141ea6a23ec6f4c3b61765d697", "filename": "compiler/rustc_data_structures/src/sip128/tests.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/a602d155f06bb3fb7129c036f372e1cb4595ab01/compiler%2Frustc_data_structures%2Fsrc%2Fsip128%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a602d155f06bb3fb7129c036f372e1cb4595ab01/compiler%2Frustc_data_structures%2Fsrc%2Fsip128%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_data_structures%2Fsrc%2Fsip128%2Ftests.rs?ref=a602d155f06bb3fb7129c036f372e1cb4595ab01", "patch": "@@ -456,12 +456,12 @@ macro_rules! test_fill_buffer {\n         // Test filling and overfilling the buffer from all possible offsets\n         // for a given integer type and its corresponding write method.\n         const SIZE: usize = std::mem::size_of::<$type>();\n-        let input = [42; BUFFER_SIZE_BYTES];\n+        let input = [42; BUFFER_SIZE];\n         let x = 0x01234567_89ABCDEF_76543210_FEDCBA98_u128 as $type;\n         let x_bytes = &x.to_ne_bytes();\n \n         for i in 1..=SIZE {\n-            let s = &input[..BUFFER_SIZE_BYTES - i];\n+            let s = &input[..BUFFER_SIZE - i];\n \n             let mut h1 = SipHasher128::new_with_keys(7, 13);\n             h1.write(s);"}]}