{"sha": "4b7c596b3aa232f40f4b4fa796240d683fe6544f", "node_id": "C_kwDOAAsO6NoAKDRiN2M1OTZiM2FhMjMyZjQwZjRiNGZhNzk2MjQwZDY4M2ZlNjU0NGY", "commit": {"author": {"name": "Dylan DPC", "email": "99973273+Dylan-DPC@users.noreply.github.com", "date": "2022-09-21T13:31:08Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-09-21T13:31:08Z"}, "message": "Rollup merge of #102041 - nnethercote:improve-meta-stats, r=bjorn3\n\nImprove `-Zmeta-stats` some more\n\nA follow-up to #97384.\n\nr? ```@bjorn3```", "tree": {"sha": "f925f3cd8b8907bd422bcd0f8b58c8cd1ce79b79", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f925f3cd8b8907bd422bcd0f8b58c8cd1ce79b79"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4b7c596b3aa232f40f4b4fa796240d683fe6544f", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJjKxIcCRBK7hj4Ov3rIwAAs6gIAJQndxJHW5hXUDXJ6C2zrPcu\nfUccG6mfecFgx6Yt830lIRnUK8CpOPsXfm3NibqFen2bdtyIogYpx4TlaBpwlRz2\n5GGQE6Fe3nleKarOvKkISTCEK3ib+TxagVbi4f8OgR/A61h7NVT2ksXU0XXGXPA1\niqnw4tDkurDmRlk5AUEM7A7XDkevzILPtJ9iqR0360hNWwEcQCKSjNy08oJOx1Dt\n6be6u6hwAP0KvAKAs9CW6PC14577P9c89A/wRmOiRxVPWNeinqU2bYc7ebgAzjKQ\n8tNagzxp9QiAP0Pr30UMs2y1HtdyFJ197mQ2JrFI/G1bgSSzCxqSBm6x/3t9X4w=\n=6CtA\n-----END PGP SIGNATURE-----\n", "payload": "tree f925f3cd8b8907bd422bcd0f8b58c8cd1ce79b79\nparent 36e39725fbb98177d8a7cdb7284028ff27f0ef37\nparent a7b35b5618da9c557a8d318aa7839a96fecb4d05\nauthor Dylan DPC <99973273+Dylan-DPC@users.noreply.github.com> 1663767068 +0530\ncommitter GitHub <noreply@github.com> 1663767068 +0530\n\nRollup merge of #102041 - nnethercote:improve-meta-stats, r=bjorn3\n\nImprove `-Zmeta-stats` some more\n\nA follow-up to #97384.\n\nr? ```@bjorn3```\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4b7c596b3aa232f40f4b4fa796240d683fe6544f", "html_url": "https://github.com/rust-lang/rust/commit/4b7c596b3aa232f40f4b4fa796240d683fe6544f", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4b7c596b3aa232f40f4b4fa796240d683fe6544f/comments", "author": {"login": "Dylan-DPC", "id": 99973273, "node_id": "U_kgDOBfV4mQ", "avatar_url": "https://avatars.githubusercontent.com/u/99973273?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dylan-DPC", "html_url": "https://github.com/Dylan-DPC", "followers_url": "https://api.github.com/users/Dylan-DPC/followers", "following_url": "https://api.github.com/users/Dylan-DPC/following{/other_user}", "gists_url": "https://api.github.com/users/Dylan-DPC/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dylan-DPC/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dylan-DPC/subscriptions", "organizations_url": "https://api.github.com/users/Dylan-DPC/orgs", "repos_url": "https://api.github.com/users/Dylan-DPC/repos", "events_url": "https://api.github.com/users/Dylan-DPC/events{/privacy}", "received_events_url": "https://api.github.com/users/Dylan-DPC/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "36e39725fbb98177d8a7cdb7284028ff27f0ef37", "url": "https://api.github.com/repos/rust-lang/rust/commits/36e39725fbb98177d8a7cdb7284028ff27f0ef37", "html_url": "https://github.com/rust-lang/rust/commit/36e39725fbb98177d8a7cdb7284028ff27f0ef37"}, {"sha": "a7b35b5618da9c557a8d318aa7839a96fecb4d05", "url": "https://api.github.com/repos/rust-lang/rust/commits/a7b35b5618da9c557a8d318aa7839a96fecb4d05", "html_url": "https://github.com/rust-lang/rust/commit/a7b35b5618da9c557a8d318aa7839a96fecb4d05"}], "stats": {"total": 365, "additions": 152, "deletions": 213}, "files": [{"sha": "67c28461ce5cf338c75373d64c430a3709c0a388", "filename": "compiler/rustc_metadata/src/rmeta/encoder.rs", "status": "modified", "additions": 152, "deletions": 213, "changes": 365, "blob_url": "https://github.com/rust-lang/rust/blob/4b7c596b3aa232f40f4b4fa796240d683fe6544f/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4b7c596b3aa232f40f4b4fa796240d683fe6544f/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_metadata%2Fsrc%2Frmeta%2Fencoder.rs?ref=4b7c596b3aa232f40f4b4fa796240d683fe6544f", "patch": "@@ -28,6 +28,7 @@ use rustc_middle::ty::codec::TyEncoder;\n use rustc_middle::ty::fast_reject::{self, SimplifiedType, TreatParams};\n use rustc_middle::ty::query::Providers;\n use rustc_middle::ty::{self, SymbolName, Ty, TyCtxt};\n+use rustc_middle::util::common::to_readable_str;\n use rustc_serialize::{opaque, Decodable, Decoder, Encodable, Encoder};\n use rustc_session::config::CrateType;\n use rustc_session::cstore::{ForeignModule, LinkagePreference, NativeLib};\n@@ -261,10 +262,10 @@ impl<'a, 'tcx> Encodable<EncodeContext<'a, 'tcx>> for Span {\n         // This allows us to avoid loading the dependencies of proc-macro crates: all of\n         // the information we need to decode `Span`s is stored in the proc-macro crate.\n         let (tag, metadata_index) = if source_file.is_imported() && !s.is_proc_macro {\n-            // To simplify deserialization, we 'rebase' this span onto the crate it originally came from\n-            // (the crate that 'owns' the file it references. These rebased 'lo' and 'hi' values\n-            // are relative to the source map information for the 'foreign' crate whose CrateNum\n-            // we write into the metadata. This allows `imported_source_files` to binary\n+            // To simplify deserialization, we 'rebase' this span onto the crate it originally came\n+            // from (the crate that 'owns' the file it references. These rebased 'lo' and 'hi'\n+            // values are relative to the source map information for the 'foreign' crate whose\n+            // CrateNum we write into the metadata. This allows `imported_source_files` to binary\n             // search through the 'foreign' crate's source map information, using the\n             // deserialized 'lo' and 'hi' values directly.\n             //\n@@ -554,78 +555,56 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n \n     fn encode_crate_root(&mut self) -> LazyValue<CrateRoot> {\n         let tcx = self.tcx;\n-        let mut i = 0;\n-        let preamble_bytes = self.position() - i;\n-\n-        // Encode the crate deps\n-        i = self.position();\n-        let crate_deps = self.encode_crate_deps();\n-        let dylib_dependency_formats = self.encode_dylib_dependency_formats();\n-        let dep_bytes = self.position() - i;\n-\n-        // Encode the lib features.\n-        i = self.position();\n-        let lib_features = self.encode_lib_features();\n-        let lib_feature_bytes = self.position() - i;\n-\n-        // Encode the stability implications.\n-        i = self.position();\n-        let stability_implications = self.encode_stability_implications();\n-        let stability_implications_bytes = self.position() - i;\n-\n-        // Encode the language items.\n-        i = self.position();\n-        let lang_items = self.encode_lang_items();\n-        let lang_items_missing = self.encode_lang_items_missing();\n-        let lang_item_bytes = self.position() - i;\n-\n-        // Encode the diagnostic items.\n-        i = self.position();\n-        let diagnostic_items = self.encode_diagnostic_items();\n-        let diagnostic_item_bytes = self.position() - i;\n-\n-        // Encode the native libraries used\n-        i = self.position();\n-        let native_libraries = self.encode_native_libraries();\n-        let native_lib_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let foreign_modules = self.encode_foreign_modules();\n-        let foreign_modules_bytes = self.position() - i;\n-\n-        // Encode DefPathTable\n-        i = self.position();\n-        self.encode_def_path_table();\n-        let def_path_table_bytes = self.position() - i;\n+        let mut stats: Vec<(&'static str, usize)> = Vec::with_capacity(32);\n+\n+        macro_rules! stat {\n+            ($label:literal, $f:expr) => {{\n+                let orig_pos = self.position();\n+                let res = $f();\n+                stats.push(($label, self.position() - orig_pos));\n+                res\n+            }};\n+        }\n+\n+        // We have already encoded some things. Get their combined size from the current position.\n+        stats.push((\"preamble\", self.position()));\n+\n+        let (crate_deps, dylib_dependency_formats) =\n+            stat!(\"dep\", || (self.encode_crate_deps(), self.encode_dylib_dependency_formats()));\n+\n+        let lib_features = stat!(\"lib-features\", || self.encode_lib_features());\n+\n+        let stability_implications =\n+            stat!(\"stability-implications\", || self.encode_stability_implications());\n+\n+        let (lang_items, lang_items_missing) = stat!(\"lang-items\", || {\n+            (self.encode_lang_items(), self.encode_lang_items_missing())\n+        });\n+\n+        let diagnostic_items = stat!(\"diagnostic-items\", || self.encode_diagnostic_items());\n+\n+        let native_libraries = stat!(\"native-libs\", || self.encode_native_libraries());\n+\n+        let foreign_modules = stat!(\"foreign-modules\", || self.encode_foreign_modules());\n+\n+        _ = stat!(\"def-path-table\", || self.encode_def_path_table());\n \n         // Encode the def IDs of traits, for rustdoc and diagnostics.\n-        i = self.position();\n-        let traits = self.encode_traits();\n-        let traits_bytes = self.position() - i;\n+        let traits = stat!(\"traits\", || self.encode_traits());\n \n         // Encode the def IDs of impls, for coherence checking.\n-        i = self.position();\n-        let impls = self.encode_impls();\n-        let impls_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let incoherent_impls = self.encode_incoherent_impls();\n-        let incoherent_impls_bytes = self.position() - i;\n-\n-        // Encode MIR.\n-        i = self.position();\n-        self.encode_mir();\n-        let mir_bytes = self.position() - i;\n-\n-        // Encode the items.\n-        i = self.position();\n-        self.encode_def_ids();\n-        self.encode_info_for_items();\n-        let item_bytes = self.position() - i;\n-\n-        // Encode the allocation index\n-        i = self.position();\n-        let interpret_alloc_index = {\n+        let impls = stat!(\"impls\", || self.encode_impls());\n+\n+        let incoherent_impls = stat!(\"incoherent-impls\", || self.encode_incoherent_impls());\n+\n+        _ = stat!(\"mir\", || self.encode_mir());\n+\n+        _ = stat!(\"items\", || {\n+            self.encode_def_ids();\n+            self.encode_info_for_items();\n+        });\n+\n+        let interpret_alloc_index = stat!(\"interpret-alloc-index\", || {\n             let mut interpret_alloc_index = Vec::new();\n             let mut n = 0;\n             trace!(\"beginning to encode alloc ids\");\n@@ -646,126 +625,90 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n                 n = new_n;\n             }\n             self.lazy_array(interpret_alloc_index)\n-        };\n-        let interpret_alloc_index_bytes = self.position() - i;\n+        });\n \n-        // Encode the proc macro data. This affects 'tables',\n-        // so we need to do this before we encode the tables.\n-        // This overwrites def_keys, so it must happen after encode_def_path_table.\n-        i = self.position();\n-        let proc_macro_data = self.encode_proc_macros();\n-        let proc_macro_data_bytes = self.position() - i;\n+        // Encode the proc macro data. This affects `tables`, so we need to do this before we\n+        // encode the tables. This overwrites def_keys, so it must happen after\n+        // encode_def_path_table.\n+        let proc_macro_data = stat!(\"proc-macro-data\", || self.encode_proc_macros());\n \n-        i = self.position();\n-        let tables = self.tables.encode(&mut self.opaque);\n-        let tables_bytes = self.position() - i;\n+        let tables = stat!(\"tables\", || self.tables.encode(&mut self.opaque));\n \n-        i = self.position();\n-        let debugger_visualizers = self.encode_debugger_visualizers();\n-        let debugger_visualizers_bytes = self.position() - i;\n+        let debugger_visualizers =\n+            stat!(\"debugger-visualizers\", || self.encode_debugger_visualizers());\n \n         // Encode exported symbols info. This is prefetched in `encode_metadata` so we encode\n         // this as late as possible to give the prefetching as much time as possible to complete.\n-        i = self.position();\n-        let exported_symbols = tcx.exported_symbols(LOCAL_CRATE);\n-        let exported_symbols = self.encode_exported_symbols(&exported_symbols);\n-        let exported_symbols_bytes = self.position() - i;\n-\n-        // Encode the hygiene data,\n-        // IMPORTANT: this *must* be the last thing that we encode (other than `SourceMap`). The process\n-        // of encoding other items (e.g. `optimized_mir`) may cause us to load\n-        // data from the incremental cache. If this causes us to deserialize a `Span`,\n-        // then we may load additional `SyntaxContext`s into the global `HygieneData`.\n-        // Therefore, we need to encode the hygiene data last to ensure that we encode\n-        // any `SyntaxContext`s that might be used.\n-        i = self.position();\n-        let (syntax_contexts, expn_data, expn_hashes) = self.encode_hygiene();\n-        let hygiene_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let def_path_hash_map = self.encode_def_path_hash_map();\n-        let def_path_hash_map_bytes = self.position() - i;\n-\n-        // Encode source_map. This needs to be done last,\n-        // since encoding `Span`s tells us which `SourceFiles` we actually\n-        // need to encode.\n-        i = self.position();\n-        let source_map = self.encode_source_map();\n-        let source_map_bytes = self.position() - i;\n-\n-        i = self.position();\n-        let attrs = tcx.hir().krate_attrs();\n-        let has_default_lib_allocator = tcx.sess.contains_name(&attrs, sym::default_lib_allocator);\n-        let root = self.lazy(CrateRoot {\n-            name: tcx.crate_name(LOCAL_CRATE),\n-            extra_filename: tcx.sess.opts.cg.extra_filename.clone(),\n-            triple: tcx.sess.opts.target_triple.clone(),\n-            hash: tcx.crate_hash(LOCAL_CRATE),\n-            stable_crate_id: tcx.def_path_hash(LOCAL_CRATE.as_def_id()).stable_crate_id(),\n-            required_panic_strategy: tcx.required_panic_strategy(LOCAL_CRATE),\n-            panic_in_drop_strategy: tcx.sess.opts.unstable_opts.panic_in_drop,\n-            edition: tcx.sess.edition(),\n-            has_global_allocator: tcx.has_global_allocator(LOCAL_CRATE),\n-            has_panic_handler: tcx.has_panic_handler(LOCAL_CRATE),\n-            has_default_lib_allocator,\n-            proc_macro_data,\n-            debugger_visualizers,\n-            compiler_builtins: tcx.sess.contains_name(&attrs, sym::compiler_builtins),\n-            needs_allocator: tcx.sess.contains_name(&attrs, sym::needs_allocator),\n-            needs_panic_runtime: tcx.sess.contains_name(&attrs, sym::needs_panic_runtime),\n-            no_builtins: tcx.sess.contains_name(&attrs, sym::no_builtins),\n-            panic_runtime: tcx.sess.contains_name(&attrs, sym::panic_runtime),\n-            profiler_runtime: tcx.sess.contains_name(&attrs, sym::profiler_runtime),\n-            symbol_mangling_version: tcx.sess.opts.get_symbol_mangling_version(),\n-\n-            crate_deps,\n-            dylib_dependency_formats,\n-            lib_features,\n-            stability_implications,\n-            lang_items,\n-            diagnostic_items,\n-            lang_items_missing,\n-            native_libraries,\n-            foreign_modules,\n-            source_map,\n-            traits,\n-            impls,\n-            incoherent_impls,\n-            exported_symbols,\n-            interpret_alloc_index,\n-            tables,\n-            syntax_contexts,\n-            expn_data,\n-            expn_hashes,\n-            def_path_hash_map,\n+        let exported_symbols = stat!(\"exported-symbols\", || {\n+            self.encode_exported_symbols(&tcx.exported_symbols(LOCAL_CRATE))\n+        });\n+\n+        // Encode the hygiene data.\n+        // IMPORTANT: this *must* be the last thing that we encode (other than `SourceMap`). The\n+        // process of encoding other items (e.g. `optimized_mir`) may cause us to load data from\n+        // the incremental cache. If this causes us to deserialize a `Span`, then we may load\n+        // additional `SyntaxContext`s into the global `HygieneData`. Therefore, we need to encode\n+        // the hygiene data last to ensure that we encode any `SyntaxContext`s that might be used.\n+        let (syntax_contexts, expn_data, expn_hashes) = stat!(\"hygiene\", || self.encode_hygiene());\n+\n+        let def_path_hash_map = stat!(\"def-path-hash-map\", || self.encode_def_path_hash_map());\n+\n+        // Encode source_map. This needs to be done last, because encoding `Span`s tells us which\n+        // `SourceFiles` we actually need to encode.\n+        let source_map = stat!(\"source-map\", || self.encode_source_map());\n+\n+        let root = stat!(\"final\", || {\n+            let attrs = tcx.hir().krate_attrs();\n+            self.lazy(CrateRoot {\n+                name: tcx.crate_name(LOCAL_CRATE),\n+                extra_filename: tcx.sess.opts.cg.extra_filename.clone(),\n+                triple: tcx.sess.opts.target_triple.clone(),\n+                hash: tcx.crate_hash(LOCAL_CRATE),\n+                stable_crate_id: tcx.def_path_hash(LOCAL_CRATE.as_def_id()).stable_crate_id(),\n+                required_panic_strategy: tcx.required_panic_strategy(LOCAL_CRATE),\n+                panic_in_drop_strategy: tcx.sess.opts.unstable_opts.panic_in_drop,\n+                edition: tcx.sess.edition(),\n+                has_global_allocator: tcx.has_global_allocator(LOCAL_CRATE),\n+                has_panic_handler: tcx.has_panic_handler(LOCAL_CRATE),\n+                has_default_lib_allocator: tcx\n+                    .sess\n+                    .contains_name(&attrs, sym::default_lib_allocator),\n+                proc_macro_data,\n+                debugger_visualizers,\n+                compiler_builtins: tcx.sess.contains_name(&attrs, sym::compiler_builtins),\n+                needs_allocator: tcx.sess.contains_name(&attrs, sym::needs_allocator),\n+                needs_panic_runtime: tcx.sess.contains_name(&attrs, sym::needs_panic_runtime),\n+                no_builtins: tcx.sess.contains_name(&attrs, sym::no_builtins),\n+                panic_runtime: tcx.sess.contains_name(&attrs, sym::panic_runtime),\n+                profiler_runtime: tcx.sess.contains_name(&attrs, sym::profiler_runtime),\n+                symbol_mangling_version: tcx.sess.opts.get_symbol_mangling_version(),\n+\n+                crate_deps,\n+                dylib_dependency_formats,\n+                lib_features,\n+                stability_implications,\n+                lang_items,\n+                diagnostic_items,\n+                lang_items_missing,\n+                native_libraries,\n+                foreign_modules,\n+                source_map,\n+                traits,\n+                impls,\n+                incoherent_impls,\n+                exported_symbols,\n+                interpret_alloc_index,\n+                tables,\n+                syntax_contexts,\n+                expn_data,\n+                expn_hashes,\n+                def_path_hash_map,\n+            })\n         });\n-        let final_bytes = self.position() - i;\n \n         let total_bytes = self.position();\n \n-        let computed_total_bytes = preamble_bytes\n-            + dep_bytes\n-            + lib_feature_bytes\n-            + stability_implications_bytes\n-            + lang_item_bytes\n-            + diagnostic_item_bytes\n-            + native_lib_bytes\n-            + foreign_modules_bytes\n-            + def_path_table_bytes\n-            + traits_bytes\n-            + impls_bytes\n-            + incoherent_impls_bytes\n-            + mir_bytes\n-            + item_bytes\n-            + interpret_alloc_index_bytes\n-            + proc_macro_data_bytes\n-            + tables_bytes\n-            + debugger_visualizers_bytes\n-            + exported_symbols_bytes\n-            + hygiene_bytes\n-            + def_path_hash_map_bytes\n-            + source_map_bytes\n-            + final_bytes;\n+        let computed_total_bytes: usize = stats.iter().map(|(_, size)| size).sum();\n         assert_eq!(total_bytes, computed_total_bytes);\n \n         if tcx.sess.meta_stats() {\n@@ -783,42 +726,38 @@ impl<'a, 'tcx> EncodeContext<'a, 'tcx> {\n             }\n             assert_eq!(self.opaque.file().stream_position().unwrap(), pos_before_rewind);\n \n+            stats.sort_by_key(|&(_, usize)| usize);\n+\n+            let prefix = \"meta-stats\";\n             let perc = |bytes| (bytes * 100) as f64 / total_bytes as f64;\n-            let p = |label, bytes| {\n-                eprintln!(\"{:>21}: {:>8} bytes ({:4.1}%)\", label, bytes, perc(bytes));\n-            };\n \n-            eprintln!(\"\");\n+            eprintln!(\"{} METADATA STATS\", prefix);\n+            eprintln!(\"{} {:<23}{:>10}\", prefix, \"Section\", \"Size\");\n+            eprintln!(\n+                \"{} ----------------------------------------------------------------\",\n+                prefix\n+            );\n+            for (label, size) in stats {\n+                eprintln!(\n+                    \"{} {:<23}{:>10} ({:4.1}%)\",\n+                    prefix,\n+                    label,\n+                    to_readable_str(size),\n+                    perc(size)\n+                );\n+            }\n+            eprintln!(\n+                \"{} ----------------------------------------------------------------\",\n+                prefix\n+            );\n             eprintln!(\n-                \"{} metadata bytes, of which {} bytes ({:.1}%) are zero\",\n-                total_bytes,\n-                zero_bytes,\n+                \"{} {:<23}{:>10} (of which {:.1}% are zero bytes)\",\n+                prefix,\n+                \"Total\",\n+                to_readable_str(total_bytes),\n                 perc(zero_bytes)\n             );\n-            p(\"preamble\", preamble_bytes);\n-            p(\"dep\", dep_bytes);\n-            p(\"lib feature\", lib_feature_bytes);\n-            p(\"stability_implications\", stability_implications_bytes);\n-            p(\"lang item\", lang_item_bytes);\n-            p(\"diagnostic item\", diagnostic_item_bytes);\n-            p(\"native lib\", native_lib_bytes);\n-            p(\"foreign modules\", foreign_modules_bytes);\n-            p(\"def-path table\", def_path_table_bytes);\n-            p(\"traits\", traits_bytes);\n-            p(\"impls\", impls_bytes);\n-            p(\"incoherent_impls\", incoherent_impls_bytes);\n-            p(\"mir\", mir_bytes);\n-            p(\"item\", item_bytes);\n-            p(\"interpret_alloc_index\", interpret_alloc_index_bytes);\n-            p(\"proc-macro-data\", proc_macro_data_bytes);\n-            p(\"tables\", tables_bytes);\n-            p(\"debugger visualizers\", debugger_visualizers_bytes);\n-            p(\"exported symbols\", exported_symbols_bytes);\n-            p(\"hygiene\", hygiene_bytes);\n-            p(\"def-path hashes\", def_path_hash_map_bytes);\n-            p(\"source_map\", source_map_bytes);\n-            p(\"final\", final_bytes);\n-            eprintln!(\"\");\n+            eprintln!(\"{}\", prefix);\n         }\n \n         root"}]}