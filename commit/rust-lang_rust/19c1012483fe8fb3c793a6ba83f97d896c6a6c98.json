{"sha": "19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE5YzEwMTI0ODNmZThmYjNjNzkzYTZiYTgzZjk3ZDg5NmM2YTZjOTg=", "commit": {"author": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2020-02-12T10:50:00Z"}, "committer": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2020-02-12T10:50:00Z"}, "message": "Use a counter instead of pointers to the stack", "tree": {"sha": "c9e4cbd3e30c725cd02f02f9b72f8b6887fc6508", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c9e4cbd3e30c725cd02f02f9b72f8b6887fc6508"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "html_url": "https://github.com/rust-lang/rust/commit/19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/comments", "author": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "77ab0d091e32ac9ec4154bba1727fc3937975d64", "url": "https://api.github.com/repos/rust-lang/rust/commits/77ab0d091e32ac9ec4154bba1727fc3937975d64", "html_url": "https://github.com/rust-lang/rust/commit/77ab0d091e32ac9ec4154bba1727fc3937975d64"}], "stats": {"total": 193, "additions": 117, "deletions": 76}, "files": [{"sha": "a3541db129151d62fb937e4cf875cfc094c390c3", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "patch": "@@ -1633,7 +1633,7 @@ pub mod tls {\n \n         /// The current query job, if any. This is updated by `JobOwner::start` in\n         /// `ty::query::plumbing` when executing a query.\n-        pub query: Option<query::QueryToken>,\n+        pub query: Option<query::QueryJobId>,\n \n         /// Where to store diagnostics for the current query job, if any.\n         /// This is updated by `JobOwner::start` in `ty::query::plumbing` when executing a query."}, {"sha": "a3c2bb2f1f557faad5a534b16e7a7854c95d85b7", "filename": "src/librustc/ty/query/job.rs", "status": "modified", "additions": 40, "deletions": 32, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fjob.rs?ref=19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "patch": "@@ -1,3 +1,4 @@\n+use crate::dep_graph::DepKind;\n use crate::ty::context::TyCtxt;\n use crate::ty::query::plumbing::CycleError;\n use crate::ty::query::Query;\n@@ -7,7 +8,7 @@ use rustc_data_structures::fx::FxHashMap;\n use rustc_span::Span;\n \n use std::marker::PhantomData;\n-use std::num::NonZeroUsize;\n+use std::num::NonZeroU32;\n \n #[cfg(parallel_compiler)]\n use {\n@@ -31,19 +32,26 @@ pub struct QueryInfo<'tcx> {\n     pub query: Query<'tcx>,\n }\n \n-type QueryMap<'tcx> = FxHashMap<QueryToken, QueryJobInfo<'tcx>>;\n+type QueryMap<'tcx> = FxHashMap<QueryJobId, QueryJobInfo<'tcx>>;\n+\n+/// A value uniquely identifiying an active query job within a shard in the query cache.\n+#[derive(Copy, Clone, Eq, PartialEq, Hash)]\n+pub struct QueryShardJobId(pub NonZeroU32);\n \n /// A value uniquely identifiying an active query job.\n-/// This value is created from a stack pointer in `get_query` and `force_query`\n-/// which is alive while the query executes.\n #[derive(Copy, Clone, Eq, PartialEq, Hash)]\n-pub struct QueryToken(NonZeroUsize);\n+pub struct QueryJobId {\n+    /// Which job within a shard is this\n+    pub job: QueryShardJobId,\n \n-impl QueryToken {\n-    pub fn from<T>(v: &T) -> Self {\n-        QueryToken(NonZeroUsize::new(v as *const T as usize).unwrap())\n-    }\n+    /// In which shard is this job\n+    pub shard: u16,\n+\n+    /// What kind of query this job is\n+    pub kind: DepKind,\n+}\n \n+impl QueryJobId {\n     fn query<'tcx>(self, map: &QueryMap<'tcx>) -> Query<'tcx> {\n         map.get(&self).unwrap().info.query.clone()\n     }\n@@ -54,7 +62,7 @@ impl QueryToken {\n     }\n \n     #[cfg(parallel_compiler)]\n-    fn parent(self, map: &QueryMap<'_>) -> Option<QueryToken> {\n+    fn parent(self, map: &QueryMap<'_>) -> Option<QueryJobId> {\n         map.get(&self).unwrap().job.parent\n     }\n \n@@ -72,13 +80,13 @@ pub struct QueryJobInfo<'tcx> {\n /// Represents an active query job.\n #[derive(Clone)]\n pub struct QueryJob<'tcx> {\n-    pub token: QueryToken,\n+    pub id: QueryShardJobId,\n \n     /// The span corresponding to the reason for which this query was required.\n     pub span: Span,\n \n     /// The parent query job which created this job and is implicitly waiting on it.\n-    pub parent: Option<QueryToken>,\n+    pub parent: Option<QueryJobId>,\n \n     /// The latch that is used to wait on this job.\n     #[cfg(parallel_compiler)]\n@@ -89,9 +97,9 @@ pub struct QueryJob<'tcx> {\n \n impl<'tcx> QueryJob<'tcx> {\n     /// Creates a new query job.\n-    pub fn new(token: QueryToken, span: Span, parent: Option<QueryToken>) -> Self {\n+    pub fn new(id: QueryShardJobId, span: Span, parent: Option<QueryJobId>) -> Self {\n         QueryJob {\n-            token,\n+            id,\n             span,\n             parent,\n             #[cfg(parallel_compiler)]\n@@ -101,16 +109,16 @@ impl<'tcx> QueryJob<'tcx> {\n     }\n \n     #[cfg(parallel_compiler)]\n-    pub(super) fn latch(&mut self) -> QueryLatch<'tcx> {\n+    pub(super) fn latch(&mut self, _id: QueryJobId) -> QueryLatch<'tcx> {\n         if self.latch.is_none() {\n             self.latch = Some(QueryLatch::new());\n         }\n         self.latch.as_ref().unwrap().clone()\n     }\n \n     #[cfg(not(parallel_compiler))]\n-    pub(super) fn latch(&mut self) -> QueryLatch<'tcx> {\n-        QueryLatch { token: self.token, dummy: PhantomData }\n+    pub(super) fn latch(&mut self, id: QueryJobId) -> QueryLatch<'tcx> {\n+        QueryLatch { id, dummy: PhantomData }\n     }\n \n     /// Signals to waiters that the query is complete.\n@@ -126,7 +134,7 @@ impl<'tcx> QueryJob<'tcx> {\n #[cfg(not(parallel_compiler))]\n #[derive(Clone)]\n pub(super) struct QueryLatch<'tcx> {\n-    token: QueryToken,\n+    id: QueryJobId,\n     dummy: PhantomData<&'tcx ()>,\n }\n \n@@ -143,7 +151,7 @@ impl<'tcx> QueryLatch<'tcx> {\n             let info = query_map.get(&job).unwrap();\n             cycle.push(info.info.clone());\n \n-            if job == self.token {\n+            if job == self.id {\n                 cycle.reverse();\n \n                 // This is the end of the cycle\n@@ -169,7 +177,7 @@ impl<'tcx> QueryLatch<'tcx> {\n \n #[cfg(parallel_compiler)]\n struct QueryWaiter<'tcx> {\n-    query: Option<QueryToken>,\n+    query: Option<QueryJobId>,\n     condvar: Condvar,\n     span: Span,\n     cycle: Lock<Option<CycleError<'tcx>>>,\n@@ -270,7 +278,7 @@ impl<'tcx> QueryLatch<'tcx> {\n \n /// A resumable waiter of a query. The usize is the index into waiters in the query's latch\n #[cfg(parallel_compiler)]\n-type Waiter = (QueryToken, usize);\n+type Waiter = (QueryJobId, usize);\n \n /// Visits all the non-resumable and resumable waiters of a query.\n /// Only waiters in a query are visited.\n@@ -284,11 +292,11 @@ type Waiter = (QueryToken, usize);\n #[cfg(parallel_compiler)]\n fn visit_waiters<'tcx, F>(\n     query_map: &QueryMap<'tcx>,\n-    query: QueryToken,\n+    query: QueryJobId,\n     mut visit: F,\n ) -> Option<Option<Waiter>>\n where\n-    F: FnMut(Span, QueryToken) -> Option<Option<Waiter>>,\n+    F: FnMut(Span, QueryJobId) -> Option<Option<Waiter>>,\n {\n     // Visit the parent query which is a non-resumable waiter since it's on the same stack\n     if let Some(parent) = query.parent(query_map) {\n@@ -319,10 +327,10 @@ where\n #[cfg(parallel_compiler)]\n fn cycle_check<'tcx>(\n     query_map: &QueryMap<'tcx>,\n-    query: QueryToken,\n+    query: QueryJobId,\n     span: Span,\n-    stack: &mut Vec<(Span, QueryToken)>,\n-    visited: &mut FxHashSet<QueryToken>,\n+    stack: &mut Vec<(Span, QueryJobId)>,\n+    visited: &mut FxHashSet<QueryJobId>,\n ) -> Option<Option<Waiter>> {\n     if !visited.insert(query) {\n         return if let Some(p) = stack.iter().position(|q| q.1 == query) {\n@@ -360,8 +368,8 @@ fn cycle_check<'tcx>(\n #[cfg(parallel_compiler)]\n fn connected_to_root<'tcx>(\n     query_map: &QueryMap<'tcx>,\n-    query: QueryToken,\n-    visited: &mut FxHashSet<QueryToken>,\n+    query: QueryJobId,\n+    visited: &mut FxHashSet<QueryJobId>,\n ) -> bool {\n     // We already visited this or we're deliberately ignoring it\n     if !visited.insert(query) {\n@@ -381,7 +389,7 @@ fn connected_to_root<'tcx>(\n \n // Deterministically pick an query from a list\n #[cfg(parallel_compiler)]\n-fn pick_query<'a, 'tcx, T, F: Fn(&T) -> (Span, QueryToken)>(\n+fn pick_query<'a, 'tcx, T, F: Fn(&T) -> (Span, QueryJobId)>(\n     query_map: &QueryMap<'tcx>,\n     tcx: TyCtxt<'tcx>,\n     queries: &'a [T],\n@@ -413,7 +421,7 @@ fn pick_query<'a, 'tcx, T, F: Fn(&T) -> (Span, QueryToken)>(\n #[cfg(parallel_compiler)]\n fn remove_cycle<'tcx>(\n     query_map: &QueryMap<'tcx>,\n-    jobs: &mut Vec<QueryToken>,\n+    jobs: &mut Vec<QueryJobId>,\n     wakelist: &mut Vec<Lrc<QueryWaiter<'tcx>>>,\n     tcx: TyCtxt<'tcx>,\n ) -> bool {\n@@ -468,7 +476,7 @@ fn remove_cycle<'tcx>(\n                     }\n                 }\n             })\n-            .collect::<Vec<(Span, QueryToken, Option<(Span, QueryToken)>)>>();\n+            .collect::<Vec<(Span, QueryJobId, Option<(Span, QueryJobId)>)>>();\n \n         // Deterministically pick an entry point\n         let (_, entry_point, usage) = pick_query(query_map, tcx, &entry_points, |e| (e.0, e.1));\n@@ -548,7 +556,7 @@ fn deadlock(tcx: TyCtxt<'_>, registry: &rayon_core::Registry) {\n \n     let mut wakelist = Vec::new();\n     let query_map = tcx.queries.try_collect_active_jobs().unwrap();\n-    let mut jobs: Vec<QueryToken> = query_map.keys().cloned().collect();\n+    let mut jobs: Vec<QueryJobId> = query_map.keys().cloned().collect();\n \n     let mut found_cycle = false;\n "}, {"sha": "ce867134831324f6201c93c35a3d93c47de7e1b8", "filename": "src/librustc/ty/query/mod.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fmod.rs?ref=19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "patch": "@@ -54,6 +54,7 @@ use rustc_span::symbol::Symbol;\n use rustc_span::{Span, DUMMY_SP};\n use std::any::type_name;\n use std::borrow::Cow;\n+use std::convert::TryFrom;\n use std::ops::Deref;\n use std::sync::Arc;\n use syntax::ast;\n@@ -67,7 +68,7 @@ mod job;\n #[cfg(parallel_compiler)]\n pub use self::job::handle_deadlock;\n use self::job::QueryJobInfo;\n-pub use self::job::{QueryInfo, QueryJob, QueryToken};\n+pub use self::job::{QueryInfo, QueryJob, QueryJobId};\n \n mod keys;\n use self::keys::Key;"}, {"sha": "4fa82156c40c11a80cc32de66189a63371cc34a0", "filename": "src/librustc/ty/query/plumbing.rs", "status": "modified", "additions": 63, "deletions": 40, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fquery%2Fplumbing.rs?ref=19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "patch": "@@ -4,7 +4,7 @@\n \n use crate::dep_graph::{DepKind, DepNode, DepNodeIndex, SerializedDepNodeIndex};\n use crate::ty::query::config::{QueryConfig, QueryDescription};\n-use crate::ty::query::job::{QueryInfo, QueryJob, QueryToken};\n+use crate::ty::query::job::{QueryInfo, QueryJob, QueryJobId, QueryShardJobId};\n use crate::ty::query::Query;\n use crate::ty::tls;\n use crate::ty::{self, TyCtxt};\n@@ -21,13 +21,19 @@ use rustc_errors::{struct_span_err, Diagnostic, DiagnosticBuilder, FatalError, H\n use rustc_span::source_map::DUMMY_SP;\n use rustc_span::Span;\n use std::collections::hash_map::Entry;\n+use std::convert::TryFrom;\n use std::hash::{Hash, Hasher};\n use std::mem;\n+use std::num::NonZeroU32;\n use std::ptr;\n \n pub struct QueryCache<'tcx, D: QueryConfig<'tcx> + ?Sized> {\n     pub(super) results: FxHashMap<D::Key, QueryValue<D::Value>>,\n     pub(super) active: FxHashMap<D::Key, QueryResult<'tcx>>,\n+\n+    /// Used to generate unique ids for active jobs.\n+    pub(super) jobs: u32,\n+\n     #[cfg(debug_assertions)]\n     pub(super) cache_hits: usize,\n }\n@@ -58,6 +64,7 @@ impl<'tcx, M: QueryConfig<'tcx>> Default for QueryCache<'tcx, M> {\n         QueryCache {\n             results: FxHashMap::default(),\n             active: FxHashMap::default(),\n+            jobs: 0,\n             #[cfg(debug_assertions)]\n             cache_hits: 0,\n         }\n@@ -69,7 +76,7 @@ impl<'tcx, M: QueryConfig<'tcx>> Default for QueryCache<'tcx, M> {\n pub(super) struct JobOwner<'a, 'tcx, Q: QueryDescription<'tcx>> {\n     cache: &'a Sharded<QueryCache<'tcx, Q>>,\n     key: Q::Key,\n-    token: QueryToken,\n+    id: QueryJobId,\n }\n \n impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n@@ -81,12 +88,7 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n     /// This function is inlined because that results in a noticeable speed-up\n     /// for some compile-time benchmarks.\n     #[inline(always)]\n-    pub(super) fn try_get(\n-        tcx: TyCtxt<'tcx>,\n-        span: Span,\n-        key: &Q::Key,\n-        token: QueryToken,\n-    ) -> TryGetJob<'a, 'tcx, Q> {\n+    pub(super) fn try_get(tcx: TyCtxt<'tcx>, span: Span, key: &Q::Key) -> TryGetJob<'a, 'tcx, Q> {\n         // Handling the `query_blocked_prof_timer` is a bit weird because of the\n         // control flow in this function: Blocking is implemented by\n         // awaiting a running job and, once that is done, entering the loop below\n@@ -109,7 +111,10 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n             key.hash(&mut state);\n             let key_hash = state.finish();\n \n-            let mut lock = cache.get_shard_by_hash(key_hash).lock();\n+            let shard = cache.get_shard_index_by_hash(key_hash);\n+            let mut lock = cache.get_shard_by_index(shard).lock();\n+            let lock = &mut *lock;\n+\n             if let Some((_, value)) =\n                 lock.results.raw_entry().from_key_hashed_nocheck(key_hash, key)\n             {\n@@ -144,16 +149,35 @@ impl<'a, 'tcx, Q: QueryDescription<'tcx>> JobOwner<'a, 'tcx, Q> {\n                                 query_blocked_prof_timer = Some(tcx.prof.query_blocked());\n                             }\n \n-                            job.latch()\n+                            // Create the id of the job we're waiting for\n+                            let id = QueryJobId {\n+                                job: job.id,\n+                                shard: u16::try_from(shard).unwrap(),\n+                                kind: Q::dep_kind(),\n+                            };\n+\n+                            job.latch(id)\n                         }\n                         QueryResult::Poisoned => FatalError.raise(),\n                     }\n                 }\n                 Entry::Vacant(entry) => {\n+                    let jobs = &mut lock.jobs;\n+\n                     // No job entry for this query. Return a new one to be started later.\n                     return tls::with_related_context(tcx, |icx| {\n-                        let job = QueryJob::new(token, span, icx.query);\n-                        let owner = JobOwner { cache, token, key: (*key).clone() };\n+                        // Generate an id unique within this shard.\n+                        let id = jobs.checked_add(1).unwrap();\n+                        *jobs = id;\n+                        let id = QueryShardJobId(NonZeroU32::new(id).unwrap());\n+\n+                        let global_id = QueryJobId {\n+                            job: id,\n+                            shard: u16::try_from(shard).unwrap(),\n+                            kind: Q::dep_kind(),\n+                        };\n+                        let job = QueryJob::new(id, span, icx.query);\n+                        let owner = JobOwner { cache, id: global_id, key: (*key).clone() };\n                         entry.insert(QueryResult::Started(job));\n                         TryGetJob::NotYetStarted(owner)\n                     });\n@@ -266,7 +290,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     #[inline(always)]\n     pub(super) fn start_query<F, R>(\n         self,\n-        token: QueryToken,\n+        token: QueryJobId,\n         diagnostics: Option<&Lock<ThinVec<Diagnostic>>>,\n         compute: F,\n     ) -> R\n@@ -384,12 +408,7 @@ impl<'tcx> TyCtxt<'tcx> {\n     pub(super) fn get_query<Q: QueryDescription<'tcx>>(self, span: Span, key: Q::Key) -> Q::Value {\n         debug!(\"ty::query::get_query<{}>(key={:?}, span={:?})\", Q::NAME, key, span);\n \n-        // Create a token which uniquely identifies this query amongst the executing queries\n-        // by using a pointer to `key`. `key` is alive until the query completes execution\n-        // which will prevent reuse of the token value.\n-        let token = QueryToken::from(&key);\n-\n-        let job = match JobOwner::try_get(self, span, &key, token) {\n+        let job = match JobOwner::try_get(self, span, &key) {\n             TryGetJob::NotYetStarted(job) => job,\n             TryGetJob::Cycle(result) => return result,\n             TryGetJob::JobCompleted((v, index)) => {\n@@ -409,7 +428,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             let prof_timer = self.prof.query_provider();\n \n             let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-                self.start_query(job.token, diagnostics, |tcx| {\n+                self.start_query(job.id, diagnostics, |tcx| {\n                     tcx.dep_graph.with_anon_task(Q::dep_kind(), || Q::compute(tcx, key))\n                 })\n             });\n@@ -435,7 +454,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             // The diagnostics for this query will be\n             // promoted to the current session during\n             // `try_mark_green()`, so we can ignore them here.\n-            let loaded = self.start_query(job.token, None, |tcx| {\n+            let loaded = self.start_query(job.id, None, |tcx| {\n                 let marked = tcx.dep_graph.try_mark_green_and_read(tcx, &dep_node);\n                 marked.map(|(prev_dep_node_index, dep_node_index)| {\n                     (\n@@ -569,7 +588,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         let prof_timer = self.prof.query_provider();\n \n         let ((result, dep_node_index), diagnostics) = with_diagnostics(|diagnostics| {\n-            self.start_query(job.token, diagnostics, |tcx| {\n+            self.start_query(job.id, diagnostics, |tcx| {\n                 if Q::EVAL_ALWAYS {\n                     tcx.dep_graph.with_eval_always_task(\n                         dep_node,\n@@ -633,14 +652,9 @@ impl<'tcx> TyCtxt<'tcx> {\n \n     #[allow(dead_code)]\n     fn force_query<Q: QueryDescription<'tcx>>(self, key: Q::Key, span: Span, dep_node: DepNode) {\n-        // Create a token which uniquely identifies this query amongst the executing queries\n-        // by using a pointer to `key`. `key` is alive until the query completes execution\n-        // which will prevent reuse of the token value.\n-        let token = QueryToken::from(&key);\n-\n         // We may be concurrently trying both execute and force a query.\n         // Ensure that only one of them runs the query.\n-        let job = match JobOwner::try_get(self, span, &key, token) {\n+        let job = match JobOwner::try_get(self, span, &key) {\n             TryGetJob::NotYetStarted(job) => job,\n             TryGetJob::Cycle(_) | TryGetJob::JobCompleted(_) => return,\n         };\n@@ -748,24 +762,33 @@ macro_rules! define_queries_inner {\n \n             pub fn try_collect_active_jobs(\n                 &self\n-            ) -> Option<FxHashMap<QueryToken, QueryJobInfo<'tcx>>> {\n+            ) -> Option<FxHashMap<QueryJobId, QueryJobInfo<'tcx>>> {\n                 let mut jobs = FxHashMap::default();\n \n                 $(\n                     // We use try_lock_shards here since we are called from the\n                     // deadlock handler, and this shouldn't be locked.\n                     let shards = self.$name.try_lock_shards()?;\n-                    jobs.extend(shards.iter().flat_map(|shard| shard.active.iter().filter_map(|(k, v)|\n-                        if let QueryResult::Started(ref job) = *v {\n-                            let info = QueryInfo {\n-                                span: job.span,\n-                                query: queries::$name::query(k.clone())\n-                            };\n-                            Some((job.token, QueryJobInfo { info,  job: job.clone() }))\n-                        } else {\n-                            None\n-                        }\n-                    )));\n+                    let shards = shards.iter().enumerate();\n+                    jobs.extend(shards.flat_map(|(shard_id, shard)| {\n+                        shard.active.iter().filter_map(move |(k, v)| {\n+                            if let QueryResult::Started(ref job) = *v {\n+                                let id = QueryJobId {\n+                                    job: job.id,\n+                                    shard:  u16::try_from(shard_id).unwrap(),\n+                                    kind:\n+                                        <queries::$name<'tcx> as QueryAccessors<'tcx>>::dep_kind(),\n+                                };\n+                                let info = QueryInfo {\n+                                    span: job.span,\n+                                    query: queries::$name::query(k.clone())\n+                                };\n+                                Some((id, QueryJobInfo { info,  job: job.clone() }))\n+                            } else {\n+                                None\n+                            }\n+                        })\n+                    }));\n                 )*\n \n                 Some(jobs)"}, {"sha": "15d1e2dd0b644c08086e60a9c8b82586fda0589d", "filename": "src/librustc_data_structures/sharded.rs", "status": "modified", "additions": 11, "deletions": 2, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc_data_structures%2Fsharded.rs", "raw_url": "https://github.com/rust-lang/rust/raw/19c1012483fe8fb3c793a6ba83f97d896c6a6c98/src%2Flibrustc_data_structures%2Fsharded.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_data_structures%2Fsharded.rs?ref=19c1012483fe8fb3c793a6ba83f97d896c6a6c98", "patch": "@@ -69,12 +69,21 @@ impl<T> Sharded<T> {\n     /// `hash` can be computed with any hasher, so long as that hasher is used\n     /// consistently for each `Sharded` instance.\n     #[inline]\n-    pub fn get_shard_by_hash(&self, hash: u64) -> &Lock<T> {\n+    pub fn get_shard_index_by_hash(&self, hash: u64) -> usize {\n         let hash_len = mem::size_of::<usize>();\n         // Ignore the top 7 bits as hashbrown uses these and get the next SHARD_BITS highest bits.\n         // hashbrown also uses the lowest bits, so we can't use those\n         let bits = (hash >> (hash_len * 8 - 7 - SHARD_BITS)) as usize;\n-        let i = bits % SHARDS;\n+        bits % SHARDS\n+    }\n+\n+    #[inline]\n+    pub fn get_shard_by_hash(&self, hash: u64) -> &Lock<T> {\n+        &self.shards[self.get_shard_index_by_hash(hash)].0\n+    }\n+\n+    #[inline]\n+    pub fn get_shard_by_index(&self, i: usize) -> &Lock<T> {\n         &self.shards[i].0\n     }\n "}]}