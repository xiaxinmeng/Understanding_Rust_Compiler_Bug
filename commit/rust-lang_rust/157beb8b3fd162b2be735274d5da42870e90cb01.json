{"sha": "157beb8b3fd162b2be735274d5da42870e90cb01", "node_id": "MDY6Q29tbWl0NzI0NzEyOjE1N2JlYjhiM2ZkMTYyYjJiZTczNTI3NGQ1ZGE0Mjg3MGU5MGNiMDE=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2019-11-18T12:09:24Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-11-18T12:09:24Z"}, "message": "Merge #2300\n\n2300: Token-based reverse-mapping r=matklad a=matklad\n\n\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "3985535b59ac5061f3c6fb7ce9c109b454dc2c1e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3985535b59ac5061f3c6fb7ce9c109b454dc2c1e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/157beb8b3fd162b2be735274d5da42870e90cb01", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJd0on0CRBK7hj4Ov3rIwAAdHIIAF5bk2xJc0KBtC+EHYzUtblG\nuSE/NxPq2VkrOqQFAkHzkgsScGSU10io/khH8ZT8PoTDQNcLHw9aHli/kzAnnUB1\n/nkmvtk7k7Ly8NHqO1uOl56vmoMeAkThW7eBkUtbCZeUr6DeZowPpFyV3l1Z6LYu\nrtYBB/zXSA6BWr0yxDgaHvc5GQ2f7PN9bzC41xiqjkZgSyDvjs7J9u6z8bmjuj9W\nUCaT3IwisQ0ElnjRouUZ+cLx/wFoiwDMFJQ4BzKYtmjtaPZUwlmw7beCRKTc1z0L\nZpnKYK7L/1Y3258/ZnvpeuuJX/n7/zMA09XKDsvEq1wiy2zy9YeJHSt/01KhQ/0=\n=h5se\n-----END PGP SIGNATURE-----\n", "payload": "tree 3985535b59ac5061f3c6fb7ce9c109b454dc2c1e\nparent 32e72ecd66fede0b39e8f34ca3e1b92128e1d91a\nparent b79d6789236bb53c5818949cc2960b5c4991cbeb\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1574078964 +0000\ncommitter GitHub <noreply@github.com> 1574078964 +0000\n\nMerge #2300\n\n2300: Token-based reverse-mapping r=matklad a=matklad\n\n\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/157beb8b3fd162b2be735274d5da42870e90cb01", "html_url": "https://github.com/rust-lang/rust/commit/157beb8b3fd162b2be735274d5da42870e90cb01", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/157beb8b3fd162b2be735274d5da42870e90cb01/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "32e72ecd66fede0b39e8f34ca3e1b92128e1d91a", "url": "https://api.github.com/repos/rust-lang/rust/commits/32e72ecd66fede0b39e8f34ca3e1b92128e1d91a", "html_url": "https://github.com/rust-lang/rust/commit/32e72ecd66fede0b39e8f34ca3e1b92128e1d91a"}, {"sha": "b79d6789236bb53c5818949cc2960b5c4991cbeb", "url": "https://api.github.com/repos/rust-lang/rust/commits/b79d6789236bb53c5818949cc2960b5c4991cbeb", "html_url": "https://github.com/rust-lang/rust/commit/b79d6789236bb53c5818949cc2960b5c4991cbeb"}], "stats": {"total": 90, "additions": 52, "deletions": 38}, "files": [{"sha": "73ec1688ccb5ac869e6f72a86ca3f5acc3a76394", "filename": "crates/ra_hir_expand/src/lib.rs", "status": "modified", "additions": 22, "deletions": 29, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_hir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir_expand%2Fsrc%2Flib.rs?ref=157beb8b3fd162b2be735274d5da42870e90cb01", "patch": "@@ -20,7 +20,7 @@ use ra_db::{salsa, CrateId, FileId};\n use ra_syntax::{\n     algo,\n     ast::{self, AstNode},\n-    SyntaxNode, SyntaxToken, TextRange, TextUnit,\n+    SyntaxNode, SyntaxToken, TextUnit,\n };\n \n use crate::ast_id_map::FileAstId;\n@@ -79,22 +79,17 @@ impl HirFileId {\n             HirFileIdRepr::MacroFile(macro_file) => {\n                 let loc: MacroCallLoc = db.lookup_intern_macro(macro_file.macro_call_id);\n \n-                let arg_start = loc.ast_id.to_node(db).token_tree()?.syntax().text_range().start();\n-                let def_start =\n-                    loc.def.ast_id.to_node(db).token_tree()?.syntax().text_range().start();\n+                let arg_tt = loc.ast_id.to_node(db).token_tree()?;\n+                let def_tt = loc.def.ast_id.to_node(db).token_tree()?;\n \n                 let macro_def = db.macro_def(loc.def)?;\n                 let (parse, exp_map) = db.parse_macro(macro_file)?;\n-                let expanded = Source::new(self, parse.syntax_node());\n                 let macro_arg = db.macro_arg(macro_file.macro_call_id)?;\n \n-                let arg_start = (loc.ast_id.file_id, arg_start);\n-                let def_start = (loc.def.ast_id.file_id, def_start);\n-\n                 Some(ExpansionInfo {\n-                    expanded,\n-                    arg_start,\n-                    def_start,\n+                    expanded: Source::new(self, parse.syntax_node()),\n+                    arg: Source::new(loc.ast_id.file_id, arg_tt),\n+                    def: Source::new(loc.ast_id.file_id, def_tt),\n                     macro_arg,\n                     macro_def,\n                     exp_map,\n@@ -159,8 +154,8 @@ impl MacroCallId {\n #[derive(Debug, Clone, PartialEq, Eq)]\n pub struct ExpansionInfo {\n     expanded: Source<SyntaxNode>,\n-    arg_start: (HirFileId, TextUnit),\n-    def_start: (HirFileId, TextUnit),\n+    arg: Source<ast::TokenTree>,\n+    def: Source<ast::TokenTree>,\n \n     macro_def: Arc<(db::TokenExpander, mbe::TokenMap)>,\n     macro_arg: Arc<(tt::Subtree, mbe::TokenMap)>,\n@@ -169,8 +164,9 @@ pub struct ExpansionInfo {\n \n impl ExpansionInfo {\n     pub fn map_token_down(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>> {\n-        assert_eq!(token.file_id, self.arg_start.0);\n-        let range = token.ast.text_range().checked_sub(self.arg_start.1)?;\n+        assert_eq!(token.file_id, self.arg.file_id);\n+        let range =\n+            token.ast.text_range().checked_sub(self.arg.ast.syntax().text_range().start())?;\n         let token_id = self.macro_arg.1.token_by_range(range)?;\n         let token_id = self.macro_def.0.map_id_down(token_id);\n \n@@ -181,25 +177,22 @@ impl ExpansionInfo {\n         Some(self.expanded.with_ast(token))\n     }\n \n-    // FIXME: a more correct signature would be\n-    // `pub fn map_token_up(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>>`\n-    pub fn find_range(&self, from: TextRange) -> Option<(HirFileId, TextRange)> {\n-        let token_id = look_in_rev_map(&self.exp_map, from)?;\n+    pub fn map_token_up(&self, token: Source<&SyntaxToken>) -> Option<Source<SyntaxToken>> {\n+        let token_id = self.exp_map.token_by_range(token.ast.text_range())?;\n \n         let (token_id, origin) = self.macro_def.0.map_id_up(token_id);\n-\n-        let (token_map, (file_id, start_offset)) = match origin {\n-            mbe::Origin::Call => (&self.macro_arg.1, self.arg_start),\n-            mbe::Origin::Def => (&self.macro_def.1, self.def_start),\n+        let (token_map, tt) = match origin {\n+            mbe::Origin::Call => (&self.macro_arg.1, &self.arg),\n+            mbe::Origin::Def => (&self.macro_def.1, &self.def),\n         };\n \n         let range = token_map.relative_range_of(token_id)?;\n-\n-        return Some((file_id, range + start_offset));\n-\n-        fn look_in_rev_map(exp_map: &mbe::RevTokenMap, from: TextRange) -> Option<tt::TokenId> {\n-            exp_map.ranges.iter().find(|&it| it.0.is_subrange(&from)).map(|it| it.1)\n-        }\n+        let token = algo::find_covering_element(\n+            tt.ast.syntax(),\n+            range + tt.ast.syntax().text_range().start(),\n+        )\n+        .into_token()?;\n+        Some(tt.with_ast(token))\n     }\n }\n "}, {"sha": "7f59e46d26bd390de6931f43646f5e0a0fb2566b", "filename": "crates/ra_ide_api/src/expand.rs", "status": "modified", "additions": 25, "deletions": 8, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fexpand.rs?ref=157beb8b3fd162b2be735274d5da42870e90cb01", "patch": "@@ -8,15 +8,32 @@ use ra_syntax::{ast, AstNode, SyntaxNode, SyntaxToken};\n use crate::{db::RootDatabase, FileRange};\n \n pub(crate) fn original_range(db: &RootDatabase, node: Source<&SyntaxNode>) -> FileRange {\n-    let text_range = node.ast.text_range();\n-    let (file_id, range) = node\n-        .file_id\n-        .expansion_info(db)\n-        .and_then(|expansion_info| expansion_info.find_range(text_range))\n-        .unwrap_or((node.file_id, text_range));\n+    let expansion = match node.file_id.expansion_info(db) {\n+        None => {\n+            return FileRange {\n+                file_id: node.file_id.original_file(db),\n+                range: node.ast.text_range(),\n+            }\n+        }\n+        Some(it) => it,\n+    };\n+    // FIXME: the following completely wrong.\n+    //\n+    // *First*, we should try to map first and last tokens of node, and, if that\n+    // fails, return the range of the overall macro expansions.\n+    //\n+    // *Second*, we should handle recurside macro expansions\n+\n+    let token = node\n+        .ast\n+        .descendants_with_tokens()\n+        .filter_map(|it| it.into_token())\n+        .find_map(|it| expansion.map_token_up(node.with_ast(&it)));\n \n-    // FIXME: handle recursive macro generated macro\n-    FileRange { file_id: file_id.original_file(db), range }\n+    match token {\n+        Some(it) => FileRange { file_id: it.file_id.original_file(db), range: it.ast.text_range() },\n+        None => FileRange { file_id: node.file_id.original_file(db), range: node.ast.text_range() },\n+    }\n }\n \n pub(crate) fn descend_into_macros("}, {"sha": "fe3b70b8da3678553c80c0b66498bf912dad33fe", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 5, "deletions": 1, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/157beb8b3fd162b2be735274d5da42870e90cb01/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=157beb8b3fd162b2be735274d5da42870e90cb01", "patch": "@@ -20,7 +20,7 @@ pub struct TokenMap {\n /// Maps relative range of the expanded syntax node to `tt::TokenId`\n #[derive(Debug, PartialEq, Eq, Default)]\n pub struct RevTokenMap {\n-    pub ranges: Vec<(TextRange, tt::TokenId)>,\n+    ranges: Vec<(TextRange, tt::TokenId)>,\n }\n \n /// Convert the syntax tree (what user has written) to a `TokenTree` (what macro\n@@ -96,6 +96,10 @@ impl TokenMap {\n }\n \n impl RevTokenMap {\n+    pub fn token_by_range(&self, relative_range: TextRange) -> Option<tt::TokenId> {\n+        self.ranges.iter().find(|&it| it.0 == relative_range).map(|it| it.1)\n+    }\n+\n     pub fn range_by_token(&self, token_id: tt::TokenId) -> Option<TextRange> {\n         let &(r, _) = self.ranges.iter().find(|(_, tid)| *tid == token_id)?;\n         Some(r)"}]}