{"sha": "328737216147b6107d6d28a405e3fd9cd1ded317", "node_id": "MDY6Q29tbWl0NzI0NzEyOjMyODczNzIxNjE0N2I2MTA3ZDZkMjhhNDA1ZTNmZDljZDFkZWQzMTc=", "commit": {"author": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-06-24T17:59:30Z"}, "committer": {"name": "Alexis Beingessner", "email": "a.beingessner@gmail.com", "date": "2015-06-24T17:59:45Z"}, "message": "so much Vec", "tree": {"sha": "0b83f09829e118cb2f6a52c5be101c63c891552c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0b83f09829e118cb2f6a52c5be101c63c891552c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/328737216147b6107d6d28a405e3fd9cd1ded317", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/328737216147b6107d6d28a405e3fd9cd1ded317", "html_url": "https://github.com/rust-lang/rust/commit/328737216147b6107d6d28a405e3fd9cd1ded317", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/328737216147b6107d6d28a405e3fd9cd1ded317/comments", "author": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Gankra", "id": 1136864, "node_id": "MDQ6VXNlcjExMzY4NjQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1136864?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Gankra", "html_url": "https://github.com/Gankra", "followers_url": "https://api.github.com/users/Gankra/followers", "following_url": "https://api.github.com/users/Gankra/following{/other_user}", "gists_url": "https://api.github.com/users/Gankra/gists{/gist_id}", "starred_url": "https://api.github.com/users/Gankra/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Gankra/subscriptions", "organizations_url": "https://api.github.com/users/Gankra/orgs", "repos_url": "https://api.github.com/users/Gankra/repos", "events_url": "https://api.github.com/users/Gankra/events{/privacy}", "received_events_url": "https://api.github.com/users/Gankra/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "75621b80a8c11d65a3cb071a9d602c30936b8d79", "url": "https://api.github.com/repos/rust-lang/rust/commits/75621b80a8c11d65a3cb071a9d602c30936b8d79", "html_url": "https://github.com/rust-lang/rust/commit/75621b80a8c11d65a3cb071a9d602c30936b8d79"}], "stats": {"total": 709, "additions": 688, "deletions": 21}, "files": [{"sha": "d38265b429e4be236d624f33541929918993f445", "filename": "vec.md", "status": "modified", "additions": 688, "deletions": 21, "changes": 709, "blob_url": "https://github.com/rust-lang/rust/blob/328737216147b6107d6d28a405e3fd9cd1ded317/vec.md", "raw_url": "https://github.com/rust-lang/rust/raw/328737216147b6107d6d28a405e3fd9cd1ded317/vec.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/vec.md?ref=328737216147b6107d6d28a405e3fd9cd1ded317", "patch": "@@ -1,17 +1,21 @@\n % Example: Implementing Vec\n \n+TODO: audit for non-ZST offsets from heap::empty\n+\n To bring everything together, we're going to write `std::Vec` from scratch.\n Because the all the best tools for writing unsafe code are unstable, this\n project will only work on nightly (as of Rust 1.2.0).\n \n+# Layout\n+\n First off, we need to come up with the struct layout. Naively we want this\n design:\n \n ```\n struct Vec<T> {\n-\tptr: *mut T,\n-\tcap: usize,\n-\tlen: usize,\n+    ptr: *mut T,\n+    cap: usize,\n+    len: usize,\n }\n ```\n \n@@ -29,7 +33,7 @@ when we have a raw pointer to an allocation we own:\n ```\n #![feature(unique)]\n \n-use std::ptr::Unique;\n+use std::ptr::{Unique, self};\n \n pub struct Vec<T> {\n     ptr: Unique<T>,\n@@ -63,6 +67,8 @@ All of the `heap` API is totally unstable under the `alloc` feature, though.\n We could trivially define `heap::EMPTY` ourselves, but we'll want the rest of\n the `heap` API anyway, so let's just get that dependency over with.\n \n+# Allocating Memory\n+\n So:\n \n ```rust\n@@ -72,14 +78,14 @@ use std::rt::heap::EMPTY;\n use std::mem;\n \n impl<T> Vec<T> {\n-\tfn new() -> Self {\n-\t\tassert!(mem::size_of::<T>() != 0, \"We're not ready to handle ZSTs\");\n-\t\tunsafe {\n-\t\t\t// need to cast EMPTY to the actual ptr type we want, let\n-\t\t\t// inference handle it.\n-\t\t\tVec { ptr: Unique::new(heap::EMPTY as *mut _), len: 0, cap: 0 }\n-\t\t}\n-\t}\n+    fn new() -> Self {\n+        assert!(mem::size_of::<T>() != 0, \"We're not ready to handle ZSTs\");\n+        unsafe {\n+            // need to cast EMPTY to the actual ptr type we want, let\n+            // inference handle it.\n+            Vec { ptr: Unique::new(heap::EMPTY as *mut _), len: 0, cap: 0 }\n+        }\n+    }\n }\n ```\n \n@@ -103,10 +109,38 @@ fn oom() {\n }\n ```\n \n-Okay, now we can write growing:\n+Okay, now we can write growing. Roughly, we want to have this logic:\n+\n+```text\n+if cap == 0:\n+    allocate()\n+    cap = 1\n+else\n+    reallocate\n+    cap *= 2\n+```\n+\n+But Rust's only supported allocator API is so low level that we'll need to\n+do a fair bit of extra work, though. We also need to guard against some special\n+conditions that can occur with really large allocations. In particular, we index\n+into arrays using unsigned integers, but `ptr::offset` takes signed integers. This\n+means Bad Things will happen if we ever manage to grow to contain more than\n+`isize::MAX` elements. Thankfully, this isn't something we need to worry about\n+in most cases.\n+\n+On 64-bit targets we're artifically limited to only 48-bits, so we'll run out\n+of memory far before we reach that point. However on 32-bit targets, particularly\n+those with extensions to use more of the address space, it's theoretically possible\n+to successfully allocate more than `isize::MAX` bytes of memory. Still, we only\n+really need to worry about that if we're allocating elements that are a byte large.\n+Anything else will use up too much space.\n+\n+However since this is a tutorial, we're not going to be particularly optimal here,\n+and just unconditionally check, rather than use clever platform-specific `cfg`s.\n \n ```rust\n fn grow(&mut self) {\n+    // this is all pretty delicate, so let's say it's all unsafe\n     unsafe {\n         let align = mem::min_align_of::<T>();\n         let elem_size = mem::size_of::<T>();\n@@ -115,27 +149,660 @@ fn grow(&mut self) {\n             let ptr = heap::allocate(elem_size, align);\n             (1, ptr)\n         } else {\n-            let new_cap = 2 * self.cap;\n+            // as an invariant, we can assume that `self.cap < isize::MAX`,\n+            // so this doesn't need to be checked.\n+            let new_cap = self.cap * 2;\n+            // Similarly this can't overflow due to previously allocating this\n+            let old_num_bytes = self.cap * elem_size;\n+\n+            // check that the new allocation doesn't exceed `isize::MAX` at all\n+            // regardless of the actual size of the capacity. This combines the\n+            // `new_cap <= isize::MAX` and `new_num_bytes <= usize::MAX` checks\n+            // we need to make. We lose the ability to allocate e.g. 2/3rds of\n+            // the address space with a single Vec of i16's on 32-bit though.\n+            // Alas, poor Yorick -- I knew him, Horatio.\n+            assert!(old_num_bytes <= (::std::isize::MAX as usize) / 2,\n+                    \"capacity overflow\");\n+\n+            let new_num_bytes = old_num_bytes * 2;\n             let ptr = heap::reallocate(*self.ptr as *mut _,\n-                                        self.cap * elem_size,\n-                                        new_cap * elem_size,\n+                                        old_num_bytes,\n+                                        new_num_bytes,\n                                         align);\n             (new_cap, ptr)\n         };\n \n         // If allocate or reallocate fail, we'll get `null` back\n-        if ptr.is_null() { oom() }\n+        if ptr.is_null() { oom(); }\n \n         self.ptr = Unique::new(ptr as *mut _);\n         self.cap = new_cap;\n     }\n }\n ```\n \n-There's nothing particularly tricky in here: if we're totally empty, we need\n-to do a fresh allocation. Otherwise, we need to reallocate the current pointer.\n-Although we have a subtle bug here with the multiply overflow.\n+Nothing particularly tricky here. Just computing sizes and alignments and doing\n+some careful multiplication checks.\n+\n+# Push and Pop\n+\n+Alright. We can initialize. We can allocate. Let's actually implement some\n+functionality! Let's start with `push`. All it needs to do is check if we're\n+full to grow, unconditionally write to the next index, and then increment our\n+length.\n+\n+To do the write we have to be careful not to evaluate the memory we want to write\n+to. At worst, it's truly uninitialized memory from the allocator. At best it's the\n+bits of some old value we popped off. Either way, we can't just index to the memory\n+and dereference it, because that will evaluate the memory as a valid instance of\n+T. Worse, `foo[idx] = x` will try to call `drop` on the old value of `foo[idx]`!\n+\n+The correct way to do this is with `ptr::write`, which just blindly overwrites the\n+target address with the bits of the value we provide. No evaluation involved.\n+\n+For `push`, if the old len (before push was called) is 0, then we want to write\n+to the 0th index. So we should offset by the old len.\n+\n+```rust\n+pub fn push(&mut self, elem: T) {\n+    if self.len == self.cap { self.grow(); }\n+\n+    unsafe {\n+        ptr::write(self.ptr.offset(self.len as isize), elem);\n+    }\n+\n+    // Can't fail, we'll OOM first.\n+    self.len += 1;\n+}\n+```\n+\n+Easy! How about `pop`? Although this time the index we want to access is\n+initialized, Rust won't just let us dereference the location of memory to move\n+the value out, because that *would* leave the memory uninitialized! For this we\n+need `ptr::read`, which just copies out the bits from the target address and\n+intrprets it as a value of type T. This will leave the memory at this address\n+*logically* uninitialized, even though there is in fact a perfectly good instance\n+of T there.\n+\n+For `pop`, if the old len is 1, we want to read out of the 0th index. So we\n+should offset by the *new* len.\n+\n+```rust\n+pub fn pop(&mut self) -> Option<T> {\n+    if self.len == 0 {\n+        None\n+    } else {\n+        self.len -= 1;\n+        unsafe {\n+            Some(ptr::read(self.ptr.offset(self.len as isize)))\n+        }\n+    }\n+}\n+```\n+\n+# Deallocating\n+\n+Next we should implement Drop so that we don't massively leaks tons of resources.\n+The easiest way is to just call `pop` until it yields None, and then deallocate\n+our buffer. Note that calling `pop` is uneeded if `T: !Drop`. In theory we can\n+ask Rust if T needs_drop and omit the calls to `pop`. However in practice LLVM\n+is *really* good at removing simple side-effect free code like this, so I wouldn't\n+bother unless you notice it's not being stripped (in this case it is).\n+\n+We must not call `heap::deallocate` when `self.cap == 0`, as in this case we haven't\n+actually allocated any memory.\n+\n+\n+```rust\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            while let Some(_) = self.pop() { }\n+\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+# Deref\n+\n+Alright! We've got a decent minimal ArrayStack implemented. We can push, we can\n+pop, and we can clean up after ourselves. However there's a whole mess of functionality\n+we'd reasonably want. In particular, we have a proper array, but none of the slice\n+functionality. That's actually pretty easy to solve: we can implement `Deref<Target=[T]>`.\n+This will magically make our Vec coerce to and behave like a slice in all sorts of\n+conditions.\n+\n+All we need is `slice::from_raw_parts`.\n+\n+```rust\n+use std::ops::Deref;\n+\n+impl<T> Deref for Vec<T> {\n+    type Target = [T];\n+    fn deref(&self) -> &[T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts(*self.ptr, self.len)\n+        }\n+    }\n+}\n+```\n+\n+And let's do DerefMut too:\n+\n+```rust\n+use std::ops::DerefMut;\n+\n+impl<T> DerefMut for Vec<T> {\n+    fn deref_mut(&mut self) -> &mut [T] {\n+        unsafe {\n+            ::std::slice::from_raw_parts_mut(*self.ptr, self.len)\n+        }\n+    }\n+}\n+```\n+\n+Now we have `len`, `first`, `last`, indexing, slicing, sorting, `iter`, `iter_mut`,\n+and all other sorts of bells and whistles provided by slice. Sweet!\n+\n+# Insert and Remove\n+\n+Something *not* provided but slice is `insert` and `remove`, so let's do those next.\n+\n+Insert needs to shift all the elements at the target index to the right by one.\n+To do this we need to use `ptr::copy`, which is our version of C's `memmove`.\n+This copies some chunk of memory from one location to another, correctly handling\n+the case where the source and destination overlap (which will definitely happen\n+here).\n+\n+If we insert at index `i`, we want to shift the `[i .. len]` to `[i+1 .. len+1]`\n+using the *old* len.\n+\n+```rust\n+pub fn insert(&mut self, index: usize, elem: T) {\n+    // Note: `<=` because it's valid to insert after everything\n+    // which would be equivalent to push.\n+    assert!(index <= self.len, \"index out of bounds\");\n+    if self.cap == self.len { self.grow(); }\n+\n+    unsafe {\n+        if index < self.len {\n+            // ptr::copy(src, dest, len): \"copy from source to dest len elems\"\n+            ptr::copy(self.ptr.offset(index as isize),\n+                      self.ptr.offset(index as isize + 1),\n+                      len - index);\n+        }\n+        ptr::write(self.ptr.offset(index as isize), elem);\n+        self.len += 1;\n+    }\n+}\n+```\n+\n+Remove behaves in the opposite manner. We need to shift all the elements from\n+`[i+1 .. len + 1]` to `[i .. len]` using the *new* len.\n+\n+```rust\n+pub fn remove(&mut self, index: usize) -> T {\n+    // Note: `<` because it's *not* valid to remove after everything\n+    assert!(index < self.len, \"index out of bounds\");\n+    unsafe {\n+        self.len -= 1;\n+        let result = ptr::read(self.ptr.offset(index as isize));\n+        ptr::copy(self.ptr.offset(index as isize + 1),\n+                  self.ptr.offset(index as isize),\n+                  len - index);\n+        result\n+    }\n+}\n+```\n+\n+# IntoIter\n+\n+Let's move on to writing iterators. `iter` and `iter_mut` have already been\n+written for us thanks to The Magic of Deref. However there's two interesting\n+iterators that Vec provides that slices can't: `into_iter` and `drain`.\n+\n+IntoIter consumes the Vec by-value, and can consequently yield its elements\n+by-value. In order to enable this, IntoIter needs to take control of Vec's\n+allocation.\n+\n+IntoIter needs to be DoubleEnded as well, to enable reading from both ends.\n+Reading from the back could just be implemented as calling `pop`, but reading\n+from the front is harder. We could call `remove(0)` but that would be insanely\n+expensive. Instead we're going to just use ptr::read to copy values out of either\n+end of the Vec without mutating the buffer at all.\n+\n+To do this we're going to use a very common C idiom for array iteration. We'll\n+make two pointers; one that points to the start of the array, and one that points\n+to one-element past the end. When we want an element from one end, we'll read out\n+the value pointed to at that end and move the pointer over by one. When the two\n+pointers are equal, we know we're done.\n+\n+Note that the order of read and offset are reversed for `next` and `next_back`\n+For `next_back` the pointer is always *after* the element it wants to read next,\n+while for `next` the pointer is always *at* the element it wants to read next.\n+To see why this is, consider the case where every element but one has been yielded.\n+\n+The array looks like this:\n+\n+```text\n+          S  E\n+[X, X, X, O, X, X, X]\n+```\n+\n+If E pointed directly at the element it wanted to yield next, it would be\n+indistinguishable from the case where there are no more elements to yield.\n+\n+So we're going to use the following struct:\n+\n+```rust\n+struct IntoIter<T> {\n+    buf: Unique<T>,\n+    cap: usize,\n+    start: *const T,\n+    end: *const T,\n+}\n+```\n+\n+And initialize it like this:\n+\n+```rust\n+impl<T> Vec<T> {\n+    fn into_iter(self) -> IntoIter<T> {\n+        // Can't destructure Vec since it's Drop\n+        let ptr = self.ptr;\n+        let cap = self.cap;\n+        let len = self.len;\n+\n+        // Make sure not to drop Vec since that will free the buffer\n+        mem::forget(self);\n+\n+        unsafe {\n+            IntoIter {\n+                buf: ptr,\n+                cap: cap,\n+                start: *ptr,\n+                end: ptr.offset(len as isize),\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Here's iterating forward:\n+\n+```rust\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                let result = ptr::read(self.start);\n+                self.start = self.start.offset(1);\n+                Some(result)\n+            }\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (usize, Option<usize>) {\n+        let len = self.end as usize - self.start as usize;\n+        (len, Some(len))\n+    }\n+}\n+```\n+\n+And here's iterating backwards.\n+\n+```rust\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+        } else {\n+            unsafe {\n+                self.end = self.end.offset(-1);\n+                Some(ptr::read(self.end))\n+            }\n+        }\n+    }\n+}\n+\n+Because IntoIter takes ownership of its allocation, it needs to implement Drop\n+to free it. However it *also* wants to implement Drop to drop any elements it\n+contains that weren't yielded.\n+\n+\n+```rust\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            // drop any remaining elements\n+            for _ in &mut *self {}\n+\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.buf as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+We've actually reached an interesting situation here: we've duplicated the logic\n+for specifying a buffer and freeing its memory. Now that we've implemented it and\n+identified *actual* logic duplication, this is a good time to perform some logic\n+compression.\n+\n+We're going to abstract out the `(ptr, cap)` pair and give them the logic for\n+allocating, growing, and freeing:\n+\n+```rust\n+\n+struct RawVec<T> {\n+    ptr: Unique<T>,\n+    cap: usize,\n+}\n+\n+impl<T> RawVec<T> {\n+    fn new() -> Self {\n+        assert!(mem::size_of::<T>() != 0, \"TODO: implement ZST support\");\n+        unsafe {\n+            RawVec { ptr: Unique::new(heap::EMPTY as *mut T), cap: 0 }\n+        }\n+    }\n+\n+    // unchanged from Vec\n+    fn grow(&mut self) {\n+        unsafe {\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+\n+            let (new_cap, ptr) = if self.cap == 0 {\n+                let ptr = heap::allocate(elem_size, align);\n+                (1, ptr)\n+            } else {\n+                let new_cap = 2 * self.cap;\n+                let ptr = heap::reallocate(*self.ptr as *mut _,\n+                                            self.cap * elem_size,\n+                                            new_cap * elem_size,\n+                                            align);\n+                (new_cap, ptr)\n+            };\n+\n+            // If allocate or reallocate fail, we'll get `null` back\n+            if ptr.is_null() { oom() }\n+\n+            self.ptr = Unique::new(ptr as *mut _);\n+            self.cap = new_cap;\n+        }\n+    }\n+}\n+\n+\n+impl<T> Drop for RawVec<T> {\n+    fn drop(&mut self) {\n+        if self.cap != 0 {\n+            let align = mem::min_align_of::<T>();\n+            let elem_size = mem::size_of::<T>();\n+            let num_bytes = elem_size * self.cap;\n+            unsafe {\n+                heap::deallocate(*self.ptr as *mut _, num_bytes, align);\n+            }\n+        }\n+    }\n+}\n+```\n+\n+And change vec as follows:\n+\n+```rust\n+pub struct Vec<T> {\n+    buf: RawVec<T>,\n+    len: usize,\n+}\n+\n+impl<T> Vec<T> {\n+    fn ptr(&self) -> *mut T { *self.buf.ptr }\n+\n+    fn cap(&self) -> usize { self.buf.cap }\n+\n+    pub fn new() -> Self {\n+        Vec { buf: RawVec::new(), len: 0 }\n+    }\n+\n+    // push/pop/insert/remove largely unchanged:\n+    // * `self.ptr -> self.ptr()`\n+    // * `self.cap -> self.cap()`\n+    // * `self.grow -> self.buf.grow()`\n+}\n+\n+impl<T> Drop for Vec<T> {\n+    fn drop(&mut self) {\n+        while let Some(_) = self.pop() {}\n+        // deallocation is handled by RawVec\n+    }\n+}\n+```\n+\n+And finally we can really simplify IntoIter:\n+\n+```rust\n+struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+// next and next_back litterally unchanged since they never referred to the buf\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        // only need to ensure all our elements are read;\n+        // buffer will clean itself up afterwards.\n+        for _ in &mut *self {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            // need to use ptr::read to unsafely move the buf out since it's\n+            // not Copy.\n+            let buf = ptr::read(&self.buf);\n+            let len = self.len;\n+            mem::forget(self);\n+\n+            IntoIter {\n+                start: *buf.ptr,\n+                end: buf.ptr.offset(len as isize),\n+                _buf: buf,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Much better.\n+\n+# Drain\n+\n+Let's move on to Drain. Drain is largely the same as IntoIter, except that\n+instead of consuming the Vec, it borrows the Vec and leaves its allocation\n+free. For now we'll only implement the \"basic\" full-range version.\n+\n+```rust,ignore\n+use std::marker::PhantomData;\n+\n+struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> {\n+        if self.start == self.end {\n+            None\n+```\n+\n+-- wait, this is seeming familiar. Let's do some more compression. Both\n+IntoIter and Drain have the exact same structure, let's just factor it out.\n+\n+```rust\n+struct RawValIter<T> {\n+    start: *const T,\n+    end: *const T,\n+}\n+\n+impl<T> RawValIter<T> {\n+    // unsafe to construct because it has no associated lifetimes.\n+    // This is necessary to store a RawValIter in the same struct as\n+    // its actual allocation. OK since it's a private implementation\n+    // detail.\n+    unsafe fn new(slice: &[T]) -> Self {\n+        RawValIter {\n+            start: slice.as_ptr(),\n+            end: slice.as_ptr().offset(slice.len() as isize),\n+        }\n+    }\n+}\n+\n+// Iterator and DoubleEndedIterator impls identical to IntoIter.\n+```\n+\n+And IntoIter becomes the following:\n+\n+```\n+pub struct IntoIter<T> {\n+    _buf: RawVec<T>, // we don't actually care about this. Just need it to live.\n+    iter: RawValIter<T>,\n+}\n+\n+impl<T> Iterator for IntoIter<T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<T> DoubleEndedIterator for IntoIter<T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<T> Drop for IntoIter<T> {\n+    fn drop(&mut self) {\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn into_iter(self) -> IntoIter<T> {\n+        unsafe {\n+            let iter = RawValIter::new(&self);\n+            let buf = ptr::read(&self.buf);\n+            mem::forget(self);\n+\n+            IntoIter {\n+                iter: iter,\n+                _buf: buf,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+Note that I've left a few quirks in this design to make upgrading Drain to work\n+with arbitrary subranges a bit easier. In particular we *could* have RawValIter\n+drain itself on drop, but that won't work right for a more complex Drain.\n+We also take a slice to simplify Drain initialization.\n+\n+Alright, now Drain is really easy:\n+\n+```rust\n+use std::marker::PhantomData;\n+\n+pub struct Drain<'a, T: 'a> {\n+    vec: PhantomData<&'a mut Vec<T>>,\n+    iter: RawValIter<T>,\n+}\n+\n+impl<'a, T> Iterator for Drain<'a, T> {\n+    type Item = T;\n+    fn next(&mut self) -> Option<T> { self.iter.next_back() }\n+    fn size_hint(&self) -> (usize, Option<usize>) { self.iter.size_hint() }\n+}\n+\n+impl<'a, T> DoubleEndedIterator for Drain<'a, T> {\n+    fn next_back(&mut self) -> Option<T> { self.iter.next_back() }\n+}\n+\n+impl<'a, T> Drop for Drain<'a, T> {\n+    fn drop(&mut self) {\n+        for _ in &mut self.iter {}\n+    }\n+}\n+\n+impl<T> Vec<T> {\n+    pub fn drain(&mut self) -> Drain<T> {\n+        // this is a mem::forget safety thing. If Drain is forgotten, we just\n+        // leak the whole Vec's contents. Also we need to do this *eventually*\n+        // anyway, so why not do it now?\n+        self.len = 0;\n+\n+        unsafe {\n+            Drain {\n+                iter: RawValIter::new(&self),\n+                vec: PhantomData,\n+            }\n+        }\n+    }\n+}\n+```\n+\n+\n+# Handling Zero-Sized Types\n+\n+It's time. We're going to fight the spectre that is zero-sized types. Safe Rust\n+*never* needs to care about this, but Vec is very intensive on raw pointers and\n+raw allocations, which are exactly the *only* two things that care about\n+zero-sized types. We need to be careful of two things:\n+\n+* The raw allocator API has undefined behaviour if you pass in 0 for an\n+  allocation size.\n+* raw pointer offsets are no-ops for zero-sized types, which will break our\n+  C-style pointer iterator\n+\n+Thankfully we abstracted out pointer-iterators and allocating handling into\n+RawValIter and RawVec respectively. How mysteriously convenient.\n+\n+\n+\n+## Allocating Zero-Sized Types\n+\n+So if the allocator API doesn't support zero-sized allocations, what on earth\n+do we store as our allocation? Why, `heap::EMPTY` of course! Almost every operation\n+with a ZST is a no-op since ZSTs have exactly one value, and therefore no state needs\n+to be considered to store or load them. This actually extends to `ptr::read` and\n+`ptr::write`: they won't actually look at the pointer at all. As such we *never* need\n+to change the pointer.\n+\n+TODO\n+\n+## Iterating Zero-Sized Types\n+\n+TODO\n \n-TODO: rest of this\n+## Advanced Drain\n \n+TODO? Not clear if informative\n "}]}