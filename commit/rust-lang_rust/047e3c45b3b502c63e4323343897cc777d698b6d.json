{"sha": "047e3c45b3b502c63e4323343897cc777d698b6d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA0N2UzYzQ1YjNiNTAyYzYzZTQzMjMzNDM4OTdjYzc3N2Q2OThiNmQ=", "commit": {"author": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-06-15T16:32:17Z"}, "committer": {"name": "Paul Stansifer", "email": "paul.stansifer@gmail.com", "date": "2012-06-15T19:41:41Z"}, "message": "Lexers now emit spans, not chposes.", "tree": {"sha": "87da69e28a8ee738d710c1f9d4b4bfc67f6ec405", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/87da69e28a8ee738d710c1f9d4b4bfc67f6ec405"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/047e3c45b3b502c63e4323343897cc777d698b6d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/047e3c45b3b502c63e4323343897cc777d698b6d", "html_url": "https://github.com/rust-lang/rust/commit/047e3c45b3b502c63e4323343897cc777d698b6d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/047e3c45b3b502c63e4323343897cc777d698b6d/comments", "author": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "committer": {"login": "paulstansifer", "id": 1431, "node_id": "MDQ6VXNlcjE0MzE=", "avatar_url": "https://avatars.githubusercontent.com/u/1431?v=4", "gravatar_id": "", "url": "https://api.github.com/users/paulstansifer", "html_url": "https://github.com/paulstansifer", "followers_url": "https://api.github.com/users/paulstansifer/followers", "following_url": "https://api.github.com/users/paulstansifer/following{/other_user}", "gists_url": "https://api.github.com/users/paulstansifer/gists{/gist_id}", "starred_url": "https://api.github.com/users/paulstansifer/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/paulstansifer/subscriptions", "organizations_url": "https://api.github.com/users/paulstansifer/orgs", "repos_url": "https://api.github.com/users/paulstansifer/repos", "events_url": "https://api.github.com/users/paulstansifer/events{/privacy}", "received_events_url": "https://api.github.com/users/paulstansifer/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d6522ab2d3f7ab03c6d5d93ea196137823d2cfcf", "url": "https://api.github.com/repos/rust-lang/rust/commits/d6522ab2d3f7ab03c6d5d93ea196137823d2cfcf", "html_url": "https://github.com/rust-lang/rust/commit/d6522ab2d3f7ab03c6d5d93ea196137823d2cfcf"}], "stats": {"total": 110, "additions": 62, "deletions": 48}, "files": [{"sha": "5f2a5b2accb7d3b20a03eeca1c4fe7376a46d925", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=047e3c45b3b502c63e4323343897cc777d698b6d", "patch": "@@ -377,7 +377,7 @@ enum blk_sort {\n enum token_tree {\n     /* for macro invocations; parsing is the macro's job */\n     tt_delim([token_tree]),\n-    tt_flat(uint, token::token)\n+    tt_flat(span, token::token)\n }\n \n #[auto_serialize]"}, {"sha": "69aa4775e436ee1b7790167024fc7d7b7fdf2023", "filename": "src/libsyntax/parse/comments.rs", "status": "modified", "additions": 13, "deletions": 9, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fcomments.rs?ref=047e3c45b3b502c63e4323343897cc777d698b6d", "patch": "@@ -1,7 +1,7 @@\n import io::reader_util;\n import io::println;//XXXXXXXXxxx\n import util::interner;\n-import lexer::{ string_reader, bump, is_eof, nextch, new_string_reader,\n+import lexer::{ string_reader, bump, is_eof, nextch,\n                is_whitespace, get_str_from, string_reader_as_reader };\n \n export cmnt;\n@@ -176,8 +176,9 @@ fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n         {|x|str::hash(*x)},\n         {|x,y|str::eq(*x, *y)}\n     );\n-    let rdr = new_string_reader(span_diagnostic,\n-                                codemap::new_filemap(path, src, 0u, 0u), itr);\n+    let rdr = lexer::new_low_level_string_reader\n+        (span_diagnostic, codemap::new_filemap(path, src, 0u, 0u), itr);\n+\n     let mut comments: [cmnt] = [];\n     let mut literals: [lit] = [];\n     let mut first_read: bool = true;\n@@ -195,14 +196,17 @@ fn gather_comments_and_literals(span_diagnostic: diagnostic::span_handler,\n             }\n             break;\n         }\n-        let bpos = rdr.pos;\n-        let tok = rdr.next_token();\n-        if token::is_lit(tok.tok) {\n-            let s = get_str_from(rdr, bpos);\n-            literals += [{lit: s, pos: tok.chpos}];\n+\n+\n+        let bstart = rdr.pos;\n+        //discard, and look ahead; we're working with internal state\n+        let {tok: tok, sp: sp} = rdr.next_token();\n+        if token::is_lit(tok) {\n+            let s = get_str_from(rdr, bstart);\n+            literals += [{lit: s, pos: sp.lo}];\n             log(debug, \"tok lit: \" + s);\n         } else {\n-            log(debug, \"tok: \" + token::to_str(*rdr.interner, tok.tok));\n+            log(debug, \"tok: \" + token::to_str(*rdr.interner, tok));\n         }\n         first_read = false;\n     }"}, {"sha": "5ef8417ec6ff3815becb5ee8b43cdc004318cc3e", "filename": "src/libsyntax/parse/eval.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Feval.rs", "raw_url": "https://github.com/rust-lang/rust/raw/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Feval.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Feval.rs?ref=047e3c45b3b502c63e4323343897cc777d698b6d", "patch": "@@ -68,7 +68,7 @@ fn parse_companion_mod(cx: ctx, prefix: str, suffix: option<str>)\n                                                 modpath, SOURCE_FILE);\n         let inner_attrs = p0.parse_inner_attrs_and_next();\n         let m0 = p0.parse_mod_items(token::EOF, inner_attrs.next);\n-        cx.sess.chpos = p0.reader.chpos();\n+        cx.sess.chpos = r0.chpos;\n         cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         ret (m0.view_items, m0.items, inner_attrs.inner);\n     } else {\n@@ -106,7 +106,7 @@ fn eval_crate_directive(cx: ctx, cdir: @ast::crate_directive, prefix: str,\n                            /* FIXME: bad */ copy id,\n                            ast::item_mod(m0), ast::public, mod_attrs);\n         // Thread defids, chpos and byte_pos through the parsers\n-        cx.sess.chpos = p0.reader.chpos();\n+        cx.sess.chpos = r0.chpos;\n         cx.sess.byte_pos = cx.sess.byte_pos + r0.pos;\n         items += [i];\n       }"}, {"sha": "14cb8b414731280f364a661176fa8c3fb331805d", "filename": "src/libsyntax/parse/lexer.rs", "status": "modified", "additions": 32, "deletions": 19, "changes": 51, "blob_url": "https://github.com/rust-lang/rust/blob/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Flexer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Flexer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer.rs?ref=047e3c45b3b502c63e4323343897cc777d698b6d", "patch": "@@ -2,17 +2,17 @@ import util::interner;\n import util::interner::intern;\n import diagnostic;\n import ast::{tt_delim,tt_flat};\n+import codemap::span;\n \n export reader, string_reader, new_string_reader, is_whitespace;\n export tt_reader,  new_tt_reader, dup_tt_reader;\n-export nextch, is_eof, bump, get_str_from;\n+export nextch, is_eof, bump, get_str_from, new_low_level_string_reader;\n export string_reader_as_reader, tt_reader_as_reader;\n \n iface reader {\n     fn is_eof() -> bool;\n-    fn next_token() -> {tok: token::token, chpos: uint};\n+    fn next_token() -> {tok: token::token, sp: span};\n     fn fatal(str) -> !;\n-    fn chpos() -> uint;\n     fn interner() -> @interner::interner<@str>;\n }\n \n@@ -33,7 +33,7 @@ type tt_reader = ~{\n     mut cur: tt_frame,\n     /* cached: */\n     mut cur_tok: token::token,\n-    mut cur_chpos: uint\n+    mut cur_span: span\n };\n \n fn new_tt_reader(span_diagnostic: diagnostic::span_handler,\n@@ -42,10 +42,11 @@ fn new_tt_reader(span_diagnostic: diagnostic::span_handler,\n     let r = ~{span_diagnostic: span_diagnostic, interner: itr,\n               mut cur: @{readme: src, mut idx: 0u,\n                          up: tt_frame_up(option::none)},\n-              mut cur_tok: token::EOF, /* dummy value, never read */\n-              mut cur_chpos: 0u /* dummy value, never read */\n+              /* dummy values, never read: */\n+              mut cur_tok: token::EOF,\n+              mut cur_span: ast_util::mk_sp(0u,0u)\n              };\n-    tt_next_token(r); /* get cur_tok and cur_chpos set up */\n+    tt_next_token(r); /* get cur_tok and cur_span set up */\n     ret r;\n }\n \n@@ -63,7 +64,7 @@ pure fn dup_tt_frame(&&f: tt_frame) -> tt_frame {\n pure fn dup_tt_reader(&&r: tt_reader) -> tt_reader {\n     ~{span_diagnostic: r.span_diagnostic, interner: r.interner,\n       mut cur: dup_tt_frame(r.cur),\n-      mut cur_tok: r.cur_tok, mut cur_chpos: r.cur_chpos}\n+      mut cur_tok: r.cur_tok, mut cur_span: r.cur_span}\n }\n \n type string_reader = @{\n@@ -80,6 +81,15 @@ type string_reader = @{\n fn new_string_reader(span_diagnostic: diagnostic::span_handler,\n                      filemap: codemap::filemap,\n                      itr: @interner::interner<@str>) -> string_reader {\n+    let r = new_low_level_string_reader(span_diagnostic, filemap, itr);\n+    ret r;\n+}\n+\n+/* For comments.rs, which hackily pokes into 'pos' and 'curr' */\n+fn new_low_level_string_reader(span_diagnostic: diagnostic::span_handler,\n+                               filemap: codemap::filemap,\n+                               itr: @interner::interner<@str>)\n+    -> string_reader {\n     let r = @{span_diagnostic: span_diagnostic, src: filemap.src,\n               mut col: 0u, mut pos: 0u, mut curr: -1 as char,\n               mut chpos: filemap.start_pos.ch,\n@@ -94,27 +104,26 @@ fn new_string_reader(span_diagnostic: diagnostic::span_handler,\n \n impl string_reader_as_reader of reader for string_reader {\n     fn is_eof() -> bool { is_eof(self) }\n-    fn next_token() -> {tok: token::token, chpos: uint} {\n+    fn next_token() -> {tok: token::token, sp: span} {\n         consume_whitespace_and_comments(self);\n         let start_chpos = self.chpos;\n         let tok = if is_eof(self) {\n             token::EOF\n         } else {\n             next_token_inner(self)\n         };\n-        ret {tok: tok, chpos: start_chpos};\n+        ret {tok: tok, sp: ast_util::mk_sp(start_chpos, self.chpos)};\n     }\n     fn fatal(m: str) -> ! {\n         self.span_diagnostic.span_fatal(\n             ast_util::mk_sp(self.chpos, self.chpos), m)\n     }\n-    fn chpos() -> uint { self.chpos }\n     fn interner() -> @interner::interner<@str> { self.interner }\n }\n \n impl tt_reader_as_reader of reader for tt_reader {\n     fn is_eof() -> bool { self.cur_tok == token::EOF }\n-    fn next_token() -> {tok: token::token, chpos: uint} {\n+    fn next_token() -> {tok: token::token, sp: span} {\n         /* weird resolve bug: if the following `if`, or any of its\n         statements are removed, we get resolution errors */\n         if false {\n@@ -124,15 +133,19 @@ impl tt_reader_as_reader of reader for tt_reader {\n         tt_next_token(self)\n     }\n     fn fatal(m: str) -> ! {\n-        self.span_diagnostic.span_fatal(\n-            ast_util::mk_sp(self.chpos(), self.chpos()), m);\n+        self.span_diagnostic.span_fatal(copy self.cur_span, m);\n     }\n-    fn chpos() -> uint { self.cur_chpos }\n     fn interner() -> @interner::interner<@str> { self.interner }\n }\n \n-fn tt_next_token(&&r: tt_reader) -> {tok: token::token, chpos: uint} {\n-    let ret_val = { tok: r.cur_tok, chpos: r.cur_chpos };\n+fn string_advance_token(&&r: string_reader) {\n+    consume_whitespace_and_comments(r);\n+\n+    next_token_inner(r);\n+}\n+\n+fn tt_next_token(&&r: tt_reader) -> {tok: token::token, sp: span} {\n+    let ret_val = { tok: r.cur_tok, sp: r.cur_span };\n     if r.cur.idx >= vec::len(r.cur.readme) {\n         /* done with this set; pop */\n         alt r.cur.up {\n@@ -158,8 +171,8 @@ fn tt_next_token(&&r: tt_reader) -> {tok: token::token, chpos: uint} {\n             r.cur = @{readme: tts, mut idx: 0u,\n                       up: tt_frame_up(option::some(copy r.cur)) };\n           }\n-          tt_flat(chpos, tok) {\n-            r.cur_chpos = chpos; r.cur_tok = tok;\n+          tt_flat(sp, tok) {\n+            r.cur_span = sp; r.cur_tok = tok;\n             r.cur.idx += 1u;\n             ret ret_val;\n           }"}, {"sha": "08eaa7792917bc6ad10b88379873902bb94dbfc6", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 14, "deletions": 17, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/047e3c45b3b502c63e4323343897cc777d698b6d/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=047e3c45b3b502c63e4323343897cc777d698b6d", "patch": "@@ -63,7 +63,7 @@ class parser {\n     let mut token: token::token;\n     let mut span: span;\n     let mut last_span: span;\n-    let mut buffer: [mut {tok: token::token, span: span}]/4;\n+    let mut buffer: [mut {tok: token::token, sp: span}]/4;\n     let mut buffer_start: int;\n     let mut buffer_end: int;\n     let mut restriction: restriction;\n@@ -75,18 +75,18 @@ class parser {\n     {\n         self.reader <- rdr;\n         let tok0 = self.reader.next_token();\n-        let span0 = ast_util::mk_sp(tok0.chpos, self.reader.chpos());\n+        let span0 = tok0.sp;\n         self.sess = sess;\n         self.cfg = cfg;\n         self.file_type = ftype;\n         self.token = tok0.tok;\n         self.span = span0;\n         self.last_span = span0;\n         self.buffer = [mut\n-            {tok: tok0.tok, span: span0},\n-            {tok: tok0.tok, span: span0},\n-            {tok: tok0.tok, span: span0},\n-            {tok: tok0.tok, span: span0}\n+            {tok: tok0.tok, sp: span0},\n+            {tok: tok0.tok, sp: span0},\n+            {tok: tok0.tok, sp: span0},\n+            {tok: tok0.tok, sp: span0}\n         ]/4;\n         self.buffer_start = 0;\n         self.buffer_end = 0;\n@@ -100,16 +100,15 @@ class parser {\n \n     fn bump() {\n         self.last_span = self.span;\n-        if self.buffer_start == self.buffer_end {\n-            let next = self.reader.next_token();\n-            self.token = next.tok;\n-            self.span = mk_sp(next.chpos, self.reader.chpos());\n+        let next = if self.buffer_start == self.buffer_end {\n+            self.reader.next_token()\n         } else {\n             let next = self.buffer[self.buffer_start];\n             self.buffer_start = (self.buffer_start + 1) & 3;\n-            self.token = next.tok;\n-            self.span = next.span;\n-        }\n+            next\n+        };\n+        self.token = next.tok;\n+        self.span = next.sp;\n     }\n     fn swap(next: token::token, lo: uint, hi: uint) {\n         self.token = next;\n@@ -124,9 +123,7 @@ class parser {\n     fn look_ahead(distance: uint) -> token::token {\n         let dist = distance as int;\n         while self.buffer_length() < dist {\n-            let next = self.reader.next_token();\n-            let sp = mk_sp(next.chpos, self.reader.chpos());\n-            self.buffer[self.buffer_end] = {tok: next.tok, span: sp};\n+            self.buffer[self.buffer_end] = self.reader.next_token();\n             self.buffer_end = (self.buffer_end + 1) & 3;\n         }\n         ret copy self.buffer[(self.buffer_start + dist - 1) & 3].tok;\n@@ -1082,7 +1079,7 @@ class parser {\n               }\n               _ { /* ok */ }\n             }\n-            let res = tt_flat(p.span.lo, p.token);\n+            let res = tt_flat(p.span, p.token);\n             p.bump();\n             ret res;\n         }"}]}