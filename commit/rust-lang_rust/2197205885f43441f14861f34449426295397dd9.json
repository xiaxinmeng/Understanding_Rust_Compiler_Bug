{"sha": "2197205885f43441f14861f34449426295397dd9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjIxOTcyMDU4ODVmNDM0NDFmMTQ4NjFmMzQ0NDk0MjYyOTUzOTdkZDk=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2019-10-23T15:57:47Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2019-10-23T15:57:47Z"}, "message": "Merge #2050\n\n2050: xtask: don't depend on itertools r=matklad a=matklad\n\n\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "3af21aaefe1efdabafeb5702959e1094504813e7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3af21aaefe1efdabafeb5702959e1094504813e7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2197205885f43441f14861f34449426295397dd9", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJdsHh7CRBK7hj4Ov3rIwAAdHIIAE5tl+b/pl+THn8OhfCj2HBj\nACsMV64U40AgiRZuDr3AA98ATJ/1kWOHUhVz84xNiAik5wTU7Wi8GTpGE+ioNB2m\nITdBYfzOFCEX/xNJQ8G3p+BVfiBcbA1mwWYVFEVLdhKnO61FtNSeGBheCoE6ISOa\nwBUve40oi8dutqnUxH9iZOSTS5q/ohYM42qKO3WZz6Q6cT4Yz6TeYApuq2Kc1izg\n+VLyBYZgSn5qdgX62FCGuUrZRTKum7kVvWFjckeM5yERkR8E7lqN7SbQYxRpwB5p\nJiBbp8233NsE8TCNC/Ko3ajCCGhPcvlmg+Ip9QxT3a+iiknQhQEOYkE0j++zL1o=\n=IUIL\n-----END PGP SIGNATURE-----\n", "payload": "tree 3af21aaefe1efdabafeb5702959e1094504813e7\nparent edf4d8e555c6847fb9e6e61d727c4def11789bfc\nparent 6048d294009f0f58593747e0870aa174e29a32af\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1571846267 +0000\ncommitter GitHub <noreply@github.com> 1571846267 +0000\n\nMerge #2050\n\n2050: xtask: don't depend on itertools r=matklad a=matklad\n\n\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2197205885f43441f14861f34449426295397dd9", "html_url": "https://github.com/rust-lang/rust/commit/2197205885f43441f14861f34449426295397dd9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2197205885f43441f14861f34449426295397dd9/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "edf4d8e555c6847fb9e6e61d727c4def11789bfc", "url": "https://api.github.com/repos/rust-lang/rust/commits/edf4d8e555c6847fb9e6e61d727c4def11789bfc", "html_url": "https://github.com/rust-lang/rust/commit/edf4d8e555c6847fb9e6e61d727c4def11789bfc"}, {"sha": "6048d294009f0f58593747e0870aa174e29a32af", "url": "https://api.github.com/repos/rust-lang/rust/commits/6048d294009f0f58593747e0870aa174e29a32af", "html_url": "https://github.com/rust-lang/rust/commit/6048d294009f0f58593747e0870aa174e29a32af"}], "stats": {"total": 1120, "additions": 576, "deletions": 544}, "files": [{"sha": "61fd24ef7f87b6e078f56fb72b24de140e3feade", "filename": "Cargo.lock", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -1771,7 +1771,6 @@ dependencies = [\n name = \"xtask\"\n version = \"0.1.0\"\n dependencies = [\n- \"itertools 0.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"pico-args 0.3.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"proc-macro2 1.0.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"quote 1.0.2 (registry+https://github.com/rust-lang/crates.io-index)\","}, {"sha": "f7d7e12e73c9bdda89fd0192124e7edffdde5ad2", "filename": "crates/ra_assists/src/assists/early_return.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/crates%2Fra_assists%2Fsrc%2Fassists%2Fearly_return.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/crates%2Fra_assists%2Fsrc%2Fassists%2Fearly_return.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fassists%2Fearly_return.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -2,7 +2,7 @@\n //!\n //! Replace a large conditional with a guarded return.\n //!\n-//! ```notrust\n+//! ```text\n //! fn <|>main() {\n //!     if cond {\n //!         foo();\n@@ -11,7 +11,7 @@\n //! }\n //! ```\n //! ->\n-//! ```notrust\n+//! ```text\n //! fn main() {\n //!     if !cond {\n //!         return;"}, {"sha": "6fd396dee6ed8814113afbf5c7412a591049645f", "filename": "docs/dev/architecture.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/docs%2Fdev%2Farchitecture.md", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/docs%2Fdev%2Farchitecture.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/docs%2Fdev%2Farchitecture.md?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -78,7 +78,7 @@ Rust syntax tree structure and parser. See\n Tests for ra_syntax are mostly data-driven: `test_data/parser` contains subdirectories with a bunch of `.rs`\n (test vectors) and `.txt` files with corresponding syntax trees. During testing, we check\n `.rs` against `.txt`. If the `.txt` file is missing, it is created (this is how you update\n-tests). Additionally, running `cargo gen-tests` will walk the grammar module and collect\n+tests). Additionally, running `cargo xtask codegen` will walk the grammar module and collect\n all `// test test_name` comments into files inside `test_data/parser/inline` directory.\n \n See [#93](https://github.com/rust-analyzer/rust-analyzer/pull/93) for an example PR which"}, {"sha": "023f6a859fd6030a2157e738f444d99e447d8ce8", "filename": "xtask/Cargo.toml", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2FCargo.toml?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -7,7 +7,6 @@ publish = false\n \n [dependencies]\n walkdir = \"2.1.3\"\n-itertools = \"0.8.0\"\n pico-args = \"0.3.0\"\n quote = \"1.0.2\"\n proc-macro2 = \"1.0.1\""}, {"sha": "cc6ccb25eeaa05e61c10bbb3a8dc1dc491f5ad70", "filename": "xtask/src/bin/pre-commit.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fbin%2Fpre-commit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fbin%2Fpre-commit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fbin%2Fpre-commit.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -2,10 +2,10 @@\n \n use std::process::Command;\n \n-use xtask::{project_root, run, run_rustfmt, Overwrite, Result};\n+use xtask::{codegen::Mode, project_root, run, run_rustfmt, Result};\n \n fn main() -> Result<()> {\n-    run_rustfmt(Overwrite)?;\n+    run_rustfmt(Mode::Overwrite)?;\n     update_staged()\n }\n "}, {"sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391", "filename": "xtask/src/boilerplate_gen.rs", "status": "modified", "additions": 0, "deletions": 348, "changes": 348, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fboilerplate_gen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fboilerplate_gen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fboilerplate_gen.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -1,348 +0,0 @@\n-//! FIXME: write short doc here\n-\n-use std::{\n-    collections::BTreeMap,\n-    fs,\n-    io::Write,\n-    process::{Command, Stdio},\n-};\n-\n-use proc_macro2::{Punct, Spacing};\n-use quote::{format_ident, quote};\n-use ron;\n-use serde::Deserialize;\n-\n-use crate::{project_root, update, Mode, Result, AST, GRAMMAR, SYNTAX_KINDS};\n-\n-pub fn generate_boilerplate(mode: Mode) -> Result<()> {\n-    let grammar = project_root().join(GRAMMAR);\n-    let grammar: Grammar = {\n-        let text = fs::read_to_string(grammar)?;\n-        ron::de::from_str(&text)?\n-    };\n-\n-    let syntax_kinds_file = project_root().join(SYNTAX_KINDS);\n-    let syntax_kinds = generate_syntax_kinds(&grammar)?;\n-    update(syntax_kinds_file.as_path(), &syntax_kinds, mode)?;\n-\n-    let ast_file = project_root().join(AST);\n-    let ast = generate_ast(&grammar)?;\n-    update(ast_file.as_path(), &ast, mode)?;\n-\n-    Ok(())\n-}\n-\n-fn generate_ast(grammar: &Grammar) -> Result<String> {\n-    let nodes = grammar.ast.iter().map(|(name, ast_node)| {\n-        let variants =\n-            ast_node.variants.iter().map(|var| format_ident!(\"{}\", var)).collect::<Vec<_>>();\n-        let name = format_ident!(\"{}\", name);\n-\n-        let adt = if variants.is_empty() {\n-            let kind = format_ident!(\"{}\", to_upper_snake_case(&name.to_string()));\n-            quote! {\n-                #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n-                pub struct #name {\n-                    pub(crate) syntax: SyntaxNode,\n-                }\n-\n-                impl AstNode for #name {\n-                    fn can_cast(kind: SyntaxKind) -> bool {\n-                        match kind {\n-                            #kind => true,\n-                            _ => false,\n-                        }\n-                    }\n-                    fn cast(syntax: SyntaxNode) -> Option<Self> {\n-                        if Self::can_cast(syntax.kind()) { Some(Self { syntax }) } else { None }\n-                    }\n-                    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-                }\n-            }\n-        } else {\n-            let kinds = variants\n-                .iter()\n-                .map(|name| format_ident!(\"{}\", to_upper_snake_case(&name.to_string())))\n-                .collect::<Vec<_>>();\n-\n-            quote! {\n-                #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n-                pub enum #name {\n-                    #(#variants(#variants),)*\n-                }\n-\n-                #(\n-                impl From<#variants> for #name {\n-                    fn from(node: #variants) -> #name {\n-                        #name::#variants(node)\n-                    }\n-                }\n-                )*\n-\n-                impl AstNode for #name {\n-                    fn can_cast(kind: SyntaxKind) -> bool {\n-                        match kind {\n-                            #(#kinds)|* => true,\n-                            _ => false,\n-                        }\n-                    }\n-                    fn cast(syntax: SyntaxNode) -> Option<Self> {\n-                        let res = match syntax.kind() {\n-                            #(\n-                            #kinds => #name::#variants(#variants { syntax }),\n-                            )*\n-                            _ => return None,\n-                        };\n-                        Some(res)\n-                    }\n-                    fn syntax(&self) -> &SyntaxNode {\n-                        match self {\n-                            #(\n-                            #name::#variants(it) => &it.syntax,\n-                            )*\n-                        }\n-                    }\n-                }\n-            }\n-        };\n-\n-        let traits = ast_node.traits.iter().map(|trait_name| {\n-            let trait_name = format_ident!(\"{}\", trait_name);\n-            quote!(impl ast::#trait_name for #name {})\n-        });\n-\n-        let collections = ast_node.collections.iter().map(|(name, kind)| {\n-            let method_name = format_ident!(\"{}\", name);\n-            let kind = format_ident!(\"{}\", kind);\n-            quote! {\n-                pub fn #method_name(&self) -> AstChildren<#kind> {\n-                    AstChildren::new(&self.syntax)\n-                }\n-            }\n-        });\n-\n-        let options = ast_node.options.iter().map(|attr| {\n-            let method_name = match attr {\n-                Attr::Type(t) => format_ident!(\"{}\", to_lower_snake_case(&t)),\n-                Attr::NameType(n, _) => format_ident!(\"{}\", n),\n-            };\n-            let ty = match attr {\n-                Attr::Type(t) | Attr::NameType(_, t) => format_ident!(\"{}\", t),\n-            };\n-            quote! {\n-                pub fn #method_name(&self) -> Option<#ty> {\n-                    AstChildren::new(&self.syntax).next()\n-                }\n-            }\n-        });\n-\n-        quote! {\n-            #adt\n-\n-            #(#traits)*\n-\n-            impl #name {\n-                #(#collections)*\n-                #(#options)*\n-            }\n-        }\n-    });\n-\n-    let ast = quote! {\n-        use crate::{\n-            SyntaxNode, SyntaxKind::{self, *},\n-            ast::{self, AstNode, AstChildren},\n-        };\n-\n-        #(#nodes)*\n-    };\n-\n-    let pretty = reformat(ast)?;\n-    Ok(pretty)\n-}\n-\n-fn generate_syntax_kinds(grammar: &Grammar) -> Result<String> {\n-    let (single_byte_tokens_values, single_byte_tokens): (Vec<_>, Vec<_>) = grammar\n-        .punct\n-        .iter()\n-        .filter(|(token, _name)| token.len() == 1)\n-        .map(|(token, name)| (token.chars().next().unwrap(), format_ident!(\"{}\", name)))\n-        .unzip();\n-\n-    let punctuation_values = grammar.punct.iter().map(|(token, _name)| {\n-        if \"{}[]()\".contains(token) {\n-            let c = token.chars().next().unwrap();\n-            quote! { #c }\n-        } else {\n-            let cs = token.chars().map(|c| Punct::new(c, Spacing::Joint));\n-            quote! { #(#cs)* }\n-        }\n-    });\n-    let punctuation =\n-        grammar.punct.iter().map(|(_token, name)| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n-\n-    let full_keywords_values = &grammar.keywords;\n-    let full_keywords =\n-        full_keywords_values.iter().map(|kw| format_ident!(\"{}_KW\", to_upper_snake_case(&kw)));\n-\n-    let all_keywords_values =\n-        grammar.keywords.iter().chain(grammar.contextual_keywords.iter()).collect::<Vec<_>>();\n-    let all_keywords_idents = all_keywords_values.iter().map(|kw| format_ident!(\"{}\", kw));\n-    let all_keywords = all_keywords_values\n-        .iter()\n-        .map(|name| format_ident!(\"{}_KW\", to_upper_snake_case(&name)))\n-        .collect::<Vec<_>>();\n-\n-    let literals =\n-        grammar.literals.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n-\n-    let tokens = grammar.tokens.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n-\n-    let nodes = grammar.nodes.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n-\n-    let ast = quote! {\n-        #![allow(bad_style, missing_docs, unreachable_pub)]\n-        /// The kind of syntax node, e.g. `IDENT`, `USE_KW`, or `STRUCT_DEF`.\n-        #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n-        #[repr(u16)]\n-        pub enum SyntaxKind {\n-            // Technical SyntaxKinds: they appear temporally during parsing,\n-            // but never end up in the final tree\n-            #[doc(hidden)]\n-            TOMBSTONE,\n-            #[doc(hidden)]\n-            EOF,\n-            #(#punctuation,)*\n-            #(#all_keywords,)*\n-            #(#literals,)*\n-            #(#tokens,)*\n-            #(#nodes,)*\n-\n-            // Technical kind so that we can cast from u16 safely\n-            #[doc(hidden)]\n-            __LAST,\n-        }\n-        use self::SyntaxKind::*;\n-\n-        impl SyntaxKind {\n-            pub fn is_keyword(self) -> bool {\n-                match self {\n-                    #(#all_keywords)|* => true,\n-                    _ => false,\n-                }\n-            }\n-\n-            pub fn is_punct(self) -> bool {\n-                match self {\n-                    #(#punctuation)|* => true,\n-                    _ => false,\n-                }\n-            }\n-\n-            pub fn is_literal(self) -> bool {\n-                match self {\n-                    #(#literals)|* => true,\n-                    _ => false,\n-                }\n-            }\n-\n-            pub fn from_keyword(ident: &str) -> Option<SyntaxKind> {\n-                let kw = match ident {\n-                    #(#full_keywords_values => #full_keywords,)*\n-                    _ => return None,\n-                };\n-                Some(kw)\n-            }\n-\n-            pub fn from_char(c: char) -> Option<SyntaxKind> {\n-                let tok = match c {\n-                    #(#single_byte_tokens_values => #single_byte_tokens,)*\n-                    _ => return None,\n-                };\n-                Some(tok)\n-            }\n-        }\n-\n-        #[macro_export]\n-        macro_rules! T {\n-            #((#punctuation_values) => { $crate::SyntaxKind::#punctuation };)*\n-            #((#all_keywords_idents) => { $crate::SyntaxKind::#all_keywords };)*\n-        }\n-    };\n-\n-    reformat(ast)\n-}\n-\n-fn reformat(text: impl std::fmt::Display) -> Result<String> {\n-    let mut rustfmt = Command::new(\"rustfmt\")\n-        .arg(\"--config-path\")\n-        .arg(project_root().join(\"rustfmt.toml\"))\n-        .stdin(Stdio::piped())\n-        .stdout(Stdio::piped())\n-        .spawn()?;\n-    write!(rustfmt.stdin.take().unwrap(), \"{}\", text)?;\n-    let output = rustfmt.wait_with_output()?;\n-    let stdout = String::from_utf8(output.stdout)?;\n-    let preamble = \"Generated file, do not edit by hand, see `crate/ra_tools/src/codegen`\";\n-    Ok(format!(\"//! {}\\n\\n{}\", preamble, stdout))\n-}\n-\n-#[derive(Deserialize, Debug)]\n-struct Grammar {\n-    punct: Vec<(String, String)>,\n-    keywords: Vec<String>,\n-    contextual_keywords: Vec<String>,\n-    literals: Vec<String>,\n-    tokens: Vec<String>,\n-    nodes: Vec<String>,\n-    ast: BTreeMap<String, AstNode>,\n-}\n-\n-#[derive(Deserialize, Debug)]\n-struct AstNode {\n-    #[serde(default)]\n-    #[serde(rename = \"enum\")]\n-    variants: Vec<String>,\n-\n-    #[serde(default)]\n-    traits: Vec<String>,\n-    #[serde(default)]\n-    collections: Vec<(String, String)>,\n-    #[serde(default)]\n-    options: Vec<Attr>,\n-}\n-\n-#[derive(Deserialize, Debug)]\n-#[serde(untagged)]\n-enum Attr {\n-    Type(String),\n-    NameType(String, String),\n-}\n-\n-fn to_upper_snake_case(s: &str) -> String {\n-    let mut buf = String::with_capacity(s.len());\n-    let mut prev_is_upper = None;\n-    for c in s.chars() {\n-        if c.is_ascii_uppercase() && prev_is_upper == Some(false) {\n-            buf.push('_')\n-        }\n-        prev_is_upper = Some(c.is_ascii_uppercase());\n-\n-        buf.push(c.to_ascii_uppercase());\n-    }\n-    buf\n-}\n-\n-fn to_lower_snake_case(s: &str) -> String {\n-    let mut buf = String::with_capacity(s.len());\n-    let mut prev_is_upper = None;\n-    for c in s.chars() {\n-        if c.is_ascii_uppercase() && prev_is_upper == Some(false) {\n-            buf.push('_')\n-        }\n-        prev_is_upper = Some(c.is_ascii_uppercase());\n-\n-        buf.push(c.to_ascii_lowercase());\n-    }\n-    buf\n-}"}, {"sha": "948b867192b881eb97b9755f1c7e5aca0e53b1c1", "filename": "xtask/src/codegen.rs", "status": "added", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fcodegen.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -0,0 +1,46 @@\n+//! We use code generation heavily in rust-analyzer.\n+//!\n+//! Rather then doing it via proc-macros, we use old-school way of just dumping\n+//! the source code.\n+//!\n+//! This module's submodules define specific bits that we generate.\n+\n+mod gen_syntax;\n+mod gen_parser_tests;\n+\n+use std::{fs, path::Path};\n+\n+use crate::Result;\n+\n+pub use self::{gen_parser_tests::generate_parser_tests, gen_syntax::generate_syntax};\n+\n+pub const GRAMMAR: &str = \"crates/ra_syntax/src/grammar.ron\";\n+const GRAMMAR_DIR: &str = \"crates/ra_parser/src/grammar\";\n+const OK_INLINE_TESTS_DIR: &str = \"crates/ra_syntax/test_data/parser/inline/ok\";\n+const ERR_INLINE_TESTS_DIR: &str = \"crates/ra_syntax/test_data/parser/inline/err\";\n+\n+pub const SYNTAX_KINDS: &str = \"crates/ra_parser/src/syntax_kind/generated.rs\";\n+pub const AST: &str = \"crates/ra_syntax/src/ast/generated.rs\";\n+\n+#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n+pub enum Mode {\n+    Overwrite,\n+    Verify,\n+}\n+\n+/// A helper to update file on disk if it has changed.\n+/// With verify = false,\n+pub fn update(path: &Path, contents: &str, mode: Mode) -> Result<()> {\n+    match fs::read_to_string(path) {\n+        Ok(ref old_contents) if old_contents == contents => {\n+            return Ok(());\n+        }\n+        _ => (),\n+    }\n+    if mode == Mode::Verify {\n+        Err(format!(\"`{}` is not up-to-date\", path.display()))?;\n+    }\n+    eprintln!(\"updating {}\", path.display());\n+    fs::write(path, contents)?;\n+    Ok(())\n+}"}, {"sha": "0f550d94884d304cca58c02ce037fe36ecf00e43", "filename": "xtask/src/codegen/gen_parser_tests.rs", "status": "added", "additions": 155, "deletions": 0, "changes": 155, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen%2Fgen_parser_tests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen%2Fgen_parser_tests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fcodegen%2Fgen_parser_tests.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -0,0 +1,155 @@\n+//! This module greps parser's code for specially formatted comments and turnes\n+//! them into tests.\n+\n+use std::{\n+    collections::HashMap,\n+    fs,\n+    path::{Path, PathBuf},\n+};\n+\n+use crate::{\n+    codegen::{self, update, Mode},\n+    project_root, Result,\n+};\n+\n+pub fn generate_parser_tests(mode: Mode) -> Result<()> {\n+    let tests = tests_from_dir(&project_root().join(Path::new(codegen::GRAMMAR_DIR)))?;\n+    fn install_tests(tests: &HashMap<String, Test>, into: &str, mode: Mode) -> Result<()> {\n+        let tests_dir = project_root().join(into);\n+        if !tests_dir.is_dir() {\n+            fs::create_dir_all(&tests_dir)?;\n+        }\n+        // ok is never actually read, but it needs to be specified to create a Test in existing_tests\n+        let existing = existing_tests(&tests_dir, true)?;\n+        for t in existing.keys().filter(|&t| !tests.contains_key(t)) {\n+            panic!(\"Test is deleted: {}\", t);\n+        }\n+\n+        let mut new_idx = existing.len() + 1;\n+        for (name, test) in tests {\n+            let path = match existing.get(name) {\n+                Some((path, _test)) => path.clone(),\n+                None => {\n+                    let file_name = format!(\"{:04}_{}.rs\", new_idx, name);\n+                    new_idx += 1;\n+                    tests_dir.join(file_name)\n+                }\n+            };\n+            update(&path, &test.text, mode)?;\n+        }\n+        Ok(())\n+    }\n+    install_tests(&tests.ok, codegen::OK_INLINE_TESTS_DIR, mode)?;\n+    install_tests(&tests.err, codegen::ERR_INLINE_TESTS_DIR, mode)\n+}\n+\n+#[derive(Debug)]\n+struct Test {\n+    pub name: String,\n+    pub text: String,\n+    pub ok: bool,\n+}\n+\n+#[derive(Default, Debug)]\n+struct Tests {\n+    pub ok: HashMap<String, Test>,\n+    pub err: HashMap<String, Test>,\n+}\n+\n+fn collect_tests(s: &str) -> Vec<(usize, Test)> {\n+    let mut res = vec![];\n+    let prefix = \"// \";\n+    let lines = s.lines().map(str::trim_start).enumerate();\n+\n+    let mut block = vec![];\n+    for (line_idx, line) in lines {\n+        let is_comment = line.starts_with(prefix);\n+        if is_comment {\n+            block.push((line_idx, &line[prefix.len()..]));\n+        } else {\n+            process_block(&mut res, &block);\n+            block.clear();\n+        }\n+    }\n+    process_block(&mut res, &block);\n+    return res;\n+\n+    fn process_block(acc: &mut Vec<(usize, Test)>, block: &[(usize, &str)]) {\n+        if block.is_empty() {\n+            return;\n+        }\n+        let mut ok = true;\n+        let mut block = block.iter();\n+        let (start_line, name) = loop {\n+            match block.next() {\n+                Some(&(idx, line)) if line.starts_with(\"test \") => {\n+                    break (idx, line[\"test \".len()..].to_string());\n+                }\n+                Some(&(idx, line)) if line.starts_with(\"test_err \") => {\n+                    ok = false;\n+                    break (idx, line[\"test_err \".len()..].to_string());\n+                }\n+                Some(_) => (),\n+                None => return,\n+            }\n+        };\n+        let text: String =\n+            block.map(|(_, line)| *line).chain(std::iter::once(\"\")).collect::<Vec<_>>().join(\"\\n\");\n+        assert!(!text.trim().is_empty() && text.ends_with('\\n'));\n+        acc.push((start_line, Test { name, text, ok }))\n+    }\n+}\n+\n+fn tests_from_dir(dir: &Path) -> Result<Tests> {\n+    let mut res = Tests::default();\n+    for entry in ::walkdir::WalkDir::new(dir) {\n+        let entry = entry.unwrap();\n+        if !entry.file_type().is_file() {\n+            continue;\n+        }\n+        if entry.path().extension().unwrap_or_default() != \"rs\" {\n+            continue;\n+        }\n+        process_file(&mut res, entry.path())?;\n+    }\n+    let grammar_rs = dir.parent().unwrap().join(\"grammar.rs\");\n+    process_file(&mut res, &grammar_rs)?;\n+    return Ok(res);\n+    fn process_file(res: &mut Tests, path: &Path) -> Result<()> {\n+        let text = fs::read_to_string(path)?;\n+\n+        for (_, test) in collect_tests(&text) {\n+            if test.ok {\n+                if let Some(old_test) = res.ok.insert(test.name.clone(), test) {\n+                    Err(format!(\"Duplicate test: {}\", old_test.name))?\n+                }\n+            } else {\n+                if let Some(old_test) = res.err.insert(test.name.clone(), test) {\n+                    Err(format!(\"Duplicate test: {}\", old_test.name))?\n+                }\n+            }\n+        }\n+        Ok(())\n+    }\n+}\n+\n+fn existing_tests(dir: &Path, ok: bool) -> Result<HashMap<String, (PathBuf, Test)>> {\n+    let mut res = HashMap::new();\n+    for file in fs::read_dir(dir)? {\n+        let file = file?;\n+        let path = file.path();\n+        if path.extension().unwrap_or_default() != \"rs\" {\n+            continue;\n+        }\n+        let name = {\n+            let file_name = path.file_name().unwrap().to_str().unwrap();\n+            file_name[5..file_name.len() - 3].to_string()\n+        };\n+        let text = fs::read_to_string(&path)?;\n+        let test = Test { name: name.clone(), text, ok };\n+        if let Some(old) = res.insert(name, (path, test)) {\n+            println!(\"Duplicate test: {:?}\", old);\n+        }\n+    }\n+    Ok(res)\n+}"}, {"sha": "6a81c0e4dfdb35e0b789c2c2e478fb3c1b3b3628", "filename": "xtask/src/codegen/gen_syntax.rs", "status": "added", "additions": 354, "deletions": 0, "changes": 354, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen%2Fgen_syntax.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fcodegen%2Fgen_syntax.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fcodegen%2Fgen_syntax.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -0,0 +1,354 @@\n+//! This module generate AST datatype used by rust-analyzer.\n+//!\n+//! Specifically, it generates the `SyntaxKind` enum and a number of newtype\n+//! wrappers around `SyntaxNode` which implement `ra_syntax::AstNode`.\n+\n+use std::{\n+    collections::BTreeMap,\n+    fs,\n+    io::Write,\n+    process::{Command, Stdio},\n+};\n+\n+use proc_macro2::{Punct, Spacing};\n+use quote::{format_ident, quote};\n+use ron;\n+use serde::Deserialize;\n+\n+use crate::{\n+    codegen::{self, update, Mode},\n+    project_root, Result,\n+};\n+\n+pub fn generate_syntax(mode: Mode) -> Result<()> {\n+    let grammar = project_root().join(codegen::GRAMMAR);\n+    let grammar: Grammar = {\n+        let text = fs::read_to_string(grammar)?;\n+        ron::de::from_str(&text)?\n+    };\n+\n+    let syntax_kinds_file = project_root().join(codegen::SYNTAX_KINDS);\n+    let syntax_kinds = generate_syntax_kinds(&grammar)?;\n+    update(syntax_kinds_file.as_path(), &syntax_kinds, mode)?;\n+\n+    let ast_file = project_root().join(codegen::AST);\n+    let ast = generate_ast(&grammar)?;\n+    update(ast_file.as_path(), &ast, mode)?;\n+\n+    Ok(())\n+}\n+\n+fn generate_ast(grammar: &Grammar) -> Result<String> {\n+    let nodes = grammar.ast.iter().map(|(name, ast_node)| {\n+        let variants =\n+            ast_node.variants.iter().map(|var| format_ident!(\"{}\", var)).collect::<Vec<_>>();\n+        let name = format_ident!(\"{}\", name);\n+\n+        let adt = if variants.is_empty() {\n+            let kind = format_ident!(\"{}\", to_upper_snake_case(&name.to_string()));\n+            quote! {\n+                #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n+                pub struct #name {\n+                    pub(crate) syntax: SyntaxNode,\n+                }\n+\n+                impl AstNode for #name {\n+                    fn can_cast(kind: SyntaxKind) -> bool {\n+                        match kind {\n+                            #kind => true,\n+                            _ => false,\n+                        }\n+                    }\n+                    fn cast(syntax: SyntaxNode) -> Option<Self> {\n+                        if Self::can_cast(syntax.kind()) { Some(Self { syntax }) } else { None }\n+                    }\n+                    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n+                }\n+            }\n+        } else {\n+            let kinds = variants\n+                .iter()\n+                .map(|name| format_ident!(\"{}\", to_upper_snake_case(&name.to_string())))\n+                .collect::<Vec<_>>();\n+\n+            quote! {\n+                #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n+                pub enum #name {\n+                    #(#variants(#variants),)*\n+                }\n+\n+                #(\n+                impl From<#variants> for #name {\n+                    fn from(node: #variants) -> #name {\n+                        #name::#variants(node)\n+                    }\n+                }\n+                )*\n+\n+                impl AstNode for #name {\n+                    fn can_cast(kind: SyntaxKind) -> bool {\n+                        match kind {\n+                            #(#kinds)|* => true,\n+                            _ => false,\n+                        }\n+                    }\n+                    fn cast(syntax: SyntaxNode) -> Option<Self> {\n+                        let res = match syntax.kind() {\n+                            #(\n+                            #kinds => #name::#variants(#variants { syntax }),\n+                            )*\n+                            _ => return None,\n+                        };\n+                        Some(res)\n+                    }\n+                    fn syntax(&self) -> &SyntaxNode {\n+                        match self {\n+                            #(\n+                            #name::#variants(it) => &it.syntax,\n+                            )*\n+                        }\n+                    }\n+                }\n+            }\n+        };\n+\n+        let traits = ast_node.traits.iter().map(|trait_name| {\n+            let trait_name = format_ident!(\"{}\", trait_name);\n+            quote!(impl ast::#trait_name for #name {})\n+        });\n+\n+        let collections = ast_node.collections.iter().map(|(name, kind)| {\n+            let method_name = format_ident!(\"{}\", name);\n+            let kind = format_ident!(\"{}\", kind);\n+            quote! {\n+                pub fn #method_name(&self) -> AstChildren<#kind> {\n+                    AstChildren::new(&self.syntax)\n+                }\n+            }\n+        });\n+\n+        let options = ast_node.options.iter().map(|attr| {\n+            let method_name = match attr {\n+                Attr::Type(t) => format_ident!(\"{}\", to_lower_snake_case(&t)),\n+                Attr::NameType(n, _) => format_ident!(\"{}\", n),\n+            };\n+            let ty = match attr {\n+                Attr::Type(t) | Attr::NameType(_, t) => format_ident!(\"{}\", t),\n+            };\n+            quote! {\n+                pub fn #method_name(&self) -> Option<#ty> {\n+                    AstChildren::new(&self.syntax).next()\n+                }\n+            }\n+        });\n+\n+        quote! {\n+            #adt\n+\n+            #(#traits)*\n+\n+            impl #name {\n+                #(#collections)*\n+                #(#options)*\n+            }\n+        }\n+    });\n+\n+    let ast = quote! {\n+        use crate::{\n+            SyntaxNode, SyntaxKind::{self, *},\n+            ast::{self, AstNode, AstChildren},\n+        };\n+\n+        #(#nodes)*\n+    };\n+\n+    let pretty = reformat(ast)?;\n+    Ok(pretty)\n+}\n+\n+fn generate_syntax_kinds(grammar: &Grammar) -> Result<String> {\n+    let (single_byte_tokens_values, single_byte_tokens): (Vec<_>, Vec<_>) = grammar\n+        .punct\n+        .iter()\n+        .filter(|(token, _name)| token.len() == 1)\n+        .map(|(token, name)| (token.chars().next().unwrap(), format_ident!(\"{}\", name)))\n+        .unzip();\n+\n+    let punctuation_values = grammar.punct.iter().map(|(token, _name)| {\n+        if \"{}[]()\".contains(token) {\n+            let c = token.chars().next().unwrap();\n+            quote! { #c }\n+        } else {\n+            let cs = token.chars().map(|c| Punct::new(c, Spacing::Joint));\n+            quote! { #(#cs)* }\n+        }\n+    });\n+    let punctuation =\n+        grammar.punct.iter().map(|(_token, name)| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n+\n+    let full_keywords_values = &grammar.keywords;\n+    let full_keywords =\n+        full_keywords_values.iter().map(|kw| format_ident!(\"{}_KW\", to_upper_snake_case(&kw)));\n+\n+    let all_keywords_values =\n+        grammar.keywords.iter().chain(grammar.contextual_keywords.iter()).collect::<Vec<_>>();\n+    let all_keywords_idents = all_keywords_values.iter().map(|kw| format_ident!(\"{}\", kw));\n+    let all_keywords = all_keywords_values\n+        .iter()\n+        .map(|name| format_ident!(\"{}_KW\", to_upper_snake_case(&name)))\n+        .collect::<Vec<_>>();\n+\n+    let literals =\n+        grammar.literals.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n+\n+    let tokens = grammar.tokens.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n+\n+    let nodes = grammar.nodes.iter().map(|name| format_ident!(\"{}\", name)).collect::<Vec<_>>();\n+\n+    let ast = quote! {\n+        #![allow(bad_style, missing_docs, unreachable_pub)]\n+        /// The kind of syntax node, e.g. `IDENT`, `USE_KW`, or `STRUCT_DEF`.\n+        #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n+        #[repr(u16)]\n+        pub enum SyntaxKind {\n+            // Technical SyntaxKinds: they appear temporally during parsing,\n+            // but never end up in the final tree\n+            #[doc(hidden)]\n+            TOMBSTONE,\n+            #[doc(hidden)]\n+            EOF,\n+            #(#punctuation,)*\n+            #(#all_keywords,)*\n+            #(#literals,)*\n+            #(#tokens,)*\n+            #(#nodes,)*\n+\n+            // Technical kind so that we can cast from u16 safely\n+            #[doc(hidden)]\n+            __LAST,\n+        }\n+        use self::SyntaxKind::*;\n+\n+        impl SyntaxKind {\n+            pub fn is_keyword(self) -> bool {\n+                match self {\n+                    #(#all_keywords)|* => true,\n+                    _ => false,\n+                }\n+            }\n+\n+            pub fn is_punct(self) -> bool {\n+                match self {\n+                    #(#punctuation)|* => true,\n+                    _ => false,\n+                }\n+            }\n+\n+            pub fn is_literal(self) -> bool {\n+                match self {\n+                    #(#literals)|* => true,\n+                    _ => false,\n+                }\n+            }\n+\n+            pub fn from_keyword(ident: &str) -> Option<SyntaxKind> {\n+                let kw = match ident {\n+                    #(#full_keywords_values => #full_keywords,)*\n+                    _ => return None,\n+                };\n+                Some(kw)\n+            }\n+\n+            pub fn from_char(c: char) -> Option<SyntaxKind> {\n+                let tok = match c {\n+                    #(#single_byte_tokens_values => #single_byte_tokens,)*\n+                    _ => return None,\n+                };\n+                Some(tok)\n+            }\n+        }\n+\n+        #[macro_export]\n+        macro_rules! T {\n+            #((#punctuation_values) => { $crate::SyntaxKind::#punctuation };)*\n+            #((#all_keywords_idents) => { $crate::SyntaxKind::#all_keywords };)*\n+        }\n+    };\n+\n+    reformat(ast)\n+}\n+\n+fn reformat(text: impl std::fmt::Display) -> Result<String> {\n+    let mut rustfmt = Command::new(\"rustfmt\")\n+        .arg(\"--config-path\")\n+        .arg(project_root().join(\"rustfmt.toml\"))\n+        .stdin(Stdio::piped())\n+        .stdout(Stdio::piped())\n+        .spawn()?;\n+    write!(rustfmt.stdin.take().unwrap(), \"{}\", text)?;\n+    let output = rustfmt.wait_with_output()?;\n+    let stdout = String::from_utf8(output.stdout)?;\n+    let preamble = \"Generated file, do not edit by hand, see `crate/ra_tools/src/codegen`\";\n+    Ok(format!(\"//! {}\\n\\n{}\", preamble, stdout))\n+}\n+\n+#[derive(Deserialize, Debug)]\n+struct Grammar {\n+    punct: Vec<(String, String)>,\n+    keywords: Vec<String>,\n+    contextual_keywords: Vec<String>,\n+    literals: Vec<String>,\n+    tokens: Vec<String>,\n+    nodes: Vec<String>,\n+    ast: BTreeMap<String, AstNode>,\n+}\n+\n+#[derive(Deserialize, Debug)]\n+struct AstNode {\n+    #[serde(default)]\n+    #[serde(rename = \"enum\")]\n+    variants: Vec<String>,\n+\n+    #[serde(default)]\n+    traits: Vec<String>,\n+    #[serde(default)]\n+    collections: Vec<(String, String)>,\n+    #[serde(default)]\n+    options: Vec<Attr>,\n+}\n+\n+#[derive(Deserialize, Debug)]\n+#[serde(untagged)]\n+enum Attr {\n+    Type(String),\n+    NameType(String, String),\n+}\n+\n+fn to_upper_snake_case(s: &str) -> String {\n+    let mut buf = String::with_capacity(s.len());\n+    let mut prev_is_upper = None;\n+    for c in s.chars() {\n+        if c.is_ascii_uppercase() && prev_is_upper == Some(false) {\n+            buf.push('_')\n+        }\n+        prev_is_upper = Some(c.is_ascii_uppercase());\n+\n+        buf.push(c.to_ascii_uppercase());\n+    }\n+    buf\n+}\n+\n+fn to_lower_snake_case(s: &str) -> String {\n+    let mut buf = String::with_capacity(s.len());\n+    let mut prev_is_upper = None;\n+    for c in s.chars() {\n+        if c.is_ascii_uppercase() && prev_is_upper == Some(false) {\n+            buf.push('_')\n+        }\n+        prev_is_upper = Some(c.is_ascii_uppercase());\n+\n+        buf.push(c.to_ascii_lowercase());\n+    }\n+    buf\n+}"}, {"sha": "730eb5c615ed8d13ff89af340e9b92a213b60c32", "filename": "xtask/src/help.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fhelp.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fhelp.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fhelp.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -13,7 +13,6 @@ SUBCOMMANDS:\n     format-hook\n     fuzz-tests\n     codegen\n-    gen-tests\n     install\n     lint\";\n "}, {"sha": "cc69463a9826273474bc0dcf4677a7154c27f32e", "filename": "xtask/src/lib.rs", "status": "modified", "additions": 3, "deletions": 172, "changes": 175, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Flib.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -1,82 +1,21 @@\n //! FIXME: write short doc here\n \n-mod boilerplate_gen;\n+pub mod codegen;\n \n use std::{\n-    collections::HashMap,\n     error::Error,\n     fs,\n     io::{Error as IoError, ErrorKind},\n     path::{Path, PathBuf},\n     process::{Command, Output, Stdio},\n };\n \n-use itertools::Itertools;\n-\n-pub use self::boilerplate_gen::generate_boilerplate;\n+use crate::codegen::Mode;\n \n pub type Result<T> = std::result::Result<T, Box<dyn Error>>;\n \n-pub const GRAMMAR: &str = \"crates/ra_syntax/src/grammar.ron\";\n-const GRAMMAR_DIR: &str = \"crates/ra_parser/src/grammar\";\n-const OK_INLINE_TESTS_DIR: &str = \"crates/ra_syntax/test_data/parser/inline/ok\";\n-const ERR_INLINE_TESTS_DIR: &str = \"crates/ra_syntax/test_data/parser/inline/err\";\n-\n-pub const SYNTAX_KINDS: &str = \"crates/ra_parser/src/syntax_kind/generated.rs\";\n-pub const AST: &str = \"crates/ra_syntax/src/ast/generated.rs\";\n const TOOLCHAIN: &str = \"stable\";\n \n-#[derive(Debug, PartialEq, Eq, Clone, Copy)]\n-pub enum Mode {\n-    Overwrite,\n-    Verify,\n-}\n-pub use Mode::*;\n-\n-#[derive(Debug)]\n-pub struct Test {\n-    pub name: String,\n-    pub text: String,\n-    pub ok: bool,\n-}\n-\n-pub fn collect_tests(s: &str) -> Vec<(usize, Test)> {\n-    let mut res = vec![];\n-    let prefix = \"// \";\n-    let comment_blocks = s\n-        .lines()\n-        .map(str::trim_start)\n-        .enumerate()\n-        .group_by(|(_idx, line)| line.starts_with(prefix));\n-\n-    'outer: for (is_comment, block) in comment_blocks.into_iter() {\n-        if !is_comment {\n-            continue;\n-        }\n-        let mut block = block.map(|(idx, line)| (idx, &line[prefix.len()..]));\n-\n-        let mut ok = true;\n-        let (start_line, name) = loop {\n-            match block.next() {\n-                Some((idx, line)) if line.starts_with(\"test \") => {\n-                    break (idx, line[\"test \".len()..].to_string());\n-                }\n-                Some((idx, line)) if line.starts_with(\"test_err \") => {\n-                    ok = false;\n-                    break (idx, line[\"test_err \".len()..].to_string());\n-                }\n-                Some(_) => (),\n-                None => continue 'outer,\n-            }\n-        };\n-        let text: String =\n-            itertools::join(block.map(|(_, line)| line).chain(::std::iter::once(\"\")), \"\\n\");\n-        assert!(!text.trim().is_empty() && text.ends_with('\\n'));\n-        res.push((start_line, Test { name, text, ok }))\n-    }\n-    res\n-}\n-\n pub fn project_root() -> PathBuf {\n     Path::new(&env!(\"CARGO_MANIFEST_DIR\")).ancestors().nth(1).unwrap().to_path_buf()\n }\n@@ -126,7 +65,7 @@ pub fn run_rustfmt(mode: Mode) -> Result<()> {\n         _ => install_rustfmt()?,\n     };\n \n-    if mode == Verify {\n+    if mode == Mode::Verify {\n         run(&format!(\"rustup run {} -- cargo fmt -- --check\", TOOLCHAIN), \".\")?;\n     } else {\n         run(&format!(\"rustup run {} -- cargo fmt\", TOOLCHAIN), \".\")?;\n@@ -206,37 +145,6 @@ pub fn run_fuzzer() -> Result<()> {\n     run(\"rustup run nightly -- cargo fuzz run parser\", \"./crates/ra_syntax\")\n }\n \n-pub fn gen_tests(mode: Mode) -> Result<()> {\n-    let tests = tests_from_dir(&project_root().join(Path::new(GRAMMAR_DIR)))?;\n-    fn install_tests(tests: &HashMap<String, Test>, into: &str, mode: Mode) -> Result<()> {\n-        let tests_dir = project_root().join(into);\n-        if !tests_dir.is_dir() {\n-            fs::create_dir_all(&tests_dir)?;\n-        }\n-        // ok is never actually read, but it needs to be specified to create a Test in existing_tests\n-        let existing = existing_tests(&tests_dir, true)?;\n-        for t in existing.keys().filter(|&t| !tests.contains_key(t)) {\n-            panic!(\"Test is deleted: {}\", t);\n-        }\n-\n-        let mut new_idx = existing.len() + 1;\n-        for (name, test) in tests {\n-            let path = match existing.get(name) {\n-                Some((path, _test)) => path.clone(),\n-                None => {\n-                    let file_name = format!(\"{:04}_{}.rs\", new_idx, name);\n-                    new_idx += 1;\n-                    tests_dir.join(file_name)\n-                }\n-            };\n-            update(&path, &test.text, mode)?;\n-        }\n-        Ok(())\n-    }\n-    install_tests(&tests.ok, OK_INLINE_TESTS_DIR, mode)?;\n-    install_tests(&tests.err, ERR_INLINE_TESTS_DIR, mode)\n-}\n-\n fn do_run<F>(cmdline: &str, dir: &str, mut f: F) -> Result<Output>\n where\n     F: FnMut(&mut Command),\n@@ -253,80 +161,3 @@ where\n     }\n     Ok(output)\n }\n-\n-#[derive(Default, Debug)]\n-struct Tests {\n-    pub ok: HashMap<String, Test>,\n-    pub err: HashMap<String, Test>,\n-}\n-\n-fn tests_from_dir(dir: &Path) -> Result<Tests> {\n-    let mut res = Tests::default();\n-    for entry in ::walkdir::WalkDir::new(dir) {\n-        let entry = entry.unwrap();\n-        if !entry.file_type().is_file() {\n-            continue;\n-        }\n-        if entry.path().extension().unwrap_or_default() != \"rs\" {\n-            continue;\n-        }\n-        process_file(&mut res, entry.path())?;\n-    }\n-    let grammar_rs = dir.parent().unwrap().join(\"grammar.rs\");\n-    process_file(&mut res, &grammar_rs)?;\n-    return Ok(res);\n-    fn process_file(res: &mut Tests, path: &Path) -> Result<()> {\n-        let text = fs::read_to_string(path)?;\n-\n-        for (_, test) in collect_tests(&text) {\n-            if test.ok {\n-                if let Some(old_test) = res.ok.insert(test.name.clone(), test) {\n-                    Err(format!(\"Duplicate test: {}\", old_test.name))?\n-                }\n-            } else {\n-                if let Some(old_test) = res.err.insert(test.name.clone(), test) {\n-                    Err(format!(\"Duplicate test: {}\", old_test.name))?\n-                }\n-            }\n-        }\n-        Ok(())\n-    }\n-}\n-\n-fn existing_tests(dir: &Path, ok: bool) -> Result<HashMap<String, (PathBuf, Test)>> {\n-    let mut res = HashMap::new();\n-    for file in fs::read_dir(dir)? {\n-        let file = file?;\n-        let path = file.path();\n-        if path.extension().unwrap_or_default() != \"rs\" {\n-            continue;\n-        }\n-        let name = {\n-            let file_name = path.file_name().unwrap().to_str().unwrap();\n-            file_name[5..file_name.len() - 3].to_string()\n-        };\n-        let text = fs::read_to_string(&path)?;\n-        let test = Test { name: name.clone(), text, ok };\n-        if let Some(old) = res.insert(name, (path, test)) {\n-            println!(\"Duplicate test: {:?}\", old);\n-        }\n-    }\n-    Ok(res)\n-}\n-\n-/// A helper to update file on disk if it has changed.\n-/// With verify = false,\n-pub fn update(path: &Path, contents: &str, mode: Mode) -> Result<()> {\n-    match fs::read_to_string(path) {\n-        Ok(ref old_contents) if old_contents == contents => {\n-            return Ok(());\n-        }\n-        _ => (),\n-    }\n-    if mode == Verify {\n-        Err(format!(\"`{}` is not up-to-date\", path.display()))?;\n-    }\n-    eprintln!(\"updating {}\", path.display());\n-    fs::write(path, contents)?;\n-    Ok(())\n-}"}, {"sha": "db901ced2632890233cd0d7c553234a0b8534834", "filename": "xtask/src/main.rs", "status": "modified", "additions": 5, "deletions": 11, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Fsrc%2Fmain.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -7,8 +7,8 @@ use core::str;\n use pico_args::Arguments;\n use std::{env, path::PathBuf};\n use xtask::{\n-    gen_tests, generate_boilerplate, install_format_hook, run, run_clippy, run_fuzzer, run_rustfmt,\n-    run_with_output, Cmd, Overwrite, Result,\n+    codegen::{self, Mode},\n+    install_format_hook, run, run_clippy, run_fuzzer, run_rustfmt, run_with_output, Cmd, Result,\n };\n \n // Latest stable, feel free to send a PR if this lags behind.\n@@ -57,26 +57,20 @@ fn main() -> Result<()> {\n             };\n             install(opts)?\n         }\n-        \"gen-tests\" => {\n-            if matches.contains([\"-h\", \"--help\"]) {\n-                help::print_no_param_subcommand_help(&subcommand);\n-                return Ok(());\n-            }\n-            gen_tests(Overwrite)?\n-        }\n         \"codegen\" => {\n             if matches.contains([\"-h\", \"--help\"]) {\n                 help::print_no_param_subcommand_help(&subcommand);\n                 return Ok(());\n             }\n-            generate_boilerplate(Overwrite)?\n+            codegen::generate_syntax(Mode::Overwrite)?;\n+            codegen::generate_parser_tests(Mode::Overwrite)?;\n         }\n         \"format\" => {\n             if matches.contains([\"-h\", \"--help\"]) {\n                 help::print_no_param_subcommand_help(&subcommand);\n                 return Ok(());\n             }\n-            run_rustfmt(Overwrite)?\n+            run_rustfmt(Mode::Overwrite)?\n         }\n         \"format-hook\" => {\n             if matches.contains([\"-h\", \"--help\"]) {"}, {"sha": "543c7d7c4538e4980a8479563af5cf5a9fd799e3", "filename": "xtask/tests/tidy-tests/cli.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/2197205885f43441f14861f34449426295397dd9/xtask%2Ftests%2Ftidy-tests%2Fcli.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2197205885f43441f14861f34449426295397dd9/xtask%2Ftests%2Ftidy-tests%2Fcli.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/xtask%2Ftests%2Ftidy-tests%2Fcli.rs?ref=2197205885f43441f14861f34449426295397dd9", "patch": "@@ -1,23 +1,26 @@\n use walkdir::WalkDir;\n-use xtask::{gen_tests, generate_boilerplate, project_root, run_rustfmt, Verify};\n+use xtask::{\n+    codegen::{self, Mode},\n+    project_root, run_rustfmt,\n+};\n \n #[test]\n fn generated_grammar_is_fresh() {\n-    if let Err(error) = generate_boilerplate(Verify) {\n+    if let Err(error) = codegen::generate_syntax(Mode::Verify) {\n         panic!(\"{}. Please update it by running `cargo xtask codegen`\", error);\n     }\n }\n \n #[test]\n fn generated_tests_are_fresh() {\n-    if let Err(error) = gen_tests(Verify) {\n-        panic!(\"{}. Please update tests by running `cargo xtask gen-tests`\", error);\n+    if let Err(error) = codegen::generate_parser_tests(Mode::Verify) {\n+        panic!(\"{}. Please update tests by running `cargo xtask codegen`\", error);\n     }\n }\n \n #[test]\n fn check_code_formatting() {\n-    if let Err(error) = run_rustfmt(Verify) {\n+    if let Err(error) = run_rustfmt(Mode::Verify) {\n         panic!(\"{}. Please format the code by running `cargo format`\", error);\n     }\n }"}]}