{"sha": "0fee14bfddcf13f370c356b94d098dea7dca378d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBmZWUxNGJmZGRjZjEzZjM3MGMzNTZiOTRkMDk4ZGVhN2RjYTM3OGQ=", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-09-02T17:10:40Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2021-09-02T17:12:08Z"}, "message": "When descending tokens don't bail on failed macro call expansions", "tree": {"sha": "236560cd88fe61d305fe3a6c273f8b2219bef2d3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/236560cd88fe61d305fe3a6c273f8b2219bef2d3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0fee14bfddcf13f370c356b94d098dea7dca378d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0fee14bfddcf13f370c356b94d098dea7dca378d", "html_url": "https://github.com/rust-lang/rust/commit/0fee14bfddcf13f370c356b94d098dea7dca378d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0fee14bfddcf13f370c356b94d098dea7dca378d/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2aee17e556743aa16643f5efe74347b06fc563a5", "url": "https://api.github.com/repos/rust-lang/rust/commits/2aee17e556743aa16643f5efe74347b06fc563a5", "html_url": "https://github.com/rust-lang/rust/commit/2aee17e556743aa16643f5efe74347b06fc563a5"}], "stats": {"total": 106, "additions": 57, "deletions": 49}, "files": [{"sha": "de84a0f55bbe8eacfad0c03ee4d15ff27dfb1206", "filename": "crates/hir/src/semantics.rs", "status": "modified", "additions": 57, "deletions": 49, "changes": 106, "blob_url": "https://github.com/rust-lang/rust/blob/0fee14bfddcf13f370c356b94d098dea7dca378d/crates%2Fhir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0fee14bfddcf13f370c356b94d098dea7dca378d/crates%2Fhir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Fsemantics.rs?ref=0fee14bfddcf13f370c356b94d098dea7dca378d", "patch": "@@ -467,65 +467,73 @@ impl<'db> SemanticsImpl<'db> {\n         let mut queue = vec![InFile::new(sa.file_id, token)];\n         let mut cache = self.expansion_info_cache.borrow_mut();\n         let mut res = smallvec![];\n+        // Remap the next token in the queue into a macro call its in, if it is not being remapped\n+        // either due to not being in a macro-call or because its unused push it into the result vec,\n+        // otherwise push the remapped tokens back into the queue as they can potentially be remapped again.\n         while let Some(token) = queue.pop() {\n             self.db.unwind_if_cancelled();\n \n             let was_not_remapped = (|| {\n                 for node in token.value.ancestors() {\n-                    match_ast! {\n-                        match node {\n-                            ast::MacroCall(macro_call) => {\n-                                let tt = macro_call.token_tree()?;\n-                                let l_delim = match tt.left_delimiter_token() {\n-                                    Some(it) => it.text_range().end(),\n-                                    None => tt.syntax().text_range().start()\n-                                };\n-                                let r_delim = match tt.right_delimiter_token() {\n-                                    Some(it) => it.text_range().start(),\n-                                    None => tt.syntax().text_range().end()\n-                                };\n-                                if !TextRange::new(l_delim, r_delim).contains_range(token.value.text_range()) {\n-                                    return None;\n-                                }\n-                                let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-                                let tokens = cache\n-                                    .entry(file_id)\n-                                    .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                                    .as_ref()?\n-                                    .map_token_down(self.db.upcast(), None, token.as_ref())?;\n-\n-                                let len = queue.len();\n-                                queue.extend(tokens.inspect(|token| {\n-                                    if let Some(parent) = token.value.parent() {\n-                                        self.cache(find_root(&parent), token.file_id);\n-                                    }\n-                                }));\n-                                return (queue.len() != len).then(|| ());\n-                            },\n-                            ast::Item(item) => {\n-                                if let Some(call_id) = self.with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone()))) {\n-                                    let file_id = call_id.as_file();\n-                                    let tokens = cache\n-                                        .entry(file_id)\n-                                        .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n-                                        .as_ref()?\n-                                        .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n-\n-                                    let len = queue.len();\n-                                    queue.extend(tokens.inspect(|token| {\n-                                        if let Some(parent) = token.value.parent() {\n-                                            self.cache(find_root(&parent), token.file_id);\n-                                        }\n-                                    }));\n-                                    return (queue.len() != len).then(|| ());\n+                    if let Some(macro_call) = ast::MacroCall::cast(node.clone()) {\n+                        let tt = match macro_call.token_tree() {\n+                            Some(tt) => tt,\n+                            None => continue,\n+                        };\n+                        let l_delim = match tt.left_delimiter_token() {\n+                            Some(it) => it.text_range().end(),\n+                            None => tt.syntax().text_range().start(),\n+                        };\n+                        let r_delim = match tt.right_delimiter_token() {\n+                            Some(it) => it.text_range().start(),\n+                            None => tt.syntax().text_range().end(),\n+                        };\n+                        if !TextRange::new(l_delim, r_delim)\n+                            .contains_range(token.value.text_range())\n+                        {\n+                            continue;\n+                        }\n+                        let file_id = match sa.expand(self.db, token.with_value(&macro_call)) {\n+                            Some(file_id) => file_id,\n+                            None => continue,\n+                        };\n+                        let tokens = cache\n+                            .entry(file_id)\n+                            .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                            .as_ref()?\n+                            .map_token_down(self.db.upcast(), None, token.as_ref())?;\n+\n+                        let len = queue.len();\n+                        queue.extend(tokens.inspect(|token| {\n+                            if let Some(parent) = token.value.parent() {\n+                                self.cache(find_root(&parent), token.file_id);\n+                            }\n+                        }));\n+                        return (queue.len() != len).then(|| ());\n+                    } else if let Some(item) = ast::Item::cast(node.clone()) {\n+                        if let Some(call_id) = self\n+                            .with_ctx(|ctx| ctx.item_to_macro_call(token.with_value(item.clone())))\n+                        {\n+                            let file_id = call_id.as_file();\n+                            let tokens = cache\n+                                .entry(file_id)\n+                                .or_insert_with(|| file_id.expansion_info(self.db.upcast()))\n+                                .as_ref()?\n+                                .map_token_down(self.db.upcast(), Some(item), token.as_ref())?;\n+\n+                            let len = queue.len();\n+                            queue.extend(tokens.inspect(|token| {\n+                                if let Some(parent) = token.value.parent() {\n+                                    self.cache(find_root(&parent), token.file_id);\n                                 }\n-                            },\n-                            _ => {}\n+                            }));\n+                            return (queue.len() != len).then(|| ());\n                         }\n                     }\n                 }\n                 None\n-            })().is_none();\n+            })()\n+            .is_none();\n             if was_not_remapped {\n                 res.push(token.value)\n             }"}]}