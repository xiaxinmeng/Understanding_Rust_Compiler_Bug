{"sha": "5c93492da914f972fb549e95db778adcbdf70480", "node_id": "MDY6Q29tbWl0NzI0NzEyOjVjOTM0OTJkYTkxNGY5NzJmYjU0OWU5NWRiNzc4YWRjYmRmNzA0ODA=", "commit": {"author": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2019-10-09T20:29:02Z"}, "committer": {"name": "Nicholas Nethercote", "email": "nnethercote@mozilla.com", "date": "2019-10-13T22:14:39Z"}, "message": "Remove the `Option` in `TokenStream`.\n\nIt means an allocation is required to create an empty `TokenStream`, but\nall other operations are simpler and marginally faster due to not having\nto check for `None`. Overall it simplifies the code for a negligible\nperformance effect.\n\nThe commit also removes `TokenStream::empty` by implementing `Default`,\nwhich is now possible.", "tree": {"sha": "c80325183ecf62fe27acb5444fc27d255e8180b2", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/c80325183ecf62fe27acb5444fc27d255e8180b2"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5c93492da914f972fb549e95db778adcbdf70480", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5c93492da914f972fb549e95db778adcbdf70480", "html_url": "https://github.com/rust-lang/rust/commit/5c93492da914f972fb549e95db778adcbdf70480", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5c93492da914f972fb549e95db778adcbdf70480/comments", "author": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "committer": {"login": "nnethercote", "id": 1940286, "node_id": "MDQ6VXNlcjE5NDAyODY=", "avatar_url": "https://avatars.githubusercontent.com/u/1940286?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nnethercote", "html_url": "https://github.com/nnethercote", "followers_url": "https://api.github.com/users/nnethercote/followers", "following_url": "https://api.github.com/users/nnethercote/following{/other_user}", "gists_url": "https://api.github.com/users/nnethercote/gists{/gist_id}", "starred_url": "https://api.github.com/users/nnethercote/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nnethercote/subscriptions", "organizations_url": "https://api.github.com/users/nnethercote/orgs", "repos_url": "https://api.github.com/users/nnethercote/repos", "events_url": "https://api.github.com/users/nnethercote/events{/privacy}", "received_events_url": "https://api.github.com/users/nnethercote/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "20cc75272619cc452e3ae6c131e61974f6aa9929", "url": "https://api.github.com/repos/rust-lang/rust/commits/20cc75272619cc452e3ae6c131e61974f6aa9929", "html_url": "https://github.com/rust-lang/rust/commit/20cc75272619cc452e3ae6c131e61974f6aa9929"}], "stats": {"total": 246, "additions": 101, "deletions": 145}, "files": [{"sha": "c2c883fd20e7adbe6104108a6aec71faa25961b4", "filename": "src/libsyntax/attr/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fattr%2Fmod.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -551,7 +551,7 @@ impl MetaItem {\n impl MetaItemKind {\n     pub fn tokens(&self, span: Span) -> TokenStream {\n         match *self {\n-            MetaItemKind::Word => TokenStream::empty(),\n+            MetaItemKind::Word => TokenStream::default(),\n             MetaItemKind::NameValue(ref lit) => {\n                 let mut vec = vec![TokenTree::token(token::Eq, span).into()];\n                 lit.tokens().append_to_tree_and_joint_vec(&mut vec);"}, {"sha": "ec87451edbd1e2ecfdd3cb83d8fbba691647c669", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -671,12 +671,12 @@ impl<'a, 'b> MacroExpander<'a, 'b> {\n                 }\n             }\n             Some(TokenTree::Token(..)) => {}\n-            None => return TokenStream::empty(),\n+            None => return TokenStream::default(),\n         }\n         self.cx.span_err(span, \"custom attribute invocations must be \\\n             of the form `#[foo]` or `#[foo(..)]`, the macro name must only be \\\n             followed by a delimiter token\");\n-        TokenStream::empty()\n+        TokenStream::default()\n     }\n \n     fn gate_proc_macro_attr_item(&self, span: Span, item: &Annotatable) {"}, {"sha": "da930436d817b6d57a474a4270f9c58766bf2835", "filename": "src/libsyntax/ext/mbe/transcribe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fmbe%2Ftranscribe.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -95,7 +95,7 @@ pub(super) fn transcribe(\n ) -> TokenStream {\n     // Nothing for us to transcribe...\n     if src.is_empty() {\n-        return TokenStream::empty();\n+        return TokenStream::default();\n     }\n \n     // We descend into the RHS (`src`), expanding things as we go. This stack contains the things"}, {"sha": "43a49dbeb5161f120d837f6a3de8274cbbac1e47", "filename": "src/libsyntax/ext/placeholders.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fplaceholders.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fplaceholders.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fplaceholders.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -15,7 +15,7 @@ pub fn placeholder(kind: AstFragmentKind, id: ast::NodeId) -> AstFragment {\n     fn mac_placeholder() -> ast::Mac {\n         ast::Mac {\n             path: ast::Path { span: DUMMY_SP, segments: Vec::new() },\n-            tts: TokenStream::empty().into(),\n+            tts: TokenStream::default().into(),\n             delim: ast::MacDelimiter::Brace,\n             span: DUMMY_SP,\n             prior_type_ascription: None,"}, {"sha": "27ac8a2b78e941340e4c11b712fcc767e67199ba", "filename": "src/libsyntax/ext/proc_macro_server.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fproc_macro_server.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -393,7 +393,7 @@ impl server::Types for Rustc<'_> {\n \n impl server::TokenStream for Rustc<'_> {\n     fn new(&mut self) -> Self::TokenStream {\n-        TokenStream::empty()\n+        TokenStream::default()\n     }\n     fn is_empty(&mut self, stream: &Self::TokenStream) -> bool {\n         stream.is_empty()"}, {"sha": "60ee17d09b7557dcb42cbceb6fe1abdd0632737d", "filename": "src/libsyntax/mut_visit.rs", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fmut_visit.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fmut_visit.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fmut_visit.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -610,10 +610,8 @@ pub fn noop_visit_tt<T: MutVisitor>(tt: &mut TokenTree, vis: &mut T) {\n }\n \n pub fn noop_visit_tts<T: MutVisitor>(TokenStream(tts): &mut TokenStream, vis: &mut T) {\n-    visit_opt(tts, |tts| {\n-        let tts = Lrc::make_mut(tts);\n-        visit_vec(tts, |(tree, _is_joint)| vis.visit_tt(tree));\n-    })\n+    let tts = Lrc::make_mut(tts);\n+    visit_vec(tts, |(tree, _is_joint)| vis.visit_tt(tree));\n }\n \n // Applies ident visitor if it's an ident; applies other visits to interpolated nodes."}, {"sha": "0963efcfc8ac082610d73722eb80b1f3d11f1ce3", "filename": "src/libsyntax/parse/attr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fparse%2Fattr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Fparse%2Fattr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fattr.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -203,7 +203,7 @@ impl<'a> Parser<'a> {\n                 };\n                 TokenStream::from_streams(smallvec![eq.into(), tokens])\n             } else {\n-                TokenStream::empty()\n+                TokenStream::default()\n             };\n             ast::AttrItem { path, tokens }\n         })"}, {"sha": "d2def5630e6f46d13f2fc58f29c8509a4ac69d94", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 91, "deletions": 133, "changes": 224, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -137,13 +137,8 @@ impl TokenTree {\n /// The goal is for procedural macros to work with `TokenStream`s and `TokenTree`s\n /// instead of a representation of the abstract syntax tree.\n /// Today's `TokenTree`s can still contain AST via `token::Interpolated` for back-compat.\n-///\n-/// The use of `Option` is an optimization that avoids the need for an\n-/// allocation when the stream is empty. However, it is not guaranteed that an\n-/// empty stream is represented with `None`; it may be represented as a `Some`\n-/// around an empty `Vec`.\n-#[derive(Clone, Debug)]\n-pub struct TokenStream(pub Option<Lrc<Vec<TreeAndJoint>>>);\n+#[derive(Clone, Debug, Default)]\n+pub struct TokenStream(pub Lrc<Vec<TreeAndJoint>>);\n \n pub type TreeAndJoint = (TokenTree, IsJoint);\n \n@@ -164,36 +159,34 @@ impl TokenStream {\n     /// separating the two arguments with a comma for diagnostic suggestions.\n     pub(crate) fn add_comma(&self) -> Option<(TokenStream, Span)> {\n         // Used to suggest if a user writes `foo!(a b);`\n-        if let Some(ref stream) = self.0 {\n-            let mut suggestion = None;\n-            let mut iter = stream.iter().enumerate().peekable();\n-            while let Some((pos, ts)) = iter.next() {\n-                if let Some((_, next)) = iter.peek() {\n-                    let sp = match (&ts, &next) {\n-                        (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n-                        ((TokenTree::Token(token_left), NonJoint),\n-                         (TokenTree::Token(token_right), _))\n-                        if ((token_left.is_ident() && !token_left.is_reserved_ident())\n-                            || token_left.is_lit()) &&\n-                            ((token_right.is_ident() && !token_right.is_reserved_ident())\n-                            || token_right.is_lit()) => token_left.span,\n-                        ((TokenTree::Delimited(sp, ..), NonJoint), _) => sp.entire(),\n-                        _ => continue,\n-                    };\n-                    let sp = sp.shrink_to_hi();\n-                    let comma = (TokenTree::token(token::Comma, sp), NonJoint);\n-                    suggestion = Some((pos, comma, sp));\n-                }\n-            }\n-            if let Some((pos, comma, sp)) = suggestion {\n-                let mut new_stream = vec![];\n-                let parts = stream.split_at(pos + 1);\n-                new_stream.extend_from_slice(parts.0);\n-                new_stream.push(comma);\n-                new_stream.extend_from_slice(parts.1);\n-                return Some((TokenStream::new(new_stream), sp));\n+        let mut suggestion = None;\n+        let mut iter = self.0.iter().enumerate().peekable();\n+        while let Some((pos, ts)) = iter.next() {\n+            if let Some((_, next)) = iter.peek() {\n+                let sp = match (&ts, &next) {\n+                    (_, (TokenTree::Token(Token { kind: token::Comma, .. }), _)) => continue,\n+                    ((TokenTree::Token(token_left), NonJoint),\n+                     (TokenTree::Token(token_right), _))\n+                    if ((token_left.is_ident() && !token_left.is_reserved_ident())\n+                        || token_left.is_lit()) &&\n+                        ((token_right.is_ident() && !token_right.is_reserved_ident())\n+                        || token_right.is_lit()) => token_left.span,\n+                    ((TokenTree::Delimited(sp, ..), NonJoint), _) => sp.entire(),\n+                    _ => continue,\n+                };\n+                let sp = sp.shrink_to_hi();\n+                let comma = (TokenTree::token(token::Comma, sp), NonJoint);\n+                suggestion = Some((pos, comma, sp));\n             }\n         }\n+        if let Some((pos, comma, sp)) = suggestion {\n+            let mut new_stream = vec![];\n+            let parts = self.0.split_at(pos + 1);\n+            new_stream.extend_from_slice(parts.0);\n+            new_stream.push(comma);\n+            new_stream.extend_from_slice(parts.1);\n+            return Some((TokenStream::new(new_stream), sp));\n+        }\n         None\n     }\n }\n@@ -225,28 +218,21 @@ impl PartialEq<TokenStream> for TokenStream {\n }\n \n impl TokenStream {\n-    pub fn len(&self) -> usize {\n-        if let Some(ref slice) = self.0 {\n-            slice.len()\n-        } else {\n-            0\n-        }\n+    pub fn new(streams: Vec<TreeAndJoint>) -> TokenStream {\n+        TokenStream(Lrc::new(streams))\n     }\n \n-    pub fn empty() -> TokenStream {\n-        TokenStream(None)\n+    pub fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n     }\n \n-    pub fn is_empty(&self) -> bool {\n-        match self.0 {\n-            None => true,\n-            Some(ref stream) => stream.is_empty(),\n-        }\n+    pub fn len(&self) -> usize {\n+        self.0.len()\n     }\n \n     pub(crate) fn from_streams(mut streams: SmallVec<[TokenStream; 2]>) -> TokenStream {\n         match streams.len() {\n-            0 => TokenStream::empty(),\n+            0 => TokenStream::default(),\n             1 => streams.pop().unwrap(),\n             _ => {\n                 // We are going to extend the first stream in `streams` with\n@@ -270,41 +256,24 @@ impl TokenStream {\n                 // Get the first stream. If it's `None`, create an empty\n                 // stream.\n                 let mut iter = streams.drain();\n-                let mut first_stream_lrc = match iter.next().unwrap().0 {\n-                    Some(first_stream_lrc) => first_stream_lrc,\n-                    None => Lrc::new(vec![]),\n-                };\n+                let mut first_stream_lrc = iter.next().unwrap().0;\n \n                 // Append the elements to the first stream, after reserving\n                 // space for them.\n                 let first_vec_mut = Lrc::make_mut(&mut first_stream_lrc);\n                 first_vec_mut.reserve(num_appends);\n                 for stream in iter {\n-                    if let Some(stream) = stream.0 {\n-                        first_vec_mut.extend(stream.iter().cloned());\n-                    }\n+                    first_vec_mut.extend(stream.0.iter().cloned());\n                 }\n \n                 // Create the final `TokenStream`.\n-                match first_vec_mut.len() {\n-                    0 => TokenStream(None),\n-                    _ => TokenStream(Some(first_stream_lrc)),\n-                }\n+                TokenStream(first_stream_lrc)\n             }\n         }\n     }\n \n-    pub fn new(streams: Vec<TreeAndJoint>) -> TokenStream {\n-        match streams.len() {\n-            0 => TokenStream(None),\n-            _ => TokenStream(Some(Lrc::new(streams))),\n-        }\n-    }\n-\n     pub fn append_to_tree_and_joint_vec(self, vec: &mut Vec<TreeAndJoint>) {\n-        if let Some(stream) = self.0 {\n-            vec.extend(stream.iter().cloned());\n-        }\n+        vec.extend(self.0.iter().cloned());\n     }\n \n     pub fn trees(&self) -> Cursor {\n@@ -371,24 +340,22 @@ impl TokenStream {\n     }\n \n     pub fn map_enumerated<F: FnMut(usize, TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        TokenStream(self.0.map(|stream| {\n-            Lrc::new(\n-                stream\n-                    .iter()\n-                    .enumerate()\n-                    .map(|(i, (tree, is_joint))| (f(i, tree.clone()), *is_joint))\n-                    .collect())\n-        }))\n+        TokenStream(Lrc::new(\n+            self.0\n+                .iter()\n+                .enumerate()\n+                .map(|(i, (tree, is_joint))| (f(i, tree.clone()), *is_joint))\n+                .collect()\n+        ))\n     }\n \n     pub fn map<F: FnMut(TokenTree) -> TokenTree>(self, mut f: F) -> TokenStream {\n-        TokenStream(self.0.map(|stream| {\n-            Lrc::new(\n-                stream\n-                    .iter()\n-                    .map(|(tree, is_joint)| (f(tree.clone()), *is_joint))\n-                    .collect())\n-        }))\n+        TokenStream(Lrc::new(\n+            self.0\n+                .iter()\n+                .map(|(tree, is_joint)| (f(tree.clone()), *is_joint))\n+                .collect()\n+        ))\n     }\n }\n \n@@ -406,44 +373,43 @@ impl TokenStreamBuilder {\n \n         // If `self` is not empty and the last tree within the last stream is a\n         // token tree marked with `Joint`...\n-        if let Some(TokenStream(Some(ref mut last_stream_lrc))) = self.0.last_mut() {\n+        if let Some(TokenStream(ref mut last_stream_lrc)) = self.0.last_mut() {\n             if let Some((TokenTree::Token(last_token), Joint)) = last_stream_lrc.last() {\n \n                 // ...and `stream` is not empty and the first tree within it is\n                 // a token tree...\n-                if let TokenStream(Some(ref mut stream_lrc)) = stream {\n-                    if let Some((TokenTree::Token(token), is_joint)) = stream_lrc.first() {\n-\n-                        // ...and the two tokens can be glued together...\n-                        if let Some(glued_tok) = last_token.glue(&token) {\n-\n-                            // ...then do so, by overwriting the last token\n-                            // tree in `self` and removing the first token tree\n-                            // from `stream`. This requires using `make_mut()`\n-                            // on the last stream in `self` and on `stream`,\n-                            // and in practice this doesn't cause cloning 99.9%\n-                            // of the time.\n-\n-                            // Overwrite the last token tree with the merged\n-                            // token.\n-                            let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n-                            *last_vec_mut.last_mut().unwrap() =\n-                                (TokenTree::Token(glued_tok), *is_joint);\n-\n-                            // Remove the first token tree from `stream`. (This\n-                            // is almost always the only tree in `stream`.)\n-                            let stream_vec_mut = Lrc::make_mut(stream_lrc);\n-                            stream_vec_mut.remove(0);\n-\n-                            // Don't push `stream` if it's empty -- that could\n-                            // block subsequent token gluing, by getting\n-                            // between two token trees that should be glued\n-                            // together.\n-                            if !stream.is_empty() {\n-                                self.0.push(stream);\n-                            }\n-                            return;\n+                let TokenStream(ref mut stream_lrc) = stream;\n+                if let Some((TokenTree::Token(token), is_joint)) = stream_lrc.first() {\n+\n+                    // ...and the two tokens can be glued together...\n+                    if let Some(glued_tok) = last_token.glue(&token) {\n+\n+                        // ...then do so, by overwriting the last token\n+                        // tree in `self` and removing the first token tree\n+                        // from `stream`. This requires using `make_mut()`\n+                        // on the last stream in `self` and on `stream`,\n+                        // and in practice this doesn't cause cloning 99.9%\n+                        // of the time.\n+\n+                        // Overwrite the last token tree with the merged\n+                        // token.\n+                        let last_vec_mut = Lrc::make_mut(last_stream_lrc);\n+                        *last_vec_mut.last_mut().unwrap() =\n+                            (TokenTree::Token(glued_tok), *is_joint);\n+\n+                        // Remove the first token tree from `stream`. (This\n+                        // is almost always the only tree in `stream`.)\n+                        let stream_vec_mut = Lrc::make_mut(stream_lrc);\n+                        stream_vec_mut.remove(0);\n+\n+                        // Don't push `stream` if it's empty -- that could\n+                        // block subsequent token gluing, by getting\n+                        // between two token trees that should be glued\n+                        // together.\n+                        if !stream.is_empty() {\n+                            self.0.push(stream);\n                         }\n+                        return;\n                     }\n                 }\n             }\n@@ -476,16 +442,11 @@ impl Cursor {\n     }\n \n     pub fn next_with_joint(&mut self) -> Option<TreeAndJoint> {\n-        match self.stream.0 {\n-            None => None,\n-            Some(ref stream) => {\n-                if self.index < stream.len() {\n-                    self.index += 1;\n-                    Some(stream[self.index - 1].clone())\n-                } else {\n-                    None\n-                }\n-            }\n+        if self.index < self.stream.len() {\n+            self.index += 1;\n+            Some(self.stream.0[self.index - 1].clone())\n+        } else {\n+            None\n         }\n     }\n \n@@ -494,16 +455,13 @@ impl Cursor {\n             return;\n         }\n         let index = self.index;\n-        let stream = mem::replace(&mut self.stream, TokenStream(None));\n+        let stream = mem::take(&mut self.stream);\n         *self = TokenStream::from_streams(smallvec![stream, new_stream]).into_trees();\n         self.index = index;\n     }\n \n     pub fn look_ahead(&self, n: usize) -> Option<TokenTree> {\n-        match self.stream.0 {\n-            None => None,\n-            Some(ref stream) => stream[self.index ..].get(n).map(|(tree, _)| tree.clone()),\n-        }\n+        self.stream.0[self.index ..].get(n).map(|(tree, _)| tree.clone())\n     }\n }\n "}, {"sha": "62c7e188eba27e5fad48b6cae0e18a43fa1b063f", "filename": "src/libsyntax_ext/plugin_macro_defs.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/5c93492da914f972fb549e95db778adcbdf70480/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax_ext%2Fplugin_macro_defs.rs?ref=5c93492da914f972fb549e95db778adcbdf70480", "patch": "@@ -20,7 +20,7 @@ fn plugin_macro_def(name: Name, span: Span) -> P<Item> {\n         attr::mk_word_item(Ident::new(sym::rustc_builtin_macro, span)));\n \n     let parens: TreeAndJoint = TokenTree::Delimited(\n-        DelimSpan::from_single(span), token::Paren, TokenStream::empty()\n+        DelimSpan::from_single(span), token::Paren, TokenStream::default()\n     ).into();\n     let trees = vec![parens.clone(), TokenTree::token(token::FatArrow, span).into(), parens];\n "}]}