{"sha": "05906da0ec54fa218b4f395086e21af01ecec40a", "node_id": "C_kwDOAAsO6NoAKDA1OTA2ZGEwZWM1NGZhMjE4YjRmMzk1MDg2ZTIxYWYwMWVjZWM0MGE", "commit": {"author": {"name": "hkalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2022-12-06T22:29:38Z"}, "committer": {"name": "hkalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2022-12-06T22:29:38Z"}, "message": "use rustc crates instead of copy paste", "tree": {"sha": "a379910c05817ba1efdb000b0687995599ee089f", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/a379910c05817ba1efdb000b0687995599ee089f"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/05906da0ec54fa218b4f395086e21af01ecec40a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/05906da0ec54fa218b4f395086e21af01ecec40a", "html_url": "https://github.com/rust-lang/rust/commit/05906da0ec54fa218b4f395086e21af01ecec40a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/05906da0ec54fa218b4f395086e21af01ecec40a/comments", "author": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "committer": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f2c95021855f6a2a54238d0c90cc3a6420d66d69", "url": "https://api.github.com/repos/rust-lang/rust/commits/f2c95021855f6a2a54238d0c90cc3a6420d66d69", "html_url": "https://github.com/rust-lang/rust/commit/f2c95021855f6a2a54238d0c90cc3a6420d66d69"}], "stats": {"total": 2368, "additions": 288, "deletions": 2080}, "files": [{"sha": "589e9322279d36ca2ecc68b51b70972bfc5f9962", "filename": "Cargo.lock", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -510,6 +510,8 @@ dependencies = [\n  \"fst\",\n  \"hashbrown\",\n  \"hir-expand\",\n+ \"hkalbasi-rustc-ap-rustc_abi\",\n+ \"hkalbasi-rustc-ap-rustc_index\",\n  \"indexmap\",\n  \"itertools\",\n  \"la-arena\",\n@@ -564,6 +566,7 @@ dependencies = [\n  \"expect-test\",\n  \"hir-def\",\n  \"hir-expand\",\n+ \"hkalbasi-rustc-ap-rustc_index\",\n  \"itertools\",\n  \"la-arena\",\n  \"limit\",\n@@ -581,6 +584,27 @@ dependencies = [\n  \"typed-arena\",\n ]\n \n+[[package]]\n+name = \"hkalbasi-rustc-ap-rustc_abi\"\n+version = \"0.0.20221125\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"29c8368a30e518c0102d670d8515f7d424d875ee615ec7a7b6d29217b57a0371\"\n+dependencies = [\n+ \"bitflags\",\n+ \"hkalbasi-rustc-ap-rustc_index\",\n+ \"tracing\",\n+]\n+\n+[[package]]\n+name = \"hkalbasi-rustc-ap-rustc_index\"\n+version = \"0.0.20221125\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"c07bba80d7f6a8e1efb0f3e2115ef1eecbf97292dc8cad84e4982226b9aa12e2\"\n+dependencies = [\n+ \"arrayvec\",\n+ \"smallvec\",\n+]\n+\n [[package]]\n name = \"home\"\n version = \"0.5.4\""}, {"sha": "9ecce46601b65f9ccee1da7d686c6b5e33b68a08", "filename": "crates/hir-def/Cargo.toml", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2FCargo.toml?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -33,6 +33,8 @@ base-db = { path = \"../base-db\", version = \"0.0.0\" }\n syntax = { path = \"../syntax\", version = \"0.0.0\" }\n profile = { path = \"../profile\", version = \"0.0.0\" }\n hir-expand = { path = \"../hir-expand\", version = \"0.0.0\" }\n+rustc_abi = { version = \"0.0.20221125\", package = \"hkalbasi-rustc-ap-rustc_abi\", default-features = false }\n+rustc_index = { version = \"0.0.20221125\", package = \"hkalbasi-rustc-ap-rustc_index\", default-features = false }\n mbe = { path = \"../mbe\", version = \"0.0.0\" }\n cfg = { path = \"../cfg\", version = \"0.0.0\" }\n tt = { path = \"../tt\", version = \"0.0.0\" }"}, {"sha": "feed4321489209772db0110ae16750c5582cf81a", "filename": "crates/hir-def/src/adt.rs", "status": "modified", "additions": 22, "deletions": 4, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2Fsrc%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2Fsrc%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Fadt.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -9,6 +9,7 @@ use hir_expand::{\n     HirFileId, InFile,\n };\n use la_arena::{Arena, ArenaMap};\n+use rustc_abi::{Integer, IntegerType};\n use syntax::ast::{self, HasName, HasVisibility};\n use tt::{Delimiter, DelimiterKind, Leaf, Subtree, TokenTree};\n \n@@ -127,15 +128,32 @@ fn parse_repr_tt(tt: &Subtree) -> Option<ReprOptions> {\n                         .map(Either::Left)\n                         .or_else(|| BuiltinUint::from_suffix(repr).map(Either::Right))\n                     {\n-                        int = Some(builtin);\n+                        int = Some(match builtin {\n+                            Either::Left(bi) => match bi {\n+                                BuiltinInt::Isize => IntegerType::Pointer(true),\n+                                BuiltinInt::I8 => IntegerType::Fixed(Integer::I8, true),\n+                                BuiltinInt::I16 => IntegerType::Fixed(Integer::I16, true),\n+                                BuiltinInt::I32 => IntegerType::Fixed(Integer::I32, true),\n+                                BuiltinInt::I64 => IntegerType::Fixed(Integer::I64, true),\n+                                BuiltinInt::I128 => IntegerType::Fixed(Integer::I128, true),\n+                            },\n+                            Either::Right(bu) => match bu {\n+                                BuiltinUint::Usize => IntegerType::Pointer(false),\n+                                BuiltinUint::U8 => IntegerType::Fixed(Integer::I8, false),\n+                                BuiltinUint::U16 => IntegerType::Fixed(Integer::I16, false),\n+                                BuiltinUint::U32 => IntegerType::Fixed(Integer::I32, false),\n+                                BuiltinUint::U64 => IntegerType::Fixed(Integer::I64, false),\n+                                BuiltinUint::U128 => IntegerType::Fixed(Integer::I128, false),\n+                            },\n+                        });\n                     }\n                     ReprFlags::empty()\n                 }\n             })\n         }\n     }\n \n-    Some(ReprOptions { int, align: max_align, pack: min_pack, flags })\n+    Some(ReprOptions { int, align: max_align, pack: min_pack, flags, field_shuffle_seed: 0 })\n }\n \n impl StructData {\n@@ -276,10 +294,10 @@ impl EnumData {\n         Some(id)\n     }\n \n-    pub fn variant_body_type(&self) -> Either<BuiltinInt, BuiltinUint> {\n+    pub fn variant_body_type(&self) -> IntegerType {\n         match self.repr {\n             Some(ReprOptions { int: Some(builtin), .. }) => builtin,\n-            _ => Either::Left(BuiltinInt::Isize),\n+            _ => IntegerType::Pointer(true),\n         }\n     }\n }"}, {"sha": "a427c464bc02dbe0e30c0ebc295fadcf6ef7d6ee", "filename": "crates/hir-def/src/layout.rs", "status": "modified", "additions": 30, "deletions": 1107, "changes": 1137, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2Fsrc%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-def%2Fsrc%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-def%2Fsrc%2Flayout.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -1,419 +1,48 @@\n-//! Definitions related to binary representations of types\n+//! Definitions needed for computing data layout of types.\n \n-use bitflags::bitflags;\n-use either::Either;\n-use std::{\n-    cmp, fmt,\n-    num::NonZeroUsize,\n-    ops::{Add, AddAssign, Mul, Sub},\n-};\n+use std::cmp;\n \n-use crate::{\n-    builtin_type::{BuiltinInt, BuiltinUint},\n-    LocalEnumVariantId,\n+use la_arena::{Idx, RawIdx};\n+pub use rustc_abi::{\n+    Abi, AbiAndPrefAlign, AddressSpace, Align, Endian, FieldsShape, Integer, IntegerType,\n+    LayoutCalculator, Niche, Primitive, ReprFlags, ReprOptions, Scalar, Size, StructKind,\n+    TargetDataLayout, WrappingRange,\n };\n-use la_arena::ArenaMap;\n-\n-/// Size of a type in bytes.\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n-pub struct Size {\n-    raw: u64,\n-}\n-\n-// This is debug-printed a lot in larger structs, don't waste too much space there\n-impl fmt::Debug for Size {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"Size({} bytes)\", self.raw)\n-    }\n-}\n-\n-// Panicking addition, subtraction and multiplication for convenience.\n-// Avoid during layout computation, return `LayoutError` instead.\n-\n-impl Add for Size {\n-    type Output = Size;\n-    #[inline]\n-    fn add(self, other: Size) -> Size {\n-        Size::from_bytes(self.bytes().checked_add(other.bytes()).unwrap_or_else(|| {\n-            panic!(\"Size::add: {} + {} doesn't fit in u64\", self.bytes(), other.bytes())\n-        }))\n-    }\n-}\n-\n-impl Sub for Size {\n-    type Output = Size;\n-    #[inline]\n-    fn sub(self, other: Size) -> Size {\n-        Size::from_bytes(self.bytes().checked_sub(other.bytes()).unwrap_or_else(|| {\n-            panic!(\"Size::sub: {} - {} would result in negative size\", self.bytes(), other.bytes())\n-        }))\n-    }\n-}\n-\n-impl Mul<Size> for u64 {\n-    type Output = Size;\n-    #[inline]\n-    fn mul(self, size: Size) -> Size {\n-        size * self\n-    }\n-}\n-\n-impl Mul<u64> for Size {\n-    type Output = Size;\n-    #[inline]\n-    fn mul(self, count: u64) -> Size {\n-        match self.bytes().checked_mul(count) {\n-            Some(bytes) => Size::from_bytes(bytes),\n-            None => panic!(\"Size::mul: {} * {} doesn't fit in u64\", self.bytes(), count),\n-        }\n-    }\n-}\n-\n-impl AddAssign for Size {\n-    #[inline]\n-    fn add_assign(&mut self, other: Size) {\n-        *self = *self + other;\n-    }\n-}\n-\n-impl Size {\n-    pub const ZERO: Size = Size { raw: 0 };\n-\n-    /// Rounds `bits` up to the next-higher byte boundary, if `bits` is\n-    /// not a multiple of 8.\n-    pub fn from_bits(bits: impl TryInto<u64>) -> Size {\n-        let bits = bits.try_into().ok().unwrap();\n-        // Avoid potential overflow from `bits + 7`.\n-        Size { raw: bits / 8 + ((bits % 8) + 7) / 8 }\n-    }\n-\n-    #[inline]\n-    pub fn from_bytes(bytes: impl TryInto<u64>) -> Size {\n-        let bytes: u64 = bytes.try_into().ok().unwrap();\n-        Size { raw: bytes }\n-    }\n-\n-    #[inline]\n-    pub fn bytes(self) -> u64 {\n-        self.raw\n-    }\n-\n-    #[inline]\n-    pub fn bytes_usize(self) -> usize {\n-        self.bytes().try_into().unwrap()\n-    }\n-\n-    #[inline]\n-    pub fn bits(self) -> u64 {\n-        #[cold]\n-        fn overflow(bytes: u64) -> ! {\n-            panic!(\"Size::bits: {} bytes in bits doesn't fit in u64\", bytes)\n-        }\n-\n-        self.bytes().checked_mul(8).unwrap_or_else(|| overflow(self.bytes()))\n-    }\n-\n-    #[inline]\n-    pub fn bits_usize(self) -> usize {\n-        self.bits().try_into().unwrap()\n-    }\n-\n-    #[inline]\n-    pub fn checked_add(self, offset: Size, dl: &TargetDataLayout) -> Option<Size> {\n-        let bytes = self.bytes().checked_add(offset.bytes())?;\n \n-        if bytes < dl.obj_size_bound() {\n-            Some(Size::from_bytes(bytes))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn checked_mul(self, count: u64, dl: &TargetDataLayout) -> Option<Size> {\n-        let bytes = self.bytes().checked_mul(count)?;\n-        if bytes < dl.obj_size_bound() {\n-            Some(Size::from_bytes(bytes))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn align_to(self, align: Align) -> Size {\n-        let mask = align.bytes() - 1;\n-        Size::from_bytes((self.bytes() + mask) & !mask)\n-    }\n-\n-    #[inline]\n-    pub fn is_aligned(self, align: Align) -> bool {\n-        let mask = align.bytes() - 1;\n-        self.bytes() & mask == 0\n-    }\n-\n-    /// Truncates `value` to `self` bits and then sign-extends it to 128 bits\n-    /// (i.e., if it is negative, fill with 1's on the left).\n-    #[inline]\n-    pub fn sign_extend(self, value: u128) -> u128 {\n-        let size = self.bits();\n-        if size == 0 {\n-            // Truncated until nothing is left.\n-            return 0;\n-        }\n-        // Sign-extend it.\n-        let shift = 128 - size;\n-        // Shift the unsigned value to the left, then shift back to the right as signed\n-        // (essentially fills with sign bit on the left).\n-        (((value << shift) as i128) >> shift) as u128\n-    }\n-\n-    /// Truncates `value` to `self` bits.\n-    #[inline]\n-    pub fn truncate(self, value: u128) -> u128 {\n-        let size = self.bits();\n-        if size == 0 {\n-            // Truncated until nothing is left.\n-            return 0;\n-        }\n-        let shift = 128 - size;\n-        // Truncate (shift left to drop out leftover values, shift right to fill with zeroes).\n-        (value << shift) >> shift\n-    }\n+use crate::LocalEnumVariantId;\n \n-    #[inline]\n-    pub fn signed_int_min(&self) -> i128 {\n-        self.sign_extend(1_u128 << (self.bits() - 1)) as i128\n-    }\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n+pub struct RustcEnumVariantIdx(pub LocalEnumVariantId);\n \n-    #[inline]\n-    pub fn signed_int_max(&self) -> i128 {\n-        i128::MAX >> (128 - self.bits())\n+impl rustc_index::vec::Idx for RustcEnumVariantIdx {\n+    fn new(idx: usize) -> Self {\n+        RustcEnumVariantIdx(Idx::from_raw(RawIdx::from(idx as u32)))\n     }\n \n-    #[inline]\n-    pub fn unsigned_int_max(&self) -> u128 {\n-        u128::MAX >> (128 - self.bits())\n+    fn index(self) -> usize {\n+        u32::from(self.0.into_raw()) as usize\n     }\n }\n \n-#[derive(Copy, Clone, Debug)]\n-pub enum StructKind {\n-    /// A tuple, closure, or univariant which cannot be coerced to unsized.\n-    AlwaysSized,\n-    /// A univariant, the last field of which may be coerced to unsized.\n-    MaybeUnsized,\n-    /// A univariant, but with a prefix of an arbitrary size & alignment (e.g., enum tag).\n-    Prefixed(Size, Align),\n-}\n-\n-/// Describes how the fields of a type are located in memory.\n-#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n-pub enum FieldsShape {\n-    /// Scalar primitives and `!`, which never have fields.\n-    Primitive,\n-\n-    /// All fields start at no offset. The `usize` is the field count.\n-    Union(NonZeroUsize),\n-\n-    /// Array/vector-like placement, with all fields of identical types.\n-    Array { stride: Size, count: u64 },\n-\n-    /// Struct-like placement, with precomputed offsets.\n-    ///\n-    /// Fields are guaranteed to not overlap, but note that gaps\n-    /// before, between and after all the fields are NOT always\n-    /// padding, and as such their contents may not be discarded.\n-    /// For example, enum variants leave a gap at the start,\n-    /// where the discriminant field in the enum layout goes.\n-    Arbitrary {\n-        /// Offsets for the first byte of each field,\n-        /// ordered to match the source definition order.\n-        /// This vector does not go in increasing order.\n-        // FIXME(eddyb) use small vector optimization for the common case.\n-        offsets: Vec<Size>,\n-\n-        /// Maps source order field indices to memory order indices,\n-        /// depending on how the fields were reordered (if at all).\n-        /// This is a permutation, with both the source order and the\n-        /// memory order using the same (0..n) index ranges.\n-        ///\n-        /// Note that during computation of `memory_index`, sometimes\n-        /// it is easier to operate on the inverse mapping (that is,\n-        /// from memory order to source order), and that is usually\n-        /// named `inverse_memory_index`.\n-        ///\n-        // FIXME(eddyb) build a better abstraction for permutations, if possible.\n-        // FIXME(camlorn) also consider small vector  optimization here.\n-        memory_index: Vec<u32>,\n-    },\n-}\n-\n-impl FieldsShape {\n-    #[inline]\n-    pub fn count(&self) -> usize {\n-        match *self {\n-            FieldsShape::Primitive => 0,\n-            FieldsShape::Union(count) => count.get(),\n-            FieldsShape::Array { count, .. } => count.try_into().unwrap(),\n-            FieldsShape::Arbitrary { ref offsets, .. } => offsets.len(),\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn offset(&self, i: usize, dl: &TargetDataLayout) -> Size {\n-        match *self {\n-            FieldsShape::Primitive => {\n-                unreachable!(\"FieldsShape::offset: `Primitive`s have no fields\")\n-            }\n-            FieldsShape::Union(count) => {\n-                assert!(\n-                    i < count.get(),\n-                    \"tried to access field {} of union with {} fields\",\n-                    i,\n-                    count\n-                );\n-                Size::ZERO\n-            }\n-            FieldsShape::Array { stride, count } => {\n-                let i = u64::try_from(i).unwrap();\n-                assert!(i < count);\n-                stride.checked_mul(i, dl).unwrap()\n-            }\n-            FieldsShape::Arbitrary { ref offsets, .. } => offsets[i],\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn memory_index(&self, i: usize) -> usize {\n-        match *self {\n-            FieldsShape::Primitive => {\n-                unreachable!(\"FieldsShape::memory_index: `Primitive`s have no fields\")\n-            }\n-            FieldsShape::Union(_) | FieldsShape::Array { .. } => i,\n-            FieldsShape::Arbitrary { ref memory_index, .. } => memory_index[i].try_into().unwrap(),\n-        }\n-    }\n-\n-    /// Gets source indices of the fields by increasing offsets.\n-    #[inline]\n-    pub fn index_by_increasing_offset<'a>(&'a self) -> impl Iterator<Item = usize> + 'a {\n-        let mut inverse_small = [0u8; 64];\n-        let mut inverse_big = vec![];\n-        let use_small = self.count() <= inverse_small.len();\n+pub type Layout = rustc_abi::LayoutS<RustcEnumVariantIdx>;\n+pub type TagEncoding = rustc_abi::TagEncoding<RustcEnumVariantIdx>;\n+pub type Variants = rustc_abi::Variants<RustcEnumVariantIdx>;\n \n-        // We have to write this logic twice in order to keep the array small.\n-        if let FieldsShape::Arbitrary { ref memory_index, .. } = *self {\n-            if use_small {\n-                for i in 0..self.count() {\n-                    inverse_small[memory_index[i] as usize] = i as u8;\n-                }\n-            } else {\n-                inverse_big = vec![0; self.count()];\n-                for i in 0..self.count() {\n-                    inverse_big[memory_index[i] as usize] = i as u32;\n-                }\n-            }\n-        }\n-\n-        (0..self.count()).map(move |i| match *self {\n-            FieldsShape::Primitive | FieldsShape::Union(_) | FieldsShape::Array { .. } => i,\n-            FieldsShape::Arbitrary { .. } => {\n-                if use_small {\n-                    inverse_small[i] as usize\n-                } else {\n-                    inverse_big[i] as usize\n-                }\n-            }\n-        })\n-    }\n-}\n-\n-/// Integers, also used for enum discriminants.\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n-pub enum Integer {\n-    I8,\n-    I16,\n-    I32,\n-    I64,\n-    I128,\n+pub trait IntegerExt {\n+    fn repr_discr(\n+        dl: &TargetDataLayout,\n+        repr: &ReprOptions,\n+        min: i128,\n+        max: i128,\n+    ) -> Result<(Integer, bool), LayoutError>;\n }\n \n-impl Integer {\n-    #[inline]\n-    pub fn size(self) -> Size {\n-        match self {\n-            Integer::I8 => Size::from_bytes(1),\n-            Integer::I16 => Size::from_bytes(2),\n-            Integer::I32 => Size::from_bytes(4),\n-            Integer::I64 => Size::from_bytes(8),\n-            Integer::I128 => Size::from_bytes(16),\n-        }\n-    }\n-\n-    pub fn align(self, dl: &TargetDataLayout) -> AbiAndPrefAlign {\n-        match self {\n-            Integer::I8 => dl.i8_align,\n-            Integer::I16 => dl.i16_align,\n-            Integer::I32 => dl.i32_align,\n-            Integer::I64 => dl.i64_align,\n-            Integer::I128 => dl.i128_align,\n-        }\n-    }\n-\n-    /// Finds the smallest integer with the given alignment.\n-    pub fn for_align(dl: &TargetDataLayout, wanted: Align) -> Option<Integer> {\n-        use Integer::*;\n-        for candidate in [I8, I16, I32, I64, I128] {\n-            if wanted == candidate.align(dl).abi && wanted.bytes() == candidate.size().bytes() {\n-                return Some(candidate);\n-            }\n-        }\n-        None\n-    }\n-\n-    /// Finds the smallest Integer type which can represent the signed value.\n-    #[inline]\n-    pub fn fit_signed(x: i128) -> Integer {\n-        match x {\n-            -0x0000_0000_0000_0080..=0x0000_0000_0000_007f => Integer::I8,\n-            -0x0000_0000_0000_8000..=0x0000_0000_0000_7fff => Integer::I16,\n-            -0x0000_0000_8000_0000..=0x0000_0000_7fff_ffff => Integer::I32,\n-            -0x8000_0000_0000_0000..=0x7fff_ffff_ffff_ffff => Integer::I64,\n-            _ => Integer::I128,\n-        }\n-    }\n-\n-    /// Finds the smallest Integer type which can represent the unsigned value.\n-    #[inline]\n-    pub fn fit_unsigned(x: u128) -> Integer {\n-        match x {\n-            0..=0x0000_0000_0000_00ff => Integer::I8,\n-            0..=0x0000_0000_0000_ffff => Integer::I16,\n-            0..=0x0000_0000_ffff_ffff => Integer::I32,\n-            0..=0xffff_ffff_ffff_ffff => Integer::I64,\n-            _ => Integer::I128,\n-        }\n-    }\n-\n-    /// Gets the Integer type from an attr::IntType.\n-    pub fn from_attr(dl: &TargetDataLayout, ity: Either<BuiltinInt, BuiltinUint>) -> Integer {\n-        match ity {\n-            Either::Left(BuiltinInt::I8) | Either::Right(BuiltinUint::U8) => Integer::I8,\n-            Either::Left(BuiltinInt::I16) | Either::Right(BuiltinUint::U16) => Integer::I16,\n-            Either::Left(BuiltinInt::I32) | Either::Right(BuiltinUint::U32) => Integer::I32,\n-            Either::Left(BuiltinInt::I64) | Either::Right(BuiltinUint::U64) => Integer::I64,\n-            Either::Left(BuiltinInt::I128) | Either::Right(BuiltinUint::U128) => Integer::I128,\n-            Either::Left(BuiltinInt::Isize) | Either::Right(BuiltinUint::Usize) => {\n-                dl.ptr_sized_integer()\n-            }\n-        }\n-    }\n-\n+impl IntegerExt for Integer {\n     /// Finds the appropriate Integer type and signedness for the given\n     /// signed discriminant range and `#[repr]` attribute.\n     /// N.B.: `u128` values above `i128::MAX` will be treated as signed, but\n     /// that shouldn't affect anything, other than maybe debuginfo.\n-    pub fn repr_discr(\n+    fn repr_discr(\n         dl: &TargetDataLayout,\n         repr: &ReprOptions,\n         min: i128,\n@@ -428,15 +57,15 @@ impl Integer {\n \n         if let Some(ity) = repr.int {\n             let discr = Integer::from_attr(dl, ity);\n-            let fit = if ity.is_left() { signed_fit } else { unsigned_fit };\n+            let fit = if ity.is_signed() { signed_fit } else { unsigned_fit };\n             if discr < fit {\n                 return Err(LayoutError::UserError(\n                     \"Integer::repr_discr: `#[repr]` hint too small for \\\n                       discriminant range of enum \"\n                         .to_string(),\n                 ));\n             }\n-            return Ok((discr, ity.is_left()));\n+            return Ok((discr, ity.is_signed()));\n         }\n \n         let at_least = if repr.c() {\n@@ -457,717 +86,11 @@ impl Integer {\n     }\n }\n \n-/// Endianness of the target, which must match cfg(target-endian).\n-#[derive(Copy, Clone, PartialEq, Eq)]\n-pub enum Endian {\n-    Little,\n-    Big,\n-}\n-\n-impl Endian {\n-    pub fn as_str(&self) -> &'static str {\n-        match self {\n-            Self::Little => \"little\",\n-            Self::Big => \"big\",\n-        }\n-    }\n-}\n-\n-impl fmt::Debug for Endian {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        f.write_str(self.as_str())\n-    }\n-}\n-\n-/// An identifier that specifies the address space that some operation\n-/// should operate on. Special address spaces have an effect on code generation,\n-/// depending on the target and the address spaces it implements.\n-#[derive(Copy, Clone, Debug, PartialEq, Eq, PartialOrd, Ord)]\n-pub struct AddressSpace(pub u32);\n-\n-/// Parsed [Data layout](https://llvm.org/docs/LangRef.html#data-layout)\n-/// for a target, which contains everything needed to compute layouts.\n-#[derive(Debug, PartialEq, Eq)]\n-pub struct TargetDataLayout {\n-    pub endian: Endian,\n-    pub i1_align: AbiAndPrefAlign,\n-    pub i8_align: AbiAndPrefAlign,\n-    pub i16_align: AbiAndPrefAlign,\n-    pub i32_align: AbiAndPrefAlign,\n-    pub i64_align: AbiAndPrefAlign,\n-    pub i128_align: AbiAndPrefAlign,\n-    pub f32_align: AbiAndPrefAlign,\n-    pub f64_align: AbiAndPrefAlign,\n-    pub pointer_size: Size,\n-    pub pointer_align: AbiAndPrefAlign,\n-    pub aggregate_align: AbiAndPrefAlign,\n-\n-    /// Alignments for vector types.\n-    pub vector_align: Vec<(Size, AbiAndPrefAlign)>,\n-\n-    pub instruction_address_space: AddressSpace,\n-\n-    /// Minimum size of #[repr(C)] enums (default I32 bits)\n-    pub c_enum_min_size: Integer,\n-}\n-\n-impl TargetDataLayout {\n-    /// Returns exclusive upper bound on object size.\n-    ///\n-    /// The theoretical maximum object size is defined as the maximum positive `isize` value.\n-    /// This ensures that the `offset` semantics remain well-defined by allowing it to correctly\n-    /// index every address within an object along with one byte past the end, along with allowing\n-    /// `isize` to store the difference between any two pointers into an object.\n-    ///\n-    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer\n-    /// to represent object size in bits. It would need to be 1 << 61 to account for this, but is\n-    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n-    /// address space on 64-bit ARMv8 and x86_64.\n-    #[inline]\n-    pub fn obj_size_bound(&self) -> u64 {\n-        match self.pointer_size.bits() {\n-            16 => 1 << 15,\n-            32 => 1 << 31,\n-            64 => 1 << 47,\n-            bits => panic!(\"obj_size_bound: unknown pointer bit size {}\", bits),\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn ptr_sized_integer(&self) -> Integer {\n-        match self.pointer_size.bits() {\n-            16 => Integer::I16,\n-            32 => Integer::I32,\n-            64 => Integer::I64,\n-            bits => panic!(\"ptr_sized_integer: unknown pointer bit size {}\", bits),\n-        }\n-    }\n-}\n-\n-/// Fundamental unit of memory access and layout.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n-pub enum Primitive {\n-    /// The `bool` is the signedness of the `Integer` type.\n-    ///\n-    /// One would think we would not care about such details this low down,\n-    /// but some ABIs are described in terms of C types and ISAs where the\n-    /// integer arithmetic is done on {sign,zero}-extended registers, e.g.\n-    /// a negative integer passed by zero-extension will appear positive in\n-    /// the callee, and most operations on it will produce the wrong values.\n-    Int(Integer, bool),\n-    F32,\n-    F64,\n-    Pointer,\n-}\n-\n-impl Primitive {\n-    pub fn size(self, dl: &TargetDataLayout) -> Size {\n-        match self {\n-            Primitive::Int(i, _) => i.size(),\n-            Primitive::F32 => Size::from_bits(32),\n-            Primitive::F64 => Size::from_bits(64),\n-            Primitive::Pointer => dl.pointer_size,\n-        }\n-    }\n-\n-    pub fn align(self, dl: &TargetDataLayout) -> AbiAndPrefAlign {\n-        match self {\n-            Primitive::Int(i, _) => i.align(dl),\n-            Primitive::F32 => dl.f32_align,\n-            Primitive::F64 => dl.f64_align,\n-            Primitive::Pointer => dl.pointer_align,\n-        }\n-    }\n-}\n-\n-/// Inclusive wrap-around range of valid values, that is, if\n-/// start > end, it represents `start..=MAX`,\n-/// followed by `0..=end`.\n-///\n-/// That is, for an i8 primitive, a range of `254..=2` means following\n-/// sequence:\n-///\n-///    254 (-2), 255 (-1), 0, 1, 2\n-///\n-/// This is intended specifically to mirror LLVM\u2019s `!range` metadata semantics.\n-#[derive(Clone, Copy, PartialEq, Eq, Hash)]\n-pub struct WrappingRange {\n-    pub start: u128,\n-    pub end: u128,\n-}\n-\n-impl WrappingRange {\n-    pub fn full(size: Size) -> Self {\n-        Self { start: 0, end: size.unsigned_int_max() }\n-    }\n-\n-    /// Returns `true` if `v` is contained in the range.\n-    #[inline(always)]\n-    pub fn contains(&self, v: u128) -> bool {\n-        if self.start <= self.end {\n-            self.start <= v && v <= self.end\n-        } else {\n-            self.start <= v || v <= self.end\n-        }\n-    }\n-\n-    /// Returns `self` with replaced `start`\n-    #[inline(always)]\n-    pub fn with_start(mut self, start: u128) -> Self {\n-        self.start = start;\n-        self\n-    }\n-\n-    /// Returns `self` with replaced `end`\n-    #[inline(always)]\n-    pub fn with_end(mut self, end: u128) -> Self {\n-        self.end = end;\n-        self\n-    }\n-\n-    /// Returns `true` if `size` completely fills the range.\n-    #[inline]\n-    pub fn is_full_for(&self, size: Size) -> bool {\n-        let max_value = size.unsigned_int_max();\n-        debug_assert!(self.start <= max_value && self.end <= max_value);\n-        self.start == (self.end.wrapping_add(1) & max_value)\n-    }\n-}\n-\n-impl fmt::Debug for WrappingRange {\n-    fn fmt(&self, fmt: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        if self.start > self.end {\n-            write!(fmt, \"(..={}) | ({}..)\", self.end, self.start)?;\n-        } else {\n-            write!(fmt, \"{}..={}\", self.start, self.end)?;\n-        }\n-        Ok(())\n-    }\n-}\n-\n-/// Information about one scalar component of a Rust type.\n-#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n-pub enum Scalar {\n-    Initialized {\n-        value: Primitive,\n-\n-        // FIXME(eddyb) always use the shortest range, e.g., by finding\n-        // the largest space between two consecutive valid values and\n-        // taking everything else as the (shortest) valid range.\n-        valid_range: WrappingRange,\n-    },\n-    Union {\n-        /// Even for unions, we need to use the correct registers for the kind of\n-        /// values inside the union, so we keep the `Primitive` type around. We\n-        /// also use it to compute the size of the scalar.\n-        /// However, unions never have niches and even allow undef,\n-        /// so there is no `valid_range`.\n-        value: Primitive,\n-    },\n-}\n-\n-impl Scalar {\n-    #[inline]\n-    pub fn is_bool(&self) -> bool {\n-        matches!(\n-            self,\n-            Scalar::Initialized {\n-                value: Primitive::Int(Integer::I8, false),\n-                valid_range: WrappingRange { start: 0, end: 1 }\n-            }\n-        )\n-    }\n-\n-    /// Get the primitive representation of this type, ignoring the valid range and whether the\n-    /// value is allowed to be undefined (due to being a union).\n-    pub fn primitive(&self) -> Primitive {\n-        match *self {\n-            Scalar::Initialized { value, .. } | Scalar::Union { value } => value,\n-        }\n-    }\n-\n-    pub fn align(self, cx: &TargetDataLayout) -> AbiAndPrefAlign {\n-        self.primitive().align(cx)\n-    }\n-\n-    pub fn size(self, cx: &TargetDataLayout) -> Size {\n-        self.primitive().size(cx)\n-    }\n-\n-    #[inline]\n-    pub fn to_union(&self) -> Self {\n-        Self::Union { value: self.primitive() }\n-    }\n-\n-    #[inline]\n-    pub fn valid_range(&self, cx: &TargetDataLayout) -> WrappingRange {\n-        match *self {\n-            Scalar::Initialized { valid_range, .. } => valid_range,\n-            Scalar::Union { value } => WrappingRange::full(value.size(cx)),\n-        }\n-    }\n-\n-    #[inline]\n-    /// Allows the caller to mutate the valid range. This operation will panic if attempted on a union.\n-    pub fn valid_range_mut(&mut self) -> &mut WrappingRange {\n-        match self {\n-            Scalar::Initialized { valid_range, .. } => valid_range,\n-            Scalar::Union { .. } => panic!(\"cannot change the valid range of a union\"),\n-        }\n-    }\n-\n-    /// Returns `true` if all possible numbers are valid, i.e `valid_range` covers the whole layout\n-    #[inline]\n-    pub fn is_always_valid(&self, cx: &TargetDataLayout) -> bool {\n-        match *self {\n-            Scalar::Initialized { valid_range, .. } => valid_range.is_full_for(self.size(cx)),\n-            Scalar::Union { .. } => true,\n-        }\n-    }\n-\n-    /// Returns `true` if this type can be left uninit.\n-    #[inline]\n-    pub fn is_uninit_valid(&self) -> bool {\n-        match *self {\n-            Scalar::Initialized { .. } => false,\n-            Scalar::Union { .. } => true,\n-        }\n-    }\n-}\n-\n-/// Describes how values of the type are passed by target ABIs,\n-/// in terms of categories of C types there are ABI rules for.\n-#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n-pub enum Abi {\n-    Uninhabited,\n-    Scalar(Scalar),\n-    ScalarPair(Scalar, Scalar),\n-    Vector {\n-        element: Scalar,\n-        count: u64,\n-    },\n-    Aggregate {\n-        /// If true, the size is exact, otherwise it's only a lower bound.\n-        sized: bool,\n-    },\n-}\n-\n-impl Abi {\n-    /// Returns `true` if the layout corresponds to an unsized type.\n-    #[inline]\n-    pub fn is_unsized(&self) -> bool {\n-        match *self {\n-            Abi::Uninhabited | Abi::Scalar(_) | Abi::ScalarPair(..) | Abi::Vector { .. } => false,\n-            Abi::Aggregate { sized } => !sized,\n-        }\n-    }\n-\n-    /// Returns `true` if this is an uninhabited type\n-    #[inline]\n-    pub fn is_uninhabited(&self) -> bool {\n-        matches!(*self, Abi::Uninhabited)\n-    }\n-\n-    /// Returns `true` is this is a scalar type\n-    #[inline]\n-    pub fn is_scalar(&self) -> bool {\n-        matches!(*self, Abi::Scalar(_))\n-    }\n-}\n-\n-/// Alignment of a type in bytes (always a power of two).\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n-pub struct Align {\n-    pow2: u8,\n-}\n-\n-// This is debug-printed a lot in larger structs, don't waste too much space there\n-impl fmt::Debug for Align {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        write!(f, \"Align({} bytes)\", self.bytes())\n-    }\n-}\n-\n-impl Align {\n-    pub const ONE: Align = Align { pow2: 0 };\n-    pub const MAX: Align = Align { pow2: 29 };\n-\n-    #[inline]\n-    pub fn from_bytes(align: u64) -> Result<Align, String> {\n-        // Treat an alignment of 0 bytes like 1-byte alignment.\n-        if align == 0 {\n-            return Ok(Align::ONE);\n-        }\n-\n-        #[cold]\n-        fn not_power_of_2(align: u64) -> String {\n-            format!(\"`{}` is not a power of 2\", align)\n-        }\n-\n-        #[cold]\n-        fn too_large(align: u64) -> String {\n-            format!(\"`{}` is too large\", align)\n-        }\n-\n-        let mut bytes = align;\n-        let mut pow2: u8 = 0;\n-        while (bytes & 1) == 0 {\n-            pow2 += 1;\n-            bytes >>= 1;\n-        }\n-        if bytes != 1 {\n-            return Err(not_power_of_2(align));\n-        }\n-        if pow2 > Self::MAX.pow2 {\n-            return Err(too_large(align));\n-        }\n-\n-        Ok(Align { pow2 })\n-    }\n-\n-    #[inline]\n-    pub fn bytes(self) -> u64 {\n-        1 << self.pow2\n-    }\n-\n-    #[inline]\n-    pub fn bits(self) -> u64 {\n-        self.bytes() * 8\n-    }\n-\n-    /// Computes the best alignment possible for the given offset\n-    /// (the largest power of two that the offset is a multiple of).\n-    ///\n-    /// N.B., for an offset of `0`, this happens to return `2^64`.\n-    #[inline]\n-    pub fn max_for_offset(offset: Size) -> Align {\n-        Align { pow2: offset.bytes().trailing_zeros() as u8 }\n-    }\n-\n-    /// Lower the alignment, if necessary, such that the given offset\n-    /// is aligned to it (the offset is a multiple of the alignment).\n-    #[inline]\n-    pub fn restrict_for_offset(self, offset: Size) -> Align {\n-        self.min(Align::max_for_offset(offset))\n-    }\n-}\n-\n-/// A pair of alignments, ABI-mandated and preferred.\n-#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n-pub struct AbiAndPrefAlign {\n-    pub abi: Align,\n-    pub pref: Align,\n-}\n-\n-impl AbiAndPrefAlign {\n-    #[inline]\n-    pub fn new(align: Align) -> AbiAndPrefAlign {\n-        AbiAndPrefAlign { abi: align, pref: align }\n-    }\n-\n-    #[inline]\n-    pub fn min(self, other: AbiAndPrefAlign) -> AbiAndPrefAlign {\n-        AbiAndPrefAlign { abi: self.abi.min(other.abi), pref: self.pref.min(other.pref) }\n-    }\n-\n-    #[inline]\n-    pub fn max(self, other: AbiAndPrefAlign) -> AbiAndPrefAlign {\n-        AbiAndPrefAlign { abi: self.abi.max(other.abi), pref: self.pref.max(other.pref) }\n-    }\n-}\n-\n-#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]\n-pub struct Niche {\n-    pub offset: Size,\n-    pub value: Primitive,\n-    pub valid_range: WrappingRange,\n-}\n-\n-impl Niche {\n-    pub fn from_scalar(cx: &TargetDataLayout, offset: Size, scalar: Scalar) -> Option<Self> {\n-        let (value, valid_range) = match scalar {\n-            Scalar::Initialized { value, valid_range } => (value, valid_range),\n-            _ => return None,\n-        };\n-        let niche = Niche { offset, value, valid_range };\n-        if niche.available(cx) > 0 {\n-            Some(niche)\n-        } else {\n-            None\n-        }\n-    }\n-\n-    pub fn available(&self, cx: &TargetDataLayout) -> u128 {\n-        let Self { value, valid_range: v, .. } = *self;\n-        let size = value.size(cx);\n-        assert!(size.bits() <= 128);\n-        let max_value = size.unsigned_int_max();\n-\n-        // Find out how many values are outside the valid range.\n-        let niche = v.end.wrapping_add(1)..v.start;\n-        niche.end.wrapping_sub(niche.start) & max_value\n-    }\n-\n-    pub fn reserve(&self, cx: &TargetDataLayout, count: u128) -> Option<(u128, Scalar)> {\n-        assert!(count > 0);\n-\n-        let Self { value, valid_range: v, .. } = *self;\n-        let size = value.size(cx);\n-        assert!(size.bits() <= 128);\n-        let max_value = size.unsigned_int_max();\n-\n-        let niche = v.end.wrapping_add(1)..v.start;\n-        let available = niche.end.wrapping_sub(niche.start) & max_value;\n-        if count > available {\n-            return None;\n-        }\n-\n-        // Extend the range of valid values being reserved by moving either `v.start` or `v.end` bound.\n-        // Given an eventual `Option<T>`, we try to maximize the chance for `None` to occupy the niche of zero.\n-        // This is accomplished by preferring enums with 2 variants(`count==1`) and always taking the shortest path to niche zero.\n-        // Having `None` in niche zero can enable some special optimizations.\n-        //\n-        // Bound selection criteria:\n-        // 1. Select closest to zero given wrapping semantics.\n-        // 2. Avoid moving past zero if possible.\n-        //\n-        // In practice this means that enums with `count > 1` are unlikely to claim niche zero, since they have to fit perfectly.\n-        // If niche zero is already reserved, the selection of bounds are of little interest.\n-        let move_start = |v: WrappingRange| {\n-            let start = v.start.wrapping_sub(count) & max_value;\n-            Some((start, Scalar::Initialized { value, valid_range: v.with_start(start) }))\n-        };\n-        let move_end = |v: WrappingRange| {\n-            let start = v.end.wrapping_add(1) & max_value;\n-            let end = v.end.wrapping_add(count) & max_value;\n-            Some((start, Scalar::Initialized { value, valid_range: v.with_end(end) }))\n-        };\n-        let distance_end_zero = max_value - v.end;\n-        if v.start > v.end {\n-            // zero is unavailable because wrapping occurs\n-            move_end(v)\n-        } else if v.start <= distance_end_zero {\n-            if count <= v.start {\n-                move_start(v)\n-            } else {\n-                // moved past zero, use other bound\n-                move_end(v)\n-            }\n-        } else {\n-            let end = v.end.wrapping_add(count) & max_value;\n-            let overshot_zero = (1..=v.end).contains(&end);\n-            if overshot_zero {\n-                // moved past zero, use other bound\n-                move_start(v)\n-            } else {\n-                move_end(v)\n-            }\n-        }\n-    }\n-}\n-\n-#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n-pub enum TagEncoding {\n-    /// The tag directly stores the discriminant, but possibly with a smaller layout\n-    /// (so converting the tag to the discriminant can require sign extension).\n-    Direct,\n-\n-    /// Niche (values invalid for a type) encoding the discriminant:\n-    /// Discriminant and variant index coincide.\n-    /// The variant `untagged_variant` contains a niche at an arbitrary\n-    /// offset (field `tag_field` of the enum), which for a variant with\n-    /// discriminant `d` is set to\n-    /// `(d - niche_variants.start).wrapping_add(niche_start)`.\n-    ///\n-    /// For example, `Option<(usize, &T)>`  is represented such that\n-    /// `None` has a null pointer for the second tuple field, and\n-    /// `Some` is the identity function (with a non-null reference).\n-    Niche { untagged_variant: LocalEnumVariantId, niche_start: u128 },\n-}\n-\n-#[derive(PartialEq, Eq, Hash, Debug, Clone)]\n-pub enum Variants {\n-    /// Single enum variants, structs/tuples, unions, and all non-ADTs.\n-    Single,\n-\n-    /// Enum-likes with more than one inhabited variant: each variant comes with\n-    /// a *discriminant* (usually the same as the variant index but the user can\n-    /// assign explicit discriminant values).  That discriminant is encoded\n-    /// as a *tag* on the machine.  The layout of each variant is\n-    /// a struct, and they all have space reserved for the tag.\n-    /// For enums, the tag is the sole field of the layout.\n-    Multiple {\n-        tag: Scalar,\n-        tag_encoding: TagEncoding,\n-        tag_field: usize,\n-        variants: ArenaMap<LocalEnumVariantId, Layout>,\n-    },\n-}\n-\n-bitflags! {\n-    #[derive(Default)]\n-    pub struct ReprFlags: u8 {\n-        const IS_C               = 1 << 0;\n-        const IS_SIMD            = 1 << 1;\n-        const IS_TRANSPARENT     = 1 << 2;\n-        // Internal only for now. If true, don't reorder fields.\n-        const IS_LINEAR          = 1 << 3;\n-        // Any of these flags being set prevent field reordering optimisation.\n-        const IS_UNOPTIMISABLE   = ReprFlags::IS_C.bits\n-                                 | ReprFlags::IS_SIMD.bits\n-                                 | ReprFlags::IS_LINEAR.bits;\n-    }\n-}\n-\n-/// Represents the repr options provided by the user,\n-#[derive(Copy, Clone, Debug, Eq, PartialEq, Default)]\n-pub struct ReprOptions {\n-    pub int: Option<Either<BuiltinInt, BuiltinUint>>,\n-    pub align: Option<Align>,\n-    pub pack: Option<Align>,\n-    pub flags: ReprFlags,\n-}\n-\n-impl ReprOptions {\n-    #[inline]\n-    pub fn simd(&self) -> bool {\n-        self.flags.contains(ReprFlags::IS_SIMD)\n-    }\n-\n-    #[inline]\n-    pub fn c(&self) -> bool {\n-        self.flags.contains(ReprFlags::IS_C)\n-    }\n-\n-    #[inline]\n-    pub fn packed(&self) -> bool {\n-        self.pack.is_some()\n-    }\n-\n-    #[inline]\n-    pub fn transparent(&self) -> bool {\n-        self.flags.contains(ReprFlags::IS_TRANSPARENT)\n-    }\n-\n-    #[inline]\n-    pub fn linear(&self) -> bool {\n-        self.flags.contains(ReprFlags::IS_LINEAR)\n-    }\n-\n-    /// Returns the discriminant type, given these `repr` options.\n-    /// This must only be called on enums!\n-    pub fn discr_type(&self) -> Either<BuiltinInt, BuiltinUint> {\n-        self.int.unwrap_or(Either::Left(BuiltinInt::Isize))\n-    }\n-\n-    /// Returns `true` if this `#[repr()]` should inhabit \"smart enum\n-    /// layout\" optimizations, such as representing `Foo<&T>` as a\n-    /// single pointer.\n-    pub fn inhibit_enum_layout_opt(&self) -> bool {\n-        self.c() || self.int.is_some()\n-    }\n-\n-    /// Returns `true` if this `#[repr()]` should inhibit struct field reordering\n-    /// optimizations, such as with `repr(C)`, `repr(packed(1))`, or `repr(<int>)`.\n-    pub fn inhibit_struct_field_reordering_opt(&self) -> bool {\n-        if let Some(pack) = self.pack {\n-            if pack.bytes() == 1 {\n-                return true;\n-            }\n-        }\n-\n-        self.flags.intersects(ReprFlags::IS_UNOPTIMISABLE) || self.int.is_some()\n-    }\n-\n-    /// Returns `true` if this `#[repr()]` should inhibit union ABI optimisations.\n-    pub fn inhibit_union_abi_opt(&self) -> bool {\n-        self.c()\n-    }\n-}\n-\n-#[derive(PartialEq, Eq, Hash, Clone)]\n-pub struct Layout {\n-    /// Says where the fields are located within the layout.\n-    pub fields: FieldsShape,\n-\n-    /// Encodes information about multi-variant layouts.\n-    /// Even with `Multiple` variants, a layout still has its own fields! Those are then\n-    /// shared between all variants. One of them will be the discriminant,\n-    /// but e.g. generators can have more.\n-    ///\n-    /// To access all fields of this layout, both `fields` and the fields of the active variant\n-    /// must be taken into account.\n-    pub variants: Variants,\n-\n-    /// The `abi` defines how this data is passed between functions, and it defines\n-    /// value restrictions via `valid_range`.\n-    ///\n-    /// Note that this is entirely orthogonal to the recursive structure defined by\n-    /// `variants` and `fields`; for example, `ManuallyDrop<Result<isize, isize>>` has\n-    /// `Abi::ScalarPair`! So, even with non-`Aggregate` `abi`, `fields` and `variants`\n-    /// have to be taken into account to find all fields of this layout.\n-    pub abi: Abi,\n-\n-    /// The leaf scalar with the largest number of invalid values\n-    /// (i.e. outside of its `valid_range`), if it exists.\n-    pub largest_niche: Option<Niche>,\n-\n-    pub align: AbiAndPrefAlign,\n-    pub size: Size,\n-}\n-\n-impl Layout {\n-    pub fn scalar(dl: &TargetDataLayout, scalar: Scalar) -> Self {\n-        let largest_niche = Niche::from_scalar(dl, Size::ZERO, scalar);\n-        let size = scalar.size(dl);\n-        let align = scalar.align(dl);\n-        Layout {\n-            variants: Variants::Single,\n-            fields: FieldsShape::Primitive,\n-            abi: Abi::Scalar(scalar),\n-            largest_niche,\n-            size,\n-            align,\n-        }\n-    }\n-}\n-\n-impl fmt::Debug for Layout {\n-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n-        // This is how `Layout` used to print before it become\n-        // `Interned<LayoutS>`. We print it like this to avoid having to update\n-        // expected output in a lot of tests.\n-        let Layout { size, align, abi, fields, largest_niche, variants } = self;\n-        f.debug_struct(\"Layout\")\n-            .field(\"size\", size)\n-            .field(\"align\", align)\n-            .field(\"abi\", abi)\n-            .field(\"fields\", fields)\n-            .field(\"largest_niche\", largest_niche)\n-            .field(\"variants\", variants)\n-            .finish()\n-    }\n-}\n-\n-impl Layout {\n-    pub fn is_unsized(&self) -> bool {\n-        self.abi.is_unsized()\n-    }\n-\n-    /// Returns `true` if the type is a ZST and not unsized.\n-    pub fn is_zst(&self) -> bool {\n-        match self.abi {\n-            Abi::Scalar(_) | Abi::ScalarPair(..) | Abi::Vector { .. } => false,\n-            Abi::Uninhabited => self.size.bytes() == 0,\n-            Abi::Aggregate { sized } => sized && self.size.bytes() == 0,\n-        }\n-    }\n-}\n-\n #[derive(Debug, PartialEq, Eq, Clone)]\n pub enum LayoutError {\n     UserError(String),\n     SizeOverflow,\n     HasPlaceholder,\n     NotImplemented,\n+    Unknown,\n }"}, {"sha": "87a206e30fb79c3dc3600233af3d96ca438c8688", "filename": "crates/hir-ty/Cargo.toml", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2FCargo.toml?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -25,6 +25,7 @@ chalk-derive = \"0.87.0\"\n la-arena = { version = \"0.3.0\", path = \"../../lib/la-arena\" }\n once_cell = \"1.15.0\"\n typed-arena = \"2.0.1\"\n+rustc_index = { version = \"0.0.20221125\", package = \"hkalbasi-rustc-ap-rustc_index\", default-features = false }\n \n stdx = { path = \"../stdx\", version = \"0.0.0\" }\n hir-def = { path = \"../hir-def\", version = \"0.0.0\" }"}, {"sha": "874a54fc3ee185717b75f590b43eacd3e29e91fd", "filename": "crates/hir-ty/src/infer.rs", "status": "modified", "additions": 22, "deletions": 3, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Finfer.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Finfer.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Finfer.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -19,10 +19,11 @@ use std::sync::Arc;\n use chalk_ir::{cast::Cast, ConstValue, DebruijnIndex, Mutability, Safety, Scalar, TypeFlags};\n use hir_def::{\n     body::Body,\n-    builtin_type::BuiltinType,\n+    builtin_type::{BuiltinInt, BuiltinType, BuiltinUint},\n     data::{ConstData, StaticData},\n     expr::{BindingAnnotation, ExprId, PatId},\n     lang_item::LangItemTarget,\n+    layout::Integer,\n     path::{path, Path},\n     resolver::{HasResolver, ResolveValueResult, Resolver, TypeNs, ValueNs},\n     type_ref::TypeRef,\n@@ -70,8 +71,26 @@ pub(crate) fn infer_query(db: &dyn HirDatabase, def: DefWithBodyId) -> Arc<Infer\n         DefWithBodyId::StaticId(s) => ctx.collect_static(&db.static_data(s)),\n         DefWithBodyId::VariantId(v) => {\n             ctx.return_ty = TyBuilder::builtin(match db.enum_data(v.parent).variant_body_type() {\n-                Either::Left(builtin) => BuiltinType::Int(builtin),\n-                Either::Right(builtin) => BuiltinType::Uint(builtin),\n+                hir_def::layout::IntegerType::Pointer(signed) => match signed {\n+                    true => BuiltinType::Int(BuiltinInt::Isize),\n+                    false => BuiltinType::Uint(BuiltinUint::Usize),\n+                },\n+                hir_def::layout::IntegerType::Fixed(size, signed) => match signed {\n+                    true => BuiltinType::Int(match size {\n+                        Integer::I8 => BuiltinInt::I8,\n+                        Integer::I16 => BuiltinInt::I16,\n+                        Integer::I32 => BuiltinInt::I32,\n+                        Integer::I64 => BuiltinInt::I64,\n+                        Integer::I128 => BuiltinInt::I128,\n+                    }),\n+                    false => BuiltinType::Uint(match size {\n+                        Integer::I8 => BuiltinUint::U8,\n+                        Integer::I16 => BuiltinUint::U16,\n+                        Integer::I32 => BuiltinUint::U32,\n+                        Integer::I64 => BuiltinUint::U64,\n+                        Integer::I128 => BuiltinUint::U128,\n+                    }),\n+                },\n             });\n         }\n     }"}, {"sha": "3c6489fa97b0010100456ce0b5d48165f95850fa", "filename": "crates/hir-ty/src/layout.rs", "status": "modified", "additions": 45, "deletions": 44, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -1,12 +1,15 @@\n //! Compute the binary representation of a type\n \n+use std::sync::Arc;\n+\n use chalk_ir::{AdtId, TyKind};\n pub(self) use hir_def::layout::*;\n use hir_def::LocalFieldId;\n+use stdx::never;\n \n use crate::{db::HirDatabase, Interner, Substitution, Ty};\n \n-use self::adt::univariant;\n+use self::adt::struct_variant_idx;\n pub use self::{\n     adt::{layout_of_adt_query, layout_of_adt_recover},\n     target::current_target_data_layout_query,\n@@ -21,6 +24,22 @@ macro_rules! user_error {\n mod adt;\n mod target;\n \n+struct LayoutCx<'a> {\n+    db: &'a dyn HirDatabase,\n+}\n+\n+impl LayoutCalculator for LayoutCx<'_> {\n+    type TargetDataLayoutRef = Arc<TargetDataLayout>;\n+\n+    fn delay_bug(&self, txt: &str) {\n+        never!(\"{}\", txt);\n+    }\n+\n+    fn current_data_layout(&self) -> Arc<TargetDataLayout> {\n+        self.db.current_target_data_layout()\n+    }\n+}\n+\n fn scalar_unit(dl: &TargetDataLayout, value: Primitive) -> Scalar {\n     Scalar::Initialized { value, valid_range: WrappingRange::full(value.size(dl)) }\n }\n@@ -29,34 +48,9 @@ fn scalar(dl: &TargetDataLayout, value: Primitive) -> Layout {\n     Layout::scalar(dl, scalar_unit(dl, value))\n }\n \n-fn scalar_pair(dl: &TargetDataLayout, a: Scalar, b: Scalar) -> Layout {\n-    let b_align = b.align(dl);\n-    let align = a.align(dl).max(b_align).max(dl.aggregate_align);\n-    let b_offset = a.size(dl).align_to(b_align.abi);\n-    let size = b_offset.checked_add(b.size(dl), dl).unwrap().align_to(align.abi);\n-\n-    // HACK(nox): We iter on `b` and then `a` because `max_by_key`\n-    // returns the last maximum.\n-    let largest_niche = Niche::from_scalar(dl, b_offset, b)\n-        .into_iter()\n-        .chain(Niche::from_scalar(dl, Size::ZERO, a))\n-        .max_by_key(|niche| niche.available(dl));\n-\n-    Layout {\n-        variants: Variants::Single,\n-        fields: FieldsShape::Arbitrary {\n-            offsets: vec![Size::ZERO, b_offset],\n-            memory_index: vec![0, 1],\n-        },\n-        abi: Abi::ScalarPair(a, b),\n-        largest_niche,\n-        align,\n-        size,\n-    }\n-}\n-\n pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError> {\n     let dl = &*db.current_target_data_layout();\n+    let cx = LayoutCx { db };\n     Ok(match ty.kind(Interner) {\n         TyKind::Adt(AdtId(def), subst) => db.layout_of_adt(*def, subst.clone())?,\n         TyKind::Scalar(s) => match s {\n@@ -113,14 +107,13 @@ pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError\n         TyKind::Tuple(len, tys) => {\n             let kind = if *len == 0 { StructKind::AlwaysSized } else { StructKind::MaybeUnsized };\n \n-            univariant(\n-                dl,\n-                &tys.iter(Interner)\n-                    .map(|k| layout_of_ty(db, k.assert_ty_ref(Interner)))\n-                    .collect::<Result<Vec<_>, _>>()?,\n-                &ReprOptions::default(),\n-                kind,\n-            )?\n+            let fields = tys\n+                .iter(Interner)\n+                .map(|k| layout_of_ty(db, k.assert_ty_ref(Interner)))\n+                .collect::<Result<Vec<_>, _>>()?;\n+            let fields = fields.iter().collect::<Vec<_>>();\n+            let fields = fields.iter().collect::<Vec<_>>();\n+            cx.univariant(dl, &fields, &ReprOptions::default(), kind).ok_or(LayoutError::Unknown)?\n         }\n         TyKind::Array(element, count) => {\n             let count = match count.data(Interner).value {\n@@ -146,7 +139,7 @@ pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError\n             let largest_niche = if count != 0 { element.largest_niche } else { None };\n \n             Layout {\n-                variants: Variants::Single,\n+                variants: Variants::Single { index: struct_variant_idx() },\n                 fields: FieldsShape::Array { stride: element.size, count },\n                 abi,\n                 largest_niche,\n@@ -157,7 +150,7 @@ pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError\n         TyKind::Slice(element) => {\n             let element = layout_of_ty(db, element)?;\n             Layout {\n-                variants: Variants::Single,\n+                variants: Variants::Single { index: struct_variant_idx() },\n                 fields: FieldsShape::Array { stride: element.size, count: 0 },\n                 abi: Abi::Aggregate { sized: false },\n                 largest_niche: None,\n@@ -194,29 +187,27 @@ pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError\n             };\n \n             // Effectively a (ptr, meta) tuple.\n-            scalar_pair(dl, data_ptr, metadata)\n-        }\n-        TyKind::FnDef(_, _) => {\n-            univariant(dl, &[], &ReprOptions::default(), StructKind::AlwaysSized)?\n+            cx.scalar_pair(data_ptr, metadata)\n         }\n+        TyKind::FnDef(_, _) => layout_of_unit(&cx, dl)?,\n         TyKind::Str => Layout {\n-            variants: Variants::Single,\n+            variants: Variants::Single { index: struct_variant_idx() },\n             fields: FieldsShape::Array { stride: Size::from_bytes(1), count: 0 },\n             abi: Abi::Aggregate { sized: false },\n             largest_niche: None,\n             align: dl.i8_align,\n             size: Size::ZERO,\n         },\n         TyKind::Never => Layout {\n-            variants: Variants::Single,\n+            variants: Variants::Single { index: struct_variant_idx() },\n             fields: FieldsShape::Primitive,\n             abi: Abi::Uninhabited,\n             largest_niche: None,\n             align: dl.i8_align,\n             size: Size::ZERO,\n         },\n         TyKind::Dyn(_) | TyKind::Foreign(_) => {\n-            let mut unit = univariant(dl, &[], &ReprOptions::default(), StructKind::AlwaysSized)?;\n+            let mut unit = layout_of_unit(&cx, dl)?;\n             match unit.abi {\n                 Abi::Aggregate { ref mut sized } => *sized = false,\n                 _ => user_error!(\"bug\"),\n@@ -241,6 +232,16 @@ pub fn layout_of_ty(db: &dyn HirDatabase, ty: &Ty) -> Result<Layout, LayoutError\n     })\n }\n \n+fn layout_of_unit(cx: &LayoutCx<'_>, dl: &TargetDataLayout) -> Result<Layout, LayoutError> {\n+    cx.univariant::<RustcEnumVariantIdx, &&Layout>(\n+        &dl,\n+        &[],\n+        &ReprOptions::default(),\n+        StructKind::AlwaysSized,\n+    )\n+    .ok_or(LayoutError::Unknown)\n+}\n+\n fn struct_tail_erasing_lifetimes(db: &dyn HirDatabase, pointee: Ty) -> Ty {\n     match pointee.kind(Interner) {\n         TyKind::Adt(AdtId(adt), subst) => match adt {"}, {"sha": "d9791a4b630d0d6bebddc4e878311db363d5e9f0", "filename": "crates/hir-ty/src/layout/adt.rs", "status": "modified", "additions": 72, "deletions": 889, "changes": 961, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Fadt.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -1,628 +1,110 @@\n //! Compute the binary representation of structs, unions and enums\n \n-use std::{\n-    cmp::{self, Ordering},\n-    iter,\n-    num::NonZeroUsize,\n-    ops::Bound,\n-};\n+use std::ops::Bound;\n \n-use chalk_ir::TyKind;\n use hir_def::{\n     adt::VariantData,\n-    layout::{\n-        Abi, AbiAndPrefAlign, Align, FieldsShape, Integer, Layout, LayoutError, Niche, Primitive,\n-        ReprOptions, Scalar, Size, StructKind, TagEncoding, TargetDataLayout, Variants,\n-        WrappingRange,\n-    },\n-    AdtId, EnumVariantId, LocalEnumVariantId, UnionId, VariantId,\n+    layout::{Integer, IntegerExt, Layout, LayoutCalculator, LayoutError, RustcEnumVariantIdx},\n+    AdtId, EnumVariantId, LocalEnumVariantId, VariantId,\n };\n-use la_arena::{ArenaMap, RawIdx};\n+use la_arena::RawIdx;\n+use rustc_index::vec::IndexVec;\n \n-struct X(Option<NonZeroUsize>);\n+use crate::{db::HirDatabase, lang_items::is_unsafe_cell, layout::field_ty, Substitution};\n \n-use crate::{\n-    db::HirDatabase,\n-    lang_items::is_unsafe_cell,\n-    layout::{field_ty, scalar_unit},\n-    Interner, Substitution,\n-};\n+use super::{layout_of_ty, LayoutCx};\n \n-use super::layout_of_ty;\n+pub(crate) fn struct_variant_idx() -> RustcEnumVariantIdx {\n+    RustcEnumVariantIdx(LocalEnumVariantId::from_raw(RawIdx::from(0)))\n+}\n \n pub fn layout_of_adt_query(\n     db: &dyn HirDatabase,\n     def: AdtId,\n     subst: Substitution,\n ) -> Result<Layout, LayoutError> {\n+    let dl = db.current_target_data_layout();\n+    let cx = LayoutCx { db };\n     let handle_variant = |def: VariantId, var: &VariantData| {\n         var.fields()\n             .iter()\n             .map(|(fd, _)| layout_of_ty(db, &field_ty(db, def, fd, &subst)))\n             .collect::<Result<Vec<_>, _>>()\n     };\n-    fn struct_variant_idx() -> LocalEnumVariantId {\n-        LocalEnumVariantId::from_raw(RawIdx::from(0))\n-    }\n-    let (variants, is_enum, repr) = match def {\n+    let (variants, is_enum, is_union, repr) = match def {\n         AdtId::StructId(s) => {\n             let data = db.struct_data(s);\n-            let mut r = ArenaMap::new();\n-            r.insert(struct_variant_idx(), handle_variant(s.into(), &data.variant_data)?);\n-            (r, false, data.repr.unwrap_or_default())\n+            let mut r = IndexVec::new();\n+            r.push(handle_variant(s.into(), &data.variant_data)?);\n+            (r, false, false, data.repr.unwrap_or_default())\n+        }\n+        AdtId::UnionId(id) => {\n+            let data = db.union_data(id);\n+            let mut r = IndexVec::new();\n+            r.push(handle_variant(id.into(), &data.variant_data)?);\n+            (r, false, true, data.repr.unwrap_or_default())\n         }\n-        AdtId::UnionId(id) => return layout_of_union(db, id, &subst),\n         AdtId::EnumId(e) => {\n             let data = db.enum_data(e);\n             let r = data\n                 .variants\n                 .iter()\n                 .map(|(idx, v)| {\n-                    Ok((\n-                        idx,\n-                        handle_variant(\n-                            EnumVariantId { parent: e, local_id: idx }.into(),\n-                            &v.variant_data,\n-                        )?,\n-                    ))\n+                    handle_variant(\n+                        EnumVariantId { parent: e, local_id: idx }.into(),\n+                        &v.variant_data,\n+                    )\n                 })\n-                .collect::<Result<_, _>>()?;\n-            (r, true, data.repr.unwrap_or_default())\n-        }\n-    };\n-\n-    // A variant is absent if it's uninhabited and only has ZST fields.\n-    // Present uninhabited variants only require space for their fields,\n-    // but *not* an encoding of the discriminant (e.g., a tag value).\n-    // See issue #49298 for more details on the need to leave space\n-    // for non-ZST uninhabited data (mostly partial initialization).\n-    let absent = |fields: &[Layout]| {\n-        let uninhabited = fields.iter().any(|f| f.abi.is_uninhabited());\n-        let is_zst = fields.iter().all(|f| f.is_zst());\n-        uninhabited && is_zst\n-    };\n-    let (present_first, present_second) = {\n-        let mut present_variants =\n-            variants.iter().filter_map(|(i, v)| if absent(v) { None } else { Some(i) });\n-        (present_variants.next(), present_variants.next())\n-    };\n-    let present_first = match present_first {\n-        Some(present_first) => present_first,\n-        // Uninhabited because it has no variants, or only absent ones.\n-        None if is_enum => return layout_of_ty(db, &TyKind::Never.intern(Interner)),\n-        // If it's a struct, still compute a layout so that we can still compute the\n-        // field offsets.\n-        None => struct_variant_idx(),\n-    };\n-\n-    let is_univariant = !is_enum ||\n-                    // Only one variant is present.\n-                    (present_second.is_none() &&\n-                        // Representation optimizations are allowed.\n-                        !repr.inhibit_enum_layout_opt());\n-    let dl = &*db.current_target_data_layout();\n-\n-    if is_univariant {\n-        // Struct, or univariant enum equivalent to a struct.\n-        // (Typechecking will reject discriminant-sizing attrs.)\n-\n-        let v = present_first;\n-        let kind = if is_enum || variants[v].is_empty() {\n-            StructKind::AlwaysSized\n-        } else {\n-            let always_sized = !variants[v].last().unwrap().is_unsized();\n-            if !always_sized {\n-                StructKind::MaybeUnsized\n-            } else {\n-                StructKind::AlwaysSized\n-            }\n-        };\n-\n-        let mut st = univariant(dl, &variants[v], &repr, kind)?;\n-        st.variants = Variants::Single;\n-\n-        if is_unsafe_cell(def, db) {\n-            let hide_niches = |scalar: &mut _| match scalar {\n-                Scalar::Initialized { value, valid_range } => {\n-                    *valid_range = WrappingRange::full(value.size(dl))\n-                }\n-                // Already doesn't have any niches\n-                Scalar::Union { .. } => {}\n-            };\n-            match &mut st.abi {\n-                Abi::Uninhabited => {}\n-                Abi::Scalar(scalar) => hide_niches(scalar),\n-                Abi::ScalarPair(a, b) => {\n-                    hide_niches(a);\n-                    hide_niches(b);\n-                }\n-                Abi::Vector { element, count: _ } => hide_niches(element),\n-                Abi::Aggregate { sized: _ } => {}\n-            }\n-            st.largest_niche = None;\n-            return Ok(st);\n-        }\n-\n-        let (start, end) = layout_scalar_valid_range(db, def);\n-        match st.abi {\n-            Abi::Scalar(ref mut scalar) | Abi::ScalarPair(ref mut scalar, _) => {\n-                if let Bound::Included(start) = start {\n-                    let valid_range = scalar.valid_range_mut();\n-                    valid_range.start = start;\n-                }\n-                if let Bound::Included(end) = end {\n-                    let valid_range = scalar.valid_range_mut();\n-                    valid_range.end = end;\n-                }\n-                // Update `largest_niche` if we have introduced a larger niche.\n-                let niche = Niche::from_scalar(dl, Size::ZERO, *scalar);\n-                if let Some(niche) = niche {\n-                    match st.largest_niche {\n-                        Some(largest_niche) => {\n-                            // Replace the existing niche even if they're equal,\n-                            // because this one is at a lower offset.\n-                            if largest_niche.available(dl) <= niche.available(dl) {\n-                                st.largest_niche = Some(niche);\n-                            }\n-                        }\n-                        None => st.largest_niche = Some(niche),\n-                    }\n-                }\n-            }\n-            _ => user_error!(\"nonscalar layout for layout_scalar_valid_range\"),\n-        }\n-\n-        return Ok(st);\n-    }\n-\n-    // Until we've decided whether to use the tagged or\n-    // niche filling LayoutS, we don't want to intern the\n-    // variant layouts, so we can't store them in the\n-    // overall LayoutS. Store the overall LayoutS\n-    // and the variant LayoutSs here until then.\n-    struct TmpLayout {\n-        layout: Layout,\n-        variants: ArenaMap<LocalEnumVariantId, Layout>,\n-    }\n-\n-    let calculate_niche_filling_layout = || -> Result<Option<TmpLayout>, LayoutError> {\n-        // The current code for niche-filling relies on variant indices\n-        // instead of actual discriminants, so enums with\n-        // explicit discriminants (RFC #2363) would misbehave.\n-        if repr.inhibit_enum_layout_opt()\n-        // FIXME: bring these codes back\n-        // || def\n-        //     .variants()\n-        //     .iter_enumerated()\n-        //     .any(|(i, v)| v.discr != ty::VariantDiscr::Relative(i.as_u32()))\n-        {\n-            return Ok(None);\n-        }\n-\n-        if variants.iter().count() < 2 {\n-            return Ok(None);\n-        }\n-\n-        let mut align = dl.aggregate_align;\n-        let mut variant_layouts = variants\n-            .iter()\n-            .map(|(j, v)| {\n-                let mut st = univariant(dl, v, &repr, StructKind::AlwaysSized)?;\n-                st.variants = Variants::Single;\n-\n-                align = align.max(st.align);\n-\n-                Ok((j, st))\n-            })\n-            .collect::<Result<ArenaMap<_, _>, _>>()?;\n-\n-        let largest_variant_index = match variant_layouts\n-            .iter()\n-            .max_by_key(|(_i, layout)| layout.size.bytes())\n-            .map(|(i, _layout)| i)\n-        {\n-            None => return Ok(None),\n-            Some(i) => i,\n-        };\n-\n-        let count = variants\n-            .iter()\n-            .map(|(i, _)| i)\n-            .filter(|x| *x != largest_variant_index && !absent(&variants[*x]))\n-            .count() as u128;\n-\n-        // Find the field with the largest niche\n-        let (field_index, niche, (niche_start, niche_scalar)) = match variants\n-            [largest_variant_index]\n-            .iter()\n-            .enumerate()\n-            .filter_map(|(j, field)| Some((j, field.largest_niche?)))\n-            .max_by_key(|(_, niche)| niche.available(dl))\n-            .and_then(|(j, niche)| Some((j, niche, niche.reserve(dl, count)?)))\n-        {\n-            None => return Ok(None),\n-            Some(x) => x,\n-        };\n-\n-        let niche_offset =\n-            niche.offset + variant_layouts[largest_variant_index].fields.offset(field_index, dl);\n-        let niche_size = niche.value.size(dl);\n-        let size = variant_layouts[largest_variant_index].size.align_to(align.abi);\n-\n-        let all_variants_fit = variant_layouts.iter_mut().all(|(i, layout)| {\n-            if i == largest_variant_index {\n-                return true;\n-            }\n-\n-            layout.largest_niche = None;\n-\n-            if layout.size <= niche_offset {\n-                // This variant will fit before the niche.\n-                return true;\n-            }\n-\n-            // Determine if it'll fit after the niche.\n-            let this_align = layout.align.abi;\n-            let this_offset = (niche_offset + niche_size).align_to(this_align);\n-\n-            if this_offset + layout.size > size {\n-                return false;\n-            }\n-\n-            // It'll fit, but we need to make some adjustments.\n-            match layout.fields {\n-                FieldsShape::Arbitrary { ref mut offsets, .. } => {\n-                    for (j, offset) in offsets.iter_mut().enumerate() {\n-                        if !variants[i][j].is_zst() {\n-                            *offset += this_offset;\n-                        }\n-                    }\n-                }\n-                _ => {\n-                    panic!(\"Layout of fields should be Arbitrary for variants\")\n-                }\n-            }\n-\n-            // It can't be a Scalar or ScalarPair because the offset isn't 0.\n-            if !layout.abi.is_uninhabited() {\n-                layout.abi = Abi::Aggregate { sized: true };\n-            }\n-            layout.size += this_offset;\n-\n-            true\n-        });\n-\n-        if !all_variants_fit {\n-            return Ok(None);\n-        }\n-\n-        let largest_niche = Niche::from_scalar(dl, niche_offset, niche_scalar);\n-\n-        let others_zst = variant_layouts\n-            .iter()\n-            .all(|(i, layout)| i == largest_variant_index || layout.size == Size::ZERO);\n-        let same_size = size == variant_layouts[largest_variant_index].size;\n-        let same_align = align == variant_layouts[largest_variant_index].align;\n-\n-        let abi = if variant_layouts.iter().all(|(_, v)| v.abi.is_uninhabited()) {\n-            Abi::Uninhabited\n-        } else if same_size && same_align && others_zst {\n-            match variant_layouts[largest_variant_index].abi {\n-                // When the total alignment and size match, we can use the\n-                // same ABI as the scalar variant with the reserved niche.\n-                Abi::Scalar(_) => Abi::Scalar(niche_scalar),\n-                Abi::ScalarPair(first, second) => {\n-                    // Only the niche is guaranteed to be initialised,\n-                    // so use union layouts for the other primitive.\n-                    if niche_offset == Size::ZERO {\n-                        Abi::ScalarPair(niche_scalar, second.to_union())\n-                    } else {\n-                        Abi::ScalarPair(first.to_union(), niche_scalar)\n-                    }\n-                }\n-                _ => Abi::Aggregate { sized: true },\n-            }\n-        } else {\n-            Abi::Aggregate { sized: true }\n-        };\n-\n-        let layout = Layout {\n-            variants: Variants::Multiple {\n-                tag: niche_scalar,\n-                tag_encoding: TagEncoding::Niche {\n-                    untagged_variant: largest_variant_index,\n-                    niche_start,\n-                },\n-                tag_field: 0,\n-                variants: ArenaMap::new(),\n-            },\n-            fields: FieldsShape::Arbitrary { offsets: vec![niche_offset], memory_index: vec![0] },\n-            abi,\n-            largest_niche,\n-            size,\n-            align,\n-        };\n-\n-        Ok(Some(TmpLayout { layout, variants: variant_layouts }))\n-    };\n-\n-    let niche_filling_layout = calculate_niche_filling_layout()?;\n-\n-    let (mut min, mut max) = (i128::MAX, i128::MIN);\n-    // FIXME: bring these back\n-    // let discr_type = repr.discr_type();\n-    // let bits = Integer::from_attr(dl, discr_type).size().bits();\n-    // for (i, discr) in def.discriminants(tcx) {\n-    //     if variants[i].iter().any(|f| f.abi.is_uninhabited()) {\n-    //         continue;\n-    //     }\n-    //     let mut x = discr.val as i128;\n-    //     if discr_type.is_signed() {\n-    //         // sign extend the raw representation to be an i128\n-    //         x = (x << (128 - bits)) >> (128 - bits);\n-    //     }\n-    //     if x < min {\n-    //         min = x;\n-    //     }\n-    //     if x > max {\n-    //         max = x;\n-    //     }\n-    // }\n-    // We might have no inhabited variants, so pretend there's at least one.\n-    if (min, max) == (i128::MAX, i128::MIN) {\n-        min = 0;\n-        max = 0;\n-    }\n-    assert!(min <= max, \"discriminant range is {}...{}\", min, max);\n-    let (min_ity, signed) = Integer::repr_discr(dl, &repr, min, max)?;\n-\n-    let mut align = dl.aggregate_align;\n-    let mut size = Size::ZERO;\n-\n-    // We're interested in the smallest alignment, so start large.\n-    let mut start_align = Align::from_bytes(256).unwrap();\n-    assert_eq!(Integer::for_align(dl, start_align), None);\n-\n-    // repr(C) on an enum tells us to make a (tag, union) layout,\n-    // so we need to grow the prefix alignment to be at least\n-    // the alignment of the union. (This value is used both for\n-    // determining the alignment of the overall enum, and the\n-    // determining the alignment of the payload after the tag.)\n-    let mut prefix_align = min_ity.align(dl).abi;\n-    if repr.c() {\n-        for (_, fields) in variants.iter() {\n-            for field in fields {\n-                prefix_align = prefix_align.max(field.align.abi);\n-            }\n+                .collect::<Result<IndexVec<RustcEnumVariantIdx, _>, _>>()?;\n+            (r, true, false, data.repr.unwrap_or_default())\n         }\n-    }\n-\n-    // Create the set of structs that represent each variant.\n-    let mut layout_variants = variants\n-        .iter()\n-        .map(|(i, field_layouts)| {\n-            let mut st = univariant(\n-                dl,\n-                &field_layouts,\n-                &repr,\n-                StructKind::Prefixed(min_ity.size(), prefix_align),\n-            )?;\n-            st.variants = Variants::Single;\n-            // Find the first field we can't move later\n-            // to make room for a larger discriminant.\n-            for field in st.fields.index_by_increasing_offset().map(|j| &field_layouts[j]) {\n-                if !field.is_zst() || field.align.abi.bytes() != 1 {\n-                    start_align = start_align.min(field.align.abi);\n-                    break;\n-                }\n-            }\n-            size = cmp::max(size, st.size);\n-            align = align.max(st.align);\n-            Ok((i, st))\n-        })\n-        .collect::<Result<ArenaMap<_, _>, _>>()?;\n-\n-    // Align the maximum variant size to the largest alignment.\n-    size = size.align_to(align.abi);\n-\n-    if size.bytes() >= dl.obj_size_bound() {\n-        return Err(LayoutError::SizeOverflow);\n-    }\n-\n-    // Check to see if we should use a different type for the\n-    // discriminant. We can safely use a type with the same size\n-    // as the alignment of the first field of each variant.\n-    // We increase the size of the discriminant to avoid LLVM copying\n-    // padding when it doesn't need to. This normally causes unaligned\n-    // load/stores and excessive memcpy/memset operations. By using a\n-    // bigger integer size, LLVM can be sure about its contents and\n-    // won't be so conservative.\n-\n-    // Use the initial field alignment\n-    let mut ity = if repr.c() || repr.int.is_some() {\n-        min_ity\n-    } else {\n-        Integer::for_align(dl, start_align).unwrap_or(min_ity)\n-    };\n-\n-    // If the alignment is not larger than the chosen discriminant size,\n-    // don't use the alignment as the final size.\n-    if ity <= min_ity {\n-        ity = min_ity;\n-    } else {\n-        // Patch up the variants' first few fields.\n-        // Patch up the variants' first few fields.\n-        let old_ity_size = min_ity.size();\n-        let new_ity_size = ity.size();\n-        for (_, variant) in layout_variants.iter_mut() {\n-            match variant.fields {\n-                FieldsShape::Arbitrary { ref mut offsets, .. } => {\n-                    for i in offsets {\n-                        if *i <= old_ity_size {\n-                            assert_eq!(*i, old_ity_size);\n-                            *i = new_ity_size;\n-                        }\n-                    }\n-                    // We might be making the struct larger.\n-                    if variant.size <= old_ity_size {\n-                        variant.size = new_ity_size;\n-                    }\n-                }\n-                _ => user_error!(\"bug\"),\n-            }\n-        }\n-    }\n-\n-    let tag_mask = ity.size().unsigned_int_max();\n-    let tag = Scalar::Initialized {\n-        value: Primitive::Int(ity, signed),\n-        valid_range: WrappingRange {\n-            start: (min as u128 & tag_mask),\n-            end: (max as u128 & tag_mask),\n-        },\n     };\n-    let mut abi = Abi::Aggregate { sized: true };\n-\n-    if layout_variants.iter().all(|(_, v)| v.abi.is_uninhabited()) {\n-        abi = Abi::Uninhabited;\n-    } else if tag.size(dl) == size {\n-        // Make sure we only use scalar layout when the enum is entirely its\n-        // own tag (i.e. it has no padding nor any non-ZST variant fields).\n-        abi = Abi::Scalar(tag);\n+    let variants = variants.iter().map(|x| x.iter().collect::<Vec<_>>()).collect::<Vec<_>>();\n+    let variants = variants.iter().map(|x| x.iter().collect()).collect();\n+    if is_union {\n+        cx.layout_of_union(&repr, &variants).ok_or(LayoutError::Unknown)\n     } else {\n-        // Try to use a ScalarPair for all tagged enums.\n-        let mut common_prim = None;\n-        let mut common_prim_initialized_in_all_variants = true;\n-        for ((_, field_layouts), (_, layout_variant)) in\n-            iter::zip(variants.iter(), layout_variants.iter())\n-        {\n-            let offsets = match layout_variant.fields {\n-                FieldsShape::Arbitrary { ref offsets, .. } => offsets,\n-                _ => user_error!(\"bug\"),\n-            };\n-            let mut fields = iter::zip(field_layouts, offsets).filter(|p| !p.0.is_zst());\n-            let (field, offset) = match (fields.next(), fields.next()) {\n-                (None, None) => {\n-                    common_prim_initialized_in_all_variants = false;\n-                    continue;\n-                }\n-                (Some(pair), None) => pair,\n-                _ => {\n-                    common_prim = None;\n-                    break;\n-                }\n-            };\n-            let prim = match field.abi {\n-                Abi::Scalar(scalar) => {\n-                    common_prim_initialized_in_all_variants &=\n-                        matches!(scalar, Scalar::Initialized { .. });\n-                    scalar.primitive()\n-                }\n-                _ => {\n-                    common_prim = None;\n-                    break;\n-                }\n-            };\n-            if let Some(pair) = common_prim {\n-                // This is pretty conservative. We could go fancier\n-                // by conflating things like i32 and u32, or even\n-                // realising that (u8, u8) could just cohabit with\n-                // u16 or even u32.\n-                if pair != (prim, offset) {\n-                    common_prim = None;\n-                    break;\n-                }\n-            } else {\n-                common_prim = Some((prim, offset));\n-            }\n-        }\n-        if let Some((prim, offset)) = common_prim {\n-            let prim_scalar = if common_prim_initialized_in_all_variants {\n-                scalar_unit(dl, prim)\n-            } else {\n-                // Common prim might be uninit.\n-                Scalar::Union { value: prim }\n-            };\n-            let pair = scalar_pair(dl, tag, prim_scalar);\n-            let pair_offsets = match pair.fields {\n-                FieldsShape::Arbitrary { ref offsets, ref memory_index } => {\n-                    assert_eq!(memory_index, &[0, 1]);\n-                    offsets\n-                }\n-                _ => user_error!(\"bug\"),\n-            };\n-            if pair_offsets[0] == Size::ZERO\n-                && pair_offsets[1] == *offset\n-                && align == pair.align\n-                && size == pair.size\n-            {\n-                // We can use `ScalarPair` only when it matches our\n-                // already computed layout (including `#[repr(C)]`).\n-                abi = pair.abi;\n-            }\n-        }\n-    }\n-\n-    // If we pick a \"clever\" (by-value) ABI, we might have to adjust the ABI of the\n-    // variants to ensure they are consistent. This is because a downcast is\n-    // semantically a NOP, and thus should not affect layout.\n-    if matches!(abi, Abi::Scalar(..) | Abi::ScalarPair(..)) {\n-        for (_, variant) in layout_variants.iter_mut() {\n-            // We only do this for variants with fields; the others are not accessed anyway.\n-            // Also do not overwrite any already existing \"clever\" ABIs.\n-            if variant.fields.count() > 0 && matches!(variant.abi, Abi::Aggregate { .. }) {\n-                variant.abi = abi;\n-                // Also need to bump up the size and alignment, so that the entire value fits in here.\n-                variant.size = cmp::max(variant.size, size);\n-                variant.align.abi = cmp::max(variant.align.abi, align.abi);\n-            }\n-        }\n+        cx.layout_of_struct_or_enum(\n+            &repr,\n+            &variants,\n+            is_enum,\n+            is_unsafe_cell(def, db),\n+            layout_scalar_valid_range(db, def),\n+            |min, max| Integer::repr_discr(&dl, &repr, min, max).unwrap_or((Integer::I8, false)),\n+            variants.iter_enumerated().filter_map(|(id, _)| {\n+                let AdtId::EnumId(e) = def else { return None };\n+                let d = match db\n+                    .const_eval_variant(EnumVariantId { parent: e, local_id: id.0 })\n+                    .ok()?\n+                {\n+                    crate::consteval::ComputedExpr::Literal(l) => match l {\n+                        hir_def::expr::Literal::Int(i, _) => i,\n+                        hir_def::expr::Literal::Uint(i, _) => i as i128,\n+                        _ => return None,\n+                    },\n+                    _ => return None,\n+                };\n+                Some((id, d))\n+            }),\n+            // FIXME: The current code for niche-filling relies on variant indices\n+            // instead of actual discriminants, so enums with\n+            // explicit discriminants (RFC #2363) would misbehave and we should disable\n+            // niche optimization for them.\n+            // The code that do it in rustc:\n+            // repr.inhibit_enum_layout_opt() || def\n+            //     .variants()\n+            //     .iter_enumerated()\n+            //     .any(|(i, v)| v.discr != ty::VariantDiscr::Relative(i.as_u32()))\n+            repr.inhibit_enum_layout_opt(),\n+            !is_enum\n+                && variants\n+                    .iter()\n+                    .next()\n+                    .and_then(|x| x.last().map(|x| x.is_unsized()))\n+                    .unwrap_or(true),\n+        )\n+        .ok_or(LayoutError::SizeOverflow)\n     }\n-\n-    let largest_niche = Niche::from_scalar(dl, Size::ZERO, tag);\n-\n-    let tagged_layout = Layout {\n-        variants: Variants::Multiple {\n-            tag,\n-            tag_encoding: TagEncoding::Direct,\n-            tag_field: 0,\n-            variants: ArenaMap::new(),\n-        },\n-        fields: FieldsShape::Arbitrary { offsets: vec![Size::ZERO], memory_index: vec![0] },\n-        largest_niche,\n-        abi,\n-        align,\n-        size,\n-    };\n-\n-    let tagged_layout = TmpLayout { layout: tagged_layout, variants: layout_variants };\n-\n-    let mut best_layout = match (tagged_layout, niche_filling_layout) {\n-        (tl, Some(nl)) => {\n-            // Pick the smaller layout; otherwise,\n-            // pick the layout with the larger niche; otherwise,\n-            // pick tagged as it has simpler codegen.\n-            use Ordering::*;\n-            let niche_size =\n-                |tmp_l: &TmpLayout| tmp_l.layout.largest_niche.map_or(0, |n| n.available(dl));\n-            match (tl.layout.size.cmp(&nl.layout.size), niche_size(&tl).cmp(&niche_size(&nl))) {\n-                (Greater, _) => nl,\n-                (Equal, Less) => nl,\n-                _ => tl,\n-            }\n-        }\n-        (tl, None) => tl,\n-    };\n-\n-    // Now we can intern the variant layouts and store them in the enum layout.\n-    best_layout.layout.variants = match best_layout.layout.variants {\n-        Variants::Multiple { tag, tag_encoding, tag_field, .. } => {\n-            Variants::Multiple { tag, tag_encoding, tag_field, variants: best_layout.variants }\n-        }\n-        _ => user_error!(\"bug\"),\n-    };\n-\n-    Ok(best_layout.layout)\n }\n \n fn layout_scalar_valid_range(db: &dyn HirDatabase, def: AdtId) -> (Bound<u128>, Bound<u128>) {\n@@ -649,302 +131,3 @@ pub fn layout_of_adt_recover(\n ) -> Result<Layout, LayoutError> {\n     user_error!(\"infinite sized recursive type\");\n }\n-\n-pub(crate) fn univariant(\n-    dl: &TargetDataLayout,\n-    fields: &[Layout],\n-    repr: &ReprOptions,\n-    kind: StructKind,\n-) -> Result<Layout, LayoutError> {\n-    let pack = repr.pack;\n-    if pack.is_some() && repr.align.is_some() {\n-        user_error!(\"Struct can not be packed and aligned\");\n-    }\n-\n-    let mut align = if pack.is_some() { dl.i8_align } else { dl.aggregate_align };\n-\n-    let mut inverse_memory_index: Vec<u32> = (0..fields.len() as u32).collect();\n-\n-    let optimize = !repr.inhibit_struct_field_reordering_opt();\n-    if optimize {\n-        let end = if let StructKind::MaybeUnsized = kind { fields.len() - 1 } else { fields.len() };\n-        let optimizing = &mut inverse_memory_index[..end];\n-        let field_align = |f: &Layout| {\n-            if let Some(pack) = pack {\n-                f.align.abi.min(pack)\n-            } else {\n-                f.align.abi\n-            }\n-        };\n-\n-        match kind {\n-            StructKind::AlwaysSized | StructKind::MaybeUnsized => {\n-                optimizing.sort_by_key(|&x| {\n-                    // Place ZSTs first to avoid \"interesting offsets\",\n-                    // especially with only one or two non-ZST fields.\n-                    let f = &fields[x as usize];\n-                    (!f.is_zst(), cmp::Reverse(field_align(f)))\n-                });\n-            }\n-\n-            StructKind::Prefixed(..) => {\n-                // Sort in ascending alignment so that the layout stays optimal\n-                // regardless of the prefix\n-                optimizing.sort_by_key(|&x| field_align(&fields[x as usize]));\n-            }\n-        }\n-    }\n-\n-    // inverse_memory_index holds field indices by increasing memory offset.\n-    // That is, if field 5 has offset 0, the first element of inverse_memory_index is 5.\n-    // We now write field offsets to the corresponding offset slot;\n-    // field 5 with offset 0 puts 0 in offsets[5].\n-    // At the bottom of this function, we invert `inverse_memory_index` to\n-    // produce `memory_index` (see `invert_mapping`).\n-\n-    let mut sized = true;\n-    let mut offsets = vec![Size::ZERO; fields.len()];\n-    let mut offset = Size::ZERO;\n-    let mut largest_niche = None;\n-    let mut largest_niche_available = 0;\n-\n-    if let StructKind::Prefixed(prefix_size, prefix_align) = kind {\n-        let prefix_align =\n-            if let Some(pack) = pack { prefix_align.min(pack) } else { prefix_align };\n-        align = align.max(AbiAndPrefAlign::new(prefix_align));\n-        offset = prefix_size.align_to(prefix_align);\n-    }\n-\n-    for &i in &inverse_memory_index {\n-        let field = &fields[i as usize];\n-        if !sized {\n-            user_error!(\"Unsized field is not last field\");\n-        }\n-\n-        if field.is_unsized() {\n-            sized = false;\n-        }\n-\n-        // Invariant: offset < dl.obj_size_bound() <= 1<<61\n-        let field_align = if let Some(pack) = pack {\n-            field.align.min(AbiAndPrefAlign::new(pack))\n-        } else {\n-            field.align\n-        };\n-        offset = offset.align_to(field_align.abi);\n-        align = align.max(field_align);\n-\n-        offsets[i as usize] = offset;\n-\n-        if let Some(mut niche) = field.largest_niche {\n-            let available = niche.available(dl);\n-            if available > largest_niche_available {\n-                largest_niche_available = available;\n-                niche.offset =\n-                    niche.offset.checked_add(offset, dl).ok_or(LayoutError::SizeOverflow)?;\n-                largest_niche = Some(niche);\n-            }\n-        }\n-\n-        offset = offset.checked_add(field.size, dl).ok_or(LayoutError::SizeOverflow)?;\n-    }\n-\n-    if let Some(repr_align) = repr.align {\n-        align = align.max(AbiAndPrefAlign::new(repr_align));\n-    }\n-\n-    let min_size = offset;\n-\n-    // As stated above, inverse_memory_index holds field indices by increasing offset.\n-    // This makes it an already-sorted view of the offsets vec.\n-    // To invert it, consider:\n-    // If field 5 has offset 0, offsets[0] is 5, and memory_index[5] should be 0.\n-    // Field 5 would be the first element, so memory_index is i:\n-    // Note: if we didn't optimize, it's already right.\n-\n-    let memory_index =\n-        if optimize { invert_mapping(&inverse_memory_index) } else { inverse_memory_index };\n-\n-    let size = min_size.align_to(align.abi);\n-    let mut abi = Abi::Aggregate { sized };\n-\n-    // Unpack newtype ABIs and find scalar pairs.\n-    if sized && size.bytes() > 0 {\n-        // All other fields must be ZSTs.\n-        let mut non_zst_fields = fields.iter().enumerate().filter(|&(_, f)| !f.is_zst());\n-\n-        match (non_zst_fields.next(), non_zst_fields.next(), non_zst_fields.next()) {\n-            // We have exactly one non-ZST field.\n-            (Some((i, field)), None, None) => {\n-                // Field fills the struct and it has a scalar or scalar pair ABI.\n-                if offsets[i].bytes() == 0 && align.abi == field.align.abi && size == field.size {\n-                    match field.abi {\n-                        // For plain scalars, or vectors of them, we can't unpack\n-                        // newtypes for `#[repr(C)]`, as that affects C ABIs.\n-                        Abi::Scalar(_) | Abi::Vector { .. } if optimize => {\n-                            abi = field.abi;\n-                        }\n-                        // But scalar pairs are Rust-specific and get\n-                        // treated as aggregates by C ABIs anyway.\n-                        Abi::ScalarPair(..) => {\n-                            abi = field.abi;\n-                        }\n-                        _ => {}\n-                    }\n-                }\n-            }\n-\n-            // Two non-ZST fields, and they're both scalars.\n-            (Some((i, a)), Some((j, b)), None) => {\n-                match (a.abi, b.abi) {\n-                    (Abi::Scalar(a), Abi::Scalar(b)) => {\n-                        // Order by the memory placement, not source order.\n-                        let ((i, a), (j, b)) = if offsets[i] < offsets[j] {\n-                            ((i, a), (j, b))\n-                        } else {\n-                            ((j, b), (i, a))\n-                        };\n-                        let pair = scalar_pair(dl, a, b);\n-                        let pair_offsets = match pair.fields {\n-                            FieldsShape::Arbitrary { ref offsets, .. } => offsets,\n-                            _ => unreachable!(),\n-                        };\n-                        if offsets[i] == pair_offsets[0]\n-                            && offsets[j] == pair_offsets[1]\n-                            && align == pair.align\n-                            && size == pair.size\n-                        {\n-                            // We can use `ScalarPair` only when it matches our\n-                            // already computed layout (including `#[repr(C)]`).\n-                            abi = pair.abi;\n-                        }\n-                    }\n-                    _ => {}\n-                }\n-            }\n-\n-            _ => {}\n-        }\n-    }\n-\n-    if fields.iter().any(|f| f.abi.is_uninhabited()) {\n-        abi = Abi::Uninhabited;\n-    }\n-\n-    Ok(Layout {\n-        variants: Variants::Single,\n-        fields: FieldsShape::Arbitrary { offsets, memory_index },\n-        abi,\n-        largest_niche,\n-        align,\n-        size,\n-    })\n-}\n-\n-fn layout_of_union(\n-    db: &dyn HirDatabase,\n-    id: UnionId,\n-    subst: &Substitution,\n-) -> Result<Layout, LayoutError> {\n-    let dl = &*db.current_target_data_layout();\n-\n-    let union_data = db.union_data(id);\n-\n-    let repr = union_data.repr.unwrap_or_default();\n-    let fields = union_data.variant_data.fields();\n-\n-    if repr.pack.is_some() && repr.align.is_some() {\n-        user_error!(\"union cannot be packed and aligned\");\n-    }\n-\n-    let mut align = if repr.pack.is_some() { dl.i8_align } else { dl.aggregate_align };\n-    if let Some(repr_align) = repr.align {\n-        align = align.max(AbiAndPrefAlign::new(repr_align));\n-    }\n-\n-    let optimize = !repr.inhibit_union_abi_opt();\n-    let mut size = Size::ZERO;\n-    let mut abi = Abi::Aggregate { sized: true };\n-    for (fd, _) in fields.iter() {\n-        let field_ty = field_ty(db, id.into(), fd, subst);\n-        let field = layout_of_ty(db, &field_ty)?;\n-        if field.is_unsized() {\n-            user_error!(\"unsized union field\");\n-        }\n-        // If all non-ZST fields have the same ABI, forward this ABI\n-        if optimize && !field.is_zst() {\n-            // Discard valid range information and allow undef\n-            let field_abi = match field.abi {\n-                Abi::Scalar(x) => Abi::Scalar(x.to_union()),\n-                Abi::ScalarPair(x, y) => Abi::ScalarPair(x.to_union(), y.to_union()),\n-                Abi::Vector { element: x, count } => Abi::Vector { element: x.to_union(), count },\n-                Abi::Uninhabited | Abi::Aggregate { .. } => Abi::Aggregate { sized: true },\n-            };\n-\n-            if size == Size::ZERO {\n-                // first non ZST: initialize 'abi'\n-                abi = field_abi;\n-            } else if abi != field_abi {\n-                // different fields have different ABI: reset to Aggregate\n-                abi = Abi::Aggregate { sized: true };\n-            }\n-        }\n-\n-        size = cmp::max(size, field.size);\n-    }\n-\n-    if let Some(pack) = repr.pack {\n-        align = align.min(AbiAndPrefAlign::new(pack));\n-    }\n-\n-    Ok(Layout {\n-        variants: Variants::Single,\n-        fields: FieldsShape::Union(\n-            NonZeroUsize::new(fields.len())\n-                .ok_or(LayoutError::UserError(\"union with zero fields\".to_string()))?,\n-        ),\n-        abi,\n-        largest_niche: None,\n-        align,\n-        size: size.align_to(align.abi),\n-    })\n-}\n-\n-// Invert a bijective mapping, i.e. `invert(map)[y] = x` if `map[x] = y`.\n-// This is used to go between `memory_index` (source field order to memory order)\n-// and `inverse_memory_index` (memory order to source field order).\n-// See also `FieldsShape::Arbitrary::memory_index` for more details.\n-// FIXME(eddyb) build a better abstraction for permutations, if possible.\n-fn invert_mapping(map: &[u32]) -> Vec<u32> {\n-    let mut inverse = vec![0; map.len()];\n-    for i in 0..map.len() {\n-        inverse[map[i] as usize] = i as u32;\n-    }\n-    inverse\n-}\n-\n-fn scalar_pair(dl: &TargetDataLayout, a: Scalar, b: Scalar) -> Layout {\n-    let b_align = b.align(dl);\n-    let align = a.align(dl).max(b_align).max(dl.aggregate_align);\n-    let b_offset = a.size(dl).align_to(b_align.abi);\n-    let size = b_offset.checked_add(b.size(dl), dl).unwrap().align_to(align.abi);\n-\n-    // HACK(nox): We iter on `b` and then `a` because `max_by_key`\n-    // returns the last maximum.\n-    let largest_niche = Niche::from_scalar(dl, b_offset, b)\n-        .into_iter()\n-        .chain(Niche::from_scalar(dl, Size::ZERO, a))\n-        .max_by_key(|niche| niche.available(dl));\n-\n-    Layout {\n-        variants: Variants::Single,\n-        fields: FieldsShape::Arbitrary {\n-            offsets: vec![Size::ZERO, b_offset],\n-            memory_index: vec![0, 1],\n-        },\n-        abi: Abi::ScalarPair(a, b),\n-        largest_niche,\n-        align,\n-        size,\n-    }\n-}"}, {"sha": "48b1a68d51b9e63b8f55293a726d34b512e8371c", "filename": "crates/hir-ty/src/layout/target.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftarget.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -35,7 +35,7 @@ pub fn current_target_data_layout_query(db: &dyn HirDatabase) -> Arc<TargetDataL\n         f32_align: AbiAndPrefAlign::new(Align::from_bytes(4).unwrap()),\n         f64_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n         pointer_size,\n-        pointer_align: AbiAndPrefAlign::new(Align::from_bytes(8).unwrap()),\n+        pointer_align: AbiAndPrefAlign::new(Align::from_bytes(pointer_size.bytes()).unwrap()),\n         aggregate_align: AbiAndPrefAlign::new(Align::from_bytes(1).unwrap()),\n         vector_align: vec![],\n         instruction_address_space: AddressSpace(0),"}, {"sha": "5d97a69501f018708c89879f4c63695ea037a0c5", "filename": "crates/hir-ty/src/layout/tests.rs", "status": "modified", "additions": 42, "deletions": 26, "changes": 68, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir-ty%2Fsrc%2Flayout%2Ftests.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -49,6 +49,17 @@ fn check_fail(ra_fixture: &str, e: LayoutError) {\n }\n \n macro_rules! size_and_align {\n+    (minicore: $($x:tt),*;$($t:tt)*) => {\n+        {\n+            #[allow(dead_code)]\n+            $($t)*\n+            check_size_and_align(\n+                &format!(\"//- minicore: {}\\n{}\", stringify!($($x),*), stringify!($($t)*)),\n+                ::std::mem::size_of::<Goal>() as u64,\n+                ::std::mem::align_of::<Goal>() as u64,\n+            );\n+        }\n+    };\n     ($($t:tt)*) => {\n         {\n             #[allow(dead_code)]\n@@ -67,7 +78,6 @@ fn hello_world() {\n     size_and_align! {\n         struct Goal(i32);\n     }\n-    //check_size_and_align(r#\"struct Goal(i32)\"#, 4, 4);\n }\n \n #[test]\n@@ -148,33 +158,39 @@ fn tuple() {\n \n #[test]\n fn non_zero() {\n-    check_size_and_align(\n-        r#\"\n-    //- minicore: non_zero, option\n-    use core::num::NonZeroU8;\n-    struct Goal(Option<NonZeroU8>);\n-    \"#,\n-        1,\n-        1,\n-    );\n+    size_and_align! {\n+        minicore: non_zero, option;\n+        use core::num::NonZeroU8;\n+        struct Goal(Option<NonZeroU8>);\n+    }\n }\n \n #[test]\n fn niche_optimization() {\n-    check_size_and_align(\n-        r#\"\n-    //- minicore: option\n-    struct Goal(Option<&i32>);\n-    \"#,\n-        8,\n-        8,\n-    );\n-    check_size_and_align(\n-        r#\"\n-    //- minicore: option\n-    struct Goal(Option<Option<bool>>);\n-    \"#,\n-        1,\n-        1,\n-    );\n+    size_and_align! {\n+        minicore: option;\n+        struct Goal(Option<&'static i32>);\n+    }\n+    size_and_align! {\n+        minicore: option;\n+        struct Goal(Option<Option<bool>>);\n+    }\n+}\n+\n+#[test]\n+fn enums_with_discriminants() {\n+    size_and_align! {\n+        enum Goal {\n+            A = 1000,\n+            B = 2000,\n+            C = 3000,\n+        }\n+    }\n+    size_and_align! {\n+        enum Goal {\n+            A = 254,\n+            B,\n+            C, // implicitly becomes 256, so we need two bytes\n+        }\n+    }\n }"}, {"sha": "1b540915395999c71450bcc55c5053bd94b1ec28", "filename": "crates/hir/src/lib.rs", "status": "modified", "additions": 24, "deletions": 2, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fhir%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir%2Fsrc%2Flib.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -994,8 +994,30 @@ impl Enum {\n         Type::new_for_crate(\n             self.id.lookup(db.upcast()).container.krate(),\n             TyBuilder::builtin(match db.enum_data(self.id).variant_body_type() {\n-                Either::Left(builtin) => hir_def::builtin_type::BuiltinType::Int(builtin),\n-                Either::Right(builtin) => hir_def::builtin_type::BuiltinType::Uint(builtin),\n+                hir_def::layout::IntegerType::Pointer(sign) => match sign {\n+                    true => hir_def::builtin_type::BuiltinType::Int(\n+                        hir_def::builtin_type::BuiltinInt::Isize,\n+                    ),\n+                    false => hir_def::builtin_type::BuiltinType::Uint(\n+                        hir_def::builtin_type::BuiltinUint::Usize,\n+                    ),\n+                },\n+                hir_def::layout::IntegerType::Fixed(i, sign) => match sign {\n+                    true => hir_def::builtin_type::BuiltinType::Int(match i {\n+                        hir_def::layout::Integer::I8 => hir_def::builtin_type::BuiltinInt::I8,\n+                        hir_def::layout::Integer::I16 => hir_def::builtin_type::BuiltinInt::I16,\n+                        hir_def::layout::Integer::I32 => hir_def::builtin_type::BuiltinInt::I32,\n+                        hir_def::layout::Integer::I64 => hir_def::builtin_type::BuiltinInt::I64,\n+                        hir_def::layout::Integer::I128 => hir_def::builtin_type::BuiltinInt::I128,\n+                    }),\n+                    false => hir_def::builtin_type::BuiltinType::Uint(match i {\n+                        hir_def::layout::Integer::I8 => hir_def::builtin_type::BuiltinUint::U8,\n+                        hir_def::layout::Integer::I16 => hir_def::builtin_type::BuiltinUint::U16,\n+                        hir_def::layout::Integer::I32 => hir_def::builtin_type::BuiltinUint::U32,\n+                        hir_def::layout::Integer::I64 => hir_def::builtin_type::BuiltinUint::U64,\n+                        hir_def::layout::Integer::I128 => hir_def::builtin_type::BuiltinUint::U128,\n+                    }),\n+                },\n             }),\n         )\n     }"}, {"sha": "f37c9f4a6d527cfd4a7ae58f84855eb3000d3e10", "filename": "crates/ide/src/hover/render.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fide%2Fsrc%2Fhover%2Frender.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fide%2Fsrc%2Fhover%2Frender.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fhover%2Frender.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -3,8 +3,7 @@ use std::fmt::Display;\n \n use either::Either;\n use hir::{\n-    db::HirDatabase, Adt, AsAssocItem, AttributeTemplate, HasAttrs, HasSource, HirDisplay,\n-    Semantics, TypeInfo,\n+    Adt, AsAssocItem, AttributeTemplate, HasAttrs, HasSource, HirDisplay, Semantics, TypeInfo,\n };\n use ide_db::{\n     base_db::SourceDatabase,\n@@ -398,7 +397,7 @@ pub(super) fn definition(\n             let offset = match var_def {\n                 hir::VariantDef::Struct(s) => {\n                     let layout = Adt::from(s).layout(db).ok()?;\n-                    layout.fields.offset(id, &db.current_target_data_layout())\n+                    layout.fields.offset(id)\n                 }\n                 _ => return None,\n             };"}, {"sha": "f82fd6d0289c6816f3302f2ccdbeac86206354f0", "filename": "crates/ide/src/hover/tests.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/05906da0ec54fa218b4f395086e21af01ecec40a/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fhover%2Ftests.rs?ref=05906da0ec54fa218b4f395086e21af01ecec40a", "patch": "@@ -537,7 +537,7 @@ struct Foo { fiel$0d_a: u8, field_b: i32, field_c: i16 }\n             ```\n \n             ```rust\n-            field_a: u8 // size = 1, align = 1, offset = 6\n+            field_a: u8 // size = 1, align = 1, offset = 4\n             ```\n         \"#]],\n     );"}]}