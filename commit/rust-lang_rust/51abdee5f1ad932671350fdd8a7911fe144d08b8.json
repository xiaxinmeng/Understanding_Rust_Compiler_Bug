{"sha": "51abdee5f1ad932671350fdd8a7911fe144d08b8", "node_id": "MDY6Q29tbWl0NzI0NzEyOjUxYWJkZWU1ZjFhZDkzMjY3MTM1MGZkZDhhNzkxMWZlMTQ0ZDA4Yjg=", "commit": {"author": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2013-12-13T02:01:59Z"}, "committer": {"name": "Alex Crichton", "email": "alex@alexcrichton.com", "date": "2013-12-25T03:59:52Z"}, "message": "green: Rip the bandaid off, introduce libgreen\n\nThis extracts everything related to green scheduling from libstd and introduces\na new libgreen crate. This mostly involves deleting most of std::rt and moving\nit to libgreen.\n\nAlong with the movement of code, this commit rearchitects many functions in the\nscheduler in order to adapt to the fact that Local::take now *only* works on a\nTask, not a scheduler. This mostly just involved threading the current green\ntask through in a few locations, but there were one or two spots where things\ngot hairy.\n\nThere are a few repercussions of this commit:\n\n* tube/rc have been removed (the runtime implementation of rc)\n* There is no longer a \"single threaded\" spawning mode for tasks. This is now\n  encompassed by 1:1 scheduling + communication. Convenience methods have been\n  introduced that are specific to libgreen to assist in the spawning of pools of\n  schedulers.", "tree": {"sha": "e65726bf152c97cb9854a3e13b3818c0ecde5493", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e65726bf152c97cb9854a3e13b3818c0ecde5493"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/51abdee5f1ad932671350fdd8a7911fe144d08b8", "comment_count": 1, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/51abdee5f1ad932671350fdd8a7911fe144d08b8", "html_url": "https://github.com/rust-lang/rust/commit/51abdee5f1ad932671350fdd8a7911fe144d08b8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/51abdee5f1ad932671350fdd8a7911fe144d08b8/comments", "author": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "alexcrichton", "id": 64996, "node_id": "MDQ6VXNlcjY0OTk2", "avatar_url": "https://avatars.githubusercontent.com/u/64996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alexcrichton", "html_url": "https://github.com/alexcrichton", "followers_url": "https://api.github.com/users/alexcrichton/followers", "following_url": "https://api.github.com/users/alexcrichton/following{/other_user}", "gists_url": "https://api.github.com/users/alexcrichton/gists{/gist_id}", "starred_url": "https://api.github.com/users/alexcrichton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alexcrichton/subscriptions", "organizations_url": "https://api.github.com/users/alexcrichton/orgs", "repos_url": "https://api.github.com/users/alexcrichton/repos", "events_url": "https://api.github.com/users/alexcrichton/events{/privacy}", "received_events_url": "https://api.github.com/users/alexcrichton/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "url": "https://api.github.com/repos/rust-lang/rust/commits/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "html_url": "https://github.com/rust-lang/rust/commit/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a"}], "stats": {"total": 3735, "additions": 1695, "deletions": 2040}, "files": [{"sha": "649a9a0664468bff165b7602f620212746a411a7", "filename": "src/libextra/task_pool.rs", "status": "modified", "additions": 3, "deletions": 15, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibextra%2Ftask_pool.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibextra%2Ftask_pool.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibextra%2Ftask_pool.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -14,7 +14,6 @@\n /// parallelism.\n \n \n-use std::task::SchedMode;\n use std::task;\n use std::vec;\n \n@@ -46,7 +45,6 @@ impl<T> TaskPool<T> {\n     /// returns a function which, given the index of the task, should return\n     /// local data to be kept around in that task.\n     pub fn new(n_tasks: uint,\n-               opt_sched_mode: Option<SchedMode>,\n                init_fn_factory: || -> proc(uint) -> T)\n                -> TaskPool<T> {\n         assert!(n_tasks >= 1);\n@@ -65,18 +63,8 @@ impl<T> TaskPool<T> {\n                 }\n             };\n \n-            // Start the task.\n-            match opt_sched_mode {\n-                None => {\n-                    // Run on this scheduler.\n-                    task::spawn(task_body);\n-                }\n-                Some(sched_mode) => {\n-                    let mut task = task::task();\n-                    task.sched_mode(sched_mode);\n-                    task.spawn(task_body);\n-                }\n-            }\n+            // Run on this scheduler.\n+            task::spawn(task_body);\n \n             chan\n         });\n@@ -99,7 +87,7 @@ fn test_task_pool() {\n         let g: proc(uint) -> uint = proc(i) i;\n         g\n     };\n-    let mut pool = TaskPool::new(4, Some(SingleThreaded), f);\n+    let mut pool = TaskPool::new(4, f);\n     8.times(|| {\n         pool.execute(proc(i) println!(\"Hello from thread {}!\", *i));\n     })"}, {"sha": "6140da08b68ac1c8c776bc52dfeb7105f34b0ab7", "filename": "src/libgreen/basic.rs", "status": "renamed", "additions": 9, "deletions": 14, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fbasic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fbasic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fbasic.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -11,15 +11,15 @@\n //! This is a basic event loop implementation not meant for any \"real purposes\"\n //! other than testing the scheduler and proving that it's possible to have a\n //! pluggable event loop.\n+//!\n+//! This implementation is also used as the fallback implementation of an event\n+//! loop if no other one is provided (and M:N scheduling is desired).\n \n-use prelude::*;\n-\n-use cast;\n-use rt::rtio::{EventLoop, IoFactory, RemoteCallback, PausableIdleCallback,\n-               Callback};\n-use unstable::sync::Exclusive;\n-use io::native;\n-use util;\n+use std::cast;\n+use std::rt::rtio::{EventLoop, IoFactory, RemoteCallback, PausibleIdleCallback,\n+                    Callback};\n+use std::unstable::sync::Exclusive;\n+use std::util;\n \n /// This is the only exported function from this module.\n pub fn event_loop() -> ~EventLoop {\n@@ -32,7 +32,6 @@ struct BasicLoop {\n     remotes: ~[(uint, ~Callback)],\n     next_remote: uint,\n     messages: Exclusive<~[Message]>,\n-    io: ~IoFactory,\n }\n \n enum Message { RunRemote(uint), RemoveRemote(uint) }\n@@ -45,7 +44,6 @@ impl BasicLoop {\n             next_remote: 0,\n             remotes: ~[],\n             messages: Exclusive::new(~[]),\n-            io: ~native::IoFactory as ~IoFactory,\n         }\n     }\n \n@@ -159,10 +157,7 @@ impl EventLoop for BasicLoop {\n         ~BasicRemote::new(self.messages.clone(), id) as ~RemoteCallback\n     }\n \n-    fn io<'a>(&'a mut self) -> Option<&'a mut IoFactory> {\n-        let factory: &mut IoFactory = self.io;\n-        Some(factory)\n-    }\n+    fn io<'a>(&'a mut self) -> Option<&'a mut IoFactory> { None }\n }\n \n struct BasicRemote {", "previous_filename": "src/libstd/rt/basic.rs"}, {"sha": "24e35627ddd695a7fe6b7790580fa2fb1f68e790", "filename": "src/libgreen/context.rs", "status": "renamed", "additions": 25, "deletions": 204, "changes": 229, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fcontext.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -8,14 +8,13 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use option::*;\n-use super::stack::StackSegment;\n-use libc::c_void;\n-use uint;\n-use cast::{transmute, transmute_mut_unsafe,\n-           transmute_region, transmute_mut_region};\n+use std::libc::c_void;\n+use std::uint;\n+use std::cast::{transmute, transmute_mut_unsafe,\n+                transmute_region, transmute_mut_region};\n+use std::unstable::stack;\n \n-pub static RED_ZONE: uint = 20 * 1024;\n+use stack::StackSegment;\n \n // FIXME #7761: Registers is boxed so that it is 16-byte aligned, for storing\n // SSE regs.  It would be marginally better not to do this. In C++ we\n@@ -25,7 +24,7 @@ pub static RED_ZONE: uint = 20 * 1024;\n // then misalign the regs again.\n pub struct Context {\n     /// The context entry point, saved here for later destruction\n-    priv start: Option<~proc()>,\n+    priv start: ~Option<proc()>,\n     /// Hold the registers while the task or scheduler is suspended\n     priv regs: ~Registers,\n     /// Lower bound and upper bound for the stack\n@@ -35,40 +34,37 @@ pub struct Context {\n impl Context {\n     pub fn empty() -> Context {\n         Context {\n-            start: None,\n+            start: ~None,\n             regs: new_regs(),\n             stack_bounds: None,\n         }\n     }\n \n     /// Create a new context that will resume execution by running proc()\n     pub fn new(start: proc(), stack: &mut StackSegment) -> Context {\n-        // FIXME #7767: Putting main into a ~ so it's a thin pointer and can\n-        // be passed to the spawn function.  Another unfortunate\n-        // allocation\n-        let start = ~start;\n-\n         // The C-ABI function that is the task entry point\n-        extern fn task_start_wrapper(f: &proc()) {\n-            // XXX(pcwalton): This may be sketchy.\n-            unsafe {\n-                let f: &|| = transmute(f);\n-                (*f)()\n-            }\n+        extern fn task_start_wrapper(f: &mut Option<proc()>) {\n+            f.take_unwrap()()\n         }\n \n-        let fp: *c_void = task_start_wrapper as *c_void;\n-        let argp: *c_void = unsafe { transmute::<&proc(), *c_void>(&*start) };\n         let sp: *uint = stack.end();\n         let sp: *mut uint = unsafe { transmute_mut_unsafe(sp) };\n         // Save and then immediately load the current context,\n         // which we will then modify to call the given function when restored\n         let mut regs = new_regs();\n         unsafe {\n-            rust_swap_registers(transmute_mut_region(&mut *regs), transmute_region(&*regs));\n+            rust_swap_registers(transmute_mut_region(&mut *regs),\n+                                transmute_region(&*regs));\n         };\n \n-        initialize_call_frame(&mut *regs, fp, argp, sp);\n+        // FIXME #7767: Putting main into a ~ so it's a thin pointer and can\n+        // be passed to the spawn function.  Another unfortunate\n+        // allocation\n+        let box = ~Some(start);\n+        initialize_call_frame(&mut *regs,\n+                              task_start_wrapper as *c_void,\n+                              unsafe { transmute(&*box) },\n+                              sp);\n \n         // Scheduler tasks don't have a stack in the \"we allocated it\" sense,\n         // but rather they run on pthreads stacks. We have complete control over\n@@ -82,7 +78,7 @@ impl Context {\n             Some((stack_base as uint, sp as uint))\n         };\n         return Context {\n-            start: Some(start),\n+            start: box,\n             regs: regs,\n             stack_bounds: bounds,\n         }\n@@ -113,17 +109,18 @@ impl Context {\n             // invalid for the current task. Lucky for us `rust_swap_registers`\n             // is a C function so we don't have to worry about that!\n             match in_context.stack_bounds {\n-                Some((lo, hi)) => record_stack_bounds(lo, hi),\n+                Some((lo, hi)) => stack::record_stack_bounds(lo, hi),\n                 // If we're going back to one of the original contexts or\n                 // something that's possibly not a \"normal task\", then reset\n                 // the stack limit to 0 to make morestack never fail\n-                None => record_stack_bounds(0, uint::max_value),\n+                None => stack::record_stack_bounds(0, uint::max_value),\n             }\n             rust_swap_registers(out_regs, in_regs)\n         }\n     }\n }\n \n+#[link(name = \"rustrt\", kind = \"static\")]\n extern {\n     fn rust_swap_registers(out_regs: *mut Registers, in_regs: *Registers);\n }\n@@ -282,182 +279,6 @@ fn align_down(sp: *mut uint) -> *mut uint {\n // ptr::mut_offset is positive ints only\n #[inline]\n pub fn mut_offset<T>(ptr: *mut T, count: int) -> *mut T {\n-    use mem::size_of;\n+    use std::mem::size_of;\n     (ptr as int + count * (size_of::<T>() as int)) as *mut T\n }\n-\n-#[inline(always)]\n-pub unsafe fn record_stack_bounds(stack_lo: uint, stack_hi: uint) {\n-    // When the old runtime had segmented stacks, it used a calculation that was\n-    // \"limit + RED_ZONE + FUDGE\". The red zone was for things like dynamic\n-    // symbol resolution, llvm function calls, etc. In theory this red zone\n-    // value is 0, but it matters far less when we have gigantic stacks because\n-    // we don't need to be so exact about our stack budget. The \"fudge factor\"\n-    // was because LLVM doesn't emit a stack check for functions < 256 bytes in\n-    // size. Again though, we have giant stacks, so we round all these\n-    // calculations up to the nice round number of 20k.\n-    record_sp_limit(stack_lo + RED_ZONE);\n-\n-    return target_record_stack_bounds(stack_lo, stack_hi);\n-\n-    #[cfg(not(windows))] #[cfg(not(target_arch = \"x86_64\"))] #[inline(always)]\n-    unsafe fn target_record_stack_bounds(_stack_lo: uint, _stack_hi: uint) {}\n-    #[cfg(windows, target_arch = \"x86_64\")] #[inline(always)]\n-    unsafe fn target_record_stack_bounds(stack_lo: uint, stack_hi: uint) {\n-        // Windows compiles C functions which may check the stack bounds. This\n-        // means that if we want to perform valid FFI on windows, then we need\n-        // to ensure that the stack bounds are what they truly are for this\n-        // task. More info can be found at:\n-        //   https://github.com/mozilla/rust/issues/3445#issuecomment-26114839\n-        //\n-        // stack range is at TIB: %gs:0x08 (top) and %gs:0x10 (bottom)\n-        asm!(\"mov $0, %gs:0x08\" :: \"r\"(stack_hi) :: \"volatile\");\n-        asm!(\"mov $0, %gs:0x10\" :: \"r\"(stack_lo) :: \"volatile\");\n-    }\n-}\n-\n-/// Records the current limit of the stack as specified by `end`.\n-///\n-/// This is stored in an OS-dependent location, likely inside of the thread\n-/// local storage. The location that the limit is stored is a pre-ordained\n-/// location because it's where LLVM has emitted code to check.\n-///\n-/// Note that this cannot be called under normal circumstances. This function is\n-/// changing the stack limit, so upon returning any further function calls will\n-/// possibly be triggering the morestack logic if you're not careful.\n-///\n-/// Also note that this and all of the inside functions are all flagged as\n-/// \"inline(always)\" because they're messing around with the stack limits.  This\n-/// would be unfortunate for the functions themselves to trigger a morestack\n-/// invocation (if they were an actual function call).\n-#[inline(always)]\n-pub unsafe fn record_sp_limit(limit: uint) {\n-    return target_record_sp_limit(limit);\n-\n-    // x86-64\n-    #[cfg(target_arch = \"x86_64\", target_os = \"macos\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        asm!(\"movq $$0x60+90*8, %rsi\n-              movq $0, %gs:(%rsi)\" :: \"r\"(limit) : \"rsi\" : \"volatile\")\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"linux\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        asm!(\"movq $0, %fs:112\" :: \"r\"(limit) :: \"volatile\")\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"win32\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        // see: http://en.wikipedia.org/wiki/Win32_Thread_Information_Block\n-        // store this inside of the \"arbitrary data slot\", but double the size\n-        // because this is 64 bit instead of 32 bit\n-        asm!(\"movq $0, %gs:0x28\" :: \"r\"(limit) :: \"volatile\")\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"freebsd\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        asm!(\"movq $0, %fs:24\" :: \"r\"(limit) :: \"volatile\")\n-    }\n-\n-    // x86\n-    #[cfg(target_arch = \"x86\", target_os = \"macos\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        asm!(\"movl $$0x48+90*4, %eax\n-              movl $0, %gs:(%eax)\" :: \"r\"(limit) : \"eax\" : \"volatile\")\n-    }\n-    #[cfg(target_arch = \"x86\", target_os = \"linux\")]\n-    #[cfg(target_arch = \"x86\", target_os = \"freebsd\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        asm!(\"movl $0, %gs:48\" :: \"r\"(limit) :: \"volatile\")\n-    }\n-    #[cfg(target_arch = \"x86\", target_os = \"win32\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        // see: http://en.wikipedia.org/wiki/Win32_Thread_Information_Block\n-        // store this inside of the \"arbitrary data slot\"\n-        asm!(\"movl $0, %fs:0x14\" :: \"r\"(limit) :: \"volatile\")\n-    }\n-\n-    // mips, arm - Some brave soul can port these to inline asm, but it's over\n-    //             my head personally\n-    #[cfg(target_arch = \"mips\")]\n-    #[cfg(target_arch = \"arm\")] #[inline(always)]\n-    unsafe fn target_record_sp_limit(limit: uint) {\n-        return record_sp_limit(limit as *c_void);\n-        extern {\n-            fn record_sp_limit(limit: *c_void);\n-        }\n-    }\n-}\n-\n-/// The counterpart of the function above, this function will fetch the current\n-/// stack limit stored in TLS.\n-///\n-/// Note that all of these functions are meant to be exact counterparts of their\n-/// brethren above, except that the operands are reversed.\n-///\n-/// As with the setter, this function does not have a __morestack header and can\n-/// therefore be called in a \"we're out of stack\" situation.\n-#[inline(always)]\n-// currently only called by `rust_stack_exhausted`, which doesn't\n-// exist in a test build.\n-#[cfg(not(test))]\n-pub unsafe fn get_sp_limit() -> uint {\n-    return target_get_sp_limit();\n-\n-    // x86-64\n-    #[cfg(target_arch = \"x86_64\", target_os = \"macos\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movq $$0x60+90*8, %rsi\n-              movq %gs:(%rsi), $0\" : \"=r\"(limit) :: \"rsi\" : \"volatile\");\n-        return limit;\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"linux\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movq %fs:112, $0\" : \"=r\"(limit) ::: \"volatile\");\n-        return limit;\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"win32\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movq %gs:0x28, $0\" : \"=r\"(limit) ::: \"volatile\");\n-        return limit;\n-    }\n-    #[cfg(target_arch = \"x86_64\", target_os = \"freebsd\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movq %fs:24, $0\" : \"=r\"(limit) ::: \"volatile\");\n-        return limit;\n-    }\n-\n-    // x86\n-    #[cfg(target_arch = \"x86\", target_os = \"macos\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movl $$0x48+90*4, %eax\n-              movl %gs:(%eax), $0\" : \"=r\"(limit) :: \"eax\" : \"volatile\");\n-        return limit;\n-    }\n-    #[cfg(target_arch = \"x86\", target_os = \"linux\")]\n-    #[cfg(target_arch = \"x86\", target_os = \"freebsd\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movl %gs:48, $0\" : \"=r\"(limit) ::: \"volatile\");\n-        return limit;\n-    }\n-    #[cfg(target_arch = \"x86\", target_os = \"win32\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        let limit;\n-        asm!(\"movl %fs:0x14, $0\" : \"=r\"(limit) ::: \"volatile\");\n-        return limit;\n-    }\n-\n-    // mips, arm - Some brave soul can port these to inline asm, but it's over\n-    //             my head personally\n-    #[cfg(target_arch = \"mips\")]\n-    #[cfg(target_arch = \"arm\")] #[inline(always)]\n-    unsafe fn target_get_sp_limit() -> uint {\n-        return get_sp_limit() as uint;\n-        extern {\n-            fn get_sp_limit() -> *c_void;\n-        }\n-    }\n-}", "previous_filename": "src/libstd/rt/context.rs"}, {"sha": "7bc5d0accfe3b2aae28920ce046a21266d5ca88f", "filename": "src/libgreen/coroutine.rs", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fcoroutine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fcoroutine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fcoroutine.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -0,0 +1,62 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// Coroutines represent nothing more than a context and a stack\n+// segment.\n+\n+use std::rt::env;\n+\n+use context::Context;\n+use stack::{StackPool, StackSegment};\n+\n+/// A coroutine is nothing more than a (register context, stack) pair.\n+pub struct Coroutine {\n+    /// The segment of stack on which the task is currently running or\n+    /// if the task is blocked, on which the task will resume\n+    /// execution.\n+    ///\n+    /// Servo needs this to be public in order to tell SpiderMonkey\n+    /// about the stack bounds.\n+    current_stack_segment: StackSegment,\n+\n+    /// Always valid if the task is alive and not running.\n+    saved_context: Context\n+}\n+\n+impl Coroutine {\n+    pub fn new(stack_pool: &mut StackPool,\n+               stack_size: Option<uint>,\n+               start: proc())\n+               -> Coroutine {\n+        let stack_size = match stack_size {\n+            Some(size) => size,\n+            None => env::min_stack()\n+        };\n+        let mut stack = stack_pool.take_segment(stack_size);\n+        let initial_context = Context::new(start, &mut stack);\n+        Coroutine {\n+            current_stack_segment: stack,\n+            saved_context: initial_context\n+        }\n+    }\n+\n+    pub fn empty() -> Coroutine {\n+        Coroutine {\n+            current_stack_segment: StackSegment::new(0),\n+            saved_context: Context::empty()\n+        }\n+    }\n+\n+    /// Destroy coroutine and try to reuse std::stack segment.\n+    pub fn recycle(self, stack_pool: &mut StackPool) {\n+        let Coroutine { current_stack_segment, .. } = self;\n+        stack_pool.give_segment(current_stack_segment);\n+    }\n+}"}, {"sha": "193b64ff7e5cddf4484956524b6a05837c85b91a", "filename": "src/libgreen/lib.rs", "status": "added", "additions": 351, "deletions": 0, "changes": 351, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -0,0 +1,351 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! The \"green scheduling\" library\n+//!\n+//! This library provides M:N threading for rust programs. Internally this has\n+//! the implementation of a green scheduler along with context switching and a\n+//! stack-allocation strategy.\n+//!\n+//! This can be optionally linked in to rust programs in order to provide M:N\n+//! functionality inside of 1:1 programs.\n+\n+#[link(name = \"green\",\n+       package_id = \"green\",\n+       vers = \"0.9-pre\",\n+       uuid = \"20c38f8c-bfea-83ed-a068-9dc05277be26\",\n+       url = \"https://github.com/mozilla/rust/tree/master/src/libgreen\")];\n+\n+#[license = \"MIT/ASL2\"];\n+#[crate_type = \"rlib\"];\n+#[crate_type = \"dylib\"];\n+\n+// NB this does *not* include globs, please keep it that way.\n+#[feature(macro_rules)];\n+\n+use std::cast;\n+use std::os;\n+use std::rt::thread::Thread;\n+use std::rt;\n+use std::rt::crate_map;\n+use std::rt::task::Task;\n+use std::rt::rtio;\n+use std::sync::deque;\n+use std::sync::atomics::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n+use std::task::TaskResult;\n+use std::vec;\n+use std::util;\n+\n+use sched::{Shutdown, Scheduler, SchedHandle};\n+use sleeper_list::SleeperList;\n+use task::{GreenTask, HomeSched};\n+\n+mod macros;\n+\n+pub mod basic;\n+pub mod context;\n+pub mod coroutine;\n+pub mod sched;\n+pub mod sleeper_list;\n+pub mod stack;\n+pub mod task;\n+\n+#[cfg(stage0)]\n+#[lang = \"start\"]\n+pub fn lang_start(main: *u8, argc: int, argv: **u8) -> int {\n+    do start(argc, argv) {\n+        let main: extern \"Rust\" fn() = unsafe { cast::transmute(main) };\n+        main();\n+    }\n+}\n+\n+/// Set up a default runtime configuration, given compiler-supplied arguments.\n+///\n+/// This function will block the current thread of execution until the entire\n+/// pool of M:N schedulers have exited.\n+///\n+/// # Arguments\n+///\n+/// * `argc` & `argv` - The argument vector. On Unix this information is used\n+///   by os::args.\n+/// * `main` - The initial procedure to run inside of the M:N scheduling pool.\n+///            Once this procedure exits, the scheduling pool will begin to shut\n+///            down. The entire pool (and this function) will only return once\n+///            all child tasks have finished executing.\n+///\n+/// # Return value\n+///\n+/// The return value is used as the process return code. 0 on success, 101 on\n+/// error.\n+pub fn start(argc: int, argv: **u8, main: proc()) -> int {\n+    rt::init(argc, argv);\n+    let exit_code = run(main);\n+    // unsafe is ok b/c we're sure that the runtime is gone\n+    unsafe { rt::cleanup() }\n+    exit_code\n+}\n+\n+/// Execute the main function in a pool of M:N schedulers.\n+///\n+/// Configures the runtime according to the environment, by default\n+/// using a task scheduler with the same number of threads as cores.\n+/// Returns a process exit code.\n+///\n+/// This function will not return until all schedulers in the associated pool\n+/// have returned.\n+pub fn run(main: proc()) -> int {\n+    let config = Config {\n+        shutdown_after_main_exits: true,\n+        ..Config::new()\n+    };\n+    Pool::spawn(config, main).wait();\n+    os::get_exit_status()\n+}\n+\n+/// Configuration of how an M:N pool of schedulers is spawned.\n+pub struct Config {\n+    /// If this flag is set, then when schedulers are spawned via the `start`\n+    /// and `run` functions the thread invoking `start` and `run` will have a\n+    /// scheduler spawned on it. This scheduler will be \"special\" in that the\n+    /// main task will be pinned to the scheduler and it will not participate in\n+    /// work stealing.\n+    ///\n+    /// If the `spawn` function is used to create a pool of schedulers, then\n+    /// this option has no effect.\n+    use_main_thread: bool,\n+\n+    /// The number of schedulers (OS threads) to spawn into this M:N pool.\n+    threads: uint,\n+\n+    /// When the main function exits, this flag will dictate whether a shutdown\n+    /// is requested of all schedulers. If this flag is `true`, this means that\n+    /// schedulers will shut down as soon as possible after the main task exits\n+    /// (but some may stay alive longer for things like I/O or other tasks).\n+    ///\n+    /// If this flag is `false`, then no action is taken when the `main` task\n+    /// exits. The scheduler pool is then shut down via the `wait()` function.\n+    shutdown_after_main_exits: bool,\n+}\n+\n+impl Config {\n+    /// Returns the default configuration, as determined the the environment\n+    /// variables of this process.\n+    pub fn new() -> Config {\n+        Config {\n+            use_main_thread: false,\n+            threads: rt::default_sched_threads(),\n+            shutdown_after_main_exits: false,\n+        }\n+    }\n+}\n+\n+/// A structure representing a handle to a pool of schedulers. This handle is\n+/// used to keep the pool alive and also reap the status from the pool.\n+pub struct Pool {\n+    priv threads: ~[Thread<()>],\n+    priv handles: Option<~[SchedHandle]>,\n+}\n+\n+impl Pool {\n+    /// Execute the main function in a pool of M:N schedulers.\n+    ///\n+    /// This will configure the pool according to the `config` parameter, and\n+    /// initially run `main` inside the pool of schedulers.\n+    pub fn spawn(config: Config, main: proc()) -> Pool {\n+        static mut POOL_ID: AtomicUint = INIT_ATOMIC_UINT;\n+\n+        let Config {\n+            threads: nscheds,\n+            use_main_thread: use_main_sched,\n+            shutdown_after_main_exits\n+        } = config;\n+\n+        let mut main = Some(main);\n+        let pool_id = unsafe { POOL_ID.fetch_add(1, SeqCst) };\n+\n+        // The shared list of sleeping schedulers.\n+        let sleepers = SleeperList::new();\n+\n+        // Create a work queue for each scheduler, ntimes. Create an extra\n+        // for the main thread if that flag is set. We won't steal from it.\n+        let mut pool = deque::BufferPool::new();\n+        let arr = vec::from_fn(nscheds, |_| pool.deque());\n+        let (workers, stealers) = vec::unzip(arr.move_iter());\n+\n+        // The schedulers.\n+        let mut scheds = ~[];\n+        // Handles to the schedulers. When the main task ends these will be\n+        // sent the Shutdown message to terminate the schedulers.\n+        let mut handles = ~[];\n+\n+        for worker in workers.move_iter() {\n+            rtdebug!(\"inserting a regular scheduler\");\n+\n+            // Every scheduler is driven by an I/O event loop.\n+            let loop_ = new_event_loop();\n+            let mut sched = ~Scheduler::new(pool_id,\n+                                            loop_,\n+                                            worker,\n+                                            stealers.clone(),\n+                                            sleepers.clone());\n+            let handle = sched.make_handle();\n+\n+            scheds.push(sched);\n+            handles.push(handle);\n+        }\n+\n+        // If we need a main-thread task then create a main thread scheduler\n+        // that will reject any task that isn't pinned to it\n+        let main_sched = if use_main_sched {\n+\n+            // Create a friend handle.\n+            let mut friend_sched = scheds.pop();\n+            let friend_handle = friend_sched.make_handle();\n+            scheds.push(friend_sched);\n+\n+            // This scheduler needs a queue that isn't part of the stealee\n+            // set.\n+            let (worker, _) = pool.deque();\n+\n+            let main_loop = new_event_loop();\n+            let mut main_sched = ~Scheduler::new_special(pool_id,\n+                                                         main_loop,\n+                                                         worker,\n+                                                         stealers.clone(),\n+                                                         sleepers.clone(),\n+                                                         false,\n+                                                         Some(friend_handle));\n+            let mut main_handle = main_sched.make_handle();\n+            // Allow the scheduler to exit when the main task exits.\n+            // Note: sending the shutdown message also prevents the scheduler\n+            // from pushing itself to the sleeper list, which is used for\n+            // waking up schedulers for work stealing; since this is a\n+            // non-work-stealing scheduler it should not be adding itself\n+            // to the list.\n+            main_handle.send(Shutdown);\n+            Some(main_sched)\n+        } else {\n+            None\n+        };\n+\n+        // The pool of schedulers that will be returned from this function\n+        let mut pool = Pool { threads: ~[], handles: None };\n+\n+        // When the main task exits, after all the tasks in the main\n+        // task tree, shut down the schedulers and set the exit code.\n+        let mut on_exit = if shutdown_after_main_exits {\n+            let handles = handles;\n+            Some(proc(exit_success: TaskResult) {\n+                let mut handles = handles;\n+                for handle in handles.mut_iter() {\n+                    handle.send(Shutdown);\n+                }\n+                if exit_success.is_err() {\n+                    os::set_exit_status(rt::DEFAULT_ERROR_CODE);\n+                }\n+            })\n+        } else {\n+            pool.handles = Some(handles);\n+            None\n+        };\n+\n+        if !use_main_sched {\n+\n+            // In the case where we do not use a main_thread scheduler we\n+            // run the main task in one of our threads.\n+\n+            let mut main = GreenTask::new(&mut scheds[0].stack_pool, None,\n+                                          main.take_unwrap());\n+            let mut main_task = ~Task::new();\n+            main_task.name = Some(SendStrStatic(\"<main>\"));\n+            main_task.death.on_exit = on_exit.take();\n+            main.put_task(main_task);\n+\n+            let sched = scheds.pop();\n+            let main = main;\n+            let thread = do Thread::start {\n+                sched.bootstrap(main);\n+            };\n+            pool.threads.push(thread);\n+        }\n+\n+        // Run each remaining scheduler in a thread.\n+        for sched in scheds.move_rev_iter() {\n+            rtdebug!(\"creating regular schedulers\");\n+            let thread = do Thread::start {\n+                let mut sched = sched;\n+                let mut task = do GreenTask::new(&mut sched.stack_pool, None) {\n+                    rtdebug!(\"boostraping a non-primary scheduler\");\n+                };\n+                task.put_task(~Task::new());\n+                sched.bootstrap(task);\n+            };\n+            pool.threads.push(thread);\n+        }\n+\n+        // If we do have a main thread scheduler, run it now.\n+\n+        if use_main_sched {\n+            rtdebug!(\"about to create the main scheduler task\");\n+\n+            let mut main_sched = main_sched.unwrap();\n+\n+            let home = HomeSched(main_sched.make_handle());\n+            let mut main = GreenTask::new_homed(&mut main_sched.stack_pool, None,\n+                                                home, main.take_unwrap());\n+            let mut main_task = ~Task::new();\n+            main_task.name = Some(SendStrStatic(\"<main>\"));\n+            main_task.death.on_exit = on_exit.take();\n+            main.put_task(main_task);\n+            rtdebug!(\"bootstrapping main_task\");\n+\n+            main_sched.bootstrap(main);\n+        }\n+\n+        return pool;\n+    }\n+\n+    /// Waits for the pool of schedulers to exit. If the pool was spawned to\n+    /// shutdown after the main task exits, this will simply wait for all the\n+    /// scheudlers to exit. If the pool was not spawned like that, this function\n+    /// will trigger shutdown of all the active schedulers. The schedulers will\n+    /// exit once all tasks in this pool of schedulers has exited.\n+    pub fn wait(&mut self) {\n+        match self.handles.take() {\n+            Some(mut handles) => {\n+                for handle in handles.mut_iter() {\n+                    handle.send(Shutdown);\n+                }\n+            }\n+            None => {}\n+        }\n+\n+        for thread in util::replace(&mut self.threads, ~[]).move_iter() {\n+            thread.join();\n+        }\n+    }\n+}\n+\n+fn new_event_loop() -> ~rtio::EventLoop {\n+    match crate_map::get_crate_map() {\n+        None => {}\n+        Some(map) => {\n+            match map.event_loop_factory {\n+                None => {}\n+                Some(factory) => return factory()\n+            }\n+        }\n+    }\n+\n+    // If the crate map didn't specify a factory to create an event loop, then\n+    // instead just use a basic event loop missing all I/O services to at least\n+    // get the scheduler running.\n+    return basic::event_loop();\n+}"}, {"sha": "ad0854e2b1ec623bb8fccf2619abdddc07aec987", "filename": "src/libgreen/macros.rs", "status": "added", "additions": 130, "deletions": 0, "changes": 130, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fmacros.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -0,0 +1,130 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+// XXX: this file probably shouldn't exist\n+\n+#[macro_escape];\n+\n+use std::fmt;\n+use std::libc;\n+\n+// Indicates whether we should perform expensive sanity checks, including rtassert!\n+// XXX: Once the runtime matures remove the `true` below to turn off rtassert, etc.\n+pub static ENFORCE_SANITY: bool = true || !cfg!(rtopt) || cfg!(rtdebug) || cfg!(rtassert);\n+\n+macro_rules! rterrln (\n+    ($($arg:tt)*) => ( {\n+        format_args!(::macros::dumb_println, $($arg)*)\n+    } )\n+)\n+\n+// Some basic logging. Enabled by passing `--cfg rtdebug` to the libstd build.\n+macro_rules! rtdebug (\n+    ($($arg:tt)*) => ( {\n+        if cfg!(rtdebug) {\n+            rterrln!($($arg)*)\n+        }\n+    })\n+)\n+\n+macro_rules! rtassert (\n+    ( $arg:expr ) => ( {\n+        if ::macros::ENFORCE_SANITY {\n+            if !$arg {\n+                rtabort!(\" assertion failed: {}\", stringify!($arg));\n+            }\n+        }\n+    } )\n+)\n+\n+\n+macro_rules! rtabort (\n+    ($($arg:tt)*) => ( {\n+        ::macros::abort(format!($($arg)*));\n+    } )\n+)\n+\n+pub fn dumb_println(args: &fmt::Arguments) {\n+    use std::io;\n+    use std::libc;\n+    use std::vec;\n+\n+    struct Stderr;\n+    impl io::Writer for Stderr {\n+        fn write(&mut self, data: &[u8]) {\n+            unsafe {\n+                libc::write(libc::STDERR_FILENO,\n+                            vec::raw::to_ptr(data) as *libc::c_void,\n+                            data.len() as libc::size_t);\n+            }\n+        }\n+    }\n+    let mut w = Stderr;\n+    fmt::writeln(&mut w as &mut io::Writer, args);\n+}\n+\n+pub fn abort(msg: &str) -> ! {\n+    let msg = if !msg.is_empty() { msg } else { \"aborted\" };\n+    let hash = msg.chars().fold(0, |accum, val| accum + (val as uint) );\n+    let quote = match hash % 10 {\n+        0 => \"\n+It was from the artists and poets that the pertinent answers came, and I\n+know that panic would have broken loose had they been able to compare notes.\n+As it was, lacking their original letters, I half suspected the compiler of\n+having asked leading questions, or of having edited the correspondence in\n+corroboration of what he had latently resolved to see.\",\n+        1 => \"\n+There are not many persons who know what wonders are opened to them in the\n+stories and visions of their youth; for when as children we listen and dream,\n+we think but half-formed thoughts, and when as men we try to remember, we are\n+dulled and prosaic with the poison of life. But some of us awake in the night\n+with strange phantasms of enchanted hills and gardens, of fountains that sing\n+in the sun, of golden cliffs overhanging murmuring seas, of plains that stretch\n+down to sleeping cities of bronze and stone, and of shadowy companies of heroes\n+that ride caparisoned white horses along the edges of thick forests; and then\n+we know that we have looked back through the ivory gates into that world of\n+wonder which was ours before we were wise and unhappy.\",\n+        2 => \"\n+Instead of the poems I had hoped for, there came only a shuddering blackness\n+and ineffable loneliness; and I saw at last a fearful truth which no one had\n+ever dared to breathe before \u2014 the unwhisperable secret of secrets \u2014 The fact\n+that this city of stone and stridor is not a sentient perpetuation of Old New\n+York as London is of Old London and Paris of Old Paris, but that it is in fact\n+quite dead, its sprawling body imperfectly embalmed and infested with queer\n+animate things which have nothing to do with it as it was in life.\",\n+        3 => \"\n+The ocean ate the last of the land and poured into the smoking gulf, thereby\n+giving up all it had ever conquered. From the new-flooded lands it flowed\n+again, uncovering death and decay; and from its ancient and immemorial bed it\n+trickled loathsomely, uncovering nighted secrets of the years when Time was\n+young and the gods unborn. Above the waves rose weedy remembered spires. The\n+moon laid pale lilies of light on dead London, and Paris stood up from its damp\n+grave to be sanctified with star-dust. Then rose spires and monoliths that were\n+weedy but not remembered; terrible spires and monoliths of lands that men never\n+knew were lands...\",\n+        4 => \"\n+There was a night when winds from unknown spaces whirled us irresistibly into\n+limitless vacuum beyond all thought and entity. Perceptions of the most\n+maddeningly untransmissible sort thronged upon us; perceptions of infinity\n+which at the time convulsed us with joy, yet which are now partly lost to my\n+memory and partly incapable of presentation to others.\",\n+        _ => \"You've met with a terrible fate, haven't you?\"\n+    };\n+    rterrln!(\"{}\", \"\");\n+    rterrln!(\"{}\", quote);\n+    rterrln!(\"{}\", \"\");\n+    rterrln!(\"fatal runtime error: {}\", msg);\n+\n+    abort();\n+\n+    fn abort() -> ! {\n+        unsafe { libc::abort() }\n+    }\n+}"}, {"sha": "b0a49f2450ad9a3d852e719ee2ebd9ed304d2ad5", "filename": "src/libgreen/sched.rs", "status": "renamed", "additions": 253, "deletions": 244, "changes": 497, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -8,27 +8,22 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use option::{Option, Some, None};\n-use cast::{transmute, transmute_mut_region, transmute_mut_unsafe};\n-use clone::Clone;\n-use unstable::raw;\n-use super::sleeper_list::SleeperList;\n-use super::stack::{StackPool};\n-use super::rtio::EventLoop;\n-use super::context::Context;\n-use super::task::{Task, AnySched, Sched};\n-use rt::kill::BlockedTask;\n-use rt::deque;\n-use rt::local_ptr;\n-use rt::local::Local;\n-use rt::rtio::{RemoteCallback, PausableIdleCallback, Callback};\n-use borrow::{to_uint};\n-use rand::{XorShiftRng, Rng, Rand};\n-use iter::range;\n-use unstable::mutex::Mutex;\n-use vec::{OwnedVector};\n-\n-use mpsc = super::mpsc_queue;\n+use std::cast;\n+use std::rand::{XorShiftRng, Rng, Rand};\n+use std::rt::local::Local;\n+use std::rt::rtio::{RemoteCallback, PausibleIdleCallback, Callback, EventLoop};\n+use std::rt::task::BlockedTask;\n+use std::rt::task::Task;\n+use std::sync::deque;\n+use std::unstable::mutex::Mutex;\n+use std::unstable::raw;\n+use mpsc = std::sync::mpsc_queue;\n+\n+use context::Context;\n+use coroutine::Coroutine;\n+use sleeper_list::SleeperList;\n+use stack::StackPool;\n+use task::{TypeSched, GreenTask, HomeSched, AnySched};\n \n /// A scheduler is responsible for coordinating the execution of Tasks\n /// on a single thread. The scheduler runs inside a slightly modified\n@@ -39,11 +34,15 @@ use mpsc = super::mpsc_queue;\n /// XXX: This creates too many callbacks to run_sched_once, resulting\n /// in too much allocation and too many events.\n pub struct Scheduler {\n+    /// ID number of the pool that this scheduler is a member of. When\n+    /// reawakening green tasks, this is used to ensure that tasks aren't\n+    /// reawoken on the wrong pool of schedulers.\n+    pool_id: uint,\n     /// There are N work queues, one per scheduler.\n-    work_queue: deque::Worker<~Task>,\n+    work_queue: deque::Worker<~GreenTask>,\n     /// Work queues for the other schedulers. These are created by\n     /// cloning the core work queues.\n-    work_queues: ~[deque::Stealer<~Task>],\n+    work_queues: ~[deque::Stealer<~GreenTask>],\n     /// The queue of incoming messages from other schedulers.\n     /// These are enqueued by SchedHandles after which a remote callback\n     /// is triggered to handle the message.\n@@ -66,15 +65,15 @@ pub struct Scheduler {\n     stack_pool: StackPool,\n     /// The scheduler runs on a special task. When it is not running\n     /// it is stored here instead of the work queue.\n-    sched_task: Option<~Task>,\n+    sched_task: Option<~GreenTask>,\n     /// An action performed after a context switch on behalf of the\n     /// code running before the context switch\n     cleanup_job: Option<CleanupJob>,\n-    /// Should this scheduler run any task, or only pinned tasks?\n-    run_anything: bool,\n     /// If the scheduler shouldn't run some tasks, a friend to send\n     /// them to.\n     friend_handle: Option<SchedHandle>,\n+    /// Should this scheduler run any task, or only pinned tasks?\n+    run_anything: bool,\n     /// A fast XorShift rng for scheduler use\n     rng: XorShiftRng,\n     /// A togglable idle callback\n@@ -117,28 +116,30 @@ impl Scheduler {\n \n     // * Initialization Functions\n \n-    pub fn new(event_loop: ~EventLoop,\n-               work_queue: deque::Worker<~Task>,\n-               work_queues: ~[deque::Stealer<~Task>],\n+    pub fn new(pool_id: uint,\n+               event_loop: ~EventLoop,\n+               work_queue: deque::Worker<~GreenTask>,\n+               work_queues: ~[deque::Stealer<~GreenTask>],\n                sleeper_list: SleeperList)\n         -> Scheduler {\n \n-        Scheduler::new_special(event_loop, work_queue,\n-                               work_queues,\n+        Scheduler::new_special(pool_id, event_loop, work_queue, work_queues,\n                                sleeper_list, true, None)\n \n     }\n \n-    pub fn new_special(event_loop: ~EventLoop,\n-                       work_queue: deque::Worker<~Task>,\n-                       work_queues: ~[deque::Stealer<~Task>],\n+    pub fn new_special(pool_id: uint,\n+                       event_loop: ~EventLoop,\n+                       work_queue: deque::Worker<~GreenTask>,\n+                       work_queues: ~[deque::Stealer<~GreenTask>],\n                        sleeper_list: SleeperList,\n                        run_anything: bool,\n                        friend: Option<SchedHandle>)\n         -> Scheduler {\n \n         let (consumer, producer) = mpsc::queue(());\n         let mut sched = Scheduler {\n+            pool_id: pool_id,\n             sleeper_list: sleeper_list,\n             message_queue: consumer,\n             message_producer: producer,\n@@ -170,83 +171,84 @@ impl Scheduler {\n \n     // Take a main task to run, and a scheduler to run it in. Create a\n     // scheduler task and bootstrap into it.\n-    pub fn bootstrap(mut ~self, task: ~Task) {\n+    pub fn bootstrap(mut ~self, task: ~GreenTask) {\n \n         // Build an Idle callback.\n         let cb = ~SchedRunner as ~Callback;\n         self.idle_callback = Some(self.event_loop.pausable_idle_callback(cb));\n \n-        // Initialize the TLS key.\n-        local_ptr::init();\n-\n         // Create a task for the scheduler with an empty context.\n-        let sched_task = ~Task::new_sched_task();\n-\n-        // Now that we have an empty task struct for the scheduler\n-        // task, put it in TLS.\n-        Local::put(sched_task);\n+        let mut sched_task = GreenTask::new_typed(Some(Coroutine::empty()),\n+                                                  TypeSched);\n+        sched_task.put_task(~Task::new());\n \n         // Before starting our first task, make sure the idle callback\n         // is active. As we do not start in the sleep state this is\n         // important.\n         self.idle_callback.get_mut_ref().resume();\n \n-        // Now, as far as all the scheduler state is concerned, we are\n-        // inside the \"scheduler\" context. So we can act like the\n-        // scheduler and resume the provided task.\n-        self.resume_task_immediately(task);\n+        // Now, as far as all the scheduler state is concerned, we are inside\n+        // the \"scheduler\" context. So we can act like the scheduler and resume\n+        // the provided task. Let it think that the currently running task is\n+        // actually the sched_task so it knows where to squirrel it away.\n+        let mut sched_task = self.resume_task_immediately(sched_task, task);\n \n         // Now we are back in the scheduler context, having\n         // successfully run the input task. Start by running the\n         // scheduler. Grab it out of TLS - performing the scheduler\n         // action will have given it away.\n-        let sched: ~Scheduler = Local::take();\n-\n+        let sched = sched_task.sched.take_unwrap();\n         rtdebug!(\"starting scheduler {}\", sched.sched_id());\n-        sched.run();\n+        let mut sched_task = sched.run(sched_task);\n \n         // Close the idle callback.\n-        let mut sched: ~Scheduler = Local::take();\n+        let mut sched = sched_task.sched.take_unwrap();\n         sched.idle_callback.take();\n         // Make one go through the loop to run the close callback.\n-        sched.run();\n+        let mut stask = sched.run(sched_task);\n \n         // Now that we are done with the scheduler, clean up the\n         // scheduler task. Do so by removing it from TLS and manually\n         // cleaning up the memory it uses. As we didn't actually call\n         // task.run() on the scheduler task we never get through all\n         // the cleanup code it runs.\n-        let mut stask: ~Task = Local::take();\n-\n         rtdebug!(\"stopping scheduler {}\", stask.sched.get_ref().sched_id());\n \n         // Should not have any messages\n         let message = stask.sched.get_mut_ref().message_queue.pop();\n         rtassert!(match message { mpsc::Empty => true, _ => false });\n \n-        stask.destroyed = true;\n+        stask.task.get_mut_ref().destroyed = true;\n     }\n \n     // This does not return a scheduler, as the scheduler is placed\n     // inside the task.\n-    pub fn run(mut ~self) {\n+    pub fn run(mut ~self, stask: ~GreenTask) -> ~GreenTask {\n \n         // This is unsafe because we need to place the scheduler, with\n         // the event_loop inside, inside our task. But we still need a\n         // mutable reference to the event_loop to give it the \"run\"\n         // command.\n         unsafe {\n             let event_loop: *mut ~EventLoop = &mut self.event_loop;\n-\n-            {\n-                // Our scheduler must be in the task before the event loop\n-                // is started.\n-                let mut stask = Local::borrow(None::<Task>);\n-                stask.get().sched = Some(self);\n-            }\n-\n+            // Our scheduler must be in the task before the event loop\n+            // is started.\n+            stask.put_with_sched(self);\n             (*event_loop).run();\n         }\n+\n+        //  This is a serious code smell, but this function could be done away\n+        //  with if necessary. The ownership of `stask` was transferred into\n+        //  local storage just before the event loop ran, so it is possible to\n+        //  transmute `stask` as a uint across the running of the event loop to\n+        //  re-acquire ownership here.\n+        //\n+        // This would involve removing the Task from TLS, removing the runtime,\n+        // forgetting the runtime, and then putting the task into `stask`. For\n+        // now, because we have `GreenTask::convert`, I chose to take this\n+        // method for cleanliness. This function is *not* a fundamental reason\n+        // why this function should exist.\n+        GreenTask::convert(Local::take())\n     }\n \n     // * Execution Functions - Core Loop Logic\n@@ -257,38 +259,37 @@ impl Scheduler {\n     // you reach the end and sleep. In the case that a scheduler\n     // action is performed the loop is evented such that this function\n     // is called again.\n-    fn run_sched_once() {\n-\n-        // When we reach the scheduler context via the event loop we\n-        // already have a scheduler stored in our local task, so we\n-        // start off by taking it. This is the only path through the\n-        // scheduler where we get the scheduler this way.\n-        let mut sched: ~Scheduler = Local::take();\n+    fn run_sched_once(mut ~self, stask: ~GreenTask) {\n+        // Make sure that we're not lying in that the `stask` argument is indeed\n+        // the scheduler task for this scheduler.\n+        assert!(self.sched_task.is_none());\n \n         // Assume that we need to continue idling unless we reach the\n         // end of this function without performing an action.\n-        sched.idle_callback.get_mut_ref().resume();\n+        self.idle_callback.get_mut_ref().resume();\n \n         // First we check for scheduler messages, these are higher\n         // priority than regular tasks.\n-        let sched = match sched.interpret_message_queue(DontTryTooHard) {\n-            Some(sched) => sched,\n-            None => return\n-        };\n+        let (sched, stask) =\n+            match self.interpret_message_queue(stask, DontTryTooHard) {\n+                Some(pair) => pair,\n+                None => return\n+            };\n \n         // This helper will use a randomized work-stealing algorithm\n         // to find work.\n-        let sched = match sched.do_work() {\n-            Some(sched) => sched,\n+        let (sched, stask) = match sched.do_work(stask) {\n+            Some(pair) => pair,\n             None => return\n         };\n \n         // Now, before sleeping we need to find out if there really\n         // were any messages. Give it your best!\n-        let mut sched = match sched.interpret_message_queue(GiveItYourBest) {\n-            Some(sched) => sched,\n-            None => return\n-        };\n+        let (mut sched, stask) =\n+            match sched.interpret_message_queue(stask, GiveItYourBest) {\n+                Some(pair) => pair,\n+                None => return\n+            };\n \n         // If we got here then there was no work to do.\n         // Generate a SchedHandle and push it to the sleeper list so\n@@ -309,14 +310,17 @@ impl Scheduler {\n \n         // Finished a cycle without using the Scheduler. Place it back\n         // in TLS.\n-        Local::put(sched);\n+        stask.put_with_sched(sched);\n     }\n \n     // This function returns None if the scheduler is \"used\", or it\n     // returns the still-available scheduler. At this point all\n     // message-handling will count as a turn of work, and as a result\n     // return None.\n-    fn interpret_message_queue(mut ~self, effort: EffortLevel) -> Option<~Scheduler> {\n+    fn interpret_message_queue(mut ~self, stask: ~GreenTask,\n+                               effort: EffortLevel)\n+        -> Option<(~Scheduler, ~GreenTask)>\n+    {\n \n         let msg = if effort == DontTryTooHard {\n             self.message_queue.casual_pop()\n@@ -345,24 +349,25 @@ impl Scheduler {\n         match msg {\n             Some(PinnedTask(task)) => {\n                 let mut task = task;\n-                task.give_home(Sched(self.make_handle()));\n-                self.resume_task_immediately(task);\n+                task.give_home(HomeSched(self.make_handle()));\n+                self.resume_task_immediately(stask, task).put();\n                 return None;\n             }\n             Some(TaskFromFriend(task)) => {\n                 rtdebug!(\"got a task from a friend. lovely!\");\n-                self.process_task(task, Scheduler::resume_task_immediately_cl);\n+                self.process_task(stask, task,\n+                                  Scheduler::resume_task_immediately_cl);\n                 return None;\n             }\n             Some(RunOnce(task)) => {\n                 // bypass the process_task logic to force running this task once\n                 // on this home scheduler. This is often used for I/O (homing).\n-                Scheduler::resume_task_immediately_cl(self, task);\n+                self.resume_task_immediately(stask, task).put();\n                 return None;\n             }\n             Some(Wake) => {\n                 self.sleepy = false;\n-                Local::put(self);\n+                stask.put_with_sched(self);\n                 return None;\n             }\n             Some(Shutdown) => {\n@@ -385,26 +390,27 @@ impl Scheduler {\n                 // event loop references we will shut down.\n                 self.no_sleep = true;\n                 self.sleepy = false;\n-                Local::put(self);\n+                stask.put_with_sched(self);\n                 return None;\n             }\n             None => {\n-                return Some(self);\n+                return Some((self, stask));\n             }\n         }\n     }\n \n-    fn do_work(mut ~self) -> Option<~Scheduler> {\n+    fn do_work(mut ~self, stask: ~GreenTask) -> Option<(~Scheduler, ~GreenTask)> {\n         rtdebug!(\"scheduler calling do work\");\n         match self.find_work() {\n             Some(task) => {\n-                rtdebug!(\"found some work! processing the task\");\n-                self.process_task(task, Scheduler::resume_task_immediately_cl);\n+                rtdebug!(\"found some work! running the task\");\n+                self.process_task(stask, task,\n+                                  Scheduler::resume_task_immediately_cl);\n                 return None;\n             }\n             None => {\n                 rtdebug!(\"no work was found, returning the scheduler struct\");\n-                return Some(self);\n+                return Some((self, stask));\n             }\n         }\n     }\n@@ -418,7 +424,7 @@ impl Scheduler {\n     // First step in the process is to find a task. This function does\n     // that by first checking the local queue, and if there is no work\n     // there, trying to steal from the remote work queues.\n-    fn find_work(&mut self) -> Option<~Task> {\n+    fn find_work(&mut self) -> Option<~GreenTask> {\n         rtdebug!(\"scheduler looking for work\");\n         if !self.steal_for_yield {\n             match self.work_queue.pop() {\n@@ -456,7 +462,7 @@ impl Scheduler {\n     // Try stealing from all queues the scheduler knows about. This\n     // naive implementation can steal from our own queue or from other\n     // special schedulers.\n-    fn try_steals(&mut self) -> Option<~Task> {\n+    fn try_steals(&mut self) -> Option<~GreenTask> {\n         let work_queues = &mut self.work_queues;\n         let len = work_queues.len();\n         let start_index = self.rng.gen_range(0, len);\n@@ -476,53 +482,48 @@ impl Scheduler {\n     // * Task Routing Functions - Make sure tasks send up in the right\n     // place.\n \n-    fn process_task(mut ~self, mut task: ~Task, schedule_fn: SchedulingFn) {\n+    fn process_task(mut ~self, cur: ~GreenTask,\n+                    mut next: ~GreenTask, schedule_fn: SchedulingFn) {\n         rtdebug!(\"processing a task\");\n \n-        let home = task.take_unwrap_home();\n-        match home {\n-            Sched(home_handle) => {\n+        match next.take_unwrap_home() {\n+            HomeSched(home_handle) => {\n                 if home_handle.sched_id != self.sched_id() {\n                     rtdebug!(\"sending task home\");\n-                    task.give_home(Sched(home_handle));\n-                    Scheduler::send_task_home(task);\n-                    Local::put(self);\n+                    next.give_home(HomeSched(home_handle));\n+                    Scheduler::send_task_home(next);\n+                    cur.put_with_sched(self);\n                 } else {\n                     rtdebug!(\"running task here\");\n-                    task.give_home(Sched(home_handle));\n-                    schedule_fn(self, task);\n+                    next.give_home(HomeSched(home_handle));\n+                    schedule_fn(self, cur, next);\n                 }\n             }\n             AnySched if self.run_anything => {\n                 rtdebug!(\"running anysched task here\");\n-                task.give_home(AnySched);\n-                schedule_fn(self, task);\n+                next.give_home(AnySched);\n+                schedule_fn(self, cur, next);\n             }\n             AnySched => {\n                 rtdebug!(\"sending task to friend\");\n-                task.give_home(AnySched);\n-                self.send_to_friend(task);\n-                Local::put(self);\n+                next.give_home(AnySched);\n+                self.send_to_friend(next);\n+                cur.put_with_sched(self);\n             }\n         }\n     }\n \n-    fn send_task_home(task: ~Task) {\n+    fn send_task_home(task: ~GreenTask) {\n         let mut task = task;\n-        let mut home = task.take_unwrap_home();\n-        match home {\n-            Sched(ref mut home_handle) => {\n-                home_handle.send(PinnedTask(task));\n-            }\n-            AnySched => {\n-                        rtabort!(\"error: cannot send anysched task home\");\n-            }\n+        match task.take_unwrap_home() {\n+            HomeSched(mut home_handle) => home_handle.send(PinnedTask(task)),\n+            AnySched => rtabort!(\"error: cannot send anysched task home\"),\n         }\n     }\n \n     /// Take a non-homed task we aren't allowed to run here and send\n     /// it to the designated friend scheduler to execute.\n-    fn send_to_friend(&mut self, task: ~Task) {\n+    fn send_to_friend(&mut self, task: ~GreenTask) {\n         rtdebug!(\"sending a task to friend\");\n         match self.friend_handle {\n             Some(ref mut handle) => {\n@@ -539,9 +540,10 @@ impl Scheduler {\n     /// Pushes the task onto the work stealing queue and tells the\n     /// event loop to run it later. Always use this instead of pushing\n     /// to the work queue directly.\n-    pub fn enqueue_task(&mut self, task: ~Task) {\n+    pub fn enqueue_task(&mut self, task: ~GreenTask) {\n \n         // We push the task onto our local queue clone.\n+        assert!(!task.is_sched());\n         self.work_queue.push(task);\n         self.idle_callback.get_mut_ref().resume();\n \n@@ -557,47 +559,31 @@ impl Scheduler {\n         };\n     }\n \n-    /// As enqueue_task, but with the possibility for the blocked task to\n-    /// already have been killed.\n-    pub fn enqueue_blocked_task(&mut self, blocked_task: BlockedTask) {\n-        blocked_task.wake().map(|task| self.enqueue_task(task));\n-    }\n-\n     // * Core Context Switching Functions\n \n     // The primary function for changing contexts. In the current\n     // design the scheduler is just a slightly modified GreenTask, so\n-    // all context swaps are from Task to Task. The only difference\n+    // all context swaps are from GreenTask to GreenTask. The only difference\n     // between the various cases is where the inputs come from, and\n     // what is done with the resulting task. That is specified by the\n     // cleanup function f, which takes the scheduler and the\n     // old task as inputs.\n \n     pub fn change_task_context(mut ~self,\n-                               next_task: ~Task,\n-                               f: |&mut Scheduler, ~Task|) {\n-        // The current task is grabbed from TLS, not taken as an input.\n-        // Doing an unsafe_take to avoid writing back a null pointer -\n-        // We're going to call `put` later to do that.\n-        let current_task: ~Task = unsafe { Local::unsafe_take() };\n-\n-        // Check that the task is not in an atomically() section (e.g.,\n-        // holding a pthread mutex, which could deadlock the scheduler).\n-        current_task.death.assert_may_sleep();\n-\n-        // These transmutes do something fishy with a closure.\n-        let f_fake_region = unsafe {\n-            transmute::<|&mut Scheduler, ~Task|,\n-                        |&mut Scheduler, ~Task|>(f)\n+                               current_task: ~GreenTask,\n+                               mut next_task: ~GreenTask,\n+                               f: |&mut Scheduler, ~GreenTask|) -> ~GreenTask {\n+        let f_opaque = ClosureConverter::from_fn(f);\n+\n+        let current_task_dupe = unsafe {\n+            *cast::transmute::<&~GreenTask, &uint>(&current_task)\n         };\n-        let f_opaque = ClosureConverter::from_fn(f_fake_region);\n \n         // The current task is placed inside an enum with the cleanup\n         // function. This enum is then placed inside the scheduler.\n         self.cleanup_job = Some(CleanupJob::new(current_task, f_opaque));\n \n         // The scheduler is then placed inside the next task.\n-        let mut next_task = next_task;\n         next_task.sched = Some(self);\n \n         // However we still need an internal mutable pointer to the\n@@ -607,12 +593,12 @@ impl Scheduler {\n         unsafe {\n \n             let sched: &mut Scheduler =\n-                transmute_mut_region(*next_task.sched.get_mut_ref());\n+                cast::transmute_mut_region(*next_task.sched.get_mut_ref());\n \n-            let current_task: &mut Task = match sched.cleanup_job {\n+            let current_task: &mut GreenTask = match sched.cleanup_job {\n                 Some(CleanupJob { task: ref task, .. }) => {\n-                    let task_ptr: *~Task = task;\n-                    transmute_mut_region(*transmute_mut_unsafe(task_ptr))\n+                    let task_ptr: *~GreenTask = task;\n+                    cast::transmute_mut_region(*cast::transmute_mut_unsafe(task_ptr))\n                 }\n                 None => {\n                     rtabort!(\"no cleanup job\");\n@@ -626,7 +612,7 @@ impl Scheduler {\n             // works because due to transmute the borrow checker\n             // believes that we have no internal pointers to\n             // next_task.\n-            Local::put(next_task);\n+            cast::forget(next_task);\n \n             // The raw context swap operation. The next action taken\n             // will be running the cleanup job from the context of the\n@@ -637,54 +623,53 @@ impl Scheduler {\n         // When the context swaps back to this task we immediately\n         // run the cleanup job, as expected by the previously called\n         // swap_contexts function.\n+        let mut current_task: ~GreenTask = unsafe {\n+            cast::transmute(current_task_dupe)\n+        };\n+        current_task.sched.get_mut_ref().run_cleanup_job();\n+\n+        // See the comments in switch_running_tasks_and_then for why a lock\n+        // is acquired here. This is the resumption points and the \"bounce\"\n+        // that it is referring to.\n         unsafe {\n-            let task: *mut Task = Local::unsafe_borrow();\n-            (*task).sched.get_mut_ref().run_cleanup_job();\n-\n-            // See the comments in switch_running_tasks_and_then for why a lock\n-            // is acquired here. This is the resumption points and the \"bounce\"\n-            // that it is referring to.\n-            (*task).nasty_deschedule_lock.lock();\n-            (*task).nasty_deschedule_lock.unlock();\n+            current_task.nasty_deschedule_lock.lock();\n+            current_task.nasty_deschedule_lock.unlock();\n         }\n+        return current_task;\n     }\n \n     // Returns a mutable reference to both contexts involved in this\n     // swap. This is unsafe - we are getting mutable internal\n     // references to keep even when we don't own the tasks. It looks\n     // kinda safe because we are doing transmutes before passing in\n     // the arguments.\n-    pub fn get_contexts<'a>(current_task: &mut Task, next_task: &mut Task) ->\n+    pub fn get_contexts<'a>(current_task: &mut GreenTask, next_task: &mut GreenTask) ->\n         (&'a mut Context, &'a mut Context) {\n         let current_task_context =\n             &mut current_task.coroutine.get_mut_ref().saved_context;\n         let next_task_context =\n                 &mut next_task.coroutine.get_mut_ref().saved_context;\n         unsafe {\n-            (transmute_mut_region(current_task_context),\n-             transmute_mut_region(next_task_context))\n+            (cast::transmute_mut_region(current_task_context),\n+             cast::transmute_mut_region(next_task_context))\n         }\n     }\n \n     // * Context Swapping Helpers - Here be ugliness!\n \n-    pub fn resume_task_immediately(~self, task: ~Task) {\n-        self.change_task_context(task, |sched, stask| {\n+    pub fn resume_task_immediately(~self, cur: ~GreenTask,\n+                                   next: ~GreenTask) -> ~GreenTask {\n+        assert!(cur.is_sched());\n+        self.change_task_context(cur, next, |sched, stask| {\n+            assert!(sched.sched_task.is_none());\n             sched.sched_task = Some(stask);\n         })\n     }\n \n     fn resume_task_immediately_cl(sched: ~Scheduler,\n-                                  task: ~Task) {\n-        sched.resume_task_immediately(task)\n-    }\n-\n-\n-    pub fn resume_blocked_task_immediately(~self, blocked_task: BlockedTask) {\n-        match blocked_task.wake() {\n-            Some(task) => { self.resume_task_immediately(task); }\n-            None => Local::put(self)\n-        };\n+                                  cur: ~GreenTask,\n+                                  next: ~GreenTask) {\n+        sched.resume_task_immediately(cur, next).put()\n     }\n \n     /// Block a running task, context switch to the scheduler, then pass the\n@@ -709,15 +694,18 @@ impl Scheduler {\n     /// guaranteed that this function will not return before the given closure\n     /// has returned.\n     pub fn deschedule_running_task_and_then(mut ~self,\n+                                            cur: ~GreenTask,\n                                             f: |&mut Scheduler, BlockedTask|) {\n         // Trickier - we need to get the scheduler task out of self\n         // and use it as the destination.\n         let stask = self.sched_task.take_unwrap();\n         // Otherwise this is the same as below.\n-        self.switch_running_tasks_and_then(stask, f);\n+        self.switch_running_tasks_and_then(cur, stask, f)\n     }\n \n-    pub fn switch_running_tasks_and_then(~self, next_task: ~Task,\n+    pub fn switch_running_tasks_and_then(~self,\n+                                         cur: ~GreenTask,\n+                                         next: ~GreenTask,\n                                          f: |&mut Scheduler, BlockedTask|) {\n         // And here comes one of the sad moments in which a lock is used in a\n         // core portion of the rust runtime. As always, this is highly\n@@ -733,80 +721,96 @@ impl Scheduler {\n         // task-local lock around this block. The resumption of the task in\n         // context switching will bounce on the lock, thereby waiting for this\n         // block to finish, eliminating the race mentioned above.\n+        // fail!(\"should never return!\");\n         //\n         // To actually maintain a handle to the lock, we use an unsafe pointer\n         // to it, but we're guaranteed that the task won't exit until we've\n         // unlocked the lock so there's no worry of this memory going away.\n-        self.change_task_context(next_task, |sched, mut task| {\n+        let cur = self.change_task_context(cur, next, |sched, mut task| {\n             let lock: *mut Mutex = &mut task.nasty_deschedule_lock;\n             unsafe { (*lock).lock() }\n-            f(sched, BlockedTask::block(task));\n+            f(sched, BlockedTask::block(task.swap()));\n             unsafe { (*lock).unlock() }\n-        })\n+        });\n+        cur.put();\n     }\n \n-    fn switch_task(sched: ~Scheduler, task: ~Task) {\n-        sched.switch_running_tasks_and_then(task, |sched, last_task| {\n-            sched.enqueue_blocked_task(last_task);\n-        });\n+    fn switch_task(sched: ~Scheduler, cur: ~GreenTask, next: ~GreenTask) {\n+        sched.change_task_context(cur, next, |sched, last_task| {\n+            if last_task.is_sched() {\n+                assert!(sched.sched_task.is_none());\n+                sched.sched_task = Some(last_task);\n+            } else {\n+                sched.enqueue_task(last_task);\n+            }\n+        }).put()\n     }\n \n     // * Task Context Helpers\n \n     /// Called by a running task to end execution, after which it will\n     /// be recycled by the scheduler for reuse in a new task.\n-    pub fn terminate_current_task(mut ~self) {\n+    pub fn terminate_current_task(mut ~self, cur: ~GreenTask) {\n         // Similar to deschedule running task and then, but cannot go through\n         // the task-blocking path. The task is already dying.\n         let stask = self.sched_task.take_unwrap();\n-        self.change_task_context(stask, |sched, mut dead_task| {\n+        let _cur = self.change_task_context(cur, stask, |sched, mut dead_task| {\n             let coroutine = dead_task.coroutine.take_unwrap();\n             coroutine.recycle(&mut sched.stack_pool);\n-        })\n+        });\n+        fail!(\"should never return!\");\n     }\n \n-    pub fn run_task(task: ~Task) {\n-        let sched: ~Scheduler = Local::take();\n-        sched.process_task(task, Scheduler::switch_task);\n+    pub fn run_task(~self, cur: ~GreenTask, next: ~GreenTask) {\n+        self.process_task(cur, next, Scheduler::switch_task);\n     }\n \n-    pub fn run_task_later(next_task: ~Task) {\n-        let mut sched = Local::borrow(None::<Scheduler>);\n-        sched.get().enqueue_task(next_task);\n+    pub fn run_task_later(mut cur: ~GreenTask, next: ~GreenTask) {\n+        let mut sched = cur.sched.take_unwrap();\n+        sched.enqueue_task(next);\n+        cur.put_with_sched(sched);\n     }\n \n     /// Yield control to the scheduler, executing another task. This is guaranteed\n     /// to introduce some amount of randomness to the scheduler. Currently the\n     /// randomness is a result of performing a round of work stealing (which\n     /// may end up stealing from the current scheduler).\n-    pub fn yield_now(mut ~self) {\n-        self.yield_check_count = reset_yield_check(&mut self.rng);\n-        // Tell the scheduler to start stealing on the next iteration\n-        self.steal_for_yield = true;\n-        self.deschedule_running_task_and_then(|sched, task| {\n-            sched.enqueue_blocked_task(task);\n-        })\n+    pub fn yield_now(mut ~self, cur: ~GreenTask) {\n+        if cur.is_sched() {\n+            assert!(self.sched_task.is_none());\n+            self.run_sched_once(cur);\n+        } else {\n+            self.yield_check_count = reset_yield_check(&mut self.rng);\n+            // Tell the scheduler to start stealing on the next iteration\n+            self.steal_for_yield = true;\n+            let stask = self.sched_task.take_unwrap();\n+            let cur = self.change_task_context(cur, stask, |sched, task| {\n+                sched.enqueue_task(task);\n+            });\n+            cur.put()\n+        }\n     }\n \n-    pub fn maybe_yield(mut ~self) {\n-        // The number of times to do the yield check before yielding, chosen arbitrarily.\n+    pub fn maybe_yield(mut ~self, cur: ~GreenTask) {\n+        // The number of times to do the yield check before yielding, chosen\n+        // arbitrarily.\n         rtassert!(self.yield_check_count > 0);\n         self.yield_check_count -= 1;\n         if self.yield_check_count == 0 {\n-            self.yield_now();\n+            self.yield_now(cur);\n         } else {\n-            Local::put(self);\n+            cur.put_with_sched(self);\n         }\n     }\n \n \n     // * Utility Functions\n \n-    pub fn sched_id(&self) -> uint { to_uint(self) }\n+    pub fn sched_id(&self) -> uint { unsafe { cast::transmute(self) } }\n \n     pub fn run_cleanup_job(&mut self) {\n         let cleanup_job = self.cleanup_job.take_unwrap();\n-        cleanup_job.run(self);\n+        cleanup_job.run(self)\n     }\n \n     pub fn make_handle(&mut self) -> SchedHandle {\n@@ -816,20 +820,20 @@ impl Scheduler {\n             remote: remote,\n             queue: self.message_producer.clone(),\n             sched_id: self.sched_id()\n-        };\n+        }\n     }\n }\n \n // Supporting types\n \n-type SchedulingFn = extern \"Rust\" fn (~Scheduler, ~Task);\n+type SchedulingFn = extern \"Rust\" fn (~Scheduler, ~GreenTask, ~GreenTask);\n \n pub enum SchedMessage {\n     Wake,\n     Shutdown,\n-    PinnedTask(~Task),\n-    TaskFromFriend(~Task),\n-    RunOnce(~Task),\n+    PinnedTask(~GreenTask),\n+    TaskFromFriend(~GreenTask),\n+    RunOnce(~GreenTask),\n }\n \n pub struct SchedHandle {\n@@ -849,17 +853,28 @@ struct SchedRunner;\n \n impl Callback for SchedRunner {\n     fn call(&mut self) {\n-        Scheduler::run_sched_once();\n+        // In theory, this function needs to invoke the `run_sched_once`\n+        // function on the scheduler. Sadly, we have no context here, except for\n+        // knowledge of the local `Task`. In order to avoid a call to\n+        // `GreenTask::convert`, we just call `yield_now` and the scheduler will\n+        // detect when a sched task performs a yield vs a green task performing\n+        // a yield (and act accordingly).\n+        //\n+        // This function could be converted to `GreenTask::convert` if\n+        // absolutely necessary, but for cleanliness it is much better to not\n+        // use the conversion function.\n+        let task: ~Task = Local::take();\n+        task.yield_now();\n     }\n }\n \n struct CleanupJob {\n-    task: ~Task,\n+    task: ~GreenTask,\n     f: UnsafeTaskReceiver\n }\n \n impl CleanupJob {\n-    pub fn new(task: ~Task, f: UnsafeTaskReceiver) -> CleanupJob {\n+    pub fn new(task: ~GreenTask, f: UnsafeTaskReceiver) -> CleanupJob {\n         CleanupJob {\n             task: task,\n             f: f\n@@ -876,14 +891,16 @@ impl CleanupJob {\n // complaining\n type UnsafeTaskReceiver = raw::Closure;\n trait ClosureConverter {\n-    fn from_fn(|&mut Scheduler, ~Task|) -> Self;\n-    fn to_fn(self) -> |&mut Scheduler, ~Task|;\n+    fn from_fn(|&mut Scheduler, ~GreenTask|) -> Self;\n+    fn to_fn(self) -> |&mut Scheduler, ~GreenTask|;\n }\n impl ClosureConverter for UnsafeTaskReceiver {\n-    fn from_fn(f: |&mut Scheduler, ~Task|) -> UnsafeTaskReceiver {\n-        unsafe { transmute(f) }\n+    fn from_fn(f: |&mut Scheduler, ~GreenTask|) -> UnsafeTaskReceiver {\n+        unsafe { cast::transmute(f) }\n+    }\n+    fn to_fn(self) -> |&mut Scheduler, ~GreenTask| {\n+        unsafe { cast::transmute(self) }\n     }\n-    fn to_fn(self) -> |&mut Scheduler, ~Task| { unsafe { transmute(self) } }\n }\n \n // On unix, we read randomness straight from /dev/urandom, but the\n@@ -897,12 +914,9 @@ fn new_sched_rng() -> XorShiftRng {\n }\n #[cfg(unix)]\n fn new_sched_rng() -> XorShiftRng {\n-    use libc;\n-    use mem;\n-    use c_str::ToCStr;\n-    use vec::MutableVector;\n-    use iter::Iterator;\n-    use rand::SeedableRng;\n+    use std::libc;\n+    use std::mem;\n+    use std::rand::SeedableRng;\n \n     let fd = \"/dev/urandom\".with_c_str(|name| {\n         unsafe { libc::open(name, libc::O_RDONLY, 0) }\n@@ -933,14 +947,11 @@ fn new_sched_rng() -> XorShiftRng {\n \n #[cfg(test)]\n mod test {\n-    use prelude::*;\n-\n     use borrow::to_uint;\n     use rt::deque::BufferPool;\n     use rt::basic;\n     use rt::sched::{Scheduler};\n-    use rt::task::{Task, Sched};\n-    use rt::test::*;\n+    use rt::task::{GreenTask, Sched};\n     use rt::thread::Thread;\n     use rt::util;\n     use task::TaskResult;\n@@ -1023,10 +1034,10 @@ mod test {\n             let mut sched = ~new_test_uv_sched();\n             let sched_handle = sched.make_handle();\n \n-            let mut task = ~do Task::new_root_homed(&mut sched.stack_pool, None,\n+            let mut task = ~do GreenTask::new_root_homed(&mut sched.stack_pool, None,\n                                                 Sched(sched_handle)) {\n                 unsafe { *task_ran_ptr = true };\n-                assert!(Task::on_appropriate_sched());\n+                assert!(GreenTask::on_appropriate_sched());\n             };\n \n             let on_exit: proc(TaskResult) = proc(exit_status) {\n@@ -1064,8 +1075,6 @@ mod test {\n \n             let normal_handle = normal_sched.make_handle();\n \n-            let friend_handle = normal_sched.make_handle();\n-\n             // Our special scheduler\n             let mut special_sched = ~Scheduler::new_special(\n                 basic::event_loop(),\n@@ -1086,30 +1095,30 @@ mod test {\n             //   3) task not homed, sched requeues\n             //   4) task not home, send home\n \n-            let task1 = ~do Task::new_root_homed(&mut special_sched.stack_pool, None,\n+            let task1 = ~do GreenTask::new_root_homed(&mut special_sched.stack_pool, None,\n                                                  Sched(t1_handle)) || {\n-                rtassert!(Task::on_appropriate_sched());\n+                rtassert!(GreenTask::on_appropriate_sched());\n             };\n             rtdebug!(\"task1 id: **{}**\", borrow::to_uint(task1));\n \n-            let task2 = ~do Task::new_root(&mut normal_sched.stack_pool, None) {\n-                rtassert!(Task::on_appropriate_sched());\n+            let task2 = ~do GreenTask::new_root(&mut normal_sched.stack_pool, None) {\n+                rtassert!(GreenTask::on_appropriate_sched());\n             };\n \n-            let task3 = ~do Task::new_root(&mut normal_sched.stack_pool, None) {\n-                rtassert!(Task::on_appropriate_sched());\n+            let task3 = ~do GreenTask::new_root(&mut normal_sched.stack_pool, None) {\n+                rtassert!(GreenTask::on_appropriate_sched());\n             };\n \n-            let task4 = ~do Task::new_root_homed(&mut special_sched.stack_pool, None,\n+            let task4 = ~do GreenTask::new_root_homed(&mut special_sched.stack_pool, None,\n                                                  Sched(t4_handle)) {\n-                rtassert!(Task::on_appropriate_sched());\n+                rtassert!(GreenTask::on_appropriate_sched());\n             };\n             rtdebug!(\"task4 id: **{}**\", borrow::to_uint(task4));\n \n             // Signal from the special task that we are done.\n             let (port, chan) = Chan::<()>::new();\n \n-            let normal_task = ~do Task::new_root(&mut normal_sched.stack_pool, None) {\n+            let normal_task = ~do GreenTask::new_root(&mut normal_sched.stack_pool, None) {\n                 rtdebug!(\"*about to submit task2*\");\n                 Scheduler::run_task(task2);\n                 rtdebug!(\"*about to submit task4*\");\n@@ -1124,7 +1133,7 @@ mod test {\n \n             rtdebug!(\"normal task: {}\", borrow::to_uint(normal_task));\n \n-            let special_task = ~do Task::new_root(&mut special_sched.stack_pool, None) {\n+            let special_task = ~do GreenTask::new_root(&mut special_sched.stack_pool, None) {\n                 rtdebug!(\"*about to submit task1*\");\n                 Scheduler::run_task(task1);\n                 rtdebug!(\"*about to submit task3*\");\n@@ -1226,14 +1235,14 @@ mod test {\n                 let thread = do Thread::start {\n                     let mut sched = sched;\n                     let bootstrap_task =\n-                        ~Task::new_root(&mut sched.stack_pool,\n+                        ~GreenTask::new_root(&mut sched.stack_pool,\n                                         None,\n                                         proc()());\n                     sched.bootstrap(bootstrap_task);\n                 };\n \n                 let mut stack_pool = StackPool::new();\n-                let task = ~Task::new_root(&mut stack_pool, None, proc()());\n+                let task = ~GreenTask::new_root(&mut stack_pool, None, proc()());\n                 handle.send(TaskFromFriend(task));\n \n                 handle.send(Shutdown);", "previous_filename": "src/libstd/rt/sched.rs"}, {"sha": "5be260efdfaefe1453137d9ba95712eb39e6bef7", "filename": "src/libgreen/sleeper_list.rs", "status": "renamed", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fsleeper_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fsleeper_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsleeper_list.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -11,10 +11,9 @@\n //! Maintains a shared list of sleeping schedulers. Schedulers\n //! use this to wake each other up.\n \n-use rt::sched::SchedHandle;\n-use rt::mpmc_bounded_queue::Queue;\n-use option::*;\n-use clone::Clone;\n+use std::sync::mpmc_bounded_queue::Queue;\n+\n+use sched::SchedHandle;\n \n pub struct SleeperList {\n     priv q: Queue<SchedHandle>,", "previous_filename": "src/libstd/rt/sleeper_list.rs"}, {"sha": "cf2a3d5f1414c8e808dcda21995af4cd3949689c", "filename": "src/libgreen/stack.rs", "status": "renamed", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fstack.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Fstack.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fstack.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -8,11 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use container::Container;\n-use ptr::RawPtr;\n-use vec;\n-use ops::Drop;\n-use libc::{c_uint, uintptr_t};\n+use std::vec;\n+use std::libc::{c_uint, uintptr_t};\n \n pub struct StackSegment {\n     priv buf: ~[u8],", "previous_filename": "src/libstd/rt/stack.rs"}, {"sha": "72e72f2cd99339228f0c1c65d1ba09b59fbf7047", "filename": "src/libgreen/task.rs", "status": "added", "additions": 505, "deletions": 0, "changes": 505, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibgreen%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Ftask.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -0,0 +1,505 @@\n+// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+//! The Green Task implementation\n+//!\n+//! This module contains the glue to the libstd runtime necessary to integrate\n+//! M:N scheduling. This GreenTask structure is hidden as a trait object in all\n+//! rust tasks and virtual calls are made in order to interface with it.\n+//!\n+//! Each green task contains a scheduler if it is currently running, and it also\n+//! contains the rust task itself in order to juggle around ownership of the\n+//! values.\n+\n+use std::cast;\n+use std::rt::Runtime;\n+use std::rt::rtio;\n+use std::rt::local::Local;\n+use std::rt::task::{Task, BlockedTask};\n+use std::task::TaskOpts;\n+use std::unstable::mutex::Mutex;\n+\n+use coroutine::Coroutine;\n+use sched::{Scheduler, SchedHandle, RunOnce};\n+use stack::StackPool;\n+\n+/// The necessary fields needed to keep track of a green task (as opposed to a\n+/// 1:1 task).\n+pub struct GreenTask {\n+    coroutine: Option<Coroutine>,\n+    handle: Option<SchedHandle>,\n+    sched: Option<~Scheduler>,\n+    task: Option<~Task>,\n+    task_type: TaskType,\n+    pool_id: uint,\n+\n+    // See the comments in the scheduler about why this is necessary\n+    nasty_deschedule_lock: Mutex,\n+}\n+\n+pub enum TaskType {\n+    TypeGreen(Option<Home>),\n+    TypeSched,\n+}\n+\n+pub enum Home {\n+    AnySched,\n+    HomeSched(SchedHandle),\n+}\n+\n+impl GreenTask {\n+    pub fn new(stack_pool: &mut StackPool,\n+               stack_size: Option<uint>,\n+               start: proc()) -> ~GreenTask {\n+        GreenTask::new_homed(stack_pool, stack_size, AnySched, start)\n+    }\n+\n+    pub fn new_homed(stack_pool: &mut StackPool,\n+                     stack_size: Option<uint>,\n+                     home: Home,\n+                     start: proc()) -> ~GreenTask {\n+        let mut ops = GreenTask::new_typed(None, TypeGreen(Some(home)));\n+        let start = GreenTask::build_start_wrapper(start, ops.as_uint());\n+        ops.coroutine = Some(Coroutine::new(stack_pool, stack_size, start));\n+        return ops;\n+    }\n+\n+    pub fn new_typed(coroutine: Option<Coroutine>,\n+                     task_type: TaskType) -> ~GreenTask {\n+        ~GreenTask {\n+            pool_id: 0,\n+            coroutine: coroutine,\n+            task_type: task_type,\n+            sched: None,\n+            handle: None,\n+            nasty_deschedule_lock: unsafe { Mutex::new() },\n+            task: None,\n+        }\n+    }\n+\n+    /// Just like the `maybe_take_runtime` function, this function should *not*\n+    /// exist. Usage of this function is _strongly_ discouraged. This is an\n+    /// absolute last resort necessary for converting a libstd task to a green\n+    /// task.\n+    ///\n+    /// This function will assert that the task is indeed a green task before\n+    /// returning (and will kill the entire process if this is wrong).\n+    pub fn convert(mut task: ~Task) -> ~GreenTask {\n+        match task.maybe_take_runtime::<GreenTask>() {\n+            Some(mut green) => {\n+                green.put_task(task);\n+                green\n+            }\n+            None => rtabort!(\"not a green task any more?\"),\n+        }\n+    }\n+\n+    /// Builds a function which is the actual starting execution point for a\n+    /// rust task. This function is the glue necessary to execute the libstd\n+    /// task and then clean up the green thread after it exits.\n+    ///\n+    /// The second argument to this function is actually a transmuted copy of\n+    /// the `GreenTask` pointer. Context switches in the scheduler silently\n+    /// transfer ownership of the `GreenTask` to the other end of the context\n+    /// switch, so because this is the first code that is running in this task,\n+    /// it must first re-acquire ownership of the green task.\n+    pub fn build_start_wrapper(start: proc(), ops: uint) -> proc() {\n+        proc() {\n+            // First code after swap to this new context. Run our\n+            // cleanup job after we have re-acquired ownership of the green\n+            // task.\n+            let mut task: ~GreenTask = unsafe { GreenTask::from_uint(ops) };\n+            task.sched.get_mut_ref().run_cleanup_job();\n+\n+            // Convert our green task to a libstd task and then execute the code\n+            // requeted. This is the \"try/catch\" block for this green task and\n+            // is the wrapper for *all* code run in the task.\n+            let mut start = Some(start);\n+            let task = task.swap().run(|| start.take_unwrap()());\n+\n+            // Once the function has exited, it's time to run the termination\n+            // routine. This means we need to context switch one more time but\n+            // clean ourselves up on the other end. Since we have no way of\n+            // preserving a handle to the GreenTask down to this point, this\n+            // unfortunately must call `GreenTask::convert`. In order to avoid\n+            // this we could add a `terminate` function to the `Runtime` trait\n+            // in libstd, but that seems less appropriate since the coversion\n+            // method exists.\n+            GreenTask::convert(task).terminate();\n+        }\n+    }\n+\n+    pub fn give_home(&mut self, new_home: Home) {\n+        match self.task_type {\n+            TypeGreen(ref mut home) => { *home = Some(new_home); }\n+            TypeSched => rtabort!(\"type error: used SchedTask as GreenTask\"),\n+        }\n+    }\n+\n+    pub fn take_unwrap_home(&mut self) -> Home {\n+        match self.task_type {\n+            TypeGreen(ref mut home) => home.take_unwrap(),\n+            TypeSched => rtabort!(\"type error: used SchedTask as GreenTask\"),\n+        }\n+    }\n+\n+    // New utility functions for homes.\n+\n+    pub fn is_home_no_tls(&self, sched: &Scheduler) -> bool {\n+        match self.task_type {\n+            TypeGreen(Some(AnySched)) => { false }\n+            TypeGreen(Some(HomeSched(SchedHandle { sched_id: ref id, .. }))) => {\n+                *id == sched.sched_id()\n+            }\n+            TypeGreen(None) => { rtabort!(\"task without home\"); }\n+            TypeSched => {\n+                // Awe yea\n+                rtabort!(\"type error: expected: TypeGreen, found: TaskSched\");\n+            }\n+        }\n+    }\n+\n+    pub fn homed(&self) -> bool {\n+        match self.task_type {\n+            TypeGreen(Some(AnySched)) => { false }\n+            TypeGreen(Some(HomeSched(SchedHandle { .. }))) => { true }\n+            TypeGreen(None) => {\n+                rtabort!(\"task without home\");\n+            }\n+            TypeSched => {\n+                rtabort!(\"type error: expected: TypeGreen, found: TaskSched\");\n+            }\n+        }\n+    }\n+\n+    pub fn is_sched(&self) -> bool {\n+        match self.task_type {\n+            TypeGreen(..) => false, TypeSched => true,\n+        }\n+    }\n+\n+    // Unsafe functions for transferring ownership of this GreenTask across\n+    // context switches\n+\n+    pub fn as_uint(&self) -> uint {\n+        unsafe { cast::transmute(self) }\n+    }\n+\n+    pub unsafe fn from_uint(val: uint) -> ~GreenTask { cast::transmute(val) }\n+\n+    // Runtime glue functions and helpers\n+\n+    pub fn put_with_sched(mut ~self, sched: ~Scheduler) {\n+        assert!(self.sched.is_none());\n+        self.sched = Some(sched);\n+        self.put();\n+    }\n+\n+    pub fn put_task(&mut self, task: ~Task) {\n+        assert!(self.task.is_none());\n+        self.task = Some(task);\n+    }\n+\n+    pub fn swap(mut ~self) -> ~Task {\n+        let mut task = self.task.take_unwrap();\n+        task.put_runtime(self as ~Runtime);\n+        return task;\n+    }\n+\n+    pub fn put(~self) {\n+        assert!(self.sched.is_some());\n+        Local::put(self.swap());\n+    }\n+\n+    fn terminate(mut ~self) {\n+        let sched = self.sched.take_unwrap();\n+        sched.terminate_current_task(self);\n+    }\n+\n+    // This function is used to remotely wakeup this green task back on to its\n+    // original pool of schedulers. In order to do so, each tasks arranges a\n+    // SchedHandle upon descheduling to be available for sending itself back to\n+    // the original pool.\n+    //\n+    // Note that there is an interesting transfer of ownership going on here. We\n+    // must relinquish ownership of the green task, but then also send the task\n+    // over the handle back to the original scheduler. In order to safely do\n+    // this, we leverage the already-present \"nasty descheduling lock\". The\n+    // reason for doing this is that each task will bounce on this lock after\n+    // resuming after a context switch. By holding the lock over the enqueueing\n+    // of the task, we're guaranteed that the SchedHandle's memory will be valid\n+    // for this entire function.\n+    //\n+    // An alternative would include having incredibly cheaply cloneable handles,\n+    // but right now a SchedHandle is something like 6 allocations, so it is\n+    // *not* a cheap operation to clone a handle. Until the day comes that we\n+    // need to optimize this, a lock should do just fine (it's completely\n+    // uncontended except for when the task is rescheduled).\n+    fn reawaken_remotely(mut ~self) {\n+        unsafe {\n+            let mtx = &mut self.nasty_deschedule_lock as *mut Mutex;\n+            let handle = self.handle.get_mut_ref() as *mut SchedHandle;\n+            (*mtx).lock();\n+            (*handle).send(RunOnce(self));\n+            (*mtx).unlock();\n+        }\n+    }\n+}\n+\n+impl Runtime for GreenTask {\n+    fn yield_now(mut ~self, cur_task: ~Task) {\n+        self.put_task(cur_task);\n+        let sched = self.sched.take_unwrap();\n+        sched.yield_now(self);\n+    }\n+\n+    fn maybe_yield(mut ~self, cur_task: ~Task) {\n+        self.put_task(cur_task);\n+        let sched = self.sched.take_unwrap();\n+        sched.maybe_yield(self);\n+    }\n+\n+    fn deschedule(mut ~self, times: uint, cur_task: ~Task,\n+                  f: |BlockedTask| -> Result<(), BlockedTask>) {\n+        self.put_task(cur_task);\n+        let mut sched = self.sched.take_unwrap();\n+\n+        // In order for this task to be reawoken in all possible contexts, we\n+        // may need a handle back in to the current scheduler. When we're woken\n+        // up in anything other than the local scheduler pool, this handle is\n+        // used to send this task back into the scheduler pool.\n+        if self.handle.is_none() {\n+            self.handle = Some(sched.make_handle());\n+            self.pool_id = sched.pool_id;\n+        }\n+\n+        // This code is pretty standard, except for the usage of\n+        // `GreenTask::convert`. Right now if we use `reawaken` directly it will\n+        // expect for there to be a task in local TLS, but that is not true for\n+        // this deschedule block (because the scheduler must retain ownership of\n+        // the task while the cleanup job is running). In order to get around\n+        // this for now, we invoke the scheduler directly with the converted\n+        // Task => GreenTask structure.\n+        if times == 1 {\n+            sched.deschedule_running_task_and_then(self, |sched, task| {\n+                match f(task) {\n+                    Ok(()) => {}\n+                    Err(t) => {\n+                        t.wake().map(|t| {\n+                            sched.enqueue_task(GreenTask::convert(t))\n+                        });\n+                    }\n+                }\n+            });\n+        } else {\n+            sched.deschedule_running_task_and_then(self, |sched, task| {\n+                for task in task.make_selectable(times) {\n+                    match f(task) {\n+                        Ok(()) => {},\n+                        Err(task) => {\n+                            task.wake().map(|t| {\n+                                sched.enqueue_task(GreenTask::convert(t))\n+                            });\n+                            break\n+                        }\n+                    }\n+                }\n+            });\n+        }\n+    }\n+\n+    fn reawaken(mut ~self, to_wake: ~Task, can_resched: bool) {\n+        self.put_task(to_wake);\n+        assert!(self.sched.is_none());\n+\n+        // Waking up a green thread is a bit of a tricky situation. We have no\n+        // guarantee about where the current task is running. The options we\n+        // have for where this current task is running are:\n+        //\n+        //  1. Our original scheduler pool\n+        //  2. Some other scheduler pool\n+        //  3. Something that isn't a scheduler pool\n+        //\n+        // In order to figure out what case we're in, this is the reason that\n+        // the `maybe_take_runtime` function exists. Using this function we can\n+        // dynamically check to see which of these cases is the current\n+        // situation and then dispatch accordingly.\n+        //\n+        // In case 1, we just use the local scheduler to resume ourselves\n+        // immediately (if a rescheduling is possible).\n+        //\n+        // In case 2 and 3, we need to remotely reawaken ourself in order to be\n+        // transplanted back to the correct scheduler pool.\n+        let mut running_task: ~Task = Local::take();\n+        match running_task.maybe_take_runtime::<GreenTask>() {\n+            Some(mut running_green_task) => {\n+                let mut sched = running_green_task.sched.take_unwrap();\n+                if sched.pool_id == self.pool_id {\n+                    running_green_task.put_task(running_task);\n+                    if can_resched {\n+                        sched.run_task(running_green_task, self);\n+                    } else {\n+                        sched.enqueue_task(self);\n+                        running_green_task.put_with_sched(sched);\n+                    }\n+                } else {\n+                    self.reawaken_remotely();\n+\n+                    // put that thing back where it came from!\n+                    running_task.put_runtime(running_green_task as ~Runtime);\n+                    Local::put(running_task);\n+                }\n+            }\n+            None => {\n+                self.reawaken_remotely();\n+                Local::put(running_task);\n+            }\n+        }\n+    }\n+\n+    fn spawn_sibling(mut ~self, cur_task: ~Task, opts: TaskOpts, f: proc()) {\n+        self.put_task(cur_task);\n+\n+        let TaskOpts {\n+            watched: _watched,\n+            notify_chan, name, stack_size\n+        } = opts;\n+\n+        // Spawns a task into the current scheduler. We allocate the new task's\n+        // stack from the scheduler's stack pool, and then configure it\n+        // accordingly to `opts`. Afterwards we bootstrap it immediately by\n+        // switching to it.\n+        //\n+        // Upon returning, our task is back in TLS and we're good to return.\n+        let mut sched = self.sched.take_unwrap();\n+        let mut sibling = GreenTask::new(&mut sched.stack_pool, stack_size, f);\n+        let mut sibling_task = ~Task::new();\n+        sibling_task.name = name;\n+        match notify_chan {\n+            Some(chan) => {\n+                let on_exit = proc(task_result) { chan.send(task_result) };\n+                sibling_task.death.on_exit = Some(on_exit);\n+            }\n+            None => {}\n+        }\n+\n+        sibling.task = Some(sibling_task);\n+        sched.run_task(self, sibling)\n+    }\n+\n+    // Local I/O is provided by the scheduler's event loop\n+    fn local_io<'a>(&'a mut self) -> Option<rtio::LocalIo<'a>> {\n+        match self.sched.get_mut_ref().event_loop.io() {\n+            Some(io) => Some(rtio::LocalIo::new(io)),\n+            None => None,\n+        }\n+    }\n+\n+    fn wrap(~self) -> ~Any { self as ~Any }\n+}\n+\n+impl Drop for GreenTask {\n+    fn drop(&mut self) {\n+        unsafe { self.nasty_deschedule_lock.destroy(); }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+\n+    #[test]\n+    fn local_heap() {\n+        do run_in_newsched_task() {\n+            let a = @5;\n+            let b = a;\n+            assert!(*a == 5);\n+            assert!(*b == 5);\n+        }\n+    }\n+\n+    #[test]\n+    fn tls() {\n+        use std::local_data;\n+        do run_in_newsched_task() {\n+            local_data_key!(key: @~str)\n+            local_data::set(key, @~\"data\");\n+            assert!(*local_data::get(key, |k| k.map(|k| *k)).unwrap() == ~\"data\");\n+            local_data_key!(key2: @~str)\n+            local_data::set(key2, @~\"data\");\n+            assert!(*local_data::get(key2, |k| k.map(|k| *k)).unwrap() == ~\"data\");\n+        }\n+    }\n+\n+    #[test]\n+    fn unwind() {\n+        do run_in_newsched_task() {\n+            let result = spawntask_try(proc()());\n+            rtdebug!(\"trying first assert\");\n+            assert!(result.is_ok());\n+            let result = spawntask_try(proc() fail!());\n+            rtdebug!(\"trying second assert\");\n+            assert!(result.is_err());\n+        }\n+    }\n+\n+    #[test]\n+    fn rng() {\n+        do run_in_uv_task() {\n+            use std::rand::{rng, Rng};\n+            let mut r = rng();\n+            let _ = r.next_u32();\n+        }\n+    }\n+\n+    #[test]\n+    fn logging() {\n+        do run_in_uv_task() {\n+            info!(\"here i am. logging in a newsched task\");\n+        }\n+    }\n+\n+    #[test]\n+    fn comm_stream() {\n+        do run_in_newsched_task() {\n+            let (port, chan) = Chan::new();\n+            chan.send(10);\n+            assert!(port.recv() == 10);\n+        }\n+    }\n+\n+    #[test]\n+    fn comm_shared_chan() {\n+        do run_in_newsched_task() {\n+            let (port, chan) = SharedChan::new();\n+            chan.send(10);\n+            assert!(port.recv() == 10);\n+        }\n+    }\n+\n+    //#[test]\n+    //fn heap_cycles() {\n+    //    use std::option::{Option, Some, None};\n+\n+    //    do run_in_newsched_task {\n+    //        struct List {\n+    //            next: Option<@mut List>,\n+    //        }\n+\n+    //        let a = @mut List { next: None };\n+    //        let b = @mut List { next: Some(a) };\n+\n+    //        a.next = Some(b);\n+    //    }\n+    //}\n+\n+    #[test]\n+    #[should_fail]\n+    fn test_begin_unwind() { begin_unwind(\"cause\", file!(), line!()) }\n+}"}, {"sha": "d1e97cb6ec0f8a993f9244ba8d8af6f708a78282", "filename": "src/libstd/rt/borrowck.rs", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fborrowck.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fborrowck.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fborrowck.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -12,9 +12,8 @@ use c_str::{ToCStr, CString};\n use libc::{c_char, size_t};\n use option::{Option, None, Some};\n use ptr::RawPtr;\n-use rt::env;\n+use rt;\n use rt::local::Local;\n-use rt::task;\n use rt::task::Task;\n use str::OwnedStr;\n use str;\n@@ -62,7 +61,7 @@ unsafe fn fail_borrowed(alloc: *mut raw::Box<()>, file: *c_char, line: size_t)\n     match try_take_task_borrow_list() {\n         None => { // not recording borrows\n             let msg = \"borrowed\";\n-            msg.with_c_str(|msg_p| task::begin_unwind_raw(msg_p, file, line))\n+            msg.with_c_str(|msg_p| rt::begin_unwind_raw(msg_p, file, line))\n         }\n         Some(borrow_list) => { // recording borrows\n             let mut msg = ~\"borrowed\";\n@@ -76,7 +75,7 @@ unsafe fn fail_borrowed(alloc: *mut raw::Box<()>, file: *c_char, line: size_t)\n                     sep = \" and at \";\n                 }\n             }\n-            msg.with_c_str(|msg_p| task::begin_unwind_raw(msg_p, file, line))\n+            msg.with_c_str(|msg_p| rt::begin_unwind_raw(msg_p, file, line))\n         }\n     }\n }\n@@ -95,7 +94,7 @@ unsafe fn debug_borrow<T,P:RawPtr<T>>(tag: &'static str,\n     //! A useful debugging function that prints a pointer + tag + newline\n     //! without allocating memory.\n \n-    if ENABLE_DEBUG && env::debug_borrow() {\n+    if ENABLE_DEBUG && rt::env::debug_borrow() {\n         debug_borrow_slow(tag, p, old_bits, new_bits, filename, line);\n     }\n \n@@ -180,7 +179,7 @@ pub unsafe fn unrecord_borrow(a: *u8,\n             if br.alloc != a || br.file != file || br.line != line {\n                 let err = format!(\"wrong borrow found, br={:?}\", br);\n                 err.with_c_str(|msg_p| {\n-                    task::begin_unwind_raw(msg_p, file, line)\n+                    rt::begin_unwind_raw(msg_p, file, line)\n                 })\n             }\n             borrow_list"}, {"sha": "f3fa482b18cca468217bcaea08f99f618d71e92c", "filename": "src/libstd/rt/env.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fenv.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fenv.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fenv.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -17,7 +17,7 @@ use os;\n // Note that these are all accessed without any synchronization.\n // They are expected to be initialized once then left alone.\n \n-static mut MIN_STACK: uint = 2000000;\n+static mut MIN_STACK: uint = 2 * 1024 * 1024;\n static mut DEBUG_BORROW: bool = false;\n static mut POISON_ON_FREE: bool = false;\n "}, {"sha": "f4f128cf5aac1053852c2475d59fa99f229d920d", "filename": "src/libstd/rt/kill.rs", "status": "removed", "additions": 0, "deletions": 318, "changes": 318, "blob_url": "https://github.com/rust-lang/rust/blob/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Fkill.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Fkill.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fkill.rs?ref=6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "patch": "@@ -1,318 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-/*!\n-\n-Task death: asynchronous killing, linked failure, exit code propagation.\n-\n-This file implements two orthogonal building-blocks for communicating failure\n-between tasks. One is 'linked failure' or 'task killing', that is, a failing\n-task causing other tasks to fail promptly (even those that are blocked on\n-pipes or I/O). The other is 'exit code propagation', which affects the result\n-observed by the parent of a task::try task that itself spawns child tasks\n-(such as any #[test] function). In both cases the data structures live in\n-KillHandle.\n-\n-\n-I. Task killing.\n-\n-The model for killing involves two atomic flags, the \"kill flag\" and the\n-\"unkillable flag\". Operations on the kill flag include:\n-\n-- In the taskgroup code (task/spawn.rs), tasks store a clone of their\n-  KillHandle in their shared taskgroup. Another task in the group that fails\n-  will use that handle to call kill().\n-- When a task blocks, it turns its ~Task into a BlockedTask by storing a\n-  the transmuted ~Task pointer inside the KillHandle's kill flag. A task\n-  trying to block and a task trying to kill it can simultaneously access the\n-  kill flag, after which the task will get scheduled and fail (no matter who\n-  wins the race). Likewise, a task trying to wake a blocked task normally and\n-  a task trying to kill it can simultaneously access the flag; only one will\n-  get the task to reschedule it.\n-\n-Operations on the unkillable flag include:\n-\n-- When a task becomes unkillable, it swaps on the flag to forbid any killer\n-  from waking it up while it's blocked inside the unkillable section. If a\n-  kill was already pending, the task fails instead of becoming unkillable.\n-- When a task is done being unkillable, it restores the flag to the normal\n-  running state. If a kill was received-but-blocked during the unkillable\n-  section, the task fails at this later point.\n-- When a task tries to kill another task, before swapping on the kill flag, it\n-  first swaps on the unkillable flag, to see if it's \"allowed\" to wake up the\n-  task. If it isn't, the killed task will receive the signal when it becomes\n-  killable again. (Of course, a task trying to wake the task normally (e.g.\n-  sending on a channel) does not access the unkillable flag at all.)\n-\n-Why do we not need acquire/release barriers on any of the kill flag swaps?\n-This is because barriers establish orderings between accesses on different\n-memory locations, but each kill-related operation is only a swap on a single\n-location, so atomicity is all that matters. The exception is kill(), which\n-does a swap on both flags in sequence. kill() needs no barriers because it\n-does not matter if its two accesses are seen reordered on another CPU: if a\n-killer does perform both writes, it means it saw a KILL_RUNNING in the\n-unkillable flag, which means an unkillable task will see KILL_KILLED and fail\n-immediately (rendering the subsequent write to the kill flag unnecessary).\n-\n-\n-II. Exit code propagation.\n-\n-The basic model for exit code propagation, which is used with the \"watched\"\n-spawn mode (on by default for linked spawns, off for supervised and unlinked\n-spawns), is that a parent will wait for all its watched children to exit\n-before reporting whether it succeeded or failed. A watching parent will only\n-report success if it succeeded and all its children also reported success;\n-otherwise, it will report failure. This is most useful for writing test cases:\n-\n- ```\n-#[test]\n-fn test_something_in_another_task {\n-    do spawn {\n-        assert!(collatz_conjecture_is_false());\n-    }\n-}\n- ```\n-\n-Here, as the child task will certainly outlive the parent task, we might miss\n-the failure of the child when deciding whether or not the test case passed.\n-The watched spawn mode avoids this problem.\n-\n-In order to propagate exit codes from children to their parents, any\n-'watching' parent must wait for all of its children to exit before it can\n-report its final exit status. We achieve this by using an UnsafeArc, using the\n-reference counting to track how many children are still alive, and using the\n-unwrap() operation in the parent's exit path to wait for all children to exit.\n-The UnsafeArc referred to here is actually the KillHandle itself.\n-\n-This also works transitively, as if a \"middle\" watched child task is itself\n-watching a grandchild task, the \"middle\" task will do unwrap() on its own\n-KillHandle (thereby waiting for the grandchild to exit) before dropping its\n-reference to its watching parent (which will alert the parent).\n-\n-While UnsafeArc::unwrap() accomplishes the synchronization, there remains the\n-matter of reporting the exit codes themselves. This is easiest when an exiting\n-watched task has no watched children of its own:\n-\n-- If the task with no watched children exits successfully, it need do nothing.\n-- If the task with no watched children has failed, it sets a flag in the\n-  parent's KillHandle (\"any_child_failed\") to false. It then stays false forever.\n-\n-However, if a \"middle\" watched task with watched children of its own exits\n-before its child exits, we need to ensure that the grandparent task may still\n-see a failure from the grandchild task. While we could achieve this by having\n-each intermediate task block on its handle, this keeps around the other resources\n-the task was using. To be more efficient, this is accomplished via \"tombstones\".\n-\n-A tombstone is a closure, proc() -> bool, which will perform any waiting necessary\n-to collect the exit code of descendant tasks. In its environment is captured\n-the KillHandle of whichever task created the tombstone, and perhaps also any\n-tombstones that that task itself had, and finally also another tombstone,\n-effectively creating a lazy-list of heap closures.\n-\n-When a child wishes to exit early and leave tombstones behind for its parent,\n-it must use a LittleLock (pthread mutex) to synchronize with any possible\n-sibling tasks which are trying to do the same thing with the same parent.\n-However, on the other side, when the parent is ready to pull on the tombstones,\n-it need not use this lock, because the unwrap() serves as a barrier that ensures\n-no children will remain with references to the handle.\n-\n-The main logic for creating and assigning tombstones can be found in the\n-function reparent_children_to() in the impl for KillHandle.\n-\n-\n-IIA. Issues with exit code propagation.\n-\n-There are two known issues with the current scheme for exit code propagation.\n-\n-- As documented in issue #8136, the structure mandates the possibility for stack\n-  overflow when collecting tombstones that are very deeply nested. This cannot\n-  be avoided with the closure representation, as tombstones end up structured in\n-  a sort of tree. However, notably, the tombstones do not actually need to be\n-  collected in any particular order, and so a doubly-linked list may be used.\n-  However we do not do this yet because DList is in libextra.\n-\n-- A discussion with Graydon made me realize that if we decoupled the exit code\n-  propagation from the parents-waiting action, this could result in a simpler\n-  implementation as the exit codes themselves would not have to be propagated,\n-  and could instead be propagated implicitly through the taskgroup mechanism\n-  that we already have. The tombstoning scheme would still be required. I have\n-  not implemented this because currently we can't receive a linked failure kill\n-  signal during the task cleanup activity, as that is currently \"unkillable\",\n-  and occurs outside the task's unwinder's \"try\" block, so would require some\n-  restructuring.\n-\n-*/\n-\n-use cast;\n-use option::{Option, Some, None};\n-use prelude::*;\n-use iter;\n-use task::TaskResult;\n-use rt::task::Task;\n-use unstable::atomics::{AtomicUint, SeqCst};\n-use unstable::sync::UnsafeArc;\n-\n-/// A handle to a blocked task. Usually this means having the ~Task pointer by\n-/// ownership, but if the task is killable, a killer can steal it at any time.\n-pub enum BlockedTask {\n-    Owned(~Task),\n-    Shared(UnsafeArc<AtomicUint>),\n-}\n-\n-/// Per-task state related to task death, killing, failure, etc.\n-pub struct Death {\n-    // Action to be done with the exit code. If set, also makes the task wait\n-    // until all its watched children exit before collecting the status.\n-    on_exit:         Option<proc(TaskResult)>,\n-    // nesting level counter for unstable::atomically calls (0 == can deschedule).\n-    priv wont_sleep:      int,\n-}\n-\n-pub struct BlockedTaskIterator {\n-    priv inner: UnsafeArc<AtomicUint>,\n-}\n-\n-impl Iterator<BlockedTask> for BlockedTaskIterator {\n-    fn next(&mut self) -> Option<BlockedTask> {\n-        Some(Shared(self.inner.clone()))\n-    }\n-}\n-\n-impl BlockedTask {\n-    /// Returns Some if the task was successfully woken; None if already killed.\n-    pub fn wake(self) -> Option<~Task> {\n-        match self {\n-            Owned(task) => Some(task),\n-            Shared(arc) => unsafe {\n-                match (*arc.get()).swap(0, SeqCst) {\n-                    0 => None,\n-                    n => cast::transmute(n),\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Create a blocked task, unless the task was already killed.\n-    pub fn block(task: ~Task) -> BlockedTask {\n-        Owned(task)\n-    }\n-\n-    /// Converts one blocked task handle to a list of many handles to the same.\n-    pub fn make_selectable(self, num_handles: uint)\n-        -> iter::Take<BlockedTaskIterator>\n-    {\n-        let arc = match self {\n-            Owned(task) => {\n-                let flag = unsafe { AtomicUint::new(cast::transmute(task)) };\n-                UnsafeArc::new(flag)\n-            }\n-            Shared(arc) => arc.clone(),\n-        };\n-        BlockedTaskIterator{ inner: arc }.take(num_handles)\n-    }\n-\n-    // This assertion has two flavours because the wake involves an atomic op.\n-    // In the faster version, destructors will fail dramatically instead.\n-    #[inline] #[cfg(not(test))]\n-    pub fn assert_already_awake(self) { }\n-    #[inline] #[cfg(test)]\n-    pub fn assert_already_awake(self) { assert!(self.wake().is_none()); }\n-\n-    /// Convert to an unsafe uint value. Useful for storing in a pipe's state flag.\n-    #[inline]\n-    pub unsafe fn cast_to_uint(self) -> uint {\n-        match self {\n-            Owned(task) => {\n-                let blocked_task_ptr: uint = cast::transmute(task);\n-                rtassert!(blocked_task_ptr & 0x1 == 0);\n-                blocked_task_ptr\n-            }\n-            Shared(arc) => {\n-                let blocked_task_ptr: uint = cast::transmute(~arc);\n-                rtassert!(blocked_task_ptr & 0x1 == 0);\n-                blocked_task_ptr | 0x1\n-            }\n-        }\n-    }\n-\n-    /// Convert from an unsafe uint value. Useful for retrieving a pipe's state flag.\n-    #[inline]\n-    pub unsafe fn cast_from_uint(blocked_task_ptr: uint) -> BlockedTask {\n-        if blocked_task_ptr & 0x1 == 0 {\n-            Owned(cast::transmute(blocked_task_ptr))\n-        } else {\n-            let ptr: ~UnsafeArc<AtomicUint> = cast::transmute(blocked_task_ptr & !1);\n-            Shared(*ptr)\n-        }\n-    }\n-}\n-\n-impl Death {\n-    pub fn new() -> Death {\n-        Death {\n-            on_exit:         None,\n-            wont_sleep:      0,\n-        }\n-    }\n-\n-    /// Collect failure exit codes from children and propagate them to a parent.\n-    pub fn collect_failure(&mut self, result: TaskResult) {\n-        match self.on_exit.take() {\n-            Some(f) => f(result),\n-            None => {}\n-        }\n-    }\n-\n-    /// Enter a possibly-nested \"atomic\" section of code. Just for assertions.\n-    /// All calls must be paired with a subsequent call to allow_deschedule.\n-    #[inline]\n-    pub fn inhibit_deschedule(&mut self) {\n-        self.wont_sleep += 1;\n-    }\n-\n-    /// Exit a possibly-nested \"atomic\" section of code. Just for assertions.\n-    /// All calls must be paired with a preceding call to inhibit_deschedule.\n-    #[inline]\n-    pub fn allow_deschedule(&mut self) {\n-        rtassert!(self.wont_sleep != 0);\n-        self.wont_sleep -= 1;\n-    }\n-\n-    /// Ensure that the task is allowed to become descheduled.\n-    #[inline]\n-    pub fn assert_may_sleep(&self) {\n-        if self.wont_sleep != 0 {\n-            rtabort!(\"illegal atomic-sleep: attempt to reschedule while \\\n-                      using an Exclusive or LittleLock\");\n-        }\n-    }\n-}\n-\n-impl Drop for Death {\n-    fn drop(&mut self) {\n-        // Mustn't be in an atomic or unkillable section at task death.\n-        rtassert!(self.wont_sleep == 0);\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use rt::test::*;\n-    use super::*;\n-\n-    // Task blocking tests\n-\n-    #[test]\n-    fn block_and_wake() {\n-        do with_test_task |task| {\n-            BlockedTask::block(task).wake().unwrap()\n-        }\n-    }\n-}"}, {"sha": "ea27956ad9033bd821a1fa06b13132c91b77434d", "filename": "src/libstd/rt/local.rs", "status": "modified", "additions": 1, "deletions": 78, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Flocal.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -8,8 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use option::{Option, Some, None};\n-use rt::sched::Scheduler;\n+use option::Option;\n use rt::task::Task;\n use rt::local_ptr;\n \n@@ -46,82 +45,6 @@ impl Local<local_ptr::Borrowed<Task>> for Task {\n     }\n }\n \n-/// Encapsulates a temporarily-borrowed scheduler.\n-pub struct BorrowedScheduler {\n-    priv task: local_ptr::Borrowed<Task>,\n-}\n-\n-impl BorrowedScheduler {\n-    fn new(mut task: local_ptr::Borrowed<Task>) -> BorrowedScheduler {\n-        if task.get().sched.is_none() {\n-            rtabort!(\"no scheduler\")\n-        } else {\n-            BorrowedScheduler {\n-                task: task,\n-            }\n-        }\n-    }\n-\n-    #[inline]\n-    pub fn get<'a>(&'a mut self) -> &'a mut ~Scheduler {\n-        match self.task.get().sched {\n-            None => rtabort!(\"no scheduler\"),\n-            Some(ref mut sched) => sched,\n-        }\n-    }\n-}\n-\n-impl Local<BorrowedScheduler> for Scheduler {\n-    fn put(value: ~Scheduler) {\n-        let mut task = Local::borrow(None::<Task>);\n-        task.get().sched = Some(value);\n-    }\n-    #[inline]\n-    fn take() -> ~Scheduler {\n-        unsafe {\n-            // XXX: Unsafe for speed\n-            let task: *mut Task = Local::unsafe_borrow();\n-            (*task).sched.take_unwrap()\n-        }\n-    }\n-    fn exists(_: Option<Scheduler>) -> bool {\n-        let mut task = Local::borrow(None::<Task>);\n-        task.get().sched.is_some()\n-    }\n-    #[inline]\n-    fn borrow(_: Option<Scheduler>) -> BorrowedScheduler {\n-        BorrowedScheduler::new(Local::borrow(None::<Task>))\n-    }\n-    unsafe fn unsafe_take() -> ~Scheduler { rtabort!(\"unimpl\") }\n-    unsafe fn unsafe_borrow() -> *mut Scheduler {\n-        let task: *mut Task = Local::unsafe_borrow();\n-        match (*task).sched {\n-            Some(~ref mut sched) => {\n-                let s: *mut Scheduler = &mut *sched;\n-                return s;\n-            }\n-            None => {\n-                rtabort!(\"no scheduler\")\n-            }\n-        }\n-    }\n-    unsafe fn try_unsafe_borrow() -> Option<*mut Scheduler> {\n-        let task_opt: Option<*mut Task> = Local::try_unsafe_borrow();\n-        match task_opt {\n-            Some(task) => {\n-                match (*task).sched {\n-                    Some(~ref mut sched) => {\n-                        let s: *mut Scheduler = &mut *sched;\n-                        Some(s)\n-                    }\n-                    None => None\n-                }\n-            }\n-            None => None\n-        }\n-    }\n-}\n-\n #[cfg(test)]\n mod test {\n     use option::None;"}, {"sha": "d0c062c1274fef73b6ec1f339af1cb3b9774af4a", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 7, "deletions": 57, "changes": 64, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -57,36 +57,26 @@ Several modules in `core` are clients of `rt`:\n // XXX: this should not be here.\n #[allow(missing_doc)];\n \n+use any::Any;\n use clone::Clone;\n use container::Container;\n use iter::Iterator;\n-use option::{Option, None, Some};\n+use option::Option;\n use ptr::RawPtr;\n-use rt::local::Local;\n-use rt::sched::{Scheduler, Shutdown};\n-use rt::sleeper_list::SleeperList;\n-use task::TaskResult;\n-use rt::task::{Task, SchedTask, GreenTask, Sched};\n-use send_str::SendStrStatic;\n-use unstable::atomics::{AtomicInt, AtomicBool, SeqCst};\n-use unstable::sync::UnsafeArc;\n+use result::Result;\n+use task::TaskOpts;\n use vec::{OwnedVector, MutableVector, ImmutableVector};\n-use vec;\n \n-use self::thread::Thread;\n-\n-// the os module needs to reach into this helper, so allow general access\n-// through this reexport.\n-pub use self::util::set_exit_status;\n+use self::task::{Task, BlockedTask};\n \n // this is somewhat useful when a program wants to spawn a \"reasonable\" number\n // of workers based on the constraints of the system that it's running on.\n // Perhaps this shouldn't be a `pub use` though and there should be another\n // method...\n pub use self::util::default_sched_threads;\n \n-// Re-export of the functionality in the kill module\n-pub use self::kill::BlockedTask;\n+// Export unwinding facilities used by the failure macros\n+pub use self::unwind::{begin_unwind, begin_unwind_raw};\n \n // XXX: these probably shouldn't be public...\n #[doc(hidden)]\n@@ -99,49 +89,19 @@ pub mod shouldnt_be_public {\n // Internal macros used by the runtime.\n mod macros;\n \n-/// Basic implementation of an EventLoop, provides no I/O interfaces\n-mod basic;\n-\n /// The global (exchange) heap.\n pub mod global_heap;\n \n /// Implementations of language-critical runtime features like @.\n pub mod task;\n \n-/// Facilities related to task failure, killing, and death.\n-mod kill;\n-\n-/// The coroutine task scheduler, built on the `io` event loop.\n-pub mod sched;\n-\n /// The EventLoop and internal synchronous I/O interface.\n pub mod rtio;\n \n /// The Local trait for types that are accessible via thread-local\n /// or task-local storage.\n pub mod local;\n \n-/// A mostly lock-free multi-producer, single consumer queue.\n-pub mod mpsc_queue;\n-\n-/// A lock-free single-producer, single consumer queue.\n-pub mod spsc_queue;\n-\n-/// A lock-free multi-producer, multi-consumer bounded queue.\n-mod mpmc_bounded_queue;\n-\n-/// A parallel work-stealing deque\n-pub mod deque;\n-\n-/// A parallel data structure for tracking sleeping schedulers.\n-pub mod sleeper_list;\n-\n-/// Stack segments and caching.\n-pub mod stack;\n-\n-/// CPU context swapping.\n-mod context;\n-\n /// Bindings to system threading libraries.\n pub mod thread;\n \n@@ -157,16 +117,6 @@ pub mod logging;\n /// Crate map\n pub mod crate_map;\n \n-/// Tools for testing the runtime\n-pub mod test;\n-\n-/// Reference counting\n-pub mod rc;\n-\n-/// A simple single-threaded channel type for passing buffered data between\n-/// scheduler and task context\n-pub mod tube;\n-\n /// The runtime needs to be able to put a pointer into thread-local storage.\n mod local_ptr;\n "}, {"sha": "2699dab6d38a871586762b7f331092b32fbc2d6b", "filename": "src/libstd/rt/rc.rs", "status": "removed", "additions": 0, "deletions": 139, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frc.rs?ref=6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "patch": "@@ -1,139 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! An owned, task-local, reference counted type\n-//!\n-//! # Safety note\n-//!\n-//! XXX There is currently no type-system mechanism for enforcing that\n-//! reference counted types are both allocated on the exchange heap\n-//! and also non-sendable\n-//!\n-//! This doesn't prevent borrowing multiple aliasable mutable pointers\n-\n-use ops::Drop;\n-use clone::Clone;\n-use libc::c_void;\n-use cast;\n-\n-pub struct RC<T> {\n-    priv p: *c_void // ~(uint, T)\n-}\n-\n-impl<T> RC<T> {\n-    pub fn new(val: T) -> RC<T> {\n-        unsafe {\n-            let v = ~(1, val);\n-            let p: *c_void = cast::transmute(v);\n-            RC { p: p }\n-        }\n-    }\n-\n-    fn get_mut_state(&mut self) -> *mut (uint, T) {\n-        unsafe {\n-            let p: &mut ~(uint, T) = cast::transmute(&mut self.p);\n-            let p: *mut (uint, T) = &mut **p;\n-            return p;\n-        }\n-    }\n-\n-    fn get_state(&self) -> *(uint, T) {\n-        unsafe {\n-            let p: &~(uint, T) = cast::transmute(&self.p);\n-            let p: *(uint, T) = &**p;\n-            return p;\n-        }\n-    }\n-\n-    pub fn unsafe_borrow_mut(&mut self) -> *mut T {\n-        unsafe {\n-            match *self.get_mut_state() {\n-                (_, ref mut p) => {\n-                    let p: *mut T = p;\n-                    return p;\n-                }\n-            }\n-        }\n-    }\n-\n-    pub fn refcount(&self) -> uint {\n-        unsafe {\n-            match *self.get_state() {\n-                (count, _) => count\n-            }\n-        }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<T> Drop for RC<T> {\n-    fn drop(&mut self) {\n-        assert!(self.refcount() > 0);\n-\n-        unsafe {\n-            match *self.get_mut_state() {\n-                (ref mut count, _) => {\n-                    *count = *count - 1\n-                }\n-            }\n-\n-            if self.refcount() == 0 {\n-                let _: ~(uint, T) = cast::transmute(self.p);\n-            }\n-        }\n-    }\n-}\n-\n-impl<T> Clone for RC<T> {\n-    fn clone(&self) -> RC<T> {\n-        unsafe {\n-            // XXX: Mutable clone\n-            let this: &mut RC<T> = cast::transmute_mut(self);\n-\n-            match *this.get_mut_state() {\n-                (ref mut count, _) => {\n-                    *count = *count + 1;\n-                }\n-            }\n-        }\n-\n-        RC { p: self.p }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use super::RC;\n-\n-    #[test]\n-    fn smoke_test() {\n-        unsafe {\n-            let mut v1 = RC::new(100);\n-            assert!(*v1.unsafe_borrow_mut() == 100);\n-            assert!(v1.refcount() == 1);\n-\n-            let mut v2 = v1.clone();\n-            assert!(*v2.unsafe_borrow_mut() == 100);\n-            assert!(v2.refcount() == 2);\n-\n-            *v2.unsafe_borrow_mut() = 200;\n-            assert!(*v2.unsafe_borrow_mut() == 200);\n-            assert!(*v1.unsafe_borrow_mut() == 200);\n-\n-            let v3 = v2.clone();\n-            assert!(v3.refcount() == 3);\n-            {\n-                let _v1 = v1;\n-                let _v2 = v2;\n-            }\n-            assert!(v3.refcount() == 1);\n-        }\n-    }\n-}"}, {"sha": "c1c40cc6dff37132026c7a4a042a2c6d7d9eaad4", "filename": "src/libstd/rt/rtio.rs", "status": "modified", "additions": 7, "deletions": 4, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Frtio.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -14,14 +14,15 @@ use comm::{SharedChan, Port};\n use libc::c_int;\n use libc;\n use ops::Drop;\n-use option::*;\n+use option::{Option, Some, None};\n use path::Path;\n-use result::*;\n+use result::{Result, Ok, Err};\n+use rt::task::Task;\n+use rt::local::Local;\n \n use ai = io::net::addrinfo;\n+use io;\n use io::IoError;\n-use io::native::NATIVE_IO_FACTORY;\n-use io::native;\n use io::net::ip::{IpAddr, SocketAddr};\n use io::process::{ProcessConfig, ProcessExit};\n use io::signal::Signum;\n@@ -149,6 +150,8 @@ impl<'a> LocalIo<'a> {\n }\n \n pub trait IoFactory {\n+    fn id(&self) -> uint;\n+\n     // networking\n     fn tcp_connect(&mut self, addr: SocketAddr) -> Result<~RtioTcpStream, IoError>;\n     fn tcp_bind(&mut self, addr: SocketAddr) -> Result<~RtioTcpListener, IoError>;"}, {"sha": "7602d7b0564ab49025552bbae39666ac307cba36", "filename": "src/libstd/rt/task.rs", "status": "modified", "additions": 229, "deletions": 444, "changes": 673, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftask.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -13,29 +13,31 @@\n //! local storage, and logging. Even a 'freestanding' Rust would likely want\n //! to implement this.\n \n-use super::local_heap::LocalHeap;\n-\n-use prelude::*;\n-\n+use any::AnyOwnExt;\n use borrow;\n use cleanup;\n use io::Writer;\n use libc::{c_char, size_t};\n use local_data;\n+use ops::Drop;\n use option::{Option, Some, None};\n+use prelude::drop;\n+use result::{Result, Ok, Err};\n+use rt::Runtime;\n use rt::borrowck::BorrowRecord;\n use rt::borrowck;\n-use rt::context::Context;\n-use rt::env;\n-use rt::kill::Death;\n use rt::local::Local;\n+use rt::local_heap::LocalHeap;\n use rt::logging::StdErrLogger;\n-use rt::sched::{Scheduler, SchedHandle};\n-use rt::stack::{StackSegment, StackPool};\n+use rt::rtio::LocalIo;\n use rt::unwind::Unwinder;\n use send_str::SendStr;\n+use sync::arc::UnsafeArc;\n+use sync::atomics::{AtomicUint, SeqCst};\n+use task::{TaskResult, TaskOpts};\n use unstable::finally::Finally;\n-use unstable::mutex::Mutex;\n+\n+#[cfg(stage0)] pub use rt::unwind::begin_unwind;\n \n // The Task struct represents all state associated with a rust\n // task. There are at this point two primary \"subtypes\" of task,\n@@ -45,201 +47,89 @@ use unstable::mutex::Mutex;\n \n pub struct Task {\n     heap: LocalHeap,\n-    priv gc: GarbageCollector,\n+    gc: GarbageCollector,\n     storage: LocalStorage,\n-    logger: Option<StdErrLogger>,\n     unwinder: Unwinder,\n     death: Death,\n     destroyed: bool,\n     name: Option<SendStr>,\n-    coroutine: Option<Coroutine>,\n-    sched: Option<~Scheduler>,\n-    task_type: TaskType,\n     // Dynamic borrowck debugging info\n     borrow_list: Option<~[BorrowRecord]>,\n+\n+    logger: Option<StdErrLogger>,\n     stdout_handle: Option<~Writer>,\n \n-    // See the comments in the scheduler about why this is necessary\n-    nasty_deschedule_lock: Mutex,\n+    priv imp: Option<~Runtime>,\n }\n \n-pub enum TaskType {\n-    GreenTask(Option<SchedHome>),\n-    SchedTask\n-}\n+pub struct GarbageCollector;\n+pub struct LocalStorage(Option<local_data::Map>);\n \n-/// A coroutine is nothing more than a (register context, stack) pair.\n-pub struct Coroutine {\n-    /// The segment of stack on which the task is currently running or\n-    /// if the task is blocked, on which the task will resume\n-    /// execution.\n-    ///\n-    /// Servo needs this to be public in order to tell SpiderMonkey\n-    /// about the stack bounds.\n-    current_stack_segment: StackSegment,\n-    /// Always valid if the task is alive and not running.\n-    saved_context: Context\n+/// A handle to a blocked task. Usually this means having the ~Task pointer by\n+/// ownership, but if the task is killable, a killer can steal it at any time.\n+pub enum BlockedTask {\n+    Owned(~Task),\n+    Shared(UnsafeArc<AtomicUint>),\n }\n \n-/// Some tasks have a dedicated home scheduler that they must run on.\n-pub enum SchedHome {\n-    AnySched,\n-    Sched(SchedHandle)\n+/// Per-task state related to task death, killing, failure, etc.\n+pub struct Death {\n+    // Action to be done with the exit code. If set, also makes the task wait\n+    // until all its watched children exit before collecting the status.\n+    on_exit: Option<proc(TaskResult)>,\n }\n \n-pub struct GarbageCollector;\n-pub struct LocalStorage(Option<local_data::Map>);\n+pub struct BlockedTaskIterator {\n+    priv inner: UnsafeArc<AtomicUint>,\n+}\n \n impl Task {\n-\n-    // A helper to build a new task using the dynamically found\n-    // scheduler and task. Only works in GreenTask context.\n-    pub fn build_homed_child(stack_size: Option<uint>,\n-                             f: proc(),\n-                             home: SchedHome)\n-                             -> ~Task {\n-        let mut running_task = Local::borrow(None::<Task>);\n-        let mut sched = running_task.get().sched.take_unwrap();\n-        let new_task = ~running_task.get()\n-                                    .new_child_homed(&mut sched.stack_pool,\n-                                                     stack_size,\n-                                                     home,\n-                                                     f);\n-        running_task.get().sched = Some(sched);\n-        new_task\n-    }\n-\n-    pub fn build_child(stack_size: Option<uint>, f: proc()) -> ~Task {\n-        Task::build_homed_child(stack_size, f, AnySched)\n-    }\n-\n-    pub fn build_homed_root(stack_size: Option<uint>,\n-                            f: proc(),\n-                            home: SchedHome)\n-                            -> ~Task {\n-        let mut running_task = Local::borrow(None::<Task>);\n-        let mut sched = running_task.get().sched.take_unwrap();\n-        let new_task = ~Task::new_root_homed(&mut sched.stack_pool,\n-                                             stack_size,\n-                                             home,\n-                                             f);\n-        running_task.get().sched = Some(sched);\n-        new_task\n-    }\n-\n-    pub fn build_root(stack_size: Option<uint>, f: proc()) -> ~Task {\n-        Task::build_homed_root(stack_size, f, AnySched)\n-    }\n-\n-    pub fn new_sched_task() -> Task {\n-        Task {\n-            heap: LocalHeap::new(),\n-            gc: GarbageCollector,\n-            storage: LocalStorage(None),\n-            logger: None,\n-            unwinder: Unwinder { unwinding: false, cause: None },\n-            death: Death::new(),\n-            destroyed: false,\n-            coroutine: Some(Coroutine::empty()),\n-            name: None,\n-            sched: None,\n-            task_type: SchedTask,\n-            borrow_list: None,\n-            stdout_handle: None,\n-            nasty_deschedule_lock: unsafe { Mutex::new() },\n-        }\n-    }\n-\n-    pub fn new_root(stack_pool: &mut StackPool,\n-                    stack_size: Option<uint>,\n-                    start: proc()) -> Task {\n-        Task::new_root_homed(stack_pool, stack_size, AnySched, start)\n-    }\n-\n-    pub fn new_child(&mut self,\n-                     stack_pool: &mut StackPool,\n-                     stack_size: Option<uint>,\n-                     start: proc()) -> Task {\n-        self.new_child_homed(stack_pool, stack_size, AnySched, start)\n-    }\n-\n-    pub fn new_root_homed(stack_pool: &mut StackPool,\n-                          stack_size: Option<uint>,\n-                          home: SchedHome,\n-                          start: proc()) -> Task {\n+    pub fn new() -> Task {\n         Task {\n             heap: LocalHeap::new(),\n             gc: GarbageCollector,\n             storage: LocalStorage(None),\n-            logger: None,\n-            unwinder: Unwinder { unwinding: false, cause: None },\n+            unwinder: Unwinder::new(),\n             death: Death::new(),\n             destroyed: false,\n             name: None,\n-            coroutine: Some(Coroutine::new(stack_pool, stack_size, start)),\n-            sched: None,\n-            task_type: GreenTask(Some(home)),\n             borrow_list: None,\n-            stdout_handle: None,\n-            nasty_deschedule_lock: unsafe { Mutex::new() },\n-        }\n-    }\n-\n-    pub fn new_child_homed(&mut self,\n-                           stack_pool: &mut StackPool,\n-                           stack_size: Option<uint>,\n-                           home: SchedHome,\n-                           start: proc()) -> Task {\n-        Task {\n-            heap: LocalHeap::new(),\n-            gc: GarbageCollector,\n-            storage: LocalStorage(None),\n             logger: None,\n-            unwinder: Unwinder { unwinding: false, cause: None },\n-            death: Death::new(),\n-            destroyed: false,\n-            name: None,\n-            coroutine: Some(Coroutine::new(stack_pool, stack_size, start)),\n-            sched: None,\n-            task_type: GreenTask(Some(home)),\n-            borrow_list: None,\n             stdout_handle: None,\n-            nasty_deschedule_lock: unsafe { Mutex::new() },\n+            imp: None,\n         }\n     }\n \n-    pub fn give_home(&mut self, new_home: SchedHome) {\n-        match self.task_type {\n-            GreenTask(ref mut home) => {\n-                *home = Some(new_home);\n-            }\n-            SchedTask => {\n-                rtabort!(\"type error: used SchedTask as GreenTask\");\n-            }\n-        }\n-    }\n-\n-    pub fn take_unwrap_home(&mut self) -> SchedHome {\n-        match self.task_type {\n-            GreenTask(ref mut home) => {\n-                let out = home.take_unwrap();\n-                return out;\n-            }\n-            SchedTask => {\n-                rtabort!(\"type error: used SchedTask as GreenTask\");\n-            }\n-        }\n-    }\n-\n-    pub fn run(&mut self, f: ||) {\n-        rtdebug!(\"run called on task: {}\", borrow::to_uint(self));\n+    /// Executes the given closure as if it's running inside this task. The task\n+    /// is consumed upon entry, and the destroyed task is returned from this\n+    /// function in order for the caller to free. This function is guaranteed to\n+    /// not unwind because the closure specified is run inside of a `rust_try`\n+    /// block. (this is the only try/catch block in the world).\n+    ///\n+    /// This function is *not* meant to be abused as a \"try/catch\" block. This\n+    /// is meant to be used at the absolute boundaries of a task's lifetime, and\n+    /// only for that purpose.\n+    pub fn run(~self, f: ||) -> ~Task {\n+        // Need to put ourselves into TLS, but also need access to the unwinder.\n+        // Unsafely get a handle to the task so we can continue to use it after\n+        // putting it in tls (so we can invoke the unwinder).\n+        let handle: *mut Task = unsafe {\n+            *cast::transmute::<&~Task, &*mut Task>(&self)\n+        };\n+        Local::put(self);\n \n         // The only try/catch block in the world. Attempt to run the task's\n         // client-specified code and catch any failures.\n-        self.unwinder.try(|| {\n+        let try_block = || {\n \n             // Run the task main function, then do some cleanup.\n             f.finally(|| {\n+                fn flush(w: Option<~Writer>) {\n+                    match w {\n+                        Some(mut w) => { w.flush(); }\n+                        None => {}\n+                    }\n+                }\n \n                 // First, destroy task-local storage. This may run user dtors.\n                 //\n@@ -260,339 +150,225 @@ impl Task {\n                 // TLS, or possibly some destructors for those objects being\n                 // annihilated invoke TLS. Sadly these two operations seemed to\n                 // be intertwined, and miraculously work for now...\n-                self.storage.take();\n+                let mut task = Local::borrow(None::<Task>);\n+                let storage = task.get().storage.take();\n+                drop(task);\n+                drop(storage);\n \n                 // Destroy remaining boxes. Also may run user dtors.\n                 unsafe { cleanup::annihilate(); }\n \n                 // Finally flush and destroy any output handles which the task\n                 // owns. There are no boxes here, and no user destructors should\n                 // run after this any more.\n-                match self.stdout_handle.take() {\n-                    Some(handle) => {\n-                        let mut handle = handle;\n-                        handle.flush();\n-                    }\n-                    None => {}\n-                }\n-                self.logger.take();\n+                let mut task = Local::borrow(None::<Task>);\n+                let stdout = task.get().stdout_handle.take();\n+                let logger = task.get().logger.take();\n+                drop(task);\n+\n+                flush(stdout);\n+                drop(logger);\n             })\n-        });\n+        };\n+\n+        unsafe { (*handle).unwinder.try(try_block); }\n \n         // Cleanup the dynamic borrowck debugging info\n         borrowck::clear_task_borrow_list();\n \n-        self.death.collect_failure(self.unwinder.result());\n-        self.destroyed = true;\n+        let mut me: ~Task = Local::take();\n+        me.death.collect_failure(me.unwinder.result());\n+        me.destroyed = true;\n+        return me;\n     }\n \n-    // New utility functions for homes.\n+    /// Inserts a runtime object into this task, transferring ownership to the\n+    /// task. It is illegal to replace a previous runtime object in this task\n+    /// with this argument.\n+    pub fn put_runtime(&mut self, ops: ~Runtime) {\n+        assert!(self.imp.is_none());\n+        self.imp = Some(ops);\n+    }\n \n-    pub fn is_home_no_tls(&self, sched: &~Scheduler) -> bool {\n-        match self.task_type {\n-            GreenTask(Some(AnySched)) => { false }\n-            GreenTask(Some(Sched(SchedHandle { sched_id: ref id, .. }))) => {\n-                *id == sched.sched_id()\n-            }\n-            GreenTask(None) => {\n-                rtabort!(\"task without home\");\n-            }\n-            SchedTask => {\n-                // Awe yea\n-                rtabort!(\"type error: expected: GreenTask, found: SchedTask\");\n+    /// Attempts to extract the runtime as a specific type. If the runtime does\n+    /// not have the provided type, then the runtime is not removed. If the\n+    /// runtime does have the specified type, then it is removed and returned\n+    /// (transfer of ownership).\n+    ///\n+    /// It is recommended to only use this method when *absolutely necessary*.\n+    /// This function may not be available in the future.\n+    pub fn maybe_take_runtime<T: 'static>(&mut self) -> Option<~T> {\n+        // This is a terrible, terrible function. The general idea here is to\n+        // take the runtime, cast it to ~Any, check if it has the right type,\n+        // and then re-cast it back if necessary. The method of doing this is\n+        // pretty sketchy and involves shuffling vtables of trait objects\n+        // around, but it gets the job done.\n+        //\n+        // XXX: This function is a serious code smell and should be avoided at\n+        //      all costs. I have yet to think of a method to avoid this\n+        //      function, and I would be saddened if more usage of the function\n+        //      crops up.\n+        unsafe {\n+            let imp = self.imp.take_unwrap();\n+            let &(vtable, _): &(uint, uint) = cast::transmute(&imp);\n+            match imp.wrap().move::<T>() {\n+                Ok(t) => Some(t),\n+                Err(t) => {\n+                    let (_, obj): (uint, uint) = cast::transmute(t);\n+                    let obj: ~Runtime = cast::transmute((vtable, obj));\n+                    self.put_runtime(obj);\n+                    None\n+                }\n             }\n         }\n     }\n \n-    pub fn homed(&self) -> bool {\n-        match self.task_type {\n-            GreenTask(Some(AnySched)) => { false }\n-            GreenTask(Some(Sched(SchedHandle { .. }))) => { true }\n-            GreenTask(None) => {\n-                rtabort!(\"task without home\");\n-            }\n-            SchedTask => {\n-                rtabort!(\"type error: expected: GreenTask, found: SchedTask\");\n-            }\n-        }\n+    /// Spawns a sibling to this task. The newly spawned task is configured with\n+    /// the `opts` structure and will run `f` as the body of its code.\n+    pub fn spawn_sibling(mut ~self, opts: TaskOpts, f: proc()) {\n+        let ops = self.imp.take_unwrap();\n+        ops.spawn_sibling(self, opts, f)\n     }\n \n-    // Grab both the scheduler and the task from TLS and check if the\n-    // task is executing on an appropriate scheduler.\n-    pub fn on_appropriate_sched() -> bool {\n-        let mut task = Local::borrow(None::<Task>);\n-        let sched_id = task.get().sched.get_ref().sched_id();\n-        let sched_run_anything = task.get().sched.get_ref().run_anything;\n-        match task.get().task_type {\n-            GreenTask(Some(AnySched)) => {\n-                rtdebug!(\"anysched task in sched check ****\");\n-                sched_run_anything\n-            }\n-            GreenTask(Some(Sched(SchedHandle { sched_id: ref id, ..}))) => {\n-                rtdebug!(\"homed task in sched check ****\");\n-                *id == sched_id\n-            }\n-            GreenTask(None) => {\n-                rtabort!(\"task without home\");\n-            }\n-            SchedTask => {\n-                rtabort!(\"type error: expected: GreenTask, found: SchedTask\");\n-            }\n-        }\n+    /// Deschedules the current task, invoking `f` `amt` times. It is not\n+    /// recommended to use this function directly, but rather communication\n+    /// primitives in `std::comm` should be used.\n+    pub fn deschedule(mut ~self, amt: uint,\n+                      f: |BlockedTask| -> Result<(), BlockedTask>) {\n+        let ops = self.imp.take_unwrap();\n+        ops.deschedule(amt, self, f)\n+    }\n+\n+    /// Wakes up a previously blocked task, optionally specifiying whether the\n+    /// current task can accept a change in scheduling. This function can only\n+    /// be called on tasks that were previously blocked in `deschedule`.\n+    pub fn reawaken(mut ~self, can_resched: bool) {\n+        let ops = self.imp.take_unwrap();\n+        ops.reawaken(self, can_resched);\n+    }\n+\n+    /// Yields control of this task to another task. This function will\n+    /// eventually return, but possibly not immediately. This is used as an\n+    /// opportunity to allow other tasks a chance to run.\n+    pub fn yield_now(mut ~self) {\n+        let ops = self.imp.take_unwrap();\n+        ops.yield_now(self);\n+    }\n+\n+    /// Similar to `yield_now`, except that this function may immediately return\n+    /// without yielding (depending on what the runtime decides to do).\n+    pub fn maybe_yield(mut ~self) {\n+        let ops = self.imp.take_unwrap();\n+        ops.maybe_yield(self);\n+    }\n+\n+    /// Acquires a handle to the I/O factory that this task contains, normally\n+    /// stored in the task's runtime. This factory may not always be available,\n+    /// which is why the return type is `Option`\n+    pub fn local_io<'a>(&'a mut self) -> Option<LocalIo<'a>> {\n+        self.imp.get_mut_ref().local_io()\n     }\n }\n \n impl Drop for Task {\n     fn drop(&mut self) {\n         rtdebug!(\"called drop for a task: {}\", borrow::to_uint(self));\n         rtassert!(self.destroyed);\n-\n-        unsafe { self.nasty_deschedule_lock.destroy(); }\n     }\n }\n \n-// Coroutines represent nothing more than a context and a stack\n-// segment.\n-\n-impl Coroutine {\n-\n-    pub fn new(stack_pool: &mut StackPool,\n-               stack_size: Option<uint>,\n-               start: proc())\n-               -> Coroutine {\n-        let stack_size = match stack_size {\n-            Some(size) => size,\n-            None => env::min_stack()\n-        };\n-        let start = Coroutine::build_start_wrapper(start);\n-        let mut stack = stack_pool.take_segment(stack_size);\n-        let initial_context = Context::new(start, &mut stack);\n-        Coroutine {\n-            current_stack_segment: stack,\n-            saved_context: initial_context\n-        }\n+impl Iterator<BlockedTask> for BlockedTaskIterator {\n+    fn next(&mut self) -> Option<BlockedTask> {\n+        Some(Shared(self.inner.clone()))\n     }\n+}\n \n-    pub fn empty() -> Coroutine {\n-        Coroutine {\n-            current_stack_segment: StackSegment::new(0),\n-            saved_context: Context::empty()\n+impl BlockedTask {\n+    /// Returns Some if the task was successfully woken; None if already killed.\n+    pub fn wake(self) -> Option<~Task> {\n+        match self {\n+            Owned(task) => Some(task),\n+            Shared(arc) => unsafe {\n+                match (*arc.get()).swap(0, SeqCst) {\n+                    0 => None,\n+                    n => Some(cast::transmute(n)),\n+                }\n+            }\n         }\n     }\n \n-    fn build_start_wrapper(start: proc()) -> proc() {\n-        let wrapper: proc() = proc() {\n-            // First code after swap to this new context. Run our\n-            // cleanup job.\n-            unsafe {\n+    // This assertion has two flavours because the wake involves an atomic op.\n+    // In the faster version, destructors will fail dramatically instead.\n+    #[cfg(not(test))] pub fn trash(self) { }\n+    #[cfg(test)]      pub fn trash(self) { assert!(self.wake().is_none()); }\n \n-                // Again - might work while safe, or it might not.\n-                {\n-                    let mut sched = Local::borrow(None::<Scheduler>);\n-                    sched.get().run_cleanup_job();\n-                }\n+    /// Create a blocked task, unless the task was already killed.\n+    pub fn block(task: ~Task) -> BlockedTask {\n+        Owned(task)\n+    }\n \n-                // To call the run method on a task we need a direct\n-                // reference to it. The task is in TLS, so we can\n-                // simply unsafe_borrow it to get this reference. We\n-                // need to still have the task in TLS though, so we\n-                // need to unsafe_borrow.\n-                let task: *mut Task = Local::unsafe_borrow();\n-\n-                let mut start_cell = Some(start);\n-                (*task).run(|| {\n-                    // N.B. Removing `start` from the start wrapper\n-                    // closure by emptying a cell is critical for\n-                    // correctness. The ~Task pointer, and in turn the\n-                    // closure used to initialize the first call\n-                    // frame, is destroyed in the scheduler context,\n-                    // not task context. So any captured closures must\n-                    // not contain user-definable dtors that expect to\n-                    // be in task context. By moving `start` out of\n-                    // the closure, all the user code goes our of\n-                    // scope while the task is still running.\n-                    let start = start_cell.take_unwrap();\n-                    start();\n-                });\n+    /// Converts one blocked task handle to a list of many handles to the same.\n+    pub fn make_selectable(self, num_handles: uint) -> Take<BlockedTaskIterator>\n+    {\n+        let arc = match self {\n+            Owned(task) => {\n+                let flag = unsafe { AtomicUint::new(cast::transmute(task)) };\n+                UnsafeArc::new(flag)\n             }\n-\n-            // We remove the sched from the Task in TLS right now.\n-            let sched: ~Scheduler = Local::take();\n-            // ... allowing us to give it away when performing a\n-            // scheduling operation.\n-            sched.terminate_current_task()\n+            Shared(arc) => arc.clone(),\n         };\n-        return wrapper;\n+        BlockedTaskIterator{ inner: arc }.take(num_handles)\n     }\n \n-    /// Destroy coroutine and try to reuse stack segment.\n-    pub fn recycle(self, stack_pool: &mut StackPool) {\n+    /// Convert to an unsafe uint value. Useful for storing in a pipe's state\n+    /// flag.\n+    #[inline]\n+    pub unsafe fn cast_to_uint(self) -> uint {\n         match self {\n-            Coroutine { current_stack_segment, .. } => {\n-                stack_pool.give_segment(current_stack_segment);\n+            Owned(task) => {\n+                let blocked_task_ptr: uint = cast::transmute(task);\n+                rtassert!(blocked_task_ptr & 0x1 == 0);\n+                blocked_task_ptr\n+            }\n+            Shared(arc) => {\n+                let blocked_task_ptr: uint = cast::transmute(~arc);\n+                rtassert!(blocked_task_ptr & 0x1 == 0);\n+                blocked_task_ptr | 0x1\n             }\n         }\n     }\n \n-}\n-\n-/// This function is invoked from rust's current __morestack function. Segmented\n-/// stacks are currently not enabled as segmented stacks, but rather one giant\n-/// stack segment. This means that whenever we run out of stack, we want to\n-/// truly consider it to be stack overflow rather than allocating a new stack.\n-#[no_mangle]      // - this is called from C code\n-#[no_split_stack] // - it would be sad for this function to trigger __morestack\n-#[doc(hidden)]    // - Function must be `pub` to get exported, but it's\n-                  //   irrelevant for documentation purposes.\n-#[cfg(not(test))] // in testing, use the original libstd's version\n-pub extern \"C\" fn rust_stack_exhausted() {\n-    use rt::context;\n-    use rt::in_green_task_context;\n-    use rt::task::Task;\n-    use rt::local::Local;\n-    use unstable::intrinsics;\n-\n-    unsafe {\n-        // We're calling this function because the stack just ran out. We need\n-        // to call some other rust functions, but if we invoke the functions\n-        // right now it'll just trigger this handler being called again. In\n-        // order to alleviate this, we move the stack limit to be inside of the\n-        // red zone that was allocated for exactly this reason.\n-        let limit = context::get_sp_limit();\n-        context::record_sp_limit(limit - context::RED_ZONE / 2);\n-\n-        // This probably isn't the best course of action. Ideally one would want\n-        // to unwind the stack here instead of just aborting the entire process.\n-        // This is a tricky problem, however. There's a few things which need to\n-        // be considered:\n-        //\n-        //  1. We're here because of a stack overflow, yet unwinding will run\n-        //     destructors and hence arbitrary code. What if that code overflows\n-        //     the stack? One possibility is to use the above allocation of an\n-        //     extra 10k to hope that we don't hit the limit, and if we do then\n-        //     abort the whole program. Not the best, but kind of hard to deal\n-        //     with unless we want to switch stacks.\n-        //\n-        //  2. LLVM will optimize functions based on whether they can unwind or\n-        //     not. It will flag functions with 'nounwind' if it believes that\n-        //     the function cannot trigger unwinding, but if we do unwind on\n-        //     stack overflow then it means that we could unwind in any function\n-        //     anywhere. We would have to make sure that LLVM only places the\n-        //     nounwind flag on functions which don't call any other functions.\n-        //\n-        //  3. The function that overflowed may have owned arguments. These\n-        //     arguments need to have their destructors run, but we haven't even\n-        //     begun executing the function yet, so unwinding will not run the\n-        //     any landing pads for these functions. If this is ignored, then\n-        //     the arguments will just be leaked.\n-        //\n-        // Exactly what to do here is a very delicate topic, and is possibly\n-        // still up in the air for what exactly to do. Some relevant issues:\n-        //\n-        //  #3555 - out-of-stack failure leaks arguments\n-        //  #3695 - should there be a stack limit?\n-        //  #9855 - possible strategies which could be taken\n-        //  #9854 - unwinding on windows through __morestack has never worked\n-        //  #2361 - possible implementation of not using landing pads\n-\n-        if in_green_task_context() {\n-            let mut task = Local::borrow(None::<Task>);\n-            let n = task.get()\n-                        .name\n-                        .as_ref()\n-                        .map(|n| n.as_slice())\n-                        .unwrap_or(\"<unnamed>\");\n-\n-            // See the message below for why this is not emitted to the\n-            // task's logger. This has the additional conundrum of the\n-            // logger may not be initialized just yet, meaning that an FFI\n-            // call would happen to initialized it (calling out to libuv),\n-            // and the FFI call needs 2MB of stack when we just ran out.\n-            rterrln!(\"task '{}' has overflowed its stack\", n);\n+    /// Convert from an unsafe uint value. Useful for retrieving a pipe's state\n+    /// flag.\n+    #[inline]\n+    pub unsafe fn cast_from_uint(blocked_task_ptr: uint) -> BlockedTask {\n+        if blocked_task_ptr & 0x1 == 0 {\n+            Owned(cast::transmute(blocked_task_ptr))\n         } else {\n-            rterrln!(\"stack overflow in non-task context\");\n+            let ptr: ~UnsafeArc<AtomicUint> =\n+                cast::transmute(blocked_task_ptr & !1);\n+            Shared(*ptr)\n         }\n-\n-        intrinsics::abort();\n     }\n }\n \n-/// This is the entry point of unwinding for things like lang items and such.\n-/// The arguments are normally generated by the compiler, and need to\n-/// have static lifetimes.\n-pub fn begin_unwind_raw(msg: *c_char, file: *c_char, line: size_t) -> ! {\n-    use c_str::CString;\n-    use cast::transmute;\n+impl Death {\n+    pub fn new() -> Death {\n+        Death { on_exit: None, }\n+    }\n \n-    #[inline]\n-    fn static_char_ptr(p: *c_char) -> &'static str {\n-        let s = unsafe { CString::new(p, false) };\n-        match s.as_str() {\n-            Some(s) => unsafe { transmute::<&str, &'static str>(s) },\n-            None => rtabort!(\"message wasn't utf8?\")\n+    /// Collect failure exit codes from children and propagate them to a parent.\n+    pub fn collect_failure(&mut self, result: TaskResult) {\n+        match self.on_exit.take() {\n+            Some(f) => f(result),\n+            None => {}\n         }\n     }\n-\n-    let msg = static_char_ptr(msg);\n-    let file = static_char_ptr(file);\n-\n-    begin_unwind(msg, file, line as uint)\n }\n \n-/// This is the entry point of unwinding for fail!() and assert!().\n-pub fn begin_unwind<M: Any + Send>(msg: M, file: &'static str, line: uint) -> ! {\n-    use any::AnyRefExt;\n-    use rt::in_green_task_context;\n-    use rt::local::Local;\n-    use rt::task::Task;\n-    use str::Str;\n-    use unstable::intrinsics;\n-\n-    unsafe {\n-        let task: *mut Task;\n-        // Note that this should be the only allocation performed in this block.\n-        // Currently this means that fail!() on OOM will invoke this code path,\n-        // but then again we're not really ready for failing on OOM anyway. If\n-        // we do start doing this, then we should propagate this allocation to\n-        // be performed in the parent of this task instead of the task that's\n-        // failing.\n-        let msg = ~msg as ~Any;\n-\n-        {\n-            //let msg: &Any = msg;\n-            let msg_s = match msg.as_ref::<&'static str>() {\n-                Some(s) => *s,\n-                None => match msg.as_ref::<~str>() {\n-                    Some(s) => s.as_slice(),\n-                    None => \"~Any\",\n-                }\n-            };\n-\n-            if !in_green_task_context() {\n-                rterrln!(\"failed in non-task context at '{}', {}:{}\",\n-                         msg_s, file, line);\n-                intrinsics::abort();\n-            }\n-\n-            task = Local::unsafe_borrow();\n-            let n = (*task).name.as_ref().map(|n| n.as_slice()).unwrap_or(\"<unnamed>\");\n-\n-            // XXX: this should no get forcibly printed to the console, this should\n-            //      either be sent to the parent task (ideally), or get printed to\n-            //      the task's logger. Right now the logger is actually a uvio\n-            //      instance, which uses unkillable blocks internally for various\n-            //      reasons. This will cause serious trouble if the task is failing\n-            //      due to mismanagment of its own kill flag, so calling our own\n-            //      logger in its current state is a bit of a problem.\n-\n-            rterrln!(\"task '{}' failed at '{}', {}:{}\", n, msg_s, file, line);\n-\n-            if (*task).unwinder.unwinding {\n-                rtabort!(\"unwinding again\");\n-            }\n-        }\n-\n-        (*task).unwinder.begin_unwind(msg);\n+impl Drop for Death {\n+    fn drop(&mut self) {\n+        // make this type noncopyable\n     }\n }\n \n@@ -690,4 +466,13 @@ mod test {\n     #[test]\n     #[should_fail]\n     fn test_begin_unwind() { begin_unwind(\"cause\", file!(), line!()) }\n+\n+    // Task blocking tests\n+\n+    #[test]\n+    fn block_and_wake() {\n+        do with_test_task |task| {\n+            BlockedTask::block(task).wake().unwrap()\n+        }\n+    }\n }"}, {"sha": "0542c444a84e249d61d70a5c59508ca62c70d0f3", "filename": "src/libstd/rt/thread.rs", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fthread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Fthread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fthread.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -69,6 +69,12 @@ impl Thread<()> {\n     /// called, when the `Thread` falls out of scope its destructor will block\n     /// waiting for the OS thread.\n     pub fn start<T: Send>(main: proc() -> T) -> Thread<T> {\n+        Thread::start_stack(DEFAULT_STACK_SIZE, main)\n+    }\n+\n+    /// Performs the same functionality as `start`, but specifies an explicit\n+    /// stack size for the new thread.\n+    pub fn start_stack<T: Send>(stack: uint, main: proc() -> T) -> Thread<T> {\n \n         // We need the address of the packet to fill in to be stable so when\n         // `main` fills it in it's still valid, so allocate an extra ~ box to do"}, {"sha": "5e867bcdfbac6655649f871650f2d777365ea082", "filename": "src/libstd/rt/tube.rs", "status": "removed", "additions": 0, "deletions": 170, "changes": 170, "blob_url": "https://github.com/rust-lang/rust/blob/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Ftube.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Frt%2Ftube.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Ftube.rs?ref=6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "patch": "@@ -1,170 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! A very simple unsynchronized channel type for sending buffered data from\n-//! scheduler context to task context.\n-//!\n-//! XXX: This would be safer to use if split into two types like Port/Chan\n-\n-use option::*;\n-use clone::Clone;\n-use super::rc::RC;\n-use rt::sched::Scheduler;\n-use rt::kill::BlockedTask;\n-use rt::local::Local;\n-use vec::OwnedVector;\n-use container::Container;\n-\n-struct TubeState<T> {\n-    blocked_task: Option<BlockedTask>,\n-    buf: ~[T]\n-}\n-\n-pub struct Tube<T> {\n-    priv p: RC<TubeState<T>>\n-}\n-\n-impl<T> Tube<T> {\n-    pub fn new() -> Tube<T> {\n-        Tube {\n-            p: RC::new(TubeState {\n-                blocked_task: None,\n-                buf: ~[]\n-            })\n-        }\n-    }\n-\n-    pub fn send(&mut self, val: T) {\n-        rtdebug!(\"tube send\");\n-        unsafe {\n-            let state = self.p.unsafe_borrow_mut();\n-            (*state).buf.push(val);\n-\n-            if (*state).blocked_task.is_some() {\n-                // There's a waiting task. Wake it up\n-                rtdebug!(\"waking blocked tube\");\n-                let task = (*state).blocked_task.take_unwrap();\n-                let sched: ~Scheduler = Local::take();\n-                sched.resume_blocked_task_immediately(task);\n-            }\n-        }\n-    }\n-\n-    pub fn recv(&mut self) -> T {\n-        unsafe {\n-            let state = self.p.unsafe_borrow_mut();\n-            if !(*state).buf.is_empty() {\n-                return (*state).buf.shift();\n-            } else {\n-                // Block and wait for the next message\n-                rtdebug!(\"blocking on tube recv\");\n-                assert!(self.p.refcount() > 1); // There better be somebody to wake us up\n-                assert!((*state).blocked_task.is_none());\n-                let sched: ~Scheduler = Local::take();\n-                sched.deschedule_running_task_and_then(|_, task| {\n-                    (*state).blocked_task = Some(task);\n-                });\n-                rtdebug!(\"waking after tube recv\");\n-                let buf = &mut (*state).buf;\n-                assert!(!buf.is_empty());\n-                return buf.shift();\n-            }\n-        }\n-    }\n-}\n-\n-impl<T> Clone for Tube<T> {\n-    fn clone(&self) -> Tube<T> {\n-        Tube { p: self.p.clone() }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use rt::test::*;\n-    use rt::rtio::EventLoop;\n-    use rt::sched::Scheduler;\n-    use rt::local::Local;\n-    use super::*;\n-    use prelude::*;\n-\n-    #[test]\n-    fn simple_test() {\n-        do run_in_newsched_task {\n-            let mut tube: Tube<int> = Tube::new();\n-            let mut tube_clone = Some(tube.clone());\n-            let sched: ~Scheduler = Local::take();\n-            sched.deschedule_running_task_and_then(|sched, task| {\n-                let mut tube_clone = tube_clone.take_unwrap();\n-                tube_clone.send(1);\n-                sched.enqueue_blocked_task(task);\n-            });\n-\n-            assert!(tube.recv() == 1);\n-        }\n-    }\n-\n-    #[test]\n-    fn blocking_test() {\n-        do run_in_newsched_task {\n-            let mut tube: Tube<int> = Tube::new();\n-            let mut tube_clone = Some(tube.clone());\n-            let sched: ~Scheduler = Local::take();\n-            sched.deschedule_running_task_and_then(|sched, task| {\n-                let tube_clone = tube_clone.take_unwrap();\n-                do sched.event_loop.callback {\n-                    let mut tube_clone = tube_clone;\n-                    // The task should be blocked on this now and\n-                    // sending will wake it up.\n-                    tube_clone.send(1);\n-                }\n-                sched.enqueue_blocked_task(task);\n-            });\n-\n-            assert!(tube.recv() == 1);\n-        }\n-    }\n-\n-    #[test]\n-    fn many_blocking_test() {\n-        static MAX: int = 100;\n-\n-        do run_in_newsched_task {\n-            let mut tube: Tube<int> = Tube::new();\n-            let mut tube_clone = Some(tube.clone());\n-            let sched: ~Scheduler = Local::take();\n-            sched.deschedule_running_task_and_then(|sched, task| {\n-                callback_send(tube_clone.take_unwrap(), 0);\n-\n-                fn callback_send(tube: Tube<int>, i: int) {\n-                    if i == 100 {\n-                        return\n-                    }\n-\n-                    let mut sched = Local::borrow(None::<Scheduler>);\n-                    do sched.get().event_loop.callback {\n-                        let mut tube = tube;\n-                        // The task should be blocked on this now and\n-                        // sending will wake it up.\n-                        tube.send(i);\n-                        callback_send(tube, i + 1);\n-                    }\n-                }\n-\n-                sched.enqueue_blocked_task(task);\n-            });\n-\n-            for i in range(0, MAX) {\n-                let j = tube.recv();\n-                assert!(j == i);\n-            }\n-        }\n-    }\n-}"}, {"sha": "8248c6274ca1c2cb7e101bc32eddea5bd4a5d3ca", "filename": "src/libstd/rt/unwind.rs", "status": "modified", "additions": 71, "deletions": 1, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Funwind.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Funwind.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Funwind.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -8,7 +8,6 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-\n // Implementation of Rust stack unwinding\n //\n // For background on exception handling and stack unwinding please see \"Exception Handling in LLVM\"\n@@ -254,3 +253,74 @@ pub extern \"C\" fn rust_eh_personality_catch(version: c_int,\n         }\n     }\n }\n+\n+/// This is the entry point of unwinding for things like lang items and such.\n+/// The arguments are normally generated by the compiler, and need to\n+/// have static lifetimes.\n+pub fn begin_unwind_raw(msg: *c_char, file: *c_char, line: size_t) -> ! {\n+    #[inline]\n+    fn static_char_ptr(p: *c_char) -> &'static str {\n+        let s = unsafe { CString::new(p, false) };\n+        match s.as_str() {\n+            Some(s) => unsafe { cast::transmute::<&str, &'static str>(s) },\n+            None => rtabort!(\"message wasn't utf8?\")\n+        }\n+    }\n+\n+    let msg = static_char_ptr(msg);\n+    let file = static_char_ptr(file);\n+\n+    begin_unwind(msg, file, line as uint)\n+}\n+\n+/// This is the entry point of unwinding for fail!() and assert!().\n+pub fn begin_unwind<M: Any + Send>(msg: M, file: &'static str, line: uint) -> ! {\n+    unsafe {\n+        let task: *mut Task;\n+        // Note that this should be the only allocation performed in this block.\n+        // Currently this means that fail!() on OOM will invoke this code path,\n+        // but then again we're not really ready for failing on OOM anyway. If\n+        // we do start doing this, then we should propagate this allocation to\n+        // be performed in the parent of this task instead of the task that's\n+        // failing.\n+        let msg = ~msg as ~Any;\n+\n+        {\n+            let msg_s = match msg.as_ref::<&'static str>() {\n+                Some(s) => *s,\n+                None => match msg.as_ref::<~str>() {\n+                    Some(s) => s.as_slice(),\n+                    None => \"~Any\",\n+                }\n+            };\n+\n+            // It is assumed that all reasonable rust code will have a local\n+            // task at all times. This means that this `try_unsafe_borrow` will\n+            // succeed almost all of the time. There are border cases, however,\n+            // when the runtime has *almost* set up the local task, but hasn't\n+            // quite gotten there yet. In order to get some better diagnostics,\n+            // we print on failure and immediately abort the whole process if\n+            // there is no local task available.\n+            match Local::try_unsafe_borrow() {\n+                Some(t) => {\n+                    task = t;\n+                    let n = (*task).name.as_ref()\n+                                   .map(|n| n.as_slice()).unwrap_or(\"<unnamed>\");\n+\n+                    println!(\"task '{}' failed at '{}', {}:{}\", n, msg_s,\n+                             file, line);\n+                }\n+                None => {\n+                    println!(\"failed at '{}', {}:{}\", msg_s, file, line);\n+                    intrinsics::abort();\n+                }\n+            }\n+\n+            if (*task).unwinder.unwinding {\n+                rtabort!(\"unwinding again\");\n+            }\n+        }\n+\n+        (*task).unwinder.begin_unwind(msg);\n+    }\n+}"}, {"sha": "69c1da39abc85a1225b0cadc41f4f333abe08e84", "filename": "src/libstd/rt/util.rs", "status": "modified", "additions": 0, "deletions": 11, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frt%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Futil.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -15,7 +15,6 @@ use libc;\n use option::{Some, None, Option};\n use os;\n use str::StrSlice;\n-use unstable::atomics::{AtomicInt, INIT_ATOMIC_INT, SeqCst};\n use unstable::running_on_valgrind;\n \n // Indicates whether we should perform expensive sanity checks, including rtassert!\n@@ -144,13 +143,3 @@ memory and partly incapable of presentation to others.\",\n         unsafe { libc::abort() }\n     }\n }\n-\n-static mut EXIT_STATUS: AtomicInt = INIT_ATOMIC_INT;\n-\n-pub fn set_exit_status(code: int) {\n-    unsafe { EXIT_STATUS.store(code, SeqCst) }\n-}\n-\n-pub fn get_exit_status() -> int {\n-    unsafe { EXIT_STATUS.load(SeqCst) }\n-}"}, {"sha": "15c0986f899e9fd8e7c9209f5fb672a85689d081", "filename": "src/libstd/run.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frun.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Frun.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frun.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -338,8 +338,8 @@ mod tests {\n     use str;\n     use task::spawn;\n     use unstable::running_on_valgrind;\n-    use io::native::file;\n-    use io::{FileNotFound, Reader, Writer, io_error};\n+    use io::pipe::PipeStream;\n+    use io::{Writer, Reader, io_error, FileNotFound, OtherIoError};\n \n     #[test]\n     #[cfg(not(target_os=\"android\"))] // FIXME(#10380)\n@@ -426,13 +426,13 @@ mod tests {\n     }\n \n     fn writeclose(fd: c_int, s: &str) {\n-        let mut writer = file::FileDesc::new(fd, true);\n+        let mut writer = PipeStream::open(fd as int);\n         writer.write(s.as_bytes());\n     }\n \n     fn readclose(fd: c_int) -> ~str {\n         let mut res = ~[];\n-        let mut reader = file::FileDesc::new(fd, true);\n+        let mut reader = PipeStream::open(fd as int);\n         let mut buf = [0, ..1024];\n         loop {\n             match reader.read(buf) {"}, {"sha": "4632a3cf6e0f45daae912cc56069c4ce33239362", "filename": "src/libstd/task.rs", "status": "renamed", "additions": 17, "deletions": 71, "changes": 88, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -53,22 +53,21 @@\n \n #[allow(missing_doc)];\n \n-use prelude::*;\n-\n+use any::Any;\n use comm::{Chan, Port};\n+use kinds::Send;\n+use option::{None, Some, Option};\n use result::{Result, Ok, Err};\n-use rt::in_green_task_context;\n use rt::local::Local;\n+use rt::task::Task;\n use send_str::{SendStr, IntoSendStr};\n+use str::Str;\n use util;\n \n-#[cfg(test)] use any::Any;\n #[cfg(test)] use comm::SharedChan;\n #[cfg(test)] use ptr;\n #[cfg(test)] use result;\n \n-pub mod spawn;\n-\n /// Indicates the manner in which a task exited.\n ///\n /// A task that completes without failing is considered to exit successfully.\n@@ -80,27 +79,6 @@ pub mod spawn;\n /// children tasks complete, recommend using a result future.\n pub type TaskResult = Result<(), ~Any>;\n \n-/// Scheduler modes\n-#[deriving(Eq)]\n-pub enum SchedMode {\n-    /// Run task on the default scheduler\n-    DefaultScheduler,\n-    /// All tasks run in the same OS thread\n-    SingleThreaded,\n-}\n-\n-/**\n- * Scheduler configuration options\n- *\n- * # Fields\n- *\n- * * sched_mode - The operating mode of the scheduler\n- *\n- */\n-pub struct SchedOpts {\n-    priv mode: SchedMode,\n-}\n-\n /**\n  * Task configuration options\n  *\n@@ -121,10 +99,9 @@ pub struct SchedOpts {\n  *           scheduler other tasks will be impeded or even blocked indefinitely.\n  */\n pub struct TaskOpts {\n-    priv watched: bool,\n-    priv notify_chan: Option<Chan<TaskResult>>,\n+    watched: bool,\n+    notify_chan: Option<Chan<TaskResult>>,\n     name: Option<SendStr>,\n-    sched: SchedOpts,\n     stack_size: Option<uint>\n }\n \n@@ -169,7 +146,6 @@ impl TaskBuilder {\n                 watched: self.opts.watched,\n                 notify_chan: notify_chan,\n                 name: name,\n-                sched: self.opts.sched,\n                 stack_size: self.opts.stack_size\n             },\n             gen_body: gen_body,\n@@ -229,11 +205,6 @@ impl TaskBuilder {\n         self.opts.name = Some(name.into_send_str());\n     }\n \n-    /// Configure a custom scheduler mode for the task.\n-    pub fn sched_mode(&mut self, mode: SchedMode) {\n-        self.opts.sched.mode = mode;\n-    }\n-\n     /**\n      * Add a wrapper to the body of the spawned task.\n      *\n@@ -285,7 +256,6 @@ impl TaskBuilder {\n             watched: x.opts.watched,\n             notify_chan: notify_chan,\n             name: name,\n-            sched: x.opts.sched,\n             stack_size: x.opts.stack_size\n         };\n         let f = match gen_body {\n@@ -296,7 +266,9 @@ impl TaskBuilder {\n                 f\n             }\n         };\n-        spawn::spawn_raw(opts, f);\n+\n+        let t: ~Task = Local::take();\n+        t.spawn_sibling(opts, f);\n     }\n \n     /**\n@@ -343,9 +315,6 @@ pub fn default_task_opts() -> TaskOpts {\n         watched: true,\n         notify_chan: None,\n         name: None,\n-        sched: SchedOpts {\n-            mode: DefaultScheduler,\n-        },\n         stack_size: None\n     }\n }\n@@ -363,24 +332,6 @@ pub fn spawn(f: proc()) {\n     task.spawn(f)\n }\n \n-pub fn spawn_sched(mode: SchedMode, f: proc()) {\n-    /*!\n-     * Creates a new task on a new or existing scheduler.\n-     *\n-     * When there are no more tasks to execute the\n-     * scheduler terminates.\n-     *\n-     * # Failure\n-     *\n-     * In manual threads mode the number of threads requested must be\n-     * greater than zero.\n-     */\n-\n-    let mut task = task();\n-    task.sched_mode(mode);\n-    task.spawn(f)\n-}\n-\n pub fn try<T:Send>(f: proc() -> T) -> Result<T, ~Any> {\n     /*!\n      * Execute a function in another task and return either the return value\n@@ -400,26 +351,21 @@ pub fn try<T:Send>(f: proc() -> T) -> Result<T, ~Any> {\n pub fn with_task_name<U>(blk: |Option<&str>| -> U) -> U {\n     use rt::task::Task;\n \n-    if in_green_task_context() {\n-        let mut task = Local::borrow(None::<Task>);\n-        match task.get().name {\n-            Some(ref name) => blk(Some(name.as_slice())),\n-            None => blk(None)\n-        }\n-    } else {\n-        fail!(\"no task name exists in non-green task context\")\n+    let mut task = Local::borrow(None::<Task>);\n+    match task.get().name {\n+        Some(ref name) => blk(Some(name.as_slice())),\n+        None => blk(None)\n     }\n }\n \n pub fn deschedule() {\n     //! Yield control to the task scheduler\n \n     use rt::local::Local;\n-    use rt::sched::Scheduler;\n \n     // FIXME(#7544): Optimize this, since we know we won't block.\n-    let sched: ~Scheduler = Local::take();\n-    sched.yield_now();\n+    let task: ~Task = Local::take();\n+    task.yield_now();\n }\n \n pub fn failing() -> bool {\n@@ -428,7 +374,7 @@ pub fn failing() -> bool {\n     use rt::task::Task;\n \n     let mut local = Local::borrow(None::<Task>);\n-    local.get().unwinder.unwinding\n+    local.get().unwinder.unwinding()\n }\n \n // The following 8 tests test the following 2^3 combinations:", "previous_filename": "src/libstd/task/mod.rs"}, {"sha": "1148774020a14b083f73d6b5d5e3064ff7061312", "filename": "src/libstd/task/spawn.rs", "status": "removed", "additions": 0, "deletions": 233, "changes": 233, "blob_url": "https://github.com/rust-lang/rust/blob/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Ftask%2Fspawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a/src%2Flibstd%2Ftask%2Fspawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask%2Fspawn.rs?ref=6aadc9d18856f8e7ea8038e2c4b2ba0f9507e26a", "patch": "@@ -1,233 +0,0 @@\n-// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-/*!**************************************************************************\n- *\n- * WARNING: linked failure has been removed since this doc comment was written,\n- *          but it was so pretty that I didn't want to remove it.\n- *\n- * Spawning & linked failure\n- *\n- * Several data structures are involved in task management to allow properly\n- * propagating failure across linked/supervised tasks.\n- *\n- * (1) The \"taskgroup_arc\" is an unsafe::exclusive which contains a hashset of\n- *     all tasks that are part of the group. Some tasks are 'members', which\n- *     means if they fail, they will kill everybody else in the taskgroup.\n- *     Other tasks are 'descendants', which means they will not kill tasks\n- *     from this group, but can be killed by failing members.\n- *\n- *     A new one of these is created each spawn_linked or spawn_supervised.\n- *\n- * (2) The \"taskgroup\" is a per-task control structure that tracks a task's\n- *     spawn configuration. It contains a reference to its taskgroup_arc, a\n- *     reference to its node in the ancestor list (below), and an optionally\n- *     configured notification port. These are stored in TLS.\n- *\n- * (3) The \"ancestor_list\" is a cons-style list of unsafe::exclusives which\n- *     tracks 'generations' of taskgroups -- a group's ancestors are groups\n- *     which (directly or transitively) spawn_supervised-ed them. Each task\n- *     is recorded in the 'descendants' of each of its ancestor groups.\n- *\n- *     Spawning a supervised task is O(n) in the number of generations still\n- *     alive, and exiting (by success or failure) that task is also O(n).\n- *\n- * This diagram depicts the references between these data structures:\n- *\n- *          linked_________________________________\n- *        ___/                   _________         \\___\n- *       /   \\                  | group X |        /   \\\n- *      (  A  ) - - - - - - - > | {A,B} {}|< - - -(  B  )\n- *       \\___/                  |_________|        \\___/\n- *      unlinked\n- *         |      __ (nil)\n- *         |      //|                         The following code causes this:\n- *         |__   //   /\\         _________\n- *        /   \\ //    ||        | group Y |     fn taskA() {\n- *       (  C  )- - - ||- - - > |{C} {D,E}|         spawn(taskB);\n- *        \\___/      /  \\=====> |_________|         spawn_unlinked(taskC);\n- *      supervise   /gen \\                          ...\n- *         |    __  \\ 00 /                      }\n- *         |    //|  \\__/                       fn taskB() { ... }\n- *         |__ //     /\\         _________      fn taskC() {\n- *        /   \\/      ||        | group Z |         spawn_supervised(taskD);\n- *       (  D  )- - - ||- - - > | {D} {E} |         ...\n- *        \\___/      /  \\=====> |_________|     }\n- *      supervise   /gen \\                      fn taskD() {\n- *         |    __  \\ 01 /                          spawn_supervised(taskE);\n- *         |    //|  \\__/                           ...\n- *         |__ //                _________      }\n- *        /   \\/                | group W |     fn taskE() { ... }\n- *       (  E  )- - - - - - - > | {E}  {} |\n- *        \\___/                 |_________|\n- *\n- *        \"tcb\"               \"taskgroup_arc\"\n- *             \"ancestor_list\"\n- *\n- ****************************************************************************/\n-\n-#[doc(hidden)];\n-\n-use prelude::*;\n-\n-use comm::Chan;\n-use rt::local::Local;\n-use rt::sched::{Scheduler, Shutdown, TaskFromFriend};\n-use rt::task::{Task, Sched};\n-use rt::thread::Thread;\n-use rt::{in_green_task_context, new_event_loop};\n-use task::{SingleThreaded, TaskOpts, TaskResult};\n-\n-#[cfg(test)] use task::default_task_opts;\n-#[cfg(test)] use task;\n-\n-pub fn spawn_raw(mut opts: TaskOpts, f: proc()) {\n-    assert!(in_green_task_context());\n-\n-    let mut task = if opts.sched.mode != SingleThreaded {\n-        if opts.watched {\n-            Task::build_child(opts.stack_size, f)\n-        } else {\n-            Task::build_root(opts.stack_size, f)\n-        }\n-    } else {\n-        unsafe {\n-            // Creating a 1:1 task:thread ...\n-            let sched: *mut Scheduler = Local::unsafe_borrow();\n-            let sched_handle = (*sched).make_handle();\n-\n-            // Since this is a 1:1 scheduler we create a queue not in\n-            // the stealee set. The run_anything flag is set false\n-            // which will disable stealing.\n-            let (worker, _stealer) = (*sched).work_queue.pool().deque();\n-\n-            // Create a new scheduler to hold the new task\n-            let mut new_sched = ~Scheduler::new_special(new_event_loop(),\n-                                                        worker,\n-                                                        (*sched).work_queues.clone(),\n-                                                        (*sched).sleeper_list.clone(),\n-                                                        false,\n-                                                        Some(sched_handle));\n-            let mut new_sched_handle = new_sched.make_handle();\n-\n-            // Allow the scheduler to exit when the pinned task exits\n-            new_sched_handle.send(Shutdown);\n-\n-            // Pin the new task to the new scheduler\n-            let new_task = if opts.watched {\n-                Task::build_homed_child(opts.stack_size, f, Sched(new_sched_handle))\n-            } else {\n-                Task::build_homed_root(opts.stack_size, f, Sched(new_sched_handle))\n-            };\n-\n-            // Create a task that will later be used to join with the new scheduler\n-            // thread when it is ready to terminate\n-            let (thread_port, thread_chan) = Chan::new();\n-            let join_task = do Task::build_child(None) {\n-                debug!(\"running join task\");\n-                let thread: Thread<()> = thread_port.recv();\n-                thread.join();\n-            };\n-\n-            // Put the scheduler into another thread\n-            let orig_sched_handle = (*sched).make_handle();\n-\n-            let new_sched = new_sched;\n-            let thread = do Thread::start {\n-                let mut new_sched = new_sched;\n-                let mut orig_sched_handle = orig_sched_handle;\n-\n-                let bootstrap_task = ~do Task::new_root(&mut new_sched.stack_pool, None) || {\n-                    debug!(\"boostrapping a 1:1 scheduler\");\n-                };\n-                new_sched.bootstrap(bootstrap_task);\n-\n-                // Now tell the original scheduler to join with this thread\n-                // by scheduling a thread-joining task on the original scheduler\n-                orig_sched_handle.send(TaskFromFriend(join_task));\n-\n-                // NB: We can't simply send a message from here to another task\n-                // because this code isn't running in a task and message passing doesn't\n-                // work outside of tasks. Hence we're sending a scheduler message\n-                // to execute a new task directly to a scheduler.\n-            };\n-\n-            // Give the thread handle to the join task\n-            thread_chan.send(thread);\n-\n-            // When this task is enqueued on the current scheduler it will then get\n-            // forwarded to the scheduler to which it is pinned\n-            new_task\n-        }\n-    };\n-\n-    if opts.notify_chan.is_some() {\n-        let notify_chan = opts.notify_chan.take_unwrap();\n-        let on_exit: proc(TaskResult) = proc(task_result) {\n-            notify_chan.try_send(task_result);\n-        };\n-        task.death.on_exit = Some(on_exit);\n-    }\n-\n-    task.name = opts.name.take();\n-    debug!(\"spawn calling run_task\");\n-    Scheduler::run_task(task);\n-\n-}\n-\n-#[test]\n-fn test_spawn_raw_simple() {\n-    let (po, ch) = Chan::new();\n-    do spawn_raw(default_task_opts()) {\n-        ch.send(());\n-    }\n-    po.recv();\n-}\n-\n-#[test]\n-fn test_spawn_raw_unsupervise() {\n-    let opts = task::TaskOpts {\n-        watched: false,\n-        notify_chan: None,\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) {\n-        fail!();\n-    }\n-}\n-\n-#[test]\n-fn test_spawn_raw_notify_success() {\n-    let (notify_po, notify_ch) = Chan::new();\n-\n-    let opts = task::TaskOpts {\n-        notify_chan: Some(notify_ch),\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) {\n-    }\n-    assert!(notify_po.recv().is_ok());\n-}\n-\n-#[test]\n-fn test_spawn_raw_notify_failure() {\n-    // New bindings for these\n-    let (notify_po, notify_ch) = Chan::new();\n-\n-    let opts = task::TaskOpts {\n-        watched: false,\n-        notify_chan: Some(notify_ch),\n-        .. default_task_opts()\n-    };\n-    do spawn_raw(opts) {\n-        fail!();\n-    }\n-    assert!(notify_po.recv().is_err());\n-}"}, {"sha": "e7e8cec9d5f178e8584969a8af511c3711eea91e", "filename": "src/libstd/unstable/lang.rs", "status": "modified", "additions": 1, "deletions": 15, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Funstable%2Flang.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Funstable%2Flang.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Flang.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -11,15 +11,13 @@\n //! Runtime calls emitted by the compiler.\n \n use c_str::ToCStr;\n-use cast::transmute;\n use libc::{c_char, size_t, uintptr_t};\n-use rt::task;\n use rt::borrowck;\n \n #[cold]\n #[lang=\"fail_\"]\n pub fn fail_(expr: *c_char, file: *c_char, line: size_t) -> ! {\n-    task::begin_unwind_raw(expr, file, line);\n+    ::rt::begin_unwind_raw(expr, file, line);\n }\n \n #[cold]\n@@ -81,15 +79,3 @@ pub unsafe fn check_not_borrowed(a: *u8,\n                                  line: size_t) {\n     borrowck::check_not_borrowed(a, file, line)\n }\n-\n-#[lang=\"start\"]\n-pub fn start(main: *u8, argc: int, argv: **c_char) -> int {\n-    use rt;\n-\n-    unsafe {\n-        return do rt::start(argc, argv as **u8) {\n-            let main: extern \"Rust\" fn() = transmute(main);\n-            main();\n-        };\n-    }\n-}"}, {"sha": "f4573785996c437e668ce3615349c0c68f15ecfb", "filename": "src/libstd/unstable/mod.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Funstable%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibstd%2Funstable%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funstable%2Fmod.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -23,6 +23,7 @@ pub mod lang;\n pub mod sync;\n pub mod mutex;\n pub mod raw;\n+pub mod stack;\n \n /**\n "}, {"sha": "2c2669e914cca9cce3d4cc2d3e578389e5092961", "filename": "src/libsyntax/ext/expand.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibsyntax%2Fext%2Fexpand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/51abdee5f1ad932671350fdd8a7911fe144d08b8/src%2Flibsyntax%2Fext%2Fexpand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Fexpand.rs?ref=51abdee5f1ad932671350fdd8a7911fe144d08b8", "patch": "@@ -740,10 +740,10 @@ pub fn std_macros() -> @str {\n             fail!(\"explicit failure\")\n         );\n         ($msg:expr) => (\n-            ::std::rt::task::begin_unwind($msg, file!(), line!())\n+            ::std::rt::begin_unwind($msg, file!(), line!())\n         );\n         ($fmt:expr, $($arg:tt)*) => (\n-            ::std::rt::task::begin_unwind(format!($fmt, $($arg)*), file!(), line!())\n+            ::std::rt::begin_unwind(format!($fmt, $($arg)*), file!(), line!())\n         )\n     )\n "}]}