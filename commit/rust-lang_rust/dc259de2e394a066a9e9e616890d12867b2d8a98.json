{"sha": "dc259de2e394a066a9e9e616890d12867b2d8a98", "node_id": "MDY6Q29tbWl0NzI0NzEyOmRjMjU5ZGUyZTM5NGEwNjZhOWU5ZTYxNjg5MGQxMjg2N2IyZDhhOTg=", "commit": {"author": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-07-19T22:50:34Z"}, "committer": {"name": "cgswords", "email": "cameronswords@gmail.com", "date": "2016-08-01T17:42:22Z"}, "message": "Reimplemented tokenstreams as ropes and reduced the exposed TokenStream API.", "tree": {"sha": "4e160e93df38ba952d80f6aeb10bbb322e5900b6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4e160e93df38ba952d80f6aeb10bbb322e5900b6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/dc259de2e394a066a9e9e616890d12867b2d8a98", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/dc259de2e394a066a9e9e616890d12867b2d8a98", "html_url": "https://github.com/rust-lang/rust/commit/dc259de2e394a066a9e9e616890d12867b2d8a98", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/dc259de2e394a066a9e9e616890d12867b2d8a98/comments", "author": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "committer": {"login": "cgswords", "id": 1130991, "node_id": "MDQ6VXNlcjExMzA5OTE=", "avatar_url": "https://avatars.githubusercontent.com/u/1130991?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cgswords", "html_url": "https://github.com/cgswords", "followers_url": "https://api.github.com/users/cgswords/followers", "following_url": "https://api.github.com/users/cgswords/following{/other_user}", "gists_url": "https://api.github.com/users/cgswords/gists{/gist_id}", "starred_url": "https://api.github.com/users/cgswords/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cgswords/subscriptions", "organizations_url": "https://api.github.com/users/cgswords/orgs", "repos_url": "https://api.github.com/users/cgswords/repos", "events_url": "https://api.github.com/users/cgswords/events{/privacy}", "received_events_url": "https://api.github.com/users/cgswords/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "5a7773a18098be712d7e1ce4fded36aed8c3c311", "url": "https://api.github.com/repos/rust-lang/rust/commits/5a7773a18098be712d7e1ce4fded36aed8c3c311", "html_url": "https://github.com/rust-lang/rust/commit/5a7773a18098be712d7e1ce4fded36aed8c3c311"}], "stats": {"total": 984, "additions": 374, "deletions": 610}, "files": [{"sha": "b176b8fefc612c718639bbc1ada2fe8ef0ab88a1", "filename": "src/libsyntax/codemap.rs", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Fcodemap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Fcodemap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fcodemap.rs?ref=dc259de2e394a066a9e9e616890d12867b2d8a98", "patch": "@@ -71,6 +71,23 @@ pub fn dummy_spanned<T>(t: T) -> Spanned<T> {\n     respan(DUMMY_SP, t)\n }\n \n+/// Build a span that covers the two provided spans.\n+pub fn combine_spans(sp1: Span, sp2: Span) -> Span {\n+    if sp1 == DUMMY_SP && sp2 == DUMMY_SP {\n+        DUMMY_SP\n+    } else if sp1 == DUMMY_SP {\n+        sp2\n+    } else if sp2 == DUMMY_SP {\n+        sp1\n+    } else {\n+        Span {\n+            lo: if sp1.lo < sp2.lo { sp1.lo } else { sp2.lo },\n+            hi: if sp1.hi > sp2.hi { sp1.hi } else { sp2.hi },\n+            expn_id: if sp1.expn_id == sp2.expn_id { sp1.expn_id } else { NO_EXPANSION },\n+        }\n+    }\n+}\n+\n #[derive(Clone, Hash, Debug)]\n pub struct NameAndSpan {\n     /// The format with which the macro was invoked."}, {"sha": "7b28952aff6b6576b740ab809ed75fd1a15e77a6", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=dc259de2e394a066a9e9e616890d12867b2d8a98", "patch": "@@ -237,7 +237,7 @@ pub fn new_parser_from_ts<'a>(sess: &'a ParseSess,\n                               cfg: ast::CrateConfig,\n                               ts: tokenstream::TokenStream)\n                               -> Parser<'a> {\n-    tts_to_parser(sess, ts.tts, cfg)\n+    tts_to_parser(sess, ts.to_tts(), cfg)\n }\n \n "}, {"sha": "89ead21cc10cb2fda48f0f88258cee98e759244a", "filename": "src/libsyntax/tokenstream.rs", "status": "modified", "additions": 356, "deletions": 609, "changes": 965, "blob_url": "https://github.com/rust-lang/rust/blob/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/dc259de2e394a066a9e9e616890d12867b2d8a98/src%2Flibsyntax%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Ftokenstream.rs?ref=dc259de2e394a066a9e9e616890d12867b2d8a98", "patch": "@@ -16,27 +16,27 @@\n //! or a SequenceRepetition specifier (for the purpose of sequence generation during macro\n //! expansion).\n //!\n-//! A TokenStream also has a slice view, `TokenSlice`, that is analogous to `str` for\n-//! `String`: it allows the programmer to divvy up, explore, and otherwise partition a\n-//! TokenStream as borrowed subsequences.\n+//! ## Ownership\n+//! TokenStreams are persistant data structures construced as ropes with reference\n+//! counted-children. In general, this means that calling an operation on a TokenStream\n+//! (such as `slice`) produces an entirely new TokenStream from the borrowed reference to\n+//! the original. This essentially coerces TokenStreams into 'views' of their subparts,\n+//! and a borrowed TokenStream is sufficient to build an owned TokenStream without taking\n+//! ownership of the original.\n \n use ast::{self, AttrStyle, LitKind};\n use syntax_pos::{Span, DUMMY_SP, NO_EXPANSION};\n-use codemap::Spanned;\n+use codemap::{Spanned, combine_spans};\n use ext::base;\n use ext::tt::macro_parser;\n use parse::lexer::comments::{doc_comment_style, strip_doc_comment_decoration};\n use parse::lexer;\n use parse;\n-use parse::token::{self, Token, Lit, InternedString, Nonterminal};\n-use parse::token::Lit as TokLit;\n+use parse::token::{self, Token, Lit, Nonterminal};\n \n use std::fmt;\n-use std::mem;\n-use std::ops::Index;\n-use std::ops;\n use std::iter::*;\n-\n+use std::ops::{self, Index};\n use std::rc::Rc;\n \n /// A delimited sequence of token trees\n@@ -335,35 +335,59 @@ impl TokenTree {\n /// struct itself shouldn't be directly manipulated; the internal structure is not stable,\n /// and may be changed at any time in the future. The operators will not, however (except\n /// for signatures, later on).\n-#[derive(Eq,Clone,Hash,RustcEncodable,RustcDecodable)]\n+#[derive(Clone, Eq, Hash, RustcEncodable, RustcDecodable)]\n pub struct TokenStream {\n-    pub span: Span,\n-    pub tts: Vec<TokenTree>,\n+    ts: InternalTS,\n+}\n+\n+// NB If Leaf access proves to be slow, inroducing a secondary Leaf without the bounds\n+// for unsliced Leafs may lead to some performance improvemenet.\n+#[derive(Clone, PartialEq, Eq, Hash, RustcEncodable, RustcDecodable)]\n+pub enum InternalTS {\n+    Empty(Span),\n+    Leaf {\n+        tts: Rc<Vec<TokenTree>>,\n+        offset: usize,\n+        len: usize,\n+        sp: Span,\n+    },\n+    Node {\n+        left: Rc<InternalTS>,\n+        right: Rc<InternalTS>,\n+        len: usize,\n+        sp: Span,\n+    },\n }\n \n impl fmt::Debug for TokenStream {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n-        if self.tts.len() == 0 {\n-            write!(f, \"([empty\")?;\n-        } else {\n-            write!(f, \"([\")?;\n-            write!(f, \"{:?}\", self.tts[0])?;\n-\n-            for tt in self.tts.iter().skip(1) {\n-                write!(f, \",{:?}\", tt)?;\n+        self.ts.fmt(f)\n+    }\n+}\n+\n+impl fmt::Debug for InternalTS {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        match *self {\n+            InternalTS::Empty(..) => Ok(()),\n+            InternalTS::Leaf { ref tts, offset, len, .. } => {\n+                for t in tts.iter().skip(offset).take(len) {\n+                    try!(write!(f, \"{:?}\", t));\n+                }\n+                Ok(())\n+            }\n+            InternalTS::Node { ref left, ref right, .. } => {\n+                try!(left.fmt(f));\n+                right.fmt(f)\n             }\n         }\n-        write!(f, \"|\")?;\n-        self.span.fmt(f)?;\n-        write!(f, \"])\")\n     }\n }\n \n /// Checks if two TokenStreams are equivalent (including spans). For unspanned\n /// equality, see `eq_unspanned`.\n impl PartialEq<TokenStream> for TokenStream {\n     fn eq(&self, other: &TokenStream) -> bool {\n-        self.tts == other.tts\n+        self.iter().eq(other.iter())\n     }\n }\n \n@@ -408,6 +432,59 @@ fn covering_span(trees: &[TokenTree]) -> Span {\n     }\n }\n \n+impl InternalTS {\n+    fn len(&self) -> usize {\n+        match *self {\n+            InternalTS::Empty(..) => 0,\n+            InternalTS::Leaf { len, .. } => len,\n+            InternalTS::Node { len, .. } => len,\n+        }\n+    }\n+\n+    fn span(&self) -> Span {\n+        match *self {\n+            InternalTS::Empty(sp) |\n+            InternalTS::Leaf { sp, .. } |\n+            InternalTS::Node { sp, .. } => sp,\n+        }\n+    }\n+\n+    fn slice(&self, range: ops::Range<usize>) -> TokenStream {\n+        let from = range.start;\n+        let to = range.end;\n+        if from == to {\n+            return TokenStream::mk_empty();\n+        }\n+        if from > to {\n+            panic!(\"Invalid range: {} to {}\", from, to);\n+        }\n+        if from == 0 && to == self.len() {\n+            return TokenStream { ts: self.clone() }; /* should be cheap */\n+        }\n+        match *self {\n+            InternalTS::Empty(..) => panic!(\"Invalid index\"),\n+            InternalTS::Leaf { ref tts, offset, .. } => {\n+                let offset = offset + from;\n+                let len = to - from;\n+                TokenStream::mk_sub_leaf(tts.clone(),\n+                                         offset,\n+                                         len,\n+                                         covering_span(&tts[offset..offset + len]))\n+            }\n+            InternalTS::Node { ref left, ref right, .. } => {\n+                let left_len = left.len();\n+                if to <= left_len {\n+                    left.slice(range)\n+                } else if from >= left_len {\n+                    right.slice(from - left_len..to - left_len)\n+                } else {\n+                    TokenStream::concat(left.slice(from..left_len), right.slice(0..to - left_len))\n+                }\n+            }\n+        }\n+    }\n+}\n+\n /// TokenStream operators include basic destructuring, boolean operations, `maybe_...`\n /// operations, and `maybe_..._prefix` operations. Boolean operations are straightforward,\n /// indicating information about the structure of the stream. The `maybe_...` operations\n@@ -419,129 +496,149 @@ fn covering_span(trees: &[TokenTree]) -> Span {\n ///\n ///    `maybe_path_prefix(\"a::b::c(a,b,c).foo()\") -> (a::b::c, \"(a,b,c).foo()\")`\n impl TokenStream {\n-    /// Convert a vector of `TokenTree`s into a `TokenStream`.\n-    pub fn from_tts(trees: Vec<TokenTree>) -> TokenStream {\n-        let span = covering_span(&trees);\n-        TokenStream {\n-            tts: trees,\n-            span: span,\n-        }\n+    pub fn mk_empty() -> TokenStream {\n+        TokenStream { ts: InternalTS::Empty(DUMMY_SP) }\n     }\n \n-    /// Copies all of the TokenTrees from the TokenSlice, appending them to the stream.\n-    pub fn append_stream(mut self, ts2: &TokenSlice) {\n-        for tt in ts2.iter() {\n-            self.tts.push(tt.clone());\n-        }\n-        self.span = covering_span(&self.tts[..]);\n+    fn mk_spanned_empty(sp: Span) -> TokenStream {\n+        TokenStream { ts: InternalTS::Empty(sp) }\n     }\n \n-    /// Manually change a TokenStream's span.\n-    pub fn respan(self, span: Span) -> TokenStream {\n+    fn mk_leaf(tts: Rc<Vec<TokenTree>>, sp: Span) -> TokenStream {\n+        let len = tts.len();\n         TokenStream {\n-            tts: self.tts,\n-            span: span,\n+            ts: InternalTS::Leaf {\n+                tts: tts,\n+                offset: 0,\n+                len: len,\n+                sp: sp,\n+            },\n         }\n     }\n \n-    /// Construct a TokenStream from an ast literal.\n-    pub fn from_ast_lit_str(lit: ast::Lit) -> Option<TokenStream> {\n-        match lit.node {\n-            LitKind::Str(val, _) => {\n-                let val = TokLit::Str_(token::intern(&val));\n-                Some(TokenStream::from_tts(vec![TokenTree::Token(lit.span,\n-                                                                 Token::Literal(val, None))]))\n-            }\n-            _ => None,\n+    fn mk_sub_leaf(tts: Rc<Vec<TokenTree>>, offset: usize, len: usize, sp: Span) -> TokenStream {\n+        TokenStream {\n+            ts: InternalTS::Leaf {\n+                tts: tts,\n+                offset: offset,\n+                len: len,\n+                sp: sp,\n+            },\n         }\n-\n     }\n \n-    /// Convert a vector of TokenTrees into a parentheses-delimited TokenStream.\n-    pub fn as_paren_delimited_stream(tts: Vec<TokenTree>) -> TokenStream {\n-        let new_sp = covering_span(&tts);\n-\n-        let new_delim = Rc::new(Delimited {\n-            delim: token::DelimToken::Paren,\n-            open_span: DUMMY_SP,\n-            tts: tts,\n-            close_span: DUMMY_SP,\n-        });\n-\n-        TokenStream::from_tts(vec![TokenTree::Delimited(new_sp, new_delim)])\n+    fn mk_int_node(left: Rc<InternalTS>,\n+                   right: Rc<InternalTS>,\n+                   len: usize,\n+                   sp: Span)\n+                   -> TokenStream {\n+        TokenStream {\n+            ts: InternalTS::Node {\n+                left: left,\n+                right: right,\n+                len: len,\n+                sp: sp,\n+            },\n+        }\n     }\n \n-    /// Convert an interned string into a one-element TokenStream.\n-    pub fn from_interned_string_as_ident(s: InternedString) -> TokenStream {\n-        TokenStream::from_tts(vec![TokenTree::Token(DUMMY_SP,\n-                                                    Token::Ident(token::str_to_ident(&s[..])))])\n+    /// Convert a vector of `TokenTree`s into a `TokenStream`.\n+    pub fn from_tts(trees: Vec<TokenTree>) -> TokenStream {\n+        let span = covering_span(&trees[..]);\n+        TokenStream::mk_leaf(Rc::new(trees), span)\n     }\n-}\n-\n-/// TokenSlices are 'views' of `TokenStream's; they fit the same role as `str`s do for\n-/// `String`s. In general, most TokenStream manipulations will be refocusing their internal\n-/// contents by taking a TokenSlice and then using indexing and the provided operators.\n-#[derive(PartialEq, Eq, Debug)]\n-pub struct TokenSlice([TokenTree]);\n-\n-impl ops::Deref for TokenStream {\n-    type Target = TokenSlice;\n \n-    fn deref(&self) -> &TokenSlice {\n-        let tts: &[TokenTree] = &*self.tts;\n-        unsafe { mem::transmute(tts) }\n+    /// Manually change a TokenStream's span.\n+    pub fn respan(self, span: Span) -> TokenStream {\n+        match self.ts {\n+            InternalTS::Empty(..) => TokenStream::mk_spanned_empty(span),\n+            InternalTS::Leaf { tts, offset, len, .. } => {\n+                TokenStream::mk_sub_leaf(tts, offset, len, span)\n+            }\n+            InternalTS::Node { left, right, len, .. } => {\n+                TokenStream::mk_int_node(left, right, len, span)\n+            }\n+        }\n     }\n-}\n \n-impl TokenSlice {\n-    /// Convert a borrowed TokenTree slice into a borrowed TokenSlice.\n-    fn from_tts(tts: &[TokenTree]) -> &TokenSlice {\n-        unsafe { mem::transmute(tts) }\n+    /// Concatenates two TokenStreams into a new TokenStream\n+    pub fn concat(left: TokenStream, right: TokenStream) -> TokenStream {\n+        let new_len = left.len() + right.len();\n+        let new_span = combine_spans(left.span(), right.span());\n+        TokenStream::mk_int_node(Rc::new(left.ts), Rc::new(right.ts), new_len, new_span)\n     }\n \n-    /// Indicates whether the `TokenStream` is empty.\n+    /// Indicate if the TokenStream is empty.\n     pub fn is_empty(&self) -> bool {\n         self.len() == 0\n     }\n \n-    /// Return the `TokenSlice`'s length.\n+    /// Return a TokenStream's length.\n     pub fn len(&self) -> usize {\n-        self.0.len()\n+        self.ts.len()\n     }\n \n-    /// Check equality versus another TokenStream, ignoring span information.\n-    pub fn eq_unspanned(&self, other: &TokenSlice) -> bool {\n-        if self.len() != other.len() {\n-            return false;\n-        }\n-        for (tt1, tt2) in self.iter().zip(other.iter()) {\n-            if !tt1.eq_unspanned(tt2) {\n-                return false;\n+    /// Convert a TokenStream into a vector of borrowed TokenTrees.\n+    pub fn to_vec(&self) -> Vec<&TokenTree> {\n+        fn internal_to_vec(ts: &InternalTS) -> Vec<&TokenTree> {\n+            match *ts {\n+                InternalTS::Empty(..) => Vec::new(),\n+                InternalTS::Leaf { ref tts, offset, len, .. } => {\n+                    tts[offset..offset + len].iter().collect()\n+                }\n+                InternalTS::Node { ref left, ref right, .. } => {\n+                    let mut v1 = internal_to_vec(left);\n+                    let mut v2 = internal_to_vec(right);\n+                    v1.append(&mut v2);\n+                    v1\n+                }\n             }\n         }\n-        true\n+        internal_to_vec(&self.ts)\n     }\n \n-    /// Compute a span that covers the entire TokenSlice (eg, one wide enough to include\n-    /// the entire slice). If the inputs share expansion identification, it is preserved.\n-    /// If they do not, it is discarded.\n-    pub fn covering_span(&self) -> Span {\n-        covering_span(&self.0)\n+    /// Convert a TokenStream into a vector of TokenTrees (by cloning the TokenTrees).\n+    /// (This operation is an O(n) deep copy of the underlying structure.)\n+    pub fn to_tts(&self) -> Vec<TokenTree> {\n+        self.to_vec().into_iter().cloned().collect::<Vec<TokenTree>>()\n     }\n \n-    /// Indicates where the stream is of the form `= <ts>`, where `<ts>` is a continued\n-    /// `TokenStream`.\n-    pub fn is_assignment(&self) -> bool {\n-        self.maybe_assignment().is_some()\n+    /// Return the TokenStream's span.\n+    pub fn span(&self) -> Span {\n+        self.ts.span()\n     }\n \n-    /// Returns the RHS of an assigment.\n-    pub fn maybe_assignment(&self) -> Option<&TokenSlice> {\n-        if !(self.len() > 1) {\n-            return None;\n+    /// Returns an iterator over a TokenStream (as a sequence of TokenTrees).\n+    pub fn iter<'a>(&self) -> Iter {\n+        Iter { vs: self, idx: 0 }\n+    }\n+\n+    /// Splits a TokenStream based on the provided `&TokenTree -> bool` predicate.\n+    pub fn split<P>(&self, pred: P) -> Split<P>\n+        where P: FnMut(&TokenTree) -> bool\n+    {\n+        Split {\n+            vs: self,\n+            pred: pred,\n+            finished: false,\n+            idx: 0,\n         }\n+    }\n+\n+    /// Produce a slice of the input TokenStream from the `from` index, inclusive, to the\n+    /// `to` index, non-inclusive.\n+    pub fn slice(&self, range: ops::Range<usize>) -> TokenStream {\n+        self.ts.slice(range)\n+    }\n+\n+    /// Slice starting at the provided index, inclusive.\n+    pub fn slice_from(&self, from: ops::RangeFrom<usize>) -> TokenStream {\n+        self.slice(from.start..self.len())\n+    }\n \n-        Some(&self[1..])\n+    /// Slice up to the provided index, non-inclusive.\n+    pub fn slice_to(&self, to: ops::RangeTo<usize>) -> TokenStream {\n+        self.slice(0..to.end)\n     }\n \n     /// Indicates where the stream is a single, delimited expression (e.g., `(a,b,c)` or\n@@ -551,50 +648,15 @@ impl TokenSlice {\n     }\n \n     /// Returns the inside of the delimited term as a new TokenStream.\n-    pub fn maybe_delimited(&self) -> Option<&TokenSlice> {\n+    pub fn maybe_delimited(&self) -> Option<TokenStream> {\n         if !(self.len() == 1) {\n             return None;\n         }\n \n+        // FIXME It would be nice to change Delimited to move the Rc around the TokenTree\n+        // vector directly in order to avoid the clone here.\n         match self[0] {\n-            TokenTree::Delimited(_, ref rc) => Some(TokenSlice::from_tts(&*rc.tts)),\n-            _ => None,\n-        }\n-    }\n-\n-    /// Returns a list of `TokenSlice`s if the stream is a delimited list, breaking the\n-    /// stream on commas.\n-    pub fn maybe_comma_list(&self) -> Option<Vec<&TokenSlice>> {\n-        let maybe_tts = self.maybe_delimited();\n-\n-        let ts: &TokenSlice;\n-        match maybe_tts {\n-            Some(t) => {\n-                ts = t;\n-            }\n-            None => {\n-                return None;\n-            }\n-        }\n-\n-        let splits: Vec<&TokenSlice> = ts.split(|x| match *x {\n-                TokenTree::Token(_, Token::Comma) => true,\n-                _ => false,\n-            })\n-            .filter(|x| x.len() > 0)\n-            .collect();\n-\n-        Some(splits)\n-    }\n-\n-    /// Returns a Nonterminal if it is Interpolated.\n-    pub fn maybe_interpolated_nonterminal(&self) -> Option<Nonterminal> {\n-        if !(self.len() == 1) {\n-            return None;\n-        }\n-\n-        match self[0] {\n-            TokenTree::Token(_, Token::Interpolated(ref nt)) => Some(nt.clone()),\n+            TokenTree::Delimited(_, ref rc) => Some(TokenStream::from_tts(rc.tts.clone())),\n             _ => None,\n         }\n     }\n@@ -610,210 +672,90 @@ impl TokenSlice {\n             return None;\n         }\n \n-        let tok = if let Some(tts) = self.maybe_delimited() {\n-            if tts.len() != 1 {\n-                return None;\n-            }\n-            &tts[0]\n-        } else {\n-            &self[0]\n-        };\n-\n-        match *tok {\n+        match self[0] {\n             TokenTree::Token(_, Token::Ident(t)) => Some(t),\n             _ => None,\n         }\n     }\n \n-    /// Indicates if the stream is exactly one literal\n-    pub fn is_lit(&self) -> bool {\n-        self.maybe_lit().is_some()\n-    }\n-\n-    /// Returns a literal\n-    pub fn maybe_lit(&self) -> Option<token::Lit> {\n-        if !(self.len() == 1) {\n-            return None;\n-        }\n-\n-        let tok = if let Some(tts) = self.maybe_delimited() {\n-            if tts.len() != 1 {\n-                return None;\n-            }\n-            &tts[0]\n-        } else {\n-            &self[0]\n-        };\n-\n-        match *tok {\n-            TokenTree::Token(_, Token::Literal(l, _)) => Some(l),\n-            _ => None,\n-        }\n-    }\n-\n-    /// Returns an AST string literal if the TokenStream is either a normal ('cooked') or\n-    /// raw string literal.\n-    pub fn maybe_str(&self) -> Option<ast::Lit> {\n-        if !(self.len() == 1) {\n-            return None;\n-        }\n-\n-        match self[0] {\n-            TokenTree::Token(sp, Token::Literal(Lit::Str_(s), _)) => {\n-                let l = LitKind::Str(token::intern_and_get_ident(&parse::str_lit(&s.as_str())),\n-                                     ast::StrStyle::Cooked);\n-                Some(Spanned {\n-                    node: l,\n-                    span: sp,\n-                })\n-            }\n-            TokenTree::Token(sp, Token::Literal(Lit::StrRaw(s, n), _)) => {\n-                let l = LitKind::Str(token::intern_and_get_ident(&parse::raw_str_lit(&s.as_str())),\n-                                     ast::StrStyle::Raw(n));\n-                Some(Spanned {\n-                    node: l,\n-                    span: sp,\n-                })\n+    /// Compares two TokenStreams, checking equality without regarding span information.\n+    pub fn eq_unspanned(&self, other: &TokenStream) -> bool {\n+        for (t1, t2) in self.iter().zip(other.iter()) {\n+            if !t1.eq_unspanned(t2) {\n+                return false;\n             }\n-            _ => None,\n         }\n+        true\n     }\n \n-    /// This operation extracts the path prefix , returning an AST path struct and the remainder\n-    /// of the stream (if it finds one). To be more specific, a tokenstream that has a valid,\n-    /// non-global path as a prefix (eg `foo(bar, baz)`, `foo::bar(bar)`, but *not*\n-    /// `::foo::bar(baz)`) will yield the path and the remaining tokens (as a slice). The previous\n-    /// examples will yield\n-    /// `Some((Path { segments = vec![foo], ... }, [(bar, baz)]))`,\n-    /// `Some((Path { segments = vec![foo, bar] }, [(baz)]))`,\n-    /// and `None`, respectively.\n-    pub fn maybe_path_prefix(&self) -> Option<(ast::Path, &TokenSlice)> {\n-        let mut segments: Vec<ast::PathSegment> = Vec::new();\n-\n-        let path: Vec<&TokenTree> = self.iter()\n-            .take_while(|x| x.is_ident() || x.eq_token(Token::ModSep))\n-            .collect::<Vec<&TokenTree>>();\n-\n-        let path_size = path.len();\n-        if path_size == 0 {\n-            return None;\n-        }\n-\n-        let cov_span = self[..path_size].covering_span();\n-        let rst = &self[path_size..];\n-\n-        let fst_id = path[0];\n-\n-        if let Some(id) = fst_id.maybe_ident() {\n-            segments.push(ast::PathSegment {\n-                identifier: id,\n-                parameters: ast::PathParameters::none(),\n-            });\n-        } else {\n-            return None;\n-        }\n-\n-        // Let's use a state machine to parse out the rest.\n-        enum State {\n-            Mod, // Expect a `::`, or return None otherwise.\n-            Ident, // Expect an ident, or return None otherwise.\n-        }\n-        let mut state = State::Mod;\n-\n-        for p in &path[1..] {\n-            match state {\n-                State::Mod => {\n-                    // State 0: ['::' -> state 1, else return None]\n-                    if p.eq_token(Token::ModSep) {\n-                        state = State::Ident;\n-                    } else {\n-                        return None;\n-                    }\n-                }\n-                State::Ident => {\n-                    // State 1: [ident -> state 0, else return None]\n-                    if let Some(id) = p.maybe_ident() {\n-                        segments.push(ast::PathSegment {\n-                            identifier: id,\n-                            parameters: ast::PathParameters::none(),\n-                        });\n-                        state = State::Mod;\n-                    } else {\n-                        return None;\n-                    }\n-                }\n-            }\n-        }\n-\n-        let path = ast::Path {\n-            span: cov_span,\n-            global: false,\n-            segments: segments,\n-        };\n-        Some((path, rst))\n-    }\n+    /// Convert a vector of TokenTrees into a parentheses-delimited TokenStream.\n+    pub fn as_delimited_stream(tts: Vec<TokenTree>, delim: token::DelimToken) -> TokenStream {\n+        let new_sp = covering_span(&tts);\n \n-    /// Returns an iterator over a TokenSlice (as a sequence of TokenStreams).\n-    fn iter(&self) -> Iter {\n-        Iter { vs: self }\n-    }\n+        let new_delim = Rc::new(Delimited {\n+            delim: delim,\n+            open_span: DUMMY_SP,\n+            tts: tts,\n+            close_span: DUMMY_SP,\n+        });\n \n-    /// Splits a TokenSlice based on the provided `&TokenTree -> bool` predicate.\n-    fn split<P>(&self, pred: P) -> Split<P>\n-        where P: FnMut(&TokenTree) -> bool\n-    {\n-        Split {\n-            vs: self,\n-            pred: pred,\n-            finished: false,\n-        }\n+        TokenStream::from_tts(vec![TokenTree::Delimited(new_sp, new_delim)])\n     }\n }\n \n+// FIXME Reimplement this iterator to hold onto a slice iterator for a leaf, getting the\n+// next leaf's iterator when the current one is exhausted.\n pub struct Iter<'a> {\n-    vs: &'a TokenSlice,\n+    vs: &'a TokenStream,\n+    idx: usize,\n }\n \n impl<'a> Iterator for Iter<'a> {\n     type Item = &'a TokenTree;\n \n     fn next(&mut self) -> Option<&'a TokenTree> {\n-        if self.vs.is_empty() {\n+        if self.vs.is_empty() || self.idx >= self.vs.len() {\n             return None;\n         }\n \n-        let ret = Some(&self.vs[0]);\n-        self.vs = &self.vs[1..];\n+        let ret = Some(&self.vs[self.idx]);\n+        self.idx = self.idx + 1;\n         ret\n     }\n }\n \n pub struct Split<'a, P>\n     where P: FnMut(&TokenTree) -> bool\n {\n-    vs: &'a TokenSlice,\n+    vs: &'a TokenStream,\n     pred: P,\n     finished: bool,\n+    idx: usize,\n }\n \n impl<'a, P> Iterator for Split<'a, P>\n     where P: FnMut(&TokenTree) -> bool\n {\n-    type Item = &'a TokenSlice;\n+    type Item = TokenStream;\n \n-    fn next(&mut self) -> Option<&'a TokenSlice> {\n+    fn next(&mut self) -> Option<TokenStream> {\n         if self.finished {\n             return None;\n         }\n+        if self.idx >= self.vs.len() {\n+            self.finished = true;\n+            return None;\n+        }\n \n-        match self.vs.iter().position(|x| (self.pred)(x)) {\n+        let mut lookup = self.vs.iter().skip(self.idx);\n+        match lookup.position(|x| (self.pred)(&x)) {\n             None => {\n                 self.finished = true;\n-                Some(&self.vs[..])\n+                Some(self.vs.slice_from(self.idx..))\n             }\n-            Some(idx) => {\n-                let ret = Some(&self.vs[..idx]);\n-                self.vs = &self.vs[idx + 1..];\n+            Some(edx) => {\n+                let ret = Some(self.vs.slice(self.idx..self.idx + edx));\n+                self.idx += edx + 1;\n                 ret\n             }\n         }\n@@ -824,98 +766,134 @@ impl Index<usize> for TokenStream {\n     type Output = TokenTree;\n \n     fn index(&self, index: usize) -> &TokenTree {\n-        Index::index(&**self, index)\n+        &self.ts[index]\n     }\n }\n \n-impl ops::Index<ops::Range<usize>> for TokenStream {\n-    type Output = TokenSlice;\n+impl Index<usize> for InternalTS {\n+    type Output = TokenTree;\n \n-    fn index(&self, index: ops::Range<usize>) -> &TokenSlice {\n-        Index::index(&**self, index)\n+    fn index(&self, index: usize) -> &TokenTree {\n+        if self.len() <= index {\n+            panic!(\"Index {} too large for {:?}\", index, self);\n+        }\n+        match *self {\n+            InternalTS::Empty(..) => panic!(\"Invalid index\"),\n+            InternalTS::Leaf { ref tts, offset, .. } => tts.get(index + offset).unwrap(),\n+            InternalTS::Node { ref left, ref right, .. } => {\n+                let left_len = left.len();\n+                if index < left_len {\n+                    Index::index(&**left, index)\n+                } else {\n+                    Index::index(&**right, index - left_len)\n+                }\n+            }\n+        }\n     }\n }\n \n-impl ops::Index<ops::RangeTo<usize>> for TokenStream {\n-    type Output = TokenSlice;\n-\n-    fn index(&self, index: ops::RangeTo<usize>) -> &TokenSlice {\n-        Index::index(&**self, index)\n-    }\n-}\n \n-impl ops::Index<ops::RangeFrom<usize>> for TokenStream {\n-    type Output = TokenSlice;\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use syntax_pos::{Span, BytePos, NO_EXPANSION, DUMMY_SP};\n+    use parse::token::{self, str_to_ident, Token};\n+    use util::parser_testing::string_to_tts;\n+    use std::rc::Rc;\n \n-    fn index(&self, index: ops::RangeFrom<usize>) -> &TokenSlice {\n-        Index::index(&**self, index)\n+    fn sp(a: u32, b: u32) -> Span {\n+        Span {\n+            lo: BytePos(a),\n+            hi: BytePos(b),\n+            expn_id: NO_EXPANSION,\n+        }\n     }\n-}\n-\n-impl ops::Index<ops::RangeFull> for TokenStream {\n-    type Output = TokenSlice;\n \n-    fn index(&self, _index: ops::RangeFull) -> &TokenSlice {\n-        Index::index(&**self, _index)\n+    fn as_paren_delimited_stream(tts: Vec<TokenTree>) -> TokenStream {\n+        TokenStream::as_delimited_stream(tts, token::DelimToken::Paren)\n     }\n-}\n-\n-impl Index<usize> for TokenSlice {\n-    type Output = TokenTree;\n \n-    fn index(&self, index: usize) -> &TokenTree {\n-        &self.0[index]\n+    #[test]\n+    fn test_concat() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"foo::bar::baz\".to_string()));\n+        let test_fst = TokenStream::from_tts(string_to_tts(\"foo::bar\".to_string()));\n+        let test_snd = TokenStream::from_tts(string_to_tts(\"::baz\".to_string()));\n+        let eq_res = TokenStream::concat(test_fst, test_snd);\n+        assert_eq!(test_res.len(), 5);\n+        assert_eq!(eq_res.len(), 5);\n+        assert_eq!(test_res.eq_unspanned(&eq_res), true);\n     }\n-}\n-\n-impl ops::Index<ops::Range<usize>> for TokenSlice {\n-    type Output = TokenSlice;\n \n-    fn index(&self, index: ops::Range<usize>) -> &TokenSlice {\n-        TokenSlice::from_tts(&self.0[index])\n+    #[test]\n+    fn test_from_to_bijection() {\n+        let test_start = string_to_tts(\"foo::bar(baz)\".to_string());\n+        let test_end = TokenStream::from_tts(string_to_tts(\"foo::bar(baz)\".to_string())).to_tts();\n+        assert_eq!(test_start, test_end)\n     }\n-}\n \n-impl ops::Index<ops::RangeTo<usize>> for TokenSlice {\n-    type Output = TokenSlice;\n+    #[test]\n+    fn test_to_from_bijection() {\n+        let test_start = TokenStream::from_tts(string_to_tts(\"foo::bar(baz)\".to_string()));\n+        let test_end = TokenStream::from_tts(test_start.clone().to_tts());\n+        assert_eq!(test_start, test_end)\n+    }\n \n-    fn index(&self, index: ops::RangeTo<usize>) -> &TokenSlice {\n-        TokenSlice::from_tts(&self.0[index])\n+    #[test]\n+    fn test_eq_0() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"foo\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"foo\".to_string()));\n+        assert_eq!(test_res, test_eqs)\n     }\n-}\n \n-impl ops::Index<ops::RangeFrom<usize>> for TokenSlice {\n-    type Output = TokenSlice;\n+    #[test]\n+    fn test_eq_1() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"::bar::baz\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"::bar::baz\".to_string()));\n+        assert_eq!(test_res, test_eqs)\n+    }\n \n-    fn index(&self, index: ops::RangeFrom<usize>) -> &TokenSlice {\n-        TokenSlice::from_tts(&self.0[index])\n+    #[test]\n+    fn test_eq_2() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"foo::bar\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"foo::bar::baz\".to_string()));\n+        assert_eq!(test_res, test_eqs.slice(0..3))\n     }\n-}\n \n-impl ops::Index<ops::RangeFull> for TokenSlice {\n-    type Output = TokenSlice;\n+    #[test]\n+    fn test_eq_3() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"\".to_string()));\n+        assert_eq!(test_res, test_eqs)\n+    }\n \n-    fn index(&self, _index: ops::RangeFull) -> &TokenSlice {\n-        TokenSlice::from_tts(&self.0[_index])\n+    #[test]\n+    fn test_diseq_0() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"::bar::baz\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"bar::baz\".to_string()));\n+        assert_eq!(test_res == test_eqs, false)\n     }\n-}\n \n+    #[test]\n+    fn test_diseq_1() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"(bar,baz)\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"bar,baz\".to_string()));\n+        assert_eq!(test_res == test_eqs, false)\n+    }\n \n-#[cfg(test)]\n-mod tests {\n-    use super::*;\n-    use ast;\n-    use syntax_pos::{Span, BytePos, NO_EXPANSION, DUMMY_SP};\n-    use parse::token::{self, str_to_ident, Token, Lit};\n-    use util::parser_testing::string_to_tts;\n-    use std::rc::Rc;\n+    #[test]\n+    fn test_slice_0() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"foo::bar\".to_string()));\n+        let test_eqs = TokenStream::from_tts(string_to_tts(\"foo::bar::baz\".to_string()));\n+        assert_eq!(test_res, test_eqs.slice(0..3))\n+    }\n \n-    fn sp(a: u32, b: u32) -> Span {\n-        Span {\n-            lo: BytePos(a),\n-            hi: BytePos(b),\n-            expn_id: NO_EXPANSION,\n-        }\n+    #[test]\n+    fn test_slice_1() {\n+        let test_res = TokenStream::from_tts(string_to_tts(\"foo::bar::baz\".to_string()))\n+            .slice(2..3);\n+        let test_eqs = TokenStream::from_tts(vec![TokenTree::Token(sp(5,8),\n+                                                    token::Ident(str_to_ident(\"bar\")))]);\n+        assert_eq!(test_res, test_eqs)\n     }\n \n     #[test]\n@@ -947,38 +925,6 @@ mod tests {\n         assert_eq!(test5.is_delimited(), false);\n     }\n \n-    #[test]\n-    fn test_is_assign() {\n-        let test0 = TokenStream::from_tts(string_to_tts(\"= bar::baz\".to_string()));\n-        let test1 = TokenStream::from_tts(string_to_tts(\"= \\\"5\\\"\".to_string()));\n-        let test2 = TokenStream::from_tts(string_to_tts(\"= 5\".to_string()));\n-        let test3 = TokenStream::from_tts(string_to_tts(\"(foo = 10)\".to_string()));\n-        let test4 = TokenStream::from_tts(string_to_tts(\"= (foo,bar,baz)\".to_string()));\n-        let test5 = TokenStream::from_tts(string_to_tts(\"\".to_string()));\n-\n-        assert_eq!(test0.is_assignment(), true);\n-        assert_eq!(test1.is_assignment(), true);\n-        assert_eq!(test2.is_assignment(), true);\n-        assert_eq!(test3.is_assignment(), false);\n-        assert_eq!(test4.is_assignment(), true);\n-        assert_eq!(test5.is_assignment(), false);\n-    }\n-\n-    #[test]\n-    fn test_is_lit() {\n-        let test0 = TokenStream::from_tts(string_to_tts(\"\\\"foo\\\"\".to_string()));\n-        let test1 = TokenStream::from_tts(string_to_tts(\"5\".to_string()));\n-        let test2 = TokenStream::from_tts(string_to_tts(\"foo\".to_string()));\n-        let test3 = TokenStream::from_tts(string_to_tts(\"foo::bar\".to_string()));\n-        let test4 = TokenStream::from_tts(string_to_tts(\"foo(bar)\".to_string()));\n-\n-        assert_eq!(test0.is_lit(), true);\n-        assert_eq!(test1.is_lit(), true);\n-        assert_eq!(test2.is_lit(), false);\n-        assert_eq!(test3.is_lit(), false);\n-        assert_eq!(test4.is_lit(), false);\n-    }\n-\n     #[test]\n     fn test_is_ident() {\n         let test0 = TokenStream::from_tts(string_to_tts(\"\\\"foo\\\"\".to_string()));\n@@ -994,62 +940,6 @@ mod tests {\n         assert_eq!(test4.is_ident(), false);\n     }\n \n-    #[test]\n-    fn test_maybe_assignment() {\n-        let test0_input = TokenStream::from_tts(string_to_tts(\"= bar::baz\".to_string()));\n-        let test1_input = TokenStream::from_tts(string_to_tts(\"= \\\"5\\\"\".to_string()));\n-        let test2_input = TokenStream::from_tts(string_to_tts(\"= 5\".to_string()));\n-        let test3_input = TokenStream::from_tts(string_to_tts(\"(foo = 10)\".to_string()));\n-        let test4_input = TokenStream::from_tts(string_to_tts(\"= (foo,bar,baz)\".to_string()));\n-        let test5_input = TokenStream::from_tts(string_to_tts(\"\".to_string()));\n-\n-        let test0 = test0_input.maybe_assignment();\n-        let test1 = test1_input.maybe_assignment();\n-        let test2 = test2_input.maybe_assignment();\n-        let test3 = test3_input.maybe_assignment();\n-        let test4 = test4_input.maybe_assignment();\n-        let test5 = test5_input.maybe_assignment();\n-\n-        let test0_expected = TokenStream::from_tts(vec![TokenTree::Token(sp(2, 5),\n-                                                        token::Ident(str_to_ident(\"bar\"))),\n-                                       TokenTree::Token(sp(5, 7), token::ModSep),\n-                                       TokenTree::Token(sp(7, 10),\n-                                                        token::Ident(str_to_ident(\"baz\")))]);\n-        assert_eq!(test0, Some(&test0_expected[..]));\n-\n-        let test1_expected = TokenStream::from_tts(vec![TokenTree::Token(sp(2, 5),\n-                                            token::Literal(Lit::Str_(token::intern(\"5\")), None))]);\n-        assert_eq!(test1, Some(&test1_expected[..]));\n-\n-        let test2_expected = TokenStream::from_tts(vec![TokenTree::Token( sp(2,3)\n-                                       , token::Literal(\n-                                           Lit::Integer(\n-                                             token::intern(&(5.to_string()))),\n-                                             None))]);\n-        assert_eq!(test2, Some(&test2_expected[..]));\n-\n-        assert_eq!(test3, None);\n-\n-\n-        let test4_tts = vec![TokenTree::Token(sp(3, 6), token::Ident(str_to_ident(\"foo\"))),\n-                             TokenTree::Token(sp(6, 7), token::Comma),\n-                             TokenTree::Token(sp(7, 10), token::Ident(str_to_ident(\"bar\"))),\n-                             TokenTree::Token(sp(10, 11), token::Comma),\n-                             TokenTree::Token(sp(11, 14), token::Ident(str_to_ident(\"baz\")))];\n-\n-        let test4_expected = TokenStream::from_tts(vec![TokenTree::Delimited(sp(2, 15),\n-                                                Rc::new(Delimited {\n-                                                    delim: token::DelimToken::Paren,\n-                                                    open_span: sp(2, 3),\n-                                                    tts: test4_tts,\n-                                                    close_span: sp(14, 15),\n-                                                }))]);\n-        assert_eq!(test4, Some(&test4_expected[..]));\n-\n-        assert_eq!(test5, None);\n-\n-    }\n-\n     #[test]\n     fn test_maybe_delimited() {\n         let test0_input = TokenStream::from_tts(string_to_tts(\"foo(bar::baz)\".to_string()));\n@@ -1074,7 +964,7 @@ mod tests {\n                                        TokenTree::Token(sp(4, 6), token::ModSep),\n                                        TokenTree::Token(sp(6, 9),\n                                                         token::Ident(str_to_ident(\"baz\")))]);\n-        assert_eq!(test1, Some(&test1_expected[..]));\n+        assert_eq!(test1, Some(test1_expected));\n \n         let test2_expected = TokenStream::from_tts(vec![TokenTree::Token(sp(1, 4),\n                                                         token::Ident(str_to_ident(\"foo\"))),\n@@ -1084,79 +974,13 @@ mod tests {\n                                        TokenTree::Token(sp(8, 9), token::Comma),\n                                        TokenTree::Token(sp(9, 12),\n                                                         token::Ident(str_to_ident(\"baz\")))]);\n-        assert_eq!(test2, Some(&test2_expected[..]));\n-\n-        assert_eq!(test3, None);\n-\n-        assert_eq!(test4, None);\n-\n-        assert_eq!(test5, None);\n-    }\n-\n-    #[test]\n-    fn test_maybe_comma_list() {\n-        let test0_input = TokenStream::from_tts(string_to_tts(\"foo(bar::baz)\".to_string()));\n-        let test1_input = TokenStream::from_tts(string_to_tts(\"(bar::baz)\".to_string()));\n-        let test2_input = TokenStream::from_tts(string_to_tts(\"(foo,bar,baz)\".to_string()));\n-        let test3_input = TokenStream::from_tts(string_to_tts(\"(foo::bar,bar,baz)\".to_string()));\n-        let test4_input = TokenStream::from_tts(string_to_tts(\"(foo,bar,baz)(zab,rab)\"\n-            .to_string()));\n-        let test5_input = TokenStream::from_tts(string_to_tts(\"(foo,bar,baz)foo\".to_string()));\n-        let test6_input = TokenStream::from_tts(string_to_tts(\"\".to_string()));\n-        // The following is supported behavior!\n-        let test7_input = TokenStream::from_tts(string_to_tts(\"(foo,bar,)\".to_string()));\n-\n-        let test0 = test0_input.maybe_comma_list();\n-        let test1 = test1_input.maybe_comma_list();\n-        let test2 = test2_input.maybe_comma_list();\n-        let test3 = test3_input.maybe_comma_list();\n-        let test4 = test4_input.maybe_comma_list();\n-        let test5 = test5_input.maybe_comma_list();\n-        let test6 = test6_input.maybe_comma_list();\n-        let test7 = test7_input.maybe_comma_list();\n-\n-        assert_eq!(test0, None);\n-\n-        let test1_stream = TokenStream::from_tts(vec![TokenTree::Token(sp(1, 4),\n-                                                        token::Ident(str_to_ident(\"bar\"))),\n-                                       TokenTree::Token(sp(4, 6), token::ModSep),\n-                                       TokenTree::Token(sp(6, 9),\n-                                                        token::Ident(str_to_ident(\"baz\")))]);\n-\n-        let test1_expected: Vec<&TokenSlice> = vec![&test1_stream[..]];\n-        assert_eq!(test1, Some(test1_expected));\n-\n-        let test2_foo = TokenStream::from_tts(vec![TokenTree::Token(sp(1, 4),\n-                                                        token::Ident(str_to_ident(\"foo\")))]);\n-        let test2_bar = TokenStream::from_tts(vec![TokenTree::Token(sp(5, 8),\n-                                                        token::Ident(str_to_ident(\"bar\")))]);\n-        let test2_baz = TokenStream::from_tts(vec![TokenTree::Token(sp(9, 12),\n-                                                        token::Ident(str_to_ident(\"baz\")))]);\n-        let test2_expected: Vec<&TokenSlice> = vec![&test2_foo[..], &test2_bar[..], &test2_baz[..]];\n         assert_eq!(test2, Some(test2_expected));\n \n-        let test3_path = TokenStream::from_tts(vec![TokenTree::Token(sp(1, 4),\n-                                                        token::Ident(str_to_ident(\"foo\"))),\n-                                       TokenTree::Token(sp(4, 6), token::ModSep),\n-                                       TokenTree::Token(sp(6, 9),\n-                                                        token::Ident(str_to_ident(\"bar\")))]);\n-        let test3_bar = TokenStream::from_tts(vec![TokenTree::Token(sp(10, 13),\n-                                                        token::Ident(str_to_ident(\"bar\")))]);\n-        let test3_baz = TokenStream::from_tts(vec![TokenTree::Token(sp(14, 17),\n-                                                        token::Ident(str_to_ident(\"baz\")))]);\n-        let test3_expected: Vec<&TokenSlice> =\n-            vec![&test3_path[..], &test3_bar[..], &test3_baz[..]];\n-        assert_eq!(test3, Some(test3_expected));\n+        assert_eq!(test3, None);\n \n         assert_eq!(test4, None);\n \n         assert_eq!(test5, None);\n-\n-        assert_eq!(test6, None);\n-\n-\n-        let test7_expected: Vec<&TokenSlice> = vec![&test2_foo[..], &test2_bar[..]];\n-        assert_eq!(test7, Some(test7_expected));\n     }\n \n     // pub fn maybe_ident(&self) -> Option<ast::Ident>\n@@ -1175,86 +999,10 @@ mod tests {\n         assert_eq!(test4, None);\n     }\n \n-    // pub fn maybe_lit(&self) -> Option<token::Lit>\n     #[test]\n-    fn test_maybe_lit() {\n-        let test0 = TokenStream::from_tts(string_to_tts(\"\\\"foo\\\"\".to_string())).maybe_lit();\n-        let test1 = TokenStream::from_tts(string_to_tts(\"5\".to_string())).maybe_lit();\n-        let test2 = TokenStream::from_tts(string_to_tts(\"foo\".to_string())).maybe_lit();\n-        let test3 = TokenStream::from_tts(string_to_tts(\"foo::bar\".to_string())).maybe_lit();\n-        let test4 = TokenStream::from_tts(string_to_tts(\"foo(bar)\".to_string())).maybe_lit();\n-\n-        assert_eq!(test0, Some(Lit::Str_(token::intern(\"foo\"))));\n-        assert_eq!(test1, Some(Lit::Integer(token::intern(&(5.to_string())))));\n-        assert_eq!(test2, None);\n-        assert_eq!(test3, None);\n-        assert_eq!(test4, None);\n-    }\n-\n-    #[test]\n-    fn test_maybe_path_prefix() {\n-        let test0_input = TokenStream::from_tts(string_to_tts(\"foo(bar::baz)\".to_string()));\n-        let test1_input = TokenStream::from_tts(string_to_tts(\"(bar::baz)\".to_string()));\n-        let test2_input = TokenStream::from_tts(string_to_tts(\"(foo,bar,baz)\".to_string()));\n-        let test3_input = TokenStream::from_tts(string_to_tts(\"foo::bar(bar,baz)\".to_string()));\n-\n-        let test0 = test0_input.maybe_path_prefix();\n-        let test1 = test1_input.maybe_path_prefix();\n-        let test2 = test2_input.maybe_path_prefix();\n-        let test3 = test3_input.maybe_path_prefix();\n-\n-        let test0_tts = vec![TokenTree::Token(sp(4, 7), token::Ident(str_to_ident(\"bar\"))),\n-                             TokenTree::Token(sp(7, 9), token::ModSep),\n-                             TokenTree::Token(sp(9, 12), token::Ident(str_to_ident(\"baz\")))];\n-\n-        let test0_stream = TokenStream::from_tts(vec![TokenTree::Delimited(sp(3, 13),\n-                                                               Rc::new(Delimited {\n-                                                                   delim: token::DelimToken::Paren,\n-                                                                   open_span: sp(3, 4),\n-                                                                   tts: test0_tts,\n-                                                                   close_span: sp(12, 13),\n-                                                               }))]);\n-\n-        let test0_expected = Some((ast::Path::from_ident(sp(0, 3), str_to_ident(\"foo\")),\n-                                   &test0_stream[..]));\n-        assert_eq!(test0, test0_expected);\n-\n-        assert_eq!(test1, None);\n-        assert_eq!(test2, None);\n-\n-        let test3_path = ast::Path {\n-            span: sp(0, 8),\n-            global: false,\n-            segments: vec![ast::PathSegment {\n-                               identifier: str_to_ident(\"foo\"),\n-                               parameters: ast::PathParameters::none(),\n-                           },\n-                           ast::PathSegment {\n-                               identifier: str_to_ident(\"bar\"),\n-                               parameters: ast::PathParameters::none(),\n-                           }],\n-        };\n-\n-        let test3_tts = vec![TokenTree::Token(sp(9, 12), token::Ident(str_to_ident(\"bar\"))),\n-                             TokenTree::Token(sp(12, 13), token::Comma),\n-                             TokenTree::Token(sp(13, 16), token::Ident(str_to_ident(\"baz\")))];\n-\n-        let test3_stream = TokenStream::from_tts(vec![TokenTree::Delimited(sp(8, 17),\n-                                                               Rc::new(Delimited {\n-                                                                   delim: token::DelimToken::Paren,\n-                                                                   open_span: sp(8, 9),\n-                                                                   tts: test3_tts,\n-                                                                   close_span: sp(16, 17),\n-                                                               }))]);\n-        let test3_expected = Some((test3_path, &test3_stream[..]));\n-        assert_eq!(test3, test3_expected);\n-    }\n-\n-    #[test]\n-    fn test_as_paren_delimited_stream() {\n-        let test0 = TokenStream::as_paren_delimited_stream(string_to_tts(\"foo,bar,\".to_string()));\n-        let test1 = TokenStream::as_paren_delimited_stream(string_to_tts(\"baz(foo,bar)\"\n-            .to_string()));\n+    fn test_as_delimited_stream() {\n+        let test0 = as_paren_delimited_stream(string_to_tts(\"foo,bar,\".to_string()));\n+        let test1 = as_paren_delimited_stream(string_to_tts(\"baz(foo,bar)\".to_string()));\n \n         let test0_tts = vec![TokenTree::Token(sp(0, 3), token::Ident(str_to_ident(\"foo\"))),\n                              TokenTree::Token(sp(3, 4), token::Comma),\n@@ -1294,5 +1042,4 @@ mod tests {\n \n         assert_eq!(test1, test1_stream);\n     }\n-\n }"}]}