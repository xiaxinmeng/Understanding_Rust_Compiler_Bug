{"sha": "c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM4NDU2MWJiNjI0MjgwYjg0ZWIyZmU2YzZiMmE2YjlmZTNmMWRiZjc=", "commit": {"author": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-02-20T20:33:40Z"}, "committer": {"name": "bors[bot]", "email": "bors[bot]@users.noreply.github.com", "date": "2019-02-20T20:33:40Z"}, "message": "Merge #863\n\n863: Token source r=matklad a=matklad\n\nSome reshuffling of parser's API with the eye towards extracting parse **without** syntax tree into a separate crate, to be used with macro expansion\n\nCo-authored-by: Aleksey Kladov <aleksey.kladov@gmail.com>", "tree": {"sha": "e47aa900bcffffded370b68b2e50604199b491e3", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e47aa900bcffffded370b68b2e50604199b491e3"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "html_url": "https://github.com/rust-lang/rust/commit/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "parents": [{"sha": "96899f8278b787280bd07d9ac9dce29a610ce40d", "url": "https://api.github.com/repos/rust-lang/rust/commits/96899f8278b787280bd07d9ac9dce29a610ce40d", "html_url": "https://github.com/rust-lang/rust/commit/96899f8278b787280bd07d9ac9dce29a610ce40d"}, {"sha": "882c47f1870f15cb2aaad8871ccbad1c51520f49", "url": "https://api.github.com/repos/rust-lang/rust/commits/882c47f1870f15cb2aaad8871ccbad1c51520f49", "html_url": "https://github.com/rust-lang/rust/commit/882c47f1870f15cb2aaad8871ccbad1c51520f49"}], "stats": {"total": 603, "additions": 245, "deletions": 358}, "files": [{"sha": "138d1394af99c8ce3841ea956f91da03bc1b490b", "filename": "crates/ra_syntax/src/parsing.rs", "status": "modified", "additions": 60, "deletions": 7, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -2,24 +2,77 @@\n mod token_set;\n mod builder;\n mod lexer;\n-mod parser_impl;\n-mod parser_api;\n+mod event;\n+mod input;\n+mod parser;\n mod grammar;\n mod reparsing;\n \n use crate::{\n-    SyntaxError,\n-    parsing::builder::GreenBuilder,\n+    SyntaxKind, SmolStr, SyntaxError,\n+    parsing::{\n+        builder::GreenBuilder,\n+        input::ParserInput,\n+        event::EventProcessor,\n+        parser::Parser,\n+    },\n     syntax_node::GreenNode,\n };\n \n pub use self::lexer::{tokenize, Token};\n \n+#[derive(Debug, Clone, PartialEq, Eq, Hash)]\n+pub struct ParseError(pub String);\n+\n pub(crate) use self::reparsing::incremental_reparse;\n \n pub(crate) fn parse_text(text: &str) -> (GreenNode, Vec<SyntaxError>) {\n     let tokens = tokenize(&text);\n-    let (green, errors) =\n-        parser_impl::parse_with(GreenBuilder::new(), text, &tokens, grammar::root);\n-    (green, errors)\n+    parse_with(GreenBuilder::default(), text, &tokens, grammar::root)\n+}\n+\n+fn parse_with<S: TreeSink>(\n+    tree_sink: S,\n+    text: &str,\n+    tokens: &[Token],\n+    f: fn(&mut Parser),\n+) -> S::Tree {\n+    let mut events = {\n+        let input = ParserInput::new(text, &tokens);\n+        let mut p = Parser::new(&input);\n+        f(&mut p);\n+        p.finish()\n+    };\n+    EventProcessor::new(tree_sink, text, tokens, &mut events).process().finish()\n+}\n+\n+/// `TreeSink` abstracts details of a particular syntax tree implementation.\n+trait TreeSink {\n+    type Tree;\n+\n+    /// Adds new leaf to the current branch.\n+    fn leaf(&mut self, kind: SyntaxKind, text: SmolStr);\n+\n+    /// Start new branch and make it current.\n+    fn start_branch(&mut self, kind: SyntaxKind);\n+\n+    /// Finish current branch and restore previous\n+    /// branch as current.\n+    fn finish_branch(&mut self);\n+\n+    fn error(&mut self, error: ParseError);\n+\n+    /// Complete tree building. Make sure that\n+    /// `start_branch` and `finish_branch` calls\n+    /// are paired!\n+    fn finish(self) -> Self::Tree;\n+}\n+\n+/// `TokenSource` abstracts the source of the tokens parser operates one.\n+///\n+/// Hopefully this will allow us to treat text and token trees in the same way!\n+trait TokenSource {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind;\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool;\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool;\n }"}, {"sha": "ee0e2cce7ae5f2a1a341ba33e8004ffa319c7823", "filename": "crates/ra_syntax/src/parsing/builder.rs", "status": "modified", "additions": 14, "deletions": 7, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fbuilder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fbuilder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fbuilder.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -1,26 +1,32 @@\n use crate::{\n-    parsing::parser_impl::Sink,\n+    SmolStr, SyntaxKind, SyntaxError, SyntaxErrorKind, TextUnit,\n+    parsing::{TreeSink, ParseError},\n     syntax_node::{GreenNode, RaTypes},\n-    SmolStr, SyntaxKind, SyntaxError,\n };\n \n use rowan::GreenNodeBuilder;\n \n pub(crate) struct GreenBuilder {\n+    text_pos: TextUnit,\n     errors: Vec<SyntaxError>,\n     inner: GreenNodeBuilder<RaTypes>,\n }\n \n-impl GreenBuilder {\n-    pub(crate) fn new() -> GreenBuilder {\n-        GreenBuilder { errors: Vec::new(), inner: GreenNodeBuilder::new() }\n+impl Default for GreenBuilder {\n+    fn default() -> GreenBuilder {\n+        GreenBuilder {\n+            text_pos: TextUnit::default(),\n+            errors: Vec::new(),\n+            inner: GreenNodeBuilder::new(),\n+        }\n     }\n }\n \n-impl Sink for GreenBuilder {\n+impl TreeSink for GreenBuilder {\n     type Tree = (GreenNode, Vec<SyntaxError>);\n \n     fn leaf(&mut self, kind: SyntaxKind, text: SmolStr) {\n+        self.text_pos += TextUnit::of_str(text.as_str());\n         self.inner.leaf(kind, text);\n     }\n \n@@ -32,7 +38,8 @@ impl Sink for GreenBuilder {\n         self.inner.finish_internal();\n     }\n \n-    fn error(&mut self, error: SyntaxError) {\n+    fn error(&mut self, error: ParseError) {\n+        let error = SyntaxError::new(SyntaxErrorKind::ParseError(error), self.text_pos);\n         self.errors.push(error)\n     }\n "}, {"sha": "f6f020eaba4bc5a6558a1a446c22845968b0b7d8", "filename": "crates/ra_syntax/src/parsing/event.rs", "status": "renamed", "additions": 6, "deletions": 13, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fevent.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fevent.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fevent.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -3,7 +3,7 @@\n //! parser, so as to allow to evolve the tree representation\n //! and the parser algorithm independently.\n //!\n-//! The `Sink` trait is the bridge between the parser and the\n+//! The `TreeSink` trait is the bridge between the parser and the\n //! tree builder: the parser produces a stream of events like\n //! `start node`, `finish node`, and `FileBuilder` converts\n //! this stream to a real tree.\n@@ -13,14 +13,9 @@ use crate::{\n     SmolStr,\n     SyntaxKind::{self, *},\n     TextRange, TextUnit,\n-    syntax_error::{\n-        ParseError,\n-        SyntaxError,\n-        SyntaxErrorKind,\n-    },\n     parsing::{\n+        ParseError, TreeSink,\n         lexer::Token,\n-        parser_impl::Sink,\n     },\n };\n \n@@ -93,7 +88,7 @@ impl Event {\n     }\n }\n \n-pub(super) struct EventProcessor<'a, S: Sink> {\n+pub(super) struct EventProcessor<'a, S: TreeSink> {\n     sink: S,\n     text_pos: TextUnit,\n     text: &'a str,\n@@ -102,7 +97,7 @@ pub(super) struct EventProcessor<'a, S: Sink> {\n     events: &'a mut [Event],\n }\n \n-impl<'a, S: Sink> EventProcessor<'a, S> {\n+impl<'a, S: TreeSink> EventProcessor<'a, S> {\n     pub(super) fn new(\n         sink: S,\n         text: &'a str,\n@@ -113,7 +108,7 @@ impl<'a, S: Sink> EventProcessor<'a, S> {\n     }\n \n     /// Generate the syntax tree with the control of events.\n-    pub(super) fn process(mut self) -> S {\n+    pub(crate) fn process(mut self) -> S {\n         let mut forward_parents = Vec::new();\n \n         for i in 0..self.events.len() {\n@@ -159,9 +154,7 @@ impl<'a, S: Sink> EventProcessor<'a, S> {\n                         .sum::<TextUnit>();\n                     self.leaf(kind, len, n_raw_tokens);\n                 }\n-                Event::Error { msg } => self\n-                    .sink\n-                    .error(SyntaxError::new(SyntaxErrorKind::ParseError(msg), self.text_pos)),\n+                Event::Error { msg } => self.sink.error(msg),\n             }\n         }\n         self.sink", "previous_filename": "crates/ra_syntax/src/parsing/parser_impl/event.rs"}, {"sha": "7ca9c223cc0ee1a4371488fba502152a065c5f31", "filename": "crates/ra_syntax/src/parsing/grammar.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fgrammar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fgrammar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fgrammar.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -41,7 +41,7 @@ use crate::{\n     SyntaxKind::{self, *},\n     parsing::{\n         token_set::TokenSet,\n-        parser_api::{CompletedMarker, Marker, Parser}\n+        parser::{CompletedMarker, Marker, Parser}\n     },\n };\n "}, {"sha": "96c03bb118506bf7b254c706a9fa636f5a84d071", "filename": "crates/ra_syntax/src/parsing/input.rs", "status": "added", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Finput.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -0,0 +1,68 @@\n+use crate::{\n+    SyntaxKind, SyntaxKind::EOF, TextRange, TextUnit,\n+    parsing::{\n+        TokenSource,\n+        lexer::Token,\n+    },\n+};\n+\n+impl<'t> TokenSource for ParserInput<'t> {\n+    fn token_kind(&self, pos: usize) -> SyntaxKind {\n+        if !(pos < self.tokens.len()) {\n+            return EOF;\n+        }\n+        self.tokens[pos].kind\n+    }\n+    fn is_token_joint_to_next(&self, pos: usize) -> bool {\n+        if !(pos + 1 < self.tokens.len()) {\n+            return true;\n+        }\n+        self.start_offsets[pos] + self.tokens[pos].len == self.start_offsets[pos + 1]\n+    }\n+    fn is_keyword(&self, pos: usize, kw: &str) -> bool {\n+        if !(pos < self.tokens.len()) {\n+            return false;\n+        }\n+        let range = TextRange::offset_len(self.start_offsets[pos], self.tokens[pos].len);\n+\n+        self.text[range] == *kw\n+    }\n+}\n+\n+pub(crate) struct ParserInput<'t> {\n+    text: &'t str,\n+    /// start position of each token(expect whitespace and comment)\n+    /// ```non-rust\n+    ///  struct Foo;\n+    /// ^------^---\n+    /// |      |  ^-\n+    /// 0      7  10\n+    /// ```\n+    /// (token, start_offset): `[(struct, 0), (Foo, 7), (;, 10)]`\n+    start_offsets: Vec<TextUnit>,\n+    /// non-whitespace/comment tokens\n+    /// ```non-rust\n+    /// struct Foo {}\n+    /// ^^^^^^ ^^^ ^^\n+    /// ```\n+    /// tokens: `[struct, Foo, {, }]`\n+    tokens: Vec<Token>,\n+}\n+\n+impl<'t> ParserInput<'t> {\n+    /// Generate input from tokens(expect comment and whitespace).\n+    pub fn new(text: &'t str, raw_tokens: &'t [Token]) -> ParserInput<'t> {\n+        let mut tokens = Vec::new();\n+        let mut start_offsets = Vec::new();\n+        let mut len = 0.into();\n+        for &token in raw_tokens.iter() {\n+            if !token.kind.is_trivia() {\n+                tokens.push(token);\n+                start_offsets.push(len);\n+            }\n+            len += token.len;\n+        }\n+\n+        ParserInput { text, start_offsets, tokens }\n+    }\n+}"}, {"sha": "923b0f2b20dba9193a5280ead2cf18bca879caeb", "filename": "crates/ra_syntax/src/parsing/parser.rs", "status": "renamed", "additions": 92, "deletions": 17, "changes": 109, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -1,10 +1,13 @@\n+use std::cell::Cell;\n+\n use drop_bomb::DropBomb;\n \n use crate::{\n-    SyntaxKind::{self, ERROR},\n+    SyntaxKind::{self, ERROR, EOF, TOMBSTONE},\n     parsing::{\n+        TokenSource, ParseError,\n         token_set::TokenSet,\n-        parser_impl::ParserImpl\n+        event::Event,\n     },\n };\n \n@@ -17,9 +20,22 @@ use crate::{\n /// tree, but rather a flat stream of events of the form\n /// \"start expression, consume number literal,\n /// finish expression\". See `Event` docs for more.\n-pub(crate) struct Parser<'t>(pub(super) ParserImpl<'t>);\n+pub(crate) struct Parser<'t> {\n+    token_source: &'t dyn TokenSource,\n+    token_pos: usize,\n+    events: Vec<Event>,\n+    steps: Cell<u32>,\n+}\n \n impl<'t> Parser<'t> {\n+    pub(super) fn new(token_source: &'t dyn TokenSource) -> Parser<'t> {\n+        Parser { token_source, token_pos: 0, events: Vec::new(), steps: Cell::new(0) }\n+    }\n+\n+    pub(crate) fn finish(self) -> Vec<Event> {\n+        self.events\n+    }\n+\n     /// Returns the kind of the current token.\n     /// If parser has already reached the end of input,\n     /// the special `EOF` kind is returned.\n@@ -32,21 +48,39 @@ impl<'t> Parser<'t> {\n     ///\n     /// Useful for parsing things like `>>`.\n     pub(crate) fn current2(&self) -> Option<(SyntaxKind, SyntaxKind)> {\n-        self.0.current2()\n+        let c1 = self.token_source.token_kind(self.token_pos);\n+        let c2 = self.token_source.token_kind(self.token_pos + 1);\n+        if self.token_source.is_token_joint_to_next(self.token_pos) {\n+            Some((c1, c2))\n+        } else {\n+            None\n+        }\n     }\n \n     /// Returns the kinds of the current three tokens, if they are not separated\n     /// by trivia.\n     ///\n     /// Useful for parsing things like `=>>`.\n     pub(crate) fn current3(&self) -> Option<(SyntaxKind, SyntaxKind, SyntaxKind)> {\n-        self.0.current3()\n+        let c1 = self.token_source.token_kind(self.token_pos);\n+        let c2 = self.token_source.token_kind(self.token_pos + 1);\n+        let c3 = self.token_source.token_kind(self.token_pos + 2);\n+        if self.token_source.is_token_joint_to_next(self.token_pos)\n+            && self.token_source.is_token_joint_to_next(self.token_pos + 1)\n+        {\n+            Some((c1, c2, c3))\n+        } else {\n+            None\n+        }\n     }\n \n     /// Lookahead operation: returns the kind of the next nth\n     /// token.\n-    pub(crate) fn nth(&self, n: u32) -> SyntaxKind {\n-        self.0.nth(n)\n+    pub(crate) fn nth(&self, n: usize) -> SyntaxKind {\n+        let steps = self.steps.get();\n+        assert!(steps <= 10_000_000, \"the parser seems stuck\");\n+        self.steps.set(steps + 1);\n+        self.token_source.token_kind(self.token_pos + n)\n     }\n \n     /// Checks if the current token is `kind`.\n@@ -60,20 +94,26 @@ impl<'t> Parser<'t> {\n     }\n \n     /// Checks if the current token is contextual keyword with text `t`.\n-    pub(crate) fn at_contextual_kw(&self, t: &str) -> bool {\n-        self.0.at_kw(t)\n+    pub(crate) fn at_contextual_kw(&self, kw: &str) -> bool {\n+        self.token_source.is_keyword(self.token_pos, kw)\n     }\n \n     /// Starts a new node in the syntax tree. All nodes and tokens\n     /// consumed between the `start` and the corresponding `Marker::complete`\n     /// belong to the same node.\n     pub(crate) fn start(&mut self) -> Marker {\n-        Marker::new(self.0.start())\n+        let pos = self.events.len() as u32;\n+        self.push_event(Event::tombstone());\n+        Marker::new(pos)\n     }\n \n     /// Advances the parser by one token unconditionally.\n     pub(crate) fn bump(&mut self) {\n-        self.0.bump();\n+        let kind = self.nth(0);\n+        if kind == EOF {\n+            return;\n+        }\n+        self.do_bump(kind, 1);\n     }\n \n     /// Advances the parser by one token, remapping its kind.\n@@ -83,22 +123,27 @@ impl<'t> Parser<'t> {\n     /// `union` keyword, and keyword is what ends up in the\n     /// final tree.\n     pub(crate) fn bump_remap(&mut self, kind: SyntaxKind) {\n-        self.0.bump_remap(kind);\n+        if self.nth(0) == EOF {\n+            // TODO: panic!?\n+            return;\n+        }\n+        self.do_bump(kind, 1);\n     }\n \n     /// Advances the parser by `n` tokens, remapping its kind.\n     /// This is useful to create compound tokens from parts. For\n     /// example, an `<<` token is two consecutive remapped `<` tokens\n     pub(crate) fn bump_compound(&mut self, kind: SyntaxKind, n: u8) {\n-        self.0.bump_compound(kind, n);\n+        self.do_bump(kind, n);\n     }\n \n     /// Emit error with the `message`\n     /// TODO: this should be much more fancy and support\n     /// structured errors with spans and notes, like rustc\n     /// does.\n     pub(crate) fn error<T: Into<String>>(&mut self, message: T) {\n-        self.0.error(message.into())\n+        let msg = ParseError(message.into());\n+        self.push_event(Event::Error { msg })\n     }\n \n     /// Consume the next token if `kind` matches.\n@@ -136,6 +181,15 @@ impl<'t> Parser<'t> {\n             m.complete(self, ERROR);\n         };\n     }\n+\n+    fn do_bump(&mut self, kind: SyntaxKind, n_raw_tokens: u8) {\n+        self.token_pos += usize::from(n_raw_tokens);\n+        self.push_event(Event::Token { kind, n_raw_tokens });\n+    }\n+\n+    fn push_event(&mut self, event: Event) {\n+        self.events.push(event)\n+    }\n }\n \n /// See `Parser::start`.\n@@ -154,15 +208,28 @@ impl Marker {\n     /// operation like `.precede()` to deal with forward_parent.\n     pub(crate) fn complete(mut self, p: &mut Parser, kind: SyntaxKind) -> CompletedMarker {\n         self.bomb.defuse();\n-        p.0.complete(self.pos, kind);\n+        let idx = self.pos as usize;\n+        match p.events[idx] {\n+            Event::Start { kind: ref mut slot, .. } => {\n+                *slot = kind;\n+            }\n+            _ => unreachable!(),\n+        }\n+        p.push_event(Event::Finish);\n         CompletedMarker::new(self.pos, kind)\n     }\n \n     /// Abandons the syntax tree node. All its children\n     /// are attached to its parent instead.\n     pub(crate) fn abandon(mut self, p: &mut Parser) {\n         self.bomb.defuse();\n-        p.0.abandon(self.pos);\n+        let idx = self.pos as usize;\n+        if idx == p.events.len() - 1 {\n+            match p.events.pop() {\n+                Some(Event::Start { kind: TOMBSTONE, forward_parent: None }) => (),\n+                _ => unreachable!(),\n+            }\n+        }\n     }\n }\n \n@@ -186,7 +253,15 @@ impl CompletedMarker {\n     /// then mark `NEWSTART` as `START`'s parent with saving its relative\n     /// distance to `NEWSTART` into forward_parent(=2 in this case);\n     pub(crate) fn precede(self, p: &mut Parser) -> Marker {\n-        Marker::new(p.0.precede(self.0))\n+        let new_pos = p.start();\n+        let idx = self.0 as usize;\n+        match p.events[idx] {\n+            Event::Start { ref mut forward_parent, .. } => {\n+                *forward_parent = Some(new_pos.pos - self.0);\n+            }\n+            _ => unreachable!(),\n+        }\n+        new_pos\n     }\n \n     pub(crate) fn kind(&self) -> SyntaxKind {", "previous_filename": "crates/ra_syntax/src/parsing/parser_api.rs"}, {"sha": "8cce1ab01ce1c15f347ee24dd5f2924ee65ebaee", "filename": "crates/ra_syntax/src/parsing/parser_impl.rs", "status": "removed", "additions": 0, "deletions": 200, "changes": 200, "blob_url": "https://github.com/rust-lang/rust/blob/96899f8278b787280bd07d9ac9dce29a610ce40d/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96899f8278b787280bd07d9ac9dce29a610ce40d/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl.rs?ref=96899f8278b787280bd07d9ac9dce29a610ce40d", "patch": "@@ -1,200 +0,0 @@\n-mod event;\n-mod input;\n-\n-use std::cell::Cell;\n-\n-use crate::{\n-    SmolStr,\n-    syntax_error::{ParseError, SyntaxError},\n-    parsing::{\n-        lexer::Token,\n-        parser_api::Parser,\n-        parser_impl::{\n-            event::{Event, EventProcessor},\n-            input::{InputPosition, ParserInput},\n-        },\n-    },\n-};\n-\n-use crate::SyntaxKind::{self, EOF, TOMBSTONE};\n-\n-pub(super) trait Sink {\n-    type Tree;\n-\n-    /// Adds new leaf to the current branch.\n-    fn leaf(&mut self, kind: SyntaxKind, text: SmolStr);\n-\n-    /// Start new branch and make it current.\n-    fn start_branch(&mut self, kind: SyntaxKind);\n-\n-    /// Finish current branch and restore previous\n-    /// branch as current.\n-    fn finish_branch(&mut self);\n-\n-    fn error(&mut self, error: SyntaxError);\n-\n-    /// Complete tree building. Make sure that\n-    /// `start_branch` and `finish_branch` calls\n-    /// are paired!\n-    fn finish(self) -> Self::Tree;\n-}\n-\n-/// Parse a sequence of tokens into the representative node tree\n-pub(super) fn parse_with<S: Sink>(\n-    sink: S,\n-    text: &str,\n-    tokens: &[Token],\n-    parser: fn(&mut Parser),\n-) -> S::Tree {\n-    let mut events = {\n-        let input = input::ParserInput::new(text, tokens);\n-        let parser_impl = ParserImpl::new(&input);\n-        let mut parser_api = Parser(parser_impl);\n-        parser(&mut parser_api);\n-        parser_api.0.into_events()\n-    };\n-    EventProcessor::new(sink, text, tokens, &mut events).process().finish()\n-}\n-\n-/// Implementation details of `Parser`, extracted\n-/// to a separate struct in order not to pollute\n-/// the public API of the `Parser`.\n-pub(super) struct ParserImpl<'t> {\n-    parser_input: &'t ParserInput<'t>,\n-    pos: InputPosition,\n-    events: Vec<Event>,\n-    steps: Cell<u32>,\n-}\n-\n-impl<'t> ParserImpl<'t> {\n-    fn new(inp: &'t ParserInput<'t>) -> ParserImpl<'t> {\n-        ParserImpl {\n-            parser_input: inp,\n-            pos: InputPosition::new(),\n-            events: Vec::new(),\n-            steps: Cell::new(0),\n-        }\n-    }\n-\n-    fn into_events(self) -> Vec<Event> {\n-        assert_eq!(self.nth(0), EOF);\n-        self.events\n-    }\n-\n-    pub(super) fn current2(&self) -> Option<(SyntaxKind, SyntaxKind)> {\n-        let c1 = self.parser_input.kind(self.pos);\n-        let c2 = self.parser_input.kind(self.pos + 1);\n-        if self.parser_input.token_start_at(self.pos + 1)\n-            == self.parser_input.token_start_at(self.pos) + self.parser_input.token_len(self.pos)\n-        {\n-            Some((c1, c2))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    pub(super) fn current3(&self) -> Option<(SyntaxKind, SyntaxKind, SyntaxKind)> {\n-        let c1 = self.parser_input.kind(self.pos);\n-        let c2 = self.parser_input.kind(self.pos + 1);\n-        let c3 = self.parser_input.kind(self.pos + 2);\n-        if self.parser_input.token_start_at(self.pos + 1)\n-            == self.parser_input.token_start_at(self.pos) + self.parser_input.token_len(self.pos)\n-            && self.parser_input.token_start_at(self.pos + 2)\n-                == self.parser_input.token_start_at(self.pos + 1)\n-                    + self.parser_input.token_len(self.pos + 1)\n-        {\n-            Some((c1, c2, c3))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    /// Get the syntax kind of the nth token.\n-    pub(super) fn nth(&self, n: u32) -> SyntaxKind {\n-        let steps = self.steps.get();\n-        assert!(steps <= 10_000_000, \"the parser seems stuck\");\n-        self.steps.set(steps + 1);\n-\n-        self.parser_input.kind(self.pos + n)\n-    }\n-\n-    pub(super) fn at_kw(&self, t: &str) -> bool {\n-        self.parser_input.token_text(self.pos) == t\n-    }\n-\n-    /// Start parsing right behind the last event.\n-    pub(super) fn start(&mut self) -> u32 {\n-        let pos = self.events.len() as u32;\n-        self.push_event(Event::tombstone());\n-        pos\n-    }\n-\n-    /// Advances the parser by one token unconditionally.\n-    pub(super) fn bump(&mut self) {\n-        let kind = self.nth(0);\n-        if kind == EOF {\n-            return;\n-        }\n-        self.do_bump(kind, 1);\n-    }\n-\n-    pub(super) fn bump_remap(&mut self, kind: SyntaxKind) {\n-        if self.nth(0) == EOF {\n-            // TODO: panic!?\n-            return;\n-        }\n-        self.do_bump(kind, 1);\n-    }\n-\n-    pub(super) fn bump_compound(&mut self, kind: SyntaxKind, n: u8) {\n-        self.do_bump(kind, n);\n-    }\n-\n-    fn do_bump(&mut self, kind: SyntaxKind, n_raw_tokens: u8) {\n-        self.pos += u32::from(n_raw_tokens);\n-        self.push_event(Event::Token { kind, n_raw_tokens });\n-    }\n-\n-    /// Append one Error event to the back of events.\n-    pub(super) fn error(&mut self, msg: String) {\n-        self.push_event(Event::Error { msg: ParseError(msg) })\n-    }\n-\n-    /// Complete an event with appending a `Finish` event.\n-    pub(super) fn complete(&mut self, pos: u32, kind: SyntaxKind) {\n-        match self.events[pos as usize] {\n-            Event::Start { kind: ref mut slot, .. } => {\n-                *slot = kind;\n-            }\n-            _ => unreachable!(),\n-        }\n-        self.push_event(Event::Finish);\n-    }\n-\n-    /// Ignore the dummy `Start` event.\n-    pub(super) fn abandon(&mut self, pos: u32) {\n-        let idx = pos as usize;\n-        if idx == self.events.len() - 1 {\n-            match self.events.pop() {\n-                Some(Event::Start { kind: TOMBSTONE, forward_parent: None }) => (),\n-                _ => unreachable!(),\n-            }\n-        }\n-    }\n-\n-    /// Save the relative distance of a completed event to its forward_parent.\n-    pub(super) fn precede(&mut self, pos: u32) -> u32 {\n-        let new_pos = self.start();\n-        match self.events[pos as usize] {\n-            Event::Start { ref mut forward_parent, .. } => {\n-                *forward_parent = Some(new_pos - pos);\n-            }\n-            _ => unreachable!(),\n-        }\n-        new_pos\n-    }\n-\n-    fn push_event(&mut self, event: Event) {\n-        self.events.push(event)\n-    }\n-}"}, {"sha": "275d949189aaccee986372c554c0a5f6d230401f", "filename": "crates/ra_syntax/src/parsing/parser_impl/input.rs", "status": "removed", "additions": 0, "deletions": 104, "changes": 104, "blob_url": "https://github.com/rust-lang/rust/blob/96899f8278b787280bd07d9ac9dce29a610ce40d/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs", "raw_url": "https://github.com/rust-lang/rust/raw/96899f8278b787280bd07d9ac9dce29a610ce40d/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Fparser_impl%2Finput.rs?ref=96899f8278b787280bd07d9ac9dce29a610ce40d", "patch": "@@ -1,104 +0,0 @@\n-use crate::{\n-    SyntaxKind, SyntaxKind::EOF, TextRange, TextUnit,\n-    parsing::lexer::Token,\n-};\n-\n-use std::ops::{Add, AddAssign};\n-\n-pub(crate) struct ParserInput<'t> {\n-    text: &'t str,\n-    /// start position of each token(expect whitespace and comment)\n-    /// ```non-rust\n-    ///  struct Foo;\n-    /// ^------^---\n-    /// |      |  ^-\n-    /// 0      7  10\n-    /// ```\n-    /// (token, start_offset): `[(struct, 0), (Foo, 7), (;, 10)]`\n-    start_offsets: Vec<TextUnit>,\n-    /// non-whitespace/comment tokens\n-    /// ```non-rust\n-    /// struct Foo {}\n-    /// ^^^^^^ ^^^ ^^\n-    /// ```\n-    /// tokens: `[struct, Foo, {, }]`\n-    tokens: Vec<Token>,\n-}\n-\n-impl<'t> ParserInput<'t> {\n-    /// Generate input from tokens(expect comment and whitespace).\n-    pub fn new(text: &'t str, raw_tokens: &'t [Token]) -> ParserInput<'t> {\n-        let mut tokens = Vec::new();\n-        let mut start_offsets = Vec::new();\n-        let mut len = 0.into();\n-        for &token in raw_tokens.iter() {\n-            if !token.kind.is_trivia() {\n-                tokens.push(token);\n-                start_offsets.push(len);\n-            }\n-            len += token.len;\n-        }\n-\n-        ParserInput { text, start_offsets, tokens }\n-    }\n-\n-    /// Get the syntax kind of token at given input position.\n-    pub fn kind(&self, pos: InputPosition) -> SyntaxKind {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return EOF;\n-        }\n-        self.tokens[idx].kind\n-    }\n-\n-    /// Get the length of a token at given input position.\n-    pub fn token_len(&self, pos: InputPosition) -> TextUnit {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return 0.into();\n-        }\n-        self.tokens[idx].len\n-    }\n-\n-    /// Get the start position of a taken at given input position.\n-    pub fn token_start_at(&self, pos: InputPosition) -> TextUnit {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return 0.into();\n-        }\n-        self.start_offsets[idx]\n-    }\n-\n-    /// Get the raw text of a token at given input position.\n-    pub fn token_text(&self, pos: InputPosition) -> &'t str {\n-        let idx = pos.0 as usize;\n-        if !(idx < self.tokens.len()) {\n-            return \"\";\n-        }\n-        let range = TextRange::offset_len(self.start_offsets[idx], self.tokens[idx].len);\n-        &self.text[range]\n-    }\n-}\n-\n-#[derive(Copy, Clone, Ord, PartialOrd, Eq, PartialEq)]\n-pub(crate) struct InputPosition(u32);\n-\n-impl InputPosition {\n-    pub fn new() -> Self {\n-        InputPosition(0)\n-    }\n-}\n-\n-impl Add<u32> for InputPosition {\n-    type Output = InputPosition;\n-\n-    fn add(self, rhs: u32) -> InputPosition {\n-        InputPosition(self.0 + rhs)\n-    }\n-}\n-\n-impl AddAssign<u32> for InputPosition {\n-    fn add_assign(&mut self, rhs: u32) {\n-        self.0 += rhs\n-    }\n-}"}, {"sha": "f2d218ab90344a518774bdd8692f70a70acedc64", "filename": "crates/ra_syntax/src/parsing/reparsing.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -4,10 +4,9 @@ use crate::{\n     syntax_node::{GreenNode, SyntaxNode},\n     syntax_error::SyntaxError,\n     parsing::{\n-        grammar,\n-        parser_impl,\n+        grammar, parse_with,\n         builder::GreenBuilder,\n-        parser_api::Parser,\n+        parser::Parser,\n         lexer::{tokenize, Token},\n     }\n };\n@@ -62,8 +61,7 @@ fn reparse_block<'node>(\n     if !is_balanced(&tokens) {\n         return None;\n     }\n-    let (green, new_errors) =\n-        parser_impl::parse_with(GreenBuilder::new(), &text, &tokens, reparser);\n+    let (green, new_errors) = parse_with(GreenBuilder::default(), &text, &tokens, reparser);\n     Some((node, green, new_errors))\n }\n "}, {"sha": "1a00fcc27a33b60105177c54a53e2ead5466a1b1", "filename": "crates/ra_syntax/src/syntax_error.rs", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fsyntax_error.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7/crates%2Fra_syntax%2Fsrc%2Fsyntax_error.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fsyntax_error.rs?ref=c84561bb624280b84eb2fe6c6b2a6b9fe3f1dbf7", "patch": "@@ -1,6 +1,6 @@\n use std::fmt;\n \n-use crate::{TextRange, TextUnit};\n+use crate::{TextRange, TextUnit, parsing::ParseError};\n \n #[derive(Debug, Clone, PartialEq, Eq, Hash)]\n pub struct SyntaxError {\n@@ -95,9 +95,6 @@ pub enum SyntaxErrorKind {\n     InvalidMatchInnerAttr,\n }\n \n-#[derive(Debug, Clone, PartialEq, Eq, Hash)]\n-pub struct ParseError(pub String);\n-\n impl fmt::Display for SyntaxErrorKind {\n     fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n         use self::SyntaxErrorKind::*;"}]}