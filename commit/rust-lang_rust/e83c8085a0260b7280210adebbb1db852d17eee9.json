{"sha": "e83c8085a0260b7280210adebbb1db852d17eee9", "node_id": "MDY6Q29tbWl0NzI0NzEyOmU4M2M4MDg1YTAyNjBiNzI4MDIxMGFkZWJiYjFkYjg1MmQxN2VlZTk=", "commit": {"author": {"name": "Michael Layzell", "email": "michael@thelayzells.com", "date": "2017-08-17T00:08:27Z"}, "committer": {"name": "Michael Layzell", "email": "michael@thelayzells.com", "date": "2017-08-17T00:08:27Z"}, "message": "Don't highlight # which does not start an attribute in rustdoc", "tree": {"sha": "994c7d977dd3a0381565640f99214dd1977613f1", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/994c7d977dd3a0381565640f99214dd1977613f1"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/e83c8085a0260b7280210adebbb1db852d17eee9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/e83c8085a0260b7280210adebbb1db852d17eee9", "html_url": "https://github.com/rust-lang/rust/commit/e83c8085a0260b7280210adebbb1db852d17eee9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/e83c8085a0260b7280210adebbb1db852d17eee9/comments", "author": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a7e0d3a81f224649c8fcfc8ac3cb93f1e1107bea", "url": "https://api.github.com/repos/rust-lang/rust/commits/a7e0d3a81f224649c8fcfc8ac3cb93f1e1107bea", "html_url": "https://github.com/rust-lang/rust/commit/a7e0d3a81f224649c8fcfc8ac3cb93f1e1107bea"}], "stats": {"total": 58, "additions": 43, "deletions": 15}, "files": [{"sha": "239bcb3d69b996f4c110c9120a405492843821db", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 43, "deletions": 15, "changes": 58, "blob_url": "https://github.com/rust-lang/rust/blob/e83c8085a0260b7280210adebbb1db852d17eee9/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/e83c8085a0260b7280210adebbb1db852d17eee9/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=e83c8085a0260b7280210adebbb1db852d17eee9", "patch": "@@ -172,6 +172,21 @@ impl<'a> Classifier<'a> {\n         }\n     }\n \n+    /// Gets the next token out of the lexer, emitting fatal errors if lexing fails.\n+    fn try_next_token(&mut self) -> io::Result<TokenAndSpan> {\n+        match self.lexer.try_next_token() {\n+            Ok(tas) => Ok(tas),\n+            Err(_) => {\n+                self.lexer.emit_fatal_errors();\n+                self.lexer.sess.span_diagnostic\n+                    .struct_warn(\"Backing out of syntax highlighting\")\n+                    .note(\"You probably did not intend to render this as a rust code-block\")\n+                    .emit();\n+                Err(io::Error::new(io::ErrorKind::Other, \"\"))\n+            }\n+        }\n+    }\n+\n     /// Exhausts the `lexer` writing the output into `out`.\n     ///\n     /// The general structure for this method is to iterate over each token,\n@@ -183,18 +198,7 @@ impl<'a> Classifier<'a> {\n                                    out: &mut W)\n                                    -> io::Result<()> {\n         loop {\n-            let next = match self.lexer.try_next_token() {\n-                Ok(tas) => tas,\n-                Err(_) => {\n-                    self.lexer.emit_fatal_errors();\n-                    self.lexer.sess.span_diagnostic\n-                        .struct_warn(\"Backing out of syntax highlighting\")\n-                        .note(\"You probably did not intend to render this as a rust code-block\")\n-                        .emit();\n-                    return Err(io::Error::new(io::ErrorKind::Other, \"\"));\n-                }\n-            };\n-\n+            let next = self.try_next_token()?;\n             if next.tok == token::Eof {\n                 break;\n             }\n@@ -255,13 +259,37 @@ impl<'a> Classifier<'a> {\n                 }\n             }\n \n-            // This is the start of an attribute. We're going to want to\n+            // This might be the start of an attribute. We're going to want to\n             // continue highlighting it as an attribute until the ending ']' is\n             // seen, so skip out early. Down below we terminate the attribute\n             // span when we see the ']'.\n             token::Pound => {\n-                self.in_attribute = true;\n-                out.enter_span(Class::Attribute)?;\n+                // We can't be sure that our # begins an attribute (it could\n+                // just be appearing in a macro) until we read either `#![` or\n+                // `#[` from the input stream.\n+                //\n+                // We don't want to start highlighting as an attribute until\n+                // we're confident there is going to be a ] coming up, as\n+                // otherwise # tokens in macros highlight the rest of the input\n+                // as an attribute.\n+\n+                // Case 1: #![inner_attribute]\n+                if self.lexer.peek().tok == token::Not {\n+                    self.try_next_token()?; // NOTE: consumes `!` token!\n+                    if self.lexer.peek().tok == token::OpenDelim(token::Bracket) {\n+                        self.in_attribute = true;\n+                        out.enter_span(Class::Attribute)?;\n+                    }\n+                    out.string(\"#\", Class::None, None)?;\n+                    out.string(\"!\", Class::None, None)?;\n+                    return Ok(());\n+                }\n+\n+                // Case 2: #[outer_attribute]\n+                if self.lexer.peek().tok == token::OpenDelim(token::Bracket) {\n+                    self.in_attribute = true;\n+                    out.enter_span(Class::Attribute)?;\n+                }\n                 out.string(\"#\", Class::None, None)?;\n                 return Ok(());\n             }"}]}