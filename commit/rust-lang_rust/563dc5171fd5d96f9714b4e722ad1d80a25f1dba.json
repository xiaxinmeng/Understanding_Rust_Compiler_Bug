{"sha": "563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU2M2RjNTE3MWZkNWQ5NmY5NzE0YjRlNzIyYWQxZDgwYTI1ZjFkYmE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-11-10T14:10:07Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2017-11-10T14:10:07Z"}, "message": "Auto merge of #45791 - eddyb:quote-unquote, r=jseyfried\n\nPrefer libproc_macro APIs to libsyntax ones in the quasi-quoter.\n\nThe shift to using `proc_macro`'s own APIs in `proc_macro::quote`, both in the implementation of the quasi-quoter and the Rust code it generates to build `TokenStream`s at runtime, greatly reduces the dependency on `libsyntax`, with the generated runtime code being completely free of it.\n\nThis is a prerequirement for introducing more abstraction/indirection between `proc_macro` and compiler implementation details (mainly those from `libsyntax`), which I want to attempt.\n\ncc @alexcrichton @jseyfried @nrc", "tree": {"sha": "3854bbee93d840c4380e952f8165a6f4e2f70c59", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3854bbee93d840c4380e952f8165a6f4e2f70c59"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "html_url": "https://github.com/rust-lang/rust/commit/563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/563dc5171fd5d96f9714b4e722ad1d80a25f1dba/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "968b6206cb140a51f2e3cc3d7841aed51b0d64d9", "url": "https://api.github.com/repos/rust-lang/rust/commits/968b6206cb140a51f2e3cc3d7841aed51b0d64d9", "html_url": "https://github.com/rust-lang/rust/commit/968b6206cb140a51f2e3cc3d7841aed51b0d64d9"}, {"sha": "fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "url": "https://api.github.com/repos/rust-lang/rust/commits/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac", "html_url": "https://github.com/rust-lang/rust/commit/fbcc6733d46c1582c1a417b5909a2ff0a587f0ac"}], "stats": {"total": 314, "additions": 158, "deletions": 156}, "files": [{"sha": "8a400f3e6360e39573e313dc60e751e23868c634", "filename": "src/libproc_macro/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/563dc5171fd5d96f9714b4e722ad1d80a25f1dba/src%2Flibproc_macro%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/563dc5171fd5d96f9714b4e722ad1d80a25f1dba/src%2Flibproc_macro%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Flib.rs?ref=563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "patch": "@@ -191,7 +191,7 @@ impl Default for Span {\n /// This is needed to implement a custom quoter.\n #[unstable(feature = \"proc_macro\", issue = \"38356\")]\n pub fn quote_span(span: Span) -> TokenStream {\n-    TokenStream(quote::Quote::quote(&span.0))\n+    quote::Quote::quote(span)\n }\n \n macro_rules! diagnostic_method {\n@@ -728,7 +728,7 @@ impl TokenTree {\n #[unstable(feature = \"proc_macro_internals\", issue = \"27812\")]\n #[doc(hidden)]\n pub mod __internal {\n-    pub use quote::{Quoter, __rt};\n+    pub use quote::{LiteralKind, Quoter, unquote};\n \n     use std::cell::Cell;\n "}, {"sha": "26f88ad6bf64937d8819cb0350fa3c8096d76329", "filename": "src/libproc_macro/quote.rs", "status": "modified", "additions": 156, "deletions": 154, "changes": 310, "blob_url": "https://github.com/rust-lang/rust/blob/563dc5171fd5d96f9714b4e722ad1d80a25f1dba/src%2Flibproc_macro%2Fquote.rs", "raw_url": "https://github.com/rust-lang/rust/raw/563dc5171fd5d96f9714b4e722ad1d80a25f1dba/src%2Flibproc_macro%2Fquote.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibproc_macro%2Fquote.rs?ref=563dc5171fd5d96f9714b4e722ad1d80a25f1dba", "patch": "@@ -11,253 +11,255 @@\n //! # Quasiquoter\n //! This file contains the implementation internals of the quasiquoter provided by `quote!`.\n \n-//! This quasiquoter uses macros 2.0 hygiene to reliably use items from `__rt`,\n-//! including re-exported API `libsyntax`, to build a `syntax::tokenstream::TokenStream`\n-//! and wrap it into a `proc_macro::TokenStream`.\n+//! This quasiquoter uses macros 2.0 hygiene to reliably access\n+//! items from `proc_macro`, to build a `proc_macro::TokenStream`.\n+\n+use {Delimiter, Literal, Spacing, Span, Term, TokenNode, TokenStream, TokenTree};\n \n-use syntax::ast::Ident;\n use syntax::ext::base::{ExtCtxt, ProcMacro};\n-use syntax::parse::token::{self, Token, Lit};\n-use syntax::symbol::Symbol;\n-use syntax::tokenstream::{Delimited, TokenTree, TokenStream, TokenStreamBuilder};\n-use syntax_pos::{DUMMY_SP, Span};\n-use syntax_pos::hygiene::SyntaxContext;\n+use syntax::parse::token;\n+use syntax::tokenstream;\n \n pub struct Quoter;\n \n-pub mod __rt {\n-    pub use syntax::ast::Ident;\n-    pub use syntax::parse::token;\n-    pub use syntax::symbol::Symbol;\n-    pub use syntax::tokenstream::{TokenStream, TokenStreamBuilder, TokenTree, Delimited};\n-    pub use super::{ctxt, span};\n-\n-    pub fn unquote<T: Into<::TokenStream> + Clone>(tokens: &T) -> TokenStream {\n-        T::into(tokens.clone()).0\n-    }\n-}\n-\n-pub fn ctxt() -> SyntaxContext {\n-    ::__internal::with_sess(|(_, mark)| SyntaxContext::empty().apply_mark(mark))\n-}\n-\n-pub fn span() -> Span {\n-    ::Span::default().0\n+pub fn unquote<T: Into<TokenStream> + Clone>(tokens: &T) -> TokenStream {\n+    T::into(tokens.clone())\n }\n \n pub trait Quote {\n-    fn quote(&self) -> TokenStream;\n+    fn quote(self) -> TokenStream;\n }\n \n macro_rules! quote_tok {\n-    (,) => { Token::Comma };\n-    (.) => { Token::Dot };\n-    (:) => { Token::Colon };\n-    (::) => { Token::ModSep };\n-    (!) => { Token::Not };\n-    (<) => { Token::Lt };\n-    (>) => { Token::Gt };\n-    (_) => { Token::Underscore };\n-    (0) => { Token::Literal(token::Lit::Integer(Symbol::intern(\"0\")), None) };\n-    (&) => { Token::BinOp(token::And) };\n-    ($i:ident) => { Token::Ident(Ident { name: Symbol::intern(stringify!($i)), ctxt: ctxt() }) };\n+    (,) => { TokenNode::Op(',', Spacing::Alone) };\n+    (.) => { TokenNode::Op('.', Spacing::Alone) };\n+    (:) => { TokenNode::Op(':', Spacing::Alone) };\n+    (::) => {\n+        [\n+            TokenNode::Op(':', Spacing::Joint),\n+            TokenNode::Op(':', Spacing::Alone)\n+        ].iter().cloned().collect::<TokenStream>()\n+    };\n+    (!) => { TokenNode::Op('!', Spacing::Alone) };\n+    (<) => { TokenNode::Op('<', Spacing::Alone) };\n+    (>) => { TokenNode::Op('>', Spacing::Alone) };\n+    (_) => { TokenNode::Op('_', Spacing::Alone) };\n+    (0) => { TokenNode::Literal(::Literal::integer(0)) };\n+    (&) => { TokenNode::Op('&', Spacing::Alone) };\n+    ($i:ident) => { TokenNode::Term(Term::intern(stringify!($i))) };\n }\n \n macro_rules! quote_tree {\n-    ((unquote $($t:tt)*)) => { TokenStream::from($($t)*) };\n+    ((unquote $($t:tt)*)) => { $($t)* };\n     ((quote $($t:tt)*)) => { ($($t)*).quote() };\n-    (($($t:tt)*)) => { delimit(token::Paren, quote!($($t)*)) };\n-    ([$($t:tt)*]) => { delimit(token::Bracket, quote!($($t)*)) };\n-    ({$($t:tt)*}) => { delimit(token::Brace, quote!($($t)*)) };\n-    (rt) => { quote!(::__internal::__rt) };\n-    ($t:tt) => { TokenStream::from(TokenTree::Token(span(), quote_tok!($t))) };\n-}\n-\n-fn delimit(delim: token::DelimToken, stream: TokenStream) -> TokenStream {\n-    TokenTree::Delimited(span(), Delimited { delim: delim, tts: stream.into() }).into()\n+    (($($t:tt)*)) => { TokenNode::Group(Delimiter::Parenthesis, quote!($($t)*)) };\n+    ([$($t:tt)*]) => { TokenNode::Group(Delimiter::Bracket, quote!($($t)*)) };\n+    ({$($t:tt)*}) => { TokenNode::Group(Delimiter::Brace, quote!($($t)*)) };\n+    ($t:tt) => { quote_tok!($t) };\n }\n \n macro_rules! quote {\n     () => { TokenStream::empty() };\n-    ($($t:tt)*) => { [ $( quote_tree!($t), )* ].iter().cloned().collect::<TokenStream>() };\n+    ($($t:tt)*) => {\n+        [\n+            $(TokenStream::from(quote_tree!($t)),)*\n+        ].iter().cloned().collect::<TokenStream>()\n+    };\n }\n \n impl ProcMacro for Quoter {\n-    fn expand<'cx>(&self, cx: &'cx mut ExtCtxt, _: Span, stream: TokenStream) -> TokenStream {\n+    fn expand<'cx>(&self, cx: &'cx mut ExtCtxt,\n+                   _: ::syntax_pos::Span,\n+                   stream: tokenstream::TokenStream)\n+                   -> tokenstream::TokenStream {\n         let mut info = cx.current_expansion.mark.expn_info().unwrap();\n         info.callee.allow_internal_unstable = true;\n         cx.current_expansion.mark.set_expn_info(info);\n-        ::__internal::set_sess(cx, || quote!(::TokenStream { 0: (quote stream) }))\n+        ::__internal::set_sess(cx, || TokenStream(stream).quote().0)\n     }\n }\n \n impl<T: Quote> Quote for Option<T> {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            Some(ref t) => quote!(Some((quote t))),\n+    fn quote(self) -> TokenStream {\n+        match self {\n+            Some(t) => quote!(Some((quote t))),\n             None => quote!(None),\n         }\n     }\n }\n \n impl Quote for TokenStream {\n-    fn quote(&self) -> TokenStream {\n-        let mut builder = TokenStreamBuilder::new();\n-        builder.push(quote!(rt::TokenStreamBuilder::new()));\n-\n-        let mut trees = self.trees();\n-        loop {\n-            let (mut tree, mut is_joint) = match trees.next_as_stream() {\n-                Some(next) => next.as_tree(),\n-                None => return builder.add(quote!(.build())).build(),\n-            };\n-            if let TokenTree::Token(_, Token::Dollar) = tree {\n-                let (next_tree, next_is_joint) = match trees.next_as_stream() {\n-                    Some(next) => next.as_tree(),\n-                    None => panic!(\"unexpected trailing `$` in `quote!`\"),\n-                };\n-                match next_tree {\n-                    TokenTree::Token(_, Token::Ident(..)) => {\n-                        builder.push(quote!(.add(rt::unquote(&(unquote next_tree)))));\n-                        continue\n-                    }\n-                    TokenTree::Token(_, Token::Dollar) => {\n-                        tree = next_tree;\n-                        is_joint = next_is_joint;\n+    fn quote(self) -> TokenStream {\n+        if self.is_empty() {\n+            return quote!(::TokenStream::empty());\n+        }\n+        let mut after_dollar = false;\n+        let tokens = self.into_iter().filter_map(|tree| {\n+            if after_dollar {\n+                after_dollar = false;\n+                match tree.kind {\n+                    TokenNode::Term(_) => {\n+                        return Some(quote!(::__internal::unquote(&(unquote tree)),));\n                     }\n+                    TokenNode::Op('$', _) => {}\n                     _ => panic!(\"`$` must be followed by an ident or `$` in `quote!`\"),\n                 }\n+            } else if let TokenNode::Op('$', _) = tree.kind {\n+                after_dollar = true;\n+                return None;\n             }\n \n-            builder.push(match is_joint {\n-                true => quote!(.add((quote tree).joint())),\n-                false => quote!(.add(rt::TokenStream::from((quote tree)))),\n-            });\n+            Some(quote!(::TokenStream::from((quote tree)),))\n+        }).collect::<TokenStream>();\n+\n+        if after_dollar {\n+            panic!(\"unexpected trailing `$` in `quote!`\");\n         }\n+\n+        quote!([(unquote tokens)].iter().cloned().collect::<::TokenStream>())\n     }\n }\n \n impl Quote for TokenTree {\n-    fn quote(&self) -> TokenStream {\n-        match *self {\n-            TokenTree::Token(span, ref token) => quote! {\n-                rt::TokenTree::Token((quote span), (quote token))\n-            },\n-            TokenTree::Delimited(span, ref delimited) => quote! {\n-                rt::TokenTree::Delimited((quote span), (quote delimited))\n-            },\n-        }\n+    fn quote(self) -> TokenStream {\n+        quote!(::TokenTree { span: (quote self.span), kind: (quote self.kind) })\n     }\n }\n \n-impl Quote for Delimited {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Delimited { delim: (quote self.delim), tts: (quote self.stream()).into() })\n+impl Quote for TokenNode {\n+    fn quote(self) -> TokenStream {\n+        macro_rules! gen_match {\n+            ($($i:ident($($arg:ident),+)),*) => {\n+                match self {\n+                    $(TokenNode::$i($($arg),+) => quote! {\n+                        ::TokenNode::$i($((quote $arg)),+)\n+                    },)*\n+                }\n+            }\n+        }\n+\n+        gen_match! { Op(op, kind), Group(delim, tokens), Term(term), Literal(lit) }\n     }\n }\n \n-impl<'a> Quote for &'a str {\n-    fn quote(&self) -> TokenStream {\n-        TokenTree::Token(span(), Token::Literal(token::Lit::Str_(Symbol::intern(self)), None))\n-            .into()\n+impl Quote for char {\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::character(self)).into()\n     }\n }\n \n-impl Quote for usize {\n-    fn quote(&self) -> TokenStream {\n-        let integer_symbol = Symbol::intern(&self.to_string());\n-        TokenTree::Token(DUMMY_SP, Token::Literal(token::Lit::Integer(integer_symbol), None))\n-            .into()\n+impl<'a> Quote for &'a str {\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::string(self)).into()\n     }\n }\n \n-impl Quote for Ident {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Ident { name: (quote self.name), ctxt: rt::ctxt() })\n+impl Quote for usize {\n+    fn quote(self) -> TokenStream {\n+        TokenNode::Literal(Literal::integer(self as i128)).into()\n     }\n }\n \n-impl Quote for Symbol {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::Symbol::intern((quote &*self.as_str())))\n+impl Quote for Term {\n+    fn quote(self) -> TokenStream {\n+        quote!(::Term::intern((quote self.as_str())))\n     }\n }\n \n impl Quote for Span {\n-    fn quote(&self) -> TokenStream {\n-        quote!(rt::span())\n+    fn quote(self) -> TokenStream {\n+        quote!(::Span::default())\n     }\n }\n \n-impl Quote for Token {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*; $($t:tt)*) => {\n-                match *self {\n-                    $( Token::$i => quote!(rt::token::$i), )*\n-                    $( $t )*\n+macro_rules! literals {\n+    ($($i:ident),*; $($raw:ident),*) => {\n+        pub enum LiteralKind {\n+            $($i,)*\n+            $($raw(usize),)*\n+        }\n+\n+        impl LiteralKind {\n+            pub fn with_contents_and_suffix(self, contents: Term, suffix: Option<Term>)\n+                                            -> Literal {\n+                let contents = contents.0;\n+                let suffix = suffix.map(|t| t.0);\n+                match self {\n+                    $(LiteralKind::$i => {\n+                        Literal(token::Literal(token::Lit::$i(contents), suffix))\n+                    })*\n+                    $(LiteralKind::$raw(n) => {\n+                        Literal(token::Literal(token::Lit::$raw(contents, n), suffix))\n+                    })*\n                 }\n             }\n         }\n \n-        gen_match! {\n-            Eq, Lt, Le, EqEq, Ne, Ge, Gt, AndAnd, OrOr, Not, Tilde, At, Dot, DotDot, DotDotDot,\n-            DotDotEq, Comma, Semi, Colon, ModSep, RArrow, LArrow, FatArrow, Pound, Dollar,\n-            Question, Underscore;\n-\n-            Token::OpenDelim(delim) => quote!(rt::token::OpenDelim((quote delim))),\n-            Token::CloseDelim(delim) => quote!(rt::token::CloseDelim((quote delim))),\n-            Token::BinOp(tok) => quote!(rt::token::BinOp((quote tok))),\n-            Token::BinOpEq(tok) => quote!(rt::token::BinOpEq((quote tok))),\n-            Token::Ident(ident) => quote!(rt::token::Ident((quote ident))),\n-            Token::Lifetime(ident) => quote!(rt::token::Lifetime((quote ident))),\n-            Token::Literal(lit, sfx) => quote!(rt::token::Literal((quote lit), (quote sfx))),\n-            _ => panic!(\"Unhandled case!\"),\n+        impl Literal {\n+            fn kind_contents_and_suffix(self) -> (LiteralKind, Term, Option<Term>) {\n+                let (lit, suffix) = match self.0 {\n+                    token::Literal(lit, suffix) => (lit, suffix),\n+                    _ => panic!(\"unsupported literal {:?}\", self.0),\n+                };\n+\n+                let (kind, contents) = match lit {\n+                    $(token::Lit::$i(contents) => (LiteralKind::$i, contents),)*\n+                    $(token::Lit::$raw(contents, n) => (LiteralKind::$raw(n), contents),)*\n+                };\n+                (kind, Term(contents), suffix.map(Term))\n+            }\n         }\n-    }\n-}\n \n-impl Quote for token::BinOpToken {\n-    fn quote(&self) -> TokenStream {\n-        macro_rules! gen_match {\n-            ($($i:ident),*) => {\n-                match *self {\n-                    $( token::BinOpToken::$i => quote!(rt::token::BinOpToken::$i), )*\n+        impl Quote for LiteralKind {\n+            fn quote(self) -> TokenStream {\n+                match self {\n+                    $(LiteralKind::$i => quote! {\n+                        ::__internal::LiteralKind::$i\n+                    },)*\n+                    $(LiteralKind::$raw(n) => quote! {\n+                        ::__internal::LiteralKind::$raw((quote n))\n+                    },)*\n                 }\n             }\n         }\n \n-        gen_match!(Plus, Minus, Star, Slash, Percent, Caret, And, Or, Shl, Shr)\n+        impl Quote for Literal {\n+            fn quote(self) -> TokenStream {\n+                let (kind, contents, suffix) = self.kind_contents_and_suffix();\n+                quote! {\n+                    (quote kind).with_contents_and_suffix((quote contents), (quote suffix))\n+                }\n+            }\n+        }\n     }\n }\n \n-impl Quote for Lit {\n-    fn quote(&self) -> TokenStream {\n+literals!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw);\n+\n+impl Quote for Delimiter {\n+    fn quote(self) -> TokenStream {\n         macro_rules! gen_match {\n-            ($($i:ident),*; $($raw:ident),*) => {\n-                match *self {\n-                    $( Lit::$i(lit) => quote!(rt::token::Lit::$i((quote lit))), )*\n-                    $( Lit::$raw(lit, n) => {\n-                        quote!(::syntax::parse::token::Lit::$raw((quote lit), (quote n)))\n-                    })*\n+            ($($i:ident),*) => {\n+                match self {\n+                    $(Delimiter::$i => { quote!(::Delimiter::$i) })*\n                 }\n             }\n         }\n \n-        gen_match!(Byte, Char, Float, Str_, Integer, ByteStr; StrRaw, ByteStrRaw)\n+        gen_match!(Parenthesis, Brace, Bracket, None)\n     }\n }\n \n-impl Quote for token::DelimToken {\n-    fn quote(&self) -> TokenStream {\n+impl Quote for Spacing {\n+    fn quote(self) -> TokenStream {\n         macro_rules! gen_match {\n             ($($i:ident),*) => {\n-                match *self {\n-                    $(token::DelimToken::$i => { quote!(rt::token::DelimToken::$i) })*\n+                match self {\n+                    $(Spacing::$i => { quote!(::Spacing::$i) })*\n                 }\n             }\n         }\n \n-        gen_match!(Paren, Bracket, Brace, NoDelim)\n+        gen_match!(Alone, Joint)\n     }\n }"}]}