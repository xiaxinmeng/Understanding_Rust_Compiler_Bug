{"sha": "c0c57acd7b8061697d196fd800a7ff3151c37f38", "node_id": "MDY6Q29tbWl0NzI0NzEyOmMwYzU3YWNkN2I4MDYxNjk3ZDE5NmZkODAwYTdmZjMxNTFjMzdmMzg=", "commit": {"author": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-04T21:02:59Z"}, "committer": {"name": "Vadim Petrochenkov", "email": "vadim.petrochenkov@gmail.com", "date": "2019-06-06T11:03:15Z"}, "message": "syntax: Use `Token` in `StringReader` and `TokenTreesReader`", "tree": {"sha": "60a34ef9211243a932a90f0fec3bd5f4e82fcd1d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/60a34ef9211243a932a90f0fec3bd5f4e82fcd1d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c0c57acd7b8061697d196fd800a7ff3151c37f38", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c0c57acd7b8061697d196fd800a7ff3151c37f38", "html_url": "https://github.com/rust-lang/rust/commit/c0c57acd7b8061697d196fd800a7ff3151c37f38", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c0c57acd7b8061697d196fd800a7ff3151c37f38/comments", "author": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "committer": {"login": "petrochenkov", "id": 5751617, "node_id": "MDQ6VXNlcjU3NTE2MTc=", "avatar_url": "https://avatars.githubusercontent.com/u/5751617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petrochenkov", "html_url": "https://github.com/petrochenkov", "followers_url": "https://api.github.com/users/petrochenkov/followers", "following_url": "https://api.github.com/users/petrochenkov/following{/other_user}", "gists_url": "https://api.github.com/users/petrochenkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/petrochenkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petrochenkov/subscriptions", "organizations_url": "https://api.github.com/users/petrochenkov/orgs", "repos_url": "https://api.github.com/users/petrochenkov/repos", "events_url": "https://api.github.com/users/petrochenkov/events{/privacy}", "received_events_url": "https://api.github.com/users/petrochenkov/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e0127dbf8135b766a332ce21c4eee48998b59bef", "url": "https://api.github.com/repos/rust-lang/rust/commits/e0127dbf8135b766a332ce21c4eee48998b59bef", "html_url": "https://github.com/rust-lang/rust/commit/e0127dbf8135b766a332ce21c4eee48998b59bef"}], "stats": {"total": 88, "additions": 37, "deletions": 51}, "files": [{"sha": "bc6eaaaa8b9f00e87ee56e81cda7894fbdbe974f", "filename": "src/librustdoc/html/highlight.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustdoc%2Fhtml%2Fhighlight.rs?ref=c0c57acd7b8061697d196fd800a7ff3151c37f38", "patch": "@@ -234,7 +234,7 @@ impl<'a> Classifier<'a> {\n             // reference or dereference operator or a reference or pointer type, instead of the\n             // bit-and or multiplication operator.\n             token::BinOp(token::And) | token::BinOp(token::Star)\n-                if self.lexer.peek() != token::Whitespace => Class::RefKeyWord,\n+                if self.lexer.peek() != &token::Whitespace => Class::RefKeyWord,\n \n             // Consider this as part of a macro invocation if there was a\n             // leading identifier.\n@@ -280,9 +280,9 @@ impl<'a> Classifier<'a> {\n                 // as an attribute.\n \n                 // Case 1: #![inner_attribute]\n-                if self.lexer.peek() == token::Not {\n+                if self.lexer.peek() == &token::Not {\n                     self.try_next_token()?; // NOTE: consumes `!` token!\n-                    if self.lexer.peek() == token::OpenDelim(token::Bracket) {\n+                    if self.lexer.peek() == &token::OpenDelim(token::Bracket) {\n                         self.in_attribute = true;\n                         out.enter_span(Class::Attribute)?;\n                     }\n@@ -292,7 +292,7 @@ impl<'a> Classifier<'a> {\n                 }\n \n                 // Case 2: #[outer_attribute]\n-                if self.lexer.peek() == token::OpenDelim(token::Bracket) {\n+                if self.lexer.peek() == &token::OpenDelim(token::Bracket) {\n                     self.in_attribute = true;\n                     out.enter_span(Class::Attribute)?;\n                 }\n@@ -341,7 +341,7 @@ impl<'a> Classifier<'a> {\n                         if self.in_macro_nonterminal {\n                             self.in_macro_nonterminal = false;\n                             Class::MacroNonTerminal\n-                        } else if self.lexer.peek() == token::Not {\n+                        } else if self.lexer.peek() == &token::Not {\n                             self.in_macro = true;\n                             Class::Macro\n                         } else {"}, {"sha": "9dba5ff3e8c84f53a5627cde37e4d2a84741e688", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 12, "deletions": 23, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=c0c57acd7b8061697d196fd800a7ff3151c37f38", "patch": "@@ -12,7 +12,6 @@ use core::unicode::property::Pattern_White_Space;\n use std::borrow::Cow;\n use std::char;\n use std::iter;\n-use std::mem::replace;\n use rustc_data_structures::sync::Lrc;\n use log::debug;\n \n@@ -41,8 +40,7 @@ pub struct StringReader<'a> {\n     /// Stop reading src at this index.\n     crate end_src_index: usize,\n     // cached:\n-    peek_tok: TokenKind,\n-    peek_span: Span,\n+    peek_token: Token,\n     peek_span_src_raw: Span,\n     fatal_errs: Vec<DiagnosticBuilder<'a>>,\n     // cache a direct reference to the source text, so that we don't have to\n@@ -90,10 +88,7 @@ impl<'a> StringReader<'a> {\n     /// Returns the next token. EFFECT: advances the string_reader.\n     pub fn try_next_token(&mut self) -> Result<Token, ()> {\n         assert!(self.fatal_errs.is_empty());\n-        let ret_val = Token {\n-            kind: replace(&mut self.peek_tok, token::Whitespace),\n-            span: self.peek_span,\n-        };\n+        let ret_val = self.peek_token.clone();\n         self.advance_token()?;\n         Ok(ret_val)\n     }\n@@ -158,7 +153,7 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn fatal(&self, m: &str) -> FatalError {\n-        self.fatal_span(self.peek_span, m)\n+        self.fatal_span(self.peek_token.span, m)\n     }\n \n     crate fn emit_fatal_errors(&mut self) {\n@@ -179,12 +174,8 @@ impl<'a> StringReader<'a> {\n         buffer\n     }\n \n-    pub fn peek(&self) -> Token {\n-        // FIXME(pcwalton): Bad copy!\n-        Token {\n-            kind: self.peek_tok.clone(),\n-            span: self.peek_span,\n-        }\n+    pub fn peek(&self) -> &Token {\n+        &self.peek_token\n     }\n \n     /// For comments.rs, which hackily pokes into next_pos and ch\n@@ -215,8 +206,7 @@ impl<'a> StringReader<'a> {\n             source_file,\n             end_src_index: src.len(),\n             // dummy values; not read\n-            peek_tok: token::Eof,\n-            peek_span: syntax_pos::DUMMY_SP,\n+            peek_token: Token { kind: token::Eof, span: syntax_pos::DUMMY_SP },\n             peek_span_src_raw: syntax_pos::DUMMY_SP,\n             src,\n             fatal_errs: Vec::new(),\n@@ -321,29 +311,28 @@ impl<'a> StringReader<'a> {\n         self.err_span_(from_pos, to_pos, &m[..]);\n     }\n \n-    /// Advance peek_tok and peek_span to refer to the next token, and\n+    /// Advance peek_token to refer to the next token, and\n     /// possibly update the interner.\n     fn advance_token(&mut self) -> Result<(), ()> {\n         match self.scan_whitespace_or_comment() {\n             Some(comment) => {\n                 self.peek_span_src_raw = comment.span;\n-                self.peek_span = comment.span;\n-                self.peek_tok = comment.kind;\n+                self.peek_token = comment;\n             }\n             None => {\n                 if self.is_eof() {\n-                    self.peek_tok = token::Eof;\n+\n                     let (real, raw) = self.mk_sp_and_raw(\n                         self.source_file.end_pos,\n                         self.source_file.end_pos,\n                     );\n-                    self.peek_span = real;\n+                    self.peek_token = Token { kind: token::Eof, span: real };\n                     self.peek_span_src_raw = raw;\n                 } else {\n                     let start_bytepos = self.pos;\n-                    self.peek_tok = self.next_token_inner()?;\n+                    let kind = self.next_token_inner()?;\n                     let (real, raw) = self.mk_sp_and_raw(start_bytepos, self.pos);\n-                    self.peek_span = real;\n+                    self.peek_token = Token { kind, span: real };\n                     self.peek_span_src_raw = raw;\n                 };\n             }"}, {"sha": "0dab441c96f17db855a50973b2a94e218607fa14", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 20, "deletions": 23, "changes": 43, "blob_url": "https://github.com/rust-lang/rust/blob/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c0c57acd7b8061697d196fd800a7ff3151c37f38/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=c0c57acd7b8061697d196fd800a7ff3151c37f38", "patch": "@@ -2,15 +2,15 @@ use syntax_pos::Span;\n \n use crate::print::pprust::token_to_string;\n use crate::parse::lexer::{StringReader, UnmatchedBrace};\n-use crate::parse::{token, PResult};\n+use crate::parse::token::{self, Token};\n+use crate::parse::PResult;\n use crate::tokenstream::{DelimSpan, IsJoint::*, TokenStream, TokenTree, TreeAndJoint};\n \n impl<'a> StringReader<'a> {\n     crate fn into_token_trees(self) -> (PResult<'a, TokenStream>, Vec<UnmatchedBrace>) {\n         let mut tt_reader = TokenTreesReader {\n             string_reader: self,\n-            token: token::Eof,\n-            span: syntax_pos::DUMMY_SP,\n+            token: token::Token { kind: token::Eof, span: syntax_pos::DUMMY_SP },\n             open_braces: Vec::new(),\n             unmatched_braces: Vec::new(),\n             matching_delim_spans: Vec::new(),\n@@ -23,8 +23,7 @@ impl<'a> StringReader<'a> {\n \n struct TokenTreesReader<'a> {\n     string_reader: StringReader<'a>,\n-    token: token::TokenKind,\n-    span: Span,\n+    token: Token,\n     /// Stack of open delimiters and their spans. Used for error message.\n     open_braces: Vec<(token::DelimToken, Span)>,\n     unmatched_braces: Vec<UnmatchedBrace>,\n@@ -52,7 +51,7 @@ impl<'a> TokenTreesReader<'a> {\n     fn parse_token_trees_until_close_delim(&mut self) -> TokenStream {\n         let mut tts = vec![];\n         loop {\n-            if let token::CloseDelim(..) = self.token {\n+            if let token::CloseDelim(..) = self.token.kind {\n                 return TokenStream::new(tts);\n             }\n \n@@ -68,11 +67,11 @@ impl<'a> TokenTreesReader<'a> {\n \n     fn parse_token_tree(&mut self) -> PResult<'a, TreeAndJoint> {\n         let sm = self.string_reader.sess.source_map();\n-        match self.token {\n+        match self.token.kind {\n             token::Eof => {\n                 let msg = \"this file contains an un-closed delimiter\";\n                 let mut err = self.string_reader.sess.span_diagnostic\n-                    .struct_span_err(self.span, msg);\n+                    .struct_span_err(self.token.span, msg);\n                 for &(_, sp) in &self.open_braces {\n                     err.span_label(sp, \"un-closed delimiter\");\n                 }\n@@ -102,10 +101,10 @@ impl<'a> TokenTreesReader<'a> {\n             },\n             token::OpenDelim(delim) => {\n                 // The span for beginning of the delimited section\n-                let pre_span = self.span;\n+                let pre_span = self.token.span;\n \n                 // Parse the open delimiter.\n-                self.open_braces.push((delim, self.span));\n+                self.open_braces.push((delim, self.token.span));\n                 self.real_token();\n \n                 // Parse the token trees within the delimiters.\n@@ -114,9 +113,9 @@ impl<'a> TokenTreesReader<'a> {\n                 let tts = self.parse_token_trees_until_close_delim();\n \n                 // Expand to cover the entire delimited token tree\n-                let delim_span = DelimSpan::from_pair(pre_span, self.span);\n+                let delim_span = DelimSpan::from_pair(pre_span, self.token.span);\n \n-                match self.token {\n+                match self.token.kind {\n                     // Correct delimiter.\n                     token::CloseDelim(d) if d == delim => {\n                         let (open_brace, open_brace_span) = self.open_braces.pop().unwrap();\n@@ -126,7 +125,7 @@ impl<'a> TokenTreesReader<'a> {\n                             self.matching_delim_spans.clear();\n                         } else {\n                             self.matching_delim_spans.push(\n-                                (open_brace, open_brace_span, self.span),\n+                                (open_brace, open_brace_span, self.token.span),\n                             );\n                         }\n                         // Parse the close delimiter.\n@@ -136,16 +135,16 @@ impl<'a> TokenTreesReader<'a> {\n                     token::CloseDelim(other) => {\n                         let mut unclosed_delimiter = None;\n                         let mut candidate = None;\n-                        if self.last_unclosed_found_span != Some(self.span) {\n+                        if self.last_unclosed_found_span != Some(self.token.span) {\n                             // do not complain about the same unclosed delimiter multiple times\n-                            self.last_unclosed_found_span = Some(self.span);\n+                            self.last_unclosed_found_span = Some(self.token.span);\n                             // This is a conservative error: only report the last unclosed\n                             // delimiter. The previous unclosed delimiters could actually be\n                             // closed! The parser just hasn't gotten to them yet.\n                             if let Some(&(_, sp)) = self.open_braces.last() {\n                                 unclosed_delimiter = Some(sp);\n                             };\n-                            if let Some(current_padding) = sm.span_to_margin(self.span) {\n+                            if let Some(current_padding) = sm.span_to_margin(self.token.span) {\n                                 for (brace, brace_span) in &self.open_braces {\n                                     if let Some(padding) = sm.span_to_margin(*brace_span) {\n                                         // high likelihood of these two corresponding\n@@ -159,7 +158,7 @@ impl<'a> TokenTreesReader<'a> {\n                             self.unmatched_braces.push(UnmatchedBrace {\n                                 expected_delim: tok,\n                                 found_delim: other,\n-                                found_span: self.span,\n+                                found_span: self.token.span,\n                                 unclosed_span: unclosed_delimiter,\n                                 candidate_span: candidate,\n                             });\n@@ -198,12 +197,12 @@ impl<'a> TokenTreesReader<'a> {\n                 let token_str = token_to_string(&self.token);\n                 let msg = format!(\"unexpected close delimiter: `{}`\", token_str);\n                 let mut err = self.string_reader.sess.span_diagnostic\n-                    .struct_span_err(self.span, &msg);\n-                err.span_label(self.span, \"unexpected close delimiter\");\n+                    .struct_span_err(self.token.span, &msg);\n+                err.span_label(self.token.span, \"unexpected close delimiter\");\n                 Err(err)\n             },\n             _ => {\n-                let tt = TokenTree::token(self.span, self.token.clone());\n+                let tt = TokenTree::Token(self.token.clone());\n                 // Note that testing for joint-ness here is done via the raw\n                 // source span as the joint-ness is a property of the raw source\n                 // rather than wanting to take `override_span` into account.\n@@ -219,8 +218,6 @@ impl<'a> TokenTreesReader<'a> {\n     }\n \n     fn real_token(&mut self) {\n-        let t = self.string_reader.real_token();\n-        self.token = t.kind;\n-        self.span = t.span;\n+        self.token = self.string_reader.real_token();\n     }\n }"}]}