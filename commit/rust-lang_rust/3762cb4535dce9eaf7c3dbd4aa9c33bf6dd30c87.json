{"sha": "3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87", "node_id": "MDY6Q29tbWl0NzI0NzEyOjM3NjJjYjQ1MzVkY2U5ZWFmN2MzZGJkNGFhOWMzM2JmNmRkMzBjODc=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2021-06-22T22:28:43Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2021-06-22T22:28:43Z"}, "message": "Merge #9383\n\n9383: internal: Rewrite token tree lowering to use an explicit stack r=jonas-schievink a=jonas-schievink\n\nPart of https://github.com/rust-analyzer/rust-analyzer/issues/9358, this fixes the first cause of the stack overflow there. Unfortunately we now run into a stack overflow in the parser.\r\n\r\nbors r+\n\nCo-authored-by: Jonas Schievink <jonasschievink@gmail.com>", "tree": {"sha": "d842fcbf296548edee40553157fef124ce9aab74", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d842fcbf296548edee40553157fef124ce9aab74"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJg0mQbCRBK7hj4Ov3rIwAADpgIALMNQSvSFn2bH3iBpLWXqjXZ\nIIJ3WouLw6BB4DEq6BDQuE7QBXzvEN6V89+/+Zm4f6JjfgA2Y3k9MQZODYWLUDLz\na/aFyhIVvjwuD+ARRqU6ZM/8H3HGMfs4iF1JVVceB3sA9rheuERROjw/yPG1syGn\n7sH7KZEOt7T6u3XiPvEHmBIMiVEtExV8ofF9Crq/mLjAWmYFi2SUrFn73pIS4At0\nZXymCdScrT7LALwAQHqjED578pgQmXBd7DLcmZXQ2KrSNdI4V2Dp+ua43L3OsBSc\nypA6L1xxRerGn4ZLtnSapAY+Nqxu11jpHfMGt+gQdXB4RUvp7/qDaSgzJQfcly4=\n=HDLj\n-----END PGP SIGNATURE-----\n", "payload": "tree d842fcbf296548edee40553157fef124ce9aab74\nparent 38da41ea6e58255223686104b3fbca27392d8162\nparent c6669776e1174170c157b685a66026d1a31ede85\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1624400923 +0000\ncommitter GitHub <noreply@github.com> 1624400923 +0000\n\nMerge #9383\n\n9383: internal: Rewrite token tree lowering to use an explicit stack r=jonas-schievink a=jonas-schievink\n\nPart of https://github.com/rust-analyzer/rust-analyzer/issues/9358, this fixes the first cause of the stack overflow there. Unfortunately we now run into a stack overflow in the parser.\r\n\r\nbors r+\n\nCo-authored-by: Jonas Schievink <jonasschievink@gmail.com>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87", "html_url": "https://github.com/rust-lang/rust/commit/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "38da41ea6e58255223686104b3fbca27392d8162", "url": "https://api.github.com/repos/rust-lang/rust/commits/38da41ea6e58255223686104b3fbca27392d8162", "html_url": "https://github.com/rust-lang/rust/commit/38da41ea6e58255223686104b3fbca27392d8162"}, {"sha": "c6669776e1174170c157b685a66026d1a31ede85", "url": "https://api.github.com/repos/rust-lang/rust/commits/c6669776e1174170c157b685a66026d1a31ede85", "html_url": "https://github.com/rust-lang/rust/commit/c6669776e1174170c157b685a66026d1a31ede85"}], "stats": {"total": 288, "additions": 164, "deletions": 124}, "files": [{"sha": "ae6058cbc8892e75fe70153663fdce6b88218faa", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 164, "deletions": 124, "changes": 288, "blob_url": "https://github.com/rust-lang/rust/blob/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=3762cb4535dce9eaf7c3dbd4aa9c33bf6dd30c87", "patch": "@@ -24,7 +24,7 @@ pub fn ast_to_token_tree(ast: &impl ast::AstNode) -> (tt::Subtree, TokenMap) {\n pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> (tt::Subtree, TokenMap) {\n     let global_offset = node.text_range().start();\n     let mut c = Convertor::new(node, global_offset);\n-    let subtree = c.go();\n+    let subtree = convert_tokens(&mut c);\n     c.id_alloc.map.shrink_to_fit();\n     (subtree, c.id_alloc.map)\n }\n@@ -80,7 +80,7 @@ pub fn parse_to_token_tree(text: &str) -> Option<(tt::Subtree, TokenMap)> {\n         },\n     };\n \n-    let subtree = conv.go();\n+    let subtree = convert_tokens(&mut conv);\n     Some((subtree, conv.id_alloc.map))\n }\n \n@@ -121,6 +121,159 @@ pub fn parse_exprs_with_sep(tt: &tt::Subtree, sep: char) -> Vec<tt::Subtree> {\n     res\n }\n \n+fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n+    struct StackEntry {\n+        subtree: tt::Subtree,\n+        idx: usize,\n+        open_range: TextRange,\n+    }\n+\n+    let entry = StackEntry {\n+        subtree: tt::Subtree { delimiter: None, ..Default::default() },\n+        // never used (delimiter is `None`)\n+        idx: !0,\n+        open_range: TextRange::empty(TextSize::of('.')),\n+    };\n+    let mut stack = vec![entry];\n+\n+    loop {\n+        let entry = stack.last_mut().unwrap();\n+        let result = &mut entry.subtree.token_trees;\n+        let (token, range) = match conv.bump() {\n+            None => break,\n+            Some(it) => it,\n+        };\n+\n+        let k: SyntaxKind = token.kind();\n+        if k == COMMENT {\n+            if let Some(tokens) = conv.convert_doc_comment(&token) {\n+                result.extend(tokens);\n+            }\n+            continue;\n+        }\n+\n+        result.push(if k.is_punct() && k != UNDERSCORE {\n+            assert_eq!(range.len(), TextSize::of('.'));\n+\n+            if let Some(delim) = entry.subtree.delimiter {\n+                let expected = match delim.kind {\n+                    tt::DelimiterKind::Parenthesis => T![')'],\n+                    tt::DelimiterKind::Brace => T!['}'],\n+                    tt::DelimiterKind::Bracket => T![']'],\n+                };\n+\n+                if k == expected {\n+                    let entry = stack.pop().unwrap();\n+                    conv.id_alloc().close_delim(entry.idx, Some(range));\n+                    stack.last_mut().unwrap().subtree.token_trees.push(entry.subtree.into());\n+                    continue;\n+                }\n+            }\n+\n+            let delim = match k {\n+                T!['('] => Some(tt::DelimiterKind::Parenthesis),\n+                T!['{'] => Some(tt::DelimiterKind::Brace),\n+                T!['['] => Some(tt::DelimiterKind::Bracket),\n+                _ => None,\n+            };\n+\n+            if let Some(kind) = delim {\n+                let mut subtree = tt::Subtree::default();\n+                let (id, idx) = conv.id_alloc().open_delim(range);\n+                subtree.delimiter = Some(tt::Delimiter { id, kind });\n+                stack.push(StackEntry { subtree, idx, open_range: range });\n+                continue;\n+            } else {\n+                let spacing = match conv.peek() {\n+                    Some(next)\n+                        if next.kind().is_trivia()\n+                            || next.kind() == T!['[']\n+                            || next.kind() == T!['{']\n+                            || next.kind() == T!['('] =>\n+                    {\n+                        tt::Spacing::Alone\n+                    }\n+                    Some(next) if next.kind().is_punct() && next.kind() != UNDERSCORE => {\n+                        tt::Spacing::Joint\n+                    }\n+                    _ => tt::Spacing::Alone,\n+                };\n+                let char = match token.to_char() {\n+                    Some(c) => c,\n+                    None => {\n+                        panic!(\"Token from lexer must be single char: token = {:#?}\", token);\n+                    }\n+                };\n+                tt::Leaf::from(tt::Punct { char, spacing, id: conv.id_alloc().alloc(range) }).into()\n+            }\n+        } else {\n+            macro_rules! make_leaf {\n+                ($i:ident) => {\n+                    tt::$i { id: conv.id_alloc().alloc(range), text: token.to_text() }.into()\n+                };\n+            }\n+            let leaf: tt::Leaf = match k {\n+                T![true] | T![false] => make_leaf!(Ident),\n+                IDENT => make_leaf!(Ident),\n+                UNDERSCORE => make_leaf!(Ident),\n+                k if k.is_keyword() => make_leaf!(Ident),\n+                k if k.is_literal() => make_leaf!(Literal),\n+                LIFETIME_IDENT => {\n+                    let char_unit = TextSize::of('\\'');\n+                    let r = TextRange::at(range.start(), char_unit);\n+                    let apostrophe = tt::Leaf::from(tt::Punct {\n+                        char: '\\'',\n+                        spacing: tt::Spacing::Joint,\n+                        id: conv.id_alloc().alloc(r),\n+                    });\n+                    result.push(apostrophe.into());\n+\n+                    let r = TextRange::at(range.start() + char_unit, range.len() - char_unit);\n+                    let ident = tt::Leaf::from(tt::Ident {\n+                        text: SmolStr::new(&token.to_text()[1..]),\n+                        id: conv.id_alloc().alloc(r),\n+                    });\n+                    result.push(ident.into());\n+                    continue;\n+                }\n+                _ => continue,\n+            };\n+\n+            leaf.into()\n+        });\n+    }\n+\n+    // If we get here, we've consumed all input tokens.\n+    // We might have more than one subtree in the stack, if the delimiters are improperly balanced.\n+    // Merge them so we're left with one.\n+    while stack.len() > 1 {\n+        let entry = stack.pop().unwrap();\n+        let parent = stack.last_mut().unwrap();\n+\n+        conv.id_alloc().close_delim(entry.idx, None);\n+        let leaf: tt::Leaf = tt::Punct {\n+            id: conv.id_alloc().alloc(entry.open_range),\n+            char: match entry.subtree.delimiter.unwrap().kind {\n+                tt::DelimiterKind::Parenthesis => '(',\n+                tt::DelimiterKind::Brace => '{',\n+                tt::DelimiterKind::Bracket => '[',\n+            },\n+            spacing: tt::Spacing::Alone,\n+        }\n+        .into();\n+        parent.subtree.token_trees.push(leaf.into());\n+        parent.subtree.token_trees.extend(entry.subtree.token_trees);\n+    }\n+\n+    let subtree = stack.pop().unwrap().subtree;\n+    if subtree.token_trees.len() == 1 {\n+        if let tt::TokenTree::Subtree(first) = &subtree.token_trees[0] {\n+            return first.clone();\n+        }\n+    }\n+    subtree\n+}\n+\n /// Returns the textual content of a doc comment block as a quoted string\n /// That is, strips leading `///` (or `/**`, etc)\n /// and strips the ending `*/`\n@@ -242,128 +395,6 @@ trait SrcToken: std::fmt::Debug {\n trait TokenConvertor {\n     type Token: SrcToken;\n \n-    fn go(&mut self) -> tt::Subtree {\n-        let mut subtree = tt::Subtree { delimiter: None, ..Default::default() };\n-        while self.peek().is_some() {\n-            self.collect_leaf(&mut subtree.token_trees);\n-        }\n-        if subtree.token_trees.len() == 1 {\n-            if let tt::TokenTree::Subtree(first) = &subtree.token_trees[0] {\n-                return first.clone();\n-            }\n-        }\n-        subtree\n-    }\n-\n-    fn collect_leaf(&mut self, result: &mut Vec<tt::TokenTree>) {\n-        let (token, range) = match self.bump() {\n-            None => return,\n-            Some(it) => it,\n-        };\n-\n-        let k: SyntaxKind = token.kind();\n-        if k == COMMENT {\n-            if let Some(tokens) = self.convert_doc_comment(&token) {\n-                result.extend(tokens);\n-            }\n-            return;\n-        }\n-\n-        result.push(if k.is_punct() && k != UNDERSCORE {\n-            assert_eq!(range.len(), TextSize::of('.'));\n-            let delim = match k {\n-                T!['('] => Some((tt::DelimiterKind::Parenthesis, T![')'])),\n-                T!['{'] => Some((tt::DelimiterKind::Brace, T!['}'])),\n-                T!['['] => Some((tt::DelimiterKind::Bracket, T![']'])),\n-                _ => None,\n-            };\n-\n-            if let Some((kind, closed)) = delim {\n-                let mut subtree = tt::Subtree::default();\n-                let (id, idx) = self.id_alloc().open_delim(range);\n-                subtree.delimiter = Some(tt::Delimiter { id, kind });\n-\n-                while self.peek().map_or(false, |it| it.kind() != closed) {\n-                    self.collect_leaf(&mut subtree.token_trees);\n-                }\n-                let last_range = match self.bump() {\n-                    None => {\n-                        // For error resilience, we insert an char punct for the opening delim here\n-                        self.id_alloc().close_delim(idx, None);\n-                        let leaf: tt::Leaf = tt::Punct {\n-                            id: self.id_alloc().alloc(range),\n-                            char: token.to_char().unwrap(),\n-                            spacing: tt::Spacing::Alone,\n-                        }\n-                        .into();\n-                        result.push(leaf.into());\n-                        result.extend(subtree.token_trees);\n-                        return;\n-                    }\n-                    Some(it) => it.1,\n-                };\n-                self.id_alloc().close_delim(idx, Some(last_range));\n-                subtree.into()\n-            } else {\n-                let spacing = match self.peek() {\n-                    Some(next)\n-                        if next.kind().is_trivia()\n-                            || next.kind() == T!['[']\n-                            || next.kind() == T!['{']\n-                            || next.kind() == T!['('] =>\n-                    {\n-                        tt::Spacing::Alone\n-                    }\n-                    Some(next) if next.kind().is_punct() && next.kind() != UNDERSCORE => {\n-                        tt::Spacing::Joint\n-                    }\n-                    _ => tt::Spacing::Alone,\n-                };\n-                let char = match token.to_char() {\n-                    Some(c) => c,\n-                    None => {\n-                        panic!(\"Token from lexer must be single char: token = {:#?}\", token);\n-                    }\n-                };\n-                tt::Leaf::from(tt::Punct { char, spacing, id: self.id_alloc().alloc(range) }).into()\n-            }\n-        } else {\n-            macro_rules! make_leaf {\n-                ($i:ident) => {\n-                    tt::$i { id: self.id_alloc().alloc(range), text: token.to_text() }.into()\n-                };\n-            }\n-            let leaf: tt::Leaf = match k {\n-                T![true] | T![false] => make_leaf!(Ident),\n-                IDENT => make_leaf!(Ident),\n-                UNDERSCORE => make_leaf!(Ident),\n-                k if k.is_keyword() => make_leaf!(Ident),\n-                k if k.is_literal() => make_leaf!(Literal),\n-                LIFETIME_IDENT => {\n-                    let char_unit = TextSize::of('\\'');\n-                    let r = TextRange::at(range.start(), char_unit);\n-                    let apostrophe = tt::Leaf::from(tt::Punct {\n-                        char: '\\'',\n-                        spacing: tt::Spacing::Joint,\n-                        id: self.id_alloc().alloc(r),\n-                    });\n-                    result.push(apostrophe.into());\n-\n-                    let r = TextRange::at(range.start() + char_unit, range.len() - char_unit);\n-                    let ident = tt::Leaf::from(tt::Ident {\n-                        text: SmolStr::new(&token.to_text()[1..]),\n-                        id: self.id_alloc().alloc(r),\n-                    });\n-                    result.push(ident.into());\n-                    return;\n-                }\n-                _ => return,\n-            };\n-\n-            leaf.into()\n-        });\n-    }\n-\n     fn convert_doc_comment(&self, token: &Self::Token) -> Option<Vec<tt::TokenTree>>;\n \n     fn bump(&mut self) -> Option<(Self::Token, TextRange)>;\n@@ -683,6 +714,7 @@ mod tests {\n         algo::{insert_children, InsertPosition},\n         ast::AstNode,\n     };\n+    use test_utils::assert_eq_text;\n \n     #[test]\n     fn convert_tt_token_source() {\n@@ -792,4 +824,12 @@ mod tests {\n         let tt = ast_to_token_tree(&struct_def).0;\n         token_tree_to_syntax_node(&tt, FragmentKind::Item).unwrap();\n     }\n+\n+    #[test]\n+    fn test_missing_closing_delim() {\n+        let source_file = ast::SourceFile::parse(\"m!(x\").tree();\n+        let node = source_file.syntax().descendants().find_map(ast::TokenTree::cast).unwrap();\n+        let tt = ast_to_token_tree(&node).0.to_string();\n+        assert_eq_text!(&*tt, \"( x\");\n+    }\n }"}]}