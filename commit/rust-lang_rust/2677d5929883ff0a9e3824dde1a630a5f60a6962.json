{"sha": "2677d5929883ff0a9e3824dde1a630a5f60a6962", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI2NzdkNTkyOTg4M2ZmMGE5ZTM4MjRkZGUxYTYzMGE1ZjYwYTY5NjI=", "commit": {"author": {"name": "Mazdak Farrokhzad", "email": "twingoow@gmail.com", "date": "2020-03-09T11:57:53Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-03-09T11:57:53Z"}, "message": "Rollup merge of #69801 - petrochenkov:nonorm, r=Centril\n\nrustc_parse: Remove `Parser::normalized(_prev)_token`\n\nPerform the \"normalization\" (renamed to \"uninterpolation\") on the fly when necessary.\n\nThe final part of https://github.com/rust-lang/rust/pull/69579 https://github.com/rust-lang/rust/pull/69384 https://github.com/rust-lang/rust/pull/69376 https://github.com/rust-lang/rust/pull/69211 https://github.com/rust-lang/rust/pull/69034 https://github.com/rust-lang/rust/pull/69006.\nr? @Centril", "tree": {"sha": "8abbd2c7a1e3a2603788dcb1b861677bd09b267c", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/8abbd2c7a1e3a2603788dcb1b861677bd09b267c"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2677d5929883ff0a9e3824dde1a630a5f60a6962", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJeZi9BCRBK7hj4Ov3rIwAAdHIIACV6iVtEX2Mf4mep3uLdcpSu\nCfA12iuecku08kZTHDHW+ZW+033W1Ecc2EqGoQVjPyhi9XxSigjzzyPvZyV2jZyk\np1N73xAcoT60gbDK68rqHQSBoP8fXsUPMcLyclkgBBJlbh06KQMHzc+51Q///XIU\nfvuY59yXfx9HKD5RONsgznu67dkqrm5IeJ2DScBvHt8kbPILv8bwTuPvahRWJQa3\nE7LYKBUkZxiEhZNlXct1zkHxT9HDCUUZyZ2ik7lcUkB7Cdcw3j+XQBwIiImIMDpm\nkaKLYuEW7pnCN8hMUM++tUfYTT0xeF7rkng3YTYvrL3+vx7cX4RWCELxFsG4vYU=\n=bf09\n-----END PGP SIGNATURE-----\n", "payload": "tree 8abbd2c7a1e3a2603788dcb1b861677bd09b267c\nparent 2409e70bdbc0889fbcfa1acf9eda6152d3ab7e68\nparent 7a30bb1676690596f73659d18959877d993510ae\nauthor Mazdak Farrokhzad <twingoow@gmail.com> 1583755073 +0100\ncommitter GitHub <noreply@github.com> 1583755073 +0100\n\nRollup merge of #69801 - petrochenkov:nonorm, r=Centril\n\nrustc_parse: Remove `Parser::normalized(_prev)_token`\n\nPerform the \"normalization\" (renamed to \"uninterpolation\") on the fly when necessary.\n\nThe final part of https://github.com/rust-lang/rust/pull/69579 https://github.com/rust-lang/rust/pull/69384 https://github.com/rust-lang/rust/pull/69376 https://github.com/rust-lang/rust/pull/69211 https://github.com/rust-lang/rust/pull/69034 https://github.com/rust-lang/rust/pull/69006.\nr? @Centril\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2677d5929883ff0a9e3824dde1a630a5f60a6962", "html_url": "https://github.com/rust-lang/rust/commit/2677d5929883ff0a9e3824dde1a630a5f60a6962", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2677d5929883ff0a9e3824dde1a630a5f60a6962/comments", "author": {"login": "Centril", "id": 855702, "node_id": "MDQ6VXNlcjg1NTcwMg==", "avatar_url": "https://avatars.githubusercontent.com/u/855702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Centril", "html_url": "https://github.com/Centril", "followers_url": "https://api.github.com/users/Centril/followers", "following_url": "https://api.github.com/users/Centril/following{/other_user}", "gists_url": "https://api.github.com/users/Centril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Centril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Centril/subscriptions", "organizations_url": "https://api.github.com/users/Centril/orgs", "repos_url": "https://api.github.com/users/Centril/repos", "events_url": "https://api.github.com/users/Centril/events{/privacy}", "received_events_url": "https://api.github.com/users/Centril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "2409e70bdbc0889fbcfa1acf9eda6152d3ab7e68", "url": "https://api.github.com/repos/rust-lang/rust/commits/2409e70bdbc0889fbcfa1acf9eda6152d3ab7e68", "html_url": "https://github.com/rust-lang/rust/commit/2409e70bdbc0889fbcfa1acf9eda6152d3ab7e68"}, {"sha": "7a30bb1676690596f73659d18959877d993510ae", "url": "https://api.github.com/repos/rust-lang/rust/commits/7a30bb1676690596f73659d18959877d993510ae", "html_url": "https://github.com/rust-lang/rust/commit/7a30bb1676690596f73659d18959877d993510ae"}], "stats": {"total": 391, "additions": 200, "deletions": 191}, "files": [{"sha": "52a59e82ae23f672db81c1c34d0a268348768a39", "filename": "src/librustc_ast/attr/mod.rs", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Fattr%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Fattr%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Fattr%2Fmod.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -286,6 +286,10 @@ impl MetaItem {\n }\n \n impl AttrItem {\n+    pub fn span(&self) -> Span {\n+        self.args.span().map_or(self.path.span, |args_span| self.path.span.to(args_span))\n+    }\n+\n     pub fn meta(&self, span: Span) -> Option<MetaItem> {\n         Some(MetaItem {\n             path: self.path.clone(),\n@@ -437,7 +441,7 @@ impl MetaItem {\n         I: Iterator<Item = TokenTree>,\n     {\n         // FIXME: Share code with `parse_path`.\n-        let path = match tokens.next() {\n+        let path = match tokens.next().map(TokenTree::uninterpolate) {\n             Some(TokenTree::Token(Token { kind: kind @ token::Ident(..), span }))\n             | Some(TokenTree::Token(Token { kind: kind @ token::ModSep, span })) => 'arm: {\n                 let mut segments = if let token::Ident(name, _) = kind {\n@@ -453,7 +457,7 @@ impl MetaItem {\n                 };\n                 loop {\n                     if let Some(TokenTree::Token(Token { kind: token::Ident(name, _), span })) =\n-                        tokens.next()\n+                        tokens.next().map(TokenTree::uninterpolate)\n                     {\n                         segments.push(PathSegment::from_ident(Ident::new(name, span)));\n                     } else {\n@@ -470,7 +474,6 @@ impl MetaItem {\n                 Path { span, segments }\n             }\n             Some(TokenTree::Token(Token { kind: token::Interpolated(nt), .. })) => match *nt {\n-                token::Nonterminal::NtIdent(ident, _) => Path::from_ident(ident),\n                 token::Nonterminal::NtMeta(ref item) => return item.meta(item.path.span),\n                 token::Nonterminal::NtPath(ref path) => path.clone(),\n                 _ => return None,"}, {"sha": "b67b7d346f7565009be3a963ca086f60978f6089", "filename": "src/librustc_ast/token.rs", "status": "modified", "additions": 69, "deletions": 24, "changes": 93, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Ftoken.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -14,8 +14,8 @@ use rustc_macros::HashStable_Generic;\n use rustc_span::symbol::kw;\n use rustc_span::symbol::Symbol;\n use rustc_span::{self, Span, DUMMY_SP};\n-use std::fmt;\n-use std::mem;\n+use std::borrow::Cow;\n+use std::{fmt, mem};\n \n #[derive(Clone, PartialEq, RustcEncodable, RustcDecodable, Hash, Debug, Copy)]\n #[derive(HashStable_Generic)]\n@@ -225,8 +225,15 @@ pub enum TokenKind {\n     /* Literals */\n     Literal(Lit),\n \n-    /* Name components */\n+    /// Identifier token.\n+    /// Do not forget about `NtIdent` when you want to match on identifiers.\n+    /// It's recommended to use `Token::(ident,uninterpolate,uninterpolated_span)` to\n+    /// treat regular and interpolated identifiers in the same way.\n     Ident(ast::Name, /* is_raw */ bool),\n+    /// Lifetime identifier token.\n+    /// Do not forget about `NtLifetime` when you want to match on lifetime identifiers.\n+    /// It's recommended to use `Token::(lifetime,uninterpolate,uninterpolated_span)` to\n+    /// treat regular and interpolated lifetime identifiers in the same way.\n     Lifetime(ast::Name),\n \n     Interpolated(Lrc<Nonterminal>),\n@@ -328,6 +335,19 @@ impl Token {\n         mem::replace(self, Token::dummy())\n     }\n \n+    /// For interpolated tokens, returns a span of the fragment to which the interpolated\n+    /// token refers. For all other tokens this is just a regular span.\n+    /// It is particularly important to use this for identifiers and lifetimes\n+    /// for which spans affect name resolution and edition checks.\n+    /// Note that keywords are also identifiers, so they should use this\n+    /// if they keep spans or perform edition checks.\n+    pub fn uninterpolated_span(&self) -> Span {\n+        match &self.kind {\n+            Interpolated(nt) => nt.span(),\n+            _ => self.span,\n+        }\n+    }\n+\n     pub fn is_op(&self) -> bool {\n         match self.kind {\n             OpenDelim(..) | CloseDelim(..) | Literal(..) | DocComment(..) | Ident(..)\n@@ -345,7 +365,7 @@ impl Token {\n \n     /// Returns `true` if the token can appear at the start of an expression.\n     pub fn can_begin_expr(&self) -> bool {\n-        match self.kind {\n+        match self.uninterpolate().kind {\n             Ident(name, is_raw)              =>\n                 ident_can_begin_expr(name, self.span, is_raw), // value name or keyword\n             OpenDelim(..)                     | // tuple, array or block\n@@ -363,12 +383,10 @@ impl Token {\n             Lifetime(..)                      | // labeled loop\n             Pound                             => true, // expression attributes\n             Interpolated(ref nt) => match **nt {\n-                NtIdent(ident, is_raw) => ident_can_begin_expr(ident.name, ident.span, is_raw),\n                 NtLiteral(..) |\n                 NtExpr(..)    |\n                 NtBlock(..)   |\n-                NtPath(..)    |\n-                NtLifetime(..) => true,\n+                NtPath(..) => true,\n                 _ => false,\n             },\n             _ => false,\n@@ -377,7 +395,7 @@ impl Token {\n \n     /// Returns `true` if the token can appear at the start of a type.\n     pub fn can_begin_type(&self) -> bool {\n-        match self.kind {\n+        match self.uninterpolate().kind {\n             Ident(name, is_raw)        =>\n                 ident_can_begin_type(name, self.span, is_raw), // type name or keyword\n             OpenDelim(Paren)            | // tuple\n@@ -391,8 +409,7 @@ impl Token {\n             Lt | BinOp(Shl)             | // associated path\n             ModSep                      => true, // global path\n             Interpolated(ref nt) => match **nt {\n-                NtIdent(ident, is_raw) => ident_can_begin_type(ident.name, ident.span, is_raw),\n-                NtTy(..) | NtPath(..) | NtLifetime(..) => true,\n+                NtTy(..) | NtPath(..) => true,\n                 _ => false,\n             },\n             _ => false,\n@@ -433,38 +450,48 @@ impl Token {\n     ///\n     /// Keep this in sync with `Lit::from_token`.\n     pub fn can_begin_literal_or_bool(&self) -> bool {\n-        match self.kind {\n+        match self.uninterpolate().kind {\n             Literal(..) | BinOp(Minus) => true,\n             Ident(name, false) if name.is_bool_lit() => true,\n             Interpolated(ref nt) => match &**nt {\n-                NtIdent(ident, false) if ident.name.is_bool_lit() => true,\n                 NtExpr(e) | NtLiteral(e) => matches!(e.kind, ast::ExprKind::Lit(_)),\n                 _ => false,\n             },\n             _ => false,\n         }\n     }\n \n+    // A convenience function for matching on identifiers during parsing.\n+    // Turns interpolated identifier (`$i: ident`) or lifetime (`$l: lifetime`) token\n+    // into the regular identifier or lifetime token it refers to,\n+    // otherwise returns the original token.\n+    pub fn uninterpolate(&self) -> Cow<'_, Token> {\n+        match &self.kind {\n+            Interpolated(nt) => match **nt {\n+                NtIdent(ident, is_raw) => {\n+                    Cow::Owned(Token::new(Ident(ident.name, is_raw), ident.span))\n+                }\n+                NtLifetime(ident) => Cow::Owned(Token::new(Lifetime(ident.name), ident.span)),\n+                _ => Cow::Borrowed(self),\n+            },\n+            _ => Cow::Borrowed(self),\n+        }\n+    }\n+\n     /// Returns an identifier if this token is an identifier.\n     pub fn ident(&self) -> Option<(ast::Ident, /* is_raw */ bool)> {\n-        match self.kind {\n-            Ident(name, is_raw) => Some((ast::Ident::new(name, self.span), is_raw)),\n-            Interpolated(ref nt) => match **nt {\n-                NtIdent(ident, is_raw) => Some((ident, is_raw)),\n-                _ => None,\n-            },\n+        let token = self.uninterpolate();\n+        match token.kind {\n+            Ident(name, is_raw) => Some((ast::Ident::new(name, token.span), is_raw)),\n             _ => None,\n         }\n     }\n \n     /// Returns a lifetime identifier if this token is a lifetime.\n     pub fn lifetime(&self) -> Option<ast::Ident> {\n-        match self.kind {\n-            Lifetime(name) => Some(ast::Ident::new(name, self.span)),\n-            Interpolated(ref nt) => match **nt {\n-                NtLifetime(ident) => Some(ident),\n-                _ => None,\n-            },\n+        let token = self.uninterpolate();\n+        match token.kind {\n+            Lifetime(name) => Some(ast::Ident::new(name, token.span)),\n             _ => None,\n         }\n     }\n@@ -714,6 +741,24 @@ pub enum Nonterminal {\n #[cfg(target_arch = \"x86_64\")]\n rustc_data_structures::static_assert_size!(Nonterminal, 40);\n \n+impl Nonterminal {\n+    fn span(&self) -> Span {\n+        match self {\n+            NtItem(item) => item.span,\n+            NtBlock(block) => block.span,\n+            NtStmt(stmt) => stmt.span,\n+            NtPat(pat) => pat.span,\n+            NtExpr(expr) | NtLiteral(expr) => expr.span,\n+            NtTy(ty) => ty.span,\n+            NtIdent(ident, _) | NtLifetime(ident) => ident.span,\n+            NtMeta(attr_item) => attr_item.span(),\n+            NtPath(path) => path.span,\n+            NtVis(vis) => vis.span,\n+            NtTT(tt) => tt.span(),\n+        }\n+    }\n+}\n+\n impl PartialEq for Nonterminal {\n     fn eq(&self, rhs: &Self) -> bool {\n         match (self, rhs) {"}, {"sha": "916a5ff6f46f49a0d6969f6e0d809e19f41b623a", "filename": "src/librustc_ast/tokenstream.rs", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Ftokenstream.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Ftokenstream.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Ftokenstream.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -116,6 +116,13 @@ impl TokenTree {\n     pub fn close_tt(span: DelimSpan, delim: DelimToken) -> TokenTree {\n         TokenTree::token(token::CloseDelim(delim), span.close)\n     }\n+\n+    pub fn uninterpolate(self) -> TokenTree {\n+        match self {\n+            TokenTree::Token(token) => TokenTree::Token(token.uninterpolate().into_owned()),\n+            tt => tt,\n+        }\n+    }\n }\n \n impl<CTX> HashStable<CTX> for TokenStream"}, {"sha": "d1757394f3a1dee633881c5720e6695022c9727c", "filename": "src/librustc_ast/util/literal.rs", "status": "modified", "additions": 4, "deletions": 11, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Futil%2Fliteral.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_ast%2Futil%2Fliteral.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_ast%2Futil%2Fliteral.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -191,23 +191,16 @@ impl Lit {\n     ///\n     /// Keep this in sync with `Token::can_begin_literal_or_bool`.\n     pub fn from_token(token: &Token) -> Result<Lit, LitError> {\n-        let lit = match token.kind {\n+        let lit = match token.uninterpolate().kind {\n             token::Ident(name, false) if name.is_bool_lit() => {\n                 token::Lit::new(token::Bool, name, None)\n             }\n             token::Literal(lit) => lit,\n             token::Interpolated(ref nt) => {\n-                match &**nt {\n-                    token::NtIdent(ident, false) if ident.name.is_bool_lit() => {\n-                        let lit = token::Lit::new(token::Bool, ident.name, None);\n-                        return Lit::from_lit_token(lit, ident.span);\n+                if let token::NtExpr(expr) | token::NtLiteral(expr) = &**nt {\n+                    if let ast::ExprKind::Lit(lit) = &expr.kind {\n+                        return Ok(lit.clone());\n                     }\n-                    token::NtExpr(expr) | token::NtLiteral(expr) => {\n-                        if let ast::ExprKind::Lit(lit) = &expr.kind {\n-                            return Ok(lit.clone());\n-                        }\n-                    }\n-                    _ => {}\n                 }\n                 return Err(LitError::NotLiteral);\n             }"}, {"sha": "2883159a9f34ca1af05fb9dd435cfd0aa14368dd", "filename": "src/librustc_builtin_macros/format.rs", "status": "modified", "additions": 32, "deletions": 33, "changes": 65, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_builtin_macros%2Fformat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_builtin_macros%2Fformat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_builtin_macros%2Fformat.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -156,44 +156,43 @@ fn parse_args<'a>(\n         if p.token == token::Eof {\n             break;\n         } // accept trailing commas\n-        if p.token.is_ident() && p.look_ahead(1, |t| *t == token::Eq) {\n-            named = true;\n-            let name = if let token::Ident(name, _) = p.normalized_token.kind {\n+        match p.token.ident() {\n+            Some((ident, _)) if p.look_ahead(1, |t| *t == token::Eq) => {\n+                named = true;\n                 p.bump();\n-                name\n-            } else {\n-                unreachable!();\n-            };\n+                p.expect(&token::Eq)?;\n+                let e = p.parse_expr()?;\n+                if let Some(prev) = names.get(&ident.name) {\n+                    ecx.struct_span_err(e.span, &format!(\"duplicate argument named `{}`\", ident))\n+                        .span_label(args[*prev].span, \"previously here\")\n+                        .span_label(e.span, \"duplicate argument\")\n+                        .emit();\n+                    continue;\n+                }\n \n-            p.expect(&token::Eq)?;\n-            let e = p.parse_expr()?;\n-            if let Some(prev) = names.get(&name) {\n-                ecx.struct_span_err(e.span, &format!(\"duplicate argument named `{}`\", name))\n-                    .span_label(args[*prev].span, \"previously here\")\n-                    .span_label(e.span, \"duplicate argument\")\n-                    .emit();\n-                continue;\n+                // Resolve names into slots early.\n+                // Since all the positional args are already seen at this point\n+                // if the input is valid, we can simply append to the positional\n+                // args. And remember the names.\n+                let slot = args.len();\n+                names.insert(ident.name, slot);\n+                args.push(e);\n             }\n-\n-            // Resolve names into slots early.\n-            // Since all the positional args are already seen at this point\n-            // if the input is valid, we can simply append to the positional\n-            // args. And remember the names.\n-            let slot = args.len();\n-            names.insert(name, slot);\n-            args.push(e);\n-        } else {\n-            let e = p.parse_expr()?;\n-            if named {\n-                let mut err = ecx\n-                    .struct_span_err(e.span, \"positional arguments cannot follow named arguments\");\n-                err.span_label(e.span, \"positional arguments must be before named arguments\");\n-                for pos in names.values() {\n-                    err.span_label(args[*pos].span, \"named argument\");\n+            _ => {\n+                let e = p.parse_expr()?;\n+                if named {\n+                    let mut err = ecx.struct_span_err(\n+                        e.span,\n+                        \"positional arguments cannot follow named arguments\",\n+                    );\n+                    err.span_label(e.span, \"positional arguments must be before named arguments\");\n+                    for pos in names.values() {\n+                        err.span_label(args[*pos].span, \"named argument\");\n+                    }\n+                    err.emit();\n                 }\n-                err.emit();\n+                args.push(e);\n             }\n-            args.push(e);\n         }\n     }\n     Ok((fmtstr, args, names))"}, {"sha": "6d4d7f5b4f394f0c99efb9eae0c27ed46ff129a4", "filename": "src/librustc_expand/mbe/macro_parser.rs", "status": "modified", "additions": 5, "deletions": 14, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_expand%2Fmbe%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_expand%2Fmbe%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_expand%2Fmbe%2Fmacro_parser.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -750,17 +750,8 @@ pub(super) fn parse_tt(parser: &mut Cow<'_, Parser<'_>>, ms: &[TokenTree]) -> Na\n \n /// The token is an identifier, but not `_`.\n /// We prohibit passing `_` to macros expecting `ident` for now.\n-fn get_macro_name(token: &Token) -> Option<(Name, bool)> {\n-    match token.kind {\n-        token::Ident(name, is_raw) if name != kw::Underscore => Some((name, is_raw)),\n-        token::Interpolated(ref nt) => match **nt {\n-            token::NtIdent(ident, is_raw) if ident.name != kw::Underscore => {\n-                Some((ident.name, is_raw))\n-            }\n-            _ => None,\n-        },\n-        _ => None,\n-    }\n+fn get_macro_ident(token: &Token) -> Option<(Ident, bool)> {\n+    token.ident().filter(|(ident, _)| ident.name != kw::Underscore)\n }\n \n /// Checks whether a non-terminal may begin with a particular token.\n@@ -783,7 +774,7 @@ fn may_begin_with(token: &Token, name: Name) -> bool {\n             && !token.is_keyword(kw::Let)\n         }\n         sym::ty => token.can_begin_type(),\n-        sym::ident => get_macro_name(token).is_some(),\n+        sym::ident => get_macro_ident(token).is_some(),\n         sym::literal => token.can_begin_literal_or_bool(),\n         sym::vis => match token.kind {\n             // The follow-set of :vis + \"priv\" keyword + interpolated\n@@ -888,9 +879,9 @@ fn parse_nt_inner<'a>(p: &mut Parser<'a>, sp: Span, name: Symbol) -> PResult<'a,\n         sym::ty => token::NtTy(p.parse_ty()?),\n         // this could be handled like a token, since it is one\n         sym::ident => {\n-            if let Some((name, is_raw)) = get_macro_name(&p.token) {\n+            if let Some((ident, is_raw)) = get_macro_ident(&p.token) {\n                 p.bump();\n-                token::NtIdent(Ident::new(name, p.normalized_prev_token.span), is_raw)\n+                token::NtIdent(ident, is_raw)\n             } else {\n                 let token_str = pprust::token_to_string(&p.token);\n                 let msg = &format!(\"expected ident, found {}\", &token_str);"}, {"sha": "10d524776a11b58c5b5ca2751244f9a1a8805f96", "filename": "src/librustc_parse/lib.rs", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Flib.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -4,7 +4,7 @@\n #![feature(crate_visibility_modifier)]\n \n use rustc_ast::ast;\n-use rustc_ast::token::{self, Nonterminal, Token};\n+use rustc_ast::token::{self, Nonterminal};\n use rustc_ast::tokenstream::{self, TokenStream, TokenTree};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n@@ -171,8 +171,7 @@ fn maybe_source_file_to_parser(\n     let mut parser = stream_to_parser(sess, stream, None);\n     parser.unclosed_delims = unclosed_delims;\n     if parser.token == token::Eof {\n-        let span = Span::new(end_pos, end_pos, parser.token.span.ctxt());\n-        parser.set_token(Token::new(token::Eof, span));\n+        parser.token.span = Span::new(end_pos, end_pos, parser.token.span.ctxt());\n     }\n \n     Ok(parser)"}, {"sha": "7c1df531ad16e341167f193314175c0402f07bd0", "filename": "src/librustc_parse/parser/diagnostics.rs", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fdiagnostics.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -192,17 +192,19 @@ impl<'a> Parser<'a> {\n             TokenKind::CloseDelim(token::DelimToken::Brace),\n             TokenKind::CloseDelim(token::DelimToken::Paren),\n         ];\n-        if let token::Ident(name, false) = self.normalized_token.kind {\n-            if Ident::new(name, self.normalized_token.span).is_raw_guess()\n-                && self.look_ahead(1, |t| valid_follow.contains(&t.kind))\n+        match self.token.ident() {\n+            Some((ident, false))\n+                if ident.is_raw_guess()\n+                    && self.look_ahead(1, |t| valid_follow.contains(&t.kind)) =>\n             {\n                 err.span_suggestion(\n-                    self.normalized_token.span,\n+                    ident.span,\n                     \"you can escape reserved keywords to use them as identifiers\",\n-                    format!(\"r#{}\", name),\n+                    format!(\"r#{}\", ident.name),\n                     Applicability::MaybeIncorrect,\n                 );\n             }\n+            _ => {}\n         }\n         if let Some(token_descr) = super::token_descr_opt(&self.token) {\n             err.span_label(self.token.span, format!(\"expected identifier, found {}\", token_descr));"}, {"sha": "16ea2773b200910c058fb3ad911dc8078d8f6362", "filename": "src/librustc_parse/parser/expr.rs", "status": "modified", "additions": 38, "deletions": 35, "changes": 73, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fexpr.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -50,7 +50,6 @@ macro_rules! maybe_whole_expr {\n                         AttrVec::new(),\n                     ));\n                 }\n-                // N.B., `NtIdent(ident)` is normalized to `Ident` in `fn bump`.\n                 _ => {}\n             };\n         }\n@@ -97,9 +96,9 @@ impl<'a> Parser<'a> {\n     fn parse_expr_catch_underscore(&mut self) -> PResult<'a, P<Expr>> {\n         match self.parse_expr() {\n             Ok(expr) => Ok(expr),\n-            Err(mut err) => match self.normalized_token.kind {\n-                token::Ident(name, false)\n-                    if name == kw::Underscore && self.look_ahead(1, |t| t == &token::Comma) =>\n+            Err(mut err) => match self.token.ident() {\n+                Some((Ident { name: kw::Underscore, .. }, false))\n+                    if self.look_ahead(1, |t| t == &token::Comma) =>\n                 {\n                     // Special-case handling of `foo(_, _, _)`\n                     err.emit();\n@@ -331,21 +330,19 @@ impl<'a> Parser<'a> {\n     ///\n     /// Also performs recovery for `and` / `or` which are mistaken for `&&` and `||` respectively.\n     fn check_assoc_op(&self) -> Option<Spanned<AssocOp>> {\n-        Some(Spanned {\n-            node: match (AssocOp::from_token(&self.token), &self.normalized_token.kind) {\n-                (Some(op), _) => op,\n-                (None, token::Ident(sym::and, false)) => {\n-                    self.error_bad_logical_op(\"and\", \"&&\", \"conjunction\");\n-                    AssocOp::LAnd\n-                }\n-                (None, token::Ident(sym::or, false)) => {\n-                    self.error_bad_logical_op(\"or\", \"||\", \"disjunction\");\n-                    AssocOp::LOr\n-                }\n-                _ => return None,\n-            },\n-            span: self.normalized_token.span,\n-        })\n+        let (op, span) = match (AssocOp::from_token(&self.token), self.token.ident()) {\n+            (Some(op), _) => (op, self.token.span),\n+            (None, Some((Ident { name: sym::and, span }, false))) => {\n+                self.error_bad_logical_op(\"and\", \"&&\", \"conjunction\");\n+                (AssocOp::LAnd, span)\n+            }\n+            (None, Some((Ident { name: sym::or, span }, false))) => {\n+                self.error_bad_logical_op(\"or\", \"||\", \"disjunction\");\n+                (AssocOp::LOr, span)\n+            }\n+            _ => return None,\n+        };\n+        Some(source_map::respan(span, op))\n     }\n \n     /// Error on `and` and `or` suggesting `&&` and `||` respectively.\n@@ -436,7 +433,7 @@ impl<'a> Parser<'a> {\n         let attrs = self.parse_or_use_outer_attributes(attrs)?;\n         let lo = self.token.span;\n         // Note: when adding new unary operators, don't forget to adjust TokenKind::can_begin_expr()\n-        let (hi, ex) = match self.normalized_token.kind {\n+        let (hi, ex) = match self.token.uninterpolate().kind {\n             token::Not => self.parse_unary_expr(lo, UnOp::Not), // `!expr`\n             token::Tilde => self.recover_tilde_expr(lo),        // `~expr`\n             token::BinOp(token::Minus) => self.parse_unary_expr(lo, UnOp::Neg), // `-expr`\n@@ -483,7 +480,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn is_mistaken_not_ident_negation(&self) -> bool {\n-        let token_cannot_continue_expr = |t: &Token| match t.kind {\n+        let token_cannot_continue_expr = |t: &Token| match t.uninterpolate().kind {\n             // These tokens can start an expression after `!`, but\n             // can't continue an expression after an ident\n             token::Ident(name, is_raw) => token::ident_can_begin_expr(name, t.span, is_raw),\n@@ -747,7 +744,7 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_dot_suffix_expr(&mut self, lo: Span, base: P<Expr>) -> PResult<'a, P<Expr>> {\n-        match self.normalized_token.kind {\n+        match self.token.uninterpolate().kind {\n             token::Ident(..) => self.parse_dot_suffix(base, lo),\n             token::Literal(token::Lit { kind: token::Integer, symbol, suffix }) => {\n                 Ok(self.parse_tuple_field_access_expr(lo, base, symbol, suffix))\n@@ -841,7 +838,7 @@ impl<'a> Parser<'a> {\n \n     /// Assuming we have just parsed `.`, continue parsing into an expression.\n     fn parse_dot_suffix(&mut self, self_arg: P<Expr>, lo: Span) -> PResult<'a, P<Expr>> {\n-        if self.normalized_token.span.rust_2018() && self.eat_keyword(kw::Await) {\n+        if self.token.uninterpolated_span().rust_2018() && self.eat_keyword(kw::Await) {\n             return self.mk_await_expr(self_arg, lo);\n         }\n \n@@ -955,7 +952,7 @@ impl<'a> Parser<'a> {\n             //       |             ^ expected expression\n             self.bump();\n             Ok(self.mk_expr_err(self.token.span))\n-        } else if self.normalized_token.span.rust_2018() {\n+        } else if self.token.uninterpolated_span().rust_2018() {\n             // `Span::rust_2018()` is somewhat expensive; don't get it repeatedly.\n             if self.check_keyword(kw::Async) {\n                 if self.is_async_block() {\n@@ -1388,11 +1385,14 @@ impl<'a> Parser<'a> {\n         let movability =\n             if self.eat_keyword(kw::Static) { Movability::Static } else { Movability::Movable };\n \n-        let asyncness =\n-            if self.normalized_token.span.rust_2018() { self.parse_asyncness() } else { Async::No };\n-        if asyncness.is_async() {\n+        let asyncness = if self.token.uninterpolated_span().rust_2018() {\n+            self.parse_asyncness()\n+        } else {\n+            Async::No\n+        };\n+        if let Async::Yes { span, .. } = asyncness {\n             // Feature-gate `async ||` closures.\n-            self.sess.gated_spans.gate(sym::async_closure, self.normalized_prev_token.span);\n+            self.sess.gated_spans.gate(sym::async_closure, span);\n         }\n \n         let capture_clause = self.parse_capture_clause();\n@@ -1748,7 +1748,7 @@ impl<'a> Parser<'a> {\n     fn is_try_block(&self) -> bool {\n         self.token.is_keyword(kw::Try) &&\n         self.look_ahead(1, |t| *t == token::OpenDelim(token::Brace)) &&\n-        self.normalized_token.span.rust_2018() &&\n+        self.token.uninterpolated_span().rust_2018() &&\n         // Prevent `while try {} {}`, `if try {} {} else {}`, etc.\n         !self.restrictions.contains(Restrictions::NO_STRUCT_LITERAL)\n     }\n@@ -1898,20 +1898,23 @@ impl<'a> Parser<'a> {\n \n     /// Use in case of error after field-looking code: `S { foo: () with a }`.\n     fn find_struct_error_after_field_looking_code(&self) -> Option<Field> {\n-        if let token::Ident(name, _) = self.normalized_token.kind {\n-            if !self.token.is_reserved_ident() && self.look_ahead(1, |t| *t == token::Colon) {\n-                return Some(ast::Field {\n-                    ident: Ident::new(name, self.normalized_token.span),\n+        match self.token.ident() {\n+            Some((ident, is_raw))\n+                if (is_raw || !ident.is_reserved())\n+                    && self.look_ahead(1, |t| *t == token::Colon) =>\n+            {\n+                Some(ast::Field {\n+                    ident,\n                     span: self.token.span,\n                     expr: self.mk_expr_err(self.token.span),\n                     is_shorthand: false,\n                     attrs: AttrVec::new(),\n                     id: DUMMY_NODE_ID,\n                     is_placeholder: false,\n-                });\n+                })\n             }\n+            _ => None,\n         }\n-        None\n     }\n \n     fn recover_struct_comma_after_dotdot(&mut self, span: Span) {"}, {"sha": "126686c8defbf5ee883538f600b744d30303ce51", "filename": "src/librustc_parse/parser/item.rs", "status": "modified", "additions": 13, "deletions": 14, "changes": 27, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fitem.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fitem.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fitem.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -574,7 +574,7 @@ impl<'a> Parser<'a> {\n             && self.look_ahead(1, |t| t.is_non_raw_ident_where(|i| i.name != kw::As))\n         {\n             self.bump(); // `default`\n-            Defaultness::Default(self.normalized_prev_token.span)\n+            Defaultness::Default(self.prev_token.uninterpolated_span())\n         } else {\n             Defaultness::Final\n         }\n@@ -750,10 +750,10 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_ident_or_underscore(&mut self) -> PResult<'a, ast::Ident> {\n-        match self.normalized_token.kind {\n-            token::Ident(name @ kw::Underscore, false) => {\n+        match self.token.ident() {\n+            Some((ident @ Ident { name: kw::Underscore, .. }, false)) => {\n                 self.bump();\n-                Ok(Ident::new(name, self.normalized_prev_token.span))\n+                Ok(ident)\n             }\n             _ => self.parse_ident(),\n         }\n@@ -1544,7 +1544,9 @@ impl<'a> Parser<'a> {\n \n         let is_name_required = match self.token.kind {\n             token::DotDotDot => false,\n-            _ => req_name(self.normalized_token.span.edition()),\n+            // FIXME: Consider using interpolated token for this edition check,\n+            // it should match the intent of edition hygiene better.\n+            _ => req_name(self.token.uninterpolate().span.edition()),\n         };\n         let (pat, ty) = if is_name_required || self.is_named_param() {\n             debug!(\"parse_param_general parse_pat (is_name_required:{})\", is_name_required);\n@@ -1609,15 +1611,12 @@ impl<'a> Parser<'a> {\n     /// Returns the parsed optional self parameter and whether a self shortcut was used.\n     fn parse_self_param(&mut self) -> PResult<'a, Option<Param>> {\n         // Extract an identifier *after* having confirmed that the token is one.\n-        let expect_self_ident = |this: &mut Self| {\n-            match this.normalized_token.kind {\n-                // Preserve hygienic context.\n-                token::Ident(name, _) => {\n-                    this.bump();\n-                    Ident::new(name, this.normalized_prev_token.span)\n-                }\n-                _ => unreachable!(),\n+        let expect_self_ident = |this: &mut Self| match this.token.ident() {\n+            Some((ident, false)) => {\n+                this.bump();\n+                ident\n             }\n+            _ => unreachable!(),\n         };\n         // Is `self` `n` tokens ahead?\n         let is_isolated_self = |this: &Self, n| {\n@@ -1651,7 +1650,7 @@ impl<'a> Parser<'a> {\n         // Only a limited set of initial token sequences is considered `self` parameters; anything\n         // else is parsed as a normal function parameter list, so some lookahead is required.\n         let eself_lo = self.token.span;\n-        let (eself, eself_ident, eself_hi) = match self.normalized_token.kind {\n+        let (eself, eself_ident, eself_hi) = match self.token.uninterpolate().kind {\n             token::BinOp(token::And) => {\n                 let eself = if is_isolated_self(self, 1) {\n                     // `&self`"}, {"sha": "9376c7c1c724d15fee382596ae6bb0b40eae5ffc", "filename": "src/librustc_parse/parser/mod.rs", "status": "modified", "additions": 12, "deletions": 44, "changes": 56, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fmod.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -88,21 +88,10 @@ macro_rules! maybe_recover_from_interpolated_ty_qpath {\n #[derive(Clone)]\n pub struct Parser<'a> {\n     pub sess: &'a ParseSess,\n-    /// The current non-normalized token.\n+    /// The current token.\n     pub token: Token,\n-    /// The current normalized token.\n-    /// \"Normalized\" means that some interpolated tokens\n-    /// (`$i: ident` and `$l: lifetime` meta-variables) are replaced\n-    /// with non-interpolated identifier and lifetime tokens they refer to.\n-    /// Use this if you need to check for `token::Ident` or `token::Lifetime` specifically,\n-    /// this also includes edition checks for edition-specific keyword identifiers.\n-    pub normalized_token: Token,\n-    /// The previous non-normalized token.\n+    /// The previous token.\n     pub prev_token: Token,\n-    /// The previous normalized token.\n-    /// Use this if you need to check for `token::Ident` or `token::Lifetime` specifically,\n-    /// this also includes edition checks for edition-specific keyword identifiers.\n-    pub normalized_prev_token: Token,\n     restrictions: Restrictions,\n     /// Used to determine the path to externally loaded source files.\n     pub(super) directory: Directory,\n@@ -374,9 +363,7 @@ impl<'a> Parser<'a> {\n         let mut parser = Parser {\n             sess,\n             token: Token::dummy(),\n-            normalized_token: Token::dummy(),\n             prev_token: Token::dummy(),\n-            normalized_prev_token: Token::dummy(),\n             restrictions: Restrictions::empty(),\n             recurse_into_file_modules,\n             directory: Directory {\n@@ -480,9 +467,9 @@ impl<'a> Parser<'a> {\n     }\n \n     fn parse_ident_common(&mut self, recover: bool) -> PResult<'a, ast::Ident> {\n-        match self.normalized_token.kind {\n-            token::Ident(name, _) => {\n-                if self.token.is_reserved_ident() {\n+        match self.token.ident() {\n+            Some((ident, is_raw)) => {\n+                if !is_raw && ident.is_reserved() {\n                     let mut err = self.expected_ident_found();\n                     if recover {\n                         err.emit();\n@@ -491,7 +478,7 @@ impl<'a> Parser<'a> {\n                     }\n                 }\n                 self.bump();\n-                Ok(Ident::new(name, self.normalized_prev_token.span))\n+                Ok(ident)\n             }\n             _ => Err(match self.prev_token.kind {\n                 TokenKind::DocComment(..) => {\n@@ -609,7 +596,7 @@ impl<'a> Parser<'a> {\n             Some((first, second)) if first == expected => {\n                 let first_span = self.sess.source_map().start_point(self.token.span);\n                 let second_span = self.token.span.with_lo(first_span.hi());\n-                self.set_token(Token::new(first, first_span));\n+                self.token = Token::new(first, first_span);\n                 self.bump_with(Token::new(second, second_span));\n                 true\n             }\n@@ -817,23 +804,6 @@ impl<'a> Parser<'a> {\n         self.parse_delim_comma_seq(token::Paren, f)\n     }\n \n-    // Interpolated identifier (`$i: ident`) and lifetime (`$l: lifetime`)\n-    // tokens are replaced with usual identifier and lifetime tokens,\n-    // so the former are never encountered during normal parsing.\n-    crate fn set_token(&mut self, token: Token) {\n-        self.token = token;\n-        self.normalized_token = match &self.token.kind {\n-            token::Interpolated(nt) => match **nt {\n-                token::NtIdent(ident, is_raw) => {\n-                    Token::new(token::Ident(ident.name, is_raw), ident.span)\n-                }\n-                token::NtLifetime(ident) => Token::new(token::Lifetime(ident.name), ident.span),\n-                _ => self.token.clone(),\n-            },\n-            _ => self.token.clone(),\n-        }\n-    }\n-\n     /// Advance the parser by one token using provided token as the next one.\n     fn bump_with(&mut self, next_token: Token) {\n         // Bumping after EOF is a bad sign, usually an infinite loop.\n@@ -843,9 +813,7 @@ impl<'a> Parser<'a> {\n         }\n \n         // Update the current and previous tokens.\n-        self.prev_token = self.token.take();\n-        self.normalized_prev_token = self.normalized_token.take();\n-        self.set_token(next_token);\n+        self.prev_token = mem::replace(&mut self.token, next_token);\n \n         // Diagnostics.\n         self.expected_tokens.clear();\n@@ -884,7 +852,7 @@ impl<'a> Parser<'a> {\n     /// Parses asyncness: `async` or nothing.\n     fn parse_asyncness(&mut self) -> Async {\n         if self.eat_keyword(kw::Async) {\n-            let span = self.normalized_prev_token.span;\n+            let span = self.prev_token.uninterpolated_span();\n             Async::Yes { span, closure_id: DUMMY_NODE_ID, return_impl_trait_id: DUMMY_NODE_ID }\n         } else {\n             Async::No\n@@ -894,7 +862,7 @@ impl<'a> Parser<'a> {\n     /// Parses unsafety: `unsafe` or nothing.\n     fn parse_unsafety(&mut self) -> Unsafe {\n         if self.eat_keyword(kw::Unsafe) {\n-            Unsafe::Yes(self.normalized_prev_token.span)\n+            Unsafe::Yes(self.prev_token.uninterpolated_span())\n         } else {\n             Unsafe::No\n         }\n@@ -903,7 +871,7 @@ impl<'a> Parser<'a> {\n     /// Parses constness: `const` or nothing.\n     fn parse_constness(&mut self) -> Const {\n         if self.eat_keyword(kw::Const) {\n-            Const::Yes(self.normalized_prev_token.span)\n+            Const::Yes(self.prev_token.uninterpolated_span())\n         } else {\n             Const::No\n         }\n@@ -1005,7 +973,7 @@ impl<'a> Parser<'a> {\n                     &mut self.token_cursor.frame,\n                     self.token_cursor.stack.pop().unwrap(),\n                 );\n-                self.set_token(Token::new(TokenKind::CloseDelim(frame.delim), frame.span.close));\n+                self.token = Token::new(TokenKind::CloseDelim(frame.delim), frame.span.close);\n                 self.bump();\n                 TokenTree::Delimited(frame.span, frame.delim, frame.tree_cursor.stream)\n             }"}, {"sha": "f52a91ff5989dd06343224768e54c09d5dc2386f", "filename": "src/librustc_parse/parser/pat.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fpat.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fpat.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fpat.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -151,7 +151,7 @@ impl<'a> Parser<'a> {\n     /// Note that there are more tokens such as `@` for which we know that the `|`\n     /// is an illegal parse. However, the user's intent is less clear in that case.\n     fn recover_trailing_vert(&mut self, lo: Option<Span>) -> bool {\n-        let is_end_ahead = self.look_ahead(1, |token| match &token.kind {\n+        let is_end_ahead = self.look_ahead(1, |token| match &token.uninterpolate().kind {\n             token::FatArrow // e.g. `a | => 0,`.\n             | token::Ident(kw::If, false) // e.g. `a | if expr`.\n             | token::Eq // e.g. `let a | = 0`."}, {"sha": "f88b4fe6ff0a8dfedec357ab9a8802e6797599ce", "filename": "src/librustc_parse/parser/path.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fpath.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fpath.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -240,10 +240,10 @@ impl<'a> Parser<'a> {\n     }\n \n     pub(super) fn parse_path_segment_ident(&mut self) -> PResult<'a, Ident> {\n-        match self.normalized_token.kind {\n-            token::Ident(name, _) if name.is_path_segment_keyword() => {\n+        match self.token.ident() {\n+            Some((ident, false)) if ident.is_path_segment_keyword() => {\n                 self.bump();\n-                Ok(Ident::new(name, self.normalized_prev_token.span))\n+                Ok(ident)\n             }\n             _ => self.parse_ident(),\n         }"}, {"sha": "16adf5c05a4eeafa9d5284052340fe0d080d32b6", "filename": "src/librustc_parse/parser/ty.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fty.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2677d5929883ff0a9e3824dde1a630a5f60a6962/src%2Flibrustc_parse%2Fparser%2Fty.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_parse%2Fparser%2Fty.rs?ref=2677d5929883ff0a9e3824dde1a630a5f60a6962", "patch": "@@ -323,7 +323,7 @@ impl<'a> Parser<'a> {\n     /// Is a `dyn B0 + ... + Bn` type allowed here?\n     fn is_explicit_dyn_type(&mut self) -> bool {\n         self.check_keyword(kw::Dyn)\n-            && (self.normalized_token.span.rust_2018()\n+            && (self.token.uninterpolated_span().rust_2018()\n                 || self.look_ahead(1, |t| {\n                     t.can_begin_bound() && !can_continue_type_after_non_fn_ident(t)\n                 }))"}]}