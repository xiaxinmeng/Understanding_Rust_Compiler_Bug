{"sha": "024c25dc7941795b84d76b6371527f31c361a329", "node_id": "MDY6Q29tbWl0NzI0NzEyOjAyNGMyNWRjNzk0MTc5NWI4NGQ3NmI2MzcxNTI3ZjMxYzM2MWEzMjk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-05-16T04:15:12Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-05-16T04:15:12Z"}, "message": "Auto merge of #60763 - matklad:tt-parser, r=petrochenkov\n\nMove token tree related lexer state to a separate struct\n\nJust a types-based refactoring.\n\nWe only used a bunch of fields when tokenizing into a token tree, so let's move them out of the base lexer", "tree": {"sha": "11460b37f2e3db156ccc67c82ec29ad7a2957040", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/11460b37f2e3db156ccc67c82ec29ad7a2957040"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/024c25dc7941795b84d76b6371527f31c361a329", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/024c25dc7941795b84d76b6371527f31c361a329", "html_url": "https://github.com/rust-lang/rust/commit/024c25dc7941795b84d76b6371527f31c361a329", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/024c25dc7941795b84d76b6371527f31c361a329/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "49d139c64b69ec5289f9f81db885ecfc2c7a8366", "url": "https://api.github.com/repos/rust-lang/rust/commits/49d139c64b69ec5289f9f81db885ecfc2c7a8366", "html_url": "https://github.com/rust-lang/rust/commit/49d139c64b69ec5289f9f81db885ecfc2c7a8366"}, {"sha": "e249f2e526cca687b78a766769c481cfb638f02e", "url": "https://api.github.com/repos/rust-lang/rust/commits/e249f2e526cca687b78a766769c481cfb638f02e", "html_url": "https://github.com/rust-lang/rust/commit/e249f2e526cca687b78a766769c481cfb638f02e"}], "stats": {"total": 105, "additions": 62, "deletions": 43}, "files": [{"sha": "47da3ee6a6c7817c1b770f9d2fd00cc884737db9", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 1, "deletions": 25, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=024c25dc7941795b84d76b6371527f31c361a329", "patch": "@@ -62,19 +62,7 @@ pub struct StringReader<'a> {\n     // cache a direct reference to the source text, so that we don't have to\n     // retrieve it via `self.source_file.src.as_ref().unwrap()` all the time.\n     src: Lrc<String>,\n-    token: token::Token,\n-    span: Span,\n-    /// The raw source span which *does not* take `override_span` into account\n-    span_src_raw: Span,\n-    /// Stack of open delimiters and their spans. Used for error message.\n-    open_braces: Vec<(token::DelimToken, Span)>,\n-    crate unmatched_braces: Vec<UnmatchedBrace>,\n-    /// The type and spans for all braces\n-    ///\n-    /// Used only for error recovery when arriving to EOF with mismatched braces.\n-    matching_delim_spans: Vec<(token::DelimToken, Span, Span)>,\n-    crate override_span: Option<Span>,\n-    last_unclosed_found_span: Option<Span>,\n+    override_span: Option<Span>,\n }\n \n impl<'a> StringReader<'a> {\n@@ -121,8 +109,6 @@ impl<'a> StringReader<'a> {\n             sp: self.peek_span,\n         };\n         self.advance_token()?;\n-        self.span_src_raw = self.peek_span_src_raw;\n-\n         Ok(ret_val)\n     }\n \n@@ -159,9 +145,6 @@ impl<'a> StringReader<'a> {\n             }\n         }\n \n-        self.token = t.tok.clone();\n-        self.span = t.sp;\n-\n         Ok(t)\n     }\n \n@@ -251,14 +234,7 @@ impl<'a> StringReader<'a> {\n             peek_span_src_raw: syntax_pos::DUMMY_SP,\n             src,\n             fatal_errs: Vec::new(),\n-            token: token::Eof,\n-            span: syntax_pos::DUMMY_SP,\n-            span_src_raw: syntax_pos::DUMMY_SP,\n-            open_braces: Vec::new(),\n-            unmatched_braces: Vec::new(),\n-            matching_delim_spans: Vec::new(),\n             override_span,\n-            last_unclosed_found_span: None,\n         }\n     }\n "}, {"sha": "4bfc5bb16c0bb236d50d140960b4648cbfbbaeb2", "filename": "src/libsyntax/parse/lexer/tokentrees.rs", "status": "modified", "additions": 55, "deletions": 12, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "raw_url": "https://github.com/rust-lang/rust/raw/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Ftokentrees.rs?ref=024c25dc7941795b84d76b6371527f31c361a329", "patch": "@@ -1,13 +1,46 @@\n+use syntax_pos::Span;\n+\n use crate::print::pprust::token_to_string;\n use crate::parse::lexer::{StringReader, UnmatchedBrace};\n use crate::parse::{token, PResult};\n use crate::tokenstream::{DelimSpan, IsJoint::*, TokenStream, TokenTree, TreeAndJoint};\n \n impl<'a> StringReader<'a> {\n+    crate fn into_token_trees(self) -> (PResult<'a, TokenStream>, Vec<UnmatchedBrace>) {\n+        let mut tt_reader = TokenTreesReader {\n+            string_reader: self,\n+            token: token::Eof,\n+            span: syntax_pos::DUMMY_SP,\n+            open_braces: Vec::new(),\n+            unmatched_braces: Vec::new(),\n+            matching_delim_spans: Vec::new(),\n+            last_unclosed_found_span: None,\n+        };\n+        let res = tt_reader.parse_all_token_trees();\n+        (res, tt_reader.unmatched_braces)\n+    }\n+}\n+\n+struct TokenTreesReader<'a> {\n+    string_reader: StringReader<'a>,\n+    token: token::Token,\n+    span: Span,\n+    /// Stack of open delimiters and their spans. Used for error message.\n+    open_braces: Vec<(token::DelimToken, Span)>,\n+    unmatched_braces: Vec<UnmatchedBrace>,\n+    /// The type and spans for all braces\n+    ///\n+    /// Used only for error recovery when arriving to EOF with mismatched braces.\n+    matching_delim_spans: Vec<(token::DelimToken, Span, Span)>,\n+    last_unclosed_found_span: Option<Span>,\n+}\n+\n+impl<'a> TokenTreesReader<'a> {\n     // Parse a stream of tokens into a list of `TokenTree`s, up to an `Eof`.\n-    crate fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n+    fn parse_all_token_trees(&mut self) -> PResult<'a, TokenStream> {\n         let mut tts = Vec::new();\n \n+        self.real_token();\n         while self.token != token::Eof {\n             tts.push(self.parse_token_tree()?);\n         }\n@@ -34,25 +67,25 @@ impl<'a> StringReader<'a> {\n     }\n \n     fn parse_token_tree(&mut self) -> PResult<'a, TreeAndJoint> {\n-        let sm = self.sess.source_map();\n+        let sm = self.string_reader.sess.source_map();\n         match self.token {\n             token::Eof => {\n                 let msg = \"this file contains an un-closed delimiter\";\n-                let mut err = self.sess.span_diagnostic.struct_span_err(self.span, msg);\n+                let mut err = self.string_reader.sess.span_diagnostic\n+                    .struct_span_err(self.span, msg);\n                 for &(_, sp) in &self.open_braces {\n                     err.span_label(sp, \"un-closed delimiter\");\n                 }\n \n                 if let Some((delim, _)) = self.open_braces.last() {\n                     if let Some((_, open_sp, close_sp)) = self.matching_delim_spans.iter()\n                         .filter(|(d, open_sp, close_sp)| {\n-\n-                        if let Some(close_padding) = sm.span_to_margin(*close_sp) {\n-                            if let Some(open_padding) = sm.span_to_margin(*open_sp) {\n-                                return delim == d && close_padding != open_padding;\n+                            if let Some(close_padding) = sm.span_to_margin(*close_sp) {\n+                                if let Some(open_padding) = sm.span_to_margin(*open_sp) {\n+                                    return delim == d && close_padding != open_padding;\n+                                }\n                             }\n-                        }\n-                        false\n+                            false\n                         }).next()  // these are in reverse order as they get inserted on close, but\n                     {              // we want the last open/first close\n                         err.span_label(\n@@ -164,7 +197,8 @@ impl<'a> StringReader<'a> {\n                 // matching opening delimiter).\n                 let token_str = token_to_string(&self.token);\n                 let msg = format!(\"unexpected close delimiter: `{}`\", token_str);\n-                let mut err = self.sess.span_diagnostic.struct_span_err(self.span, &msg);\n+                let mut err = self.string_reader.sess.span_diagnostic\n+                    .struct_span_err(self.span, &msg);\n                 err.span_label(self.span, \"unexpected close delimiter\");\n                 Err(err)\n             },\n@@ -173,11 +207,20 @@ impl<'a> StringReader<'a> {\n                 // Note that testing for joint-ness here is done via the raw\n                 // source span as the joint-ness is a property of the raw source\n                 // rather than wanting to take `override_span` into account.\n-                let raw = self.span_src_raw;\n+                // Additionally, we actually check if the *next* pair of tokens\n+                // is joint, but this is equivalent to checking the current pair.\n+                let raw = self.string_reader.peek_span_src_raw;\n                 self.real_token();\n-                let is_joint = raw.hi() == self.span_src_raw.lo() && token::is_op(&self.token);\n+                let is_joint = raw.hi() == self.string_reader.peek_span_src_raw.lo()\n+                    && token::is_op(&self.token);\n                 Ok((tt, if is_joint { Joint } else { NonJoint }))\n             }\n         }\n     }\n+\n+    fn real_token(&mut self) {\n+        let t = self.string_reader.real_token();\n+        self.token = t.tok;\n+        self.span = t.sp;\n+    }\n }"}, {"sha": "0611c1d9b42a5a6dd88791c5809e6848d5b97556", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/024c25dc7941795b84d76b6371527f31c361a329/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=024c25dc7941795b84d76b6371527f31c361a329", "patch": "@@ -290,22 +290,22 @@ pub fn source_file_to_stream(\n }\n \n /// Given a source file, produces a sequence of token trees. Returns any buffered errors from\n-/// parsing the token tream.\n+/// parsing the token stream.\n pub fn maybe_file_to_stream(\n     sess: &ParseSess,\n     source_file: Lrc<SourceFile>,\n     override_span: Option<Span>,\n ) -> Result<(TokenStream, Vec<lexer::UnmatchedBrace>), Vec<Diagnostic>> {\n-    let mut srdr = lexer::StringReader::new_or_buffered_errs(sess, source_file, override_span)?;\n-    srdr.real_token();\n+    let srdr = lexer::StringReader::new_or_buffered_errs(sess, source_file, override_span)?;\n+    let (token_trees, unmatched_braces) = srdr.into_token_trees();\n \n-    match srdr.parse_all_token_trees() {\n-        Ok(stream) => Ok((stream, srdr.unmatched_braces)),\n+    match token_trees {\n+        Ok(stream) => Ok((stream, unmatched_braces)),\n         Err(err) => {\n             let mut buffer = Vec::with_capacity(1);\n             err.buffer(&mut buffer);\n             // Not using `emit_unclosed_delims` to use `db.buffer`\n-            for unmatched in srdr.unmatched_braces {\n+            for unmatched in unmatched_braces {\n                 let mut db = sess.span_diagnostic.struct_span_err(unmatched.found_span, &format!(\n                     \"incorrect close delimiter: `{}`\",\n                     token_to_string(&token::Token::CloseDelim(unmatched.found_delim)),"}]}