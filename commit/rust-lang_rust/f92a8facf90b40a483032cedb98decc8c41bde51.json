{"sha": "f92a8facf90b40a483032cedb98decc8c41bde51", "node_id": "MDY6Q29tbWl0NzI0NzEyOmY5MmE4ZmFjZjkwYjQwYTQ4MzAzMmNlZGI5OGRlY2M4YzQxYmRlNTE=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-06-11T01:07:07Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-06-11T01:07:07Z"}, "message": "auto merge of #14768 : riccieri/rust/detransmute-arena, r=alexcrichton\n\n**Update**\r\n\r\nI've reimplemented this using `Cell` and `RefCell`, as suggested by @alexcrichton. By taking care with the duration of the borrows, I was able to maintain the recursive allocation feature (now covered by a test) without the use of `Unsafe`, and without breaking the non-aliasing `&mut` invariant.\r\n\r\n**Original**\r\n\r\nChanges both `Arena` and `TypedArena` to contain an inner struct wrapped in a `Unsafe`, and change field access to go through those instead of transmuting `&self` to `&mut self`.\r\n\r\nPart of #13933", "tree": {"sha": "d92fd19592134de268eff55a380af07fe8cb02df", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d92fd19592134de268eff55a380af07fe8cb02df"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/f92a8facf90b40a483032cedb98decc8c41bde51", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/f92a8facf90b40a483032cedb98decc8c41bde51", "html_url": "https://github.com/rust-lang/rust/commit/f92a8facf90b40a483032cedb98decc8c41bde51", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/f92a8facf90b40a483032cedb98decc8c41bde51/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b1302f9c4f6619bf83fff39b305b990d8f628eb7", "url": "https://api.github.com/repos/rust-lang/rust/commits/b1302f9c4f6619bf83fff39b305b990d8f628eb7", "html_url": "https://github.com/rust-lang/rust/commit/b1302f9c4f6619bf83fff39b305b990d8f628eb7"}, {"sha": "47b72e388d6f2207c977fb6b06399717bca96a77", "url": "https://api.github.com/repos/rust-lang/rust/commits/47b72e388d6f2207c977fb6b06399717bca96a77", "html_url": "https://github.com/rust-lang/rust/commit/47b72e388d6f2207c977fb6b06399717bca96a77"}], "stats": {"total": 154, "additions": 87, "deletions": 67}, "files": [{"sha": "996369cbf6d7d90f6c52c60110194c039d8952c1", "filename": "src/libarena/lib.rs", "status": "modified", "additions": 87, "deletions": 67, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/f92a8facf90b40a483032cedb98decc8c41bde51/src%2Flibarena%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/f92a8facf90b40a483032cedb98decc8c41bde51/src%2Flibarena%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibarena%2Flib.rs?ref=f92a8facf90b40a483032cedb98decc8c41bde51", "patch": "@@ -81,8 +81,8 @@ pub struct Arena {\n     // The head is separated out from the list as a unbenchmarked\n     // microoptimization, to avoid needing to case on the list to access the\n     // head.\n-    head: Chunk,\n-    copy_head: Chunk,\n+    head: RefCell<Chunk>,\n+    copy_head: RefCell<Chunk>,\n     chunks: RefCell<Vec<Chunk>>,\n }\n \n@@ -95,8 +95,8 @@ impl Arena {\n     /// Allocate a new Arena with `initial_size` bytes preallocated.\n     pub fn new_with_size(initial_size: uint) -> Arena {\n         Arena {\n-            head: chunk(initial_size, false),\n-            copy_head: chunk(initial_size, true),\n+            head: RefCell::new(chunk(initial_size, false)),\n+            copy_head: RefCell::new(chunk(initial_size, true)),\n             chunks: RefCell::new(Vec::new()),\n         }\n     }\n@@ -114,7 +114,7 @@ fn chunk(size: uint, is_copy: bool) -> Chunk {\n impl Drop for Arena {\n     fn drop(&mut self) {\n         unsafe {\n-            destroy_chunk(&self.head);\n+            destroy_chunk(&*self.head.borrow());\n             for chunk in self.chunks.borrow().iter() {\n                 if !chunk.is_copy.get() {\n                     destroy_chunk(chunk);\n@@ -171,38 +171,40 @@ fn un_bitpack_tydesc_ptr(p: uint) -> (*TyDesc, bool) {\n \n impl Arena {\n     fn chunk_size(&self) -> uint {\n-        self.copy_head.capacity()\n+        self.copy_head.borrow().capacity()\n     }\n+\n     // Functions for the POD part of the arena\n-    fn alloc_copy_grow(&mut self, n_bytes: uint, align: uint) -> *u8 {\n+    fn alloc_copy_grow(&self, n_bytes: uint, align: uint) -> *u8 {\n         // Allocate a new chunk.\n         let new_min_chunk_size = cmp::max(n_bytes, self.chunk_size());\n-        self.chunks.borrow_mut().push(self.copy_head.clone());\n-        self.copy_head =\n+        self.chunks.borrow_mut().push(self.copy_head.borrow().clone());\n+\n+        *self.copy_head.borrow_mut() =\n             chunk(num::next_power_of_two(new_min_chunk_size + 1u), true);\n \n         return self.alloc_copy_inner(n_bytes, align);\n     }\n \n     #[inline]\n-    fn alloc_copy_inner(&mut self, n_bytes: uint, align: uint) -> *u8 {\n-        unsafe {\n-            let start = round_up(self.copy_head.fill.get(), align);\n-            let end = start + n_bytes;\n-            if end > self.chunk_size() {\n-                return self.alloc_copy_grow(n_bytes, align);\n-            }\n-            self.copy_head.fill.set(end);\n+    fn alloc_copy_inner(&self, n_bytes: uint, align: uint) -> *u8 {\n+        let start = round_up(self.copy_head.borrow().fill.get(), align);\n+\n+        let end = start + n_bytes;\n+        if end > self.chunk_size() {\n+            return self.alloc_copy_grow(n_bytes, align);\n+        }\n \n-            //debug!(\"idx = {}, size = {}, align = {}, fill = {}\",\n-            //       start, n_bytes, align, head.fill.get());\n+        let copy_head = self.copy_head.borrow();\n+        copy_head.fill.set(end);\n \n-            self.copy_head.as_ptr().offset(start as int)\n+        unsafe {\n+            copy_head.as_ptr().offset(start as int)\n         }\n     }\n \n     #[inline]\n-    fn alloc_copy<'a, T>(&'a mut self, op: || -> T) -> &'a T {\n+    fn alloc_copy<'a, T>(&'a self, op: || -> T) -> &'a T {\n         unsafe {\n             let ptr = self.alloc_copy_inner(mem::size_of::<T>(),\n                                             mem::min_align_of::<T>());\n@@ -213,42 +215,48 @@ impl Arena {\n     }\n \n     // Functions for the non-POD part of the arena\n-    fn alloc_noncopy_grow(&mut self, n_bytes: uint, align: uint)\n-                         -> (*u8, *u8) {\n+    fn alloc_noncopy_grow(&self, n_bytes: uint, align: uint) -> (*u8, *u8) {\n         // Allocate a new chunk.\n         let new_min_chunk_size = cmp::max(n_bytes, self.chunk_size());\n-        self.chunks.borrow_mut().push(self.head.clone());\n-        self.head =\n+        self.chunks.borrow_mut().push(self.head.borrow().clone());\n+\n+        *self.head.borrow_mut() =\n             chunk(num::next_power_of_two(new_min_chunk_size + 1u), false);\n \n         return self.alloc_noncopy_inner(n_bytes, align);\n     }\n \n     #[inline]\n-    fn alloc_noncopy_inner(&mut self, n_bytes: uint, align: uint)\n-                          -> (*u8, *u8) {\n-        unsafe {\n-            let tydesc_start = self.head.fill.get();\n-            let after_tydesc = self.head.fill.get() + mem::size_of::<*TyDesc>();\n+    fn alloc_noncopy_inner(&self, n_bytes: uint, align: uint) -> (*u8, *u8) {\n+        // Be careful to not maintain any `head` borrows active, because\n+        // `alloc_noncopy_grow` borrows it mutably.\n+        let (start, end, tydesc_start, head_capacity) = {\n+            let head = self.head.borrow();\n+            let fill = head.fill.get();\n+\n+            let tydesc_start = fill;\n+            let after_tydesc = fill + mem::size_of::<*TyDesc>();\n             let start = round_up(after_tydesc, align);\n             let end = start + n_bytes;\n \n-            if end > self.head.capacity() {\n-                return self.alloc_noncopy_grow(n_bytes, align);\n-            }\n+            (start, end, tydesc_start, head.capacity())\n+        };\n \n-            self.head.fill.set(round_up(end, mem::align_of::<*TyDesc>()));\n+        if end > head_capacity {\n+            return self.alloc_noncopy_grow(n_bytes, align);\n+        }\n \n-            //debug!(\"idx = {}, size = {}, align = {}, fill = {}\",\n-            //       start, n_bytes, align, head.fill);\n+        let head = self.head.borrow();\n+        head.fill.set(round_up(end, mem::align_of::<*TyDesc>()));\n \n-            let buf = self.head.as_ptr();\n+        unsafe {\n+            let buf = head.as_ptr();\n             return (buf.offset(tydesc_start as int), buf.offset(start as int));\n         }\n     }\n \n     #[inline]\n-    fn alloc_noncopy<'a, T>(&'a mut self, op: || -> T) -> &'a T {\n+    fn alloc_noncopy<'a, T>(&'a self, op: || -> T) -> &'a T {\n         unsafe {\n             let tydesc = get_tydesc::<T>();\n             let (ty_ptr, ptr) =\n@@ -274,12 +282,10 @@ impl Arena {\n     #[inline]\n     pub fn alloc<'a, T>(&'a self, op: || -> T) -> &'a T {\n         unsafe {\n-            // FIXME #13933: Remove/justify all `&T` to `&mut T` transmutes\n-            let this: &mut Arena = mem::transmute::<&_, &mut _>(self);\n             if intrinsics::needs_drop::<T>() {\n-                this.alloc_noncopy(op)\n+                self.alloc_noncopy(op)\n             } else {\n-                this.alloc_copy(op)\n+                self.alloc_copy(op)\n             }\n         }\n     }\n@@ -298,6 +304,20 @@ fn test_arena_destructors() {\n     }\n }\n \n+#[test]\n+fn test_arena_alloc_nested() {\n+    struct Inner { value: uint }\n+    struct Outer<'a> { inner: &'a Inner }\n+\n+    let arena = Arena::new();\n+\n+    let result = arena.alloc(|| Outer {\n+        inner: arena.alloc(|| Inner { value: 10 })\n+    });\n+\n+    assert_eq!(result.inner.value, 10);\n+}\n+\n #[test]\n #[should_fail]\n fn test_arena_destructors_fail() {\n@@ -325,19 +345,20 @@ fn test_arena_destructors_fail() {\n /// run again for these objects.\n pub struct TypedArena<T> {\n     /// A pointer to the next object to be allocated.\n-    ptr: *T,\n+    ptr: Cell<*T>,\n \n     /// A pointer to the end of the allocated area. When this pointer is\n     /// reached, a new chunk is allocated.\n-    end: *T,\n+    end: Cell<*T>,\n \n     /// A pointer to the first arena segment.\n-    first: Option<Box<TypedArenaChunk<T>>>,\n+    first: RefCell<TypedArenaChunkRef<T>>,\n }\n+type TypedArenaChunkRef<T> = Option<Box<TypedArenaChunk<T>>>;\n \n struct TypedArenaChunk<T> {\n     /// Pointer to the next arena segment.\n-    next: Option<Box<TypedArenaChunk<T>>>,\n+    next: TypedArenaChunkRef<T>,\n \n     /// The number of elements that this chunk can hold.\n     capacity: uint,\n@@ -423,53 +444,52 @@ impl<T> TypedArena<T> {\n     pub fn with_capacity(capacity: uint) -> TypedArena<T> {\n         let chunk = TypedArenaChunk::<T>::new(None, capacity);\n         TypedArena {\n-            ptr: chunk.start() as *T,\n-            end: chunk.end() as *T,\n-            first: Some(chunk),\n+            ptr: Cell::new(chunk.start() as *T),\n+            end: Cell::new(chunk.end() as *T),\n+            first: RefCell::new(Some(chunk)),\n         }\n     }\n \n     /// Allocates an object in the TypedArena, returning a reference to it.\n     #[inline]\n     pub fn alloc<'a>(&'a self, object: T) -> &'a T {\n-        unsafe {\n-            // FIXME #13933: Remove/justify all `&T` to `&mut T` transmutes\n-            let this: &mut TypedArena<T> = mem::transmute::<&_, &mut _>(self);\n-            if this.ptr == this.end {\n-                this.grow()\n-            }\n+        if self.ptr == self.end {\n+            self.grow()\n+        }\n \n-            let ptr: &'a mut T = mem::transmute(this.ptr);\n+        let ptr: &'a T = unsafe {\n+            let ptr: &'a mut T = mem::transmute(self.ptr);\n             ptr::write(ptr, object);\n-            this.ptr = this.ptr.offset(1);\n-            let ptr: &'a T = ptr;\n+            self.ptr.set(self.ptr.get().offset(1));\n             ptr\n-        }\n+        };\n+\n+        ptr\n     }\n \n     /// Grows the arena.\n     #[inline(never)]\n-    fn grow(&mut self) {\n-        let chunk = self.first.take_unwrap();\n+    fn grow(&self) {\n+        let chunk = self.first.borrow_mut().take_unwrap();\n         let new_capacity = chunk.capacity.checked_mul(&2).unwrap();\n         let chunk = TypedArenaChunk::<T>::new(Some(chunk), new_capacity);\n-        self.ptr = chunk.start() as *T;\n-        self.end = chunk.end() as *T;\n-        self.first = Some(chunk)\n+        self.ptr.set(chunk.start() as *T);\n+        self.end.set(chunk.end() as *T);\n+        *self.first.borrow_mut() = Some(chunk)\n     }\n }\n \n #[unsafe_destructor]\n impl<T> Drop for TypedArena<T> {\n     fn drop(&mut self) {\n         // Determine how much was filled.\n-        let start = self.first.get_ref().start() as uint;\n-        let end = self.ptr as uint;\n+        let start = self.first.borrow().get_ref().start() as uint;\n+        let end = self.ptr.get() as uint;\n         let diff = (end - start) / mem::size_of::<T>();\n \n         // Pass that to the `destroy` method.\n         unsafe {\n-            self.first.get_mut_ref().destroy(diff)\n+            self.first.borrow_mut().get_mut_ref().destroy(diff)\n         }\n     }\n }"}]}