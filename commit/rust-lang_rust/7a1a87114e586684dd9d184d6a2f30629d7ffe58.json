{"sha": "7a1a87114e586684dd9d184d6a2f30629d7ffe58", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdhMWE4NzExNGU1ODY2ODRkZDlkMTg0ZDZhMmYzMDYyOWQ3ZmZlNTg=", "commit": {"author": {"name": "Jonas Schievink", "email": "jonasschievink@gmail.com", "date": "2020-09-26T23:53:29Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-09-26T23:53:29Z"}, "message": "Rollup merge of #77235 - petrochenkov:reparse, r=Aaron1011\n\npretty-print-reparse hack: Rename some variables for clarity\n\nThis will also make it easier to make the comparisons asymmetric.\n\nAlso one impossible case is removed.\n\nr? @Aaron1011", "tree": {"sha": "4f20a590c929b8f867062d5829c6fd0967bf67d0", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4f20a590c929b8f867062d5829c6fd0967bf67d0"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7a1a87114e586684dd9d184d6a2f30629d7ffe58", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJfb9R5CRBK7hj4Ov3rIwAAdHIIAKoSMfPVJOJBfOeYKrJ7chTf\nTtIbJKqOshRZIBzsw+I14QUhR+fGvYPyMa58SA27qdkrU8NGrLfPZDlXSTonTPDJ\nLjwYUc0h/PdcTfQj9sAD+QOyNIiKuZviG2q6kXP7oVez2WatV7gjHbbPv8GTCbHy\nCKjZNXxRMSNcUvmexo0W8rMnTLASuawKf+cck41XaM3ObckjJQDKPVf8zJ+BJJxJ\nWhvYfcw7C8F/AhWzyfCoXyHkffDN678YtM09PXI6R9/wlL5qqBIyS+BOp3Qcu5Hi\n12JmVvwPMl3LsAP5jMzhIMPN6pIw971csvD7BVrunXS3nA4PHsScx6I+J2E8+o4=\n=UDXT\n-----END PGP SIGNATURE-----\n", "payload": "tree 4f20a590c929b8f867062d5829c6fd0967bf67d0\nparent aa35c527fd4257d0eddfbd7837e87d6c2d1e75bb\nparent fe3e5aa729ee34749ae730bbb5fd9c906877b82a\nauthor Jonas Schievink <jonasschievink@gmail.com> 1601164409 +0200\ncommitter GitHub <noreply@github.com> 1601164409 +0200\n\nRollup merge of #77235 - petrochenkov:reparse, r=Aaron1011\n\npretty-print-reparse hack: Rename some variables for clarity\n\nThis will also make it easier to make the comparisons asymmetric.\n\nAlso one impossible case is removed.\n\nr? @Aaron1011\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7a1a87114e586684dd9d184d6a2f30629d7ffe58", "html_url": "https://github.com/rust-lang/rust/commit/7a1a87114e586684dd9d184d6a2f30629d7ffe58", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7a1a87114e586684dd9d184d6a2f30629d7ffe58/comments", "author": {"login": "jonas-schievink", "id": 1786438, "node_id": "MDQ6VXNlcjE3ODY0Mzg=", "avatar_url": "https://avatars.githubusercontent.com/u/1786438?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jonas-schievink", "html_url": "https://github.com/jonas-schievink", "followers_url": "https://api.github.com/users/jonas-schievink/followers", "following_url": "https://api.github.com/users/jonas-schievink/following{/other_user}", "gists_url": "https://api.github.com/users/jonas-schievink/gists{/gist_id}", "starred_url": "https://api.github.com/users/jonas-schievink/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jonas-schievink/subscriptions", "organizations_url": "https://api.github.com/users/jonas-schievink/orgs", "repos_url": "https://api.github.com/users/jonas-schievink/repos", "events_url": "https://api.github.com/users/jonas-schievink/events{/privacy}", "received_events_url": "https://api.github.com/users/jonas-schievink/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "aa35c527fd4257d0eddfbd7837e87d6c2d1e75bb", "url": "https://api.github.com/repos/rust-lang/rust/commits/aa35c527fd4257d0eddfbd7837e87d6c2d1e75bb", "html_url": "https://github.com/rust-lang/rust/commit/aa35c527fd4257d0eddfbd7837e87d6c2d1e75bb"}, {"sha": "fe3e5aa729ee34749ae730bbb5fd9c906877b82a", "url": "https://api.github.com/repos/rust-lang/rust/commits/fe3e5aa729ee34749ae730bbb5fd9c906877b82a", "html_url": "https://github.com/rust-lang/rust/commit/fe3e5aa729ee34749ae730bbb5fd9c906877b82a"}], "stats": {"total": 42, "additions": 22, "deletions": 20}, "files": [{"sha": "d59dd4016a9f95609b22a7f56e70dd40518540d9", "filename": "compiler/rustc_parse/src/lib.rs", "status": "modified", "additions": 22, "deletions": 20, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/7a1a87114e586684dd9d184d6a2f30629d7ffe58/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7a1a87114e586684dd9d184d6a2f30629d7ffe58/compiler%2Frustc_parse%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_parse%2Fsrc%2Flib.rs?ref=7a1a87114e586684dd9d184d6a2f30629d7ffe58", "patch": "@@ -7,7 +7,7 @@\n #![feature(or_patterns)]\n \n use rustc_ast as ast;\n-use rustc_ast::token::{self, DelimToken, Nonterminal, Token, TokenKind};\n+use rustc_ast::token::{self, Nonterminal, Token, TokenKind};\n use rustc_ast::tokenstream::{self, Spacing, TokenStream, TokenTree};\n use rustc_ast_pretty::pprust;\n use rustc_data_structures::sync::Lrc;\n@@ -299,7 +299,7 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // FIXME(#43081): Avoid this pretty-print + reparse hack\n     let source = pprust::nonterminal_to_string(nt);\n     let filename = FileName::macro_expansion_source_code(&source);\n-    let tokens_for_real = parse_stream_from_source_str(filename, source, sess, Some(span));\n+    let reparsed_tokens = parse_stream_from_source_str(filename, source, sess, Some(span));\n \n     // During early phases of the compiler the AST could get modified\n     // directly (e.g., attributes added or removed) and the internal cache\n@@ -325,17 +325,17 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n     // modifications, including adding/removing typically non-semantic\n     // tokens such as extra braces and commas, don't happen.\n     if let Some(tokens) = tokens {\n-        if tokenstream_probably_equal_for_proc_macro(&tokens, &tokens_for_real, sess) {\n+        if tokenstream_probably_equal_for_proc_macro(&tokens, &reparsed_tokens, sess) {\n             return tokens;\n         }\n         info!(\n             \"cached tokens found, but they're not \\\"probably equal\\\", \\\n                 going with stringified version\"\n         );\n         info!(\"cached tokens: {:?}\", tokens);\n-        info!(\"reparsed tokens: {:?}\", tokens_for_real);\n+        info!(\"reparsed tokens: {:?}\", reparsed_tokens);\n     }\n-    tokens_for_real\n+    reparsed_tokens\n }\n \n // See comments in `Nonterminal::to_tokenstream` for why we care about\n@@ -344,8 +344,8 @@ pub fn nt_to_tokenstream(nt: &Nonterminal, sess: &ParseSess, span: Span) -> Toke\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n pub fn tokenstream_probably_equal_for_proc_macro(\n-    first: &TokenStream,\n-    other: &TokenStream,\n+    tokens: &TokenStream,\n+    reparsed_tokens: &TokenStream,\n     sess: &ParseSess,\n ) -> bool {\n     // When checking for `probably_eq`, we ignore certain tokens that aren't\n@@ -359,9 +359,6 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n                 // The pretty printer tends to add trailing commas to\n                 // everything, and in particular, after struct fields.\n                 | token::Comma\n-                // The pretty printer emits `NoDelim` as whitespace.\n-                | token::OpenDelim(DelimToken::NoDelim)\n-                | token::CloseDelim(DelimToken::NoDelim)\n                 // The pretty printer collapses many semicolons into one.\n                 | token::Semi\n                 // We don't preserve leading `|` tokens in patterns, so\n@@ -460,10 +457,11 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n \n     // Break tokens after we expand any nonterminals, so that we break tokens\n     // that are produced as a result of nonterminal expansion.\n-    let t1 = first.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n-    let t2 = other.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n+    let tokens = tokens.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n+    let reparsed_tokens =\n+        reparsed_tokens.trees().filter(semantic_tree).flat_map(expand_nt).flat_map(break_tokens);\n \n-    t1.eq_by(t2, |t1, t2| tokentree_probably_equal_for_proc_macro(&t1, &t2, sess))\n+    tokens.eq_by(reparsed_tokens, |t, rt| tokentree_probably_equal_for_proc_macro(&t, &rt, sess))\n }\n \n // See comments in `Nonterminal::to_tokenstream` for why we care about\n@@ -472,16 +470,20 @@ pub fn tokenstream_probably_equal_for_proc_macro(\n // This is otherwise the same as `eq_unspanned`, only recursing with a\n // different method.\n pub fn tokentree_probably_equal_for_proc_macro(\n-    first: &TokenTree,\n-    other: &TokenTree,\n+    token: &TokenTree,\n+    reparsed_token: &TokenTree,\n     sess: &ParseSess,\n ) -> bool {\n-    match (first, other) {\n-        (TokenTree::Token(token), TokenTree::Token(token2)) => {\n-            token_probably_equal_for_proc_macro(token, token2)\n+    match (token, reparsed_token) {\n+        (TokenTree::Token(token), TokenTree::Token(reparsed_token)) => {\n+            token_probably_equal_for_proc_macro(token, reparsed_token)\n         }\n-        (TokenTree::Delimited(_, delim, tts), TokenTree::Delimited(_, delim2, tts2)) => {\n-            delim == delim2 && tokenstream_probably_equal_for_proc_macro(&tts, &tts2, sess)\n+        (\n+            TokenTree::Delimited(_, delim, tokens),\n+            TokenTree::Delimited(_, reparsed_delim, reparsed_tokens),\n+        ) => {\n+            delim == reparsed_delim\n+                && tokenstream_probably_equal_for_proc_macro(tokens, reparsed_tokens, sess)\n         }\n         _ => false,\n     }"}]}