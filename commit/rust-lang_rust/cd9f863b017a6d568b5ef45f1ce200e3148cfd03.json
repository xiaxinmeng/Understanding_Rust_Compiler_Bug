{"sha": "cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "node_id": "MDY6Q29tbWl0NzI0NzEyOmNkOWY4NjNiMDE3YTZkNTY4YjVlZjQ1ZjFjZTIwMGUzMTQ4Y2ZkMDM=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-07-30T20:38:24Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-07-30T20:38:24Z"}, "message": "Use CmdArgs pattern for bench & analysis stats", "tree": {"sha": "695d0632ebf8cd6a3504a9f48890cf9e538c1a5b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/695d0632ebf8cd6a3504a9f48890cf9e538c1a5b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "html_url": "https://github.com/rust-lang/rust/commit/cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "be49547b446cba240f8f2a9592284e77d4a6896f", "url": "https://api.github.com/repos/rust-lang/rust/commits/be49547b446cba240f8f2a9592284e77d4a6896f", "html_url": "https://github.com/rust-lang/rust/commit/be49547b446cba240f8f2a9592284e77d4a6896f"}], "stats": {"total": 636, "additions": 305, "deletions": 331}, "files": [{"sha": "f16e35d86bc4e82546f026a12adfcd8ec6eeeafb", "filename": "crates/rust-analyzer/src/bin/args.rs", "status": "modified", "additions": 12, "deletions": 21, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fargs.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fargs.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fargs.rs?ref=cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "patch": "@@ -8,7 +8,7 @@ use std::{env, fmt::Write, path::PathBuf};\n use anyhow::{bail, Result};\n use pico_args::Arguments;\n use ra_ssr::{SsrPattern, SsrRule};\n-use rust_analyzer::cli::{BenchWhat, Position, Verbosity};\n+use rust_analyzer::cli::{AnalysisStatsCmd, BenchCmd, BenchWhat, Position, Verbosity};\n use vfs::AbsPathBuf;\n \n pub(crate) struct Args {\n@@ -24,23 +24,8 @@ pub(crate) enum Command {\n     Highlight {\n         rainbow: bool,\n     },\n-    Stats {\n-        randomize: bool,\n-        parallel: bool,\n-        memory_usage: bool,\n-        only: Option<String>,\n-        with_deps: bool,\n-        path: PathBuf,\n-        load_output_dirs: bool,\n-        with_proc_macro: bool,\n-    },\n-    Bench {\n-        memory_usage: bool,\n-        path: PathBuf,\n-        what: BenchWhat,\n-        load_output_dirs: bool,\n-        with_proc_macro: bool,\n-    },\n+    AnalysisStats(AnalysisStatsCmd),\n+    Bench(BenchCmd),\n     Diagnostics {\n         path: PathBuf,\n         load_output_dirs: bool,\n@@ -199,7 +184,7 @@ ARGS:\n                     trailing.pop().unwrap().into()\n                 };\n \n-                Command::Stats {\n+                Command::AnalysisStats(AnalysisStatsCmd {\n                     randomize,\n                     parallel,\n                     memory_usage,\n@@ -208,7 +193,7 @@ ARGS:\n                     path,\n                     load_output_dirs,\n                     with_proc_macro,\n-                }\n+                })\n             }\n             \"analysis-bench\" => {\n                 if matches.contains([\"-h\", \"--help\"]) {\n@@ -256,7 +241,13 @@ ARGS:\n                 let memory_usage = matches.contains(\"--memory-usage\");\n                 let load_output_dirs = matches.contains(\"--load-output-dirs\");\n                 let with_proc_macro = matches.contains(\"--with-proc-macro\");\n-                Command::Bench { memory_usage, path, what, load_output_dirs, with_proc_macro }\n+                Command::Bench(BenchCmd {\n+                    memory_usage,\n+                    path,\n+                    what,\n+                    load_output_dirs,\n+                    with_proc_macro,\n+                })\n             }\n             \"diagnostics\" => {\n                 if matches.contains([\"-h\", \"--help\"]) {"}, {"sha": "ff8234495fad4c2de548ac292c512da0125a5f92", "filename": "crates/rust-analyzer/src/bin/main.rs", "status": "modified", "additions": 2, "deletions": 30, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fbin%2Fmain.rs?ref=cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "patch": "@@ -33,36 +33,8 @@ fn main() -> Result<()> {\n         args::Command::Parse { no_dump } => cli::parse(no_dump)?,\n         args::Command::Symbols => cli::symbols()?,\n         args::Command::Highlight { rainbow } => cli::highlight(rainbow)?,\n-        args::Command::Stats {\n-            randomize,\n-            parallel,\n-            memory_usage,\n-            only,\n-            with_deps,\n-            path,\n-            load_output_dirs,\n-            with_proc_macro,\n-        } => cli::analysis_stats(\n-            args.verbosity,\n-            memory_usage,\n-            path.as_ref(),\n-            only.as_ref().map(String::as_ref),\n-            with_deps,\n-            randomize,\n-            parallel,\n-            load_output_dirs,\n-            with_proc_macro,\n-        )?,\n-        args::Command::Bench { memory_usage, path, what, load_output_dirs, with_proc_macro } => {\n-            cli::analysis_bench(\n-                args.verbosity,\n-                path.as_ref(),\n-                what,\n-                memory_usage,\n-                load_output_dirs,\n-                with_proc_macro,\n-            )?\n-        }\n+        args::Command::AnalysisStats(cmd) => cmd.run(args.verbosity)?,\n+        args::Command::Bench(cmd) => cmd.run(args.verbosity)?,\n         args::Command::Diagnostics { path, load_output_dirs, with_proc_macro, all } => {\n             cli::diagnostics(path.as_ref(), load_output_dirs, with_proc_macro, all)?\n         }"}, {"sha": "1034d11bd89f4859886ed9fdacd68ab9ca8ceb90", "filename": "crates/rust-analyzer/src/cli.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli.rs?ref=cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "patch": "@@ -14,8 +14,8 @@ use ra_ide::Analysis;\n use ra_prof::profile;\n use ra_syntax::{AstNode, SourceFile};\n \n-pub use analysis_bench::{analysis_bench, BenchWhat, Position};\n-pub use analysis_stats::analysis_stats;\n+pub use analysis_bench::{BenchCmd, BenchWhat, Position};\n+pub use analysis_stats::AnalysisStatsCmd;\n pub use diagnostics::diagnostics;\n pub use load_cargo::load_cargo;\n pub use ssr::{apply_ssr_rules, search_for_patterns};"}, {"sha": "c54ee5f4de18ac4c39212ef3a20ce286def0ef07", "filename": "crates/rust-analyzer/src/cli/analysis_bench.rs", "status": "modified", "additions": 60, "deletions": 56, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_bench.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_bench.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_bench.rs?ref=cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "patch": "@@ -1,6 +1,6 @@\n //! Benchmark operations like highlighting or goto definition.\n \n-use std::{env, path::Path, str::FromStr, sync::Arc, time::Instant};\n+use std::{env, path::PathBuf, str::FromStr, sync::Arc, time::Instant};\n \n use anyhow::{bail, format_err, Result};\n use ra_db::{\n@@ -15,6 +15,14 @@ use crate::{\n     print_memory_usage,\n };\n \n+pub struct BenchCmd {\n+    pub path: PathBuf,\n+    pub what: BenchWhat,\n+    pub memory_usage: bool,\n+    pub load_output_dirs: bool,\n+    pub with_proc_macro: bool,\n+}\n+\n pub enum BenchWhat {\n     Highlight { path: AbsPathBuf },\n     Complete(Position),\n@@ -42,72 +50,68 @@ impl FromStr for Position {\n     }\n }\n \n-pub fn analysis_bench(\n-    verbosity: Verbosity,\n-    path: &Path,\n-    what: BenchWhat,\n-    memory_usage: bool,\n-    load_output_dirs: bool,\n-    with_proc_macro: bool,\n-) -> Result<()> {\n-    ra_prof::init();\n-\n-    let start = Instant::now();\n-    eprint!(\"loading: \");\n-    let (mut host, vfs) = load_cargo(path, load_output_dirs, with_proc_macro)?;\n-    eprintln!(\"{:?}\\n\", start.elapsed());\n-\n-    let file_id = {\n-        let path = match &what {\n-            BenchWhat::Highlight { path } => path,\n-            BenchWhat::Complete(pos) | BenchWhat::GotoDef(pos) => &pos.path,\n-        };\n-        let path = path.clone().into();\n-        vfs.file_id(&path).ok_or_else(|| format_err!(\"Can't find {}\", path))?\n-    };\n-\n-    match &what {\n-        BenchWhat::Highlight { .. } => {\n-            let res = do_work(&mut host, file_id, |analysis| {\n-                analysis.diagnostics(file_id, true).unwrap();\n-                analysis.highlight_as_html(file_id, false).unwrap()\n-            });\n-            if verbosity.is_verbose() {\n-                println!(\"\\n{}\", res);\n-            }\n-        }\n-        BenchWhat::Complete(pos) | BenchWhat::GotoDef(pos) => {\n-            let is_completion = matches!(what, BenchWhat::Complete(..));\n+impl BenchCmd {\n+    pub fn run(self, verbosity: Verbosity) -> Result<()> {\n+        ra_prof::init();\n+\n+        let start = Instant::now();\n+        eprint!(\"loading: \");\n+        let (mut host, vfs) = load_cargo(&self.path, self.load_output_dirs, self.with_proc_macro)?;\n+        eprintln!(\"{:?}\\n\", start.elapsed());\n \n-            let offset = host\n-                .analysis()\n-                .file_line_index(file_id)?\n-                .offset(LineCol { line: pos.line - 1, col_utf16: pos.column });\n-            let file_position = FilePosition { file_id, offset };\n+        let file_id = {\n+            let path = match &self.what {\n+                BenchWhat::Highlight { path } => path,\n+                BenchWhat::Complete(pos) | BenchWhat::GotoDef(pos) => &pos.path,\n+            };\n+            let path = path.clone().into();\n+            vfs.file_id(&path).ok_or_else(|| format_err!(\"Can't find {}\", path))?\n+        };\n \n-            if is_completion {\n-                let options = CompletionConfig::default();\n+        match &self.what {\n+            BenchWhat::Highlight { .. } => {\n                 let res = do_work(&mut host, file_id, |analysis| {\n-                    analysis.completions(&options, file_position)\n+                    analysis.diagnostics(file_id, true).unwrap();\n+                    analysis.highlight_as_html(file_id, false).unwrap()\n                 });\n                 if verbosity.is_verbose() {\n-                    println!(\"\\n{:#?}\", res);\n+                    println!(\"\\n{}\", res);\n                 }\n-            } else {\n-                let res =\n-                    do_work(&mut host, file_id, |analysis| analysis.goto_definition(file_position));\n-                if verbosity.is_verbose() {\n-                    println!(\"\\n{:#?}\", res);\n+            }\n+            BenchWhat::Complete(pos) | BenchWhat::GotoDef(pos) => {\n+                let is_completion = matches!(self.what, BenchWhat::Complete(..));\n+\n+                let offset = host\n+                    .analysis()\n+                    .file_line_index(file_id)?\n+                    .offset(LineCol { line: pos.line - 1, col_utf16: pos.column });\n+                let file_position = FilePosition { file_id, offset };\n+\n+                if is_completion {\n+                    let options = CompletionConfig::default();\n+                    let res = do_work(&mut host, file_id, |analysis| {\n+                        analysis.completions(&options, file_position)\n+                    });\n+                    if verbosity.is_verbose() {\n+                        println!(\"\\n{:#?}\", res);\n+                    }\n+                } else {\n+                    let res = do_work(&mut host, file_id, |analysis| {\n+                        analysis.goto_definition(file_position)\n+                    });\n+                    if verbosity.is_verbose() {\n+                        println!(\"\\n{:#?}\", res);\n+                    }\n                 }\n             }\n         }\n-    }\n \n-    if memory_usage {\n-        print_memory_usage(host, vfs);\n-    }\n+        if self.memory_usage {\n+            print_memory_usage(host, vfs);\n+        }\n \n-    Ok(())\n+        Ok(())\n+    }\n }\n \n fn do_work<F: Fn(&Analysis) -> T, T>(host: &mut AnalysisHost, file_id: FileId, work: F) -> T {"}, {"sha": "721d41a58f8432ec47ccde6a7ce65407bb1bda36", "filename": "crates/rust-analyzer/src/cli/analysis_stats.rs", "status": "modified", "additions": 229, "deletions": 222, "changes": 451, "blob_url": "https://github.com/rust-lang/rust/blob/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/cd9f863b017a6d568b5ef45f1ce200e3148cfd03/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Fanalysis_stats.rs?ref=cd9f863b017a6d568b5ef45f1ce200e3148cfd03", "patch": "@@ -2,7 +2,7 @@\n //! errors.\n \n use std::{\n-    path::Path,\n+    path::PathBuf,\n     time::{SystemTime, UNIX_EPOCH},\n };\n \n@@ -39,273 +39,280 @@ impl<DB: ParallelDatabase> Clone for Snap<salsa::Snapshot<DB>> {\n     }\n }\n \n-pub fn analysis_stats(\n-    verbosity: Verbosity,\n-    memory_usage: bool,\n-    path: &Path,\n-    only: Option<&str>,\n-    with_deps: bool,\n-    randomize: bool,\n-    parallel: bool,\n-    load_output_dirs: bool,\n-    with_proc_macro: bool,\n-) -> Result<()> {\n-    let mut rng = {\n-        let seed = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as u64;\n-        Rand32::new(seed)\n-    };\n+pub struct AnalysisStatsCmd {\n+    pub randomize: bool,\n+    pub parallel: bool,\n+    pub memory_usage: bool,\n+    pub only: Option<String>,\n+    pub with_deps: bool,\n+    pub path: PathBuf,\n+    pub load_output_dirs: bool,\n+    pub with_proc_macro: bool,\n+}\n \n-    let mut db_load_sw = StopWatch::start().memory(memory_usage);\n-    let (host, vfs) = load_cargo(path, load_output_dirs, with_proc_macro)?;\n-    let db = host.raw_database();\n-    eprintln!(\"Database loaded {}\", db_load_sw.elapsed());\n+impl AnalysisStatsCmd {\n+    pub fn run(self, verbosity: Verbosity) -> Result<()> {\n+        let mut rng = {\n+            let seed = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as u64;\n+            Rand32::new(seed)\n+        };\n \n-    let mut analysis_sw = StopWatch::start().memory(memory_usage);\n-    let mut num_crates = 0;\n-    let mut visited_modules = FxHashSet::default();\n-    let mut visit_queue = Vec::new();\n+        let mut db_load_sw = self.stop_watch();\n+        let (host, vfs) = load_cargo(&self.path, self.load_output_dirs, self.with_proc_macro)?;\n+        let db = host.raw_database();\n+        eprintln!(\"Database loaded {}\", db_load_sw.elapsed());\n \n-    let mut krates = Crate::all(db);\n-    if randomize {\n-        shuffle(&mut rng, &mut krates);\n-    }\n-    for krate in krates {\n-        let module = krate.root_module(db).expect(\"crate without root module\");\n-        let file_id = module.definition_source(db).file_id;\n-        let file_id = file_id.original_file(db);\n-        let source_root = db.file_source_root(file_id);\n-        let source_root = db.source_root(source_root);\n-        if !source_root.is_library || with_deps {\n-            num_crates += 1;\n-            visit_queue.push(module);\n-        }\n-    }\n+        let mut analysis_sw = self.stop_watch();\n+        let mut num_crates = 0;\n+        let mut visited_modules = FxHashSet::default();\n+        let mut visit_queue = Vec::new();\n \n-    if randomize {\n-        shuffle(&mut rng, &mut visit_queue);\n-    }\n+        let mut krates = Crate::all(db);\n+        if self.randomize {\n+            shuffle(&mut rng, &mut krates);\n+        }\n+        for krate in krates {\n+            let module = krate.root_module(db).expect(\"crate without root module\");\n+            let file_id = module.definition_source(db).file_id;\n+            let file_id = file_id.original_file(db);\n+            let source_root = db.file_source_root(file_id);\n+            let source_root = db.source_root(source_root);\n+            if !source_root.is_library || self.with_deps {\n+                num_crates += 1;\n+                visit_queue.push(module);\n+            }\n+        }\n \n-    eprintln!(\"Crates in this dir: {}\", num_crates);\n-    let mut num_decls = 0;\n-    let mut funcs = Vec::new();\n-    while let Some(module) = visit_queue.pop() {\n-        if visited_modules.insert(module) {\n-            visit_queue.extend(module.children(db));\n+        if self.randomize {\n+            shuffle(&mut rng, &mut visit_queue);\n+        }\n \n-            for decl in module.declarations(db) {\n-                num_decls += 1;\n-                if let ModuleDef::Function(f) = decl {\n-                    funcs.push(f);\n-                }\n-            }\n+        eprintln!(\"Crates in this dir: {}\", num_crates);\n+        let mut num_decls = 0;\n+        let mut funcs = Vec::new();\n+        while let Some(module) = visit_queue.pop() {\n+            if visited_modules.insert(module) {\n+                visit_queue.extend(module.children(db));\n \n-            for impl_def in module.impl_defs(db) {\n-                for item in impl_def.items(db) {\n+                for decl in module.declarations(db) {\n                     num_decls += 1;\n-                    if let AssocItem::Function(f) = item {\n+                    if let ModuleDef::Function(f) = decl {\n                         funcs.push(f);\n                     }\n                 }\n+\n+                for impl_def in module.impl_defs(db) {\n+                    for item in impl_def.items(db) {\n+                        num_decls += 1;\n+                        if let AssocItem::Function(f) = item {\n+                            funcs.push(f);\n+                        }\n+                    }\n+                }\n             }\n         }\n-    }\n-    eprintln!(\"Total modules found: {}\", visited_modules.len());\n-    eprintln!(\"Total declarations: {}\", num_decls);\n-    eprintln!(\"Total functions: {}\", funcs.len());\n-    eprintln!(\"Item Collection: {}\", analysis_sw.elapsed());\n-\n-    if randomize {\n-        shuffle(&mut rng, &mut funcs);\n-    }\n+        eprintln!(\"Total modules found: {}\", visited_modules.len());\n+        eprintln!(\"Total declarations: {}\", num_decls);\n+        eprintln!(\"Total functions: {}\", funcs.len());\n+        eprintln!(\"Item Collection: {}\", analysis_sw.elapsed());\n \n-    let mut bar = match verbosity {\n-        Verbosity::Quiet | Verbosity::Spammy => ProgressReport::hidden(),\n-        _ if parallel => ProgressReport::hidden(),\n-        _ => ProgressReport::new(funcs.len() as u64),\n-    };\n+        if self.randomize {\n+            shuffle(&mut rng, &mut funcs);\n+        }\n \n-    if parallel {\n-        let mut inference_sw = StopWatch::start().memory(memory_usage);\n-        let snap = Snap(db.snapshot());\n-        funcs\n-            .par_iter()\n-            .map_with(snap, |snap, &f| {\n-                let f_id = FunctionId::from(f);\n-                snap.0.body(f_id.into());\n-                snap.0.infer(f_id.into());\n-            })\n-            .count();\n-        eprintln!(\"Parallel Inference: {}\", inference_sw.elapsed());\n-    }\n+        let mut bar = match verbosity {\n+            Verbosity::Quiet | Verbosity::Spammy => ProgressReport::hidden(),\n+            _ if self.parallel => ProgressReport::hidden(),\n+            _ => ProgressReport::new(funcs.len() as u64),\n+        };\n \n-    let mut inference_sw = StopWatch::start().memory(memory_usage);\n-    bar.tick();\n-    let mut num_exprs = 0;\n-    let mut num_exprs_unknown = 0;\n-    let mut num_exprs_partially_unknown = 0;\n-    let mut num_type_mismatches = 0;\n-    for f in funcs {\n-        let name = f.name(db);\n-        let full_name = f\n-            .module(db)\n-            .path_to_root(db)\n-            .into_iter()\n-            .rev()\n-            .filter_map(|it| it.name(db))\n-            .chain(Some(f.name(db)))\n-            .join(\"::\");\n-        if let Some(only_name) = only {\n-            if name.to_string() != only_name && full_name != only_name {\n-                continue;\n-            }\n-        }\n-        let mut msg = format!(\"processing: {}\", full_name);\n-        if verbosity.is_verbose() {\n-            let src = f.source(db);\n-            let original_file = src.file_id.original_file(db);\n-            let path = vfs.file_path(original_file);\n-            let syntax_range = src.value.syntax().text_range();\n-            format_to!(msg, \" ({} {:?})\", path, syntax_range);\n+        if self.parallel {\n+            let mut inference_sw = self.stop_watch();\n+            let snap = Snap(db.snapshot());\n+            funcs\n+                .par_iter()\n+                .map_with(snap, |snap, &f| {\n+                    let f_id = FunctionId::from(f);\n+                    snap.0.body(f_id.into());\n+                    snap.0.infer(f_id.into());\n+                })\n+                .count();\n+            eprintln!(\"Parallel Inference: {}\", inference_sw.elapsed());\n         }\n-        if verbosity.is_spammy() {\n-            bar.println(msg.to_string());\n-        }\n-        bar.set_message(&msg);\n-        let f_id = FunctionId::from(f);\n-        let body = db.body(f_id.into());\n-        let inference_result = db.infer(f_id.into());\n-        let (previous_exprs, previous_unknown, previous_partially_unknown) =\n-            (num_exprs, num_exprs_unknown, num_exprs_partially_unknown);\n-        for (expr_id, _) in body.exprs.iter() {\n-            let ty = &inference_result[expr_id];\n-            num_exprs += 1;\n-            if let Ty::Unknown = ty {\n-                num_exprs_unknown += 1;\n-            } else {\n-                let mut is_partially_unknown = false;\n-                ty.walk(&mut |ty| {\n-                    if let Ty::Unknown = ty {\n-                        is_partially_unknown = true;\n-                    }\n-                });\n-                if is_partially_unknown {\n-                    num_exprs_partially_unknown += 1;\n+\n+        let mut inference_sw = self.stop_watch();\n+        bar.tick();\n+        let mut num_exprs = 0;\n+        let mut num_exprs_unknown = 0;\n+        let mut num_exprs_partially_unknown = 0;\n+        let mut num_type_mismatches = 0;\n+        for f in funcs {\n+            let name = f.name(db);\n+            let full_name = f\n+                .module(db)\n+                .path_to_root(db)\n+                .into_iter()\n+                .rev()\n+                .filter_map(|it| it.name(db))\n+                .chain(Some(f.name(db)))\n+                .join(\"::\");\n+            if let Some(only_name) = self.only.as_deref() {\n+                if name.to_string() != only_name && full_name != only_name {\n+                    continue;\n                 }\n             }\n-            if only.is_some() && verbosity.is_spammy() {\n-                // in super-verbose mode for just one function, we print every single expression\n-                let (_, sm) = db.body_with_source_map(f_id.into());\n-                let src = sm.expr_syntax(expr_id);\n-                if let Ok(src) = src {\n-                    let node = {\n-                        let root = db.parse_or_expand(src.file_id).unwrap();\n-                        src.value.to_node(&root)\n-                    };\n-                    let original_file = src.file_id.original_file(db);\n-                    let line_index = host.analysis().file_line_index(original_file).unwrap();\n-                    let text_range = node.syntax().text_range();\n-                    let (start, end) = (\n-                        line_index.line_col(text_range.start()),\n-                        line_index.line_col(text_range.end()),\n-                    );\n-                    bar.println(format!(\n-                        \"{}:{}-{}:{}: {}\",\n-                        start.line + 1,\n-                        start.col_utf16,\n-                        end.line + 1,\n-                        end.col_utf16,\n-                        ty.display(db)\n-                    ));\n+            let mut msg = format!(\"processing: {}\", full_name);\n+            if verbosity.is_verbose() {\n+                let src = f.source(db);\n+                let original_file = src.file_id.original_file(db);\n+                let path = vfs.file_path(original_file);\n+                let syntax_range = src.value.syntax().text_range();\n+                format_to!(msg, \" ({} {:?})\", path, syntax_range);\n+            }\n+            if verbosity.is_spammy() {\n+                bar.println(msg.to_string());\n+            }\n+            bar.set_message(&msg);\n+            let f_id = FunctionId::from(f);\n+            let body = db.body(f_id.into());\n+            let inference_result = db.infer(f_id.into());\n+            let (previous_exprs, previous_unknown, previous_partially_unknown) =\n+                (num_exprs, num_exprs_unknown, num_exprs_partially_unknown);\n+            for (expr_id, _) in body.exprs.iter() {\n+                let ty = &inference_result[expr_id];\n+                num_exprs += 1;\n+                if let Ty::Unknown = ty {\n+                    num_exprs_unknown += 1;\n                 } else {\n-                    bar.println(format!(\"unknown location: {}\", ty.display(db)));\n+                    let mut is_partially_unknown = false;\n+                    ty.walk(&mut |ty| {\n+                        if let Ty::Unknown = ty {\n+                            is_partially_unknown = true;\n+                        }\n+                    });\n+                    if is_partially_unknown {\n+                        num_exprs_partially_unknown += 1;\n+                    }\n                 }\n-            }\n-            if let Some(mismatch) = inference_result.type_mismatch_for_expr(expr_id) {\n-                num_type_mismatches += 1;\n-                if verbosity.is_verbose() {\n+                if self.only.is_some() && verbosity.is_spammy() {\n+                    // in super-verbose mode for just one function, we print every single expression\n                     let (_, sm) = db.body_with_source_map(f_id.into());\n                     let src = sm.expr_syntax(expr_id);\n                     if let Ok(src) = src {\n-                        // FIXME: it might be nice to have a function (on Analysis?) that goes from Source<T> -> (LineCol, LineCol) directly\n-                        // But also, we should just turn the type mismatches into diagnostics and provide these\n-                        let root = db.parse_or_expand(src.file_id).unwrap();\n-                        let node = src.map(|e| e.to_node(&root).syntax().clone());\n-                        let original_range = original_range(db, node.as_ref());\n-                        let path = vfs.file_path(original_range.file_id);\n-                        let line_index =\n-                            host.analysis().file_line_index(original_range.file_id).unwrap();\n-                        let text_range = original_range.range;\n+                        let node = {\n+                            let root = db.parse_or_expand(src.file_id).unwrap();\n+                            src.value.to_node(&root)\n+                        };\n+                        let original_file = src.file_id.original_file(db);\n+                        let line_index = host.analysis().file_line_index(original_file).unwrap();\n+                        let text_range = node.syntax().text_range();\n                         let (start, end) = (\n                             line_index.line_col(text_range.start()),\n                             line_index.line_col(text_range.end()),\n                         );\n                         bar.println(format!(\n-                            \"{} {}:{}-{}:{}: Expected {}, got {}\",\n-                            path,\n+                            \"{}:{}-{}:{}: {}\",\n                             start.line + 1,\n                             start.col_utf16,\n                             end.line + 1,\n                             end.col_utf16,\n-                            mismatch.expected.display(db),\n-                            mismatch.actual.display(db)\n+                            ty.display(db)\n                         ));\n                     } else {\n-                        bar.println(format!(\n-                            \"{}: Expected {}, got {}\",\n-                            name,\n-                            mismatch.expected.display(db),\n-                            mismatch.actual.display(db)\n-                        ));\n+                        bar.println(format!(\"unknown location: {}\", ty.display(db)));\n+                    }\n+                }\n+                if let Some(mismatch) = inference_result.type_mismatch_for_expr(expr_id) {\n+                    num_type_mismatches += 1;\n+                    if verbosity.is_verbose() {\n+                        let (_, sm) = db.body_with_source_map(f_id.into());\n+                        let src = sm.expr_syntax(expr_id);\n+                        if let Ok(src) = src {\n+                            // FIXME: it might be nice to have a function (on Analysis?) that goes from Source<T> -> (LineCol, LineCol) directly\n+                            // But also, we should just turn the type mismatches into diagnostics and provide these\n+                            let root = db.parse_or_expand(src.file_id).unwrap();\n+                            let node = src.map(|e| e.to_node(&root).syntax().clone());\n+                            let original_range = original_range(db, node.as_ref());\n+                            let path = vfs.file_path(original_range.file_id);\n+                            let line_index =\n+                                host.analysis().file_line_index(original_range.file_id).unwrap();\n+                            let text_range = original_range.range;\n+                            let (start, end) = (\n+                                line_index.line_col(text_range.start()),\n+                                line_index.line_col(text_range.end()),\n+                            );\n+                            bar.println(format!(\n+                                \"{} {}:{}-{}:{}: Expected {}, got {}\",\n+                                path,\n+                                start.line + 1,\n+                                start.col_utf16,\n+                                end.line + 1,\n+                                end.col_utf16,\n+                                mismatch.expected.display(db),\n+                                mismatch.actual.display(db)\n+                            ));\n+                        } else {\n+                            bar.println(format!(\n+                                \"{}: Expected {}, got {}\",\n+                                name,\n+                                mismatch.expected.display(db),\n+                                mismatch.actual.display(db)\n+                            ));\n+                        }\n                     }\n                 }\n             }\n+            if verbosity.is_spammy() {\n+                bar.println(format!(\n+                    \"In {}: {} exprs, {} unknown, {} partial\",\n+                    full_name,\n+                    num_exprs - previous_exprs,\n+                    num_exprs_unknown - previous_unknown,\n+                    num_exprs_partially_unknown - previous_partially_unknown\n+                ));\n+            }\n+            bar.inc(1);\n         }\n-        if verbosity.is_spammy() {\n-            bar.println(format!(\n-                \"In {}: {} exprs, {} unknown, {} partial\",\n-                full_name,\n-                num_exprs - previous_exprs,\n-                num_exprs_unknown - previous_unknown,\n-                num_exprs_partially_unknown - previous_partially_unknown\n-            ));\n-        }\n-        bar.inc(1);\n-    }\n-    bar.finish_and_clear();\n-    eprintln!(\"Total expressions: {}\", num_exprs);\n-    eprintln!(\n-        \"Expressions of unknown type: {} ({}%)\",\n-        num_exprs_unknown,\n-        if num_exprs > 0 { num_exprs_unknown * 100 / num_exprs } else { 100 }\n-    );\n-    report_metric(\"unknown type\", num_exprs_unknown, \"#\");\n+        bar.finish_and_clear();\n+        eprintln!(\"Total expressions: {}\", num_exprs);\n+        eprintln!(\n+            \"Expressions of unknown type: {} ({}%)\",\n+            num_exprs_unknown,\n+            if num_exprs > 0 { num_exprs_unknown * 100 / num_exprs } else { 100 }\n+        );\n+        report_metric(\"unknown type\", num_exprs_unknown, \"#\");\n \n-    eprintln!(\n-        \"Expressions of partially unknown type: {} ({}%)\",\n-        num_exprs_partially_unknown,\n-        if num_exprs > 0 { num_exprs_partially_unknown * 100 / num_exprs } else { 100 }\n-    );\n+        eprintln!(\n+            \"Expressions of partially unknown type: {} ({}%)\",\n+            num_exprs_partially_unknown,\n+            if num_exprs > 0 { num_exprs_partially_unknown * 100 / num_exprs } else { 100 }\n+        );\n \n-    eprintln!(\"Type mismatches: {}\", num_type_mismatches);\n-    report_metric(\"type mismatches\", num_type_mismatches, \"#\");\n+        eprintln!(\"Type mismatches: {}\", num_type_mismatches);\n+        report_metric(\"type mismatches\", num_type_mismatches, \"#\");\n \n-    eprintln!(\"Inference: {}\", inference_sw.elapsed());\n+        eprintln!(\"Inference: {}\", inference_sw.elapsed());\n \n-    let total_span = analysis_sw.elapsed();\n-    eprintln!(\"Total: {}\", total_span);\n-    report_metric(\"total time\", total_span.time.as_millis() as u64, \"ms\");\n-    if let Some(instructions) = total_span.instructions {\n-        report_metric(\"total instructions\", instructions, \"#instr\");\n-    }\n-    if let Some(memory) = total_span.memory {\n-        report_metric(\"total memory\", memory.allocated.megabytes() as u64, \"MB\");\n-    }\n+        let total_span = analysis_sw.elapsed();\n+        eprintln!(\"Total: {}\", total_span);\n+        report_metric(\"total time\", total_span.time.as_millis() as u64, \"ms\");\n+        if let Some(instructions) = total_span.instructions {\n+            report_metric(\"total instructions\", instructions, \"#instr\");\n+        }\n+        if let Some(memory) = total_span.memory {\n+            report_metric(\"total memory\", memory.allocated.megabytes() as u64, \"MB\");\n+        }\n \n-    if memory_usage {\n-        print_memory_usage(host, vfs);\n+        if self.memory_usage {\n+            print_memory_usage(host, vfs);\n+        }\n+\n+        Ok(())\n     }\n \n-    Ok(())\n+    fn stop_watch(&self) -> StopWatch {\n+        StopWatch::start().memory(self.memory_usage)\n+    }\n }\n \n fn shuffle<T>(rng: &mut Rand32, slice: &mut [T]) {"}]}