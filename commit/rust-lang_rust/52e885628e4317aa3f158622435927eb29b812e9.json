{"sha": "52e885628e4317aa3f158622435927eb29b812e9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjUyZTg4NTYyOGU0MzE3YWEzZjE1ODYyMjQzNTkyN2ViMjliODEyZTk=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-03-15T19:24:15Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2019-03-15T19:24:15Z"}, "message": "Auto merge of #58556 - oli-obk:imperative_recursion, r=pnkfelix\n\nOptimize copying large ranges of undefmask blocks\n\nHopefully fixes #58523", "tree": {"sha": "724467877f922110e0be9fcc9a7f3e59e6c0a008", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/724467877f922110e0be9fcc9a7f3e59e6c0a008"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/52e885628e4317aa3f158622435927eb29b812e9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/52e885628e4317aa3f158622435927eb29b812e9", "html_url": "https://github.com/rust-lang/rust/commit/52e885628e4317aa3f158622435927eb29b812e9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/52e885628e4317aa3f158622435927eb29b812e9/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ad8a3eb039ca3dc1ff5a3d5757afc5e5330c1bce", "url": "https://api.github.com/repos/rust-lang/rust/commits/ad8a3eb039ca3dc1ff5a3d5757afc5e5330c1bce", "html_url": "https://github.com/rust-lang/rust/commit/ad8a3eb039ca3dc1ff5a3d5757afc5e5330c1bce"}, {"sha": "2a1eb1cef1a36c6f0a9d2e347529561c1293044e", "url": "https://api.github.com/repos/rust-lang/rust/commits/2a1eb1cef1a36c6f0a9d2e347529561c1293044e", "html_url": "https://github.com/rust-lang/rust/commit/2a1eb1cef1a36c6f0a9d2e347529561c1293044e"}], "stats": {"total": 204, "additions": 165, "deletions": 39}, "files": [{"sha": "80fef910cc71811e98ea867c67b7dec3ef251d76", "filename": "src/librustc/mir/interpret/allocation.rs", "status": "modified", "additions": 63, "deletions": 13, "changes": 76, "blob_url": "https://github.com/rust-lang/rust/blob/52e885628e4317aa3f158622435927eb29b812e9/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52e885628e4317aa3f158622435927eb29b812e9/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fmir%2Finterpret%2Fallocation.rs?ref=52e885628e4317aa3f158622435927eb29b812e9", "patch": "@@ -101,8 +101,7 @@ impl AllocationExtra<(), ()> for () {\n impl<Tag, Extra> Allocation<Tag, Extra> {\n     /// Creates a read-only allocation initialized by the given bytes\n     pub fn from_bytes(slice: &[u8], align: Align, extra: Extra) -> Self {\n-        let mut undef_mask = UndefMask::new(Size::ZERO);\n-        undef_mask.grow(Size::from_bytes(slice.len() as u64), true);\n+        let undef_mask = UndefMask::new(Size::from_bytes(slice.len() as u64), true);\n         Self {\n             bytes: slice.to_owned(),\n             relocations: Relocations::new(),\n@@ -122,7 +121,7 @@ impl<Tag, Extra> Allocation<Tag, Extra> {\n         Allocation {\n             bytes: vec![0; size.bytes() as usize],\n             relocations: Relocations::new(),\n-            undef_mask: UndefMask::new(size),\n+            undef_mask: UndefMask::new(size, false),\n             align,\n             mutability: Mutability::Mutable,\n             extra,\n@@ -614,8 +613,9 @@ impl<Tag> DerefMut for Relocations<Tag> {\n ////////////////////////////////////////////////////////////////////////////////\n \n type Block = u64;\n-const BLOCK_SIZE: u64 = 64;\n \n+/// A bitmask where each bit refers to the byte with the same index. If the bit is `true`, the byte\n+/// is defined. If it is `false` the byte is undefined.\n #[derive(Clone, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, RustcEncodable, RustcDecodable)]\n pub struct UndefMask {\n     blocks: Vec<Block>,\n@@ -625,12 +625,14 @@ pub struct UndefMask {\n impl_stable_hash_for!(struct mir::interpret::UndefMask{blocks, len});\n \n impl UndefMask {\n-    pub fn new(size: Size) -> Self {\n+    pub const BLOCK_SIZE: u64 = 64;\n+\n+    pub fn new(size: Size, state: bool) -> Self {\n         let mut m = UndefMask {\n             blocks: vec![],\n             len: Size::ZERO,\n         };\n-        m.grow(size, false);\n+        m.grow(size, state);\n         m\n     }\n \n@@ -644,6 +646,7 @@ impl UndefMask {\n             return Err(self.len);\n         }\n \n+        // FIXME(oli-obk): optimize this for allocations larger than a block.\n         let idx = (start.bytes()..end.bytes())\n             .map(|i| Size::from_bytes(i))\n             .find(|&i| !self.get(i));\n@@ -663,20 +666,63 @@ impl UndefMask {\n     }\n \n     pub fn set_range_inbounds(&mut self, start: Size, end: Size, new_state: bool) {\n-        for i in start.bytes()..end.bytes() {\n-            self.set(Size::from_bytes(i), new_state);\n+        let (blocka, bita) = bit_index(start);\n+        let (blockb, bitb) = bit_index(end);\n+        if blocka == blockb {\n+            // first set all bits but the first `bita`\n+            // then unset the last `64 - bitb` bits\n+            let range = if bitb == 0 {\n+                u64::max_value() << bita\n+            } else {\n+                (u64::max_value() << bita) & (u64::max_value() >> (64 - bitb))\n+            };\n+            if new_state {\n+                self.blocks[blocka] |= range;\n+            } else {\n+                self.blocks[blocka] &= !range;\n+            }\n+            return;\n+        }\n+        // across block boundaries\n+        if new_state {\n+            // set bita..64 to 1\n+            self.blocks[blocka] |= u64::max_value() << bita;\n+            // set 0..bitb to 1\n+            if bitb != 0 {\n+                self.blocks[blockb] |= u64::max_value() >> (64 - bitb);\n+            }\n+            // fill in all the other blocks (much faster than one bit at a time)\n+            for block in (blocka + 1) .. blockb {\n+                self.blocks[block] = u64::max_value();\n+            }\n+        } else {\n+            // set bita..64 to 0\n+            self.blocks[blocka] &= !(u64::max_value() << bita);\n+            // set 0..bitb to 0\n+            if bitb != 0 {\n+                self.blocks[blockb] &= !(u64::max_value() >> (64 - bitb));\n+            }\n+            // fill in all the other blocks (much faster than one bit at a time)\n+            for block in (blocka + 1) .. blockb {\n+                self.blocks[block] = 0;\n+            }\n         }\n     }\n \n     #[inline]\n     pub fn get(&self, i: Size) -> bool {\n         let (block, bit) = bit_index(i);\n-        (self.blocks[block] & 1 << bit) != 0\n+        (self.blocks[block] & (1 << bit)) != 0\n     }\n \n     #[inline]\n     pub fn set(&mut self, i: Size, new_state: bool) {\n         let (block, bit) = bit_index(i);\n+        self.set_bit(block, bit, new_state);\n+    }\n+\n+    #[inline]\n+    fn set_bit(&mut self, block: usize, bit: usize, new_state: bool) {\n         if new_state {\n             self.blocks[block] |= 1 << bit;\n         } else {\n@@ -685,11 +731,15 @@ impl UndefMask {\n     }\n \n     pub fn grow(&mut self, amount: Size, new_state: bool) {\n-        let unused_trailing_bits = self.blocks.len() as u64 * BLOCK_SIZE - self.len.bytes();\n+        if amount.bytes() == 0 {\n+            return;\n+        }\n+        let unused_trailing_bits = self.blocks.len() as u64 * Self::BLOCK_SIZE - self.len.bytes();\n         if amount.bytes() > unused_trailing_bits {\n-            let additional_blocks = amount.bytes() / BLOCK_SIZE + 1;\n+            let additional_blocks = amount.bytes() / Self::BLOCK_SIZE + 1;\n             assert_eq!(additional_blocks as usize as u64, additional_blocks);\n             self.blocks.extend(\n+                // FIXME(oli-obk): optimize this by repeating `new_state as Block`\n                 iter::repeat(0).take(additional_blocks as usize),\n             );\n         }\n@@ -702,8 +752,8 @@ impl UndefMask {\n #[inline]\n fn bit_index(bits: Size) -> (usize, usize) {\n     let bits = bits.bytes();\n-    let a = bits / BLOCK_SIZE;\n-    let b = bits % BLOCK_SIZE;\n+    let a = bits / UndefMask::BLOCK_SIZE;\n+    let b = bits % UndefMask::BLOCK_SIZE;\n     assert_eq!(a as usize as u64, a);\n     assert_eq!(b as usize as u64, b);\n     (a as usize, b as usize)"}, {"sha": "6ea200d4e4fad3519335096d9b912e41c95e31a6", "filename": "src/librustc_mir/interpret/memory.rs", "status": "modified", "additions": 76, "deletions": 26, "changes": 102, "blob_url": "https://github.com/rust-lang/rust/blob/52e885628e4317aa3f158622435927eb29b812e9/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52e885628e4317aa3f158622435927eb29b812e9/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_mir%2Finterpret%2Fmemory.rs?ref=52e885628e4317aa3f158622435927eb29b812e9", "patch": "@@ -700,24 +700,29 @@ impl<'a, 'mir, 'tcx, M: Machine<'a, 'mir, 'tcx>> Memory<'a, 'mir, 'tcx, M> {\n         // relocations overlapping the edges; those would not be handled correctly).\n         let relocations = {\n             let relocations = self.get(src.alloc_id)?.relocations(self, src, size);\n-            let mut new_relocations = Vec::with_capacity(relocations.len() * (length as usize));\n-            for i in 0..length {\n-                new_relocations.extend(\n-                    relocations\n-                    .iter()\n-                    .map(|&(offset, reloc)| {\n-                        // compute offset for current repetition\n-                        let dest_offset = dest.offset + (i * size);\n-                        (\n-                            // shift offsets from source allocation to destination allocation\n-                            offset + dest_offset - src.offset,\n-                            reloc,\n-                        )\n-                    })\n-                );\n-            }\n+            if relocations.is_empty() {\n+                // nothing to copy, ignore even the `length` loop\n+                Vec::new()\n+            } else {\n+                let mut new_relocations = Vec::with_capacity(relocations.len() * (length as usize));\n+                for i in 0..length {\n+                    new_relocations.extend(\n+                        relocations\n+                        .iter()\n+                        .map(|&(offset, reloc)| {\n+                            // compute offset for current repetition\n+                            let dest_offset = dest.offset + (i * size);\n+                            (\n+                                // shift offsets from source allocation to destination allocation\n+                                offset + dest_offset - src.offset,\n+                                reloc,\n+                            )\n+                        })\n+                    );\n+                }\n \n-            new_relocations\n+                new_relocations\n+            }\n         };\n \n         let tcx = self.tcx.tcx;\n@@ -784,20 +789,65 @@ impl<'a, 'mir, 'tcx, M: Machine<'a, 'mir, 'tcx>> Memory<'a, 'mir, 'tcx, M> {\n         // The bits have to be saved locally before writing to dest in case src and dest overlap.\n         assert_eq!(size.bytes() as usize as u64, size.bytes());\n \n-        let undef_mask = self.get(src.alloc_id)?.undef_mask.clone();\n-        let dest_allocation = self.get_mut(dest.alloc_id)?;\n+        let undef_mask = &self.get(src.alloc_id)?.undef_mask;\n+\n+        // Since we are copying `size` bytes from `src` to `dest + i * size` (`for i in 0..repeat`),\n+        // a naive undef mask copying algorithm would repeatedly have to read the undef mask from\n+        // the source and write it to the destination. Even if we optimized the memory accesses,\n+        // we'd be doing all of this `repeat` times.\n+        // Therefor we precompute a compressed version of the undef mask of the source value and\n+        // then write it back `repeat` times without computing any more information from the source.\n+\n+        // a precomputed cache for ranges of defined/undefined bits\n+        // 0000010010001110 will become\n+        // [5, 1, 2, 1, 3, 3, 1]\n+        // where each element toggles the state\n+        let mut ranges = smallvec::SmallVec::<[u64; 1]>::new();\n+        let first = undef_mask.get(src.offset);\n+        let mut cur_len = 1;\n+        let mut cur = first;\n+        for i in 1..size.bytes() {\n+            // FIXME: optimize to bitshift the current undef block's bits and read the top bit\n+            if undef_mask.get(src.offset + Size::from_bytes(i)) == cur {\n+                cur_len += 1;\n+            } else {\n+                ranges.push(cur_len);\n+                cur_len = 1;\n+                cur = !cur;\n+            }\n+        }\n \n-        for i in 0..size.bytes() {\n-            let defined = undef_mask.get(src.offset + Size::from_bytes(i));\n+        // now fill in all the data\n+        let dest_allocation = self.get_mut(dest.alloc_id)?;\n+        // an optimization where we can just overwrite an entire range of definedness bits if\n+        // they are going to be uniformly `1` or `0`.\n+        if ranges.is_empty() {\n+            dest_allocation.undef_mask.set_range_inbounds(\n+                dest.offset,\n+                dest.offset + size * repeat,\n+                first,\n+            );\n+            return Ok(())\n+        }\n \n-            for j in 0..repeat {\n-                dest_allocation.undef_mask.set(\n-                    dest.offset + Size::from_bytes(i + (size.bytes() * j)),\n-                    defined\n+        // remember to fill in the trailing bits\n+        ranges.push(cur_len);\n+\n+        for mut j in 0..repeat {\n+            j *= size.bytes();\n+            j += dest.offset.bytes();\n+            let mut cur = first;\n+            for range in &ranges {\n+                let old_j = j;\n+                j += range;\n+                dest_allocation.undef_mask.set_range_inbounds(\n+                    Size::from_bytes(old_j),\n+                    Size::from_bytes(j),\n+                    cur,\n                 );\n+                cur = !cur;\n             }\n         }\n-\n         Ok(())\n     }\n }"}, {"sha": "cf6e6f72316384812aa6ed749f7e6d1b66bd751f", "filename": "src/test/run-pass-fulldeps/undef_mask.rs", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/rust-lang/rust/blob/52e885628e4317aa3f158622435927eb29b812e9/src%2Ftest%2Frun-pass-fulldeps%2Fundef_mask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/52e885628e4317aa3f158622435927eb29b812e9/src%2Ftest%2Frun-pass-fulldeps%2Fundef_mask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fundef_mask.rs?ref=52e885628e4317aa3f158622435927eb29b812e9", "patch": "@@ -0,0 +1,26 @@\n+// ignore-cross-compile\n+// ignore-stage1\n+\n+#![feature(rustc_private)]\n+\n+extern crate rustc;\n+\n+use rustc::mir::interpret::UndefMask;\n+use rustc::ty::layout::Size;\n+\n+fn main() {\n+    let mut mask = UndefMask::new(Size::from_bytes(500), false);\n+    assert!(!mask.get(Size::from_bytes(499)));\n+    mask.set(Size::from_bytes(499), true);\n+    assert!(mask.get(Size::from_bytes(499)));\n+    mask.set_range_inbounds(Size::from_bytes(100), Size::from_bytes(256), true);\n+    for i in 0..100 {\n+        assert!(!mask.get(Size::from_bytes(i)));\n+    }\n+    for i in 100..256 {\n+        assert!(mask.get(Size::from_bytes(i)));\n+    }\n+    for i in 256..499 {\n+        assert!(!mask.get(Size::from_bytes(i)));\n+    }\n+}"}]}