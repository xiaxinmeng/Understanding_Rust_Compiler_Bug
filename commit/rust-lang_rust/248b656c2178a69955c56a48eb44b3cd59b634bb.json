{"sha": "248b656c2178a69955c56a48eb44b3cd59b634bb", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI0OGI2NTZjMjE3OGE2OTk1NWM1NmE0OGViNDRiM2NkNTliNjM0YmI=", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2020-07-01T11:40:47Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-07-01T11:40:47Z"}, "message": "Merge #5162\n\n5162: Try to reduce Semantics monomorphisations r=matklad a=lnicola\n\n\n\nCo-authored-by: Lauren\u021biu Nicola <lnicola@dend.ro>", "tree": {"sha": "3dd06d0f68a2ce856097fd064fbd9354ebedb645", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/3dd06d0f68a2ce856097fd064fbd9354ebedb645"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/248b656c2178a69955c56a48eb44b3cd59b634bb", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe/HY/CRBK7hj4Ov3rIwAAdHIIAJnJ7hnVgs08GM1pdBVAtZYW\nfTICBZb17m5MHOVuRDReOaAjkIXghg10B+7IrZU5IfvzU7csTqCAw9HwJDAdHgRH\nu9ProIOXLzZa/S1qPwTHMlqW3/MvWtdI3bgY6Xak+EDXU4bWmcgsp+MQ1h2a88WU\nbMjNgNpUZQMk+Yqce99dA6xV31ANgL87j8u9feI0s7StazflvTvZ2EHScMqdreYk\nKX9D+Ic2mRJHOF1yprUIbOGgJhsb3xKMBUI8cMrqUK8WKZ3/0SsYTEiQOi37P7G6\nz0hHJ5C43C56XP6SDwZ+D8zUyYMKFFbiILJEInp89a8qZunXBcm5iQFYQZRId4M=\n=wPKN\n-----END PGP SIGNATURE-----\n", "payload": "tree 3dd06d0f68a2ce856097fd064fbd9354ebedb645\nparent f372b13a858a6d037e38ab13ec7ae0286be5a001\nparent d89827f9e01d855e9116a0d5276ffe1dad34ed3b\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1593603647 +0000\ncommitter GitHub <noreply@github.com> 1593603647 +0000\n\nMerge #5162\n\n5162: Try to reduce Semantics monomorphisations r=matklad a=lnicola\n\n\n\nCo-authored-by: Lauren\u021biu Nicola <lnicola@dend.ro>\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/248b656c2178a69955c56a48eb44b3cd59b634bb", "html_url": "https://github.com/rust-lang/rust/commit/248b656c2178a69955c56a48eb44b3cd59b634bb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/248b656c2178a69955c56a48eb44b3cd59b634bb/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f372b13a858a6d037e38ab13ec7ae0286be5a001", "url": "https://api.github.com/repos/rust-lang/rust/commits/f372b13a858a6d037e38ab13ec7ae0286be5a001", "html_url": "https://github.com/rust-lang/rust/commit/f372b13a858a6d037e38ab13ec7ae0286be5a001"}, {"sha": "d89827f9e01d855e9116a0d5276ffe1dad34ed3b", "url": "https://api.github.com/repos/rust-lang/rust/commits/d89827f9e01d855e9116a0d5276ffe1dad34ed3b", "html_url": "https://github.com/rust-lang/rust/commit/d89827f9e01d855e9116a0d5276ffe1dad34ed3b"}], "stats": {"total": 261, "additions": 204, "deletions": 57}, "files": [{"sha": "3d78f71c1fa8f8d9bf5d4475a16a4d9f5dbae460", "filename": "crates/ra_hir/src/semantics.rs", "status": "modified", "additions": 197, "deletions": 56, "changes": 253, "blob_url": "https://github.com/rust-lang/rust/blob/248b656c2178a69955c56a48eb44b3cd59b634bb/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/248b656c2178a69955c56a48eb44b3cd59b634bb/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsemantics.rs?ref=248b656c2178a69955c56a48eb44b3cd59b634bb", "patch": "@@ -83,6 +83,11 @@ impl PathResolution {\n /// Primary API to get semantic information, like types, from syntax trees.\n pub struct Semantics<'db, DB> {\n     pub db: &'db DB,\n+    imp: SemanticsImpl<'db>,\n+}\n+\n+pub struct SemanticsImpl<'db> {\n+    pub db: &'db dyn HirDatabase,\n     s2d_cache: RefCell<SourceToDefCache>,\n     cache: RefCell<FxHashMap<SyntaxNode, HirFileId>>,\n }\n@@ -95,20 +100,180 @@ impl<DB> fmt::Debug for Semantics<'_, DB> {\n \n impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n     pub fn new(db: &DB) -> Semantics<DB> {\n-        Semantics { db, s2d_cache: Default::default(), cache: Default::default() }\n+        let impl_ = SemanticsImpl::new(db);\n+        Semantics { db, imp: impl_ }\n     }\n \n     pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n-        let tree = self.db.parse(file_id).tree();\n-        self.cache(tree.syntax().clone(), file_id.into());\n-        tree\n+        self.imp.parse(file_id)\n     }\n \n     pub fn ast<T: AstDiagnostic + Diagnostic>(&self, d: &T) -> <T as AstDiagnostic>::AST {\n         let file_id = d.source().file_id;\n         let root = self.db.parse_or_expand(file_id).unwrap();\n-        self.cache(root, file_id);\n-        d.ast(self.db)\n+        self.imp.cache(root, file_id);\n+        d.ast(self.db.upcast())\n+    }\n+\n+    pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n+        self.imp.expand(macro_call)\n+    }\n+\n+    pub fn expand_hypothetical(\n+        &self,\n+        actual_macro_call: &ast::MacroCall,\n+        hypothetical_args: &ast::TokenTree,\n+        token_to_map: SyntaxToken,\n+    ) -> Option<(SyntaxNode, SyntaxToken)> {\n+        self.imp.expand_hypothetical(actual_macro_call, hypothetical_args, token_to_map)\n+    }\n+\n+    pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n+        self.imp.descend_into_macros(token)\n+    }\n+\n+    pub fn descend_node_at_offset<N: ast::AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        self.imp.descend_node_at_offset(node, offset).find_map(N::cast)\n+    }\n+\n+    pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n+        self.imp.original_range(node)\n+    }\n+\n+    pub fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n+        self.imp.diagnostics_range(diagnostics)\n+    }\n+\n+    pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n+        self.imp.ancestors_with_macros(node)\n+    }\n+\n+    pub fn ancestors_at_offset_with_macros(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> impl Iterator<Item = SyntaxNode> + '_ {\n+        self.imp.ancestors_at_offset_with_macros(node, offset)\n+    }\n+\n+    /// Find a AstNode by offset inside SyntaxNode, if it is inside *Macrofile*,\n+    /// search up until it is of the target AstNode type\n+    pub fn find_node_at_offset_with_macros<N: AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        self.imp.ancestors_at_offset_with_macros(node, offset).find_map(N::cast)\n+    }\n+\n+    /// Find a AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,\n+    /// descend it and find again\n+    pub fn find_node_at_offset_with_descend<N: AstNode>(\n+        &self,\n+        node: &SyntaxNode,\n+        offset: TextSize,\n+    ) -> Option<N> {\n+        if let Some(it) = find_node_at_offset(&node, offset) {\n+            return Some(it);\n+        }\n+\n+        self.imp.descend_node_at_offset(node, offset).find_map(N::cast)\n+    }\n+\n+    pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n+        self.imp.type_of_expr(expr)\n+    }\n+\n+    pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n+        self.imp.type_of_pat(pat)\n+    }\n+\n+    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+        self.imp.resolve_method_call(call)\n+    }\n+\n+    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n+        self.imp.resolve_field(field)\n+    }\n+\n+    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n+        self.imp.resolve_record_field(field)\n+    }\n+\n+    pub fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n+        self.imp.resolve_record_field_pat(field)\n+    }\n+\n+    pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n+        self.imp.resolve_macro_call(macro_call)\n+    }\n+\n+    pub fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n+        self.imp.resolve_path(path)\n+    }\n+\n+    pub fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n+        self.imp.resolve_variant(record_lit)\n+    }\n+\n+    pub fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n+        self.imp.lower_path(path)\n+    }\n+\n+    pub fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n+        self.imp.resolve_bind_pat_to_const(pat)\n+    }\n+\n+    // FIXME: use this instead?\n+    // pub fn resolve_name_ref(&self, name_ref: &ast::NameRef) -> Option<???>;\n+\n+    pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n+        self.imp.record_literal_missing_fields(literal)\n+    }\n+\n+    pub fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n+        self.imp.record_pattern_missing_fields(pattern)\n+    }\n+\n+    pub fn to_def<T: ToDef>(&self, src: &T) -> Option<T::Def> {\n+        let src = self.imp.find_file(src.syntax().clone()).with_value(src).cloned();\n+        T::to_def(&self.imp, src)\n+    }\n+\n+    pub fn to_module_def(&self, file: FileId) -> Option<Module> {\n+        self.imp.to_module_def(file)\n+    }\n+\n+    pub fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n+        self.imp.scope(node)\n+    }\n+\n+    pub fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n+        self.imp.scope_at_offset(node, offset)\n+    }\n+\n+    pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n+        self.imp.scope_for_def(def)\n+    }\n+\n+    pub fn assert_contains_node(&self, node: &SyntaxNode) {\n+        self.imp.assert_contains_node(node)\n+    }\n+}\n+\n+impl<'db> SemanticsImpl<'db> {\n+    pub fn new(db: &'db dyn HirDatabase) -> Self {\n+        Self { db, s2d_cache: Default::default(), cache: Default::default() }\n+    }\n+\n+    pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n+        let tree = self.db.parse(file_id).tree();\n+        self.cache(tree.syntax().clone(), file_id.into());\n+        tree\n     }\n \n     pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n@@ -130,9 +295,15 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             self.find_file(actual_macro_call.syntax().clone()).with_value(actual_macro_call);\n         let sa = self.analyze2(macro_call.map(|it| it.syntax()), None);\n         let krate = sa.resolver.krate()?;\n-        let macro_call_id = macro_call\n-            .as_call_id(self.db, krate, |path| sa.resolver.resolve_path_as_macro(self.db, &path))?;\n-        hir_expand::db::expand_hypothetical(self.db, macro_call_id, hypothetical_args, token_to_map)\n+        let macro_call_id = macro_call.as_call_id(self.db.upcast(), krate, |path| {\n+            sa.resolver.resolve_path_as_macro(self.db.upcast(), &path)\n+        })?;\n+        hir_expand::db::expand_hypothetical(\n+            self.db.upcast(),\n+            macro_call_id,\n+            hypothetical_args,\n+            token_to_map,\n+        )\n     }\n \n     pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n@@ -147,7 +318,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n                 return None;\n             }\n             let file_id = sa.expand(self.db, token.with_value(&macro_call))?;\n-            let token = file_id.expansion_info(self.db)?.map_token_down(token.as_ref())?;\n+            let token = file_id.expansion_info(self.db.upcast())?.map_token_down(token.as_ref())?;\n \n             self.cache(find_root(&token.value.parent()), token.file_id);\n \n@@ -159,15 +330,16 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         token.value\n     }\n \n-    pub fn descend_node_at_offset<N: ast::AstNode>(\n+    pub fn descend_node_at_offset(\n         &self,\n         node: &SyntaxNode,\n         offset: TextSize,\n-    ) -> Option<N> {\n+    ) -> impl Iterator<Item = SyntaxNode> + '_ {\n         // Handle macro token cases\n         node.token_at_offset(offset)\n             .map(|token| self.descend_into_macros(token))\n-            .find_map(|it| self.ancestors_with_macros(it.parent()).find_map(N::cast))\n+            .map(|it| self.ancestors_with_macros(it.parent()))\n+            .flatten()\n     }\n \n     pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n@@ -184,7 +356,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n \n     pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n         let node = self.find_file(node);\n-        node.ancestors_with_macros(self.db).map(|it| it.value)\n+        node.ancestors_with_macros(self.db.upcast()).map(|it| it.value)\n     }\n \n     pub fn ancestors_at_offset_with_macros(\n@@ -197,29 +369,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             .kmerge_by(|node1, node2| node1.text_range().len() < node2.text_range().len())\n     }\n \n-    /// Find a AstNode by offset inside SyntaxNode, if it is inside *Macrofile*,\n-    /// search up until it is of the target AstNode type\n-    pub fn find_node_at_offset_with_macros<N: AstNode>(\n-        &self,\n-        node: &SyntaxNode,\n-        offset: TextSize,\n-    ) -> Option<N> {\n-        self.ancestors_at_offset_with_macros(node, offset).find_map(N::cast)\n-    }\n-\n-    /// Find a AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,\n-    /// descend it and find again\n-    pub fn find_node_at_offset_with_descend<N: AstNode>(\n-        &self,\n-        node: &SyntaxNode,\n-        offset: TextSize,\n-    ) -> Option<N> {\n-        if let Some(it) = find_node_at_offset(&node, offset) {\n-            return Some(it);\n-        }\n-        self.descend_node_at_offset(&node, offset)\n-    }\n-\n     pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n         self.analyze(expr.syntax()).type_of(self.db, &expr)\n     }\n@@ -267,9 +416,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         self.analyze(pat.syntax()).resolve_bind_pat_to_const(self.db, pat)\n     }\n \n-    // FIXME: use this instead?\n-    // pub fn resolve_name_ref(&self, name_ref: &ast::NameRef) -> Option<???>;\n-\n     pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n         self.analyze(literal.syntax())\n             .record_literal_missing_fields(self.db, literal)\n@@ -282,11 +428,6 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             .unwrap_or_default()\n     }\n \n-    pub fn to_def<T: ToDef>(&self, src: &T) -> Option<T::Def> {\n-        let src = self.find_file(src.syntax().clone()).with_value(src).cloned();\n-        T::to_def(self, src)\n-    }\n-\n     fn with_ctx<F: FnOnce(&mut SourceToDefCtx) -> T, T>(&self, f: F) -> T {\n         let mut cache = self.s2d_cache.borrow_mut();\n         let mut ctx = SourceToDefCtx { db: self.db, cache: &mut *cache };\n@@ -310,7 +451,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n     }\n \n     pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n-        let resolver = def.id.resolver(self.db);\n+        let resolver = def.id.resolver(self.db.upcast());\n         SemanticsScope { db: self.db, resolver }\n     }\n \n@@ -331,17 +472,17 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n             ChildContainer::DefWithBodyId(def) => {\n                 return SourceAnalyzer::new_for_body(self.db, def, src, offset)\n             }\n-            ChildContainer::TraitId(it) => it.resolver(self.db),\n-            ChildContainer::ImplId(it) => it.resolver(self.db),\n-            ChildContainer::ModuleId(it) => it.resolver(self.db),\n-            ChildContainer::EnumId(it) => it.resolver(self.db),\n-            ChildContainer::VariantId(it) => it.resolver(self.db),\n-            ChildContainer::GenericDefId(it) => it.resolver(self.db),\n+            ChildContainer::TraitId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::ImplId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::ModuleId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::EnumId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::VariantId(it) => it.resolver(self.db.upcast()),\n+            ChildContainer::GenericDefId(it) => it.resolver(self.db.upcast()),\n         };\n         SourceAnalyzer::new_for_resolver(resolver, src)\n     }\n \n-    fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n+    pub fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n         assert!(root_node.parent().is_none());\n         let mut cache = self.cache.borrow_mut();\n         let prev = cache.insert(root_node, file_id);\n@@ -357,7 +498,7 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n         cache.get(root_node).copied()\n     }\n \n-    fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n+    pub fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n         let root_node = find_root(&node);\n         let file_id = self.lookup(&root_node).unwrap_or_else(|| {\n             panic!(\n@@ -382,14 +523,14 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n pub trait ToDef: AstNode + Clone {\n     type Def;\n \n-    fn to_def<DB: HirDatabase>(sema: &Semantics<DB>, src: InFile<Self>) -> Option<Self::Def>;\n+    fn to_def(sema: &SemanticsImpl, src: InFile<Self>) -> Option<Self::Def>;\n }\n \n macro_rules! to_def_impls {\n     ($(($def:path, $ast:path, $meth:ident)),* ,) => {$(\n         impl ToDef for $ast {\n             type Def = $def;\n-            fn to_def<DB: HirDatabase>(sema: &Semantics<DB>, src: InFile<Self>) -> Option<Self::Def> {\n+            fn to_def(sema: &SemanticsImpl, src: InFile<Self>) -> Option<Self::Def> {\n                 sema.with_ctx(|ctx| ctx.$meth(src)).map(<$def>::from)\n             }\n         }"}, {"sha": "c78071ad6ecddbbc69bc6f4cdfa5d7cf831c2ffd", "filename": "crates/ra_ide_db/src/lib.rs", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/248b656c2178a69955c56a48eb44b3cd59b634bb/crates%2Fra_ide_db%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/248b656c2178a69955c56a48eb44b3cd59b634bb/crates%2Fra_ide_db%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_db%2Fsrc%2Flib.rs?ref=248b656c2178a69955c56a48eb44b3cd59b634bb", "patch": "@@ -13,7 +13,7 @@ mod wasm_shims;\n \n use std::sync::Arc;\n \n-use hir::db::{AstDatabase, DefDatabase};\n+use hir::db::{AstDatabase, DefDatabase, HirDatabase};\n use ra_db::{\n     salsa::{self, Database, Durability},\n     Canceled, CheckCanceled, CrateId, FileId, FileLoader, FileLoaderDelegate, SourceDatabase,\n@@ -52,6 +52,12 @@ impl Upcast<dyn DefDatabase> for RootDatabase {\n     }\n }\n \n+impl Upcast<dyn HirDatabase> for RootDatabase {\n+    fn upcast(&self) -> &(dyn HirDatabase + 'static) {\n+        &*self\n+    }\n+}\n+\n impl FileLoader for RootDatabase {\n     fn file_text(&self, file_id: FileId) -> Arc<String> {\n         FileLoaderDelegate(self).file_text(file_id)"}]}