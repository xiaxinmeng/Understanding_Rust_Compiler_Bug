{"sha": "5401f086f017f035ad66f83f14892c822d160866", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU0MDFmMDg2ZjAxN2YwMzVhZDY2ZjgzZjE0ODkyYzgyMmQxNjA4NjY=", "commit": {"author": {"name": "Steve Klabnik", "email": "steve@steveklabnik.com", "date": "2015-01-14T03:06:52Z"}, "committer": {"name": "Steve Klabnik", "email": "steve@steveklabnik.com", "date": "2015-02-05T02:47:16Z"}, "message": "A concurrency chapter to replace the tasks chapter.\n\nFixes #18936\nFixes #18938\nFixes #20038\nFixes #8395\nFixes #2080\nFixes #21194", "tree": {"sha": "d479506c03a32c641529c359aad6f3dc6ad170bf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d479506c03a32c641529c359aad6f3dc6ad170bf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/5401f086f017f035ad66f83f14892c822d160866", "comment_count": 2, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/5401f086f017f035ad66f83f14892c822d160866", "html_url": "https://github.com/rust-lang/rust/commit/5401f086f017f035ad66f83f14892c822d160866", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/5401f086f017f035ad66f83f14892c822d160866/comments", "author": {"login": "steveklabnik", "id": 27786, "node_id": "MDQ6VXNlcjI3Nzg2", "avatar_url": "https://avatars.githubusercontent.com/u/27786?v=4", "gravatar_id": "", "url": "https://api.github.com/users/steveklabnik", "html_url": "https://github.com/steveklabnik", "followers_url": "https://api.github.com/users/steveklabnik/followers", "following_url": "https://api.github.com/users/steveklabnik/following{/other_user}", "gists_url": "https://api.github.com/users/steveklabnik/gists{/gist_id}", "starred_url": "https://api.github.com/users/steveklabnik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/steveklabnik/subscriptions", "organizations_url": "https://api.github.com/users/steveklabnik/orgs", "repos_url": "https://api.github.com/users/steveklabnik/repos", "events_url": "https://api.github.com/users/steveklabnik/events{/privacy}", "received_events_url": "https://api.github.com/users/steveklabnik/received_events", "type": "User", "site_admin": false}, "committer": {"login": "steveklabnik", "id": 27786, "node_id": "MDQ6VXNlcjI3Nzg2", "avatar_url": "https://avatars.githubusercontent.com/u/27786?v=4", "gravatar_id": "", "url": "https://api.github.com/users/steveklabnik", "html_url": "https://github.com/steveklabnik", "followers_url": "https://api.github.com/users/steveklabnik/followers", "following_url": "https://api.github.com/users/steveklabnik/following{/other_user}", "gists_url": "https://api.github.com/users/steveklabnik/gists{/gist_id}", "starred_url": "https://api.github.com/users/steveklabnik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/steveklabnik/subscriptions", "organizations_url": "https://api.github.com/users/steveklabnik/orgs", "repos_url": "https://api.github.com/users/steveklabnik/repos", "events_url": "https://api.github.com/users/steveklabnik/events{/privacy}", "received_events_url": "https://api.github.com/users/steveklabnik/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96", "url": "https://api.github.com/repos/rust-lang/rust/commits/ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96", "html_url": "https://github.com/rust-lang/rust/commit/ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96"}], "stats": {"total": 789, "additions": 392, "deletions": 397}, "files": [{"sha": "9d65f30e7237993e2d2793dc410644e664019ed3", "filename": "src/doc/trpl/SUMMARY.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/5401f086f017f035ad66f83f14892c822d160866/src%2Fdoc%2Ftrpl%2FSUMMARY.md", "raw_url": "https://github.com/rust-lang/rust/raw/5401f086f017f035ad66f83f14892c822d160866/src%2Fdoc%2Ftrpl%2FSUMMARY.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftrpl%2FSUMMARY.md?ref=5401f086f017f035ad66f83f14892c822d160866", "patch": "@@ -27,7 +27,7 @@\n     * [Iterators](iterators.md)\n     * [Generics](generics.md)\n     * [Traits](traits.md)\n-    * [Threads](threads.md)\n+    * [Concurrency](concurrency.md)\n     * [Error Handling](error-handling.md)\n     * [Documentation](documentation.md)\n * [III: Advanced Topics](advanced.md)"}, {"sha": "5dba1b2a9bf0a4dafb8bba8c59260a4a31834300", "filename": "src/doc/trpl/concurrency.md", "status": "added", "additions": 391, "deletions": 0, "changes": 391, "blob_url": "https://github.com/rust-lang/rust/blob/5401f086f017f035ad66f83f14892c822d160866/src%2Fdoc%2Ftrpl%2Fconcurrency.md", "raw_url": "https://github.com/rust-lang/rust/raw/5401f086f017f035ad66f83f14892c822d160866/src%2Fdoc%2Ftrpl%2Fconcurrency.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftrpl%2Fconcurrency.md?ref=5401f086f017f035ad66f83f14892c822d160866", "patch": "@@ -0,0 +1,391 @@\n+% Concurrency\n+\n+Concurrency and parallelism are incredibly important topics in computer\n+science, and are also a hot topic in industry today. Computers are gaining more\n+and more cores, yet many programmers aren't prepared to fully utilize them.\n+\n+Rust's memory safety features also apply to its concurrency story too. Even\n+concurrent Rust programs must be memory safe, having no data races. Rust's type\n+system is up to the task, and gives you powerful ways to reason about\n+concurrent code at compile time.\n+\n+Before we talk about the concurrency features that come with Rust, it's important\n+to understand something: Rust is low-level enough that all of this is provided\n+by the standard library, not by the language. This means that if you don't like\n+some aspect of the way Rust handles concurrency, you can implement an alternative\n+way of doing things. [mio](https://github.com/carllerche/mio) is a real-world\n+example of this principle in action.\n+\n+## Background: `Send` and `Sync`\n+\n+Concurrency is difficult to reason about. In Rust, we have a strong, static\n+type system to help us reason about our code. As such, Rust gives us two traits\n+to help us make sense of code that can possibly be concurrent.\n+\n+### `Send`\n+\n+The first trait we're going to talk about is\n+[`Send`](../std/marker/trait.Send.html). When a type `T` implements `Send`, it indicates\n+to the compiler that something of this type is able to have ownership transferred\n+safely between threads.\n+\n+This is important to enforce certain restrictions. For example, if we have a\n+channel connecting two threads, we would want to be able to send some data\n+down the channel and to the other thread. Therefore, we'd ensure that `Send` was\n+implemented for that type.\n+\n+In the opposite way, if we were wrapping a library with FFI that isn't\n+threadsafe, we wouldn't want to implement `Send`, and so the compiler will help\n+us enforce that it can't leave the current thread.\n+\n+### `Sync`\n+\n+The second of these two trait is called [`Sync`](../std/marker/trait.Sync.html).\n+When a type `T` implements `Sync`, it indicates to the compiler that something\n+of this type has no possibility of introducing memory unsafety when used from\n+multiple threads concurrently.\n+\n+For example, sharing immutable data with an atomic reference count is\n+threadsafe. Rust provides a type like this, `Arc<T>`, and it implements `Sync`,\n+so that it could be safely shared between threads.\n+\n+These two traits allow you to use the type system to make strong guarantees\n+about the properties of your code under concurrency. Before we demonstrate\n+why, we need to learn how to create a concurrent Rust program in the first\n+place!\n+\n+## Threads\n+\n+Rust's standard library provides a library for 'threads', which allow you to\n+run Rust code in parallel. Here's a basic example of using `Thread`:\n+\n+```\n+use std::thread::Thread;\n+\n+fn main() {\n+    Thread::scoped(|| {\n+        println!(\"Hello from a thread!\");\n+    });\n+}\n+```\n+\n+The `Thread::scoped()` method accepts a closure, which is executed in a new\n+thread. It's called `scoped` because this thread returns a join guard:\n+\n+```\n+use std::thread::Thread;\n+\n+fn main() {\n+    let guard = Thread::scoped(|| {\n+        println!(\"Hello from a thread!\");\n+    });\n+\n+    // guard goes out of scope here\n+}\n+```\n+\n+When `guard` goes out of scope, it will block execution until the thread is\n+finished. If we didn't want this behaviour, we could use `Thread::spawn()`:\n+\n+```\n+use std::thread::Thread;\n+use std::old_io::timer;\n+use std::time::Duration;\n+\n+fn main() {\n+    Thread::spawn(|| {\n+        println!(\"Hello from a thread!\");\n+    });\n+\n+    timer::sleep(Duration::milliseconds(50));\n+}\n+```\n+\n+Or call `.detach()`:\n+\n+```\n+use std::thread::Thread;\n+use std::old_io::timer;\n+use std::time::Duration;\n+\n+fn main() {\n+    let guard = Thread::scoped(|| {\n+        println!(\"Hello from a thread!\");\n+    });\n+\n+    guard.detach();\n+\n+    timer::sleep(Duration::milliseconds(50));\n+}\n+```\n+\n+We need to `sleep` here because when `main()` ends, it kills all of the\n+running threads.\n+\n+[`scoped`](std/thread/struct.Builder.html#method.scoped) has an interesting\n+type signature:\n+\n+```text\n+fn scoped<'a, T, F>(self, f: F) -> JoinGuard<'a, T>\n+    where T: Send + 'a,\n+          F: FnOnce() -> T,\n+          F: Send + 'a\n+```\n+\n+Specifically, `F`, the closure that we pass to execute in the new thread. It\n+has two restrictions: It must be a `FnOnce` from `()` to `T`. Using `FnOnce`\n+allows the closure to take ownership of any data it mentions from the parent\n+thread. The other restriction is that `F` must be `Send`. We aren't allowed to\n+transfer this ownership unless the type thinks that's okay.\n+\n+Many languages have the ability to execute threads, but it's wildly unsafe.\n+There are entire books about how to prevent errors that occur from shared\n+mutable state. Rust helps out with its type system here as well, by preventing\n+data races at compile time. Let's talk about how you actually share things\n+between threads.\n+\n+## Safe Shared Mutable State\n+\n+Due to Rust's type system, we have a concept that sounds like a lie: \"safe\n+shared mutable state.\" Many programmers agree that shared mutable state is\n+very, very bad.\n+\n+Someone once said this:\n+\n+> Shared mutable state is the root of all evil. Most languages attempt to deal\n+> with this problem through the 'mutable' part, but Rust deals with it by\n+> solving the 'shared' part.\n+\n+The same [ownership system](ownership.html) that helps prevent using pointers\n+incorrectly also helps rule out data races, one of the worst kinds of\n+concurrency bugs.\n+\n+As an example, here is a Rust program that would have a data race in many\n+languages. It will not compile:\n+\n+```ignore\n+use std::thread::Thread;\n+use std::old_io::timer;\n+use std::time::Duration;\n+\n+fn main() {\n+    let mut data = vec![1u32, 2, 3];\n+\n+    for i in 0 .. 2 {\n+        Thread::spawn(move || {\n+            data[i] += 1;\n+        });\n+    }\n+\n+    timer::sleep(Duration::milliseconds(50));\n+}\n+```\n+\n+This gives us an error:\n+\n+```text\n+12:17 error: capture of moved value: `data`\n+        data[i] += 1;\n+        ^~~~\n+```\n+\n+In this case, we know that our code _should_ be safe, but Rust isn't sure. And\n+it's actually not safe: if we had a reference to `data` in each thread, and the\n+thread takes ownership of the reference, we have three owners! That's bad. We\n+can fix this by using the `Arc<T>` type, which is an atomic reference counted\n+pointer. The 'atomic' part means that it's safe to share across threads.\n+\n+`Arc<T>` assumes one more property about its contents to ensure that it is safe\n+to share across threads: it assumes its contents are `Sync`. But in our\n+case, we want to be able to mutate the value. We need a type that can ensure\n+only one person at a time can mutate what's inside. For that, we can use the\n+`Mutex<T>` type. Here's the second version of our code. It still doesn't work,\n+but for a different reason:\n+\n+```ignore\n+use std::thread::Thread;\n+use std::old_io::timer;\n+use std::time::Duration;\n+use std::sync::Mutex;\n+\n+fn main() {\n+    let mut data = Mutex::new(vec![1u32, 2, 3]);\n+\n+    for i in 0 .. 2 {\n+        let data = data.lock().unwrap();\n+        Thread::spawn(move || {\n+            data[i] += 1;\n+        });\n+    }\n+\n+    timer::sleep(Duration::milliseconds(50));\n+}\n+```\n+\n+Here's the error:\n+\n+```text\n+<anon>:11:9: 11:22 error: the trait `core::marker::Send` is not implemented for the type `std::sync::mutex::MutexGuard<'_, collections::vec::Vec<u32>>` [E0277]\n+<anon>:11         Thread::spawn(move || {\n+                  ^~~~~~~~~~~~~\n+<anon>:11:9: 11:22 note: `std::sync::mutex::MutexGuard<'_, collections::vec::Vec<u32>>` cannot be sent between threads safely\n+<anon>:11         Thread::spawn(move || {\n+                  ^~~~~~~~~~~~~\n+```\n+\n+You see, [`Mutex`](std/sync/struct.Mutex.html) has a\n+[`lock`](http://doc.rust-lang.org/nightly/std/sync/struct.Mutex.html#method.lock)\n+method which has this signature:\n+\n+```ignore\n+fn lock(&self) -> LockResult<MutexGuard<T>>\n+```\n+\n+If we [look at the code for MutexGuard](https://github.com/rust-lang/rust/blob/ca4b9674c26c1de07a2042cb68e6a062d7184cef/src/libstd/sync/mutex.rs#L172), we'll see\n+this:\n+\n+```ignore\n+__marker: marker::NoSend,\n+```\n+\n+Because our guard is `NoSend`, it's not `Send`. Which means we can't actually\n+transfer the guard across thread boundaries, which gives us our error.\n+\n+We can use `Arc<T>` to fix this. Here's the working version:\n+\n+```\n+use std::sync::{Arc, Mutex};\n+use std::thread::Thread;\n+use std::old_io::timer;\n+use std::time::Duration;\n+\n+fn main() {\n+    let data = Arc::new(Mutex::new(vec![1u32, 2, 3]));\n+\n+    for i in (0us..2) {\n+        let data = data.clone();\n+        Thread::spawn(move || {\n+            let mut data = data.lock().unwrap();\n+            data[i] += 1;\n+        });\n+    }\n+\n+    timer::sleep(Duration::milliseconds(50));\n+}\n+```\n+\n+We now call `clone()` on our `Arc`, which increases the internal count. This\n+handle is then moved into the new thread. Let's examine the body of the\n+thread more closely:\n+\n+```\n+# use std::sync::{Arc, Mutex};\n+# use std::thread::Thread;\n+# use std::old_io::timer;\n+# use std::time::Duration;\n+# fn main() {\n+#     let data = Arc::new(Mutex::new(vec![1u32, 2, 3]));\n+#     for i in (0us..2) {\n+#         let data = data.clone();\n+Thread::spawn(move || {\n+    let mut data = data.lock().unwrap();\n+    data[i] += 1;\n+});\n+#     }\n+# }\n+```\n+\n+First, we call `lock()`, which acquires the mutex's lock. Because this may fail,\n+it returns an `Result<T, E>`, and because this is just an example, we `unwrap()`\n+it to get a reference to the data. Real code would have more robust error handling\n+here. We're then free to mutate it, since we have the lock.\n+\n+This timer bit is a bit awkward, however. We have picked a reasonable amount of\n+time to wait, but it's entirely possible that we've picked too high, and that\n+we could be taking less time. It's also possible that we've picked too low,\n+and that we aren't actually finishing this computation.\n+\n+Rust's standard library provides a few more mechanisms for two threads to\n+synchronize with each other. Let's talk about one: channels.\n+\n+## Channels\n+\n+Here's a version of our code that uses channels for synchronization, rather\n+than waiting for a specific time:\n+\n+```\n+use std::sync::{Arc, Mutex};\n+use std::thread::Thread;\n+use std::sync::mpsc;\n+\n+fn main() {\n+    let data = Arc::new(Mutex::new(0u32));\n+\n+    let (tx, rx) = mpsc::channel();\n+\n+    for _ in (0..10) {\n+        let (data, tx) = (data.clone(), tx.clone());\n+\n+        Thread::spawn(move || {\n+            let mut data = data.lock().unwrap();\n+            *data += 1;\n+\n+            tx.send(());\n+        });\n+    }\n+\n+    for _ in 0 .. 10 {\n+        rx.recv();\n+    }\n+}\n+```\n+\n+We use the `mpsc::channel()` method to construct a new channel. We just `send`\n+a simple `()` down the channel, and then wait for ten of them to come back.\n+\n+While this channel is just sending a generic signal, we can send any data that\n+is `Send` over the channel!\n+\n+```\n+use std::sync::{Arc, Mutex};\n+use std::thread::Thread;\n+use std::sync::mpsc;\n+\n+fn main() {\n+    let (tx, rx) = mpsc::channel();\n+\n+    for _ in range(0, 10) {\n+        let tx = tx.clone();\n+\n+        Thread::spawn(move || {\n+            let answer = 42u32;\n+\n+            tx.send(answer);\n+        });\n+    }\n+\n+   rx.recv().ok().expect(\"Could not recieve answer\");\n+}\n+```\n+\n+A `u32` is `Send` because we can make a copy. So we create a thread, ask it to calculate\n+the answer, and then it `send()`s us the answer over the channel.\n+\n+\n+## Panics\n+\n+A `panic!` will crash the currently executing thread. You can use Rust's\n+threads as a simple isolation mechanism:\n+\n+```\n+use std::thread::Thread;\n+\n+let result = Thread::scoped(move || {\n+    panic!(\"oops!\");\n+}).join();\n+\n+assert!(result.is_err());\n+```\n+\n+Our `Thread` gives us a `Result` back, which allows us to check if the thread\n+has panicked or not."}, {"sha": "a801a1ab0e9217e1982f406aeabe5160b42662ef", "filename": "src/doc/trpl/threads.md", "status": "removed", "additions": 0, "deletions": 396, "changes": 396, "blob_url": "https://github.com/rust-lang/rust/blob/ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96/src%2Fdoc%2Ftrpl%2Fthreads.md", "raw_url": "https://github.com/rust-lang/rust/raw/ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96/src%2Fdoc%2Ftrpl%2Fthreads.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Ftrpl%2Fthreads.md?ref=ba2f13ef0667ce90f55ab0f1506bf5ee7b852d96", "patch": "@@ -1,396 +0,0 @@\n-% The Rust Threads and Communication Guide\n-\n-**NOTE** This guide is badly out of date and needs to be rewritten.\n-\n-# Introduction\n-\n-Rust provides safe concurrent abstractions through a number of core library\n-primitives. This guide will describe the concurrency model in Rust, how it\n-relates to the Rust type system, and introduce the fundamental library\n-abstractions for constructing concurrent programs.\n-\n-Threads provide failure isolation and recovery. When a fatal error occurs in Rust\n-code as a result of an explicit call to `panic!()`, an assertion failure, or\n-another invalid operation, the runtime system destroys the entire thread. Unlike\n-in languages such as Java and C++, there is no way to `catch` an exception.\n-Instead, threads may monitor each other to see if they panic.\n-\n-Threads use Rust's type system to provide strong memory safety guarantees.  In\n-particular, the type system guarantees that threads cannot induce a data race\n-from shared mutable state.\n-\n-# Basics\n-\n-At its simplest, creating a thread is a matter of calling the `spawn` function\n-with a closure argument. `spawn` executes the closure in the new thread.\n-\n-```{rust,ignore}\n-# use std::thread::spawn;\n-\n-// Print something profound in a different thread using a named function\n-fn print_message() { println!(\"I am running in a different thread!\"); }\n-spawn(print_message);\n-\n-// Alternatively, use a `move ||` expression instead of a named function.\n-// `||` expressions evaluate to an unnamed closure. The `move` keyword\n-// indicates that the closure should take ownership of any variables it\n-// touches.\n-spawn(move || println!(\"I am also running in a different thread!\"));\n-```\n-\n-In Rust, a thread is not a concept that appears in the language semantics.\n-Instead, Rust's type system provides all the tools necessary to implement safe\n-concurrency: particularly, ownership. The language leaves the implementation\n-details to the standard library.\n-\n-The `spawn` function has the type signature: `fn\n-spawn<F:FnOnce()+Send>(f: F)`.  This indicates that it takes as\n-argument a closure (of type `F`) that it will run exactly once. This\n-closure is limited to capturing `Send`-able data from its environment\n-(that is, data which is deeply owned). Limiting the closure to `Send`\n-ensures that `spawn` can safely move the entire closure and all its\n-associated state into an entirely different thread for execution.\n-\n-```rust\n-use std::thread::Thread;\n-\n-fn generate_thread_number() -> i32 { 4 } // a very simple generation\n-\n-// Generate some state locally\n-let child_thread_number = generate_thread_number();\n-\n-Thread::spawn(move || {\n-    // Capture it in the remote thread. The `move` keyword indicates\n-    // that this closure should move `child_thread_number` into its\n-    // environment, rather than capturing a reference into the\n-    // enclosing stack frame.\n-    println!(\"I am child number {}\", child_thread_number);\n-});\n-```\n-\n-## Communication\n-\n-Now that we have spawned a new thread, it would be nice if we could communicate\n-with it. For this, we use *channels*. A channel is simply a pair of endpoints:\n-one for sending messages and another for receiving messages.\n-\n-The simplest way to create a channel is to use the `channel` function to create a\n-`(Sender, Receiver)` pair. In Rust parlance, a *sender* is a sending endpoint\n-of a channel, and a *receiver* is the receiving endpoint. Consider the following\n-example of calculating two results concurrently:\n-\n-```rust\n-use std::thread::Thread;\n-use std::sync::mpsc;\n-\n-let (tx, rx): (mpsc::Sender<u32>, mpsc::Receiver<u32>) = mpsc::channel();\n-\n-Thread::spawn(move || {\n-    let result = some_expensive_computation();\n-    tx.send(result);\n-});\n-\n-some_other_expensive_computation();\n-let result = rx.recv();\n-\n-fn some_expensive_computation() -> u32 { 42 } // very expensive ;)\n-fn some_other_expensive_computation() {}      // even more so\n-```\n-\n-Let's examine this example in detail. First, the `let` statement creates a\n-stream for sending and receiving integers (the left-hand side of the `let`,\n-`(tx, rx)`, is an example of a destructuring let: the pattern separates a tuple\n-into its component parts).\n-\n-```rust\n-# use std::sync::mpsc;\n-let (tx, rx): (mpsc::Sender<u32>, mpsc::Receiver<u32>) = mpsc::channel();\n-```\n-\n-The child thread will use the sender to send data to the parent thread, which will\n-wait to receive the data on the receiver. The next statement spawns the child\n-thread.\n-\n-```rust\n-# use std::thread::Thread;\n-# use std::sync::mpsc;\n-# fn some_expensive_computation() -> u32 { 42 }\n-# let (tx, rx) = mpsc::channel();\n-Thread::spawn(move || {\n-    let result = some_expensive_computation();\n-    tx.send(result);\n-});\n-```\n-\n-Notice that the creation of the thread closure transfers `tx` to the child thread\n-implicitly: the closure captures `tx` in its environment. Both `Sender` and\n-`Receiver` are sendable types and may be captured into threads or otherwise\n-transferred between them. In the example, the child thread runs an expensive\n-computation, then sends the result over the captured channel.\n-\n-Finally, the parent continues with some other expensive computation, then waits\n-for the child's result to arrive on the receiver:\n-\n-```rust\n-# use std::sync::mpsc;\n-# fn some_other_expensive_computation() {}\n-# let (tx, rx) = mpsc::channel::<u32>();\n-# tx.send(0);\n-some_other_expensive_computation();\n-let result = rx.recv();\n-```\n-\n-The `Sender` and `Receiver` pair created by `channel` enables efficient\n-communication between a single sender and a single receiver, but multiple\n-senders cannot use a single `Sender` value, and multiple receivers cannot use a\n-single `Receiver` value.  What if our example needed to compute multiple\n-results across a number of threads? The following program is ill-typed:\n-\n-```{rust,ignore}\n-# use std::sync::mpsc;\n-# fn some_expensive_computation() -> u32 { 42 }\n-let (tx, rx) = mpsc::channel();\n-\n-spawn(move || {\n-    tx.send(some_expensive_computation());\n-});\n-\n-// ERROR! The previous spawn statement already owns the sender,\n-// so the compiler will not allow it to be captured again\n-spawn(move || {\n-    tx.send(some_expensive_computation());\n-});\n-```\n-\n-Instead we can clone the `tx`, which allows for multiple senders.\n-\n-```rust\n-use std::thread::Thread;\n-use std::sync::mpsc;\n-\n-let (tx, rx) = mpsc::channel();\n-\n-for init_val in 0 .. 3 {\n-    // Create a new channel handle to distribute to the child thread\n-    let child_tx = tx.clone();\n-    Thread::spawn(move || {\n-        child_tx.send(some_expensive_computation(init_val));\n-    });\n-}\n-\n-let result = rx.recv().unwrap() + rx.recv().unwrap() + rx.recv().unwrap();\n-# fn some_expensive_computation(_i: i32) -> i32 { 42 }\n-```\n-\n-Cloning a `Sender` produces a new handle to the same channel, allowing multiple\n-threads to send data to a single receiver. It upgrades the channel internally in\n-order to allow this functionality, which means that channels that are not\n-cloned can avoid the overhead required to handle multiple senders. But this\n-fact has no bearing on the channel's usage: the upgrade is transparent.\n-\n-Note that the above cloning example is somewhat contrived since you could also\n-simply use three `Sender` pairs, but it serves to illustrate the point. For\n-reference, written with multiple streams, it might look like the example below.\n-\n-```rust\n-use std::thread::Thread;\n-use std::sync::mpsc;\n-\n-// Create a vector of ports, one for each child thread\n-let rxs = (0 .. 3).map(|&:init_val| {\n-    let (tx, rx) = mpsc::channel();\n-    Thread::spawn(move || {\n-        tx.send(some_expensive_computation(init_val));\n-    });\n-    rx\n-}).collect::<Vec<_>>();\n-\n-// Wait on each port, accumulating the results\n-let result = rxs.iter().fold(0, |&:accum, rx| accum + rx.recv().unwrap() );\n-# fn some_expensive_computation(_i: i32) -> i32 { 42 }\n-```\n-\n-## Backgrounding computations: Futures\n-\n-With `sync::Future`, rust has a mechanism for requesting a computation and\n-getting the result later.\n-\n-The basic example below illustrates this.\n-\n-```{rust,ignore}\n-# #![allow(deprecated)]\n-use std::sync::Future;\n-\n-# fn main() {\n-# fn make_a_sandwich() {};\n-fn fib(n: u64) -> u64 {\n-    // lengthy computation returning an 64\n-    12586269025\n-}\n-\n-let mut delayed_fib = Future::spawn(move || fib(50));\n-make_a_sandwich();\n-println!(\"fib(50) = {}\", delayed_fib.get())\n-# }\n-```\n-\n-The call to `future::spawn` immediately returns a `future` object regardless of\n-how long it takes to run `fib(50)`. You can then make yourself a sandwich while\n-the computation of `fib` is running. The result of the execution of the method\n-is obtained by calling `get` on the future. This call will block until the\n-value is available (*i.e.* the computation is complete). Note that the future\n-needs to be mutable so that it can save the result for next time `get` is\n-called.\n-\n-Here is another example showing how futures allow you to background\n-computations. The workload will be distributed on the available cores.\n-\n-```{rust,ignore}\n-# #![allow(deprecated)]\n-# use std::num::Float;\n-# use std::sync::Future;\n-fn partial_sum(start: u64) -> f64 {\n-    let mut local_sum = 0f64;\n-    for num in range(start*100000, (start+1)*100000) {\n-        local_sum += (num as f64 + 1.0).powf(-2.0);\n-    }\n-    local_sum\n-}\n-\n-fn main() {\n-    let mut futures = Vec::from_fn(200, |ind| Future::spawn(move || partial_sum(ind)));\n-\n-    let mut final_res = 0f64;\n-    for ft in futures.iter_mut()  {\n-        final_res += ft.get();\n-    }\n-    println!(\"\u03c0^2/6 is not far from : {}\", final_res);\n-}\n-```\n-\n-## Sharing without copying: Arc\n-\n-To share data between threads, a first approach would be to only use channel as\n-we have seen previously. A copy of the data to share would then be made for\n-each thread. In some cases, this would add up to a significant amount of wasted\n-memory and would require copying the same data more than necessary.\n-\n-To tackle this issue, one can use an Atomically Reference Counted wrapper\n-(`Arc`) as implemented in the `sync` library of Rust. With an Arc, the data\n-will no longer be copied for each thread. The Arc acts as a reference to the\n-shared data and only this reference is shared and cloned.\n-\n-Here is a small example showing how to use Arcs. We wish to run concurrently\n-several computations on a single large vector of floats. Each thread needs the\n-full vector to perform its duty.\n-\n-```{rust,ignore}\n-use std::num::Float;\n-use std::rand;\n-use std::sync::Arc;\n-\n-fn pnorm(nums: &[f64], p: u64) -> f64 {\n-    nums.iter().fold(0.0, |a, b| a + b.powf(p as f64)).powf(1.0 / (p as f64))\n-}\n-\n-fn main() {\n-    let numbers = Vec::from_fn(1000000, |_| rand::random::<f64>());\n-    let numbers_arc = Arc::new(numbers);\n-\n-    for num in range(1, 10) {\n-        let thread_numbers = numbers_arc.clone();\n-\n-        spawn(move || {\n-            println!(\"{}-norm = {}\", num, pnorm(thread_numbers.as_slice(), num));\n-        });\n-    }\n-}\n-```\n-\n-The function `pnorm` performs a simple computation on the vector (it computes\n-the sum of its items at the power given as argument and takes the inverse power\n-of this value). The Arc on the vector is created by the line:\n-\n-```{rust,ignore}\n-# use std::rand;\n-# use std::sync::Arc;\n-# fn main() {\n-# let numbers = Vec::from_fn(1000000, |_| rand::random::<f64>());\n-let numbers_arc = Arc::new(numbers);\n-# }\n-```\n-\n-and a clone is captured for each thread via a procedure. This only copies\n-the wrapper and not its contents. Within the thread's procedure, the captured\n-Arc reference can be used as a shared reference to the underlying vector as\n-if it were local.\n-\n-```{rust,ignore}\n-# use std::rand;\n-# use std::sync::Arc;\n-# fn pnorm(nums: &[f64], p: u64) -> f64 { 4.0 }\n-# fn main() {\n-# let numbers=Vec::from_fn(1000000, |_| rand::random::<f64>());\n-# let numbers_arc = Arc::new(numbers);\n-# let num = 4;\n-let thread_numbers = numbers_arc.clone();\n-spawn(move || {\n-    // Capture thread_numbers and use it as if it was the underlying vector\n-    println!(\"{}-norm = {}\", num, pnorm(thread_numbers.as_slice(), num));\n-});\n-# }\n-```\n-\n-# Handling thread panics\n-\n-Rust has a built-in mechanism for raising exceptions. The `panic!()` macro\n-(which can also be written with an error string as an argument: `panic!(\n-~reason)`) and the `assert!` construct (which effectively calls `panic!()` if a\n-boolean expression is false) are both ways to raise exceptions. When a thread\n-raises an exception, the thread unwinds its stack\u2014running destructors and\n-freeing memory along the way\u2014and then exits. Unlike exceptions in C++,\n-exceptions in Rust are unrecoverable within a single thread: once a thread panics,\n-there is no way to \"catch\" the exception.\n-\n-While it isn't possible for a thread to recover from panicking, threads may notify\n-each other if they panic. The simplest way of handling a panic is with the\n-`try` function, which is similar to `spawn`, but immediately blocks and waits\n-for the child thread to finish. `try` returns a value of type\n-`Result<T, Box<Any + Send>>`. `Result` is an `enum` type with two variants:\n-`Ok` and `Err`. In this case, because the type arguments to `Result` are `i32`\n-and `()`, callers can pattern-match on a result to check whether it's an `Ok`\n-result with an `i32` field (representing a successful result) or an `Err` result\n-(representing termination with an error).\n-\n-```{rust,ignore}\n-# use std::thread::Thread;\n-# fn some_condition() -> bool { false }\n-# fn calculate_result() -> i32 { 0 }\n-let result: Result<i32, Box<std::any::Any + Send>> = Thread::spawn(move || {\n-    if some_condition() {\n-        calculate_result()\n-    } else {\n-        panic!(\"oops!\");\n-    }\n-}).join();\n-assert!(result.is_err());\n-```\n-\n-Unlike `spawn`, the function spawned using `try` may return a value, which\n-`try` will dutifully propagate back to the caller in a [`Result`] enum. If the\n-child thread terminates successfully, `try` will return an `Ok` result; if the\n-child thread panics, `try` will return an `Error` result.\n-\n-[`Result`]: ../std/result/index.html\n-\n-> *Note:* A panicked thread does not currently produce a useful error\n-> value (`try` always returns `Err(())`). In the\n-> future, it may be possible for threads to intercept the value passed to\n-> `panic!()`.\n-\n-But not all panics are created equal. In some cases you might need to abort\n-the entire program (perhaps you're writing an assert which, if it trips,\n-indicates an unrecoverable logic error); in other cases you might want to\n-contain the panic at a certain boundary (perhaps a small piece of input from\n-the outside world, which you happen to be processing in parallel, is malformed\n-such that the processing thread cannot proceed)."}]}