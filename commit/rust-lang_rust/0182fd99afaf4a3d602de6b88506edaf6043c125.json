{"sha": "0182fd99afaf4a3d602de6b88506edaf6043c125", "node_id": "C_kwDOAAsO6NoAKDAxODJmZDk5YWZhZjRhM2Q2MDJkZTZiODg1MDZlZGFmNjA0M2MxMjU", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-06-18T07:37:14Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2022-06-18T07:37:14Z"}, "message": "Auto merge of #98186 - mystor:tokenstream_as_vec_tt, r=eddyb\n\nBatch proc_macro RPC for TokenStream iteration and combination operations\n\nThis is the first part of #86822, split off as requested in https://github.com/rust-lang/rust/pull/86822#pullrequestreview-1008655452. It reduces the number of RPC calls required for common operations such as iterating over and concatenating TokenStreams.", "tree": {"sha": "0f1d069247abbd18fbe832ada76544ca12d02645", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/0f1d069247abbd18fbe832ada76544ca12d02645"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0182fd99afaf4a3d602de6b88506edaf6043c125", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0182fd99afaf4a3d602de6b88506edaf6043c125", "html_url": "https://github.com/rust-lang/rust/commit/0182fd99afaf4a3d602de6b88506edaf6043c125", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0182fd99afaf4a3d602de6b88506edaf6043c125/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ff86b27e7be1ffff9e00d80beb15560d5f301459", "url": "https://api.github.com/repos/rust-lang/rust/commits/ff86b27e7be1ffff9e00d80beb15560d5f301459", "html_url": "https://github.com/rust-lang/rust/commit/ff86b27e7be1ffff9e00d80beb15560d5f301459"}, {"sha": "df925fda9c9eee8010564dde7daa44bc5286446e", "url": "https://api.github.com/repos/rust-lang/rust/commits/df925fda9c9eee8010564dde7daa44bc5286446e", "html_url": "https://github.com/rust-lang/rust/commit/df925fda9c9eee8010564dde7daa44bc5286446e"}], "stats": {"total": 476, "additions": 303, "deletions": 173}, "files": [{"sha": "093896c339d29dde3d76ce28de9901506e2e493b", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 55, "deletions": 44, "changes": 99, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -277,12 +277,6 @@ impl ToInternal<rustc_errors::Level> for Level {\n \n pub struct FreeFunctions;\n \n-#[derive(Clone)]\n-pub struct TokenStreamIter {\n-    cursor: tokenstream::Cursor,\n-    stack: Vec<TokenTree<Group, Punct, Ident, Literal>>,\n-}\n-\n #[derive(Clone)]\n pub struct Group {\n     delimiter: Delimiter,\n@@ -382,8 +376,6 @@ impl<'a, 'b> Rustc<'a, 'b> {\n impl server::Types for Rustc<'_, '_> {\n     type FreeFunctions = FreeFunctions;\n     type TokenStream = TokenStream;\n-    type TokenStreamBuilder = tokenstream::TokenStreamBuilder;\n-    type TokenStreamIter = TokenStreamIter;\n     type Group = Group;\n     type Punct = Punct;\n     type Ident = Ident;\n@@ -408,9 +400,6 @@ impl server::FreeFunctions for Rustc<'_, '_> {\n }\n \n impl server::TokenStream for Rustc<'_, '_> {\n-    fn new(&mut self) -> Self::TokenStream {\n-        TokenStream::default()\n-    }\n     fn is_empty(&mut self, stream: &Self::TokenStream) -> bool {\n         stream.is_empty()\n     }\n@@ -481,53 +470,75 @@ impl server::TokenStream for Rustc<'_, '_> {\n     ) -> Self::TokenStream {\n         tree.to_internal()\n     }\n-    fn into_iter(&mut self, stream: Self::TokenStream) -> Self::TokenStreamIter {\n-        TokenStreamIter { cursor: stream.into_trees(), stack: vec![] }\n-    }\n-}\n-\n-impl server::TokenStreamBuilder for Rustc<'_, '_> {\n-    fn new(&mut self) -> Self::TokenStreamBuilder {\n-        tokenstream::TokenStreamBuilder::new()\n-    }\n-    fn push(&mut self, builder: &mut Self::TokenStreamBuilder, stream: Self::TokenStream) {\n-        builder.push(stream);\n+    fn concat_trees(\n+        &mut self,\n+        base: Option<Self::TokenStream>,\n+        trees: Vec<TokenTree<Self::Group, Self::Punct, Self::Ident, Self::Literal>>,\n+    ) -> Self::TokenStream {\n+        let mut builder = tokenstream::TokenStreamBuilder::new();\n+        if let Some(base) = base {\n+            builder.push(base);\n+        }\n+        for tree in trees {\n+            builder.push(tree.to_internal());\n+        }\n+        builder.build()\n     }\n-    fn build(&mut self, builder: Self::TokenStreamBuilder) -> Self::TokenStream {\n+    fn concat_streams(\n+        &mut self,\n+        base: Option<Self::TokenStream>,\n+        streams: Vec<Self::TokenStream>,\n+    ) -> Self::TokenStream {\n+        let mut builder = tokenstream::TokenStreamBuilder::new();\n+        if let Some(base) = base {\n+            builder.push(base);\n+        }\n+        for stream in streams {\n+            builder.push(stream);\n+        }\n         builder.build()\n     }\n-}\n-\n-impl server::TokenStreamIter for Rustc<'_, '_> {\n-    fn next(\n+    fn into_trees(\n         &mut self,\n-        iter: &mut Self::TokenStreamIter,\n-    ) -> Option<TokenTree<Self::Group, Self::Punct, Self::Ident, Self::Literal>> {\n+        stream: Self::TokenStream,\n+    ) -> Vec<TokenTree<Self::Group, Self::Punct, Self::Ident, Self::Literal>> {\n+        // FIXME: This is a raw port of the previous approach (which had a\n+        // `TokenStreamIter` server-side object with a single `next` method),\n+        // and can probably be optimized (for bulk conversion).\n+        let mut cursor = stream.into_trees();\n+        let mut stack = Vec::new();\n+        let mut tts = Vec::new();\n         loop {\n-            let tree = iter.stack.pop().or_else(|| {\n-                let next = iter.cursor.next_with_spacing()?;\n-                Some(TokenTree::from_internal((next, &mut iter.stack, self)))\n-            })?;\n-            // A hack used to pass AST fragments to attribute and derive macros\n-            // as a single nonterminal token instead of a token stream.\n-            // Such token needs to be \"unwrapped\" and not represented as a delimited group.\n-            // FIXME: It needs to be removed, but there are some compatibility issues (see #73345).\n-            if let TokenTree::Group(ref group) = tree {\n-                if group.flatten {\n-                    iter.cursor.append(group.stream.clone());\n-                    continue;\n+            let next = stack.pop().or_else(|| {\n+                let next = cursor.next_with_spacing()?;\n+                Some(TokenTree::from_internal((next, &mut stack, self)))\n+            });\n+            match next {\n+                Some(TokenTree::Group(group)) => {\n+                    // A hack used to pass AST fragments to attribute and derive\n+                    // macros as a single nonterminal token instead of a token\n+                    // stream.  Such token needs to be \"unwrapped\" and not\n+                    // represented as a delimited group.\n+                    // FIXME: It needs to be removed, but there are some\n+                    // compatibility issues (see #73345).\n+                    if group.flatten {\n+                        cursor.append(group.stream);\n+                        continue;\n+                    }\n+                    tts.push(TokenTree::Group(group));\n                 }\n+                Some(tt) => tts.push(tt),\n+                None => return tts,\n             }\n-            return Some(tree);\n         }\n     }\n }\n \n impl server::Group for Rustc<'_, '_> {\n-    fn new(&mut self, delimiter: Delimiter, stream: Self::TokenStream) -> Self::Group {\n+    fn new(&mut self, delimiter: Delimiter, stream: Option<Self::TokenStream>) -> Self::Group {\n         Group {\n             delimiter,\n-            stream,\n+            stream: stream.unwrap_or_default(),\n             span: DelimSpan::from_single(server::Span::call_site(self)),\n             flatten: false,\n         }"}, {"sha": "068f3e241beac4f56d1f31b9e7d5a782d8e77324", "filename": "library/proc_macro/src/bridge/client.rs", "status": "modified", "additions": 2, "deletions": 10, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Fbridge%2Fclient.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -178,8 +178,6 @@ define_handles! {\n     'owned:\n     FreeFunctions,\n     TokenStream,\n-    TokenStreamBuilder,\n-    TokenStreamIter,\n     Group,\n     Literal,\n     SourceFile,\n@@ -204,12 +202,6 @@ impl Clone for TokenStream {\n     }\n }\n \n-impl Clone for TokenStreamIter {\n-    fn clone(&self) -> Self {\n-        self.clone()\n-    }\n-}\n-\n impl Clone for Group {\n     fn clone(&self) -> Self {\n         self.clone()\n@@ -435,7 +427,7 @@ impl Client<crate::TokenStream, crate::TokenStream> {\n         Client {\n             get_handle_counters: HandleCounters::get,\n             run: super::selfless_reify::reify_to_extern_c_fn_hrt_bridge(move |bridge| {\n-                run_client(bridge, |input| f(crate::TokenStream(input)).0)\n+                run_client(bridge, |input| f(crate::TokenStream(Some(input))).0)\n             }),\n             _marker: PhantomData,\n         }\n@@ -450,7 +442,7 @@ impl Client<(crate::TokenStream, crate::TokenStream), crate::TokenStream> {\n             get_handle_counters: HandleCounters::get,\n             run: super::selfless_reify::reify_to_extern_c_fn_hrt_bridge(move |bridge| {\n                 run_client(bridge, |(input, input2)| {\n-                    f(crate::TokenStream(input), crate::TokenStream(input2)).0\n+                    f(crate::TokenStream(Some(input)), crate::TokenStream(Some(input2))).0\n                 })\n             }),\n             _marker: PhantomData,"}, {"sha": "4e931569ef6337f625b95ec5f3e7ba9fb2c05070", "filename": "library/proc_macro/src/bridge/mod.rs", "status": "modified", "additions": 76, "deletions": 60, "changes": 136, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Fbridge%2Fmod.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -60,33 +60,29 @@ macro_rules! with_api {\n             TokenStream {\n                 fn drop($self: $S::TokenStream);\n                 fn clone($self: &$S::TokenStream) -> $S::TokenStream;\n-                fn new() -> $S::TokenStream;\n                 fn is_empty($self: &$S::TokenStream) -> bool;\n                 fn expand_expr($self: &$S::TokenStream) -> Result<$S::TokenStream, ()>;\n                 fn from_str(src: &str) -> $S::TokenStream;\n                 fn to_string($self: &$S::TokenStream) -> String;\n                 fn from_token_tree(\n                     tree: TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>,\n                 ) -> $S::TokenStream;\n-                fn into_iter($self: $S::TokenStream) -> $S::TokenStreamIter;\n-            },\n-            TokenStreamBuilder {\n-                fn drop($self: $S::TokenStreamBuilder);\n-                fn new() -> $S::TokenStreamBuilder;\n-                fn push($self: &mut $S::TokenStreamBuilder, stream: $S::TokenStream);\n-                fn build($self: $S::TokenStreamBuilder) -> $S::TokenStream;\n-            },\n-            TokenStreamIter {\n-                fn drop($self: $S::TokenStreamIter);\n-                fn clone($self: &$S::TokenStreamIter) -> $S::TokenStreamIter;\n-                fn next(\n-                    $self: &mut $S::TokenStreamIter,\n-                ) -> Option<TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>>;\n+                fn concat_trees(\n+                    base: Option<$S::TokenStream>,\n+                    trees: Vec<TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>>,\n+                ) -> $S::TokenStream;\n+                fn concat_streams(\n+                    base: Option<$S::TokenStream>,\n+                    streams: Vec<$S::TokenStream>,\n+                ) -> $S::TokenStream;\n+                fn into_trees(\n+                    $self: $S::TokenStream\n+                ) -> Vec<TokenTree<$S::Group, $S::Punct, $S::Ident, $S::Literal>>;\n             },\n             Group {\n                 fn drop($self: $S::Group);\n                 fn clone($self: &$S::Group) -> $S::Group;\n-                fn new(delimiter: Delimiter, stream: $S::TokenStream) -> $S::Group;\n+                fn new(delimiter: Delimiter, stream: Option<$S::TokenStream>) -> $S::Group;\n                 fn delimiter($self: &$S::Group) -> Delimiter;\n                 fn stream($self: &$S::Group) -> $S::TokenStream;\n                 fn span($self: &$S::Group) -> $S::Span;\n@@ -311,29 +307,18 @@ impl<'a, T, M> Unmark for &'a mut Marked<T, M> {\n     }\n }\n \n-impl<T: Mark> Mark for Option<T> {\n-    type Unmarked = Option<T::Unmarked>;\n-    fn mark(unmarked: Self::Unmarked) -> Self {\n-        unmarked.map(T::mark)\n-    }\n-}\n-impl<T: Unmark> Unmark for Option<T> {\n-    type Unmarked = Option<T::Unmarked>;\n-    fn unmark(self) -> Self::Unmarked {\n-        self.map(T::unmark)\n-    }\n-}\n-\n-impl<T: Mark, E: Mark> Mark for Result<T, E> {\n-    type Unmarked = Result<T::Unmarked, E::Unmarked>;\n+impl<T: Mark> Mark for Vec<T> {\n+    type Unmarked = Vec<T::Unmarked>;\n     fn mark(unmarked: Self::Unmarked) -> Self {\n-        unmarked.map(T::mark).map_err(E::mark)\n+        // Should be a no-op due to std's in-place collect optimizations.\n+        unmarked.into_iter().map(T::mark).collect()\n     }\n }\n-impl<T: Unmark, E: Unmark> Unmark for Result<T, E> {\n-    type Unmarked = Result<T::Unmarked, E::Unmarked>;\n+impl<T: Unmark> Unmark for Vec<T> {\n+    type Unmarked = Vec<T::Unmarked>;\n     fn unmark(self) -> Self::Unmarked {\n-        self.map(T::unmark).map_err(E::unmark)\n+        // Should be a no-op due to std's in-place collect optimizations.\n+        self.into_iter().map(T::unmark).collect()\n     }\n }\n \n@@ -367,7 +352,6 @@ mark_noop! {\n     Level,\n     LineColumn,\n     Spacing,\n-    Bound<usize>,\n }\n \n rpc_encode_decode!(\n@@ -394,6 +378,61 @@ rpc_encode_decode!(\n     }\n );\n \n+macro_rules! mark_compound {\n+    (enum $name:ident <$($T:ident),+> { $($variant:ident $(($field:ident))?),* $(,)? }) => {\n+        impl<$($T: Mark),+> Mark for $name <$($T),+> {\n+            type Unmarked = $name <$($T::Unmarked),+>;\n+            fn mark(unmarked: Self::Unmarked) -> Self {\n+                match unmarked {\n+                    $($name::$variant $(($field))? => {\n+                        $name::$variant $((Mark::mark($field)))?\n+                    })*\n+                }\n+            }\n+        }\n+\n+        impl<$($T: Unmark),+> Unmark for $name <$($T),+> {\n+            type Unmarked = $name <$($T::Unmarked),+>;\n+            fn unmark(self) -> Self::Unmarked {\n+                match self {\n+                    $($name::$variant $(($field))? => {\n+                        $name::$variant $((Unmark::unmark($field)))?\n+                    })*\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+macro_rules! compound_traits {\n+    ($($t:tt)*) => {\n+        rpc_encode_decode!($($t)*);\n+        mark_compound!($($t)*);\n+    };\n+}\n+\n+compound_traits!(\n+    enum Bound<T> {\n+        Included(x),\n+        Excluded(x),\n+        Unbounded,\n+    }\n+);\n+\n+compound_traits!(\n+    enum Option<T> {\n+        Some(t),\n+        None,\n+    }\n+);\n+\n+compound_traits!(\n+    enum Result<T, E> {\n+        Ok(t),\n+        Err(e),\n+    }\n+);\n+\n #[derive(Clone)]\n pub enum TokenTree<G, P, I, L> {\n     Group(G),\n@@ -402,30 +441,7 @@ pub enum TokenTree<G, P, I, L> {\n     Literal(L),\n }\n \n-impl<G: Mark, P: Mark, I: Mark, L: Mark> Mark for TokenTree<G, P, I, L> {\n-    type Unmarked = TokenTree<G::Unmarked, P::Unmarked, I::Unmarked, L::Unmarked>;\n-    fn mark(unmarked: Self::Unmarked) -> Self {\n-        match unmarked {\n-            TokenTree::Group(tt) => TokenTree::Group(G::mark(tt)),\n-            TokenTree::Punct(tt) => TokenTree::Punct(P::mark(tt)),\n-            TokenTree::Ident(tt) => TokenTree::Ident(I::mark(tt)),\n-            TokenTree::Literal(tt) => TokenTree::Literal(L::mark(tt)),\n-        }\n-    }\n-}\n-impl<G: Unmark, P: Unmark, I: Unmark, L: Unmark> Unmark for TokenTree<G, P, I, L> {\n-    type Unmarked = TokenTree<G::Unmarked, P::Unmarked, I::Unmarked, L::Unmarked>;\n-    fn unmark(self) -> Self::Unmarked {\n-        match self {\n-            TokenTree::Group(tt) => TokenTree::Group(tt.unmark()),\n-            TokenTree::Punct(tt) => TokenTree::Punct(tt.unmark()),\n-            TokenTree::Ident(tt) => TokenTree::Ident(tt.unmark()),\n-            TokenTree::Literal(tt) => TokenTree::Literal(tt.unmark()),\n-        }\n-    }\n-}\n-\n-rpc_encode_decode!(\n+compound_traits!(\n     enum TokenTree<G, P, I, L> {\n         Group(tt),\n         Punct(tt),"}, {"sha": "e9d7a46c06f6d270d66e848788e9f01fbd776e54", "filename": "library/proc_macro/src/bridge/rpc.rs", "status": "modified", "additions": 26, "deletions": 27, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Frpc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Frpc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Fbridge%2Frpc.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -4,7 +4,6 @@ use std::any::Any;\n use std::char;\n use std::io::Write;\n use std::num::NonZeroU32;\n-use std::ops::Bound;\n use std::str;\n \n pub(super) type Writer = super::buffer::Buffer;\n@@ -43,15 +42,17 @@ macro_rules! rpc_encode_decode {\n             }\n         }\n     };\n-    (struct $name:ident { $($field:ident),* $(,)? }) => {\n-        impl<S> Encode<S> for $name {\n+    (struct $name:ident $(<$($T:ident),+>)? { $($field:ident),* $(,)? }) => {\n+        impl<S, $($($T: Encode<S>),+)?> Encode<S> for $name $(<$($T),+>)? {\n             fn encode(self, w: &mut Writer, s: &mut S) {\n                 $(self.$field.encode(w, s);)*\n             }\n         }\n \n-        impl<S> DecodeMut<'_, '_, S> for $name {\n-            fn decode(r: &mut Reader<'_>, s: &mut S) -> Self {\n+        impl<'a, S, $($($T: for<'s> DecodeMut<'a, 's, S>),+)?> DecodeMut<'a, '_, S>\n+            for $name $(<$($T),+>)?\n+        {\n+            fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n                 $name {\n                     $($field: DecodeMut::decode(r, s)),*\n                 }\n@@ -184,28 +185,6 @@ impl<'a, S, A: for<'s> DecodeMut<'a, 's, S>, B: for<'s> DecodeMut<'a, 's, S>> De\n     }\n }\n \n-rpc_encode_decode!(\n-    enum Bound<T> {\n-        Included(x),\n-        Excluded(x),\n-        Unbounded,\n-    }\n-);\n-\n-rpc_encode_decode!(\n-    enum Option<T> {\n-        None,\n-        Some(x),\n-    }\n-);\n-\n-rpc_encode_decode!(\n-    enum Result<T, E> {\n-        Ok(x),\n-        Err(e),\n-    }\n-);\n-\n impl<S> Encode<S> for &[u8] {\n     fn encode(self, w: &mut Writer, s: &mut S) {\n         self.len().encode(w, s);\n@@ -246,6 +225,26 @@ impl<S> DecodeMut<'_, '_, S> for String {\n     }\n }\n \n+impl<S, T: Encode<S>> Encode<S> for Vec<T> {\n+    fn encode(self, w: &mut Writer, s: &mut S) {\n+        self.len().encode(w, s);\n+        for x in self {\n+            x.encode(w, s);\n+        }\n+    }\n+}\n+\n+impl<'a, S, T: for<'s> DecodeMut<'a, 's, S>> DecodeMut<'a, '_, S> for Vec<T> {\n+    fn decode(r: &mut Reader<'a>, s: &mut S) -> Self {\n+        let len = usize::decode(r, s);\n+        let mut vec = Vec::with_capacity(len);\n+        for _ in 0..len {\n+            vec.push(T::decode(r, s));\n+        }\n+        vec\n+    }\n+}\n+\n /// Simplified version of panic payloads, ignoring\n /// types other than `&'static str` and `String`.\n pub enum PanicMessage {"}, {"sha": "3672299f18f486a1361045ac40110c0d3bc5530c", "filename": "library/proc_macro/src/bridge/server.rs", "status": "modified", "additions": 14, "deletions": 8, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fserver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Fbridge%2Fserver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Fbridge%2Fserver.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -8,8 +8,6 @@ use super::client::HandleStore;\n pub trait Types {\n     type FreeFunctions: 'static;\n     type TokenStream: 'static + Clone;\n-    type TokenStreamBuilder: 'static;\n-    type TokenStreamIter: 'static + Clone;\n     type Group: 'static + Clone;\n     type Punct: 'static + Copy + Eq + Hash;\n     type Ident: 'static + Copy + Eq + Hash;\n@@ -275,13 +273,17 @@ fn run_server<\n }\n \n impl client::Client<crate::TokenStream, crate::TokenStream> {\n-    pub fn run<S: Server>(\n+    pub fn run<S>(\n         &self,\n         strategy: &impl ExecutionStrategy,\n         server: S,\n         input: S::TokenStream,\n         force_show_panics: bool,\n-    ) -> Result<S::TokenStream, PanicMessage> {\n+    ) -> Result<S::TokenStream, PanicMessage>\n+    where\n+        S: Server,\n+        S::TokenStream: Default,\n+    {\n         let client::Client { get_handle_counters, run, _marker } = *self;\n         run_server(\n             strategy,\n@@ -291,19 +293,23 @@ impl client::Client<crate::TokenStream, crate::TokenStream> {\n             run,\n             force_show_panics,\n         )\n-        .map(<MarkedTypes<S> as Types>::TokenStream::unmark)\n+        .map(|s| <Option<<MarkedTypes<S> as Types>::TokenStream>>::unmark(s).unwrap_or_default())\n     }\n }\n \n impl client::Client<(crate::TokenStream, crate::TokenStream), crate::TokenStream> {\n-    pub fn run<S: Server>(\n+    pub fn run<S>(\n         &self,\n         strategy: &impl ExecutionStrategy,\n         server: S,\n         input: S::TokenStream,\n         input2: S::TokenStream,\n         force_show_panics: bool,\n-    ) -> Result<S::TokenStream, PanicMessage> {\n+    ) -> Result<S::TokenStream, PanicMessage>\n+    where\n+        S: Server,\n+        S::TokenStream: Default,\n+    {\n         let client::Client { get_handle_counters, run, _marker } = *self;\n         run_server(\n             strategy,\n@@ -316,6 +322,6 @@ impl client::Client<(crate::TokenStream, crate::TokenStream), crate::TokenStream\n             run,\n             force_show_panics,\n         )\n-        .map(<MarkedTypes<S> as Types>::TokenStream::unmark)\n+        .map(|s| <Option<<MarkedTypes<S> as Types>::TokenStream>>::unmark(s).unwrap_or_default())\n     }\n }"}, {"sha": "5e1289ec79d30fcaa52b6bb875fe883d20a7ec96", "filename": "library/proc_macro/src/lib.rs", "status": "modified", "additions": 130, "deletions": 24, "changes": 154, "blob_url": "https://github.com/rust-lang/rust/blob/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0182fd99afaf4a3d602de6b88506edaf6043c125/library%2Fproc_macro%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Flib.rs?ref=0182fd99afaf4a3d602de6b88506edaf6043c125", "patch": "@@ -43,7 +43,7 @@ use std::cmp::Ordering;\n use std::ops::RangeBounds;\n use std::path::PathBuf;\n use std::str::FromStr;\n-use std::{error, fmt, iter, mem};\n+use std::{error, fmt, iter};\n \n /// Determines whether proc_macro has been made accessible to the currently\n /// running program.\n@@ -72,7 +72,7 @@ pub fn is_available() -> bool {\n /// and `#[proc_macro_derive]` definitions.\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n #[derive(Clone)]\n-pub struct TokenStream(bridge::client::TokenStream);\n+pub struct TokenStream(Option<bridge::client::TokenStream>);\n \n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl !Send for TokenStream {}\n@@ -126,13 +126,13 @@ impl TokenStream {\n     /// Returns an empty `TokenStream` containing no token trees.\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     pub fn new() -> TokenStream {\n-        TokenStream(bridge::client::TokenStream::new())\n+        TokenStream(None)\n     }\n \n     /// Checks if this `TokenStream` is empty.\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     pub fn is_empty(&self) -> bool {\n-        self.0.is_empty()\n+        self.0.as_ref().map(|h| h.is_empty()).unwrap_or(true)\n     }\n \n     /// Parses this `TokenStream` as an expression and attempts to expand any\n@@ -147,8 +147,9 @@ impl TokenStream {\n     /// considered errors, is unspecified and may change in the future.\n     #[unstable(feature = \"proc_macro_expand\", issue = \"90765\")]\n     pub fn expand_expr(&self) -> Result<TokenStream, ExpandError> {\n-        match bridge::client::TokenStream::expand_expr(&self.0) {\n-            Ok(stream) => Ok(TokenStream(stream)),\n+        let stream = self.0.as_ref().ok_or(ExpandError)?;\n+        match bridge::client::TokenStream::expand_expr(stream) {\n+            Ok(stream) => Ok(TokenStream(Some(stream))),\n             Err(_) => Err(ExpandError),\n         }\n     }\n@@ -166,7 +167,7 @@ impl FromStr for TokenStream {\n     type Err = LexError;\n \n     fn from_str(src: &str) -> Result<TokenStream, LexError> {\n-        Ok(TokenStream(bridge::client::TokenStream::from_str(src)))\n+        Ok(TokenStream(Some(bridge::client::TokenStream::from_str(src))))\n     }\n }\n \n@@ -175,7 +176,7 @@ impl FromStr for TokenStream {\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl ToString for TokenStream {\n     fn to_string(&self) -> String {\n-        self.0.to_string()\n+        self.0.as_ref().map(|t| t.to_string()).unwrap_or_default()\n     }\n }\n \n@@ -208,24 +209,114 @@ impl Default for TokenStream {\n #[unstable(feature = \"proc_macro_quote\", issue = \"54722\")]\n pub use quote::{quote, quote_span};\n \n+fn tree_to_bridge_tree(\n+    tree: TokenTree,\n+) -> bridge::TokenTree<\n+    bridge::client::Group,\n+    bridge::client::Punct,\n+    bridge::client::Ident,\n+    bridge::client::Literal,\n+> {\n+    match tree {\n+        TokenTree::Group(tt) => bridge::TokenTree::Group(tt.0),\n+        TokenTree::Punct(tt) => bridge::TokenTree::Punct(tt.0),\n+        TokenTree::Ident(tt) => bridge::TokenTree::Ident(tt.0),\n+        TokenTree::Literal(tt) => bridge::TokenTree::Literal(tt.0),\n+    }\n+}\n+\n /// Creates a token stream containing a single token tree.\n #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n impl From<TokenTree> for TokenStream {\n     fn from(tree: TokenTree) -> TokenStream {\n-        TokenStream(bridge::client::TokenStream::from_token_tree(match tree {\n-            TokenTree::Group(tt) => bridge::TokenTree::Group(tt.0),\n-            TokenTree::Punct(tt) => bridge::TokenTree::Punct(tt.0),\n-            TokenTree::Ident(tt) => bridge::TokenTree::Ident(tt.0),\n-            TokenTree::Literal(tt) => bridge::TokenTree::Literal(tt.0),\n-        }))\n+        TokenStream(Some(bridge::client::TokenStream::from_token_tree(tree_to_bridge_tree(tree))))\n+    }\n+}\n+\n+/// Non-generic helper for implementing `FromIterator<TokenTree>` and\n+/// `Extend<TokenTree>` with less monomorphization in calling crates.\n+struct ConcatTreesHelper {\n+    trees: Vec<\n+        bridge::TokenTree<\n+            bridge::client::Group,\n+            bridge::client::Punct,\n+            bridge::client::Ident,\n+            bridge::client::Literal,\n+        >,\n+    >,\n+}\n+\n+impl ConcatTreesHelper {\n+    fn new(capacity: usize) -> Self {\n+        ConcatTreesHelper { trees: Vec::with_capacity(capacity) }\n+    }\n+\n+    fn push(&mut self, tree: TokenTree) {\n+        self.trees.push(tree_to_bridge_tree(tree));\n+    }\n+\n+    fn build(self) -> TokenStream {\n+        if self.trees.is_empty() {\n+            TokenStream(None)\n+        } else {\n+            TokenStream(Some(bridge::client::TokenStream::concat_trees(None, self.trees)))\n+        }\n+    }\n+\n+    fn append_to(self, stream: &mut TokenStream) {\n+        if self.trees.is_empty() {\n+            return;\n+        }\n+        stream.0 = Some(bridge::client::TokenStream::concat_trees(stream.0.take(), self.trees))\n+    }\n+}\n+\n+/// Non-generic helper for implementing `FromIterator<TokenStream>` and\n+/// `Extend<TokenStream>` with less monomorphization in calling crates.\n+struct ConcatStreamsHelper {\n+    streams: Vec<bridge::client::TokenStream>,\n+}\n+\n+impl ConcatStreamsHelper {\n+    fn new(capacity: usize) -> Self {\n+        ConcatStreamsHelper { streams: Vec::with_capacity(capacity) }\n+    }\n+\n+    fn push(&mut self, stream: TokenStream) {\n+        if let Some(stream) = stream.0 {\n+            self.streams.push(stream);\n+        }\n+    }\n+\n+    fn build(mut self) -> TokenStream {\n+        if self.streams.len() <= 1 {\n+            TokenStream(self.streams.pop())\n+        } else {\n+            TokenStream(Some(bridge::client::TokenStream::concat_streams(None, self.streams)))\n+        }\n+    }\n+\n+    fn append_to(mut self, stream: &mut TokenStream) {\n+        if self.streams.is_empty() {\n+            return;\n+        }\n+        let base = stream.0.take();\n+        if base.is_none() && self.streams.len() == 1 {\n+            stream.0 = self.streams.pop();\n+        } else {\n+            stream.0 = Some(bridge::client::TokenStream::concat_streams(base, self.streams));\n+        }\n     }\n }\n \n /// Collects a number of token trees into a single stream.\n #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n impl iter::FromIterator<TokenTree> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenTree>>(trees: I) -> Self {\n-        trees.into_iter().map(TokenStream::from).collect()\n+        let iter = trees.into_iter();\n+        let mut builder = ConcatTreesHelper::new(iter.size_hint().0);\n+        iter.for_each(|tree| builder.push(tree));\n+        builder.build()\n     }\n }\n \n@@ -234,24 +325,30 @@ impl iter::FromIterator<TokenTree> for TokenStream {\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl iter::FromIterator<TokenStream> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenStream>>(streams: I) -> Self {\n-        let mut builder = bridge::client::TokenStreamBuilder::new();\n-        streams.into_iter().for_each(|stream| builder.push(stream.0));\n-        TokenStream(builder.build())\n+        let iter = streams.into_iter();\n+        let mut builder = ConcatStreamsHelper::new(iter.size_hint().0);\n+        iter.for_each(|stream| builder.push(stream));\n+        builder.build()\n     }\n }\n \n #[stable(feature = \"token_stream_extend\", since = \"1.30.0\")]\n impl Extend<TokenTree> for TokenStream {\n     fn extend<I: IntoIterator<Item = TokenTree>>(&mut self, trees: I) {\n-        self.extend(trees.into_iter().map(TokenStream::from));\n+        let iter = trees.into_iter();\n+        let mut builder = ConcatTreesHelper::new(iter.size_hint().0);\n+        iter.for_each(|tree| builder.push(tree));\n+        builder.append_to(self);\n     }\n }\n \n #[stable(feature = \"token_stream_extend\", since = \"1.30.0\")]\n impl Extend<TokenStream> for TokenStream {\n     fn extend<I: IntoIterator<Item = TokenStream>>(&mut self, streams: I) {\n-        // FIXME(eddyb) Use an optimized implementation if/when possible.\n-        *self = iter::once(mem::replace(self, Self::new())).chain(streams).collect();\n+        let iter = streams.into_iter();\n+        let mut builder = ConcatStreamsHelper::new(iter.size_hint().0);\n+        iter.for_each(|stream| builder.push(stream));\n+        builder.append_to(self);\n     }\n }\n \n@@ -265,7 +362,16 @@ pub mod token_stream {\n     /// and returns whole groups as token trees.\n     #[derive(Clone)]\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n-    pub struct IntoIter(bridge::client::TokenStreamIter);\n+    pub struct IntoIter(\n+        std::vec::IntoIter<\n+            bridge::TokenTree<\n+                bridge::client::Group,\n+                bridge::client::Punct,\n+                bridge::client::Ident,\n+                bridge::client::Literal,\n+            >,\n+        >,\n+    );\n \n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     impl Iterator for IntoIter {\n@@ -287,7 +393,7 @@ pub mod token_stream {\n         type IntoIter = IntoIter;\n \n         fn into_iter(self) -> IntoIter {\n-            IntoIter(self.0.into_iter())\n+            IntoIter(self.0.map(|v| v.into_trees()).unwrap_or_default().into_iter())\n         }\n     }\n }\n@@ -734,7 +840,7 @@ impl Group {\n     /// returned above.\n     #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n     pub fn stream(&self) -> TokenStream {\n-        TokenStream(self.0.stream())\n+        TokenStream(Some(self.0.stream()))\n     }\n \n     /// Returns the span for the delimiters of this token stream, spanning the"}]}