{"sha": "3fc4916b53894c63320e31855e3c62b974dfcc95", "node_id": "MDY6Q29tbWl0NzI0NzEyOjNmYzQ5MTZiNTM4OTRjNjMzMjBlMzE4NTVlM2M2MmI5NzRkZmNjOTU=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-07-11T10:31:50Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2020-07-11T10:31:50Z"}, "message": "Reduce visibility", "tree": {"sha": "727e44223da0b60fa01f41ad6b2d26cc9b5cc2c5", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/727e44223da0b60fa01f41ad6b2d26cc9b5cc2c5"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/3fc4916b53894c63320e31855e3c62b974dfcc95", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/3fc4916b53894c63320e31855e3c62b974dfcc95", "html_url": "https://github.com/rust-lang/rust/commit/3fc4916b53894c63320e31855e3c62b974dfcc95", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/3fc4916b53894c63320e31855e3c62b974dfcc95/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6c1546c3a495785cf293dbbfb7f65ea124602528", "url": "https://api.github.com/repos/rust-lang/rust/commits/6c1546c3a495785cf293dbbfb7f65ea124602528", "html_url": "https://github.com/rust-lang/rust/commit/6c1546c3a495785cf293dbbfb7f65ea124602528"}], "stats": {"total": 62, "additions": 31, "deletions": 31}, "files": [{"sha": "97125b32a3a63d74b99e444757ef0c4cfeed68ce", "filename": "crates/ra_hir/src/semantics.rs", "status": "modified", "additions": 31, "deletions": 31, "changes": 62, "blob_url": "https://github.com/rust-lang/rust/blob/3fc4916b53894c63320e31855e3c62b974dfcc95/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/3fc4916b53894c63320e31855e3c62b974dfcc95/crates%2Fra_hir%2Fsrc%2Fsemantics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsemantics.rs?ref=3fc4916b53894c63320e31855e3c62b974dfcc95", "patch": "@@ -270,17 +270,17 @@ impl<'db, DB: HirDatabase> Semantics<'db, DB> {\n }\n \n impl<'db> SemanticsImpl<'db> {\n-    pub fn new(db: &'db dyn HirDatabase) -> Self {\n+    fn new(db: &'db dyn HirDatabase) -> Self {\n         Self { db, s2d_cache: Default::default(), cache: Default::default() }\n     }\n \n-    pub fn parse(&self, file_id: FileId) -> ast::SourceFile {\n+    fn parse(&self, file_id: FileId) -> ast::SourceFile {\n         let tree = self.db.parse(file_id).tree();\n         self.cache(tree.syntax().clone(), file_id.into());\n         tree\n     }\n \n-    pub fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n+    fn expand(&self, macro_call: &ast::MacroCall) -> Option<SyntaxNode> {\n         let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n         let sa = self.analyze2(macro_call.map(|it| it.syntax()), None);\n         let file_id = sa.expand(self.db, macro_call)?;\n@@ -289,7 +289,7 @@ impl<'db> SemanticsImpl<'db> {\n         Some(node)\n     }\n \n-    pub fn expand_hypothetical(\n+    fn expand_hypothetical(\n         &self,\n         actual_macro_call: &ast::MacroCall,\n         hypothetical_args: &ast::TokenTree,\n@@ -310,7 +310,7 @@ impl<'db> SemanticsImpl<'db> {\n         )\n     }\n \n-    pub fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n+    fn descend_into_macros(&self, token: SyntaxToken) -> SyntaxToken {\n         let parent = token.parent();\n         let parent = self.find_file(parent);\n         let sa = self.analyze2(parent.as_ref(), None);\n@@ -334,7 +334,7 @@ impl<'db> SemanticsImpl<'db> {\n         token.value\n     }\n \n-    pub fn descend_node_at_offset(\n+    fn descend_node_at_offset(\n         &self,\n         node: &SyntaxNode,\n         offset: TextSize,\n@@ -346,24 +346,24 @@ impl<'db> SemanticsImpl<'db> {\n             .flatten()\n     }\n \n-    pub fn original_range(&self, node: &SyntaxNode) -> FileRange {\n+    fn original_range(&self, node: &SyntaxNode) -> FileRange {\n         let node = self.find_file(node.clone());\n         original_range(self.db, node.as_ref())\n     }\n \n-    pub fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n+    fn diagnostics_range(&self, diagnostics: &dyn Diagnostic) -> FileRange {\n         let src = diagnostics.source();\n         let root = self.db.parse_or_expand(src.file_id).unwrap();\n         let node = src.value.to_node(&root);\n         original_range(self.db, src.with_value(&node))\n     }\n \n-    pub fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n+    fn ancestors_with_macros(&self, node: SyntaxNode) -> impl Iterator<Item = SyntaxNode> + '_ {\n         let node = self.find_file(node);\n         node.ancestors_with_macros(self.db.upcast()).map(|it| it.value)\n     }\n \n-    pub fn ancestors_at_offset_with_macros(\n+    fn ancestors_at_offset_with_macros(\n         &self,\n         node: &SyntaxNode,\n         offset: TextSize,\n@@ -373,64 +373,64 @@ impl<'db> SemanticsImpl<'db> {\n             .kmerge_by(|node1, node2| node1.text_range().len() < node2.text_range().len())\n     }\n \n-    pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n+    fn type_of_expr(&self, expr: &ast::Expr) -> Option<Type> {\n         self.analyze(expr.syntax()).type_of_expr(self.db, &expr)\n     }\n \n-    pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n+    fn type_of_pat(&self, pat: &ast::Pat) -> Option<Type> {\n         self.analyze(pat.syntax()).type_of_pat(self.db, &pat)\n     }\n \n-    pub fn type_of_self(&self, param: &ast::SelfParam) -> Option<Type> {\n+    fn type_of_self(&self, param: &ast::SelfParam) -> Option<Type> {\n         self.analyze(param.syntax()).type_of_self(self.db, &param)\n     }\n \n-    pub fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n+    fn resolve_method_call(&self, call: &ast::MethodCallExpr) -> Option<Function> {\n         self.analyze(call.syntax()).resolve_method_call(self.db, call)\n     }\n \n-    pub fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n+    fn resolve_field(&self, field: &ast::FieldExpr) -> Option<Field> {\n         self.analyze(field.syntax()).resolve_field(self.db, field)\n     }\n \n-    pub fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n+    fn resolve_record_field(&self, field: &ast::RecordField) -> Option<(Field, Option<Local>)> {\n         self.analyze(field.syntax()).resolve_record_field(self.db, field)\n     }\n \n-    pub fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n+    fn resolve_record_field_pat(&self, field: &ast::RecordFieldPat) -> Option<Field> {\n         self.analyze(field.syntax()).resolve_record_field_pat(self.db, field)\n     }\n \n-    pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n+    fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<MacroDef> {\n         let sa = self.analyze(macro_call.syntax());\n         let macro_call = self.find_file(macro_call.syntax().clone()).with_value(macro_call);\n         sa.resolve_macro_call(self.db, macro_call)\n     }\n \n-    pub fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n+    fn resolve_path(&self, path: &ast::Path) -> Option<PathResolution> {\n         self.analyze(path.syntax()).resolve_path(self.db, path)\n     }\n \n-    pub fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n+    fn resolve_variant(&self, record_lit: ast::RecordLit) -> Option<VariantId> {\n         self.analyze(record_lit.syntax()).resolve_variant(self.db, record_lit)\n     }\n \n-    pub fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n+    fn lower_path(&self, path: &ast::Path) -> Option<Path> {\n         let src = self.find_file(path.syntax().clone());\n         Path::from_src(path.clone(), &Hygiene::new(self.db.upcast(), src.file_id.into()))\n     }\n \n-    pub fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n+    fn resolve_bind_pat_to_const(&self, pat: &ast::BindPat) -> Option<ModuleDef> {\n         self.analyze(pat.syntax()).resolve_bind_pat_to_const(self.db, pat)\n     }\n \n-    pub fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n+    fn record_literal_missing_fields(&self, literal: &ast::RecordLit) -> Vec<(Field, Type)> {\n         self.analyze(literal.syntax())\n             .record_literal_missing_fields(self.db, literal)\n             .unwrap_or_default()\n     }\n \n-    pub fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n+    fn record_pattern_missing_fields(&self, pattern: &ast::RecordPat) -> Vec<(Field, Type)> {\n         self.analyze(pattern.syntax())\n             .record_pattern_missing_fields(self.db, pattern)\n             .unwrap_or_default()\n@@ -442,23 +442,23 @@ impl<'db> SemanticsImpl<'db> {\n         f(&mut ctx)\n     }\n \n-    pub fn to_module_def(&self, file: FileId) -> Option<Module> {\n+    fn to_module_def(&self, file: FileId) -> Option<Module> {\n         self.with_ctx(|ctx| ctx.file_to_def(file)).map(Module::from)\n     }\n \n-    pub fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n+    fn scope(&self, node: &SyntaxNode) -> SemanticsScope<'db> {\n         let node = self.find_file(node.clone());\n         let resolver = self.analyze2(node.as_ref(), None).resolver;\n         SemanticsScope { db: self.db, resolver }\n     }\n \n-    pub fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n+    fn scope_at_offset(&self, node: &SyntaxNode, offset: TextSize) -> SemanticsScope<'db> {\n         let node = self.find_file(node.clone());\n         let resolver = self.analyze2(node.as_ref(), Some(offset)).resolver;\n         SemanticsScope { db: self.db, resolver }\n     }\n \n-    pub fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n+    fn scope_for_def(&self, def: Trait) -> SemanticsScope<'db> {\n         let resolver = def.id.resolver(self.db.upcast());\n         SemanticsScope { db: self.db, resolver }\n     }\n@@ -490,14 +490,14 @@ impl<'db> SemanticsImpl<'db> {\n         SourceAnalyzer::new_for_resolver(resolver, src)\n     }\n \n-    pub fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n+    fn cache(&self, root_node: SyntaxNode, file_id: HirFileId) {\n         assert!(root_node.parent().is_none());\n         let mut cache = self.cache.borrow_mut();\n         let prev = cache.insert(root_node, file_id);\n         assert!(prev == None || prev == Some(file_id))\n     }\n \n-    pub fn assert_contains_node(&self, node: &SyntaxNode) {\n+    fn assert_contains_node(&self, node: &SyntaxNode) {\n         self.find_file(node.clone());\n     }\n \n@@ -506,7 +506,7 @@ impl<'db> SemanticsImpl<'db> {\n         cache.get(root_node).copied()\n     }\n \n-    pub fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n+    fn find_file(&self, node: SyntaxNode) -> InFile<SyntaxNode> {\n         let root_node = find_root(&node);\n         let file_id = self.lookup(&root_node).unwrap_or_else(|| {\n             panic!("}]}