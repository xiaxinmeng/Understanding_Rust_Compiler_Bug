{"sha": "d85c017f92156d0d6854292c976c13c3312bba8e", "node_id": "MDY6Q29tbWl0NzI0NzEyOmQ4NWMwMTdmOTIxNTZkMGQ2ODU0MjkyYzk3NmMxM2MzMzEyYmJhOGU=", "commit": {"author": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2015-01-02T22:00:06Z"}, "committer": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2015-01-06T23:24:48Z"}, "message": "Cleanup and followup to PR #17830: parsing changes\n\nPrevents breaking down `$name` tokens into separate `$` and `name`.\nReports unknown macro variables.\n\nFixes #18775\nFixes #18839\nFixes #15640", "tree": {"sha": "5c5c5e9cd47264e05afe3ad83fc6f8cdc72f14e6", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5c5c5e9cd47264e05afe3ad83fc6f8cdc72f14e6"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/d85c017f92156d0d6854292c976c13c3312bba8e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/d85c017f92156d0d6854292c976c13c3312bba8e", "html_url": "https://github.com/rust-lang/rust/commit/d85c017f92156d0d6854292c976c13c3312bba8e", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/d85c017f92156d0d6854292c976c13c3312bba8e/comments", "author": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8efd9901b628d687d11a4d0ccc153553b38ada49", "url": "https://api.github.com/repos/rust-lang/rust/commits/8efd9901b628d687d11a4d0ccc153553b38ada49", "html_url": "https://github.com/rust-lang/rust/commit/8efd9901b628d687d11a4d0ccc153553b38ada49"}], "stats": {"total": 273, "additions": 170, "deletions": 103}, "files": [{"sha": "a907f096809e6b4774627a225863d184d3d25f2b", "filename": "src/doc/reference.md", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Fdoc%2Freference.md", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Fdoc%2Freference.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Freference.md?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -690,10 +690,9 @@ balanced, but they are otherwise not special.\n \n In the matcher, `$` _name_ `:` _designator_ matches the nonterminal in the Rust\n syntax named by _designator_. Valid designators are `item`, `block`, `stmt`,\n-`pat`, `expr`, `ty` (type), `ident`, `path`, `matchers` (lhs of the `=>` in\n-macro rules), `tt` (rhs of the `=>` in macro rules). In the transcriber, the\n-designator is already known, and so only the name of a matched nonterminal\n-comes after the dollar sign.\n+`pat`, `expr`, `ty` (type), `ident`, `path`, `tt` (either side of the `=>`\n+in macro rules). In the transcriber, the designator is already known, and so\n+only the name of a matched nonterminal comes after the dollar sign.\n \n In both the matcher and transcriber, the Kleene star-like operator indicates\n repetition. The Kleene star operator consists of `$` and parens, optionally"}, {"sha": "7c144cb2befdc146c18588ece80cbc28ef228afa", "filename": "src/libstd/io/mod.rs", "status": "modified", "additions": 11, "deletions": 9, "changes": 20, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibstd%2Fio%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibstd%2Fio%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fmod.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -1780,9 +1780,11 @@ pub struct UnstableFileStat {\n     pub gen: u64,\n }\n \n+\n+// NOTE(stage0): change this one last #[doc=..] to /// after the next snapshot\n bitflags! {\n-    #[doc = \"A set of permissions for a file or directory is represented\"]\n-    #[doc = \"by a set of flags which are or'd together.\"]\n+    #[doc = \"A set of permissions for a file or directory is represented by a set of\"]\n+    /// flags which are or'd together.\n     flags FilePermission: u32 {\n         const USER_READ     = 0o400,\n         const USER_WRITE    = 0o200,\n@@ -1798,20 +1800,20 @@ bitflags! {\n         const GROUP_RWX = GROUP_READ.bits | GROUP_WRITE.bits | GROUP_EXECUTE.bits,\n         const OTHER_RWX = OTHER_READ.bits | OTHER_WRITE.bits | OTHER_EXECUTE.bits,\n \n-        #[doc = \"Permissions for user owned files, equivalent to 0644 on\"]\n-        #[doc = \"unix-like systems.\"]\n+        /// Permissions for user owned files, equivalent to 0644 on unix-like\n+        /// systems.\n         const USER_FILE = USER_READ.bits | USER_WRITE.bits | GROUP_READ.bits | OTHER_READ.bits,\n \n-        #[doc = \"Permissions for user owned directories, equivalent to 0755 on\"]\n-        #[doc = \"unix-like systems.\"]\n+        /// Permissions for user owned directories, equivalent to 0755 on\n+        /// unix-like systems.\n         const USER_DIR  = USER_RWX.bits | GROUP_READ.bits | GROUP_EXECUTE.bits |\n                    OTHER_READ.bits | OTHER_EXECUTE.bits,\n \n-        #[doc = \"Permissions for user owned executables, equivalent to 0755\"]\n-        #[doc = \"on unix-like systems.\"]\n+        /// Permissions for user owned executables, equivalent to 0755\n+        /// on unix-like systems.\n         const USER_EXEC = USER_DIR.bits,\n \n-        #[doc = \"All possible permissions enabled.\"]\n+        /// All possible permissions enabled.\n         const ALL_PERMISSIONS = USER_RWX.bits | GROUP_RWX.bits | OTHER_RWX.bits,\n     }\n }"}, {"sha": "684082f15ac15413b9ee49c0fd44b989f79c250d", "filename": "src/libsyntax/ast.rs", "status": "modified", "additions": 0, "deletions": 6, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fast.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -883,7 +883,6 @@ impl TokenTree {\n     pub fn len(&self) -> uint {\n         match *self {\n             TtToken(_, token::DocComment(_)) => 2,\n-            TtToken(_, token::SubstNt(..)) => 2,\n             TtToken(_, token::SpecialVarNt(..)) => 2,\n             TtToken(_, token::MatchNt(..)) => 3,\n             TtDelimited(_, ref delimed) => {\n@@ -921,11 +920,6 @@ impl TokenTree {\n                 }\n                 delimed.tts[index - 1].clone()\n             }\n-            (&TtToken(sp, token::SubstNt(name, name_st)), _) => {\n-                let v = [TtToken(sp, token::Dollar),\n-                         TtToken(sp, token::Ident(name, name_st))];\n-                v[index]\n-            }\n             (&TtToken(sp, token::SpecialVarNt(var)), _) => {\n                 let v = [TtToken(sp, token::Dollar),\n                          TtToken(sp, token::Ident(token::str_to_ident(var.as_str()),"}, {"sha": "1d46c4ba3f211da6aec111a7fea15e162dd42863", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 11, "deletions": 6, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -506,6 +506,17 @@ pub fn parse(sess: &ParseSess,\n }\n \n pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n+    match name {\n+        \"tt\" => {\n+            p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n+            let res = token::NtTT(P(p.parse_token_tree()));\n+            p.quote_depth -= 1u;\n+            return res;\n+        }\n+        _ => {}\n+    }\n+    // check at the beginning and the parser checks after each bump\n+    p.check_unknown_macro_variable();\n     match name {\n       \"item\" => match p.parse_item(Vec::new()) {\n         Some(i) => token::NtItem(i),\n@@ -529,12 +540,6 @@ pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n         token::NtPath(box p.parse_path(LifetimeAndTypesWithoutColons))\n       }\n       \"meta\" => token::NtMeta(p.parse_meta_item()),\n-      \"tt\" => {\n-        p.quote_depth += 1u; //but in theory, non-quoted tts might be useful\n-        let res = token::NtTT(P(p.parse_token_tree()));\n-        p.quote_depth -= 1u;\n-        res\n-      }\n       _ => {\n           p.fatal(format!(\"unsupported builtin nonterminal parser: {}\", name)[])\n       }"}, {"sha": "fe28863e942b0b73d1b17d945eebf44fe0e0bd0b", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -16,7 +16,7 @@ use ext::base::{NormalTT, TTMacroExpander};\n use ext::tt::macro_parser::{Success, Error, Failure};\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use ext::tt::macro_parser::{parse, parse_or_else};\n-use parse::lexer::new_tt_reader;\n+use parse::lexer::{new_tt_reader, new_tt_reader_with_doc_flag};\n use parse::parser::Parser;\n use parse::attr::ParserAttr;\n use parse::token::{special_idents, gensym_ident};\n@@ -158,13 +158,13 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                 _ => cx.span_fatal(sp, \"malformed macro lhs\")\n             };\n             // `None` is because we're not interpolating\n-            let mut arg_rdr = new_tt_reader(&cx.parse_sess().span_diagnostic,\n-                                            None,\n-                                            None,\n-                                            arg.iter()\n-                                               .map(|x| (*x).clone())\n-                                               .collect());\n-            arg_rdr.desugar_doc_comments = true;\n+            let arg_rdr = new_tt_reader_with_doc_flag(&cx.parse_sess().span_diagnostic,\n+                                                      None,\n+                                                      None,\n+                                                      arg.iter()\n+                                                         .map(|x| (*x).clone())\n+                                                         .collect(),\n+                                                      true);\n             match parse(cx.parse_sess(), cx.cfg(), arg_rdr, lhs_tt) {\n               Success(named_matches) => {\n                 let rhs = match *rhses[i] {\n@@ -183,7 +183,8 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                                            Some(named_matches),\n                                            imported_from,\n                                            rhs);\n-                let p = Parser::new(cx.parse_sess(), cx.cfg(), box trncbr);\n+                let mut p = Parser::new(cx.parse_sess(), cx.cfg(), box trncbr);\n+                p.check_unknown_macro_variable();\n                 // Let the context choose how to interpret the result.\n                 // Weird, but useful for X-macros.\n                 return box ParserAnyMacro {"}, {"sha": "8632d44e872e2aace82dfb28f8fd2a1413dff8b1", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 23, "deletions": 11, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -53,13 +53,28 @@ pub struct TtReader<'a> {\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n-/// `src` contains no `TtSequence`s and `TtNonterminal`s, `interp` can (and\n-/// should) be none.\n+/// `src` contains no `TtSequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n+/// (and should) be None.\n pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n                          interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n                          imported_from: Option<Ident>,\n-                         src: Vec<ast::TokenTree> )\n+                         src: Vec<ast::TokenTree>)\n                          -> TtReader<'a> {\n+    new_tt_reader_with_doc_flag(sp_diag, interp, imported_from, src, false)\n+}\n+\n+/// The extra `desugar_doc_comments` flag enables reading doc comments\n+/// like any other attribute which consists of `meta` and surrounding #[ ] tokens.\n+///\n+/// This can do Macro-By-Example transcription. On the other hand, if\n+/// `src` contains no `TtSequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n+/// (and should) be None.\n+pub fn new_tt_reader_with_doc_flag<'a>(sp_diag: &'a SpanHandler,\n+                                       interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n+                                       imported_from: Option<Ident>,\n+                                       src: Vec<ast::TokenTree>,\n+                                       desugar_doc_comments: bool)\n+                                       -> TtReader<'a> {\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: vec!(TtFrame {\n@@ -80,7 +95,7 @@ pub fn new_tt_reader<'a>(sp_diag: &'a SpanHandler,\n         crate_name_next: None,\n         repeat_idx: Vec::new(),\n         repeat_len: Vec::new(),\n-        desugar_doc_comments: false,\n+        desugar_doc_comments: desugar_doc_comments,\n         /* dummy values, never read: */\n         cur_tok: token::Eof,\n         cur_span: DUMMY_SP,\n@@ -266,18 +281,15 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             }\n             // FIXME #2887: think about span stuff here\n             TtToken(sp, SubstNt(ident, namep)) => {\n+                r.stack.last_mut().unwrap().idx += 1;\n                 match lookup_cur_matched(r, ident) {\n                     None => {\n-                        r.stack.push(TtFrame {\n-                            forest: TtToken(sp, SubstNt(ident, namep)),\n-                            idx: 0,\n-                            dotdotdoted: false,\n-                            sep: None\n-                        });\n+                        r.cur_span = sp;\n+                        r.cur_tok = SubstNt(ident, namep);\n+                        return ret_val;\n                         // this can't be 0 length, just like TtDelimited\n                     }\n                     Some(cur_matched) => {\n-                        r.stack.last_mut().unwrap().idx += 1;\n                         match *cur_matched {\n                             // sidestep the interpolation tricks for ident because\n                             // (a) idents can be in lots of places, so it'd be a pain"}, {"sha": "a095e733f022e76c6785e821dd6b8e4bbb98a3a7", "filename": "src/libsyntax/parse/lexer/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fmod.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -25,7 +25,7 @@ use std::rc::Rc;\n use std::str;\n use std::string::CowString;\n \n-pub use ext::tt::transcribe::{TtReader, new_tt_reader};\n+pub use ext::tt::transcribe::{TtReader, new_tt_reader, new_tt_reader_with_doc_flag};\n \n pub mod comments;\n "}, {"sha": "403e87647309172d4c43d21f5b74864cf9c57170", "filename": "src/libsyntax/parse/mod.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fmod.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -297,7 +297,9 @@ pub fn tts_to_parser<'a>(sess: &'a ParseSess,\n                          tts: Vec<ast::TokenTree>,\n                          cfg: ast::CrateConfig) -> Parser<'a> {\n     let trdr = lexer::new_tt_reader(&sess.span_diagnostic, None, None, tts);\n-    Parser::new(sess, cfg, box trdr)\n+    let mut p = Parser::new(sess, cfg, box trdr);\n+    p.check_unknown_macro_variable();\n+    p\n }\n \n // FIXME (Issue #16472): The `with_hygiene` mod should go away after"}, {"sha": "631a8a5081348fbefb321bb1b160504673eca7dc", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 83, "deletions": 55, "changes": 138, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -946,6 +946,8 @@ impl<'a> Parser<'a> {\n         self.token = next.tok;\n         self.tokens_consumed += 1u;\n         self.expected_tokens.clear();\n+        // check after each token\n+        self.check_unknown_macro_variable();\n     }\n \n     /// Advance the parser by one token and return the bumped token.\n@@ -2655,6 +2657,70 @@ impl<'a> Parser<'a> {\n         return e;\n     }\n \n+    // Parse unquoted tokens after a `$` in a token tree\n+    fn parse_unquoted(&mut self) -> TokenTree {\n+        let mut sp = self.span;\n+        let (name, namep) = match self.token {\n+            token::Dollar => {\n+                self.bump();\n+\n+                if self.token == token::OpenDelim(token::Paren) {\n+                    let Spanned { node: seq, span: seq_span } = self.parse_seq(\n+                        &token::OpenDelim(token::Paren),\n+                        &token::CloseDelim(token::Paren),\n+                        seq_sep_none(),\n+                        |p| p.parse_token_tree()\n+                    );\n+                    let (sep, repeat) = self.parse_sep_and_kleene_op();\n+                    let name_num = macro_parser::count_names(seq[]);\n+                    return TtSequence(mk_sp(sp.lo, seq_span.hi),\n+                                      Rc::new(SequenceRepetition {\n+                                          tts: seq,\n+                                          separator: sep,\n+                                          op: repeat,\n+                                          num_captures: name_num\n+                                      }));\n+                } else if self.token.is_keyword_allow_following_colon(keywords::Crate) {\n+                    self.bump();\n+                    return TtToken(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar));\n+                } else {\n+                    sp = mk_sp(sp.lo, self.span.hi);\n+                    let namep = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n+                    let name = self.parse_ident();\n+                    (name, namep)\n+                }\n+            }\n+            token::SubstNt(name, namep) => {\n+                self.bump();\n+                (name, namep)\n+            }\n+            _ => unreachable!()\n+        };\n+        // continue by trying to parse the `:ident` after `$name`\n+        if self.token == token::Colon && self.look_ahead(1, |t| t.is_ident() &&\n+                                                                !t.is_strict_keyword() &&\n+                                                                !t.is_reserved_keyword()) {\n+            self.bump();\n+            sp = mk_sp(sp.lo, self.span.hi);\n+            let kindp = match self.token { token::Ident(_, p) => p, _ => token::Plain };\n+            let nt_kind = self.parse_ident();\n+            TtToken(sp, MatchNt(name, nt_kind, namep, kindp))\n+        } else {\n+            TtToken(sp, SubstNt(name, namep))\n+        }\n+    }\n+\n+    pub fn check_unknown_macro_variable(&mut self) {\n+        if self.quote_depth == 0u {\n+            match self.token {\n+                token::SubstNt(name, _) =>\n+                    self.fatal(format!(\"unknown macro variable `{}`\",\n+                                       token::get_ident(name))[]),\n+                _ => {}\n+            }\n+        }\n+    }\n+\n     /// Parse an optional separator followed by a Kleene-style\n     /// repetition token (+ or *).\n     pub fn parse_sep_and_kleene_op(&mut self) -> (Option<token::Token>, ast::KleeneOp) {\n@@ -2701,63 +2767,25 @@ impl<'a> Parser<'a> {\n         fn parse_non_delim_tt_tok(p: &mut Parser) -> TokenTree {\n             maybe_whole!(deref p, NtTT);\n             match p.token {\n-              token::CloseDelim(_) => {\n-                  // This is a conservative error: only report the last unclosed delimiter. The\n-                  // previous unclosed delimiters could actually be closed! The parser just hasn't\n-                  // gotten to them yet.\n-                  match p.open_braces.last() {\n-                      None => {}\n-                      Some(&sp) => p.span_note(sp, \"unclosed delimiter\"),\n-                  };\n-                  let token_str = p.this_token_to_string();\n-                  p.fatal(format!(\"incorrect close delimiter: `{}`\",\n-                                  token_str)[])\n-              },\n-              /* we ought to allow different depths of unquotation */\n-              token::Dollar if p.quote_depth > 0u => {\n-                p.bump();\n-                let sp = p.span;\n-\n-                if p.token == token::OpenDelim(token::Paren) {\n-                    let seq = p.parse_seq(\n-                        &token::OpenDelim(token::Paren),\n-                        &token::CloseDelim(token::Paren),\n-                        seq_sep_none(),\n-                        |p| p.parse_token_tree()\n-                    );\n-                    let (sep, repeat) = p.parse_sep_and_kleene_op();\n-                    let seq = match seq {\n-                        Spanned { node, .. } => node,\n+                token::CloseDelim(_) => {\n+                    // This is a conservative error: only report the last unclosed delimiter. The\n+                    // previous unclosed delimiters could actually be closed! The parser just hasn't\n+                    // gotten to them yet.\n+                    match p.open_braces.last() {\n+                        None => {}\n+                        Some(&sp) => p.span_note(sp, \"unclosed delimiter\"),\n                     };\n-                    let name_num = macro_parser::count_names(seq[]);\n-                    TtSequence(mk_sp(sp.lo, p.span.hi),\n-                               Rc::new(SequenceRepetition {\n-                                   tts: seq,\n-                                   separator: sep,\n-                                   op: repeat,\n-                                   num_captures: name_num\n-                               }))\n-                } else if p.token.is_keyword_allow_following_colon(keywords::Crate) {\n-                    p.bump();\n-                    TtToken(sp, SpecialVarNt(SpecialMacroVar::CrateMacroVar))\n-                } else {\n-                    // A nonterminal that matches or not\n-                    let namep = match p.token { token::Ident(_, p) => p, _ => token::Plain };\n-                    let name = p.parse_ident();\n-                    if p.token == token::Colon && p.look_ahead(1, |t| t.is_ident()) {\n-                        p.bump();\n-                        let kindp = match p.token { token::Ident(_, p) => p, _ => token::Plain };\n-                        let nt_kind = p.parse_ident();\n-                        let m = TtToken(sp, MatchNt(name, nt_kind, namep, kindp));\n-                        m\n-                    } else {\n-                        TtToken(sp, SubstNt(name, namep))\n-                    }\n+                    let token_str = p.this_token_to_string();\n+                    p.fatal(format!(\"incorrect close delimiter: `{}`\",\n+                                    token_str)[])\n+                },\n+                /* we ought to allow different depths of unquotation */\n+                token::Dollar | token::SubstNt(..) if p.quote_depth > 0u => {\n+                    p.parse_unquoted()\n+                }\n+                _ => {\n+                    TtToken(p.span, p.bump_and_get())\n                 }\n-              }\n-              _ => {\n-                  TtToken(p.span, p.bump_and_get())\n-              }\n             }\n         }\n "}, {"sha": "e988f404c3c6f45dcf7c8792d92b155546b19501", "filename": "src/test/compile-fail/issue-6596-1.rs", "status": "renamed", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Fcompile-fail%2Fissue-6596-1.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Fcompile-fail%2Fissue-6596-1.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-6596-1.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -8,7 +8,7 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-// error-pattern: unexpected token\n+// error-pattern: unknown macro variable `nonexistent`\n \n macro_rules! e {\n     ($inp:ident) => (", "previous_filename": "src/test/compile-fail/issue-6596.rs"}, {"sha": "0158ad4ba4e0362c5986253f863a28575bf025fe", "filename": "src/test/compile-fail/issue-6596-2.rs", "status": "added", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Fcompile-fail%2Fissue-6596-2.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Fcompile-fail%2Fissue-6596-2.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fcompile-fail%2Fissue-6596-2.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -0,0 +1,23 @@\n+// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+#![feature(macro_rules)]\n+\n+// error-pattern: unknown macro variable `nonexistent`\n+\n+macro_rules! g {\n+    ($inp:ident) => (\n+        { $inp $nonexistent }\n+    );\n+}\n+\n+fn main() {\n+    g!(foo);\n+}"}, {"sha": "aeb6a89a98ea6e2c50030096399f7546c5b1ffec", "filename": "src/test/run-pass-fulldeps/issue-18763-quote-token-tree.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Frun-pass-fulldeps%2Fissue-18763-quote-token-tree.rs", "raw_url": "https://github.com/rust-lang/rust/raw/d85c017f92156d0d6854292c976c13c3312bba8e/src%2Ftest%2Frun-pass-fulldeps%2Fissue-18763-quote-token-tree.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass-fulldeps%2Fissue-18763-quote-token-tree.rs?ref=d85c017f92156d0d6854292c976c13c3312bba8e", "patch": "@@ -21,6 +21,7 @@ fn syntax_extension(cx: &ExtCtxt) {\n     let _toks_1 = vec![quote_tokens!(cx, /** comment */ fn foo() {})];\n     let name = quote_tokens!(cx, bar);\n     let _toks_2 = vec![quote_item!(cx, static $name:int = 2;)];\n+    let _toks_4 = quote_tokens!(cx, $name:static $name:sizeof);\n     let _toks_3 = vec![quote_item!(cx,\n         /// comment\n         fn foo() { let $name:int = 3; }"}]}