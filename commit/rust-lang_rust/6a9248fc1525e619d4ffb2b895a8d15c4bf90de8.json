{"sha": "6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "node_id": "MDY6Q29tbWl0NzI0NzEyOjZhOTI0OGZjMTUyNWU2MTlkNGZmYjJiODk1YThkMTVjNGJmOTBkZTg=", "commit": {"author": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-14T12:15:26Z"}, "committer": {"name": "Jeffrey Seyfried", "email": "jeffrey.seyfried@gmail.com", "date": "2017-01-17T08:17:28Z"}, "message": "Clean up `ext::tt::transcribe`.", "tree": {"sha": "e3fd3e025f12bc78e870374c87dbbb5f4240bdec", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/e3fd3e025f12bc78e870374c87dbbb5f4240bdec"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "html_url": "https://github.com/rust-lang/rust/commit/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8/comments", "author": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jseyfried", "id": 8652869, "node_id": "MDQ6VXNlcjg2NTI4Njk=", "avatar_url": "https://avatars.githubusercontent.com/u/8652869?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jseyfried", "html_url": "https://github.com/jseyfried", "followers_url": "https://api.github.com/users/jseyfried/followers", "following_url": "https://api.github.com/users/jseyfried/following{/other_user}", "gists_url": "https://api.github.com/users/jseyfried/gists{/gist_id}", "starred_url": "https://api.github.com/users/jseyfried/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jseyfried/subscriptions", "organizations_url": "https://api.github.com/users/jseyfried/orgs", "repos_url": "https://api.github.com/users/jseyfried/repos", "events_url": "https://api.github.com/users/jseyfried/events{/privacy}", "received_events_url": "https://api.github.com/users/jseyfried/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "debcbf0b8e8fcf6f1d44e8f79cc06c0866d8d1dd", "url": "https://api.github.com/repos/rust-lang/rust/commits/debcbf0b8e8fcf6f1d44e8f79cc06c0866d8d1dd", "html_url": "https://github.com/rust-lang/rust/commit/debcbf0b8e8fcf6f1d44e8f79cc06c0866d8d1dd"}], "stats": {"total": 109, "additions": 35, "deletions": 74}, "files": [{"sha": "f6a25d4aceed7a7923b1e249cbeed92f87c7e7b6", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 2, "deletions": 11, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "patch": "@@ -16,7 +16,7 @@ use ext::expand::{Expansion, ExpansionKind};\n use ext::tt::macro_parser::{Success, Error, Failure};\n use ext::tt::macro_parser::{MatchedSeq, MatchedNonterminal};\n use ext::tt::macro_parser::{parse, parse_failure_msg};\n-use ext::tt::transcribe::new_tt_reader;\n+use ext::tt::transcribe::transcribe;\n use parse::{Directory, ParseSess};\n use parse::parser::Parser;\n use parse::token::{self, NtTT, Token};\n@@ -113,16 +113,7 @@ fn generic_extension<'cx>(cx: &'cx ExtCtxt,\n                     _ => cx.span_bug(sp, \"malformed macro rhs\"),\n                 };\n                 // rhs has holes ( `$id` and `$(...)` that need filled)\n-                let mut trncbr =\n-                    new_tt_reader(&cx.parse_sess.span_diagnostic, Some(named_matches), rhs);\n-                let mut tts = Vec::new();\n-                loop {\n-                    let tok = trncbr.real_token();\n-                    if tok.tok == token::Eof {\n-                        break\n-                    }\n-                    tts.push(TokenTree::Token(tok.sp, tok.tok));\n-                }\n+                let tts = transcribe(&cx.parse_sess.span_diagnostic, Some(named_matches), rhs);\n                 let directory = Directory {\n                     path: cx.current_expansion.module.directory.clone(),\n                     ownership: cx.current_expansion.directory_ownership,"}, {"sha": "bf6851ec1dc014b6f808fbce0377742cc0cb3972", "filename": "src/libsyntax/ext/tt/transcribe.rs", "status": "modified", "additions": 33, "deletions": 63, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/6a9248fc1525e619d4ffb2b895a8d15c4bf90de8/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Ftranscribe.rs?ref=6a9248fc1525e619d4ffb2b895a8d15c4bf90de8", "patch": "@@ -13,7 +13,6 @@ use ast::Ident;\n use errors::Handler;\n use ext::tt::macro_parser::{NamedMatch, MatchedSeq, MatchedNonterminal};\n use parse::token::{self, MatchNt, SubstNt, Token, NtIdent};\n-use parse::lexer::TokenAndSpan;\n use syntax_pos::{Span, DUMMY_SP};\n use tokenstream::{self, TokenTree};\n use util::small_vector::SmallVector;\n@@ -32,33 +31,24 @@ struct TtFrame {\n }\n \n #[derive(Clone)]\n-pub struct TtReader<'a> {\n-    pub sp_diag: &'a Handler,\n+struct TtReader<'a> {\n+    sp_diag: &'a Handler,\n     /// the unzipped tree:\n     stack: SmallVector<TtFrame>,\n     /* for MBE-style macro transcription */\n     interpolations: HashMap<Ident, Rc<NamedMatch>>,\n \n     repeat_idx: Vec<usize>,\n     repeat_len: Vec<usize>,\n-    /* cached: */\n-    pub cur_tok: Token,\n-    pub cur_span: Span,\n-}\n-\n-impl<'a> TtReader<'a> {\n-    pub fn real_token(&mut self) -> TokenAndSpan {\n-        tt_next_token(self)\n-    }\n }\n \n /// This can do Macro-By-Example transcription. On the other hand, if\n /// `src` contains no `TokenTree::Sequence`s, `MatchNt`s or `SubstNt`s, `interp` can\n /// (and should) be None.\n-pub fn new_tt_reader(sp_diag: &Handler,\n-                     interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n-                     src: Vec<tokenstream::TokenTree>)\n-                     -> TtReader {\n+pub fn transcribe(sp_diag: &Handler,\n+                  interp: Option<HashMap<Ident, Rc<NamedMatch>>>,\n+                  src: Vec<tokenstream::TokenTree>)\n+                  -> Vec<TokenTree> {\n     let mut r = TtReader {\n         sp_diag: sp_diag,\n         stack: SmallVector::one(TtFrame {\n@@ -77,12 +67,15 @@ pub fn new_tt_reader(sp_diag: &Handler,\n         },\n         repeat_idx: Vec::new(),\n         repeat_len: Vec::new(),\n-        /* dummy values, never read: */\n-        cur_tok: token::Eof,\n-        cur_span: DUMMY_SP,\n     };\n-    tt_next_token(&mut r); /* get cur_tok and cur_span set up */\n-    r\n+\n+    let mut tts = Vec::new();\n+    let mut prev_span = DUMMY_SP;\n+    while let Some(tt) = tt_next_token(&mut r, prev_span) {\n+        prev_span = tt.span();\n+        tts.push(tt);\n+    }\n+    tts\n }\n \n fn lookup_cur_matched_by_matched(r: &TtReader, start: Rc<NamedMatch>) -> Rc<NamedMatch> {\n@@ -156,38 +149,24 @@ fn lockstep_iter_size(t: &TokenTree, r: &TtReader) -> LockstepIterSize {\n \n /// Return the next token from the TtReader.\n /// EFFECT: advances the reader's token field\n-pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n-    // FIXME(pcwalton): Bad copy?\n-    let ret_val = TokenAndSpan {\n-        tok: r.cur_tok.clone(),\n-        sp: r.cur_span.clone(),\n-    };\n+fn tt_next_token(r: &mut TtReader, prev_span: Span) -> Option<TokenTree> {\n     loop {\n-        let should_pop = match r.stack.last() {\n-            None => {\n-                assert_eq!(ret_val.tok, token::Eof);\n-                return ret_val;\n-            }\n-            Some(frame) => {\n-                if frame.idx < frame.forest.len() {\n-                    break;\n-                }\n-                !frame.dotdotdoted ||\n-                    *r.repeat_idx.last().unwrap() == *r.repeat_len.last().unwrap() - 1\n+        let should_pop = if let Some(frame) = r.stack.last() {\n+            if frame.idx < frame.forest.len() {\n+                break;\n             }\n+            !frame.dotdotdoted || *r.repeat_idx.last().unwrap() == *r.repeat_len.last().unwrap() - 1\n+        } else {\n+            return None;\n         };\n \n         /* done with this set; pop or repeat? */\n         if should_pop {\n             let prev = r.stack.pop().unwrap();\n-            match r.stack.last_mut() {\n-                None => {\n-                    r.cur_tok = token::Eof;\n-                    return ret_val;\n-                }\n-                Some(frame) => {\n-                    frame.idx += 1;\n-                }\n+            if let Some(frame) = r.stack.last_mut() {\n+                frame.idx += 1;\n+            } else {\n+                return None;\n             }\n             if prev.dotdotdoted {\n                 r.repeat_idx.pop();\n@@ -197,8 +176,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n             *r.repeat_idx.last_mut().unwrap() += 1;\n             r.stack.last_mut().unwrap().idx = 0;\n             if let Some(tk) = r.stack.last().unwrap().sep.clone() {\n-                r.cur_tok = tk; // repeat same span, I guess\n-                return ret_val;\n+                return Some(TokenTree::Token(prev_span, tk)); // repeat same span, I guess\n             }\n         }\n     }\n@@ -234,7 +212,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                             }\n \n                             r.stack.last_mut().unwrap().idx += 1;\n-                            return tt_next_token(r);\n+                            return tt_next_token(r, prev_span);\n                         }\n                         r.repeat_len.push(len);\n                         r.repeat_idx.push(0);\n@@ -252,9 +230,7 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 r.stack.last_mut().unwrap().idx += 1;\n                 match lookup_cur_matched(r, ident) {\n                     None => {\n-                        r.cur_span = sp;\n-                        r.cur_tok = SubstNt(ident);\n-                        return ret_val;\n+                        return Some(TokenTree::Token(sp, SubstNt(ident)));\n                         // this can't be 0 length, just like TokenTree::Delimited\n                     }\n                     Some(cur_matched) => if let MatchedNonterminal(ref nt) = *cur_matched {\n@@ -263,15 +239,11 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                             // (a) idents can be in lots of places, so it'd be a pain\n                             // (b) we actually can, since it's a token.\n                             NtIdent(ref sn) => {\n-                                r.cur_span = sn.span;\n-                                r.cur_tok = token::Ident(sn.node);\n-                                return ret_val;\n+                                return Some(TokenTree::Token(sn.span, token::Ident(sn.node)));\n                             }\n                             _ => {\n-                                // FIXME(pcwalton): Bad copy.\n-                                r.cur_span = sp;\n-                                r.cur_tok = token::Interpolated(nt.clone());\n-                                return ret_val;\n+                                // FIXME(pcwalton): Bad copy\n+                                return Some(TokenTree::Token(sp, token::Interpolated(nt.clone())));\n                             }\n                         }\n                     } else {\n@@ -292,11 +264,9 @@ pub fn tt_next_token(r: &mut TtReader) -> TokenAndSpan {\n                 });\n                 // if this could be 0-length, we'd need to potentially recur here\n             }\n-            TokenTree::Token(sp, tok) => {\n-                r.cur_span = sp;\n-                r.cur_tok = tok;\n+            tt @ TokenTree::Token(..) => {\n                 r.stack.last_mut().unwrap().idx += 1;\n-                return ret_val;\n+                return Some(tt);\n             }\n         }\n     }"}]}