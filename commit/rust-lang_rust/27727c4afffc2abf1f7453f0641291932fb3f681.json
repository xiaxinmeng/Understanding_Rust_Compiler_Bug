{"sha": "27727c4afffc2abf1f7453f0641291932fb3f681", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI3NzI3YzRhZmZmYzJhYmYxZjc0NTNmMDY0MTI5MTkzMmZiM2Y2ODE=", "commit": {"author": {"name": "Martin Carton", "email": "cartonmartin+github@gmail.com", "date": "2017-06-17T17:24:33Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2017-06-17T17:24:33Z"}, "message": "Merge pull request #1799 from Manishearth/docs\n\nRewrite `doc_markdown` to use `pulldown-cmark`", "tree": {"sha": "6493e09a331870352ed6c19e38ccd986d2b3fb4d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/6493e09a331870352ed6c19e38ccd986d2b3fb4d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/27727c4afffc2abf1f7453f0641291932fb3f681", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/27727c4afffc2abf1f7453f0641291932fb3f681", "html_url": "https://github.com/rust-lang/rust/commit/27727c4afffc2abf1f7453f0641291932fb3f681", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/27727c4afffc2abf1f7453f0641291932fb3f681/comments", "author": {"login": "mcarton", "id": 3751788, "node_id": "MDQ6VXNlcjM3NTE3ODg=", "avatar_url": "https://avatars.githubusercontent.com/u/3751788?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mcarton", "html_url": "https://github.com/mcarton", "followers_url": "https://api.github.com/users/mcarton/followers", "following_url": "https://api.github.com/users/mcarton/following{/other_user}", "gists_url": "https://api.github.com/users/mcarton/gists{/gist_id}", "starred_url": "https://api.github.com/users/mcarton/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mcarton/subscriptions", "organizations_url": "https://api.github.com/users/mcarton/orgs", "repos_url": "https://api.github.com/users/mcarton/repos", "events_url": "https://api.github.com/users/mcarton/events{/privacy}", "received_events_url": "https://api.github.com/users/mcarton/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6c587004b5901499e1da7313da9137871762920a", "url": "https://api.github.com/repos/rust-lang/rust/commits/6c587004b5901499e1da7313da9137871762920a", "html_url": "https://github.com/rust-lang/rust/commit/6c587004b5901499e1da7313da9137871762920a"}, {"sha": "898dafba1deac8ccde822ff1cd26f37e547c266c", "url": "https://api.github.com/repos/rust-lang/rust/commits/898dafba1deac8ccde822ff1cd26f37e547c266c", "html_url": "https://github.com/rust-lang/rust/commit/898dafba1deac8ccde822ff1cd26f37e547c266c"}], "stats": {"total": 617, "additions": 218, "deletions": 399}, "files": [{"sha": "78132722c561beadb2f93d1b6dd6467104831339", "filename": "CHANGELOG.md", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/CHANGELOG.md", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/CHANGELOG.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/CHANGELOG.md?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -1,13 +1,16 @@\n # Change Log\n All notable changes to this project will be documented in this file.\n \n+## 0.0.141\n+* Rewrite of the `doc_markdown` lint.\n+\n ## 0.0.140 - 2017-06-16\n * Update to *rustc 1.19.0-nightly (258ae6dd9 2017-06-15)*\n \n ## 0.0.139 \u2014 2017-06-10\n * Update to *rustc 1.19.0-nightly (4bf5c99af 2017-06-10)*\n * Fix bugs with for loop desugaring\n-* Check for AsRef/AsMut arguments in wrong_self_convention\n+* Check for [`AsRef`]/[`AsMut`] arguments in [`wrong_self_convention`]\n \n ## 0.0.138 \u2014 2017-06-05\n * Update to *rustc 1.19.0-nightly (0418fa9d3 2017-06-04)*\n@@ -354,6 +357,8 @@ All notable changes to this project will be documented in this file.\n * Update to *rustc 1.9.0-nightly (998a6720b 2016-03-07)*\n * New lint: [`redundant_closure_call`]\n \n+[`AsMut`]: https://doc.rust-lang.org/std/convert/trait.AsMut.html\n+[`AsRef`]: https://doc.rust-lang.org/std/convert/trait.AsRef.html\n [configuration file]: ./rust-clippy#configuration\n \n <!-- begin autogenerated links to wiki -->"}, {"sha": "d594a295cb6c4a6706e5805aa1310bfb335b7d95", "filename": "clippy_lints/Cargo.toml", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_lints%2FCargo.toml?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -17,15 +17,16 @@ keywords = [\"clippy\", \"lint\", \"plugin\"]\n workspace = \"../clippy_tests\"\n \n [dependencies]\n+itertools = \"0.6.0\"\n+lazy_static = \"0.2.8\"\n matches = \"0.1.2\"\n+quine-mc_cluskey = \"0.2.2\"\n regex-syntax = \"0.4.0\"\n semver = \"0.6.0\"\n-toml = \"0.4\"\n-unicode-normalization = \"0.1\"\n-quine-mc_cluskey = \"0.2.2\"\n serde = \"1.0\"\n serde_derive = \"1.0\"\n-lazy_static = \"0.2.8\"\n+toml = \"0.4\"\n+unicode-normalization = \"0.1\"\n \n [features]\n debugging = []"}, {"sha": "49fdb39a3805c8263ce4b0b421fcfb3861dfd8b5", "filename": "clippy_lints/src/doc.rs", "status": "modified", "additions": 131, "deletions": 283, "changes": 414, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2Fsrc%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2Fsrc%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_lints%2Fsrc%2Fdoc.rs?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -1,6 +1,9 @@\n+use itertools::Itertools;\n+use pulldown_cmark;\n use rustc::lint::*;\n use syntax::ast;\n use syntax::codemap::{Span, BytePos};\n+use syntax_pos::Pos;\n use utils::span_lint;\n \n /// **What it does:** Checks for the presence of `_`, `::` or camel-case words\n@@ -53,324 +56,178 @@ impl EarlyLintPass for Doc {\n     }\n }\n \n+struct Parser<'a> {\n+    parser: pulldown_cmark::Parser<'a>,\n+}\n+\n+impl<'a> Parser<'a> {\n+    fn new(parser: pulldown_cmark::Parser<'a>) -> Parser<'a> {\n+        Self { parser }\n+    }\n+}\n+\n+impl<'a> Iterator for Parser<'a> {\n+    type Item = (usize, pulldown_cmark::Event<'a>);\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        let offset = self.parser.get_offset();\n+        self.parser.next().map(|event| (offset, event))\n+    }\n+}\n+\n /// Cleanup documentation decoration (`///` and such).\n ///\n /// We can't use `syntax::attr::AttributeMethods::with_desugared_doc` or\n /// `syntax::parse::lexer::comments::strip_doc_comment_decoration` because we need to keep track of\n-/// the span but this function is inspired from the later.\n+/// the spans but this function is inspired from the later.\n #[allow(cast_possible_truncation)]\n-pub fn strip_doc_comment_decoration((comment, span): (String, Span)) -> Vec<(String, Span)> {\n+pub fn strip_doc_comment_decoration(comment: &str, span: Span) -> (String, Vec<(usize, Span)>) {\n     // one-line comments lose their prefix\n     const ONELINERS: &'static [&'static str] = &[\"///!\", \"///\", \"//!\", \"//\"];\n     for prefix in ONELINERS {\n         if comment.starts_with(*prefix) {\n-            return vec![(comment[prefix.len()..].to_owned(),\n-                         Span { lo: span.lo + BytePos(prefix.len() as u32), ..span })];\n+            let doc = &comment[prefix.len()..];\n+            let mut doc = doc.to_owned();\n+            doc.push('\\n');\n+            return (\n+                doc.to_owned(),\n+                vec![(doc.len(), Span { lo: span.lo + BytePos(prefix.len() as u32), ..span })]\n+            );\n         }\n     }\n \n     if comment.starts_with(\"/*\") {\n-        return comment[3..comment.len() - 2]\n-            .lines()\n-            .map(|line| {\n-                let offset = line.as_ptr() as usize - comment.as_ptr() as usize;\n-                debug_assert_eq!(offset as u32 as usize, offset);\n-\n-                (line.to_owned(), Span { lo: span.lo + BytePos(offset as u32), ..span })\n-            })\n-            .collect();\n+        let doc = &comment[3..comment.len() - 2];\n+        let mut sizes = vec![];\n+\n+        for line in doc.lines() {\n+            let offset = line.as_ptr() as usize - comment.as_ptr() as usize;\n+            debug_assert_eq!(offset as u32 as usize, offset);\n+\n+            // +1 for the newline\n+            sizes.push((line.len()+1, Span { lo: span.lo + BytePos(offset as u32), ..span }));\n+        }\n+\n+        return (doc.to_string(), sizes);\n     }\n \n     panic!(\"not a doc-comment: {}\", comment);\n }\n \n pub fn check_attrs<'a>(cx: &EarlyContext, valid_idents: &[String], attrs: &'a [ast::Attribute]) {\n-    let mut docs = vec![];\n+    let mut doc = String::new();\n+    let mut spans = vec![];\n \n     for attr in attrs {\n         if attr.is_sugared_doc {\n-            if let Some(ref doc) = attr.value_str() {\n-                let doc = doc.to_string();\n-                docs.extend_from_slice(&strip_doc_comment_decoration((doc, attr.span)));\n+            if let Some(ref current) = attr.value_str() {\n+                let current = current.to_string();\n+                let (current, current_spans) = strip_doc_comment_decoration(&current, attr.span);\n+                spans.extend_from_slice(&current_spans);\n+                doc.push_str(&current);\n+            }\n+        } else if let Some(name) = attr.name() {\n+            // ignore mix of sugared and non-sugared doc\n+            if name == \"doc\" {\n+                return;\n             }\n         }\n     }\n \n-    if !docs.is_empty() {\n-        let _ = check_doc(cx, valid_idents, &docs);\n-    }\n-}\n-\n-#[allow(while_let_loop)] // #362\n-fn check_doc(cx: &EarlyContext, valid_idents: &[String], docs: &[(String, Span)]) -> Result<(), ()> {\n-    // In markdown, `_` can be used to emphasize something, or, is a raw `_` depending on context.\n-    // There really is no markdown specification that would disambiguate this properly. This is\n-    // what GitHub and Rustdoc do:\n-    //\n-    // foo_bar test_quz    \u2192 foo_bar test_quz\n-    // foo_bar_baz         \u2192 foo_bar_baz (note that the \u201cofficial\u201d spec says this should be emphasized)\n-    // _foo bar_ test_quz_ \u2192 <em>foo bar</em> test_quz_\n-    // \\_foo bar\\_         \u2192 _foo bar_\n-    // (_baz_)             \u2192 (<em>baz</em>)\n-    // foo _ bar _ baz     \u2192 foo _ bar _ baz\n-\n-    /// Character that can appear in a path\n-    fn is_path_char(c: char) -> bool {\n-        match c {\n-            t if t.is_alphanumeric() => true,\n-            ':' | '_' => true,\n-            _ => false,\n-        }\n-    }\n-\n-    #[derive(Clone, Debug)]\n-    /// This type is used to iterate through the documentation characters, keeping the span at the\n-    /// same time.\n-    struct Parser<'a> {\n-        /// First byte of the current potential match\n-        current_word_begin: usize,\n-        /// List of lines and their associated span\n-        docs: &'a [(String, Span)],\n-        /// Index of the current line we are parsing\n-        line: usize,\n-        /// Whether we are in a link\n-        link: bool,\n-        /// Whether we are at the beginning of a line\n-        new_line: bool,\n-        /// Whether we were to the end of a line last time `next` was called\n-        reset: bool,\n-        /// The position of the current character within the current line\n-        pos: usize,\n+    let mut current = 0;\n+    for &mut (ref mut offset, _) in &mut spans {\n+        let offset_copy = *offset;\n+        *offset = current;\n+        current += offset_copy;\n     }\n \n-    impl<'a> Parser<'a> {\n-        fn advance_begin(&mut self) {\n-            self.current_word_begin = self.pos;\n-        }\n-\n-        fn line(&self) -> (&'a str, Span) {\n-            let (ref doc, span) = self.docs[self.line];\n-            (doc, span)\n-        }\n+    if !doc.is_empty() {\n+        let parser = Parser::new(pulldown_cmark::Parser::new(&doc));\n+        let parser = parser.coalesce(|x, y| {\n+            use pulldown_cmark::Event::*;\n \n-        fn peek(&self) -> Option<char> {\n-            self.line().0[self.pos..].chars().next()\n-        }\n+            let x_offset = x.0;\n+            let y_offset = y.0;\n \n-        #[allow(while_let_on_iterator)] // borrowck complains about for\n-        fn jump_to(&mut self, n: char) -> Result<bool, ()> {\n-            while let Some((new_line, c)) = self.next() {\n-                if c == n {\n-                    self.advance_begin();\n-                    return Ok(new_line);\n+            match (x.1, y.1) {\n+                (Text(x), Text(y)) => {\n+                    let mut x = x.into_owned();\n+                    x.push_str(&y);\n+                    Ok((x_offset, Text(x.into())))\n                 }\n+                (x, y) => Err(((x_offset, x), (y_offset, y))),\n             }\n-\n-            Err(())\n-        }\n-\n-        fn next_line(&mut self) {\n-            self.pos = 0;\n-            self.current_word_begin = 0;\n-            self.line += 1;\n-            self.new_line = true;\n-        }\n-\n-        fn put_back(&mut self, c: char) {\n-            self.pos -= c.len_utf8();\n-        }\n-\n-        #[allow(cast_possible_truncation)]\n-        fn word(&self) -> (&'a str, Span) {\n-            let begin = self.current_word_begin;\n-            let end = self.pos;\n-\n-            debug_assert_eq!(end as u32 as usize, end);\n-            debug_assert_eq!(begin as u32 as usize, begin);\n-\n-            let (doc, mut span) = self.line();\n-            span.hi = span.lo + BytePos(end as u32);\n-            span.lo = span.lo + BytePos(begin as u32);\n-\n-            (&doc[begin..end], span)\n-        }\n+        });\n+        check_doc(cx, valid_idents, parser, &spans);\n     }\n+}\n \n-    impl<'a> Iterator for Parser<'a> {\n-        type Item = (bool, char);\n-\n-        fn next(&mut self) -> Option<(bool, char)> {\n-            if self.line < self.docs.len() {\n-                if self.reset {\n-                    self.line += 1;\n-                    self.reset = false;\n-                    self.pos = 0;\n-                    self.current_word_begin = 0;\n-                }\n-\n-                let mut chars = self.line().0[self.pos..].chars();\n-                let c = chars.next();\n-\n-                if let Some(c) = c {\n-                    self.pos += c.len_utf8();\n-                    let new_line = self.new_line;\n-                    self.new_line = c == '\\n' || (self.new_line && c.is_whitespace());\n-                    Some((new_line, c))\n-                } else if self.line == self.docs.len() - 1 {\n-                    None\n-                } else {\n-                    self.new_line = true;\n-                    self.reset = true;\n-                    self.pos += 1;\n-                    Some((true, '\\n'))\n+fn check_doc<'a, Events: Iterator<Item=(usize, pulldown_cmark::Event<'a>)>>(\n+    cx: &EarlyContext,\n+    valid_idents: &[String],\n+    docs: Events,\n+    spans: &[(usize, Span)]\n+) {\n+    use pulldown_cmark::Event::*;\n+    use pulldown_cmark::Tag::*;\n+\n+    let mut in_code = false;\n+\n+    for (offset, event) in docs {\n+        match event {\n+            Start(CodeBlock(_)) | Start(Code) => in_code = true,\n+            End(CodeBlock(_)) | End(Code) => in_code = false,\n+            Start(_tag) | End(_tag) => (), // We don't care about other tags\n+            Html(_html) | InlineHtml(_html) => (), // HTML is weird, just ignore it\n+            SoftBreak => (),\n+            HardBreak => (),\n+            FootnoteReference(text) | Text(text) => {\n+                if !in_code {\n+                    let index = match spans.binary_search_by(|c| c.0.cmp(&offset)) {\n+                        Ok(o) => o,\n+                        Err(e) => e-1,\n+                    };\n+\n+                    let (begin, span) = spans[index];\n+\n+                    // Adjust for the begining of the current `Event`\n+                    let span = Span {\n+                        lo: span.lo + BytePos::from_usize(offset - begin),\n+                        ..span\n+                    };\n+\n+                    check_text(cx, valid_idents, &text, span);\n                 }\n-            } else {\n-                None\n-            }\n+            },\n         }\n     }\n+}\n \n-    let mut parser = Parser {\n-        current_word_begin: 0,\n-        docs: docs,\n-        line: 0,\n-        link: false,\n-        new_line: true,\n-        reset: false,\n-        pos: 0,\n-    };\n-\n-    /// Check for fanced code block.\n-    macro_rules! check_block {\n-        ($parser:expr, $c:tt, $new_line:expr) => {{\n-            check_block!($parser, $c, $c, $new_line)\n-        }};\n-\n-        ($parser:expr, $c:pat, $c_expr:expr, $new_line:expr) => {{\n-            fn check_block(parser: &mut Parser, new_line: bool) -> Result<bool, ()> {\n-                if new_line {\n-                    let mut lookup_parser = parser.clone();\n-                    if let (Some((false, $c)), Some((false, $c))) = (lookup_parser.next(), lookup_parser.next()) {\n-                        *parser = lookup_parser;\n-                        // 3 or more ` or ~ open a code block to be closed with the same number of ` or ~\n-                        let mut open_count = 3;\n-                        while let Some((false, $c)) = parser.next() {\n-                            open_count += 1;\n-                        }\n-\n-                        loop {\n-                            loop {\n-                                if try!(parser.jump_to($c_expr)) {\n-                                    break;\n-                                }\n-                            }\n-\n-                            lookup_parser = parser.clone();\n-                            let a = lookup_parser.next();\n-                            let b = lookup_parser.next();\n-                            if let (Some((false, $c)), Some((false, $c))) = (a, b) {\n-                                let mut close_count = 3;\n-                                while let Some((false, $c)) = lookup_parser.next() {\n-                                    close_count += 1;\n-                                }\n-\n-                                if close_count == open_count {\n-                                    *parser = lookup_parser;\n-                                    return Ok(true);\n-                                }\n-                            }\n-                        }\n-                    }\n-                }\n-\n-                Ok(false)\n-            }\n+fn check_text(cx: &EarlyContext, valid_idents: &[String], text: &str, span: Span) {\n+    for word in text.split_whitespace() {\n+        // Trim punctuation as in `some comment (see foo::bar).`\n+        //                                                   ^^\n+        // Or even as in `_foo bar_` which is emphasized.\n+        let word = word.trim_matches(|c: char| !c.is_alphanumeric());\n \n-            check_block(&mut $parser, $new_line)\n-        }};\n-    }\n+        if valid_idents.iter().any(|i| i == word) {\n+            continue;\n+        }\n \n-    loop {\n-        match parser.next() {\n-            Some((new_line, c)) => {\n-                match c {\n-                    '#' if new_line => {\n-                        // don\u2019t warn on titles\n-                        parser.next_line();\n-                    },\n-                    '`' => {\n-                        if try!(check_block!(parser, '`', new_line)) {\n-                            continue;\n-                        }\n-\n-                        // not a code block, just inline code\n-                        try!(parser.jump_to('`'));\n-                    },\n-                    '~' => {\n-                        if try!(check_block!(parser, '~', new_line)) {\n-                            continue;\n-                        }\n-\n-                        // ~ does not introduce inline code, but two of them introduce\n-                        // strikethrough. Too bad for the consistency but we don't care about\n-                        // strikethrough.\n-                    },\n-                    '[' => {\n-                        // Check for a reference definition `[foo]:` at the beginning of a line\n-                        let mut link = true;\n-\n-                        if new_line {\n-                            let mut lookup_parser = parser.clone();\n-                            if lookup_parser.any(|(_, c)| c == ']') {\n-                                if let Some((_, ':')) = lookup_parser.next() {\n-                                    lookup_parser.next_line();\n-                                    parser = lookup_parser;\n-                                    link = false;\n-                                }\n-                            }\n-                        }\n-\n-                        parser.advance_begin();\n-                        parser.link = link;\n-                    },\n-                    ']' if parser.link => {\n-                        parser.link = false;\n-\n-                        match parser.peek() {\n-                            Some('(') => {\n-                                try!(parser.jump_to(')'));\n-                            },\n-                            Some('[') => {\n-                                try!(parser.jump_to(']'));\n-                            },\n-                            Some(_) => continue,\n-                            None => return Err(()),\n-                        }\n-                    },\n-                    c if !is_path_char(c) => {\n-                        parser.advance_begin();\n-                    },\n-                    _ => {\n-                        if let Some((_, c)) = parser.find(|&(_, c)| !is_path_char(c)) {\n-                            parser.put_back(c);\n-                        }\n-\n-                        let (word, span) = parser.word();\n-                        check_word(cx, valid_idents, word, span);\n-                        parser.advance_begin();\n-                    },\n-                }\n+        // Adjust for the current word\n+        let offset = word.as_ptr() as usize - text.as_ptr() as usize;\n+        let span = Span {\n+            lo: span.lo + BytePos::from_usize(offset),\n+            hi: span.lo + BytePos::from_usize(offset + word.len()),\n+            ..span\n+        };\n \n-            },\n-            None => break,\n-        }\n+        check_word(cx, word, span);\n     }\n-\n-    Ok(())\n }\n \n-fn check_word(cx: &EarlyContext, valid_idents: &[String], word: &str, span: Span) {\n-    /// Checks if a string a camel-case, ie. contains at least two uppercase letter (`Clippy` is\n+fn check_word(cx: &EarlyContext, word: &str, span: Span) {\n+    /// Checks if a string is camel-case, ie. contains at least two uppercase letter (`Clippy` is\n     /// ok) and one lower-case letter (`NASA` is ok). Plural are also excluded (`IDs` is ok).\n     fn is_camel_case(s: &str) -> bool {\n         if s.starts_with(|c: char| c.is_digit(10)) {\n@@ -391,15 +248,6 @@ fn check_word(cx: &EarlyContext, valid_idents: &[String], word: &str, span: Span\n         s != \"_\" && !s.contains(\"\\\\_\") && s.contains('_')\n     }\n \n-    // Trim punctuation as in `some comment (see foo::bar).`\n-    //                                                   ^^\n-    // Or even as in `_foo bar_` which is emphasized.\n-    let word = word.trim_matches(|c: char| !c.is_alphanumeric());\n-\n-    if valid_idents.iter().any(|i| i == word) {\n-        return;\n-    }\n-\n     if has_underscore(word) || word.contains(\"::\") || is_camel_case(word) {\n         span_lint(cx,\n                   DOC_MARKDOWN,"}, {"sha": "410cdf6264ad14257149223593e816744bf3c4e1", "filename": "clippy_lints/src/lib.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_lints%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_lints%2Fsrc%2Flib.rs?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -51,6 +51,9 @@ extern crate serde;\n #[macro_use]\n extern crate lazy_static;\n \n+extern crate itertools;\n+extern crate pulldown_cmark;\n+\n macro_rules! declare_restriction_lint {\n     { pub $name:tt, $description:tt } => {\n         declare_lint! { pub $name, Allow, $description }"}, {"sha": "0be34aa6f53a22373190e933d08fbec24507ff0d", "filename": "clippy_tests/examples/doc.rs", "status": "modified", "additions": 17, "deletions": 31, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_tests%2Fexamples%2Fdoc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_tests%2Fexamples%2Fdoc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_tests%2Fexamples%2Fdoc.rs?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -2,13 +2,13 @@\n \n #![feature(plugin)]\n #![plugin(clippy)]\n-\n+#![allow(dead_code)]\n #![warn(doc_markdown)]\n \n /// The foo_bar function does _nothing_. See also foo::bar. (note the dot there)\n /// Markdown is _weird_. I mean _really weird_.  This \\_ is ok. So is `_`. But not Foo::some_fun\n /// which should be reported only once despite being __doubly bad__.\n-/// Here be ::is::a::global:path.\n+/// Here be ::a::global:path.\n /// That's not code ~NotInCodeBlock~.\n /// be_sure_we_got_to_the_end_of_it\n fn foo_bar() {\n@@ -49,35 +49,6 @@ fn test_emphasis() {\n fn test_units() {\n }\n \n-/// This one checks we don\u2019t try to split unicode codepoints\n-/// `\u00df`\n-/// `\u211d`\n-/// `\ud83d\udca3`\n-/// `\u2764\ufe0f`\n-/// \u00df_foo\n-/// \u211d_foo\n-/// \ud83d\udca3_foo\n-/// \u2764\ufe0f_foo\n-/// foo_\u00df\n-/// foo_\u211d\n-/// foo_\ud83d\udca3\n-/// foo_\u2764\ufe0f\n-/// [\u00dfdummy text\u00df][foo_1\u00df]\n-/// [\u211ddummy text\u211d][foo_2\u211d]\n-/// [\ud83d\udca3dummy tex\ud83d\udca3t][foo3_\ud83d\udca3]\n-/// [\u2764\ufe0fdummy text\u2764\ufe0f][foo_4\u2764\ufe0f]\n-/// [\u00dfdummy text\u00df](foo_5\u00df)\n-/// [\u211ddummy text\u211d](foo_6\u211d)\n-/// [\ud83d\udca3dummy tex\ud83d\udca3t](fo7o_\ud83d\udca3)\n-/// [\u2764\ufe0fdummy text\u2764\ufe0f](foo_8\u2764\ufe0f)\n-/// [foo1_\u00df]: dummy text\n-/// [foo2_\u211d]: dummy text\n-/// [foo3_\ud83d\udca3]: dummy text\n-/// [foo4_\u2764\ufe0f]: dummy text\n-/// be_sure_we_got_to_the_end_of_it\n-fn test_unicode() {\n-}\n-\n /// This test has [a link_with_underscores][chunked-example] inside it. See #823.\n /// See also [the issue tracker](https://github.com/Manishearth/rust-clippy/search?q=doc_markdown&type=Issues)\n /// on GitHub (which is a camel-cased word, but is OK). And here is another [inline link][inline_link].\n@@ -167,3 +138,18 @@ fn issue1073_alt() {\n /// be_sure_we_got_to_the_end_of_it\n fn four_quotes() {\n }\n+\n+/// See [NIST SP 800-56A, revision 2].\n+///\n+/// [NIST SP 800-56A, revision 2]:\n+///     https://github.com/Manishearth/rust-clippy/issues/902#issuecomment-261919419\n+fn issue_902_comment() {}\n+\n+#[cfg_attr(feature = \"a\", doc = \" ```\")]\n+#[cfg_attr(not(feature = \"a\"), doc = \" ```ignore\")]\n+/// fn main() {\n+///     let s = \"localhost:10000\".to_string();\n+///     println!(\"{}\", s);\n+/// }\n+/// ```\n+fn issue_1469() {}"}, {"sha": "7e23de55da1e70f39dfb24619d2f94b62a241be4", "filename": "clippy_tests/examples/doc.stderr", "status": "modified", "additions": 56, "deletions": 80, "changes": 136, "blob_url": "https://github.com/rust-lang/rust/blob/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_tests%2Fexamples%2Fdoc.stderr", "raw_url": "https://github.com/rust-lang/rust/raw/27727c4afffc2abf1f7453f0641291932fb3f681/clippy_tests%2Fexamples%2Fdoc.stderr", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/clippy_tests%2Fexamples%2Fdoc.stderr?ref=27727c4afffc2abf1f7453f0641291932fb3f681", "patch": "@@ -30,19 +30,19 @@ error: you should put `Foo::some_fun` between ticks in the documentation\n   |\n   = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `is::a::global:path` between ticks in the documentation\n-  --> doc.rs:11:13\n+error: you should put `a::global:path` between ticks in the documentation\n+  --> doc.rs:11:15\n    |\n-11 | /// Here be ::is::a::global:path.\n-   |             ^^^^^^^^^^^^^^^^^^^^\n+11 | /// Here be ::a::global:path.\n+   |               ^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `NotInCodeBlock` between ticks in the documentation\n-  --> doc.rs:12:21\n+  --> doc.rs:12:22\n    |\n 12 | /// That's not code ~NotInCodeBlock~.\n-   |                     ^^^^^^^^^^^^^^^\n+   |                      ^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n@@ -78,154 +78,130 @@ error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the doc\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `\u00df_foo` between ticks in the documentation\n-  --> doc.rs:57:5\n+error: you should put `link_with_underscores` between ticks in the documentation\n+  --> doc.rs:52:22\n    |\n-57 | /// \u00df_foo\n-   |     ^^^^^\n+52 | /// This test has [a link_with_underscores][chunked-example] inside it. See #823.\n+   |                      ^^^^^^^^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `\u211d_foo` between ticks in the documentation\n-  --> doc.rs:58:5\n+error: you should put `inline_link2` between ticks in the documentation\n+  --> doc.rs:55:21\n    |\n-58 | /// \u211d_foo\n-   |     ^^^^^\n+55 | /// It can also be [inline_link2].\n+   |                     ^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `foo_\u00df` between ticks in the documentation\n-  --> doc.rs:61:5\n+error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n+  --> doc.rs:65:5\n    |\n-61 | /// foo_\u00df\n-   |     ^^^^^\n+65 | /// be_sure_we_got_to_the_end_of_it\n+   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `foo_\u211d` between ticks in the documentation\n-  --> doc.rs:62:5\n+error: you should put `CamelCaseThing` between ticks in the documentation\n+  --> doc.rs:73:8\n    |\n-62 | /// foo_\u211d\n-   |     ^^^^^\n+73 | /// ## CamelCaseThing\n+   |        ^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-  --> doc.rs:77:5\n+error: you should put `CamelCaseThing` between ticks in the documentation\n+  --> doc.rs:76:7\n    |\n-77 | /// be_sure_we_got_to_the_end_of_it\n-   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+76 | /// # CamelCaseThing\n+   |       ^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `link_with_underscores` between ticks in the documentation\n-  --> doc.rs:81:22\n+error: you should put `CamelCaseThing` between ticks in the documentation\n+  --> doc.rs:78:22\n    |\n-81 | /// This test has [a link_with_underscores][chunked-example] inside it. See #823.\n-   |                      ^^^^^^^^^^^^^^^^^^^^^\n+78 | /// Not a title #897 CamelCaseThing\n+   |                      ^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `inline_link2` between ticks in the documentation\n-  --> doc.rs:84:21\n+error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n+  --> doc.rs:79:5\n    |\n-84 | /// It can also be [inline_link2].\n-   |                     ^^^^^^^^^^^^\n+79 | /// be_sure_we_got_to_the_end_of_it\n+   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-  --> doc.rs:94:5\n+  --> doc.rs:86:5\n    |\n-94 | /// be_sure_we_got_to_the_end_of_it\n+86 | /// be_sure_we_got_to_the_end_of_it\n    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    |\n    = note: `-D doc-markdown` implied by `-D warnings`\n \n-error: you should put `CamelCaseThing` between ticks in the documentation\n-   --> doc.rs:107:22\n-    |\n-107 | /// Not a title #897 CamelCaseThing\n-    |                      ^^^^^^^^^^^^^^\n-    |\n-    = note: `-D doc-markdown` implied by `-D warnings`\n-\n error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:108:5\n-    |\n-108 | /// be_sure_we_got_to_the_end_of_it\n-    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n-    |\n-    = note: `-D doc-markdown` implied by `-D warnings`\n-\n-error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:115:5\n-    |\n-115 | /// be_sure_we_got_to_the_end_of_it\n-    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n-    |\n-    = note: `-D doc-markdown` implied by `-D warnings`\n-\n-error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:128:5\n-    |\n-128 | /// be_sure_we_got_to_the_end_of_it\n-    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n-    |\n-    = note: `-D doc-markdown` implied by `-D warnings`\n+  --> doc.rs:99:5\n+   |\n+99 | /// be_sure_we_got_to_the_end_of_it\n+   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+   |\n+   = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `FooBar` between ticks in the documentation\n-   --> doc.rs:139:42\n+   --> doc.rs:110:42\n     |\n-139 | /** E.g. serialization of an empty list: FooBar\n+110 | /** E.g. serialization of an empty list: FooBar\n     |                                          ^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `BarQuz` between ticks in the documentation\n-   --> doc.rs:144:5\n+   --> doc.rs:115:5\n     |\n-144 | And BarQuz too.\n+115 | And BarQuz too.\n     |     ^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:145:1\n+   --> doc.rs:116:1\n     |\n-145 | be_sure_we_got_to_the_end_of_it\n+116 | be_sure_we_got_to_the_end_of_it\n     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `FooBar` between ticks in the documentation\n-   --> doc.rs:150:42\n+   --> doc.rs:121:42\n     |\n-150 | /** E.g. serialization of an empty list: FooBar\n+121 | /** E.g. serialization of an empty list: FooBar\n     |                                          ^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `BarQuz` between ticks in the documentation\n-   --> doc.rs:155:5\n+   --> doc.rs:126:5\n     |\n-155 | And BarQuz too.\n+126 | And BarQuz too.\n     |     ^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:156:1\n+   --> doc.rs:127:1\n     |\n-156 | be_sure_we_got_to_the_end_of_it\n+127 | be_sure_we_got_to_the_end_of_it\n     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`\n \n error: you should put `be_sure_we_got_to_the_end_of_it` between ticks in the documentation\n-   --> doc.rs:167:5\n+   --> doc.rs:138:5\n     |\n-167 | /// be_sure_we_got_to_the_end_of_it\n+138 | /// be_sure_we_got_to_the_end_of_it\n     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n     |\n     = note: `-D doc-markdown` implied by `-D warnings`"}]}