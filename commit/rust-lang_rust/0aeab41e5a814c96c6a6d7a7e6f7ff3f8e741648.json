{"sha": "0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBhZWFiNDFlNWE4MTRjOTZjNmE2ZDdhN2U2ZjdmZjNmOGU3NDE2NDg=", "commit": {"author": {"name": "Julien Cretin", "email": "cretin@google.com", "date": "2019-05-29T18:21:26Z"}, "committer": {"name": "Julien Cretin", "email": "cretin@google.com", "date": "2019-06-23T09:44:52Z"}, "message": "Run rustfmt", "tree": {"sha": "86b875a54708106a0846bc048ca850c85896ca0e", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/86b875a54708106a0846bc048ca850c85896ca0e"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "html_url": "https://github.com/rust-lang/rust/commit/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648/comments", "author": {"login": "ia0", "id": 969295, "node_id": "MDQ6VXNlcjk2OTI5NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/969295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ia0", "html_url": "https://github.com/ia0", "followers_url": "https://api.github.com/users/ia0/followers", "following_url": "https://api.github.com/users/ia0/following{/other_user}", "gists_url": "https://api.github.com/users/ia0/gists{/gist_id}", "starred_url": "https://api.github.com/users/ia0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ia0/subscriptions", "organizations_url": "https://api.github.com/users/ia0/orgs", "repos_url": "https://api.github.com/users/ia0/repos", "events_url": "https://api.github.com/users/ia0/events{/privacy}", "received_events_url": "https://api.github.com/users/ia0/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ia0", "id": 969295, "node_id": "MDQ6VXNlcjk2OTI5NQ==", "avatar_url": "https://avatars.githubusercontent.com/u/969295?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ia0", "html_url": "https://github.com/ia0", "followers_url": "https://api.github.com/users/ia0/followers", "following_url": "https://api.github.com/users/ia0/following{/other_user}", "gists_url": "https://api.github.com/users/ia0/gists{/gist_id}", "starred_url": "https://api.github.com/users/ia0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ia0/subscriptions", "organizations_url": "https://api.github.com/users/ia0/orgs", "repos_url": "https://api.github.com/users/ia0/repos", "events_url": "https://api.github.com/users/ia0/events{/privacy}", "received_events_url": "https://api.github.com/users/ia0/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a96ba969156d257e5d5b692946fa8fe40ed6543a", "url": "https://api.github.com/repos/rust-lang/rust/commits/a96ba969156d257e5d5b692946fa8fe40ed6543a", "html_url": "https://github.com/rust-lang/rust/commit/a96ba969156d257e5d5b692946fa8fe40ed6543a"}], "stats": {"total": 508, "additions": 273, "deletions": 235}, "files": [{"sha": "1a448cb2a43cf61a7442a5d4050d6fb69768bc89", "filename": "src/libsyntax/ext/tt/macro_rules.rs", "status": "modified", "additions": 260, "deletions": 206, "changes": 466, "blob_url": "https://github.com/rust-lang/rust/blob/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_rules.rs?ref=0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "patch": "@@ -1,37 +1,37 @@\n-use crate::{ast, attr};\n use crate::edition::Edition;\n-use crate::ext::base::{SyntaxExtension, SyntaxExtensionKind};\n use crate::ext::base::{DummyResult, ExtCtxt, MacResult, TTMacroExpander};\n+use crate::ext::base::{SyntaxExtension, SyntaxExtensionKind};\n use crate::ext::expand::{AstFragment, AstFragmentKind};\n use crate::ext::hygiene::Transparency;\n-use crate::ext::tt::macro_parser::{Success, Error, Failure};\n-use crate::ext::tt::macro_parser::{MatchedSeq, MatchedNonterminal};\n use crate::ext::tt::macro_parser::{parse, parse_failure_msg};\n+use crate::ext::tt::macro_parser::{Error, Failure, Success};\n+use crate::ext::tt::macro_parser::{MatchedNonterminal, MatchedSeq};\n use crate::ext::tt::quoted;\n use crate::ext::tt::transcribe::transcribe;\n use crate::feature_gate::Features;\n-use crate::parse::{Directory, ParseSess};\n use crate::parse::parser::Parser;\n-use crate::parse::token::{self, Token, NtTT};\n use crate::parse::token::TokenKind::*;\n-use crate::symbol::{Symbol, kw, sym};\n+use crate::parse::token::{self, NtTT, Token};\n+use crate::parse::{Directory, ParseSess};\n+use crate::symbol::{kw, sym, Symbol};\n use crate::tokenstream::{DelimSpan, TokenStream, TokenTree};\n+use crate::{ast, attr};\n \n use errors::FatalError;\n-use syntax_pos::{Span, symbol::Ident};\n use log::debug;\n+use syntax_pos::{symbol::Ident, Span};\n \n-use rustc_data_structures::fx::{FxHashMap};\n+use rustc_data_structures::fx::FxHashMap;\n use std::borrow::Cow;\n use std::collections::hash_map::Entry;\n use std::slice;\n \n-use rustc_data_structures::sync::Lrc;\n use errors::Applicability;\n+use rustc_data_structures::sync::Lrc;\n \n const VALID_FRAGMENT_NAMES_MSG: &str = \"valid fragment specifiers are \\\n-    `ident`, `block`, `stmt`, `expr`, `pat`, `ty`, `lifetime`, `literal`, \\\n-    `path`, `meta`, `tt`, `item` and `vis`\";\n+                                        `ident`, `block`, `stmt`, `expr`, `pat`, `ty`, `lifetime`, \\\n+                                        `literal`, `path`, `meta`, `tt`, `item` and `vis`\";\n \n pub struct ParserAnyMacro<'a> {\n     parser: Parser<'a>,\n@@ -48,7 +48,8 @@ impl<'a> ParserAnyMacro<'a> {\n         let ParserAnyMacro { site_span, macro_ident, ref mut parser, arm_span } = *self;\n         let fragment = panictry!(parser.parse_ast_fragment(kind, true).map_err(|mut e| {\n             if parser.token == token::Eof && e.message().ends_with(\", found `<eof>`\") {\n-                if !e.span.is_dummy() {  // early end of macro arm (#52866)\n+                if !e.span.is_dummy() {\n+                    // early end of macro arm (#52866)\n                     e.replace_span_with(parser.sess.source_map().next_point(parser.token.span));\n                 }\n                 let msg = &e.message[0];\n@@ -60,7 +61,8 @@ impl<'a> ParserAnyMacro<'a> {\n                     msg.1,\n                 );\n             }\n-            if e.span.is_dummy() {  // Get around lack of span in error (#30128)\n+            if e.span.is_dummy() {\n+                // Get around lack of span in error (#30128)\n                 e.replace_span_with(site_span);\n                 if parser.sess.source_map().span_to_filename(arm_span).is_real() {\n                     e.span_label(arm_span, \"in this macro arm\");\n@@ -99,17 +101,11 @@ impl TTMacroExpander for MacroRulesMacroExpander {\n         sp: Span,\n         input: TokenStream,\n         def_span: Option<Span>,\n-    ) -> Box<dyn MacResult+'cx> {\n+    ) -> Box<dyn MacResult + 'cx> {\n         if !self.valid {\n             return DummyResult::any(sp);\n         }\n-        generic_extension(cx,\n-                          sp,\n-                          def_span,\n-                          self.name,\n-                          input,\n-                          &self.lhses,\n-                          &self.rhses)\n+        generic_extension(cx, sp, def_span, self.name, input, &self.lhses, &self.rhses)\n     }\n }\n \n@@ -119,25 +115,27 @@ fn trace_macros_note(cx: &mut ExtCtxt<'_>, sp: Span, message: String) {\n }\n \n /// Given `lhses` and `rhses`, this is the new macro we create\n-fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n-                          sp: Span,\n-                          def_span: Option<Span>,\n-                          name: ast::Ident,\n-                          arg: TokenStream,\n-                          lhses: &[quoted::TokenTree],\n-                          rhses: &[quoted::TokenTree])\n-                          -> Box<dyn MacResult+'cx> {\n+fn generic_extension<'cx>(\n+    cx: &'cx mut ExtCtxt<'_>,\n+    sp: Span,\n+    def_span: Option<Span>,\n+    name: ast::Ident,\n+    arg: TokenStream,\n+    lhses: &[quoted::TokenTree],\n+    rhses: &[quoted::TokenTree],\n+) -> Box<dyn MacResult + 'cx> {\n     if cx.trace_macros() {\n         trace_macros_note(cx, sp, format!(\"expanding `{}! {{ {} }}`\", name, arg));\n     }\n \n     // Which arm's failure should we report? (the one furthest along)\n     let mut best_failure: Option<(Token, &str)> = None;\n \n-    for (i, lhs) in lhses.iter().enumerate() { // try each arm's matchers\n+    for (i, lhs) in lhses.iter().enumerate() {\n+        // try each arm's matchers\n         let lhs_tt = match *lhs {\n             quoted::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n-            _ => cx.span_bug(sp, \"malformed macro lhs\")\n+            _ => cx.span_bug(sp, \"malformed macro lhs\"),\n         };\n \n         match TokenTree::parse(cx, lhs_tt, arg.clone()) {\n@@ -173,8 +171,8 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n                     ownership: cx.current_expansion.directory_ownership,\n                 };\n                 let mut p = Parser::new(cx.parse_sess(), tts, Some(directory), true, false, None);\n-                p.root_module_name = cx.current_expansion.module.mod_path.last()\n-                    .map(|id| id.as_str().to_string());\n+                p.root_module_name =\n+                    cx.current_expansion.module.mod_path.last().map(|id| id.as_str().to_string());\n \n                 p.process_potential_macro_variable();\n                 // Let the context choose how to interpret the result.\n@@ -188,15 +186,13 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n                     site_span: sp,\n                     macro_ident: name,\n                     arm_span,\n-                })\n+                });\n             }\n             Failure(token, msg) => match best_failure {\n                 Some((ref best_token, _)) if best_token.span.lo() >= token.span.lo() => {}\n-                _ => best_failure = Some((token, msg))\n-            }\n-            Error(err_sp, ref msg) => {\n-                cx.span_fatal(err_sp.substitute_dummy(sp), &msg[..])\n-            }\n+                _ => best_failure = Some((token, msg)),\n+            },\n+            Error(err_sp, ref msg) => cx.span_fatal(err_sp.substitute_dummy(sp), &msg[..]),\n         }\n     }\n \n@@ -212,7 +208,8 @@ fn generic_extension<'cx>(cx: &'cx mut ExtCtxt<'_>,\n \n     // Check whether there's a missing comma in this macro call, like `println!(\"{}\" a);`\n     if let Some((arg, comma_span)) = arg.add_comma() {\n-        for lhs in lhses { // try each arm's matchers\n+        for lhs in lhses {\n+            // try each arm's matchers\n             let lhs_tt = match *lhs {\n                 quoted::TokenTree::Delimited(_, ref delim) => &delim.tts[..],\n                 _ => continue,\n@@ -249,7 +246,7 @@ pub fn compile(\n     sess: &ParseSess,\n     features: &Features,\n     def: &ast::Item,\n-    edition: Edition\n+    edition: Edition,\n ) -> SyntaxExtension {\n     let lhs_nm = ast::Ident::new(sym::lhs, def.span);\n     let rhs_nm = ast::Ident::new(sym::rhs, def.span);\n@@ -267,25 +264,32 @@ pub fn compile(\n     // ...quasiquoting this would be nice.\n     // These spans won't matter, anyways\n     let argument_gram = vec![\n-        quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n-            tts: vec![\n-                quoted::TokenTree::MetaVarDecl(def.span, lhs_nm, tt_spec),\n-                quoted::TokenTree::token(token::FatArrow, def.span),\n-                quoted::TokenTree::MetaVarDecl(def.span, rhs_nm, tt_spec),\n-            ],\n-            separator: Some(Token::new(\n-                if body.legacy { token::Semi } else { token::Comma }, def.span\n-            )),\n-            op: quoted::KleeneOp::OneOrMore,\n-            num_captures: 2,\n-        })),\n+        quoted::TokenTree::Sequence(\n+            DelimSpan::dummy(),\n+            Lrc::new(quoted::SequenceRepetition {\n+                tts: vec![\n+                    quoted::TokenTree::MetaVarDecl(def.span, lhs_nm, tt_spec),\n+                    quoted::TokenTree::token(token::FatArrow, def.span),\n+                    quoted::TokenTree::MetaVarDecl(def.span, rhs_nm, tt_spec),\n+                ],\n+                separator: Some(Token::new(\n+                    if body.legacy { token::Semi } else { token::Comma },\n+                    def.span,\n+                )),\n+                op: quoted::KleeneOp::OneOrMore,\n+                num_captures: 2,\n+            }),\n+        ),\n         // to phase into semicolon-termination instead of semicolon-separation\n-        quoted::TokenTree::Sequence(DelimSpan::dummy(), Lrc::new(quoted::SequenceRepetition {\n-            tts: vec![quoted::TokenTree::token(token::Semi, def.span)],\n-            separator: None,\n-            op: quoted::KleeneOp::ZeroOrMore,\n-            num_captures: 0\n-        })),\n+        quoted::TokenTree::Sequence(\n+            DelimSpan::dummy(),\n+            Lrc::new(quoted::SequenceRepetition {\n+                tts: vec![quoted::TokenTree::token(token::Semi, def.span)],\n+                separator: None,\n+                op: quoted::KleeneOp::ZeroOrMore,\n+                num_captures: 0,\n+            }),\n+        ),\n     ];\n \n     let argument_map = match parse(sess, body.stream(), &argument_gram, None, true) {\n@@ -307,8 +311,9 @@ pub fn compile(\n \n     // Extract the arguments:\n     let lhses = match *argument_map[&lhs_nm] {\n-        MatchedSeq(ref s, _) => {\n-            s.iter().map(|m| {\n+        MatchedSeq(ref s, _) => s\n+            .iter()\n+            .map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n                         let tt = quoted::parse(\n@@ -327,14 +332,15 @@ pub fn compile(\n                     }\n                 }\n                 sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n-            }).collect::<Vec<quoted::TokenTree>>()\n-        }\n-        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n+            })\n+            .collect::<Vec<quoted::TokenTree>>(),\n+        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\"),\n     };\n \n     let rhses = match *argument_map[&rhs_nm] {\n-        MatchedSeq(ref s, _) => {\n-            s.iter().map(|m| {\n+        MatchedSeq(ref s, _) => s\n+            .iter()\n+            .map(|m| {\n                 if let MatchedNonterminal(ref nt) = *m {\n                     if let NtTT(ref tt) = **nt {\n                         return quoted::parse(\n@@ -345,14 +351,15 @@ pub fn compile(\n                             &def.attrs,\n                             edition,\n                             def.id,\n-                        ).pop()\n-                         .unwrap();\n+                        )\n+                        .pop()\n+                        .unwrap();\n                     }\n                 }\n                 sess.span_diagnostic.span_bug(def.span, \"wrong-structured lhs\")\n-            }).collect::<Vec<quoted::TokenTree>>()\n-        }\n-        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\")\n+            })\n+            .collect::<Vec<quoted::TokenTree>>(),\n+        _ => sess.span_diagnostic.span_bug(def.span, \"wrong-structured rhs\"),\n     };\n \n     for rhs in &rhses {\n@@ -366,16 +373,12 @@ pub fn compile(\n             sess,\n             slice::from_ref(lhs),\n             &mut FxHashMap::default(),\n-            def.id\n+            def.id,\n         );\n     }\n \n-    let expander: Box<_> = Box::new(MacroRulesMacroExpander {\n-        name: def.ident,\n-        lhses,\n-        rhses,\n-        valid,\n-    });\n+    let expander: Box<_> =\n+        Box::new(MacroRulesMacroExpander { name: def.ident, lhses, rhses, valid });\n \n     let default_transparency = if attr::contains_name(&def.attrs, sym::rustc_transparent_macro) {\n         Transparency::Transparent\n@@ -385,29 +388,34 @@ pub fn compile(\n         Transparency::Opaque\n     };\n \n-    let allow_internal_unstable = attr::find_by_name(&def.attrs, sym::allow_internal_unstable)\n-        .map(|attr| attr\n-            .meta_item_list()\n-            .map(|list| list.iter()\n-                .filter_map(|it| {\n-                    let name = it.ident().map(|ident| ident.name);\n-                    if name.is_none() {\n-                        sess.span_diagnostic.span_err(it.span(),\n-                            \"allow internal unstable expects feature names\")\n-                    }\n-                    name\n+    let allow_internal_unstable =\n+        attr::find_by_name(&def.attrs, sym::allow_internal_unstable).map(|attr| {\n+            attr.meta_item_list()\n+                .map(|list| {\n+                    list.iter()\n+                        .filter_map(|it| {\n+                            let name = it.ident().map(|ident| ident.name);\n+                            if name.is_none() {\n+                                sess.span_diagnostic.span_err(\n+                                    it.span(),\n+                                    \"allow internal unstable expects feature names\",\n+                                )\n+                            }\n+                            name\n+                        })\n+                        .collect::<Vec<Symbol>>()\n+                        .into()\n                 })\n-                .collect::<Vec<Symbol>>().into()\n-            )\n-            .unwrap_or_else(|| {\n-                sess.span_diagnostic.span_warn(\n-                    attr.span, \"allow_internal_unstable expects list of feature names. In the \\\n-                    future this will become a hard error. Please use `allow_internal_unstable(\\\n-                    foo, bar)` to only allow the `foo` and `bar` features\",\n-                );\n-                vec![sym::allow_internal_unstable_backcompat_hack].into()\n-            })\n-        );\n+                .unwrap_or_else(|| {\n+                    sess.span_diagnostic.span_warn(\n+                        attr.span,\n+                        \"allow_internal_unstable expects list of feature names. In the \\\n+                         future this will become a hard error. Please use `allow_internal_unstable(\\\n+                         foo, bar)` to only allow the `foo` and `bar` features\",\n+                    );\n+                    vec![sym::allow_internal_unstable_backcompat_hack].into()\n+                })\n+        });\n \n     let allow_internal_unsafe = attr::contains_name(&def.attrs, sym::allow_internal_unsafe);\n \n@@ -418,14 +426,14 @@ pub fn compile(\n         }\n     }\n \n-    let unstable_feature = attr::find_stability(&sess,\n-                                                &def.attrs, def.span).and_then(|stability| {\n-        if let attr::StabilityLevel::Unstable { issue, .. } = stability.level {\n-            Some((stability.feature, issue))\n-        } else {\n-            None\n-        }\n-    });\n+    let unstable_feature =\n+        attr::find_stability(&sess, &def.attrs, def.span).and_then(|stability| {\n+            if let attr::StabilityLevel::Unstable { issue, .. } = stability.level {\n+                Some((stability.feature, issue))\n+            } else {\n+                None\n+            }\n+        });\n \n     SyntaxExtension {\n         kind: SyntaxExtensionKind::LegacyBang(expander),\n@@ -440,10 +448,12 @@ pub fn compile(\n     }\n }\n \n-fn check_lhs_nt_follows(sess: &ParseSess,\n-                        features: &Features,\n-                        attrs: &[ast::Attribute],\n-                        lhs: &quoted::TokenTree) -> bool {\n+fn check_lhs_nt_follows(\n+    sess: &ParseSess,\n+    features: &Features,\n+    attrs: &[ast::Attribute],\n+    lhs: &quoted::TokenTree,\n+) -> bool {\n     // lhs is going to be like TokenTree::Delimited(...), where the\n     // entire lhs is those tts. Or, it can be a \"bare sequence\", not wrapped in parens.\n     if let quoted::TokenTree::Delimited(_, ref tts) = *lhs {\n@@ -464,19 +474,22 @@ fn check_lhs_no_empty_seq(sess: &ParseSess, tts: &[quoted::TokenTree]) -> bool {\n     for tt in tts {\n         match *tt {\n             TokenTree::Token(..) | TokenTree::MetaVar(..) | TokenTree::MetaVarDecl(..) => (),\n-            TokenTree::Delimited(_, ref del) => if !check_lhs_no_empty_seq(sess, &del.tts) {\n-                return false;\n-            },\n+            TokenTree::Delimited(_, ref del) => {\n+                if !check_lhs_no_empty_seq(sess, &del.tts) {\n+                    return false;\n+                }\n+            }\n             TokenTree::Sequence(span, ref seq) => {\n-                if seq.separator.is_none() && seq.tts.iter().all(|seq_tt| {\n-                    match *seq_tt {\n+                if seq.separator.is_none()\n+                    && seq.tts.iter().all(|seq_tt| match *seq_tt {\n                         TokenTree::MetaVarDecl(_, _, id) => id.name == sym::vis,\n-                        TokenTree::Sequence(_, ref sub_seq) =>\n+                        TokenTree::Sequence(_, ref sub_seq) => {\n                             sub_seq.op == quoted::KleeneOp::ZeroOrMore\n-                            || sub_seq.op == quoted::KleeneOp::ZeroOrOne,\n+                                || sub_seq.op == quoted::KleeneOp::ZeroOrOne\n+                        }\n                         _ => false,\n-                    }\n-                }) {\n+                    })\n+                {\n                     let sp = span.entire();\n                     sess.span_diagnostic.span_err(sp, \"repetition matches empty token tree\");\n                     return false;\n@@ -517,7 +530,7 @@ fn check_lhs_duplicate_matcher_bindings(\n                 if !check_lhs_duplicate_matcher_bindings(sess, &del.tts, metavar_names, node_id) {\n                     return false;\n                 }\n-            },\n+            }\n             TokenTree::Sequence(_, ref seq) => {\n                 if !check_lhs_duplicate_matcher_bindings(sess, &seq.tts, metavar_names, node_id) {\n                     return false;\n@@ -533,15 +546,17 @@ fn check_lhs_duplicate_matcher_bindings(\n fn check_rhs(sess: &ParseSess, rhs: &quoted::TokenTree) -> bool {\n     match *rhs {\n         quoted::TokenTree::Delimited(..) => return true,\n-        _ => sess.span_diagnostic.span_err(rhs.span(), \"macro rhs must be delimited\")\n+        _ => sess.span_diagnostic.span_err(rhs.span(), \"macro rhs must be delimited\"),\n     }\n     false\n }\n \n-fn check_matcher(sess: &ParseSess,\n-                 features: &Features,\n-                 attrs: &[ast::Attribute],\n-                 matcher: &[quoted::TokenTree]) -> bool {\n+fn check_matcher(\n+    sess: &ParseSess,\n+    features: &Features,\n+    attrs: &[ast::Attribute],\n+    matcher: &[quoted::TokenTree],\n+) -> bool {\n     let first_sets = FirstSets::new(matcher);\n     let empty_suffix = TokenSet::empty();\n     let err = sess.span_diagnostic.err_count();\n@@ -620,8 +635,8 @@ impl FirstSets {\n \n                         // Reverse scan: Sequence comes before `first`.\n                         if subfirst.maybe_empty\n-                           || seq_rep.op == quoted::KleeneOp::ZeroOrMore\n-                           || seq_rep.op == quoted::KleeneOp::ZeroOrOne\n+                            || seq_rep.op == quoted::KleeneOp::ZeroOrMore\n+                            || seq_rep.op == quoted::KleeneOp::ZeroOrOne\n                         {\n                             // If sequence is potentially empty, then\n                             // union them (preserving first emptiness).\n@@ -659,7 +674,6 @@ impl FirstSets {\n                 TokenTree::Sequence(sp, ref seq_rep) => {\n                     match self.first.get(&sp.entire()) {\n                         Some(&Some(ref subfirst)) => {\n-\n                             // If the sequence contents can be empty, then the first\n                             // token could be the separator token itself.\n \n@@ -670,8 +684,8 @@ impl FirstSets {\n                             assert!(first.maybe_empty);\n                             first.add_all(subfirst);\n                             if subfirst.maybe_empty\n-                               || seq_rep.op == quoted::KleeneOp::ZeroOrMore\n-                               || seq_rep.op == quoted::KleeneOp::ZeroOrOne\n+                                || seq_rep.op == quoted::KleeneOp::ZeroOrMore\n+                                || seq_rep.op == quoted::KleeneOp::ZeroOrOne\n                             {\n                                 // continue scanning for more first\n                                 // tokens, but also make sure we\n@@ -720,7 +734,9 @@ struct TokenSet {\n \n impl TokenSet {\n     // Returns a set for the empty sequence.\n-    fn empty() -> Self { TokenSet { tokens: Vec::new(), maybe_empty: true } }\n+    fn empty() -> Self {\n+        TokenSet { tokens: Vec::new(), maybe_empty: true }\n+    }\n \n     // Returns the set `{ tok }` for the single-token (and thus\n     // non-empty) sequence [tok].\n@@ -789,12 +805,14 @@ impl TokenSet {\n //\n // Requires that `first_sets` is pre-computed for `matcher`;\n // see `FirstSets::new`.\n-fn check_matcher_core(sess: &ParseSess,\n-                      features: &Features,\n-                      attrs: &[ast::Attribute],\n-                      first_sets: &FirstSets,\n-                      matcher: &[quoted::TokenTree],\n-                      follow: &TokenSet) -> TokenSet {\n+fn check_matcher_core(\n+    sess: &ParseSess,\n+    features: &Features,\n+    attrs: &[ast::Attribute],\n+    first_sets: &FirstSets,\n+    matcher: &[quoted::TokenTree],\n+    follow: &TokenSet,\n+) -> TokenSet {\n     use quoted::TokenTree;\n \n     let mut last = TokenSet::empty();\n@@ -804,11 +822,13 @@ fn check_matcher_core(sess: &ParseSess,\n     // then ensure T can also be followed by any element of FOLLOW.\n     'each_token: for i in 0..matcher.len() {\n         let token = &matcher[i];\n-        let suffix = &matcher[i+1..];\n+        let suffix = &matcher[i + 1..];\n \n         let build_suffix_first = || {\n             let mut s = first_sets.first(suffix);\n-            if s.maybe_empty { s.add_all(follow); }\n+            if s.maybe_empty {\n+                s.add_all(follow);\n+            }\n             s\n         };\n \n@@ -824,7 +844,8 @@ fn check_matcher_core(sess: &ParseSess,\n                 let can_be_followed_by_any;\n                 if let Err(bad_frag) = has_legal_fragment_specifier(sess, features, attrs, token) {\n                     let msg = format!(\"invalid fragment specifier `{}`\", bad_frag);\n-                    sess.span_diagnostic.struct_span_err(token.span(), &msg)\n+                    sess.span_diagnostic\n+                        .struct_span_err(token.span(), &msg)\n                         .help(VALID_FRAGMENT_NAMES_MSG)\n                         .emit();\n                     // (This eliminates false positives and duplicates\n@@ -879,12 +900,8 @@ fn check_matcher_core(sess: &ParseSess,\n                 // At this point, `suffix_first` is built, and\n                 // `my_suffix` is some TokenSet that we can use\n                 // for checking the interior of `seq_rep`.\n-                let next = check_matcher_core(sess,\n-                                              features,\n-                                              attrs,\n-                                              first_sets,\n-                                              &seq_rep.tts,\n-                                              my_suffix);\n+                let next =\n+                    check_matcher_core(sess, features, attrs, first_sets, &seq_rep.tts, my_suffix);\n                 if next.maybe_empty {\n                     last.add_all(&next);\n                 } else {\n@@ -906,16 +923,17 @@ fn check_matcher_core(sess: &ParseSess,\n                 for next_token in &suffix_first.tokens {\n                     match is_in_follow(next_token, &frag_spec.as_str()) {\n                         IsInFollow::Invalid(msg, help) => {\n-                            sess.span_diagnostic.struct_span_err(next_token.span(), &msg)\n-                                .help(help).emit();\n+                            sess.span_diagnostic\n+                                .struct_span_err(next_token.span(), &msg)\n+                                .help(help)\n+                                .emit();\n                             // don't bother reporting every source of\n                             // conflict for a particular element of `last`.\n                             continue 'each_last;\n                         }\n                         IsInFollow::Yes => {}\n                         IsInFollow::No(possible) => {\n-                            let may_be = if last.tokens.len() == 1 &&\n-                                suffix_first.tokens.len() == 1\n+                            let may_be = if last.tokens.len() == 1 && suffix_first.tokens.len() == 1\n                             {\n                                 \"is\"\n                             } else {\n@@ -925,12 +943,14 @@ fn check_matcher_core(sess: &ParseSess,\n                             let sp = next_token.span();\n                             let mut err = sess.span_diagnostic.struct_span_err(\n                                 sp,\n-                                &format!(\"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n-                                          is not allowed for `{frag}` fragments\",\n-                                         name=name,\n-                                         frag=frag_spec,\n-                                         next=quoted_tt_to_string(next_token),\n-                                         may_be=may_be),\n+                                &format!(\n+                                    \"`${name}:{frag}` {may_be} followed by `{next}`, which \\\n+                                     is not allowed for `{frag}` fragments\",\n+                                    name = name,\n+                                    frag = frag_spec,\n+                                    next = quoted_tt_to_string(next_token),\n+                                    may_be = may_be\n+                                ),\n                             );\n                             err.span_label(\n                                 sp,\n@@ -942,16 +962,18 @@ fn check_matcher_core(sess: &ParseSess,\n                                 &[t] => {\n                                     err.note(&format!(\n                                         \"only {} is allowed after `{}` fragments\",\n-                                        t,\n-                                        frag_spec,\n+                                        t, frag_spec,\n                                     ));\n                                 }\n                                 ts => {\n                                     err.note(&format!(\n                                         \"{}{} or {}\",\n                                         msg,\n-                                        ts[..ts.len() - 1].iter().map(|s| *s)\n-                                            .collect::<Vec<_>>().join(\", \"),\n+                                        ts[..ts.len() - 1]\n+                                            .iter()\n+                                            .map(|s| *s)\n+                                            .collect::<Vec<_>>()\n+                                            .join(\", \"),\n                                         ts[ts.len() - 1],\n                                     ));\n                                 }\n@@ -1026,13 +1048,13 @@ fn is_in_follow(tok: &quoted::TokenTree, frag: &str) -> IsInFollow {\n                 // since items *must* be followed by either a `;` or a `}`, we can\n                 // accept anything after them\n                 IsInFollow::Yes\n-            },\n+            }\n             \"block\" => {\n                 // anything can follow block, the braces provide an easy boundary to\n                 // maintain\n                 IsInFollow::Yes\n-            },\n-            \"stmt\" | \"expr\"  => {\n+            }\n+            \"stmt\" | \"expr\" => {\n                 const TOKENS: &[&str] = &[\"`=>`\", \"`,`\", \"`;`\"];\n                 match tok {\n                     TokenTree::Token(token) => match token.kind {\n@@ -1041,7 +1063,7 @@ fn is_in_follow(tok: &quoted::TokenTree, frag: &str) -> IsInFollow {\n                     },\n                     _ => IsInFollow::No(TOKENS),\n                 }\n-            },\n+            }\n             \"pat\" => {\n                 const TOKENS: &[&str] = &[\"`=>`\", \"`,`\", \"`=`\", \"`|`\", \"`if`\", \"`in`\"];\n                 match tok {\n@@ -1052,71 +1074,88 @@ fn is_in_follow(tok: &quoted::TokenTree, frag: &str) -> IsInFollow {\n                     },\n                     _ => IsInFollow::No(TOKENS),\n                 }\n-            },\n+            }\n             \"path\" | \"ty\" => {\n                 const TOKENS: &[&str] = &[\n-                    \"`{`\", \"`[`\", \"`=>`\", \"`,`\", \"`>`\",\"`=`\", \"`:`\", \"`;`\", \"`|`\", \"`as`\",\n+                    \"`{`\", \"`[`\", \"`=>`\", \"`,`\", \"`>`\", \"`=`\", \"`:`\", \"`;`\", \"`|`\", \"`as`\",\n                     \"`where`\",\n                 ];\n                 match tok {\n                     TokenTree::Token(token) => match token.kind {\n-                        OpenDelim(token::DelimToken::Brace) |\n-                        OpenDelim(token::DelimToken::Bracket) |\n-                        Comma | FatArrow | Colon | Eq | Gt | BinOp(token::Shr) | Semi |\n-                        BinOp(token::Or) => IsInFollow::Yes,\n-                        Ident(name, false) if name == kw::As ||\n-                                              name == kw::Where => IsInFollow::Yes,\n+                        OpenDelim(token::DelimToken::Brace)\n+                        | OpenDelim(token::DelimToken::Bracket)\n+                        | Comma\n+                        | FatArrow\n+                        | Colon\n+                        | Eq\n+                        | Gt\n+                        | BinOp(token::Shr)\n+                        | Semi\n+                        | BinOp(token::Or) => IsInFollow::Yes,\n+                        Ident(name, false) if name == kw::As || name == kw::Where => {\n+                            IsInFollow::Yes\n+                        }\n                         _ => IsInFollow::No(TOKENS),\n                     },\n-                    TokenTree::MetaVarDecl(_, _, frag) if frag.name == sym::block =>\n-                        IsInFollow::Yes,\n+                    TokenTree::MetaVarDecl(_, _, frag) if frag.name == sym::block => {\n+                        IsInFollow::Yes\n+                    }\n                     _ => IsInFollow::No(TOKENS),\n                 }\n-            },\n+            }\n             \"ident\" | \"lifetime\" => {\n                 // being a single token, idents and lifetimes are harmless\n                 IsInFollow::Yes\n-            },\n+            }\n             \"literal\" => {\n                 // literals may be of a single token, or two tokens (negative numbers)\n                 IsInFollow::Yes\n-            },\n+            }\n             \"meta\" | \"tt\" => {\n                 // being either a single token or a delimited sequence, tt is\n                 // harmless\n                 IsInFollow::Yes\n-            },\n+            }\n             \"vis\" => {\n                 // Explicitly disallow `priv`, on the off chance it comes back.\n                 const TOKENS: &[&str] = &[\"`,`\", \"an ident\", \"a type\"];\n                 match tok {\n                     TokenTree::Token(token) => match token.kind {\n                         Comma => IsInFollow::Yes,\n                         Ident(name, is_raw) if is_raw || name != kw::Priv => IsInFollow::Yes,\n-                        _ => if token.can_begin_type() {\n-                            IsInFollow::Yes\n-                        } else {\n-                            IsInFollow::No(TOKENS)\n+                        _ => {\n+                            if token.can_begin_type() {\n+                                IsInFollow::Yes\n+                            } else {\n+                                IsInFollow::No(TOKENS)\n+                            }\n                         }\n                     },\n-                    TokenTree::MetaVarDecl(_, _, frag) if frag.name == sym::ident\n-                                                       || frag.name == sym::ty\n-                                                       || frag.name == sym::path =>\n-                        IsInFollow::Yes,\n+                    TokenTree::MetaVarDecl(_, _, frag)\n+                        if frag.name == sym::ident\n+                            || frag.name == sym::ty\n+                            || frag.name == sym::path =>\n+                    {\n+                        IsInFollow::Yes\n+                    }\n                     _ => IsInFollow::No(TOKENS),\n                 }\n-            },\n+            }\n             \"\" => IsInFollow::Yes, // kw::Invalid\n-            _ => IsInFollow::Invalid(format!(\"invalid fragment specifier `{}`\", frag),\n-                                     VALID_FRAGMENT_NAMES_MSG),\n+            _ => IsInFollow::Invalid(\n+                format!(\"invalid fragment specifier `{}`\", frag),\n+                VALID_FRAGMENT_NAMES_MSG,\n+            ),\n         }\n     }\n }\n \n-fn has_legal_fragment_specifier(sess: &ParseSess,\n-                                features: &Features,\n-                                attrs: &[ast::Attribute],\n-                                tok: &quoted::TokenTree) -> Result<(), String> {\n+fn has_legal_fragment_specifier(\n+    sess: &ParseSess,\n+    features: &Features,\n+    attrs: &[ast::Attribute],\n+    tok: &quoted::TokenTree,\n+) -> Result<(), String> {\n     debug!(\"has_legal_fragment_specifier({:?})\", tok);\n     if let quoted::TokenTree::MetaVarDecl(_, _, ref frag_spec) = *tok {\n         let frag_span = tok.span();\n@@ -1127,21 +1166,34 @@ fn has_legal_fragment_specifier(sess: &ParseSess,\n     Ok(())\n }\n \n-fn is_legal_fragment_specifier(_sess: &ParseSess,\n-                               _features: &Features,\n-                               _attrs: &[ast::Attribute],\n-                               frag_name: Symbol,\n-                               _frag_span: Span) -> bool {\n+fn is_legal_fragment_specifier(\n+    _sess: &ParseSess,\n+    _features: &Features,\n+    _attrs: &[ast::Attribute],\n+    frag_name: Symbol,\n+    _frag_span: Span,\n+) -> bool {\n     /*\n      * If new fragment specifiers are invented in nightly, `_sess`,\n      * `_features`, `_attrs`, and `_frag_span` will be useful here\n      * for checking against feature gates. See past versions of\n      * this function.\n      */\n     match frag_name {\n-        sym::item | sym::block | sym::stmt | sym::expr | sym::pat |\n-        sym::lifetime | sym::path | sym::ty | sym::ident | sym::meta | sym::tt |\n-        sym::vis | sym::literal | kw::Invalid => true,\n+        sym::item\n+        | sym::block\n+        | sym::stmt\n+        | sym::expr\n+        | sym::pat\n+        | sym::lifetime\n+        | sym::path\n+        | sym::ty\n+        | sym::ident\n+        | sym::meta\n+        | sym::tt\n+        | sym::vis\n+        | sym::literal\n+        | kw::Invalid => true,\n         _ => false,\n     }\n }\n@@ -1151,7 +1203,9 @@ fn quoted_tt_to_string(tt: &quoted::TokenTree) -> String {\n         quoted::TokenTree::Token(ref token) => crate::print::pprust::token_to_string(&token),\n         quoted::TokenTree::MetaVar(_, name) => format!(\"${}\", name),\n         quoted::TokenTree::MetaVarDecl(_, name, kind) => format!(\"${}:{}\", name, kind),\n-        _ => panic!(\"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n-                     in follow set checker\"),\n+        _ => panic!(\n+            \"unexpected quoted::TokenTree::{{Sequence or Delimited}} \\\n+             in follow set checker\"\n+        ),\n     }\n }"}, {"sha": "6f5ce89bc315af8f88c5d67fc1a09378dfbacd36", "filename": "src/libsyntax/ext/tt/quoted.rs", "status": "modified", "additions": 13, "deletions": 29, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fquoted.rs?ref=0aeab41e5a814c96c6a6d7a7e6f7ff3f8e741648", "patch": "@@ -1,12 +1,12 @@\n+use crate::ast;\n use crate::ast::NodeId;\n use crate::ext::tt::macro_parser;\n use crate::feature_gate::Features;\n use crate::parse::token::{self, Token, TokenKind};\n use crate::parse::ParseSess;\n use crate::print::pprust;\n-use crate::tokenstream::{self, DelimSpan};\n-use crate::ast;\n use crate::symbol::kw;\n+use crate::tokenstream::{self, DelimSpan};\n \n use syntax_pos::{edition::Edition, BytePos, Span};\n \n@@ -137,8 +137,7 @@ impl TokenTree {\n             TokenTree::Token(Token { span, .. })\n             | TokenTree::MetaVar(span, _)\n             | TokenTree::MetaVarDecl(span, _, _) => span,\n-            TokenTree::Delimited(span, _)\n-            | TokenTree::Sequence(span, _) => span.entire(),\n+            TokenTree::Delimited(span, _) | TokenTree::Sequence(span, _) => span.entire(),\n         }\n     }\n \n@@ -199,7 +198,7 @@ pub fn parse(\n         match tree {\n             TokenTree::MetaVar(start_sp, ident) if expect_matchers => {\n                 let span = match trees.next() {\n-                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span })) =>\n+                    Some(tokenstream::TokenTree::Token(Token { kind: token::Colon, span })) => {\n                         match trees.next() {\n                             Some(tokenstream::TokenTree::Token(token)) => match token.ident() {\n                                 Some((kind, _)) => {\n@@ -209,22 +208,13 @@ pub fn parse(\n                                 }\n                                 _ => token.span,\n                             },\n-                            tree => tree\n-                                .as_ref()\n-                                .map(tokenstream::TokenTree::span)\n-                                .unwrap_or(span),\n-                        },\n-                    tree => tree\n-                        .as_ref()\n-                        .map(tokenstream::TokenTree::span)\n-                        .unwrap_or(start_sp),\n+                            tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span),\n+                        }\n+                    }\n+                    tree => tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(start_sp),\n                 };\n                 sess.missing_fragment_specifiers.borrow_mut().insert(span);\n-                result.push(TokenTree::MetaVarDecl(\n-                    span,\n-                    ident,\n-                    ast::Ident::invalid(),\n-                ));\n+                result.push(TokenTree::MetaVarDecl(span, ident, ast::Ident::invalid()));\n             }\n \n             // Not a metavar or no matchers allowed, so just return the tree\n@@ -311,10 +301,8 @@ fn parse_tree(\n \n             // `tree` is followed by a random token. This is an error.\n             Some(tokenstream::TokenTree::Token(token)) => {\n-                let msg = format!(\n-                    \"expected identifier, found `{}`\",\n-                    pprust::token_to_string(&token),\n-                );\n+                let msg =\n+                    format!(\"expected identifier, found `{}`\", pprust::token_to_string(&token),);\n                 sess.span_diagnostic.span_err(token.span, &msg);\n                 TokenTree::MetaVar(token.span, ast::Ident::invalid())\n             }\n@@ -371,10 +359,7 @@ fn parse_kleene_op(\n             Some(op) => Ok(Ok((op, token.span))),\n             None => Ok(Err(token)),\n         },\n-        tree => Err(tree\n-            .as_ref()\n-            .map(tokenstream::TokenTree::span)\n-            .unwrap_or(span)),\n+        tree => Err(tree.as_ref().map(tokenstream::TokenTree::span).unwrap_or(span)),\n     }\n }\n \n@@ -426,8 +411,7 @@ fn parse_sep_and_kleene_op(\n     };\n \n     // If we ever get to this point, we have experienced an \"unexpected token\" error\n-    sess.span_diagnostic\n-        .span_err(span, \"expected one of: `*`, `+`, or `?`\");\n+    sess.span_diagnostic.span_err(span, \"expected one of: `*`, `+`, or `?`\");\n \n     // Return a dummy\n     (None, KleeneOp::ZeroOrMore)"}]}