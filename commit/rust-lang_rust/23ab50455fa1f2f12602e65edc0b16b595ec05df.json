{"sha": "23ab50455fa1f2f12602e65edc0b16b595ec05df", "node_id": "MDY6Q29tbWl0NzI0NzEyOjIzYWI1MDQ1NWZhMWYyZjEyNjAyZTY1ZWRjMGIxNmI1OTVlYzA1ZGY=", "commit": {"author": {"name": "Felix S. Klock II", "email": "pnkfelix@pnkfx.org", "date": "2017-05-24T16:06:11Z"}, "committer": {"name": "Felix S. Klock II", "email": "pnkfelix@pnkfx.org", "date": "2017-06-15T21:48:30Z"}, "message": "Allocator integration in `RawVec`.\n\nIncludes methods exposing underlying allocator and the dellocation\nroutine.\n\nIncludes test illustrating a tiny `Alloc` that just bounds the total\nbytes allocated.\n\nAlpha-renamed `Allocator` to `Alloc` (and `HeapAllocator` to `HeapAlloc`).", "tree": {"sha": "373e848cf6dfc5fe5e818a47c1256e28ba49a28d", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/373e848cf6dfc5fe5e818a47c1256e28ba49a28d"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/23ab50455fa1f2f12602e65edc0b16b595ec05df", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/23ab50455fa1f2f12602e65edc0b16b595ec05df", "html_url": "https://github.com/rust-lang/rust/commit/23ab50455fa1f2f12602e65edc0b16b595ec05df", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/23ab50455fa1f2f12602e65edc0b16b595ec05df/comments", "author": {"login": "pnkfelix", "id": 173127, "node_id": "MDQ6VXNlcjE3MzEyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/173127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pnkfelix", "html_url": "https://github.com/pnkfelix", "followers_url": "https://api.github.com/users/pnkfelix/followers", "following_url": "https://api.github.com/users/pnkfelix/following{/other_user}", "gists_url": "https://api.github.com/users/pnkfelix/gists{/gist_id}", "starred_url": "https://api.github.com/users/pnkfelix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pnkfelix/subscriptions", "organizations_url": "https://api.github.com/users/pnkfelix/orgs", "repos_url": "https://api.github.com/users/pnkfelix/repos", "events_url": "https://api.github.com/users/pnkfelix/events{/privacy}", "received_events_url": "https://api.github.com/users/pnkfelix/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pnkfelix", "id": 173127, "node_id": "MDQ6VXNlcjE3MzEyNw==", "avatar_url": "https://avatars.githubusercontent.com/u/173127?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pnkfelix", "html_url": "https://github.com/pnkfelix", "followers_url": "https://api.github.com/users/pnkfelix/followers", "following_url": "https://api.github.com/users/pnkfelix/following{/other_user}", "gists_url": "https://api.github.com/users/pnkfelix/gists{/gist_id}", "starred_url": "https://api.github.com/users/pnkfelix/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pnkfelix/subscriptions", "organizations_url": "https://api.github.com/users/pnkfelix/orgs", "repos_url": "https://api.github.com/users/pnkfelix/repos", "events_url": "https://api.github.com/users/pnkfelix/events{/privacy}", "received_events_url": "https://api.github.com/users/pnkfelix/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "65d02b26c525c07d47686302a15231b28914fda4", "url": "https://api.github.com/repos/rust-lang/rust/commits/65d02b26c525c07d47686302a15231b28914fda4", "html_url": "https://github.com/rust-lang/rust/commit/65d02b26c525c07d47686302a15231b28914fda4"}], "stats": {"total": 337, "additions": 220, "deletions": 117}, "files": [{"sha": "7117c4468211e8ddbce2eef799d06930323e8e68", "filename": "src/liballoc/raw_vec.rs", "status": "modified", "additions": 220, "deletions": 117, "changes": 337, "blob_url": "https://github.com/rust-lang/rust/blob/23ab50455fa1f2f12602e65edc0b16b595ec05df/src%2Fliballoc%2Fraw_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/23ab50455fa1f2f12602e65edc0b16b595ec05df/src%2Fliballoc%2Fraw_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec.rs?ref=23ab50455fa1f2f12602e65edc0b16b595ec05df", "patch": "@@ -8,11 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-use core::ptr::Unique;\n+use allocator::{Alloc, Layout};\n+use core::ptr::{self, Unique};\n use core::mem;\n use core::slice;\n-use heap;\n-use super::oom;\n+use heap::{HeapAlloc};\n use super::boxed::Box;\n use core::ops::Drop;\n use core::cmp;\n@@ -45,53 +45,42 @@ use core::cmp;\n /// field. This allows zero-sized types to not be special-cased by consumers of\n /// this type.\n #[allow(missing_debug_implementations)]\n-pub struct RawVec<T> {\n+pub struct RawVec<T, A: Alloc = HeapAlloc> {\n     ptr: Unique<T>,\n     cap: usize,\n+    a: A,\n }\n \n-impl<T> RawVec<T> {\n-    /// Creates the biggest possible RawVec without allocating. If T has positive\n-    /// size, then this makes a RawVec with capacity 0. If T has 0 size, then it\n-    /// it makes a RawVec with capacity `usize::MAX`. Useful for implementing\n-    /// delayed allocation.\n-    pub fn new() -> Self {\n+impl<T, A: Alloc> RawVec<T, A> {\n+    /// Like `new` but parameterized over the choice of allocator for\n+    /// the returned RawVec.\n+    pub fn new_in(a: A) -> Self {\n         // !0 is usize::MAX. This branch should be stripped at compile time.\n         let cap = if mem::size_of::<T>() == 0 { !0 } else { 0 };\n \n         // Unique::empty() doubles as \"unallocated\" and \"zero-sized allocation\"\n         RawVec {\n             ptr: Unique::empty(),\n             cap: cap,\n+            a: a,\n         }\n     }\n \n-    /// Creates a RawVec with exactly the capacity and alignment requirements\n-    /// for a `[T; cap]`. This is equivalent to calling RawVec::new when `cap` is 0\n-    /// or T is zero-sized. Note that if `T` is zero-sized this means you will *not*\n-    /// get a RawVec with the requested capacity!\n-    ///\n-    /// # Panics\n-    ///\n-    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n-    /// * Panics on 32-bit platforms if the requested capacity exceeds\n-    ///   `isize::MAX` bytes.\n-    ///\n-    /// # Aborts\n-    ///\n-    /// Aborts on OOM\n+    /// Like `with_capacity` but parameterized over the choice of\n+    /// allocator for the returned RawVec.\n     #[inline]\n-    pub fn with_capacity(cap: usize) -> Self {\n-        RawVec::allocate(cap, false)\n+    pub fn with_capacity_in(cap: usize, a: A) -> Self {\n+        RawVec::allocate_in(cap, false, a)\n     }\n \n-    /// Like `with_capacity` but guarantees the buffer is zeroed.\n+    /// Like `with_capacity_zeroed` but parameterized over the choice\n+    /// of allocator for the returned RawVec.\n     #[inline]\n-    pub fn with_capacity_zeroed(cap: usize) -> Self {\n-        RawVec::allocate(cap, true)\n+    pub fn with_capacity_zeroed_in(cap: usize, a: A) -> Self {\n+        RawVec::allocate_in(cap, true, a)\n     }\n \n-    fn allocate(cap: usize, zeroed: bool) -> Self {\n+    fn allocate_in(cap: usize, zeroed: bool, mut a: A) -> Self {\n         unsafe {\n             let elem_size = mem::size_of::<T>();\n \n@@ -103,35 +92,93 @@ impl<T> RawVec<T> {\n                 mem::align_of::<T>() as *mut u8\n             } else {\n                 let align = mem::align_of::<T>();\n-                let ptr = if zeroed {\n-                    heap::allocate_zeroed(alloc_size, align)\n+                let result = if zeroed {\n+                    a.alloc_zeroed(Layout::from_size_align(alloc_size, align).unwrap())\n                 } else {\n-                    heap::allocate(alloc_size, align)\n+                    a.alloc(Layout::from_size_align(alloc_size, align).unwrap())\n                 };\n-                if ptr.is_null() {\n-                    oom()\n+                match result {\n+                    Ok(ptr) => ptr,\n+                    Err(err) => a.oom(err),\n                 }\n-                ptr\n             };\n \n             RawVec {\n                 ptr: Unique::new(ptr as *mut _),\n                 cap: cap,\n+                a: a,\n             }\n         }\n     }\n+}\n+\n+impl<T> RawVec<T, HeapAlloc> {\n+    /// Creates the biggest possible RawVec (on the system heap)\n+    /// without allocating. If T has positive size, then this makes a\n+    /// RawVec with capacity 0. If T has 0 size, then it it makes a\n+    /// RawVec with capacity `usize::MAX`. Useful for implementing\n+    /// delayed allocation.\n+    pub fn new() -> Self {\n+        Self::new_in(HeapAlloc)\n+    }\n+\n+    /// Creates a RawVec (on the system heap) with exactly the\n+    /// capacity and alignment requirements for a `[T; cap]`. This is\n+    /// equivalent to calling RawVec::new when `cap` is 0 or T is\n+    /// zero-sized. Note that if `T` is zero-sized this means you will\n+    /// *not* get a RawVec with the requested capacity!\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    ///\n+    /// # Aborts\n+    ///\n+    /// Aborts on OOM\n+    #[inline]\n+    pub fn with_capacity(cap: usize) -> Self {\n+        RawVec::allocate_in(cap, false, HeapAlloc)\n+    }\n+\n+    /// Like `with_capacity` but guarantees the buffer is zeroed.\n+    #[inline]\n+    pub fn with_capacity_zeroed(cap: usize) -> Self {\n+        RawVec::allocate_in(cap, true, HeapAlloc)\n+    }\n+}\n+\n+impl<T, A: Alloc> RawVec<T, A> {\n+    /// Reconstitutes a RawVec from a pointer, capacity, and allocator.\n+    ///\n+    /// # Undefined Behavior\n+    ///\n+    /// The ptr must be allocated (via the given allocator `a`), and with the given capacity. The\n+    /// capacity cannot exceed `isize::MAX` (only a concern on 32-bit systems).\n+    /// If the ptr and capacity come from a RawVec created via `a`, then this is guaranteed.\n+    pub unsafe fn from_raw_parts_in(ptr: *mut T, cap: usize, a: A) -> Self {\n+        RawVec {\n+            ptr: Unique::new(ptr),\n+            cap: cap,\n+            a: a,\n+        }\n+    }\n+}\n \n-    /// Reconstitutes a RawVec from a pointer and capacity.\n+impl<T> RawVec<T, HeapAlloc> {\n+    /// Reconstitutes a RawVec from a pointer, capacity.\n     ///\n     /// # Undefined Behavior\n     ///\n-    /// The ptr must be allocated, and with the given capacity. The\n+    /// The ptr must be allocated (on the system heap), and with the given capacity. The\n     /// capacity cannot exceed `isize::MAX` (only a concern on 32-bit systems).\n     /// If the ptr and capacity come from a RawVec, then this is guaranteed.\n     pub unsafe fn from_raw_parts(ptr: *mut T, cap: usize) -> Self {\n         RawVec {\n             ptr: Unique::new(ptr),\n             cap: cap,\n+            a: HeapAlloc,\n         }\n     }\n \n@@ -145,7 +192,7 @@ impl<T> RawVec<T> {\n     }\n }\n \n-impl<T> RawVec<T> {\n+impl<T, A: Alloc> RawVec<T, A> {\n     /// Gets a raw pointer to the start of the allocation. Note that this is\n     /// Unique::empty() if `cap = 0` or T is zero-sized. In the former case, you must\n     /// be careful.\n@@ -165,6 +212,16 @@ impl<T> RawVec<T> {\n         }\n     }\n \n+    /// Returns a shared reference to the allocator backing this RawVec.\n+    pub fn alloc(&self) -> &A {\n+        &self.a\n+    }\n+\n+    /// Returns a mutable reference to the allocator backing this RawVec.\n+    pub fn alloc_mut(&mut self) -> &mut A {\n+        &mut self.a\n+    }\n+\n     /// Doubles the size of the type's backing allocation. This is common enough\n     /// to want to do that it's easiest to just have a dedicated method. Slightly\n     /// more efficient logic can be provided for this than the general case.\n@@ -215,32 +272,28 @@ impl<T> RawVec<T> {\n             // 0, getting to here necessarily means the RawVec is overfull.\n             assert!(elem_size != 0, \"capacity overflow\");\n \n-            let align = mem::align_of::<T>();\n-\n-            let (new_cap, ptr) = if self.cap == 0 {\n+            let (new_cap, ptr_res) = if self.cap == 0 {\n                 // skip to 4 because tiny Vec's are dumb; but not if that would cause overflow\n                 let new_cap = if elem_size > (!0) / 8 { 1 } else { 4 };\n-                let ptr = heap::allocate(new_cap * elem_size, align);\n-                (new_cap, ptr)\n+                let ptr_res = self.a.alloc_array::<T>(new_cap);\n+                (new_cap, ptr_res)\n             } else {\n                 // Since we guarantee that we never allocate more than isize::MAX bytes,\n                 // `elem_size * self.cap <= isize::MAX` as a precondition, so this can't overflow\n                 let new_cap = 2 * self.cap;\n                 let new_alloc_size = new_cap * elem_size;\n                 alloc_guard(new_alloc_size);\n-                let ptr = heap::reallocate(self.ptr() as *mut _,\n-                                           self.cap * elem_size,\n-                                           new_alloc_size,\n-                                           align);\n-                (new_cap, ptr)\n+                let ptr_res = self.a.realloc_array(self.ptr, self.cap, new_cap);\n+                (new_cap, ptr_res)\n             };\n \n             // If allocate or reallocate fail, we'll get `null` back\n-            if ptr.is_null() {\n-                oom()\n-            }\n+            let uniq = match ptr_res {\n+                Err(err) => self.a.oom(err),\n+                Ok(uniq) => uniq,\n+            };\n \n-            self.ptr = Unique::new(ptr as *mut _);\n+            self.ptr = uniq;\n             self.cap = new_cap;\n         }\n     }\n@@ -262,7 +315,6 @@ impl<T> RawVec<T> {\n     pub fn double_in_place(&mut self) -> bool {\n         unsafe {\n             let elem_size = mem::size_of::<T>();\n-            let align = mem::align_of::<T>();\n \n             // since we set the capacity to usize::MAX when elem_size is\n             // 0, getting to here necessarily means the RawVec is overfull.\n@@ -274,15 +326,20 @@ impl<T> RawVec<T> {\n             let new_alloc_size = new_cap * elem_size;\n \n             alloc_guard(new_alloc_size);\n-            let size = heap::reallocate_inplace(self.ptr() as *mut _,\n-                                                self.cap * elem_size,\n-                                                new_alloc_size,\n-                                                align);\n-            if size >= new_alloc_size {\n-                // We can't directly divide `size`.\n-                self.cap = new_cap;\n+\n+            let ptr = self.ptr() as *mut _;\n+            let old_layout = Layout::new::<T>().repeat(self.cap).unwrap().0;\n+            let new_layout = Layout::new::<T>().repeat(new_cap).unwrap().0;\n+            match self.a.grow_in_place(ptr, old_layout, new_layout) {\n+                Ok(_) => {\n+                    // We can't directly divide `size`.\n+                    self.cap = new_cap;\n+                    true\n+                }\n+                Err(_) => {\n+                    false\n+                }\n             }\n-            size >= new_alloc_size\n         }\n     }\n \n@@ -309,7 +366,6 @@ impl<T> RawVec<T> {\n     pub fn reserve_exact(&mut self, used_cap: usize, needed_extra_cap: usize) {\n         unsafe {\n             let elem_size = mem::size_of::<T>();\n-            let align = mem::align_of::<T>();\n \n             // NOTE: we don't early branch on ZSTs here because we want this\n             // to actually catch \"asking for more than usize::MAX\" in that case.\n@@ -327,21 +383,19 @@ impl<T> RawVec<T> {\n             let new_alloc_size = new_cap.checked_mul(elem_size).expect(\"capacity overflow\");\n             alloc_guard(new_alloc_size);\n \n-            let ptr = if self.cap == 0 {\n-                heap::allocate(new_alloc_size, align)\n+            let result = if self.cap == 0 {\n+                self.a.alloc_array::<T>(new_cap)\n             } else {\n-                heap::reallocate(self.ptr() as *mut _,\n-                                 self.cap * elem_size,\n-                                 new_alloc_size,\n-                                 align)\n+                self.a.realloc_array(self.ptr, self.cap, new_cap)\n             };\n \n             // If allocate or reallocate fail, we'll get `null` back\n-            if ptr.is_null() {\n-                oom()\n-            }\n+            let uniq = match result {\n+                Err(err) => self.a.oom(err),\n+                Ok(uniq) => uniq,\n+            };\n \n-            self.ptr = Unique::new(ptr as *mut _);\n+            self.ptr = uniq;\n             self.cap = new_cap;\n         }\n     }\n@@ -408,9 +462,6 @@ impl<T> RawVec<T> {\n     /// ```\n     pub fn reserve(&mut self, used_cap: usize, needed_extra_cap: usize) {\n         unsafe {\n-            let elem_size = mem::size_of::<T>();\n-            let align = mem::align_of::<T>();\n-\n             // NOTE: we don't early branch on ZSTs here because we want this\n             // to actually catch \"asking for more than usize::MAX\" in that case.\n             // If we make it past the first branch then we are guaranteed to\n@@ -426,21 +477,18 @@ impl<T> RawVec<T> {\n             // FIXME: may crash and burn on over-reserve\n             alloc_guard(new_alloc_size);\n \n-            let ptr = if self.cap == 0 {\n-                heap::allocate(new_alloc_size, align)\n+            let result = if self.cap == 0 {\n+                self.a.alloc_array::<T>(new_cap)\n             } else {\n-                heap::reallocate(self.ptr() as *mut _,\n-                                 self.cap * elem_size,\n-                                 new_alloc_size,\n-                                 align)\n+                self.a.realloc_array(self.ptr, self.cap, new_cap)\n             };\n \n-            // If allocate or reallocate fail, we'll get `null` back\n-            if ptr.is_null() {\n-                oom()\n-            }\n+            let uniq = match result {\n+                Err(err) => self.a.oom(err),\n+                Ok(uniq) => uniq,\n+            };\n \n-            self.ptr = Unique::new(ptr as *mut _);\n+            self.ptr = uniq;\n             self.cap = new_cap;\n         }\n     }\n@@ -464,9 +512,6 @@ impl<T> RawVec<T> {\n     ///   `isize::MAX` bytes.\n     pub fn reserve_in_place(&mut self, used_cap: usize, needed_extra_cap: usize) -> bool {\n         unsafe {\n-            let elem_size = mem::size_of::<T>();\n-            let align = mem::align_of::<T>();\n-\n             // NOTE: we don't early branch on ZSTs here because we want this\n             // to actually catch \"asking for more than usize::MAX\" in that case.\n             // If we make it past the first branch then we are guaranteed to\n@@ -479,18 +524,26 @@ impl<T> RawVec<T> {\n                 return false;\n             }\n \n-            let (_, new_alloc_size) = self.amortized_new_size(used_cap, needed_extra_cap);\n+            let (new_cap, new_alloc_size) = self.amortized_new_size(used_cap, needed_extra_cap);\n             // FIXME: may crash and burn on over-reserve\n             alloc_guard(new_alloc_size);\n \n-            let size = heap::reallocate_inplace(self.ptr() as *mut _,\n-                                                self.cap * elem_size,\n-                                                new_alloc_size,\n-                                                align);\n-            if size >= new_alloc_size {\n-                self.cap = new_alloc_size / elem_size;\n+            // Here, `cap < used_cap + needed_extra_cap <= new_cap`\n+            // (regardless of whether `self.cap - used_cap` wrapped).\n+            // Therefore we can safely call grow_in_place.\n+\n+            let ptr = self.ptr() as *mut _;\n+            let old_layout = Layout::new::<T>().repeat(self.cap).unwrap().0;\n+            let new_layout = Layout::new::<T>().repeat(new_cap).unwrap().0;\n+            match self.a.grow_in_place(ptr, old_layout, new_layout) {\n+                Ok(_) => {\n+                    self.cap = new_cap;\n+                    true\n+                }\n+                Err(_) => {\n+                    false\n+                }\n             }\n-            size >= new_alloc_size\n         }\n     }\n \n@@ -506,7 +559,6 @@ impl<T> RawVec<T> {\n     /// Aborts on OOM.\n     pub fn shrink_to_fit(&mut self, amount: usize) {\n         let elem_size = mem::size_of::<T>();\n-        let align = mem::align_of::<T>();\n \n         // Set the `cap` because they might be about to promote to a `Box<[T]>`\n         if elem_size == 0 {\n@@ -518,24 +570,30 @@ impl<T> RawVec<T> {\n         assert!(self.cap >= amount, \"Tried to shrink to a larger capacity\");\n \n         if amount == 0 {\n-            mem::replace(self, RawVec::new());\n+            // We want to create a new zero-length vector within the\n+            // same allocator.  We use ptr::write to avoid an\n+            // erroneous attempt to drop the contents, and we use\n+            // ptr::read to sidestep condition against destructuring\n+            // types that implement Drop.\n+\n+            unsafe {\n+                let a = ptr::read(&self.a as *const A);\n+                self.dealloc_buffer();\n+                ptr::write(self, RawVec::new_in(a));\n+            }\n         } else if self.cap != amount {\n             unsafe {\n-                // Overflow check is unnecessary as the vector is already at\n-                // least this large.\n-                let ptr = heap::reallocate(self.ptr() as *mut _,\n-                                           self.cap * elem_size,\n-                                           amount * elem_size,\n-                                           align);\n-                if ptr.is_null() {\n-                    oom()\n+                match self.a.realloc_array(self.ptr, self.cap, amount) {\n+                    Err(err) => self.a.oom(err),\n+                    Ok(uniq) => self.ptr = uniq,\n                 }\n-                self.ptr = Unique::new(ptr as *mut _);\n             }\n             self.cap = amount;\n         }\n     }\n+}\n \n+impl<T> RawVec<T, HeapAlloc> {\n     /// Converts the entire buffer into `Box<[T]>`.\n     ///\n     /// While it is not *strictly* Undefined Behavior to call\n@@ -553,21 +611,25 @@ impl<T> RawVec<T> {\n     }\n }\n \n-unsafe impl<#[may_dangle] T> Drop for RawVec<T> {\n+impl<T, A: Alloc> RawVec<T, A> {\n     /// Frees the memory owned by the RawVec *without* trying to Drop its contents.\n-    fn drop(&mut self) {\n+    pub unsafe fn dealloc_buffer(&mut self) {\n         let elem_size = mem::size_of::<T>();\n         if elem_size != 0 && self.cap != 0 {\n-            let align = mem::align_of::<T>();\n-\n-            let num_bytes = elem_size * self.cap;\n-            unsafe {\n-                heap::deallocate(self.ptr() as *mut u8, num_bytes, align);\n-            }\n+            let ptr = self.ptr() as *mut u8;\n+            let layout = Layout::new::<T>().repeat(self.cap).unwrap().0;\n+            self.a.dealloc(ptr, layout);\n         }\n     }\n }\n \n+unsafe impl<#[may_dangle] T, A: Alloc> Drop for RawVec<T, A> {\n+    /// Frees the memory owned by the RawVec *without* trying to Drop its contents.\n+    fn drop(&mut self) {\n+        unsafe { self.dealloc_buffer(); }\n+    }\n+}\n+\n \n \n // We need to guarantee the following:\n@@ -592,6 +654,46 @@ fn alloc_guard(alloc_size: usize) {\n mod tests {\n     use super::*;\n \n+    #[test]\n+    fn allocator_param() {\n+        use allocator::{Alloc, AllocErr};\n+\n+        // Writing a test of integration between third-party\n+        // allocators and RawVec is a little tricky because the RawVec\n+        // API does not expose fallible allocation methods, so we\n+        // cannot check what happens when allocator is exhausted\n+        // (beyond detecting a panic).\n+        //\n+        // Instead, this just checks that the RawVec methods do at\n+        // least go through the Allocator API when it reserves\n+        // storage.\n+\n+        // A dumb allocator that consumes a fixed amount of fuel\n+        // before allocation attempts start failing.\n+        struct BoundedAlloc { fuel: usize }\n+        unsafe impl Alloc for BoundedAlloc {\n+            unsafe fn alloc(&mut self, layout: Layout) -> Result<*mut u8, AllocErr> {\n+                let size = layout.size();\n+                if size > self.fuel {\n+                    return Err(AllocErr::Unsupported { details: \"fuel exhausted\" });\n+                }\n+                match HeapAlloc.alloc(layout) {\n+                    ok @ Ok(_) => { self.fuel -= size; ok }\n+                    err @ Err(_) => err,\n+                }\n+            }\n+            unsafe fn dealloc(&mut self, ptr: *mut u8, layout: Layout) {\n+                HeapAlloc.dealloc(ptr, layout)\n+            }\n+        }\n+\n+        let a = BoundedAlloc { fuel: 500 };\n+        let mut v: RawVec<u8, _> = RawVec::with_capacity_in(50, a);\n+        assert_eq!(v.a.fuel, 450);\n+        v.reserve(50, 150); // (causes a realloc, thus using 50 + 150 = 200 units of fuel)\n+        assert_eq!(v.a.fuel, 250);\n+    }\n+\n     #[test]\n     fn reserve_does_not_overallocate() {\n         {\n@@ -624,4 +726,5 @@ mod tests {\n         }\n     }\n \n+\n }"}]}