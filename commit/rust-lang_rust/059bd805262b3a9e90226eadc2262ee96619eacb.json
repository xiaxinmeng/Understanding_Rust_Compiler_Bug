{"sha": "059bd805262b3a9e90226eadc2262ee96619eacb", "node_id": "MDY6Q29tbWl0NzI0NzEyOjA1OWJkODA1MjYyYjNhOWU5MDIyNmVhZGMyMjYyZWU5NjYxOWVhY2I=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2017-11-28T15:58:02Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo", "date": "2017-12-01T12:48:59Z"}, "message": "incr.comp.: Load diagnostics from previous session lazily and clean up on-disk-cache persistence code.", "tree": {"sha": "5427a0eab289d24df6488ec0af51bef50cf292ce", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/5427a0eab289d24df6488ec0af51bef50cf292ce"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/059bd805262b3a9e90226eadc2262ee96619eacb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/059bd805262b3a9e90226eadc2262ee96619eacb", "html_url": "https://github.com/rust-lang/rust/commit/059bd805262b3a9e90226eadc2262ee96619eacb", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/059bd805262b3a9e90226eadc2262ee96619eacb/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "64e109327dfd96cb8902b994b0a1e7f2d32215b0", "url": "https://api.github.com/repos/rust-lang/rust/commits/64e109327dfd96cb8902b994b0a1e7f2d32215b0", "html_url": "https://github.com/rust-lang/rust/commit/64e109327dfd96cb8902b994b0a1e7f2d32215b0"}], "stats": {"total": 294, "additions": 159, "deletions": 135}, "files": [{"sha": "e8e284236c846574e54ecb6522005fef7cc8d70b", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=059bd805262b3a9e90226eadc2262ee96619eacb", "patch": "@@ -461,10 +461,10 @@ impl DepGraph {\n         self.data.as_ref().and_then(|data| data.colors.borrow().get(dep_node).cloned())\n     }\n \n-    pub fn try_mark_green(&self,\n-                          tcx: TyCtxt,\n-                          dep_node: &DepNode)\n-                          -> Option<DepNodeIndex> {\n+    pub fn try_mark_green<'a, 'tcx>(&self,\n+                                    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                    dep_node: &DepNode)\n+                                    -> Option<DepNodeIndex> {\n         debug!(\"try_mark_green({:?}) - BEGIN\", dep_node);\n         let data = self.data.as_ref().unwrap();\n \n@@ -621,7 +621,7 @@ impl DepGraph {\n         // ... emitting any stored diagnostic ...\n         {\n             let diagnostics = tcx.on_disk_query_result_cache\n-                                 .load_diagnostics(prev_dep_node_index);\n+                                 .load_diagnostics(tcx, prev_dep_node_index);\n \n             if diagnostics.len() > 0 {\n                 let handle = tcx.sess.diagnostic();"}, {"sha": "0ab769d4fe307bbbdab59614408cd8c974b8e3c7", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=059bd805262b3a9e90226eadc2262ee96619eacb", "patch": "@@ -1235,7 +1235,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                                            -> Result<(), E::Error>\n         where E: ty::codec::TyEncoder\n     {\n-        self.on_disk_query_result_cache.serialize(self.global_tcx(), self.cstore, encoder)\n+        self.on_disk_query_result_cache.serialize(self.global_tcx(), encoder)\n     }\n \n }"}, {"sha": "0d09692bc353000e70a75f19b00baf277841912f", "filename": "src/librustc/ty/maps/on_disk_cache.rs", "status": "modified", "additions": 148, "deletions": 128, "changes": 276, "blob_url": "https://github.com/rust-lang/rust/blob/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fon_disk_cache.rs?ref=059bd805262b3a9e90226eadc2262ee96619eacb", "patch": "@@ -34,10 +34,7 @@ use ty;\n use ty::codec::{self as ty_codec, TyDecoder, TyEncoder};\n use ty::context::TyCtxt;\n \n-// Some magic values used for verifying that encoding and decoding. These are\n-// basically random numbers.\n-const PREV_DIAGNOSTICS_TAG: u64 = 0x1234_5678_A1A1_A1A1;\n-const QUERY_RESULT_INDEX_TAG: u64 = 0x1234_5678_C3C3_C3C3;\n+const TAG_FILE_FOOTER: u128 = 0xC0FFEE_C0FFEE_C0FFEE_C0FFEE_C0FFEE;\n \n const TAG_CLEAR_CROSS_CRATE_CLEAR: u8 = 0;\n const TAG_CLEAR_CROSS_CRATE_SET: u8 = 1;\n@@ -58,9 +55,6 @@ pub struct OnDiskCache<'sess> {\n     // The complete cache data in serialized form.\n     serialized_data: Vec<u8>,\n \n-    // The diagnostics emitted during the previous compilation session.\n-    prev_diagnostics: FxHashMap<SerializedDepNodeIndex, Vec<Diagnostic>>,\n-\n     // This field collects all Diagnostics emitted during the current\n     // compilation session.\n     current_diagnostics: RefCell<FxHashMap<DepNodeIndex, Vec<Diagnostic>>>,\n@@ -78,17 +72,24 @@ pub struct OnDiskCache<'sess> {\n     // A map from dep-node to the position of the cached query result in\n     // `serialized_data`.\n     query_result_index: FxHashMap<SerializedDepNodeIndex, AbsoluteBytePos>,\n+\n+    // A map from dep-node to the position of any associated diagnostics in\n+    // `serialized_data`.\n+    prev_diagnostics_index: FxHashMap<SerializedDepNodeIndex, AbsoluteBytePos>,\n }\n \n // This type is used only for (de-)serialization.\n #[derive(RustcEncodable, RustcDecodable)]\n-struct Header {\n+struct Footer {\n     file_index_to_stable_id: FxHashMap<FileMapIndex, StableFilemapId>,\n     prev_cnums: Vec<(u32, String, CrateDisambiguator)>,\n+    query_result_index: EncodedQueryResultIndex,\n+    diagnostics_index: EncodedQueryResultIndex,\n }\n \n-type EncodedPrevDiagnostics = Vec<(SerializedDepNodeIndex, Vec<Diagnostic>)>;\n type EncodedQueryResultIndex = Vec<(SerializedDepNodeIndex, AbsoluteBytePos)>;\n+type EncodedDiagnosticsIndex = Vec<(SerializedDepNodeIndex, AbsoluteBytePos)>;\n+type EncodedDiagnostics = Vec<Diagnostic>;\n \n #[derive(Copy, Clone, PartialEq, Eq, Hash, Debug, RustcEncodable, RustcDecodable)]\n struct FileMapIndex(u32);\n@@ -112,87 +113,54 @@ impl<'sess> OnDiskCache<'sess> {\n     pub fn new(sess: &'sess Session, data: Vec<u8>, start_pos: usize) -> OnDiskCache<'sess> {\n         debug_assert!(sess.opts.incremental.is_some());\n \n-        // Decode the header\n-        let (header, post_header_pos) = {\n+        // Wrapping in a scope so we can borrow `data`\n+        let footer: Footer = {\n             let mut decoder = opaque::Decoder::new(&data[..], start_pos);\n-            let header = Header::decode(&mut decoder)\n-                .expect(\"Error while trying to decode incr. comp. cache header.\");\n-            (header, decoder.position())\n-        };\n \n-        let mut synthetic_expansion_infos = FxHashMap();\n-        let mut file_index_to_file = FxHashMap();\n-\n-        let (prev_diagnostics, query_result_index) = {\n-            let mut decoder = CacheDecoder {\n-                tcx: None,\n-                opaque: opaque::Decoder::new(&data[..], post_header_pos),\n-                codemap: sess.codemap(),\n-                cnum_map: &IndexVec::new(),\n-                synthetic_expansion_infos: &mut synthetic_expansion_infos,\n-                file_index_to_file: &mut file_index_to_file,\n-                file_index_to_stable_id: &header.file_index_to_stable_id,\n-            };\n-\n-            // Decode Diagnostics\n-            let prev_diagnostics: FxHashMap<_, _> = {\n-                let diagnostics: EncodedPrevDiagnostics =\n-                    decode_tagged(&mut decoder, PREV_DIAGNOSTICS_TAG)\n-                        .expect(\"Error while trying to decode previous session \\\n-                                 diagnostics from incr. comp. cache.\");\n-                diagnostics.into_iter().collect()\n-            };\n-\n-            // Decode the *position* of the query result index\n-            let query_result_index_pos = {\n-                let pos_pos = data.len() - IntEncodedWithFixedSize::ENCODED_SIZE;\n-                decoder.with_position(pos_pos, |decoder| {\n-                    IntEncodedWithFixedSize::decode(decoder)\n-                }).expect(\"Error while trying to decode query result index position.\")\n-                .0 as usize\n-            };\n-\n-            // Decode the query result index itself\n-            let query_result_index: EncodedQueryResultIndex =\n-                decoder.with_position(query_result_index_pos, |decoder| {\n-                    decode_tagged(decoder, QUERY_RESULT_INDEX_TAG)\n-                }).expect(\"Error while trying to decode query result index.\");\n-\n-            (prev_diagnostics, query_result_index)\n+            // Decode the *position* of the footer which can be found in the\n+            // last 8 bytes of the file.\n+            decoder.set_position(data.len() - IntEncodedWithFixedSize::ENCODED_SIZE);\n+            let query_result_index_pos = IntEncodedWithFixedSize::decode(&mut decoder)\n+                .expect(\"Error while trying to decode query result index position.\")\n+                .0 as usize;\n+\n+            // Decoder the file footer which contains all the lookup tables, etc.\n+            decoder.set_position(query_result_index_pos);\n+            decode_tagged(&mut decoder, TAG_FILE_FOOTER)\n+                .expect(\"Error while trying to decode query result index position.\")\n         };\n \n         OnDiskCache {\n             serialized_data: data,\n-            prev_diagnostics,\n-            file_index_to_stable_id: header.file_index_to_stable_id,\n-            file_index_to_file: RefCell::new(file_index_to_file),\n-            prev_cnums: header.prev_cnums,\n+            file_index_to_stable_id: footer.file_index_to_stable_id,\n+            file_index_to_file: RefCell::new(FxHashMap()),\n+            prev_cnums: footer.prev_cnums,\n             cnum_map: RefCell::new(None),\n             codemap: sess.codemap(),\n             current_diagnostics: RefCell::new(FxHashMap()),\n-            query_result_index: query_result_index.into_iter().collect(),\n-            synthetic_expansion_infos: RefCell::new(synthetic_expansion_infos),\n+            query_result_index: footer.query_result_index.into_iter().collect(),\n+            prev_diagnostics_index: footer.diagnostics_index.into_iter().collect(),\n+            synthetic_expansion_infos: RefCell::new(FxHashMap()),\n         }\n     }\n \n     pub fn new_empty(codemap: &'sess CodeMap) -> OnDiskCache<'sess> {\n         OnDiskCache {\n             serialized_data: Vec::new(),\n-            prev_diagnostics: FxHashMap(),\n             file_index_to_stable_id: FxHashMap(),\n             file_index_to_file: RefCell::new(FxHashMap()),\n             prev_cnums: vec![],\n             cnum_map: RefCell::new(None),\n             codemap,\n             current_diagnostics: RefCell::new(FxHashMap()),\n             query_result_index: FxHashMap(),\n+            prev_diagnostics_index: FxHashMap(),\n             synthetic_expansion_infos: RefCell::new(FxHashMap()),\n         }\n     }\n \n     pub fn serialize<'a, 'tcx, E>(&self,\n                                   tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-                                  cstore: &CrateStore,\n                                   encoder: &mut E)\n                                   -> Result<(), E::Error>\n         where E: ty_codec::TyEncoder\n@@ -225,31 +193,6 @@ impl<'sess> OnDiskCache<'sess> {\n             file_to_file_index,\n         };\n \n-        // Encode the file header\n-        let sorted_cnums = sorted_cnums_including_local_crate(cstore);\n-\n-        let prev_cnums: Vec<_> = sorted_cnums.iter().map(|&cnum| {\n-            let crate_name = tcx.original_crate_name(cnum).as_str().to_string();\n-            let crate_disambiguator = tcx.crate_disambiguator(cnum);\n-            (cnum.as_u32(), crate_name, crate_disambiguator)\n-        }).collect();\n-\n-        Header {\n-            file_index_to_stable_id,\n-            prev_cnums,\n-        }.encode(&mut encoder)?;\n-\n-\n-        // Encode Diagnostics\n-        let diagnostics: EncodedPrevDiagnostics =\n-            self.current_diagnostics\n-                .borrow()\n-                .iter()\n-                .map(|(k, v)| (SerializedDepNodeIndex::new(k.index()), v.clone()))\n-                .collect();\n-\n-        encoder.encode_tagged(PREV_DIAGNOSTICS_TAG, &diagnostics)?;\n-\n         // Load everything into memory so we can write it out to the on-disk\n         // cache. The vast majority of cacheable query results should already\n         // be in memory, so this should be a cheap operation.\n@@ -267,19 +210,53 @@ impl<'sess> OnDiskCache<'sess> {\n             encode_query_results::<typeck_tables_of, _>(tcx, enc, qri)?;\n         }\n \n-        // Encode query result index\n-        let query_result_index_pos = encoder.position() as u64;\n-        encoder.encode_tagged(QUERY_RESULT_INDEX_TAG, &query_result_index)?;\n+        // Encode diagnostics\n+        let diagnostics_index = {\n+            let mut diagnostics_index = EncodedDiagnosticsIndex::new();\n+\n+            for (dep_node_index, diagnostics) in self.current_diagnostics\n+                                                     .borrow()\n+                                                     .iter() {\n+                let pos = AbsoluteBytePos::new(encoder.position());\n+                // Let's make sure we get the expected type here:\n+                let diagnostics: &EncodedDiagnostics = diagnostics;\n+                let dep_node_index =\n+                    SerializedDepNodeIndex::new(dep_node_index.index());\n+                encoder.encode_tagged(dep_node_index, diagnostics)?;\n+                diagnostics_index.push((dep_node_index, pos));\n+            }\n+\n+            diagnostics_index\n+        };\n+\n+        let sorted_cnums = sorted_cnums_including_local_crate(tcx);\n+        let prev_cnums: Vec<_> = sorted_cnums.iter().map(|&cnum| {\n+            let crate_name = tcx.original_crate_name(cnum).as_str().to_string();\n+            let crate_disambiguator = tcx.crate_disambiguator(cnum);\n+            (cnum.as_u32(), crate_name, crate_disambiguator)\n+        }).collect();\n+\n+        // Encode the file footer\n+        let footer_pos = encoder.position() as u64;\n+        encoder.encode_tagged(TAG_FILE_FOOTER, &Footer {\n+            file_index_to_stable_id,\n+            prev_cnums,\n+            query_result_index,\n+            diagnostics_index,\n+        })?;\n \n-        // Encode the position of the query result index as the last 8 bytes of\n+        // Encode the position of the footer as the last 8 bytes of the\n         // file so we know where to look for it.\n-        IntEncodedWithFixedSize(query_result_index_pos).encode(&mut encoder)?;\n+        IntEncodedWithFixedSize(footer_pos).encode(encoder.encoder)?;\n+\n+        // DO NOT WRITE ANYTHING TO THE ENCODER AFTER THIS POINT! The address\n+        // of the footer must be the last thing in the data stream.\n \n         return Ok(());\n \n-        fn sorted_cnums_including_local_crate(cstore: &CrateStore) -> Vec<CrateNum> {\n+        fn sorted_cnums_including_local_crate(tcx: TyCtxt) -> Vec<CrateNum> {\n             let mut cnums = vec![LOCAL_CRATE];\n-            cnums.extend_from_slice(&cstore.crates_untracked()[..]);\n+            cnums.extend_from_slice(&tcx.crates()[..]);\n             cnums.sort_unstable();\n             // Just to be sure...\n             cnums.dedup();\n@@ -288,10 +265,17 @@ impl<'sess> OnDiskCache<'sess> {\n     }\n \n     /// Load a diagnostic emitted during the previous compilation session.\n-    pub fn load_diagnostics(&self,\n-                            dep_node_index: SerializedDepNodeIndex)\n-                            -> Vec<Diagnostic> {\n-        self.prev_diagnostics.get(&dep_node_index).cloned().unwrap_or(vec![])\n+    pub fn load_diagnostics<'a, 'tcx>(&self,\n+                                      tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                      dep_node_index: SerializedDepNodeIndex)\n+                                      -> Vec<Diagnostic> {\n+        let diagnostics: Option<EncodedDiagnostics> = self.load_indexed(\n+            tcx,\n+            dep_node_index,\n+            &self.prev_diagnostics_index,\n+            \"diagnostics\");\n+\n+        diagnostics.unwrap_or(Vec::new())\n     }\n \n     /// Store a diagnostic emitted during the current compilation session.\n@@ -311,7 +295,47 @@ impl<'sess> OnDiskCache<'sess> {\n                                           -> T\n         where T: Decodable\n     {\n-        let pos = self.query_result_index[&dep_node_index];\n+        let result = self.load_indexed(tcx,\n+                                       dep_node_index,\n+                                       &self.query_result_index,\n+                                       \"query result\");\n+        if let Some(result) = result {\n+            result\n+        } else {\n+            bug!(\"Could not find query result for key {:?}\", dep_node_index)\n+        }\n+    }\n+\n+    /// Store a diagnostic emitted during computation of an anonymous query.\n+    /// Since many anonymous queries can share the same `DepNode`, we aggregate\n+    /// them -- as opposed to regular queries where we assume that there is a\n+    /// 1:1 relationship between query-key and `DepNode`.\n+    pub fn store_diagnostics_for_anon_node(&self,\n+                                           dep_node_index: DepNodeIndex,\n+                                           mut diagnostics: Vec<Diagnostic>) {\n+        let mut current_diagnostics = self.current_diagnostics.borrow_mut();\n+\n+        let x = current_diagnostics.entry(dep_node_index).or_insert_with(|| {\n+            mem::replace(&mut diagnostics, Vec::new())\n+        });\n+\n+        x.extend(diagnostics.into_iter());\n+    }\n+\n+    fn load_indexed<'a, 'tcx, T>(&self,\n+                                 tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+                                 dep_node_index: SerializedDepNodeIndex,\n+                                 index: &FxHashMap<SerializedDepNodeIndex,\n+                                                   AbsoluteBytePos>,\n+                                 debug_tag: &'static str)\n+                                 -> Option<T>\n+        where T: Decodable\n+    {\n+        let pos = if let Some(&pos) = index.get(&dep_node_index) {\n+            pos\n+        } else {\n+            return None\n+        };\n \n         let mut cnum_map = self.cnum_map.borrow_mut();\n         if cnum_map.is_none() {\n@@ -322,7 +346,7 @@ impl<'sess> OnDiskCache<'sess> {\n         let mut file_index_to_file = self.file_index_to_file.borrow_mut();\n \n         let mut decoder = CacheDecoder {\n-            tcx: Some(tcx),\n+            tcx,\n             opaque: opaque::Decoder::new(&self.serialized_data[..], pos.to_usize()),\n             codemap: self.codemap,\n             cnum_map: cnum_map.as_ref().unwrap(),\n@@ -333,30 +357,14 @@ impl<'sess> OnDiskCache<'sess> {\n \n         match decode_tagged(&mut decoder, dep_node_index) {\n             Ok(value) => {\n-                value\n+                Some(value)\n             }\n             Err(e) => {\n-                bug!(\"Could not decode cached query result: {}\", e)\n+                bug!(\"Could not decode cached {}: {}\", debug_tag, e)\n             }\n         }\n     }\n \n-    /// Store a diagnostic emitted during computation of an anonymous query.\n-    /// Since many anonymous queries can share the same `DepNode`, we aggregate\n-    /// them -- as opposed to regular queries where we assume that there is a\n-    /// 1:1 relationship between query-key and `DepNode`.\n-    pub fn store_diagnostics_for_anon_node(&self,\n-                                           dep_node_index: DepNodeIndex,\n-                                           mut diagnostics: Vec<Diagnostic>) {\n-        let mut current_diagnostics = self.current_diagnostics.borrow_mut();\n-\n-        let x = current_diagnostics.entry(dep_node_index).or_insert_with(|| {\n-            mem::replace(&mut diagnostics, Vec::new())\n-        });\n-\n-        x.extend(diagnostics.into_iter());\n-    }\n-\n     // This function builds mapping from previous-session-CrateNum to\n     // current-session-CrateNum. There might be CrateNums from the previous\n     // Session that don't occur in the current one. For these, the mapping\n@@ -399,7 +407,7 @@ impl<'sess> OnDiskCache<'sess> {\n /// we use for crate metadata decoding in that it can rebase spans and\n /// eventually will also handle things that contain `Ty` instances.\n struct CacheDecoder<'a, 'tcx: 'a, 'x> {\n-    tcx: Option<TyCtxt<'a, 'tcx, 'tcx>>,\n+    tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     opaque: opaque::Decoder<'x>,\n     codemap: &'x CodeMap,\n     cnum_map: &'x IndexVec<CrateNum, Option<CrateNum>>,\n@@ -425,14 +433,30 @@ impl<'a, 'tcx, 'x> CacheDecoder<'a, 'tcx, 'x> {\n     }\n }\n \n+trait DecoderWithPosition: Decoder {\n+    fn position(&self) -> usize;\n+}\n+\n+impl<'enc> DecoderWithPosition for opaque::Decoder<'enc> {\n+    fn position(&self) -> usize {\n+        self.position()\n+    }\n+}\n+\n+impl<'a, 'tcx, 'x> DecoderWithPosition for CacheDecoder<'a, 'tcx, 'x> {\n+    fn position(&self) -> usize {\n+        self.opaque.position()\n+    }\n+}\n+\n // Decode something that was encoded with encode_tagged() and verify that the\n // tag matches and the correct amount of bytes was read.\n fn decode_tagged<'a, 'tcx, D, T, V>(decoder: &mut D,\n                                     expected_tag: T)\n                                     -> Result<V, D::Error>\n     where T: Decodable + Eq + ::std::fmt::Debug,\n           V: Decodable,\n-          D: Decoder + ty_codec::TyDecoder<'a, 'tcx>,\n+          D: DecoderWithPosition,\n           'tcx: 'a,\n {\n     let start_pos = decoder.position();\n@@ -453,7 +477,7 @@ impl<'a, 'tcx: 'a, 'x> ty_codec::TyDecoder<'a, 'tcx> for CacheDecoder<'a, 'tcx,\n \n     #[inline]\n     fn tcx(&self) -> TyCtxt<'a, 'tcx, 'tcx> {\n-        self.tcx.expect(\"missing TyCtxt in CacheDecoder\")\n+        self.tcx\n     }\n \n     #[inline]\n@@ -535,7 +559,7 @@ impl<'a, 'tcx, 'x> SpecializedDecoder<Span> for CacheDecoder<'a, 'tcx, 'x> {\n                 SyntaxContext::empty()\n             }\n             TAG_EXPANSION_INFO_INLINE => {\n-                let pos = AbsoluteBytePos::new(self.position());\n+                let pos = AbsoluteBytePos::new(self.opaque.position());\n                 let expn_info: ExpnInfo = Decodable::decode(self)?;\n                 let ctxt = SyntaxContext::allocate_directly(expn_info);\n                 self.synthetic_expansion_infos.insert(pos, ctxt);\n@@ -919,10 +943,7 @@ impl IntEncodedWithFixedSize {\n impl UseSpecializedEncodable for IntEncodedWithFixedSize {}\n impl UseSpecializedDecodable for IntEncodedWithFixedSize {}\n \n-impl<'enc, 'a, 'tcx, E> SpecializedEncoder<IntEncodedWithFixedSize>\n-for CacheEncoder<'enc, 'a, 'tcx, E>\n-    where E: 'enc + ty_codec::TyEncoder\n-{\n+impl<'enc> SpecializedEncoder<IntEncodedWithFixedSize> for opaque::Encoder<'enc> {\n     fn specialized_encode(&mut self, x: &IntEncodedWithFixedSize) -> Result<(), Self::Error> {\n         let start_pos = self.position();\n         for i in 0 .. IntEncodedWithFixedSize::ENCODED_SIZE {\n@@ -934,8 +955,7 @@ for CacheEncoder<'enc, 'a, 'tcx, E>\n     }\n }\n \n-impl<'a, 'tcx, 'x> SpecializedDecoder<IntEncodedWithFixedSize>\n-for CacheDecoder<'a, 'tcx, 'x> {\n+impl<'enc> SpecializedDecoder<IntEncodedWithFixedSize> for opaque::Decoder<'enc> {\n     fn specialized_decode(&mut self) -> Result<IntEncodedWithFixedSize, Self::Error> {\n         let mut value: u64 = 0;\n         let start_pos = self.position();"}, {"sha": "3121cceeea03ecc0bf744131314847f7cd20e202", "filename": "src/librustc/ty/maps/plumbing.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fmaps%2Fplumbing.rs?ref=059bd805262b3a9e90226eadc2262ee96619eacb", "patch": "@@ -145,7 +145,7 @@ impl<'a, 'gcx, 'tcx> TyCtxt<'a, 'gcx, 'tcx> {\n                 if !self.dep_graph.is_fully_enabled() {\n                     return None;\n                 }\n-                match self.dep_graph.try_mark_green(self, &dep_node) {\n+                match self.dep_graph.try_mark_green(self.global_tcx(), &dep_node) {\n                     Some(dep_node_index) => {\n                         debug_assert!(self.dep_graph.is_green(dep_node_index));\n                         self.dep_graph.read_index(dep_node_index);"}, {"sha": "99557659b297bfbb794220802b66c8a700439763", "filename": "src/libserialize/opaque.rs", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibserialize%2Fopaque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/059bd805262b3a9e90226eadc2262ee96619eacb/src%2Flibserialize%2Fopaque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibserialize%2Fopaque.rs?ref=059bd805262b3a9e90226eadc2262ee96619eacb", "patch": "@@ -162,6 +162,10 @@ impl<'a> Decoder<'a> {\n         self.position\n     }\n \n+    pub fn set_position(&mut self, pos: usize) {\n+        self.position = pos\n+    }\n+\n     pub fn advance(&mut self, bytes: usize) {\n         self.position += bytes;\n     }"}]}