{"sha": "a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "node_id": "MDY6Q29tbWl0NzI0NzEyOmE1MTM3YWZlOGNkZGYyMzY2MDQ1YzhkM2RlMjNhMTdjNWFjOGRjMjU=", "commit": {"author": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2016-11-15T20:20:39Z"}, "committer": {"name": "Michael Woerister", "email": "michaelwoerister@posteo.net", "date": "2016-11-18T21:45:59Z"}, "message": "ICH: Hash MacroDefs in a mostly stable way.", "tree": {"sha": "171599eb7014842cc0583804f9f9e7a95af9abdf", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/171599eb7014842cc0583804f9f9e7a95af9abdf"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "html_url": "https://github.com/rust-lang/rust/commit/a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/a5137afe8cddf2366045c8d3de23a17c5ac8dc25/comments", "author": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "committer": {"login": "michaelwoerister", "id": 1825894, "node_id": "MDQ6VXNlcjE4MjU4OTQ=", "avatar_url": "https://avatars.githubusercontent.com/u/1825894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/michaelwoerister", "html_url": "https://github.com/michaelwoerister", "followers_url": "https://api.github.com/users/michaelwoerister/followers", "following_url": "https://api.github.com/users/michaelwoerister/following{/other_user}", "gists_url": "https://api.github.com/users/michaelwoerister/gists{/gist_id}", "starred_url": "https://api.github.com/users/michaelwoerister/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/michaelwoerister/subscriptions", "organizations_url": "https://api.github.com/users/michaelwoerister/orgs", "repos_url": "https://api.github.com/users/michaelwoerister/repos", "events_url": "https://api.github.com/users/michaelwoerister/events{/privacy}", "received_events_url": "https://api.github.com/users/michaelwoerister/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "003b1699c0044aef757c9c32df13a529fd4c485b", "url": "https://api.github.com/repos/rust-lang/rust/commits/003b1699c0044aef757c9c32df13a529fd4c485b", "html_url": "https://github.com/rust-lang/rust/commit/003b1699c0044aef757c9c32df13a529fd4c485b"}], "stats": {"total": 146, "additions": 143, "deletions": 3}, "files": [{"sha": "f98e698a1c9d416b740457a4cfb8f0150977c0da", "filename": "src/librustc_incremental/calculate_svh/mod.rs", "status": "modified", "additions": 6, "deletions": 1, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/a5137afe8cddf2366045c8d3de23a17c5ac8dc25/src%2Flibrustc_incremental%2Fcalculate_svh%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a5137afe8cddf2366045c8d3de23a17c5ac8dc25/src%2Flibrustc_incremental%2Fcalculate_svh%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fcalculate_svh%2Fmod.rs?ref=a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "patch": "@@ -46,6 +46,7 @@ use self::caching_codemap_view::CachingCodemapView;\n use self::hasher::IchHasher;\n use ich::Fingerprint;\n \n+\n mod def_path_hash;\n mod svh_visitor;\n mod caching_codemap_view;\n@@ -113,8 +114,12 @@ pub fn compute_incremental_hashes_map<'a, 'tcx: 'a>(tcx: TyCtxt<'a, 'tcx, 'tcx>)\n     record_time(&tcx.sess.perf_stats.incr_comp_hashes_time, || {\n         visitor.calculate_def_id(DefId::local(CRATE_DEF_INDEX),\n                                  |v| visit::walk_crate(v, krate));\n-        // FIXME(#37713) if foreign items were item likes, could use ItemLikeVisitor\n         krate.visit_all_item_likes(&mut visitor.as_deep_visitor());\n+\n+        for macro_def in krate.exported_macros.iter() {\n+            visitor.calculate_node_id(macro_def.id,\n+                                      |v| v.visit_macro_def(macro_def));\n+        }\n     });\n \n     tcx.sess.perf_stats.incr_comp_hashes_count.set(visitor.hashes.len() as u64);"}, {"sha": "e8608b187d84cb4241fca4e0eb09a091e2359382", "filename": "src/librustc_incremental/calculate_svh/svh_visitor.rs", "status": "modified", "additions": 137, "deletions": 2, "changes": 139, "blob_url": "https://github.com/rust-lang/rust/blob/a5137afe8cddf2366045c8d3de23a17c5ac8dc25/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs", "raw_url": "https://github.com/rust-lang/rust/raw/a5137afe8cddf2366045c8d3de23a17c5ac8dc25/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_incremental%2Fcalculate_svh%2Fsvh_visitor.rs?ref=a5137afe8cddf2366045c8d3de23a17c5ac8dc25", "patch": "@@ -24,6 +24,7 @@ use syntax::ast::{self, Name, NodeId};\n use syntax::attr;\n use syntax::parse::token;\n use syntax_pos::{Span, NO_EXPANSION, COMMAND_LINE_EXPN, BytePos};\n+use syntax::tokenstream;\n use rustc::hir;\n use rustc::hir::*;\n use rustc::hir::def::{Def, PathResolution};\n@@ -769,9 +770,10 @@ impl<'a, 'hash, 'tcx> visit::Visitor<'tcx> for StrictVersionHashVisitor<'a, 'has\n         debug!(\"visit_macro_def: st={:?}\", self.st);\n         SawMacroDef.hash(self.st);\n         hash_attrs!(self, &macro_def.attrs);\n+        for tt in &macro_def.body {\n+            self.hash_token_tree(tt);\n+        }\n         visit::walk_macro_def(self, macro_def)\n-        // FIXME(mw): We should hash the body of the macro too but we don't\n-        //            have a stable way of doing so yet.\n     }\n }\n \n@@ -941,4 +943,137 @@ impl<'a, 'hash, 'tcx> StrictVersionHashVisitor<'a, 'hash, 'tcx> {\n             self.overflow_checks_enabled = true;\n         }\n     }\n+\n+    fn hash_token_tree(&mut self, tt: &tokenstream::TokenTree) {\n+        self.hash_discriminant(tt);\n+        match *tt {\n+            tokenstream::TokenTree::Token(span, ref token) => {\n+                hash_span!(self, span);\n+                self.hash_token(token);\n+            }\n+            tokenstream::TokenTree::Delimited(span, ref delimited) => {\n+                hash_span!(self, span);\n+                let tokenstream::Delimited {\n+                    ref delim,\n+                    open_span,\n+                    ref tts,\n+                    close_span,\n+                } = **delimited;\n+\n+                delim.hash(self.st);\n+                hash_span!(self, open_span);\n+                tts.len().hash(self.st);\n+                for sub_tt in tts {\n+                    self.hash_token_tree(sub_tt);\n+                }\n+                hash_span!(self, close_span);\n+            }\n+            tokenstream::TokenTree::Sequence(span, ref sequence_repetition) => {\n+                hash_span!(self, span);\n+                let tokenstream::SequenceRepetition {\n+                    ref tts,\n+                    ref separator,\n+                    op,\n+                    num_captures,\n+                } = **sequence_repetition;\n+\n+                tts.len().hash(self.st);\n+                for sub_tt in tts {\n+                    self.hash_token_tree(sub_tt);\n+                }\n+                self.hash_discriminant(separator);\n+                if let Some(ref separator) = *separator {\n+                    self.hash_token(separator);\n+                }\n+                op.hash(self.st);\n+                num_captures.hash(self.st);\n+            }\n+        }\n+    }\n+\n+    fn hash_token(&mut self, token: &token::Token) {\n+        self.hash_discriminant(token);\n+        match *token {\n+            token::Token::Eq |\n+            token::Token::Lt |\n+            token::Token::Le |\n+            token::Token::EqEq |\n+            token::Token::Ne |\n+            token::Token::Ge |\n+            token::Token::Gt |\n+            token::Token::AndAnd |\n+            token::Token::OrOr |\n+            token::Token::Not |\n+            token::Token::Tilde |\n+            token::Token::At |\n+            token::Token::Dot |\n+            token::Token::DotDot |\n+            token::Token::DotDotDot |\n+            token::Token::Comma |\n+            token::Token::Semi |\n+            token::Token::Colon |\n+            token::Token::ModSep |\n+            token::Token::RArrow |\n+            token::Token::LArrow |\n+            token::Token::FatArrow |\n+            token::Token::Pound |\n+            token::Token::Dollar |\n+            token::Token::Question |\n+            token::Token::Underscore |\n+            token::Token::Whitespace |\n+            token::Token::Comment |\n+            token::Token::Eof => {}\n+\n+            token::Token::BinOp(bin_op_token) |\n+            token::Token::BinOpEq(bin_op_token) => bin_op_token.hash(self.st),\n+\n+            token::Token::OpenDelim(delim_token) |\n+            token::Token::CloseDelim(delim_token) => delim_token.hash(self.st),\n+\n+            token::Token::Literal(ref lit, ref opt_name) => {\n+                self.hash_discriminant(lit);\n+                match *lit {\n+                    token::Lit::Byte(val) |\n+                    token::Lit::Char(val) |\n+                    token::Lit::Integer(val) |\n+                    token::Lit::Float(val) |\n+                    token::Lit::Str_(val) |\n+                    token::Lit::ByteStr(val) => val.as_str().hash(self.st),\n+                    token::Lit::StrRaw(val, n) |\n+                    token::Lit::ByteStrRaw(val, n) => {\n+                        val.as_str().hash(self.st);\n+                        n.hash(self.st);\n+                    }\n+                };\n+                opt_name.map(ast::Name::as_str).hash(self.st);\n+            }\n+\n+            token::Token::Ident(ident) |\n+            token::Token::Lifetime(ident) |\n+            token::Token::SubstNt(ident) => ident.name.as_str().hash(self.st),\n+            token::Token::MatchNt(ident1, ident2) => {\n+                ident1.name.as_str().hash(self.st);\n+                ident2.name.as_str().hash(self.st);\n+            }\n+\n+            token::Token::Interpolated(ref non_terminal) => {\n+                // FIXME(mw): This could be implemented properly. It's just a\n+                //            lot of work, since we would need to hash the AST\n+                //            in a stable way, in addition to the HIR.\n+                //            Since this is hardly used anywhere, just emit a\n+                //            warning for now.\n+                if self.tcx.sess.opts.debugging_opts.incremental.is_some() {\n+                    let msg = format!(\"Quasi-quoting might make incremental \\\n+                                       compilation very inefficient: {:?}\",\n+                                      non_terminal);\n+                    self.tcx.sess.warn(&msg[..]);\n+                }\n+\n+                non_terminal.hash(self.st);\n+            }\n+\n+            token::Token::DocComment(val) |\n+            token::Token::Shebang(val) => val.as_str().hash(self.st),\n+        }\n+    }\n }"}]}