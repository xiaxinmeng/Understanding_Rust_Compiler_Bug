{"sha": "55479de2993195bedafdc2104db21e52709ed137", "node_id": "MDY6Q29tbWl0NzI0NzEyOjU1NDc5ZGUyOTkzMTk1YmVkYWZkYzIxMDRkYjIxZTUyNzA5ZWQxMzc=", "commit": {"author": {"name": "Manish Goregaokar", "email": "manishsmail@gmail.com", "date": "2020-06-19T16:14:58Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2020-06-19T16:14:58Z"}, "message": "Rollup merge of #72709 - LeSeulArtichaut:unsafe-liballoc, r=nikomatsakis\n\n`#[deny(unsafe_op_in_unsafe_fn)]` in liballoc\n\nThis PR proposes to make use of the new `unsafe_op_in_unsafe_fn` lint, i.e. no longer consider the body of an unsafe function as an unsafe block and require explicit unsafe block to perform unsafe operations.\n\nThis has been first (partly) suggested by @Mark-Simulacrum in https://github.com/rust-lang/rust/pull/69245#issuecomment-587817065\n\nTracking issue for the feature: #71668.\n~~Blocked on #71862.~~\nr? @Mark-Simulacrum cc @nikomatsakis can you confirm that those changes are desirable? Should I restrict it to only BTree for the moment?", "tree": {"sha": "bd5b19df582f3efbaeeb29c22c0b17e575401b2a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/bd5b19df582f3efbaeeb29c22c0b17e575401b2a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/55479de2993195bedafdc2104db21e52709ed137", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJe7OSCCRBK7hj4Ov3rIwAAdHIIAI9Zay/tBhRZP6Ks7GzmE/Gr\nWGJ79gy2rqKDWh6PADVA8YLjK7tyVklP1oLJl6uv4iY4RbQ6d/EEuQ253RjDt4yE\n3irtKwsIrMgnzuWFVNpfnV/L1NTFuie5+hR6ezXrYCMO2ywd4kPgsu+ps6/EkPIi\nnSjMdXtTQ8gYAfMSNIrIihHeXxXhtbccnlexypZdTvHHU+7sX2pK9ApxlWk1cq+q\n4HYUsk1bCroFmTN8nROMTXhtfVBhJy9U98cAaEO7s+JMWtd6/AuPzlzCT/T5O/ao\nwc3OQRxN3k6gpYklpthBkPRqmh1uXnILVwkXm+C6R5Ff3F84pvU5rYlEEmzOuUk=\n=0nww\n-----END PGP SIGNATURE-----\n", "payload": "tree bd5b19df582f3efbaeeb29c22c0b17e575401b2a\nparent 85e1c3baca9a23e2640c9eb408b0a65848a5d0f0\nparent 7b6398657c2335c053d7733f5bb752e8d2b5d261\nauthor Manish Goregaokar <manishsmail@gmail.com> 1592583298 -0700\ncommitter GitHub <noreply@github.com> 1592583298 -0700\n\nRollup merge of #72709 - LeSeulArtichaut:unsafe-liballoc, r=nikomatsakis\n\n`#[deny(unsafe_op_in_unsafe_fn)]` in liballoc\n\nThis PR proposes to make use of the new `unsafe_op_in_unsafe_fn` lint, i.e. no longer consider the body of an unsafe function as an unsafe block and require explicit unsafe block to perform unsafe operations.\n\nThis has been first (partly) suggested by @Mark-Simulacrum in https://github.com/rust-lang/rust/pull/69245#issuecomment-587817065\n\nTracking issue for the feature: #71668.\n~~Blocked on #71862.~~\nr? @Mark-Simulacrum cc @nikomatsakis can you confirm that those changes are desirable? Should I restrict it to only BTree for the moment?\n"}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/55479de2993195bedafdc2104db21e52709ed137", "html_url": "https://github.com/rust-lang/rust/commit/55479de2993195bedafdc2104db21e52709ed137", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/55479de2993195bedafdc2104db21e52709ed137/comments", "author": {"login": "Manishearth", "id": 1617736, "node_id": "MDQ6VXNlcjE2MTc3MzY=", "avatar_url": "https://avatars.githubusercontent.com/u/1617736?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Manishearth", "html_url": "https://github.com/Manishearth", "followers_url": "https://api.github.com/users/Manishearth/followers", "following_url": "https://api.github.com/users/Manishearth/following{/other_user}", "gists_url": "https://api.github.com/users/Manishearth/gists{/gist_id}", "starred_url": "https://api.github.com/users/Manishearth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Manishearth/subscriptions", "organizations_url": "https://api.github.com/users/Manishearth/orgs", "repos_url": "https://api.github.com/users/Manishearth/repos", "events_url": "https://api.github.com/users/Manishearth/events{/privacy}", "received_events_url": "https://api.github.com/users/Manishearth/received_events", "type": "User", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "85e1c3baca9a23e2640c9eb408b0a65848a5d0f0", "url": "https://api.github.com/repos/rust-lang/rust/commits/85e1c3baca9a23e2640c9eb408b0a65848a5d0f0", "html_url": "https://github.com/rust-lang/rust/commit/85e1c3baca9a23e2640c9eb408b0a65848a5d0f0"}, {"sha": "7b6398657c2335c053d7733f5bb752e8d2b5d261", "url": "https://api.github.com/repos/rust-lang/rust/commits/7b6398657c2335c053d7733f5bb752e8d2b5d261", "html_url": "https://github.com/rust-lang/rust/commit/7b6398657c2335c053d7733f5bb752e8d2b5d261"}], "stats": {"total": 644, "additions": 387, "deletions": 257}, "files": [{"sha": "98c7ac3f2ef17cde30f163dfd658c70a0bfeae45", "filename": "src/liballoc/alloc.rs", "status": "modified", "additions": 28, "deletions": 17, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Falloc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Falloc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Falloc.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -77,7 +77,7 @@ pub struct Global;\n #[stable(feature = \"global_alloc\", since = \"1.28.0\")]\n #[inline]\n pub unsafe fn alloc(layout: Layout) -> *mut u8 {\n-    __rust_alloc(layout.size(), layout.align())\n+    unsafe { __rust_alloc(layout.size(), layout.align()) }\n }\n \n /// Deallocate memory with the global allocator.\n@@ -99,7 +99,7 @@ pub unsafe fn alloc(layout: Layout) -> *mut u8 {\n #[stable(feature = \"global_alloc\", since = \"1.28.0\")]\n #[inline]\n pub unsafe fn dealloc(ptr: *mut u8, layout: Layout) {\n-    __rust_dealloc(ptr, layout.size(), layout.align())\n+    unsafe { __rust_dealloc(ptr, layout.size(), layout.align()) }\n }\n \n /// Reallocate memory with the global allocator.\n@@ -121,7 +121,7 @@ pub unsafe fn dealloc(ptr: *mut u8, layout: Layout) {\n #[stable(feature = \"global_alloc\", since = \"1.28.0\")]\n #[inline]\n pub unsafe fn realloc(ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n-    __rust_realloc(ptr, layout.size(), layout.align(), new_size)\n+    unsafe { __rust_realloc(ptr, layout.size(), layout.align(), new_size) }\n }\n \n /// Allocate zero-initialized memory with the global allocator.\n@@ -158,7 +158,7 @@ pub unsafe fn realloc(ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8\n #[stable(feature = \"global_alloc\", since = \"1.28.0\")]\n #[inline]\n pub unsafe fn alloc_zeroed(layout: Layout) -> *mut u8 {\n-    __rust_alloc_zeroed(layout.size(), layout.align())\n+    unsafe { __rust_alloc_zeroed(layout.size(), layout.align()) }\n }\n \n #[unstable(feature = \"allocator_api\", issue = \"32838\")]\n@@ -183,7 +183,7 @@ unsafe impl AllocRef for Global {\n     #[inline]\n     unsafe fn dealloc(&mut self, ptr: NonNull<u8>, layout: Layout) {\n         if layout.size() != 0 {\n-            dealloc(ptr.as_ptr(), layout)\n+            unsafe { dealloc(ptr.as_ptr(), layout) }\n         }\n     }\n \n@@ -209,16 +209,21 @@ unsafe impl AllocRef for Global {\n         match placement {\n             ReallocPlacement::InPlace => Err(AllocErr),\n             ReallocPlacement::MayMove if layout.size() == 0 => {\n-                let new_layout = Layout::from_size_align_unchecked(new_size, layout.align());\n+                let new_layout =\n+                    unsafe { Layout::from_size_align_unchecked(new_size, layout.align()) };\n                 self.alloc(new_layout, init)\n             }\n             ReallocPlacement::MayMove => {\n                 // `realloc` probably checks for `new_size > size` or something similar.\n-                intrinsics::assume(new_size > size);\n-                let ptr = realloc(ptr.as_ptr(), layout, new_size);\n+                let ptr = unsafe {\n+                    intrinsics::assume(new_size > size);\n+                    realloc(ptr.as_ptr(), layout, new_size)\n+                };\n                 let memory =\n                     MemoryBlock { ptr: NonNull::new(ptr).ok_or(AllocErr)?, size: new_size };\n-                init.init_offset(memory, size);\n+                unsafe {\n+                    init.init_offset(memory, size);\n+                }\n                 Ok(memory)\n             }\n         }\n@@ -245,13 +250,17 @@ unsafe impl AllocRef for Global {\n         match placement {\n             ReallocPlacement::InPlace => Err(AllocErr),\n             ReallocPlacement::MayMove if new_size == 0 => {\n-                self.dealloc(ptr, layout);\n+                unsafe {\n+                    self.dealloc(ptr, layout);\n+                }\n                 Ok(MemoryBlock { ptr: layout.dangling(), size: 0 })\n             }\n             ReallocPlacement::MayMove => {\n                 // `realloc` probably checks for `new_size < size` or something similar.\n-                intrinsics::assume(new_size < size);\n-                let ptr = realloc(ptr.as_ptr(), layout, new_size);\n+                let ptr = unsafe {\n+                    intrinsics::assume(new_size < size);\n+                    realloc(ptr.as_ptr(), layout, new_size)\n+                };\n                 Ok(MemoryBlock { ptr: NonNull::new(ptr).ok_or(AllocErr)?, size: new_size })\n             }\n         }\n@@ -264,7 +273,7 @@ unsafe impl AllocRef for Global {\n #[lang = \"exchange_malloc\"]\n #[inline]\n unsafe fn exchange_malloc(size: usize, align: usize) -> *mut u8 {\n-    let layout = Layout::from_size_align_unchecked(size, align);\n+    let layout = unsafe { Layout::from_size_align_unchecked(size, align) };\n     match Global.alloc(layout, AllocInit::Uninitialized) {\n         Ok(memory) => memory.ptr.as_ptr(),\n         Err(_) => handle_alloc_error(layout),\n@@ -279,10 +288,12 @@ unsafe fn exchange_malloc(size: usize, align: usize) -> *mut u8 {\n // For example if `Box` is changed to  `struct Box<T: ?Sized, A: AllocRef>(Unique<T>, A)`,\n // this function has to be changed to `fn box_free<T: ?Sized, A: AllocRef>(Unique<T>, A)` as well.\n pub(crate) unsafe fn box_free<T: ?Sized>(ptr: Unique<T>) {\n-    let size = size_of_val(ptr.as_ref());\n-    let align = min_align_of_val(ptr.as_ref());\n-    let layout = Layout::from_size_align_unchecked(size, align);\n-    Global.dealloc(ptr.cast().into(), layout)\n+    unsafe {\n+        let size = size_of_val(ptr.as_ref());\n+        let align = min_align_of_val(ptr.as_ref());\n+        let layout = Layout::from_size_align_unchecked(size, align);\n+        Global.dealloc(ptr.cast().into(), layout)\n+    }\n }\n \n /// Abort on memory allocation error or failure."}, {"sha": "d10cbf1afab30b9bddff1aecd94bcec1b183da25", "filename": "src/liballoc/boxed.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fboxed.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fboxed.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fboxed.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -311,7 +311,7 @@ impl<T> Box<mem::MaybeUninit<T>> {\n     #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n     #[inline]\n     pub unsafe fn assume_init(self) -> Box<T> {\n-        Box::from_raw(Box::into_raw(self) as *mut T)\n+        unsafe { Box::from_raw(Box::into_raw(self) as *mut T) }\n     }\n }\n \n@@ -349,7 +349,7 @@ impl<T> Box<[mem::MaybeUninit<T>]> {\n     #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n     #[inline]\n     pub unsafe fn assume_init(self) -> Box<[T]> {\n-        Box::from_raw(Box::into_raw(self) as *mut [T])\n+        unsafe { Box::from_raw(Box::into_raw(self) as *mut [T]) }\n     }\n }\n \n@@ -393,7 +393,7 @@ impl<T: ?Sized> Box<T> {\n     #[stable(feature = \"box_raw\", since = \"1.4.0\")]\n     #[inline]\n     pub unsafe fn from_raw(raw: *mut T) -> Self {\n-        Box(Unique::new_unchecked(raw))\n+        Box(unsafe { Unique::new_unchecked(raw) })\n     }\n \n     /// Consumes the `Box`, returning a wrapped raw pointer."}, {"sha": "15313e333ce732a876646d5fe533b77a58f4d0bf", "filename": "src/liballoc/collections/binary_heap.rs", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbinary_heap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbinary_heap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fbinary_heap.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -1003,7 +1003,7 @@ impl<'a, T> Hole<'a, T> {\n     unsafe fn new(data: &'a mut [T], pos: usize) -> Self {\n         debug_assert!(pos < data.len());\n         // SAFE: pos should be inside the slice\n-        let elt = ptr::read(data.get_unchecked(pos));\n+        let elt = unsafe { ptr::read(data.get_unchecked(pos)) };\n         Hole { data, elt: ManuallyDrop::new(elt), pos }\n     }\n \n@@ -1025,7 +1025,7 @@ impl<'a, T> Hole<'a, T> {\n     unsafe fn get(&self, index: usize) -> &T {\n         debug_assert!(index != self.pos);\n         debug_assert!(index < self.data.len());\n-        self.data.get_unchecked(index)\n+        unsafe { self.data.get_unchecked(index) }\n     }\n \n     /// Move hole to new location\n@@ -1035,9 +1035,11 @@ impl<'a, T> Hole<'a, T> {\n     unsafe fn move_to(&mut self, index: usize) {\n         debug_assert!(index != self.pos);\n         debug_assert!(index < self.data.len());\n-        let index_ptr: *const _ = self.data.get_unchecked(index);\n-        let hole_ptr = self.data.get_unchecked_mut(self.pos);\n-        ptr::copy_nonoverlapping(index_ptr, hole_ptr, 1);\n+        unsafe {\n+            let index_ptr: *const _ = self.data.get_unchecked(index);\n+            let hole_ptr = self.data.get_unchecked_mut(self.pos);\n+            ptr::copy_nonoverlapping(index_ptr, hole_ptr, 1);\n+        }\n         self.pos = index;\n     }\n }"}, {"sha": "2fcc8cc98737d4beb7c93346fd8e9196c9992f6a", "filename": "src/liballoc/collections/btree/map.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fmap.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fmap.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fbtree%2Fmap.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -1725,7 +1725,7 @@ impl<'a, K: 'a, V: 'a> DrainFilterInner<'a, K, V> {\n         &mut self,\n     ) -> Option<Handle<NodeRef<marker::Mut<'a>, K, V, marker::LeafOrInternal>, marker::KV>> {\n         let edge = self.cur_leaf_edge.as_ref()?;\n-        ptr::read(edge).next_kv().ok()\n+        unsafe { ptr::read(edge).next_kv().ok() }\n     }\n \n     /// Implementation of a typical `DrainFilter::next` method, given the predicate.\n@@ -1808,7 +1808,7 @@ impl<'a, K, V> Range<'a, K, V> {\n     }\n \n     unsafe fn next_unchecked(&mut self) -> (&'a K, &'a V) {\n-        unwrap_unchecked(self.front.as_mut()).next_unchecked()\n+        unsafe { unwrap_unchecked(self.front.as_mut()).next_unchecked() }\n     }\n }\n \n@@ -1821,7 +1821,7 @@ impl<'a, K, V> DoubleEndedIterator for Range<'a, K, V> {\n \n impl<'a, K, V> Range<'a, K, V> {\n     unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a V) {\n-        unwrap_unchecked(self.back.as_mut()).next_back_unchecked()\n+        unsafe { unwrap_unchecked(self.back.as_mut()).next_back_unchecked() }\n     }\n }\n \n@@ -1859,7 +1859,7 @@ impl<'a, K, V> RangeMut<'a, K, V> {\n     }\n \n     unsafe fn next_unchecked(&mut self) -> (&'a mut K, &'a mut V) {\n-        unwrap_unchecked(self.front.as_mut()).next_unchecked()\n+        unsafe { unwrap_unchecked(self.front.as_mut()).next_unchecked() }\n     }\n }\n \n@@ -1880,7 +1880,7 @@ impl<K, V> FusedIterator for RangeMut<'_, K, V> {}\n \n impl<'a, K, V> RangeMut<'a, K, V> {\n     unsafe fn next_back_unchecked(&mut self) -> (&'a mut K, &'a mut V) {\n-        unwrap_unchecked(self.back.as_mut()).next_back_unchecked()\n+        unsafe { unwrap_unchecked(self.back.as_mut()).next_back_unchecked() }\n     }\n }\n "}, {"sha": "543ff41a4d48d55fc2b4616f39a8a17cc69c2a87", "filename": "src/liballoc/collections/btree/mod.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fbtree%2Fmod.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -19,7 +19,9 @@ pub unsafe fn unwrap_unchecked<T>(val: Option<T>) -> T {\n         if cfg!(debug_assertions) {\n             panic!(\"'unchecked' unwrap on None in BTreeMap\");\n         } else {\n-            core::intrinsics::unreachable();\n+            unsafe {\n+                core::intrinsics::unreachable();\n+            }\n         }\n     })\n }"}, {"sha": "5478d822438b1ca3afd2f169f7d50422147dbd52", "filename": "src/liballoc/collections/btree/navigate.rs", "status": "modified", "additions": 58, "deletions": 42, "changes": 100, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fnavigate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fnavigate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fbtree%2Fnavigate.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -64,8 +64,10 @@ macro_rules! def_next_kv_uncheched_dealloc {\n                 edge = match edge.$adjacent_kv() {\n                     Ok(internal_kv) => return internal_kv,\n                     Err(last_edge) => {\n-                        let parent_edge = last_edge.into_node().deallocate_and_ascend();\n-                        unwrap_unchecked(parent_edge).forget_node_type()\n+                        unsafe {\n+                            let parent_edge = last_edge.into_node().deallocate_and_ascend();\n+                            unwrap_unchecked(parent_edge).forget_node_type()\n+                        }\n                     }\n                 }\n             }\n@@ -82,9 +84,11 @@ def_next_kv_uncheched_dealloc! {unsafe fn next_back_kv_unchecked_dealloc: left_k\n /// Safety: The change closure must not panic.\n #[inline]\n unsafe fn replace<T, R>(v: &mut T, change: impl FnOnce(T) -> (T, R)) -> R {\n-    let value = ptr::read(v);\n+    let value = unsafe { ptr::read(v) };\n     let (new_value, ret) = change(value);\n-    ptr::write(v, new_value);\n+    unsafe {\n+        ptr::write(v, new_value);\n+    }\n     ret\n }\n \n@@ -93,22 +97,26 @@ impl<'a, K, V> Handle<NodeRef<marker::Immut<'a>, K, V, marker::Leaf>, marker::Ed\n     /// key and value in between.\n     /// Unsafe because the caller must ensure that the leaf edge is not the last one in the tree.\n     pub unsafe fn next_unchecked(&mut self) -> (&'a K, &'a V) {\n-        replace(self, |leaf_edge| {\n-            let kv = leaf_edge.next_kv();\n-            let kv = unwrap_unchecked(kv.ok());\n-            (kv.next_leaf_edge(), kv.into_kv())\n-        })\n+        unsafe {\n+            replace(self, |leaf_edge| {\n+                let kv = leaf_edge.next_kv();\n+                let kv = unwrap_unchecked(kv.ok());\n+                (kv.next_leaf_edge(), kv.into_kv())\n+            })\n+        }\n     }\n \n     /// Moves the leaf edge handle to the previous leaf edge and returns references to the\n     /// key and value in between.\n     /// Unsafe because the caller must ensure that the leaf edge is not the first one in the tree.\n     pub unsafe fn next_back_unchecked(&mut self) -> (&'a K, &'a V) {\n-        replace(self, |leaf_edge| {\n-            let kv = leaf_edge.next_back_kv();\n-            let kv = unwrap_unchecked(kv.ok());\n-            (kv.next_back_leaf_edge(), kv.into_kv())\n-        })\n+        unsafe {\n+            replace(self, |leaf_edge| {\n+                let kv = leaf_edge.next_back_kv();\n+                let kv = unwrap_unchecked(kv.ok());\n+                (kv.next_back_leaf_edge(), kv.into_kv())\n+            })\n+        }\n     }\n }\n \n@@ -119,14 +127,16 @@ impl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge\n     /// - The caller must ensure that the leaf edge is not the last one in the tree.\n     /// - Using the updated handle may well invalidate the returned references.\n     pub unsafe fn next_unchecked(&mut self) -> (&'a mut K, &'a mut V) {\n-        let kv = replace(self, |leaf_edge| {\n-            let kv = leaf_edge.next_kv();\n-            let kv = unwrap_unchecked(kv.ok());\n-            (ptr::read(&kv).next_leaf_edge(), kv)\n-        });\n-        // Doing the descend (and perhaps another move) invalidates the references\n-        // returned by `into_kv_mut`, so we have to do this last.\n-        kv.into_kv_mut()\n+        unsafe {\n+            let kv = replace(self, |leaf_edge| {\n+                let kv = leaf_edge.next_kv();\n+                let kv = unwrap_unchecked(kv.ok());\n+                (ptr::read(&kv).next_leaf_edge(), kv)\n+            });\n+            // Doing the descend (and perhaps another move) invalidates the references\n+            // returned by `into_kv_mut`, so we have to do this last.\n+            kv.into_kv_mut()\n+        }\n     }\n \n     /// Moves the leaf edge handle to the previous leaf and returns references to the\n@@ -135,14 +145,16 @@ impl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Leaf>, marker::Edge\n     /// - The caller must ensure that the leaf edge is not the first one in the tree.\n     /// - Using the updated handle may well invalidate the returned references.\n     pub unsafe fn next_back_unchecked(&mut self) -> (&'a mut K, &'a mut V) {\n-        let kv = replace(self, |leaf_edge| {\n-            let kv = leaf_edge.next_back_kv();\n-            let kv = unwrap_unchecked(kv.ok());\n-            (ptr::read(&kv).next_back_leaf_edge(), kv)\n-        });\n-        // Doing the descend (and perhaps another move) invalidates the references\n-        // returned by `into_kv_mut`, so we have to do this last.\n-        kv.into_kv_mut()\n+        unsafe {\n+            let kv = replace(self, |leaf_edge| {\n+                let kv = leaf_edge.next_back_kv();\n+                let kv = unwrap_unchecked(kv.ok());\n+                (ptr::read(&kv).next_back_leaf_edge(), kv)\n+            });\n+            // Doing the descend (and perhaps another move) invalidates the references\n+            // returned by `into_kv_mut`, so we have to do this last.\n+            kv.into_kv_mut()\n+        }\n     }\n }\n \n@@ -159,12 +171,14 @@ impl<K, V> Handle<NodeRef<marker::Owned, K, V, marker::Leaf>, marker::Edge> {\n     ///   if the two preconditions above hold.\n     /// - Using the updated handle may well invalidate the returned references.\n     pub unsafe fn next_unchecked(&mut self) -> (K, V) {\n-        replace(self, |leaf_edge| {\n-            let kv = next_kv_unchecked_dealloc(leaf_edge);\n-            let k = ptr::read(kv.reborrow().into_kv().0);\n-            let v = ptr::read(kv.reborrow().into_kv().1);\n-            (kv.next_leaf_edge(), (k, v))\n-        })\n+        unsafe {\n+            replace(self, |leaf_edge| {\n+                let kv = next_kv_unchecked_dealloc(leaf_edge);\n+                let k = ptr::read(kv.reborrow().into_kv().0);\n+                let v = ptr::read(kv.reborrow().into_kv().1);\n+                (kv.next_leaf_edge(), (k, v))\n+            })\n+        }\n     }\n \n     /// Moves the leaf edge handle to the previous leaf edge and returns the key\n@@ -179,12 +193,14 @@ impl<K, V> Handle<NodeRef<marker::Owned, K, V, marker::Leaf>, marker::Edge> {\n     ///   if the two preconditions above hold.\n     /// - Using the updated handle may well invalidate the returned references.\n     pub unsafe fn next_back_unchecked(&mut self) -> (K, V) {\n-        replace(self, |leaf_edge| {\n-            let kv = next_back_kv_unchecked_dealloc(leaf_edge);\n-            let k = ptr::read(kv.reborrow().into_kv().0);\n-            let v = ptr::read(kv.reborrow().into_kv().1);\n-            (kv.next_back_leaf_edge(), (k, v))\n-        })\n+        unsafe {\n+            replace(self, |leaf_edge| {\n+                let kv = next_back_kv_unchecked_dealloc(leaf_edge);\n+                let k = ptr::read(kv.reborrow().into_kv().0);\n+                let v = ptr::read(kv.reborrow().into_kv().1);\n+                (kv.next_back_leaf_edge(), (k, v))\n+            })\n+        }\n     }\n }\n "}, {"sha": "a4b6cf12a23bd92671d30db8cdc4eaa8b293aeed", "filename": "src/liballoc/collections/btree/node.rs", "status": "modified", "additions": 32, "deletions": 22, "changes": 54, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fnode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fbtree%2Fnode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fbtree%2Fnode.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -107,7 +107,7 @@ impl<K, V> InternalNode<K, V> {\n     /// `len` of 0), there must be one initialized and valid edge. This function does not set up\n     /// such an edge.\n     unsafe fn new() -> Self {\n-        InternalNode { data: LeafNode::new(), edges: [MaybeUninit::UNINIT; 2 * B] }\n+        InternalNode { data: unsafe { LeafNode::new() }, edges: [MaybeUninit::UNINIT; 2 * B] }\n     }\n }\n \n@@ -131,7 +131,7 @@ impl<K, V> BoxedNode<K, V> {\n     }\n \n     unsafe fn from_ptr(ptr: NonNull<LeafNode<K, V>>) -> Self {\n-        BoxedNode { ptr: Unique::new_unchecked(ptr.as_ptr()) }\n+        BoxedNode { ptr: unsafe { Unique::new_unchecked(ptr.as_ptr()) } }\n     }\n \n     fn as_ptr(&self) -> NonNull<LeafNode<K, V>> {\n@@ -392,14 +392,16 @@ impl<K, V> NodeRef<marker::Owned, K, V, marker::LeafOrInternal> {\n         let height = self.height;\n         let node = self.node;\n         let ret = self.ascend().ok();\n-        Global.dealloc(\n-            node.cast(),\n-            if height > 0 {\n-                Layout::new::<InternalNode<K, V>>()\n-            } else {\n-                Layout::new::<LeafNode<K, V>>()\n-            },\n-        );\n+        unsafe {\n+            Global.dealloc(\n+                node.cast(),\n+                if height > 0 {\n+                    Layout::new::<InternalNode<K, V>>()\n+                } else {\n+                    Layout::new::<LeafNode<K, V>>()\n+                },\n+            );\n+        }\n         ret\n     }\n }\n@@ -565,7 +567,7 @@ impl<'a, K, V> NodeRef<marker::Mut<'a>, K, V, marker::Internal> {\n         debug_assert!(first <= self.len());\n         debug_assert!(after_last <= self.len() + 1);\n         for i in first..after_last {\n-            Handle::new_edge(self.reborrow_mut(), i).correct_parent_link();\n+            unsafe { Handle::new_edge(self.reborrow_mut(), i) }.correct_parent_link();\n         }\n     }\n \n@@ -789,7 +791,7 @@ impl<'a, K, V, NodeType, HandleType> Handle<NodeRef<marker::Mut<'a>, K, V, NodeT\n         &mut self,\n     ) -> Handle<NodeRef<marker::Mut<'_>, K, V, NodeType>, HandleType> {\n         // We can't use Handle::new_kv or Handle::new_edge because we don't know our type\n-        Handle { node: self.node.reborrow_mut(), idx: self.idx, _marker: PhantomData }\n+        Handle { node: unsafe { self.node.reborrow_mut() }, idx: self.idx, _marker: PhantomData }\n     }\n }\n \n@@ -885,7 +887,7 @@ impl<'a, K, V> Handle<NodeRef<marker::Mut<'a>, K, V, marker::Internal>, marker::\n     unsafe fn cast_unchecked<NewType>(\n         &mut self,\n     ) -> Handle<NodeRef<marker::Mut<'_>, K, V, NewType>, marker::Edge> {\n-        Handle::new_edge(self.node.cast_unchecked(), self.idx)\n+        unsafe { Handle::new_edge(self.node.cast_unchecked(), self.idx) }\n     }\n \n     /// Inserts a new key/value pair and an edge that will go to the right of that new pair\n@@ -1330,8 +1332,10 @@ unsafe fn move_kv<K, V>(\n     dest_offset: usize,\n     count: usize,\n ) {\n-    ptr::copy_nonoverlapping(source.0.add(source_offset), dest.0.add(dest_offset), count);\n-    ptr::copy_nonoverlapping(source.1.add(source_offset), dest.1.add(dest_offset), count);\n+    unsafe {\n+        ptr::copy_nonoverlapping(source.0.add(source_offset), dest.0.add(dest_offset), count);\n+        ptr::copy_nonoverlapping(source.1.add(source_offset), dest.1.add(dest_offset), count);\n+    }\n }\n \n // Source and destination must have the same height.\n@@ -1344,8 +1348,10 @@ unsafe fn move_edges<K, V>(\n ) {\n     let source_ptr = source.as_internal_mut().edges.as_mut_ptr();\n     let dest_ptr = dest.as_internal_mut().edges.as_mut_ptr();\n-    ptr::copy_nonoverlapping(source_ptr.add(source_offset), dest_ptr.add(dest_offset), count);\n-    dest.correct_childrens_parent_links(dest_offset, dest_offset + count);\n+    unsafe {\n+        ptr::copy_nonoverlapping(source_ptr.add(source_offset), dest_ptr.add(dest_offset), count);\n+        dest.correct_childrens_parent_links(dest_offset, dest_offset + count);\n+    }\n }\n \n impl<BorrowType, K, V> Handle<NodeRef<BorrowType, K, V, marker::Leaf>, marker::Edge> {\n@@ -1459,12 +1465,16 @@ pub mod marker {\n }\n \n unsafe fn slice_insert<T>(slice: &mut [T], idx: usize, val: T) {\n-    ptr::copy(slice.as_ptr().add(idx), slice.as_mut_ptr().add(idx + 1), slice.len() - idx);\n-    ptr::write(slice.get_unchecked_mut(idx), val);\n+    unsafe {\n+        ptr::copy(slice.as_ptr().add(idx), slice.as_mut_ptr().add(idx + 1), slice.len() - idx);\n+        ptr::write(slice.get_unchecked_mut(idx), val);\n+    }\n }\n \n unsafe fn slice_remove<T>(slice: &mut [T], idx: usize) -> T {\n-    let ret = ptr::read(slice.get_unchecked(idx));\n-    ptr::copy(slice.as_ptr().add(idx + 1), slice.as_mut_ptr().add(idx), slice.len() - idx - 1);\n-    ret\n+    unsafe {\n+        let ret = ptr::read(slice.get_unchecked(idx));\n+        ptr::copy(slice.as_ptr().add(idx + 1), slice.as_mut_ptr().add(idx), slice.len() - idx - 1);\n+        ret\n+    }\n }"}, {"sha": "36b5785fdf6c5ed930340eb4b38d772d7dd21f4a", "filename": "src/liballoc/collections/linked_list.rs", "status": "modified", "additions": 25, "deletions": 11, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Flinked_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Flinked_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Flinked_list.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -225,17 +225,17 @@ impl<T> LinkedList<T> {\n     /// maintain validity of aliasing pointers.\n     #[inline]\n     unsafe fn unlink_node(&mut self, mut node: NonNull<Node<T>>) {\n-        let node = node.as_mut(); // this one is ours now, we can create an &mut.\n+        let node = unsafe { node.as_mut() }; // this one is ours now, we can create an &mut.\n \n         // Not creating new mutable (unique!) references overlapping `element`.\n         match node.prev {\n-            Some(prev) => (*prev.as_ptr()).next = node.next,\n+            Some(prev) => unsafe { (*prev.as_ptr()).next = node.next },\n             // this node is the head node\n             None => self.head = node.next,\n         };\n \n         match node.next {\n-            Some(next) => (*next.as_ptr()).prev = node.prev,\n+            Some(next) => unsafe { (*next.as_ptr()).prev = node.prev },\n             // this node is the tail node\n             None => self.tail = node.prev,\n         };\n@@ -258,17 +258,23 @@ impl<T> LinkedList<T> {\n         // This method takes care not to create multiple mutable references to whole nodes at the same time,\n         // to maintain validity of aliasing pointers into `element`.\n         if let Some(mut existing_prev) = existing_prev {\n-            existing_prev.as_mut().next = Some(splice_start);\n+            unsafe {\n+                existing_prev.as_mut().next = Some(splice_start);\n+            }\n         } else {\n             self.head = Some(splice_start);\n         }\n         if let Some(mut existing_next) = existing_next {\n-            existing_next.as_mut().prev = Some(splice_end);\n+            unsafe {\n+                existing_next.as_mut().prev = Some(splice_end);\n+            }\n         } else {\n             self.tail = Some(splice_end);\n         }\n-        splice_start.as_mut().prev = existing_prev;\n-        splice_end.as_mut().next = existing_next;\n+        unsafe {\n+            splice_start.as_mut().prev = existing_prev;\n+            splice_end.as_mut().next = existing_next;\n+        }\n \n         self.len += splice_length;\n     }\n@@ -297,9 +303,13 @@ impl<T> LinkedList<T> {\n         if let Some(mut split_node) = split_node {\n             let first_part_head;\n             let first_part_tail;\n-            first_part_tail = split_node.as_mut().prev.take();\n+            unsafe {\n+                first_part_tail = split_node.as_mut().prev.take();\n+            }\n             if let Some(mut tail) = first_part_tail {\n-                tail.as_mut().next = None;\n+                unsafe {\n+                    tail.as_mut().next = None;\n+                }\n                 first_part_head = self.head;\n             } else {\n                 first_part_head = None;\n@@ -333,9 +343,13 @@ impl<T> LinkedList<T> {\n         if let Some(mut split_node) = split_node {\n             let second_part_head;\n             let second_part_tail;\n-            second_part_head = split_node.as_mut().next.take();\n+            unsafe {\n+                second_part_head = split_node.as_mut().next.take();\n+            }\n             if let Some(mut head) = second_part_head {\n-                head.as_mut().prev = None;\n+                unsafe {\n+                    head.as_mut().prev = None;\n+                }\n                 second_part_tail = self.tail;\n             } else {\n                 second_part_tail = None;"}, {"sha": "15f3a94ca2d6a84d1dc270114de33daddaa15efc", "filename": "src/liballoc/collections/vec_deque.rs", "status": "modified", "additions": 55, "deletions": 25, "changes": 80, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fvec_deque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fcollections%2Fvec_deque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fcollections%2Fvec_deque.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -7,6 +7,8 @@\n \n #![stable(feature = \"rust1\", since = \"1.0.0\")]\n \n+// ignore-tidy-filelength\n+\n use core::array::LengthAtMost32;\n use core::cmp::{self, Ordering};\n use core::fmt;\n@@ -201,25 +203,27 @@ impl<T> VecDeque<T> {\n     /// Turn ptr into a slice\n     #[inline]\n     unsafe fn buffer_as_slice(&self) -> &[T] {\n-        slice::from_raw_parts(self.ptr(), self.cap())\n+        unsafe { slice::from_raw_parts(self.ptr(), self.cap()) }\n     }\n \n     /// Turn ptr into a mut slice\n     #[inline]\n     unsafe fn buffer_as_mut_slice(&mut self) -> &mut [T] {\n-        slice::from_raw_parts_mut(self.ptr(), self.cap())\n+        unsafe { slice::from_raw_parts_mut(self.ptr(), self.cap()) }\n     }\n \n     /// Moves an element out of the buffer\n     #[inline]\n     unsafe fn buffer_read(&mut self, off: usize) -> T {\n-        ptr::read(self.ptr().add(off))\n+        unsafe { ptr::read(self.ptr().add(off)) }\n     }\n \n     /// Writes an element into the buffer, moving it.\n     #[inline]\n     unsafe fn buffer_write(&mut self, off: usize, value: T) {\n-        ptr::write(self.ptr().add(off), value);\n+        unsafe {\n+            ptr::write(self.ptr().add(off), value);\n+        }\n     }\n \n     /// Returns `true` if the buffer is at full capacity.\n@@ -268,7 +272,9 @@ impl<T> VecDeque<T> {\n             len,\n             self.cap()\n         );\n-        ptr::copy(self.ptr().add(src), self.ptr().add(dst), len);\n+        unsafe {\n+            ptr::copy(self.ptr().add(src), self.ptr().add(dst), len);\n+        }\n     }\n \n     /// Copies a contiguous block of memory len long from src to dst\n@@ -290,7 +296,9 @@ impl<T> VecDeque<T> {\n             len,\n             self.cap()\n         );\n-        ptr::copy_nonoverlapping(self.ptr().add(src), self.ptr().add(dst), len);\n+        unsafe {\n+            ptr::copy_nonoverlapping(self.ptr().add(src), self.ptr().add(dst), len);\n+        }\n     }\n \n     /// Copies a potentially wrapping block of memory len long from src to dest.\n@@ -330,7 +338,9 @@ impl<T> VecDeque<T> {\n                 // 2 [_ _ A A A A B B _]\n                 //            D . . .\n                 //\n-                self.copy(dst, src, len);\n+                unsafe {\n+                    self.copy(dst, src, len);\n+                }\n             }\n             (false, false, true) => {\n                 // dst before src, src doesn't wrap, dst wraps\n@@ -341,8 +351,10 @@ impl<T> VecDeque<T> {\n                 // 3 [B B B B _ _ _ A A]\n                 //    . .           D .\n                 //\n-                self.copy(dst, src, dst_pre_wrap_len);\n-                self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n+                unsafe {\n+                    self.copy(dst, src, dst_pre_wrap_len);\n+                    self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n+                }\n             }\n             (true, false, true) => {\n                 // src before dst, src doesn't wrap, dst wraps\n@@ -353,8 +365,10 @@ impl<T> VecDeque<T> {\n                 // 3 [B B _ _ _ A A A A]\n                 //    . .           D .\n                 //\n-                self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n-                self.copy(dst, src, dst_pre_wrap_len);\n+                unsafe {\n+                    self.copy(0, src + dst_pre_wrap_len, len - dst_pre_wrap_len);\n+                    self.copy(dst, src, dst_pre_wrap_len);\n+                }\n             }\n             (false, true, false) => {\n                 // dst before src, src wraps, dst doesn't wrap\n@@ -365,8 +379,10 @@ impl<T> VecDeque<T> {\n                 // 3 [C C _ _ _ B B C C]\n                 //              D . . .\n                 //\n-                self.copy(dst, src, src_pre_wrap_len);\n-                self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n+                unsafe {\n+                    self.copy(dst, src, src_pre_wrap_len);\n+                    self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n+                }\n             }\n             (true, true, false) => {\n                 // src before dst, src wraps, dst doesn't wrap\n@@ -377,8 +393,10 @@ impl<T> VecDeque<T> {\n                 // 3 [C C A A _ _ _ C C]\n                 //    D . . .\n                 //\n-                self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n-                self.copy(dst, src, src_pre_wrap_len);\n+                unsafe {\n+                    self.copy(dst + src_pre_wrap_len, 0, len - src_pre_wrap_len);\n+                    self.copy(dst, src, src_pre_wrap_len);\n+                }\n             }\n             (false, true, true) => {\n                 // dst before src, src wraps, dst wraps\n@@ -392,9 +410,11 @@ impl<T> VecDeque<T> {\n                 //\n                 debug_assert!(dst_pre_wrap_len > src_pre_wrap_len);\n                 let delta = dst_pre_wrap_len - src_pre_wrap_len;\n-                self.copy(dst, src, src_pre_wrap_len);\n-                self.copy(dst + src_pre_wrap_len, 0, delta);\n-                self.copy(0, delta, len - dst_pre_wrap_len);\n+                unsafe {\n+                    self.copy(dst, src, src_pre_wrap_len);\n+                    self.copy(dst + src_pre_wrap_len, 0, delta);\n+                    self.copy(0, delta, len - dst_pre_wrap_len);\n+                }\n             }\n             (true, true, true) => {\n                 // src before dst, src wraps, dst wraps\n@@ -408,9 +428,11 @@ impl<T> VecDeque<T> {\n                 //\n                 debug_assert!(src_pre_wrap_len > dst_pre_wrap_len);\n                 let delta = src_pre_wrap_len - dst_pre_wrap_len;\n-                self.copy(delta, 0, len - src_pre_wrap_len);\n-                self.copy(0, self.cap() - delta, delta);\n-                self.copy(dst, src, dst_pre_wrap_len);\n+                unsafe {\n+                    self.copy(delta, 0, len - src_pre_wrap_len);\n+                    self.copy(0, self.cap() - delta, delta);\n+                    self.copy(dst, src, dst_pre_wrap_len);\n+                }\n             }\n         }\n     }\n@@ -440,13 +462,17 @@ impl<T> VecDeque<T> {\n             // Nop\n         } else if self.head < old_capacity - self.tail {\n             // B\n-            self.copy_nonoverlapping(old_capacity, 0, self.head);\n+            unsafe {\n+                self.copy_nonoverlapping(old_capacity, 0, self.head);\n+            }\n             self.head += old_capacity;\n             debug_assert!(self.head > self.tail);\n         } else {\n             // C\n             let new_tail = new_capacity - (old_capacity - self.tail);\n-            self.copy_nonoverlapping(new_tail, self.tail, old_capacity - self.tail);\n+            unsafe {\n+                self.copy_nonoverlapping(new_tail, self.tail, old_capacity - self.tail);\n+            }\n             self.tail = new_tail;\n             debug_assert!(self.head < self.tail);\n         }\n@@ -2297,7 +2323,9 @@ impl<T> VecDeque<T> {\n \n     unsafe fn rotate_left_inner(&mut self, mid: usize) {\n         debug_assert!(mid * 2 <= self.len());\n-        self.wrap_copy(self.head, self.tail, mid);\n+        unsafe {\n+            self.wrap_copy(self.head, self.tail, mid);\n+        }\n         self.head = self.wrap_add(self.head, mid);\n         self.tail = self.wrap_add(self.tail, mid);\n     }\n@@ -2306,7 +2334,9 @@ impl<T> VecDeque<T> {\n         debug_assert!(k * 2 <= self.len());\n         self.head = self.wrap_sub(self.head, k);\n         self.tail = self.wrap_sub(self.tail, k);\n-        self.wrap_copy(self.tail, self.head, k);\n+        unsafe {\n+            self.wrap_copy(self.tail, self.head, k);\n+        }\n     }\n }\n "}, {"sha": "41c2b221704e67ffb9e358e3174e418658df083b", "filename": "src/liballoc/lib.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Flib.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -72,6 +72,7 @@\n #![deny(intra_doc_link_resolution_failure)] // rustdoc is run without -D warnings\n #![allow(explicit_outlives_requirements)]\n #![allow(incomplete_features)]\n+#![deny(unsafe_op_in_unsafe_fn)]\n #![cfg_attr(not(test), feature(generator_trait))]\n #![cfg_attr(test, feature(test))]\n #![feature(allocator_api)]\n@@ -118,6 +119,7 @@\n #![feature(try_reserve)]\n #![feature(unboxed_closures)]\n #![feature(unicode_internals)]\n+#![feature(unsafe_block_in_unsafe_fn)]\n #![feature(unsize)]\n #![feature(unsized_locals)]\n #![feature(allocator_internals)]"}, {"sha": "15e81f9288722e0f5786ddf0a9ebf6b04cf422e8", "filename": "src/liballoc/raw_vec.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fraw_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fraw_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -108,7 +108,7 @@ impl<T> RawVec<T, Global> {\n     /// If the `ptr` and `capacity` come from a `RawVec`, then this is guaranteed.\n     #[inline]\n     pub unsafe fn from_raw_parts(ptr: *mut T, capacity: usize) -> Self {\n-        Self::from_raw_parts_in(ptr, capacity, Global)\n+        unsafe { Self::from_raw_parts_in(ptr, capacity, Global) }\n     }\n \n     /// Converts a `Box<[T]>` into a `RawVec<T>`.\n@@ -139,8 +139,10 @@ impl<T> RawVec<T, Global> {\n         );\n \n         let me = ManuallyDrop::new(self);\n-        let slice = slice::from_raw_parts_mut(me.ptr() as *mut MaybeUninit<T>, len);\n-        Box::from_raw(slice)\n+        unsafe {\n+            let slice = slice::from_raw_parts_mut(me.ptr() as *mut MaybeUninit<T>, len);\n+            Box::from_raw(slice)\n+        }\n     }\n }\n \n@@ -192,7 +194,7 @@ impl<T, A: AllocRef> RawVec<T, A> {\n     /// If the `ptr` and `capacity` come from a `RawVec` created via `a`, then this is guaranteed.\n     #[inline]\n     pub unsafe fn from_raw_parts_in(ptr: *mut T, capacity: usize, a: A) -> Self {\n-        Self { ptr: Unique::new_unchecked(ptr), cap: capacity, alloc: a }\n+        Self { ptr: unsafe { Unique::new_unchecked(ptr) }, cap: capacity, alloc: a }\n     }\n \n     /// Gets a raw pointer to the start of the allocation. Note that this is"}, {"sha": "6418c4a9823f20665b4b4dc0aa9a3d4fdbbb6d8b", "filename": "src/liballoc/raw_vec/tests.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fraw_vec%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fraw_vec%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec%2Ftests.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -35,7 +35,7 @@ fn allocator_param() {\n             }\n         }\n         unsafe fn dealloc(&mut self, ptr: NonNull<u8>, layout: Layout) {\n-            Global.dealloc(ptr, layout)\n+            unsafe { Global.dealloc(ptr, layout) }\n         }\n     }\n "}, {"sha": "4d50ae9efca9532eb717f17db20985e2541e233e", "filename": "src/liballoc/rc.rs", "status": "modified", "additions": 51, "deletions": 39, "changes": 90, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Frc.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Frc.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Frc.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -304,7 +304,7 @@ impl<T: ?Sized> Rc<T> {\n     }\n \n     unsafe fn from_ptr(ptr: *mut RcBox<T>) -> Self {\n-        Self::from_inner(NonNull::new_unchecked(ptr))\n+        Self::from_inner(unsafe { NonNull::new_unchecked(ptr) })\n     }\n }\n \n@@ -544,7 +544,7 @@ impl<T> Rc<[mem::MaybeUninit<T>]> {\n     #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n     #[inline]\n     pub unsafe fn assume_init(self) -> Rc<[T]> {\n-        Rc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _)\n+        unsafe { Rc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _) }\n     }\n }\n \n@@ -643,13 +643,13 @@ impl<T: ?Sized> Rc<T> {\n     /// ```\n     #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n     pub unsafe fn from_raw(ptr: *const T) -> Self {\n-        let offset = data_offset(ptr);\n+        let offset = unsafe { data_offset(ptr) };\n \n         // Reverse the offset to find the original RcBox.\n         let fake_ptr = ptr as *mut RcBox<T>;\n-        let rc_ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n+        let rc_ptr = unsafe { set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset)) };\n \n-        Self::from_ptr(rc_ptr)\n+        unsafe { Self::from_ptr(rc_ptr) }\n     }\n \n     /// Consumes the `Rc`, returning the wrapped pointer as `NonNull<T>`.\n@@ -805,7 +805,7 @@ impl<T: ?Sized> Rc<T> {\n     #[inline]\n     #[unstable(feature = \"get_mut_unchecked\", issue = \"63292\")]\n     pub unsafe fn get_mut_unchecked(this: &mut Self) -> &mut T {\n-        &mut this.ptr.as_mut().value\n+        unsafe { &mut this.ptr.as_mut().value }\n     }\n \n     #[inline]\n@@ -964,20 +964,24 @@ impl<T: ?Sized> Rc<T> {\n \n         // Initialize the RcBox\n         let inner = mem_to_rcbox(mem.ptr.as_ptr());\n-        debug_assert_eq!(Layout::for_value(&*inner), layout);\n+        unsafe {\n+            debug_assert_eq!(Layout::for_value(&*inner), layout);\n \n-        ptr::write(&mut (*inner).strong, Cell::new(1));\n-        ptr::write(&mut (*inner).weak, Cell::new(1));\n+            ptr::write(&mut (*inner).strong, Cell::new(1));\n+            ptr::write(&mut (*inner).weak, Cell::new(1));\n+        }\n \n         inner\n     }\n \n     /// Allocates an `RcBox<T>` with sufficient space for an unsized inner value\n     unsafe fn allocate_for_ptr(ptr: *const T) -> *mut RcBox<T> {\n         // Allocate for the `RcBox<T>` using the given value.\n-        Self::allocate_for_layout(Layout::for_value(&*ptr), |mem| {\n-            set_data_ptr(ptr as *mut T, mem) as *mut RcBox<T>\n-        })\n+        unsafe {\n+            Self::allocate_for_layout(Layout::for_value(&*ptr), |mem| {\n+                set_data_ptr(ptr as *mut T, mem) as *mut RcBox<T>\n+            })\n+        }\n     }\n \n     fn from_box(v: Box<T>) -> Rc<T> {\n@@ -1006,9 +1010,11 @@ impl<T: ?Sized> Rc<T> {\n impl<T> Rc<[T]> {\n     /// Allocates an `RcBox<[T]>` with the given length.\n     unsafe fn allocate_for_slice(len: usize) -> *mut RcBox<[T]> {\n-        Self::allocate_for_layout(Layout::array::<T>(len).unwrap(), |mem| {\n-            ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut RcBox<[T]>\n-        })\n+        unsafe {\n+            Self::allocate_for_layout(Layout::array::<T>(len).unwrap(), |mem| {\n+                ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut RcBox<[T]>\n+            })\n+        }\n     }\n }\n \n@@ -1017,7 +1023,9 @@ impl<T> Rc<[T]> {\n /// For a slice/trait object, this sets the `data` field and leaves the rest\n /// unchanged. For a sized raw pointer, this simply sets the pointer.\n unsafe fn set_data_ptr<T: ?Sized, U>(mut ptr: *mut T, data: *mut U) -> *mut T {\n-    ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n+    unsafe {\n+        ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n+    }\n     ptr\n }\n \n@@ -1026,11 +1034,11 @@ impl<T> Rc<[T]> {\n     ///\n     /// Unsafe because the caller must either take ownership or bind `T: Copy`\n     unsafe fn copy_from_slice(v: &[T]) -> Rc<[T]> {\n-        let ptr = Self::allocate_for_slice(v.len());\n-\n-        ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).value as *mut [T] as *mut T, v.len());\n-\n-        Self::from_ptr(ptr)\n+        unsafe {\n+            let ptr = Self::allocate_for_slice(v.len());\n+            ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).value as *mut [T] as *mut T, v.len());\n+            Self::from_ptr(ptr)\n+        }\n     }\n \n     /// Constructs an `Rc<[T]>` from an iterator known to be of a certain size.\n@@ -1058,25 +1066,27 @@ impl<T> Rc<[T]> {\n             }\n         }\n \n-        let ptr = Self::allocate_for_slice(len);\n+        unsafe {\n+            let ptr = Self::allocate_for_slice(len);\n \n-        let mem = ptr as *mut _ as *mut u8;\n-        let layout = Layout::for_value(&*ptr);\n+            let mem = ptr as *mut _ as *mut u8;\n+            let layout = Layout::for_value(&*ptr);\n \n-        // Pointer to first element\n-        let elems = &mut (*ptr).value as *mut [T] as *mut T;\n+            // Pointer to first element\n+            let elems = &mut (*ptr).value as *mut [T] as *mut T;\n \n-        let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n+            let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n \n-        for (i, item) in iter.enumerate() {\n-            ptr::write(elems.add(i), item);\n-            guard.n_elems += 1;\n-        }\n+            for (i, item) in iter.enumerate() {\n+                ptr::write(elems.add(i), item);\n+                guard.n_elems += 1;\n+            }\n \n-        // All clear. Forget the guard so it doesn't free the new RcBox.\n-        forget(guard);\n+            // All clear. Forget the guard so it doesn't free the new RcBox.\n+            forget(guard);\n \n-        Self::from_ptr(ptr)\n+            Self::from_ptr(ptr)\n+        }\n     }\n }\n \n@@ -1786,10 +1796,12 @@ impl<T> Weak<T> {\n             Self::new()\n         } else {\n             // See Rc::from_raw for details\n-            let offset = data_offset(ptr);\n-            let fake_ptr = ptr as *mut RcBox<T>;\n-            let ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n-            Weak { ptr: NonNull::new(ptr).expect(\"Invalid pointer passed to from_raw\") }\n+            unsafe {\n+                let offset = data_offset(ptr);\n+                let fake_ptr = ptr as *mut RcBox<T>;\n+                let ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n+                Weak { ptr: NonNull::new(ptr).expect(\"Invalid pointer passed to from_raw\") }\n+            }\n         }\n     }\n }\n@@ -2106,7 +2118,7 @@ unsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n     // Because it is ?Sized, it will always be the last field in memory.\n     // Note: This is a detail of the current implementation of the compiler,\n     // and is not a guaranteed language detail. Do not rely on it outside of std.\n-    data_offset_align(align_of_val(&*ptr))\n+    unsafe { data_offset_align(align_of_val(&*ptr)) }\n }\n \n /// Computes the offset of the data field within `RcBox`."}, {"sha": "d7dc2174d665f3bce0a3ebb5da7da0b328b1576e", "filename": "src/liballoc/slice.rs", "status": "modified", "additions": 27, "deletions": 20, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fslice.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -831,8 +831,7 @@ where\n {\n     let len = v.len();\n     let v = v.as_mut_ptr();\n-    let v_mid = v.add(mid);\n-    let v_end = v.add(len);\n+    let (v_mid, v_end) = unsafe { (v.add(mid), v.add(len)) };\n \n     // The merge process first copies the shorter run into `buf`. Then it traces the newly copied\n     // run and the longer run forwards (or backwards), comparing their next unconsumed elements and\n@@ -855,8 +854,10 @@ where\n \n     if mid <= len - mid {\n         // The left run is shorter.\n-        ptr::copy_nonoverlapping(v, buf, mid);\n-        hole = MergeHole { start: buf, end: buf.add(mid), dest: v };\n+        unsafe {\n+            ptr::copy_nonoverlapping(v, buf, mid);\n+            hole = MergeHole { start: buf, end: buf.add(mid), dest: v };\n+        }\n \n         // Initially, these pointers point to the beginnings of their arrays.\n         let left = &mut hole.start;\n@@ -866,17 +867,21 @@ where\n         while *left < hole.end && right < v_end {\n             // Consume the lesser side.\n             // If equal, prefer the left run to maintain stability.\n-            let to_copy = if is_less(&*right, &**left) {\n-                get_and_increment(&mut right)\n-            } else {\n-                get_and_increment(left)\n-            };\n-            ptr::copy_nonoverlapping(to_copy, get_and_increment(out), 1);\n+            unsafe {\n+                let to_copy = if is_less(&*right, &**left) {\n+                    get_and_increment(&mut right)\n+                } else {\n+                    get_and_increment(left)\n+                };\n+                ptr::copy_nonoverlapping(to_copy, get_and_increment(out), 1);\n+            }\n         }\n     } else {\n         // The right run is shorter.\n-        ptr::copy_nonoverlapping(v_mid, buf, len - mid);\n-        hole = MergeHole { start: buf, end: buf.add(len - mid), dest: v_mid };\n+        unsafe {\n+            ptr::copy_nonoverlapping(v_mid, buf, len - mid);\n+            hole = MergeHole { start: buf, end: buf.add(len - mid), dest: v_mid };\n+        }\n \n         // Initially, these pointers point past the ends of their arrays.\n         let left = &mut hole.dest;\n@@ -886,25 +891,27 @@ where\n         while v < *left && buf < *right {\n             // Consume the greater side.\n             // If equal, prefer the right run to maintain stability.\n-            let to_copy = if is_less(&*right.offset(-1), &*left.offset(-1)) {\n-                decrement_and_get(left)\n-            } else {\n-                decrement_and_get(right)\n-            };\n-            ptr::copy_nonoverlapping(to_copy, decrement_and_get(&mut out), 1);\n+            unsafe {\n+                let to_copy = if is_less(&*right.offset(-1), &*left.offset(-1)) {\n+                    decrement_and_get(left)\n+                } else {\n+                    decrement_and_get(right)\n+                };\n+                ptr::copy_nonoverlapping(to_copy, decrement_and_get(&mut out), 1);\n+            }\n         }\n     }\n     // Finally, `hole` gets dropped. If the shorter run was not fully consumed, whatever remains of\n     // it will now be copied into the hole in `v`.\n \n     unsafe fn get_and_increment<T>(ptr: &mut *mut T) -> *mut T {\n         let old = *ptr;\n-        *ptr = ptr.offset(1);\n+        *ptr = unsafe { ptr.offset(1) };\n         old\n     }\n \n     unsafe fn decrement_and_get<T>(ptr: &mut *mut T) -> *mut T {\n-        *ptr = ptr.offset(-1);\n+        *ptr = unsafe { ptr.offset(-1) };\n         *ptr\n     }\n "}, {"sha": "57927c688479b5f72746d6220b271f58dd2c7e41", "filename": "src/liballoc/str.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fstr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fstr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fstr.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -583,5 +583,5 @@ impl str {\n #[stable(feature = \"str_box_extras\", since = \"1.20.0\")]\n #[inline]\n pub unsafe fn from_boxed_utf8_unchecked(v: Box<[u8]>) -> Box<str> {\n-    Box::from_raw(Box::into_raw(v) as *mut str)\n+    unsafe { Box::from_raw(Box::into_raw(v) as *mut str) }\n }"}, {"sha": "91b6d526796003090c8a97ab890340672baa95f3", "filename": "src/liballoc/string.rs", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fstring.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fstring.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fstring.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -724,7 +724,7 @@ impl String {\n     #[inline]\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub unsafe fn from_raw_parts(buf: *mut u8, length: usize, capacity: usize) -> String {\n-        String { vec: Vec::from_raw_parts(buf, length, capacity) }\n+        unsafe { String { vec: Vec::from_raw_parts(buf, length, capacity) } }\n     }\n \n     /// Converts a vector of bytes to a `String` without checking that the\n@@ -1329,9 +1329,11 @@ impl String {\n         let amt = bytes.len();\n         self.vec.reserve(amt);\n \n-        ptr::copy(self.vec.as_ptr().add(idx), self.vec.as_mut_ptr().add(idx + amt), len - idx);\n-        ptr::copy(bytes.as_ptr(), self.vec.as_mut_ptr().add(idx), amt);\n-        self.vec.set_len(len + amt);\n+        unsafe {\n+            ptr::copy(self.vec.as_ptr().add(idx), self.vec.as_mut_ptr().add(idx + amt), len - idx);\n+            ptr::copy(bytes.as_ptr(), self.vec.as_mut_ptr().add(idx), amt);\n+            self.vec.set_len(len + amt);\n+        }\n     }\n \n     /// Inserts a string slice into this `String` at a byte position."}, {"sha": "826f0c8fa833fbf001e0aacb434ccddeab100e66", "filename": "src/liballoc/sync.rs", "status": "modified", "additions": 58, "deletions": 42, "changes": 100, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fsync.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fsync.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fsync.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -232,7 +232,7 @@ impl<T: ?Sized> Arc<T> {\n     }\n \n     unsafe fn from_ptr(ptr: *mut ArcInner<T>) -> Self {\n-        Self::from_inner(NonNull::new_unchecked(ptr))\n+        unsafe { Self::from_inner(NonNull::new_unchecked(ptr)) }\n     }\n }\n \n@@ -543,7 +543,7 @@ impl<T> Arc<[mem::MaybeUninit<T>]> {\n     #[unstable(feature = \"new_uninit\", issue = \"63291\")]\n     #[inline]\n     pub unsafe fn assume_init(self) -> Arc<[T]> {\n-        Arc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _)\n+        unsafe { Arc::from_ptr(mem::ManuallyDrop::new(self).ptr.as_ptr() as _) }\n     }\n }\n \n@@ -642,13 +642,15 @@ impl<T: ?Sized> Arc<T> {\n     /// ```\n     #[stable(feature = \"rc_raw\", since = \"1.17.0\")]\n     pub unsafe fn from_raw(ptr: *const T) -> Self {\n-        let offset = data_offset(ptr);\n+        unsafe {\n+            let offset = data_offset(ptr);\n \n-        // Reverse the offset to find the original ArcInner.\n-        let fake_ptr = ptr as *mut ArcInner<T>;\n-        let arc_ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n+            // Reverse the offset to find the original ArcInner.\n+            let fake_ptr = ptr as *mut ArcInner<T>;\n+            let arc_ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n \n-        Self::from_ptr(arc_ptr)\n+            Self::from_ptr(arc_ptr)\n+        }\n     }\n \n     /// Consumes the `Arc`, returning the wrapped pointer as `NonNull<T>`.\n@@ -807,7 +809,7 @@ impl<T: ?Sized> Arc<T> {\n     #[unstable(feature = \"arc_mutate_strong_count\", issue = \"71983\")]\n     pub unsafe fn incr_strong_count(ptr: *const T) {\n         // Retain Arc, but don't touch refcount by wrapping in ManuallyDrop\n-        let arc = mem::ManuallyDrop::new(Arc::<T>::from_raw(ptr));\n+        let arc = unsafe { mem::ManuallyDrop::new(Arc::<T>::from_raw(ptr)) };\n         // Now increase refcount, but don't drop new refcount either\n         let _arc_clone: mem::ManuallyDrop<_> = arc.clone();\n     }\n@@ -847,7 +849,7 @@ impl<T: ?Sized> Arc<T> {\n     #[inline]\n     #[unstable(feature = \"arc_mutate_strong_count\", issue = \"71983\")]\n     pub unsafe fn decr_strong_count(ptr: *const T) {\n-        mem::drop(Arc::from_raw(ptr));\n+        unsafe { mem::drop(Arc::from_raw(ptr)) };\n     }\n \n     #[inline]\n@@ -865,7 +867,7 @@ impl<T: ?Sized> Arc<T> {\n     unsafe fn drop_slow(&mut self) {\n         // Destroy the data at this time, even though we may not free the box\n         // allocation itself (there may still be weak pointers lying around).\n-        ptr::drop_in_place(Self::get_mut_unchecked(self));\n+        unsafe { ptr::drop_in_place(Self::get_mut_unchecked(self)) };\n \n         // Drop the weak ref collectively held by all strong references\n         drop(Weak { ptr: self.ptr });\n@@ -917,20 +919,24 @@ impl<T: ?Sized> Arc<T> {\n \n         // Initialize the ArcInner\n         let inner = mem_to_arcinner(mem.ptr.as_ptr());\n-        debug_assert_eq!(Layout::for_value(&*inner), layout);\n+        debug_assert_eq!(unsafe { Layout::for_value(&*inner) }, layout);\n \n-        ptr::write(&mut (*inner).strong, atomic::AtomicUsize::new(1));\n-        ptr::write(&mut (*inner).weak, atomic::AtomicUsize::new(1));\n+        unsafe {\n+            ptr::write(&mut (*inner).strong, atomic::AtomicUsize::new(1));\n+            ptr::write(&mut (*inner).weak, atomic::AtomicUsize::new(1));\n+        }\n \n         inner\n     }\n \n     /// Allocates an `ArcInner<T>` with sufficient space for an unsized inner value.\n     unsafe fn allocate_for_ptr(ptr: *const T) -> *mut ArcInner<T> {\n         // Allocate for the `ArcInner<T>` using the given value.\n-        Self::allocate_for_layout(Layout::for_value(&*ptr), |mem| {\n-            set_data_ptr(ptr as *mut T, mem) as *mut ArcInner<T>\n-        })\n+        unsafe {\n+            Self::allocate_for_layout(Layout::for_value(&*ptr), |mem| {\n+                set_data_ptr(ptr as *mut T, mem) as *mut ArcInner<T>\n+            })\n+        }\n     }\n \n     fn from_box(v: Box<T>) -> Arc<T> {\n@@ -959,9 +965,11 @@ impl<T: ?Sized> Arc<T> {\n impl<T> Arc<[T]> {\n     /// Allocates an `ArcInner<[T]>` with the given length.\n     unsafe fn allocate_for_slice(len: usize) -> *mut ArcInner<[T]> {\n-        Self::allocate_for_layout(Layout::array::<T>(len).unwrap(), |mem| {\n-            ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut ArcInner<[T]>\n-        })\n+        unsafe {\n+            Self::allocate_for_layout(Layout::array::<T>(len).unwrap(), |mem| {\n+                ptr::slice_from_raw_parts_mut(mem as *mut T, len) as *mut ArcInner<[T]>\n+            })\n+        }\n     }\n }\n \n@@ -970,7 +978,9 @@ impl<T> Arc<[T]> {\n /// For a slice/trait object, this sets the `data` field and leaves the rest\n /// unchanged. For a sized raw pointer, this simply sets the pointer.\n unsafe fn set_data_ptr<T: ?Sized, U>(mut ptr: *mut T, data: *mut U) -> *mut T {\n-    ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n+    unsafe {\n+        ptr::write(&mut ptr as *mut _ as *mut *mut u8, data as *mut u8);\n+    }\n     ptr\n }\n \n@@ -979,11 +989,13 @@ impl<T> Arc<[T]> {\n     ///\n     /// Unsafe because the caller must either take ownership or bind `T: Copy`.\n     unsafe fn copy_from_slice(v: &[T]) -> Arc<[T]> {\n-        let ptr = Self::allocate_for_slice(v.len());\n+        unsafe {\n+            let ptr = Self::allocate_for_slice(v.len());\n \n-        ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).data as *mut [T] as *mut T, v.len());\n+            ptr::copy_nonoverlapping(v.as_ptr(), &mut (*ptr).data as *mut [T] as *mut T, v.len());\n \n-        Self::from_ptr(ptr)\n+            Self::from_ptr(ptr)\n+        }\n     }\n \n     /// Constructs an `Arc<[T]>` from an iterator known to be of a certain size.\n@@ -1011,25 +1023,27 @@ impl<T> Arc<[T]> {\n             }\n         }\n \n-        let ptr = Self::allocate_for_slice(len);\n+        unsafe {\n+            let ptr = Self::allocate_for_slice(len);\n \n-        let mem = ptr as *mut _ as *mut u8;\n-        let layout = Layout::for_value(&*ptr);\n+            let mem = ptr as *mut _ as *mut u8;\n+            let layout = Layout::for_value(&*ptr);\n \n-        // Pointer to first element\n-        let elems = &mut (*ptr).data as *mut [T] as *mut T;\n+            // Pointer to first element\n+            let elems = &mut (*ptr).data as *mut [T] as *mut T;\n \n-        let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n+            let mut guard = Guard { mem: NonNull::new_unchecked(mem), elems, layout, n_elems: 0 };\n \n-        for (i, item) in iter.enumerate() {\n-            ptr::write(elems.add(i), item);\n-            guard.n_elems += 1;\n-        }\n+            for (i, item) in iter.enumerate() {\n+                ptr::write(elems.add(i), item);\n+                guard.n_elems += 1;\n+            }\n \n-        // All clear. Forget the guard so it doesn't free the new ArcInner.\n-        mem::forget(guard);\n+            // All clear. Forget the guard so it doesn't free the new ArcInner.\n+            mem::forget(guard);\n \n-        Self::from_ptr(ptr)\n+            Self::from_ptr(ptr)\n+        }\n     }\n }\n \n@@ -1274,7 +1288,7 @@ impl<T: ?Sized> Arc<T> {\n     pub unsafe fn get_mut_unchecked(this: &mut Self) -> &mut T {\n         // We are careful to *not* create a reference covering the \"count\" fields, as\n         // this would alias with concurrent access to the reference counts (e.g. by `Weak`).\n-        &mut (*this.ptr.as_ptr()).data\n+        unsafe { &mut (*this.ptr.as_ptr()).data }\n     }\n \n     /// Determine whether this is the unique reference (including weak refs) to\n@@ -1551,10 +1565,12 @@ impl<T> Weak<T> {\n             Self::new()\n         } else {\n             // See Arc::from_raw for details\n-            let offset = data_offset(ptr);\n-            let fake_ptr = ptr as *mut ArcInner<T>;\n-            let ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n-            Weak { ptr: NonNull::new(ptr).expect(\"Invalid pointer passed to from_raw\") }\n+            unsafe {\n+                let offset = data_offset(ptr);\n+                let fake_ptr = ptr as *mut ArcInner<T>;\n+                let ptr = set_data_ptr(fake_ptr, (ptr as *mut u8).offset(-offset));\n+                Weak { ptr: NonNull::new(ptr).expect(\"Invalid pointer passed to from_raw\") }\n+            }\n         }\n     }\n }\n@@ -2260,7 +2276,7 @@ unsafe fn data_offset<T: ?Sized>(ptr: *const T) -> isize {\n     // Because it is `?Sized`, it will always be the last field in memory.\n     // Note: This is a detail of the current implementation of the compiler,\n     // and is not a guaranteed language detail. Do not rely on it outside of std.\n-    data_offset_align(align_of_val(&*ptr))\n+    unsafe { data_offset_align(align_of_val(&*ptr)) }\n }\n \n /// Computes the offset of the data field within `ArcInner`."}, {"sha": "0d1cc99df47c552e24bccd7b7e22bd63b7ddd352", "filename": "src/liballoc/task.rs", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Ftask.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -60,7 +60,7 @@ impl<W: Wake + Send + Sync + 'static> From<Arc<W>> for RawWaker {\n fn raw_waker<W: Wake + Send + Sync + 'static>(waker: Arc<W>) -> RawWaker {\n     // Increment the reference count of the arc to clone it.\n     unsafe fn clone_waker<W: Wake + Send + Sync + 'static>(waker: *const ()) -> RawWaker {\n-        Arc::incr_strong_count(waker as *const W);\n+        unsafe { Arc::incr_strong_count(waker as *const W) };\n         RawWaker::new(\n             waker as *const (),\n             &RawWakerVTable::new(clone_waker::<W>, wake::<W>, wake_by_ref::<W>, drop_waker::<W>),\n@@ -69,19 +69,20 @@ fn raw_waker<W: Wake + Send + Sync + 'static>(waker: Arc<W>) -> RawWaker {\n \n     // Wake by value, moving the Arc into the Wake::wake function\n     unsafe fn wake<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n-        let waker: Arc<W> = Arc::from_raw(waker as *const W);\n+        let waker: Arc<W> = unsafe { Arc::from_raw(waker as *const W) };\n         <W as Wake>::wake(waker);\n     }\n \n     // Wake by reference, wrap the waker in ManuallyDrop to avoid dropping it\n     unsafe fn wake_by_ref<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n-        let waker: ManuallyDrop<Arc<W>> = ManuallyDrop::new(Arc::from_raw(waker as *const W));\n+        let waker: ManuallyDrop<Arc<W>> =\n+            unsafe { ManuallyDrop::new(Arc::from_raw(waker as *const W)) };\n         <W as Wake>::wake_by_ref(&waker);\n     }\n \n     // Decrement the reference count of the Arc on drop\n     unsafe fn drop_waker<W: Wake + Send + Sync + 'static>(waker: *const ()) {\n-        Arc::decr_strong_count(waker as *const W);\n+        unsafe { Arc::decr_strong_count(waker as *const W) };\n     }\n \n     RawWaker::new("}, {"sha": "95c3b3b18616162feddc05e81bb2ec54f2863bfd", "filename": "src/liballoc/vec.rs", "status": "modified", "additions": 14, "deletions": 11, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fvec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/55479de2993195bedafdc2104db21e52709ed137/src%2Fliballoc%2Fvec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fvec.rs?ref=55479de2993195bedafdc2104db21e52709ed137", "patch": "@@ -465,7 +465,7 @@ impl<T> Vec<T> {\n     /// ```\n     #[stable(feature = \"rust1\", since = \"1.0.0\")]\n     pub unsafe fn from_raw_parts(ptr: *mut T, length: usize, capacity: usize) -> Vec<T> {\n-        Vec { buf: RawVec::from_raw_parts(ptr, capacity), len: length }\n+        unsafe { Vec { buf: RawVec::from_raw_parts(ptr, capacity), len: length } }\n     }\n \n     /// Returns the number of elements the vector can hold without\n@@ -1264,10 +1264,10 @@ impl<T> Vec<T> {\n     /// Appends elements to `Self` from other buffer.\n     #[inline]\n     unsafe fn append_elements(&mut self, other: *const [T]) {\n-        let count = (*other).len();\n+        let count = unsafe { (*other).len() };\n         self.reserve(count);\n         let len = self.len();\n-        ptr::copy_nonoverlapping(other as *const T, self.as_mut_ptr().add(len), count);\n+        unsafe { ptr::copy_nonoverlapping(other as *const T, self.as_mut_ptr().add(len), count) };\n         self.len += count;\n     }\n \n@@ -2965,15 +2965,16 @@ impl<T> Drain<'_, T> {\n     /// Fill that range as much as possible with new elements from the `replace_with` iterator.\n     /// Returns `true` if we filled the entire range. (`replace_with.next()` didn\u2019t return `None`.)\n     unsafe fn fill<I: Iterator<Item = T>>(&mut self, replace_with: &mut I) -> bool {\n-        let vec = self.vec.as_mut();\n+        let vec = unsafe { self.vec.as_mut() };\n         let range_start = vec.len;\n         let range_end = self.tail_start;\n-        let range_slice =\n-            slice::from_raw_parts_mut(vec.as_mut_ptr().add(range_start), range_end - range_start);\n+        let range_slice = unsafe {\n+            slice::from_raw_parts_mut(vec.as_mut_ptr().add(range_start), range_end - range_start)\n+        };\n \n         for place in range_slice {\n             if let Some(new_item) = replace_with.next() {\n-                ptr::write(place, new_item);\n+                unsafe { ptr::write(place, new_item) };\n                 vec.len += 1;\n             } else {\n                 return false;\n@@ -2984,14 +2985,16 @@ impl<T> Drain<'_, T> {\n \n     /// Makes room for inserting more elements before the tail.\n     unsafe fn move_tail(&mut self, additional: usize) {\n-        let vec = self.vec.as_mut();\n+        let vec = unsafe { self.vec.as_mut() };\n         let len = self.tail_start + self.tail_len;\n         vec.buf.reserve(len, additional);\n \n         let new_tail_start = self.tail_start + additional;\n-        let src = vec.as_ptr().add(self.tail_start);\n-        let dst = vec.as_mut_ptr().add(new_tail_start);\n-        ptr::copy(src, dst, self.tail_len);\n+        unsafe {\n+            let src = vec.as_ptr().add(self.tail_start);\n+            let dst = vec.as_mut_ptr().add(new_tail_start);\n+            ptr::copy(src, dst, self.tail_len);\n+        }\n         self.tail_start = new_tail_start;\n     }\n }"}]}