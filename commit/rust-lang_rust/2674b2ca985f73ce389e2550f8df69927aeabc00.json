{"sha": "2674b2ca985f73ce389e2550f8df69927aeabc00", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI2NzRiMmNhOTg1ZjczY2UzODllMjU1MGY4ZGY2OTkyN2FlYWJjMDA=", "commit": {"author": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2015-08-12T03:53:58Z"}, "committer": {"name": "Piotr Czarnecki", "email": "pioczarn@gmail.com", "date": "2016-01-05T09:47:57Z"}, "message": "Implement in-place growth for RawVec", "tree": {"sha": "4910d7c840dc8a85ec9386a58c873d340ede39b7", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/4910d7c840dc8a85ec9386a58c873d340ede39b7"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/2674b2ca985f73ce389e2550f8df69927aeabc00", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/2674b2ca985f73ce389e2550f8df69927aeabc00", "html_url": "https://github.com/rust-lang/rust/commit/2674b2ca985f73ce389e2550f8df69927aeabc00", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/2674b2ca985f73ce389e2550f8df69927aeabc00/comments", "author": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "committer": {"login": "pczarn", "id": 3356767, "node_id": "MDQ6VXNlcjMzNTY3Njc=", "avatar_url": "https://avatars.githubusercontent.com/u/3356767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pczarn", "html_url": "https://github.com/pczarn", "followers_url": "https://api.github.com/users/pczarn/followers", "following_url": "https://api.github.com/users/pczarn/following{/other_user}", "gists_url": "https://api.github.com/users/pczarn/gists{/gist_id}", "starred_url": "https://api.github.com/users/pczarn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pczarn/subscriptions", "organizations_url": "https://api.github.com/users/pczarn/orgs", "repos_url": "https://api.github.com/users/pczarn/repos", "events_url": "https://api.github.com/users/pczarn/events{/privacy}", "received_events_url": "https://api.github.com/users/pczarn/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d4b67cd7cce8e29b22082bc9bc3a667ba3b2e036", "url": "https://api.github.com/repos/rust-lang/rust/commits/d4b67cd7cce8e29b22082bc9bc3a667ba3b2e036", "html_url": "https://github.com/rust-lang/rust/commit/d4b67cd7cce8e29b22082bc9bc3a667ba3b2e036"}], "stats": {"total": 118, "additions": 107, "deletions": 11}, "files": [{"sha": "52bd62f7a660a8da2e5b9a4ab857d32ea8f08fff", "filename": "src/liballoc/raw_vec.rs", "status": "modified", "additions": 107, "deletions": 11, "changes": 118, "blob_url": "https://github.com/rust-lang/rust/blob/2674b2ca985f73ce389e2550f8df69927aeabc00/src%2Fliballoc%2Fraw_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/2674b2ca985f73ce389e2550f8df69927aeabc00/src%2Fliballoc%2Fraw_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Fraw_vec.rs?ref=2674b2ca985f73ce389e2550f8df69927aeabc00", "patch": "@@ -240,6 +240,47 @@ impl<T> RawVec<T> {\n         }\n     }\n \n+    /// Attempts to double the size of the type's backing allocation in place. This is common\n+    /// enough to want to do that it's easiest to just have a dedicated method. Slightly\n+    /// more efficient logic can be provided for this than the general case.\n+    ///\n+    /// Returns true if the reallocation attempt has succeeded, or false otherwise.\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if T is zero-sized on the assumption that you managed to exhaust\n+    ///   all `usize::MAX` slots in your imaginary buffer.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    #[inline(never)]\n+    #[cold]\n+    pub fn double_in_place(&mut self) -> bool {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+            let align = mem::align_of::<T>();\n+\n+            // since we set the capacity to usize::MAX when elem_size is\n+            // 0, getting to here necessarily means the RawVec is overfull.\n+            assert!(elem_size != 0, \"capacity overflow\");\n+\n+            // Since we guarantee that we never allocate more than isize::MAX bytes,\n+            // `elem_size * self.cap <= isize::MAX` as a precondition, so this can't overflow\n+            let new_cap = 2 * self.cap;\n+            let new_alloc_size = new_cap * elem_size;\n+\n+            alloc_guard(new_alloc_size);\n+            let size = heap::reallocate_inplace(self.ptr() as *mut _,\n+                                                self.cap * elem_size,\n+                                                new_alloc_size,\n+                                                align);\n+            if size >= new_alloc_size {\n+                // We can't directly divide `size`.\n+                self.cap = new_cap;\n+            }\n+            size >= new_alloc_size\n+        }\n+    }\n+\n     /// Ensures that the buffer contains at least enough space to hold\n     /// `used_cap + needed_extra_cap` elements. If it doesn't already,\n     /// will reallocate the minimum possible amount of memory necessary.\n@@ -300,6 +341,22 @@ impl<T> RawVec<T> {\n         }\n     }\n \n+    /// Calculates the buffer's new size given that it'll hold `used_cap +\n+    /// needed_extra_cap` elements. This logic is used in amortized reserve methods.\n+    /// Returns `(new_capacity, new_alloc_size)`.\n+    fn amortized_new_size(&self, used_cap: usize, needed_extra_cap: usize) -> (usize, usize) {\n+        let elem_size = mem::size_of::<T>();\n+        // Nothing we can really do about these checks :(\n+        let required_cap = used_cap.checked_add(needed_extra_cap)\n+                                   .expect(\"capacity overflow\");\n+        // Cannot overflow, because `cap <= isize::MAX`, and type of `cap` is `usize`.\n+        let double_cap = self.cap * 2;\n+        // `double_cap` guarantees exponential growth.\n+        let new_cap = cmp::max(double_cap, required_cap);\n+        let new_alloc_size = new_cap.checked_mul(elem_size).expect(\"capacity overflow\");\n+        (new_cap, new_alloc_size)\n+    }\n+\n     /// Ensures that the buffer contains at least enough space to hold\n     /// `used_cap + needed_extra_cap` elements. If it doesn't already have\n     /// enough capacity, will reallocate enough space plus comfortable slack\n@@ -360,17 +417,7 @@ impl<T> RawVec<T> {\n                 return;\n             }\n \n-            // Nothing we can really do about these checks :(\n-            let required_cap = used_cap.checked_add(needed_extra_cap)\n-                                       .expect(\"capacity overflow\");\n-\n-            // Cannot overflow, because `cap <= isize::MAX`, and type of `cap` is `usize`.\n-            let double_cap = self.cap * 2;\n-\n-            // `double_cap` guarantees exponential growth.\n-            let new_cap = cmp::max(double_cap, required_cap);\n-\n-            let new_alloc_size = new_cap.checked_mul(elem_size).expect(\"capacity overflow\");\n+            let (new_cap, new_alloc_size) = self.amortized_new_size(used_cap, needed_extra_cap);\n             // FIXME: may crash and burn on over-reserve\n             alloc_guard(new_alloc_size);\n \n@@ -393,6 +440,55 @@ impl<T> RawVec<T> {\n         }\n     }\n \n+    /// Attempts to ensure that the buffer contains at least enough space to hold\n+    /// `used_cap + needed_extra_cap` elements. If it doesn't already have\n+    /// enough capacity, will reallocate in place enough space plus comfortable slack\n+    /// space to get amortized `O(1)` behaviour. Will limit this behaviour\n+    /// if it would needlessly cause itself to panic.\n+    ///\n+    /// If `used_cap` exceeds `self.cap()`, this may fail to actually allocate\n+    /// the requested space. This is not really unsafe, but the unsafe\n+    /// code *you* write that relies on the behaviour of this function may break.\n+    ///\n+    /// Returns true if the reallocation attempt has succeeded, or false otherwise.\n+    ///\n+    /// # Panics\n+    ///\n+    /// * Panics if the requested capacity exceeds `usize::MAX` bytes.\n+    /// * Panics on 32-bit platforms if the requested capacity exceeds\n+    ///   `isize::MAX` bytes.\n+    pub fn reserve_in_place(&mut self, used_cap: usize, needed_extra_cap: usize) -> bool {\n+        unsafe {\n+            let elem_size = mem::size_of::<T>();\n+            let align = mem::align_of::<T>();\n+\n+            // NOTE: we don't early branch on ZSTs here because we want this\n+            // to actually catch \"asking for more than usize::MAX\" in that case.\n+            // If we make it past the first branch then we are guaranteed to\n+            // panic.\n+\n+            // Don't actually need any more capacity. If the current `cap` is 0, we can't\n+            // reallocate in place.\n+            // Wrapping in case they give a bad `used_cap`\n+            if self.cap().wrapping_sub(used_cap) >= needed_extra_cap || self.cap == 0 {\n+                return false;\n+            }\n+\n+            let (_, new_alloc_size) = self.amortized_new_size(used_cap, needed_extra_cap);\n+            // FIXME: may crash and burn on over-reserve\n+            alloc_guard(new_alloc_size);\n+\n+            let size = heap::reallocate_inplace(self.ptr() as *mut _,\n+                                                self.cap * elem_size,\n+                                                new_alloc_size,\n+                                                align);\n+            if size >= new_alloc_size {\n+                self.cap = new_alloc_size / elem_size;\n+            }\n+            size >= new_alloc_size\n+        }\n+    }\n+\n     /// Shrinks the allocation down to the specified amount. If the given amount\n     /// is 0, actually completely deallocates.\n     ///"}]}