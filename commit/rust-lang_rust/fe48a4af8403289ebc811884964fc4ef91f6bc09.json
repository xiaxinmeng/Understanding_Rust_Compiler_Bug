{"sha": "fe48a4af8403289ebc811884964fc4ef91f6bc09", "node_id": "MDY6Q29tbWl0NzI0NzEyOmZlNDhhNGFmODQwMzI4OWViYzgxMTg4NDk2NGZjNGVmOTFmNmJjMDk=", "commit": {"author": {"name": "Eduard Burtescu", "email": "edy.burt@gmail.com", "date": "2016-04-19T06:11:46Z"}, "committer": {"name": "Eduard Burtescu", "email": "edy.burt@gmail.com", "date": "2016-04-19T13:08:45Z"}, "message": "Compute LLVM-agnostic type layouts in rustc.\n\n# Conflicts:\n#\tsrc/librustc/ty/layout.rs", "tree": {"sha": "54d817ca10ea43601095c408439e566038bfdd73", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/54d817ca10ea43601095c408439e566038bfdd73"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/fe48a4af8403289ebc811884964fc4ef91f6bc09", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/fe48a4af8403289ebc811884964fc4ef91f6bc09", "html_url": "https://github.com/rust-lang/rust/commit/fe48a4af8403289ebc811884964fc4ef91f6bc09", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/fe48a4af8403289ebc811884964fc4ef91f6bc09/comments", "author": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "efd0ea5b20a72a0967f80ea3a63f6dc4d1434ce0", "url": "https://api.github.com/repos/rust-lang/rust/commits/efd0ea5b20a72a0967f80ea3a63f6dc4d1434ce0", "html_url": "https://github.com/rust-lang/rust/commit/efd0ea5b20a72a0967f80ea3a63f6dc4d1434ce0"}], "stats": {"total": 1043, "additions": 1006, "deletions": 37}, "files": [{"sha": "31e32f94ac6cbe05daa5662bd622d384f1e6d427", "filename": "src/librustc/ty/context.rs", "status": "modified", "additions": 24, "deletions": 1, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Fcontext.rs?ref=fe48a4af8403289ebc811884964fc4ef91f6bc09", "patch": "@@ -31,7 +31,7 @@ use hir::FreevarMap;\n use ty::{BareFnTy, InferTy, ParamTy, ProjectionTy, TraitTy};\n use ty::{TyVar, TyVid, IntVar, IntVid, FloatVar, FloatVid};\n use ty::TypeVariants::*;\n-use ty::layout::TargetDataLayout;\n+use ty::layout::{Layout, TargetDataLayout};\n use ty::maps;\n use util::common::MemoizationMap;\n use util::nodemap::{NodeMap, NodeSet, DefIdMap, DefIdSet};\n@@ -56,6 +56,7 @@ pub struct CtxtArenas<'tcx> {\n     bare_fn: TypedArena<BareFnTy<'tcx>>,\n     region: TypedArena<Region>,\n     stability: TypedArena<attr::Stability>,\n+    layout: TypedArena<Layout>,\n \n     // references\n     trait_defs: TypedArena<ty::TraitDef<'tcx>>,\n@@ -70,6 +71,7 @@ impl<'tcx> CtxtArenas<'tcx> {\n             bare_fn: TypedArena::new(),\n             region: TypedArena::new(),\n             stability: TypedArena::new(),\n+            layout: TypedArena::new(),\n \n             trait_defs: TypedArena::new(),\n             adt_defs: TypedArena::new()\n@@ -230,6 +232,7 @@ pub struct TyCtxt<'tcx> {\n     bare_fn_interner: RefCell<FnvHashMap<&'tcx BareFnTy<'tcx>, &'tcx BareFnTy<'tcx>>>,\n     region_interner: RefCell<FnvHashMap<&'tcx Region, &'tcx Region>>,\n     stability_interner: RefCell<FnvHashMap<&'tcx attr::Stability, &'tcx attr::Stability>>,\n+    layout_interner: RefCell<FnvHashMap<&'tcx Layout, &'tcx Layout>>,\n \n     pub dep_graph: DepGraph,\n \n@@ -423,6 +426,9 @@ pub struct TyCtxt<'tcx> {\n \n     /// Data layout specification for the current target.\n     pub data_layout: TargetDataLayout,\n+\n+    /// Cache for layouts computed from types.\n+    pub layout_cache: RefCell<FnvHashMap<Ty<'tcx>, &'tcx Layout>>,\n }\n \n impl<'tcx> TyCtxt<'tcx> {\n@@ -504,6 +510,20 @@ impl<'tcx> TyCtxt<'tcx> {\n         interned\n     }\n \n+    pub fn intern_layout(&self, layout: Layout) -> &'tcx Layout {\n+        if let Some(layout) = self.layout_interner.borrow().get(&layout) {\n+            return layout;\n+        }\n+\n+        let interned = self.arenas.layout.alloc(layout);\n+        if let Some(prev) = self.layout_interner\n+                                .borrow_mut()\n+                                .insert(interned, interned) {\n+            bug!(\"Tried to overwrite interned Layout: {:?}\", prev)\n+        }\n+        interned\n+    }\n+\n     pub fn store_free_region_map(&self, id: NodeId, map: FreeRegionMap) {\n         if self.free_region_maps.borrow_mut().insert(id, map).is_some() {\n             bug!(\"Tried to overwrite interned FreeRegionMap for NodeId {:?}\", id)\n@@ -547,6 +567,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             bare_fn_interner: RefCell::new(FnvHashMap()),\n             region_interner: RefCell::new(FnvHashMap()),\n             stability_interner: RefCell::new(FnvHashMap()),\n+            layout_interner: RefCell::new(FnvHashMap()),\n             dep_graph: dep_graph.clone(),\n             types: common_types,\n             named_region_map: named_region_map,\n@@ -595,6 +616,7 @@ impl<'tcx> TyCtxt<'tcx> {\n             fragment_infos: RefCell::new(DefIdMap()),\n             crate_name: token::intern_and_get_ident(crate_name),\n             data_layout: data_layout,\n+            layout_cache: RefCell::new(FnvHashMap()),\n        }, f)\n     }\n }\n@@ -768,6 +790,7 @@ impl<'tcx> TyCtxt<'tcx> {\n         println!(\"BareFnTy interner: #{}\", self.bare_fn_interner.borrow().len());\n         println!(\"Region interner: #{}\", self.region_interner.borrow().len());\n         println!(\"Stability interner: #{}\", self.stability_interner.borrow().len());\n+        println!(\"Layout interner: #{}\", self.layout_interner.borrow().len());\n     }\n }\n "}, {"sha": "494335933b63168a02384c5e553e6b0f0acd2ed6", "filename": "src/librustc/ty/layout.rs", "status": "modified", "additions": 961, "deletions": 8, "changes": 969, "blob_url": "https://github.com/rust-lang/rust/blob/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Flayout.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Flayout.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Flayout.rs?ref=fe48a4af8403289ebc811884964fc4ef91f6bc09", "patch": "@@ -8,9 +8,22 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+pub use self::Integer::*;\n+pub use self::Layout::*;\n+pub use self::Primitive::*;\n+\n+use infer::{InferCtxt, drain_fulfillment_cx_or_panic};\n use session::Session;\n+use traits;\n+use ty::{self, Ty, TyCtxt, TypeFoldable};\n+\n+use syntax::ast::{FloatTy, IntTy, UintTy};\n+use syntax::attr;\n+use syntax::codemap::DUMMY_SP;\n \n use std::cmp;\n+use std::fmt;\n+use std::i64;\n \n /// Parsed [Data layout](http://llvm.org/docs/LangRef.html#data-layout)\n /// for a target, which contains everything needed to compute layouts.\n@@ -27,7 +40,7 @@ pub struct TargetDataLayout {\n     pub pointer_align: Align,\n     pub aggregate_align: Align,\n \n-    /// Alignments for vector types, sorted by size.\n+    /// Alignments for vector types.\n     pub vector_align: Vec<(Size, Align)>\n }\n \n@@ -45,8 +58,10 @@ impl Default for TargetDataLayout {\n             pointer_size: Size::from_bits(64),\n             pointer_align: Align::from_bits(64, 64).unwrap(),\n             aggregate_align: Align::from_bits(0, 64).unwrap(),\n-            vector_align: vec![(Size::from_bits(128),\n-                                Align::from_bits(128, 128).unwrap())]\n+            vector_align: vec![\n+                (Size::from_bits(64), Align::from_bits(64, 64).unwrap()),\n+                (Size::from_bits(128), Align::from_bits(128, 128).unwrap())\n+            ]\n         }\n     }\n }\n@@ -122,9 +137,6 @@ impl TargetDataLayout {\n             }\n         }\n \n-        // Sort vector alignments by size.\n-        dl.vector_align.sort_by_key(|&(s, _)| s);\n-\n         // Perform consistency checks against the Target information.\n         let endian_str = match dl.endian {\n             Endian::Little => \"little\",\n@@ -144,6 +156,33 @@ impl TargetDataLayout {\n \n         dl\n     }\n+\n+    /// Return exclusive upper bound on object size.\n+    ///\n+    /// The theoretical maximum object size is defined as the maximum positive `isize` value.\n+    /// This ensures that the `offset` semantics remain well-defined by allowing it to correctly\n+    /// index every address within an object along with one byte past the end, along with allowing\n+    /// `isize` to store the difference between any two pointers into an object.\n+    ///\n+    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer\n+    /// to represent object size in bits. It would need to be 1 << 61 to account for this, but is\n+    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n+    /// address space on 64-bit ARMv8 and x86_64.\n+    pub fn obj_size_bound(&self) -> u64 {\n+        match self.pointer_size.bits() {\n+            32 => 1 << 31,\n+            64 => 1 << 47,\n+            bits => bug!(\"obj_size_bound: unknown pointer bit size {}\", bits)\n+        }\n+    }\n+\n+    pub fn ptr_sized_integer(&self) -> Integer {\n+        match self.pointer_size.bits() {\n+            32 => I32,\n+            64 => I64,\n+            bits => bug!(\"ptr_sized_integer: unknown pointer bit size {}\", bits)\n+        }\n+    }\n }\n \n /// Endianness of the target, which must match cfg(target-endian).\n@@ -154,7 +193,7 @@ pub enum Endian {\n }\n \n /// Size of a type in bytes.\n-#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord)]\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n pub struct Size {\n     raw: u64\n }\n@@ -180,12 +219,40 @@ impl Size {\n     pub fn bits(self) -> u64 {\n         self.bytes() * 8\n     }\n+\n+    pub fn abi_align(self, align: Align) -> Size {\n+        let mask = align.abi() - 1;\n+        Size::from_bytes((self.bytes() + mask) & !mask)\n+    }\n+\n+    pub fn checked_add(self, offset: Size, dl: &TargetDataLayout) -> Option<Size> {\n+        // Each Size is less than dl.obj_size_bound(), so the sum is\n+        // also less than 1 << 62 (and therefore can't overflow).\n+        let bytes = self.bytes() + offset.bytes();\n+\n+        if bytes < dl.obj_size_bound() {\n+            Some(Size::from_bytes(bytes))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn checked_mul(self, count: u64, dl: &TargetDataLayout) -> Option<Size> {\n+        // Each Size is less than dl.obj_size_bound(), so the sum is\n+        // also less than 1 << 62 (and therefore can't overflow).\n+        match self.bytes().checked_mul(count) {\n+            Some(bytes) if bytes < dl.obj_size_bound() => {\n+                Some(Size::from_bytes(bytes))\n+            }\n+            _ => None\n+        }\n+    }\n }\n \n /// Alignment of a type in bytes, both ABI-mandated and preferred.\n /// Since alignments are always powers of 2, we can pack both in one byte,\n /// giving each a nibble (4 bits) for a maximum alignment of 2^15 = 32768.\n-#[derive(Copy, Clone)]\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n pub struct Align {\n     raw: u8\n }\n@@ -246,3 +313,889 @@ impl Align {\n         }\n     }\n }\n+\n+/// Integers, also used for enum discriminants.\n+#[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Debug)]\n+pub enum Integer {\n+    I1,\n+    I8,\n+    I16,\n+    I32,\n+    I64\n+}\n+\n+impl Integer {\n+    /// Find the smallest Integer type which can represent the signed value.\n+    pub fn fit_signed(x: i64) -> Integer {\n+        match x {\n+            -0x0000_0001...0x0000_0000 => I1,\n+            -0x0000_0080...0x0000_007f => I8,\n+            -0x0000_8000...0x0000_7fff => I16,\n+            -0x8000_0000...0x7fff_ffff => I32,\n+            _ => I64\n+        }\n+    }\n+\n+    /// Find the smallest Integer type which can represent the unsigned value.\n+    pub fn fit_unsigned(x: u64) -> Integer {\n+        match x {\n+            0...0x0000_0001 => I1,\n+            0...0x0000_00ff => I8,\n+            0...0x0000_ffff => I16,\n+            0...0xffff_ffff => I32,\n+            _ => I64\n+        }\n+    }\n+\n+    /// Get the Integer type from an attr::IntType.\n+    pub fn from_attr(dl: &TargetDataLayout, ity: attr::IntType) -> Integer {\n+        match ity {\n+            attr::SignedInt(IntTy::I8) | attr::UnsignedInt(UintTy::U8) => I8,\n+            attr::SignedInt(IntTy::I16) | attr::UnsignedInt(UintTy::U16) => I16,\n+            attr::SignedInt(IntTy::I32) | attr::UnsignedInt(UintTy::U32) => I32,\n+            attr::SignedInt(IntTy::I64) | attr::UnsignedInt(UintTy::U64) => I64,\n+            attr::SignedInt(IntTy::Is) | attr::UnsignedInt(UintTy::Us) => {\n+                dl.ptr_sized_integer()\n+            }\n+        }\n+    }\n+\n+    /// Find the appropriate Integer type and signedness for the given\n+    /// signed discriminant range and #[repr] attribute.\n+    /// N.B.: u64 values above i64::MAX will be treated as signed, but\n+    /// that shouldn't affect anything, other than maybe debuginfo.\n+    pub fn repr_discr(tcx: &TyCtxt, hint: attr::ReprAttr, min: i64, max: i64)\n+                      -> (Integer, bool) {\n+        // Theoretically, negative values could be larger in unsigned representation\n+        // than the unsigned representation of the signed minimum. However, if there\n+        // are any negative values, the only valid unsigned representation is u64\n+        // which can fit all i64 values, so the result remains unaffected.\n+        let unsigned_fit = Integer::fit_unsigned(cmp::max(min as u64, max as u64));\n+        let signed_fit = cmp::max(Integer::fit_signed(min), Integer::fit_signed(max));\n+\n+        let at_least = match hint {\n+            attr::ReprInt(span, ity) => {\n+                let discr = Integer::from_attr(&tcx.data_layout, ity);\n+                let fit = if ity.is_signed() { signed_fit } else { unsigned_fit };\n+                if discr < fit {\n+                    span_bug!(span, \"representation hint insufficient for discriminant range\")\n+                }\n+                return (discr, ity.is_signed());\n+            }\n+            attr::ReprExtern => {\n+                match &tcx.sess.target.target.arch[..] {\n+                    // WARNING: the ARM EABI has two variants; the one corresponding\n+                    // to `at_least == I32` appears to be used on Linux and NetBSD,\n+                    // but some systems may use the variant corresponding to no\n+                    // lower bound.  However, we don't run on those yet...?\n+                    \"arm\" => I32,\n+                    _ => I32,\n+                }\n+            }\n+            attr::ReprAny => I8,\n+            attr::ReprPacked => {\n+                bug!(\"Integer::repr_discr: found #[repr(packed)] on an enum\");\n+            }\n+            attr::ReprSimd => {\n+                bug!(\"Integer::repr_discr: found #[repr(simd)] on an enum\");\n+            }\n+        };\n+\n+        // If there are no negative values, we can use the unsigned fit.\n+        if min >= 0 {\n+            (cmp::max(unsigned_fit, at_least), false)\n+        } else {\n+            (cmp::max(signed_fit, at_least), true)\n+        }\n+    }\n+}\n+\n+/// Fundamental unit of memory access and layout.\n+#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]\n+pub enum Primitive {\n+    Int(Integer),\n+    F32,\n+    F64,\n+    Pointer\n+}\n+\n+impl Primitive {\n+    pub fn size(self, dl: &TargetDataLayout) -> Size {\n+        match self {\n+            Int(I1) | Int(I8) => Size::from_bits(8),\n+            Int(I16) => Size::from_bits(16),\n+            Int(I32) | F32 => Size::from_bits(32),\n+            Int(I64) | F64 => Size::from_bits(64),\n+            Pointer => dl.pointer_size\n+        }\n+    }\n+\n+    pub fn align(self, dl: &TargetDataLayout) -> Align {\n+        match self {\n+            Int(I1) => dl.i1_align,\n+            Int(I8) => dl.i8_align,\n+            Int(I16) => dl.i16_align,\n+            Int(I32) => dl.i32_align,\n+            Int(I64) => dl.i64_align,\n+            F32 => dl.f32_align,\n+            F64 => dl.f64_align,\n+            Pointer => dl.pointer_align\n+        }\n+    }\n+}\n+\n+/// Path through fields of nested structures.\n+// FIXME(eddyb) use small vector optimization for the common case.\n+pub type FieldPath = Vec<u32>;\n+\n+/// A structure, a product type in ADT terms.\n+#[derive(PartialEq, Eq, Hash, Debug)]\n+pub struct Struct {\n+    pub align: Align,\n+\n+    /// If true, no alignment padding is used.\n+    pub packed: bool,\n+\n+    /// If true, the size is exact, otherwise it's only a lower bound.\n+    pub sized: bool,\n+\n+    /// Offsets for the first byte after each field.\n+    /// That is, field_offset(i) = offset_after_field[i - 1] and the\n+    /// whole structure's size is the last offset, excluding padding.\n+    // FIXME(eddyb) use small vector optimization for the common case.\n+    pub offset_after_field: Vec<Size>\n+}\n+\n+impl Struct {\n+    pub fn new(dl: &TargetDataLayout, packed: bool) -> Struct {\n+        Struct {\n+            align: if packed { dl.i8_align } else { dl.aggregate_align },\n+            packed: packed,\n+            sized: true,\n+            offset_after_field: vec![]\n+        }\n+    }\n+\n+    /// Extend the Struct with more fields.\n+    pub fn extend<'a, 'tcx, I>(&mut self, dl: &TargetDataLayout,\n+                               fields: I,\n+                               scapegoat: Ty<'tcx>)\n+                               -> Result<(), LayoutError<'tcx>>\n+    where I: Iterator<Item=Result<&'a Layout, LayoutError<'tcx>>> {\n+        self.offset_after_field.reserve(fields.size_hint().0);\n+\n+        for field in fields {\n+            if !self.sized {\n+                bug!(\"Struct::compute: field #{} of `{}` comes after unsized field\",\n+                     self.offset_after_field.len(), scapegoat);\n+            }\n+\n+            let field = field?;\n+            if field.is_unsized() {\n+                self.sized = false;\n+            }\n+\n+            // Invariant: offset < dl.obj_size_bound() <= 1<<61\n+            let mut offset = if !self.packed {\n+                let align = field.align(dl);\n+                self.align = self.align.max(align);\n+                self.offset_after_field.last_mut().map_or(Size::from_bytes(0), |last| {\n+                    *last = last.abi_align(align);\n+                    *last\n+                })\n+            } else {\n+                self.offset_after_field.last().map_or(Size::from_bytes(0), |&last| last)\n+            };\n+\n+            offset = offset.checked_add(field.size(dl), dl)\n+                           .map_or(Err(LayoutError::SizeOverflow(scapegoat)), Ok)?;\n+\n+            self.offset_after_field.push(offset);\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Get the size without trailing alignment padding.\n+    pub fn min_size(&self) -> Size {\n+        self.offset_after_field.last().map_or(Size::from_bytes(0), |&last| last)\n+    }\n+\n+    /// Get the size with trailing aligment padding.\n+    pub fn stride(&self) -> Size {\n+        self.min_size().abi_align(self.align)\n+    }\n+\n+    /// Determine whether a structure would be zero-sized, given its fields.\n+    pub fn would_be_zero_sized<'a, 'tcx, I>(dl: &TargetDataLayout, fields: I)\n+                                            -> Result<bool, LayoutError<'tcx>>\n+    where I: Iterator<Item=Result<&'a Layout, LayoutError<'tcx>>> {\n+        for field in fields {\n+            let field = field?;\n+            if field.is_unsized() || field.size(dl).bytes() > 0 {\n+                return Ok(false);\n+            }\n+        }\n+        Ok(true)\n+    }\n+\n+    /// Find the path leading to a non-zero leaf field, starting from\n+    /// the given type and recursing through aggregates.\n+    // FIXME(eddyb) track value ranges and traverse already optimized enums.\n+    pub fn non_zero_field_in_type<'a, 'tcx>(infcx: &InferCtxt<'a, 'tcx>,\n+                                            ty: Ty<'tcx>)\n+                                            -> Result<Option<FieldPath>, LayoutError<'tcx>> {\n+        let tcx = infcx.tcx;\n+        match (ty.layout(infcx)?, &ty.sty) {\n+            (&Scalar { non_zero: true, .. }, _) => Ok(Some(vec![])),\n+            (&FatPointer { non_zero: true, .. }, _) => {\n+                Ok(Some(vec![FAT_PTR_ADDR as u32]))\n+            }\n+\n+            // Is this the NonZero lang item wrapping a pointer or integer type?\n+            (&Univariant { non_zero: true, .. }, &ty::TyStruct(def, substs)) => {\n+                let fields = &def.struct_variant().fields;\n+                assert_eq!(fields.len(), 1);\n+                let ty = normalize_associated_type(infcx, fields[0].ty(tcx, substs));\n+                match *ty.layout(infcx)? {\n+                    // FIXME(eddyb) also allow floating-point types here.\n+                    Scalar { value: Int(_), non_zero: false } |\n+                    Scalar { value: Pointer, non_zero: false } => {\n+                        Ok(Some(vec![0]))\n+                    }\n+                    FatPointer { non_zero: false, .. } => {\n+                        Ok(Some(vec![FAT_PTR_ADDR as u32, 0]))\n+                    }\n+                    _ => Ok(None)\n+                }\n+            }\n+\n+            // Perhaps one of the fields of this struct is non-zero\n+            // let's recurse and find out\n+            (_, &ty::TyStruct(def, substs)) => {\n+                Struct::non_zero_field_path(infcx, def.struct_variant().fields\n+                                                      .iter().map(|field| {\n+                    normalize_associated_type(infcx, field.ty(tcx, substs))\n+                }))\n+            }\n+\n+            // Perhaps one of the upvars of this closure is non-zero\n+            // Let's recurse and find out!\n+            (_, &ty::TyClosure(_, box ty::ClosureSubsts { upvar_tys: ref tys, .. })) |\n+            // Can we use one of the fields in this tuple?\n+            (_, &ty::TyTuple(ref tys)) => {\n+                Struct::non_zero_field_path(infcx, tys.iter().cloned())\n+            }\n+\n+            // Is this a fixed-size array of something non-zero\n+            // with at least one element?\n+            (_, &ty::TyArray(ety, d)) if d > 0 => {\n+                Struct::non_zero_field_path(infcx, Some(ety).into_iter())\n+            }\n+\n+            // Anything else is not a non-zero type.\n+            _ => Ok(None)\n+        }\n+    }\n+\n+    /// Find the path leading to a non-zero leaf field, starting from\n+    /// the given set of fields and recursing through aggregates.\n+    pub fn non_zero_field_path<'a, 'tcx, I>(infcx: &InferCtxt<'a, 'tcx>,\n+                                            fields: I)\n+                                            -> Result<Option<FieldPath>, LayoutError<'tcx>>\n+    where I: Iterator<Item=Ty<'tcx>> {\n+        for (i, ty) in fields.enumerate() {\n+            if let Some(mut path) = Struct::non_zero_field_in_type(infcx, ty)? {\n+                path.push(i as u32);\n+                return Ok(Some(path));\n+            }\n+        }\n+        Ok(None)\n+    }\n+}\n+\n+/// The first half of a fat pointer.\n+/// - For a trait object, this is the address of the box.\n+/// - For a slice, this is the base address.\n+pub const FAT_PTR_ADDR: usize = 0;\n+\n+/// The second half of a fat pointer.\n+/// - For a trait object, this is the address of the vtable.\n+/// - For a slice, this is the length.\n+pub const FAT_PTR_EXTRA: usize = 1;\n+\n+/// Type layout, from which size and alignment can be cheaply computed.\n+/// For ADTs, it also includes field placement and enum optimizations.\n+/// NOTE: Because Layout is interned, redundant information should be\n+/// kept to a minimum, e.g. it includes no sub-component Ty or Layout.\n+#[derive(Debug, PartialEq, Eq, Hash)]\n+pub enum Layout {\n+    /// TyBool, TyChar, TyInt, TyUint, TyFloat, TyRawPtr, TyRef or TyFnPtr.\n+    Scalar {\n+        value: Primitive,\n+        // If true, the value cannot represent a bit pattern of all zeroes.\n+        non_zero: bool\n+    },\n+\n+    /// SIMD vectors, from TyStruct marked with #[repr(simd)].\n+    Vector {\n+        element: Primitive,\n+        count: u64\n+    },\n+\n+    /// TyArray, TySlice or TyStr.\n+    Array {\n+        /// If true, the size is exact, otherwise it's only a lower bound.\n+        sized: bool,\n+        align: Align,\n+        size: Size\n+    },\n+\n+    /// TyRawPtr or TyRef with a !Sized pointee.\n+    FatPointer {\n+        metadata: Primitive,\n+        // If true, the pointer cannot be null.\n+        non_zero: bool\n+    },\n+\n+    // Remaining variants are all ADTs such as TyStruct, TyEnum or TyTuple.\n+\n+    /// C-like enums; basically an integer.\n+    CEnum {\n+        discr: Integer,\n+        signed: bool,\n+        // Inclusive discriminant range.\n+        // If min > max, it represents min...u64::MAX followed by 0...max.\n+        // FIXME(eddyb) always use the shortest range, e.g. by finding\n+        // the largest space between two consecutive discriminants and\n+        // taking everything else as the (shortest) discriminant range.\n+        min: u64,\n+        max: u64\n+    },\n+\n+    /// Single-case enums, and structs/tuples.\n+    Univariant {\n+        variant: Struct,\n+        // If true, the structure is NonZero.\n+        // FIXME(eddyb) use a newtype Layout kind for this.\n+        non_zero: bool\n+    },\n+\n+    /// General-case enums: for each case there is a struct, and they\n+    /// all start with a field for the discriminant.\n+    General {\n+        discr: Integer,\n+        variants: Vec<Struct>,\n+        size: Size,\n+        align: Align\n+    },\n+\n+    /// Two cases distinguished by a nullable pointer: the case with discriminant\n+    /// `nndiscr` must have single field which is known to be nonnull due to its type.\n+    /// The other case is known to be zero sized. Hence we represent the enum\n+    /// as simply a nullable pointer: if not null it indicates the `nndiscr` variant,\n+    /// otherwise it indicates the other case.\n+    ///\n+    /// For example, `std::option::Option` instantiated at a safe pointer type\n+    /// is represented such that `None` is a null pointer and `Some` is the\n+    /// identity function.\n+    RawNullablePointer {\n+        nndiscr: u64,\n+        value: Primitive\n+    },\n+\n+    /// Two cases distinguished by a nullable pointer: the case with discriminant\n+    /// `nndiscr` is represented by the struct `nonnull`, where the `discrfield`th\n+    /// field is known to be nonnull due to its type; if that field is null, then\n+    /// it represents the other case, which is known to be zero sized.\n+    StructWrappedNullablePointer {\n+        nndiscr: u64,\n+        nonnull: Struct,\n+        // N.B. There is a 0 at the start, for LLVM GEP through a pointer.\n+        discrfield: FieldPath\n+    }\n+}\n+\n+#[derive(Copy, Clone, Debug)]\n+pub enum LayoutError<'tcx> {\n+    Unknown(Ty<'tcx>),\n+    SizeOverflow(Ty<'tcx>)\n+}\n+\n+impl<'tcx> fmt::Display for LayoutError<'tcx> {\n+    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n+        match *self {\n+            LayoutError::Unknown(ty) => {\n+                write!(f, \"the type `{:?}` has an unknown layout\", ty)\n+            }\n+            LayoutError::SizeOverflow(ty) => {\n+                write!(f, \"the type `{:?}` is too big for the current architecture\", ty)\n+            }\n+        }\n+    }\n+}\n+\n+/// Helper function for normalizing associated types in an inference context.\n+fn normalize_associated_type<'a, 'tcx>(infcx: &InferCtxt<'a, 'tcx>,\n+                                       ty: Ty<'tcx>)\n+                                       -> Ty<'tcx> {\n+    if !ty.has_projection_types() {\n+        return ty;\n+    }\n+\n+    let mut selcx = traits::SelectionContext::new(infcx);\n+    let cause = traits::ObligationCause::dummy();\n+    let traits::Normalized { value: result, obligations } =\n+        traits::normalize(&mut selcx, cause, &ty);\n+\n+    let mut fulfill_cx = traits::FulfillmentContext::new();\n+\n+    for obligation in obligations {\n+        fulfill_cx.register_predicate_obligation(infcx, obligation);\n+    }\n+\n+    drain_fulfillment_cx_or_panic(DUMMY_SP, infcx, &mut fulfill_cx, &result)\n+}\n+\n+impl Layout {\n+    pub fn compute_uncached<'a, 'tcx>(ty: Ty<'tcx>,\n+                                      infcx: &InferCtxt<'a, 'tcx>)\n+                                      -> Result<Layout, LayoutError<'tcx>> {\n+        let tcx = infcx.tcx;\n+        let dl = &tcx.data_layout;\n+        assert!(!ty.has_infer_types());\n+\n+        let layout = match ty.sty {\n+            // Basic scalars.\n+            ty::TyBool => Scalar { value: Int(I1), non_zero: false },\n+            ty::TyChar => Scalar { value: Int(I32), non_zero: false },\n+            ty::TyInt(ity) => {\n+                Scalar {\n+                    value: Int(Integer::from_attr(dl, attr::SignedInt(ity))),\n+                    non_zero: false\n+                }\n+            }\n+            ty::TyUint(ity) => {\n+                Scalar {\n+                    value: Int(Integer::from_attr(dl, attr::UnsignedInt(ity))),\n+                    non_zero: false\n+                }\n+            }\n+            ty::TyFloat(FloatTy::F32) => Scalar { value: F32, non_zero: false },\n+            ty::TyFloat(FloatTy::F64) => Scalar { value: F64, non_zero: false },\n+            ty::TyFnPtr(_) => Scalar { value: Pointer, non_zero: true },\n+\n+            // Potentially-fat pointers.\n+            ty::TyBox(pointee) |\n+            ty::TyRef(_, ty::TypeAndMut { ty: pointee, .. }) |\n+            ty::TyRawPtr(ty::TypeAndMut { ty: pointee, .. }) => {\n+                let non_zero = !ty.is_unsafe_ptr();\n+                if pointee.is_sized(&infcx.parameter_environment, DUMMY_SP) {\n+                    Scalar { value: Pointer, non_zero: non_zero }\n+                } else {\n+                    let unsized_part = tcx.struct_tail(pointee);\n+                    let meta = match unsized_part.sty {\n+                        ty::TySlice(_) | ty::TyStr => {\n+                            Int(dl.ptr_sized_integer())\n+                        }\n+                        ty::TyTrait(_) => Pointer,\n+                        _ => return Err(LayoutError::Unknown(unsized_part))\n+                    };\n+                    FatPointer { metadata: meta, non_zero: non_zero }\n+                }\n+            }\n+\n+            // Arrays and slices.\n+            ty::TyArray(element, count) => {\n+                let element = element.layout(infcx)?;\n+                Array {\n+                    sized: true,\n+                    align: element.align(dl),\n+                    size: element.size(dl).checked_mul(count as u64, dl)\n+                                 .map_or(Err(LayoutError::SizeOverflow(ty)), Ok)?\n+                }\n+            }\n+            ty::TySlice(element) => {\n+                Array {\n+                    sized: false,\n+                    align: element.layout(infcx)?.align(dl),\n+                    size: Size::from_bytes(0)\n+                }\n+            }\n+            ty::TyStr => {\n+                Array {\n+                    sized: false,\n+                    align: dl.i8_align,\n+                    size: Size::from_bytes(0)\n+                }\n+            }\n+\n+            // Odd unit types.\n+            ty::TyFnDef(..) => {\n+                Univariant {\n+                    variant: Struct::new(dl, false),\n+                    non_zero: false\n+                }\n+            }\n+            ty::TyTrait(_) => {\n+                let mut unit = Struct::new(dl, false);\n+                unit.sized = false;\n+                Univariant { variant: unit, non_zero: false }\n+            }\n+\n+            // Tuples.\n+            ty::TyClosure(_, box ty::ClosureSubsts { upvar_tys: ref tys, .. }) |\n+            ty::TyTuple(ref tys) => {\n+                let mut st = Struct::new(dl, false);\n+                st.extend(dl, tys.iter().map(|ty| ty.layout(infcx)), ty)?;\n+                Univariant { variant: st, non_zero: false }\n+            }\n+\n+            // ADTs.\n+            ty::TyStruct(def, substs) => {\n+                if ty.is_simd() {\n+                    // SIMD vector types.\n+                    let element = ty.simd_type(tcx);\n+                    match *element.layout(infcx)? {\n+                        Scalar { value, .. } => {\n+                            return Ok(Vector {\n+                                element: value,\n+                                count: ty.simd_size(tcx) as u64\n+                            });\n+                        }\n+                        _ => {\n+                            tcx.sess.fatal(&format!(\"monomorphising SIMD type `{}` with \\\n+                                                     a non-machine element type `{}`\",\n+                                                    ty, element));\n+                        }\n+                    }\n+                }\n+                let fields = def.struct_variant().fields.iter().map(|field| {\n+                    normalize_associated_type(infcx, field.ty(tcx, substs))\n+                        .layout(infcx)\n+                });\n+                let packed = tcx.lookup_packed(def.did);\n+                let mut st = Struct::new(dl, packed);\n+                st.extend(dl, fields, ty)?;\n+\n+                // FIXME(16758) don't add a drop flag to unsized structs, as it\n+                // won't actually be in the location we say it is because it'll be after\n+                // the unsized field. Several other pieces of code assume that the unsized\n+                // field is definitely the last one.\n+                if def.dtor_kind().has_drop_flag() &&\n+                   ty.is_sized(&infcx.parameter_environment, DUMMY_SP) {\n+                    st.extend(dl, Some(Ok(&Scalar {\n+                        value: Int(I8),\n+                        non_zero: false\n+                    })).into_iter(), ty)?;\n+                }\n+                Univariant {\n+                    variant: st,\n+                    non_zero: Some(def.did) == tcx.lang_items.non_zero()\n+                }\n+            }\n+            ty::TyEnum(def, substs) => {\n+                let hint = *tcx.lookup_repr_hints(def.did).get(0)\n+                    .unwrap_or(&attr::ReprAny);\n+\n+                let dtor = def.dtor_kind().has_drop_flag();\n+                let drop_flag = if dtor {\n+                    Some(Scalar { value: Int(I8), non_zero: false })\n+                } else {\n+                    None\n+                };\n+\n+                if def.variants.is_empty() {\n+                    // Uninhabitable; represent as unit\n+                    // (Typechecking will reject discriminant-sizing attrs.)\n+                    assert_eq!(hint, attr::ReprAny);\n+\n+                    let mut st = Struct::new(dl, false);\n+                    st.extend(dl, drop_flag.iter().map(Ok), ty)?;\n+                    return Ok(Univariant { variant: st, non_zero: false });\n+                }\n+\n+                if !dtor && def.variants.iter().all(|v| v.fields.is_empty()) {\n+                    // All bodies empty -> intlike\n+                    let (mut min, mut max) = (i64::MAX, i64::MIN);\n+                    for v in &def.variants {\n+                        let x = v.disr_val.to_u64_unchecked() as i64;\n+                        if x < min { min = x; }\n+                        if x > max { max = x; }\n+                    }\n+\n+                    let (discr, signed) = Integer::repr_discr(tcx, hint, min, max);\n+                    return Ok(CEnum {\n+                        discr: discr,\n+                        signed: signed,\n+                        min: min as u64,\n+                        max: max as u64\n+                    });\n+                }\n+\n+                // Since there's at least one\n+                // non-empty body, explicit discriminants should have\n+                // been rejected by a checker before this point.\n+                for (i, v) in def.variants.iter().enumerate() {\n+                    if i as u64 != v.disr_val.to_u64_unchecked() {\n+                        bug!(\"non-C-like enum {} with specified discriminants\",\n+                             tcx.item_path_str(def.did));\n+                    }\n+                }\n+\n+                if def.variants.len() == 1 {\n+                    // Equivalent to a struct/tuple/newtype.\n+                    // (Typechecking will reject discriminant-sizing attrs.)\n+                    assert_eq!(hint, attr::ReprAny);\n+                    let fields = def.variants[0].fields.iter().map(|field| {\n+                        normalize_associated_type(infcx, field.ty(tcx, substs))\n+                            .layout(infcx)\n+                    });\n+                    let mut st = Struct::new(dl, false);\n+                    st.extend(dl, fields.chain(drop_flag.iter().map(Ok)), ty)?;\n+                    return Ok(Univariant { variant: st, non_zero: false });\n+                }\n+\n+                // Cache the substituted and normalized variant field types.\n+                let variants = def.variants.iter().map(|v| {\n+                    v.fields.iter().map(|field| {\n+                        normalize_associated_type(infcx, field.ty(tcx, substs))\n+                    }).collect::<Vec<_>>()\n+                }).collect::<Vec<_>>();\n+\n+                if !dtor && variants.len() == 2 && hint == attr::ReprAny {\n+                    // Nullable pointer optimization\n+                    for discr in 0..2 {\n+                        let other_fields = variants[1 - discr].iter().map(|ty| {\n+                            ty.layout(infcx)\n+                        });\n+                        if !Struct::would_be_zero_sized(dl, other_fields)? {\n+                            continue;\n+                        }\n+                        let path = Struct::non_zero_field_path(infcx,\n+                            variants[discr].iter().cloned())?;\n+                        let mut path = if let Some(p) = path { p } else { continue };\n+\n+                        // FIXME(eddyb) should take advantage of a newtype.\n+                        if path == &[0] && variants[discr].len() == 1 {\n+                            match *variants[discr][0].layout(infcx)? {\n+                                Scalar { value, .. } => {\n+                                    return Ok(RawNullablePointer {\n+                                        nndiscr: discr as u64,\n+                                        value: value\n+                                    });\n+                                }\n+                                _ => {\n+                                    bug!(\"Layout::compute: `{}`'s non-zero \\\n+                                          `{}` field not scalar?!\",\n+                                         ty, variants[discr][0])\n+                                }\n+                            }\n+                        }\n+\n+                        path.push(0); // For GEP through a pointer.\n+                        path.reverse();\n+                        let mut st = Struct::new(dl, false);\n+                        st.extend(dl, variants[discr].iter().map(|ty| {\n+                            ty.layout(infcx)\n+                        }), ty)?;\n+                        return Ok(StructWrappedNullablePointer {\n+                            nndiscr: discr as u64,\n+                            nonnull: st,\n+                            discrfield: path\n+                        });\n+                    }\n+                }\n+\n+                // The general case.\n+                let discr_max = (variants.len() - 1) as i64;\n+                assert!(discr_max >= 0);\n+                let (min_ity, _) = Integer::repr_discr(tcx, hint, 0, discr_max);\n+\n+                let mut align = dl.aggregate_align;\n+                let mut size = Size::from_bytes(0);\n+\n+                // We're interested in the smallest alignment, so start large.\n+                let mut start_align = Align::from_bytes(256, 256).unwrap();\n+\n+                // Create the set of structs that represent each variant\n+                // Use the minimum integer type we figured out above\n+                let discr = Some(Scalar { value: Int(min_ity), non_zero: false });\n+                let mut variants = variants.into_iter().map(|fields| {\n+                    let mut found_start = false;\n+                    let fields = fields.into_iter().map(|field| {\n+                        let field = field.layout(infcx)?;\n+                        if !found_start {\n+                            // Find the first field we can't move later\n+                            // to make room for a larger discriminant.\n+                            let field_align = field.align(dl);\n+                            if field.size(dl).bytes() != 0 || field_align.abi() != 1 {\n+                                start_align = start_align.min(field_align);\n+                                found_start = true;\n+                            }\n+                        }\n+                        Ok(field)\n+                    });\n+                    let mut st = Struct::new(dl, false);\n+                    st.extend(dl, discr.iter().map(Ok).chain(fields)\n+                                              .chain(drop_flag.iter().map(Ok)), ty)?;\n+                    size = cmp::max(size, st.min_size());\n+                    align = align.max(st.align);\n+                    Ok(st)\n+                }).collect::<Result<Vec<_>, _>>()?;\n+\n+                // Align the maximum variant size to the largest alignment.\n+                size = size.abi_align(align);\n+\n+                if size.bytes() >= dl.obj_size_bound() {\n+                    return Err(LayoutError::SizeOverflow(ty));\n+                }\n+\n+                // Check to see if we should use a different type for the\n+                // discriminant. We can safely use a type with the same size\n+                // as the alignment of the first field of each variant.\n+                // We increase the size of the discriminant to avoid LLVM copying\n+                // padding when it doesn't need to. This normally causes unaligned\n+                // load/stores and excessive memcpy/memset operations. By using a\n+                // bigger integer size, LLVM can be sure about it's contents and\n+                // won't be so conservative.\n+\n+                // Use the initial field alignment\n+                let wanted = start_align.abi();\n+                let mut ity = min_ity;\n+                for &candidate in &[I16, I32, I64] {\n+                    let ty = Int(candidate);\n+                    if wanted == ty.align(dl).abi() && wanted == ty.size(dl).bytes() {\n+                        ity = candidate;\n+                        break;\n+                    }\n+                }\n+\n+                // FIXME(eddyb) conservative only to avoid diverging from trans::adt.\n+                if align.abi() != start_align.abi() {\n+                    ity = min_ity;\n+                }\n+\n+                // If the alignment is not larger than the chosen discriminant size,\n+                // don't use the alignment as the final size.\n+                if ity <= min_ity {\n+                    ity = min_ity;\n+                } else {\n+                    // Patch up the variants' first few fields.\n+                    let old_ity_size = Int(min_ity).size(dl);\n+                    let new_ity_size = Int(ity).size(dl);\n+                    for variant in &mut variants {\n+                        for offset in &mut variant.offset_after_field {\n+                            if *offset > old_ity_size {\n+                                break;\n+                            }\n+                            *offset = new_ity_size;\n+                        }\n+                    }\n+                }\n+\n+                General {\n+                    discr: ity,\n+                    variants: variants,\n+                    size: size,\n+                    align: align\n+                }\n+            }\n+\n+            // Types with no meaningful known layout.\n+            ty::TyProjection(_) | ty::TyParam(_) => {\n+                return Err(LayoutError::Unknown(ty));\n+            }\n+            ty::TyInfer(_) | ty::TyError => {\n+                bug!(\"Layout::compute: unexpected type `{}`\", ty)\n+            }\n+        };\n+\n+        Ok(layout)\n+    }\n+\n+    /// Returns true if the layout corresponds to an unsized type.\n+    pub fn is_unsized(&self) -> bool {\n+        match *self {\n+            Scalar {..} | Vector {..} | FatPointer {..} |\n+            CEnum {..} | General {..} |\n+            RawNullablePointer {..} |\n+            StructWrappedNullablePointer {..} => false,\n+\n+            Array { sized, .. } |\n+            Univariant { variant: Struct { sized, .. }, .. } => !sized\n+        }\n+    }\n+\n+    pub fn size(&self, dl: &TargetDataLayout) -> Size {\n+        match *self {\n+            Scalar { value, .. } | RawNullablePointer { value, .. } => {\n+                value.size(dl)\n+            }\n+\n+            Vector { element, count } => {\n+                let elem_size = element.size(dl);\n+                let vec_size = match elem_size.checked_mul(count, dl) {\n+                    Some(size) => size,\n+                    None => bug!(\"Layout::size({:?}): {} * {} overflowed\",\n+                                 self, elem_size.bytes(), count)\n+                };\n+                vec_size.abi_align(self.align(dl))\n+            }\n+\n+            FatPointer { metadata, .. } => {\n+                // Effectively a (ptr, meta) tuple.\n+                Pointer.size(dl).abi_align(metadata.align(dl))\n+                       .checked_add(metadata.size(dl), dl).unwrap()\n+                       .abi_align(self.align(dl))\n+            }\n+\n+            CEnum { discr, .. } => Int(discr).size(dl),\n+            Array { size, .. } | General { size, .. } => size,\n+\n+            Univariant { ref variant, .. } |\n+            StructWrappedNullablePointer { nonnull: ref variant, .. } => {\n+                variant.stride()\n+            }\n+        }\n+    }\n+\n+    pub fn align(&self, dl: &TargetDataLayout) -> Align {\n+        match *self {\n+            Scalar { value, .. } | RawNullablePointer { value, .. } => {\n+                value.align(dl)\n+            }\n+\n+            Vector { element, count } => {\n+                let elem_size = element.size(dl);\n+                let vec_size = match elem_size.checked_mul(count, dl) {\n+                    Some(size) => size,\n+                    None => bug!(\"Layout::align({:?}): {} * {} overflowed\",\n+                                 self, elem_size.bytes(), count)\n+                };\n+                for &(size, align) in &dl.vector_align {\n+                    if size == vec_size {\n+                        return align;\n+                    }\n+                }\n+                // Default to natural alignment, which is what LLVM does.\n+                // That is, use the size, rounded up to a power of 2.\n+                let align = vec_size.bytes().next_power_of_two();\n+                Align::from_bytes(align, align).unwrap()\n+            }\n+\n+            FatPointer { metadata, .. } => {\n+                // Effectively a (ptr, meta) tuple.\n+                Pointer.align(dl).max(metadata.align(dl))\n+            }\n+\n+            CEnum { discr, .. } => Int(discr).align(dl),\n+            Array { align, .. } | General { align, .. } => align,\n+\n+            Univariant { ref variant, .. } |\n+            StructWrappedNullablePointer { nonnull: ref variant, .. } => {\n+                variant.align\n+            }\n+        }\n+    }\n+}"}, {"sha": "2e4f37f1cc1d46901fa49fc38f957fad24dc8d83", "filename": "src/librustc/ty/util.rs", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/rust-lang/rust/blob/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Futil.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc%2Fty%2Futil.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fty%2Futil.rs?ref=fe48a4af8403289ebc811884964fc4ef91f6bc09", "patch": "@@ -18,6 +18,7 @@ use hir::pat_util;\n use traits::{self, ProjectionMode};\n use ty::{self, Ty, TyCtxt, TypeAndMut, TypeFlags, TypeFoldable};\n use ty::{Disr, ParameterEnvironment};\n+use ty::layout::{Layout, LayoutError};\n use ty::TypeVariants::*;\n \n use rustc_const_math::{ConstInt, ConstIsize, ConstUsize};\n@@ -597,6 +598,24 @@ impl<'tcx> ty::TyS<'tcx> {\n         result\n     }\n \n+    #[inline]\n+    pub fn layout<'a>(&'tcx self, infcx: &infer::InferCtxt<'a, 'tcx>)\n+                      -> Result<&'tcx Layout, LayoutError<'tcx>> {\n+        let can_cache = !self.has_param_types() && !self.has_self_ty();\n+        if can_cache {\n+            if let Some(&cached) = infcx.tcx.layout_cache.borrow().get(&self) {\n+                return Ok(cached);\n+            }\n+        }\n+\n+        let layout = Layout::compute_uncached(self, infcx)?;\n+        let layout = infcx.tcx.intern_layout(layout);\n+        if can_cache {\n+            infcx.tcx.layout_cache.borrow_mut().insert(self, layout);\n+        }\n+        Ok(layout)\n+    }\n+\n \n     /// Check whether a type is representable. This means it cannot contain unboxed\n     /// structural recursion. This check is needed for structs and enums."}, {"sha": "9bbe0cb5f69572cc81be487e638ed919d99e18c4", "filename": "src/librustc_trans/abi.rs", "status": "modified", "additions": 1, "deletions": 12, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc_trans%2Fabi.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc_trans%2Fabi.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fabi.rs?ref=fe48a4af8403289ebc811884964fc4ef91f6bc09", "patch": "@@ -32,18 +32,7 @@ use rustc::ty::{self, Ty};\n use libc::c_uint;\n \n pub use syntax::abi::Abi;\n-\n-/// The first half of a fat pointer.\n-/// - For a closure, this is the code address.\n-/// - For an object or trait instance, this is the address of the box.\n-/// - For a slice, this is the base address.\n-pub const FAT_PTR_ADDR: usize = 0;\n-\n-/// The second half of a fat pointer.\n-/// - For a closure, this is the address of the environment.\n-/// - For an object or trait instance, this is the address of the vtable.\n-/// - For a slice, this is the length.\n-pub const FAT_PTR_EXTRA: usize = 1;\n+pub use rustc::ty::layout::{FAT_PTR_ADDR, FAT_PTR_EXTRA};\n \n #[derive(Clone, Copy, PartialEq, Debug)]\n enum ArgKind {"}, {"sha": "1217b2b5a1b17fbddfce4e6405cdc71617db0490", "filename": "src/librustc_trans/context.rs", "status": "modified", "additions": 1, "deletions": 16, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc_trans%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/fe48a4af8403289ebc811884964fc4ef91f6bc09/src%2Flibrustc_trans%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fcontext.rs?ref=fe48a4af8403289ebc811884964fc4ef91f6bc09", "patch": "@@ -784,23 +784,8 @@ impl<'b, 'tcx> CrateContext<'b, 'tcx> {\n         &self.local.trait_cache\n     }\n \n-    /// Return exclusive upper bound on object size.\n-    ///\n-    /// The theoretical maximum object size is defined as the maximum positive `int` value. This\n-    /// ensures that the `offset` semantics remain well-defined by allowing it to correctly index\n-    /// every address within an object along with one byte past the end, along with allowing `int`\n-    /// to store the difference between any two pointers into an object.\n-    ///\n-    /// The upper bound on 64-bit currently needs to be lower because LLVM uses a 64-bit integer to\n-    /// represent object size in bits. It would need to be 1 << 61 to account for this, but is\n-    /// currently conservatively bounded to 1 << 47 as that is enough to cover the current usable\n-    /// address space on 64-bit ARMv8 and x86_64.\n     pub fn obj_size_bound(&self) -> u64 {\n-        match &self.sess().target.target.target_pointer_width[..] {\n-            \"32\" => 1 << 31,\n-            \"64\" => 1 << 47,\n-            _ => bug!() // error handled by config::build_target_config\n-        }\n+        self.tcx().data_layout.obj_size_bound()\n     }\n \n     pub fn report_overbig_object(&self, obj: Ty<'tcx>) -> ! {"}]}