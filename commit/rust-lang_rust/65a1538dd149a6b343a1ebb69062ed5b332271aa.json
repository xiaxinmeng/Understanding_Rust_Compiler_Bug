{"sha": "65a1538dd149a6b343a1ebb69062ed5b332271aa", "node_id": "C_kwDOAAsO6NoAKDY1YTE1MzhkZDE0OWE2YjM0M2ExZWJiNjkwNjJlZDViMzMyMjcxYWE", "commit": {"author": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-01-02T02:25:47Z"}, "committer": {"name": "Lukas Wirth", "email": "lukastw97@gmail.com", "date": "2022-01-02T02:48:19Z"}, "message": "internal: Use basic NonEmptyVec in mbe::syntax_bridge", "tree": {"sha": "dff66a3c60cfa890c5322f47ba9c9fabce2b0c5a", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/dff66a3c60cfa890c5322f47ba9c9fabce2b0c5a"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/65a1538dd149a6b343a1ebb69062ed5b332271aa", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/65a1538dd149a6b343a1ebb69062ed5b332271aa", "html_url": "https://github.com/rust-lang/rust/commit/65a1538dd149a6b343a1ebb69062ed5b332271aa", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/65a1538dd149a6b343a1ebb69062ed5b332271aa/comments", "author": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Veykril", "id": 3757771, "node_id": "MDQ6VXNlcjM3NTc3NzE=", "avatar_url": "https://avatars.githubusercontent.com/u/3757771?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Veykril", "html_url": "https://github.com/Veykril", "followers_url": "https://api.github.com/users/Veykril/followers", "following_url": "https://api.github.com/users/Veykril/following{/other_user}", "gists_url": "https://api.github.com/users/Veykril/gists{/gist_id}", "starred_url": "https://api.github.com/users/Veykril/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Veykril/subscriptions", "organizations_url": "https://api.github.com/users/Veykril/orgs", "repos_url": "https://api.github.com/users/Veykril/repos", "events_url": "https://api.github.com/users/Veykril/events{/privacy}", "received_events_url": "https://api.github.com/users/Veykril/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "a0e0e4575b79f89825d3ac6130a659982228eda4", "url": "https://api.github.com/repos/rust-lang/rust/commits/a0e0e4575b79f89825d3ac6130a659982228eda4", "html_url": "https://github.com/rust-lang/rust/commit/a0e0e4575b79f89825d3ac6130a659982228eda4"}], "stats": {"total": 149, "additions": 98, "deletions": 51}, "files": [{"sha": "066b305205f97b0e4b031b26bf4200fc73972c64", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 52, "deletions": 51, "changes": 103, "blob_url": "https://github.com/rust-lang/rust/blob/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=65a1538dd149a6b343a1ebb69062ed5b332271aa", "patch": "@@ -1,6 +1,7 @@\n //! Conversions between [`SyntaxNode`] and [`tt::TokenTree`].\n \n use rustc_hash::{FxHashMap, FxHashSet};\n+use stdx::non_empty_vec::NonEmptyVec;\n use syntax::{\n     ast::{self, make::tokens::doc_comment},\n     AstToken, Parse, PreorderWithTokens, SmolStr, SyntaxElement, SyntaxKind,\n@@ -141,25 +142,26 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n         idx: !0,\n         open_range: TextRange::empty(TextSize::of('.')),\n     };\n-    let mut stack = vec![entry];\n+    let mut stack = NonEmptyVec::new(entry);\n \n     loop {\n-        let entry = stack.last_mut().unwrap();\n-        let result = &mut entry.subtree.token_trees;\n+        let StackEntry { subtree, .. } = stack.last_mut();\n+        let result = &mut subtree.token_trees;\n         let (token, range) = match conv.bump() {\n             Some(it) => it,\n             None => break,\n         };\n \n-        let k: SyntaxKind = token.kind(&conv);\n-        if k == COMMENT {\n+        let kind = token.kind(&conv);\n+        if kind == COMMENT {\n             if let Some(tokens) = conv.convert_doc_comment(&token) {\n                 // FIXME: There has to be a better way to do this\n                 // Add the comments token id to the converted doc string\n                 let id = conv.id_alloc().alloc(range);\n                 result.extend(tokens.into_iter().map(|mut tt| {\n                     if let tt::TokenTree::Subtree(sub) = &mut tt {\n-                        if let tt::TokenTree::Leaf(tt::Leaf::Literal(lit)) = &mut sub.token_trees[2]\n+                        if let Some(tt::TokenTree::Leaf(tt::Leaf::Literal(lit))) =\n+                            sub.token_trees.get_mut(2)\n                         {\n                             lit.id = id\n                         }\n@@ -169,26 +171,26 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n             }\n             continue;\n         }\n-\n-        result.push(if k.is_punct() && k != UNDERSCORE {\n+        let tt = if kind.is_punct() && kind != UNDERSCORE {\n             assert_eq!(range.len(), TextSize::of('.'));\n \n-            if let Some(delim) = entry.subtree.delimiter {\n+            if let Some(delim) = subtree.delimiter {\n                 let expected = match delim.kind {\n                     tt::DelimiterKind::Parenthesis => T![')'],\n                     tt::DelimiterKind::Brace => T!['}'],\n                     tt::DelimiterKind::Bracket => T![']'],\n                 };\n \n-                if k == expected {\n-                    let entry = stack.pop().unwrap();\n-                    conv.id_alloc().close_delim(entry.idx, Some(range));\n-                    stack.last_mut().unwrap().subtree.token_trees.push(entry.subtree.into());\n+                if kind == expected {\n+                    if let Some(entry) = stack.pop() {\n+                        conv.id_alloc().close_delim(entry.idx, Some(range));\n+                        stack.last_mut().subtree.token_trees.push(entry.subtree.into());\n+                    }\n                     continue;\n                 }\n             }\n \n-            let delim = match k {\n+            let delim = match kind {\n                 T!['('] => Some(tt::DelimiterKind::Parenthesis),\n                 T!['{'] => Some(tt::DelimiterKind::Brace),\n                 T!['['] => Some(tt::DelimiterKind::Bracket),\n@@ -201,36 +203,35 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n                 subtree.delimiter = Some(tt::Delimiter { id, kind });\n                 stack.push(StackEntry { subtree, idx, open_range: range });\n                 continue;\n-            } else {\n-                let spacing = match conv.peek() {\n-                    Some(next)\n-                        if next.kind(&conv).is_trivia()\n-                            || next.kind(&conv) == T!['[']\n-                            || next.kind(&conv) == T!['{']\n-                            || next.kind(&conv) == T!['('] =>\n-                    {\n-                        tt::Spacing::Alone\n-                    }\n-                    Some(next) if next.kind(&conv).is_punct() && next.kind(&conv) != UNDERSCORE => {\n-                        tt::Spacing::Joint\n-                    }\n-                    _ => tt::Spacing::Alone,\n-                };\n-                let char = match token.to_char(&conv) {\n-                    Some(c) => c,\n-                    None => {\n-                        panic!(\"Token from lexer must be single char: token = {:#?}\", token);\n-                    }\n-                };\n-                tt::Leaf::from(tt::Punct { char, spacing, id: conv.id_alloc().alloc(range) }).into()\n             }\n+\n+            let spacing = match conv.peek().map(|next| next.kind(&conv)) {\n+                Some(kind)\n+                    if !kind.is_trivia()\n+                        && kind.is_punct()\n+                        && kind != T!['[']\n+                        && kind != T!['{']\n+                        && kind != T!['(']\n+                        && kind != UNDERSCORE =>\n+                {\n+                    tt::Spacing::Joint\n+                }\n+                _ => tt::Spacing::Alone,\n+            };\n+            let char = match token.to_char(&conv) {\n+                Some(c) => c,\n+                None => {\n+                    panic!(\"Token from lexer must be single char: token = {:#?}\", token);\n+                }\n+            };\n+            tt::Leaf::from(tt::Punct { char, spacing, id: conv.id_alloc().alloc(range) }).into()\n         } else {\n             macro_rules! make_leaf {\n                 ($i:ident) => {\n                     tt::$i { id: conv.id_alloc().alloc(range), text: token.to_text(conv) }.into()\n                 };\n             }\n-            let leaf: tt::Leaf = match k {\n+            let leaf: tt::Leaf = match kind {\n                 T![true] | T![false] => make_leaf!(Ident),\n                 IDENT => make_leaf!(Ident),\n                 UNDERSCORE => make_leaf!(Ident),\n@@ -258,15 +259,15 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n             };\n \n             leaf.into()\n-        });\n+        };\n+        result.push(tt);\n     }\n \n     // If we get here, we've consumed all input tokens.\n     // We might have more than one subtree in the stack, if the delimiters are improperly balanced.\n     // Merge them so we're left with one.\n-    while stack.len() > 1 {\n-        let entry = stack.pop().unwrap();\n-        let parent = stack.last_mut().unwrap();\n+    while let Some(entry) = stack.pop() {\n+        let parent = stack.last_mut();\n \n         conv.id_alloc().close_delim(entry.idx, None);\n         let leaf: tt::Leaf = tt::Punct {\n@@ -283,13 +284,12 @@ fn convert_tokens<C: TokenConvertor>(conv: &mut C) -> tt::Subtree {\n         parent.subtree.token_trees.extend(entry.subtree.token_trees);\n     }\n \n-    let subtree = stack.pop().unwrap().subtree;\n-    if subtree.token_trees.len() == 1 {\n-        if let tt::TokenTree::Subtree(first) = &subtree.token_trees[0] {\n-            return first.clone();\n-        }\n+    let subtree = stack.into_first().subtree;\n+    if let [tt::TokenTree::Subtree(first)] = &*subtree.token_trees {\n+        first.clone()\n+    } else {\n+        subtree\n     }\n-    subtree\n }\n \n /// Returns the textual content of a doc comment block as a quoted string\n@@ -320,7 +320,8 @@ fn convert_doc_comment(token: &syntax::SyntaxToken) -> Option<Vec<tt::TokenTree>\n     let meta_tkns = vec![mk_ident(\"doc\"), mk_punct('='), mk_doc_literal(&comment)];\n \n     // Make `#![]`\n-    let mut token_trees = vec![mk_punct('#')];\n+    let mut token_trees = Vec::with_capacity(3);\n+    token_trees.push(mk_punct('#'));\n     if let ast::CommentPlacement::Inner = doc {\n         token_trees.push(mk_punct('!'));\n     }\n@@ -439,8 +440,8 @@ impl<'a> SrcToken<RawConvertor<'a>> for usize {\n impl<'a> TokenConvertor for RawConvertor<'a> {\n     type Token = usize;\n \n-    fn convert_doc_comment(&self, token: &usize) -> Option<Vec<tt::TokenTree>> {\n-        let text = self.lexed.text(*token);\n+    fn convert_doc_comment(&self, &token: &usize) -> Option<Vec<tt::TokenTree>> {\n+        let text = self.lexed.text(token);\n         convert_doc_comment(&doc_comment(text))\n     }\n \n@@ -568,9 +569,9 @@ impl TokenConvertor for Convertor<'_> {\n         }\n         self.current = Self::next_token(&mut self.preorder, self.censor);\n         let token = if curr.kind().is_punct() {\n+            self.punct_offset = Some((curr.clone(), 0.into()));\n             let range = curr.text_range();\n             let range = TextRange::at(range.start(), TextSize::of('.'));\n-            self.punct_offset = Some((curr.clone(), 0.into()));\n             (SynToken::Punch(curr, 0.into()), range)\n         } else {\n             self.punct_offset = None;"}, {"sha": "16b8558f4110bc4a4fb0f9fd68c2a747c6bafc62", "filename": "crates/stdx/src/lib.rs", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fstdx%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fstdx%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fstdx%2Fsrc%2Flib.rs?ref=65a1538dd149a6b343a1ebb69062ed5b332271aa", "patch": "@@ -5,6 +5,7 @@ use std::{cmp::Ordering, ops, time::Instant};\n mod macros;\n pub mod process;\n pub mod panic_context;\n+pub mod non_empty_vec;\n \n pub use always_assert::{always, never};\n "}, {"sha": "199ee18b94b320d3bd270f1ee7ee19594b5be04c", "filename": "crates/stdx/src/non_empty_vec.rs", "status": "added", "additions": 45, "deletions": 0, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fstdx%2Fsrc%2Fnon_empty_vec.rs", "raw_url": "https://github.com/rust-lang/rust/raw/65a1538dd149a6b343a1ebb69062ed5b332271aa/crates%2Fstdx%2Fsrc%2Fnon_empty_vec.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fstdx%2Fsrc%2Fnon_empty_vec.rs?ref=65a1538dd149a6b343a1ebb69062ed5b332271aa", "patch": "@@ -0,0 +1,45 @@\n+//! A [`Vec`] that is guaranteed to at least contain one element.\n+\n+pub struct NonEmptyVec<T>(Vec<T>);\n+\n+impl<T> NonEmptyVec<T> {\n+    #[inline]\n+    pub fn new(initial: T) -> Self {\n+        NonEmptyVec(vec![initial])\n+    }\n+\n+    #[inline]\n+    pub fn last_mut(&mut self) -> &mut T {\n+        match self.0.last_mut() {\n+            Some(it) => it,\n+            None => unreachable!(),\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn pop(&mut self) -> Option<T> {\n+        if self.0.len() <= 1 {\n+            None\n+        } else {\n+            self.0.pop()\n+        }\n+    }\n+\n+    #[inline]\n+    pub fn push(&mut self, value: T) {\n+        self.0.push(value)\n+    }\n+\n+    #[inline]\n+    pub fn len(&self) -> usize {\n+        self.0.len()\n+    }\n+\n+    #[inline]\n+    pub fn into_first(mut self) -> T {\n+        match self.0.pop() {\n+            Some(it) => it,\n+            None => unreachable!(),\n+        }\n+    }\n+}"}]}