{"sha": "eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "node_id": "MDY6Q29tbWl0NzI0NzEyOmVlYjU4NGNjYmQ1Yjc0MDA4NjQyYmJmMWI3ZTc1ZGZjOTBiYzllOTM=", "commit": {"author": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-11-23T02:20:28Z"}, "committer": {"name": "Graydon Hoare", "email": "graydon@mozilla.com", "date": "2012-11-23T02:31:12Z"}, "message": "std: initial sketch of workcache, barely does anything.", "tree": {"sha": "ae48ed6f546e2ed6a043d2e8a7ced19a94ef2a12", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ae48ed6f546e2ed6a043d2e8a7ced19a94ef2a12"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "html_url": "https://github.com/rust-lang/rust/commit/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93/comments", "author": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "committer": {"login": "graydon", "id": 14097, "node_id": "MDQ6VXNlcjE0MDk3", "avatar_url": "https://avatars.githubusercontent.com/u/14097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/graydon", "html_url": "https://github.com/graydon", "followers_url": "https://api.github.com/users/graydon/followers", "following_url": "https://api.github.com/users/graydon/following{/other_user}", "gists_url": "https://api.github.com/users/graydon/gists{/gist_id}", "starred_url": "https://api.github.com/users/graydon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/graydon/subscriptions", "organizations_url": "https://api.github.com/users/graydon/orgs", "repos_url": "https://api.github.com/users/graydon/repos", "events_url": "https://api.github.com/users/graydon/events{/privacy}", "received_events_url": "https://api.github.com/users/graydon/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "105a0b9fc144ef0dd82eae89daf4e1048235631d", "url": "https://api.github.com/repos/rust-lang/rust/commits/105a0b9fc144ef0dd82eae89daf4e1048235631d", "html_url": "https://github.com/rust-lang/rust/commit/105a0b9fc144ef0dd82eae89daf4e1048235631d"}], "stats": {"total": 312, "additions": 312, "deletions": 0}, "files": [{"sha": "dd895e60d8f2d39625dd2fbf4898a23abc08d7b1", "filename": "src/libstd/std.rc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93/src%2Flibstd%2Fstd.rc", "raw_url": "https://github.com/rust-lang/rust/raw/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93/src%2Flibstd%2Fstd.rc", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fstd.rc?ref=eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "patch": "@@ -85,6 +85,7 @@ pub mod par;\n pub mod cmp;\n pub mod base64;\n pub mod rl;\n+pub mod workcache;\n \n #[cfg(unicode)]\n mod unicode;"}, {"sha": "231946e64c1a4a97baf18665817031a09c01aaf2", "filename": "src/libstd/workcache.rs", "status": "added", "additions": 311, "deletions": 0, "changes": 311, "blob_url": "https://github.com/rust-lang/rust/blob/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93/src%2Flibstd%2Fworkcache.rs", "raw_url": "https://github.com/rust-lang/rust/raw/eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93/src%2Flibstd%2Fworkcache.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fworkcache.rs?ref=eeb584ccbd5b74008642bbf1b7e75dfc90bc9e93", "patch": "@@ -0,0 +1,311 @@\n+extern mod std;\n+\n+use core::cmp::Eq;\n+use send_map::linear::LinearMap;\n+use pipes::{recv, oneshot, PortOne, send_one};\n+use either::{Right,Left,Either};\n+\n+use std::json;\n+use std::sha1;\n+use std::serialization::{Serializer,Serializable,\n+                         Deserializer,Deserializable,\n+                         deserialize};\n+\n+/**\n+*\n+* This is a loose clone of the fbuild build system, made a touch more\n+* generic (not wired to special cases on files) and much less metaprogram-y\n+* due to rust's comparative weakness there, relative to python.\n+*\n+* It's based around _imperative bulids_ that happen to have some function\n+* calls cached. That is, it's _just_ a mechanism for describing cached\n+* functions. This makes it much simpler and smaller than a \"build system\"\n+* that produces an IR and evaluates it. The evaluation order is normal\n+* function calls. Some of them just return really quickly.\n+*\n+* A cached function consumes and produces a set of _works_. A work has a\n+* name, a kind (that determines how the value is to be checked for\n+* freshness) and a value. Works must also be (de)serializable. Some\n+* examples of works:\n+*\n+*    kind   name    value\n+*   ------------------------\n+*    cfg    os      linux\n+*    file   foo.c   <sha1>\n+*    url    foo.com <etag>\n+*\n+* Works are conceptually single units, but we store them most of the time\n+* in maps of the form (type,name) => value. These are WorkMaps.\n+*\n+* A cached function divides the works it's interested up into inputs and\n+* outputs, and subdivides those into declared (input and output) works and\n+* discovered (input and output) works.\n+*\n+* A _declared_ input or output is one that is given to the workcache before\n+* any work actually happens, in the \"prep\" phase. Even when a function's\n+* work-doing part (the \"exec\" phase) never gets called, it has declared\n+* inputs and outputs, which can be checked for freshness (and potentially\n+* used to determine that the function can be skipped).\n+*\n+* The workcache checks _all_ works for freshness, but uses the set of\n+* discovered outputs from the _previous_ exec (which it will re-discover\n+* and re-record each time the exec phase runs).\n+*\n+* Therefore the discovered works cached in the db might be a\n+* mis-approximation of the current discoverable works, but this is ok for\n+* the following reason: we assume that if an artifact A changed from\n+* depending on B,C,D to depending on B,C,D,E, then A itself changed (as\n+* part of the change-in-dependencies), so we will be ok.\n+*\n+* Each function has a single discriminated output work called its _result_.\n+* This is only different from other works in that it is returned, by value,\n+* from a call to the cacheable function; the other output works are used in\n+* passing to invalidate dependencies elsewhere in the cache, but do not\n+* otherwise escape from a function invocation. Most functions only have one\n+* output work anyways.\n+*\n+* A database (the central store of a workcache) stores a mappings:\n+*\n+* (fn_name,{declared_input}) => ({declared_output},{discovered_input},\n+*                                {discovered_output},result)\n+*\n+*/\n+\n+struct WorkKey {\n+    kind: ~str,\n+    name: ~str\n+}\n+\n+impl WorkKey: to_bytes::IterBytes {\n+    #[inline(always)]\n+    pure fn iter_bytes(lsb0: bool, f: to_bytes::Cb) {\n+        let mut flag = true;\n+        self.kind.iter_bytes(lsb0, |bytes| {flag = f(bytes); flag});\n+        if !flag { return; }\n+        self.name.iter_bytes(lsb0, f);\n+    }\n+}\n+\n+impl WorkKey {\n+    static fn new(kind: &str, name: &str) -> WorkKey {\n+    WorkKey { kind: kind.to_owned(), name: name.to_owned() }\n+    }\n+}\n+\n+impl WorkKey: core::cmp::Eq {\n+    pure fn eq(&self, other: &WorkKey) -> bool {\n+        self.kind == other.kind && self.name == other.name\n+    }\n+    pure fn ne(&self, other: &WorkKey) -> bool {\n+        self.kind != other.kind || self.name != other.name\n+    }\n+}\n+\n+type WorkMap = LinearMap<WorkKey, ~str>;\n+\n+struct Database {\n+    // XXX: Fill in.\n+    a: ()\n+}\n+\n+impl Database {\n+    pure fn prepare(_fn_name: &str,\n+                    _declared_inputs: &const WorkMap) ->\n+        Option<(WorkMap, WorkMap, WorkMap, ~str)> {\n+        // XXX: load\n+        None\n+    }\n+    pure fn cache(_fn_name: &str,\n+             _declared_inputs: &WorkMap,\n+             _declared_outputs: &WorkMap,\n+             _discovered_inputs: &WorkMap,\n+             _discovered_outputs: &WorkMap,\n+             _result: &str) {\n+        // XXX: store\n+    }\n+}\n+\n+struct Logger {\n+    // XXX: Fill in\n+    a: ()\n+}\n+\n+struct Context {\n+    db: @Database,\n+    logger: @Logger,\n+    cfg: @json::Object,\n+    freshness: LinearMap<~str,~fn(&str,&str)->bool>\n+}\n+\n+struct Prep {\n+    ctxt: @Context,\n+    fn_name: ~str,\n+    declared_inputs: WorkMap,\n+    declared_outputs: WorkMap\n+}\n+\n+struct Exec {\n+    discovered_inputs: WorkMap,\n+    discovered_outputs: WorkMap\n+}\n+\n+struct Work<T:Send> {\n+    prep: @mut Prep,\n+    res: Option<Either<T,PortOne<(Exec,T)>>>\n+}\n+\n+fn digest<T:Serializable<json::Serializer>\n+            Deserializable<json::Deserializer>>(t: &T) -> ~str {\n+    let sha = sha1::sha1();\n+    let s = do io::with_str_writer |wr| {\n+        // XXX: sha1 should be a writer itself, shouldn't\n+        // go via strings.\n+        t.serialize(&json::Serializer(wr));\n+    };\n+    sha.input_str(s);\n+    sha.result_str()\n+}\n+\n+fn digest_file(path: &Path) -> ~str {\n+    let sha = sha1::sha1();\n+    let s = io::read_whole_file_str(path);\n+    sha.input_str(*s.get_ref());\n+    sha.result_str()\n+}\n+\n+impl Context {\n+\n+    static fn new(db: @Database, lg: @Logger,\n+                  cfg: @json::Object) -> Context {\n+        Context {db: db, logger: lg, cfg: cfg, freshness: LinearMap()}\n+    }\n+\n+    fn prep<T:Send\n+              Serializable<json::Serializer>\n+              Deserializable<json::Deserializer>>(\n+                  @self,\n+                  fn_name:&str,\n+                  blk: fn((@mut Prep))->Work<T>) -> Work<T> {\n+        let p = @mut Prep {ctxt: self,\n+                           fn_name: fn_name.to_owned(),\n+                           declared_inputs: LinearMap(),\n+                           declared_outputs: LinearMap()};\n+        blk(p)\n+    }\n+}\n+\n+impl Prep {\n+    fn declare_input(&mut self, kind:&str, name:&str, val:&str) {\n+        self.declared_inputs.insert(WorkKey::new(kind, name),\n+                                    val.to_owned());\n+    }\n+\n+    fn declare_output(&mut self, kind:&str, name:&str, val:&str) {\n+        self.declared_outputs.insert(WorkKey::new(kind, name),\n+                                     val.to_owned());\n+    }\n+\n+    fn exec<T:Send\n+              Serializable<json::Serializer>\n+              Deserializable<json::Deserializer>>(\n+                  @mut self, blk: ~fn(&Exec) -> T) -> Work<T> {\n+        let cached = self.ctxt.db.prepare(self.fn_name,\n+                                          &self.declared_inputs);\n+\n+        match move cached {\n+            None => (),\n+            Some((move _decl_out,\n+                  move _disc_in,\n+                  move _disc_out,\n+                  move res)) => {\n+                // XXX: check deps for freshness, only return if fresh.\n+                let v : T = do io::with_str_reader(res) |rdr| {\n+                    let j = result::unwrap(json::from_reader(rdr));\n+                    deserialize(&json::Deserializer(move j))\n+                };\n+                return Work::new(self, move Left(move v));\n+            }\n+        }\n+\n+        let (chan, port) = oneshot::init();\n+\n+        let chan = ~mut Some(move chan);\n+        do task::spawn |move blk, move chan| {\n+            let exe = Exec { discovered_inputs: LinearMap(),\n+                             discovered_outputs: LinearMap() };\n+            let chan = option::swap_unwrap(&mut *chan);\n+            let v = blk(&exe);\n+            send_one(move chan, (move exe, move v));\n+        }\n+\n+        Work::new(self, move Right(move port))\n+    }\n+}\n+\n+impl<T:Send\n+       Serializable<json::Serializer>\n+       Deserializable<json::Deserializer>>\n+    Work<T> {\n+    static fn new(p: @mut Prep, e: Either<T,PortOne<(Exec,T)>>) -> Work<T> {\n+        move Work { prep: p, res: Some(move e) }\n+    }\n+}\n+\n+// FIXME (#3724): movable self. This should be in impl Work.\n+fn unwrap<T:Send\n+            Serializable<json::Serializer>\n+            Deserializable<json::Deserializer>>(w: Work<T>) -> T {\n+\n+    let mut ww = move w;\n+    let mut s = None;\n+\n+    ww.res <-> s;\n+\n+    match move s {\n+        None => fail,\n+        Some(Left(move v)) => move v,\n+        Some(Right(move port)) => {\n+\n+            let (exe, v) = match recv(move port) {\n+                oneshot::send(move data) => move data\n+            };\n+\n+            let s = do io::with_str_writer |wr| {\n+                v.serialize(&json::Serializer(wr));\n+            };\n+\n+            ww.prep.ctxt.db.cache(ww.prep.fn_name,\n+                                  &ww.prep.declared_inputs,\n+                                  &ww.prep.declared_outputs,\n+                                  &exe.discovered_inputs,\n+                                  &exe.discovered_outputs,\n+                                  s);\n+            move v\n+        }\n+    }\n+}\n+\n+#[test]\n+fn test() {\n+    use io::WriterUtil;\n+    let db = @Database { a: () };\n+    let lg = @Logger { a: () };\n+    let cfg = @LinearMap();\n+    let cx = @Context::new(db, lg, cfg);\n+    let w:Work<~str> = do cx.prep(\"test1\") |prep| {\n+        let pth = Path(\"foo.c\");\n+        {\n+            let file = io::file_writer(&pth, [io::Create]).get();\n+            file.write_str(\"void main() { }\");\n+        }\n+\n+        prep.declare_input(\"file\", pth.to_str(), digest_file(&pth));\n+        do prep.exec |_exe| {\n+            let out = Path(\"foo.o\");\n+            run::run_program(\"gcc\", [~\"foo.c\", ~\"-o\", out.to_str()]);\n+            move out.to_str()\n+        }\n+    };\n+    let s = unwrap(move w);\n+    io::println(s);\n+}"}]}