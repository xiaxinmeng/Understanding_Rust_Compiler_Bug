{"sha": "c9f6d696420107f82304b992cf623b806995fe18", "node_id": "MDY6Q29tbWl0NzI0NzEyOmM5ZjZkNjk2NDIwMTA3ZjgyMzA0Yjk5MmNmNjIzYjgwNjk5NWZlMTg=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-21T03:41:45Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2014-11-21T03:41:45Z"}, "message": "auto merge of #18967 : aturon/rust/remove-runtime, r=alexcrichton\n\nThis PR completes the removal of the runtime system and green-threaded abstractions as part of implementing [RFC 230](https://github.com/rust-lang/rfcs/pull/230).\r\n\r\nSpecifically:\r\n\r\n* It removes the `Runtime` trait, welding the scheduling infrastructure directly to native threads.\r\n\r\n* It removes `libgreen` and `libnative` entirely.\r\n\r\n* It rewrites `sync::mutex` as a trivial layer on top of native mutexes. Eventually, the two modules will be merged.\r\n\r\n* It hides the vast majority of `std::rt`.\r\n\r\nThis completes the basic task of removing the runtime system (I/O and scheduling) and components that depend on it. \r\n\r\nAfter this lands, a follow-up PR will pull the `rustrt` crate back into `std`, turn `std::task` into `std::thread` (with API changes to go along with it), and completely cut out the remaining startup/teardown sequence. Other changes, including new [TLS](https://github.com/rust-lang/rfcs/pull/461) and synchronization are in the RFC or pre-RFC phase.\r\n\r\nCloses #17325\r\nCloses #18687\r\n\r\n[breaking-change]\r\n\r\nr? @alexcrichton", "tree": {"sha": "d2224bd566aaf93132fb5a959e0ba33192bde035", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d2224bd566aaf93132fb5a959e0ba33192bde035"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/c9f6d696420107f82304b992cf623b806995fe18", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/c9f6d696420107f82304b992cf623b806995fe18", "html_url": "https://github.com/rust-lang/rust/commit/c9f6d696420107f82304b992cf623b806995fe18", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/c9f6d696420107f82304b992cf623b806995fe18/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "98300516072c6afd0e93654b325f5924b60dea53", "url": "https://api.github.com/repos/rust-lang/rust/commits/98300516072c6afd0e93654b325f5924b60dea53", "html_url": "https://github.com/rust-lang/rust/commit/98300516072c6afd0e93654b325f5924b60dea53"}, {"sha": "32c3d027801b8f30f741b1b5340682e7009d02ac", "url": "https://api.github.com/repos/rust-lang/rust/commits/32c3d027801b8f30f741b1b5340682e7009d02ac", "html_url": "https://github.com/rust-lang/rust/commit/32c3d027801b8f30f741b1b5340682e7009d02ac"}], "stats": {"total": 7379, "additions": 378, "deletions": 7001}, "files": [{"sha": "012b43a2b0050479d11cfaca25202a52ac469efa", "filename": "mk/crates.mk", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/mk%2Fcrates.mk", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/mk%2Fcrates.mk", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/mk%2Fcrates.mk?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -37,7 +37,7 @@\n #\n #   DEPS_<crate>\n #\tThese lists are the dependencies of the <crate> that is to be built.\n-#\tRust dependencies are listed bare (i.e. std, green) and native\n+#\tRust dependencies are listed bare (i.e. std) and native\n #\tdependencies have a \"native:\" prefix (i.e. native:hoedown). All deps\n #\twill be built before the crate itself is built.\n #\n@@ -49,7 +49,7 @@\n # automatically generated for all stage/host/target combinations.\n ################################################################################\n \n-TARGET_CRATES := libc std green native flate arena term \\\n+TARGET_CRATES := libc std flate arena term \\\n                  serialize sync getopts collections test time rand \\\n                  log regex graphviz core rbml alloc rustrt \\\n                  unicode\n@@ -66,8 +66,6 @@ DEPS_rustrt := alloc core libc collections native:rustrt_native\n DEPS_std := core libc rand alloc collections rustrt sync unicode \\\n \tnative:rust_builtin native:backtrace\n DEPS_graphviz := std\n-DEPS_green := std native:context_switch\n-DEPS_native := std\n DEPS_syntax := std term serialize log fmt_macros arena libc\n DEPS_rustc_trans := rustc rustc_back rustc_llvm libc\n DEPS_rustc := syntax flate arena serialize getopts rbml \\\n@@ -95,9 +93,9 @@ DEPS_regex := std\n DEPS_regex_macros = rustc syntax std regex\n DEPS_fmt_macros = std\n \n-TOOL_DEPS_compiletest := test getopts native\n-TOOL_DEPS_rustdoc := rustdoc native\n-TOOL_DEPS_rustc := rustc_trans native\n+TOOL_DEPS_compiletest := test getopts\n+TOOL_DEPS_rustdoc := rustdoc\n+TOOL_DEPS_rustc := rustc_trans\n TOOL_SOURCE_compiletest := $(S)src/compiletest/compiletest.rs\n TOOL_SOURCE_rustdoc := $(S)src/driver/driver.rs\n TOOL_SOURCE_rustc := $(S)src/driver/driver.rs"}, {"sha": "c72fd14ec5b6d09487e80d1f6c0938942a906bfa", "filename": "src/README.md", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2FREADME.md", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2FREADME.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FREADME.md?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -9,8 +9,6 @@ Source layout:\n | `libcore/`          | The Rust core library                                     |\n | `libdebug/`         | Debugging utilities                                       |\n | `libstd/`           | The standard library (imported and linked by default)     |\n-| `libgreen/`         | The M:N runtime library                                   |\n-| `libnative/`        | The 1:1 runtime library                                   |\n | `libsyntax/`        | The Rust parser and pretty-printer                        |\n | `libtest/`          | Rust's test-runner code                                   |\n | ------------------- | --------------------------------------------------------- |"}, {"sha": "65027df20c32c00fe04d964ff77f88e6675ebdfa", "filename": "src/doc/reference.md", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Fdoc%2Freference.md", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Fdoc%2Freference.md", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdoc%2Freference.md?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -1059,14 +1059,14 @@ An example of what will and will not work for `use` items:\n \n ```\n # #![allow(unused_imports)]\n-use foo::native::start;  // good: foo is at the root of the crate\n+use foo::core::iter;  // good: foo is at the root of the crate\n use foo::baz::foobaz;    // good: foo is at the root of the crate\n \n mod foo {\n-    extern crate native;\n+    extern crate core;\n \n-    use foo::native::start; // good: foo is at crate root\n-//  use native::start;      // bad:  native is not at the crate root\n+    use foo::core::iter; // good: foo is at crate root\n+//  use core::iter;      // bad:  native is not at the crate root\n     use self::baz::foobaz;  // good: self refers to module 'foo'\n     use foo::bar::foobar;   // good: foo is at crate root\n "}, {"sha": "224b4f1b5c578cd8cb27872bc841d20c44a869c9", "filename": "src/driver/driver.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fdriver%2Fdriver.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,6 +8,8 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+#![no_start]\n+\n #[cfg(rustdoc)]\n extern crate \"rustdoc\" as this;\n "}, {"sha": "173ca008d0356762a3b78b9ea715f6ecae96de86", "filename": "src/liballoc/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Fliballoc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Fliballoc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliballoc%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -73,7 +73,6 @@ extern crate libc;\n \n // Allow testing this library\n \n-#[cfg(test)] extern crate native;\n #[cfg(test)] #[phase(plugin, link)] extern crate std;\n #[cfg(test)] #[phase(plugin, link)] extern crate log;\n "}, {"sha": "7965ac26a62f8bc22dc4e9bfed43e443a1424376", "filename": "src/libcollections/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibcollections%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibcollections%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -31,7 +31,6 @@\n extern crate unicode;\n extern crate alloc;\n \n-#[cfg(test)] extern crate native;\n #[cfg(test)] extern crate test;\n \n #[cfg(test)] #[phase(plugin, link)] extern crate std;"}, {"sha": "c3a248ce3185b318d29a4d7c9587364f055c3fe7", "filename": "src/libcollections/slice.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibcollections%2Fslice.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibcollections%2Fslice.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibcollections%2Fslice.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -666,6 +666,8 @@ pub mod raw {\n \n #[cfg(test)]\n mod tests {\n+    extern crate rustrt;\n+\n     use std::cell::Cell;\n     use std::default::Default;\n     use std::mem;\n@@ -949,9 +951,9 @@ mod tests {\n     #[test]\n     fn test_swap_remove_noncopyable() {\n         // Tests that we don't accidentally run destructors twice.\n-        let mut v = vec![rt::exclusive::Exclusive::new(()),\n-                         rt::exclusive::Exclusive::new(()),\n-                         rt::exclusive::Exclusive::new(())];\n+        let mut v = vec![rustrt::exclusive::Exclusive::new(()),\n+                         rustrt::exclusive::Exclusive::new(()),\n+                         rustrt::exclusive::Exclusive::new(())];\n         let mut _e = v.swap_remove(0);\n         assert_eq!(v.len(), 2);\n         _e = v.swap_remove(1);"}, {"sha": "aa933f182e54511654d434499bf1daf474f33b65", "filename": "src/libgreen/basic.rs", "status": "removed", "additions": 0, "deletions": 259, "changes": 259, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fbasic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fbasic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fbasic.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,259 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! This is a basic event loop implementation not meant for any \"real purposes\"\n-//! other than testing the scheduler and proving that it's possible to have a\n-//! pluggable event loop.\n-//!\n-//! This implementation is also used as the fallback implementation of an event\n-//! loop if no other one is provided (and M:N scheduling is desired).\n-use self::Message::*;\n-\n-use alloc::arc::Arc;\n-use std::sync::atomic;\n-use std::mem;\n-use std::rt::rtio::{EventLoop, RemoteCallback};\n-use std::rt::rtio::{PausableIdleCallback, Callback};\n-use std::rt::exclusive::Exclusive;\n-\n-/// This is the only exported function from this module.\n-pub fn event_loop() -> Box<EventLoop + Send> {\n-    box BasicLoop::new() as Box<EventLoop + Send>\n-}\n-\n-struct BasicLoop {\n-    work: Vec<proc(): Send>,             // pending work\n-    remotes: Vec<(uint, Box<Callback + Send>)>,\n-    next_remote: uint,\n-    messages: Arc<Exclusive<Vec<Message>>>,\n-    idle: Option<Box<Callback + Send>>,\n-    idle_active: Option<Arc<atomic::AtomicBool>>,\n-}\n-\n-enum Message { RunRemote(uint), RemoveRemote(uint) }\n-\n-impl BasicLoop {\n-    fn new() -> BasicLoop {\n-        BasicLoop {\n-            work: vec![],\n-            idle: None,\n-            idle_active: None,\n-            next_remote: 0,\n-            remotes: vec![],\n-            messages: Arc::new(Exclusive::new(Vec::new())),\n-        }\n-    }\n-\n-    /// Process everything in the work queue (continually)\n-    fn work(&mut self) {\n-        while self.work.len() > 0 {\n-            for work in mem::replace(&mut self.work, vec![]).into_iter() {\n-                work();\n-            }\n-        }\n-    }\n-\n-    fn remote_work(&mut self) {\n-        let messages = unsafe {\n-            mem::replace(&mut *self.messages.lock(), Vec::new())\n-        };\n-        for message in messages.into_iter() {\n-            self.message(message);\n-        }\n-    }\n-\n-    fn message(&mut self, message: Message) {\n-        match message {\n-            RunRemote(i) => {\n-                match self.remotes.iter_mut().find(|& &(id, _)| id == i) {\n-                    Some(&(_, ref mut f)) => f.call(),\n-                    None => panic!(\"bad remote: {}\", i),\n-                }\n-            }\n-            RemoveRemote(i) => {\n-                match self.remotes.iter().position(|&(id, _)| id == i) {\n-                    Some(i) => { self.remotes.remove(i).unwrap(); }\n-                    None => panic!(\"bad remote: {}\", i),\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Run the idle callback if one is registered\n-    fn idle(&mut self) {\n-        match self.idle {\n-            Some(ref mut idle) => {\n-                if self.idle_active.as_ref().unwrap().load(atomic::SeqCst) {\n-                    idle.call();\n-                }\n-            }\n-            None => {}\n-        }\n-    }\n-\n-    fn has_idle(&self) -> bool {\n-        self.idle.is_some() && self.idle_active.as_ref().unwrap().load(atomic::SeqCst)\n-    }\n-}\n-\n-impl EventLoop for BasicLoop {\n-    fn run(&mut self) {\n-        // Not exactly efficient, but it gets the job done.\n-        while self.remotes.len() > 0 || self.work.len() > 0 || self.has_idle() {\n-\n-            self.work();\n-            self.remote_work();\n-\n-            if self.has_idle() {\n-                self.idle();\n-                continue\n-            }\n-\n-            unsafe {\n-                let messages = self.messages.lock();\n-                // We block here if we have no messages to process and we may\n-                // receive a message at a later date\n-                if self.remotes.len() > 0 && messages.len() == 0 &&\n-                   self.work.len() == 0 {\n-                    messages.wait()\n-                }\n-            }\n-        }\n-    }\n-\n-    fn callback(&mut self, f: proc():Send) {\n-        self.work.push(f);\n-    }\n-\n-    // FIXME: Seems like a really weird requirement to have an event loop provide.\n-    fn pausable_idle_callback(&mut self, cb: Box<Callback + Send>)\n-                              -> Box<PausableIdleCallback + Send> {\n-        rtassert!(self.idle.is_none());\n-        self.idle = Some(cb);\n-        let a = Arc::new(atomic::AtomicBool::new(true));\n-        self.idle_active = Some(a.clone());\n-        box BasicPausable { active: a } as Box<PausableIdleCallback + Send>\n-    }\n-\n-    fn remote_callback(&mut self, f: Box<Callback + Send>)\n-                       -> Box<RemoteCallback + Send> {\n-        let id = self.next_remote;\n-        self.next_remote += 1;\n-        self.remotes.push((id, f));\n-        box BasicRemote::new(self.messages.clone(), id) as\n-            Box<RemoteCallback + Send>\n-    }\n-\n-    fn has_active_io(&self) -> bool { false }\n-}\n-\n-struct BasicRemote {\n-    queue: Arc<Exclusive<Vec<Message>>>,\n-    id: uint,\n-}\n-\n-impl BasicRemote {\n-    fn new(queue: Arc<Exclusive<Vec<Message>>>, id: uint) -> BasicRemote {\n-        BasicRemote { queue: queue, id: id }\n-    }\n-}\n-\n-impl RemoteCallback for BasicRemote {\n-    fn fire(&mut self) {\n-        let mut queue = unsafe { self.queue.lock() };\n-        queue.push(RunRemote(self.id));\n-        queue.signal();\n-    }\n-}\n-\n-impl Drop for BasicRemote {\n-    fn drop(&mut self) {\n-        let mut queue = unsafe { self.queue.lock() };\n-        queue.push(RemoveRemote(self.id));\n-        queue.signal();\n-    }\n-}\n-\n-struct BasicPausable {\n-    active: Arc<atomic::AtomicBool>,\n-}\n-\n-impl PausableIdleCallback for BasicPausable {\n-    fn pause(&mut self) {\n-        self.active.store(false, atomic::SeqCst);\n-    }\n-    fn resume(&mut self) {\n-        self.active.store(true, atomic::SeqCst);\n-    }\n-}\n-\n-impl Drop for BasicPausable {\n-    fn drop(&mut self) {\n-        self.active.store(false, atomic::SeqCst);\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use std::rt::task::TaskOpts;\n-\n-    use basic;\n-    use PoolConfig;\n-    use SchedPool;\n-\n-    fn pool() -> SchedPool {\n-        SchedPool::new(PoolConfig {\n-            threads: 1,\n-            event_loop_factory: basic::event_loop,\n-        })\n-    }\n-\n-    fn run(f: proc():Send) {\n-        let mut pool = pool();\n-        pool.spawn(TaskOpts::new(), f);\n-        pool.shutdown();\n-    }\n-\n-    #[test]\n-    fn smoke() {\n-        run(proc() {});\n-    }\n-\n-    #[test]\n-    fn some_channels() {\n-        run(proc() {\n-            let (tx, rx) = channel();\n-            spawn(proc() {\n-                tx.send(());\n-            });\n-            rx.recv();\n-        });\n-    }\n-\n-    #[test]\n-    fn multi_thread() {\n-        let mut pool = SchedPool::new(PoolConfig {\n-            threads: 2,\n-            event_loop_factory: basic::event_loop,\n-        });\n-\n-        for _ in range(0u, 20) {\n-            pool.spawn(TaskOpts::new(), proc() {\n-                let (tx, rx) = channel();\n-                spawn(proc() {\n-                    tx.send(());\n-                });\n-                rx.recv();\n-            });\n-        }\n-\n-        pool.shutdown();\n-    }\n-}"}, {"sha": "2d3e85cc833f3460a4ebb4b5f30332ef4269dded", "filename": "src/libgreen/context.rs", "status": "removed", "additions": 0, "deletions": 325, "changes": 325, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fcontext.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fcontext.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fcontext.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,325 +0,0 @@\n-// Copyright 2013-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use stack::Stack;\n-use std::uint;\n-use std::mem::transmute;\n-use std::rt::stack;\n-use std::raw;\n-#[cfg(target_arch = \"x86_64\")]\n-use std::simd;\n-use libc;\n-\n-// FIXME #7761: Registers is boxed so that it is 16-byte aligned, for storing\n-// SSE regs.  It would be marginally better not to do this. In C++ we\n-// use an attribute on a struct.\n-// FIXME #7761: It would be nice to define regs as `Box<Option<Registers>>`\n-// since the registers are sometimes empty, but the discriminant would\n-// then misalign the regs again.\n-pub struct Context {\n-    /// Hold the registers while the task or scheduler is suspended\n-    regs: Box<Registers>,\n-    /// Lower bound and upper bound for the stack\n-    stack_bounds: Option<(uint, uint)>,\n-}\n-\n-pub type InitFn = extern \"C\" fn(uint, *mut (), *mut ()) -> !;\n-\n-impl Context {\n-    pub fn empty() -> Context {\n-        Context {\n-            regs: new_regs(),\n-            stack_bounds: None,\n-        }\n-    }\n-\n-    /// Create a new context that will resume execution by running proc()\n-    ///\n-    /// The `init` function will be run with `arg` and the `start` procedure\n-    /// split up into code and env pointers. It is required that the `init`\n-    /// function never return.\n-    ///\n-    /// FIXME: this is basically an awful the interface. The main reason for\n-    ///        this is to reduce the number of allocations made when a green\n-    ///        task is spawned as much as possible\n-    pub fn new(init: InitFn, arg: uint, start: proc():Send,\n-               stack: &mut Stack) -> Context {\n-\n-        let sp: *const uint = stack.end();\n-        let sp: *mut uint = sp as *mut uint;\n-        // Save and then immediately load the current context,\n-        // which we will then modify to call the given function when restored\n-        let mut regs = new_regs();\n-\n-        initialize_call_frame(&mut *regs,\n-                              init,\n-                              arg,\n-                              unsafe { transmute(start) },\n-                              sp);\n-\n-        // Scheduler tasks don't have a stack in the \"we allocated it\" sense,\n-        // but rather they run on pthreads stacks. We have complete control over\n-        // them in terms of the code running on them (and hopefully they don't\n-        // overflow). Additionally, their coroutine stacks are listed as being\n-        // zero-length, so that's how we detect what's what here.\n-        let stack_base: *const uint = stack.start();\n-        let bounds = if sp as libc::uintptr_t == stack_base as libc::uintptr_t {\n-            None\n-        } else {\n-            Some((stack_base as uint, sp as uint))\n-        };\n-        return Context {\n-            regs: regs,\n-            stack_bounds: bounds,\n-        }\n-    }\n-\n-    /* Switch contexts\n-\n-    Suspend the current execution context and resume another by\n-    saving the registers values of the executing thread to a Context\n-    then loading the registers from a previously saved Context.\n-    */\n-    pub fn swap(out_context: &mut Context, in_context: &Context) {\n-        rtdebug!(\"swapping contexts\");\n-        let out_regs: &mut Registers = match out_context {\n-            &Context { regs: box ref mut r, .. } => r\n-        };\n-        let in_regs: &Registers = match in_context {\n-            &Context { regs: box ref r, .. } => r\n-        };\n-\n-        rtdebug!(\"noting the stack limit and doing raw swap\");\n-\n-        unsafe {\n-            // Right before we switch to the new context, set the new context's\n-            // stack limit in the OS-specified TLS slot. This also  means that\n-            // we cannot call any more rust functions after record_stack_bounds\n-            // returns because they would all likely panic due to the limit being\n-            // invalid for the current task. Lucky for us `rust_swap_registers`\n-            // is a C function so we don't have to worry about that!\n-            match in_context.stack_bounds {\n-                Some((lo, hi)) => stack::record_rust_managed_stack_bounds(lo, hi),\n-                // If we're going back to one of the original contexts or\n-                // something that's possibly not a \"normal task\", then reset\n-                // the stack limit to 0 to make morestack never panic\n-                None => stack::record_rust_managed_stack_bounds(0, uint::MAX),\n-            }\n-            rust_swap_registers(out_regs, in_regs);\n-        }\n-    }\n-}\n-\n-#[link(name = \"context_switch\", kind = \"static\")]\n-extern {\n-    fn rust_swap_registers(out_regs: *mut Registers, in_regs: *const Registers);\n-}\n-\n-// Register contexts used in various architectures\n-//\n-// These structures all represent a context of one task throughout its\n-// execution. Each struct is a representation of the architecture's register\n-// set. When swapping between tasks, these register sets are used to save off\n-// the current registers into one struct, and load them all from another.\n-//\n-// Note that this is only used for context switching, which means that some of\n-// the registers may go unused. For example, for architectures with\n-// callee/caller saved registers, the context will only reflect the callee-saved\n-// registers. This is because the caller saved registers are already stored\n-// elsewhere on the stack (if it was necessary anyway).\n-//\n-// Additionally, there may be fields on various architectures which are unused\n-// entirely because they only reflect what is theoretically possible for a\n-// \"complete register set\" to show, but user-space cannot alter these registers.\n-// An example of this would be the segment selectors for x86.\n-//\n-// These structures/functions are roughly in-sync with the source files inside\n-// of src/rt/arch/$arch. The only currently used function from those folders is\n-// the `rust_swap_registers` function, but that's only because for now segmented\n-// stacks are disabled.\n-\n-#[cfg(target_arch = \"x86\")]\n-#[repr(C)]\n-struct Registers {\n-    eax: u32, ebx: u32, ecx: u32, edx: u32,\n-    ebp: u32, esi: u32, edi: u32, esp: u32,\n-    cs: u16, ds: u16, ss: u16, es: u16, fs: u16, gs: u16,\n-    eflags: u32, eip: u32\n-}\n-\n-#[cfg(target_arch = \"x86\")]\n-fn new_regs() -> Box<Registers> {\n-    box Registers {\n-        eax: 0, ebx: 0, ecx: 0, edx: 0,\n-        ebp: 0, esi: 0, edi: 0, esp: 0,\n-        cs: 0, ds: 0, ss: 0, es: 0, fs: 0, gs: 0,\n-        eflags: 0, eip: 0\n-    }\n-}\n-\n-#[cfg(target_arch = \"x86\")]\n-fn initialize_call_frame(regs: &mut Registers, fptr: InitFn, arg: uint,\n-                         procedure: raw::Procedure, sp: *mut uint) {\n-    let sp = sp as *mut uint;\n-    // x86 has interesting stack alignment requirements, so do some alignment\n-    // plus some offsetting to figure out what the actual stack should be.\n-    let sp = align_down(sp);\n-    let sp = mut_offset(sp, -4);\n-\n-    unsafe { *mut_offset(sp, 2) = procedure.env as uint };\n-    unsafe { *mut_offset(sp, 1) = procedure.code as uint };\n-    unsafe { *mut_offset(sp, 0) = arg as uint };\n-    let sp = mut_offset(sp, -1);\n-    unsafe { *sp = 0 }; // The final return address\n-\n-    regs.esp = sp as u32;\n-    regs.eip = fptr as u32;\n-\n-    // Last base pointer on the stack is 0\n-    regs.ebp = 0;\n-}\n-\n-// windows requires saving more registers (both general and XMM), so the windows\n-// register context must be larger.\n-#[cfg(all(windows, target_arch = \"x86_64\"))]\n-#[repr(C)]\n-struct Registers {\n-    gpr:[libc::uintptr_t, ..14],\n-    _xmm:[simd::u32x4, ..10]\n-}\n-#[cfg(all(not(windows), target_arch = \"x86_64\"))]\n-#[repr(C)]\n-struct Registers {\n-    gpr:[libc::uintptr_t, ..10],\n-    _xmm:[simd::u32x4, ..6]\n-}\n-\n-#[cfg(all(windows, target_arch = \"x86_64\"))]\n-fn new_regs() -> Box<Registers> {\n-    box() Registers {\n-        gpr:[0,..14],\n-        _xmm:[simd::u32x4(0,0,0,0),..10]\n-    }\n-}\n-#[cfg(all(not(windows), target_arch = \"x86_64\"))]\n-fn new_regs() -> Box<Registers> {\n-    box() Registers {\n-        gpr:[0,..10],\n-        _xmm:[simd::u32x4(0,0,0,0),..6]\n-    }\n-}\n-\n-#[cfg(target_arch = \"x86_64\")]\n-fn initialize_call_frame(regs: &mut Registers, fptr: InitFn, arg: uint,\n-                         procedure: raw::Procedure, sp: *mut uint) {\n-    extern { fn rust_bootstrap_green_task(); }\n-\n-    // Redefinitions from rt/arch/x86_64/regs.h\n-    static RUSTRT_RSP: uint = 1;\n-    static RUSTRT_IP: uint = 8;\n-    static RUSTRT_RBP: uint = 2;\n-    static RUSTRT_R12: uint = 4;\n-    static RUSTRT_R13: uint = 5;\n-    static RUSTRT_R14: uint = 6;\n-    static RUSTRT_R15: uint = 7;\n-\n-    let sp = align_down(sp);\n-    let sp = mut_offset(sp, -1);\n-\n-    // The final return address. 0 indicates the bottom of the stack\n-    unsafe { *sp = 0; }\n-\n-    rtdebug!(\"creating call frame\");\n-    rtdebug!(\"fptr {:#x}\", fptr as libc::uintptr_t);\n-    rtdebug!(\"arg {:#x}\", arg);\n-    rtdebug!(\"sp {}\", sp);\n-\n-    // These registers are frobbed by rust_bootstrap_green_task into the right\n-    // location so we can invoke the \"real init function\", `fptr`.\n-    regs.gpr[RUSTRT_R12] = arg as libc::uintptr_t;\n-    regs.gpr[RUSTRT_R13] = procedure.code as libc::uintptr_t;\n-    regs.gpr[RUSTRT_R14] = procedure.env as libc::uintptr_t;\n-    regs.gpr[RUSTRT_R15] = fptr as libc::uintptr_t;\n-\n-    // These registers are picked up by the regular context switch paths. These\n-    // will put us in \"mostly the right context\" except for frobbing all the\n-    // arguments to the right place. We have the small trampoline code inside of\n-    // rust_bootstrap_green_task to do that.\n-    regs.gpr[RUSTRT_RSP] = sp as libc::uintptr_t;\n-    regs.gpr[RUSTRT_IP] = rust_bootstrap_green_task as libc::uintptr_t;\n-\n-    // Last base pointer on the stack should be 0\n-    regs.gpr[RUSTRT_RBP] = 0;\n-}\n-\n-#[cfg(target_arch = \"arm\")]\n-type Registers = [libc::uintptr_t, ..32];\n-\n-#[cfg(target_arch = \"arm\")]\n-fn new_regs() -> Box<Registers> { box {[0, .. 32]} }\n-\n-#[cfg(target_arch = \"arm\")]\n-fn initialize_call_frame(regs: &mut Registers, fptr: InitFn, arg: uint,\n-                         procedure: raw::Procedure, sp: *mut uint) {\n-    extern { fn rust_bootstrap_green_task(); }\n-\n-    let sp = align_down(sp);\n-    // sp of arm eabi is 8-byte aligned\n-    let sp = mut_offset(sp, -2);\n-\n-    // The final return address. 0 indicates the bottom of the stack\n-    unsafe { *sp = 0; }\n-\n-    // ARM uses the same technique as x86_64 to have a landing pad for the start\n-    // of all new green tasks. Neither r1/r2 are saved on a context switch, so\n-    // the shim will copy r3/r4 into r1/r2 and then execute the function in r5\n-    regs[0] = arg as libc::uintptr_t;              // r0\n-    regs[3] = procedure.code as libc::uintptr_t;   // r3\n-    regs[4] = procedure.env as libc::uintptr_t;    // r4\n-    regs[5] = fptr as libc::uintptr_t;             // r5\n-    regs[13] = sp as libc::uintptr_t;                          // #52 sp, r13\n-    regs[14] = rust_bootstrap_green_task as libc::uintptr_t;   // #56 pc, r14 --> lr\n-}\n-\n-#[cfg(any(target_arch = \"mips\", target_arch = \"mipsel\"))]\n-type Registers = [libc::uintptr_t, ..32];\n-\n-#[cfg(any(target_arch = \"mips\", target_arch = \"mipsel\"))]\n-fn new_regs() -> Box<Registers> { box {[0, .. 32]} }\n-\n-#[cfg(any(target_arch = \"mips\", target_arch = \"mipsel\"))]\n-fn initialize_call_frame(regs: &mut Registers, fptr: InitFn, arg: uint,\n-                         procedure: raw::Procedure, sp: *mut uint) {\n-    let sp = align_down(sp);\n-    // sp of mips o32 is 8-byte aligned\n-    let sp = mut_offset(sp, -2);\n-\n-    // The final return address. 0 indicates the bottom of the stack\n-    unsafe { *sp = 0; }\n-\n-    regs[4] = arg as libc::uintptr_t;\n-    regs[5] = procedure.code as libc::uintptr_t;\n-    regs[6] = procedure.env as libc::uintptr_t;\n-    regs[29] = sp as libc::uintptr_t;\n-    regs[25] = fptr as libc::uintptr_t;\n-    regs[31] = fptr as libc::uintptr_t;\n-}\n-\n-fn align_down(sp: *mut uint) -> *mut uint {\n-    let sp = (sp as uint) & !(16 - 1);\n-    sp as *mut uint\n-}\n-\n-// ptr::mut_offset is positive ints only\n-#[inline]\n-pub fn mut_offset<T>(ptr: *mut T, count: int) -> *mut T {\n-    use std::mem::size_of;\n-    (ptr as int + count * (size_of::<T>() as int)) as *mut T\n-}"}, {"sha": "f2e64dc25a970423d442a5e3e8dbda92250ebb0f", "filename": "src/libgreen/coroutine.rs", "status": "removed", "additions": 0, "deletions": 44, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fcoroutine.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fcoroutine.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fcoroutine.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,44 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// Coroutines represent nothing more than a context and a stack\n-// segment.\n-\n-use context::Context;\n-use stack::{StackPool, Stack};\n-\n-/// A coroutine is nothing more than a (register context, stack) pair.\n-pub struct Coroutine {\n-    /// The segment of stack on which the task is currently running or\n-    /// if the task is blocked, on which the task will resume\n-    /// execution.\n-    ///\n-    /// Servo needs this to be public in order to tell SpiderMonkey\n-    /// about the stack bounds.\n-    pub current_stack_segment: Stack,\n-\n-    /// Always valid if the task is alive and not running.\n-    pub saved_context: Context\n-}\n-\n-impl Coroutine {\n-    pub fn empty() -> Coroutine {\n-        Coroutine {\n-            current_stack_segment: unsafe { Stack::dummy_stack() },\n-            saved_context: Context::empty()\n-        }\n-    }\n-\n-    /// Destroy coroutine and try to reuse std::stack segment.\n-    pub fn recycle(self, stack_pool: &mut StackPool) {\n-        let Coroutine { current_stack_segment, .. } = self;\n-        stack_pool.give_stack(current_stack_segment);\n-    }\n-}"}, {"sha": "4e2908dd2b025b16fde151f25dfc7cbbc3ae8f38", "filename": "src/libgreen/lib.rs", "status": "removed", "additions": 0, "deletions": 567, "changes": 567, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Flib.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,567 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! The \"green scheduling\" library\n-//!\n-//! This library provides M:N threading for rust programs. Internally this has\n-//! the implementation of a green scheduler along with context switching and a\n-//! stack-allocation strategy. This can be optionally linked in to rust\n-//! programs in order to provide M:N functionality inside of 1:1 programs.\n-//!\n-//! # Architecture\n-//!\n-//! An M:N scheduling library implies that there are N OS thread upon which M\n-//! \"green threads\" are multiplexed. In other words, a set of green threads are\n-//! all run inside a pool of OS threads.\n-//!\n-//! With this design, you can achieve _concurrency_ by spawning many green\n-//! threads, and you can achieve _parallelism_ by running the green threads\n-//! simultaneously on multiple OS threads. Each OS thread is a candidate for\n-//! being scheduled on a different core (the source of parallelism), and then\n-//! all of the green threads cooperatively schedule amongst one another (the\n-//! source of concurrency).\n-//!\n-//! ## Schedulers\n-//!\n-//! In order to coordinate among green threads, each OS thread is primarily\n-//! running something which we call a Scheduler. Whenever a reference to a\n-//! Scheduler is made, it is synonymous to referencing one OS thread. Each\n-//! scheduler is bound to one and exactly one OS thread, and the thread that it\n-//! is bound to never changes.\n-//!\n-//! Each scheduler is connected to a pool of other schedulers (a `SchedPool`)\n-//! which is the thread pool term from above. A pool of schedulers all share the\n-//! work that they create. Furthermore, whenever a green thread is created (also\n-//! synonymously referred to as a green task), it is associated with a\n-//! `SchedPool` forevermore. A green thread cannot leave its scheduler pool.\n-//!\n-//! Schedulers can have at most one green thread running on them at a time. When\n-//! a scheduler is asleep on its event loop, there are no green tasks running on\n-//! the OS thread or the scheduler. The term \"context switch\" is used for when\n-//! the running green thread is swapped out, but this simply changes the one\n-//! green thread which is running on the scheduler.\n-//!\n-//! ## Green Threads\n-//!\n-//! A green thread can largely be summarized by a stack and a register context.\n-//! Whenever a green thread is spawned, it allocates a stack, and then prepares\n-//! a register context for execution. The green task may be executed across\n-//! multiple OS threads, but it will always use the same stack and it will carry\n-//! its register context across OS threads.\n-//!\n-//! Each green thread is cooperatively scheduled with other green threads.\n-//! Primarily, this means that there is no pre-emption of a green thread. The\n-//! major consequence of this design is that a green thread stuck in an infinite\n-//! loop will prevent all other green threads from running on that particular\n-//! scheduler.\n-//!\n-//! Scheduling events for green threads occur on communication and I/O\n-//! boundaries. For example, if a green task blocks waiting for a message on a\n-//! channel some other green thread can now run on the scheduler. This also has\n-//! the consequence that until a green thread performs any form of scheduling\n-//! event, it will be running on the same OS thread (unconditionally).\n-//!\n-//! ## Work Stealing\n-//!\n-//! With a pool of schedulers, a new green task has a number of options when\n-//! deciding where to run initially. The current implementation uses a concept\n-//! called work stealing in order to spread out work among schedulers.\n-//!\n-//! In a work-stealing model, each scheduler maintains a local queue of tasks to\n-//! run, and this queue is stolen from by other schedulers. Implementation-wise,\n-//! work stealing has some hairy parts, but from a user-perspective, work\n-//! stealing simply implies what with M green threads and N schedulers where\n-//! M > N it is very likely that all schedulers will be busy executing work.\n-//!\n-//! # Considerations when using libgreen\n-//!\n-//! An M:N runtime has both pros and cons, and there is no one answer as to\n-//! whether M:N or 1:1 is appropriate to use. As always, there are many\n-//! advantages and disadvantages between the two. Regardless of the workload,\n-//! however, there are some aspects of using green thread which you should be\n-//! aware of:\n-//!\n-//! * The largest concern when using libgreen is interoperating with native\n-//!   code. Care should be taken when calling native code that will block the OS\n-//!   thread as it will prevent further green tasks from being scheduled on the\n-//!   OS thread.\n-//!\n-//! * Native code using thread-local-storage should be approached\n-//!   with care. Green threads may migrate among OS threads at any time, so\n-//!   native libraries using thread-local state may not always work.\n-//!\n-//! * Native synchronization primitives (e.g. pthread mutexes) will also not\n-//!   work for green threads. The reason for this is because native primitives\n-//!   often operate on a _os thread_ granularity whereas green threads are\n-//!   operating on a more granular unit of work.\n-//!\n-//! * A green threading runtime is not fork-safe. If the process forks(), it\n-//!   cannot expect to make reasonable progress by continuing to use green\n-//!   threads.\n-//!\n-//! Note that these concerns do not mean that operating with native code is a\n-//! lost cause. These are simply just concerns which should be considered when\n-//! invoking native code.\n-//!\n-//! # Starting with libgreen\n-//!\n-//! ```rust\n-//! extern crate green;\n-//!\n-//! #[start]\n-//! fn start(argc: int, argv: *const *const u8) -> int {\n-//!     green::start(argc, argv, green::basic::event_loop, main)\n-//! }\n-//!\n-//! fn main() {\n-//!     // this code is running in a pool of schedulers\n-//! }\n-//! ```\n-//!\n-//! > **Note**: This `main` function in this example does *not* have I/O\n-//! >           support. The basic event loop does not provide any support\n-//!\n-//! # Using a scheduler pool\n-//!\n-//! This library adds a `GreenTaskBuilder` trait that extends the methods\n-//! available on `std::task::TaskBuilder` to allow spawning a green task,\n-//! possibly pinned to a particular scheduler thread:\n-//!\n-//! ```rust\n-//! extern crate green;\n-//!\n-//! # fn main() {\n-//! use std::task::TaskBuilder;\n-//! use green::{SchedPool, PoolConfig, GreenTaskBuilder};\n-//!\n-//! let mut config = PoolConfig::new();\n-//!\n-//! let mut pool = SchedPool::new(config);\n-//!\n-//! // Spawn tasks into the pool of schedulers\n-//! TaskBuilder::new().green(&mut pool).spawn(proc() {\n-//!     // this code is running inside the pool of schedulers\n-//!\n-//!     spawn(proc() {\n-//!         // this code is also running inside the same scheduler pool\n-//!     });\n-//! });\n-//!\n-//! // Dynamically add a new scheduler to the scheduler pool. This adds another\n-//! // OS thread that green threads can be multiplexed on to.\n-//! let mut handle = pool.spawn_sched();\n-//!\n-//! // Pin a task to the spawned scheduler\n-//! TaskBuilder::new().green_pinned(&mut pool, &mut handle).spawn(proc() {\n-//!     /* ... */\n-//! });\n-//!\n-//! // Handles keep schedulers alive, so be sure to drop all handles before\n-//! // destroying the sched pool\n-//! drop(handle);\n-//!\n-//! // Required to shut down this scheduler pool.\n-//! // The task will panic if `shutdown` is not called.\n-//! pool.shutdown();\n-//! # }\n-//! ```\n-\n-#![crate_name = \"green\"]\n-#![experimental]\n-#![license = \"MIT/ASL2\"]\n-#![crate_type = \"rlib\"]\n-#![crate_type = \"dylib\"]\n-#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n-       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n-       html_root_url = \"http://doc.rust-lang.org/nightly/\",\n-       html_playground_url = \"http://play.rust-lang.org/\")]\n-\n-#![feature(macro_rules, phase, default_type_params, globs)]\n-#![allow(deprecated)]\n-\n-#[cfg(test)] #[phase(plugin, link)] extern crate log;\n-extern crate libc;\n-extern crate alloc;\n-\n-use alloc::arc::Arc;\n-use std::mem::replace;\n-use std::os;\n-use std::rt::rtio;\n-use std::rt::thread::Thread;\n-use std::rt::task::TaskOpts;\n-use std::rt;\n-use std::sync::atomic::{SeqCst, AtomicUint, INIT_ATOMIC_UINT};\n-use std::sync::deque;\n-use std::task::{TaskBuilder, Spawner};\n-\n-use sched::{Shutdown, Scheduler, SchedHandle, TaskFromFriend, PinnedTask, NewNeighbor};\n-use sleeper_list::SleeperList;\n-use stack::StackPool;\n-use task::GreenTask;\n-\n-mod macros;\n-mod simple;\n-mod message_queue;\n-\n-pub mod basic;\n-pub mod context;\n-pub mod coroutine;\n-pub mod sched;\n-pub mod sleeper_list;\n-pub mod stack;\n-pub mod task;\n-\n-/// Set up a default runtime configuration, given compiler-supplied arguments.\n-///\n-/// This function will block until the entire pool of M:N schedulers have\n-/// exited. This function also requires a local task to be available.\n-///\n-/// # Arguments\n-///\n-/// * `argc` & `argv` - The argument vector. On Unix this information is used\n-///   by os::args.\n-/// * `main` - The initial procedure to run inside of the M:N scheduling pool.\n-///            Once this procedure exits, the scheduling pool will begin to shut\n-///            down. The entire pool (and this function) will only return once\n-///            all child tasks have finished executing.\n-///\n-/// # Return value\n-///\n-/// The return value is used as the process return code. 0 on success, 101 on\n-/// error.\n-pub fn start(argc: int, argv: *const *const u8,\n-             event_loop_factory: fn() -> Box<rtio::EventLoop + Send>,\n-             main: proc():Send) -> int {\n-    rt::init(argc, argv);\n-    let mut main = Some(main);\n-    let mut ret = None;\n-    simple::task().run(|| {\n-        ret = Some(run(event_loop_factory, main.take().unwrap()));\n-    }).destroy();\n-    // unsafe is ok b/c we're sure that the runtime is gone\n-    unsafe { rt::cleanup() }\n-    ret.unwrap()\n-}\n-\n-/// Execute the main function in a pool of M:N schedulers.\n-///\n-/// Configures the runtime according to the environment, by default using a task\n-/// scheduler with the same number of threads as cores.  Returns a process exit\n-/// code.\n-///\n-/// This function will not return until all schedulers in the associated pool\n-/// have returned.\n-pub fn run(event_loop_factory: fn() -> Box<rtio::EventLoop + Send>,\n-           main: proc():Send) -> int {\n-    // Create a scheduler pool and spawn the main task into this pool. We will\n-    // get notified over a channel when the main task exits.\n-    let mut cfg = PoolConfig::new();\n-    cfg.event_loop_factory = event_loop_factory;\n-    let mut pool = SchedPool::new(cfg);\n-    let (tx, rx) = channel();\n-    let mut opts = TaskOpts::new();\n-    opts.on_exit = Some(proc(r) tx.send(r));\n-    opts.name = Some(\"<main>\".into_maybe_owned());\n-    pool.spawn(opts, main);\n-\n-    // Wait for the main task to return, and set the process error code\n-    // appropriately.\n-    if rx.recv().is_err() {\n-        os::set_exit_status(rt::DEFAULT_ERROR_CODE);\n-    }\n-\n-    // Now that we're sure all tasks are dead, shut down the pool of schedulers,\n-    // waiting for them all to return.\n-    pool.shutdown();\n-    os::get_exit_status()\n-}\n-\n-/// Configuration of how an M:N pool of schedulers is spawned.\n-pub struct PoolConfig {\n-    /// The number of schedulers (OS threads) to spawn into this M:N pool.\n-    pub threads: uint,\n-    /// A factory function used to create new event loops. If this is not\n-    /// specified then the default event loop factory is used.\n-    pub event_loop_factory: fn() -> Box<rtio::EventLoop + Send>,\n-}\n-\n-impl PoolConfig {\n-    /// Returns the default configuration, as determined the environment\n-    /// variables of this process.\n-    pub fn new() -> PoolConfig {\n-        PoolConfig {\n-            threads: rt::default_sched_threads(),\n-            event_loop_factory: basic::event_loop,\n-        }\n-    }\n-}\n-\n-/// A structure representing a handle to a pool of schedulers. This handle is\n-/// used to keep the pool alive and also reap the status from the pool.\n-pub struct SchedPool {\n-    id: uint,\n-    threads: Vec<Thread<()>>,\n-    handles: Vec<SchedHandle>,\n-    stealers: Vec<deque::Stealer<Box<task::GreenTask>>>,\n-    next_friend: uint,\n-    stack_pool: StackPool,\n-    deque_pool: deque::BufferPool<Box<task::GreenTask>>,\n-    sleepers: SleeperList,\n-    factory: fn() -> Box<rtio::EventLoop + Send>,\n-    task_state: TaskState,\n-    tasks_done: Receiver<()>,\n-}\n-\n-/// This is an internal state shared among a pool of schedulers. This is used to\n-/// keep track of how many tasks are currently running in the pool and then\n-/// sending on a channel once the entire pool has been drained of all tasks.\n-#[deriving(Clone)]\n-pub struct TaskState {\n-    cnt: Arc<AtomicUint>,\n-    done: Sender<()>,\n-}\n-\n-impl SchedPool {\n-    /// Execute the main function in a pool of M:N schedulers.\n-    ///\n-    /// This will configure the pool according to the `config` parameter, and\n-    /// initially run `main` inside the pool of schedulers.\n-    pub fn new(config: PoolConfig) -> SchedPool {\n-        static POOL_ID: AtomicUint = INIT_ATOMIC_UINT;\n-\n-        let PoolConfig {\n-            threads: nscheds,\n-            event_loop_factory: factory\n-        } = config;\n-        assert!(nscheds > 0);\n-\n-        // The pool of schedulers that will be returned from this function\n-        let (p, state) = TaskState::new();\n-        let mut pool = SchedPool {\n-            threads: vec![],\n-            handles: vec![],\n-            stealers: vec![],\n-            id: POOL_ID.fetch_add(1, SeqCst),\n-            sleepers: SleeperList::new(),\n-            stack_pool: StackPool::new(),\n-            deque_pool: deque::BufferPool::new(),\n-            next_friend: 0,\n-            factory: factory,\n-            task_state: state,\n-            tasks_done: p,\n-        };\n-\n-        // Create a work queue for each scheduler, ntimes. Create an extra\n-        // for the main thread if that flag is set. We won't steal from it.\n-        let mut workers = Vec::with_capacity(nscheds);\n-        let mut stealers = Vec::with_capacity(nscheds);\n-\n-        for _ in range(0, nscheds) {\n-            let (w, s) = pool.deque_pool.deque();\n-            workers.push(w);\n-            stealers.push(s);\n-        }\n-        pool.stealers = stealers;\n-\n-        // Now that we've got all our work queues, create one scheduler per\n-        // queue, spawn the scheduler into a thread, and be sure to keep a\n-        // handle to the scheduler and the thread to keep them alive.\n-        for worker in workers.into_iter() {\n-            rtdebug!(\"inserting a regular scheduler\");\n-\n-            let mut sched = box Scheduler::new(pool.id,\n-                                            (pool.factory)(),\n-                                            worker,\n-                                            pool.stealers.clone(),\n-                                            pool.sleepers.clone(),\n-                                            pool.task_state.clone());\n-            pool.handles.push(sched.make_handle());\n-            pool.threads.push(Thread::start(proc() { sched.bootstrap(); }));\n-        }\n-\n-        return pool;\n-    }\n-\n-    /// Creates a new task configured to run inside of this pool of schedulers.\n-    /// This is useful to create a task which can then be sent to a specific\n-    /// scheduler created by `spawn_sched` (and possibly pin it to that\n-    /// scheduler).\n-    #[deprecated = \"use the green and green_pinned methods of GreenTaskBuilder instead\"]\n-    pub fn task(&mut self, opts: TaskOpts, f: proc():Send) -> Box<GreenTask> {\n-        GreenTask::configure(&mut self.stack_pool, opts, f)\n-    }\n-\n-    /// Spawns a new task into this pool of schedulers, using the specified\n-    /// options to configure the new task which is spawned.\n-    ///\n-    /// New tasks are spawned in a round-robin fashion to the schedulers in this\n-    /// pool, but tasks can certainly migrate among schedulers once they're in\n-    /// the pool.\n-    #[deprecated = \"use the green and green_pinned methods of GreenTaskBuilder instead\"]\n-    pub fn spawn(&mut self, opts: TaskOpts, f: proc():Send) {\n-        let task = self.task(opts, f);\n-\n-        // Figure out someone to send this task to\n-        let idx = self.next_friend;\n-        self.next_friend += 1;\n-        if self.next_friend >= self.handles.len() {\n-            self.next_friend = 0;\n-        }\n-\n-        // Jettison the task away!\n-        self.handles[idx].send(TaskFromFriend(task));\n-    }\n-\n-    /// Spawns a new scheduler into this M:N pool. A handle is returned to the\n-    /// scheduler for use. The scheduler will not exit as long as this handle is\n-    /// active.\n-    ///\n-    /// The scheduler spawned will participate in work stealing with all of the\n-    /// other schedulers currently in the scheduler pool.\n-    pub fn spawn_sched(&mut self) -> SchedHandle {\n-        let (worker, stealer) = self.deque_pool.deque();\n-        self.stealers.push(stealer.clone());\n-\n-        // Tell all existing schedulers about this new scheduler so they can all\n-        // steal work from it\n-        for handle in self.handles.iter_mut() {\n-            handle.send(NewNeighbor(stealer.clone()));\n-        }\n-\n-        // Create the new scheduler, using the same sleeper list as all the\n-        // other schedulers as well as having a stealer handle to all other\n-        // schedulers.\n-        let mut sched = box Scheduler::new(self.id,\n-                                        (self.factory)(),\n-                                        worker,\n-                                        self.stealers.clone(),\n-                                        self.sleepers.clone(),\n-                                        self.task_state.clone());\n-        let ret = sched.make_handle();\n-        self.handles.push(sched.make_handle());\n-        self.threads.push(Thread::start(proc() { sched.bootstrap() }));\n-\n-        return ret;\n-    }\n-\n-    /// Consumes the pool of schedulers, waiting for all tasks to exit and all\n-    /// schedulers to shut down.\n-    ///\n-    /// This function is required to be called in order to drop a pool of\n-    /// schedulers, it is considered an error to drop a pool without calling\n-    /// this method.\n-    ///\n-    /// This only waits for all tasks in *this pool* of schedulers to exit, any\n-    /// native tasks or extern pools will not be waited on\n-    pub fn shutdown(mut self) {\n-        self.stealers = vec![];\n-\n-        // Wait for everyone to exit. We may have reached a 0-task count\n-        // multiple times in the past, meaning there could be several buffered\n-        // messages on the `tasks_done` port. We're guaranteed that after *some*\n-        // message the current task count will be 0, so we just receive in a\n-        // loop until everything is totally dead.\n-        while self.task_state.active() {\n-            self.tasks_done.recv();\n-        }\n-\n-        // Now that everyone's gone, tell everything to shut down.\n-        for mut handle in replace(&mut self.handles, vec![]).into_iter() {\n-            handle.send(Shutdown);\n-        }\n-        for thread in replace(&mut self.threads, vec![]).into_iter() {\n-            thread.join();\n-        }\n-    }\n-}\n-\n-impl TaskState {\n-    fn new() -> (Receiver<()>, TaskState) {\n-        let (tx, rx) = channel();\n-        (rx, TaskState {\n-            cnt: Arc::new(AtomicUint::new(0)),\n-            done: tx,\n-        })\n-    }\n-\n-    fn increment(&mut self) {\n-        self.cnt.fetch_add(1, SeqCst);\n-    }\n-\n-    fn active(&self) -> bool {\n-        self.cnt.load(SeqCst) != 0\n-    }\n-\n-    fn decrement(&mut self) {\n-        let prev = self.cnt.fetch_sub(1, SeqCst);\n-        if prev == 1 {\n-            self.done.send(());\n-        }\n-    }\n-}\n-\n-impl Drop for SchedPool {\n-    fn drop(&mut self) {\n-        if self.threads.len() > 0 {\n-            panic!(\"dropping a M:N scheduler pool that wasn't shut down\");\n-        }\n-    }\n-}\n-\n-/// A spawner for green tasks\n-pub struct GreenSpawner<'a>{\n-    pool: &'a mut SchedPool,\n-    handle: Option<&'a mut SchedHandle>\n-}\n-\n-impl<'a> Spawner for GreenSpawner<'a> {\n-    #[inline]\n-    fn spawn(self, opts: TaskOpts, f: proc():Send) {\n-        let GreenSpawner { pool, handle } = self;\n-        match handle {\n-            None    => pool.spawn(opts, f),\n-            Some(h) => h.send(PinnedTask(pool.task(opts, f)))\n-        }\n-    }\n-}\n-\n-/// An extension trait adding `green` configuration methods to `TaskBuilder`.\n-pub trait GreenTaskBuilder {\n-    fn green<'a>(self, &'a mut SchedPool) -> TaskBuilder<GreenSpawner<'a>>;\n-    fn green_pinned<'a>(self, &'a mut SchedPool, &'a mut SchedHandle)\n-                        -> TaskBuilder<GreenSpawner<'a>>;\n-}\n-\n-impl<S: Spawner> GreenTaskBuilder for TaskBuilder<S> {\n-    fn green<'a>(self, pool: &'a mut SchedPool) -> TaskBuilder<GreenSpawner<'a>> {\n-        self.spawner(GreenSpawner {pool: pool, handle: None})\n-    }\n-\n-    fn green_pinned<'a>(self, pool: &'a mut SchedPool, handle: &'a mut SchedHandle)\n-                        -> TaskBuilder<GreenSpawner<'a>> {\n-        self.spawner(GreenSpawner {pool: pool, handle: Some(handle)})\n-    }\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use std::task::TaskBuilder;\n-    use super::{SchedPool, PoolConfig, GreenTaskBuilder};\n-\n-    #[test]\n-    fn test_green_builder() {\n-        let mut pool = SchedPool::new(PoolConfig::new());\n-        let res = TaskBuilder::new().green(&mut pool).try(proc() {\n-            \"Success!\".to_string()\n-        });\n-        assert_eq!(res.ok().unwrap(), \"Success!\".to_string());\n-        pool.shutdown();\n-    }\n-}"}, {"sha": "4cce430d88a8d3522e1e75e776a64ab1a29cd97b", "filename": "src/libgreen/macros.rs", "status": "removed", "additions": 0, "deletions": 118, "changes": 118, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fmacros.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fmacros.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fmacros.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,118 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// FIXME: this file probably shouldn't exist\n-// ignore-lexer-test FIXME #15677\n-\n-#![macro_escape]\n-\n-use std::fmt;\n-\n-// Indicates whether we should perform expensive sanity checks, including rtassert!\n-// FIXME: Once the runtime matures remove the `true` below to turn off rtassert, etc.\n-pub static ENFORCE_SANITY: bool = true || !cfg!(rtopt) || cfg!(rtdebug) || cfg!(rtassert);\n-\n-macro_rules! rterrln (\n-    ($($arg:tt)*) => ( {\n-        format_args!(::macros::dumb_println, $($arg)*)\n-    } )\n-)\n-\n-// Some basic logging. Enabled by passing `--cfg rtdebug` to the libstd build.\n-macro_rules! rtdebug (\n-    ($($arg:tt)*) => ( {\n-        if cfg!(rtdebug) {\n-            rterrln!($($arg)*)\n-        }\n-    })\n-)\n-\n-macro_rules! rtassert (\n-    ( $arg:expr ) => ( {\n-        if ::macros::ENFORCE_SANITY {\n-            if !$arg {\n-                rtabort!(\" assertion failed: {}\", stringify!($arg));\n-            }\n-        }\n-    } )\n-)\n-\n-\n-macro_rules! rtabort (\n-    ($($arg:tt)*) => ( {\n-        ::macros::abort(format!($($arg)*).as_slice());\n-    } )\n-)\n-\n-pub fn dumb_println(args: &fmt::Arguments) {\n-    use std::rt;\n-    let mut w = rt::Stderr;\n-    let _ = writeln!(&mut w, \"{}\", args);\n-}\n-\n-pub fn abort(msg: &str) -> ! {\n-    let msg = if !msg.is_empty() { msg } else { \"aborted\" };\n-    let hash = msg.chars().fold(0, |accum, val| accum + (val as uint) );\n-    let quote = match hash % 10 {\n-        0 => \"\n-It was from the artists and poets that the pertinent answers came, and I\n-know that panic would have broken loose had they been able to compare notes.\n-As it was, lacking their original letters, I half suspected the compiler of\n-having asked leading questions, or of having edited the correspondence in\n-corroboration of what he had latently resolved to see.\",\n-        1 => \"\n-There are not many persons who know what wonders are opened to them in the\n-stories and visions of their youth; for when as children we listen and dream,\n-we think but half-formed thoughts, and when as men we try to remember, we are\n-dulled and prosaic with the poison of life. But some of us awake in the night\n-with strange phantasms of enchanted hills and gardens, of fountains that sing\n-in the sun, of golden cliffs overhanging murmuring seas, of plains that stretch\n-down to sleeping cities of bronze and stone, and of shadowy companies of heroes\n-that ride caparisoned white horses along the edges of thick forests; and then\n-we know that we have looked back through the ivory gates into that world of\n-wonder which was ours before we were wise and unhappy.\",\n-        2 => \"\n-Instead of the poems I had hoped for, there came only a shuddering blackness\n-and ineffable loneliness; and I saw at last a fearful truth which no one had\n-ever dared to breathe before \u2014 the unwhisperable secret of secrets \u2014 The fact\n-that this city of stone and stridor is not a sentient perpetuation of Old New\n-York as London is of Old London and Paris of Old Paris, but that it is in fact\n-quite dead, its sprawling body imperfectly embalmed and infested with queer\n-animate things which have nothing to do with it as it was in life.\",\n-        3 => \"\n-The ocean ate the last of the land and poured into the smoking gulf, thereby\n-giving up all it had ever conquered. From the new-flooded lands it flowed\n-again, uncovering death and decay; and from its ancient and immemorial bed it\n-trickled loathsomely, uncovering nighted secrets of the years when Time was\n-young and the gods unborn. Above the waves rose weedy remembered spires. The\n-moon laid pale lilies of light on dead London, and Paris stood up from its damp\n-grave to be sanctified with star-dust. Then rose spires and monoliths that were\n-weedy but not remembered; terrible spires and monoliths of lands that men never\n-knew were lands...\",\n-        4 => \"\n-There was a night when winds from unknown spaces whirled us irresistibly into\n-limitless vacuum beyond all thought and entity. Perceptions of the most\n-maddeningly untransmissible sort thronged upon us; perceptions of infinity\n-which at the time convulsed us with joy, yet which are now partly lost to my\n-memory and partly incapable of presentation to others.\",\n-        _ => \"You've met with a terrible fate, haven't you?\"\n-    };\n-    rterrln!(\"{}\", \"\");\n-    rterrln!(\"{}\", quote);\n-    rterrln!(\"{}\", \"\");\n-    rterrln!(\"fatal runtime error: {}\", msg);\n-\n-    abort();\n-\n-    fn abort() -> ! {\n-        use std::intrinsics;\n-        unsafe { intrinsics::abort() }\n-    }\n-}"}, {"sha": "c589a9fb592d8804d1407b0adabd1575005d6dd3", "filename": "src/libgreen/message_queue.rs", "status": "removed", "additions": 0, "deletions": 67, "changes": 67, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fmessage_queue.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fmessage_queue.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fmessage_queue.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,67 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-pub use self::PopResult::*;\n-\n-use alloc::arc::Arc;\n-use std::sync::mpsc_queue as mpsc;\n-use std::kinds::marker;\n-\n-pub enum PopResult<T> {\n-    Inconsistent,\n-    Empty,\n-    Data(T),\n-}\n-\n-pub fn queue<T: Send>() -> (Consumer<T>, Producer<T>) {\n-    let a = Arc::new(mpsc::Queue::new());\n-    (Consumer { inner: a.clone(), noshare: marker::NoSync },\n-     Producer { inner: a, noshare: marker::NoSync })\n-}\n-\n-pub struct Producer<T> {\n-    inner: Arc<mpsc::Queue<T>>,\n-    noshare: marker::NoSync,\n-}\n-\n-pub struct Consumer<T> {\n-    inner: Arc<mpsc::Queue<T>>,\n-    noshare: marker::NoSync,\n-}\n-\n-impl<T: Send> Consumer<T> {\n-    pub fn pop(&self) -> PopResult<T> {\n-        match self.inner.pop() {\n-            mpsc::Inconsistent => Inconsistent,\n-            mpsc::Empty => Empty,\n-            mpsc::Data(t) => Data(t),\n-        }\n-    }\n-\n-    pub fn casual_pop(&self) -> Option<T> {\n-        match self.inner.pop() {\n-            mpsc::Inconsistent => None,\n-            mpsc::Empty => None,\n-            mpsc::Data(t) => Some(t),\n-        }\n-    }\n-}\n-\n-impl<T: Send> Producer<T> {\n-    pub fn push(&self, t: T) {\n-        self.inner.push(t);\n-    }\n-}\n-\n-impl<T: Send> Clone for Producer<T> {\n-    fn clone(&self) -> Producer<T> {\n-        Producer { inner: self.inner.clone(), noshare: marker::NoSync }\n-    }\n-}"}, {"sha": "e8cb65d35df6a1c1434f7bc91db12a440866f2ad", "filename": "src/libgreen/sched.rs", "status": "removed", "additions": 0, "deletions": 1523, "changes": 1523, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsched.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsched.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsched.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,1523 +0,0 @@\n-// Copyright 2013-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-pub use self::SchedMessage::*;\n-use self::EffortLevel::*;\n-\n-use std::mem;\n-use std::rt::local::Local;\n-use std::rt::mutex::NativeMutex;\n-use std::rt::rtio::{RemoteCallback, PausableIdleCallback, Callback, EventLoop};\n-use std::rt::task::BlockedTask;\n-use std::rt::task::Task;\n-use std::sync::deque;\n-use std::raw;\n-\n-use std::rand::{XorShiftRng, Rng, Rand};\n-\n-use TaskState;\n-use context::Context;\n-use coroutine::Coroutine;\n-use sleeper_list::SleeperList;\n-use stack::StackPool;\n-use task::{TypeSched, GreenTask, HomeSched, AnySched};\n-use message_queue as msgq;\n-\n-/// A scheduler is responsible for coordinating the execution of Tasks\n-/// on a single thread. The scheduler runs inside a slightly modified\n-/// Rust Task. When not running this task is stored in the scheduler\n-/// struct. The scheduler struct acts like a baton, all scheduling\n-/// actions are transfers of the baton.\n-///\n-/// FIXME: This creates too many callbacks to run_sched_once, resulting\n-/// in too much allocation and too many events.\n-pub struct Scheduler {\n-    /// ID number of the pool that this scheduler is a member of. When\n-    /// reawakening green tasks, this is used to ensure that tasks aren't\n-    /// reawoken on the wrong pool of schedulers.\n-    pub pool_id: uint,\n-    /// The pool of stacks that this scheduler has cached\n-    pub stack_pool: StackPool,\n-    /// Bookkeeping for the number of tasks which are currently running around\n-    /// inside this pool of schedulers\n-    pub task_state: TaskState,\n-    /// There are N work queues, one per scheduler.\n-    work_queue: deque::Worker<Box<GreenTask>>,\n-    /// Work queues for the other schedulers. These are created by\n-    /// cloning the core work queues.\n-    work_queues: Vec<deque::Stealer<Box<GreenTask>>>,\n-    /// The queue of incoming messages from other schedulers.\n-    /// These are enqueued by SchedHandles after which a remote callback\n-    /// is triggered to handle the message.\n-    message_queue: msgq::Consumer<SchedMessage>,\n-    /// Producer used to clone sched handles from\n-    message_producer: msgq::Producer<SchedMessage>,\n-    /// A shared list of sleeping schedulers. We'll use this to wake\n-    /// up schedulers when pushing work onto the work queue.\n-    sleeper_list: SleeperList,\n-    /// Indicates that we have previously pushed a handle onto the\n-    /// SleeperList but have not yet received the Wake message.\n-    /// Being `true` does not necessarily mean that the scheduler is\n-    /// not active since there are multiple event sources that may\n-    /// wake the scheduler. It just prevents the scheduler from pushing\n-    /// multiple handles onto the sleeper list.\n-    sleepy: bool,\n-    /// A flag to indicate we've received the shutdown message and should\n-    /// no longer try to go to sleep, but exit instead.\n-    no_sleep: bool,\n-    /// The scheduler runs on a special task. When it is not running\n-    /// it is stored here instead of the work queue.\n-    sched_task: Option<Box<GreenTask>>,\n-    /// An action performed after a context switch on behalf of the\n-    /// code running before the context switch\n-    cleanup_job: Option<CleanupJob>,\n-    /// If the scheduler shouldn't run some tasks, a friend to send\n-    /// them to.\n-    friend_handle: Option<SchedHandle>,\n-    /// Should this scheduler run any task, or only pinned tasks?\n-    run_anything: bool,\n-    /// A fast XorShift rng for scheduler use\n-    rng: XorShiftRng,\n-    /// A toggleable idle callback\n-    idle_callback: Option<Box<PausableIdleCallback + Send>>,\n-    /// A countdown that starts at a random value and is decremented\n-    /// every time a yield check is performed. When it hits 0 a task\n-    /// will yield.\n-    yield_check_count: uint,\n-    /// A flag to tell the scheduler loop it needs to do some stealing\n-    /// in order to introduce randomness as part of a yield\n-    steal_for_yield: bool,\n-\n-    // n.b. currently destructors of an object are run in top-to-bottom in order\n-    //      of field declaration. Due to its nature, the pausable idle callback\n-    //      must have some sort of handle to the event loop, so it needs to get\n-    //      destroyed before the event loop itself. For this reason, we destroy\n-    //      the event loop last to ensure that any unsafe references to it are\n-    //      destroyed before it's actually destroyed.\n-\n-    /// The event loop used to drive the scheduler and perform I/O\n-    pub event_loop: Box<EventLoop + Send>,\n-}\n-\n-/// An indication of how hard to work on a given operation, the difference\n-/// mainly being whether memory is synchronized or not\n-#[deriving(PartialEq)]\n-enum EffortLevel {\n-    DontTryTooHard,\n-    GiveItYourBest\n-}\n-\n-static MAX_YIELD_CHECKS: uint = 20000;\n-\n-fn reset_yield_check(rng: &mut XorShiftRng) -> uint {\n-    let r: uint = Rand::rand(rng);\n-    r % MAX_YIELD_CHECKS + 1\n-}\n-\n-impl Scheduler {\n-\n-    // * Initialization Functions\n-\n-    pub fn new(pool_id: uint,\n-               event_loop: Box<EventLoop + Send>,\n-               work_queue: deque::Worker<Box<GreenTask>>,\n-               work_queues: Vec<deque::Stealer<Box<GreenTask>>>,\n-               sleeper_list: SleeperList,\n-               state: TaskState)\n-        -> Scheduler {\n-\n-        Scheduler::new_special(pool_id, event_loop, work_queue, work_queues,\n-                               sleeper_list, true, None, state)\n-\n-    }\n-\n-    pub fn new_special(pool_id: uint,\n-                       event_loop: Box<EventLoop + Send>,\n-                       work_queue: deque::Worker<Box<GreenTask>>,\n-                       work_queues: Vec<deque::Stealer<Box<GreenTask>>>,\n-                       sleeper_list: SleeperList,\n-                       run_anything: bool,\n-                       friend: Option<SchedHandle>,\n-                       state: TaskState)\n-        -> Scheduler {\n-\n-        let (consumer, producer) = msgq::queue();\n-        let mut sched = Scheduler {\n-            pool_id: pool_id,\n-            sleeper_list: sleeper_list,\n-            message_queue: consumer,\n-            message_producer: producer,\n-            sleepy: false,\n-            no_sleep: false,\n-            event_loop: event_loop,\n-            work_queue: work_queue,\n-            work_queues: work_queues,\n-            stack_pool: StackPool::new(),\n-            sched_task: None,\n-            cleanup_job: None,\n-            run_anything: run_anything,\n-            friend_handle: friend,\n-            rng: new_sched_rng(),\n-            idle_callback: None,\n-            yield_check_count: 0,\n-            steal_for_yield: false,\n-            task_state: state,\n-        };\n-\n-        sched.yield_check_count = reset_yield_check(&mut sched.rng);\n-\n-        return sched;\n-    }\n-\n-    // FIXME: This may eventually need to be refactored so that\n-    // the scheduler itself doesn't have to call event_loop.run.\n-    // That will be important for embedding the runtime into external\n-    // event loops.\n-\n-    // Take a main task to run, and a scheduler to run it in. Create a\n-    // scheduler task and bootstrap into it.\n-    pub fn bootstrap(mut self: Box<Scheduler>) {\n-\n-        // Build an Idle callback.\n-        let cb = box SchedRunner as Box<Callback + Send>;\n-        self.idle_callback = Some(self.event_loop.pausable_idle_callback(cb));\n-\n-        // Create a task for the scheduler with an empty context.\n-        let sched_task = GreenTask::new_typed(Some(Coroutine::empty()),\n-                                              TypeSched);\n-\n-        // Before starting our first task, make sure the idle callback\n-        // is active. As we do not start in the sleep state this is\n-        // important.\n-        self.idle_callback.as_mut().unwrap().resume();\n-\n-        // Now, as far as all the scheduler state is concerned, we are inside\n-        // the \"scheduler\" context. The scheduler immediately hands over control\n-        // to the event loop, and this will only exit once the event loop no\n-        // longer has any references (handles or I/O objects).\n-        rtdebug!(\"starting scheduler {}\", self.sched_id());\n-        let mut sched_task = self.run(sched_task);\n-\n-        // Close the idle callback.\n-        let mut sched = sched_task.sched.take().unwrap();\n-        sched.idle_callback.take();\n-        // Make one go through the loop to run the close callback.\n-        let mut stask = sched.run(sched_task);\n-\n-        // Now that we are done with the scheduler, clean up the\n-        // scheduler task. Do so by removing it from TLS and manually\n-        // cleaning up the memory it uses. As we didn't actually call\n-        // task.run() on the scheduler task we never get through all\n-        // the cleanup code it runs.\n-        rtdebug!(\"stopping scheduler {}\", stask.sched.as_ref().unwrap().sched_id());\n-\n-        // Should not have any messages\n-        let message = stask.sched.as_mut().unwrap().message_queue.pop();\n-        rtassert!(match message { msgq::Empty => true, _ => false });\n-\n-        stask.task.take().unwrap().drop();\n-    }\n-\n-    // This does not return a scheduler, as the scheduler is placed\n-    // inside the task.\n-    pub fn run(mut self: Box<Scheduler>, stask: Box<GreenTask>)\n-               -> Box<GreenTask> {\n-\n-        // This is unsafe because we need to place the scheduler, with\n-        // the event_loop inside, inside our task. But we still need a\n-        // mutable reference to the event_loop to give it the \"run\"\n-        // command.\n-        unsafe {\n-            let event_loop: *mut Box<EventLoop + Send> = &mut self.event_loop;\n-            // Our scheduler must be in the task before the event loop\n-            // is started.\n-            stask.put_with_sched(self);\n-            (*event_loop).run();\n-        }\n-\n-        //  This is a serious code smell, but this function could be done away\n-        //  with if necessary. The ownership of `stask` was transferred into\n-        //  local storage just before the event loop ran, so it is possible to\n-        //  transmute `stask` as a uint across the running of the event loop to\n-        //  re-acquire ownership here.\n-        //\n-        // This would involve removing the Task from TLS, removing the runtime,\n-        // forgetting the runtime, and then putting the task into `stask`. For\n-        // now, because we have `GreenTask::convert`, I chose to take this\n-        // method for cleanliness. This function is *not* a fundamental reason\n-        // why this function should exist.\n-        GreenTask::convert(Local::take())\n-    }\n-\n-    // * Execution Functions - Core Loop Logic\n-\n-    // This function is run from the idle callback on the uv loop, indicating\n-    // that there are no I/O events pending. When this function returns, we will\n-    // fall back to epoll() in the uv event loop, waiting for more things to\n-    // happen. We may come right back off epoll() if the idle callback is still\n-    // active, in which case we're truly just polling to see if I/O events are\n-    // complete.\n-    //\n-    // The model for this function is to execute as much work as possible while\n-    // still fairly considering I/O tasks. Falling back to epoll() frequently is\n-    // often quite expensive, so we attempt to avoid it as much as possible. If\n-    // we have any active I/O on the event loop, then we're forced to fall back\n-    // to epoll() in order to provide fairness, but as long as we're doing work\n-    // and there's no active I/O, we can continue to do work.\n-    //\n-    // If we try really hard to do some work, but no work is available to be\n-    // done, then we fall back to epoll() to block this thread waiting for more\n-    // work (instead of busy waiting).\n-    fn run_sched_once(mut self: Box<Scheduler>, stask: Box<GreenTask>) {\n-        // Make sure that we're not lying in that the `stask` argument is indeed\n-        // the scheduler task for this scheduler.\n-        assert!(self.sched_task.is_none());\n-\n-        // Assume that we need to continue idling unless we reach the\n-        // end of this function without performing an action.\n-        self.idle_callback.as_mut().unwrap().resume();\n-\n-        // First we check for scheduler messages, these are higher\n-        // priority than regular tasks.\n-        let (mut sched, mut stask, mut did_work) =\n-            self.interpret_message_queue(stask, DontTryTooHard);\n-\n-        // After processing a message, we consider doing some more work on the\n-        // event loop. The \"keep going\" condition changes after the first\n-        // iteration because we don't want to spin here infinitely.\n-        //\n-        // Once we start doing work we can keep doing work so long as the\n-        // iteration does something. Note that we don't want to starve the\n-        // message queue here, so each iteration when we're done working we\n-        // check the message queue regardless of whether we did work or not.\n-        let mut keep_going = !did_work || !sched.event_loop.has_active_io();\n-        while keep_going {\n-            let (a, b, c) = match sched.do_work(stask) {\n-                (sched, task, false) => {\n-                    sched.interpret_message_queue(task, GiveItYourBest)\n-                }\n-                (sched, task, true) => {\n-                    let (sched, task, _) =\n-                        sched.interpret_message_queue(task, GiveItYourBest);\n-                    (sched, task, true)\n-                }\n-            };\n-            sched = a;\n-            stask = b;\n-            did_work = c;\n-\n-            // We only keep going if we managed to do something productive and\n-            // also don't have any active I/O. If we didn't do anything, we\n-            // should consider going to sleep, and if we have active I/O we need\n-            // to poll for completion.\n-            keep_going = did_work && !sched.event_loop.has_active_io();\n-        }\n-\n-        // If we ever did some work, then we shouldn't put our scheduler\n-        // entirely to sleep just yet. Leave the idle callback active and fall\n-        // back to epoll() to see what's going on.\n-        if did_work {\n-            return stask.put_with_sched(sched);\n-        }\n-\n-        // If we got here then there was no work to do.\n-        // Generate a SchedHandle and push it to the sleeper list so\n-        // somebody can wake us up later.\n-        if !sched.sleepy && !sched.no_sleep {\n-            rtdebug!(\"scheduler has no work to do, going to sleep\");\n-            sched.sleepy = true;\n-            let handle = sched.make_handle();\n-            sched.sleeper_list.push(handle);\n-            // Since we are sleeping, deactivate the idle callback.\n-            sched.idle_callback.as_mut().unwrap().pause();\n-        } else {\n-            rtdebug!(\"not sleeping, already doing so or no_sleep set\");\n-            // We may not be sleeping, but we still need to deactivate\n-            // the idle callback.\n-            sched.idle_callback.as_mut().unwrap().pause();\n-        }\n-\n-        // Finished a cycle without using the Scheduler. Place it back\n-        // in TLS.\n-        stask.put_with_sched(sched);\n-    }\n-\n-    // This function returns None if the scheduler is \"used\", or it\n-    // returns the still-available scheduler. At this point all\n-    // message-handling will count as a turn of work, and as a result\n-    // return None.\n-    fn interpret_message_queue(mut self: Box<Scheduler>,\n-                               stask: Box<GreenTask>,\n-                               effort: EffortLevel)\n-                               -> (Box<Scheduler>, Box<GreenTask>, bool) {\n-        let msg = if effort == DontTryTooHard {\n-            self.message_queue.casual_pop()\n-        } else {\n-            // When popping our message queue, we could see an \"inconsistent\"\n-            // state which means that we *should* be able to pop data, but we\n-            // are unable to at this time. Our options are:\n-            //\n-            //  1. Spin waiting for data\n-            //  2. Ignore this and pretend we didn't find a message\n-            //\n-            // If we choose route 1, then if the pusher in question is currently\n-            // pre-empted, we're going to take up our entire time slice just\n-            // spinning on this queue. If we choose route 2, then the pusher in\n-            // question is still guaranteed to make a send() on its async\n-            // handle, so we will guaranteed wake up and see its message at some\n-            // point.\n-            //\n-            // I have chosen to take route #2.\n-            match self.message_queue.pop() {\n-                msgq::Data(t) => Some(t),\n-                msgq::Empty | msgq::Inconsistent => None\n-            }\n-        };\n-\n-        match msg {\n-            Some(PinnedTask(task)) => {\n-                let mut task = task;\n-                task.give_home(HomeSched(self.make_handle()));\n-                let (sched, task) = self.resume_task_immediately(stask, task);\n-                (sched, task, true)\n-            }\n-            Some(TaskFromFriend(task)) => {\n-                rtdebug!(\"got a task from a friend. lovely!\");\n-                let (sched, task) =\n-                    self.process_task(stask, task,\n-                                      Scheduler::resume_task_immediately_cl);\n-                (sched, task, true)\n-            }\n-            Some(RunOnce(task)) => {\n-                // bypass the process_task logic to force running this task once\n-                // on this home scheduler. This is often used for I/O (homing).\n-                let (sched, task) = self.resume_task_immediately(stask, task);\n-                (sched, task, true)\n-            }\n-            Some(Wake) => {\n-                self.sleepy = false;\n-                (self, stask, true)\n-            }\n-            Some(Shutdown) => {\n-                rtdebug!(\"shutting down\");\n-                if self.sleepy {\n-                    // There may be an outstanding handle on the\n-                    // sleeper list.  Pop them all to make sure that's\n-                    // not the case.\n-                    loop {\n-                        match self.sleeper_list.pop() {\n-                            Some(handle) => {\n-                                let mut handle = handle;\n-                                handle.send(Wake);\n-                            }\n-                            None => break\n-                        }\n-                    }\n-                }\n-                // No more sleeping. After there are no outstanding\n-                // event loop references we will shut down.\n-                self.no_sleep = true;\n-                self.sleepy = false;\n-                (self, stask, true)\n-            }\n-            Some(NewNeighbor(neighbor)) => {\n-                self.work_queues.push(neighbor);\n-                (self, stask, false)\n-            }\n-            None => (self, stask, false)\n-        }\n-    }\n-\n-    fn do_work(mut self: Box<Scheduler>, stask: Box<GreenTask>)\n-               -> (Box<Scheduler>, Box<GreenTask>, bool) {\n-        rtdebug!(\"scheduler calling do work\");\n-        match self.find_work() {\n-            Some(task) => {\n-                rtdebug!(\"found some work! running the task\");\n-                let (sched, task) =\n-                    self.process_task(stask, task,\n-                                      Scheduler::resume_task_immediately_cl);\n-                (sched, task, true)\n-            }\n-            None => {\n-                rtdebug!(\"no work was found, returning the scheduler struct\");\n-                (self, stask, false)\n-            }\n-        }\n-    }\n-\n-    // Workstealing: In this iteration of the runtime each scheduler\n-    // thread has a distinct work queue. When no work is available\n-    // locally, make a few attempts to steal work from the queues of\n-    // other scheduler threads. If a few steals fail we end up in the\n-    // old \"no work\" path which is fine.\n-\n-    // First step in the process is to find a task. This function does\n-    // that by first checking the local queue, and if there is no work\n-    // there, trying to steal from the remote work queues.\n-    fn find_work(&mut self) -> Option<Box<GreenTask>> {\n-        rtdebug!(\"scheduler looking for work\");\n-        if !self.steal_for_yield {\n-            match self.work_queue.pop() {\n-                Some(task) => {\n-                    rtdebug!(\"found a task locally\");\n-                    return Some(task)\n-                }\n-                None => {\n-                    rtdebug!(\"scheduler trying to steal\");\n-                    return self.try_steals();\n-                }\n-            }\n-        } else {\n-            // During execution of the last task, it performed a 'yield',\n-            // so we're doing some work stealing in order to introduce some\n-            // scheduling randomness. Otherwise we would just end up popping\n-            // that same task again. This is pretty lame and is to work around\n-            // the problem that work stealing is not designed for 'non-strict'\n-            // (non-fork-join) task parallelism.\n-            self.steal_for_yield = false;\n-            match self.try_steals() {\n-                Some(task) => {\n-                    rtdebug!(\"stole a task after yielding\");\n-                    return Some(task);\n-                }\n-                None => {\n-                    rtdebug!(\"did not steal a task after yielding\");\n-                    // Back to business\n-                    return self.find_work();\n-                }\n-            }\n-        }\n-    }\n-\n-    // Try stealing from all queues the scheduler knows about. This\n-    // naive implementation can steal from our own queue or from other\n-    // special schedulers.\n-    fn try_steals(&mut self) -> Option<Box<GreenTask>> {\n-        let work_queues = &mut self.work_queues;\n-        let len = work_queues.len();\n-        let start_index = self.rng.gen_range(0, len);\n-        for index in range(0, len).map(|i| (i + start_index) % len) {\n-            match work_queues[index].steal() {\n-                deque::Data(task) => {\n-                    rtdebug!(\"found task by stealing\");\n-                    return Some(task)\n-                }\n-                _ => ()\n-            }\n-        };\n-        rtdebug!(\"giving up on stealing\");\n-        return None;\n-    }\n-\n-    // * Task Routing Functions - Make sure tasks send up in the right\n-    // place.\n-\n-    fn process_task(mut self: Box<Scheduler>,\n-                    cur: Box<GreenTask>,\n-                    mut next: Box<GreenTask>,\n-                    schedule_fn: SchedulingFn)\n-                    -> (Box<Scheduler>, Box<GreenTask>) {\n-        rtdebug!(\"processing a task\");\n-\n-        match next.take_unwrap_home() {\n-            HomeSched(home_handle) => {\n-                if home_handle.sched_id != self.sched_id() {\n-                    rtdebug!(\"sending task home\");\n-                    next.give_home(HomeSched(home_handle));\n-                    Scheduler::send_task_home(next);\n-                    (self, cur)\n-                } else {\n-                    rtdebug!(\"running task here\");\n-                    next.give_home(HomeSched(home_handle));\n-                    schedule_fn(self, cur, next)\n-                }\n-            }\n-            AnySched if self.run_anything => {\n-                rtdebug!(\"running anysched task here\");\n-                next.give_home(AnySched);\n-                schedule_fn(self, cur, next)\n-            }\n-            AnySched => {\n-                rtdebug!(\"sending task to friend\");\n-                next.give_home(AnySched);\n-                self.send_to_friend(next);\n-                (self, cur)\n-            }\n-        }\n-    }\n-\n-    fn send_task_home(task: Box<GreenTask>) {\n-        let mut task = task;\n-        match task.take_unwrap_home() {\n-            HomeSched(mut home_handle) => home_handle.send(PinnedTask(task)),\n-            AnySched => rtabort!(\"error: cannot send anysched task home\"),\n-        }\n-    }\n-\n-    /// Take a non-homed task we aren't allowed to run here and send\n-    /// it to the designated friend scheduler to execute.\n-    fn send_to_friend(&mut self, task: Box<GreenTask>) {\n-        rtdebug!(\"sending a task to friend\");\n-        match self.friend_handle {\n-            Some(ref mut handle) => {\n-                handle.send(TaskFromFriend(task));\n-            }\n-            None => {\n-                rtabort!(\"tried to send task to a friend but scheduler has no friends\");\n-            }\n-        }\n-    }\n-\n-    /// Schedule a task to be executed later.\n-    ///\n-    /// Pushes the task onto the work stealing queue and tells the\n-    /// event loop to run it later. Always use this instead of pushing\n-    /// to the work queue directly.\n-    pub fn enqueue_task(&mut self, task: Box<GreenTask>) {\n-\n-        // We push the task onto our local queue clone.\n-        assert!(!task.is_sched());\n-        self.work_queue.push(task);\n-        match self.idle_callback {\n-            Some(ref mut idle) => idle.resume(),\n-            None => {} // allow enqueuing before the scheduler starts\n-        }\n-\n-        // We've made work available. Notify a\n-        // sleeping scheduler.\n-\n-        match self.sleeper_list.casual_pop() {\n-            Some(handle) => {\n-                let mut handle = handle;\n-                handle.send(Wake)\n-            }\n-            None => { (/* pass */) }\n-        };\n-    }\n-\n-    // * Core Context Switching Functions\n-\n-    // The primary function for changing contexts. In the current\n-    // design the scheduler is just a slightly modified GreenTask, so\n-    // all context swaps are from GreenTask to GreenTask. The only difference\n-    // between the various cases is where the inputs come from, and\n-    // what is done with the resulting task. That is specified by the\n-    // cleanup function f, which takes the scheduler and the\n-    // old task as inputs.\n-\n-    pub fn change_task_context(mut self: Box<Scheduler>,\n-                               mut current_task: Box<GreenTask>,\n-                               mut next_task: Box<GreenTask>,\n-                               f: |&mut Scheduler, Box<GreenTask>|)\n-                               -> Box<GreenTask> {\n-        let f_opaque = ClosureConverter::from_fn(f);\n-\n-        let current_task_dupe = &mut *current_task as *mut GreenTask;\n-\n-        // The current task is placed inside an enum with the cleanup\n-        // function. This enum is then placed inside the scheduler.\n-        self.cleanup_job = Some(CleanupJob::new(current_task, f_opaque));\n-\n-        // The scheduler is then placed inside the next task.\n-        next_task.sched = Some(self);\n-\n-        // However we still need an internal mutable pointer to the\n-        // original task. The strategy here was \"arrange memory, then\n-        // get pointers\", so we crawl back up the chain using\n-        // transmute to eliminate borrowck errors.\n-        unsafe {\n-\n-            let sched: &mut Scheduler =\n-                mem::transmute(&**next_task.sched.as_mut().unwrap());\n-\n-            let current_task: &mut GreenTask = match sched.cleanup_job {\n-                Some(CleanupJob { ref mut task, .. }) => &mut **task,\n-                None => rtabort!(\"no cleanup job\")\n-            };\n-\n-            let (current_task_context, next_task_context) =\n-                Scheduler::get_contexts(current_task, &mut *next_task);\n-\n-            // Done with everything - put the next task in TLS. This\n-            // works because due to transmute the borrow checker\n-            // believes that we have no internal pointers to\n-            // next_task.\n-            mem::forget(next_task);\n-\n-            // The raw context swap operation. The next action taken\n-            // will be running the cleanup job from the context of the\n-            // next task.\n-            Context::swap(current_task_context, next_task_context);\n-        }\n-\n-        // When the context swaps back to this task we immediately\n-        // run the cleanup job, as expected by the previously called\n-        // swap_contexts function.\n-        let mut current_task: Box<GreenTask> = unsafe {\n-            mem::transmute(current_task_dupe)\n-        };\n-        current_task.sched.as_mut().unwrap().run_cleanup_job();\n-\n-        // See the comments in switch_running_tasks_and_then for why a lock\n-        // is acquired here. This is the resumption points and the \"bounce\"\n-        // that it is referring to.\n-        unsafe {\n-            let _guard = current_task.nasty_deschedule_lock.lock();\n-        }\n-        return current_task;\n-    }\n-\n-    // Returns a mutable reference to both contexts involved in this\n-    // swap. This is unsafe - we are getting mutable internal\n-    // references to keep even when we don't own the tasks. It looks\n-    // kinda safe because we are doing transmutes before passing in\n-    // the arguments.\n-    pub fn get_contexts<'a>(current_task: &mut GreenTask,\n-                            next_task: &mut GreenTask)\n-        -> (&'a mut Context, &'a mut Context)\n-    {\n-        let current_task_context =\n-            &mut current_task.coroutine.as_mut().unwrap().saved_context;\n-        let next_task_context =\n-                &mut next_task.coroutine.as_mut().unwrap().saved_context;\n-        unsafe {\n-            (mem::transmute(current_task_context),\n-             mem::transmute(next_task_context))\n-        }\n-    }\n-\n-    // * Context Swapping Helpers - Here be ugliness!\n-\n-    pub fn resume_task_immediately(self: Box<Scheduler>,\n-                                   cur: Box<GreenTask>,\n-                                   next: Box<GreenTask>)\n-                                   -> (Box<Scheduler>, Box<GreenTask>) {\n-        assert!(cur.is_sched());\n-        let mut cur = self.change_task_context(cur, next, |sched, stask| {\n-            assert!(sched.sched_task.is_none());\n-            sched.sched_task = Some(stask);\n-        });\n-        (cur.sched.take().unwrap(), cur)\n-    }\n-\n-    fn resume_task_immediately_cl(sched: Box<Scheduler>,\n-                                  cur: Box<GreenTask>,\n-                                  next: Box<GreenTask>)\n-                                  -> (Box<Scheduler>, Box<GreenTask>) {\n-        sched.resume_task_immediately(cur, next)\n-    }\n-\n-    /// Block a running task, context switch to the scheduler, then pass the\n-    /// blocked task to a closure.\n-    ///\n-    /// # Safety note\n-    ///\n-    /// The closure here is a *stack* closure that lives in the\n-    /// running task.  It gets transmuted to the scheduler's lifetime\n-    /// and called while the task is blocked.\n-    ///\n-    /// This passes a Scheduler pointer to the fn after the context switch\n-    /// in order to prevent that fn from performing further scheduling operations.\n-    /// Doing further scheduling could easily result in infinite recursion.\n-    ///\n-    /// Note that if the closure provided relinquishes ownership of the\n-    /// BlockedTask, then it is possible for the task to resume execution before\n-    /// the closure has finished executing. This would naturally introduce a\n-    /// race if the closure and task shared portions of the environment.\n-    ///\n-    /// This situation is currently prevented, or in other words it is\n-    /// guaranteed that this function will not return before the given closure\n-    /// has returned.\n-    pub fn deschedule_running_task_and_then(mut self: Box<Scheduler>,\n-                                            cur: Box<GreenTask>,\n-                                            f: |&mut Scheduler, BlockedTask|) {\n-        // Trickier - we need to get the scheduler task out of self\n-        // and use it as the destination.\n-        let stask = self.sched_task.take().unwrap();\n-        // Otherwise this is the same as below.\n-        self.switch_running_tasks_and_then(cur, stask, f)\n-    }\n-\n-    pub fn switch_running_tasks_and_then(self: Box<Scheduler>,\n-                                         cur: Box<GreenTask>,\n-                                         next: Box<GreenTask>,\n-                                         f: |&mut Scheduler, BlockedTask|) {\n-        // And here comes one of the sad moments in which a lock is used in a\n-        // core portion of the rust runtime. As always, this is highly\n-        // undesirable, so there's a good reason behind it.\n-        //\n-        // There is an excellent outline of the problem in issue #8132, and it's\n-        // summarized in that `f` is executed on a sched task, but its\n-        // environment is on the previous task. If `f` relinquishes ownership of\n-        // the BlockedTask, then it may introduce a race where `f` is using the\n-        // environment as well as the code after the 'deschedule' block.\n-        //\n-        // The solution we have chosen to adopt for now is to acquire a\n-        // task-local lock around this block. The resumption of the task in\n-        // context switching will bounce on the lock, thereby waiting for this\n-        // block to finish, eliminating the race mentioned above.\n-        // panic!(\"should never return!\");\n-        //\n-        // To actually maintain a handle to the lock, we use an unsafe pointer\n-        // to it, but we're guaranteed that the task won't exit until we've\n-        // unlocked the lock so there's no worry of this memory going away.\n-        let cur = self.change_task_context(cur, next, |sched, mut task| {\n-            let lock: *mut NativeMutex = &mut task.nasty_deschedule_lock;\n-            unsafe {\n-                let _guard = (*lock).lock();\n-                f(sched, BlockedTask::block(task.swap()));\n-            }\n-        });\n-        cur.put();\n-    }\n-\n-    fn switch_task(sched: Box<Scheduler>,\n-                   cur: Box<GreenTask>,\n-                   next: Box<GreenTask>)\n-                   -> (Box<Scheduler>, Box<GreenTask>) {\n-        let mut cur = sched.change_task_context(cur, next, |sched, last_task| {\n-            if last_task.is_sched() {\n-                assert!(sched.sched_task.is_none());\n-                sched.sched_task = Some(last_task);\n-            } else {\n-                sched.enqueue_task(last_task);\n-            }\n-        });\n-        (cur.sched.take().unwrap(), cur)\n-    }\n-\n-    // * Task Context Helpers\n-\n-    /// Called by a running task to end execution, after which it will\n-    /// be recycled by the scheduler for reuse in a new task.\n-    pub fn terminate_current_task(mut self: Box<Scheduler>,\n-                                  cur: Box<GreenTask>)\n-                                  -> ! {\n-        // Similar to deschedule running task and then, but cannot go through\n-        // the task-blocking path. The task is already dying.\n-        let stask = self.sched_task.take().unwrap();\n-        let _cur = self.change_task_context(cur, stask, |sched, mut dead_task| {\n-            let coroutine = dead_task.coroutine.take().unwrap();\n-            coroutine.recycle(&mut sched.stack_pool);\n-            sched.task_state.decrement();\n-        });\n-        panic!(\"should never return!\");\n-    }\n-\n-    pub fn run_task(self: Box<Scheduler>,\n-                    cur: Box<GreenTask>,\n-                    next: Box<GreenTask>) {\n-        let (sched, task) =\n-            self.process_task(cur, next, Scheduler::switch_task);\n-        task.put_with_sched(sched);\n-    }\n-\n-    pub fn run_task_later(mut cur: Box<GreenTask>, next: Box<GreenTask>) {\n-        let mut sched = cur.sched.take().unwrap();\n-        sched.enqueue_task(next);\n-        cur.put_with_sched(sched);\n-    }\n-\n-    /// Yield control to the scheduler, executing another task. This is guaranteed\n-    /// to introduce some amount of randomness to the scheduler. Currently the\n-    /// randomness is a result of performing a round of work stealing (which\n-    /// may end up stealing from the current scheduler).\n-    pub fn yield_now(mut self: Box<Scheduler>, cur: Box<GreenTask>) {\n-        // Async handles trigger the scheduler by calling yield_now on the local\n-        // task, which eventually gets us to here. See comments in SchedRunner\n-        // for more info on this.\n-        if cur.is_sched() {\n-            assert!(self.sched_task.is_none());\n-            self.run_sched_once(cur);\n-        } else {\n-            self.yield_check_count = reset_yield_check(&mut self.rng);\n-            // Tell the scheduler to start stealing on the next iteration\n-            self.steal_for_yield = true;\n-            let stask = self.sched_task.take().unwrap();\n-            let cur = self.change_task_context(cur, stask, |sched, task| {\n-                sched.enqueue_task(task);\n-            });\n-            cur.put()\n-        }\n-    }\n-\n-    pub fn maybe_yield(mut self: Box<Scheduler>, cur: Box<GreenTask>) {\n-        // It's possible for sched tasks to possibly call this function, and it\n-        // just means that they're likely sending on channels (which\n-        // occasionally call this function). Sched tasks follow different paths\n-        // when executing yield_now(), which may possibly trip the assertion\n-        // below. For this reason, we just have sched tasks bail out soon.\n-        //\n-        // Sched tasks have no need to yield anyway because as soon as they\n-        // return they'll yield to other threads by falling back to the event\n-        // loop. Additionally, we completely control sched tasks, so we can make\n-        // sure that they never execute more than enough code.\n-        if cur.is_sched() {\n-            return cur.put_with_sched(self)\n-        }\n-\n-        // The number of times to do the yield check before yielding, chosen\n-        // arbitrarily.\n-        rtassert!(self.yield_check_count > 0);\n-        self.yield_check_count -= 1;\n-        if self.yield_check_count == 0 {\n-            self.yield_now(cur);\n-        } else {\n-            cur.put_with_sched(self);\n-        }\n-    }\n-\n-\n-    // * Utility Functions\n-\n-    pub fn sched_id(&self) -> uint { self as *const Scheduler as uint }\n-\n-    pub fn run_cleanup_job(&mut self) {\n-        let cleanup_job = self.cleanup_job.take().unwrap();\n-        cleanup_job.run(self)\n-    }\n-\n-    pub fn make_handle(&mut self) -> SchedHandle {\n-        let remote = self.event_loop.remote_callback(box SchedRunner);\n-\n-        return SchedHandle {\n-            remote: remote,\n-            queue: self.message_producer.clone(),\n-            sched_id: self.sched_id()\n-        }\n-    }\n-}\n-\n-// Supporting types\n-\n-type SchedulingFn = fn(Box<Scheduler>, Box<GreenTask>, Box<GreenTask>)\n-                       -> (Box<Scheduler>, Box<GreenTask>);\n-\n-pub enum SchedMessage {\n-    Wake,\n-    Shutdown,\n-    NewNeighbor(deque::Stealer<Box<GreenTask>>),\n-    PinnedTask(Box<GreenTask>),\n-    TaskFromFriend(Box<GreenTask>),\n-    RunOnce(Box<GreenTask>),\n-}\n-\n-pub struct SchedHandle {\n-    remote: Box<RemoteCallback + Send>,\n-    queue: msgq::Producer<SchedMessage>,\n-    pub sched_id: uint\n-}\n-\n-impl SchedHandle {\n-    pub fn send(&mut self, msg: SchedMessage) {\n-        self.queue.push(msg);\n-        self.remote.fire();\n-    }\n-}\n-\n-struct SchedRunner;\n-\n-impl Callback for SchedRunner {\n-    fn call(&mut self) {\n-        // In theory, this function needs to invoke the `run_sched_once`\n-        // function on the scheduler. Sadly, we have no context here, except for\n-        // knowledge of the local `Task`. In order to avoid a call to\n-        // `GreenTask::convert`, we just call `yield_now` and the scheduler will\n-        // detect when a sched task performs a yield vs a green task performing\n-        // a yield (and act accordingly).\n-        //\n-        // This function could be converted to `GreenTask::convert` if\n-        // absolutely necessary, but for cleanliness it is much better to not\n-        // use the conversion function.\n-        let task: Box<Task> = Local::take();\n-        task.yield_now();\n-    }\n-}\n-\n-struct CleanupJob {\n-    task: Box<GreenTask>,\n-    f: UnsafeTaskReceiver\n-}\n-\n-impl CleanupJob {\n-    pub fn new(task: Box<GreenTask>, f: UnsafeTaskReceiver) -> CleanupJob {\n-        CleanupJob {\n-            task: task,\n-            f: f\n-        }\n-    }\n-\n-    pub fn run(self, sched: &mut Scheduler) {\n-        let CleanupJob { task, f } = self;\n-        f.to_fn()(sched, task)\n-    }\n-}\n-\n-// FIXME: Some hacks to put a || closure in Scheduler without borrowck\n-// complaining\n-type UnsafeTaskReceiver = raw::Closure;\n-trait ClosureConverter {\n-    fn from_fn(|&mut Scheduler, Box<GreenTask>|) -> Self;\n-    fn to_fn(self) -> |&mut Scheduler, Box<GreenTask>|:'static ;\n-}\n-impl ClosureConverter for UnsafeTaskReceiver {\n-    fn from_fn(f: |&mut Scheduler, Box<GreenTask>|) -> UnsafeTaskReceiver {\n-        unsafe { mem::transmute(f) }\n-    }\n-    fn to_fn(self) -> |&mut Scheduler, Box<GreenTask>|:'static {\n-        unsafe { mem::transmute(self) }\n-    }\n-}\n-\n-// On unix, we read randomness straight from /dev/urandom, but the\n-// default constructor of an XorShiftRng does this via io::fs, which\n-// relies on the scheduler existing, so we have to manually load\n-// randomness. Windows has its own C API for this, so we don't need to\n-// worry there.\n-#[cfg(windows)]\n-fn new_sched_rng() -> XorShiftRng {\n-    use std::rand::OsRng;\n-    match OsRng::new() {\n-        Ok(mut r) => r.gen(),\n-        Err(e) => {\n-            rtabort!(\"sched: failed to create seeded RNG: {}\", e)\n-        }\n-    }\n-}\n-#[cfg(unix)]\n-fn new_sched_rng() -> XorShiftRng {\n-    use libc;\n-    use std::mem;\n-    use std::rand::SeedableRng;\n-\n-    let fd = \"/dev/urandom\".with_c_str(|name| {\n-        unsafe { libc::open(name, libc::O_RDONLY, 0) }\n-    });\n-    if fd == -1 {\n-        rtabort!(\"could not open /dev/urandom for reading.\")\n-    }\n-\n-    let mut seeds = [0u32, .. 4];\n-    let size = mem::size_of_val(&seeds);\n-    loop {\n-        let nbytes = unsafe {\n-            libc::read(fd,\n-                       seeds.as_mut_ptr() as *mut libc::c_void,\n-                       size as libc::size_t)\n-        };\n-        rtassert!(nbytes as uint == size);\n-\n-        if !seeds.iter().all(|x| *x == 0) {\n-            break;\n-        }\n-    }\n-\n-    unsafe {libc::close(fd);}\n-\n-    SeedableRng::from_seed(seeds)\n-}\n-\n-#[cfg(test)]\n-mod test {\n-    use std::rt::task::TaskOpts;\n-    use std::rt::task::Task;\n-    use std::rt::local::Local;\n-\n-    use {TaskState, PoolConfig, SchedPool};\n-    use basic;\n-    use sched::{TaskFromFriend, PinnedTask};\n-    use task::{GreenTask, HomeSched, AnySched};\n-\n-    fn pool() -> SchedPool {\n-        SchedPool::new(PoolConfig {\n-            threads: 1,\n-            event_loop_factory: basic::event_loop,\n-        })\n-    }\n-\n-    fn run(f: proc():Send) {\n-        let mut pool = pool();\n-        pool.spawn(TaskOpts::new(), f);\n-        pool.shutdown();\n-    }\n-\n-    fn sched_id() -> uint {\n-        let mut task = Local::borrow(None::<Task>);\n-        match task.maybe_take_runtime::<GreenTask>() {\n-            Some(green) => {\n-                let ret = green.sched.as_ref().unwrap().sched_id();\n-                task.put_runtime(green);\n-                return ret;\n-            }\n-            None => panic!()\n-        }\n-    }\n-\n-    #[test]\n-    fn trivial_run_in_newsched_task_test() {\n-        let mut task_ran = false;\n-        let task_ran_ptr: *mut bool = &mut task_ran;\n-        run(proc() {\n-            unsafe { *task_ran_ptr = true };\n-            rtdebug!(\"executed from the new scheduler\")\n-        });\n-        assert!(task_ran);\n-    }\n-\n-    #[test]\n-    fn multiple_task_test() {\n-        let total = 10;\n-        let mut task_run_count = 0;\n-        let task_run_count_ptr: *mut uint = &mut task_run_count;\n-        // with only one thread this is safe to run in without worries of\n-        // contention.\n-        run(proc() {\n-            for _ in range(0u, total) {\n-                spawn(proc() {\n-                    unsafe { *task_run_count_ptr = *task_run_count_ptr + 1};\n-                });\n-            }\n-        });\n-        assert!(task_run_count == total);\n-    }\n-\n-    #[test]\n-    fn multiple_task_nested_test() {\n-        let mut task_run_count = 0;\n-        let task_run_count_ptr: *mut uint = &mut task_run_count;\n-        run(proc() {\n-            spawn(proc() {\n-                unsafe { *task_run_count_ptr = *task_run_count_ptr + 1 };\n-                spawn(proc() {\n-                    unsafe { *task_run_count_ptr = *task_run_count_ptr + 1 };\n-                    spawn(proc() {\n-                        unsafe { *task_run_count_ptr = *task_run_count_ptr + 1 };\n-                    })\n-                })\n-            })\n-        });\n-        assert!(task_run_count == 3);\n-    }\n-\n-    // A very simple test that confirms that a task executing on the\n-    // home scheduler notices that it is home.\n-    #[test]\n-    fn test_home_sched() {\n-        let mut pool = pool();\n-\n-        let (dtx, drx) = channel();\n-        {\n-            let (tx, rx) = channel();\n-            let mut handle1 = pool.spawn_sched();\n-            let mut handle2 = pool.spawn_sched();\n-\n-            handle1.send(TaskFromFriend(pool.task(TaskOpts::new(), proc() {\n-                tx.send(sched_id());\n-            })));\n-            let sched1_id = rx.recv();\n-\n-            let mut task = pool.task(TaskOpts::new(), proc() {\n-                assert_eq!(sched_id(), sched1_id);\n-                dtx.send(());\n-            });\n-            task.give_home(HomeSched(handle1));\n-            handle2.send(TaskFromFriend(task));\n-        }\n-        drx.recv();\n-\n-        pool.shutdown();\n-    }\n-\n-    // An advanced test that checks all four possible states that a\n-    // (task,sched) can be in regarding homes.\n-\n-    #[test]\n-    fn test_schedule_home_states() {\n-        use sleeper_list::SleeperList;\n-        use super::{Shutdown, Scheduler, SchedHandle};\n-        use std::rt::thread::Thread;\n-        use std::sync::deque::BufferPool;\n-\n-        Thread::start(proc() {\n-            let sleepers = SleeperList::new();\n-            let pool = BufferPool::new();\n-            let (normal_worker, normal_stealer) = pool.deque();\n-            let (special_worker, special_stealer) = pool.deque();\n-            let queues = vec![normal_stealer, special_stealer];\n-            let (_p, state) = TaskState::new();\n-\n-            // Our normal scheduler\n-            let mut normal_sched = box Scheduler::new(\n-                1,\n-                basic::event_loop(),\n-                normal_worker,\n-                queues.clone(),\n-                sleepers.clone(),\n-                state.clone());\n-\n-            let normal_handle = normal_sched.make_handle();\n-            let friend_handle = normal_sched.make_handle();\n-\n-            // Our special scheduler\n-            let mut special_sched = box Scheduler::new_special(\n-                1,\n-                basic::event_loop(),\n-                special_worker,\n-                queues.clone(),\n-                sleepers.clone(),\n-                false,\n-                Some(friend_handle),\n-                state);\n-\n-            let special_handle = special_sched.make_handle();\n-\n-            let t1_handle = special_sched.make_handle();\n-            let t4_handle = special_sched.make_handle();\n-\n-            // Four test tasks:\n-            //   1) task is home on special\n-            //   2) task not homed, sched doesn't care\n-            //   3) task not homed, sched requeues\n-            //   4) task not home, send home\n-\n-            // Grab both the scheduler and the task from TLS and check if the\n-            // task is executing on an appropriate scheduler.\n-            fn on_appropriate_sched() -> bool {\n-                use task::{TypeGreen, TypeSched, HomeSched};\n-                let task = GreenTask::convert(Local::take());\n-                let sched_id = task.sched.as_ref().unwrap().sched_id();\n-                let run_any = task.sched.as_ref().unwrap().run_anything;\n-                let ret = match task.task_type {\n-                    TypeGreen(Some(AnySched)) => {\n-                        run_any\n-                    }\n-                    TypeGreen(Some(HomeSched(SchedHandle {\n-                        sched_id: ref id,\n-                        ..\n-                    }))) => {\n-                        *id == sched_id\n-                    }\n-                    TypeGreen(None) => { panic!(\"task without home\"); }\n-                    TypeSched => { panic!(\"expected green task\"); }\n-                };\n-                task.put();\n-                ret\n-            }\n-\n-            let task1 = GreenTask::new_homed(&mut special_sched.stack_pool,\n-                                             None, HomeSched(t1_handle), proc() {\n-                rtassert!(on_appropriate_sched());\n-            });\n-\n-            let task2 = GreenTask::new(&mut normal_sched.stack_pool, None, proc() {\n-                rtassert!(on_appropriate_sched());\n-            });\n-\n-            let task3 = GreenTask::new(&mut normal_sched.stack_pool, None, proc() {\n-                rtassert!(on_appropriate_sched());\n-            });\n-\n-            let task4 = GreenTask::new_homed(&mut special_sched.stack_pool,\n-                                             None, HomeSched(t4_handle), proc() {\n-                rtassert!(on_appropriate_sched());\n-            });\n-\n-            // Signal from the special task that we are done.\n-            let (tx, rx) = channel::<()>();\n-\n-            fn run(next: Box<GreenTask>) {\n-                let mut task = GreenTask::convert(Local::take());\n-                let sched = task.sched.take().unwrap();\n-                sched.run_task(task, next)\n-            }\n-\n-            let normal_task = GreenTask::new(&mut normal_sched.stack_pool, None, proc() {\n-                run(task2);\n-                run(task4);\n-                rx.recv();\n-                let mut nh = normal_handle;\n-                nh.send(Shutdown);\n-                let mut sh = special_handle;\n-                sh.send(Shutdown);\n-            });\n-            normal_sched.enqueue_task(normal_task);\n-\n-            let special_task = GreenTask::new(&mut special_sched.stack_pool, None, proc() {\n-                run(task1);\n-                run(task3);\n-                tx.send(());\n-            });\n-            special_sched.enqueue_task(special_task);\n-\n-            let normal_sched = normal_sched;\n-            let normal_thread = Thread::start(proc() { normal_sched.bootstrap() });\n-\n-            let special_sched = special_sched;\n-            let special_thread = Thread::start(proc() { special_sched.bootstrap() });\n-\n-            normal_thread.join();\n-            special_thread.join();\n-        }).join();\n-    }\n-\n-    //#[test]\n-    //fn test_stress_schedule_task_states() {\n-    //    if util::limit_thread_creation_due_to_osx_and_valgrind() { return; }\n-    //    let n = stress_factor() * 120;\n-    //    for _ in range(0, n as int) {\n-    //        test_schedule_home_states();\n-    //    }\n-    //}\n-\n-    #[test]\n-    fn wakeup_across_scheds() {\n-        let (tx1, rx1) = channel();\n-        let (tx2, rx2) = channel();\n-\n-        let mut pool1 = pool();\n-        let mut pool2 = pool();\n-\n-        pool1.spawn(TaskOpts::new(), proc() {\n-            let id = sched_id();\n-            tx1.send(());\n-            rx2.recv();\n-            assert_eq!(id, sched_id());\n-        });\n-\n-        pool2.spawn(TaskOpts::new(), proc() {\n-            let id = sched_id();\n-            rx1.recv();\n-            assert_eq!(id, sched_id());\n-            tx2.send(());\n-        });\n-\n-        pool1.shutdown();\n-        pool2.shutdown();\n-    }\n-\n-    // A regression test that the final message is always handled.\n-    // Used to deadlock because Shutdown was never recvd.\n-    #[test]\n-    fn no_missed_messages() {\n-        let mut pool = pool();\n-\n-        let task = pool.task(TaskOpts::new(), proc()());\n-        pool.spawn_sched().send(TaskFromFriend(task));\n-\n-        pool.shutdown();\n-    }\n-\n-    #[test]\n-    fn multithreading() {\n-        run(proc() {\n-            let mut rxs = vec![];\n-            for _ in range(0u, 10) {\n-                let (tx, rx) = channel();\n-                spawn(proc() {\n-                    tx.send(());\n-                });\n-                rxs.push(rx);\n-            }\n-\n-            loop {\n-                match rxs.pop() {\n-                    Some(rx) => rx.recv(),\n-                    None => break,\n-                }\n-            }\n-        });\n-    }\n-\n-     #[test]\n-    fn thread_ring() {\n-        run(proc() {\n-            let (end_tx, end_rx) = channel();\n-\n-            let n_tasks = 10;\n-            let token = 2000;\n-\n-            let (tx1, mut rx) = channel();\n-            tx1.send((token, end_tx));\n-            let mut i = 2;\n-            while i <= n_tasks {\n-                let (tx, next_rx) = channel();\n-                let imm_i = i;\n-                let imm_rx = rx;\n-                spawn(proc() {\n-                    roundtrip(imm_i, n_tasks, &imm_rx, &tx);\n-                });\n-                rx = next_rx;\n-                i += 1;\n-            }\n-            let rx = rx;\n-            spawn(proc() {\n-                roundtrip(1, n_tasks, &rx, &tx1);\n-            });\n-\n-            end_rx.recv();\n-        });\n-\n-        fn roundtrip(id: int, n_tasks: int,\n-                     rx: &Receiver<(int, Sender<()>)>,\n-                     tx: &Sender<(int, Sender<()>)>) {\n-            loop {\n-                match rx.recv() {\n-                    (1, end_tx) => {\n-                        debug!(\"{}\\n\", id);\n-                        end_tx.send(());\n-                        return;\n-                    }\n-                    (token, end_tx) => {\n-                        debug!(\"thread: {}   got token: {}\", id, token);\n-                        tx.send((token - 1, end_tx));\n-                        if token <= n_tasks {\n-                            return;\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-    }\n-\n-    #[test]\n-    fn start_closure_dtor() {\n-        // Regression test that the `start` task entrypoint can\n-        // contain dtors that use task resources\n-        run(proc() {\n-            #[allow(dead_code)]\n-            struct S { field: () }\n-\n-            impl Drop for S {\n-                fn drop(&mut self) {\n-                    let _foo = box 0i;\n-                }\n-            }\n-\n-            let s = S { field: () };\n-\n-            spawn(proc() {\n-                let _ss = &s;\n-            });\n-        });\n-    }\n-\n-    #[test]\n-    fn dont_starve_1() {\n-        let mut pool = SchedPool::new(PoolConfig {\n-            threads: 2, // this must be > 1\n-            event_loop_factory: basic::event_loop,\n-        });\n-        pool.spawn(TaskOpts::new(), proc() {\n-            let (tx, rx) = channel();\n-\n-            // This task should not be able to starve the sender;\n-            // The sender should get stolen to another thread.\n-            spawn(proc() {\n-                while rx.try_recv().is_err() { }\n-            });\n-\n-            tx.send(());\n-        });\n-        pool.shutdown();\n-    }\n-\n-    #[test]\n-    fn dont_starve_2() {\n-        run(proc() {\n-            let (tx1, rx1) = channel();\n-            let (tx2, _rx2) = channel();\n-\n-            // This task should not be able to starve the other task.\n-            // The sends should eventually yield.\n-            spawn(proc() {\n-                while rx1.try_recv().is_err() {\n-                    tx2.send(());\n-                }\n-            });\n-\n-            tx1.send(());\n-        });\n-    }\n-\n-    // Regression test for a logic bug that would cause single-threaded\n-    // schedulers to sleep forever after yielding and stealing another task.\n-    #[test]\n-    fn single_threaded_yield() {\n-        use std::task::deschedule;\n-        run(proc() {\n-            for _ in range(0u, 5) { deschedule(); }\n-        });\n-    }\n-\n-    #[test]\n-    fn test_spawn_sched_blocking() {\n-        use std::rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n-        static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n-\n-        // Testing that a task in one scheduler can block in foreign code\n-        // without affecting other schedulers\n-        for _ in range(0u, 20) {\n-            let mut pool = pool();\n-            let (start_tx, start_rx) = channel();\n-            let (fin_tx, fin_rx) = channel();\n-\n-            let mut handle = pool.spawn_sched();\n-            handle.send(PinnedTask(pool.task(TaskOpts::new(), proc() {\n-                unsafe {\n-                    let guard = LOCK.lock();\n-\n-                    start_tx.send(());\n-                    guard.wait();   // block the scheduler thread\n-                    guard.signal(); // let them know we have the lock\n-                }\n-\n-                fin_tx.send(());\n-            })));\n-            drop(handle);\n-\n-            let mut handle = pool.spawn_sched();\n-            handle.send(PinnedTask(pool.task(TaskOpts::new(), proc() {\n-                // Wait until the other task has its lock\n-                start_rx.recv();\n-\n-                fn pingpong(po: &Receiver<int>, ch: &Sender<int>) {\n-                    let mut val = 20;\n-                    while val > 0 {\n-                        val = po.recv();\n-                        let _ = ch.send_opt(val - 1);\n-                    }\n-                }\n-\n-                let (setup_tx, setup_rx) = channel();\n-                let (parent_tx, parent_rx) = channel();\n-                spawn(proc() {\n-                    let (child_tx, child_rx) = channel();\n-                    setup_tx.send(child_tx);\n-                    pingpong(&child_rx, &parent_tx);\n-                });\n-\n-                let child_tx = setup_rx.recv();\n-                child_tx.send(20);\n-                pingpong(&parent_rx, &child_tx);\n-                unsafe {\n-                    let guard = LOCK.lock();\n-                    guard.signal();   // wakeup waiting scheduler\n-                    guard.wait();     // wait for them to grab the lock\n-                }\n-            })));\n-            drop(handle);\n-\n-            fin_rx.recv();\n-            pool.shutdown();\n-        }\n-        unsafe { LOCK.destroy(); }\n-    }\n-}"}, {"sha": "e26a099c0282561f0a19628f1f0df3cbbdf504f3", "filename": "src/libgreen/simple.rs", "status": "removed", "additions": 0, "deletions": 96, "changes": 96, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsimple.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsimple.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsimple.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,96 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! A small module implementing a simple \"runtime\" used for bootstrapping a rust\n-//! scheduler pool and then interacting with it.\n-\n-use std::any::Any;\n-use std::mem;\n-use std::rt::Runtime;\n-use std::rt::local::Local;\n-use std::rt::mutex::NativeMutex;\n-use std::rt::task::{Task, BlockedTask, TaskOpts};\n-\n-struct SimpleTask {\n-    lock: NativeMutex,\n-    awoken: bool,\n-}\n-\n-impl Runtime for SimpleTask {\n-    // Implement the simple tasks of descheduling and rescheduling, but only in\n-    // a simple number of cases.\n-    fn deschedule(mut self: Box<SimpleTask>,\n-                  times: uint,\n-                  mut cur_task: Box<Task>,\n-                  f: |BlockedTask| -> Result<(), BlockedTask>) {\n-        assert!(times == 1);\n-\n-        let me = &mut *self as *mut SimpleTask;\n-        let cur_dupe = &mut *cur_task as *mut Task;\n-        cur_task.put_runtime(self);\n-        let task = BlockedTask::block(cur_task);\n-\n-        // See libnative/task.rs for what's going on here with the `awoken`\n-        // field and the while loop around wait()\n-        unsafe {\n-            let guard = (*me).lock.lock();\n-            (*me).awoken = false;\n-            match f(task) {\n-                Ok(()) => {\n-                    while !(*me).awoken {\n-                        guard.wait();\n-                    }\n-                }\n-                Err(task) => { mem::forget(task.wake()); }\n-            }\n-            drop(guard);\n-            cur_task = mem::transmute(cur_dupe);\n-        }\n-        Local::put(cur_task);\n-    }\n-    fn reawaken(mut self: Box<SimpleTask>, mut to_wake: Box<Task>) {\n-        let me = &mut *self as *mut SimpleTask;\n-        to_wake.put_runtime(self);\n-        unsafe {\n-            mem::forget(to_wake);\n-            let guard = (*me).lock.lock();\n-            (*me).awoken = true;\n-            guard.signal();\n-        }\n-    }\n-\n-    // These functions are all unimplemented and panic as a result. This is on\n-    // purpose. A \"simple task\" is just that, a very simple task that can't\n-    // really do a whole lot. The only purpose of the task is to get us off our\n-    // feet and running.\n-    fn yield_now(self: Box<SimpleTask>, _cur_task: Box<Task>) { panic!() }\n-    fn maybe_yield(self: Box<SimpleTask>, _cur_task: Box<Task>) { panic!() }\n-    fn spawn_sibling(self: Box<SimpleTask>,\n-                     _cur_task: Box<Task>,\n-                     _opts: TaskOpts,\n-                     _f: proc():Send) {\n-        panic!()\n-    }\n-\n-    fn stack_bounds(&self) -> (uint, uint) { panic!() }\n-    fn stack_guard(&self) -> Option<uint> { panic!() }\n-\n-    fn can_block(&self) -> bool { true }\n-    fn wrap(self: Box<SimpleTask>) -> Box<Any+'static> { panic!() }\n-}\n-\n-pub fn task() -> Box<Task> {\n-    let mut task = box Task::new();\n-    task.put_runtime(box SimpleTask {\n-        lock: unsafe {NativeMutex::new()},\n-        awoken: false,\n-    });\n-    return task;\n-}"}, {"sha": "5df866955e656101470378a26a3bcf5edb1f60b3", "filename": "src/libgreen/sleeper_list.rs", "status": "removed", "additions": 0, "deletions": 46, "changes": 46, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsleeper_list.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fsleeper_list.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fsleeper_list.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,46 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Maintains a shared list of sleeping schedulers. Schedulers\n-//! use this to wake each other up.\n-\n-use std::sync::mpmc_bounded_queue::Queue;\n-\n-use sched::SchedHandle;\n-\n-pub struct SleeperList {\n-    q: Queue<SchedHandle>,\n-}\n-\n-impl SleeperList {\n-    pub fn new() -> SleeperList {\n-        SleeperList{q: Queue::with_capacity(8*1024)}\n-    }\n-\n-    pub fn push(&mut self, value: SchedHandle) {\n-        assert!(self.q.push(value))\n-    }\n-\n-    pub fn pop(&mut self) -> Option<SchedHandle> {\n-        self.q.pop()\n-    }\n-\n-    pub fn casual_pop(&mut self) -> Option<SchedHandle> {\n-        self.q.pop()\n-    }\n-}\n-\n-impl Clone for SleeperList {\n-    fn clone(&self) -> SleeperList {\n-        SleeperList {\n-            q: self.q.clone()\n-        }\n-    }\n-}"}, {"sha": "81e6152b3d7c3802499a7f9c11e8e8849b0af6f7", "filename": "src/libgreen/stack.rs", "status": "removed", "additions": 0, "deletions": 215, "changes": 215, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fstack.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Fstack.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Fstack.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,215 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use std::ptr;\n-use std::sync::atomic;\n-use std::os::{errno, page_size, MemoryMap, MapReadable, MapWritable,\n-              MapNonStandardFlags, getenv};\n-use libc;\n-\n-/// A task's stack. The name \"Stack\" is a vestige of segmented stacks.\n-pub struct Stack {\n-    buf: Option<MemoryMap>,\n-    min_size: uint,\n-    valgrind_id: libc::c_uint,\n-}\n-\n-// Try to use MAP_STACK on platforms that support it (it's what we're doing\n-// anyway), but some platforms don't support it at all. For example, it appears\n-// that there's a bug in freebsd that MAP_STACK implies MAP_FIXED (so it always\n-// panics): http://lists.freebsd.org/pipermail/freebsd-bugs/2011-July/044840.html\n-//\n-// DragonFly BSD also seems to suffer from the same problem. When MAP_STACK is\n-// used, it returns the same `ptr` multiple times.\n-#[cfg(not(any(windows, target_os = \"freebsd\", target_os = \"dragonfly\")))]\n-static STACK_FLAGS: libc::c_int = libc::MAP_STACK | libc::MAP_PRIVATE |\n-                                  libc::MAP_ANON;\n-#[cfg(any(target_os = \"freebsd\", target_os = \"dragonfly\"))]\n-static STACK_FLAGS: libc::c_int = libc::MAP_PRIVATE | libc::MAP_ANON;\n-#[cfg(windows)]\n-static STACK_FLAGS: libc::c_int = 0;\n-\n-impl Stack {\n-    /// Allocate a new stack of `size`. If size = 0, this will panic. Use\n-    /// `dummy_stack` if you want a zero-sized stack.\n-    pub fn new(size: uint) -> Stack {\n-        // Map in a stack. Eventually we might be able to handle stack\n-        // allocation failure, which would fail to spawn the task. But there's\n-        // not many sensible things to do on OOM. Panic seems fine (and is\n-        // what the old stack allocation did).\n-        let stack = match MemoryMap::new(size, &[MapReadable, MapWritable,\n-                                                 MapNonStandardFlags(STACK_FLAGS)]) {\n-            Ok(map) => map,\n-            Err(e) => panic!(\"mmap for stack of size {} failed: {}\", size, e)\n-        };\n-\n-        // Change the last page to be inaccessible. This is to provide safety;\n-        // when an FFI function overflows it will (hopefully) hit this guard\n-        // page. It isn't guaranteed, but that's why FFI is unsafe. buf.data is\n-        // guaranteed to be aligned properly.\n-        if !protect_last_page(&stack) {\n-            panic!(\"Could not memory-protect guard page. stack={}, errno={}\",\n-                  stack.data(), errno());\n-        }\n-\n-        let mut stk = Stack {\n-            buf: Some(stack),\n-            min_size: size,\n-            valgrind_id: 0\n-        };\n-\n-        // FIXME: Using the FFI to call a C macro. Slow\n-        stk.valgrind_id = unsafe {\n-            rust_valgrind_stack_register(stk.start() as *const libc::uintptr_t,\n-                                         stk.end() as *const libc::uintptr_t)\n-        };\n-        return stk;\n-    }\n-\n-    /// Create a 0-length stack which starts (and ends) at 0.\n-    pub unsafe fn dummy_stack() -> Stack {\n-        Stack {\n-            buf: None,\n-            min_size: 0,\n-            valgrind_id: 0\n-        }\n-    }\n-\n-    /// Point to the last writable byte of the stack\n-    pub fn guard(&self) -> *const uint {\n-        (self.start() as uint + page_size()) as *const uint\n-    }\n-\n-    /// Point to the low end of the allocated stack\n-    pub fn start(&self) -> *const uint {\n-        self.buf.as_ref().map(|m| m.data() as *const uint)\n-            .unwrap_or(ptr::null())\n-    }\n-\n-    /// Point one uint beyond the high end of the allocated stack\n-    pub fn end(&self) -> *const uint {\n-        self.buf.as_ref().map(|buf| unsafe {\n-            buf.data().offset(buf.len() as int) as *const uint\n-        }).unwrap_or(ptr::null())\n-    }\n-}\n-\n-#[cfg(unix)]\n-fn protect_last_page(stack: &MemoryMap) -> bool {\n-    unsafe {\n-        // This may seem backwards: the start of the segment is the last page?\n-        // Yes! The stack grows from higher addresses (the end of the allocated\n-        // block) to lower addresses (the start of the allocated block).\n-        let last_page = stack.data() as *mut libc::c_void;\n-        libc::mprotect(last_page, page_size() as libc::size_t,\n-                       libc::PROT_NONE) != -1\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn protect_last_page(stack: &MemoryMap) -> bool {\n-    unsafe {\n-        // see above\n-        let last_page = stack.data() as *mut libc::c_void;\n-        let mut old_prot: libc::DWORD = 0;\n-        libc::VirtualProtect(last_page, page_size() as libc::SIZE_T,\n-                             libc::PAGE_NOACCESS,\n-                             &mut old_prot as libc::LPDWORD) != 0\n-    }\n-}\n-\n-impl Drop for Stack {\n-    fn drop(&mut self) {\n-        unsafe {\n-            // FIXME: Using the FFI to call a C macro. Slow\n-            rust_valgrind_stack_deregister(self.valgrind_id);\n-        }\n-    }\n-}\n-\n-pub struct StackPool {\n-    // Ideally this would be some data structure that preserved ordering on\n-    // Stack.min_size.\n-    stacks: Vec<Stack>,\n-}\n-\n-impl StackPool {\n-    pub fn new() -> StackPool {\n-        StackPool {\n-            stacks: vec![],\n-        }\n-    }\n-\n-    pub fn take_stack(&mut self, min_size: uint) -> Stack {\n-        // Ideally this would be a binary search\n-        match self.stacks.iter().position(|s| min_size <= s.min_size) {\n-            Some(idx) => self.stacks.swap_remove(idx).unwrap(),\n-            None => Stack::new(min_size)\n-        }\n-    }\n-\n-    pub fn give_stack(&mut self, stack: Stack) {\n-        if self.stacks.len() <= max_cached_stacks() {\n-            self.stacks.push(stack)\n-        }\n-    }\n-}\n-\n-fn max_cached_stacks() -> uint {\n-    static AMT: atomic::AtomicUint = atomic::INIT_ATOMIC_UINT;\n-    match AMT.load(atomic::SeqCst) {\n-        0 => {}\n-        n => return n - 1,\n-    }\n-    let amt = getenv(\"RUST_MAX_CACHED_STACKS\").and_then(|s| from_str(s.as_slice()));\n-    // This default corresponds to 20M of cache per scheduler (at the\n-    // default size).\n-    let amt = amt.unwrap_or(10);\n-    // 0 is our sentinel value, so ensure that we'll never see 0 after\n-    // initialization has run\n-    AMT.store(amt + 1, atomic::SeqCst);\n-    return amt;\n-}\n-\n-extern {\n-    fn rust_valgrind_stack_register(start: *const libc::uintptr_t,\n-                                    end: *const libc::uintptr_t) -> libc::c_uint;\n-    fn rust_valgrind_stack_deregister(id: libc::c_uint);\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use super::StackPool;\n-\n-    #[test]\n-    fn stack_pool_caches() {\n-        let mut p = StackPool::new();\n-        let s = p.take_stack(10);\n-        p.give_stack(s);\n-        let s = p.take_stack(4);\n-        assert_eq!(s.min_size, 10);\n-        p.give_stack(s);\n-        let s = p.take_stack(14);\n-        assert_eq!(s.min_size, 14);\n-        p.give_stack(s);\n-    }\n-\n-    #[test]\n-    fn stack_pool_caches_exact() {\n-        let mut p = StackPool::new();\n-        let mut s = p.take_stack(10);\n-        s.valgrind_id = 100;\n-        p.give_stack(s);\n-\n-        let s = p.take_stack(10);\n-        assert_eq!(s.min_size, 10);\n-        assert_eq!(s.valgrind_id, 100);\n-    }\n-}"}, {"sha": "e159c153bc38c73a576db94442011dc53574129d", "filename": "src/libgreen/task.rs", "status": "removed", "additions": 0, "deletions": 602, "changes": 602, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibgreen%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibgreen%2Ftask.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,602 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! The Green Task implementation\n-//!\n-//! This module contains the glue to the libstd runtime necessary to integrate\n-//! M:N scheduling. This GreenTask structure is hidden as a trait object in all\n-//! rust tasks and virtual calls are made in order to interface with it.\n-//!\n-//! Each green task contains a scheduler if it is currently running, and it also\n-//! contains the rust task itself in order to juggle around ownership of the\n-//! values.\n-\n-pub use self::TaskType::*;\n-pub use self::Home::*;\n-\n-use std::any::Any;\n-use std::mem;\n-use std::raw;\n-use std::rt::Runtime;\n-use std::rt::local::Local;\n-use std::rt::mutex::NativeMutex;\n-use std::rt::stack;\n-use std::rt::task::{Task, BlockedTask, TaskOpts};\n-use std::rt;\n-\n-use context::Context;\n-use coroutine::Coroutine;\n-use sched::{Scheduler, SchedHandle, RunOnce};\n-use stack::StackPool;\n-\n-/// The necessary fields needed to keep track of a green task (as opposed to a\n-/// 1:1 task).\n-pub struct GreenTask {\n-    /// Coroutine that this task is running on, otherwise known as the register\n-    /// context and the stack that this task owns. This field is optional to\n-    /// relinquish ownership back to a scheduler to recycle stacks at a later\n-    /// date.\n-    pub coroutine: Option<Coroutine>,\n-\n-    /// Optional handle back into the home sched pool of this task. This field\n-    /// is lazily initialized.\n-    pub handle: Option<SchedHandle>,\n-\n-    /// Slot for maintaining ownership of a scheduler. If a task is running,\n-    /// this value will be Some(sched) where the task is running on \"sched\".\n-    pub sched: Option<Box<Scheduler>>,\n-\n-    /// Temporary ownership slot of a std::rt::task::Task object. This is used\n-    /// to squirrel that libstd task away while we're performing green task\n-    /// operations.\n-    pub task: Option<Box<Task>>,\n-\n-    /// Dictates whether this is a sched task or a normal green task\n-    pub task_type: TaskType,\n-\n-    /// Home pool that this task was spawned into. This field is lazily\n-    /// initialized until when the task is initially scheduled, and is used to\n-    /// make sure that tasks are always woken up in the correct pool of\n-    /// schedulers.\n-    pub pool_id: uint,\n-\n-    // See the comments in the scheduler about why this is necessary\n-    pub nasty_deschedule_lock: NativeMutex,\n-}\n-\n-pub enum TaskType {\n-    TypeGreen(Option<Home>),\n-    TypeSched,\n-}\n-\n-pub enum Home {\n-    AnySched,\n-    HomeSched(SchedHandle),\n-}\n-\n-/// Trampoline code for all new green tasks which are running around. This\n-/// function is passed through to Context::new as the initial rust landing pad\n-/// for all green tasks. This code is actually called after the initial context\n-/// switch onto a green thread.\n-///\n-/// The first argument to this function is the `Box<GreenTask>` pointer, and\n-/// the next two arguments are the user-provided procedure for running code.\n-///\n-/// The goal for having this weird-looking function is to reduce the number of\n-/// allocations done on a green-task startup as much as possible.\n-extern fn bootstrap_green_task(task: uint, code: *mut (), env: *mut ()) -> ! {\n-    // Acquire ownership of the `proc()`\n-    let start: proc() = unsafe {\n-        mem::transmute(raw::Procedure { code: code, env: env })\n-    };\n-\n-    // Acquire ownership of the `Box<GreenTask>`\n-    let mut task: Box<GreenTask> = unsafe { mem::transmute(task) };\n-\n-    // First code after swap to this new context. Run our cleanup job\n-    task.pool_id = {\n-        let sched = task.sched.as_mut().unwrap();\n-        sched.run_cleanup_job();\n-        sched.task_state.increment();\n-        sched.pool_id\n-    };\n-\n-    // Convert our green task to a libstd task and then execute the code\n-    // requested. This is the \"try/catch\" block for this green task and\n-    // is the wrapper for *all* code run in the task.\n-    let mut start = Some(start);\n-    let task = task.swap().run(|| start.take().unwrap()()).destroy();\n-\n-    // Once the function has exited, it's time to run the termination\n-    // routine. This means we need to context switch one more time but\n-    // clean ourselves up on the other end. Since we have no way of\n-    // preserving a handle to the GreenTask down to this point, this\n-    // unfortunately must call `GreenTask::convert`. In order to avoid\n-    // this we could add a `terminate` function to the `Runtime` trait\n-    // in libstd, but that seems less appropriate since the conversion\n-    // method exists.\n-    GreenTask::convert(task).terminate();\n-}\n-\n-impl GreenTask {\n-    /// Creates a new green task which is not homed to any particular scheduler\n-    /// and will not have any contained Task structure.\n-    pub fn new(stack_pool: &mut StackPool,\n-               stack_size: Option<uint>,\n-               start: proc():Send) -> Box<GreenTask> {\n-        GreenTask::new_homed(stack_pool, stack_size, AnySched, start)\n-    }\n-\n-    /// Creates a new task (like `new`), but specifies the home for new task.\n-    pub fn new_homed(stack_pool: &mut StackPool,\n-                     stack_size: Option<uint>,\n-                     home: Home,\n-                     start: proc():Send) -> Box<GreenTask> {\n-        // Allocate ourselves a GreenTask structure\n-        let mut ops = GreenTask::new_typed(None, TypeGreen(Some(home)));\n-\n-        // Allocate a stack for us to run on\n-        let stack_size = stack_size.unwrap_or_else(|| rt::min_stack());\n-        let mut stack = stack_pool.take_stack(stack_size);\n-        let context = Context::new(bootstrap_green_task, ops.as_uint(), start,\n-                                   &mut stack);\n-\n-        // Package everything up in a coroutine and return\n-        ops.coroutine = Some(Coroutine {\n-            current_stack_segment: stack,\n-            saved_context: context,\n-        });\n-        return ops;\n-    }\n-\n-    /// Creates a new green task with the specified coroutine and type, this is\n-    /// useful when creating scheduler tasks.\n-    pub fn new_typed(coroutine: Option<Coroutine>,\n-                     task_type: TaskType) -> Box<GreenTask> {\n-        box GreenTask {\n-            pool_id: 0,\n-            coroutine: coroutine,\n-            task_type: task_type,\n-            sched: None,\n-            handle: None,\n-            nasty_deschedule_lock: unsafe { NativeMutex::new() },\n-            task: Some(box Task::new()),\n-        }\n-    }\n-\n-    /// Creates a new green task with the given configuration options for the\n-    /// contained Task object. The given stack pool is also used to allocate a\n-    /// new stack for this task.\n-    pub fn configure(pool: &mut StackPool,\n-                     opts: TaskOpts,\n-                     f: proc():Send) -> Box<GreenTask> {\n-        let TaskOpts { name, stack_size, on_exit } = opts;\n-\n-        let mut green = GreenTask::new(pool, stack_size, f);\n-        {\n-            let task = green.task.as_mut().unwrap();\n-            task.name = name;\n-            task.death.on_exit = on_exit;\n-        }\n-        return green;\n-    }\n-\n-    /// Just like the `maybe_take_runtime` function, this function should *not*\n-    /// exist. Usage of this function is _strongly_ discouraged. This is an\n-    /// absolute last resort necessary for converting a libstd task to a green\n-    /// task.\n-    ///\n-    /// This function will assert that the task is indeed a green task before\n-    /// returning (and will kill the entire process if this is wrong).\n-    pub fn convert(mut task: Box<Task>) -> Box<GreenTask> {\n-        match task.maybe_take_runtime::<GreenTask>() {\n-            Some(mut green) => {\n-                green.put_task(task);\n-                green\n-            }\n-            None => rtabort!(\"not a green task any more?\"),\n-        }\n-    }\n-\n-    pub fn give_home(&mut self, new_home: Home) {\n-        match self.task_type {\n-            TypeGreen(ref mut home) => { *home = Some(new_home); }\n-            TypeSched => rtabort!(\"type error: used SchedTask as GreenTask\"),\n-        }\n-    }\n-\n-    pub fn take_unwrap_home(&mut self) -> Home {\n-        match self.task_type {\n-            TypeGreen(ref mut home) => home.take().unwrap(),\n-            TypeSched => rtabort!(\"type error: used SchedTask as GreenTask\"),\n-        }\n-    }\n-\n-    // New utility functions for homes.\n-\n-    pub fn is_home_no_tls(&self, sched: &Scheduler) -> bool {\n-        match self.task_type {\n-            TypeGreen(Some(AnySched)) => { false }\n-            TypeGreen(Some(HomeSched(SchedHandle { sched_id: ref id, .. }))) => {\n-                *id == sched.sched_id()\n-            }\n-            TypeGreen(None) => { rtabort!(\"task without home\"); }\n-            TypeSched => {\n-                // Awe yea\n-                rtabort!(\"type error: expected: TypeGreen, found: TaskSched\");\n-            }\n-        }\n-    }\n-\n-    pub fn homed(&self) -> bool {\n-        match self.task_type {\n-            TypeGreen(Some(AnySched)) => { false }\n-            TypeGreen(Some(HomeSched(SchedHandle { .. }))) => { true }\n-            TypeGreen(None) => {\n-                rtabort!(\"task without home\");\n-            }\n-            TypeSched => {\n-                rtabort!(\"type error: expected: TypeGreen, found: TaskSched\");\n-            }\n-        }\n-    }\n-\n-    pub fn is_sched(&self) -> bool {\n-        match self.task_type {\n-            TypeGreen(..) => false, TypeSched => true,\n-        }\n-    }\n-\n-    // Unsafe functions for transferring ownership of this GreenTask across\n-    // context switches\n-\n-    pub fn as_uint(&self) -> uint {\n-        self as *const GreenTask as uint\n-    }\n-\n-    pub unsafe fn from_uint(val: uint) -> Box<GreenTask> {\n-        mem::transmute(val)\n-    }\n-\n-    // Runtime glue functions and helpers\n-\n-    pub fn put_with_sched(mut self: Box<GreenTask>, sched: Box<Scheduler>) {\n-        assert!(self.sched.is_none());\n-        self.sched = Some(sched);\n-        self.put();\n-    }\n-\n-    pub fn put_task(&mut self, task: Box<Task>) {\n-        assert!(self.task.is_none());\n-        self.task = Some(task);\n-    }\n-\n-    pub fn swap(mut self: Box<GreenTask>) -> Box<Task> {\n-        let mut task = self.task.take().unwrap();\n-        task.put_runtime(self);\n-        return task;\n-    }\n-\n-    pub fn put(self: Box<GreenTask>) {\n-        assert!(self.sched.is_some());\n-        Local::put(self.swap());\n-    }\n-\n-    fn terminate(mut self: Box<GreenTask>) -> ! {\n-        let sched = self.sched.take().unwrap();\n-        sched.terminate_current_task(self)\n-    }\n-\n-    // This function is used to remotely wakeup this green task back on to its\n-    // original pool of schedulers. In order to do so, each tasks arranges a\n-    // SchedHandle upon descheduling to be available for sending itself back to\n-    // the original pool.\n-    //\n-    // Note that there is an interesting transfer of ownership going on here. We\n-    // must relinquish ownership of the green task, but then also send the task\n-    // over the handle back to the original scheduler. In order to safely do\n-    // this, we leverage the already-present \"nasty descheduling lock\". The\n-    // reason for doing this is that each task will bounce on this lock after\n-    // resuming after a context switch. By holding the lock over the enqueueing\n-    // of the task, we're guaranteed that the SchedHandle's memory will be valid\n-    // for this entire function.\n-    //\n-    // An alternative would include having incredibly cheaply cloneable handles,\n-    // but right now a SchedHandle is something like 6 allocations, so it is\n-    // *not* a cheap operation to clone a handle. Until the day comes that we\n-    // need to optimize this, a lock should do just fine (it's completely\n-    // uncontended except for when the task is rescheduled).\n-    fn reawaken_remotely(mut self: Box<GreenTask>) {\n-        unsafe {\n-            let mtx = &mut self.nasty_deschedule_lock as *mut NativeMutex;\n-            let handle = self.handle.as_mut().unwrap() as *mut SchedHandle;\n-            let _guard = (*mtx).lock();\n-            (*handle).send(RunOnce(self));\n-        }\n-    }\n-}\n-\n-impl Runtime for GreenTask {\n-    fn yield_now(mut self: Box<GreenTask>, cur_task: Box<Task>) {\n-        self.put_task(cur_task);\n-        let sched = self.sched.take().unwrap();\n-        sched.yield_now(self);\n-    }\n-\n-    fn maybe_yield(mut self: Box<GreenTask>, cur_task: Box<Task>) {\n-        self.put_task(cur_task);\n-        let sched = self.sched.take().unwrap();\n-        sched.maybe_yield(self);\n-    }\n-\n-    fn deschedule(mut self: Box<GreenTask>,\n-                  times: uint,\n-                  cur_task: Box<Task>,\n-                  f: |BlockedTask| -> Result<(), BlockedTask>) {\n-        self.put_task(cur_task);\n-        let mut sched = self.sched.take().unwrap();\n-\n-        // In order for this task to be reawoken in all possible contexts, we\n-        // may need a handle back in to the current scheduler. When we're woken\n-        // up in anything other than the local scheduler pool, this handle is\n-        // used to send this task back into the scheduler pool.\n-        if self.handle.is_none() {\n-            self.handle = Some(sched.make_handle());\n-            self.pool_id = sched.pool_id;\n-        }\n-\n-        // This code is pretty standard, except for the usage of\n-        // `GreenTask::convert`. Right now if we use `reawaken` directly it will\n-        // expect for there to be a task in local TLS, but that is not true for\n-        // this deschedule block (because the scheduler must retain ownership of\n-        // the task while the cleanup job is running). In order to get around\n-        // this for now, we invoke the scheduler directly with the converted\n-        // Task => GreenTask structure.\n-        if times == 1 {\n-            sched.deschedule_running_task_and_then(self, |sched, task| {\n-                match f(task) {\n-                    Ok(()) => {}\n-                    Err(t) => {\n-                        t.wake().map(|t| {\n-                            sched.enqueue_task(GreenTask::convert(t))\n-                        });\n-                    }\n-                }\n-            });\n-        } else {\n-            sched.deschedule_running_task_and_then(self, |sched, task| {\n-                for task in task.make_selectable(times) {\n-                    match f(task) {\n-                        Ok(()) => {},\n-                        Err(task) => {\n-                            task.wake().map(|t| {\n-                                sched.enqueue_task(GreenTask::convert(t))\n-                            });\n-                            break\n-                        }\n-                    }\n-                }\n-            });\n-        }\n-    }\n-\n-    fn reawaken(mut self: Box<GreenTask>, to_wake: Box<Task>) {\n-        self.put_task(to_wake);\n-        assert!(self.sched.is_none());\n-\n-        // Optimistically look for a local task, but if one's not available to\n-        // inspect (in order to see if it's in the same sched pool as we are),\n-        // then just use our remote wakeup routine and carry on!\n-        let mut running_task: Box<Task> = match Local::try_take() {\n-            Some(task) => task,\n-            None => return self.reawaken_remotely()\n-        };\n-\n-        // Waking up a green thread is a bit of a tricky situation. We have no\n-        // guarantee about where the current task is running. The options we\n-        // have for where this current task is running are:\n-        //\n-        //  1. Our original scheduler pool\n-        //  2. Some other scheduler pool\n-        //  3. Something that isn't a scheduler pool\n-        //\n-        // In order to figure out what case we're in, this is the reason that\n-        // the `maybe_take_runtime` function exists. Using this function we can\n-        // dynamically check to see which of these cases is the current\n-        // situation and then dispatch accordingly.\n-        //\n-        // In case 1, we just use the local scheduler to resume ourselves\n-        // immediately (if a rescheduling is possible).\n-        //\n-        // In case 2 and 3, we need to remotely reawaken ourself in order to be\n-        // transplanted back to the correct scheduler pool.\n-        match running_task.maybe_take_runtime::<GreenTask>() {\n-            Some(mut running_green_task) => {\n-                running_green_task.put_task(running_task);\n-                let sched = running_green_task.sched.take().unwrap();\n-\n-                if sched.pool_id == self.pool_id {\n-                    sched.run_task(running_green_task, self);\n-                } else {\n-                    self.reawaken_remotely();\n-\n-                    // put that thing back where it came from!\n-                    running_green_task.put_with_sched(sched);\n-                }\n-            }\n-            None => {\n-                self.reawaken_remotely();\n-                Local::put(running_task);\n-            }\n-        }\n-    }\n-\n-    fn spawn_sibling(mut self: Box<GreenTask>,\n-                     cur_task: Box<Task>,\n-                     opts: TaskOpts,\n-                     f: proc():Send) {\n-        self.put_task(cur_task);\n-\n-        // First, set up a bomb which when it goes off will restore the local\n-        // task unless its disarmed. This will allow us to gracefully panic from\n-        // inside of `configure` which allocates a new task.\n-        struct Bomb { inner: Option<Box<GreenTask>> }\n-        impl Drop for Bomb {\n-            fn drop(&mut self) {\n-                let _ = self.inner.take().map(|task| task.put());\n-            }\n-        }\n-        let mut bomb = Bomb { inner: Some(self) };\n-\n-        // Spawns a task into the current scheduler. We allocate the new task's\n-        // stack from the scheduler's stack pool, and then configure it\n-        // accordingly to `opts`. Afterwards we bootstrap it immediately by\n-        // switching to it.\n-        //\n-        // Upon returning, our task is back in TLS and we're good to return.\n-        let sibling = {\n-            let sched = bomb.inner.as_mut().unwrap().sched.as_mut().unwrap();\n-            GreenTask::configure(&mut sched.stack_pool, opts, f)\n-        };\n-        let mut me = bomb.inner.take().unwrap();\n-        let sched = me.sched.take().unwrap();\n-        sched.run_task(me, sibling)\n-    }\n-\n-    fn stack_bounds(&self) -> (uint, uint) {\n-        let c = self.coroutine.as_ref()\n-            .expect(\"GreenTask.stack_bounds called without a coroutine\");\n-\n-        // Don't return the red zone as part of the usable stack of this task,\n-        // it's essentially an implementation detail.\n-        (c.current_stack_segment.start() as uint + stack::RED_ZONE,\n-         c.current_stack_segment.end() as uint)\n-    }\n-\n-    fn stack_guard(&self) -> Option<uint> {\n-        let c = self.coroutine.as_ref()\n-            .expect(\"GreenTask.stack_guard called without a coroutine\");\n-\n-        Some(c.current_stack_segment.guard() as uint)\n-    }\n-\n-    fn can_block(&self) -> bool { false }\n-\n-    fn wrap(self: Box<GreenTask>) -> Box<Any+'static> {\n-        self as Box<Any+'static>\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use std::rt::local::Local;\n-    use std::rt::task::Task;\n-    use std::task;\n-    use std::rt::task::TaskOpts;\n-\n-    use super::super::{PoolConfig, SchedPool};\n-    use super::GreenTask;\n-\n-    fn spawn_opts(opts: TaskOpts, f: proc():Send) {\n-        let mut pool = SchedPool::new(PoolConfig {\n-            threads: 1,\n-            event_loop_factory: super::super::basic::event_loop,\n-        });\n-        pool.spawn(opts, f);\n-        pool.shutdown();\n-    }\n-\n-    #[test]\n-    fn smoke() {\n-        let (tx, rx) = channel();\n-        spawn_opts(TaskOpts::new(), proc() {\n-            tx.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn smoke_panic() {\n-        let (tx, rx) = channel::<int>();\n-        spawn_opts(TaskOpts::new(), proc() {\n-            let _tx = tx;\n-            panic!()\n-        });\n-        assert_eq!(rx.recv_opt(), Err(()));\n-    }\n-\n-    #[test]\n-    fn smoke_opts() {\n-        let mut opts = TaskOpts::new();\n-        opts.name = Some(\"test\".into_maybe_owned());\n-        opts.stack_size = Some(20 * 4096);\n-        let (tx, rx) = channel();\n-        opts.on_exit = Some(proc(r) tx.send(r));\n-        spawn_opts(opts, proc() {});\n-        assert!(rx.recv().is_ok());\n-    }\n-\n-    #[test]\n-    fn smoke_opts_panic() {\n-        let mut opts = TaskOpts::new();\n-        let (tx, rx) = channel();\n-        opts.on_exit = Some(proc(r) tx.send(r));\n-        spawn_opts(opts, proc() { panic!() });\n-        assert!(rx.recv().is_err());\n-    }\n-\n-    #[test]\n-    fn yield_test() {\n-        let (tx, rx) = channel();\n-        spawn_opts(TaskOpts::new(), proc() {\n-            for _ in range(0u, 10) { task::deschedule(); }\n-            tx.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn spawn_children() {\n-        let (tx1, rx) = channel();\n-        spawn_opts(TaskOpts::new(), proc() {\n-            let (tx2, rx) = channel();\n-            spawn(proc() {\n-                let (tx3, rx) = channel();\n-                spawn(proc() {\n-                    tx3.send(());\n-                });\n-                rx.recv();\n-                tx2.send(());\n-            });\n-            rx.recv();\n-            tx1.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn spawn_inherits() {\n-        let (tx, rx) = channel();\n-        spawn_opts(TaskOpts::new(), proc() {\n-            spawn(proc() {\n-                let mut task: Box<Task> = Local::take();\n-                match task.maybe_take_runtime::<GreenTask>() {\n-                    Some(ops) => {\n-                        task.put_runtime(ops);\n-                    }\n-                    None => panic!(),\n-                }\n-                Local::put(task);\n-                tx.send(());\n-            });\n-        });\n-        rx.recv();\n-    }\n-}"}, {"sha": "10610b705840650b6a227d901ea903f62a99e01b", "filename": "src/liblibc/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Fliblibc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Fliblibc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fliblibc%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -83,7 +83,6 @@ extern crate core;\n \n #[cfg(test)] extern crate std;\n #[cfg(test)] extern crate test;\n-#[cfg(test)] extern crate native;\n \n pub use self::Nullable::*;\n "}, {"sha": "d40438e4272a3bd0f69892b7e8537d3938cb803c", "filename": "src/libnative/io/addrinfo.rs", "status": "removed", "additions": 0, "deletions": 116, "changes": 116, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Fio%2Faddrinfo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Fio%2Faddrinfo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Faddrinfo.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,116 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use libc::{c_char, c_int};\n-use libc;\n-use std::mem;\n-use std::ptr::{null, null_mut};\n-use std::rt::rtio;\n-use std::rt::rtio::IoError;\n-\n-use super::net;\n-\n-pub struct GetAddrInfoRequest;\n-\n-impl GetAddrInfoRequest {\n-    pub fn run(host: Option<&str>, servname: Option<&str>,\n-               hint: Option<rtio::AddrinfoHint>)\n-        -> Result<Vec<rtio::AddrinfoInfo>, IoError>\n-    {\n-        assert!(host.is_some() || servname.is_some());\n-\n-        let c_host = host.map(|x| x.to_c_str());\n-        let c_host = c_host.as_ref().map(|x| x.as_ptr()).unwrap_or(null());\n-        let c_serv = servname.map(|x| x.to_c_str());\n-        let c_serv = c_serv.as_ref().map(|x| x.as_ptr()).unwrap_or(null());\n-\n-        let hint = hint.map(|hint| {\n-            libc::addrinfo {\n-                ai_flags: hint.flags as c_int,\n-                ai_family: hint.family as c_int,\n-                ai_socktype: 0,\n-                ai_protocol: 0,\n-                ai_addrlen: 0,\n-                ai_canonname: null_mut(),\n-                ai_addr: null_mut(),\n-                ai_next: null_mut()\n-            }\n-        });\n-\n-        let hint_ptr = hint.as_ref().map_or(null(), |x| {\n-            x as *const libc::addrinfo\n-        });\n-        let mut res = null_mut();\n-\n-        // Make the call\n-        let s = unsafe {\n-            getaddrinfo(c_host, c_serv, hint_ptr, &mut res)\n-        };\n-\n-        // Error?\n-        if s != 0 {\n-            return Err(get_error(s));\n-        }\n-\n-        // Collect all the results we found\n-        let mut addrs = Vec::new();\n-        let mut rp = res;\n-        while rp.is_not_null() {\n-            unsafe {\n-                let addr = match net::sockaddr_to_addr(mem::transmute((*rp).ai_addr),\n-                                                       (*rp).ai_addrlen as uint) {\n-                    Ok(a) => a,\n-                    Err(e) => return Err(e)\n-                };\n-                addrs.push(rtio::AddrinfoInfo {\n-                    address: addr,\n-                    family: (*rp).ai_family as uint,\n-                    socktype: 0,\n-                    protocol: 0,\n-                    flags: (*rp).ai_flags as uint\n-                });\n-\n-                rp = (*rp).ai_next as *mut libc::addrinfo;\n-            }\n-        }\n-\n-        unsafe { freeaddrinfo(res); }\n-\n-        Ok(addrs)\n-    }\n-}\n-\n-extern \"system\" {\n-    fn getaddrinfo(node: *const c_char, service: *const c_char,\n-                   hints: *const libc::addrinfo,\n-                   res: *mut *mut libc::addrinfo) -> c_int;\n-    fn freeaddrinfo(res: *mut libc::addrinfo);\n-    #[cfg(not(windows))]\n-    fn gai_strerror(errcode: c_int) -> *const c_char;\n-}\n-\n-#[cfg(windows)]\n-fn get_error(_: c_int) -> IoError {\n-    net::last_error()\n-}\n-\n-#[cfg(not(windows))]\n-fn get_error(s: c_int) -> IoError {\n-    use std::c_str::CString;\n-\n-    let err_str = unsafe {\n-        CString::new(gai_strerror(s), false).as_str().unwrap().to_string()\n-    };\n-    IoError {\n-        code: s as uint,\n-        extra: 0,\n-        detail: Some(err_str),\n-    }\n-}"}, {"sha": "30c916f3303464c024a311e8f8df85ede0862005", "filename": "src/libnative/io/process.rs", "status": "removed", "additions": 0, "deletions": 1240, "changes": 1240, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Fio%2Fprocess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Fio%2Fprocess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Fio%2Fprocess.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,1240 +0,0 @@\n-// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-use libc::{pid_t, c_void, c_int};\n-use libc;\n-use std::c_str::CString;\n-use std::io;\n-use std::mem;\n-use std::os;\n-use std::ptr;\n-use std::rt::rtio::{ProcessConfig, IoResult, IoError};\n-use std::rt::rtio;\n-\n-use super::file;\n-use super::util;\n-\n-#[cfg(windows)] use std::io::fs::PathExtensions;\n-#[cfg(windows)] use std::string::String;\n-#[cfg(unix)] use super::c;\n-#[cfg(unix)] use super::retry;\n-#[cfg(unix)] use io::helper_thread::Helper;\n-\n-#[cfg(unix)]\n-helper_init!(static HELPER: Helper<Req>)\n-\n-/**\n- * A value representing a child process.\n- *\n- * The lifetime of this value is linked to the lifetime of the actual\n- * process - the Process destructor calls self.finish() which waits\n- * for the process to terminate.\n- */\n-pub struct Process {\n-    /// The unique id of the process (this should never be negative).\n-    pid: pid_t,\n-\n-    /// A handle to the process - on unix this will always be NULL, but on\n-    /// windows it will be a HANDLE to the process, which will prevent the\n-    /// pid being re-used until the handle is closed.\n-    handle: *mut (),\n-\n-    /// None until finish() is called.\n-    exit_code: Option<rtio::ProcessExit>,\n-\n-    /// Manually delivered signal\n-    exit_signal: Option<int>,\n-\n-    /// Deadline after which wait() will return\n-    deadline: u64,\n-}\n-\n-#[cfg(unix)]\n-enum Req {\n-    NewChild(libc::pid_t, Sender<rtio::ProcessExit>, u64),\n-}\n-\n-impl Process {\n-    /// Creates a new process using native process-spawning abilities provided\n-    /// by the OS. Operations on this process will be blocking instead of using\n-    /// the runtime for sleeping just this current task.\n-    pub fn spawn(cfg: ProcessConfig)\n-        -> IoResult<(Process, Vec<Option<file::FileDesc>>)>\n-    {\n-        // right now we only handle stdin/stdout/stderr.\n-        if cfg.extra_io.len() > 0 {\n-            return Err(super::unimpl());\n-        }\n-\n-        fn get_io(io: rtio::StdioContainer,\n-                  ret: &mut Vec<Option<file::FileDesc>>)\n-            -> IoResult<Option<file::FileDesc>>\n-        {\n-            match io {\n-                rtio::Ignored => { ret.push(None); Ok(None) }\n-                rtio::InheritFd(fd) => {\n-                    ret.push(None);\n-                    Ok(Some(file::FileDesc::new(fd, false)))\n-                }\n-                rtio::CreatePipe(readable, _writable) => {\n-                    let (reader, writer) = try!(pipe());\n-                    let (theirs, ours) = if readable {\n-                        (reader, writer)\n-                    } else {\n-                        (writer, reader)\n-                    };\n-                    ret.push(Some(ours));\n-                    Ok(Some(theirs))\n-                }\n-            }\n-        }\n-\n-        let mut ret_io = Vec::new();\n-        let res = spawn_process_os(cfg,\n-                                   try!(get_io(cfg.stdin, &mut ret_io)),\n-                                   try!(get_io(cfg.stdout, &mut ret_io)),\n-                                   try!(get_io(cfg.stderr, &mut ret_io)));\n-\n-        match res {\n-            Ok(res) => {\n-                let p = Process {\n-                    pid: res.pid,\n-                    handle: res.handle,\n-                    exit_code: None,\n-                    exit_signal: None,\n-                    deadline: 0,\n-                };\n-                Ok((p, ret_io))\n-            }\n-            Err(e) => Err(e)\n-        }\n-    }\n-\n-    pub fn kill(pid: libc::pid_t, signum: int) -> IoResult<()> {\n-        unsafe { killpid(pid, signum) }\n-    }\n-}\n-\n-impl rtio::RtioProcess for Process {\n-    fn id(&self) -> pid_t { self.pid }\n-\n-    fn set_timeout(&mut self, timeout: Option<u64>) {\n-        self.deadline = timeout.map(|i| i + ::io::timer::now()).unwrap_or(0);\n-    }\n-\n-    fn wait(&mut self) -> IoResult<rtio::ProcessExit> {\n-        match self.exit_code {\n-            Some(code) => Ok(code),\n-            None => {\n-                let code = try!(waitpid(self.pid, self.deadline));\n-                // On windows, waitpid will never return a signal. If a signal\n-                // was successfully delivered to the process, however, we can\n-                // consider it as having died via a signal.\n-                let code = match self.exit_signal {\n-                    None => code,\n-                    Some(signal) if cfg!(windows) => rtio::ExitSignal(signal),\n-                    Some(..) => code,\n-                };\n-                self.exit_code = Some(code);\n-                Ok(code)\n-            }\n-        }\n-    }\n-\n-    fn kill(&mut self, signum: int) -> IoResult<()> {\n-        #[cfg(unix)] use libc::EINVAL as ERROR;\n-        #[cfg(windows)] use libc::ERROR_NOTHING_TO_TERMINATE as ERROR;\n-\n-        // On Linux (and possibly other unices), a process that has exited will\n-        // continue to accept signals because it is \"defunct\". The delivery of\n-        // signals will only fail once the child has been reaped. For this\n-        // reason, if the process hasn't exited yet, then we attempt to collect\n-        // their status with WNOHANG.\n-        if self.exit_code.is_none() {\n-            match waitpid_nowait(self.pid) {\n-                Some(code) => { self.exit_code = Some(code); }\n-                None => {}\n-            }\n-        }\n-\n-        // if the process has finished, and therefore had waitpid called,\n-        // and we kill it, then on unix we might ending up killing a\n-        // newer process that happens to have the same (re-used) id\n-        match self.exit_code {\n-            Some(..) => return Err(IoError {\n-                code: ERROR as uint,\n-                extra: 0,\n-                detail: Some(\"can't kill an exited process\".to_string()),\n-            }),\n-            None => {}\n-        }\n-\n-        // A successfully delivered signal that isn't 0 (just a poll for being\n-        // alive) is recorded for windows (see wait())\n-        match unsafe { killpid(self.pid, signum) } {\n-            Ok(()) if signum == 0 => Ok(()),\n-            Ok(()) => { self.exit_signal = Some(signum); Ok(()) }\n-            Err(e) => Err(e),\n-        }\n-    }\n-}\n-\n-impl Drop for Process {\n-    fn drop(&mut self) {\n-        free_handle(self.handle);\n-    }\n-}\n-\n-pub fn pipe() -> IoResult<(file::FileDesc, file::FileDesc)> {\n-    #[cfg(unix)] use libc::EMFILE as ERROR;\n-    #[cfg(windows)] use libc::WSAEMFILE as ERROR;\n-    struct Closer { fd: libc::c_int }\n-\n-    let os::Pipe { reader, writer } = match unsafe { os::pipe() } {\n-        Ok(p) => p,\n-        Err(io::IoError { detail, .. }) => return Err(IoError {\n-            code: ERROR as uint,\n-            extra: 0,\n-            detail: detail,\n-        })\n-    };\n-    let mut reader = Closer { fd: reader };\n-    let mut writer = Closer { fd: writer };\n-\n-    let native_reader = file::FileDesc::new(reader.fd, true);\n-    reader.fd = -1;\n-    let native_writer = file::FileDesc::new(writer.fd, true);\n-    writer.fd = -1;\n-    return Ok((native_reader, native_writer));\n-\n-    impl Drop for Closer {\n-        fn drop(&mut self) {\n-            if self.fd != -1 {\n-                let _ = unsafe { libc::close(self.fd) };\n-            }\n-        }\n-    }\n-}\n-\n-#[cfg(windows)]\n-unsafe fn killpid(pid: pid_t, signal: int) -> IoResult<()> {\n-    let handle = libc::OpenProcess(libc::PROCESS_TERMINATE |\n-                                   libc::PROCESS_QUERY_INFORMATION,\n-                                   libc::FALSE, pid as libc::DWORD);\n-    if handle.is_null() {\n-        return Err(super::last_error())\n-    }\n-    let ret = match signal {\n-        // test for existence on signal 0\n-        0 => {\n-            let mut status = 0;\n-            let ret = libc::GetExitCodeProcess(handle, &mut status);\n-            if ret == 0 {\n-                Err(super::last_error())\n-            } else if status != libc::STILL_ACTIVE {\n-                Err(IoError {\n-                    code: libc::ERROR_NOTHING_TO_TERMINATE as uint,\n-                    extra: 0,\n-                    detail: None,\n-                })\n-            } else {\n-                Ok(())\n-            }\n-        }\n-        15 | 9 => { // sigterm or sigkill\n-            let ret = libc::TerminateProcess(handle, 1);\n-            super::mkerr_winbool(ret)\n-        }\n-        _ => Err(IoError {\n-            code: libc::ERROR_CALL_NOT_IMPLEMENTED as uint,\n-            extra: 0,\n-            detail: Some(\"unsupported signal on windows\".to_string()),\n-        })\n-    };\n-    let _ = libc::CloseHandle(handle);\n-    return ret;\n-}\n-\n-#[cfg(not(windows))]\n-unsafe fn killpid(pid: pid_t, signal: int) -> IoResult<()> {\n-    let r = libc::funcs::posix88::signal::kill(pid, signal as c_int);\n-    super::mkerr_libc(r)\n-}\n-\n-struct SpawnProcessResult {\n-    pid: pid_t,\n-    handle: *mut (),\n-}\n-\n-#[cfg(windows)]\n-fn spawn_process_os(cfg: ProcessConfig,\n-                    in_fd: Option<file::FileDesc>,\n-                    out_fd: Option<file::FileDesc>,\n-                    err_fd: Option<file::FileDesc>)\n-                 -> IoResult<SpawnProcessResult> {\n-    use libc::types::os::arch::extra::{DWORD, HANDLE, STARTUPINFO};\n-    use libc::consts::os::extra::{\n-        TRUE, FALSE,\n-        STARTF_USESTDHANDLES,\n-        INVALID_HANDLE_VALUE,\n-        DUPLICATE_SAME_ACCESS\n-    };\n-    use libc::funcs::extra::kernel32::{\n-        GetCurrentProcess,\n-        DuplicateHandle,\n-        CloseHandle,\n-        CreateProcessW\n-    };\n-    use libc::funcs::extra::msvcrt::get_osfhandle;\n-\n-    use std::mem;\n-    use std::iter::Iterator;\n-    use std::str::StrPrelude;\n-\n-    if cfg.gid.is_some() || cfg.uid.is_some() {\n-        return Err(IoError {\n-            code: libc::ERROR_CALL_NOT_IMPLEMENTED as uint,\n-            extra: 0,\n-            detail: Some(\"unsupported gid/uid requested on windows\".to_string()),\n-        })\n-    }\n-\n-    // To have the spawning semantics of unix/windows stay the same, we need to\n-    // read the *child's* PATH if one is provided. See #15149 for more details.\n-    let program = cfg.env.and_then(|env| {\n-        for &(ref key, ref v) in env.iter() {\n-            if b\"PATH\" != key.as_bytes_no_nul() { continue }\n-\n-            // Split the value and test each path to see if the program exists.\n-            for path in os::split_paths(v.as_bytes_no_nul()).into_iter() {\n-                let path = path.join(cfg.program.as_bytes_no_nul())\n-                               .with_extension(os::consts::EXE_EXTENSION);\n-                if path.exists() {\n-                    return Some(path.to_c_str())\n-                }\n-            }\n-            break\n-        }\n-        None\n-    });\n-\n-    unsafe {\n-        let mut si = zeroed_startupinfo();\n-        si.cb = mem::size_of::<STARTUPINFO>() as DWORD;\n-        si.dwFlags = STARTF_USESTDHANDLES;\n-\n-        let cur_proc = GetCurrentProcess();\n-\n-        // Similarly to unix, we don't actually leave holes for the stdio file\n-        // descriptors, but rather open up /dev/null equivalents. These\n-        // equivalents are drawn from libuv's windows process spawning.\n-        let set_fd = |fd: &Option<file::FileDesc>, slot: &mut HANDLE,\n-                      is_stdin: bool| {\n-            match *fd {\n-                None => {\n-                    let access = if is_stdin {\n-                        libc::FILE_GENERIC_READ\n-                    } else {\n-                        libc::FILE_GENERIC_WRITE | libc::FILE_READ_ATTRIBUTES\n-                    };\n-                    let size = mem::size_of::<libc::SECURITY_ATTRIBUTES>();\n-                    let mut sa = libc::SECURITY_ATTRIBUTES {\n-                        nLength: size as libc::DWORD,\n-                        lpSecurityDescriptor: ptr::null_mut(),\n-                        bInheritHandle: 1,\n-                    };\n-                    let mut filename: Vec<u16> = \"NUL\".utf16_units().collect();\n-                    filename.push(0);\n-                    *slot = libc::CreateFileW(filename.as_ptr(),\n-                                              access,\n-                                              libc::FILE_SHARE_READ |\n-                                                  libc::FILE_SHARE_WRITE,\n-                                              &mut sa,\n-                                              libc::OPEN_EXISTING,\n-                                              0,\n-                                              ptr::null_mut());\n-                    if *slot == INVALID_HANDLE_VALUE {\n-                        return Err(super::last_error())\n-                    }\n-                }\n-                Some(ref fd) => {\n-                    let orig = get_osfhandle(fd.fd()) as HANDLE;\n-                    if orig == INVALID_HANDLE_VALUE {\n-                        return Err(super::last_error())\n-                    }\n-                    if DuplicateHandle(cur_proc, orig, cur_proc, slot,\n-                                       0, TRUE, DUPLICATE_SAME_ACCESS) == FALSE {\n-                        return Err(super::last_error())\n-                    }\n-                }\n-            }\n-            Ok(())\n-        };\n-\n-        try!(set_fd(&in_fd, &mut si.hStdInput, true));\n-        try!(set_fd(&out_fd, &mut si.hStdOutput, false));\n-        try!(set_fd(&err_fd, &mut si.hStdError, false));\n-\n-        let cmd_str = make_command_line(program.as_ref().unwrap_or(cfg.program),\n-                                        cfg.args);\n-        let mut pi = zeroed_process_information();\n-        let mut create_err = None;\n-\n-        // stolen from the libuv code.\n-        let mut flags = libc::CREATE_UNICODE_ENVIRONMENT;\n-        if cfg.detach {\n-            flags |= libc::DETACHED_PROCESS | libc::CREATE_NEW_PROCESS_GROUP;\n-        }\n-\n-        with_envp(cfg.env, |envp| {\n-            with_dirp(cfg.cwd, |dirp| {\n-                let mut cmd_str: Vec<u16> = cmd_str.as_slice().utf16_units().collect();\n-                cmd_str.push(0);\n-                let created = CreateProcessW(ptr::null(),\n-                                             cmd_str.as_mut_ptr(),\n-                                             ptr::null_mut(),\n-                                             ptr::null_mut(),\n-                                             TRUE,\n-                                             flags, envp, dirp,\n-                                             &mut si, &mut pi);\n-                if created == FALSE {\n-                    create_err = Some(super::last_error());\n-                }\n-            })\n-        });\n-\n-        assert!(CloseHandle(si.hStdInput) != 0);\n-        assert!(CloseHandle(si.hStdOutput) != 0);\n-        assert!(CloseHandle(si.hStdError) != 0);\n-\n-        match create_err {\n-            Some(err) => return Err(err),\n-            None => {}\n-        }\n-\n-        // We close the thread handle because we don't care about keeping the\n-        // thread id valid, and we aren't keeping the thread handle around to be\n-        // able to close it later. We don't close the process handle however\n-        // because std::we want the process id to stay valid at least until the\n-        // calling code closes the process handle.\n-        assert!(CloseHandle(pi.hThread) != 0);\n-\n-        Ok(SpawnProcessResult {\n-            pid: pi.dwProcessId as pid_t,\n-            handle: pi.hProcess as *mut ()\n-        })\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn zeroed_startupinfo() -> libc::types::os::arch::extra::STARTUPINFO {\n-    libc::types::os::arch::extra::STARTUPINFO {\n-        cb: 0,\n-        lpReserved: ptr::null_mut(),\n-        lpDesktop: ptr::null_mut(),\n-        lpTitle: ptr::null_mut(),\n-        dwX: 0,\n-        dwY: 0,\n-        dwXSize: 0,\n-        dwYSize: 0,\n-        dwXCountChars: 0,\n-        dwYCountCharts: 0,\n-        dwFillAttribute: 0,\n-        dwFlags: 0,\n-        wShowWindow: 0,\n-        cbReserved2: 0,\n-        lpReserved2: ptr::null_mut(),\n-        hStdInput: libc::INVALID_HANDLE_VALUE,\n-        hStdOutput: libc::INVALID_HANDLE_VALUE,\n-        hStdError: libc::INVALID_HANDLE_VALUE,\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn zeroed_process_information() -> libc::types::os::arch::extra::PROCESS_INFORMATION {\n-    libc::types::os::arch::extra::PROCESS_INFORMATION {\n-        hProcess: ptr::null_mut(),\n-        hThread: ptr::null_mut(),\n-        dwProcessId: 0,\n-        dwThreadId: 0\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn make_command_line(prog: &CString, args: &[CString]) -> String {\n-    let mut cmd = String::new();\n-    append_arg(&mut cmd, prog.as_str()\n-                             .expect(\"expected program name to be utf-8 encoded\"));\n-    for arg in args.iter() {\n-        cmd.push(' ');\n-        append_arg(&mut cmd, arg.as_str()\n-                                .expect(\"expected argument to be utf-8 encoded\"));\n-    }\n-    return cmd;\n-\n-    fn append_arg(cmd: &mut String, arg: &str) {\n-        // If an argument has 0 characters then we need to quote it to ensure\n-        // that it actually gets passed through on the command line or otherwise\n-        // it will be dropped entirely when parsed on the other end.\n-        let quote = arg.chars().any(|c| c == ' ' || c == '\\t') || arg.len() == 0;\n-        if quote {\n-            cmd.push('\"');\n-        }\n-        let argvec: Vec<char> = arg.chars().collect();\n-        for i in range(0u, argvec.len()) {\n-            append_char_at(cmd, argvec.as_slice(), i);\n-        }\n-        if quote {\n-            cmd.push('\"');\n-        }\n-    }\n-\n-    fn append_char_at(cmd: &mut String, arg: &[char], i: uint) {\n-        match arg[i] {\n-            '\"' => {\n-                // Escape quotes.\n-                cmd.push_str(\"\\\\\\\"\");\n-            }\n-            '\\\\' => {\n-                if backslash_run_ends_in_quote(arg, i) {\n-                    // Double all backslashes that are in runs before quotes.\n-                    cmd.push_str(\"\\\\\\\\\");\n-                } else {\n-                    // Pass other backslashes through unescaped.\n-                    cmd.push('\\\\');\n-                }\n-            }\n-            c => {\n-                cmd.push(c);\n-            }\n-        }\n-    }\n-\n-    fn backslash_run_ends_in_quote(s: &[char], mut i: uint) -> bool {\n-        while i < s.len() && s[i] == '\\\\' {\n-            i += 1;\n-        }\n-        return i < s.len() && s[i] == '\"';\n-    }\n-}\n-\n-#[cfg(unix)]\n-fn spawn_process_os(cfg: ProcessConfig,\n-                    in_fd: Option<file::FileDesc>,\n-                    out_fd: Option<file::FileDesc>,\n-                    err_fd: Option<file::FileDesc>)\n-                -> IoResult<SpawnProcessResult>\n-{\n-    use libc::funcs::posix88::unistd::{fork, dup2, close, chdir, execvp};\n-    use libc::funcs::bsd44::getdtablesize;\n-    use io::c;\n-\n-    mod rustrt {\n-        extern {\n-            pub fn rust_unset_sigprocmask();\n-        }\n-    }\n-\n-    #[cfg(target_os = \"macos\")]\n-    unsafe fn set_environ(envp: *const c_void) {\n-        extern { fn _NSGetEnviron() -> *mut *const c_void; }\n-\n-        *_NSGetEnviron() = envp;\n-    }\n-    #[cfg(not(target_os = \"macos\"))]\n-    unsafe fn set_environ(envp: *const c_void) {\n-        extern { static mut environ: *const c_void; }\n-        environ = envp;\n-    }\n-\n-    unsafe fn set_cloexec(fd: c_int) {\n-        let ret = c::ioctl(fd, c::FIOCLEX);\n-        assert_eq!(ret, 0);\n-    }\n-\n-    let dirp = cfg.cwd.map(|c| c.as_ptr()).unwrap_or(ptr::null());\n-\n-    let cfg = unsafe {\n-        mem::transmute::<ProcessConfig,ProcessConfig<'static>>(cfg)\n-    };\n-\n-    with_envp(cfg.env, proc(envp) {\n-        with_argv(cfg.program, cfg.args, proc(argv) unsafe {\n-            let (mut input, mut output) = try!(pipe());\n-\n-            // We may use this in the child, so perform allocations before the\n-            // fork\n-            let devnull = \"/dev/null\".to_c_str();\n-\n-            set_cloexec(output.fd());\n-\n-            let pid = fork();\n-            if pid < 0 {\n-                return Err(super::last_error())\n-            } else if pid > 0 {\n-                drop(output);\n-                let mut bytes = [0, ..4];\n-                return match input.inner_read(bytes) {\n-                    Ok(4) => {\n-                        let errno = (bytes[0] as i32 << 24) |\n-                                    (bytes[1] as i32 << 16) |\n-                                    (bytes[2] as i32 <<  8) |\n-                                    (bytes[3] as i32 <<  0);\n-\n-                        Err(IoError {\n-                            code: errno as uint,\n-                            detail: None,\n-                            extra: 0,\n-                        })\n-                    }\n-                    Err(..) => {\n-                        Ok(SpawnProcessResult {\n-                            pid: pid,\n-                            handle: ptr::null_mut()\n-                        })\n-                    }\n-                    Ok(..) => panic!(\"short read on the cloexec pipe\"),\n-                };\n-            }\n-            // And at this point we've reached a special time in the life of the\n-            // child. The child must now be considered hamstrung and unable to\n-            // do anything other than syscalls really. Consider the following\n-            // scenario:\n-            //\n-            //      1. Thread A of process 1 grabs the malloc() mutex\n-            //      2. Thread B of process 1 forks(), creating thread C\n-            //      3. Thread C of process 2 then attempts to malloc()\n-            //      4. The memory of process 2 is the same as the memory of\n-            //         process 1, so the mutex is locked.\n-            //\n-            // This situation looks a lot like deadlock, right? It turns out\n-            // that this is what pthread_atfork() takes care of, which is\n-            // presumably implemented across platforms. The first thing that\n-            // threads to *before* forking is to do things like grab the malloc\n-            // mutex, and then after the fork they unlock it.\n-            //\n-            // Despite this information, libnative's spawn has been witnessed to\n-            // deadlock on both OSX and FreeBSD. I'm not entirely sure why, but\n-            // all collected backtraces point at malloc/free traffic in the\n-            // child spawned process.\n-            //\n-            // For this reason, the block of code below should contain 0\n-            // invocations of either malloc of free (or their related friends).\n-            //\n-            // As an example of not having malloc/free traffic, we don't close\n-            // this file descriptor by dropping the FileDesc (which contains an\n-            // allocation). Instead we just close it manually. This will never\n-            // have the drop glue anyway because this code never returns (the\n-            // child will either exec() or invoke libc::exit)\n-            let _ = libc::close(input.fd());\n-\n-            fn fail(output: &mut file::FileDesc) -> ! {\n-                let errno = os::errno();\n-                let bytes = [\n-                    (errno >> 24) as u8,\n-                    (errno >> 16) as u8,\n-                    (errno >>  8) as u8,\n-                    (errno >>  0) as u8,\n-                ];\n-                assert!(output.inner_write(bytes).is_ok());\n-                unsafe { libc::_exit(1) }\n-            }\n-\n-            rustrt::rust_unset_sigprocmask();\n-\n-            // If a stdio file descriptor is set to be ignored (via a -1 file\n-            // descriptor), then we don't actually close it, but rather open\n-            // up /dev/null into that file descriptor. Otherwise, the first file\n-            // descriptor opened up in the child would be numbered as one of the\n-            // stdio file descriptors, which is likely to wreak havoc.\n-            let setup = |src: Option<file::FileDesc>, dst: c_int| {\n-                let src = match src {\n-                    None => {\n-                        let flags = if dst == libc::STDIN_FILENO {\n-                            libc::O_RDONLY\n-                        } else {\n-                            libc::O_RDWR\n-                        };\n-                        libc::open(devnull.as_ptr(), flags, 0)\n-                    }\n-                    Some(obj) => {\n-                        let fd = obj.fd();\n-                        // Leak the memory and the file descriptor. We're in the\n-                        // child now an all our resources are going to be\n-                        // cleaned up very soon\n-                        mem::forget(obj);\n-                        fd\n-                    }\n-                };\n-                src != -1 && retry(|| dup2(src, dst)) != -1\n-            };\n-\n-            if !setup(in_fd, libc::STDIN_FILENO) { fail(&mut output) }\n-            if !setup(out_fd, libc::STDOUT_FILENO) { fail(&mut output) }\n-            if !setup(err_fd, libc::STDERR_FILENO) { fail(&mut output) }\n-\n-            // close all other fds\n-            for fd in range(3, getdtablesize()).rev() {\n-                if fd != output.fd() {\n-                    let _ = close(fd as c_int);\n-                }\n-            }\n-\n-            match cfg.gid {\n-                Some(u) => {\n-                    if libc::setgid(u as libc::gid_t) != 0 {\n-                        fail(&mut output);\n-                    }\n-                }\n-                None => {}\n-            }\n-            match cfg.uid {\n-                Some(u) => {\n-                    // When dropping privileges from root, the `setgroups` call\n-                    // will remove any extraneous groups. If we don't call this,\n-                    // then even though our uid has dropped, we may still have\n-                    // groups that enable us to do super-user things. This will\n-                    // fail if we aren't root, so don't bother checking the\n-                    // return value, this is just done as an optimistic\n-                    // privilege dropping function.\n-                    extern {\n-                        fn setgroups(ngroups: libc::c_int,\n-                                     ptr: *const libc::c_void) -> libc::c_int;\n-                    }\n-                    let _ = setgroups(0, 0 as *const libc::c_void);\n-\n-                    if libc::setuid(u as libc::uid_t) != 0 {\n-                        fail(&mut output);\n-                    }\n-                }\n-                None => {}\n-            }\n-            if cfg.detach {\n-                // Don't check the error of setsid because it fails if we're the\n-                // process leader already. We just forked so it shouldn't return\n-                // error, but ignore it anyway.\n-                let _ = libc::setsid();\n-            }\n-            if !dirp.is_null() && chdir(dirp) == -1 {\n-                fail(&mut output);\n-            }\n-            if !envp.is_null() {\n-                set_environ(envp);\n-            }\n-            let _ = execvp(*argv, argv as *mut _);\n-            fail(&mut output);\n-        })\n-    })\n-}\n-\n-#[cfg(unix)]\n-fn with_argv<T>(prog: &CString, args: &[CString],\n-                cb: proc(*const *const libc::c_char) -> T) -> T {\n-    let mut ptrs: Vec<*const libc::c_char> = Vec::with_capacity(args.len()+1);\n-\n-    // Convert the CStrings into an array of pointers. Note: the\n-    // lifetime of the various CStrings involved is guaranteed to be\n-    // larger than the lifetime of our invocation of cb, but this is\n-    // technically unsafe as the callback could leak these pointers\n-    // out of our scope.\n-    ptrs.push(prog.as_ptr());\n-    ptrs.extend(args.iter().map(|tmp| tmp.as_ptr()));\n-\n-    // Add a terminating null pointer (required by libc).\n-    ptrs.push(ptr::null());\n-\n-    cb(ptrs.as_ptr())\n-}\n-\n-#[cfg(unix)]\n-fn with_envp<T>(env: Option<&[(&CString, &CString)]>,\n-                cb: proc(*const c_void) -> T) -> T {\n-    // On posixy systems we can pass a char** for envp, which is a\n-    // null-terminated array of \"k=v\\0\" strings. Since we must create\n-    // these strings locally, yet expose a raw pointer to them, we\n-    // create a temporary vector to own the CStrings that outlives the\n-    // call to cb.\n-    match env {\n-        Some(env) => {\n-            let mut tmps = Vec::with_capacity(env.len());\n-\n-            for pair in env.iter() {\n-                let mut kv = Vec::new();\n-                kv.push_all(pair.ref0().as_bytes_no_nul());\n-                kv.push('=' as u8);\n-                kv.push_all(pair.ref1().as_bytes()); // includes terminal \\0\n-                tmps.push(kv);\n-            }\n-\n-            // As with `with_argv`, this is unsafe, since cb could leak the pointers.\n-            let mut ptrs: Vec<*const libc::c_char> =\n-                tmps.iter()\n-                    .map(|tmp| tmp.as_ptr() as *const libc::c_char)\n-                    .collect();\n-            ptrs.push(ptr::null());\n-\n-            cb(ptrs.as_ptr() as *const c_void)\n-        }\n-        _ => cb(ptr::null())\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn with_envp<T>(env: Option<&[(&CString, &CString)]>, cb: |*mut c_void| -> T) -> T {\n-    // On Windows we pass an \"environment block\" which is not a char**, but\n-    // rather a concatenation of null-terminated k=v\\0 sequences, with a final\n-    // \\0 to terminate.\n-    match env {\n-        Some(env) => {\n-            let mut blk = Vec::new();\n-\n-            for pair in env.iter() {\n-                let kv = format!(\"{}={}\",\n-                                 pair.ref0().as_str().unwrap(),\n-                                 pair.ref1().as_str().unwrap());\n-                blk.extend(kv.as_slice().utf16_units());\n-                blk.push(0);\n-            }\n-\n-            blk.push(0);\n-\n-            cb(blk.as_mut_ptr() as *mut c_void)\n-        }\n-        _ => cb(ptr::null_mut())\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn with_dirp<T>(d: Option<&CString>, cb: |*const u16| -> T) -> T {\n-    match d {\n-      Some(dir) => {\n-          let dir_str = dir.as_str()\n-                           .expect(\"expected workingdirectory to be utf-8 encoded\");\n-          let mut dir_str: Vec<u16> = dir_str.utf16_units().collect();\n-          dir_str.push(0);\n-          cb(dir_str.as_ptr())\n-      },\n-      None => cb(ptr::null())\n-    }\n-}\n-\n-#[cfg(windows)]\n-fn free_handle(handle: *mut ()) {\n-    assert!(unsafe {\n-        libc::CloseHandle(mem::transmute(handle)) != 0\n-    })\n-}\n-\n-#[cfg(unix)]\n-fn free_handle(_handle: *mut ()) {\n-    // unix has no process handle object, just a pid\n-}\n-\n-#[cfg(unix)]\n-fn translate_status(status: c_int) -> rtio::ProcessExit {\n-    #![allow(non_snake_case)]\n-    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n-    mod imp {\n-        pub fn WIFEXITED(status: i32) -> bool { (status & 0xff) == 0 }\n-        pub fn WEXITSTATUS(status: i32) -> i32 { (status >> 8) & 0xff }\n-        pub fn WTERMSIG(status: i32) -> i32 { status & 0x7f }\n-    }\n-\n-    #[cfg(any(target_os = \"macos\",\n-              target_os = \"ios\",\n-              target_os = \"freebsd\",\n-              target_os = \"dragonfly\"))]\n-    mod imp {\n-        pub fn WIFEXITED(status: i32) -> bool { (status & 0x7f) == 0 }\n-        pub fn WEXITSTATUS(status: i32) -> i32 { status >> 8 }\n-        pub fn WTERMSIG(status: i32) -> i32 { status & 0o177 }\n-    }\n-\n-    if imp::WIFEXITED(status) {\n-        rtio::ExitStatus(imp::WEXITSTATUS(status) as int)\n-    } else {\n-        rtio::ExitSignal(imp::WTERMSIG(status) as int)\n-    }\n-}\n-\n-/**\n- * Waits for a process to exit and returns the exit code, failing\n- * if there is no process with the specified id.\n- *\n- * Note that this is private to avoid race conditions on unix where if\n- * a user calls waitpid(some_process.get_id()) then some_process.finish()\n- * and some_process.destroy() and some_process.finalize() will then either\n- * operate on a none-existent process or, even worse, on a newer process\n- * with the same id.\n- */\n-#[cfg(windows)]\n-fn waitpid(pid: pid_t, deadline: u64) -> IoResult<rtio::ProcessExit> {\n-    use libc::types::os::arch::extra::DWORD;\n-    use libc::consts::os::extra::{\n-        SYNCHRONIZE,\n-        PROCESS_QUERY_INFORMATION,\n-        FALSE,\n-        STILL_ACTIVE,\n-        INFINITE,\n-        WAIT_TIMEOUT,\n-        WAIT_OBJECT_0,\n-    };\n-    use libc::funcs::extra::kernel32::{\n-        OpenProcess,\n-        GetExitCodeProcess,\n-        CloseHandle,\n-        WaitForSingleObject,\n-    };\n-\n-    unsafe {\n-        let process = OpenProcess(SYNCHRONIZE | PROCESS_QUERY_INFORMATION,\n-                                  FALSE,\n-                                  pid as DWORD);\n-        if process.is_null() {\n-            return Err(super::last_error())\n-        }\n-\n-        loop {\n-            let mut status = 0;\n-            if GetExitCodeProcess(process, &mut status) == FALSE {\n-                let err = Err(super::last_error());\n-                assert!(CloseHandle(process) != 0);\n-                return err;\n-            }\n-            if status != STILL_ACTIVE {\n-                assert!(CloseHandle(process) != 0);\n-                return Ok(rtio::ExitStatus(status as int));\n-            }\n-            let interval = if deadline == 0 {\n-                INFINITE\n-            } else {\n-                let now = ::io::timer::now();\n-                if deadline < now {0} else {(deadline - now) as u32}\n-            };\n-            match WaitForSingleObject(process, interval) {\n-                WAIT_OBJECT_0 => {}\n-                WAIT_TIMEOUT => {\n-                    assert!(CloseHandle(process) != 0);\n-                    return Err(util::timeout(\"process wait timed out\"))\n-                }\n-                _ => {\n-                    let err = Err(super::last_error());\n-                    assert!(CloseHandle(process) != 0);\n-                    return err\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-#[cfg(unix)]\n-fn waitpid(pid: pid_t, deadline: u64) -> IoResult<rtio::ProcessExit> {\n-    use std::cmp;\n-    use std::comm;\n-\n-    static mut WRITE_FD: libc::c_int = 0;\n-\n-    let mut status = 0 as c_int;\n-    if deadline == 0 {\n-        return match retry(|| unsafe { c::waitpid(pid, &mut status, 0) }) {\n-            -1 => panic!(\"unknown waitpid error: {}\", super::last_error().code),\n-            _ => Ok(translate_status(status)),\n-        }\n-    }\n-\n-    // On unix, wait() and its friends have no timeout parameters, so there is\n-    // no way to time out a thread in wait(). From some googling and some\n-    // thinking, it appears that there are a few ways to handle timeouts in\n-    // wait(), but the only real reasonable one for a multi-threaded program is\n-    // to listen for SIGCHLD.\n-    //\n-    // With this in mind, the waiting mechanism with a timeout barely uses\n-    // waitpid() at all. There are a few times that waitpid() is invoked with\n-    // WNOHANG, but otherwise all the necessary blocking is done by waiting for\n-    // a SIGCHLD to arrive (and that blocking has a timeout). Note, however,\n-    // that waitpid() is still used to actually reap the child.\n-    //\n-    // Signal handling is super tricky in general, and this is no exception. Due\n-    // to the async nature of SIGCHLD, we use the self-pipe trick to transmit\n-    // data out of the signal handler to the rest of the application. The first\n-    // idea would be to have each thread waiting with a timeout to read this\n-    // output file descriptor, but a write() is akin to a signal(), not a\n-    // broadcast(), so it would only wake up one thread, and possibly the wrong\n-    // thread. Hence a helper thread is used.\n-    //\n-    // The helper thread here is responsible for farming requests for a\n-    // waitpid() with a timeout, and then processing all of the wait requests.\n-    // By guaranteeing that only this helper thread is reading half of the\n-    // self-pipe, we're sure that we'll never lose a SIGCHLD. This helper thread\n-    // is also responsible for select() to wait for incoming messages or\n-    // incoming SIGCHLD messages, along with passing an appropriate timeout to\n-    // select() to wake things up as necessary.\n-    //\n-    // The ordering of the following statements is also very purposeful. First,\n-    // we must be guaranteed that the helper thread is booted and available to\n-    // receive SIGCHLD signals, and then we must also ensure that we do a\n-    // nonblocking waitpid() at least once before we go ask the sigchld helper.\n-    // This prevents the race where the child exits, we boot the helper, and\n-    // then we ask for the child's exit status (never seeing a sigchld).\n-    //\n-    // The actual communication between the helper thread and this thread is\n-    // quite simple, just a channel moving data around.\n-\n-    HELPER.boot(register_sigchld, waitpid_helper);\n-\n-    match waitpid_nowait(pid) {\n-        Some(ret) => return Ok(ret),\n-        None => {}\n-    }\n-\n-    let (tx, rx) = channel();\n-    HELPER.send(NewChild(pid, tx, deadline));\n-    return match rx.recv_opt() {\n-        Ok(e) => Ok(e),\n-        Err(()) => Err(util::timeout(\"wait timed out\")),\n-    };\n-\n-    // Register a new SIGCHLD handler, returning the reading half of the\n-    // self-pipe plus the old handler registered (return value of sigaction).\n-    //\n-    // Be sure to set up the self-pipe first because as soon as we register a\n-    // handler we're going to start receiving signals.\n-    fn register_sigchld() -> (libc::c_int, c::sigaction) {\n-        unsafe {\n-            let mut pipes = [0, ..2];\n-            assert_eq!(libc::pipe(pipes.as_mut_ptr()), 0);\n-            util::set_nonblocking(pipes[0], true).ok().unwrap();\n-            util::set_nonblocking(pipes[1], true).ok().unwrap();\n-            WRITE_FD = pipes[1];\n-\n-            let mut old: c::sigaction = mem::zeroed();\n-            let mut new: c::sigaction = mem::zeroed();\n-            new.sa_handler = sigchld_handler;\n-            new.sa_flags = c::SA_NOCLDSTOP;\n-            assert_eq!(c::sigaction(c::SIGCHLD, &new, &mut old), 0);\n-            (pipes[0], old)\n-        }\n-    }\n-\n-    // Helper thread for processing SIGCHLD messages\n-    fn waitpid_helper(input: libc::c_int,\n-                      messages: Receiver<Req>,\n-                      (read_fd, old): (libc::c_int, c::sigaction)) {\n-        util::set_nonblocking(input, true).ok().unwrap();\n-        let mut set: c::fd_set = unsafe { mem::zeroed() };\n-        let mut tv: libc::timeval;\n-        let mut active = Vec::<(libc::pid_t, Sender<rtio::ProcessExit>, u64)>::new();\n-        let max = cmp::max(input, read_fd) + 1;\n-\n-        'outer: loop {\n-            // Figure out the timeout of our syscall-to-happen. If we're waiting\n-            // for some processes, then they'll have a timeout, otherwise we\n-            // wait indefinitely for a message to arrive.\n-            //\n-            // FIXME: sure would be nice to not have to scan the entire array\n-            let min = active.iter().map(|a| *a.ref2()).enumerate().min_by(|p| {\n-                p.val1()\n-            });\n-            let (p, idx) = match min {\n-                Some((idx, deadline)) => {\n-                    let now = ::io::timer::now();\n-                    let ms = if now < deadline {deadline - now} else {0};\n-                    tv = util::ms_to_timeval(ms);\n-                    (&mut tv as *mut _, idx)\n-                }\n-                None => (ptr::null_mut(), -1),\n-            };\n-\n-            // Wait for something to happen\n-            c::fd_set(&mut set, input);\n-            c::fd_set(&mut set, read_fd);\n-            match unsafe { c::select(max, &mut set, ptr::null_mut(),\n-                                     ptr::null_mut(), p) } {\n-                // interrupted, retry\n-                -1 if os::errno() == libc::EINTR as int => continue,\n-\n-                // We read something, break out and process\n-                1 | 2 => {}\n-\n-                // Timeout, the pending request is removed\n-                0 => {\n-                    drop(active.remove(idx));\n-                    continue\n-                }\n-\n-                n => panic!(\"error in select {} ({})\", os::errno(), n),\n-            }\n-\n-            // Process any pending messages\n-            if drain(input) {\n-                loop {\n-                    match messages.try_recv() {\n-                        Ok(NewChild(pid, tx, deadline)) => {\n-                            active.push((pid, tx, deadline));\n-                        }\n-                        Err(comm::Disconnected) => {\n-                            assert!(active.len() == 0);\n-                            break 'outer;\n-                        }\n-                        Err(comm::Empty) => break,\n-                    }\n-                }\n-            }\n-\n-            // If a child exited (somehow received SIGCHLD), then poll all\n-            // children to see if any of them exited.\n-            //\n-            // We also attempt to be responsible netizens when dealing with\n-            // SIGCHLD by invoking any previous SIGCHLD handler instead of just\n-            // ignoring any previous SIGCHLD handler. Note that we don't provide\n-            // a 1:1 mapping of our handler invocations to the previous handler\n-            // invocations because we drain the `read_fd` entirely. This is\n-            // probably OK because the kernel is already allowed to coalesce\n-            // simultaneous signals, we're just doing some extra coalescing.\n-            //\n-            // Another point of note is that this likely runs the signal handler\n-            // on a different thread than the one that received the signal. I\n-            // *think* this is ok at this time.\n-            //\n-            // The main reason for doing this is to allow stdtest to run native\n-            // tests as well. Both libgreen and libnative are running around\n-            // with process timeouts, but libgreen should get there first\n-            // (currently libuv doesn't handle old signal handlers).\n-            if drain(read_fd) {\n-                let i: uint = unsafe { mem::transmute(old.sa_handler) };\n-                if i != 0 {\n-                    assert!(old.sa_flags & c::SA_SIGINFO == 0);\n-                    (old.sa_handler)(c::SIGCHLD);\n-                }\n-\n-                // FIXME: sure would be nice to not have to scan the entire\n-                //        array...\n-                active.retain(|&(pid, ref tx, _)| {\n-                    match waitpid_nowait(pid) {\n-                        Some(msg) => { tx.send(msg); false }\n-                        None => true,\n-                    }\n-                });\n-            }\n-        }\n-\n-        // Once this helper thread is done, we re-register the old sigchld\n-        // handler and close our intermediate file descriptors.\n-        unsafe {\n-            assert_eq!(c::sigaction(c::SIGCHLD, &old, ptr::null_mut()), 0);\n-            let _ = libc::close(read_fd);\n-            let _ = libc::close(WRITE_FD);\n-            WRITE_FD = -1;\n-        }\n-    }\n-\n-    // Drain all pending data from the file descriptor, returning if any data\n-    // could be drained. This requires that the file descriptor is in\n-    // nonblocking mode.\n-    fn drain(fd: libc::c_int) -> bool {\n-        let mut ret = false;\n-        loop {\n-            let mut buf = [0u8, ..1];\n-            match unsafe {\n-                libc::read(fd, buf.as_mut_ptr() as *mut libc::c_void,\n-                           buf.len() as libc::size_t)\n-            } {\n-                n if n > 0 => { ret = true; }\n-                0 => return true,\n-                -1 if util::wouldblock() => return ret,\n-                n => panic!(\"bad read {} ({})\", os::last_os_error(), n),\n-            }\n-        }\n-    }\n-\n-    // Signal handler for SIGCHLD signals, must be async-signal-safe!\n-    //\n-    // This function will write to the writing half of the \"self pipe\" to wake\n-    // up the helper thread if it's waiting. Note that this write must be\n-    // nonblocking because if it blocks and the reader is the thread we\n-    // interrupted, then we'll deadlock.\n-    //\n-    // When writing, if the write returns EWOULDBLOCK then we choose to ignore\n-    // it. At that point we're guaranteed that there's something in the pipe\n-    // which will wake up the other end at some point, so we just allow this\n-    // signal to be coalesced with the pending signals on the pipe.\n-    extern fn sigchld_handler(_signum: libc::c_int) {\n-        let msg = 1i;\n-        match unsafe {\n-            libc::write(WRITE_FD, &msg as *const _ as *const libc::c_void, 1)\n-        } {\n-            1 => {}\n-            -1 if util::wouldblock() => {} // see above comments\n-            n => panic!(\"bad error on write fd: {} {}\", n, os::errno()),\n-        }\n-    }\n-}\n-\n-fn waitpid_nowait(pid: pid_t) -> Option<rtio::ProcessExit> {\n-    return waitpid_os(pid);\n-\n-    // This code path isn't necessary on windows\n-    #[cfg(windows)]\n-    fn waitpid_os(_pid: pid_t) -> Option<rtio::ProcessExit> { None }\n-\n-    #[cfg(unix)]\n-    fn waitpid_os(pid: pid_t) -> Option<rtio::ProcessExit> {\n-        let mut status = 0 as c_int;\n-        match retry(|| unsafe {\n-            c::waitpid(pid, &mut status, c::WNOHANG)\n-        }) {\n-            n if n == pid => Some(translate_status(status)),\n-            0 => None,\n-            n => panic!(\"unknown waitpid error `{}`: {}\", n,\n-                       super::last_error().code),\n-        }\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-\n-    #[test] #[cfg(windows)]\n-    fn test_make_command_line() {\n-        use std::str;\n-        use std::c_str::CString;\n-        use super::make_command_line;\n-\n-        fn test_wrapper(prog: &str, args: &[&str]) -> String {\n-            make_command_line(&prog.to_c_str(),\n-                              args.iter()\n-                                  .map(|a| a.to_c_str())\n-                                  .collect::<Vec<CString>>()\n-                                  .as_slice())\n-        }\n-\n-        assert_eq!(\n-            test_wrapper(\"prog\", [\"aaa\", \"bbb\", \"ccc\"]),\n-            \"prog aaa bbb ccc\".to_string()\n-        );\n-\n-        assert_eq!(\n-            test_wrapper(\"C:\\\\Program Files\\\\blah\\\\blah.exe\", [\"aaa\"]),\n-            \"\\\"C:\\\\Program Files\\\\blah\\\\blah.exe\\\" aaa\".to_string()\n-        );\n-        assert_eq!(\n-            test_wrapper(\"C:\\\\Program Files\\\\test\", [\"aa\\\"bb\"]),\n-            \"\\\"C:\\\\Program Files\\\\test\\\" aa\\\\\\\"bb\".to_string()\n-        );\n-        assert_eq!(\n-            test_wrapper(\"echo\", [\"a b c\"]),\n-            \"echo \\\"a b c\\\"\".to_string()\n-        );\n-        assert_eq!(\n-            test_wrapper(\"\\u03c0\\u042f\\u97f3\\u00e6\\u221e\", []),\n-            \"\\u03c0\\u042f\\u97f3\\u00e6\\u221e\".to_string()\n-        );\n-    }\n-}"}, {"sha": "ea1136dfe3c43ff3d4bde72bfc29b89d55709ebc", "filename": "src/libnative/lib.rs", "status": "removed", "additions": 0, "deletions": 155, "changes": 155, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Flib.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,155 +0,0 @@\n-// Copyright 2013-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! The native I/O and threading crate\n-//!\n-//! This crate contains an implementation of 1:1 scheduling for a \"native\"\n-//! runtime. In addition, all I/O provided by this crate is the thread blocking\n-//! version of I/O.\n-//!\n-//! # Starting with libnative\n-//!\n-//! ```rust\n-//! extern crate native;\n-//!\n-//! #[start]\n-//! fn start(argc: int, argv: *const *const u8) -> int {\n-//!     native::start(argc, argv, main)\n-//! }\n-//!\n-//! fn main() {\n-//!     // this code is running on the main OS thread\n-//! }\n-//! ```\n-//!\n-//! # Force spawning a native task\n-//!\n-//! ```rust\n-//! extern crate native;\n-//!\n-//! use std::task::TaskBuilder;\n-//! use native::NativeTaskBuilder;\n-//!\n-//! fn main() {\n-//!     // We're not sure whether this main function is run in 1:1 or M:N mode.\n-//!\n-//!     TaskBuilder::new().native().spawn(proc() {\n-//!         // this code is guaranteed to be run on a native thread\n-//!     });\n-//! }\n-//! ```\n-\n-#![crate_name = \"native\"]\n-#![experimental]\n-#![license = \"MIT/ASL2\"]\n-#![crate_type = \"rlib\"]\n-#![crate_type = \"dylib\"]\n-#![doc(html_logo_url = \"http://www.rust-lang.org/logos/rust-logo-128x128-blk-v2.png\",\n-       html_favicon_url = \"http://www.rust-lang.org/favicon.ico\",\n-       html_root_url = \"http://doc.rust-lang.org/nightly/\")]\n-\n-#![deny(unused_results, unused_must_use)]\n-#![allow(non_camel_case_types)]\n-#![allow(unknown_features)]\n-#![feature(default_type_params, lang_items, slicing_syntax, globs)]\n-\n-// NB this crate explicitly does *not* allow glob imports, please seriously\n-//    consider whether they're needed before adding that feature here (the\n-//    answer is that you don't need them)\n-#![feature(macro_rules, unsafe_destructor, default_type_params)]\n-\n-extern crate alloc;\n-extern crate libc;\n-\n-use std::os;\n-use std::rt;\n-use std::str;\n-\n-pub use task::NativeTaskBuilder;\n-\n-pub mod task;\n-\n-#[cfg(any(windows, android))]\n-static OS_DEFAULT_STACK_ESTIMATE: uint = 1 << 20;\n-#[cfg(all(unix, not(android)))]\n-static OS_DEFAULT_STACK_ESTIMATE: uint = 2 * (1 << 20);\n-\n-#[lang = \"start\"]\n-#[cfg(not(test))]\n-pub fn lang_start(main: *const u8, argc: int, argv: *const *const u8) -> int {\n-    use std::mem;\n-    start(argc, argv, proc() {\n-        let main: extern \"Rust\" fn() = unsafe { mem::transmute(main) };\n-        main();\n-    })\n-}\n-\n-/// Executes the given procedure after initializing the runtime with the given\n-/// argc/argv.\n-///\n-/// This procedure is guaranteed to run on the thread calling this function, but\n-/// the stack bounds for this rust task will *not* be set. Care must be taken\n-/// for this function to not overflow its stack.\n-///\n-/// This function will only return once *all* native threads in the system have\n-/// exited.\n-pub fn start(argc: int, argv: *const *const u8, main: proc()) -> int {\n-    let something_around_the_top_of_the_stack = 1;\n-    let addr = &something_around_the_top_of_the_stack as *const int;\n-    let my_stack_top = addr as uint;\n-\n-    // FIXME #11359 we just assume that this thread has a stack of a\n-    // certain size, and estimate that there's at most 20KB of stack\n-    // frames above our current position.\n-    let my_stack_bottom = my_stack_top + 20000 - OS_DEFAULT_STACK_ESTIMATE;\n-\n-    // When using libgreen, one of the first things that we do is to turn off\n-    // the SIGPIPE signal (set it to ignore). By default, some platforms will\n-    // send a *signal* when a EPIPE error would otherwise be delivered. This\n-    // runtime doesn't install a SIGPIPE handler, causing it to kill the\n-    // program, which isn't exactly what we want!\n-    //\n-    // Hence, we set SIGPIPE to ignore when the program starts up in order to\n-    // prevent this problem.\n-    #[cfg(windows)] fn ignore_sigpipe() {}\n-    #[cfg(unix)] fn ignore_sigpipe() {\n-        use libc;\n-        use libc::funcs::posix01::signal::signal;\n-        unsafe {\n-            assert!(signal(libc::SIGPIPE, libc::SIG_IGN) != -1);\n-        }\n-    }\n-    ignore_sigpipe();\n-\n-    rt::init(argc, argv);\n-    let mut exit_code = None;\n-    let mut main = Some(main);\n-    let mut task = task::new((my_stack_bottom, my_stack_top),\n-                             rt::thread::main_guard_page());\n-    task.name = Some(str::Slice(\"<main>\"));\n-    drop(task.run(|| {\n-        unsafe {\n-            rt::stack::record_os_managed_stack_bounds(my_stack_bottom, my_stack_top);\n-        }\n-        exit_code = Some(run(main.take().unwrap()));\n-    }).destroy());\n-    unsafe { rt::cleanup(); }\n-    // If the exit code wasn't set, then the task block must have panicked.\n-    return exit_code.unwrap_or(rt::DEFAULT_ERROR_CODE);\n-}\n-\n-/// Executes a procedure on the current thread in a Rust task context.\n-///\n-/// This function has all of the same details as `start` except for a different\n-/// number of arguments.\n-pub fn run(main: proc()) -> int {\n-    main();\n-    os::get_exit_status()\n-}"}, {"sha": "6d640b61b18d3a6dd0c79014d7ecbe6f0ebe6918", "filename": "src/libnative/task.rs", "status": "removed", "additions": 0, "deletions": 376, "changes": 376, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibnative%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibnative%2Ftask.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,376 +0,0 @@\n-// Copyright 2013-2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! Tasks implemented on top of OS threads\n-//!\n-//! This module contains the implementation of the 1:1 threading module required\n-//! by rust tasks. This implements the necessary API traits laid out by std::rt\n-//! in order to spawn new tasks and deschedule the current task.\n-\n-use std::any::Any;\n-use std::mem;\n-use std::rt::bookkeeping;\n-use std::rt::local::Local;\n-use std::rt::mutex::NativeMutex;\n-use std::rt::stack;\n-use std::rt::task::{Task, BlockedTask, TaskOpts};\n-use std::rt::thread::Thread;\n-use std::rt;\n-\n-use std::task::{TaskBuilder, Spawner};\n-\n-/// Creates a new Task which is ready to execute as a 1:1 task.\n-pub fn new(stack_bounds: (uint, uint), stack_guard: uint) -> Box<Task> {\n-    let mut task = box Task::new();\n-    let mut ops = ops();\n-    ops.stack_bounds = stack_bounds;\n-    ops.stack_guard = stack_guard;\n-    task.put_runtime(ops);\n-    return task;\n-}\n-\n-fn ops() -> Box<Ops> {\n-    box Ops {\n-        lock: unsafe { NativeMutex::new() },\n-        awoken: false,\n-        // these *should* get overwritten\n-        stack_bounds: (0, 0),\n-        stack_guard: 0\n-    }\n-}\n-\n-/// A spawner for native tasks\n-pub struct NativeSpawner;\n-\n-impl Spawner for NativeSpawner {\n-    fn spawn(self, opts: TaskOpts, f: proc():Send) {\n-        let TaskOpts { name, stack_size, on_exit } = opts;\n-\n-        let mut task = box Task::new();\n-        task.name = name;\n-        task.death.on_exit = on_exit;\n-\n-        let stack = stack_size.unwrap_or(rt::min_stack());\n-        let task = task;\n-        let ops = ops();\n-\n-        // Note that this increment must happen *before* the spawn in order to\n-        // guarantee that if this task exits it will always end up waiting for\n-        // the spawned task to exit.\n-        let token = bookkeeping::increment();\n-\n-        // Spawning a new OS thread guarantees that __morestack will never get\n-        // triggered, but we must manually set up the actual stack bounds once\n-        // this function starts executing. This raises the lower limit by a bit\n-        // because by the time that this function is executing we've already\n-        // consumed at least a little bit of stack (we don't know the exact byte\n-        // address at which our stack started).\n-        Thread::spawn_stack(stack, proc() {\n-            let something_around_the_top_of_the_stack = 1;\n-            let addr = &something_around_the_top_of_the_stack as *const int;\n-            let my_stack = addr as uint;\n-            unsafe {\n-                stack::record_os_managed_stack_bounds(my_stack - stack + 1024,\n-                                                      my_stack);\n-            }\n-            let mut ops = ops;\n-            ops.stack_guard = rt::thread::current_guard_page();\n-            ops.stack_bounds = (my_stack - stack + 1024, my_stack);\n-\n-            let mut f = Some(f);\n-            let mut task = task;\n-            task.put_runtime(ops);\n-            drop(task.run(|| { f.take().unwrap()() }).destroy());\n-            drop(token);\n-        })\n-    }\n-}\n-\n-/// An extension trait adding a `native` configuration method to `TaskBuilder`.\n-pub trait NativeTaskBuilder {\n-    fn native(self) -> TaskBuilder<NativeSpawner>;\n-}\n-\n-impl<S: Spawner> NativeTaskBuilder for TaskBuilder<S> {\n-    fn native(self) -> TaskBuilder<NativeSpawner> {\n-        self.spawner(NativeSpawner)\n-    }\n-}\n-\n-// This structure is the glue between channels and the 1:1 scheduling mode. This\n-// structure is allocated once per task.\n-struct Ops {\n-    lock: NativeMutex,       // native synchronization\n-    awoken: bool,      // used to prevent spurious wakeups\n-\n-    // This field holds the known bounds of the stack in (lo, hi) form. Not all\n-    // native tasks necessarily know their precise bounds, hence this is\n-    // optional.\n-    stack_bounds: (uint, uint),\n-\n-    stack_guard: uint\n-}\n-\n-impl rt::Runtime for Ops {\n-    fn yield_now(self: Box<Ops>, mut cur_task: Box<Task>) {\n-        // put the task back in TLS and then invoke the OS thread yield\n-        cur_task.put_runtime(self);\n-        Local::put(cur_task);\n-        Thread::yield_now();\n-    }\n-\n-    fn maybe_yield(self: Box<Ops>, mut cur_task: Box<Task>) {\n-        // just put the task back in TLS, on OS threads we never need to\n-        // opportunistically yield b/c the OS will do that for us (preemption)\n-        cur_task.put_runtime(self);\n-        Local::put(cur_task);\n-    }\n-\n-    fn wrap(self: Box<Ops>) -> Box<Any+'static> {\n-        self as Box<Any+'static>\n-    }\n-\n-    fn stack_bounds(&self) -> (uint, uint) { self.stack_bounds }\n-\n-    fn stack_guard(&self) -> Option<uint> {\n-        if self.stack_guard != 0 {\n-            Some(self.stack_guard)\n-        } else {\n-            None\n-        }\n-    }\n-\n-    fn can_block(&self) -> bool { true }\n-\n-    // This function gets a little interesting. There are a few safety and\n-    // ownership violations going on here, but this is all done in the name of\n-    // shared state. Additionally, all of the violations are protected with a\n-    // mutex, so in theory there are no races.\n-    //\n-    // The first thing we need to do is to get a pointer to the task's internal\n-    // mutex. This address will not be changing (because the task is allocated\n-    // on the heap). We must have this handle separately because the task will\n-    // have its ownership transferred to the given closure. We're guaranteed,\n-    // however, that this memory will remain valid because *this* is the current\n-    // task's execution thread.\n-    //\n-    // The next weird part is where ownership of the task actually goes. We\n-    // relinquish it to the `f` blocking function, but upon returning this\n-    // function needs to replace the task back in TLS. There is no communication\n-    // from the wakeup thread back to this thread about the task pointer, and\n-    // there's really no need to. In order to get around this, we cast the task\n-    // to a `uint` which is then used at the end of this function to cast back\n-    // to a `Box<Task>` object. Naturally, this looks like it violates\n-    // ownership semantics in that there may be two `Box<Task>` objects.\n-    //\n-    // The fun part is that the wakeup half of this implementation knows to\n-    // \"forget\" the task on the other end. This means that the awakening half of\n-    // things silently relinquishes ownership back to this thread, but not in a\n-    // way that the compiler can understand. The task's memory is always valid\n-    // for both tasks because these operations are all done inside of a mutex.\n-    //\n-    // You'll also find that if blocking fails (the `f` function hands the\n-    // BlockedTask back to us), we will `mem::forget` the handles. The\n-    // reasoning for this is the same logic as above in that the task silently\n-    // transfers ownership via the `uint`, not through normal compiler\n-    // semantics.\n-    //\n-    // On a mildly unrelated note, it should also be pointed out that OS\n-    // condition variables are susceptible to spurious wakeups, which we need to\n-    // be ready for. In order to accommodate for this fact, we have an extra\n-    // `awoken` field which indicates whether we were actually woken up via some\n-    // invocation of `reawaken`. This flag is only ever accessed inside the\n-    // lock, so there's no need to make it atomic.\n-    fn deschedule(mut self: Box<Ops>,\n-                  times: uint,\n-                  mut cur_task: Box<Task>,\n-                  f: |BlockedTask| -> Result<(), BlockedTask>) {\n-        let me = &mut *self as *mut Ops;\n-        cur_task.put_runtime(self);\n-\n-        unsafe {\n-            let cur_task_dupe = &mut *cur_task as *mut Task;\n-            let task = BlockedTask::block(cur_task);\n-\n-            if times == 1 {\n-                let guard = (*me).lock.lock();\n-                (*me).awoken = false;\n-                match f(task) {\n-                    Ok(()) => {\n-                        while !(*me).awoken {\n-                            guard.wait();\n-                        }\n-                    }\n-                    Err(task) => { mem::forget(task.wake()); }\n-                }\n-            } else {\n-                let iter = task.make_selectable(times);\n-                let guard = (*me).lock.lock();\n-                (*me).awoken = false;\n-\n-                // Apply the given closure to all of the \"selectable tasks\",\n-                // bailing on the first one that produces an error. Note that\n-                // care must be taken such that when an error is occurred, we\n-                // may not own the task, so we may still have to wait for the\n-                // task to become available. In other words, if task.wake()\n-                // returns `None`, then someone else has ownership and we must\n-                // wait for their signal.\n-                match iter.map(f).filter_map(|a| a.err()).next() {\n-                    None => {}\n-                    Some(task) => {\n-                        match task.wake() {\n-                            Some(task) => {\n-                                mem::forget(task);\n-                                (*me).awoken = true;\n-                            }\n-                            None => {}\n-                        }\n-                    }\n-                }\n-                while !(*me).awoken {\n-                    guard.wait();\n-                }\n-            }\n-            // re-acquire ownership of the task\n-            cur_task = mem::transmute(cur_task_dupe);\n-        }\n-\n-        // put the task back in TLS, and everything is as it once was.\n-        Local::put(cur_task);\n-    }\n-\n-    // See the comments on `deschedule` for why the task is forgotten here, and\n-    // why it's valid to do so.\n-    fn reawaken(mut self: Box<Ops>, mut to_wake: Box<Task>) {\n-        unsafe {\n-            let me = &mut *self as *mut Ops;\n-            to_wake.put_runtime(self);\n-            mem::forget(to_wake);\n-            let guard = (*me).lock.lock();\n-            (*me).awoken = true;\n-            guard.signal();\n-        }\n-    }\n-\n-    fn spawn_sibling(self: Box<Ops>,\n-                     mut cur_task: Box<Task>,\n-                     opts: TaskOpts,\n-                     f: proc():Send) {\n-        cur_task.put_runtime(self);\n-        Local::put(cur_task);\n-\n-        NativeSpawner.spawn(opts, f);\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use std::rt::local::Local;\n-    use std::rt::task::{Task, TaskOpts};\n-    use std::task;\n-    use std::task::{TaskBuilder, Spawner};\n-\n-    use super::{Ops, NativeTaskBuilder, NativeSpawner};\n-\n-    #[test]\n-    fn smoke() {\n-        let (tx, rx) = channel();\n-        spawn(proc() {\n-            tx.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn smoke_panic() {\n-        let (tx, rx) = channel::<()>();\n-        spawn(proc() {\n-            let _tx = tx;\n-            panic!()\n-        });\n-        assert_eq!(rx.recv_opt(), Err(()));\n-    }\n-\n-    #[test]\n-    fn smoke_opts() {\n-        let mut opts = TaskOpts::new();\n-        opts.name = Some(\"test\".into_maybe_owned());\n-        opts.stack_size = Some(20 * 4096);\n-        let (tx, rx) = channel();\n-        opts.on_exit = Some(proc(r) tx.send(r));\n-        NativeSpawner.spawn(opts, proc() {});\n-        assert!(rx.recv().is_ok());\n-    }\n-\n-    #[test]\n-    fn smoke_opts_panic() {\n-        let mut opts = TaskOpts::new();\n-        let (tx, rx) = channel();\n-        opts.on_exit = Some(proc(r) tx.send(r));\n-        NativeSpawner.spawn(opts, proc() { panic!() });\n-        assert!(rx.recv().is_err());\n-    }\n-\n-    #[test]\n-    fn yield_test() {\n-        let (tx, rx) = channel();\n-        spawn(proc() {\n-            for _ in range(0u, 10) { task::deschedule(); }\n-            tx.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn spawn_children() {\n-        let (tx1, rx) = channel();\n-        spawn(proc() {\n-            let (tx2, rx) = channel();\n-            spawn(proc() {\n-                let (tx3, rx) = channel();\n-                spawn(proc() {\n-                    tx3.send(());\n-                });\n-                rx.recv();\n-                tx2.send(());\n-            });\n-            rx.recv();\n-            tx1.send(());\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn spawn_inherits() {\n-        let (tx, rx) = channel();\n-        TaskBuilder::new().spawner(NativeSpawner).spawn(proc() {\n-            spawn(proc() {\n-                let mut task: Box<Task> = Local::take();\n-                match task.maybe_take_runtime::<Ops>() {\n-                    Some(ops) => {\n-                        task.put_runtime(ops);\n-                    }\n-                    None => panic!(),\n-                }\n-                Local::put(task);\n-                tx.send(());\n-            });\n-        });\n-        rx.recv();\n-    }\n-\n-    #[test]\n-    fn test_native_builder() {\n-        let res = TaskBuilder::new().native().try(proc() {\n-            \"Success!\".to_string()\n-        });\n-        assert_eq!(res.ok().unwrap(), \"Success!\".to_string());\n-    }\n-}"}, {"sha": "1ff66d0653f9652085951eefdca6a1f5dd479737", "filename": "src/librand/lib.rs", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrand%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrand%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrand%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -33,7 +33,6 @@ extern crate core;\n \n #[cfg(test)] #[phase(plugin, link)] extern crate std;\n #[cfg(test)] #[phase(plugin, link)] extern crate log;\n-#[cfg(test)] extern crate native;\n \n use core::prelude::*;\n "}, {"sha": "b3b68d0c22b381306df5770aa83be1116463e8e2", "filename": "src/librustc_trans/driver/driver.rs", "status": "modified", "additions": 1, "deletions": 6, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Fdriver%2Fdriver.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -198,10 +198,6 @@ pub fn phase_2_configure_and_expand(sess: &Session,\n         *sess.features.borrow_mut() = features;\n     });\n \n-    let any_exe = sess.crate_types.borrow().iter().any(|ty| {\n-        *ty == config::CrateTypeExecutable\n-    });\n-\n     // strip before expansion to allow macros to depend on\n     // configuration variables e.g/ in\n     //\n@@ -215,8 +211,7 @@ pub fn phase_2_configure_and_expand(sess: &Session,\n \n     krate = time(time_passes, \"crate injection\", krate, |krate|\n                  syntax::std_inject::maybe_inject_crates_ref(krate,\n-                                                             sess.opts.alt_std_name.clone(),\n-                                                             any_exe));\n+                                                             sess.opts.alt_std_name.clone()));\n \n     let mut addl_plugins = Some(addl_plugins);\n     let Plugins { macros, registrars }"}, {"sha": "65e6bdb70f818babdb017c2dde3130fe238217d2", "filename": "src/librustrt/lib.rs", "status": "modified", "additions": 0, "deletions": 41, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -30,7 +30,6 @@ extern crate collections;\n \n #[cfg(test)] extern crate \"rustrt\" as realrustrt;\n #[cfg(test)] extern crate test;\n-#[cfg(test)] extern crate native;\n \n #[cfg(test)] #[phase(plugin, link)] extern crate std;\n \n@@ -39,11 +38,6 @@ pub use self::unwind::{begin_unwind, begin_unwind_fmt};\n \n use core::prelude::*;\n \n-use alloc::boxed::Box;\n-use core::any::Any;\n-\n-use task::{Task, BlockedTask, TaskOpts};\n-\n mod macros;\n \n mod at_exit_imp;\n@@ -60,46 +54,11 @@ pub mod exclusive;\n pub mod local;\n pub mod local_data;\n pub mod mutex;\n-pub mod rtio;\n pub mod stack;\n pub mod task;\n pub mod thread;\n pub mod unwind;\n \n-/// The interface to the current runtime.\n-///\n-/// This trait is used as the abstraction between 1:1 and M:N scheduling. The\n-/// two independent crates, libnative and libgreen, both have objects which\n-/// implement this trait. The goal of this trait is to encompass all the\n-/// fundamental differences in functionality between the 1:1 and M:N runtime\n-/// modes.\n-pub trait Runtime {\n-    // Necessary scheduling functions, used for channels and blocking I/O\n-    // (sometimes).\n-    fn yield_now(self: Box<Self>, cur_task: Box<Task>);\n-    fn maybe_yield(self: Box<Self>, cur_task: Box<Task>);\n-    fn deschedule(self: Box<Self>,\n-                  times: uint,\n-                  cur_task: Box<Task>,\n-                  f: |BlockedTask| -> Result<(), BlockedTask>);\n-    fn reawaken(self: Box<Self>, to_wake: Box<Task>);\n-\n-    // Miscellaneous calls which are very different depending on what context\n-    // you're in.\n-    fn spawn_sibling(self: Box<Self>,\n-                     cur_task: Box<Task>,\n-                     opts: TaskOpts,\n-                     f: proc():Send);\n-    /// The (low, high) edges of the current stack.\n-    fn stack_bounds(&self) -> (uint, uint); // (lo, hi)\n-    /// The last writable byte of the stack next to the guard page\n-    fn stack_guard(&self) -> Option<uint>;\n-    fn can_block(&self) -> bool;\n-\n-    // FIXME: This is a serious code smell and this should not exist at all.\n-    fn wrap(self: Box<Self>) -> Box<Any+'static>;\n-}\n-\n /// The default error code of the rust runtime if the main task panics instead\n /// of exiting cleanly.\n pub const DEFAULT_ERROR_CODE: int = 101;"}, {"sha": "b1d387a9cc358239d02342c62b296585d78244d4", "filename": "src/librustrt/local.rs", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Flocal.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Flocal.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Flocal.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -53,14 +53,14 @@ impl Local<local_ptr::Borrowed<Task>> for Task {\n #[cfg(test)]\n mod test {\n     use std::prelude::*;\n-    use std::rt::thread::Thread;\n+    use thread::Thread;\n     use super::*;\n     use task::Task;\n \n     #[test]\n     fn thread_local_task_smoke_test() {\n         Thread::start(proc() {\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n             let task: Box<Task> = Local::take();\n             cleanup_task(task);\n@@ -70,11 +70,11 @@ mod test {\n     #[test]\n     fn thread_local_task_two_instances() {\n         Thread::start(proc() {\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n             let task: Box<Task> = Local::take();\n             cleanup_task(task);\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n             let task: Box<Task> = Local::take();\n             cleanup_task(task);\n@@ -84,7 +84,7 @@ mod test {\n     #[test]\n     fn borrow_smoke_test() {\n         Thread::start(proc() {\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n \n             unsafe {\n@@ -98,7 +98,7 @@ mod test {\n     #[test]\n     fn borrow_with_return() {\n         Thread::start(proc() {\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n \n             {\n@@ -113,7 +113,7 @@ mod test {\n     #[test]\n     fn try_take() {\n         Thread::start(proc() {\n-            let task = box Task::new();\n+            let task = box Task::new(None, None);\n             Local::put(task);\n \n             let t: Box<Task> = Local::try_take().unwrap();"}, {"sha": "2f0daf8f6e2429a073bc7d4d1c7794e5a1a2ea39", "filename": "src/librustrt/mutex.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fmutex.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -33,7 +33,7 @@\n //! # Example\n //!\n //! ```rust\n-//! use std::rt::mutex::{NativeMutex, StaticNativeMutex, NATIVE_MUTEX_INIT};\n+//! use rustrt::mutex::{NativeMutex, StaticNativeMutex, NATIVE_MUTEX_INIT};\n //!\n //! // Use a statically initialized mutex\n //! static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n@@ -108,7 +108,7 @@ impl StaticNativeMutex {\n     /// # Example\n     ///\n     /// ```rust\n-    /// use std::rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    /// use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n     /// static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n     /// unsafe {\n     ///     let _guard = LOCK.lock();\n@@ -225,7 +225,7 @@ impl NativeMutex {\n     /// # Example\n     ///\n     /// ```rust\n-    /// use std::rt::mutex::NativeMutex;\n+    /// use rustrt::mutex::NativeMutex;\n     /// unsafe {\n     ///     let mut lock = NativeMutex::new();\n     ///\n@@ -653,7 +653,7 @@ mod test {\n \n     use std::mem::drop;\n     use super::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n-    use std::rt::thread::Thread;\n+    use thread::Thread;\n \n     #[test]\n     fn smoke_lock() {"}, {"sha": "86de8168189ca77afe962f35ef4f9a7ff1554602", "filename": "src/librustrt/rtio.rs", "status": "removed", "additions": 0, "deletions": 45, "changes": 45, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibrustrt%2Frtio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibrustrt%2Frtio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Frtio.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,45 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-//! The EventLoop and internal synchronous I/O interface.\n-\n-use core::prelude::*;\n-use alloc::boxed::Box;\n-\n-pub trait EventLoop {\n-    fn run(&mut self);\n-    fn callback(&mut self, arg: proc(): Send);\n-    fn pausable_idle_callback(&mut self, Box<Callback + Send>)\n-                              -> Box<PausableIdleCallback + Send>;\n-    fn remote_callback(&mut self, Box<Callback + Send>)\n-                       -> Box<RemoteCallback + Send>;\n-\n-    // last vestige of IoFactory\n-    fn has_active_io(&self) -> bool;\n-}\n-\n-pub trait Callback {\n-    fn call(&mut self);\n-}\n-\n-pub trait RemoteCallback {\n-    /// Trigger the remote callback. Note that the number of times the\n-    /// callback is run is not guaranteed. All that is guaranteed is\n-    /// that, after calling 'fire', the callback will be called at\n-    /// least once, but multiple callbacks may be coalesced and\n-    /// callbacks may be called more often requested. Destruction also\n-    /// triggers the callback.\n-    fn fire(&mut self);\n-}\n-\n-pub trait PausableIdleCallback {\n-    fn pause(&mut self);\n-    fn resume(&mut self);\n-}"}, {"sha": "193484496800480f9cf4c88387b84b0fefa9c82f", "filename": "src/librustrt/stack_overflow.rs", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Fstack_overflow.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Fstack_overflow.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Fstack_overflow.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -65,14 +65,7 @@ pub unsafe fn report() {\n #[cfg(any(windows, target_os = \"linux\", target_os = \"macos\"))]\n unsafe fn get_task_guard_page() -> Option<uint> {\n     let task: Option<*mut Task> = Local::try_unsafe_borrow();\n-\n-    task.map(|task| {\n-        let runtime = (*task).take_runtime();\n-        let guard = runtime.stack_guard();\n-        (*task).put_runtime(runtime);\n-\n-        guard.unwrap_or(0)\n-    })\n+    task.map(|task| (&*task).stack_guard().unwrap_or(0))\n }\n \n #[cfg(windows)]"}, {"sha": "64c402bfbbc3985c8293205f169629c3b9a755c7", "filename": "src/librustrt/task.rs", "status": "modified", "additions": 174, "deletions": 175, "changes": 349, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibrustrt%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustrt%2Ftask.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -16,92 +16,45 @@ pub use self::BlockedTask::*;\n use self::TaskState::*;\n \n use alloc::arc::Arc;\n-use alloc::boxed::{BoxAny, Box};\n+use alloc::boxed::Box;\n use core::any::Any;\n use core::atomic::{AtomicUint, SeqCst};\n use core::iter::Take;\n use core::kinds::marker;\n use core::mem;\n use core::prelude::{Clone, Drop, Err, Iterator, None, Ok, Option, Send, Some};\n use core::prelude::{drop};\n-use core::raw;\n \n+use bookkeeping;\n+use mutex::NativeMutex;\n use local_data;\n-use Runtime;\n use local::Local;\n+use thread::{mod, Thread};\n+use stack;\n use unwind;\n use unwind::Unwinder;\n use collections::str::SendStr;\n \n /// State associated with Rust tasks.\n ///\n-/// Rust tasks are primarily built with two separate components. One is this\n-/// structure which handles standard services such as TLD, unwinding support,\n-/// naming of a task, etc. The second component is the runtime of this task, a\n-/// `Runtime` trait object.\n-///\n-/// The `Runtime` object instructs this task how it can perform critical\n-/// operations such as blocking, rescheduling, I/O constructors, etc. The two\n-/// halves are separately owned, but one is often found contained in the other.\n-/// A task's runtime can be reflected upon with the `maybe_take_runtime` method,\n-/// and otherwise its ownership is managed with `take_runtime` and\n-/// `put_runtime`.\n-///\n-/// In general, this structure should not be used. This is meant to be an\n-/// unstable internal detail of the runtime itself. From time-to-time, however,\n-/// it is useful to manage tasks directly. An example of this would be\n-/// interoperating with the Rust runtime from FFI callbacks or such. For this\n-/// reason, there are two methods of note with the `Task` structure.\n-///\n-/// * `run` - This function will execute a closure inside the context of a task.\n-///           Failure is caught and handled via the task's on_exit callback. If\n-///           this panics, the task is still returned, but it can no longer be\n-///           used, it is poisoned.\n-///\n-/// * `destroy` - This is a required function to call to destroy a task. If a\n-///               task falls out of scope without calling `destroy`, its\n-///               destructor bomb will go off, aborting the process.\n-///\n-/// With these two methods, tasks can be re-used to execute code inside of its\n-/// context while having a point in the future where destruction is allowed.\n-/// More information can be found on these specific methods.\n-///\n-/// # Example\n-///\n-/// ```no_run\n-/// extern crate native;\n-/// use std::uint;\n-/// # fn main() {\n-///\n-/// // Create a task using a native runtime\n-/// let task = native::task::new((0, uint::MAX), 0);\n-///\n-/// // Run some code, catching any possible panic\n-/// let task = task.run(|| {\n-///     // Run some code inside this task\n-///     println!(\"Hello with a native runtime!\");\n-/// });\n-///\n-/// // Run some code again, catching the panic\n-/// let task = task.run(|| {\n-///     panic!(\"oh no, what to do!\");\n-/// });\n-///\n-/// // Now that the task has panicked, it can never be used again\n-/// assert!(task.is_destroyed());\n-///\n-/// // Deallocate the resources associated with this task\n-/// task.destroy();\n-/// # }\n-/// ```\n+/// This structure is currently undergoing major changes, and is\n+/// likely to be move/be merged with a `Thread` structure.\n pub struct Task {\n     pub storage: LocalStorage,\n     pub unwinder: Unwinder,\n     pub death: Death,\n     pub name: Option<SendStr>,\n \n     state: TaskState,\n-    imp: Option<Box<Runtime + Send + 'static>>,\n+    lock: NativeMutex,       // native synchronization\n+    awoken: bool,            // used to prevent spurious wakeups\n+\n+    // This field holds the known bounds of the stack in (lo, hi) form. Not all\n+    // native tasks necessarily know their precise bounds, hence this is\n+    // optional.\n+    stack_bounds: (uint, uint),\n+\n+    stack_guard: uint\n }\n \n // Once a task has entered the `Armed` state it must be destroyed via `drop`,\n@@ -152,23 +105,60 @@ pub struct BlockedTasks {\n \n impl Task {\n     /// Creates a new uninitialized task.\n-    ///\n-    /// This method cannot be used to immediately invoke `run` because the task\n-    /// itself will likely require a runtime to be inserted via `put_runtime`.\n-    ///\n-    /// Note that you likely don't want to call this function, but rather the\n-    /// task creation functions through libnative or libgreen.\n-    pub fn new() -> Task {\n+    pub fn new(stack_bounds: Option<(uint, uint)>, stack_guard: Option<uint>) -> Task {\n         Task {\n             storage: LocalStorage(None),\n             unwinder: Unwinder::new(),\n             death: Death::new(),\n             state: New,\n             name: None,\n-            imp: None,\n+            lock: unsafe { NativeMutex::new() },\n+            awoken: false,\n+            // these *should* get overwritten\n+            stack_bounds: stack_bounds.unwrap_or((0, 0)),\n+            stack_guard: stack_guard.unwrap_or(0)\n         }\n     }\n \n+    pub fn spawn(opts: TaskOpts, f: proc():Send) {\n+        let TaskOpts { name, stack_size, on_exit } = opts;\n+\n+        let mut task = box Task::new(None, None);\n+        task.name = name;\n+        task.death.on_exit = on_exit;\n+\n+        // FIXME: change this back after moving rustrt into std\n+        // let stack = stack_size.unwrap_or(rt::min_stack());\n+        let stack = stack_size.unwrap_or(2 * 1024 * 1024);\n+\n+        // Note that this increment must happen *before* the spawn in order to\n+        // guarantee that if this task exits it will always end up waiting for\n+        // the spawned task to exit.\n+        let token = bookkeeping::increment();\n+\n+        // Spawning a new OS thread guarantees that __morestack will never get\n+        // triggered, but we must manually set up the actual stack bounds once\n+        // this function starts executing. This raises the lower limit by a bit\n+        // because by the time that this function is executing we've already\n+        // consumed at least a little bit of stack (we don't know the exact byte\n+        // address at which our stack started).\n+        Thread::spawn_stack(stack, proc() {\n+            let something_around_the_top_of_the_stack = 1;\n+            let addr = &something_around_the_top_of_the_stack as *const int;\n+            let my_stack = addr as uint;\n+            unsafe {\n+                stack::record_os_managed_stack_bounds(my_stack - stack + 1024,\n+                                                      my_stack);\n+            }\n+            task.stack_guard = thread::current_guard_page();\n+            task.stack_bounds = (my_stack - stack + 1024, my_stack);\n+\n+            let mut f = Some(f);\n+            drop(task.run(|| { f.take().unwrap()() }).destroy());\n+            drop(token);\n+        })\n+    }\n+\n     /// Consumes ownership of a task, runs some code, and returns the task back.\n     ///\n     /// This function can be used as an emulated \"try/catch\" to interoperate\n@@ -190,23 +180,6 @@ impl Task {\n     ///\n     /// It is invalid to call this function with a task that has been previously\n     /// destroyed via a failed call to `run`.\n-    ///\n-    /// # Example\n-    ///\n-    /// ```no_run\n-    /// extern crate native;\n-    /// use std::uint;\n-    /// # fn main() {\n-    ///\n-    /// // Create a new native task\n-    /// let task = native::task::new((0, uint::MAX), 0);\n-    ///\n-    /// // Run some code once and then destroy this task\n-    /// task.run(|| {\n-    ///     println!(\"Hello with a native runtime!\");\n-    /// }).destroy();\n-    /// # }\n-    /// ```\n     pub fn run(mut self: Box<Task>, f: ||) -> Box<Task> {\n         assert!(!self.is_destroyed(), \"cannot re-use a destroyed task\");\n \n@@ -329,111 +302,136 @@ impl Task {\n     /// Queries whether this can be destroyed or not.\n     pub fn is_destroyed(&self) -> bool { self.state == Destroyed }\n \n-    /// Inserts a runtime object into this task, transferring ownership to the\n-    /// task. It is illegal to replace a previous runtime object in this task\n-    /// with this argument.\n-    pub fn put_runtime(&mut self, ops: Box<Runtime + Send + 'static>) {\n-        assert!(self.imp.is_none());\n-        self.imp = Some(ops);\n-    }\n-\n-    /// Removes the runtime from this task, transferring ownership to the\n-    /// caller.\n-    pub fn take_runtime(&mut self) -> Box<Runtime + Send + 'static> {\n-        assert!(self.imp.is_some());\n-        self.imp.take().unwrap()\n-    }\n-\n-    /// Attempts to extract the runtime as a specific type. If the runtime does\n-    /// not have the provided type, then the runtime is not removed. If the\n-    /// runtime does have the specified type, then it is removed and returned\n-    /// (transfer of ownership).\n-    ///\n-    /// It is recommended to only use this method when *absolutely necessary*.\n-    /// This function may not be available in the future.\n-    pub fn maybe_take_runtime<T: 'static>(&mut self) -> Option<Box<T>> {\n-        // This is a terrible, terrible function. The general idea here is to\n-        // take the runtime, cast it to Box<Any>, check if it has the right\n-        // type, and then re-cast it back if necessary. The method of doing\n-        // this is pretty sketchy and involves shuffling vtables of trait\n-        // objects around, but it gets the job done.\n-        //\n-        // FIXME: This function is a serious code smell and should be avoided at\n-        //      all costs. I have yet to think of a method to avoid this\n-        //      function, and I would be saddened if more usage of the function\n-        //      crops up.\n-        unsafe {\n-            let imp = self.imp.take().unwrap();\n-            let vtable = mem::transmute::<_, &raw::TraitObject>(&imp).vtable;\n-            match imp.wrap().downcast::<T>() {\n-                Ok(t) => Some(t),\n-                Err(t) => {\n-                    let data = mem::transmute::<_, raw::TraitObject>(t).data;\n-                    let obj: Box<Runtime + Send + 'static> =\n-                        mem::transmute(raw::TraitObject {\n-                            vtable: vtable,\n-                            data: data,\n-                        });\n-                    self.put_runtime(obj);\n-                    None\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Spawns a sibling to this task. The newly spawned task is configured with\n-    /// the `opts` structure and will run `f` as the body of its code.\n-    pub fn spawn_sibling(mut self: Box<Task>,\n-                         opts: TaskOpts,\n-                         f: proc(): Send) {\n-        let ops = self.imp.take().unwrap();\n-        ops.spawn_sibling(self, opts, f)\n-    }\n-\n     /// Deschedules the current task, invoking `f` `amt` times. It is not\n     /// recommended to use this function directly, but rather communication\n     /// primitives in `std::comm` should be used.\n+    //\n+    // This function gets a little interesting. There are a few safety and\n+    // ownership violations going on here, but this is all done in the name of\n+    // shared state. Additionally, all of the violations are protected with a\n+    // mutex, so in theory there are no races.\n+    //\n+    // The first thing we need to do is to get a pointer to the task's internal\n+    // mutex. This address will not be changing (because the task is allocated\n+    // on the heap). We must have this handle separately because the task will\n+    // have its ownership transferred to the given closure. We're guaranteed,\n+    // however, that this memory will remain valid because *this* is the current\n+    // task's execution thread.\n+    //\n+    // The next weird part is where ownership of the task actually goes. We\n+    // relinquish it to the `f` blocking function, but upon returning this\n+    // function needs to replace the task back in TLS. There is no communication\n+    // from the wakeup thread back to this thread about the task pointer, and\n+    // there's really no need to. In order to get around this, we cast the task\n+    // to a `uint` which is then used at the end of this function to cast back\n+    // to a `Box<Task>` object. Naturally, this looks like it violates\n+    // ownership semantics in that there may be two `Box<Task>` objects.\n+    //\n+    // The fun part is that the wakeup half of this implementation knows to\n+    // \"forget\" the task on the other end. This means that the awakening half of\n+    // things silently relinquishes ownership back to this thread, but not in a\n+    // way that the compiler can understand. The task's memory is always valid\n+    // for both tasks because these operations are all done inside of a mutex.\n+    //\n+    // You'll also find that if blocking fails (the `f` function hands the\n+    // BlockedTask back to us), we will `mem::forget` the handles. The\n+    // reasoning for this is the same logic as above in that the task silently\n+    // transfers ownership via the `uint`, not through normal compiler\n+    // semantics.\n+    //\n+    // On a mildly unrelated note, it should also be pointed out that OS\n+    // condition variables are susceptible to spurious wakeups, which we need to\n+    // be ready for. In order to accommodate for this fact, we have an extra\n+    // `awoken` field which indicates whether we were actually woken up via some\n+    // invocation of `reawaken`. This flag is only ever accessed inside the\n+    // lock, so there's no need to make it atomic.\n     pub fn deschedule(mut self: Box<Task>,\n-                      amt: uint,\n+                      times: uint,\n                       f: |BlockedTask| -> ::core::result::Result<(), BlockedTask>) {\n-        let ops = self.imp.take().unwrap();\n-        ops.deschedule(amt, self, f)\n+        unsafe {\n+            let me = &mut *self as *mut Task;\n+            let task = BlockedTask::block(self);\n+\n+            if times == 1 {\n+                let guard = (*me).lock.lock();\n+                (*me).awoken = false;\n+                match f(task) {\n+                    Ok(()) => {\n+                        while !(*me).awoken {\n+                            guard.wait();\n+                        }\n+                    }\n+                    Err(task) => { mem::forget(task.wake()); }\n+                }\n+            } else {\n+                let iter = task.make_selectable(times);\n+                let guard = (*me).lock.lock();\n+                (*me).awoken = false;\n+\n+                // Apply the given closure to all of the \"selectable tasks\",\n+                // bailing on the first one that produces an error. Note that\n+                // care must be taken such that when an error is occurred, we\n+                // may not own the task, so we may still have to wait for the\n+                // task to become available. In other words, if task.wake()\n+                // returns `None`, then someone else has ownership and we must\n+                // wait for their signal.\n+                match iter.map(f).filter_map(|a| a.err()).next() {\n+                    None => {}\n+                    Some(task) => {\n+                        match task.wake() {\n+                            Some(task) => {\n+                                mem::forget(task);\n+                                (*me).awoken = true;\n+                            }\n+                            None => {}\n+                        }\n+                    }\n+                }\n+                while !(*me).awoken {\n+                    guard.wait();\n+                }\n+            }\n+            // put the task back in TLS, and everything is as it once was.\n+            Local::put(mem::transmute(me));\n+        }\n     }\n \n-    /// Wakes up a previously blocked task, optionally specifying whether the\n-    /// current task can accept a change in scheduling. This function can only\n-    /// be called on tasks that were previously blocked in `deschedule`.\n+    /// Wakes up a previously blocked task. This function can only be\n+    /// called on tasks that were previously blocked in `deschedule`.\n+    //\n+    // See the comments on `deschedule` for why the task is forgotten here, and\n+    // why it's valid to do so.\n     pub fn reawaken(mut self: Box<Task>) {\n-        let ops = self.imp.take().unwrap();\n-        ops.reawaken(self);\n+        unsafe {\n+            let me = &mut *self as *mut Task;\n+            mem::forget(self);\n+            let guard = (*me).lock.lock();\n+            (*me).awoken = true;\n+            guard.signal();\n+        }\n     }\n \n     /// Yields control of this task to another task. This function will\n     /// eventually return, but possibly not immediately. This is used as an\n     /// opportunity to allow other tasks a chance to run.\n-    pub fn yield_now(mut self: Box<Task>) {\n-        let ops = self.imp.take().unwrap();\n-        ops.yield_now(self);\n-    }\n-\n-    /// Similar to `yield_now`, except that this function may immediately return\n-    /// without yielding (depending on what the runtime decides to do).\n-    pub fn maybe_yield(mut self: Box<Task>) {\n-        let ops = self.imp.take().unwrap();\n-        ops.maybe_yield(self);\n+    pub fn yield_now() {\n+        Thread::yield_now();\n     }\n \n     /// Returns the stack bounds for this task in (lo, hi) format. The stack\n     /// bounds may not be known for all tasks, so the return value may be\n     /// `None`.\n     pub fn stack_bounds(&self) -> (uint, uint) {\n-        self.imp.as_ref().unwrap().stack_bounds()\n+        self.stack_bounds\n     }\n \n-    /// Returns whether it is legal for this task to block the OS thread that it\n-    /// is running on.\n-    pub fn can_block(&self) -> bool {\n-        self.imp.as_ref().unwrap().can_block()\n+    /// Returns the stack guard for this task, if known.\n+    pub fn stack_guard(&self) -> Option<uint> {\n+        if self.stack_guard != 0 {\n+            Some(self.stack_guard)\n+        } else {\n+            None\n+        }\n     }\n \n     /// Consume this task, flagging it as a candidate for destruction.\n@@ -549,6 +547,7 @@ mod test {\n     use super::*;\n     use std::prelude::*;\n     use std::task;\n+    use unwind;\n \n     #[test]\n     fn tls() {\n@@ -594,20 +593,20 @@ mod test {\n     #[test]\n     #[should_fail]\n     fn test_begin_unwind() {\n-        use std::rt::unwind::begin_unwind;\n+        use unwind::begin_unwind;\n         begin_unwind(\"cause\", &(file!(), line!()))\n     }\n \n     #[test]\n     fn drop_new_task_ok() {\n-        drop(Task::new());\n+        drop(Task::new(None, None));\n     }\n \n     // Task blocking tests\n \n     #[test]\n     fn block_and_wake() {\n-        let task = box Task::new();\n+        let task = box Task::new(None, None);\n         let task = BlockedTask::block(task).wake().unwrap();\n         task.drop();\n     }"}, {"sha": "0f119d44485324afb179db12abf4eb7e55effe44", "filename": "src/libstd/dynamic_lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fdynamic_lib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fdynamic_lib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fdynamic_lib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -229,7 +229,7 @@ pub mod dl {\n     }\n \n     pub fn check_for_errors_in<T>(f: || -> T) -> Result<T, String> {\n-        use rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+        use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n         static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n         unsafe {\n             // dlerror isn't thread safe, so we need to lock around this entire"}, {"sha": "c23e043c174091876a60189b0c7f44a229148407", "filename": "src/libstd/failure.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Ffailure.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Ffailure.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ffailure.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -18,7 +18,7 @@ use kinds::Send;\n use option::{Some, None};\n use result::Ok;\n use rt::backtrace;\n-use rt::{Stderr, Stdio};\n+use rustrt::{Stderr, Stdio};\n use rustrt::local::Local;\n use rustrt::task::Task;\n use str::Str;"}, {"sha": "8c20ea0886385b58872dc428fda50bf056556ee9", "filename": "src/libstd/io/pipe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fpipe.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -45,7 +45,7 @@ impl PipeStream {\n     ///\n     /// # Example\n     ///\n-    /// ```rust\n+    /// ```{rust,no_run}\n     /// # #![allow(unused_must_use)]\n     /// extern crate libc;\n     ///"}, {"sha": "d4d24c1e12fc88449391980fe6f56358cc424092", "filename": "src/libstd/io/process.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fprocess.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fprocess.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fprocess.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -740,8 +740,6 @@ impl Drop for Process {\n mod tests {\n     #![allow(unused_imports)]\n \n-    extern crate native;\n-\n     use super::*;\n     use prelude::*;\n     use io::timer::*;"}, {"sha": "7374668a69d834c1cbfa961e1a20ab2ace2c990e", "filename": "src/libstd/io/stdio.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fstdio.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fio%2Fstdio.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fio%2Fstdio.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -40,9 +40,9 @@ use option::{Option, Some, None};\n use boxed::Box;\n use sys::{fs, tty};\n use result::{Ok, Err};\n-use rt;\n-use rt::local::Local;\n-use rt::task::Task;\n+use rustrt;\n+use rustrt::local::Local;\n+use rustrt::task::Task;\n use slice::SlicePrelude;\n use str::StrPrelude;\n use uint;\n@@ -207,7 +207,7 @@ fn with_task_stdout(f: |&mut Writer| -> IoResult<()>) {\n         local_stdout.replace(Some(my_stdout));\n         result\n     } else {\n-        let mut io = rt::Stdout;\n+        let mut io = rustrt::Stdout;\n         f(&mut io as &mut Writer)\n     };\n     match result {"}, {"sha": "b35c49efdd80cfee79aea45e806dd39ed5b7390c", "filename": "src/libstd/lib.rs", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -117,7 +117,6 @@\n \n #![reexport_test_harness_main = \"test_main\"]\n \n-#[cfg(test)] extern crate green;\n #[cfg(test)] #[phase(plugin, link)] extern crate log;\n \n extern crate alloc;\n@@ -163,7 +162,6 @@ pub use core::result;\n pub use core::option;\n \n pub use alloc::boxed;\n-\n pub use alloc::rc;\n \n pub use core_collections::slice;\n@@ -248,8 +246,6 @@ pub mod fmt;\n \n #[path = \"sys/common/mod.rs\"] mod sys_common;\n \n-// FIXME #7809: This shouldn't be pub, and it should be reexported under 'unstable'\n-// but name resolution doesn't work without it being pub.\n pub mod rt;\n mod failure;\n "}, {"sha": "d7ba4877086ea2275a617c5339f5c3974083ce16", "filename": "src/libstd/os.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fos.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fos.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fos.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -208,7 +208,7 @@ Accessing environment variables is not generally threadsafe.\n Serialize access through a global lock.\n */\n fn with_env_lock<T>(f: || -> T) -> T {\n-    use rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n \n     static LOCK: StaticNativeMutex = NATIVE_MUTEX_INIT;\n \n@@ -1039,9 +1039,9 @@ fn real_args_as_bytes() -> Vec<Vec<u8>> {\n           target_os = \"freebsd\",\n           target_os = \"dragonfly\"))]\n fn real_args_as_bytes() -> Vec<Vec<u8>> {\n-    use rt;\n+    use rustrt;\n \n-    match rt::args::clone() {\n+    match rustrt::args::clone() {\n         Some(args) => args,\n         None => panic!(\"process arguments not initialized\")\n     }"}, {"sha": "107518ef27c9d818457f6088728217a2e306b311", "filename": "src/libstd/rt/backtrace.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Frt%2Fbacktrace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Frt%2Fbacktrace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fbacktrace.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -238,7 +238,7 @@ mod imp {\n     use mem;\n     use option::{Some, None, Option};\n     use result::{Ok, Err};\n-    use rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n \n     /// As always - iOS on arm uses SjLj exceptions and\n     /// _Unwind_Backtrace is even not available there. Still,\n@@ -667,7 +667,7 @@ mod imp {\n     use option::{Some, None};\n     use path::Path;\n     use result::{Ok, Err};\n-    use rt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n+    use rustrt::mutex::{StaticNativeMutex, NATIVE_MUTEX_INIT};\n     use slice::SlicePrelude;\n     use str::StrPrelude;\n     use dynamic_lib::DynamicLibrary;"}, {"sha": "21b4edb6375812650620195b7fa6a222c9ec6987", "filename": "src/libstd/rt/mod.rs", "status": "modified", "additions": 80, "deletions": 4, "changes": 84, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Frt%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Frt%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Frt%2Fmod.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -54,18 +54,19 @@ Several modules in `core` are clients of `rt`:\n // FIXME: this should not be here.\n #![allow(missing_docs)]\n \n+#![allow(dead_code)]\n+\n use failure;\n use rustrt;\n+use os;\n \n // Reexport some of our utilities which are expected by other crates.\n pub use self::util::{default_sched_threads, min_stack, running_on_valgrind};\n \n // Reexport functionality from librustrt and other crates underneath the\n // standard library which work together to create the entire runtime.\n pub use alloc::heap;\n-pub use rustrt::{task, local, mutex, exclusive, stack, args, rtio, thread};\n-pub use rustrt::{Stdio, Stdout, Stderr, begin_unwind, begin_unwind_fmt};\n-pub use rustrt::{bookkeeping, at_exit, unwind, DEFAULT_ERROR_CODE, Runtime};\n+pub use rustrt::{begin_unwind, begin_unwind_fmt, at_exit};\n \n // Simple backtrace functionality (to print on panic)\n pub mod backtrace;\n@@ -81,7 +82,82 @@ mod util;\n #[allow(experimental)]\n pub fn init(argc: int, argv: *const *const u8) {\n     rustrt::init(argc, argv);\n-    unsafe { unwind::register(failure::on_fail); }\n+    unsafe { rustrt::unwind::register(failure::on_fail); }\n+}\n+\n+#[cfg(any(windows, android))]\n+static OS_DEFAULT_STACK_ESTIMATE: uint = 1 << 20;\n+#[cfg(all(unix, not(android)))]\n+static OS_DEFAULT_STACK_ESTIMATE: uint = 2 * (1 << 20);\n+\n+#[cfg(not(test))]\n+#[lang = \"start\"]\n+fn lang_start(main: *const u8, argc: int, argv: *const *const u8) -> int {\n+    use mem;\n+    start(argc, argv, proc() {\n+        let main: extern \"Rust\" fn() = unsafe { mem::transmute(main) };\n+        main();\n+    })\n+}\n+\n+/// Executes the given procedure after initializing the runtime with the given\n+/// argc/argv.\n+///\n+/// This procedure is guaranteed to run on the thread calling this function, but\n+/// the stack bounds for this rust task will *not* be set. Care must be taken\n+/// for this function to not overflow its stack.\n+///\n+/// This function will only return once *all* native threads in the system have\n+/// exited.\n+pub fn start(argc: int, argv: *const *const u8, main: proc()) -> int {\n+    use prelude::*;\n+    use rt;\n+    use rustrt::task::Task;\n+    use str;\n+\n+    let something_around_the_top_of_the_stack = 1;\n+    let addr = &something_around_the_top_of_the_stack as *const int;\n+    let my_stack_top = addr as uint;\n+\n+    // FIXME #11359 we just assume that this thread has a stack of a\n+    // certain size, and estimate that there's at most 20KB of stack\n+    // frames above our current position.\n+    let my_stack_bottom = my_stack_top + 20000 - OS_DEFAULT_STACK_ESTIMATE;\n+\n+    // When using libgreen, one of the first things that we do is to turn off\n+    // the SIGPIPE signal (set it to ignore). By default, some platforms will\n+    // send a *signal* when a EPIPE error would otherwise be delivered. This\n+    // runtime doesn't install a SIGPIPE handler, causing it to kill the\n+    // program, which isn't exactly what we want!\n+    //\n+    // Hence, we set SIGPIPE to ignore when the program starts up in order to\n+    // prevent this problem.\n+    #[cfg(windows)] fn ignore_sigpipe() {}\n+    #[cfg(unix)] fn ignore_sigpipe() {\n+        use libc;\n+        use libc::funcs::posix01::signal::signal;\n+        unsafe {\n+            assert!(signal(libc::SIGPIPE, libc::SIG_IGN) != -1);\n+        }\n+    }\n+    ignore_sigpipe();\n+\n+    init(argc, argv);\n+    let mut exit_code = None;\n+    let mut main = Some(main);\n+    let mut task = box Task::new(Some((my_stack_bottom, my_stack_top)),\n+                                 Some(rustrt::thread::main_guard_page()));\n+    task.name = Some(str::Slice(\"<main>\"));\n+    drop(task.run(|| {\n+        unsafe {\n+            rustrt::stack::record_os_managed_stack_bounds(my_stack_bottom, my_stack_top);\n+        }\n+        (main.take().unwrap())();\n+        exit_code = Some(os::get_exit_status());\n+    }).destroy());\n+    unsafe { rt::cleanup(); }\n+    // If the exit code wasn't set, then the task block must have panicked.\n+    return exit_code.unwrap_or(rustrt::DEFAULT_ERROR_CODE);\n }\n \n /// One-time runtime cleanup."}, {"sha": "9508d8d92325bab97d0022c4dc31a068a170552c", "filename": "src/libstd/sys/common/helper_thread.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fhelper_thread.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -21,9 +21,9 @@\n //! time.\n \n use mem;\n-use rt::bookkeeping;\n-use rt::mutex::StaticNativeMutex;\n-use rt;\n+use rustrt::bookkeeping;\n+use rustrt::mutex::StaticNativeMutex;\n+use rustrt;\n use cell::UnsafeCell;\n use sys::helper_signal;\n use prelude::*;\n@@ -83,7 +83,7 @@ impl<M: Send> Helper<M> {\n                     self.lock.lock().signal()\n                 });\n \n-                rt::at_exit(proc() { self.shutdown() });\n+                rustrt::at_exit(proc() { self.shutdown() });\n                 *self.initialized.get() = true;\n             }\n         }"}, {"sha": "029fc8527426152cf61e6c073d240634c146c35b", "filename": "src/libstd/sys/common/net.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fcommon%2Fnet.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -16,7 +16,7 @@ use libc::{mod, c_char, c_int};\n use mem;\n use num::Int;\n use ptr::{mod, null, null_mut};\n-use rt::mutex;\n+use rustrt::mutex;\n use io::net::ip::{SocketAddr, IpAddr, Ipv4Addr, Ipv6Addr};\n use io::net::addrinfo;\n use io::{IoResult, IoError};"}, {"sha": "664a6a1e70c767b1b3b1f17d6a4b48782642f462", "filename": "src/libstd/sys/unix/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Funix%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Funix%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fmod.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -25,7 +25,7 @@ use sys_common::mkerr_libc;\n \n macro_rules! helper_init( (static $name:ident: Helper<$m:ty>) => (\n     static $name: Helper<$m> = Helper {\n-        lock: ::rt::mutex::NATIVE_MUTEX_INIT,\n+        lock: ::rustrt::mutex::NATIVE_MUTEX_INIT,\n         chan: ::cell::UnsafeCell { value: 0 as *mut Sender<$m> },\n         signal: ::cell::UnsafeCell { value: 0 },\n         initialized: ::cell::UnsafeCell { value: false },"}, {"sha": "4d3469a9c24a80d19e55f84015f2da512519765a", "filename": "src/libstd/sys/unix/pipe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Funix%2Fpipe.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -12,7 +12,7 @@ use alloc::arc::Arc;\n use libc;\n use c_str::CString;\n use mem;\n-use rt::mutex;\n+use rustrt::mutex;\n use sync::atomic;\n use io::{mod, IoResult, IoError};\n use prelude::*;"}, {"sha": "815ace21f879d931f80bbe8e2a5f2b915b7a86b2", "filename": "src/libstd/sys/windows/mod.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fmod.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -26,7 +26,7 @@ use sync::{Once, ONCE_INIT};\n \n macro_rules! helper_init( (static $name:ident: Helper<$m:ty>) => (\n     static $name: Helper<$m> = Helper {\n-        lock: ::rt::mutex::NATIVE_MUTEX_INIT,\n+        lock: ::rustrt::mutex::NATIVE_MUTEX_INIT,\n         chan: ::cell::UnsafeCell { value: 0 as *mut Sender<$m> },\n         signal: ::cell::UnsafeCell { value: 0 },\n         initialized: ::cell::UnsafeCell { value: false },"}, {"sha": "a623c2cd8e29737ba9e34a72e576f9f967404bab", "filename": "src/libstd/sys/windows/pipe.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fsys%2Fwindows%2Fpipe.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -90,7 +90,7 @@ use c_str::CString;\n use mem;\n use ptr;\n use sync::atomic;\n-use rt::mutex;\n+use rustrt::mutex;\n use io::{mod, IoError, IoResult};\n use prelude::*;\n "}, {"sha": "4f5f47e980c0dbc4bed01abe8303c3b11b447e80", "filename": "src/libstd/task.rs", "status": "modified", "additions": 19, "deletions": 121, "changes": 140, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Ftask.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibstd%2Ftask.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Ftask.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -11,11 +11,7 @@\n //! Task creation\n //!\n //! An executing Rust program consists of a collection of tasks, each\n-//! with their own stack and local state. A Rust task is typically\n-//! backed by an operating system thread, making tasks 'just threads',\n-//! but may also be implemented via other strategies as well\n-//! (e.g. Rust comes with the [`green`](../../green/index.html)\n-//! scheduling crate for creating tasks backed by green threads).\n+//! with their own stack and local state.\n //!\n //! Tasks generally have their memory *isolated* from each other by\n //! virtue of Rust's owned types (which of course may only be owned by\n@@ -36,60 +32,13 @@\n //! the main task panics the application will exit with a non-zero\n //! exit code.\n //!\n-//! # Basic task scheduling\n-//!\n-//! By default, every task is created with the same \"flavor\" as the calling task.\n-//! This flavor refers to the scheduling mode, with two possibilities currently\n-//! being 1:1 and M:N modes. Green (M:N) tasks are cooperatively scheduled and\n-//! native (1:1) tasks are scheduled by the OS kernel.\n-//!\n //! ## Example\n //!\n //! ```rust\n //! spawn(proc() {\n //!     println!(\"Hello, World!\");\n //! })\n //! ```\n-//!\n-//! # Advanced task scheduling\n-//!\n-//! Task spawning can also be configured to use a particular scheduler, to\n-//! redirect the new task's output, or to yield a `future` representing the\n-//! task's final result. The configuration is established using the\n-//! `TaskBuilder` API:\n-//!\n-//! ## Example\n-//!\n-//! ```rust\n-//! extern crate green;\n-//! extern crate native;\n-//!\n-//! use std::task::TaskBuilder;\n-//! use green::{SchedPool, PoolConfig, GreenTaskBuilder};\n-//! use native::NativeTaskBuilder;\n-//!\n-//! # fn main() {\n-//! // Create a green scheduler pool with the default configuration\n-//! let mut pool = SchedPool::new(PoolConfig::new());\n-//!\n-//! // Spawn a task in the green pool\n-//! let mut fut_green = TaskBuilder::new().green(&mut pool).try_future(proc() {\n-//!     /* ... */\n-//! });\n-//!\n-//! // Spawn a native task\n-//! let mut fut_native = TaskBuilder::new().native().try_future(proc() {\n-//!     /* ... */\n-//! });\n-//!\n-//! // Wait for both tasks to finish, recording their outcome\n-//! let res_green  = fut_green.unwrap();\n-//! let res_native = fut_native.unwrap();\n-//!\n-//! // Shut down the green scheduler pool\n-//! pool.shutdown();\n-//! # }\n-//! ```\n \n #![unstable = \"The task spawning model will be changed as part of runtime reform, and the module \\\n                will likely be renamed from `task` to `thread`.\"]\n@@ -101,33 +50,13 @@ use kinds::{Send, marker};\n use option::{None, Some, Option};\n use boxed::Box;\n use result::Result;\n-use rt::local::Local;\n-use rt::task;\n-use rt::task::Task;\n+use rustrt::local::Local;\n+use rustrt::task;\n+use rustrt::task::Task;\n use str::{Str, SendStr, IntoMaybeOwned};\n use string::{String, ToString};\n use sync::Future;\n \n-/// A means of spawning a task\n-pub trait Spawner {\n-    /// Spawn a task, given low-level task options.\n-    fn spawn(self, opts: task::TaskOpts, f: proc():Send);\n-}\n-\n-/// The default task spawner, which spawns siblings to the current task.\n-pub struct SiblingSpawner;\n-\n-impl Spawner for SiblingSpawner {\n-    fn spawn(self, opts: task::TaskOpts, f: proc():Send) {\n-        // bind tb to provide type annotation\n-        let tb: Option<Box<Task>> = Local::try_take();\n-        match tb {\n-            Some(t) => t.spawn_sibling(opts, f),\n-            None => panic!(\"need a local task to spawn a sibling task\"),\n-        };\n-    }\n-}\n-\n /// The task builder type.\n ///\n /// Provides detailed control over the properties and behavior of new tasks.\n@@ -139,7 +68,7 @@ impl Spawner for SiblingSpawner {\n // when you try to reuse the builder to spawn a new task. We'll just\n // sidestep that whole issue by making builders uncopyable and making\n // the run function move them in.\n-pub struct TaskBuilder<S = SiblingSpawner> {\n+pub struct TaskBuilder {\n     // A name for the task-to-be, for identification in panic messages\n     name: Option<SendStr>,\n     // The size of the stack for the spawned task\n@@ -148,88 +77,60 @@ pub struct TaskBuilder<S = SiblingSpawner> {\n     stdout: Option<Box<Writer + Send>>,\n     // Task-local stderr\n     stderr: Option<Box<Writer + Send>>,\n-    // The mechanics of actually spawning the task (i.e.: green or native)\n-    spawner: S,\n     // Optionally wrap the eventual task body\n     gen_body: Option<proc(v: proc():Send):Send -> proc():Send>,\n     nocopy: marker::NoCopy,\n }\n \n-impl TaskBuilder<SiblingSpawner> {\n+impl TaskBuilder {\n     /// Generate the base configuration for spawning a task, off of which more\n     /// configuration methods can be chained.\n-    pub fn new() -> TaskBuilder<SiblingSpawner> {\n+    pub fn new() -> TaskBuilder {\n         TaskBuilder {\n             name: None,\n             stack_size: None,\n             stdout: None,\n             stderr: None,\n-            spawner: SiblingSpawner,\n             gen_body: None,\n             nocopy: marker::NoCopy,\n         }\n     }\n }\n \n-impl<S: Spawner> TaskBuilder<S> {\n+impl TaskBuilder {\n     /// Name the task-to-be. Currently the name is used for identification\n     /// only in panic messages.\n     #[unstable = \"IntoMaybeOwned will probably change.\"]\n-    pub fn named<T: IntoMaybeOwned<'static>>(mut self, name: T) -> TaskBuilder<S> {\n+    pub fn named<T: IntoMaybeOwned<'static>>(mut self, name: T) -> TaskBuilder {\n         self.name = Some(name.into_maybe_owned());\n         self\n     }\n \n     /// Set the size of the stack for the new task.\n-    pub fn stack_size(mut self, size: uint) -> TaskBuilder<S> {\n+    pub fn stack_size(mut self, size: uint) -> TaskBuilder {\n         self.stack_size = Some(size);\n         self\n     }\n \n     /// Redirect task-local stdout.\n     #[experimental = \"May not want to make stdio overridable here.\"]\n-    pub fn stdout(mut self, stdout: Box<Writer + Send>) -> TaskBuilder<S> {\n+    pub fn stdout(mut self, stdout: Box<Writer + Send>) -> TaskBuilder {\n         self.stdout = Some(stdout);\n         self\n     }\n \n     /// Redirect task-local stderr.\n     #[experimental = \"May not want to make stdio overridable here.\"]\n-    pub fn stderr(mut self, stderr: Box<Writer + Send>) -> TaskBuilder<S> {\n+    pub fn stderr(mut self, stderr: Box<Writer + Send>) -> TaskBuilder {\n         self.stderr = Some(stderr);\n         self\n     }\n \n-    /// Set the spawning mechanism for the task.\n-    ///\n-    /// The `TaskBuilder` API configures a task to be spawned, but defers to the\n-    /// \"spawner\" to actually create and spawn the task. The `spawner` method\n-    /// should not be called directly by `TaskBuiler` clients. It is intended\n-    /// for use by downstream crates (like `native` and `green`) that implement\n-    /// tasks. These downstream crates then add extension methods to the\n-    /// builder, like `.native()` and `.green(pool)`, that actually set the\n-    /// spawner.\n-    pub fn spawner<T: Spawner>(self, spawner: T) -> TaskBuilder<T> {\n-        // repackage the entire TaskBuilder since its type is changing.\n-        let TaskBuilder {\n-            name, stack_size, stdout, stderr, spawner: _, gen_body, nocopy\n-        } = self;\n-        TaskBuilder {\n-            name: name,\n-            stack_size: stack_size,\n-            stdout: stdout,\n-            stderr: stderr,\n-            spawner: spawner,\n-            gen_body: gen_body,\n-            nocopy: nocopy,\n-        }\n-    }\n-\n     // Where spawning actually happens (whether yielding a future or not)\n     fn spawn_internal(self, f: proc():Send,\n                       on_exit: Option<proc(Result<(), Box<Any + Send>>):Send>) {\n         let TaskBuilder {\n-            name, stack_size, stdout, stderr, spawner, mut gen_body, nocopy: _\n+            name, stack_size, stdout, stderr, mut gen_body, nocopy: _\n         } = self;\n         let f = match gen_body.take() {\n             Some(gen) => gen(f),\n@@ -241,13 +142,13 @@ impl<S: Spawner> TaskBuilder<S> {\n             stack_size: stack_size,\n         };\n         if stdout.is_some() || stderr.is_some() {\n-            spawner.spawn(opts, proc() {\n+            Task::spawn(opts, proc() {\n                 let _ = stdout.map(stdio::set_stdout);\n                 let _ = stderr.map(stdio::set_stderr);\n                 f();\n             })\n         } else {\n-            spawner.spawn(opts, f)\n+            Task::spawn(opts, f)\n         }\n     }\n \n@@ -336,7 +237,7 @@ pub fn try_future<T:Send>(f: proc():Send -> T) -> Future<Result<T, Box<Any + Sen\n /// Read the name of the current task.\n #[stable]\n pub fn name() -> Option<String> {\n-    use rt::task::Task;\n+    use rustrt::task::Task;\n \n     let task = Local::borrow(None::<Task>);\n     match task.name {\n@@ -348,18 +249,15 @@ pub fn name() -> Option<String> {\n /// Yield control to the task scheduler.\n #[unstable = \"Name will change.\"]\n pub fn deschedule() {\n-    use rt::local::Local;\n-\n-    // FIXME(#7544): Optimize this, since we know we won't block.\n-    let task: Box<Task> = Local::take();\n-    task.yield_now();\n+    use rustrt::task::Task;\n+    Task::yield_now();\n }\n \n /// True if the running task is currently panicking (e.g. will return `true` inside a\n /// destructor that is run while unwinding the stack after a call to `panic!()`).\n #[unstable = \"May move to a different module.\"]\n pub fn failing() -> bool {\n-    use rt::task::Task;\n+    use rustrt::task::Task;\n     Local::borrow(None::<Task>).unwinder.unwinding()\n }\n "}, {"sha": "b4b2ef5218cef756f8c9fcca9235348662f8ce8c", "filename": "src/libsync/atomic.rs", "status": "modified", "additions": 1, "deletions": 8, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fatomic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fatomic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fatomic.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -42,7 +42,6 @@\n //! ```\n //! use std::sync::Arc;\n //! use std::sync::atomic::{AtomicUint, SeqCst};\n-//! use std::task::deschedule;\n //!\n //! fn main() {\n //!     let spinlock = Arc::new(AtomicUint::new(1));\n@@ -53,13 +52,7 @@\n //!     });\n //!\n //!     // Wait for the other task to release the lock\n-//!     while spinlock.load(SeqCst) != 0 {\n-//!         // Since tasks may not be preemptive (if they are green threads)\n-//!         // yield to the scheduler to let the other task run. Low level\n-//!         // concurrent code needs to take into account Rust's two threading\n-//!         // models.\n-//!         deschedule();\n-//!     }\n+//!     while spinlock.load(SeqCst) != 0 {}\n //! }\n //! ```\n //!"}, {"sha": "3c7e46036d6fbe689800ac25cf192d84c709a745", "filename": "src/libsync/comm/mod.rs", "status": "modified", "additions": 8, "deletions": 55, "changes": 63, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fcomm%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fcomm%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Fmod.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -65,10 +65,6 @@\n //! the `try_send` method on a `SyncSender`, but no other operations are\n //! guaranteed to be safe.\n //!\n-//! Additionally, channels can interoperate between runtimes. If one task in a\n-//! program is running on libnative and another is running on libgreen, they can\n-//! still communicate with one another using channels.\n-//!\n //! # Example\n //!\n //! Simple usage:\n@@ -328,13 +324,10 @@ pub use self::TrySendError::*;\n use self::Flavor::*;\n \n use alloc::arc::Arc;\n-use alloc::boxed::Box;\n-use core::cell::Cell;\n use core::kinds::marker;\n use core::mem;\n use core::cell::UnsafeCell;\n-use rustrt::local::Local;\n-use rustrt::task::{Task, BlockedTask};\n+use rustrt::task::BlockedTask;\n \n pub use comm::select::{Select, Handle};\n \n@@ -343,23 +336,16 @@ macro_rules! test (\n         mod $name {\n             #![allow(unused_imports)]\n \n+            extern crate rustrt;\n+\n             use std::prelude::*;\n \n-            use native;\n             use comm::*;\n             use super::*;\n             use super::super::*;\n             use std::task;\n \n-            fn f() $b\n-\n-            $(#[$a])* #[test] fn uv() { f() }\n-            $(#[$a])* #[test] fn native() {\n-                use native;\n-                let (tx, rx) = channel();\n-                spawn(proc() { tx.send(f()) });\n-                rx.recv();\n-            }\n+            $(#[$a])* #[test] fn f() { $b }\n         }\n     )\n )\n@@ -370,16 +356,11 @@ mod shared;\n mod stream;\n mod sync;\n \n-// Use a power of 2 to allow LLVM to optimize to something that's not a\n-// division, this is hit pretty regularly.\n-static RESCHED_FREQ: int = 256;\n-\n /// The receiving-half of Rust's channel type. This half can only be owned by\n /// one task\n #[unstable]\n pub struct Receiver<T> {\n     inner: UnsafeCell<Flavor<T>>,\n-    receives: Cell<uint>,\n     // can't share in an arc\n     _marker: marker::NoSync,\n }\n@@ -397,7 +378,6 @@ pub struct Messages<'a, T:'a> {\n #[unstable]\n pub struct Sender<T> {\n     inner: UnsafeCell<Flavor<T>>,\n-    sends: Cell<uint>,\n     // can't share in an arc\n     _marker: marker::NoSync,\n }\n@@ -544,7 +524,6 @@ impl<T: Send> Sender<T> {\n     fn new(inner: Flavor<T>) -> Sender<T> {\n         Sender {\n             inner: UnsafeCell::new(inner),\n-            sends: Cell::new(0),\n             _marker: marker::NoSync,\n         }\n     }\n@@ -608,21 +587,6 @@ impl<T: Send> Sender<T> {\n     /// ```\n     #[unstable = \"this function may be renamed to send() in the future\"]\n     pub fn send_opt(&self, t: T) -> Result<(), T> {\n-        // In order to prevent starvation of other tasks in situations where\n-        // a task sends repeatedly without ever receiving, we occasionally\n-        // yield instead of doing a send immediately.\n-        //\n-        // Don't unconditionally attempt to yield because the TLS overhead can\n-        // be a bit much, and also use `try_take` instead of `take` because\n-        // there's no reason that this send shouldn't be usable off the\n-        // runtime.\n-        let cnt = self.sends.get() + 1;\n-        self.sends.set(cnt);\n-        if cnt % (RESCHED_FREQ as uint) == 0 {\n-            let task: Option<Box<Task>> = Local::try_take();\n-            task.map(|t| t.maybe_yield());\n-        }\n-\n         let (new_inner, ret) = match *unsafe { self.inner() } {\n             Oneshot(ref p) => {\n                 unsafe {\n@@ -809,7 +773,7 @@ impl<T: Send> Drop for SyncSender<T> {\n \n impl<T: Send> Receiver<T> {\n     fn new(inner: Flavor<T>) -> Receiver<T> {\n-        Receiver { inner: UnsafeCell::new(inner), receives: Cell::new(0), _marker: marker::NoSync }\n+        Receiver { inner: UnsafeCell::new(inner), _marker: marker::NoSync }\n     }\n \n     /// Blocks waiting for a value on this receiver\n@@ -854,17 +818,6 @@ impl<T: Send> Receiver<T> {\n     /// This function cannot panic.\n     #[unstable = \"the return type of this function may be altered\"]\n     pub fn try_recv(&self) -> Result<T, TryRecvError> {\n-        // If a thread is spinning in try_recv, we should take the opportunity\n-        // to reschedule things occasionally. See notes above in scheduling on\n-        // sends for why this doesn't always hit TLS, and also for why this uses\n-        // `try_take` instead of `take`.\n-        let cnt = self.receives.get() + 1;\n-        self.receives.set(cnt);\n-        if cnt % (RESCHED_FREQ as uint) == 0 {\n-            let task: Option<Box<Task>> = Local::try_take();\n-            task.map(|t| t.maybe_yield());\n-        }\n-\n         loop {\n             let new_port = match *unsafe { self.inner() } {\n                 Oneshot(ref p) => {\n@@ -1561,7 +1514,7 @@ mod test {\n     })\n \n     test!(fn sends_off_the_runtime() {\n-        use std::rt::thread::Thread;\n+        use rustrt::thread::Thread;\n \n         let (tx, rx) = channel();\n         let t = Thread::start(proc() {\n@@ -1576,7 +1529,7 @@ mod test {\n     })\n \n     test!(fn try_recvs_off_the_runtime() {\n-        use std::rt::thread::Thread;\n+        use rustrt::thread::Thread;\n \n         let (tx, rx) = channel();\n         let (cdone, pdone) = channel();\n@@ -2026,7 +1979,7 @@ mod sync_tests {\n     })\n \n     test!(fn try_recvs_off_the_runtime() {\n-        use std::rt::thread::Thread;\n+        use rustrt::thread::Thread;\n \n         let (tx, rx) = sync_channel::<()>(0);\n         let (cdone, pdone) = channel();"}, {"sha": "96c0acacd80e152a1de40731b89d994e89252642", "filename": "src/libsync/comm/shared.rs", "status": "modified", "additions": 0, "deletions": 11, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fcomm%2Fshared.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fcomm%2Fshared.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fcomm%2Fshared.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -279,17 +279,6 @@ impl<T: Send> Packet<T> {\n             // because the remote sender should finish their enqueue\n             // operation \"very quickly\".\n             //\n-            // Note that this yield loop does *not* attempt to do a green\n-            // yield (regardless of the context), but *always* performs an\n-            // OS-thread yield. The reasoning for this is that the pusher in\n-            // question which is causing the inconsistent state is\n-            // guaranteed to *not* be a blocked task (green tasks can't get\n-            // pre-empted), so it must be on a different OS thread. Also,\n-            // `try_recv` is normally a \"guaranteed no rescheduling\" context\n-            // in a green-thread situation. By yielding control of the\n-            // thread, we will hopefully allow time for the remote task on\n-            // the other OS thread to make progress.\n-            //\n             // Avoiding this yield loop would require a different queue\n             // abstraction which provides the guarantee that after M\n             // pushes have succeeded, at least M pops will succeed. The"}, {"sha": "1fece03b27364bb2194b1d69d8e19d4eef8d9185", "filename": "src/libsync/deque.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fdeque.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fdeque.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fdeque.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -414,7 +414,7 @@ mod tests {\n     use super::{Data, BufferPool, Abort, Empty, Worker, Stealer};\n \n     use std::mem;\n-    use std::rt::thread::Thread;\n+    use rustrt::thread::Thread;\n     use std::rand;\n     use std::rand::Rng;\n     use atomic::{AtomicBool, INIT_ATOMIC_BOOL, SeqCst,"}, {"sha": "9d6f6513a658fd84565642f2e16a59e7fccc669b", "filename": "src/libsync/lib.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -38,7 +38,6 @@ extern crate collections;\n extern crate rustrt;\n \n #[cfg(test)] extern crate test;\n-#[cfg(test)] extern crate native;\n #[cfg(test)] #[phase(plugin, link)] extern crate std;\n \n pub use alloc::arc::{Arc, Weak};\n@@ -54,7 +53,6 @@ pub mod atomic;\n \n // Concurrent data structures\n \n-mod mpsc_intrusive;\n pub mod spsc_queue;\n pub mod mpsc_queue;\n pub mod mpmc_bounded_queue;"}, {"sha": "1f7841de7c128995975ee49a46e230b76d117cae", "filename": "src/libsync/mpsc_intrusive.rs", "status": "removed", "additions": 0, "deletions": 144, "changes": 144, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibsync%2Fmpsc_intrusive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Flibsync%2Fmpsc_intrusive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmpsc_intrusive.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,144 +0,0 @@\n-/* Copyright (c) 2010-2011 Dmitry Vyukov. All rights reserved.\n- * Redistribution and use in source and binary forms, with or without\n- * modification, are permitted provided that the following conditions are met:\n- *\n- *    1. Redistributions of source code must retain the above copyright notice,\n- *       this list of conditions and the following disclaimer.\n- *\n- *    2. Redistributions in binary form must reproduce the above copyright\n- *       notice, this list of conditions and the following disclaimer in the\n- *       documentation and/or other materials provided with the distribution.\n- *\n- * THIS SOFTWARE IS PROVIDED BY DMITRY VYUKOV \"AS IS\" AND ANY EXPRESS OR IMPLIED\n- * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n- * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO\n- * EVENT SHALL DMITRY VYUKOV OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n- * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA,\n- * OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n- * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n- * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,\n- * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n- *\n- * The views and conclusions contained in the software and documentation are\n- * those of the authors and should not be interpreted as representing official\n- * policies, either expressed or implied, of Dmitry Vyukov.\n- */\n-\n-//! A mostly lock-free multi-producer, single consumer queue.\n-//!\n-//! This module implements an intrusive MPSC queue. This queue is incredibly\n-//! unsafe (due to use of unsafe pointers for nodes), and hence is not public.\n-\n-#![experimental]\n-\n-// http://www.1024cores.net/home/lock-free-algorithms\n-//                         /queues/intrusive-mpsc-node-based-queue\n-\n-use core::prelude::*;\n-\n-use core::atomic;\n-use core::mem;\n-use core::cell::UnsafeCell;\n-\n-// NB: all links are done as AtomicUint instead of AtomicPtr to allow for static\n-// initialization.\n-\n-pub struct Node<T> {\n-    pub next: atomic::AtomicUint,\n-    pub data: T,\n-}\n-\n-pub struct DummyNode {\n-    pub next: atomic::AtomicUint,\n-}\n-\n-pub struct Queue<T> {\n-    pub head: atomic::AtomicUint,\n-    pub tail: UnsafeCell<*mut Node<T>>,\n-    pub stub: DummyNode,\n-}\n-\n-impl<T: Send> Queue<T> {\n-    pub fn new() -> Queue<T> {\n-        Queue {\n-            head: atomic::AtomicUint::new(0),\n-            tail: UnsafeCell::new(0 as *mut Node<T>),\n-            stub: DummyNode {\n-                next: atomic::AtomicUint::new(0),\n-            },\n-        }\n-    }\n-\n-    pub unsafe fn push(&self, node: *mut Node<T>) {\n-        (*node).next.store(0, atomic::Release);\n-        let prev = self.head.swap(node as uint, atomic::AcqRel);\n-\n-        // Note that this code is slightly modified to allow static\n-        // initialization of these queues with rust's flavor of static\n-        // initialization.\n-        if prev == 0 {\n-            self.stub.next.store(node as uint, atomic::Release);\n-        } else {\n-            let prev = prev as *mut Node<T>;\n-            (*prev).next.store(node as uint, atomic::Release);\n-        }\n-    }\n-\n-    /// You'll note that the other MPSC queue in std::sync is non-intrusive and\n-    /// returns a `PopResult` here to indicate when the queue is inconsistent.\n-    /// An \"inconsistent state\" in the other queue means that a pusher has\n-    /// pushed, but it hasn't finished linking the rest of the chain.\n-    ///\n-    /// This queue also suffers from this problem, but I currently haven't been\n-    /// able to detangle when this actually happens. This code is translated\n-    /// verbatim from the website above, and is more complicated than the\n-    /// non-intrusive version.\n-    ///\n-    /// Right now consumers of this queue must be ready for this fact. Just\n-    /// because `pop` returns `None` does not mean that there is not data\n-    /// on the queue.\n-    pub unsafe fn pop(&self) -> Option<*mut Node<T>> {\n-        let tail = *self.tail.get();\n-        let mut tail = if !tail.is_null() {tail} else {\n-            mem::transmute(&self.stub)\n-        };\n-        let mut next = (*tail).next(atomic::Relaxed);\n-        if tail as uint == &self.stub as *const DummyNode as uint {\n-            if next.is_null() {\n-                return None;\n-            }\n-            *self.tail.get() = next;\n-            tail = next;\n-            next = (*next).next(atomic::Relaxed);\n-        }\n-        if !next.is_null() {\n-            *self.tail.get() = next;\n-            return Some(tail);\n-        }\n-        let head = self.head.load(atomic::Acquire) as *mut Node<T>;\n-        if tail != head {\n-            return None;\n-        }\n-        let stub = mem::transmute(&self.stub);\n-        self.push(stub);\n-        next = (*tail).next(atomic::Relaxed);\n-        if !next.is_null() {\n-            *self.tail.get() = next;\n-            return Some(tail);\n-        }\n-        return None\n-    }\n-}\n-\n-impl<T: Send> Node<T> {\n-    pub fn new(t: T) -> Node<T> {\n-        Node {\n-            data: t,\n-            next: atomic::AtomicUint::new(0),\n-        }\n-    }\n-    pub unsafe fn next(&self, ord: atomic::Ordering) -> *mut Node<T> {\n-        mem::transmute::<uint, *mut Node<T>>(self.next.load(ord))\n-    }\n-}"}, {"sha": "365609695ff4f74214cfa25ec2a86bc716914cfa", "filename": "src/libsync/mutex.rs", "status": "modified", "additions": 12, "deletions": 380, "changes": 392, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fmutex.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsync%2Fmutex.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsync%2Fmutex.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,80 +8,20 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-//! A proper mutex implementation regardless of the \"flavor of task\" which is\n-//! acquiring the lock.\n+//! A simple native mutex implementation. Warning: this API is likely\n+//! to change soon.\n \n-// # Implementation of Rust mutexes\n-//\n-// Most answers to the question of \"how do I use a mutex\" are \"use pthreads\",\n-// but for Rust this isn't quite sufficient. Green threads cannot acquire an OS\n-// mutex because they can context switch among many OS threads, leading to\n-// deadlocks with other green threads.\n-//\n-// Another problem for green threads grabbing an OS mutex is that POSIX dictates\n-// that unlocking a mutex on a different thread from where it was locked is\n-// undefined behavior. Remember that green threads can migrate among OS threads,\n-// so this would mean that we would have to pin green threads to OS threads,\n-// which is less than ideal.\n-//\n-// ## Using deschedule/reawaken\n-//\n-// We already have primitives for descheduling/reawakening tasks, so they're the\n-// first obvious choice when implementing a mutex. The idea would be to have a\n-// concurrent queue that everyone is pushed on to, and then the owner of the\n-// mutex is the one popping from the queue.\n-//\n-// Unfortunately, this is not very performant for native tasks. The suspected\n-// reason for this is that each native thread is suspended on its own condition\n-// variable, unique from all the other threads. In this situation, the kernel\n-// has no idea what the scheduling semantics are of the user program, so all of\n-// the threads are distributed among all cores on the system. This ends up\n-// having very expensive wakeups of remote cores high up in the profile when\n-// handing off the mutex among native tasks. On the other hand, when using an OS\n-// mutex, the kernel knows that all native threads are contended on the same\n-// mutex, so they're in theory all migrated to a single core (fast context\n-// switching).\n-//\n-// ## Mixing implementations\n-//\n-// From that above information, we have two constraints. The first is that\n-// green threads can't touch os mutexes, and the second is that native tasks\n-// pretty much *must* touch an os mutex.\n-//\n-// As a compromise, the queueing implementation is used for green threads and\n-// the os mutex is used for native threads (why not have both?). This ends up\n-// leading to fairly decent performance for both native threads and green\n-// threads on various workloads (uncontended and contended).\n-//\n-// The crux of this implementation is an atomic work which is CAS'd on many\n-// times in order to manage a few flags about who's blocking where and whether\n-// it's locked or not.\n+#![allow(dead_code)]\n \n use core::prelude::*;\n-use self::Flavor::*;\n-\n use alloc::boxed::Box;\n-use core::atomic;\n-use core::mem;\n-use core::cell::UnsafeCell;\n-use rustrt::local::Local;\n use rustrt::mutex;\n-use rustrt::task::{BlockedTask, Task};\n-use rustrt::thread::Thread;\n-\n-use mpsc_intrusive as q;\n \n pub const LOCKED: uint = 1 << 0;\n-pub const GREEN_BLOCKED: uint = 1 << 1;\n-pub const NATIVE_BLOCKED: uint = 1 << 2;\n+pub const BLOCKED: uint = 1 << 1;\n \n /// A mutual exclusion primitive useful for protecting shared data\n ///\n-/// This mutex is an implementation of a lock for all flavors of tasks which may\n-/// be grabbing. A common problem with green threads is that they cannot grab\n-/// locks (if they reschedule during the lock a contender could deadlock the\n-/// system), but this mutex does *not* suffer this problem.\n-///\n /// This mutex will properly block tasks waiting for the lock to become\n /// available. The mutex can also be statically initialized or created via a\n /// `new` constructor.\n@@ -107,14 +47,6 @@ pub struct Mutex {\n     lock: Box<StaticMutex>,\n }\n \n-#[deriving(PartialEq, Show)]\n-enum Flavor {\n-    Unlocked,\n-    TryLockAcquisition,\n-    GreenAcquisition,\n-    NativeAcquisition,\n-}\n-\n /// The static mutex type is provided to allow for static allocation of mutexes.\n ///\n /// Note that this is a separate type because using a Mutex correctly means that\n@@ -137,310 +69,35 @@ enum Flavor {\n /// // lock is unlocked here.\n /// ```\n pub struct StaticMutex {\n-    /// Current set of flags on this mutex\n-    state: atomic::AtomicUint,\n-    /// an OS mutex used by native threads\n     lock: mutex::StaticNativeMutex,\n-\n-    /// Type of locking operation currently on this mutex\n-    flavor: UnsafeCell<Flavor>,\n-    /// uint-cast of the green thread waiting for this mutex\n-    green_blocker: UnsafeCell<uint>,\n-    /// uint-cast of the native thread waiting for this mutex\n-    native_blocker: UnsafeCell<uint>,\n-\n-    /// A concurrent mpsc queue used by green threads, along with a count used\n-    /// to figure out when to dequeue and enqueue.\n-    q: q::Queue<uint>,\n-    green_cnt: atomic::AtomicUint,\n }\n \n /// An RAII implementation of a \"scoped lock\" of a mutex. When this structure is\n /// dropped (falls out of scope), the lock will be unlocked.\n #[must_use]\n pub struct Guard<'a> {\n-    lock: &'a StaticMutex,\n+    guard: mutex::LockGuard<'a>,\n+}\n+\n+fn lift_guard(guard: mutex::LockGuard) -> Guard {\n+    Guard { guard: guard }\n }\n \n /// Static initialization of a mutex. This constant can be used to initialize\n /// other mutex constants.\n pub const MUTEX_INIT: StaticMutex = StaticMutex {\n-    lock: mutex::NATIVE_MUTEX_INIT,\n-    state: atomic::INIT_ATOMIC_UINT,\n-    flavor: UnsafeCell { value: Unlocked },\n-    green_blocker: UnsafeCell { value: 0 },\n-    native_blocker: UnsafeCell { value: 0 },\n-    green_cnt: atomic::INIT_ATOMIC_UINT,\n-    q: q::Queue {\n-        head: atomic::INIT_ATOMIC_UINT,\n-        tail: UnsafeCell { value: 0 as *mut q::Node<uint> },\n-        stub: q::DummyNode {\n-            next: atomic::INIT_ATOMIC_UINT,\n-        }\n-    }\n+    lock: mutex::NATIVE_MUTEX_INIT\n };\n \n impl StaticMutex {\n     /// Attempts to grab this lock, see `Mutex::try_lock`\n     pub fn try_lock<'a>(&'a self) -> Option<Guard<'a>> {\n-        // Attempt to steal the mutex from an unlocked state.\n-        //\n-        // FIXME: this can mess up the fairness of the mutex, seems bad\n-        match self.state.compare_and_swap(0, LOCKED, atomic::SeqCst) {\n-            0 => {\n-                // After acquiring the mutex, we can safely access the inner\n-                // fields.\n-                let prev = unsafe {\n-                    mem::replace(&mut *self.flavor.get(), TryLockAcquisition)\n-                };\n-                assert_eq!(prev, Unlocked);\n-                Some(Guard::new(self))\n-            }\n-            _ => None\n-        }\n+        unsafe { self.lock.trylock().map(lift_guard) }\n     }\n \n     /// Acquires this lock, see `Mutex::lock`\n     pub fn lock<'a>(&'a self) -> Guard<'a> {\n-        // First, attempt to steal the mutex from an unlocked state. The \"fast\n-        // path\" needs to have as few atomic instructions as possible, and this\n-        // one cmpxchg is already pretty expensive.\n-        //\n-        // FIXME: this can mess up the fairness of the mutex, seems bad\n-        match self.try_lock() {\n-            Some(guard) => return guard,\n-            None => {}\n-        }\n-\n-        // After we've failed the fast path, then we delegate to the different\n-        // locking protocols for green/native tasks. This will select two tasks\n-        // to continue further (one native, one green).\n-        let t: Box<Task> = Local::take();\n-        let can_block = t.can_block();\n-        let native_bit;\n-        if can_block {\n-            self.native_lock(t);\n-            native_bit = NATIVE_BLOCKED;\n-        } else {\n-            self.green_lock(t);\n-            native_bit = GREEN_BLOCKED;\n-        }\n-\n-        // After we've arbitrated among task types, attempt to re-acquire the\n-        // lock (avoids a deschedule). This is very important to do in order to\n-        // allow threads coming out of the native_lock function to try their\n-        // best to not hit a cvar in deschedule.\n-        let mut old = match self.state.compare_and_swap(0, LOCKED,\n-                                                        atomic::SeqCst) {\n-            0 => {\n-                let flavor = if can_block {\n-                    NativeAcquisition\n-                } else {\n-                    GreenAcquisition\n-                };\n-                // We've acquired the lock, so this unsafe access to flavor is\n-                // allowed.\n-                unsafe { *self.flavor.get() = flavor; }\n-                return Guard::new(self)\n-            }\n-            old => old,\n-        };\n-\n-        // Alright, everything else failed. We need to deschedule ourselves and\n-        // flag ourselves as waiting. Note that this case should only happen\n-        // regularly in native/green contention. Due to try_lock and the header\n-        // of lock stealing the lock, it's also possible for native/native\n-        // contention to hit this location, but as less common.\n-        let t: Box<Task> = Local::take();\n-        t.deschedule(1, |task| {\n-            let task = unsafe { task.cast_to_uint() };\n-\n-            // These accesses are protected by the respective native/green\n-            // mutexes which were acquired above.\n-            let prev = if can_block {\n-                unsafe { mem::replace(&mut *self.native_blocker.get(), task) }\n-            } else {\n-                unsafe { mem::replace(&mut *self.green_blocker.get(), task) }\n-            };\n-            assert_eq!(prev, 0);\n-\n-            loop {\n-                assert_eq!(old & native_bit, 0);\n-                // If the old state was locked, then we need to flag ourselves\n-                // as blocking in the state. If the old state was unlocked, then\n-                // we attempt to acquire the mutex. Everything here is a CAS\n-                // loop that'll eventually make progress.\n-                if old & LOCKED != 0 {\n-                    old = match self.state.compare_and_swap(old,\n-                                                            old | native_bit,\n-                                                            atomic::SeqCst) {\n-                        n if n == old => return Ok(()),\n-                        n => n\n-                    };\n-                } else {\n-                    assert_eq!(old, 0);\n-                    old = match self.state.compare_and_swap(old,\n-                                                            old | LOCKED,\n-                                                            atomic::SeqCst) {\n-                        n if n == old => {\n-                            // After acquiring the lock, we have access to the\n-                            // flavor field, and we've regained access to our\n-                            // respective native/green blocker field.\n-                            let prev = if can_block {\n-                                unsafe {\n-                                    *self.native_blocker.get() = 0;\n-                                    mem::replace(&mut *self.flavor.get(),\n-                                                 NativeAcquisition)\n-                                }\n-                            } else {\n-                                unsafe {\n-                                    *self.green_blocker.get() = 0;\n-                                    mem::replace(&mut *self.flavor.get(),\n-                                                 GreenAcquisition)\n-                                }\n-                            };\n-                            assert_eq!(prev, Unlocked);\n-                            return Err(unsafe {\n-                                BlockedTask::cast_from_uint(task)\n-                            })\n-                        }\n-                        n => n,\n-                    };\n-                }\n-            }\n-        });\n-\n-        Guard::new(self)\n-    }\n-\n-    // Tasks which can block are super easy. These tasks just call the blocking\n-    // `lock()` function on an OS mutex\n-    fn native_lock(&self, t: Box<Task>) {\n-        Local::put(t);\n-        unsafe { self.lock.lock_noguard(); }\n-    }\n-\n-    fn native_unlock(&self) {\n-        unsafe { self.lock.unlock_noguard(); }\n-    }\n-\n-    fn green_lock(&self, t: Box<Task>) {\n-        // Green threads flag their presence with an atomic counter, and if they\n-        // fail to be the first to the mutex, they enqueue themselves on a\n-        // concurrent internal queue with a stack-allocated node.\n-        //\n-        // FIXME: There isn't a cancellation currently of an enqueue, forcing\n-        //        the unlocker to spin for a bit.\n-        if self.green_cnt.fetch_add(1, atomic::SeqCst) == 0 {\n-            Local::put(t);\n-            return\n-        }\n-\n-        let mut node = q::Node::new(0);\n-        t.deschedule(1, |task| {\n-            unsafe {\n-                node.data = task.cast_to_uint();\n-                self.q.push(&mut node);\n-            }\n-            Ok(())\n-        });\n-    }\n-\n-    fn green_unlock(&self) {\n-        // If we're the only green thread, then no need to check the queue,\n-        // otherwise the fixme above forces us to spin for a bit.\n-        if self.green_cnt.fetch_sub(1, atomic::SeqCst) == 1 { return }\n-        let node;\n-        loop {\n-            match unsafe { self.q.pop() } {\n-                Some(t) => { node = t; break; }\n-                None => Thread::yield_now(),\n-            }\n-        }\n-        let task = unsafe { BlockedTask::cast_from_uint((*node).data) };\n-        task.wake().map(|t| t.reawaken());\n-    }\n-\n-    fn unlock(&self) {\n-        // Unlocking this mutex is a little tricky. We favor any task that is\n-        // manually blocked (not in each of the separate locks) in order to help\n-        // provide a little fairness (green threads will wake up the pending\n-        // native thread and native threads will wake up the pending green\n-        // thread).\n-        //\n-        // There's also the question of when we unlock the actual green/native\n-        // locking halves as well. If we're waking up someone, then we can wait\n-        // to unlock until we've acquired the task to wake up (we're guaranteed\n-        // the mutex memory is still valid when there's contenders), but as soon\n-        // as we don't find any contenders we must unlock the mutex, and *then*\n-        // flag the mutex as unlocked.\n-        //\n-        // This flagging can fail, leading to another round of figuring out if a\n-        // task needs to be woken, and in this case it's ok that the \"mutex\n-        // halves\" are unlocked, we're just mainly dealing with the atomic state\n-        // of the outer mutex.\n-        let flavor = unsafe { mem::replace(&mut *self.flavor.get(), Unlocked) };\n-\n-        let mut state = self.state.load(atomic::SeqCst);\n-        let mut unlocked = false;\n-        let task;\n-        loop {\n-            assert!(state & LOCKED != 0);\n-            if state & GREEN_BLOCKED != 0 {\n-                self.unset(state, GREEN_BLOCKED);\n-                task = unsafe {\n-                    *self.flavor.get() = GreenAcquisition;\n-                    let task = mem::replace(&mut *self.green_blocker.get(), 0);\n-                    BlockedTask::cast_from_uint(task)\n-                };\n-                break;\n-            } else if state & NATIVE_BLOCKED != 0 {\n-                self.unset(state, NATIVE_BLOCKED);\n-                task = unsafe {\n-                    *self.flavor.get() = NativeAcquisition;\n-                    let task = mem::replace(&mut *self.native_blocker.get(), 0);\n-                    BlockedTask::cast_from_uint(task)\n-                };\n-                break;\n-            } else {\n-                assert_eq!(state, LOCKED);\n-                if !unlocked {\n-                    match flavor {\n-                        GreenAcquisition => { self.green_unlock(); }\n-                        NativeAcquisition => { self.native_unlock(); }\n-                        TryLockAcquisition => {}\n-                        Unlocked => unreachable!(),\n-                    }\n-                    unlocked = true;\n-                }\n-                match self.state.compare_and_swap(LOCKED, 0, atomic::SeqCst) {\n-                    LOCKED => return,\n-                    n => { state = n; }\n-                }\n-            }\n-        }\n-        if !unlocked {\n-            match flavor {\n-                GreenAcquisition => { self.green_unlock(); }\n-                NativeAcquisition => { self.native_unlock(); }\n-                TryLockAcquisition => {}\n-                Unlocked => unreachable!(),\n-            }\n-        }\n-\n-        task.wake().map(|t| t.reawaken());\n-    }\n-\n-    /// Loops around a CAS to unset the `bit` in `state`\n-    fn unset(&self, mut state: uint, bit: uint) {\n-        loop {\n-            assert!(state & bit != 0);\n-            let new = state ^ bit;\n-            match self.state.compare_and_swap(state, new, atomic::SeqCst) {\n-                n if n == state => break,\n-                n => { state = n; }\n-            }\n-        }\n+        lift_guard(unsafe { self.lock.lock() })\n     }\n \n     /// Deallocates resources associated with this static mutex.\n@@ -463,12 +120,6 @@ impl Mutex {\n     pub fn new() -> Mutex {\n         Mutex {\n             lock: box StaticMutex {\n-                state: atomic::AtomicUint::new(0),\n-                flavor: UnsafeCell::new(Unlocked),\n-                green_blocker: UnsafeCell::new(0),\n-                native_blocker: UnsafeCell::new(0),\n-                green_cnt: atomic::AtomicUint::new(0),\n-                q: q::Queue::new(),\n                 lock: unsafe { mutex::StaticNativeMutex::new() },\n             }\n         }\n@@ -494,25 +145,6 @@ impl Mutex {\n     pub fn lock<'a>(&'a self) -> Guard<'a> { self.lock.lock() }\n }\n \n-impl<'a> Guard<'a> {\n-    fn new<'b>(lock: &'b StaticMutex) -> Guard<'b> {\n-        if cfg!(debug) {\n-            // once we've acquired a lock, it's ok to access the flavor\n-            assert!(unsafe { *lock.flavor.get() != Unlocked });\n-            assert!(lock.state.load(atomic::SeqCst) & LOCKED != 0);\n-        }\n-        Guard { lock: lock }\n-    }\n-}\n-\n-#[unsafe_destructor]\n-impl<'a> Drop for Guard<'a> {\n-    #[inline]\n-    fn drop(&mut self) {\n-        self.lock.unlock();\n-    }\n-}\n-\n impl Drop for Mutex {\n     fn drop(&mut self) {\n         // This is actually safe b/c we know that there is no further usage of"}, {"sha": "e98be046586ea4c64d408c4c476dccf46f5a2fb7", "filename": "src/libsyntax/std_inject.rs", "status": "modified", "additions": 3, "deletions": 28, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsyntax%2Fstd_inject.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Flibsyntax%2Fstd_inject.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fstd_inject.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -22,10 +22,10 @@ use util::small_vector::SmallVector;\n \n use std::mem;\n \n-pub fn maybe_inject_crates_ref(krate: ast::Crate, alt_std_name: Option<String>, any_exe: bool)\n+pub fn maybe_inject_crates_ref(krate: ast::Crate, alt_std_name: Option<String>)\n                                -> ast::Crate {\n     if use_std(&krate) {\n-        inject_crates_ref(krate, alt_std_name, any_exe)\n+        inject_crates_ref(krate, alt_std_name)\n     } else {\n         krate\n     }\n@@ -43,17 +43,12 @@ fn use_std(krate: &ast::Crate) -> bool {\n     !attr::contains_name(krate.attrs.as_slice(), \"no_std\")\n }\n \n-fn use_start(krate: &ast::Crate) -> bool {\n-    !attr::contains_name(krate.attrs.as_slice(), \"no_start\")\n-}\n-\n fn no_prelude(attrs: &[ast::Attribute]) -> bool {\n     attr::contains_name(attrs, \"no_implicit_prelude\")\n }\n \n struct StandardLibraryInjector<'a> {\n     alt_std_name: Option<String>,\n-    any_exe: bool,\n }\n \n impl<'a> fold::Folder for StandardLibraryInjector<'a> {\n@@ -80,23 +75,6 @@ impl<'a> fold::Folder for StandardLibraryInjector<'a> {\n             span: DUMMY_SP\n         });\n \n-        if use_start(&krate) && self.any_exe {\n-            let visible_rt_name = \"rt\";\n-            let actual_rt_name = \"native\";\n-            // Gensym the ident so it can't be named\n-            let visible_rt_name = token::gensym_ident(visible_rt_name);\n-            let actual_rt_name = token::intern_and_get_ident(actual_rt_name);\n-\n-            vis.push(ast::ViewItem {\n-                node: ast::ViewItemExternCrate(visible_rt_name,\n-                                               Some((actual_rt_name, ast::CookedStr)),\n-                                               ast::DUMMY_NODE_ID),\n-                attrs: Vec::new(),\n-                vis: ast::Inherited,\n-                span: DUMMY_SP\n-            });\n-        }\n-\n         // `extern crate` must be precede `use` items\n         mem::swap(&mut vis, &mut krate.module.view_items);\n         krate.module.view_items.extend(vis.into_iter());\n@@ -118,12 +96,9 @@ impl<'a> fold::Folder for StandardLibraryInjector<'a> {\n     }\n }\n \n-fn inject_crates_ref(krate: ast::Crate,\n-                     alt_std_name: Option<String>,\n-                     any_exe: bool) -> ast::Crate {\n+fn inject_crates_ref(krate: ast::Crate, alt_std_name: Option<String>) -> ast::Crate {\n     let mut fold = StandardLibraryInjector {\n         alt_std_name: alt_std_name,\n-        any_exe: any_exe,\n     };\n     fold.fold_crate(krate)\n }"}, {"sha": "6f02bff9f310e5e4caee9a005a0c96f529db1c8b", "filename": "src/test/bench/rt-spawn-rate.rs", "status": "removed", "additions": 0, "deletions": 41, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Fbench%2Frt-spawn-rate.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Fbench%2Frt-spawn-rate.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Frt-spawn-rate.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,41 +0,0 @@\n-// Copyright 2013 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-#![no_start]\n-\n-extern crate green;\n-\n-use std::task::spawn;\n-use std::os;\n-use std::uint;\n-\n-// Very simple spawn rate test. Spawn N tasks that do nothing and\n-// return.\n-\n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    green::start(argc, argv, green::basic::event_loop, main)\n-}\n-\n-fn main() {\n-\n-    let args = os::args();\n-    let args = args.as_slice();\n-    let n = if args.len() == 2 {\n-        from_str::<uint>(args[1].as_slice()).unwrap()\n-    } else {\n-        100000\n-    };\n-\n-    for _ in range(0, n) {\n-        spawn(proc() {});\n-    }\n-\n-}"}, {"sha": "bc2723f6d74b3b2900577d78d43f2c66e31025ef", "filename": "src/test/bench/silly-test-spawn.rs", "status": "removed", "additions": 0, "deletions": 25, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Fbench%2Fsilly-test-spawn.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Fbench%2Fsilly-test-spawn.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fbench%2Fsilly-test-spawn.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,25 +0,0 @@\n-// Copyright 2012 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// This is (hopefully) a quick test to get a good idea about spawning\n-// performance in libgreen.\n-\n-extern crate green;\n-\n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    green::start(argc, argv, green::basic::event_loop, main)\n-}\n-\n-fn main() {\n-    for _ in range(1u32, 100_000) {\n-        spawn(proc() {})\n-    }\n-}"}, {"sha": "94a168a74ebb572972aa570ec3edd2ddcd761957", "filename": "src/test/pretty/issue-4264.pp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Fpretty%2Fissue-4264.pp", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Fpretty%2Fissue-4264.pp", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Fpretty%2Fissue-4264.pp?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -3,7 +3,6 @@\n #![feature(globs)]\n #[phase(plugin, link)]\n extern crate \"std\" as std;\n-extern crate \"native\" as rt;\n #[prelude_import]\n use std::prelude::*;\n // Copyright 2014 The Rust Project Developers. See the COPYRIGHT"}, {"sha": "0b261676cb2df24621081c3e5b778529c208c35a", "filename": "src/test/run-fail/native-panic.rs", "status": "removed", "additions": 0, "deletions": 21, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Frun-fail%2Fnative-panic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Frun-fail%2Fnative-panic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-fail%2Fnative-panic.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,21 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// ignore-android (FIXME #11419)\n-// error-pattern:explicit panic\n-\n-extern crate native;\n-\n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    native::start(argc, argv, proc() {\n-        panic!();\n-    })\n-}"}, {"sha": "34d9cc48ffe20385f40a344e1ba85bf36b816b8a", "filename": "src/test/run-make/bootstrap-from-c-with-native/lib.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-make%2Fbootstrap-from-c-with-native%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-make%2Fbootstrap-from-c-with-native%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-make%2Fbootstrap-from-c-with-native%2Flib.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -11,11 +11,11 @@\n #![crate_name=\"boot\"]\n #![crate_type=\"dylib\"]\n \n-extern crate native;\n+use std::rt;\n \n #[no_mangle] // this needs to get called from C\n pub extern \"C\" fn foo(argc: int, argv: *const *const u8) -> int {\n-    native::start(argc, argv, proc() {\n+    rt::start(argc, argv, proc() {\n         spawn(proc() {\n             println!(\"hello\");\n         });"}, {"sha": "a267b8dcc86d22a83b9be03aeff888bddf53f9a9", "filename": "src/test/run-pass/backtrace.rs", "status": "modified", "additions": 3, "deletions": 8, "changes": 11, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fbacktrace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fbacktrace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fbacktrace.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -10,18 +10,11 @@\n \n // no-pretty-expanded FIXME #15189\n // ignore-windows FIXME #13259\n-extern crate native;\n-\n use std::os;\n use std::io::process::Command;\n use std::finally::Finally;\n use std::str;\n \n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    native::start(argc, argv, main)\n-}\n-\n #[inline(never)]\n fn foo() {\n     let _v = vec![1i, 2, 3];\n@@ -64,7 +57,9 @@ fn runtest(me: &str) {\n     let out = p.wait_with_output().unwrap();\n     assert!(!out.status.success());\n     let s = str::from_utf8(out.error.as_slice()).unwrap();\n-    assert!(s.contains(\"stack backtrace\") && s.contains(\"double::h\"),\n+    // loosened the following from double::h to double:: due to\n+    // spurious failures on mac, 32bit, optimized\n+    assert!(s.contains(\"stack backtrace\") && s.contains(\"double::\"),\n             \"bad output3: {}\", s);\n \n     // Make sure a stack trace isn't printed too many times"}, {"sha": "a6744585e47a3ef240d88abc5c45b3e25110edff", "filename": "src/test/run-pass/capturing-logging.rs", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fcapturing-logging.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fcapturing-logging.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fcapturing-logging.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -15,7 +15,6 @@\n \n #[phase(plugin, link)]\n extern crate log;\n-extern crate native;\n \n use log::{set_logger, Logger, LogRecord};\n use std::fmt;\n@@ -30,13 +29,6 @@ impl Logger for MyWriter {\n     }\n }\n \n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    native::start(argc, argv, proc() {\n-        main();\n-    })\n-}\n-\n fn main() {\n     let (tx, rx) = channel();\n     let (mut r, w) = (ChanReader::new(rx), ChanWriter::new(tx));"}, {"sha": "af36387f06c2c9fb46d32ace369c0518507529ad", "filename": "src/test/run-pass/foreign-call-no-runtime.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fforeign-call-no-runtime.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fforeign-call-no-runtime.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fforeign-call-no-runtime.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -9,9 +9,10 @@\n // except according to those terms.\n \n extern crate libc;\n+extern crate rustrt;\n \n use std::mem;\n-use std::rt::thread::Thread;\n+use rustrt::thread::Thread;\n \n #[link(name = \"rust_test_helpers\")]\n extern {"}, {"sha": "2dc25181606ab5cd7e98b817064c95a3dee78c45", "filename": "src/test/run-pass/issue-12699.rs", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fissue-12699.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fissue-12699.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-12699.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,17 +8,9 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-\n-extern crate native;\n-\n use std::io::timer;\n use std::time::Duration;\n \n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    native::start(argc, argv, main)\n-}\n-\n fn main() {\n     timer::sleep(Duration::milliseconds(250));\n }"}, {"sha": "35f713c4c2c0bc23cebf873d79be9970c9e40916", "filename": "src/test/run-pass/issue-8860.rs", "status": "modified", "additions": 10, "deletions": 15, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fissue-8860.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fissue-8860.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fissue-8860.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,24 +8,10 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-\n-extern crate green;\n-\n static mut DROP: int = 0i;\n static mut DROP_S: int = 0i;\n static mut DROP_T: int = 0i;\n \n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    let ret = green::start(argc, argv, green::basic::event_loop, main);\n-    unsafe {\n-        assert_eq!(2, DROP);\n-        assert_eq!(1, DROP_S);\n-        assert_eq!(1, DROP_T);\n-    }\n-    ret\n-}\n-\n struct S;\n impl Drop for S {\n     fn drop(&mut self) {\n@@ -48,7 +34,7 @@ impl Drop for T {\n }\n fn g(ref _t: T) {}\n \n-fn main() {\n+fn do_test() {\n     let s = S;\n     f(s);\n     unsafe {\n@@ -59,3 +45,12 @@ fn main() {\n     g(t);\n     unsafe { assert_eq!(1, DROP_T); }\n }\n+\n+fn main() {\n+    do_test();\n+    unsafe {\n+        assert_eq!(2, DROP);\n+        assert_eq!(1, DROP_S);\n+        assert_eq!(1, DROP_T);\n+    }\n+}"}, {"sha": "ac783961b508e8363d8f492a8cd6afa0edea23b2", "filename": "src/test/run-pass/match-ref-binding-in-guard-3256.rs", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fmatch-ref-binding-in-guard-3256.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fmatch-ref-binding-in-guard-3256.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fmatch-ref-binding-in-guard-3256.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,9 +8,11 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+extern crate rustrt;\n+\n pub fn main() {\n     unsafe {\n-        let x = Some(::std::rt::exclusive::Exclusive::new(true));\n+        let x = Some(::rustrt::exclusive::Exclusive::new(true));\n         match x {\n             Some(ref z) if *z.lock() => {\n                 assert!(*z.lock());"}, {"sha": "ea3eb29964883520cdfe2eefc82f84d0a9177517", "filename": "src/test/run-pass/native-always-waits.rs", "status": "removed", "additions": 0, "deletions": 28, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Frun-pass%2Fnative-always-waits.rs", "raw_url": "https://github.com/rust-lang/rust/raw/98300516072c6afd0e93654b325f5924b60dea53/src%2Ftest%2Frun-pass%2Fnative-always-waits.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fnative-always-waits.rs?ref=98300516072c6afd0e93654b325f5924b60dea53", "patch": "@@ -1,28 +0,0 @@\n-// Copyright 2014 The Rust Project Developers. See the COPYRIGHT\n-// file at the top-level directory of this distribution and at\n-// http://rust-lang.org/COPYRIGHT.\n-//\n-// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n-// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n-// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n-// option. This file may not be copied, modified, or distributed\n-// except according to those terms.\n-\n-// ignore-android (FIXME #11419)\n-\n-extern crate native;\n-\n-static mut set: bool = false;\n-\n-#[start]\n-fn start(argc: int, argv: *const *const u8) -> int {\n-    // make sure that native::start always waits for all children to finish\n-    native::start(argc, argv, proc() {\n-        spawn(proc() {\n-            unsafe { set = true; }\n-        });\n-    });\n-\n-    // if we didn't set the global, then return a nonzero code\n-    if unsafe {set} {0} else {1}\n-}"}, {"sha": "21847a486d949f574fb87f7781e84abd5adb78c4", "filename": "src/test/run-pass/out-of-stack-new-thread-no-split.rs", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fout-of-stack-new-thread-no-split.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fout-of-stack-new-thread-no-split.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fout-of-stack-new-thread-no-split.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -36,9 +36,12 @@ fn main() {\n     let args = os::args();\n     let args = args.as_slice();\n     if args.len() > 1 && args[1].as_slice() == \"recurse\" {\n+        let (tx, rx) = channel();\n         spawn(proc() {\n             recurse();\n+            tx.send(());\n         });\n+        rx.recv();\n     } else {\n         let recurse = Command::new(args[0].as_slice()).arg(\"recurse\").output().unwrap();\n         assert!(!recurse.status.success());"}, {"sha": "cceb0bf4d96e832d8de6a2f22d8d447370e96caf", "filename": "src/test/run-pass/process-spawn-with-unicode-params.rs", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fprocess-spawn-with-unicode-params.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fprocess-spawn-with-unicode-params.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fprocess-spawn-with-unicode-params.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -16,8 +16,6 @@\n // non-ASCII characters.  The child process ensures all the strings are\n // intact.\n \n-extern crate native;\n-\n use std::io;\n use std::io::fs;\n use std::io::Command;"}, {"sha": "ed4c20c80943ab58ca9a98ef0683e8dfc7a3e54a", "filename": "src/test/run-pass/running-with-no-runtime.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Frunning-with-no-runtime.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Frunning-with-no-runtime.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Frunning-with-no-runtime.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,12 +8,14 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n-extern crate native;\n+extern crate rustrt;\n \n use std::io::process::{Command, ProcessOutput};\n use std::os;\n use std::str;\n-use std::rt::unwind::try;\n+use std::rt;\n+\n+use rustrt::unwind::try;\n \n local_data_key!(foo: int)\n \n@@ -36,7 +38,7 @@ fn start(argc: int, argv: *const *const u8) -> int {\n         return 0\n     }\n \n-    native::start(argc, argv, main)\n+    rt::start(argc, argv, main)\n }\n \n fn main() {"}, {"sha": "c8d281a791c90f760a1e0653b56d84768bad3894", "filename": "src/test/run-pass/writealias.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fwritealias.rs", "raw_url": "https://github.com/rust-lang/rust/raw/c9f6d696420107f82304b992cf623b806995fe18/src%2Ftest%2Frun-pass%2Fwritealias.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Ftest%2Frun-pass%2Fwritealias.rs?ref=c9f6d696420107f82304b992cf623b806995fe18", "patch": "@@ -8,14 +8,15 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+extern crate rustrt;\n \n struct Point {x: int, y: int, z: int}\n \n fn f(p: &mut Point) { p.z = 13; }\n \n pub fn main() {\n     unsafe {\n-        let x = Some(::std::rt::exclusive::Exclusive::new(true));\n+        let x = Some(::rustrt::exclusive::Exclusive::new(true));\n         match x {\n             Some(ref z) if *z.lock() => {\n                 assert!(*z.lock());"}]}