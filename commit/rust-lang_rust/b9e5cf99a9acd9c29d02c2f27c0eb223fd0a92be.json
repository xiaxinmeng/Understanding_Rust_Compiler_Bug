{"sha": "b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "node_id": "MDY6Q29tbWl0NzI0NzEyOmI5ZTVjZjk5YTlhY2Q5YzI5ZDAyYzJmMjdjMGViMjIzZmQwYTkyYmU=", "commit": {"author": {"name": "Denis Merigoux", "email": "denis.merigoux@gmail.com", "date": "2018-10-23T15:01:35Z"}, "committer": {"name": "Eduard-Mihai Burtescu", "email": "edy.burt@gmail.com", "date": "2018-11-16T13:08:18Z"}, "message": "Separating the back folder between backend-agnostic and LLVM-specific code", "tree": {"sha": "1a71a1dc4a8bf0ee5d36f9aa49de11cef2750a83", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/1a71a1dc4a8bf0ee5d36f9aa49de11cef2750a83"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "html_url": "https://github.com/rust-lang/rust/commit/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/comments", "author": {"login": "denismerigoux", "id": 1766128, "node_id": "MDQ6VXNlcjE3NjYxMjg=", "avatar_url": "https://avatars.githubusercontent.com/u/1766128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/denismerigoux", "html_url": "https://github.com/denismerigoux", "followers_url": "https://api.github.com/users/denismerigoux/followers", "following_url": "https://api.github.com/users/denismerigoux/following{/other_user}", "gists_url": "https://api.github.com/users/denismerigoux/gists{/gist_id}", "starred_url": "https://api.github.com/users/denismerigoux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/denismerigoux/subscriptions", "organizations_url": "https://api.github.com/users/denismerigoux/orgs", "repos_url": "https://api.github.com/users/denismerigoux/repos", "events_url": "https://api.github.com/users/denismerigoux/events{/privacy}", "received_events_url": "https://api.github.com/users/denismerigoux/received_events", "type": "User", "site_admin": false}, "committer": {"login": "eddyb", "id": 77424, "node_id": "MDQ6VXNlcjc3NDI0", "avatar_url": "https://avatars.githubusercontent.com/u/77424?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eddyb", "html_url": "https://github.com/eddyb", "followers_url": "https://api.github.com/users/eddyb/followers", "following_url": "https://api.github.com/users/eddyb/following{/other_user}", "gists_url": "https://api.github.com/users/eddyb/gists{/gist_id}", "starred_url": "https://api.github.com/users/eddyb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eddyb/subscriptions", "organizations_url": "https://api.github.com/users/eddyb/orgs", "repos_url": "https://api.github.com/users/eddyb/repos", "events_url": "https://api.github.com/users/eddyb/events{/privacy}", "received_events_url": "https://api.github.com/users/eddyb/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "b25b80401384dc97731909c86557e74598890c4b", "url": "https://api.github.com/repos/rust-lang/rust/commits/b25b80401384dc97731909c86557e74598890c4b", "html_url": "https://github.com/rust-lang/rust/commit/b25b80401384dc97731909c86557e74598890c4b"}], "stats": {"total": 5191, "additions": 2724, "deletions": 2467}, "files": [{"sha": "8b7f3591a2505fc6ce463c3fe68c487fb851f8eb", "filename": "src/Cargo.lock", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2FCargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2FCargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2FCargo.lock?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -2129,6 +2129,12 @@ dependencies = [\n [[package]]\n name = \"rustc_codegen_ssa\"\n version = \"0.0.0\"\n+dependencies = [\n+ \"cc 1.0.25 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"memmap 0.6.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"num_cpus 1.8.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"rustc-demangle 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n+]\n \n [[package]]\n name = \"rustc_codegen_utils\"\n@@ -2137,13 +2143,11 @@ dependencies = [\n  \"flate2 1.0.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"log 0.4.5 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"rustc 0.0.0\",\n- \"rustc_allocator 0.0.0\",\n  \"rustc_data_structures 0.0.0\",\n  \"rustc_incremental 0.0.0\",\n  \"rustc_metadata 0.0.0\",\n  \"rustc_mir 0.0.0\",\n  \"rustc_target 0.0.0\",\n- \"serialize 0.0.0\",\n  \"syntax 0.0.0\",\n  \"syntax_pos 0.0.0\",\n ]"}, {"sha": "76c50711639a4a10db73931dbedb64409465390d", "filename": "src/librustc_codegen_llvm/back/archive.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Farchive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Farchive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Farchive.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -18,6 +18,7 @@ use std::ptr;\n use std::str;\n \n use back::bytecode::RLIB_BYTECODE_EXTENSION;\n+use rustc_codegen_ssa::back::archive::find_library;\n use libc;\n use llvm::archive_ro::{ArchiveRO, Child};\n use llvm::{self, ArchiveKind};\n@@ -52,7 +53,6 @@ enum Addition {\n     },\n }\n \n-\n fn is_relevant_child(c: &Child) -> bool {\n     match c.name() {\n         Some(name) => !name.contains(\"SYMDEF\"),\n@@ -107,7 +107,7 @@ impl<'a> ArchiveBuilder<'a> {\n     /// Adds all of the contents of a native library to this archive. This will\n     /// search in the relevant locations for a library named `name`.\n     pub fn add_native_library(&mut self, name: &str) {\n-        let location = ::rustc_codegen_utils::find_library(name, &self.config.lib_search_paths,\n+        let location = find_library(name, &self.config.lib_search_paths,\n                                     self.config.sess);\n         self.add_archive(&location, |_| false).unwrap_or_else(|e| {\n             self.config.sess.fatal(&format!(\"failed to add native library {}: {}\","}, {"sha": "20f05d110877a242184bbaa6a358a327ee0b21e9", "filename": "src/librustc_codegen_llvm/back/link.rs", "status": "modified", "additions": 11, "deletions": 188, "changes": 199, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Flink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Flink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flink.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -9,9 +9,12 @@\n // except according to those terms.\n \n use back::wasm;\n-use cc::windows_registry;\n use super::archive::{ArchiveBuilder, ArchiveConfig};\n use super::bytecode::RLIB_BYTECODE_EXTENSION;\n+use rustc_codegen_ssa::back::linker::Linker;\n+use rustc_codegen_ssa::back::link::{remove, ignored_for_lto, each_linked_rlib, linker_and_flavor,\n+    get_linker};\n+use rustc_codegen_ssa::back::command::Command;\n use super::rpath::RPathConfig;\n use super::rpath;\n use metadata::METADATA_FILENAME;\n@@ -20,18 +23,15 @@ use rustc::session::config::{RUST_CGU_EXT, Lto};\n use rustc::session::filesearch;\n use rustc::session::search_paths::PathKind;\n use rustc::session::Session;\n-use rustc::middle::cstore::{NativeLibrary, LibSource, NativeLibraryKind};\n+use rustc::middle::cstore::{NativeLibrary, NativeLibraryKind};\n use rustc::middle::dependency_format::Linkage;\n-use rustc_codegen_ssa::CrateInfo;\n-use CodegenResults;\n+use rustc_codegen_ssa::CodegenResults;\n use rustc::util::common::time;\n use rustc_fs_util::fix_windows_verbatim_for_gcc;\n use rustc::hir::def_id::CrateNum;\n use tempfile::{Builder as TempFileBuilder, TempDir};\n use rustc_target::spec::{PanicStrategy, RelroLevel, LinkerFlavor};\n use rustc_data_structures::fx::FxHashSet;\n-use rustc_codegen_utils::linker::Linker;\n-use rustc_codegen_utils::command::Command;\n use context::get_reloc_model;\n use llvm;\n \n@@ -51,69 +51,6 @@ pub use rustc_codegen_utils::link::{find_crate_name, filename_for_input, default\n                                     invalid_output_for_target, filename_for_metadata,\n                                     out_filename, check_file_is_writeable};\n \n-// The third parameter is for env vars, used on windows to set up the\n-// path for MSVC to find its DLLs, and gcc to find its bundled\n-// toolchain\n-pub fn get_linker(sess: &Session, linker: &Path, flavor: LinkerFlavor) -> (PathBuf, Command) {\n-    let msvc_tool = windows_registry::find_tool(&sess.opts.target_triple.triple(), \"link.exe\");\n-\n-    // If our linker looks like a batch script on Windows then to execute this\n-    // we'll need to spawn `cmd` explicitly. This is primarily done to handle\n-    // emscripten where the linker is `emcc.bat` and needs to be spawned as\n-    // `cmd /c emcc.bat ...`.\n-    //\n-    // This worked historically but is needed manually since #42436 (regression\n-    // was tagged as #42791) and some more info can be found on #44443 for\n-    // emscripten itself.\n-    let mut cmd = match linker.to_str() {\n-        Some(linker) if cfg!(windows) && linker.ends_with(\".bat\") => Command::bat_script(linker),\n-        _ => match flavor {\n-            LinkerFlavor::Lld(f) => Command::lld(linker, f),\n-            LinkerFlavor::Msvc\n-                if sess.opts.cg.linker.is_none() && sess.target.target.options.linker.is_none() =>\n-            {\n-                Command::new(msvc_tool.as_ref().map(|t| t.path()).unwrap_or(linker))\n-            },\n-            _ => Command::new(linker),\n-        }\n-    };\n-\n-    // The compiler's sysroot often has some bundled tools, so add it to the\n-    // PATH for the child.\n-    let mut new_path = sess.host_filesearch(PathKind::All)\n-                           .get_tools_search_paths();\n-    let mut msvc_changed_path = false;\n-    if sess.target.target.options.is_like_msvc {\n-        if let Some(ref tool) = msvc_tool {\n-            cmd.args(tool.args());\n-            for &(ref k, ref v) in tool.env() {\n-                if k == \"PATH\" {\n-                    new_path.extend(env::split_paths(v));\n-                    msvc_changed_path = true;\n-                } else {\n-                    cmd.env(k, v);\n-                }\n-            }\n-        }\n-    }\n-\n-    if !msvc_changed_path {\n-        if let Some(path) = env::var_os(\"PATH\") {\n-            new_path.extend(env::split_paths(&path));\n-        }\n-    }\n-    cmd.env(\"PATH\", env::join_paths(new_path).unwrap());\n-\n-    (linker.to_path_buf(), cmd)\n-}\n-\n-pub fn remove(sess: &Session, path: &Path) {\n-    if let Err(e) = fs::remove_file(path) {\n-        sess.err(&format!(\"failed to remove {}: {}\",\n-                          path.display(),\n-                          e));\n-    }\n-}\n \n /// Perform the linkage portion of the compilation phase. This will generate all\n /// of the requested outputs for this compilation session.\n@@ -215,60 +152,6 @@ fn preserve_objects_for_their_debuginfo(sess: &Session) -> bool {\n     false\n }\n \n-pub(crate) fn each_linked_rlib(sess: &Session,\n-                               info: &CrateInfo,\n-                               f: &mut dyn FnMut(CrateNum, &Path)) -> Result<(), String> {\n-    let crates = info.used_crates_static.iter();\n-    let fmts = sess.dependency_formats.borrow();\n-    let fmts = fmts.get(&config::CrateType::Executable)\n-                   .or_else(|| fmts.get(&config::CrateType::Staticlib))\n-                   .or_else(|| fmts.get(&config::CrateType::Cdylib))\n-                   .or_else(|| fmts.get(&config::CrateType::ProcMacro));\n-    let fmts = match fmts {\n-        Some(f) => f,\n-        None => return Err(\"could not find formats for rlibs\".to_string())\n-    };\n-    for &(cnum, ref path) in crates {\n-        match fmts.get(cnum.as_usize() - 1) {\n-            Some(&Linkage::NotLinked) |\n-            Some(&Linkage::IncludedFromDylib) => continue,\n-            Some(_) => {}\n-            None => return Err(\"could not find formats for rlibs\".to_string())\n-        }\n-        let name = &info.crate_name[&cnum];\n-        let path = match *path {\n-            LibSource::Some(ref p) => p,\n-            LibSource::MetadataOnly => {\n-                return Err(format!(\"could not find rlib for: `{}`, found rmeta (metadata) file\",\n-                                   name))\n-            }\n-            LibSource::None => {\n-                return Err(format!(\"could not find rlib for: `{}`\", name))\n-            }\n-        };\n-        f(cnum, &path);\n-    }\n-    Ok(())\n-}\n-\n-/// Returns a boolean indicating whether the specified crate should be ignored\n-/// during LTO.\n-///\n-/// Crates ignored during LTO are not lumped together in the \"massive object\n-/// file\" that we create and are linked in their normal rlib states. See\n-/// comments below for what crates do not participate in LTO.\n-///\n-/// It's unusual for a crate to not participate in LTO. Typically only\n-/// compiler-specific and unstable crates have a reason to not participate in\n-/// LTO.\n-pub(crate) fn ignored_for_lto(sess: &Session, info: &CrateInfo, cnum: CrateNum) -> bool {\n-    // If our target enables builtin function lowering in LLVM then the\n-    // crates providing these functions don't participate in LTO (e.g.\n-    // no_builtins or compiler builtins crates).\n-    !sess.target.target.options.no_builtins &&\n-        (info.compiler_builtins == Some(cnum) || info.is_no_builtins.contains(&cnum))\n-}\n-\n fn link_binary_output(sess: &Session,\n                       codegen_results: &CodegenResults,\n                       crate_type: config::CrateType,\n@@ -353,8 +236,11 @@ fn archive_config<'a>(sess: &'a Session,\n /// building an `.rlib` (stomping over one another), or writing an `.rmeta` into a\n /// directory being searched for `extern crate` (observing an incomplete file).\n /// The returned path is the temporary file containing the complete metadata.\n-fn emit_metadata<'a>(sess: &'a Session, codegen_results: &CodegenResults, tmpdir: &TempDir)\n-                     -> PathBuf {\n+fn emit_metadata<'a>(\n+    sess: &'a Session,\n+    codegen_results: &CodegenResults,\n+    tmpdir: &TempDir\n+) -> PathBuf {\n     let out_filename = tmpdir.path().join(METADATA_FILENAME);\n     let result = fs::write(&out_filename, &codegen_results.metadata.raw_data);\n \n@@ -576,69 +462,6 @@ fn print_native_static_libs(sess: &Session, all_native_libs: &[NativeLibrary]) {\n     }\n }\n \n-pub fn linker_and_flavor(sess: &Session) -> (PathBuf, LinkerFlavor) {\n-    fn infer_from(\n-        sess: &Session,\n-        linker: Option<PathBuf>,\n-        flavor: Option<LinkerFlavor>,\n-    ) -> Option<(PathBuf, LinkerFlavor)> {\n-        match (linker, flavor) {\n-            (Some(linker), Some(flavor)) => Some((linker, flavor)),\n-            // only the linker flavor is known; use the default linker for the selected flavor\n-            (None, Some(flavor)) => Some((PathBuf::from(match flavor {\n-                LinkerFlavor::Em  => if cfg!(windows) { \"emcc.bat\" } else { \"emcc\" },\n-                LinkerFlavor::Gcc => \"cc\",\n-                LinkerFlavor::Ld => \"ld\",\n-                LinkerFlavor::Msvc => \"link.exe\",\n-                LinkerFlavor::Lld(_) => \"lld\",\n-            }), flavor)),\n-            (Some(linker), None) => {\n-                let stem = linker.file_stem().and_then(|stem| stem.to_str()).unwrap_or_else(|| {\n-                    sess.fatal(\"couldn't extract file stem from specified linker\");\n-                }).to_owned();\n-\n-                let flavor = if stem == \"emcc\" {\n-                    LinkerFlavor::Em\n-                } else if stem == \"gcc\" || stem.ends_with(\"-gcc\") {\n-                    LinkerFlavor::Gcc\n-                } else if stem == \"ld\" || stem == \"ld.lld\" || stem.ends_with(\"-ld\") {\n-                    LinkerFlavor::Ld\n-                } else if stem == \"link\" || stem == \"lld-link\" {\n-                    LinkerFlavor::Msvc\n-                } else if stem == \"lld\" || stem == \"rust-lld\" {\n-                    LinkerFlavor::Lld(sess.target.target.options.lld_flavor)\n-                } else {\n-                    // fall back to the value in the target spec\n-                    sess.target.target.linker_flavor\n-                };\n-\n-                Some((linker, flavor))\n-            },\n-            (None, None) => None,\n-        }\n-    }\n-\n-    // linker and linker flavor specified via command line have precedence over what the target\n-    // specification specifies\n-    if let Some(ret) = infer_from(\n-        sess,\n-        sess.opts.cg.linker.clone(),\n-        sess.opts.debugging_opts.linker_flavor,\n-    ) {\n-        return ret;\n-    }\n-\n-    if let Some(ret) = infer_from(\n-        sess,\n-        sess.target.target.options.linker.clone().map(PathBuf::from),\n-        Some(sess.target.target.linker_flavor),\n-    ) {\n-        return ret;\n-    }\n-\n-    bug!(\"Not enough information provided to determine how to invoke the linker\");\n-}\n-\n // Create a dynamic library or executable\n //\n // This will invoke the system linker/cc to create the resulting file. This"}, {"sha": "a5f07e46e11fe5da8fe8aba29f59f5936cccfcc6", "filename": "src/librustc_codegen_llvm/back/lto.rs", "status": "modified", "additions": 164, "deletions": 260, "changes": 424, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Flto.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -9,22 +9,23 @@\n // except according to those terms.\n \n use back::bytecode::{DecodedBytecode, RLIB_BYTECODE_EXTENSION};\n-use back::write::{ModuleConfig, with_llvm_pmb, CodegenContext};\n-use back::write::{self, DiagnosticHandlers, pre_lto_bitcode_filename};\n+use rustc_codegen_ssa::back::symbol_export;\n+use rustc_codegen_ssa::back::write::{ModuleConfig, CodegenContext, pre_lto_bitcode_filename};\n+use rustc_codegen_ssa::back::lto::{SerializedModule, LtoModuleCodegen, ThinShared, ThinModule};\n+use rustc_codegen_ssa::interfaces::*;\n+use back::write::{self, DiagnosticHandlers, with_llvm_pmb, save_temp_bitcode, get_llvm_opt_level};\n use errors::{FatalError, Handler};\n use llvm::archive_ro::ArchiveRO;\n use llvm::{self, True, False};\n-use memmap;\n use rustc::dep_graph::WorkProduct;\n use rustc::dep_graph::cgu_reuse_tracker::CguReuse;\n use rustc::hir::def_id::LOCAL_CRATE;\n use rustc::middle::exported_symbols::SymbolExportLevel;\n use rustc::session::config::{self, Lto};\n use rustc::util::common::time_ext;\n use rustc_data_structures::fx::FxHashMap;\n-use rustc_codegen_utils::symbol_export;\n use time_graph::Timeline;\n-use ModuleLlvm;\n+use {ModuleLlvm, LlvmCodegenBackend};\n use rustc_codegen_ssa::{ModuleCodegen, ModuleKind};\n \n use libc;\n@@ -47,71 +48,16 @@ pub fn crate_type_allows_lto(crate_type: config::CrateType) -> bool {\n     }\n }\n \n-pub(crate) enum LtoModuleCodegen {\n-    Fat {\n-        module: Option<ModuleCodegen<ModuleLlvm>>,\n-        _serialized_bitcode: Vec<SerializedModule>,\n-    },\n-\n-    Thin(ThinModule),\n-}\n-\n-impl LtoModuleCodegen {\n-    pub fn name(&self) -> &str {\n-        match *self {\n-            LtoModuleCodegen::Fat { .. } => \"everything\",\n-            LtoModuleCodegen::Thin(ref m) => m.name(),\n-        }\n-    }\n-\n-    /// Optimize this module within the given codegen context.\n-    ///\n-    /// This function is unsafe as it'll return a `ModuleCodegen` still\n-    /// points to LLVM data structures owned by this `LtoModuleCodegen`.\n-    /// It's intended that the module returned is immediately code generated and\n-    /// dropped, and then this LTO module is dropped.\n-    pub(crate) unsafe fn optimize(&mut self,\n-                                  cgcx: &CodegenContext,\n-                                  timeline: &mut Timeline)\n-        -> Result<ModuleCodegen<ModuleLlvm>, FatalError>\n-    {\n-        match *self {\n-            LtoModuleCodegen::Fat { ref mut module, .. } => {\n-                let module = module.take().unwrap();\n-                {\n-                    let config = cgcx.config(module.kind);\n-                    let llmod = module.module_llvm.llmod();\n-                    let tm = &*module.module_llvm.tm;\n-                    run_pass_manager(cgcx, tm, llmod, config, false);\n-                    timeline.record(\"fat-done\");\n-                }\n-                Ok(module)\n-            }\n-            LtoModuleCodegen::Thin(ref mut thin) => thin.optimize(cgcx, timeline),\n-        }\n-    }\n-\n-    /// A \"gauge\" of how costly it is to optimize this module, used to sort\n-    /// biggest modules first.\n-    pub fn cost(&self) -> u64 {\n-        match *self {\n-            // Only one module with fat LTO, so the cost doesn't matter.\n-            LtoModuleCodegen::Fat { .. } => 0,\n-            LtoModuleCodegen::Thin(ref m) => m.cost(),\n-        }\n-    }\n-}\n-\n /// Performs LTO, which in the case of full LTO means merging all modules into\n /// a single one and returning it for further optimizing. For ThinLTO, it will\n /// do the global analysis necessary and return two lists, one of the modules\n /// the need optimization and another for modules that can simply be copied over\n /// from the incr. comp. cache.\n-pub(crate) fn run(cgcx: &CodegenContext,\n+pub(crate) fn run(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                   modules: Vec<ModuleCodegen<ModuleLlvm>>,\n-                  cached_modules: Vec<(SerializedModule, WorkProduct)>,\n+                  cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n                   timeline: &mut Timeline)\n-    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n+    -> Result<(Vec<LtoModuleCodegen<LlvmCodegenBackend>>, Vec<WorkProduct>), FatalError>\n {\n     let diag_handler = cgcx.create_diag_handler();\n     let export_threshold = match cgcx.lto {\n@@ -230,13 +176,13 @@ pub(crate) fn run(cgcx: &CodegenContext,\n     }\n }\n \n-fn fat_lto(cgcx: &CodegenContext,\n+fn fat_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n            diag_handler: &Handler,\n            mut modules: Vec<ModuleCodegen<ModuleLlvm>>,\n-           mut serialized_modules: Vec<(SerializedModule, CString)>,\n+           mut serialized_modules: Vec<(SerializedModule<ModuleBuffer>, CString)>,\n            symbol_white_list: &[*const libc::c_char],\n            timeline: &mut Timeline)\n-    -> Result<Vec<LtoModuleCodegen>, FatalError>\n+    -> Result<Vec<LtoModuleCodegen<LlvmCodegenBackend>>, FatalError>\n {\n     info!(\"going for a fat lto\");\n \n@@ -303,7 +249,7 @@ fn fat_lto(cgcx: &CodegenContext,\n             serialized_bitcode.push(bc_decoded);\n         }\n         drop(linker);\n-        cgcx.save_temp_bitcode(&module, \"lto.input\");\n+        save_temp_bitcode(&cgcx, &module, \"lto.input\");\n \n         // Internalize everything that *isn't* in our whitelist to help strip out\n         // more modules and such\n@@ -312,14 +258,14 @@ fn fat_lto(cgcx: &CodegenContext,\n             llvm::LLVMRustRunRestrictionPass(llmod,\n                                              ptr as *const *const libc::c_char,\n                                              symbol_white_list.len() as libc::size_t);\n-            cgcx.save_temp_bitcode(&module, \"lto.after-restriction\");\n+            save_temp_bitcode(&cgcx, &module, \"lto.after-restriction\");\n         }\n \n         if cgcx.no_landing_pads {\n             unsafe {\n                 llvm::LLVMRustMarkAllFunctionsNounwind(llmod);\n             }\n-            cgcx.save_temp_bitcode(&module, \"lto.after-nounwind\");\n+            save_temp_bitcode(&cgcx, &module, \"lto.after-nounwind\");\n         }\n         timeline.record(\"passes\");\n     }\n@@ -386,14 +332,14 @@ impl Drop for Linker<'a> {\n /// calculating the *index* for ThinLTO. This index will then be shared amongst\n /// all of the `LtoModuleCodegen` units returned below and destroyed once\n /// they all go out of scope.\n-fn thin_lto(cgcx: &CodegenContext,\n+fn thin_lto(cgcx: &CodegenContext<LlvmCodegenBackend>,\n             diag_handler: &Handler,\n             modules: Vec<ModuleCodegen<ModuleLlvm>>,\n-            serialized_modules: Vec<(SerializedModule, CString)>,\n-            cached_modules: Vec<(SerializedModule, WorkProduct)>,\n+            serialized_modules: Vec<(SerializedModule<ModuleBuffer>, CString)>,\n+            cached_modules: Vec<(SerializedModule<ModuleBuffer>, WorkProduct)>,\n             symbol_white_list: &[*const libc::c_char],\n             timeline: &mut Timeline)\n-    -> Result<(Vec<LtoModuleCodegen>, Vec<WorkProduct>), FatalError>\n+    -> Result<(Vec<LtoModuleCodegen<LlvmCodegenBackend>>, Vec<WorkProduct>), FatalError>\n {\n     unsafe {\n         info!(\"going for that thin, thin LTO\");\n@@ -556,9 +502,8 @@ fn thin_lto(cgcx: &CodegenContext,\n     }\n }\n \n-fn run_pass_manager(cgcx: &CodegenContext,\n-                    tm: &llvm::TargetMachine,\n-                    llmod: &llvm::Module,\n+pub(crate) fn run_pass_manager(cgcx: &CodegenContext<LlvmCodegenBackend>,\n+                    module: &ModuleCodegen<ModuleLlvm>,\n                     config: &ModuleConfig,\n                     thin: bool) {\n     // Now we have one massive module inside of llmod. Time to run the\n@@ -569,7 +514,7 @@ fn run_pass_manager(cgcx: &CodegenContext,\n     debug!(\"running the pass manager\");\n     unsafe {\n         let pm = llvm::LLVMCreatePassManager();\n-        llvm::LLVMRustAddAnalysisPasses(tm, pm, llmod);\n+        llvm::LLVMRustAddAnalysisPasses(module.module_llvm.tm, pm, module.module_llvm.llmod());\n \n         if config.verify_llvm_ir {\n             let pass = llvm::LLVMRustFindAndCreatePass(\"verify\\0\".as_ptr() as *const _);\n@@ -588,12 +533,13 @@ fn run_pass_manager(cgcx: &CodegenContext,\n         // Note that in general this shouldn't matter too much as you typically\n         // only turn on ThinLTO when you're compiling with optimizations\n         // otherwise.\n-        let opt_level = config.opt_level.unwrap_or(llvm::CodeGenOptLevel::None);\n+        let opt_level = config.opt_level.map(get_llvm_opt_level)\n+            .unwrap_or(llvm::CodeGenOptLevel::None);\n         let opt_level = match opt_level {\n             llvm::CodeGenOptLevel::None => llvm::CodeGenOptLevel::Less,\n             level => level,\n         };\n-        with_llvm_pmb(llmod, config, opt_level, false, &mut |b| {\n+        with_llvm_pmb(module.module_llvm.llmod(), config, opt_level, false, &mut |b| {\n             if thin {\n                 llvm::LLVMRustPassManagerBuilderPopulateThinLTOPassManager(b, pm);\n             } else {\n@@ -615,29 +561,14 @@ fn run_pass_manager(cgcx: &CodegenContext,\n             llvm::LLVMRustAddPass(pm, pass.unwrap());\n         }\n \n-        time_ext(cgcx.time_passes, None, \"LTO passes\", || llvm::LLVMRunPassManager(pm, llmod));\n+        time_ext(cgcx.time_passes, None, \"LTO passes\", ||\n+             llvm::LLVMRunPassManager(pm, module.module_llvm.llmod()));\n \n         llvm::LLVMDisposePassManager(pm);\n     }\n     debug!(\"lto done\");\n }\n \n-pub enum SerializedModule {\n-    Local(ModuleBuffer),\n-    FromRlib(Vec<u8>),\n-    FromUncompressedFile(memmap::Mmap),\n-}\n-\n-impl SerializedModule {\n-    fn data(&self) -> &[u8] {\n-        match *self {\n-            SerializedModule::Local(ref m) => m.data(),\n-            SerializedModule::FromRlib(ref m) => m,\n-            SerializedModule::FromUncompressedFile(ref m) => m,\n-        }\n-    }\n-}\n-\n pub struct ModuleBuffer(&'static mut llvm::ModuleBuffer);\n \n unsafe impl Send for ModuleBuffer {}\n@@ -649,8 +580,10 @@ impl ModuleBuffer {\n             llvm::LLVMRustModuleBufferCreate(m)\n         })\n     }\n+}\n \n-    pub fn data(&self) -> &[u8] {\n+impl ModuleBufferMethods for ModuleBuffer {\n+    fn data(&self) -> &[u8] {\n         unsafe {\n             let ptr = llvm::LLVMRustModuleBufferPtr(self.0);\n             let len = llvm::LLVMRustModuleBufferLen(self.0);\n@@ -665,19 +598,7 @@ impl Drop for ModuleBuffer {\n     }\n }\n \n-pub struct ThinModule {\n-    shared: Arc<ThinShared>,\n-    idx: usize,\n-}\n-\n-struct ThinShared {\n-    data: ThinData,\n-    thin_buffers: Vec<ThinBuffer>,\n-    serialized_modules: Vec<SerializedModule>,\n-    module_names: Vec<CString>,\n-}\n-\n-struct ThinData(&'static mut llvm::ThinLTOData);\n+pub struct ThinData(&'static mut llvm::ThinLTOData);\n \n unsafe impl Send for ThinData {}\n unsafe impl Sync for ThinData {}\n@@ -702,8 +623,10 @@ impl ThinBuffer {\n             ThinBuffer(buffer)\n         }\n     }\n+}\n \n-    pub fn data(&self) -> &[u8] {\n+impl ThinBufferMethods for ThinBuffer {\n+    fn data(&self) -> &[u8] {\n         unsafe {\n             let ptr = llvm::LLVMRustThinLTOBufferPtr(self.0) as *const _;\n             let len = llvm::LLVMRustThinLTOBufferLen(self.0);\n@@ -720,161 +643,142 @@ impl Drop for ThinBuffer {\n     }\n }\n \n-impl ThinModule {\n-    fn name(&self) -> &str {\n-        self.shared.module_names[self.idx].to_str().unwrap()\n-    }\n-\n-    fn cost(&self) -> u64 {\n-        // Yes, that's correct, we're using the size of the bytecode as an\n-        // indicator for how costly this codegen unit is.\n-        self.data().len() as u64\n-    }\n-\n-    fn data(&self) -> &[u8] {\n-        let a = self.shared.thin_buffers.get(self.idx).map(|b| b.data());\n-        a.unwrap_or_else(|| {\n-            let len = self.shared.thin_buffers.len();\n-            self.shared.serialized_modules[self.idx - len].data()\n-        })\n-    }\n-\n-    unsafe fn optimize(&mut self, cgcx: &CodegenContext, timeline: &mut Timeline)\n-        -> Result<ModuleCodegen<ModuleLlvm>, FatalError>\n-    {\n-        let diag_handler = cgcx.create_diag_handler();\n-        let tm = (cgcx.tm_factory)().map_err(|e| {\n-            write::llvm_err(&diag_handler, &e)\n-        })?;\n-\n-        // Right now the implementation we've got only works over serialized\n-        // modules, so we create a fresh new LLVM context and parse the module\n-        // into that context. One day, however, we may do this for upstream\n-        // crates but for locally codegened modules we may be able to reuse\n-        // that LLVM Context and Module.\n-        let llcx = llvm::LLVMRustContextCreate(cgcx.fewer_names);\n-        let llmod_raw = llvm::LLVMRustParseBitcodeForThinLTO(\n+pub unsafe fn optimize_thin_module(\n+    thin_module: &mut ThinModule<LlvmCodegenBackend>,\n+    cgcx: &CodegenContext<LlvmCodegenBackend>,\n+    timeline: &mut Timeline\n+) -> Result<ModuleCodegen<ModuleLlvm>, FatalError> {\n+    let diag_handler = cgcx.create_diag_handler();\n+    let tm = (cgcx.tm_factory)().map_err(|e| {\n+        write::llvm_err(&diag_handler, &e)\n+    })?;\n+\n+    // Right now the implementation we've got only works over serialized\n+    // modules, so we create a fresh new LLVM context and parse the module\n+    // into that context. One day, however, we may do this for upstream\n+    // crates but for locally codegened modules we may be able to reuse\n+    // that LLVM Context and Module.\n+    let llcx = llvm::LLVMRustContextCreate(cgcx.fewer_names);\n+    let llmod_raw = llvm::LLVMRustParseBitcodeForThinLTO(\n+        llcx,\n+        thin_module.data().as_ptr(),\n+        thin_module.data().len(),\n+        thin_module.shared.module_names[thin_module.idx].as_ptr(),\n+    ).ok_or_else(|| {\n+        let msg = \"failed to parse bitcode for thin LTO module\";\n+        write::llvm_err(&diag_handler, msg)\n+    })? as *const _;\n+    let module = ModuleCodegen {\n+        module_llvm: ModuleLlvm {\n+            llmod_raw,\n             llcx,\n-            self.data().as_ptr(),\n-            self.data().len(),\n-            self.shared.module_names[self.idx].as_ptr(),\n-        ).ok_or_else(|| {\n-            let msg = \"failed to parse bitcode for thin LTO module\";\n-            write::llvm_err(&diag_handler, msg)\n-        })? as *const _;\n-        let module = ModuleCodegen {\n-            module_llvm: ModuleLlvm {\n-                llmod_raw,\n-                llcx,\n-                tm,\n-            },\n-            name: self.name().to_string(),\n-            kind: ModuleKind::Regular,\n-        };\n-        {\n-            let llmod = module.module_llvm.llmod();\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-input\");\n-\n-            // Before we do much else find the \"main\" `DICompileUnit` that we'll be\n-            // using below. If we find more than one though then rustc has changed\n-            // in a way we're not ready for, so generate an ICE by returning\n-            // an error.\n-            let mut cu1 = ptr::null_mut();\n-            let mut cu2 = ptr::null_mut();\n-            llvm::LLVMRustThinLTOGetDICompileUnit(llmod, &mut cu1, &mut cu2);\n-            if !cu2.is_null() {\n-                let msg = \"multiple source DICompileUnits found\";\n-                return Err(write::llvm_err(&diag_handler, msg))\n-            }\n+            tm,\n+        },\n+        name: thin_module.name().to_string(),\n+        kind: ModuleKind::Regular,\n+    };\n+    {\n+        let llmod = module.module_llvm.llmod();\n+        save_temp_bitcode(&cgcx, &module, \"thin-lto-input\");\n+\n+        // Before we do much else find the \"main\" `DICompileUnit` that we'll be\n+        // using below. If we find more than one though then rustc has changed\n+        // in a way we're not ready for, so generate an ICE by returning\n+        // an error.\n+        let mut cu1 = ptr::null_mut();\n+        let mut cu2 = ptr::null_mut();\n+        llvm::LLVMRustThinLTOGetDICompileUnit(llmod, &mut cu1, &mut cu2);\n+        if !cu2.is_null() {\n+            let msg = \"multiple source DICompileUnits found\";\n+            return Err(write::llvm_err(&diag_handler, msg))\n+        }\n \n-            // Like with \"fat\" LTO, get some better optimizations if landing pads\n-            // are disabled by removing all landing pads.\n-            if cgcx.no_landing_pads {\n-                llvm::LLVMRustMarkAllFunctionsNounwind(llmod);\n-                cgcx.save_temp_bitcode(&module, \"thin-lto-after-nounwind\");\n-                timeline.record(\"nounwind\");\n-            }\n+        // Like with \"fat\" LTO, get some better optimizations if landing pads\n+        // are disabled by removing all landing pads.\n+        if cgcx.no_landing_pads {\n+            llvm::LLVMRustMarkAllFunctionsNounwind(llmod);\n+            save_temp_bitcode(&cgcx, &module, \"thin-lto-after-nounwind\");\n+            timeline.record(\"nounwind\");\n+        }\n \n-            // Up next comes the per-module local analyses that we do for Thin LTO.\n-            // Each of these functions is basically copied from the LLVM\n-            // implementation and then tailored to suit this implementation. Ideally\n-            // each of these would be supported by upstream LLVM but that's perhaps\n-            // a patch for another day!\n-            //\n-            // You can find some more comments about these functions in the LLVM\n-            // bindings we've got (currently `PassWrapper.cpp`)\n-            if !llvm::LLVMRustPrepareThinLTORename(self.shared.data.0, llmod) {\n-                let msg = \"failed to prepare thin LTO module\";\n-                return Err(write::llvm_err(&diag_handler, msg))\n-            }\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-rename\");\n-            timeline.record(\"rename\");\n-            if !llvm::LLVMRustPrepareThinLTOResolveWeak(self.shared.data.0, llmod) {\n-                let msg = \"failed to prepare thin LTO module\";\n-                return Err(write::llvm_err(&diag_handler, msg))\n-            }\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-resolve\");\n-            timeline.record(\"resolve\");\n-            if !llvm::LLVMRustPrepareThinLTOInternalize(self.shared.data.0, llmod) {\n-                let msg = \"failed to prepare thin LTO module\";\n-                return Err(write::llvm_err(&diag_handler, msg))\n-            }\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-internalize\");\n-            timeline.record(\"internalize\");\n-            if !llvm::LLVMRustPrepareThinLTOImport(self.shared.data.0, llmod) {\n-                let msg = \"failed to prepare thin LTO module\";\n-                return Err(write::llvm_err(&diag_handler, msg))\n-            }\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-import\");\n-            timeline.record(\"import\");\n-\n-            // Ok now this is a bit unfortunate. This is also something you won't\n-            // find upstream in LLVM's ThinLTO passes! This is a hack for now to\n-            // work around bugs in LLVM.\n-            //\n-            // First discovered in #45511 it was found that as part of ThinLTO\n-            // importing passes LLVM will import `DICompileUnit` metadata\n-            // information across modules. This means that we'll be working with one\n-            // LLVM module that has multiple `DICompileUnit` instances in it (a\n-            // bunch of `llvm.dbg.cu` members). Unfortunately there's a number of\n-            // bugs in LLVM's backend which generates invalid DWARF in a situation\n-            // like this:\n-            //\n-            //  https://bugs.llvm.org/show_bug.cgi?id=35212\n-            //  https://bugs.llvm.org/show_bug.cgi?id=35562\n-            //\n-            // While the first bug there is fixed the second ended up causing #46346\n-            // which was basically a resurgence of #45511 after LLVM's bug 35212 was\n-            // fixed.\n-            //\n-            // This function below is a huge hack around this problem. The function\n-            // below is defined in `PassWrapper.cpp` and will basically \"merge\"\n-            // all `DICompileUnit` instances in a module. Basically it'll take all\n-            // the objects, rewrite all pointers of `DISubprogram` to point to the\n-            // first `DICompileUnit`, and then delete all the other units.\n-            //\n-            // This is probably mangling to the debug info slightly (but hopefully\n-            // not too much) but for now at least gets LLVM to emit valid DWARF (or\n-            // so it appears). Hopefully we can remove this once upstream bugs are\n-            // fixed in LLVM.\n-            llvm::LLVMRustThinLTOPatchDICompileUnit(llmod, cu1);\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-patch\");\n-            timeline.record(\"patch\");\n-\n-            // Alright now that we've done everything related to the ThinLTO\n-            // analysis it's time to run some optimizations! Here we use the same\n-            // `run_pass_manager` as the \"fat\" LTO above except that we tell it to\n-            // populate a thin-specific pass manager, which presumably LLVM treats a\n-            // little differently.\n-            info!(\"running thin lto passes over {}\", module.name);\n-            let config = cgcx.config(module.kind);\n-            run_pass_manager(cgcx, module.module_llvm.tm, llmod, config, true);\n-            cgcx.save_temp_bitcode(&module, \"thin-lto-after-pm\");\n-            timeline.record(\"thin-done\");\n+        // Up next comes the per-module local analyses that we do for Thin LTO.\n+        // Each of these functions is basically copied from the LLVM\n+        // implementation and then tailored to suit this implementation. Ideally\n+        // each of these would be supported by upstream LLVM but that's perhaps\n+        // a patch for another day!\n+        //\n+        // You can find some more comments about these functions in the LLVM\n+        // bindings we've got (currently `PassWrapper.cpp`)\n+        if !llvm::LLVMRustPrepareThinLTORename(thin_module.shared.data.0, llmod) {\n+            let msg = \"failed to prepare thin LTO module\";\n+            return Err(write::llvm_err(&diag_handler, msg))\n         }\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-rename\");\n+        timeline.record(\"rename\");\n+        if !llvm::LLVMRustPrepareThinLTOResolveWeak(thin_module.shared.data.0, llmod) {\n+            let msg = \"failed to prepare thin LTO module\";\n+            return Err(write::llvm_err(&diag_handler, msg))\n+        }\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-resolve\");\n+        timeline.record(\"resolve\");\n+        if !llvm::LLVMRustPrepareThinLTOInternalize(thin_module.shared.data.0, llmod) {\n+            let msg = \"failed to prepare thin LTO module\";\n+            return Err(write::llvm_err(&diag_handler, msg))\n+        }\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-internalize\");\n+        timeline.record(\"internalize\");\n+        if !llvm::LLVMRustPrepareThinLTOImport(thin_module.shared.data.0, llmod) {\n+            let msg = \"failed to prepare thin LTO module\";\n+            return Err(write::llvm_err(&diag_handler, msg))\n+        }\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-import\");\n+        timeline.record(\"import\");\n \n-        Ok(module)\n+        // Ok now this is a bit unfortunate. This is also something you won't\n+        // find upstream in LLVM's ThinLTO passes! This is a hack for now to\n+        // work around bugs in LLVM.\n+        //\n+        // First discovered in #45511 it was found that as part of ThinLTO\n+        // importing passes LLVM will import `DICompileUnit` metadata\n+        // information across modules. This means that we'll be working with one\n+        // LLVM module that has multiple `DICompileUnit` instances in it (a\n+        // bunch of `llvm.dbg.cu` members). Unfortunately there's a number of\n+        // bugs in LLVM's backend which generates invalid DWARF in a situation\n+        // like this:\n+        //\n+        //  https://bugs.llvm.org/show_bug.cgi?id=35212\n+        //  https://bugs.llvm.org/show_bug.cgi?id=35562\n+        //\n+        // While the first bug there is fixed the second ended up causing #46346\n+        // which was basically a resurgence of #45511 after LLVM's bug 35212 was\n+        // fixed.\n+        //\n+        // This function below is a huge hack around this problem. The function\n+        // below is defined in `PassWrapper.cpp` and will basically \"merge\"\n+        // all `DICompileUnit` instances in a module. Basically it'll take all\n+        // the objects, rewrite all pointers of `DISubprogram` to point to the\n+        // first `DICompileUnit`, and then delete all the other units.\n+        //\n+        // This is probably mangling to the debug info slightly (but hopefully\n+        // not too much) but for now at least gets LLVM to emit valid DWARF (or\n+        // so it appears). Hopefully we can remove this once upstream bugs are\n+        // fixed in LLVM.\n+        llvm::LLVMRustThinLTOPatchDICompileUnit(llmod, cu1);\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-patch\");\n+        timeline.record(\"patch\");\n+\n+        // Alright now that we've done everything related to the ThinLTO\n+        // analysis it's time to run some optimizations! Here we use the same\n+        // `run_pass_manager` as the \"fat\" LTO above except that we tell it to\n+        // populate a thin-specific pass manager, which presumably LLVM treats a\n+        // little differently.\n+        info!(\"running thin lto passes over {}\", module.name);\n+        let config = cgcx.config(module.kind);\n+        run_pass_manager(cgcx, &module, config, true);\n+        save_temp_bitcode(cgcx, &module, \"thin-lto-after-pm\");\n+        timeline.record(\"thin-done\");\n     }\n+    Ok(module)\n }\n \n #[derive(Debug, Default)]"}, {"sha": "97adfab516f80864d1ea6a05d6bb71a6d43828c1", "filename": "src/librustc_codegen_llvm/back/write.rs", "status": "modified", "additions": 43, "deletions": 1827, "changes": 1870, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fback%2Fwrite.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -10,57 +10,35 @@\n \n use attributes;\n use back::bytecode::{self, RLIB_BYTECODE_EXTENSION};\n-use back::lto::{self, ThinBuffer, SerializedModule};\n-use back::link::{self, get_linker, remove};\n+use back::lto::ThinBuffer;\n+use rustc_codegen_ssa::back::write::{CodegenContext, ModuleConfig, run_assembler};\n+use rustc_codegen_ssa::interfaces::*;\n use base;\n use consts;\n-use memmap;\n-use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir,\n-                        in_incr_comp_dir, in_incr_comp_dir_sess};\n-use rustc::dep_graph::{WorkProduct, WorkProductId, WorkProductFileKind};\n-use rustc::dep_graph::cgu_reuse_tracker::CguReuseTracker;\n-use rustc::middle::cstore::EncodedMetadata;\n-use rustc::session::config::{self, OutputFilenames, OutputType, Passes, Sanitizer, Lto};\n+use rustc::session::config::{self, OutputType, Passes, Lto};\n use rustc::session::Session;\n-use rustc::util::nodemap::FxHashMap;\n-use time_graph::{self, TimeGraph, Timeline};\n+use time_graph::Timeline;\n use llvm::{self, DiagnosticInfo, PassManager, SMDiagnostic};\n use llvm_util;\n-use {CodegenResults, ModuleLlvm};\n-use rustc_codegen_ssa::{ModuleCodegen, ModuleKind, CachedModuleCodegen, CompiledModule, CrateInfo};\n-use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n-use rustc::ty::TyCtxt;\n-use rustc::util::common::{time_ext, time_depth, set_time_depth, print_time_passes_entry};\n+use ModuleLlvm;\n+use rustc_codegen_ssa::{ModuleCodegen, CompiledModule};\n+use rustc::util::common::time_ext;\n use rustc_fs_util::{path2cstr, link_or_copy};\n use rustc_data_structures::small_c_str::SmallCStr;\n-use rustc_data_structures::svh::Svh;\n-use rustc_codegen_utils::command::Command;\n-use rustc_codegen_utils::linker::LinkerInfo;\n-use rustc_codegen_utils::symbol_export::ExportedSymbols;\n-use errors::{self, Handler, Level, DiagnosticBuilder, FatalError, DiagnosticId};\n-use errors::emitter::{Emitter};\n-use syntax::attr;\n-use syntax::ext::hygiene::Mark;\n-use syntax_pos::MultiSpan;\n-use syntax_pos::symbol::Symbol;\n+use errors::{self, Handler, FatalError};\n use type_::Type;\n use context::{is_pie_binary, get_reloc_model};\n use common;\n-use jobserver::{Client, Acquired};\n+use LlvmCodegenBackend;\n use rustc_demangle;\n \n-use std::any::Any;\n use std::ffi::{CString, CStr};\n use std::fs;\n use std::io::{self, Write};\n-use std::mem;\n-use std::path::{Path, PathBuf};\n+use std::path::Path;\n use std::str;\n use std::sync::Arc;\n-use std::sync::mpsc::{channel, Sender, Receiver};\n use std::slice;\n-use std::time::Instant;\n-use std::thread;\n use libc::{c_uint, c_void, c_char, size_t};\n \n pub const RELOC_MODEL_ARGS : [(&str, llvm::RelocMode); 7] = [\n@@ -87,8 +65,6 @@ pub const TLS_MODEL_ARGS : [(&str, llvm::ThreadLocalMode); 4] = [\n     (\"local-exec\", llvm::ThreadLocalMode::LocalExec),\n ];\n \n-const PRE_THIN_LTO_BC_EXT: &str = \"pre-thin-lto.bc\";\n-\n pub fn llvm_err(handler: &errors::Handler, msg: &str) -> FatalError {\n     match llvm::last_error() {\n         Some(err) => handler.fatal(&format!(\"{}: {}\", msg, err)),\n@@ -115,7 +91,7 @@ pub fn write_output_file(\n     }\n }\n \n-fn get_llvm_opt_level(optimize: config::OptLevel) -> llvm::CodeGenOptLevel {\n+pub(crate) fn get_llvm_opt_level(optimize: config::OptLevel) -> llvm::CodeGenOptLevel {\n     match optimize {\n       config::OptLevel::No => llvm::CodeGenOptLevel::None,\n       config::OptLevel::Less => llvm::CodeGenOptLevel::Less,\n@@ -125,7 +101,7 @@ fn get_llvm_opt_level(optimize: config::OptLevel) -> llvm::CodeGenOptLevel {\n     }\n }\n \n-fn get_llvm_opt_size(optimize: config::OptLevel) -> llvm::CodeGenOptSize {\n+pub(crate) fn get_llvm_opt_size(optimize: config::OptLevel) -> llvm::CodeGenOptSize {\n     match optimize {\n       config::OptLevel::Size => llvm::CodeGenOptSizeDefault,\n       config::OptLevel::SizeMin => llvm::CodeGenOptSizeAggressive,\n@@ -223,212 +199,31 @@ pub fn target_machine_factory(sess: &Session, find_features: bool)\n     })\n }\n \n-/// Module-specific configuration for `optimize_and_codegen`.\n-pub struct ModuleConfig {\n-    /// Names of additional optimization passes to run.\n-    passes: Vec<String>,\n-    /// Some(level) to optimize at a certain level, or None to run\n-    /// absolutely no optimizations (used for the metadata module).\n-    pub opt_level: Option<llvm::CodeGenOptLevel>,\n-\n-    /// Some(level) to optimize binary size, or None to not affect program size.\n-    opt_size: Option<llvm::CodeGenOptSize>,\n-\n-    pgo_gen: Option<String>,\n-    pgo_use: String,\n-\n-    // Flags indicating which outputs to produce.\n-    pub emit_pre_thin_lto_bc: bool,\n-    emit_no_opt_bc: bool,\n-    emit_bc: bool,\n-    emit_bc_compressed: bool,\n-    emit_lto_bc: bool,\n-    emit_ir: bool,\n-    emit_asm: bool,\n-    emit_obj: bool,\n-    // Miscellaneous flags.  These are mostly copied from command-line\n-    // options.\n-    pub verify_llvm_ir: bool,\n-    no_prepopulate_passes: bool,\n-    no_builtins: bool,\n-    time_passes: bool,\n-    vectorize_loop: bool,\n-    vectorize_slp: bool,\n-    merge_functions: bool,\n-    inline_threshold: Option<usize>,\n-    // Instead of creating an object file by doing LLVM codegen, just\n-    // make the object file bitcode. Provides easy compatibility with\n-    // emscripten's ecc compiler, when used as the linker.\n-    obj_is_bitcode: bool,\n-    no_integrated_as: bool,\n-    embed_bitcode: bool,\n-    embed_bitcode_marker: bool,\n-}\n-\n-impl ModuleConfig {\n-    fn new(passes: Vec<String>) -> ModuleConfig {\n-        ModuleConfig {\n-            passes,\n-            opt_level: None,\n-            opt_size: None,\n-\n-            pgo_gen: None,\n-            pgo_use: String::new(),\n-\n-            emit_no_opt_bc: false,\n-            emit_pre_thin_lto_bc: false,\n-            emit_bc: false,\n-            emit_bc_compressed: false,\n-            emit_lto_bc: false,\n-            emit_ir: false,\n-            emit_asm: false,\n-            emit_obj: false,\n-            obj_is_bitcode: false,\n-            embed_bitcode: false,\n-            embed_bitcode_marker: false,\n-            no_integrated_as: false,\n-\n-            verify_llvm_ir: false,\n-            no_prepopulate_passes: false,\n-            no_builtins: false,\n-            time_passes: false,\n-            vectorize_loop: false,\n-            vectorize_slp: false,\n-            merge_functions: false,\n-            inline_threshold: None\n-        }\n-    }\n-\n-    fn set_flags(&mut self, sess: &Session, no_builtins: bool) {\n-        self.verify_llvm_ir = sess.verify_llvm_ir();\n-        self.no_prepopulate_passes = sess.opts.cg.no_prepopulate_passes;\n-        self.no_builtins = no_builtins || sess.target.target.options.no_builtins;\n-        self.time_passes = sess.time_passes();\n-        self.inline_threshold = sess.opts.cg.inline_threshold;\n-        self.obj_is_bitcode = sess.target.target.options.obj_is_bitcode ||\n-                              sess.opts.debugging_opts.cross_lang_lto.enabled();\n-        let embed_bitcode = sess.target.target.options.embed_bitcode ||\n-                            sess.opts.debugging_opts.embed_bitcode;\n-        if embed_bitcode {\n-            match sess.opts.optimize {\n-                config::OptLevel::No |\n-                config::OptLevel::Less => {\n-                    self.embed_bitcode_marker = embed_bitcode;\n-                }\n-                _ => self.embed_bitcode = embed_bitcode,\n-            }\n-        }\n-\n-        // Copy what clang does by turning on loop vectorization at O2 and\n-        // slp vectorization at O3. Otherwise configure other optimization aspects\n-        // of this pass manager builder.\n-        // Turn off vectorization for emscripten, as it's not very well supported.\n-        self.vectorize_loop = !sess.opts.cg.no_vectorize_loops &&\n-                             (sess.opts.optimize == config::OptLevel::Default ||\n-                              sess.opts.optimize == config::OptLevel::Aggressive) &&\n-                             !sess.target.target.options.is_like_emscripten;\n-\n-        self.vectorize_slp = !sess.opts.cg.no_vectorize_slp &&\n-                            sess.opts.optimize == config::OptLevel::Aggressive &&\n-                            !sess.target.target.options.is_like_emscripten;\n-\n-        self.merge_functions = sess.opts.optimize == config::OptLevel::Default ||\n-                               sess.opts.optimize == config::OptLevel::Aggressive;\n-    }\n-\n-    pub fn bitcode_needed(&self) -> bool {\n-        self.emit_bc || self.obj_is_bitcode\n-            || self.emit_bc_compressed || self.embed_bitcode\n-    }\n-}\n-\n-/// Assembler name and command used by codegen when no_integrated_as is enabled\n-struct AssemblerCommand {\n-    name: PathBuf,\n-    cmd: Command,\n-}\n-\n-/// Additional resources used by optimize_and_codegen (not module specific)\n-#[derive(Clone)]\n-pub struct CodegenContext {\n-    // Resources needed when running LTO\n-    pub time_passes: bool,\n-    pub lto: Lto,\n-    pub no_landing_pads: bool,\n-    pub save_temps: bool,\n-    pub fewer_names: bool,\n-    pub exported_symbols: Option<Arc<ExportedSymbols>>,\n-    pub opts: Arc<config::Options>,\n-    pub crate_types: Vec<config::CrateType>,\n-    pub each_linked_rlib_for_lto: Vec<(CrateNum, PathBuf)>,\n-    output_filenames: Arc<OutputFilenames>,\n-    regular_module_config: Arc<ModuleConfig>,\n-    metadata_module_config: Arc<ModuleConfig>,\n-    allocator_module_config: Arc<ModuleConfig>,\n-    pub tm_factory: Arc<dyn Fn() -> Result<&'static mut llvm::TargetMachine, String> + Send + Sync>,\n-    pub msvc_imps_needed: bool,\n-    pub target_pointer_width: String,\n-    debuginfo: config::DebugInfo,\n-\n-    // Number of cgus excluding the allocator/metadata modules\n-    pub total_cgus: usize,\n-    // Handler to use for diagnostics produced during codegen.\n-    pub diag_emitter: SharedEmitter,\n-    // LLVM passes added by plugins.\n-    pub plugin_passes: Vec<String>,\n-    // LLVM optimizations for which we want to print remarks.\n-    pub remark: Passes,\n-    // Worker thread number\n-    pub worker: usize,\n-    // The incremental compilation session directory, or None if we are not\n-    // compiling incrementally\n-    pub incr_comp_session_dir: Option<PathBuf>,\n-    // Used to update CGU re-use information during the thinlto phase.\n-    pub cgu_reuse_tracker: CguReuseTracker,\n-    // Channel back to the main control thread to send messages to\n-    coordinator_send: Sender<Box<dyn Any + Send>>,\n-    // A reference to the TimeGraph so we can register timings. None means that\n-    // measuring is disabled.\n-    time_graph: Option<TimeGraph>,\n-    // The assembler command if no_integrated_as option is enabled, None otherwise\n-    assembler_cmd: Option<Arc<AssemblerCommand>>\n-}\n-\n-impl CodegenContext {\n-    pub fn create_diag_handler(&self) -> Handler {\n-        Handler::with_emitter(true, false, Box::new(self.diag_emitter.clone()))\n-    }\n-\n-    pub(crate) fn config(&self, kind: ModuleKind) -> &ModuleConfig {\n-        match kind {\n-            ModuleKind::Regular => &self.regular_module_config,\n-            ModuleKind::Metadata => &self.metadata_module_config,\n-            ModuleKind::Allocator => &self.allocator_module_config,\n-        }\n+pub(crate) fn save_temp_bitcode(\n+    cgcx: &CodegenContext<LlvmCodegenBackend>,\n+    module: &ModuleCodegen<ModuleLlvm>,\n+    name: &str\n+) {\n+    if !cgcx.save_temps {\n+        return\n     }\n-\n-    pub(crate) fn save_temp_bitcode(&self, module: &ModuleCodegen<ModuleLlvm>, name: &str) {\n-        if !self.save_temps {\n-            return\n-        }\n-        unsafe {\n-            let ext = format!(\"{}.bc\", name);\n-            let cgu = Some(&module.name[..]);\n-            let path = self.output_filenames.temp_path_ext(&ext, cgu);\n-            let cstr = path2cstr(&path);\n-            let llmod = module.module_llvm.llmod();\n-            llvm::LLVMWriteBitcodeToFile(llmod, cstr.as_ptr());\n-        }\n+    unsafe {\n+        let ext = format!(\"{}.bc\", name);\n+        let cgu = Some(&module.name[..]);\n+        let path = cgcx.output_filenames.temp_path_ext(&ext, cgu);\n+        let cstr = path2cstr(&path);\n+        let llmod = module.module_llvm.llmod();\n+        llvm::LLVMWriteBitcodeToFile(llmod, cstr.as_ptr());\n     }\n }\n \n pub struct DiagnosticHandlers<'a> {\n-    data: *mut (&'a CodegenContext, &'a Handler),\n+    data: *mut (&'a CodegenContext<LlvmCodegenBackend>, &'a Handler),\n     llcx: &'a llvm::Context,\n }\n \n impl<'a> DiagnosticHandlers<'a> {\n-    pub fn new(cgcx: &'a CodegenContext,\n+    pub fn new(cgcx: &'a CodegenContext<LlvmCodegenBackend>,\n                handler: &'a Handler,\n                llcx: &'a llvm::Context) -> Self {\n         let data = Box::into_raw(Box::new((cgcx, handler)));\n@@ -451,7 +246,7 @@ impl<'a> Drop for DiagnosticHandlers<'a> {\n     }\n }\n \n-unsafe extern \"C\" fn report_inline_asm<'a, 'b>(cgcx: &'a CodegenContext,\n+unsafe extern \"C\" fn report_inline_asm<'a, 'b>(cgcx: &'a CodegenContext<LlvmCodegenBackend>,\n                                                msg: &'b str,\n                                                cookie: c_uint) {\n     cgcx.diag_emitter.inline_asm_error(cookie as u32, msg.to_owned());\n@@ -463,7 +258,7 @@ unsafe extern \"C\" fn inline_asm_handler(diag: &SMDiagnostic,\n     if user.is_null() {\n         return\n     }\n-    let (cgcx, _) = *(user as *const (&CodegenContext, &Handler));\n+    let (cgcx, _) = *(user as *const (&CodegenContext<LlvmCodegenBackend>, &Handler));\n \n     let msg = llvm::build_string(|s| llvm::LLVMRustWriteSMDiagnosticToString(diag, s))\n         .expect(\"non-UTF8 SMDiagnostic\");\n@@ -475,7 +270,7 @@ unsafe extern \"C\" fn diagnostic_handler(info: &DiagnosticInfo, user: *mut c_void\n     if user.is_null() {\n         return\n     }\n-    let (cgcx, diag_handler) = *(user as *const (&CodegenContext, &Handler));\n+    let (cgcx, diag_handler) = *(user as *const (&CodegenContext<LlvmCodegenBackend>, &Handler));\n \n     match llvm::diagnostic::Diagnostic::unpack(info) {\n         llvm::diagnostic::InlineAsm(inline) => {\n@@ -512,7 +307,7 @@ unsafe extern \"C\" fn diagnostic_handler(info: &DiagnosticInfo, user: *mut c_void\n }\n \n // Unsafe due to LLVM calls.\n-unsafe fn optimize(cgcx: &CodegenContext,\n+pub(crate) unsafe fn optimize(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                    diag_handler: &Handler,\n                    module: &ModuleCodegen<ModuleLlvm>,\n                    config: &ModuleConfig,\n@@ -572,7 +367,8 @@ unsafe fn optimize(cgcx: &CodegenContext,\n             if !config.no_prepopulate_passes {\n                 llvm::LLVMRustAddAnalysisPasses(tm, fpm, llmod);\n                 llvm::LLVMRustAddAnalysisPasses(tm, mpm, llmod);\n-                let opt_level = config.opt_level.unwrap_or(llvm::CodeGenOptLevel::None);\n+                let opt_level = config.opt_level.map(get_llvm_opt_level)\n+                    .unwrap_or(llvm::CodeGenOptLevel::None);\n                 let prepare_for_thin_lto = cgcx.lto == Lto::Thin || cgcx.lto == Lto::ThinLocal ||\n                     (cgcx.lto != Lto::Fat && cgcx.opts.debugging_opts.cross_lang_lto.enabled());\n                 have_name_anon_globals_pass = have_name_anon_globals_pass || prepare_for_thin_lto;\n@@ -644,35 +440,7 @@ unsafe fn optimize(cgcx: &CodegenContext,\n     Ok(())\n }\n \n-fn generate_lto_work(cgcx: &CodegenContext,\n-                     modules: Vec<ModuleCodegen<ModuleLlvm>>,\n-                     import_only_modules: Vec<(SerializedModule, WorkProduct)>)\n-    -> Vec<(WorkItem, u64)>\n-{\n-    let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n-        tg.start(CODEGEN_WORKER_TIMELINE,\n-                 CODEGEN_WORK_PACKAGE_KIND,\n-                 \"generate lto\")\n-    }).unwrap_or(Timeline::noop());\n-    let (lto_modules, copy_jobs) = lto::run(cgcx, modules, import_only_modules, &mut timeline)\n-        .unwrap_or_else(|e| e.raise());\n-\n-    let lto_modules = lto_modules.into_iter().map(|module| {\n-        let cost = module.cost();\n-        (WorkItem::LTO(module), cost)\n-    });\n-\n-    let copy_jobs = copy_jobs.into_iter().map(|wp| {\n-        (WorkItem::CopyPostLtoArtifacts(CachedModuleCodegen {\n-            name: wp.cgu_name.clone(),\n-            source: wp,\n-        }), 0)\n-    });\n-\n-    lto_modules.chain(copy_jobs).collect()\n-}\n-\n-unsafe fn codegen(cgcx: &CodegenContext,\n+pub(crate) unsafe fn codegen(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                   diag_handler: &Handler,\n                   module: ModuleCodegen<ModuleLlvm>,\n                   config: &ModuleConfig,\n@@ -879,7 +647,7 @@ unsafe fn codegen(cgcx: &CodegenContext,\n ///\n /// Basically all of this is us attempting to follow in the footsteps of clang\n /// on iOS. See #35968 for lots more info.\n-unsafe fn embed_bitcode(cgcx: &CodegenContext,\n+unsafe fn embed_bitcode(cgcx: &CodegenContext<LlvmCodegenBackend>,\n                         llcx: &llvm::Context,\n                         llmod: &llvm::Module,\n                         bitcode: Option<&[u8]>) {\n@@ -919,1279 +687,6 @@ unsafe fn embed_bitcode(cgcx: &CodegenContext,\n     llvm::LLVMRustSetLinkage(llglobal, llvm::Linkage::PrivateLinkage);\n }\n \n-pub(crate) struct CompiledModules {\n-    pub modules: Vec<CompiledModule>,\n-    pub metadata_module: CompiledModule,\n-    pub allocator_module: Option<CompiledModule>,\n-}\n-\n-fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n-    sess.crate_types.borrow().contains(&config::CrateType::Rlib) &&\n-    sess.opts.output_types.contains_key(&OutputType::Exe)\n-}\n-\n-fn need_pre_thin_lto_bitcode_for_incr_comp(sess: &Session) -> bool {\n-    if sess.opts.incremental.is_none() {\n-        return false\n-    }\n-\n-    match sess.lto() {\n-        Lto::Fat |\n-        Lto::No => false,\n-        Lto::Thin |\n-        Lto::ThinLocal => true,\n-    }\n-}\n-\n-pub fn start_async_codegen(tcx: TyCtxt,\n-                           time_graph: Option<TimeGraph>,\n-                           metadata: EncodedMetadata,\n-                           coordinator_receive: Receiver<Box<dyn Any + Send>>,\n-                           total_cgus: usize)\n-                           -> OngoingCodegen {\n-    let sess = tcx.sess;\n-    let crate_name = tcx.crate_name(LOCAL_CRATE);\n-    let crate_hash = tcx.crate_hash(LOCAL_CRATE);\n-    let no_builtins = attr::contains_name(&tcx.hir.krate().attrs, \"no_builtins\");\n-    let subsystem = attr::first_attr_value_str_by_name(&tcx.hir.krate().attrs,\n-                                                       \"windows_subsystem\");\n-    let windows_subsystem = subsystem.map(|subsystem| {\n-        if subsystem != \"windows\" && subsystem != \"console\" {\n-            tcx.sess.fatal(&format!(\"invalid windows subsystem `{}`, only \\\n-                                     `windows` and `console` are allowed\",\n-                                    subsystem));\n-        }\n-        subsystem.to_string()\n-    });\n-\n-    let linker_info = LinkerInfo::new(tcx);\n-    let crate_info = CrateInfo::new(tcx);\n-\n-    // Figure out what we actually need to build.\n-    let mut modules_config = ModuleConfig::new(sess.opts.cg.passes.clone());\n-    let mut metadata_config = ModuleConfig::new(vec![]);\n-    let mut allocator_config = ModuleConfig::new(vec![]);\n-\n-    if let Some(ref sanitizer) = sess.opts.debugging_opts.sanitizer {\n-        match *sanitizer {\n-            Sanitizer::Address => {\n-                modules_config.passes.push(\"asan\".to_owned());\n-                modules_config.passes.push(\"asan-module\".to_owned());\n-            }\n-            Sanitizer::Memory => {\n-                modules_config.passes.push(\"msan\".to_owned())\n-            }\n-            Sanitizer::Thread => {\n-                modules_config.passes.push(\"tsan\".to_owned())\n-            }\n-            _ => {}\n-        }\n-    }\n-\n-    if sess.opts.debugging_opts.profile {\n-        modules_config.passes.push(\"insert-gcov-profiling\".to_owned())\n-    }\n-\n-    modules_config.pgo_gen = sess.opts.debugging_opts.pgo_gen.clone();\n-    modules_config.pgo_use = sess.opts.debugging_opts.pgo_use.clone();\n-\n-    modules_config.opt_level = Some(get_llvm_opt_level(sess.opts.optimize));\n-    modules_config.opt_size = Some(get_llvm_opt_size(sess.opts.optimize));\n-\n-    // Save all versions of the bytecode if we're saving our temporaries.\n-    if sess.opts.cg.save_temps {\n-        modules_config.emit_no_opt_bc = true;\n-        modules_config.emit_pre_thin_lto_bc = true;\n-        modules_config.emit_bc = true;\n-        modules_config.emit_lto_bc = true;\n-        metadata_config.emit_bc = true;\n-        allocator_config.emit_bc = true;\n-    }\n-\n-    // Emit compressed bitcode files for the crate if we're emitting an rlib.\n-    // Whenever an rlib is created, the bitcode is inserted into the archive in\n-    // order to allow LTO against it.\n-    if need_crate_bitcode_for_rlib(sess) {\n-        modules_config.emit_bc_compressed = true;\n-        allocator_config.emit_bc_compressed = true;\n-    }\n-\n-    modules_config.emit_pre_thin_lto_bc =\n-        need_pre_thin_lto_bitcode_for_incr_comp(sess);\n-\n-    modules_config.no_integrated_as = tcx.sess.opts.cg.no_integrated_as ||\n-        tcx.sess.target.target.options.no_integrated_as;\n-\n-    for output_type in sess.opts.output_types.keys() {\n-        match *output_type {\n-            OutputType::Bitcode => { modules_config.emit_bc = true; }\n-            OutputType::LlvmAssembly => { modules_config.emit_ir = true; }\n-            OutputType::Assembly => {\n-                modules_config.emit_asm = true;\n-                // If we're not using the LLVM assembler, this function\n-                // could be invoked specially with output_type_assembly, so\n-                // in this case we still want the metadata object file.\n-                if !sess.opts.output_types.contains_key(&OutputType::Assembly) {\n-                    metadata_config.emit_obj = true;\n-                    allocator_config.emit_obj = true;\n-                }\n-            }\n-            OutputType::Object => { modules_config.emit_obj = true; }\n-            OutputType::Metadata => { metadata_config.emit_obj = true; }\n-            OutputType::Exe => {\n-                modules_config.emit_obj = true;\n-                metadata_config.emit_obj = true;\n-                allocator_config.emit_obj = true;\n-            },\n-            OutputType::Mir => {}\n-            OutputType::DepInfo => {}\n-        }\n-    }\n-\n-    modules_config.set_flags(sess, no_builtins);\n-    metadata_config.set_flags(sess, no_builtins);\n-    allocator_config.set_flags(sess, no_builtins);\n-\n-    // Exclude metadata and allocator modules from time_passes output, since\n-    // they throw off the \"LLVM passes\" measurement.\n-    metadata_config.time_passes = false;\n-    allocator_config.time_passes = false;\n-\n-    let (shared_emitter, shared_emitter_main) = SharedEmitter::new();\n-    let (codegen_worker_send, codegen_worker_receive) = channel();\n-\n-    let coordinator_thread = start_executing_work(tcx,\n-                                                  &crate_info,\n-                                                  shared_emitter,\n-                                                  codegen_worker_send,\n-                                                  coordinator_receive,\n-                                                  total_cgus,\n-                                                  sess.jobserver.clone(),\n-                                                  time_graph.clone(),\n-                                                  Arc::new(modules_config),\n-                                                  Arc::new(metadata_config),\n-                                                  Arc::new(allocator_config));\n-\n-    OngoingCodegen {\n-        crate_name,\n-        crate_hash,\n-        metadata,\n-        windows_subsystem,\n-        linker_info,\n-        crate_info,\n-\n-        time_graph,\n-        coordinator_send: tcx.tx_to_llvm_workers.lock().clone(),\n-        codegen_worker_receive,\n-        shared_emitter_main,\n-        future: coordinator_thread,\n-        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n-    }\n-}\n-\n-fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n-    sess: &Session,\n-    compiled_modules: &CompiledModules,\n-) -> FxHashMap<WorkProductId, WorkProduct> {\n-    let mut work_products = FxHashMap::default();\n-\n-    if sess.opts.incremental.is_none() {\n-        return work_products;\n-    }\n-\n-    for module in compiled_modules.modules.iter().filter(|m| m.kind == ModuleKind::Regular) {\n-        let mut files = vec![];\n-\n-        if let Some(ref path) = module.object {\n-            files.push((WorkProductFileKind::Object, path.clone()));\n-        }\n-        if let Some(ref path) = module.bytecode {\n-            files.push((WorkProductFileKind::Bytecode, path.clone()));\n-        }\n-        if let Some(ref path) = module.bytecode_compressed {\n-            files.push((WorkProductFileKind::BytecodeCompressed, path.clone()));\n-        }\n-\n-        if let Some((id, product)) =\n-            copy_cgu_workproducts_to_incr_comp_cache_dir(sess, &module.name, &files)\n-        {\n-            work_products.insert(id, product);\n-        }\n-    }\n-\n-    work_products\n-}\n-\n-fn produce_final_output_artifacts(sess: &Session,\n-                                  compiled_modules: &CompiledModules,\n-                                  crate_output: &OutputFilenames) {\n-    let mut user_wants_bitcode = false;\n-    let mut user_wants_objects = false;\n-\n-    // Produce final compile outputs.\n-    let copy_gracefully = |from: &Path, to: &Path| {\n-        if let Err(e) = fs::copy(from, to) {\n-            sess.err(&format!(\"could not copy {:?} to {:?}: {}\", from, to, e));\n-        }\n-    };\n-\n-    let copy_if_one_unit = |output_type: OutputType,\n-                            keep_numbered: bool| {\n-        if compiled_modules.modules.len() == 1 {\n-            // 1) Only one codegen unit.  In this case it's no difficulty\n-            //    to copy `foo.0.x` to `foo.x`.\n-            let module_name = Some(&compiled_modules.modules[0].name[..]);\n-            let path = crate_output.temp_path(output_type, module_name);\n-            copy_gracefully(&path,\n-                            &crate_output.path(output_type));\n-            if !sess.opts.cg.save_temps && !keep_numbered {\n-                // The user just wants `foo.x`, not `foo.#module-name#.x`.\n-                remove(sess, &path);\n-            }\n-        } else {\n-            let ext = crate_output.temp_path(output_type, None)\n-                                  .extension()\n-                                  .unwrap()\n-                                  .to_str()\n-                                  .unwrap()\n-                                  .to_owned();\n-\n-            if crate_output.outputs.contains_key(&output_type) {\n-                // 2) Multiple codegen units, with `--emit foo=some_name`.  We have\n-                //    no good solution for this case, so warn the user.\n-                sess.warn(&format!(\"ignoring emit path because multiple .{} files \\\n-                                    were produced\", ext));\n-            } else if crate_output.single_output_file.is_some() {\n-                // 3) Multiple codegen units, with `-o some_name`.  We have\n-                //    no good solution for this case, so warn the user.\n-                sess.warn(&format!(\"ignoring -o because multiple .{} files \\\n-                                    were produced\", ext));\n-            } else {\n-                // 4) Multiple codegen units, but no explicit name.  We\n-                //    just leave the `foo.0.x` files in place.\n-                // (We don't have to do any work in this case.)\n-            }\n-        }\n-    };\n-\n-    // Flag to indicate whether the user explicitly requested bitcode.\n-    // Otherwise, we produced it only as a temporary output, and will need\n-    // to get rid of it.\n-    for output_type in crate_output.outputs.keys() {\n-        match *output_type {\n-            OutputType::Bitcode => {\n-                user_wants_bitcode = true;\n-                // Copy to .bc, but always keep the .0.bc.  There is a later\n-                // check to figure out if we should delete .0.bc files, or keep\n-                // them for making an rlib.\n-                copy_if_one_unit(OutputType::Bitcode, true);\n-            }\n-            OutputType::LlvmAssembly => {\n-                copy_if_one_unit(OutputType::LlvmAssembly, false);\n-            }\n-            OutputType::Assembly => {\n-                copy_if_one_unit(OutputType::Assembly, false);\n-            }\n-            OutputType::Object => {\n-                user_wants_objects = true;\n-                copy_if_one_unit(OutputType::Object, true);\n-            }\n-            OutputType::Mir |\n-            OutputType::Metadata |\n-            OutputType::Exe |\n-            OutputType::DepInfo => {}\n-        }\n-    }\n-\n-    // Clean up unwanted temporary files.\n-\n-    // We create the following files by default:\n-    //  - #crate#.#module-name#.bc\n-    //  - #crate#.#module-name#.o\n-    //  - #crate#.crate.metadata.bc\n-    //  - #crate#.crate.metadata.o\n-    //  - #crate#.o (linked from crate.##.o)\n-    //  - #crate#.bc (copied from crate.##.bc)\n-    // We may create additional files if requested by the user (through\n-    // `-C save-temps` or `--emit=` flags).\n-\n-    if !sess.opts.cg.save_temps {\n-        // Remove the temporary .#module-name#.o objects.  If the user didn't\n-        // explicitly request bitcode (with --emit=bc), and the bitcode is not\n-        // needed for building an rlib, then we must remove .#module-name#.bc as\n-        // well.\n-\n-        // Specific rules for keeping .#module-name#.bc:\n-        //  - If the user requested bitcode (`user_wants_bitcode`), and\n-        //    codegen_units > 1, then keep it.\n-        //  - If the user requested bitcode but codegen_units == 1, then we\n-        //    can toss .#module-name#.bc because we copied it to .bc earlier.\n-        //  - If we're not building an rlib and the user didn't request\n-        //    bitcode, then delete .#module-name#.bc.\n-        // If you change how this works, also update back::link::link_rlib,\n-        // where .#module-name#.bc files are (maybe) deleted after making an\n-        // rlib.\n-        let needs_crate_object = crate_output.outputs.contains_key(&OutputType::Exe);\n-\n-        let keep_numbered_bitcode = user_wants_bitcode && sess.codegen_units() > 1;\n-\n-        let keep_numbered_objects = needs_crate_object ||\n-                (user_wants_objects && sess.codegen_units() > 1);\n-\n-        for module in compiled_modules.modules.iter() {\n-            if let Some(ref path) = module.object {\n-                if !keep_numbered_objects {\n-                    remove(sess, path);\n-                }\n-            }\n-\n-            if let Some(ref path) = module.bytecode {\n-                if !keep_numbered_bitcode {\n-                    remove(sess, path);\n-                }\n-            }\n-        }\n-\n-        if !user_wants_bitcode {\n-            if let Some(ref path) = compiled_modules.metadata_module.bytecode {\n-                remove(sess, &path);\n-            }\n-\n-            if let Some(ref allocator_module) = compiled_modules.allocator_module {\n-                if let Some(ref path) = allocator_module.bytecode {\n-                    remove(sess, path);\n-                }\n-            }\n-        }\n-    }\n-\n-    // We leave the following files around by default:\n-    //  - #crate#.o\n-    //  - #crate#.crate.metadata.o\n-    //  - #crate#.bc\n-    // These are used in linking steps and will be cleaned up afterward.\n-}\n-\n-pub(crate) fn dump_incremental_data(_codegen_results: &CodegenResults) {\n-    // FIXME(mw): This does not work at the moment because the situation has\n-    //            become more complicated due to incremental LTO. Now a CGU\n-    //            can have more than two caching states.\n-    // println!(\"[incremental] Re-using {} out of {} modules\",\n-    //           codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n-    //           codegen_results.modules.len());\n-}\n-\n-enum WorkItem {\n-    /// Optimize a newly codegened, totally unoptimized module.\n-    Optimize(ModuleCodegen<ModuleLlvm>),\n-    /// Copy the post-LTO artifacts from the incremental cache to the output\n-    /// directory.\n-    CopyPostLtoArtifacts(CachedModuleCodegen),\n-    /// Perform (Thin)LTO on the given module.\n-    LTO(lto::LtoModuleCodegen),\n-}\n-\n-impl WorkItem {\n-    fn module_kind(&self) -> ModuleKind {\n-        match *self {\n-            WorkItem::Optimize(ref m) => m.kind,\n-            WorkItem::CopyPostLtoArtifacts(_) |\n-            WorkItem::LTO(_) => ModuleKind::Regular,\n-        }\n-    }\n-\n-    fn name(&self) -> String {\n-        match *self {\n-            WorkItem::Optimize(ref m) => format!(\"optimize: {}\", m.name),\n-            WorkItem::CopyPostLtoArtifacts(ref m) => format!(\"copy post LTO artifacts: {}\", m.name),\n-            WorkItem::LTO(ref m) => format!(\"lto: {}\", m.name()),\n-        }\n-    }\n-}\n-\n-enum WorkItemResult {\n-    Compiled(CompiledModule),\n-    NeedsLTO(ModuleCodegen<ModuleLlvm>),\n-}\n-\n-fn execute_work_item(cgcx: &CodegenContext,\n-                     work_item: WorkItem,\n-                     timeline: &mut Timeline)\n-    -> Result<WorkItemResult, FatalError>\n-{\n-    let module_config = cgcx.config(work_item.module_kind());\n-\n-    match work_item {\n-        WorkItem::Optimize(module) => {\n-            execute_optimize_work_item(cgcx, module, module_config, timeline)\n-        }\n-        WorkItem::CopyPostLtoArtifacts(module) => {\n-            execute_copy_from_cache_work_item(cgcx, module, module_config, timeline)\n-        }\n-        WorkItem::LTO(module) => {\n-            execute_lto_work_item(cgcx, module, module_config, timeline)\n-        }\n-    }\n-}\n-\n-fn execute_optimize_work_item(cgcx: &CodegenContext,\n-                              module: ModuleCodegen<ModuleLlvm>,\n-                              module_config: &ModuleConfig,\n-                              timeline: &mut Timeline)\n-    -> Result<WorkItemResult, FatalError>\n-{\n-    let diag_handler = cgcx.create_diag_handler();\n-\n-    unsafe {\n-        optimize(cgcx, &diag_handler, &module, module_config, timeline)?;\n-    }\n-\n-    let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n-\n-    // After we've done the initial round of optimizations we need to\n-    // decide whether to synchronously codegen this module or ship it\n-    // back to the coordinator thread for further LTO processing (which\n-    // has to wait for all the initial modules to be optimized).\n-    //\n-    // Here we dispatch based on the `cgcx.lto` and kind of module we're\n-    // codegenning...\n-    let needs_lto = match cgcx.lto {\n-        Lto::No => false,\n-\n-        // If the linker does LTO, we don't have to do it. Note that we\n-        // keep doing full LTO, if it is requested, as not to break the\n-        // assumption that the output will be a single module.\n-        Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n-\n-        // Here we've got a full crate graph LTO requested. We ignore\n-        // this, however, if the crate type is only an rlib as there's\n-        // no full crate graph to process, that'll happen later.\n-        //\n-        // This use case currently comes up primarily for targets that\n-        // require LTO so the request for LTO is always unconditionally\n-        // passed down to the backend, but we don't actually want to do\n-        // anything about it yet until we've got a final product.\n-        Lto::Fat | Lto::Thin => {\n-            cgcx.crate_types.len() != 1 ||\n-                cgcx.crate_types[0] != config::CrateType::Rlib\n-        }\n-\n-        // When we're automatically doing ThinLTO for multi-codegen-unit\n-        // builds we don't actually want to LTO the allocator modules if\n-        // it shows up. This is due to various linker shenanigans that\n-        // we'll encounter later.\n-        Lto::ThinLocal => {\n-            module.kind != ModuleKind::Allocator\n-        }\n-    };\n-\n-    // Metadata modules never participate in LTO regardless of the lto\n-    // settings.\n-    let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n-\n-    if needs_lto {\n-        Ok(WorkItemResult::NeedsLTO(module))\n-    } else {\n-        let module = unsafe {\n-            codegen(cgcx, &diag_handler, module, module_config, timeline)?\n-        };\n-        Ok(WorkItemResult::Compiled(module))\n-    }\n-}\n-\n-fn execute_copy_from_cache_work_item(cgcx: &CodegenContext,\n-                                     module: CachedModuleCodegen,\n-                                     module_config: &ModuleConfig,\n-                                     _: &mut Timeline)\n-    -> Result<WorkItemResult, FatalError>\n-{\n-    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n-                                    .as_ref()\n-                                    .unwrap();\n-    let mut object = None;\n-    let mut bytecode = None;\n-    let mut bytecode_compressed = None;\n-    for (kind, saved_file) in &module.source.saved_files {\n-        let obj_out = match kind {\n-            WorkProductFileKind::Object => {\n-                let path = cgcx.output_filenames.temp_path(OutputType::Object,\n-                                                           Some(&module.name));\n-                object = Some(path.clone());\n-                path\n-            }\n-            WorkProductFileKind::Bytecode => {\n-                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n-                                                           Some(&module.name));\n-                bytecode = Some(path.clone());\n-                path\n-            }\n-            WorkProductFileKind::BytecodeCompressed => {\n-                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n-                                                           Some(&module.name))\n-                    .with_extension(RLIB_BYTECODE_EXTENSION);\n-                bytecode_compressed = Some(path.clone());\n-                path\n-            }\n-        };\n-        let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n-                                           &saved_file);\n-        debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n-               module.name,\n-               source_file,\n-               obj_out.display());\n-        if let Err(err) = link_or_copy(&source_file, &obj_out) {\n-            let diag_handler = cgcx.create_diag_handler();\n-            diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n-                                      source_file.display(),\n-                                      obj_out.display(),\n-                                      err));\n-        }\n-    }\n-\n-    assert_eq!(object.is_some(), module_config.emit_obj);\n-    assert_eq!(bytecode.is_some(), module_config.emit_bc);\n-    assert_eq!(bytecode_compressed.is_some(), module_config.emit_bc_compressed);\n-\n-    Ok(WorkItemResult::Compiled(CompiledModule {\n-        name: module.name,\n-        kind: ModuleKind::Regular,\n-        object,\n-        bytecode,\n-        bytecode_compressed,\n-    }))\n-}\n-\n-fn execute_lto_work_item(cgcx: &CodegenContext,\n-                         mut module: lto::LtoModuleCodegen,\n-                         module_config: &ModuleConfig,\n-                         timeline: &mut Timeline)\n-    -> Result<WorkItemResult, FatalError>\n-{\n-    let diag_handler = cgcx.create_diag_handler();\n-\n-    unsafe {\n-        let module = module.optimize(cgcx, timeline)?;\n-        let module = codegen(cgcx, &diag_handler, module, module_config, timeline)?;\n-        Ok(WorkItemResult::Compiled(module))\n-    }\n-}\n-\n-enum Message {\n-    Token(io::Result<Acquired>),\n-    NeedsLTO {\n-        result: ModuleCodegen<ModuleLlvm>,\n-        worker_id: usize,\n-    },\n-    Done {\n-        result: Result<CompiledModule, ()>,\n-        worker_id: usize,\n-    },\n-    CodegenDone {\n-        llvm_work_item: WorkItem,\n-        cost: u64,\n-    },\n-    AddImportOnlyModule {\n-        module_data: SerializedModule,\n-        work_product: WorkProduct,\n-    },\n-    CodegenComplete,\n-    CodegenItem,\n-    CodegenAborted,\n-}\n-\n-struct Diagnostic {\n-    msg: String,\n-    code: Option<DiagnosticId>,\n-    lvl: Level,\n-}\n-\n-#[derive(PartialEq, Clone, Copy, Debug)]\n-enum MainThreadWorkerState {\n-    Idle,\n-    Codegenning,\n-    LLVMing,\n-}\n-\n-fn start_executing_work(tcx: TyCtxt,\n-                        crate_info: &CrateInfo,\n-                        shared_emitter: SharedEmitter,\n-                        codegen_worker_send: Sender<Message>,\n-                        coordinator_receive: Receiver<Box<dyn Any + Send>>,\n-                        total_cgus: usize,\n-                        jobserver: Client,\n-                        time_graph: Option<TimeGraph>,\n-                        modules_config: Arc<ModuleConfig>,\n-                        metadata_config: Arc<ModuleConfig>,\n-                        allocator_config: Arc<ModuleConfig>)\n-                        -> thread::JoinHandle<Result<CompiledModules, ()>> {\n-    let coordinator_send = tcx.tx_to_llvm_workers.lock().clone();\n-    let sess = tcx.sess;\n-\n-    // Compute the set of symbols we need to retain when doing LTO (if we need to)\n-    let exported_symbols = {\n-        let mut exported_symbols = FxHashMap::default();\n-\n-        let copy_symbols = |cnum| {\n-            let symbols = tcx.exported_symbols(cnum)\n-                             .iter()\n-                             .map(|&(s, lvl)| (s.symbol_name(tcx).to_string(), lvl))\n-                             .collect();\n-            Arc::new(symbols)\n-        };\n-\n-        match sess.lto() {\n-            Lto::No => None,\n-            Lto::ThinLocal => {\n-                exported_symbols.insert(LOCAL_CRATE, copy_symbols(LOCAL_CRATE));\n-                Some(Arc::new(exported_symbols))\n-            }\n-            Lto::Fat | Lto::Thin => {\n-                exported_symbols.insert(LOCAL_CRATE, copy_symbols(LOCAL_CRATE));\n-                for &cnum in tcx.crates().iter() {\n-                    exported_symbols.insert(cnum, copy_symbols(cnum));\n-                }\n-                Some(Arc::new(exported_symbols))\n-            }\n-        }\n-    };\n-\n-    // First up, convert our jobserver into a helper thread so we can use normal\n-    // mpsc channels to manage our messages and such.\n-    // After we've requested tokens then we'll, when we can,\n-    // get tokens on `coordinator_receive` which will\n-    // get managed in the main loop below.\n-    let coordinator_send2 = coordinator_send.clone();\n-    let helper = jobserver.into_helper_thread(move |token| {\n-        drop(coordinator_send2.send(Box::new(Message::Token(token))));\n-    }).expect(\"failed to spawn helper thread\");\n-\n-    let mut each_linked_rlib_for_lto = Vec::new();\n-    drop(link::each_linked_rlib(sess, crate_info, &mut |cnum, path| {\n-        if link::ignored_for_lto(sess, crate_info, cnum) {\n-            return\n-        }\n-        each_linked_rlib_for_lto.push((cnum, path.to_path_buf()));\n-    }));\n-\n-    let assembler_cmd = if modules_config.no_integrated_as {\n-        // HACK: currently we use linker (gcc) as our assembler\n-        let (linker, flavor) = link::linker_and_flavor(sess);\n-\n-        let (name, mut cmd) = get_linker(sess, &linker, flavor);\n-        cmd.args(&sess.target.target.options.asm_args);\n-\n-        Some(Arc::new(AssemblerCommand { name, cmd }))\n-    } else {\n-        None\n-    };\n-\n-    let cgcx = CodegenContext {\n-        crate_types: sess.crate_types.borrow().clone(),\n-        each_linked_rlib_for_lto,\n-        lto: sess.lto(),\n-        no_landing_pads: sess.no_landing_pads(),\n-        fewer_names: sess.fewer_names(),\n-        save_temps: sess.opts.cg.save_temps,\n-        opts: Arc::new(sess.opts.clone()),\n-        time_passes: sess.time_passes(),\n-        exported_symbols,\n-        plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n-        remark: sess.opts.cg.remark.clone(),\n-        worker: 0,\n-        incr_comp_session_dir: sess.incr_comp_session_dir_opt().map(|r| r.clone()),\n-        cgu_reuse_tracker: sess.cgu_reuse_tracker.clone(),\n-        coordinator_send,\n-        diag_emitter: shared_emitter.clone(),\n-        time_graph,\n-        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n-        regular_module_config: modules_config,\n-        metadata_module_config: metadata_config,\n-        allocator_module_config: allocator_config,\n-        tm_factory: target_machine_factory(tcx.sess, false),\n-        total_cgus,\n-        msvc_imps_needed: msvc_imps_needed(tcx),\n-        target_pointer_width: tcx.sess.target.target.target_pointer_width.clone(),\n-        debuginfo: tcx.sess.opts.debuginfo,\n-        assembler_cmd,\n-    };\n-\n-    // This is the \"main loop\" of parallel work happening for parallel codegen.\n-    // It's here that we manage parallelism, schedule work, and work with\n-    // messages coming from clients.\n-    //\n-    // There are a few environmental pre-conditions that shape how the system\n-    // is set up:\n-    //\n-    // - Error reporting only can happen on the main thread because that's the\n-    //   only place where we have access to the compiler `Session`.\n-    // - LLVM work can be done on any thread.\n-    // - Codegen can only happen on the main thread.\n-    // - Each thread doing substantial work most be in possession of a `Token`\n-    //   from the `Jobserver`.\n-    // - The compiler process always holds one `Token`. Any additional `Tokens`\n-    //   have to be requested from the `Jobserver`.\n-    //\n-    // Error Reporting\n-    // ===============\n-    // The error reporting restriction is handled separately from the rest: We\n-    // set up a `SharedEmitter` the holds an open channel to the main thread.\n-    // When an error occurs on any thread, the shared emitter will send the\n-    // error message to the receiver main thread (`SharedEmitterMain`). The\n-    // main thread will periodically query this error message queue and emit\n-    // any error messages it has received. It might even abort compilation if\n-    // has received a fatal error. In this case we rely on all other threads\n-    // being torn down automatically with the main thread.\n-    // Since the main thread will often be busy doing codegen work, error\n-    // reporting will be somewhat delayed, since the message queue can only be\n-    // checked in between to work packages.\n-    //\n-    // Work Processing Infrastructure\n-    // ==============================\n-    // The work processing infrastructure knows three major actors:\n-    //\n-    // - the coordinator thread,\n-    // - the main thread, and\n-    // - LLVM worker threads\n-    //\n-    // The coordinator thread is running a message loop. It instructs the main\n-    // thread about what work to do when, and it will spawn off LLVM worker\n-    // threads as open LLVM WorkItems become available.\n-    //\n-    // The job of the main thread is to codegen CGUs into LLVM work package\n-    // (since the main thread is the only thread that can do this). The main\n-    // thread will block until it receives a message from the coordinator, upon\n-    // which it will codegen one CGU, send it to the coordinator and block\n-    // again. This way the coordinator can control what the main thread is\n-    // doing.\n-    //\n-    // The coordinator keeps a queue of LLVM WorkItems, and when a `Token` is\n-    // available, it will spawn off a new LLVM worker thread and let it process\n-    // that a WorkItem. When a LLVM worker thread is done with its WorkItem,\n-    // it will just shut down, which also frees all resources associated with\n-    // the given LLVM module, and sends a message to the coordinator that the\n-    // has been completed.\n-    //\n-    // Work Scheduling\n-    // ===============\n-    // The scheduler's goal is to minimize the time it takes to complete all\n-    // work there is, however, we also want to keep memory consumption low\n-    // if possible. These two goals are at odds with each other: If memory\n-    // consumption were not an issue, we could just let the main thread produce\n-    // LLVM WorkItems at full speed, assuring maximal utilization of\n-    // Tokens/LLVM worker threads. However, since codegen usual is faster\n-    // than LLVM processing, the queue of LLVM WorkItems would fill up and each\n-    // WorkItem potentially holds on to a substantial amount of memory.\n-    //\n-    // So the actual goal is to always produce just enough LLVM WorkItems as\n-    // not to starve our LLVM worker threads. That means, once we have enough\n-    // WorkItems in our queue, we can block the main thread, so it does not\n-    // produce more until we need them.\n-    //\n-    // Doing LLVM Work on the Main Thread\n-    // ----------------------------------\n-    // Since the main thread owns the compiler processes implicit `Token`, it is\n-    // wasteful to keep it blocked without doing any work. Therefore, what we do\n-    // in this case is: We spawn off an additional LLVM worker thread that helps\n-    // reduce the queue. The work it is doing corresponds to the implicit\n-    // `Token`. The coordinator will mark the main thread as being busy with\n-    // LLVM work. (The actual work happens on another OS thread but we just care\n-    // about `Tokens`, not actual threads).\n-    //\n-    // When any LLVM worker thread finishes while the main thread is marked as\n-    // \"busy with LLVM work\", we can do a little switcheroo: We give the Token\n-    // of the just finished thread to the LLVM worker thread that is working on\n-    // behalf of the main thread's implicit Token, thus freeing up the main\n-    // thread again. The coordinator can then again decide what the main thread\n-    // should do. This allows the coordinator to make decisions at more points\n-    // in time.\n-    //\n-    // Striking a Balance between Throughput and Memory Consumption\n-    // ------------------------------------------------------------\n-    // Since our two goals, (1) use as many Tokens as possible and (2) keep\n-    // memory consumption as low as possible, are in conflict with each other,\n-    // we have to find a trade off between them. Right now, the goal is to keep\n-    // all workers busy, which means that no worker should find the queue empty\n-    // when it is ready to start.\n-    // How do we do achieve this? Good question :) We actually never know how\n-    // many `Tokens` are potentially available so it's hard to say how much to\n-    // fill up the queue before switching the main thread to LLVM work. Also we\n-    // currently don't have a means to estimate how long a running LLVM worker\n-    // will still be busy with it's current WorkItem. However, we know the\n-    // maximal count of available Tokens that makes sense (=the number of CPU\n-    // cores), so we can take a conservative guess. The heuristic we use here\n-    // is implemented in the `queue_full_enough()` function.\n-    //\n-    // Some Background on Jobservers\n-    // -----------------------------\n-    // It's worth also touching on the management of parallelism here. We don't\n-    // want to just spawn a thread per work item because while that's optimal\n-    // parallelism it may overload a system with too many threads or violate our\n-    // configuration for the maximum amount of cpu to use for this process. To\n-    // manage this we use the `jobserver` crate.\n-    //\n-    // Job servers are an artifact of GNU make and are used to manage\n-    // parallelism between processes. A jobserver is a glorified IPC semaphore\n-    // basically. Whenever we want to run some work we acquire the semaphore,\n-    // and whenever we're done with that work we release the semaphore. In this\n-    // manner we can ensure that the maximum number of parallel workers is\n-    // capped at any one point in time.\n-    //\n-    // LTO and the coordinator thread\n-    // ------------------------------\n-    //\n-    // The final job the coordinator thread is responsible for is managing LTO\n-    // and how that works. When LTO is requested what we'll to is collect all\n-    // optimized LLVM modules into a local vector on the coordinator. Once all\n-    // modules have been codegened and optimized we hand this to the `lto`\n-    // module for further optimization. The `lto` module will return back a list\n-    // of more modules to work on, which the coordinator will continue to spawn\n-    // work for.\n-    //\n-    // Each LLVM module is automatically sent back to the coordinator for LTO if\n-    // necessary. There's already optimizations in place to avoid sending work\n-    // back to the coordinator if LTO isn't requested.\n-    return thread::spawn(move || {\n-        // We pretend to be within the top-level LLVM time-passes task here:\n-        set_time_depth(1);\n-\n-        let max_workers = ::num_cpus::get();\n-        let mut worker_id_counter = 0;\n-        let mut free_worker_ids = Vec::new();\n-        let mut get_worker_id = |free_worker_ids: &mut Vec<usize>| {\n-            if let Some(id) = free_worker_ids.pop() {\n-                id\n-            } else {\n-                let id = worker_id_counter;\n-                worker_id_counter += 1;\n-                id\n-            }\n-        };\n-\n-        // This is where we collect codegen units that have gone all the way\n-        // through codegen and LLVM.\n-        let mut compiled_modules = vec![];\n-        let mut compiled_metadata_module = None;\n-        let mut compiled_allocator_module = None;\n-        let mut needs_lto = Vec::new();\n-        let mut lto_import_only_modules = Vec::new();\n-        let mut started_lto = false;\n-        let mut codegen_aborted = false;\n-\n-        // This flag tracks whether all items have gone through codegens\n-        let mut codegen_done = false;\n-\n-        // This is the queue of LLVM work items that still need processing.\n-        let mut work_items = Vec::<(WorkItem, u64)>::new();\n-\n-        // This are the Jobserver Tokens we currently hold. Does not include\n-        // the implicit Token the compiler process owns no matter what.\n-        let mut tokens = Vec::new();\n-\n-        let mut main_thread_worker_state = MainThreadWorkerState::Idle;\n-        let mut running = 0;\n-\n-        let mut llvm_start_time = None;\n-\n-        // Run the message loop while there's still anything that needs message\n-        // processing. Note that as soon as codegen is aborted we simply want to\n-        // wait for all existing work to finish, so many of the conditions here\n-        // only apply if codegen hasn't been aborted as they represent pending\n-        // work to be done.\n-        while !codegen_done ||\n-              running > 0 ||\n-              (!codegen_aborted && (\n-                  work_items.len() > 0 ||\n-                  needs_lto.len() > 0 ||\n-                  lto_import_only_modules.len() > 0 ||\n-                  main_thread_worker_state != MainThreadWorkerState::Idle\n-              ))\n-        {\n-\n-            // While there are still CGUs to be codegened, the coordinator has\n-            // to decide how to utilize the compiler processes implicit Token:\n-            // For codegenning more CGU or for running them through LLVM.\n-            if !codegen_done {\n-                if main_thread_worker_state == MainThreadWorkerState::Idle {\n-                    if !queue_full_enough(work_items.len(), running, max_workers) {\n-                        // The queue is not full enough, codegen more items:\n-                        if let Err(_) = codegen_worker_send.send(Message::CodegenItem) {\n-                            panic!(\"Could not send Message::CodegenItem to main thread\")\n-                        }\n-                        main_thread_worker_state = MainThreadWorkerState::Codegenning;\n-                    } else {\n-                        // The queue is full enough to not let the worker\n-                        // threads starve. Use the implicit Token to do some\n-                        // LLVM work too.\n-                        let (item, _) = work_items.pop()\n-                            .expect(\"queue empty - queue_full_enough() broken?\");\n-                        let cgcx = CodegenContext {\n-                            worker: get_worker_id(&mut free_worker_ids),\n-                            .. cgcx.clone()\n-                        };\n-                        maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n-                                               &mut llvm_start_time);\n-                        main_thread_worker_state = MainThreadWorkerState::LLVMing;\n-                        spawn_work(cgcx, item);\n-                    }\n-                }\n-            } else if codegen_aborted {\n-                // don't queue up any more work if codegen was aborted, we're\n-                // just waiting for our existing children to finish\n-            } else {\n-                // If we've finished everything related to normal codegen\n-                // then it must be the case that we've got some LTO work to do.\n-                // Perform the serial work here of figuring out what we're\n-                // going to LTO and then push a bunch of work items onto our\n-                // queue to do LTO\n-                if work_items.len() == 0 &&\n-                   running == 0 &&\n-                   main_thread_worker_state == MainThreadWorkerState::Idle {\n-                    assert!(!started_lto);\n-                    assert!(needs_lto.len() + lto_import_only_modules.len() > 0);\n-                    started_lto = true;\n-                    let modules = mem::replace(&mut needs_lto, Vec::new());\n-                    let import_only_modules =\n-                        mem::replace(&mut lto_import_only_modules, Vec::new());\n-                    for (work, cost) in generate_lto_work(&cgcx, modules, import_only_modules) {\n-                        let insertion_index = work_items\n-                            .binary_search_by_key(&cost, |&(_, cost)| cost)\n-                            .unwrap_or_else(|e| e);\n-                        work_items.insert(insertion_index, (work, cost));\n-                        if !cgcx.opts.debugging_opts.no_parallel_llvm {\n-                            helper.request_token();\n-                        }\n-                    }\n-                }\n-\n-                // In this branch, we know that everything has been codegened,\n-                // so it's just a matter of determining whether the implicit\n-                // Token is free to use for LLVM work.\n-                match main_thread_worker_state {\n-                    MainThreadWorkerState::Idle => {\n-                        if let Some((item, _)) = work_items.pop() {\n-                            let cgcx = CodegenContext {\n-                                worker: get_worker_id(&mut free_worker_ids),\n-                                .. cgcx.clone()\n-                            };\n-                            maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n-                                                   &mut llvm_start_time);\n-                            main_thread_worker_state = MainThreadWorkerState::LLVMing;\n-                            spawn_work(cgcx, item);\n-                        } else {\n-                            // There is no unstarted work, so let the main thread\n-                            // take over for a running worker. Otherwise the\n-                            // implicit token would just go to waste.\n-                            // We reduce the `running` counter by one. The\n-                            // `tokens.truncate()` below will take care of\n-                            // giving the Token back.\n-                            debug_assert!(running > 0);\n-                            running -= 1;\n-                            main_thread_worker_state = MainThreadWorkerState::LLVMing;\n-                        }\n-                    }\n-                    MainThreadWorkerState::Codegenning => {\n-                        bug!(\"codegen worker should not be codegenning after \\\n-                              codegen was already completed\")\n-                    }\n-                    MainThreadWorkerState::LLVMing => {\n-                        // Already making good use of that token\n-                    }\n-                }\n-            }\n-\n-            // Spin up what work we can, only doing this while we've got available\n-            // parallelism slots and work left to spawn.\n-            while !codegen_aborted && work_items.len() > 0 && running < tokens.len() {\n-                let (item, _) = work_items.pop().unwrap();\n-\n-                maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n-                                       &mut llvm_start_time);\n-\n-                let cgcx = CodegenContext {\n-                    worker: get_worker_id(&mut free_worker_ids),\n-                    .. cgcx.clone()\n-                };\n-\n-                spawn_work(cgcx, item);\n-                running += 1;\n-            }\n-\n-            // Relinquish accidentally acquired extra tokens\n-            tokens.truncate(running);\n-\n-            let msg = coordinator_receive.recv().unwrap();\n-            match *msg.downcast::<Message>().ok().unwrap() {\n-                // Save the token locally and the next turn of the loop will use\n-                // this to spawn a new unit of work, or it may get dropped\n-                // immediately if we have no more work to spawn.\n-                Message::Token(token) => {\n-                    match token {\n-                        Ok(token) => {\n-                            tokens.push(token);\n-\n-                            if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n-                                // If the main thread token is used for LLVM work\n-                                // at the moment, we turn that thread into a regular\n-                                // LLVM worker thread, so the main thread is free\n-                                // to react to codegen demand.\n-                                main_thread_worker_state = MainThreadWorkerState::Idle;\n-                                running += 1;\n-                            }\n-                        }\n-                        Err(e) => {\n-                            let msg = &format!(\"failed to acquire jobserver token: {}\", e);\n-                            shared_emitter.fatal(msg);\n-                            // Exit the coordinator thread\n-                            panic!(\"{}\", msg)\n-                        }\n-                    }\n-                }\n-\n-                Message::CodegenDone { llvm_work_item, cost } => {\n-                    // We keep the queue sorted by estimated processing cost,\n-                    // so that more expensive items are processed earlier. This\n-                    // is good for throughput as it gives the main thread more\n-                    // time to fill up the queue and it avoids scheduling\n-                    // expensive items to the end.\n-                    // Note, however, that this is not ideal for memory\n-                    // consumption, as LLVM module sizes are not evenly\n-                    // distributed.\n-                    let insertion_index =\n-                        work_items.binary_search_by_key(&cost, |&(_, cost)| cost);\n-                    let insertion_index = match insertion_index {\n-                        Ok(idx) | Err(idx) => idx\n-                    };\n-                    work_items.insert(insertion_index, (llvm_work_item, cost));\n-\n-                    if !cgcx.opts.debugging_opts.no_parallel_llvm {\n-                        helper.request_token();\n-                    }\n-                    assert!(!codegen_aborted);\n-                    assert_eq!(main_thread_worker_state,\n-                               MainThreadWorkerState::Codegenning);\n-                    main_thread_worker_state = MainThreadWorkerState::Idle;\n-                }\n-\n-                Message::CodegenComplete => {\n-                    codegen_done = true;\n-                    assert!(!codegen_aborted);\n-                    assert_eq!(main_thread_worker_state,\n-                               MainThreadWorkerState::Codegenning);\n-                    main_thread_worker_state = MainThreadWorkerState::Idle;\n-                }\n-\n-                // If codegen is aborted that means translation was aborted due\n-                // to some normal-ish compiler error. In this situation we want\n-                // to exit as soon as possible, but we want to make sure all\n-                // existing work has finished. Flag codegen as being done, and\n-                // then conditions above will ensure no more work is spawned but\n-                // we'll keep executing this loop until `running` hits 0.\n-                Message::CodegenAborted => {\n-                    assert!(!codegen_aborted);\n-                    codegen_done = true;\n-                    codegen_aborted = true;\n-                    assert_eq!(main_thread_worker_state,\n-                               MainThreadWorkerState::Codegenning);\n-                }\n-\n-                // If a thread exits successfully then we drop a token associated\n-                // with that worker and update our `running` count. We may later\n-                // re-acquire a token to continue running more work. We may also not\n-                // actually drop a token here if the worker was running with an\n-                // \"ephemeral token\"\n-                //\n-                // Note that if the thread failed that means it panicked, so we\n-                // abort immediately.\n-                Message::Done { result: Ok(compiled_module), worker_id } => {\n-                    if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n-                        main_thread_worker_state = MainThreadWorkerState::Idle;\n-                    } else {\n-                        running -= 1;\n-                    }\n-\n-                    free_worker_ids.push(worker_id);\n-\n-                    match compiled_module.kind {\n-                        ModuleKind::Regular => {\n-                            compiled_modules.push(compiled_module);\n-                        }\n-                        ModuleKind::Metadata => {\n-                            assert!(compiled_metadata_module.is_none());\n-                            compiled_metadata_module = Some(compiled_module);\n-                        }\n-                        ModuleKind::Allocator => {\n-                            assert!(compiled_allocator_module.is_none());\n-                            compiled_allocator_module = Some(compiled_module);\n-                        }\n-                    }\n-                }\n-                Message::NeedsLTO { result, worker_id } => {\n-                    assert!(!started_lto);\n-                    if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n-                        main_thread_worker_state = MainThreadWorkerState::Idle;\n-                    } else {\n-                        running -= 1;\n-                    }\n-                    free_worker_ids.push(worker_id);\n-                    needs_lto.push(result);\n-                }\n-                Message::AddImportOnlyModule { module_data, work_product } => {\n-                    assert!(!started_lto);\n-                    assert!(!codegen_done);\n-                    assert_eq!(main_thread_worker_state,\n-                               MainThreadWorkerState::Codegenning);\n-                    lto_import_only_modules.push((module_data, work_product));\n-                    main_thread_worker_state = MainThreadWorkerState::Idle;\n-                }\n-                Message::Done { result: Err(()), worker_id: _ } => {\n-                    bug!(\"worker thread panicked\");\n-                }\n-                Message::CodegenItem => {\n-                    bug!(\"the coordinator should not receive codegen requests\")\n-                }\n-            }\n-        }\n-\n-        if let Some(llvm_start_time) = llvm_start_time {\n-            let total_llvm_time = Instant::now().duration_since(llvm_start_time);\n-            // This is the top-level timing for all of LLVM, set the time-depth\n-            // to zero.\n-            set_time_depth(0);\n-            print_time_passes_entry(cgcx.time_passes,\n-                                    \"LLVM passes\",\n-                                    total_llvm_time);\n-        }\n-\n-        // Regardless of what order these modules completed in, report them to\n-        // the backend in the same order every time to ensure that we're handing\n-        // out deterministic results.\n-        compiled_modules.sort_by(|a, b| a.name.cmp(&b.name));\n-\n-        let compiled_metadata_module = compiled_metadata_module\n-            .expect(\"Metadata module not compiled?\");\n-\n-        Ok(CompiledModules {\n-            modules: compiled_modules,\n-            metadata_module: compiled_metadata_module,\n-            allocator_module: compiled_allocator_module,\n-        })\n-    });\n-\n-    // A heuristic that determines if we have enough LLVM WorkItems in the\n-    // queue so that the main thread can do LLVM work instead of codegen\n-    fn queue_full_enough(items_in_queue: usize,\n-                         workers_running: usize,\n-                         max_workers: usize) -> bool {\n-        // Tune me, plz.\n-        items_in_queue > 0 &&\n-        items_in_queue >= max_workers.saturating_sub(workers_running / 2)\n-    }\n-\n-    fn maybe_start_llvm_timer(config: &ModuleConfig,\n-                              llvm_start_time: &mut Option<Instant>) {\n-        // We keep track of the -Ztime-passes output manually,\n-        // since the closure-based interface does not fit well here.\n-        if config.time_passes {\n-            if llvm_start_time.is_none() {\n-                *llvm_start_time = Some(Instant::now());\n-            }\n-        }\n-    }\n-}\n-\n-pub const CODEGEN_WORKER_ID: usize = ::std::usize::MAX;\n-pub const CODEGEN_WORKER_TIMELINE: time_graph::TimelineId =\n-    time_graph::TimelineId(CODEGEN_WORKER_ID);\n-pub const CODEGEN_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n-    time_graph::WorkPackageKind(&[\"#DE9597\", \"#FED1D3\", \"#FDC5C7\", \"#B46668\", \"#88494B\"]);\n-const LLVM_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n-    time_graph::WorkPackageKind(&[\"#7DB67A\", \"#C6EEC4\", \"#ACDAAA\", \"#579354\", \"#3E6F3C\"]);\n-\n-fn spawn_work(cgcx: CodegenContext, work: WorkItem) {\n-    let depth = time_depth();\n-\n-    thread::spawn(move || {\n-        set_time_depth(depth);\n-\n-        // Set up a destructor which will fire off a message that we're done as\n-        // we exit.\n-        struct Bomb {\n-            coordinator_send: Sender<Box<dyn Any + Send>>,\n-            result: Option<WorkItemResult>,\n-            worker_id: usize,\n-        }\n-        impl Drop for Bomb {\n-            fn drop(&mut self) {\n-                let worker_id = self.worker_id;\n-                let msg = match self.result.take() {\n-                    Some(WorkItemResult::Compiled(m)) => {\n-                        Message::Done { result: Ok(m), worker_id }\n-                    }\n-                    Some(WorkItemResult::NeedsLTO(m)) => {\n-                        Message::NeedsLTO { result: m, worker_id }\n-                    }\n-                    None => Message::Done { result: Err(()), worker_id }\n-                };\n-                drop(self.coordinator_send.send(Box::new(msg)));\n-            }\n-        }\n-\n-        let mut bomb = Bomb {\n-            coordinator_send: cgcx.coordinator_send.clone(),\n-            result: None,\n-            worker_id: cgcx.worker,\n-        };\n-\n-        // Execute the work itself, and if it finishes successfully then flag\n-        // ourselves as a success as well.\n-        //\n-        // Note that we ignore any `FatalError` coming out of `execute_work_item`,\n-        // as a diagnostic was already sent off to the main thread - just\n-        // surface that there was an error in this worker.\n-        bomb.result = {\n-            let timeline = cgcx.time_graph.as_ref().map(|tg| {\n-                tg.start(time_graph::TimelineId(cgcx.worker),\n-                         LLVM_WORK_PACKAGE_KIND,\n-                         &work.name())\n-            });\n-            let mut timeline = timeline.unwrap_or(Timeline::noop());\n-            execute_work_item(&cgcx, work, &mut timeline).ok()\n-        };\n-    });\n-}\n-\n-pub fn run_assembler(cgcx: &CodegenContext, handler: &Handler, assembly: &Path, object: &Path) {\n-    let assembler = cgcx.assembler_cmd\n-        .as_ref()\n-        .expect(\"cgcx.assembler_cmd is missing?\");\n-\n-    let pname = &assembler.name;\n-    let mut cmd = assembler.cmd.clone();\n-    cmd.arg(\"-c\").arg(\"-o\").arg(object).arg(assembly);\n-    debug!(\"{:?}\", cmd);\n-\n-    match cmd.output() {\n-        Ok(prog) => {\n-            if !prog.status.success() {\n-                let mut note = prog.stderr.clone();\n-                note.extend_from_slice(&prog.stdout);\n-\n-                handler.struct_err(&format!(\"linking with `{}` failed: {}\",\n-                                            pname.display(),\n-                                            prog.status))\n-                       .note(&format!(\"{:?}\", &cmd))\n-                       .note(str::from_utf8(&note[..]).unwrap())\n-                       .emit();\n-                handler.abort_if_errors();\n-            }\n-        },\n-        Err(e) => {\n-            handler.err(&format!(\"could not exec the linker `{}`: {}\", pname.display(), e));\n-            handler.abort_if_errors();\n-        }\n-    }\n-}\n-\n pub unsafe fn with_llvm_pmb(llmod: &llvm::Module,\n                             config: &ModuleConfig,\n                             opt_level: llvm::CodeGenOptLevel,\n@@ -2203,7 +698,7 @@ pub unsafe fn with_llvm_pmb(llmod: &llvm::Module,\n     // reasonable defaults and prepare it to actually populate the pass\n     // manager.\n     let builder = llvm::LLVMPassManagerBuilderCreate();\n-    let opt_size = config.opt_size.unwrap_or(llvm::CodeGenOptSizeNone);\n+    let opt_size = config.opt_size.map(get_llvm_opt_size).unwrap_or(llvm::CodeGenOptSizeNone);\n     let inline_threshold = config.inline_threshold;\n \n     let pgo_gen_path = config.pgo_gen.as_ref().map(|s| {\n@@ -2271,295 +766,16 @@ pub unsafe fn with_llvm_pmb(llmod: &llvm::Module,\n     llvm::LLVMPassManagerBuilderDispose(builder);\n }\n \n-\n-enum SharedEmitterMessage {\n-    Diagnostic(Diagnostic),\n-    InlineAsmError(u32, String),\n-    AbortIfErrors,\n-    Fatal(String),\n-}\n-\n-#[derive(Clone)]\n-pub struct SharedEmitter {\n-    sender: Sender<SharedEmitterMessage>,\n-}\n-\n-pub struct SharedEmitterMain {\n-    receiver: Receiver<SharedEmitterMessage>,\n-}\n-\n-impl SharedEmitter {\n-    pub fn new() -> (SharedEmitter, SharedEmitterMain) {\n-        let (sender, receiver) = channel();\n-\n-        (SharedEmitter { sender }, SharedEmitterMain { receiver })\n-    }\n-\n-    fn inline_asm_error(&self, cookie: u32, msg: String) {\n-        drop(self.sender.send(SharedEmitterMessage::InlineAsmError(cookie, msg)));\n-    }\n-\n-    fn fatal(&self, msg: &str) {\n-        drop(self.sender.send(SharedEmitterMessage::Fatal(msg.to_string())));\n-    }\n-}\n-\n-impl Emitter for SharedEmitter {\n-    fn emit(&mut self, db: &DiagnosticBuilder) {\n-        drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n-            msg: db.message(),\n-            code: db.code.clone(),\n-            lvl: db.level,\n-        })));\n-        for child in &db.children {\n-            drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n-                msg: child.message(),\n-                code: None,\n-                lvl: child.level,\n-            })));\n-        }\n-        drop(self.sender.send(SharedEmitterMessage::AbortIfErrors));\n-    }\n-}\n-\n-impl SharedEmitterMain {\n-    pub fn check(&self, sess: &Session, blocking: bool) {\n-        loop {\n-            let message = if blocking {\n-                match self.receiver.recv() {\n-                    Ok(message) => Ok(message),\n-                    Err(_) => Err(()),\n-                }\n-            } else {\n-                match self.receiver.try_recv() {\n-                    Ok(message) => Ok(message),\n-                    Err(_) => Err(()),\n-                }\n-            };\n-\n-            match message {\n-                Ok(SharedEmitterMessage::Diagnostic(diag)) => {\n-                    let handler = sess.diagnostic();\n-                    match diag.code {\n-                        Some(ref code) => {\n-                            handler.emit_with_code(&MultiSpan::new(),\n-                                                   &diag.msg,\n-                                                   code.clone(),\n-                                                   diag.lvl);\n-                        }\n-                        None => {\n-                            handler.emit(&MultiSpan::new(),\n-                                         &diag.msg,\n-                                         diag.lvl);\n-                        }\n-                    }\n-                }\n-                Ok(SharedEmitterMessage::InlineAsmError(cookie, msg)) => {\n-                    match Mark::from_u32(cookie).expn_info() {\n-                        Some(ei) => sess.span_err(ei.call_site, &msg),\n-                        None     => sess.err(&msg),\n-                    }\n-                }\n-                Ok(SharedEmitterMessage::AbortIfErrors) => {\n-                    sess.abort_if_errors();\n-                }\n-                Ok(SharedEmitterMessage::Fatal(msg)) => {\n-                    sess.fatal(&msg);\n-                }\n-                Err(_) => {\n-                    break;\n-                }\n-            }\n-\n-        }\n-    }\n-}\n-\n-pub struct OngoingCodegen {\n-    crate_name: Symbol,\n-    crate_hash: Svh,\n-    metadata: EncodedMetadata,\n-    windows_subsystem: Option<String>,\n-    linker_info: LinkerInfo,\n-    crate_info: CrateInfo,\n-    time_graph: Option<TimeGraph>,\n-    coordinator_send: Sender<Box<dyn Any + Send>>,\n-    codegen_worker_receive: Receiver<Message>,\n-    shared_emitter_main: SharedEmitterMain,\n-    future: thread::JoinHandle<Result<CompiledModules, ()>>,\n-    output_filenames: Arc<OutputFilenames>,\n-}\n-\n-impl OngoingCodegen {\n-    pub(crate) fn join(\n-        self,\n-        sess: &Session\n-    ) -> (CodegenResults, FxHashMap<WorkProductId, WorkProduct>) {\n-        self.shared_emitter_main.check(sess, true);\n-        let compiled_modules = match self.future.join() {\n-            Ok(Ok(compiled_modules)) => compiled_modules,\n-            Ok(Err(())) => {\n-                sess.abort_if_errors();\n-                panic!(\"expected abort due to worker thread errors\")\n-            },\n-            Err(_) => {\n-                bug!(\"panic during codegen/LLVM phase\");\n-            }\n-        };\n-\n-        sess.cgu_reuse_tracker.check_expected_reuse(sess);\n-\n-        sess.abort_if_errors();\n-\n-        if let Some(time_graph) = self.time_graph {\n-            time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n-        }\n-\n-        let work_products =\n-            copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n-                                                             &compiled_modules);\n-        produce_final_output_artifacts(sess,\n-                                       &compiled_modules,\n-                                       &self.output_filenames);\n-\n-        // FIXME: time_llvm_passes support - does this use a global context or\n-        // something?\n-        if sess.codegen_units() == 1 && sess.time_llvm_passes() {\n-            unsafe { llvm::LLVMRustPrintPassTimings(); }\n-        }\n-\n-        (CodegenResults {\n-            crate_name: self.crate_name,\n-            crate_hash: self.crate_hash,\n-            metadata: self.metadata,\n-            windows_subsystem: self.windows_subsystem,\n-            linker_info: self.linker_info,\n-            crate_info: self.crate_info,\n-\n-            modules: compiled_modules.modules,\n-            allocator_module: compiled_modules.allocator_module,\n-            metadata_module: compiled_modules.metadata_module,\n-        }, work_products)\n-    }\n-\n-    pub(crate) fn submit_pre_codegened_module_to_llvm(&self,\n-                                                      tcx: TyCtxt,\n-                                                      module: ModuleCodegen<ModuleLlvm>) {\n-        self.wait_for_signal_to_codegen_item();\n-        self.check_for_errors(tcx.sess);\n-\n-        // These are generally cheap and won't through off scheduling.\n-        let cost = 0;\n-        submit_codegened_module_to_llvm(tcx, module, cost);\n-    }\n-\n-    pub fn codegen_finished(&self, tcx: TyCtxt) {\n-        self.wait_for_signal_to_codegen_item();\n-        self.check_for_errors(tcx.sess);\n-        drop(self.coordinator_send.send(Box::new(Message::CodegenComplete)));\n-    }\n-\n-    /// Consume this context indicating that codegen was entirely aborted, and\n-    /// we need to exit as quickly as possible.\n-    ///\n-    /// This method blocks the current thread until all worker threads have\n-    /// finished, and all worker threads should have exited or be real close to\n-    /// exiting at this point.\n-    pub fn codegen_aborted(self) {\n-        // Signal to the coordinator it should spawn no more work and start\n-        // shutdown.\n-        drop(self.coordinator_send.send(Box::new(Message::CodegenAborted)));\n-        drop(self.future.join());\n-    }\n-\n-    pub fn check_for_errors(&self, sess: &Session) {\n-        self.shared_emitter_main.check(sess, false);\n-    }\n-\n-    pub fn wait_for_signal_to_codegen_item(&self) {\n-        match self.codegen_worker_receive.recv() {\n-            Ok(Message::CodegenItem) => {\n-                // Nothing to do\n-            }\n-            Ok(_) => panic!(\"unexpected message\"),\n-            Err(_) => {\n-                // One of the LLVM threads must have panicked, fall through so\n-                // error handling can be reached.\n-            }\n-        }\n-    }\n-}\n-\n-// impl Drop for OngoingCodegen {\n-//     fn drop(&mut self) {\n-//     }\n-// }\n-\n-pub(crate) fn submit_codegened_module_to_llvm(tcx: TyCtxt,\n-                                              module: ModuleCodegen<ModuleLlvm>,\n-                                              cost: u64) {\n-    let llvm_work_item = WorkItem::Optimize(module);\n-    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n-        llvm_work_item,\n-        cost,\n-    })));\n-}\n-\n-pub(crate) fn submit_post_lto_module_to_llvm(tcx: TyCtxt,\n-                                             module: CachedModuleCodegen) {\n-    let llvm_work_item = WorkItem::CopyPostLtoArtifacts(module);\n-    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone {\n-        llvm_work_item,\n-        cost: 0,\n-    })));\n-}\n-\n-pub(crate) fn submit_pre_lto_module_to_llvm(tcx: TyCtxt,\n-                                            module: CachedModuleCodegen) {\n-    let filename = pre_lto_bitcode_filename(&module.name);\n-    let bc_path = in_incr_comp_dir_sess(tcx.sess, &filename);\n-    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n-        panic!(\"failed to open bitcode file `{}`: {}\", bc_path.display(), e)\n-    });\n-\n-    let mmap = unsafe {\n-        memmap::Mmap::map(&file).unwrap_or_else(|e| {\n-            panic!(\"failed to mmap bitcode file `{}`: {}\", bc_path.display(), e)\n-        })\n-    };\n-\n-    // Schedule the module to be loaded\n-    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::AddImportOnlyModule {\n-        module_data: SerializedModule::FromUncompressedFile(mmap),\n-        work_product: module.source,\n-    })));\n-}\n-\n-pub(super) fn pre_lto_bitcode_filename(module_name: &str) -> String {\n-    format!(\"{}.{}\", module_name, PRE_THIN_LTO_BC_EXT)\n-}\n-\n-fn msvc_imps_needed(tcx: TyCtxt) -> bool {\n-    // This should never be true (because it's not supported). If it is true,\n-    // something is wrong with commandline arg validation.\n-    assert!(!(tcx.sess.opts.debugging_opts.cross_lang_lto.enabled() &&\n-              tcx.sess.target.target.options.is_like_msvc &&\n-              tcx.sess.opts.cg.prefer_dynamic));\n-\n-    tcx.sess.target.target.options.is_like_msvc &&\n-        tcx.sess.crate_types.borrow().iter().any(|ct| *ct == config::CrateType::Rlib) &&\n-    // ThinLTO can't handle this workaround in all cases, so we don't\n-    // emit the `__imp_` symbols. Instead we make them unnecessary by disallowing\n-    // dynamic linking when cross-language LTO is enabled.\n-    !tcx.sess.opts.debugging_opts.cross_lang_lto.enabled()\n-}\n-\n // Create a `__imp_<symbol> = &symbol` global for every public static `symbol`.\n // This is required to satisfy `dllimport` references to static data in .rlibs\n // when using MSVC linker.  We do this only for data, as linker can fix up\n // code references on its own.\n // See #26591, #27438\n-fn create_msvc_imps(cgcx: &CodegenContext, llcx: &llvm::Context, llmod: &llvm::Module) {\n+fn create_msvc_imps(\n+    cgcx: &CodegenContext<LlvmCodegenBackend>,\n+    llcx: &llvm::Context,\n+    llmod: &llvm::Module\n+) {\n     if !cgcx.msvc_imps_needed {\n         return\n     }"}, {"sha": "529639bf0330a578332f8ec4913a447e321fb202", "filename": "src/librustc_codegen_llvm/base.rs", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Fbase.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -28,7 +28,6 @@ use rustc_codegen_ssa::{ModuleCodegen, ModuleKind};\n use rustc_codegen_ssa::base::maybe_create_entry_wrapper;\n use super::LlvmCodegenBackend;\n \n-use back::write;\n use llvm;\n use metadata;\n use rustc::mir::mono::{Linkage, Visibility, Stats};\n@@ -44,6 +43,7 @@ use rustc_codegen_ssa::mono_item::MonoItemExt;\n use rustc_data_structures::small_c_str::SmallCStr;\n \n use rustc_codegen_ssa::interfaces::*;\n+use rustc_codegen_ssa::back::write::submit_codegened_module_to_llvm;\n \n use std::ffi::CString;\n use std::time::Instant;\n@@ -53,7 +53,7 @@ use rustc::hir::CodegenFnAttrs;\n use value::Value;\n \n \n-pub(crate) fn write_metadata<'a, 'gcx>(\n+pub fn write_metadata<'a, 'gcx>(\n     tcx: TyCtxt<'a, 'gcx, 'gcx>,\n     llvm_module: &ModuleLlvm\n ) -> EncodedMetadata {\n@@ -163,9 +163,7 @@ pub fn compile_codegen_unit<'ll, 'tcx>(tcx: TyCtxt<'ll, 'tcx, 'tcx>,\n     let cost = time_to_codegen.as_secs() * 1_000_000_000 +\n                time_to_codegen.subsec_nanos() as u64;\n \n-    write::submit_codegened_module_to_llvm(tcx,\n-                                           module,\n-                                           cost);\n+    submit_codegened_module_to_llvm(&LlvmCodegenBackend(()), tcx, module, cost);\n     return stats;\n \n     fn module_codegen<'ll, 'tcx>("}, {"sha": "8f14637d6f14034dae31b22aee169ae1a2a4e7a7", "filename": "src/librustc_codegen_llvm/lib.rs", "status": "modified", "additions": 96, "deletions": 69, "changes": 165, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_llvm%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_llvm%2Flib.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -68,15 +68,17 @@ extern crate tempfile;\n extern crate memmap;\n \n use rustc_codegen_ssa::interfaces::*;\n-use time_graph::TimeGraph;\n-use std::sync::mpsc::Receiver;\n-use back::write::{self, OngoingCodegen};\n+use rustc_codegen_ssa::back::write::{CodegenContext, ModuleConfig};\n+use rustc_codegen_ssa::back::lto::{SerializedModule, LtoModuleCodegen, ThinModule};\n+use rustc_codegen_ssa::CompiledModule;\n+use errors::{FatalError, Handler};\n+use rustc::dep_graph::WorkProduct;\n+use rustc::util::time_graph::Timeline;\n use syntax_pos::symbol::InternedString;\n use rustc::mir::mono::Stats;\n-\n pub use llvm_util::target_features;\n use std::any::Any;\n-use std::sync::mpsc;\n+use std::sync::{mpsc, Arc};\n \n use rustc::dep_graph::DepGraph;\n use rustc::middle::allocator::AllocatorKind;\n@@ -87,9 +89,8 @@ use rustc::ty::{self, TyCtxt};\n use rustc::util::time_graph;\n use rustc::util::profiling::ProfileCategory;\n use rustc_mir::monomorphize;\n-use rustc_codegen_ssa::{ModuleCodegen, CompiledModule, CachedModuleCodegen, CrateInfo};\n+use rustc_codegen_ssa::ModuleCodegen;\n use rustc_codegen_utils::codegen_backend::CodegenBackend;\n-use rustc_data_structures::svh::Svh;\n \n mod diagnostics;\n \n@@ -127,12 +128,10 @@ mod type_;\n mod type_of;\n mod value;\n \n+#[derive(Clone)]\n pub struct LlvmCodegenBackend(());\n \n impl ExtraBackendMethods for LlvmCodegenBackend {\n-    type Module = ModuleLlvm;\n-    type OngoingCodegen = OngoingCodegen;\n-\n     fn new_metadata(&self, sess: &Session, mod_name: &str) -> ModuleLlvm {\n         ModuleLlvm::new(sess, mod_name)\n     }\n@@ -143,65 +142,103 @@ impl ExtraBackendMethods for LlvmCodegenBackend {\n     ) -> EncodedMetadata {\n         base::write_metadata(tcx, metadata)\n     }\n-    fn start_async_codegen(\n+    fn codegen_allocator(&self, tcx: TyCtxt, mods: &ModuleLlvm, kind: AllocatorKind) {\n+        unsafe { allocator::codegen(tcx, mods, kind) }\n+    }\n+    fn compile_codegen_unit<'a, 'tcx: 'a>(\n         &self,\n-        tcx: TyCtxt,\n-        time_graph: Option<TimeGraph>,\n-        metadata: EncodedMetadata,\n-        coordinator_receive: Receiver<Box<dyn Any + Send>>,\n-        total_cgus: usize\n-    ) -> OngoingCodegen {\n-        write::start_async_codegen(tcx, time_graph, metadata, coordinator_receive, total_cgus)\n+        tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+        cgu_name: InternedString,\n+    ) -> Stats {\n+        base::compile_codegen_unit(tcx, cgu_name)\n     }\n-    fn submit_pre_codegened_module_to_backend(\n+    fn target_machine_factory(\n         &self,\n-        codegen: &OngoingCodegen,\n-        tcx: TyCtxt,\n-        module: ModuleCodegen<ModuleLlvm>\n-    ) {\n-        codegen.submit_pre_codegened_module_to_llvm(tcx, module)\n+        sess: &Session,\n+        find_features: bool\n+    ) -> Arc<dyn Fn() ->\n+        Result<&'static mut llvm::TargetMachine, String> + Send + Sync> {\n+        back::write::target_machine_factory(sess, find_features)\n     }\n-    fn submit_pre_lto_module_to_backend(&self, tcx: TyCtxt, module: CachedModuleCodegen) {\n-        write::submit_pre_lto_module_to_llvm(tcx, module)\n+    fn target_cpu<'b>(&self, sess: &'b Session) -> &'b str {\n+        llvm_util::target_cpu(sess)\n     }\n-    fn submit_post_lto_module_to_backend(&self, tcx: TyCtxt, module: CachedModuleCodegen) {\n-        write::submit_post_lto_module_to_llvm(tcx, module)\n+}\n+\n+impl Clone for &'static mut llvm::TargetMachine {\n+    fn clone(&self) -> Self {\n+        // This method should never be called. It is put here because in\n+        // rustc_codegen_ssa::back::write::CodegenContext, the TargetMachine is contained in a\n+        // closure returned by a function under an Arc. The clone-deriving algorithm works when the\n+        // struct contains the original LLVM TargetMachine type but not any more when supplied with\n+        // a generic type. Hence this dummy Clone implementation.\n+        panic!()\n     }\n-    fn codegen_aborted(codegen: OngoingCodegen) {\n-        codegen.codegen_aborted();\n+}\n+\n+impl WriteBackendMethods for LlvmCodegenBackend {\n+    type Module = ModuleLlvm;\n+    type ModuleBuffer = back::lto::ModuleBuffer;\n+    type Context = llvm::Context;\n+    type TargetMachine = &'static mut llvm::TargetMachine;\n+    type ThinData = back::lto::ThinData;\n+    type ThinBuffer = back::lto::ThinBuffer;\n+    fn print_pass_timings(&self) {\n+            unsafe { llvm::LLVMRustPrintPassTimings(); }\n     }\n-    fn codegen_finished(&self, codegen: &OngoingCodegen, tcx: TyCtxt) {\n-        codegen.codegen_finished(tcx)\n+    fn run_lto(\n+        cgcx: &CodegenContext<Self>,\n+        modules: Vec<ModuleCodegen<Self::Module>>,\n+        cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n+        timeline: &mut Timeline\n+    ) -> Result<(Vec<LtoModuleCodegen<Self>>, Vec<WorkProduct>), FatalError> {\n+        back::lto::run(cgcx, modules, cached_modules, timeline)\n     }\n-    fn check_for_errors(&self, codegen: &OngoingCodegen, sess: &Session) {\n-        codegen.check_for_errors(sess)\n+    unsafe fn optimize(\n+        cgcx: &CodegenContext<Self>,\n+        diag_handler: &Handler,\n+        module: &ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        timeline: &mut Timeline\n+    ) -> Result<(), FatalError> {\n+        back::write::optimize(cgcx, diag_handler, module, config, timeline)\n     }\n-    fn codegen_allocator(&self, tcx: TyCtxt, mods: &ModuleLlvm, kind: AllocatorKind) {\n-        unsafe { allocator::codegen(tcx, mods, kind) }\n+    unsafe fn optimize_thin(\n+        cgcx: &CodegenContext<Self>,\n+        thin: &mut ThinModule<Self>,\n+        timeline: &mut Timeline\n+    ) -> Result<ModuleCodegen<Self::Module>, FatalError> {\n+        back::lto::optimize_thin_module(thin, cgcx, timeline)\n     }\n-    fn wait_for_signal_to_codegen_item(&self, codegen: &OngoingCodegen) {\n-        codegen.wait_for_signal_to_codegen_item()\n+    unsafe fn codegen(\n+        cgcx: &CodegenContext<Self>,\n+        diag_handler: &Handler,\n+        module: ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        timeline: &mut Timeline\n+    ) -> Result<CompiledModule, FatalError> {\n+        back::write::codegen(cgcx, diag_handler, module, config, timeline)\n     }\n-    fn compile_codegen_unit<'a, 'tcx: 'a>(\n-        &self,\n-        tcx: TyCtxt<'a, 'tcx, 'tcx>,\n-        cgu_name: InternedString,\n-    ) -> Stats {\n-        base::compile_codegen_unit(tcx, cgu_name)\n+    fn run_lto_pass_manager(\n+        cgcx: &CodegenContext<Self>,\n+        module: &ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        thin: bool\n+    ) {\n+        back::lto::run_pass_manager(cgcx, module, config, thin)\n     }\n }\n \n-\n-impl !Send for LlvmCodegenBackend {} // Llvm is on a per-thread basis\n-impl !Sync for LlvmCodegenBackend {}\n+unsafe impl<'a> Send for LlvmCodegenBackend {} // Llvm is on a per-thread basis\n+unsafe impl<'a> Sync for LlvmCodegenBackend {}\n \n impl LlvmCodegenBackend {\n     pub fn new() -> Box<dyn CodegenBackend> {\n         box LlvmCodegenBackend(())\n     }\n }\n \n-impl CodegenBackend for LlvmCodegenBackend {\n+impl<'a> CodegenBackend for LlvmCodegenBackend {\n     fn init(&self, sess: &Session) {\n         llvm_util::init(sess); // Make sure llvm is inited\n     }\n@@ -254,21 +291,21 @@ impl CodegenBackend for LlvmCodegenBackend {\n     }\n \n     fn provide(&self, providers: &mut ty::query::Providers) {\n-        rustc_codegen_utils::symbol_export::provide(providers);\n         rustc_codegen_utils::symbol_names::provide(providers);\n+        rustc_codegen_ssa::back::symbol_export::provide(providers);\n         rustc_codegen_ssa::base::provide_both(providers);\n         attributes::provide(providers);\n     }\n \n     fn provide_extern(&self, providers: &mut ty::query::Providers) {\n-        rustc_codegen_utils::symbol_export::provide_extern(providers);\n+        rustc_codegen_ssa::back::symbol_export::provide_extern(providers);\n         rustc_codegen_ssa::base::provide_both(providers);\n         attributes::provide_extern(providers);\n     }\n \n-    fn codegen_crate<'a, 'tcx>(\n+    fn codegen_crate<'b, 'tcx>(\n         &self,\n-        tcx: TyCtxt<'a, 'tcx, 'tcx>,\n+        tcx: TyCtxt<'b, 'tcx, 'tcx>,\n         rx: mpsc::Receiver<Box<dyn Any + Send>>\n     ) -> Box<dyn Any> {\n         box rustc_codegen_ssa::base::codegen_crate(LlvmCodegenBackend(()), tcx, rx)\n@@ -282,12 +319,13 @@ impl CodegenBackend for LlvmCodegenBackend {\n         outputs: &OutputFilenames,\n     ) -> Result<(), CompileIncomplete>{\n         use rustc::util::common::time;\n-        let (ongoing_codegen, work_products) =\n-            ongoing_codegen.downcast::<::back::write::OngoingCodegen>()\n+        let (codegen_results, work_products) =\n+            ongoing_codegen.downcast::\n+                <rustc_codegen_ssa::back::write::OngoingCodegen<LlvmCodegenBackend>>()\n                 .expect(\"Expected LlvmCodegenBackend's OngoingCodegen, found Box<Any>\")\n                 .join(sess);\n         if sess.opts.debugging_opts.incremental_info {\n-            back::write::dump_incremental_data(&ongoing_codegen);\n+            rustc_codegen_ssa::back::write::dump_incremental_data(&codegen_results);\n         }\n \n         time(sess,\n@@ -305,14 +343,14 @@ impl CodegenBackend for LlvmCodegenBackend {\n         // This should produce either a finished executable or library.\n         sess.profiler(|p| p.start_activity(ProfileCategory::Linking));\n         time(sess, \"linking\", || {\n-            back::link::link_binary(sess, &ongoing_codegen,\n-                                    outputs, &ongoing_codegen.crate_name.as_str());\n+            back::link::link_binary(sess, &codegen_results,\n+                                    outputs, &codegen_results.crate_name.as_str());\n         });\n         sess.profiler(|p| p.end_activity(ProfileCategory::Linking));\n \n         // Now that we won't touch anything in the incremental compilation directory\n         // any more, we can finalize it (which involves renaming it)\n-        rustc_incremental::finalize_session_directory(sess, ongoing_codegen.crate_hash);\n+        rustc_incremental::finalize_session_directory(sess, codegen_results.crate_hash);\n \n         Ok(())\n     }\n@@ -363,15 +401,4 @@ impl Drop for ModuleLlvm {\n     }\n }\n \n-struct CodegenResults {\n-    crate_name: Symbol,\n-    modules: Vec<CompiledModule>,\n-    allocator_module: Option<CompiledModule>,\n-    metadata_module: CompiledModule,\n-    crate_hash: Svh,\n-    metadata: rustc::middle::cstore::EncodedMetadata,\n-    windows_subsystem: Option<String>,\n-    linker_info: rustc_codegen_utils::linker::LinkerInfo,\n-    crate_info: CrateInfo,\n-}\n __build_diagnostic_array! { librustc_codegen_llvm, DIAGNOSTICS }"}, {"sha": "a158c34f9d1c2a1257bbfd6bded4221133ffa36a", "filename": "src/librustc_codegen_ssa/Cargo.toml", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2FCargo.toml?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -9,3 +9,7 @@ path = \"lib.rs\"\n test = false\n \n [dependencies]\n+cc = \"1.0.1\"\n+num_cpus = \"1.0\"\n+rustc-demangle = \"0.1.4\"\n+memmap = \"0.6\""}, {"sha": "b5e1deb0d5df3f4837527340eee8d3cc85c17df0", "filename": "src/librustc_codegen_ssa/back/archive.rs", "status": "added", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Farchive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Farchive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Farchive.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,36 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use rustc::session::Session;\n+\n+use std::path::PathBuf;\n+\n+pub fn find_library(name: &str, search_paths: &[PathBuf], sess: &Session)\n+                    -> PathBuf {\n+    // On Windows, static libraries sometimes show up as libfoo.a and other\n+    // times show up as foo.lib\n+    let oslibname = format!(\"{}{}{}\",\n+                            sess.target.target.options.staticlib_prefix,\n+                            name,\n+                            sess.target.target.options.staticlib_suffix);\n+    let unixlibname = format!(\"lib{}.a\", name);\n+\n+    for path in search_paths {\n+        debug!(\"looking for {} inside {:?}\", name, path);\n+        let test = path.join(&oslibname);\n+        if test.exists() { return test }\n+        if oslibname != unixlibname {\n+            let test = path.join(&unixlibname);\n+            if test.exists() { return test }\n+        }\n+    }\n+    sess.fatal(&format!(\"could not find native static library `{}`, \\\n+                         perhaps an -L flag is missing?\", name));\n+}"}, {"sha": "9ebbdd7c3c936eefdde8466292c4cb34f5337458", "filename": "src/librustc_codegen_ssa/back/command.rs", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fcommand.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fcommand.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fcommand.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "previous_filename": "src/librustc_codegen_utils/command.rs"}, {"sha": "b0575b841d5d5daa1dcfa1e8c3e2331af208b9f5", "filename": "src/librustc_codegen_ssa/back/link.rs", "status": "added", "additions": 208, "deletions": 0, "changes": 208, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Flink.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,208 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+/// For all the linkers we support, and information they might\n+/// need out of the shared crate context before we get rid of it.\n+\n+use rustc::session::{Session, config};\n+use rustc::session::search_paths::PathKind;\n+use rustc::middle::dependency_format::Linkage;\n+use rustc::middle::cstore::LibSource;\n+use rustc_target::spec::LinkerFlavor;\n+use rustc::hir::def_id::CrateNum;\n+\n+use super::command::Command;\n+use CrateInfo;\n+\n+use cc::windows_registry;\n+use std::fs;\n+use std::path::{Path, PathBuf};\n+use std::env;\n+\n+pub fn remove(sess: &Session, path: &Path) {\n+    if let Err(e) = fs::remove_file(path) {\n+        sess.err(&format!(\"failed to remove {}: {}\",\n+                          path.display(),\n+                          e));\n+    }\n+}\n+\n+// The third parameter is for env vars, used on windows to set up the\n+// path for MSVC to find its DLLs, and gcc to find its bundled\n+// toolchain\n+pub fn get_linker(sess: &Session, linker: &Path, flavor: LinkerFlavor) -> (PathBuf, Command) {\n+    let msvc_tool = windows_registry::find_tool(&sess.opts.target_triple.triple(), \"link.exe\");\n+\n+    // If our linker looks like a batch script on Windows then to execute this\n+    // we'll need to spawn `cmd` explicitly. This is primarily done to handle\n+    // emscripten where the linker is `emcc.bat` and needs to be spawned as\n+    // `cmd /c emcc.bat ...`.\n+    //\n+    // This worked historically but is needed manually since #42436 (regression\n+    // was tagged as #42791) and some more info can be found on #44443 for\n+    // emscripten itself.\n+    let mut cmd = match linker.to_str() {\n+        Some(linker) if cfg!(windows) && linker.ends_with(\".bat\") => Command::bat_script(linker),\n+        _ => match flavor {\n+            LinkerFlavor::Lld(f) => Command::lld(linker, f),\n+            LinkerFlavor::Msvc\n+                if sess.opts.cg.linker.is_none() && sess.target.target.options.linker.is_none() =>\n+            {\n+                Command::new(msvc_tool.as_ref().map(|t| t.path()).unwrap_or(linker))\n+            },\n+            _ => Command::new(linker),\n+        }\n+    };\n+\n+    // The compiler's sysroot often has some bundled tools, so add it to the\n+    // PATH for the child.\n+    let mut new_path = sess.host_filesearch(PathKind::All)\n+                           .get_tools_search_paths();\n+    let mut msvc_changed_path = false;\n+    if sess.target.target.options.is_like_msvc {\n+        if let Some(ref tool) = msvc_tool {\n+            cmd.args(tool.args());\n+            for &(ref k, ref v) in tool.env() {\n+                if k == \"PATH\" {\n+                    new_path.extend(env::split_paths(v));\n+                    msvc_changed_path = true;\n+                } else {\n+                    cmd.env(k, v);\n+                }\n+            }\n+        }\n+    }\n+\n+    if !msvc_changed_path {\n+        if let Some(path) = env::var_os(\"PATH\") {\n+            new_path.extend(env::split_paths(&path));\n+        }\n+    }\n+    cmd.env(\"PATH\", env::join_paths(new_path).unwrap());\n+\n+    (linker.to_path_buf(), cmd)\n+}\n+\n+pub fn each_linked_rlib(sess: &Session,\n+                               info: &CrateInfo,\n+                               f: &mut dyn FnMut(CrateNum, &Path)) -> Result<(), String> {\n+    let crates = info.used_crates_static.iter();\n+    let fmts = sess.dependency_formats.borrow();\n+    let fmts = fmts.get(&config::CrateType::Executable)\n+                   .or_else(|| fmts.get(&config::CrateType::Staticlib))\n+                   .or_else(|| fmts.get(&config::CrateType::Cdylib))\n+                   .or_else(|| fmts.get(&config::CrateType::ProcMacro));\n+    let fmts = match fmts {\n+        Some(f) => f,\n+        None => return Err(\"could not find formats for rlibs\".to_string())\n+    };\n+    for &(cnum, ref path) in crates {\n+        match fmts.get(cnum.as_usize() - 1) {\n+            Some(&Linkage::NotLinked) |\n+            Some(&Linkage::IncludedFromDylib) => continue,\n+            Some(_) => {}\n+            None => return Err(\"could not find formats for rlibs\".to_string())\n+        }\n+        let name = &info.crate_name[&cnum];\n+        let path = match *path {\n+            LibSource::Some(ref p) => p,\n+            LibSource::MetadataOnly => {\n+                return Err(format!(\"could not find rlib for: `{}`, found rmeta (metadata) file\",\n+                                   name))\n+            }\n+            LibSource::None => {\n+                return Err(format!(\"could not find rlib for: `{}`\", name))\n+            }\n+        };\n+        f(cnum, &path);\n+    }\n+    Ok(())\n+}\n+\n+/// Returns a boolean indicating whether the specified crate should be ignored\n+/// during LTO.\n+///\n+/// Crates ignored during LTO are not lumped together in the \"massive object\n+/// file\" that we create and are linked in their normal rlib states. See\n+/// comments below for what crates do not participate in LTO.\n+///\n+/// It's unusual for a crate to not participate in LTO. Typically only\n+/// compiler-specific and unstable crates have a reason to not participate in\n+/// LTO.\n+pub fn ignored_for_lto(sess: &Session, info: &CrateInfo, cnum: CrateNum) -> bool {\n+    // If our target enables builtin function lowering in LLVM then the\n+    // crates providing these functions don't participate in LTO (e.g.\n+    // no_builtins or compiler builtins crates).\n+    !sess.target.target.options.no_builtins &&\n+        (info.compiler_builtins == Some(cnum) || info.is_no_builtins.contains(&cnum))\n+}\n+\n+pub fn linker_and_flavor(sess: &Session) -> (PathBuf, LinkerFlavor) {\n+    fn infer_from(\n+        sess: &Session,\n+        linker: Option<PathBuf>,\n+        flavor: Option<LinkerFlavor>,\n+    ) -> Option<(PathBuf, LinkerFlavor)> {\n+        match (linker, flavor) {\n+            (Some(linker), Some(flavor)) => Some((linker, flavor)),\n+            // only the linker flavor is known; use the default linker for the selected flavor\n+            (None, Some(flavor)) => Some((PathBuf::from(match flavor {\n+                LinkerFlavor::Em  => if cfg!(windows) { \"emcc.bat\" } else { \"emcc\" },\n+                LinkerFlavor::Gcc => \"cc\",\n+                LinkerFlavor::Ld => \"ld\",\n+                LinkerFlavor::Msvc => \"link.exe\",\n+                LinkerFlavor::Lld(_) => \"lld\",\n+            }), flavor)),\n+            (Some(linker), None) => {\n+                let stem = linker.file_stem().and_then(|stem| stem.to_str()).unwrap_or_else(|| {\n+                    sess.fatal(\"couldn't extract file stem from specified linker\");\n+                }).to_owned();\n+\n+                let flavor = if stem == \"emcc\" {\n+                    LinkerFlavor::Em\n+                } else if stem == \"gcc\" || stem.ends_with(\"-gcc\") {\n+                    LinkerFlavor::Gcc\n+                } else if stem == \"ld\" || stem == \"ld.lld\" || stem.ends_with(\"-ld\") {\n+                    LinkerFlavor::Ld\n+                } else if stem == \"link\" || stem == \"lld-link\" {\n+                    LinkerFlavor::Msvc\n+                } else if stem == \"lld\" || stem == \"rust-lld\" {\n+                    LinkerFlavor::Lld(sess.target.target.options.lld_flavor)\n+                } else {\n+                    // fall back to the value in the target spec\n+                    sess.target.target.linker_flavor\n+                };\n+\n+                Some((linker, flavor))\n+            },\n+            (None, None) => None,\n+        }\n+    }\n+\n+    // linker and linker flavor specified via command line have precedence over what the target\n+    // specification specifies\n+    if let Some(ret) = infer_from(\n+        sess,\n+        sess.opts.cg.linker.clone(),\n+        sess.opts.debugging_opts.linker_flavor,\n+    ) {\n+        return ret;\n+    }\n+\n+    if let Some(ret) = infer_from(\n+        sess,\n+        sess.target.target.options.linker.clone().map(PathBuf::from),\n+        Some(sess.target.target.linker_flavor),\n+    ) {\n+        return ret;\n+    }\n+\n+    bug!(\"Not enough information provided to determine how to invoke the linker\");\n+}"}, {"sha": "da9cfbb94d1c5425ba2df5239fc51a1723e2337e", "filename": "src/librustc_codegen_ssa/back/linker.rs", "status": "renamed", "additions": 34, "deletions": 32, "changes": 66, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flinker.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flinker.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Flinker.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -8,14 +8,17 @@\n // option. This file may not be copied, modified, or distributed\n // except according to those terms.\n \n+use super::symbol_export;\n+use super::command::Command;\n+use super::archive;\n+\n use rustc_data_structures::fx::FxHashMap;\n use std::ffi::{OsStr, OsString};\n use std::fs::{self, File};\n use std::io::prelude::*;\n use std::io::{self, BufWriter};\n use std::path::{Path, PathBuf};\n \n-use command::Command;\n use rustc::hir::def_id::{LOCAL_CRATE, CrateNum};\n use rustc::middle::dependency_format::Linkage;\n use rustc::session::Session;\n@@ -256,7 +259,7 @@ impl<'a> Linker for GccLinker<'a> {\n             // -force_load is the macOS equivalent of --whole-archive, but it\n             // involves passing the full path to the library to link.\n             self.linker_arg(\"-force_load\");\n-            let lib = ::find_library(lib, search_path, &self.sess);\n+            let lib = archive::find_library(lib, search_path, &self.sess);\n             self.linker_arg(&lib);\n         }\n     }\n@@ -878,36 +881,6 @@ impl<'a> Linker for EmLinker<'a> {\n     }\n }\n \n-fn exported_symbols(tcx: TyCtxt, crate_type: CrateType) -> Vec<String> {\n-    let mut symbols = Vec::new();\n-\n-    let export_threshold =\n-        ::symbol_export::crates_export_threshold(&[crate_type]);\n-    for &(symbol, level) in tcx.exported_symbols(LOCAL_CRATE).iter() {\n-        if level.is_below_threshold(export_threshold) {\n-            symbols.push(symbol.symbol_name(tcx).to_string());\n-        }\n-    }\n-\n-    let formats = tcx.sess.dependency_formats.borrow();\n-    let deps = formats[&crate_type].iter();\n-\n-    for (index, dep_format) in deps.enumerate() {\n-        let cnum = CrateNum::new(index + 1);\n-        // For each dependency that we are linking to statically ...\n-        if *dep_format == Linkage::Static {\n-            // ... we add its symbol list to our export list.\n-            for &(symbol, level) in tcx.exported_symbols(cnum).iter() {\n-                if level.is_below_threshold(export_threshold) {\n-                    symbols.push(symbol.symbol_name(tcx).to_string());\n-                }\n-            }\n-        }\n-    }\n-\n-    symbols\n-}\n-\n pub struct WasmLd<'a> {\n     cmd: Command,\n     sess: &'a Session,\n@@ -1075,3 +1048,32 @@ impl<'a> Linker for WasmLd<'a> {\n         // Do nothing for now\n     }\n }\n+\n+fn exported_symbols(tcx: TyCtxt, crate_type: CrateType) -> Vec<String> {\n+    let mut symbols = Vec::new();\n+\n+    let export_threshold = symbol_export::crates_export_threshold(&[crate_type]);\n+    for &(symbol, level) in tcx.exported_symbols(LOCAL_CRATE).iter() {\n+        if level.is_below_threshold(export_threshold) {\n+            symbols.push(symbol.symbol_name(tcx).to_string());\n+        }\n+    }\n+\n+    let formats = tcx.sess.dependency_formats.borrow();\n+    let deps = formats[&crate_type].iter();\n+\n+    for (index, dep_format) in deps.enumerate() {\n+        let cnum = CrateNum::new(index + 1);\n+        // For each dependency that we are linking to statically ...\n+        if *dep_format == Linkage::Static {\n+            // ... we add its symbol list to our export list.\n+            for &(symbol, level) in tcx.exported_symbols(cnum).iter() {\n+                if level.is_below_threshold(export_threshold) {\n+                    symbols.push(symbol.symbol_name(tcx).to_string());\n+                }\n+            }\n+        }\n+    }\n+\n+    symbols\n+}", "previous_filename": "src/librustc_codegen_utils/linker.rs"}, {"sha": "f68a82d8780b3617e441b54200f445be3042ed4e", "filename": "src/librustc_codegen_ssa/back/lto.rs", "status": "added", "additions": 122, "deletions": 0, "changes": 122, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Flto.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,122 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use super::write::CodegenContext;\n+use interfaces::*;\n+use ModuleCodegen;\n+\n+use rustc::util::time_graph::Timeline;\n+use rustc_errors::FatalError;\n+\n+use std::sync::Arc;\n+use std::ffi::CString;\n+\n+pub struct ThinModule<B: WriteBackendMethods> {\n+    pub shared: Arc<ThinShared<B>>,\n+    pub idx: usize,\n+}\n+\n+impl<B: WriteBackendMethods> ThinModule<B> {\n+    pub fn name(&self) -> &str {\n+        self.shared.module_names[self.idx].to_str().unwrap()\n+    }\n+\n+    pub fn cost(&self) -> u64 {\n+        // Yes, that's correct, we're using the size of the bytecode as an\n+        // indicator for how costly this codegen unit is.\n+        self.data().len() as u64\n+    }\n+\n+    pub fn data(&self) -> &[u8] {\n+        let a = self.shared.thin_buffers.get(self.idx).map(|b| b.data());\n+        a.unwrap_or_else(|| {\n+            let len = self.shared.thin_buffers.len();\n+            self.shared.serialized_modules[self.idx - len].data()\n+        })\n+    }\n+}\n+\n+pub struct ThinShared<B: WriteBackendMethods> {\n+    pub data: B::ThinData,\n+    pub thin_buffers: Vec<B::ThinBuffer>,\n+    pub serialized_modules: Vec<SerializedModule<B::ModuleBuffer>>,\n+    pub module_names: Vec<CString>,\n+}\n+\n+\n+pub enum LtoModuleCodegen<B: WriteBackendMethods> {\n+    Fat {\n+        module: Option<ModuleCodegen<B::Module>>,\n+        _serialized_bitcode: Vec<SerializedModule<B::ModuleBuffer>>,\n+    },\n+\n+    Thin(ThinModule<B>),\n+}\n+\n+impl<B: WriteBackendMethods> LtoModuleCodegen<B> {\n+    pub fn name(&self) -> &str {\n+        match *self {\n+            LtoModuleCodegen::Fat { .. } => \"everything\",\n+            LtoModuleCodegen::Thin(ref m) => m.name(),\n+        }\n+    }\n+\n+    /// Optimize this module within the given codegen context.\n+    ///\n+    /// This function is unsafe as it'll return a `ModuleCodegen` still\n+    /// points to LLVM data structures owned by this `LtoModuleCodegen`.\n+    /// It's intended that the module returned is immediately code generated and\n+    /// dropped, and then this LTO module is dropped.\n+    pub unsafe fn optimize(\n+        &mut self,\n+        cgcx: &CodegenContext<B>,\n+        timeline: &mut Timeline\n+    ) -> Result<ModuleCodegen<B::Module>, FatalError> {\n+        match *self {\n+            LtoModuleCodegen::Fat { ref mut module, .. } => {\n+                let module = module.take().unwrap();\n+                {\n+                    let config = cgcx.config(module.kind);\n+                    B::run_lto_pass_manager(cgcx, &module, config, false);\n+                    timeline.record(\"fat-done\");\n+                }\n+                Ok(module)\n+            }\n+            LtoModuleCodegen::Thin(ref mut thin) => B::optimize_thin(cgcx, thin, timeline),\n+        }\n+    }\n+\n+    /// A \"gauge\" of how costly it is to optimize this module, used to sort\n+    /// biggest modules first.\n+    pub fn cost(&self) -> u64 {\n+        match *self {\n+            // Only one module with fat LTO, so the cost doesn't matter.\n+            LtoModuleCodegen::Fat { .. } => 0,\n+            LtoModuleCodegen::Thin(ref m) => m.cost(),\n+        }\n+    }\n+}\n+\n+\n+pub enum SerializedModule<M: ModuleBufferMethods> {\n+    Local(M),\n+    FromRlib(Vec<u8>),\n+    FromUncompressedFile(memmap::Mmap),\n+}\n+\n+impl<M: ModuleBufferMethods> SerializedModule<M> {\n+    pub fn data(&self) -> &[u8] {\n+        match *self {\n+            SerializedModule::Local(ref m) => m.data(),\n+            SerializedModule::FromRlib(ref m) => m,\n+            SerializedModule::FromUncompressedFile(ref m) => m,\n+        }\n+    }\n+}"}, {"sha": "3d7ead74d1c5dc69d38a5d94919c0d1a814698cd", "filename": "src/librustc_codegen_ssa/back/mod.rs", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fmod.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,17 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+pub mod write;\n+pub mod linker;\n+pub mod lto;\n+pub mod link;\n+pub mod command;\n+pub mod symbol_export;\n+pub mod archive;"}, {"sha": "dff7e518630e4d23628aea3f6db9000caf04a35a", "filename": "src/librustc_codegen_ssa/back/symbol_export.rs", "status": "renamed", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fsymbol_export.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fsymbol_export.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fsymbol_export.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "previous_filename": "src/librustc_codegen_utils/symbol_export.rs"}, {"sha": "e958b5441f22141d4dce9896274ae92a97d7a919", "filename": "src/librustc_codegen_ssa/back/write.rs", "status": "added", "additions": 1843, "deletions": 0, "changes": 1843, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fback%2Fwrite.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,1843 @@\n+// Copyright 2013-2015 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use {ModuleCodegen, ModuleKind, CachedModuleCodegen, CompiledModule, CrateInfo, CodegenResults,\n+    RLIB_BYTECODE_EXTENSION};\n+use super::linker::LinkerInfo;\n+use super::lto::{self, SerializedModule};\n+use super::link::{self, remove, get_linker};\n+use super::command::Command;\n+use super::symbol_export::ExportedSymbols;\n+\n+use memmap;\n+use rustc_incremental::{copy_cgu_workproducts_to_incr_comp_cache_dir,\n+                        in_incr_comp_dir, in_incr_comp_dir_sess};\n+use rustc::dep_graph::{WorkProduct, WorkProductId, WorkProductFileKind};\n+use rustc::dep_graph::cgu_reuse_tracker::CguReuseTracker;\n+use rustc::middle::cstore::EncodedMetadata;\n+use rustc::session::config::{self, OutputFilenames, OutputType, Passes, Sanitizer, Lto};\n+use rustc::session::Session;\n+use rustc::util::nodemap::FxHashMap;\n+use rustc::util::time_graph::{self, TimeGraph, Timeline};\n+use interfaces::*;\n+use rustc::hir::def_id::{CrateNum, LOCAL_CRATE};\n+use rustc::ty::TyCtxt;\n+use rustc::util::common::{time_depth, set_time_depth, print_time_passes_entry};\n+use rustc_fs_util::link_or_copy;\n+use rustc_data_structures::svh::Svh;\n+use rustc_errors::{Handler, Level, DiagnosticBuilder, FatalError, DiagnosticId};\n+use rustc_errors::emitter::{Emitter};\n+use syntax::attr;\n+use syntax::ext::hygiene::Mark;\n+use syntax_pos::MultiSpan;\n+use syntax_pos::symbol::Symbol;\n+use jobserver::{Client, Acquired};\n+\n+use std::any::Any;\n+use std::fs;\n+use std::io;\n+use std::mem;\n+use std::path::{Path, PathBuf};\n+use std::str;\n+use std::sync::Arc;\n+use std::sync::mpsc::{channel, Sender, Receiver};\n+use std::time::Instant;\n+use std::thread;\n+\n+const PRE_THIN_LTO_BC_EXT: &str = \"pre-thin-lto.bc\";\n+\n+/// Module-specific configuration for `optimize_and_codegen`.\n+pub struct ModuleConfig {\n+    /// Names of additional optimization passes to run.\n+    pub passes: Vec<String>,\n+    /// Some(level) to optimize at a certain level, or None to run\n+    /// absolutely no optimizations (used for the metadata module).\n+    pub opt_level: Option<config::OptLevel>,\n+\n+    /// Some(level) to optimize binary size, or None to not affect program size.\n+    pub opt_size: Option<config::OptLevel>,\n+\n+    pub pgo_gen: Option<String>,\n+    pub pgo_use: String,\n+\n+    // Flags indicating which outputs to produce.\n+    pub emit_pre_thin_lto_bc: bool,\n+    pub emit_no_opt_bc: bool,\n+    pub emit_bc: bool,\n+    pub emit_bc_compressed: bool,\n+    pub emit_lto_bc: bool,\n+    pub emit_ir: bool,\n+    pub emit_asm: bool,\n+    pub emit_obj: bool,\n+    // Miscellaneous flags.  These are mostly copied from command-line\n+    // options.\n+    pub verify_llvm_ir: bool,\n+    pub no_prepopulate_passes: bool,\n+    pub no_builtins: bool,\n+    pub time_passes: bool,\n+    pub vectorize_loop: bool,\n+    pub vectorize_slp: bool,\n+    pub merge_functions: bool,\n+    pub inline_threshold: Option<usize>,\n+    // Instead of creating an object file by doing LLVM codegen, just\n+    // make the object file bitcode. Provides easy compatibility with\n+    // emscripten's ecc compiler, when used as the linker.\n+    pub obj_is_bitcode: bool,\n+    pub no_integrated_as: bool,\n+    pub embed_bitcode: bool,\n+    pub embed_bitcode_marker: bool,\n+}\n+\n+impl ModuleConfig {\n+    fn new(passes: Vec<String>) -> ModuleConfig {\n+        ModuleConfig {\n+            passes,\n+            opt_level: None,\n+            opt_size: None,\n+\n+            pgo_gen: None,\n+            pgo_use: String::new(),\n+\n+            emit_no_opt_bc: false,\n+            emit_pre_thin_lto_bc: false,\n+            emit_bc: false,\n+            emit_bc_compressed: false,\n+            emit_lto_bc: false,\n+            emit_ir: false,\n+            emit_asm: false,\n+            emit_obj: false,\n+            obj_is_bitcode: false,\n+            embed_bitcode: false,\n+            embed_bitcode_marker: false,\n+            no_integrated_as: false,\n+\n+            verify_llvm_ir: false,\n+            no_prepopulate_passes: false,\n+            no_builtins: false,\n+            time_passes: false,\n+            vectorize_loop: false,\n+            vectorize_slp: false,\n+            merge_functions: false,\n+            inline_threshold: None\n+        }\n+    }\n+\n+    fn set_flags(&mut self, sess: &Session, no_builtins: bool) {\n+        self.verify_llvm_ir = sess.verify_llvm_ir();\n+        self.no_prepopulate_passes = sess.opts.cg.no_prepopulate_passes;\n+        self.no_builtins = no_builtins || sess.target.target.options.no_builtins;\n+        self.time_passes = sess.time_passes();\n+        self.inline_threshold = sess.opts.cg.inline_threshold;\n+        self.obj_is_bitcode = sess.target.target.options.obj_is_bitcode ||\n+                              sess.opts.debugging_opts.cross_lang_lto.enabled();\n+        let embed_bitcode = sess.target.target.options.embed_bitcode ||\n+                            sess.opts.debugging_opts.embed_bitcode;\n+        if embed_bitcode {\n+            match sess.opts.optimize {\n+                config::OptLevel::No |\n+                config::OptLevel::Less => {\n+                    self.embed_bitcode_marker = embed_bitcode;\n+                }\n+                _ => self.embed_bitcode = embed_bitcode,\n+            }\n+        }\n+\n+        // Copy what clang does by turning on loop vectorization at O2 and\n+        // slp vectorization at O3. Otherwise configure other optimization aspects\n+        // of this pass manager builder.\n+        // Turn off vectorization for emscripten, as it's not very well supported.\n+        self.vectorize_loop = !sess.opts.cg.no_vectorize_loops &&\n+                             (sess.opts.optimize == config::OptLevel::Default ||\n+                              sess.opts.optimize == config::OptLevel::Aggressive) &&\n+                             !sess.target.target.options.is_like_emscripten;\n+\n+        self.vectorize_slp = !sess.opts.cg.no_vectorize_slp &&\n+                            sess.opts.optimize == config::OptLevel::Aggressive &&\n+                            !sess.target.target.options.is_like_emscripten;\n+\n+        self.merge_functions = sess.opts.optimize == config::OptLevel::Default ||\n+                               sess.opts.optimize == config::OptLevel::Aggressive;\n+    }\n+\n+    pub fn bitcode_needed(&self) -> bool {\n+        self.emit_bc || self.obj_is_bitcode\n+            || self.emit_bc_compressed || self.embed_bitcode\n+    }\n+}\n+\n+/// Assembler name and command used by codegen when no_integrated_as is enabled\n+pub struct AssemblerCommand {\n+    name: PathBuf,\n+    cmd: Command,\n+}\n+\n+/// Additional resources used by optimize_and_codegen (not module specific)\n+#[derive(Clone)]\n+pub struct CodegenContext<B: WriteBackendMethods> {\n+    // Resources needed when running LTO\n+    pub backend: B,\n+    pub time_passes: bool,\n+    pub lto: Lto,\n+    pub no_landing_pads: bool,\n+    pub save_temps: bool,\n+    pub fewer_names: bool,\n+    pub exported_symbols: Option<Arc<ExportedSymbols>>,\n+    pub opts: Arc<config::Options>,\n+    pub crate_types: Vec<config::CrateType>,\n+    pub each_linked_rlib_for_lto: Vec<(CrateNum, PathBuf)>,\n+    pub output_filenames: Arc<OutputFilenames>,\n+    pub regular_module_config: Arc<ModuleConfig>,\n+    pub metadata_module_config: Arc<ModuleConfig>,\n+    pub allocator_module_config: Arc<ModuleConfig>,\n+    pub tm_factory: Arc<dyn Fn()\n+        -> Result<B::TargetMachine, String> + Send + Sync>,\n+    pub msvc_imps_needed: bool,\n+    pub target_pointer_width: String,\n+    pub debuginfo: config::DebugInfo,\n+\n+    // Number of cgus excluding the allocator/metadata modules\n+    pub total_cgus: usize,\n+    // Handler to use for diagnostics produced during codegen.\n+    pub diag_emitter: SharedEmitter,\n+    // LLVM passes added by plugins.\n+    pub plugin_passes: Vec<String>,\n+    // LLVM optimizations for which we want to print remarks.\n+    pub remark: Passes,\n+    // Worker thread number\n+    pub worker: usize,\n+    // The incremental compilation session directory, or None if we are not\n+    // compiling incrementally\n+    pub incr_comp_session_dir: Option<PathBuf>,\n+    // Used to update CGU re-use information during the thinlto phase.\n+    pub cgu_reuse_tracker: CguReuseTracker,\n+    // Channel back to the main control thread to send messages to\n+    pub coordinator_send: Sender<Box<dyn Any + Send>>,\n+    // A reference to the TimeGraph so we can register timings. None means that\n+    // measuring is disabled.\n+    pub time_graph: Option<TimeGraph>,\n+    // The assembler command if no_integrated_as option is enabled, None otherwise\n+    pub assembler_cmd: Option<Arc<AssemblerCommand>>\n+}\n+\n+impl<B: WriteBackendMethods> CodegenContext<B> {\n+    pub fn create_diag_handler(&self) -> Handler {\n+        Handler::with_emitter(true, false, Box::new(self.diag_emitter.clone()))\n+    }\n+\n+    pub fn config(&self, kind: ModuleKind) -> &ModuleConfig {\n+        match kind {\n+            ModuleKind::Regular => &self.regular_module_config,\n+            ModuleKind::Metadata => &self.metadata_module_config,\n+            ModuleKind::Allocator => &self.allocator_module_config,\n+        }\n+    }\n+}\n+\n+fn generate_lto_work<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    modules: Vec<ModuleCodegen<B::Module>>,\n+    import_only_modules: Vec<(SerializedModule<B::ModuleBuffer>, WorkProduct)>\n+) -> Vec<(WorkItem<B>, u64)> {\n+    let mut timeline = cgcx.time_graph.as_ref().map(|tg| {\n+        tg.start(CODEGEN_WORKER_TIMELINE,\n+                 CODEGEN_WORK_PACKAGE_KIND,\n+                 \"generate lto\")\n+    }).unwrap_or(Timeline::noop());\n+    let (lto_modules, copy_jobs) = B::run_lto(cgcx, modules, import_only_modules, &mut timeline)\n+        .unwrap_or_else(|e| e.raise());\n+\n+    let lto_modules = lto_modules.into_iter().map(|module| {\n+        let cost = module.cost();\n+        (WorkItem::LTO(module), cost)\n+    });\n+\n+    let copy_jobs = copy_jobs.into_iter().map(|wp| {\n+        (WorkItem::CopyPostLtoArtifacts(CachedModuleCodegen {\n+            name: wp.cgu_name.clone(),\n+            source: wp,\n+        }), 0)\n+    });\n+\n+    lto_modules.chain(copy_jobs).collect()\n+}\n+\n+pub struct CompiledModules {\n+    pub modules: Vec<CompiledModule>,\n+    pub metadata_module: CompiledModule,\n+    pub allocator_module: Option<CompiledModule>,\n+}\n+\n+fn need_crate_bitcode_for_rlib(sess: &Session) -> bool {\n+    sess.crate_types.borrow().contains(&config::CrateType::Rlib) &&\n+    sess.opts.output_types.contains_key(&OutputType::Exe)\n+}\n+\n+fn need_pre_thin_lto_bitcode_for_incr_comp(sess: &Session) -> bool {\n+    if sess.opts.incremental.is_none() {\n+        return false\n+    }\n+\n+    match sess.lto() {\n+        Lto::Fat |\n+        Lto::No => false,\n+        Lto::Thin |\n+        Lto::ThinLocal => true,\n+    }\n+}\n+\n+pub fn start_async_codegen<B: ExtraBackendMethods>(\n+    backend: B,\n+    tcx: TyCtxt,\n+    time_graph: Option<TimeGraph>,\n+    metadata: EncodedMetadata,\n+    coordinator_receive: Receiver<Box<dyn Any + Send>>,\n+    total_cgus: usize\n+) -> OngoingCodegen<B> {\n+    let sess = tcx.sess;\n+    let crate_name = tcx.crate_name(LOCAL_CRATE);\n+    let crate_hash = tcx.crate_hash(LOCAL_CRATE);\n+    let no_builtins = attr::contains_name(&tcx.hir.krate().attrs, \"no_builtins\");\n+    let subsystem = attr::first_attr_value_str_by_name(&tcx.hir.krate().attrs,\n+                                                       \"windows_subsystem\");\n+    let windows_subsystem = subsystem.map(|subsystem| {\n+        if subsystem != \"windows\" && subsystem != \"console\" {\n+            tcx.sess.fatal(&format!(\"invalid windows subsystem `{}`, only \\\n+                                     `windows` and `console` are allowed\",\n+                                    subsystem));\n+        }\n+        subsystem.to_string()\n+    });\n+\n+    let linker_info = LinkerInfo::new(tcx);\n+    let crate_info = CrateInfo::new(tcx);\n+\n+    // Figure out what we actually need to build.\n+    let mut modules_config = ModuleConfig::new(sess.opts.cg.passes.clone());\n+    let mut metadata_config = ModuleConfig::new(vec![]);\n+    let mut allocator_config = ModuleConfig::new(vec![]);\n+\n+    if let Some(ref sanitizer) = sess.opts.debugging_opts.sanitizer {\n+        match *sanitizer {\n+            Sanitizer::Address => {\n+                modules_config.passes.push(\"asan\".to_owned());\n+                modules_config.passes.push(\"asan-module\".to_owned());\n+            }\n+            Sanitizer::Memory => {\n+                modules_config.passes.push(\"msan\".to_owned())\n+            }\n+            Sanitizer::Thread => {\n+                modules_config.passes.push(\"tsan\".to_owned())\n+            }\n+            _ => {}\n+        }\n+    }\n+\n+    if sess.opts.debugging_opts.profile {\n+        modules_config.passes.push(\"insert-gcov-profiling\".to_owned())\n+    }\n+\n+    modules_config.pgo_gen = sess.opts.debugging_opts.pgo_gen.clone();\n+    modules_config.pgo_use = sess.opts.debugging_opts.pgo_use.clone();\n+\n+    modules_config.opt_level = Some(sess.opts.optimize);\n+    modules_config.opt_size = Some(sess.opts.optimize);\n+\n+    // Save all versions of the bytecode if we're saving our temporaries.\n+    if sess.opts.cg.save_temps {\n+        modules_config.emit_no_opt_bc = true;\n+        modules_config.emit_pre_thin_lto_bc = true;\n+        modules_config.emit_bc = true;\n+        modules_config.emit_lto_bc = true;\n+        metadata_config.emit_bc = true;\n+        allocator_config.emit_bc = true;\n+    }\n+\n+    // Emit compressed bitcode files for the crate if we're emitting an rlib.\n+    // Whenever an rlib is created, the bitcode is inserted into the archive in\n+    // order to allow LTO against it.\n+    if need_crate_bitcode_for_rlib(sess) {\n+        modules_config.emit_bc_compressed = true;\n+        allocator_config.emit_bc_compressed = true;\n+    }\n+\n+    modules_config.emit_pre_thin_lto_bc =\n+        need_pre_thin_lto_bitcode_for_incr_comp(sess);\n+\n+    modules_config.no_integrated_as = tcx.sess.opts.cg.no_integrated_as ||\n+        tcx.sess.target.target.options.no_integrated_as;\n+\n+    for output_type in sess.opts.output_types.keys() {\n+        match *output_type {\n+            OutputType::Bitcode => { modules_config.emit_bc = true; }\n+            OutputType::LlvmAssembly => { modules_config.emit_ir = true; }\n+            OutputType::Assembly => {\n+                modules_config.emit_asm = true;\n+                // If we're not using the LLVM assembler, this function\n+                // could be invoked specially with output_type_assembly, so\n+                // in this case we still want the metadata object file.\n+                if !sess.opts.output_types.contains_key(&OutputType::Assembly) {\n+                    metadata_config.emit_obj = true;\n+                    allocator_config.emit_obj = true;\n+                }\n+            }\n+            OutputType::Object => { modules_config.emit_obj = true; }\n+            OutputType::Metadata => { metadata_config.emit_obj = true; }\n+            OutputType::Exe => {\n+                modules_config.emit_obj = true;\n+                metadata_config.emit_obj = true;\n+                allocator_config.emit_obj = true;\n+            },\n+            OutputType::Mir => {}\n+            OutputType::DepInfo => {}\n+        }\n+    }\n+\n+    modules_config.set_flags(sess, no_builtins);\n+    metadata_config.set_flags(sess, no_builtins);\n+    allocator_config.set_flags(sess, no_builtins);\n+\n+    // Exclude metadata and allocator modules from time_passes output, since\n+    // they throw off the \"LLVM passes\" measurement.\n+    metadata_config.time_passes = false;\n+    allocator_config.time_passes = false;\n+\n+    let (shared_emitter, shared_emitter_main) = SharedEmitter::new();\n+    let (codegen_worker_send, codegen_worker_receive) = channel();\n+\n+    let coordinator_thread = start_executing_work(backend.clone(),\n+                                                  tcx,\n+                                                  &crate_info,\n+                                                  shared_emitter,\n+                                                  codegen_worker_send,\n+                                                  coordinator_receive,\n+                                                  total_cgus,\n+                                                  sess.jobserver.clone(),\n+                                                  time_graph.clone(),\n+                                                  Arc::new(modules_config),\n+                                                  Arc::new(metadata_config),\n+                                                  Arc::new(allocator_config));\n+\n+    OngoingCodegen {\n+        backend,\n+        crate_name,\n+        crate_hash,\n+        metadata,\n+        windows_subsystem,\n+        linker_info,\n+        crate_info,\n+\n+        time_graph,\n+        coordinator_send: tcx.tx_to_llvm_workers.lock().clone(),\n+        codegen_worker_receive,\n+        shared_emitter_main,\n+        future: coordinator_thread,\n+        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n+    }\n+}\n+\n+fn copy_all_cgu_workproducts_to_incr_comp_cache_dir(\n+    sess: &Session,\n+    compiled_modules: &CompiledModules,\n+) -> FxHashMap<WorkProductId, WorkProduct> {\n+    let mut work_products = FxHashMap::default();\n+\n+    if sess.opts.incremental.is_none() {\n+        return work_products;\n+    }\n+\n+    for module in compiled_modules.modules.iter().filter(|m| m.kind == ModuleKind::Regular) {\n+        let mut files = vec![];\n+\n+        if let Some(ref path) = module.object {\n+            files.push((WorkProductFileKind::Object, path.clone()));\n+        }\n+        if let Some(ref path) = module.bytecode {\n+            files.push((WorkProductFileKind::Bytecode, path.clone()));\n+        }\n+        if let Some(ref path) = module.bytecode_compressed {\n+            files.push((WorkProductFileKind::BytecodeCompressed, path.clone()));\n+        }\n+\n+        if let Some((id, product)) =\n+                copy_cgu_workproducts_to_incr_comp_cache_dir(sess, &module.name, &files) {\n+            work_products.insert(id, product);\n+        }\n+    }\n+\n+    work_products\n+}\n+\n+fn produce_final_output_artifacts(sess: &Session,\n+                                  compiled_modules: &CompiledModules,\n+                                  crate_output: &OutputFilenames) {\n+    let mut user_wants_bitcode = false;\n+    let mut user_wants_objects = false;\n+\n+    // Produce final compile outputs.\n+    let copy_gracefully = |from: &Path, to: &Path| {\n+        if let Err(e) = fs::copy(from, to) {\n+            sess.err(&format!(\"could not copy {:?} to {:?}: {}\", from, to, e));\n+        }\n+    };\n+\n+    let copy_if_one_unit = |output_type: OutputType,\n+                            keep_numbered: bool| {\n+        if compiled_modules.modules.len() == 1 {\n+            // 1) Only one codegen unit.  In this case it's no difficulty\n+            //    to copy `foo.0.x` to `foo.x`.\n+            let module_name = Some(&compiled_modules.modules[0].name[..]);\n+            let path = crate_output.temp_path(output_type, module_name);\n+            copy_gracefully(&path,\n+                            &crate_output.path(output_type));\n+            if !sess.opts.cg.save_temps && !keep_numbered {\n+                // The user just wants `foo.x`, not `foo.#module-name#.x`.\n+                remove(sess, &path);\n+            }\n+        } else {\n+            let ext = crate_output.temp_path(output_type, None)\n+                                  .extension()\n+                                  .unwrap()\n+                                  .to_str()\n+                                  .unwrap()\n+                                  .to_owned();\n+\n+            if crate_output.outputs.contains_key(&output_type) {\n+                // 2) Multiple codegen units, with `--emit foo=some_name`.  We have\n+                //    no good solution for this case, so warn the user.\n+                sess.warn(&format!(\"ignoring emit path because multiple .{} files \\\n+                                    were produced\", ext));\n+            } else if crate_output.single_output_file.is_some() {\n+                // 3) Multiple codegen units, with `-o some_name`.  We have\n+                //    no good solution for this case, so warn the user.\n+                sess.warn(&format!(\"ignoring -o because multiple .{} files \\\n+                                    were produced\", ext));\n+            } else {\n+                // 4) Multiple codegen units, but no explicit name.  We\n+                //    just leave the `foo.0.x` files in place.\n+                // (We don't have to do any work in this case.)\n+            }\n+        }\n+    };\n+\n+    // Flag to indicate whether the user explicitly requested bitcode.\n+    // Otherwise, we produced it only as a temporary output, and will need\n+    // to get rid of it.\n+    for output_type in crate_output.outputs.keys() {\n+        match *output_type {\n+            OutputType::Bitcode => {\n+                user_wants_bitcode = true;\n+                // Copy to .bc, but always keep the .0.bc.  There is a later\n+                // check to figure out if we should delete .0.bc files, or keep\n+                // them for making an rlib.\n+                copy_if_one_unit(OutputType::Bitcode, true);\n+            }\n+            OutputType::LlvmAssembly => {\n+                copy_if_one_unit(OutputType::LlvmAssembly, false);\n+            }\n+            OutputType::Assembly => {\n+                copy_if_one_unit(OutputType::Assembly, false);\n+            }\n+            OutputType::Object => {\n+                user_wants_objects = true;\n+                copy_if_one_unit(OutputType::Object, true);\n+            }\n+            OutputType::Mir |\n+            OutputType::Metadata |\n+            OutputType::Exe |\n+            OutputType::DepInfo => {}\n+        }\n+    }\n+\n+    // Clean up unwanted temporary files.\n+\n+    // We create the following files by default:\n+    //  - #crate#.#module-name#.bc\n+    //  - #crate#.#module-name#.o\n+    //  - #crate#.crate.metadata.bc\n+    //  - #crate#.crate.metadata.o\n+    //  - #crate#.o (linked from crate.##.o)\n+    //  - #crate#.bc (copied from crate.##.bc)\n+    // We may create additional files if requested by the user (through\n+    // `-C save-temps` or `--emit=` flags).\n+\n+    if !sess.opts.cg.save_temps {\n+        // Remove the temporary .#module-name#.o objects.  If the user didn't\n+        // explicitly request bitcode (with --emit=bc), and the bitcode is not\n+        // needed for building an rlib, then we must remove .#module-name#.bc as\n+        // well.\n+\n+        // Specific rules for keeping .#module-name#.bc:\n+        //  - If the user requested bitcode (`user_wants_bitcode`), and\n+        //    codegen_units > 1, then keep it.\n+        //  - If the user requested bitcode but codegen_units == 1, then we\n+        //    can toss .#module-name#.bc because we copied it to .bc earlier.\n+        //  - If we're not building an rlib and the user didn't request\n+        //    bitcode, then delete .#module-name#.bc.\n+        // If you change how this works, also update back::link::link_rlib,\n+        // where .#module-name#.bc files are (maybe) deleted after making an\n+        // rlib.\n+        let needs_crate_object = crate_output.outputs.contains_key(&OutputType::Exe);\n+\n+        let keep_numbered_bitcode = user_wants_bitcode && sess.codegen_units() > 1;\n+\n+        let keep_numbered_objects = needs_crate_object ||\n+                (user_wants_objects && sess.codegen_units() > 1);\n+\n+        for module in compiled_modules.modules.iter() {\n+            if let Some(ref path) = module.object {\n+                if !keep_numbered_objects {\n+                    remove(sess, path);\n+                }\n+            }\n+\n+            if let Some(ref path) = module.bytecode {\n+                if !keep_numbered_bitcode {\n+                    remove(sess, path);\n+                }\n+            }\n+        }\n+\n+        if !user_wants_bitcode {\n+            if let Some(ref path) = compiled_modules.metadata_module.bytecode {\n+                remove(sess, &path);\n+            }\n+\n+            if let Some(ref allocator_module) = compiled_modules.allocator_module {\n+                if let Some(ref path) = allocator_module.bytecode {\n+                    remove(sess, path);\n+                }\n+            }\n+        }\n+    }\n+\n+    // We leave the following files around by default:\n+    //  - #crate#.o\n+    //  - #crate#.crate.metadata.o\n+    //  - #crate#.bc\n+    // These are used in linking steps and will be cleaned up afterward.\n+}\n+\n+pub fn dump_incremental_data(_codegen_results: &CodegenResults) {\n+    // FIXME(mw): This does not work at the moment because the situation has\n+    //            become more complicated due to incremental LTO. Now a CGU\n+    //            can have more than two caching states.\n+    // println!(\"[incremental] Re-using {} out of {} modules\",\n+    //           codegen_results.modules.iter().filter(|m| m.pre_existing).count(),\n+    //           codegen_results.modules.len());\n+}\n+\n+pub enum WorkItem<B: WriteBackendMethods> {\n+    /// Optimize a newly codegened, totally unoptimized module.\n+    Optimize(ModuleCodegen<B::Module>),\n+    /// Copy the post-LTO artifacts from the incremental cache to the output\n+    /// directory.\n+    CopyPostLtoArtifacts(CachedModuleCodegen),\n+    /// Perform (Thin)LTO on the given module.\n+    LTO(lto::LtoModuleCodegen<B>),\n+}\n+\n+impl<B: WriteBackendMethods> WorkItem<B> {\n+    pub fn module_kind(&self) -> ModuleKind {\n+        match *self {\n+            WorkItem::Optimize(ref m) => m.kind,\n+            WorkItem::CopyPostLtoArtifacts(_) |\n+            WorkItem::LTO(_) => ModuleKind::Regular,\n+        }\n+    }\n+\n+    pub fn name(&self) -> String {\n+        match *self {\n+            WorkItem::Optimize(ref m) => format!(\"optimize: {}\", m.name),\n+            WorkItem::CopyPostLtoArtifacts(ref m) => format!(\"copy post LTO artifacts: {}\", m.name),\n+            WorkItem::LTO(ref m) => format!(\"lto: {}\", m.name()),\n+        }\n+    }\n+}\n+\n+enum WorkItemResult<M> {\n+    Compiled(CompiledModule),\n+    NeedsLTO(ModuleCodegen<M>),\n+}\n+\n+fn execute_work_item<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    work_item: WorkItem<B>,\n+    timeline: &mut Timeline\n+) -> Result<WorkItemResult<B::Module>, FatalError> {\n+    let module_config = cgcx.config(work_item.module_kind());\n+\n+    match work_item {\n+        WorkItem::Optimize(module) => {\n+            execute_optimize_work_item(cgcx, module, module_config, timeline)\n+        }\n+        WorkItem::CopyPostLtoArtifacts(module) => {\n+            execute_copy_from_cache_work_item(cgcx, module, module_config, timeline)\n+        }\n+        WorkItem::LTO(module) => {\n+            execute_lto_work_item(cgcx, module, module_config, timeline)\n+        }\n+    }\n+}\n+\n+fn execute_optimize_work_item<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    module: ModuleCodegen<B::Module>,\n+    module_config: &ModuleConfig,\n+    timeline: &mut Timeline\n+) -> Result<WorkItemResult<B::Module>, FatalError> {\n+    let diag_handler = cgcx.create_diag_handler();\n+\n+    unsafe {\n+        B::optimize(cgcx, &diag_handler, &module, module_config, timeline)?;\n+    }\n+\n+    let linker_does_lto = cgcx.opts.debugging_opts.cross_lang_lto.enabled();\n+\n+    // After we've done the initial round of optimizations we need to\n+    // decide whether to synchronously codegen this module or ship it\n+    // back to the coordinator thread for further LTO processing (which\n+    // has to wait for all the initial modules to be optimized).\n+    //\n+    // Here we dispatch based on the `cgcx.lto` and kind of module we're\n+    // codegenning...\n+    let needs_lto = match cgcx.lto {\n+        Lto::No => false,\n+\n+        // If the linker does LTO, we don't have to do it. Note that we\n+        // keep doing full LTO, if it is requested, as not to break the\n+        // assumption that the output will be a single module.\n+        Lto::Thin | Lto::ThinLocal if linker_does_lto => false,\n+\n+        // Here we've got a full crate graph LTO requested. We ignore\n+        // this, however, if the crate type is only an rlib as there's\n+        // no full crate graph to process, that'll happen later.\n+        //\n+        // This use case currently comes up primarily for targets that\n+        // require LTO so the request for LTO is always unconditionally\n+        // passed down to the backend, but we don't actually want to do\n+        // anything about it yet until we've got a final product.\n+        Lto::Fat | Lto::Thin => {\n+            cgcx.crate_types.len() != 1 ||\n+                cgcx.crate_types[0] != config::CrateType::Rlib\n+        }\n+\n+        // When we're automatically doing ThinLTO for multi-codegen-unit\n+        // builds we don't actually want to LTO the allocator modules if\n+        // it shows up. This is due to various linker shenanigans that\n+        // we'll encounter later.\n+        Lto::ThinLocal => {\n+            module.kind != ModuleKind::Allocator\n+        }\n+    };\n+\n+    // Metadata modules never participate in LTO regardless of the lto\n+    // settings.\n+    let needs_lto = needs_lto && module.kind != ModuleKind::Metadata;\n+\n+    if needs_lto {\n+        Ok(WorkItemResult::NeedsLTO(module))\n+    } else {\n+        let module = unsafe { B::codegen(cgcx, &diag_handler, module, module_config, timeline)? };\n+        Ok(WorkItemResult::Compiled(module))\n+    }\n+}\n+\n+fn execute_copy_from_cache_work_item<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    module: CachedModuleCodegen,\n+    module_config: &ModuleConfig,\n+    _: &mut Timeline\n+) -> Result<WorkItemResult<B::Module>, FatalError> {\n+    let incr_comp_session_dir = cgcx.incr_comp_session_dir\n+                                    .as_ref()\n+                                    .unwrap();\n+    let mut object = None;\n+    let mut bytecode = None;\n+    let mut bytecode_compressed = None;\n+    for (kind, saved_file) in &module.source.saved_files {\n+        let obj_out = match kind {\n+            WorkProductFileKind::Object => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Object,\n+                                                           Some(&module.name));\n+                object = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::Bytecode => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name));\n+                bytecode = Some(path.clone());\n+                path\n+            }\n+            WorkProductFileKind::BytecodeCompressed => {\n+                let path = cgcx.output_filenames.temp_path(OutputType::Bitcode,\n+                                                           Some(&module.name))\n+                    .with_extension(RLIB_BYTECODE_EXTENSION);\n+                bytecode_compressed = Some(path.clone());\n+                path\n+            }\n+        };\n+        let source_file = in_incr_comp_dir(&incr_comp_session_dir,\n+                                           &saved_file);\n+        debug!(\"copying pre-existing module `{}` from {:?} to {}\",\n+               module.name,\n+               source_file,\n+               obj_out.display());\n+        if let Err(err) = link_or_copy(&source_file, &obj_out) {\n+            let diag_handler = cgcx.create_diag_handler();\n+            diag_handler.err(&format!(\"unable to copy {} to {}: {}\",\n+                                      source_file.display(),\n+                                      obj_out.display(),\n+                                      err));\n+        }\n+    }\n+\n+    assert_eq!(object.is_some(), module_config.emit_obj);\n+    assert_eq!(bytecode.is_some(), module_config.emit_bc);\n+    assert_eq!(bytecode_compressed.is_some(), module_config.emit_bc_compressed);\n+\n+    Ok(WorkItemResult::Compiled(CompiledModule {\n+        name: module.name,\n+        kind: ModuleKind::Regular,\n+        object,\n+        bytecode,\n+        bytecode_compressed,\n+    }))\n+}\n+\n+fn execute_lto_work_item<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    mut module: lto::LtoModuleCodegen<B>,\n+    module_config: &ModuleConfig,\n+    timeline: &mut Timeline\n+) -> Result<WorkItemResult<B::Module>, FatalError> {\n+    let diag_handler = cgcx.create_diag_handler();\n+\n+    unsafe {\n+        let module = module.optimize(cgcx, timeline)?;\n+        let module = B::codegen(cgcx, &diag_handler, module, module_config, timeline)?;\n+        Ok(WorkItemResult::Compiled(module))\n+    }\n+}\n+\n+pub enum Message<B: WriteBackendMethods> {\n+    Token(io::Result<Acquired>),\n+    NeedsLTO {\n+        result: ModuleCodegen<B::Module>,\n+        worker_id: usize,\n+    },\n+    Done {\n+        result: Result<CompiledModule, ()>,\n+        worker_id: usize,\n+    },\n+    CodegenDone {\n+        llvm_work_item: WorkItem<B>,\n+        cost: u64,\n+    },\n+    AddImportOnlyModule {\n+        module_data: SerializedModule<B::ModuleBuffer>,\n+        work_product: WorkProduct,\n+    },\n+    CodegenComplete,\n+    CodegenItem,\n+    CodegenAborted,\n+}\n+\n+struct Diagnostic {\n+    msg: String,\n+    code: Option<DiagnosticId>,\n+    lvl: Level,\n+}\n+\n+#[derive(PartialEq, Clone, Copy, Debug)]\n+enum MainThreadWorkerState {\n+    Idle,\n+    Codegenning,\n+    LLVMing,\n+}\n+\n+fn start_executing_work<B: ExtraBackendMethods>(\n+    backend: B,\n+    tcx: TyCtxt,\n+    crate_info: &CrateInfo,\n+    shared_emitter: SharedEmitter,\n+    codegen_worker_send: Sender<Message<B>>,\n+    coordinator_receive: Receiver<Box<dyn Any + Send>>,\n+    total_cgus: usize,\n+    jobserver: Client,\n+    time_graph: Option<TimeGraph>,\n+    modules_config: Arc<ModuleConfig>,\n+    metadata_config: Arc<ModuleConfig>,\n+    allocator_config: Arc<ModuleConfig>\n+) -> thread::JoinHandle<Result<CompiledModules, ()>> {\n+    let coordinator_send = tcx.tx_to_llvm_workers.lock().clone();\n+    let sess = tcx.sess;\n+\n+    // Compute the set of symbols we need to retain when doing LTO (if we need to)\n+    let exported_symbols = {\n+        let mut exported_symbols = FxHashMap::default();\n+\n+        let copy_symbols = |cnum| {\n+            let symbols = tcx.exported_symbols(cnum)\n+                             .iter()\n+                             .map(|&(s, lvl)| (s.symbol_name(tcx).to_string(), lvl))\n+                             .collect();\n+            Arc::new(symbols)\n+        };\n+\n+        match sess.lto() {\n+            Lto::No => None,\n+            Lto::ThinLocal => {\n+                exported_symbols.insert(LOCAL_CRATE, copy_symbols(LOCAL_CRATE));\n+                Some(Arc::new(exported_symbols))\n+            }\n+            Lto::Fat | Lto::Thin => {\n+                exported_symbols.insert(LOCAL_CRATE, copy_symbols(LOCAL_CRATE));\n+                for &cnum in tcx.crates().iter() {\n+                    exported_symbols.insert(cnum, copy_symbols(cnum));\n+                }\n+                Some(Arc::new(exported_symbols))\n+            }\n+        }\n+    };\n+\n+    // First up, convert our jobserver into a helper thread so we can use normal\n+    // mpsc channels to manage our messages and such.\n+    // After we've requested tokens then we'll, when we can,\n+    // get tokens on `coordinator_receive` which will\n+    // get managed in the main loop below.\n+    let coordinator_send2 = coordinator_send.clone();\n+    let helper = jobserver.into_helper_thread(move |token| {\n+        drop(coordinator_send2.send(Box::new(Message::Token::<B>(token))));\n+    }).expect(\"failed to spawn helper thread\");\n+\n+    let mut each_linked_rlib_for_lto = Vec::new();\n+    drop(link::each_linked_rlib(sess, crate_info, &mut |cnum, path| {\n+        if link::ignored_for_lto(sess, crate_info, cnum) {\n+            return\n+        }\n+        each_linked_rlib_for_lto.push((cnum, path.to_path_buf()));\n+    }));\n+\n+    let assembler_cmd = if modules_config.no_integrated_as {\n+        // HACK: currently we use linker (gcc) as our assembler\n+        let (linker, flavor) = link::linker_and_flavor(sess);\n+\n+        let (name, mut cmd) = get_linker(sess, &linker, flavor);\n+        cmd.args(&sess.target.target.options.asm_args);\n+        Some(Arc::new(AssemblerCommand {\n+            name,\n+            cmd,\n+        }))\n+    } else {\n+        None\n+    };\n+\n+    let cgcx = CodegenContext::<B> {\n+        backend: backend.clone(),\n+        crate_types: sess.crate_types.borrow().clone(),\n+        each_linked_rlib_for_lto,\n+        lto: sess.lto(),\n+        no_landing_pads: sess.no_landing_pads(),\n+        fewer_names: sess.fewer_names(),\n+        save_temps: sess.opts.cg.save_temps,\n+        opts: Arc::new(sess.opts.clone()),\n+        time_passes: sess.time_passes(),\n+        exported_symbols,\n+        plugin_passes: sess.plugin_llvm_passes.borrow().clone(),\n+        remark: sess.opts.cg.remark.clone(),\n+        worker: 0,\n+        incr_comp_session_dir: sess.incr_comp_session_dir_opt().map(|r| r.clone()),\n+        cgu_reuse_tracker: sess.cgu_reuse_tracker.clone(),\n+        coordinator_send,\n+        diag_emitter: shared_emitter.clone(),\n+        time_graph,\n+        output_filenames: tcx.output_filenames(LOCAL_CRATE),\n+        regular_module_config: modules_config,\n+        metadata_module_config: metadata_config,\n+        allocator_module_config: allocator_config,\n+        tm_factory: backend.target_machine_factory(tcx.sess, false),\n+        total_cgus,\n+        msvc_imps_needed: msvc_imps_needed(tcx),\n+        target_pointer_width: tcx.sess.target.target.target_pointer_width.clone(),\n+        debuginfo: tcx.sess.opts.debuginfo,\n+        assembler_cmd,\n+    };\n+\n+    // This is the \"main loop\" of parallel work happening for parallel codegen.\n+    // It's here that we manage parallelism, schedule work, and work with\n+    // messages coming from clients.\n+    //\n+    // There are a few environmental pre-conditions that shape how the system\n+    // is set up:\n+    //\n+    // - Error reporting only can happen on the main thread because that's the\n+    //   only place where we have access to the compiler `Session`.\n+    // - LLVM work can be done on any thread.\n+    // - Codegen can only happen on the main thread.\n+    // - Each thread doing substantial work most be in possession of a `Token`\n+    //   from the `Jobserver`.\n+    // - The compiler process always holds one `Token`. Any additional `Tokens`\n+    //   have to be requested from the `Jobserver`.\n+    //\n+    // Error Reporting\n+    // ===============\n+    // The error reporting restriction is handled separately from the rest: We\n+    // set up a `SharedEmitter` the holds an open channel to the main thread.\n+    // When an error occurs on any thread, the shared emitter will send the\n+    // error message to the receiver main thread (`SharedEmitterMain`). The\n+    // main thread will periodically query this error message queue and emit\n+    // any error messages it has received. It might even abort compilation if\n+    // has received a fatal error. In this case we rely on all other threads\n+    // being torn down automatically with the main thread.\n+    // Since the main thread will often be busy doing codegen work, error\n+    // reporting will be somewhat delayed, since the message queue can only be\n+    // checked in between to work packages.\n+    //\n+    // Work Processing Infrastructure\n+    // ==============================\n+    // The work processing infrastructure knows three major actors:\n+    //\n+    // - the coordinator thread,\n+    // - the main thread, and\n+    // - LLVM worker threads\n+    //\n+    // The coordinator thread is running a message loop. It instructs the main\n+    // thread about what work to do when, and it will spawn off LLVM worker\n+    // threads as open LLVM WorkItems become available.\n+    //\n+    // The job of the main thread is to codegen CGUs into LLVM work package\n+    // (since the main thread is the only thread that can do this). The main\n+    // thread will block until it receives a message from the coordinator, upon\n+    // which it will codegen one CGU, send it to the coordinator and block\n+    // again. This way the coordinator can control what the main thread is\n+    // doing.\n+    //\n+    // The coordinator keeps a queue of LLVM WorkItems, and when a `Token` is\n+    // available, it will spawn off a new LLVM worker thread and let it process\n+    // that a WorkItem. When a LLVM worker thread is done with its WorkItem,\n+    // it will just shut down, which also frees all resources associated with\n+    // the given LLVM module, and sends a message to the coordinator that the\n+    // has been completed.\n+    //\n+    // Work Scheduling\n+    // ===============\n+    // The scheduler's goal is to minimize the time it takes to complete all\n+    // work there is, however, we also want to keep memory consumption low\n+    // if possible. These two goals are at odds with each other: If memory\n+    // consumption were not an issue, we could just let the main thread produce\n+    // LLVM WorkItems at full speed, assuring maximal utilization of\n+    // Tokens/LLVM worker threads. However, since codegen usual is faster\n+    // than LLVM processing, the queue of LLVM WorkItems would fill up and each\n+    // WorkItem potentially holds on to a substantial amount of memory.\n+    //\n+    // So the actual goal is to always produce just enough LLVM WorkItems as\n+    // not to starve our LLVM worker threads. That means, once we have enough\n+    // WorkItems in our queue, we can block the main thread, so it does not\n+    // produce more until we need them.\n+    //\n+    // Doing LLVM Work on the Main Thread\n+    // ----------------------------------\n+    // Since the main thread owns the compiler processes implicit `Token`, it is\n+    // wasteful to keep it blocked without doing any work. Therefore, what we do\n+    // in this case is: We spawn off an additional LLVM worker thread that helps\n+    // reduce the queue. The work it is doing corresponds to the implicit\n+    // `Token`. The coordinator will mark the main thread as being busy with\n+    // LLVM work. (The actual work happens on another OS thread but we just care\n+    // about `Tokens`, not actual threads).\n+    //\n+    // When any LLVM worker thread finishes while the main thread is marked as\n+    // \"busy with LLVM work\", we can do a little switcheroo: We give the Token\n+    // of the just finished thread to the LLVM worker thread that is working on\n+    // behalf of the main thread's implicit Token, thus freeing up the main\n+    // thread again. The coordinator can then again decide what the main thread\n+    // should do. This allows the coordinator to make decisions at more points\n+    // in time.\n+    //\n+    // Striking a Balance between Throughput and Memory Consumption\n+    // ------------------------------------------------------------\n+    // Since our two goals, (1) use as many Tokens as possible and (2) keep\n+    // memory consumption as low as possible, are in conflict with each other,\n+    // we have to find a trade off between them. Right now, the goal is to keep\n+    // all workers busy, which means that no worker should find the queue empty\n+    // when it is ready to start.\n+    // How do we do achieve this? Good question :) We actually never know how\n+    // many `Tokens` are potentially available so it's hard to say how much to\n+    // fill up the queue before switching the main thread to LLVM work. Also we\n+    // currently don't have a means to estimate how long a running LLVM worker\n+    // will still be busy with it's current WorkItem. However, we know the\n+    // maximal count of available Tokens that makes sense (=the number of CPU\n+    // cores), so we can take a conservative guess. The heuristic we use here\n+    // is implemented in the `queue_full_enough()` function.\n+    //\n+    // Some Background on Jobservers\n+    // -----------------------------\n+    // It's worth also touching on the management of parallelism here. We don't\n+    // want to just spawn a thread per work item because while that's optimal\n+    // parallelism it may overload a system with too many threads or violate our\n+    // configuration for the maximum amount of cpu to use for this process. To\n+    // manage this we use the `jobserver` crate.\n+    //\n+    // Job servers are an artifact of GNU make and are used to manage\n+    // parallelism between processes. A jobserver is a glorified IPC semaphore\n+    // basically. Whenever we want to run some work we acquire the semaphore,\n+    // and whenever we're done with that work we release the semaphore. In this\n+    // manner we can ensure that the maximum number of parallel workers is\n+    // capped at any one point in time.\n+    //\n+    // LTO and the coordinator thread\n+    // ------------------------------\n+    //\n+    // The final job the coordinator thread is responsible for is managing LTO\n+    // and how that works. When LTO is requested what we'll to is collect all\n+    // optimized LLVM modules into a local vector on the coordinator. Once all\n+    // modules have been codegened and optimized we hand this to the `lto`\n+    // module for further optimization. The `lto` module will return back a list\n+    // of more modules to work on, which the coordinator will continue to spawn\n+    // work for.\n+    //\n+    // Each LLVM module is automatically sent back to the coordinator for LTO if\n+    // necessary. There's already optimizations in place to avoid sending work\n+    // back to the coordinator if LTO isn't requested.\n+    return thread::spawn(move || {\n+        // We pretend to be within the top-level LLVM time-passes task here:\n+        set_time_depth(1);\n+\n+        let max_workers = ::num_cpus::get();\n+        let mut worker_id_counter = 0;\n+        let mut free_worker_ids = Vec::new();\n+        let mut get_worker_id = |free_worker_ids: &mut Vec<usize>| {\n+            if let Some(id) = free_worker_ids.pop() {\n+                id\n+            } else {\n+                let id = worker_id_counter;\n+                worker_id_counter += 1;\n+                id\n+            }\n+        };\n+\n+        // This is where we collect codegen units that have gone all the way\n+        // through codegen and LLVM.\n+        let mut compiled_modules = vec![];\n+        let mut compiled_metadata_module = None;\n+        let mut compiled_allocator_module = None;\n+        let mut needs_lto = Vec::new();\n+        let mut lto_import_only_modules = Vec::new();\n+        let mut started_lto = false;\n+        let mut codegen_aborted = false;\n+\n+        // This flag tracks whether all items have gone through codegens\n+        let mut codegen_done = false;\n+\n+        // This is the queue of LLVM work items that still need processing.\n+        let mut work_items = Vec::<(WorkItem<B>, u64)>::new();\n+\n+        // This are the Jobserver Tokens we currently hold. Does not include\n+        // the implicit Token the compiler process owns no matter what.\n+        let mut tokens = Vec::new();\n+\n+        let mut main_thread_worker_state = MainThreadWorkerState::Idle;\n+        let mut running = 0;\n+\n+        let mut llvm_start_time = None;\n+\n+        // Run the message loop while there's still anything that needs message\n+        // processing. Note that as soon as codegen is aborted we simply want to\n+        // wait for all existing work to finish, so many of the conditions here\n+        // only apply if codegen hasn't been aborted as they represent pending\n+        // work to be done.\n+        while !codegen_done ||\n+              running > 0 ||\n+              (!codegen_aborted && (\n+                  work_items.len() > 0 ||\n+                  needs_lto.len() > 0 ||\n+                  lto_import_only_modules.len() > 0 ||\n+                  main_thread_worker_state != MainThreadWorkerState::Idle\n+              ))\n+        {\n+\n+            // While there are still CGUs to be codegened, the coordinator has\n+            // to decide how to utilize the compiler processes implicit Token:\n+            // For codegenning more CGU or for running them through LLVM.\n+            if !codegen_done {\n+                if main_thread_worker_state == MainThreadWorkerState::Idle {\n+                    if !queue_full_enough(work_items.len(), running, max_workers) {\n+                        // The queue is not full enough, codegen more items:\n+                        if let Err(_) = codegen_worker_send.send(Message::CodegenItem) {\n+                            panic!(\"Could not send Message::CodegenItem to main thread\")\n+                        }\n+                        main_thread_worker_state = MainThreadWorkerState::Codegenning;\n+                    } else {\n+                        // The queue is full enough to not let the worker\n+                        // threads starve. Use the implicit Token to do some\n+                        // LLVM work too.\n+                        let (item, _) = work_items.pop()\n+                            .expect(\"queue empty - queue_full_enough() broken?\");\n+                        let cgcx = CodegenContext {\n+                            worker: get_worker_id(&mut free_worker_ids),\n+                            .. cgcx.clone()\n+                        };\n+                        maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n+                                               &mut llvm_start_time);\n+                        main_thread_worker_state = MainThreadWorkerState::LLVMing;\n+                        spawn_work(cgcx, item);\n+                    }\n+                }\n+            } else if codegen_aborted {\n+                // don't queue up any more work if codegen was aborted, we're\n+                // just waiting for our existing children to finish\n+            } else {\n+                // If we've finished everything related to normal codegen\n+                // then it must be the case that we've got some LTO work to do.\n+                // Perform the serial work here of figuring out what we're\n+                // going to LTO and then push a bunch of work items onto our\n+                // queue to do LTO\n+                if work_items.len() == 0 &&\n+                   running == 0 &&\n+                   main_thread_worker_state == MainThreadWorkerState::Idle {\n+                    assert!(!started_lto);\n+                    assert!(needs_lto.len() + lto_import_only_modules.len() > 0);\n+                    started_lto = true;\n+                    let modules = mem::replace(&mut needs_lto, Vec::new());\n+                    let import_only_modules =\n+                        mem::replace(&mut lto_import_only_modules, Vec::new());\n+                    for (work, cost) in generate_lto_work(&cgcx, modules, import_only_modules) {\n+                        let insertion_index = work_items\n+                            .binary_search_by_key(&cost, |&(_, cost)| cost)\n+                            .unwrap_or_else(|e| e);\n+                        work_items.insert(insertion_index, (work, cost));\n+                        if !cgcx.opts.debugging_opts.no_parallel_llvm {\n+                            helper.request_token();\n+                        }\n+                    }\n+                }\n+\n+                // In this branch, we know that everything has been codegened,\n+                // so it's just a matter of determining whether the implicit\n+                // Token is free to use for LLVM work.\n+                match main_thread_worker_state {\n+                    MainThreadWorkerState::Idle => {\n+                        if let Some((item, _)) = work_items.pop() {\n+                            let cgcx = CodegenContext {\n+                                worker: get_worker_id(&mut free_worker_ids),\n+                                .. cgcx.clone()\n+                            };\n+                            maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n+                                                   &mut llvm_start_time);\n+                            main_thread_worker_state = MainThreadWorkerState::LLVMing;\n+                            spawn_work(cgcx, item);\n+                        } else {\n+                            // There is no unstarted work, so let the main thread\n+                            // take over for a running worker. Otherwise the\n+                            // implicit token would just go to waste.\n+                            // We reduce the `running` counter by one. The\n+                            // `tokens.truncate()` below will take care of\n+                            // giving the Token back.\n+                            debug_assert!(running > 0);\n+                            running -= 1;\n+                            main_thread_worker_state = MainThreadWorkerState::LLVMing;\n+                        }\n+                    }\n+                    MainThreadWorkerState::Codegenning => {\n+                        bug!(\"codegen worker should not be codegenning after \\\n+                              codegen was already completed\")\n+                    }\n+                    MainThreadWorkerState::LLVMing => {\n+                        // Already making good use of that token\n+                    }\n+                }\n+            }\n+\n+            // Spin up what work we can, only doing this while we've got available\n+            // parallelism slots and work left to spawn.\n+            while !codegen_aborted && work_items.len() > 0 && running < tokens.len() {\n+                let (item, _) = work_items.pop().unwrap();\n+\n+                maybe_start_llvm_timer(cgcx.config(item.module_kind()),\n+                                       &mut llvm_start_time);\n+\n+                let cgcx = CodegenContext {\n+                    worker: get_worker_id(&mut free_worker_ids),\n+                    .. cgcx.clone()\n+                };\n+\n+                spawn_work(cgcx, item);\n+                running += 1;\n+            }\n+\n+            // Relinquish accidentally acquired extra tokens\n+            tokens.truncate(running);\n+\n+            let msg = coordinator_receive.recv().unwrap();\n+            match *msg.downcast::<Message<B>>().ok().unwrap() {\n+                // Save the token locally and the next turn of the loop will use\n+                // this to spawn a new unit of work, or it may get dropped\n+                // immediately if we have no more work to spawn.\n+                Message::Token(token) => {\n+                    match token {\n+                        Ok(token) => {\n+                            tokens.push(token);\n+\n+                            if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n+                                // If the main thread token is used for LLVM work\n+                                // at the moment, we turn that thread into a regular\n+                                // LLVM worker thread, so the main thread is free\n+                                // to react to codegen demand.\n+                                main_thread_worker_state = MainThreadWorkerState::Idle;\n+                                running += 1;\n+                            }\n+                        }\n+                        Err(e) => {\n+                            let msg = &format!(\"failed to acquire jobserver token: {}\", e);\n+                            shared_emitter.fatal(msg);\n+                            // Exit the coordinator thread\n+                            panic!(\"{}\", msg)\n+                        }\n+                    }\n+                }\n+\n+                Message::CodegenDone { llvm_work_item, cost } => {\n+                    // We keep the queue sorted by estimated processing cost,\n+                    // so that more expensive items are processed earlier. This\n+                    // is good for throughput as it gives the main thread more\n+                    // time to fill up the queue and it avoids scheduling\n+                    // expensive items to the end.\n+                    // Note, however, that this is not ideal for memory\n+                    // consumption, as LLVM module sizes are not evenly\n+                    // distributed.\n+                    let insertion_index =\n+                        work_items.binary_search_by_key(&cost, |&(_, cost)| cost);\n+                    let insertion_index = match insertion_index {\n+                        Ok(idx) | Err(idx) => idx\n+                    };\n+                    work_items.insert(insertion_index, (llvm_work_item, cost));\n+\n+                    if !cgcx.opts.debugging_opts.no_parallel_llvm {\n+                        helper.request_token();\n+                    }\n+                    assert!(!codegen_aborted);\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n+                }\n+\n+                Message::CodegenComplete => {\n+                    codegen_done = true;\n+                    assert!(!codegen_aborted);\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n+                }\n+\n+                // If codegen is aborted that means translation was aborted due\n+                // to some normal-ish compiler error. In this situation we want\n+                // to exit as soon as possible, but we want to make sure all\n+                // existing work has finished. Flag codegen as being done, and\n+                // then conditions above will ensure no more work is spawned but\n+                // we'll keep executing this loop until `running` hits 0.\n+                Message::CodegenAborted => {\n+                    assert!(!codegen_aborted);\n+                    codegen_done = true;\n+                    codegen_aborted = true;\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                }\n+\n+                // If a thread exits successfully then we drop a token associated\n+                // with that worker and update our `running` count. We may later\n+                // re-acquire a token to continue running more work. We may also not\n+                // actually drop a token here if the worker was running with an\n+                // \"ephemeral token\"\n+                //\n+                // Note that if the thread failed that means it panicked, so we\n+                // abort immediately.\n+                Message::Done { result: Ok(compiled_module), worker_id } => {\n+                    if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n+                        main_thread_worker_state = MainThreadWorkerState::Idle;\n+                    } else {\n+                        running -= 1;\n+                    }\n+\n+                    free_worker_ids.push(worker_id);\n+\n+                    match compiled_module.kind {\n+                        ModuleKind::Regular => {\n+                            compiled_modules.push(compiled_module);\n+                        }\n+                        ModuleKind::Metadata => {\n+                            assert!(compiled_metadata_module.is_none());\n+                            compiled_metadata_module = Some(compiled_module);\n+                        }\n+                        ModuleKind::Allocator => {\n+                            assert!(compiled_allocator_module.is_none());\n+                            compiled_allocator_module = Some(compiled_module);\n+                        }\n+                    }\n+                }\n+                Message::NeedsLTO { result, worker_id } => {\n+                    assert!(!started_lto);\n+                    if main_thread_worker_state == MainThreadWorkerState::LLVMing {\n+                        main_thread_worker_state = MainThreadWorkerState::Idle;\n+                    } else {\n+                        running -= 1;\n+                    }\n+                    free_worker_ids.push(worker_id);\n+                    needs_lto.push(result);\n+                }\n+                Message::AddImportOnlyModule { module_data, work_product } => {\n+                    assert!(!started_lto);\n+                    assert!(!codegen_done);\n+                    assert_eq!(main_thread_worker_state,\n+                               MainThreadWorkerState::Codegenning);\n+                    lto_import_only_modules.push((module_data, work_product));\n+                    main_thread_worker_state = MainThreadWorkerState::Idle;\n+                }\n+                Message::Done { result: Err(()), worker_id: _ } => {\n+                    bug!(\"worker thread panicked\");\n+                }\n+                Message::CodegenItem => {\n+                    bug!(\"the coordinator should not receive codegen requests\")\n+                }\n+            }\n+        }\n+\n+        if let Some(llvm_start_time) = llvm_start_time {\n+            let total_llvm_time = Instant::now().duration_since(llvm_start_time);\n+            // This is the top-level timing for all of LLVM, set the time-depth\n+            // to zero.\n+            set_time_depth(0);\n+            print_time_passes_entry(cgcx.time_passes,\n+                                    \"LLVM passes\",\n+                                    total_llvm_time);\n+        }\n+\n+        // Regardless of what order these modules completed in, report them to\n+        // the backend in the same order every time to ensure that we're handing\n+        // out deterministic results.\n+        compiled_modules.sort_by(|a, b| a.name.cmp(&b.name));\n+\n+        let compiled_metadata_module = compiled_metadata_module\n+            .expect(\"Metadata module not compiled?\");\n+\n+        Ok(CompiledModules {\n+            modules: compiled_modules,\n+            metadata_module: compiled_metadata_module,\n+            allocator_module: compiled_allocator_module,\n+        })\n+    });\n+\n+    // A heuristic that determines if we have enough LLVM WorkItems in the\n+    // queue so that the main thread can do LLVM work instead of codegen\n+    fn queue_full_enough(items_in_queue: usize,\n+                         workers_running: usize,\n+                         max_workers: usize) -> bool {\n+        // Tune me, plz.\n+        items_in_queue > 0 &&\n+        items_in_queue >= max_workers.saturating_sub(workers_running / 2)\n+    }\n+\n+    fn maybe_start_llvm_timer(config: &ModuleConfig,\n+                              llvm_start_time: &mut Option<Instant>) {\n+        // We keep track of the -Ztime-passes output manually,\n+        // since the closure-based interface does not fit well here.\n+        if config.time_passes {\n+            if llvm_start_time.is_none() {\n+                *llvm_start_time = Some(Instant::now());\n+            }\n+        }\n+    }\n+}\n+\n+pub const CODEGEN_WORKER_ID: usize = ::std::usize::MAX;\n+pub const CODEGEN_WORKER_TIMELINE: time_graph::TimelineId =\n+    time_graph::TimelineId(CODEGEN_WORKER_ID);\n+pub const CODEGEN_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n+    time_graph::WorkPackageKind(&[\"#DE9597\", \"#FED1D3\", \"#FDC5C7\", \"#B46668\", \"#88494B\"]);\n+const LLVM_WORK_PACKAGE_KIND: time_graph::WorkPackageKind =\n+    time_graph::WorkPackageKind(&[\"#7DB67A\", \"#C6EEC4\", \"#ACDAAA\", \"#579354\", \"#3E6F3C\"]);\n+\n+fn spawn_work<B: ExtraBackendMethods>(\n+    cgcx: CodegenContext<B>,\n+    work: WorkItem<B>\n+) {\n+    let depth = time_depth();\n+\n+    thread::spawn(move || {\n+        set_time_depth(depth);\n+\n+        // Set up a destructor which will fire off a message that we're done as\n+        // we exit.\n+        struct Bomb<B: ExtraBackendMethods> {\n+            coordinator_send: Sender<Box<dyn Any + Send>>,\n+            result: Option<WorkItemResult<B::Module>>,\n+            worker_id: usize,\n+        }\n+        impl<B: ExtraBackendMethods> Drop for Bomb<B> {\n+            fn drop(&mut self) {\n+                let worker_id = self.worker_id;\n+                let msg = match self.result.take() {\n+                    Some(WorkItemResult::Compiled(m)) => {\n+                        Message::Done::<B> { result: Ok(m), worker_id }\n+                    }\n+                    Some(WorkItemResult::NeedsLTO(m)) => {\n+                        Message::NeedsLTO::<B> { result: m, worker_id }\n+                    }\n+                    None => Message::Done::<B> { result: Err(()), worker_id }\n+                };\n+                drop(self.coordinator_send.send(Box::new(msg)));\n+            }\n+        }\n+\n+        let mut bomb = Bomb::<B> {\n+            coordinator_send: cgcx.coordinator_send.clone(),\n+            result: None,\n+            worker_id: cgcx.worker,\n+        };\n+\n+        // Execute the work itself, and if it finishes successfully then flag\n+        // ourselves as a success as well.\n+        //\n+        // Note that we ignore any `FatalError` coming out of `execute_work_item`,\n+        // as a diagnostic was already sent off to the main thread - just\n+        // surface that there was an error in this worker.\n+        bomb.result = {\n+            let timeline = cgcx.time_graph.as_ref().map(|tg| {\n+                tg.start(time_graph::TimelineId(cgcx.worker),\n+                         LLVM_WORK_PACKAGE_KIND,\n+                         &work.name())\n+            });\n+            let mut timeline = timeline.unwrap_or(Timeline::noop());\n+            execute_work_item(&cgcx, work, &mut timeline).ok()\n+        };\n+    });\n+}\n+\n+pub fn run_assembler<B: ExtraBackendMethods>(\n+    cgcx: &CodegenContext<B>,\n+    handler: &Handler,\n+    assembly: &Path,\n+    object: &Path\n+) {\n+    let assembler = cgcx.assembler_cmd\n+        .as_ref()\n+        .expect(\"cgcx.assembler_cmd is missing?\");\n+\n+    let pname = &assembler.name;\n+    let mut cmd = assembler.cmd.clone();\n+    cmd.arg(\"-c\").arg(\"-o\").arg(object).arg(assembly);\n+    debug!(\"{:?}\", cmd);\n+\n+    match cmd.output() {\n+        Ok(prog) => {\n+            if !prog.status.success() {\n+                let mut note = prog.stderr.clone();\n+                note.extend_from_slice(&prog.stdout);\n+\n+                handler.struct_err(&format!(\"linking with `{}` failed: {}\",\n+                                            pname.display(),\n+                                            prog.status))\n+                    .note(&format!(\"{:?}\", &cmd))\n+                    .note(str::from_utf8(&note[..]).unwrap())\n+                    .emit();\n+                handler.abort_if_errors();\n+            }\n+        },\n+        Err(e) => {\n+            handler.err(&format!(\"could not exec the linker `{}`: {}\", pname.display(), e));\n+            handler.abort_if_errors();\n+        }\n+    }\n+}\n+\n+\n+enum SharedEmitterMessage {\n+    Diagnostic(Diagnostic),\n+    InlineAsmError(u32, String),\n+    AbortIfErrors,\n+    Fatal(String),\n+}\n+\n+#[derive(Clone)]\n+pub struct SharedEmitter {\n+    sender: Sender<SharedEmitterMessage>,\n+}\n+\n+pub struct SharedEmitterMain {\n+    receiver: Receiver<SharedEmitterMessage>,\n+}\n+\n+impl SharedEmitter {\n+    pub fn new() -> (SharedEmitter, SharedEmitterMain) {\n+        let (sender, receiver) = channel();\n+\n+        (SharedEmitter { sender }, SharedEmitterMain { receiver })\n+    }\n+\n+    pub fn inline_asm_error(&self, cookie: u32, msg: String) {\n+        drop(self.sender.send(SharedEmitterMessage::InlineAsmError(cookie, msg)));\n+    }\n+\n+    pub fn fatal(&self, msg: &str) {\n+        drop(self.sender.send(SharedEmitterMessage::Fatal(msg.to_string())));\n+    }\n+}\n+\n+impl Emitter for SharedEmitter {\n+    fn emit(&mut self, db: &DiagnosticBuilder) {\n+        drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n+            msg: db.message(),\n+            code: db.code.clone(),\n+            lvl: db.level,\n+        })));\n+        for child in &db.children {\n+            drop(self.sender.send(SharedEmitterMessage::Diagnostic(Diagnostic {\n+                msg: child.message(),\n+                code: None,\n+                lvl: child.level,\n+            })));\n+        }\n+        drop(self.sender.send(SharedEmitterMessage::AbortIfErrors));\n+    }\n+}\n+\n+impl SharedEmitterMain {\n+    pub fn check(&self, sess: &Session, blocking: bool) {\n+        loop {\n+            let message = if blocking {\n+                match self.receiver.recv() {\n+                    Ok(message) => Ok(message),\n+                    Err(_) => Err(()),\n+                }\n+            } else {\n+                match self.receiver.try_recv() {\n+                    Ok(message) => Ok(message),\n+                    Err(_) => Err(()),\n+                }\n+            };\n+\n+            match message {\n+                Ok(SharedEmitterMessage::Diagnostic(diag)) => {\n+                    let handler = sess.diagnostic();\n+                    match diag.code {\n+                        Some(ref code) => {\n+                            handler.emit_with_code(&MultiSpan::new(),\n+                                                   &diag.msg,\n+                                                   code.clone(),\n+                                                   diag.lvl);\n+                        }\n+                        None => {\n+                            handler.emit(&MultiSpan::new(),\n+                                         &diag.msg,\n+                                         diag.lvl);\n+                        }\n+                    }\n+                }\n+                Ok(SharedEmitterMessage::InlineAsmError(cookie, msg)) => {\n+                    match Mark::from_u32(cookie).expn_info() {\n+                        Some(ei) => sess.span_err(ei.call_site, &msg),\n+                        None     => sess.err(&msg),\n+                    }\n+                }\n+                Ok(SharedEmitterMessage::AbortIfErrors) => {\n+                    sess.abort_if_errors();\n+                }\n+                Ok(SharedEmitterMessage::Fatal(msg)) => {\n+                    sess.fatal(&msg);\n+                }\n+                Err(_) => {\n+                    break;\n+                }\n+            }\n+\n+        }\n+    }\n+}\n+\n+pub struct OngoingCodegen<B: ExtraBackendMethods> {\n+    pub backend: B,\n+    pub crate_name: Symbol,\n+    pub crate_hash: Svh,\n+    pub metadata: EncodedMetadata,\n+    pub windows_subsystem: Option<String>,\n+    pub linker_info: LinkerInfo,\n+    pub crate_info: CrateInfo,\n+    pub time_graph: Option<TimeGraph>,\n+    pub coordinator_send: Sender<Box<dyn Any + Send>>,\n+    pub codegen_worker_receive: Receiver<Message<B>>,\n+    pub shared_emitter_main: SharedEmitterMain,\n+    pub future: thread::JoinHandle<Result<CompiledModules, ()>>,\n+    pub output_filenames: Arc<OutputFilenames>,\n+}\n+\n+impl<B: ExtraBackendMethods> OngoingCodegen<B> {\n+    pub fn join(\n+        self,\n+        sess: &Session\n+    ) -> (CodegenResults, FxHashMap<WorkProductId, WorkProduct>) {\n+        self.shared_emitter_main.check(sess, true);\n+        let compiled_modules = match self.future.join() {\n+            Ok(Ok(compiled_modules)) => compiled_modules,\n+            Ok(Err(())) => {\n+                sess.abort_if_errors();\n+                panic!(\"expected abort due to worker thread errors\")\n+            },\n+            Err(_) => {\n+                bug!(\"panic during codegen/LLVM phase\");\n+            }\n+        };\n+\n+        sess.cgu_reuse_tracker.check_expected_reuse(sess);\n+\n+        sess.abort_if_errors();\n+\n+        if let Some(time_graph) = self.time_graph {\n+            time_graph.dump(&format!(\"{}-timings\", self.crate_name));\n+        }\n+\n+        let work_products =\n+            copy_all_cgu_workproducts_to_incr_comp_cache_dir(sess,\n+                                                             &compiled_modules);\n+        produce_final_output_artifacts(sess,\n+                                       &compiled_modules,\n+                                       &self.output_filenames);\n+\n+        // FIXME: time_llvm_passes support - does this use a global context or\n+        // something?\n+        if sess.codegen_units() == 1 && sess.time_llvm_passes() {\n+            self.backend.print_pass_timings()\n+        }\n+\n+        (CodegenResults {\n+            crate_name: self.crate_name,\n+            crate_hash: self.crate_hash,\n+            metadata: self.metadata,\n+            windows_subsystem: self.windows_subsystem,\n+            linker_info: self.linker_info,\n+            crate_info: self.crate_info,\n+\n+            modules: compiled_modules.modules,\n+            allocator_module: compiled_modules.allocator_module,\n+            metadata_module: compiled_modules.metadata_module,\n+        }, work_products)\n+    }\n+\n+    pub fn submit_pre_codegened_module_to_llvm(&self,\n+                                                       tcx: TyCtxt,\n+                                                       module: ModuleCodegen<B::Module>) {\n+        self.wait_for_signal_to_codegen_item();\n+        self.check_for_errors(tcx.sess);\n+\n+        // These are generally cheap and won't through off scheduling.\n+        let cost = 0;\n+        submit_codegened_module_to_llvm(&self.backend, tcx, module, cost);\n+    }\n+\n+    pub fn codegen_finished(&self, tcx: TyCtxt) {\n+        self.wait_for_signal_to_codegen_item();\n+        self.check_for_errors(tcx.sess);\n+        drop(self.coordinator_send.send(Box::new(Message::CodegenComplete::<B>)));\n+    }\n+\n+    /// Consume this context indicating that codegen was entirely aborted, and\n+    /// we need to exit as quickly as possible.\n+    ///\n+    /// This method blocks the current thread until all worker threads have\n+    /// finished, and all worker threads should have exited or be real close to\n+    /// exiting at this point.\n+    pub fn codegen_aborted(self) {\n+        // Signal to the coordinator it should spawn no more work and start\n+        // shutdown.\n+        drop(self.coordinator_send.send(Box::new(Message::CodegenAborted::<B>)));\n+        drop(self.future.join());\n+    }\n+\n+    pub fn check_for_errors(&self, sess: &Session) {\n+        self.shared_emitter_main.check(sess, false);\n+    }\n+\n+    pub fn wait_for_signal_to_codegen_item(&self) {\n+        match self.codegen_worker_receive.recv() {\n+            Ok(Message::CodegenItem) => {\n+                // Nothing to do\n+            }\n+            Ok(_) => panic!(\"unexpected message\"),\n+            Err(_) => {\n+                // One of the LLVM threads must have panicked, fall through so\n+                // error handling can be reached.\n+            }\n+        }\n+    }\n+}\n+\n+pub fn submit_codegened_module_to_llvm<B: ExtraBackendMethods>(\n+    _backend: &B,\n+    tcx: TyCtxt,\n+    module: ModuleCodegen<B::Module>,\n+    cost: u64\n+) {\n+    let llvm_work_item = WorkItem::Optimize(module);\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone::<B> {\n+        llvm_work_item,\n+        cost,\n+    })));\n+}\n+\n+pub fn submit_post_lto_module_to_llvm<B: ExtraBackendMethods>(\n+    _backend: &B,\n+    tcx: TyCtxt,\n+    module: CachedModuleCodegen\n+) {\n+    let llvm_work_item = WorkItem::CopyPostLtoArtifacts(module);\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::CodegenDone::<B> {\n+        llvm_work_item,\n+        cost: 0,\n+    })));\n+}\n+\n+pub fn submit_pre_lto_module_to_llvm<B: ExtraBackendMethods>(\n+    _backend: &B,\n+    tcx: TyCtxt,\n+    module: CachedModuleCodegen\n+) {\n+    let filename = pre_lto_bitcode_filename(&module.name);\n+    let bc_path = in_incr_comp_dir_sess(tcx.sess, &filename);\n+    let file = fs::File::open(&bc_path).unwrap_or_else(|e| {\n+        panic!(\"failed to open bitcode file `{}`: {}\", bc_path.display(), e)\n+    });\n+\n+    let mmap = unsafe {\n+        memmap::Mmap::map(&file).unwrap_or_else(|e| {\n+            panic!(\"failed to mmap bitcode file `{}`: {}\", bc_path.display(), e)\n+        })\n+    };\n+    // Schedule the module to be loaded\n+    drop(tcx.tx_to_llvm_workers.lock().send(Box::new(Message::AddImportOnlyModule::<B> {\n+        module_data: SerializedModule::FromUncompressedFile(mmap),\n+        work_product: module.source,\n+    })));\n+}\n+\n+pub fn pre_lto_bitcode_filename(module_name: &str) -> String {\n+    format!(\"{}.{}\", module_name, PRE_THIN_LTO_BC_EXT)\n+}\n+\n+fn msvc_imps_needed(tcx: TyCtxt) -> bool {\n+    // This should never be true (because it's not supported). If it is true,\n+    // something is wrong with commandline arg validation.\n+    assert!(!(tcx.sess.opts.debugging_opts.cross_lang_lto.enabled() &&\n+              tcx.sess.target.target.options.is_like_msvc &&\n+              tcx.sess.opts.cg.prefer_dynamic));\n+\n+    tcx.sess.target.target.options.is_like_msvc &&\n+        tcx.sess.crate_types.borrow().iter().any(|ct| *ct == config::CrateType::Rlib) &&\n+    // ThinLTO can't handle this workaround in all cases, so we don't\n+    // emit the `__imp_` symbols. Instead we make them unnecessary by disallowing\n+    // dynamic linking when cross-language LTO is enabled.\n+    !tcx.sess.opts.debugging_opts.cross_lang_lto.enabled()\n+}"}, {"sha": "a590dcd3ea823150777ae15168c3d1a0f0e47db9", "filename": "src/librustc_codegen_ssa/base.rs", "status": "modified", "additions": 24, "deletions": 20, "changes": 44, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fbase.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Fbase.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Fbase.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -39,6 +39,8 @@ use rustc::util::profiling::ProfileCategory;\n use rustc::session::config::{self, EntryFnType, Lto};\n use rustc::session::Session;\n use mir::place::PlaceRef;\n+use back::write::{OngoingCodegen, start_async_codegen, submit_pre_lto_module_to_llvm,\n+    submit_post_lto_module_to_llvm};\n use {MemFlags, CrateInfo};\n use callee;\n use rustc_mir::monomorphize::item::DefPathBasedNames;\n@@ -556,7 +558,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     backend: B,\n     tcx: TyCtxt<'a, 'tcx, 'tcx>,\n     rx: mpsc::Receiver<Box<dyn Any + Send>>\n-) -> B::OngoingCodegen {\n+) -> OngoingCodegen<B> {\n \n     check_for_rustc_errors_attr(tcx);\n \n@@ -590,19 +592,20 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     // Skip crate items and just output metadata in -Z no-codegen mode.\n     if tcx.sess.opts.debugging_opts.no_codegen ||\n        !tcx.sess.opts.output_types.should_codegen() {\n-        let ongoing_codegen = backend.start_async_codegen(\n+        let ongoing_codegen = start_async_codegen(\n+            backend,\n             tcx,\n             time_graph,\n             metadata,\n             rx,\n             1);\n \n-        backend.submit_pre_codegened_module_to_backend(&ongoing_codegen, tcx, metadata_module);\n-        backend.codegen_finished(&ongoing_codegen, tcx);\n+        ongoing_codegen.submit_pre_codegened_module_to_llvm(tcx, metadata_module);\n+        ongoing_codegen.codegen_finished(tcx);\n \n         assert_and_save_dep_graph(tcx);\n \n-        backend.check_for_errors(&ongoing_codegen, tcx.sess);\n+        ongoing_codegen.check_for_errors(tcx.sess);\n \n         return ongoing_codegen;\n     }\n@@ -623,7 +626,8 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n         }\n     }\n \n-    let ongoing_codegen = backend.start_async_codegen(\n+    let ongoing_codegen = start_async_codegen(\n+        backend.clone(),\n         tcx,\n         time_graph.clone(),\n         metadata,\n@@ -667,10 +671,10 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     };\n \n     if let Some(allocator_module) = allocator_module {\n-        backend.submit_pre_codegened_module_to_backend(&ongoing_codegen, tcx, allocator_module);\n+        ongoing_codegen.submit_pre_codegened_module_to_llvm(tcx, allocator_module);\n     }\n \n-    backend.submit_pre_codegened_module_to_backend(&ongoing_codegen, tcx, metadata_module);\n+    ongoing_codegen.submit_pre_codegened_module_to_llvm(tcx, metadata_module);\n \n     // We sort the codegen units by size. This way we can schedule work for LLVM\n     // a bit more efficiently.\n@@ -684,8 +688,8 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n     let mut all_stats = Stats::default();\n \n     for cgu in codegen_units.into_iter() {\n-        backend.wait_for_signal_to_codegen_item(&ongoing_codegen);\n-        backend.check_for_errors(&ongoing_codegen, tcx.sess);\n+        ongoing_codegen.wait_for_signal_to_codegen_item();\n+        ongoing_codegen.check_for_errors(tcx.sess);\n \n         let cgu_reuse = determine_cgu_reuse(tcx, &cgu);\n         tcx.sess.cgu_reuse_tracker.set_actual_reuse(&cgu.name().as_str(), cgu_reuse);\n@@ -704,14 +708,14 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n                 false\n             }\n             CguReuse::PreLto => {\n-                backend.submit_pre_lto_module_to_backend(tcx, CachedModuleCodegen {\n+                submit_pre_lto_module_to_llvm(&backend, tcx, CachedModuleCodegen {\n                     name: cgu.name().to_string(),\n                     source: cgu.work_product(tcx),\n                 });\n                 true\n             }\n             CguReuse::PostLto => {\n-                backend.submit_post_lto_module_to_backend(tcx, CachedModuleCodegen {\n+                submit_post_lto_module_to_llvm(&backend, tcx, CachedModuleCodegen {\n                     name: cgu.name().to_string(),\n                     source: cgu.work_product(tcx),\n                 });\n@@ -720,7 +724,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n         };\n     }\n \n-    backend.codegen_finished(&ongoing_codegen, tcx);\n+    ongoing_codegen.codegen_finished(tcx);\n \n     // Since the main thread is sometimes blocked during codegen, we keep track\n     // -Ztime-passes output manually.\n@@ -754,7 +758,7 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n         }\n     }\n \n-    backend.check_for_errors(&ongoing_codegen, tcx.sess);\n+    ongoing_codegen.check_for_errors(tcx.sess);\n \n     assert_and_save_dep_graph(tcx);\n     ongoing_codegen.into_inner()\n@@ -777,32 +781,32 @@ pub fn codegen_crate<B: ExtraBackendMethods>(\n /// If you see this comment in the code, then it means that this workaround\n /// worked! We may yet one day track down the mysterious cause of that\n /// segfault...\n-struct AbortCodegenOnDrop<B: ExtraBackendMethods>(Option<B::OngoingCodegen>);\n+struct AbortCodegenOnDrop<B: ExtraBackendMethods>(Option<OngoingCodegen<B>>);\n \n impl<B: ExtraBackendMethods> AbortCodegenOnDrop<B> {\n-    fn into_inner(mut self) -> B::OngoingCodegen {\n+    fn into_inner(mut self) -> OngoingCodegen<B> {\n         self.0.take().unwrap()\n     }\n }\n \n impl<B: ExtraBackendMethods> Deref for AbortCodegenOnDrop<B> {\n-    type Target = B::OngoingCodegen;\n+    type Target = OngoingCodegen<B>;\n \n-    fn deref(&self) -> &B::OngoingCodegen {\n+    fn deref(&self) -> &OngoingCodegen<B> {\n         self.0.as_ref().unwrap()\n     }\n }\n \n impl<B: ExtraBackendMethods> DerefMut for AbortCodegenOnDrop<B> {\n-    fn deref_mut(&mut self) -> &mut B::OngoingCodegen {\n+    fn deref_mut(&mut self) -> &mut OngoingCodegen<B> {\n         self.0.as_mut().unwrap()\n     }\n }\n \n impl<B: ExtraBackendMethods> Drop for AbortCodegenOnDrop<B> {\n     fn drop(&mut self) {\n         if let Some(codegen) = self.0.take() {\n-            B::codegen_aborted(codegen);\n+            codegen.codegen_aborted();\n         }\n     }\n }"}, {"sha": "b4d376cf5f0e29792700ebbac3bf56329e6eb13f", "filename": "src/librustc_codegen_ssa/interfaces/backend.rs", "status": "modified", "additions": 12, "deletions": 29, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fbackend.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fbackend.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fbackend.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -11,18 +11,16 @@\n use rustc::ty::layout::{HasTyCtxt, LayoutOf, TyLayout};\n use rustc::ty::Ty;\n \n+use super::write::WriteBackendMethods;\n use super::CodegenObject;\n use rustc::middle::allocator::AllocatorKind;\n use rustc::middle::cstore::EncodedMetadata;\n use rustc::mir::mono::Stats;\n use rustc::session::Session;\n use rustc::ty::TyCtxt;\n-use rustc::util::time_graph::TimeGraph;\n use rustc_codegen_utils::codegen_backend::CodegenBackend;\n-use std::any::Any;\n-use std::sync::mpsc::Receiver;\n+use std::sync::Arc;\n use syntax_pos::symbol::InternedString;\n-use {CachedModuleCodegen, ModuleCodegen};\n \n pub trait BackendTypes {\n     type Value: CodegenObject;\n@@ -43,41 +41,26 @@ impl<'tcx, T> Backend<'tcx> for T where\n     Self: BackendTypes + HasTyCtxt<'tcx> + LayoutOf<Ty = Ty<'tcx>, TyLayout = TyLayout<'tcx>>\n {}\n \n-pub trait ExtraBackendMethods: CodegenBackend {\n-    type Module;\n-    type OngoingCodegen;\n-\n+pub trait ExtraBackendMethods: CodegenBackend + WriteBackendMethods + Sized + Send {\n     fn new_metadata(&self, sess: &Session, mod_name: &str) -> Self::Module;\n     fn write_metadata<'b, 'gcx>(\n         &self,\n         tcx: TyCtxt<'b, 'gcx, 'gcx>,\n         metadata: &Self::Module,\n     ) -> EncodedMetadata;\n     fn codegen_allocator(&self, tcx: TyCtxt, mods: &Self::Module, kind: AllocatorKind);\n-\n-    fn start_async_codegen(\n-        &self,\n-        tcx: TyCtxt,\n-        time_graph: Option<TimeGraph>,\n-        metadata: EncodedMetadata,\n-        coordinator_receive: Receiver<Box<dyn Any + Send>>,\n-        total_cgus: usize,\n-    ) -> Self::OngoingCodegen;\n-    fn submit_pre_codegened_module_to_backend(\n-        &self,\n-        codegen: &Self::OngoingCodegen,\n-        tcx: TyCtxt,\n-        module: ModuleCodegen<Self::Module>,\n-    );\n-    fn submit_pre_lto_module_to_backend(&self, tcx: TyCtxt, module: CachedModuleCodegen);\n-    fn submit_post_lto_module_to_backend(&self, tcx: TyCtxt, module: CachedModuleCodegen);\n-    fn codegen_aborted(codegen: Self::OngoingCodegen);\n-    fn codegen_finished(&self, codegen: &Self::OngoingCodegen, tcx: TyCtxt);\n-    fn check_for_errors(&self, codegen: &Self::OngoingCodegen, sess: &Session);\n-    fn wait_for_signal_to_codegen_item(&self, codegen: &Self::OngoingCodegen);\n     fn compile_codegen_unit<'a, 'tcx: 'a>(\n         &self,\n         tcx: TyCtxt<'a, 'tcx, 'tcx>,\n         cgu_name: InternedString,\n     ) -> Stats;\n+    // If find_features is true this won't access `sess.crate_types` by assuming\n+    // that `is_pie_binary` is false. When we discover LLVM target features\n+    // `sess.crate_types` is uninitialized so we cannot access it.\n+    fn target_machine_factory(\n+        &self,\n+        sess: &Session,\n+        find_features: bool,\n+    ) -> Arc<dyn Fn() -> Result<Self::TargetMachine, String> + Send + Sync>;\n+    fn target_cpu<'b>(&self, sess: &'b Session) -> &'b str;\n }"}, {"sha": "5cff31e17b5bc7abdd2f603c48ee2f6e717c665a", "filename": "src/librustc_codegen_ssa/interfaces/mod.rs", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fmod.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fmod.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fmod.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -35,6 +35,7 @@ mod intrinsic;\n mod misc;\n mod statics;\n mod type_;\n+mod write;\n \n pub use self::abi::{AbiBuilderMethods, AbiMethods};\n pub use self::asm::{AsmBuilderMethods, AsmMethods};\n@@ -49,6 +50,7 @@ pub use self::statics::StaticMethods;\n pub use self::type_::{\n     ArgTypeMethods, BaseTypeMethods, DerivedTypeMethods, LayoutTypeMethods, TypeMethods,\n };\n+pub use self::write::{ModuleBufferMethods, ThinBufferMethods, WriteBackendMethods};\n \n use std::fmt;\n "}, {"sha": "3419e1c59edac2a61d2dafe943ea72e0a0dfb716", "filename": "src/librustc_codegen_ssa/interfaces/write.rs", "status": "added", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fwrite.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fwrite.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Finterfaces%2Fwrite.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -0,0 +1,72 @@\n+// Copyright 2018 The Rust Project Developers. See the COPYRIGHT\n+// file at the top-level directory of this distribution and at\n+// http://rust-lang.org/COPYRIGHT.\n+//\n+// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or\n+// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license\n+// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your\n+// option. This file may not be copied, modified, or distributed\n+// except according to those terms.\n+\n+use back::lto::{LtoModuleCodegen, SerializedModule, ThinModule};\n+use back::write::{CodegenContext, ModuleConfig};\n+use {CompiledModule, ModuleCodegen};\n+\n+use rustc::dep_graph::WorkProduct;\n+use rustc::util::time_graph::Timeline;\n+use rustc_errors::{FatalError, Handler};\n+\n+pub trait WriteBackendMethods: 'static + Sized + Clone {\n+    type Module: Send + Sync;\n+    type TargetMachine: Clone;\n+    type ModuleBuffer: ModuleBufferMethods;\n+    type Context: ?Sized;\n+    type ThinData: Send + Sync;\n+    type ThinBuffer: ThinBufferMethods;\n+\n+    /// Performs LTO, which in the case of full LTO means merging all modules into\n+    /// a single one and returning it for further optimizing. For ThinLTO, it will\n+    /// do the global analysis necessary and return two lists, one of the modules\n+    /// the need optimization and another for modules that can simply be copied over\n+    /// from the incr. comp. cache.\n+    fn run_lto(\n+        cgcx: &CodegenContext<Self>,\n+        modules: Vec<ModuleCodegen<Self::Module>>,\n+        cached_modules: Vec<(SerializedModule<Self::ModuleBuffer>, WorkProduct)>,\n+        timeline: &mut Timeline,\n+    ) -> Result<(Vec<LtoModuleCodegen<Self>>, Vec<WorkProduct>), FatalError>;\n+    fn print_pass_timings(&self);\n+    unsafe fn optimize(\n+        cgcx: &CodegenContext<Self>,\n+        diag_handler: &Handler,\n+        module: &ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        timeline: &mut Timeline,\n+    ) -> Result<(), FatalError>;\n+    unsafe fn optimize_thin(\n+        cgcx: &CodegenContext<Self>,\n+        thin: &mut ThinModule<Self>,\n+        timeline: &mut Timeline,\n+    ) -> Result<ModuleCodegen<Self::Module>, FatalError>;\n+    unsafe fn codegen(\n+        cgcx: &CodegenContext<Self>,\n+        diag_handler: &Handler,\n+        module: ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        timeline: &mut Timeline,\n+    ) -> Result<CompiledModule, FatalError>;\n+    fn run_lto_pass_manager(\n+        cgcx: &CodegenContext<Self>,\n+        llmod: &ModuleCodegen<Self::Module>,\n+        config: &ModuleConfig,\n+        thin: bool,\n+    );\n+}\n+\n+pub trait ThinBufferMethods: Send + Sync {\n+    fn data(&self) -> &[u8];\n+}\n+\n+pub trait ModuleBufferMethods: Send + Sync {\n+    fn data(&self) -> &[u8];\n+}"}, {"sha": "e779d8f146926df1be6060db60f1b9b72a39c4fd", "filename": "src/librustc_codegen_ssa/lib.rs", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_ssa%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_ssa%2Flib.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -39,7 +39,16 @@ extern crate syntax_pos;\n extern crate rustc_incremental;\n extern crate rustc_codegen_utils;\n extern crate rustc_data_structures;\n+extern crate rustc_allocator;\n+extern crate rustc_fs_util;\n+extern crate serialize;\n+extern crate rustc_errors;\n+extern crate rustc_demangle;\n+extern crate cc;\n extern crate libc;\n+extern crate jobserver;\n+extern crate memmap;\n+extern crate num_cpus;\n \n use std::path::PathBuf;\n use rustc::dep_graph::WorkProduct;\n@@ -48,7 +57,9 @@ use rustc::middle::lang_items::LangItem;\n use rustc::hir::def_id::CrateNum;\n use rustc_data_structures::fx::{FxHashMap, FxHashSet};\n use rustc_data_structures::sync::Lrc;\n+use rustc_data_structures::svh::Svh;\n use rustc::middle::cstore::{LibSource, CrateSource, NativeLibrary};\n+use syntax_pos::symbol::Symbol;\n \n // NB: This module needs to be declared first so diagnostics are\n // registered before they are used.\n@@ -63,6 +74,7 @@ pub mod callee;\n pub mod glue;\n pub mod meth;\n pub mod mono_item;\n+pub mod back;\n \n pub struct ModuleCodegen<M> {\n     /// The name of the module. When the crate may be saved between\n@@ -159,4 +171,17 @@ pub struct CrateInfo {\n     pub missing_lang_items: FxHashMap<CrateNum, Vec<LangItem>>,\n }\n \n+\n+pub struct CodegenResults {\n+    pub crate_name: Symbol,\n+    pub modules: Vec<CompiledModule>,\n+    pub allocator_module: Option<CompiledModule>,\n+    pub metadata_module: CompiledModule,\n+    pub crate_hash: Svh,\n+    pub metadata: rustc::middle::cstore::EncodedMetadata,\n+    pub windows_subsystem: Option<String>,\n+    pub linker_info: back::linker::LinkerInfo,\n+    pub crate_info: CrateInfo,\n+}\n+\n __build_diagnostic_array! { librustc_codegen_ssa, DIAGNOSTICS }"}, {"sha": "34a09f30b641162e1ed5541673832dd686935634", "filename": "src/librustc_codegen_utils/Cargo.toml", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_utils%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_utils%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_utils%2FCargo.toml?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -13,11 +13,9 @@ test = false\n flate2 = \"1.0\"\n log = \"0.4\"\n \n-serialize = { path = \"../libserialize\" }\n syntax = { path = \"../libsyntax\" }\n syntax_pos = { path = \"../libsyntax_pos\" }\n rustc = { path = \"../librustc\" }\n-rustc_allocator = { path = \"../librustc_allocator\" }\n rustc_target = { path = \"../librustc_target\" }\n rustc_data_structures = { path = \"../librustc_data_structures\" }\n rustc_metadata = { path = \"../librustc_metadata\" }"}, {"sha": "96b319481a7f6f62c74d9f5d051ef7d406e9a572", "filename": "src/librustc_codegen_utils/lib.rs", "status": "modified", "additions": 0, "deletions": 31, "changes": 31, "blob_url": "https://github.com/rust-lang/rust/blob/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_utils%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be/src%2Flibrustc_codegen_utils%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_codegen_utils%2Flib.rs?ref=b9e5cf99a9acd9c29d02c2f27c0eb223fd0a92be", "patch": "@@ -31,10 +31,8 @@ extern crate flate2;\n #[macro_use]\n extern crate log;\n \n-extern crate serialize;\n #[macro_use]\n extern crate rustc;\n-extern crate rustc_allocator;\n extern crate rustc_target;\n extern crate rustc_metadata;\n extern crate rustc_mir;\n@@ -43,16 +41,10 @@ extern crate syntax;\n extern crate syntax_pos;\n #[macro_use] extern crate rustc_data_structures;\n \n-use std::path::PathBuf;\n-\n-use rustc::session::Session;\n use rustc::ty::TyCtxt;\n \n-pub mod command;\n pub mod link;\n-pub mod linker;\n pub mod codegen_backend;\n-pub mod symbol_export;\n pub mod symbol_names;\n pub mod symbol_names_test;\n \n@@ -70,27 +62,4 @@ pub fn check_for_rustc_errors_attr(tcx: TyCtxt) {\n     }\n }\n \n-pub fn find_library(name: &str, search_paths: &[PathBuf], sess: &Session)\n-                    -> PathBuf {\n-    // On Windows, static libraries sometimes show up as libfoo.a and other\n-    // times show up as foo.lib\n-    let oslibname = format!(\"{}{}{}\",\n-                            sess.target.target.options.staticlib_prefix,\n-                            name,\n-                            sess.target.target.options.staticlib_suffix);\n-    let unixlibname = format!(\"lib{}.a\", name);\n-\n-    for path in search_paths {\n-        debug!(\"looking for {} inside {:?}\", name, path);\n-        let test = path.join(&oslibname);\n-        if test.exists() { return test }\n-        if oslibname != unixlibname {\n-            let test = path.join(&unixlibname);\n-            if test.exists() { return test }\n-        }\n-    }\n-    sess.fatal(&format!(\"could not find native static library `{}`, \\\n-                         perhaps an -L flag is missing?\", name));\n-}\n-\n __build_diagnostic_array! { librustc_codegen_utils, DIAGNOSTICS }"}]}