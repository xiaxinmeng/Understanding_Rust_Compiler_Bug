{"sha": "665ad9c175f746b78c7eae81432b543d2e16c3c9", "node_id": "MDY6Q29tbWl0NzI0NzEyOjY2NWFkOWMxNzVmNzQ2Yjc4YzdlYWU4MTQzMmI1NDNkMmUxNmMzYzk=", "commit": {"author": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-28T00:05:28Z"}, "committer": {"name": "Brendan Zabarauskas", "email": "bjzaba@yahoo.com.au", "date": "2014-10-28T04:55:38Z"}, "message": "Move token-to-string functions into print::pprust", "tree": {"sha": "ef3ee489fe83735580ee2dcea9f82ad61296a07b", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ef3ee489fe83735580ee2dcea9f82ad61296a07b"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/665ad9c175f746b78c7eae81432b543d2e16c3c9", "comment_count": 5, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/665ad9c175f746b78c7eae81432b543d2e16c3c9", "html_url": "https://github.com/rust-lang/rust/commit/665ad9c175f746b78c7eae81432b543d2e16c3c9", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/665ad9c175f746b78c7eae81432b543d2e16c3c9/comments", "author": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "committer": {"login": "brendanzab", "id": 695077, "node_id": "MDQ6VXNlcjY5NTA3Nw==", "avatar_url": "https://avatars.githubusercontent.com/u/695077?v=4", "gravatar_id": "", "url": "https://api.github.com/users/brendanzab", "html_url": "https://github.com/brendanzab", "followers_url": "https://api.github.com/users/brendanzab/followers", "following_url": "https://api.github.com/users/brendanzab/following{/other_user}", "gists_url": "https://api.github.com/users/brendanzab/gists{/gist_id}", "starred_url": "https://api.github.com/users/brendanzab/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/brendanzab/subscriptions", "organizations_url": "https://api.github.com/users/brendanzab/orgs", "repos_url": "https://api.github.com/users/brendanzab/repos", "events_url": "https://api.github.com/users/brendanzab/events{/privacy}", "received_events_url": "https://api.github.com/users/brendanzab/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "url": "https://api.github.com/repos/rust-lang/rust/commits/cd049591a25973cd41ca5b69e7a151ae5fa0b71f", "html_url": "https://github.com/rust-lang/rust/commit/cd049591a25973cd41ca5b69e7a151ae5fa0b71f"}], "stats": {"total": 214, "additions": 108, "deletions": 106}, "files": [{"sha": "073bebcb3f6ff9da353a756fa2c09f9bbbae7ee3", "filename": "src/libsyntax/ext/tt/macro_parser.rs", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/rust-lang/rust/blob/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fext%2Ftt%2Fmacro_parser.rs?ref=665ad9c175f746b78c7eae81432b543d2e16c3c9", "patch": "@@ -87,6 +87,7 @@ use parse::attr::ParserAttr;\n use parse::parser::{LifetimeAndTypesWithoutColons, Parser};\n use parse::token::{Token, Nonterminal};\n use parse::token;\n+use print::pprust;\n use ptr::P;\n \n use std::rc::Rc;\n@@ -402,7 +403,7 @@ pub fn parse(sess: &ParseSess,\n                     nts, next_eis.len()).to_string());\n             } else if bb_eis.len() == 0u && next_eis.len() == 0u {\n                 return Failure(sp, format!(\"no rules expected the token `{}`\",\n-                            token::to_string(&tok)).to_string());\n+                            pprust::token_to_string(&tok)).to_string());\n             } else if next_eis.len() > 0u {\n                 /* Now process the next token */\n                 while next_eis.len() > 0u {\n@@ -449,7 +450,7 @@ pub fn parse_nt(p: &mut Parser, name: &str) -> Nonterminal {\n       \"ident\" => match p.token {\n         token::Ident(sn,b) => { p.bump(); token::NtIdent(box sn,b) }\n         _ => {\n-            let token_str = token::to_string(&p.token);\n+            let token_str = pprust::token_to_string(&p.token);\n             p.fatal((format!(\"expected ident, found {}\",\n                              token_str.as_slice())).as_slice())\n         }"}, {"sha": "3814ecfbe5bc65cd9b28d62dcad8c79ab69bf286", "filename": "src/libsyntax/parse/lexer/comments.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "raw_url": "https://github.com/rust-lang/rust/raw/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Flexer%2Fcomments.rs?ref=665ad9c175f746b78c7eae81432b543d2e16c3c9", "patch": "@@ -15,7 +15,7 @@ use parse::lexer::{is_whitespace, Reader};\n use parse::lexer::{StringReader, TokenAndSpan};\n use parse::lexer::is_block_doc_comment;\n use parse::lexer;\n-use parse::token;\n+use print::pprust;\n \n use std::io;\n use std::str;\n@@ -373,7 +373,7 @@ pub fn gather_comments_and_literals(span_diagnostic: &diagnostic::SpanHandler,\n                 literals.push(Literal {lit: s.to_string(), pos: sp.lo});\n             })\n         } else {\n-            debug!(\"tok: {}\", token::to_string(&tok));\n+            debug!(\"tok: {}\", pprust::token_to_string(&tok));\n         }\n         first_read = false;\n     }"}, {"sha": "654de709566ae3b408b20213ecb3315a04977217", "filename": "src/libsyntax/parse/parser.rs", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/rust-lang/rust/blob/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Fparser.rs", "raw_url": "https://github.com/rust-lang/rust/raw/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Fparser.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Fparser.rs?ref=665ad9c175f746b78c7eae81432b543d2e16c3c9", "patch": "@@ -78,6 +78,7 @@ use parse::token::InternedString;\n use parse::token::{keywords, special_idents};\n use parse::token;\n use parse::{new_sub_parser_from_file, ParseSess};\n+use print::pprust;\n use ptr::P;\n use owned_slice::OwnedSlice;\n \n@@ -394,7 +395,7 @@ impl<'a> Parser<'a> {\n \n     /// Convert a token to a string using self's reader\n     pub fn token_to_string(token: &token::Token) -> String {\n-        token::to_string(token)\n+        pprust::token_to_string(token)\n     }\n \n     /// Convert the current token to a string using self's reader"}, {"sha": "9ed8e4bc3a70752e81ba5ce85684a9c6ffefa78c", "filename": "src/libsyntax/parse/token.rs", "status": "modified", "additions": 0, "deletions": 95, "changes": 95, "blob_url": "https://github.com/rust-lang/rust/blob/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Ftoken.rs", "raw_url": "https://github.com/rust-lang/rust/raw/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fparse%2Ftoken.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fparse%2Ftoken.rs?ref=665ad9c175f746b78c7eae81432b543d2e16c3c9", "patch": "@@ -431,101 +431,6 @@ impl fmt::Show for Nonterminal {\n     }\n }\n \n-pub fn binop_to_string(o: BinOpToken) -> &'static str {\n-    match o {\n-        Plus      => \"+\",\n-        Minus     => \"-\",\n-        Star      => \"*\",\n-        Slash     => \"/\",\n-        Percent   => \"%\",\n-        Caret     => \"^\",\n-        And       => \"&\",\n-        Or        => \"|\",\n-        Shl       => \"<<\",\n-        Shr       => \">>\",\n-    }\n-}\n-\n-pub fn to_string(t: &Token) -> String {\n-    match *t {\n-        Eq                  => \"=\".into_string(),\n-        Lt                  => \"<\".into_string(),\n-        Le                  => \"<=\".into_string(),\n-        EqEq                => \"==\".into_string(),\n-        Ne                  => \"!=\".into_string(),\n-        Ge                  => \">=\".into_string(),\n-        Gt                  => \">\".into_string(),\n-        Not                 => \"!\".into_string(),\n-        Tilde               => \"~\".into_string(),\n-        OrOr                => \"||\".into_string(),\n-        AndAnd              => \"&&\".into_string(),\n-        BinOp(op)           => binop_to_string(op).into_string(),\n-        BinOpEq(op)         => format!(\"{}=\", binop_to_string(op)),\n-\n-        /* Structural symbols */\n-        At                  => \"@\".into_string(),\n-        Dot                 => \".\".into_string(),\n-        DotDot              => \"..\".into_string(),\n-        DotDotDot           => \"...\".into_string(),\n-        Comma               => \",\".into_string(),\n-        Semi                => \";\".into_string(),\n-        Colon               => \":\".into_string(),\n-        ModSep              => \"::\".into_string(),\n-        RArrow              => \"->\".into_string(),\n-        LArrow              => \"<-\".into_string(),\n-        FatArrow            => \"=>\".into_string(),\n-        LParen              => \"(\".into_string(),\n-        RParen              => \")\".into_string(),\n-        LBracket            => \"[\".into_string(),\n-        RBracket            => \"]\".into_string(),\n-        LBrace              => \"{\".into_string(),\n-        RBrace              => \"}\".into_string(),\n-        Pound               => \"#\".into_string(),\n-        Dollar              => \"$\".into_string(),\n-        Question            => \"?\".into_string(),\n-\n-        /* Literals */\n-        LitByte(b)          => format!(\"b'{}'\", b.as_str()),\n-        LitChar(c)          => format!(\"'{}'\", c.as_str()),\n-        LitFloat(c)         => c.as_str().into_string(),\n-        LitInteger(c)       => c.as_str().into_string(),\n-        LitStr(s)           => format!(\"\\\"{}\\\"\", s.as_str()),\n-        LitStrRaw(s, n)     => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n-                                       delim=\"#\".repeat(n),\n-                                       string=s.as_str()),\n-        LitBinary(v)        => format!(\"b\\\"{}\\\"\", v.as_str()),\n-        LitBinaryRaw(s, n)  => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n-                                       delim=\"#\".repeat(n),\n-                                       string=s.as_str()),\n-\n-        /* Name components */\n-        Ident(s, _)         => get_ident(s).get().into_string(),\n-        Lifetime(s)         => format!(\"{}\", get_ident(s)),\n-        Underscore          => \"_\".into_string(),\n-\n-        /* Other */\n-        DocComment(s)       => s.as_str().into_string(),\n-        Eof                 => \"<eof>\".into_string(),\n-        Whitespace          => \" \".into_string(),\n-        Comment             => \"/* */\".into_string(),\n-        Shebang(s)          => format!(\"/* shebang: {}*/\", s.as_str()),\n-\n-        Interpolated(ref nt) => match *nt {\n-            NtExpr(ref e)  => ::print::pprust::expr_to_string(&**e),\n-            NtMeta(ref e)  => ::print::pprust::meta_item_to_string(&**e),\n-            NtTy(ref e)    => ::print::pprust::ty_to_string(&**e),\n-            NtPath(ref e)  => ::print::pprust::path_to_string(&**e),\n-            NtItem(..)     => \"an interpolated item\".into_string(),\n-            NtBlock(..)    => \"an interpolated block\".into_string(),\n-            NtStmt(..)     => \"an interpolated statement\".into_string(),\n-            NtPat(..)      => \"an interpolated pattern\".into_string(),\n-            NtIdent(..)    => \"an interpolated identifier\".into_string(),\n-            NtTT(..)       => \"an interpolated tt\".into_string(),\n-            NtMatchers(..) => \"an interpolated matcher sequence\".into_string(),\n-        }\n-    }\n-}\n-\n // Get the first \"argument\"\n macro_rules! first {\n     ( $first:expr, $( $remainder:expr, )* ) => ( $first )"}, {"sha": "a52987f5bd174b24f540589d342c9c2e7814923a", "filename": "src/libsyntax/print/pprust.rs", "status": "modified", "additions": 101, "deletions": 6, "changes": 107, "blob_url": "https://github.com/rust-lang/rust/blob/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fprint%2Fpprust.rs", "raw_url": "https://github.com/rust-lang/rust/raw/665ad9c175f746b78c7eae81432b543d2e16c3c9/src%2Flibsyntax%2Fprint%2Fpprust.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibsyntax%2Fprint%2Fpprust.rs?ref=665ad9c175f746b78c7eae81432b543d2e16c3c9", "patch": "@@ -21,6 +21,7 @@ use attr::{AttrMetaMethods, AttributeMethods};\n use codemap::{CodeMap, BytePos};\n use codemap;\n use diagnostic;\n+use parse::token::{BinOpToken, Token};\n use parse::token;\n use parse::lexer::comments;\n use parse;\n@@ -181,6 +182,101 @@ pub fn to_string(f: |&mut State| -> IoResult<()>) -> String {\n     }\n }\n \n+pub fn binop_to_string(op: BinOpToken) -> &'static str {\n+    match op {\n+        token::Plus     => \"+\",\n+        token::Minus    => \"-\",\n+        token::Star     => \"*\",\n+        token::Slash    => \"/\",\n+        token::Percent  => \"%\",\n+        token::Caret    => \"^\",\n+        token::And      => \"&\",\n+        token::Or       => \"|\",\n+        token::Shl      => \"<<\",\n+        token::Shr      => \">>\",\n+    }\n+}\n+\n+pub fn token_to_string(tok: &Token) -> String {\n+    match *tok {\n+        token::Eq                   => \"=\".into_string(),\n+        token::Lt                   => \"<\".into_string(),\n+        token::Le                   => \"<=\".into_string(),\n+        token::EqEq                 => \"==\".into_string(),\n+        token::Ne                   => \"!=\".into_string(),\n+        token::Ge                   => \">=\".into_string(),\n+        token::Gt                   => \">\".into_string(),\n+        token::Not                  => \"!\".into_string(),\n+        token::Tilde                => \"~\".into_string(),\n+        token::OrOr                 => \"||\".into_string(),\n+        token::AndAnd               => \"&&\".into_string(),\n+        token::BinOp(op)            => binop_to_string(op).into_string(),\n+        token::BinOpEq(op)          => format!(\"{}=\", binop_to_string(op)),\n+\n+        /* Structural symbols */\n+        token::At                   => \"@\".into_string(),\n+        token::Dot                  => \".\".into_string(),\n+        token::DotDot               => \"..\".into_string(),\n+        token::DotDotDot            => \"...\".into_string(),\n+        token::Comma                => \",\".into_string(),\n+        token::Semi                 => \";\".into_string(),\n+        token::Colon                => \":\".into_string(),\n+        token::ModSep               => \"::\".into_string(),\n+        token::RArrow               => \"->\".into_string(),\n+        token::LArrow               => \"<-\".into_string(),\n+        token::FatArrow             => \"=>\".into_string(),\n+        token::LParen               => \"(\".into_string(),\n+        token::RParen               => \")\".into_string(),\n+        token::LBracket             => \"[\".into_string(),\n+        token::RBracket             => \"]\".into_string(),\n+        token::LBrace               => \"{\".into_string(),\n+        token::RBrace               => \"}\".into_string(),\n+        token::Pound                => \"#\".into_string(),\n+        token::Dollar               => \"$\".into_string(),\n+        token::Question             => \"?\".into_string(),\n+\n+        /* Literals */\n+        token::LitByte(b)           => format!(\"b'{}'\", b.as_str()),\n+        token::LitChar(c)           => format!(\"'{}'\", c.as_str()),\n+        token::LitFloat(c)          => c.as_str().into_string(),\n+        token::LitInteger(c)        => c.as_str().into_string(),\n+        token::LitStr(s)            => format!(\"\\\"{}\\\"\", s.as_str()),\n+        token::LitStrRaw(s, n)      => format!(\"r{delim}\\\"{string}\\\"{delim}\",\n+                                               delim=\"#\".repeat(n),\n+                                               string=s.as_str()),\n+        token::LitBinary(v)         => format!(\"b\\\"{}\\\"\", v.as_str()),\n+        token::LitBinaryRaw(s, n)   => format!(\"br{delim}\\\"{string}\\\"{delim}\",\n+                                               delim=\"#\".repeat(n),\n+                                               string=s.as_str()),\n+\n+        /* Name components */\n+        token::Ident(s, _)          => token::get_ident(s).get().into_string(),\n+        token::Lifetime(s)          => format!(\"{}\", token::get_ident(s)),\n+        token::Underscore           => \"_\".into_string(),\n+\n+        /* Other */\n+        token::DocComment(s)        => s.as_str().into_string(),\n+        token::Eof                  => \"<eof>\".into_string(),\n+        token::Whitespace           => \" \".into_string(),\n+        token::Comment              => \"/* */\".into_string(),\n+        token::Shebang(s)           => format!(\"/* shebang: {}*/\", s.as_str()),\n+\n+        token::Interpolated(ref nt) => match *nt {\n+            token::NtExpr(ref e)  => expr_to_string(&**e),\n+            token::NtMeta(ref e)  => meta_item_to_string(&**e),\n+            token::NtTy(ref e)    => ty_to_string(&**e),\n+            token::NtPath(ref e)  => path_to_string(&**e),\n+            token::NtItem(..)     => \"an interpolated item\".into_string(),\n+            token::NtBlock(..)    => \"an interpolated block\".into_string(),\n+            token::NtStmt(..)     => \"an interpolated statement\".into_string(),\n+            token::NtPat(..)      => \"an interpolated pattern\".into_string(),\n+            token::NtIdent(..)    => \"an interpolated identifier\".into_string(),\n+            token::NtTT(..)       => \"an interpolated tt\".into_string(),\n+            token::NtMatchers(..) => \"an interpolated matcher sequence\".into_string(),\n+        }\n+    }\n+}\n+\n // FIXME (Issue #16472): the thing_to_string_impls macro should go away\n // after we revise the syntax::ext::quote::ToToken impls to go directly\n // to token-trees instead of thing -> string -> token-trees.\n@@ -1026,14 +1122,14 @@ impl<'a> State<'a> {\n         match *tt {\n             ast::TtDelimited(_, ref delimed) => {\n                 let (ref open, ref tts, ref close) = **delimed;\n-                try!(word(&mut self.s, parse::token::to_string(&open.token).as_slice()));\n+                try!(word(&mut self.s, token_to_string(&open.token).as_slice()));\n                 try!(space(&mut self.s));\n                 try!(self.print_tts(tts.as_slice()));\n                 try!(space(&mut self.s));\n-                word(&mut self.s, parse::token::to_string(&close.token).as_slice())\n+                word(&mut self.s, token_to_string(&close.token).as_slice())\n             },\n             ast::TtToken(_, ref tk) => {\n-                try!(word(&mut self.s, parse::token::to_string(tk).as_slice()));\n+                try!(word(&mut self.s, token_to_string(tk).as_slice()));\n                 match *tk {\n                     parse::token::DocComment(..) => {\n                         hardbreak(&mut self.s)\n@@ -1049,10 +1145,9 @@ impl<'a> State<'a> {\n                 try!(word(&mut self.s, \")\"));\n                 match *separator {\n                     Some(ref tk) => {\n-                        try!(word(&mut self.s,\n-                                  parse::token::to_string(tk).as_slice()));\n+                        try!(word(&mut self.s, token_to_string(tk).as_slice()));\n                     }\n-                    None => ()\n+                    None => {},\n                 }\n                 match kleene_op {\n                     ast::ZeroOrMore => word(&mut self.s, \"*\"),"}]}