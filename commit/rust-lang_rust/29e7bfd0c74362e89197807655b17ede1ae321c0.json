{"sha": "29e7bfd0c74362e89197807655b17ede1ae321c0", "node_id": "MDY6Q29tbWl0NzI0NzEyOjI5ZTdiZmQwYzc0MzYyZTg5MTk3ODA3NjU1YjE3ZWRlMWFlMzIxYzA=", "commit": {"author": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2019-04-19T16:49:15Z"}, "committer": {"name": "John K\u00e5re Alsaker", "email": "john.kare.alsaker@gmail.com", "date": "2019-07-11T00:09:37Z"}, "message": "Refactor diagnostic emission for green nodes", "tree": {"sha": "59f0796f0573726a90da9e134f1eb1067efee674", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/59f0796f0573726a90da9e134f1eb1067efee674"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/29e7bfd0c74362e89197807655b17ede1ae321c0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/29e7bfd0c74362e89197807655b17ede1ae321c0", "html_url": "https://github.com/rust-lang/rust/commit/29e7bfd0c74362e89197807655b17ede1ae321c0", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/29e7bfd0c74362e89197807655b17ede1ae321c0/comments", "author": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "committer": {"login": "Zoxc", "id": 25784, "node_id": "MDQ6VXNlcjI1Nzg0", "avatar_url": "https://avatars.githubusercontent.com/u/25784?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Zoxc", "html_url": "https://github.com/Zoxc", "followers_url": "https://api.github.com/users/Zoxc/followers", "following_url": "https://api.github.com/users/Zoxc/following{/other_user}", "gists_url": "https://api.github.com/users/Zoxc/gists{/gist_id}", "starred_url": "https://api.github.com/users/Zoxc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Zoxc/subscriptions", "organizations_url": "https://api.github.com/users/Zoxc/orgs", "repos_url": "https://api.github.com/users/Zoxc/repos", "events_url": "https://api.github.com/users/Zoxc/events{/privacy}", "received_events_url": "https://api.github.com/users/Zoxc/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "d4e15655092d1bdae79619eb0ff2c3cb5468fc36", "url": "https://api.github.com/repos/rust-lang/rust/commits/d4e15655092d1bdae79619eb0ff2c3cb5468fc36", "html_url": "https://github.com/rust-lang/rust/commit/d4e15655092d1bdae79619eb0ff2c3cb5468fc36"}], "stats": {"total": 86, "additions": 51, "deletions": 35}, "files": [{"sha": "7eea336cbbfa1e3804f0c7fc6c68e533433a1695", "filename": "src/librustc/dep_graph/graph.rs", "status": "modified", "additions": 51, "deletions": 35, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/29e7bfd0c74362e89197807655b17ede1ae321c0/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "raw_url": "https://github.com/rust-lang/rust/raw/29e7bfd0c74362e89197807655b17ede1ae321c0/src%2Flibrustc%2Fdep_graph%2Fgraph.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc%2Fdep_graph%2Fgraph.rs?ref=29e7bfd0c74362e89197807655b17ede1ae321c0", "patch": "@@ -7,6 +7,7 @@ use rustc_data_structures::sync::{Lrc, Lock, AtomicU32, Ordering};\n use std::env;\n use std::hash::Hash;\n use std::collections::hash_map::Entry;\n+use std::mem;\n use crate::ty::{self, TyCtxt};\n use crate::util::common::{ProfileQueriesMsg, profq_msg};\n use parking_lot::{Mutex, Condvar};\n@@ -61,11 +62,11 @@ struct DepGraphData {\n \n     colors: DepNodeColorMap,\n \n-    /// A set of loaded diagnostics that have been emitted.\n-    emitted_diagnostics: Mutex<FxHashSet<DepNodeIndex>>,\n+    /// A set of loaded diagnostics that is in the progress of being emitted.\n+    emitting_diagnostics: Mutex<FxHashSet<DepNodeIndex>>,\n \n     /// Used to wait for diagnostics to be emitted.\n-    emitted_diagnostics_cond_var: Condvar,\n+    emitting_diagnostics_cond_var: Condvar,\n \n     /// When we load, there may be `.o` files, cached MIR, or other such\n     /// things available to us. If we find that they are not dirty, we\n@@ -99,8 +100,8 @@ impl DepGraph {\n                 previous_work_products: prev_work_products,\n                 dep_node_debug: Default::default(),\n                 current: Lock::new(CurrentDepGraph::new(prev_graph_node_count)),\n-                emitted_diagnostics: Default::default(),\n-                emitted_diagnostics_cond_var: Condvar::new(),\n+                emitting_diagnostics: Default::default(),\n+                emitting_diagnostics_cond_var: Condvar::new(),\n                 previous: prev_graph,\n                 colors: DepNodeColorMap::new(prev_graph_node_count),\n                 loaded_from_cache: Default::default(),\n@@ -744,7 +745,7 @@ impl DepGraph {\n \n         // There may be multiple threads trying to mark the same dep node green concurrently\n \n-        let (dep_node_index, did_allocation) = {\n+        let dep_node_index = {\n             let mut current = data.current.borrow_mut();\n \n             // Copy the fingerprint from the previous graph,\n@@ -758,71 +759,86 @@ impl DepGraph {\n \n         // ... emitting any stored diagnostic ...\n \n+        // FIXME: Store the fact that a node has diagnostics in a bit in the dep graph somewhere\n+        // Maybe store a list on disk and encode this fact in the DepNodeState\n         let diagnostics = tcx.queries.on_disk_cache\n-                                .load_diagnostics(tcx, prev_dep_node_index);\n+                             .load_diagnostics(tcx, prev_dep_node_index);\n+\n+        #[cfg(not(parallel_compiler))]\n+        debug_assert!(data.colors.get(prev_dep_node_index).is_none(),\n+                      \"DepGraph::try_mark_previous_green() - Duplicate DepNodeColor \\\n+                      insertion for {:?}\", dep_node);\n \n         if unlikely!(diagnostics.len() > 0) {\n             self.emit_diagnostics(\n                 tcx,\n                 data,\n                 dep_node_index,\n-                did_allocation,\n+                prev_dep_node_index,\n                 diagnostics\n             );\n         }\n \n         // ... and finally storing a \"Green\" entry in the color map.\n         // Multiple threads can all write the same color here\n-        #[cfg(not(parallel_compiler))]\n-        debug_assert!(data.colors.get(prev_dep_node_index).is_none(),\n-                      \"DepGraph::try_mark_previous_green() - Duplicate DepNodeColor \\\n-                      insertion for {:?}\", dep_node);\n-\n         data.colors.insert(prev_dep_node_index, DepNodeColor::Green(dep_node_index));\n \n         debug!(\"try_mark_previous_green({:?}) - END - successfully marked as green\", dep_node);\n         Some(dep_node_index)\n     }\n \n-    /// Atomically emits some loaded diagnotics, assuming that this only gets called with\n-    /// `did_allocation` set to `true` on a single thread.\n+    /// Atomically emits some loaded diagnostics.\n+    /// This may be called concurrently on multiple threads for the same dep node.\n     #[cold]\n     #[inline(never)]\n     fn emit_diagnostics<'tcx>(\n         &self,\n         tcx: TyCtxt<'tcx>,\n         data: &DepGraphData,\n         dep_node_index: DepNodeIndex,\n-        did_allocation: bool,\n+        prev_dep_node_index: SerializedDepNodeIndex,\n         diagnostics: Vec<Diagnostic>,\n     ) {\n-        if did_allocation || !cfg!(parallel_compiler) {\n-            // Only the thread which did the allocation emits the error messages\n-            let handle = tcx.sess.diagnostic();\n+        let mut emitting = data.emitting_diagnostics.lock();\n+\n+        if data.colors.get(prev_dep_node_index) == Some(DepNodeColor::Green(dep_node_index)) {\n+            // The node is already green so diagnostics must have been emitted already\n+            return;\n+        }\n+\n+        if emitting.insert(dep_node_index) {\n+            // We were the first to insert the node in the set so this thread\n+            // must emit the diagnostics and signal other potentially waiting\n+            // threads after.\n+            mem::drop(emitting);\n \n             // Promote the previous diagnostics to the current session.\n             tcx.queries.on_disk_cache\n-                .store_diagnostics(dep_node_index, diagnostics.clone().into());\n+               .store_diagnostics(dep_node_index, diagnostics.clone().into());\n+\n+            let handle = tcx.sess.diagnostic();\n \n             for diagnostic in diagnostics {\n                 DiagnosticBuilder::new_diagnostic(handle, diagnostic).emit();\n             }\n \n-            #[cfg(parallel_compiler)]\n-            {\n-                // Mark the diagnostics and emitted and wake up waiters\n-                data.emitted_diagnostics.lock().insert(dep_node_index);\n-                data.emitted_diagnostics_cond_var.notify_all();\n-            }\n+            // Mark the node as green now that diagnostics are emitted\n+            data.colors.insert(prev_dep_node_index, DepNodeColor::Green(dep_node_index));\n+\n+            // Remove the node from the set\n+            data.emitting_diagnostics.lock().remove(&dep_node_index);\n+\n+            // Wake up waiters\n+            data.emitting_diagnostics_cond_var.notify_all();\n         } else {\n-            // The other threads will wait for the diagnostics to be emitted\n+            // We must wait for the other thread to finish emitting the diagnostic\n \n-            let mut emitted_diagnostics = data.emitted_diagnostics.lock();\n             loop {\n-                if emitted_diagnostics.contains(&dep_node_index) {\n+                data.emitting_diagnostics_cond_var.wait(&mut emitting);\n+                if data.colors\n+                       .get(prev_dep_node_index) == Some(DepNodeColor::Green(dep_node_index)) {\n                     break;\n                 }\n-                data.emitted_diagnostics_cond_var.wait(&mut emitted_diagnostics);\n             }\n         }\n     }\n@@ -1027,7 +1043,7 @@ impl CurrentDepGraph {\n             hash: self.anon_id_seed.combine(hasher.finish()),\n         };\n \n-        self.intern_node(target_dep_node, task_deps.reads, Fingerprint::ZERO).0\n+        self.intern_node(target_dep_node, task_deps.reads, Fingerprint::ZERO)\n     }\n \n     fn alloc_node(\n@@ -1037,19 +1053,19 @@ impl CurrentDepGraph {\n         fingerprint: Fingerprint\n     ) -> DepNodeIndex {\n         debug_assert!(!self.node_to_node_index.contains_key(&dep_node));\n-        self.intern_node(dep_node, edges, fingerprint).0\n+        self.intern_node(dep_node, edges, fingerprint)\n     }\n \n     fn intern_node(\n         &mut self,\n         dep_node: DepNode,\n         edges: SmallVec<[DepNodeIndex; 8]>,\n         fingerprint: Fingerprint\n-    ) -> (DepNodeIndex, bool) {\n+    ) -> DepNodeIndex {\n         debug_assert_eq!(self.node_to_node_index.len(), self.data.len());\n \n         match self.node_to_node_index.entry(dep_node) {\n-            Entry::Occupied(entry) => (*entry.get(), false),\n+            Entry::Occupied(entry) => *entry.get(),\n             Entry::Vacant(entry) => {\n                 let dep_node_index = DepNodeIndex::new(self.data.len());\n                 self.data.push(DepNodeData {\n@@ -1058,7 +1074,7 @@ impl CurrentDepGraph {\n                     fingerprint\n                 });\n                 entry.insert(dep_node_index);\n-                (dep_node_index, true)\n+                dep_node_index\n             }\n         }\n     }"}]}