{"sha": "0c6cc11e05de145641a610c342b75c2f9f01ce6d", "node_id": "MDY6Q29tbWl0NzI0NzEyOjBjNmNjMTFlMDVkZTE0NTY0MWE2MTBjMzQyYjc1YzJmOWYwMWNlNmQ=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-08-21T18:01:44Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2013-08-21T18:01:44Z"}, "message": "auto merge of #8445 : Florob/rust/unicode, r=graydon\n\nThis adds support for performing Unicode Normalization Forms D and KD on strings.\r\nTo enable this the decomposition and canonical combining class properties are added to std::unicode.\r\nOn my system this increases libstd's size by ~250KiB.", "tree": {"sha": "748cd34da5ef3f99d9be723b14465c430641c8ba", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/748cd34da5ef3f99d9be723b14465c430641c8ba"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/0c6cc11e05de145641a610c342b75c2f9f01ce6d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/0c6cc11e05de145641a610c342b75c2f9f01ce6d", "html_url": "https://github.com/rust-lang/rust/commit/0c6cc11e05de145641a610c342b75c2f9f01ce6d", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/0c6cc11e05de145641a610c342b75c2f9f01ce6d/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e66478193b1ad0582cdabb5ca769a85b26ea000c", "url": "https://api.github.com/repos/rust-lang/rust/commits/e66478193b1ad0582cdabb5ca769a85b26ea000c", "html_url": "https://github.com/rust-lang/rust/commit/e66478193b1ad0582cdabb5ca769a85b26ea000c"}, {"sha": "3d720c6c09aff77068caaad8668834878132c7ae", "url": "https://api.github.com/repos/rust-lang/rust/commits/3d720c6c09aff77068caaad8668834878132c7ae", "html_url": "https://github.com/rust-lang/rust/commit/3d720c6c09aff77068caaad8668834878132c7ae"}], "stats": {"total": 2590, "additions": 2556, "deletions": 34}, "files": [{"sha": "0f6e1c4c606218ac61869c36ed04d19728a6e895", "filename": "src/etc/unicode.py", "status": "modified", "additions": 150, "deletions": 33, "changes": 183, "blob_url": "https://github.com/rust-lang/rust/blob/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Fetc%2Funicode.py", "raw_url": "https://github.com/rust-lang/rust/raw/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Fetc%2Funicode.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Funicode.py?ref=0c6cc11e05de145641a610c342b75c2f9f01ce6d", "patch": "@@ -26,11 +26,15 @@ def fetch(f):\n def load_unicode_data(f):\n     fetch(f)\n     gencats = {}\n+    combines = []\n     canon_decomp = {}\n     compat_decomp = {}\n     curr_cat = \"\"\n+    curr_combine = \"\"\n     c_lo = 0\n     c_hi = 0\n+    com_lo = 0\n+    com_hi = 0\n     for line in fileinput.input(f):\n         fields = line.split(\";\")\n         if len(fields) != 15:\n@@ -69,7 +73,21 @@ def load_unicode_data(f):\n             c_lo = code\n             c_hi = code\n \n-    return (canon_decomp, compat_decomp, gencats)\n+        if curr_combine == \"\":\n+            curr_combine = combine\n+            com_lo = code\n+            com_hi = code\n+\n+        if curr_combine == combine:\n+            com_hi = code\n+        else:\n+            if curr_combine != \"0\":\n+                combines.append((com_lo, com_hi, curr_combine))\n+            curr_combine = combine\n+            com_lo = code\n+            com_hi = code\n+\n+    return (canon_decomp, compat_decomp, gencats, combines)\n \n \n def load_derived_core_properties(f):\n@@ -178,50 +196,149 @@ def emit_property_module_old(f, mod, tbl):\n         f.write(\"    }\\n\\n\")\n     f.write(\"}\\n\")\n \n-def emit_decomp_module(f, canon, compat):\n+def format_table_content(f, content, indent):\n+    line = \" \"*indent\n+    first = True\n+    for chunk in content.split(\",\"):\n+        if len(line) + len(chunk) < 98:\n+            if first:\n+                line += chunk\n+            else:\n+                line += \", \" + chunk\n+            first = False\n+        else:\n+            f.write(line + \",\\n\")\n+            line = \" \"*indent + chunk\n+    f.write(line)\n+\n+def emit_decomp_module(f, canon, compat, combine):\n     canon_keys = canon.keys()\n     canon_keys.sort()\n \n     compat_keys = compat.keys()\n     compat_keys.sort()\n-    f.write(\"mod decompose {\\n\\n\");\n-    f.write(\"    export canonical, compatibility;\\n\\n\")\n-    f.write(\"    fn canonical(c: char, i: block(char)) \"\n-            + \"{ d(c, i, false); }\\n\\n\")\n-    f.write(\"    fn compatibility(c: char, i: block(char)) \"\n-            +\"{ d(c, i, true); }\\n\\n\")\n-    f.write(\"    fn d(c: char, i: block(char), k: bool) {\\n\")\n+    f.write(\"pub mod decompose {\\n\");\n+    f.write(\"    use option::Option;\\n\");\n+    f.write(\"    use option::{Some, None};\\n\");\n+    f.write(\"    use vec::ImmutableVector;\\n\");\n+    f.write(\"\"\"\n+    fn bsearch_table(c: char, r: &'static [(char, &'static [char])]) -> Option<&'static [char]> {\n+        use cmp::{Equal, Less, Greater};\n+        match r.bsearch(|&(val, _)| {\n+            if c == val { Equal }\n+            else if val < c { Less }\n+            else { Greater }\n+        }) {\n+            Some(idx) => {\n+                let (_, result) = r[idx];\n+                Some(result)\n+            }\n+            None => None\n+        }\n+    }\\n\n+\"\"\")\n \n-    f.write(\"        if c <= '\\\\x7f' { i(c); ret; }\\n\")\n+    f.write(\"\"\"\n+    fn bsearch_range_value_table(c: char, r: &'static [(char, char, u8)]) -> u8 {\n+        use cmp::{Equal, Less, Greater};\n+        match r.bsearch(|&(lo, hi, _)| {\n+            if lo <= c && c <= hi { Equal }\n+            else if hi < c { Less }\n+            else { Greater }\n+        }) {\n+            Some(idx) => {\n+                let (_, _, result) = r[idx];\n+                result\n+            }\n+            None => 0\n+        }\n+    }\\n\\n\n+\"\"\")\n \n-    # First check the canonical decompositions\n-    f.write(\"        // Canonical decomposition\\n\")\n-    f.write(\"        alt c {\\n\")\n+    f.write(\"    // Canonical decompositions\\n\")\n+    f.write(\"    static canonical_table : &'static [(char, &'static [char])] = &[\\n\")\n+    data = \"\"\n+    first = True\n     for char in canon_keys:\n-        f.write(\"          %s {\\n\" % escape_char(char))\n+        if not first:\n+            data += \",\"\n+        first = False\n+        data += \"(%s,&[\" % escape_char(char)\n+        first2 = True\n         for d in canon[char]:\n-            f.write(\"            d(%s, i, k);\\n\"\n-                    % escape_char(d))\n-        f.write(\"          }\\n\")\n+            if not first2:\n+                data += \",\"\n+            first2 = False\n+            data += escape_char(d)\n+        data += \"])\"\n+    format_table_content(f, data, 8)\n+    f.write(\"\\n    ];\\n\\n\")\n+\n+    f.write(\"    // Compatibility decompositions\\n\")\n+    f.write(\"    static compatibility_table : &'static [(char, &'static [char])] = &[\\n\")\n+    data = \"\"\n+    first = True\n+    for char in compat_keys:\n+        if not first:\n+            data += \",\"\n+        first = False\n+        data += \"(%s,&[\" % escape_char(char)\n+        first2 = True\n+        for d in compat[char]:\n+            if not first2:\n+                data += \",\"\n+            first2 = False\n+            data += escape_char(d)\n+        data += \"])\"\n+    format_table_content(f, data, 8)\n+    f.write(\"\\n    ];\\n\\n\")\n+\n+    f.write(\"    static combining_class_table : &'static [(char, char, u8)] = &[\\n\")\n+    ix = 0\n+    for pair in combine:\n+        f.write(ch_prefix(ix))\n+        f.write(\"(%s, %s, %s)\" % (escape_char(pair[0]), escape_char(pair[1]), pair[2]))\n+        ix += 1\n+    f.write(\"\\n    ];\\n\")\n+\n+    f.write(\"    pub fn canonical(c: char, i: &fn(char)) \"\n+        + \"{ d(c, i, false); }\\n\\n\")\n+    f.write(\"    pub fn compatibility(c: char, i: &fn(char)) \"\n+            +\"{ d(c, i, true); }\\n\\n\")\n+    f.write(\"    pub fn canonical_combining_class(c: char) -> u8 {\\n\"\n+        + \"        bsearch_range_value_table(c, combining_class_table)\\n\"\n+        + \"    }\\n\\n\")\n+    f.write(\"    fn d(c: char, i: &fn(char), k: bool) {\\n\")\n+    f.write(\"        use iterator::Iterator;\\n\");\n \n-    f.write(\"          _ { }\\n\")\n-    f.write(\"        }\\n\\n\")\n+    f.write(\"        if c <= '\\\\x7f' { i(c); return; }\\n\")\n+\n+    # First check the canonical decompositions\n+    f.write(\"\"\"\n+        match bsearch_table(c, canonical_table) {\n+            Some(canon) => {\n+                for x in canon.iter() {\n+                    d(*x, |b| i(b), k);\n+                }\n+                return;\n+            }\n+            None => ()\n+        }\\n\\n\"\"\")\n \n     # Bottom out if we're not doing compat.\n-    f.write(\"        if !k { i(c); ret; }\\n\\n \")\n+    f.write(\"        if !k { i(c); return; }\\n\")\n \n     # Then check the compatibility decompositions\n-    f.write(\"        // Compatibility decomposition\\n\")\n-    f.write(\"        alt c {\\n\")\n-    for char in compat_keys:\n-        f.write(\"          %s {\\n\" % escape_char(char))\n-        for d in compat[char]:\n-            f.write(\"            d(%s, i, k);\\n\"\n-                    % escape_char(d))\n-        f.write(\"          }\\n\")\n-\n-    f.write(\"          _ { }\\n\")\n-    f.write(\"        }\\n\\n\")\n+    f.write(\"\"\"\n+        match bsearch_table(c, compatibility_table) {\n+            Some(compat) => {\n+                for x in compat.iter() {\n+                    d(*x, |b| i(b), k);\n+                }\n+                return;\n+            }\n+            None => ()\n+        }\\n\\n\"\"\")\n \n     # Finally bottom out.\n     f.write(\"        i(c);\\n\")\n@@ -234,7 +351,7 @@ def emit_decomp_module(f, canon, compat):\n         os.remove(i);\n rf = open(r, \"w\")\n \n-(canon_decomp, compat_decomp, gencats) = load_unicode_data(\"UnicodeData.txt\")\n+(canon_decomp, compat_decomp, gencats, combines) = load_unicode_data(\"UnicodeData.txt\")\n \n # Preamble\n rf.write('''// Copyright 2012-2013 The Rust Project Developers. See the COPYRIGHT\n@@ -256,7 +373,7 @@ def emit_decomp_module(f, canon, compat):\n \n emit_property_module(rf, \"general_category\", gencats)\n \n-#emit_decomp_module(rf, canon_decomp, compat_decomp)\n+emit_decomp_module(rf, canon_decomp, compat_decomp, combines)\n \n derived = load_derived_core_properties(\"DerivedCoreProperties.txt\")\n emit_property_module(rf, \"derived_property\", derived)"}, {"sha": "e2612e0e09b46370c47b1bea5c4a917bc38c1fb6", "filename": "src/libstd/char.rs", "status": "modified", "additions": 46, "deletions": 1, "changes": 47, "blob_url": "https://github.com/rust-lang/rust/blob/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Fchar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Fchar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fchar.rs?ref=0c6cc11e05de145641a610c342b75c2f9f01ce6d", "patch": "@@ -13,7 +13,7 @@\n use option::{None, Option, Some};\n use int;\n use str::StrSlice;\n-use unicode::{derived_property, general_category};\n+use unicode::{derived_property, general_category, decompose};\n \n #[cfg(test)] use str::OwnedStr;\n \n@@ -202,6 +202,51 @@ pub fn from_digit(num: uint, radix: uint) -> Option<char> {\n     }\n }\n \n+// Constants from Unicode 6.2.0 Section 3.12 Conjoining Jamo Behavior\n+static S_BASE: uint = 0xAC00;\n+static L_BASE: uint = 0x1100;\n+static V_BASE: uint = 0x1161;\n+static T_BASE: uint = 0x11A7;\n+static L_COUNT: uint = 19;\n+static V_COUNT: uint = 21;\n+static T_COUNT: uint = 28;\n+static N_COUNT: uint = (V_COUNT * T_COUNT);\n+static S_COUNT: uint = (L_COUNT * N_COUNT);\n+\n+// Decompose a precomposed Hangul syllable\n+fn decompose_hangul(s: char, f: &fn(char)) {\n+    let si = s as uint - S_BASE;\n+\n+    let li = si / N_COUNT;\n+    f((L_BASE + li) as char);\n+\n+    let vi = (si % N_COUNT) / T_COUNT;\n+    f((V_BASE + vi) as char);\n+\n+    let ti = si % T_COUNT;\n+    if ti > 0 {\n+        f((T_BASE + ti) as char);\n+    }\n+}\n+\n+/// Returns the canonical decompostion of a character\n+pub fn decompose_canonical(c: char, f: &fn(char)) {\n+    if (c as uint) < S_BASE || (c as uint) >= (S_BASE + S_COUNT) {\n+        decompose::canonical(c, f);\n+    } else {\n+        decompose_hangul(c, f);\n+    }\n+}\n+\n+/// Returns the compatibility decompostion of a character\n+pub fn decompose_compatible(c: char, f: &fn(char)) {\n+    if (c as uint) < S_BASE || (c as uint) >= (S_BASE + S_COUNT) {\n+        decompose::compatibility(c, f);\n+    } else {\n+        decompose_hangul(c, f);\n+    }\n+}\n+\n ///\n /// Return the hexadecimal unicode escape of a char.\n ///"}, {"sha": "0dd84fd3443463b40bb4532cd0efbf78c0d4dbf9", "filename": "src/libstd/str.rs", "status": "modified", "additions": 143, "deletions": 0, "changes": 143, "blob_url": "https://github.com/rust-lang/rust/blob/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Fstr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Fstr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Fstr.rs?ref=0c6cc11e05de145641a610c342b75c2f9f01ce6d", "patch": "@@ -450,6 +450,97 @@ impl<'self> Iterator<&'self str> for StrSplitIterator<'self> {\n     }\n }\n \n+// Helper functions used for Unicode normalization\n+fn canonical_sort(comb: &mut [(char, u8)]) {\n+    use iterator::range;\n+    use tuple::CopyableTuple;\n+\n+    let len = comb.len();\n+    for i in range(0, len) {\n+        let mut swapped = false;\n+        for j in range(1, len-i) {\n+            let classA = comb[j-1].second();\n+            let classB = comb[j].second();\n+            if classA != 0 && classB != 0 && classA > classB {\n+                comb.swap(j-1, j);\n+                swapped = true;\n+            }\n+        }\n+        if !swapped { break; }\n+    }\n+}\n+\n+#[deriving(Clone)]\n+enum NormalizationForm {\n+    NFD,\n+    NFKD\n+}\n+\n+/// External iterator for a string's normalization's characters.\n+/// Use with the `std::iterator` module.\n+#[deriving(Clone)]\n+struct NormalizationIterator<'self> {\n+    priv kind: NormalizationForm,\n+    priv index: uint,\n+    priv string: &'self str,\n+    priv buffer: ~[(char, u8)],\n+    priv sorted: bool\n+}\n+\n+impl<'self> Iterator<char> for NormalizationIterator<'self> {\n+    #[inline]\n+    fn next(&mut self) -> Option<char> {\n+        use unicode::decompose::canonical_combining_class;\n+\n+        match self.buffer.head_opt() {\n+            Some(&(c, 0)) => {\n+                self.sorted = false;\n+                self.buffer.shift();\n+                return Some(c);\n+            }\n+            Some(&(c, _)) if self.sorted => {\n+                self.buffer.shift();\n+                return Some(c);\n+            }\n+            _ => self.sorted = false\n+        }\n+\n+        let decomposer = match self.kind {\n+            NFD => char::decompose_canonical,\n+            NFKD => char::decompose_compatible\n+        };\n+\n+        while !self.sorted && self.index < self.string.len() {\n+            let CharRange {ch, next} = self.string.char_range_at(self.index);\n+            self.index = next;\n+            do decomposer(ch) |d| {\n+                let class = canonical_combining_class(d);\n+                if class == 0 && !self.sorted {\n+                    canonical_sort(self.buffer);\n+                    self.sorted = true;\n+                }\n+                self.buffer.push((d, class));\n+            }\n+        }\n+\n+        if !self.sorted {\n+            canonical_sort(self.buffer);\n+            self.sorted = true;\n+        }\n+\n+        match self.buffer.shift_opt() {\n+            Some((c, 0)) => {\n+                self.sorted = false;\n+                Some(c)\n+            }\n+            Some((c, _)) => Some(c),\n+            None => None\n+        }\n+    }\n+\n+    fn size_hint(&self) -> (uint, Option<uint>) { (self.string.len(), None) }\n+}\n+\n /// Replace all occurrences of one string with another\n ///\n /// # Arguments\n@@ -1128,6 +1219,8 @@ pub trait StrSlice<'self> {\n     fn line_iter(&self) -> CharSplitIterator<'self, char>;\n     fn any_line_iter(&self) -> AnyLineIterator<'self>;\n     fn word_iter(&self) -> WordIterator<'self>;\n+    fn nfd_iter(&self) -> NormalizationIterator<'self>;\n+    fn nfkd_iter(&self) -> NormalizationIterator<'self>;\n     fn ends_with(&self, needle: &str) -> bool;\n     fn is_whitespace(&self) -> bool;\n     fn is_alphanumeric(&self) -> bool;\n@@ -1343,6 +1436,28 @@ impl<'self> StrSlice<'self> for &'self str {\n         self.split_iter(char::is_whitespace).filter(|s| !s.is_empty())\n     }\n \n+    /// Returns the string in Unicode Normalization Form D (canonical decomposition)\n+    fn nfd_iter(&self) -> NormalizationIterator<'self> {\n+        NormalizationIterator {\n+            index: 0,\n+            string: *self,\n+            buffer: ~[],\n+            sorted: false,\n+            kind: NFD\n+        }\n+    }\n+\n+    /// Returns the string in Unicode Normalization Form KD (compatibility decomposition)\n+    fn nfkd_iter(&self) -> NormalizationIterator<'self> {\n+        NormalizationIterator {\n+            index: 0,\n+            string: *self,\n+            buffer: ~[],\n+            sorted: false,\n+            kind: NFKD\n+        }\n+    }\n+\n     /// Returns true if the string contains only whitespace\n     ///\n     /// Whitespace characters are determined by `char::is_whitespace`\n@@ -3217,6 +3332,34 @@ mod tests {\n         assert_eq!(words, ~[\"M\u00e4ry\", \"h\u00e4d\", \"\u00e4\", \"little\", \"l\u00e4mb\", \"Little\", \"l\u00e4mb\"])\n     }\n \n+    #[test]\n+    fn test_nfd_iter() {\n+        assert_eq!(\"abc\".nfd_iter().collect::<~str>(), ~\"abc\");\n+        assert_eq!(\"\\u1e0b\\u01c4\".nfd_iter().collect::<~str>(), ~\"d\\u0307\\u01c4\");\n+        assert_eq!(\"\\u2026\".nfd_iter().collect::<~str>(), ~\"\\u2026\");\n+        assert_eq!(\"\\u2126\".nfd_iter().collect::<~str>(), ~\"\\u03a9\");\n+        assert_eq!(\"\\u1e0b\\u0323\".nfd_iter().collect::<~str>(), ~\"d\\u0323\\u0307\");\n+        assert_eq!(\"\\u1e0d\\u0307\".nfd_iter().collect::<~str>(), ~\"d\\u0323\\u0307\");\n+        assert_eq!(\"a\\u0301\".nfd_iter().collect::<~str>(), ~\"a\\u0301\");\n+        assert_eq!(\"\\u0301a\".nfd_iter().collect::<~str>(), ~\"\\u0301a\");\n+        assert_eq!(\"\\ud4db\".nfd_iter().collect::<~str>(), ~\"\\u1111\\u1171\\u11b6\");\n+        assert_eq!(\"\\uac1c\".nfd_iter().collect::<~str>(), ~\"\\u1100\\u1162\");\n+    }\n+\n+    #[test]\n+    fn test_nfkd_iter() {\n+        assert_eq!(\"abc\".nfkd_iter().collect::<~str>(), ~\"abc\");\n+        assert_eq!(\"\\u1e0b\\u01c4\".nfkd_iter().collect::<~str>(), ~\"d\\u0307DZ\\u030c\");\n+        assert_eq!(\"\\u2026\".nfkd_iter().collect::<~str>(), ~\"...\");\n+        assert_eq!(\"\\u2126\".nfkd_iter().collect::<~str>(), ~\"\\u03a9\");\n+        assert_eq!(\"\\u1e0b\\u0323\".nfkd_iter().collect::<~str>(), ~\"d\\u0323\\u0307\");\n+        assert_eq!(\"\\u1e0d\\u0307\".nfkd_iter().collect::<~str>(), ~\"d\\u0323\\u0307\");\n+        assert_eq!(\"a\\u0301\".nfkd_iter().collect::<~str>(), ~\"a\\u0301\");\n+        assert_eq!(\"\\u0301a\".nfkd_iter().collect::<~str>(), ~\"\\u0301a\");\n+        assert_eq!(\"\\ud4db\".nfkd_iter().collect::<~str>(), ~\"\\u1111\\u1171\\u11b6\");\n+        assert_eq!(\"\\uac1c\".nfkd_iter().collect::<~str>(), ~\"\\u1100\\u1162\");\n+    }\n+\n     #[test]\n     fn test_line_iter() {\n         let data = \"\\nM\u00e4ry h\u00e4d \u00e4 little l\u00e4mb\\n\\nLittle l\u00e4mb\\n\";"}, {"sha": "6d763b58cd125db1073a2e15f25a4d19f3971c54", "filename": "src/libstd/unicode.rs", "status": "modified", "additions": 2217, "deletions": 0, "changes": 2217, "blob_url": "https://github.com/rust-lang/rust/blob/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Funicode.rs", "raw_url": "https://github.com/rust-lang/rust/raw/0c6cc11e05de145641a610c342b75c2f9f01ce6d/src%2Flibstd%2Funicode.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibstd%2Funicode.rs?ref=0c6cc11e05de145641a610c342b75c2f9f01ce6d"}]}