{"sha": "9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "node_id": "MDY6Q29tbWl0NzI0NzEyOjllMjEzMzg1YzlkMDZkYjNjOGNhMjA4MTI3NzllMmI4ZjhhZDJjNzE=", "commit": {"author": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-03-30T10:25:53Z"}, "committer": {"name": "Aleksey Kladov", "email": "aleksey.kladov@gmail.com", "date": "2019-04-01T09:06:24Z"}, "message": "switch to new rowan", "tree": {"sha": "fe57697b54ccfb791fe96c13cb553a8570516270", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/fe57697b54ccfb791fe96c13cb553a8570516270"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "html_url": "https://github.com/rust-lang/rust/commit/9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/comments", "author": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "committer": {"login": "matklad", "id": 1711539, "node_id": "MDQ6VXNlcjE3MTE1Mzk=", "avatar_url": "https://avatars.githubusercontent.com/u/1711539?v=4", "gravatar_id": "", "url": "https://api.github.com/users/matklad", "html_url": "https://github.com/matklad", "followers_url": "https://api.github.com/users/matklad/followers", "following_url": "https://api.github.com/users/matklad/following{/other_user}", "gists_url": "https://api.github.com/users/matklad/gists{/gist_id}", "starred_url": "https://api.github.com/users/matklad/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/matklad/subscriptions", "organizations_url": "https://api.github.com/users/matklad/orgs", "repos_url": "https://api.github.com/users/matklad/repos", "events_url": "https://api.github.com/users/matklad/events{/privacy}", "received_events_url": "https://api.github.com/users/matklad/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "dec9bde10868b5e459535449476d17a6a0987b3e", "url": "https://api.github.com/repos/rust-lang/rust/commits/dec9bde10868b5e459535449476d17a6a0987b3e", "html_url": "https://github.com/rust-lang/rust/commit/dec9bde10868b5e459535449476d17a6a0987b3e"}], "stats": {"total": 2255, "additions": 1027, "deletions": 1228}, "files": [{"sha": "ddd508b0ad702ed3aecf4b365858127b13ad2f69", "filename": "Cargo.lock", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/Cargo.lock", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/Cargo.lock", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/Cargo.lock?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1077,8 +1077,8 @@ dependencies = [\n  \"parking_lot 0.7.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"ra_parser 0.1.0\",\n  \"ra_text_edit 0.1.0\",\n- \"rowan 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"smol_str 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"rowan 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"smol_str 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"test_utils 0.1.0\",\n  \"text_unit 0.1.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"unicode-xid 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n@@ -1098,7 +1098,7 @@ dependencies = [\n name = \"ra_tt\"\n version = \"0.1.0\"\n dependencies = [\n- \"smol_str 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"smol_str 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n [[package]]\n@@ -1298,12 +1298,12 @@ dependencies = [\n \n [[package]]\n name = \"rowan\"\n-version = \"0.3.3\"\n+version = \"0.4.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n dependencies = [\n  \"colosseum 0.2.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"parking_lot 0.7.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n- \"smol_str 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n+ \"smol_str 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\",\n  \"text_unit 0.1.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n ]\n \n@@ -1456,7 +1456,7 @@ source = \"registry+https://github.com/rust-lang/crates.io-index\"\n \n [[package]]\n name = \"smol_str\"\n-version = \"0.1.9\"\n+version = \"0.1.10\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n dependencies = [\n  \"serde 1.0.89 (registry+https://github.com/rust-lang/crates.io-index)\",\n@@ -1964,7 +1964,7 @@ dependencies = [\n \"checksum relative-path 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"0e7790c7f1cc73d831d28dc5a7deb316a006e7848e6a7f467cdb10a0a9e0fb1c\"\n \"checksum remove_dir_all 0.5.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"3488ba1b9a2084d38645c4c08276a1752dcbf2c7130d74f1569681ad5d2799c5\"\n \"checksum ron 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"17f52a24414403f81528b67488cf8edc4eda977d3af1646bb6b106a600ead78f\"\n-\"checksum rowan 0.3.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"74d41f779e2c893339e34bebf035652c58214823cd412550111886c06632f89d\"\n+\"checksum rowan 0.4.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"397cd19c109641f10f3c66433440285e232d8cbd37406cf8f944a15ab1e63a8e\"\n \"checksum rustc-demangle 0.1.13 (registry+https://github.com/rust-lang/crates.io-index)\" = \"adacaae16d02b6ec37fdc7acfcddf365978de76d1983d3ee22afc260e1ca9619\"\n \"checksum rustc-hash 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"7540fc8b0c49f096ee9c961cda096467dce8084bec6bdca2fc83895fd9b28cb8\"\n \"checksum rustc_version 0.2.3 (registry+https://github.com/rust-lang/crates.io-index)\" = \"138e3e0acb6c9fb258b19b67cb8abd63c00679d2851805ea151465464fe9030a\"\n@@ -1983,7 +1983,7 @@ dependencies = [\n \"checksum slab 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\" = \"c111b5bd5695e56cffe5129854aa230b39c93a305372fdbb2668ca2394eea9f8\"\n \"checksum slug 0.1.4 (registry+https://github.com/rust-lang/crates.io-index)\" = \"b3bc762e6a4b6c6fcaade73e77f9ebc6991b676f88bb2358bddb56560f073373\"\n \"checksum smallvec 0.6.9 (registry+https://github.com/rust-lang/crates.io-index)\" = \"c4488ae950c49d403731982257768f48fada354a5203fe81f9bb6f43ca9002be\"\n-\"checksum smol_str 0.1.9 (registry+https://github.com/rust-lang/crates.io-index)\" = \"9af1035bc5d742ab6b7ab16713e41cc2ffe78cb474f6f43cd696b2d16052007e\"\n+\"checksum smol_str 0.1.10 (registry+https://github.com/rust-lang/crates.io-index)\" = \"d077b3367211e9c6e2e012fb804c444e0d80ab5a51ae4137739b58e6446dcaef\"\n \"checksum stable_deref_trait 1.1.1 (registry+https://github.com/rust-lang/crates.io-index)\" = \"dba1a27d3efae4351c8051072d619e3ade2820635c3958d826bfea39d59b54c8\"\n \"checksum strsim 0.7.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"bb4f380125926a99e52bc279241539c018323fab05ad6368b56f93d9369ff550\"\n \"checksum superslice 1.0.0 (registry+https://github.com/rust-lang/crates.io-index)\" = \"ab16ced94dbd8a46c82fd81e3ed9a8727dac2977ea869d217bcc4ea1f122e81f\""}, {"sha": "0c4cf261507dfe36db2cdc46687b8b0ec270a32b", "filename": "crates/ra_assists/src/add_derive.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_derive.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_derive.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fadd_derive.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -33,8 +33,10 @@ pub(crate) fn add_derive(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist>\n \n // Insert `derive` after doc comments.\n fn derive_insertion_offset(nominal: &ast::NominalDef) -> Option<TextUnit> {\n-    let non_ws_child =\n-        nominal.syntax().children().find(|it| it.kind() != COMMENT && it.kind() != WHITESPACE)?;\n+    let non_ws_child = nominal\n+        .syntax()\n+        .children_with_tokens()\n+        .find(|it| it.kind() != COMMENT && it.kind() != WHITESPACE)?;\n     Some(non_ws_child.range().start())\n }\n "}, {"sha": "fa1c85890642b1c08f43bf7563d7692f49aaf550", "filename": "crates/ra_assists/src/add_impl.rs", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_impl.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_impl.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fadd_impl.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,7 +1,7 @@\n use join_to_string::join;\n use hir::db::HirDatabase;\n use ra_syntax::{\n-    ast::{self, AstNode, AstToken, NameOwner, TypeParamsOwner},\n+    ast::{self, AstNode, NameOwner, TypeParamsOwner},\n     TextUnit,\n };\n \n@@ -22,8 +22,10 @@ pub(crate) fn add_impl(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n         buf.push_str(\" \");\n         buf.push_str(name.text().as_str());\n         if let Some(type_params) = type_params {\n-            let lifetime_params =\n-                type_params.lifetime_params().filter_map(|it| it.lifetime()).map(|it| it.text());\n+            let lifetime_params = type_params\n+                .lifetime_params()\n+                .filter_map(|it| it.lifetime_token())\n+                .map(|it| it.text());\n             let type_params =\n                 type_params.type_params().filter_map(|it| it.name()).map(|it| it.text());\n             join(lifetime_params.chain(type_params)).surround_with(\"<\", \">\").to_buf(&mut buf);"}, {"sha": "5b01e898e961341bbee2d45c0bd675779af543bd", "filename": "crates/ra_assists/src/add_missing_impl_members.rs", "status": "modified", "additions": 8, "deletions": 5, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_missing_impl_members.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fadd_missing_impl_members.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fadd_missing_impl_members.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,3 +1,5 @@\n+use std::fmt::Write;\n+\n use crate::{Assist, AssistId, AssistCtx};\n \n use hir::Resolver;\n@@ -91,8 +93,9 @@ fn add_missing_impl_members_inner(\n         };\n \n         let changed_range = {\n-            let children = impl_item_list.syntax().children();\n-            let last_whitespace = children.filter_map(ast::Whitespace::cast).last();\n+            let children = impl_item_list.syntax().children_with_tokens();\n+            let last_whitespace =\n+                children.filter_map(|it| ast::Whitespace::cast(it.as_token()?)).last();\n \n             last_whitespace.map(|w| w.syntax().range()).unwrap_or_else(|| {\n                 let in_brackets = impl_item_list.syntax().range().end() - TextUnit::of_str(\"}\");\n@@ -134,13 +137,13 @@ fn resolve_target_trait_def(\n fn build_func_body(def: &ast::FnDef) -> String {\n     let mut buf = String::new();\n \n-    for child in def.syntax().children() {\n-        match (child.prev_sibling().map(|c| c.kind()), child.kind()) {\n+    for child in def.syntax().children_with_tokens() {\n+        match (child.prev_sibling_or_token().map(|c| c.kind()), child.kind()) {\n             (_, SyntaxKind::SEMI) => buf.push_str(\" { unimplemented!() }\"),\n             (_, SyntaxKind::ATTR) | (_, SyntaxKind::COMMENT) => {}\n             (Some(SyntaxKind::ATTR), SyntaxKind::WHITESPACE)\n             | (Some(SyntaxKind::COMMENT), SyntaxKind::WHITESPACE) => {}\n-            _ => child.text().push_to(&mut buf),\n+            _ => write!(buf, \"{}\", child).unwrap(),\n         };\n     }\n "}, {"sha": "bb5742bd98b620d7758d491d186be7f7389b9e58", "filename": "crates/ra_assists/src/assist_ctx.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fassist_ctx.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -2,8 +2,8 @@ use hir::db::HirDatabase;\n use ra_text_edit::TextEditBuilder;\n use ra_db::FileRange;\n use ra_syntax::{\n-    SourceFile, TextRange, AstNode, TextUnit, SyntaxNode,\n-    algo::{find_leaf_at_offset, find_node_at_offset, find_covering_node, LeafAtOffset},\n+    SourceFile, TextRange, AstNode, TextUnit, SyntaxNode, SyntaxElement, SyntaxToken,\n+    algo::{find_token_at_offset, find_node_at_offset, find_covering_element, TokenAtOffset},\n };\n use ra_fmt::{leading_indent, reindent};\n \n@@ -104,15 +104,15 @@ impl<'a, DB: HirDatabase> AssistCtx<'a, DB> {\n         Some(self.assist)\n     }\n \n-    pub(crate) fn leaf_at_offset(&self) -> LeafAtOffset<&'a SyntaxNode> {\n-        find_leaf_at_offset(self.source_file.syntax(), self.frange.range.start())\n+    pub(crate) fn token_at_offset(&self) -> TokenAtOffset<SyntaxToken<'a>> {\n+        find_token_at_offset(self.source_file.syntax(), self.frange.range.start())\n     }\n \n     pub(crate) fn node_at_offset<N: AstNode>(&self) -> Option<&'a N> {\n         find_node_at_offset(self.source_file.syntax(), self.frange.range.start())\n     }\n-    pub(crate) fn covering_node(&self) -> &'a SyntaxNode {\n-        find_covering_node(self.source_file.syntax(), self.frange.range)\n+    pub(crate) fn covering_element(&self) -> SyntaxElement<'a> {\n+        find_covering_element(self.source_file.syntax(), self.frange.range)\n     }\n }\n "}, {"sha": "3fdf6b0d9a26c7648d548c8cfd3905df28b96857", "filename": "crates/ra_assists/src/auto_import.rs", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fauto_import.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fauto_import.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fauto_import.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -21,19 +21,19 @@ fn collect_path_segments_raw<'a>(\n ) -> Option<usize> {\n     let oldlen = segments.len();\n     loop {\n-        let mut children = path.syntax().children();\n+        let mut children = path.syntax().children_with_tokens();\n         let (first, second, third) = (\n             children.next().map(|n| (n, n.kind())),\n             children.next().map(|n| (n, n.kind())),\n             children.next().map(|n| (n, n.kind())),\n         );\n         match (first, second, third) {\n             (Some((subpath, PATH)), Some((_, COLONCOLON)), Some((segment, PATH_SEGMENT))) => {\n-                path = ast::Path::cast(subpath)?;\n-                segments.push(ast::PathSegment::cast(segment)?);\n+                path = ast::Path::cast(subpath.as_node()?)?;\n+                segments.push(ast::PathSegment::cast(segment.as_node()?)?);\n             }\n             (Some((segment, PATH_SEGMENT)), _, _) => {\n-                segments.push(ast::PathSegment::cast(segment)?);\n+                segments.push(ast::PathSegment::cast(segment.as_node()?)?);\n                 break;\n             }\n             (_, _, _) => return None,\n@@ -514,8 +514,7 @@ fn apply_auto_import<'a>(\n }\n \n pub(crate) fn auto_import(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n-    let node = ctx.covering_node();\n-    let path = node.ancestors().find_map(ast::Path::cast)?;\n+    let path: &ast::Path = ctx.node_at_offset()?;\n     // We don't want to mess with use statements\n     if path.syntax().ancestors().find_map(ast::UseItem::cast).is_some() {\n         return None;\n@@ -537,7 +536,7 @@ pub(crate) fn auto_import(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist\n             );\n         }\n     } else {\n-        let current_file = node.ancestors().find_map(ast::SourceFile::cast)?;\n+        let current_file = path.syntax().ancestors().find_map(ast::SourceFile::cast)?;\n         ctx.add_action(\n             AssistId(\"auto_import\"),\n             format!(\"import {} in the current file\", fmt_segments(&segments)),"}, {"sha": "c63470726a9680198f17e8de42bb0e376f5667c2", "filename": "crates/ra_assists/src/change_visibility.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fchange_visibility.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fchange_visibility.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fchange_visibility.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -15,13 +15,13 @@ pub(crate) fn change_visibility(ctx: AssistCtx<impl HirDatabase>) -> Option<Assi\n }\n \n fn add_vis(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n-    let item_keyword = ctx.leaf_at_offset().find(|leaf| match leaf.kind() {\n+    let item_keyword = ctx.token_at_offset().find(|leaf| match leaf.kind() {\n         FN_KW | MOD_KW | STRUCT_KW | ENUM_KW | TRAIT_KW => true,\n         _ => false,\n     });\n \n     let (offset, target) = if let Some(keyword) = item_keyword {\n-        let parent = keyword.parent()?;\n+        let parent = keyword.parent();\n         let def_kws = vec![FN_DEF, MODULE, STRUCT_DEF, ENUM_DEF, TRAIT_DEF];\n         // Parent is not a definition, can't add visibility\n         if !def_kws.iter().any(|&def_kw| def_kw == parent.kind()) {\n@@ -33,8 +33,8 @@ fn add_vis(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n         }\n         (vis_offset(parent), keyword.range())\n     } else {\n-        let ident = ctx.leaf_at_offset().find(|leaf| leaf.kind() == IDENT)?;\n-        let field = ident.ancestors().find_map(ast::NamedFieldDef::cast)?;\n+        let ident = ctx.token_at_offset().find(|leaf| leaf.kind() == IDENT)?;\n+        let field = ident.parent().ancestors().find_map(ast::NamedFieldDef::cast)?;\n         if field.name()?.syntax().range() != ident.range() && field.visibility().is_some() {\n             return None;\n         }\n@@ -51,7 +51,7 @@ fn add_vis(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n }\n \n fn vis_offset(node: &SyntaxNode) -> TextUnit {\n-    node.children()\n+    node.children_with_tokens()\n         .skip_while(|it| match it.kind() {\n             WHITESPACE | COMMENT | ATTR => true,\n             _ => false,"}, {"sha": "02d27f66d19c8bb99e08cf01b9a286c02ad8bcc5", "filename": "crates/ra_assists/src/flip_binexpr.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fflip_binexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fflip_binexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fflip_binexpr.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -8,7 +8,7 @@ pub(crate) fn flip_binexpr(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assis\n     let expr = ctx.node_at_offset::<BinExpr>()?;\n     let lhs = expr.lhs()?.syntax();\n     let rhs = expr.rhs()?.syntax();\n-    let op_range = expr.op()?.range();\n+    let op_range = expr.op_token()?.range();\n     // The assist should be applied only if the cursor is on the operator\n     let cursor_in_range = ctx.frange.range.is_subrange(&op_range);\n     if !cursor_in_range {"}, {"sha": "a9b1081117aa1fb3beb00ccc9077782d005aac86", "filename": "crates/ra_assists/src/flip_comma.rs", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fflip_comma.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fflip_comma.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fflip_comma.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -8,13 +8,13 @@ use ra_syntax::{\n use crate::{AssistCtx, Assist, AssistId};\n \n pub(crate) fn flip_comma(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n-    let comma = ctx.leaf_at_offset().find(|leaf| leaf.kind() == COMMA)?;\n-    let prev = non_trivia_sibling(comma, Direction::Prev)?;\n-    let next = non_trivia_sibling(comma, Direction::Next)?;\n+    let comma = ctx.token_at_offset().find(|leaf| leaf.kind() == COMMA)?;\n+    let prev = non_trivia_sibling(comma.into(), Direction::Prev)?;\n+    let next = non_trivia_sibling(comma.into(), Direction::Next)?;\n     ctx.add_action(AssistId(\"flip_comma\"), \"flip comma\", |edit| {\n         edit.target(comma.range());\n-        edit.replace(prev.range(), next.text());\n-        edit.replace(next.range(), prev.text());\n+        edit.replace(prev.range(), next.to_string());\n+        edit.replace(next.range(), prev.to_string());\n     });\n \n     ctx.build()"}, {"sha": "2258ca1390c865cd18ab337463ef4bd81e26e5ec", "filename": "crates/ra_assists/src/inline_local_variable.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Finline_local_variable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Finline_local_variable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Finline_local_variable.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -46,8 +46,10 @@ pub(crate) fn inline_local_varialbe(mut ctx: AssistCtx<impl HirDatabase>) -> Opt\n         | ExprKind::BlockExpr(_) => false,\n     };\n \n-    let delete_range = if let Some(whitespace) =\n-        let_stmt.syntax().next_sibling().and_then(ast::Whitespace::cast)\n+    let delete_range = if let Some(whitespace) = let_stmt\n+        .syntax()\n+        .next_sibling_or_token()\n+        .and_then(|it| ast::Whitespace::cast(it.as_token()?))\n     {\n         TextRange::from_to(let_stmt.syntax().range().start(), whitespace.syntax().range().end())\n     } else {"}, {"sha": "fb7333c8c55e135f8344ba68dff06a51029ce6be", "filename": "crates/ra_assists/src/introduce_variable.rs", "status": "modified", "additions": 13, "deletions": 15, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fintroduce_variable.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fintroduce_variable.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fintroduce_variable.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -2,9 +2,8 @@ use test_utils::tested_by;\n use hir::db::HirDatabase;\n use ra_syntax::{\n     ast::{self, AstNode},\n-    SyntaxKind::{\n-        WHITESPACE, MATCH_ARM, LAMBDA_EXPR, PATH_EXPR, BREAK_EXPR, LOOP_EXPR, RETURN_EXPR, COMMENT\n-    }, SyntaxNode, TextUnit,\n+    SyntaxNode, TextUnit,\n+    SyntaxKind::{WHITESPACE, MATCH_ARM, LAMBDA_EXPR, PATH_EXPR, BREAK_EXPR, LOOP_EXPR, RETURN_EXPR, COMMENT},\n };\n \n use crate::{AssistCtx, Assist, AssistId};\n@@ -13,14 +12,14 @@ pub(crate) fn introduce_variable(mut ctx: AssistCtx<impl HirDatabase>) -> Option\n     if ctx.frange.range.is_empty() {\n         return None;\n     }\n-    let node = ctx.covering_node();\n+    let node = ctx.covering_element();\n     if node.kind() == COMMENT {\n         tested_by!(introduce_var_in_comment_is_not_applicable);\n         return None;\n     }\n     let expr = node.ancestors().find_map(valid_target_expr)?;\n     let (anchor_stmt, wrap_in_block) = anchor_stmt(expr)?;\n-    let indent = anchor_stmt.prev_sibling()?;\n+    let indent = anchor_stmt.prev_sibling_or_token()?.as_token()?;\n     if indent.kind() != WHITESPACE {\n         return None;\n     }\n@@ -54,16 +53,15 @@ pub(crate) fn introduce_variable(mut ctx: AssistCtx<impl HirDatabase>) -> Option\n             // We want to maintain the indent level,\n             // but we do not want to duplicate possible\n             // extra newlines in the indent block\n-            for chunk in indent.text().chunks() {\n-                if chunk.starts_with(\"\\r\\n\") {\n-                    buf.push_str(\"\\r\\n\");\n-                    buf.push_str(chunk.trim_start_matches(\"\\r\\n\"));\n-                } else if chunk.starts_with(\"\\n\") {\n-                    buf.push_str(\"\\n\");\n-                    buf.push_str(chunk.trim_start_matches(\"\\n\"));\n-                } else {\n-                    buf.push_str(chunk);\n-                }\n+            let text = indent.text();\n+            if text.starts_with(\"\\r\\n\") {\n+                buf.push_str(\"\\r\\n\");\n+                buf.push_str(text.trim_start_matches(\"\\r\\n\"));\n+            } else if text.starts_with(\"\\n\") {\n+                buf.push_str(\"\\n\");\n+                buf.push_str(text.trim_start_matches(\"\\n\"));\n+            } else {\n+                buf.push_str(text);\n             }\n \n             edit.target(expr.syntax().range());"}, {"sha": "ae9958f119016970d18c78e63ced99d8f323c2ea", "filename": "crates/ra_assists/src/remove_dbg.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fremove_dbg.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fremove_dbg.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fremove_dbg.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -62,15 +62,15 @@ fn is_valid_macrocall(macro_call: &ast::MacroCall, macro_name: &str) -> Option<b\n     let name_ref = path.segment()?.name_ref()?;\n \n     // Make sure it is actually a dbg-macro call, dbg followed by !\n-    let excl = path.syntax().next_sibling()?;\n+    let excl = path.syntax().next_sibling_or_token()?;\n \n     if name_ref.text() != macro_name || excl.kind() != EXCL {\n         return None;\n     }\n \n     let node = macro_call.token_tree()?.syntax();\n-    let first_child = node.first_child()?;\n-    let last_child = node.last_child()?;\n+    let first_child = node.first_child_or_token()?;\n+    let last_child = node.last_child_or_token()?;\n \n     match (first_child.kind(), last_child.kind()) {\n         (L_PAREN, R_PAREN) | (L_BRACK, R_BRACK) | (L_CURLY, R_CURLY) => Some(true),"}, {"sha": "4bf1852db5774b28143fc2498238d15cf399c299", "filename": "crates/ra_assists/src/split_import.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fsplit_import.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_assists%2Fsrc%2Fsplit_import.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_assists%2Fsrc%2Fsplit_import.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -8,8 +8,8 @@ use ra_syntax::{\n use crate::{AssistCtx, Assist, AssistId};\n \n pub(crate) fn split_import(mut ctx: AssistCtx<impl HirDatabase>) -> Option<Assist> {\n-    let colon_colon = ctx.leaf_at_offset().find(|leaf| leaf.kind() == COLONCOLON)?;\n-    let path = colon_colon.parent().and_then(ast::Path::cast)?;\n+    let colon_colon = ctx.token_at_offset().find(|leaf| leaf.kind() == COLONCOLON)?;\n+    let path = ast::Path::cast(colon_colon.parent())?;\n     let top_path = generate(Some(path), |it| it.parent_path()).last()?;\n \n     let use_tree = top_path.syntax().ancestors().find_map(ast::UseTree::cast);"}, {"sha": "4516ed66086a5c9d8bc8ef948c283b64440f2f97", "filename": "crates/ra_cli/src/analysis_stats.rs", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_cli%2Fsrc%2Fanalysis_stats.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_cli%2Fsrc%2Fanalysis_stats.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_cli%2Fsrc%2Fanalysis_stats.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,4 +1,4 @@\n-use std::collections::HashSet;\n+use std::{collections::HashSet, time::Instant};\n \n use ra_db::SourceDatabase;\n use ra_batch::BatchDatabase;\n@@ -8,8 +8,10 @@ use ra_syntax::AstNode;\n use crate::Result;\n \n pub fn run(verbose: bool) -> Result<()> {\n+    let db_load_time = Instant::now();\n     let (db, roots) = BatchDatabase::load_cargo(\".\")?;\n-    println!(\"Database loaded, {} roots\", roots.len());\n+    println!(\"Database loaded, {} roots, {:?}\", roots.len(), db_load_time.elapsed());\n+    let analysis_time = Instant::now();\n     let mut num_crates = 0;\n     let mut visited_modules = HashSet::new();\n     let mut visit_queue = Vec::new();\n@@ -96,5 +98,6 @@ pub fn run(verbose: bool) -> Result<()> {\n         num_exprs_partially_unknown,\n         (num_exprs_partially_unknown * 100 / num_exprs)\n     );\n+    println!(\"Analysis: {:?}\", analysis_time.elapsed());\n     Ok(())\n }"}, {"sha": "1f2750d8956854cec70c77e954a9177f911065a1", "filename": "crates/ra_cli/src/main.rs", "status": "modified", "additions": 1, "deletions": 34, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_cli%2Fsrc%2Fmain.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_cli%2Fsrc%2Fmain.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_cli%2Fsrc%2Fmain.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -3,10 +3,8 @@ mod analysis_stats;\n use std::{fs, io::Read, path::Path, time::Instant};\n \n use clap::{App, Arg, SubCommand};\n-use join_to_string::join;\n-use ra_ide_api::{Analysis, FileRange};\n use ra_ide_api::file_structure;\n-use ra_syntax::{SourceFile, TextRange, TreeArc, AstNode};\n+use ra_syntax::{SourceFile, TreeArc, AstNode};\n use tools::collect_tests;\n use flexi_logger::Logger;\n \n@@ -23,11 +21,6 @@ fn main() -> Result<()> {\n         )\n         .subcommand(SubCommand::with_name(\"parse\").arg(Arg::with_name(\"no-dump\").long(\"--no-dump\")))\n         .subcommand(SubCommand::with_name(\"symbols\"))\n-        .subcommand(\n-            SubCommand::with_name(\"extend-selection\")\n-                .arg(Arg::with_name(\"start\"))\n-                .arg(Arg::with_name(\"end\")),\n-        )\n         .subcommand(\n             SubCommand::with_name(\"analysis-stats\").arg(Arg::with_name(\"verbose\").short(\"v\")),\n         )\n@@ -57,13 +50,6 @@ fn main() -> Result<()> {\n             let (test, tree) = render_test(file, line)?;\n             println!(\"{}\\n{}\", test, tree);\n         }\n-        (\"extend-selection\", Some(matches)) => {\n-            let start: u32 = matches.value_of(\"start\").unwrap().parse()?;\n-            let end: u32 = matches.value_of(\"end\").unwrap().parse()?;\n-            let text = read_stdin()?;\n-            let sels = selections(text, start, end);\n-            println!(\"{}\", sels)\n-        }\n         (\"analysis-stats\", Some(matches)) => {\n             let verbose = matches.is_present(\"verbose\");\n             analysis_stats::run(verbose)?;\n@@ -98,22 +84,3 @@ fn render_test(file: &Path, line: usize) -> Result<(String, String)> {\n     let tree = file.syntax().debug_dump();\n     Ok((test.text, tree))\n }\n-\n-fn selections(text: String, start: u32, end: u32) -> String {\n-    let (analysis, file_id) = Analysis::from_single_file(text);\n-    let mut ranges = Vec::new();\n-    let mut range = TextRange::from_to((start - 1).into(), (end - 1).into());\n-    loop {\n-        ranges.push(range);\n-        let next = analysis.extend_selection(FileRange { file_id, range }).unwrap();\n-        if range == next {\n-            break;\n-        }\n-        range = next;\n-    }\n-    let ranges = ranges\n-        .iter()\n-        .map(|r| (1 + u32::from(r.start()), 1 + u32::from(r.end())))\n-        .map(|(s, e)| format!(\"({} {})\", s, e));\n-    join(ranges).separator(\" \").surround_with(\"(\", \")\").to_string()\n-}"}, {"sha": "ea90dc2b827f1d02ab158bd4dcd6212894da06f1", "filename": "crates/ra_fmt/src/lib.rs", "status": "modified", "additions": 12, "deletions": 16, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_fmt%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_fmt%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_fmt%2Fsrc%2Flib.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -3,8 +3,8 @@\n use itertools::Itertools;\n use ra_syntax::{\n     AstNode,\n-    SyntaxNode, SyntaxKind::*,\n-    ast::{self, AstToken},\n+    SyntaxNode, SyntaxKind::*, SyntaxToken, SyntaxKind,\n+    ast,\n     algo::generate,\n };\n \n@@ -15,26 +15,22 @@ pub fn reindent(text: &str, indent: &str) -> String {\n \n /// If the node is on the beginning of the line, calculate indent.\n pub fn leading_indent(node: &SyntaxNode) -> Option<&str> {\n-    for leaf in prev_leaves(node) {\n-        if let Some(ws) = ast::Whitespace::cast(leaf) {\n+    for token in prev_tokens(node.first_token()?) {\n+        if let Some(ws) = ast::Whitespace::cast(token) {\n             let ws_text = ws.text();\n             if let Some(pos) = ws_text.rfind('\\n') {\n                 return Some(&ws_text[pos + 1..]);\n             }\n         }\n-        if leaf.leaf_text().unwrap().contains('\\n') {\n+        if token.text().contains('\\n') {\n             break;\n         }\n     }\n     None\n }\n \n-fn prev_leaves(node: &SyntaxNode) -> impl Iterator<Item = &SyntaxNode> {\n-    generate(prev_leaf(node), |&node| prev_leaf(node))\n-}\n-\n-fn prev_leaf(node: &SyntaxNode) -> Option<&SyntaxNode> {\n-    generate(node.ancestors().find_map(SyntaxNode::prev_sibling), |it| it.last_child()).last()\n+fn prev_tokens(token: SyntaxToken) -> impl Iterator<Item = SyntaxToken> {\n+    generate(token.prev_token(), |&token| token.prev_token())\n }\n \n pub fn extract_trivial_expression(block: &ast::Block) -> Option<&ast::Expr> {\n@@ -52,20 +48,20 @@ pub fn extract_trivial_expression(block: &ast::Block) -> Option<&ast::Expr> {\n     Some(expr)\n }\n \n-pub fn compute_ws(left: &SyntaxNode, right: &SyntaxNode) -> &'static str {\n-    match left.kind() {\n+pub fn compute_ws(left: SyntaxKind, right: SyntaxKind) -> &'static str {\n+    match left {\n         L_PAREN | L_BRACK => return \"\",\n         L_CURLY => {\n-            if let USE_TREE = right.kind() {\n+            if let USE_TREE = right {\n                 return \"\";\n             }\n         }\n         _ => (),\n     }\n-    match right.kind() {\n+    match right {\n         R_PAREN | R_BRACK => return \"\",\n         R_CURLY => {\n-            if let USE_TREE = left.kind() {\n+            if let USE_TREE = left {\n                 return \"\";\n             }\n         }"}, {"sha": "2ff4139f9cc4ccf99b360f4f86e54896ac4b9c29", "filename": "crates/ra_hir/src/expr.rs", "status": "modified", "additions": 2, "deletions": 10, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fexpr.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fexpr.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fexpr.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -726,13 +726,7 @@ impl ExprCollector {\n                 self.alloc_expr(Expr::Array { exprs }, syntax_ptr)\n             }\n             ast::ExprKind::Literal(e) => {\n-                let child = if let Some(child) = e.literal_expr() {\n-                    child\n-                } else {\n-                    return self.alloc_expr(Expr::Missing, syntax_ptr);\n-                };\n-\n-                let lit = match child.flavor() {\n+                let lit = match e.flavor() {\n                     LiteralFlavor::IntNumber { suffix } => {\n                         let known_name = suffix\n                             .and_then(|it| IntTy::from_suffix(&it).map(UncertainIntTy::Known));\n@@ -874,9 +868,7 @@ impl ExprCollector {\n     fn collect_fn_body(&mut self, node: &ast::FnDef) {\n         if let Some(param_list) = node.param_list() {\n             if let Some(self_param) = param_list.self_param() {\n-                let self_param = SyntaxNodePtr::new(\n-                    self_param.self_kw().expect(\"self param without self keyword\").syntax(),\n-                );\n+                let self_param = SyntaxNodePtr::new(self_param.syntax());\n                 let param_pat = self.alloc_pat(\n                     Pat::Bind {\n                         name: Name::self_param(),"}, {"sha": "54dc273998a831c2ce11998a7dbe5781acdd5222", "filename": "crates/ra_hir/src/source_binder.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fsource_binder.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -9,7 +9,7 @@ use ra_db::{FileId, FilePosition};\n use ra_syntax::{\n     SyntaxNode,\n     ast::{self, AstNode, NameOwner},\n-    algo::{find_node_at_offset, find_leaf_at_offset},\n+    algo::{find_node_at_offset, find_token_at_offset},\n };\n \n use crate::{\n@@ -155,9 +155,9 @@ pub fn trait_from_module(\n pub fn resolver_for_position(db: &impl HirDatabase, position: FilePosition) -> Resolver {\n     let file_id = position.file_id;\n     let file = db.parse(file_id);\n-    find_leaf_at_offset(file.syntax(), position.offset)\n-        .find_map(|node| {\n-            node.ancestors().find_map(|node| {\n+    find_token_at_offset(file.syntax(), position.offset)\n+        .find_map(|token| {\n+            token.parent().ancestors().find_map(|node| {\n                 if ast::Expr::cast(node).is_some() || ast::Block::cast(node).is_some() {\n                     if let Some(func) = function_from_child_node(db, file_id, node) {\n                         let scopes = func.scopes(db);"}, {"sha": "943c5499bdc1b4acb511d997e8bad5beaf056704", "filename": "crates/ra_hir/src/ty/tests.rs", "status": "modified", "additions": 6, "deletions": 8, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fty%2Ftests.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_hir%2Fsrc%2Fty%2Ftests.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_hir%2Fsrc%2Fty%2Ftests.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -2251,14 +2251,12 @@ fn infer(content: &str) -> String {\n         types.sort_by_key(|(ptr, _)| (ptr.range().start(), ptr.range().end()));\n         for (syntax_ptr, ty) in &types {\n             let node = syntax_ptr.to_node(&source_file);\n-            write!(\n-                acc,\n-                \"{} '{}': {}\\n\",\n-                syntax_ptr.range(),\n-                ellipsize(node.text().to_string().replace(\"\\n\", \" \"), 15),\n-                ty.display(&db)\n-            )\n-            .unwrap();\n+            let (range, text) = if let Some(self_param) = ast::SelfParam::cast(node) {\n+                (self_param.self_kw_token().range(), \"self\".to_string())\n+            } else {\n+                (syntax_ptr.range(), node.text().to_string().replace(\"\\n\", \" \"))\n+            };\n+            write!(acc, \"{} '{}': {}\\n\", range, ellipsize(text, 15), ty.display(&db)).unwrap();\n         }\n     }\n     acc.truncate(acc.trim_end().len());"}, {"sha": "a846a7a3cb2d67189bd2a27a4d0bb174771a397c", "filename": "crates/ra_ide_api/src/completion.rs", "status": "modified", "additions": 10, "deletions": 13, "changes": 23, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fcompletion.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -13,7 +13,7 @@ mod complete_scope;\n mod complete_postfix;\n \n use ra_db::SourceDatabase;\n-use ra_syntax::ast::{self, AstNode};\n+use ra_syntax::{ast::{self, AstNode}, SyntaxKind::{ATTR, COMMENT}};\n \n use crate::{\n     db,\n@@ -76,11 +76,10 @@ pub fn function_label(node: &ast::FnDef) -> Option<String> {\n         let body_range = body.syntax().range();\n         let label: String = node\n             .syntax()\n-            .children()\n+            .children_with_tokens()\n             .filter(|child| !child.range().is_subrange(&body_range)) // Filter out body\n-            .filter(|child| ast::Comment::cast(child).is_none()) // Filter out comments\n-            .filter(|child| ast::Attr::cast(child).is_none()) // Filter out attributes\n-            .map(|node| node.text().to_string())\n+            .filter(|child| !(child.kind() == COMMENT || child.kind() == ATTR)) // Filter out comments and attrs\n+            .map(|node| node.to_string())\n             .collect();\n         label\n     } else {\n@@ -93,10 +92,9 @@ pub fn function_label(node: &ast::FnDef) -> Option<String> {\n pub fn const_label(node: &ast::ConstDef) -> String {\n     let label: String = node\n         .syntax()\n-        .children()\n-        .filter(|child| ast::Comment::cast(child).is_none())\n-        .filter(|child| ast::Attr::cast(child).is_none())\n-        .map(|node| node.text().to_string())\n+        .children_with_tokens()\n+        .filter(|child| !(child.kind() == COMMENT || child.kind() == ATTR))\n+        .map(|node| node.to_string())\n         .collect();\n \n     label.trim().to_owned()\n@@ -105,10 +103,9 @@ pub fn const_label(node: &ast::ConstDef) -> String {\n pub fn type_label(node: &ast::TypeAliasDef) -> String {\n     let label: String = node\n         .syntax()\n-        .children()\n-        .filter(|child| ast::Comment::cast(child).is_none())\n-        .filter(|child| ast::Attr::cast(child).is_none())\n-        .map(|node| node.text().to_string())\n+        .children_with_tokens()\n+        .filter(|child| !(child.kind() == COMMENT || child.kind() == ATTR))\n+        .map(|node| node.to_string())\n         .collect();\n \n     label.trim().to_owned()"}, {"sha": "f87ccdeb9de5303730564ffa6c170d6624c26098", "filename": "crates/ra_ide_api/src/completion/complete_fn_param.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_fn_param.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_fn_param.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_fn_param.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -17,7 +17,7 @@ pub(super) fn complete_fn_param(acc: &mut Completions, ctx: &CompletionContext)\n     }\n \n     let mut params = FxHashMap::default();\n-    for node in ctx.leaf.ancestors() {\n+    for node in ctx.token.parent().ancestors() {\n         let _ = visitor_ctx(&mut params)\n             .visit::<ast::SourceFile, _>(process)\n             .visit::<ast::ItemList, _>(process)"}, {"sha": "718b834184046a9618fa62c49522c3fbd6d239ef", "filename": "crates/ra_ide_api/src/completion/complete_keyword.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_keyword.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_keyword.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcomplete_keyword.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -2,7 +2,7 @@ use ra_syntax::{\n     algo::visit::{visitor, Visitor},\n     AstNode,\n     ast::{self, LoopBodyOwner},\n-    SyntaxKind::*, SyntaxNode,\n+    SyntaxKind::*, SyntaxToken,\n };\n \n use crate::completion::{CompletionContext, CompletionItem, Completions, CompletionKind, CompletionItemKind};\n@@ -62,7 +62,7 @@ pub(super) fn complete_expr_keyword(acc: &mut Completions, ctx: &CompletionConte\n         acc.add(keyword(ctx, \"else\", \"else {$0}\"));\n         acc.add(keyword(ctx, \"else if\", \"else if $0 {}\"));\n     }\n-    if is_in_loop_body(ctx.leaf) {\n+    if is_in_loop_body(ctx.token) {\n         if ctx.can_be_stmt {\n             acc.add(keyword(ctx, \"continue\", \"continue;\"));\n             acc.add(keyword(ctx, \"break\", \"break;\"));\n@@ -74,8 +74,8 @@ pub(super) fn complete_expr_keyword(acc: &mut Completions, ctx: &CompletionConte\n     acc.add_all(complete_return(ctx, fn_def, ctx.can_be_stmt));\n }\n \n-fn is_in_loop_body(leaf: &SyntaxNode) -> bool {\n-    for node in leaf.ancestors() {\n+fn is_in_loop_body(leaf: SyntaxToken) -> bool {\n+    for node in leaf.parent().ancestors() {\n         if node.kind() == FN_DEF || node.kind() == LAMBDA_EXPR {\n             break;\n         }"}, {"sha": "65dffa4706c4df55ffea225b8bfbd5c123ca66fd", "filename": "crates/ra_ide_api/src/completion/completion_context.rs", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcompletion_context.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcompletion_context.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fcompletion%2Fcompletion_context.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,8 +1,8 @@\n use ra_text_edit::AtomTextEdit;\n use ra_syntax::{\n-    AstNode, SyntaxNode, SourceFile, TextUnit, TextRange,\n+    AstNode, SyntaxNode, SourceFile, TextUnit, TextRange, SyntaxToken,\n     ast,\n-    algo::{find_leaf_at_offset, find_covering_node, find_node_at_offset},\n+    algo::{find_token_at_offset, find_covering_element, find_node_at_offset},\n     SyntaxKind::*,\n };\n use hir::{source_binder, Resolver};\n@@ -15,7 +15,7 @@ use crate::{db, FilePosition};\n pub(crate) struct CompletionContext<'a> {\n     pub(super) db: &'a db::RootDatabase,\n     pub(super) offset: TextUnit,\n-    pub(super) leaf: &'a SyntaxNode,\n+    pub(super) token: SyntaxToken<'a>,\n     pub(super) resolver: Resolver,\n     pub(super) module: Option<hir::Module>,\n     pub(super) function: Option<hir::Function>,\n@@ -49,10 +49,10 @@ impl<'a> CompletionContext<'a> {\n     ) -> Option<CompletionContext<'a>> {\n         let resolver = source_binder::resolver_for_position(db, position);\n         let module = source_binder::module_from_position(db, position);\n-        let leaf = find_leaf_at_offset(original_file.syntax(), position.offset).left_biased()?;\n+        let token = find_token_at_offset(original_file.syntax(), position.offset).left_biased()?;\n         let mut ctx = CompletionContext {\n             db,\n-            leaf,\n+            token,\n             offset: position.offset,\n             resolver,\n             module,\n@@ -76,9 +76,9 @@ impl<'a> CompletionContext<'a> {\n \n     // The range of the identifier that is being completed.\n     pub(crate) fn source_range(&self) -> TextRange {\n-        match self.leaf.kind() {\n+        match self.token.kind() {\n             // workaroud when completion is triggered by trigger characters.\n-            IDENT => self.leaf.range(),\n+            IDENT => self.token.range(),\n             _ => TextRange::offset_len(self.offset, 0.into()),\n         }\n     }\n@@ -139,10 +139,11 @@ impl<'a> CompletionContext<'a> {\n             _ => (),\n         }\n \n-        self.use_item_syntax = self.leaf.ancestors().find_map(ast::UseItem::cast);\n+        self.use_item_syntax = self.token.parent().ancestors().find_map(ast::UseItem::cast);\n \n         self.function_syntax = self\n-            .leaf\n+            .token\n+            .parent()\n             .ancestors()\n             .take_while(|it| it.kind() != SOURCE_FILE && it.kind() != MODULE)\n             .find_map(ast::FnDef::cast);\n@@ -224,8 +225,7 @@ impl<'a> CompletionContext<'a> {\n }\n \n fn find_node_with_range<N: AstNode>(syntax: &SyntaxNode, range: TextRange) -> Option<&N> {\n-    let node = find_covering_node(syntax, range);\n-    node.ancestors().find_map(N::cast)\n+    find_covering_element(syntax, range).ancestors().find_map(N::cast)\n }\n \n fn is_node<N: AstNode>(node: &SyntaxNode) -> bool {"}, {"sha": "2dfaa00452e4634386739e9a3b94d74d58a22839", "filename": "crates/ra_ide_api/src/diagnostics.rs", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fdiagnostics.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fdiagnostics.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fdiagnostics.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -106,8 +106,10 @@ fn text_edit_for_remove_unnecessary_braces_with_self_in_use_statement(\n     single_use_tree: &ast::UseTree,\n ) -> Option<TextEdit> {\n     let use_tree_list_node = single_use_tree.syntax().parent()?;\n-    if single_use_tree.path()?.segment()?.syntax().first_child()?.kind() == SyntaxKind::SELF_KW {\n-        let start = use_tree_list_node.prev_sibling()?.range().start();\n+    if single_use_tree.path()?.segment()?.syntax().first_child_or_token()?.kind()\n+        == SyntaxKind::SELF_KW\n+    {\n+        let start = use_tree_list_node.prev_sibling_or_token()?.range().start();\n         let end = use_tree_list_node.range().end();\n         let range = TextRange::from_to(start, end);\n         let mut edit_builder = TextEditBuilder::default();"}, {"sha": "e743bf0fe1c4cd8a0a96e2dd7fbe33410b8974ea", "filename": "crates/ra_ide_api/src/extend_selection.rs", "status": "modified", "additions": 73, "deletions": 71, "changes": 144, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fextend_selection.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fextend_selection.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fextend_selection.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,8 +1,9 @@\n use ra_db::SourceDatabase;\n use ra_syntax::{\n-    Direction, SyntaxNode, TextRange, TextUnit, AstNode,\n-    algo::{find_covering_node, find_leaf_at_offset, LeafAtOffset},\n-    SyntaxKind::*,\n+    Direction, SyntaxNode, TextRange, TextUnit, AstNode, SyntaxElement,\n+    algo::{find_covering_element, find_token_at_offset, TokenAtOffset},\n+    SyntaxKind::*, SyntaxToken,\n+    ast::Comment,\n };\n \n use crate::{FileRange, db::RootDatabase};\n@@ -32,53 +33,58 @@ fn try_extend_selection(root: &SyntaxNode, range: TextRange) -> Option<TextRange\n \n     if range.is_empty() {\n         let offset = range.start();\n-        let mut leaves = find_leaf_at_offset(root, offset);\n+        let mut leaves = find_token_at_offset(root, offset);\n         if leaves.clone().all(|it| it.kind() == WHITESPACE) {\n             return Some(extend_ws(root, leaves.next()?, offset));\n         }\n         let leaf_range = match leaves {\n-            LeafAtOffset::None => return None,\n-            LeafAtOffset::Single(l) => {\n+            TokenAtOffset::None => return None,\n+            TokenAtOffset::Single(l) => {\n                 if string_kinds.contains(&l.kind()) {\n                     extend_single_word_in_comment_or_string(l, offset).unwrap_or_else(|| l.range())\n                 } else {\n                     l.range()\n                 }\n             }\n-            LeafAtOffset::Between(l, r) => pick_best(l, r).range(),\n+            TokenAtOffset::Between(l, r) => pick_best(l, r).range(),\n         };\n         return Some(leaf_range);\n     };\n-    let node = find_covering_node(root, range);\n+    let node = match find_covering_element(root, range) {\n+        SyntaxElement::Token(token) => {\n+            if token.range() != range {\n+                return Some(token.range());\n+            }\n+            if let Some(comment) = Comment::cast(token) {\n+                if let Some(range) = extend_comments(comment) {\n+                    return Some(range);\n+                }\n+            }\n+            token.parent()\n+        }\n+        SyntaxElement::Node(node) => node,\n+    };\n+    if node.range() != range {\n+        return Some(node.range());\n+    }\n \n     // Using shallowest node with same range allows us to traverse siblings.\n     let node = node.ancestors().take_while(|n| n.range() == node.range()).last().unwrap();\n \n-    if range == node.range() {\n-        if string_kinds.contains(&node.kind()) {\n-            if let Some(range) = extend_comments(node) {\n-                return Some(range);\n-            }\n-        }\n-\n-        if node.parent().map(|n| list_kinds.contains(&n.kind())) == Some(true) {\n-            if let Some(range) = extend_list_item(node) {\n-                return Some(range);\n-            }\n+    if node.parent().map(|n| list_kinds.contains(&n.kind())) == Some(true) {\n+        if let Some(range) = extend_list_item(node) {\n+            return Some(range);\n         }\n     }\n \n-    match node.ancestors().skip_while(|n| n.range() == range).next() {\n-        None => None,\n-        Some(parent) => Some(parent.range()),\n-    }\n+    node.parent().map(|it| it.range())\n }\n \n fn extend_single_word_in_comment_or_string(\n-    leaf: &SyntaxNode,\n+    leaf: SyntaxToken,\n     offset: TextUnit,\n ) -> Option<TextRange> {\n-    let text: &str = leaf.leaf_text()?;\n+    let text: &str = leaf.text();\n     let cursor_position: u32 = (offset - leaf.range().start()).into();\n \n     let (before, after) = text.split_at(cursor_position as usize);\n@@ -101,14 +107,14 @@ fn extend_single_word_in_comment_or_string(\n     }\n }\n \n-fn extend_ws(root: &SyntaxNode, ws: &SyntaxNode, offset: TextUnit) -> TextRange {\n-    let ws_text = ws.leaf_text().unwrap();\n+fn extend_ws(root: &SyntaxNode, ws: SyntaxToken, offset: TextUnit) -> TextRange {\n+    let ws_text = ws.text();\n     let suffix = TextRange::from_to(offset, ws.range().end()) - ws.range().start();\n     let prefix = TextRange::from_to(ws.range().start(), offset) - ws.range().start();\n     let ws_suffix = &ws_text.as_str()[suffix];\n     let ws_prefix = &ws_text.as_str()[prefix];\n     if ws_text.contains('\\n') && !ws_suffix.contains('\\n') {\n-        if let Some(node) = ws.next_sibling() {\n+        if let Some(node) = ws.next_sibling_or_token() {\n             let start = match ws_prefix.rfind('\\n') {\n                 Some(idx) => ws.range().start() + TextUnit::from((idx + 1) as u32),\n                 None => node.range().start(),\n@@ -124,9 +130,9 @@ fn extend_ws(root: &SyntaxNode, ws: &SyntaxNode, offset: TextUnit) -> TextRange\n     ws.range()\n }\n \n-fn pick_best<'a>(l: &'a SyntaxNode, r: &'a SyntaxNode) -> &'a SyntaxNode {\n+fn pick_best<'a>(l: SyntaxToken<'a>, r: SyntaxToken<'a>) -> SyntaxToken<'a> {\n     return if priority(r) > priority(l) { r } else { l };\n-    fn priority(n: &SyntaxNode) -> usize {\n+    fn priority(n: SyntaxToken) -> usize {\n         match n.kind() {\n             WHITESPACE => 0,\n             IDENT | SELF_KW | SUPER_KW | CRATE_KW | LIFETIME => 2,\n@@ -137,54 +143,60 @@ fn pick_best<'a>(l: &'a SyntaxNode, r: &'a SyntaxNode) -> &'a SyntaxNode {\n \n /// Extend list item selection to include nearby comma and whitespace.\n fn extend_list_item(node: &SyntaxNode) -> Option<TextRange> {\n-    fn is_single_line_ws(node: &SyntaxNode) -> bool {\n-        node.kind() == WHITESPACE && !node.leaf_text().unwrap().contains('\\n')\n+    fn is_single_line_ws(node: &SyntaxToken) -> bool {\n+        node.kind() == WHITESPACE && !node.text().contains('\\n')\n     }\n \n-    fn nearby_comma(node: &SyntaxNode, dir: Direction) -> Option<&SyntaxNode> {\n-        node.siblings(dir)\n+    fn nearby_comma(node: &SyntaxNode, dir: Direction) -> Option<SyntaxToken> {\n+        node.siblings_with_tokens(dir)\n             .skip(1)\n-            .skip_while(|node| is_single_line_ws(node))\n+            .skip_while(|node| match node {\n+                SyntaxElement::Node(_) => false,\n+                SyntaxElement::Token(it) => is_single_line_ws(it),\n+            })\n             .next()\n+            .and_then(|it| it.as_token())\n             .filter(|node| node.kind() == COMMA)\n     }\n \n     if let Some(comma_node) = nearby_comma(node, Direction::Prev) {\n         return Some(TextRange::from_to(comma_node.range().start(), node.range().end()));\n     }\n-\n     if let Some(comma_node) = nearby_comma(node, Direction::Next) {\n         // Include any following whitespace when comma if after list item.\n         let final_node = comma_node\n-            .siblings(Direction::Next)\n-            .skip(1)\n-            .next()\n+            .next_sibling_or_token()\n+            .and_then(|it| it.as_token())\n             .filter(|node| is_single_line_ws(node))\n             .unwrap_or(comma_node);\n \n         return Some(TextRange::from_to(node.range().start(), final_node.range().end()));\n     }\n \n-    return None;\n+    None\n }\n \n-fn extend_comments(node: &SyntaxNode) -> Option<TextRange> {\n-    let prev = adj_comments(node, Direction::Prev);\n-    let next = adj_comments(node, Direction::Next);\n+fn extend_comments(comment: Comment) -> Option<TextRange> {\n+    let prev = adj_comments(comment, Direction::Prev);\n+    let next = adj_comments(comment, Direction::Next);\n     if prev != next {\n-        Some(TextRange::from_to(prev.range().start(), next.range().end()))\n+        Some(TextRange::from_to(prev.syntax().range().start(), next.syntax().range().end()))\n     } else {\n         None\n     }\n }\n \n-fn adj_comments(node: &SyntaxNode, dir: Direction) -> &SyntaxNode {\n-    let mut res = node;\n-    for node in node.siblings(dir) {\n-        match node.kind() {\n-            COMMENT => res = node,\n-            WHITESPACE if !node.leaf_text().unwrap().as_str().contains(\"\\n\\n\") => (),\n-            _ => break,\n+fn adj_comments(comment: Comment, dir: Direction) -> Comment {\n+    let mut res = comment;\n+    for element in comment.syntax().siblings_with_tokens(dir) {\n+        let token = match element.as_token() {\n+            None => break,\n+            Some(token) => token,\n+        };\n+        if let Some(c) = Comment::cast(token) {\n+            res = c\n+        } else if token.kind() != WHITESPACE || token.text().contains(\"\\n\\n\") {\n+            break;\n         }\n     }\n     res\n@@ -308,37 +320,27 @@ fn bar(){}\n /*\n foo\n _bar1<|>*/\n-    \"#,\n+\"#,\n             &[\"_bar1\", \"/*\\nfoo\\n_bar1*/\"],\n         );\n \n-        do_check(\n-            r#\"\n-//!<|>foo_2 bar\n-    \"#,\n-            &[\"foo_2\", \"//!foo_2 bar\"],\n-        );\n+        do_check(r#\"//!<|>foo_2 bar\"#, &[\"foo_2\", \"//!foo_2 bar\"]);\n \n-        do_check(\n-            r#\"\n-/<|>/foo bar\n-    \"#,\n-            &[\"//foo bar\"],\n-        );\n+        do_check(r#\"/<|>/foo bar\"#, &[\"//foo bar\"]);\n     }\n \n     #[test]\n     fn test_extend_selection_prefer_idents() {\n         do_check(\n             r#\"\n fn main() { foo<|>+bar;}\n-    \"#,\n+\"#,\n             &[\"foo\", \"foo+bar\"],\n         );\n         do_check(\n             r#\"\n fn main() { foo+<|>bar;}\n-    \"#,\n+\"#,\n             &[\"bar\", \"foo+bar\"],\n         );\n     }\n@@ -355,11 +357,11 @@ fn main() { foo+<|>bar;}\n         do_check(\n             r#\"\n impl S {\n-    fn foo() {\n-        // hel<|>lo world\n-    }\n+fn foo() {\n+// hel<|>lo world\n }\n-        \"#,\n+}\n+\"#,\n             &[\"hello\", \"// hello world\"],\n         );\n     }\n@@ -371,7 +373,7 @@ impl S {\n fn bar(){}\n \n \" fn f<|>oo() {\"\n-    \"#,\n+\"#,\n             &[\"foo\", \"\\\" fn foo() {\\\"\"],\n         );\n     }"}, {"sha": "a6fe8a5d5995876fea34f6e9f53ec8b469c40cd9", "filename": "crates/ra_ide_api/src/folding_ranges.rs", "status": "modified", "additions": 78, "deletions": 56, "changes": 134, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Ffolding_ranges.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Ffolding_ranges.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Ffolding_ranges.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,9 +1,9 @@\n use rustc_hash::FxHashSet;\n \n use ra_syntax::{\n-    AstNode, Direction, SourceFile, SyntaxNode, TextRange,\n+    AstNode, SourceFile, SyntaxNode, TextRange, Direction, SyntaxElement,\n     SyntaxKind::{self, *},\n-    ast::{self, VisibilityOwner},\n+    ast::{self, VisibilityOwner, Comment},\n };\n \n #[derive(Debug, PartialEq, Eq)]\n@@ -26,34 +26,49 @@ pub(crate) fn folding_ranges(file: &SourceFile) -> Vec<Fold> {\n     let mut visited_imports = FxHashSet::default();\n     let mut visited_mods = FxHashSet::default();\n \n-    for node in file.syntax().descendants() {\n+    for element in file.syntax().descendants_with_tokens() {\n         // Fold items that span multiple lines\n-        if let Some(kind) = fold_kind(node.kind()) {\n-            if node.text().contains('\\n') {\n-                res.push(Fold { range: node.range(), kind });\n+        if let Some(kind) = fold_kind(element.kind()) {\n+            let is_multiline = match element {\n+                SyntaxElement::Node(node) => node.text().contains('\\n'),\n+                SyntaxElement::Token(token) => token.text().contains('\\n'),\n+            };\n+            if is_multiline {\n+                res.push(Fold { range: element.range(), kind });\n+                continue;\n             }\n         }\n \n-        // Fold groups of comments\n-        if node.kind() == COMMENT && !visited_comments.contains(&node) {\n-            if let Some(range) = contiguous_range_for_comment(node, &mut visited_comments) {\n-                res.push(Fold { range, kind: FoldKind::Comment })\n+        match element {\n+            SyntaxElement::Token(token) => {\n+                // Fold groups of comments\n+                if let Some(comment) = ast::Comment::cast(token) {\n+                    if !visited_comments.contains(&comment) {\n+                        if let Some(range) =\n+                            contiguous_range_for_comment(comment, &mut visited_comments)\n+                        {\n+                            res.push(Fold { range, kind: FoldKind::Comment })\n+                        }\n+                    }\n+                }\n             }\n-        }\n-\n-        // Fold groups of imports\n-        if node.kind() == USE_ITEM && !visited_imports.contains(&node) {\n-            if let Some(range) = contiguous_range_for_group(node, &mut visited_imports) {\n-                res.push(Fold { range, kind: FoldKind::Imports })\n-            }\n-        }\n-\n-        // Fold groups of mods\n-        if node.kind() == MODULE && !has_visibility(&node) && !visited_mods.contains(&node) {\n-            if let Some(range) =\n-                contiguous_range_for_group_unless(node, has_visibility, &mut visited_mods)\n-            {\n-                res.push(Fold { range, kind: FoldKind::Mods })\n+            SyntaxElement::Node(node) => {\n+                // Fold groups of imports\n+                if node.kind() == USE_ITEM && !visited_imports.contains(&node) {\n+                    if let Some(range) = contiguous_range_for_group(node, &mut visited_imports) {\n+                        res.push(Fold { range, kind: FoldKind::Imports })\n+                    }\n+                }\n+\n+                // Fold groups of mods\n+                if node.kind() == MODULE && !has_visibility(&node) && !visited_mods.contains(&node)\n+                {\n+                    if let Some(range) =\n+                        contiguous_range_for_group_unless(node, has_visibility, &mut visited_mods)\n+                    {\n+                        res.push(Fold { range, kind: FoldKind::Mods })\n+                    }\n+                }\n             }\n         }\n     }\n@@ -90,16 +105,21 @@ fn contiguous_range_for_group_unless<'a>(\n     visited.insert(first);\n \n     let mut last = first;\n-    for node in first.siblings(Direction::Next) {\n-        if let Some(ws) = ast::Whitespace::cast(node) {\n-            // There is a blank line, which means that the group ends here\n-            if ws.count_newlines_lazy().take(2).count() == 2 {\n+    for element in first.siblings_with_tokens(Direction::Next) {\n+        let node = match element {\n+            SyntaxElement::Token(token) => {\n+                if let Some(ws) = ast::Whitespace::cast(token) {\n+                    if !ws.spans_multiple_lines() {\n+                        // Ignore whitespace without blank lines\n+                        continue;\n+                    }\n+                }\n+                // There is a blank line or another token, which means that the\n+                // group ends here\n                 break;\n             }\n-\n-            // Ignore whitespace without blank lines\n-            continue;\n-        }\n+            SyntaxElement::Node(node) => node,\n+        };\n \n         // Stop if we find a node that doesn't belong to the group\n         if node.kind() != first.kind() || unless(node) {\n@@ -119,40 +139,42 @@ fn contiguous_range_for_group_unless<'a>(\n }\n \n fn contiguous_range_for_comment<'a>(\n-    first: &'a SyntaxNode,\n-    visited: &mut FxHashSet<&'a SyntaxNode>,\n+    first: Comment<'a>,\n+    visited: &mut FxHashSet<Comment<'a>>,\n ) -> Option<TextRange> {\n     visited.insert(first);\n \n     // Only fold comments of the same flavor\n-    let group_flavor = ast::Comment::cast(first)?.flavor();\n+    let group_flavor = first.flavor();\n \n     let mut last = first;\n-    for node in first.siblings(Direction::Next) {\n-        if let Some(ws) = ast::Whitespace::cast(node) {\n-            // There is a blank line, which means the group ends here\n-            if ws.count_newlines_lazy().take(2).count() == 2 {\n+    for element in first.syntax().siblings_with_tokens(Direction::Next) {\n+        match element {\n+            SyntaxElement::Token(token) => {\n+                if let Some(ws) = ast::Whitespace::cast(token) {\n+                    if !ws.spans_multiple_lines() {\n+                        // Ignore whitespace without blank lines\n+                        continue;\n+                    }\n+                }\n+                if let Some(c) = Comment::cast(token) {\n+                    if c.flavor() == group_flavor {\n+                        visited.insert(c);\n+                        last = c;\n+                        continue;\n+                    }\n+                }\n+                // The comment group ends because either:\n+                // * An element of a different kind was reached\n+                // * A comment of a different flavor was reached\n                 break;\n             }\n-\n-            // Ignore whitespace without blank lines\n-            continue;\n-        }\n-\n-        match ast::Comment::cast(node) {\n-            Some(next_comment) if next_comment.flavor() == group_flavor => {\n-                visited.insert(node);\n-                last = node;\n-            }\n-            // The comment group ends because either:\n-            // * An element of a different kind was reached\n-            // * A comment of a different flavor was reached\n-            _ => break,\n-        }\n+            SyntaxElement::Node(_) => break,\n+        };\n     }\n \n     if first != last {\n-        Some(TextRange::from_to(first.range().start(), last.range().end()))\n+        Some(TextRange::from_to(first.syntax().range().start(), last.syntax().range().end()))\n     } else {\n         // The group consists of only one element, therefore it cannot be folded\n         None"}, {"sha": "bfa7cd67abc11c0883058764fac0f162b3699695", "filename": "crates/ra_ide_api/src/hover.rs", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fhover.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fhover.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fhover.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,7 +1,7 @@\n use ra_db::SourceDatabase;\n use ra_syntax::{\n     AstNode, SyntaxNode, TreeArc, ast::{self, NameOwner, VisibilityOwner, TypeAscriptionOwner},\n-    algo::{find_covering_node, find_node_at_offset, find_leaf_at_offset, visit::{visitor, Visitor}},\n+    algo::{find_covering_element, find_node_at_offset, find_token_at_offset, visit::{visitor, Visitor}},\n };\n use hir::HirDisplay;\n \n@@ -104,8 +104,11 @@ pub(crate) fn hover(db: &RootDatabase, position: FilePosition) -> Option<RangeIn\n     }\n \n     if range.is_none() {\n-        let node = find_leaf_at_offset(file.syntax(), position.offset).find_map(|leaf| {\n-            leaf.ancestors().find(|n| ast::Expr::cast(*n).is_some() || ast::Pat::cast(*n).is_some())\n+        let node = find_token_at_offset(file.syntax(), position.offset).find_map(|token| {\n+            token\n+                .parent()\n+                .ancestors()\n+                .find(|n| ast::Expr::cast(*n).is_some() || ast::Pat::cast(*n).is_some())\n         })?;\n         let frange = FileRange { file_id: position.file_id, range: node.range() };\n         res.extend(type_of(db, frange).map(rust_code_markup));\n@@ -123,13 +126,12 @@ pub(crate) fn hover(db: &RootDatabase, position: FilePosition) -> Option<RangeIn\n pub(crate) fn type_of(db: &RootDatabase, frange: FileRange) -> Option<String> {\n     let file = db.parse(frange.file_id);\n     let syntax = file.syntax();\n-    let leaf_node = find_covering_node(syntax, frange.range);\n+    let leaf_node = find_covering_element(syntax, frange.range);\n     // if we picked identifier, expand to pattern/expression\n     let node = leaf_node\n         .ancestors()\n         .take_while(|it| it.range() == leaf_node.range())\n-        .find(|&it| ast::Expr::cast(it).is_some() || ast::Pat::cast(it).is_some())\n-        .unwrap_or(leaf_node);\n+        .find(|&it| ast::Expr::cast(it).is_some() || ast::Pat::cast(it).is_some())?;\n     let parent_fn = node.ancestors().find_map(ast::FnDef::cast)?;\n     let function = hir::source_binder::function_from_source(db, frange.file_id, parent_fn)?;\n     let infer = function.infer(db);"}, {"sha": "57b6f8384b9cd0b50c1c94b5c6a3cfba33273fff", "filename": "crates/ra_ide_api/src/join_lines.rs", "status": "modified", "additions": 40, "deletions": 39, "changes": 79, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fjoin_lines.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fjoin_lines.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fjoin_lines.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,8 +1,8 @@\n use itertools::Itertools;\n use ra_syntax::{\n-    SourceFile, TextRange, TextUnit, AstNode, SyntaxNode,\n+    SourceFile, TextRange, TextUnit, AstNode, SyntaxNode, SyntaxElement, SyntaxToken,\n     SyntaxKind::{self, WHITESPACE, COMMA, R_CURLY, R_PAREN, R_BRACK},\n-    algo::{find_covering_node, non_trivia_sibling},\n+    algo::{find_covering_element, non_trivia_sibling},\n     ast,\n     Direction,\n };\n@@ -24,40 +24,35 @@ pub fn join_lines(file: &SourceFile, range: TextRange) -> TextEdit {\n         range\n     };\n \n-    let node = find_covering_node(file.syntax(), range);\n+    let node = match find_covering_element(file.syntax(), range) {\n+        SyntaxElement::Node(node) => node,\n+        SyntaxElement::Token(token) => token.parent(),\n+    };\n     let mut edit = TextEditBuilder::default();\n-    for node in node.descendants() {\n-        let text = match node.leaf_text() {\n-            Some(text) => text,\n-            None => continue,\n-        };\n-        let range = match range.intersection(&node.range()) {\n+    for token in node.descendants_with_tokens().filter_map(|it| it.as_token()) {\n+        let range = match range.intersection(&token.range()) {\n             Some(range) => range,\n             None => continue,\n-        } - node.range().start();\n+        } - token.range().start();\n+        let text = token.text();\n         for (pos, _) in text[range].bytes().enumerate().filter(|&(_, b)| b == b'\\n') {\n             let pos: TextUnit = (pos as u32).into();\n-            let off = node.range().start() + range.start() + pos;\n+            let off = token.range().start() + range.start() + pos;\n             if !edit.invalidates_offset(off) {\n-                remove_newline(&mut edit, node, text.as_str(), off);\n+                remove_newline(&mut edit, token, off);\n             }\n         }\n     }\n \n     edit.finish()\n }\n \n-fn remove_newline(\n-    edit: &mut TextEditBuilder,\n-    node: &SyntaxNode,\n-    node_text: &str,\n-    offset: TextUnit,\n-) {\n-    if node.kind() != WHITESPACE || node_text.bytes().filter(|&b| b == b'\\n').count() != 1 {\n+fn remove_newline(edit: &mut TextEditBuilder, token: SyntaxToken, offset: TextUnit) {\n+    if token.kind() != WHITESPACE || token.text().bytes().filter(|&b| b == b'\\n').count() != 1 {\n         // The node is either the first or the last in the file\n-        let suff = &node_text[TextRange::from_to(\n-            offset - node.range().start() + TextUnit::of_char('\\n'),\n-            TextUnit::of_str(node_text),\n+        let suff = &token.text()[TextRange::from_to(\n+            offset - token.range().start() + TextUnit::of_char('\\n'),\n+            TextUnit::of_str(token.text()),\n         )];\n         let spaces = suff.bytes().take_while(|&b| b == b' ').count();\n \n@@ -74,7 +69,7 @@ fn remove_newline(\n     // ```\n     //\n     // into `my_function(<some-expr>)`\n-    if join_single_expr_block(edit, node).is_some() {\n+    if join_single_expr_block(edit, token).is_some() {\n         return;\n     }\n     // ditto for\n@@ -84,44 +79,50 @@ fn remove_newline(\n     //    bar\n     // };\n     // ```\n-    if join_single_use_tree(edit, node).is_some() {\n+    if join_single_use_tree(edit, token).is_some() {\n         return;\n     }\n \n     // The node is between two other nodes\n-    let prev = node.prev_sibling().unwrap();\n-    let next = node.next_sibling().unwrap();\n+    let prev = token.prev_sibling_or_token().unwrap();\n+    let next = token.next_sibling_or_token().unwrap();\n     if is_trailing_comma(prev.kind(), next.kind()) {\n         // Removes: trailing comma, newline (incl. surrounding whitespace)\n-        edit.delete(TextRange::from_to(prev.range().start(), node.range().end()));\n+        edit.delete(TextRange::from_to(prev.range().start(), token.range().end()));\n     } else if prev.kind() == COMMA && next.kind() == R_CURLY {\n         // Removes: comma, newline (incl. surrounding whitespace)\n-        let space = if let Some(left) = prev.prev_sibling() { compute_ws(left, next) } else { \" \" };\n+        let space = if let Some(left) = prev.prev_sibling_or_token() {\n+            compute_ws(left.kind(), next.kind())\n+        } else {\n+            \" \"\n+        };\n         edit.replace(\n-            TextRange::from_to(prev.range().start(), node.range().end()),\n+            TextRange::from_to(prev.range().start(), token.range().end()),\n             space.to_string(),\n         );\n-    } else if let (Some(_), Some(next)) = (ast::Comment::cast(prev), ast::Comment::cast(next)) {\n+    } else if let (Some(_), Some(next)) =\n+        (prev.as_token().and_then(ast::Comment::cast), next.as_token().and_then(ast::Comment::cast))\n+    {\n         // Removes: newline (incl. surrounding whitespace), start of the next comment\n         edit.delete(TextRange::from_to(\n-            node.range().start(),\n+            token.range().start(),\n             next.syntax().range().start() + TextUnit::of_str(next.prefix()),\n         ));\n     } else {\n         // Remove newline but add a computed amount of whitespace characters\n-        edit.replace(node.range(), compute_ws(prev, next).to_string());\n+        edit.replace(token.range(), compute_ws(prev.kind(), next.kind()).to_string());\n     }\n }\n \n fn has_comma_after(node: &SyntaxNode) -> bool {\n-    match non_trivia_sibling(node, Direction::Next) {\n+    match non_trivia_sibling(node.into(), Direction::Next) {\n         Some(n) => n.kind() == COMMA,\n         _ => false,\n     }\n }\n \n-fn join_single_expr_block(edit: &mut TextEditBuilder, node: &SyntaxNode) -> Option<()> {\n-    let block = ast::Block::cast(node.parent()?)?;\n+fn join_single_expr_block(edit: &mut TextEditBuilder, token: SyntaxToken) -> Option<()> {\n+    let block = ast::Block::cast(token.parent())?;\n     let block_expr = ast::BlockExpr::cast(block.syntax().parent()?)?;\n     let expr = extract_trivial_expression(block)?;\n \n@@ -140,8 +141,8 @@ fn join_single_expr_block(edit: &mut TextEditBuilder, node: &SyntaxNode) -> Opti\n     Some(())\n }\n \n-fn join_single_use_tree(edit: &mut TextEditBuilder, node: &SyntaxNode) -> Option<()> {\n-    let use_tree_list = ast::UseTreeList::cast(node.parent()?)?;\n+fn join_single_use_tree(edit: &mut TextEditBuilder, token: SyntaxToken) -> Option<()> {\n+    let use_tree_list = ast::UseTreeList::cast(token.parent())?;\n     let (tree,) = use_tree_list.use_trees().collect_tuple()?;\n     edit.replace(use_tree_list.syntax().range(), tree.syntax().text().to_string());\n     Some(())\n@@ -401,13 +402,13 @@ use ra_syntax::{\n             r\"\n use ra_syntax::{\n     algo::<|>{\n-        find_leaf_at_offset,\n+        find_token_at_offset,\n     },\n     ast,\n };\",\n             r\"\n use ra_syntax::{\n-    algo::<|>find_leaf_at_offset,\n+    algo::<|>find_token_at_offset,\n     ast,\n };\",\n         );"}, {"sha": "bebd16a6984d940340510db6b73b269f8f5cbc08", "filename": "crates/ra_ide_api/src/matching_brace.rs", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fmatching_brace.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fmatching_brace.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fmatching_brace.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,22 +1,22 @@\n use ra_syntax::{\n     SourceFile, TextUnit,\n-    algo::find_leaf_at_offset,\n+    algo::find_token_at_offset,\n     SyntaxKind::{self, *},\n     ast::AstNode,\n };\n \n pub fn matching_brace(file: &SourceFile, offset: TextUnit) -> Option<TextUnit> {\n     const BRACES: &[SyntaxKind] =\n         &[L_CURLY, R_CURLY, L_BRACK, R_BRACK, L_PAREN, R_PAREN, L_ANGLE, R_ANGLE];\n-    let (brace_node, brace_idx) = find_leaf_at_offset(file.syntax(), offset)\n+    let (brace_node, brace_idx) = find_token_at_offset(file.syntax(), offset)\n         .filter_map(|node| {\n             let idx = BRACES.iter().position(|&brace| brace == node.kind())?;\n             Some((node, idx))\n         })\n         .next()?;\n-    let parent = brace_node.parent()?;\n+    let parent = brace_node.parent();\n     let matching_kind = BRACES[brace_idx ^ 1];\n-    let matching_node = parent.children().find(|node| node.kind() == matching_kind)?;\n+    let matching_node = parent.children_with_tokens().find(|node| node.kind() == matching_kind)?;\n     Some(matching_node.range().start())\n }\n \n@@ -41,5 +41,4 @@ mod tests {\n \n         do_check(\"struct Foo { a: i32, }<|>\", \"struct Foo <|>{ a: i32, }\");\n     }\n-\n }"}, {"sha": "d9a28d2b5b0a391a713974a02ef201a81af6f583", "filename": "crates/ra_ide_api/src/syntax_highlighting.rs", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fsyntax_highlighting.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,6 +1,6 @@\n use rustc_hash::FxHashSet;\n \n-use ra_syntax::{ast, AstNode, TextRange, Direction, SyntaxKind::*};\n+use ra_syntax::{ast, AstNode, TextRange, Direction, SyntaxKind::*, SyntaxElement};\n use ra_db::SourceDatabase;\n \n use crate::{FileId, db::RootDatabase};\n@@ -15,9 +15,9 @@ pub(crate) fn highlight(db: &RootDatabase, file_id: FileId) -> Vec<HighlightedRa\n     let source_file = db.parse(file_id);\n \n     // Visited nodes to handle highlighting priorities\n-    let mut highlighted = FxHashSet::default();\n+    let mut highlighted: FxHashSet<SyntaxElement> = FxHashSet::default();\n     let mut res = Vec::new();\n-    for node in source_file.syntax().descendants() {\n+    for node in source_file.syntax().descendants_with_tokens() {\n         if highlighted.contains(&node) {\n             continue;\n         }\n@@ -31,14 +31,14 @@ pub(crate) fn highlight(db: &RootDatabase, file_id: FileId) -> Vec<HighlightedRa\n             LIFETIME => \"parameter\",\n             k if k.is_keyword() => \"keyword\",\n             _ => {\n-                if let Some(macro_call) = ast::MacroCall::cast(node) {\n+                if let Some(macro_call) = node.as_node().and_then(ast::MacroCall::cast) {\n                     if let Some(path) = macro_call.path() {\n                         if let Some(segment) = path.segment() {\n                             if let Some(name_ref) = segment.name_ref() {\n-                                highlighted.insert(name_ref.syntax());\n+                                highlighted.insert(name_ref.syntax().into());\n                                 let range_start = name_ref.syntax().range().start();\n                                 let mut range_end = name_ref.syntax().range().end();\n-                                for sibling in path.syntax().siblings(Direction::Next) {\n+                                for sibling in path.syntax().siblings_with_tokens(Direction::Next) {\n                                     match sibling.kind() {\n                                         EXCL | IDENT => range_end = sibling.range().end(),\n                                         _ => (),"}, {"sha": "a4e4c3dbef3dba09a4639db0deaa4dd76b18131e", "filename": "crates/ra_ide_api/src/syntax_tree.rs", "status": "modified", "additions": 19, "deletions": 14, "changes": 33, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fsyntax_tree.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Fsyntax_tree.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Fsyntax_tree.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,8 +1,9 @@\n use ra_db::SourceDatabase;\r\n use crate::db::RootDatabase;\r\n use ra_syntax::{\r\n-    SourceFile, SyntaxNode, TextRange, AstNode,\r\n-    algo::{self, visit::{visitor, Visitor}}, ast::{self, AstToken}\r\n+    SourceFile, TextRange, AstNode, SyntaxToken, SyntaxElement,\r\n+    algo,\r\n+    SyntaxKind::{STRING, RAW_STRING},\r\n };\r\n \r\n pub use ra_db::FileId;\r\n@@ -14,11 +15,15 @@ pub(crate) fn syntax_tree(\n ) -> String {\r\n     if let Some(text_range) = text_range {\r\n         let file = db.parse(file_id);\r\n-        let node = algo::find_covering_node(file.syntax(), text_range);\r\n-\r\n-        if let Some(tree) = syntax_tree_for_string(node, text_range) {\r\n-            return tree;\r\n-        }\r\n+        let node = match algo::find_covering_element(file.syntax(), text_range) {\r\n+            SyntaxElement::Node(node) => node,\r\n+            SyntaxElement::Token(token) => {\r\n+                if let Some(tree) = syntax_tree_for_string(token, text_range) {\r\n+                    return tree;\r\n+                }\r\n+                token.parent()\r\n+            }\r\n+        };\r\n \r\n         node.debug_dump()\r\n     } else {\r\n@@ -28,19 +33,19 @@ pub(crate) fn syntax_tree(\n \r\n /// Attempts parsing the selected contents of a string literal\r\n /// as rust syntax and returns its syntax tree\r\n-fn syntax_tree_for_string(node: &SyntaxNode, text_range: TextRange) -> Option<String> {\r\n+fn syntax_tree_for_string(token: SyntaxToken, text_range: TextRange) -> Option<String> {\r\n     // When the range is inside a string\r\n     // we'll attempt parsing it as rust syntax\r\n     // to provide the syntax tree of the contents of the string\r\n-    visitor()\r\n-        .visit(|node: &ast::String| syntax_tree_for_token(node, text_range))\r\n-        .visit(|node: &ast::RawString| syntax_tree_for_token(node, text_range))\r\n-        .accept(node)?\r\n+    match token.kind() {\r\n+        STRING | RAW_STRING => syntax_tree_for_token(token, text_range),\r\n+        _ => None,\r\n+    }\r\n }\r\n \r\n-fn syntax_tree_for_token<T: AstToken>(node: &T, text_range: TextRange) -> Option<String> {\r\n+fn syntax_tree_for_token(node: SyntaxToken, text_range: TextRange) -> Option<String> {\r\n     // Range of the full node\r\n-    let node_range = node.syntax().range();\r\n+    let node_range = node.range();\r\n     let text = node.text().to_string();\r\n \r\n     // We start at some point inside the node\r"}, {"sha": "4510d663d8701241bb9c1e1c470d4a4880d9e176", "filename": "crates/ra_ide_api/src/typing.rs", "status": "modified", "additions": 16, "deletions": 16, "changes": 32, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Ftyping.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_ide_api%2Fsrc%2Ftyping.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_ide_api%2Fsrc%2Ftyping.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,8 +1,8 @@\n use ra_syntax::{\n     AstNode, SourceFile, SyntaxKind::*,\n-    SyntaxNode, TextUnit, TextRange,\n-    algo::{find_node_at_offset, find_leaf_at_offset, LeafAtOffset},\n-    ast::{self, AstToken},\n+    TextUnit, TextRange, SyntaxToken,\n+    algo::{find_node_at_offset, find_token_at_offset, TokenAtOffset},\n+    ast::{self},\n };\n use ra_fmt::leading_indent;\n use ra_text_edit::{TextEdit, TextEditBuilder};\n@@ -11,11 +11,11 @@ use crate::{db::RootDatabase, SourceChange, SourceFileEdit};\n \n pub(crate) fn on_enter(db: &RootDatabase, position: FilePosition) -> Option<SourceChange> {\n     let file = db.parse(position.file_id);\n-    let comment = find_leaf_at_offset(file.syntax(), position.offset)\n+    let comment = find_token_at_offset(file.syntax(), position.offset)\n         .left_biased()\n         .and_then(ast::Comment::cast)?;\n \n-    if let ast::CommentFlavor::Multiline = comment.flavor() {\n+    if comment.flavor() == ast::CommentFlavor::Multiline {\n         return None;\n     }\n \n@@ -41,23 +41,23 @@ pub(crate) fn on_enter(db: &RootDatabase, position: FilePosition) -> Option<Sour\n     )\n }\n \n-fn node_indent<'a>(file: &'a SourceFile, node: &SyntaxNode) -> Option<&'a str> {\n-    let ws = match find_leaf_at_offset(file.syntax(), node.range().start()) {\n-        LeafAtOffset::Between(l, r) => {\n-            assert!(r == node);\n+fn node_indent<'a>(file: &'a SourceFile, token: SyntaxToken) -> Option<&'a str> {\n+    let ws = match find_token_at_offset(file.syntax(), token.range().start()) {\n+        TokenAtOffset::Between(l, r) => {\n+            assert!(r == token);\n             l\n         }\n-        LeafAtOffset::Single(n) => {\n-            assert!(n == node);\n+        TokenAtOffset::Single(n) => {\n+            assert!(n == token);\n             return Some(\"\");\n         }\n-        LeafAtOffset::None => unreachable!(),\n+        TokenAtOffset::None => unreachable!(),\n     };\n     if ws.kind() != WHITESPACE {\n         return None;\n     }\n-    let text = ws.leaf_text().unwrap();\n-    let pos = text.as_str().rfind('\\n').map(|it| it + 1).unwrap_or(0);\n+    let text = ws.text();\n+    let pos = text.rfind('\\n').map(|it| it + 1).unwrap_or(0);\n     Some(&text[pos..])\n }\n \n@@ -88,7 +88,7 @@ pub(crate) fn on_dot_typed(db: &RootDatabase, position: FilePosition) -> Option<\n     let file = db.parse(position.file_id);\n     assert_eq!(file.syntax().text().char_at(position.offset), Some('.'));\n \n-    let whitespace = find_leaf_at_offset(file.syntax(), position.offset)\n+    let whitespace = find_token_at_offset(file.syntax(), position.offset)\n         .left_biased()\n         .and_then(ast::Whitespace::cast)?;\n \n@@ -100,7 +100,7 @@ pub(crate) fn on_dot_typed(db: &RootDatabase, position: FilePosition) -> Option<\n     let current_indent_len = TextUnit::of_str(current_indent);\n \n     // Make sure dot is a part of call chain\n-    let field_expr = whitespace.syntax().parent().and_then(ast::FieldExpr::cast)?;\n+    let field_expr = ast::FieldExpr::cast(whitespace.syntax().parent())?;\n     let prev_indent = leading_indent(field_expr.syntax())?;\n     let target_indent = format!(\"    {}\", prev_indent);\n     let target_indent_len = TextUnit::of_str(&target_indent);"}, {"sha": "05f9817dae86602182608d718c2e569d5f358e0b", "filename": "crates/ra_mbe/src/syntax_bridge.rs", "status": "modified", "additions": 47, "deletions": 39, "changes": 86, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_mbe%2Fsrc%2Fsyntax_bridge.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,6 +1,6 @@\n use ra_parser::{TokenSource, TreeSink, ParseError};\n use ra_syntax::{\n-    AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc,\n+    AstNode, SyntaxNode, TextRange, SyntaxKind, SmolStr, SyntaxTreeBuilder, TreeArc, SyntaxElement,\n     ast, SyntaxKind::*, TextUnit\n };\n \n@@ -47,48 +47,56 @@ fn convert_tt(\n     global_offset: TextUnit,\n     tt: &SyntaxNode,\n ) -> Option<tt::Subtree> {\n-    let first_child = tt.first_child()?;\n-    let last_child = tt.last_child()?;\n+    let first_child = tt.first_child_or_token()?;\n+    let last_child = tt.last_child_or_token()?;\n     let delimiter = match (first_child.kind(), last_child.kind()) {\n         (L_PAREN, R_PAREN) => tt::Delimiter::Parenthesis,\n         (L_CURLY, R_CURLY) => tt::Delimiter::Brace,\n         (L_BRACK, R_BRACK) => tt::Delimiter::Bracket,\n         _ => return None,\n     };\n     let mut token_trees = Vec::new();\n-    for child in tt.children().skip(1) {\n+    for child in tt.children_with_tokens().skip(1) {\n         if child == first_child || child == last_child || child.kind().is_trivia() {\n             continue;\n         }\n-        if child.kind().is_punct() {\n-            let mut prev = None;\n-            for char in child.leaf_text().unwrap().chars() {\n-                if let Some(char) = prev {\n-                    token_trees.push(\n-                        tt::Leaf::from(tt::Punct { char, spacing: tt::Spacing::Joint }).into(),\n-                    );\n+        match child {\n+            SyntaxElement::Token(token) => {\n+                if token.kind().is_punct() {\n+                    let mut prev = None;\n+                    for char in token.text().chars() {\n+                        if let Some(char) = prev {\n+                            token_trees.push(\n+                                tt::Leaf::from(tt::Punct { char, spacing: tt::Spacing::Joint })\n+                                    .into(),\n+                            );\n+                        }\n+                        prev = Some(char)\n+                    }\n+                    if let Some(char) = prev {\n+                        token_trees.push(\n+                            tt::Leaf::from(tt::Punct { char, spacing: tt::Spacing::Alone }).into(),\n+                        );\n+                    }\n+                } else {\n+                    let child = if token.kind().is_keyword() || token.kind() == IDENT {\n+                        let relative_range = token.range() - global_offset;\n+                        let id = token_map.alloc(relative_range);\n+                        let text = token.text().clone();\n+                        tt::Leaf::from(tt::Ident { text, id }).into()\n+                    } else if token.kind().is_literal() {\n+                        tt::Leaf::from(tt::Literal { text: token.text().clone() }).into()\n+                    } else {\n+                        return None;\n+                    };\n+                    token_trees.push(child);\n                 }\n-                prev = Some(char)\n             }\n-            if let Some(char) = prev {\n-                token_trees\n-                    .push(tt::Leaf::from(tt::Punct { char, spacing: tt::Spacing::Alone }).into());\n+            SyntaxElement::Node(node) => {\n+                let child = convert_tt(token_map, global_offset, node)?.into();\n+                token_trees.push(child);\n             }\n-        } else {\n-            let child: tt::TokenTree = if child.kind() == TOKEN_TREE {\n-                convert_tt(token_map, global_offset, child)?.into()\n-            } else if child.kind().is_keyword() || child.kind() == IDENT {\n-                let relative_range = child.range() - global_offset;\n-                let id = token_map.alloc(relative_range);\n-                let text = child.leaf_text().unwrap().clone();\n-                tt::Leaf::from(tt::Ident { text, id }).into()\n-            } else if child.kind().is_literal() {\n-                tt::Leaf::from(tt::Literal { text: child.leaf_text().unwrap().clone() }).into()\n-            } else {\n-                return None;\n-            };\n-            token_trees.push(child)\n-        }\n+        };\n     }\n \n     let res = tt::Subtree { delimiter, token_trees };\n@@ -118,12 +126,12 @@ impl TtTokenSource {\n     }\n     fn convert_tt(&mut self, tt: &tt::TokenTree) {\n         match tt {\n-            tt::TokenTree::Leaf(leaf) => self.convert_leaf(leaf),\n+            tt::TokenTree::Leaf(token) => self.convert_token(token),\n             tt::TokenTree::Subtree(sub) => self.convert_subtree(sub),\n         }\n     }\n-    fn convert_leaf(&mut self, leaf: &tt::Leaf) {\n-        let tok = match leaf {\n+    fn convert_token(&mut self, token: &tt::Leaf) {\n+        let tok = match token {\n             tt::Leaf::Literal(l) => TtToken {\n                 kind: SyntaxKind::INT_NUMBER, // FIXME\n                 is_joint_to_next: false,\n@@ -206,23 +214,23 @@ impl<'a> TtTreeSink<'a> {\n }\n \n impl<'a> TreeSink for TtTreeSink<'a> {\n-    fn leaf(&mut self, kind: SyntaxKind, n_tokens: u8) {\n+    fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         for _ in 0..n_tokens {\n             self.buf += self.tokens[self.token_pos].text.as_str();\n             self.token_pos += 1;\n         }\n         self.text_pos += TextUnit::of_str(&self.buf);\n         let text = SmolStr::new(self.buf.as_str());\n         self.buf.clear();\n-        self.inner.leaf(kind, text)\n+        self.inner.token(kind, text)\n     }\n \n-    fn start_branch(&mut self, kind: SyntaxKind) {\n-        self.inner.start_branch(kind);\n+    fn start_node(&mut self, kind: SyntaxKind) {\n+        self.inner.start_node(kind);\n     }\n \n-    fn finish_branch(&mut self) {\n-        self.inner.finish_branch();\n+    fn finish_node(&mut self) {\n+        self.inner.finish_node();\n     }\n \n     fn error(&mut self, error: ParseError) {"}, {"sha": "87cf4eca09a5e0aa9f3ed34f39ca6c685d089765", "filename": "crates/ra_parser/src/event.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_parser%2Fsrc%2Fevent.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_parser%2Fsrc%2Fevent.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Fevent.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -116,12 +116,12 @@ pub(super) fn process(sink: &mut dyn TreeSink, mut events: Vec<Event>) {\n                 }\n \n                 for kind in forward_parents.drain(..).rev() {\n-                    sink.start_branch(kind);\n+                    sink.start_node(kind);\n                 }\n             }\n-            Event::Finish => sink.finish_branch(),\n+            Event::Finish => sink.finish_node(),\n             Event::Token { kind, n_raw_tokens } => {\n-                sink.leaf(kind, n_raw_tokens);\n+                sink.token(kind, n_raw_tokens);\n             }\n             Event::Error { msg } => sink.error(msg),\n         }"}, {"sha": "30ba06aacdac8f7ccba3dc7af93fa28edb3659e6", "filename": "crates/ra_parser/src/lib.rs", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_parser%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_parser%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_parser%2Fsrc%2Flib.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -40,15 +40,15 @@ pub trait TokenSource {\n \n /// `TreeSink` abstracts details of a particular syntax tree implementation.\n pub trait TreeSink {\n-    /// Adds new leaf to the current branch.\n-    fn leaf(&mut self, kind: SyntaxKind, n_tokens: u8);\n+    /// Adds new token to the current branch.\n+    fn token(&mut self, kind: SyntaxKind, n_tokens: u8);\n \n     /// Start new branch and make it current.\n-    fn start_branch(&mut self, kind: SyntaxKind);\n+    fn start_node(&mut self, kind: SyntaxKind);\n \n     /// Finish current branch and restore previous\n     /// branch as current.\n-    fn finish_branch(&mut self);\n+    fn finish_node(&mut self);\n \n     fn error(&mut self, error: ParseError);\n }"}, {"sha": "1a763fb4726ae6f89e53178b8c3be649b42cbbb0", "filename": "crates/ra_syntax/Cargo.toml", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2FCargo.toml", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2FCargo.toml", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2FCargo.toml?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -13,7 +13,7 @@ unicode-xid = \"0.1.0\"\n itertools = \"0.8.0\"\n drop_bomb = \"0.1.4\"\n parking_lot = \"0.7.0\"\n-rowan = \"0.3.3\"\n+rowan = \"0.4.0\"\n \n # ideally, `serde` should be enabled by `ra_lsp_server`, but we enable it here\n # to reduce number of compilations"}, {"sha": "06b45135c92e67ad858a5795344fc50f0e33ceb8", "filename": "crates/ra_syntax/src/algo.rs", "status": "modified", "additions": 25, "deletions": 16, "changes": 41, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Falgo.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Falgo.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Falgo.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,18 +1,14 @@\n pub mod visit;\n \n-use rowan::TransparentNewType;\n+use crate::{SyntaxNode, TextRange, TextUnit, AstNode, Direction, SyntaxToken, SyntaxElement};\n \n-use crate::{SyntaxNode, TextRange, TextUnit, AstNode, Direction};\n+pub use rowan::TokenAtOffset;\n \n-pub use rowan::LeafAtOffset;\n-\n-pub fn find_leaf_at_offset(node: &SyntaxNode, offset: TextUnit) -> LeafAtOffset<&SyntaxNode> {\n-    match node.0.leaf_at_offset(offset) {\n-        LeafAtOffset::None => LeafAtOffset::None,\n-        LeafAtOffset::Single(n) => LeafAtOffset::Single(SyntaxNode::from_repr(n)),\n-        LeafAtOffset::Between(l, r) => {\n-            LeafAtOffset::Between(SyntaxNode::from_repr(l), SyntaxNode::from_repr(r))\n-        }\n+pub fn find_token_at_offset(node: &SyntaxNode, offset: TextUnit) -> TokenAtOffset<SyntaxToken> {\n+    match node.0.token_at_offset(offset) {\n+        TokenAtOffset::None => TokenAtOffset::None,\n+        TokenAtOffset::Single(n) => TokenAtOffset::Single(n.into()),\n+        TokenAtOffset::Between(l, r) => TokenAtOffset::Between(l.into(), r.into()),\n     }\n }\n \n@@ -26,16 +22,29 @@ pub fn find_leaf_at_offset(node: &SyntaxNode, offset: TextUnit) -> LeafAtOffset<\n ///\n /// then the left node will be silently preferred.\n pub fn find_node_at_offset<N: AstNode>(syntax: &SyntaxNode, offset: TextUnit) -> Option<&N> {\n-    find_leaf_at_offset(syntax, offset).find_map(|leaf| leaf.ancestors().find_map(N::cast))\n+    find_token_at_offset(syntax, offset)\n+        .find_map(|leaf| leaf.parent().ancestors().find_map(N::cast))\n }\n \n /// Finds the first sibling in the given direction which is not `trivia`\n-pub fn non_trivia_sibling(node: &SyntaxNode, direction: Direction) -> Option<&SyntaxNode> {\n-    node.siblings(direction).skip(1).find(|node| !node.kind().is_trivia())\n+pub fn non_trivia_sibling(element: SyntaxElement, direction: Direction) -> Option<SyntaxElement> {\n+    return match element {\n+        SyntaxElement::Node(node) => node.siblings_with_tokens(direction).skip(1).find(not_trivia),\n+        SyntaxElement::Token(token) => {\n+            token.siblings_with_tokens(direction).skip(1).find(not_trivia)\n+        }\n+    };\n+\n+    fn not_trivia(element: &SyntaxElement) -> bool {\n+        match element {\n+            SyntaxElement::Node(_) => true,\n+            SyntaxElement::Token(token) => !token.kind().is_trivia(),\n+        }\n+    }\n }\n \n-pub fn find_covering_node(root: &SyntaxNode, range: TextRange) -> &SyntaxNode {\n-    SyntaxNode::from_repr(root.0.covering_node(range))\n+pub fn find_covering_element(root: &SyntaxNode, range: TextRange) -> SyntaxElement {\n+    root.0.covering_node(range).into()\n }\n \n // Replace with `std::iter::successors` in `1.34.0`"}, {"sha": "9a44afc67e37cb9e11215575e0dab142c0d4726d", "filename": "crates/ra_syntax/src/ast.rs", "status": "modified", "additions": 161, "deletions": 85, "changes": 246, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fast.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fast.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fast.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -7,7 +7,7 @@ use itertools::Itertools;\n \n pub use self::generated::*;\n use crate::{\n-    syntax_node::{SyntaxNode, SyntaxNodeChildren, TreeArc, RaTypes},\n+    syntax_node::{SyntaxNode, SyntaxNodeChildren, TreeArc, RaTypes, SyntaxToken, SyntaxElement, SyntaxElementChildren},\n     SmolStr,\n     SyntaxKind::*,\n };\n@@ -27,7 +27,8 @@ pub trait AstNode:\n \n pub trait AstToken: AstNode {\n     fn text(&self) -> &SmolStr {\n-        self.syntax().leaf_text().unwrap()\n+        // self.syntax().leaf_text().unwrap()\n+        unimplemented!()\n     }\n }\n \n@@ -126,8 +127,8 @@ pub trait AttrsOwner: AstNode {\n }\n \n pub trait DocCommentsOwner: AstNode {\n-    fn doc_comments(&self) -> AstChildren<Comment> {\n-        children(self)\n+    fn doc_comments(&self) -> CommentIter {\n+        CommentIter { iter: self.syntax().children_with_tokens() }\n     }\n \n     /// Returns the textual content of a doc comment block as a single string.\n@@ -179,37 +180,56 @@ impl Attr {\n \n     pub fn as_atom(&self) -> Option<SmolStr> {\n         let tt = self.value()?;\n-        let (_bra, attr, _ket) = tt.syntax().children().collect_tuple()?;\n+        let (_bra, attr, _ket) = tt.syntax().children_with_tokens().collect_tuple()?;\n         if attr.kind() == IDENT {\n-            Some(attr.leaf_text().unwrap().clone())\n+            Some(attr.as_token()?.text().clone())\n         } else {\n             None\n         }\n     }\n \n     pub fn as_call(&self) -> Option<(SmolStr, &TokenTree)> {\n         let tt = self.value()?;\n-        let (_bra, attr, args, _ket) = tt.syntax().children().collect_tuple()?;\n-        let args = TokenTree::cast(args)?;\n+        let (_bra, attr, args, _ket) = tt.syntax().children_with_tokens().collect_tuple()?;\n+        let args = TokenTree::cast(args.as_node()?)?;\n         if attr.kind() == IDENT {\n-            Some((attr.leaf_text().unwrap().clone(), args))\n+            Some((attr.as_token()?.text().clone(), args))\n         } else {\n             None\n         }\n     }\n \n     pub fn as_named(&self) -> Option<SmolStr> {\n         let tt = self.value()?;\n-        let attr = tt.syntax().children().nth(1)?;\n+        let attr = tt.syntax().children_with_tokens().nth(1)?;\n         if attr.kind() == IDENT {\n-            Some(attr.leaf_text().unwrap().clone())\n+            Some(attr.as_token()?.text().clone())\n         } else {\n             None\n         }\n     }\n }\n \n-impl Comment {\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n+pub struct Comment<'a>(SyntaxToken<'a>);\n+\n+impl<'a> Comment<'a> {\n+    pub fn cast(token: SyntaxToken<'a>) -> Option<Self> {\n+        if token.kind() == COMMENT {\n+            Some(Comment(token))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn syntax(&self) -> SyntaxToken<'a> {\n+        self.0\n+    }\n+\n+    pub fn text(&self) -> &'a SmolStr {\n+        self.0.text()\n+    }\n+\n     pub fn flavor(&self) -> CommentFlavor {\n         let text = self.text();\n         if text.starts_with(\"///\") {\n@@ -230,13 +250,16 @@ impl Comment {\n     pub fn prefix(&self) -> &'static str {\n         self.flavor().prefix()\n     }\n+}\n \n-    pub fn count_newlines_lazy(&self) -> impl Iterator<Item = &()> {\n-        self.text().chars().filter(|&c| c == '\\n').map(|_| &())\n-    }\n+pub struct CommentIter<'a> {\n+    iter: SyntaxElementChildren<'a>,\n+}\n \n-    pub fn has_newlines(&self) -> bool {\n-        self.count_newlines_lazy().count() > 0\n+impl<'a> Iterator for CommentIter<'a> {\n+    type Item = Comment<'a>;\n+    fn next(&mut self) -> Option<Comment<'a>> {\n+        self.iter.by_ref().find_map(|el| el.as_token().and_then(Comment::cast))\n     }\n }\n \n@@ -267,27 +290,42 @@ impl CommentFlavor {\n     }\n }\n \n-impl Whitespace {\n-    pub fn count_newlines_lazy(&self) -> impl Iterator<Item = &()> {\n-        self.text().chars().filter(|&c| c == '\\n').map(|_| &())\n+pub struct Whitespace<'a>(SyntaxToken<'a>);\n+\n+impl<'a> Whitespace<'a> {\n+    pub fn cast(token: SyntaxToken<'a>) -> Option<Self> {\n+        if token.kind() == WHITESPACE {\n+            Some(Whitespace(token))\n+        } else {\n+            None\n+        }\n+    }\n+\n+    pub fn syntax(&self) -> SyntaxToken<'a> {\n+        self.0\n     }\n \n-    pub fn has_newlines(&self) -> bool {\n-        self.text().contains('\\n')\n+    pub fn text(&self) -> &'a SmolStr {\n+        self.0.text()\n+    }\n+\n+    pub fn spans_multiple_lines(&self) -> bool {\n+        let text = self.text();\n+        text.find('\\n').map_or(false, |idx| text[idx + 1..].contains('\\n'))\n     }\n }\n \n impl Name {\n     pub fn text(&self) -> &SmolStr {\n-        let ident = self.syntax().first_child().unwrap();\n-        ident.leaf_text().unwrap()\n+        let ident = self.syntax().first_child_or_token().unwrap().as_token().unwrap();\n+        ident.text()\n     }\n }\n \n impl NameRef {\n     pub fn text(&self) -> &SmolStr {\n-        let ident = self.syntax().first_child().unwrap();\n-        ident.leaf_text().unwrap()\n+        let ident = self.syntax().first_child_or_token().unwrap().as_token().unwrap();\n+        ident.text()\n     }\n }\n \n@@ -316,7 +354,7 @@ impl ImplBlock {\n \n impl Module {\n     pub fn has_semi(&self) -> bool {\n-        match self.syntax().last_child() {\n+        match self.syntax().last_child_or_token() {\n             None => false,\n             Some(node) => node.kind() == SEMI,\n         }\n@@ -325,7 +363,7 @@ impl Module {\n \n impl LetStmt {\n     pub fn has_semi(&self) -> bool {\n-        match self.syntax().last_child() {\n+        match self.syntax().last_child_or_token() {\n             None => false,\n             Some(node) => node.kind() == SEMI,\n         }\n@@ -360,7 +398,7 @@ impl IfExpr {\n \n impl ExprStmt {\n     pub fn has_semi(&self) -> bool {\n-        match self.syntax().last_child() {\n+        match self.syntax().last_child_or_token() {\n             None => false,\n             Some(node) => node.kind() == SEMI,\n         }\n@@ -384,7 +422,7 @@ impl PathSegment {\n         let res = if let Some(name_ref) = self.name_ref() {\n             PathSegmentKind::Name(name_ref)\n         } else {\n-            match self.syntax().first_child()?.kind() {\n+            match self.syntax().first_child_or_token()?.kind() {\n                 SELF_KW => PathSegmentKind::SelfKw,\n                 SUPER_KW => PathSegmentKind::SuperKw,\n                 CRATE_KW => PathSegmentKind::CrateKw,\n@@ -395,7 +433,7 @@ impl PathSegment {\n     }\n \n     pub fn has_colon_colon(&self) -> bool {\n-        match self.syntax.first_child().map(|s| s.kind()) {\n+        match self.syntax.first_child_or_token().map(|s| s.kind()) {\n             Some(COLONCOLON) => true,\n             _ => false,\n         }\n@@ -410,7 +448,7 @@ impl Path {\n \n impl UseTree {\n     pub fn has_star(&self) -> bool {\n-        self.syntax().children().any(|it| it.kind() == STAR)\n+        self.syntax().children_with_tokens().any(|it| it.kind() == STAR)\n     }\n }\n \n@@ -425,7 +463,7 @@ impl UseTreeList {\n \n impl RefPat {\n     pub fn is_mut(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == MUT_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == MUT_KW)\n     }\n }\n \n@@ -500,19 +538,19 @@ impl EnumVariant {\n \n impl PointerType {\n     pub fn is_mut(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == MUT_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == MUT_KW)\n     }\n }\n \n impl ReferenceType {\n     pub fn is_mut(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == MUT_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == MUT_KW)\n     }\n }\n \n impl RefExpr {\n     pub fn is_mut(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == MUT_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == MUT_KW)\n     }\n }\n \n@@ -528,16 +566,16 @@ pub enum PrefixOp {\n \n impl PrefixExpr {\n     pub fn op_kind(&self) -> Option<PrefixOp> {\n-        match self.syntax().first_child()?.kind() {\n+        match self.op_token()?.kind() {\n             STAR => Some(PrefixOp::Deref),\n             EXCL => Some(PrefixOp::Not),\n             MINUS => Some(PrefixOp::Neg),\n             _ => None,\n         }\n     }\n \n-    pub fn op(&self) -> Option<&SyntaxNode> {\n-        self.syntax().first_child()\n+    pub fn op_token(&self) -> Option<SyntaxToken> {\n+        self.syntax().first_child_or_token()?.as_token()\n     }\n }\n \n@@ -608,48 +646,50 @@ pub enum BinOp {\n }\n \n impl BinExpr {\n-    fn op_details(&self) -> Option<(&SyntaxNode, BinOp)> {\n-        self.syntax().children().find_map(|c| match c.kind() {\n-            PIPEPIPE => Some((c, BinOp::BooleanOr)),\n-            AMPAMP => Some((c, BinOp::BooleanAnd)),\n-            EQEQ => Some((c, BinOp::EqualityTest)),\n-            NEQ => Some((c, BinOp::NegatedEqualityTest)),\n-            LTEQ => Some((c, BinOp::LesserEqualTest)),\n-            GTEQ => Some((c, BinOp::GreaterEqualTest)),\n-            L_ANGLE => Some((c, BinOp::LesserTest)),\n-            R_ANGLE => Some((c, BinOp::GreaterTest)),\n-            PLUS => Some((c, BinOp::Addition)),\n-            STAR => Some((c, BinOp::Multiplication)),\n-            MINUS => Some((c, BinOp::Subtraction)),\n-            SLASH => Some((c, BinOp::Division)),\n-            PERCENT => Some((c, BinOp::Remainder)),\n-            SHL => Some((c, BinOp::LeftShift)),\n-            SHR => Some((c, BinOp::RightShift)),\n-            CARET => Some((c, BinOp::BitwiseXor)),\n-            PIPE => Some((c, BinOp::BitwiseOr)),\n-            AMP => Some((c, BinOp::BitwiseAnd)),\n-            DOTDOT => Some((c, BinOp::RangeRightOpen)),\n-            DOTDOTEQ => Some((c, BinOp::RangeRightClosed)),\n-            EQ => Some((c, BinOp::Assignment)),\n-            PLUSEQ => Some((c, BinOp::AddAssign)),\n-            SLASHEQ => Some((c, BinOp::DivAssign)),\n-            STAREQ => Some((c, BinOp::MulAssign)),\n-            PERCENTEQ => Some((c, BinOp::RemAssign)),\n-            SHREQ => Some((c, BinOp::ShrAssign)),\n-            SHLEQ => Some((c, BinOp::ShlAssign)),\n-            MINUSEQ => Some((c, BinOp::SubAssign)),\n-            PIPEEQ => Some((c, BinOp::BitOrAssign)),\n-            AMPEQ => Some((c, BinOp::BitAndAssign)),\n-            CARETEQ => Some((c, BinOp::BitXorAssign)),\n-            _ => None,\n+    fn op_details(&self) -> Option<(SyntaxToken, BinOp)> {\n+        self.syntax().children_with_tokens().filter_map(|it| it.as_token()).find_map(|c| {\n+            match c.kind() {\n+                PIPEPIPE => Some((c, BinOp::BooleanOr)),\n+                AMPAMP => Some((c, BinOp::BooleanAnd)),\n+                EQEQ => Some((c, BinOp::EqualityTest)),\n+                NEQ => Some((c, BinOp::NegatedEqualityTest)),\n+                LTEQ => Some((c, BinOp::LesserEqualTest)),\n+                GTEQ => Some((c, BinOp::GreaterEqualTest)),\n+                L_ANGLE => Some((c, BinOp::LesserTest)),\n+                R_ANGLE => Some((c, BinOp::GreaterTest)),\n+                PLUS => Some((c, BinOp::Addition)),\n+                STAR => Some((c, BinOp::Multiplication)),\n+                MINUS => Some((c, BinOp::Subtraction)),\n+                SLASH => Some((c, BinOp::Division)),\n+                PERCENT => Some((c, BinOp::Remainder)),\n+                SHL => Some((c, BinOp::LeftShift)),\n+                SHR => Some((c, BinOp::RightShift)),\n+                CARET => Some((c, BinOp::BitwiseXor)),\n+                PIPE => Some((c, BinOp::BitwiseOr)),\n+                AMP => Some((c, BinOp::BitwiseAnd)),\n+                DOTDOT => Some((c, BinOp::RangeRightOpen)),\n+                DOTDOTEQ => Some((c, BinOp::RangeRightClosed)),\n+                EQ => Some((c, BinOp::Assignment)),\n+                PLUSEQ => Some((c, BinOp::AddAssign)),\n+                SLASHEQ => Some((c, BinOp::DivAssign)),\n+                STAREQ => Some((c, BinOp::MulAssign)),\n+                PERCENTEQ => Some((c, BinOp::RemAssign)),\n+                SHREQ => Some((c, BinOp::ShrAssign)),\n+                SHLEQ => Some((c, BinOp::ShlAssign)),\n+                MINUSEQ => Some((c, BinOp::SubAssign)),\n+                PIPEEQ => Some((c, BinOp::BitOrAssign)),\n+                AMPEQ => Some((c, BinOp::BitAndAssign)),\n+                CARETEQ => Some((c, BinOp::BitXorAssign)),\n+                _ => None,\n+            }\n         })\n     }\n \n     pub fn op_kind(&self) -> Option<BinOp> {\n         self.op_details().map(|t| t.1)\n     }\n \n-    pub fn op(&self) -> Option<&SyntaxNode> {\n+    pub fn op_token(&self) -> Option<SyntaxToken> {\n         self.op_details().map(|t| t.0)\n     }\n \n@@ -680,11 +720,23 @@ pub enum SelfParamFlavor {\n }\n \n impl SelfParam {\n+    pub fn self_kw_token(&self) -> SyntaxToken {\n+        self.syntax()\n+            .children_with_tokens()\n+            .filter_map(|it| it.as_token())\n+            .find(|it| it.kind() == SELF_KW)\n+            .expect(\"invalid tree: self param must have self\")\n+    }\n+\n     pub fn flavor(&self) -> SelfParamFlavor {\n-        let borrowed = self.syntax().children().any(|n| n.kind() == AMP);\n+        let borrowed = self.syntax().children_with_tokens().any(|n| n.kind() == AMP);\n         if borrowed {\n             // check for a `mut` coming after the & -- `mut &self` != `&mut self`\n-            if self.syntax().children().skip_while(|n| n.kind() != AMP).any(|n| n.kind() == MUT_KW)\n+            if self\n+                .syntax()\n+                .children_with_tokens()\n+                .skip_while(|n| n.kind() != AMP)\n+                .any(|n| n.kind() == MUT_KW)\n             {\n                 SelfParamFlavor::MutRef\n             } else {\n@@ -707,25 +759,31 @@ pub enum LiteralFlavor {\n     Bool,\n }\n \n-impl LiteralExpr {\n+impl Literal {\n+    pub fn token(&self) -> SyntaxToken {\n+        match self.syntax().first_child_or_token().unwrap() {\n+            SyntaxElement::Token(token) => token,\n+            _ => unreachable!(),\n+        }\n+    }\n+\n     pub fn flavor(&self) -> LiteralFlavor {\n-        let syntax = self.syntax();\n-        match syntax.kind() {\n+        match self.token().kind() {\n             INT_NUMBER => {\n                 let allowed_suffix_list = [\n                     \"isize\", \"i128\", \"i64\", \"i32\", \"i16\", \"i8\", \"usize\", \"u128\", \"u64\", \"u32\",\n                     \"u16\", \"u8\",\n                 ];\n-                let text = syntax.text().to_string();\n+                let text = self.token().text().to_string();\n                 let suffix = allowed_suffix_list\n                     .iter()\n                     .find(|&s| text.ends_with(s))\n                     .map(|&suf| SmolStr::new(suf));\n-                LiteralFlavor::IntNumber { suffix: suffix }\n+                LiteralFlavor::IntNumber { suffix }\n             }\n             FLOAT_NUMBER => {\n                 let allowed_suffix_list = [\"f64\", \"f32\"];\n-                let text = syntax.text().to_string();\n+                let text = self.token().text().to_string();\n                 let suffix = allowed_suffix_list\n                     .iter()\n                     .find(|&s| text.ends_with(s))\n@@ -750,11 +808,29 @@ impl NamedField {\n \n impl BindPat {\n     pub fn is_mutable(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == MUT_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == MUT_KW)\n     }\n \n     pub fn is_ref(&self) -> bool {\n-        self.syntax().children().any(|n| n.kind() == REF_KW)\n+        self.syntax().children_with_tokens().any(|n| n.kind() == REF_KW)\n+    }\n+}\n+\n+impl LifetimeParam {\n+    pub fn lifetime_token(&self) -> Option<SyntaxToken> {\n+        self.syntax()\n+            .children_with_tokens()\n+            .filter_map(|it| it.as_token())\n+            .find(|it| it.kind() == LIFETIME)\n+    }\n+}\n+\n+impl WherePred {\n+    pub fn lifetime_token(&self) -> Option<SyntaxToken> {\n+        self.syntax()\n+            .children_with_tokens()\n+            .filter_map(|it| it.as_token())\n+            .find(|it| it.kind() == LIFETIME)\n     }\n }\n \n@@ -835,7 +911,7 @@ where\n     let pred = predicates.next().unwrap();\n     let mut bounds = pred.type_bound_list().unwrap().bounds();\n \n-    assert_eq!(\"'a\", pred.lifetime().unwrap().syntax().text().to_string());\n+    assert_eq!(\"'a\", pred.lifetime_token().unwrap().text());\n \n     assert_bound(\"'b\", bounds.next());\n     assert_bound(\"'c\", bounds.next());"}, {"sha": "4afe1a146217f9ad47c5d240279e87511bad2482", "filename": "crates/ra_syntax/src/ast/generated.rs", "status": "modified", "additions": 4, "deletions": 523, "changes": 527, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fast%2Fgenerated.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -376,64 +376,6 @@ impl BreakExpr {\n     }\n }\n \n-// Byte\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct Byte {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for Byte {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for Byte {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            BYTE => Some(Byte::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for Byte {\n-    type Owned = TreeArc<Byte>;\n-    fn to_owned(&self) -> TreeArc<Byte> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for Byte {}\n-impl Byte {}\n-\n-// ByteString\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct ByteString {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for ByteString {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for ByteString {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            BYTE_STRING => Some(ByteString::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for ByteString {\n-    type Owned = TreeArc<ByteString>;\n-    fn to_owned(&self) -> TreeArc<ByteString> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for ByteString {}\n-impl ByteString {}\n-\n // CallExpr\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -503,64 +445,6 @@ impl CastExpr {\n     }\n }\n \n-// Char\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct Char {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for Char {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for Char {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            CHAR => Some(Char::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for Char {\n-    type Owned = TreeArc<Char>;\n-    fn to_owned(&self) -> TreeArc<Char> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for Char {}\n-impl Char {}\n-\n-// Comment\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct Comment {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for Comment {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for Comment {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            COMMENT => Some(Comment::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for Comment {\n-    type Owned = TreeArc<Comment>;\n-    fn to_owned(&self) -> TreeArc<Comment> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for Comment {}\n-impl Comment {}\n-\n // Condition\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -1115,35 +999,6 @@ impl ExternCrateItem {\n     }\n }\n \n-// FalseKw\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct FalseKw {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for FalseKw {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for FalseKw {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            FALSE_KW => Some(FalseKw::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for FalseKw {\n-    type Owned = TreeArc<FalseKw>;\n-    fn to_owned(&self) -> TreeArc<FalseKw> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for FalseKw {}\n-impl FalseKw {}\n-\n // FieldExpr\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -1249,35 +1104,6 @@ impl FieldPatList {\n     }\n }\n \n-// FloatNumber\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct FloatNumber {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for FloatNumber {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for FloatNumber {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            FLOAT_NUMBER => Some(FloatNumber::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for FloatNumber {\n-    type Owned = TreeArc<FloatNumber>;\n-    fn to_owned(&self) -> TreeArc<FloatNumber> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for FloatNumber {}\n-impl FloatNumber {}\n-\n // FnDef\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -1613,35 +1439,6 @@ impl ToOwned for IndexExpr {\n \n impl IndexExpr {}\n \n-// IntNumber\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct IntNumber {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for IntNumber {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for IntNumber {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            INT_NUMBER => Some(IntNumber::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for IntNumber {\n-    type Owned = TreeArc<IntNumber>;\n-    fn to_owned(&self) -> TreeArc<IntNumber> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for IntNumber {}\n-impl IntNumber {}\n-\n // ItemList\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -1777,35 +1574,6 @@ impl LetStmt {\n     }\n }\n \n-// Lifetime\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct Lifetime {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for Lifetime {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for Lifetime {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            LIFETIME => Some(Lifetime::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for Lifetime {\n-    type Owned = TreeArc<Lifetime>;\n-    fn to_owned(&self) -> TreeArc<Lifetime> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for Lifetime {}\n-impl Lifetime {}\n-\n // LifetimeArg\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -1832,11 +1600,7 @@ impl ToOwned for LifetimeArg {\n }\n \n \n-impl LifetimeArg {\n-    pub fn lifetime(&self) -> Option<&Lifetime> {\n-        super::child_opt(self)\n-    }\n-}\n+impl LifetimeArg {}\n \n // LifetimeParam\n #[derive(Debug, PartialEq, Eq, Hash)]\n@@ -1865,11 +1629,7 @@ impl ToOwned for LifetimeParam {\n \n \n impl ast::AttrsOwner for LifetimeParam {}\n-impl LifetimeParam {\n-    pub fn lifetime(&self) -> Option<&Lifetime> {\n-        super::child_opt(self)\n-    }\n-}\n+impl LifetimeParam {}\n \n // Literal\n #[derive(Debug, PartialEq, Eq, Hash)]\n@@ -1897,130 +1657,7 @@ impl ToOwned for Literal {\n }\n \n \n-impl Literal {\n-    pub fn literal_expr(&self) -> Option<&LiteralExpr> {\n-        super::child_opt(self)\n-    }\n-}\n-\n-// LiteralExpr\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct LiteralExpr {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for LiteralExpr {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n-pub enum LiteralExprKind<'a> {\n-    String(&'a String),\n-    ByteString(&'a ByteString),\n-    RawString(&'a RawString),\n-    RawByteString(&'a RawByteString),\n-    Char(&'a Char),\n-    Byte(&'a Byte),\n-    IntNumber(&'a IntNumber),\n-    FloatNumber(&'a FloatNumber),\n-    TrueKw(&'a TrueKw),\n-    FalseKw(&'a FalseKw),\n-}\n-impl<'a> From<&'a String> for &'a LiteralExpr {\n-    fn from(n: &'a String) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a ByteString> for &'a LiteralExpr {\n-    fn from(n: &'a ByteString) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a RawString> for &'a LiteralExpr {\n-    fn from(n: &'a RawString) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a RawByteString> for &'a LiteralExpr {\n-    fn from(n: &'a RawByteString) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a Char> for &'a LiteralExpr {\n-    fn from(n: &'a Char) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a Byte> for &'a LiteralExpr {\n-    fn from(n: &'a Byte) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a IntNumber> for &'a LiteralExpr {\n-    fn from(n: &'a IntNumber) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a FloatNumber> for &'a LiteralExpr {\n-    fn from(n: &'a FloatNumber) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a TrueKw> for &'a LiteralExpr {\n-    fn from(n: &'a TrueKw) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-impl<'a> From<&'a FalseKw> for &'a LiteralExpr {\n-    fn from(n: &'a FalseKw) -> &'a LiteralExpr {\n-        LiteralExpr::cast(&n.syntax).unwrap()\n-    }\n-}\n-\n-\n-impl AstNode for LiteralExpr {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            | STRING\n-            | BYTE_STRING\n-            | RAW_STRING\n-            | RAW_BYTE_STRING\n-            | CHAR\n-            | BYTE\n-            | INT_NUMBER\n-            | FLOAT_NUMBER\n-            | TRUE_KW\n-            | FALSE_KW => Some(LiteralExpr::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for LiteralExpr {\n-    type Owned = TreeArc<LiteralExpr>;\n-    fn to_owned(&self) -> TreeArc<LiteralExpr> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-impl LiteralExpr {\n-    pub fn kind(&self) -> LiteralExprKind {\n-        match self.syntax.kind() {\n-            STRING => LiteralExprKind::String(String::cast(&self.syntax).unwrap()),\n-            BYTE_STRING => LiteralExprKind::ByteString(ByteString::cast(&self.syntax).unwrap()),\n-            RAW_STRING => LiteralExprKind::RawString(RawString::cast(&self.syntax).unwrap()),\n-            RAW_BYTE_STRING => LiteralExprKind::RawByteString(RawByteString::cast(&self.syntax).unwrap()),\n-            CHAR => LiteralExprKind::Char(Char::cast(&self.syntax).unwrap()),\n-            BYTE => LiteralExprKind::Byte(Byte::cast(&self.syntax).unwrap()),\n-            INT_NUMBER => LiteralExprKind::IntNumber(IntNumber::cast(&self.syntax).unwrap()),\n-            FLOAT_NUMBER => LiteralExprKind::FloatNumber(FloatNumber::cast(&self.syntax).unwrap()),\n-            TRUE_KW => LiteralExprKind::TrueKw(TrueKw::cast(&self.syntax).unwrap()),\n-            FALSE_KW => LiteralExprKind::FalseKw(FalseKw::cast(&self.syntax).unwrap()),\n-            _ => unreachable!(),\n-        }\n-    }\n-}\n-\n-impl LiteralExpr {}\n+impl Literal {}\n \n // LiteralPat\n #[derive(Debug, PartialEq, Eq, Hash)]\n@@ -3404,64 +3041,6 @@ impl ToOwned for RangePat {\n \n impl RangePat {}\n \n-// RawByteString\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct RawByteString {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for RawByteString {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for RawByteString {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            RAW_BYTE_STRING => Some(RawByteString::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for RawByteString {\n-    type Owned = TreeArc<RawByteString>;\n-    fn to_owned(&self) -> TreeArc<RawByteString> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for RawByteString {}\n-impl RawByteString {}\n-\n-// RawString\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct RawString {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for RawString {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for RawString {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            RAW_STRING => Some(RawString::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for RawString {\n-    type Owned = TreeArc<RawString>;\n-    fn to_owned(&self) -> TreeArc<RawString> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for RawString {}\n-impl RawString {}\n-\n // RefExpr\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -3622,34 +3201,6 @@ impl ReturnExpr {\n     }\n }\n \n-// SelfKw\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct SelfKw {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for SelfKw {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for SelfKw {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            SELF_KW => Some(SelfKw::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for SelfKw {\n-    type Owned = TreeArc<SelfKw>;\n-    fn to_owned(&self) -> TreeArc<SelfKw> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl SelfKw {}\n-\n // SelfParam\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -3677,11 +3228,7 @@ impl ToOwned for SelfParam {\n \n \n impl ast::TypeAscriptionOwner for SelfParam {}\n-impl SelfParam {\n-    pub fn self_kw(&self) -> Option<&SelfKw> {\n-        super::child_opt(self)\n-    }\n-}\n+impl SelfParam {}\n \n // SlicePat\n #[derive(Debug, PartialEq, Eq, Hash)]\n@@ -3866,35 +3413,6 @@ impl Stmt {\n \n impl Stmt {}\n \n-// String\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct String {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for String {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for String {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            STRING => Some(String::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for String {\n-    type Owned = TreeArc<String>;\n-    fn to_owned(&self) -> TreeArc<String> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for String {}\n-impl String {}\n-\n // StructDef\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -4070,35 +3588,6 @@ impl TraitDef {\n     }\n }\n \n-// TrueKw\n-#[derive(Debug, PartialEq, Eq, Hash)]\n-#[repr(transparent)]\n-pub struct TrueKw {\n-    pub(crate) syntax: SyntaxNode,\n-}\n-unsafe impl TransparentNewType for TrueKw {\n-    type Repr = rowan::SyntaxNode<RaTypes>;\n-}\n-\n-impl AstNode for TrueKw {\n-    fn cast(syntax: &SyntaxNode) -> Option<&Self> {\n-        match syntax.kind() {\n-            TRUE_KW => Some(TrueKw::from_repr(syntax.into_repr())),\n-            _ => None,\n-        }\n-    }\n-    fn syntax(&self) -> &SyntaxNode { &self.syntax }\n-}\n-\n-impl ToOwned for TrueKw {\n-    type Owned = TreeArc<TrueKw>;\n-    fn to_owned(&self) -> TreeArc<TrueKw> { TreeArc::cast(self.syntax.to_owned()) }\n-}\n-\n-\n-impl ast::AstToken for TrueKw {}\n-impl TrueKw {}\n-\n // TryExpr\n #[derive(Debug, PartialEq, Eq, Hash)]\n #[repr(transparent)]\n@@ -4403,10 +3892,6 @@ impl TypeBound {\n     pub fn type_ref(&self) -> Option<&TypeRef> {\n         super::child_opt(self)\n     }\n-\n-    pub fn lifetime(&self) -> Option<&Lifetime> {\n-        super::child_opt(self)\n-    }\n }\n \n // TypeBoundList\n@@ -4847,10 +4332,6 @@ impl WherePred {\n     pub fn type_ref(&self) -> Option<&TypeRef> {\n         super::child_opt(self)\n     }\n-\n-    pub fn lifetime(&self) -> Option<&Lifetime> {\n-        super::child_opt(self)\n-    }\n }\n \n // WhileExpr"}, {"sha": "6d7a5a1cbc05417021466b3b941b3589eefd338e", "filename": "crates/ra_syntax/src/grammar.ron", "status": "modified", "additions": 2, "deletions": 33, "changes": 35, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fgrammar.ron?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -463,31 +463,7 @@ Grammar(\n         \"RangeExpr\": (),\n         \"BinExpr\": (),\n \n-        \"IntNumber\": ( traits: [\"AstToken\"] ),\n-        \"FloatNumber\": ( traits: [\"AstToken\"] ),\n-        \"String\": ( traits: [\"AstToken\"] ),\n-        \"RawString\": ( traits: [\"AstToken\"] ),\n-        \"Byte\": ( traits: [\"AstToken\"] ),\n-        \"RawByteString\": ( traits: [\"AstToken\"] ),\n-        \"ByteString\": ( traits: [\"AstToken\"] ),\n-        \"Char\": ( traits: [\"AstToken\"] ),\n-        \"TrueKw\": ( traits: [\"AstToken\"] ),\n-        \"FalseKw\": ( traits: [\"AstToken\"] ),\n-        \"LiteralExpr\": (\n-            enum: [\n-                \"String\",\n-                \"ByteString\",\n-                \"RawString\",\n-                \"RawByteString\",\n-                \"Char\",\n-                \"Byte\",\n-                \"IntNumber\",\n-                \"FloatNumber\",\n-                \"TrueKw\",\n-                \"FalseKw\",\n-            ]\n-        ),\n-        \"Literal\": (options: [\"LiteralExpr\"]),\n+        \"Literal\": (),\n \n         \"Expr\": (\n             enum: [\n@@ -580,14 +556,11 @@ Grammar(\n         ),\n         \"TypeParam\": ( traits: [\"NameOwner\", \"AttrsOwner\", \"TypeBoundsOwner\"] ),\n         \"LifetimeParam\": (\n-            options: [ \"Lifetime\"],\n             traits: [\"AttrsOwner\"],\n         ),\n-        \"Lifetime\": ( traits: [\"AstToken\"] ),\n         \"TypeBound\": (\n             options: [\n                 \"TypeRef\",\n-                \"Lifetime\",\n             ]\n         ),\n         \"TypeBoundList\": (\n@@ -598,7 +571,6 @@ Grammar(\n         \"WherePred\": (\n             options: [\n                 \"TypeRef\",\n-                \"Lifetime\",\n             ],\n             traits: [\n                 \"TypeBoundsOwner\",\n@@ -643,12 +615,10 @@ Grammar(\n             ]\n         ),\n         \"SelfParam\": (\n-            options: [\"SelfKw\"],\n             traits: [\n                 \"TypeAscriptionOwner\",\n             ]\n         ),\n-        \"SelfKw\": (),\n         \"Param\": (\n             options: [ \"Pat\" ],\n             traits: [\n@@ -692,8 +662,7 @@ Grammar(\n         ]),\n         \"TypeArg\": (options: [\"TypeRef\"]),\n         \"AssocTypeArg\": (options: [\"NameRef\", \"TypeRef\"]),\n-        \"LifetimeArg\": (options: [\"Lifetime\"]),\n-        \"Comment\": ( traits: [\"AstToken\"] ),\n+        \"LifetimeArg\": (),\n         \"Whitespace\": ( traits: [\"AstToken\"] ),\n     },\n )"}, {"sha": "e1088e2966869a8551041bcf4ec6c33a8589fda9", "filename": "crates/ra_syntax/src/lib.rs", "status": "modified", "additions": 20, "deletions": 14, "changes": 34, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Flib.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -38,7 +38,7 @@ pub use crate::{\n     ast::AstNode,\n     syntax_error::{SyntaxError, SyntaxErrorKind, Location},\n     syntax_text::SyntaxText,\n-    syntax_node::{Direction,  SyntaxNode, WalkEvent, TreeArc, SyntaxTreeBuilder},\n+    syntax_node::{Direction,  SyntaxNode, WalkEvent, TreeArc, SyntaxTreeBuilder, SyntaxElement, SyntaxToken},\n     ptr::{SyntaxNodePtr, AstPtr},\n     parsing::{tokenize, Token},\n };\n@@ -70,7 +70,7 @@ impl SourceFile {\n \n     pub fn incremental_reparse(&self, edit: &AtomTextEdit) -> Option<TreeArc<SourceFile>> {\n         parsing::incremental_reparse(self.syntax(), edit, self.errors())\n-            .map(|(green_node, errors)| SourceFile::new(green_node, errors))\n+            .map(|(green_node, errors, _reparsed_range)| SourceFile::new(green_node, errors))\n     }\n \n     fn full_reparse(&self, edit: &AtomTextEdit) -> TreeArc<SourceFile> {\n@@ -179,15 +179,23 @@ fn api_walkthrough() {\n \n     // There's a bunch of traversal methods on `SyntaxNode`:\n     assert_eq!(expr_syntax.parent(), Some(block.syntax()));\n-    assert_eq!(block.syntax().first_child().map(|it| it.kind()), Some(SyntaxKind::L_CURLY));\n-    assert_eq!(expr_syntax.next_sibling().map(|it| it.kind()), Some(SyntaxKind::WHITESPACE));\n+    assert_eq!(\n+        block.syntax().first_child_or_token().map(|it| it.kind()),\n+        Some(SyntaxKind::L_CURLY)\n+    );\n+    assert_eq!(\n+        expr_syntax.next_sibling_or_token().map(|it| it.kind()),\n+        Some(SyntaxKind::WHITESPACE)\n+    );\n \n     // As well as some iterator helpers:\n     let f = expr_syntax.ancestors().find_map(ast::FnDef::cast);\n     assert_eq!(f, Some(&*func));\n-    assert!(expr_syntax.siblings(Direction::Next).any(|it| it.kind() == SyntaxKind::R_CURLY));\n+    assert!(expr_syntax\n+        .siblings_with_tokens(Direction::Next)\n+        .any(|it| it.kind() == SyntaxKind::R_CURLY));\n     assert_eq!(\n-        expr_syntax.descendants().count(),\n+        expr_syntax.descendants_with_tokens().count(),\n         8, // 5 tokens `1`, ` `, `+`, ` `, `!`\n            // 2 child literal expressions: `1`, `1`\n            // 1 the node itself: `1 + 1`\n@@ -196,16 +204,14 @@ fn api_walkthrough() {\n     // There's also a `preorder` method with a more fine-grained iteration control:\n     let mut buf = String::new();\n     let mut indent = 0;\n-    for event in expr_syntax.preorder() {\n+    for event in expr_syntax.preorder_with_tokens() {\n         match event {\n             WalkEvent::Enter(node) => {\n-                buf += &format!(\n-                    \"{:indent$}{:?} {:?}\\n\",\n-                    \" \",\n-                    node.text(),\n-                    node.kind(),\n-                    indent = indent\n-                );\n+                let text = match node {\n+                    SyntaxElement::Node(it) => it.text().to_string(),\n+                    SyntaxElement::Token(it) => it.text().to_string(),\n+                };\n+                buf += &format!(\"{:indent$}{:?} {:?}\\n\", \" \", text, node.kind(), indent = indent);\n                 indent += 2;\n             }\n             WalkEvent::Leave(_) => indent -= 2,"}, {"sha": "69887f50063ded0597305f94171154cf356f04f7", "filename": "crates/ra_syntax/src/parsing/reparsing.rs", "status": "modified", "additions": 80, "deletions": 62, "changes": 142, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Freparsing.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -12,7 +12,7 @@ use ra_parser::Reparser;\n use crate::{\n     SyntaxKind::*, TextRange, TextUnit, SyntaxError,\n     algo,\n-    syntax_node::{GreenNode, SyntaxNode},\n+    syntax_node::{GreenNode, SyntaxNode, GreenToken, SyntaxElement},\n     parsing::{\n         text_token_source::TextTokenSource,\n         text_tree_sink::TextTreeSink,\n@@ -24,60 +24,62 @@ pub(crate) fn incremental_reparse(\n     node: &SyntaxNode,\n     edit: &AtomTextEdit,\n     errors: Vec<SyntaxError>,\n-) -> Option<(GreenNode, Vec<SyntaxError>)> {\n-    let (node, green, new_errors) =\n-        reparse_leaf(node, &edit).or_else(|| reparse_block(node, &edit))?;\n-    let green_root = node.replace_with(green);\n-    let errors = merge_errors(errors, new_errors, node, edit);\n-    Some((green_root, errors))\n+) -> Option<(GreenNode, Vec<SyntaxError>, TextRange)> {\n+    if let Some((green, old_range)) = reparse_token(node, &edit) {\n+        return Some((green, merge_errors(errors, Vec::new(), old_range, edit), old_range));\n+    }\n+\n+    if let Some((green, new_errors, old_range)) = reparse_block(node, &edit) {\n+        return Some((green, merge_errors(errors, new_errors, old_range, edit), old_range));\n+    }\n+    None\n }\n \n-fn reparse_leaf<'node>(\n+fn reparse_token<'node>(\n     root: &'node SyntaxNode,\n     edit: &AtomTextEdit,\n-) -> Option<(&'node SyntaxNode, GreenNode, Vec<SyntaxError>)> {\n-    let node = algo::find_covering_node(root, edit.delete);\n-    match node.kind() {\n+) -> Option<(GreenNode, TextRange)> {\n+    let token = algo::find_covering_element(root, edit.delete).as_token()?;\n+    match token.kind() {\n         WHITESPACE | COMMENT | IDENT | STRING | RAW_STRING => {\n-            if node.kind() == WHITESPACE || node.kind() == COMMENT {\n+            if token.kind() == WHITESPACE || token.kind() == COMMENT {\n                 // removing a new line may extends previous token\n-                if node.text().to_string()[edit.delete - node.range().start()].contains('\\n') {\n+                if token.text().to_string()[edit.delete - token.range().start()].contains('\\n') {\n                     return None;\n                 }\n             }\n \n-            let text = get_text_after_edit(node, &edit);\n-            let tokens = tokenize(&text);\n-            let token = match tokens[..] {\n-                [token] if token.kind == node.kind() => token,\n+            let text = get_text_after_edit(token.into(), &edit);\n+            let lex_tokens = tokenize(&text);\n+            let lex_token = match lex_tokens[..] {\n+                [lex_token] if lex_token.kind == token.kind() => lex_token,\n                 _ => return None,\n             };\n \n-            if token.kind == IDENT && is_contextual_kw(&text) {\n+            if lex_token.kind == IDENT && is_contextual_kw(&text) {\n                 return None;\n             }\n \n-            if let Some(next_char) = root.text().char_at(node.range().end()) {\n+            if let Some(next_char) = root.text().char_at(token.range().end()) {\n                 let tokens_with_next_char = tokenize(&format!(\"{}{}\", text, next_char));\n                 if tokens_with_next_char.len() == 1 {\n                     return None;\n                 }\n             }\n \n-            let green = GreenNode::new_leaf(node.kind(), text.into());\n-            let new_errors = vec![];\n-            Some((node, green, new_errors))\n+            let new_token = GreenToken::new(token.kind(), text.into());\n+            Some((token.replace_with(new_token), token.range()))\n         }\n         _ => None,\n     }\n }\n \n fn reparse_block<'node>(\n-    node: &'node SyntaxNode,\n+    root: &'node SyntaxNode,\n     edit: &AtomTextEdit,\n-) -> Option<(&'node SyntaxNode, GreenNode, Vec<SyntaxError>)> {\n-    let (node, reparser) = find_reparsable_node(node, edit.delete)?;\n-    let text = get_text_after_edit(node, &edit);\n+) -> Option<(GreenNode, Vec<SyntaxError>, TextRange)> {\n+    let (node, reparser) = find_reparsable_node(root, edit.delete)?;\n+    let text = get_text_after_edit(node.into(), &edit);\n     let tokens = tokenize(&text);\n     if !is_balanced(&tokens) {\n         return None;\n@@ -86,12 +88,16 @@ fn reparse_block<'node>(\n     let mut tree_sink = TextTreeSink::new(&text, &tokens);\n     reparser.parse(&token_source, &mut tree_sink);\n     let (green, new_errors) = tree_sink.finish();\n-    Some((node, green, new_errors))\n+    Some((node.replace_with(green), new_errors, node.range()))\n }\n \n-fn get_text_after_edit(node: &SyntaxNode, edit: &AtomTextEdit) -> String {\n-    let edit = AtomTextEdit::replace(edit.delete - node.range().start(), edit.insert.clone());\n-    edit.apply(node.text().to_string())\n+fn get_text_after_edit(element: SyntaxElement, edit: &AtomTextEdit) -> String {\n+    let edit = AtomTextEdit::replace(edit.delete - element.range().start(), edit.insert.clone());\n+    let text = match element {\n+        SyntaxElement::Token(token) => token.text().to_string(),\n+        SyntaxElement::Node(node) => node.text().to_string(),\n+    };\n+    edit.apply(text)\n }\n \n fn is_contextual_kw(text: &str) -> bool {\n@@ -102,9 +108,13 @@ fn is_contextual_kw(text: &str) -> bool {\n }\n \n fn find_reparsable_node(node: &SyntaxNode, range: TextRange) -> Option<(&SyntaxNode, Reparser)> {\n-    let node = algo::find_covering_node(node, range);\n-    node.ancestors().find_map(|node| {\n-        let first_child = node.first_child().map(|it| it.kind());\n+    let node = algo::find_covering_element(node, range);\n+    let mut ancestors = match node {\n+        SyntaxElement::Token(it) => it.parent().ancestors(),\n+        SyntaxElement::Node(it) => it.ancestors(),\n+    };\n+    ancestors.find_map(|node| {\n+        let first_child = node.first_child_or_token().map(|it| it.kind());\n         let parent = node.parent().map(|it| it.kind());\n         Reparser::for_node(node.kind(), first_child, parent).map(|r| (node, r))\n     })\n@@ -136,19 +146,19 @@ fn is_balanced(tokens: &[Token]) -> bool {\n fn merge_errors(\n     old_errors: Vec<SyntaxError>,\n     new_errors: Vec<SyntaxError>,\n-    old_node: &SyntaxNode,\n+    old_range: TextRange,\n     edit: &AtomTextEdit,\n ) -> Vec<SyntaxError> {\n     let mut res = Vec::new();\n     for e in old_errors {\n-        if e.offset() <= old_node.range().start() {\n+        if e.offset() <= old_range.start() {\n             res.push(e)\n-        } else if e.offset() >= old_node.range().end() {\n+        } else if e.offset() >= old_range.end() {\n             res.push(e.add_offset(TextUnit::of_str(&edit.insert), edit.delete.len()));\n         }\n     }\n     for e in new_errors {\n-        res.push(e.add_offset(old_node.range().start(), 0.into()));\n+        res.push(e.add_offset(old_range.start(), 0.into()));\n     }\n     res\n }\n@@ -160,13 +170,7 @@ mod tests {\n     use crate::{SourceFile, AstNode};\n     use super::*;\n \n-    fn do_check<F>(before: &str, replace_with: &str, reparser: F)\n-    where\n-        for<'a> F: Fn(\n-            &'a SyntaxNode,\n-            &AtomTextEdit,\n-        ) -> Option<(&'a SyntaxNode, GreenNode, Vec<SyntaxError>)>,\n-    {\n+    fn do_check(before: &str, replace_with: &str, reparsed_len: u32) {\n         let (range, before) = extract_range(before);\n         let edit = AtomTextEdit::replace(range, replace_with.to_owned());\n         let after = edit.apply(before.clone());\n@@ -175,30 +179,28 @@ mod tests {\n         let incrementally_reparsed = {\n             let f = SourceFile::parse(&before);\n             let edit = AtomTextEdit { delete: range, insert: replace_with.to_string() };\n-            let (node, green, new_errors) =\n-                reparser(f.syntax(), &edit).expect(\"cannot incrementally reparse\");\n-            let green_root = node.replace_with(green);\n-            let errors = super::merge_errors(f.errors(), new_errors, node, &edit);\n-            SourceFile::new(green_root, errors)\n+            let (green, new_errors, range) =\n+                incremental_reparse(f.syntax(), &edit, f.errors()).unwrap();\n+            assert_eq!(range.len(), reparsed_len.into(), \"reparsed fragment has wrong length\");\n+            SourceFile::new(green, new_errors)\n         };\n \n         assert_eq_text!(\n             &fully_reparsed.syntax().debug_dump(),\n             &incrementally_reparsed.syntax().debug_dump(),\n-        )\n+        );\n     }\n \n-    #[test]\n+    #[test] // FIXME: some test here actually test token reparsing\n     fn reparse_block_tests() {\n-        let do_check = |before, replace_to| do_check(before, replace_to, reparse_block);\n-\n         do_check(\n             r\"\n fn foo() {\n     let x = foo + <|>bar<|>\n }\n \",\n             \"baz\",\n+            3,\n         );\n         do_check(\n             r\"\n@@ -207,6 +209,7 @@ fn foo() {\n }\n \",\n             \"baz\",\n+            25,\n         );\n         do_check(\n             r\"\n@@ -215,6 +218,7 @@ struct Foo {\n }\n \",\n             \",\\n    g: (),\",\n+            14,\n         );\n         do_check(\n             r\"\n@@ -225,6 +229,7 @@ fn foo {\n }\n \",\n             \"62\",\n+            31, // FIXME: reparse only int literal here\n         );\n         do_check(\n             r\"\n@@ -233,14 +238,17 @@ mod foo {\n }\n \",\n             \"bar\",\n+            11,\n         );\n+\n         do_check(\n             r\"\n trait Foo {\n     type <|>Foo<|>;\n }\n \",\n             \"Output\",\n+            3,\n         );\n         do_check(\n             r\"\n@@ -249,26 +257,24 @@ impl IntoIterator<Item=i32> for Foo {\n }\n \",\n             \"n next(\",\n+            9,\n         );\n-        do_check(\n-            r\"\n-use a::b::{foo,<|>,bar<|>};\n-    \",\n-            \"baz\",\n-        );\n+        do_check(r\"use a::b::{foo,<|>,bar<|>};\", \"baz\", 10);\n         do_check(\n             r\"\n pub enum A {\n     Foo<|><|>\n }\n \",\n             \"\\nBar;\\n\",\n+            11,\n         );\n         do_check(\n             r\"\n foo!{a, b<|><|> d}\n \",\n             \", c[3]\",\n+            8,\n         );\n         do_check(\n             r\"\n@@ -277,6 +283,7 @@ fn foo() {\n }\n \",\n             \"123\",\n+            14,\n         );\n         do_check(\n             r\"\n@@ -285,79 +292,89 @@ extern {\n }\n \",\n             \" exit(code: c_int)\",\n+            11,\n         );\n     }\n \n     #[test]\n-    fn reparse_leaf_tests() {\n-        let do_check = |before, replace_to| do_check(before, replace_to, reparse_leaf);\n-\n+    fn reparse_token_tests() {\n         do_check(\n             r\"<|><|>\n fn foo() -> i32 { 1 }\n \",\n             \"\\n\\n\\n   \\n\",\n+            1,\n         );\n         do_check(\n             r\"\n fn foo() -> <|><|> {}\n \",\n             \"  \\n\",\n+            2,\n         );\n         do_check(\n             r\"\n fn <|>foo<|>() -> i32 { 1 }\n \",\n             \"bar\",\n+            3,\n         );\n         do_check(\n             r\"\n fn foo<|><|>foo() {  }\n \",\n             \"bar\",\n+            6,\n         );\n         do_check(\n             r\"\n fn foo /* <|><|> */ () {}\n \",\n             \"some comment\",\n+            6,\n         );\n         do_check(\n             r\"\n fn baz <|><|> () {}\n \",\n             \"    \\t\\t\\n\\n\",\n+            2,\n         );\n         do_check(\n             r\"\n fn baz <|><|> () {}\n \",\n             \"    \\t\\t\\n\\n\",\n+            2,\n         );\n         do_check(\n             r\"\n /// foo <|><|>omment\n mod { }\n \",\n             \"c\",\n+            14,\n         );\n         do_check(\n             r#\"\n fn -> &str { \"Hello<|><|>\" }\n \"#,\n             \", world\",\n+            7,\n         );\n         do_check(\n             r#\"\n fn -> &str { // \"Hello<|><|>\"\n \"#,\n             \", world\",\n+            10,\n         );\n         do_check(\n             r##\"\n fn -> &str { r#\"Hello<|><|>\"#\n \"##,\n             \", world\",\n+            10,\n         );\n         do_check(\n             r\"\n@@ -367,6 +384,7 @@ enum Foo {\n }\n \",\n             \"Clone\",\n+            4,\n         );\n     }\n }"}, {"sha": "71fc515f2ea3b495a109e9e749a5bce25417a925", "filename": "crates/ra_syntax/src/parsing/text_tree_sink.rs", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fparsing%2Ftext_tree_sink.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -28,10 +28,10 @@ enum State {\n }\n \n impl<'a> TreeSink for TextTreeSink<'a> {\n-    fn leaf(&mut self, kind: SyntaxKind, n_tokens: u8) {\n+    fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {\n         match mem::replace(&mut self.state, State::Normal) {\n             State::PendingStart => unreachable!(),\n-            State::PendingFinish => self.inner.finish_branch(),\n+            State::PendingFinish => self.inner.finish_node(),\n             State::Normal => (),\n         }\n         self.eat_trivias();\n@@ -40,18 +40,18 @@ impl<'a> TreeSink for TextTreeSink<'a> {\n             .iter()\n             .map(|it| it.len)\n             .sum::<TextUnit>();\n-        self.do_leaf(kind, len, n_tokens);\n+        self.do_token(kind, len, n_tokens);\n     }\n \n-    fn start_branch(&mut self, kind: SyntaxKind) {\n+    fn start_node(&mut self, kind: SyntaxKind) {\n         match mem::replace(&mut self.state, State::Normal) {\n             State::PendingStart => {\n-                self.inner.start_branch(kind);\n+                self.inner.start_node(kind);\n                 // No need to attach trivias to previous node: there is no\n                 // previous node.\n                 return;\n             }\n-            State::PendingFinish => self.inner.finish_branch(),\n+            State::PendingFinish => self.inner.finish_node(),\n             State::Normal => (),\n         }\n \n@@ -71,14 +71,14 @@ impl<'a> TreeSink for TextTreeSink<'a> {\n             n_attached_trivias(kind, leading_trivias)\n         };\n         self.eat_n_trivias(n_trivias - n_attached_trivias);\n-        self.inner.start_branch(kind);\n+        self.inner.start_node(kind);\n         self.eat_n_trivias(n_attached_trivias);\n     }\n \n-    fn finish_branch(&mut self) {\n+    fn finish_node(&mut self) {\n         match mem::replace(&mut self.state, State::PendingFinish) {\n             State::PendingStart => unreachable!(),\n-            State::PendingFinish => self.inner.finish_branch(),\n+            State::PendingFinish => self.inner.finish_node(),\n             State::Normal => (),\n         }\n     }\n@@ -104,7 +104,7 @@ impl<'a> TextTreeSink<'a> {\n         match mem::replace(&mut self.state, State::Normal) {\n             State::PendingFinish => {\n                 self.eat_trivias();\n-                self.inner.finish_branch()\n+                self.inner.finish_node()\n             }\n             State::PendingStart | State::Normal => unreachable!(),\n         }\n@@ -117,24 +117,24 @@ impl<'a> TextTreeSink<'a> {\n             if !token.kind.is_trivia() {\n                 break;\n             }\n-            self.do_leaf(token.kind, token.len, 1);\n+            self.do_token(token.kind, token.len, 1);\n         }\n     }\n \n     fn eat_n_trivias(&mut self, n: usize) {\n         for _ in 0..n {\n             let token = self.tokens[self.token_pos];\n             assert!(token.kind.is_trivia());\n-            self.do_leaf(token.kind, token.len, 1);\n+            self.do_token(token.kind, token.len, 1);\n         }\n     }\n \n-    fn do_leaf(&mut self, kind: SyntaxKind, len: TextUnit, n_tokens: usize) {\n+    fn do_token(&mut self, kind: SyntaxKind, len: TextUnit, n_tokens: usize) {\n         let range = TextRange::offset_len(self.text_pos, len);\n         let text: SmolStr = self.text[range].into();\n         self.text_pos += len;\n         self.token_pos += n_tokens;\n-        self.inner.leaf(kind, text);\n+        self.inner.token(kind, text);\n     }\n }\n "}, {"sha": "be181d0ae6302da1eef3f504d77d52eddde07592", "filename": "crates/ra_syntax/src/syntax_node.rs", "status": "modified", "additions": 258, "deletions": 29, "changes": 287, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fsyntax_node.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fsyntax_node.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fsyntax_node.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -29,6 +29,9 @@ impl Types for RaTypes {\n }\n \n pub(crate) type GreenNode = rowan::GreenNode<RaTypes>;\n+pub(crate) type GreenToken = rowan::GreenToken<RaTypes>;\n+#[allow(unused)]\n+pub(crate) type GreenElement = rowan::GreenElement<RaTypes>;\n \n /// Marker trait for CST and AST nodes\n pub trait SyntaxNodeWrapper: TransparentNewType<Repr = rowan::SyntaxNode<RaTypes>> {}\n@@ -113,11 +116,13 @@ impl ToOwned for SyntaxNode {\n \n impl fmt::Debug for SyntaxNode {\n     fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n-        write!(fmt, \"{:?}@{:?}\", self.kind(), self.range())?;\n-        if has_short_text(self.kind()) {\n-            write!(fmt, \" \\\"{}\\\"\", self.text())?;\n-        }\n-        Ok(())\n+        write!(fmt, \"{:?}@{:?}\", self.kind(), self.range())\n+    }\n+}\n+\n+impl fmt::Display for SyntaxNode {\n+    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n+        fmt::Display::fmt(&self.text(), fmt)\n     }\n }\n \n@@ -145,14 +150,6 @@ impl SyntaxNode {\n         SyntaxText::new(self)\n     }\n \n-    pub fn is_leaf(&self) -> bool {\n-        self.0.is_leaf()\n-    }\n-\n-    pub fn leaf_text(&self) -> Option<&SmolStr> {\n-        self.0.leaf_text()\n-    }\n-\n     pub fn parent(&self) -> Option<&SyntaxNode> {\n         self.0.parent().map(SyntaxNode::from_repr)\n     }\n@@ -161,22 +158,50 @@ impl SyntaxNode {\n         self.0.first_child().map(SyntaxNode::from_repr)\n     }\n \n+    pub fn first_child_or_token(&self) -> Option<SyntaxElement> {\n+        self.0.first_child_or_token().map(SyntaxElement::from)\n+    }\n+\n     pub fn last_child(&self) -> Option<&SyntaxNode> {\n         self.0.last_child().map(SyntaxNode::from_repr)\n     }\n \n+    pub fn last_child_or_token(&self) -> Option<SyntaxElement> {\n+        self.0.last_child_or_token().map(SyntaxElement::from)\n+    }\n+\n     pub fn next_sibling(&self) -> Option<&SyntaxNode> {\n         self.0.next_sibling().map(SyntaxNode::from_repr)\n     }\n \n+    pub fn next_sibling_or_token(&self) -> Option<SyntaxElement> {\n+        self.0.next_sibling_or_token().map(SyntaxElement::from)\n+    }\n+\n     pub fn prev_sibling(&self) -> Option<&SyntaxNode> {\n         self.0.prev_sibling().map(SyntaxNode::from_repr)\n     }\n \n+    pub fn prev_sibling_or_token(&self) -> Option<SyntaxElement> {\n+        self.0.prev_sibling_or_token().map(SyntaxElement::from)\n+    }\n+\n     pub fn children(&self) -> SyntaxNodeChildren {\n         SyntaxNodeChildren(self.0.children())\n     }\n \n+    pub fn children_with_tokens(&self) -> SyntaxElementChildren {\n+        SyntaxElementChildren(self.0.children_with_tokens())\n+    }\n+\n+    pub fn first_token(&self) -> Option<SyntaxToken> {\n+        self.0.first_token().map(SyntaxToken::from)\n+    }\n+\n+    pub fn last_token(&self) -> Option<SyntaxToken> {\n+        self.0.last_token().map(SyntaxToken::from)\n+    }\n+\n     pub fn ancestors(&self) -> impl Iterator<Item = &SyntaxNode> {\n         crate::algo::generate(Some(self), |&node| node.parent())\n     }\n@@ -188,20 +213,45 @@ impl SyntaxNode {\n         })\n     }\n \n+    pub fn descendants_with_tokens(&self) -> impl Iterator<Item = SyntaxElement> {\n+        self.preorder_with_tokens().filter_map(|event| match event {\n+            WalkEvent::Enter(it) => Some(it),\n+            WalkEvent::Leave(_) => None,\n+        })\n+    }\n+\n     pub fn siblings(&self, direction: Direction) -> impl Iterator<Item = &SyntaxNode> {\n         crate::algo::generate(Some(self), move |&node| match direction {\n             Direction::Next => node.next_sibling(),\n             Direction::Prev => node.prev_sibling(),\n         })\n     }\n \n+    pub fn siblings_with_tokens(\n+        &self,\n+        direction: Direction,\n+    ) -> impl Iterator<Item = SyntaxElement> {\n+        let me: SyntaxElement = self.into();\n+        crate::algo::generate(Some(me), move |el| match direction {\n+            Direction::Next => el.next_sibling_or_token(),\n+            Direction::Prev => el.prev_sibling_or_token(),\n+        })\n+    }\n+\n     pub fn preorder(&self) -> impl Iterator<Item = WalkEvent<&SyntaxNode>> {\n         self.0.preorder().map(|event| match event {\n             WalkEvent::Enter(n) => WalkEvent::Enter(SyntaxNode::from_repr(n)),\n             WalkEvent::Leave(n) => WalkEvent::Leave(SyntaxNode::from_repr(n)),\n         })\n     }\n \n+    pub fn preorder_with_tokens(&self) -> impl Iterator<Item = WalkEvent<SyntaxElement>> {\n+        self.0.preorder_with_tokens().map(|event| match event {\n+            WalkEvent::Enter(n) => WalkEvent::Enter(n.into()),\n+            WalkEvent::Leave(n) => WalkEvent::Leave(n.into()),\n+        })\n+    }\n+\n     pub fn memory_size_of_subtree(&self) -> usize {\n         self.0.memory_size_of_subtree()\n     }\n@@ -223,17 +273,20 @@ impl SyntaxNode {\n             };\n         }\n \n-        for event in self.preorder() {\n+        for event in self.preorder_with_tokens() {\n             match event {\n-                WalkEvent::Enter(node) => {\n+                WalkEvent::Enter(element) => {\n                     indent!();\n-                    writeln!(buf, \"{:?}\", node).unwrap();\n-                    if node.first_child().is_none() {\n-                        let off = node.range().end();\n-                        while err_pos < errors.len() && errors[err_pos].offset() <= off {\n-                            indent!();\n-                            writeln!(buf, \"err: `{}`\", errors[err_pos]).unwrap();\n-                            err_pos += 1;\n+                    match element {\n+                        SyntaxElement::Node(node) => writeln!(buf, \"{:?}\", node).unwrap(),\n+                        SyntaxElement::Token(token) => {\n+                            writeln!(buf, \"{:?}\", token).unwrap();\n+                            let off = token.range().end();\n+                            while err_pos < errors.len() && errors[err_pos].offset() <= off {\n+                                indent!();\n+                                writeln!(buf, \"err: `{}`\", errors[err_pos]).unwrap();\n+                                err_pos += 1;\n+                            }\n                         }\n                     }\n                     level += 1;\n@@ -255,7 +308,172 @@ impl SyntaxNode {\n     }\n \n     pub(crate) fn replace_with(&self, replacement: GreenNode) -> GreenNode {\n-        self.0.replace_self(replacement)\n+        self.0.replace_with(replacement)\n+    }\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Hash)]\n+pub struct SyntaxToken<'a>(pub(crate) rowan::SyntaxToken<'a, RaTypes>);\n+\n+//FIXME: always output text\n+impl<'a> fmt::Debug for SyntaxToken<'a> {\n+    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n+        write!(fmt, \"{:?}@{:?}\", self.kind(), self.range())?;\n+        if has_short_text(self.kind()) {\n+            write!(fmt, \" \\\"{}\\\"\", self.text())?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+impl<'a> fmt::Display for SyntaxToken<'a> {\n+    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n+        fmt::Display::fmt(self.text(), fmt)\n+    }\n+}\n+\n+impl<'a> From<rowan::SyntaxToken<'a, RaTypes>> for SyntaxToken<'a> {\n+    fn from(t: rowan::SyntaxToken<'a, RaTypes>) -> Self {\n+        SyntaxToken(t)\n+    }\n+}\n+\n+impl<'a> SyntaxToken<'a> {\n+    pub fn kind(&self) -> SyntaxKind {\n+        self.0.kind()\n+    }\n+\n+    pub fn text(&self) -> &'a SmolStr {\n+        self.0.text()\n+    }\n+\n+    pub fn range(&self) -> TextRange {\n+        self.0.range()\n+    }\n+\n+    pub fn parent(&self) -> &'a SyntaxNode {\n+        SyntaxNode::from_repr(self.0.parent())\n+    }\n+\n+    pub fn next_sibling_or_token(&self) -> Option<SyntaxElement<'a>> {\n+        self.0.next_sibling_or_token().map(SyntaxElement::from)\n+    }\n+\n+    pub fn prev_sibling_or_token(&self) -> Option<SyntaxElement<'a>> {\n+        self.0.prev_sibling_or_token().map(SyntaxElement::from)\n+    }\n+\n+    pub fn siblings_with_tokens(\n+        &self,\n+        direction: Direction,\n+    ) -> impl Iterator<Item = SyntaxElement<'a>> {\n+        let me: SyntaxElement = (*self).into();\n+        crate::algo::generate(Some(me), move |el| match direction {\n+            Direction::Next => el.next_sibling_or_token(),\n+            Direction::Prev => el.prev_sibling_or_token(),\n+        })\n+    }\n+\n+    pub fn next_token(&self) -> Option<SyntaxToken<'a>> {\n+        self.0.next_token().map(SyntaxToken::from)\n+    }\n+\n+    pub fn prev_token(&self) -> Option<SyntaxToken<'a>> {\n+        self.0.prev_token().map(SyntaxToken::from)\n+    }\n+\n+    pub(crate) fn replace_with(&self, new_token: GreenToken) -> GreenNode {\n+        self.0.replace_with(new_token)\n+    }\n+}\n+\n+#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]\n+pub enum SyntaxElement<'a> {\n+    Node(&'a SyntaxNode),\n+    Token(SyntaxToken<'a>),\n+}\n+\n+impl<'a> fmt::Display for SyntaxElement<'a> {\n+    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n+        match self {\n+            SyntaxElement::Node(it) => fmt::Display::fmt(it, fmt),\n+            SyntaxElement::Token(it) => fmt::Display::fmt(it, fmt),\n+        }\n+    }\n+}\n+\n+impl<'a> SyntaxElement<'a> {\n+    pub fn kind(&self) -> SyntaxKind {\n+        match self {\n+            SyntaxElement::Node(it) => it.kind(),\n+            SyntaxElement::Token(it) => it.kind(),\n+        }\n+    }\n+\n+    pub fn as_node(&self) -> Option<&'a SyntaxNode> {\n+        match self {\n+            SyntaxElement::Node(node) => Some(*node),\n+            SyntaxElement::Token(_) => None,\n+        }\n+    }\n+\n+    pub fn as_token(&self) -> Option<SyntaxToken<'a>> {\n+        match self {\n+            SyntaxElement::Node(_) => None,\n+            SyntaxElement::Token(token) => Some(*token),\n+        }\n+    }\n+\n+    pub fn next_sibling_or_token(&self) -> Option<SyntaxElement<'a>> {\n+        match self {\n+            SyntaxElement::Node(it) => it.next_sibling_or_token(),\n+            SyntaxElement::Token(it) => it.next_sibling_or_token(),\n+        }\n+    }\n+\n+    pub fn prev_sibling_or_token(&self) -> Option<SyntaxElement<'a>> {\n+        match self {\n+            SyntaxElement::Node(it) => it.prev_sibling_or_token(),\n+            SyntaxElement::Token(it) => it.prev_sibling_or_token(),\n+        }\n+    }\n+\n+    pub fn ancestors(&self) -> impl Iterator<Item = &'a SyntaxNode> {\n+        match self {\n+            SyntaxElement::Node(it) => it,\n+            SyntaxElement::Token(it) => it.parent(),\n+        }\n+        .ancestors()\n+    }\n+}\n+\n+impl<'a> From<rowan::SyntaxElement<'a, RaTypes>> for SyntaxElement<'a> {\n+    fn from(el: rowan::SyntaxElement<'a, RaTypes>) -> Self {\n+        match el {\n+            rowan::SyntaxElement::Node(n) => SyntaxElement::Node(SyntaxNode::from_repr(n)),\n+            rowan::SyntaxElement::Token(t) => SyntaxElement::Token(t.into()),\n+        }\n+    }\n+}\n+\n+impl<'a> From<&'a SyntaxNode> for SyntaxElement<'a> {\n+    fn from(node: &'a SyntaxNode) -> SyntaxElement<'a> {\n+        SyntaxElement::Node(node)\n+    }\n+}\n+\n+impl<'a> From<SyntaxToken<'a>> for SyntaxElement<'a> {\n+    fn from(token: SyntaxToken<'a>) -> SyntaxElement<'a> {\n+        SyntaxElement::Token(token)\n+    }\n+}\n+\n+impl<'a> SyntaxElement<'a> {\n+    pub fn range(&self) -> TextRange {\n+        match self {\n+            SyntaxElement::Node(it) => it.range(),\n+            SyntaxElement::Token(it) => it.range(),\n+        }\n     }\n }\n \n@@ -270,6 +488,17 @@ impl<'a> Iterator for SyntaxNodeChildren<'a> {\n     }\n }\n \n+#[derive(Debug)]\n+pub struct SyntaxElementChildren<'a>(rowan::SyntaxElementChildren<'a, RaTypes>);\n+\n+impl<'a> Iterator for SyntaxElementChildren<'a> {\n+    type Item = SyntaxElement<'a>;\n+\n+    fn next(&mut self) -> Option<SyntaxElement<'a>> {\n+        self.0.next().map(SyntaxElement::from)\n+    }\n+}\n+\n fn has_short_text(kind: SyntaxKind) -> bool {\n     use crate::SyntaxKind::*;\n     match kind {\n@@ -304,16 +533,16 @@ impl SyntaxTreeBuilder {\n         node\n     }\n \n-    pub fn leaf(&mut self, kind: SyntaxKind, text: SmolStr) {\n-        self.inner.leaf(kind, text)\n+    pub fn token(&mut self, kind: SyntaxKind, text: SmolStr) {\n+        self.inner.token(kind, text)\n     }\n \n-    pub fn start_branch(&mut self, kind: SyntaxKind) {\n-        self.inner.start_internal(kind)\n+    pub fn start_node(&mut self, kind: SyntaxKind) {\n+        self.inner.start_node(kind)\n     }\n \n-    pub fn finish_branch(&mut self) {\n-        self.inner.finish_internal()\n+    pub fn finish_node(&mut self) {\n+        self.inner.finish_node()\n     }\n \n     pub fn error(&mut self, error: ParseError, text_pos: TextUnit) {"}, {"sha": "6bb2ff461611493b793978ae611e27a67b3fdbc6", "filename": "crates/ra_syntax/src/syntax_text.rs", "status": "modified", "additions": 9, "deletions": 6, "changes": 15, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fsyntax_text.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fsyntax_text.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fsyntax_text.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,6 +1,6 @@\n use std::{fmt, ops};\n \n-use crate::{SyntaxNode, TextRange, TextUnit};\n+use crate::{SyntaxNode, TextRange, TextUnit, SyntaxElement};\n \n #[derive(Clone)]\n pub struct SyntaxText<'a> {\n@@ -15,11 +15,14 @@ impl<'a> SyntaxText<'a> {\n \n     pub fn chunks(&self) -> impl Iterator<Item = &'a str> {\n         let range = self.range;\n-        self.node.descendants().filter_map(move |node| {\n-            let text = node.leaf_text()?;\n-            let range = range.intersection(&node.range())?;\n-            let range = range - node.range().start();\n-            Some(&text[range])\n+        self.node.descendants_with_tokens().filter_map(move |el| match el {\n+            SyntaxElement::Token(t) => {\n+                let text = t.text();\n+                let range = range.intersection(&t.range())?;\n+                let range = range - t.range().start();\n+                Some(&text[range])\n+            }\n+            SyntaxElement::Node(_) => None,\n         })\n     }\n "}, {"sha": "fc534df83b954087d48ea1d6e82560504726594e", "filename": "crates/ra_syntax/src/validation.rs", "status": "modified", "additions": 13, "deletions": 5, "changes": 18, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fvalidation.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -6,7 +6,7 @@ mod block;\n \n use crate::{\n     SourceFile, SyntaxError, AstNode, SyntaxNode,\n-    SyntaxKind::{L_CURLY, R_CURLY},\n+    SyntaxKind::{L_CURLY, R_CURLY, BYTE, BYTE_STRING, STRING, CHAR},\n     ast,\n     algo::visit::{visitor_ctx, VisitorCtx},\n };\n@@ -15,16 +15,24 @@ pub(crate) fn validate(file: &SourceFile) -> Vec<SyntaxError> {\n     let mut errors = Vec::new();\n     for node in file.syntax().descendants() {\n         let _ = visitor_ctx(&mut errors)\n-            .visit::<ast::Byte, _>(byte::validate_byte_node)\n-            .visit::<ast::ByteString, _>(byte_string::validate_byte_string_node)\n-            .visit::<ast::Char, _>(char::validate_char_node)\n-            .visit::<ast::String, _>(string::validate_string_node)\n+            .visit::<ast::Literal, _>(validate_literal)\n             .visit::<ast::Block, _>(block::validate_block_node)\n             .accept(node);\n     }\n     errors\n }\n \n+// FIXME: kill duplication\n+fn validate_literal(literal: &ast::Literal, acc: &mut Vec<SyntaxError>) {\n+    match literal.token().kind() {\n+        BYTE => byte::validate_byte_node(literal.token(), acc),\n+        BYTE_STRING => byte_string::validate_byte_string_node(literal.token(), acc),\n+        STRING => string::validate_string_node(literal.token(), acc),\n+        CHAR => char::validate_char_node(literal.token(), acc),\n+        _ => (),\n+    }\n+}\n+\n pub(crate) fn validate_block_structure(root: &SyntaxNode) {\n     let mut stack = Vec::new();\n     for node in root.descendants() {"}, {"sha": "290f80fc651b96f68d109eb3459696f9f8a49d1a", "filename": "crates/ra_syntax/src/validation/byte.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,17 +1,17 @@\n //! Validation of byte literals\n \n use crate::{\n-    ast::{self, AstNode, AstToken},\n     string_lexing::{self, StringComponentKind},\n     TextRange,\n     validation::char,\n     SyntaxError,\n     SyntaxErrorKind::*,\n+    SyntaxToken,\n };\n \n-pub(super) fn validate_byte_node(node: &ast::Byte, errors: &mut Vec<SyntaxError>) {\n+pub(super) fn validate_byte_node(node: SyntaxToken, errors: &mut Vec<SyntaxError>) {\n     let literal_text = node.text();\n-    let literal_range = node.syntax().range();\n+    let literal_range = node.range();\n     let mut components = string_lexing::parse_byte_literal(literal_text);\n     let mut len = 0;\n     for component in &mut components {"}, {"sha": "eae395e9d8bfcd024c218d5071d56184b3b4fddc", "filename": "crates/ra_syntax/src/validation/byte_string.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte_string.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte_string.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fbyte_string.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,15 +1,15 @@\n use crate::{\n-    ast::{self, AstNode, AstToken},\n     string_lexing::{self, StringComponentKind},\n     SyntaxError,\n     SyntaxErrorKind::*,\n+    SyntaxToken,\n };\n \n use super::byte;\n \n-pub(crate) fn validate_byte_string_node(node: &ast::ByteString, errors: &mut Vec<SyntaxError>) {\n+pub(crate) fn validate_byte_string_node(node: SyntaxToken, errors: &mut Vec<SyntaxError>) {\n     let literal_text = node.text();\n-    let literal_range = node.syntax().range();\n+    let literal_range = node.range();\n     let mut components = string_lexing::parse_byte_string_literal(literal_text);\n     for component in &mut components {\n         let range = component.range + literal_range.start();"}, {"sha": "a385accddf054bd12c8b353a661d65f384e3dd84", "filename": "crates/ra_syntax/src/validation/char.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fchar.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fchar.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fchar.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -5,16 +5,16 @@ use std::u32;\n use arrayvec::ArrayString;\n \n use crate::{\n-    ast::{self, AstNode, AstToken},\n     string_lexing::{self, StringComponentKind},\n     TextRange,\n     SyntaxError,\n     SyntaxErrorKind::*,\n+    SyntaxToken,\n };\n \n-pub(super) fn validate_char_node(node: &ast::Char, errors: &mut Vec<SyntaxError>) {\n+pub(super) fn validate_char_node(node: SyntaxToken, errors: &mut Vec<SyntaxError>) {\n     let literal_text = node.text();\n-    let literal_range = node.syntax().range();\n+    let literal_range = node.range();\n     let mut components = string_lexing::parse_char_literal(literal_text);\n     let mut len = 0;\n     for component in &mut components {"}, {"sha": "f7f5c02c07d71d03070fefe0a26d3510bbc6948a", "filename": "crates/ra_syntax/src/validation/string.rs", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/rust-lang/rust/blob/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fstring.rs", "raw_url": "https://github.com/rust-lang/rust/raw/9e213385c9d06db3c8ca20812779e2b8f8ad2c71/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fstring.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fra_syntax%2Fsrc%2Fvalidation%2Fstring.rs?ref=9e213385c9d06db3c8ca20812779e2b8f8ad2c71", "patch": "@@ -1,15 +1,15 @@\n use crate::{\n-    ast::{self, AstNode, AstToken},\n     string_lexing,\n     SyntaxError,\n     SyntaxErrorKind::*,\n+    SyntaxToken,\n };\n \n use super::char;\n \n-pub(crate) fn validate_string_node(node: &ast::String, errors: &mut Vec<SyntaxError>) {\n+pub(crate) fn validate_string_node(node: SyntaxToken, errors: &mut Vec<SyntaxError>) {\n     let literal_text = node.text();\n-    let literal_range = node.syntax().range();\n+    let literal_range = node.range();\n     let mut components = string_lexing::parse_string_literal(literal_text);\n     for component in &mut components {\n         let range = component.range + literal_range.start();"}]}