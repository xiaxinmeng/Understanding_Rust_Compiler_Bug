{"sha": "48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "node_id": "C_kwDOAAsO6NoAKDQ4YmViZWFhMzJkMWUwZWI1MzMzNmI4MGYxNGQ4Njk1ZjNjZGQzMGE", "commit": {"author": {"name": "hamidreza kalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2021-09-23T12:58:21Z"}, "committer": {"name": "hamidreza kalbasi", "email": "hamidrezakalbasi@protonmail.com", "date": "2021-09-26T06:34:02Z"}, "message": "support goto definition and find references", "tree": {"sha": "ff3519390ccbbaecae6fc1d06965c8d99dde3239", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/ff3519390ccbbaecae6fc1d06965c8d99dde3239"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "html_url": "https://github.com/rust-lang/rust/commit/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/comments", "author": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "committer": {"login": "HKalbasi", "id": 45197576, "node_id": "MDQ6VXNlcjQ1MTk3NTc2", "avatar_url": "https://avatars.githubusercontent.com/u/45197576?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HKalbasi", "html_url": "https://github.com/HKalbasi", "followers_url": "https://api.github.com/users/HKalbasi/followers", "following_url": "https://api.github.com/users/HKalbasi/following{/other_user}", "gists_url": "https://api.github.com/users/HKalbasi/gists{/gist_id}", "starred_url": "https://api.github.com/users/HKalbasi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HKalbasi/subscriptions", "organizations_url": "https://api.github.com/users/HKalbasi/orgs", "repos_url": "https://api.github.com/users/HKalbasi/repos", "events_url": "https://api.github.com/users/HKalbasi/events{/privacy}", "received_events_url": "https://api.github.com/users/HKalbasi/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f2775ac2e955218321e9dce2ca0580e3e6e505bb", "url": "https://api.github.com/repos/rust-lang/rust/commits/f2775ac2e955218321e9dce2ca0580e3e6e505bb", "html_url": "https://github.com/rust-lang/rust/commit/f2775ac2e955218321e9dce2ca0580e3e6e505bb"}], "stats": {"total": 208, "additions": 163, "deletions": 45}, "files": [{"sha": "f3e3cab1d6e1436d14eb1612c6814c3244ea5e19", "filename": ".gitignore", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/.gitignore", "raw_url": "https://github.com/rust-lang/rust/raw/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/.gitignore", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/.gitignore?ref=48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "patch": "@@ -11,3 +11,5 @@ generated_assists.adoc\n generated_features.adoc\n generated_diagnostic.adoc\n .DS_Store\n+/out/\n+/dump.lsif"}, {"sha": "dbfa99bdf240174355b0e049ad1abefc3610a450", "filename": "crates/ide/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Fide%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Fide%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Flib.rs?ref=48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "patch": "@@ -87,7 +87,7 @@ pub use crate::{\n     references::ReferenceSearchResult,\n     rename::RenameError,\n     runnables::{Runnable, RunnableKind, TestId},\n-    static_index::{StaticIndex, StaticIndexedFile, TokenStaticData, TokenId},\n+    static_index::{StaticIndex, StaticIndexedFile, TokenId, TokenStaticData},\n     syntax_highlighting::{\n         tags::{Highlight, HlMod, HlMods, HlOperator, HlPunct, HlTag},\n         HlRange,"}, {"sha": "55a6710fcf4f4296ce95f6b56df8317c19e58749", "filename": "crates/ide/src/static_index.rs", "status": "modified", "additions": 59, "deletions": 30, "changes": 89, "blob_url": "https://github.com/rust-lang/rust/blob/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Fide%2Fsrc%2Fstatic_index.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Fide%2Fsrc%2Fstatic_index.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fide%2Fsrc%2Fstatic_index.rs?ref=48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "patch": "@@ -3,15 +3,17 @@\n \n use std::collections::HashMap;\n \n+use hir::Semantics;\n use hir::{db::HirDatabase, Crate, Module};\n-use ide_db::base_db::{FileId, SourceDatabaseExt};\n-use ide_db::RootDatabase;\n+use ide_db::base_db::{FileId, FileRange, SourceDatabaseExt};\n use ide_db::defs::Definition;\n+use ide_db::RootDatabase;\n use rustc_hash::FxHashSet;\n-use syntax::TextRange;\n use syntax::{AstNode, SyntaxKind::*, T};\n+use syntax::{SyntaxToken, TextRange};\n \n-use crate::hover::{get_definition_of_token, hover_for_definition};\n+use crate::display::TryToNav;\n+use crate::hover::hover_for_definition;\n use crate::{Analysis, Cancellable, Fold, HoverConfig, HoverDocFormat, HoverResult};\n \n /// A static representation of fully analyzed source code.\n@@ -25,8 +27,15 @@ pub struct StaticIndex<'a> {\n     def_map: HashMap<Definition, TokenId>,\n }\n \n+pub struct ReferenceData {\n+    pub range: FileRange,\n+    pub is_definition: bool,\n+}\n+\n pub struct TokenStaticData {\n     pub hover: Option<HoverResult>,\n+    pub definition: Option<FileRange>,\n+    pub references: Vec<ReferenceData>,\n }\n \n #[derive(Clone, Copy, PartialEq, Eq, Hash)]\n@@ -42,14 +51,16 @@ impl TokenStore {\n         id\n     }\n \n+    pub fn get_mut(&mut self, id: TokenId) -> Option<&mut TokenStaticData> {\n+        self.0.get_mut(id.0)\n+    }\n+\n     pub fn get(&self, id: TokenId) -> Option<&TokenStaticData> {\n         self.0.get(id.0)\n     }\n-    \n-    pub fn iter(self) -> impl Iterator<Item=(TokenId, TokenStaticData)> {\n-        self.0.into_iter().enumerate().map(|(i, x)| {\n-            (TokenId(i), x)\n-        })\n+\n+    pub fn iter(self) -> impl Iterator<Item = (TokenId, TokenStaticData)> {\n+        self.0.into_iter().enumerate().map(|(i, x)| (TokenId(i), x))\n     }\n }\n \n@@ -84,26 +95,15 @@ impl StaticIndex<'_> {\n         });\n         let hover_config =\n             HoverConfig { links_in_hover: true, documentation: Some(HoverDocFormat::Markdown) };\n-        let tokens = tokens\n-            .filter(|token| match token.kind() {\n-                IDENT\n-                | INT_NUMBER\n-                | LIFETIME_IDENT\n-                | T![self]\n-                | T![super]\n-                | T![crate] => true,\n-                _ => false,\n-            });\n-        let mut result = StaticIndexedFile {\n-            file_id,\n-            folds,\n-            tokens: vec![],\n-        };\n+        let tokens = tokens.filter(|token| match token.kind() {\n+            IDENT | INT_NUMBER | LIFETIME_IDENT | T![self] | T![super] | T![crate] => true,\n+            _ => false,\n+        });\n+        let mut result = StaticIndexedFile { file_id, folds, tokens: vec![] };\n         for token in tokens {\n             let range = token.text_range();\n             let node = token.parent().unwrap();\n-            let def = get_definition_of_token(self.db, &sema, &sema.descend_into_macros(token), file_id, range.start(), &mut None);\n-            let def = if let Some(x) = def {\n+            let def = if let Some(x) = get_definition(&sema, token.clone()) {\n                 x\n             } else {\n                 continue;\n@@ -112,18 +112,34 @@ impl StaticIndex<'_> {\n                 *x\n             } else {\n                 let x = self.tokens.insert(TokenStaticData {\n-                    hover: hover_for_definition(self.db, file_id, &sema, def, node, &hover_config),\n+                    hover: hover_for_definition(&sema, file_id, def, &node, &hover_config),\n+                    definition: def\n+                        .try_to_nav(self.db)\n+                        .map(|x| FileRange { file_id: x.file_id, range: x.focus_or_full_range() }),\n+                    references: vec![],\n                 });\n                 self.def_map.insert(def, x);\n                 x\n             };\n+            let token = self.tokens.get_mut(id).unwrap();\n+            token.references.push(ReferenceData {\n+                range: FileRange { range, file_id },\n+                is_definition: if let Some(x) = def.try_to_nav(self.db) {\n+                    x.file_id == file_id && x.focus_or_full_range() == range\n+                } else {\n+                    false\n+                },\n+            });\n             result.tokens.push((range, id));\n         }\n         self.files.push(result);\n         Ok(())\n     }\n-    \n-    pub fn compute<'a>(db: &'a RootDatabase, analysis: &'a Analysis) -> Cancellable<StaticIndex<'a>> {\n+\n+    pub fn compute<'a>(\n+        db: &'a RootDatabase,\n+        analysis: &'a Analysis,\n+    ) -> Cancellable<StaticIndex<'a>> {\n         let work = all_modules(db).into_iter().filter(|module| {\n             let file_id = module.definition_source(db).file_id.original_file(db);\n             let source_root = db.file_source_root(file_id);\n@@ -133,7 +149,8 @@ impl StaticIndex<'_> {\n         let mut this = StaticIndex {\n             files: vec![],\n             tokens: Default::default(),\n-            analysis, db,\n+            analysis,\n+            db,\n             def_map: Default::default(),\n         };\n         let mut visited_files = FxHashSet::default();\n@@ -150,3 +167,15 @@ impl StaticIndex<'_> {\n         Ok(this)\n     }\n }\n+\n+fn get_definition(sema: &Semantics<RootDatabase>, token: SyntaxToken) -> Option<Definition> {\n+    for token in sema.descend_into_macros_many(token) {\n+        let def = Definition::from_token(&sema, &token);\n+        if let [x] = def.as_slice() {\n+            return Some(*x);\n+        } else {\n+            continue;\n+        };\n+    }\n+    None\n+}"}, {"sha": "f7be8374ca6e90d93f00d1ff40a76d7333a4678a", "filename": "crates/rust-analyzer/src/cli/lsif.rs", "status": "modified", "additions": 101, "deletions": 14, "changes": 115, "blob_url": "https://github.com/rust-lang/rust/blob/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs", "raw_url": "https://github.com/rust-lang/rust/raw/48bebeaa32d1e0eb53336b80f14d8695f3cdd30a/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Frust-analyzer%2Fsrc%2Fcli%2Flsif.rs?ref=48bebeaa32d1e0eb53336b80f14d8695f3cdd30a", "patch": "@@ -4,7 +4,10 @@ use std::collections::HashMap;\n use std::env;\n use std::time::Instant;\n \n-use ide::{Analysis, Cancellable, RootDatabase, StaticIndex, StaticIndexedFile, TokenId, TokenStaticData};\n+use ide::{\n+    Analysis, Cancellable, FileId, FileRange, RootDatabase, StaticIndex, StaticIndexedFile,\n+    TokenId, TokenStaticData,\n+};\n use ide_db::LineIndexDatabase;\n \n use ide_db::base_db::salsa::{self, ParallelDatabase};\n@@ -31,6 +34,8 @@ impl<DB: ParallelDatabase> Clone for Snap<salsa::Snapshot<DB>> {\n struct LsifManager<'a> {\n     count: i32,\n     token_map: HashMap<TokenId, Id>,\n+    range_map: HashMap<FileRange, Id>,\n+    file_map: HashMap<FileId, Id>,\n     analysis: &'a Analysis,\n     db: &'a RootDatabase,\n     vfs: &'a Vfs,\n@@ -50,12 +55,14 @@ impl LsifManager<'_> {\n         LsifManager {\n             count: 0,\n             token_map: HashMap::default(),\n+            range_map: HashMap::default(),\n+            file_map: HashMap::default(),\n             analysis,\n             db,\n             vfs,\n         }\n     }\n-    \n+\n     fn add(&mut self, data: Element) -> Id {\n         let id = Id(self.count);\n         self.emit(&serde_json::to_string(&Entry { id: id.into(), data }).unwrap());\n@@ -68,9 +75,54 @@ impl LsifManager<'_> {\n         println!(\"{}\", data);\n     }\n \n-    fn add_token(&mut self, id: TokenId, token: TokenStaticData) {\n+    fn get_token_id(&mut self, id: TokenId) -> Id {\n+        if let Some(x) = self.token_map.get(&id) {\n+            return *x;\n+        }\n         let result_set_id = self.add(Element::Vertex(Vertex::ResultSet(ResultSet { key: None })));\n         self.token_map.insert(id, result_set_id);\n+        result_set_id\n+    }\n+\n+    fn get_range_id(&mut self, id: FileRange) -> Cancellable<Id> {\n+        if let Some(x) = self.range_map.get(&id) {\n+            return Ok(*x);\n+        }\n+        let file_id = id.file_id;\n+        let doc_id = self.get_file_id(file_id);\n+        let line_index = self.db.line_index(file_id);\n+        let line_index = LineIndex {\n+            index: line_index.clone(),\n+            encoding: OffsetEncoding::Utf16,\n+            endings: LineEndings::Unix,\n+        };\n+        let range_id = self.add(Element::Vertex(Vertex::Range {\n+            range: to_proto::range(&line_index, id.range),\n+            tag: None,\n+        }));\n+        self.add(Element::Edge(Edge::Contains(EdgeDataMultiIn {\n+            in_vs: vec![range_id.into()],\n+            out_v: doc_id.into(),\n+        })));\n+        Ok(range_id)\n+    }\n+\n+    fn get_file_id(&mut self, id: FileId) -> Id {\n+        if let Some(x) = self.file_map.get(&id) {\n+            return *x;\n+        }\n+        let path = self.vfs.file_path(id);\n+        let path = path.as_path().unwrap();\n+        let doc_id = self.add(Element::Vertex(Vertex::Document(Document {\n+            language_id: \"rust\".to_string(),\n+            uri: lsp_types::Url::from_file_path(path).unwrap(),\n+        })));\n+        self.file_map.insert(id, doc_id);\n+        doc_id\n+    }\n+\n+    fn add_token(&mut self, id: TokenId, token: TokenStaticData) -> Cancellable<()> {\n+        let result_set_id = self.get_token_id(id);\n         if let Some(hover) = token.hover {\n             let hover_id = self.add(Element::Vertex(Vertex::HoverResult {\n                 result: Hover {\n@@ -83,16 +135,50 @@ impl LsifManager<'_> {\n                 out_v: result_set_id.into(),\n             })));\n         }\n+        if let Some(def) = token.definition {\n+            let result_id = self.add(Element::Vertex(Vertex::DefinitionResult));\n+            let def_vertex = self.get_range_id(def)?;\n+            self.add(Element::Edge(Edge::Item(Item {\n+                document: (*self.file_map.get(&def.file_id).unwrap()).into(),\n+                property: None,\n+                edge_data: EdgeDataMultiIn {\n+                    in_vs: vec![def_vertex.into()],\n+                    out_v: result_id.into(),\n+                },\n+            })));\n+            self.add(Element::Edge(Edge::Definition(EdgeData {\n+                in_v: result_id.into(),\n+                out_v: result_set_id.into(),\n+            })));\n+        }\n+        if !token.references.is_empty() {\n+            let result_id = self.add(Element::Vertex(Vertex::ReferenceResult));\n+            self.add(Element::Edge(Edge::References(EdgeData {\n+                in_v: result_id.into(),\n+                out_v: result_set_id.into(),\n+            })));\n+            for x in token.references {\n+                let vertex = *self.range_map.get(&x.range).unwrap();\n+                self.add(Element::Edge(Edge::Item(Item {\n+                    document: (*self.file_map.get(&x.range.file_id).unwrap()).into(),\n+                    property: Some(if x.is_definition {\n+                        ItemKind::Definitions\n+                    } else {\n+                        ItemKind::References\n+                    }),\n+                    edge_data: EdgeDataMultiIn {\n+                        in_vs: vec![vertex.into()],\n+                        out_v: result_id.into(),\n+                    },\n+                })));\n+            }\n+        }\n+        Ok(())\n     }\n \n     fn add_file(&mut self, file: StaticIndexedFile) -> Cancellable<()> {\n-        let StaticIndexedFile { file_id, tokens, folds} = file;\n-        let path = self.vfs.file_path(file_id);\n-        let path = path.as_path().unwrap();\n-        let doc_id = self.add(Element::Vertex(Vertex::Document(Document {\n-            language_id: \"rust\".to_string(),\n-            uri: lsp_types::Url::from_file_path(path).unwrap(),\n-        })));\n+        let StaticIndexedFile { file_id, tokens, folds } = file;\n+        let doc_id = self.get_file_id(file_id);\n         let text = self.analysis.file_text(file_id)?;\n         let line_index = self.db.line_index(file_id);\n         let line_index = LineIndex {\n@@ -116,7 +202,8 @@ impl LsifManager<'_> {\n                     range: to_proto::range(&line_index, range),\n                     tag: None,\n                 }));\n-                let result_set_id = *self.token_map.get(&id).expect(\"token map doesn't contain id\");\n+                self.range_map.insert(FileRange { file_id, range }, range_id);\n+                let result_set_id = self.get_token_id(id);\n                 self.add(Element::Edge(Edge::Next(EdgeData {\n                     in_v: result_set_id.into(),\n                     out_v: range_id.into(),\n@@ -161,12 +248,12 @@ impl flags::Lsif {\n             position_encoding: Encoding::Utf16,\n             tool_info: None,\n         })));\n-        for (id, token) in si.tokens.iter() {\n-            lsif.add_token(id, token);\n-        }\n         for file in si.files {\n             lsif.add_file(file)?;\n         }\n+        for (id, token) in si.tokens.iter() {\n+            lsif.add_token(id, token)?;\n+        }\n         eprintln!(\"Generating LSIF finished in {:?}\", now.elapsed());\n         Ok(())\n     }"}]}