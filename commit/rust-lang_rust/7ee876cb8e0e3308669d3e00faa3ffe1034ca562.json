{"sha": "7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "node_id": "MDY6Q29tbWl0NzI0NzEyOjdlZTg3NmNiOGUwZTMzMDg2NjlkM2UwMGZhYTNmZmUxMDM0Y2E1NjI=", "commit": {"author": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-09-05T02:15:41Z"}, "committer": {"name": "bors", "email": "bors@rust-lang.org", "date": "2015-09-05T02:15:41Z"}, "message": "Auto merge of #28221 - huonw:simd, r=alexcrichton\n\nThe ARM equivalents of the AArch64 are annoyingly more complicated (and some of the AArch64 ones are too).\r\n\r\nI think I've got exposed all the x86 intrinsics from SSE to AVX2 now (at least, the ones that LLVM implements as callable intrinsics).", "tree": {"sha": "f819386845dc1a31741740867e09f695d411ca23", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/f819386845dc1a31741740867e09f695d411ca23"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "html_url": "https://github.com/rust-lang/rust/commit/7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/comments", "author": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "committer": {"login": "bors", "id": 3372342, "node_id": "MDQ6VXNlcjMzNzIzNDI=", "avatar_url": "https://avatars.githubusercontent.com/u/3372342?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors", "html_url": "https://github.com/bors", "followers_url": "https://api.github.com/users/bors/followers", "following_url": "https://api.github.com/users/bors/following{/other_user}", "gists_url": "https://api.github.com/users/bors/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors/subscriptions", "organizations_url": "https://api.github.com/users/bors/orgs", "repos_url": "https://api.github.com/users/bors/repos", "events_url": "https://api.github.com/users/bors/events{/privacy}", "received_events_url": "https://api.github.com/users/bors/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "779b2a9847319106647dcad12fc6dc472bc0cf4d", "url": "https://api.github.com/repos/rust-lang/rust/commits/779b2a9847319106647dcad12fc6dc472bc0cf4d", "html_url": "https://github.com/rust-lang/rust/commit/779b2a9847319106647dcad12fc6dc472bc0cf4d"}, {"sha": "67aa4c775ac90342440bb5f2af3b023d3c0f3042", "url": "https://api.github.com/repos/rust-lang/rust/commits/67aa4c775ac90342440bb5f2af3b023d3c0f3042", "html_url": "https://github.com/rust-lang/rust/commit/67aa4c775ac90342440bb5f2af3b023d3c0f3042"}], "stats": {"total": 1536, "additions": 1421, "deletions": 115}, "files": [{"sha": "79fd7699428895bf2191ba22f4bc1a062919c38a", "filename": "src/etc/platform-intrinsics/aarch64.json", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Faarch64.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -336,6 +336,48 @@\n             \"ret\": \"i8\",\n             \"args\": [\"0\"]\n         },\n+        {\n+            \"intrinsic\": \"ld2{0[0].width}_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld2.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);2]\",\"[f(32-64);2]\"],\n+            \"args\": [\"0.0SPc/0.0\"]\n+        },\n+        {\n+            \"intrinsic\": \"ld3{0[0].width}_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld3.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);3]\",\"[f(32-64);3]\"],\n+            \"args\": [\"0.0SPc/0.0\"]\n+        },\n+        {\n+            \"intrinsic\": \"ld4{0[0].width}_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld4.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);4]\",\"[f(32-64);4]\"],\n+            \"args\": [\"0.0SPc/0.0\"]\n+        },\n+        {\n+            \"intrinsic\": \"ld2{0[0].width}_dup_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld2.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);2]\",\"[f(32-64);2]\"],\n+            \"args\": [\"0.0SPc\"]\n+        },\n+        {\n+            \"intrinsic\": \"ld3{0[0].width}_dup_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld3.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);3]\",\"[f(32-64);3]\"],\n+            \"args\": [\"0.0SPc\"]\n+        },\n+        {\n+            \"intrinsic\": \"ld4{0[0].width}_dup_{0[0].data_type}\",\n+            \"width\": [64, 128],\n+            \"llvm\": \"ld4.{0[0].llvm_name}.{1.llvm_name}\",\n+            \"ret\": [\"[i(8-64);4]\",\"[f(32-64);4]\"],\n+            \"args\": [\"0.0SPc\"]\n+        },\n         {\n             \"intrinsic\": \"padd{0.width}_{0.data_type}\",\n             \"width\": [64, 128],"}, {"sha": "d1217c1fb2b4a916b8882c5f8ac0ff1ae2172a2b", "filename": "src/etc/platform-intrinsics/generator.py", "status": "modified", "additions": 320, "deletions": 89, "changes": 409, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fgenerator.py?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -14,11 +14,13 @@\n import sys\n import re\n import textwrap\n+import itertools\n \n SPEC = re.compile(\n-    r'^(?:(?P<id>[iusfIUSF])(?:\\((?P<start>\\d+)-(?P<end>\\d+)\\)|'\n+    r'^(?:(?P<void>V)|(?P<id>[iusfIUSF])(?:\\((?P<start>\\d+)-(?P<end>\\d+)\\)|'\n     r'(?P<width>\\d+)(:?/(?P<llvm_width>\\d+))?)'\n-    r'|(?P<reference>\\d+)(?P<modifiers>[vShdnwus]*)(?P<force_width>x\\d+)?)$'\n+    r'|(?P<reference>\\d+))(?P<index>\\.\\d+)?(?P<modifiers>[vShdnwusfDMC]*)(?P<force_width>x\\d+)?'\n+    r'(?:(?P<pointer>Pm|Pc)(?P<llvm_pointer>/.*)?|(?P<bitcast>->.*))?$'\n )\n \n class PlatformInfo(object):\n@@ -68,37 +70,75 @@ def lookup(raw):\n                                 {k: lookup(v) for k, v in data.items()})\n \n class PlatformTypeInfo(object):\n-    def __init__(self, llvm_name, properties):\n-        self.properties = properties\n-        self.llvm_name = llvm_name\n+    def __init__(self, llvm_name, properties, elems = None):\n+        if elems is None:\n+            self.properties = properties\n+            self.llvm_name = llvm_name\n+        else:\n+            assert properties is None and llvm_name is None\n+            self.properties = {}\n+            self.elems = elems\n+\n+    def __repr__(self):\n+        return '<PlatformTypeInfo {}, {}>'.format(self.llvm_name, self.properties)\n \n     def __getattr__(self, name):\n         return self.properties[name]\n \n+    def __getitem__(self, idx):\n+        return self.elems[idx]\n+\n     def vectorize(self, length, width_info):\n         props = self.properties.copy()\n         props.update(width_info)\n         return PlatformTypeInfo('v{}{}'.format(length, self.llvm_name), props)\n \n+    def pointer(self, llvm_elem):\n+        name = self.llvm_name if llvm_elem is None else llvm_elem.llvm_name\n+        return PlatformTypeInfo('p0{}'.format(name), self.properties)\n+\n+BITWIDTH_POINTER = '<pointer>'\n+\n class Type(object):\n     def __init__(self, bitwidth):\n         self._bitwidth = bitwidth\n \n     def bitwidth(self):\n         return self._bitwidth\n \n-    def modify(self, spec, width):\n+    def modify(self, spec, width, previous):\n         raise NotImplementedError()\n \n+    def __ne__(self, other):\n+        return not (self == other)\n+\n+class Void(Type):\n+    def __init__(self):\n+        Type.__init__(self, 0)\n+\n+    def compiler_ctor(self):\n+        return 'void()'\n+\n+    def rust_name(self):\n+        return '()'\n+\n+    def type_info(self, platform_info):\n+        return None\n+\n+    def __eq__(self, other):\n+        return isinstance(other, Void)\n+\n class Number(Type):\n     def __init__(self, bitwidth):\n         Type.__init__(self, bitwidth)\n \n-    def modify(self, spec, width):\n+    def modify(self, spec, width, previous):\n         if spec == 'u':\n             return Unsigned(self.bitwidth())\n         elif spec == 's':\n             return Signed(self.bitwidth())\n+        elif spec == 'f':\n+            return Float(self.bitwidth())\n         elif spec == 'w':\n             return self.__class__(self.bitwidth() * 2)\n         elif spec == 'n':\n@@ -111,11 +151,16 @@ def modify(self, spec, width):\n     def type_info(self, platform_info):\n         return platform_info.number_type_info(self)\n \n+    def __eq__(self, other):\n+        # print(self, other)\n+        return self.__class__ == other.__class__ and self.bitwidth() == other.bitwidth()\n+\n class Signed(Number):\n     def __init__(self, bitwidth, llvm_bitwidth = None):\n         Number.__init__(self, bitwidth)\n         self._llvm_bitwidth = llvm_bitwidth\n \n+\n     def compiler_ctor(self):\n         if self._llvm_bitwidth is None:\n             return 'i({})'.format(self.bitwidth())\n@@ -164,26 +209,47 @@ def rust_name(self):\n         return 'f{}'.format(self.bitwidth())\n \n class Vector(Type):\n-    def __init__(self, elem, length):\n+    def __init__(self, elem, length, bitcast = None):\n         assert isinstance(elem, Type) and not isinstance(elem, Vector)\n         Type.__init__(self,\n                       elem.bitwidth() * length)\n         self._length = length\n         self._elem = elem\n+        assert bitcast is None or (isinstance(bitcast, Vector) and\n+                                   bitcast._bitcast is None and\n+                                   bitcast._elem.bitwidth() == elem.bitwidth())\n+        if bitcast is not None and bitcast._elem != elem:\n+            self._bitcast = bitcast._elem\n+        else:\n+            self._bitcast = None\n \n-    def modify(self, spec, width):\n-        if spec == 'h':\n+    def modify(self, spec, width, previous):\n+        if spec == 'S':\n+            return self._elem\n+        elif spec == 'h':\n             return Vector(self._elem, self._length // 2)\n         elif spec == 'd':\n             return Vector(self._elem, self._length * 2)\n         elif spec.startswith('x'):\n             new_bitwidth = int(spec[1:])\n             return Vector(self._elem, new_bitwidth // self._elem.bitwidth())\n+        elif spec.startswith('->'):\n+            bitcast_to = TypeSpec(spec[2:])\n+            choices = list(bitcast_to.enumerate(width, previous))\n+            assert len(choices) == 1\n+            bitcast_to = choices[0]\n+            return Vector(self._elem, self._length, bitcast_to)\n         else:\n-            return Vector(self._elem.modify(spec, width), self._length)\n+            return Vector(self._elem.modify(spec, width, previous), self._length)\n \n     def compiler_ctor(self):\n-        return 'v({}, {})'.format(self._elem.compiler_ctor(), self._length)\n+        if self._bitcast is None:\n+            return 'v({}, {})'.format(self._elem.compiler_ctor(),\n+                                      self._length)\n+        else:\n+            return 'v_({}, {}, {})'.format(self._elem.compiler_ctor(),\n+                                           self._bitcast.compiler_ctor(),\n+                                           self._length)\n \n     def rust_name(self):\n         return '{}x{}'.format(self._elem.rust_name(), self._length)\n@@ -193,6 +259,51 @@ def type_info(self, platform_info):\n         return elem_info.vectorize(self._length,\n                                    platform_info.width_info(self.bitwidth()))\n \n+    def __eq__(self, other):\n+        return isinstance(other, Vector) and self._length == other._length and \\\n+            self._elem == other._elem and self._bitcast == other._bitcast\n+\n+class Pointer(Type):\n+    def __init__(self, elem, llvm_elem, const):\n+        self._elem = elem;\n+        self._llvm_elem = llvm_elem\n+        self._const = const\n+        Type.__init__(self, BITWIDTH_POINTER)\n+\n+    def modify(self, spec, width, previous):\n+        if spec == 'D':\n+            return self._elem\n+        elif spec == 'M':\n+            return Pointer(self._elem, self._llvm_elem, False)\n+        elif spec == 'C':\n+            return Pointer(self._elem, self._llvm_elem, True)\n+        else:\n+            return Pointer(self._elem.modify(spec, width, previous), self._llvm_elem, self._const)\n+\n+    def compiler_ctor(self):\n+        if self._llvm_elem is None:\n+            llvm_elem = 'None'\n+        else:\n+            llvm_elem = 'Some({})'.format(self._llvm_elem.compiler_ctor())\n+        return 'p({}, {}, {})'.format('true' if self._const else 'false',\n+                                      self._elem.compiler_ctor(),\n+                                      llvm_elem)\n+\n+    def rust_name(self):\n+        return '*{} {}'.format('const' if self._const else 'mut',\n+                               self._elem.rust_name())\n+\n+    def type_info(self, platform_info):\n+        if self._llvm_elem is None:\n+            llvm_elem = None\n+        else:\n+            llvm_elem = self._llvm_elem.type_info(platform_info)\n+        return self._elem.type_info(platform_info).pointer(llvm_elem)\n+\n+    def __eq__(self, other):\n+        return isinstance(other, Pointer) and self._const == other._const \\\n+            and self._elem == other._elem and self._llvm_elem == other._llvm_elem\n+\n class Aggregate(Type):\n     def __init__(self, flatten, elems):\n         self._flatten = flatten\n@@ -202,6 +313,14 @@ def __init__(self, flatten, elems):\n     def __repr__(self):\n         return '<Aggregate {}>'.format(self._elems)\n \n+    def modify(self, spec, width, previous):\n+        if spec.startswith('.'):\n+            num = int(spec[1:])\n+            return self._elems[num]\n+        else:\n+            print(spec)\n+            raise NotImplementedError()\n+\n     def compiler_ctor(self):\n         return 'agg({}, vec![{}])'.format('true' if self._flatten else 'false',\n                                           ', '.join(elem.compiler_ctor() for elem in self._elems))\n@@ -210,87 +329,138 @@ def rust_name(self):\n         return '({})'.format(', '.join(elem.rust_name() for elem in self._elems))\n \n     def type_info(self, platform_info):\n-        #return PlatformTypeInfo(None, None, self._llvm_name)\n-        return None\n+        return PlatformTypeInfo(None, None, [elem.type_info(platform_info) for elem in self._elems])\n+\n+    def __eq__(self, other):\n+        return isinstance(other, Aggregate) and self._flatten == other._flatten and \\\n+            self._elems == other._elems\n \n \n TYPE_ID_LOOKUP = {'i': [Signed, Unsigned],\n                   's': [Signed],\n                   'u': [Unsigned],\n                   'f': [Float]}\n \n+def ptrify(match, elem, width, previous):\n+    ptr = match.group('pointer')\n+    if ptr is None:\n+        return elem\n+    else:\n+        llvm_ptr = match.group('llvm_pointer')\n+        if llvm_ptr is None:\n+            llvm_elem = None\n+        else:\n+            assert llvm_ptr.startswith('/')\n+            options = list(TypeSpec(llvm_ptr[1:]).enumerate(width, previous))\n+            assert len(options) == 1\n+            llvm_elem = options[0]\n+        assert ptr in ('Pc', 'Pm')\n+        return Pointer(elem, llvm_elem, ptr == 'Pc')\n+\n class TypeSpec(object):\n     def __init__(self, spec):\n         if not isinstance(spec, list):\n             spec = [spec]\n \n         self.spec = spec\n \n-    def enumerate(self, width):\n+    def enumerate(self, width, previous):\n         for spec in self.spec:\n             match = SPEC.match(spec)\n-            if match:\n+            if match is not None:\n                 id = match.group('id')\n-                is_vector = id.islower()\n-                type_ctors = TYPE_ID_LOOKUP[id.lower()]\n-\n-                start = match.group('start')\n-                if start is not None:\n-                    end = match.group('end')\n-                    llvm_width = None\n+                reference = match.group('reference')\n+\n+                modifiers = []\n+                index = match.group('index')\n+                if index is not None:\n+                    modifiers.append(index)\n+                modifiers += list(match.group('modifiers') or '')\n+                force = match.group('force_width')\n+                if force is not None:\n+                    modifiers.append(force)\n+                bitcast = match.group('bitcast')\n+                if bitcast is not None:\n+                    modifiers.append(bitcast)\n+\n+                if match.group('void') is not None:\n+                    assert spec == 'V'\n+                    yield Void()\n+                elif id is not None:\n+                    is_vector = id.islower()\n+                    type_ctors = TYPE_ID_LOOKUP[id.lower()]\n+\n+                    start = match.group('start')\n+                    if start is not None:\n+                        end = match.group('end')\n+                        llvm_width = None\n+                    else:\n+                        start = end = match.group('width')\n+                        llvm_width = match.group('llvm_width')\n+                    start = int(start)\n+                    end = int(end)\n+\n+                    bitwidth = start\n+                    while bitwidth <= end:\n+                        for ctor in type_ctors:\n+                            if llvm_width is not None:\n+                                assert not is_vector\n+                                llvm_width = int(llvm_width)\n+                                assert llvm_width < bitwidth\n+                                scalar = ctor(bitwidth, llvm_width)\n+                            else:\n+                                scalar = ctor(bitwidth)\n+\n+                            if is_vector:\n+                                elem = Vector(scalar, width // bitwidth)\n+                            else:\n+                                assert bitcast is None\n+                                elem = scalar\n+\n+                            for x in modifiers:\n+                                elem = elem.modify(x, width, previous)\n+                            yield ptrify(match, elem, width, previous)\n+                        bitwidth *= 2\n+                elif reference is not None:\n+                    reference = int(reference)\n+                    assert reference < len(previous), \\\n+                        'referring to argument {}, but only {} are known'.format(reference,\n+                                                                                 len(previous))\n+                    ret = previous[reference]\n+                    for x in modifiers:\n+                        ret = ret.modify(x, width, previous)\n+                    yield ptrify(match, ret, width, previous)\n                 else:\n-                    start = end = match.group('width')\n-                    llvm_width = match.group('llvm_width')\n-                start = int(start)\n-                end = int(end)\n-\n-                bitwidth = start\n-                while bitwidth <= end:\n-                    for ctor in type_ctors:\n-                        if llvm_width is not None:\n-                            assert not is_vector\n-                            llvm_width = int(llvm_width)\n-                            assert llvm_width < bitwidth\n-                            scalar = ctor(bitwidth, llvm_width)\n-                        else:\n-                            scalar = ctor(bitwidth)\n-\n-                        if is_vector:\n-                            yield Vector(scalar, width // bitwidth)\n-                        else:\n-                            yield scalar\n-                    bitwidth *= 2\n+                    assert False, 'matched `{}`, but didn\\'t understand it?'.format(spec)\n+            elif spec.startswith('('):\n+                if spec.endswith(')'):\n+                    true_spec = spec[1:-1]\n+                    flatten = False\n+                elif spec.endswith(')f'):\n+                    true_spec = spec[1:-2]\n+                    flatten = True\n+                else:\n+                    assert False, 'found unclosed aggregate `{}`'.format(spec)\n+\n+                for elems in itertools.product(*(TypeSpec(subspec).enumerate(width, previous)\n+                                                 for subspec in true_spec.split(','))):\n+                    yield Aggregate(flatten, elems)\n+            elif spec.startswith('['):\n+                if spec.endswith(']'):\n+                    true_spec = spec[1:-1]\n+                    flatten = False\n+                elif spec.endswith(']f'):\n+                    true_spec = spec[1:-2]\n+                    flatten = True\n+                else:\n+                    assert False, 'found unclosed aggregate `{}`'.format(spec)\n+                elem_spec, count = true_spec.split(';')\n+\n+                count = int(count)\n+                for elem in TypeSpec(elem_spec).enumerate(width, previous):\n+                    yield Aggregate(flatten, [elem] * count)\n             else:\n-                print('Failed to parse: `{}`'.format(spec), file=sys.stderr)\n-\n-    def resolve(self, width, zero):\n-        assert len(self.spec) == 1\n-        spec = self.spec[0]\n-        match = SPEC.match(spec)\n-        if match:\n-            id  = match.group('id')\n-            if id is not None:\n-                options = list(self.enumerate(width))\n-                assert len(options) == 1\n-                return options[0]\n-            reference = match.group('reference')\n-            if reference != '0':\n-                raise NotImplementedError('only argument 0 (return value) references are supported')\n-            ret = zero\n-            for x in match.group('modifiers') or []:\n-                ret = ret.modify(x, width)\n-            force = match.group('force_width')\n-            if force is not None:\n-                ret = ret.modify(force, width)\n-            return ret\n-        elif spec.startswith('('):\n-            if spec.endswith(')'):\n-                raise NotImplementedError()\n-            elif spec.endswith(')f'):\n-                true_spec = spec[1:-2]\n-                flatten = True\n-            elems = [TypeSpec(subspec).resolve(width, zero) for subspec in true_spec.split(',')]\n-            return Aggregate(flatten, elems)\n+                assert False, 'Failed to parse `{}`'.format(spec)\n \n class GenericIntrinsic(object):\n     def __init__(self, platform, intrinsic, widths, llvm_name, ret, args):\n@@ -305,10 +475,22 @@ def monomorphise(self):\n         for width in self.widths:\n             # must be a power of two\n             assert width & (width - 1) == 0\n-            for ret in self.ret.enumerate(width):\n-                args = [arg.resolve(width, ret) for arg in self.args]\n-                yield MonomorphicIntrinsic(self._platform, self.intrinsic, width, self.llvm_name,\n-                                           ret, args)\n+            def recur(processed, untouched):\n+                if untouched == []:\n+                    ret = processed[0]\n+                    args = processed[1:]\n+                    yield MonomorphicIntrinsic(self._platform, self.intrinsic, width,\n+                                               self.llvm_name,\n+                                               ret, args)\n+                else:\n+                    raw_arg = untouched[0]\n+                    rest = untouched[1:]\n+                    for arg in raw_arg.enumerate(width, processed):\n+                        for intr in recur(processed + [arg], rest):\n+                            yield intr\n+\n+            for x in recur([], [self.ret] + self.args):\n+                yield x\n \n class MonomorphicIntrinsic(object):\n     def __init__(self, platform, intrinsic, width, llvm_name, ret, args):\n@@ -369,7 +551,18 @@ def parse_args():\n         ## Type specifier grammar\n \n         ```\n-        type := vector | scalar | aggregate | reference\n+        type := core_type modifier* suffix?\n+\n+        core_type := void | vector | scalar | aggregate | reference\n+\n+        modifier := 'v' | 'h' | 'd' | 'n' | 'w' | 'u' | 's' |\n+                     'x' number | '.' number\n+        suffix := pointer | bitcast\n+        pointer := 'Pm' llvm_pointer? | 'Pc' llvm_pointer?\n+        llvm_pointer := '/' type\n+        bitcast := '->' type\n+\n+        void := 'V'\n \n         vector := vector_elem width |\n         vector_elem := 'i' | 'u' | 's' | 'f'\n@@ -378,18 +571,20 @@ def parse_args():\n         scalar_type := 'U' | 'S' | 'F'\n         llvm_width := '/' number\n \n-        aggregate := '(' (type),* ')' 'f'?\n-\n-        reference := number modifiers*\n-        modifiers := 'v' | 'h' | 'd' | 'n' | 'w' | 'u' | 's' |\n-                     'x' number\n+        aggregate := '(' (type),* ')' 'f'? | '[' type ';' number ']' 'f'?\n \n+        reference := number\n \n         width = number | '(' number '-' number ')'\n \n         number = [0-9]+\n         ```\n \n+        ## Void\n+\n+        The `V` type corresponds to `void` in LLVM (`()` in\n+        Rust). It's likely to only work in return position.\n+\n         ## Vectors\n \n         The vector grammar is a pattern describing many possibilities\n@@ -433,6 +628,12 @@ def parse_args():\n         - no `f` corresponds to `declare ... @llvm.foo({float, i32})`.\n         - having an `f` corresponds to `declare ... @llvm.foo(float, i32)`.\n \n+        The `[type;number]` form is a just shorter way to write\n+        `(...)`, except avoids doing a cartesian product of generic\n+        types, e.g. `[S32;2]` is the same as `(S32, S32)`, while\n+        `[I32;2]` is describing just the two types `(S32,S32)` and\n+        `(U32,U32)` (i.e. doesn't include `(S32,U32)`, `(U32,S32)` as\n+        `(I32,I32)` would).\n \n         (Currently aggregates can not contain other aggregates.)\n \n@@ -441,19 +642,49 @@ def parse_args():\n         A reference uses the type of another argument, with possible\n         modifications. The number refers to the type to use, starting\n         with 0 == return value, 1 == first argument, 2 == second\n-        argument, etc. (Currently only referencing 0, the return\n-        value, is supported.)\n+        argument, etc.\n+\n+        ## Affixes\n+\n+        The `modifier` and `suffix` adaptors change the precise\n+        representation.\n \n         ### Modifiers\n \n         - 'v': put a scalar into a vector of the current width (u32 -> u32x4, when width == 128)\n+        - 'S': get the scalar element of a vector (u32x4 -> u32)\n         - 'h': half the length of the vector (u32x4 -> u32x2)\n         - 'd': double the length of the vector (u32x2 -> u32x4)\n         - 'n': narrow the element of the vector (u32x4 -> u16x4)\n         - 'w': widen the element of the vector (u16x4 -> u32x4)\n-        - 'u': force an integer (vector or scalar) to be unsigned (i32x4 -> u32x4)\n-        - 's': force an integer (vector or scalar) to be signed (u32x4 -> i32x4)\n+        - 'u': force a number (vector or scalar) to be unsigned int (f32x4 -> u32x4)\n+        - 's': force a number (vector or scalar) to be signed int (u32x4 -> i32x4)\n+        - 'f': force a number (vector or scalar) to be float (u32x4 -> f32x4)\n         - 'x' number: force the type to be a vector of bitwidth `number`.\n+        - '.' number: get the `number`th element of an aggregate\n+        - 'D': dereference a pointer (*mut u32 -> u32)\n+        - 'C': make a pointer const (*mut u32 -> *const u32)\n+        - 'M': make a pointer mut (*const u32 -> *mut u32)\n+\n+        ### Pointers\n+\n+        Pointers can be created of any type by appending a `P*`\n+        suffix. The `m` vs. `c` chooses mut vs. const. e.g. `S32Pm`\n+        corresponds to `*mut i32`, and `i32Pc` corresponds (with width\n+        128) to `*const i8x16`, `*const u32x4`, etc.\n+\n+        The type after the `/` (optional) represents the type used\n+        internally to LLVM, e.g. `S32pm/S8` is exposed as `*mut i32`\n+        in Rust, but is `i8*` in LLVM. (This defaults to the main\n+        type).\n+\n+        ### Bitcast\n+\n+        The `'->' type` bitcast suffix will cause the value to be\n+        bitcast to the right-hand type when calling the intrinsic,\n+        e.g. `s32->f32` will expose the intrinsic as `i32x4` at the\n+        Rust level, but will cast that vector to `f32x4` when calling\n+        the LLVM intrinsic.\n         '''))\n     parser.add_argument('--format', choices=FORMATS, required=True,\n                         help = 'Output format.')\n@@ -502,7 +733,7 @@ def open(self, platform):\n \n #![allow(unused_imports)]\n \n-use {{Intrinsic, i, i_, u, u_, f, v, agg}};\n+use {{Intrinsic, i, i_, u, u_, f, v, v_, agg, p, void}};\n use IntrinsicDef::Named;\n use rustc::middle::ty;\n "}, {"sha": "2c1492c2954c8e18dd8eb6296f523a903a252deb", "filename": "src/etc/platform-intrinsics/x86/avx.json", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -36,6 +36,20 @@\n             \"ret\": \"f(32-64)\",\n             \"args\": [\"0\", \"0\"]\n         },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_maskload_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"maskload.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"f(32-64)\"],\n+            \"args\": [\"0SPc/S8\", \"0s->0\"]\n+        },\n+        {\n+            \"intrinsic\": \"{3.width_mm}_maskstore_{3.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"maskstore.{3.data_type_short}{3.width_suffix}\",\n+            \"ret\": \"V\",\n+            \"args\": [\"F(32-64)Pm/S8\", \"1Dsv->1Dv\", \"1Dv\"]\n+        },\n         {\n             \"intrinsic\": \"256_min_{0.data_type}\",\n             \"width\": [256],\n@@ -78,6 +92,20 @@\n             \"ret\": \"f32\",\n             \"args\": [\"f32\"]\n         },\n+        {\n+            \"intrinsic\": \"256_storeu_{2.data_type}\",\n+            \"width\": [256],\n+            \"llvm\": \"storeu.ps.256\",\n+            \"ret\": \"V\",\n+            \"args\": [\"f(32-64)Pm/U8\", \"1D\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_storeu_si256\",\n+            \"width\": [256],\n+            \"llvm\": \"storeu.dq.256\",\n+            \"ret\": \"V\",\n+            \"args\": [\"u8Pm/U8\", \"1D\"]\n+        },\n         {\n             \"intrinsic\": \"256_sqrt_{0.data_type}\",\n             \"width\": [256],\n@@ -147,6 +175,20 @@\n             \"llvm\": \"ptestz.256\",\n             \"ret\": \"S32\",\n             \"args\": [\"u64\", \"u64\"]\n+        },\n+        {\n+            \"intrinsic\": \"256_zeroall\",\n+            \"width\": [256],\n+            \"llvm\": \"vzeroall\",\n+            \"ret\": \"V\",\n+            \"args\": []\n+        },\n+        {\n+            \"intrinsic\": \"256_zeroupper\",\n+            \"width\": [256],\n+            \"llvm\": \"vzeroupper\",\n+            \"ret\": \"V\",\n+            \"args\": []\n         }\n     ]\n }"}, {"sha": "e88ff3d2b806dbf1fe45b6b2448c84cd2bc2e893", "filename": "src/etc/platform-intrinsics/x86/avx2.json", "status": "modified", "additions": 45, "deletions": 3, "changes": 48, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Favx2.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -4,21 +4,21 @@\n         {\n             \"intrinsic\": \"256_abs_{0.data_type}\",\n             \"width\": [256],\n-            \"llvm\": \"avx2.pabs.{0.data_type_short}\",\n+            \"llvm\": \"pabs.{0.data_type_short}\",\n             \"ret\": \"s(8-32)\",\n             \"args\": [\"0\"]\n         },\n         {\n             \"intrinsic\": \"256_adds_{0.data_type}\",\n             \"width\": [256],\n-            \"llvm\": \"avx2.padd{0.kind_short}s.{0.data_type_short}\",\n+            \"llvm\": \"padd{0.kind_short}s.{0.data_type_short}\",\n             \"ret\": \"i(8-16)\",\n             \"args\": [\"0\", \"0\"]\n         },\n         {\n             \"intrinsic\": \"256_avg_{0.data_type}\",\n             \"width\": [256],\n-            \"llvm\": \"avx2.pavg.{0.data_type_short}\",\n+            \"llvm\": \"pavg.{0.data_type_short}\",\n             \"ret\": \"u(8-16)\",\n             \"args\": [\"0\", \"0\"]\n         },\n@@ -64,6 +64,48 @@\n             \"ret\": \"s16\",\n             \"args\": [\"s8\", \"s8\"]\n         },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_mask_i32gather_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"gather.d.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"s32\", \"f32\"],\n+            \"args\": [\"0\", \"0SPc/S8\", \"s32\", \"0s->0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_mask_i32gather_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"gather.d.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"s64\", \"f64\"],\n+            \"args\": [\"0\", \"0SPc/S8\", \"s32x128\", \"0s->0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"{3.width_mm}_mask_i64gather_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"gather.q.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"s32x128\", \"f32x128\"],\n+            \"args\": [\"0\", \"0SPc/S8\", \"s64\", \"0s->0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_mask_i64gather_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"gather.q.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"s64\", \"f64\"],\n+            \"args\": [\"0\", \"0SPc/S8\", \"s64\", \"0s->0\", \"S32/8\"]\n+        },\n+        {\n+            \"intrinsic\": \"{0.width_mm}_maskload_{0.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"maskload.{0.data_type_short}{0.width_suffix}\",\n+            \"ret\": [\"s(32-64)\"],\n+            \"args\": [\"0Pc/S8\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"{2.width_mm}_maskstore_{2.data_type}\",\n+            \"width\": [128, 256],\n+            \"llvm\": \"maskstore.{2.data_type_short}{2.width_suffix}\",\n+            \"ret\": \"V\",\n+            \"args\": [\"S(32-64)Pm/S8\", \"1Dv\", \"2\"]\n+        },\n         {\n             \"intrinsic\": \"256_max_{0.data_type}\",\n             \"width\": [256],"}, {"sha": "adff0dc41b2afd8221eb8f0a4dc7535a43c28790", "filename": "src/etc/platform-intrinsics/x86/sse.json", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -42,6 +42,13 @@\n             \"llvm\": \"!llvm.sqrt.v4f32\",\n             \"ret\": \"f32\",\n             \"args\": [\"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_storeu_ps\",\n+            \"width\": [128],\n+            \"llvm\": \"storeu.ps\",\n+            \"ret\": \"V\",\n+            \"args\": [\"F32Pm/S8\", \"f32\"]\n         }\n     ]\n }"}, {"sha": "d09980d95f31b8d09d73e503e4548cb298da9f0a", "filename": "src/etc/platform-intrinsics/x86/sse2.json", "status": "modified", "additions": 42, "deletions": 0, "changes": 42, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse2.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -15,13 +15,27 @@\n             \"ret\": \"u(8-16)\",\n             \"args\": [\"0\", \"0\"]\n         },\n+        {\n+            \"intrinsic\": \"_lfence\",\n+            \"width\": [128],\n+            \"llvm\": \"lfence\",\n+            \"ret\": \"V\",\n+            \"args\": []\n+        },\n         {\n             \"intrinsic\": \"_madd_epi16\",\n             \"width\": [128],\n             \"llvm\": \"pmadd.wd\",\n             \"ret\": \"s32\",\n             \"args\": [\"s16\", \"s16\"]\n         },\n+        {\n+            \"intrinsic\": \"_maskmoveu_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"maskmov.dqu\",\n+            \"ret\": \"V\",\n+            \"args\": [\"u8\", \"u8\", \"U8Pm\"]\n+        },\n         {\n             \"intrinsic\": \"_max_{0.data_type}\",\n             \"width\": [128],\n@@ -36,6 +50,13 @@\n             \"ret\": \"f64\",\n             \"args\": [\"0\", \"0\"]\n         },\n+        {\n+            \"intrinsic\": \"_mfence\",\n+            \"width\": [128],\n+            \"llvm\": \"fence\",\n+            \"ret\": \"V\",\n+            \"args\": []\n+        },\n         {\n             \"intrinsic\": \"_min_{0.data_type}\",\n             \"width\": [128],\n@@ -99,13 +120,34 @@\n             \"ret\": \"u64\",\n             \"args\": [\"u8\", \"u8\"]\n         },\n+        {\n+            \"intrinsic\": \"_sfence\",\n+            \"width\": [128],\n+            \"llvm\": \"sfence\",\n+            \"ret\": \"V\",\n+            \"args\": []\n+        },\n         {\n             \"intrinsic\": \"_sqrt_pd\",\n             \"width\": [128],\n             \"llvm\": \"!llvm.sqrt.v2f64\",\n             \"ret\": \"f64\",\n             \"args\": [\"0\"]\n         },\n+        {\n+            \"intrinsic\": \"_storeu_pd\",\n+            \"width\": [128],\n+            \"llvm\": \"storeu.pd\",\n+            \"ret\": \"V\",\n+            \"args\": [\"F64Pm/U8\", \"f64\"]\n+        },\n+        {\n+            \"intrinsic\": \"_storeu_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"storeu.dq\",\n+            \"ret\": \"V\",\n+            \"args\": [\"u8Pm/U8\", \"u8\"]\n+        },\n         {\n             \"intrinsic\": \"_subs_{0.data_type}\",\n             \"width\": [128],"}, {"sha": "ed13595929d1b24c752333eb702cfe638bee1e7e", "filename": "src/etc/platform-intrinsics/x86/sse3.json", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Fetc%2Fplatform-intrinsics%2Fx86%2Fsse3.json?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -21,6 +21,13 @@\n             \"llvm\": \"hsub.{0.data_type}\",\n             \"ret\": \"f(32-64)\",\n             \"args\": [\"0\", \"0\"]\n+        },\n+        {\n+            \"intrinsic\": \"_lddqu_si128\",\n+            \"width\": [128],\n+            \"llvm\": \"ldu.dq\",\n+            \"ret\": \"u8\",\n+            \"args\": [\"0Pc/S8\"]\n         }\n     ]\n }"}, {"sha": "a3084d903e27fe26b615a0fe56906c1e5850733d", "filename": "src/librustc_platform_intrinsics/aarch64.rs", "status": "modified", "additions": 601, "deletions": 1, "changes": 602, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Faarch64.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Faarch64.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Faarch64.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -13,7 +13,7 @@\n \n #![allow(unused_imports)]\n \n-use {Intrinsic, i, u, f, v, agg};\n+use {Intrinsic, i, i_, u, u_, f, v, v_, agg, p, void};\n use IntrinsicDef::Named;\n use rustc::middle::ty;\n \n@@ -1910,6 +1910,606 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(u(8), 16),\n             definition: Named(\"llvm.aarch64.neon.rbit.v16i8\")\n         },\n+        \"ld2_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 8)))],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i8.p0v8i8\")\n+        },\n+        \"ld2_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 8)))],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i8.p0v8i8\")\n+        },\n+        \"ld2_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 4)))],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i16.p0v4i16\")\n+        },\n+        \"ld2_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 4)))],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i16.p0v4i16\")\n+        },\n+        \"ld2_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 2)))],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i32.p0v2i32\")\n+        },\n+        \"ld2_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 2)))],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i32.p0v2i32\")\n+        },\n+        \"ld2_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 1)))],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1i64.p0v1i64\")\n+        },\n+        \"ld2_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 1)))],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1i64.p0v1i64\")\n+        },\n+        \"ld2_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 2)))],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2f32.p0v2f32\")\n+        },\n+        \"ld2_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 1)))],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1f64.p0v1f64\")\n+        },\n+        \"ld2q_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 16)))],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v16i8.p0v16i8\")\n+        },\n+        \"ld2q_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 16)))],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v16i8.p0v16i8\")\n+        },\n+        \"ld2q_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 8)))],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i16.p0v8i16\")\n+        },\n+        \"ld2q_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 8)))],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i16.p0v8i16\")\n+        },\n+        \"ld2q_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 4)))],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i32.p0v4i32\")\n+        },\n+        \"ld2q_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 4)))],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i32.p0v4i32\")\n+        },\n+        \"ld2q_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 2)))],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i64.p0v2i64\")\n+        },\n+        \"ld2q_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 2)))],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i64.p0v2i64\")\n+        },\n+        \"ld2q_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 4)))],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4f32.p0v4f32\")\n+        },\n+        \"ld2q_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 2)))],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2f64.p0v2f64\")\n+        },\n+        \"ld3_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 8)))],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i8.p0v8i8\")\n+        },\n+        \"ld3_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 8)))],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i8.p0v8i8\")\n+        },\n+        \"ld3_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 4)))],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i16.p0v4i16\")\n+        },\n+        \"ld3_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 4)))],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i16.p0v4i16\")\n+        },\n+        \"ld3_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 2)))],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i32.p0v2i32\")\n+        },\n+        \"ld3_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 2)))],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i32.p0v2i32\")\n+        },\n+        \"ld3_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 1)))],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1i64.p0v1i64\")\n+        },\n+        \"ld3_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 1)))],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1i64.p0v1i64\")\n+        },\n+        \"ld3_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 2)))],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2f32.p0v2f32\")\n+        },\n+        \"ld3_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 1)))],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1f64.p0v1f64\")\n+        },\n+        \"ld3q_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 16)))],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v16i8.p0v16i8\")\n+        },\n+        \"ld3q_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 16)))],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v16i8.p0v16i8\")\n+        },\n+        \"ld3q_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 8)))],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i16.p0v8i16\")\n+        },\n+        \"ld3q_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 8)))],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i16.p0v8i16\")\n+        },\n+        \"ld3q_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 4)))],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i32.p0v4i32\")\n+        },\n+        \"ld3q_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 4)))],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i32.p0v4i32\")\n+        },\n+        \"ld3q_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 2)))],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i64.p0v2i64\")\n+        },\n+        \"ld3q_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 2)))],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i64.p0v2i64\")\n+        },\n+        \"ld3q_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 4)))],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4f32.p0v4f32\")\n+        },\n+        \"ld3q_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 2)))],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2f64.p0v2f64\")\n+        },\n+        \"ld4_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 8)))],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i8.p0v8i8\")\n+        },\n+        \"ld4_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 8)))],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i8.p0v8i8\")\n+        },\n+        \"ld4_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 4)))],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4), v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i16.p0v4i16\")\n+        },\n+        \"ld4_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 4)))],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4), v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i16.p0v4i16\")\n+        },\n+        \"ld4_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 2)))],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2), v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i32.p0v2i32\")\n+        },\n+        \"ld4_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 2)))],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2), v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i32.p0v2i32\")\n+        },\n+        \"ld4_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 1)))],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1), v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1i64.p0v1i64\")\n+        },\n+        \"ld4_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 1)))],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1), v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1i64.p0v1i64\")\n+        },\n+        \"ld4_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 2)))],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2), v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2f32.p0v2f32\")\n+        },\n+        \"ld4_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 1)))],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1), v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1f64.p0v1f64\")\n+        },\n+        \"ld4q_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), Some(v(i(8), 16)))],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16), v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v16i8.p0v16i8\")\n+        },\n+        \"ld4q_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), Some(v(u(8), 16)))],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16), v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v16i8.p0v16i8\")\n+        },\n+        \"ld4q_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), Some(v(i(16), 8)))],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8), v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i16.p0v8i16\")\n+        },\n+        \"ld4q_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), Some(v(u(16), 8)))],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8), v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i16.p0v8i16\")\n+        },\n+        \"ld4q_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), Some(v(i(32), 4)))],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4), v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i32.p0v4i32\")\n+        },\n+        \"ld4q_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), Some(v(u(32), 4)))],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4), v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i32.p0v4i32\")\n+        },\n+        \"ld4q_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), Some(v(i(64), 2)))],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2), v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i64.p0v2i64\")\n+        },\n+        \"ld4q_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), Some(v(u(64), 2)))],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2), v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i64.p0v2i64\")\n+        },\n+        \"ld4q_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(v(f(32), 4)))],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4), v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4f32.p0v4f32\")\n+        },\n+        \"ld4q_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(v(f(64), 2)))],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2), v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2f64.p0v2f64\")\n+        },\n+        \"ld2_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i8.p0i8\")\n+        },\n+        \"ld2_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i8.p0i8\")\n+        },\n+        \"ld2_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i16.p0i16\")\n+        },\n+        \"ld2_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i16.p0i16\")\n+        },\n+        \"ld2_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i32.p0i32\")\n+        },\n+        \"ld2_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i32.p0i32\")\n+        },\n+        \"ld2_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1i64.p0i64\")\n+        },\n+        \"ld2_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1i64.p0i64\")\n+        },\n+        \"ld2_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2f32.p0f32\")\n+        },\n+        \"ld2_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v1f64.p0f64\")\n+        },\n+        \"ld2q_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v16i8.p0i8\")\n+        },\n+        \"ld2q_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v16i8.p0i8\")\n+        },\n+        \"ld2q_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i16.p0i16\")\n+        },\n+        \"ld2q_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v8i16.p0i16\")\n+        },\n+        \"ld2q_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i32.p0i32\")\n+        },\n+        \"ld2q_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4i32.p0i32\")\n+        },\n+        \"ld2q_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i64.p0i64\")\n+        },\n+        \"ld2q_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2i64.p0i64\")\n+        },\n+        \"ld2q_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v4f32.p0f32\")\n+        },\n+        \"ld2q_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld2.v2f64.p0f64\")\n+        },\n+        \"ld3_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i8.p0i8\")\n+        },\n+        \"ld3_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i8.p0i8\")\n+        },\n+        \"ld3_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i16.p0i16\")\n+        },\n+        \"ld3_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i16.p0i16\")\n+        },\n+        \"ld3_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i32.p0i32\")\n+        },\n+        \"ld3_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i32.p0i32\")\n+        },\n+        \"ld3_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1i64.p0i64\")\n+        },\n+        \"ld3_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1i64.p0i64\")\n+        },\n+        \"ld3_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2f32.p0f32\")\n+        },\n+        \"ld3_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v1f64.p0f64\")\n+        },\n+        \"ld3q_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v16i8.p0i8\")\n+        },\n+        \"ld3q_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v16i8.p0i8\")\n+        },\n+        \"ld3q_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i16.p0i16\")\n+        },\n+        \"ld3q_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v8i16.p0i16\")\n+        },\n+        \"ld3q_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i32.p0i32\")\n+        },\n+        \"ld3q_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4i32.p0i32\")\n+        },\n+        \"ld3q_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i64.p0i64\")\n+        },\n+        \"ld3q_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2i64.p0i64\")\n+        },\n+        \"ld3q_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v4f32.p0f32\")\n+        },\n+        \"ld3q_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld3.v2f64.p0f64\")\n+        },\n+        \"ld4_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 8), v(i(8), 8), v(i(8), 8), v(i(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i8.p0i8\")\n+        },\n+        \"ld4_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 8), v(u(8), 8), v(u(8), 8), v(u(8), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i8.p0i8\")\n+        },\n+        \"ld4_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 4), v(i(16), 4), v(i(16), 4), v(i(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i16.p0i16\")\n+        },\n+        \"ld4_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 4), v(u(16), 4), v(u(16), 4), v(u(16), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i16.p0i16\")\n+        },\n+        \"ld4_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 2), v(i(32), 2), v(i(32), 2), v(i(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i32.p0i32\")\n+        },\n+        \"ld4_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 2), v(u(32), 2), v(u(32), 2), v(u(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i32.p0i32\")\n+        },\n+        \"ld4_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 1), v(i(64), 1), v(i(64), 1), v(i(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1i64.p0i64\")\n+        },\n+        \"ld4_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 1), v(u(64), 1), v(u(64), 1), v(u(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1i64.p0i64\")\n+        },\n+        \"ld4_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 2), v(f(32), 2), v(f(32), 2), v(f(32), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2f32.p0f32\")\n+        },\n+        \"ld4_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 1), v(f(64), 1), v(f(64), 1), v(f(64), 1)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v1f64.p0f64\")\n+        },\n+        \"ld4q_dup_s8\" => Intrinsic {\n+            inputs: vec![p(true, i(8), None)],\n+            output: agg(false, vec![v(i(8), 16), v(i(8), 16), v(i(8), 16), v(i(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v16i8.p0i8\")\n+        },\n+        \"ld4q_dup_u8\" => Intrinsic {\n+            inputs: vec![p(true, u(8), None)],\n+            output: agg(false, vec![v(u(8), 16), v(u(8), 16), v(u(8), 16), v(u(8), 16)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v16i8.p0i8\")\n+        },\n+        \"ld4q_dup_s16\" => Intrinsic {\n+            inputs: vec![p(true, i(16), None)],\n+            output: agg(false, vec![v(i(16), 8), v(i(16), 8), v(i(16), 8), v(i(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i16.p0i16\")\n+        },\n+        \"ld4q_dup_u16\" => Intrinsic {\n+            inputs: vec![p(true, u(16), None)],\n+            output: agg(false, vec![v(u(16), 8), v(u(16), 8), v(u(16), 8), v(u(16), 8)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v8i16.p0i16\")\n+        },\n+        \"ld4q_dup_s32\" => Intrinsic {\n+            inputs: vec![p(true, i(32), None)],\n+            output: agg(false, vec![v(i(32), 4), v(i(32), 4), v(i(32), 4), v(i(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i32.p0i32\")\n+        },\n+        \"ld4q_dup_u32\" => Intrinsic {\n+            inputs: vec![p(true, u(32), None)],\n+            output: agg(false, vec![v(u(32), 4), v(u(32), 4), v(u(32), 4), v(u(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4i32.p0i32\")\n+        },\n+        \"ld4q_dup_s64\" => Intrinsic {\n+            inputs: vec![p(true, i(64), None)],\n+            output: agg(false, vec![v(i(64), 2), v(i(64), 2), v(i(64), 2), v(i(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i64.p0i64\")\n+        },\n+        \"ld4q_dup_u64\" => Intrinsic {\n+            inputs: vec![p(true, u(64), None)],\n+            output: agg(false, vec![v(u(64), 2), v(u(64), 2), v(u(64), 2), v(u(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2i64.p0i64\")\n+        },\n+        \"ld4q_dup_f32\" => Intrinsic {\n+            inputs: vec![p(true, f(32), None)],\n+            output: agg(false, vec![v(f(32), 4), v(f(32), 4), v(f(32), 4), v(f(32), 4)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v4f32.p0f32\")\n+        },\n+        \"ld4q_dup_f64\" => Intrinsic {\n+            inputs: vec![p(true, f(64), None)],\n+            output: agg(false, vec![v(f(64), 2), v(f(64), 2), v(f(64), 2), v(f(64), 2)]),\n+            definition: Named(\"llvm.aarch64.neon.ld4.v2f64.p0f64\")\n+        },\n         \"padd_s8\" => Intrinsic {\n             inputs: vec![v(i(8), 8), v(i(8), 8)],\n             output: v(i(8), 8),"}, {"sha": "89b147027b5e857b7e141f74dc49988ab3f29b4e", "filename": "src/librustc_platform_intrinsics/arm.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Farm.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Farm.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Farm.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -13,7 +13,7 @@\n \n #![allow(unused_imports)]\n \n-use {Intrinsic, i, u, f, v, agg};\n+use {Intrinsic, i, i_, u, u_, f, v, agg, p};\n use IntrinsicDef::Named;\n use rustc::middle::ty;\n "}, {"sha": "9aee15b05df4cd212af49b76d251300fd33b6fef", "filename": "src/librustc_platform_intrinsics/lib.rs", "status": "modified", "additions": 13, "deletions": 3, "changes": 16, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Flib.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -30,10 +30,11 @@ pub struct Intrinsic {\n \n #[derive(Clone, Hash, Eq, PartialEq)]\n pub enum Type {\n+    Void,\n     Integer(/* signed */ bool, u8, /* llvm width */ u8),\n     Float(u8),\n-    Pointer(Box<Type>),\n-    Vector(Box<Type>, u8),\n+    Pointer(Box<Type>, Option<Box<Type>>, /* const */ bool),\n+    Vector(Box<Type>, Option<Box<Type>>, u8),\n     Aggregate(bool, Vec<Type>),\n }\n \n@@ -47,10 +48,19 @@ fn u(width: u8) -> Type { Type::Integer(false, width, width) }\n #[allow(dead_code)]\n fn u_(width: u8, llvm_width: u8) -> Type { Type::Integer(false, width, llvm_width) }\n fn f(width: u8) -> Type { Type::Float(width) }\n-fn v(x: Type, length: u8) -> Type { Type::Vector(Box::new(x), length) }\n+fn v(x: Type, length: u8) -> Type { Type::Vector(Box::new(x), None, length) }\n+fn v_(x: Type, bitcast: Type, length: u8) -> Type {\n+    Type::Vector(Box::new(x), Some(Box::new(bitcast)), length)\n+}\n fn agg(flatten: bool, types: Vec<Type>) -> Type {\n     Type::Aggregate(flatten, types)\n }\n+fn p(const_: bool, elem: Type, llvm_elem: Option<Type>) -> Type {\n+    Type::Pointer(Box::new(elem), llvm_elem.map(Box::new), const_)\n+}\n+fn void() -> Type {\n+    Type::Void\n+}\n \n mod x86;\n mod arm;"}, {"sha": "2dfd00e9ce3bfa8208737d04222026bc1350ce17", "filename": "src/librustc_platform_intrinsics/x86.rs", "status": "modified", "additions": 235, "deletions": 10, "changes": 245, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Fx86.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_platform_intrinsics%2Fx86.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_platform_intrinsics%2Fx86.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -13,7 +13,7 @@\n \n #![allow(unused_imports)]\n \n-use {Intrinsic, i, i_, u, u_, f, v, agg};\n+use {Intrinsic, i, i_, u, u_, f, v, v_, agg, p, void};\n use IntrinsicDef::Named;\n use rustc::middle::ty;\n \n@@ -50,6 +50,11 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(f(32), 4),\n             definition: Named(\"llvm.sqrt.v4f32\")\n         },\n+        \"_storeu_ps\" => Intrinsic {\n+            inputs: vec![p(false, f(32), Some(i(8))), v(f(32), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse.storeu.ps\")\n+        },\n         \"_adds_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 16), v(i(8), 16)],\n             output: v(i(8), 16),\n@@ -80,11 +85,21 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(u(16), 8),\n             definition: Named(\"llvm.x86.sse2.pavg.w\")\n         },\n+        \"_lfence\" => Intrinsic {\n+            inputs: vec![],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.lfence\")\n+        },\n         \"_madd_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 8), v(i(16), 8)],\n             output: v(i(32), 4),\n             definition: Named(\"llvm.x86.sse2.pmadd.wd\")\n         },\n+        \"_maskmoveu_si128\" => Intrinsic {\n+            inputs: vec![v(u(8), 16), v(u(8), 16), p(false, u(8), None)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.maskmov.dqu\")\n+        },\n         \"_max_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 8), v(i(16), 8)],\n             output: v(i(16), 8),\n@@ -100,6 +115,11 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(f(64), 2),\n             definition: Named(\"llvm.x86.sse2.max.pd\")\n         },\n+        \"_mfence\" => Intrinsic {\n+            inputs: vec![],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.fence\")\n+        },\n         \"_min_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 8), v(i(16), 8)],\n             output: v(i(16), 8),\n@@ -160,11 +180,26 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(u(64), 2),\n             definition: Named(\"llvm.x86.sse2.psad.bw\")\n         },\n+        \"_sfence\" => Intrinsic {\n+            inputs: vec![],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.sfence\")\n+        },\n         \"_sqrt_pd\" => Intrinsic {\n             inputs: vec![v(f(64), 2)],\n             output: v(f(64), 2),\n             definition: Named(\"llvm.sqrt.v2f64\")\n         },\n+        \"_storeu_pd\" => Intrinsic {\n+            inputs: vec![p(false, f(64), Some(u(8))), v(f(64), 2)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.storeu.pd\")\n+        },\n+        \"_storeu_si128\" => Intrinsic {\n+            inputs: vec![p(false, v(u(8), 16), Some(u(8))), v(u(8), 16)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.sse2.storeu.dq\")\n+        },\n         \"_subs_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 16), v(i(8), 16)],\n             output: v(i(8), 16),\n@@ -215,6 +250,11 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(f(64), 2),\n             definition: Named(\"llvm.x86.sse3.hsub.pd\")\n         },\n+        \"_lddqu_si128\" => Intrinsic {\n+            inputs: vec![p(true, v(u(8), 16), Some(i(8)))],\n+            output: v(u(8), 16),\n+            definition: Named(\"llvm.x86.sse3.ldu.dq\")\n+        },\n         \"_abs_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 16)],\n             output: v(i(8), 16),\n@@ -490,6 +530,46 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(f(64), 4),\n             definition: Named(\"llvm.x86.avx.max.pd.256\")\n         },\n+        \"_maskload_ps\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(i(8))), v_(i(32), f(32), 4)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.avx.maskload.ps\")\n+        },\n+        \"_maskload_pd\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(i(8))), v_(i(64), f(64), 2)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.avx.maskload.pd\")\n+        },\n+        \"256_maskload_ps\" => Intrinsic {\n+            inputs: vec![p(true, f(32), Some(i(8))), v_(i(32), f(32), 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx.maskload.ps.256\")\n+        },\n+        \"256_maskload_pd\" => Intrinsic {\n+            inputs: vec![p(true, f(64), Some(i(8))), v_(i(64), f(64), 4)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx.maskload.pd.256\")\n+        },\n+        \"_maskstore_ps\" => Intrinsic {\n+            inputs: vec![p(false, f(32), Some(i(8))), v_(i(32), f(32), 4), v(f(32), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.maskstore.ps\")\n+        },\n+        \"_maskstore_pd\" => Intrinsic {\n+            inputs: vec![p(false, f(64), Some(i(8))), v_(i(64), f(64), 2), v(f(64), 2)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.maskstore.pd\")\n+        },\n+        \"256_maskstore_ps\" => Intrinsic {\n+            inputs: vec![p(false, f(32), Some(i(8))), v_(i(32), f(32), 8), v(f(32), 8)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.maskstore.ps.256\")\n+        },\n+        \"256_maskstore_pd\" => Intrinsic {\n+            inputs: vec![p(false, f(64), Some(i(8))), v_(i(64), f(64), 4), v(f(64), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.maskstore.pd.256\")\n+        },\n         \"256_min_ps\" => Intrinsic {\n             inputs: vec![v(f(32), 8), v(f(32), 8)],\n             output: v(f(32), 8),\n@@ -540,6 +620,21 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(f(32), 8),\n             definition: Named(\"llvm.x86.avx.rsqrt.ps.256\")\n         },\n+        \"256_storeu_ps\" => Intrinsic {\n+            inputs: vec![p(false, v(f(32), 8), Some(u(8))), v(f(32), 8)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.storeu.ps.256\")\n+        },\n+        \"256_storeu_pd\" => Intrinsic {\n+            inputs: vec![p(false, v(f(64), 4), Some(u(8))), v(f(64), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.storeu.ps.256\")\n+        },\n+        \"256_storeu_si256\" => Intrinsic {\n+            inputs: vec![p(false, v(u(8), 32), Some(u(8))), v(u(8), 32)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.storeu.dq.256\")\n+        },\n         \"256_sqrt_ps\" => Intrinsic {\n             inputs: vec![v(f(32), 8)],\n             output: v(f(32), 8),\n@@ -625,50 +720,60 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: i(32),\n             definition: Named(\"llvm.x86.avx.ptestz.256\")\n         },\n+        \"256_zeroall\" => Intrinsic {\n+            inputs: vec![],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.vzeroall\")\n+        },\n+        \"256_zeroupper\" => Intrinsic {\n+            inputs: vec![],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx.vzeroupper\")\n+        },\n         \"256_abs_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 32)],\n             output: v(i(8), 32),\n-            definition: Named(\"llvm.x86.avx2.avx2.pabs.b\")\n+            definition: Named(\"llvm.x86.avx2.pabs.b\")\n         },\n         \"256_abs_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 16)],\n             output: v(i(16), 16),\n-            definition: Named(\"llvm.x86.avx2.avx2.pabs.w\")\n+            definition: Named(\"llvm.x86.avx2.pabs.w\")\n         },\n         \"256_abs_epi32\" => Intrinsic {\n             inputs: vec![v(i(32), 8)],\n             output: v(i(32), 8),\n-            definition: Named(\"llvm.x86.avx2.avx2.pabs.d\")\n+            definition: Named(\"llvm.x86.avx2.pabs.d\")\n         },\n         \"256_adds_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 32), v(i(8), 32)],\n             output: v(i(8), 32),\n-            definition: Named(\"llvm.x86.avx2.avx2.padds.b\")\n+            definition: Named(\"llvm.x86.avx2.padds.b\")\n         },\n         \"256_adds_epu8\" => Intrinsic {\n             inputs: vec![v(u(8), 32), v(u(8), 32)],\n             output: v(u(8), 32),\n-            definition: Named(\"llvm.x86.avx2.avx2.paddus.b\")\n+            definition: Named(\"llvm.x86.avx2.paddus.b\")\n         },\n         \"256_adds_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 16), v(i(16), 16)],\n             output: v(i(16), 16),\n-            definition: Named(\"llvm.x86.avx2.avx2.padds.w\")\n+            definition: Named(\"llvm.x86.avx2.padds.w\")\n         },\n         \"256_adds_epu16\" => Intrinsic {\n             inputs: vec![v(u(16), 16), v(u(16), 16)],\n             output: v(u(16), 16),\n-            definition: Named(\"llvm.x86.avx2.avx2.paddus.w\")\n+            definition: Named(\"llvm.x86.avx2.paddus.w\")\n         },\n         \"256_avg_epu8\" => Intrinsic {\n             inputs: vec![v(u(8), 32), v(u(8), 32)],\n             output: v(u(8), 32),\n-            definition: Named(\"llvm.x86.avx2.avx2.pavg.b\")\n+            definition: Named(\"llvm.x86.avx2.pavg.b\")\n         },\n         \"256_avg_epu16\" => Intrinsic {\n             inputs: vec![v(u(16), 16), v(u(16), 16)],\n             output: v(u(16), 16),\n-            definition: Named(\"llvm.x86.avx2.avx2.pavg.w\")\n+            definition: Named(\"llvm.x86.avx2.pavg.w\")\n         },\n         \"256_hadd_epi16\" => Intrinsic {\n             inputs: vec![v(i(16), 16), v(i(16), 16)],\n@@ -710,6 +815,126 @@ pub fn find<'tcx>(_tcx: &ty::ctxt<'tcx>, name: &str) -> Option<Intrinsic> {\n             output: v(i(16), 16),\n             definition: Named(\"llvm.x86.avx2.pmadd.ub.sw\")\n         },\n+        \"_mask_i32gather_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), p(true, i(32), Some(i(8))), v(i(32), 4), v(i(32), 4), i_(32, 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.d.d\")\n+        },\n+        \"_mask_i32gather_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), p(true, f(32), Some(i(8))), v(i(32), 4), v_(i(32), f(32), 4), i_(32, 8)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.d.ps\")\n+        },\n+        \"256_mask_i32gather_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 8), p(true, i(32), Some(i(8))), v(i(32), 8), v(i(32), 8), i_(32, 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.gather.d.d.256\")\n+        },\n+        \"256_mask_i32gather_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 8), p(true, f(32), Some(i(8))), v(i(32), 8), v_(i(32), f(32), 8), i_(32, 8)],\n+            output: v(f(32), 8),\n+            definition: Named(\"llvm.x86.avx2.gather.d.ps.256\")\n+        },\n+        \"_mask_i32gather_epi64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), p(true, i(64), Some(i(8))), v(i(32), 4), v(i(64), 2), i_(32, 8)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.x86.avx2.gather.d.q\")\n+        },\n+        \"_mask_i32gather_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), p(true, f(64), Some(i(8))), v(i(32), 4), v_(i(64), f(64), 2), i_(32, 8)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.avx2.gather.d.pd\")\n+        },\n+        \"256_mask_i32gather_epi64\" => Intrinsic {\n+            inputs: vec![v(i(64), 4), p(true, i(64), Some(i(8))), v(i(32), 4), v(i(64), 4), i_(32, 8)],\n+            output: v(i(64), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.d.q.256\")\n+        },\n+        \"256_mask_i32gather_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), p(true, f(64), Some(i(8))), v(i(32), 4), v_(i(64), f(64), 4), i_(32, 8)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.d.pd.256\")\n+        },\n+        \"_mask_i64gather_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), p(true, i(32), Some(i(8))), v(i(64), 2), v(i(32), 4), i_(32, 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.d\")\n+        },\n+        \"_mask_i64gather_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), p(true, f(32), Some(i(8))), v(i(64), 2), v_(i(32), f(32), 4), i_(32, 8)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.ps\")\n+        },\n+        \"256_mask_i64gather_epi32\" => Intrinsic {\n+            inputs: vec![v(i(32), 4), p(true, i(32), Some(i(8))), v(i(64), 4), v(i(32), 4), i_(32, 8)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.d\")\n+        },\n+        \"256_mask_i64gather_ps\" => Intrinsic {\n+            inputs: vec![v(f(32), 4), p(true, f(32), Some(i(8))), v(i(64), 4), v_(i(32), f(32), 4), i_(32, 8)],\n+            output: v(f(32), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.ps\")\n+        },\n+        \"_mask_i64gather_epi64\" => Intrinsic {\n+            inputs: vec![v(i(64), 2), p(true, i(64), Some(i(8))), v(i(64), 2), v(i(64), 2), i_(32, 8)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.x86.avx2.gather.q.q\")\n+        },\n+        \"_mask_i64gather_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 2), p(true, f(64), Some(i(8))), v(i(64), 2), v_(i(64), f(64), 2), i_(32, 8)],\n+            output: v(f(64), 2),\n+            definition: Named(\"llvm.x86.avx2.gather.q.pd\")\n+        },\n+        \"256_mask_i64gather_epi64\" => Intrinsic {\n+            inputs: vec![v(i(64), 4), p(true, i(64), Some(i(8))), v(i(64), 4), v(i(64), 4), i_(32, 8)],\n+            output: v(i(64), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.q.256\")\n+        },\n+        \"256_mask_i64gather_pd\" => Intrinsic {\n+            inputs: vec![v(f(64), 4), p(true, f(64), Some(i(8))), v(i(64), 4), v_(i(64), f(64), 4), i_(32, 8)],\n+            output: v(f(64), 4),\n+            definition: Named(\"llvm.x86.avx2.gather.q.pd.256\")\n+        },\n+        \"_maskload_epi32\" => Intrinsic {\n+            inputs: vec![p(true, v(i(32), 4), Some(i(8))), v(i(32), 4)],\n+            output: v(i(32), 4),\n+            definition: Named(\"llvm.x86.avx2.maskload.d\")\n+        },\n+        \"_maskload_epi64\" => Intrinsic {\n+            inputs: vec![p(true, v(i(64), 2), Some(i(8))), v(i(64), 2)],\n+            output: v(i(64), 2),\n+            definition: Named(\"llvm.x86.avx2.maskload.q\")\n+        },\n+        \"256_maskload_epi32\" => Intrinsic {\n+            inputs: vec![p(true, v(i(32), 8), Some(i(8))), v(i(32), 8)],\n+            output: v(i(32), 8),\n+            definition: Named(\"llvm.x86.avx2.maskload.d.256\")\n+        },\n+        \"256_maskload_epi64\" => Intrinsic {\n+            inputs: vec![p(true, v(i(64), 4), Some(i(8))), v(i(64), 4)],\n+            output: v(i(64), 4),\n+            definition: Named(\"llvm.x86.avx2.maskload.q.256\")\n+        },\n+        \"_maskstore_epi32\" => Intrinsic {\n+            inputs: vec![p(false, i(32), Some(i(8))), v(i(32), 4), v(i(32), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx2.maskstore.d\")\n+        },\n+        \"_maskstore_epi64\" => Intrinsic {\n+            inputs: vec![p(false, i(64), Some(i(8))), v(i(64), 2), v(i(64), 2)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx2.maskstore.q\")\n+        },\n+        \"256_maskstore_epi32\" => Intrinsic {\n+            inputs: vec![p(false, i(32), Some(i(8))), v(i(32), 8), v(i(32), 8)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx2.maskstore.d.256\")\n+        },\n+        \"256_maskstore_epi64\" => Intrinsic {\n+            inputs: vec![p(false, i(64), Some(i(8))), v(i(64), 4), v(i(64), 4)],\n+            output: void(),\n+            definition: Named(\"llvm.x86.avx2.maskstore.q.256\")\n+        },\n         \"256_max_epi8\" => Intrinsic {\n             inputs: vec![v(i(8), 32), v(i(8), 32)],\n             output: v(i(8), 32),"}, {"sha": "bcfd44d8835d7605d257db184fcc2295367b7e9a", "filename": "src/librustc_trans/trans/intrinsic.rs", "status": "modified", "additions": 47, "deletions": 6, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_trans%2Ftrans%2Fintrinsic.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -936,6 +936,7 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                           any_changes_needed: &mut bool) -> Vec<Type> {\n                 use intrinsics::Type::*;\n                 match *t {\n+                    Void => vec![Type::void(ccx)],\n                     Integer(_signed, width, llvm_width) => {\n                         *any_changes_needed |= width != llvm_width;\n                         vec![Type::ix(ccx, llvm_width as u64)]\n@@ -947,14 +948,29 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                             _ => unreachable!()\n                         }\n                     }\n-                    Pointer(_) => unimplemented!(),\n-                    Vector(ref t, length) => {\n+                    Pointer(ref t, ref llvm_elem, _const) => {\n+                        *any_changes_needed |= llvm_elem.is_some();\n+\n+                        let t = llvm_elem.as_ref().unwrap_or(t);\n+                        let elem = one(ty_to_type(ccx, t,\n+                                                  any_changes_needed));\n+                        vec![elem.ptr_to()]\n+                    }\n+                    Vector(ref t, ref llvm_elem, length) => {\n+                        *any_changes_needed |= llvm_elem.is_some();\n+\n+                        let t = llvm_elem.as_ref().unwrap_or(t);\n                         let elem = one(ty_to_type(ccx, t,\n                                                   any_changes_needed));\n                         vec![Type::vector(&elem,\n                                           length as u64)]\n                     }\n-                    Aggregate(false, _) => unimplemented!(),\n+                    Aggregate(false, ref contents) => {\n+                        let elems = contents.iter()\n+                                            .map(|t| one(ty_to_type(ccx, t, any_changes_needed)))\n+                                            .collect::<Vec<_>>();\n+                        vec![Type::struct_(ccx, &elems, false)]\n+                    }\n                     Aggregate(true, ref contents) => {\n                         *any_changes_needed = true;\n                         contents.iter()\n@@ -965,8 +981,9 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n             }\n \n             // This allows an argument list like `foo, (bar, baz),\n-            // qux` to be converted into `foo, bar, baz, qux`, and\n-            // integer arguments to be truncated as needed.\n+            // qux` to be converted into `foo, bar, baz, qux`, integer\n+            // arguments to be truncated as needed and pointers to be\n+            // cast.\n             fn modify_as_needed<'blk, 'tcx>(bcx: Block<'blk, 'tcx>,\n                                             t: &intrinsics::Type,\n                                             arg_type: Ty<'tcx>,\n@@ -991,6 +1008,16 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n                             })\n                             .collect()\n                     }\n+                    intrinsics::Type::Pointer(_, Some(ref llvm_elem), _) => {\n+                        let llvm_elem = one(ty_to_type(bcx.ccx(), llvm_elem, &mut false));\n+                        vec![PointerCast(bcx, llarg,\n+                                         llvm_elem.ptr_to())]\n+                    }\n+                    intrinsics::Type::Vector(_, Some(ref llvm_elem), length) => {\n+                        let llvm_elem = one(ty_to_type(bcx.ccx(), llvm_elem, &mut false));\n+                        vec![BitCast(bcx, llarg,\n+                                     Type::vector(&llvm_elem, length as u64))]\n+                    }\n                     intrinsics::Type::Integer(_, width, llvm_width) if width != llvm_width => {\n                         // the LLVM intrinsic uses a smaller integer\n                         // size than the C intrinsic's signature, so\n@@ -1027,14 +1054,28 @@ pub fn trans_intrinsic_call<'a, 'blk, 'tcx>(mut bcx: Block<'blk, 'tcx>,\n             };\n             assert_eq!(inputs.len(), llargs.len());\n \n-            match intr.definition {\n+            let val = match intr.definition {\n                 intrinsics::IntrinsicDef::Named(name) => {\n                     let f = declare::declare_cfn(ccx,\n                                                  name,\n                                                  Type::func(&inputs, &outputs),\n                                                  tcx.mk_nil());\n                     Call(bcx, f, &llargs, None, call_debug_location)\n                 }\n+            };\n+\n+            match intr.output {\n+                intrinsics::Type::Aggregate(flatten, ref elems) => {\n+                    // the output is a tuple so we need to munge it properly\n+                    assert!(!flatten);\n+\n+                    for i in 0..elems.len() {\n+                        let val = ExtractValue(bcx, val, i);\n+                        Store(bcx, val, StructGEP(bcx, llresult, i));\n+                    }\n+                    C_nil(ccx)\n+                }\n+                _ => val,\n             }\n         }\n     };"}, {"sha": "d1f898d82fdd395bd17fd29e13fd5b7a765f1cec", "filename": "src/librustc_typeck/check/intrinsic.rs", "status": "modified", "additions": 19, "deletions": 2, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "raw_url": "https://github.com/rust-lang/rust/raw/7ee876cb8e0e3308669d3e00faa3ffe1034ca562/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/src%2Flibrustc_typeck%2Fcheck%2Fintrinsic.rs?ref=7ee876cb8e0e3308669d3e00faa3ffe1034ca562", "patch": "@@ -464,6 +464,10 @@ fn match_intrinsic_type_to_type<'tcx, 'a>(\n     };\n \n     match *expected {\n+        Void => match t.sty {\n+            ty::TyTuple(ref v) if v.is_empty() => {},\n+            _ => simple_error(&format!(\"`{}`\", t), \"()\"),\n+        },\n         // (The width we pass to LLVM doesn't concern the type checker.)\n         Integer(signed, bits, _llvm_width) => match (signed, bits, &t.sty) {\n             (true,  8,  &ty::TyInt(hir::IntTy::TyI8)) |\n@@ -485,8 +489,21 @@ fn match_intrinsic_type_to_type<'tcx, 'a>(\n             _ => simple_error(&format!(\"`{}`\", t),\n                               &format!(\"`f{n}`\", n = bits)),\n         },\n-        Pointer(_) => unimplemented!(),\n-        Vector(ref inner_expected, len) => {\n+        Pointer(ref inner_expected, ref _llvm_type, const_) => {\n+            match t.sty {\n+                ty::TyRawPtr(ty::TypeAndMut { ty, mutbl }) => {\n+                    if (mutbl == hir::MutImmutable) != const_ {\n+                        simple_error(&format!(\"`{}`\", t),\n+                                     if const_ {\"const pointer\"} else {\"mut pointer\"})\n+                    }\n+                    match_intrinsic_type_to_type(tcx, position, span, structural_to_nominal,\n+                                                 inner_expected, ty)\n+                }\n+                _ => simple_error(&format!(\"`{}`\", t),\n+                                  &format!(\"raw pointer\")),\n+            }\n+        }\n+        Vector(ref inner_expected, ref _llvm_type, len) => {\n             if !t.is_simd() {\n                 simple_error(&format!(\"non-simd type `{}`\", t),\n                              \"simd type\");"}]}