{"sha": "63fd643d725512cf41fb818a76f25ce7f5465327", "node_id": "C_kwDOAAsO6NoAKDYzZmQ2NDNkNzI1NTEyY2Y0MWZiODE4YTc2ZjI1Y2U3ZjU0NjUzMjc", "commit": {"author": {"name": "Florian Diebold", "email": "flodiebold@gmail.com", "date": "2022-02-09T15:30:10Z"}, "committer": {"name": "Florian Diebold", "email": "flodiebold@gmail.com", "date": "2022-02-09T15:30:10Z"}, "message": "Various fixes", "tree": {"sha": "d5f5d47f0702274d517fe2ecffc4f669be188a51", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/d5f5d47f0702274d517fe2ecffc4f669be188a51"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/63fd643d725512cf41fb818a76f25ce7f5465327", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/63fd643d725512cf41fb818a76f25ce7f5465327", "html_url": "https://github.com/rust-lang/rust/commit/63fd643d725512cf41fb818a76f25ce7f5465327", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/63fd643d725512cf41fb818a76f25ce7f5465327/comments", "author": {"login": "flodiebold", "id": 906069, "node_id": "MDQ6VXNlcjkwNjA2OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/906069?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flodiebold", "html_url": "https://github.com/flodiebold", "followers_url": "https://api.github.com/users/flodiebold/followers", "following_url": "https://api.github.com/users/flodiebold/following{/other_user}", "gists_url": "https://api.github.com/users/flodiebold/gists{/gist_id}", "starred_url": "https://api.github.com/users/flodiebold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flodiebold/subscriptions", "organizations_url": "https://api.github.com/users/flodiebold/orgs", "repos_url": "https://api.github.com/users/flodiebold/repos", "events_url": "https://api.github.com/users/flodiebold/events{/privacy}", "received_events_url": "https://api.github.com/users/flodiebold/received_events", "type": "User", "site_admin": false}, "committer": {"login": "flodiebold", "id": 906069, "node_id": "MDQ6VXNlcjkwNjA2OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/906069?v=4", "gravatar_id": "", "url": "https://api.github.com/users/flodiebold", "html_url": "https://github.com/flodiebold", "followers_url": "https://api.github.com/users/flodiebold/followers", "following_url": "https://api.github.com/users/flodiebold/following{/other_user}", "gists_url": "https://api.github.com/users/flodiebold/gists{/gist_id}", "starred_url": "https://api.github.com/users/flodiebold/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/flodiebold/subscriptions", "organizations_url": "https://api.github.com/users/flodiebold/orgs", "repos_url": "https://api.github.com/users/flodiebold/repos", "events_url": "https://api.github.com/users/flodiebold/events{/privacy}", "received_events_url": "https://api.github.com/users/flodiebold/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bdb7ae5dd055e5ee4ab7b2e008f4299172a67709", "url": "https://api.github.com/repos/rust-lang/rust/commits/bdb7ae5dd055e5ee4ab7b2e008f4299172a67709", "html_url": "https://github.com/rust-lang/rust/commit/bdb7ae5dd055e5ee4ab7b2e008f4299172a67709"}], "stats": {"total": 100, "additions": 75, "deletions": 25}, "files": [{"sha": "75766a54a74f7920e16746860ed39bf750bb8507", "filename": "crates/hir_expand/src/db.rs", "status": "modified", "additions": 15, "deletions": 7, "changes": 22, "blob_url": "https://github.com/rust-lang/rust/blob/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "raw_url": "https://github.com/rust-lang/rust/raw/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Fdb.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fdb.rs?ref=63fd643d725512cf41fb818a76f25ce7f5465327", "patch": "@@ -111,7 +111,7 @@ pub trait AstDatabase: SourceDatabase {\n     fn macro_arg(\n         &self,\n         id: MacroCallId,\n-    ) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupMap)>>;\n+    ) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>>;\n     /// Extracts syntax node, corresponding to a macro call. That's a firewall\n     /// query, only typing in the macro call itself changes the returned\n     /// subtree.\n@@ -151,8 +151,10 @@ pub fn expand_speculative(\n     let censor = censor_for_macro_input(&loc, &speculative_args);\n     let mut fixups = fixup::fixup_syntax(&speculative_args);\n     fixups.replace.extend(censor.into_iter().map(|node| (node, Vec::new())));\n-    let (mut tt, spec_args_tmap) = mbe::syntax_node_to_token_tree_with_modifications(\n+    let (mut tt, spec_args_tmap, _) = mbe::syntax_node_to_token_tree_with_modifications(\n         &speculative_args,\n+        fixups.token_map,\n+        fixups.next_id,\n         fixups.replace,\n         fixups.append,\n     );\n@@ -202,14 +204,15 @@ pub fn expand_speculative(\n \n     // Do the actual expansion, we need to directly expand the proc macro due to the attribute args\n     // Otherwise the expand query will fetch the non speculative attribute args and pass those instead.\n-    let speculative_expansion = if let MacroDefKind::ProcMacro(expander, ..) = loc.def.kind {\n+    let mut speculative_expansion = if let MacroDefKind::ProcMacro(expander, ..) = loc.def.kind {\n         tt.delimiter = None;\n         expander.expand(db, loc.krate, &tt, attr_arg.as_ref())\n     } else {\n         macro_def.expand(db, actual_macro_call, &tt)\n     };\n \n     let expand_to = macro_expand_to(db, actual_macro_call);\n+    fixup::reverse_fixups(&mut speculative_expansion.value, &spec_args_tmap, &fixups.undo_info);\n     let (node, rev_tmap) = token_tree_to_syntax_node(&speculative_expansion.value, expand_to);\n \n     let range = rev_tmap.first_range_by_token(token_id, token_to_map.kind())?;\n@@ -300,23 +303,28 @@ fn parse_macro_expansion(\n fn macro_arg(\n     db: &dyn AstDatabase,\n     id: MacroCallId,\n-) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupMap)>> {\n+) -> Option<Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>> {\n     let arg = db.macro_arg_text(id)?;\n     let loc = db.lookup_intern_macro_call(id);\n \n     let node = SyntaxNode::new_root(arg);\n     let censor = censor_for_macro_input(&loc, &node);\n     let mut fixups = fixup::fixup_syntax(&node);\n     fixups.replace.extend(censor.into_iter().map(|node| (node, Vec::new())));\n-    let (mut tt, tmap) =\n-        mbe::syntax_node_to_token_tree_with_modifications(&node, fixups.replace, fixups.append);\n+    let (mut tt, tmap, _) = mbe::syntax_node_to_token_tree_with_modifications(\n+        &node,\n+        fixups.token_map,\n+        fixups.next_id,\n+        fixups.replace,\n+        fixups.append,\n+    );\n \n     if loc.def.is_proc_macro() {\n         // proc macros expect their inputs without parentheses, MBEs expect it with them included\n         tt.delimiter = None;\n     }\n \n-    Some(Arc::new((tt, tmap, fixups.map)))\n+    Some(Arc::new((tt, tmap, fixups.undo_info)))\n }\n \n fn censor_for_macro_input(loc: &MacroCallLoc, node: &SyntaxNode) -> FxHashSet<SyntaxNode> {"}, {"sha": "36425c8078036fef729e6046ac1c19bc8e4e47da", "filename": "crates/hir_expand/src/fixup.rs", "status": "modified", "additions": 42, "deletions": 11, "changes": 53, "blob_url": "https://github.com/rust-lang/rust/blob/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Ffixup.rs", "raw_url": "https://github.com/rust-lang/rust/raw/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Ffixup.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Ffixup.rs?ref=63fd643d725512cf41fb818a76f25ce7f5465327", "patch": "@@ -1,3 +1,7 @@\n+//! To make attribute macros work reliably when typing, we need to take care to\n+//! fix up syntax errors in the code we're passing to them.\n+use std::mem;\n+\n use mbe::{SyntheticToken, SyntheticTokenId, TokenMap};\n use rustc_hash::FxHashMap;\n use syntax::{\n@@ -6,16 +10,22 @@ use syntax::{\n };\n use tt::Subtree;\n \n+/// The result of calculating fixes for a syntax node -- a bunch of changes\n+/// (appending to and replacing nodes), the information that is needed to\n+/// reverse those changes afterwards, and a token map.\n #[derive(Debug)]\n pub struct SyntaxFixups {\n     pub append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n     pub replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-    pub map: SyntaxFixupMap,\n+    pub undo_info: SyntaxFixupUndoInfo,\n+    pub token_map: TokenMap,\n+    pub next_id: u32,\n }\n \n+/// This is the information needed to reverse the fixups.\n #[derive(Debug, PartialEq, Eq)]\n-pub struct SyntaxFixupMap {\n-    original: Vec<(Subtree, TokenMap)>,\n+pub struct SyntaxFixupUndoInfo {\n+    original: Vec<Subtree>,\n }\n \n const EMPTY_ID: SyntheticTokenId = SyntheticTokenId(!0);\n@@ -25,15 +35,26 @@ pub fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n     let mut replace = FxHashMap::default();\n     let mut preorder = node.preorder();\n     let mut original = Vec::new();\n+    let mut token_map = TokenMap::default();\n+    let mut next_id = 0;\n     while let Some(event) = preorder.next() {\n         let node = match event {\n             syntax::WalkEvent::Enter(node) => node,\n             syntax::WalkEvent::Leave(_) => continue,\n         };\n+\n         if can_handle_error(&node) && has_error_to_handle(&node) {\n             // the node contains an error node, we have to completely replace it by something valid\n-            let original_tree = mbe::syntax_node_to_token_tree(&node);\n-            // TODO handle token ids / token map\n+            let (original_tree, new_tmap, new_next_id) =\n+                mbe::syntax_node_to_token_tree_with_modifications(\n+                    &node,\n+                    mem::take(&mut token_map),\n+                    next_id,\n+                    Default::default(),\n+                    Default::default(),\n+                );\n+            token_map = new_tmap;\n+            next_id = new_next_id;\n             let idx = original.len() as u32;\n             original.push(original_tree);\n             let replacement = SyntheticToken {\n@@ -46,6 +67,8 @@ pub fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n             preorder.skip_subtree();\n             continue;\n         }\n+\n+        // In some other situations, we can fix things by just appending some tokens.\n         let end_range = TextRange::empty(node.text_range().end());\n         match_ast! {\n             match node {\n@@ -78,7 +101,13 @@ pub fn fixup_syntax(node: &SyntaxNode) -> SyntaxFixups {\n             }\n         }\n     }\n-    SyntaxFixups { append, replace, map: SyntaxFixupMap { original } }\n+    SyntaxFixups {\n+        append,\n+        replace,\n+        token_map,\n+        next_id,\n+        undo_info: SyntaxFixupUndoInfo { original },\n+    }\n }\n \n fn has_error(node: &SyntaxNode) -> bool {\n@@ -93,7 +122,7 @@ fn has_error_to_handle(node: &SyntaxNode) -> bool {\n     has_error(node) || node.children().any(|c| !can_handle_error(&c) && has_error_to_handle(&c))\n }\n \n-pub fn reverse_fixups(tt: &mut Subtree, token_map: &TokenMap, fixup_map: &SyntaxFixupMap) {\n+pub fn reverse_fixups(tt: &mut Subtree, token_map: &TokenMap, undo_info: &SyntaxFixupUndoInfo) {\n     tt.token_trees.retain(|tt| match tt {\n         tt::TokenTree::Leaf(leaf) => {\n             token_map.synthetic_token_id(leaf.id()).is_none()\n@@ -102,10 +131,10 @@ pub fn reverse_fixups(tt: &mut Subtree, token_map: &TokenMap, fixup_map: &Syntax\n         _ => true,\n     });\n     tt.token_trees.iter_mut().for_each(|tt| match tt {\n-        tt::TokenTree::Subtree(tt) => reverse_fixups(tt, token_map, fixup_map),\n+        tt::TokenTree::Subtree(tt) => reverse_fixups(tt, token_map, undo_info),\n         tt::TokenTree::Leaf(leaf) => {\n             if let Some(id) = token_map.synthetic_token_id(leaf.id()) {\n-                let (original, _original_tmap) = &fixup_map.original[id.0 as usize];\n+                let original = &undo_info.original[id.0 as usize];\n                 *tt = tt::TokenTree::Subtree(original.clone());\n             }\n         }\n@@ -123,8 +152,10 @@ mod tests {\n         let parsed = syntax::SourceFile::parse(ra_fixture);\n         eprintln!(\"parse: {:#?}\", parsed.syntax_node());\n         let fixups = super::fixup_syntax(&parsed.syntax_node());\n-        let (mut tt, tmap) = mbe::syntax_node_to_token_tree_with_modifications(\n+        let (mut tt, tmap, _) = mbe::syntax_node_to_token_tree_with_modifications(\n             &parsed.syntax_node(),\n+            fixups.token_map,\n+            fixups.next_id,\n             fixups.replace,\n             fixups.append,\n         );\n@@ -144,7 +175,7 @@ mod tests {\n             parse.syntax_node()\n         );\n \n-        reverse_fixups(&mut tt, &tmap, &fixups.map);\n+        reverse_fixups(&mut tt, &tmap, &fixups.undo_info);\n \n         // the fixed-up + reversed version should be equivalent to the original input\n         // (but token IDs don't matter)"}, {"sha": "d60734372c0cedd9589a2b789bb4fabfae4e2098", "filename": "crates/hir_expand/src/hygiene.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "raw_url": "https://github.com/rust-lang/rust/raw/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Fhygiene.rs?ref=63fd643d725512cf41fb818a76f25ce7f5465327", "patch": "@@ -128,7 +128,7 @@ struct HygieneInfo {\n     attr_input_or_mac_def_start: Option<InFile<TextSize>>,\n \n     macro_def: Arc<TokenExpander>,\n-    macro_arg: Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupMap)>,\n+    macro_arg: Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>,\n     macro_arg_shift: mbe::Shift,\n     exp_map: Arc<mbe::TokenMap>,\n }"}, {"sha": "37186532bbe50a1380894661327a3394d9d95628", "filename": "crates/hir_expand/src/lib.rs", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/rust-lang/rust/blob/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fhir_expand%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fhir_expand%2Fsrc%2Flib.rs?ref=63fd643d725512cf41fb818a76f25ce7f5465327", "patch": "@@ -427,7 +427,7 @@ pub struct ExpansionInfo {\n     attr_input_or_mac_def: Option<InFile<ast::TokenTree>>,\n \n     macro_def: Arc<TokenExpander>,\n-    macro_arg: Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupMap)>,\n+    macro_arg: Arc<(tt::Subtree, mbe::TokenMap, fixup::SyntaxFixupUndoInfo)>,\n     /// A shift built from `macro_arg`'s subtree, relevant for attributes as the item is the macro arg\n     /// and as such we need to shift tokens if they are part of an attributes input instead of their item.\n     macro_arg_shift: mbe::Shift,"}, {"sha": "83f97c4970cf19be0e3e2a3b8dd4196e7d7b7a51", "filename": "crates/mbe/src/syntax_bridge.rs", "status": "modified", "additions": 16, "deletions": 5, "changes": 21, "blob_url": "https://github.com/rust-lang/rust/blob/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "raw_url": "https://github.com/rust-lang/rust/raw/63fd643d725512cf41fb818a76f25ce7f5465327/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/crates%2Fmbe%2Fsrc%2Fsyntax_bridge.rs?ref=63fd643d725512cf41fb818a76f25ce7f5465327", "patch": "@@ -15,23 +15,32 @@ use crate::{to_parser_input::to_parser_input, tt_iter::TtIter, TokenMap};\n /// Convert the syntax node to a `TokenTree` (what macro\n /// will consume).\n pub fn syntax_node_to_token_tree(node: &SyntaxNode) -> (tt::Subtree, TokenMap) {\n-    syntax_node_to_token_tree_with_modifications(node, Default::default(), Default::default())\n+    let (subtree, token_map, _) = syntax_node_to_token_tree_with_modifications(\n+        node,\n+        Default::default(),\n+        0,\n+        Default::default(),\n+        Default::default(),\n+    );\n+    (subtree, token_map)\n }\n \n /// Convert the syntax node to a `TokenTree` (what macro will consume)\n /// with the censored range excluded.\n pub fn syntax_node_to_token_tree_with_modifications(\n     node: &SyntaxNode,\n+    existing_token_map: TokenMap,\n+    next_id: u32,\n     replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n     append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n-) -> (tt::Subtree, TokenMap) {\n+) -> (tt::Subtree, TokenMap, u32) {\n     let global_offset = node.text_range().start();\n-    let mut c = Convertor::new(node, global_offset, replace, append);\n+    let mut c = Convertor::new(node, global_offset, existing_token_map, next_id, replace, append);\n     let subtree = convert_tokens(&mut c);\n     c.id_alloc.map.shrink_to_fit();\n     always!(c.replace.is_empty(), \"replace: {:?}\", c.replace);\n     always!(c.append.is_empty(), \"append: {:?}\", c.append);\n-    (subtree, c.id_alloc.map)\n+    (subtree, c.id_alloc.map, c.id_alloc.next_id)\n }\n \n #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]\n@@ -510,14 +519,16 @@ impl Convertor {\n     fn new(\n         node: &SyntaxNode,\n         global_offset: TextSize,\n+        existing_token_map: TokenMap,\n+        next_id: u32,\n         mut replace: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n         mut append: FxHashMap<SyntaxNode, Vec<SyntheticToken>>,\n     ) -> Convertor {\n         let range = node.text_range();\n         let mut preorder = node.preorder_with_tokens();\n         let (first, synthetic) = Self::next_token(&mut preorder, &mut replace, &mut append);\n         Convertor {\n-            id_alloc: { TokenIdAlloc { map: TokenMap::default(), global_offset, next_id: 0 } },\n+            id_alloc: { TokenIdAlloc { map: existing_token_map, global_offset, next_id } },\n             current: first,\n             current_synthetic: synthetic,\n             preorder,"}]}