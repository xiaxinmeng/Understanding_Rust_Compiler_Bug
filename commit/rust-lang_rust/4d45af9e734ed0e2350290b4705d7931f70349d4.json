{"sha": "4d45af9e734ed0e2350290b4705d7931f70349d4", "node_id": "C_kwDOAAsO6NoAKDRkNDVhZjllNzM0ZWQwZTIzNTAyOTBiNDcwNWQ3OTMxZjcwMzQ5ZDQ", "commit": {"author": {"name": "Nika Layzell", "email": "nika@thelayzells.com", "date": "2022-05-15T17:46:33Z"}, "committer": {"name": "Nika Layzell", "email": "nika@thelayzells.com", "date": "2022-06-17T04:42:26Z"}, "message": "Try to reduce codegen complexity of TokenStream's FromIterator and Extend impls\n\nThis is an experimental patch to try to reduce the codegen complexity of\nTokenStream's FromIterator and Extend implementations for downstream\ncrates, by moving the core logic into a helper type. This might help\nimprove build performance of crates which depend on proc_macro as\niterators are used less, and the compiler may take less time to do\nthings like attempt specializations or other iterator optimizations.\n\nThe change intentionally sacrifices some optimization opportunities,\nsuch as using the specializations for collecting iterators derived from\nVec::into_iter() into Vec.\n\nThis is one of the simpler potential approaches to reducing the amount\nof code generated in crates depending on proc_macro, so it seems worth\ntrying before other more-involved changes.", "tree": {"sha": "982e7588463ee54a8acb9a10fced1e3db70fdd37", "url": "https://api.github.com/repos/rust-lang/rust/git/trees/982e7588463ee54a8acb9a10fced1e3db70fdd37"}, "url": "https://api.github.com/repos/rust-lang/rust/git/commits/4d45af9e734ed0e2350290b4705d7931f70349d4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/rust-lang/rust/commits/4d45af9e734ed0e2350290b4705d7931f70349d4", "html_url": "https://github.com/rust-lang/rust/commit/4d45af9e734ed0e2350290b4705d7931f70349d4", "comments_url": "https://api.github.com/repos/rust-lang/rust/commits/4d45af9e734ed0e2350290b4705d7931f70349d4/comments", "author": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mystor", "id": 1261662, "node_id": "MDQ6VXNlcjEyNjE2NjI=", "avatar_url": "https://avatars.githubusercontent.com/u/1261662?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mystor", "html_url": "https://github.com/mystor", "followers_url": "https://api.github.com/users/mystor/followers", "following_url": "https://api.github.com/users/mystor/following{/other_user}", "gists_url": "https://api.github.com/users/mystor/gists{/gist_id}", "starred_url": "https://api.github.com/users/mystor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mystor/subscriptions", "organizations_url": "https://api.github.com/users/mystor/orgs", "repos_url": "https://api.github.com/users/mystor/repos", "events_url": "https://api.github.com/users/mystor/events{/privacy}", "received_events_url": "https://api.github.com/users/mystor/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0a049fd30d564d1cbc2d60398de848612a6c8125", "url": "https://api.github.com/repos/rust-lang/rust/commits/0a049fd30d564d1cbc2d60398de848612a6c8125", "html_url": "https://github.com/rust-lang/rust/commit/0a049fd30d564d1cbc2d60398de848612a6c8125"}], "stats": {"total": 112, "additions": 94, "deletions": 18}, "files": [{"sha": "cc66eefac3e89f2d91ec6d81d82012e130d04deb", "filename": "compiler/rustc_expand/src/proc_macro_server.rs", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/rust-lang/rust/blob/4d45af9e734ed0e2350290b4705d7931f70349d4/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4d45af9e734ed0e2350290b4705d7931f70349d4/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/compiler%2Frustc_expand%2Fsrc%2Fproc_macro_server.rs?ref=4d45af9e734ed0e2350290b4705d7931f70349d4", "patch": "@@ -502,8 +502,8 @@ impl server::TokenStream for Rustc<'_, '_> {\n         &mut self,\n         stream: Self::TokenStream,\n     ) -> Vec<TokenTree<Self::Group, Self::Punct, Self::Ident, Self::Literal>> {\n-        // XXX: This is a raw port of the previous approach, and can probably be\n-        // optimized.\n+        // FIXME: This is a raw port of the previous approach, and can probably\n+        // be optimized.\n         let mut cursor = stream.into_trees();\n         let mut stack = Vec::new();\n         let mut tts = Vec::new();"}, {"sha": "6e645216c8dd269c739ae2f8ce3dba0050f54616", "filename": "library/proc_macro/src/lib.rs", "status": "modified", "additions": 92, "deletions": 16, "changes": 108, "blob_url": "https://github.com/rust-lang/rust/blob/4d45af9e734ed0e2350290b4705d7931f70349d4/library%2Fproc_macro%2Fsrc%2Flib.rs", "raw_url": "https://github.com/rust-lang/rust/raw/4d45af9e734ed0e2350290b4705d7931f70349d4/library%2Fproc_macro%2Fsrc%2Flib.rs", "contents_url": "https://api.github.com/repos/rust-lang/rust/contents/library%2Fproc_macro%2Fsrc%2Flib.rs?ref=4d45af9e734ed0e2350290b4705d7931f70349d4", "patch": "@@ -233,14 +233,90 @@ impl From<TokenTree> for TokenStream {\n     }\n }\n \n+/// Non-generic helper for implementing `FromIterator<TokenTree>` and\n+/// `Extend<TokenTree>` with less monomorphization in calling crates.\n+struct ExtendStreamWithTreesHelper {\n+    trees: Vec<\n+        bridge::TokenTree<\n+            bridge::client::Group,\n+            bridge::client::Punct,\n+            bridge::client::Ident,\n+            bridge::client::Literal,\n+        >,\n+    >,\n+}\n+\n+impl ExtendStreamWithTreesHelper {\n+    fn new(capacity: usize) -> Self {\n+        ExtendStreamWithTreesHelper { trees: Vec::with_capacity(capacity) }\n+    }\n+\n+    fn push(&mut self, tree: TokenTree) {\n+        self.trees.push(tree_to_bridge_tree(tree));\n+    }\n+\n+    fn build(self) -> TokenStream {\n+        if self.trees.is_empty() {\n+            TokenStream(None)\n+        } else {\n+            TokenStream(Some(bridge::client::TokenStream::concat_trees(None, self.trees)))\n+        }\n+    }\n+\n+    fn extend(self, stream: &mut TokenStream) {\n+        if self.trees.is_empty() {\n+            return;\n+        }\n+        stream.0 = Some(bridge::client::TokenStream::concat_trees(stream.0.take(), self.trees))\n+    }\n+}\n+\n+/// Non-generic helper for implementing `FromIterator<TokenStream>` and\n+/// `Extend<TokenStream>` with less monomorphization in calling crates.\n+struct ExtendStreamWithStreamsHelper {\n+    streams: Vec<bridge::client::TokenStream>,\n+}\n+\n+impl ExtendStreamWithStreamsHelper {\n+    fn new(capacity: usize) -> Self {\n+        ExtendStreamWithStreamsHelper { streams: Vec::with_capacity(capacity) }\n+    }\n+\n+    fn push(&mut self, stream: TokenStream) {\n+        if let Some(stream) = stream.0 {\n+            self.streams.push(stream);\n+        }\n+    }\n+\n+    fn build(mut self) -> TokenStream {\n+        if self.streams.len() <= 1 {\n+            TokenStream(self.streams.pop())\n+        } else {\n+            TokenStream(Some(bridge::client::TokenStream::concat_streams(None, self.streams)))\n+        }\n+    }\n+\n+    fn extend(mut self, stream: &mut TokenStream) {\n+        if self.streams.is_empty() {\n+            return;\n+        }\n+        let base = stream.0.take();\n+        if base.is_none() && self.streams.len() == 1 {\n+            stream.0 = self.streams.pop();\n+        } else {\n+            stream.0 = Some(bridge::client::TokenStream::concat_streams(base, self.streams));\n+        }\n+    }\n+}\n+\n /// Collects a number of token trees into a single stream.\n #[stable(feature = \"proc_macro_lib2\", since = \"1.29.0\")]\n impl iter::FromIterator<TokenTree> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenTree>>(trees: I) -> Self {\n-        TokenStream(Some(bridge::client::TokenStream::concat_trees(\n-            None,\n-            trees.into_iter().map(tree_to_bridge_tree).collect(),\n-        )))\n+        let iter = trees.into_iter();\n+        let mut builder = ExtendStreamWithTreesHelper::new(iter.size_hint().0);\n+        iter.for_each(|tree| builder.push(tree));\n+        builder.build()\n     }\n }\n \n@@ -249,30 +325,30 @@ impl iter::FromIterator<TokenTree> for TokenStream {\n #[stable(feature = \"proc_macro_lib\", since = \"1.15.0\")]\n impl iter::FromIterator<TokenStream> for TokenStream {\n     fn from_iter<I: IntoIterator<Item = TokenStream>>(streams: I) -> Self {\n-        TokenStream(Some(bridge::client::TokenStream::concat_streams(\n-            None,\n-            streams.into_iter().filter_map(|stream| stream.0).collect(),\n-        )))\n+        let iter = streams.into_iter();\n+        let mut builder = ExtendStreamWithStreamsHelper::new(iter.size_hint().0);\n+        iter.for_each(|stream| builder.push(stream));\n+        builder.build()\n     }\n }\n \n #[stable(feature = \"token_stream_extend\", since = \"1.30.0\")]\n impl Extend<TokenTree> for TokenStream {\n     fn extend<I: IntoIterator<Item = TokenTree>>(&mut self, trees: I) {\n-        *self = TokenStream(Some(bridge::client::TokenStream::concat_trees(\n-            self.0.take(),\n-            trees.into_iter().map(|tree| tree_to_bridge_tree(tree)).collect(),\n-        )));\n+        let iter = trees.into_iter();\n+        let mut builder = ExtendStreamWithTreesHelper::new(iter.size_hint().0);\n+        iter.for_each(|tree| builder.push(tree));\n+        builder.extend(self);\n     }\n }\n \n #[stable(feature = \"token_stream_extend\", since = \"1.30.0\")]\n impl Extend<TokenStream> for TokenStream {\n     fn extend<I: IntoIterator<Item = TokenStream>>(&mut self, streams: I) {\n-        *self = TokenStream(Some(bridge::client::TokenStream::concat_streams(\n-            self.0.take(),\n-            streams.into_iter().filter_map(|stream| stream.0).collect(),\n-        )));\n+        let iter = streams.into_iter();\n+        let mut builder = ExtendStreamWithStreamsHelper::new(iter.size_hint().0);\n+        iter.for_each(|stream| builder.push(stream));\n+        builder.extend(self);\n     }\n }\n "}]}